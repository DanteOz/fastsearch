{"text": " This is week 7 of 7, although in a sense it's week 7 of 14. No pressure and no commitment, but how many of you are thinking you might want to come back for part 2 next year? We started this, I thought if 1 in 5 people come back for part 2, I'll be happy. That's the best thing I've ever seen. Thank you so much. Today I'm going to show you, and I think you'll be surprised and maybe a little overwhelmed, what you can do with this little set of tools you've learned already. So this is going to be a kind of part 1 of this lesson. It's going to be a well-widened tour of a bunch of different architectures. And different architectures are not just different because some of them will be better at doing what we've been doing, but some of them will be doing different things. And I want to set your expectations and say that looking at an architecture and understanding how it does what it does is something that took me quite a few weeks to get an intuitive feel for it. So don't feel bad. As you'll see, it's like unprogramming. It's like we're going to describe something we would think would be great if the model knew how to do it, and then we'll say fit, and suddenly the model knows how to do it, and we'll look inside it and we'll be like, how does it know how to do that. The other thing I want to mention is, having said that, everything we're about to see uses only the things we've done to date. In the first half, we're only going to use CNS. There's going to be no cropping of images, there's going to be no filtering, there's going to be nothing hand-tuned, it's just going to be a bunch of convolutional or dense layers with activation functions. But we're going to put them together in some interesting ways. So let me start with one of the most important developments, perhaps, of the last year or two, which is called ResNet. ResNet won the 2015 ImageNet competition. I was delighted that it won it because it's an incredibly simple and intuitively understandable concept. It's very simple to implement. In fact, what I would like to do is to show you. Let me describe as best as I can how ResNet works. In fact, before I describe how it works, I will show you why you should care that it works. So let's for now just put aside the idea that there's a thing called ResNet, and it's another architecture, a lot like VGG, that's used for image classification or other CNN type things. It's actually broader than just image classification. We use it just the same way as we use the VGG16 class you're familiar with. We just say create something a ResNet. Again, there's different size ResNets. I'm going to use 50 because it's the smallest one and it works super well. I've started adding a prouder to my versions of these networks. I've added it to the new VGG as well, which is includeTop. It's actually the same as what the Keras author has started doing with his models. Basically the idea is that if you say includeTop equals false, you don't have to go model.pop afterwards to remove the layers if you want to fine-tune. IncludeTop equals false means only include the convolutional layers basically, and I'm going to stick my own final classification layers on top of that. So when I do this, it's not going to give me the last few layers. Maybe the best way to explain that is to show you when I create this network, I've got this thing at the end that says if includeTop, and if so then we add the last few layers with this last densely connected layer, which makes it just ImageNet things, it's probably 1000 categories. If we're not including Top, then don't add these additional layers. So this is just a thing which means you can load in a model which is specifically designed for fine-tuning. As you'll see shortly, it has some really helpful properties. We're in the Cats and Dogs competition here. The winner of the Cats and Dogs competition had an accuracy of 0.985 on the private leaderboard and 0.989 on the private leaderboard. We used this ResNet model in the same way as usual. We grab our batches, we can pre-compute some features. And in fact, every single CNN model I'm going to show you, we're always going to pre-compute the convolutional features. So everything we see today will be things you can do without retraining any of the convolutional layers. So pretty much everything I train will train in a small number of seconds. And that's because in my experience when you're working with photos, it's almost never helpful to retrain the convolutional layers. So we can stick something on top of our ResNet in the usual way. And we can say go ahead and compile and fit it. And in 48 seconds it's created a model with a 0.986 accuracy, which is win on the private leaderboard or be second on the private leaderboard. So that's pretty impressive. More impressive is, and I'm going to show you how this works in a moment, but ResNet is actually designed to not be used with a standard bunch of dense layers, but it's designed to be used with something called a global average pooling layer, which I'm about to describe to you. So for now let me just show you what happens if instead of the previous model, I instead use this model, which has 3 layers, and compile it, fit it, I get 0.9875 in 3 seconds. In fact I can even tell it that I don't want to use 224x224 images, but I want to use 400x400 images. And if I do that, and then in my get batches I say I want to create 400x400 images, and create those features, compile them, fit, I get 99.3. So this is kind of off the charts to go from somewhere around 98.5 to 99.3, we're reducing the amount of error by somewhere around a third to a half. So this is why you should be interested in ResNet. It's incredibly accurate. We're using it for the thing it's best at. This ResNet was trained on ImageNet, and the dogs and cats competition looks a lot like ImageNet images. They're single pictures of a single thing that's recently large in the picture, they're not very big images on the whole. And so this is something which this kind of ResNet approach is particularly good for. So I do actually want to show you how it works, because I think it's fascinating and awesome. And I'm going to stick to the same approach that we've used so far when we've talked about architectures. Any shape represents a matrix of activations, and any arrow represents a layer operation. So that's a convolution or a dense layer with an activation function. ResNet looks a lot like VGG. So I've mentioned that there's some part of the model down here that we're not going to worry about too much. We're kind of like halfway through the model, and there's some hidden activation layer that we've got to. With VGG, the approach is generally to go, the layers are basically a 3x3 conv, that gives you some activations, another 3x3 conv, that gives you some activations, another 3x3 conv, that gives you some activations, and then from time to time it also does a max pooling. So each of these is representing a convolution layer. ResNet looks a lot like this. In fact, it has exactly that path, which is a bunch of convolutions and relu's on top of each other. But it does something else, which is there's this bit that comes out. And remember, when we have two arrows coming into a shape, that means we're adding things. And you'll notice here, there's no shapes anywhere on the way here. In fact, this arrow does not represent a convolution, it does not represent a dense layer, it actually represents identity. In other words, we do nothing at all. This whole thing here is called a ResNet block. If we represented a ResNet block as a square, ResNet is just a whole bunch of these blocks stacked on top of each other. And then there's an input, which is the input data, and then the output. So another way of looking at this is just to look at the code. I think the code is nice and intuitive to understand. So let's have a look at this thing they call an identity block. So here's the code for what I just described. You might notice that everything I just selected here looks like a totally standard VGG block. I've got a conv2d, a batch normalization, and an activation function. I guess it looks like our improved VGG because it's got a batch normal. Another convolution, another batch normal, another activation. Another conv2d, another batch normal. But then this is the magic that makes it ResNet, this single line of code. And it does something incredibly simple. It takes the result of all those 3 convolutions and it adds it to our original input. So normally, we have the output of some block is equal to a kind of like a convolutions of convolutions of convolutions of some input to that block. But we're doing something different. We're saying the output to a block, so let's call this hidden state at time t plus 1, is equal to the convolutions of convolutions of convolutions of hidden state at time t plus the hidden state at time t. That is the magic which makes it ResNet. So why is it that that can give us this huge improvement in the state of the art in such a short period of time? And this is actually, interestingly, something that is somewhat controversial. The authors of this paper that originally developed this describe it in a number of ways. They basically gave 2 main reasons. The first is they claim that you can create much deeper networks this way. Because when you're backpropagating the weights, backpropagating through an identity is easy. You're never going to have an explosion of gradients or explosion of activations. And indeed, this did turn out to be true. The authors created a ResNet with over 1000 layers and got very good results. But it also turned out to be a bit of a red herring. Because a few months ago, some other folks created a ResNet which was not at all deep. I think it had like 40 or 50 layers. But instead it's very wide and had a lot of activations. And that did even better. So it's one of these funny things that seems even the original authors might have been wrong about why they built what they built. The second reason of why they built what they built seems to have stood the test of time forever. Which is that if we take this equation and rejig it, let's subtract that from both sides. And that gives us ht plus 1 minus ht. So the hidden activations at the next time period minus the hidden activations at the previous time period equals a convolution of convolution of convolution applied to the previous hidden state. When you run it like that, it might make you realize something. All of the weights we're learning here. So we're learning a bunch of weights which allow us to make our previous guess as to the predictions a little bit better. So basically saying let's take the previous predictions we've got, however we got to them, and try and build a set of things which makes them a little bit better. In statistics, this thing is called the residual. The residual is the difference between the thing you're trying to predict and your actuals. So what the authors of ResNet basically did here was they designed an architecture which, without us having to do anything special, automatically learns how to model the residuals. It learns how to build a bunch of layers which continually slightly improve the previous answer. For those of you who have more of a machine learning background, you would recognize this as essentially being boosting. Boosting refers to the idea of having a bunch of models where each model tries to predict the errors of the previous model. If you have a whole chain of those, you can then predict the errors on top of the errors, and you can add them all together, and boosting is a way of getting much improved ensembles. So this ResNet is not manually doing boosting, it's not manually doing anything. It's just this single one extra line of code. It's all in the architecture. Question about dimensionality. I would have assumed that by the time we were close to output, the dimensions would be so different that element-wise addition wouldn't be possible between the last layer and the first layer. It's important to note that this input tensor is the input tensor to the block. So you'll see there's no max pooling inside here, or no strides inside here. So the dimensionality remains constant throughout all these lines of code, so we can add them up. And then we can do our strides or max pooling, and then we do another identity block. So we're only adding it back to the input of the block, not the input of the original image. And that's indeed what we want. We want to say the input to each block is our best prediction so far is effectively what it's doing. Question about qualitatively. How does this compare to dropout? In most ways it's unrelated to dropout. And indeed you can add dropout to ResNet. At the end of a ResNet block, after this merge, you can add dropout. So ResNet is not a regularization technique per se. Having said that, it does seem to have excellent generalization characteristics. And if memory serves correctly, yes, I just searched this entire codebase for dropout and it didn't appear. So the ImageNet window didn't use any dropout, they didn't find it useful. But this is very problem-dependent. If you have only a small amount of data, you may well need dropout. I'll explain another reason we don't need dropout for this in just a moment. In fact, I'll do that right now. Which is, remember what I did here at the end was I created a model which had a special kind of layer called a global average falling layer. This is the next key thing I want to teach you about today. It's a really important concept that's going to come up a couple more times during today's class. Let's describe what this is. It's actually very simple. Here is the output of the pre-computed ResNet on our 400x400. It's 13x13. So on the 224x224, the pre-computed convolutional residual blocks give us a 13x13 output with 2048 fuel reset. One way of thinking about this would be to say, well each of these 13x13 blocks could potentially try to say how catty or how doggy each one of those 13 blocks is. So then rather than max-pulling, we could do average-pulling, which is to say across those 13x13 areas, what is the average amount of dogginess in each one, what is the average amount of cattiness in each one. That's actually what global average-pulling does. What global average-pulling does is it's identical to saying average-pulling 13x13 because the input to it is 13x13. So in other words, whatever the input to a global average-pulling layer is, it will take all of the x and all of the y coordinates and just take the average for every one of these 2048 filters. So what this is doing is it's taking an input of 2048x13 and it's going to return an output which is just a single vector of 2048. And that vector is on average how much does this whole image have each of those 2048 filters. This ResNet actually was originally trained with global average-pulling 2D. This was actually written before the global average-pulling 2D layer existed, so they just did it manually. I'm going to put an average-pulling 7.7 here. So because ResNet was trained originally with this layer, that means that it was trained such that the last identity block was basically creating features that were designed to be averaged together. So that means that when we used this tiny little architecture, we got the best results because that was how ResNet was originally designed to be used. Question asked. If you had a wider network without the input fed forward to the output activation, couldn't you get the same result? The extra activations in the wider network could pass the input all the way through all the layers. Answer the question. Well, you can in theory have convolutional filters that don't do anything, as you can act as a multi-entity matrix. But the point is, having to learn that is learning lots and lots of filters designed to learn that. And so maybe the best way I can describe this is, everything I'm telling you about architectures is in some ways irrelevant. You could create nothing but dense layers at every level of your model. And dense layers have every input connected to every output. So every architecture I'm telling you about is just a simplified version of that. We're just deleting some of those. But it's really helpful to do that. It's really helpful to help our SGD optimizer by making it so that the default thing it can do is the thing that we want. So yes, in theory, a conv net or a native fully connected net could learn to do the same thing that resnet does. In practice, it would take a lot of parameters for it to do so and time to do so. So this is why we care about architectures. In practice, having a good architecture makes a huge difference. Question, would it be fair to say that if VGG was trained with average pooling, it would yield better results? Answer that question. I'm not sure. So let's talk about that a little bit. One of the reasons or maybe the main reason that resnet didn't need dropout is because we're using global average pooling. Because we're using global average pooling, there's a hell of a lot less parameters in this model. Remember, the vast majority of the parameters in the model are in the dense layers. Because if you've got n inputs and n outputs, you have n times m connections. So in VGG, I can't quite remember, but that first dense layer had something like 300 million parameters. Because it had every possible feature of the convolutional layer by each of the 3 basic limitations of the convolutional layer by every one of the 4,000 outputs. So it just created a lot of features and made it very easy to overfit. So with global average pooling and indeed not having any dense layers, we have a lot less parameters, so it's going to generalize better. It also generalizes better because we're treating every one of those 7x7 or 13x13 areas in the same way. We're saying how doggy or catty are each of these, we're just averaging them. So it turns out that these global average pooling layer models do seem to generalize very well. We're going to be seeing more of that in a moment. Question-3. How do you use global average pooling instead of max pooling? You wouldn't want to max pool over... well, it depends. You can try both. In this case, the images in the dogs and cats competition is basically an image where nearly the entire frame is a dog or a cat. So if you did max pooling, you would say which bit of that 7x7 or 13x13 grid that we've down sampled down to has the most dogginess or cattiness, and I only care about that. That's unlikely to give you the best results, despite us saying let's look at every part of the image and have it more together. On the other hand, I haven't tried this. The fisheries competition. The fish is generally a very small part of each image. So maybe in the fisheries competition you should use a global max pooling layer. Give it a try and tell us how it goes. Because in that case, you actually don't care about all the parts of the image which have nothing to do with fish. That would be a very interesting thing to try. ResNet is very powerful, but it has not been studied much at all for transfer learning. This is not to say it won't work well for transfer learning. I just literally haven't found a single paper yet where somebody has analyzed its effectiveness for transfer learning. And to me, 99.9999% of what you'll work on will be transfer learning. Because if you're not using transfer learning, it means you're looking at a dataset that is so different to anything that anybody has looked at before that none of the features in any model is remotely helpful for you. That's going to be rare. Nearly all of the work I've seen on transfer learning, both in terms of CABL winners and in terms of papers, uses VGG. And I think one of the reasons for that is, as we talked about in lesson 1, the VGG architecture really is designed to create layers of gradually increasing semantic complexity. All the work I've seen on visualizing layers tends to use VGG or something similar to that as well, like that Matt Zylostuff we saw or those Jason Yosinski videos we saw. So we've seen how the VGG network, those kinds of networks, create gradually more complex representations, which is exactly what we want for transfer learning. Because it lets us say, how different is this new domain to the previous domain, and then we can pick a layer far enough back, we can try a few, that the features seem to work well. So for that reason we're going to go back to looking at VGG now for the rest of these architectures. I'm going to look at the fisheries competition. The fisheries competition is actually very interesting. The pictures are from a dozen boats, and each one of these boats has a fixed camera. They can do both daytime and nighttime shots. So every picture has the same basic shape and structure for each of the 12 boats, because it's a fixed camera. And then somewhere in there, most of the time, there's one or more fish. And your job is to say what kind of fish is it. The fish are pretty small. So one of the things that makes this interesting is that this is the kind of somewhat weird, kind of complex, different thing to ImageNet, which is exactly the kind of stuff you're going to have to deal with any time you're doing some kind of computer vision problem or any kind of CNN problem. It's very likely that the thing you're doing won't be quite the same as what all the academics have been looking at. So trying to figure out how to do a good job of the fisheries competition is a great example. When I started on the fisheries competition, I just did the usual thing, which was to create a VGG16 model, fine-tuned it to have just 8 outputs, because we have to say which of 8 types of fish do we see in it. And then I, as per usual, pre-computed the convolutional layers using the pre-chained VGG network. And then everything after that, I just used those pre-computed convolutional layers. And as per usual, the first thing I did was to stick a few dense layers on top and see how that goes. So the nice thing about this is you can see each epoch takes less than a second to run. So when people talk about needing lots of data or lots of time, it's not really true because for most stuff you do in real life, you're only using pre-computed convolutional features. And in our validation set, we get an accuracy of 96.2%, approximately loss of 0.8%. That's pretty good. We seem to be recognizing the fish pretty well. But here's the problem. There is all kinds of data leakage going on. And this is one of the most important concepts to understand when it comes to building any kind of model or any kind of machine learning project leakage. There was a paper, I think it actually won the KDD Best Paper award a couple of years ago from Claudia Perlich and some of her colleagues, which studied data leakage. Data leakage occurs when something about the target you're trying to predict is encoded in the things that you're predicting with, but that information is either not going to be available or it won't be helpful in practice when you're going to use the model. For example, in a fisheries competition, different boats fish in different parts of the sea. Different parts of the sea have different fish in them. And so in the fisheries competition, if you just use something representing which boat the image came from, you can get a pretty good accurate validation set result. What I mean by that, for example, is here's something which is very tricky. This is a list of the size of each photo along with how many times that appears. You can see it has gone through every photo and opened it using PIL, which is the Python Imaging Library, and graded size. You can see that there's basically a small number of sizes that appear. It turns out that if you create a simple linear model that says any image of size 1192x670 or anything with 1280x720, you get a pretty accurate model. Because these are the different ships. The different ships have different cameras. And this isn't helpful in practice because what the fisheries people actually wanted to do was to use this to find out when people are illegally or accidentally overfishing or fishing in the wrong way. So if they're bringing up dolphins or something, they want to know about it. So any model that says I know what kind of fish this is because I know what the boat is, is entirely useless. So this is an example of leakage. In this particular paper I mentioned, the authors looked at machine learning competitions and discovered that over 50% of them had some kind of data leakage. I spoke to Claudia after she presented that paper and I asked her if she thought that regular machine learning projects in inside companies would have more or less leakage than that, and she said a lot more. Because in competitions, people have tried really hard to clean up the data ahead of time because they know that lots and lots of people are going to be looking at it. And if there is leakage, you're almost certain that somebody's going to find it because it's a competition. Whereas if you have leakage in your dataset, it's very likely you won't even know about it until you try to put the model into production and discover that it doesn't work as well as you thought it would. I was just going to add that it might not even help you in the competition if your test set is brand new boats that weren't in your training set. So trying to win a Kaggle competition and trying to do a good job are somewhat independent. When I'm working on Kaggle, I focus on trying to win the Kaggle competition. I have a clear metric and I try to optimize the metric. And sometimes that means finding leakage and taking advantage of it. So in this case, step number 1 for me in the fisheries competition was to say, can I take advantage of this leakage? I want to be very clear. This is the exact opposite of what you would want to do if you were actually trying to help the fisheries people create a good model. Having said that, there's $150,000 at stake and I could donate that to the Fred Pollard Foundation and get lots of people their site back. So winning this would be good. So let me show you how I try to take advantage of this leakage, which is totally legal in a Kaggle competition, and see what happens. And then I'll talk more about Rachel's issue after that. So the first thing I did was I made a list for every file of how big the NNP dimensions were. And I did that for the validation of the training set. I normalized them by subtracting the mean and dividing them by standard deviation. And then I created an almost exact copy of the previous model I showed you. But this time, rather than using the sequential API, I used the functional API. But other than that, this is almost identical. The only difference is in this line, where what I've done is I've taken not just the input which is the output of the last convolutional layer of my VGG model, but I have a second input. And the second input is what size image is it. And I should mention I have one hot encoded those image sizes so they're treated as categories. So I now have an additional input. So I have two inputs. One is the output of the VGG convolutional layer, one is the one hot encoded image size. I batch normalized that, obviously. And then right at the very last step, I concatenate the two together. So my model is basically a standard last few layers of VGG model, so 3 dense layers. And then I have my input, and then I have another input. And it's not being signed for being concatenated. And that creates the output. So what this can do now is that that last dense layer can now learn to combine the image features along with this metadata. This is useful for all kinds of things other than taking advantage in a vastly way of leakage. For example, if you were doing a collaborative filtering model, you might have information about the user, such as their age, their gender, their favorite genres, they asked to be mentioned on a survey. This is how you incorporate that kind of metadata into a standard neural net. So I batch the two together and run it. And initially it's looking encouraging. If we go back and look at the standard model, we have.84,.94,.95. This multi-input model is a little better,.86,.95,.96. So that's encouraging. But interestingly, the model without using the leakage gets somewhere around 96.5, 97.5, maybe even 98. It's kind of all over the place, which isn't a great sign. But let's say somewhere around 97, 97.5. This multi-input model, on the other hand, does not get better than that. Its best is also around 97.5. Why is that? This is very, very common when people try to utilize metadata in deep learning models. It often turns out that the main thing you're looking at, in this case the image, already encodes everything that your metadata has anyway. In this case, the size of the image tells us what Bodo comes from, but you can also just look at the picture and see what Bodo comes from. So by the later epochs, the convolutional model has learned already to figure out what Bodo comes from. So the leakage actually turned out not to be helpful anyway. So it's amazing how often people assume they need to find metadata and incorporate it into their model, and how often it turns out to be a waste of time. Because the raw, real data, whether it be audio, pictures, language, turns out to encode all of that. Finally I wanted to go back to what Rachel was talking about, which is what would have happened if this did work. Let's say that actually this gave us a much better validation result than the non-leakage model. If I then submitted it to Kaggle and my leaderboard result was great, that would tell me that I have found leakage, that the Kaggle competition administrators didn't, and I'm possibly on the way to winning competition. Having said that, the Kaggle competition administrators first and foremost try to avoid leakage. And indeed if you do try and submit this to the leaderboard, you'll find it doesn't do that great. And I haven't really looked into it yet, but somehow the competition administrators have seen to have made some attempt to remove the leakage. The kind of ways that we did that when I was at Kaggle would be to do things like some kind of stratified sampling, where we'd say, oh there's way more apocore from this ship than this ship. Let's enforce that every ship has to have the same number of the same kind of fish, or something like that where we try to limit leakage. But honestly, it's a very difficult thing to do. And this impacts a lot more than just machine learning competitions. Every one of your real-world projects, you're going to have to think long and hard about how can you replicate real-world conditions in your real-world test set. Maybe the best example I can come up with is, when you put your model into production, it will probably be a few months after you grabbed the data and trained it, how much has the world changed? And so therefore, wouldn't it be great if instead you could create a test set that had data from a few months later than your training set. And then you can really try to replicate the situation that you actually have when you put your model into production. One is just a note that they're releasing another test set later on in the fishery competition. Did you do two classifications, one for the boats and one for the fish? Is that a waste of time? I have two inputs, not two outputs. So my input is the one hot encoded size of the image, which I assumed is a proxy for the boat ID. And some discussion on the Kaggle forum suggested that's a reasonable assumption. We're going to look at multi-output in a moment. In fact, we're going to do it now. Multi-output, there's a lot of nice things about how Kaggle competitions are structured. One of the things I really like is that in most of them, you can create your finds, your own data sources, as long as you share them with the community. And so one of the people in the fisheries competition has gone through and by hand put a little square around every fish, which is called annotating the data set. Specifically, this kind of annotation is called a bounding box. A bounding box is a box in which your object fully fits. Because of the rules of Kaggle, he had to make that available to everybody in the Kaggle community, which he provided a link on the Kaggle forum. So I went ahead and downloaded those. They're a bunch of JSON files that basically look like this. For each fish in that image, it had the height, width, next, and y. So the details of the code don't matter too much, but I basically just went ahead and found the largest fish in each image and created a list of them. So I've got now my training bounding boxes and my validation bounding boxes. For things that didn't have a fish, I just had 0000. So as always, when I want to understand new data, the first thing to do is to look at it. When we're doing computer vision problems, it's very easy to look at data because it's pictures. So I went ahead and created this little show bounding box thing, which I tried it on an image, and here is the fish, and here is the animals. There are two questions. I don't know if you wanted to get to a good stopping point on your thought. One is adding metadata. Is that not useful for both CNNs and RNNs or just for CNNs? The other one is VGG required images all the same size in training. In the fisheries case, are there different size images being used for training and how do you train a model on images with different dimensions? So regarding whether metadata is useful for RNNs or CNNs, it's got nothing to do with the architecture. It's entirely about the semantics of the data. If your text or audio or whatever unstructured data in some way encodes the same information that is in the metadata, the metadata is unlikely to be helpful. So for example, in the Netflix prize, in the early stages of the competition, people found that it was helpful to link to IMDB and bring in information about the movies. In later stages they found it wasn't. The reason why is because in later stages they had figured out how to extrapolate from the ratings themselves. They basically contained implicitly all the same information. How do we deal with different sized images? I'm about to show you some tricks. But so far throughout this course we have always resized everything to 224x224. Whenever you use get-batches, I default to resizing to 224x224 because that's what ImageNet did, with the exception that in my previous ResNet model I showed you resizing to 400x400 instead. So far, and in fact everything we're doing this year, we're going to resize everything to be the same size. Question about the 400x400, is that because there are two different RESTIC models? Answer that question. Now that we've got these bounding boxes, here is the complexity. They're both a practical one and a Kaggle one. The Kaggle complexity is the rules say you're not allowed to manually annotate the test set. So we can't put bounding boxes on the test set. So if for example we want to go through and crop out just the fish in every image and just train on them, this is not enough to do that because we can't do that on the test set because we don't have bounding boxes. The practical meaning of this is basically, in practice they're trying to create an automatic warning system to let them know if somebody is taking the wrong kind of fish, they don't want to have somebody drawing a box on everyone. So what we're going to do is build a model that can find these bounding boxes automatically. And how do we do that? It may surprise you to know we use exactly the same techniques that we've always used. Here is the exact same model again, but this time as well as having something at the end which has 8 softmax outputs, we also have something which has 4 linear outputs, i.e. 4 outputs with no activation function. What this is saying, and what we're going to do is when we train this model, we now have 2 outputs. So when we compile it, we're going to say, this model has 2 outputs. One is the 4 outputs with no activation function, one is the 8 softmax. When I compile it, the first of those I want you to optimize for mean squared error, and the second of those I want you to optimize for cross entropy loss. And the first of them I want you to multiply the loss by 0.001 because the mean squared error of finding the location of an image is going to be a much bigger number than the categorical cross entropy. And then when you train it, I want you to use the bounding boxes as the labels for the first output, and the fish types as the labels for the second output. So what this is going to have to do is figure out how to come up with a bunch of dense layers which is capable of doing these 2 things simultaneously. So in other words, we now have something that looks like this. 2 outputs and one input. And notice that the 2 outputs, you don't have to do it this way, but in the way I've got it, the 2 outputs both come out, they both have their own dense layer. It would be possible to do it like this instead. That is to say, each of the 2 outputs could have 2 dense layers of their own before it. In this case though, we're going to talk about the pros and cons. Both of my last layers are both going to have to use the same set of features to generate both the bounding boxes and the fish classes. So let's have this go. So we just go fit as usual. But now that we have 2 outputs, we get a lot more information. We get the bounding box loss, we get the fishing classification loss, we get the total loss, which is equal to.001 times the bounding box, because you can see this is over 1000 times bigger than this. So you can see why I multiplied by.01. So that's the 2 added together with that weight. Then we get the validation loss, total validation bounding box loss, and the validation classification loss. So here's something pretty interesting. The first thing I want to point out is after I go fit it a little bit, we actually get a much better accuracy. Now maybe this is counterintuitive, because we're now saying our model has exactly the same capacity as before. Our previous dense layer is of size 512. And before that last layer only had to do one thing, which is to tell us what kind of fish it was. Now it has to do 2 things. It has to tell us where the fish is and what kind of fish it is. But yet it's still done better. Why is it done better? Well the reason it's done better is because by telling it we want you to use those features to figure out where the fish is, we've given it a hint about what to look for. We've really given it more information about what to work on. So interestingly, even if we didn't use the bounding box for anything else and just threw it away at this point, we already have a much better model. Do you notice also the model is much more stable? 97.8, 98, 98, 98.2. Before our loss was all over the place. So by having multiple outputs, we've created a much more stable, resilient, and accurate classification model. And we also have bounding boxes. The best way to look at how accurate the bounding boxes are is to look at the picture. So I do a prediction for the first 10 validation examples. It's important to use the validation set any time you're looking at how good your model is. This time I slightly increased the function to show the bounding boxes to now create a yellow box for my prediction and a default red box for my actual. And there it is. So I just want to make it very clear here. We haven't done anything clever. We didn't do anything to program this. We just said there is an output which will have 4 outputs and has no activation function, so that's linear. And I want you to use mean squared error to find a set of weights that would optimize those weights such that the bounding boxes and your predictions are as close as possible. And somehow it has done that. So that is to say, very often if you're trying to get a neural net to do something, your first step before you create some complex programming heuristic thing is just ask the neural net to do it. And very often it does. Why do both in the same fitting instead of training the boxes first and feeding that as input to recognize fishes? Well we can. But the first thing I want to point out is, even then I would still have the first stage do both at the same time, because the more compatible tasks you can give it, so like where is the fish and what kind of fish it is, the more it can create an internal representation that is as appropriate as possible. Now if you now want to go away over the next couple of weeks and crop out these fish and create the second model, I can almost guarantee you'll get into the top 10 of this competition. And the reason I can almost guarantee that is because there was quite a similar competition on Kaggle last year, which was trying to identify particular whales, a whale or a rat whale, and literally saying which individual whale is it. And all of the top 3 in that competition did some kind of bounding box prediction and some kind of cropping and then modeled the second layer on the cropped features. By the 4 bounding box outputs, the vertical and horizontal size of the box and the 2 coordinates for its center? It's whatever we were given, which was not quite that, it was the height, width, x and y. So how many of the people in this Kaggle competition are using this sort of model? If you came up with this with a bit of tinkering, do you think you would actually stay in the top 10 or would this just be an obvious thing that people would tend to do and so your ranking would basically drop over time as everyone else incorporates this? I'm going to show you a few techniques that I used this week. They're all very basic, very normal. We're at a point now in this $150,000 competition where over 500 people have been invented and I am currently 20th. The stuff that you're learning in this course is not at all well-known. There's never been an applied deep learning course before. So the people who are above me in the competition are people who have figured these things out over time and read lots of papers and studied and whatever else. So I definitely think that people in this course, particularly if somebody teamed up together, would have a very good chance of winning this competition because it's a perfect fit for everything we've been talking about. Particularly you can collaborate on forums and stuff like that. I should mention this 20th is I haven't even done any cropping yet. This is just using the whole image, which is clearly not the right way to tackle this. I was actually intentionally trying not to do too well because I'm going to have to release this to everybody on the CACL forum to say I've done this and here's the notebook because it's $150,000. I didn't want to say here's a way to get in the top 10 because that's not fair to everybody else. So to answer your question, by the end of the competition, to win one of these things, you've got to do everything right at every point. And every time you fail, you have to keep trying again. Tenacity is part of winning these things. I know from experience the feeling of being on top of the leaderboard and waking up the next day and finding that 5 people have passed you. But the thing is, they have found something that is there and you haven't found yet. And that's part of what makes competing in the CACL competition so different to doing academic papers or looking at old CACL competitions that are long gone. It's a really great test of your own processes and your own grit. What you'll probably find yourself doing is repeatedly fucking around with hyperparameters and minor architectural details because it's just so addictive until eventually you go away and go, what's a totally different way of thinking about this problem. I hope some of you will consider seriously investing in putting an hour a day into a competition because I learned far more doing that than everything else I've ever done in my life. It's totally different to just playing around. And after it, it's something that every real-world project does. It's greatly better for that experience. So to give you a sense of this, here's number 6. I can't even see that fish, but it's done a pretty good job. Maybe it kind of knows that people tend to float around where the fish is or something because it's pretty hard to see. As you can see, this is just a 224x224 image. So this model is doing a pretty great job and the amount of time it took to train was under 10 seconds. Question. Is there a way to find the bounding box without hand-coding it? Before we look at finding things without manually annotating bounding boxes, I want to talk more about different size images. So let's talk about sizes. Let's specifically talk about in which situations is our model going to be sensitive to the size of the input. Like a pre-trained model with pre-trained weights. And it's all about what are these layer operations exactly. If it's a dense layer, then there's a weight going from every input to every output. And so if you have a different sized input, then that's not going to work at all because the weight matrix for your dense layer is just simply of the wrong size. Who knows what it should do. What if it's a convolutional layer? If it's a convolutional layer, then we have a little set of weights for each 3x3 block for each different feature, and then that 3x3 block is going to be slid over to create the outputs. If the image is bigger, it doesn't change the number of weights. It just means that block is going to be slid around more and the output will be bigger. A max-pauling layer doesn't have any weights. A batch normalization layer simply cares about the number of weights of the previous layer. So really when you think about it, the only layer that really cares what size your input is, is a dense layer. And remember that with VGG, nearly all of the layers are convolutional layers. So that's why it is that we can say not only include top equals false, but we can also choose what size we want. So if you look at my new version of the VGG model, I've actually got something here that says if size is not equal to 224x224, then don't try to add the fully connected blocks at all. Just return that. So in other words, if we cut off whatever our architecture is before any dense layers happen, then we're going to be able to use it on any size input to at least create those convolutional features. That's what I'm about to show you now. There's no particular reason it has to be fixed. A dense layer has to be fixed because a dense layer has a specific weight matrix. And the input to that weight matrix generally is the flattened out version of the previous convolutional layer, and the size of that depends on the size of the image. But the convolutional weight matrix simply depends on the filter size, not on the image size. So let's try it. Specifically, we're going to try building something called a fully convolutional net, which is going to have no dense layers at all. So the input, as usual, will be the output of the last VGG convolutional layer. But this time, when we create our VGG 16 model, we're going to tell it we want it to be 640x360. Now be careful here. When we talk about matrices, we talk about rows by columns. When we talk about images, we talk about columns by rows. So a 640x360 image is a 360x640 matrix. I mention this because I screwed it up. But I knew I screwed it up because I always draw pictures. So when I drew the picture and I saw I had this little squashed boat, I knew I screwed it up. This is the exact same VGG 16 network we've been using since I added BatchNorm. Nothing's been changed other than this one piece of code I just showed you, which says you can use different sizes, and if you do, don't add the fully connected layers. So now that I've got this VGG model, which is expecting a 640x360 input, I can then add to it my top layers. And this time, my top layers are going to get in an input which is of size 22x40. So normally, our VGG's final layer is 14x14, or if you include the final max pooling, it's 7x7. In this case, it's 22x40, and that's because we're not going to pass it a 224x224, we're going to pass it a 640x360. So this is what happens. We end up with a different output shape. So if we now try to pass that to the same dense layer we used before, it wouldn't work, so it would be the wrong size. But we're actually going to do something very different anyway. We're not going to use any pre-trained fully connected weights. We're instead going to have, in fact, no dense layers at all. Instead, we're going to go conv batch norm max pool, conv batch norm max pool, conv batch norm max pool, conv global average pooling. So the best way to look at that is to see what's happening to our shape. So it goes from 22x40 until the max pooling, 11x20, 5x10, and because this is rectangular, the last max pooling I did a 1,2 shape, so that gives me a square result, so 5x5. Then I do a convolutional layer in which I have just 8 filters. And remember, there are 8 types of fish. There are no other weights after this. And in fact, even the dropout is not doing anything because I've set my p-value to 0. So ignore that dropout layer. So we're going straight from a convolutional layer, which is going to be grid-size 5x5 and have 8 filters, and then we're going to average across the 5x5, and that's going to give us something of size 8. So if we now say, please train this model, and please try and make these 8 things equal to the classes of fish. Now you have to think backwards. How would it do that? If it was to do that for us, and it will because it's going to use SGD, what would it have to do? Well, it has no ability to use any weights to get to this point, so it has to do everything by the time it gets to this point. Which means this convolution 2D layer is going to have to have in each of its 5 grid areas something saying how fishy is that area. Because that's all it can do. After that, all it can do is to average them together. So we haven't done anything specifically to calculate it that way. We just created an architecture which has to do that. My feeling is that ought to work pretty well because as we saw in that earlier picture, the fish only appears in one little spot. And indeed, as we discussed earlier, maybe even a global max pooling could be better. So let's try this. We can fit it as per usual, and you can see here, even without using bounding boxes, we've got a pretty stable and pretty good result in about 30 seconds. When I then tried this on the Kaggle leaderboard, I got a much better result. The 20th place was me just averaging together 4 of the models that I'm showing you today. But this one on its own was 0.986, which would be 20 seconds. So that little model on its own would get us 20 seconds. No data augmentation, no pseudo-labeling, we're not using the validation set to help us, which you should when you do your final Kaggle entry. So you can get 20 seconds position with this very simple approach, which is to use a slightly larger image and use a fully convolutional network. There's something else cool about this fully convolutional network which can get us into a 20 second position, and that is that we can actually look at the output of this layout. As always before, VGG is the input to this model. So I first of all calculated every single model I'm showing you today, I pre-computed the output of the last convolutional layout with VGG. I go get data, I want to get a 360,640 size data, so that gives me my image. I then create my model, pop off the last layout, I don't want the last max pooling layout, so that's the size. And then call predict to get the features from that last layout. So it's what we always do. It's just the only difference is that we passed 360,640 to our constructor for the model and we passed 360,640 to the get data command. So I'm always skipping that bit, but everything I'm showing you today is taking as input the last convolutional layout from VGG. Question. Why did we replace all dense layers with CNNs? A couple of reasons why. The first is because the authors of the paper, which created the fully convolutional net, found that it worked pretty well. The global average pooling 2D layer, as we've discussed, turns out to have excellent generalization characteristics. So you'll notice here we have no dropout, and yet we're in 22nd place on the leaderboard without even beginning to try. And then the final reason is the thing I'm about to show you, which is that we basically have maintained a sense of kind of XY coordinates all the way through, which means that we can actually now visualize this last layer. So I can say, let's create a function which takes our model's input as input and our fourth from last layer as output, that is that convolutional layout. And then I'm going to take that and I'm going to pass into it the features of my first validation image and draw a picture of it for this picture. And here is my picture. And so you can see it's done exactly what we thought it would do, which is it's had to figure out that there's a fishy bit here. So these fully convolutional networks have a nice side effect, which is that they allow us to find whereabouts the interesting parts are. Question- Why does max pooling reduce the dimensions along the X and Y to half what they were previously? Answer- The default parameters of max pooling are 2,2, so it's taking each 2x2 square and replacing it with the largest value in that 2x2 square. So this is not the most high-res heatmap we've ever seen. So the obvious thing to make it all more high-res would be to remove all the max pooling layers. So here's exactly the same thing as before, but I've removed all the max pooling layers. So that means that my model now remains at 22x40 all the way through. Everything else is the same. And that indeed does not give quite as accurate a result. We get 95.2, rather than whatever it was, 97.6. But on the other hand, we do have a much higher resolution grid. So if we now do exactly the same thing to create the heatmap, the other thing we're going to do is we're going to resize the heatmap to 360x640. And by default, this resize command will try and interpolate. So it's going to replace big pixels with interpolated small pixels. And that gives us, for this image, this answer, which is much more interesting. And so now we can stick one on top of the other like so. And this tells us a lot. It tells us that on the whole, this is doing a good job of saying the thing that mattered, the fishy thing, the albacorey thing specifically, because we're asking here for the albacore plus. Remember, that layer of the model is 8x22x40. So we have to ask how much like albacore is each of those areas, or how much like shark is each of those areas. So when we called this function, it returned basically a heatmap for every type of fish. So we can pass in 0 for albacore. Class number 4 is no fish. So one of the classes you have to predict in this competition is no fish. So we could say, tell us how much each part of this picture looks like the no fish class. What happens is if you look at the no fish version, it's basically the exact opposite of this. You get a big blue spot here and pink all around it. The other thing I wanted to point out here is these areas of pinkishness that are not where the fish is. This is telling me that our model is not currently just looking for fish. It's also looking for particular characteristics of the boat. So this is suggesting to me that since it's not all concentrated on the fish, I do think there's some data leakage still coming through. Question asked. I think we know everything about why it's working. We have set up a model where we've said we want you to predict each of the 8 fish classes. We have set it up such that the last layer simply averages the answers from the previous layer. The previous layer we have set up has the 8 classes we need. So that's obviously the only way you can average and get the right number of classes. We know that SGD is a general optimization approach which will find a set of parameters which solve the problem that you give it, and we've given it that problem. So really, when you think of it that way, unless it failed to train, it could only get a decent answer if it solved it in this way, if it actually looked at each area and figured out how fishy it is. Question asked. We're not doing attention models in this part of the course per se. I would say for now, the simple attention model that I would do would be to find the largest area of the heat map and crop that, and maybe compare that to the bounding boxes and make sure they look about the same, and those that don't, you might want to hand fix. And if you hand fix them, you have to give that back to the Kaggle community, of course, because that's hand labeling. And honestly, that's the state of the art. In terms of who wins the money in Kaggle, that's how the Kaggle winners have won these kinds of competitions, is by having a two-stage pipeline where first of all they find the thing of interest, and then they zoom into it and then they do a model on that thing. Actually the other thing that you might want to do is to orient the fish so that the tail is kind of in the same place and the head is at the same place. Make it as easy as possible, basically, for your ConvNet to do what it needs to do. You guys might have heard of another architecture called Inception. A combination of Inception plus ResNet won this year's ImageNet competition. And I want to give you a very quick hint as to how it works. I have built the world's tiniest little Inception network here. One of the reasons I want to show it to you is because it actually uses the same technique that we heard from Ben Bowles that he used. Remember in his language model at Quid, Ben used a trick where he had multiple different convolution filter sizes and ran all of them and concatenated them together. That's actually what the Inception network does. Question from the audience. How would you align the head and tail? How is this a better way to isolate the fish than just taking the bounding box approach that the classifier generated? To align the head and tail, the easiest way would be to hand annotate the head and hand annotate the tail. That was what was done in the whale competition. Hand labeling always has errors. Indeed, there are quite a few people in the forum who have pointed out various bounding boxes that they don't think are correct. So it's great to have an automatic approach which ought to give about the same answer as the hand approach, and you can then compare the two and use the best of both worlds. And in general, this idea of combining human intelligence and machine intelligence seems to be a great approach, particularly early on. You can do that for the first few bounding boxes to improve your bounding box model, and then use that to gradually make the model have to ask you less and less for your input. Question from the audience. The heat map you don't need to. The heat map was just visualizing one of the layers of the network. We didn't use the bounding boxes, we didn't do anything special. It's just a side effect of this kind of model, is that you can visualize the last compositional layer and doing so will give you a heat map. Question from the audience. There are so many ways of interpreting neural nets, and one of them is to draw pictures of the intermediate activations. You can also draw pictures of the intermediate gradients. There are all kinds of things you can draw pictures of. Question from the audience. So the inception network is going to use this trick where we're going to use multiple different compositional filter sizes and concatenate them all together. So just like in ResNet, there's this idea of a ResNet block, which is repeated again and again. In the inception network, there's an inception block, which is repeated again and again. And I've created a version of one here. So I have one thing which takes my input and does a 1x1 convolution. I've got one thing that takes the input and does a 5x5 convolution. I've got one thing that takes the input and does 2x3 convolutions. I've got one thing that takes the input and just average pulls it. And then we concatenate them all together. So what this is doing is each inception block is basically able to look for things at various different scales and create a single feature map at the end, which adds all those things together. So once I've defined that, I can then just create a little model. I haven't managed to get this to work terribly well yet. I haven't actually tried submitting this to Kaggle. Part of the purpose of this is to give you guys a sense of the kinds of things we'll be doing next year. This idea of we've built the basic pieces now of convolutions, fully connected layers, activation functions, SGD. And really from here, deep learning is putting these pieces together. What are the ways people have learned about putting these things together in ways that solve problems as well as possible. And so the inception network is one of these ways. And the other thing I wanted to do was to give you plenty of things to think about over the next couple of months and play with, so hopefully this notebook is going to be full of things you can experiment with and maybe even try submitting some Kaggle results. I guess the warnings about the inception network are a bit similar to the warnings about the ResNet network. Like ResNet, the inception network is available. Actually, Keras, I haven't converted one to my standard approach, but Keras has an inception network that you can download and use. It hasn't been well studied in terms of its transfer learning capabilities. And again, I haven't seen people who have won Kaggle competitions using transfer learning of inception network, so it's just a little bit less well studied. But like ResNet, the combination of inception plus ResNet is the most recent ImageNet winner. So if you are looking to really start with the most predictive model, this is where you would want to start. So I want to finish off on a very different note, which is looking at RNNs one more time. I've spent much more time on CNNs and RNNs. The reason is that this course is really all about being pragmatic. It's about teaching you the stuff that works. In the vast majority of areas where I see people using deep learning to solve their problems, they're using CNNs. Having said that, some of the most challenging problems are now being solved with RNNs like speech recognition and language translation. So when you use Google Translate now, you're using RNNs. My suspicion is you're going to come across these kinds of problems a lot less often. But I also suspect that in a business context, a very common kind of problem is a time series problem, like looking at the time series of click events on your website, or e-commerce transactions or logistics. These sequence-to-sequence RNNs we've been looking at, which we've been using to create Nietzschean philosophy, are identical to the ones you would use to analyze a sequence of e-commerce transactions and try to find anomalies. So I think CNNs are more practically important for most people in most organizations right now. RNNs also have a lot of opportunities. And of course, we'll also be looking at them when it comes to attentional models next year, which is figuring out in a really big image which part should we look at next. The inception merge is a concat rather than an add, which is the same as what we saw when we looked at Ben Bolz's quid NLP model. We're taking multiple convolution filter sizes and we're sticking them next to each other. So that feature basically contains information about 5x5 features and 3x3 features and 1x1 features. So when you add them together, you lose that information. And ResNet does that for a specific reason, we want to cause it to own residuals. In inception, we don't want that. In inception, we want to keep them all in the feature space. The other reason I wanted to look at RNNs is that last week we looked at building an RNN nearly from scratch in Theano. And I say nearly from scratch because there was one key step which it did for us, which was the gradients. Really understanding how the gradients are calculated is not something you would probably ever have to do by hand, but I think it can be very helpful to your intuition of training neural networks to be able to trace it through. So for that reason, this is kind of the one time in this course, and next year's course, where we're going to really go through and actually calculate the gradients ourselves. So here is a recurrent neural network in pure Python. And the reason I'm doing a recurrent neural network in pure Python is this is kind of the hardest. RNNs are the hardest thing to get your head around backpropagating gradients. So if you look at this and study this and step through this over the next couple of months, you will really be able to get a great understanding of what a neural net is really doing. There's going to be no magic or mystery because this whole thing is going to be every line of code. So if we're going to do it all ourselves, we have to write everything ourselves. So if we want a sigmoid function, we have to write the sigmoid function. Anytime we write any function, we also have to create its derivative. So I'm going to use this approach where underscore D is the derivative of the function. So I'm going to have to have relU and the derivative of relU. And I just kind of check myself as I go along that they look reasonable. The Euclidean distance and the derivative of the Euclidean distance. The cross entropy and the derivative of the cross entropy. And note here that I am clipping my predictions, because if you have zeros or ones there, you're going to get infinities and it destroys everything. So you have to be careful of this. This did actually happen. I didn't have this clip in at first and I was starting to get infinities and this is necessary. Here's my softmax. Here's the derivative of softmax. So then I basically go through and I double-check that the answers I get with my versions are the same as the answers I get with the Theano versions to make sure they're all correct. They all seem to be fine. So I am going to use as my activation function relU, which means the derivative is relU derivative and my loss function is cross entropy. So the loss function is cross entropy derivative. I also have to write my own scan. So you guys remember scan. Scan is this thing where we go through a sequence one step at a time, calling a function on each element of the sequence. And each time the function is going to get 2 things, it's going to get the next element of the sequence as well as the previous result of the call. So for example, scan of add2things together on the integers from 0 to 5 is going to give us a cumulative sum. And remember the reason we do this is because GPUs don't know how to do loops, so our Theano version used a scan, and I wanted to make this as close to the Theano version as possible. In Theano, scan is not implemented like this with a for loop. In Theano, they use a very clever approach which basically creates a tree where it does a whole lot of the things kind of simultaneously and gradually combines them together. Next year we may even look at how that works if anybody's interested. So in order to create our Michian philosophy, we need an input and an output. So we have the 8 character sequences, one hot encoded for our inputs, and the 8 character sequences moved across by one, one hot encoded for our outputs. And we've got our vocab size, which is 86 characters. So here's our input and output shapes, 75,000 phrases, each one has 8 characters in, and each of those 8 characters is a one hot encoded vector of size 86. So we first of all need to do the forward pass. So the forward pass is to scan through all of the characters in the nth phrase, the input and output, calling some function. So here is the forward pass. And this is basically identical to what we saw in Theano. In Theano, we had to lay out the forward pass as well. So to create the hidden state, we have to take the dot product of X with its weight matrix and the dot product of the hidden with its weight matrix, and then we have to put all that through the activation function. And then to create the predictions, we have to take the dot product of the hidden with its weight matrix and then put that through softmax. And so we have to make sure we keep track of all of the state that it needs, so at the end we will return the loss, the pre-hidden and pre-pred, because we're going to use them each time we go through. In the backprop, we'll be using those. We need to know the hidden state, of course, we have to keep track of that because we're going to be using it the next time through the RNN. And of course we're going to need our actual predictions. So that's the forward pass, very similar to Theano. The backward pass is the bit I wanted to show you. I want to show you how I think about it. This is how I think about it. All of my errors, I've reversed their direction. And the reason for that is that when we create a derivative, we're really saying how does a change in the input impact the output. And to do that, we have to use the chain rule, we have to go back from the end all the way back to the start. So this is our output last hidden layer activation matrix. This is our loss, which is adding together all of the losses of each of the characters. If we want the derivative of the loss with respect to this hidden activation, we would have to take the derivative of the loss with respect to this output activation and multiply it by the derivative of this output activation with respect to this hidden activation. We have to then multiply them together because that's the chain rule. The chain rule basically tells you to go from some function of some other function of x, the derivative is the product of those functions. So I find it really helpful to literally draw the arrows. Let's draw the arrow from the loss function to each of the outputs as well. And so to calculate the derivatives, we basically have to go through and undo each of those steps. In order to figure out how that input would change that output, we have to undo it. We have to go back along the arrow in the opposite direction. So how do we get from the loss to the output? So to do that, we need the derivative of the loss function, and then we're also going to need the derivative of the activation function as well. So you can see it here. This is a single backward pass. We grab one of our inputs, one of our outputs, and then we go backwards through each one, each of the 8 characters, from the end to the start. So grab our input character and our output character. And the first thing we want is the derivative of pre-pred. Remember pre-pred was the prediction prior to putting it through the softmax. So that was the bit I just showed you. It's the derivative of the softmax times the derivative of the loss. So the derivative of the loss is going to get us from here back to here, and then the derivative of the softmax gets us from here back to the other side of the activation function. So that's what that gets us to. So we want to keep going further, which is we want to get back to the other side of the hidden. We want to get all the way over now to here. So to do that, we have to take the derivative of a matrix multiplication is the multiplication with the transpose of that matrix. So in order to take the derivative of the pre-hidden times its weights, we simply take it by the transpose of its weights. So this is the derivative of that part. And remember the hidden, we've actually got 2 arrows coming back out of it, and we've got also 2 arrows coming into it. So we're going to have to add together that derivative and that derivative. So here is the second part. So there it is with respect to the outputs, and there it is with respect to the hidden. And then finally we have to undo the activation function. So multiply it by the derivative of the activation function. So that's the chain rule that gets us all the way back to here. So now that we've got those 2 pieces of information, we can update our weights. So we can now say for the blue line, what are these weights now going to equal? So we basically have to take the derivative that we got to at this point, which we called dprepred, we have to multiply it by our learning rate, and then we have to undo the multiplication by the hidden state to get the derivative with respect to the weights. And I created this little columnify function to do that. So it's turning a vector into a column, so it's taking its transpose if you like. So that gives me my new output weights. My new hidden weights are basically the same thing. It's the learning rate times the derivative that we just calculated, and then we have to undo its weights and our new input weights, again the learning rate times the pre-hidden times the columnified version of X. So I'm going through that very quickly. The details aren't important, but if you're interested, it might be fun to look at it over the Christmas break or the next few days. Because you can see in this here is all the steps necessary to do backprop through an RNN, which is also why we would never want to do this by hand again. So when I wrote this code, luckily I did it before I got my cold. You can see I've written after every one the dimensions of each matrix and vector because it makes your head hurt just keeping everything straight. So thank God, Theano does this for us. But I think it's useful to see it. So finally, I now just have to create my initial weight matrices, which are normally distributed matrices where these normal distributions are going to use the square root of 2 divided by the number of inputs, because that's that chloro thing. Remember, for my hidden matrix, for a simple RNN, we'll use the identity matrix to initialize it. We haven't got to that bit yet. So it depends how we use this. At this stage, all we've done is we've defined the matrices and we've defined the transitions. And whether we maintain state will depend entirely on what we do next, which is the loop. So here is our loop. So in our loop, we're going to go through a bunch of examples. Run one forward step and then one backward step, and then from time to time print out how we're getting along. So in this case, the forward step is passing to scan the initial state is a whole bunch of zeros. So currently this is resetting the state. It's not doing it statefully. If you wanted to do it statefully, it would be pretty easy to change. You would have to have the final state returned by this and keep track of it and then feed it back the next time through the loop. If you're interested, maybe you could try that. Having said that, you probably won't get great results, because remember that when you do things statefully, you're much more likely to have gradients and activations explode unless you do a GRU or an LSTM, which we're not. So my guess is it probably won't work very well. So that was a very quick fly-through and really more showing you around the code so that if you're interested, you can check it out. What I really wanted to do though was get onto this more interesting type of RNN. There are actually two interesting types of RNN called long short-term memory and gated recurrent unit. Many of you will have heard of the one on the left, LSTM. For stateful RNNs, you can't exactly have mini-batches because you're doing one at a time. In our case, we were going through it in order. Using mini-batches is a great way to parallelize things on the GPU and make things run faster. Then you have to be careful about how you're thinking about state. So LSTM's a lot of you will have heard about because they've been pretty popular over the last couple of years for all kinds of cool stuff that Google does. On the right, however, is the GRU, which is simpler and better than the LSTM. So I'm not going to talk about the LSTM, I'm going to talk about the GRU. They're both techniques for building your recurrent neural network where your gradients are much less likely to explode. Another great interesting example of a clever architecture, but it's just going to be more of using the same ideas that we've seen again and again. So what we have here on the right hand side is this box is basically zooming into what's going on inside one of these circles in a GRU. So normally in our standard RNN, what's going on in here is pretty simple, which is we do a multiplication by this WH weight matrix and stick it through an activation function, and we grab our input, do it by a multiplication by weight matrix, grab its and put it through its activation function, and we add the two together. A GRU is going to do something more complex. We still have the input coming in and the output going out. So that's what these arrows are. They're representing our new input character and our prediction. But what's going on in the middle is more complex. We still have our hidden state, just like before. But whereas in a normal RNN, the hidden state each time simply updates itself. It just goes through a weight matrix and an activation function and updates itself. But in this case, you can see that the loop looks like it's going back to come back to itself, but then there's this gate here. And so it's actually not just a self loop, there's something more complicated. So in order to understand what's going on, we're going to have to follow across to the right hand side. So on the right hand side, you can see that the hidden state is going to go through another gate. So what's a gate? A gate is simply a little mini neural network which is going to output a bunch of numbers between 0 and 1, which we're going to multiply by its input. In this particular one, the R stands for reset. And so the numbers between 0 and 1, if they were all 0, then the thing coming out of the reset gate would be just a big bunch of 0s. In other words, it would allow this network to forget the hidden state. Or it could be a big bunch of 1s, which would allow the network to remember all of the hidden states. Do we want it to remember or forget? We don't know, which is why we implement this gate using a little neural network. This little neural network is going to have 2 inputs, which is the input to the input to the GRU unit and the current hidden state. And so it's going to learn a set of weights that it's going to use to decide when to forget. So it's now got the ability to forget what it knows. And that's what the reset gate does. So assuming that the reset gate has at least some non-zero entries, which it surely will most of the time, then whatever comes through, we're going to call H tilde. So this is the new value of the hidden state after being reset. And so then finally, that goes up to this top bit here. The original hidden state goes up to this top bit here. And then there's a gate which decides how much of each one should we have. So this update gate is going to decide if it's 1, we'll take more from this side, if it's 0, we'll take more from this side. And again, that's implemented as a little neural network. I think the easiest way to understand this is probably to look at the code. So I have implemented this in Theano. You can use a GRU in Keras by simply replacing the words simpleRNN with GRU. So you don't really need to know this to use it and you get pretty good results. But here's what it looks like when implemented. We don't just have a hidden weight matrix, input weight matrix and an output weight matrix anymore. We also have a hidden and input weight matrix for our reset gate, mini-neural net, and for our update gate, mini-neural net. So here's the definition of a gate. A gate is something which takes its inputs, its hidden state, its hidden state weights, its input weights and its biases. It does a dot product of the x with wx, a dot product of h with wh, and adds the biases and sticks it to a single function. So that's what I meant by a mini-neural net. It's hardly a neural net, it's just got one layer. So that's the definition of the reset gate and the update gate. So then in our step function, this is the thing that runs each time on the scan, it looks exactly the same as what we looked at last week. The output equals the hidden state times the hidden weight matrix plus the hidden biases. The new hidden state equals our inputs times its weights and the hidden state times its weights plus the biases. But this time the hidden weights are multiplied by the reset gate. And the reset gate is just our little neural net. So now that we have hnew, our actual new hidden state is equal to that times 1 minus the update gate plus our previous hidden state times the update gate. So you can see that update plus 1 minus update will add to 1. So you can see why it's been drawn like so, which is that this can really be anywhere at either end or somewhere in between. So the update gate decides how much is hnew going to replace the new hidden state with. So actually although people tend to talk about LSTNs and GRUs as being pretty complex, it really wasn't that hard to write. The key outcome of this though is that because we now have these reset and update gates, it has the ability to learn these special sets of weights to make sure that it throws away state when that's a good idea, or to ignore state when that's a good idea. So these extra degrees of freedom allow SGD to find better answers. So again, this is one of these things where we're coming up with architectures which just try to make it easier for the optimizer to come up with good answers. Everything after this is identical to what we looked at last week. That goes into the scan function, we calculate the loss, we calculate the gradients, we do the SGD updates, and we chuck it into a little loop. So I think really the main reason I wanted to do all that today was to show you the back prop example. I know some learning styles are more detail-oriented as well, so I think some of you hopefully will have found that helpful. Any time you find yourself wondering how the hell did this neural network do this, you can come back to this piece of code and that's all it did. That's one way of thinking about it. Where you really get successful with neural nets though is when you go to a whole other level and you don't think of it at that level anymore, but instead you start thinking, if I'm an optimizer and I'm given an architecture like this, what would I have to do in order to optimize it? And once you start thinking like that, then you can start thinking in this kind of upside-down way that is necessary to come up with good architectures. You can start to understand why it is that this convolution layer followed by this average pooling layer gives the answers that it does. Why does it work? You get that real intuition for what's going to work for your problem well. So there's kind of two levels at which you need to think about neural nets. The sooner you can think of it at this super high level, the sooner you'll do well with them. And one of the best ways to do that is to over the next couple of weeks run this fish notebook yourself and screw around with it a lot. And make sure that you know how to do these things that I did where I actually create a little function that allows me to spit out the output of any of the layers and visualize it. Make sure you know how to inspect it and you can really look at the inputs and outputs. I think that's the best way to get an intuition. So this was kind of like, particularly the first half of this class was a bit of a preview of next year, which is to say, in the first 6 weeks, you learn all the pieces. And then today we very rapidly tried putting those pieces together in a thousand different ways and saw what happened. And there's a million more ways that we know of, and probably a billion more ways we don't know of. So knowing this little set of tools, convolutions, fully connected layers, activation functions, etc., you're now able to be an architect, create these architectures. Keras' functional API makes it ridiculously easy. I created all of the architectures you see today, this week while I was sick and my baby wasn't sleeping. My brain was not even working, that's how easy Keras makes this. It takes a few weeks to build your comfort level up, but hopefully you can try that. And most importantly, over the next few weeks, as Rachel and I, maybe with some of your help, start to develop the MOOC, you guys can stay up talking on the forums about keep working through whatever problems you're interested in, whether it be the projects that you want to apply these things to in your own organizations or your personal passion projects, or if you want to try and win a competition or two. Rachel and I are going to still be on the forums. And then in a few weeks' time when the MOOC goes online, hopefully there's going to be thousands of people joining this community. So we'll be like the seed. So I really hope you guys will stay a part of it and kind of help. Can you imagine that first day when half the people still think that a python is a snake and don't know how to connect to an AWS instance, and you'll all be able to say, read the wiki, here's the page, oh yeah, I have that problem too. And hopefully our goal here is to create a new generation of deep learning practitioners, people who have useful problems that they're trying to solve and can use this tool to solve them rather than create more and more exclusive, heavily mathematical content that's designed to pull people off. So that's our hope. That's really why we're doing this. It really has been a genuine pleasure. I'm so happy to hear that most of you are going to see you again next year. You guys obviously all get first dibs on places for next year's course. If the MOOC is successful, next year's course could be quite popular, so I do suggest that you do nonetheless get your applications in not too late. Be aware if you're not already, we don't send email much. Really the forums is our main way to communicate in Slack to some extent. So if you want to see what's going on, that's the places to look. And of course, our Wiki is the knowledge base that we're creating for everybody. So anytime you see something missing on the Wiki or something you think could be improved, edit it. Even if you're not sure if you're saying the right thing, you can add a little comment afterwards saying, I'm not sure if this is correct. Thanks so much everybody. I hope you all have a great vacation season.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.6, "text": " This is week 7 of 7, although in a sense it's week 7 of 14. No pressure and no commitment,", "tokens": [639, 307, 1243, 1614, 295, 1614, 11, 4878, 294, 257, 2020, 309, 311, 1243, 1614, 295, 3499, 13, 883, 3321, 293, 572, 8371, 11], "temperature": 0.0, "avg_logprob": -0.3526641690001196, "compression_ratio": 1.300751879699248, "no_speech_prob": 0.055772848427295685}, {"id": 1, "seek": 0, "start": 12.6, "end": 20.88, "text": " but how many of you are thinking you might want to come back for part 2 next year?", "tokens": [457, 577, 867, 295, 291, 366, 1953, 291, 1062, 528, 281, 808, 646, 337, 644, 568, 958, 1064, 30], "temperature": 0.0, "avg_logprob": -0.3526641690001196, "compression_ratio": 1.300751879699248, "no_speech_prob": 0.055772848427295685}, {"id": 2, "seek": 2088, "start": 20.88, "end": 30.56, "text": " We started this, I thought if 1 in 5 people come back for part 2, I'll be happy. That's", "tokens": [492, 1409, 341, 11, 286, 1194, 498, 502, 294, 1025, 561, 808, 646, 337, 644, 568, 11, 286, 603, 312, 2055, 13, 663, 311], "temperature": 0.0, "avg_logprob": -0.4390328725179036, "compression_ratio": 1.393939393939394, "no_speech_prob": 2.6684358090278693e-05}, {"id": 3, "seek": 2088, "start": 30.56, "end": 33.56, "text": " the best thing I've ever seen. Thank you so much.", "tokens": [264, 1151, 551, 286, 600, 1562, 1612, 13, 1044, 291, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.4390328725179036, "compression_ratio": 1.393939393939394, "no_speech_prob": 2.6684358090278693e-05}, {"id": 4, "seek": 2088, "start": 33.56, "end": 42.599999999999994, "text": " Today I'm going to show you, and I think you'll be surprised and maybe a little overwhelmed,", "tokens": [2692, 286, 478, 516, 281, 855, 291, 11, 293, 286, 519, 291, 603, 312, 6100, 293, 1310, 257, 707, 19042, 11], "temperature": 0.0, "avg_logprob": -0.4390328725179036, "compression_ratio": 1.393939393939394, "no_speech_prob": 2.6684358090278693e-05}, {"id": 5, "seek": 4260, "start": 42.6, "end": 51.56, "text": " what you can do with this little set of tools you've learned already. So this is going to", "tokens": [437, 291, 393, 360, 365, 341, 707, 992, 295, 3873, 291, 600, 3264, 1217, 13, 407, 341, 307, 516, 281], "temperature": 0.0, "avg_logprob": -0.256130608179236, "compression_ratio": 1.7826086956521738, "no_speech_prob": 4.6823213779134676e-05}, {"id": 6, "seek": 4260, "start": 51.56, "end": 56.800000000000004, "text": " be a kind of part 1 of this lesson. It's going to be a well-widened tour of a bunch of different", "tokens": [312, 257, 733, 295, 644, 502, 295, 341, 6898, 13, 467, 311, 516, 281, 312, 257, 731, 12, 86, 4380, 292, 3512, 295, 257, 3840, 295, 819], "temperature": 0.0, "avg_logprob": -0.256130608179236, "compression_ratio": 1.7826086956521738, "no_speech_prob": 4.6823213779134676e-05}, {"id": 7, "seek": 4260, "start": 56.800000000000004, "end": 61.36, "text": " architectures. And different architectures are not just different because some of them", "tokens": [6331, 1303, 13, 400, 819, 6331, 1303, 366, 406, 445, 819, 570, 512, 295, 552], "temperature": 0.0, "avg_logprob": -0.256130608179236, "compression_ratio": 1.7826086956521738, "no_speech_prob": 4.6823213779134676e-05}, {"id": 8, "seek": 4260, "start": 61.36, "end": 67.96000000000001, "text": " will be better at doing what we've been doing, but some of them will be doing different things.", "tokens": [486, 312, 1101, 412, 884, 437, 321, 600, 668, 884, 11, 457, 512, 295, 552, 486, 312, 884, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.256130608179236, "compression_ratio": 1.7826086956521738, "no_speech_prob": 4.6823213779134676e-05}, {"id": 9, "seek": 6796, "start": 67.96, "end": 77.08, "text": " And I want to set your expectations and say that looking at an architecture and understanding", "tokens": [400, 286, 528, 281, 992, 428, 9843, 293, 584, 300, 1237, 412, 364, 9482, 293, 3701], "temperature": 0.0, "avg_logprob": -0.20328348138359156, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00029584579169750214}, {"id": 10, "seek": 6796, "start": 77.08, "end": 82.36, "text": " how it does what it does is something that took me quite a few weeks to get an intuitive", "tokens": [577, 309, 775, 437, 309, 775, 307, 746, 300, 1890, 385, 1596, 257, 1326, 3259, 281, 483, 364, 21769], "temperature": 0.0, "avg_logprob": -0.20328348138359156, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00029584579169750214}, {"id": 11, "seek": 6796, "start": 82.36, "end": 89.03999999999999, "text": " feel for it. So don't feel bad. As you'll see, it's like unprogramming. It's like we're", "tokens": [841, 337, 309, 13, 407, 500, 380, 841, 1578, 13, 1018, 291, 603, 536, 11, 309, 311, 411, 517, 32726, 2810, 13, 467, 311, 411, 321, 434], "temperature": 0.0, "avg_logprob": -0.20328348138359156, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00029584579169750214}, {"id": 12, "seek": 6796, "start": 89.03999999999999, "end": 94.32, "text": " going to describe something we would think would be great if the model knew how to do", "tokens": [516, 281, 6786, 746, 321, 576, 519, 576, 312, 869, 498, 264, 2316, 2586, 577, 281, 360], "temperature": 0.0, "avg_logprob": -0.20328348138359156, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00029584579169750214}, {"id": 13, "seek": 9432, "start": 94.32, "end": 98.55999999999999, "text": " it, and then we'll say fit, and suddenly the model knows how to do it, and we'll look inside", "tokens": [309, 11, 293, 550, 321, 603, 584, 3318, 11, 293, 5800, 264, 2316, 3255, 577, 281, 360, 309, 11, 293, 321, 603, 574, 1854], "temperature": 0.0, "avg_logprob": -0.25143713870290985, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.143312591826543e-05}, {"id": 14, "seek": 9432, "start": 98.55999999999999, "end": 102.75999999999999, "text": " it and we'll be like, how does it know how to do that.", "tokens": [309, 293, 321, 603, 312, 411, 11, 577, 775, 309, 458, 577, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.25143713870290985, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.143312591826543e-05}, {"id": 15, "seek": 9432, "start": 102.75999999999999, "end": 107.96, "text": " The other thing I want to mention is, having said that, everything we're about to see uses", "tokens": [440, 661, 551, 286, 528, 281, 2152, 307, 11, 1419, 848, 300, 11, 1203, 321, 434, 466, 281, 536, 4960], "temperature": 0.0, "avg_logprob": -0.25143713870290985, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.143312591826543e-05}, {"id": 16, "seek": 9432, "start": 107.96, "end": 113.39999999999999, "text": " only the things we've done to date. In the first half, we're only going to use CNS. There's", "tokens": [787, 264, 721, 321, 600, 1096, 281, 4002, 13, 682, 264, 700, 1922, 11, 321, 434, 787, 516, 281, 764, 14589, 50, 13, 821, 311], "temperature": 0.0, "avg_logprob": -0.25143713870290985, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.143312591826543e-05}, {"id": 17, "seek": 9432, "start": 113.39999999999999, "end": 117.88, "text": " going to be no cropping of images, there's going to be no filtering, there's going to", "tokens": [516, 281, 312, 572, 4848, 3759, 295, 5267, 11, 456, 311, 516, 281, 312, 572, 30822, 11, 456, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.25143713870290985, "compression_ratio": 1.8571428571428572, "no_speech_prob": 5.143312591826543e-05}, {"id": 18, "seek": 11788, "start": 117.88, "end": 124.56, "text": " be nothing hand-tuned, it's just going to be a bunch of convolutional or dense layers", "tokens": [312, 1825, 1011, 12, 83, 43703, 11, 309, 311, 445, 516, 281, 312, 257, 3840, 295, 45216, 304, 420, 18011, 7914], "temperature": 0.0, "avg_logprob": -0.21606185619647686, "compression_ratio": 1.4804469273743017, "no_speech_prob": 1.5936097042867914e-05}, {"id": 19, "seek": 11788, "start": 124.56, "end": 130.76, "text": " with activation functions. But we're going to put them together in some interesting ways.", "tokens": [365, 24433, 6828, 13, 583, 321, 434, 516, 281, 829, 552, 1214, 294, 512, 1880, 2098, 13], "temperature": 0.0, "avg_logprob": -0.21606185619647686, "compression_ratio": 1.4804469273743017, "no_speech_prob": 1.5936097042867914e-05}, {"id": 20, "seek": 11788, "start": 130.76, "end": 139.56, "text": " So let me start with one of the most important developments, perhaps, of the last year or", "tokens": [407, 718, 385, 722, 365, 472, 295, 264, 881, 1021, 20862, 11, 4317, 11, 295, 264, 1036, 1064, 420], "temperature": 0.0, "avg_logprob": -0.21606185619647686, "compression_ratio": 1.4804469273743017, "no_speech_prob": 1.5936097042867914e-05}, {"id": 21, "seek": 13956, "start": 139.56, "end": 148.36, "text": " two, which is called ResNet. ResNet won the 2015 ImageNet competition. I was delighted", "tokens": [732, 11, 597, 307, 1219, 5015, 31890, 13, 5015, 31890, 1582, 264, 7546, 29903, 31890, 6211, 13, 286, 390, 18783], "temperature": 0.0, "avg_logprob": -0.29903232760545684, "compression_ratio": 1.286764705882353, "no_speech_prob": 3.705031849676743e-05}, {"id": 22, "seek": 13956, "start": 148.36, "end": 156.72, "text": " that it won it because it's an incredibly simple and intuitively understandable concept.", "tokens": [300, 309, 1582, 309, 570, 309, 311, 364, 6252, 2199, 293, 46506, 25648, 3410, 13], "temperature": 0.0, "avg_logprob": -0.29903232760545684, "compression_ratio": 1.286764705882353, "no_speech_prob": 3.705031849676743e-05}, {"id": 23, "seek": 15672, "start": 156.72, "end": 169.84, "text": " It's very simple to implement. In fact, what I would like to do is to show you. Let me", "tokens": [467, 311, 588, 2199, 281, 4445, 13, 682, 1186, 11, 437, 286, 576, 411, 281, 360, 307, 281, 855, 291, 13, 961, 385], "temperature": 0.0, "avg_logprob": -0.2017591455009546, "compression_ratio": 1.6631578947368422, "no_speech_prob": 3.8828369724797085e-05}, {"id": 24, "seek": 15672, "start": 169.84, "end": 177.76, "text": " describe as best as I can how ResNet works. In fact, before I describe how it works, I", "tokens": [6786, 382, 1151, 382, 286, 393, 577, 5015, 31890, 1985, 13, 682, 1186, 11, 949, 286, 6786, 577, 309, 1985, 11, 286], "temperature": 0.0, "avg_logprob": -0.2017591455009546, "compression_ratio": 1.6631578947368422, "no_speech_prob": 3.8828369724797085e-05}, {"id": 25, "seek": 15672, "start": 177.76, "end": 181.56, "text": " will show you why you should care that it works.", "tokens": [486, 855, 291, 983, 291, 820, 1127, 300, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.2017591455009546, "compression_ratio": 1.6631578947368422, "no_speech_prob": 3.8828369724797085e-05}, {"id": 26, "seek": 15672, "start": 181.56, "end": 186.4, "text": " So let's for now just put aside the idea that there's a thing called ResNet, and it's another", "tokens": [407, 718, 311, 337, 586, 445, 829, 7359, 264, 1558, 300, 456, 311, 257, 551, 1219, 5015, 31890, 11, 293, 309, 311, 1071], "temperature": 0.0, "avg_logprob": -0.2017591455009546, "compression_ratio": 1.6631578947368422, "no_speech_prob": 3.8828369724797085e-05}, {"id": 27, "seek": 18640, "start": 186.4, "end": 192.96, "text": " architecture, a lot like VGG, that's used for image classification or other CNN type", "tokens": [9482, 11, 257, 688, 411, 691, 27561, 11, 300, 311, 1143, 337, 3256, 21538, 420, 661, 24859, 2010], "temperature": 0.0, "avg_logprob": -0.2715926652544, "compression_ratio": 1.5656108597285068, "no_speech_prob": 8.613945101387799e-05}, {"id": 28, "seek": 18640, "start": 192.96, "end": 198.12, "text": " things. It's actually broader than just image classification. We use it just the same way", "tokens": [721, 13, 467, 311, 767, 13227, 813, 445, 3256, 21538, 13, 492, 764, 309, 445, 264, 912, 636], "temperature": 0.0, "avg_logprob": -0.2715926652544, "compression_ratio": 1.5656108597285068, "no_speech_prob": 8.613945101387799e-05}, {"id": 29, "seek": 18640, "start": 198.12, "end": 207.48000000000002, "text": " as we use the VGG16 class you're familiar with. We just say create something a ResNet.", "tokens": [382, 321, 764, 264, 691, 27561, 6866, 1508, 291, 434, 4963, 365, 13, 492, 445, 584, 1884, 746, 257, 5015, 31890, 13], "temperature": 0.0, "avg_logprob": -0.2715926652544, "compression_ratio": 1.5656108597285068, "no_speech_prob": 8.613945101387799e-05}, {"id": 30, "seek": 18640, "start": 207.48000000000002, "end": 211.6, "text": " Again, there's different size ResNets. I'm going to use 50 because it's the smallest", "tokens": [3764, 11, 456, 311, 819, 2744, 5015, 45, 1385, 13, 286, 478, 516, 281, 764, 2625, 570, 309, 311, 264, 16998], "temperature": 0.0, "avg_logprob": -0.2715926652544, "compression_ratio": 1.5656108597285068, "no_speech_prob": 8.613945101387799e-05}, {"id": 31, "seek": 21160, "start": 211.6, "end": 218.28, "text": " one and it works super well. I've started adding a prouder to my versions of these networks.", "tokens": [472, 293, 309, 1985, 1687, 731, 13, 286, 600, 1409, 5127, 257, 582, 263, 1068, 281, 452, 9606, 295, 613, 9590, 13], "temperature": 0.0, "avg_logprob": -0.2672171694167117, "compression_ratio": 1.5859030837004404, "no_speech_prob": 2.392255555605516e-05}, {"id": 32, "seek": 21160, "start": 218.28, "end": 223.95999999999998, "text": " I've added it to the new VGG as well, which is includeTop. It's actually the same as what", "tokens": [286, 600, 3869, 309, 281, 264, 777, 691, 27561, 382, 731, 11, 597, 307, 4090, 50118, 13, 467, 311, 767, 264, 912, 382, 437], "temperature": 0.0, "avg_logprob": -0.2672171694167117, "compression_ratio": 1.5859030837004404, "no_speech_prob": 2.392255555605516e-05}, {"id": 33, "seek": 21160, "start": 223.95999999999998, "end": 229.68, "text": " the Keras author has started doing with his models. Basically the idea is that if you", "tokens": [264, 591, 6985, 3793, 575, 1409, 884, 365, 702, 5245, 13, 8537, 264, 1558, 307, 300, 498, 291], "temperature": 0.0, "avg_logprob": -0.2672171694167117, "compression_ratio": 1.5859030837004404, "no_speech_prob": 2.392255555605516e-05}, {"id": 34, "seek": 21160, "start": 229.68, "end": 235.51999999999998, "text": " say includeTop equals false, you don't have to go model.pop afterwards to remove the layers", "tokens": [584, 4090, 50118, 6915, 7908, 11, 291, 500, 380, 362, 281, 352, 2316, 13, 13872, 10543, 281, 4159, 264, 7914], "temperature": 0.0, "avg_logprob": -0.2672171694167117, "compression_ratio": 1.5859030837004404, "no_speech_prob": 2.392255555605516e-05}, {"id": 35, "seek": 23552, "start": 235.52, "end": 243.16000000000003, "text": " if you want to fine-tune. IncludeTop equals false means only include the convolutional", "tokens": [498, 291, 528, 281, 2489, 12, 83, 2613, 13, 7779, 32334, 50118, 6915, 7908, 1355, 787, 4090, 264, 45216, 304], "temperature": 0.0, "avg_logprob": -0.20235612358845456, "compression_ratio": 1.4692737430167597, "no_speech_prob": 1.3211726582085248e-05}, {"id": 36, "seek": 23552, "start": 243.16000000000003, "end": 249.76000000000002, "text": " layers basically, and I'm going to stick my own final classification layers on top of", "tokens": [7914, 1936, 11, 293, 286, 478, 516, 281, 2897, 452, 1065, 2572, 21538, 7914, 322, 1192, 295], "temperature": 0.0, "avg_logprob": -0.20235612358845456, "compression_ratio": 1.4692737430167597, "no_speech_prob": 1.3211726582085248e-05}, {"id": 37, "seek": 23552, "start": 249.76000000000002, "end": 250.76000000000002, "text": " that.", "tokens": [300, 13], "temperature": 0.0, "avg_logprob": -0.20235612358845456, "compression_ratio": 1.4692737430167597, "no_speech_prob": 1.3211726582085248e-05}, {"id": 38, "seek": 23552, "start": 250.76000000000002, "end": 255.96, "text": " So when I do this, it's not going to give me the last few layers. Maybe the best way", "tokens": [407, 562, 286, 360, 341, 11, 309, 311, 406, 516, 281, 976, 385, 264, 1036, 1326, 7914, 13, 2704, 264, 1151, 636], "temperature": 0.0, "avg_logprob": -0.20235612358845456, "compression_ratio": 1.4692737430167597, "no_speech_prob": 1.3211726582085248e-05}, {"id": 39, "seek": 25596, "start": 255.96, "end": 265.56, "text": " to explain that is to show you when I create this network, I've got this thing at the end", "tokens": [281, 2903, 300, 307, 281, 855, 291, 562, 286, 1884, 341, 3209, 11, 286, 600, 658, 341, 551, 412, 264, 917], "temperature": 0.0, "avg_logprob": -0.29314697356451125, "compression_ratio": 1.5586854460093897, "no_speech_prob": 7.766806447762065e-06}, {"id": 40, "seek": 25596, "start": 265.56, "end": 271.32, "text": " that says if includeTop, and if so then we add the last few layers with this last densely", "tokens": [300, 1619, 498, 4090, 50118, 11, 293, 498, 370, 550, 321, 909, 264, 1036, 1326, 7914, 365, 341, 1036, 24505, 736], "temperature": 0.0, "avg_logprob": -0.29314697356451125, "compression_ratio": 1.5586854460093897, "no_speech_prob": 7.766806447762065e-06}, {"id": 41, "seek": 25596, "start": 271.32, "end": 275.76, "text": " connected layer, which makes it just ImageNet things, it's probably 1000 categories. If", "tokens": [4582, 4583, 11, 597, 1669, 309, 445, 29903, 31890, 721, 11, 309, 311, 1391, 9714, 10479, 13, 759], "temperature": 0.0, "avg_logprob": -0.29314697356451125, "compression_ratio": 1.5586854460093897, "no_speech_prob": 7.766806447762065e-06}, {"id": 42, "seek": 25596, "start": 275.76, "end": 279.40000000000003, "text": " we're not including Top, then don't add these additional layers.", "tokens": [321, 434, 406, 3009, 8840, 11, 550, 500, 380, 909, 613, 4497, 7914, 13], "temperature": 0.0, "avg_logprob": -0.29314697356451125, "compression_ratio": 1.5586854460093897, "no_speech_prob": 7.766806447762065e-06}, {"id": 43, "seek": 27940, "start": 279.4, "end": 286.15999999999997, "text": " So this is just a thing which means you can load in a model which is specifically designed", "tokens": [407, 341, 307, 445, 257, 551, 597, 1355, 291, 393, 3677, 294, 257, 2316, 597, 307, 4682, 4761], "temperature": 0.0, "avg_logprob": -0.24972395844511933, "compression_ratio": 1.655813953488372, "no_speech_prob": 2.6688092475524172e-05}, {"id": 44, "seek": 27940, "start": 286.15999999999997, "end": 293.0, "text": " for fine-tuning. As you'll see shortly, it has some really helpful properties.", "tokens": [337, 2489, 12, 83, 37726, 13, 1018, 291, 603, 536, 13392, 11, 309, 575, 512, 534, 4961, 7221, 13], "temperature": 0.0, "avg_logprob": -0.24972395844511933, "compression_ratio": 1.655813953488372, "no_speech_prob": 2.6688092475524172e-05}, {"id": 45, "seek": 27940, "start": 293.0, "end": 299.96, "text": " We're in the Cats and Dogs competition here. The winner of the Cats and Dogs competition", "tokens": [492, 434, 294, 264, 40902, 293, 35504, 6211, 510, 13, 440, 8507, 295, 264, 40902, 293, 35504, 6211], "temperature": 0.0, "avg_logprob": -0.24972395844511933, "compression_ratio": 1.655813953488372, "no_speech_prob": 2.6688092475524172e-05}, {"id": 46, "seek": 27940, "start": 299.96, "end": 307.12, "text": " had an accuracy of 0.985 on the private leaderboard and 0.989 on the private leaderboard. We used", "tokens": [632, 364, 14170, 295, 1958, 13, 22516, 20, 322, 264, 4551, 5263, 3787, 293, 1958, 13, 24, 21115, 322, 264, 4551, 5263, 3787, 13, 492, 1143], "temperature": 0.0, "avg_logprob": -0.24972395844511933, "compression_ratio": 1.655813953488372, "no_speech_prob": 2.6688092475524172e-05}, {"id": 47, "seek": 30712, "start": 307.12, "end": 312.56, "text": " this ResNet model in the same way as usual. We grab our batches, we can pre-compute some", "tokens": [341, 5015, 31890, 2316, 294, 264, 912, 636, 382, 7713, 13, 492, 4444, 527, 15245, 279, 11, 321, 393, 659, 12, 21541, 1169, 512], "temperature": 0.0, "avg_logprob": -0.19005479431152345, "compression_ratio": 1.7256944444444444, "no_speech_prob": 1.8058091882267036e-05}, {"id": 48, "seek": 30712, "start": 312.56, "end": 318.16, "text": " features. And in fact, every single CNN model I'm going to show you, we're always going", "tokens": [4122, 13, 400, 294, 1186, 11, 633, 2167, 24859, 2316, 286, 478, 516, 281, 855, 291, 11, 321, 434, 1009, 516], "temperature": 0.0, "avg_logprob": -0.19005479431152345, "compression_ratio": 1.7256944444444444, "no_speech_prob": 1.8058091882267036e-05}, {"id": 49, "seek": 30712, "start": 318.16, "end": 320.52, "text": " to pre-compute the convolutional features.", "tokens": [281, 659, 12, 21541, 1169, 264, 45216, 304, 4122, 13], "temperature": 0.0, "avg_logprob": -0.19005479431152345, "compression_ratio": 1.7256944444444444, "no_speech_prob": 1.8058091882267036e-05}, {"id": 50, "seek": 30712, "start": 320.52, "end": 325.84000000000003, "text": " So everything we see today will be things you can do without retraining any of the convolutional", "tokens": [407, 1203, 321, 536, 965, 486, 312, 721, 291, 393, 360, 1553, 49356, 1760, 604, 295, 264, 45216, 304], "temperature": 0.0, "avg_logprob": -0.19005479431152345, "compression_ratio": 1.7256944444444444, "no_speech_prob": 1.8058091882267036e-05}, {"id": 51, "seek": 30712, "start": 325.84000000000003, "end": 332.0, "text": " layers. So pretty much everything I train will train in a small number of seconds. And that's", "tokens": [7914, 13, 407, 1238, 709, 1203, 286, 3847, 486, 3847, 294, 257, 1359, 1230, 295, 3949, 13, 400, 300, 311], "temperature": 0.0, "avg_logprob": -0.19005479431152345, "compression_ratio": 1.7256944444444444, "no_speech_prob": 1.8058091882267036e-05}, {"id": 52, "seek": 30712, "start": 332.0, "end": 336.72, "text": " because in my experience when you're working with photos, it's almost never helpful to", "tokens": [570, 294, 452, 1752, 562, 291, 434, 1364, 365, 5787, 11, 309, 311, 1920, 1128, 4961, 281], "temperature": 0.0, "avg_logprob": -0.19005479431152345, "compression_ratio": 1.7256944444444444, "no_speech_prob": 1.8058091882267036e-05}, {"id": 53, "seek": 33672, "start": 336.72, "end": 340.68, "text": " retrain the convolutional layers.", "tokens": [1533, 7146, 264, 45216, 304, 7914, 13], "temperature": 0.0, "avg_logprob": -0.20374341011047364, "compression_ratio": 1.3419354838709678, "no_speech_prob": 2.014537494687829e-05}, {"id": 54, "seek": 33672, "start": 340.68, "end": 350.72, "text": " So we can stick something on top of our ResNet in the usual way. And we can say go ahead", "tokens": [407, 321, 393, 2897, 746, 322, 1192, 295, 527, 5015, 31890, 294, 264, 7713, 636, 13, 400, 321, 393, 584, 352, 2286], "temperature": 0.0, "avg_logprob": -0.20374341011047364, "compression_ratio": 1.3419354838709678, "no_speech_prob": 2.014537494687829e-05}, {"id": 55, "seek": 33672, "start": 350.72, "end": 359.92, "text": " and compile and fit it. And in 48 seconds it's created a model with a 0.986 accuracy,", "tokens": [293, 31413, 293, 3318, 309, 13, 400, 294, 11174, 3949, 309, 311, 2942, 257, 2316, 365, 257, 1958, 13, 24, 22193, 14170, 11], "temperature": 0.0, "avg_logprob": -0.20374341011047364, "compression_ratio": 1.3419354838709678, "no_speech_prob": 2.014537494687829e-05}, {"id": 56, "seek": 35992, "start": 359.92, "end": 366.92, "text": " which is win on the private leaderboard or be second on the private leaderboard. So that's", "tokens": [597, 307, 1942, 322, 264, 4551, 5263, 3787, 420, 312, 1150, 322, 264, 4551, 5263, 3787, 13, 407, 300, 311], "temperature": 0.0, "avg_logprob": -0.21296641031901042, "compression_ratio": 1.7345454545454546, "no_speech_prob": 2.6274197807651944e-05}, {"id": 57, "seek": 35992, "start": 366.92, "end": 368.0, "text": " pretty impressive.", "tokens": [1238, 8992, 13], "temperature": 0.0, "avg_logprob": -0.21296641031901042, "compression_ratio": 1.7345454545454546, "no_speech_prob": 2.6274197807651944e-05}, {"id": 58, "seek": 35992, "start": 368.0, "end": 372.44, "text": " More impressive is, and I'm going to show you how this works in a moment, but ResNet", "tokens": [5048, 8992, 307, 11, 293, 286, 478, 516, 281, 855, 291, 577, 341, 1985, 294, 257, 1623, 11, 457, 5015, 31890], "temperature": 0.0, "avg_logprob": -0.21296641031901042, "compression_ratio": 1.7345454545454546, "no_speech_prob": 2.6274197807651944e-05}, {"id": 59, "seek": 35992, "start": 372.44, "end": 378.12, "text": " is actually designed to not be used with a standard bunch of dense layers, but it's designed", "tokens": [307, 767, 4761, 281, 406, 312, 1143, 365, 257, 3832, 3840, 295, 18011, 7914, 11, 457, 309, 311, 4761], "temperature": 0.0, "avg_logprob": -0.21296641031901042, "compression_ratio": 1.7345454545454546, "no_speech_prob": 2.6274197807651944e-05}, {"id": 60, "seek": 35992, "start": 378.12, "end": 382.40000000000003, "text": " to be used with something called a global average pooling layer, which I'm about to", "tokens": [281, 312, 1143, 365, 746, 1219, 257, 4338, 4274, 7005, 278, 4583, 11, 597, 286, 478, 466, 281], "temperature": 0.0, "avg_logprob": -0.21296641031901042, "compression_ratio": 1.7345454545454546, "no_speech_prob": 2.6274197807651944e-05}, {"id": 61, "seek": 35992, "start": 382.40000000000003, "end": 383.40000000000003, "text": " describe to you.", "tokens": [6786, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.21296641031901042, "compression_ratio": 1.7345454545454546, "no_speech_prob": 2.6274197807651944e-05}, {"id": 62, "seek": 35992, "start": 383.40000000000003, "end": 386.8, "text": " So for now let me just show you what happens if instead of the previous model, I instead", "tokens": [407, 337, 586, 718, 385, 445, 855, 291, 437, 2314, 498, 2602, 295, 264, 3894, 2316, 11, 286, 2602], "temperature": 0.0, "avg_logprob": -0.21296641031901042, "compression_ratio": 1.7345454545454546, "no_speech_prob": 2.6274197807651944e-05}, {"id": 63, "seek": 38680, "start": 386.8, "end": 399.96000000000004, "text": " use this model, which has 3 layers, and compile it, fit it, I get 0.9875 in 3 seconds. In", "tokens": [764, 341, 2316, 11, 597, 575, 805, 7914, 11, 293, 31413, 309, 11, 3318, 309, 11, 286, 483, 1958, 13, 22516, 11901, 294, 805, 3949, 13, 682], "temperature": 0.0, "avg_logprob": -0.19647054203221057, "compression_ratio": 1.2949640287769784, "no_speech_prob": 1.834271643019747e-05}, {"id": 64, "seek": 38680, "start": 399.96000000000004, "end": 409.76, "text": " fact I can even tell it that I don't want to use 224x224 images, but I want to use 400x400", "tokens": [1186, 286, 393, 754, 980, 309, 300, 286, 500, 380, 528, 281, 764, 5853, 19, 87, 7490, 19, 5267, 11, 457, 286, 528, 281, 764, 8423, 87, 13741], "temperature": 0.0, "avg_logprob": -0.19647054203221057, "compression_ratio": 1.2949640287769784, "no_speech_prob": 1.834271643019747e-05}, {"id": 65, "seek": 40976, "start": 409.76, "end": 417.12, "text": " images. And if I do that, and then in my get batches I say I want to create 400x400 images,", "tokens": [5267, 13, 400, 498, 286, 360, 300, 11, 293, 550, 294, 452, 483, 15245, 279, 286, 584, 286, 528, 281, 1884, 8423, 87, 13741, 5267, 11], "temperature": 0.0, "avg_logprob": -0.26777972532122324, "compression_ratio": 1.517766497461929, "no_speech_prob": 7.889171683927998e-06}, {"id": 66, "seek": 40976, "start": 417.12, "end": 426.12, "text": " and create those features, compile them, fit, I get 99.3. So this is kind of off the charts", "tokens": [293, 1884, 729, 4122, 11, 31413, 552, 11, 3318, 11, 286, 483, 11803, 13, 18, 13, 407, 341, 307, 733, 295, 766, 264, 17767], "temperature": 0.0, "avg_logprob": -0.26777972532122324, "compression_ratio": 1.517766497461929, "no_speech_prob": 7.889171683927998e-06}, {"id": 67, "seek": 40976, "start": 426.12, "end": 433.48, "text": " to go from somewhere around 98.5 to 99.3, we're reducing the amount of error by somewhere", "tokens": [281, 352, 490, 4079, 926, 20860, 13, 20, 281, 11803, 13, 18, 11, 321, 434, 12245, 264, 2372, 295, 6713, 538, 4079], "temperature": 0.0, "avg_logprob": -0.26777972532122324, "compression_ratio": 1.517766497461929, "no_speech_prob": 7.889171683927998e-06}, {"id": 68, "seek": 40976, "start": 433.48, "end": 435.84, "text": " around a third to a half.", "tokens": [926, 257, 2636, 281, 257, 1922, 13], "temperature": 0.0, "avg_logprob": -0.26777972532122324, "compression_ratio": 1.517766497461929, "no_speech_prob": 7.889171683927998e-06}, {"id": 69, "seek": 43584, "start": 435.84, "end": 444.32, "text": " So this is why you should be interested in ResNet. It's incredibly accurate. We're using", "tokens": [407, 341, 307, 983, 291, 820, 312, 3102, 294, 5015, 31890, 13, 467, 311, 6252, 8559, 13, 492, 434, 1228], "temperature": 0.0, "avg_logprob": -0.1848845048384233, "compression_ratio": 1.5944700460829493, "no_speech_prob": 8.013392289285548e-06}, {"id": 70, "seek": 43584, "start": 444.32, "end": 450.96, "text": " it for the thing it's best at. This ResNet was trained on ImageNet, and the dogs and", "tokens": [309, 337, 264, 551, 309, 311, 1151, 412, 13, 639, 5015, 31890, 390, 8895, 322, 29903, 31890, 11, 293, 264, 7197, 293], "temperature": 0.0, "avg_logprob": -0.1848845048384233, "compression_ratio": 1.5944700460829493, "no_speech_prob": 8.013392289285548e-06}, {"id": 71, "seek": 43584, "start": 450.96, "end": 455.96, "text": " cats competition looks a lot like ImageNet images. They're single pictures of a single", "tokens": [11111, 6211, 1542, 257, 688, 411, 29903, 31890, 5267, 13, 814, 434, 2167, 5242, 295, 257, 2167], "temperature": 0.0, "avg_logprob": -0.1848845048384233, "compression_ratio": 1.5944700460829493, "no_speech_prob": 8.013392289285548e-06}, {"id": 72, "seek": 43584, "start": 455.96, "end": 461.08, "text": " thing that's recently large in the picture, they're not very big images on the whole.", "tokens": [551, 300, 311, 3938, 2416, 294, 264, 3036, 11, 436, 434, 406, 588, 955, 5267, 322, 264, 1379, 13], "temperature": 0.0, "avg_logprob": -0.1848845048384233, "compression_ratio": 1.5944700460829493, "no_speech_prob": 8.013392289285548e-06}, {"id": 73, "seek": 46108, "start": 461.08, "end": 467.24, "text": " And so this is something which this kind of ResNet approach is particularly good for.", "tokens": [400, 370, 341, 307, 746, 597, 341, 733, 295, 5015, 31890, 3109, 307, 4098, 665, 337, 13], "temperature": 0.0, "avg_logprob": -0.17439546158064656, "compression_ratio": 1.4754098360655739, "no_speech_prob": 2.5866667783702724e-05}, {"id": 74, "seek": 46108, "start": 467.24, "end": 471.96, "text": " So I do actually want to show you how it works, because I think it's fascinating and awesome.", "tokens": [407, 286, 360, 767, 528, 281, 855, 291, 577, 309, 1985, 11, 570, 286, 519, 309, 311, 10343, 293, 3476, 13], "temperature": 0.0, "avg_logprob": -0.17439546158064656, "compression_ratio": 1.4754098360655739, "no_speech_prob": 2.5866667783702724e-05}, {"id": 75, "seek": 46108, "start": 471.96, "end": 478.32, "text": " And I'm going to stick to the same approach that we've used so far when we've talked about", "tokens": [400, 286, 478, 516, 281, 2897, 281, 264, 912, 3109, 300, 321, 600, 1143, 370, 1400, 562, 321, 600, 2825, 466], "temperature": 0.0, "avg_logprob": -0.17439546158064656, "compression_ratio": 1.4754098360655739, "no_speech_prob": 2.5866667783702724e-05}, {"id": 76, "seek": 47832, "start": 478.32, "end": 495.84, "text": " architectures. Any shape represents a matrix of activations, and any arrow represents a", "tokens": [6331, 1303, 13, 2639, 3909, 8855, 257, 8141, 295, 2430, 763, 11, 293, 604, 11610, 8855, 257], "temperature": 0.0, "avg_logprob": -0.25494334697723386, "compression_ratio": 1.4262295081967213, "no_speech_prob": 2.8408991056494415e-05}, {"id": 77, "seek": 47832, "start": 495.84, "end": 505.56, "text": " layer operation. So that's a convolution or a dense layer with an activation function.", "tokens": [4583, 6916, 13, 407, 300, 311, 257, 45216, 420, 257, 18011, 4583, 365, 364, 24433, 2445, 13], "temperature": 0.0, "avg_logprob": -0.25494334697723386, "compression_ratio": 1.4262295081967213, "no_speech_prob": 2.8408991056494415e-05}, {"id": 78, "seek": 50556, "start": 505.56, "end": 513.08, "text": " ResNet looks a lot like VGG. So I've mentioned that there's some part of the model down here", "tokens": [5015, 31890, 1542, 257, 688, 411, 691, 27561, 13, 407, 286, 600, 2835, 300, 456, 311, 512, 644, 295, 264, 2316, 760, 510], "temperature": 0.0, "avg_logprob": -0.19661899095170954, "compression_ratio": 1.5446009389671362, "no_speech_prob": 2.5866913347272202e-05}, {"id": 79, "seek": 50556, "start": 513.08, "end": 518.04, "text": " that we're not going to worry about too much. We're kind of like halfway through the model,", "tokens": [300, 321, 434, 406, 516, 281, 3292, 466, 886, 709, 13, 492, 434, 733, 295, 411, 15461, 807, 264, 2316, 11], "temperature": 0.0, "avg_logprob": -0.19661899095170954, "compression_ratio": 1.5446009389671362, "no_speech_prob": 2.5866913347272202e-05}, {"id": 80, "seek": 50556, "start": 518.04, "end": 523.96, "text": " and there's some hidden activation layer that we've got to.", "tokens": [293, 456, 311, 512, 7633, 24433, 4583, 300, 321, 600, 658, 281, 13], "temperature": 0.0, "avg_logprob": -0.19661899095170954, "compression_ratio": 1.5446009389671362, "no_speech_prob": 2.5866913347272202e-05}, {"id": 81, "seek": 50556, "start": 523.96, "end": 534.44, "text": " With VGG, the approach is generally to go, the layers are basically a 3x3 conv, that", "tokens": [2022, 691, 27561, 11, 264, 3109, 307, 5101, 281, 352, 11, 264, 7914, 366, 1936, 257, 805, 87, 18, 3754, 11, 300], "temperature": 0.0, "avg_logprob": -0.19661899095170954, "compression_ratio": 1.5446009389671362, "no_speech_prob": 2.5866913347272202e-05}, {"id": 82, "seek": 53444, "start": 534.44, "end": 539.12, "text": " gives you some activations, another 3x3 conv, that gives you some activations, another 3x3", "tokens": [2709, 291, 512, 2430, 763, 11, 1071, 805, 87, 18, 3754, 11, 300, 2709, 291, 512, 2430, 763, 11, 1071, 805, 87, 18], "temperature": 0.0, "avg_logprob": -0.25480567932128906, "compression_ratio": 1.8756476683937824, "no_speech_prob": 1.8058024579659104e-05}, {"id": 83, "seek": 53444, "start": 539.12, "end": 547.4000000000001, "text": " conv, that gives you some activations, and then from time to time it also does a max", "tokens": [3754, 11, 300, 2709, 291, 512, 2430, 763, 11, 293, 550, 490, 565, 281, 565, 309, 611, 775, 257, 11469], "temperature": 0.0, "avg_logprob": -0.25480567932128906, "compression_ratio": 1.8756476683937824, "no_speech_prob": 1.8058024579659104e-05}, {"id": 84, "seek": 53444, "start": 547.4000000000001, "end": 548.4000000000001, "text": " pooling.", "tokens": [7005, 278, 13], "temperature": 0.0, "avg_logprob": -0.25480567932128906, "compression_ratio": 1.8756476683937824, "no_speech_prob": 1.8058024579659104e-05}, {"id": 85, "seek": 53444, "start": 548.4000000000001, "end": 556.0, "text": " So each of these is representing a convolution layer. ResNet looks a lot like this. In fact,", "tokens": [407, 1184, 295, 613, 307, 13460, 257, 45216, 4583, 13, 5015, 31890, 1542, 257, 688, 411, 341, 13, 682, 1186, 11], "temperature": 0.0, "avg_logprob": -0.25480567932128906, "compression_ratio": 1.8756476683937824, "no_speech_prob": 1.8058024579659104e-05}, {"id": 86, "seek": 53444, "start": 556.0, "end": 562.2800000000001, "text": " it has exactly that path, which is a bunch of convolutions and relu's on top of each", "tokens": [309, 575, 2293, 300, 3100, 11, 597, 307, 257, 3840, 295, 3754, 15892, 293, 1039, 84, 311, 322, 1192, 295, 1184], "temperature": 0.0, "avg_logprob": -0.25480567932128906, "compression_ratio": 1.8756476683937824, "no_speech_prob": 1.8058024579659104e-05}, {"id": 87, "seek": 56228, "start": 562.28, "end": 575.24, "text": " other. But it does something else, which is there's this bit that comes out. And remember,", "tokens": [661, 13, 583, 309, 775, 746, 1646, 11, 597, 307, 456, 311, 341, 857, 300, 1487, 484, 13, 400, 1604, 11], "temperature": 0.0, "avg_logprob": -0.2223908935768017, "compression_ratio": 1.5529411764705883, "no_speech_prob": 1.6701287677278742e-05}, {"id": 88, "seek": 56228, "start": 575.24, "end": 580.92, "text": " when we have two arrows coming into a shape, that means we're adding things. And you'll", "tokens": [562, 321, 362, 732, 19669, 1348, 666, 257, 3909, 11, 300, 1355, 321, 434, 5127, 721, 13, 400, 291, 603], "temperature": 0.0, "avg_logprob": -0.2223908935768017, "compression_ratio": 1.5529411764705883, "no_speech_prob": 1.6701287677278742e-05}, {"id": 89, "seek": 56228, "start": 580.92, "end": 590.3199999999999, "text": " notice here, there's no shapes anywhere on the way here. In fact, this arrow does not", "tokens": [3449, 510, 11, 456, 311, 572, 10854, 4992, 322, 264, 636, 510, 13, 682, 1186, 11, 341, 11610, 775, 406], "temperature": 0.0, "avg_logprob": -0.2223908935768017, "compression_ratio": 1.5529411764705883, "no_speech_prob": 1.6701287677278742e-05}, {"id": 90, "seek": 59032, "start": 590.32, "end": 597.44, "text": " represent a convolution, it does not represent a dense layer, it actually represents identity.", "tokens": [2906, 257, 45216, 11, 309, 775, 406, 2906, 257, 18011, 4583, 11, 309, 767, 8855, 6575, 13], "temperature": 0.0, "avg_logprob": -0.21818242073059083, "compression_ratio": 1.6476683937823835, "no_speech_prob": 5.422188678494422e-06}, {"id": 91, "seek": 59032, "start": 597.44, "end": 600.2, "text": " In other words, we do nothing at all.", "tokens": [682, 661, 2283, 11, 321, 360, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.21818242073059083, "compression_ratio": 1.6476683937823835, "no_speech_prob": 5.422188678494422e-06}, {"id": 92, "seek": 59032, "start": 600.2, "end": 612.5600000000001, "text": " This whole thing here is called a ResNet block. If we represented a ResNet block as a square,", "tokens": [639, 1379, 551, 510, 307, 1219, 257, 5015, 31890, 3461, 13, 759, 321, 10379, 257, 5015, 31890, 3461, 382, 257, 3732, 11], "temperature": 0.0, "avg_logprob": -0.21818242073059083, "compression_ratio": 1.6476683937823835, "no_speech_prob": 5.422188678494422e-06}, {"id": 93, "seek": 59032, "start": 612.5600000000001, "end": 619.08, "text": " ResNet is just a whole bunch of these blocks stacked on top of each other. And then there's", "tokens": [5015, 31890, 307, 445, 257, 1379, 3840, 295, 613, 8474, 28867, 322, 1192, 295, 1184, 661, 13, 400, 550, 456, 311], "temperature": 0.0, "avg_logprob": -0.21818242073059083, "compression_ratio": 1.6476683937823835, "no_speech_prob": 5.422188678494422e-06}, {"id": 94, "seek": 61908, "start": 619.08, "end": 626.0, "text": " an input, which is the input data, and then the output.", "tokens": [364, 4846, 11, 597, 307, 264, 4846, 1412, 11, 293, 550, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.28896022233806673, "compression_ratio": 1.5684931506849316, "no_speech_prob": 1.5689376596128568e-05}, {"id": 95, "seek": 61908, "start": 626.0, "end": 632.6, "text": " So another way of looking at this is just to look at the code. I think the code is nice", "tokens": [407, 1071, 636, 295, 1237, 412, 341, 307, 445, 281, 574, 412, 264, 3089, 13, 286, 519, 264, 3089, 307, 1481], "temperature": 0.0, "avg_logprob": -0.28896022233806673, "compression_ratio": 1.5684931506849316, "no_speech_prob": 1.5689376596128568e-05}, {"id": 96, "seek": 61908, "start": 632.6, "end": 641.6, "text": " and intuitive to understand. So let's have a look at this thing they call an identity", "tokens": [293, 21769, 281, 1223, 13, 407, 718, 311, 362, 257, 574, 412, 341, 551, 436, 818, 364, 6575], "temperature": 0.0, "avg_logprob": -0.28896022233806673, "compression_ratio": 1.5684931506849316, "no_speech_prob": 1.5689376596128568e-05}, {"id": 97, "seek": 64160, "start": 641.6, "end": 650.44, "text": " block. So here's the code for what I just described. You might notice that everything", "tokens": [3461, 13, 407, 510, 311, 264, 3089, 337, 437, 286, 445, 7619, 13, 509, 1062, 3449, 300, 1203], "temperature": 0.0, "avg_logprob": -0.28954805329788563, "compression_ratio": 1.6525821596244132, "no_speech_prob": 3.2377513434767025e-06}, {"id": 98, "seek": 64160, "start": 650.44, "end": 658.48, "text": " I just selected here looks like a totally standard VGG block. I've got a conv2d, a batch", "tokens": [286, 445, 8209, 510, 1542, 411, 257, 3879, 3832, 691, 27561, 3461, 13, 286, 600, 658, 257, 3754, 17, 67, 11, 257, 15245], "temperature": 0.0, "avg_logprob": -0.28954805329788563, "compression_ratio": 1.6525821596244132, "no_speech_prob": 3.2377513434767025e-06}, {"id": 99, "seek": 64160, "start": 658.48, "end": 663.48, "text": " normalization, and an activation function. I guess it looks like our improved VGG because", "tokens": [2710, 2144, 11, 293, 364, 24433, 2445, 13, 286, 2041, 309, 1542, 411, 527, 9689, 691, 27561, 570], "temperature": 0.0, "avg_logprob": -0.28954805329788563, "compression_ratio": 1.6525821596244132, "no_speech_prob": 3.2377513434767025e-06}, {"id": 100, "seek": 64160, "start": 663.48, "end": 668.0400000000001, "text": " it's got a batch normal. Another convolution, another batch normal, another activation.", "tokens": [309, 311, 658, 257, 15245, 2710, 13, 3996, 45216, 11, 1071, 15245, 2710, 11, 1071, 24433, 13], "temperature": 0.0, "avg_logprob": -0.28954805329788563, "compression_ratio": 1.6525821596244132, "no_speech_prob": 3.2377513434767025e-06}, {"id": 101, "seek": 66804, "start": 668.04, "end": 674.56, "text": " Another conv2d, another batch normal. But then this is the magic that makes it ResNet,", "tokens": [3996, 3754, 17, 67, 11, 1071, 15245, 2710, 13, 583, 550, 341, 307, 264, 5585, 300, 1669, 309, 5015, 31890, 11], "temperature": 0.0, "avg_logprob": -0.21298825936239274, "compression_ratio": 1.4311377245508983, "no_speech_prob": 3.39313737640623e-06}, {"id": 102, "seek": 66804, "start": 674.56, "end": 679.56, "text": " this single line of code. And it does something incredibly simple. It takes the result of", "tokens": [341, 2167, 1622, 295, 3089, 13, 400, 309, 775, 746, 6252, 2199, 13, 467, 2516, 264, 1874, 295], "temperature": 0.0, "avg_logprob": -0.21298825936239274, "compression_ratio": 1.4311377245508983, "no_speech_prob": 3.39313737640623e-06}, {"id": 103, "seek": 66804, "start": 679.56, "end": 689.16, "text": " all those 3 convolutions and it adds it to our original input.", "tokens": [439, 729, 805, 3754, 15892, 293, 309, 10860, 309, 281, 527, 3380, 4846, 13], "temperature": 0.0, "avg_logprob": -0.21298825936239274, "compression_ratio": 1.4311377245508983, "no_speech_prob": 3.39313737640623e-06}, {"id": 104, "seek": 68916, "start": 689.16, "end": 707.36, "text": " So normally, we have the output of some block is equal to a kind of like a convolutions", "tokens": [407, 5646, 11, 321, 362, 264, 5598, 295, 512, 3461, 307, 2681, 281, 257, 733, 295, 411, 257, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.2623568410458772, "compression_ratio": 1.5040650406504066, "no_speech_prob": 4.289311618776992e-06}, {"id": 105, "seek": 68916, "start": 707.36, "end": 714.0799999999999, "text": " of convolutions of convolutions of some input to that block. But we're doing something different.", "tokens": [295, 3754, 15892, 295, 3754, 15892, 295, 512, 4846, 281, 300, 3461, 13, 583, 321, 434, 884, 746, 819, 13], "temperature": 0.0, "avg_logprob": -0.2623568410458772, "compression_ratio": 1.5040650406504066, "no_speech_prob": 4.289311618776992e-06}, {"id": 106, "seek": 71408, "start": 714.08, "end": 724.8000000000001, "text": " We're saying the output to a block, so let's call this hidden state at time t plus 1, is", "tokens": [492, 434, 1566, 264, 5598, 281, 257, 3461, 11, 370, 718, 311, 818, 341, 7633, 1785, 412, 565, 256, 1804, 502, 11, 307], "temperature": 0.0, "avg_logprob": -0.17102885968757398, "compression_ratio": 1.8088235294117647, "no_speech_prob": 2.99443127005361e-06}, {"id": 107, "seek": 71408, "start": 724.8000000000001, "end": 731.6800000000001, "text": " equal to the convolutions of convolutions of convolutions of hidden state at time t plus", "tokens": [2681, 281, 264, 3754, 15892, 295, 3754, 15892, 295, 3754, 15892, 295, 7633, 1785, 412, 565, 256, 1804], "temperature": 0.0, "avg_logprob": -0.17102885968757398, "compression_ratio": 1.8088235294117647, "no_speech_prob": 2.99443127005361e-06}, {"id": 108, "seek": 71408, "start": 731.6800000000001, "end": 739.88, "text": " the hidden state at time t. That is the magic which makes it ResNet.", "tokens": [264, 7633, 1785, 412, 565, 256, 13, 663, 307, 264, 5585, 597, 1669, 309, 5015, 31890, 13], "temperature": 0.0, "avg_logprob": -0.17102885968757398, "compression_ratio": 1.8088235294117647, "no_speech_prob": 2.99443127005361e-06}, {"id": 109, "seek": 73988, "start": 739.88, "end": 748.88, "text": " So why is it that that can give us this huge improvement in the state of the art in such", "tokens": [407, 983, 307, 309, 300, 300, 393, 976, 505, 341, 2603, 10444, 294, 264, 1785, 295, 264, 1523, 294, 1270], "temperature": 0.0, "avg_logprob": -0.21923351287841797, "compression_ratio": 1.5588235294117647, "no_speech_prob": 3.611958845795016e-06}, {"id": 110, "seek": 73988, "start": 748.88, "end": 755.84, "text": " a short period of time? And this is actually, interestingly, something that is somewhat", "tokens": [257, 2099, 2896, 295, 565, 30, 400, 341, 307, 767, 11, 25873, 11, 746, 300, 307, 8344], "temperature": 0.0, "avg_logprob": -0.21923351287841797, "compression_ratio": 1.5588235294117647, "no_speech_prob": 3.611958845795016e-06}, {"id": 111, "seek": 73988, "start": 755.84, "end": 764.4, "text": " controversial. The authors of this paper that originally developed this describe it in a", "tokens": [17323, 13, 440, 16552, 295, 341, 3035, 300, 7993, 4743, 341, 6786, 309, 294, 257], "temperature": 0.0, "avg_logprob": -0.21923351287841797, "compression_ratio": 1.5588235294117647, "no_speech_prob": 3.611958845795016e-06}, {"id": 112, "seek": 76440, "start": 764.4, "end": 769.92, "text": " number of ways. They basically gave 2 main reasons. The first is they claim that you", "tokens": [1230, 295, 2098, 13, 814, 1936, 2729, 568, 2135, 4112, 13, 440, 700, 307, 436, 3932, 300, 291], "temperature": 0.0, "avg_logprob": -0.2149528373371471, "compression_ratio": 1.5963302752293578, "no_speech_prob": 9.516022146272007e-06}, {"id": 113, "seek": 76440, "start": 769.92, "end": 775.36, "text": " can create much deeper networks this way. Because when you're backpropagating the weights,", "tokens": [393, 1884, 709, 7731, 9590, 341, 636, 13, 1436, 562, 291, 434, 646, 79, 1513, 559, 990, 264, 17443, 11], "temperature": 0.0, "avg_logprob": -0.2149528373371471, "compression_ratio": 1.5963302752293578, "no_speech_prob": 9.516022146272007e-06}, {"id": 114, "seek": 76440, "start": 775.36, "end": 782.0, "text": " backpropagating through an identity is easy. You're never going to have an explosion of", "tokens": [646, 79, 1513, 559, 990, 807, 364, 6575, 307, 1858, 13, 509, 434, 1128, 516, 281, 362, 364, 15673, 295], "temperature": 0.0, "avg_logprob": -0.2149528373371471, "compression_ratio": 1.5963302752293578, "no_speech_prob": 9.516022146272007e-06}, {"id": 115, "seek": 76440, "start": 782.0, "end": 788.16, "text": " gradients or explosion of activations. And indeed, this did turn out to be true. The", "tokens": [2771, 2448, 420, 15673, 295, 2430, 763, 13, 400, 6451, 11, 341, 630, 1261, 484, 281, 312, 2074, 13, 440], "temperature": 0.0, "avg_logprob": -0.2149528373371471, "compression_ratio": 1.5963302752293578, "no_speech_prob": 9.516022146272007e-06}, {"id": 116, "seek": 78816, "start": 788.16, "end": 795.16, "text": " authors created a ResNet with over 1000 layers and got very good results. But it also turned", "tokens": [16552, 2942, 257, 5015, 31890, 365, 670, 9714, 7914, 293, 658, 588, 665, 3542, 13, 583, 309, 611, 3574], "temperature": 0.0, "avg_logprob": -0.18693911701167396, "compression_ratio": 1.6216216216216217, "no_speech_prob": 9.223395863955375e-06}, {"id": 117, "seek": 78816, "start": 795.16, "end": 801.0, "text": " out to be a bit of a red herring. Because a few months ago, some other folks created", "tokens": [484, 281, 312, 257, 857, 295, 257, 2182, 720, 2937, 13, 1436, 257, 1326, 2493, 2057, 11, 512, 661, 4024, 2942], "temperature": 0.0, "avg_logprob": -0.18693911701167396, "compression_ratio": 1.6216216216216217, "no_speech_prob": 9.223395863955375e-06}, {"id": 118, "seek": 78816, "start": 801.0, "end": 808.1999999999999, "text": " a ResNet which was not at all deep. I think it had like 40 or 50 layers. But instead it's", "tokens": [257, 5015, 31890, 597, 390, 406, 412, 439, 2452, 13, 286, 519, 309, 632, 411, 3356, 420, 2625, 7914, 13, 583, 2602, 309, 311], "temperature": 0.0, "avg_logprob": -0.18693911701167396, "compression_ratio": 1.6216216216216217, "no_speech_prob": 9.223395863955375e-06}, {"id": 119, "seek": 78816, "start": 808.1999999999999, "end": 812.0, "text": " very wide and had a lot of activations. And that did even better.", "tokens": [588, 4874, 293, 632, 257, 688, 295, 2430, 763, 13, 400, 300, 630, 754, 1101, 13], "temperature": 0.0, "avg_logprob": -0.18693911701167396, "compression_ratio": 1.6216216216216217, "no_speech_prob": 9.223395863955375e-06}, {"id": 120, "seek": 78816, "start": 812.0, "end": 816.4399999999999, "text": " So it's one of these funny things that seems even the original authors might have been", "tokens": [407, 309, 311, 472, 295, 613, 4074, 721, 300, 2544, 754, 264, 3380, 16552, 1062, 362, 668], "temperature": 0.0, "avg_logprob": -0.18693911701167396, "compression_ratio": 1.6216216216216217, "no_speech_prob": 9.223395863955375e-06}, {"id": 121, "seek": 81644, "start": 816.44, "end": 820.9200000000001, "text": " wrong about why they built what they built. The second reason of why they built what they", "tokens": [2085, 466, 983, 436, 3094, 437, 436, 3094, 13, 440, 1150, 1778, 295, 983, 436, 3094, 437, 436], "temperature": 0.0, "avg_logprob": -0.21571261088053387, "compression_ratio": 1.7839195979899498, "no_speech_prob": 5.255346422927687e-06}, {"id": 122, "seek": 81644, "start": 820.9200000000001, "end": 826.72, "text": " built seems to have stood the test of time forever. Which is that if we take this equation", "tokens": [3094, 2544, 281, 362, 9371, 264, 1500, 295, 565, 5680, 13, 3013, 307, 300, 498, 321, 747, 341, 5367], "temperature": 0.0, "avg_logprob": -0.21571261088053387, "compression_ratio": 1.7839195979899498, "no_speech_prob": 5.255346422927687e-06}, {"id": 123, "seek": 81644, "start": 826.72, "end": 835.8000000000001, "text": " and rejig it, let's subtract that from both sides. And that gives us ht plus 1 minus ht.", "tokens": [293, 319, 73, 328, 309, 11, 718, 311, 16390, 300, 490, 1293, 4881, 13, 400, 300, 2709, 505, 276, 83, 1804, 502, 3175, 276, 83, 13], "temperature": 0.0, "avg_logprob": -0.21571261088053387, "compression_ratio": 1.7839195979899498, "no_speech_prob": 5.255346422927687e-06}, {"id": 124, "seek": 81644, "start": 835.8000000000001, "end": 841.2, "text": " So the hidden activations at the next time period minus the hidden activations at the", "tokens": [407, 264, 7633, 2430, 763, 412, 264, 958, 565, 2896, 3175, 264, 7633, 2430, 763, 412, 264], "temperature": 0.0, "avg_logprob": -0.21571261088053387, "compression_ratio": 1.7839195979899498, "no_speech_prob": 5.255346422927687e-06}, {"id": 125, "seek": 84120, "start": 841.2, "end": 853.8000000000001, "text": " previous time period equals a convolution of convolution of convolution applied to the", "tokens": [3894, 565, 2896, 6915, 257, 45216, 295, 45216, 295, 45216, 6456, 281, 264], "temperature": 0.0, "avg_logprob": -0.2858325746324327, "compression_ratio": 1.5, "no_speech_prob": 1.4738800928171258e-05}, {"id": 126, "seek": 84120, "start": 853.8000000000001, "end": 857.76, "text": " previous hidden state.", "tokens": [3894, 7633, 1785, 13], "temperature": 0.0, "avg_logprob": -0.2858325746324327, "compression_ratio": 1.5, "no_speech_prob": 1.4738800928171258e-05}, {"id": 127, "seek": 84120, "start": 857.76, "end": 866.96, "text": " When you run it like that, it might make you realize something. All of the weights we're", "tokens": [1133, 291, 1190, 309, 411, 300, 11, 309, 1062, 652, 291, 4325, 746, 13, 1057, 295, 264, 17443, 321, 434], "temperature": 0.0, "avg_logprob": -0.2858325746324327, "compression_ratio": 1.5, "no_speech_prob": 1.4738800928171258e-05}, {"id": 128, "seek": 86696, "start": 866.96, "end": 874.36, "text": " learning here. So we're learning a bunch of weights which allow us to make our previous", "tokens": [2539, 510, 13, 407, 321, 434, 2539, 257, 3840, 295, 17443, 597, 2089, 505, 281, 652, 527, 3894], "temperature": 0.0, "avg_logprob": -0.18180772532587466, "compression_ratio": 1.7657657657657657, "no_speech_prob": 2.2125363102531992e-05}, {"id": 129, "seek": 86696, "start": 874.36, "end": 881.2800000000001, "text": " guess as to the predictions a little bit better. So basically saying let's take the previous", "tokens": [2041, 382, 281, 264, 21264, 257, 707, 857, 1101, 13, 407, 1936, 1566, 718, 311, 747, 264, 3894], "temperature": 0.0, "avg_logprob": -0.18180772532587466, "compression_ratio": 1.7657657657657657, "no_speech_prob": 2.2125363102531992e-05}, {"id": 130, "seek": 86696, "start": 881.2800000000001, "end": 886.64, "text": " predictions we've got, however we got to them, and try and build a set of things which makes", "tokens": [21264, 321, 600, 658, 11, 4461, 321, 658, 281, 552, 11, 293, 853, 293, 1322, 257, 992, 295, 721, 597, 1669], "temperature": 0.0, "avg_logprob": -0.18180772532587466, "compression_ratio": 1.7657657657657657, "no_speech_prob": 2.2125363102531992e-05}, {"id": 131, "seek": 86696, "start": 886.64, "end": 888.0400000000001, "text": " them a little bit better.", "tokens": [552, 257, 707, 857, 1101, 13], "temperature": 0.0, "avg_logprob": -0.18180772532587466, "compression_ratio": 1.7657657657657657, "no_speech_prob": 2.2125363102531992e-05}, {"id": 132, "seek": 86696, "start": 888.0400000000001, "end": 893.48, "text": " In statistics, this thing is called the residual. The residual is the difference between the", "tokens": [682, 12523, 11, 341, 551, 307, 1219, 264, 27980, 13, 440, 27980, 307, 264, 2649, 1296, 264], "temperature": 0.0, "avg_logprob": -0.18180772532587466, "compression_ratio": 1.7657657657657657, "no_speech_prob": 2.2125363102531992e-05}, {"id": 133, "seek": 89348, "start": 893.48, "end": 900.88, "text": " thing you're trying to predict and your actuals. So what the authors of ResNet basically did", "tokens": [551, 291, 434, 1382, 281, 6069, 293, 428, 3539, 82, 13, 407, 437, 264, 16552, 295, 5015, 31890, 1936, 630], "temperature": 0.0, "avg_logprob": -0.19645370231879936, "compression_ratio": 1.6313725490196078, "no_speech_prob": 2.0784864318557084e-05}, {"id": 134, "seek": 89348, "start": 900.88, "end": 906.16, "text": " here was they designed an architecture which, without us having to do anything special,", "tokens": [510, 390, 436, 4761, 364, 9482, 597, 11, 1553, 505, 1419, 281, 360, 1340, 2121, 11], "temperature": 0.0, "avg_logprob": -0.19645370231879936, "compression_ratio": 1.6313725490196078, "no_speech_prob": 2.0784864318557084e-05}, {"id": 135, "seek": 89348, "start": 906.16, "end": 911.8000000000001, "text": " automatically learns how to model the residuals. It learns how to build a bunch of layers which", "tokens": [6772, 27152, 577, 281, 2316, 264, 27980, 82, 13, 467, 27152, 577, 281, 1322, 257, 3840, 295, 7914, 597], "temperature": 0.0, "avg_logprob": -0.19645370231879936, "compression_ratio": 1.6313725490196078, "no_speech_prob": 2.0784864318557084e-05}, {"id": 136, "seek": 89348, "start": 911.8000000000001, "end": 916.84, "text": " continually slightly improve the previous answer.", "tokens": [22277, 4748, 3470, 264, 3894, 1867, 13], "temperature": 0.0, "avg_logprob": -0.19645370231879936, "compression_ratio": 1.6313725490196078, "no_speech_prob": 2.0784864318557084e-05}, {"id": 137, "seek": 89348, "start": 916.84, "end": 920.48, "text": " For those of you who have more of a machine learning background, you would recognize this", "tokens": [1171, 729, 295, 291, 567, 362, 544, 295, 257, 3479, 2539, 3678, 11, 291, 576, 5521, 341], "temperature": 0.0, "avg_logprob": -0.19645370231879936, "compression_ratio": 1.6313725490196078, "no_speech_prob": 2.0784864318557084e-05}, {"id": 138, "seek": 92048, "start": 920.48, "end": 928.48, "text": " as essentially being boosting. Boosting refers to the idea of having a bunch of models where", "tokens": [382, 4476, 885, 43117, 13, 43902, 278, 14942, 281, 264, 1558, 295, 1419, 257, 3840, 295, 5245, 689], "temperature": 0.0, "avg_logprob": -0.19611149299435499, "compression_ratio": 1.7643979057591623, "no_speech_prob": 1.0783226571220439e-05}, {"id": 139, "seek": 92048, "start": 928.48, "end": 933.28, "text": " each model tries to predict the errors of the previous model. If you have a whole chain", "tokens": [1184, 2316, 9898, 281, 6069, 264, 13603, 295, 264, 3894, 2316, 13, 759, 291, 362, 257, 1379, 5021], "temperature": 0.0, "avg_logprob": -0.19611149299435499, "compression_ratio": 1.7643979057591623, "no_speech_prob": 1.0783226571220439e-05}, {"id": 140, "seek": 92048, "start": 933.28, "end": 937.44, "text": " of those, you can then predict the errors on top of the errors, and you can add them", "tokens": [295, 729, 11, 291, 393, 550, 6069, 264, 13603, 322, 1192, 295, 264, 13603, 11, 293, 291, 393, 909, 552], "temperature": 0.0, "avg_logprob": -0.19611149299435499, "compression_ratio": 1.7643979057591623, "no_speech_prob": 1.0783226571220439e-05}, {"id": 141, "seek": 92048, "start": 937.44, "end": 943.8000000000001, "text": " all together, and boosting is a way of getting much improved ensembles.", "tokens": [439, 1214, 11, 293, 43117, 307, 257, 636, 295, 1242, 709, 9689, 12567, 2504, 904, 13], "temperature": 0.0, "avg_logprob": -0.19611149299435499, "compression_ratio": 1.7643979057591623, "no_speech_prob": 1.0783226571220439e-05}, {"id": 142, "seek": 94380, "start": 943.8, "end": 950.3599999999999, "text": " So this ResNet is not manually doing boosting, it's not manually doing anything. It's just", "tokens": [407, 341, 5015, 31890, 307, 406, 16945, 884, 43117, 11, 309, 311, 406, 16945, 884, 1340, 13, 467, 311, 445], "temperature": 0.0, "avg_logprob": -0.1914880116780599, "compression_ratio": 1.669603524229075, "no_speech_prob": 6.6434072323318105e-06}, {"id": 143, "seek": 94380, "start": 950.3599999999999, "end": 958.88, "text": " this single one extra line of code. It's all in the architecture.", "tokens": [341, 2167, 472, 2857, 1622, 295, 3089, 13, 467, 311, 439, 294, 264, 9482, 13], "temperature": 0.0, "avg_logprob": -0.1914880116780599, "compression_ratio": 1.669603524229075, "no_speech_prob": 6.6434072323318105e-06}, {"id": 144, "seek": 94380, "start": 958.88, "end": 965.04, "text": " Question about dimensionality. I would have assumed that by the time we were close to", "tokens": [14464, 466, 10139, 1860, 13, 286, 576, 362, 15895, 300, 538, 264, 565, 321, 645, 1998, 281], "temperature": 0.0, "avg_logprob": -0.1914880116780599, "compression_ratio": 1.669603524229075, "no_speech_prob": 6.6434072323318105e-06}, {"id": 145, "seek": 94380, "start": 965.04, "end": 970.0, "text": " output, the dimensions would be so different that element-wise addition wouldn't be possible", "tokens": [5598, 11, 264, 12819, 576, 312, 370, 819, 300, 4478, 12, 3711, 4500, 2759, 380, 312, 1944], "temperature": 0.0, "avg_logprob": -0.1914880116780599, "compression_ratio": 1.669603524229075, "no_speech_prob": 6.6434072323318105e-06}, {"id": 146, "seek": 94380, "start": 970.0, "end": 972.04, "text": " between the last layer and the first layer.", "tokens": [1296, 264, 1036, 4583, 293, 264, 700, 4583, 13], "temperature": 0.0, "avg_logprob": -0.1914880116780599, "compression_ratio": 1.669603524229075, "no_speech_prob": 6.6434072323318105e-06}, {"id": 147, "seek": 97204, "start": 972.04, "end": 980.0, "text": " It's important to note that this input tensor is the input tensor to the block. So you'll", "tokens": [467, 311, 1021, 281, 3637, 300, 341, 4846, 40863, 307, 264, 4846, 40863, 281, 264, 3461, 13, 407, 291, 603], "temperature": 0.0, "avg_logprob": -0.1876896402110224, "compression_ratio": 1.865546218487395, "no_speech_prob": 5.255361884337617e-06}, {"id": 148, "seek": 97204, "start": 980.0, "end": 986.36, "text": " see there's no max pooling inside here, or no strides inside here. So the dimensionality", "tokens": [536, 456, 311, 572, 11469, 7005, 278, 1854, 510, 11, 420, 572, 1056, 1875, 1854, 510, 13, 407, 264, 10139, 1860], "temperature": 0.0, "avg_logprob": -0.1876896402110224, "compression_ratio": 1.865546218487395, "no_speech_prob": 5.255361884337617e-06}, {"id": 149, "seek": 97204, "start": 986.36, "end": 991.24, "text": " remains constant throughout all these lines of code, so we can add them up. And then we", "tokens": [7023, 5754, 3710, 439, 613, 3876, 295, 3089, 11, 370, 321, 393, 909, 552, 493, 13, 400, 550, 321], "temperature": 0.0, "avg_logprob": -0.1876896402110224, "compression_ratio": 1.865546218487395, "no_speech_prob": 5.255361884337617e-06}, {"id": 150, "seek": 97204, "start": 991.24, "end": 995.9599999999999, "text": " can do our strides or max pooling, and then we do another identity block. So we're only", "tokens": [393, 360, 527, 1056, 1875, 420, 11469, 7005, 278, 11, 293, 550, 321, 360, 1071, 6575, 3461, 13, 407, 321, 434, 787], "temperature": 0.0, "avg_logprob": -0.1876896402110224, "compression_ratio": 1.865546218487395, "no_speech_prob": 5.255361884337617e-06}, {"id": 151, "seek": 97204, "start": 995.9599999999999, "end": 1001.12, "text": " adding it back to the input of the block, not the input of the original image. And that's", "tokens": [5127, 309, 646, 281, 264, 4846, 295, 264, 3461, 11, 406, 264, 4846, 295, 264, 3380, 3256, 13, 400, 300, 311], "temperature": 0.0, "avg_logprob": -0.1876896402110224, "compression_ratio": 1.865546218487395, "no_speech_prob": 5.255361884337617e-06}, {"id": 152, "seek": 100112, "start": 1001.12, "end": 1008.76, "text": " indeed what we want. We want to say the input to each block is our best prediction so far", "tokens": [6451, 437, 321, 528, 13, 492, 528, 281, 584, 264, 4846, 281, 1184, 3461, 307, 527, 1151, 17630, 370, 1400], "temperature": 0.0, "avg_logprob": -0.2518446151524374, "compression_ratio": 1.5054945054945055, "no_speech_prob": 8.13962469692342e-06}, {"id": 153, "seek": 100112, "start": 1008.76, "end": 1010.76, "text": " is effectively what it's doing.", "tokens": [307, 8659, 437, 309, 311, 884, 13], "temperature": 0.0, "avg_logprob": -0.2518446151524374, "compression_ratio": 1.5054945054945055, "no_speech_prob": 8.13962469692342e-06}, {"id": 154, "seek": 100112, "start": 1010.76, "end": 1014.0, "text": " Question about qualitatively. How does this compare to dropout?", "tokens": [14464, 466, 31312, 356, 13, 1012, 775, 341, 6794, 281, 3270, 346, 30], "temperature": 0.0, "avg_logprob": -0.2518446151524374, "compression_ratio": 1.5054945054945055, "no_speech_prob": 8.13962469692342e-06}, {"id": 155, "seek": 100112, "start": 1014.0, "end": 1023.0, "text": " In most ways it's unrelated to dropout. And indeed you can add dropout to ResNet. At the", "tokens": [682, 881, 2098, 309, 311, 38967, 281, 3270, 346, 13, 400, 6451, 291, 393, 909, 3270, 346, 281, 5015, 31890, 13, 1711, 264], "temperature": 0.0, "avg_logprob": -0.2518446151524374, "compression_ratio": 1.5054945054945055, "no_speech_prob": 8.13962469692342e-06}, {"id": 156, "seek": 102300, "start": 1023.0, "end": 1031.8, "text": " end of a ResNet block, after this merge, you can add dropout. So ResNet is not a regularization", "tokens": [917, 295, 257, 5015, 31890, 3461, 11, 934, 341, 22183, 11, 291, 393, 909, 3270, 346, 13, 407, 5015, 31890, 307, 406, 257, 3890, 2144], "temperature": 0.0, "avg_logprob": -0.2104849916823367, "compression_ratio": 1.5836909871244635, "no_speech_prob": 6.962203315197257e-06}, {"id": 157, "seek": 102300, "start": 1031.8, "end": 1039.76, "text": " technique per se. Having said that, it does seem to have excellent generalization characteristics.", "tokens": [6532, 680, 369, 13, 10222, 848, 300, 11, 309, 775, 1643, 281, 362, 7103, 2674, 2144, 10891, 13], "temperature": 0.0, "avg_logprob": -0.2104849916823367, "compression_ratio": 1.5836909871244635, "no_speech_prob": 6.962203315197257e-06}, {"id": 158, "seek": 102300, "start": 1039.76, "end": 1045.84, "text": " And if memory serves correctly, yes, I just searched this entire codebase for dropout", "tokens": [400, 498, 4675, 13451, 8944, 11, 2086, 11, 286, 445, 22961, 341, 2302, 3089, 17429, 337, 3270, 346], "temperature": 0.0, "avg_logprob": -0.2104849916823367, "compression_ratio": 1.5836909871244635, "no_speech_prob": 6.962203315197257e-06}, {"id": 159, "seek": 102300, "start": 1045.84, "end": 1051.24, "text": " and it didn't appear. So the ImageNet window didn't use any dropout, they didn't find it", "tokens": [293, 309, 994, 380, 4204, 13, 407, 264, 29903, 31890, 4910, 994, 380, 764, 604, 3270, 346, 11, 436, 994, 380, 915, 309], "temperature": 0.0, "avg_logprob": -0.2104849916823367, "compression_ratio": 1.5836909871244635, "no_speech_prob": 6.962203315197257e-06}, {"id": 160, "seek": 105124, "start": 1051.24, "end": 1056.92, "text": " useful. But this is very problem-dependent. If you have only a small amount of data, you", "tokens": [4420, 13, 583, 341, 307, 588, 1154, 12, 36763, 317, 13, 759, 291, 362, 787, 257, 1359, 2372, 295, 1412, 11, 291], "temperature": 0.0, "avg_logprob": -0.2764176262749566, "compression_ratio": 1.4816753926701571, "no_speech_prob": 1.6442256310256198e-05}, {"id": 161, "seek": 105124, "start": 1056.92, "end": 1057.92, "text": " may well need dropout.", "tokens": [815, 731, 643, 3270, 346, 13], "temperature": 0.0, "avg_logprob": -0.2764176262749566, "compression_ratio": 1.4816753926701571, "no_speech_prob": 1.6442256310256198e-05}, {"id": 162, "seek": 105124, "start": 1057.92, "end": 1064.1200000000001, "text": " I'll explain another reason we don't need dropout for this in just a moment. In fact,", "tokens": [286, 603, 2903, 1071, 1778, 321, 500, 380, 643, 3270, 346, 337, 341, 294, 445, 257, 1623, 13, 682, 1186, 11], "temperature": 0.0, "avg_logprob": -0.2764176262749566, "compression_ratio": 1.4816753926701571, "no_speech_prob": 1.6442256310256198e-05}, {"id": 163, "seek": 105124, "start": 1064.1200000000001, "end": 1071.56, "text": " I'll do that right now. Which is, remember what I did here at the end was I created a", "tokens": [286, 603, 360, 300, 558, 586, 13, 3013, 307, 11, 1604, 437, 286, 630, 510, 412, 264, 917, 390, 286, 2942, 257], "temperature": 0.0, "avg_logprob": -0.2764176262749566, "compression_ratio": 1.4816753926701571, "no_speech_prob": 1.6442256310256198e-05}, {"id": 164, "seek": 107156, "start": 1071.56, "end": 1081.2, "text": " model which had a special kind of layer called a global average falling layer. This is the", "tokens": [2316, 597, 632, 257, 2121, 733, 295, 4583, 1219, 257, 4338, 4274, 7440, 4583, 13, 639, 307, 264], "temperature": 0.0, "avg_logprob": -0.21793253668423357, "compression_ratio": 1.4478527607361964, "no_speech_prob": 2.1782216208521277e-05}, {"id": 165, "seek": 107156, "start": 1081.2, "end": 1085.2, "text": " next key thing I want to teach you about today. It's a really important concept that's going", "tokens": [958, 2141, 551, 286, 528, 281, 2924, 291, 466, 965, 13, 467, 311, 257, 534, 1021, 3410, 300, 311, 516], "temperature": 0.0, "avg_logprob": -0.21793253668423357, "compression_ratio": 1.4478527607361964, "no_speech_prob": 2.1782216208521277e-05}, {"id": 166, "seek": 107156, "start": 1085.2, "end": 1089.84, "text": " to come up a couple more times during today's class.", "tokens": [281, 808, 493, 257, 1916, 544, 1413, 1830, 965, 311, 1508, 13], "temperature": 0.0, "avg_logprob": -0.21793253668423357, "compression_ratio": 1.4478527607361964, "no_speech_prob": 2.1782216208521277e-05}, {"id": 167, "seek": 108984, "start": 1089.84, "end": 1103.48, "text": " Let's describe what this is. It's actually very simple. Here is the output of the pre-computed", "tokens": [961, 311, 6786, 437, 341, 307, 13, 467, 311, 767, 588, 2199, 13, 1692, 307, 264, 5598, 295, 264, 659, 12, 1112, 2582, 292], "temperature": 0.0, "avg_logprob": -0.14494400365012033, "compression_ratio": 1.1058823529411765, "no_speech_prob": 9.314173075836152e-05}, {"id": 168, "seek": 110348, "start": 1103.48, "end": 1121.08, "text": " ResNet on our 400x400. It's 13x13. So on the 224x224, the pre-computed convolutional residual", "tokens": [5015, 31890, 322, 527, 8423, 87, 13741, 13, 467, 311, 3705, 87, 7668, 13, 407, 322, 264, 5853, 19, 87, 7490, 19, 11, 264, 659, 12, 1112, 2582, 292, 45216, 304, 27980], "temperature": 0.0, "avg_logprob": -0.36685730860783505, "compression_ratio": 1.16, "no_speech_prob": 3.024122452188749e-05}, {"id": 169, "seek": 110348, "start": 1121.08, "end": 1129.16, "text": " blocks give us a 13x13 output with 2048 fuel reset.", "tokens": [8474, 976, 505, 257, 3705, 87, 7668, 5598, 365, 945, 13318, 6616, 14322, 13], "temperature": 0.0, "avg_logprob": -0.36685730860783505, "compression_ratio": 1.16, "no_speech_prob": 3.024122452188749e-05}, {"id": 170, "seek": 112916, "start": 1129.16, "end": 1137.24, "text": " One way of thinking about this would be to say, well each of these 13x13 blocks could", "tokens": [1485, 636, 295, 1953, 466, 341, 576, 312, 281, 584, 11, 731, 1184, 295, 613, 3705, 87, 7668, 8474, 727], "temperature": 0.0, "avg_logprob": -0.2117669984891817, "compression_ratio": 1.5892857142857142, "no_speech_prob": 1.4970896700106096e-05}, {"id": 171, "seek": 112916, "start": 1137.24, "end": 1144.88, "text": " potentially try to say how catty or how doggy each one of those 13 blocks is. So then rather", "tokens": [7263, 853, 281, 584, 577, 3857, 874, 420, 577, 3000, 1480, 1184, 472, 295, 729, 3705, 8474, 307, 13, 407, 550, 2831], "temperature": 0.0, "avg_logprob": -0.2117669984891817, "compression_ratio": 1.5892857142857142, "no_speech_prob": 1.4970896700106096e-05}, {"id": 172, "seek": 112916, "start": 1144.88, "end": 1157.0, "text": " than max-pulling, we could do average-pulling, which is to say across those 13x13 areas,", "tokens": [813, 11469, 12, 79, 858, 278, 11, 321, 727, 360, 4274, 12, 79, 858, 278, 11, 597, 307, 281, 584, 2108, 729, 3705, 87, 7668, 3179, 11], "temperature": 0.0, "avg_logprob": -0.2117669984891817, "compression_ratio": 1.5892857142857142, "no_speech_prob": 1.4970896700106096e-05}, {"id": 173, "seek": 115700, "start": 1157.0, "end": 1162.88, "text": " what is the average amount of dogginess in each one, what is the average amount of cattiness", "tokens": [437, 307, 264, 4274, 2372, 295, 360, 1615, 1324, 294, 1184, 472, 11, 437, 307, 264, 4274, 2372, 295, 269, 1591, 1324], "temperature": 0.0, "avg_logprob": -0.22658849373841897, "compression_ratio": 1.8758620689655172, "no_speech_prob": 5.173881618247833e-06}, {"id": 174, "seek": 115700, "start": 1162.88, "end": 1169.8, "text": " in each one. That's actually what global average-pulling does. What global average-pulling does is", "tokens": [294, 1184, 472, 13, 663, 311, 767, 437, 4338, 4274, 12, 79, 858, 278, 775, 13, 708, 4338, 4274, 12, 79, 858, 278, 775, 307], "temperature": 0.0, "avg_logprob": -0.22658849373841897, "compression_ratio": 1.8758620689655172, "no_speech_prob": 5.173881618247833e-06}, {"id": 175, "seek": 115700, "start": 1169.8, "end": 1182.32, "text": " it's identical to saying average-pulling 13x13 because the input to it is 13x13.", "tokens": [309, 311, 14800, 281, 1566, 4274, 12, 79, 858, 278, 3705, 87, 7668, 570, 264, 4846, 281, 309, 307, 3705, 87, 7668, 13], "temperature": 0.0, "avg_logprob": -0.22658849373841897, "compression_ratio": 1.8758620689655172, "no_speech_prob": 5.173881618247833e-06}, {"id": 176, "seek": 118232, "start": 1182.32, "end": 1194.12, "text": " So in other words, whatever the input to a global average-pulling layer is, it will take", "tokens": [407, 294, 661, 2283, 11, 2035, 264, 4846, 281, 257, 4338, 4274, 12, 79, 858, 278, 4583, 307, 11, 309, 486, 747], "temperature": 0.0, "avg_logprob": -0.14660368142304597, "compression_ratio": 1.4191176470588236, "no_speech_prob": 2.1568068859778577e-06}, {"id": 177, "seek": 118232, "start": 1194.12, "end": 1199.3999999999999, "text": " all of the x and all of the y coordinates and just take the average for every one of", "tokens": [439, 295, 264, 2031, 293, 439, 295, 264, 288, 21056, 293, 445, 747, 264, 4274, 337, 633, 472, 295], "temperature": 0.0, "avg_logprob": -0.14660368142304597, "compression_ratio": 1.4191176470588236, "no_speech_prob": 2.1568068859778577e-06}, {"id": 178, "seek": 118232, "start": 1199.3999999999999, "end": 1208.36, "text": " these 2048 filters.", "tokens": [613, 945, 13318, 15995, 13], "temperature": 0.0, "avg_logprob": -0.14660368142304597, "compression_ratio": 1.4191176470588236, "no_speech_prob": 2.1568068859778577e-06}, {"id": 179, "seek": 120836, "start": 1208.36, "end": 1219.4399999999998, "text": " So what this is doing is it's taking an input of 2048x13 and it's going to return an output", "tokens": [407, 437, 341, 307, 884, 307, 309, 311, 1940, 364, 4846, 295, 945, 13318, 87, 7668, 293, 309, 311, 516, 281, 2736, 364, 5598], "temperature": 0.0, "avg_logprob": -0.21112326652772964, "compression_ratio": 1.4640522875816993, "no_speech_prob": 4.860426997765899e-06}, {"id": 180, "seek": 120836, "start": 1219.4399999999998, "end": 1227.9599999999998, "text": " which is just a single vector of 2048. And that vector is on average how much does this", "tokens": [597, 307, 445, 257, 2167, 8062, 295, 945, 13318, 13, 400, 300, 8062, 307, 322, 4274, 577, 709, 775, 341], "temperature": 0.0, "avg_logprob": -0.21112326652772964, "compression_ratio": 1.4640522875816993, "no_speech_prob": 4.860426997765899e-06}, {"id": 181, "seek": 120836, "start": 1227.9599999999998, "end": 1234.6, "text": " whole image have each of those 2048 filters.", "tokens": [1379, 3256, 362, 1184, 295, 729, 945, 13318, 15995, 13], "temperature": 0.0, "avg_logprob": -0.21112326652772964, "compression_ratio": 1.4640522875816993, "no_speech_prob": 4.860426997765899e-06}, {"id": 182, "seek": 123460, "start": 1234.6, "end": 1257.12, "text": " This ResNet actually was originally trained with global average-pulling 2D. This was actually", "tokens": [639, 5015, 31890, 767, 390, 7993, 8895, 365, 4338, 4274, 12, 79, 858, 278, 568, 35, 13, 639, 390, 767], "temperature": 0.0, "avg_logprob": -0.25891070670269906, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.3552414859295823e-05}, {"id": 183, "seek": 123460, "start": 1257.12, "end": 1262.12, "text": " written before the global average-pulling 2D layer existed, so they just did it manually.", "tokens": [3720, 949, 264, 4338, 4274, 12, 79, 858, 278, 568, 35, 4583, 13135, 11, 370, 436, 445, 630, 309, 16945, 13], "temperature": 0.0, "avg_logprob": -0.25891070670269906, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.3552414859295823e-05}, {"id": 184, "seek": 126212, "start": 1262.12, "end": 1269.28, "text": " I'm going to put an average-pulling 7.7 here.", "tokens": [286, 478, 516, 281, 829, 364, 4274, 12, 79, 858, 278, 1614, 13, 22, 510, 13], "temperature": 0.0, "avg_logprob": -0.20008416493733724, "compression_ratio": 1.597938144329897, "no_speech_prob": 3.9669571378908586e-06}, {"id": 185, "seek": 126212, "start": 1269.28, "end": 1278.32, "text": " So because ResNet was trained originally with this layer, that means that it was trained", "tokens": [407, 570, 5015, 31890, 390, 8895, 7993, 365, 341, 4583, 11, 300, 1355, 300, 309, 390, 8895], "temperature": 0.0, "avg_logprob": -0.20008416493733724, "compression_ratio": 1.597938144329897, "no_speech_prob": 3.9669571378908586e-06}, {"id": 186, "seek": 126212, "start": 1278.32, "end": 1284.04, "text": " such that the last identity block was basically creating features that were designed to be", "tokens": [1270, 300, 264, 1036, 6575, 3461, 390, 1936, 4084, 4122, 300, 645, 4761, 281, 312], "temperature": 0.0, "avg_logprob": -0.20008416493733724, "compression_ratio": 1.597938144329897, "no_speech_prob": 3.9669571378908586e-06}, {"id": 187, "seek": 126212, "start": 1284.04, "end": 1291.6, "text": " averaged together. So that means that when we used this tiny little architecture, we", "tokens": [18247, 2980, 1214, 13, 407, 300, 1355, 300, 562, 321, 1143, 341, 5870, 707, 9482, 11, 321], "temperature": 0.0, "avg_logprob": -0.20008416493733724, "compression_ratio": 1.597938144329897, "no_speech_prob": 3.9669571378908586e-06}, {"id": 188, "seek": 129160, "start": 1291.6, "end": 1297.52, "text": " got the best results because that was how ResNet was originally designed to be used.", "tokens": [658, 264, 1151, 3542, 570, 300, 390, 577, 5015, 31890, 390, 7993, 4761, 281, 312, 1143, 13], "temperature": 0.0, "avg_logprob": -0.2576153079668681, "compression_ratio": 1.6857142857142857, "no_speech_prob": 1.6964278984232806e-05}, {"id": 189, "seek": 129160, "start": 1297.52, "end": 1302.04, "text": " Question asked. If you had a wider network without the input fed forward to the output", "tokens": [14464, 2351, 13, 759, 291, 632, 257, 11842, 3209, 1553, 264, 4846, 4636, 2128, 281, 264, 5598], "temperature": 0.0, "avg_logprob": -0.2576153079668681, "compression_ratio": 1.6857142857142857, "no_speech_prob": 1.6964278984232806e-05}, {"id": 190, "seek": 129160, "start": 1302.04, "end": 1307.6, "text": " activation, couldn't you get the same result? The extra activations in the wider network", "tokens": [24433, 11, 2809, 380, 291, 483, 264, 912, 1874, 30, 440, 2857, 2430, 763, 294, 264, 11842, 3209], "temperature": 0.0, "avg_logprob": -0.2576153079668681, "compression_ratio": 1.6857142857142857, "no_speech_prob": 1.6964278984232806e-05}, {"id": 191, "seek": 129160, "start": 1307.6, "end": 1310.28, "text": " could pass the input all the way through all the layers.", "tokens": [727, 1320, 264, 4846, 439, 264, 636, 807, 439, 264, 7914, 13], "temperature": 0.0, "avg_logprob": -0.2576153079668681, "compression_ratio": 1.6857142857142857, "no_speech_prob": 1.6964278984232806e-05}, {"id": 192, "seek": 129160, "start": 1310.28, "end": 1319.0, "text": " Answer the question. Well, you can in theory have convolutional filters that don't do anything,", "tokens": [24545, 264, 1168, 13, 1042, 11, 291, 393, 294, 5261, 362, 45216, 304, 15995, 300, 500, 380, 360, 1340, 11], "temperature": 0.0, "avg_logprob": -0.2576153079668681, "compression_ratio": 1.6857142857142857, "no_speech_prob": 1.6964278984232806e-05}, {"id": 193, "seek": 131900, "start": 1319.0, "end": 1327.96, "text": " as you can act as a multi-entity matrix. But the point is, having to learn that is learning", "tokens": [382, 291, 393, 605, 382, 257, 4825, 12, 317, 507, 8141, 13, 583, 264, 935, 307, 11, 1419, 281, 1466, 300, 307, 2539], "temperature": 0.0, "avg_logprob": -0.29844748973846436, "compression_ratio": 1.5853658536585367, "no_speech_prob": 2.355216201976873e-05}, {"id": 194, "seek": 131900, "start": 1327.96, "end": 1331.32, "text": " lots and lots of filters designed to learn that.", "tokens": [3195, 293, 3195, 295, 15995, 4761, 281, 1466, 300, 13], "temperature": 0.0, "avg_logprob": -0.29844748973846436, "compression_ratio": 1.5853658536585367, "no_speech_prob": 2.355216201976873e-05}, {"id": 195, "seek": 131900, "start": 1331.32, "end": 1338.24, "text": " And so maybe the best way I can describe this is, everything I'm telling you about architectures", "tokens": [400, 370, 1310, 264, 1151, 636, 286, 393, 6786, 341, 307, 11, 1203, 286, 478, 3585, 291, 466, 6331, 1303], "temperature": 0.0, "avg_logprob": -0.29844748973846436, "compression_ratio": 1.5853658536585367, "no_speech_prob": 2.355216201976873e-05}, {"id": 196, "seek": 131900, "start": 1338.24, "end": 1343.96, "text": " is in some ways irrelevant. You could create nothing but dense layers at every level of", "tokens": [307, 294, 512, 2098, 28682, 13, 509, 727, 1884, 1825, 457, 18011, 7914, 412, 633, 1496, 295], "temperature": 0.0, "avg_logprob": -0.29844748973846436, "compression_ratio": 1.5853658536585367, "no_speech_prob": 2.355216201976873e-05}, {"id": 197, "seek": 134396, "start": 1343.96, "end": 1351.72, "text": " your model. And dense layers have every input connected to every output. So every architecture", "tokens": [428, 2316, 13, 400, 18011, 7914, 362, 633, 4846, 4582, 281, 633, 5598, 13, 407, 633, 9482], "temperature": 0.0, "avg_logprob": -0.17445240464321402, "compression_ratio": 1.6214953271028036, "no_speech_prob": 9.665945981396362e-06}, {"id": 198, "seek": 134396, "start": 1351.72, "end": 1356.6000000000001, "text": " I'm telling you about is just a simplified version of that. We're just deleting some", "tokens": [286, 478, 3585, 291, 466, 307, 445, 257, 26335, 3037, 295, 300, 13, 492, 434, 445, 48946, 512], "temperature": 0.0, "avg_logprob": -0.17445240464321402, "compression_ratio": 1.6214953271028036, "no_speech_prob": 9.665945981396362e-06}, {"id": 199, "seek": 134396, "start": 1356.6000000000001, "end": 1367.24, "text": " of those. But it's really helpful to do that. It's really helpful to help our SGD optimizer", "tokens": [295, 729, 13, 583, 309, 311, 534, 4961, 281, 360, 300, 13, 467, 311, 534, 4961, 281, 854, 527, 34520, 35, 5028, 6545], "temperature": 0.0, "avg_logprob": -0.17445240464321402, "compression_ratio": 1.6214953271028036, "no_speech_prob": 9.665945981396362e-06}, {"id": 200, "seek": 134396, "start": 1367.24, "end": 1373.04, "text": " by making it so that the default thing it can do is the thing that we want.", "tokens": [538, 1455, 309, 370, 300, 264, 7576, 551, 309, 393, 360, 307, 264, 551, 300, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.17445240464321402, "compression_ratio": 1.6214953271028036, "no_speech_prob": 9.665945981396362e-06}, {"id": 201, "seek": 137304, "start": 1373.04, "end": 1378.6399999999999, "text": " So yes, in theory, a conv net or a native fully connected net could learn to do the", "tokens": [407, 2086, 11, 294, 5261, 11, 257, 3754, 2533, 420, 257, 8470, 4498, 4582, 2533, 727, 1466, 281, 360, 264], "temperature": 0.0, "avg_logprob": -0.2756860017776489, "compression_ratio": 1.6117021276595744, "no_speech_prob": 9.080309609998949e-06}, {"id": 202, "seek": 137304, "start": 1378.6399999999999, "end": 1384.52, "text": " same thing that resnet does. In practice, it would take a lot of parameters for it to", "tokens": [912, 551, 300, 725, 7129, 775, 13, 682, 3124, 11, 309, 576, 747, 257, 688, 295, 9834, 337, 309, 281], "temperature": 0.0, "avg_logprob": -0.2756860017776489, "compression_ratio": 1.6117021276595744, "no_speech_prob": 9.080309609998949e-06}, {"id": 203, "seek": 137304, "start": 1384.52, "end": 1394.0, "text": " do so and time to do so. So this is why we care about architectures. In practice, having", "tokens": [360, 370, 293, 565, 281, 360, 370, 13, 407, 341, 307, 983, 321, 1127, 466, 6331, 1303, 13, 682, 3124, 11, 1419], "temperature": 0.0, "avg_logprob": -0.2756860017776489, "compression_ratio": 1.6117021276595744, "no_speech_prob": 9.080309609998949e-06}, {"id": 204, "seek": 137304, "start": 1394.0, "end": 1396.92, "text": " a good architecture makes a huge difference.", "tokens": [257, 665, 9482, 1669, 257, 2603, 2649, 13], "temperature": 0.0, "avg_logprob": -0.2756860017776489, "compression_ratio": 1.6117021276595744, "no_speech_prob": 9.080309609998949e-06}, {"id": 205, "seek": 139692, "start": 1396.92, "end": 1407.52, "text": " Question, would it be fair to say that if VGG was trained with average pooling, it would", "tokens": [14464, 11, 576, 309, 312, 3143, 281, 584, 300, 498, 691, 27561, 390, 8895, 365, 4274, 7005, 278, 11, 309, 576], "temperature": 0.0, "avg_logprob": -0.23463048563375102, "compression_ratio": 1.455, "no_speech_prob": 8.139617420965806e-06}, {"id": 206, "seek": 139692, "start": 1407.52, "end": 1409.0, "text": " yield better results?", "tokens": [11257, 1101, 3542, 30], "temperature": 0.0, "avg_logprob": -0.23463048563375102, "compression_ratio": 1.455, "no_speech_prob": 8.139617420965806e-06}, {"id": 207, "seek": 139692, "start": 1409.0, "end": 1418.3200000000002, "text": " Answer that question. I'm not sure. So let's talk about that a little bit. One of the reasons", "tokens": [24545, 300, 1168, 13, 286, 478, 406, 988, 13, 407, 718, 311, 751, 466, 300, 257, 707, 857, 13, 1485, 295, 264, 4112], "temperature": 0.0, "avg_logprob": -0.23463048563375102, "compression_ratio": 1.455, "no_speech_prob": 8.139617420965806e-06}, {"id": 208, "seek": 139692, "start": 1418.3200000000002, "end": 1422.88, "text": " or maybe the main reason that resnet didn't need dropout is because we're using global", "tokens": [420, 1310, 264, 2135, 1778, 300, 725, 7129, 994, 380, 643, 3270, 346, 307, 570, 321, 434, 1228, 4338], "temperature": 0.0, "avg_logprob": -0.23463048563375102, "compression_ratio": 1.455, "no_speech_prob": 8.139617420965806e-06}, {"id": 209, "seek": 142288, "start": 1422.88, "end": 1428.3200000000002, "text": " average pooling. Because we're using global average pooling, there's a hell of a lot less", "tokens": [4274, 7005, 278, 13, 1436, 321, 434, 1228, 4338, 4274, 7005, 278, 11, 456, 311, 257, 4921, 295, 257, 688, 1570], "temperature": 0.0, "avg_logprob": -0.22571631537543402, "compression_ratio": 1.6497695852534562, "no_speech_prob": 1.300701387663139e-05}, {"id": 210, "seek": 142288, "start": 1428.3200000000002, "end": 1433.24, "text": " parameters in this model. Remember, the vast majority of the parameters in the model are", "tokens": [9834, 294, 341, 2316, 13, 5459, 11, 264, 8369, 6286, 295, 264, 9834, 294, 264, 2316, 366], "temperature": 0.0, "avg_logprob": -0.22571631537543402, "compression_ratio": 1.6497695852534562, "no_speech_prob": 1.300701387663139e-05}, {"id": 211, "seek": 142288, "start": 1433.24, "end": 1439.24, "text": " in the dense layers. Because if you've got n inputs and n outputs, you have n times m", "tokens": [294, 264, 18011, 7914, 13, 1436, 498, 291, 600, 658, 297, 15743, 293, 297, 23930, 11, 291, 362, 297, 1413, 275], "temperature": 0.0, "avg_logprob": -0.22571631537543402, "compression_ratio": 1.6497695852534562, "no_speech_prob": 1.300701387663139e-05}, {"id": 212, "seek": 142288, "start": 1439.24, "end": 1444.92, "text": " connections. So in VGG, I can't quite remember, but that first dense layer had something like", "tokens": [9271, 13, 407, 294, 691, 27561, 11, 286, 393, 380, 1596, 1604, 11, 457, 300, 700, 18011, 4583, 632, 746, 411], "temperature": 0.0, "avg_logprob": -0.22571631537543402, "compression_ratio": 1.6497695852534562, "no_speech_prob": 1.300701387663139e-05}, {"id": 213, "seek": 144492, "start": 1444.92, "end": 1453.3200000000002, "text": " 300 million parameters. Because it had every possible feature of the convolutional layer", "tokens": [6641, 2459, 9834, 13, 1436, 309, 632, 633, 1944, 4111, 295, 264, 45216, 304, 4583], "temperature": 0.0, "avg_logprob": -0.2918875159286871, "compression_ratio": 1.6715686274509804, "no_speech_prob": 1.0952989214274567e-05}, {"id": 214, "seek": 144492, "start": 1453.3200000000002, "end": 1458.8400000000001, "text": " by each of the 3 basic limitations of the convolutional layer by every one of the 4,000", "tokens": [538, 1184, 295, 264, 805, 3875, 15705, 295, 264, 45216, 304, 4583, 538, 633, 472, 295, 264, 1017, 11, 1360], "temperature": 0.0, "avg_logprob": -0.2918875159286871, "compression_ratio": 1.6715686274509804, "no_speech_prob": 1.0952989214274567e-05}, {"id": 215, "seek": 144492, "start": 1458.8400000000001, "end": 1464.68, "text": " outputs. So it just created a lot of features and made it very easy to overfit.", "tokens": [23930, 13, 407, 309, 445, 2942, 257, 688, 295, 4122, 293, 1027, 309, 588, 1858, 281, 670, 6845, 13], "temperature": 0.0, "avg_logprob": -0.2918875159286871, "compression_ratio": 1.6715686274509804, "no_speech_prob": 1.0952989214274567e-05}, {"id": 216, "seek": 144492, "start": 1464.68, "end": 1471.3200000000002, "text": " So with global average pooling and indeed not having any dense layers, we have a lot", "tokens": [407, 365, 4338, 4274, 7005, 278, 293, 6451, 406, 1419, 604, 18011, 7914, 11, 321, 362, 257, 688], "temperature": 0.0, "avg_logprob": -0.2918875159286871, "compression_ratio": 1.6715686274509804, "no_speech_prob": 1.0952989214274567e-05}, {"id": 217, "seek": 147132, "start": 1471.32, "end": 1476.8799999999999, "text": " less parameters, so it's going to generalize better. It also generalizes better because", "tokens": [1570, 9834, 11, 370, 309, 311, 516, 281, 2674, 1125, 1101, 13, 467, 611, 2674, 5660, 1101, 570], "temperature": 0.0, "avg_logprob": -0.19461168826205058, "compression_ratio": 1.6754385964912282, "no_speech_prob": 1.3419851711660158e-05}, {"id": 218, "seek": 147132, "start": 1476.8799999999999, "end": 1485.12, "text": " we're treating every one of those 7x7 or 13x13 areas in the same way. We're saying how doggy", "tokens": [321, 434, 15083, 633, 472, 295, 729, 1614, 87, 22, 420, 3705, 87, 7668, 3179, 294, 264, 912, 636, 13, 492, 434, 1566, 577, 3000, 1480], "temperature": 0.0, "avg_logprob": -0.19461168826205058, "compression_ratio": 1.6754385964912282, "no_speech_prob": 1.3419851711660158e-05}, {"id": 219, "seek": 147132, "start": 1485.12, "end": 1493.3999999999999, "text": " or catty are each of these, we're just averaging them. So it turns out that these global average", "tokens": [420, 3857, 874, 366, 1184, 295, 613, 11, 321, 434, 445, 47308, 552, 13, 407, 309, 4523, 484, 300, 613, 4338, 4274], "temperature": 0.0, "avg_logprob": -0.19461168826205058, "compression_ratio": 1.6754385964912282, "no_speech_prob": 1.3419851711660158e-05}, {"id": 220, "seek": 147132, "start": 1493.3999999999999, "end": 1499.1599999999999, "text": " pooling layer models do seem to generalize very well. We're going to be seeing more of", "tokens": [7005, 278, 4583, 5245, 360, 1643, 281, 2674, 1125, 588, 731, 13, 492, 434, 516, 281, 312, 2577, 544, 295], "temperature": 0.0, "avg_logprob": -0.19461168826205058, "compression_ratio": 1.6754385964912282, "no_speech_prob": 1.3419851711660158e-05}, {"id": 221, "seek": 147132, "start": 1499.1599999999999, "end": 1500.1599999999999, "text": " that in a moment.", "tokens": [300, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.19461168826205058, "compression_ratio": 1.6754385964912282, "no_speech_prob": 1.3419851711660158e-05}, {"id": 222, "seek": 150016, "start": 1500.16, "end": 1504.64, "text": " Question-3. How do you use global average pooling instead of max pooling?", "tokens": [14464, 12, 18, 13, 1012, 360, 291, 764, 4338, 4274, 7005, 278, 2602, 295, 11469, 7005, 278, 30], "temperature": 0.0, "avg_logprob": -0.2853408731440062, "compression_ratio": 1.540909090909091, "no_speech_prob": 1.184305983770173e-05}, {"id": 223, "seek": 150016, "start": 1504.64, "end": 1514.0400000000002, "text": " You wouldn't want to max pool over... well, it depends. You can try both. In this case,", "tokens": [509, 2759, 380, 528, 281, 11469, 7005, 670, 1097, 731, 11, 309, 5946, 13, 509, 393, 853, 1293, 13, 682, 341, 1389, 11], "temperature": 0.0, "avg_logprob": -0.2853408731440062, "compression_ratio": 1.540909090909091, "no_speech_prob": 1.184305983770173e-05}, {"id": 224, "seek": 150016, "start": 1514.0400000000002, "end": 1518.4, "text": " the images in the dogs and cats competition is basically an image where nearly the entire", "tokens": [264, 5267, 294, 264, 7197, 293, 11111, 6211, 307, 1936, 364, 3256, 689, 6217, 264, 2302], "temperature": 0.0, "avg_logprob": -0.2853408731440062, "compression_ratio": 1.540909090909091, "no_speech_prob": 1.184305983770173e-05}, {"id": 225, "seek": 150016, "start": 1518.4, "end": 1526.0400000000002, "text": " frame is a dog or a cat. So if you did max pooling, you would say which bit of that 7x7", "tokens": [3920, 307, 257, 3000, 420, 257, 3857, 13, 407, 498, 291, 630, 11469, 7005, 278, 11, 291, 576, 584, 597, 857, 295, 300, 1614, 87, 22], "temperature": 0.0, "avg_logprob": -0.2853408731440062, "compression_ratio": 1.540909090909091, "no_speech_prob": 1.184305983770173e-05}, {"id": 226, "seek": 152604, "start": 1526.04, "end": 1533.08, "text": " or 13x13 grid that we've down sampled down to has the most dogginess or cattiness, and", "tokens": [420, 3705, 87, 7668, 10748, 300, 321, 600, 760, 3247, 15551, 760, 281, 575, 264, 881, 3000, 70, 1324, 420, 269, 1591, 1324, 11, 293], "temperature": 0.0, "avg_logprob": -0.26874419746048955, "compression_ratio": 1.66, "no_speech_prob": 1.9333508589625126e-06}, {"id": 227, "seek": 152604, "start": 1533.08, "end": 1537.56, "text": " I only care about that. That's unlikely to give you the best results, despite us saying", "tokens": [286, 787, 1127, 466, 300, 13, 663, 311, 17518, 281, 976, 291, 264, 1151, 3542, 11, 7228, 505, 1566], "temperature": 0.0, "avg_logprob": -0.26874419746048955, "compression_ratio": 1.66, "no_speech_prob": 1.9333508589625126e-06}, {"id": 228, "seek": 152604, "start": 1537.56, "end": 1541.68, "text": " let's look at every part of the image and have it more together.", "tokens": [718, 311, 574, 412, 633, 644, 295, 264, 3256, 293, 362, 309, 544, 1214, 13], "temperature": 0.0, "avg_logprob": -0.26874419746048955, "compression_ratio": 1.66, "no_speech_prob": 1.9333508589625126e-06}, {"id": 229, "seek": 152604, "start": 1541.68, "end": 1549.28, "text": " On the other hand, I haven't tried this. The fisheries competition. The fish is generally", "tokens": [1282, 264, 661, 1011, 11, 286, 2378, 380, 3031, 341, 13, 440, 20698, 530, 6211, 13, 440, 3506, 307, 5101], "temperature": 0.0, "avg_logprob": -0.26874419746048955, "compression_ratio": 1.66, "no_speech_prob": 1.9333508589625126e-06}, {"id": 230, "seek": 152604, "start": 1549.28, "end": 1554.3999999999999, "text": " a very small part of each image. So maybe in the fisheries competition you should use", "tokens": [257, 588, 1359, 644, 295, 1184, 3256, 13, 407, 1310, 294, 264, 20698, 530, 6211, 291, 820, 764], "temperature": 0.0, "avg_logprob": -0.26874419746048955, "compression_ratio": 1.66, "no_speech_prob": 1.9333508589625126e-06}, {"id": 231, "seek": 155440, "start": 1554.4, "end": 1561.24, "text": " a global max pooling layer. Give it a try and tell us how it goes. Because in that case,", "tokens": [257, 4338, 11469, 7005, 278, 4583, 13, 5303, 309, 257, 853, 293, 980, 505, 577, 309, 1709, 13, 1436, 294, 300, 1389, 11], "temperature": 0.0, "avg_logprob": -0.25029776526279135, "compression_ratio": 1.4074074074074074, "no_speech_prob": 3.966964868595824e-06}, {"id": 232, "seek": 155440, "start": 1561.24, "end": 1570.0400000000002, "text": " you actually don't care about all the parts of the image which have nothing to do with", "tokens": [291, 767, 500, 380, 1127, 466, 439, 264, 3166, 295, 264, 3256, 597, 362, 1825, 281, 360, 365], "temperature": 0.0, "avg_logprob": -0.25029776526279135, "compression_ratio": 1.4074074074074074, "no_speech_prob": 3.966964868595824e-06}, {"id": 233, "seek": 155440, "start": 1570.0400000000002, "end": 1578.2800000000002, "text": " fish. That would be a very interesting thing to try.", "tokens": [3506, 13, 663, 576, 312, 257, 588, 1880, 551, 281, 853, 13], "temperature": 0.0, "avg_logprob": -0.25029776526279135, "compression_ratio": 1.4074074074074074, "no_speech_prob": 3.966964868595824e-06}, {"id": 234, "seek": 157828, "start": 1578.28, "end": 1586.3999999999999, "text": " ResNet is very powerful, but it has not been studied much at all for transfer learning.", "tokens": [5015, 31890, 307, 588, 4005, 11, 457, 309, 575, 406, 668, 9454, 709, 412, 439, 337, 5003, 2539, 13], "temperature": 0.0, "avg_logprob": -0.18487724216505028, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.6700967535143718e-05}, {"id": 235, "seek": 157828, "start": 1586.3999999999999, "end": 1590.84, "text": " This is not to say it won't work well for transfer learning. I just literally haven't", "tokens": [639, 307, 406, 281, 584, 309, 1582, 380, 589, 731, 337, 5003, 2539, 13, 286, 445, 3736, 2378, 380], "temperature": 0.0, "avg_logprob": -0.18487724216505028, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.6700967535143718e-05}, {"id": 236, "seek": 157828, "start": 1590.84, "end": 1597.6399999999999, "text": " found a single paper yet where somebody has analyzed its effectiveness for transfer learning.", "tokens": [1352, 257, 2167, 3035, 1939, 689, 2618, 575, 28181, 1080, 21208, 337, 5003, 2539, 13], "temperature": 0.0, "avg_logprob": -0.18487724216505028, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.6700967535143718e-05}, {"id": 237, "seek": 157828, "start": 1597.6399999999999, "end": 1604.76, "text": " And to me, 99.9999% of what you'll work on will be transfer learning. Because if you're", "tokens": [400, 281, 385, 11, 11803, 13, 8494, 8494, 4, 295, 437, 291, 603, 589, 322, 486, 312, 5003, 2539, 13, 1436, 498, 291, 434], "temperature": 0.0, "avg_logprob": -0.18487724216505028, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.6700967535143718e-05}, {"id": 238, "seek": 160476, "start": 1604.76, "end": 1608.24, "text": " not using transfer learning, it means you're looking at a dataset that is so different", "tokens": [406, 1228, 5003, 2539, 11, 309, 1355, 291, 434, 1237, 412, 257, 28872, 300, 307, 370, 819], "temperature": 0.0, "avg_logprob": -0.2513452230715284, "compression_ratio": 1.6502057613168724, "no_speech_prob": 5.507526566361776e-06}, {"id": 239, "seek": 160476, "start": 1608.24, "end": 1612.48, "text": " to anything that anybody has looked at before that none of the features in any model is", "tokens": [281, 1340, 300, 4472, 575, 2956, 412, 949, 300, 6022, 295, 264, 4122, 294, 604, 2316, 307], "temperature": 0.0, "avg_logprob": -0.2513452230715284, "compression_ratio": 1.6502057613168724, "no_speech_prob": 5.507526566361776e-06}, {"id": 240, "seek": 160476, "start": 1612.48, "end": 1622.28, "text": " remotely helpful for you. That's going to be rare.", "tokens": [20824, 4961, 337, 291, 13, 663, 311, 516, 281, 312, 5892, 13], "temperature": 0.0, "avg_logprob": -0.2513452230715284, "compression_ratio": 1.6502057613168724, "no_speech_prob": 5.507526566361776e-06}, {"id": 241, "seek": 160476, "start": 1622.28, "end": 1627.52, "text": " Nearly all of the work I've seen on transfer learning, both in terms of CABL winners and", "tokens": [38000, 439, 295, 264, 589, 286, 600, 1612, 322, 5003, 2539, 11, 1293, 294, 2115, 295, 383, 13868, 43, 17193, 293], "temperature": 0.0, "avg_logprob": -0.2513452230715284, "compression_ratio": 1.6502057613168724, "no_speech_prob": 5.507526566361776e-06}, {"id": 242, "seek": 160476, "start": 1627.52, "end": 1632.72, "text": " in terms of papers, uses VGG. And I think one of the reasons for that is, as we talked", "tokens": [294, 2115, 295, 10577, 11, 4960, 691, 27561, 13, 400, 286, 519, 472, 295, 264, 4112, 337, 300, 307, 11, 382, 321, 2825], "temperature": 0.0, "avg_logprob": -0.2513452230715284, "compression_ratio": 1.6502057613168724, "no_speech_prob": 5.507526566361776e-06}, {"id": 243, "seek": 163272, "start": 1632.72, "end": 1643.96, "text": " about in lesson 1, the VGG architecture really is designed to create layers of gradually", "tokens": [466, 294, 6898, 502, 11, 264, 691, 27561, 9482, 534, 307, 4761, 281, 1884, 7914, 295, 13145], "temperature": 0.0, "avg_logprob": -0.30592697858810425, "compression_ratio": 1.4202127659574468, "no_speech_prob": 1.2805233382096048e-05}, {"id": 244, "seek": 163272, "start": 1643.96, "end": 1651.0, "text": " increasing semantic complexity. All the work I've seen on visualizing layers tends to use", "tokens": [5662, 47982, 14024, 13, 1057, 264, 589, 286, 600, 1612, 322, 5056, 3319, 7914, 12258, 281, 764], "temperature": 0.0, "avg_logprob": -0.30592697858810425, "compression_ratio": 1.4202127659574468, "no_speech_prob": 1.2805233382096048e-05}, {"id": 245, "seek": 163272, "start": 1651.0, "end": 1655.56, "text": " VGG or something similar to that as well, like that Matt Zylostuff we saw or those Jason", "tokens": [691, 27561, 420, 746, 2531, 281, 300, 382, 731, 11, 411, 300, 7397, 1176, 5088, 555, 1245, 321, 1866, 420, 729, 11181], "temperature": 0.0, "avg_logprob": -0.30592697858810425, "compression_ratio": 1.4202127659574468, "no_speech_prob": 1.2805233382096048e-05}, {"id": 246, "seek": 165556, "start": 1655.56, "end": 1662.56, "text": " Yosinski videos we saw. So we've seen how the VGG network, those kinds of networks,", "tokens": [398, 329, 38984, 2145, 321, 1866, 13, 407, 321, 600, 1612, 577, 264, 691, 27561, 3209, 11, 729, 3685, 295, 9590, 11], "temperature": 0.0, "avg_logprob": -0.2834614063131398, "compression_ratio": 1.5128205128205128, "no_speech_prob": 6.54030600344413e-06}, {"id": 247, "seek": 165556, "start": 1662.56, "end": 1667.6799999999998, "text": " create gradually more complex representations, which is exactly what we want for transfer", "tokens": [1884, 13145, 544, 3997, 33358, 11, 597, 307, 2293, 437, 321, 528, 337, 5003], "temperature": 0.0, "avg_logprob": -0.2834614063131398, "compression_ratio": 1.5128205128205128, "no_speech_prob": 6.54030600344413e-06}, {"id": 248, "seek": 165556, "start": 1667.6799999999998, "end": 1675.48, "text": " learning. Because it lets us say, how different is this new domain to the previous domain,", "tokens": [2539, 13, 1436, 309, 6653, 505, 584, 11, 577, 819, 307, 341, 777, 9274, 281, 264, 3894, 9274, 11], "temperature": 0.0, "avg_logprob": -0.2834614063131398, "compression_ratio": 1.5128205128205128, "no_speech_prob": 6.54030600344413e-06}, {"id": 249, "seek": 165556, "start": 1675.48, "end": 1681.56, "text": " and then we can pick a layer far enough back, we can try a few, that the features seem to", "tokens": [293, 550, 321, 393, 1888, 257, 4583, 1400, 1547, 646, 11, 321, 393, 853, 257, 1326, 11, 300, 264, 4122, 1643, 281], "temperature": 0.0, "avg_logprob": -0.2834614063131398, "compression_ratio": 1.5128205128205128, "no_speech_prob": 6.54030600344413e-06}, {"id": 250, "seek": 168156, "start": 1681.56, "end": 1688.12, "text": " work well. So for that reason we're going to go back to looking at VGG now for the rest", "tokens": [589, 731, 13, 407, 337, 300, 1778, 321, 434, 516, 281, 352, 646, 281, 1237, 412, 691, 27561, 586, 337, 264, 1472], "temperature": 0.0, "avg_logprob": -0.2011996217676111, "compression_ratio": 1.6497175141242937, "no_speech_prob": 1.5446074030478485e-05}, {"id": 251, "seek": 168156, "start": 1688.12, "end": 1689.12, "text": " of these architectures.", "tokens": [295, 613, 6331, 1303, 13], "temperature": 0.0, "avg_logprob": -0.2011996217676111, "compression_ratio": 1.6497175141242937, "no_speech_prob": 1.5446074030478485e-05}, {"id": 252, "seek": 168156, "start": 1689.12, "end": 1697.32, "text": " I'm going to look at the fisheries competition. The fisheries competition is actually very", "tokens": [286, 478, 516, 281, 574, 412, 264, 20698, 530, 6211, 13, 440, 20698, 530, 6211, 307, 767, 588], "temperature": 0.0, "avg_logprob": -0.2011996217676111, "compression_ratio": 1.6497175141242937, "no_speech_prob": 1.5446074030478485e-05}, {"id": 253, "seek": 168156, "start": 1697.32, "end": 1706.96, "text": " interesting. The pictures are from a dozen boats, and each one of these boats has a fixed", "tokens": [1880, 13, 440, 5242, 366, 490, 257, 16654, 17772, 11, 293, 1184, 472, 295, 613, 17772, 575, 257, 6806], "temperature": 0.0, "avg_logprob": -0.2011996217676111, "compression_ratio": 1.6497175141242937, "no_speech_prob": 1.5446074030478485e-05}, {"id": 254, "seek": 170696, "start": 1706.96, "end": 1715.6000000000001, "text": " camera. They can do both daytime and nighttime shots. So every picture has the same basic", "tokens": [2799, 13, 814, 393, 360, 1293, 31908, 293, 38595, 8305, 13, 407, 633, 3036, 575, 264, 912, 3875], "temperature": 0.0, "avg_logprob": -0.22915852724850833, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.0615998689900152e-05}, {"id": 255, "seek": 170696, "start": 1715.6000000000001, "end": 1720.52, "text": " shape and structure for each of the 12 boats, because it's a fixed camera. And then somewhere", "tokens": [3909, 293, 3877, 337, 1184, 295, 264, 2272, 17772, 11, 570, 309, 311, 257, 6806, 2799, 13, 400, 550, 4079], "temperature": 0.0, "avg_logprob": -0.22915852724850833, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.0615998689900152e-05}, {"id": 256, "seek": 170696, "start": 1720.52, "end": 1725.4, "text": " in there, most of the time, there's one or more fish. And your job is to say what kind", "tokens": [294, 456, 11, 881, 295, 264, 565, 11, 456, 311, 472, 420, 544, 3506, 13, 400, 428, 1691, 307, 281, 584, 437, 733], "temperature": 0.0, "avg_logprob": -0.22915852724850833, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.0615998689900152e-05}, {"id": 257, "seek": 170696, "start": 1725.4, "end": 1732.68, "text": " of fish is it. The fish are pretty small. So one of the things that makes this interesting", "tokens": [295, 3506, 307, 309, 13, 440, 3506, 366, 1238, 1359, 13, 407, 472, 295, 264, 721, 300, 1669, 341, 1880], "temperature": 0.0, "avg_logprob": -0.22915852724850833, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.0615998689900152e-05}, {"id": 258, "seek": 173268, "start": 1732.68, "end": 1742.72, "text": " is that this is the kind of somewhat weird, kind of complex, different thing to ImageNet,", "tokens": [307, 300, 341, 307, 264, 733, 295, 8344, 3657, 11, 733, 295, 3997, 11, 819, 551, 281, 29903, 31890, 11], "temperature": 0.0, "avg_logprob": -0.19795320745100053, "compression_ratio": 1.7606177606177607, "no_speech_prob": 2.2473706849268638e-05}, {"id": 259, "seek": 173268, "start": 1742.72, "end": 1746.0, "text": " which is exactly the kind of stuff you're going to have to deal with any time you're", "tokens": [597, 307, 2293, 264, 733, 295, 1507, 291, 434, 516, 281, 362, 281, 2028, 365, 604, 565, 291, 434], "temperature": 0.0, "avg_logprob": -0.19795320745100053, "compression_ratio": 1.7606177606177607, "no_speech_prob": 2.2473706849268638e-05}, {"id": 260, "seek": 173268, "start": 1746.0, "end": 1750.88, "text": " doing some kind of computer vision problem or any kind of CNN problem. It's very likely", "tokens": [884, 512, 733, 295, 3820, 5201, 1154, 420, 604, 733, 295, 24859, 1154, 13, 467, 311, 588, 3700], "temperature": 0.0, "avg_logprob": -0.19795320745100053, "compression_ratio": 1.7606177606177607, "no_speech_prob": 2.2473706849268638e-05}, {"id": 261, "seek": 173268, "start": 1750.88, "end": 1754.48, "text": " that the thing you're doing won't be quite the same as what all the academics have been", "tokens": [300, 264, 551, 291, 434, 884, 1582, 380, 312, 1596, 264, 912, 382, 437, 439, 264, 25695, 362, 668], "temperature": 0.0, "avg_logprob": -0.19795320745100053, "compression_ratio": 1.7606177606177607, "no_speech_prob": 2.2473706849268638e-05}, {"id": 262, "seek": 173268, "start": 1754.48, "end": 1755.48, "text": " looking at.", "tokens": [1237, 412, 13], "temperature": 0.0, "avg_logprob": -0.19795320745100053, "compression_ratio": 1.7606177606177607, "no_speech_prob": 2.2473706849268638e-05}, {"id": 263, "seek": 173268, "start": 1755.48, "end": 1761.4, "text": " So trying to figure out how to do a good job of the fisheries competition is a great example.", "tokens": [407, 1382, 281, 2573, 484, 577, 281, 360, 257, 665, 1691, 295, 264, 20698, 530, 6211, 307, 257, 869, 1365, 13], "temperature": 0.0, "avg_logprob": -0.19795320745100053, "compression_ratio": 1.7606177606177607, "no_speech_prob": 2.2473706849268638e-05}, {"id": 264, "seek": 176140, "start": 1761.4, "end": 1766.6000000000001, "text": " When I started on the fisheries competition, I just did the usual thing, which was to create", "tokens": [1133, 286, 1409, 322, 264, 20698, 530, 6211, 11, 286, 445, 630, 264, 7713, 551, 11, 597, 390, 281, 1884], "temperature": 0.0, "avg_logprob": -0.2205544090270996, "compression_ratio": 1.568888888888889, "no_speech_prob": 8.939542567532044e-06}, {"id": 265, "seek": 176140, "start": 1766.6000000000001, "end": 1772.2800000000002, "text": " a VGG16 model, fine-tuned it to have just 8 outputs, because we have to say which of", "tokens": [257, 691, 27561, 6866, 2316, 11, 2489, 12, 83, 43703, 309, 281, 362, 445, 1649, 23930, 11, 570, 321, 362, 281, 584, 597, 295], "temperature": 0.0, "avg_logprob": -0.2205544090270996, "compression_ratio": 1.568888888888889, "no_speech_prob": 8.939542567532044e-06}, {"id": 266, "seek": 176140, "start": 1772.2800000000002, "end": 1781.76, "text": " 8 types of fish do we see in it. And then I, as per usual, pre-computed the convolutional", "tokens": [1649, 3467, 295, 3506, 360, 321, 536, 294, 309, 13, 400, 550, 286, 11, 382, 680, 7713, 11, 659, 12, 1112, 2582, 292, 264, 45216, 304], "temperature": 0.0, "avg_logprob": -0.2205544090270996, "compression_ratio": 1.568888888888889, "no_speech_prob": 8.939542567532044e-06}, {"id": 267, "seek": 176140, "start": 1781.76, "end": 1786.76, "text": " layers using the pre-chained VGG network. And then everything after that, I just used", "tokens": [7914, 1228, 264, 659, 12, 339, 3563, 691, 27561, 3209, 13, 400, 550, 1203, 934, 300, 11, 286, 445, 1143], "temperature": 0.0, "avg_logprob": -0.2205544090270996, "compression_ratio": 1.568888888888889, "no_speech_prob": 8.939542567532044e-06}, {"id": 268, "seek": 178676, "start": 1786.76, "end": 1791.44, "text": " those pre-computed convolutional layers. And as per usual, the first thing I did was to", "tokens": [729, 659, 12, 1112, 2582, 292, 45216, 304, 7914, 13, 400, 382, 680, 7713, 11, 264, 700, 551, 286, 630, 390, 281], "temperature": 0.0, "avg_logprob": -0.1399388653891427, "compression_ratio": 1.6761133603238867, "no_speech_prob": 3.393128054085537e-06}, {"id": 269, "seek": 178676, "start": 1791.44, "end": 1796.68, "text": " stick a few dense layers on top and see how that goes.", "tokens": [2897, 257, 1326, 18011, 7914, 322, 1192, 293, 536, 577, 300, 1709, 13], "temperature": 0.0, "avg_logprob": -0.1399388653891427, "compression_ratio": 1.6761133603238867, "no_speech_prob": 3.393128054085537e-06}, {"id": 270, "seek": 178676, "start": 1796.68, "end": 1802.4, "text": " So the nice thing about this is you can see each epoch takes less than a second to run.", "tokens": [407, 264, 1481, 551, 466, 341, 307, 291, 393, 536, 1184, 30992, 339, 2516, 1570, 813, 257, 1150, 281, 1190, 13], "temperature": 0.0, "avg_logprob": -0.1399388653891427, "compression_ratio": 1.6761133603238867, "no_speech_prob": 3.393128054085537e-06}, {"id": 271, "seek": 178676, "start": 1802.4, "end": 1808.16, "text": " So when people talk about needing lots of data or lots of time, it's not really true", "tokens": [407, 562, 561, 751, 466, 18006, 3195, 295, 1412, 420, 3195, 295, 565, 11, 309, 311, 406, 534, 2074], "temperature": 0.0, "avg_logprob": -0.1399388653891427, "compression_ratio": 1.6761133603238867, "no_speech_prob": 3.393128054085537e-06}, {"id": 272, "seek": 178676, "start": 1808.16, "end": 1812.32, "text": " because for most stuff you do in real life, you're only using pre-computed convolutional", "tokens": [570, 337, 881, 1507, 291, 360, 294, 957, 993, 11, 291, 434, 787, 1228, 659, 12, 1112, 2582, 292, 45216, 304], "temperature": 0.0, "avg_logprob": -0.1399388653891427, "compression_ratio": 1.6761133603238867, "no_speech_prob": 3.393128054085537e-06}, {"id": 273, "seek": 178676, "start": 1812.32, "end": 1813.32, "text": " features.", "tokens": [4122, 13], "temperature": 0.0, "avg_logprob": -0.1399388653891427, "compression_ratio": 1.6761133603238867, "no_speech_prob": 3.393128054085537e-06}, {"id": 274, "seek": 181332, "start": 1813.32, "end": 1822.0, "text": " And in our validation set, we get an accuracy of 96.2%, approximately loss of 0.8%. That's", "tokens": [400, 294, 527, 24071, 992, 11, 321, 483, 364, 14170, 295, 24124, 13, 17, 8923, 10447, 4470, 295, 1958, 13, 23, 6856, 663, 311], "temperature": 0.0, "avg_logprob": -0.19643876211983816, "compression_ratio": 1.3692307692307693, "no_speech_prob": 2.1112193280714564e-05}, {"id": 275, "seek": 181332, "start": 1822.0, "end": 1829.72, "text": " pretty good. We seem to be recognizing the fish pretty well. But here's the problem.", "tokens": [1238, 665, 13, 492, 1643, 281, 312, 18538, 264, 3506, 1238, 731, 13, 583, 510, 311, 264, 1154, 13], "temperature": 0.0, "avg_logprob": -0.19643876211983816, "compression_ratio": 1.3692307692307693, "no_speech_prob": 2.1112193280714564e-05}, {"id": 276, "seek": 181332, "start": 1829.72, "end": 1839.1599999999999, "text": " There is all kinds of data leakage going on. And this is one of the most important concepts", "tokens": [821, 307, 439, 3685, 295, 1412, 47799, 516, 322, 13, 400, 341, 307, 472, 295, 264, 881, 1021, 10392], "temperature": 0.0, "avg_logprob": -0.19643876211983816, "compression_ratio": 1.3692307692307693, "no_speech_prob": 2.1112193280714564e-05}, {"id": 277, "seek": 183916, "start": 1839.16, "end": 1847.0600000000002, "text": " to understand when it comes to building any kind of model or any kind of machine learning", "tokens": [281, 1223, 562, 309, 1487, 281, 2390, 604, 733, 295, 2316, 420, 604, 733, 295, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.2270644920459692, "compression_ratio": 1.5260416666666667, "no_speech_prob": 1.5446110410266556e-05}, {"id": 278, "seek": 183916, "start": 1847.0600000000002, "end": 1849.72, "text": " project leakage.", "tokens": [1716, 47799, 13], "temperature": 0.0, "avg_logprob": -0.2270644920459692, "compression_ratio": 1.5260416666666667, "no_speech_prob": 1.5446110410266556e-05}, {"id": 279, "seek": 183916, "start": 1849.72, "end": 1857.4, "text": " There was a paper, I think it actually won the KDD Best Paper award a couple of years", "tokens": [821, 390, 257, 3035, 11, 286, 519, 309, 767, 1582, 264, 591, 20818, 9752, 24990, 7130, 257, 1916, 295, 924], "temperature": 0.0, "avg_logprob": -0.2270644920459692, "compression_ratio": 1.5260416666666667, "no_speech_prob": 1.5446110410266556e-05}, {"id": 280, "seek": 183916, "start": 1857.4, "end": 1865.52, "text": " ago from Claudia Perlich and some of her colleagues, which studied data leakage. Data leakage occurs", "tokens": [2057, 490, 36785, 3026, 1739, 293, 512, 295, 720, 7734, 11, 597, 9454, 1412, 47799, 13, 11888, 47799, 11843], "temperature": 0.0, "avg_logprob": -0.2270644920459692, "compression_ratio": 1.5260416666666667, "no_speech_prob": 1.5446110410266556e-05}, {"id": 281, "seek": 186552, "start": 1865.52, "end": 1873.0, "text": " when something about the target you're trying to predict is encoded in the things that you're", "tokens": [562, 746, 466, 264, 3779, 291, 434, 1382, 281, 6069, 307, 2058, 12340, 294, 264, 721, 300, 291, 434], "temperature": 0.0, "avg_logprob": -0.14803744585086137, "compression_ratio": 1.6717171717171717, "no_speech_prob": 1.2029492609144654e-05}, {"id": 282, "seek": 186552, "start": 1873.0, "end": 1879.16, "text": " predicting with, but that information is either not going to be available or it won't be helpful", "tokens": [32884, 365, 11, 457, 300, 1589, 307, 2139, 406, 516, 281, 312, 2435, 420, 309, 1582, 380, 312, 4961], "temperature": 0.0, "avg_logprob": -0.14803744585086137, "compression_ratio": 1.6717171717171717, "no_speech_prob": 1.2029492609144654e-05}, {"id": 283, "seek": 186552, "start": 1879.16, "end": 1882.76, "text": " in practice when you're going to use the model.", "tokens": [294, 3124, 562, 291, 434, 516, 281, 764, 264, 2316, 13], "temperature": 0.0, "avg_logprob": -0.14803744585086137, "compression_ratio": 1.6717171717171717, "no_speech_prob": 1.2029492609144654e-05}, {"id": 284, "seek": 186552, "start": 1882.76, "end": 1890.8, "text": " For example, in a fisheries competition, different boats fish in different parts of the sea.", "tokens": [1171, 1365, 11, 294, 257, 20698, 530, 6211, 11, 819, 17772, 3506, 294, 819, 3166, 295, 264, 4158, 13], "temperature": 0.0, "avg_logprob": -0.14803744585086137, "compression_ratio": 1.6717171717171717, "no_speech_prob": 1.2029492609144654e-05}, {"id": 285, "seek": 189080, "start": 1890.8, "end": 1896.8799999999999, "text": " Different parts of the sea have different fish in them. And so in the fisheries competition,", "tokens": [20825, 3166, 295, 264, 4158, 362, 819, 3506, 294, 552, 13, 400, 370, 294, 264, 20698, 530, 6211, 11], "temperature": 0.0, "avg_logprob": -0.2590316050761455, "compression_ratio": 1.5198019801980198, "no_speech_prob": 2.6016004994744435e-06}, {"id": 286, "seek": 189080, "start": 1896.8799999999999, "end": 1904.24, "text": " if you just use something representing which boat the image came from, you can get a pretty", "tokens": [498, 291, 445, 764, 746, 13460, 597, 6582, 264, 3256, 1361, 490, 11, 291, 393, 483, 257, 1238], "temperature": 0.0, "avg_logprob": -0.2590316050761455, "compression_ratio": 1.5198019801980198, "no_speech_prob": 2.6016004994744435e-06}, {"id": 287, "seek": 189080, "start": 1904.24, "end": 1909.04, "text": " good accurate validation set result.", "tokens": [665, 8559, 24071, 992, 1874, 13], "temperature": 0.0, "avg_logprob": -0.2590316050761455, "compression_ratio": 1.5198019801980198, "no_speech_prob": 2.6016004994744435e-06}, {"id": 288, "seek": 189080, "start": 1909.04, "end": 1916.68, "text": " What I mean by that, for example, is here's something which is very tricky. This is a", "tokens": [708, 286, 914, 538, 300, 11, 337, 1365, 11, 307, 510, 311, 746, 597, 307, 588, 12414, 13, 639, 307, 257], "temperature": 0.0, "avg_logprob": -0.2590316050761455, "compression_ratio": 1.5198019801980198, "no_speech_prob": 2.6016004994744435e-06}, {"id": 289, "seek": 191668, "start": 1916.68, "end": 1924.8400000000001, "text": " list of the size of each photo along with how many times that appears. You can see it", "tokens": [1329, 295, 264, 2744, 295, 1184, 5052, 2051, 365, 577, 867, 1413, 300, 7038, 13, 509, 393, 536, 309], "temperature": 0.0, "avg_logprob": -0.25088746207101004, "compression_ratio": 1.5682819383259912, "no_speech_prob": 5.594259619101649e-06}, {"id": 290, "seek": 191668, "start": 1924.8400000000001, "end": 1930.68, "text": " has gone through every photo and opened it using PIL, which is the Python Imaging Library,", "tokens": [575, 2780, 807, 633, 5052, 293, 5625, 309, 1228, 430, 4620, 11, 597, 307, 264, 15329, 4331, 3568, 12806, 11], "temperature": 0.0, "avg_logprob": -0.25088746207101004, "compression_ratio": 1.5682819383259912, "no_speech_prob": 5.594259619101649e-06}, {"id": 291, "seek": 191668, "start": 1930.68, "end": 1936.6000000000001, "text": " and graded size. You can see that there's basically a small number of sizes that appear.", "tokens": [293, 2771, 292, 2744, 13, 509, 393, 536, 300, 456, 311, 1936, 257, 1359, 1230, 295, 11602, 300, 4204, 13], "temperature": 0.0, "avg_logprob": -0.25088746207101004, "compression_ratio": 1.5682819383259912, "no_speech_prob": 5.594259619101649e-06}, {"id": 292, "seek": 191668, "start": 1936.6000000000001, "end": 1946.4, "text": " It turns out that if you create a simple linear model that says any image of size 1192x670", "tokens": [467, 4523, 484, 300, 498, 291, 1884, 257, 2199, 8213, 2316, 300, 1619, 604, 3256, 295, 2744, 2975, 21821, 87, 21, 5867], "temperature": 0.0, "avg_logprob": -0.25088746207101004, "compression_ratio": 1.5682819383259912, "no_speech_prob": 5.594259619101649e-06}, {"id": 293, "seek": 194640, "start": 1946.4, "end": 1956.0400000000002, "text": " or anything with 1280x720, you get a pretty accurate model. Because these are the different", "tokens": [420, 1340, 365, 2272, 4702, 87, 22, 2009, 11, 291, 483, 257, 1238, 8559, 2316, 13, 1436, 613, 366, 264, 819], "temperature": 0.0, "avg_logprob": -0.23243070784069242, "compression_ratio": 1.6053811659192825, "no_speech_prob": 4.222807092446601e-06}, {"id": 294, "seek": 194640, "start": 1956.0400000000002, "end": 1962.52, "text": " ships. The different ships have different cameras. And this isn't helpful in practice", "tokens": [11434, 13, 440, 819, 11434, 362, 819, 8622, 13, 400, 341, 1943, 380, 4961, 294, 3124], "temperature": 0.0, "avg_logprob": -0.23243070784069242, "compression_ratio": 1.6053811659192825, "no_speech_prob": 4.222807092446601e-06}, {"id": 295, "seek": 194640, "start": 1962.52, "end": 1966.92, "text": " because what the fisheries people actually wanted to do was to use this to find out when", "tokens": [570, 437, 264, 20698, 530, 561, 767, 1415, 281, 360, 390, 281, 764, 341, 281, 915, 484, 562], "temperature": 0.0, "avg_logprob": -0.23243070784069242, "compression_ratio": 1.6053811659192825, "no_speech_prob": 4.222807092446601e-06}, {"id": 296, "seek": 194640, "start": 1966.92, "end": 1974.5600000000002, "text": " people are illegally or accidentally overfishing or fishing in the wrong way. So if they're", "tokens": [561, 366, 39585, 420, 15715, 670, 69, 3807, 420, 10180, 294, 264, 2085, 636, 13, 407, 498, 436, 434], "temperature": 0.0, "avg_logprob": -0.23243070784069242, "compression_ratio": 1.6053811659192825, "no_speech_prob": 4.222807092446601e-06}, {"id": 297, "seek": 197456, "start": 1974.56, "end": 1980.76, "text": " bringing up dolphins or something, they want to know about it. So any model that says I", "tokens": [5062, 493, 44835, 420, 746, 11, 436, 528, 281, 458, 466, 309, 13, 407, 604, 2316, 300, 1619, 286], "temperature": 0.0, "avg_logprob": -0.17372099161148072, "compression_ratio": 1.5688073394495412, "no_speech_prob": 4.092889412277145e-06}, {"id": 298, "seek": 197456, "start": 1980.76, "end": 1985.32, "text": " know what kind of fish this is because I know what the boat is, is entirely useless.", "tokens": [458, 437, 733, 295, 3506, 341, 307, 570, 286, 458, 437, 264, 6582, 307, 11, 307, 7696, 14115, 13], "temperature": 0.0, "avg_logprob": -0.17372099161148072, "compression_ratio": 1.5688073394495412, "no_speech_prob": 4.092889412277145e-06}, {"id": 299, "seek": 197456, "start": 1985.32, "end": 1995.2, "text": " So this is an example of leakage. In this particular paper I mentioned, the authors", "tokens": [407, 341, 307, 364, 1365, 295, 47799, 13, 682, 341, 1729, 3035, 286, 2835, 11, 264, 16552], "temperature": 0.0, "avg_logprob": -0.17372099161148072, "compression_ratio": 1.5688073394495412, "no_speech_prob": 4.092889412277145e-06}, {"id": 300, "seek": 197456, "start": 1995.2, "end": 2000.3999999999999, "text": " looked at machine learning competitions and discovered that over 50% of them had some", "tokens": [2956, 412, 3479, 2539, 26185, 293, 6941, 300, 670, 2625, 4, 295, 552, 632, 512], "temperature": 0.0, "avg_logprob": -0.17372099161148072, "compression_ratio": 1.5688073394495412, "no_speech_prob": 4.092889412277145e-06}, {"id": 301, "seek": 200040, "start": 2000.4, "end": 2008.6000000000001, "text": " kind of data leakage. I spoke to Claudia after she presented that paper and I asked her if", "tokens": [733, 295, 1412, 47799, 13, 286, 7179, 281, 36785, 934, 750, 8212, 300, 3035, 293, 286, 2351, 720, 498], "temperature": 0.0, "avg_logprob": -0.2131167325106534, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.9222339687985368e-05}, {"id": 302, "seek": 200040, "start": 2008.6000000000001, "end": 2013.76, "text": " she thought that regular machine learning projects in inside companies would have more", "tokens": [750, 1194, 300, 3890, 3479, 2539, 4455, 294, 1854, 3431, 576, 362, 544], "temperature": 0.0, "avg_logprob": -0.2131167325106534, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.9222339687985368e-05}, {"id": 303, "seek": 200040, "start": 2013.76, "end": 2023.8000000000002, "text": " or less leakage than that, and she said a lot more. Because in competitions, people", "tokens": [420, 1570, 47799, 813, 300, 11, 293, 750, 848, 257, 688, 544, 13, 1436, 294, 26185, 11, 561], "temperature": 0.0, "avg_logprob": -0.2131167325106534, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.9222339687985368e-05}, {"id": 304, "seek": 200040, "start": 2023.8000000000002, "end": 2026.96, "text": " have tried really hard to clean up the data ahead of time because they know that lots", "tokens": [362, 3031, 534, 1152, 281, 2541, 493, 264, 1412, 2286, 295, 565, 570, 436, 458, 300, 3195], "temperature": 0.0, "avg_logprob": -0.2131167325106534, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.9222339687985368e-05}, {"id": 305, "seek": 202696, "start": 2026.96, "end": 2030.6000000000001, "text": " and lots of people are going to be looking at it. And if there is leakage, you're almost", "tokens": [293, 3195, 295, 561, 366, 516, 281, 312, 1237, 412, 309, 13, 400, 498, 456, 307, 47799, 11, 291, 434, 1920], "temperature": 0.0, "avg_logprob": -0.19206655675714665, "compression_ratio": 1.7110266159695817, "no_speech_prob": 1.4738771824340802e-05}, {"id": 306, "seek": 202696, "start": 2030.6000000000001, "end": 2035.28, "text": " certain that somebody's going to find it because it's a competition. Whereas if you have leakage", "tokens": [1629, 300, 2618, 311, 516, 281, 915, 309, 570, 309, 311, 257, 6211, 13, 13813, 498, 291, 362, 47799], "temperature": 0.0, "avg_logprob": -0.19206655675714665, "compression_ratio": 1.7110266159695817, "no_speech_prob": 1.4738771824340802e-05}, {"id": 307, "seek": 202696, "start": 2035.28, "end": 2040.52, "text": " in your dataset, it's very likely you won't even know about it until you try to put the", "tokens": [294, 428, 28872, 11, 309, 311, 588, 3700, 291, 1582, 380, 754, 458, 466, 309, 1826, 291, 853, 281, 829, 264], "temperature": 0.0, "avg_logprob": -0.19206655675714665, "compression_ratio": 1.7110266159695817, "no_speech_prob": 1.4738771824340802e-05}, {"id": 308, "seek": 202696, "start": 2040.52, "end": 2045.48, "text": " model into production and discover that it doesn't work as well as you thought it would.", "tokens": [2316, 666, 4265, 293, 4411, 300, 309, 1177, 380, 589, 382, 731, 382, 291, 1194, 309, 576, 13], "temperature": 0.0, "avg_logprob": -0.19206655675714665, "compression_ratio": 1.7110266159695817, "no_speech_prob": 1.4738771824340802e-05}, {"id": 309, "seek": 202696, "start": 2045.48, "end": 2051.8, "text": " I was just going to add that it might not even help you in the competition if your test", "tokens": [286, 390, 445, 516, 281, 909, 300, 309, 1062, 406, 754, 854, 291, 294, 264, 6211, 498, 428, 1500], "temperature": 0.0, "avg_logprob": -0.19206655675714665, "compression_ratio": 1.7110266159695817, "no_speech_prob": 1.4738771824340802e-05}, {"id": 310, "seek": 205180, "start": 2051.8, "end": 2059.0, "text": " set is brand new boats that weren't in your training set.", "tokens": [992, 307, 3360, 777, 17772, 300, 4999, 380, 294, 428, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.3056468055361793, "compression_ratio": 1.535031847133758, "no_speech_prob": 1.6964135284069926e-05}, {"id": 311, "seek": 205180, "start": 2059.0, "end": 2071.04, "text": " So trying to win a Kaggle competition and trying to do a good job are somewhat independent.", "tokens": [407, 1382, 281, 1942, 257, 48751, 22631, 6211, 293, 1382, 281, 360, 257, 665, 1691, 366, 8344, 6695, 13], "temperature": 0.0, "avg_logprob": -0.3056468055361793, "compression_ratio": 1.535031847133758, "no_speech_prob": 1.6964135284069926e-05}, {"id": 312, "seek": 205180, "start": 2071.04, "end": 2077.0, "text": " When I'm working on Kaggle, I focus on trying to win the Kaggle competition. I have a clear", "tokens": [1133, 286, 478, 1364, 322, 48751, 22631, 11, 286, 1879, 322, 1382, 281, 1942, 264, 48751, 22631, 6211, 13, 286, 362, 257, 1850], "temperature": 0.0, "avg_logprob": -0.3056468055361793, "compression_ratio": 1.535031847133758, "no_speech_prob": 1.6964135284069926e-05}, {"id": 313, "seek": 207700, "start": 2077.0, "end": 2081.84, "text": " metric and I try to optimize the metric. And sometimes that means finding leakage and taking", "tokens": [20678, 293, 286, 853, 281, 19719, 264, 20678, 13, 400, 2171, 300, 1355, 5006, 47799, 293, 1940], "temperature": 0.0, "avg_logprob": -0.20703783605852696, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.08032052393537e-06}, {"id": 314, "seek": 207700, "start": 2081.84, "end": 2082.84, "text": " advantage of it.", "tokens": [5002, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.20703783605852696, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.08032052393537e-06}, {"id": 315, "seek": 207700, "start": 2082.84, "end": 2088.64, "text": " So in this case, step number 1 for me in the fisheries competition was to say, can I take", "tokens": [407, 294, 341, 1389, 11, 1823, 1230, 502, 337, 385, 294, 264, 20698, 530, 6211, 390, 281, 584, 11, 393, 286, 747], "temperature": 0.0, "avg_logprob": -0.20703783605852696, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.08032052393537e-06}, {"id": 316, "seek": 207700, "start": 2088.64, "end": 2093.88, "text": " advantage of this leakage? I want to be very clear. This is the exact opposite of what", "tokens": [5002, 295, 341, 47799, 30, 286, 528, 281, 312, 588, 1850, 13, 639, 307, 264, 1900, 6182, 295, 437], "temperature": 0.0, "avg_logprob": -0.20703783605852696, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.08032052393537e-06}, {"id": 317, "seek": 207700, "start": 2093.88, "end": 2097.12, "text": " you would want to do if you were actually trying to help the fisheries people create", "tokens": [291, 576, 528, 281, 360, 498, 291, 645, 767, 1382, 281, 854, 264, 20698, 530, 561, 1884], "temperature": 0.0, "avg_logprob": -0.20703783605852696, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.08032052393537e-06}, {"id": 318, "seek": 207700, "start": 2097.12, "end": 2102.76, "text": " a good model. Having said that, there's $150,000 at stake and I could donate that to the Fred", "tokens": [257, 665, 2316, 13, 10222, 848, 300, 11, 456, 311, 1848, 20120, 11, 1360, 412, 10407, 293, 286, 727, 17751, 300, 281, 264, 10112], "temperature": 0.0, "avg_logprob": -0.20703783605852696, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.08032052393537e-06}, {"id": 319, "seek": 210276, "start": 2102.76, "end": 2107.6000000000004, "text": " Pollard Foundation and get lots of people their site back. So winning this would be", "tokens": [31304, 515, 10335, 293, 483, 3195, 295, 561, 641, 3621, 646, 13, 407, 8224, 341, 576, 312], "temperature": 0.0, "avg_logprob": -0.3210484640938895, "compression_ratio": 1.5020408163265306, "no_speech_prob": 8.01329588284716e-06}, {"id": 320, "seek": 210276, "start": 2107.6000000000004, "end": 2108.6000000000004, "text": " good.", "tokens": [665, 13], "temperature": 0.0, "avg_logprob": -0.3210484640938895, "compression_ratio": 1.5020408163265306, "no_speech_prob": 8.01329588284716e-06}, {"id": 321, "seek": 210276, "start": 2108.6000000000004, "end": 2113.7200000000003, "text": " So let me show you how I try to take advantage of this leakage, which is totally legal in", "tokens": [407, 718, 385, 855, 291, 577, 286, 853, 281, 747, 5002, 295, 341, 47799, 11, 597, 307, 3879, 5089, 294], "temperature": 0.0, "avg_logprob": -0.3210484640938895, "compression_ratio": 1.5020408163265306, "no_speech_prob": 8.01329588284716e-06}, {"id": 322, "seek": 210276, "start": 2113.7200000000003, "end": 2121.2400000000002, "text": " a Kaggle competition, and see what happens. And then I'll talk more about Rachel's issue", "tokens": [257, 48751, 22631, 6211, 11, 293, 536, 437, 2314, 13, 400, 550, 286, 603, 751, 544, 466, 14246, 311, 2734], "temperature": 0.0, "avg_logprob": -0.3210484640938895, "compression_ratio": 1.5020408163265306, "no_speech_prob": 8.01329588284716e-06}, {"id": 323, "seek": 210276, "start": 2121.2400000000002, "end": 2122.2400000000002, "text": " after that.", "tokens": [934, 300, 13], "temperature": 0.0, "avg_logprob": -0.3210484640938895, "compression_ratio": 1.5020408163265306, "no_speech_prob": 8.01329588284716e-06}, {"id": 324, "seek": 210276, "start": 2122.2400000000002, "end": 2128.1200000000003, "text": " So the first thing I did was I made a list for every file of how big the NNP dimensions", "tokens": [407, 264, 700, 551, 286, 630, 390, 286, 1027, 257, 1329, 337, 633, 3991, 295, 577, 955, 264, 426, 45, 47, 12819], "temperature": 0.0, "avg_logprob": -0.3210484640938895, "compression_ratio": 1.5020408163265306, "no_speech_prob": 8.01329588284716e-06}, {"id": 325, "seek": 212812, "start": 2128.12, "end": 2134.3199999999997, "text": " were. And I did that for the validation of the training set. I normalized them by subtracting", "tokens": [645, 13, 400, 286, 630, 300, 337, 264, 24071, 295, 264, 3097, 992, 13, 286, 48704, 552, 538, 16390, 278], "temperature": 0.0, "avg_logprob": -0.2370413338265768, "compression_ratio": 1.6398104265402844, "no_speech_prob": 1.8924809410236776e-05}, {"id": 326, "seek": 212812, "start": 2134.3199999999997, "end": 2140.8399999999997, "text": " the mean and dividing them by standard deviation. And then I created an almost exact copy of", "tokens": [264, 914, 293, 26764, 552, 538, 3832, 25163, 13, 400, 550, 286, 2942, 364, 1920, 1900, 5055, 295], "temperature": 0.0, "avg_logprob": -0.2370413338265768, "compression_ratio": 1.6398104265402844, "no_speech_prob": 1.8924809410236776e-05}, {"id": 327, "seek": 212812, "start": 2140.8399999999997, "end": 2147.8399999999997, "text": " the previous model I showed you. But this time, rather than using the sequential API,", "tokens": [264, 3894, 2316, 286, 4712, 291, 13, 583, 341, 565, 11, 2831, 813, 1228, 264, 42881, 9362, 11], "temperature": 0.0, "avg_logprob": -0.2370413338265768, "compression_ratio": 1.6398104265402844, "no_speech_prob": 1.8924809410236776e-05}, {"id": 328, "seek": 212812, "start": 2147.8399999999997, "end": 2152.6, "text": " I used the functional API. But other than that, this is almost identical.", "tokens": [286, 1143, 264, 11745, 9362, 13, 583, 661, 813, 300, 11, 341, 307, 1920, 14800, 13], "temperature": 0.0, "avg_logprob": -0.2370413338265768, "compression_ratio": 1.6398104265402844, "no_speech_prob": 1.8924809410236776e-05}, {"id": 329, "seek": 215260, "start": 2152.6, "end": 2162.96, "text": " The only difference is in this line, where what I've done is I've taken not just the", "tokens": [440, 787, 2649, 307, 294, 341, 1622, 11, 689, 437, 286, 600, 1096, 307, 286, 600, 2726, 406, 445, 264], "temperature": 0.0, "avg_logprob": -0.2069224236716687, "compression_ratio": 1.5549132947976878, "no_speech_prob": 6.7480059442459606e-06}, {"id": 330, "seek": 215260, "start": 2162.96, "end": 2169.56, "text": " input which is the output of the last convolutional layer of my VGG model, but I have a second", "tokens": [4846, 597, 307, 264, 5598, 295, 264, 1036, 45216, 304, 4583, 295, 452, 691, 27561, 2316, 11, 457, 286, 362, 257, 1150], "temperature": 0.0, "avg_logprob": -0.2069224236716687, "compression_ratio": 1.5549132947976878, "no_speech_prob": 6.7480059442459606e-06}, {"id": 331, "seek": 215260, "start": 2169.56, "end": 2181.52, "text": " input. And the second input is what size image is it. And I should mention I have one hot", "tokens": [4846, 13, 400, 264, 1150, 4846, 307, 437, 2744, 3256, 307, 309, 13, 400, 286, 820, 2152, 286, 362, 472, 2368], "temperature": 0.0, "avg_logprob": -0.2069224236716687, "compression_ratio": 1.5549132947976878, "no_speech_prob": 6.7480059442459606e-06}, {"id": 332, "seek": 218152, "start": 2181.52, "end": 2187.68, "text": " encoded those image sizes so they're treated as categories.", "tokens": [2058, 12340, 729, 3256, 11602, 370, 436, 434, 8668, 382, 10479, 13], "temperature": 0.0, "avg_logprob": -0.20185417964540678, "compression_ratio": 1.5849056603773586, "no_speech_prob": 1.2411423085723072e-05}, {"id": 333, "seek": 218152, "start": 2187.68, "end": 2193.16, "text": " So I now have an additional input. So I have two inputs. One is the output of the VGG convolutional", "tokens": [407, 286, 586, 362, 364, 4497, 4846, 13, 407, 286, 362, 732, 15743, 13, 1485, 307, 264, 5598, 295, 264, 691, 27561, 45216, 304], "temperature": 0.0, "avg_logprob": -0.20185417964540678, "compression_ratio": 1.5849056603773586, "no_speech_prob": 1.2411423085723072e-05}, {"id": 334, "seek": 218152, "start": 2193.16, "end": 2200.68, "text": " layer, one is the one hot encoded image size. I batch normalized that, obviously. And then", "tokens": [4583, 11, 472, 307, 264, 472, 2368, 2058, 12340, 3256, 2744, 13, 286, 15245, 48704, 300, 11, 2745, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.20185417964540678, "compression_ratio": 1.5849056603773586, "no_speech_prob": 1.2411423085723072e-05}, {"id": 335, "seek": 218152, "start": 2200.68, "end": 2207.96, "text": " right at the very last step, I concatenate the two together. So my model is basically", "tokens": [558, 412, 264, 588, 1036, 1823, 11, 286, 1588, 7186, 473, 264, 732, 1214, 13, 407, 452, 2316, 307, 1936], "temperature": 0.0, "avg_logprob": -0.20185417964540678, "compression_ratio": 1.5849056603773586, "no_speech_prob": 1.2411423085723072e-05}, {"id": 336, "seek": 220796, "start": 2207.96, "end": 2223.12, "text": " a standard last few layers of VGG model, so 3 dense layers. And then I have my input,", "tokens": [257, 3832, 1036, 1326, 7914, 295, 691, 27561, 2316, 11, 370, 805, 18011, 7914, 13, 400, 550, 286, 362, 452, 4846, 11], "temperature": 0.0, "avg_logprob": -0.32777321555397726, "compression_ratio": 1.455223880597015, "no_speech_prob": 5.507582500285935e-06}, {"id": 337, "seek": 220796, "start": 2223.12, "end": 2230.56, "text": " and then I have another input. And it's not being signed for being concatenated. And that", "tokens": [293, 550, 286, 362, 1071, 4846, 13, 400, 309, 311, 406, 885, 8175, 337, 885, 1588, 7186, 770, 13, 400, 300], "temperature": 0.0, "avg_logprob": -0.32777321555397726, "compression_ratio": 1.455223880597015, "no_speech_prob": 5.507582500285935e-06}, {"id": 338, "seek": 220796, "start": 2230.56, "end": 2233.96, "text": " creates the output.", "tokens": [7829, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.32777321555397726, "compression_ratio": 1.455223880597015, "no_speech_prob": 5.507582500285935e-06}, {"id": 339, "seek": 223396, "start": 2233.96, "end": 2241.68, "text": " So what this can do now is that that last dense layer can now learn to combine the image", "tokens": [407, 437, 341, 393, 360, 586, 307, 300, 300, 1036, 18011, 4583, 393, 586, 1466, 281, 10432, 264, 3256], "temperature": 0.0, "avg_logprob": -0.23271337369593179, "compression_ratio": 1.584070796460177, "no_speech_prob": 3.8830206904094666e-05}, {"id": 340, "seek": 223396, "start": 2241.68, "end": 2248.64, "text": " features along with this metadata. This is useful for all kinds of things other than", "tokens": [4122, 2051, 365, 341, 26603, 13, 639, 307, 4420, 337, 439, 3685, 295, 721, 661, 813], "temperature": 0.0, "avg_logprob": -0.23271337369593179, "compression_ratio": 1.584070796460177, "no_speech_prob": 3.8830206904094666e-05}, {"id": 341, "seek": 223396, "start": 2248.64, "end": 2254.44, "text": " taking advantage in a vastly way of leakage. For example, if you were doing a collaborative", "tokens": [1940, 5002, 294, 257, 41426, 636, 295, 47799, 13, 1171, 1365, 11, 498, 291, 645, 884, 257, 16555], "temperature": 0.0, "avg_logprob": -0.23271337369593179, "compression_ratio": 1.584070796460177, "no_speech_prob": 3.8830206904094666e-05}, {"id": 342, "seek": 223396, "start": 2254.44, "end": 2263.16, "text": " filtering model, you might have information about the user, such as their age, their gender,", "tokens": [30822, 2316, 11, 291, 1062, 362, 1589, 466, 264, 4195, 11, 1270, 382, 641, 3205, 11, 641, 7898, 11], "temperature": 0.0, "avg_logprob": -0.23271337369593179, "compression_ratio": 1.584070796460177, "no_speech_prob": 3.8830206904094666e-05}, {"id": 343, "seek": 226316, "start": 2263.16, "end": 2269.56, "text": " their favorite genres, they asked to be mentioned on a survey. This is how you incorporate that", "tokens": [641, 2954, 30057, 11, 436, 2351, 281, 312, 2835, 322, 257, 8984, 13, 639, 307, 577, 291, 16091, 300], "temperature": 0.0, "avg_logprob": -0.32120826027610083, "compression_ratio": 1.4125, "no_speech_prob": 4.35686115451972e-06}, {"id": 344, "seek": 226316, "start": 2269.56, "end": 2275.8799999999997, "text": " kind of metadata into a standard neural net.", "tokens": [733, 295, 26603, 666, 257, 3832, 18161, 2533, 13], "temperature": 0.0, "avg_logprob": -0.32120826027610083, "compression_ratio": 1.4125, "no_speech_prob": 4.35686115451972e-06}, {"id": 345, "seek": 226316, "start": 2275.8799999999997, "end": 2282.12, "text": " So I batch the two together and run it. And initially it's looking encouraging. If we", "tokens": [407, 286, 15245, 264, 732, 1214, 293, 1190, 309, 13, 400, 9105, 309, 311, 1237, 14580, 13, 759, 321], "temperature": 0.0, "avg_logprob": -0.32120826027610083, "compression_ratio": 1.4125, "no_speech_prob": 4.35686115451972e-06}, {"id": 346, "seek": 228212, "start": 2282.12, "end": 2293.96, "text": " go back and look at the standard model, we have.84,.94,.95. This multi-input model", "tokens": [352, 646, 293, 574, 412, 264, 3832, 2316, 11, 321, 362, 2411, 25494, 11, 2411, 27032, 11, 2411, 15718, 13, 639, 4825, 12, 259, 2582, 2316], "temperature": 0.0, "avg_logprob": -0.16302575383867537, "compression_ratio": 1.2388059701492538, "no_speech_prob": 7.5279617703927215e-06}, {"id": 347, "seek": 228212, "start": 2293.96, "end": 2304.08, "text": " is a little better,.86,.95,.96. So that's encouraging. But interestingly, the model", "tokens": [307, 257, 707, 1101, 11, 2411, 22193, 11, 2411, 15718, 11, 2411, 22962, 13, 407, 300, 311, 14580, 13, 583, 25873, 11, 264, 2316], "temperature": 0.0, "avg_logprob": -0.16302575383867537, "compression_ratio": 1.2388059701492538, "no_speech_prob": 7.5279617703927215e-06}, {"id": 348, "seek": 230408, "start": 2304.08, "end": 2313.3199999999997, "text": " without using the leakage gets somewhere around 96.5, 97.5, maybe even 98. It's kind of all", "tokens": [1553, 1228, 264, 47799, 2170, 4079, 926, 24124, 13, 20, 11, 23399, 13, 20, 11, 1310, 754, 20860, 13, 467, 311, 733, 295, 439], "temperature": 0.0, "avg_logprob": -0.15554743927794618, "compression_ratio": 1.4444444444444444, "no_speech_prob": 1.2805369806301314e-05}, {"id": 349, "seek": 230408, "start": 2313.3199999999997, "end": 2320.7599999999998, "text": " over the place, which isn't a great sign. But let's say somewhere around 97, 97.5.", "tokens": [670, 264, 1081, 11, 597, 1943, 380, 257, 869, 1465, 13, 583, 718, 311, 584, 4079, 926, 23399, 11, 23399, 13, 20, 13], "temperature": 0.0, "avg_logprob": -0.15554743927794618, "compression_ratio": 1.4444444444444444, "no_speech_prob": 1.2805369806301314e-05}, {"id": 350, "seek": 230408, "start": 2320.7599999999998, "end": 2327.6, "text": " This multi-input model, on the other hand, does not get better than that. Its best is", "tokens": [639, 4825, 12, 259, 2582, 2316, 11, 322, 264, 661, 1011, 11, 775, 406, 483, 1101, 813, 300, 13, 6953, 1151, 307], "temperature": 0.0, "avg_logprob": -0.15554743927794618, "compression_ratio": 1.4444444444444444, "no_speech_prob": 1.2805369806301314e-05}, {"id": 351, "seek": 232760, "start": 2327.6, "end": 2336.56, "text": " also around 97.5. Why is that? This is very, very common when people try to utilize metadata", "tokens": [611, 926, 23399, 13, 20, 13, 1545, 307, 300, 30, 639, 307, 588, 11, 588, 2689, 562, 561, 853, 281, 16117, 26603], "temperature": 0.0, "avg_logprob": -0.22607328995414402, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.9944192192488117e-06}, {"id": 352, "seek": 232760, "start": 2336.56, "end": 2341.8399999999997, "text": " in deep learning models. It often turns out that the main thing you're looking at, in", "tokens": [294, 2452, 2539, 5245, 13, 467, 2049, 4523, 484, 300, 264, 2135, 551, 291, 434, 1237, 412, 11, 294], "temperature": 0.0, "avg_logprob": -0.22607328995414402, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.9944192192488117e-06}, {"id": 353, "seek": 232760, "start": 2341.8399999999997, "end": 2347.8399999999997, "text": " this case the image, already encodes everything that your metadata has anyway. In this case,", "tokens": [341, 1389, 264, 3256, 11, 1217, 2058, 4789, 1203, 300, 428, 26603, 575, 4033, 13, 682, 341, 1389, 11], "temperature": 0.0, "avg_logprob": -0.22607328995414402, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.9944192192488117e-06}, {"id": 354, "seek": 232760, "start": 2347.8399999999997, "end": 2351.56, "text": " the size of the image tells us what Bodo comes from, but you can also just look at the picture", "tokens": [264, 2744, 295, 264, 3256, 5112, 505, 437, 363, 17423, 1487, 490, 11, 457, 291, 393, 611, 445, 574, 412, 264, 3036], "temperature": 0.0, "avg_logprob": -0.22607328995414402, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.9944192192488117e-06}, {"id": 355, "seek": 232760, "start": 2351.56, "end": 2356.36, "text": " and see what Bodo comes from. So by the later epochs, the convolutional model has learned", "tokens": [293, 536, 437, 363, 17423, 1487, 490, 13, 407, 538, 264, 1780, 30992, 28346, 11, 264, 45216, 304, 2316, 575, 3264], "temperature": 0.0, "avg_logprob": -0.22607328995414402, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.9944192192488117e-06}, {"id": 356, "seek": 235636, "start": 2356.36, "end": 2361.1200000000003, "text": " already to figure out what Bodo comes from. So the leakage actually turned out not to", "tokens": [1217, 281, 2573, 484, 437, 363, 17423, 1487, 490, 13, 407, 264, 47799, 767, 3574, 484, 406, 281], "temperature": 0.0, "avg_logprob": -0.26881863730294364, "compression_ratio": 1.5135135135135136, "no_speech_prob": 8.013370461412705e-06}, {"id": 357, "seek": 235636, "start": 2361.1200000000003, "end": 2362.8, "text": " be helpful anyway.", "tokens": [312, 4961, 4033, 13], "temperature": 0.0, "avg_logprob": -0.26881863730294364, "compression_ratio": 1.5135135135135136, "no_speech_prob": 8.013370461412705e-06}, {"id": 358, "seek": 235636, "start": 2362.8, "end": 2372.0, "text": " So it's amazing how often people assume they need to find metadata and incorporate it into", "tokens": [407, 309, 311, 2243, 577, 2049, 561, 6552, 436, 643, 281, 915, 26603, 293, 16091, 309, 666], "temperature": 0.0, "avg_logprob": -0.26881863730294364, "compression_ratio": 1.5135135135135136, "no_speech_prob": 8.013370461412705e-06}, {"id": 359, "seek": 235636, "start": 2372.0, "end": 2377.84, "text": " their model, and how often it turns out to be a waste of time. Because the raw, real", "tokens": [641, 2316, 11, 293, 577, 2049, 309, 4523, 484, 281, 312, 257, 5964, 295, 565, 13, 1436, 264, 8936, 11, 957], "temperature": 0.0, "avg_logprob": -0.26881863730294364, "compression_ratio": 1.5135135135135136, "no_speech_prob": 8.013370461412705e-06}, {"id": 360, "seek": 237784, "start": 2377.84, "end": 2390.48, "text": " data, whether it be audio, pictures, language, turns out to encode all of that.", "tokens": [1412, 11, 1968, 309, 312, 6278, 11, 5242, 11, 2856, 11, 4523, 484, 281, 2058, 1429, 439, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.2816578149795532, "compression_ratio": 1.4245810055865922, "no_speech_prob": 5.1738356887653936e-06}, {"id": 361, "seek": 237784, "start": 2390.48, "end": 2394.52, "text": " Finally I wanted to go back to what Rachel was talking about, which is what would have", "tokens": [6288, 286, 1415, 281, 352, 646, 281, 437, 14246, 390, 1417, 466, 11, 597, 307, 437, 576, 362], "temperature": 0.0, "avg_logprob": -0.2816578149795532, "compression_ratio": 1.4245810055865922, "no_speech_prob": 5.1738356887653936e-06}, {"id": 362, "seek": 237784, "start": 2394.52, "end": 2400.44, "text": " happened if this did work. Let's say that actually this gave us a much better validation", "tokens": [2011, 498, 341, 630, 589, 13, 961, 311, 584, 300, 767, 341, 2729, 505, 257, 709, 1101, 24071], "temperature": 0.0, "avg_logprob": -0.2816578149795532, "compression_ratio": 1.4245810055865922, "no_speech_prob": 5.1738356887653936e-06}, {"id": 363, "seek": 240044, "start": 2400.44, "end": 2407.8, "text": " result than the non-leakage model. If I then submitted it to Kaggle and my leaderboard", "tokens": [1874, 813, 264, 2107, 12, 306, 514, 609, 2316, 13, 759, 286, 550, 14405, 309, 281, 48751, 22631, 293, 452, 5263, 3787], "temperature": 0.0, "avg_logprob": -0.20719871066865467, "compression_ratio": 1.7524752475247525, "no_speech_prob": 1.7231412130058743e-05}, {"id": 364, "seek": 240044, "start": 2407.8, "end": 2414.04, "text": " result was great, that would tell me that I have found leakage, that the Kaggle competition", "tokens": [1874, 390, 869, 11, 300, 576, 980, 385, 300, 286, 362, 1352, 47799, 11, 300, 264, 48751, 22631, 6211], "temperature": 0.0, "avg_logprob": -0.20719871066865467, "compression_ratio": 1.7524752475247525, "no_speech_prob": 1.7231412130058743e-05}, {"id": 365, "seek": 240044, "start": 2414.04, "end": 2419.36, "text": " administrators didn't, and I'm possibly on the way to winning competition. Having said", "tokens": [27754, 994, 380, 11, 293, 286, 478, 6264, 322, 264, 636, 281, 8224, 6211, 13, 10222, 848], "temperature": 0.0, "avg_logprob": -0.20719871066865467, "compression_ratio": 1.7524752475247525, "no_speech_prob": 1.7231412130058743e-05}, {"id": 366, "seek": 240044, "start": 2419.36, "end": 2426.44, "text": " that, the Kaggle competition administrators first and foremost try to avoid leakage. And", "tokens": [300, 11, 264, 48751, 22631, 6211, 27754, 700, 293, 18864, 853, 281, 5042, 47799, 13, 400], "temperature": 0.0, "avg_logprob": -0.20719871066865467, "compression_ratio": 1.7524752475247525, "no_speech_prob": 1.7231412130058743e-05}, {"id": 367, "seek": 242644, "start": 2426.44, "end": 2431.7200000000003, "text": " indeed if you do try and submit this to the leaderboard, you'll find it doesn't do that", "tokens": [6451, 498, 291, 360, 853, 293, 10315, 341, 281, 264, 5263, 3787, 11, 291, 603, 915, 309, 1177, 380, 360, 300], "temperature": 0.0, "avg_logprob": -0.27472942897251673, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.4510308574244846e-05}, {"id": 368, "seek": 242644, "start": 2431.7200000000003, "end": 2437.92, "text": " great. And I haven't really looked into it yet, but somehow the competition administrators", "tokens": [869, 13, 400, 286, 2378, 380, 534, 2956, 666, 309, 1939, 11, 457, 6063, 264, 6211, 27754], "temperature": 0.0, "avg_logprob": -0.27472942897251673, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.4510308574244846e-05}, {"id": 369, "seek": 242644, "start": 2437.92, "end": 2441.88, "text": " have seen to have made some attempt to remove the leakage.", "tokens": [362, 1612, 281, 362, 1027, 512, 5217, 281, 4159, 264, 47799, 13], "temperature": 0.0, "avg_logprob": -0.27472942897251673, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.4510308574244846e-05}, {"id": 370, "seek": 242644, "start": 2441.88, "end": 2446.28, "text": " The kind of ways that we did that when I was at Kaggle would be to do things like some", "tokens": [440, 733, 295, 2098, 300, 321, 630, 300, 562, 286, 390, 412, 48751, 22631, 576, 312, 281, 360, 721, 411, 512], "temperature": 0.0, "avg_logprob": -0.27472942897251673, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.4510308574244846e-05}, {"id": 371, "seek": 242644, "start": 2446.28, "end": 2451.56, "text": " kind of stratified sampling, where we'd say, oh there's way more apocore from this ship", "tokens": [733, 295, 23674, 2587, 21179, 11, 689, 321, 1116, 584, 11, 1954, 456, 311, 636, 544, 1882, 905, 418, 490, 341, 5374], "temperature": 0.0, "avg_logprob": -0.27472942897251673, "compression_ratio": 1.6414342629482073, "no_speech_prob": 1.4510308574244846e-05}, {"id": 372, "seek": 245156, "start": 2451.56, "end": 2457.16, "text": " than this ship. Let's enforce that every ship has to have the same number of the same kind", "tokens": [813, 341, 5374, 13, 961, 311, 24825, 300, 633, 5374, 575, 281, 362, 264, 912, 1230, 295, 264, 912, 733], "temperature": 0.0, "avg_logprob": -0.2789009475708008, "compression_ratio": 1.6546184738955823, "no_speech_prob": 1.1125383934995625e-05}, {"id": 373, "seek": 245156, "start": 2457.16, "end": 2462.96, "text": " of fish, or something like that where we try to limit leakage.", "tokens": [295, 3506, 11, 420, 746, 411, 300, 689, 321, 853, 281, 4948, 47799, 13], "temperature": 0.0, "avg_logprob": -0.2789009475708008, "compression_ratio": 1.6546184738955823, "no_speech_prob": 1.1125383934995625e-05}, {"id": 374, "seek": 245156, "start": 2462.96, "end": 2470.4, "text": " But honestly, it's a very difficult thing to do. And this impacts a lot more than just", "tokens": [583, 6095, 11, 309, 311, 257, 588, 2252, 551, 281, 360, 13, 400, 341, 11606, 257, 688, 544, 813, 445], "temperature": 0.0, "avg_logprob": -0.2789009475708008, "compression_ratio": 1.6546184738955823, "no_speech_prob": 1.1125383934995625e-05}, {"id": 375, "seek": 245156, "start": 2470.4, "end": 2474.52, "text": " machine learning competitions. Every one of your real-world projects, you're going to", "tokens": [3479, 2539, 26185, 13, 2048, 472, 295, 428, 957, 12, 13217, 4455, 11, 291, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.2789009475708008, "compression_ratio": 1.6546184738955823, "no_speech_prob": 1.1125383934995625e-05}, {"id": 376, "seek": 245156, "start": 2474.52, "end": 2479.7999999999997, "text": " have to think long and hard about how can you replicate real-world conditions in your", "tokens": [362, 281, 519, 938, 293, 1152, 466, 577, 393, 291, 25356, 957, 12, 13217, 4487, 294, 428], "temperature": 0.0, "avg_logprob": -0.2789009475708008, "compression_ratio": 1.6546184738955823, "no_speech_prob": 1.1125383934995625e-05}, {"id": 377, "seek": 247980, "start": 2479.8, "end": 2486.5600000000004, "text": " real-world test set. Maybe the best example I can come up with is, when you put your model", "tokens": [957, 12, 13217, 1500, 992, 13, 2704, 264, 1151, 1365, 286, 393, 808, 493, 365, 307, 11, 562, 291, 829, 428, 2316], "temperature": 0.0, "avg_logprob": -0.29365279788062687, "compression_ratio": 1.6846153846153846, "no_speech_prob": 1.0289249075867701e-05}, {"id": 378, "seek": 247980, "start": 2486.5600000000004, "end": 2491.0, "text": " into production, it will probably be a few months after you grabbed the data and trained", "tokens": [666, 4265, 11, 309, 486, 1391, 312, 257, 1326, 2493, 934, 291, 18607, 264, 1412, 293, 8895], "temperature": 0.0, "avg_logprob": -0.29365279788062687, "compression_ratio": 1.6846153846153846, "no_speech_prob": 1.0289249075867701e-05}, {"id": 379, "seek": 247980, "start": 2491.0, "end": 2497.88, "text": " it, how much has the world changed? And so therefore, wouldn't it be great if instead", "tokens": [309, 11, 577, 709, 575, 264, 1002, 3105, 30, 400, 370, 4412, 11, 2759, 380, 309, 312, 869, 498, 2602], "temperature": 0.0, "avg_logprob": -0.29365279788062687, "compression_ratio": 1.6846153846153846, "no_speech_prob": 1.0289249075867701e-05}, {"id": 380, "seek": 247980, "start": 2497.88, "end": 2503.0800000000004, "text": " you could create a test set that had data from a few months later than your training", "tokens": [291, 727, 1884, 257, 1500, 992, 300, 632, 1412, 490, 257, 1326, 2493, 1780, 813, 428, 3097], "temperature": 0.0, "avg_logprob": -0.29365279788062687, "compression_ratio": 1.6846153846153846, "no_speech_prob": 1.0289249075867701e-05}, {"id": 381, "seek": 247980, "start": 2503.0800000000004, "end": 2509.1200000000003, "text": " set. And then you can really try to replicate the situation that you actually have when", "tokens": [992, 13, 400, 550, 291, 393, 534, 853, 281, 25356, 264, 2590, 300, 291, 767, 362, 562], "temperature": 0.0, "avg_logprob": -0.29365279788062687, "compression_ratio": 1.6846153846153846, "no_speech_prob": 1.0289249075867701e-05}, {"id": 382, "seek": 250912, "start": 2509.12, "end": 2512.7999999999997, "text": " you put your model into production.", "tokens": [291, 829, 428, 2316, 666, 4265, 13], "temperature": 0.0, "avg_logprob": -0.1939223977022393, "compression_ratio": 1.5588235294117647, "no_speech_prob": 9.818149919738062e-06}, {"id": 383, "seek": 250912, "start": 2512.7999999999997, "end": 2521.16, "text": " One is just a note that they're releasing another test set later on in the fishery competition.", "tokens": [1485, 307, 445, 257, 3637, 300, 436, 434, 16327, 1071, 1500, 992, 1780, 322, 294, 264, 20698, 88, 6211, 13], "temperature": 0.0, "avg_logprob": -0.1939223977022393, "compression_ratio": 1.5588235294117647, "no_speech_prob": 9.818149919738062e-06}, {"id": 384, "seek": 250912, "start": 2521.16, "end": 2526.52, "text": " Did you do two classifications, one for the boats and one for the fish? Is that a waste", "tokens": [2589, 291, 360, 732, 1508, 7833, 11, 472, 337, 264, 17772, 293, 472, 337, 264, 3506, 30, 1119, 300, 257, 5964], "temperature": 0.0, "avg_logprob": -0.1939223977022393, "compression_ratio": 1.5588235294117647, "no_speech_prob": 9.818149919738062e-06}, {"id": 385, "seek": 250912, "start": 2526.52, "end": 2527.52, "text": " of time?", "tokens": [295, 565, 30], "temperature": 0.0, "avg_logprob": -0.1939223977022393, "compression_ratio": 1.5588235294117647, "no_speech_prob": 9.818149919738062e-06}, {"id": 386, "seek": 250912, "start": 2527.52, "end": 2538.08, "text": " I have two inputs, not two outputs. So my input is the one hot encoded size of the image,", "tokens": [286, 362, 732, 15743, 11, 406, 732, 23930, 13, 407, 452, 4846, 307, 264, 472, 2368, 2058, 12340, 2744, 295, 264, 3256, 11], "temperature": 0.0, "avg_logprob": -0.1939223977022393, "compression_ratio": 1.5588235294117647, "no_speech_prob": 9.818149919738062e-06}, {"id": 387, "seek": 253808, "start": 2538.08, "end": 2546.24, "text": " which I assumed is a proxy for the boat ID. And some discussion on the Kaggle forum suggested", "tokens": [597, 286, 15895, 307, 257, 29690, 337, 264, 6582, 7348, 13, 400, 512, 5017, 322, 264, 48751, 22631, 17542, 10945], "temperature": 0.0, "avg_logprob": -0.29970241629559063, "compression_ratio": 1.2794117647058822, "no_speech_prob": 7.484293018933386e-05}, {"id": 388, "seek": 253808, "start": 2546.24, "end": 2554.44, "text": " that's a reasonable assumption. We're going to look at multi-output in a moment.", "tokens": [300, 311, 257, 10585, 15302, 13, 492, 434, 516, 281, 574, 412, 4825, 12, 346, 2582, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.29970241629559063, "compression_ratio": 1.2794117647058822, "no_speech_prob": 7.484293018933386e-05}, {"id": 389, "seek": 255444, "start": 2554.44, "end": 2580.36, "text": " In fact, we're going to do it now.", "tokens": [682, 1186, 11, 321, 434, 516, 281, 360, 309, 586, 13], "temperature": 0.0, "avg_logprob": -0.4732469240824381, "compression_ratio": 0.8095238095238095, "no_speech_prob": 6.601169297937304e-05}, {"id": 390, "seek": 258036, "start": 2580.36, "end": 2588.84, "text": " Multi-output, there's a lot of nice things about how Kaggle competitions are structured.", "tokens": [29238, 12, 346, 2582, 11, 456, 311, 257, 688, 295, 1481, 721, 466, 577, 48751, 22631, 26185, 366, 18519, 13], "temperature": 0.0, "avg_logprob": -0.22091052748940207, "compression_ratio": 1.59375, "no_speech_prob": 8.801001968095079e-06}, {"id": 391, "seek": 258036, "start": 2588.84, "end": 2595.32, "text": " One of the things I really like is that in most of them, you can create your finds, your", "tokens": [1485, 295, 264, 721, 286, 534, 411, 307, 300, 294, 881, 295, 552, 11, 291, 393, 1884, 428, 10704, 11, 428], "temperature": 0.0, "avg_logprob": -0.22091052748940207, "compression_ratio": 1.59375, "no_speech_prob": 8.801001968095079e-06}, {"id": 392, "seek": 258036, "start": 2595.32, "end": 2600.1600000000003, "text": " own data sources, as long as you share them with the community. And so one of the people", "tokens": [1065, 1412, 7139, 11, 382, 938, 382, 291, 2073, 552, 365, 264, 1768, 13, 400, 370, 472, 295, 264, 561], "temperature": 0.0, "avg_logprob": -0.22091052748940207, "compression_ratio": 1.59375, "no_speech_prob": 8.801001968095079e-06}, {"id": 393, "seek": 258036, "start": 2600.1600000000003, "end": 2605.96, "text": " in the fisheries competition has gone through and by hand put a little square around every", "tokens": [294, 264, 20698, 530, 6211, 575, 2780, 807, 293, 538, 1011, 829, 257, 707, 3732, 926, 633], "temperature": 0.0, "avg_logprob": -0.22091052748940207, "compression_ratio": 1.59375, "no_speech_prob": 8.801001968095079e-06}, {"id": 394, "seek": 260596, "start": 2605.96, "end": 2614.04, "text": " fish, which is called annotating the data set. Specifically, this kind of annotation", "tokens": [3506, 11, 597, 307, 1219, 25339, 990, 264, 1412, 992, 13, 26058, 11, 341, 733, 295, 48654], "temperature": 0.0, "avg_logprob": -0.24562301216544685, "compression_ratio": 1.646788990825688, "no_speech_prob": 2.046236659225542e-05}, {"id": 395, "seek": 260596, "start": 2614.04, "end": 2621.36, "text": " is called a bounding box. A bounding box is a box in which your object fully fits. Because", "tokens": [307, 1219, 257, 5472, 278, 2424, 13, 316, 5472, 278, 2424, 307, 257, 2424, 294, 597, 428, 2657, 4498, 9001, 13, 1436], "temperature": 0.0, "avg_logprob": -0.24562301216544685, "compression_ratio": 1.646788990825688, "no_speech_prob": 2.046236659225542e-05}, {"id": 396, "seek": 260596, "start": 2621.36, "end": 2624.84, "text": " of the rules of Kaggle, he had to make that available to everybody in the Kaggle community,", "tokens": [295, 264, 4474, 295, 48751, 22631, 11, 415, 632, 281, 652, 300, 2435, 281, 2201, 294, 264, 48751, 22631, 1768, 11], "temperature": 0.0, "avg_logprob": -0.24562301216544685, "compression_ratio": 1.646788990825688, "no_speech_prob": 2.046236659225542e-05}, {"id": 397, "seek": 260596, "start": 2624.84, "end": 2630.4, "text": " which he provided a link on the Kaggle forum. So I went ahead and downloaded those. They're", "tokens": [597, 415, 5649, 257, 2113, 322, 264, 48751, 22631, 17542, 13, 407, 286, 1437, 2286, 293, 21748, 729, 13, 814, 434], "temperature": 0.0, "avg_logprob": -0.24562301216544685, "compression_ratio": 1.646788990825688, "no_speech_prob": 2.046236659225542e-05}, {"id": 398, "seek": 263040, "start": 2630.4, "end": 2637.48, "text": " a bunch of JSON files that basically look like this. For each fish in that image, it", "tokens": [257, 3840, 295, 31828, 7098, 300, 1936, 574, 411, 341, 13, 1171, 1184, 3506, 294, 300, 3256, 11, 309], "temperature": 0.0, "avg_logprob": -0.2696377277374268, "compression_ratio": 1.517766497461929, "no_speech_prob": 9.223191227647476e-06}, {"id": 399, "seek": 263040, "start": 2637.48, "end": 2640.88, "text": " had the height, width, next, and y.", "tokens": [632, 264, 6681, 11, 11402, 11, 958, 11, 293, 288, 13], "temperature": 0.0, "avg_logprob": -0.2696377277374268, "compression_ratio": 1.517766497461929, "no_speech_prob": 9.223191227647476e-06}, {"id": 400, "seek": 263040, "start": 2640.88, "end": 2645.6800000000003, "text": " So the details of the code don't matter too much, but I basically just went ahead and", "tokens": [407, 264, 4365, 295, 264, 3089, 500, 380, 1871, 886, 709, 11, 457, 286, 1936, 445, 1437, 2286, 293], "temperature": 0.0, "avg_logprob": -0.2696377277374268, "compression_ratio": 1.517766497461929, "no_speech_prob": 9.223191227647476e-06}, {"id": 401, "seek": 263040, "start": 2645.6800000000003, "end": 2654.96, "text": " found the largest fish in each image and created a list of them. So I've got now my training", "tokens": [1352, 264, 6443, 3506, 294, 1184, 3256, 293, 2942, 257, 1329, 295, 552, 13, 407, 286, 600, 658, 586, 452, 3097], "temperature": 0.0, "avg_logprob": -0.2696377277374268, "compression_ratio": 1.517766497461929, "no_speech_prob": 9.223191227647476e-06}, {"id": 402, "seek": 265496, "start": 2654.96, "end": 2660.76, "text": " bounding boxes and my validation bounding boxes. For things that didn't have a fish,", "tokens": [5472, 278, 9002, 293, 452, 24071, 5472, 278, 9002, 13, 1171, 721, 300, 994, 380, 362, 257, 3506, 11], "temperature": 0.0, "avg_logprob": -0.283263678079123, "compression_ratio": 1.6018518518518519, "no_speech_prob": 4.0062470361590385e-05}, {"id": 403, "seek": 265496, "start": 2660.76, "end": 2667.96, "text": " I just had 0000. So as always, when I want to understand new data, the first thing to", "tokens": [286, 445, 632, 7143, 628, 13, 407, 382, 1009, 11, 562, 286, 528, 281, 1223, 777, 1412, 11, 264, 700, 551, 281], "temperature": 0.0, "avg_logprob": -0.283263678079123, "compression_ratio": 1.6018518518518519, "no_speech_prob": 4.0062470361590385e-05}, {"id": 404, "seek": 265496, "start": 2667.96, "end": 2671.68, "text": " do is to look at it. When we're doing computer vision problems, it's very easy to look at", "tokens": [360, 307, 281, 574, 412, 309, 13, 1133, 321, 434, 884, 3820, 5201, 2740, 11, 309, 311, 588, 1858, 281, 574, 412], "temperature": 0.0, "avg_logprob": -0.283263678079123, "compression_ratio": 1.6018518518518519, "no_speech_prob": 4.0062470361590385e-05}, {"id": 405, "seek": 265496, "start": 2671.68, "end": 2676.44, "text": " data because it's pictures. So I went ahead and created this little show bounding box", "tokens": [1412, 570, 309, 311, 5242, 13, 407, 286, 1437, 2286, 293, 2942, 341, 707, 855, 5472, 278, 2424], "temperature": 0.0, "avg_logprob": -0.283263678079123, "compression_ratio": 1.6018518518518519, "no_speech_prob": 4.0062470361590385e-05}, {"id": 406, "seek": 267644, "start": 2676.44, "end": 2685.2400000000002, "text": " thing, which I tried it on an image, and here is the fish, and here is the animals.", "tokens": [551, 11, 597, 286, 3031, 309, 322, 364, 3256, 11, 293, 510, 307, 264, 3506, 11, 293, 510, 307, 264, 4882, 13], "temperature": 0.0, "avg_logprob": -0.2318510479397244, "compression_ratio": 1.4827586206896552, "no_speech_prob": 2.0784131265827455e-05}, {"id": 407, "seek": 267644, "start": 2685.2400000000002, "end": 2690.64, "text": " There are two questions. I don't know if you wanted to get to a good stopping point on", "tokens": [821, 366, 732, 1651, 13, 286, 500, 380, 458, 498, 291, 1415, 281, 483, 281, 257, 665, 12767, 935, 322], "temperature": 0.0, "avg_logprob": -0.2318510479397244, "compression_ratio": 1.4827586206896552, "no_speech_prob": 2.0784131265827455e-05}, {"id": 408, "seek": 267644, "start": 2690.64, "end": 2699.32, "text": " your thought. One is adding metadata. Is that not useful for both CNNs and RNNs or just", "tokens": [428, 1194, 13, 1485, 307, 5127, 26603, 13, 1119, 300, 406, 4420, 337, 1293, 24859, 82, 293, 45702, 45, 82, 420, 445], "temperature": 0.0, "avg_logprob": -0.2318510479397244, "compression_ratio": 1.4827586206896552, "no_speech_prob": 2.0784131265827455e-05}, {"id": 409, "seek": 269932, "start": 2699.32, "end": 2708.92, "text": " for CNNs? The other one is VGG required images all the same size in training. In the fisheries", "tokens": [337, 24859, 82, 30, 440, 661, 472, 307, 691, 27561, 4739, 5267, 439, 264, 912, 2744, 294, 3097, 13, 682, 264, 20698, 530], "temperature": 0.0, "avg_logprob": -0.18254303320860252, "compression_ratio": 1.5477386934673367, "no_speech_prob": 1.363087631034432e-05}, {"id": 410, "seek": 269932, "start": 2708.92, "end": 2714.1200000000003, "text": " case, are there different size images being used for training and how do you train a model", "tokens": [1389, 11, 366, 456, 819, 2744, 5267, 885, 1143, 337, 3097, 293, 577, 360, 291, 3847, 257, 2316], "temperature": 0.0, "avg_logprob": -0.18254303320860252, "compression_ratio": 1.5477386934673367, "no_speech_prob": 1.363087631034432e-05}, {"id": 411, "seek": 269932, "start": 2714.1200000000003, "end": 2720.36, "text": " on images with different dimensions?", "tokens": [322, 5267, 365, 819, 12819, 30], "temperature": 0.0, "avg_logprob": -0.18254303320860252, "compression_ratio": 1.5477386934673367, "no_speech_prob": 1.363087631034432e-05}, {"id": 412, "seek": 269932, "start": 2720.36, "end": 2725.52, "text": " So regarding whether metadata is useful for RNNs or CNNs, it's got nothing to do with", "tokens": [407, 8595, 1968, 26603, 307, 4420, 337, 45702, 45, 82, 420, 24859, 82, 11, 309, 311, 658, 1825, 281, 360, 365], "temperature": 0.0, "avg_logprob": -0.18254303320860252, "compression_ratio": 1.5477386934673367, "no_speech_prob": 1.363087631034432e-05}, {"id": 413, "seek": 272552, "start": 2725.52, "end": 2733.8, "text": " the architecture. It's entirely about the semantics of the data. If your text or audio", "tokens": [264, 9482, 13, 467, 311, 7696, 466, 264, 4361, 45298, 295, 264, 1412, 13, 759, 428, 2487, 420, 6278], "temperature": 0.0, "avg_logprob": -0.19850369771321616, "compression_ratio": 1.5888324873096447, "no_speech_prob": 2.6274366973666474e-05}, {"id": 414, "seek": 272552, "start": 2733.8, "end": 2740.8, "text": " or whatever unstructured data in some way encodes the same information that is in the metadata,", "tokens": [420, 2035, 18799, 46847, 1412, 294, 512, 636, 2058, 4789, 264, 912, 1589, 300, 307, 294, 264, 26603, 11], "temperature": 0.0, "avg_logprob": -0.19850369771321616, "compression_ratio": 1.5888324873096447, "no_speech_prob": 2.6274366973666474e-05}, {"id": 415, "seek": 272552, "start": 2740.8, "end": 2742.72, "text": " the metadata is unlikely to be helpful.", "tokens": [264, 26603, 307, 17518, 281, 312, 4961, 13], "temperature": 0.0, "avg_logprob": -0.19850369771321616, "compression_ratio": 1.5888324873096447, "no_speech_prob": 2.6274366973666474e-05}, {"id": 416, "seek": 272552, "start": 2742.72, "end": 2748.36, "text": " So for example, in the Netflix prize, in the early stages of the competition, people found", "tokens": [407, 337, 1365, 11, 294, 264, 12778, 12818, 11, 294, 264, 2440, 10232, 295, 264, 6211, 11, 561, 1352], "temperature": 0.0, "avg_logprob": -0.19850369771321616, "compression_ratio": 1.5888324873096447, "no_speech_prob": 2.6274366973666474e-05}, {"id": 417, "seek": 274836, "start": 2748.36, "end": 2756.52, "text": " that it was helpful to link to IMDB and bring in information about the movies. In later", "tokens": [300, 309, 390, 4961, 281, 2113, 281, 21463, 27735, 293, 1565, 294, 1589, 466, 264, 6233, 13, 682, 1780], "temperature": 0.0, "avg_logprob": -0.2373654522112946, "compression_ratio": 1.5210526315789474, "no_speech_prob": 4.425460247148294e-06}, {"id": 418, "seek": 274836, "start": 2756.52, "end": 2761.2400000000002, "text": " stages they found it wasn't. The reason why is because in later stages they had figured", "tokens": [10232, 436, 1352, 309, 2067, 380, 13, 440, 1778, 983, 307, 570, 294, 1780, 10232, 436, 632, 8932], "temperature": 0.0, "avg_logprob": -0.2373654522112946, "compression_ratio": 1.5210526315789474, "no_speech_prob": 4.425460247148294e-06}, {"id": 419, "seek": 274836, "start": 2761.2400000000002, "end": 2768.36, "text": " out how to extrapolate from the ratings themselves. They basically contained implicitly all the", "tokens": [484, 577, 281, 48224, 473, 490, 264, 24603, 2969, 13, 814, 1936, 16212, 26947, 356, 439, 264], "temperature": 0.0, "avg_logprob": -0.2373654522112946, "compression_ratio": 1.5210526315789474, "no_speech_prob": 4.425460247148294e-06}, {"id": 420, "seek": 274836, "start": 2768.36, "end": 2772.2000000000003, "text": " same information.", "tokens": [912, 1589, 13], "temperature": 0.0, "avg_logprob": -0.2373654522112946, "compression_ratio": 1.5210526315789474, "no_speech_prob": 4.425460247148294e-06}, {"id": 421, "seek": 277220, "start": 2772.2, "end": 2778.52, "text": " How do we deal with different sized images? I'm about to show you some tricks. But so", "tokens": [1012, 360, 321, 2028, 365, 819, 20004, 5267, 30, 286, 478, 466, 281, 855, 291, 512, 11733, 13, 583, 370], "temperature": 0.0, "avg_logprob": -0.17093326648076376, "compression_ratio": 1.5240174672489082, "no_speech_prob": 4.6836801629979163e-05}, {"id": 422, "seek": 277220, "start": 2778.52, "end": 2785.2, "text": " far throughout this course we have always resized everything to 224x224. Whenever you", "tokens": [1400, 3710, 341, 1164, 321, 362, 1009, 725, 1602, 1203, 281, 5853, 19, 87, 7490, 19, 13, 14159, 291], "temperature": 0.0, "avg_logprob": -0.17093326648076376, "compression_ratio": 1.5240174672489082, "no_speech_prob": 4.6836801629979163e-05}, {"id": 423, "seek": 277220, "start": 2785.2, "end": 2791.3199999999997, "text": " use get-batches, I default to resizing to 224x224 because that's what ImageNet did,", "tokens": [764, 483, 12, 65, 852, 279, 11, 286, 7576, 281, 725, 3319, 281, 5853, 19, 87, 7490, 19, 570, 300, 311, 437, 29903, 31890, 630, 11], "temperature": 0.0, "avg_logprob": -0.17093326648076376, "compression_ratio": 1.5240174672489082, "no_speech_prob": 4.6836801629979163e-05}, {"id": 424, "seek": 277220, "start": 2791.3199999999997, "end": 2799.2799999999997, "text": " with the exception that in my previous ResNet model I showed you resizing to 400x400 instead.", "tokens": [365, 264, 11183, 300, 294, 452, 3894, 5015, 31890, 2316, 286, 4712, 291, 725, 3319, 281, 8423, 87, 13741, 2602, 13], "temperature": 0.0, "avg_logprob": -0.17093326648076376, "compression_ratio": 1.5240174672489082, "no_speech_prob": 4.6836801629979163e-05}, {"id": 425, "seek": 279928, "start": 2799.28, "end": 2806.2400000000002, "text": " So far, and in fact everything we're doing this year, we're going to resize everything", "tokens": [407, 1400, 11, 293, 294, 1186, 1203, 321, 434, 884, 341, 1064, 11, 321, 434, 516, 281, 50069, 1203], "temperature": 0.0, "avg_logprob": -0.4170158978166251, "compression_ratio": 1.394736842105263, "no_speech_prob": 1.834087925089989e-05}, {"id": 426, "seek": 279928, "start": 2806.2400000000002, "end": 2807.2400000000002, "text": " to be the same size.", "tokens": [281, 312, 264, 912, 2744, 13], "temperature": 0.0, "avg_logprob": -0.4170158978166251, "compression_ratio": 1.394736842105263, "no_speech_prob": 1.834087925089989e-05}, {"id": 427, "seek": 279928, "start": 2807.2400000000002, "end": 2817.48, "text": " Question about the 400x400, is that because there are two different RESTIC models?", "tokens": [14464, 466, 264, 8423, 87, 13741, 11, 307, 300, 570, 456, 366, 732, 819, 497, 14497, 2532, 5245, 30], "temperature": 0.0, "avg_logprob": -0.4170158978166251, "compression_ratio": 1.394736842105263, "no_speech_prob": 1.834087925089989e-05}, {"id": 428, "seek": 279928, "start": 2817.48, "end": 2820.48, "text": " Answer that question.", "tokens": [24545, 300, 1168, 13], "temperature": 0.0, "avg_logprob": -0.4170158978166251, "compression_ratio": 1.394736842105263, "no_speech_prob": 1.834087925089989e-05}, {"id": 429, "seek": 282048, "start": 2820.48, "end": 2836.96, "text": " Now that we've got these bounding boxes, here is the complexity. They're both a practical", "tokens": [823, 300, 321, 600, 658, 613, 5472, 278, 9002, 11, 510, 307, 264, 14024, 13, 814, 434, 1293, 257, 8496], "temperature": 0.0, "avg_logprob": -0.2127230657290106, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.1659271876851562e-05}, {"id": 430, "seek": 282048, "start": 2836.96, "end": 2841.76, "text": " one and a Kaggle one. The Kaggle complexity is the rules say you're not allowed to manually", "tokens": [472, 293, 257, 48751, 22631, 472, 13, 440, 48751, 22631, 14024, 307, 264, 4474, 584, 291, 434, 406, 4350, 281, 16945], "temperature": 0.0, "avg_logprob": -0.2127230657290106, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.1659271876851562e-05}, {"id": 431, "seek": 282048, "start": 2841.76, "end": 2846.76, "text": " annotate the test set. So we can't put bounding boxes on the test set. So if for example we", "tokens": [25339, 473, 264, 1500, 992, 13, 407, 321, 393, 380, 829, 5472, 278, 9002, 322, 264, 1500, 992, 13, 407, 498, 337, 1365, 321], "temperature": 0.0, "avg_logprob": -0.2127230657290106, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.1659271876851562e-05}, {"id": 432, "seek": 284676, "start": 2846.76, "end": 2853.36, "text": " want to go through and crop out just the fish in every image and just train on them, this", "tokens": [528, 281, 352, 807, 293, 9086, 484, 445, 264, 3506, 294, 633, 3256, 293, 445, 3847, 322, 552, 11, 341], "temperature": 0.0, "avg_logprob": -0.1893915267217727, "compression_ratio": 1.7708333333333333, "no_speech_prob": 6.1441401157935616e-06}, {"id": 433, "seek": 284676, "start": 2853.36, "end": 2857.5600000000004, "text": " is not enough to do that because we can't do that on the test set because we don't have", "tokens": [307, 406, 1547, 281, 360, 300, 570, 321, 393, 380, 360, 300, 322, 264, 1500, 992, 570, 321, 500, 380, 362], "temperature": 0.0, "avg_logprob": -0.1893915267217727, "compression_ratio": 1.7708333333333333, "no_speech_prob": 6.1441401157935616e-06}, {"id": 434, "seek": 284676, "start": 2857.5600000000004, "end": 2858.5600000000004, "text": " bounding boxes.", "tokens": [5472, 278, 9002, 13], "temperature": 0.0, "avg_logprob": -0.1893915267217727, "compression_ratio": 1.7708333333333333, "no_speech_prob": 6.1441401157935616e-06}, {"id": 435, "seek": 284676, "start": 2858.5600000000004, "end": 2864.2400000000002, "text": " The practical meaning of this is basically, in practice they're trying to create an automatic", "tokens": [440, 8496, 3620, 295, 341, 307, 1936, 11, 294, 3124, 436, 434, 1382, 281, 1884, 364, 12509], "temperature": 0.0, "avg_logprob": -0.1893915267217727, "compression_ratio": 1.7708333333333333, "no_speech_prob": 6.1441401157935616e-06}, {"id": 436, "seek": 284676, "start": 2864.2400000000002, "end": 2870.0, "text": " warning system to let them know if somebody is taking the wrong kind of fish, they don't", "tokens": [9164, 1185, 281, 718, 552, 458, 498, 2618, 307, 1940, 264, 2085, 733, 295, 3506, 11, 436, 500, 380], "temperature": 0.0, "avg_logprob": -0.1893915267217727, "compression_ratio": 1.7708333333333333, "no_speech_prob": 6.1441401157935616e-06}, {"id": 437, "seek": 284676, "start": 2870.0, "end": 2874.5200000000004, "text": " want to have somebody drawing a box on everyone.", "tokens": [528, 281, 362, 2618, 6316, 257, 2424, 322, 1518, 13], "temperature": 0.0, "avg_logprob": -0.1893915267217727, "compression_ratio": 1.7708333333333333, "no_speech_prob": 6.1441401157935616e-06}, {"id": 438, "seek": 287452, "start": 2874.52, "end": 2879.88, "text": " So what we're going to do is build a model that can find these bounding boxes automatically.", "tokens": [407, 437, 321, 434, 516, 281, 360, 307, 1322, 257, 2316, 300, 393, 915, 613, 5472, 278, 9002, 6772, 13], "temperature": 0.0, "avg_logprob": -0.1355726307836072, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.7853099001949886e-06}, {"id": 439, "seek": 287452, "start": 2879.88, "end": 2884.2, "text": " And how do we do that? It may surprise you to know we use exactly the same techniques", "tokens": [400, 577, 360, 321, 360, 300, 30, 467, 815, 6365, 291, 281, 458, 321, 764, 2293, 264, 912, 7512], "temperature": 0.0, "avg_logprob": -0.1355726307836072, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.7853099001949886e-06}, {"id": 440, "seek": 287452, "start": 2884.2, "end": 2892.24, "text": " that we've always used. Here is the exact same model again, but this time as well as", "tokens": [300, 321, 600, 1009, 1143, 13, 1692, 307, 264, 1900, 912, 2316, 797, 11, 457, 341, 565, 382, 731, 382], "temperature": 0.0, "avg_logprob": -0.1355726307836072, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.7853099001949886e-06}, {"id": 441, "seek": 287452, "start": 2892.24, "end": 2899.0, "text": " having something at the end which has 8 softmax outputs, we also have something which has", "tokens": [1419, 746, 412, 264, 917, 597, 575, 1649, 2787, 41167, 23930, 11, 321, 611, 362, 746, 597, 575], "temperature": 0.0, "avg_logprob": -0.1355726307836072, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.7853099001949886e-06}, {"id": 442, "seek": 289900, "start": 2899.0, "end": 2907.4, "text": " 4 linear outputs, i.e. 4 outputs with no activation function.", "tokens": [1017, 8213, 23930, 11, 741, 13, 68, 13, 1017, 23930, 365, 572, 24433, 2445, 13], "temperature": 0.0, "avg_logprob": -0.17926299964988623, "compression_ratio": 1.8786127167630058, "no_speech_prob": 3.0894818792148726e-06}, {"id": 443, "seek": 289900, "start": 2907.4, "end": 2911.52, "text": " What this is saying, and what we're going to do is when we train this model, we now", "tokens": [708, 341, 307, 1566, 11, 293, 437, 321, 434, 516, 281, 360, 307, 562, 321, 3847, 341, 2316, 11, 321, 586], "temperature": 0.0, "avg_logprob": -0.17926299964988623, "compression_ratio": 1.8786127167630058, "no_speech_prob": 3.0894818792148726e-06}, {"id": 444, "seek": 289900, "start": 2911.52, "end": 2917.72, "text": " have 2 outputs. So when we compile it, we're going to say, this model has 2 outputs. One", "tokens": [362, 568, 23930, 13, 407, 562, 321, 31413, 309, 11, 321, 434, 516, 281, 584, 11, 341, 2316, 575, 568, 23930, 13, 1485], "temperature": 0.0, "avg_logprob": -0.17926299964988623, "compression_ratio": 1.8786127167630058, "no_speech_prob": 3.0894818792148726e-06}, {"id": 445, "seek": 289900, "start": 2917.72, "end": 2926.2, "text": " is the 4 outputs with no activation function, one is the 8 softmax. When I compile it, the", "tokens": [307, 264, 1017, 23930, 365, 572, 24433, 2445, 11, 472, 307, 264, 1649, 2787, 41167, 13, 1133, 286, 31413, 309, 11, 264], "temperature": 0.0, "avg_logprob": -0.17926299964988623, "compression_ratio": 1.8786127167630058, "no_speech_prob": 3.0894818792148726e-06}, {"id": 446, "seek": 292620, "start": 2926.2, "end": 2930.7999999999997, "text": " first of those I want you to optimize for mean squared error, and the second of those", "tokens": [700, 295, 729, 286, 528, 291, 281, 19719, 337, 914, 8889, 6713, 11, 293, 264, 1150, 295, 729], "temperature": 0.0, "avg_logprob": -0.21514391344647074, "compression_ratio": 1.8429319371727748, "no_speech_prob": 1.4510291293845512e-05}, {"id": 447, "seek": 292620, "start": 2930.7999999999997, "end": 2937.0, "text": " I want you to optimize for cross entropy loss. And the first of them I want you to multiply", "tokens": [286, 528, 291, 281, 19719, 337, 3278, 30867, 4470, 13, 400, 264, 700, 295, 552, 286, 528, 291, 281, 12972], "temperature": 0.0, "avg_logprob": -0.21514391344647074, "compression_ratio": 1.8429319371727748, "no_speech_prob": 1.4510291293845512e-05}, {"id": 448, "seek": 292620, "start": 2937.0, "end": 2944.72, "text": " the loss by 0.001 because the mean squared error of finding the location of an image", "tokens": [264, 4470, 538, 1958, 13, 628, 16, 570, 264, 914, 8889, 6713, 295, 5006, 264, 4914, 295, 364, 3256], "temperature": 0.0, "avg_logprob": -0.21514391344647074, "compression_ratio": 1.8429319371727748, "no_speech_prob": 1.4510291293845512e-05}, {"id": 449, "seek": 292620, "start": 2944.72, "end": 2950.6, "text": " is going to be a much bigger number than the categorical cross entropy. And then when you", "tokens": [307, 516, 281, 312, 257, 709, 3801, 1230, 813, 264, 19250, 804, 3278, 30867, 13, 400, 550, 562, 291], "temperature": 0.0, "avg_logprob": -0.21514391344647074, "compression_ratio": 1.8429319371727748, "no_speech_prob": 1.4510291293845512e-05}, {"id": 450, "seek": 295060, "start": 2950.6, "end": 2958.68, "text": " train it, I want you to use the bounding boxes as the labels for the first output, and the", "tokens": [3847, 309, 11, 286, 528, 291, 281, 764, 264, 5472, 278, 9002, 382, 264, 16949, 337, 264, 700, 5598, 11, 293, 264], "temperature": 0.0, "avg_logprob": -0.15310930436657322, "compression_ratio": 1.5782312925170068, "no_speech_prob": 5.338118626241339e-06}, {"id": 451, "seek": 295060, "start": 2958.68, "end": 2962.36, "text": " fish types as the labels for the second output.", "tokens": [3506, 3467, 382, 264, 16949, 337, 264, 1150, 5598, 13], "temperature": 0.0, "avg_logprob": -0.15310930436657322, "compression_ratio": 1.5782312925170068, "no_speech_prob": 5.338118626241339e-06}, {"id": 452, "seek": 295060, "start": 2962.36, "end": 2968.24, "text": " So what this is going to have to do is figure out how to come up with a bunch of dense layers", "tokens": [407, 437, 341, 307, 516, 281, 362, 281, 360, 307, 2573, 484, 577, 281, 808, 493, 365, 257, 3840, 295, 18011, 7914], "temperature": 0.0, "avg_logprob": -0.15310930436657322, "compression_ratio": 1.5782312925170068, "no_speech_prob": 5.338118626241339e-06}, {"id": 453, "seek": 296824, "start": 2968.24, "end": 2983.56, "text": " which is capable of doing these 2 things simultaneously. So in other words, we now have something that", "tokens": [597, 307, 8189, 295, 884, 613, 568, 721, 16561, 13, 407, 294, 661, 2283, 11, 321, 586, 362, 746, 300], "temperature": 0.0, "avg_logprob": -0.1706498066584269, "compression_ratio": 1.1333333333333333, "no_speech_prob": 2.561264409450814e-06}, {"id": 454, "seek": 298356, "start": 2983.56, "end": 2998.36, "text": " looks like this. 2 outputs and one input. And notice that the 2 outputs, you don't have", "tokens": [1542, 411, 341, 13, 568, 23930, 293, 472, 4846, 13, 400, 3449, 300, 264, 568, 23930, 11, 291, 500, 380, 362], "temperature": 0.0, "avg_logprob": -0.28661424973431754, "compression_ratio": 1.453781512605042, "no_speech_prob": 1.9637986952147912e-06}, {"id": 455, "seek": 298356, "start": 2998.36, "end": 3004.7599999999998, "text": " to do it this way, but in the way I've got it, the 2 outputs both come out, they both", "tokens": [281, 360, 309, 341, 636, 11, 457, 294, 264, 636, 286, 600, 658, 309, 11, 264, 568, 23930, 1293, 808, 484, 11, 436, 1293], "temperature": 0.0, "avg_logprob": -0.28661424973431754, "compression_ratio": 1.453781512605042, "no_speech_prob": 1.9637986952147912e-06}, {"id": 456, "seek": 300476, "start": 3004.76, "end": 3027.7200000000003, "text": " have their own dense layer. It would be possible to do it like this instead. That is to say,", "tokens": [362, 641, 1065, 18011, 4583, 13, 467, 576, 312, 1944, 281, 360, 309, 411, 341, 2602, 13, 663, 307, 281, 584, 11], "temperature": 0.0, "avg_logprob": -0.2354861862805425, "compression_ratio": 1.4122137404580153, "no_speech_prob": 5.014708222006448e-06}, {"id": 457, "seek": 300476, "start": 3027.7200000000003, "end": 3033.48, "text": " each of the 2 outputs could have 2 dense layers of their own before it. In this case though,", "tokens": [1184, 295, 264, 568, 23930, 727, 362, 568, 18011, 7914, 295, 641, 1065, 949, 309, 13, 682, 341, 1389, 1673, 11], "temperature": 0.0, "avg_logprob": -0.2354861862805425, "compression_ratio": 1.4122137404580153, "no_speech_prob": 5.014708222006448e-06}, {"id": 458, "seek": 303348, "start": 3033.48, "end": 3039.2400000000002, "text": " we're going to talk about the pros and cons. Both of my last layers are both going to have", "tokens": [321, 434, 516, 281, 751, 466, 264, 6267, 293, 1014, 13, 6767, 295, 452, 1036, 7914, 366, 1293, 516, 281, 362], "temperature": 0.0, "avg_logprob": -0.18040109449817288, "compression_ratio": 1.6886792452830188, "no_speech_prob": 6.048880095477216e-06}, {"id": 459, "seek": 303348, "start": 3039.2400000000002, "end": 3048.04, "text": " to use the same set of features to generate both the bounding boxes and the fish classes.", "tokens": [281, 764, 264, 912, 992, 295, 4122, 281, 8460, 1293, 264, 5472, 278, 9002, 293, 264, 3506, 5359, 13], "temperature": 0.0, "avg_logprob": -0.18040109449817288, "compression_ratio": 1.6886792452830188, "no_speech_prob": 6.048880095477216e-06}, {"id": 460, "seek": 303348, "start": 3048.04, "end": 3053.04, "text": " So let's have this go. So we just go fit as usual. But now that we have 2 outputs, we", "tokens": [407, 718, 311, 362, 341, 352, 13, 407, 321, 445, 352, 3318, 382, 7713, 13, 583, 586, 300, 321, 362, 568, 23930, 11, 321], "temperature": 0.0, "avg_logprob": -0.18040109449817288, "compression_ratio": 1.6886792452830188, "no_speech_prob": 6.048880095477216e-06}, {"id": 461, "seek": 303348, "start": 3053.04, "end": 3060.84, "text": " get a lot more information. We get the bounding box loss, we get the fishing classification", "tokens": [483, 257, 688, 544, 1589, 13, 492, 483, 264, 5472, 278, 2424, 4470, 11, 321, 483, 264, 10180, 21538], "temperature": 0.0, "avg_logprob": -0.18040109449817288, "compression_ratio": 1.6886792452830188, "no_speech_prob": 6.048880095477216e-06}, {"id": 462, "seek": 306084, "start": 3060.84, "end": 3066.4, "text": " loss, we get the total loss, which is equal to.001 times the bounding box, because you", "tokens": [4470, 11, 321, 483, 264, 3217, 4470, 11, 597, 307, 2681, 281, 2411, 628, 16, 1413, 264, 5472, 278, 2424, 11, 570, 291], "temperature": 0.0, "avg_logprob": -0.25094991360070573, "compression_ratio": 1.7647058823529411, "no_speech_prob": 2.8409369406290352e-05}, {"id": 463, "seek": 306084, "start": 3066.4, "end": 3071.8, "text": " can see this is over 1000 times bigger than this. So you can see why I multiplied by.01.", "tokens": [393, 536, 341, 307, 670, 9714, 1413, 3801, 813, 341, 13, 407, 291, 393, 536, 983, 286, 17207, 538, 2411, 10607, 13], "temperature": 0.0, "avg_logprob": -0.25094991360070573, "compression_ratio": 1.7647058823529411, "no_speech_prob": 2.8409369406290352e-05}, {"id": 464, "seek": 306084, "start": 3071.8, "end": 3078.92, "text": " So that's the 2 added together with that weight. Then we get the validation loss, total validation", "tokens": [407, 300, 311, 264, 568, 3869, 1214, 365, 300, 3364, 13, 1396, 321, 483, 264, 24071, 4470, 11, 3217, 24071], "temperature": 0.0, "avg_logprob": -0.25094991360070573, "compression_ratio": 1.7647058823529411, "no_speech_prob": 2.8409369406290352e-05}, {"id": 465, "seek": 306084, "start": 3078.92, "end": 3083.56, "text": " bounding box loss, and the validation classification loss.", "tokens": [5472, 278, 2424, 4470, 11, 293, 264, 24071, 21538, 4470, 13], "temperature": 0.0, "avg_logprob": -0.25094991360070573, "compression_ratio": 1.7647058823529411, "no_speech_prob": 2.8409369406290352e-05}, {"id": 466, "seek": 306084, "start": 3083.56, "end": 3087.48, "text": " So here's something pretty interesting. The first thing I want to point out is after I", "tokens": [407, 510, 311, 746, 1238, 1880, 13, 440, 700, 551, 286, 528, 281, 935, 484, 307, 934, 286], "temperature": 0.0, "avg_logprob": -0.25094991360070573, "compression_ratio": 1.7647058823529411, "no_speech_prob": 2.8409369406290352e-05}, {"id": 467, "seek": 308748, "start": 3087.48, "end": 3098.08, "text": " go fit it a little bit, we actually get a much better accuracy. Now maybe this is counterintuitive,", "tokens": [352, 3318, 309, 257, 707, 857, 11, 321, 767, 483, 257, 709, 1101, 14170, 13, 823, 1310, 341, 307, 5682, 686, 48314, 11], "temperature": 0.0, "avg_logprob": -0.1654956042766571, "compression_ratio": 1.5574468085106383, "no_speech_prob": 1.321186573477462e-05}, {"id": 468, "seek": 308748, "start": 3098.08, "end": 3103.16, "text": " because we're now saying our model has exactly the same capacity as before. Our previous", "tokens": [570, 321, 434, 586, 1566, 527, 2316, 575, 2293, 264, 912, 6042, 382, 949, 13, 2621, 3894], "temperature": 0.0, "avg_logprob": -0.1654956042766571, "compression_ratio": 1.5574468085106383, "no_speech_prob": 1.321186573477462e-05}, {"id": 469, "seek": 308748, "start": 3103.16, "end": 3109.08, "text": " dense layer is of size 512. And before that last layer only had to do one thing, which", "tokens": [18011, 4583, 307, 295, 2744, 1025, 4762, 13, 400, 949, 300, 1036, 4583, 787, 632, 281, 360, 472, 551, 11, 597], "temperature": 0.0, "avg_logprob": -0.1654956042766571, "compression_ratio": 1.5574468085106383, "no_speech_prob": 1.321186573477462e-05}, {"id": 470, "seek": 308748, "start": 3109.08, "end": 3113.6, "text": " is to tell us what kind of fish it was. Now it has to do 2 things. It has to tell us where", "tokens": [307, 281, 980, 505, 437, 733, 295, 3506, 309, 390, 13, 823, 309, 575, 281, 360, 568, 721, 13, 467, 575, 281, 980, 505, 689], "temperature": 0.0, "avg_logprob": -0.1654956042766571, "compression_ratio": 1.5574468085106383, "no_speech_prob": 1.321186573477462e-05}, {"id": 471, "seek": 311360, "start": 3113.6, "end": 3121.48, "text": " the fish is and what kind of fish it is. But yet it's still done better. Why is it done", "tokens": [264, 3506, 307, 293, 437, 733, 295, 3506, 309, 307, 13, 583, 1939, 309, 311, 920, 1096, 1101, 13, 1545, 307, 309, 1096], "temperature": 0.0, "avg_logprob": -0.1759957096032929, "compression_ratio": 1.715953307392996, "no_speech_prob": 5.77189848627313e-06}, {"id": 472, "seek": 311360, "start": 3121.48, "end": 3126.24, "text": " better? Well the reason it's done better is because by telling it we want you to use those", "tokens": [1101, 30, 1042, 264, 1778, 309, 311, 1096, 1101, 307, 570, 538, 3585, 309, 321, 528, 291, 281, 764, 729], "temperature": 0.0, "avg_logprob": -0.1759957096032929, "compression_ratio": 1.715953307392996, "no_speech_prob": 5.77189848627313e-06}, {"id": 473, "seek": 311360, "start": 3126.24, "end": 3132.56, "text": " features to figure out where the fish is, we've given it a hint about what to look for.", "tokens": [4122, 281, 2573, 484, 689, 264, 3506, 307, 11, 321, 600, 2212, 309, 257, 12075, 466, 437, 281, 574, 337, 13], "temperature": 0.0, "avg_logprob": -0.1759957096032929, "compression_ratio": 1.715953307392996, "no_speech_prob": 5.77189848627313e-06}, {"id": 474, "seek": 311360, "start": 3132.56, "end": 3137.92, "text": " We've really given it more information about what to work on. So interestingly, even if", "tokens": [492, 600, 534, 2212, 309, 544, 1589, 466, 437, 281, 589, 322, 13, 407, 25873, 11, 754, 498], "temperature": 0.0, "avg_logprob": -0.1759957096032929, "compression_ratio": 1.715953307392996, "no_speech_prob": 5.77189848627313e-06}, {"id": 475, "seek": 311360, "start": 3137.92, "end": 3142.36, "text": " we didn't use the bounding box for anything else and just threw it away at this point,", "tokens": [321, 994, 380, 764, 264, 5472, 278, 2424, 337, 1340, 1646, 293, 445, 11918, 309, 1314, 412, 341, 935, 11], "temperature": 0.0, "avg_logprob": -0.1759957096032929, "compression_ratio": 1.715953307392996, "no_speech_prob": 5.77189848627313e-06}, {"id": 476, "seek": 314236, "start": 3142.36, "end": 3147.36, "text": " we already have a much better model. Do you notice also the model is much more stable?", "tokens": [321, 1217, 362, 257, 709, 1101, 2316, 13, 1144, 291, 3449, 611, 264, 2316, 307, 709, 544, 8351, 30], "temperature": 0.0, "avg_logprob": -0.19973025114639945, "compression_ratio": 1.5981735159817352, "no_speech_prob": 5.338134997145971e-06}, {"id": 477, "seek": 314236, "start": 3147.36, "end": 3155.84, "text": " 97.8, 98, 98, 98.2. Before our loss was all over the place. So by having multiple outputs,", "tokens": [23399, 13, 23, 11, 20860, 11, 20860, 11, 20860, 13, 17, 13, 4546, 527, 4470, 390, 439, 670, 264, 1081, 13, 407, 538, 1419, 3866, 23930, 11], "temperature": 0.0, "avg_logprob": -0.19973025114639945, "compression_ratio": 1.5981735159817352, "no_speech_prob": 5.338134997145971e-06}, {"id": 478, "seek": 314236, "start": 3155.84, "end": 3163.84, "text": " we've created a much more stable, resilient, and accurate classification model. And we", "tokens": [321, 600, 2942, 257, 709, 544, 8351, 11, 23699, 11, 293, 8559, 21538, 2316, 13, 400, 321], "temperature": 0.0, "avg_logprob": -0.19973025114639945, "compression_ratio": 1.5981735159817352, "no_speech_prob": 5.338134997145971e-06}, {"id": 479, "seek": 314236, "start": 3163.84, "end": 3170.4, "text": " also have bounding boxes. The best way to look at how accurate the bounding boxes are", "tokens": [611, 362, 5472, 278, 9002, 13, 440, 1151, 636, 281, 574, 412, 577, 8559, 264, 5472, 278, 9002, 366], "temperature": 0.0, "avg_logprob": -0.19973025114639945, "compression_ratio": 1.5981735159817352, "no_speech_prob": 5.338134997145971e-06}, {"id": 480, "seek": 317040, "start": 3170.4, "end": 3173.52, "text": " is to look at the picture.", "tokens": [307, 281, 574, 412, 264, 3036, 13], "temperature": 0.0, "avg_logprob": -0.16942572593688965, "compression_ratio": 1.6054054054054054, "no_speech_prob": 1.2805282494809944e-05}, {"id": 481, "seek": 317040, "start": 3173.52, "end": 3180.08, "text": " So I do a prediction for the first 10 validation examples. It's important to use the validation", "tokens": [407, 286, 360, 257, 17630, 337, 264, 700, 1266, 24071, 5110, 13, 467, 311, 1021, 281, 764, 264, 24071], "temperature": 0.0, "avg_logprob": -0.16942572593688965, "compression_ratio": 1.6054054054054054, "no_speech_prob": 1.2805282494809944e-05}, {"id": 482, "seek": 317040, "start": 3180.08, "end": 3187.4, "text": " set any time you're looking at how good your model is. This time I slightly increased the", "tokens": [992, 604, 565, 291, 434, 1237, 412, 577, 665, 428, 2316, 307, 13, 639, 565, 286, 4748, 6505, 264], "temperature": 0.0, "avg_logprob": -0.16942572593688965, "compression_ratio": 1.6054054054054054, "no_speech_prob": 1.2805282494809944e-05}, {"id": 483, "seek": 317040, "start": 3187.4, "end": 3192.52, "text": " function to show the bounding boxes to now create a yellow box for my prediction and", "tokens": [2445, 281, 855, 264, 5472, 278, 9002, 281, 586, 1884, 257, 5566, 2424, 337, 452, 17630, 293], "temperature": 0.0, "avg_logprob": -0.16942572593688965, "compression_ratio": 1.6054054054054054, "no_speech_prob": 1.2805282494809944e-05}, {"id": 484, "seek": 319252, "start": 3192.52, "end": 3202.04, "text": " a default red box for my actual. And there it is. So I just want to make it very clear", "tokens": [257, 7576, 2182, 2424, 337, 452, 3539, 13, 400, 456, 309, 307, 13, 407, 286, 445, 528, 281, 652, 309, 588, 1850], "temperature": 0.0, "avg_logprob": -0.25134203327235893, "compression_ratio": 1.494186046511628, "no_speech_prob": 6.3391594267159235e-06}, {"id": 485, "seek": 319252, "start": 3202.04, "end": 3211.2, "text": " here. We haven't done anything clever. We didn't do anything to program this. We just", "tokens": [510, 13, 492, 2378, 380, 1096, 1340, 13494, 13, 492, 994, 380, 360, 1340, 281, 1461, 341, 13, 492, 445], "temperature": 0.0, "avg_logprob": -0.25134203327235893, "compression_ratio": 1.494186046511628, "no_speech_prob": 6.3391594267159235e-06}, {"id": 486, "seek": 319252, "start": 3211.2, "end": 3218.0, "text": " said there is an output which will have 4 outputs and has no activation function, so", "tokens": [848, 456, 307, 364, 5598, 597, 486, 362, 1017, 23930, 293, 575, 572, 24433, 2445, 11, 370], "temperature": 0.0, "avg_logprob": -0.25134203327235893, "compression_ratio": 1.494186046511628, "no_speech_prob": 6.3391594267159235e-06}, {"id": 487, "seek": 321800, "start": 3218.0, "end": 3222.92, "text": " that's linear. And I want you to use mean squared error to find a set of weights that", "tokens": [300, 311, 8213, 13, 400, 286, 528, 291, 281, 764, 914, 8889, 6713, 281, 915, 257, 992, 295, 17443, 300], "temperature": 0.0, "avg_logprob": -0.16902894240159255, "compression_ratio": 1.5297029702970297, "no_speech_prob": 2.1907744667259976e-06}, {"id": 488, "seek": 321800, "start": 3222.92, "end": 3228.4, "text": " would optimize those weights such that the bounding boxes and your predictions are as", "tokens": [576, 19719, 729, 17443, 1270, 300, 264, 5472, 278, 9002, 293, 428, 21264, 366, 382], "temperature": 0.0, "avg_logprob": -0.16902894240159255, "compression_ratio": 1.5297029702970297, "no_speech_prob": 2.1907744667259976e-06}, {"id": 489, "seek": 321800, "start": 3228.4, "end": 3235.8, "text": " close as possible. And somehow it has done that.", "tokens": [1998, 382, 1944, 13, 400, 6063, 309, 575, 1096, 300, 13], "temperature": 0.0, "avg_logprob": -0.16902894240159255, "compression_ratio": 1.5297029702970297, "no_speech_prob": 2.1907744667259976e-06}, {"id": 490, "seek": 321800, "start": 3235.8, "end": 3243.4, "text": " So that is to say, very often if you're trying to get a neural net to do something, your", "tokens": [407, 300, 307, 281, 584, 11, 588, 2049, 498, 291, 434, 1382, 281, 483, 257, 18161, 2533, 281, 360, 746, 11, 428], "temperature": 0.0, "avg_logprob": -0.16902894240159255, "compression_ratio": 1.5297029702970297, "no_speech_prob": 2.1907744667259976e-06}, {"id": 491, "seek": 324340, "start": 3243.4, "end": 3248.92, "text": " first step before you create some complex programming heuristic thing is just ask the", "tokens": [700, 1823, 949, 291, 1884, 512, 3997, 9410, 415, 374, 3142, 551, 307, 445, 1029, 264], "temperature": 0.0, "avg_logprob": -0.22442034179089115, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.854301773273619e-06}, {"id": 492, "seek": 324340, "start": 3248.92, "end": 3254.12, "text": " neural net to do it. And very often it does.", "tokens": [18161, 2533, 281, 360, 309, 13, 400, 588, 2049, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.22442034179089115, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.854301773273619e-06}, {"id": 493, "seek": 324340, "start": 3254.12, "end": 3258.8, "text": " Why do both in the same fitting instead of training the boxes first and feeding that", "tokens": [1545, 360, 1293, 294, 264, 912, 15669, 2602, 295, 3097, 264, 9002, 700, 293, 12919, 300], "temperature": 0.0, "avg_logprob": -0.22442034179089115, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.854301773273619e-06}, {"id": 494, "seek": 324340, "start": 3258.8, "end": 3261.12, "text": " as input to recognize fishes?", "tokens": [382, 4846, 281, 5521, 41734, 30], "temperature": 0.0, "avg_logprob": -0.22442034179089115, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.854301773273619e-06}, {"id": 495, "seek": 324340, "start": 3261.12, "end": 3266.44, "text": " Well we can. But the first thing I want to point out is, even then I would still have", "tokens": [1042, 321, 393, 13, 583, 264, 700, 551, 286, 528, 281, 935, 484, 307, 11, 754, 550, 286, 576, 920, 362], "temperature": 0.0, "avg_logprob": -0.22442034179089115, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.854301773273619e-06}, {"id": 496, "seek": 324340, "start": 3266.44, "end": 3272.92, "text": " the first stage do both at the same time, because the more compatible tasks you can", "tokens": [264, 700, 3233, 360, 1293, 412, 264, 912, 565, 11, 570, 264, 544, 18218, 9608, 291, 393], "temperature": 0.0, "avg_logprob": -0.22442034179089115, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.854301773273619e-06}, {"id": 497, "seek": 327292, "start": 3272.92, "end": 3279.08, "text": " give it, so like where is the fish and what kind of fish it is, the more it can create", "tokens": [976, 309, 11, 370, 411, 689, 307, 264, 3506, 293, 437, 733, 295, 3506, 309, 307, 11, 264, 544, 309, 393, 1884], "temperature": 0.0, "avg_logprob": -0.20389140524515292, "compression_ratio": 1.5754716981132075, "no_speech_prob": 1.3419898095889948e-05}, {"id": 498, "seek": 327292, "start": 3279.08, "end": 3284.48, "text": " an internal representation that is as appropriate as possible.", "tokens": [364, 6920, 10290, 300, 307, 382, 6854, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.20389140524515292, "compression_ratio": 1.5754716981132075, "no_speech_prob": 1.3419898095889948e-05}, {"id": 499, "seek": 327292, "start": 3284.48, "end": 3290.64, "text": " Now if you now want to go away over the next couple of weeks and crop out these fish and", "tokens": [823, 498, 291, 586, 528, 281, 352, 1314, 670, 264, 958, 1916, 295, 3259, 293, 9086, 484, 613, 3506, 293], "temperature": 0.0, "avg_logprob": -0.20389140524515292, "compression_ratio": 1.5754716981132075, "no_speech_prob": 1.3419898095889948e-05}, {"id": 500, "seek": 327292, "start": 3290.64, "end": 3300.84, "text": " create the second model, I can almost guarantee you'll get into the top 10 of this competition.", "tokens": [1884, 264, 1150, 2316, 11, 286, 393, 1920, 10815, 291, 603, 483, 666, 264, 1192, 1266, 295, 341, 6211, 13], "temperature": 0.0, "avg_logprob": -0.20389140524515292, "compression_ratio": 1.5754716981132075, "no_speech_prob": 1.3419898095889948e-05}, {"id": 501, "seek": 330084, "start": 3300.84, "end": 3303.8, "text": " And the reason I can almost guarantee that is because there was quite a similar competition", "tokens": [400, 264, 1778, 286, 393, 1920, 10815, 300, 307, 570, 456, 390, 1596, 257, 2531, 6211], "temperature": 0.0, "avg_logprob": -0.22788332867366012, "compression_ratio": 1.6680497925311204, "no_speech_prob": 8.939602594182361e-06}, {"id": 502, "seek": 330084, "start": 3303.8, "end": 3313.6400000000003, "text": " on Kaggle last year, which was trying to identify particular whales, a whale or a rat whale,", "tokens": [322, 48751, 22631, 1036, 1064, 11, 597, 390, 1382, 281, 5876, 1729, 32403, 11, 257, 25370, 420, 257, 5937, 25370, 11], "temperature": 0.0, "avg_logprob": -0.22788332867366012, "compression_ratio": 1.6680497925311204, "no_speech_prob": 8.939602594182361e-06}, {"id": 503, "seek": 330084, "start": 3313.6400000000003, "end": 3321.08, "text": " and literally saying which individual whale is it. And all of the top 3 in that competition", "tokens": [293, 3736, 1566, 597, 2609, 25370, 307, 309, 13, 400, 439, 295, 264, 1192, 805, 294, 300, 6211], "temperature": 0.0, "avg_logprob": -0.22788332867366012, "compression_ratio": 1.6680497925311204, "no_speech_prob": 8.939602594182361e-06}, {"id": 504, "seek": 330084, "start": 3321.08, "end": 3325.6800000000003, "text": " did some kind of bounding box prediction and some kind of cropping and then modeled the", "tokens": [630, 512, 733, 295, 5472, 278, 2424, 17630, 293, 512, 733, 295, 4848, 3759, 293, 550, 37140, 264], "temperature": 0.0, "avg_logprob": -0.22788332867366012, "compression_ratio": 1.6680497925311204, "no_speech_prob": 8.939602594182361e-06}, {"id": 505, "seek": 330084, "start": 3325.6800000000003, "end": 3329.4, "text": " second layer on the cropped features.", "tokens": [1150, 4583, 322, 264, 4848, 3320, 4122, 13], "temperature": 0.0, "avg_logprob": -0.22788332867366012, "compression_ratio": 1.6680497925311204, "no_speech_prob": 8.939602594182361e-06}, {"id": 506, "seek": 332940, "start": 3329.4, "end": 3334.44, "text": " By the 4 bounding box outputs, the vertical and horizontal size of the box and the 2 coordinates", "tokens": [3146, 264, 1017, 5472, 278, 2424, 23930, 11, 264, 9429, 293, 12750, 2744, 295, 264, 2424, 293, 264, 568, 21056], "temperature": 0.0, "avg_logprob": -0.19086457476203825, "compression_ratio": 1.4702970297029703, "no_speech_prob": 7.030794949969277e-05}, {"id": 507, "seek": 332940, "start": 3334.44, "end": 3335.44, "text": " for its center?", "tokens": [337, 1080, 3056, 30], "temperature": 0.0, "avg_logprob": -0.19086457476203825, "compression_ratio": 1.4702970297029703, "no_speech_prob": 7.030794949969277e-05}, {"id": 508, "seek": 332940, "start": 3335.44, "end": 3346.6800000000003, "text": " It's whatever we were given, which was not quite that, it was the height, width, x and", "tokens": [467, 311, 2035, 321, 645, 2212, 11, 597, 390, 406, 1596, 300, 11, 309, 390, 264, 6681, 11, 11402, 11, 2031, 293], "temperature": 0.0, "avg_logprob": -0.19086457476203825, "compression_ratio": 1.4702970297029703, "no_speech_prob": 7.030794949969277e-05}, {"id": 509, "seek": 332940, "start": 3346.6800000000003, "end": 3348.6800000000003, "text": " y.", "tokens": [288, 13], "temperature": 0.0, "avg_logprob": -0.19086457476203825, "compression_ratio": 1.4702970297029703, "no_speech_prob": 7.030794949969277e-05}, {"id": 510, "seek": 332940, "start": 3348.6800000000003, "end": 3357.04, "text": " So how many of the people in this Kaggle competition are using this sort of model? If you came", "tokens": [407, 577, 867, 295, 264, 561, 294, 341, 48751, 22631, 6211, 366, 1228, 341, 1333, 295, 2316, 30, 759, 291, 1361], "temperature": 0.0, "avg_logprob": -0.19086457476203825, "compression_ratio": 1.4702970297029703, "no_speech_prob": 7.030794949969277e-05}, {"id": 511, "seek": 335704, "start": 3357.04, "end": 3367.68, "text": " up with this with a bit of tinkering, do you think you would actually stay in the top 10", "tokens": [493, 365, 341, 365, 257, 857, 295, 256, 475, 1794, 11, 360, 291, 519, 291, 576, 767, 1754, 294, 264, 1192, 1266], "temperature": 0.0, "avg_logprob": -0.2276468276977539, "compression_ratio": 1.5477707006369428, "no_speech_prob": 5.06411051901523e-05}, {"id": 512, "seek": 335704, "start": 3367.68, "end": 3373.56, "text": " or would this just be an obvious thing that people would tend to do and so your ranking", "tokens": [420, 576, 341, 445, 312, 364, 6322, 551, 300, 561, 576, 3928, 281, 360, 293, 370, 428, 17833], "temperature": 0.0, "avg_logprob": -0.2276468276977539, "compression_ratio": 1.5477707006369428, "no_speech_prob": 5.06411051901523e-05}, {"id": 513, "seek": 335704, "start": 3373.56, "end": 3376.92, "text": " would basically drop over time as everyone else incorporates this?", "tokens": [576, 1936, 3270, 670, 565, 382, 1518, 1646, 50193, 341, 30], "temperature": 0.0, "avg_logprob": -0.2276468276977539, "compression_ratio": 1.5477707006369428, "no_speech_prob": 5.06411051901523e-05}, {"id": 514, "seek": 337692, "start": 3376.92, "end": 3397.48, "text": " I'm going to show you a few techniques that I used this week. They're all very basic,", "tokens": [286, 478, 516, 281, 855, 291, 257, 1326, 7512, 300, 286, 1143, 341, 1243, 13, 814, 434, 439, 588, 3875, 11], "temperature": 0.0, "avg_logprob": -0.28327970301851313, "compression_ratio": 1.25, "no_speech_prob": 1.7777521861717105e-05}, {"id": 515, "seek": 337692, "start": 3397.48, "end": 3403.2400000000002, "text": " very normal. We're at a point now in this $150,000 competition where over 500 people", "tokens": [588, 2710, 13, 492, 434, 412, 257, 935, 586, 294, 341, 1848, 20120, 11, 1360, 6211, 689, 670, 5923, 561], "temperature": 0.0, "avg_logprob": -0.28327970301851313, "compression_ratio": 1.25, "no_speech_prob": 1.7777521861717105e-05}, {"id": 516, "seek": 340324, "start": 3403.24, "end": 3410.3599999999997, "text": " have been invented and I am currently 20th.", "tokens": [362, 668, 14479, 293, 286, 669, 4362, 945, 392, 13], "temperature": 0.0, "avg_logprob": -0.2369482421875, "compression_ratio": 1.5441176470588236, "no_speech_prob": 6.048823252058355e-06}, {"id": 517, "seek": 340324, "start": 3410.3599999999997, "end": 3415.68, "text": " The stuff that you're learning in this course is not at all well-known. There's never been", "tokens": [440, 1507, 300, 291, 434, 2539, 294, 341, 1164, 307, 406, 412, 439, 731, 12, 6861, 13, 821, 311, 1128, 668], "temperature": 0.0, "avg_logprob": -0.2369482421875, "compression_ratio": 1.5441176470588236, "no_speech_prob": 6.048823252058355e-06}, {"id": 518, "seek": 340324, "start": 3415.68, "end": 3421.3999999999996, "text": " an applied deep learning course before. So the people who are above me in the competition", "tokens": [364, 6456, 2452, 2539, 1164, 949, 13, 407, 264, 561, 567, 366, 3673, 385, 294, 264, 6211], "temperature": 0.0, "avg_logprob": -0.2369482421875, "compression_ratio": 1.5441176470588236, "no_speech_prob": 6.048823252058355e-06}, {"id": 519, "seek": 340324, "start": 3421.3999999999996, "end": 3429.4399999999996, "text": " are people who have figured these things out over time and read lots of papers and studied", "tokens": [366, 561, 567, 362, 8932, 613, 721, 484, 670, 565, 293, 1401, 3195, 295, 10577, 293, 9454], "temperature": 0.0, "avg_logprob": -0.2369482421875, "compression_ratio": 1.5441176470588236, "no_speech_prob": 6.048823252058355e-06}, {"id": 520, "seek": 342944, "start": 3429.44, "end": 3435.0, "text": " and whatever else. So I definitely think that people in this course, particularly if somebody", "tokens": [293, 2035, 1646, 13, 407, 286, 2138, 519, 300, 561, 294, 341, 1164, 11, 4098, 498, 2618], "temperature": 0.0, "avg_logprob": -0.2710885251505991, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.0716641049366444e-05}, {"id": 521, "seek": 342944, "start": 3435.0, "end": 3439.6, "text": " teamed up together, would have a very good chance of winning this competition because", "tokens": [47426, 493, 1214, 11, 576, 362, 257, 588, 665, 2931, 295, 8224, 341, 6211, 570], "temperature": 0.0, "avg_logprob": -0.2710885251505991, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.0716641049366444e-05}, {"id": 522, "seek": 342944, "start": 3439.6, "end": 3444.92, "text": " it's a perfect fit for everything we've been talking about. Particularly you can collaborate", "tokens": [309, 311, 257, 2176, 3318, 337, 1203, 321, 600, 668, 1417, 466, 13, 32281, 291, 393, 18338], "temperature": 0.0, "avg_logprob": -0.2710885251505991, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.0716641049366444e-05}, {"id": 523, "seek": 342944, "start": 3444.92, "end": 3449.48, "text": " on forums and stuff like that.", "tokens": [322, 26998, 293, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2710885251505991, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.0716641049366444e-05}, {"id": 524, "seek": 342944, "start": 3449.48, "end": 3455.08, "text": " I should mention this 20th is I haven't even done any cropping yet. This is just using", "tokens": [286, 820, 2152, 341, 945, 392, 307, 286, 2378, 380, 754, 1096, 604, 4848, 3759, 1939, 13, 639, 307, 445, 1228], "temperature": 0.0, "avg_logprob": -0.2710885251505991, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.0716641049366444e-05}, {"id": 525, "seek": 345508, "start": 3455.08, "end": 3462.16, "text": " the whole image, which is clearly not the right way to tackle this. I was actually intentionally", "tokens": [264, 1379, 3256, 11, 597, 307, 4448, 406, 264, 558, 636, 281, 14896, 341, 13, 286, 390, 767, 22062], "temperature": 0.0, "avg_logprob": -0.2167229894864357, "compression_ratio": 1.6691449814126393, "no_speech_prob": 4.1332936234539375e-05}, {"id": 526, "seek": 345508, "start": 3462.16, "end": 3468.2, "text": " trying not to do too well because I'm going to have to release this to everybody on the", "tokens": [1382, 406, 281, 360, 886, 731, 570, 286, 478, 516, 281, 362, 281, 4374, 341, 281, 2201, 322, 264], "temperature": 0.0, "avg_logprob": -0.2167229894864357, "compression_ratio": 1.6691449814126393, "no_speech_prob": 4.1332936234539375e-05}, {"id": 527, "seek": 345508, "start": 3468.2, "end": 3473.2, "text": " CACL forum to say I've done this and here's the notebook because it's $150,000. I didn't", "tokens": [383, 4378, 43, 17542, 281, 584, 286, 600, 1096, 341, 293, 510, 311, 264, 21060, 570, 309, 311, 1848, 20120, 11, 1360, 13, 286, 994, 380], "temperature": 0.0, "avg_logprob": -0.2167229894864357, "compression_ratio": 1.6691449814126393, "no_speech_prob": 4.1332936234539375e-05}, {"id": 528, "seek": 345508, "start": 3473.2, "end": 3478.68, "text": " want to say here's a way to get in the top 10 because that's not fair to everybody else.", "tokens": [528, 281, 584, 510, 311, 257, 636, 281, 483, 294, 264, 1192, 1266, 570, 300, 311, 406, 3143, 281, 2201, 1646, 13], "temperature": 0.0, "avg_logprob": -0.2167229894864357, "compression_ratio": 1.6691449814126393, "no_speech_prob": 4.1332936234539375e-05}, {"id": 529, "seek": 345508, "start": 3478.68, "end": 3485.0, "text": " So to answer your question, by the end of the competition, to win one of these things,", "tokens": [407, 281, 1867, 428, 1168, 11, 538, 264, 917, 295, 264, 6211, 11, 281, 1942, 472, 295, 613, 721, 11], "temperature": 0.0, "avg_logprob": -0.2167229894864357, "compression_ratio": 1.6691449814126393, "no_speech_prob": 4.1332936234539375e-05}, {"id": 530, "seek": 348500, "start": 3485.0, "end": 3490.64, "text": " you've got to do everything right at every point. And every time you fail, you have to", "tokens": [291, 600, 658, 281, 360, 1203, 558, 412, 633, 935, 13, 400, 633, 565, 291, 3061, 11, 291, 362, 281], "temperature": 0.0, "avg_logprob": -0.21495057870675852, "compression_ratio": 1.7218045112781954, "no_speech_prob": 2.318698534509167e-05}, {"id": 531, "seek": 348500, "start": 3490.64, "end": 3495.4, "text": " keep trying again. Tenacity is part of winning these things. I know from experience the feeling", "tokens": [1066, 1382, 797, 13, 9380, 19008, 307, 644, 295, 8224, 613, 721, 13, 286, 458, 490, 1752, 264, 2633], "temperature": 0.0, "avg_logprob": -0.21495057870675852, "compression_ratio": 1.7218045112781954, "no_speech_prob": 2.318698534509167e-05}, {"id": 532, "seek": 348500, "start": 3495.4, "end": 3499.68, "text": " of being on top of the leaderboard and waking up the next day and finding that 5 people", "tokens": [295, 885, 322, 1192, 295, 264, 5263, 3787, 293, 20447, 493, 264, 958, 786, 293, 5006, 300, 1025, 561], "temperature": 0.0, "avg_logprob": -0.21495057870675852, "compression_ratio": 1.7218045112781954, "no_speech_prob": 2.318698534509167e-05}, {"id": 533, "seek": 348500, "start": 3499.68, "end": 3506.48, "text": " have passed you. But the thing is, they have found something that is there and you haven't", "tokens": [362, 4678, 291, 13, 583, 264, 551, 307, 11, 436, 362, 1352, 746, 300, 307, 456, 293, 291, 2378, 380], "temperature": 0.0, "avg_logprob": -0.21495057870675852, "compression_ratio": 1.7218045112781954, "no_speech_prob": 2.318698534509167e-05}, {"id": 534, "seek": 348500, "start": 3506.48, "end": 3512.44, "text": " found yet. And that's part of what makes competing in the CACL competition so different to doing", "tokens": [1352, 1939, 13, 400, 300, 311, 644, 295, 437, 1669, 15439, 294, 264, 383, 4378, 43, 6211, 370, 819, 281, 884], "temperature": 0.0, "avg_logprob": -0.21495057870675852, "compression_ratio": 1.7218045112781954, "no_speech_prob": 2.318698534509167e-05}, {"id": 535, "seek": 351244, "start": 3512.44, "end": 3519.76, "text": " academic papers or looking at old CACL competitions that are long gone. It's a really great test", "tokens": [7778, 10577, 420, 1237, 412, 1331, 383, 4378, 43, 26185, 300, 366, 938, 2780, 13, 467, 311, 257, 534, 869, 1500], "temperature": 0.0, "avg_logprob": -0.1127503788660443, "compression_ratio": 1.4789473684210526, "no_speech_prob": 3.535438372637145e-05}, {"id": 536, "seek": 351244, "start": 3519.76, "end": 3530.2400000000002, "text": " of your own processes and your own grit. What you'll probably find yourself doing is repeatedly", "tokens": [295, 428, 1065, 7555, 293, 428, 1065, 30133, 13, 708, 291, 603, 1391, 915, 1803, 884, 307, 18227], "temperature": 0.0, "avg_logprob": -0.1127503788660443, "compression_ratio": 1.4789473684210526, "no_speech_prob": 3.535438372637145e-05}, {"id": 537, "seek": 351244, "start": 3530.2400000000002, "end": 3535.52, "text": " fucking around with hyperparameters and minor architectural details because it's just so", "tokens": [5546, 926, 365, 9848, 2181, 335, 6202, 293, 6696, 26621, 4365, 570, 309, 311, 445, 370], "temperature": 0.0, "avg_logprob": -0.1127503788660443, "compression_ratio": 1.4789473684210526, "no_speech_prob": 3.535438372637145e-05}, {"id": 538, "seek": 353552, "start": 3535.52, "end": 3542.8, "text": " addictive until eventually you go away and go, what's a totally different way of thinking", "tokens": [36486, 1826, 4728, 291, 352, 1314, 293, 352, 11, 437, 311, 257, 3879, 819, 636, 295, 1953], "temperature": 0.0, "avg_logprob": -0.28086936473846436, "compression_ratio": 1.521505376344086, "no_speech_prob": 8.397816600336228e-06}, {"id": 539, "seek": 353552, "start": 3542.8, "end": 3543.8, "text": " about this problem.", "tokens": [466, 341, 1154, 13], "temperature": 0.0, "avg_logprob": -0.28086936473846436, "compression_ratio": 1.521505376344086, "no_speech_prob": 8.397816600336228e-06}, {"id": 540, "seek": 353552, "start": 3543.8, "end": 3550.8, "text": " I hope some of you will consider seriously investing in putting an hour a day into a", "tokens": [286, 1454, 512, 295, 291, 486, 1949, 6638, 10978, 294, 3372, 364, 1773, 257, 786, 666, 257], "temperature": 0.0, "avg_logprob": -0.28086936473846436, "compression_ratio": 1.521505376344086, "no_speech_prob": 8.397816600336228e-06}, {"id": 541, "seek": 353552, "start": 3550.8, "end": 3557.68, "text": " competition because I learned far more doing that than everything else I've ever done in", "tokens": [6211, 570, 286, 3264, 1400, 544, 884, 300, 813, 1203, 1646, 286, 600, 1562, 1096, 294], "temperature": 0.0, "avg_logprob": -0.28086936473846436, "compression_ratio": 1.521505376344086, "no_speech_prob": 8.397816600336228e-06}, {"id": 542, "seek": 355768, "start": 3557.68, "end": 3566.04, "text": " my life. It's totally different to just playing around. And after it, it's something that", "tokens": [452, 993, 13, 467, 311, 3879, 819, 281, 445, 2433, 926, 13, 400, 934, 309, 11, 309, 311, 746, 300], "temperature": 0.0, "avg_logprob": -0.29430320297462353, "compression_ratio": 1.423728813559322, "no_speech_prob": 1.9222656192141585e-05}, {"id": 543, "seek": 355768, "start": 3566.04, "end": 3573.7999999999997, "text": " every real-world project does. It's greatly better for that experience.", "tokens": [633, 957, 12, 13217, 1716, 775, 13, 467, 311, 14147, 1101, 337, 300, 1752, 13], "temperature": 0.0, "avg_logprob": -0.29430320297462353, "compression_ratio": 1.423728813559322, "no_speech_prob": 1.9222656192141585e-05}, {"id": 544, "seek": 355768, "start": 3573.7999999999997, "end": 3586.2799999999997, "text": " So to give you a sense of this, here's number 6. I can't even see that fish, but it's done", "tokens": [407, 281, 976, 291, 257, 2020, 295, 341, 11, 510, 311, 1230, 1386, 13, 286, 393, 380, 754, 536, 300, 3506, 11, 457, 309, 311, 1096], "temperature": 0.0, "avg_logprob": -0.29430320297462353, "compression_ratio": 1.423728813559322, "no_speech_prob": 1.9222656192141585e-05}, {"id": 545, "seek": 358628, "start": 3586.28, "end": 3592.6000000000004, "text": " a pretty good job. Maybe it kind of knows that people tend to float around where the", "tokens": [257, 1238, 665, 1691, 13, 2704, 309, 733, 295, 3255, 300, 561, 3928, 281, 15706, 926, 689, 264], "temperature": 0.0, "avg_logprob": -0.2641318116006972, "compression_ratio": 1.4619289340101522, "no_speech_prob": 3.3213113056262955e-05}, {"id": 546, "seek": 358628, "start": 3592.6000000000004, "end": 3597.8, "text": " fish is or something because it's pretty hard to see. As you can see, this is just a 224x224", "tokens": [3506, 307, 420, 746, 570, 309, 311, 1238, 1152, 281, 536, 13, 1018, 291, 393, 536, 11, 341, 307, 445, 257, 5853, 19, 87, 7490, 19], "temperature": 0.0, "avg_logprob": -0.2641318116006972, "compression_ratio": 1.4619289340101522, "no_speech_prob": 3.3213113056262955e-05}, {"id": 547, "seek": 358628, "start": 3597.8, "end": 3603.6800000000003, "text": " image. So this model is doing a pretty great job and the amount of time it took to train", "tokens": [3256, 13, 407, 341, 2316, 307, 884, 257, 1238, 869, 1691, 293, 264, 2372, 295, 565, 309, 1890, 281, 3847], "temperature": 0.0, "avg_logprob": -0.2641318116006972, "compression_ratio": 1.4619289340101522, "no_speech_prob": 3.3213113056262955e-05}, {"id": 548, "seek": 358628, "start": 3603.6800000000003, "end": 3605.6800000000003, "text": " was under 10 seconds.", "tokens": [390, 833, 1266, 3949, 13], "temperature": 0.0, "avg_logprob": -0.2641318116006972, "compression_ratio": 1.4619289340101522, "no_speech_prob": 3.3213113056262955e-05}, {"id": 549, "seek": 360568, "start": 3605.68, "end": 3628.68, "text": " Question. Is there a way to find the bounding box without hand-coding it?", "tokens": [14464, 13, 1119, 456, 257, 636, 281, 915, 264, 5472, 278, 2424, 1553, 1011, 12, 66, 8616, 309, 30], "temperature": 0.0, "avg_logprob": -0.217360585234886, "compression_ratio": 1.3524590163934427, "no_speech_prob": 2.5465480575803667e-05}, {"id": 550, "seek": 360568, "start": 3628.68, "end": 3634.3199999999997, "text": " Before we look at finding things without manually annotating bounding boxes, I want to talk", "tokens": [4546, 321, 574, 412, 5006, 721, 1553, 16945, 25339, 990, 5472, 278, 9002, 11, 286, 528, 281, 751], "temperature": 0.0, "avg_logprob": -0.217360585234886, "compression_ratio": 1.3524590163934427, "no_speech_prob": 2.5465480575803667e-05}, {"id": 551, "seek": 363432, "start": 3634.32, "end": 3636.7200000000003, "text": " more about different size images.", "tokens": [544, 466, 819, 2744, 5267, 13], "temperature": 0.0, "avg_logprob": -0.19900063464516088, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.0616024155751802e-05}, {"id": 552, "seek": 363432, "start": 3636.7200000000003, "end": 3646.36, "text": " So let's talk about sizes. Let's specifically talk about in which situations is our model", "tokens": [407, 718, 311, 751, 466, 11602, 13, 961, 311, 4682, 751, 466, 294, 597, 6851, 307, 527, 2316], "temperature": 0.0, "avg_logprob": -0.19900063464516088, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.0616024155751802e-05}, {"id": 553, "seek": 363432, "start": 3646.36, "end": 3654.6400000000003, "text": " going to be sensitive to the size of the input. Like a pre-trained model with pre-trained", "tokens": [516, 281, 312, 9477, 281, 264, 2744, 295, 264, 4846, 13, 1743, 257, 659, 12, 17227, 2001, 2316, 365, 659, 12, 17227, 2001], "temperature": 0.0, "avg_logprob": -0.19900063464516088, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.0616024155751802e-05}, {"id": 554, "seek": 363432, "start": 3654.6400000000003, "end": 3663.44, "text": " weights. And it's all about what are these layer operations exactly. If it's a dense", "tokens": [17443, 13, 400, 309, 311, 439, 466, 437, 366, 613, 4583, 7705, 2293, 13, 759, 309, 311, 257, 18011], "temperature": 0.0, "avg_logprob": -0.19900063464516088, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.0616024155751802e-05}, {"id": 555, "seek": 366344, "start": 3663.44, "end": 3671.64, "text": " layer, then there's a weight going from every input to every output. And so if you have", "tokens": [4583, 11, 550, 456, 311, 257, 3364, 516, 490, 633, 4846, 281, 633, 5598, 13, 400, 370, 498, 291, 362], "temperature": 0.0, "avg_logprob": -0.13118589841402495, "compression_ratio": 1.532544378698225, "no_speech_prob": 1.0451488378748763e-05}, {"id": 556, "seek": 366344, "start": 3671.64, "end": 3678.32, "text": " a different sized input, then that's not going to work at all because the weight matrix for", "tokens": [257, 819, 20004, 4846, 11, 550, 300, 311, 406, 516, 281, 589, 412, 439, 570, 264, 3364, 8141, 337], "temperature": 0.0, "avg_logprob": -0.13118589841402495, "compression_ratio": 1.532544378698225, "no_speech_prob": 1.0451488378748763e-05}, {"id": 557, "seek": 366344, "start": 3678.32, "end": 3685.8, "text": " your dense layer is just simply of the wrong size. Who knows what it should do.", "tokens": [428, 18011, 4583, 307, 445, 2935, 295, 264, 2085, 2744, 13, 2102, 3255, 437, 309, 820, 360, 13], "temperature": 0.0, "avg_logprob": -0.13118589841402495, "compression_ratio": 1.532544378698225, "no_speech_prob": 1.0451488378748763e-05}, {"id": 558, "seek": 368580, "start": 3685.8, "end": 3693.76, "text": " What if it's a convolutional layer? If it's a convolutional layer, then we have a little", "tokens": [708, 498, 309, 311, 257, 45216, 304, 4583, 30, 759, 309, 311, 257, 45216, 304, 4583, 11, 550, 321, 362, 257, 707], "temperature": 0.0, "avg_logprob": -0.10468224261669402, "compression_ratio": 1.7846153846153847, "no_speech_prob": 4.9369737098459154e-06}, {"id": 559, "seek": 368580, "start": 3693.76, "end": 3700.2400000000002, "text": " set of weights for each 3x3 block for each different feature, and then that 3x3 block", "tokens": [992, 295, 17443, 337, 1184, 805, 87, 18, 3461, 337, 1184, 819, 4111, 11, 293, 550, 300, 805, 87, 18, 3461], "temperature": 0.0, "avg_logprob": -0.10468224261669402, "compression_ratio": 1.7846153846153847, "no_speech_prob": 4.9369737098459154e-06}, {"id": 560, "seek": 368580, "start": 3700.2400000000002, "end": 3707.76, "text": " is going to be slid over to create the outputs. If the image is bigger, it doesn't change", "tokens": [307, 516, 281, 312, 1061, 327, 670, 281, 1884, 264, 23930, 13, 759, 264, 3256, 307, 3801, 11, 309, 1177, 380, 1319], "temperature": 0.0, "avg_logprob": -0.10468224261669402, "compression_ratio": 1.7846153846153847, "no_speech_prob": 4.9369737098459154e-06}, {"id": 561, "seek": 368580, "start": 3707.76, "end": 3712.92, "text": " the number of weights. It just means that block is going to be slid around more and", "tokens": [264, 1230, 295, 17443, 13, 467, 445, 1355, 300, 3461, 307, 516, 281, 312, 1061, 327, 926, 544, 293], "temperature": 0.0, "avg_logprob": -0.10468224261669402, "compression_ratio": 1.7846153846153847, "no_speech_prob": 4.9369737098459154e-06}, {"id": 562, "seek": 371292, "start": 3712.92, "end": 3721.02, "text": " the output will be bigger. A max-pauling layer doesn't have any weights. A batch normalization", "tokens": [264, 5598, 486, 312, 3801, 13, 316, 11469, 12, 4306, 425, 278, 4583, 1177, 380, 362, 604, 17443, 13, 316, 15245, 2710, 2144], "temperature": 0.0, "avg_logprob": -0.1360717263332633, "compression_ratio": 1.6093023255813954, "no_speech_prob": 8.990955393528566e-07}, {"id": 563, "seek": 371292, "start": 3721.02, "end": 3726.44, "text": " layer simply cares about the number of weights of the previous layer.", "tokens": [4583, 2935, 12310, 466, 264, 1230, 295, 17443, 295, 264, 3894, 4583, 13], "temperature": 0.0, "avg_logprob": -0.1360717263332633, "compression_ratio": 1.6093023255813954, "no_speech_prob": 8.990955393528566e-07}, {"id": 564, "seek": 371292, "start": 3726.44, "end": 3731.2400000000002, "text": " So really when you think about it, the only layer that really cares what size your input", "tokens": [407, 534, 562, 291, 519, 466, 309, 11, 264, 787, 4583, 300, 534, 12310, 437, 2744, 428, 4846], "temperature": 0.0, "avg_logprob": -0.1360717263332633, "compression_ratio": 1.6093023255813954, "no_speech_prob": 8.990955393528566e-07}, {"id": 565, "seek": 371292, "start": 3731.2400000000002, "end": 3738.4, "text": " is, is a dense layer. And remember that with VGG, nearly all of the layers are convolutional", "tokens": [307, 11, 307, 257, 18011, 4583, 13, 400, 1604, 300, 365, 691, 27561, 11, 6217, 439, 295, 264, 7914, 366, 45216, 304], "temperature": 0.0, "avg_logprob": -0.1360717263332633, "compression_ratio": 1.6093023255813954, "no_speech_prob": 8.990955393528566e-07}, {"id": 566, "seek": 373840, "start": 3738.4, "end": 3752.48, "text": " layers. So that's why it is that we can say not only include top equals false, but we", "tokens": [7914, 13, 407, 300, 311, 983, 309, 307, 300, 321, 393, 584, 406, 787, 4090, 1192, 6915, 7908, 11, 457, 321], "temperature": 0.0, "avg_logprob": -0.1322406324846991, "compression_ratio": 1.375, "no_speech_prob": 2.8573092549777357e-06}, {"id": 567, "seek": 373840, "start": 3752.48, "end": 3755.8, "text": " can also choose what size we want.", "tokens": [393, 611, 2826, 437, 2744, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.1322406324846991, "compression_ratio": 1.375, "no_speech_prob": 2.8573092549777357e-06}, {"id": 568, "seek": 373840, "start": 3755.8, "end": 3767.04, "text": " So if you look at my new version of the VGG model, I've actually got something here that", "tokens": [407, 498, 291, 574, 412, 452, 777, 3037, 295, 264, 691, 27561, 2316, 11, 286, 600, 767, 658, 746, 510, 300], "temperature": 0.0, "avg_logprob": -0.1322406324846991, "compression_ratio": 1.375, "no_speech_prob": 2.8573092549777357e-06}, {"id": 569, "seek": 376704, "start": 3767.04, "end": 3777.08, "text": " says if size is not equal to 224x224, then don't try to add the fully connected blocks", "tokens": [1619, 498, 2744, 307, 406, 2681, 281, 5853, 19, 87, 7490, 19, 11, 550, 500, 380, 853, 281, 909, 264, 4498, 4582, 8474], "temperature": 0.0, "avg_logprob": -0.11627114548975108, "compression_ratio": 1.2794117647058822, "no_speech_prob": 1.8448191667630454e-06}, {"id": 570, "seek": 376704, "start": 3777.08, "end": 3791.56, "text": " at all. Just return that. So in other words, if we cut off whatever our architecture is", "tokens": [412, 439, 13, 1449, 2736, 300, 13, 407, 294, 661, 2283, 11, 498, 321, 1723, 766, 2035, 527, 9482, 307], "temperature": 0.0, "avg_logprob": -0.11627114548975108, "compression_ratio": 1.2794117647058822, "no_speech_prob": 1.8448191667630454e-06}, {"id": 571, "seek": 379156, "start": 3791.56, "end": 3798.4, "text": " before any dense layers happen, then we're going to be able to use it on any size input", "tokens": [949, 604, 18011, 7914, 1051, 11, 550, 321, 434, 516, 281, 312, 1075, 281, 764, 309, 322, 604, 2744, 4846], "temperature": 0.0, "avg_logprob": -0.17345880907635355, "compression_ratio": 1.6842105263157894, "no_speech_prob": 2.9023028673691442e-06}, {"id": 572, "seek": 379156, "start": 3798.4, "end": 3805.4, "text": " to at least create those convolutional features. That's what I'm about to show you now.", "tokens": [281, 412, 1935, 1884, 729, 45216, 304, 4122, 13, 663, 311, 437, 286, 478, 466, 281, 855, 291, 586, 13], "temperature": 0.0, "avg_logprob": -0.17345880907635355, "compression_ratio": 1.6842105263157894, "no_speech_prob": 2.9023028673691442e-06}, {"id": 573, "seek": 379156, "start": 3805.4, "end": 3815.44, "text": " There's no particular reason it has to be fixed. A dense layer has to be fixed because", "tokens": [821, 311, 572, 1729, 1778, 309, 575, 281, 312, 6806, 13, 316, 18011, 4583, 575, 281, 312, 6806, 570], "temperature": 0.0, "avg_logprob": -0.17345880907635355, "compression_ratio": 1.6842105263157894, "no_speech_prob": 2.9023028673691442e-06}, {"id": 574, "seek": 379156, "start": 3815.44, "end": 3821.08, "text": " a dense layer has a specific weight matrix. And the input to that weight matrix generally", "tokens": [257, 18011, 4583, 575, 257, 2685, 3364, 8141, 13, 400, 264, 4846, 281, 300, 3364, 8141, 5101], "temperature": 0.0, "avg_logprob": -0.17345880907635355, "compression_ratio": 1.6842105263157894, "no_speech_prob": 2.9023028673691442e-06}, {"id": 575, "seek": 382108, "start": 3821.08, "end": 3826.72, "text": " is the flattened out version of the previous convolutional layer, and the size of that", "tokens": [307, 264, 24183, 292, 484, 3037, 295, 264, 3894, 45216, 304, 4583, 11, 293, 264, 2744, 295, 300], "temperature": 0.0, "avg_logprob": -0.11150524139404297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 3.966970325564034e-06}, {"id": 576, "seek": 382108, "start": 3826.72, "end": 3833.34, "text": " depends on the size of the image. But the convolutional weight matrix simply depends", "tokens": [5946, 322, 264, 2744, 295, 264, 3256, 13, 583, 264, 45216, 304, 3364, 8141, 2935, 5946], "temperature": 0.0, "avg_logprob": -0.11150524139404297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 3.966970325564034e-06}, {"id": 577, "seek": 382108, "start": 3833.34, "end": 3838.6, "text": " on the filter size, not on the image size.", "tokens": [322, 264, 6608, 2744, 11, 406, 322, 264, 3256, 2744, 13], "temperature": 0.0, "avg_logprob": -0.11150524139404297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 3.966970325564034e-06}, {"id": 578, "seek": 382108, "start": 3838.6, "end": 3846.2799999999997, "text": " So let's try it. Specifically, we're going to try building something called a fully convolutional", "tokens": [407, 718, 311, 853, 309, 13, 26058, 11, 321, 434, 516, 281, 853, 2390, 746, 1219, 257, 4498, 45216, 304], "temperature": 0.0, "avg_logprob": -0.11150524139404297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 3.966970325564034e-06}, {"id": 579, "seek": 384628, "start": 3846.28, "end": 3852.84, "text": " net, which is going to have no dense layers at all. So the input, as usual, will be the", "tokens": [2533, 11, 597, 307, 516, 281, 362, 572, 18011, 7914, 412, 439, 13, 407, 264, 4846, 11, 382, 7713, 11, 486, 312, 264], "temperature": 0.0, "avg_logprob": -0.17869227273123606, "compression_ratio": 1.3902439024390243, "no_speech_prob": 8.267828889074735e-06}, {"id": 580, "seek": 384628, "start": 3852.84, "end": 3858.36, "text": " output of the last VGG convolutional layer.", "tokens": [5598, 295, 264, 1036, 691, 27561, 45216, 304, 4583, 13], "temperature": 0.0, "avg_logprob": -0.17869227273123606, "compression_ratio": 1.3902439024390243, "no_speech_prob": 8.267828889074735e-06}, {"id": 581, "seek": 384628, "start": 3858.36, "end": 3876.0400000000004, "text": " But this time, when we create our VGG 16 model, we're going to tell it we want it to be 640x360.", "tokens": [583, 341, 565, 11, 562, 321, 1884, 527, 691, 27561, 3165, 2316, 11, 321, 434, 516, 281, 980, 309, 321, 528, 309, 281, 312, 1386, 5254, 87, 34099, 13], "temperature": 0.0, "avg_logprob": -0.17869227273123606, "compression_ratio": 1.3902439024390243, "no_speech_prob": 8.267828889074735e-06}, {"id": 582, "seek": 387604, "start": 3876.04, "end": 3882.92, "text": " Now be careful here. When we talk about matrices, we talk about rows by columns. When we talk", "tokens": [823, 312, 5026, 510, 13, 1133, 321, 751, 466, 32284, 11, 321, 751, 466, 13241, 538, 13766, 13, 1133, 321, 751], "temperature": 0.0, "avg_logprob": -0.15508734319627898, "compression_ratio": 1.7524752475247525, "no_speech_prob": 4.0694052586331964e-05}, {"id": 583, "seek": 387604, "start": 3882.92, "end": 3892.8, "text": " about images, we talk about columns by rows. So a 640x360 image is a 360x640 matrix. I", "tokens": [466, 5267, 11, 321, 751, 466, 13766, 538, 13241, 13, 407, 257, 1386, 5254, 87, 34099, 3256, 307, 257, 13898, 87, 21, 5254, 8141, 13, 286], "temperature": 0.0, "avg_logprob": -0.15508734319627898, "compression_ratio": 1.7524752475247525, "no_speech_prob": 4.0694052586331964e-05}, {"id": 584, "seek": 387604, "start": 3892.8, "end": 3897.16, "text": " mention this because I screwed it up. But I knew I screwed it up because I always draw", "tokens": [2152, 341, 570, 286, 20331, 309, 493, 13, 583, 286, 2586, 286, 20331, 309, 493, 570, 286, 1009, 2642], "temperature": 0.0, "avg_logprob": -0.15508734319627898, "compression_ratio": 1.7524752475247525, "no_speech_prob": 4.0694052586331964e-05}, {"id": 585, "seek": 387604, "start": 3897.16, "end": 3903.12, "text": " pictures. So when I drew the picture and I saw I had this little squashed boat, I knew", "tokens": [5242, 13, 407, 562, 286, 12804, 264, 3036, 293, 286, 1866, 286, 632, 341, 707, 2339, 12219, 6582, 11, 286, 2586], "temperature": 0.0, "avg_logprob": -0.15508734319627898, "compression_ratio": 1.7524752475247525, "no_speech_prob": 4.0694052586331964e-05}, {"id": 586, "seek": 390312, "start": 3903.12, "end": 3910.96, "text": " I screwed it up.", "tokens": [286, 20331, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.1882519787305022, "compression_ratio": 1.365979381443299, "no_speech_prob": 2.2125237592263147e-05}, {"id": 587, "seek": 390312, "start": 3910.96, "end": 3916.56, "text": " This is the exact same VGG 16 network we've been using since I added BatchNorm. Nothing's", "tokens": [639, 307, 264, 1900, 912, 691, 27561, 3165, 3209, 321, 600, 668, 1228, 1670, 286, 3869, 363, 852, 45, 687, 13, 6693, 311], "temperature": 0.0, "avg_logprob": -0.1882519787305022, "compression_ratio": 1.365979381443299, "no_speech_prob": 2.2125237592263147e-05}, {"id": 588, "seek": 390312, "start": 3916.56, "end": 3921.7999999999997, "text": " been changed other than this one piece of code I just showed you, which says you can", "tokens": [668, 3105, 661, 813, 341, 472, 2522, 295, 3089, 286, 445, 4712, 291, 11, 597, 1619, 291, 393], "temperature": 0.0, "avg_logprob": -0.1882519787305022, "compression_ratio": 1.365979381443299, "no_speech_prob": 2.2125237592263147e-05}, {"id": 589, "seek": 390312, "start": 3921.7999999999997, "end": 3931.4, "text": " use different sizes, and if you do, don't add the fully connected layers.", "tokens": [764, 819, 11602, 11, 293, 498, 291, 360, 11, 500, 380, 909, 264, 4498, 4582, 7914, 13], "temperature": 0.0, "avg_logprob": -0.1882519787305022, "compression_ratio": 1.365979381443299, "no_speech_prob": 2.2125237592263147e-05}, {"id": 590, "seek": 393140, "start": 3931.4, "end": 3941.28, "text": " So now that I've got this VGG model, which is expecting a 640x360 input, I can then add", "tokens": [407, 586, 300, 286, 600, 658, 341, 691, 27561, 2316, 11, 597, 307, 9650, 257, 1386, 5254, 87, 34099, 4846, 11, 286, 393, 550, 909], "temperature": 0.0, "avg_logprob": -0.11808385966736594, "compression_ratio": 1.4530386740331491, "no_speech_prob": 7.646478479728103e-06}, {"id": 591, "seek": 393140, "start": 3941.28, "end": 3949.44, "text": " to it my top layers. And this time, my top layers are going to get in an input which", "tokens": [281, 309, 452, 1192, 7914, 13, 400, 341, 565, 11, 452, 1192, 7914, 366, 516, 281, 483, 294, 364, 4846, 597], "temperature": 0.0, "avg_logprob": -0.11808385966736594, "compression_ratio": 1.4530386740331491, "no_speech_prob": 7.646478479728103e-06}, {"id": 592, "seek": 393140, "start": 3949.44, "end": 3959.88, "text": " is of size 22x40. So normally, our VGG's final layer is 14x14, or if you include the final", "tokens": [307, 295, 2744, 5853, 87, 5254, 13, 407, 5646, 11, 527, 691, 27561, 311, 2572, 4583, 307, 3499, 87, 7271, 11, 420, 498, 291, 4090, 264, 2572], "temperature": 0.0, "avg_logprob": -0.11808385966736594, "compression_ratio": 1.4530386740331491, "no_speech_prob": 7.646478479728103e-06}, {"id": 593, "seek": 395988, "start": 3959.88, "end": 3963.92, "text": " max pooling, it's 7x7.", "tokens": [11469, 7005, 278, 11, 309, 311, 1614, 87, 22, 13], "temperature": 0.0, "avg_logprob": -0.19278272986412048, "compression_ratio": 1.680161943319838, "no_speech_prob": 6.854274943179917e-06}, {"id": 594, "seek": 395988, "start": 3963.92, "end": 3970.6400000000003, "text": " In this case, it's 22x40, and that's because we're not going to pass it a 224x224, we're", "tokens": [682, 341, 1389, 11, 309, 311, 5853, 87, 5254, 11, 293, 300, 311, 570, 321, 434, 406, 516, 281, 1320, 309, 257, 5853, 19, 87, 7490, 19, 11, 321, 434], "temperature": 0.0, "avg_logprob": -0.19278272986412048, "compression_ratio": 1.680161943319838, "no_speech_prob": 6.854274943179917e-06}, {"id": 595, "seek": 395988, "start": 3970.6400000000003, "end": 3976.56, "text": " going to pass it a 640x360. So this is what happens. We end up with a different output", "tokens": [516, 281, 1320, 309, 257, 1386, 5254, 87, 34099, 13, 407, 341, 307, 437, 2314, 13, 492, 917, 493, 365, 257, 819, 5598], "temperature": 0.0, "avg_logprob": -0.19278272986412048, "compression_ratio": 1.680161943319838, "no_speech_prob": 6.854274943179917e-06}, {"id": 596, "seek": 395988, "start": 3976.56, "end": 3981.32, "text": " shape. So if we now try to pass that to the same dense layer we used before, it wouldn't", "tokens": [3909, 13, 407, 498, 321, 586, 853, 281, 1320, 300, 281, 264, 912, 18011, 4583, 321, 1143, 949, 11, 309, 2759, 380], "temperature": 0.0, "avg_logprob": -0.19278272986412048, "compression_ratio": 1.680161943319838, "no_speech_prob": 6.854274943179917e-06}, {"id": 597, "seek": 395988, "start": 3981.32, "end": 3982.8, "text": " work, so it would be the wrong size.", "tokens": [589, 11, 370, 309, 576, 312, 264, 2085, 2744, 13], "temperature": 0.0, "avg_logprob": -0.19278272986412048, "compression_ratio": 1.680161943319838, "no_speech_prob": 6.854274943179917e-06}, {"id": 598, "seek": 395988, "start": 3982.8, "end": 3987.36, "text": " But we're actually going to do something very different anyway. We're not going to use any", "tokens": [583, 321, 434, 767, 516, 281, 360, 746, 588, 819, 4033, 13, 492, 434, 406, 516, 281, 764, 604], "temperature": 0.0, "avg_logprob": -0.19278272986412048, "compression_ratio": 1.680161943319838, "no_speech_prob": 6.854274943179917e-06}, {"id": 599, "seek": 398736, "start": 3987.36, "end": 3994.88, "text": " pre-trained fully connected weights. We're instead going to have, in fact, no dense layers", "tokens": [659, 12, 17227, 2001, 4498, 4582, 17443, 13, 492, 434, 2602, 516, 281, 362, 11, 294, 1186, 11, 572, 18011, 7914], "temperature": 0.0, "avg_logprob": -0.16084667693736943, "compression_ratio": 1.7362637362637363, "no_speech_prob": 1.1659443771350197e-05}, {"id": 600, "seek": 398736, "start": 3994.88, "end": 4001.32, "text": " at all. Instead, we're going to go conv batch norm max pool, conv batch norm max pool, conv", "tokens": [412, 439, 13, 7156, 11, 321, 434, 516, 281, 352, 3754, 15245, 2026, 11469, 7005, 11, 3754, 15245, 2026, 11469, 7005, 11, 3754], "temperature": 0.0, "avg_logprob": -0.16084667693736943, "compression_ratio": 1.7362637362637363, "no_speech_prob": 1.1659443771350197e-05}, {"id": 601, "seek": 398736, "start": 4001.32, "end": 4007.1600000000003, "text": " batch norm max pool, conv global average pooling.", "tokens": [15245, 2026, 11469, 7005, 11, 3754, 4338, 4274, 7005, 278, 13], "temperature": 0.0, "avg_logprob": -0.16084667693736943, "compression_ratio": 1.7362637362637363, "no_speech_prob": 1.1659443771350197e-05}, {"id": 602, "seek": 398736, "start": 4007.1600000000003, "end": 4013.8, "text": " So the best way to look at that is to see what's happening to our shape. So it goes", "tokens": [407, 264, 1151, 636, 281, 574, 412, 300, 307, 281, 536, 437, 311, 2737, 281, 527, 3909, 13, 407, 309, 1709], "temperature": 0.0, "avg_logprob": -0.16084667693736943, "compression_ratio": 1.7362637362637363, "no_speech_prob": 1.1659443771350197e-05}, {"id": 603, "seek": 401380, "start": 4013.8, "end": 4023.1200000000003, "text": " from 22x40 until the max pooling, 11x20, 5x10, and because this is rectangular, the last", "tokens": [490, 5853, 87, 5254, 1826, 264, 11469, 7005, 278, 11, 2975, 87, 2009, 11, 1025, 87, 3279, 11, 293, 570, 341, 307, 31167, 11, 264, 1036], "temperature": 0.0, "avg_logprob": -0.19777793150681716, "compression_ratio": 1.3681318681318682, "no_speech_prob": 1.0511487289477373e-06}, {"id": 604, "seek": 401380, "start": 4023.1200000000003, "end": 4032.8, "text": " max pooling I did a 1,2 shape, so that gives me a square result, so 5x5.", "tokens": [11469, 7005, 278, 286, 630, 257, 502, 11, 17, 3909, 11, 370, 300, 2709, 385, 257, 3732, 1874, 11, 370, 1025, 87, 20, 13], "temperature": 0.0, "avg_logprob": -0.19777793150681716, "compression_ratio": 1.3681318681318682, "no_speech_prob": 1.0511487289477373e-06}, {"id": 605, "seek": 401380, "start": 4032.8, "end": 4039.4, "text": " Then I do a convolutional layer in which I have just 8 filters. And remember, there are", "tokens": [1396, 286, 360, 257, 45216, 304, 4583, 294, 597, 286, 362, 445, 1649, 15995, 13, 400, 1604, 11, 456, 366], "temperature": 0.0, "avg_logprob": -0.19777793150681716, "compression_ratio": 1.3681318681318682, "no_speech_prob": 1.0511487289477373e-06}, {"id": 606, "seek": 403940, "start": 4039.4, "end": 4045.08, "text": " 8 types of fish. There are no other weights after this. And in fact, even the dropout", "tokens": [1649, 3467, 295, 3506, 13, 821, 366, 572, 661, 17443, 934, 341, 13, 400, 294, 1186, 11, 754, 264, 3270, 346], "temperature": 0.0, "avg_logprob": -0.1327421063574675, "compression_ratio": 1.5889830508474576, "no_speech_prob": 7.76691194914747e-06}, {"id": 607, "seek": 403940, "start": 4045.08, "end": 4051.28, "text": " is not doing anything because I've set my p-value to 0. So ignore that dropout layer.", "tokens": [307, 406, 884, 1340, 570, 286, 600, 992, 452, 280, 12, 29155, 281, 1958, 13, 407, 11200, 300, 3270, 346, 4583, 13], "temperature": 0.0, "avg_logprob": -0.1327421063574675, "compression_ratio": 1.5889830508474576, "no_speech_prob": 7.76691194914747e-06}, {"id": 608, "seek": 403940, "start": 4051.28, "end": 4056.4, "text": " So we're going straight from a convolutional layer, which is going to be grid-size 5x5", "tokens": [407, 321, 434, 516, 2997, 490, 257, 45216, 304, 4583, 11, 597, 307, 516, 281, 312, 10748, 12, 27553, 1025, 87, 20], "temperature": 0.0, "avg_logprob": -0.1327421063574675, "compression_ratio": 1.5889830508474576, "no_speech_prob": 7.76691194914747e-06}, {"id": 609, "seek": 403940, "start": 4056.4, "end": 4062.7200000000003, "text": " and have 8 filters, and then we're going to average across the 5x5, and that's going to", "tokens": [293, 362, 1649, 15995, 11, 293, 550, 321, 434, 516, 281, 4274, 2108, 264, 1025, 87, 20, 11, 293, 300, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.1327421063574675, "compression_ratio": 1.5889830508474576, "no_speech_prob": 7.76691194914747e-06}, {"id": 610, "seek": 403940, "start": 4062.7200000000003, "end": 4067.84, "text": " give us something of size 8.", "tokens": [976, 505, 746, 295, 2744, 1649, 13], "temperature": 0.0, "avg_logprob": -0.1327421063574675, "compression_ratio": 1.5889830508474576, "no_speech_prob": 7.76691194914747e-06}, {"id": 611, "seek": 406784, "start": 4067.84, "end": 4073.48, "text": " So if we now say, please train this model, and please try and make these 8 things equal", "tokens": [407, 498, 321, 586, 584, 11, 1767, 3847, 341, 2316, 11, 293, 1767, 853, 293, 652, 613, 1649, 721, 2681], "temperature": 0.0, "avg_logprob": -0.1288549057160965, "compression_ratio": 1.6181818181818182, "no_speech_prob": 5.77189848627313e-06}, {"id": 612, "seek": 406784, "start": 4073.48, "end": 4079.98, "text": " to the classes of fish. Now you have to think backwards. How would it do that? If it was", "tokens": [281, 264, 5359, 295, 3506, 13, 823, 291, 362, 281, 519, 12204, 13, 1012, 576, 309, 360, 300, 30, 759, 309, 390], "temperature": 0.0, "avg_logprob": -0.1288549057160965, "compression_ratio": 1.6181818181818182, "no_speech_prob": 5.77189848627313e-06}, {"id": 613, "seek": 406784, "start": 4079.98, "end": 4085.84, "text": " to do that for us, and it will because it's going to use SGD, what would it have to do?", "tokens": [281, 360, 300, 337, 505, 11, 293, 309, 486, 570, 309, 311, 516, 281, 764, 34520, 35, 11, 437, 576, 309, 362, 281, 360, 30], "temperature": 0.0, "avg_logprob": -0.1288549057160965, "compression_ratio": 1.6181818181818182, "no_speech_prob": 5.77189848627313e-06}, {"id": 614, "seek": 406784, "start": 4085.84, "end": 4093.36, "text": " Well, it has no ability to use any weights to get to this point, so it has to do everything", "tokens": [1042, 11, 309, 575, 572, 3485, 281, 764, 604, 17443, 281, 483, 281, 341, 935, 11, 370, 309, 575, 281, 360, 1203], "temperature": 0.0, "avg_logprob": -0.1288549057160965, "compression_ratio": 1.6181818181818182, "no_speech_prob": 5.77189848627313e-06}, {"id": 615, "seek": 409336, "start": 4093.36, "end": 4098.4400000000005, "text": " by the time it gets to this point. Which means this convolution 2D layer is going to have", "tokens": [538, 264, 565, 309, 2170, 281, 341, 935, 13, 3013, 1355, 341, 45216, 568, 35, 4583, 307, 516, 281, 362], "temperature": 0.0, "avg_logprob": -0.17237773694490133, "compression_ratio": 1.660649819494585, "no_speech_prob": 4.860425178776495e-06}, {"id": 616, "seek": 409336, "start": 4098.4400000000005, "end": 4104.32, "text": " to have in each of its 5 grid areas something saying how fishy is that area. Because that's", "tokens": [281, 362, 294, 1184, 295, 1080, 1025, 10748, 3179, 746, 1566, 577, 41991, 307, 300, 1859, 13, 1436, 300, 311], "temperature": 0.0, "avg_logprob": -0.17237773694490133, "compression_ratio": 1.660649819494585, "no_speech_prob": 4.860425178776495e-06}, {"id": 617, "seek": 409336, "start": 4104.32, "end": 4108.92, "text": " all it can do. After that, all it can do is to average them together.", "tokens": [439, 309, 393, 360, 13, 2381, 300, 11, 439, 309, 393, 360, 307, 281, 4274, 552, 1214, 13], "temperature": 0.0, "avg_logprob": -0.17237773694490133, "compression_ratio": 1.660649819494585, "no_speech_prob": 4.860425178776495e-06}, {"id": 618, "seek": 409336, "start": 4108.92, "end": 4114.0, "text": " So we haven't done anything specifically to calculate it that way. We just created an", "tokens": [407, 321, 2378, 380, 1096, 1340, 4682, 281, 8873, 309, 300, 636, 13, 492, 445, 2942, 364], "temperature": 0.0, "avg_logprob": -0.17237773694490133, "compression_ratio": 1.660649819494585, "no_speech_prob": 4.860425178776495e-06}, {"id": 619, "seek": 409336, "start": 4114.0, "end": 4116.72, "text": " architecture which has to do that.", "tokens": [9482, 597, 575, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.17237773694490133, "compression_ratio": 1.660649819494585, "no_speech_prob": 4.860425178776495e-06}, {"id": 620, "seek": 409336, "start": 4116.72, "end": 4122.0, "text": " My feeling is that ought to work pretty well because as we saw in that earlier picture,", "tokens": [1222, 2633, 307, 300, 13416, 281, 589, 1238, 731, 570, 382, 321, 1866, 294, 300, 3071, 3036, 11], "temperature": 0.0, "avg_logprob": -0.17237773694490133, "compression_ratio": 1.660649819494585, "no_speech_prob": 4.860425178776495e-06}, {"id": 621, "seek": 412200, "start": 4122.0, "end": 4125.48, "text": " the fish only appears in one little spot. And indeed, as we discussed earlier, maybe", "tokens": [264, 3506, 787, 7038, 294, 472, 707, 4008, 13, 400, 6451, 11, 382, 321, 7152, 3071, 11, 1310], "temperature": 0.0, "avg_logprob": -0.17094014638877778, "compression_ratio": 1.4694835680751173, "no_speech_prob": 1.4738859135832172e-05}, {"id": 622, "seek": 412200, "start": 4125.48, "end": 4130.56, "text": " even a global max pooling could be better.", "tokens": [754, 257, 4338, 11469, 7005, 278, 727, 312, 1101, 13], "temperature": 0.0, "avg_logprob": -0.17094014638877778, "compression_ratio": 1.4694835680751173, "no_speech_prob": 1.4738859135832172e-05}, {"id": 623, "seek": 412200, "start": 4130.56, "end": 4136.24, "text": " So let's try this. We can fit it as per usual, and you can see here, even without using bounding", "tokens": [407, 718, 311, 853, 341, 13, 492, 393, 3318, 309, 382, 680, 7713, 11, 293, 291, 393, 536, 510, 11, 754, 1553, 1228, 5472, 278], "temperature": 0.0, "avg_logprob": -0.17094014638877778, "compression_ratio": 1.4694835680751173, "no_speech_prob": 1.4738859135832172e-05}, {"id": 624, "seek": 412200, "start": 4136.24, "end": 4146.64, "text": " boxes, we've got a pretty stable and pretty good result in about 30 seconds. When I then", "tokens": [9002, 11, 321, 600, 658, 257, 1238, 8351, 293, 1238, 665, 1874, 294, 466, 2217, 3949, 13, 1133, 286, 550], "temperature": 0.0, "avg_logprob": -0.17094014638877778, "compression_ratio": 1.4694835680751173, "no_speech_prob": 1.4738859135832172e-05}, {"id": 625, "seek": 414664, "start": 4146.64, "end": 4161.320000000001, "text": " tried this on the Kaggle leaderboard, I got a much better result.", "tokens": [3031, 341, 322, 264, 48751, 22631, 5263, 3787, 11, 286, 658, 257, 709, 1101, 1874, 13], "temperature": 0.0, "avg_logprob": -0.21199862162272134, "compression_ratio": 1.220472440944882, "no_speech_prob": 6.339173523883801e-06}, {"id": 626, "seek": 414664, "start": 4161.320000000001, "end": 4167.64, "text": " The 20th place was me just averaging together 4 of the models that I'm showing you today.", "tokens": [440, 945, 392, 1081, 390, 385, 445, 47308, 1214, 1017, 295, 264, 5245, 300, 286, 478, 4099, 291, 965, 13], "temperature": 0.0, "avg_logprob": -0.21199862162272134, "compression_ratio": 1.220472440944882, "no_speech_prob": 6.339173523883801e-06}, {"id": 627, "seek": 416764, "start": 4167.64, "end": 4191.56, "text": " But this one on its own was 0.986, which would be 20 seconds. So that little model on its", "tokens": [583, 341, 472, 322, 1080, 1065, 390, 1958, 13, 24, 22193, 11, 597, 576, 312, 945, 3949, 13, 407, 300, 707, 2316, 322, 1080], "temperature": 0.0, "avg_logprob": -0.2118497405733381, "compression_ratio": 1.0348837209302326, "no_speech_prob": 5.862765192432562e-06}, {"id": 628, "seek": 419156, "start": 4191.56, "end": 4198.280000000001, "text": " own would get us 20 seconds. No data augmentation, no pseudo-labeling, we're not using the validation", "tokens": [1065, 576, 483, 505, 945, 3949, 13, 883, 1412, 14501, 19631, 11, 572, 35899, 12, 44990, 11031, 11, 321, 434, 406, 1228, 264, 24071], "temperature": 0.0, "avg_logprob": -0.187494978612783, "compression_ratio": 1.6707818930041152, "no_speech_prob": 4.222782081342302e-06}, {"id": 629, "seek": 419156, "start": 4198.280000000001, "end": 4205.400000000001, "text": " set to help us, which you should when you do your final Kaggle entry. So you can get", "tokens": [992, 281, 854, 505, 11, 597, 291, 820, 562, 291, 360, 428, 2572, 48751, 22631, 8729, 13, 407, 291, 393, 483], "temperature": 0.0, "avg_logprob": -0.187494978612783, "compression_ratio": 1.6707818930041152, "no_speech_prob": 4.222782081342302e-06}, {"id": 630, "seek": 419156, "start": 4205.400000000001, "end": 4210.76, "text": " 20 seconds position with this very simple approach, which is to use a slightly larger", "tokens": [945, 3949, 2535, 365, 341, 588, 2199, 3109, 11, 597, 307, 281, 764, 257, 4748, 4833], "temperature": 0.0, "avg_logprob": -0.187494978612783, "compression_ratio": 1.6707818930041152, "no_speech_prob": 4.222782081342302e-06}, {"id": 631, "seek": 419156, "start": 4210.76, "end": 4214.64, "text": " image and use a fully convolutional network.", "tokens": [3256, 293, 764, 257, 4498, 45216, 304, 3209, 13], "temperature": 0.0, "avg_logprob": -0.187494978612783, "compression_ratio": 1.6707818930041152, "no_speech_prob": 4.222782081342302e-06}, {"id": 632, "seek": 419156, "start": 4214.64, "end": 4219.0, "text": " There's something else cool about this fully convolutional network which can get us into", "tokens": [821, 311, 746, 1646, 1627, 466, 341, 4498, 45216, 304, 3209, 597, 393, 483, 505, 666], "temperature": 0.0, "avg_logprob": -0.187494978612783, "compression_ratio": 1.6707818930041152, "no_speech_prob": 4.222782081342302e-06}, {"id": 633, "seek": 421900, "start": 4219.0, "end": 4239.84, "text": " a 20 second position, and that is that we can actually look at the output of this layout.", "tokens": [257, 945, 1150, 2535, 11, 293, 300, 307, 300, 321, 393, 767, 574, 412, 264, 5598, 295, 341, 13333, 13], "temperature": 0.0, "avg_logprob": -0.23100486009017282, "compression_ratio": 1.3082706766917294, "no_speech_prob": 1.4285314136941452e-05}, {"id": 634, "seek": 421900, "start": 4239.84, "end": 4247.12, "text": " As always before, VGG is the input to this model. So I first of all calculated every", "tokens": [1018, 1009, 949, 11, 691, 27561, 307, 264, 4846, 281, 341, 2316, 13, 407, 286, 700, 295, 439, 15598, 633], "temperature": 0.0, "avg_logprob": -0.23100486009017282, "compression_ratio": 1.3082706766917294, "no_speech_prob": 1.4285314136941452e-05}, {"id": 635, "seek": 424712, "start": 4247.12, "end": 4252.08, "text": " single model I'm showing you today, I pre-computed the output of the last convolutional layout", "tokens": [2167, 2316, 286, 478, 4099, 291, 965, 11, 286, 659, 12, 1112, 2582, 292, 264, 5598, 295, 264, 1036, 45216, 304, 13333], "temperature": 0.0, "avg_logprob": -0.37096017599105835, "compression_ratio": 1.1063829787234043, "no_speech_prob": 4.469256236916408e-05}, {"id": 636, "seek": 424712, "start": 4252.08, "end": 4253.08, "text": " with VGG.", "tokens": [365, 691, 27561, 13], "temperature": 0.0, "avg_logprob": -0.37096017599105835, "compression_ratio": 1.1063829787234043, "no_speech_prob": 4.469256236916408e-05}, {"id": 637, "seek": 425308, "start": 4253.08, "end": 4279.88, "text": " I go get data, I want to get a 360,640 size data, so that gives me my image. I then create", "tokens": [286, 352, 483, 1412, 11, 286, 528, 281, 483, 257, 13898, 11, 21, 5254, 2744, 1412, 11, 370, 300, 2709, 385, 452, 3256, 13, 286, 550, 1884], "temperature": 0.0, "avg_logprob": -0.35729346736784906, "compression_ratio": 1.0975609756097562, "no_speech_prob": 2.6273255571140908e-05}, {"id": 638, "seek": 427988, "start": 4279.88, "end": 4285.96, "text": " my model, pop off the last layout, I don't want the last max pooling layout, so that's", "tokens": [452, 2316, 11, 1665, 766, 264, 1036, 13333, 11, 286, 500, 380, 528, 264, 1036, 11469, 7005, 278, 13333, 11, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.20111380683051217, "compression_ratio": 1.4943181818181819, "no_speech_prob": 1.4970860320318025e-05}, {"id": 639, "seek": 427988, "start": 4285.96, "end": 4299.16, "text": " the size. And then call predict to get the features from that last layout. So it's what", "tokens": [264, 2744, 13, 400, 550, 818, 6069, 281, 483, 264, 4122, 490, 300, 1036, 13333, 13, 407, 309, 311, 437], "temperature": 0.0, "avg_logprob": -0.20111380683051217, "compression_ratio": 1.4943181818181819, "no_speech_prob": 1.4970860320318025e-05}, {"id": 640, "seek": 427988, "start": 4299.16, "end": 4304.76, "text": " we always do. It's just the only difference is that we passed 360,640 to our constructor", "tokens": [321, 1009, 360, 13, 467, 311, 445, 264, 787, 2649, 307, 300, 321, 4678, 13898, 11, 21, 5254, 281, 527, 47479], "temperature": 0.0, "avg_logprob": -0.20111380683051217, "compression_ratio": 1.4943181818181819, "no_speech_prob": 1.4970860320318025e-05}, {"id": 641, "seek": 430476, "start": 4304.76, "end": 4314.360000000001, "text": " for the model and we passed 360,640 to the get data command.", "tokens": [337, 264, 2316, 293, 321, 4678, 13898, 11, 21, 5254, 281, 264, 483, 1412, 5622, 13], "temperature": 0.0, "avg_logprob": -0.3044476325695331, "compression_ratio": 1.2857142857142858, "no_speech_prob": 4.133355832891539e-05}, {"id": 642, "seek": 430476, "start": 4314.360000000001, "end": 4325.280000000001, "text": " So I'm always skipping that bit, but everything I'm showing you today is taking as input the", "tokens": [407, 286, 478, 1009, 31533, 300, 857, 11, 457, 1203, 286, 478, 4099, 291, 965, 307, 1940, 382, 4846, 264], "temperature": 0.0, "avg_logprob": -0.3044476325695331, "compression_ratio": 1.2857142857142858, "no_speech_prob": 4.133355832891539e-05}, {"id": 643, "seek": 430476, "start": 4325.280000000001, "end": 4327.400000000001, "text": " last convolutional layout from VGG.", "tokens": [1036, 45216, 304, 13333, 490, 691, 27561, 13], "temperature": 0.0, "avg_logprob": -0.3044476325695331, "compression_ratio": 1.2857142857142858, "no_speech_prob": 4.133355832891539e-05}, {"id": 644, "seek": 432740, "start": 4327.4, "end": 4335.599999999999, "text": " Question. Why did we replace all dense layers with CNNs?", "tokens": [14464, 13, 1545, 630, 321, 7406, 439, 18011, 7914, 365, 24859, 82, 30], "temperature": 0.0, "avg_logprob": -0.2531495280080027, "compression_ratio": 1.4375, "no_speech_prob": 1.8342474504606798e-05}, {"id": 645, "seek": 432740, "start": 4335.599999999999, "end": 4340.08, "text": " A couple of reasons why. The first is because the authors of the paper, which created the", "tokens": [316, 1916, 295, 4112, 983, 13, 440, 700, 307, 570, 264, 16552, 295, 264, 3035, 11, 597, 2942, 264], "temperature": 0.0, "avg_logprob": -0.2531495280080027, "compression_ratio": 1.4375, "no_speech_prob": 1.8342474504606798e-05}, {"id": 646, "seek": 432740, "start": 4340.08, "end": 4347.44, "text": " fully convolutional net, found that it worked pretty well. The global average pooling 2D", "tokens": [4498, 45216, 304, 2533, 11, 1352, 300, 309, 2732, 1238, 731, 13, 440, 4338, 4274, 7005, 278, 568, 35], "temperature": 0.0, "avg_logprob": -0.2531495280080027, "compression_ratio": 1.4375, "no_speech_prob": 1.8342474504606798e-05}, {"id": 647, "seek": 432740, "start": 4347.44, "end": 4351.08, "text": " layer, as we've discussed, turns out to have excellent generalization characteristics.", "tokens": [4583, 11, 382, 321, 600, 7152, 11, 4523, 484, 281, 362, 7103, 2674, 2144, 10891, 13], "temperature": 0.0, "avg_logprob": -0.2531495280080027, "compression_ratio": 1.4375, "no_speech_prob": 1.8342474504606798e-05}, {"id": 648, "seek": 435108, "start": 4351.08, "end": 4358.48, "text": " So you'll notice here we have no dropout, and yet we're in 22nd place on the leaderboard", "tokens": [407, 291, 603, 3449, 510, 321, 362, 572, 3270, 346, 11, 293, 1939, 321, 434, 294, 5853, 273, 1081, 322, 264, 5263, 3787], "temperature": 0.0, "avg_logprob": -0.17888426169370994, "compression_ratio": 1.515, "no_speech_prob": 5.7718661992112175e-06}, {"id": 649, "seek": 435108, "start": 4358.48, "end": 4362.4, "text": " without even beginning to try.", "tokens": [1553, 754, 2863, 281, 853, 13], "temperature": 0.0, "avg_logprob": -0.17888426169370994, "compression_ratio": 1.515, "no_speech_prob": 5.7718661992112175e-06}, {"id": 650, "seek": 435108, "start": 4362.4, "end": 4366.72, "text": " And then the final reason is the thing I'm about to show you, which is that we basically", "tokens": [400, 550, 264, 2572, 1778, 307, 264, 551, 286, 478, 466, 281, 855, 291, 11, 597, 307, 300, 321, 1936], "temperature": 0.0, "avg_logprob": -0.17888426169370994, "compression_ratio": 1.515, "no_speech_prob": 5.7718661992112175e-06}, {"id": 651, "seek": 435108, "start": 4366.72, "end": 4377.14, "text": " have maintained a sense of kind of XY coordinates all the way through, which means that we can", "tokens": [362, 17578, 257, 2020, 295, 733, 295, 48826, 21056, 439, 264, 636, 807, 11, 597, 1355, 300, 321, 393], "temperature": 0.0, "avg_logprob": -0.17888426169370994, "compression_ratio": 1.515, "no_speech_prob": 5.7718661992112175e-06}, {"id": 652, "seek": 437714, "start": 4377.14, "end": 4385.42, "text": " actually now visualize this last layer.", "tokens": [767, 586, 23273, 341, 1036, 4583, 13], "temperature": 0.0, "avg_logprob": -0.2613878055494659, "compression_ratio": 1.4087591240875912, "no_speech_prob": 2.9772672860417515e-05}, {"id": 653, "seek": 437714, "start": 4385.42, "end": 4394.08, "text": " So I can say, let's create a function which takes our model's input as input and our fourth", "tokens": [407, 286, 393, 584, 11, 718, 311, 1884, 257, 2445, 597, 2516, 527, 2316, 311, 4846, 382, 4846, 293, 527, 6409], "temperature": 0.0, "avg_logprob": -0.2613878055494659, "compression_ratio": 1.4087591240875912, "no_speech_prob": 2.9772672860417515e-05}, {"id": 654, "seek": 437714, "start": 4394.08, "end": 4399.76, "text": " from last layer as output, that is that convolutional layout.", "tokens": [490, 1036, 4583, 382, 5598, 11, 300, 307, 300, 45216, 304, 13333, 13], "temperature": 0.0, "avg_logprob": -0.2613878055494659, "compression_ratio": 1.4087591240875912, "no_speech_prob": 2.9772672860417515e-05}, {"id": 655, "seek": 439976, "start": 4399.76, "end": 4408.84, "text": " And then I'm going to take that and I'm going to pass into it the features of my first validation", "tokens": [400, 550, 286, 478, 516, 281, 747, 300, 293, 286, 478, 516, 281, 1320, 666, 309, 264, 4122, 295, 452, 700, 24071], "temperature": 0.0, "avg_logprob": -0.15738208205611617, "compression_ratio": 1.6428571428571428, "no_speech_prob": 4.029425326734781e-06}, {"id": 656, "seek": 439976, "start": 4408.84, "end": 4417.6, "text": " image and draw a picture of it for this picture. And here is my picture.", "tokens": [3256, 293, 2642, 257, 3036, 295, 309, 337, 341, 3036, 13, 400, 510, 307, 452, 3036, 13], "temperature": 0.0, "avg_logprob": -0.15738208205611617, "compression_ratio": 1.6428571428571428, "no_speech_prob": 4.029425326734781e-06}, {"id": 657, "seek": 439976, "start": 4417.6, "end": 4421.14, "text": " And so you can see it's done exactly what we thought it would do, which is it's had", "tokens": [400, 370, 291, 393, 536, 309, 311, 1096, 2293, 437, 321, 1194, 309, 576, 360, 11, 597, 307, 309, 311, 632], "temperature": 0.0, "avg_logprob": -0.15738208205611617, "compression_ratio": 1.6428571428571428, "no_speech_prob": 4.029425326734781e-06}, {"id": 658, "seek": 439976, "start": 4421.14, "end": 4426.04, "text": " to figure out that there's a fishy bit here.", "tokens": [281, 2573, 484, 300, 456, 311, 257, 41991, 857, 510, 13], "temperature": 0.0, "avg_logprob": -0.15738208205611617, "compression_ratio": 1.6428571428571428, "no_speech_prob": 4.029425326734781e-06}, {"id": 659, "seek": 442604, "start": 4426.04, "end": 4432.32, "text": " So these fully convolutional networks have a nice side effect, which is that they allow", "tokens": [407, 613, 4498, 45216, 304, 9590, 362, 257, 1481, 1252, 1802, 11, 597, 307, 300, 436, 2089], "temperature": 0.0, "avg_logprob": -0.25932552113252527, "compression_ratio": 1.506787330316742, "no_speech_prob": 6.540382855746429e-06}, {"id": 660, "seek": 442604, "start": 4432.32, "end": 4439.92, "text": " us to find whereabouts the interesting parts are.", "tokens": [505, 281, 915, 689, 41620, 264, 1880, 3166, 366, 13], "temperature": 0.0, "avg_logprob": -0.25932552113252527, "compression_ratio": 1.506787330316742, "no_speech_prob": 6.540382855746429e-06}, {"id": 661, "seek": 442604, "start": 4439.92, "end": 4446.0, "text": " Question- Why does max pooling reduce the dimensions along the X and Y to half what", "tokens": [14464, 12, 1545, 775, 11469, 7005, 278, 5407, 264, 12819, 2051, 264, 1783, 293, 398, 281, 1922, 437], "temperature": 0.0, "avg_logprob": -0.25932552113252527, "compression_ratio": 1.506787330316742, "no_speech_prob": 6.540382855746429e-06}, {"id": 662, "seek": 442604, "start": 4446.0, "end": 4447.0, "text": " they were previously?", "tokens": [436, 645, 8046, 30], "temperature": 0.0, "avg_logprob": -0.25932552113252527, "compression_ratio": 1.506787330316742, "no_speech_prob": 6.540382855746429e-06}, {"id": 663, "seek": 442604, "start": 4447.0, "end": 4453.48, "text": " Answer- The default parameters of max pooling are 2,2, so it's taking each 2x2 square and", "tokens": [24545, 12, 440, 7576, 9834, 295, 11469, 7005, 278, 366, 568, 11, 17, 11, 370, 309, 311, 1940, 1184, 568, 87, 17, 3732, 293], "temperature": 0.0, "avg_logprob": -0.25932552113252527, "compression_ratio": 1.506787330316742, "no_speech_prob": 6.540382855746429e-06}, {"id": 664, "seek": 445348, "start": 4453.48, "end": 4458.5199999999995, "text": " replacing it with the largest value in that 2x2 square.", "tokens": [19139, 309, 365, 264, 6443, 2158, 294, 300, 568, 87, 17, 3732, 13], "temperature": 0.0, "avg_logprob": -0.14209863489324395, "compression_ratio": 1.7155172413793103, "no_speech_prob": 7.690364327572752e-07}, {"id": 665, "seek": 445348, "start": 4458.5199999999995, "end": 4463.36, "text": " So this is not the most high-res heatmap we've ever seen. So the obvious thing to make it", "tokens": [407, 341, 307, 406, 264, 881, 1090, 12, 495, 3738, 24223, 321, 600, 1562, 1612, 13, 407, 264, 6322, 551, 281, 652, 309], "temperature": 0.0, "avg_logprob": -0.14209863489324395, "compression_ratio": 1.7155172413793103, "no_speech_prob": 7.690364327572752e-07}, {"id": 666, "seek": 445348, "start": 4463.36, "end": 4468.5199999999995, "text": " all more high-res would be to remove all the max pooling layers.", "tokens": [439, 544, 1090, 12, 495, 576, 312, 281, 4159, 439, 264, 11469, 7005, 278, 7914, 13], "temperature": 0.0, "avg_logprob": -0.14209863489324395, "compression_ratio": 1.7155172413793103, "no_speech_prob": 7.690364327572752e-07}, {"id": 667, "seek": 445348, "start": 4468.5199999999995, "end": 4474.08, "text": " So here's exactly the same thing as before, but I've removed all the max pooling layers.", "tokens": [407, 510, 311, 2293, 264, 912, 551, 382, 949, 11, 457, 286, 600, 7261, 439, 264, 11469, 7005, 278, 7914, 13], "temperature": 0.0, "avg_logprob": -0.14209863489324395, "compression_ratio": 1.7155172413793103, "no_speech_prob": 7.690364327572752e-07}, {"id": 668, "seek": 445348, "start": 4474.08, "end": 4481.24, "text": " So that means that my model now remains at 22x40 all the way through. Everything else", "tokens": [407, 300, 1355, 300, 452, 2316, 586, 7023, 412, 5853, 87, 5254, 439, 264, 636, 807, 13, 5471, 1646], "temperature": 0.0, "avg_logprob": -0.14209863489324395, "compression_ratio": 1.7155172413793103, "no_speech_prob": 7.690364327572752e-07}, {"id": 669, "seek": 445348, "start": 4481.24, "end": 4483.24, "text": " is the same.", "tokens": [307, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.14209863489324395, "compression_ratio": 1.7155172413793103, "no_speech_prob": 7.690364327572752e-07}, {"id": 670, "seek": 448324, "start": 4483.24, "end": 4491.12, "text": " And that indeed does not give quite as accurate a result. We get 95.2, rather than whatever", "tokens": [400, 300, 6451, 775, 406, 976, 1596, 382, 8559, 257, 1874, 13, 492, 483, 13420, 13, 17, 11, 2831, 813, 2035], "temperature": 0.0, "avg_logprob": -0.17043962284010283, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.6701354979886673e-05}, {"id": 671, "seek": 448324, "start": 4491.12, "end": 4499.2, "text": " it was, 97.6. But on the other hand, we do have a much higher resolution grid. So if", "tokens": [309, 390, 11, 23399, 13, 21, 13, 583, 322, 264, 661, 1011, 11, 321, 360, 362, 257, 709, 2946, 8669, 10748, 13, 407, 498], "temperature": 0.0, "avg_logprob": -0.17043962284010283, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.6701354979886673e-05}, {"id": 672, "seek": 448324, "start": 4499.2, "end": 4506.16, "text": " we now do exactly the same thing to create the heatmap, the other thing we're going to", "tokens": [321, 586, 360, 2293, 264, 912, 551, 281, 1884, 264, 3738, 24223, 11, 264, 661, 551, 321, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.17043962284010283, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.6701354979886673e-05}, {"id": 673, "seek": 448324, "start": 4506.16, "end": 4512.5199999999995, "text": " do is we're going to resize the heatmap to 360x640. And by default, this resize command", "tokens": [360, 307, 321, 434, 516, 281, 50069, 264, 3738, 24223, 281, 13898, 87, 21, 5254, 13, 400, 538, 7576, 11, 341, 50069, 5622], "temperature": 0.0, "avg_logprob": -0.17043962284010283, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.6701354979886673e-05}, {"id": 674, "seek": 451252, "start": 4512.52, "end": 4518.64, "text": " will try and interpolate. So it's going to replace big pixels with interpolated small", "tokens": [486, 853, 293, 44902, 473, 13, 407, 309, 311, 516, 281, 7406, 955, 18668, 365, 44902, 770, 1359], "temperature": 0.0, "avg_logprob": -0.13617519948674345, "compression_ratio": 1.6020408163265305, "no_speech_prob": 1.0129942893399857e-05}, {"id": 675, "seek": 451252, "start": 4518.64, "end": 4520.46, "text": " pixels.", "tokens": [18668, 13], "temperature": 0.0, "avg_logprob": -0.13617519948674345, "compression_ratio": 1.6020408163265305, "no_speech_prob": 1.0129942893399857e-05}, {"id": 676, "seek": 451252, "start": 4520.46, "end": 4528.8, "text": " And that gives us, for this image, this answer, which is much more interesting. And so now", "tokens": [400, 300, 2709, 505, 11, 337, 341, 3256, 11, 341, 1867, 11, 597, 307, 709, 544, 1880, 13, 400, 370, 586], "temperature": 0.0, "avg_logprob": -0.13617519948674345, "compression_ratio": 1.6020408163265305, "no_speech_prob": 1.0129942893399857e-05}, {"id": 677, "seek": 451252, "start": 4528.8, "end": 4533.84, "text": " we can stick one on top of the other like so.", "tokens": [321, 393, 2897, 472, 322, 1192, 295, 264, 661, 411, 370, 13], "temperature": 0.0, "avg_logprob": -0.13617519948674345, "compression_ratio": 1.6020408163265305, "no_speech_prob": 1.0129942893399857e-05}, {"id": 678, "seek": 451252, "start": 4533.84, "end": 4541.160000000001, "text": " And this tells us a lot. It tells us that on the whole, this is doing a good job of", "tokens": [400, 341, 5112, 505, 257, 688, 13, 467, 5112, 505, 300, 322, 264, 1379, 11, 341, 307, 884, 257, 665, 1691, 295], "temperature": 0.0, "avg_logprob": -0.13617519948674345, "compression_ratio": 1.6020408163265305, "no_speech_prob": 1.0129942893399857e-05}, {"id": 679, "seek": 454116, "start": 4541.16, "end": 4545.72, "text": " saying the thing that mattered, the fishy thing, the albacorey thing specifically, because", "tokens": [1566, 264, 551, 300, 44282, 11, 264, 41991, 551, 11, 264, 419, 65, 326, 418, 88, 551, 4682, 11, 570], "temperature": 0.0, "avg_logprob": -0.18579533161261144, "compression_ratio": 1.576470588235294, "no_speech_prob": 1.9525677998899482e-05}, {"id": 680, "seek": 454116, "start": 4545.72, "end": 4556.88, "text": " we're asking here for the albacore plus. Remember, that layer of the model is 8x22x40. So we", "tokens": [321, 434, 3365, 510, 337, 264, 419, 65, 326, 418, 1804, 13, 5459, 11, 300, 4583, 295, 264, 2316, 307, 1649, 87, 7490, 87, 5254, 13, 407, 321], "temperature": 0.0, "avg_logprob": -0.18579533161261144, "compression_ratio": 1.576470588235294, "no_speech_prob": 1.9525677998899482e-05}, {"id": 681, "seek": 454116, "start": 4556.88, "end": 4562.32, "text": " have to ask how much like albacore is each of those areas, or how much like shark is", "tokens": [362, 281, 1029, 577, 709, 411, 419, 65, 326, 418, 307, 1184, 295, 729, 3179, 11, 420, 577, 709, 411, 13327, 307], "temperature": 0.0, "avg_logprob": -0.18579533161261144, "compression_ratio": 1.576470588235294, "no_speech_prob": 1.9525677998899482e-05}, {"id": 682, "seek": 456232, "start": 4562.32, "end": 4571.5599999999995, "text": " each of those areas. So when we called this function, it returned basically a heatmap", "tokens": [1184, 295, 729, 3179, 13, 407, 562, 321, 1219, 341, 2445, 11, 309, 8752, 1936, 257, 3738, 24223], "temperature": 0.0, "avg_logprob": -0.18643100559711456, "compression_ratio": 1.4873417721518987, "no_speech_prob": 9.368653081764933e-06}, {"id": 683, "seek": 456232, "start": 4571.5599999999995, "end": 4580.719999999999, "text": " for every type of fish. So we can pass in 0 for albacore.", "tokens": [337, 633, 2010, 295, 3506, 13, 407, 321, 393, 1320, 294, 1958, 337, 419, 65, 326, 418, 13], "temperature": 0.0, "avg_logprob": -0.18643100559711456, "compression_ratio": 1.4873417721518987, "no_speech_prob": 9.368653081764933e-06}, {"id": 684, "seek": 456232, "start": 4580.719999999999, "end": 4586.299999999999, "text": " Class number 4 is no fish. So one of the classes you have to predict in this competition is", "tokens": [9471, 1230, 1017, 307, 572, 3506, 13, 407, 472, 295, 264, 5359, 291, 362, 281, 6069, 294, 341, 6211, 307], "temperature": 0.0, "avg_logprob": -0.18643100559711456, "compression_ratio": 1.4873417721518987, "no_speech_prob": 9.368653081764933e-06}, {"id": 685, "seek": 458630, "start": 4586.3, "end": 4592.12, "text": " no fish. So we could say, tell us how much each part of this picture looks like the no", "tokens": [572, 3506, 13, 407, 321, 727, 584, 11, 980, 505, 577, 709, 1184, 644, 295, 341, 3036, 1542, 411, 264, 572], "temperature": 0.0, "avg_logprob": -0.1480413853437051, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.3405253816454206e-06}, {"id": 686, "seek": 458630, "start": 4592.12, "end": 4598.18, "text": " fish class. What happens is if you look at the no fish version, it's basically the exact", "tokens": [3506, 1508, 13, 708, 2314, 307, 498, 291, 574, 412, 264, 572, 3506, 3037, 11, 309, 311, 1936, 264, 1900], "temperature": 0.0, "avg_logprob": -0.1480413853437051, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.3405253816454206e-06}, {"id": 687, "seek": 458630, "start": 4598.18, "end": 4605.68, "text": " opposite of this. You get a big blue spot here and pink all around it.", "tokens": [6182, 295, 341, 13, 509, 483, 257, 955, 3344, 4008, 510, 293, 7022, 439, 926, 309, 13], "temperature": 0.0, "avg_logprob": -0.1480413853437051, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.3405253816454206e-06}, {"id": 688, "seek": 458630, "start": 4605.68, "end": 4611.320000000001, "text": " The other thing I wanted to point out here is these areas of pinkishness that are not", "tokens": [440, 661, 551, 286, 1415, 281, 935, 484, 510, 307, 613, 3179, 295, 7022, 742, 1287, 300, 366, 406], "temperature": 0.0, "avg_logprob": -0.1480413853437051, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.3405253816454206e-06}, {"id": 689, "seek": 461132, "start": 4611.32, "end": 4616.96, "text": " where the fish is. This is telling me that our model is not currently just looking for", "tokens": [689, 264, 3506, 307, 13, 639, 307, 3585, 385, 300, 527, 2316, 307, 406, 4362, 445, 1237, 337], "temperature": 0.0, "avg_logprob": -0.18452953611101422, "compression_ratio": 1.5815217391304348, "no_speech_prob": 3.089483698204276e-06}, {"id": 690, "seek": 461132, "start": 4616.96, "end": 4629.24, "text": " fish. It's also looking for particular characteristics of the boat. So this is suggesting to me that", "tokens": [3506, 13, 467, 311, 611, 1237, 337, 1729, 10891, 295, 264, 6582, 13, 407, 341, 307, 18094, 281, 385, 300], "temperature": 0.0, "avg_logprob": -0.18452953611101422, "compression_ratio": 1.5815217391304348, "no_speech_prob": 3.089483698204276e-06}, {"id": 691, "seek": 461132, "start": 4629.24, "end": 4635.5599999999995, "text": " since it's not all concentrated on the fish, I do think there's some data leakage still", "tokens": [1670, 309, 311, 406, 439, 21321, 322, 264, 3506, 11, 286, 360, 519, 456, 311, 512, 1412, 47799, 920], "temperature": 0.0, "avg_logprob": -0.18452953611101422, "compression_ratio": 1.5815217391304348, "no_speech_prob": 3.089483698204276e-06}, {"id": 692, "seek": 461132, "start": 4635.5599999999995, "end": 4636.5599999999995, "text": " coming through.", "tokens": [1348, 807, 13], "temperature": 0.0, "avg_logprob": -0.18452953611101422, "compression_ratio": 1.5815217391304348, "no_speech_prob": 3.089483698204276e-06}, {"id": 693, "seek": 463656, "start": 4636.56, "end": 4642.080000000001, "text": " Question asked.", "tokens": [14464, 2351, 13], "temperature": 0.0, "avg_logprob": -0.23210974397330447, "compression_ratio": 1.1222222222222222, "no_speech_prob": 1.1659430128929671e-05}, {"id": 694, "seek": 463656, "start": 4642.080000000001, "end": 4657.72, "text": " I think we know everything about why it's working. We have set up a model where we've", "tokens": [286, 519, 321, 458, 1203, 466, 983, 309, 311, 1364, 13, 492, 362, 992, 493, 257, 2316, 689, 321, 600], "temperature": 0.0, "avg_logprob": -0.23210974397330447, "compression_ratio": 1.1222222222222222, "no_speech_prob": 1.1659430128929671e-05}, {"id": 695, "seek": 465772, "start": 4657.72, "end": 4668.92, "text": " said we want you to predict each of the 8 fish classes. We have set it up such that", "tokens": [848, 321, 528, 291, 281, 6069, 1184, 295, 264, 1649, 3506, 5359, 13, 492, 362, 992, 309, 493, 1270, 300], "temperature": 0.0, "avg_logprob": -0.11924819688539247, "compression_ratio": 1.6741573033707866, "no_speech_prob": 2.8573065264936304e-06}, {"id": 696, "seek": 465772, "start": 4668.92, "end": 4675.360000000001, "text": " the last layer simply averages the answers from the previous layer. The previous layer", "tokens": [264, 1036, 4583, 2935, 42257, 264, 6338, 490, 264, 3894, 4583, 13, 440, 3894, 4583], "temperature": 0.0, "avg_logprob": -0.11924819688539247, "compression_ratio": 1.6741573033707866, "no_speech_prob": 2.8573065264936304e-06}, {"id": 697, "seek": 465772, "start": 4675.360000000001, "end": 4681.08, "text": " we have set up has the 8 classes we need. So that's obviously the only way you can average", "tokens": [321, 362, 992, 493, 575, 264, 1649, 5359, 321, 643, 13, 407, 300, 311, 2745, 264, 787, 636, 291, 393, 4274], "temperature": 0.0, "avg_logprob": -0.11924819688539247, "compression_ratio": 1.6741573033707866, "no_speech_prob": 2.8573065264936304e-06}, {"id": 698, "seek": 465772, "start": 4681.08, "end": 4683.900000000001, "text": " and get the right number of classes.", "tokens": [293, 483, 264, 558, 1230, 295, 5359, 13], "temperature": 0.0, "avg_logprob": -0.11924819688539247, "compression_ratio": 1.6741573033707866, "no_speech_prob": 2.8573065264936304e-06}, {"id": 699, "seek": 468390, "start": 4683.9, "end": 4690.04, "text": " We know that SGD is a general optimization approach which will find a set of parameters", "tokens": [492, 458, 300, 34520, 35, 307, 257, 2674, 19618, 3109, 597, 486, 915, 257, 992, 295, 9834], "temperature": 0.0, "avg_logprob": -0.12890976125543768, "compression_ratio": 1.4804469273743017, "no_speech_prob": 2.9480079319910146e-06}, {"id": 700, "seek": 468390, "start": 4690.04, "end": 4697.42, "text": " which solve the problem that you give it, and we've given it that problem. So really,", "tokens": [597, 5039, 264, 1154, 300, 291, 976, 309, 11, 293, 321, 600, 2212, 309, 300, 1154, 13, 407, 534, 11], "temperature": 0.0, "avg_logprob": -0.12890976125543768, "compression_ratio": 1.4804469273743017, "no_speech_prob": 2.9480079319910146e-06}, {"id": 701, "seek": 468390, "start": 4697.42, "end": 4711.4, "text": " when you think of it that way, unless it failed to train, it could only get a decent answer", "tokens": [562, 291, 519, 295, 309, 300, 636, 11, 5969, 309, 7612, 281, 3847, 11, 309, 727, 787, 483, 257, 8681, 1867], "temperature": 0.0, "avg_logprob": -0.12890976125543768, "compression_ratio": 1.4804469273743017, "no_speech_prob": 2.9480079319910146e-06}, {"id": 702, "seek": 471140, "start": 4711.4, "end": 4715.96, "text": " if it solved it in this way, if it actually looked at each area and figured out how fishy", "tokens": [498, 309, 13041, 309, 294, 341, 636, 11, 498, 309, 767, 2956, 412, 1184, 1859, 293, 8932, 484, 577, 41991], "temperature": 0.0, "avg_logprob": -0.15124224377917006, "compression_ratio": 1.6201117318435754, "no_speech_prob": 5.0936537263623904e-06}, {"id": 703, "seek": 471140, "start": 4715.96, "end": 4716.96, "text": " it is.", "tokens": [309, 307, 13], "temperature": 0.0, "avg_logprob": -0.15124224377917006, "compression_ratio": 1.6201117318435754, "no_speech_prob": 5.0936537263623904e-06}, {"id": 704, "seek": 471140, "start": 4716.96, "end": 4717.96, "text": " Question asked.", "tokens": [14464, 2351, 13], "temperature": 0.0, "avg_logprob": -0.15124224377917006, "compression_ratio": 1.6201117318435754, "no_speech_prob": 5.0936537263623904e-06}, {"id": 705, "seek": 471140, "start": 4717.96, "end": 4731.96, "text": " We're not doing attention models in this part of the course per se. I would say for now,", "tokens": [492, 434, 406, 884, 3202, 5245, 294, 341, 644, 295, 264, 1164, 680, 369, 13, 286, 576, 584, 337, 586, 11], "temperature": 0.0, "avg_logprob": -0.15124224377917006, "compression_ratio": 1.6201117318435754, "no_speech_prob": 5.0936537263623904e-06}, {"id": 706, "seek": 471140, "start": 4731.96, "end": 4739.04, "text": " the simple attention model that I would do would be to find the largest area of the heat", "tokens": [264, 2199, 3202, 2316, 300, 286, 576, 360, 576, 312, 281, 915, 264, 6443, 1859, 295, 264, 3738], "temperature": 0.0, "avg_logprob": -0.15124224377917006, "compression_ratio": 1.6201117318435754, "no_speech_prob": 5.0936537263623904e-06}, {"id": 707, "seek": 473904, "start": 4739.04, "end": 4745.92, "text": " map and crop that, and maybe compare that to the bounding boxes and make sure they look", "tokens": [4471, 293, 9086, 300, 11, 293, 1310, 6794, 300, 281, 264, 5472, 278, 9002, 293, 652, 988, 436, 574], "temperature": 0.0, "avg_logprob": -0.1981431026847995, "compression_ratio": 1.733009708737864, "no_speech_prob": 2.318708175153006e-05}, {"id": 708, "seek": 473904, "start": 4745.92, "end": 4750.72, "text": " about the same, and those that don't, you might want to hand fix. And if you hand fix", "tokens": [466, 264, 912, 11, 293, 729, 300, 500, 380, 11, 291, 1062, 528, 281, 1011, 3191, 13, 400, 498, 291, 1011, 3191], "temperature": 0.0, "avg_logprob": -0.1981431026847995, "compression_ratio": 1.733009708737864, "no_speech_prob": 2.318708175153006e-05}, {"id": 709, "seek": 473904, "start": 4750.72, "end": 4756.04, "text": " them, you have to give that back to the Kaggle community, of course, because that's hand", "tokens": [552, 11, 291, 362, 281, 976, 300, 646, 281, 264, 48751, 22631, 1768, 11, 295, 1164, 11, 570, 300, 311, 1011], "temperature": 0.0, "avg_logprob": -0.1981431026847995, "compression_ratio": 1.733009708737864, "no_speech_prob": 2.318708175153006e-05}, {"id": 710, "seek": 473904, "start": 4756.04, "end": 4757.8, "text": " labeling.", "tokens": [40244, 13], "temperature": 0.0, "avg_logprob": -0.1981431026847995, "compression_ratio": 1.733009708737864, "no_speech_prob": 2.318708175153006e-05}, {"id": 711, "seek": 473904, "start": 4757.8, "end": 4765.6, "text": " And honestly, that's the state of the art. In terms of who wins the money in Kaggle,", "tokens": [400, 6095, 11, 300, 311, 264, 1785, 295, 264, 1523, 13, 682, 2115, 295, 567, 10641, 264, 1460, 294, 48751, 22631, 11], "temperature": 0.0, "avg_logprob": -0.1981431026847995, "compression_ratio": 1.733009708737864, "no_speech_prob": 2.318708175153006e-05}, {"id": 712, "seek": 476560, "start": 4765.6, "end": 4771.320000000001, "text": " that's how the Kaggle winners have won these kinds of competitions, is by having a two-stage", "tokens": [300, 311, 577, 264, 48751, 22631, 17193, 362, 1582, 613, 3685, 295, 26185, 11, 307, 538, 1419, 257, 732, 12, 17882], "temperature": 0.0, "avg_logprob": -0.1890797661346139, "compression_ratio": 1.7521739130434784, "no_speech_prob": 3.219189602532424e-05}, {"id": 713, "seek": 476560, "start": 4771.320000000001, "end": 4775.4800000000005, "text": " pipeline where first of all they find the thing of interest, and then they zoom into", "tokens": [15517, 689, 700, 295, 439, 436, 915, 264, 551, 295, 1179, 11, 293, 550, 436, 8863, 666], "temperature": 0.0, "avg_logprob": -0.1890797661346139, "compression_ratio": 1.7521739130434784, "no_speech_prob": 3.219189602532424e-05}, {"id": 714, "seek": 476560, "start": 4775.4800000000005, "end": 4780.320000000001, "text": " it and then they do a model on that thing.", "tokens": [309, 293, 550, 436, 360, 257, 2316, 322, 300, 551, 13], "temperature": 0.0, "avg_logprob": -0.1890797661346139, "compression_ratio": 1.7521739130434784, "no_speech_prob": 3.219189602532424e-05}, {"id": 715, "seek": 476560, "start": 4780.320000000001, "end": 4787.56, "text": " Actually the other thing that you might want to do is to orient the fish so that the tail", "tokens": [5135, 264, 661, 551, 300, 291, 1062, 528, 281, 360, 307, 281, 8579, 264, 3506, 370, 300, 264, 6838], "temperature": 0.0, "avg_logprob": -0.1890797661346139, "compression_ratio": 1.7521739130434784, "no_speech_prob": 3.219189602532424e-05}, {"id": 716, "seek": 476560, "start": 4787.56, "end": 4792.240000000001, "text": " is kind of in the same place and the head is at the same place. Make it as easy as possible,", "tokens": [307, 733, 295, 294, 264, 912, 1081, 293, 264, 1378, 307, 412, 264, 912, 1081, 13, 4387, 309, 382, 1858, 382, 1944, 11], "temperature": 0.0, "avg_logprob": -0.1890797661346139, "compression_ratio": 1.7521739130434784, "no_speech_prob": 3.219189602532424e-05}, {"id": 717, "seek": 479224, "start": 4792.24, "end": 4803.08, "text": " basically, for your ConvNet to do what it needs to do.", "tokens": [1936, 11, 337, 428, 2656, 85, 31890, 281, 360, 437, 309, 2203, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.18436033585492304, "compression_ratio": 1.3445945945945945, "no_speech_prob": 8.26780524221249e-06}, {"id": 718, "seek": 479224, "start": 4803.08, "end": 4809.44, "text": " You guys might have heard of another architecture called Inception. A combination of Inception", "tokens": [509, 1074, 1062, 362, 2198, 295, 1071, 9482, 1219, 682, 7311, 13, 316, 6562, 295, 682, 7311], "temperature": 0.0, "avg_logprob": -0.18436033585492304, "compression_ratio": 1.3445945945945945, "no_speech_prob": 8.26780524221249e-06}, {"id": 719, "seek": 479224, "start": 4809.44, "end": 4816.88, "text": " plus ResNet won this year's ImageNet competition.", "tokens": [1804, 5015, 31890, 1582, 341, 1064, 311, 29903, 31890, 6211, 13], "temperature": 0.0, "avg_logprob": -0.18436033585492304, "compression_ratio": 1.3445945945945945, "no_speech_prob": 8.26780524221249e-06}, {"id": 720, "seek": 481688, "start": 4816.88, "end": 4825.68, "text": " And I want to give you a very quick hint as to how it works. I have built the world's", "tokens": [400, 286, 528, 281, 976, 291, 257, 588, 1702, 12075, 382, 281, 577, 309, 1985, 13, 286, 362, 3094, 264, 1002, 311], "temperature": 0.0, "avg_logprob": -0.17408433372591747, "compression_ratio": 1.4926108374384237, "no_speech_prob": 7.889171683927998e-06}, {"id": 721, "seek": 481688, "start": 4825.68, "end": 4831.76, "text": " tiniest little Inception network here.", "tokens": [256, 3812, 377, 707, 682, 7311, 3209, 510, 13], "temperature": 0.0, "avg_logprob": -0.17408433372591747, "compression_ratio": 1.4926108374384237, "no_speech_prob": 7.889171683927998e-06}, {"id": 722, "seek": 481688, "start": 4831.76, "end": 4836.16, "text": " One of the reasons I want to show it to you is because it actually uses the same technique", "tokens": [1485, 295, 264, 4112, 286, 528, 281, 855, 309, 281, 291, 307, 570, 309, 767, 4960, 264, 912, 6532], "temperature": 0.0, "avg_logprob": -0.17408433372591747, "compression_ratio": 1.4926108374384237, "no_speech_prob": 7.889171683927998e-06}, {"id": 723, "seek": 481688, "start": 4836.16, "end": 4843.0, "text": " that we heard from Ben Bowles that he used. Remember in his language model at Quid, Ben", "tokens": [300, 321, 2198, 490, 3964, 12903, 904, 300, 415, 1143, 13, 5459, 294, 702, 2856, 2316, 412, 2326, 327, 11, 3964], "temperature": 0.0, "avg_logprob": -0.17408433372591747, "compression_ratio": 1.4926108374384237, "no_speech_prob": 7.889171683927998e-06}, {"id": 724, "seek": 484300, "start": 4843.0, "end": 4849.76, "text": " used a trick where he had multiple different convolution filter sizes and ran all of them", "tokens": [1143, 257, 4282, 689, 415, 632, 3866, 819, 45216, 6608, 11602, 293, 5872, 439, 295, 552], "temperature": 0.0, "avg_logprob": -0.27693456626800167, "compression_ratio": 1.5614035087719298, "no_speech_prob": 2.078491343127098e-05}, {"id": 725, "seek": 484300, "start": 4849.76, "end": 4854.12, "text": " and concatenated them together. That's actually what the Inception network does.", "tokens": [293, 1588, 7186, 770, 552, 1214, 13, 663, 311, 767, 437, 264, 682, 7311, 3209, 775, 13], "temperature": 0.0, "avg_logprob": -0.27693456626800167, "compression_ratio": 1.5614035087719298, "no_speech_prob": 2.078491343127098e-05}, {"id": 726, "seek": 484300, "start": 4854.12, "end": 4857.12, "text": " Question from the audience.", "tokens": [14464, 490, 264, 4034, 13], "temperature": 0.0, "avg_logprob": -0.27693456626800167, "compression_ratio": 1.5614035087719298, "no_speech_prob": 2.078491343127098e-05}, {"id": 727, "seek": 484300, "start": 4857.12, "end": 4866.12, "text": " How would you align the head and tail? How is this a better way to isolate the fish than", "tokens": [1012, 576, 291, 7975, 264, 1378, 293, 6838, 30, 1012, 307, 341, 257, 1101, 636, 281, 25660, 264, 3506, 813], "temperature": 0.0, "avg_logprob": -0.27693456626800167, "compression_ratio": 1.5614035087719298, "no_speech_prob": 2.078491343127098e-05}, {"id": 728, "seek": 484300, "start": 4866.12, "end": 4869.92, "text": " just taking the bounding box approach that the classifier generated?", "tokens": [445, 1940, 264, 5472, 278, 2424, 3109, 300, 264, 1508, 9902, 10833, 30], "temperature": 0.0, "avg_logprob": -0.27693456626800167, "compression_ratio": 1.5614035087719298, "no_speech_prob": 2.078491343127098e-05}, {"id": 729, "seek": 486992, "start": 4869.92, "end": 4874.36, "text": " To align the head and tail, the easiest way would be to hand annotate the head and hand", "tokens": [1407, 7975, 264, 1378, 293, 6838, 11, 264, 12889, 636, 576, 312, 281, 1011, 25339, 473, 264, 1378, 293, 1011], "temperature": 0.0, "avg_logprob": -0.19912213455011815, "compression_ratio": 1.625, "no_speech_prob": 2.5071107302210294e-05}, {"id": 730, "seek": 486992, "start": 4874.36, "end": 4890.6, "text": " annotate the tail. That was what was done in the whale competition.", "tokens": [25339, 473, 264, 6838, 13, 663, 390, 437, 390, 1096, 294, 264, 25370, 6211, 13], "temperature": 0.0, "avg_logprob": -0.19912213455011815, "compression_ratio": 1.625, "no_speech_prob": 2.5071107302210294e-05}, {"id": 731, "seek": 486992, "start": 4890.6, "end": 4895.36, "text": " Hand labeling always has errors. Indeed, there are quite a few people in the forum", "tokens": [8854, 40244, 1009, 575, 13603, 13, 15061, 11, 456, 366, 1596, 257, 1326, 561, 294, 264, 17542], "temperature": 0.0, "avg_logprob": -0.19912213455011815, "compression_ratio": 1.625, "no_speech_prob": 2.5071107302210294e-05}, {"id": 732, "seek": 486992, "start": 4895.36, "end": 4899.28, "text": " who have pointed out various bounding boxes that they don't think are correct. So it's", "tokens": [567, 362, 10932, 484, 3683, 5472, 278, 9002, 300, 436, 500, 380, 519, 366, 3006, 13, 407, 309, 311], "temperature": 0.0, "avg_logprob": -0.19912213455011815, "compression_ratio": 1.625, "no_speech_prob": 2.5071107302210294e-05}, {"id": 733, "seek": 489928, "start": 4899.28, "end": 4903.5599999999995, "text": " great to have an automatic approach which ought to give about the same answer as the", "tokens": [869, 281, 362, 364, 12509, 3109, 597, 13416, 281, 976, 466, 264, 912, 1867, 382, 264], "temperature": 0.0, "avg_logprob": -0.1337425525371845, "compression_ratio": 1.6699029126213591, "no_speech_prob": 4.1985018469858915e-05}, {"id": 734, "seek": 489928, "start": 4903.5599999999995, "end": 4910.48, "text": " hand approach, and you can then compare the two and use the best of both worlds.", "tokens": [1011, 3109, 11, 293, 291, 393, 550, 6794, 264, 732, 293, 764, 264, 1151, 295, 1293, 13401, 13], "temperature": 0.0, "avg_logprob": -0.1337425525371845, "compression_ratio": 1.6699029126213591, "no_speech_prob": 4.1985018469858915e-05}, {"id": 735, "seek": 489928, "start": 4910.48, "end": 4915.679999999999, "text": " And in general, this idea of combining human intelligence and machine intelligence seems", "tokens": [400, 294, 2674, 11, 341, 1558, 295, 21928, 1952, 7599, 293, 3479, 7599, 2544], "temperature": 0.0, "avg_logprob": -0.1337425525371845, "compression_ratio": 1.6699029126213591, "no_speech_prob": 4.1985018469858915e-05}, {"id": 736, "seek": 489928, "start": 4915.679999999999, "end": 4921.2, "text": " to be a great approach, particularly early on. You can do that for the first few bounding", "tokens": [281, 312, 257, 869, 3109, 11, 4098, 2440, 322, 13, 509, 393, 360, 300, 337, 264, 700, 1326, 5472, 278], "temperature": 0.0, "avg_logprob": -0.1337425525371845, "compression_ratio": 1.6699029126213591, "no_speech_prob": 4.1985018469858915e-05}, {"id": 737, "seek": 492120, "start": 4921.2, "end": 4931.44, "text": " boxes to improve your bounding box model, and then use that to gradually make the model", "tokens": [9002, 281, 3470, 428, 5472, 278, 2424, 2316, 11, 293, 550, 764, 300, 281, 13145, 652, 264, 2316], "temperature": 0.0, "avg_logprob": -0.24867420196533202, "compression_ratio": 1.33, "no_speech_prob": 7.84350631874986e-05}, {"id": 738, "seek": 492120, "start": 4931.44, "end": 4935.76, "text": " have to ask you less and less for your input.", "tokens": [362, 281, 1029, 291, 1570, 293, 1570, 337, 428, 4846, 13], "temperature": 0.0, "avg_logprob": -0.24867420196533202, "compression_ratio": 1.33, "no_speech_prob": 7.84350631874986e-05}, {"id": 739, "seek": 493576, "start": 4935.76, "end": 4952.68, "text": " Question from the audience.", "tokens": [14464, 490, 264, 4034, 13], "temperature": 0.0, "avg_logprob": -0.7961726188659668, "compression_ratio": 0.7714285714285715, "no_speech_prob": 0.00013550170115195215}, {"id": 740, "seek": 495268, "start": 4952.68, "end": 4970.72, "text": " The heat map you don't need to. The heat map was just visualizing one of the layers of", "tokens": [440, 3738, 4471, 291, 500, 380, 643, 281, 13, 440, 3738, 4471, 390, 445, 5056, 3319, 472, 295, 264, 7914, 295], "temperature": 0.0, "avg_logprob": -0.20552655628749303, "compression_ratio": 1.5647058823529412, "no_speech_prob": 3.32132913172245e-05}, {"id": 741, "seek": 495268, "start": 4970.72, "end": 4976.68, "text": " the network. We didn't use the bounding boxes, we didn't do anything special. It's just a", "tokens": [264, 3209, 13, 492, 994, 380, 764, 264, 5472, 278, 9002, 11, 321, 994, 380, 360, 1340, 2121, 13, 467, 311, 445, 257], "temperature": 0.0, "avg_logprob": -0.20552655628749303, "compression_ratio": 1.5647058823529412, "no_speech_prob": 3.32132913172245e-05}, {"id": 742, "seek": 495268, "start": 4976.68, "end": 4982.280000000001, "text": " side effect of this kind of model, is that you can visualize the last compositional layer", "tokens": [1252, 1802, 295, 341, 733, 295, 2316, 11, 307, 300, 291, 393, 23273, 264, 1036, 10199, 2628, 4583], "temperature": 0.0, "avg_logprob": -0.20552655628749303, "compression_ratio": 1.5647058823529412, "no_speech_prob": 3.32132913172245e-05}, {"id": 743, "seek": 498228, "start": 4982.28, "end": 4984.28, "text": " and doing so will give you a heat map.", "tokens": [293, 884, 370, 486, 976, 291, 257, 3738, 4471, 13], "temperature": 0.0, "avg_logprob": -0.3215402396949562, "compression_ratio": 1.75, "no_speech_prob": 4.264609742676839e-05}, {"id": 744, "seek": 498228, "start": 4984.28, "end": 4986.28, "text": " Question from the audience.", "tokens": [14464, 490, 264, 4034, 13], "temperature": 0.0, "avg_logprob": -0.3215402396949562, "compression_ratio": 1.75, "no_speech_prob": 4.264609742676839e-05}, {"id": 745, "seek": 498228, "start": 4986.28, "end": 4999.2, "text": " There are so many ways of interpreting neural nets, and one of them is to draw pictures", "tokens": [821, 366, 370, 867, 2098, 295, 37395, 18161, 36170, 11, 293, 472, 295, 552, 307, 281, 2642, 5242], "temperature": 0.0, "avg_logprob": -0.3215402396949562, "compression_ratio": 1.75, "no_speech_prob": 4.264609742676839e-05}, {"id": 746, "seek": 498228, "start": 4999.2, "end": 5003.8, "text": " of the intermediate activations. You can also draw pictures of the intermediate gradients.", "tokens": [295, 264, 19376, 2430, 763, 13, 509, 393, 611, 2642, 5242, 295, 264, 19376, 2771, 2448, 13], "temperature": 0.0, "avg_logprob": -0.3215402396949562, "compression_ratio": 1.75, "no_speech_prob": 4.264609742676839e-05}, {"id": 747, "seek": 498228, "start": 5003.8, "end": 5007.2, "text": " There are all kinds of things you can draw pictures of.", "tokens": [821, 366, 439, 3685, 295, 721, 291, 393, 2642, 5242, 295, 13], "temperature": 0.0, "avg_logprob": -0.3215402396949562, "compression_ratio": 1.75, "no_speech_prob": 4.264609742676839e-05}, {"id": 748, "seek": 500720, "start": 5007.2, "end": 5031.36, "text": " Question from the audience.", "tokens": [14464, 490, 264, 4034, 13], "temperature": 0.0, "avg_logprob": -0.21204042434692383, "compression_ratio": 1.2947368421052632, "no_speech_prob": 2.7533737011253834e-05}, {"id": 749, "seek": 500720, "start": 5031.36, "end": 5036.16, "text": " So the inception network is going to use this trick where we're going to use multiple different", "tokens": [407, 264, 49834, 3209, 307, 516, 281, 764, 341, 4282, 689, 321, 434, 516, 281, 764, 3866, 819], "temperature": 0.0, "avg_logprob": -0.21204042434692383, "compression_ratio": 1.2947368421052632, "no_speech_prob": 2.7533737011253834e-05}, {"id": 750, "seek": 503616, "start": 5036.16, "end": 5046.12, "text": " compositional filter sizes and concatenate them all together.", "tokens": [10199, 2628, 6608, 11602, 293, 1588, 7186, 473, 552, 439, 1214, 13], "temperature": 0.0, "avg_logprob": -0.19445502039897872, "compression_ratio": 1.7301587301587302, "no_speech_prob": 2.178231989091728e-05}, {"id": 751, "seek": 503616, "start": 5046.12, "end": 5051.12, "text": " So just like in ResNet, there's this idea of a ResNet block, which is repeated again", "tokens": [407, 445, 411, 294, 5015, 31890, 11, 456, 311, 341, 1558, 295, 257, 5015, 31890, 3461, 11, 597, 307, 10477, 797], "temperature": 0.0, "avg_logprob": -0.19445502039897872, "compression_ratio": 1.7301587301587302, "no_speech_prob": 2.178231989091728e-05}, {"id": 752, "seek": 503616, "start": 5051.12, "end": 5055.44, "text": " and again. In the inception network, there's an inception block, which is repeated again", "tokens": [293, 797, 13, 682, 264, 49834, 3209, 11, 456, 311, 364, 49834, 3461, 11, 597, 307, 10477, 797], "temperature": 0.0, "avg_logprob": -0.19445502039897872, "compression_ratio": 1.7301587301587302, "no_speech_prob": 2.178231989091728e-05}, {"id": 753, "seek": 503616, "start": 5055.44, "end": 5063.44, "text": " and again. And I've created a version of one here. So I have one thing which takes my input", "tokens": [293, 797, 13, 400, 286, 600, 2942, 257, 3037, 295, 472, 510, 13, 407, 286, 362, 472, 551, 597, 2516, 452, 4846], "temperature": 0.0, "avg_logprob": -0.19445502039897872, "compression_ratio": 1.7301587301587302, "no_speech_prob": 2.178231989091728e-05}, {"id": 754, "seek": 506344, "start": 5063.44, "end": 5069.639999999999, "text": " and does a 1x1 convolution. I've got one thing that takes the input and does a 5x5 convolution.", "tokens": [293, 775, 257, 502, 87, 16, 45216, 13, 286, 600, 658, 472, 551, 300, 2516, 264, 4846, 293, 775, 257, 1025, 87, 20, 45216, 13], "temperature": 0.0, "avg_logprob": -0.14436229906584086, "compression_ratio": 1.9612068965517242, "no_speech_prob": 5.771857559011551e-06}, {"id": 755, "seek": 506344, "start": 5069.639999999999, "end": 5074.16, "text": " I've got one thing that takes the input and does 2x3 convolutions. I've got one thing", "tokens": [286, 600, 658, 472, 551, 300, 2516, 264, 4846, 293, 775, 568, 87, 18, 3754, 15892, 13, 286, 600, 658, 472, 551], "temperature": 0.0, "avg_logprob": -0.14436229906584086, "compression_ratio": 1.9612068965517242, "no_speech_prob": 5.771857559011551e-06}, {"id": 756, "seek": 506344, "start": 5074.16, "end": 5080.679999999999, "text": " that takes the input and just average pulls it. And then we concatenate them all together.", "tokens": [300, 2516, 264, 4846, 293, 445, 4274, 16982, 309, 13, 400, 550, 321, 1588, 7186, 473, 552, 439, 1214, 13], "temperature": 0.0, "avg_logprob": -0.14436229906584086, "compression_ratio": 1.9612068965517242, "no_speech_prob": 5.771857559011551e-06}, {"id": 757, "seek": 506344, "start": 5080.679999999999, "end": 5086.599999999999, "text": " So what this is doing is each inception block is basically able to look for things at various", "tokens": [407, 437, 341, 307, 884, 307, 1184, 49834, 3461, 307, 1936, 1075, 281, 574, 337, 721, 412, 3683], "temperature": 0.0, "avg_logprob": -0.14436229906584086, "compression_ratio": 1.9612068965517242, "no_speech_prob": 5.771857559011551e-06}, {"id": 758, "seek": 506344, "start": 5086.599999999999, "end": 5092.639999999999, "text": " different scales and create a single feature map at the end, which adds all those things", "tokens": [819, 17408, 293, 1884, 257, 2167, 4111, 4471, 412, 264, 917, 11, 597, 10860, 439, 729, 721], "temperature": 0.0, "avg_logprob": -0.14436229906584086, "compression_ratio": 1.9612068965517242, "no_speech_prob": 5.771857559011551e-06}, {"id": 759, "seek": 509264, "start": 5092.64, "end": 5094.64, "text": " together.", "tokens": [1214, 13], "temperature": 0.0, "avg_logprob": -0.21622713088989257, "compression_ratio": 1.373134328358209, "no_speech_prob": 2.753542321443092e-05}, {"id": 760, "seek": 509264, "start": 5094.64, "end": 5105.52, "text": " So once I've defined that, I can then just create a little model. I haven't managed to", "tokens": [407, 1564, 286, 600, 7642, 300, 11, 286, 393, 550, 445, 1884, 257, 707, 2316, 13, 286, 2378, 380, 6453, 281], "temperature": 0.0, "avg_logprob": -0.21622713088989257, "compression_ratio": 1.373134328358209, "no_speech_prob": 2.753542321443092e-05}, {"id": 761, "seek": 509264, "start": 5105.52, "end": 5117.72, "text": " get this to work terribly well yet. I haven't actually tried submitting this to Kaggle.", "tokens": [483, 341, 281, 589, 22903, 731, 1939, 13, 286, 2378, 380, 767, 3031, 31836, 341, 281, 48751, 22631, 13], "temperature": 0.0, "avg_logprob": -0.21622713088989257, "compression_ratio": 1.373134328358209, "no_speech_prob": 2.753542321443092e-05}, {"id": 762, "seek": 511772, "start": 5117.72, "end": 5123.72, "text": " Part of the purpose of this is to give you guys a sense of the kinds of things we'll", "tokens": [4100, 295, 264, 4334, 295, 341, 307, 281, 976, 291, 1074, 257, 2020, 295, 264, 3685, 295, 721, 321, 603], "temperature": 0.0, "avg_logprob": -0.15594557353428432, "compression_ratio": 1.6233183856502242, "no_speech_prob": 5.8627624639484566e-06}, {"id": 763, "seek": 511772, "start": 5123.72, "end": 5132.4400000000005, "text": " be doing next year. This idea of we've built the basic pieces now of convolutions, fully", "tokens": [312, 884, 958, 1064, 13, 639, 1558, 295, 321, 600, 3094, 264, 3875, 3755, 586, 295, 3754, 15892, 11, 4498], "temperature": 0.0, "avg_logprob": -0.15594557353428432, "compression_ratio": 1.6233183856502242, "no_speech_prob": 5.8627624639484566e-06}, {"id": 764, "seek": 511772, "start": 5132.4400000000005, "end": 5140.4400000000005, "text": " connected layers, activation functions, SGD. And really from here, deep learning is putting", "tokens": [4582, 7914, 11, 24433, 6828, 11, 34520, 35, 13, 400, 534, 490, 510, 11, 2452, 2539, 307, 3372], "temperature": 0.0, "avg_logprob": -0.15594557353428432, "compression_ratio": 1.6233183856502242, "no_speech_prob": 5.8627624639484566e-06}, {"id": 765, "seek": 511772, "start": 5140.4400000000005, "end": 5144.76, "text": " these pieces together. What are the ways people have learned about putting these things together", "tokens": [613, 3755, 1214, 13, 708, 366, 264, 2098, 561, 362, 3264, 466, 3372, 613, 721, 1214], "temperature": 0.0, "avg_logprob": -0.15594557353428432, "compression_ratio": 1.6233183856502242, "no_speech_prob": 5.8627624639484566e-06}, {"id": 766, "seek": 514476, "start": 5144.76, "end": 5150.24, "text": " in ways that solve problems as well as possible.", "tokens": [294, 2098, 300, 5039, 2740, 382, 731, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.16042015438988094, "compression_ratio": 1.8047808764940239, "no_speech_prob": 9.972818588721566e-06}, {"id": 767, "seek": 514476, "start": 5150.24, "end": 5154.08, "text": " And so the inception network is one of these ways. And the other thing I wanted to do was", "tokens": [400, 370, 264, 49834, 3209, 307, 472, 295, 613, 2098, 13, 400, 264, 661, 551, 286, 1415, 281, 360, 390], "temperature": 0.0, "avg_logprob": -0.16042015438988094, "compression_ratio": 1.8047808764940239, "no_speech_prob": 9.972818588721566e-06}, {"id": 768, "seek": 514476, "start": 5154.08, "end": 5158.88, "text": " to give you plenty of things to think about over the next couple of months and play with,", "tokens": [281, 976, 291, 7140, 295, 721, 281, 519, 466, 670, 264, 958, 1916, 295, 2493, 293, 862, 365, 11], "temperature": 0.0, "avg_logprob": -0.16042015438988094, "compression_ratio": 1.8047808764940239, "no_speech_prob": 9.972818588721566e-06}, {"id": 769, "seek": 514476, "start": 5158.88, "end": 5163.84, "text": " so hopefully this notebook is going to be full of things you can experiment with and", "tokens": [370, 4696, 341, 21060, 307, 516, 281, 312, 1577, 295, 721, 291, 393, 5120, 365, 293], "temperature": 0.0, "avg_logprob": -0.16042015438988094, "compression_ratio": 1.8047808764940239, "no_speech_prob": 9.972818588721566e-06}, {"id": 770, "seek": 514476, "start": 5163.84, "end": 5170.280000000001, "text": " maybe even try submitting some Kaggle results.", "tokens": [1310, 754, 853, 31836, 512, 48751, 22631, 3542, 13], "temperature": 0.0, "avg_logprob": -0.16042015438988094, "compression_ratio": 1.8047808764940239, "no_speech_prob": 9.972818588721566e-06}, {"id": 771, "seek": 514476, "start": 5170.280000000001, "end": 5173.24, "text": " I guess the warnings about the inception network are a bit similar to the warnings about the", "tokens": [286, 2041, 264, 30009, 466, 264, 49834, 3209, 366, 257, 857, 2531, 281, 264, 30009, 466, 264], "temperature": 0.0, "avg_logprob": -0.16042015438988094, "compression_ratio": 1.8047808764940239, "no_speech_prob": 9.972818588721566e-06}, {"id": 772, "seek": 517324, "start": 5173.24, "end": 5180.48, "text": " ResNet network. Like ResNet, the inception network is available. Actually, Keras, I haven't", "tokens": [5015, 31890, 3209, 13, 1743, 5015, 31890, 11, 264, 49834, 3209, 307, 2435, 13, 5135, 11, 591, 6985, 11, 286, 2378, 380], "temperature": 0.0, "avg_logprob": -0.1759611197880336, "compression_ratio": 1.6233183856502242, "no_speech_prob": 4.2645930079743266e-05}, {"id": 773, "seek": 517324, "start": 5180.48, "end": 5186.0, "text": " converted one to my standard approach, but Keras has an inception network that you can", "tokens": [16424, 472, 281, 452, 3832, 3109, 11, 457, 591, 6985, 575, 364, 49834, 3209, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.1759611197880336, "compression_ratio": 1.6233183856502242, "no_speech_prob": 4.2645930079743266e-05}, {"id": 774, "seek": 517324, "start": 5186.0, "end": 5195.04, "text": " download and use. It hasn't been well studied in terms of its transfer learning capabilities.", "tokens": [5484, 293, 764, 13, 467, 6132, 380, 668, 731, 9454, 294, 2115, 295, 1080, 5003, 2539, 10862, 13], "temperature": 0.0, "avg_logprob": -0.1759611197880336, "compression_ratio": 1.6233183856502242, "no_speech_prob": 4.2645930079743266e-05}, {"id": 775, "seek": 517324, "start": 5195.04, "end": 5201.639999999999, "text": " And again, I haven't seen people who have won Kaggle competitions using transfer learning", "tokens": [400, 797, 11, 286, 2378, 380, 1612, 561, 567, 362, 1582, 48751, 22631, 26185, 1228, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.1759611197880336, "compression_ratio": 1.6233183856502242, "no_speech_prob": 4.2645930079743266e-05}, {"id": 776, "seek": 520164, "start": 5201.64, "end": 5209.08, "text": " of inception network, so it's just a little bit less well studied. But like ResNet, the", "tokens": [295, 49834, 3209, 11, 370, 309, 311, 445, 257, 707, 857, 1570, 731, 9454, 13, 583, 411, 5015, 31890, 11, 264], "temperature": 0.0, "avg_logprob": -0.17087933511445016, "compression_ratio": 1.4861878453038675, "no_speech_prob": 1.8631337297847494e-05}, {"id": 777, "seek": 520164, "start": 5209.08, "end": 5215.72, "text": " combination of inception plus ResNet is the most recent ImageNet winner. So if you are", "tokens": [6562, 295, 49834, 1804, 5015, 31890, 307, 264, 881, 5162, 29903, 31890, 8507, 13, 407, 498, 291, 366], "temperature": 0.0, "avg_logprob": -0.17087933511445016, "compression_ratio": 1.4861878453038675, "no_speech_prob": 1.8631337297847494e-05}, {"id": 778, "seek": 520164, "start": 5215.72, "end": 5222.6, "text": " looking to really start with the most predictive model, this is where you would want to start.", "tokens": [1237, 281, 534, 722, 365, 264, 881, 35521, 2316, 11, 341, 307, 689, 291, 576, 528, 281, 722, 13], "temperature": 0.0, "avg_logprob": -0.17087933511445016, "compression_ratio": 1.4861878453038675, "no_speech_prob": 1.8631337297847494e-05}, {"id": 779, "seek": 522260, "start": 5222.6, "end": 5236.400000000001, "text": " So I want to finish off on a very different note, which is looking at RNNs one more time.", "tokens": [407, 286, 528, 281, 2413, 766, 322, 257, 588, 819, 3637, 11, 597, 307, 1237, 412, 45702, 45, 82, 472, 544, 565, 13], "temperature": 0.0, "avg_logprob": -0.13983971542782253, "compression_ratio": 1.4565217391304348, "no_speech_prob": 9.666014193498995e-06}, {"id": 780, "seek": 522260, "start": 5236.400000000001, "end": 5242.120000000001, "text": " I've spent much more time on CNNs and RNNs. The reason is that this course is really all", "tokens": [286, 600, 4418, 709, 544, 565, 322, 24859, 82, 293, 45702, 45, 82, 13, 440, 1778, 307, 300, 341, 1164, 307, 534, 439], "temperature": 0.0, "avg_logprob": -0.13983971542782253, "compression_ratio": 1.4565217391304348, "no_speech_prob": 9.666014193498995e-06}, {"id": 781, "seek": 522260, "start": 5242.120000000001, "end": 5248.68, "text": " about being pragmatic. It's about teaching you the stuff that works. In the vast majority", "tokens": [466, 885, 46904, 13, 467, 311, 466, 4571, 291, 264, 1507, 300, 1985, 13, 682, 264, 8369, 6286], "temperature": 0.0, "avg_logprob": -0.13983971542782253, "compression_ratio": 1.4565217391304348, "no_speech_prob": 9.666014193498995e-06}, {"id": 782, "seek": 524868, "start": 5248.68, "end": 5258.52, "text": " of areas where I see people using deep learning to solve their problems, they're using CNNs.", "tokens": [295, 3179, 689, 286, 536, 561, 1228, 2452, 2539, 281, 5039, 641, 2740, 11, 436, 434, 1228, 24859, 82, 13], "temperature": 0.0, "avg_logprob": -0.14232502520923884, "compression_ratio": 1.5376344086021505, "no_speech_prob": 6.643380402238108e-06}, {"id": 783, "seek": 524868, "start": 5258.52, "end": 5265.18, "text": " Having said that, some of the most challenging problems are now being solved with RNNs like", "tokens": [10222, 848, 300, 11, 512, 295, 264, 881, 7595, 2740, 366, 586, 885, 13041, 365, 45702, 45, 82, 411], "temperature": 0.0, "avg_logprob": -0.14232502520923884, "compression_ratio": 1.5376344086021505, "no_speech_prob": 6.643380402238108e-06}, {"id": 784, "seek": 524868, "start": 5265.18, "end": 5271.0, "text": " speech recognition and language translation. So when you use Google Translate now, you're", "tokens": [6218, 11150, 293, 2856, 12853, 13, 407, 562, 291, 764, 3329, 6531, 17593, 586, 11, 291, 434], "temperature": 0.0, "avg_logprob": -0.14232502520923884, "compression_ratio": 1.5376344086021505, "no_speech_prob": 6.643380402238108e-06}, {"id": 785, "seek": 524868, "start": 5271.0, "end": 5272.0, "text": " using RNNs.", "tokens": [1228, 45702, 45, 82, 13], "temperature": 0.0, "avg_logprob": -0.14232502520923884, "compression_ratio": 1.5376344086021505, "no_speech_prob": 6.643380402238108e-06}, {"id": 786, "seek": 527200, "start": 5272.0, "end": 5279.52, "text": " My suspicion is you're going to come across these kinds of problems a lot less often.", "tokens": [1222, 32020, 307, 291, 434, 516, 281, 808, 2108, 613, 3685, 295, 2740, 257, 688, 1570, 2049, 13], "temperature": 0.0, "avg_logprob": -0.16821603041428787, "compression_ratio": 1.5344827586206897, "no_speech_prob": 7.889177140896209e-06}, {"id": 787, "seek": 527200, "start": 5279.52, "end": 5287.08, "text": " But I also suspect that in a business context, a very common kind of problem is a time series", "tokens": [583, 286, 611, 9091, 300, 294, 257, 1606, 4319, 11, 257, 588, 2689, 733, 295, 1154, 307, 257, 565, 2638], "temperature": 0.0, "avg_logprob": -0.16821603041428787, "compression_ratio": 1.5344827586206897, "no_speech_prob": 7.889177140896209e-06}, {"id": 788, "seek": 527200, "start": 5287.08, "end": 5293.72, "text": " problem, like looking at the time series of click events on your website, or e-commerce", "tokens": [1154, 11, 411, 1237, 412, 264, 565, 2638, 295, 2052, 3931, 322, 428, 3144, 11, 420, 308, 12, 26926], "temperature": 0.0, "avg_logprob": -0.16821603041428787, "compression_ratio": 1.5344827586206897, "no_speech_prob": 7.889177140896209e-06}, {"id": 789, "seek": 529372, "start": 5293.72, "end": 5304.12, "text": " transactions or logistics. These sequence-to-sequence RNNs we've been looking at, which we've been", "tokens": [16856, 420, 27420, 13, 1981, 8310, 12, 1353, 12, 11834, 655, 45702, 45, 82, 321, 600, 668, 1237, 412, 11, 597, 321, 600, 668], "temperature": 0.0, "avg_logprob": -0.14914884911962303, "compression_ratio": 1.554054054054054, "no_speech_prob": 8.664569577376824e-06}, {"id": 790, "seek": 529372, "start": 5304.12, "end": 5309.92, "text": " using to create Nietzschean philosophy, are identical to the ones you would use to analyze", "tokens": [1228, 281, 1884, 36583, 89, 12287, 282, 10675, 11, 366, 14800, 281, 264, 2306, 291, 576, 764, 281, 12477], "temperature": 0.0, "avg_logprob": -0.14914884911962303, "compression_ratio": 1.554054054054054, "no_speech_prob": 8.664569577376824e-06}, {"id": 791, "seek": 529372, "start": 5309.92, "end": 5315.4400000000005, "text": " a sequence of e-commerce transactions and try to find anomalies.", "tokens": [257, 8310, 295, 308, 12, 26926, 16856, 293, 853, 281, 915, 24769, 48872, 13], "temperature": 0.0, "avg_logprob": -0.14914884911962303, "compression_ratio": 1.554054054054054, "no_speech_prob": 8.664569577376824e-06}, {"id": 792, "seek": 529372, "start": 5315.4400000000005, "end": 5323.360000000001, "text": " So I think CNNs are more practically important for most people in most organizations right", "tokens": [407, 286, 519, 24859, 82, 366, 544, 15667, 1021, 337, 881, 561, 294, 881, 6150, 558], "temperature": 0.0, "avg_logprob": -0.14914884911962303, "compression_ratio": 1.554054054054054, "no_speech_prob": 8.664569577376824e-06}, {"id": 793, "seek": 532336, "start": 5323.36, "end": 5330.96, "text": " now. RNNs also have a lot of opportunities. And of course, we'll also be looking at them", "tokens": [586, 13, 45702, 45, 82, 611, 362, 257, 688, 295, 4786, 13, 400, 295, 1164, 11, 321, 603, 611, 312, 1237, 412, 552], "temperature": 0.0, "avg_logprob": -0.2050805268464265, "compression_ratio": 1.4975369458128078, "no_speech_prob": 3.169251067447476e-05}, {"id": 794, "seek": 532336, "start": 5330.96, "end": 5336.4, "text": " when it comes to attentional models next year, which is figuring out in a really big image", "tokens": [562, 309, 1487, 281, 3202, 304, 5245, 958, 1064, 11, 597, 307, 15213, 484, 294, 257, 534, 955, 3256], "temperature": 0.0, "avg_logprob": -0.2050805268464265, "compression_ratio": 1.4975369458128078, "no_speech_prob": 3.169251067447476e-05}, {"id": 795, "seek": 532336, "start": 5336.4, "end": 5345.08, "text": " which part should we look at next.", "tokens": [597, 644, 820, 321, 574, 412, 958, 13], "temperature": 0.0, "avg_logprob": -0.2050805268464265, "compression_ratio": 1.4975369458128078, "no_speech_prob": 3.169251067447476e-05}, {"id": 796, "seek": 532336, "start": 5345.08, "end": 5349.759999999999, "text": " The inception merge is a concat rather than an add, which is the same as what we saw when", "tokens": [440, 49834, 22183, 307, 257, 1588, 267, 2831, 813, 364, 909, 11, 597, 307, 264, 912, 382, 437, 321, 1866, 562], "temperature": 0.0, "avg_logprob": -0.2050805268464265, "compression_ratio": 1.4975369458128078, "no_speech_prob": 3.169251067447476e-05}, {"id": 797, "seek": 534976, "start": 5349.76, "end": 5360.16, "text": " we looked at Ben Bolz's quid NLP model. We're taking multiple convolution filter sizes and", "tokens": [321, 2956, 412, 3964, 14331, 89, 311, 421, 327, 426, 45196, 2316, 13, 492, 434, 1940, 3866, 45216, 6608, 11602, 293], "temperature": 0.0, "avg_logprob": -0.1647954548106474, "compression_ratio": 1.4777777777777779, "no_speech_prob": 1.834247996157501e-05}, {"id": 798, "seek": 534976, "start": 5360.16, "end": 5367.280000000001, "text": " we're sticking them next to each other. So that feature basically contains information", "tokens": [321, 434, 13465, 552, 958, 281, 1184, 661, 13, 407, 300, 4111, 1936, 8306, 1589], "temperature": 0.0, "avg_logprob": -0.1647954548106474, "compression_ratio": 1.4777777777777779, "no_speech_prob": 1.834247996157501e-05}, {"id": 799, "seek": 534976, "start": 5367.280000000001, "end": 5375.76, "text": " about 5x5 features and 3x3 features and 1x1 features. So when you add them together, you", "tokens": [466, 1025, 87, 20, 4122, 293, 805, 87, 18, 4122, 293, 502, 87, 16, 4122, 13, 407, 562, 291, 909, 552, 1214, 11, 291], "temperature": 0.0, "avg_logprob": -0.1647954548106474, "compression_ratio": 1.4777777777777779, "no_speech_prob": 1.834247996157501e-05}, {"id": 800, "seek": 537576, "start": 5375.76, "end": 5381.12, "text": " lose that information. And ResNet does that for a specific reason, we want to cause it", "tokens": [3624, 300, 1589, 13, 400, 5015, 31890, 775, 300, 337, 257, 2685, 1778, 11, 321, 528, 281, 3082, 309], "temperature": 0.0, "avg_logprob": -0.22041727041269277, "compression_ratio": 1.6045197740112995, "no_speech_prob": 8.397940291615669e-06}, {"id": 801, "seek": 537576, "start": 5381.12, "end": 5386.72, "text": " to own residuals. In inception, we don't want that. In inception, we want to keep them all", "tokens": [281, 1065, 27980, 82, 13, 682, 49834, 11, 321, 500, 380, 528, 300, 13, 682, 49834, 11, 321, 528, 281, 1066, 552, 439], "temperature": 0.0, "avg_logprob": -0.22041727041269277, "compression_ratio": 1.6045197740112995, "no_speech_prob": 8.397940291615669e-06}, {"id": 802, "seek": 537576, "start": 5386.72, "end": 5395.320000000001, "text": " in the feature space.", "tokens": [294, 264, 4111, 1901, 13], "temperature": 0.0, "avg_logprob": -0.22041727041269277, "compression_ratio": 1.6045197740112995, "no_speech_prob": 8.397940291615669e-06}, {"id": 803, "seek": 537576, "start": 5395.320000000001, "end": 5402.92, "text": " The other reason I wanted to look at RNNs is that last week we looked at building an", "tokens": [440, 661, 1778, 286, 1415, 281, 574, 412, 45702, 45, 82, 307, 300, 1036, 1243, 321, 2956, 412, 2390, 364], "temperature": 0.0, "avg_logprob": -0.22041727041269277, "compression_ratio": 1.6045197740112995, "no_speech_prob": 8.397940291615669e-06}, {"id": 804, "seek": 540292, "start": 5402.92, "end": 5409.4800000000005, "text": " RNN nearly from scratch in Theano. And I say nearly from scratch because there was one", "tokens": [45702, 45, 6217, 490, 8459, 294, 440, 3730, 13, 400, 286, 584, 6217, 490, 8459, 570, 456, 390, 472], "temperature": 0.0, "avg_logprob": -0.12452466147286552, "compression_ratio": 1.59375, "no_speech_prob": 1.202949533762876e-05}, {"id": 805, "seek": 540292, "start": 5409.4800000000005, "end": 5419.08, "text": " key step which it did for us, which was the gradients. Really understanding how the gradients", "tokens": [2141, 1823, 597, 309, 630, 337, 505, 11, 597, 390, 264, 2771, 2448, 13, 4083, 3701, 577, 264, 2771, 2448], "temperature": 0.0, "avg_logprob": -0.12452466147286552, "compression_ratio": 1.59375, "no_speech_prob": 1.202949533762876e-05}, {"id": 806, "seek": 540292, "start": 5419.08, "end": 5425.64, "text": " are calculated is not something you would probably ever have to do by hand, but I think", "tokens": [366, 15598, 307, 406, 746, 291, 576, 1391, 1562, 362, 281, 360, 538, 1011, 11, 457, 286, 519], "temperature": 0.0, "avg_logprob": -0.12452466147286552, "compression_ratio": 1.59375, "no_speech_prob": 1.202949533762876e-05}, {"id": 807, "seek": 540292, "start": 5425.64, "end": 5432.32, "text": " it can be very helpful to your intuition of training neural networks to be able to trace", "tokens": [309, 393, 312, 588, 4961, 281, 428, 24002, 295, 3097, 18161, 9590, 281, 312, 1075, 281, 13508], "temperature": 0.0, "avg_logprob": -0.12452466147286552, "compression_ratio": 1.59375, "no_speech_prob": 1.202949533762876e-05}, {"id": 808, "seek": 543232, "start": 5432.32, "end": 5433.32, "text": " it through.", "tokens": [309, 807, 13], "temperature": 0.0, "avg_logprob": -0.1464963800766889, "compression_ratio": 1.8852459016393444, "no_speech_prob": 6.14413920629886e-06}, {"id": 809, "seek": 543232, "start": 5433.32, "end": 5439.0, "text": " So for that reason, this is kind of the one time in this course, and next year's course,", "tokens": [407, 337, 300, 1778, 11, 341, 307, 733, 295, 264, 472, 565, 294, 341, 1164, 11, 293, 958, 1064, 311, 1164, 11], "temperature": 0.0, "avg_logprob": -0.1464963800766889, "compression_ratio": 1.8852459016393444, "no_speech_prob": 6.14413920629886e-06}, {"id": 810, "seek": 543232, "start": 5439.0, "end": 5443.96, "text": " where we're going to really go through and actually calculate the gradients ourselves.", "tokens": [689, 321, 434, 516, 281, 534, 352, 807, 293, 767, 8873, 264, 2771, 2448, 4175, 13], "temperature": 0.0, "avg_logprob": -0.1464963800766889, "compression_ratio": 1.8852459016393444, "no_speech_prob": 6.14413920629886e-06}, {"id": 811, "seek": 543232, "start": 5443.96, "end": 5450.2, "text": " So here is a recurrent neural network in pure Python. And the reason I'm doing a recurrent", "tokens": [407, 510, 307, 257, 18680, 1753, 18161, 3209, 294, 6075, 15329, 13, 400, 264, 1778, 286, 478, 884, 257, 18680, 1753], "temperature": 0.0, "avg_logprob": -0.1464963800766889, "compression_ratio": 1.8852459016393444, "no_speech_prob": 6.14413920629886e-06}, {"id": 812, "seek": 543232, "start": 5450.2, "end": 5454.88, "text": " neural network in pure Python is this is kind of the hardest. RNNs are the hardest thing", "tokens": [18161, 3209, 294, 6075, 15329, 307, 341, 307, 733, 295, 264, 13158, 13, 45702, 45, 82, 366, 264, 13158, 551], "temperature": 0.0, "avg_logprob": -0.1464963800766889, "compression_ratio": 1.8852459016393444, "no_speech_prob": 6.14413920629886e-06}, {"id": 813, "seek": 543232, "start": 5454.88, "end": 5461.28, "text": " to get your head around backpropagating gradients. So if you look at this and study this and", "tokens": [281, 483, 428, 1378, 926, 646, 79, 1513, 559, 990, 2771, 2448, 13, 407, 498, 291, 574, 412, 341, 293, 2979, 341, 293], "temperature": 0.0, "avg_logprob": -0.1464963800766889, "compression_ratio": 1.8852459016393444, "no_speech_prob": 6.14413920629886e-06}, {"id": 814, "seek": 546128, "start": 5461.28, "end": 5465.12, "text": " step through this over the next couple of months, you will really be able to get a great", "tokens": [1823, 807, 341, 670, 264, 958, 1916, 295, 2493, 11, 291, 486, 534, 312, 1075, 281, 483, 257, 869], "temperature": 0.0, "avg_logprob": -0.13641589727157202, "compression_ratio": 1.856, "no_speech_prob": 2.355231117689982e-05}, {"id": 815, "seek": 546128, "start": 5465.12, "end": 5469.84, "text": " understanding of what a neural net is really doing. There's going to be no magic or mystery", "tokens": [3701, 295, 437, 257, 18161, 2533, 307, 534, 884, 13, 821, 311, 516, 281, 312, 572, 5585, 420, 11422], "temperature": 0.0, "avg_logprob": -0.13641589727157202, "compression_ratio": 1.856, "no_speech_prob": 2.355231117689982e-05}, {"id": 816, "seek": 546128, "start": 5469.84, "end": 5475.599999999999, "text": " because this whole thing is going to be every line of code.", "tokens": [570, 341, 1379, 551, 307, 516, 281, 312, 633, 1622, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.13641589727157202, "compression_ratio": 1.856, "no_speech_prob": 2.355231117689982e-05}, {"id": 817, "seek": 546128, "start": 5475.599999999999, "end": 5481.599999999999, "text": " So if we're going to do it all ourselves, we have to write everything ourselves. So", "tokens": [407, 498, 321, 434, 516, 281, 360, 309, 439, 4175, 11, 321, 362, 281, 2464, 1203, 4175, 13, 407], "temperature": 0.0, "avg_logprob": -0.13641589727157202, "compression_ratio": 1.856, "no_speech_prob": 2.355231117689982e-05}, {"id": 818, "seek": 546128, "start": 5481.599999999999, "end": 5485.719999999999, "text": " if we want a sigmoid function, we have to write the sigmoid function. Anytime we write", "tokens": [498, 321, 528, 257, 4556, 3280, 327, 2445, 11, 321, 362, 281, 2464, 264, 4556, 3280, 327, 2445, 13, 39401, 321, 2464], "temperature": 0.0, "avg_logprob": -0.13641589727157202, "compression_ratio": 1.856, "no_speech_prob": 2.355231117689982e-05}, {"id": 819, "seek": 546128, "start": 5485.719999999999, "end": 5490.24, "text": " any function, we also have to create its derivative.", "tokens": [604, 2445, 11, 321, 611, 362, 281, 1884, 1080, 13760, 13], "temperature": 0.0, "avg_logprob": -0.13641589727157202, "compression_ratio": 1.856, "no_speech_prob": 2.355231117689982e-05}, {"id": 820, "seek": 549024, "start": 5490.24, "end": 5494.84, "text": " So I'm going to use this approach where underscore D is the derivative of the function. So I'm", "tokens": [407, 286, 478, 516, 281, 764, 341, 3109, 689, 37556, 413, 307, 264, 13760, 295, 264, 2445, 13, 407, 286, 478], "temperature": 0.0, "avg_logprob": -0.2529041847486175, "compression_ratio": 1.9021739130434783, "no_speech_prob": 1.618743408471346e-05}, {"id": 821, "seek": 549024, "start": 5494.84, "end": 5502.24, "text": " going to have to have relU and the derivative of relU. And I just kind of check myself as", "tokens": [516, 281, 362, 281, 362, 1039, 52, 293, 264, 13760, 295, 1039, 52, 13, 400, 286, 445, 733, 295, 1520, 2059, 382], "temperature": 0.0, "avg_logprob": -0.2529041847486175, "compression_ratio": 1.9021739130434783, "no_speech_prob": 1.618743408471346e-05}, {"id": 822, "seek": 549024, "start": 5502.24, "end": 5507.24, "text": " I go along that they look reasonable. The Euclidean distance and the derivative of the", "tokens": [286, 352, 2051, 300, 436, 574, 10585, 13, 440, 462, 1311, 31264, 282, 4560, 293, 264, 13760, 295, 264], "temperature": 0.0, "avg_logprob": -0.2529041847486175, "compression_ratio": 1.9021739130434783, "no_speech_prob": 1.618743408471346e-05}, {"id": 823, "seek": 549024, "start": 5507.24, "end": 5514.88, "text": " Euclidean distance. The cross entropy and the derivative of the cross entropy.", "tokens": [462, 1311, 31264, 282, 4560, 13, 440, 3278, 30867, 293, 264, 13760, 295, 264, 3278, 30867, 13], "temperature": 0.0, "avg_logprob": -0.2529041847486175, "compression_ratio": 1.9021739130434783, "no_speech_prob": 1.618743408471346e-05}, {"id": 824, "seek": 551488, "start": 5514.88, "end": 5521.28, "text": " And note here that I am clipping my predictions, because if you have zeros or ones there, you're", "tokens": [400, 3637, 510, 300, 286, 669, 49320, 452, 21264, 11, 570, 498, 291, 362, 35193, 420, 2306, 456, 11, 291, 434], "temperature": 0.0, "avg_logprob": -0.1862068342125934, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.5446208635694347e-05}, {"id": 825, "seek": 551488, "start": 5521.28, "end": 5527.28, "text": " going to get infinities and it destroys everything. So you have to be careful of this. This did", "tokens": [516, 281, 483, 7193, 1088, 293, 309, 36714, 1203, 13, 407, 291, 362, 281, 312, 5026, 295, 341, 13, 639, 630], "temperature": 0.0, "avg_logprob": -0.1862068342125934, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.5446208635694347e-05}, {"id": 826, "seek": 551488, "start": 5527.28, "end": 5530.400000000001, "text": " actually happen. I didn't have this clip in at first and I was starting to get infinities", "tokens": [767, 1051, 13, 286, 994, 380, 362, 341, 7353, 294, 412, 700, 293, 286, 390, 2891, 281, 483, 7193, 1088], "temperature": 0.0, "avg_logprob": -0.1862068342125934, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.5446208635694347e-05}, {"id": 827, "seek": 551488, "start": 5530.400000000001, "end": 5532.2, "text": " and this is necessary.", "tokens": [293, 341, 307, 4818, 13], "temperature": 0.0, "avg_logprob": -0.1862068342125934, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.5446208635694347e-05}, {"id": 828, "seek": 551488, "start": 5532.2, "end": 5538.6, "text": " Here's my softmax. Here's the derivative of softmax.", "tokens": [1692, 311, 452, 2787, 41167, 13, 1692, 311, 264, 13760, 295, 2787, 41167, 13], "temperature": 0.0, "avg_logprob": -0.1862068342125934, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.5446208635694347e-05}, {"id": 829, "seek": 551488, "start": 5538.6, "end": 5542.32, "text": " So then I basically go through and I double-check that the answers I get with my versions are", "tokens": [407, 550, 286, 1936, 352, 807, 293, 286, 3834, 12, 15723, 300, 264, 6338, 286, 483, 365, 452, 9606, 366], "temperature": 0.0, "avg_logprob": -0.1862068342125934, "compression_ratio": 1.6802973977695168, "no_speech_prob": 1.5446208635694347e-05}, {"id": 830, "seek": 554232, "start": 5542.32, "end": 5547.08, "text": " the same as the answers I get with the Theano versions to make sure they're all correct.", "tokens": [264, 912, 382, 264, 6338, 286, 483, 365, 264, 440, 3730, 9606, 281, 652, 988, 436, 434, 439, 3006, 13], "temperature": 0.0, "avg_logprob": -0.18870231083461217, "compression_ratio": 1.8018433179723503, "no_speech_prob": 8.664615961606614e-06}, {"id": 831, "seek": 554232, "start": 5547.08, "end": 5552.2, "text": " They all seem to be fine.", "tokens": [814, 439, 1643, 281, 312, 2489, 13], "temperature": 0.0, "avg_logprob": -0.18870231083461217, "compression_ratio": 1.8018433179723503, "no_speech_prob": 8.664615961606614e-06}, {"id": 832, "seek": 554232, "start": 5552.2, "end": 5557.84, "text": " So I am going to use as my activation function relU, which means the derivative is relU derivative", "tokens": [407, 286, 669, 516, 281, 764, 382, 452, 24433, 2445, 1039, 52, 11, 597, 1355, 264, 13760, 307, 1039, 52, 13760], "temperature": 0.0, "avg_logprob": -0.18870231083461217, "compression_ratio": 1.8018433179723503, "no_speech_prob": 8.664615961606614e-06}, {"id": 833, "seek": 554232, "start": 5557.84, "end": 5563.36, "text": " and my loss function is cross entropy. So the loss function is cross entropy derivative.", "tokens": [293, 452, 4470, 2445, 307, 3278, 30867, 13, 407, 264, 4470, 2445, 307, 3278, 30867, 13760, 13], "temperature": 0.0, "avg_logprob": -0.18870231083461217, "compression_ratio": 1.8018433179723503, "no_speech_prob": 8.664615961606614e-06}, {"id": 834, "seek": 554232, "start": 5563.36, "end": 5568.5199999999995, "text": " I also have to write my own scan. So you guys remember scan. Scan is this thing where we", "tokens": [286, 611, 362, 281, 2464, 452, 1065, 11049, 13, 407, 291, 1074, 1604, 11049, 13, 41177, 307, 341, 551, 689, 321], "temperature": 0.0, "avg_logprob": -0.18870231083461217, "compression_ratio": 1.8018433179723503, "no_speech_prob": 8.664615961606614e-06}, {"id": 835, "seek": 556852, "start": 5568.52, "end": 5573.400000000001, "text": " go through a sequence one step at a time, calling a function on each element of the", "tokens": [352, 807, 257, 8310, 472, 1823, 412, 257, 565, 11, 5141, 257, 2445, 322, 1184, 4478, 295, 264], "temperature": 0.0, "avg_logprob": -0.13873389748965992, "compression_ratio": 1.7553191489361701, "no_speech_prob": 6.24091990175657e-06}, {"id": 836, "seek": 556852, "start": 5573.400000000001, "end": 5578.160000000001, "text": " sequence. And each time the function is going to get 2 things, it's going to get the next", "tokens": [8310, 13, 400, 1184, 565, 264, 2445, 307, 516, 281, 483, 568, 721, 11, 309, 311, 516, 281, 483, 264, 958], "temperature": 0.0, "avg_logprob": -0.13873389748965992, "compression_ratio": 1.7553191489361701, "no_speech_prob": 6.24091990175657e-06}, {"id": 837, "seek": 556852, "start": 5578.160000000001, "end": 5582.700000000001, "text": " element of the sequence as well as the previous result of the call.", "tokens": [4478, 295, 264, 8310, 382, 731, 382, 264, 3894, 1874, 295, 264, 818, 13], "temperature": 0.0, "avg_logprob": -0.13873389748965992, "compression_ratio": 1.7553191489361701, "no_speech_prob": 6.24091990175657e-06}, {"id": 838, "seek": 556852, "start": 5582.700000000001, "end": 5592.6, "text": " So for example, scan of add2things together on the integers from 0 to 5 is going to give", "tokens": [407, 337, 1365, 11, 11049, 295, 909, 17, 825, 82, 1214, 322, 264, 41674, 490, 1958, 281, 1025, 307, 516, 281, 976], "temperature": 0.0, "avg_logprob": -0.13873389748965992, "compression_ratio": 1.7553191489361701, "no_speech_prob": 6.24091990175657e-06}, {"id": 839, "seek": 559260, "start": 5592.6, "end": 5599.52, "text": " us a cumulative sum. And remember the reason we do this is because GPUs don't know how", "tokens": [505, 257, 38379, 2408, 13, 400, 1604, 264, 1778, 321, 360, 341, 307, 570, 18407, 82, 500, 380, 458, 577], "temperature": 0.0, "avg_logprob": -0.18747057466425449, "compression_ratio": 1.6537102473498233, "no_speech_prob": 2.482472609699471e-06}, {"id": 840, "seek": 559260, "start": 5599.52, "end": 5603.92, "text": " to do loops, so our Theano version used a scan, and I wanted to make this as close to", "tokens": [281, 360, 16121, 11, 370, 527, 440, 3730, 3037, 1143, 257, 11049, 11, 293, 286, 1415, 281, 652, 341, 382, 1998, 281], "temperature": 0.0, "avg_logprob": -0.18747057466425449, "compression_ratio": 1.6537102473498233, "no_speech_prob": 2.482472609699471e-06}, {"id": 841, "seek": 559260, "start": 5603.92, "end": 5606.360000000001, "text": " the Theano version as possible.", "tokens": [264, 440, 3730, 3037, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.18747057466425449, "compression_ratio": 1.6537102473498233, "no_speech_prob": 2.482472609699471e-06}, {"id": 842, "seek": 559260, "start": 5606.360000000001, "end": 5612.0, "text": " In Theano, scan is not implemented like this with a for loop. In Theano, they use a very", "tokens": [682, 440, 3730, 11, 11049, 307, 406, 12270, 411, 341, 365, 257, 337, 6367, 13, 682, 440, 3730, 11, 436, 764, 257, 588], "temperature": 0.0, "avg_logprob": -0.18747057466425449, "compression_ratio": 1.6537102473498233, "no_speech_prob": 2.482472609699471e-06}, {"id": 843, "seek": 559260, "start": 5612.0, "end": 5616.4400000000005, "text": " clever approach which basically creates a tree where it does a whole lot of the things", "tokens": [13494, 3109, 597, 1936, 7829, 257, 4230, 689, 309, 775, 257, 1379, 688, 295, 264, 721], "temperature": 0.0, "avg_logprob": -0.18747057466425449, "compression_ratio": 1.6537102473498233, "no_speech_prob": 2.482472609699471e-06}, {"id": 844, "seek": 559260, "start": 5616.4400000000005, "end": 5621.84, "text": " kind of simultaneously and gradually combines them together. Next year we may even look", "tokens": [733, 295, 16561, 293, 13145, 29520, 552, 1214, 13, 3087, 1064, 321, 815, 754, 574], "temperature": 0.0, "avg_logprob": -0.18747057466425449, "compression_ratio": 1.6537102473498233, "no_speech_prob": 2.482472609699471e-06}, {"id": 845, "seek": 562184, "start": 5621.84, "end": 5627.08, "text": " at how that works if anybody's interested.", "tokens": [412, 577, 300, 1985, 498, 4472, 311, 3102, 13], "temperature": 0.0, "avg_logprob": -0.21573625292096818, "compression_ratio": 1.5492957746478873, "no_speech_prob": 7.29630482965149e-06}, {"id": 846, "seek": 562184, "start": 5627.08, "end": 5633.64, "text": " So in order to create our Michian philosophy, we need an input and an output. So we have", "tokens": [407, 294, 1668, 281, 1884, 527, 3392, 952, 10675, 11, 321, 643, 364, 4846, 293, 364, 5598, 13, 407, 321, 362], "temperature": 0.0, "avg_logprob": -0.21573625292096818, "compression_ratio": 1.5492957746478873, "no_speech_prob": 7.29630482965149e-06}, {"id": 847, "seek": 562184, "start": 5633.64, "end": 5641.64, "text": " the 8 character sequences, one hot encoded for our inputs, and the 8 character sequences", "tokens": [264, 1649, 2517, 22978, 11, 472, 2368, 2058, 12340, 337, 527, 15743, 11, 293, 264, 1649, 2517, 22978], "temperature": 0.0, "avg_logprob": -0.21573625292096818, "compression_ratio": 1.5492957746478873, "no_speech_prob": 7.29630482965149e-06}, {"id": 848, "seek": 564164, "start": 5641.64, "end": 5652.12, "text": " moved across by one, one hot encoded for our outputs. And we've got our vocab size, which", "tokens": [4259, 2108, 538, 472, 11, 472, 2368, 2058, 12340, 337, 527, 23930, 13, 400, 321, 600, 658, 527, 2329, 455, 2744, 11, 597], "temperature": 0.0, "avg_logprob": -0.22878416923627462, "compression_ratio": 1.5843373493975903, "no_speech_prob": 3.844918410322862e-06}, {"id": 849, "seek": 564164, "start": 5652.12, "end": 5656.88, "text": " is 86 characters. So here's our input and output shapes, 75,000 phrases, each one has", "tokens": [307, 26687, 4342, 13, 407, 510, 311, 527, 4846, 293, 5598, 10854, 11, 9562, 11, 1360, 20312, 11, 1184, 472, 575], "temperature": 0.0, "avg_logprob": -0.22878416923627462, "compression_ratio": 1.5843373493975903, "no_speech_prob": 3.844918410322862e-06}, {"id": 850, "seek": 564164, "start": 5656.88, "end": 5664.4800000000005, "text": " 8 characters in, and each of those 8 characters is a one hot encoded vector of size 86.", "tokens": [1649, 4342, 294, 11, 293, 1184, 295, 729, 1649, 4342, 307, 257, 472, 2368, 2058, 12340, 8062, 295, 2744, 26687, 13], "temperature": 0.0, "avg_logprob": -0.22878416923627462, "compression_ratio": 1.5843373493975903, "no_speech_prob": 3.844918410322862e-06}, {"id": 851, "seek": 566448, "start": 5664.48, "end": 5674.44, "text": " So we first of all need to do the forward pass. So the forward pass is to scan through", "tokens": [407, 321, 700, 295, 439, 643, 281, 360, 264, 2128, 1320, 13, 407, 264, 2128, 1320, 307, 281, 11049, 807], "temperature": 0.0, "avg_logprob": -0.14550792603265672, "compression_ratio": 1.7541899441340782, "no_speech_prob": 2.902301275753416e-06}, {"id": 852, "seek": 566448, "start": 5674.44, "end": 5682.4, "text": " all of the characters in the nth phrase, the input and output, calling some function. So", "tokens": [439, 295, 264, 4342, 294, 264, 297, 392, 9535, 11, 264, 4846, 293, 5598, 11, 5141, 512, 2445, 13, 407], "temperature": 0.0, "avg_logprob": -0.14550792603265672, "compression_ratio": 1.7541899441340782, "no_speech_prob": 2.902301275753416e-06}, {"id": 853, "seek": 566448, "start": 5682.4, "end": 5687.759999999999, "text": " here is the forward pass. And this is basically identical to what we saw in Theano. In Theano,", "tokens": [510, 307, 264, 2128, 1320, 13, 400, 341, 307, 1936, 14800, 281, 437, 321, 1866, 294, 440, 3730, 13, 682, 440, 3730, 11], "temperature": 0.0, "avg_logprob": -0.14550792603265672, "compression_ratio": 1.7541899441340782, "no_speech_prob": 2.902301275753416e-06}, {"id": 854, "seek": 566448, "start": 5687.759999999999, "end": 5690.04, "text": " we had to lay out the forward pass as well.", "tokens": [321, 632, 281, 2360, 484, 264, 2128, 1320, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.14550792603265672, "compression_ratio": 1.7541899441340782, "no_speech_prob": 2.902301275753416e-06}, {"id": 855, "seek": 569004, "start": 5690.04, "end": 5695.16, "text": " So to create the hidden state, we have to take the dot product of X with its weight", "tokens": [407, 281, 1884, 264, 7633, 1785, 11, 321, 362, 281, 747, 264, 5893, 1674, 295, 1783, 365, 1080, 3364], "temperature": 0.0, "avg_logprob": -0.13500654914162374, "compression_ratio": 2.284974093264249, "no_speech_prob": 3.480749364825897e-05}, {"id": 856, "seek": 569004, "start": 5695.16, "end": 5700.8, "text": " matrix and the dot product of the hidden with its weight matrix, and then we have to put", "tokens": [8141, 293, 264, 5893, 1674, 295, 264, 7633, 365, 1080, 3364, 8141, 11, 293, 550, 321, 362, 281, 829], "temperature": 0.0, "avg_logprob": -0.13500654914162374, "compression_ratio": 2.284974093264249, "no_speech_prob": 3.480749364825897e-05}, {"id": 857, "seek": 569004, "start": 5700.8, "end": 5706.28, "text": " all that through the activation function. And then to create the predictions, we have", "tokens": [439, 300, 807, 264, 24433, 2445, 13, 400, 550, 281, 1884, 264, 21264, 11, 321, 362], "temperature": 0.0, "avg_logprob": -0.13500654914162374, "compression_ratio": 2.284974093264249, "no_speech_prob": 3.480749364825897e-05}, {"id": 858, "seek": 569004, "start": 5706.28, "end": 5712.92, "text": " to take the dot product of the hidden with its weight matrix and then put that through", "tokens": [281, 747, 264, 5893, 1674, 295, 264, 7633, 365, 1080, 3364, 8141, 293, 550, 829, 300, 807], "temperature": 0.0, "avg_logprob": -0.13500654914162374, "compression_ratio": 2.284974093264249, "no_speech_prob": 3.480749364825897e-05}, {"id": 859, "seek": 569004, "start": 5712.92, "end": 5715.28, "text": " softmax.", "tokens": [2787, 41167, 13], "temperature": 0.0, "avg_logprob": -0.13500654914162374, "compression_ratio": 2.284974093264249, "no_speech_prob": 3.480749364825897e-05}, {"id": 860, "seek": 569004, "start": 5715.28, "end": 5718.92, "text": " And so we have to make sure we keep track of all of the state that it needs, so at the", "tokens": [400, 370, 321, 362, 281, 652, 988, 321, 1066, 2837, 295, 439, 295, 264, 1785, 300, 309, 2203, 11, 370, 412, 264], "temperature": 0.0, "avg_logprob": -0.13500654914162374, "compression_ratio": 2.284974093264249, "no_speech_prob": 3.480749364825897e-05}, {"id": 861, "seek": 571892, "start": 5718.92, "end": 5731.2, "text": " end we will return the loss, the pre-hidden and pre-pred, because we're going to use them", "tokens": [917, 321, 486, 2736, 264, 4470, 11, 264, 659, 12, 71, 6171, 293, 659, 12, 79, 986, 11, 570, 321, 434, 516, 281, 764, 552], "temperature": 0.0, "avg_logprob": -0.1742204993662208, "compression_ratio": 1.7254901960784315, "no_speech_prob": 1.1125539458589628e-05}, {"id": 862, "seek": 571892, "start": 5731.2, "end": 5736.88, "text": " each time we go through. In the backprop, we'll be using those. We need to know the", "tokens": [1184, 565, 321, 352, 807, 13, 682, 264, 646, 79, 1513, 11, 321, 603, 312, 1228, 729, 13, 492, 643, 281, 458, 264], "temperature": 0.0, "avg_logprob": -0.1742204993662208, "compression_ratio": 1.7254901960784315, "no_speech_prob": 1.1125539458589628e-05}, {"id": 863, "seek": 571892, "start": 5736.88, "end": 5740.8, "text": " hidden state, of course, we have to keep track of that because we're going to be using it", "tokens": [7633, 1785, 11, 295, 1164, 11, 321, 362, 281, 1066, 2837, 295, 300, 570, 321, 434, 516, 281, 312, 1228, 309], "temperature": 0.0, "avg_logprob": -0.1742204993662208, "compression_ratio": 1.7254901960784315, "no_speech_prob": 1.1125539458589628e-05}, {"id": 864, "seek": 571892, "start": 5740.8, "end": 5747.04, "text": " the next time through the RNN. And of course we're going to need our actual predictions.", "tokens": [264, 958, 565, 807, 264, 45702, 45, 13, 400, 295, 1164, 321, 434, 516, 281, 643, 527, 3539, 21264, 13], "temperature": 0.0, "avg_logprob": -0.1742204993662208, "compression_ratio": 1.7254901960784315, "no_speech_prob": 1.1125539458589628e-05}, {"id": 865, "seek": 574704, "start": 5747.04, "end": 5750.6, "text": " So that's the forward pass, very similar to Theano.", "tokens": [407, 300, 311, 264, 2128, 1320, 11, 588, 2531, 281, 440, 3730, 13], "temperature": 0.0, "avg_logprob": -0.18849007288614908, "compression_ratio": 1.6421052631578947, "no_speech_prob": 1.2805365258827806e-05}, {"id": 866, "seek": 574704, "start": 5750.6, "end": 5757.5199999999995, "text": " The backward pass is the bit I wanted to show you. I want to show you how I think about", "tokens": [440, 23897, 1320, 307, 264, 857, 286, 1415, 281, 855, 291, 13, 286, 528, 281, 855, 291, 577, 286, 519, 466], "temperature": 0.0, "avg_logprob": -0.18849007288614908, "compression_ratio": 1.6421052631578947, "no_speech_prob": 1.2805365258827806e-05}, {"id": 867, "seek": 574704, "start": 5757.5199999999995, "end": 5770.16, "text": " it. This is how I think about it. All of my errors, I've reversed their direction. And", "tokens": [309, 13, 639, 307, 577, 286, 519, 466, 309, 13, 1057, 295, 452, 13603, 11, 286, 600, 30563, 641, 3513, 13, 400], "temperature": 0.0, "avg_logprob": -0.18849007288614908, "compression_ratio": 1.6421052631578947, "no_speech_prob": 1.2805365258827806e-05}, {"id": 868, "seek": 574704, "start": 5770.16, "end": 5774.04, "text": " the reason for that is that when we create a derivative, we're really saying how does", "tokens": [264, 1778, 337, 300, 307, 300, 562, 321, 1884, 257, 13760, 11, 321, 434, 534, 1566, 577, 775], "temperature": 0.0, "avg_logprob": -0.18849007288614908, "compression_ratio": 1.6421052631578947, "no_speech_prob": 1.2805365258827806e-05}, {"id": 869, "seek": 577404, "start": 5774.04, "end": 5782.24, "text": " a change in the input impact the output. And to do that, we have to use the chain rule,", "tokens": [257, 1319, 294, 264, 4846, 2712, 264, 5598, 13, 400, 281, 360, 300, 11, 321, 362, 281, 764, 264, 5021, 4978, 11], "temperature": 0.0, "avg_logprob": -0.13527242997113395, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.769393177004531e-06}, {"id": 870, "seek": 577404, "start": 5782.24, "end": 5785.96, "text": " we have to go back from the end all the way back to the start.", "tokens": [321, 362, 281, 352, 646, 490, 264, 917, 439, 264, 636, 646, 281, 264, 722, 13], "temperature": 0.0, "avg_logprob": -0.13527242997113395, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.769393177004531e-06}, {"id": 871, "seek": 577404, "start": 5785.96, "end": 5796.2, "text": " So this is our output last hidden layer activation matrix. This is our loss, which is adding", "tokens": [407, 341, 307, 527, 5598, 1036, 7633, 4583, 24433, 8141, 13, 639, 307, 527, 4470, 11, 597, 307, 5127], "temperature": 0.0, "avg_logprob": -0.13527242997113395, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.769393177004531e-06}, {"id": 872, "seek": 577404, "start": 5796.2, "end": 5802.64, "text": " together all of the losses of each of the characters. If we want the derivative of the", "tokens": [1214, 439, 295, 264, 15352, 295, 1184, 295, 264, 4342, 13, 759, 321, 528, 264, 13760, 295, 264], "temperature": 0.0, "avg_logprob": -0.13527242997113395, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.769393177004531e-06}, {"id": 873, "seek": 580264, "start": 5802.64, "end": 5806.96, "text": " loss with respect to this hidden activation, we would have to take the derivative of the", "tokens": [4470, 365, 3104, 281, 341, 7633, 24433, 11, 321, 576, 362, 281, 747, 264, 13760, 295, 264], "temperature": 0.0, "avg_logprob": -0.11408001394832835, "compression_ratio": 2.1021505376344085, "no_speech_prob": 1.9222916307626292e-05}, {"id": 874, "seek": 580264, "start": 5806.96, "end": 5812.4800000000005, "text": " loss with respect to this output activation and multiply it by the derivative of this", "tokens": [4470, 365, 3104, 281, 341, 5598, 24433, 293, 12972, 309, 538, 264, 13760, 295, 341], "temperature": 0.0, "avg_logprob": -0.11408001394832835, "compression_ratio": 2.1021505376344085, "no_speech_prob": 1.9222916307626292e-05}, {"id": 875, "seek": 580264, "start": 5812.4800000000005, "end": 5817.280000000001, "text": " output activation with respect to this hidden activation. We have to then multiply them", "tokens": [5598, 24433, 365, 3104, 281, 341, 7633, 24433, 13, 492, 362, 281, 550, 12972, 552], "temperature": 0.0, "avg_logprob": -0.11408001394832835, "compression_ratio": 2.1021505376344085, "no_speech_prob": 1.9222916307626292e-05}, {"id": 876, "seek": 580264, "start": 5817.280000000001, "end": 5819.84, "text": " together because that's the chain rule.", "tokens": [1214, 570, 300, 311, 264, 5021, 4978, 13], "temperature": 0.0, "avg_logprob": -0.11408001394832835, "compression_ratio": 2.1021505376344085, "no_speech_prob": 1.9222916307626292e-05}, {"id": 877, "seek": 580264, "start": 5819.84, "end": 5828.64, "text": " The chain rule basically tells you to go from some function of some other function of x,", "tokens": [440, 5021, 4978, 1936, 5112, 291, 281, 352, 490, 512, 2445, 295, 512, 661, 2445, 295, 2031, 11], "temperature": 0.0, "avg_logprob": -0.11408001394832835, "compression_ratio": 2.1021505376344085, "no_speech_prob": 1.9222916307626292e-05}, {"id": 878, "seek": 582864, "start": 5828.64, "end": 5837.72, "text": " the derivative is the product of those functions.", "tokens": [264, 13760, 307, 264, 1674, 295, 729, 6828, 13], "temperature": 0.0, "avg_logprob": -0.15249976244839755, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.356872523203492e-06}, {"id": 879, "seek": 582864, "start": 5837.72, "end": 5844.200000000001, "text": " So I find it really helpful to literally draw the arrows. Let's draw the arrow from the", "tokens": [407, 286, 915, 309, 534, 4961, 281, 3736, 2642, 264, 19669, 13, 961, 311, 2642, 264, 11610, 490, 264], "temperature": 0.0, "avg_logprob": -0.15249976244839755, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.356872523203492e-06}, {"id": 880, "seek": 582864, "start": 5844.200000000001, "end": 5849.96, "text": " loss function to each of the outputs as well.", "tokens": [4470, 2445, 281, 1184, 295, 264, 23930, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.15249976244839755, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.356872523203492e-06}, {"id": 881, "seek": 582864, "start": 5849.96, "end": 5857.160000000001, "text": " And so to calculate the derivatives, we basically have to go through and undo each of those", "tokens": [400, 370, 281, 8873, 264, 33733, 11, 321, 1936, 362, 281, 352, 807, 293, 23779, 1184, 295, 729], "temperature": 0.0, "avg_logprob": -0.15249976244839755, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.356872523203492e-06}, {"id": 882, "seek": 585716, "start": 5857.16, "end": 5862.32, "text": " steps. In order to figure out how that input would change that output, we have to undo", "tokens": [4439, 13, 682, 1668, 281, 2573, 484, 577, 300, 4846, 576, 1319, 300, 5598, 11, 321, 362, 281, 23779], "temperature": 0.0, "avg_logprob": -0.17034659224949525, "compression_ratio": 1.768041237113402, "no_speech_prob": 2.6425780106364982e-06}, {"id": 883, "seek": 585716, "start": 5862.32, "end": 5866.72, "text": " it. We have to go back along the arrow in the opposite direction.", "tokens": [309, 13, 492, 362, 281, 352, 646, 2051, 264, 11610, 294, 264, 6182, 3513, 13], "temperature": 0.0, "avg_logprob": -0.17034659224949525, "compression_ratio": 1.768041237113402, "no_speech_prob": 2.6425780106364982e-06}, {"id": 884, "seek": 585716, "start": 5866.72, "end": 5872.5199999999995, "text": " So how do we get from the loss to the output?", "tokens": [407, 577, 360, 321, 483, 490, 264, 4470, 281, 264, 5598, 30], "temperature": 0.0, "avg_logprob": -0.17034659224949525, "compression_ratio": 1.768041237113402, "no_speech_prob": 2.6425780106364982e-06}, {"id": 885, "seek": 585716, "start": 5872.5199999999995, "end": 5879.08, "text": " So to do that, we need the derivative of the loss function, and then we're also going to", "tokens": [407, 281, 360, 300, 11, 321, 643, 264, 13760, 295, 264, 4470, 2445, 11, 293, 550, 321, 434, 611, 516, 281], "temperature": 0.0, "avg_logprob": -0.17034659224949525, "compression_ratio": 1.768041237113402, "no_speech_prob": 2.6425780106364982e-06}, {"id": 886, "seek": 585716, "start": 5879.08, "end": 5885.76, "text": " need the derivative of the activation function as well.", "tokens": [643, 264, 13760, 295, 264, 24433, 2445, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17034659224949525, "compression_ratio": 1.768041237113402, "no_speech_prob": 2.6425780106364982e-06}, {"id": 887, "seek": 588576, "start": 5885.76, "end": 5893.64, "text": " So you can see it here. This is a single backward pass. We grab one of our inputs, one of our", "tokens": [407, 291, 393, 536, 309, 510, 13, 639, 307, 257, 2167, 23897, 1320, 13, 492, 4444, 472, 295, 527, 15743, 11, 472, 295, 527], "temperature": 0.0, "avg_logprob": -0.1380232445737149, "compression_ratio": 1.7548076923076923, "no_speech_prob": 1.5446214092662558e-05}, {"id": 888, "seek": 588576, "start": 5893.64, "end": 5900.84, "text": " outputs, and then we go backwards through each one, each of the 8 characters, from the end", "tokens": [23930, 11, 293, 550, 321, 352, 12204, 807, 1184, 472, 11, 1184, 295, 264, 1649, 4342, 11, 490, 264, 917], "temperature": 0.0, "avg_logprob": -0.1380232445737149, "compression_ratio": 1.7548076923076923, "no_speech_prob": 1.5446214092662558e-05}, {"id": 889, "seek": 588576, "start": 5900.84, "end": 5908.0, "text": " to the start. So grab our input character and our output character. And the first thing", "tokens": [281, 264, 722, 13, 407, 4444, 527, 4846, 2517, 293, 527, 5598, 2517, 13, 400, 264, 700, 551], "temperature": 0.0, "avg_logprob": -0.1380232445737149, "compression_ratio": 1.7548076923076923, "no_speech_prob": 1.5446214092662558e-05}, {"id": 890, "seek": 588576, "start": 5908.0, "end": 5915.6, "text": " we want is the derivative of pre-pred. Remember pre-pred was the prediction prior to putting", "tokens": [321, 528, 307, 264, 13760, 295, 659, 12, 79, 986, 13, 5459, 659, 12, 79, 986, 390, 264, 17630, 4059, 281, 3372], "temperature": 0.0, "avg_logprob": -0.1380232445737149, "compression_ratio": 1.7548076923076923, "no_speech_prob": 1.5446214092662558e-05}, {"id": 891, "seek": 591560, "start": 5915.6, "end": 5918.8, "text": " it through the softmax.", "tokens": [309, 807, 264, 2787, 41167, 13], "temperature": 0.0, "avg_logprob": -0.1492183382918195, "compression_ratio": 2.066225165562914, "no_speech_prob": 1.1843102583952714e-05}, {"id": 892, "seek": 591560, "start": 5918.8, "end": 5925.400000000001, "text": " So that was the bit I just showed you. It's the derivative of the softmax times the derivative", "tokens": [407, 300, 390, 264, 857, 286, 445, 4712, 291, 13, 467, 311, 264, 13760, 295, 264, 2787, 41167, 1413, 264, 13760], "temperature": 0.0, "avg_logprob": -0.1492183382918195, "compression_ratio": 2.066225165562914, "no_speech_prob": 1.1843102583952714e-05}, {"id": 893, "seek": 591560, "start": 5925.400000000001, "end": 5933.120000000001, "text": " of the loss. So the derivative of the loss is going to get us from here back to here,", "tokens": [295, 264, 4470, 13, 407, 264, 13760, 295, 264, 4470, 307, 516, 281, 483, 505, 490, 510, 646, 281, 510, 11], "temperature": 0.0, "avg_logprob": -0.1492183382918195, "compression_ratio": 2.066225165562914, "no_speech_prob": 1.1843102583952714e-05}, {"id": 894, "seek": 591560, "start": 5933.120000000001, "end": 5938.240000000001, "text": " and then the derivative of the softmax gets us from here back to the other side of the", "tokens": [293, 550, 264, 13760, 295, 264, 2787, 41167, 2170, 505, 490, 510, 646, 281, 264, 661, 1252, 295, 264], "temperature": 0.0, "avg_logprob": -0.1492183382918195, "compression_ratio": 2.066225165562914, "no_speech_prob": 1.1843102583952714e-05}, {"id": 895, "seek": 591560, "start": 5938.240000000001, "end": 5939.240000000001, "text": " activation function.", "tokens": [24433, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1492183382918195, "compression_ratio": 2.066225165562914, "no_speech_prob": 1.1843102583952714e-05}, {"id": 896, "seek": 593924, "start": 5939.24, "end": 5952.5199999999995, "text": " So that's what that gets us to. So we want to keep going further, which is we want to", "tokens": [407, 300, 311, 437, 300, 2170, 505, 281, 13, 407, 321, 528, 281, 1066, 516, 3052, 11, 597, 307, 321, 528, 281], "temperature": 0.0, "avg_logprob": -0.16217147827148437, "compression_ratio": 1.4700854700854702, "no_speech_prob": 2.3187260012491606e-05}, {"id": 897, "seek": 593924, "start": 5952.5199999999995, "end": 5959.679999999999, "text": " get back to the other side of the hidden. We want to get all the way over now to here.", "tokens": [483, 646, 281, 264, 661, 1252, 295, 264, 7633, 13, 492, 528, 281, 483, 439, 264, 636, 670, 586, 281, 510, 13], "temperature": 0.0, "avg_logprob": -0.16217147827148437, "compression_ratio": 1.4700854700854702, "no_speech_prob": 2.3187260012491606e-05}, {"id": 898, "seek": 595968, "start": 5959.68, "end": 5977.400000000001, "text": " So to do that, we have to take the derivative of a matrix multiplication is the multiplication", "tokens": [407, 281, 360, 300, 11, 321, 362, 281, 747, 264, 13760, 295, 257, 8141, 27290, 307, 264, 27290], "temperature": 0.0, "avg_logprob": -0.16087876425849068, "compression_ratio": 1.6206896551724137, "no_speech_prob": 1.1478699889266863e-05}, {"id": 899, "seek": 595968, "start": 5977.400000000001, "end": 5986.0, "text": " with the transpose of that matrix. So in order to take the derivative of the pre-hidden times", "tokens": [365, 264, 25167, 295, 300, 8141, 13, 407, 294, 1668, 281, 747, 264, 13760, 295, 264, 659, 12, 71, 6171, 1413], "temperature": 0.0, "avg_logprob": -0.16087876425849068, "compression_ratio": 1.6206896551724137, "no_speech_prob": 1.1478699889266863e-05}, {"id": 900, "seek": 598600, "start": 5986.0, "end": 5993.8, "text": " its weights, we simply take it by the transpose of its weights. So this is the derivative", "tokens": [1080, 17443, 11, 321, 2935, 747, 309, 538, 264, 25167, 295, 1080, 17443, 13, 407, 341, 307, 264, 13760], "temperature": 0.0, "avg_logprob": -0.19222356111575395, "compression_ratio": 1.6988636363636365, "no_speech_prob": 1.4285393262980506e-05}, {"id": 901, "seek": 598600, "start": 5993.8, "end": 5996.0, "text": " of that part.", "tokens": [295, 300, 644, 13], "temperature": 0.0, "avg_logprob": -0.19222356111575395, "compression_ratio": 1.6988636363636365, "no_speech_prob": 1.4285393262980506e-05}, {"id": 902, "seek": 598600, "start": 5996.0, "end": 6000.8, "text": " And remember the hidden, we've actually got 2 arrows coming back out of it, and we've", "tokens": [400, 1604, 264, 7633, 11, 321, 600, 767, 658, 568, 19669, 1348, 646, 484, 295, 309, 11, 293, 321, 600], "temperature": 0.0, "avg_logprob": -0.19222356111575395, "compression_ratio": 1.6988636363636365, "no_speech_prob": 1.4285393262980506e-05}, {"id": 903, "seek": 598600, "start": 6000.8, "end": 6008.92, "text": " got also 2 arrows coming into it. So we're going to have to add together that derivative", "tokens": [658, 611, 568, 19669, 1348, 666, 309, 13, 407, 321, 434, 516, 281, 362, 281, 909, 1214, 300, 13760], "temperature": 0.0, "avg_logprob": -0.19222356111575395, "compression_ratio": 1.6988636363636365, "no_speech_prob": 1.4285393262980506e-05}, {"id": 904, "seek": 598600, "start": 6008.92, "end": 6010.92, "text": " and that derivative.", "tokens": [293, 300, 13760, 13], "temperature": 0.0, "avg_logprob": -0.19222356111575395, "compression_ratio": 1.6988636363636365, "no_speech_prob": 1.4285393262980506e-05}, {"id": 905, "seek": 601092, "start": 6010.92, "end": 6017.0, "text": " So here is the second part. So there it is with respect to the outputs, and there it", "tokens": [407, 510, 307, 264, 1150, 644, 13, 407, 456, 309, 307, 365, 3104, 281, 264, 23930, 11, 293, 456, 309], "temperature": 0.0, "avg_logprob": -0.164096310933431, "compression_ratio": 1.8282208588957056, "no_speech_prob": 4.356864792498527e-06}, {"id": 906, "seek": 601092, "start": 6017.0, "end": 6024.16, "text": " is with respect to the hidden. And then finally we have to undo the activation function. So", "tokens": [307, 365, 3104, 281, 264, 7633, 13, 400, 550, 2721, 321, 362, 281, 23779, 264, 24433, 2445, 13, 407], "temperature": 0.0, "avg_logprob": -0.164096310933431, "compression_ratio": 1.8282208588957056, "no_speech_prob": 4.356864792498527e-06}, {"id": 907, "seek": 601092, "start": 6024.16, "end": 6028.92, "text": " multiply it by the derivative of the activation function. So that's the chain rule that gets", "tokens": [12972, 309, 538, 264, 13760, 295, 264, 24433, 2445, 13, 407, 300, 311, 264, 5021, 4978, 300, 2170], "temperature": 0.0, "avg_logprob": -0.164096310933431, "compression_ratio": 1.8282208588957056, "no_speech_prob": 4.356864792498527e-06}, {"id": 908, "seek": 601092, "start": 6028.92, "end": 6034.56, "text": " us all the way back to here.", "tokens": [505, 439, 264, 636, 646, 281, 510, 13], "temperature": 0.0, "avg_logprob": -0.164096310933431, "compression_ratio": 1.8282208588957056, "no_speech_prob": 4.356864792498527e-06}, {"id": 909, "seek": 603456, "start": 6034.56, "end": 6042.0, "text": " So now that we've got those 2 pieces of information, we can update our weights. So we can now say", "tokens": [407, 586, 300, 321, 600, 658, 729, 568, 3755, 295, 1589, 11, 321, 393, 5623, 527, 17443, 13, 407, 321, 393, 586, 584], "temperature": 0.0, "avg_logprob": -0.1626269057556823, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.223427696269937e-06}, {"id": 910, "seek": 603456, "start": 6042.0, "end": 6049.160000000001, "text": " for the blue line, what are these weights now going to equal? So we basically have to", "tokens": [337, 264, 3344, 1622, 11, 437, 366, 613, 17443, 586, 516, 281, 2681, 30, 407, 321, 1936, 362, 281], "temperature": 0.0, "avg_logprob": -0.1626269057556823, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.223427696269937e-06}, {"id": 911, "seek": 603456, "start": 6049.160000000001, "end": 6056.360000000001, "text": " take the derivative that we got to at this point, which we called dprepred, we have to", "tokens": [747, 264, 13760, 300, 321, 658, 281, 412, 341, 935, 11, 597, 321, 1219, 274, 3712, 79, 986, 11, 321, 362, 281], "temperature": 0.0, "avg_logprob": -0.1626269057556823, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.223427696269937e-06}, {"id": 912, "seek": 603456, "start": 6056.360000000001, "end": 6064.120000000001, "text": " multiply it by our learning rate, and then we have to undo the multiplication by the", "tokens": [12972, 309, 538, 527, 2539, 3314, 11, 293, 550, 321, 362, 281, 23779, 264, 27290, 538, 264], "temperature": 0.0, "avg_logprob": -0.1626269057556823, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.223427696269937e-06}, {"id": 913, "seek": 606412, "start": 6064.12, "end": 6069.68, "text": " hidden state to get the derivative with respect to the weights. And I created this little", "tokens": [7633, 1785, 281, 483, 264, 13760, 365, 3104, 281, 264, 17443, 13, 400, 286, 2942, 341, 707], "temperature": 0.0, "avg_logprob": -0.19320311753646188, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.3923308617668226e-05}, {"id": 914, "seek": 606412, "start": 6069.68, "end": 6075.92, "text": " columnify function to do that. So it's turning a vector into a column, so it's taking its", "tokens": [7738, 2505, 2445, 281, 360, 300, 13, 407, 309, 311, 6246, 257, 8062, 666, 257, 7738, 11, 370, 309, 311, 1940, 1080], "temperature": 0.0, "avg_logprob": -0.19320311753646188, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.3923308617668226e-05}, {"id": 915, "seek": 606412, "start": 6075.92, "end": 6077.76, "text": " transpose if you like.", "tokens": [25167, 498, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.19320311753646188, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.3923308617668226e-05}, {"id": 916, "seek": 606412, "start": 6077.76, "end": 6083.08, "text": " So that gives me my new output weights. My new hidden weights are basically the same", "tokens": [407, 300, 2709, 385, 452, 777, 5598, 17443, 13, 1222, 777, 7633, 17443, 366, 1936, 264, 912], "temperature": 0.0, "avg_logprob": -0.19320311753646188, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.3923308617668226e-05}, {"id": 917, "seek": 606412, "start": 6083.08, "end": 6089.32, "text": " thing. It's the learning rate times the derivative that we just calculated, and then we have", "tokens": [551, 13, 467, 311, 264, 2539, 3314, 1413, 264, 13760, 300, 321, 445, 15598, 11, 293, 550, 321, 362], "temperature": 0.0, "avg_logprob": -0.19320311753646188, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.3923308617668226e-05}, {"id": 918, "seek": 608932, "start": 6089.32, "end": 6096.36, "text": " to undo its weights and our new input weights, again the learning rate times the pre-hidden", "tokens": [281, 23779, 1080, 17443, 293, 527, 777, 4846, 17443, 11, 797, 264, 2539, 3314, 1413, 264, 659, 12, 71, 6171], "temperature": 0.0, "avg_logprob": -0.23738560676574708, "compression_ratio": 1.4766355140186915, "no_speech_prob": 4.029439423902659e-06}, {"id": 919, "seek": 608932, "start": 6096.36, "end": 6100.16, "text": " times the columnified version of X.", "tokens": [1413, 264, 7738, 2587, 3037, 295, 1783, 13], "temperature": 0.0, "avg_logprob": -0.23738560676574708, "compression_ratio": 1.4766355140186915, "no_speech_prob": 4.029439423902659e-06}, {"id": 920, "seek": 608932, "start": 6100.16, "end": 6105.88, "text": " So I'm going through that very quickly. The details aren't important, but if you're interested,", "tokens": [407, 286, 478, 516, 807, 300, 588, 2661, 13, 440, 4365, 3212, 380, 1021, 11, 457, 498, 291, 434, 3102, 11], "temperature": 0.0, "avg_logprob": -0.23738560676574708, "compression_ratio": 1.4766355140186915, "no_speech_prob": 4.029439423902659e-06}, {"id": 921, "seek": 608932, "start": 6105.88, "end": 6112.12, "text": " it might be fun to look at it over the Christmas break or the next few days. Because you can", "tokens": [309, 1062, 312, 1019, 281, 574, 412, 309, 670, 264, 5272, 1821, 420, 264, 958, 1326, 1708, 13, 1436, 291, 393], "temperature": 0.0, "avg_logprob": -0.23738560676574708, "compression_ratio": 1.4766355140186915, "no_speech_prob": 4.029439423902659e-06}, {"id": 922, "seek": 611212, "start": 6112.12, "end": 6120.2, "text": " see in this here is all the steps necessary to do backprop through an RNN, which is also", "tokens": [536, 294, 341, 510, 307, 439, 264, 4439, 4818, 281, 360, 646, 79, 1513, 807, 364, 45702, 45, 11, 597, 307, 611], "temperature": 0.0, "avg_logprob": -0.1627368697200913, "compression_ratio": 1.4790697674418605, "no_speech_prob": 2.247379597974941e-05}, {"id": 923, "seek": 611212, "start": 6120.2, "end": 6124.64, "text": " why we would never want to do this by hand again.", "tokens": [983, 321, 576, 1128, 528, 281, 360, 341, 538, 1011, 797, 13], "temperature": 0.0, "avg_logprob": -0.1627368697200913, "compression_ratio": 1.4790697674418605, "no_speech_prob": 2.247379597974941e-05}, {"id": 924, "seek": 611212, "start": 6124.64, "end": 6133.08, "text": " So when I wrote this code, luckily I did it before I got my cold. You can see I've written", "tokens": [407, 562, 286, 4114, 341, 3089, 11, 22880, 286, 630, 309, 949, 286, 658, 452, 3554, 13, 509, 393, 536, 286, 600, 3720], "temperature": 0.0, "avg_logprob": -0.1627368697200913, "compression_ratio": 1.4790697674418605, "no_speech_prob": 2.247379597974941e-05}, {"id": 925, "seek": 611212, "start": 6133.08, "end": 6137.64, "text": " after every one the dimensions of each matrix and vector because it makes your head hurt", "tokens": [934, 633, 472, 264, 12819, 295, 1184, 8141, 293, 8062, 570, 309, 1669, 428, 1378, 4607], "temperature": 0.0, "avg_logprob": -0.1627368697200913, "compression_ratio": 1.4790697674418605, "no_speech_prob": 2.247379597974941e-05}, {"id": 926, "seek": 613764, "start": 6137.64, "end": 6144.12, "text": " just keeping everything straight. So thank God, Theano does this for us. But I think", "tokens": [445, 5145, 1203, 2997, 13, 407, 1309, 1265, 11, 440, 3730, 775, 341, 337, 505, 13, 583, 286, 519], "temperature": 0.0, "avg_logprob": -0.29144628188189337, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.9550775404204614e-06}, {"id": 927, "seek": 613764, "start": 6144.12, "end": 6147.68, "text": " it's useful to see it.", "tokens": [309, 311, 4420, 281, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.29144628188189337, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.9550775404204614e-06}, {"id": 928, "seek": 613764, "start": 6147.68, "end": 6154.4800000000005, "text": " So finally, I now just have to create my initial weight matrices, which are normally distributed", "tokens": [407, 2721, 11, 286, 586, 445, 362, 281, 1884, 452, 5883, 3364, 32284, 11, 597, 366, 5646, 12631], "temperature": 0.0, "avg_logprob": -0.29144628188189337, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.9550775404204614e-06}, {"id": 929, "seek": 613764, "start": 6154.4800000000005, "end": 6159.160000000001, "text": " matrices where these normal distributions are going to use the square root of 2 divided", "tokens": [32284, 689, 613, 2710, 37870, 366, 516, 281, 764, 264, 3732, 5593, 295, 568, 6666], "temperature": 0.0, "avg_logprob": -0.29144628188189337, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.9550775404204614e-06}, {"id": 930, "seek": 613764, "start": 6159.160000000001, "end": 6162.240000000001, "text": " by the number of inputs, because that's that chloro thing.", "tokens": [538, 264, 1230, 295, 15743, 11, 570, 300, 311, 300, 18178, 78, 551, 13], "temperature": 0.0, "avg_logprob": -0.29144628188189337, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.9550775404204614e-06}, {"id": 931, "seek": 616224, "start": 6162.24, "end": 6171.12, "text": " Remember, for my hidden matrix, for a simple RNN, we'll use the identity matrix to initialize", "tokens": [5459, 11, 337, 452, 7633, 8141, 11, 337, 257, 2199, 45702, 45, 11, 321, 603, 764, 264, 6575, 8141, 281, 5883, 1125], "temperature": 0.0, "avg_logprob": -0.20005339070370323, "compression_ratio": 1.576271186440678, "no_speech_prob": 1.2029390745738056e-05}, {"id": 932, "seek": 616224, "start": 6171.12, "end": 6178.12, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.20005339070370323, "compression_ratio": 1.576271186440678, "no_speech_prob": 1.2029390745738056e-05}, {"id": 933, "seek": 616224, "start": 6178.12, "end": 6182.48, "text": " We haven't got to that bit yet. So it depends how we use this. At this stage, all we've", "tokens": [492, 2378, 380, 658, 281, 300, 857, 1939, 13, 407, 309, 5946, 577, 321, 764, 341, 13, 1711, 341, 3233, 11, 439, 321, 600], "temperature": 0.0, "avg_logprob": -0.20005339070370323, "compression_ratio": 1.576271186440678, "no_speech_prob": 1.2029390745738056e-05}, {"id": 934, "seek": 616224, "start": 6182.48, "end": 6188.719999999999, "text": " done is we've defined the matrices and we've defined the transitions. And whether we maintain", "tokens": [1096, 307, 321, 600, 7642, 264, 32284, 293, 321, 600, 7642, 264, 23767, 13, 400, 1968, 321, 6909], "temperature": 0.0, "avg_logprob": -0.20005339070370323, "compression_ratio": 1.576271186440678, "no_speech_prob": 1.2029390745738056e-05}, {"id": 935, "seek": 618872, "start": 6188.72, "end": 6194.04, "text": " state will depend entirely on what we do next, which is the loop.", "tokens": [1785, 486, 5672, 7696, 322, 437, 321, 360, 958, 11, 597, 307, 264, 6367, 13], "temperature": 0.0, "avg_logprob": -0.22023858446063418, "compression_ratio": 1.5705128205128205, "no_speech_prob": 1.4510388609778602e-05}, {"id": 936, "seek": 618872, "start": 6194.04, "end": 6201.7, "text": " So here is our loop. So in our loop, we're going to go through a bunch of examples. Run", "tokens": [407, 510, 307, 527, 6367, 13, 407, 294, 527, 6367, 11, 321, 434, 516, 281, 352, 807, 257, 3840, 295, 5110, 13, 8950], "temperature": 0.0, "avg_logprob": -0.22023858446063418, "compression_ratio": 1.5705128205128205, "no_speech_prob": 1.4510388609778602e-05}, {"id": 937, "seek": 618872, "start": 6201.7, "end": 6212.52, "text": " one forward step and then one backward step, and then from time to time print out how we're", "tokens": [472, 2128, 1823, 293, 550, 472, 23897, 1823, 11, 293, 550, 490, 565, 281, 565, 4482, 484, 577, 321, 434], "temperature": 0.0, "avg_logprob": -0.22023858446063418, "compression_ratio": 1.5705128205128205, "no_speech_prob": 1.4510388609778602e-05}, {"id": 938, "seek": 621252, "start": 6212.52, "end": 6225.120000000001, "text": " getting along. So in this case, the forward step is passing to scan the initial state", "tokens": [1242, 2051, 13, 407, 294, 341, 1389, 11, 264, 2128, 1823, 307, 8437, 281, 11049, 264, 5883, 1785], "temperature": 0.0, "avg_logprob": -0.13558315885239752, "compression_ratio": 1.5529411764705883, "no_speech_prob": 8.186351010408544e-07}, {"id": 939, "seek": 621252, "start": 6225.120000000001, "end": 6232.040000000001, "text": " is a whole bunch of zeros. So currently this is resetting the state. It's not doing it", "tokens": [307, 257, 1379, 3840, 295, 35193, 13, 407, 4362, 341, 307, 14322, 783, 264, 1785, 13, 467, 311, 406, 884, 309], "temperature": 0.0, "avg_logprob": -0.13558315885239752, "compression_ratio": 1.5529411764705883, "no_speech_prob": 8.186351010408544e-07}, {"id": 940, "seek": 621252, "start": 6232.040000000001, "end": 6237.92, "text": " statefully. If you wanted to do it statefully, it would be pretty easy to change. You would", "tokens": [1785, 2277, 13, 759, 291, 1415, 281, 360, 309, 1785, 2277, 11, 309, 576, 312, 1238, 1858, 281, 1319, 13, 509, 576], "temperature": 0.0, "avg_logprob": -0.13558315885239752, "compression_ratio": 1.5529411764705883, "no_speech_prob": 8.186351010408544e-07}, {"id": 941, "seek": 623792, "start": 6237.92, "end": 6244.6, "text": " have to have the final state returned by this and keep track of it and then feed it back", "tokens": [362, 281, 362, 264, 2572, 1785, 8752, 538, 341, 293, 1066, 2837, 295, 309, 293, 550, 3154, 309, 646], "temperature": 0.0, "avg_logprob": -0.14481788303541102, "compression_ratio": 1.6153846153846154, "no_speech_prob": 8.26780069473898e-06}, {"id": 942, "seek": 623792, "start": 6244.6, "end": 6246.16, "text": " the next time through the loop.", "tokens": [264, 958, 565, 807, 264, 6367, 13], "temperature": 0.0, "avg_logprob": -0.14481788303541102, "compression_ratio": 1.6153846153846154, "no_speech_prob": 8.26780069473898e-06}, {"id": 943, "seek": 623792, "start": 6246.16, "end": 6249.72, "text": " If you're interested, maybe you could try that. Having said that, you probably won't", "tokens": [759, 291, 434, 3102, 11, 1310, 291, 727, 853, 300, 13, 10222, 848, 300, 11, 291, 1391, 1582, 380], "temperature": 0.0, "avg_logprob": -0.14481788303541102, "compression_ratio": 1.6153846153846154, "no_speech_prob": 8.26780069473898e-06}, {"id": 944, "seek": 623792, "start": 6249.72, "end": 6254.28, "text": " get great results, because remember that when you do things statefully, you're much more", "tokens": [483, 869, 3542, 11, 570, 1604, 300, 562, 291, 360, 721, 1785, 2277, 11, 291, 434, 709, 544], "temperature": 0.0, "avg_logprob": -0.14481788303541102, "compression_ratio": 1.6153846153846154, "no_speech_prob": 8.26780069473898e-06}, {"id": 945, "seek": 623792, "start": 6254.28, "end": 6260.6, "text": " likely to have gradients and activations explode unless you do a GRU or an LSTM, which we're", "tokens": [3700, 281, 362, 2771, 2448, 293, 2430, 763, 21411, 5969, 291, 360, 257, 10903, 52, 420, 364, 441, 6840, 44, 11, 597, 321, 434], "temperature": 0.0, "avg_logprob": -0.14481788303541102, "compression_ratio": 1.6153846153846154, "no_speech_prob": 8.26780069473898e-06}, {"id": 946, "seek": 623792, "start": 6260.6, "end": 6265.92, "text": " not. So my guess is it probably won't work very well.", "tokens": [406, 13, 407, 452, 2041, 307, 309, 1391, 1582, 380, 589, 588, 731, 13], "temperature": 0.0, "avg_logprob": -0.14481788303541102, "compression_ratio": 1.6153846153846154, "no_speech_prob": 8.26780069473898e-06}, {"id": 947, "seek": 626592, "start": 6265.92, "end": 6275.12, "text": " So that was a very quick fly-through and really more showing you around the code so that if", "tokens": [407, 300, 390, 257, 588, 1702, 3603, 12, 11529, 293, 534, 544, 4099, 291, 926, 264, 3089, 370, 300, 498], "temperature": 0.0, "avg_logprob": -0.1808141072591146, "compression_ratio": 1.6, "no_speech_prob": 3.6119679407420335e-06}, {"id": 948, "seek": 626592, "start": 6275.12, "end": 6279.92, "text": " you're interested, you can check it out.", "tokens": [291, 434, 3102, 11, 291, 393, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.1808141072591146, "compression_ratio": 1.6, "no_speech_prob": 3.6119679407420335e-06}, {"id": 949, "seek": 626592, "start": 6279.92, "end": 6287.4, "text": " What I really wanted to do though was get onto this more interesting type of RNN. There", "tokens": [708, 286, 534, 1415, 281, 360, 1673, 390, 483, 3911, 341, 544, 1880, 2010, 295, 45702, 45, 13, 821], "temperature": 0.0, "avg_logprob": -0.1808141072591146, "compression_ratio": 1.6, "no_speech_prob": 3.6119679407420335e-06}, {"id": 950, "seek": 626592, "start": 6287.4, "end": 6295.0, "text": " are actually two interesting types of RNN called long short-term memory and gated recurrent", "tokens": [366, 767, 732, 1880, 3467, 295, 45702, 45, 1219, 938, 2099, 12, 7039, 4675, 293, 290, 770, 18680, 1753], "temperature": 0.0, "avg_logprob": -0.1808141072591146, "compression_ratio": 1.6, "no_speech_prob": 3.6119679407420335e-06}, {"id": 951, "seek": 629500, "start": 6295.0, "end": 6302.0, "text": " unit. Many of you will have heard of the one on the left, LSTM.", "tokens": [4985, 13, 5126, 295, 291, 486, 362, 2198, 295, 264, 472, 322, 264, 1411, 11, 441, 6840, 44, 13], "temperature": 0.0, "avg_logprob": -0.2598656245640346, "compression_ratio": 1.2131147540983607, "no_speech_prob": 2.2124842871562578e-05}, {"id": 952, "seek": 629500, "start": 6302.0, "end": 6318.44, "text": " For stateful RNNs, you can't exactly have mini-batches because you're doing one at a", "tokens": [1171, 1785, 906, 45702, 45, 82, 11, 291, 393, 380, 2293, 362, 8382, 12, 65, 852, 279, 570, 291, 434, 884, 472, 412, 257], "temperature": 0.0, "avg_logprob": -0.2598656245640346, "compression_ratio": 1.2131147540983607, "no_speech_prob": 2.2124842871562578e-05}, {"id": 953, "seek": 631844, "start": 6318.44, "end": 6328.08, "text": " time. In our case, we were going through it in order.", "tokens": [565, 13, 682, 527, 1389, 11, 321, 645, 516, 807, 309, 294, 1668, 13], "temperature": 0.0, "avg_logprob": -0.19768177590719083, "compression_ratio": 1.4734299516908214, "no_speech_prob": 1.101590896723792e-06}, {"id": 954, "seek": 631844, "start": 6328.08, "end": 6334.719999999999, "text": " Using mini-batches is a great way to parallelize things on the GPU and make things run faster.", "tokens": [11142, 8382, 12, 65, 852, 279, 307, 257, 869, 636, 281, 8952, 1125, 721, 322, 264, 18407, 293, 652, 721, 1190, 4663, 13], "temperature": 0.0, "avg_logprob": -0.19768177590719083, "compression_ratio": 1.4734299516908214, "no_speech_prob": 1.101590896723792e-06}, {"id": 955, "seek": 631844, "start": 6334.719999999999, "end": 6341.44, "text": " Then you have to be careful about how you're thinking about state.", "tokens": [1396, 291, 362, 281, 312, 5026, 466, 577, 291, 434, 1953, 466, 1785, 13], "temperature": 0.0, "avg_logprob": -0.19768177590719083, "compression_ratio": 1.4734299516908214, "no_speech_prob": 1.101590896723792e-06}, {"id": 956, "seek": 631844, "start": 6341.44, "end": 6344.879999999999, "text": " So LSTM's a lot of you will have heard about because they've been pretty popular over the", "tokens": [407, 441, 6840, 44, 311, 257, 688, 295, 291, 486, 362, 2198, 466, 570, 436, 600, 668, 1238, 3743, 670, 264], "temperature": 0.0, "avg_logprob": -0.19768177590719083, "compression_ratio": 1.4734299516908214, "no_speech_prob": 1.101590896723792e-06}, {"id": 957, "seek": 634488, "start": 6344.88, "end": 6350.16, "text": " last couple of years for all kinds of cool stuff that Google does.", "tokens": [1036, 1916, 295, 924, 337, 439, 3685, 295, 1627, 1507, 300, 3329, 775, 13], "temperature": 0.0, "avg_logprob": -0.12397107211026279, "compression_ratio": 1.5352112676056338, "no_speech_prob": 5.9550770856731106e-06}, {"id": 958, "seek": 634488, "start": 6350.16, "end": 6359.08, "text": " On the right, however, is the GRU, which is simpler and better than the LSTM. So I'm not", "tokens": [1282, 264, 558, 11, 4461, 11, 307, 264, 10903, 52, 11, 597, 307, 18587, 293, 1101, 813, 264, 441, 6840, 44, 13, 407, 286, 478, 406], "temperature": 0.0, "avg_logprob": -0.12397107211026279, "compression_ratio": 1.5352112676056338, "no_speech_prob": 5.9550770856731106e-06}, {"id": 959, "seek": 634488, "start": 6359.08, "end": 6365.400000000001, "text": " going to talk about the LSTM, I'm going to talk about the GRU. They're both techniques", "tokens": [516, 281, 751, 466, 264, 441, 6840, 44, 11, 286, 478, 516, 281, 751, 466, 264, 10903, 52, 13, 814, 434, 1293, 7512], "temperature": 0.0, "avg_logprob": -0.12397107211026279, "compression_ratio": 1.5352112676056338, "no_speech_prob": 5.9550770856731106e-06}, {"id": 960, "seek": 634488, "start": 6365.400000000001, "end": 6369.4800000000005, "text": " for building your recurrent neural network where your gradients are much less likely", "tokens": [337, 2390, 428, 18680, 1753, 18161, 3209, 689, 428, 2771, 2448, 366, 709, 1570, 3700], "temperature": 0.0, "avg_logprob": -0.12397107211026279, "compression_ratio": 1.5352112676056338, "no_speech_prob": 5.9550770856731106e-06}, {"id": 961, "seek": 636948, "start": 6369.48, "end": 6379.48, "text": " to explode. Another great interesting example of a clever architecture, but it's just going", "tokens": [281, 21411, 13, 3996, 869, 1880, 1365, 295, 257, 13494, 9482, 11, 457, 309, 311, 445, 516], "temperature": 0.0, "avg_logprob": -0.16544005076090496, "compression_ratio": 1.4761904761904763, "no_speech_prob": 6.144127382867737e-06}, {"id": 962, "seek": 636948, "start": 6379.48, "end": 6384.5599999999995, "text": " to be more of using the same ideas that we've seen again and again.", "tokens": [281, 312, 544, 295, 1228, 264, 912, 3487, 300, 321, 600, 1612, 797, 293, 797, 13], "temperature": 0.0, "avg_logprob": -0.16544005076090496, "compression_ratio": 1.4761904761904763, "no_speech_prob": 6.144127382867737e-06}, {"id": 963, "seek": 636948, "start": 6384.5599999999995, "end": 6397.4, "text": " So what we have here on the right hand side is this box is basically zooming into what's", "tokens": [407, 437, 321, 362, 510, 322, 264, 558, 1011, 1252, 307, 341, 2424, 307, 1936, 48226, 666, 437, 311], "temperature": 0.0, "avg_logprob": -0.16544005076090496, "compression_ratio": 1.4761904761904763, "no_speech_prob": 6.144127382867737e-06}, {"id": 964, "seek": 639740, "start": 6397.4, "end": 6401.44, "text": " going on inside one of these circles in a GRU.", "tokens": [516, 322, 1854, 472, 295, 613, 13040, 294, 257, 10903, 52, 13], "temperature": 0.0, "avg_logprob": -0.2276048147550193, "compression_ratio": 1.7464788732394365, "no_speech_prob": 1.428531322744675e-05}, {"id": 965, "seek": 639740, "start": 6401.44, "end": 6405.759999999999, "text": " So normally in our standard RNN, what's going on in here is pretty simple, which is we do", "tokens": [407, 5646, 294, 527, 3832, 45702, 45, 11, 437, 311, 516, 322, 294, 510, 307, 1238, 2199, 11, 597, 307, 321, 360], "temperature": 0.0, "avg_logprob": -0.2276048147550193, "compression_ratio": 1.7464788732394365, "no_speech_prob": 1.428531322744675e-05}, {"id": 966, "seek": 639740, "start": 6405.759999999999, "end": 6411.719999999999, "text": " a multiplication by this WH weight matrix and stick it through an activation function,", "tokens": [257, 27290, 538, 341, 8183, 3364, 8141, 293, 2897, 309, 807, 364, 24433, 2445, 11], "temperature": 0.0, "avg_logprob": -0.2276048147550193, "compression_ratio": 1.7464788732394365, "no_speech_prob": 1.428531322744675e-05}, {"id": 967, "seek": 639740, "start": 6411.719999999999, "end": 6416.759999999999, "text": " and we grab our input, do it by a multiplication by weight matrix, grab its and put it through", "tokens": [293, 321, 4444, 527, 4846, 11, 360, 309, 538, 257, 27290, 538, 3364, 8141, 11, 4444, 1080, 293, 829, 309, 807], "temperature": 0.0, "avg_logprob": -0.2276048147550193, "compression_ratio": 1.7464788732394365, "no_speech_prob": 1.428531322744675e-05}, {"id": 968, "seek": 639740, "start": 6416.759999999999, "end": 6421.92, "text": " its activation function, and we add the two together.", "tokens": [1080, 24433, 2445, 11, 293, 321, 909, 264, 732, 1214, 13], "temperature": 0.0, "avg_logprob": -0.2276048147550193, "compression_ratio": 1.7464788732394365, "no_speech_prob": 1.428531322744675e-05}, {"id": 969, "seek": 642192, "start": 6421.92, "end": 6427.92, "text": " A GRU is going to do something more complex. We still have the input coming in and the", "tokens": [316, 10903, 52, 307, 516, 281, 360, 746, 544, 3997, 13, 492, 920, 362, 264, 4846, 1348, 294, 293, 264], "temperature": 0.0, "avg_logprob": -0.13386194893483366, "compression_ratio": 1.6854460093896713, "no_speech_prob": 7.411264505208237e-06}, {"id": 970, "seek": 642192, "start": 6427.92, "end": 6433.12, "text": " output going out. So that's what these arrows are. They're representing our new input character", "tokens": [5598, 516, 484, 13, 407, 300, 311, 437, 613, 19669, 366, 13, 814, 434, 13460, 527, 777, 4846, 2517], "temperature": 0.0, "avg_logprob": -0.13386194893483366, "compression_ratio": 1.6854460093896713, "no_speech_prob": 7.411264505208237e-06}, {"id": 971, "seek": 642192, "start": 6433.12, "end": 6438.8, "text": " and our prediction. But what's going on in the middle is more complex. We still have", "tokens": [293, 527, 17630, 13, 583, 437, 311, 516, 322, 294, 264, 2808, 307, 544, 3997, 13, 492, 920, 362], "temperature": 0.0, "avg_logprob": -0.13386194893483366, "compression_ratio": 1.6854460093896713, "no_speech_prob": 7.411264505208237e-06}, {"id": 972, "seek": 642192, "start": 6438.8, "end": 6448.56, "text": " our hidden state, just like before. But whereas in a normal RNN, the hidden state each time", "tokens": [527, 7633, 1785, 11, 445, 411, 949, 13, 583, 9735, 294, 257, 2710, 45702, 45, 11, 264, 7633, 1785, 1184, 565], "temperature": 0.0, "avg_logprob": -0.13386194893483366, "compression_ratio": 1.6854460093896713, "no_speech_prob": 7.411264505208237e-06}, {"id": 973, "seek": 644856, "start": 6448.56, "end": 6455.92, "text": " simply updates itself. It just goes through a weight matrix and an activation function", "tokens": [2935, 9205, 2564, 13, 467, 445, 1709, 807, 257, 3364, 8141, 293, 364, 24433, 2445], "temperature": 0.0, "avg_logprob": -0.1550221868080668, "compression_ratio": 1.694915254237288, "no_speech_prob": 1.0783282050397247e-05}, {"id": 974, "seek": 644856, "start": 6455.92, "end": 6459.6, "text": " and updates itself.", "tokens": [293, 9205, 2564, 13], "temperature": 0.0, "avg_logprob": -0.1550221868080668, "compression_ratio": 1.694915254237288, "no_speech_prob": 1.0783282050397247e-05}, {"id": 975, "seek": 644856, "start": 6459.6, "end": 6463.76, "text": " But in this case, you can see that the loop looks like it's going back to come back to", "tokens": [583, 294, 341, 1389, 11, 291, 393, 536, 300, 264, 6367, 1542, 411, 309, 311, 516, 646, 281, 808, 646, 281], "temperature": 0.0, "avg_logprob": -0.1550221868080668, "compression_ratio": 1.694915254237288, "no_speech_prob": 1.0783282050397247e-05}, {"id": 976, "seek": 644856, "start": 6463.76, "end": 6472.56, "text": " itself, but then there's this gate here. And so it's actually not just a self loop, there's", "tokens": [2564, 11, 457, 550, 456, 311, 341, 8539, 510, 13, 400, 370, 309, 311, 767, 406, 445, 257, 2698, 6367, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.1550221868080668, "compression_ratio": 1.694915254237288, "no_speech_prob": 1.0783282050397247e-05}, {"id": 977, "seek": 644856, "start": 6472.56, "end": 6474.120000000001, "text": " something more complicated.", "tokens": [746, 544, 6179, 13], "temperature": 0.0, "avg_logprob": -0.1550221868080668, "compression_ratio": 1.694915254237288, "no_speech_prob": 1.0783282050397247e-05}, {"id": 978, "seek": 644856, "start": 6474.120000000001, "end": 6476.84, "text": " So in order to understand what's going on, we're going to have to follow across to the", "tokens": [407, 294, 1668, 281, 1223, 437, 311, 516, 322, 11, 321, 434, 516, 281, 362, 281, 1524, 2108, 281, 264], "temperature": 0.0, "avg_logprob": -0.1550221868080668, "compression_ratio": 1.694915254237288, "no_speech_prob": 1.0783282050397247e-05}, {"id": 979, "seek": 647684, "start": 6476.84, "end": 6482.64, "text": " right hand side. So on the right hand side, you can see that the hidden state is going", "tokens": [558, 1011, 1252, 13, 407, 322, 264, 558, 1011, 1252, 11, 291, 393, 536, 300, 264, 7633, 1785, 307, 516], "temperature": 0.0, "avg_logprob": -0.12845030697909268, "compression_ratio": 1.5815217391304348, "no_speech_prob": 4.860433364228811e-06}, {"id": 980, "seek": 647684, "start": 6482.64, "end": 6489.400000000001, "text": " to go through another gate.", "tokens": [281, 352, 807, 1071, 8539, 13], "temperature": 0.0, "avg_logprob": -0.12845030697909268, "compression_ratio": 1.5815217391304348, "no_speech_prob": 4.860433364228811e-06}, {"id": 981, "seek": 647684, "start": 6489.400000000001, "end": 6496.2, "text": " So what's a gate? A gate is simply a little mini neural network which is going to output", "tokens": [407, 437, 311, 257, 8539, 30, 316, 8539, 307, 2935, 257, 707, 8382, 18161, 3209, 597, 307, 516, 281, 5598], "temperature": 0.0, "avg_logprob": -0.12845030697909268, "compression_ratio": 1.5815217391304348, "no_speech_prob": 4.860433364228811e-06}, {"id": 982, "seek": 647684, "start": 6496.2, "end": 6503.12, "text": " a bunch of numbers between 0 and 1, which we're going to multiply by its input. In this", "tokens": [257, 3840, 295, 3547, 1296, 1958, 293, 502, 11, 597, 321, 434, 516, 281, 12972, 538, 1080, 4846, 13, 682, 341], "temperature": 0.0, "avg_logprob": -0.12845030697909268, "compression_ratio": 1.5815217391304348, "no_speech_prob": 4.860433364228811e-06}, {"id": 983, "seek": 650312, "start": 6503.12, "end": 6510.04, "text": " particular one, the R stands for reset. And so the numbers between 0 and 1, if they were", "tokens": [1729, 472, 11, 264, 497, 7382, 337, 14322, 13, 400, 370, 264, 3547, 1296, 1958, 293, 502, 11, 498, 436, 645], "temperature": 0.0, "avg_logprob": -0.14345884814704815, "compression_ratio": 1.704225352112676, "no_speech_prob": 9.666062396718189e-06}, {"id": 984, "seek": 650312, "start": 6510.04, "end": 6516.5599999999995, "text": " all 0, then the thing coming out of the reset gate would be just a big bunch of 0s. In other", "tokens": [439, 1958, 11, 550, 264, 551, 1348, 484, 295, 264, 14322, 8539, 576, 312, 445, 257, 955, 3840, 295, 1958, 82, 13, 682, 661], "temperature": 0.0, "avg_logprob": -0.14345884814704815, "compression_ratio": 1.704225352112676, "no_speech_prob": 9.666062396718189e-06}, {"id": 985, "seek": 650312, "start": 6516.5599999999995, "end": 6523.44, "text": " words, it would allow this network to forget the hidden state. Or it could be a big bunch", "tokens": [2283, 11, 309, 576, 2089, 341, 3209, 281, 2870, 264, 7633, 1785, 13, 1610, 309, 727, 312, 257, 955, 3840], "temperature": 0.0, "avg_logprob": -0.14345884814704815, "compression_ratio": 1.704225352112676, "no_speech_prob": 9.666062396718189e-06}, {"id": 986, "seek": 650312, "start": 6523.44, "end": 6531.76, "text": " of 1s, which would allow the network to remember all of the hidden states. Do we want it to", "tokens": [295, 502, 82, 11, 597, 576, 2089, 264, 3209, 281, 1604, 439, 295, 264, 7633, 4368, 13, 1144, 321, 528, 309, 281], "temperature": 0.0, "avg_logprob": -0.14345884814704815, "compression_ratio": 1.704225352112676, "no_speech_prob": 9.666062396718189e-06}, {"id": 987, "seek": 653176, "start": 6531.76, "end": 6538.04, "text": " remember or forget? We don't know, which is why we implement this gate using a little", "tokens": [1604, 420, 2870, 30, 492, 500, 380, 458, 11, 597, 307, 983, 321, 4445, 341, 8539, 1228, 257, 707], "temperature": 0.0, "avg_logprob": -0.14439710974693298, "compression_ratio": 1.740566037735849, "no_speech_prob": 1.6536872635697364e-06}, {"id": 988, "seek": 653176, "start": 6538.04, "end": 6539.04, "text": " neural network.", "tokens": [18161, 3209, 13], "temperature": 0.0, "avg_logprob": -0.14439710974693298, "compression_ratio": 1.740566037735849, "no_speech_prob": 1.6536872635697364e-06}, {"id": 989, "seek": 653176, "start": 6539.04, "end": 6546.96, "text": " This little neural network is going to have 2 inputs, which is the input to the input", "tokens": [639, 707, 18161, 3209, 307, 516, 281, 362, 568, 15743, 11, 597, 307, 264, 4846, 281, 264, 4846], "temperature": 0.0, "avg_logprob": -0.14439710974693298, "compression_ratio": 1.740566037735849, "no_speech_prob": 1.6536872635697364e-06}, {"id": 990, "seek": 653176, "start": 6546.96, "end": 6554.24, "text": " to the GRU unit and the current hidden state. And so it's going to learn a set of weights", "tokens": [281, 264, 10903, 52, 4985, 293, 264, 2190, 7633, 1785, 13, 400, 370, 309, 311, 516, 281, 1466, 257, 992, 295, 17443], "temperature": 0.0, "avg_logprob": -0.14439710974693298, "compression_ratio": 1.740566037735849, "no_speech_prob": 1.6536872635697364e-06}, {"id": 991, "seek": 653176, "start": 6554.24, "end": 6560.54, "text": " that it's going to use to decide when to forget. So it's now got the ability to forget what", "tokens": [300, 309, 311, 516, 281, 764, 281, 4536, 562, 281, 2870, 13, 407, 309, 311, 586, 658, 264, 3485, 281, 2870, 437], "temperature": 0.0, "avg_logprob": -0.14439710974693298, "compression_ratio": 1.740566037735849, "no_speech_prob": 1.6536872635697364e-06}, {"id": 992, "seek": 656054, "start": 6560.54, "end": 6565.24, "text": " it knows. And that's what the reset gate does.", "tokens": [309, 3255, 13, 400, 300, 311, 437, 264, 14322, 8539, 775, 13], "temperature": 0.0, "avg_logprob": -0.18252849578857422, "compression_ratio": 1.5625, "no_speech_prob": 1.6536874909434118e-06}, {"id": 993, "seek": 656054, "start": 6565.24, "end": 6570.4, "text": " So assuming that the reset gate has at least some non-zero entries, which it surely will", "tokens": [407, 11926, 300, 264, 14322, 8539, 575, 412, 1935, 512, 2107, 12, 32226, 23041, 11, 597, 309, 11468, 486], "temperature": 0.0, "avg_logprob": -0.18252849578857422, "compression_ratio": 1.5625, "no_speech_prob": 1.6536874909434118e-06}, {"id": 994, "seek": 656054, "start": 6570.4, "end": 6581.72, "text": " most of the time, then whatever comes through, we're going to call H tilde. So this is the", "tokens": [881, 295, 264, 565, 11, 550, 2035, 1487, 807, 11, 321, 434, 516, 281, 818, 389, 45046, 13, 407, 341, 307, 264], "temperature": 0.0, "avg_logprob": -0.18252849578857422, "compression_ratio": 1.5625, "no_speech_prob": 1.6536874909434118e-06}, {"id": 995, "seek": 656054, "start": 6581.72, "end": 6587.28, "text": " new value of the hidden state after being reset.", "tokens": [777, 2158, 295, 264, 7633, 1785, 934, 885, 14322, 13], "temperature": 0.0, "avg_logprob": -0.18252849578857422, "compression_ratio": 1.5625, "no_speech_prob": 1.6536874909434118e-06}, {"id": 996, "seek": 658728, "start": 6587.28, "end": 6593.24, "text": " And so then finally, that goes up to this top bit here. The original hidden state goes", "tokens": [400, 370, 550, 2721, 11, 300, 1709, 493, 281, 341, 1192, 857, 510, 13, 440, 3380, 7633, 1785, 1709], "temperature": 0.0, "avg_logprob": -0.1303000381027443, "compression_ratio": 1.6163522012578617, "no_speech_prob": 3.2887419365579262e-06}, {"id": 997, "seek": 658728, "start": 6593.24, "end": 6599.84, "text": " up to this top bit here. And then there's a gate which decides how much of each one", "tokens": [493, 281, 341, 1192, 857, 510, 13, 400, 550, 456, 311, 257, 8539, 597, 14898, 577, 709, 295, 1184, 472], "temperature": 0.0, "avg_logprob": -0.1303000381027443, "compression_ratio": 1.6163522012578617, "no_speech_prob": 3.2887419365579262e-06}, {"id": 998, "seek": 658728, "start": 6599.84, "end": 6612.639999999999, "text": " should we have. So this update gate is going to decide if it's 1, we'll take more from", "tokens": [820, 321, 362, 13, 407, 341, 5623, 8539, 307, 516, 281, 4536, 498, 309, 311, 502, 11, 321, 603, 747, 544, 490], "temperature": 0.0, "avg_logprob": -0.1303000381027443, "compression_ratio": 1.6163522012578617, "no_speech_prob": 3.2887419365579262e-06}, {"id": 999, "seek": 661264, "start": 6612.64, "end": 6617.6, "text": " this side, if it's 0, we'll take more from this side. And again, that's implemented as", "tokens": [341, 1252, 11, 498, 309, 311, 1958, 11, 321, 603, 747, 544, 490, 341, 1252, 13, 400, 797, 11, 300, 311, 12270, 382], "temperature": 0.0, "avg_logprob": -0.14921306680749963, "compression_ratio": 1.563265306122449, "no_speech_prob": 4.157354851486161e-06}, {"id": 1000, "seek": 661264, "start": 6617.6, "end": 6620.96, "text": " a little neural network.", "tokens": [257, 707, 18161, 3209, 13], "temperature": 0.0, "avg_logprob": -0.14921306680749963, "compression_ratio": 1.563265306122449, "no_speech_prob": 4.157354851486161e-06}, {"id": 1001, "seek": 661264, "start": 6620.96, "end": 6624.8, "text": " I think the easiest way to understand this is probably to look at the code. So I have", "tokens": [286, 519, 264, 12889, 636, 281, 1223, 341, 307, 1391, 281, 574, 412, 264, 3089, 13, 407, 286, 362], "temperature": 0.0, "avg_logprob": -0.14921306680749963, "compression_ratio": 1.563265306122449, "no_speech_prob": 4.157354851486161e-06}, {"id": 1002, "seek": 661264, "start": 6624.8, "end": 6631.320000000001, "text": " implemented this in Theano. You can use a GRU in Keras by simply replacing the words", "tokens": [12270, 341, 294, 440, 3730, 13, 509, 393, 764, 257, 10903, 52, 294, 591, 6985, 538, 2935, 19139, 264, 2283], "temperature": 0.0, "avg_logprob": -0.14921306680749963, "compression_ratio": 1.563265306122449, "no_speech_prob": 4.157354851486161e-06}, {"id": 1003, "seek": 661264, "start": 6631.320000000001, "end": 6637.8, "text": " simpleRNN with GRU. So you don't really need to know this to use it and you get pretty", "tokens": [2199, 49, 45, 45, 365, 10903, 52, 13, 407, 291, 500, 380, 534, 643, 281, 458, 341, 281, 764, 309, 293, 291, 483, 1238], "temperature": 0.0, "avg_logprob": -0.14921306680749963, "compression_ratio": 1.563265306122449, "no_speech_prob": 4.157354851486161e-06}, {"id": 1004, "seek": 661264, "start": 6637.8, "end": 6642.0, "text": " good results.", "tokens": [665, 3542, 13], "temperature": 0.0, "avg_logprob": -0.14921306680749963, "compression_ratio": 1.563265306122449, "no_speech_prob": 4.157354851486161e-06}, {"id": 1005, "seek": 664200, "start": 6642.0, "end": 6650.0, "text": " But here's what it looks like when implemented. We don't just have a hidden weight matrix,", "tokens": [583, 510, 311, 437, 309, 1542, 411, 562, 12270, 13, 492, 500, 380, 445, 362, 257, 7633, 3364, 8141, 11], "temperature": 0.0, "avg_logprob": -0.1734848644422448, "compression_ratio": 1.8333333333333333, "no_speech_prob": 8.801009244052693e-06}, {"id": 1006, "seek": 664200, "start": 6650.0, "end": 6655.64, "text": " input weight matrix and an output weight matrix anymore. We also have a hidden and input weight", "tokens": [4846, 3364, 8141, 293, 364, 5598, 3364, 8141, 3602, 13, 492, 611, 362, 257, 7633, 293, 4846, 3364], "temperature": 0.0, "avg_logprob": -0.1734848644422448, "compression_ratio": 1.8333333333333333, "no_speech_prob": 8.801009244052693e-06}, {"id": 1007, "seek": 664200, "start": 6655.64, "end": 6664.44, "text": " matrix for our reset gate, mini-neural net, and for our update gate, mini-neural net.", "tokens": [8141, 337, 527, 14322, 8539, 11, 8382, 12, 716, 1807, 2533, 11, 293, 337, 527, 5623, 8539, 11, 8382, 12, 716, 1807, 2533, 13], "temperature": 0.0, "avg_logprob": -0.1734848644422448, "compression_ratio": 1.8333333333333333, "no_speech_prob": 8.801009244052693e-06}, {"id": 1008, "seek": 664200, "start": 6664.44, "end": 6670.52, "text": " So here's the definition of a gate. A gate is something which takes its inputs, its hidden", "tokens": [407, 510, 311, 264, 7123, 295, 257, 8539, 13, 316, 8539, 307, 746, 597, 2516, 1080, 15743, 11, 1080, 7633], "temperature": 0.0, "avg_logprob": -0.1734848644422448, "compression_ratio": 1.8333333333333333, "no_speech_prob": 8.801009244052693e-06}, {"id": 1009, "seek": 667052, "start": 6670.52, "end": 6678.0, "text": " state, its hidden state weights, its input weights and its biases. It does a dot product", "tokens": [1785, 11, 1080, 7633, 1785, 17443, 11, 1080, 4846, 17443, 293, 1080, 32152, 13, 467, 775, 257, 5893, 1674], "temperature": 0.0, "avg_logprob": -0.21345035552978517, "compression_ratio": 1.7241379310344827, "no_speech_prob": 8.939627150539309e-06}, {"id": 1010, "seek": 667052, "start": 6678.0, "end": 6683.400000000001, "text": " of the x with wx, a dot product of h with wh, and adds the biases and sticks it to a", "tokens": [295, 264, 2031, 365, 261, 87, 11, 257, 5893, 1674, 295, 276, 365, 315, 11, 293, 10860, 264, 32152, 293, 12518, 309, 281, 257], "temperature": 0.0, "avg_logprob": -0.21345035552978517, "compression_ratio": 1.7241379310344827, "no_speech_prob": 8.939627150539309e-06}, {"id": 1011, "seek": 667052, "start": 6683.400000000001, "end": 6684.400000000001, "text": " single function.", "tokens": [2167, 2445, 13], "temperature": 0.0, "avg_logprob": -0.21345035552978517, "compression_ratio": 1.7241379310344827, "no_speech_prob": 8.939627150539309e-06}, {"id": 1012, "seek": 667052, "start": 6684.400000000001, "end": 6689.4800000000005, "text": " So that's what I meant by a mini-neural net. It's hardly a neural net, it's just got one", "tokens": [407, 300, 311, 437, 286, 4140, 538, 257, 8382, 12, 716, 1807, 2533, 13, 467, 311, 13572, 257, 18161, 2533, 11, 309, 311, 445, 658, 472], "temperature": 0.0, "avg_logprob": -0.21345035552978517, "compression_ratio": 1.7241379310344827, "no_speech_prob": 8.939627150539309e-06}, {"id": 1013, "seek": 667052, "start": 6689.4800000000005, "end": 6698.040000000001, "text": " layer. So that's the definition of the reset gate and the update gate.", "tokens": [4583, 13, 407, 300, 311, 264, 7123, 295, 264, 14322, 8539, 293, 264, 5623, 8539, 13], "temperature": 0.0, "avg_logprob": -0.21345035552978517, "compression_ratio": 1.7241379310344827, "no_speech_prob": 8.939627150539309e-06}, {"id": 1014, "seek": 669804, "start": 6698.04, "end": 6705.16, "text": " So then in our step function, this is the thing that runs each time on the scan, it", "tokens": [407, 550, 294, 527, 1823, 2445, 11, 341, 307, 264, 551, 300, 6676, 1184, 565, 322, 264, 11049, 11, 309], "temperature": 0.0, "avg_logprob": -0.12373114795219607, "compression_ratio": 1.9086021505376345, "no_speech_prob": 4.860429726250004e-06}, {"id": 1015, "seek": 669804, "start": 6705.16, "end": 6711.4, "text": " looks exactly the same as what we looked at last week. The output equals the hidden state", "tokens": [1542, 2293, 264, 912, 382, 437, 321, 2956, 412, 1036, 1243, 13, 440, 5598, 6915, 264, 7633, 1785], "temperature": 0.0, "avg_logprob": -0.12373114795219607, "compression_ratio": 1.9086021505376345, "no_speech_prob": 4.860429726250004e-06}, {"id": 1016, "seek": 669804, "start": 6711.4, "end": 6720.76, "text": " times the hidden weight matrix plus the hidden biases. The new hidden state equals our inputs", "tokens": [1413, 264, 7633, 3364, 8141, 1804, 264, 7633, 32152, 13, 440, 777, 7633, 1785, 6915, 527, 15743], "temperature": 0.0, "avg_logprob": -0.12373114795219607, "compression_ratio": 1.9086021505376345, "no_speech_prob": 4.860429726250004e-06}, {"id": 1017, "seek": 669804, "start": 6720.76, "end": 6727.38, "text": " times its weights and the hidden state times its weights plus the biases. But this time", "tokens": [1413, 1080, 17443, 293, 264, 7633, 1785, 1413, 1080, 17443, 1804, 264, 32152, 13, 583, 341, 565], "temperature": 0.0, "avg_logprob": -0.12373114795219607, "compression_ratio": 1.9086021505376345, "no_speech_prob": 4.860429726250004e-06}, {"id": 1018, "seek": 672738, "start": 6727.38, "end": 6735.38, "text": " the hidden weights are multiplied by the reset gate. And the reset gate is just our little", "tokens": [264, 7633, 17443, 366, 17207, 538, 264, 14322, 8539, 13, 400, 264, 14322, 8539, 307, 445, 527, 707], "temperature": 0.0, "avg_logprob": -0.15239368166242326, "compression_ratio": 1.7317073170731707, "no_speech_prob": 1.349700937680609e-06}, {"id": 1019, "seek": 672738, "start": 6735.38, "end": 6737.36, "text": " neural net.", "tokens": [18161, 2533, 13], "temperature": 0.0, "avg_logprob": -0.15239368166242326, "compression_ratio": 1.7317073170731707, "no_speech_prob": 1.349700937680609e-06}, {"id": 1020, "seek": 672738, "start": 6737.36, "end": 6748.04, "text": " So now that we have hnew, our actual new hidden state is equal to that times 1 minus the update", "tokens": [407, 586, 300, 321, 362, 276, 7686, 11, 527, 3539, 777, 7633, 1785, 307, 2681, 281, 300, 1413, 502, 3175, 264, 5623], "temperature": 0.0, "avg_logprob": -0.15239368166242326, "compression_ratio": 1.7317073170731707, "no_speech_prob": 1.349700937680609e-06}, {"id": 1021, "seek": 672738, "start": 6748.04, "end": 6753.64, "text": " gate plus our previous hidden state times the update gate. So you can see that update", "tokens": [8539, 1804, 527, 3894, 7633, 1785, 1413, 264, 5623, 8539, 13, 407, 291, 393, 536, 300, 5623], "temperature": 0.0, "avg_logprob": -0.15239368166242326, "compression_ratio": 1.7317073170731707, "no_speech_prob": 1.349700937680609e-06}, {"id": 1022, "seek": 675364, "start": 6753.64, "end": 6762.64, "text": " plus 1 minus update will add to 1. So you can see why it's been drawn like so, which", "tokens": [1804, 502, 3175, 5623, 486, 909, 281, 502, 13, 407, 291, 393, 536, 983, 309, 311, 668, 10117, 411, 370, 11, 597], "temperature": 0.0, "avg_logprob": -0.15468071401119232, "compression_ratio": 1.5153374233128833, "no_speech_prob": 4.710892426373903e-06}, {"id": 1023, "seek": 675364, "start": 6762.64, "end": 6769.08, "text": " is that this can really be anywhere at either end or somewhere in between.", "tokens": [307, 300, 341, 393, 534, 312, 4992, 412, 2139, 917, 420, 4079, 294, 1296, 13], "temperature": 0.0, "avg_logprob": -0.15468071401119232, "compression_ratio": 1.5153374233128833, "no_speech_prob": 4.710892426373903e-06}, {"id": 1024, "seek": 675364, "start": 6769.08, "end": 6779.6, "text": " So the update gate decides how much is hnew going to replace the new hidden state with.", "tokens": [407, 264, 5623, 8539, 14898, 577, 709, 307, 276, 7686, 516, 281, 7406, 264, 777, 7633, 1785, 365, 13], "temperature": 0.0, "avg_logprob": -0.15468071401119232, "compression_ratio": 1.5153374233128833, "no_speech_prob": 4.710892426373903e-06}, {"id": 1025, "seek": 677960, "start": 6779.6, "end": 6785.64, "text": " So actually although people tend to talk about LSTNs and GRUs as being pretty complex, it", "tokens": [407, 767, 4878, 561, 3928, 281, 751, 466, 441, 6840, 45, 82, 293, 10903, 29211, 382, 885, 1238, 3997, 11, 309], "temperature": 0.0, "avg_logprob": -0.17297829808415593, "compression_ratio": 1.505050505050505, "no_speech_prob": 5.093678282719338e-06}, {"id": 1026, "seek": 677960, "start": 6785.64, "end": 6791.08, "text": " really wasn't that hard to write.", "tokens": [534, 2067, 380, 300, 1152, 281, 2464, 13], "temperature": 0.0, "avg_logprob": -0.17297829808415593, "compression_ratio": 1.505050505050505, "no_speech_prob": 5.093678282719338e-06}, {"id": 1027, "seek": 677960, "start": 6791.08, "end": 6797.120000000001, "text": " The key outcome of this though is that because we now have these reset and update gates,", "tokens": [440, 2141, 9700, 295, 341, 1673, 307, 300, 570, 321, 586, 362, 613, 14322, 293, 5623, 19792, 11], "temperature": 0.0, "avg_logprob": -0.17297829808415593, "compression_ratio": 1.505050505050505, "no_speech_prob": 5.093678282719338e-06}, {"id": 1028, "seek": 677960, "start": 6797.120000000001, "end": 6803.88, "text": " it has the ability to learn these special sets of weights to make sure that it throws", "tokens": [309, 575, 264, 3485, 281, 1466, 613, 2121, 6352, 295, 17443, 281, 652, 988, 300, 309, 19251], "temperature": 0.0, "avg_logprob": -0.17297829808415593, "compression_ratio": 1.505050505050505, "no_speech_prob": 5.093678282719338e-06}, {"id": 1029, "seek": 680388, "start": 6803.88, "end": 6810.12, "text": " away state when that's a good idea, or to ignore state when that's a good idea. So these", "tokens": [1314, 1785, 562, 300, 311, 257, 665, 1558, 11, 420, 281, 11200, 1785, 562, 300, 311, 257, 665, 1558, 13, 407, 613], "temperature": 0.0, "avg_logprob": -0.1410266623205068, "compression_ratio": 1.6794871794871795, "no_speech_prob": 1.7330476111965254e-06}, {"id": 1030, "seek": 680388, "start": 6810.12, "end": 6818.12, "text": " extra degrees of freedom allow SGD to find better answers. So again, this is one of these", "tokens": [2857, 5310, 295, 5645, 2089, 34520, 35, 281, 915, 1101, 6338, 13, 407, 797, 11, 341, 307, 472, 295, 613], "temperature": 0.0, "avg_logprob": -0.1410266623205068, "compression_ratio": 1.6794871794871795, "no_speech_prob": 1.7330476111965254e-06}, {"id": 1031, "seek": 680388, "start": 6818.12, "end": 6826.64, "text": " things where we're coming up with architectures which just try to make it easier for the optimizer", "tokens": [721, 689, 321, 434, 1348, 493, 365, 6331, 1303, 597, 445, 853, 281, 652, 309, 3571, 337, 264, 5028, 6545], "temperature": 0.0, "avg_logprob": -0.1410266623205068, "compression_ratio": 1.6794871794871795, "no_speech_prob": 1.7330476111965254e-06}, {"id": 1032, "seek": 680388, "start": 6826.64, "end": 6828.8, "text": " to come up with good answers.", "tokens": [281, 808, 493, 365, 665, 6338, 13], "temperature": 0.0, "avg_logprob": -0.1410266623205068, "compression_ratio": 1.6794871794871795, "no_speech_prob": 1.7330476111965254e-06}, {"id": 1033, "seek": 680388, "start": 6828.8, "end": 6831.64, "text": " Everything after this is identical to what we looked at last week. That goes into the", "tokens": [5471, 934, 341, 307, 14800, 281, 437, 321, 2956, 412, 1036, 1243, 13, 663, 1709, 666, 264], "temperature": 0.0, "avg_logprob": -0.1410266623205068, "compression_ratio": 1.6794871794871795, "no_speech_prob": 1.7330476111965254e-06}, {"id": 1034, "seek": 683164, "start": 6831.64, "end": 6838.12, "text": " scan function, we calculate the loss, we calculate the gradients, we do the SGD updates, and", "tokens": [11049, 2445, 11, 321, 8873, 264, 4470, 11, 321, 8873, 264, 2771, 2448, 11, 321, 360, 264, 34520, 35, 9205, 11, 293], "temperature": 0.0, "avg_logprob": -0.20332040457889952, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.8342723706155084e-05}, {"id": 1035, "seek": 683164, "start": 6838.12, "end": 6843.92, "text": " we chuck it into a little loop.", "tokens": [321, 20870, 309, 666, 257, 707, 6367, 13], "temperature": 0.0, "avg_logprob": -0.20332040457889952, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.8342723706155084e-05}, {"id": 1036, "seek": 683164, "start": 6843.92, "end": 6854.240000000001, "text": " So I think really the main reason I wanted to do all that today was to show you the back", "tokens": [407, 286, 519, 534, 264, 2135, 1778, 286, 1415, 281, 360, 439, 300, 965, 390, 281, 855, 291, 264, 646], "temperature": 0.0, "avg_logprob": -0.20332040457889952, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.8342723706155084e-05}, {"id": 1037, "seek": 685424, "start": 6854.24, "end": 6862.04, "text": " prop example. I know some learning styles are more detail-oriented as well, so I think", "tokens": [2365, 1365, 13, 286, 458, 512, 2539, 13273, 366, 544, 2607, 12, 27414, 382, 731, 11, 370, 286, 519], "temperature": 0.0, "avg_logprob": -0.1679554218199195, "compression_ratio": 1.5432692307692308, "no_speech_prob": 1.184302345791366e-05}, {"id": 1038, "seek": 685424, "start": 6862.04, "end": 6866.5199999999995, "text": " some of you hopefully will have found that helpful.", "tokens": [512, 295, 291, 4696, 486, 362, 1352, 300, 4961, 13], "temperature": 0.0, "avg_logprob": -0.1679554218199195, "compression_ratio": 1.5432692307692308, "no_speech_prob": 1.184302345791366e-05}, {"id": 1039, "seek": 685424, "start": 6866.5199999999995, "end": 6872.639999999999, "text": " Any time you find yourself wondering how the hell did this neural network do this, you", "tokens": [2639, 565, 291, 915, 1803, 6359, 577, 264, 4921, 630, 341, 18161, 3209, 360, 341, 11, 291], "temperature": 0.0, "avg_logprob": -0.1679554218199195, "compression_ratio": 1.5432692307692308, "no_speech_prob": 1.184302345791366e-05}, {"id": 1040, "seek": 685424, "start": 6872.639999999999, "end": 6881.24, "text": " can come back to this piece of code and that's all it did. That's one way of thinking about", "tokens": [393, 808, 646, 281, 341, 2522, 295, 3089, 293, 300, 311, 439, 309, 630, 13, 663, 311, 472, 636, 295, 1953, 466], "temperature": 0.0, "avg_logprob": -0.1679554218199195, "compression_ratio": 1.5432692307692308, "no_speech_prob": 1.184302345791366e-05}, {"id": 1041, "seek": 685424, "start": 6881.24, "end": 6882.24, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.1679554218199195, "compression_ratio": 1.5432692307692308, "no_speech_prob": 1.184302345791366e-05}, {"id": 1042, "seek": 688224, "start": 6882.24, "end": 6886.5599999999995, "text": " Where you really get successful with neural nets though is when you go to a whole other", "tokens": [2305, 291, 534, 483, 4406, 365, 18161, 36170, 1673, 307, 562, 291, 352, 281, 257, 1379, 661], "temperature": 0.0, "avg_logprob": -0.1392636449713456, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.9442162233171985e-05}, {"id": 1043, "seek": 688224, "start": 6886.5599999999995, "end": 6893.16, "text": " level and you don't think of it at that level anymore, but instead you start thinking, if", "tokens": [1496, 293, 291, 500, 380, 519, 295, 309, 412, 300, 1496, 3602, 11, 457, 2602, 291, 722, 1953, 11, 498], "temperature": 0.0, "avg_logprob": -0.1392636449713456, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.9442162233171985e-05}, {"id": 1044, "seek": 688224, "start": 6893.16, "end": 6898.599999999999, "text": " I'm an optimizer and I'm given an architecture like this, what would I have to do in order", "tokens": [286, 478, 364, 5028, 6545, 293, 286, 478, 2212, 364, 9482, 411, 341, 11, 437, 576, 286, 362, 281, 360, 294, 1668], "temperature": 0.0, "avg_logprob": -0.1392636449713456, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.9442162233171985e-05}, {"id": 1045, "seek": 688224, "start": 6898.599999999999, "end": 6901.24, "text": " to optimize it?", "tokens": [281, 19719, 309, 30], "temperature": 0.0, "avg_logprob": -0.1392636449713456, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.9442162233171985e-05}, {"id": 1046, "seek": 688224, "start": 6901.24, "end": 6907.76, "text": " And once you start thinking like that, then you can start thinking in this kind of upside-down", "tokens": [400, 1564, 291, 722, 1953, 411, 300, 11, 550, 291, 393, 722, 1953, 294, 341, 733, 295, 14119, 12, 5093], "temperature": 0.0, "avg_logprob": -0.1392636449713456, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.9442162233171985e-05}, {"id": 1047, "seek": 690776, "start": 6907.76, "end": 6914.0, "text": " way that is necessary to come up with good architectures. You can start to understand", "tokens": [636, 300, 307, 4818, 281, 808, 493, 365, 665, 6331, 1303, 13, 509, 393, 722, 281, 1223], "temperature": 0.0, "avg_logprob": -0.20004183451334637, "compression_ratio": 1.5889830508474576, "no_speech_prob": 6.144136932562105e-06}, {"id": 1048, "seek": 690776, "start": 6914.0, "end": 6920.76, "text": " why it is that this convolution layer followed by this average pooling layer gives the answers", "tokens": [983, 309, 307, 300, 341, 45216, 4583, 6263, 538, 341, 4274, 7005, 278, 4583, 2709, 264, 6338], "temperature": 0.0, "avg_logprob": -0.20004183451334637, "compression_ratio": 1.5889830508474576, "no_speech_prob": 6.144136932562105e-06}, {"id": 1049, "seek": 690776, "start": 6920.76, "end": 6925.56, "text": " that it does. Why does it work? You get that real intuition for what's going to work for", "tokens": [300, 309, 775, 13, 1545, 775, 309, 589, 30, 509, 483, 300, 957, 24002, 337, 437, 311, 516, 281, 589, 337], "temperature": 0.0, "avg_logprob": -0.20004183451334637, "compression_ratio": 1.5889830508474576, "no_speech_prob": 6.144136932562105e-06}, {"id": 1050, "seek": 690776, "start": 6925.56, "end": 6926.76, "text": " your problem well.", "tokens": [428, 1154, 731, 13], "temperature": 0.0, "avg_logprob": -0.20004183451334637, "compression_ratio": 1.5889830508474576, "no_speech_prob": 6.144136932562105e-06}, {"id": 1051, "seek": 690776, "start": 6926.76, "end": 6936.6, "text": " So there's kind of two levels at which you need to think about neural nets. The sooner", "tokens": [407, 456, 311, 733, 295, 732, 4358, 412, 597, 291, 643, 281, 519, 466, 18161, 36170, 13, 440, 15324], "temperature": 0.0, "avg_logprob": -0.20004183451334637, "compression_ratio": 1.5889830508474576, "no_speech_prob": 6.144136932562105e-06}, {"id": 1052, "seek": 693660, "start": 6936.6, "end": 6941.360000000001, "text": " you can think of it at this super high level, the sooner you'll do well with them. And one", "tokens": [291, 393, 519, 295, 309, 412, 341, 1687, 1090, 1496, 11, 264, 15324, 291, 603, 360, 731, 365, 552, 13, 400, 472], "temperature": 0.0, "avg_logprob": -0.11946206682183769, "compression_ratio": 1.6289592760180995, "no_speech_prob": 4.63785136162187e-06}, {"id": 1053, "seek": 693660, "start": 6941.360000000001, "end": 6949.200000000001, "text": " of the best ways to do that is to over the next couple of weeks run this fish notebook", "tokens": [295, 264, 1151, 2098, 281, 360, 300, 307, 281, 670, 264, 958, 1916, 295, 3259, 1190, 341, 3506, 21060], "temperature": 0.0, "avg_logprob": -0.11946206682183769, "compression_ratio": 1.6289592760180995, "no_speech_prob": 4.63785136162187e-06}, {"id": 1054, "seek": 693660, "start": 6949.200000000001, "end": 6955.64, "text": " yourself and screw around with it a lot. And make sure that you know how to do these things", "tokens": [1803, 293, 5630, 926, 365, 309, 257, 688, 13, 400, 652, 988, 300, 291, 458, 577, 281, 360, 613, 721], "temperature": 0.0, "avg_logprob": -0.11946206682183769, "compression_ratio": 1.6289592760180995, "no_speech_prob": 4.63785136162187e-06}, {"id": 1055, "seek": 693660, "start": 6955.64, "end": 6964.240000000001, "text": " that I did where I actually create a little function that allows me to spit out the output", "tokens": [300, 286, 630, 689, 286, 767, 1884, 257, 707, 2445, 300, 4045, 385, 281, 22127, 484, 264, 5598], "temperature": 0.0, "avg_logprob": -0.11946206682183769, "compression_ratio": 1.6289592760180995, "no_speech_prob": 4.63785136162187e-06}, {"id": 1056, "seek": 696424, "start": 6964.24, "end": 6970.04, "text": " of any of the layers and visualize it. Make sure you know how to inspect it and you can", "tokens": [295, 604, 295, 264, 7914, 293, 23273, 309, 13, 4387, 988, 291, 458, 577, 281, 15018, 309, 293, 291, 393], "temperature": 0.0, "avg_logprob": -0.18176605880901378, "compression_ratio": 1.5803571428571428, "no_speech_prob": 3.6688436466647545e-06}, {"id": 1057, "seek": 696424, "start": 6970.04, "end": 6978.44, "text": " really look at the inputs and outputs. I think that's the best way to get an intuition.", "tokens": [534, 574, 412, 264, 15743, 293, 23930, 13, 286, 519, 300, 311, 264, 1151, 636, 281, 483, 364, 24002, 13], "temperature": 0.0, "avg_logprob": -0.18176605880901378, "compression_ratio": 1.5803571428571428, "no_speech_prob": 3.6688436466647545e-06}, {"id": 1058, "seek": 696424, "start": 6978.44, "end": 6983.24, "text": " So this was kind of like, particularly the first half of this class was a bit of a preview", "tokens": [407, 341, 390, 733, 295, 411, 11, 4098, 264, 700, 1922, 295, 341, 1508, 390, 257, 857, 295, 257, 14281], "temperature": 0.0, "avg_logprob": -0.18176605880901378, "compression_ratio": 1.5803571428571428, "no_speech_prob": 3.6688436466647545e-06}, {"id": 1059, "seek": 696424, "start": 6983.24, "end": 6990.639999999999, "text": " of next year, which is to say, in the first 6 weeks, you learn all the pieces. And then", "tokens": [295, 958, 1064, 11, 597, 307, 281, 584, 11, 294, 264, 700, 1386, 3259, 11, 291, 1466, 439, 264, 3755, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.18176605880901378, "compression_ratio": 1.5803571428571428, "no_speech_prob": 3.6688436466647545e-06}, {"id": 1060, "seek": 699064, "start": 6990.64, "end": 6997.08, "text": " today we very rapidly tried putting those pieces together in a thousand different ways", "tokens": [965, 321, 588, 12910, 3031, 3372, 729, 3755, 1214, 294, 257, 4714, 819, 2098], "temperature": 0.0, "avg_logprob": -0.162857001935932, "compression_ratio": 1.577319587628866, "no_speech_prob": 3.2377508887293516e-06}, {"id": 1061, "seek": 699064, "start": 6997.08, "end": 7004.4400000000005, "text": " and saw what happened. And there's a million more ways that we know of, and probably a", "tokens": [293, 1866, 437, 2011, 13, 400, 456, 311, 257, 2459, 544, 2098, 300, 321, 458, 295, 11, 293, 1391, 257], "temperature": 0.0, "avg_logprob": -0.162857001935932, "compression_ratio": 1.577319587628866, "no_speech_prob": 3.2377508887293516e-06}, {"id": 1062, "seek": 699064, "start": 7004.4400000000005, "end": 7006.9800000000005, "text": " billion more ways we don't know of.", "tokens": [5218, 544, 2098, 321, 500, 380, 458, 295, 13], "temperature": 0.0, "avg_logprob": -0.162857001935932, "compression_ratio": 1.577319587628866, "no_speech_prob": 3.2377508887293516e-06}, {"id": 1063, "seek": 699064, "start": 7006.9800000000005, "end": 7016.8, "text": " So knowing this little set of tools, convolutions, fully connected layers, activation functions,", "tokens": [407, 5276, 341, 707, 992, 295, 3873, 11, 3754, 15892, 11, 4498, 4582, 7914, 11, 24433, 6828, 11], "temperature": 0.0, "avg_logprob": -0.162857001935932, "compression_ratio": 1.577319587628866, "no_speech_prob": 3.2377508887293516e-06}, {"id": 1064, "seek": 701680, "start": 7016.8, "end": 7025.16, "text": " etc., you're now able to be an architect, create these architectures. Keras' functional", "tokens": [5183, 7933, 291, 434, 586, 1075, 281, 312, 364, 6331, 11, 1884, 613, 6331, 1303, 13, 591, 6985, 6, 11745], "temperature": 0.0, "avg_logprob": -0.2079909689286176, "compression_ratio": 1.4833333333333334, "no_speech_prob": 1.9222763512516394e-05}, {"id": 1065, "seek": 701680, "start": 7025.16, "end": 7032.24, "text": " API makes it ridiculously easy. I created all of the architectures you see today, this", "tokens": [9362, 1669, 309, 41358, 1858, 13, 286, 2942, 439, 295, 264, 6331, 1303, 291, 536, 965, 11, 341], "temperature": 0.0, "avg_logprob": -0.2079909689286176, "compression_ratio": 1.4833333333333334, "no_speech_prob": 1.9222763512516394e-05}, {"id": 1066, "seek": 701680, "start": 7032.24, "end": 7038.84, "text": " week while I was sick and my baby wasn't sleeping. My brain was not even working, that's how", "tokens": [1243, 1339, 286, 390, 4998, 293, 452, 3186, 2067, 380, 8296, 13, 1222, 3567, 390, 406, 754, 1364, 11, 300, 311, 577], "temperature": 0.0, "avg_logprob": -0.2079909689286176, "compression_ratio": 1.4833333333333334, "no_speech_prob": 1.9222763512516394e-05}, {"id": 1067, "seek": 703884, "start": 7038.84, "end": 7051.08, "text": " easy Keras makes this. It takes a few weeks to build your comfort level up, but hopefully", "tokens": [1858, 591, 6985, 1669, 341, 13, 467, 2516, 257, 1326, 3259, 281, 1322, 428, 3400, 1496, 493, 11, 457, 4696], "temperature": 0.0, "avg_logprob": -0.17566396539861506, "compression_ratio": 1.3673469387755102, "no_speech_prob": 1.012982647807803e-05}, {"id": 1068, "seek": 703884, "start": 7051.08, "end": 7053.400000000001, "text": " you can try that.", "tokens": [291, 393, 853, 300, 13], "temperature": 0.0, "avg_logprob": -0.17566396539861506, "compression_ratio": 1.3673469387755102, "no_speech_prob": 1.012982647807803e-05}, {"id": 1069, "seek": 703884, "start": 7053.400000000001, "end": 7060.4400000000005, "text": " And most importantly, over the next few weeks, as Rachel and I, maybe with some of your help,", "tokens": [400, 881, 8906, 11, 670, 264, 958, 1326, 3259, 11, 382, 14246, 293, 286, 11, 1310, 365, 512, 295, 428, 854, 11], "temperature": 0.0, "avg_logprob": -0.17566396539861506, "compression_ratio": 1.3673469387755102, "no_speech_prob": 1.012982647807803e-05}, {"id": 1070, "seek": 706044, "start": 7060.44, "end": 7068.919999999999, "text": " start to develop the MOOC, you guys can stay up talking on the forums about keep working", "tokens": [722, 281, 1499, 264, 49197, 34, 11, 291, 1074, 393, 1754, 493, 1417, 322, 264, 26998, 466, 1066, 1364], "temperature": 0.0, "avg_logprob": -0.23460782807448816, "compression_ratio": 1.6150442477876106, "no_speech_prob": 4.39998293586541e-05}, {"id": 1071, "seek": 706044, "start": 7068.919999999999, "end": 7072.44, "text": " through whatever problems you're interested in, whether it be the projects that you want", "tokens": [807, 2035, 2740, 291, 434, 3102, 294, 11, 1968, 309, 312, 264, 4455, 300, 291, 528], "temperature": 0.0, "avg_logprob": -0.23460782807448816, "compression_ratio": 1.6150442477876106, "no_speech_prob": 4.39998293586541e-05}, {"id": 1072, "seek": 706044, "start": 7072.44, "end": 7077.719999999999, "text": " to apply these things to in your own organizations or your personal passion projects, or if you", "tokens": [281, 3079, 613, 721, 281, 294, 428, 1065, 6150, 420, 428, 2973, 5418, 4455, 11, 420, 498, 291], "temperature": 0.0, "avg_logprob": -0.23460782807448816, "compression_ratio": 1.6150442477876106, "no_speech_prob": 4.39998293586541e-05}, {"id": 1073, "seek": 706044, "start": 7077.719999999999, "end": 7083.12, "text": " want to try and win a competition or two. Rachel and I are going to still be on the", "tokens": [528, 281, 853, 293, 1942, 257, 6211, 420, 732, 13, 14246, 293, 286, 366, 516, 281, 920, 312, 322, 264], "temperature": 0.0, "avg_logprob": -0.23460782807448816, "compression_ratio": 1.6150442477876106, "no_speech_prob": 4.39998293586541e-05}, {"id": 1074, "seek": 706044, "start": 7083.12, "end": 7085.16, "text": " forums.", "tokens": [26998, 13], "temperature": 0.0, "avg_logprob": -0.23460782807448816, "compression_ratio": 1.6150442477876106, "no_speech_prob": 4.39998293586541e-05}, {"id": 1075, "seek": 708516, "start": 7085.16, "end": 7091.24, "text": " And then in a few weeks' time when the MOOC goes online, hopefully there's going to be", "tokens": [400, 550, 294, 257, 1326, 3259, 6, 565, 562, 264, 49197, 34, 1709, 2950, 11, 4696, 456, 311, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.16815642024693864, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.6964013411779888e-05}, {"id": 1076, "seek": 708516, "start": 7091.24, "end": 7099.12, "text": " thousands of people joining this community. So we'll be like the seed. So I really hope", "tokens": [5383, 295, 561, 5549, 341, 1768, 13, 407, 321, 603, 312, 411, 264, 8871, 13, 407, 286, 534, 1454], "temperature": 0.0, "avg_logprob": -0.16815642024693864, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.6964013411779888e-05}, {"id": 1077, "seek": 708516, "start": 7099.12, "end": 7106.72, "text": " you guys will stay a part of it and kind of help. Can you imagine that first day when", "tokens": [291, 1074, 486, 1754, 257, 644, 295, 309, 293, 733, 295, 854, 13, 1664, 291, 3811, 300, 700, 786, 562], "temperature": 0.0, "avg_logprob": -0.16815642024693864, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.6964013411779888e-05}, {"id": 1078, "seek": 708516, "start": 7106.72, "end": 7112.36, "text": " half the people still think that a python is a snake and don't know how to connect to", "tokens": [1922, 264, 561, 920, 519, 300, 257, 38797, 307, 257, 12650, 293, 500, 380, 458, 577, 281, 1745, 281], "temperature": 0.0, "avg_logprob": -0.16815642024693864, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.6964013411779888e-05}, {"id": 1079, "seek": 711236, "start": 7112.36, "end": 7119.32, "text": " an AWS instance, and you'll all be able to say, read the wiki, here's the page, oh yeah,", "tokens": [364, 17650, 5197, 11, 293, 291, 603, 439, 312, 1075, 281, 584, 11, 1401, 264, 261, 9850, 11, 510, 311, 264, 3028, 11, 1954, 1338, 11], "temperature": 0.0, "avg_logprob": -0.23690120797408254, "compression_ratio": 1.5364583333333333, "no_speech_prob": 2.93106149911182e-05}, {"id": 1080, "seek": 711236, "start": 7119.32, "end": 7120.96, "text": " I have that problem too.", "tokens": [286, 362, 300, 1154, 886, 13], "temperature": 0.0, "avg_logprob": -0.23690120797408254, "compression_ratio": 1.5364583333333333, "no_speech_prob": 2.93106149911182e-05}, {"id": 1081, "seek": 711236, "start": 7120.96, "end": 7128.5199999999995, "text": " And hopefully our goal here is to create a new generation of deep learning practitioners,", "tokens": [400, 4696, 527, 3387, 510, 307, 281, 1884, 257, 777, 5125, 295, 2452, 2539, 25742, 11], "temperature": 0.0, "avg_logprob": -0.23690120797408254, "compression_ratio": 1.5364583333333333, "no_speech_prob": 2.93106149911182e-05}, {"id": 1082, "seek": 711236, "start": 7128.5199999999995, "end": 7135.24, "text": " people who have useful problems that they're trying to solve and can use this tool to solve", "tokens": [561, 567, 362, 4420, 2740, 300, 436, 434, 1382, 281, 5039, 293, 393, 764, 341, 2290, 281, 5039], "temperature": 0.0, "avg_logprob": -0.23690120797408254, "compression_ratio": 1.5364583333333333, "no_speech_prob": 2.93106149911182e-05}, {"id": 1083, "seek": 713524, "start": 7135.24, "end": 7145.44, "text": " them rather than create more and more exclusive, heavily mathematical content that's designed", "tokens": [552, 2831, 813, 1884, 544, 293, 544, 13005, 11, 10950, 18894, 2701, 300, 311, 4761], "temperature": 0.0, "avg_logprob": -0.35106151048527207, "compression_ratio": 1.352, "no_speech_prob": 2.355194737901911e-05}, {"id": 1084, "seek": 713524, "start": 7145.44, "end": 7149.599999999999, "text": " to pull people off. So that's our hope.", "tokens": [281, 2235, 561, 766, 13, 407, 300, 311, 527, 1454, 13], "temperature": 0.0, "avg_logprob": -0.35106151048527207, "compression_ratio": 1.352, "no_speech_prob": 2.355194737901911e-05}, {"id": 1085, "seek": 713524, "start": 7149.599999999999, "end": 7153.88, "text": " That's really why we're doing this.", "tokens": [663, 311, 534, 983, 321, 434, 884, 341, 13], "temperature": 0.0, "avg_logprob": -0.35106151048527207, "compression_ratio": 1.352, "no_speech_prob": 2.355194737901911e-05}, {"id": 1086, "seek": 715388, "start": 7153.88, "end": 7166.64, "text": " It really has been a genuine pleasure. I'm so happy to hear that most of you are going", "tokens": [467, 534, 575, 668, 257, 16699, 6834, 13, 286, 478, 370, 2055, 281, 1568, 300, 881, 295, 291, 366, 516], "temperature": 0.0, "avg_logprob": -0.20607886515872578, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.00011059807002311572}, {"id": 1087, "seek": 715388, "start": 7166.64, "end": 7175.28, "text": " to see you again next year. You guys obviously all get first dibs on places for next year's", "tokens": [281, 536, 291, 797, 958, 1064, 13, 509, 1074, 2745, 439, 483, 700, 23064, 82, 322, 3190, 337, 958, 1064, 311], "temperature": 0.0, "avg_logprob": -0.20607886515872578, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.00011059807002311572}, {"id": 1088, "seek": 715388, "start": 7175.28, "end": 7181.76, "text": " course. If the MOOC is successful, next year's course could be quite popular, so I do suggest", "tokens": [1164, 13, 759, 264, 49197, 34, 307, 4406, 11, 958, 1064, 311, 1164, 727, 312, 1596, 3743, 11, 370, 286, 360, 3402], "temperature": 0.0, "avg_logprob": -0.20607886515872578, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.00011059807002311572}, {"id": 1089, "seek": 718176, "start": 7181.76, "end": 7188.76, "text": " that you do nonetheless get your applications in not too late.", "tokens": [300, 291, 360, 26756, 483, 428, 5821, 294, 406, 886, 3469, 13], "temperature": 0.0, "avg_logprob": -0.3206655502319336, "compression_ratio": 1.5028901734104045, "no_speech_prob": 3.647464109235443e-05}, {"id": 1090, "seek": 718176, "start": 7188.76, "end": 7199.8, "text": " Be aware if you're not already, we don't send email much. Really the forums is our main", "tokens": [879, 3650, 498, 291, 434, 406, 1217, 11, 321, 500, 380, 2845, 3796, 709, 13, 4083, 264, 26998, 307, 527, 2135], "temperature": 0.0, "avg_logprob": -0.3206655502319336, "compression_ratio": 1.5028901734104045, "no_speech_prob": 3.647464109235443e-05}, {"id": 1091, "seek": 718176, "start": 7199.8, "end": 7204.88, "text": " way to communicate in Slack to some extent. So if you want to see what's going on, that's", "tokens": [636, 281, 7890, 294, 37211, 281, 512, 8396, 13, 407, 498, 291, 528, 281, 536, 437, 311, 516, 322, 11, 300, 311], "temperature": 0.0, "avg_logprob": -0.3206655502319336, "compression_ratio": 1.5028901734104045, "no_speech_prob": 3.647464109235443e-05}, {"id": 1092, "seek": 718176, "start": 7204.88, "end": 7206.280000000001, "text": " the places to look.", "tokens": [264, 3190, 281, 574, 13], "temperature": 0.0, "avg_logprob": -0.3206655502319336, "compression_ratio": 1.5028901734104045, "no_speech_prob": 3.647464109235443e-05}, {"id": 1093, "seek": 720628, "start": 7206.28, "end": 7212.8, "text": " And of course, our Wiki is the knowledge base that we're creating for everybody. So anytime", "tokens": [400, 295, 1164, 11, 527, 35892, 307, 264, 3601, 3096, 300, 321, 434, 4084, 337, 2201, 13, 407, 13038], "temperature": 0.0, "avg_logprob": -0.19335666455720601, "compression_ratio": 1.638655462184874, "no_speech_prob": 3.0714061722392216e-05}, {"id": 1094, "seek": 720628, "start": 7212.8, "end": 7217.48, "text": " you see something missing on the Wiki or something you think could be improved, edit it. Even", "tokens": [291, 536, 746, 5361, 322, 264, 35892, 420, 746, 291, 519, 727, 312, 9689, 11, 8129, 309, 13, 2754], "temperature": 0.0, "avg_logprob": -0.19335666455720601, "compression_ratio": 1.638655462184874, "no_speech_prob": 3.0714061722392216e-05}, {"id": 1095, "seek": 720628, "start": 7217.48, "end": 7220.48, "text": " if you're not sure if you're saying the right thing, you can add a little comment afterwards", "tokens": [498, 291, 434, 406, 988, 498, 291, 434, 1566, 264, 558, 551, 11, 291, 393, 909, 257, 707, 2871, 10543], "temperature": 0.0, "avg_logprob": -0.19335666455720601, "compression_ratio": 1.638655462184874, "no_speech_prob": 3.0714061722392216e-05}, {"id": 1096, "seek": 720628, "start": 7220.48, "end": 7226.04, "text": " saying, I'm not sure if this is correct.", "tokens": [1566, 11, 286, 478, 406, 988, 498, 341, 307, 3006, 13], "temperature": 0.0, "avg_logprob": -0.19335666455720601, "compression_ratio": 1.638655462184874, "no_speech_prob": 3.0714061722392216e-05}, {"id": 1097, "seek": 722604, "start": 7226.04, "end": 7237.28, "text": " Thanks so much everybody. I hope you all have a great vacation season.", "tokens": [50364, 2561, 370, 709, 2201, 13, 286, 1454, 291, 439, 362, 257, 869, 12830, 3196, 13, 50926], "temperature": 0.0, "avg_logprob": -0.30223361651102704, "compression_ratio": 0.9859154929577465, "no_speech_prob": 7.710137288086116e-05}], "language": "en"}