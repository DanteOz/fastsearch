{"text": " Welcome back. We're going to be talking today about Random forests we're going to finish building our own random forest from scratch But before we do I wanted to tackle a few things that have come up during the week a few questions that I've had And I want to start with kind of the position of random forests in general, so we spent About half of this course doing random forests And then after today the second half of this course will be neural networks broadly defined This is because these these two Represent like the T the two key classes of techniques which cover Nearly everything that you're likely to need to do random forests belong to the class of techniques of decision tree ensembles Along with gradient boosting machines being the other key type and some variants like extremely randomized trees they Have the benefit that they're highly interpretable scalable Flexible work well for most kinds of data They have the downside that they don't extrapolate at all to like Data that's outside the range that you've seen as we looked at at the end of last week's session but You know they're they're they're a great starting point and so I think you know there's a huge catalog of Machine learning tools out there and so and like a lot of courses and books Don't attempt to kind of curate that down and say like for these kinds of problems use this for these kinds of problems use that Finished you know, but they're rather like here's a description of a hundred different algorithms and You just don't need them You know like I don't see why you would ever use in support vector machine today for instance Like no no reason at all I could think of doing that People loved studying them in the 90s because they are like very theoretically elegant and like you can really Write a lot of math about support vector machines and people did but you know in practice I don't see them as having any place so There's like a lot of techniques that you could include in an exhaustive list of every way that people have open machine learning problems But I would rather tell you like how to actually solve machine learning problems in practice I think they you know with we're about to finish today the first class which is you know one type of decision tree ensembles In in part two unit will tell you about the other key type there being gradient boosting and we're about to launch next lesson into neural nets which includes all kinds of glm ridge regression elastic net lasso Logistic regression etc are all variants of neural nets You know interestingly Leo Breiman who created random forests did so very late in his life and Unfortunately passed away not many years later So partly because of that very little has been written about them in the academic literature Partly because SVM's were just taken over at that point. You know other people didn't look at them And also like just because they're like quite hard to grasp at a theoretical level like analyze them theoretically It's quite a hard to write conference papers about them or academic papers about them So there hasn't been that much written about them But there's been a real resurgence or not resurgence a new wave in recent years of empirical machine learning like what actually works Kaggle's been part of that but also just part of it has just been like Companies using machine learning to make shitloads of money like Amazon and Google and so nowadays a lot of people are writing about decision tree ensembles and creating better software for decision tree ensembles like light GBM and XGBoost and Ranger for are and psychic learn and so forth But a lot of this is being done in industry rather than academia But you know it's it's encouraging to see There's certainly More work being done in deep learning than in decision tree ensembles Particularly in in academia, but but there's a lot of progress being made in both You know if you look at like of the packages being used today for decision tree ensembles like All the best ones the top five or six. I don't know that any of them really existed Five years ago, you know maybe other than like sk learn or even three years ago, so it's that's that's been good But I think there's a lot of work still to be done. We talked about for example figuring out what interactions are the most important last week and Some of you pointed out in the forums that actually there is such a project already for gradient boosting machines Which is great, but it doesn't seem that there's anything like that yet for random forests And you know random forests do have a nice benefit over GBMs that they're kind of Harder to screw up you know and easier to scale So hopefully that's something that you know this community might help fix Another question I had during the week was about the size of your validation set How big should it be So like to answer this question about how big does your validation set need to be you first need to answer the question How How accurate do I need help how precisely do I need to know the accuracy of this algorithm right so like If the validation set that you have is saying like this is 70% accurate and If somebody said well is it 75% or 65% or 70% and the answer was I don't know anything in that range is close enough Like that would be one answer where else if it's like is it 70% or 70.01% or 69.99% Like then that's something else again, right so you need to kind of start out by saying like how how accurate do I need this? So like for example in the deep learning course we've been looking at dogs versus cats images and The models that we're looking at had about a 99 point for 99.5 percent accuracy on the validation set okay, and our validation set size was 2000 okay in fact let's do this in Excel that'll be a bit easier So our validation set Size was 2000 and our accuracy was 99 point four percent right so the number of incorrect is Something around One minus accuracy times and so we were getting about 12 wrong right and The number of cats we had is half and So the number of wrong cats is about Six Okay, so then like we we run a new model and we find instead that the accuracy has gone to 99.2 percent Right and then it's like okay. Is this less good at finding cats. There's like well it got two more cats wrong. So it's like probably not right, so But then it's like well does this matter there's 99.4 versus 99.2 Matter and if this was like it wasn't about cats and dogs, but it was about finding fraud right then the difference between a point six percent error rate and a point eight percent error rate is like 25% of your cost of fraud So like that can be huge like it was really interesting like when image net came out earlier this year the new competition results came out and The accuracy had gone down from three percent So the error went down from three percent to two percent and I saw a lot of people on the internet like famous machine learning researchers being like Yeah, some Chinese guys got it better from like 97 percent to 198 percent is like statistically not even significant Who cares kind of a thing? But actually I thought like Holy crap this Chinese team just blew away the state-of-the-art and image recognition like the old one was 50% less accurate Than the new one like that's that's actually the right way to think about it, isn't it? because it's like you know we were trying to recognize you know like which tomatoes were ripe and which ones weren't and Like our new approach, you know the old approach like 50% of the time more was like letting in the unripe tomatoes or You know 50% more of the time we were like accepting fraudulent customers like that's a really big difference So just because like this particular validation set we can't really see six versus eight doesn't mean the point two percent different isn't Important it could be so my kind of rule of thumb is that this like this number of like how many? Observations you actually looking at I want that generally to be somewhere higher than 22 Why 22 because 22 is the magic number where the t distribution roughly turns into the normal distribution? All right, so as you may have learned the t distribution is is the normal distribution for small Data sets right and so in other words once we have 22 of something or more it kind of starts to behave kind of Normally in both sense of the words like it's kind of more stable and you can kind of understand it better so That's my magic number when somebody says do I have enough of something? I kind of start out by saying like do you have 22 observations of the thing of interest? so if you were looking at like Lung cancer, you know and you had a data set that had like a thousand people without lung cancer and 20 people with lung Cancer I'd be like I very much doubt we're gonna make much progress, you know, because we haven't even got 20 of the thing You want? So ditto with a validation set if you don't have 20 of the thing you want that it's very unlikely to be useful or if like The at the level of accuracy we need it's not plus or minus 20. It's just it's that that's the point where I'm thinking like Be a bit careful so just to be clear you want 22 to be the number of samples in each set like in the validation the test and the train or so what I'm saying is like if there's if there's less than 22 of A class in any of the sets then it's it's gonna get it's getting pretty unstable at that point, right? And so like that's just like the first rule of thumb but then what I would actually do is like start practicing what we learned about the binomial distribution or actually generally distribution, so What's the? What is the mean of the binomial distribution of n samples and probability P? And times P. Okay. Thank you and times P is our mean Right, so if you've got a 50% chance of getting ahead and you toss it a hundred times on average you get 50 heads Okay, and then what's the standard deviation? And P 1 minus P Okay, so these are like Two numbers. Well the first number you don't really have to remember It's intuitively obvious. The second one is one that try to remember forever more Because not only does it come up all the time the people that you work with will all have forgotten it So you'll be like the one person in the conversation who could immediately go we don't have to run this a hundred times I can tell you straight away. It's binomial. It's going to be NP Q NP 1 minus P Then there's the standard error the standard error is if you run a bunch of trials each time getting a mean What is the standard deviation of the mean? I? Don't think you guys have covered this yet. Is that right? No, so this is really important because this means like if you train a hundred models right each time the validation set accuracy is like the mean of a distribution and So therefore the standard deviation of that validation set accuracy it can be calculated with the standard error And this is equal to the standard deviation divided by square root and Right so this tells you So like one approach to figuring out like is my validation set big enough is train your model five times with exactly the same hyper parameters each time and look at the validation set accuracy each time and you know There's like a mean and a standard deviation of five numbers. You could use or a maximum and minimum you can choose But save yourself some time you can figure out straight away that like Okay, well I I have a point nine nine nine accuracy as to you know whether I get the cat correct or not correct so Therefore the standard deviation is equal to 0.99 times 0.01 Okay, and then I can get the Standard error of that right so so basically the size of the validation set you need it's like However big it has to be such that your insights about its accuracy are good enough for your particular business problem And so like I say like the simple way to do it is to pick a validation set of like a size of thousand Train five models and see how much the validation set accuracy varies And if it's like if they're if it's a they're all close enough for what you need then you're fine If it's not maybe you should make it bigger Or maybe you should consider using cross validation instead Okay So like as you can see it really depends on what it is you're trying to do How common your less common class is and how accurate your model is could you pass that back to Melissa, please Thank you I have a question about the less common classes if you have less than 22 Let's say you have one sample of something Let's say it's a face and I only have one representation from that particular country Do I toss that into the training set and it adds variety? Do I pull it out completely out of the data set or? Do I put it in a test set instead of the validation set? So you certainly couldn't put it in the test of the validation set because you're asking Can I mean in general because you're asking can I recognize something I've never seen before? But actually this this question of like can I recognize something I've not seen before there's actually a whole class of models specifically For that purpose it's called either one-shot learning Which is you get to see something once and then you have to recognize it again or zero shot learning Which is where you have to recognize something you've never seen before we're not going to cover them in this course But they can be useful for things like Face recognition You know like is this the same person I've seen before and so generally speaking obviously for something like that to work It's not that you've never seen our face before it's that you've never seen Melissa's face before you know and so you see Melissa's face once and you have to recognize it again Yeah, so in general you know your validation set and test set need to have the same mix or frequency Observations that you're going to see in production in the real world and then your training set Should have an equal number in each class and if you don't Just replicate the less common one Until it is equal so this is I think we've mentioned this paper before very recent paper that came out They tried lots of different approaches to training with unbalanced data sets and found consistently that Oversampling the less common class until it is the same size as the more common class is Always the right thing to do So you could literally copy You know so like I've only got a thousand you know ten examples of people with cancer and a hundred without so I could just copy those ten Another you know 90 times That's kind of a little memory inefficient so a lot of things including I think SK learns random forests have a class weights parameter that says each time you're bootstrapping or resampling I want you to sample the less common class with a higher probability Or ditto if you're doing deep learning you know make sure in your mini batch It's not randomly sampled, but it's a stratified sample so the less common class is picked more often Okay Okay, so let's get back to finishing off Our random forests and so what we're going to do today is we're going to finish off writing our random forest and then after day your your after today your homework will be to take this class and To add to it all of the random forest interpretation algorithms that we've learned okay, so Obviously to be able to do that you're going to need to totally understand how this class works So please you know ask lots of questions as necessary as we go along So just to remind you We we're doing the the bulldozers kaggle competition data set again We split it as before into 12,000 validation the last 12,000 records and then Just to make it easier for us to keep track of what we're doing We're going to just pick two columns out to start with year made and machine hours on the meter Okay, and so what we did last time was we started out by creating a tree ensemble and the tree ensemble had a bunch of trees which was literally a list of n trees trees Where each time we just called create tree? okay, and create tree contained a sample size number of random indexes Okay, this one was drawn without replacement So remember bootstrapping means sampling with replacement so normally with scikit-learn if you've got n rows We grab n rows with replacement which means many of them will appear more than once So each time we get a different sample But it's always the same size as the original data set and then we have our set RF samples Function that we can use which does with replacement sampling of less than n rows This is doing something again, which is it sampling without replacement? Sample size rows okay because we're permuting The numbers from naught to self dot y minus 1 and then grabbing the first self dot sample size of them Actually, there's a faster way to do this you can just use NP dot random dot choice, which is a slightly more direct way But this way works as well Alright, so this is our random sample for this one of our entries trees And so then we're going to create a decision tree and our decision tree We don't pass it all of X we pass it these specific indexes and remember X is a pandas data frame So if we want to index into it with a bunch of integers we have to use I lock integer locations And that makes it behave indexing wise just like numpy Our Y vector is numpy so we can just index into it directly and then we're going to keep track of our minimum leaf size So then the only other thing we really need an ensemble is some way to make a prediction and so we were just going to Do the mean of the tree prediction? for each tree Alright, so that was that and so then in order to be able to run that We need a decision tree class because it's being called here And so there we go Okay, so that's the starting point so The next thing we need to do is to flesh out our decision tree So the important thing to remember is all of our randomness Happened back here in the tree ensemble The decision tree class we're going to create Doesn't have randomness in it Okay, so right now we are building a random t regressor right so that's why we're taking the mean of the tree The outputs if we were to work with classification Do we take the max like the classifier will give you either zeros or ones? No, I would still take the mean so the so each tree is going to tell you What percentage of that leaf node contains cats and what percentage take contains dogs? so then I would average all those percentages and say across the trees on average there is 19 percent cats and 81 percent dogs Good question so you know Random tree classifiers are almost identical or can be almost identical the random tree regresses the Technique we're going to use to build this today will basically exactly work for a classification It's certainly for binary classification you can do with exactly the same code for multi-class classification. You just need to change your data structure So that like you have like a one hot encoded matrix or a List of integers that you treat as a one hot encoded matrix Okay, so our decision tree So remember our idea here is that we're going to like try to avoid thinking so we're going to basically write It as if everything we need already exists, okay, so we know From when we created the decision tree we're going to pass in the X the Y and the minimum leaf size So here we need to make sure we've got the X and the Y and the minimum leaf size, okay so then there's one other thing which is as we split our tree into sub trees, we're going to need to keep track of Which of the row indexes went into the left hand side of the tree which went into the right hand side of the tree? Okay, so we're going to have this thing called indexes as Well, right so at first we just didn't bother passing in indexes at all So if indexes is not passed in if it's none, then we're just going to set it to Ever the entire length of Y right so NP dot a range is the same as just range in Python But it returns a numpy array right so that the root of a decision tree Contains all the roads. That's the definition really of the root of a decision tree So all the rows is for naught row one row two etc up to row y minus one Okay, and then we're just going to store away all that information that we were given We're going to keep track of how many? Rows are there and how many columns are there okay? so then the every Leaf and every node in a tree has a value it has a prediction And that prediction is just equal to the average of the dependent variable Okay, so every node in the tree Y indexed with the indexes is The values of the dependent variable that are in this branch of the tree and so here is the mean Some Nodes in a tree also have a score which is like how effective was the split? Here right, but that's only going to be true if it's not a leaf node right a leaf node has no further splits And at this point when we create a tree we haven't done any splits yet, so its score starts out as being infinity So having built the The root of the tree our next job is to find out which variable should we split on and what? Level of that variable should we split on so let's pretend that there's something that does that fine basket So then we're done, okay, so how do we find a variable to split on so well we could just go through each Potential variable so C contains the number of columns We have so go through each one and see if we can find a better split than we have so far on that column Okay Now notice this is like not The full random forest definition this is assuming that max features Is set to all right remember we could set max features to like 0.5 in which case we wouldn't check all the numbers from not to see we would check half the numbers at random from not to See so if you want to turn this into like a random forest that has the max features Support you could easily like add one line of code to do that, but we're not going to do it in our implementation today So then we just need to find better split and since we're not interested in thinking at the moment for now We're just going to leave that empty All right so The one other thing I like to do With my kind of where I start writing a class is I like to have some way to print out what's in that class Right and so if you type print followed by an object or if it Jupiter notebook you just type the name of the object At the moment it's just printing out Underscore underscore main underscore underscore decision tree at blah blah blah which is not very helpful right so if we want to replace this with Something helpful we have to define the special Python method name Dunder repra To get a representation of this object so when we when we basically just Write the name like this behind the scenes that calls that function and the default Implementation of that method is just to print out this Unhelpful stuff so we can replace it by instead saying let's create a format string Where we're going to print out n and then show n and then print val and then show val okay, so how many? How many rows are in this node and what's the average of the dependent variable okay? Then if it's not a leaf node so if it has a split then we should also be able to print out the score The value we split out and the variable that we split on Now you'll notice here Self dot is leaf is leaf is defined as a method, but I don't have any parentheses after it This is a special kind of method called a property and so a property is something that kind of looks like a regular Variable, but it's actually calculated on the fly so when I call its leaf it actually calls This function right, but I've got this special decorator property Okay, and what this says is basically you don't have to include the parentheses when you call it Okay, and so it's going to say all right is this a leaf or not so a leaf is Something that we don't spit on if we haven't split on it then its score is still set to infinity So that's my logic That makes sense so this this at notation This at notation is called a decorator. It's basically a way of Telling Python more information about your method Does anybody here remember where you have seen decorators before? You pass it over here Yeah, where have you seen that where have you seen decorators last tell us more about flask and where how it uses that It was the at app route Yeah, what does that do? that Okay So flask so anybody who's done any web programming before with something like flask or a similar framework Would have had to have said like this method is going to respond to this Bit of the URL and either to post or to get and you put it in a special decorator so Behind the scenes that's telling Python to treat this method in a special way so here's another decorator, okay? And so you know if you get more advanced with Python you can actually learn how to write your own decorators Which as was mentioned you know basically insert some additional code, but for now just know there's a bunch of predefined decorators we can use to Change how our methods behave and one of them is at property which basically means you don't have to put parentheses anymore Which of course means you can't add any more parameters beyond self Yep Why if it's not a leaf why is the score infinity? Because it's an infinity mean you're at the root Why no infinity means that you're not at the root it means you're at a leaf so the root will have a split Assuming we find one yeah, but everything will have a split till we get all the way to the bottom The leaf and so the leaves will have a score of infinity because they won't split Great all right so that's our Decision tree it doesn't do very much, but at least we can like create an ensemble Right ten trees sample size a thousand right and we can like print out so now when I go m trees zero It doesn't say blah blah blah blah it says What we asked it to say and call the thousand foul colon ten point eight oh wait Okay, and this is a leaf because we haven't spit on it yet, so we've got nothing more to say Okay, so then the indexes are all the numbers from naught to a thousand Okay, because the base of the tree has everything this is like everything in The random sample that was passed to it because remember by the time we get to the point where it's a decision tree Where we don't have to worry about any of the randomness in the random forest anymore? All right, so Let's try to write the thing which finds a split okay, so we need to implement Find better split okay, and so it's going to take the index of a variable variable number one variable number three Whatever and it's going to figure out What's the best split point? Is that better than any split we have so far and? For the first variable the answer will always be yes because the best one so far is none at all which is infinity bad, okay? So let's start by making sure we've got something to compare to so the thing we're going to compare to will be scikit-learns random forest and So we need to make sure that scikit-learns random forest gets exactly the same data that we have so we start out by creating ensemble Grab a tree out of it and then find out which particular random sample of X and Y did this tree use Okay, and we're going to store them away so that we can pass them to scikit-learn so we have exactly the same information So let's go ahead and now create our random forest using scikit-learn so one tree one decision No bootstrapping so the whole the whole data set that so this should Be exactly the same as the thing that we're going to create this tree So let's try So we need to define Find better split Okay, so find better split takes a variable Okay, so let's define our X independent variables and say okay. Well. It's everything inside our tree, but only Those indexes that are in this node, right which at the top of the tree is everything right and just this one variable Okay, and then for our wise it's just whatever our dependent variable is at the indexes in this node Okay, so there's our X and Y So let's now go through every single value in our independent variable and So I'll show you what's going to happen, so let's say our independent variable is EMA And Not going to be an order Right and so we're going to go to the very first row and we're going to say okay Yeah, mate here is three right and so what I'm going to do is I'm going to try and calculate The score if we decided to branch on the number three Right so I need to know which rows are greater than three Which rows are less than an equal to three and they're going to become my left hand side my right hand side Right and then we need a score right, so There's lots of scores we could use so in random forests We call this the information gain right the information gain is like how much better does our score get because we split it into? These two groups of data there's lots of ways we could calculate it Jimmy cross entropy root mean squared error whatever If you think about it there is an alternative formulation of root mean squared error Which is mathematically the same to within a constant scale? But it's a little bit easier to deal with which is we're going to try and find a split Which the causes the two groups to each have as lower standard deviation as possible All right, so like I want to find a split that puts all the cats over here and all the dogs over here Right so if these are all cats and these are all dogs then this has a standard deviation of zero and this has a standard Deviation of zero or else. This is like a totally random mix of cats and dogs This is a totally random mix of cats and dogs. They're going to have a much higher standard deviation That makes sense and so it turns out if you find a split that minimizes those group standard deviations or specifically the Weighted average of the two standard deviations. It's mathematically the same as minimizing the root mean squared error That's something you can prove to yourself after class if you want to All right, so we're going to need to find First of all split this into two groups. So where's all the stuff that is greater than three? So greater than three is this one this one and this one so we need the standard deviation of that so let's go ahead and say standard deviation of greater than three that one that one and that one, okay, and then the next will be the standard deviation of Less than or equal to three so that would be that one that one that one and Then we just take the weighted average of those two and that's our score That would be our score if we split on three That makes sense and so then the next step would be try to split on four try splitting on one try splitting on six Redundantly try splitting on four again Redundantly try splitting on one again and find out which one works best So that's our code here is we're going to go through every row and so let's say okay left-hand side is Any values in X that are less than or equal to this particular value? Our right-hand side is every value in X that are greater than this particular value Okay, so what's the data type that's going to be in LHS and RHS? What are they actually going to contain? They're going to be arrays arrays of what? Rays of arrays of Booleans yeah, which we can treat as zero and one okay, so LHS will be an array of false Every time it's not less than or equal to and true otherwise and RHS will be a Boolean array of the opposite Okay, and now we can't take a standard deviation of an empty set right so if there's nothing that's greater than This number then these will all be false which means the sum will be zero Okay, and in that case let's not go any further with this step because there's nothing to take the standard deviation of and it's obviously Not a useful split okay, so assuming. We've got this part. We can now calculate the standard deviation of the left-hand side and of the right-hand side and Take the weighted average or the sums the same thing to us to a scalar Right and so there's our score and so we can then check is this better than our best score so far and our best score So far we initially initialized it to infinity right so initially. This is this is better So if it's better Let's store away All of the information we need which variable has found this better split. What was the score we found and What was the? Value that we spit on Okay, so there it is So if we run that And I'm using time it so what time it does is it sees how long this command takes to run and? It tries to give you a kind of statistically valid measure of that so you can see here. It's run run at ten times To get an average and then it's done that seven times to get a mean and standard deviation across runs And so it's taking me 75 milliseconds plus or minus ten Okay So let's check that this works Find let us split tree zero so zero is you made one is machine hours current meter? So with one We got back machine hours current meter 3744 with this score And then we ran it again with zero that's you made and we've got a better score 658 and split 1974 and so 1974 Let's compare Yeah, that was what this tree did as well. Okay, so we've got we've confirmed that this Method is doing is giving the same result that SK learns random forest did Okay, and you can also see here the value 10.08 and again matching here the value 10.08 Okay, so we've got something that confined one split could you pass that to your net please? So Jeremy, why don't we put a unique on the X there? Because I'm not trying to optimize the performance yet, but you see that no like he's doing more Yeah, so it's like and you can see in the Excel. I like checked this one twice. I checked this for twice unnecessarily Yeah Okay, so and So you know it's already thinking about performance, which is good So tell me what is the computational complexity of this section of the code and Like have a think about it, but also like feel free to talk us through it if you want to kind of Think and talk at the same time What's the computational complexity of this piece of code? Can I pass it over there yes All right, Jay take us through your thought process I think you have to take each different values through the column to calculate it Once to see the splits so and it compared All the like all the possible combinations between these different values so that can be expensive Like cuz you're uh-huh can you know does somebody else want to tell us the actual computational complexity? So like yeah quite high Jade's thinking How high I? Think it's n-squared okay, so tell me why is it n-squared because for the for loop it is in yes And I think I guess the standard deviation will take in so it's n-squared okay, or This one maybe is even easier to know like this is like which ones are less than x. I I'm gonna have to check every Value to see if it's less than x. I okay, and so so it's useful to know like How do I quickly calculate computational complexity? I can guarantee most of the interviews you do are gonna ask you to calculate Computational complexity on the fly and it's also like when you're coding you want it to be second nature So it's like you're going to have to calculate the complexity of the code and you're going to have to calculate the complexity So the technique is basically is there a loop? Okay, we're then we're obviously doing this n times Okay, so there's an n involved is there a loop inside the loop if there is then you need to multiply those two together In this case there's not is there anything inside the loop that's not a constant time thing So you might see a sort in there And you just need to know that sort is n log n like that should be second nature if you see a matrix Multiply you need to know what that is in this case. There are some things that are doing element wise array operations Right so keep an eye out for anything where numpy is doing something to every value of an array in this case It's checking every value of X Against a constant so it's going to have to do that n times so to flesh this out into a computational complexity You just take the number of things in the loop and you multiply it by the highest Computational complexity inside the loop n times n is n squared you pass that In this case couldn't we just pre sort the list and then do like one and log n computation And there's lots of things we can do to speed this up so at this stage is just like what is the computational complexity we have? But absolutely it's certainly not as good as it can be okay, so that's where we're going to go next It's like all right n squared is not it's not great, so let's try and make it better so Here's my attempt at making it better And the idea is this Okay, who wants to first of all tell me what's the equation for standard deviation? Masha can you grab the box? So for the standard deviation, it's the difference between the value and its mean It's we take a square root of that. Sorry we take the The power of two Then we sum up all of these observations, and we take the square root out of all this some yeah You have to divide divide by n. Yeah, yeah great good. Okay now in practice we Don't normally use that formulation because it kind of requires us calculating You know X minus the mean lots of times does anybody know the formulation that just requires X and X squared Anybody happen to know that one yes at the back trying to pass that back there Square root of a mean of squares minus Square of mean yeah great mean of squares minus the square of the means alright, so that's a really good one Divided by n. That's a really good one to know because like you can now calculate Variances or standard deviations of anything you just have to first of all grab the column as it is The column squared right and as long as you've got those stored away somewhere you can immediately calculate the standard deviation So the reason this is handy for us is that if we first of all? Sort our data right Let's go ahead and sort our data Then if you think about it as we kind of start going down one step at a time Right then each group is exactly the same as the previous group on the left-hand side with one more thing in it And on the right-hand side with one less thing in it So given that we just have to keep track of sum of X and some of X squared We can just add one more thing to X one more thing to X squared on the left and remove one thing on the right Okay, so we don't have to go through the whole lot each time and so we can turn this into a order n Algorithm so that's all I do here is I sort the data right and they're going to keep track of the count of things on the right the sum of things on the right and the sum of squares on the right and Initially everything's in the right-hand side Okay, so initially n is the count Y sum is the sum on the right and Y squared sum is the sum of squares on the right and Then nothing is initially on the left, so it's zeros okay, and then we just have to loop through each observation right and Add one to the left-hand count subtract one from the left right hand count add the value to the left-hand count Subtract it from the right-hand count add the value squared to the left hand subtract it from the right hand Okay Now we do need to be careful though because if we're saying less than or equal to one say we're not stopping here We're stopping here like we have to have everything in that group So the other thing I'm going to do is I'm just going to make sure That the next value is not the same as this value if it is I'm going to skip over it right So I'm just going to double check That this value and the next one aren't the same Okay, so as long as they're not the same I can keep going ahead and calculate my standard deviation now passing in the count the sum and the sum squared Right and there's that formula Okay, the sum of squared Divided by the square of the sum sorry minus the square of the sum Do that for the right-hand side and so now we can calculate the weighted average score Just like before and all of these lines are now the same okay, so we've turned our order and Squared algorithm into an order n algorithm and in general stuff Like this is going to get you a lot more value than like pushing something onto a spark cluster or Ordering faster RAM or using normal cores in your CPU or whatever right? This is the way you want to be you know improving your code and specifically Write your code Right without thinking too much about performance run it is it fast enough for what you need then you're done if not Profile it right so in Jupiter instead of saying percent time it you say percent p run and It will tell you Exactly where the time was spent in your algorithm And then you can go to the bit that's actually taking the time and think about like okay is this Is this algorithmically as efficient as it can be? Okay, so in this case we run it and we've gone down from 76 milliseconds to less than 2 milliseconds and Now some people that are new to programming think like oh great. I've saved 60 something milliseconds, but the point is this is going to get run Like tens of millions of times Okay, so the 76 millisecond version is so slow that it's going to be Impractical for any random forest you use in in practice right where else the 1 millisecond version I found is actually quite quite acceptable And then check the numbers should be exactly the same as before and they are okay so now that we have a Function find better split that does what we want I? Want to insert it into my decision tree class, and this is a really cool Python trick Python does everything dynamically Right so we can actually say The method called find better split in decision tree is That function I just created and that might sticks it inside that class now I'll tell you what's slightly confusing about this is that this thing this word here and This word here. They actually have no relationship to each other They just happen to have the same letters in the same order right so like I could call this fine better split underscore foo Right and then I could like call that Right and call that That right so now my function is actually called fine better split underscore foo, but my method I'm expecting to call something called Decision tree dot fine better split Right so here. I could say decision tree dot fine better split equals find better split underscore foo Okay, you see that's the same thing right so like It's important to understand how namespaces work like in every Language that you use one of the most important things is kind of understanding How how it figures out what a name refers to so this here? Means find better split as defined inside this class right and no nowhere else right well I mean a sub a parent class, but never mind about that this one here means find better split foo In the global namespace a lot of languages don't have a global namespace, but Python does okay, and so the two are Like even if they happen to have the same letters in the same order. They're not referring in any way to the same thing That makes sense. It's like This family over here may have somebody called Jeremy and my family has somebody called Jeremy and our names happen to be the same But we're not the same person okay? Great so now that we've stuck The decision tree sorry the fine better split method inside the decision tree with this new definition When I now call the tree ensemble constructor Right the decision tree ensemble instructor called create tree Create tree instantiated decision tree Decision tree called find vast split which went through every column to see if it could find a better split and we've now defined find better split and Therefore tree ensemble when we create it has gone ahead and done the split That makes sense don't have any anybody have any questions or uncertainties about that like we're only creating one single split so far All right, so this is pretty pretty neat right we kind of just do a little bit at a time testing everything as we go and so it's as as as you all Implement the random forest interpretation techniques You may want to try programming this way to like every step check that you know What you're doing matches up with what psychic learn does or with a test that you've built or whatever So at this point we should try to go deeper Very inception right so let's go now max depth is 2 And so here is what psychic learn did after breaking at year made 74 It then broke at machine hours beta 2956 So we had this thing called Find vast split Right we just went through every column and tried to see if there was a better split there right but actually We need to go a bit further than that Not only do we have to go through every column and see if there's a better split in this node But then we also have to see whether there's a better split in the left and the right sides that we just created Right in other words the left right side and the right hand side should become decision trees themselves Right so there's no difference at all between what we do here to create this tree And what we do here to create this tree other than this one contains 159 samples this one contains a thousand So this row of codes exactly the same as we had before Right and then we check actually we could do this a little bit easier. We could say if self dot is Leaf right would be the same thing Okay, but I'll just leave it here for now. So is self dot score so if the score is Infinite still in fact. Let's write it properly Yes, wait So let's go back up and just remind ourselves is leaf is Self dot score equals in okay So since there we might as well use it so if it's a leaf node Then we have nothing further to do right so that means we're right at the bottom There's no split that's been made okay, so we don't have to do anything further on the other hand if it's not a leaf node So it's somewhere back earlier on Then we need to split it into the left-hand side and the right-hand side Now earlier on we created a left-hand side and a right-hand side a ray of Boolean's right now I'm better would be to have here would be have an array of indexes And that's because we don't want to have a full array of all the Boolean's in every single Node right because remember although it doesn't look like there are many nodes when you see a tree of this size When it's fully expanded the bottom level if there's a minimum leaf size of one contains the same number of nodes as The entire data set and so if every one of those contained a full Boolean array of size of the whole data set You've got squared memory requirements, which would be bad right on the other hand if we just store the indexes If the things in this node, then that's going to get smaller and smaller Okay So NP dot nonzero is exactly the same as just this thing which gets the Boolean array But it turns it into the indexes of the trues okay, so this is now a list of indexes for the left-hand side and indexes the right-hand side So now that we have the indexes the left-hand side and the right-hand side We can now just go ahead and create a decision tree Okay, so there's a decision tree for the left And there's our decision tree for the right Okay, and we don't have to do anything else we've already written these we already have a function of a constructor that can create a decision tree So like when you really think about what this is doing it kind of hurts your head right because the reason the whole reason that find varsplit got called is because Find varsplit is called by the decision tree constructor But then the decision tree that then find varsplit itself then causes the decision tree constructor, so we actually have circular recursion and I'm not nearly smart enough to be able to think through recursion So I just choose not to right like I just write what I mean and Then I don't think about it anymore Right like what do I want? Well to find a variable split I've got to go through every column see if there's something better If it managed to do a split figure out the left-hand side of the right-hand side and make them into decision trees Okay, but now try to think through how these two methods call each other would just drive me crazy But I don't need to right. I know I have a decision tree constructor that works, right? I know I have a via find varsplit that works. So that's it right? That's how I Do recursive programming is? By pretending I don't I just just ignore it. That's my advice I lot of you are probably smart enough to be able to think through it better than I can so that's fine If you can right so now that I've written that again, I can patch it into the decision tree class And as soon as I do The tree ensemble constructor will now use that right because Python's dynamic, right? That's just happens automatically So now I can check my left hand side Should have a hundred and fifty nine samples Right and a value of nine point six six There it is hundred fifty nine samples nine point six six right hand side Eight forty one ten point one five the left hand side of the left hand side hundred and fifty samples nine point six two Hundred and fifty samples nine point six two. Okay, so you can see it like I'm Because I'm not nearly clever enough to write machine learning algorithms like not only can I not write them correctly the first time Often like every single line I write will be wrong, right? So I always start from the assumption that the the line of code I just typed is almost certainly wrong and I just have to see why and how Right and so like I just make sure and so eventually I get to the point where like much to my surprise It's not broken anymore, you know So here I can feel like okay this it would be surprising if all of these things Accidentally happen to be exactly the same as scikit-learn. So this is looking pretty good So now that we have something that can build a whole tree Where you want to have something that can calculate predictions? Okay, and so to remind you we already have something that calculates predictions for a tree ensemble by calling tree dot predict But there is nothing called tree dot predict. So we're gonna have to write that To make this more interesting, let's start bringing up the number of columns that we use Let's create our tree ensemble again and this time let's go to a maximum depth of three Okay, so now our tree is getting more interesting And let's now define how do we create a set of predictions for a tree and So a set of predictions for a tree is simply the prediction for a row for every row That's it. All right, that's our predictions. So the predictions for a tree are every rows predictions in an array, okay, so again, we're like Skipping thinking thinking is hard, you know, so let's just like keep pushing it back This is kind of handy right notice that you can do for For La in array with a numpy array regardless of the rank of the array regardless of the number of axes in The array and what it does is it will loop through the leading axis right and these these Concepts are going to be very very important as we get into more and more neural networks because we're going to be all doing Tensor computations all the time. So the leading axis of a vector is the vector itself The leading axis of a matrix are the rows the leading axis axis of a three-dimensional tensor The matrices that represent the slices and so forth, right? So in this case because X is a matrix this is going to loop through the rows and if you write your kind of tensor code this way then it'll kind of tend to Generalize nicely to higher dimensions like it doesn't really mention matter how many dimensions are in X This is going to loop through each of the leading axis, right? Okay, so we can now call that decision tree dot predict Right so all I need to do is write predict row Right and I've delayed thinking so much which is great that the actual point. We're actually have to do the work It's now basically trivial So if we're at a leaf No, then the prediction is just equal to Whatever that value was Which we calculated right back in the original tree constructor. It's just the average of the wise, right? If it's not a leaf node Then we have to figure out whether to go down the left-hand path or the right-hand path to get the prediction right so if This variable in this row is less than or equal to the thing we decide the amount we decided to split on Then we go down the left path Otherwise we go down the right path Okay, and then having figured out what path we want which tree we want then we can just call predict row on that right and again We've accidentally created something recursive Again, I don't want to think about how that Works control flow wise or whatever, but I don't need to because like I just It just does like I just told it what I wanted so I trust it to work right if it's a leaf return the value Otherwise return the prediction for the left-hand side or the right-hand side as appropriate Okay Notice this here this if Has nothing to do with this if All right, this if is a control flow statement That tells Python to go down that path or that path to do some calculation this if is an operator That returns a value So those of you that have done C or C++ will recognize it as being identical to that it's called the ternary operator All right, if you haven't that's fine. Basically what we're doing is we're going to get a value Where we're going to say it's this value if this thing is true and That value otherwise And so you could write it This way, right but that would require writing four lines of code to do one thing It also require you to have code that if you read it to yourself or to somebody else is not at all Naturally the way you would express it right I want to say the tree I got to go down is the left-hand side if the variables less than the split or the right-hand side otherwise All right, so I want to write my code the way I would think about or the way I would say my code Okay, so this kind of a ternary operator can be quite helpful for that All right So now that I've got a prediction for a row I can dump that into my class and Now I can create calculate predictions And I can now plot my actuals against my predictions when You do a scatter plot You'll often have a lot of dots sitting on top of each other So a good trick is to use alpha alpha means how transparent the things not just in matplotlib But like in every graphics package in the world pretty much and so if you set alpha to less than one Then this is saying you would need 20 dots on top of each other for it to be fully blue And so this is a good way to kind of see How much things are sitting on top of each other? So it's a good trick good trick for scatter plots There's my r squared not bad And so let's now go ahead and do a random forest With no max amount of splitting And our Tree ensemble had no max amount of splitting we can compare our r squared To their r squared and so they're not the same But actually ours is a little better, so I don't know what we did differently, but we'll take it Okay, so we have now something which for a Forest with a single tree in is giving as good accuracy On a validation set using an actual real-world data set you know bullbooks for blue doses compared to psychic learn So let's go ahead and round this out So what I would want to do now is to create a package that has this coding and I created it by like creating a method Here a method here a method here and patching them together So what I did with now is I went back through my notebook and collected up all the cells That implemented methods and pasted them all together right, and I've just pasted them down here So here's this is my original tree ensemble and here is all the cells from the decision tree I just dumped them all into one place without any change So that was it that was the code we wrote together, so now I can go ahead and I can create a Tree ensemble I Can calculate my predictions I can do my scatter plot I can get my R squared right and this is now with five trees Right and here we are we have a model of Blue dook for bulldozers with a 71% R squared with a random forest we wrote entirely from scratch So that's pretty cool Any questions about that and I know there's like quite a lot to get through so during the week feel free to ask on the forum About any bits of code you come across can somebody pass the box to Marsha? Oh there is Can we get back to the probably to the top of maybe a The decision tree when we set the score equal to infinity right yes, I do it calculate this car this score For that I mean like I lost track of that and specifically I wonder When we implement when we implement Find our split we check for self score equal to whether it's equal to infinity or not It seems to me it seems like unclear whether we fall out of this I Mean like if we ever implement The methods if if our initial value is infinity So okay, let's talk through the logic so So the decision tree Starts out with a score at infinity so in other words at this point when we've created the node there is no split So it's infinitely bad Okay, that's why the score is infinity and then we try to find a variable and a split that is better and to do that we loop through each column and Say hey column. Do you have a split which is better than the best one we have so far and So then we implement that let's Do the slow way since it's a bit simpler find better split we do that by looping through each row and Finding out this is the current score if we split here Is it better than the current score the current score is infinitely bad so yes it is and so now we set the new score Equal to what we just calculated and we keep track of which variable we chose and the split we spit on Okay, no worries Okay, great, let's take a five-minute break, and I'll see you back here at 22 So when I tried comparing the performance of this Against scikit-learn This is quite a lot slower and the reason why is That although like a lot of the works being done by numpy Which is nicely optimized C code think about like the very bottom level of a tree if we've got a million data points and the bottom level of the tree has something like five hundred thousand decision points with a million leaves underneath right and so that's like 500,000 split methods being called each one of contained which contains multiple calls to numpy which only have like one Item that's actually being calculated on and so it's like that's like very inefficient, and it's the kind of thing that python is Particularly not good at performance wise right like calling lots of functions lots of times I mean we can see it's it's not bad right you know for a kind of a random forest which 15 years ago would have been considered pretty big this would be considered pretty good performance right but nowadays this is some hundreds of times at least slower than that it should be so What the scikit-learn folks did to avoid this problem was that they wrote their implementation in something called scython and Scython is a super set of python so any python you've written pretty much You can use as scython right? But then what happens is scython runs it in a very different way rather than passing it to the kind of the Python interpreter it instead converts it to C Compiles that and then runs that C code Right which means the first time you run it it takes a little longer because it has to go through the the kind of translation and compilation, but then after that it can be quite a bit faster and so I wanted just to quickly show you what that looks like because You are absolutely going to be in a position where scython is going to help you with your work and Most of the people you're working with will have never used it may not even know it exists And so this is like a great superpower to have So to use scython in the notebook you say load ext load extension scython right and So here's a python function Fib one Here is the same as a scython function is exactly the same thing with percent percent scython at the top This actually runs about twice as fast as this right just because it does the compilation Here is the same version again where I've used a special scython extension called C death which defines the C data type of the return value and of each variable right and so Basically, that's the trick that you can use to start making things Run quickly right and at that point now it knows it's not just some Python object called T. In fact, I probably should put one here as well Let's try that so we've got fib 2 we'll call that fib 3 So for fib 3 Yeah, so it's exactly the same as before but we say what the data type of the thing we pass to it was is and then define the data types of each of The variables and so then if we call that Okay, we've now got something that's ten times faster, right so Yeah, it doesn't really take that much extra and it's just it's just Python with a few little bits of markup so that's like it's good to know that that exists because If there's something custom you're trying to do It's actually I find it kind of painful having to go out and you know Go into C and compile it and link it back and all that whereas doing it here is pretty easy Can you pass that just to your right please? Masha? So when you're doing like for the sit on version of it so in the case of an array for an empty array This is a specific C type of yeah, so there's like a lot of specific stuff for integrating scython with numpy And there's a whole page about it Yeah, so we won't worry about going over it But you can read that and you can basically see the basic ideas. There's this C import which basically imports a Certain types of Python library into the kind of the C bit of the code and you can then use it in your scython Yeah, it's It's pretty straightforward Good question. Thank you. All right, so your your mission now is To implement Confidence based on tree variance feature importance partial dependence and tree interpreter for that random first Removing redundant features doesn't use a random first at all So you don't have to worry about that Extrapolation is not an interpretation technique. So you don't have to worry about that. So it's just the other ones So confidence based on tree variance. We've already written that code So I suspect that the exact same code we have in the notebook should continue to work So you can try and make sure it get that working Feature importance is with the variable shuffling technique and once you have that working Partial dependence will just be a couple of lines of code away because rather than you know rather than shuffling Column you're just replacing it with a constant value. That's nearly the same code and then tree interpreter Is going to require you writing some code and thinking about that But once you've written tree interpreter, you're very close if you want to to creating the second approach to Feature importance the one where you add up the importance across all of the rows Which means you would then be very close to doing interaction importance So it turns out that there are actually there's actually a very good library for interaction importance for XGBoost But there doesn't seem to be one for random forest So you could like start by getting it working on our version and if you want to do interaction importance And then you could like get it working on the original SK learn version and that would be a cool Contribution like sometimes writing it against your own implementation is kind of nicer because you can see exactly what's going on All right, so that's that's your job You don't have to rewrite the random forest feel free to if you want to you know practice So if you Get stuck at any point you know ask on the forum right? there is a Whole page here on wiki dot fast AI about how to ask for help so when you ask your Co-workers on slack for help when you ask people in a technical community on github or discourse for help or whatever Asking for help the right way will go a long way towards You know having people want to help you and be able to help you right so So like search for your answer like search for the error you're getting see if somebody's already asked about it You Know how if you tried to fix it already, what do you think's going wrong? What kind of computer are you on? How is it set up? What are the software versions? Exactly, what did you type and exactly what happened right now you could? do that by Taking a screenshot so you know make sure you've got some screenshot software That's really easy to use so if I were to take a screenshot. I just hit a button Select the area copy to clipboard go to my forum Paste it in and there we go right that looks a little bit too big so let's make it a little smaller Right and so now I've got a screenshot people can see exactly what happened better still if there's a few lines of code and error messages to look at and create a a gist a gist is a handy little GitHub thing which basically lets you share code so if I wanted to create a gist of this I Actually have a extension There we are that little extension so if I click on here Give it a name Say make public All right, and that takes my Jupiter notebook shares it publicly I can then grab that URL copy link location Right and paste it into my forum post Right and then when people Click on it Then they'll immediately see My notebook when it renders Okay, so that's a really good way now that particular button is an extension So on Jupiter you need to click envy extensions and click on Just it right while you're there. You should also click on collapsible headings That's this really handy thing. I use that lets me collapse things and open them up If you go to your Jupiter and don't see this envy extensions button Then just Google for Jupiter and the extensions that will show you how to pip install it and and get it set up Right, but those two extensions are super duper handy All right, so Other than that assignment Where we're done with random forests and until the next course when you look at GBMs. We're done with decision tree ensembles And So we're going to move on to neural networks broadly defined and so Neural networks are going to allow us to To go beyond just you know the kind of nearest neighbors approach of random forests You know all the random forest can do is to average data that it's already seen It can't extrapolate it can't it can't calculate right linear regression Can calculate and can extrapolate but only in very limited ways Neural nets give us the best of both worlds We're going to start by applying them to Unstructured data Right so unstructured data means like pixels or the amplitudes of sound waves or words you know data where everything in all the columns are All the same type You know as opposed to like a database table where you've got like a revenue and a cost and a zip code and as state It should be structured data We're going to use it for structured data as well, but we're going to do that a little bit later So unstructured data is a little easier And it's also the area which more people have been applying deep learning to for longer The If you're doing the deep learning course as well You know you'll see that we're going to be approaching kind of the same conclusion from two different directions so the deep learning course is starting out with big complicated convolutional neural networks being solved with you know Sophisticated optimization schemes, and we're going to kind of gradually drill down into like exactly how they work Where else with the machine learning course we're going to be starting out more with like How does stochastic gradient descent actually work? What do we do? What can we do with like one single layer which would allow us to create things like logistic regression when we add? regularization to that how does that give us things like Ridge regression elastic net less oh and then as we add additional layers to that how does that let us? Handle more complex problems, and so we're not going to we're only going to be looking at fully connected layers in this machine learning course and Then I think next semester with your net you're probably going to be looking at some more more Sophisticated approaches and so yeah so this machine learning we're going to be looking much more like what's actually happening with the matrices And how they actually calculate it and the deep learning it's much more like what are the best practices for actually? Solving you know at a world-class level real-world deep learning problems, right so next week we're going to Be looking at like the classic MNIST problem, which is like how do we? recognize digits now If you're interested you can like skip ahead and like try and do this with a random forest And you'll find it's not bad like given that a random forest is basically a type of nearest neighbors, right? It's finding like what are the nearest neighbors in in tree space? Then a random forest could absolutely recognize that this nine those pixels You know are similar to pixels We've seen in these other ones and on average they were nines as well right and so like we can absolutely solve These kinds of problems to an extent using random forests But we end up being rather data limited because every time we put in another decision point You know we're having our data roughly and so there's this just this limitation and the amount of calculation that we can do Where else with neural nets? We're going to be able to use lots and lots and lots of parameters Using these tricks we're going to learn about with regularization And so we're going to be able to do lots of computation, and there's going to be very little limitation on really What we can actually end up calculating as a result? Great good luck with your random forest interpretation, and I will see you next time", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.2600000000000002, "text": " Welcome back. We're going to be talking today about", "tokens": [4027, 646, 13, 492, 434, 516, 281, 312, 1417, 965, 466], "temperature": 0.0, "avg_logprob": -0.20905269665664503, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0031719235703349113}, {"id": 1, "seek": 0, "start": 4.32, "end": 8.28, "text": " Random forests we're going to finish building our own random forest from scratch", "tokens": [37603, 21700, 321, 434, 516, 281, 2413, 2390, 527, 1065, 4974, 6719, 490, 8459], "temperature": 0.0, "avg_logprob": -0.20905269665664503, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0031719235703349113}, {"id": 2, "seek": 0, "start": 10.24, "end": 16.92, "text": " But before we do I wanted to tackle a few things that have come up during the week a few questions that I've had", "tokens": [583, 949, 321, 360, 286, 1415, 281, 14896, 257, 1326, 721, 300, 362, 808, 493, 1830, 264, 1243, 257, 1326, 1651, 300, 286, 600, 632], "temperature": 0.0, "avg_logprob": -0.20905269665664503, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0031719235703349113}, {"id": 3, "seek": 0, "start": 17.64, "end": 22.64, "text": " And I want to start with kind of the position of random forests in general, so we spent", "tokens": [400, 286, 528, 281, 722, 365, 733, 295, 264, 2535, 295, 4974, 21700, 294, 2674, 11, 370, 321, 4418], "temperature": 0.0, "avg_logprob": -0.20905269665664503, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0031719235703349113}, {"id": 4, "seek": 0, "start": 24.28, "end": 27.36, "text": " About half of this course doing random forests", "tokens": [7769, 1922, 295, 341, 1164, 884, 4974, 21700], "temperature": 0.0, "avg_logprob": -0.20905269665664503, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0031719235703349113}, {"id": 5, "seek": 2736, "start": 27.36, "end": 30.08, "text": " And then after today the second half of this course will be", "tokens": [400, 550, 934, 965, 264, 1150, 1922, 295, 341, 1164, 486, 312], "temperature": 0.0, "avg_logprob": -0.2056433227327135, "compression_ratio": 1.601010101010101, "no_speech_prob": 1.8924643882201053e-05}, {"id": 6, "seek": 2736, "start": 31.2, "end": 33.2, "text": " neural networks broadly defined", "tokens": [18161, 9590, 19511, 7642], "temperature": 0.0, "avg_logprob": -0.2056433227327135, "compression_ratio": 1.601010101010101, "no_speech_prob": 1.8924643882201053e-05}, {"id": 7, "seek": 2736, "start": 38.16, "end": 40.86, "text": " This is because these these two", "tokens": [639, 307, 570, 613, 613, 732], "temperature": 0.0, "avg_logprob": -0.2056433227327135, "compression_ratio": 1.601010101010101, "no_speech_prob": 1.8924643882201053e-05}, {"id": 8, "seek": 2736, "start": 41.64, "end": 46.3, "text": " Represent like the T the two key classes of techniques which cover", "tokens": [19945, 411, 264, 314, 264, 732, 2141, 5359, 295, 7512, 597, 2060], "temperature": 0.0, "avg_logprob": -0.2056433227327135, "compression_ratio": 1.601010101010101, "no_speech_prob": 1.8924643882201053e-05}, {"id": 9, "seek": 2736, "start": 46.92, "end": 49.239999999999995, "text": " Nearly everything that you're likely to need to do", "tokens": [38000, 1203, 300, 291, 434, 3700, 281, 643, 281, 360], "temperature": 0.0, "avg_logprob": -0.2056433227327135, "compression_ratio": 1.601010101010101, "no_speech_prob": 1.8924643882201053e-05}, {"id": 10, "seek": 2736, "start": 50.32, "end": 53.92, "text": " random forests belong to the class of techniques of decision tree ensembles", "tokens": [4974, 21700, 5784, 281, 264, 1508, 295, 7512, 295, 3537, 4230, 12567, 2504, 904], "temperature": 0.0, "avg_logprob": -0.2056433227327135, "compression_ratio": 1.601010101010101, "no_speech_prob": 1.8924643882201053e-05}, {"id": 11, "seek": 5392, "start": 53.92, "end": 60.7, "text": " Along with gradient boosting machines being the other key type and some variants like extremely randomized trees", "tokens": [17457, 365, 16235, 43117, 8379, 885, 264, 661, 2141, 2010, 293, 512, 21669, 411, 4664, 38513, 5852], "temperature": 0.0, "avg_logprob": -0.20456590545311404, "compression_ratio": 1.6050420168067228, "no_speech_prob": 4.860398348682793e-06}, {"id": 12, "seek": 5392, "start": 61.96, "end": 63.6, "text": " they", "tokens": [436], "temperature": 0.0, "avg_logprob": -0.20456590545311404, "compression_ratio": 1.6050420168067228, "no_speech_prob": 4.860398348682793e-06}, {"id": 13, "seek": 5392, "start": 63.6, "end": 66.58, "text": " Have the benefit that they're highly interpretable", "tokens": [3560, 264, 5121, 300, 436, 434, 5405, 7302, 712], "temperature": 0.0, "avg_logprob": -0.20456590545311404, "compression_ratio": 1.6050420168067228, "no_speech_prob": 4.860398348682793e-06}, {"id": 14, "seek": 5392, "start": 67.68, "end": 69.0, "text": " scalable", "tokens": [38481], "temperature": 0.0, "avg_logprob": -0.20456590545311404, "compression_ratio": 1.6050420168067228, "no_speech_prob": 4.860398348682793e-06}, {"id": 15, "seek": 5392, "start": 69.0, "end": 71.44, "text": " Flexible work well for most kinds of data", "tokens": [29208, 964, 589, 731, 337, 881, 3685, 295, 1412], "temperature": 0.0, "avg_logprob": -0.20456590545311404, "compression_ratio": 1.6050420168067228, "no_speech_prob": 4.860398348682793e-06}, {"id": 16, "seek": 5392, "start": 72.08, "end": 76.76, "text": " They have the downside that they don't extrapolate at all to like", "tokens": [814, 362, 264, 25060, 300, 436, 500, 380, 48224, 473, 412, 439, 281, 411], "temperature": 0.0, "avg_logprob": -0.20456590545311404, "compression_ratio": 1.6050420168067228, "no_speech_prob": 4.860398348682793e-06}, {"id": 17, "seek": 5392, "start": 77.56, "end": 81.84, "text": " Data that's outside the range that you've seen as we looked at at the end of last week's session", "tokens": [11888, 300, 311, 2380, 264, 3613, 300, 291, 600, 1612, 382, 321, 2956, 412, 412, 264, 917, 295, 1036, 1243, 311, 5481], "temperature": 0.0, "avg_logprob": -0.20456590545311404, "compression_ratio": 1.6050420168067228, "no_speech_prob": 4.860398348682793e-06}, {"id": 18, "seek": 8184, "start": 81.84, "end": 83.84, "text": " but", "tokens": [457], "temperature": 0.0, "avg_logprob": -0.21606515248616537, "compression_ratio": 1.7939698492462313, "no_speech_prob": 3.3931135021703085e-06}, {"id": 19, "seek": 8184, "start": 86.32000000000001, "end": 89.2, "text": " You know they're they're they're a great starting point and so", "tokens": [509, 458, 436, 434, 436, 434, 436, 434, 257, 869, 2891, 935, 293, 370], "temperature": 0.0, "avg_logprob": -0.21606515248616537, "compression_ratio": 1.7939698492462313, "no_speech_prob": 3.3931135021703085e-06}, {"id": 20, "seek": 8184, "start": 91.2, "end": 94.72, "text": " I think you know there's a huge catalog of", "tokens": [286, 519, 291, 458, 456, 311, 257, 2603, 19746, 295], "temperature": 0.0, "avg_logprob": -0.21606515248616537, "compression_ratio": 1.7939698492462313, "no_speech_prob": 3.3931135021703085e-06}, {"id": 21, "seek": 8184, "start": 95.52000000000001, "end": 99.32000000000001, "text": " Machine learning tools out there and so and like a lot of courses and books", "tokens": [22155, 2539, 3873, 484, 456, 293, 370, 293, 411, 257, 688, 295, 7712, 293, 3642], "temperature": 0.0, "avg_logprob": -0.21606515248616537, "compression_ratio": 1.7939698492462313, "no_speech_prob": 3.3931135021703085e-06}, {"id": 22, "seek": 8184, "start": 100.48, "end": 106.84, "text": " Don't attempt to kind of curate that down and say like for these kinds of problems use this for these kinds of problems use that", "tokens": [1468, 380, 5217, 281, 733, 295, 1262, 473, 300, 760, 293, 584, 411, 337, 613, 3685, 295, 2740, 764, 341, 337, 613, 3685, 295, 2740, 764, 300], "temperature": 0.0, "avg_logprob": -0.21606515248616537, "compression_ratio": 1.7939698492462313, "no_speech_prob": 3.3931135021703085e-06}, {"id": 23, "seek": 8184, "start": 107.60000000000001, "end": 109.60000000000001, "text": " Finished you know, but they're rather like", "tokens": [48188, 291, 458, 11, 457, 436, 434, 2831, 411], "temperature": 0.0, "avg_logprob": -0.21606515248616537, "compression_ratio": 1.7939698492462313, "no_speech_prob": 3.3931135021703085e-06}, {"id": 24, "seek": 10960, "start": 109.6, "end": 112.6, "text": " here's a description of a hundred different algorithms and", "tokens": [510, 311, 257, 3855, 295, 257, 3262, 819, 14642, 293], "temperature": 0.0, "avg_logprob": -0.1831139155796596, "compression_ratio": 1.6576923076923078, "no_speech_prob": 2.6425664145790506e-06}, {"id": 25, "seek": 10960, "start": 114.0, "end": 116.0, "text": " You just don't need them", "tokens": [509, 445, 500, 380, 643, 552], "temperature": 0.0, "avg_logprob": -0.1831139155796596, "compression_ratio": 1.6576923076923078, "no_speech_prob": 2.6425664145790506e-06}, {"id": 26, "seek": 10960, "start": 116.0, "end": 121.28, "text": " You know like I don't see why you would ever use in support vector machine today for instance", "tokens": [509, 458, 411, 286, 500, 380, 536, 983, 291, 576, 1562, 764, 294, 1406, 8062, 3479, 965, 337, 5197], "temperature": 0.0, "avg_logprob": -0.1831139155796596, "compression_ratio": 1.6576923076923078, "no_speech_prob": 2.6425664145790506e-06}, {"id": 27, "seek": 10960, "start": 121.56, "end": 125.11999999999999, "text": " Like no no reason at all I could think of doing that", "tokens": [1743, 572, 572, 1778, 412, 439, 286, 727, 519, 295, 884, 300], "temperature": 0.0, "avg_logprob": -0.1831139155796596, "compression_ratio": 1.6576923076923078, "no_speech_prob": 2.6425664145790506e-06}, {"id": 28, "seek": 10960, "start": 125.56, "end": 131.42, "text": " People loved studying them in the 90s because they are like very theoretically elegant and like you can really", "tokens": [3432, 4333, 7601, 552, 294, 264, 4289, 82, 570, 436, 366, 411, 588, 29400, 21117, 293, 411, 291, 393, 534], "temperature": 0.0, "avg_logprob": -0.1831139155796596, "compression_ratio": 1.6576923076923078, "no_speech_prob": 2.6425664145790506e-06}, {"id": 29, "seek": 10960, "start": 131.88, "end": 136.38, "text": " Write a lot of math about support vector machines and people did but you know in practice", "tokens": [23499, 257, 688, 295, 5221, 466, 1406, 8062, 8379, 293, 561, 630, 457, 291, 458, 294, 3124], "temperature": 0.0, "avg_logprob": -0.1831139155796596, "compression_ratio": 1.6576923076923078, "no_speech_prob": 2.6425664145790506e-06}, {"id": 30, "seek": 13638, "start": 136.38, "end": 140.48, "text": " I don't see them as having any place so", "tokens": [286, 500, 380, 536, 552, 382, 1419, 604, 1081, 370], "temperature": 0.0, "avg_logprob": -0.1692579215932115, "compression_ratio": 1.7259786476868328, "no_speech_prob": 6.747952284058556e-06}, {"id": 31, "seek": 13638, "start": 142.92, "end": 148.92, "text": " There's like a lot of techniques that you could include in an exhaustive list of every way that people have open machine learning problems", "tokens": [821, 311, 411, 257, 688, 295, 7512, 300, 291, 727, 4090, 294, 364, 14687, 488, 1329, 295, 633, 636, 300, 561, 362, 1269, 3479, 2539, 2740], "temperature": 0.0, "avg_logprob": -0.1692579215932115, "compression_ratio": 1.7259786476868328, "no_speech_prob": 6.747952284058556e-06}, {"id": 32, "seek": 13638, "start": 150.12, "end": 154.51999999999998, "text": " But I would rather tell you like how to actually solve machine learning problems in practice", "tokens": [583, 286, 576, 2831, 980, 291, 411, 577, 281, 767, 5039, 3479, 2539, 2740, 294, 3124], "temperature": 0.0, "avg_logprob": -0.1692579215932115, "compression_ratio": 1.7259786476868328, "no_speech_prob": 6.747952284058556e-06}, {"id": 33, "seek": 13638, "start": 154.51999999999998, "end": 160.76, "text": " I think they you know with we're about to finish today the first class which is you know one type of decision tree ensembles", "tokens": [286, 519, 436, 291, 458, 365, 321, 434, 466, 281, 2413, 965, 264, 700, 1508, 597, 307, 291, 458, 472, 2010, 295, 3537, 4230, 12567, 2504, 904], "temperature": 0.0, "avg_logprob": -0.1692579215932115, "compression_ratio": 1.7259786476868328, "no_speech_prob": 6.747952284058556e-06}, {"id": 34, "seek": 16076, "start": 160.76, "end": 168.6, "text": " In in part two unit will tell you about the other key type there being gradient boosting and we're about to launch next lesson", "tokens": [682, 294, 644, 732, 4985, 486, 980, 291, 466, 264, 661, 2141, 2010, 456, 885, 16235, 43117, 293, 321, 434, 466, 281, 4025, 958, 6898], "temperature": 0.0, "avg_logprob": -0.25339505166718457, "compression_ratio": 1.5792349726775956, "no_speech_prob": 4.5659126044483855e-06}, {"id": 35, "seek": 16076, "start": 168.6, "end": 173.34, "text": " into neural nets which includes all kinds of glm", "tokens": [666, 18161, 36170, 597, 5974, 439, 3685, 295, 1563, 76], "temperature": 0.0, "avg_logprob": -0.25339505166718457, "compression_ratio": 1.5792349726775956, "no_speech_prob": 4.5659126044483855e-06}, {"id": 36, "seek": 16076, "start": 174.2, "end": 176.51999999999998, "text": " ridge regression elastic net lasso", "tokens": [34651, 24590, 17115, 2533, 2439, 539], "temperature": 0.0, "avg_logprob": -0.25339505166718457, "compression_ratio": 1.5792349726775956, "no_speech_prob": 4.5659126044483855e-06}, {"id": 37, "seek": 16076, "start": 178.2, "end": 181.6, "text": " Logistic regression etc are all variants of neural nets", "tokens": [10824, 3142, 24590, 5183, 366, 439, 21669, 295, 18161, 36170], "temperature": 0.0, "avg_logprob": -0.25339505166718457, "compression_ratio": 1.5792349726775956, "no_speech_prob": 4.5659126044483855e-06}, {"id": 38, "seek": 16076, "start": 184.48, "end": 186.48, "text": " You know interestingly", "tokens": [509, 458, 25873], "temperature": 0.0, "avg_logprob": -0.25339505166718457, "compression_ratio": 1.5792349726775956, "no_speech_prob": 4.5659126044483855e-06}, {"id": 39, "seek": 18648, "start": 186.48, "end": 193.95999999999998, "text": " Leo Breiman who created random forests did so very late in his life and", "tokens": [19344, 7090, 25504, 567, 2942, 4974, 21700, 630, 370, 588, 3469, 294, 702, 993, 293], "temperature": 0.0, "avg_logprob": -0.2500257626385756, "compression_ratio": 1.5196078431372548, "no_speech_prob": 1.6028003528845147e-06}, {"id": 40, "seek": 18648, "start": 194.92, "end": 197.51999999999998, "text": " Unfortunately passed away not many years later", "tokens": [8590, 4678, 1314, 406, 867, 924, 1780], "temperature": 0.0, "avg_logprob": -0.2500257626385756, "compression_ratio": 1.5196078431372548, "no_speech_prob": 1.6028003528845147e-06}, {"id": 41, "seek": 18648, "start": 200.2, "end": 204.79999999999998, "text": " So partly because of that very little has been written about them in the academic literature", "tokens": [407, 17031, 570, 295, 300, 588, 707, 575, 668, 3720, 466, 552, 294, 264, 7778, 10394], "temperature": 0.0, "avg_logprob": -0.2500257626385756, "compression_ratio": 1.5196078431372548, "no_speech_prob": 1.6028003528845147e-06}, {"id": 42, "seek": 18648, "start": 205.56, "end": 210.51999999999998, "text": " Partly because SVM's were just taken over at that point. You know other people didn't look at them", "tokens": [4100, 356, 570, 31910, 44, 311, 645, 445, 2726, 670, 412, 300, 935, 13, 509, 458, 661, 561, 994, 380, 574, 412, 552], "temperature": 0.0, "avg_logprob": -0.2500257626385756, "compression_ratio": 1.5196078431372548, "no_speech_prob": 1.6028003528845147e-06}, {"id": 43, "seek": 21052, "start": 210.52, "end": 220.52, "text": " And also like just because they're like quite hard to grasp at a theoretical level like analyze them theoretically", "tokens": [400, 611, 411, 445, 570, 436, 434, 411, 1596, 1152, 281, 21743, 412, 257, 20864, 1496, 411, 12477, 552, 29400], "temperature": 0.0, "avg_logprob": -0.15091479696878574, "compression_ratio": 1.7741935483870968, "no_speech_prob": 1.7880520317703485e-06}, {"id": 44, "seek": 21052, "start": 220.52, "end": 224.56, "text": " It's quite a hard to write conference papers about them or academic papers about them", "tokens": [467, 311, 1596, 257, 1152, 281, 2464, 7586, 10577, 466, 552, 420, 7778, 10577, 466, 552], "temperature": 0.0, "avg_logprob": -0.15091479696878574, "compression_ratio": 1.7741935483870968, "no_speech_prob": 1.7880520317703485e-06}, {"id": 45, "seek": 21052, "start": 224.56, "end": 226.88, "text": " So there hasn't been that much written about them", "tokens": [407, 456, 6132, 380, 668, 300, 709, 3720, 466, 552], "temperature": 0.0, "avg_logprob": -0.15091479696878574, "compression_ratio": 1.7741935483870968, "no_speech_prob": 1.7880520317703485e-06}, {"id": 46, "seek": 21052, "start": 227.36, "end": 235.36, "text": " But there's been a real resurgence or not resurgence a new wave in recent years of empirical machine learning like what actually works", "tokens": [583, 456, 311, 668, 257, 957, 725, 44607, 420, 406, 725, 44607, 257, 777, 5772, 294, 5162, 924, 295, 31886, 3479, 2539, 411, 437, 767, 1985], "temperature": 0.0, "avg_logprob": -0.15091479696878574, "compression_ratio": 1.7741935483870968, "no_speech_prob": 1.7880520317703485e-06}, {"id": 47, "seek": 23536, "start": 235.36, "end": 241.04000000000002, "text": " Kaggle's been part of that but also just part of it has just been like", "tokens": [48751, 22631, 311, 668, 644, 295, 300, 457, 611, 445, 644, 295, 309, 575, 445, 668, 411], "temperature": 0.0, "avg_logprob": -0.2903128537264737, "compression_ratio": 1.6790697674418604, "no_speech_prob": 5.014670932723675e-06}, {"id": 48, "seek": 23536, "start": 241.60000000000002, "end": 245.44000000000003, "text": " Companies using machine learning to make shitloads of money like Amazon and Google", "tokens": [44031, 1228, 3479, 2539, 281, 652, 4611, 2907, 82, 295, 1460, 411, 6795, 293, 3329], "temperature": 0.0, "avg_logprob": -0.2903128537264737, "compression_ratio": 1.6790697674418604, "no_speech_prob": 5.014670932723675e-06}, {"id": 49, "seek": 23536, "start": 245.92000000000002, "end": 249.76000000000002, "text": " and so nowadays a lot of people are writing about", "tokens": [293, 370, 13434, 257, 688, 295, 561, 366, 3579, 466], "temperature": 0.0, "avg_logprob": -0.2903128537264737, "compression_ratio": 1.6790697674418604, "no_speech_prob": 5.014670932723675e-06}, {"id": 50, "seek": 23536, "start": 250.52, "end": 257.12, "text": " decision tree ensembles and creating better software for decision tree ensembles like light GBM and XGBoost and", "tokens": [3537, 4230, 12567, 2504, 904, 293, 4084, 1101, 4722, 337, 3537, 4230, 12567, 2504, 904, 411, 1442, 460, 18345, 293, 1783, 8769, 78, 555, 293], "temperature": 0.0, "avg_logprob": -0.2903128537264737, "compression_ratio": 1.6790697674418604, "no_speech_prob": 5.014670932723675e-06}, {"id": 51, "seek": 23536, "start": 258.16, "end": 262.16, "text": " Ranger for are and psychic learn and so forth", "tokens": [34222, 337, 366, 293, 35406, 1466, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.2903128537264737, "compression_ratio": 1.6790697674418604, "no_speech_prob": 5.014670932723675e-06}, {"id": 52, "seek": 26216, "start": 262.16, "end": 266.32000000000005, "text": " But a lot of this is being done in industry rather than academia", "tokens": [583, 257, 688, 295, 341, 307, 885, 1096, 294, 3518, 2831, 813, 28937], "temperature": 0.0, "avg_logprob": -0.14411684100547534, "compression_ratio": 1.7428571428571429, "no_speech_prob": 9.368448445457034e-06}, {"id": 53, "seek": 26216, "start": 267.48, "end": 270.8, "text": " But you know it's it's encouraging to see", "tokens": [583, 291, 458, 309, 311, 309, 311, 14580, 281, 536], "temperature": 0.0, "avg_logprob": -0.14411684100547534, "compression_ratio": 1.7428571428571429, "no_speech_prob": 9.368448445457034e-06}, {"id": 54, "seek": 26216, "start": 272.32000000000005, "end": 274.08000000000004, "text": " There's certainly", "tokens": [821, 311, 3297], "temperature": 0.0, "avg_logprob": -0.14411684100547534, "compression_ratio": 1.7428571428571429, "no_speech_prob": 9.368448445457034e-06}, {"id": 55, "seek": 26216, "start": 274.08000000000004, "end": 278.52000000000004, "text": " More work being done in deep learning than in decision tree ensembles", "tokens": [5048, 589, 885, 1096, 294, 2452, 2539, 813, 294, 3537, 4230, 12567, 2504, 904], "temperature": 0.0, "avg_logprob": -0.14411684100547534, "compression_ratio": 1.7428571428571429, "no_speech_prob": 9.368448445457034e-06}, {"id": 56, "seek": 26216, "start": 279.40000000000003, "end": 285.04, "text": " Particularly in in academia, but but there's a lot of progress being made in both", "tokens": [32281, 294, 294, 28937, 11, 457, 457, 456, 311, 257, 688, 295, 4205, 885, 1027, 294, 1293], "temperature": 0.0, "avg_logprob": -0.14411684100547534, "compression_ratio": 1.7428571428571429, "no_speech_prob": 9.368448445457034e-06}, {"id": 57, "seek": 28504, "start": 285.04, "end": 291.68, "text": " You know if you look at like of the packages being used today for decision tree ensembles like", "tokens": [509, 458, 498, 291, 574, 412, 411, 295, 264, 17401, 885, 1143, 965, 337, 3537, 4230, 12567, 2504, 904, 411], "temperature": 0.0, "avg_logprob": -0.16460718172732916, "compression_ratio": 1.6197718631178708, "no_speech_prob": 2.8572926566994283e-06}, {"id": 58, "seek": 28504, "start": 292.40000000000003, "end": 296.8, "text": " All the best ones the top five or six. I don't know that any of them really existed", "tokens": [1057, 264, 1151, 2306, 264, 1192, 1732, 420, 2309, 13, 286, 500, 380, 458, 300, 604, 295, 552, 534, 13135], "temperature": 0.0, "avg_logprob": -0.16460718172732916, "compression_ratio": 1.6197718631178708, "no_speech_prob": 2.8572926566994283e-06}, {"id": 59, "seek": 28504, "start": 297.76000000000005, "end": 304.28000000000003, "text": " Five years ago, you know maybe other than like sk learn or even three years ago, so it's that's that's been good", "tokens": [9436, 924, 2057, 11, 291, 458, 1310, 661, 813, 411, 1110, 1466, 420, 754, 1045, 924, 2057, 11, 370, 309, 311, 300, 311, 300, 311, 668, 665], "temperature": 0.0, "avg_logprob": -0.16460718172732916, "compression_ratio": 1.6197718631178708, "no_speech_prob": 2.8572926566994283e-06}, {"id": 60, "seek": 28504, "start": 305.68, "end": 310.40000000000003, "text": " But I think there's a lot of work still to be done. We talked about for example", "tokens": [583, 286, 519, 456, 311, 257, 688, 295, 589, 920, 281, 312, 1096, 13, 492, 2825, 466, 337, 1365], "temperature": 0.0, "avg_logprob": -0.16460718172732916, "compression_ratio": 1.6197718631178708, "no_speech_prob": 2.8572926566994283e-06}, {"id": 61, "seek": 31040, "start": 310.4, "end": 315.88, "text": " figuring out what interactions are the most important last week and", "tokens": [15213, 484, 437, 13280, 366, 264, 881, 1021, 1036, 1243, 293], "temperature": 0.0, "avg_logprob": -0.12960865186608356, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.8631189959705807e-05}, {"id": 62, "seek": 31040, "start": 316.52, "end": 321.4, "text": " Some of you pointed out in the forums that actually there is such a project already for gradient boosting machines", "tokens": [2188, 295, 291, 10932, 484, 294, 264, 26998, 300, 767, 456, 307, 1270, 257, 1716, 1217, 337, 16235, 43117, 8379], "temperature": 0.0, "avg_logprob": -0.12960865186608356, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.8631189959705807e-05}, {"id": 63, "seek": 31040, "start": 321.84, "end": 325.64, "text": " Which is great, but it doesn't seem that there's anything like that yet for random forests", "tokens": [3013, 307, 869, 11, 457, 309, 1177, 380, 1643, 300, 456, 311, 1340, 411, 300, 1939, 337, 4974, 21700], "temperature": 0.0, "avg_logprob": -0.12960865186608356, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.8631189959705807e-05}, {"id": 64, "seek": 31040, "start": 325.64, "end": 330.73999999999995, "text": " And you know random forests do have a nice benefit over GBMs that they're kind of", "tokens": [400, 291, 458, 4974, 21700, 360, 362, 257, 1481, 5121, 670, 460, 18345, 82, 300, 436, 434, 733, 295], "temperature": 0.0, "avg_logprob": -0.12960865186608356, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.8631189959705807e-05}, {"id": 65, "seek": 31040, "start": 331.67999999999995, "end": 334.47999999999996, "text": " Harder to screw up you know and easier to scale", "tokens": [11817, 260, 281, 5630, 493, 291, 458, 293, 3571, 281, 4373], "temperature": 0.0, "avg_logprob": -0.12960865186608356, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.8631189959705807e-05}, {"id": 66, "seek": 33448, "start": 334.48, "end": 340.52000000000004, "text": " So hopefully that's something that you know this community might help fix", "tokens": [407, 4696, 300, 311, 746, 300, 291, 458, 341, 1768, 1062, 854, 3191], "temperature": 0.0, "avg_logprob": -0.13540907873623614, "compression_ratio": 1.7085714285714286, "no_speech_prob": 9.08038236957509e-06}, {"id": 67, "seek": 33448, "start": 342.84000000000003, "end": 347.22, "text": " Another question I had during the week was about the size of your validation set", "tokens": [3996, 1168, 286, 632, 1830, 264, 1243, 390, 466, 264, 2744, 295, 428, 24071, 992], "temperature": 0.0, "avg_logprob": -0.13540907873623614, "compression_ratio": 1.7085714285714286, "no_speech_prob": 9.08038236957509e-06}, {"id": 68, "seek": 33448, "start": 349.84000000000003, "end": 351.84000000000003, "text": " How big should it be", "tokens": [1012, 955, 820, 309, 312], "temperature": 0.0, "avg_logprob": -0.13540907873623614, "compression_ratio": 1.7085714285714286, "no_speech_prob": 9.08038236957509e-06}, {"id": 69, "seek": 33448, "start": 352.72, "end": 360.0, "text": " So like to answer this question about how big does your validation set need to be you first need to answer the question", "tokens": [407, 411, 281, 1867, 341, 1168, 466, 577, 955, 775, 428, 24071, 992, 643, 281, 312, 291, 700, 643, 281, 1867, 264, 1168], "temperature": 0.0, "avg_logprob": -0.13540907873623614, "compression_ratio": 1.7085714285714286, "no_speech_prob": 9.08038236957509e-06}, {"id": 70, "seek": 33448, "start": 361.52000000000004, "end": 363.52000000000004, "text": " How", "tokens": [1012], "temperature": 0.0, "avg_logprob": -0.13540907873623614, "compression_ratio": 1.7085714285714286, "no_speech_prob": 9.08038236957509e-06}, {"id": 71, "seek": 36352, "start": 363.52, "end": 371.4, "text": " How accurate do I need help how precisely do I need to know the accuracy of this algorithm right so like", "tokens": [1012, 8559, 360, 286, 643, 854, 577, 13402, 360, 286, 643, 281, 458, 264, 14170, 295, 341, 9284, 558, 370, 411], "temperature": 0.0, "avg_logprob": -0.16553110689730258, "compression_ratio": 1.563157894736842, "no_speech_prob": 1.6280450836347882e-06}, {"id": 72, "seek": 36352, "start": 373.76, "end": 378.44, "text": " If the validation set that you have is saying like this is 70% accurate and", "tokens": [759, 264, 24071, 992, 300, 291, 362, 307, 1566, 411, 341, 307, 5285, 4, 8559, 293], "temperature": 0.0, "avg_logprob": -0.16553110689730258, "compression_ratio": 1.563157894736842, "no_speech_prob": 1.6280450836347882e-06}, {"id": 73, "seek": 36352, "start": 379.59999999999997, "end": 387.08, "text": " If somebody said well is it 75% or 65% or 70% and the answer was I don't know anything in that range is close enough", "tokens": [759, 2618, 848, 731, 307, 309, 9562, 4, 420, 11624, 4, 420, 5285, 4, 293, 264, 1867, 390, 286, 500, 380, 458, 1340, 294, 300, 3613, 307, 1998, 1547], "temperature": 0.0, "avg_logprob": -0.16553110689730258, "compression_ratio": 1.563157894736842, "no_speech_prob": 1.6280450836347882e-06}, {"id": 74, "seek": 38708, "start": 387.08, "end": 394.8, "text": " Like that would be one answer where else if it's like is it 70% or 70.01% or 69.99%", "tokens": [1743, 300, 576, 312, 472, 1867, 689, 1646, 498, 309, 311, 411, 307, 309, 5285, 4, 420, 5285, 13, 10607, 4, 420, 28267, 13, 8494, 4], "temperature": 0.0, "avg_logprob": -0.21856131012906732, "compression_ratio": 1.5041666666666667, "no_speech_prob": 1.0511469099583337e-06}, {"id": 75, "seek": 38708, "start": 395.71999999999997, "end": 403.4, "text": " Like then that's something else again, right so you need to kind of start out by saying like how how accurate do I need this?", "tokens": [1743, 550, 300, 311, 746, 1646, 797, 11, 558, 370, 291, 643, 281, 733, 295, 722, 484, 538, 1566, 411, 577, 577, 8559, 360, 286, 643, 341, 30], "temperature": 0.0, "avg_logprob": -0.21856131012906732, "compression_ratio": 1.5041666666666667, "no_speech_prob": 1.0511469099583337e-06}, {"id": 76, "seek": 38708, "start": 404.12, "end": 409.12, "text": " So like for example in the deep learning course we've been looking at dogs versus cats", "tokens": [407, 411, 337, 1365, 294, 264, 2452, 2539, 1164, 321, 600, 668, 1237, 412, 7197, 5717, 11111], "temperature": 0.0, "avg_logprob": -0.21856131012906732, "compression_ratio": 1.5041666666666667, "no_speech_prob": 1.0511469099583337e-06}, {"id": 77, "seek": 38708, "start": 409.71999999999997, "end": 411.71999999999997, "text": " images and", "tokens": [5267, 293], "temperature": 0.0, "avg_logprob": -0.21856131012906732, "compression_ratio": 1.5041666666666667, "no_speech_prob": 1.0511469099583337e-06}, {"id": 78, "seek": 38708, "start": 411.79999999999995, "end": 415.36, "text": " The models that we're looking at had about a 99 point", "tokens": [440, 5245, 300, 321, 434, 1237, 412, 632, 466, 257, 11803, 935], "temperature": 0.0, "avg_logprob": -0.21856131012906732, "compression_ratio": 1.5041666666666667, "no_speech_prob": 1.0511469099583337e-06}, {"id": 79, "seek": 41536, "start": 415.36, "end": 417.24, "text": " for", "tokens": [337], "temperature": 0.0, "avg_logprob": -0.32323858473036027, "compression_ratio": 1.544776119402985, "no_speech_prob": 9.080408744921442e-06}, {"id": 80, "seek": 41536, "start": 417.24, "end": 423.24, "text": " 99.5 percent accuracy on the validation set okay, and our validation set size", "tokens": [11803, 13, 20, 3043, 14170, 322, 264, 24071, 992, 1392, 11, 293, 527, 24071, 992, 2744], "temperature": 0.0, "avg_logprob": -0.32323858473036027, "compression_ratio": 1.544776119402985, "no_speech_prob": 9.080408744921442e-06}, {"id": 81, "seek": 41536, "start": 424.76, "end": 426.76, "text": " was", "tokens": [390], "temperature": 0.0, "avg_logprob": -0.32323858473036027, "compression_ratio": 1.544776119402985, "no_speech_prob": 9.080408744921442e-06}, {"id": 82, "seek": 41536, "start": 426.96000000000004, "end": 431.6, "text": " 2000 okay in fact let's do this in Excel that'll be a bit easier", "tokens": [8132, 1392, 294, 1186, 718, 311, 360, 341, 294, 19060, 300, 603, 312, 257, 857, 3571], "temperature": 0.0, "avg_logprob": -0.32323858473036027, "compression_ratio": 1.544776119402985, "no_speech_prob": 9.080408744921442e-06}, {"id": 83, "seek": 41536, "start": 434.76, "end": 436.76, "text": " So our validation set", "tokens": [407, 527, 24071, 992], "temperature": 0.0, "avg_logprob": -0.32323858473036027, "compression_ratio": 1.544776119402985, "no_speech_prob": 9.080408744921442e-06}, {"id": 84, "seek": 41536, "start": 437.8, "end": 439.6, "text": " Size was", "tokens": [35818, 390], "temperature": 0.0, "avg_logprob": -0.32323858473036027, "compression_ratio": 1.544776119402985, "no_speech_prob": 9.080408744921442e-06}, {"id": 85, "seek": 41536, "start": 439.6, "end": 441.32, "text": " 2000 and", "tokens": [8132, 293], "temperature": 0.0, "avg_logprob": -0.32323858473036027, "compression_ratio": 1.544776119402985, "no_speech_prob": 9.080408744921442e-06}, {"id": 86, "seek": 41536, "start": 441.32, "end": 443.32, "text": " our accuracy was", "tokens": [527, 14170, 390], "temperature": 0.0, "avg_logprob": -0.32323858473036027, "compression_ratio": 1.544776119402985, "no_speech_prob": 9.080408744921442e-06}, {"id": 87, "seek": 44332, "start": 443.32, "end": 450.08, "text": " 99 point four percent right so the number of incorrect is", "tokens": [11803, 935, 1451, 3043, 558, 370, 264, 1230, 295, 18424, 307], "temperature": 0.0, "avg_logprob": -0.35789535522460936, "compression_ratio": 1.3909774436090225, "no_speech_prob": 5.626392862723151e-07}, {"id": 88, "seek": 44332, "start": 452.0, "end": 454.0, "text": " Something around", "tokens": [6595, 926], "temperature": 0.0, "avg_logprob": -0.35789535522460936, "compression_ratio": 1.3909774436090225, "no_speech_prob": 5.626392862723151e-07}, {"id": 89, "seek": 44332, "start": 454.71999999999997, "end": 460.84, "text": " One minus accuracy times and so we were getting about 12 wrong", "tokens": [1485, 3175, 14170, 1413, 293, 370, 321, 645, 1242, 466, 2272, 2085], "temperature": 0.0, "avg_logprob": -0.35789535522460936, "compression_ratio": 1.3909774436090225, "no_speech_prob": 5.626392862723151e-07}, {"id": 90, "seek": 44332, "start": 462.0, "end": 464.0, "text": " right and", "tokens": [558, 293], "temperature": 0.0, "avg_logprob": -0.35789535522460936, "compression_ratio": 1.3909774436090225, "no_speech_prob": 5.626392862723151e-07}, {"id": 91, "seek": 44332, "start": 464.96, "end": 466.96, "text": " The number of cats we had", "tokens": [440, 1230, 295, 11111, 321, 632], "temperature": 0.0, "avg_logprob": -0.35789535522460936, "compression_ratio": 1.3909774436090225, "no_speech_prob": 5.626392862723151e-07}, {"id": 92, "seek": 44332, "start": 468.24, "end": 470.24, "text": " is half and", "tokens": [307, 1922, 293], "temperature": 0.0, "avg_logprob": -0.35789535522460936, "compression_ratio": 1.3909774436090225, "no_speech_prob": 5.626392862723151e-07}, {"id": 93, "seek": 47024, "start": 470.24, "end": 474.92, "text": " So the number of wrong cats is about", "tokens": [407, 264, 1230, 295, 2085, 11111, 307, 466], "temperature": 0.0, "avg_logprob": -0.2334099073667784, "compression_ratio": 1.4628571428571429, "no_speech_prob": 1.1189401902811369e-06}, {"id": 94, "seek": 47024, "start": 477.68, "end": 479.2, "text": " Six", "tokens": [11678], "temperature": 0.0, "avg_logprob": -0.2334099073667784, "compression_ratio": 1.4628571428571429, "no_speech_prob": 1.1189401902811369e-06}, {"id": 95, "seek": 47024, "start": 479.2, "end": 486.56, "text": " Okay, so then like we we run a new model and we find instead that the accuracy", "tokens": [1033, 11, 370, 550, 411, 321, 321, 1190, 257, 777, 2316, 293, 321, 915, 2602, 300, 264, 14170], "temperature": 0.0, "avg_logprob": -0.2334099073667784, "compression_ratio": 1.4628571428571429, "no_speech_prob": 1.1189401902811369e-06}, {"id": 96, "seek": 47024, "start": 487.24, "end": 489.24, "text": " has gone to", "tokens": [575, 2780, 281], "temperature": 0.0, "avg_logprob": -0.2334099073667784, "compression_ratio": 1.4628571428571429, "no_speech_prob": 1.1189401902811369e-06}, {"id": 97, "seek": 47024, "start": 489.88, "end": 491.88, "text": " 99.2 percent", "tokens": [11803, 13, 17, 3043], "temperature": 0.0, "avg_logprob": -0.2334099073667784, "compression_ratio": 1.4628571428571429, "no_speech_prob": 1.1189401902811369e-06}, {"id": 98, "seek": 49188, "start": 491.88, "end": 501.08, "text": " Right and then it's like okay. Is this less good at finding cats. There's like well it got two more cats wrong. So it's like probably not", "tokens": [1779, 293, 550, 309, 311, 411, 1392, 13, 1119, 341, 1570, 665, 412, 5006, 11111, 13, 821, 311, 411, 731, 309, 658, 732, 544, 11111, 2085, 13, 407, 309, 311, 411, 1391, 406], "temperature": 0.0, "avg_logprob": -0.19095227831885928, "compression_ratio": 1.6203208556149733, "no_speech_prob": 3.0415881155931856e-06}, {"id": 99, "seek": 49188, "start": 502.04, "end": 504.04, "text": " right, so", "tokens": [558, 11, 370], "temperature": 0.0, "avg_logprob": -0.19095227831885928, "compression_ratio": 1.6203208556149733, "no_speech_prob": 3.0415881155931856e-06}, {"id": 100, "seek": 49188, "start": 504.4, "end": 509.48, "text": " But then it's like well does this matter there's 99.4 versus 99.2", "tokens": [583, 550, 309, 311, 411, 731, 775, 341, 1871, 456, 311, 11803, 13, 19, 5717, 11803, 13, 17], "temperature": 0.0, "avg_logprob": -0.19095227831885928, "compression_ratio": 1.6203208556149733, "no_speech_prob": 3.0415881155931856e-06}, {"id": 101, "seek": 49188, "start": 510.24, "end": 515.36, "text": " Matter and if this was like it wasn't about cats and dogs, but it was about finding fraud", "tokens": [20285, 293, 498, 341, 390, 411, 309, 2067, 380, 466, 11111, 293, 7197, 11, 457, 309, 390, 466, 5006, 14560], "temperature": 0.0, "avg_logprob": -0.19095227831885928, "compression_ratio": 1.6203208556149733, "no_speech_prob": 3.0415881155931856e-06}, {"id": 102, "seek": 51536, "start": 515.36, "end": 521.44, "text": " right then the difference between a point six percent error rate and a point eight percent error rate is like", "tokens": [558, 550, 264, 2649, 1296, 257, 935, 2309, 3043, 6713, 3314, 293, 257, 935, 3180, 3043, 6713, 3314, 307, 411], "temperature": 0.0, "avg_logprob": -0.17350509931456368, "compression_ratio": 1.837837837837838, "no_speech_prob": 2.48247215495212e-06}, {"id": 103, "seek": 51536, "start": 522.04, "end": 524.04, "text": " 25% of your cost of fraud", "tokens": [3552, 4, 295, 428, 2063, 295, 14560], "temperature": 0.0, "avg_logprob": -0.17350509931456368, "compression_ratio": 1.837837837837838, "no_speech_prob": 2.48247215495212e-06}, {"id": 104, "seek": 51536, "start": 524.28, "end": 526.28, "text": " So like that can be huge", "tokens": [407, 411, 300, 393, 312, 2603], "temperature": 0.0, "avg_logprob": -0.17350509931456368, "compression_ratio": 1.837837837837838, "no_speech_prob": 2.48247215495212e-06}, {"id": 105, "seek": 51536, "start": 527.36, "end": 532.6800000000001, "text": " like it was really interesting like when image net came out earlier this year the new competition results came out and", "tokens": [411, 309, 390, 534, 1880, 411, 562, 3256, 2533, 1361, 484, 3071, 341, 1064, 264, 777, 6211, 3542, 1361, 484, 293], "temperature": 0.0, "avg_logprob": -0.17350509931456368, "compression_ratio": 1.837837837837838, "no_speech_prob": 2.48247215495212e-06}, {"id": 106, "seek": 51536, "start": 533.48, "end": 536.36, "text": " The accuracy had gone down from three percent", "tokens": [440, 14170, 632, 2780, 760, 490, 1045, 3043], "temperature": 0.0, "avg_logprob": -0.17350509931456368, "compression_ratio": 1.837837837837838, "no_speech_prob": 2.48247215495212e-06}, {"id": 107, "seek": 51536, "start": 537.24, "end": 539.88, "text": " So the error went down from three percent to two percent", "tokens": [407, 264, 6713, 1437, 760, 490, 1045, 3043, 281, 732, 3043], "temperature": 0.0, "avg_logprob": -0.17350509931456368, "compression_ratio": 1.837837837837838, "no_speech_prob": 2.48247215495212e-06}, {"id": 108, "seek": 51536, "start": 539.88, "end": 544.2, "text": " and I saw a lot of people on the internet like famous machine learning researchers being like", "tokens": [293, 286, 1866, 257, 688, 295, 561, 322, 264, 4705, 411, 4618, 3479, 2539, 10309, 885, 411], "temperature": 0.0, "avg_logprob": -0.17350509931456368, "compression_ratio": 1.837837837837838, "no_speech_prob": 2.48247215495212e-06}, {"id": 109, "seek": 54420, "start": 544.2, "end": 552.12, "text": " Yeah, some Chinese guys got it better from like 97 percent to 198 percent is like statistically not even significant", "tokens": [865, 11, 512, 4649, 1074, 658, 309, 1101, 490, 411, 23399, 3043, 281, 6375, 3043, 307, 411, 36478, 406, 754, 4776], "temperature": 0.0, "avg_logprob": -0.2260077240270212, "compression_ratio": 1.641304347826087, "no_speech_prob": 8.013431397557724e-06}, {"id": 110, "seek": 54420, "start": 552.12, "end": 555.88, "text": " Who cares kind of a thing? But actually I thought like", "tokens": [2102, 12310, 733, 295, 257, 551, 30, 583, 767, 286, 1194, 411], "temperature": 0.0, "avg_logprob": -0.2260077240270212, "compression_ratio": 1.641304347826087, "no_speech_prob": 8.013431397557724e-06}, {"id": 111, "seek": 54420, "start": 556.5600000000001, "end": 564.2, "text": " Holy crap this Chinese team just blew away the state-of-the-art and image recognition like the old one was 50% less accurate", "tokens": [6295, 12426, 341, 4649, 1469, 445, 19075, 1314, 264, 1785, 12, 2670, 12, 3322, 12, 446, 293, 3256, 11150, 411, 264, 1331, 472, 390, 2625, 4, 1570, 8559], "temperature": 0.0, "avg_logprob": -0.2260077240270212, "compression_ratio": 1.641304347826087, "no_speech_prob": 8.013431397557724e-06}, {"id": 112, "seek": 54420, "start": 564.6, "end": 568.36, "text": " Than the new one like that's that's actually the right way to think about it, isn't it?", "tokens": [18289, 264, 777, 472, 411, 300, 311, 300, 311, 767, 264, 558, 636, 281, 519, 466, 309, 11, 1943, 380, 309, 30], "temperature": 0.0, "avg_logprob": -0.2260077240270212, "compression_ratio": 1.641304347826087, "no_speech_prob": 8.013431397557724e-06}, {"id": 113, "seek": 54420, "start": 568.36, "end": 572.0400000000001, "text": " because it's like you know we were trying to recognize you know like", "tokens": [570, 309, 311, 411, 291, 458, 321, 645, 1382, 281, 5521, 291, 458, 411], "temperature": 0.0, "avg_logprob": -0.2260077240270212, "compression_ratio": 1.641304347826087, "no_speech_prob": 8.013431397557724e-06}, {"id": 114, "seek": 57204, "start": 572.04, "end": 576.0, "text": " which tomatoes were ripe and which ones weren't and", "tokens": [597, 15135, 645, 31421, 293, 597, 2306, 4999, 380, 293], "temperature": 0.0, "avg_logprob": -0.2014152880796452, "compression_ratio": 1.7510204081632652, "no_speech_prob": 9.972813131753355e-06}, {"id": 115, "seek": 57204, "start": 576.5999999999999, "end": 582.4, "text": " Like our new approach, you know the old approach like 50% of the time more", "tokens": [1743, 527, 777, 3109, 11, 291, 458, 264, 1331, 3109, 411, 2625, 4, 295, 264, 565, 544], "temperature": 0.0, "avg_logprob": -0.2014152880796452, "compression_ratio": 1.7510204081632652, "no_speech_prob": 9.972813131753355e-06}, {"id": 116, "seek": 57204, "start": 583.04, "end": 586.3199999999999, "text": " was like letting in the unripe tomatoes or", "tokens": [390, 411, 8295, 294, 264, 517, 470, 494, 15135, 420], "temperature": 0.0, "avg_logprob": -0.2014152880796452, "compression_ratio": 1.7510204081632652, "no_speech_prob": 9.972813131753355e-06}, {"id": 117, "seek": 57204, "start": 587.04, "end": 593.04, "text": " You know 50% more of the time we were like accepting fraudulent customers like that's a really big difference", "tokens": [509, 458, 2625, 4, 544, 295, 264, 565, 321, 645, 411, 17391, 14560, 23405, 4581, 411, 300, 311, 257, 534, 955, 2649], "temperature": 0.0, "avg_logprob": -0.2014152880796452, "compression_ratio": 1.7510204081632652, "no_speech_prob": 9.972813131753355e-06}, {"id": 118, "seek": 59304, "start": 593.04, "end": 601.4, "text": " So just because like this particular validation set we can't really see six versus eight doesn't mean the point two percent different isn't", "tokens": [407, 445, 570, 411, 341, 1729, 24071, 992, 321, 393, 380, 534, 536, 2309, 5717, 3180, 1177, 380, 914, 264, 935, 732, 3043, 819, 1943, 380], "temperature": 0.0, "avg_logprob": -0.1714544925060901, "compression_ratio": 1.6848249027237354, "no_speech_prob": 4.495157099881908e-06}, {"id": 119, "seek": 59304, "start": 601.52, "end": 608.9599999999999, "text": " Important it could be so my kind of rule of thumb is that this like this number of like how many?", "tokens": [42908, 309, 727, 312, 370, 452, 733, 295, 4978, 295, 9298, 307, 300, 341, 411, 341, 1230, 295, 411, 577, 867, 30], "temperature": 0.0, "avg_logprob": -0.1714544925060901, "compression_ratio": 1.6848249027237354, "no_speech_prob": 4.495157099881908e-06}, {"id": 120, "seek": 59304, "start": 610.04, "end": 615.02, "text": " Observations you actually looking at I want that generally to be somewhere higher than 22", "tokens": [42547, 763, 291, 767, 1237, 412, 286, 528, 300, 5101, 281, 312, 4079, 2946, 813, 5853], "temperature": 0.0, "avg_logprob": -0.1714544925060901, "compression_ratio": 1.6848249027237354, "no_speech_prob": 4.495157099881908e-06}, {"id": 121, "seek": 61502, "start": 615.02, "end": 622.66, "text": " Why 22 because 22 is the magic number where the t distribution roughly turns into the normal distribution?", "tokens": [1545, 5853, 570, 5853, 307, 264, 5585, 1230, 689, 264, 256, 7316, 9810, 4523, 666, 264, 2710, 7316, 30], "temperature": 0.0, "avg_logprob": -0.19972897559097133, "compression_ratio": 1.7890295358649788, "no_speech_prob": 1.9333513137098635e-06}, {"id": 122, "seek": 61502, "start": 622.66, "end": 628.78, "text": " All right, so as you may have learned the t distribution is is the normal distribution for small", "tokens": [1057, 558, 11, 370, 382, 291, 815, 362, 3264, 264, 256, 7316, 307, 307, 264, 2710, 7316, 337, 1359], "temperature": 0.0, "avg_logprob": -0.19972897559097133, "compression_ratio": 1.7890295358649788, "no_speech_prob": 1.9333513137098635e-06}, {"id": 123, "seek": 61502, "start": 629.54, "end": 636.46, "text": " Data sets right and so in other words once we have 22 of something or more it kind of starts to behave", "tokens": [11888, 6352, 558, 293, 370, 294, 661, 2283, 1564, 321, 362, 5853, 295, 746, 420, 544, 309, 733, 295, 3719, 281, 15158], "temperature": 0.0, "avg_logprob": -0.19972897559097133, "compression_ratio": 1.7890295358649788, "no_speech_prob": 1.9333513137098635e-06}, {"id": 124, "seek": 61502, "start": 637.5, "end": 639.06, "text": " kind of", "tokens": [733, 295], "temperature": 0.0, "avg_logprob": -0.19972897559097133, "compression_ratio": 1.7890295358649788, "no_speech_prob": 1.9333513137098635e-06}, {"id": 125, "seek": 61502, "start": 639.06, "end": 644.26, "text": " Normally in both sense of the words like it's kind of more stable and you can kind of understand it better so", "tokens": [17424, 294, 1293, 2020, 295, 264, 2283, 411, 309, 311, 733, 295, 544, 8351, 293, 291, 393, 733, 295, 1223, 309, 1101, 370], "temperature": 0.0, "avg_logprob": -0.19972897559097133, "compression_ratio": 1.7890295358649788, "no_speech_prob": 1.9333513137098635e-06}, {"id": 126, "seek": 64426, "start": 644.26, "end": 649.1, "text": " That's my magic number when somebody says do I have enough of something?", "tokens": [663, 311, 452, 5585, 1230, 562, 2618, 1619, 360, 286, 362, 1547, 295, 746, 30], "temperature": 0.0, "avg_logprob": -0.148604063861138, "compression_ratio": 1.7153846153846153, "no_speech_prob": 1.6280464478768408e-06}, {"id": 127, "seek": 64426, "start": 649.1, "end": 653.58, "text": " I kind of start out by saying like do you have 22 observations of the thing of interest?", "tokens": [286, 733, 295, 722, 484, 538, 1566, 411, 360, 291, 362, 5853, 18163, 295, 264, 551, 295, 1179, 30], "temperature": 0.0, "avg_logprob": -0.148604063861138, "compression_ratio": 1.7153846153846153, "no_speech_prob": 1.6280464478768408e-06}, {"id": 128, "seek": 64426, "start": 654.26, "end": 656.26, "text": " so if you were looking at like", "tokens": [370, 498, 291, 645, 1237, 412, 411], "temperature": 0.0, "avg_logprob": -0.148604063861138, "compression_ratio": 1.7153846153846153, "no_speech_prob": 1.6280464478768408e-06}, {"id": 129, "seek": 64426, "start": 656.9, "end": 664.78, "text": " Lung cancer, you know and you had a data set that had like a thousand people without lung cancer and 20 people with lung", "tokens": [441, 1063, 5592, 11, 291, 458, 293, 291, 632, 257, 1412, 992, 300, 632, 411, 257, 4714, 561, 1553, 16730, 5592, 293, 945, 561, 365, 16730], "temperature": 0.0, "avg_logprob": -0.148604063861138, "compression_ratio": 1.7153846153846153, "no_speech_prob": 1.6280464478768408e-06}, {"id": 130, "seek": 64426, "start": 664.78, "end": 671.02, "text": " Cancer I'd be like I very much doubt we're gonna make much progress, you know, because we haven't even got 20 of the thing", "tokens": [26127, 286, 1116, 312, 411, 286, 588, 709, 6385, 321, 434, 799, 652, 709, 4205, 11, 291, 458, 11, 570, 321, 2378, 380, 754, 658, 945, 295, 264, 551], "temperature": 0.0, "avg_logprob": -0.148604063861138, "compression_ratio": 1.7153846153846153, "no_speech_prob": 1.6280464478768408e-06}, {"id": 131, "seek": 64426, "start": 671.02, "end": 671.98, "text": " You want?", "tokens": [509, 528, 30], "temperature": 0.0, "avg_logprob": -0.148604063861138, "compression_ratio": 1.7153846153846153, "no_speech_prob": 1.6280464478768408e-06}, {"id": 132, "seek": 67198, "start": 671.98, "end": 677.98, "text": " So ditto with a validation set if you don't have 20 of the thing you want that it's very unlikely to be useful or if like", "tokens": [407, 274, 34924, 365, 257, 24071, 992, 498, 291, 500, 380, 362, 945, 295, 264, 551, 291, 528, 300, 309, 311, 588, 17518, 281, 312, 4420, 420, 498, 411], "temperature": 0.0, "avg_logprob": -0.14949906667073568, "compression_ratio": 1.7490196078431373, "no_speech_prob": 2.190772192989243e-06}, {"id": 133, "seek": 67198, "start": 677.98, "end": 684.4, "text": " The at the level of accuracy we need it's not plus or minus 20. It's just it's that that's the point where I'm thinking like", "tokens": [440, 412, 264, 1496, 295, 14170, 321, 643, 309, 311, 406, 1804, 420, 3175, 945, 13, 467, 311, 445, 309, 311, 300, 300, 311, 264, 935, 689, 286, 478, 1953, 411], "temperature": 0.0, "avg_logprob": -0.14949906667073568, "compression_ratio": 1.7490196078431373, "no_speech_prob": 2.190772192989243e-06}, {"id": 134, "seek": 67198, "start": 684.94, "end": 686.62, "text": " Be a bit careful", "tokens": [879, 257, 857, 5026], "temperature": 0.0, "avg_logprob": -0.14949906667073568, "compression_ratio": 1.7490196078431373, "no_speech_prob": 2.190772192989243e-06}, {"id": 135, "seek": 67198, "start": 686.62, "end": 691.58, "text": " so just to be clear you want 22 to be the number of", "tokens": [370, 445, 281, 312, 1850, 291, 528, 5853, 281, 312, 264, 1230, 295], "temperature": 0.0, "avg_logprob": -0.14949906667073568, "compression_ratio": 1.7490196078431373, "no_speech_prob": 2.190772192989243e-06}, {"id": 136, "seek": 67198, "start": 692.7, "end": 696.62, "text": " samples in each set like in the validation the test and the train or", "tokens": [10938, 294, 1184, 992, 411, 294, 264, 24071, 264, 1500, 293, 264, 3847, 420], "temperature": 0.0, "avg_logprob": -0.14949906667073568, "compression_ratio": 1.7490196078431373, "no_speech_prob": 2.190772192989243e-06}, {"id": 137, "seek": 69662, "start": 696.62, "end": 701.86, "text": " so what I'm saying is like if there's if there's less than 22 of", "tokens": [370, 437, 286, 478, 1566, 307, 411, 498, 456, 311, 498, 456, 311, 1570, 813, 5853, 295], "temperature": 0.0, "avg_logprob": -0.19998436831356434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 3.726616341737099e-06}, {"id": 138, "seek": 69662, "start": 702.46, "end": 710.66, "text": " A class in any of the sets then it's it's gonna get it's getting pretty unstable at that point, right?", "tokens": [316, 1508, 294, 604, 295, 264, 6352, 550, 309, 311, 309, 311, 799, 483, 309, 311, 1242, 1238, 23742, 412, 300, 935, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19998436831356434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 3.726616341737099e-06}, {"id": 139, "seek": 69662, "start": 711.34, "end": 714.34, "text": " And so like that's just like the first rule of thumb", "tokens": [400, 370, 411, 300, 311, 445, 411, 264, 700, 4978, 295, 9298], "temperature": 0.0, "avg_logprob": -0.19998436831356434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 3.726616341737099e-06}, {"id": 140, "seek": 69662, "start": 715.46, "end": 720.66, "text": " but then what I would actually do is like start practicing what we learned about the", "tokens": [457, 550, 437, 286, 576, 767, 360, 307, 411, 722, 11350, 437, 321, 3264, 466, 264], "temperature": 0.0, "avg_logprob": -0.19998436831356434, "compression_ratio": 1.7142857142857142, "no_speech_prob": 3.726616341737099e-06}, {"id": 141, "seek": 72066, "start": 720.66, "end": 725.86, "text": " binomial distribution or actually generally distribution, so", "tokens": [5171, 47429, 7316, 420, 767, 5101, 7316, 11, 370], "temperature": 0.0, "avg_logprob": -0.32892234370393575, "compression_ratio": 1.5037037037037038, "no_speech_prob": 8.939613508118782e-06}, {"id": 142, "seek": 72066, "start": 727.3, "end": 729.3, "text": " What's the?", "tokens": [708, 311, 264, 30], "temperature": 0.0, "avg_logprob": -0.32892234370393575, "compression_ratio": 1.5037037037037038, "no_speech_prob": 8.939613508118782e-06}, {"id": 143, "seek": 72066, "start": 730.42, "end": 737.74, "text": " What is the mean of the binomial distribution of n samples and probability P?", "tokens": [708, 307, 264, 914, 295, 264, 5171, 47429, 7316, 295, 297, 10938, 293, 8482, 430, 30], "temperature": 0.0, "avg_logprob": -0.32892234370393575, "compression_ratio": 1.5037037037037038, "no_speech_prob": 8.939613508118782e-06}, {"id": 144, "seek": 72066, "start": 739.5799999999999, "end": 743.7199999999999, "text": " And times P. Okay. Thank you and times P is our mean", "tokens": [400, 1413, 430, 13, 1033, 13, 1044, 291, 293, 1413, 430, 307, 527, 914], "temperature": 0.0, "avg_logprob": -0.32892234370393575, "compression_ratio": 1.5037037037037038, "no_speech_prob": 8.939613508118782e-06}, {"id": 145, "seek": 74372, "start": 743.72, "end": 751.6800000000001, "text": " Right, so if you've got a 50% chance of getting ahead and you toss it a hundred times on average you get 50 heads", "tokens": [1779, 11, 370, 498, 291, 600, 658, 257, 2625, 4, 2931, 295, 1242, 2286, 293, 291, 14432, 309, 257, 3262, 1413, 322, 4274, 291, 483, 2625, 8050], "temperature": 0.0, "avg_logprob": -0.23380096538646802, "compression_ratio": 1.417989417989418, "no_speech_prob": 2.726452748902375e-06}, {"id": 146, "seek": 74372, "start": 752.08, "end": 754.6800000000001, "text": " Okay, and then what's the standard deviation?", "tokens": [1033, 11, 293, 550, 437, 311, 264, 3832, 25163, 30], "temperature": 0.0, "avg_logprob": -0.23380096538646802, "compression_ratio": 1.417989417989418, "no_speech_prob": 2.726452748902375e-06}, {"id": 147, "seek": 74372, "start": 757.64, "end": 759.64, "text": " And P 1 minus P", "tokens": [400, 430, 502, 3175, 430], "temperature": 0.0, "avg_logprob": -0.23380096538646802, "compression_ratio": 1.417989417989418, "no_speech_prob": 2.726452748902375e-06}, {"id": 148, "seek": 74372, "start": 762.9200000000001, "end": 765.28, "text": " Okay, so these are like", "tokens": [1033, 11, 370, 613, 366, 411], "temperature": 0.0, "avg_logprob": -0.23380096538646802, "compression_ratio": 1.417989417989418, "no_speech_prob": 2.726452748902375e-06}, {"id": 149, "seek": 74372, "start": 765.84, "end": 768.72, "text": " Two numbers. Well the first number you don't really have to remember", "tokens": [4453, 3547, 13, 1042, 264, 700, 1230, 291, 500, 380, 534, 362, 281, 1604], "temperature": 0.0, "avg_logprob": -0.23380096538646802, "compression_ratio": 1.417989417989418, "no_speech_prob": 2.726452748902375e-06}, {"id": 150, "seek": 76872, "start": 768.72, "end": 773.5600000000001, "text": " It's intuitively obvious. The second one is one that try to remember forever more", "tokens": [467, 311, 46506, 6322, 13, 440, 1150, 472, 307, 472, 300, 853, 281, 1604, 5680, 544], "temperature": 0.0, "avg_logprob": -0.16031866807204026, "compression_ratio": 1.6546762589928057, "no_speech_prob": 5.682416485797148e-06}, {"id": 151, "seek": 76872, "start": 774.24, "end": 779.08, "text": " Because not only does it come up all the time the people that you work with will all have forgotten it", "tokens": [1436, 406, 787, 775, 309, 808, 493, 439, 264, 565, 264, 561, 300, 291, 589, 365, 486, 439, 362, 11832, 309], "temperature": 0.0, "avg_logprob": -0.16031866807204026, "compression_ratio": 1.6546762589928057, "no_speech_prob": 5.682416485797148e-06}, {"id": 152, "seek": 76872, "start": 779.08, "end": 783.9200000000001, "text": " So you'll be like the one person in the conversation who could immediately go we don't have to run this a hundred times", "tokens": [407, 291, 603, 312, 411, 264, 472, 954, 294, 264, 3761, 567, 727, 4258, 352, 321, 500, 380, 362, 281, 1190, 341, 257, 3262, 1413], "temperature": 0.0, "avg_logprob": -0.16031866807204026, "compression_ratio": 1.6546762589928057, "no_speech_prob": 5.682416485797148e-06}, {"id": 153, "seek": 76872, "start": 783.9200000000001, "end": 787.32, "text": " I can tell you straight away. It's binomial. It's going to be NP Q", "tokens": [286, 393, 980, 291, 2997, 1314, 13, 467, 311, 5171, 47429, 13, 467, 311, 516, 281, 312, 38611, 1249], "temperature": 0.0, "avg_logprob": -0.16031866807204026, "compression_ratio": 1.6546762589928057, "no_speech_prob": 5.682416485797148e-06}, {"id": 154, "seek": 76872, "start": 788.08, "end": 790.08, "text": " NP 1 minus P", "tokens": [38611, 502, 3175, 430], "temperature": 0.0, "avg_logprob": -0.16031866807204026, "compression_ratio": 1.6546762589928057, "no_speech_prob": 5.682416485797148e-06}, {"id": 155, "seek": 76872, "start": 791.1600000000001, "end": 793.1600000000001, "text": " Then there's the standard error", "tokens": [1396, 456, 311, 264, 3832, 6713], "temperature": 0.0, "avg_logprob": -0.16031866807204026, "compression_ratio": 1.6546762589928057, "no_speech_prob": 5.682416485797148e-06}, {"id": 156, "seek": 76872, "start": 793.28, "end": 797.12, "text": " the standard error is if you run a bunch of", "tokens": [264, 3832, 6713, 307, 498, 291, 1190, 257, 3840, 295], "temperature": 0.0, "avg_logprob": -0.16031866807204026, "compression_ratio": 1.6546762589928057, "no_speech_prob": 5.682416485797148e-06}, {"id": 157, "seek": 79712, "start": 797.12, "end": 800.5600000000001, "text": " trials each time getting a mean", "tokens": [12450, 1184, 565, 1242, 257, 914], "temperature": 0.0, "avg_logprob": -0.21603322347005208, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.3320678792515537e-06}, {"id": 158, "seek": 79712, "start": 801.08, "end": 804.28, "text": " What is the standard deviation of the mean? I?", "tokens": [708, 307, 264, 3832, 25163, 295, 264, 914, 30, 286, 30], "temperature": 0.0, "avg_logprob": -0.21603322347005208, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.3320678792515537e-06}, {"id": 159, "seek": 79712, "start": 805.64, "end": 807.88, "text": " Don't think you guys have covered this yet. Is that right?", "tokens": [1468, 380, 519, 291, 1074, 362, 5343, 341, 1939, 13, 1119, 300, 558, 30], "temperature": 0.0, "avg_logprob": -0.21603322347005208, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.3320678792515537e-06}, {"id": 160, "seek": 79712, "start": 808.96, "end": 815.64, "text": " No, so this is really important because this means like if you train a hundred models", "tokens": [883, 11, 370, 341, 307, 534, 1021, 570, 341, 1355, 411, 498, 291, 3847, 257, 3262, 5245], "temperature": 0.0, "avg_logprob": -0.21603322347005208, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.3320678792515537e-06}, {"id": 161, "seek": 79712, "start": 816.24, "end": 821.6800000000001, "text": " right each time the validation set accuracy is like the mean of a distribution and", "tokens": [558, 1184, 565, 264, 24071, 992, 14170, 307, 411, 264, 914, 295, 257, 7316, 293], "temperature": 0.0, "avg_logprob": -0.21603322347005208, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.3320678792515537e-06}, {"id": 162, "seek": 82168, "start": 821.68, "end": 828.92, "text": " So therefore the standard deviation of that validation set accuracy it can be calculated with the standard error", "tokens": [407, 4412, 264, 3832, 25163, 295, 300, 24071, 992, 14170, 309, 393, 312, 15598, 365, 264, 3832, 6713], "temperature": 0.0, "avg_logprob": -0.20645850045340403, "compression_ratio": 1.6956521739130435, "no_speech_prob": 7.934483505778189e-07}, {"id": 163, "seek": 82168, "start": 828.92, "end": 831.7199999999999, "text": " And this is equal to the standard deviation", "tokens": [400, 341, 307, 2681, 281, 264, 3832, 25163], "temperature": 0.0, "avg_logprob": -0.20645850045340403, "compression_ratio": 1.6956521739130435, "no_speech_prob": 7.934483505778189e-07}, {"id": 164, "seek": 82168, "start": 832.76, "end": 834.4, "text": " divided by", "tokens": [6666, 538], "temperature": 0.0, "avg_logprob": -0.20645850045340403, "compression_ratio": 1.6956521739130435, "no_speech_prob": 7.934483505778189e-07}, {"id": 165, "seek": 82168, "start": 834.4, "end": 836.4, "text": " square root and", "tokens": [3732, 5593, 293], "temperature": 0.0, "avg_logprob": -0.20645850045340403, "compression_ratio": 1.6956521739130435, "no_speech_prob": 7.934483505778189e-07}, {"id": 166, "seek": 82168, "start": 837.68, "end": 840.04, "text": " Right so this tells you", "tokens": [1779, 370, 341, 5112, 291], "temperature": 0.0, "avg_logprob": -0.20645850045340403, "compression_ratio": 1.6956521739130435, "no_speech_prob": 7.934483505778189e-07}, {"id": 167, "seek": 82168, "start": 840.8, "end": 846.3199999999999, "text": " So like one approach to figuring out like is my validation set big enough is train your model five times", "tokens": [407, 411, 472, 3109, 281, 15213, 484, 411, 307, 452, 24071, 992, 955, 1547, 307, 3847, 428, 2316, 1732, 1413], "temperature": 0.0, "avg_logprob": -0.20645850045340403, "compression_ratio": 1.6956521739130435, "no_speech_prob": 7.934483505778189e-07}, {"id": 168, "seek": 84632, "start": 846.32, "end": 854.12, "text": " with exactly the same hyper parameters each time and look at the validation set accuracy each time and you know", "tokens": [365, 2293, 264, 912, 9848, 9834, 1184, 565, 293, 574, 412, 264, 24071, 992, 14170, 1184, 565, 293, 291, 458], "temperature": 0.0, "avg_logprob": -0.2211699883143107, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.0904519715259084e-06}, {"id": 169, "seek": 84632, "start": 854.12, "end": 859.6, "text": " There's like a mean and a standard deviation of five numbers. You could use or a maximum and minimum you can choose", "tokens": [821, 311, 411, 257, 914, 293, 257, 3832, 25163, 295, 1732, 3547, 13, 509, 727, 764, 420, 257, 6674, 293, 7285, 291, 393, 2826], "temperature": 0.0, "avg_logprob": -0.2211699883143107, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.0904519715259084e-06}, {"id": 170, "seek": 84632, "start": 860.5200000000001, "end": 864.6, "text": " But save yourself some time you can figure out straight away that like", "tokens": [583, 3155, 1803, 512, 565, 291, 393, 2573, 484, 2997, 1314, 300, 411], "temperature": 0.0, "avg_logprob": -0.2211699883143107, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.0904519715259084e-06}, {"id": 171, "seek": 84632, "start": 865.4000000000001, "end": 867.4000000000001, "text": " Okay, well", "tokens": [1033, 11, 731], "temperature": 0.0, "avg_logprob": -0.2211699883143107, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.0904519715259084e-06}, {"id": 172, "seek": 84632, "start": 867.44, "end": 870.2800000000001, "text": " I I have a point nine nine", "tokens": [286, 286, 362, 257, 935, 4949, 4949], "temperature": 0.0, "avg_logprob": -0.2211699883143107, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.0904519715259084e-06}, {"id": 173, "seek": 87028, "start": 870.28, "end": 876.48, "text": " nine accuracy as to you know whether I get the cat correct or not correct so", "tokens": [4949, 14170, 382, 281, 291, 458, 1968, 286, 483, 264, 3857, 3006, 420, 406, 3006, 370], "temperature": 0.0, "avg_logprob": -0.24639055003290591, "compression_ratio": 1.4745762711864407, "no_speech_prob": 4.425465249369154e-06}, {"id": 174, "seek": 87028, "start": 877.24, "end": 882.3, "text": " Therefore the standard deviation is equal to 0.99 times 0.01", "tokens": [7504, 264, 3832, 25163, 307, 2681, 281, 1958, 13, 8494, 1413, 1958, 13, 10607], "temperature": 0.0, "avg_logprob": -0.24639055003290591, "compression_ratio": 1.4745762711864407, "no_speech_prob": 4.425465249369154e-06}, {"id": 175, "seek": 87028, "start": 883.52, "end": 885.72, "text": " Okay, and then I can get the", "tokens": [1033, 11, 293, 550, 286, 393, 483, 264], "temperature": 0.0, "avg_logprob": -0.24639055003290591, "compression_ratio": 1.4745762711864407, "no_speech_prob": 4.425465249369154e-06}, {"id": 176, "seek": 87028, "start": 887.76, "end": 894.22, "text": " Standard error of that right so so basically the size of the validation set you need", "tokens": [21298, 6713, 295, 300, 558, 370, 370, 1936, 264, 2744, 295, 264, 24071, 992, 291, 643], "temperature": 0.0, "avg_logprob": -0.24639055003290591, "compression_ratio": 1.4745762711864407, "no_speech_prob": 4.425465249369154e-06}, {"id": 177, "seek": 87028, "start": 894.88, "end": 896.4, "text": " it's like", "tokens": [309, 311, 411], "temperature": 0.0, "avg_logprob": -0.24639055003290591, "compression_ratio": 1.4745762711864407, "no_speech_prob": 4.425465249369154e-06}, {"id": 178, "seek": 89640, "start": 896.4, "end": 903.64, "text": " However big it has to be such that your insights about its accuracy are good enough for your particular", "tokens": [2908, 955, 309, 575, 281, 312, 1270, 300, 428, 14310, 466, 1080, 14170, 366, 665, 1547, 337, 428, 1729], "temperature": 0.0, "avg_logprob": -0.1722625876372715, "compression_ratio": 1.7429718875502007, "no_speech_prob": 2.2959086436458165e-06}, {"id": 179, "seek": 89640, "start": 904.6, "end": 905.48, "text": " business problem", "tokens": [1606, 1154], "temperature": 0.0, "avg_logprob": -0.1722625876372715, "compression_ratio": 1.7429718875502007, "no_speech_prob": 2.2959086436458165e-06}, {"id": 180, "seek": 89640, "start": 905.48, "end": 911.1999999999999, "text": " And so like I say like the simple way to do it is to pick a validation set of like a size of thousand", "tokens": [400, 370, 411, 286, 584, 411, 264, 2199, 636, 281, 360, 309, 307, 281, 1888, 257, 24071, 992, 295, 411, 257, 2744, 295, 4714], "temperature": 0.0, "avg_logprob": -0.1722625876372715, "compression_ratio": 1.7429718875502007, "no_speech_prob": 2.2959086436458165e-06}, {"id": 181, "seek": 89640, "start": 911.72, "end": 916.12, "text": " Train five models and see how much the validation set accuracy varies", "tokens": [28029, 1732, 5245, 293, 536, 577, 709, 264, 24071, 992, 14170, 21716], "temperature": 0.0, "avg_logprob": -0.1722625876372715, "compression_ratio": 1.7429718875502007, "no_speech_prob": 2.2959086436458165e-06}, {"id": 182, "seek": 89640, "start": 916.12, "end": 921.14, "text": " And if it's like if they're if it's a they're all close enough for what you need then you're fine", "tokens": [400, 498, 309, 311, 411, 498, 436, 434, 498, 309, 311, 257, 436, 434, 439, 1998, 1547, 337, 437, 291, 643, 550, 291, 434, 2489], "temperature": 0.0, "avg_logprob": -0.1722625876372715, "compression_ratio": 1.7429718875502007, "no_speech_prob": 2.2959086436458165e-06}, {"id": 183, "seek": 89640, "start": 921.3199999999999, "end": 923.88, "text": " If it's not maybe you should make it bigger", "tokens": [759, 309, 311, 406, 1310, 291, 820, 652, 309, 3801], "temperature": 0.0, "avg_logprob": -0.1722625876372715, "compression_ratio": 1.7429718875502007, "no_speech_prob": 2.2959086436458165e-06}, {"id": 184, "seek": 92388, "start": 923.88, "end": 926.52, "text": " Or maybe you should consider", "tokens": [1610, 1310, 291, 820, 1949], "temperature": 0.0, "avg_logprob": -0.21546141680549172, "compression_ratio": 1.6057692307692308, "no_speech_prob": 6.240895345399622e-06}, {"id": 185, "seek": 92388, "start": 927.32, "end": 929.32, "text": " using cross validation", "tokens": [1228, 3278, 24071], "temperature": 0.0, "avg_logprob": -0.21546141680549172, "compression_ratio": 1.6057692307692308, "no_speech_prob": 6.240895345399622e-06}, {"id": 186, "seek": 92388, "start": 929.84, "end": 931.08, "text": " instead", "tokens": [2602], "temperature": 0.0, "avg_logprob": -0.21546141680549172, "compression_ratio": 1.6057692307692308, "no_speech_prob": 6.240895345399622e-06}, {"id": 187, "seek": 92388, "start": 931.08, "end": 932.72, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.21546141680549172, "compression_ratio": 1.6057692307692308, "no_speech_prob": 6.240895345399622e-06}, {"id": 188, "seek": 92388, "start": 932.72, "end": 937.36, "text": " So like as you can see it really depends on what it is you're trying to do", "tokens": [407, 411, 382, 291, 393, 536, 309, 534, 5946, 322, 437, 309, 307, 291, 434, 1382, 281, 360], "temperature": 0.0, "avg_logprob": -0.21546141680549172, "compression_ratio": 1.6057692307692308, "no_speech_prob": 6.240895345399622e-06}, {"id": 189, "seek": 92388, "start": 939.2, "end": 944.68, "text": " How common your less common class is and how accurate your model is could you pass that back to Melissa, please", "tokens": [1012, 2689, 428, 1570, 2689, 1508, 307, 293, 577, 8559, 428, 2316, 307, 727, 291, 1320, 300, 646, 281, 22844, 11, 1767], "temperature": 0.0, "avg_logprob": -0.21546141680549172, "compression_ratio": 1.6057692307692308, "no_speech_prob": 6.240895345399622e-06}, {"id": 190, "seek": 92388, "start": 947.04, "end": 948.12, "text": " Thank you", "tokens": [1044, 291], "temperature": 0.0, "avg_logprob": -0.21546141680549172, "compression_ratio": 1.6057692307692308, "no_speech_prob": 6.240895345399622e-06}, {"id": 191, "seek": 92388, "start": 948.12, "end": 953.16, "text": " I have a question about the less common classes if you have less than 22", "tokens": [286, 362, 257, 1168, 466, 264, 1570, 2689, 5359, 498, 291, 362, 1570, 813, 5853], "temperature": 0.0, "avg_logprob": -0.21546141680549172, "compression_ratio": 1.6057692307692308, "no_speech_prob": 6.240895345399622e-06}, {"id": 192, "seek": 95316, "start": 953.16, "end": 955.3199999999999, "text": " Let's say you have one sample of something", "tokens": [961, 311, 584, 291, 362, 472, 6889, 295, 746], "temperature": 0.0, "avg_logprob": -0.19672858958341638, "compression_ratio": 1.7534246575342465, "no_speech_prob": 5.338096343621146e-06}, {"id": 193, "seek": 95316, "start": 956.68, "end": 961.76, "text": " Let's say it's a face and I only have one representation from that particular country", "tokens": [961, 311, 584, 309, 311, 257, 1851, 293, 286, 787, 362, 472, 10290, 490, 300, 1729, 1941], "temperature": 0.0, "avg_logprob": -0.19672858958341638, "compression_ratio": 1.7534246575342465, "no_speech_prob": 5.338096343621146e-06}, {"id": 194, "seek": 95316, "start": 961.76, "end": 965.7199999999999, "text": " Do I toss that into the training set and it adds variety?", "tokens": [1144, 286, 14432, 300, 666, 264, 3097, 992, 293, 309, 10860, 5673, 30], "temperature": 0.0, "avg_logprob": -0.19672858958341638, "compression_ratio": 1.7534246575342465, "no_speech_prob": 5.338096343621146e-06}, {"id": 195, "seek": 95316, "start": 965.7199999999999, "end": 969.6, "text": " Do I pull it out completely out of the data set or?", "tokens": [1144, 286, 2235, 309, 484, 2584, 484, 295, 264, 1412, 992, 420, 30], "temperature": 0.0, "avg_logprob": -0.19672858958341638, "compression_ratio": 1.7534246575342465, "no_speech_prob": 5.338096343621146e-06}, {"id": 196, "seek": 95316, "start": 970.56, "end": 975.9599999999999, "text": " Do I put it in a test set instead of the validation set?", "tokens": [1144, 286, 829, 309, 294, 257, 1500, 992, 2602, 295, 264, 24071, 992, 30], "temperature": 0.0, "avg_logprob": -0.19672858958341638, "compression_ratio": 1.7534246575342465, "no_speech_prob": 5.338096343621146e-06}, {"id": 197, "seek": 95316, "start": 976.48, "end": 979.92, "text": " So you certainly couldn't put it in the test of the validation set because you're asking", "tokens": [407, 291, 3297, 2809, 380, 829, 309, 294, 264, 1500, 295, 264, 24071, 992, 570, 291, 434, 3365], "temperature": 0.0, "avg_logprob": -0.19672858958341638, "compression_ratio": 1.7534246575342465, "no_speech_prob": 5.338096343621146e-06}, {"id": 198, "seek": 97992, "start": 979.92, "end": 984.28, "text": " Can I mean in general because you're asking can I recognize something I've never seen before?", "tokens": [1664, 286, 914, 294, 2674, 570, 291, 434, 3365, 393, 286, 5521, 746, 286, 600, 1128, 1612, 949, 30], "temperature": 0.0, "avg_logprob": -0.1663992621681907, "compression_ratio": 1.9688715953307394, "no_speech_prob": 1.0953010132652707e-05}, {"id": 199, "seek": 97992, "start": 986.0, "end": 991.8199999999999, "text": " But actually this this question of like can I recognize something I've not seen before there's actually a whole class of models specifically", "tokens": [583, 767, 341, 341, 1168, 295, 411, 393, 286, 5521, 746, 286, 600, 406, 1612, 949, 456, 311, 767, 257, 1379, 1508, 295, 5245, 4682], "temperature": 0.0, "avg_logprob": -0.1663992621681907, "compression_ratio": 1.9688715953307394, "no_speech_prob": 1.0953010132652707e-05}, {"id": 200, "seek": 97992, "start": 992.4, "end": 995.0999999999999, "text": " For that purpose it's called either one-shot learning", "tokens": [1171, 300, 4334, 309, 311, 1219, 2139, 472, 12, 18402, 2539], "temperature": 0.0, "avg_logprob": -0.1663992621681907, "compression_ratio": 1.9688715953307394, "no_speech_prob": 1.0953010132652707e-05}, {"id": 201, "seek": 97992, "start": 995.14, "end": 999.6999999999999, "text": " Which is you get to see something once and then you have to recognize it again or zero shot learning", "tokens": [3013, 307, 291, 483, 281, 536, 746, 1564, 293, 550, 291, 362, 281, 5521, 309, 797, 420, 4018, 3347, 2539], "temperature": 0.0, "avg_logprob": -0.1663992621681907, "compression_ratio": 1.9688715953307394, "no_speech_prob": 1.0953010132652707e-05}, {"id": 202, "seek": 97992, "start": 999.6999999999999, "end": 1004.04, "text": " Which is where you have to recognize something you've never seen before we're not going to cover them in this course", "tokens": [3013, 307, 689, 291, 362, 281, 5521, 746, 291, 600, 1128, 1612, 949, 321, 434, 406, 516, 281, 2060, 552, 294, 341, 1164], "temperature": 0.0, "avg_logprob": -0.1663992621681907, "compression_ratio": 1.9688715953307394, "no_speech_prob": 1.0953010132652707e-05}, {"id": 203, "seek": 100404, "start": 1004.04, "end": 1008.9599999999999, "text": " But they can be useful for things like", "tokens": [583, 436, 393, 312, 4420, 337, 721, 411], "temperature": 0.0, "avg_logprob": -0.15226801872253418, "compression_ratio": 1.831896551724138, "no_speech_prob": 1.653676008572802e-06}, {"id": 204, "seek": 100404, "start": 1009.64, "end": 1011.36, "text": " Face recognition", "tokens": [4047, 11150], "temperature": 0.0, "avg_logprob": -0.15226801872253418, "compression_ratio": 1.831896551724138, "no_speech_prob": 1.653676008572802e-06}, {"id": 205, "seek": 100404, "start": 1011.36, "end": 1018.0799999999999, "text": " You know like is this the same person I've seen before and so generally speaking obviously for something like that to work", "tokens": [509, 458, 411, 307, 341, 264, 912, 954, 286, 600, 1612, 949, 293, 370, 5101, 4124, 2745, 337, 746, 411, 300, 281, 589], "temperature": 0.0, "avg_logprob": -0.15226801872253418, "compression_ratio": 1.831896551724138, "no_speech_prob": 1.653676008572802e-06}, {"id": 206, "seek": 100404, "start": 1018.16, "end": 1022.28, "text": " It's not that you've never seen our face before it's that you've never seen", "tokens": [467, 311, 406, 300, 291, 600, 1128, 1612, 527, 1851, 949, 309, 311, 300, 291, 600, 1128, 1612], "temperature": 0.0, "avg_logprob": -0.15226801872253418, "compression_ratio": 1.831896551724138, "no_speech_prob": 1.653676008572802e-06}, {"id": 207, "seek": 100404, "start": 1022.5999999999999, "end": 1027.3799999999999, "text": " Melissa's face before you know and so you see Melissa's face once and you have to recognize it again", "tokens": [22844, 311, 1851, 949, 291, 458, 293, 370, 291, 536, 22844, 311, 1851, 1564, 293, 291, 362, 281, 5521, 309, 797], "temperature": 0.0, "avg_logprob": -0.15226801872253418, "compression_ratio": 1.831896551724138, "no_speech_prob": 1.653676008572802e-06}, {"id": 208, "seek": 102738, "start": 1027.38, "end": 1034.98, "text": " Yeah, so in general you know your validation set and test set need to have the same", "tokens": [865, 11, 370, 294, 2674, 291, 458, 428, 24071, 992, 293, 1500, 992, 643, 281, 362, 264, 912], "temperature": 0.0, "avg_logprob": -0.21444061440481266, "compression_ratio": 1.5396825396825398, "no_speech_prob": 1.2098602155674598e-06}, {"id": 209, "seek": 102738, "start": 1036.0200000000002, "end": 1038.0200000000002, "text": " mix or frequency", "tokens": [2890, 420, 7893], "temperature": 0.0, "avg_logprob": -0.21444061440481266, "compression_ratio": 1.5396825396825398, "no_speech_prob": 1.2098602155674598e-06}, {"id": 210, "seek": 102738, "start": 1039.22, "end": 1045.18, "text": " Observations that you're going to see in production in the real world and then your training set", "tokens": [42547, 763, 300, 291, 434, 516, 281, 536, 294, 4265, 294, 264, 957, 1002, 293, 550, 428, 3097, 992], "temperature": 0.0, "avg_logprob": -0.21444061440481266, "compression_ratio": 1.5396825396825398, "no_speech_prob": 1.2098602155674598e-06}, {"id": 211, "seek": 102738, "start": 1046.5400000000002, "end": 1051.96, "text": " Should have an equal number in each class and if you don't", "tokens": [6454, 362, 364, 2681, 1230, 294, 1184, 1508, 293, 498, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.21444061440481266, "compression_ratio": 1.5396825396825398, "no_speech_prob": 1.2098602155674598e-06}, {"id": 212, "seek": 102738, "start": 1052.7, "end": 1054.96, "text": " Just replicate the less common one", "tokens": [1449, 25356, 264, 1570, 2689, 472], "temperature": 0.0, "avg_logprob": -0.21444061440481266, "compression_ratio": 1.5396825396825398, "no_speech_prob": 1.2098602155674598e-06}, {"id": 213, "seek": 105496, "start": 1054.96, "end": 1061.28, "text": " Until it is equal so this is I think we've mentioned this paper before very recent paper that came out", "tokens": [9088, 309, 307, 2681, 370, 341, 307, 286, 519, 321, 600, 2835, 341, 3035, 949, 588, 5162, 3035, 300, 1361, 484], "temperature": 0.0, "avg_logprob": -0.1598641655661843, "compression_ratio": 1.6888111888111887, "no_speech_prob": 1.1365599448254216e-06}, {"id": 214, "seek": 105496, "start": 1061.28, "end": 1066.68, "text": " They tried lots of different approaches to training with unbalanced data sets and found consistently that", "tokens": [814, 3031, 3195, 295, 819, 11587, 281, 3097, 365, 517, 40251, 1412, 6352, 293, 1352, 14961, 300], "temperature": 0.0, "avg_logprob": -0.1598641655661843, "compression_ratio": 1.6888111888111887, "no_speech_prob": 1.1365599448254216e-06}, {"id": 215, "seek": 105496, "start": 1067.6000000000001, "end": 1072.52, "text": " Oversampling the less common class until it is the same size as the more common class is", "tokens": [422, 840, 335, 11970, 264, 1570, 2689, 1508, 1826, 309, 307, 264, 912, 2744, 382, 264, 544, 2689, 1508, 307], "temperature": 0.0, "avg_logprob": -0.1598641655661843, "compression_ratio": 1.6888111888111887, "no_speech_prob": 1.1365599448254216e-06}, {"id": 216, "seek": 105496, "start": 1073.28, "end": 1075.28, "text": " Always the right thing to do", "tokens": [11270, 264, 558, 551, 281, 360], "temperature": 0.0, "avg_logprob": -0.1598641655661843, "compression_ratio": 1.6888111888111887, "no_speech_prob": 1.1365599448254216e-06}, {"id": 217, "seek": 105496, "start": 1076.56, "end": 1078.48, "text": " So you could literally copy", "tokens": [407, 291, 727, 3736, 5055], "temperature": 0.0, "avg_logprob": -0.1598641655661843, "compression_ratio": 1.6888111888111887, "no_speech_prob": 1.1365599448254216e-06}, {"id": 218, "seek": 105496, "start": 1078.48, "end": 1084.48, "text": " You know so like I've only got a thousand you know ten examples of people with cancer and a hundred without so I could just copy", "tokens": [509, 458, 370, 411, 286, 600, 787, 658, 257, 4714, 291, 458, 2064, 5110, 295, 561, 365, 5592, 293, 257, 3262, 1553, 370, 286, 727, 445, 5055], "temperature": 0.0, "avg_logprob": -0.1598641655661843, "compression_ratio": 1.6888111888111887, "no_speech_prob": 1.1365599448254216e-06}, {"id": 219, "seek": 108448, "start": 1084.48, "end": 1086.28, "text": " those ten", "tokens": [729, 2064], "temperature": 0.0, "avg_logprob": -0.19647601766323824, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.7330437458440429e-06}, {"id": 220, "seek": 108448, "start": 1086.28, "end": 1088.28, "text": " Another you know 90 times", "tokens": [3996, 291, 458, 4289, 1413], "temperature": 0.0, "avg_logprob": -0.19647601766323824, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.7330437458440429e-06}, {"id": 221, "seek": 108448, "start": 1089.1200000000001, "end": 1094.16, "text": " That's kind of a little memory inefficient so a lot of things including", "tokens": [663, 311, 733, 295, 257, 707, 4675, 43495, 370, 257, 688, 295, 721, 3009], "temperature": 0.0, "avg_logprob": -0.19647601766323824, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.7330437458440429e-06}, {"id": 222, "seek": 108448, "start": 1094.16, "end": 1100.56, "text": " I think SK learns random forests have a class weights parameter that says each time you're bootstrapping or resampling", "tokens": [286, 519, 21483, 27152, 4974, 21700, 362, 257, 1508, 17443, 13075, 300, 1619, 1184, 565, 291, 434, 11450, 19639, 3759, 420, 725, 335, 11970], "temperature": 0.0, "avg_logprob": -0.19647601766323824, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.7330437458440429e-06}, {"id": 223, "seek": 108448, "start": 1100.56, "end": 1104.92, "text": " I want you to sample the less common class with a higher probability", "tokens": [286, 528, 291, 281, 6889, 264, 1570, 2689, 1508, 365, 257, 2946, 8482], "temperature": 0.0, "avg_logprob": -0.19647601766323824, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.7330437458440429e-06}, {"id": 224, "seek": 108448, "start": 1105.44, "end": 1109.3600000000001, "text": " Or ditto if you're doing deep learning you know make sure in your mini batch", "tokens": [1610, 274, 34924, 498, 291, 434, 884, 2452, 2539, 291, 458, 652, 988, 294, 428, 8382, 15245], "temperature": 0.0, "avg_logprob": -0.19647601766323824, "compression_ratio": 1.6902985074626866, "no_speech_prob": 1.7330437458440429e-06}, {"id": 225, "seek": 110936, "start": 1109.36, "end": 1115.6799999999998, "text": " It's not randomly sampled, but it's a stratified sample so the less common class is picked more often", "tokens": [467, 311, 406, 16979, 3247, 15551, 11, 457, 309, 311, 257, 23674, 2587, 6889, 370, 264, 1570, 2689, 1508, 307, 6183, 544, 2049], "temperature": 0.0, "avg_logprob": -0.1509508532147075, "compression_ratio": 1.7323232323232323, "no_speech_prob": 3.4465685985196615e-06}, {"id": 226, "seek": 110936, "start": 1116.84, "end": 1118.6799999999998, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.1509508532147075, "compression_ratio": 1.7323232323232323, "no_speech_prob": 3.4465685985196615e-06}, {"id": 227, "seek": 110936, "start": 1118.6799999999998, "end": 1121.84, "text": " Okay, so let's get back to finishing off", "tokens": [1033, 11, 370, 718, 311, 483, 646, 281, 12693, 766], "temperature": 0.0, "avg_logprob": -0.1509508532147075, "compression_ratio": 1.7323232323232323, "no_speech_prob": 3.4465685985196615e-06}, {"id": 228, "seek": 110936, "start": 1122.6, "end": 1128.32, "text": " Our random forests and so what we're going to do today is we're going to finish off writing our random forest", "tokens": [2621, 4974, 21700, 293, 370, 437, 321, 434, 516, 281, 360, 965, 307, 321, 434, 516, 281, 2413, 766, 3579, 527, 4974, 6719], "temperature": 0.0, "avg_logprob": -0.1509508532147075, "compression_ratio": 1.7323232323232323, "no_speech_prob": 3.4465685985196615e-06}, {"id": 229, "seek": 110936, "start": 1128.32, "end": 1133.1599999999999, "text": " and then after day your your after today your homework will be to take this class and", "tokens": [293, 550, 934, 786, 428, 428, 934, 965, 428, 14578, 486, 312, 281, 747, 341, 1508, 293], "temperature": 0.0, "avg_logprob": -0.1509508532147075, "compression_ratio": 1.7323232323232323, "no_speech_prob": 3.4465685985196615e-06}, {"id": 230, "seek": 113316, "start": 1133.16, "end": 1140.68, "text": " To add to it all of the random forest interpretation algorithms that we've learned okay, so", "tokens": [1407, 909, 281, 309, 439, 295, 264, 4974, 6719, 14174, 14642, 300, 321, 600, 3264, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.16662766819908506, "compression_ratio": 1.524229074889868, "no_speech_prob": 1.933349949467811e-06}, {"id": 231, "seek": 113316, "start": 1141.3600000000001, "end": 1145.74, "text": " Obviously to be able to do that you're going to need to totally understand how this class works", "tokens": [7580, 281, 312, 1075, 281, 360, 300, 291, 434, 516, 281, 643, 281, 3879, 1223, 577, 341, 1508, 1985], "temperature": 0.0, "avg_logprob": -0.16662766819908506, "compression_ratio": 1.524229074889868, "no_speech_prob": 1.933349949467811e-06}, {"id": 232, "seek": 113316, "start": 1145.92, "end": 1150.0, "text": " So please you know ask lots of questions as necessary as we go along", "tokens": [407, 1767, 291, 458, 1029, 3195, 295, 1651, 382, 4818, 382, 321, 352, 2051], "temperature": 0.0, "avg_logprob": -0.16662766819908506, "compression_ratio": 1.524229074889868, "no_speech_prob": 1.933349949467811e-06}, {"id": 233, "seek": 113316, "start": 1151.52, "end": 1153.52, "text": " So just to remind you", "tokens": [407, 445, 281, 4160, 291], "temperature": 0.0, "avg_logprob": -0.16662766819908506, "compression_ratio": 1.524229074889868, "no_speech_prob": 1.933349949467811e-06}, {"id": 234, "seek": 113316, "start": 1156.5600000000002, "end": 1160.72, "text": " We we're doing the the bulldozers kaggle competition data set again", "tokens": [492, 321, 434, 884, 264, 264, 4693, 2595, 41698, 350, 559, 22631, 6211, 1412, 992, 797], "temperature": 0.0, "avg_logprob": -0.16662766819908506, "compression_ratio": 1.524229074889868, "no_speech_prob": 1.933349949467811e-06}, {"id": 235, "seek": 116072, "start": 1160.72, "end": 1167.44, "text": " We split it as before into 12,000 validation the last 12,000 records and then", "tokens": [492, 7472, 309, 382, 949, 666, 2272, 11, 1360, 24071, 264, 1036, 2272, 11, 1360, 7724, 293, 550], "temperature": 0.0, "avg_logprob": -0.16946105567776426, "compression_ratio": 1.6470588235294117, "no_speech_prob": 4.247020513048483e-07}, {"id": 236, "seek": 116072, "start": 1167.84, "end": 1171.4, "text": " Just to make it easier for us to keep track of what we're doing", "tokens": [1449, 281, 652, 309, 3571, 337, 505, 281, 1066, 2837, 295, 437, 321, 434, 884], "temperature": 0.0, "avg_logprob": -0.16946105567776426, "compression_ratio": 1.6470588235294117, "no_speech_prob": 4.247020513048483e-07}, {"id": 237, "seek": 116072, "start": 1171.4, "end": 1176.08, "text": " We're going to just pick two columns out to start with year made and machine hours on the meter", "tokens": [492, 434, 516, 281, 445, 1888, 732, 13766, 484, 281, 722, 365, 1064, 1027, 293, 3479, 2496, 322, 264, 9255], "temperature": 0.0, "avg_logprob": -0.16946105567776426, "compression_ratio": 1.6470588235294117, "no_speech_prob": 4.247020513048483e-07}, {"id": 238, "seek": 116072, "start": 1176.48, "end": 1182.44, "text": " Okay, and so what we did last time was we started out by creating a tree ensemble and", "tokens": [1033, 11, 293, 370, 437, 321, 630, 1036, 565, 390, 321, 1409, 484, 538, 4084, 257, 4230, 19492, 293], "temperature": 0.0, "avg_logprob": -0.16946105567776426, "compression_ratio": 1.6470588235294117, "no_speech_prob": 4.247020513048483e-07}, {"id": 239, "seek": 116072, "start": 1182.88, "end": 1188.1200000000001, "text": " the tree ensemble had a bunch of trees which was literally a list of", "tokens": [264, 4230, 19492, 632, 257, 3840, 295, 5852, 597, 390, 3736, 257, 1329, 295], "temperature": 0.0, "avg_logprob": -0.16946105567776426, "compression_ratio": 1.6470588235294117, "no_speech_prob": 4.247020513048483e-07}, {"id": 240, "seek": 118812, "start": 1188.12, "end": 1189.56, "text": " n", "tokens": [297], "temperature": 0.0, "avg_logprob": -0.27851900736490887, "compression_ratio": 1.540983606557377, "no_speech_prob": 9.874612487692502e-07}, {"id": 241, "seek": 118812, "start": 1189.56, "end": 1191.12, "text": " trees trees", "tokens": [5852, 5852], "temperature": 0.0, "avg_logprob": -0.27851900736490887, "compression_ratio": 1.540983606557377, "no_speech_prob": 9.874612487692502e-07}, {"id": 242, "seek": 118812, "start": 1191.12, "end": 1193.84, "text": " Where each time we just called create tree?", "tokens": [2305, 1184, 565, 321, 445, 1219, 1884, 4230, 30], "temperature": 0.0, "avg_logprob": -0.27851900736490887, "compression_ratio": 1.540983606557377, "no_speech_prob": 9.874612487692502e-07}, {"id": 243, "seek": 118812, "start": 1194.4799999999998, "end": 1196.1999999999998, "text": " okay, and", "tokens": [1392, 11, 293], "temperature": 0.0, "avg_logprob": -0.27851900736490887, "compression_ratio": 1.540983606557377, "no_speech_prob": 9.874612487692502e-07}, {"id": 244, "seek": 118812, "start": 1196.1999999999998, "end": 1198.36, "text": " create tree contained a", "tokens": [1884, 4230, 16212, 257], "temperature": 0.0, "avg_logprob": -0.27851900736490887, "compression_ratio": 1.540983606557377, "no_speech_prob": 9.874612487692502e-07}, {"id": 245, "seek": 118812, "start": 1199.6, "end": 1203.08, "text": " sample size number of random indexes", "tokens": [6889, 2744, 1230, 295, 4974, 8186, 279], "temperature": 0.0, "avg_logprob": -0.27851900736490887, "compression_ratio": 1.540983606557377, "no_speech_prob": 9.874612487692502e-07}, {"id": 246, "seek": 118812, "start": 1203.6799999999998, "end": 1207.12, "text": " Okay, this one was drawn without replacement", "tokens": [1033, 11, 341, 472, 390, 10117, 1553, 14419], "temperature": 0.0, "avg_logprob": -0.27851900736490887, "compression_ratio": 1.540983606557377, "no_speech_prob": 9.874612487692502e-07}, {"id": 247, "seek": 118812, "start": 1208.04, "end": 1216.32, "text": " So remember bootstrapping means sampling with replacement so normally with scikit-learn if you've got n rows", "tokens": [407, 1604, 11450, 19639, 3759, 1355, 21179, 365, 14419, 370, 5646, 365, 2180, 22681, 12, 306, 1083, 498, 291, 600, 658, 297, 13241], "temperature": 0.0, "avg_logprob": -0.27851900736490887, "compression_ratio": 1.540983606557377, "no_speech_prob": 9.874612487692502e-07}, {"id": 248, "seek": 121632, "start": 1216.32, "end": 1223.4399999999998, "text": " We grab n rows with replacement which means many of them will appear more than once", "tokens": [492, 4444, 297, 13241, 365, 14419, 597, 1355, 867, 295, 552, 486, 4204, 544, 813, 1564], "temperature": 0.0, "avg_logprob": -0.18337122599283853, "compression_ratio": 1.688073394495413, "no_speech_prob": 4.664445043545129e-07}, {"id": 249, "seek": 121632, "start": 1223.8, "end": 1226.08, "text": " So each time we get a different sample", "tokens": [407, 1184, 565, 321, 483, 257, 819, 6889], "temperature": 0.0, "avg_logprob": -0.18337122599283853, "compression_ratio": 1.688073394495413, "no_speech_prob": 4.664445043545129e-07}, {"id": 250, "seek": 121632, "start": 1226.08, "end": 1233.04, "text": " But it's always the same size as the original data set and then we have our set RF samples", "tokens": [583, 309, 311, 1009, 264, 912, 2744, 382, 264, 3380, 1412, 992, 293, 550, 321, 362, 527, 992, 26204, 10938], "temperature": 0.0, "avg_logprob": -0.18337122599283853, "compression_ratio": 1.688073394495413, "no_speech_prob": 4.664445043545129e-07}, {"id": 251, "seek": 121632, "start": 1233.72, "end": 1240.46, "text": " Function that we can use which does with replacement sampling of less than n rows", "tokens": [11166, 882, 300, 321, 393, 764, 597, 775, 365, 14419, 21179, 295, 1570, 813, 297, 13241], "temperature": 0.0, "avg_logprob": -0.18337122599283853, "compression_ratio": 1.688073394495413, "no_speech_prob": 4.664445043545129e-07}, {"id": 252, "seek": 124046, "start": 1240.46, "end": 1246.1000000000001, "text": " This is doing something again, which is it sampling without replacement?", "tokens": [639, 307, 884, 746, 797, 11, 597, 307, 309, 21179, 1553, 14419, 30], "temperature": 0.0, "avg_logprob": -0.2323763553912823, "compression_ratio": 1.6360153256704981, "no_speech_prob": 4.247027334258746e-07}, {"id": 253, "seek": 124046, "start": 1246.42, "end": 1248.8600000000001, "text": " Sample size rows okay because we're permuting", "tokens": [4832, 781, 2744, 13241, 1392, 570, 321, 434, 4784, 10861], "temperature": 0.0, "avg_logprob": -0.2323763553912823, "compression_ratio": 1.6360153256704981, "no_speech_prob": 4.247027334258746e-07}, {"id": 254, "seek": 124046, "start": 1249.46, "end": 1255.7, "text": " The numbers from naught to self dot y minus 1 and then grabbing the first self dot sample size of them", "tokens": [440, 3547, 490, 13138, 281, 2698, 5893, 288, 3175, 502, 293, 550, 23771, 264, 700, 2698, 5893, 6889, 2744, 295, 552], "temperature": 0.0, "avg_logprob": -0.2323763553912823, "compression_ratio": 1.6360153256704981, "no_speech_prob": 4.247027334258746e-07}, {"id": 255, "seek": 124046, "start": 1256.1000000000001, "end": 1262.02, "text": " Actually, there's a faster way to do this you can just use NP dot random dot choice, which is a slightly more direct way", "tokens": [5135, 11, 456, 311, 257, 4663, 636, 281, 360, 341, 291, 393, 445, 764, 38611, 5893, 4974, 5893, 3922, 11, 597, 307, 257, 4748, 544, 2047, 636], "temperature": 0.0, "avg_logprob": -0.2323763553912823, "compression_ratio": 1.6360153256704981, "no_speech_prob": 4.247027334258746e-07}, {"id": 256, "seek": 124046, "start": 1262.46, "end": 1264.46, "text": " But this way works as well", "tokens": [583, 341, 636, 1985, 382, 731], "temperature": 0.0, "avg_logprob": -0.2323763553912823, "compression_ratio": 1.6360153256704981, "no_speech_prob": 4.247027334258746e-07}, {"id": 257, "seek": 124046, "start": 1264.58, "end": 1269.22, "text": " Alright, so this is our random sample for this one of our", "tokens": [2798, 11, 370, 341, 307, 527, 4974, 6889, 337, 341, 472, 295, 527], "temperature": 0.0, "avg_logprob": -0.2323763553912823, "compression_ratio": 1.6360153256704981, "no_speech_prob": 4.247027334258746e-07}, {"id": 258, "seek": 126922, "start": 1269.22, "end": 1271.22, "text": " entries trees", "tokens": [23041, 5852], "temperature": 0.0, "avg_logprob": -0.21007650548761542, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.368793047935469e-06}, {"id": 259, "seek": 126922, "start": 1272.3, "end": 1276.6200000000001, "text": " And so then we're going to create a decision tree and our decision tree", "tokens": [400, 370, 550, 321, 434, 516, 281, 1884, 257, 3537, 4230, 293, 527, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.21007650548761542, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.368793047935469e-06}, {"id": 260, "seek": 126922, "start": 1277.02, "end": 1284.24, "text": " We don't pass it all of X we pass it these specific indexes and remember X is a pandas data frame", "tokens": [492, 500, 380, 1320, 309, 439, 295, 1783, 321, 1320, 309, 613, 2685, 8186, 279, 293, 1604, 1783, 307, 257, 4565, 296, 1412, 3920], "temperature": 0.0, "avg_logprob": -0.21007650548761542, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.368793047935469e-06}, {"id": 261, "seek": 126922, "start": 1284.66, "end": 1291.3, "text": " So if we want to index into it with a bunch of integers we have to use I lock integer locations", "tokens": [407, 498, 321, 528, 281, 8186, 666, 309, 365, 257, 3840, 295, 41674, 321, 362, 281, 764, 286, 4017, 24922, 9253], "temperature": 0.0, "avg_logprob": -0.21007650548761542, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.368793047935469e-06}, {"id": 262, "seek": 126922, "start": 1292.02, "end": 1294.02, "text": " And that makes it behave", "tokens": [400, 300, 1669, 309, 15158], "temperature": 0.0, "avg_logprob": -0.21007650548761542, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.368793047935469e-06}, {"id": 263, "seek": 126922, "start": 1293.98, "end": 1295.98, "text": " indexing wise just like numpy", "tokens": [8186, 278, 10829, 445, 411, 1031, 8200], "temperature": 0.0, "avg_logprob": -0.21007650548761542, "compression_ratio": 1.6372549019607843, "no_speech_prob": 2.368793047935469e-06}, {"id": 264, "seek": 129598, "start": 1295.98, "end": 1297.98, "text": " Our", "tokens": [2621], "temperature": 0.0, "avg_logprob": -0.19356587592591631, "compression_ratio": 1.6153846153846154, "no_speech_prob": 2.2252741018746747e-06}, {"id": 265, "seek": 129598, "start": 1297.98, "end": 1305.18, "text": " Y vector is numpy so we can just index into it directly and then we're going to keep track of our minimum leaf size", "tokens": [398, 8062, 307, 1031, 8200, 370, 321, 393, 445, 8186, 666, 309, 3838, 293, 550, 321, 434, 516, 281, 1066, 2837, 295, 527, 7285, 10871, 2744], "temperature": 0.0, "avg_logprob": -0.19356587592591631, "compression_ratio": 1.6153846153846154, "no_speech_prob": 2.2252741018746747e-06}, {"id": 266, "seek": 129598, "start": 1308.22, "end": 1313.26, "text": " So then the only other thing we really need an ensemble is some way to make a prediction and so we were just going to", "tokens": [407, 550, 264, 787, 661, 551, 321, 534, 643, 364, 19492, 307, 512, 636, 281, 652, 257, 17630, 293, 370, 321, 645, 445, 516, 281], "temperature": 0.0, "avg_logprob": -0.19356587592591631, "compression_ratio": 1.6153846153846154, "no_speech_prob": 2.2252741018746747e-06}, {"id": 267, "seek": 129598, "start": 1313.26, "end": 1316.24, "text": " Do the mean of the tree prediction?", "tokens": [1144, 264, 914, 295, 264, 4230, 17630, 30], "temperature": 0.0, "avg_logprob": -0.19356587592591631, "compression_ratio": 1.6153846153846154, "no_speech_prob": 2.2252741018746747e-06}, {"id": 268, "seek": 129598, "start": 1317.6200000000001, "end": 1319.38, "text": " for each tree", "tokens": [337, 1184, 4230], "temperature": 0.0, "avg_logprob": -0.19356587592591631, "compression_ratio": 1.6153846153846154, "no_speech_prob": 2.2252741018746747e-06}, {"id": 269, "seek": 129598, "start": 1319.38, "end": 1323.58, "text": " Alright, so that was that and so then in order to be able to run that", "tokens": [2798, 11, 370, 300, 390, 300, 293, 370, 550, 294, 1668, 281, 312, 1075, 281, 1190, 300], "temperature": 0.0, "avg_logprob": -0.19356587592591631, "compression_ratio": 1.6153846153846154, "no_speech_prob": 2.2252741018746747e-06}, {"id": 270, "seek": 132358, "start": 1323.58, "end": 1328.3, "text": " We need a decision tree class because it's being called here", "tokens": [492, 643, 257, 3537, 4230, 1508, 570, 309, 311, 885, 1219, 510], "temperature": 0.0, "avg_logprob": -0.1873745974372415, "compression_ratio": 1.689119170984456, "no_speech_prob": 1.6797279158708989e-06}, {"id": 271, "seek": 132358, "start": 1328.9399999999998, "end": 1330.9399999999998, "text": " And so there we go", "tokens": [400, 370, 456, 321, 352], "temperature": 0.0, "avg_logprob": -0.1873745974372415, "compression_ratio": 1.689119170984456, "no_speech_prob": 1.6797279158708989e-06}, {"id": 272, "seek": 132358, "start": 1332.1, "end": 1335.78, "text": " Okay, so that's the starting point so", "tokens": [1033, 11, 370, 300, 311, 264, 2891, 935, 370], "temperature": 0.0, "avg_logprob": -0.1873745974372415, "compression_ratio": 1.689119170984456, "no_speech_prob": 1.6797279158708989e-06}, {"id": 273, "seek": 132358, "start": 1337.6999999999998, "end": 1342.1999999999998, "text": " The next thing we need to do is to flesh out our decision tree", "tokens": [440, 958, 551, 321, 643, 281, 360, 307, 281, 12497, 484, 527, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.1873745974372415, "compression_ratio": 1.689119170984456, "no_speech_prob": 1.6797279158708989e-06}, {"id": 274, "seek": 132358, "start": 1342.1999999999998, "end": 1345.86, "text": " So the important thing to remember is all of our randomness", "tokens": [407, 264, 1021, 551, 281, 1604, 307, 439, 295, 527, 4974, 1287], "temperature": 0.0, "avg_logprob": -0.1873745974372415, "compression_ratio": 1.689119170984456, "no_speech_prob": 1.6797279158708989e-06}, {"id": 275, "seek": 132358, "start": 1346.6599999999999, "end": 1348.6599999999999, "text": " Happened back here in the tree ensemble", "tokens": [7412, 5320, 646, 510, 294, 264, 4230, 19492], "temperature": 0.0, "avg_logprob": -0.1873745974372415, "compression_ratio": 1.689119170984456, "no_speech_prob": 1.6797279158708989e-06}, {"id": 276, "seek": 132358, "start": 1349.6599999999999, "end": 1351.98, "text": " The decision tree class we're going to create", "tokens": [440, 3537, 4230, 1508, 321, 434, 516, 281, 1884], "temperature": 0.0, "avg_logprob": -0.1873745974372415, "compression_ratio": 1.689119170984456, "no_speech_prob": 1.6797279158708989e-06}, {"id": 277, "seek": 135198, "start": 1351.98, "end": 1353.98, "text": " Doesn't have randomness in it", "tokens": [12955, 380, 362, 4974, 1287, 294, 309], "temperature": 0.0, "avg_logprob": -0.1991128921508789, "compression_ratio": 1.6018957345971565, "no_speech_prob": 3.844909770123195e-06}, {"id": 278, "seek": 135198, "start": 1356.58, "end": 1363.54, "text": " Okay, so right now we are building a random t regressor right so that's why we're taking the mean of the tree", "tokens": [1033, 11, 370, 558, 586, 321, 366, 2390, 257, 4974, 256, 1121, 735, 284, 558, 370, 300, 311, 983, 321, 434, 1940, 264, 914, 295, 264, 4230], "temperature": 0.0, "avg_logprob": -0.1991128921508789, "compression_ratio": 1.6018957345971565, "no_speech_prob": 3.844909770123195e-06}, {"id": 279, "seek": 135198, "start": 1364.46, "end": 1367.7, "text": " The outputs if we were to work with classification", "tokens": [440, 23930, 498, 321, 645, 281, 589, 365, 21538], "temperature": 0.0, "avg_logprob": -0.1991128921508789, "compression_ratio": 1.6018957345971565, "no_speech_prob": 3.844909770123195e-06}, {"id": 280, "seek": 135198, "start": 1368.18, "end": 1372.8600000000001, "text": " Do we take the max like the classifier will give you either zeros or ones?", "tokens": [1144, 321, 747, 264, 11469, 411, 264, 1508, 9902, 486, 976, 291, 2139, 35193, 420, 2306, 30], "temperature": 0.0, "avg_logprob": -0.1991128921508789, "compression_ratio": 1.6018957345971565, "no_speech_prob": 3.844909770123195e-06}, {"id": 281, "seek": 135198, "start": 1373.42, "end": 1378.9, "text": " No, I would still take the mean so the so each tree is going to tell you", "tokens": [883, 11, 286, 576, 920, 747, 264, 914, 370, 264, 370, 1184, 4230, 307, 516, 281, 980, 291], "temperature": 0.0, "avg_logprob": -0.1991128921508789, "compression_ratio": 1.6018957345971565, "no_speech_prob": 3.844909770123195e-06}, {"id": 282, "seek": 137890, "start": 1378.9, "end": 1385.46, "text": " What percentage of that leaf node contains cats and what percentage take contains dogs?", "tokens": [708, 9668, 295, 300, 10871, 9984, 8306, 11111, 293, 437, 9668, 747, 8306, 7197, 30], "temperature": 0.0, "avg_logprob": -0.19682916876387924, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.9278555163946294e-07}, {"id": 283, "seek": 137890, "start": 1385.8600000000001, "end": 1392.7800000000002, "text": " so then I would average all those percentages and say across the trees on average there is 19 percent cats and", "tokens": [370, 550, 286, 576, 4274, 439, 729, 42270, 293, 584, 2108, 264, 5852, 322, 4274, 456, 307, 1294, 3043, 11111, 293], "temperature": 0.0, "avg_logprob": -0.19682916876387924, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.9278555163946294e-07}, {"id": 284, "seek": 137890, "start": 1394.26, "end": 1396.26, "text": " 81 percent dogs", "tokens": [30827, 3043, 7197], "temperature": 0.0, "avg_logprob": -0.19682916876387924, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.9278555163946294e-07}, {"id": 285, "seek": 137890, "start": 1396.5800000000002, "end": 1398.5800000000002, "text": " Good question so you know", "tokens": [2205, 1168, 370, 291, 458], "temperature": 0.0, "avg_logprob": -0.19682916876387924, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.9278555163946294e-07}, {"id": 286, "seek": 137890, "start": 1400.7800000000002, "end": 1407.26, "text": " Random tree classifiers are almost identical or can be almost identical the random tree regresses", "tokens": [37603, 4230, 1508, 23463, 366, 1920, 14800, 420, 393, 312, 1920, 14800, 264, 4974, 4230, 1121, 40352], "temperature": 0.0, "avg_logprob": -0.19682916876387924, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.9278555163946294e-07}, {"id": 287, "seek": 140726, "start": 1407.26, "end": 1409.26, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.2319057204506614, "compression_ratio": 1.7188940092165899, "no_speech_prob": 1.101592943086871e-06}, {"id": 288, "seek": 140726, "start": 1409.46, "end": 1414.14, "text": " Technique we're going to use to build this today will basically exactly work for a classification", "tokens": [8337, 1925, 321, 434, 516, 281, 764, 281, 1322, 341, 965, 486, 1936, 2293, 589, 337, 257, 21538], "temperature": 0.0, "avg_logprob": -0.2319057204506614, "compression_ratio": 1.7188940092165899, "no_speech_prob": 1.101592943086871e-06}, {"id": 289, "seek": 140726, "start": 1414.34, "end": 1421.9, "text": " It's certainly for binary classification you can do with exactly the same code for multi-class classification. You just need to change your data structure", "tokens": [467, 311, 3297, 337, 17434, 21538, 291, 393, 360, 365, 2293, 264, 912, 3089, 337, 4825, 12, 11665, 21538, 13, 509, 445, 643, 281, 1319, 428, 1412, 3877], "temperature": 0.0, "avg_logprob": -0.2319057204506614, "compression_ratio": 1.7188940092165899, "no_speech_prob": 1.101592943086871e-06}, {"id": 290, "seek": 140726, "start": 1422.9, "end": 1425.58, "text": " So that like you have like a one hot encoded", "tokens": [407, 300, 411, 291, 362, 411, 257, 472, 2368, 2058, 12340], "temperature": 0.0, "avg_logprob": -0.2319057204506614, "compression_ratio": 1.7188940092165899, "no_speech_prob": 1.101592943086871e-06}, {"id": 291, "seek": 140726, "start": 1426.3, "end": 1428.3, "text": " matrix or a", "tokens": [8141, 420, 257], "temperature": 0.0, "avg_logprob": -0.2319057204506614, "compression_ratio": 1.7188940092165899, "no_speech_prob": 1.101592943086871e-06}, {"id": 292, "seek": 140726, "start": 1428.7, "end": 1431.66, "text": " List of integers that you treat as a one hot encoded matrix", "tokens": [17668, 295, 41674, 300, 291, 2387, 382, 257, 472, 2368, 2058, 12340, 8141], "temperature": 0.0, "avg_logprob": -0.2319057204506614, "compression_ratio": 1.7188940092165899, "no_speech_prob": 1.101592943086871e-06}, {"id": 293, "seek": 143166, "start": 1431.66, "end": 1437.18, "text": " Okay, so our decision tree", "tokens": [1033, 11, 370, 527, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.1645153264204661, "compression_ratio": 1.8349514563106797, "no_speech_prob": 1.9033769831366953e-06}, {"id": 294, "seek": 143166, "start": 1439.0600000000002, "end": 1445.14, "text": " So remember our idea here is that we're going to like try to avoid thinking so we're going to basically write", "tokens": [407, 1604, 527, 1558, 510, 307, 300, 321, 434, 516, 281, 411, 853, 281, 5042, 1953, 370, 321, 434, 516, 281, 1936, 2464], "temperature": 0.0, "avg_logprob": -0.1645153264204661, "compression_ratio": 1.8349514563106797, "no_speech_prob": 1.9033769831366953e-06}, {"id": 295, "seek": 143166, "start": 1445.5800000000002, "end": 1450.1000000000001, "text": " It as if everything we need already exists, okay, so we know", "tokens": [467, 382, 498, 1203, 321, 643, 1217, 8198, 11, 1392, 11, 370, 321, 458], "temperature": 0.0, "avg_logprob": -0.1645153264204661, "compression_ratio": 1.8349514563106797, "no_speech_prob": 1.9033769831366953e-06}, {"id": 296, "seek": 143166, "start": 1450.78, "end": 1456.52, "text": " From when we created the decision tree we're going to pass in the X the Y and the minimum leaf size", "tokens": [3358, 562, 321, 2942, 264, 3537, 4230, 321, 434, 516, 281, 1320, 294, 264, 1783, 264, 398, 293, 264, 7285, 10871, 2744], "temperature": 0.0, "avg_logprob": -0.1645153264204661, "compression_ratio": 1.8349514563106797, "no_speech_prob": 1.9033769831366953e-06}, {"id": 297, "seek": 145652, "start": 1456.52, "end": 1462.24, "text": " So here we need to make sure we've got the X and the Y and the minimum leaf size, okay", "tokens": [407, 510, 321, 643, 281, 652, 988, 321, 600, 658, 264, 1783, 293, 264, 398, 293, 264, 7285, 10871, 2744, 11, 1392], "temperature": 0.0, "avg_logprob": -0.1512321453650021, "compression_ratio": 1.7980769230769231, "no_speech_prob": 1.7880593077279627e-06}, {"id": 298, "seek": 145652, "start": 1462.52, "end": 1465.16, "text": " so then there's one other thing which is as we", "tokens": [370, 550, 456, 311, 472, 661, 551, 597, 307, 382, 321], "temperature": 0.0, "avg_logprob": -0.1512321453650021, "compression_ratio": 1.7980769230769231, "no_speech_prob": 1.7880593077279627e-06}, {"id": 299, "seek": 145652, "start": 1466.04, "end": 1470.72, "text": " split our tree into sub trees, we're going to need to keep track of", "tokens": [7472, 527, 4230, 666, 1422, 5852, 11, 321, 434, 516, 281, 643, 281, 1066, 2837, 295], "temperature": 0.0, "avg_logprob": -0.1512321453650021, "compression_ratio": 1.7980769230769231, "no_speech_prob": 1.7880593077279627e-06}, {"id": 300, "seek": 145652, "start": 1472.04, "end": 1477.76, "text": " Which of the row indexes went into the left hand side of the tree which went into the right hand side of the tree?", "tokens": [3013, 295, 264, 5386, 8186, 279, 1437, 666, 264, 1411, 1011, 1252, 295, 264, 4230, 597, 1437, 666, 264, 558, 1011, 1252, 295, 264, 4230, 30], "temperature": 0.0, "avg_logprob": -0.1512321453650021, "compression_ratio": 1.7980769230769231, "no_speech_prob": 1.7880593077279627e-06}, {"id": 301, "seek": 145652, "start": 1477.8, "end": 1479.92, "text": " Okay, so we're going to have this thing called", "tokens": [1033, 11, 370, 321, 434, 516, 281, 362, 341, 551, 1219], "temperature": 0.0, "avg_logprob": -0.1512321453650021, "compression_ratio": 1.7980769230769231, "no_speech_prob": 1.7880593077279627e-06}, {"id": 302, "seek": 145652, "start": 1480.6, "end": 1482.04, "text": " indexes as", "tokens": [8186, 279, 382], "temperature": 0.0, "avg_logprob": -0.1512321453650021, "compression_ratio": 1.7980769230769231, "no_speech_prob": 1.7880593077279627e-06}, {"id": 303, "seek": 148204, "start": 1482.04, "end": 1486.7, "text": " Well, right so at first we just didn't bother passing in indexes at all", "tokens": [1042, 11, 558, 370, 412, 700, 321, 445, 994, 380, 8677, 8437, 294, 8186, 279, 412, 439], "temperature": 0.0, "avg_logprob": -0.20521710713704427, "compression_ratio": 1.7280701754385965, "no_speech_prob": 5.043470423515828e-07}, {"id": 304, "seek": 148204, "start": 1486.7, "end": 1491.04, "text": " So if indexes is not passed in if it's none, then we're just going to set it to", "tokens": [407, 498, 8186, 279, 307, 406, 4678, 294, 498, 309, 311, 6022, 11, 550, 321, 434, 445, 516, 281, 992, 309, 281], "temperature": 0.0, "avg_logprob": -0.20521710713704427, "compression_ratio": 1.7280701754385965, "no_speech_prob": 5.043470423515828e-07}, {"id": 305, "seek": 148204, "start": 1492.3999999999999, "end": 1499.1, "text": " Ever the entire length of Y right so NP dot a range is the same as just range in Python", "tokens": [12123, 264, 2302, 4641, 295, 398, 558, 370, 38611, 5893, 257, 3613, 307, 264, 912, 382, 445, 3613, 294, 15329], "temperature": 0.0, "avg_logprob": -0.20521710713704427, "compression_ratio": 1.7280701754385965, "no_speech_prob": 5.043470423515828e-07}, {"id": 306, "seek": 148204, "start": 1499.1, "end": 1504.2, "text": " But it returns a numpy array right so that the root of a decision tree", "tokens": [583, 309, 11247, 257, 1031, 8200, 10225, 558, 370, 300, 264, 5593, 295, 257, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.20521710713704427, "compression_ratio": 1.7280701754385965, "no_speech_prob": 5.043470423515828e-07}, {"id": 307, "seek": 148204, "start": 1505.12, "end": 1509.98, "text": " Contains all the roads. That's the definition really of the root of a decision tree", "tokens": [4839, 2315, 439, 264, 11344, 13, 663, 311, 264, 7123, 534, 295, 264, 5593, 295, 257, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.20521710713704427, "compression_ratio": 1.7280701754385965, "no_speech_prob": 5.043470423515828e-07}, {"id": 308, "seek": 150998, "start": 1509.98, "end": 1515.5, "text": " So all the rows is for naught row one row two etc up to row y minus one", "tokens": [407, 439, 264, 13241, 307, 337, 13138, 5386, 472, 5386, 732, 5183, 493, 281, 5386, 288, 3175, 472], "temperature": 0.0, "avg_logprob": -0.22804191838140073, "compression_ratio": 1.6237623762376239, "no_speech_prob": 3.0590214805670257e-07}, {"id": 309, "seek": 150998, "start": 1516.06, "end": 1521.22, "text": " Okay, and then we're just going to store away all that information that we were given", "tokens": [1033, 11, 293, 550, 321, 434, 445, 516, 281, 3531, 1314, 439, 300, 1589, 300, 321, 645, 2212], "temperature": 0.0, "avg_logprob": -0.22804191838140073, "compression_ratio": 1.6237623762376239, "no_speech_prob": 3.0590214805670257e-07}, {"id": 310, "seek": 150998, "start": 1522.02, "end": 1524.02, "text": " We're going to keep track of how many?", "tokens": [492, 434, 516, 281, 1066, 2837, 295, 577, 867, 30], "temperature": 0.0, "avg_logprob": -0.22804191838140073, "compression_ratio": 1.6237623762376239, "no_speech_prob": 3.0590214805670257e-07}, {"id": 311, "seek": 150998, "start": 1524.26, "end": 1527.8600000000001, "text": " Rows are there and how many columns are there okay?", "tokens": [497, 1509, 366, 456, 293, 577, 867, 13766, 366, 456, 1392, 30], "temperature": 0.0, "avg_logprob": -0.22804191838140073, "compression_ratio": 1.6237623762376239, "no_speech_prob": 3.0590214805670257e-07}, {"id": 312, "seek": 150998, "start": 1528.66, "end": 1530.66, "text": " so then the", "tokens": [370, 550, 264], "temperature": 0.0, "avg_logprob": -0.22804191838140073, "compression_ratio": 1.6237623762376239, "no_speech_prob": 3.0590214805670257e-07}, {"id": 313, "seek": 150998, "start": 1530.74, "end": 1531.9, "text": " every", "tokens": [633], "temperature": 0.0, "avg_logprob": -0.22804191838140073, "compression_ratio": 1.6237623762376239, "no_speech_prob": 3.0590214805670257e-07}, {"id": 314, "seek": 150998, "start": 1531.9, "end": 1537.18, "text": " Leaf and every node in a tree has a value it has a prediction", "tokens": [32290, 293, 633, 9984, 294, 257, 4230, 575, 257, 2158, 309, 575, 257, 17630], "temperature": 0.0, "avg_logprob": -0.22804191838140073, "compression_ratio": 1.6237623762376239, "no_speech_prob": 3.0590214805670257e-07}, {"id": 315, "seek": 153718, "start": 1537.18, "end": 1542.3400000000001, "text": " And that prediction is just equal to the average of the dependent variable", "tokens": [400, 300, 17630, 307, 445, 2681, 281, 264, 4274, 295, 264, 12334, 7006], "temperature": 0.0, "avg_logprob": -0.1978176236152649, "compression_ratio": 1.619047619047619, "no_speech_prob": 5.203565933697973e-07}, {"id": 316, "seek": 153718, "start": 1543.3, "end": 1545.3, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.1978176236152649, "compression_ratio": 1.619047619047619, "no_speech_prob": 5.203565933697973e-07}, {"id": 317, "seek": 153718, "start": 1545.3400000000001, "end": 1547.3400000000001, "text": " every node in the tree", "tokens": [633, 9984, 294, 264, 4230], "temperature": 0.0, "avg_logprob": -0.1978176236152649, "compression_ratio": 1.619047619047619, "no_speech_prob": 5.203565933697973e-07}, {"id": 318, "seek": 153718, "start": 1548.22, "end": 1550.8200000000002, "text": " Y indexed with the indexes is", "tokens": [398, 8186, 292, 365, 264, 8186, 279, 307], "temperature": 0.0, "avg_logprob": -0.1978176236152649, "compression_ratio": 1.619047619047619, "no_speech_prob": 5.203565933697973e-07}, {"id": 319, "seek": 153718, "start": 1551.94, "end": 1557.42, "text": " The values of the dependent variable that are in this branch of the tree and so here is the mean", "tokens": [440, 4190, 295, 264, 12334, 7006, 300, 366, 294, 341, 9819, 295, 264, 4230, 293, 370, 510, 307, 264, 914], "temperature": 0.0, "avg_logprob": -0.1978176236152649, "compression_ratio": 1.619047619047619, "no_speech_prob": 5.203565933697973e-07}, {"id": 320, "seek": 153718, "start": 1560.3, "end": 1561.74, "text": " Some", "tokens": [2188], "temperature": 0.0, "avg_logprob": -0.1978176236152649, "compression_ratio": 1.619047619047619, "no_speech_prob": 5.203565933697973e-07}, {"id": 321, "seek": 156174, "start": 1561.74, "end": 1567.94, "text": " Nodes in a tree also have a score which is like how effective was the split?", "tokens": [426, 4789, 294, 257, 4230, 611, 362, 257, 6175, 597, 307, 411, 577, 4942, 390, 264, 7472, 30], "temperature": 0.0, "avg_logprob": -0.1640181713793651, "compression_ratio": 1.5870646766169154, "no_speech_prob": 5.626396841762471e-07}, {"id": 322, "seek": 156174, "start": 1568.78, "end": 1575.54, "text": " Here right, but that's only going to be true if it's not a leaf node right a leaf node has no further splits", "tokens": [1692, 558, 11, 457, 300, 311, 787, 516, 281, 312, 2074, 498, 309, 311, 406, 257, 10871, 9984, 558, 257, 10871, 9984, 575, 572, 3052, 37741], "temperature": 0.0, "avg_logprob": -0.1640181713793651, "compression_ratio": 1.5870646766169154, "no_speech_prob": 5.626396841762471e-07}, {"id": 323, "seek": 156174, "start": 1575.54, "end": 1582.42, "text": " And at this point when we create a tree we haven't done any splits yet, so its score starts out as being infinity", "tokens": [400, 412, 341, 935, 562, 321, 1884, 257, 4230, 321, 2378, 380, 1096, 604, 37741, 1939, 11, 370, 1080, 6175, 3719, 484, 382, 885, 13202], "temperature": 0.0, "avg_logprob": -0.1640181713793651, "compression_ratio": 1.5870646766169154, "no_speech_prob": 5.626396841762471e-07}, {"id": 324, "seek": 156174, "start": 1584.06, "end": 1586.06, "text": " So having built the", "tokens": [407, 1419, 3094, 264], "temperature": 0.0, "avg_logprob": -0.1640181713793651, "compression_ratio": 1.5870646766169154, "no_speech_prob": 5.626396841762471e-07}, {"id": 325, "seek": 158606, "start": 1586.06, "end": 1592.94, "text": " The root of the tree our next job is to find out which variable should we split on and what?", "tokens": [440, 5593, 295, 264, 4230, 527, 958, 1691, 307, 281, 915, 484, 597, 7006, 820, 321, 7472, 322, 293, 437, 30], "temperature": 0.0, "avg_logprob": -0.17532236148149538, "compression_ratio": 1.654054054054054, "no_speech_prob": 1.0511481605135486e-06}, {"id": 326, "seek": 158606, "start": 1593.58, "end": 1599.82, "text": " Level of that variable should we split on so let's pretend that there's something that does that fine basket", "tokens": [16872, 295, 300, 7006, 820, 321, 7472, 322, 370, 718, 311, 11865, 300, 456, 311, 746, 300, 775, 300, 2489, 8390], "temperature": 0.0, "avg_logprob": -0.17532236148149538, "compression_ratio": 1.654054054054054, "no_speech_prob": 1.0511481605135486e-06}, {"id": 327, "seek": 158606, "start": 1601.8999999999999, "end": 1607.7, "text": " So then we're done, okay, so how do we find a", "tokens": [407, 550, 321, 434, 1096, 11, 1392, 11, 370, 577, 360, 321, 915, 257], "temperature": 0.0, "avg_logprob": -0.17532236148149538, "compression_ratio": 1.654054054054054, "no_speech_prob": 1.0511481605135486e-06}, {"id": 328, "seek": 160770, "start": 1607.7, "end": 1614.5, "text": " variable to split on so well we could just go through each", "tokens": [7006, 281, 7472, 322, 370, 731, 321, 727, 445, 352, 807, 1184], "temperature": 0.0, "avg_logprob": -0.21111935288158815, "compression_ratio": 1.5723270440251573, "no_speech_prob": 8.059437845986395e-07}, {"id": 329, "seek": 160770, "start": 1616.02, "end": 1619.42, "text": " Potential variable so C contains the number of columns", "tokens": [9145, 2549, 7006, 370, 383, 8306, 264, 1230, 295, 13766], "temperature": 0.0, "avg_logprob": -0.21111935288158815, "compression_ratio": 1.5723270440251573, "no_speech_prob": 8.059437845986395e-07}, {"id": 330, "seek": 160770, "start": 1619.5800000000002, "end": 1626.42, "text": " We have so go through each one and see if we can find a better split than we have so far on that column", "tokens": [492, 362, 370, 352, 807, 1184, 472, 293, 536, 498, 321, 393, 915, 257, 1101, 7472, 813, 321, 362, 370, 1400, 322, 300, 7738], "temperature": 0.0, "avg_logprob": -0.21111935288158815, "compression_ratio": 1.5723270440251573, "no_speech_prob": 8.059437845986395e-07}, {"id": 331, "seek": 160770, "start": 1627.74, "end": 1629.56, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.21111935288158815, "compression_ratio": 1.5723270440251573, "no_speech_prob": 8.059437845986395e-07}, {"id": 332, "seek": 160770, "start": 1629.56, "end": 1631.66, "text": " Now notice this is like", "tokens": [823, 3449, 341, 307, 411], "temperature": 0.0, "avg_logprob": -0.21111935288158815, "compression_ratio": 1.5723270440251573, "no_speech_prob": 8.059437845986395e-07}, {"id": 333, "seek": 160770, "start": 1632.42, "end": 1633.74, "text": " not", "tokens": [406], "temperature": 0.0, "avg_logprob": -0.21111935288158815, "compression_ratio": 1.5723270440251573, "no_speech_prob": 8.059437845986395e-07}, {"id": 334, "seek": 163374, "start": 1633.74, "end": 1637.94, "text": " The full random forest definition this is assuming that max features", "tokens": [440, 1577, 4974, 6719, 7123, 341, 307, 11926, 300, 11469, 4122], "temperature": 0.0, "avg_logprob": -0.1563563124041691, "compression_ratio": 1.842741935483871, "no_speech_prob": 3.84492250304902e-06}, {"id": 335, "seek": 163374, "start": 1638.5, "end": 1641.9, "text": " Is set to all right remember we could set max features to like", "tokens": [1119, 992, 281, 439, 558, 1604, 321, 727, 992, 11469, 4122, 281, 411], "temperature": 0.0, "avg_logprob": -0.1563563124041691, "compression_ratio": 1.842741935483871, "no_speech_prob": 3.84492250304902e-06}, {"id": 336, "seek": 163374, "start": 1642.6200000000001, "end": 1649.16, "text": " 0.5 in which case we wouldn't check all the numbers from not to see we would check half the numbers at random from not to", "tokens": [1958, 13, 20, 294, 597, 1389, 321, 2759, 380, 1520, 439, 264, 3547, 490, 406, 281, 536, 321, 576, 1520, 1922, 264, 3547, 412, 4974, 490, 406, 281], "temperature": 0.0, "avg_logprob": -0.1563563124041691, "compression_ratio": 1.842741935483871, "no_speech_prob": 3.84492250304902e-06}, {"id": 337, "seek": 163374, "start": 1649.16, "end": 1654.28, "text": " See so if you want to turn this into like a random forest that has the max features", "tokens": [3008, 370, 498, 291, 528, 281, 1261, 341, 666, 411, 257, 4974, 6719, 300, 575, 264, 11469, 4122], "temperature": 0.0, "avg_logprob": -0.1563563124041691, "compression_ratio": 1.842741935483871, "no_speech_prob": 3.84492250304902e-06}, {"id": 338, "seek": 165428, "start": 1654.28, "end": 1662.92, "text": " Support you could easily like add one line of code to do that, but we're not going to do it in our implementation today", "tokens": [18073, 291, 727, 3612, 411, 909, 472, 1622, 295, 3089, 281, 360, 300, 11, 457, 321, 434, 406, 516, 281, 360, 309, 294, 527, 11420, 965], "temperature": 0.0, "avg_logprob": -0.1432164510091146, "compression_ratio": 1.5606060606060606, "no_speech_prob": 2.1907760583417257e-06}, {"id": 339, "seek": 165428, "start": 1665.28, "end": 1670.1399999999999, "text": " So then we just need to find better split and since we're not interested in thinking at the moment for now", "tokens": [407, 550, 321, 445, 643, 281, 915, 1101, 7472, 293, 1670, 321, 434, 406, 3102, 294, 1953, 412, 264, 1623, 337, 586], "temperature": 0.0, "avg_logprob": -0.1432164510091146, "compression_ratio": 1.5606060606060606, "no_speech_prob": 2.1907760583417257e-06}, {"id": 340, "seek": 165428, "start": 1670.1399999999999, "end": 1671.76, "text": " We're just going to leave that empty", "tokens": [492, 434, 445, 516, 281, 1856, 300, 6707], "temperature": 0.0, "avg_logprob": -0.1432164510091146, "compression_ratio": 1.5606060606060606, "no_speech_prob": 2.1907760583417257e-06}, {"id": 341, "seek": 165428, "start": 1671.76, "end": 1673.48, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.1432164510091146, "compression_ratio": 1.5606060606060606, "no_speech_prob": 2.1907760583417257e-06}, {"id": 342, "seek": 165428, "start": 1673.48, "end": 1675.48, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.1432164510091146, "compression_ratio": 1.5606060606060606, "no_speech_prob": 2.1907760583417257e-06}, {"id": 343, "seek": 165428, "start": 1675.72, "end": 1677.72, "text": " The one other thing I like to do", "tokens": [440, 472, 661, 551, 286, 411, 281, 360], "temperature": 0.0, "avg_logprob": -0.1432164510091146, "compression_ratio": 1.5606060606060606, "no_speech_prob": 2.1907760583417257e-06}, {"id": 344, "seek": 167772, "start": 1677.72, "end": 1684.34, "text": " With my kind of where I start writing a class is I like to have some way to print out what's in that class", "tokens": [2022, 452, 733, 295, 689, 286, 722, 3579, 257, 1508, 307, 286, 411, 281, 362, 512, 636, 281, 4482, 484, 437, 311, 294, 300, 1508], "temperature": 0.0, "avg_logprob": -0.2294906102693998, "compression_ratio": 1.7300380228136882, "no_speech_prob": 3.0894777864887146e-06}, {"id": 345, "seek": 167772, "start": 1684.48, "end": 1690.96, "text": " Right and so if you type print followed by an object or if it Jupiter notebook you just type the name of the object", "tokens": [1779, 293, 370, 498, 291, 2010, 4482, 6263, 538, 364, 2657, 420, 498, 309, 24567, 21060, 291, 445, 2010, 264, 1315, 295, 264, 2657], "temperature": 0.0, "avg_logprob": -0.2294906102693998, "compression_ratio": 1.7300380228136882, "no_speech_prob": 3.0894777864887146e-06}, {"id": 346, "seek": 167772, "start": 1692.44, "end": 1694.94, "text": " At the moment it's just printing out", "tokens": [1711, 264, 1623, 309, 311, 445, 14699, 484], "temperature": 0.0, "avg_logprob": -0.2294906102693998, "compression_ratio": 1.7300380228136882, "no_speech_prob": 3.0894777864887146e-06}, {"id": 347, "seek": 167772, "start": 1695.72, "end": 1703.22, "text": " Underscore underscore main underscore underscore decision tree at blah blah blah which is not very helpful right so if we want to replace this with", "tokens": [2719, 433, 12352, 37556, 2135, 37556, 37556, 3537, 4230, 412, 12288, 12288, 12288, 597, 307, 406, 588, 4961, 558, 370, 498, 321, 528, 281, 7406, 341, 365], "temperature": 0.0, "avg_logprob": -0.2294906102693998, "compression_ratio": 1.7300380228136882, "no_speech_prob": 3.0894777864887146e-06}, {"id": 348, "seek": 167772, "start": 1703.22, "end": 1706.38, "text": " Something helpful we have to define the special", "tokens": [6595, 4961, 321, 362, 281, 6964, 264, 2121], "temperature": 0.0, "avg_logprob": -0.2294906102693998, "compression_ratio": 1.7300380228136882, "no_speech_prob": 3.0894777864887146e-06}, {"id": 349, "seek": 170638, "start": 1706.38, "end": 1708.38, "text": " Python method name", "tokens": [15329, 3170, 1315], "temperature": 0.0, "avg_logprob": -0.22922136783599853, "compression_ratio": 1.6237623762376239, "no_speech_prob": 1.5534940303041367e-06}, {"id": 350, "seek": 170638, "start": 1709.0600000000002, "end": 1711.0600000000002, "text": " Dunder repra", "tokens": [413, 6617, 1085, 424], "temperature": 0.0, "avg_logprob": -0.22922136783599853, "compression_ratio": 1.6237623762376239, "no_speech_prob": 1.5534940303041367e-06}, {"id": 351, "seek": 170638, "start": 1711.0600000000002, "end": 1716.8200000000002, "text": " To get a representation of this object so when we when we basically just", "tokens": [1407, 483, 257, 10290, 295, 341, 2657, 370, 562, 321, 562, 321, 1936, 445], "temperature": 0.0, "avg_logprob": -0.22922136783599853, "compression_ratio": 1.6237623762376239, "no_speech_prob": 1.5534940303041367e-06}, {"id": 352, "seek": 170638, "start": 1717.5, "end": 1722.0400000000002, "text": " Write the name like this behind the scenes that calls that function and the default", "tokens": [23499, 264, 1315, 411, 341, 2261, 264, 8026, 300, 5498, 300, 2445, 293, 264, 7576], "temperature": 0.0, "avg_logprob": -0.22922136783599853, "compression_ratio": 1.6237623762376239, "no_speech_prob": 1.5534940303041367e-06}, {"id": 353, "seek": 170638, "start": 1722.7800000000002, "end": 1726.1000000000001, "text": " Implementation of that method is just to print out this", "tokens": [4331, 781, 19631, 295, 300, 3170, 307, 445, 281, 4482, 484, 341], "temperature": 0.0, "avg_logprob": -0.22922136783599853, "compression_ratio": 1.6237623762376239, "no_speech_prob": 1.5534940303041367e-06}, {"id": 354, "seek": 170638, "start": 1726.98, "end": 1732.0800000000002, "text": " Unhelpful stuff so we can replace it by instead saying let's create a format string", "tokens": [1156, 37451, 906, 1507, 370, 321, 393, 7406, 309, 538, 2602, 1566, 718, 311, 1884, 257, 7877, 6798], "temperature": 0.0, "avg_logprob": -0.22922136783599853, "compression_ratio": 1.6237623762376239, "no_speech_prob": 1.5534940303041367e-06}, {"id": 355, "seek": 173208, "start": 1732.08, "end": 1739.32, "text": " Where we're going to print out n and then show n and then print val and then show val okay, so how many?", "tokens": [2305, 321, 434, 516, 281, 4482, 484, 297, 293, 550, 855, 297, 293, 550, 4482, 1323, 293, 550, 855, 1323, 1392, 11, 370, 577, 867, 30], "temperature": 0.0, "avg_logprob": -0.1596209452702449, "compression_ratio": 1.8125, "no_speech_prob": 9.276340051656007e-07}, {"id": 356, "seek": 173208, "start": 1740.04, "end": 1746.1999999999998, "text": " How many rows are in this node and what's the average of the dependent variable okay?", "tokens": [1012, 867, 13241, 366, 294, 341, 9984, 293, 437, 311, 264, 4274, 295, 264, 12334, 7006, 1392, 30], "temperature": 0.0, "avg_logprob": -0.1596209452702449, "compression_ratio": 1.8125, "no_speech_prob": 9.276340051656007e-07}, {"id": 357, "seek": 173208, "start": 1747.48, "end": 1754.12, "text": " Then if it's not a leaf node so if it has a split then we should also be able to print out the score", "tokens": [1396, 498, 309, 311, 406, 257, 10871, 9984, 370, 498, 309, 575, 257, 7472, 550, 321, 820, 611, 312, 1075, 281, 4482, 484, 264, 6175], "temperature": 0.0, "avg_logprob": -0.1596209452702449, "compression_ratio": 1.8125, "no_speech_prob": 9.276340051656007e-07}, {"id": 358, "seek": 173208, "start": 1755.12, "end": 1758.84, "text": " The value we split out and the variable that we split on", "tokens": [440, 2158, 321, 7472, 484, 293, 264, 7006, 300, 321, 7472, 322], "temperature": 0.0, "avg_logprob": -0.1596209452702449, "compression_ratio": 1.8125, "no_speech_prob": 9.276340051656007e-07}, {"id": 359, "seek": 175884, "start": 1758.84, "end": 1760.84, "text": " Now you'll notice here", "tokens": [823, 291, 603, 3449, 510], "temperature": 0.0, "avg_logprob": -0.3267904097034085, "compression_ratio": 1.7104072398190044, "no_speech_prob": 1.586999189839844e-07}, {"id": 360, "seek": 175884, "start": 1761.08, "end": 1767.28, "text": " Self dot is leaf is leaf is defined as a method, but I don't have any parentheses after it", "tokens": [16348, 5893, 307, 10871, 307, 10871, 307, 7642, 382, 257, 3170, 11, 457, 286, 500, 380, 362, 604, 34153, 934, 309], "temperature": 0.0, "avg_logprob": -0.3267904097034085, "compression_ratio": 1.7104072398190044, "no_speech_prob": 1.586999189839844e-07}, {"id": 361, "seek": 175884, "start": 1767.8, "end": 1775.24, "text": " This is a special kind of method called a property and so a property is something that kind of looks like a regular", "tokens": [639, 307, 257, 2121, 733, 295, 3170, 1219, 257, 4707, 293, 370, 257, 4707, 307, 746, 300, 733, 295, 1542, 411, 257, 3890], "temperature": 0.0, "avg_logprob": -0.3267904097034085, "compression_ratio": 1.7104072398190044, "no_speech_prob": 1.586999189839844e-07}, {"id": 362, "seek": 175884, "start": 1775.9199999999998, "end": 1783.1599999999999, "text": " Variable, but it's actually calculated on the fly so when I call its leaf it actually calls", "tokens": [32511, 712, 11, 457, 309, 311, 767, 15598, 322, 264, 3603, 370, 562, 286, 818, 1080, 10871, 309, 767, 5498], "temperature": 0.0, "avg_logprob": -0.3267904097034085, "compression_ratio": 1.7104072398190044, "no_speech_prob": 1.586999189839844e-07}, {"id": 363, "seek": 175884, "start": 1783.6799999999998, "end": 1786.8799999999999, "text": " This function right, but I've got this special decorator", "tokens": [639, 2445, 558, 11, 457, 286, 600, 658, 341, 2121, 7919, 1639], "temperature": 0.0, "avg_logprob": -0.3267904097034085, "compression_ratio": 1.7104072398190044, "no_speech_prob": 1.586999189839844e-07}, {"id": 364, "seek": 178688, "start": 1786.88, "end": 1788.16, "text": " property", "tokens": [4707], "temperature": 0.0, "avg_logprob": -0.39473826910859794, "compression_ratio": 1.683168316831683, "no_speech_prob": 7.571141509288282e-07}, {"id": 365, "seek": 178688, "start": 1788.16, "end": 1793.0800000000002, "text": " Okay, and what this says is basically you don't have to include the parentheses when you call it", "tokens": [1033, 11, 293, 437, 341, 1619, 307, 1936, 291, 500, 380, 362, 281, 4090, 264, 34153, 562, 291, 818, 309], "temperature": 0.0, "avg_logprob": -0.39473826910859794, "compression_ratio": 1.683168316831683, "no_speech_prob": 7.571141509288282e-07}, {"id": 366, "seek": 178688, "start": 1794.16, "end": 1800.0, "text": " Okay, and so it's going to say all right is this a leaf or not so a leaf is", "tokens": [1033, 11, 293, 370, 309, 311, 516, 281, 584, 439, 558, 307, 341, 257, 10871, 420, 406, 370, 257, 10871, 307], "temperature": 0.0, "avg_logprob": -0.39473826910859794, "compression_ratio": 1.683168316831683, "no_speech_prob": 7.571141509288282e-07}, {"id": 367, "seek": 178688, "start": 1800.48, "end": 1805.92, "text": " Something that we don't spit on if we haven't split on it then its score is still set to infinity", "tokens": [6595, 300, 321, 500, 380, 22127, 322, 498, 321, 2378, 380, 7472, 322, 309, 550, 1080, 6175, 307, 920, 992, 281, 13202], "temperature": 0.0, "avg_logprob": -0.39473826910859794, "compression_ratio": 1.683168316831683, "no_speech_prob": 7.571141509288282e-07}, {"id": 368, "seek": 178688, "start": 1806.24, "end": 1808.24, "text": " So that's my logic", "tokens": [407, 300, 311, 452, 9952], "temperature": 0.0, "avg_logprob": -0.39473826910859794, "compression_ratio": 1.683168316831683, "no_speech_prob": 7.571141509288282e-07}, {"id": 369, "seek": 178688, "start": 1808.48, "end": 1810.48, "text": " That makes sense", "tokens": [663, 1669, 2020], "temperature": 0.0, "avg_logprob": -0.39473826910859794, "compression_ratio": 1.683168316831683, "no_speech_prob": 7.571141509288282e-07}, {"id": 370, "seek": 178688, "start": 1811.0400000000002, "end": 1814.68, "text": " so this this at notation", "tokens": [370, 341, 341, 412, 24657], "temperature": 0.0, "avg_logprob": -0.39473826910859794, "compression_ratio": 1.683168316831683, "no_speech_prob": 7.571141509288282e-07}, {"id": 371, "seek": 181468, "start": 1814.68, "end": 1819.52, "text": " This at notation is called a decorator. It's basically a way of", "tokens": [639, 412, 24657, 307, 1219, 257, 7919, 1639, 13, 467, 311, 1936, 257, 636, 295], "temperature": 0.0, "avg_logprob": -0.344981544896176, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.1189404176548123e-06}, {"id": 372, "seek": 181468, "start": 1820.2, "end": 1823.3200000000002, "text": " Telling Python more information about your method", "tokens": [5115, 278, 15329, 544, 1589, 466, 428, 3170], "temperature": 0.0, "avg_logprob": -0.344981544896176, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.1189404176548123e-06}, {"id": 373, "seek": 181468, "start": 1823.88, "end": 1828.18, "text": " Does anybody here remember where you have seen decorators before?", "tokens": [4402, 4472, 510, 1604, 689, 291, 362, 1612, 7919, 3391, 949, 30], "temperature": 0.0, "avg_logprob": -0.344981544896176, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.1189404176548123e-06}, {"id": 374, "seek": 181468, "start": 1830.48, "end": 1832.48, "text": " You pass it over here", "tokens": [509, 1320, 309, 670, 510], "temperature": 0.0, "avg_logprob": -0.344981544896176, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.1189404176548123e-06}, {"id": 375, "seek": 181468, "start": 1833.0, "end": 1837.8, "text": " Yeah, where have you seen that where have you seen decorators last tell us more about flask and where how it uses that", "tokens": [865, 11, 689, 362, 291, 1612, 300, 689, 362, 291, 1612, 7919, 3391, 1036, 980, 505, 544, 466, 932, 3863, 293, 689, 577, 309, 4960, 300], "temperature": 0.0, "avg_logprob": -0.344981544896176, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.1189404176548123e-06}, {"id": 376, "seek": 181468, "start": 1837.8, "end": 1839.8, "text": " It was the at app route", "tokens": [467, 390, 264, 412, 724, 7955], "temperature": 0.0, "avg_logprob": -0.344981544896176, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.1189404176548123e-06}, {"id": 377, "seek": 181468, "start": 1839.92, "end": 1841.92, "text": " Yeah, what does that do?", "tokens": [865, 11, 437, 775, 300, 360, 30], "temperature": 0.0, "avg_logprob": -0.344981544896176, "compression_ratio": 1.7083333333333333, "no_speech_prob": 1.1189404176548123e-06}, {"id": 378, "seek": 184192, "start": 1841.92, "end": 1843.92, "text": " that", "tokens": [300], "temperature": 0.0, "avg_logprob": -0.20674731407636476, "compression_ratio": 1.5198019801980198, "no_speech_prob": 1.2098619208700256e-06}, {"id": 379, "seek": 184192, "start": 1844.72, "end": 1846.72, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.20674731407636476, "compression_ratio": 1.5198019801980198, "no_speech_prob": 1.2098619208700256e-06}, {"id": 380, "seek": 184192, "start": 1847.0800000000002, "end": 1853.96, "text": " So flask so anybody who's done any web programming before with something like flask or a similar framework", "tokens": [407, 932, 3863, 370, 4472, 567, 311, 1096, 604, 3670, 9410, 949, 365, 746, 411, 932, 3863, 420, 257, 2531, 8388], "temperature": 0.0, "avg_logprob": -0.20674731407636476, "compression_ratio": 1.5198019801980198, "no_speech_prob": 1.2098619208700256e-06}, {"id": 381, "seek": 184192, "start": 1854.5600000000002, "end": 1858.72, "text": " Would have had to have said like this method is going to respond to this", "tokens": [6068, 362, 632, 281, 362, 848, 411, 341, 3170, 307, 516, 281, 4196, 281, 341], "temperature": 0.0, "avg_logprob": -0.20674731407636476, "compression_ratio": 1.5198019801980198, "no_speech_prob": 1.2098619208700256e-06}, {"id": 382, "seek": 184192, "start": 1858.96, "end": 1865.04, "text": " Bit of the URL and either to post or to get and you put it in a special decorator", "tokens": [9101, 295, 264, 12905, 293, 2139, 281, 2183, 420, 281, 483, 293, 291, 829, 309, 294, 257, 2121, 7919, 1639], "temperature": 0.0, "avg_logprob": -0.20674731407636476, "compression_ratio": 1.5198019801980198, "no_speech_prob": 1.2098619208700256e-06}, {"id": 383, "seek": 184192, "start": 1866.0800000000002, "end": 1867.68, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.20674731407636476, "compression_ratio": 1.5198019801980198, "no_speech_prob": 1.2098619208700256e-06}, {"id": 384, "seek": 184192, "start": 1867.68, "end": 1869.68, "text": " Behind the scenes that's telling", "tokens": [20475, 264, 8026, 300, 311, 3585], "temperature": 0.0, "avg_logprob": -0.20674731407636476, "compression_ratio": 1.5198019801980198, "no_speech_prob": 1.2098619208700256e-06}, {"id": 385, "seek": 186968, "start": 1869.68, "end": 1875.04, "text": " Python to treat this method in a special way so here's another decorator, okay?", "tokens": [15329, 281, 2387, 341, 3170, 294, 257, 2121, 636, 370, 510, 311, 1071, 7919, 1639, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.16929295857747395, "compression_ratio": 1.7011070110701108, "no_speech_prob": 4.785068995261099e-06}, {"id": 386, "seek": 186968, "start": 1875.04, "end": 1880.92, "text": " And so you know if you get more advanced with Python you can actually learn how to write your own decorators", "tokens": [400, 370, 291, 458, 498, 291, 483, 544, 7339, 365, 15329, 291, 393, 767, 1466, 577, 281, 2464, 428, 1065, 7919, 3391], "temperature": 0.0, "avg_logprob": -0.16929295857747395, "compression_ratio": 1.7011070110701108, "no_speech_prob": 4.785068995261099e-06}, {"id": 387, "seek": 186968, "start": 1880.92, "end": 1886.0, "text": " Which as was mentioned you know basically insert some additional code, but for now just know", "tokens": [3013, 382, 390, 2835, 291, 458, 1936, 8969, 512, 4497, 3089, 11, 457, 337, 586, 445, 458], "temperature": 0.0, "avg_logprob": -0.16929295857747395, "compression_ratio": 1.7011070110701108, "no_speech_prob": 4.785068995261099e-06}, {"id": 388, "seek": 186968, "start": 1886.24, "end": 1889.48, "text": " there's a bunch of predefined decorators we can use to", "tokens": [456, 311, 257, 3840, 295, 659, 37716, 7919, 3391, 321, 393, 764, 281], "temperature": 0.0, "avg_logprob": -0.16929295857747395, "compression_ratio": 1.7011070110701108, "no_speech_prob": 4.785068995261099e-06}, {"id": 389, "seek": 186968, "start": 1890.4, "end": 1896.5600000000002, "text": " Change how our methods behave and one of them is at property which basically means you don't have to put parentheses anymore", "tokens": [15060, 577, 527, 7150, 15158, 293, 472, 295, 552, 307, 412, 4707, 597, 1936, 1355, 291, 500, 380, 362, 281, 829, 34153, 3602], "temperature": 0.0, "avg_logprob": -0.16929295857747395, "compression_ratio": 1.7011070110701108, "no_speech_prob": 4.785068995261099e-06}, {"id": 390, "seek": 189656, "start": 1896.56, "end": 1900.2, "text": " Which of course means you can't add any more parameters beyond self", "tokens": [3013, 295, 1164, 1355, 291, 393, 380, 909, 604, 544, 9834, 4399, 2698], "temperature": 0.0, "avg_logprob": -0.2369518665352253, "compression_ratio": 1.7894736842105263, "no_speech_prob": 2.3320671971305273e-06}, {"id": 391, "seek": 189656, "start": 1901.08, "end": 1903.08, "text": " Yep", "tokens": [7010], "temperature": 0.0, "avg_logprob": -0.2369518665352253, "compression_ratio": 1.7894736842105263, "no_speech_prob": 2.3320671971305273e-06}, {"id": 392, "seek": 189656, "start": 1903.12, "end": 1907.36, "text": " Why if it's not a leaf why is the score infinity?", "tokens": [1545, 498, 309, 311, 406, 257, 10871, 983, 307, 264, 6175, 13202, 30], "temperature": 0.0, "avg_logprob": -0.2369518665352253, "compression_ratio": 1.7894736842105263, "no_speech_prob": 2.3320671971305273e-06}, {"id": 393, "seek": 189656, "start": 1908.3999999999999, "end": 1910.6399999999999, "text": " Because it's an infinity mean you're at the root", "tokens": [1436, 309, 311, 364, 13202, 914, 291, 434, 412, 264, 5593], "temperature": 0.0, "avg_logprob": -0.2369518665352253, "compression_ratio": 1.7894736842105263, "no_speech_prob": 2.3320671971305273e-06}, {"id": 394, "seek": 189656, "start": 1911.6799999999998, "end": 1917.96, "text": " Why no infinity means that you're not at the root it means you're at a leaf so the root will have a split", "tokens": [1545, 572, 13202, 1355, 300, 291, 434, 406, 412, 264, 5593, 309, 1355, 291, 434, 412, 257, 10871, 370, 264, 5593, 486, 362, 257, 7472], "temperature": 0.0, "avg_logprob": -0.2369518665352253, "compression_ratio": 1.7894736842105263, "no_speech_prob": 2.3320671971305273e-06}, {"id": 395, "seek": 189656, "start": 1918.56, "end": 1922.76, "text": " Assuming we find one yeah, but everything will have a split till we get all the way to the bottom", "tokens": [6281, 24919, 321, 915, 472, 1338, 11, 457, 1203, 486, 362, 257, 7472, 4288, 321, 483, 439, 264, 636, 281, 264, 2767], "temperature": 0.0, "avg_logprob": -0.2369518665352253, "compression_ratio": 1.7894736842105263, "no_speech_prob": 2.3320671971305273e-06}, {"id": 396, "seek": 192276, "start": 1922.76, "end": 1927.92, "text": " The leaf and so the leaves will have a score of infinity because they won't split", "tokens": [440, 10871, 293, 370, 264, 5510, 486, 362, 257, 6175, 295, 13202, 570, 436, 1582, 380, 7472], "temperature": 0.0, "avg_logprob": -0.2206012640106544, "compression_ratio": 1.6407766990291262, "no_speech_prob": 7.183233265095623e-06}, {"id": 397, "seek": 192276, "start": 1929.68, "end": 1931.68, "text": " Great all right", "tokens": [3769, 439, 558], "temperature": 0.0, "avg_logprob": -0.2206012640106544, "compression_ratio": 1.6407766990291262, "no_speech_prob": 7.183233265095623e-06}, {"id": 398, "seek": 192276, "start": 1932.56, "end": 1934.56, "text": " so that's our", "tokens": [370, 300, 311, 527], "temperature": 0.0, "avg_logprob": -0.2206012640106544, "compression_ratio": 1.6407766990291262, "no_speech_prob": 7.183233265095623e-06}, {"id": 399, "seek": 192276, "start": 1935.08, "end": 1939.28, "text": " Decision tree it doesn't do very much, but at least we can like create an ensemble", "tokens": [12427, 1991, 4230, 309, 1177, 380, 360, 588, 709, 11, 457, 412, 1935, 321, 393, 411, 1884, 364, 19492], "temperature": 0.0, "avg_logprob": -0.2206012640106544, "compression_ratio": 1.6407766990291262, "no_speech_prob": 7.183233265095623e-06}, {"id": 400, "seek": 192276, "start": 1939.72, "end": 1946.02, "text": " Right ten trees sample size a thousand right and we can like print out so now when I go m trees zero", "tokens": [1779, 2064, 5852, 6889, 2744, 257, 4714, 558, 293, 321, 393, 411, 4482, 484, 370, 586, 562, 286, 352, 275, 5852, 4018], "temperature": 0.0, "avg_logprob": -0.2206012640106544, "compression_ratio": 1.6407766990291262, "no_speech_prob": 7.183233265095623e-06}, {"id": 401, "seek": 192276, "start": 1946.24, "end": 1949.32, "text": " It doesn't say blah blah blah blah it says", "tokens": [467, 1177, 380, 584, 12288, 12288, 12288, 12288, 309, 1619], "temperature": 0.0, "avg_logprob": -0.2206012640106544, "compression_ratio": 1.6407766990291262, "no_speech_prob": 7.183233265095623e-06}, {"id": 402, "seek": 194932, "start": 1949.32, "end": 1955.56, "text": " What we asked it to say and call the thousand foul colon ten point eight oh wait", "tokens": [708, 321, 2351, 309, 281, 584, 293, 818, 264, 4714, 23491, 8255, 2064, 935, 3180, 1954, 1699], "temperature": 0.0, "avg_logprob": -0.20327486642977086, "compression_ratio": 1.6770833333333333, "no_speech_prob": 1.3081737506581703e-06}, {"id": 403, "seek": 194932, "start": 1956.0, "end": 1961.9399999999998, "text": " Okay, and this is a leaf because we haven't spit on it yet, so we've got nothing more to say", "tokens": [1033, 11, 293, 341, 307, 257, 10871, 570, 321, 2378, 380, 22127, 322, 309, 1939, 11, 370, 321, 600, 658, 1825, 544, 281, 584], "temperature": 0.0, "avg_logprob": -0.20327486642977086, "compression_ratio": 1.6770833333333333, "no_speech_prob": 1.3081737506581703e-06}, {"id": 404, "seek": 194932, "start": 1963.9199999999998, "end": 1968.84, "text": " Okay, so then the indexes are all the numbers from naught to a thousand", "tokens": [1033, 11, 370, 550, 264, 8186, 279, 366, 439, 264, 3547, 490, 13138, 281, 257, 4714], "temperature": 0.0, "avg_logprob": -0.20327486642977086, "compression_ratio": 1.6770833333333333, "no_speech_prob": 1.3081737506581703e-06}, {"id": 405, "seek": 194932, "start": 1969.84, "end": 1974.56, "text": " Okay, because the base of the tree has everything this is like everything in", "tokens": [1033, 11, 570, 264, 3096, 295, 264, 4230, 575, 1203, 341, 307, 411, 1203, 294], "temperature": 0.0, "avg_logprob": -0.20327486642977086, "compression_ratio": 1.6770833333333333, "no_speech_prob": 1.3081737506581703e-06}, {"id": 406, "seek": 197456, "start": 1974.56, "end": 1979.8799999999999, "text": " The random sample that was passed to it because remember by the time we get to the point where it's a decision tree", "tokens": [440, 4974, 6889, 300, 390, 4678, 281, 309, 570, 1604, 538, 264, 565, 321, 483, 281, 264, 935, 689, 309, 311, 257, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.14212450417139197, "compression_ratio": 1.6255506607929515, "no_speech_prob": 5.98926476413908e-07}, {"id": 407, "seek": 197456, "start": 1980.28, "end": 1984.6, "text": " Where we don't have to worry about any of the randomness in the random forest anymore?", "tokens": [2305, 321, 500, 380, 362, 281, 3292, 466, 604, 295, 264, 4974, 1287, 294, 264, 4974, 6719, 3602, 30], "temperature": 0.0, "avg_logprob": -0.14212450417139197, "compression_ratio": 1.6255506607929515, "no_speech_prob": 5.98926476413908e-07}, {"id": 408, "seek": 197456, "start": 1987.1599999999999, "end": 1989.1599999999999, "text": " All right, so", "tokens": [1057, 558, 11, 370], "temperature": 0.0, "avg_logprob": -0.14212450417139197, "compression_ratio": 1.6255506607929515, "no_speech_prob": 5.98926476413908e-07}, {"id": 409, "seek": 197456, "start": 1989.8, "end": 1996.72, "text": " Let's try to write the thing which finds a split okay, so we need to implement", "tokens": [961, 311, 853, 281, 2464, 264, 551, 597, 10704, 257, 7472, 1392, 11, 370, 321, 643, 281, 4445], "temperature": 0.0, "avg_logprob": -0.14212450417139197, "compression_ratio": 1.6255506607929515, "no_speech_prob": 5.98926476413908e-07}, {"id": 410, "seek": 199672, "start": 1996.72, "end": 2006.28, "text": " Find better split okay, and so it's going to take the index of a variable variable number one variable number three", "tokens": [11809, 1101, 7472, 1392, 11, 293, 370, 309, 311, 516, 281, 747, 264, 8186, 295, 257, 7006, 7006, 1230, 472, 7006, 1230, 1045], "temperature": 0.0, "avg_logprob": -0.17215080475539304, "compression_ratio": 1.75, "no_speech_prob": 5.0147045840276405e-06}, {"id": 411, "seek": 199672, "start": 2006.28, "end": 2008.28, "text": " Whatever and it's going to figure out", "tokens": [8541, 293, 309, 311, 516, 281, 2573, 484], "temperature": 0.0, "avg_logprob": -0.17215080475539304, "compression_ratio": 1.75, "no_speech_prob": 5.0147045840276405e-06}, {"id": 412, "seek": 199672, "start": 2009.48, "end": 2011.48, "text": " What's the best split point?", "tokens": [708, 311, 264, 1151, 7472, 935, 30], "temperature": 0.0, "avg_logprob": -0.17215080475539304, "compression_ratio": 1.75, "no_speech_prob": 5.0147045840276405e-06}, {"id": 413, "seek": 199672, "start": 2011.6000000000001, "end": 2014.1200000000001, "text": " Is that better than any split we have so far and?", "tokens": [1119, 300, 1101, 813, 604, 7472, 321, 362, 370, 1400, 293, 30], "temperature": 0.0, "avg_logprob": -0.17215080475539304, "compression_ratio": 1.75, "no_speech_prob": 5.0147045840276405e-06}, {"id": 414, "seek": 199672, "start": 2014.96, "end": 2020.8600000000001, "text": " For the first variable the answer will always be yes because the best one so far is none at all which is infinity bad, okay?", "tokens": [1171, 264, 700, 7006, 264, 1867, 486, 1009, 312, 2086, 570, 264, 1151, 472, 370, 1400, 307, 6022, 412, 439, 597, 307, 13202, 1578, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.17215080475539304, "compression_ratio": 1.75, "no_speech_prob": 5.0147045840276405e-06}, {"id": 415, "seek": 202086, "start": 2020.86, "end": 2028.5, "text": " So let's start by making sure we've got something to compare to so the thing we're going to compare to will be", "tokens": [407, 718, 311, 722, 538, 1455, 988, 321, 600, 658, 746, 281, 6794, 281, 370, 264, 551, 321, 434, 516, 281, 6794, 281, 486, 312], "temperature": 0.0, "avg_logprob": -0.14659426609675089, "compression_ratio": 1.7819905213270142, "no_speech_prob": 1.436747425032081e-06}, {"id": 416, "seek": 202086, "start": 2028.9799999999998, "end": 2030.9799999999998, "text": " scikit-learns random forest and", "tokens": [2180, 22681, 12, 306, 1083, 82, 4974, 6719, 293], "temperature": 0.0, "avg_logprob": -0.14659426609675089, "compression_ratio": 1.7819905213270142, "no_speech_prob": 1.436747425032081e-06}, {"id": 417, "seek": 202086, "start": 2031.58, "end": 2038.1799999999998, "text": " So we need to make sure that scikit-learns random forest gets exactly the same data that we have so we start out by creating ensemble", "tokens": [407, 321, 643, 281, 652, 988, 300, 2180, 22681, 12, 306, 1083, 82, 4974, 6719, 2170, 2293, 264, 912, 1412, 300, 321, 362, 370, 321, 722, 484, 538, 4084, 19492], "temperature": 0.0, "avg_logprob": -0.14659426609675089, "compression_ratio": 1.7819905213270142, "no_speech_prob": 1.436747425032081e-06}, {"id": 418, "seek": 202086, "start": 2039.1, "end": 2046.2199999999998, "text": " Grab a tree out of it and then find out which particular random sample of X and Y did this tree use", "tokens": [20357, 257, 4230, 484, 295, 309, 293, 550, 915, 484, 597, 1729, 4974, 6889, 295, 1783, 293, 398, 630, 341, 4230, 764], "temperature": 0.0, "avg_logprob": -0.14659426609675089, "compression_ratio": 1.7819905213270142, "no_speech_prob": 1.436747425032081e-06}, {"id": 419, "seek": 204622, "start": 2046.22, "end": 2052.9, "text": " Okay, and we're going to store them away so that we can pass them to scikit-learn so we have exactly the same information", "tokens": [1033, 11, 293, 321, 434, 516, 281, 3531, 552, 1314, 370, 300, 321, 393, 1320, 552, 281, 2180, 22681, 12, 306, 1083, 370, 321, 362, 2293, 264, 912, 1589], "temperature": 0.0, "avg_logprob": -0.130316618717078, "compression_ratio": 1.7864077669902914, "no_speech_prob": 2.0904528810206102e-06}, {"id": 420, "seek": 204622, "start": 2054.46, "end": 2059.06, "text": " So let's go ahead and now create our random forest using scikit-learn so one tree", "tokens": [407, 718, 311, 352, 2286, 293, 586, 1884, 527, 4974, 6719, 1228, 2180, 22681, 12, 306, 1083, 370, 472, 4230], "temperature": 0.0, "avg_logprob": -0.130316618717078, "compression_ratio": 1.7864077669902914, "no_speech_prob": 2.0904528810206102e-06}, {"id": 421, "seek": 204622, "start": 2059.9, "end": 2061.58, "text": " one decision", "tokens": [472, 3537], "temperature": 0.0, "avg_logprob": -0.130316618717078, "compression_ratio": 1.7864077669902914, "no_speech_prob": 2.0904528810206102e-06}, {"id": 422, "seek": 204622, "start": 2061.58, "end": 2066.2200000000003, "text": " No bootstrapping so the whole the whole data set that so this should", "tokens": [883, 11450, 19639, 3759, 370, 264, 1379, 264, 1379, 1412, 992, 300, 370, 341, 820], "temperature": 0.0, "avg_logprob": -0.130316618717078, "compression_ratio": 1.7864077669902914, "no_speech_prob": 2.0904528810206102e-06}, {"id": 423, "seek": 204622, "start": 2067.1, "end": 2070.62, "text": " Be exactly the same as the thing that we're going to create this tree", "tokens": [879, 2293, 264, 912, 382, 264, 551, 300, 321, 434, 516, 281, 1884, 341, 4230], "temperature": 0.0, "avg_logprob": -0.130316618717078, "compression_ratio": 1.7864077669902914, "no_speech_prob": 2.0904528810206102e-06}, {"id": 424, "seek": 204622, "start": 2072.66, "end": 2074.66, "text": " So let's try", "tokens": [407, 718, 311, 853], "temperature": 0.0, "avg_logprob": -0.130316618717078, "compression_ratio": 1.7864077669902914, "no_speech_prob": 2.0904528810206102e-06}, {"id": 425, "seek": 207466, "start": 2074.66, "end": 2076.66, "text": " So we need to define", "tokens": [407, 321, 643, 281, 6964], "temperature": 0.0, "avg_logprob": -0.23874733246952654, "compression_ratio": 1.6473684210526316, "no_speech_prob": 1.248267608389142e-06}, {"id": 426, "seek": 207466, "start": 2077.62, "end": 2079.62, "text": " Find better split", "tokens": [11809, 1101, 7472], "temperature": 0.0, "avg_logprob": -0.23874733246952654, "compression_ratio": 1.6473684210526316, "no_speech_prob": 1.248267608389142e-06}, {"id": 427, "seek": 207466, "start": 2080.1, "end": 2083.42, "text": " Okay, so find better split takes a variable", "tokens": [1033, 11, 370, 915, 1101, 7472, 2516, 257, 7006], "temperature": 0.0, "avg_logprob": -0.23874733246952654, "compression_ratio": 1.6473684210526316, "no_speech_prob": 1.248267608389142e-06}, {"id": 428, "seek": 207466, "start": 2084.1, "end": 2086.2599999999998, "text": " Okay, so let's define our", "tokens": [1033, 11, 370, 718, 311, 6964, 527], "temperature": 0.0, "avg_logprob": -0.23874733246952654, "compression_ratio": 1.6473684210526316, "no_speech_prob": 1.248267608389142e-06}, {"id": 429, "seek": 207466, "start": 2087.02, "end": 2093.2999999999997, "text": " X independent variables and say okay. Well. It's everything inside our tree, but only", "tokens": [1783, 6695, 9102, 293, 584, 1392, 13, 1042, 13, 467, 311, 1203, 1854, 527, 4230, 11, 457, 787], "temperature": 0.0, "avg_logprob": -0.23874733246952654, "compression_ratio": 1.6473684210526316, "no_speech_prob": 1.248267608389142e-06}, {"id": 430, "seek": 207466, "start": 2093.98, "end": 2100.7799999999997, "text": " Those indexes that are in this node, right which at the top of the tree is everything right and just", "tokens": [3950, 8186, 279, 300, 366, 294, 341, 9984, 11, 558, 597, 412, 264, 1192, 295, 264, 4230, 307, 1203, 558, 293, 445], "temperature": 0.0, "avg_logprob": -0.23874733246952654, "compression_ratio": 1.6473684210526316, "no_speech_prob": 1.248267608389142e-06}, {"id": 431, "seek": 207466, "start": 2101.62, "end": 2103.62, "text": " this one variable", "tokens": [341, 472, 7006], "temperature": 0.0, "avg_logprob": -0.23874733246952654, "compression_ratio": 1.6473684210526316, "no_speech_prob": 1.248267608389142e-06}, {"id": 432, "seek": 210362, "start": 2103.62, "end": 2110.18, "text": " Okay, and then for our wise it's just whatever our dependent variable is at the indexes in this node", "tokens": [1033, 11, 293, 550, 337, 527, 10829, 309, 311, 445, 2035, 527, 12334, 7006, 307, 412, 264, 8186, 279, 294, 341, 9984], "temperature": 0.0, "avg_logprob": -0.2080713907877604, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.955104370514164e-06}, {"id": 433, "seek": 210362, "start": 2110.3399999999997, "end": 2112.3399999999997, "text": " Okay, so there's our X and Y", "tokens": [1033, 11, 370, 456, 311, 527, 1783, 293, 398], "temperature": 0.0, "avg_logprob": -0.2080713907877604, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.955104370514164e-06}, {"id": 434, "seek": 210362, "start": 2113.98, "end": 2115.98, "text": " So let's now go through", "tokens": [407, 718, 311, 586, 352, 807], "temperature": 0.0, "avg_logprob": -0.2080713907877604, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.955104370514164e-06}, {"id": 435, "seek": 210362, "start": 2116.22, "end": 2120.58, "text": " every single value in our independent variable and", "tokens": [633, 2167, 2158, 294, 527, 6695, 7006, 293], "temperature": 0.0, "avg_logprob": -0.2080713907877604, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.955104370514164e-06}, {"id": 436, "seek": 210362, "start": 2121.5, "end": 2126.42, "text": " So I'll show you what's going to happen, so let's say our independent variable is EMA", "tokens": [407, 286, 603, 855, 291, 437, 311, 516, 281, 1051, 11, 370, 718, 311, 584, 527, 6695, 7006, 307, 462, 9998], "temperature": 0.0, "avg_logprob": -0.2080713907877604, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.955104370514164e-06}, {"id": 437, "seek": 212642, "start": 2126.42, "end": 2128.42, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.190088685353597, "compression_ratio": 1.5905511811023623, "no_speech_prob": 2.0904524262732593e-06}, {"id": 438, "seek": 212642, "start": 2133.78, "end": 2135.78, "text": " Not going to be an order", "tokens": [1726, 516, 281, 312, 364, 1668], "temperature": 0.0, "avg_logprob": -0.190088685353597, "compression_ratio": 1.5905511811023623, "no_speech_prob": 2.0904524262732593e-06}, {"id": 439, "seek": 212642, "start": 2141.54, "end": 2146.7000000000003, "text": " Right and so we're going to go to the very first row and we're going to say okay", "tokens": [1779, 293, 370, 321, 434, 516, 281, 352, 281, 264, 588, 700, 5386, 293, 321, 434, 516, 281, 584, 1392], "temperature": 0.0, "avg_logprob": -0.190088685353597, "compression_ratio": 1.5905511811023623, "no_speech_prob": 2.0904524262732593e-06}, {"id": 440, "seek": 212642, "start": 2146.7000000000003, "end": 2151.78, "text": " Yeah, mate here is three right and so what I'm going to do is I'm going to try and calculate", "tokens": [865, 11, 11709, 510, 307, 1045, 558, 293, 370, 437, 286, 478, 516, 281, 360, 307, 286, 478, 516, 281, 853, 293, 8873], "temperature": 0.0, "avg_logprob": -0.190088685353597, "compression_ratio": 1.5905511811023623, "no_speech_prob": 2.0904524262732593e-06}, {"id": 441, "seek": 215178, "start": 2151.78, "end": 2156.98, "text": " The score if we decided to branch on the number three", "tokens": [440, 6175, 498, 321, 3047, 281, 9819, 322, 264, 1230, 1045], "temperature": 0.0, "avg_logprob": -0.196725897832748, "compression_ratio": 1.8024193548387097, "no_speech_prob": 2.561277142376639e-06}, {"id": 442, "seek": 215178, "start": 2157.42, "end": 2162.1800000000003, "text": " Right so I need to know which rows are greater than three", "tokens": [1779, 370, 286, 643, 281, 458, 597, 13241, 366, 5044, 813, 1045], "temperature": 0.0, "avg_logprob": -0.196725897832748, "compression_ratio": 1.8024193548387097, "no_speech_prob": 2.561277142376639e-06}, {"id": 443, "seek": 215178, "start": 2162.7000000000003, "end": 2167.38, "text": " Which rows are less than an equal to three and they're going to become my left hand side my right hand side", "tokens": [3013, 13241, 366, 1570, 813, 364, 2681, 281, 1045, 293, 436, 434, 516, 281, 1813, 452, 1411, 1011, 1252, 452, 558, 1011, 1252], "temperature": 0.0, "avg_logprob": -0.196725897832748, "compression_ratio": 1.8024193548387097, "no_speech_prob": 2.561277142376639e-06}, {"id": 444, "seek": 215178, "start": 2167.5, "end": 2169.5, "text": " Right and then we need a score", "tokens": [1779, 293, 550, 321, 643, 257, 6175], "temperature": 0.0, "avg_logprob": -0.196725897832748, "compression_ratio": 1.8024193548387097, "no_speech_prob": 2.561277142376639e-06}, {"id": 445, "seek": 215178, "start": 2169.7000000000003, "end": 2171.42, "text": " right, so", "tokens": [558, 11, 370], "temperature": 0.0, "avg_logprob": -0.196725897832748, "compression_ratio": 1.8024193548387097, "no_speech_prob": 2.561277142376639e-06}, {"id": 446, "seek": 215178, "start": 2171.42, "end": 2174.7400000000002, "text": " There's lots of scores we could use so in random forests", "tokens": [821, 311, 3195, 295, 13444, 321, 727, 764, 370, 294, 4974, 21700], "temperature": 0.0, "avg_logprob": -0.196725897832748, "compression_ratio": 1.8024193548387097, "no_speech_prob": 2.561277142376639e-06}, {"id": 447, "seek": 215178, "start": 2174.7400000000002, "end": 2181.2200000000003, "text": " We call this the information gain right the information gain is like how much better does our score get because we split it into?", "tokens": [492, 818, 341, 264, 1589, 6052, 558, 264, 1589, 6052, 307, 411, 577, 709, 1101, 775, 527, 6175, 483, 570, 321, 7472, 309, 666, 30], "temperature": 0.0, "avg_logprob": -0.196725897832748, "compression_ratio": 1.8024193548387097, "no_speech_prob": 2.561277142376639e-06}, {"id": 448, "seek": 218122, "start": 2181.22, "end": 2188.4199999999996, "text": " These two groups of data there's lots of ways we could calculate it Jimmy cross entropy root mean squared error whatever", "tokens": [1981, 732, 3935, 295, 1412, 456, 311, 3195, 295, 2098, 321, 727, 8873, 309, 15709, 3278, 30867, 5593, 914, 8889, 6713, 2035], "temperature": 0.0, "avg_logprob": -0.19305761655171713, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.611969304984086e-06}, {"id": 449, "seek": 218122, "start": 2190.02, "end": 2194.2599999999998, "text": " If you think about it there is an alternative formulation of root mean squared error", "tokens": [759, 291, 519, 466, 309, 456, 307, 364, 8535, 37642, 295, 5593, 914, 8889, 6713], "temperature": 0.0, "avg_logprob": -0.19305761655171713, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.611969304984086e-06}, {"id": 450, "seek": 218122, "start": 2194.54, "end": 2198.54, "text": " Which is mathematically the same to within a constant scale?", "tokens": [3013, 307, 44003, 264, 912, 281, 1951, 257, 5754, 4373, 30], "temperature": 0.0, "avg_logprob": -0.19305761655171713, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.611969304984086e-06}, {"id": 451, "seek": 218122, "start": 2198.54, "end": 2203.3799999999997, "text": " But it's a little bit easier to deal with which is we're going to try and find a split", "tokens": [583, 309, 311, 257, 707, 857, 3571, 281, 2028, 365, 597, 307, 321, 434, 516, 281, 853, 293, 915, 257, 7472], "temperature": 0.0, "avg_logprob": -0.19305761655171713, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.611969304984086e-06}, {"id": 452, "seek": 218122, "start": 2203.98, "end": 2209.8199999999997, "text": " Which the causes the two groups to each have as lower standard deviation as possible", "tokens": [3013, 264, 7700, 264, 732, 3935, 281, 1184, 362, 382, 3126, 3832, 25163, 382, 1944], "temperature": 0.0, "avg_logprob": -0.19305761655171713, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.611969304984086e-06}, {"id": 453, "seek": 220982, "start": 2209.82, "end": 2214.98, "text": " All right, so like I want to find a split that puts all the cats over here and all the dogs over here", "tokens": [1057, 558, 11, 370, 411, 286, 528, 281, 915, 257, 7472, 300, 8137, 439, 264, 11111, 670, 510, 293, 439, 264, 7197, 670, 510], "temperature": 0.0, "avg_logprob": -0.15918244085004252, "compression_ratio": 2.0790513833992095, "no_speech_prob": 7.811474915797589e-07}, {"id": 454, "seek": 220982, "start": 2215.1800000000003, "end": 2221.54, "text": " Right so if these are all cats and these are all dogs then this has a standard deviation of zero and this has a standard", "tokens": [1779, 370, 498, 613, 366, 439, 11111, 293, 613, 366, 439, 7197, 550, 341, 575, 257, 3832, 25163, 295, 4018, 293, 341, 575, 257, 3832], "temperature": 0.0, "avg_logprob": -0.15918244085004252, "compression_ratio": 2.0790513833992095, "no_speech_prob": 7.811474915797589e-07}, {"id": 455, "seek": 220982, "start": 2221.54, "end": 2225.46, "text": " Deviation of zero or else. This is like a totally random mix of cats and dogs", "tokens": [48565, 399, 295, 4018, 420, 1646, 13, 639, 307, 411, 257, 3879, 4974, 2890, 295, 11111, 293, 7197], "temperature": 0.0, "avg_logprob": -0.15918244085004252, "compression_ratio": 2.0790513833992095, "no_speech_prob": 7.811474915797589e-07}, {"id": 456, "seek": 220982, "start": 2225.46, "end": 2229.92, "text": " This is a totally random mix of cats and dogs. They're going to have a much higher standard deviation", "tokens": [639, 307, 257, 3879, 4974, 2890, 295, 11111, 293, 7197, 13, 814, 434, 516, 281, 362, 257, 709, 2946, 3832, 25163], "temperature": 0.0, "avg_logprob": -0.15918244085004252, "compression_ratio": 2.0790513833992095, "no_speech_prob": 7.811474915797589e-07}, {"id": 457, "seek": 220982, "start": 2230.7000000000003, "end": 2238.0800000000004, "text": " That makes sense and so it turns out if you find a split that minimizes those group standard deviations or specifically the", "tokens": [663, 1669, 2020, 293, 370, 309, 4523, 484, 498, 291, 915, 257, 7472, 300, 4464, 5660, 729, 1594, 3832, 31219, 763, 420, 4682, 264], "temperature": 0.0, "avg_logprob": -0.15918244085004252, "compression_ratio": 2.0790513833992095, "no_speech_prob": 7.811474915797589e-07}, {"id": 458, "seek": 223808, "start": 2238.08, "end": 2244.2799999999997, "text": " Weighted average of the two standard deviations. It's mathematically the same as minimizing the root mean squared error", "tokens": [44464, 292, 4274, 295, 264, 732, 3832, 31219, 763, 13, 467, 311, 44003, 264, 912, 382, 46608, 264, 5593, 914, 8889, 6713], "temperature": 0.0, "avg_logprob": -0.1722473246710641, "compression_ratio": 1.8185328185328185, "no_speech_prob": 1.5056991742312675e-06}, {"id": 459, "seek": 223808, "start": 2244.3199999999997, "end": 2247.88, "text": " That's something you can prove to yourself after class if you want to", "tokens": [663, 311, 746, 291, 393, 7081, 281, 1803, 934, 1508, 498, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.1722473246710641, "compression_ratio": 1.8185328185328185, "no_speech_prob": 1.5056991742312675e-06}, {"id": 460, "seek": 223808, "start": 2248.92, "end": 2250.92, "text": " All right, so we're going to need to find", "tokens": [1057, 558, 11, 370, 321, 434, 516, 281, 643, 281, 915], "temperature": 0.0, "avg_logprob": -0.1722473246710641, "compression_ratio": 1.8185328185328185, "no_speech_prob": 1.5056991742312675e-06}, {"id": 461, "seek": 223808, "start": 2251.96, "end": 2256.74, "text": " First of all split this into two groups. So where's all the stuff that is greater than three?", "tokens": [2386, 295, 439, 7472, 341, 666, 732, 3935, 13, 407, 689, 311, 439, 264, 1507, 300, 307, 5044, 813, 1045, 30], "temperature": 0.0, "avg_logprob": -0.1722473246710641, "compression_ratio": 1.8185328185328185, "no_speech_prob": 1.5056991742312675e-06}, {"id": 462, "seek": 223808, "start": 2257.3199999999997, "end": 2261.72, "text": " So greater than three is this one this one and this one so we need the standard deviation of that", "tokens": [407, 5044, 813, 1045, 307, 341, 472, 341, 472, 293, 341, 472, 370, 321, 643, 264, 3832, 25163, 295, 300], "temperature": 0.0, "avg_logprob": -0.1722473246710641, "compression_ratio": 1.8185328185328185, "no_speech_prob": 1.5056991742312675e-06}, {"id": 463, "seek": 223808, "start": 2262.92, "end": 2265.88, "text": " so let's go ahead and say standard deviation of", "tokens": [370, 718, 311, 352, 2286, 293, 584, 3832, 25163, 295], "temperature": 0.0, "avg_logprob": -0.1722473246710641, "compression_ratio": 1.8185328185328185, "no_speech_prob": 1.5056991742312675e-06}, {"id": 464, "seek": 226588, "start": 2265.88, "end": 2268.8, "text": " greater than three that one", "tokens": [5044, 813, 1045, 300, 472], "temperature": 0.0, "avg_logprob": -0.2630171775817871, "compression_ratio": 1.8641975308641976, "no_speech_prob": 2.5215647383447504e-06}, {"id": 465, "seek": 226588, "start": 2270.08, "end": 2273.76, "text": " that one and that one, okay, and", "tokens": [300, 472, 293, 300, 472, 11, 1392, 11, 293], "temperature": 0.0, "avg_logprob": -0.2630171775817871, "compression_ratio": 1.8641975308641976, "no_speech_prob": 2.5215647383447504e-06}, {"id": 466, "seek": 226588, "start": 2274.76, "end": 2278.56, "text": " then the next will be the standard deviation of", "tokens": [550, 264, 958, 486, 312, 264, 3832, 25163, 295], "temperature": 0.0, "avg_logprob": -0.2630171775817871, "compression_ratio": 1.8641975308641976, "no_speech_prob": 2.5215647383447504e-06}, {"id": 467, "seek": 226588, "start": 2280.0, "end": 2282.82, "text": " Less than or equal to three so that would be that one", "tokens": [18649, 813, 420, 2681, 281, 1045, 370, 300, 576, 312, 300, 472], "temperature": 0.0, "avg_logprob": -0.2630171775817871, "compression_ratio": 1.8641975308641976, "no_speech_prob": 2.5215647383447504e-06}, {"id": 468, "seek": 226588, "start": 2284.2000000000003, "end": 2286.48, "text": " that one that one and", "tokens": [300, 472, 300, 472, 293], "temperature": 0.0, "avg_logprob": -0.2630171775817871, "compression_ratio": 1.8641975308641976, "no_speech_prob": 2.5215647383447504e-06}, {"id": 469, "seek": 226588, "start": 2287.7200000000003, "end": 2290.92, "text": " Then we just take the weighted average of those two and that's our score", "tokens": [1396, 321, 445, 747, 264, 32807, 4274, 295, 729, 732, 293, 300, 311, 527, 6175], "temperature": 0.0, "avg_logprob": -0.2630171775817871, "compression_ratio": 1.8641975308641976, "no_speech_prob": 2.5215647383447504e-06}, {"id": 470, "seek": 229092, "start": 2290.92, "end": 2295.2000000000003, "text": " That would be our score if we split on three", "tokens": [663, 576, 312, 527, 6175, 498, 321, 7472, 322, 1045], "temperature": 0.0, "avg_logprob": -0.2100271124588816, "compression_ratio": 1.875, "no_speech_prob": 1.003012926048541e-06}, {"id": 471, "seek": 229092, "start": 2296.2400000000002, "end": 2302.8, "text": " That makes sense and so then the next step would be try to split on four try splitting on one try splitting on six", "tokens": [663, 1669, 2020, 293, 370, 550, 264, 958, 1823, 576, 312, 853, 281, 7472, 322, 1451, 853, 30348, 322, 472, 853, 30348, 322, 2309], "temperature": 0.0, "avg_logprob": -0.2100271124588816, "compression_ratio": 1.875, "no_speech_prob": 1.003012926048541e-06}, {"id": 472, "seek": 229092, "start": 2304.8, "end": 2306.8, "text": " Redundantly try splitting on four again", "tokens": [4477, 997, 3627, 853, 30348, 322, 1451, 797], "temperature": 0.0, "avg_logprob": -0.2100271124588816, "compression_ratio": 1.875, "no_speech_prob": 1.003012926048541e-06}, {"id": 473, "seek": 229092, "start": 2307.92, "end": 2310.6, "text": " Redundantly try splitting on one again and find out which one works best", "tokens": [4477, 997, 3627, 853, 30348, 322, 472, 797, 293, 915, 484, 597, 472, 1985, 1151], "temperature": 0.0, "avg_logprob": -0.2100271124588816, "compression_ratio": 1.875, "no_speech_prob": 1.003012926048541e-06}, {"id": 474, "seek": 229092, "start": 2311.36, "end": 2317.7200000000003, "text": " So that's our code here is we're going to go through every row and so let's say okay left-hand side is", "tokens": [407, 300, 311, 527, 3089, 510, 307, 321, 434, 516, 281, 352, 807, 633, 5386, 293, 370, 718, 311, 584, 1392, 1411, 12, 5543, 1252, 307], "temperature": 0.0, "avg_logprob": -0.2100271124588816, "compression_ratio": 1.875, "no_speech_prob": 1.003012926048541e-06}, {"id": 475, "seek": 231772, "start": 2317.72, "end": 2324.48, "text": " Any values in X that are less than or equal to this particular value?", "tokens": [2639, 4190, 294, 1783, 300, 366, 1570, 813, 420, 2681, 281, 341, 1729, 2158, 30], "temperature": 0.0, "avg_logprob": -0.1745502414988048, "compression_ratio": 1.5889570552147239, "no_speech_prob": 2.0580403088388266e-06}, {"id": 476, "seek": 231772, "start": 2325.7999999999997, "end": 2331.08, "text": " Our right-hand side is every value in X that are greater than this particular value", "tokens": [2621, 558, 12, 5543, 1252, 307, 633, 2158, 294, 1783, 300, 366, 5044, 813, 341, 1729, 2158], "temperature": 0.0, "avg_logprob": -0.1745502414988048, "compression_ratio": 1.5889570552147239, "no_speech_prob": 2.0580403088388266e-06}, {"id": 477, "seek": 233108, "start": 2331.08, "end": 2345.2, "text": " Okay, so what's the data type that's going to be in LHS and RHS? What are they actually going to contain?", "tokens": [1033, 11, 370, 437, 311, 264, 1412, 2010, 300, 311, 516, 281, 312, 294, 441, 12527, 293, 497, 12527, 30, 708, 366, 436, 767, 516, 281, 5304, 30], "temperature": 0.0, "avg_logprob": -0.19231515387966208, "compression_ratio": 1.546583850931677, "no_speech_prob": 1.228910718964471e-06}, {"id": 478, "seek": 233108, "start": 2349.56, "end": 2351.56, "text": " They're going to be arrays arrays of what?", "tokens": [814, 434, 516, 281, 312, 41011, 41011, 295, 437, 30], "temperature": 0.0, "avg_logprob": -0.19231515387966208, "compression_ratio": 1.546583850931677, "no_speech_prob": 1.228910718964471e-06}, {"id": 479, "seek": 233108, "start": 2353.4, "end": 2359.72, "text": " Rays of arrays of Booleans yeah, which we can treat as zero and one okay, so LHS will be an array of", "tokens": [497, 3772, 295, 41011, 295, 23351, 24008, 1338, 11, 597, 321, 393, 2387, 382, 4018, 293, 472, 1392, 11, 370, 441, 12527, 486, 312, 364, 10225, 295], "temperature": 0.0, "avg_logprob": -0.19231515387966208, "compression_ratio": 1.546583850931677, "no_speech_prob": 1.228910718964471e-06}, {"id": 480, "seek": 235972, "start": 2359.72, "end": 2361.2799999999997, "text": " false", "tokens": [7908], "temperature": 0.0, "avg_logprob": -0.1500291913469261, "compression_ratio": 1.743083003952569, "no_speech_prob": 1.1015932841473841e-06}, {"id": 481, "seek": 235972, "start": 2361.2799999999997, "end": 2367.6, "text": " Every time it's not less than or equal to and true otherwise and RHS will be a Boolean array of the opposite", "tokens": [2048, 565, 309, 311, 406, 1570, 813, 420, 2681, 281, 293, 2074, 5911, 293, 497, 12527, 486, 312, 257, 23351, 28499, 10225, 295, 264, 6182], "temperature": 0.0, "avg_logprob": -0.1500291913469261, "compression_ratio": 1.743083003952569, "no_speech_prob": 1.1015932841473841e-06}, {"id": 482, "seek": 235972, "start": 2368.0, "end": 2375.2, "text": " Okay, and now we can't take a standard deviation of an empty set right so if there's nothing that's greater than", "tokens": [1033, 11, 293, 586, 321, 393, 380, 747, 257, 3832, 25163, 295, 364, 6707, 992, 558, 370, 498, 456, 311, 1825, 300, 311, 5044, 813], "temperature": 0.0, "avg_logprob": -0.1500291913469261, "compression_ratio": 1.743083003952569, "no_speech_prob": 1.1015932841473841e-06}, {"id": 483, "seek": 235972, "start": 2376.0, "end": 2381.7599999999998, "text": " This number then these will all be false which means the sum will be zero", "tokens": [639, 1230, 550, 613, 486, 439, 312, 7908, 597, 1355, 264, 2408, 486, 312, 4018], "temperature": 0.0, "avg_logprob": -0.1500291913469261, "compression_ratio": 1.743083003952569, "no_speech_prob": 1.1015932841473841e-06}, {"id": 484, "seek": 235972, "start": 2382.3199999999997, "end": 2389.12, "text": " Okay, and in that case let's not go any further with this step because there's nothing to take the standard deviation of and it's obviously", "tokens": [1033, 11, 293, 294, 300, 1389, 718, 311, 406, 352, 604, 3052, 365, 341, 1823, 570, 456, 311, 1825, 281, 747, 264, 3832, 25163, 295, 293, 309, 311, 2745], "temperature": 0.0, "avg_logprob": -0.1500291913469261, "compression_ratio": 1.743083003952569, "no_speech_prob": 1.1015932841473841e-06}, {"id": 485, "seek": 238912, "start": 2389.12, "end": 2396.0, "text": " Not a useful split okay, so assuming. We've got this part. We can now calculate the standard deviation of the left-hand side and", "tokens": [1726, 257, 4420, 7472, 1392, 11, 370, 11926, 13, 492, 600, 658, 341, 644, 13, 492, 393, 586, 8873, 264, 3832, 25163, 295, 264, 1411, 12, 5543, 1252, 293], "temperature": 0.0, "avg_logprob": -0.15734381987669757, "compression_ratio": 1.819327731092437, "no_speech_prob": 5.422194590209983e-06}, {"id": 486, "seek": 238912, "start": 2396.52, "end": 2398.52, "text": " of the right-hand side and", "tokens": [295, 264, 558, 12, 5543, 1252, 293], "temperature": 0.0, "avg_logprob": -0.15734381987669757, "compression_ratio": 1.819327731092437, "no_speech_prob": 5.422194590209983e-06}, {"id": 487, "seek": 238912, "start": 2398.7599999999998, "end": 2404.2, "text": " Take the weighted average or the sums the same thing to us to a scalar", "tokens": [3664, 264, 32807, 4274, 420, 264, 34499, 264, 912, 551, 281, 505, 281, 257, 39684], "temperature": 0.0, "avg_logprob": -0.15734381987669757, "compression_ratio": 1.819327731092437, "no_speech_prob": 5.422194590209983e-06}, {"id": 488, "seek": 238912, "start": 2404.52, "end": 2411.3199999999997, "text": " Right and so there's our score and so we can then check is this better than our best score so far and our best score", "tokens": [1779, 293, 370, 456, 311, 527, 6175, 293, 370, 321, 393, 550, 1520, 307, 341, 1101, 813, 527, 1151, 6175, 370, 1400, 293, 527, 1151, 6175], "temperature": 0.0, "avg_logprob": -0.15734381987669757, "compression_ratio": 1.819327731092437, "no_speech_prob": 5.422194590209983e-06}, {"id": 489, "seek": 238912, "start": 2411.3199999999997, "end": 2416.7999999999997, "text": " So far we initially initialized it to infinity right so initially. This is this is better", "tokens": [407, 1400, 321, 9105, 5883, 1602, 309, 281, 13202, 558, 370, 9105, 13, 639, 307, 341, 307, 1101], "temperature": 0.0, "avg_logprob": -0.15734381987669757, "compression_ratio": 1.819327731092437, "no_speech_prob": 5.422194590209983e-06}, {"id": 490, "seek": 241680, "start": 2416.8, "end": 2418.8, "text": " So if it's better", "tokens": [407, 498, 309, 311, 1101], "temperature": 0.0, "avg_logprob": -0.18981864426162218, "compression_ratio": 1.5736040609137056, "no_speech_prob": 2.156811660825042e-06}, {"id": 491, "seek": 241680, "start": 2419.32, "end": 2421.32, "text": " Let's store away", "tokens": [961, 311, 3531, 1314], "temperature": 0.0, "avg_logprob": -0.18981864426162218, "compression_ratio": 1.5736040609137056, "no_speech_prob": 2.156811660825042e-06}, {"id": 492, "seek": 241680, "start": 2423.32, "end": 2429.36, "text": " All of the information we need which variable has found this better split. What was the score we found and", "tokens": [1057, 295, 264, 1589, 321, 643, 597, 7006, 575, 1352, 341, 1101, 7472, 13, 708, 390, 264, 6175, 321, 1352, 293], "temperature": 0.0, "avg_logprob": -0.18981864426162218, "compression_ratio": 1.5736040609137056, "no_speech_prob": 2.156811660825042e-06}, {"id": 493, "seek": 241680, "start": 2430.04, "end": 2431.88, "text": " What was the?", "tokens": [708, 390, 264, 30], "temperature": 0.0, "avg_logprob": -0.18981864426162218, "compression_ratio": 1.5736040609137056, "no_speech_prob": 2.156811660825042e-06}, {"id": 494, "seek": 241680, "start": 2431.88, "end": 2433.88, "text": " Value that we spit on", "tokens": [39352, 300, 321, 22127, 322], "temperature": 0.0, "avg_logprob": -0.18981864426162218, "compression_ratio": 1.5736040609137056, "no_speech_prob": 2.156811660825042e-06}, {"id": 495, "seek": 241680, "start": 2434.2000000000003, "end": 2436.2000000000003, "text": " Okay, so there it is", "tokens": [1033, 11, 370, 456, 309, 307], "temperature": 0.0, "avg_logprob": -0.18981864426162218, "compression_ratio": 1.5736040609137056, "no_speech_prob": 2.156811660825042e-06}, {"id": 496, "seek": 241680, "start": 2438.1600000000003, "end": 2440.1600000000003, "text": " So if we run that", "tokens": [407, 498, 321, 1190, 300], "temperature": 0.0, "avg_logprob": -0.18981864426162218, "compression_ratio": 1.5736040609137056, "no_speech_prob": 2.156811660825042e-06}, {"id": 497, "seek": 241680, "start": 2440.5600000000004, "end": 2446.32, "text": " And I'm using time it so what time it does is it sees how long this command takes to run and?", "tokens": [400, 286, 478, 1228, 565, 309, 370, 437, 565, 309, 775, 307, 309, 8194, 577, 938, 341, 5622, 2516, 281, 1190, 293, 30], "temperature": 0.0, "avg_logprob": -0.18981864426162218, "compression_ratio": 1.5736040609137056, "no_speech_prob": 2.156811660825042e-06}, {"id": 498, "seek": 244632, "start": 2446.32, "end": 2452.92, "text": " It tries to give you a kind of statistically valid measure of that so you can see here. It's run run at ten times", "tokens": [467, 9898, 281, 976, 291, 257, 733, 295, 36478, 7363, 3481, 295, 300, 370, 291, 393, 536, 510, 13, 467, 311, 1190, 1190, 412, 2064, 1413], "temperature": 0.0, "avg_logprob": -0.16684203786948293, "compression_ratio": 1.6131687242798354, "no_speech_prob": 2.6425780106364982e-06}, {"id": 499, "seek": 244632, "start": 2453.6800000000003, "end": 2459.6800000000003, "text": " To get an average and then it's done that seven times to get a mean and standard deviation across runs", "tokens": [1407, 483, 364, 4274, 293, 550, 309, 311, 1096, 300, 3407, 1413, 281, 483, 257, 914, 293, 3832, 25163, 2108, 6676], "temperature": 0.0, "avg_logprob": -0.16684203786948293, "compression_ratio": 1.6131687242798354, "no_speech_prob": 2.6425780106364982e-06}, {"id": 500, "seek": 244632, "start": 2459.6800000000003, "end": 2462.92, "text": " And so it's taking me 75 milliseconds plus or minus ten", "tokens": [400, 370, 309, 311, 1940, 385, 9562, 34184, 1804, 420, 3175, 2064], "temperature": 0.0, "avg_logprob": -0.16684203786948293, "compression_ratio": 1.6131687242798354, "no_speech_prob": 2.6425780106364982e-06}, {"id": 501, "seek": 244632, "start": 2463.56, "end": 2465.4, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.16684203786948293, "compression_ratio": 1.6131687242798354, "no_speech_prob": 2.6425780106364982e-06}, {"id": 502, "seek": 244632, "start": 2465.4, "end": 2467.4, "text": " So let's check that this works", "tokens": [407, 718, 311, 1520, 300, 341, 1985], "temperature": 0.0, "avg_logprob": -0.16684203786948293, "compression_ratio": 1.6131687242798354, "no_speech_prob": 2.6425780106364982e-06}, {"id": 503, "seek": 246740, "start": 2467.4, "end": 2474.54, "text": " Find let us split tree zero so zero is you made one is machine hours current meter?", "tokens": [11809, 718, 505, 7472, 4230, 4018, 370, 4018, 307, 291, 1027, 472, 307, 3479, 2496, 2190, 9255, 30], "temperature": 0.0, "avg_logprob": -0.26047325134277344, "compression_ratio": 1.6242774566473988, "no_speech_prob": 2.9944267225801013e-06}, {"id": 504, "seek": 246740, "start": 2477.2400000000002, "end": 2479.2400000000002, "text": " So with one", "tokens": [407, 365, 472], "temperature": 0.0, "avg_logprob": -0.26047325134277344, "compression_ratio": 1.6242774566473988, "no_speech_prob": 2.9944267225801013e-06}, {"id": 505, "seek": 246740, "start": 2479.38, "end": 2483.6800000000003, "text": " We got back machine hours current meter 3744 with this score", "tokens": [492, 658, 646, 3479, 2496, 2190, 9255, 13435, 13912, 365, 341, 6175], "temperature": 0.0, "avg_logprob": -0.26047325134277344, "compression_ratio": 1.6242774566473988, "no_speech_prob": 2.9944267225801013e-06}, {"id": 506, "seek": 246740, "start": 2483.6800000000003, "end": 2489.12, "text": " And then we ran it again with zero that's you made and we've got a better score", "tokens": [400, 550, 321, 5872, 309, 797, 365, 4018, 300, 311, 291, 1027, 293, 321, 600, 658, 257, 1101, 6175], "temperature": 0.0, "avg_logprob": -0.26047325134277344, "compression_ratio": 1.6242774566473988, "no_speech_prob": 2.9944267225801013e-06}, {"id": 507, "seek": 246740, "start": 2489.44, "end": 2493.44, "text": " 658 and split 1974 and so 1974", "tokens": [11624, 23, 293, 7472, 33422, 293, 370, 33422], "temperature": 0.0, "avg_logprob": -0.26047325134277344, "compression_ratio": 1.6242774566473988, "no_speech_prob": 2.9944267225801013e-06}, {"id": 508, "seek": 246740, "start": 2494.32, "end": 2496.08, "text": " Let's compare", "tokens": [961, 311, 6794], "temperature": 0.0, "avg_logprob": -0.26047325134277344, "compression_ratio": 1.6242774566473988, "no_speech_prob": 2.9944267225801013e-06}, {"id": 509, "seek": 249608, "start": 2496.08, "end": 2500.84, "text": " Yeah, that was what this tree did as well. Okay, so we've got we've confirmed that this", "tokens": [865, 11, 300, 390, 437, 341, 4230, 630, 382, 731, 13, 1033, 11, 370, 321, 600, 658, 321, 600, 11341, 300, 341], "temperature": 0.0, "avg_logprob": -0.19955827924940323, "compression_ratio": 1.6896551724137931, "no_speech_prob": 2.0261347799532814e-06}, {"id": 510, "seek": 249608, "start": 2501.52, "end": 2506.6, "text": " Method is doing is giving the same result that SK learns random forest did", "tokens": [25285, 307, 884, 307, 2902, 264, 912, 1874, 300, 21483, 27152, 4974, 6719, 630], "temperature": 0.0, "avg_logprob": -0.19955827924940323, "compression_ratio": 1.6896551724137931, "no_speech_prob": 2.0261347799532814e-06}, {"id": 511, "seek": 249608, "start": 2507.0, "end": 2509.6, "text": " Okay, and you can also see here the value", "tokens": [1033, 11, 293, 291, 393, 611, 536, 510, 264, 2158], "temperature": 0.0, "avg_logprob": -0.19955827924940323, "compression_ratio": 1.6896551724137931, "no_speech_prob": 2.0261347799532814e-06}, {"id": 512, "seek": 249608, "start": 2511.16, "end": 2515.12, "text": " 10.08 and again matching here the value 10.08", "tokens": [1266, 13, 16133, 293, 797, 14324, 510, 264, 2158, 1266, 13, 16133], "temperature": 0.0, "avg_logprob": -0.19955827924940323, "compression_ratio": 1.6896551724137931, "no_speech_prob": 2.0261347799532814e-06}, {"id": 513, "seek": 249608, "start": 2516.0, "end": 2521.2599999999998, "text": " Okay, so we've got something that confined one split could you pass that to your net please?", "tokens": [1033, 11, 370, 321, 600, 658, 746, 300, 31745, 472, 7472, 727, 291, 1320, 300, 281, 428, 2533, 1767, 30], "temperature": 0.0, "avg_logprob": -0.19955827924940323, "compression_ratio": 1.6896551724137931, "no_speech_prob": 2.0261347799532814e-06}, {"id": 514, "seek": 252126, "start": 2521.26, "end": 2527.38, "text": " So Jeremy, why don't we put a unique on the X there?", "tokens": [407, 17809, 11, 983, 500, 380, 321, 829, 257, 3845, 322, 264, 1783, 456, 30], "temperature": 0.0, "avg_logprob": -0.23143046735280967, "compression_ratio": 1.4973821989528795, "no_speech_prob": 6.643385859206319e-06}, {"id": 515, "seek": 252126, "start": 2529.9, "end": 2535.2200000000003, "text": " Because I'm not trying to optimize the performance yet, but you see that no like he's doing more", "tokens": [1436, 286, 478, 406, 1382, 281, 19719, 264, 3389, 1939, 11, 457, 291, 536, 300, 572, 411, 415, 311, 884, 544], "temperature": 0.0, "avg_logprob": -0.23143046735280967, "compression_ratio": 1.4973821989528795, "no_speech_prob": 6.643385859206319e-06}, {"id": 516, "seek": 252126, "start": 2535.5400000000004, "end": 2541.3, "text": " Yeah, so it's like and you can see in the Excel. I like checked this one twice. I checked this for twice unnecessarily", "tokens": [865, 11, 370, 309, 311, 411, 293, 291, 393, 536, 294, 264, 19060, 13, 286, 411, 10033, 341, 472, 6091, 13, 286, 10033, 341, 337, 6091, 16799, 3289], "temperature": 0.0, "avg_logprob": -0.23143046735280967, "compression_ratio": 1.4973821989528795, "no_speech_prob": 6.643385859206319e-06}, {"id": 517, "seek": 252126, "start": 2542.1800000000003, "end": 2544.1800000000003, "text": " Yeah", "tokens": [865], "temperature": 0.0, "avg_logprob": -0.23143046735280967, "compression_ratio": 1.4973821989528795, "no_speech_prob": 6.643385859206319e-06}, {"id": 518, "seek": 252126, "start": 2545.0200000000004, "end": 2547.0200000000004, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.23143046735280967, "compression_ratio": 1.4973821989528795, "no_speech_prob": 6.643385859206319e-06}, {"id": 519, "seek": 252126, "start": 2547.1400000000003, "end": 2548.42, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.23143046735280967, "compression_ratio": 1.4973821989528795, "no_speech_prob": 6.643385859206319e-06}, {"id": 520, "seek": 254842, "start": 2548.42, "end": 2551.2000000000003, "text": " So you know it's already thinking about performance, which is good", "tokens": [407, 291, 458, 309, 311, 1217, 1953, 466, 3389, 11, 597, 307, 665], "temperature": 0.0, "avg_logprob": -0.21665575364056755, "compression_ratio": 1.6868686868686869, "no_speech_prob": 7.296308012882946e-06}, {"id": 521, "seek": 254842, "start": 2553.46, "end": 2556.9, "text": " So tell me what is the computational complexity of", "tokens": [407, 980, 385, 437, 307, 264, 28270, 14024, 295], "temperature": 0.0, "avg_logprob": -0.21665575364056755, "compression_ratio": 1.6868686868686869, "no_speech_prob": 7.296308012882946e-06}, {"id": 522, "seek": 254842, "start": 2557.98, "end": 2559.9, "text": " this", "tokens": [341], "temperature": 0.0, "avg_logprob": -0.21665575364056755, "compression_ratio": 1.6868686868686869, "no_speech_prob": 7.296308012882946e-06}, {"id": 523, "seek": 254842, "start": 2559.9, "end": 2561.9, "text": " section of the code and", "tokens": [3541, 295, 264, 3089, 293], "temperature": 0.0, "avg_logprob": -0.21665575364056755, "compression_ratio": 1.6868686868686869, "no_speech_prob": 7.296308012882946e-06}, {"id": 524, "seek": 254842, "start": 2561.98, "end": 2566.46, "text": " Like have a think about it, but also like feel free to talk us through it if you want to kind of", "tokens": [1743, 362, 257, 519, 466, 309, 11, 457, 611, 411, 841, 1737, 281, 751, 505, 807, 309, 498, 291, 528, 281, 733, 295], "temperature": 0.0, "avg_logprob": -0.21665575364056755, "compression_ratio": 1.6868686868686869, "no_speech_prob": 7.296308012882946e-06}, {"id": 525, "seek": 254842, "start": 2567.42, "end": 2569.42, "text": " Think and talk at the same time", "tokens": [6557, 293, 751, 412, 264, 912, 565], "temperature": 0.0, "avg_logprob": -0.21665575364056755, "compression_ratio": 1.6868686868686869, "no_speech_prob": 7.296308012882946e-06}, {"id": 526, "seek": 254842, "start": 2569.9, "end": 2573.14, "text": " What's the computational complexity of this piece of code?", "tokens": [708, 311, 264, 28270, 14024, 295, 341, 2522, 295, 3089, 30], "temperature": 0.0, "avg_logprob": -0.21665575364056755, "compression_ratio": 1.6868686868686869, "no_speech_prob": 7.296308012882946e-06}, {"id": 527, "seek": 257314, "start": 2573.14, "end": 2575.9, "text": " Can I pass it over there yes", "tokens": [1664, 286, 1320, 309, 670, 456, 2086], "temperature": 0.0, "avg_logprob": -0.5579089289126189, "compression_ratio": 1.578125, "no_speech_prob": 1.0129620022780728e-05}, {"id": 528, "seek": 257314, "start": 2576.98, "end": 2579.3799999999997, "text": " All right, Jay take us through your thought process", "tokens": [1057, 558, 11, 11146, 747, 505, 807, 428, 1194, 1399], "temperature": 0.0, "avg_logprob": -0.5579089289126189, "compression_ratio": 1.578125, "no_speech_prob": 1.0129620022780728e-05}, {"id": 529, "seek": 257314, "start": 2580.1, "end": 2585.94, "text": " I think you have to take each different values through the column to calculate it", "tokens": [286, 519, 291, 362, 281, 747, 1184, 819, 4190, 807, 264, 7738, 281, 8873, 309], "temperature": 0.0, "avg_logprob": -0.5579089289126189, "compression_ratio": 1.578125, "no_speech_prob": 1.0129620022780728e-05}, {"id": 530, "seek": 257314, "start": 2586.98, "end": 2590.5, "text": " Once to see the splits so and it compared", "tokens": [3443, 281, 536, 264, 37741, 370, 293, 309, 5347], "temperature": 0.0, "avg_logprob": -0.5579089289126189, "compression_ratio": 1.578125, "no_speech_prob": 1.0129620022780728e-05}, {"id": 531, "seek": 257314, "start": 2591.22, "end": 2597.18, "text": " All the like all the possible combinations between these different values so that can be expensive", "tokens": [1057, 264, 411, 439, 264, 1944, 21267, 1296, 613, 819, 4190, 370, 300, 393, 312, 5124], "temperature": 0.0, "avg_logprob": -0.5579089289126189, "compression_ratio": 1.578125, "no_speech_prob": 1.0129620022780728e-05}, {"id": 532, "seek": 259718, "start": 2597.18, "end": 2602.5, "text": " Like cuz you're uh-huh can you know does somebody else want to tell us the actual computational complexity?", "tokens": [1743, 11910, 291, 434, 2232, 12, 18710, 393, 291, 458, 775, 2618, 1646, 528, 281, 980, 505, 264, 3539, 28270, 14024, 30], "temperature": 0.0, "avg_logprob": -0.43023862336811264, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.8408689104253426e-05}, {"id": 533, "seek": 259718, "start": 2602.5, "end": 2605.06, "text": " So like yeah quite high Jade's thinking", "tokens": [407, 411, 1338, 1596, 1090, 37021, 311, 1953], "temperature": 0.0, "avg_logprob": -0.43023862336811264, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.8408689104253426e-05}, {"id": 534, "seek": 259718, "start": 2605.8599999999997, "end": 2607.8599999999997, "text": " How high I?", "tokens": [1012, 1090, 286, 30], "temperature": 0.0, "avg_logprob": -0.43023862336811264, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.8408689104253426e-05}, {"id": 535, "seek": 259718, "start": 2610.2599999999998, "end": 2616.8999999999996, "text": " Think it's n-squared okay, so tell me why is it n-squared because for the for loop it is in yes", "tokens": [6557, 309, 311, 297, 12, 33292, 1642, 1392, 11, 370, 980, 385, 983, 307, 309, 297, 12, 33292, 1642, 570, 337, 264, 337, 6367, 309, 307, 294, 2086], "temperature": 0.0, "avg_logprob": -0.43023862336811264, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.8408689104253426e-05}, {"id": 536, "seek": 259718, "start": 2616.8999999999996, "end": 2621.8599999999997, "text": " And I think I guess the standard deviation will take in so it's n-squared okay, or", "tokens": [400, 286, 519, 286, 2041, 264, 3832, 25163, 486, 747, 294, 370, 309, 311, 297, 12, 33292, 1642, 1392, 11, 420], "temperature": 0.0, "avg_logprob": -0.43023862336811264, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.8408689104253426e-05}, {"id": 537, "seek": 262186, "start": 2621.86, "end": 2628.06, "text": " This one maybe is even easier to know like this is like which ones are less than x. I I'm gonna have to check every", "tokens": [639, 472, 1310, 307, 754, 3571, 281, 458, 411, 341, 307, 411, 597, 2306, 366, 1570, 813, 2031, 13, 286, 286, 478, 799, 362, 281, 1520, 633], "temperature": 0.0, "avg_logprob": -0.4788930522861765, "compression_ratio": 2.018181818181818, "no_speech_prob": 5.422166850621579e-06}, {"id": 538, "seek": 262186, "start": 2628.06, "end": 2633.2200000000003, "text": " Value to see if it's less than x. I okay, and so so it's useful to know like", "tokens": [39352, 281, 536, 498, 309, 311, 1570, 813, 2031, 13, 286, 1392, 11, 293, 370, 370, 309, 311, 4420, 281, 458, 411], "temperature": 0.0, "avg_logprob": -0.4788930522861765, "compression_ratio": 2.018181818181818, "no_speech_prob": 5.422166850621579e-06}, {"id": 539, "seek": 262186, "start": 2634.02, "end": 2636.5, "text": " How do I quickly calculate computational complexity?", "tokens": [1012, 360, 286, 2661, 8873, 28270, 14024, 30], "temperature": 0.0, "avg_logprob": -0.4788930522861765, "compression_ratio": 2.018181818181818, "no_speech_prob": 5.422166850621579e-06}, {"id": 540, "seek": 262186, "start": 2636.5, "end": 2640.1400000000003, "text": " I can guarantee most of the interviews you do are gonna ask you to calculate", "tokens": [286, 393, 10815, 881, 295, 264, 12318, 291, 360, 366, 799, 1029, 291, 281, 8873], "temperature": 0.0, "avg_logprob": -0.4788930522861765, "compression_ratio": 2.018181818181818, "no_speech_prob": 5.422166850621579e-06}, {"id": 541, "seek": 262186, "start": 2640.38, "end": 2645.54, "text": " Computational complexity on the fly and it's also like when you're coding you want it to be second nature", "tokens": [37804, 1478, 14024, 322, 264, 3603, 293, 309, 311, 611, 411, 562, 291, 434, 17720, 291, 528, 309, 281, 312, 1150, 3687], "temperature": 0.0, "avg_logprob": -0.4788930522861765, "compression_ratio": 2.018181818181818, "no_speech_prob": 5.422166850621579e-06}, {"id": 542, "seek": 262186, "start": 2645.54, "end": 2651.58, "text": " So it's like you're going to have to calculate the complexity of the code and you're going to have to calculate the complexity", "tokens": [407, 309, 311, 411, 291, 434, 516, 281, 362, 281, 8873, 264, 14024, 295, 264, 3089, 293, 291, 434, 516, 281, 362, 281, 8873, 264, 14024], "temperature": 0.0, "avg_logprob": -0.4788930522861765, "compression_ratio": 2.018181818181818, "no_speech_prob": 5.422166850621579e-06}, {"id": 543, "seek": 265158, "start": 2651.58, "end": 2654.18, "text": " So the technique is basically is there a loop?", "tokens": [407, 264, 6532, 307, 1936, 307, 456, 257, 6367, 30], "temperature": 0.0, "avg_logprob": -0.15583457265581405, "compression_ratio": 1.8893617021276596, "no_speech_prob": 4.495159373618662e-06}, {"id": 544, "seek": 265158, "start": 2654.7799999999997, "end": 2657.7, "text": " Okay, we're then we're obviously doing this n times", "tokens": [1033, 11, 321, 434, 550, 321, 434, 2745, 884, 341, 297, 1413], "temperature": 0.0, "avg_logprob": -0.15583457265581405, "compression_ratio": 1.8893617021276596, "no_speech_prob": 4.495159373618662e-06}, {"id": 545, "seek": 265158, "start": 2658.2999999999997, "end": 2663.7799999999997, "text": " Okay, so there's an n involved is there a loop inside the loop if there is then you need to multiply those two together", "tokens": [1033, 11, 370, 456, 311, 364, 297, 3288, 307, 456, 257, 6367, 1854, 264, 6367, 498, 456, 307, 550, 291, 643, 281, 12972, 729, 732, 1214], "temperature": 0.0, "avg_logprob": -0.15583457265581405, "compression_ratio": 1.8893617021276596, "no_speech_prob": 4.495159373618662e-06}, {"id": 546, "seek": 265158, "start": 2663.7799999999997, "end": 2670.1, "text": " In this case there's not is there anything inside the loop that's not a constant time thing", "tokens": [682, 341, 1389, 456, 311, 406, 307, 456, 1340, 1854, 264, 6367, 300, 311, 406, 257, 5754, 565, 551], "temperature": 0.0, "avg_logprob": -0.15583457265581405, "compression_ratio": 1.8893617021276596, "no_speech_prob": 4.495159373618662e-06}, {"id": 547, "seek": 265158, "start": 2670.14, "end": 2671.98, "text": " So you might see a sort in there", "tokens": [407, 291, 1062, 536, 257, 1333, 294, 456], "temperature": 0.0, "avg_logprob": -0.15583457265581405, "compression_ratio": 1.8893617021276596, "no_speech_prob": 4.495159373618662e-06}, {"id": 548, "seek": 265158, "start": 2671.98, "end": 2677.18, "text": " And you just need to know that sort is n log n like that should be second nature if you see a matrix", "tokens": [400, 291, 445, 643, 281, 458, 300, 1333, 307, 297, 3565, 297, 411, 300, 820, 312, 1150, 3687, 498, 291, 536, 257, 8141], "temperature": 0.0, "avg_logprob": -0.15583457265581405, "compression_ratio": 1.8893617021276596, "no_speech_prob": 4.495159373618662e-06}, {"id": 549, "seek": 267718, "start": 2677.18, "end": 2684.46, "text": " Multiply you need to know what that is in this case. There are some things that are doing element wise array operations", "tokens": [31150, 356, 291, 643, 281, 458, 437, 300, 307, 294, 341, 1389, 13, 821, 366, 512, 721, 300, 366, 884, 4478, 10829, 10225, 7705], "temperature": 0.0, "avg_logprob": -0.16583953713471034, "compression_ratio": 1.7461538461538462, "no_speech_prob": 1.003012130240677e-06}, {"id": 550, "seek": 267718, "start": 2684.5, "end": 2690.14, "text": " Right so keep an eye out for anything where numpy is doing something to every value of an array in this case", "tokens": [1779, 370, 1066, 364, 3313, 484, 337, 1340, 689, 1031, 8200, 307, 884, 746, 281, 633, 2158, 295, 364, 10225, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.16583953713471034, "compression_ratio": 1.7461538461538462, "no_speech_prob": 1.003012130240677e-06}, {"id": 551, "seek": 267718, "start": 2690.14, "end": 2692.14, "text": " It's checking every value of X", "tokens": [467, 311, 8568, 633, 2158, 295, 1783], "temperature": 0.0, "avg_logprob": -0.16583953713471034, "compression_ratio": 1.7461538461538462, "no_speech_prob": 1.003012130240677e-06}, {"id": 552, "seek": 267718, "start": 2692.3799999999997, "end": 2698.5, "text": " Against a constant so it's going to have to do that n times so to flesh this out into a computational complexity", "tokens": [29995, 257, 5754, 370, 309, 311, 516, 281, 362, 281, 360, 300, 297, 1413, 370, 281, 12497, 341, 484, 666, 257, 28270, 14024], "temperature": 0.0, "avg_logprob": -0.16583953713471034, "compression_ratio": 1.7461538461538462, "no_speech_prob": 1.003012130240677e-06}, {"id": 553, "seek": 267718, "start": 2698.98, "end": 2704.02, "text": " You just take the number of things in the loop and you multiply it by the highest", "tokens": [509, 445, 747, 264, 1230, 295, 721, 294, 264, 6367, 293, 291, 12972, 309, 538, 264, 6343], "temperature": 0.0, "avg_logprob": -0.16583953713471034, "compression_ratio": 1.7461538461538462, "no_speech_prob": 1.003012130240677e-06}, {"id": 554, "seek": 270402, "start": 2704.02, "end": 2708.36, "text": " Computational complexity inside the loop n times n is n squared you pass that", "tokens": [37804, 1478, 14024, 1854, 264, 6367, 297, 1413, 297, 307, 297, 8889, 291, 1320, 300], "temperature": 0.0, "avg_logprob": -0.1895535945892334, "compression_ratio": 1.7822878228782288, "no_speech_prob": 3.28873875332647e-06}, {"id": 555, "seek": 270402, "start": 2710.2599999999998, "end": 2715.78, "text": " In this case couldn't we just pre sort the list and then do like one and log n computation", "tokens": [682, 341, 1389, 2809, 380, 321, 445, 659, 1333, 264, 1329, 293, 550, 360, 411, 472, 293, 3565, 297, 24903], "temperature": 0.0, "avg_logprob": -0.1895535945892334, "compression_ratio": 1.7822878228782288, "no_speech_prob": 3.28873875332647e-06}, {"id": 556, "seek": 270402, "start": 2715.78, "end": 2720.56, "text": " And there's lots of things we can do to speed this up so at this stage is just like what is the computational complexity we have?", "tokens": [400, 456, 311, 3195, 295, 721, 321, 393, 360, 281, 3073, 341, 493, 370, 412, 341, 3233, 307, 445, 411, 437, 307, 264, 28270, 14024, 321, 362, 30], "temperature": 0.0, "avg_logprob": -0.1895535945892334, "compression_ratio": 1.7822878228782288, "no_speech_prob": 3.28873875332647e-06}, {"id": 557, "seek": 270402, "start": 2721.38, "end": 2726.94, "text": " But absolutely it's certainly not as good as it can be okay, so that's where we're going to go next", "tokens": [583, 3122, 309, 311, 3297, 406, 382, 665, 382, 309, 393, 312, 1392, 11, 370, 300, 311, 689, 321, 434, 516, 281, 352, 958], "temperature": 0.0, "avg_logprob": -0.1895535945892334, "compression_ratio": 1.7822878228782288, "no_speech_prob": 3.28873875332647e-06}, {"id": 558, "seek": 272694, "start": 2726.94, "end": 2734.2200000000003, "text": " It's like all right n squared is not it's not great, so let's try and make it better so", "tokens": [467, 311, 411, 439, 558, 297, 8889, 307, 406, 309, 311, 406, 869, 11, 370, 718, 311, 853, 293, 652, 309, 1101, 370], "temperature": 0.0, "avg_logprob": -0.2604471155115076, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936964160151547e-06}, {"id": 559, "seek": 272694, "start": 2735.66, "end": 2737.66, "text": " Here's my attempt at making it better", "tokens": [1692, 311, 452, 5217, 412, 1455, 309, 1101], "temperature": 0.0, "avg_logprob": -0.2604471155115076, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936964160151547e-06}, {"id": 560, "seek": 272694, "start": 2739.18, "end": 2741.18, "text": " And the idea is this", "tokens": [400, 264, 1558, 307, 341], "temperature": 0.0, "avg_logprob": -0.2604471155115076, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936964160151547e-06}, {"id": 561, "seek": 272694, "start": 2742.42, "end": 2749.1, "text": " Okay, who wants to first of all tell me what's the equation for standard deviation?", "tokens": [1033, 11, 567, 2738, 281, 700, 295, 439, 980, 385, 437, 311, 264, 5367, 337, 3832, 25163, 30], "temperature": 0.0, "avg_logprob": -0.2604471155115076, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936964160151547e-06}, {"id": 562, "seek": 272694, "start": 2752.26, "end": 2754.26, "text": " Masha can you grab the box?", "tokens": [376, 12137, 393, 291, 4444, 264, 2424, 30], "temperature": 0.0, "avg_logprob": -0.2604471155115076, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936964160151547e-06}, {"id": 563, "seek": 275426, "start": 2754.26, "end": 2761.2200000000003, "text": " So for the standard deviation, it's the difference between the value and its mean", "tokens": [407, 337, 264, 3832, 25163, 11, 309, 311, 264, 2649, 1296, 264, 2158, 293, 1080, 914], "temperature": 0.0, "avg_logprob": -0.3196768977425315, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.1478489795990754e-05}, {"id": 564, "seek": 275426, "start": 2762.6600000000003, "end": 2766.3, "text": " It's we take a square root of that. Sorry we take the", "tokens": [467, 311, 321, 747, 257, 3732, 5593, 295, 300, 13, 4919, 321, 747, 264], "temperature": 0.0, "avg_logprob": -0.3196768977425315, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.1478489795990754e-05}, {"id": 565, "seek": 275426, "start": 2768.42, "end": 2770.3, "text": " The power of two", "tokens": [440, 1347, 295, 732], "temperature": 0.0, "avg_logprob": -0.3196768977425315, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.1478489795990754e-05}, {"id": 566, "seek": 275426, "start": 2770.3, "end": 2776.32, "text": " Then we sum up all of these observations, and we take the square root out of all this some yeah", "tokens": [1396, 321, 2408, 493, 439, 295, 613, 18163, 11, 293, 321, 747, 264, 3732, 5593, 484, 295, 439, 341, 512, 1338], "temperature": 0.0, "avg_logprob": -0.3196768977425315, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.1478489795990754e-05}, {"id": 567, "seek": 275426, "start": 2776.32, "end": 2780.6000000000004, "text": " You have to divide divide by n. Yeah, yeah great good. Okay now", "tokens": [509, 362, 281, 9845, 9845, 538, 297, 13, 865, 11, 1338, 869, 665, 13, 1033, 586], "temperature": 0.0, "avg_logprob": -0.3196768977425315, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.1478489795990754e-05}, {"id": 568, "seek": 275426, "start": 2781.3, "end": 2783.1400000000003, "text": " in practice we", "tokens": [294, 3124, 321], "temperature": 0.0, "avg_logprob": -0.3196768977425315, "compression_ratio": 1.6029411764705883, "no_speech_prob": 1.1478489795990754e-05}, {"id": 569, "seek": 278314, "start": 2783.14, "end": 2787.8599999999997, "text": " Don't normally use that formulation because it kind of requires us calculating", "tokens": [1468, 380, 5646, 764, 300, 37642, 570, 309, 733, 295, 7029, 505, 28258], "temperature": 0.0, "avg_logprob": -0.24105415344238282, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.933355179062346e-06}, {"id": 570, "seek": 278314, "start": 2788.2999999999997, "end": 2793.98, "text": " You know X minus the mean lots of times does anybody know the formulation that just requires", "tokens": [509, 458, 1783, 3175, 264, 914, 3195, 295, 1413, 775, 4472, 458, 264, 37642, 300, 445, 7029], "temperature": 0.0, "avg_logprob": -0.24105415344238282, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.933355179062346e-06}, {"id": 571, "seek": 278314, "start": 2794.7, "end": 2796.7, "text": " X and X squared", "tokens": [1783, 293, 1783, 8889], "temperature": 0.0, "avg_logprob": -0.24105415344238282, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.933355179062346e-06}, {"id": 572, "seek": 278314, "start": 2796.98, "end": 2799.62, "text": " Anybody happen to know that one yes at the back trying to pass that back there", "tokens": [19082, 1051, 281, 458, 300, 472, 2086, 412, 264, 646, 1382, 281, 1320, 300, 646, 456], "temperature": 0.0, "avg_logprob": -0.24105415344238282, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.933355179062346e-06}, {"id": 573, "seek": 278314, "start": 2801.2999999999997, "end": 2804.1, "text": " Square root of a mean of squares minus", "tokens": [16463, 5593, 295, 257, 914, 295, 19368, 3175], "temperature": 0.0, "avg_logprob": -0.24105415344238282, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.933355179062346e-06}, {"id": 574, "seek": 280410, "start": 2804.1, "end": 2812.5, "text": " Square of mean yeah great mean of squares minus the square of the means alright, so that's a really good one", "tokens": [16463, 295, 914, 1338, 869, 914, 295, 19368, 3175, 264, 3732, 295, 264, 1355, 5845, 11, 370, 300, 311, 257, 534, 665, 472], "temperature": 0.0, "avg_logprob": -0.20283695102966937, "compression_ratio": 1.7656903765690377, "no_speech_prob": 6.083579364712932e-07}, {"id": 575, "seek": 280410, "start": 2813.22, "end": 2817.62, "text": " Divided by n. That's a really good one to know because like you can now calculate", "tokens": [413, 1843, 292, 538, 297, 13, 663, 311, 257, 534, 665, 472, 281, 458, 570, 411, 291, 393, 586, 8873], "temperature": 0.0, "avg_logprob": -0.20283695102966937, "compression_ratio": 1.7656903765690377, "no_speech_prob": 6.083579364712932e-07}, {"id": 576, "seek": 280410, "start": 2819.46, "end": 2824.8199999999997, "text": " Variances or standard deviations of anything you just have to first of all grab the column as it is", "tokens": [691, 10652, 887, 420, 3832, 31219, 763, 295, 1340, 291, 445, 362, 281, 700, 295, 439, 4444, 264, 7738, 382, 309, 307], "temperature": 0.0, "avg_logprob": -0.20283695102966937, "compression_ratio": 1.7656903765690377, "no_speech_prob": 6.083579364712932e-07}, {"id": 577, "seek": 280410, "start": 2825.54, "end": 2833.18, "text": " The column squared right and as long as you've got those stored away somewhere you can immediately calculate the standard deviation", "tokens": [440, 7738, 8889, 558, 293, 382, 938, 382, 291, 600, 658, 729, 12187, 1314, 4079, 291, 393, 4258, 8873, 264, 3832, 25163], "temperature": 0.0, "avg_logprob": -0.20283695102966937, "compression_ratio": 1.7656903765690377, "no_speech_prob": 6.083579364712932e-07}, {"id": 578, "seek": 283318, "start": 2833.18, "end": 2838.02, "text": " So the reason this is handy for us is that if we first of all?", "tokens": [407, 264, 1778, 341, 307, 13239, 337, 505, 307, 300, 498, 321, 700, 295, 439, 30], "temperature": 0.0, "avg_logprob": -0.17966492643061371, "compression_ratio": 1.7, "no_speech_prob": 1.3709557151742047e-06}, {"id": 579, "seek": 283318, "start": 2839.1, "end": 2841.58, "text": " Sort our data right", "tokens": [26149, 527, 1412, 558], "temperature": 0.0, "avg_logprob": -0.17966492643061371, "compression_ratio": 1.7, "no_speech_prob": 1.3709557151742047e-06}, {"id": 580, "seek": 283318, "start": 2842.8999999999996, "end": 2844.8999999999996, "text": " Let's go ahead and sort our data", "tokens": [961, 311, 352, 2286, 293, 1333, 527, 1412], "temperature": 0.0, "avg_logprob": -0.17966492643061371, "compression_ratio": 1.7, "no_speech_prob": 1.3709557151742047e-06}, {"id": 581, "seek": 283318, "start": 2845.7799999999997, "end": 2849.8199999999997, "text": " Then if you think about it as we kind of start going down one step at a time", "tokens": [1396, 498, 291, 519, 466, 309, 382, 321, 733, 295, 722, 516, 760, 472, 1823, 412, 257, 565], "temperature": 0.0, "avg_logprob": -0.17966492643061371, "compression_ratio": 1.7, "no_speech_prob": 1.3709557151742047e-06}, {"id": 582, "seek": 283318, "start": 2850.8199999999997, "end": 2857.62, "text": " Right then each group is exactly the same as the previous group on the left-hand side with one more thing in it", "tokens": [1779, 550, 1184, 1594, 307, 2293, 264, 912, 382, 264, 3894, 1594, 322, 264, 1411, 12, 5543, 1252, 365, 472, 544, 551, 294, 309], "temperature": 0.0, "avg_logprob": -0.17966492643061371, "compression_ratio": 1.7, "no_speech_prob": 1.3709557151742047e-06}, {"id": 583, "seek": 283318, "start": 2857.8599999999997, "end": 2860.22, "text": " And on the right-hand side with one less thing in it", "tokens": [400, 322, 264, 558, 12, 5543, 1252, 365, 472, 1570, 551, 294, 309], "temperature": 0.0, "avg_logprob": -0.17966492643061371, "compression_ratio": 1.7, "no_speech_prob": 1.3709557151742047e-06}, {"id": 584, "seek": 286022, "start": 2860.22, "end": 2864.5, "text": " So given that we just have to keep track of sum of X and some of X squared", "tokens": [407, 2212, 300, 321, 445, 362, 281, 1066, 2837, 295, 2408, 295, 1783, 293, 512, 295, 1783, 8889], "temperature": 0.0, "avg_logprob": -0.127075702772228, "compression_ratio": 1.8185840707964602, "no_speech_prob": 9.42243332247017e-07}, {"id": 585, "seek": 286022, "start": 2864.74, "end": 2871.14, "text": " We can just add one more thing to X one more thing to X squared on the left and remove one thing on the right", "tokens": [492, 393, 445, 909, 472, 544, 551, 281, 1783, 472, 544, 551, 281, 1783, 8889, 322, 264, 1411, 293, 4159, 472, 551, 322, 264, 558], "temperature": 0.0, "avg_logprob": -0.127075702772228, "compression_ratio": 1.8185840707964602, "no_speech_prob": 9.42243332247017e-07}, {"id": 586, "seek": 286022, "start": 2871.2599999999998, "end": 2878.2999999999997, "text": " Okay, so we don't have to go through the whole lot each time and so we can turn this into a order n", "tokens": [1033, 11, 370, 321, 500, 380, 362, 281, 352, 807, 264, 1379, 688, 1184, 565, 293, 370, 321, 393, 1261, 341, 666, 257, 1668, 297], "temperature": 0.0, "avg_logprob": -0.127075702772228, "compression_ratio": 1.8185840707964602, "no_speech_prob": 9.42243332247017e-07}, {"id": 587, "seek": 286022, "start": 2878.98, "end": 2885.8399999999997, "text": " Algorithm so that's all I do here is I sort the data right and they're going to keep track of the count of things on the right", "tokens": [35014, 6819, 76, 370, 300, 311, 439, 286, 360, 510, 307, 286, 1333, 264, 1412, 558, 293, 436, 434, 516, 281, 1066, 2837, 295, 264, 1207, 295, 721, 322, 264, 558], "temperature": 0.0, "avg_logprob": -0.127075702772228, "compression_ratio": 1.8185840707964602, "no_speech_prob": 9.42243332247017e-07}, {"id": 588, "seek": 288584, "start": 2885.84, "end": 2890.32, "text": " the sum of things on the right and the sum of squares on the right and", "tokens": [264, 2408, 295, 721, 322, 264, 558, 293, 264, 2408, 295, 19368, 322, 264, 558, 293], "temperature": 0.0, "avg_logprob": -0.2688529517060967, "compression_ratio": 2.016759776536313, "no_speech_prob": 2.1233740881143603e-06}, {"id": 589, "seek": 288584, "start": 2891.44, "end": 2893.54, "text": " Initially everything's in the right-hand side", "tokens": [29446, 1203, 311, 294, 264, 558, 12, 5543, 1252], "temperature": 0.0, "avg_logprob": -0.2688529517060967, "compression_ratio": 2.016759776536313, "no_speech_prob": 2.1233740881143603e-06}, {"id": 590, "seek": 288584, "start": 2894.2400000000002, "end": 2896.56, "text": " Okay, so initially n is the count", "tokens": [1033, 11, 370, 9105, 297, 307, 264, 1207], "temperature": 0.0, "avg_logprob": -0.2688529517060967, "compression_ratio": 2.016759776536313, "no_speech_prob": 2.1233740881143603e-06}, {"id": 591, "seek": 288584, "start": 2897.36, "end": 2903.6800000000003, "text": " Y sum is the sum on the right and Y squared sum is the sum of squares on the right and", "tokens": [398, 2408, 307, 264, 2408, 322, 264, 558, 293, 398, 8889, 2408, 307, 264, 2408, 295, 19368, 322, 264, 558, 293], "temperature": 0.0, "avg_logprob": -0.2688529517060967, "compression_ratio": 2.016759776536313, "no_speech_prob": 2.1233740881143603e-06}, {"id": 592, "seek": 288584, "start": 2904.0, "end": 2910.0, "text": " Then nothing is initially on the left, so it's zeros okay, and then we just have to loop through", "tokens": [1396, 1825, 307, 9105, 322, 264, 1411, 11, 370, 309, 311, 35193, 1392, 11, 293, 550, 321, 445, 362, 281, 6367, 807], "temperature": 0.0, "avg_logprob": -0.2688529517060967, "compression_ratio": 2.016759776536313, "no_speech_prob": 2.1233740881143603e-06}, {"id": 593, "seek": 291000, "start": 2910.0, "end": 2915.28, "text": " each observation right and", "tokens": [1184, 14816, 558, 293], "temperature": 0.0, "avg_logprob": -0.19919615525465745, "compression_ratio": 2.022099447513812, "no_speech_prob": 1.7330482933175517e-06}, {"id": 594, "seek": 291000, "start": 2915.8, "end": 2921.98, "text": " Add one to the left-hand count subtract one from the left right hand count add the value to the left-hand count", "tokens": [5349, 472, 281, 264, 1411, 12, 5543, 1207, 16390, 472, 490, 264, 1411, 558, 1011, 1207, 909, 264, 2158, 281, 264, 1411, 12, 5543, 1207], "temperature": 0.0, "avg_logprob": -0.19919615525465745, "compression_ratio": 2.022099447513812, "no_speech_prob": 1.7330482933175517e-06}, {"id": 595, "seek": 291000, "start": 2922.2, "end": 2927.84, "text": " Subtract it from the right-hand count add the value squared to the left hand subtract it from the right hand", "tokens": [8511, 83, 1897, 309, 490, 264, 558, 12, 5543, 1207, 909, 264, 2158, 8889, 281, 264, 1411, 1011, 16390, 309, 490, 264, 558, 1011], "temperature": 0.0, "avg_logprob": -0.19919615525465745, "compression_ratio": 2.022099447513812, "no_speech_prob": 1.7330482933175517e-06}, {"id": 596, "seek": 291000, "start": 2928.48, "end": 2930.04, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.19919615525465745, "compression_ratio": 2.022099447513812, "no_speech_prob": 1.7330482933175517e-06}, {"id": 597, "seek": 291000, "start": 2930.04, "end": 2937.62, "text": " Now we do need to be careful though because if we're saying less than or equal to one say we're not stopping here", "tokens": [823, 321, 360, 643, 281, 312, 5026, 1673, 570, 498, 321, 434, 1566, 1570, 813, 420, 2681, 281, 472, 584, 321, 434, 406, 12767, 510], "temperature": 0.0, "avg_logprob": -0.19919615525465745, "compression_ratio": 2.022099447513812, "no_speech_prob": 1.7330482933175517e-06}, {"id": 598, "seek": 293762, "start": 2937.62, "end": 2940.66, "text": " We're stopping here like we have to have everything in that group", "tokens": [492, 434, 12767, 510, 411, 321, 362, 281, 362, 1203, 294, 300, 1594], "temperature": 0.0, "avg_logprob": -0.13311744337322332, "compression_ratio": 1.8847736625514404, "no_speech_prob": 2.601610503916163e-06}, {"id": 599, "seek": 293762, "start": 2941.18, "end": 2943.18, "text": " So the other thing I'm going to do is I'm just going to make sure", "tokens": [407, 264, 661, 551, 286, 478, 516, 281, 360, 307, 286, 478, 445, 516, 281, 652, 988], "temperature": 0.0, "avg_logprob": -0.13311744337322332, "compression_ratio": 1.8847736625514404, "no_speech_prob": 2.601610503916163e-06}, {"id": 600, "seek": 293762, "start": 2943.8599999999997, "end": 2949.7, "text": " That the next value is not the same as this value if it is I'm going to skip over it right", "tokens": [663, 264, 958, 2158, 307, 406, 264, 912, 382, 341, 2158, 498, 309, 307, 286, 478, 516, 281, 10023, 670, 309, 558], "temperature": 0.0, "avg_logprob": -0.13311744337322332, "compression_ratio": 1.8847736625514404, "no_speech_prob": 2.601610503916163e-06}, {"id": 601, "seek": 293762, "start": 2949.7, "end": 2951.7, "text": " So I'm just going to double check", "tokens": [407, 286, 478, 445, 516, 281, 3834, 1520], "temperature": 0.0, "avg_logprob": -0.13311744337322332, "compression_ratio": 1.8847736625514404, "no_speech_prob": 2.601610503916163e-06}, {"id": 602, "seek": 293762, "start": 2951.7, "end": 2954.08, "text": " That this value and the next one aren't the same", "tokens": [663, 341, 2158, 293, 264, 958, 472, 3212, 380, 264, 912], "temperature": 0.0, "avg_logprob": -0.13311744337322332, "compression_ratio": 1.8847736625514404, "no_speech_prob": 2.601610503916163e-06}, {"id": 603, "seek": 293762, "start": 2954.58, "end": 2958.4, "text": " Okay, so as long as they're not the same", "tokens": [1033, 11, 370, 382, 938, 382, 436, 434, 406, 264, 912], "temperature": 0.0, "avg_logprob": -0.13311744337322332, "compression_ratio": 1.8847736625514404, "no_speech_prob": 2.601610503916163e-06}, {"id": 604, "seek": 293762, "start": 2958.4, "end": 2965.3599999999997, "text": " I can keep going ahead and calculate my standard deviation now passing in the count the sum and the sum squared", "tokens": [286, 393, 1066, 516, 2286, 293, 8873, 452, 3832, 25163, 586, 8437, 294, 264, 1207, 264, 2408, 293, 264, 2408, 8889], "temperature": 0.0, "avg_logprob": -0.13311744337322332, "compression_ratio": 1.8847736625514404, "no_speech_prob": 2.601610503916163e-06}, {"id": 605, "seek": 296536, "start": 2965.36, "end": 2967.84, "text": " Right and there's that formula", "tokens": [1779, 293, 456, 311, 300, 8513], "temperature": 0.0, "avg_logprob": -0.19424282986184824, "compression_ratio": 1.7272727272727273, "no_speech_prob": 3.288745347163058e-06}, {"id": 606, "seek": 296536, "start": 2969.1200000000003, "end": 2971.1200000000003, "text": " Okay, the sum of squared", "tokens": [1033, 11, 264, 2408, 295, 8889], "temperature": 0.0, "avg_logprob": -0.19424282986184824, "compression_ratio": 1.7272727272727273, "no_speech_prob": 3.288745347163058e-06}, {"id": 607, "seek": 296536, "start": 2972.44, "end": 2976.44, "text": " Divided by the square of the sum sorry minus the square of the sum", "tokens": [413, 1843, 292, 538, 264, 3732, 295, 264, 2408, 2597, 3175, 264, 3732, 295, 264, 2408], "temperature": 0.0, "avg_logprob": -0.19424282986184824, "compression_ratio": 1.7272727272727273, "no_speech_prob": 3.288745347163058e-06}, {"id": 608, "seek": 296536, "start": 2978.6, "end": 2983.08, "text": " Do that for the right-hand side and so now we can calculate the weighted average score", "tokens": [1144, 300, 337, 264, 558, 12, 5543, 1252, 293, 370, 586, 321, 393, 8873, 264, 32807, 4274, 6175], "temperature": 0.0, "avg_logprob": -0.19424282986184824, "compression_ratio": 1.7272727272727273, "no_speech_prob": 3.288745347163058e-06}, {"id": 609, "seek": 296536, "start": 2983.2000000000003, "end": 2988.36, "text": " Just like before and all of these lines are now the same okay, so we've turned our order and", "tokens": [1449, 411, 949, 293, 439, 295, 613, 3876, 366, 586, 264, 912, 1392, 11, 370, 321, 600, 3574, 527, 1668, 293], "temperature": 0.0, "avg_logprob": -0.19424282986184824, "compression_ratio": 1.7272727272727273, "no_speech_prob": 3.288745347163058e-06}, {"id": 610, "seek": 296536, "start": 2989.2400000000002, "end": 2993.02, "text": " Squared algorithm into an order n algorithm and in general", "tokens": [8683, 1642, 9284, 666, 364, 1668, 297, 9284, 293, 294, 2674], "temperature": 0.0, "avg_logprob": -0.19424282986184824, "compression_ratio": 1.7272727272727273, "no_speech_prob": 3.288745347163058e-06}, {"id": 611, "seek": 299302, "start": 2993.02, "end": 2994.62, "text": " stuff", "tokens": [1507], "temperature": 0.0, "avg_logprob": -0.20974182814694523, "compression_ratio": 1.596638655462185, "no_speech_prob": 1.9638002868305193e-06}, {"id": 612, "seek": 299302, "start": 2994.62, "end": 3000.72, "text": " Like this is going to get you a lot more value than like pushing something onto a spark cluster or", "tokens": [1743, 341, 307, 516, 281, 483, 291, 257, 688, 544, 2158, 813, 411, 7380, 746, 3911, 257, 9908, 13630, 420], "temperature": 0.0, "avg_logprob": -0.20974182814694523, "compression_ratio": 1.596638655462185, "no_speech_prob": 1.9638002868305193e-06}, {"id": 613, "seek": 299302, "start": 3001.34, "end": 3006.0, "text": " Ordering faster RAM or using normal cores in your CPU or whatever right?", "tokens": [16321, 278, 4663, 14561, 420, 1228, 2710, 24826, 294, 428, 13199, 420, 2035, 558, 30], "temperature": 0.0, "avg_logprob": -0.20974182814694523, "compression_ratio": 1.596638655462185, "no_speech_prob": 1.9638002868305193e-06}, {"id": 614, "seek": 299302, "start": 3007.18, "end": 3011.46, "text": " This is the way you want to be you know improving your code and specifically", "tokens": [639, 307, 264, 636, 291, 528, 281, 312, 291, 458, 11470, 428, 3089, 293, 4682], "temperature": 0.0, "avg_logprob": -0.20974182814694523, "compression_ratio": 1.596638655462185, "no_speech_prob": 1.9638002868305193e-06}, {"id": 615, "seek": 299302, "start": 3013.38, "end": 3014.98, "text": " Write your code", "tokens": [23499, 428, 3089], "temperature": 0.0, "avg_logprob": -0.20974182814694523, "compression_ratio": 1.596638655462185, "no_speech_prob": 1.9638002868305193e-06}, {"id": 616, "seek": 299302, "start": 3014.98, "end": 3021.66, "text": " Right without thinking too much about performance run it is it fast enough for what you need then you're done", "tokens": [1779, 1553, 1953, 886, 709, 466, 3389, 1190, 309, 307, 309, 2370, 1547, 337, 437, 291, 643, 550, 291, 434, 1096], "temperature": 0.0, "avg_logprob": -0.20974182814694523, "compression_ratio": 1.596638655462185, "no_speech_prob": 1.9638002868305193e-06}, {"id": 617, "seek": 302166, "start": 3021.66, "end": 3023.66, "text": " if not", "tokens": [498, 406], "temperature": 0.0, "avg_logprob": -0.1914119138950255, "compression_ratio": 1.596938775510204, "no_speech_prob": 3.089487790930434e-06}, {"id": 618, "seek": 302166, "start": 3023.8999999999996, "end": 3025.8999999999996, "text": " Profile it right so in", "tokens": [6039, 794, 309, 558, 370, 294], "temperature": 0.0, "avg_logprob": -0.1914119138950255, "compression_ratio": 1.596938775510204, "no_speech_prob": 3.089487790930434e-06}, {"id": 619, "seek": 302166, "start": 3028.22, "end": 3032.3799999999997, "text": " Jupiter instead of saying percent time it you say percent p run and", "tokens": [24567, 2602, 295, 1566, 3043, 565, 309, 291, 584, 3043, 280, 1190, 293], "temperature": 0.0, "avg_logprob": -0.1914119138950255, "compression_ratio": 1.596938775510204, "no_speech_prob": 3.089487790930434e-06}, {"id": 620, "seek": 302166, "start": 3033.8599999999997, "end": 3035.8599999999997, "text": " It will tell you", "tokens": [467, 486, 980, 291], "temperature": 0.0, "avg_logprob": -0.1914119138950255, "compression_ratio": 1.596938775510204, "no_speech_prob": 3.089487790930434e-06}, {"id": 621, "seek": 302166, "start": 3035.98, "end": 3039.2599999999998, "text": " Exactly where the time was spent in your algorithm", "tokens": [7587, 689, 264, 565, 390, 4418, 294, 428, 9284], "temperature": 0.0, "avg_logprob": -0.1914119138950255, "compression_ratio": 1.596938775510204, "no_speech_prob": 3.089487790930434e-06}, {"id": 622, "seek": 302166, "start": 3039.2599999999998, "end": 3044.3799999999997, "text": " And then you can go to the bit that's actually taking the time and think about like okay is this", "tokens": [400, 550, 291, 393, 352, 281, 264, 857, 300, 311, 767, 1940, 264, 565, 293, 519, 466, 411, 1392, 307, 341], "temperature": 0.0, "avg_logprob": -0.1914119138950255, "compression_ratio": 1.596938775510204, "no_speech_prob": 3.089487790930434e-06}, {"id": 623, "seek": 302166, "start": 3045.3399999999997, "end": 3049.22, "text": " Is this algorithmically as efficient as it can be?", "tokens": [1119, 341, 9284, 984, 382, 7148, 382, 309, 393, 312, 30], "temperature": 0.0, "avg_logprob": -0.1914119138950255, "compression_ratio": 1.596938775510204, "no_speech_prob": 3.089487790930434e-06}, {"id": 624, "seek": 304922, "start": 3049.22, "end": 3054.8599999999997, "text": " Okay, so in this case we run it and we've gone down from", "tokens": [1033, 11, 370, 294, 341, 1389, 321, 1190, 309, 293, 321, 600, 2780, 760, 490], "temperature": 0.0, "avg_logprob": -0.19013383354939206, "compression_ratio": 1.530054644808743, "no_speech_prob": 5.203559680921899e-07}, {"id": 625, "seek": 304922, "start": 3056.18, "end": 3059.8999999999996, "text": " 76 milliseconds to less than 2 milliseconds and", "tokens": [24733, 34184, 281, 1570, 813, 568, 34184, 293], "temperature": 0.0, "avg_logprob": -0.19013383354939206, "compression_ratio": 1.530054644808743, "no_speech_prob": 5.203559680921899e-07}, {"id": 626, "seek": 304922, "start": 3060.62, "end": 3065.2599999999998, "text": " Now some people that are new to programming think like oh great. I've saved", "tokens": [823, 512, 561, 300, 366, 777, 281, 9410, 519, 411, 1954, 869, 13, 286, 600, 6624], "temperature": 0.0, "avg_logprob": -0.19013383354939206, "compression_ratio": 1.530054644808743, "no_speech_prob": 5.203559680921899e-07}, {"id": 627, "seek": 304922, "start": 3065.98, "end": 3069.7799999999997, "text": " 60 something milliseconds, but the point is this is going to get run", "tokens": [4060, 746, 34184, 11, 457, 264, 935, 307, 341, 307, 516, 281, 483, 1190], "temperature": 0.0, "avg_logprob": -0.19013383354939206, "compression_ratio": 1.530054644808743, "no_speech_prob": 5.203559680921899e-07}, {"id": 628, "seek": 304922, "start": 3071.1, "end": 3073.1, "text": " Like tens of millions of times", "tokens": [1743, 10688, 295, 6803, 295, 1413], "temperature": 0.0, "avg_logprob": -0.19013383354939206, "compression_ratio": 1.530054644808743, "no_speech_prob": 5.203559680921899e-07}, {"id": 629, "seek": 307310, "start": 3073.1, "end": 3078.86, "text": " Okay, so the 76 millisecond version is so slow that it's going to be", "tokens": [1033, 11, 370, 264, 24733, 27940, 18882, 3037, 307, 370, 2964, 300, 309, 311, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.18625615990680197, "compression_ratio": 1.593073593073593, "no_speech_prob": 4.092890776519198e-06}, {"id": 630, "seek": 307310, "start": 3079.74, "end": 3085.42, "text": " Impractical for any random forest you use in in practice right where else the 1 millisecond version", "tokens": [4331, 42559, 804, 337, 604, 4974, 6719, 291, 764, 294, 294, 3124, 558, 689, 1646, 264, 502, 27940, 18882, 3037], "temperature": 0.0, "avg_logprob": -0.18625615990680197, "compression_ratio": 1.593073593073593, "no_speech_prob": 4.092890776519198e-06}, {"id": 631, "seek": 307310, "start": 3085.42, "end": 3087.94, "text": " I found is actually quite quite acceptable", "tokens": [286, 1352, 307, 767, 1596, 1596, 15513], "temperature": 0.0, "avg_logprob": -0.18625615990680197, "compression_ratio": 1.593073593073593, "no_speech_prob": 4.092890776519198e-06}, {"id": 632, "seek": 307310, "start": 3089.06, "end": 3094.42, "text": " And then check the numbers should be exactly the same as before and they are okay", "tokens": [400, 550, 1520, 264, 3547, 820, 312, 2293, 264, 912, 382, 949, 293, 436, 366, 1392], "temperature": 0.0, "avg_logprob": -0.18625615990680197, "compression_ratio": 1.593073593073593, "no_speech_prob": 4.092890776519198e-06}, {"id": 633, "seek": 307310, "start": 3095.42, "end": 3097.42, "text": " so now that we have a", "tokens": [370, 586, 300, 321, 362, 257], "temperature": 0.0, "avg_logprob": -0.18625615990680197, "compression_ratio": 1.593073593073593, "no_speech_prob": 4.092890776519198e-06}, {"id": 634, "seek": 307310, "start": 3098.18, "end": 3100.94, "text": " Function find better split that does what we want I?", "tokens": [11166, 882, 915, 1101, 7472, 300, 775, 437, 321, 528, 286, 30], "temperature": 0.0, "avg_logprob": -0.18625615990680197, "compression_ratio": 1.593073593073593, "no_speech_prob": 4.092890776519198e-06}, {"id": 635, "seek": 310094, "start": 3100.94, "end": 3108.94, "text": " Want to insert it into my decision tree class, and this is a really cool Python trick Python does everything dynamically", "tokens": [11773, 281, 8969, 309, 666, 452, 3537, 4230, 1508, 11, 293, 341, 307, 257, 534, 1627, 15329, 4282, 15329, 775, 1203, 43492], "temperature": 0.0, "avg_logprob": -0.25953131011038116, "compression_ratio": 1.6057142857142856, "no_speech_prob": 5.626394568025717e-07}, {"id": 636, "seek": 310094, "start": 3109.46, "end": 3111.9, "text": " Right so we can actually say", "tokens": [1779, 370, 321, 393, 767, 584], "temperature": 0.0, "avg_logprob": -0.25953131011038116, "compression_ratio": 1.6057142857142856, "no_speech_prob": 5.626394568025717e-07}, {"id": 637, "seek": 310094, "start": 3113.46, "end": 3116.1, "text": " The method called find better split in", "tokens": [440, 3170, 1219, 915, 1101, 7472, 294], "temperature": 0.0, "avg_logprob": -0.25953131011038116, "compression_ratio": 1.6057142857142856, "no_speech_prob": 5.626394568025717e-07}, {"id": 638, "seek": 310094, "start": 3117.3, "end": 3119.3, "text": " decision tree is", "tokens": [3537, 4230, 307], "temperature": 0.0, "avg_logprob": -0.25953131011038116, "compression_ratio": 1.6057142857142856, "no_speech_prob": 5.626394568025717e-07}, {"id": 639, "seek": 310094, "start": 3120.06, "end": 3125.02, "text": " That function I just created and that might sticks it inside that class", "tokens": [663, 2445, 286, 445, 2942, 293, 300, 1062, 12518, 309, 1854, 300, 1508], "temperature": 0.0, "avg_logprob": -0.25953131011038116, "compression_ratio": 1.6057142857142856, "no_speech_prob": 5.626394568025717e-07}, {"id": 640, "seek": 310094, "start": 3125.86, "end": 3127.58, "text": " now", "tokens": [586], "temperature": 0.0, "avg_logprob": -0.25953131011038116, "compression_ratio": 1.6057142857142856, "no_speech_prob": 5.626394568025717e-07}, {"id": 641, "seek": 312758, "start": 3127.58, "end": 3132.1, "text": " I'll tell you what's slightly confusing about this is that this thing this word here and", "tokens": [286, 603, 980, 291, 437, 311, 4748, 13181, 466, 341, 307, 300, 341, 551, 341, 1349, 510, 293], "temperature": 0.0, "avg_logprob": -0.16117240764476634, "compression_ratio": 1.7055837563451777, "no_speech_prob": 2.64257641902077e-06}, {"id": 642, "seek": 312758, "start": 3132.62, "end": 3136.0, "text": " This word here. They actually have no relationship to each other", "tokens": [639, 1349, 510, 13, 814, 767, 362, 572, 2480, 281, 1184, 661], "temperature": 0.0, "avg_logprob": -0.16117240764476634, "compression_ratio": 1.7055837563451777, "no_speech_prob": 2.64257641902077e-06}, {"id": 643, "seek": 312758, "start": 3136.0, "end": 3141.74, "text": " They just happen to have the same letters in the same order right so like I could call this fine better split", "tokens": [814, 445, 1051, 281, 362, 264, 912, 7825, 294, 264, 912, 1668, 558, 370, 411, 286, 727, 818, 341, 2489, 1101, 7472], "temperature": 0.0, "avg_logprob": -0.16117240764476634, "compression_ratio": 1.7055837563451777, "no_speech_prob": 2.64257641902077e-06}, {"id": 644, "seek": 312758, "start": 3142.54, "end": 3144.2999999999997, "text": " underscore foo", "tokens": [37556, 726, 78], "temperature": 0.0, "avg_logprob": -0.16117240764476634, "compression_ratio": 1.7055837563451777, "no_speech_prob": 2.64257641902077e-06}, {"id": 645, "seek": 312758, "start": 3144.2999999999997, "end": 3147.42, "text": " Right and then I could like call that", "tokens": [1779, 293, 550, 286, 727, 411, 818, 300], "temperature": 0.0, "avg_logprob": -0.16117240764476634, "compression_ratio": 1.7055837563451777, "no_speech_prob": 2.64257641902077e-06}, {"id": 646, "seek": 312758, "start": 3150.74, "end": 3152.74, "text": " Right and call that", "tokens": [1779, 293, 818, 300], "temperature": 0.0, "avg_logprob": -0.16117240764476634, "compression_ratio": 1.7055837563451777, "no_speech_prob": 2.64257641902077e-06}, {"id": 647, "seek": 315274, "start": 3152.74, "end": 3160.3399999999997, "text": " That right so now my function is actually called fine better split underscore foo, but my method", "tokens": [663, 558, 370, 586, 452, 2445, 307, 767, 1219, 2489, 1101, 7472, 37556, 726, 78, 11, 457, 452, 3170], "temperature": 0.0, "avg_logprob": -0.2158317318210354, "compression_ratio": 1.8100558659217878, "no_speech_prob": 8.44621354190167e-07}, {"id": 648, "seek": 315274, "start": 3162.58, "end": 3165.02, "text": " I'm expecting to call something called", "tokens": [286, 478, 9650, 281, 818, 746, 1219], "temperature": 0.0, "avg_logprob": -0.2158317318210354, "compression_ratio": 1.8100558659217878, "no_speech_prob": 8.44621354190167e-07}, {"id": 649, "seek": 315274, "start": 3165.8999999999996, "end": 3167.8999999999996, "text": " Decision tree dot fine better split", "tokens": [12427, 1991, 4230, 5893, 2489, 1101, 7472], "temperature": 0.0, "avg_logprob": -0.2158317318210354, "compression_ratio": 1.8100558659217878, "no_speech_prob": 8.44621354190167e-07}, {"id": 650, "seek": 315274, "start": 3168.3399999999997, "end": 3174.4399999999996, "text": " Right so here. I could say decision tree dot fine better split equals find better split underscore foo", "tokens": [1779, 370, 510, 13, 286, 727, 584, 3537, 4230, 5893, 2489, 1101, 7472, 6915, 915, 1101, 7472, 37556, 726, 78], "temperature": 0.0, "avg_logprob": -0.2158317318210354, "compression_ratio": 1.8100558659217878, "no_speech_prob": 8.44621354190167e-07}, {"id": 651, "seek": 315274, "start": 3175.06, "end": 3177.9799999999996, "text": " Okay, you see that's the same thing right so like", "tokens": [1033, 11, 291, 536, 300, 311, 264, 912, 551, 558, 370, 411], "temperature": 0.0, "avg_logprob": -0.2158317318210354, "compression_ratio": 1.8100558659217878, "no_speech_prob": 8.44621354190167e-07}, {"id": 652, "seek": 317798, "start": 3177.98, "end": 3184.54, "text": " It's important to understand how namespaces work like in every", "tokens": [467, 311, 1021, 281, 1223, 577, 5288, 79, 2116, 589, 411, 294, 633], "temperature": 0.0, "avg_logprob": -0.1885657467684903, "compression_ratio": 1.6869565217391305, "no_speech_prob": 1.2098630577384029e-06}, {"id": 653, "seek": 317798, "start": 3185.06, "end": 3188.34, "text": " Language that you use one of the most important things is kind of understanding", "tokens": [24445, 300, 291, 764, 472, 295, 264, 881, 1021, 721, 307, 733, 295, 3701], "temperature": 0.0, "avg_logprob": -0.1885657467684903, "compression_ratio": 1.6869565217391305, "no_speech_prob": 1.2098630577384029e-06}, {"id": 654, "seek": 317798, "start": 3188.34, "end": 3193.38, "text": " How how it figures out what a name refers to so this here?", "tokens": [1012, 577, 309, 9624, 484, 437, 257, 1315, 14942, 281, 370, 341, 510, 30], "temperature": 0.0, "avg_logprob": -0.1885657467684903, "compression_ratio": 1.6869565217391305, "no_speech_prob": 1.2098630577384029e-06}, {"id": 655, "seek": 317798, "start": 3193.86, "end": 3200.98, "text": " Means find better split as defined inside this class right and no nowhere else right well", "tokens": [40290, 915, 1101, 7472, 382, 7642, 1854, 341, 1508, 558, 293, 572, 11159, 1646, 558, 731], "temperature": 0.0, "avg_logprob": -0.1885657467684903, "compression_ratio": 1.6869565217391305, "no_speech_prob": 1.2098630577384029e-06}, {"id": 656, "seek": 317798, "start": 3200.98, "end": 3207.1, "text": " I mean a sub a parent class, but never mind about that this one here means find better split foo", "tokens": [286, 914, 257, 1422, 257, 2596, 1508, 11, 457, 1128, 1575, 466, 300, 341, 472, 510, 1355, 915, 1101, 7472, 726, 78], "temperature": 0.0, "avg_logprob": -0.1885657467684903, "compression_ratio": 1.6869565217391305, "no_speech_prob": 1.2098630577384029e-06}, {"id": 657, "seek": 320710, "start": 3207.1, "end": 3214.98, "text": " In the global namespace a lot of languages don't have a global namespace, but Python does okay, and so", "tokens": [682, 264, 4338, 5288, 17940, 257, 688, 295, 8650, 500, 380, 362, 257, 4338, 5288, 17940, 11, 457, 15329, 775, 1392, 11, 293, 370], "temperature": 0.0, "avg_logprob": -0.13470221928187778, "compression_ratio": 1.790794979079498, "no_speech_prob": 1.3925441635365132e-06}, {"id": 658, "seek": 320710, "start": 3215.5, "end": 3217.14, "text": " the two are", "tokens": [264, 732, 366], "temperature": 0.0, "avg_logprob": -0.13470221928187778, "compression_ratio": 1.790794979079498, "no_speech_prob": 1.3925441635365132e-06}, {"id": 659, "seek": 320710, "start": 3217.14, "end": 3222.36, "text": " Like even if they happen to have the same letters in the same order. They're not referring in any way to the same thing", "tokens": [1743, 754, 498, 436, 1051, 281, 362, 264, 912, 7825, 294, 264, 912, 1668, 13, 814, 434, 406, 13761, 294, 604, 636, 281, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.13470221928187778, "compression_ratio": 1.790794979079498, "no_speech_prob": 1.3925441635365132e-06}, {"id": 660, "seek": 320710, "start": 3223.1, "end": 3225.1, "text": " That makes sense. It's like", "tokens": [663, 1669, 2020, 13, 467, 311, 411], "temperature": 0.0, "avg_logprob": -0.13470221928187778, "compression_ratio": 1.790794979079498, "no_speech_prob": 1.3925441635365132e-06}, {"id": 661, "seek": 320710, "start": 3225.58, "end": 3232.54, "text": " This family over here may have somebody called Jeremy and my family has somebody called Jeremy and our names happen to be the same", "tokens": [639, 1605, 670, 510, 815, 362, 2618, 1219, 17809, 293, 452, 1605, 575, 2618, 1219, 17809, 293, 527, 5288, 1051, 281, 312, 264, 912], "temperature": 0.0, "avg_logprob": -0.13470221928187778, "compression_ratio": 1.790794979079498, "no_speech_prob": 1.3925441635365132e-06}, {"id": 662, "seek": 323254, "start": 3232.54, "end": 3239.1, "text": " But we're not the same person okay? Great so now that we've stuck", "tokens": [583, 321, 434, 406, 264, 912, 954, 1392, 30, 3769, 370, 586, 300, 321, 600, 5541], "temperature": 0.0, "avg_logprob": -0.2616615018982818, "compression_ratio": 1.76536312849162, "no_speech_prob": 8.315264494740404e-07}, {"id": 663, "seek": 323254, "start": 3239.62, "end": 3245.58, "text": " The decision tree sorry the fine better split method inside the decision tree with this new definition", "tokens": [440, 3537, 4230, 2597, 264, 2489, 1101, 7472, 3170, 1854, 264, 3537, 4230, 365, 341, 777, 7123], "temperature": 0.0, "avg_logprob": -0.2616615018982818, "compression_ratio": 1.76536312849162, "no_speech_prob": 8.315264494740404e-07}, {"id": 664, "seek": 323254, "start": 3245.86, "end": 3248.7, "text": " When I now call the tree ensemble constructor", "tokens": [1133, 286, 586, 818, 264, 4230, 19492, 47479], "temperature": 0.0, "avg_logprob": -0.2616615018982818, "compression_ratio": 1.76536312849162, "no_speech_prob": 8.315264494740404e-07}, {"id": 665, "seek": 323254, "start": 3250.46, "end": 3254.38, "text": " Right the decision tree ensemble instructor called create tree", "tokens": [1779, 264, 3537, 4230, 19492, 18499, 1219, 1884, 4230], "temperature": 0.0, "avg_logprob": -0.2616615018982818, "compression_ratio": 1.76536312849162, "no_speech_prob": 8.315264494740404e-07}, {"id": 666, "seek": 323254, "start": 3255.34, "end": 3257.9, "text": " Create tree instantiated decision tree", "tokens": [20248, 4230, 9836, 72, 770, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.2616615018982818, "compression_ratio": 1.76536312849162, "no_speech_prob": 8.315264494740404e-07}, {"id": 667, "seek": 325790, "start": 3257.9, "end": 3265.5, "text": " Decision tree called find vast split which went through every column to see if it could find a better split and", "tokens": [12427, 1991, 4230, 1219, 915, 8369, 7472, 597, 1437, 807, 633, 7738, 281, 536, 498, 309, 727, 915, 257, 1101, 7472, 293], "temperature": 0.0, "avg_logprob": -0.20709529923804013, "compression_ratio": 1.6883720930232557, "no_speech_prob": 9.874602255877107e-07}, {"id": 668, "seek": 325790, "start": 3265.94, "end": 3268.9, "text": " we've now defined find better split and", "tokens": [321, 600, 586, 7642, 915, 1101, 7472, 293], "temperature": 0.0, "avg_logprob": -0.20709529923804013, "compression_ratio": 1.6883720930232557, "no_speech_prob": 9.874602255877107e-07}, {"id": 669, "seek": 325790, "start": 3269.7400000000002, "end": 3274.9, "text": " Therefore tree ensemble when we create it has gone ahead and done the split", "tokens": [7504, 4230, 19492, 562, 321, 1884, 309, 575, 2780, 2286, 293, 1096, 264, 7472], "temperature": 0.0, "avg_logprob": -0.20709529923804013, "compression_ratio": 1.6883720930232557, "no_speech_prob": 9.874602255877107e-07}, {"id": 670, "seek": 325790, "start": 3277.62, "end": 3284.86, "text": " That makes sense don't have any anybody have any questions or uncertainties about that like we're only creating one single split", "tokens": [663, 1669, 2020, 500, 380, 362, 604, 4472, 362, 604, 1651, 420, 11308, 6097, 466, 300, 411, 321, 434, 787, 4084, 472, 2167, 7472], "temperature": 0.0, "avg_logprob": -0.20709529923804013, "compression_ratio": 1.6883720930232557, "no_speech_prob": 9.874602255877107e-07}, {"id": 671, "seek": 328486, "start": 3284.86, "end": 3286.86, "text": " so far", "tokens": [370, 1400], "temperature": 0.0, "avg_logprob": -0.1725971021150288, "compression_ratio": 1.634453781512605, "no_speech_prob": 1.0030112207459752e-06}, {"id": 672, "seek": 328486, "start": 3288.38, "end": 3295.38, "text": " All right, so this is pretty pretty neat right we kind of just do a little bit at a time testing everything as we go", "tokens": [1057, 558, 11, 370, 341, 307, 1238, 1238, 10654, 558, 321, 733, 295, 445, 360, 257, 707, 857, 412, 257, 565, 4997, 1203, 382, 321, 352], "temperature": 0.0, "avg_logprob": -0.1725971021150288, "compression_ratio": 1.634453781512605, "no_speech_prob": 1.0030112207459752e-06}, {"id": 673, "seek": 328486, "start": 3296.1400000000003, "end": 3298.78, "text": " and so it's as as as you all", "tokens": [293, 370, 309, 311, 382, 382, 382, 291, 439], "temperature": 0.0, "avg_logprob": -0.1725971021150288, "compression_ratio": 1.634453781512605, "no_speech_prob": 1.0030112207459752e-06}, {"id": 674, "seek": 328486, "start": 3299.3, "end": 3302.26, "text": " Implement the random forest interpretation techniques", "tokens": [4331, 43704, 264, 4974, 6719, 14174, 7512], "temperature": 0.0, "avg_logprob": -0.1725971021150288, "compression_ratio": 1.634453781512605, "no_speech_prob": 1.0030112207459752e-06}, {"id": 675, "seek": 328486, "start": 3302.26, "end": 3307.34, "text": " You may want to try programming this way to like every step check that you know", "tokens": [509, 815, 528, 281, 853, 9410, 341, 636, 281, 411, 633, 1823, 1520, 300, 291, 458], "temperature": 0.0, "avg_logprob": -0.1725971021150288, "compression_ratio": 1.634453781512605, "no_speech_prob": 1.0030112207459752e-06}, {"id": 676, "seek": 328486, "start": 3307.54, "end": 3312.6200000000003, "text": " What you're doing matches up with what psychic learn does or with a test that you've built or whatever", "tokens": [708, 291, 434, 884, 10676, 493, 365, 437, 35406, 1466, 775, 420, 365, 257, 1500, 300, 291, 600, 3094, 420, 2035], "temperature": 0.0, "avg_logprob": -0.1725971021150288, "compression_ratio": 1.634453781512605, "no_speech_prob": 1.0030112207459752e-06}, {"id": 677, "seek": 331262, "start": 3312.62, "end": 3316.74, "text": " So at this point we should try to go deeper", "tokens": [407, 412, 341, 935, 321, 820, 853, 281, 352, 7731], "temperature": 0.0, "avg_logprob": -0.32537716456821986, "compression_ratio": 1.3910614525139664, "no_speech_prob": 1.10159248833952e-06}, {"id": 678, "seek": 331262, "start": 3317.7799999999997, "end": 3321.98, "text": " Very inception right so let's go now max depth is 2", "tokens": [4372, 49834, 558, 370, 718, 311, 352, 586, 11469, 7161, 307, 568], "temperature": 0.0, "avg_logprob": -0.32537716456821986, "compression_ratio": 1.3910614525139664, "no_speech_prob": 1.10159248833952e-06}, {"id": 679, "seek": 331262, "start": 3323.18, "end": 3327.7599999999998, "text": " And so here is what psychic learn did after breaking at year made 74", "tokens": [400, 370, 510, 307, 437, 35406, 1466, 630, 934, 7697, 412, 1064, 1027, 28868], "temperature": 0.0, "avg_logprob": -0.32537716456821986, "compression_ratio": 1.3910614525139664, "no_speech_prob": 1.10159248833952e-06}, {"id": 680, "seek": 331262, "start": 3328.2999999999997, "end": 3330.5, "text": " It then broke at machine hours beta", "tokens": [467, 550, 6902, 412, 3479, 2496, 9861], "temperature": 0.0, "avg_logprob": -0.32537716456821986, "compression_ratio": 1.3910614525139664, "no_speech_prob": 1.10159248833952e-06}, {"id": 681, "seek": 331262, "start": 3331.58, "end": 3333.58, "text": " 2956", "tokens": [9413, 18317], "temperature": 0.0, "avg_logprob": -0.32537716456821986, "compression_ratio": 1.3910614525139664, "no_speech_prob": 1.10159248833952e-06}, {"id": 682, "seek": 331262, "start": 3333.8599999999997, "end": 3335.8599999999997, "text": " So we had this thing called", "tokens": [407, 321, 632, 341, 551, 1219], "temperature": 0.0, "avg_logprob": -0.32537716456821986, "compression_ratio": 1.3910614525139664, "no_speech_prob": 1.10159248833952e-06}, {"id": 683, "seek": 331262, "start": 3337.1, "end": 3339.1, "text": " Find vast split", "tokens": [11809, 8369, 7472], "temperature": 0.0, "avg_logprob": -0.32537716456821986, "compression_ratio": 1.3910614525139664, "no_speech_prob": 1.10159248833952e-06}, {"id": 684, "seek": 333910, "start": 3339.1, "end": 3345.94, "text": " Right we just went through every column and tried to see if there was a better split there right but actually", "tokens": [1779, 321, 445, 1437, 807, 633, 7738, 293, 3031, 281, 536, 498, 456, 390, 257, 1101, 7472, 456, 558, 457, 767], "temperature": 0.0, "avg_logprob": -0.14827830905006045, "compression_ratio": 2.0675675675675675, "no_speech_prob": 8.990941751108039e-07}, {"id": 685, "seek": 333910, "start": 3346.58, "end": 3348.58, "text": " We need to go a bit further than that", "tokens": [492, 643, 281, 352, 257, 857, 3052, 813, 300], "temperature": 0.0, "avg_logprob": -0.14827830905006045, "compression_ratio": 2.0675675675675675, "no_speech_prob": 8.990941751108039e-07}, {"id": 686, "seek": 333910, "start": 3348.7799999999997, "end": 3354.5, "text": " Not only do we have to go through every column and see if there's a better split in this node", "tokens": [1726, 787, 360, 321, 362, 281, 352, 807, 633, 7738, 293, 536, 498, 456, 311, 257, 1101, 7472, 294, 341, 9984], "temperature": 0.0, "avg_logprob": -0.14827830905006045, "compression_ratio": 2.0675675675675675, "no_speech_prob": 8.990941751108039e-07}, {"id": 687, "seek": 333910, "start": 3355.2599999999998, "end": 3361.02, "text": " But then we also have to see whether there's a better split in the left and the right sides that we just created", "tokens": [583, 550, 321, 611, 362, 281, 536, 1968, 456, 311, 257, 1101, 7472, 294, 264, 1411, 293, 264, 558, 4881, 300, 321, 445, 2942], "temperature": 0.0, "avg_logprob": -0.14827830905006045, "compression_ratio": 2.0675675675675675, "no_speech_prob": 8.990941751108039e-07}, {"id": 688, "seek": 333910, "start": 3361.7, "end": 3367.54, "text": " Right in other words the left right side and the right hand side should become decision trees themselves", "tokens": [1779, 294, 661, 2283, 264, 1411, 558, 1252, 293, 264, 558, 1011, 1252, 820, 1813, 3537, 5852, 2969], "temperature": 0.0, "avg_logprob": -0.14827830905006045, "compression_ratio": 2.0675675675675675, "no_speech_prob": 8.990941751108039e-07}, {"id": 689, "seek": 336754, "start": 3367.54, "end": 3373.22, "text": " Right so there's no difference at all between what we do here to create this tree", "tokens": [1779, 370, 456, 311, 572, 2649, 412, 439, 1296, 437, 321, 360, 510, 281, 1884, 341, 4230], "temperature": 0.0, "avg_logprob": -0.17201906569460604, "compression_ratio": 1.7924528301886793, "no_speech_prob": 1.392543481415487e-06}, {"id": 690, "seek": 336754, "start": 3373.22, "end": 3376.58, "text": " And what we do here to create this tree other than this one contains", "tokens": [400, 437, 321, 360, 510, 281, 1884, 341, 4230, 661, 813, 341, 472, 8306], "temperature": 0.0, "avg_logprob": -0.17201906569460604, "compression_ratio": 1.7924528301886793, "no_speech_prob": 1.392543481415487e-06}, {"id": 691, "seek": 336754, "start": 3377.42, "end": 3380.22, "text": " 159 samples this one contains a thousand", "tokens": [2119, 24, 10938, 341, 472, 8306, 257, 4714], "temperature": 0.0, "avg_logprob": -0.17201906569460604, "compression_ratio": 1.7924528301886793, "no_speech_prob": 1.392543481415487e-06}, {"id": 692, "seek": 336754, "start": 3381.7, "end": 3384.86, "text": " So this row of codes exactly the same as we had before", "tokens": [407, 341, 5386, 295, 14211, 2293, 264, 912, 382, 321, 632, 949], "temperature": 0.0, "avg_logprob": -0.17201906569460604, "compression_ratio": 1.7924528301886793, "no_speech_prob": 1.392543481415487e-06}, {"id": 693, "seek": 336754, "start": 3385.82, "end": 3391.62, "text": " Right and then we check actually we could do this a little bit easier. We could say if self dot is", "tokens": [1779, 293, 550, 321, 1520, 767, 321, 727, 360, 341, 257, 707, 857, 3571, 13, 492, 727, 584, 498, 2698, 5893, 307], "temperature": 0.0, "avg_logprob": -0.17201906569460604, "compression_ratio": 1.7924528301886793, "no_speech_prob": 1.392543481415487e-06}, {"id": 694, "seek": 336754, "start": 3392.86, "end": 3395.22, "text": " Leaf right would be the same thing", "tokens": [32290, 558, 576, 312, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.17201906569460604, "compression_ratio": 1.7924528301886793, "no_speech_prob": 1.392543481415487e-06}, {"id": 695, "seek": 339522, "start": 3395.22, "end": 3400.66, "text": " Okay, but I'll just leave it here for now. So is self dot score so if the score is", "tokens": [1033, 11, 457, 286, 603, 445, 1856, 309, 510, 337, 586, 13, 407, 307, 2698, 5893, 6175, 370, 498, 264, 6175, 307], "temperature": 0.0, "avg_logprob": -0.35114743492820044, "compression_ratio": 1.529100529100529, "no_speech_prob": 6.854280854895478e-06}, {"id": 696, "seek": 339522, "start": 3401.62, "end": 3403.9399999999996, "text": " Infinite still in fact. Let's write it properly", "tokens": [43368, 920, 294, 1186, 13, 961, 311, 2464, 309, 6108], "temperature": 0.0, "avg_logprob": -0.35114743492820044, "compression_ratio": 1.529100529100529, "no_speech_prob": 6.854280854895478e-06}, {"id": 697, "seek": 339522, "start": 3404.7799999999997, "end": 3406.7799999999997, "text": " Yes, wait", "tokens": [1079, 11, 1699], "temperature": 0.0, "avg_logprob": -0.35114743492820044, "compression_ratio": 1.529100529100529, "no_speech_prob": 6.854280854895478e-06}, {"id": 698, "seek": 339522, "start": 3407.06, "end": 3409.06, "text": " So let's go back up and just remind ourselves", "tokens": [407, 718, 311, 352, 646, 493, 293, 445, 4160, 4175], "temperature": 0.0, "avg_logprob": -0.35114743492820044, "compression_ratio": 1.529100529100529, "no_speech_prob": 6.854280854895478e-06}, {"id": 699, "seek": 339522, "start": 3410.2999999999997, "end": 3411.58, "text": " is", "tokens": [307], "temperature": 0.0, "avg_logprob": -0.35114743492820044, "compression_ratio": 1.529100529100529, "no_speech_prob": 6.854280854895478e-06}, {"id": 700, "seek": 339522, "start": 3411.58, "end": 3413.3399999999997, "text": " leaf is", "tokens": [10871, 307], "temperature": 0.0, "avg_logprob": -0.35114743492820044, "compression_ratio": 1.529100529100529, "no_speech_prob": 6.854280854895478e-06}, {"id": 701, "seek": 339522, "start": 3413.3399999999997, "end": 3415.72, "text": " Self dot score equals in okay", "tokens": [16348, 5893, 6175, 6915, 294, 1392], "temperature": 0.0, "avg_logprob": -0.35114743492820044, "compression_ratio": 1.529100529100529, "no_speech_prob": 6.854280854895478e-06}, {"id": 702, "seek": 339522, "start": 3416.62, "end": 3419.8799999999997, "text": " So since there we might as well use it so if it's a leaf node", "tokens": [407, 1670, 456, 321, 1062, 382, 731, 764, 309, 370, 498, 309, 311, 257, 10871, 9984], "temperature": 0.0, "avg_logprob": -0.35114743492820044, "compression_ratio": 1.529100529100529, "no_speech_prob": 6.854280854895478e-06}, {"id": 703, "seek": 341988, "start": 3419.88, "end": 3426.08, "text": " Then we have nothing further to do right so that means we're right at the bottom", "tokens": [1396, 321, 362, 1825, 3052, 281, 360, 558, 370, 300, 1355, 321, 434, 558, 412, 264, 2767], "temperature": 0.0, "avg_logprob": -0.1340391732812897, "compression_ratio": 1.9256198347107438, "no_speech_prob": 3.393136239537853e-06}, {"id": 704, "seek": 341988, "start": 3426.08, "end": 3432.2000000000003, "text": " There's no split that's been made okay, so we don't have to do anything further on the other hand if it's not a leaf node", "tokens": [821, 311, 572, 7472, 300, 311, 668, 1027, 1392, 11, 370, 321, 500, 380, 362, 281, 360, 1340, 3052, 322, 264, 661, 1011, 498, 309, 311, 406, 257, 10871, 9984], "temperature": 0.0, "avg_logprob": -0.1340391732812897, "compression_ratio": 1.9256198347107438, "no_speech_prob": 3.393136239537853e-06}, {"id": 705, "seek": 341988, "start": 3432.2000000000003, "end": 3434.2000000000003, "text": " So it's somewhere back earlier on", "tokens": [407, 309, 311, 4079, 646, 3071, 322], "temperature": 0.0, "avg_logprob": -0.1340391732812897, "compression_ratio": 1.9256198347107438, "no_speech_prob": 3.393136239537853e-06}, {"id": 706, "seek": 341988, "start": 3434.28, "end": 3438.52, "text": " Then we need to split it into the left-hand side and the right-hand side", "tokens": [1396, 321, 643, 281, 7472, 309, 666, 264, 1411, 12, 5543, 1252, 293, 264, 558, 12, 5543, 1252], "temperature": 0.0, "avg_logprob": -0.1340391732812897, "compression_ratio": 1.9256198347107438, "no_speech_prob": 3.393136239537853e-06}, {"id": 707, "seek": 341988, "start": 3438.92, "end": 3445.32, "text": " Now earlier on we created a left-hand side and a right-hand side a ray of Boolean's right now", "tokens": [823, 3071, 322, 321, 2942, 257, 1411, 12, 5543, 1252, 293, 257, 558, 12, 5543, 1252, 257, 18592, 295, 23351, 28499, 311, 558, 586], "temperature": 0.0, "avg_logprob": -0.1340391732812897, "compression_ratio": 1.9256198347107438, "no_speech_prob": 3.393136239537853e-06}, {"id": 708, "seek": 344532, "start": 3445.32, "end": 3449.4, "text": " I'm better would be to have here would be have an array of indexes", "tokens": [286, 478, 1101, 576, 312, 281, 362, 510, 576, 312, 362, 364, 10225, 295, 8186, 279], "temperature": 0.0, "avg_logprob": -0.12732223636847884, "compression_ratio": 1.7971014492753623, "no_speech_prob": 6.577923272743647e-07}, {"id": 709, "seek": 344532, "start": 3449.4, "end": 3454.28, "text": " And that's because we don't want to have a full array of all the Boolean's in every single", "tokens": [400, 300, 311, 570, 321, 500, 380, 528, 281, 362, 257, 1577, 10225, 295, 439, 264, 23351, 28499, 311, 294, 633, 2167], "temperature": 0.0, "avg_logprob": -0.12732223636847884, "compression_ratio": 1.7971014492753623, "no_speech_prob": 6.577923272743647e-07}, {"id": 710, "seek": 344532, "start": 3454.6800000000003, "end": 3459.6000000000004, "text": " Node right because remember although it doesn't look like there are many nodes when you see a tree of this size", "tokens": [38640, 558, 570, 1604, 4878, 309, 1177, 380, 574, 411, 456, 366, 867, 13891, 562, 291, 536, 257, 4230, 295, 341, 2744], "temperature": 0.0, "avg_logprob": -0.12732223636847884, "compression_ratio": 1.7971014492753623, "no_speech_prob": 6.577923272743647e-07}, {"id": 711, "seek": 344532, "start": 3460.2000000000003, "end": 3462.2000000000003, "text": " When it's fully expanded", "tokens": [1133, 309, 311, 4498, 14342], "temperature": 0.0, "avg_logprob": -0.12732223636847884, "compression_ratio": 1.7971014492753623, "no_speech_prob": 6.577923272743647e-07}, {"id": 712, "seek": 344532, "start": 3462.52, "end": 3468.04, "text": " the bottom level if there's a minimum leaf size of one contains the same number of nodes as", "tokens": [264, 2767, 1496, 498, 456, 311, 257, 7285, 10871, 2744, 295, 472, 8306, 264, 912, 1230, 295, 13891, 382], "temperature": 0.0, "avg_logprob": -0.12732223636847884, "compression_ratio": 1.7971014492753623, "no_speech_prob": 6.577923272743647e-07}, {"id": 713, "seek": 346804, "start": 3468.04, "end": 3475.12, "text": " The entire data set and so if every one of those contained a full Boolean array of size of the whole data set", "tokens": [440, 2302, 1412, 992, 293, 370, 498, 633, 472, 295, 729, 16212, 257, 1577, 23351, 28499, 10225, 295, 2744, 295, 264, 1379, 1412, 992], "temperature": 0.0, "avg_logprob": -0.16853616855762624, "compression_ratio": 1.68359375, "no_speech_prob": 7.979936356150574e-08}, {"id": 714, "seek": 346804, "start": 3475.16, "end": 3481.6, "text": " You've got squared memory requirements, which would be bad right on the other hand if we just store the indexes", "tokens": [509, 600, 658, 8889, 4675, 7728, 11, 597, 576, 312, 1578, 558, 322, 264, 661, 1011, 498, 321, 445, 3531, 264, 8186, 279], "temperature": 0.0, "avg_logprob": -0.16853616855762624, "compression_ratio": 1.68359375, "no_speech_prob": 7.979936356150574e-08}, {"id": 715, "seek": 346804, "start": 3481.96, "end": 3484.68, "text": " If the things in this node, then that's going to get smaller and smaller", "tokens": [759, 264, 721, 294, 341, 9984, 11, 550, 300, 311, 516, 281, 483, 4356, 293, 4356], "temperature": 0.0, "avg_logprob": -0.16853616855762624, "compression_ratio": 1.68359375, "no_speech_prob": 7.979936356150574e-08}, {"id": 716, "seek": 346804, "start": 3485.52, "end": 3487.52, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.16853616855762624, "compression_ratio": 1.68359375, "no_speech_prob": 7.979936356150574e-08}, {"id": 717, "seek": 346804, "start": 3487.84, "end": 3493.6, "text": " So NP dot nonzero is exactly the same as just this thing which gets the Boolean array", "tokens": [407, 38611, 5893, 2107, 32226, 307, 2293, 264, 912, 382, 445, 341, 551, 597, 2170, 264, 23351, 28499, 10225], "temperature": 0.0, "avg_logprob": -0.16853616855762624, "compression_ratio": 1.68359375, "no_speech_prob": 7.979936356150574e-08}, {"id": 718, "seek": 349360, "start": 3493.6, "end": 3501.12, "text": " But it turns it into the indexes of the trues okay, so this is now a list of indexes for the left-hand side and", "tokens": [583, 309, 4523, 309, 666, 264, 8186, 279, 295, 264, 504, 1247, 1392, 11, 370, 341, 307, 586, 257, 1329, 295, 8186, 279, 337, 264, 1411, 12, 5543, 1252, 293], "temperature": 0.0, "avg_logprob": -0.15914337158203126, "compression_ratio": 2.1137440758293837, "no_speech_prob": 2.2603194338444155e-06}, {"id": 719, "seek": 349360, "start": 3501.92, "end": 3503.92, "text": " indexes the right-hand side", "tokens": [8186, 279, 264, 558, 12, 5543, 1252], "temperature": 0.0, "avg_logprob": -0.15914337158203126, "compression_ratio": 2.1137440758293837, "no_speech_prob": 2.2603194338444155e-06}, {"id": 720, "seek": 349360, "start": 3504.3199999999997, "end": 3507.8199999999997, "text": " So now that we have the indexes the left-hand side and the right-hand side", "tokens": [407, 586, 300, 321, 362, 264, 8186, 279, 264, 1411, 12, 5543, 1252, 293, 264, 558, 12, 5543, 1252], "temperature": 0.0, "avg_logprob": -0.15914337158203126, "compression_ratio": 2.1137440758293837, "no_speech_prob": 2.2603194338444155e-06}, {"id": 721, "seek": 349360, "start": 3508.8399999999997, "end": 3510.8399999999997, "text": " We can now just go ahead and create a decision tree", "tokens": [492, 393, 586, 445, 352, 2286, 293, 1884, 257, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.15914337158203126, "compression_ratio": 2.1137440758293837, "no_speech_prob": 2.2603194338444155e-06}, {"id": 722, "seek": 349360, "start": 3511.36, "end": 3513.36, "text": " Okay, so there's a decision tree for the left", "tokens": [1033, 11, 370, 456, 311, 257, 3537, 4230, 337, 264, 1411], "temperature": 0.0, "avg_logprob": -0.15914337158203126, "compression_ratio": 2.1137440758293837, "no_speech_prob": 2.2603194338444155e-06}, {"id": 723, "seek": 349360, "start": 3514.3199999999997, "end": 3516.3199999999997, "text": " And there's our decision tree for the right", "tokens": [400, 456, 311, 527, 3537, 4230, 337, 264, 558], "temperature": 0.0, "avg_logprob": -0.15914337158203126, "compression_ratio": 2.1137440758293837, "no_speech_prob": 2.2603194338444155e-06}, {"id": 724, "seek": 349360, "start": 3516.56, "end": 3519.0, "text": " Okay, and we don't have to do anything else we've already written these", "tokens": [1033, 11, 293, 321, 500, 380, 362, 281, 360, 1340, 1646, 321, 600, 1217, 3720, 613], "temperature": 0.0, "avg_logprob": -0.15914337158203126, "compression_ratio": 2.1137440758293837, "no_speech_prob": 2.2603194338444155e-06}, {"id": 725, "seek": 349360, "start": 3519.96, "end": 3521.96, "text": " we already have a", "tokens": [321, 1217, 362, 257], "temperature": 0.0, "avg_logprob": -0.15914337158203126, "compression_ratio": 2.1137440758293837, "no_speech_prob": 2.2603194338444155e-06}, {"id": 726, "seek": 352196, "start": 3521.96, "end": 3524.96, "text": " function of a constructor that can create a decision tree", "tokens": [2445, 295, 257, 47479, 300, 393, 1884, 257, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.23707034371115945, "compression_ratio": 1.7116564417177915, "no_speech_prob": 1.3496992323780432e-06}, {"id": 727, "seek": 352196, "start": 3526.04, "end": 3532.76, "text": " So like when you really think about what this is doing it kind of hurts your head right because", "tokens": [407, 411, 562, 291, 534, 519, 466, 437, 341, 307, 884, 309, 733, 295, 11051, 428, 1378, 558, 570], "temperature": 0.0, "avg_logprob": -0.23707034371115945, "compression_ratio": 1.7116564417177915, "no_speech_prob": 1.3496992323780432e-06}, {"id": 728, "seek": 352196, "start": 3533.4, "end": 3537.04, "text": " the reason the whole reason that find varsplit got called is", "tokens": [264, 1778, 264, 1379, 1778, 300, 915, 46130, 564, 270, 658, 1219, 307], "temperature": 0.0, "avg_logprob": -0.23707034371115945, "compression_ratio": 1.7116564417177915, "no_speech_prob": 1.3496992323780432e-06}, {"id": 729, "seek": 352196, "start": 3538.36, "end": 3540.36, "text": " because", "tokens": [570], "temperature": 0.0, "avg_logprob": -0.23707034371115945, "compression_ratio": 1.7116564417177915, "no_speech_prob": 1.3496992323780432e-06}, {"id": 730, "seek": 352196, "start": 3542.68, "end": 3546.8, "text": " Find varsplit is called by the decision tree constructor", "tokens": [11809, 46130, 564, 270, 307, 1219, 538, 264, 3537, 4230, 47479], "temperature": 0.0, "avg_logprob": -0.23707034371115945, "compression_ratio": 1.7116564417177915, "no_speech_prob": 1.3496992323780432e-06}, {"id": 731, "seek": 354680, "start": 3546.8, "end": 3555.0800000000004, "text": " But then the decision tree that then find varsplit itself then causes the decision tree constructor, so we actually have", "tokens": [583, 550, 264, 3537, 4230, 300, 550, 915, 46130, 564, 270, 2564, 550, 7700, 264, 3537, 4230, 47479, 11, 370, 321, 767, 362], "temperature": 0.0, "avg_logprob": -0.20589839710908778, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.3925446182838641e-06}, {"id": 732, "seek": 354680, "start": 3556.04, "end": 3558.04, "text": " circular recursion and", "tokens": [16476, 20560, 313, 293], "temperature": 0.0, "avg_logprob": -0.20589839710908778, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.3925446182838641e-06}, {"id": 733, "seek": 354680, "start": 3559.4, "end": 3563.1600000000003, "text": " I'm not nearly smart enough to be able to think through recursion", "tokens": [286, 478, 406, 6217, 4069, 1547, 281, 312, 1075, 281, 519, 807, 20560, 313], "temperature": 0.0, "avg_logprob": -0.20589839710908778, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.3925446182838641e-06}, {"id": 734, "seek": 354680, "start": 3563.48, "end": 3568.04, "text": " So I just choose not to right like I just write what I mean and", "tokens": [407, 286, 445, 2826, 406, 281, 558, 411, 286, 445, 2464, 437, 286, 914, 293], "temperature": 0.0, "avg_logprob": -0.20589839710908778, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.3925446182838641e-06}, {"id": 735, "seek": 354680, "start": 3568.76, "end": 3570.76, "text": " Then I don't think about it anymore", "tokens": [1396, 286, 500, 380, 519, 466, 309, 3602], "temperature": 0.0, "avg_logprob": -0.20589839710908778, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.3925446182838641e-06}, {"id": 736, "seek": 354680, "start": 3571.28, "end": 3573.28, "text": " Right like what do I want?", "tokens": [1779, 411, 437, 360, 286, 528, 30], "temperature": 0.0, "avg_logprob": -0.20589839710908778, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.3925446182838641e-06}, {"id": 737, "seek": 357328, "start": 3573.28, "end": 3577.44, "text": " Well to find a variable split I've got to go through every column see if there's something better", "tokens": [1042, 281, 915, 257, 7006, 7472, 286, 600, 658, 281, 352, 807, 633, 7738, 536, 498, 456, 311, 746, 1101], "temperature": 0.0, "avg_logprob": -0.18260419564168962, "compression_ratio": 1.7194244604316546, "no_speech_prob": 3.6119699871051125e-06}, {"id": 738, "seek": 357328, "start": 3578.52, "end": 3584.32, "text": " If it managed to do a split figure out the left-hand side of the right-hand side and make them into decision trees", "tokens": [759, 309, 6453, 281, 360, 257, 7472, 2573, 484, 264, 1411, 12, 5543, 1252, 295, 264, 558, 12, 5543, 1252, 293, 652, 552, 666, 3537, 5852], "temperature": 0.0, "avg_logprob": -0.18260419564168962, "compression_ratio": 1.7194244604316546, "no_speech_prob": 3.6119699871051125e-06}, {"id": 739, "seek": 357328, "start": 3585.1200000000003, "end": 3591.2400000000002, "text": " Okay, but now try to think through how these two methods call each other would just drive me crazy", "tokens": [1033, 11, 457, 586, 853, 281, 519, 807, 577, 613, 732, 7150, 818, 1184, 661, 576, 445, 3332, 385, 3219], "temperature": 0.0, "avg_logprob": -0.18260419564168962, "compression_ratio": 1.7194244604316546, "no_speech_prob": 3.6119699871051125e-06}, {"id": 740, "seek": 357328, "start": 3591.2400000000002, "end": 3596.0, "text": " But I don't need to right. I know I have a decision tree constructor that works, right?", "tokens": [583, 286, 500, 380, 643, 281, 558, 13, 286, 458, 286, 362, 257, 3537, 4230, 47479, 300, 1985, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18260419564168962, "compression_ratio": 1.7194244604316546, "no_speech_prob": 3.6119699871051125e-06}, {"id": 741, "seek": 357328, "start": 3596.0, "end": 3600.6400000000003, "text": " I know I have a via find varsplit that works. So that's it right? That's how I", "tokens": [286, 458, 286, 362, 257, 5766, 915, 46130, 564, 270, 300, 1985, 13, 407, 300, 311, 309, 558, 30, 663, 311, 577, 286], "temperature": 0.0, "avg_logprob": -0.18260419564168962, "compression_ratio": 1.7194244604316546, "no_speech_prob": 3.6119699871051125e-06}, {"id": 742, "seek": 360064, "start": 3600.64, "end": 3603.24, "text": " Do recursive programming is?", "tokens": [1144, 20560, 488, 9410, 307, 30], "temperature": 0.0, "avg_logprob": -0.18439105912750842, "compression_ratio": 1.6378600823045268, "no_speech_prob": 3.2887414818105754e-06}, {"id": 743, "seek": 360064, "start": 3604.0, "end": 3608.48, "text": " By pretending I don't I just just ignore it. That's my advice", "tokens": [3146, 22106, 286, 500, 380, 286, 445, 445, 11200, 309, 13, 663, 311, 452, 5192], "temperature": 0.0, "avg_logprob": -0.18439105912750842, "compression_ratio": 1.6378600823045268, "no_speech_prob": 3.2887414818105754e-06}, {"id": 744, "seek": 360064, "start": 3608.48, "end": 3612.7999999999997, "text": " I lot of you are probably smart enough to be able to think through it better than I can so that's fine", "tokens": [286, 688, 295, 291, 366, 1391, 4069, 1547, 281, 312, 1075, 281, 519, 807, 309, 1101, 813, 286, 393, 370, 300, 311, 2489], "temperature": 0.0, "avg_logprob": -0.18439105912750842, "compression_ratio": 1.6378600823045268, "no_speech_prob": 3.2887414818105754e-06}, {"id": 745, "seek": 360064, "start": 3612.7999999999997, "end": 3618.16, "text": " If you can right so now that I've written that again, I can patch it into the decision tree class", "tokens": [759, 291, 393, 558, 370, 586, 300, 286, 600, 3720, 300, 797, 11, 286, 393, 9972, 309, 666, 264, 3537, 4230, 1508], "temperature": 0.0, "avg_logprob": -0.18439105912750842, "compression_ratio": 1.6378600823045268, "no_speech_prob": 3.2887414818105754e-06}, {"id": 746, "seek": 360064, "start": 3621.48, "end": 3623.2799999999997, "text": " And as soon as I do", "tokens": [400, 382, 2321, 382, 286, 360], "temperature": 0.0, "avg_logprob": -0.18439105912750842, "compression_ratio": 1.6378600823045268, "no_speech_prob": 3.2887414818105754e-06}, {"id": 747, "seek": 360064, "start": 3623.2799999999997, "end": 3628.7599999999998, "text": " The tree ensemble constructor will now use that right because Python's dynamic, right?", "tokens": [440, 4230, 19492, 47479, 486, 586, 764, 300, 558, 570, 15329, 311, 8546, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18439105912750842, "compression_ratio": 1.6378600823045268, "no_speech_prob": 3.2887414818105754e-06}, {"id": 748, "seek": 362876, "start": 3628.76, "end": 3630.96, "text": " That's just happens automatically", "tokens": [663, 311, 445, 2314, 6772], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 749, "seek": 362876, "start": 3631.8, "end": 3633.8, "text": " So now I can check", "tokens": [407, 586, 286, 393, 1520], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 750, "seek": 362876, "start": 3634.0400000000004, "end": 3636.0400000000004, "text": " my left hand side", "tokens": [452, 1411, 1011, 1252], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 751, "seek": 362876, "start": 3636.84, "end": 3639.6000000000004, "text": " Should have a hundred and fifty nine samples", "tokens": [6454, 362, 257, 3262, 293, 13442, 4949, 10938], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 752, "seek": 362876, "start": 3640.4, "end": 3643.6000000000004, "text": " Right and a value of nine point six six", "tokens": [1779, 293, 257, 2158, 295, 4949, 935, 2309, 2309], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 753, "seek": 362876, "start": 3644.36, "end": 3647.0800000000004, "text": " There it is hundred fifty nine samples nine point six six", "tokens": [821, 309, 307, 3262, 13442, 4949, 10938, 4949, 935, 2309, 2309], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 754, "seek": 362876, "start": 3647.6800000000003, "end": 3649.6800000000003, "text": " right hand side", "tokens": [558, 1011, 1252], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 755, "seek": 362876, "start": 3650.0, "end": 3652.0, "text": " Eight forty one ten point one five", "tokens": [17708, 15815, 472, 2064, 935, 472, 1732], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 756, "seek": 362876, "start": 3652.6000000000004, "end": 3654.7200000000003, "text": " the left hand side of the left hand side", "tokens": [264, 1411, 1011, 1252, 295, 264, 1411, 1011, 1252], "temperature": 0.0, "avg_logprob": -0.2527138970114968, "compression_ratio": 1.8876404494382022, "no_speech_prob": 2.9944299058115575e-06}, {"id": 757, "seek": 365472, "start": 3654.72, "end": 3658.0, "text": " hundred and fifty samples nine point six two", "tokens": [3262, 293, 13442, 10938, 4949, 935, 2309, 732], "temperature": 0.0, "avg_logprob": -0.15990692209974627, "compression_ratio": 1.739463601532567, "no_speech_prob": 1.5779575051055872e-06}, {"id": 758, "seek": 365472, "start": 3659.7999999999997, "end": 3663.6, "text": " Hundred and fifty samples nine point six two. Okay, so you can see it like I'm", "tokens": [32869, 293, 13442, 10938, 4949, 935, 2309, 732, 13, 1033, 11, 370, 291, 393, 536, 309, 411, 286, 478], "temperature": 0.0, "avg_logprob": -0.15990692209974627, "compression_ratio": 1.739463601532567, "no_speech_prob": 1.5779575051055872e-06}, {"id": 759, "seek": 365472, "start": 3665.08, "end": 3671.2799999999997, "text": " Because I'm not nearly clever enough to write machine learning algorithms like not only can I not write them correctly the first time", "tokens": [1436, 286, 478, 406, 6217, 13494, 1547, 281, 2464, 3479, 2539, 14642, 411, 406, 787, 393, 286, 406, 2464, 552, 8944, 264, 700, 565], "temperature": 0.0, "avg_logprob": -0.15990692209974627, "compression_ratio": 1.739463601532567, "no_speech_prob": 1.5779575051055872e-06}, {"id": 760, "seek": 365472, "start": 3672.0, "end": 3675.2799999999997, "text": " Often like every single line I write will be wrong, right?", "tokens": [20043, 411, 633, 2167, 1622, 286, 2464, 486, 312, 2085, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15990692209974627, "compression_ratio": 1.739463601532567, "no_speech_prob": 1.5779575051055872e-06}, {"id": 761, "seek": 365472, "start": 3675.2799999999997, "end": 3679.2, "text": " So I always start from the assumption that the the line of code", "tokens": [407, 286, 1009, 722, 490, 264, 15302, 300, 264, 264, 1622, 295, 3089], "temperature": 0.0, "avg_logprob": -0.15990692209974627, "compression_ratio": 1.739463601532567, "no_speech_prob": 1.5779575051055872e-06}, {"id": 762, "seek": 365472, "start": 3679.2, "end": 3683.4399999999996, "text": " I just typed is almost certainly wrong and I just have to see why and how", "tokens": [286, 445, 33941, 307, 1920, 3297, 2085, 293, 286, 445, 362, 281, 536, 983, 293, 577], "temperature": 0.0, "avg_logprob": -0.15990692209974627, "compression_ratio": 1.739463601532567, "no_speech_prob": 1.5779575051055872e-06}, {"id": 763, "seek": 368344, "start": 3683.44, "end": 3688.96, "text": " Right and so like I just make sure and so eventually I get to the point where like much to my surprise", "tokens": [1779, 293, 370, 411, 286, 445, 652, 988, 293, 370, 4728, 286, 483, 281, 264, 935, 689, 411, 709, 281, 452, 6365], "temperature": 0.0, "avg_logprob": -0.16191415332612538, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.003012130240677e-06}, {"id": 764, "seek": 368344, "start": 3689.12, "end": 3691.2400000000002, "text": " It's not broken anymore, you know", "tokens": [467, 311, 406, 5463, 3602, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.16191415332612538, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.003012130240677e-06}, {"id": 765, "seek": 368344, "start": 3691.2400000000002, "end": 3695.4, "text": " So here I can feel like okay this it would be surprising if all of these things", "tokens": [407, 510, 286, 393, 841, 411, 1392, 341, 309, 576, 312, 8830, 498, 439, 295, 613, 721], "temperature": 0.0, "avg_logprob": -0.16191415332612538, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.003012130240677e-06}, {"id": 766, "seek": 368344, "start": 3695.6, "end": 3699.2000000000003, "text": " Accidentally happen to be exactly the same as scikit-learn. So this is looking pretty good", "tokens": [5725, 36578, 1051, 281, 312, 2293, 264, 912, 382, 2180, 22681, 12, 306, 1083, 13, 407, 341, 307, 1237, 1238, 665], "temperature": 0.0, "avg_logprob": -0.16191415332612538, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.003012130240677e-06}, {"id": 767, "seek": 368344, "start": 3703.52, "end": 3706.56, "text": " So now that we have something that can build a whole tree", "tokens": [407, 586, 300, 321, 362, 746, 300, 393, 1322, 257, 1379, 4230], "temperature": 0.0, "avg_logprob": -0.16191415332612538, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.003012130240677e-06}, {"id": 768, "seek": 368344, "start": 3707.28, "end": 3709.88, "text": " Where you want to have something that can calculate predictions?", "tokens": [2305, 291, 528, 281, 362, 746, 300, 393, 8873, 21264, 30], "temperature": 0.0, "avg_logprob": -0.16191415332612538, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.003012130240677e-06}, {"id": 769, "seek": 370988, "start": 3709.88, "end": 3716.1600000000003, "text": " Okay, and so to remind you we already have something that calculates predictions for a tree ensemble", "tokens": [1033, 11, 293, 370, 281, 4160, 291, 321, 1217, 362, 746, 300, 4322, 1024, 21264, 337, 257, 4230, 19492], "temperature": 0.0, "avg_logprob": -0.1656388057751602, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.5403987719037104e-06}, {"id": 770, "seek": 370988, "start": 3716.6400000000003, "end": 3718.6400000000003, "text": " by calling tree dot predict", "tokens": [538, 5141, 4230, 5893, 6069], "temperature": 0.0, "avg_logprob": -0.1656388057751602, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.5403987719037104e-06}, {"id": 771, "seek": 370988, "start": 3719.6400000000003, "end": 3723.88, "text": " But there is nothing called tree dot predict. So we're gonna have to write that", "tokens": [583, 456, 307, 1825, 1219, 4230, 5893, 6069, 13, 407, 321, 434, 799, 362, 281, 2464, 300], "temperature": 0.0, "avg_logprob": -0.1656388057751602, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.5403987719037104e-06}, {"id": 772, "seek": 370988, "start": 3726.96, "end": 3730.6800000000003, "text": " To make this more interesting, let's start bringing up the number of columns that we use", "tokens": [1407, 652, 341, 544, 1880, 11, 718, 311, 722, 5062, 493, 264, 1230, 295, 13766, 300, 321, 764], "temperature": 0.0, "avg_logprob": -0.1656388057751602, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.5403987719037104e-06}, {"id": 773, "seek": 373068, "start": 3730.68, "end": 3738.7999999999997, "text": " Let's create our tree ensemble again and this time let's go to a maximum depth of three", "tokens": [961, 311, 1884, 527, 4230, 19492, 797, 293, 341, 565, 718, 311, 352, 281, 257, 6674, 7161, 295, 1045], "temperature": 0.0, "avg_logprob": -0.18813069225990608, "compression_ratio": 1.7239263803680982, "no_speech_prob": 1.0845149063243298e-06}, {"id": 774, "seek": 373068, "start": 3741.16, "end": 3743.48, "text": " Okay, so now our tree is getting more interesting", "tokens": [1033, 11, 370, 586, 527, 4230, 307, 1242, 544, 1880], "temperature": 0.0, "avg_logprob": -0.18813069225990608, "compression_ratio": 1.7239263803680982, "no_speech_prob": 1.0845149063243298e-06}, {"id": 775, "seek": 373068, "start": 3747.2799999999997, "end": 3749.8399999999997, "text": " And let's now define how do we", "tokens": [400, 718, 311, 586, 6964, 577, 360, 321], "temperature": 0.0, "avg_logprob": -0.18813069225990608, "compression_ratio": 1.7239263803680982, "no_speech_prob": 1.0845149063243298e-06}, {"id": 776, "seek": 373068, "start": 3751.12, "end": 3753.64, "text": " create a set of predictions for a tree and", "tokens": [1884, 257, 992, 295, 21264, 337, 257, 4230, 293], "temperature": 0.0, "avg_logprob": -0.18813069225990608, "compression_ratio": 1.7239263803680982, "no_speech_prob": 1.0845149063243298e-06}, {"id": 777, "seek": 373068, "start": 3754.24, "end": 3758.54, "text": " So a set of predictions for a tree is simply the prediction for a row", "tokens": [407, 257, 992, 295, 21264, 337, 257, 4230, 307, 2935, 264, 17630, 337, 257, 5386], "temperature": 0.0, "avg_logprob": -0.18813069225990608, "compression_ratio": 1.7239263803680982, "no_speech_prob": 1.0845149063243298e-06}, {"id": 778, "seek": 375854, "start": 3758.54, "end": 3760.1, "text": " for", "tokens": [337], "temperature": 0.0, "avg_logprob": -0.20667403084891184, "compression_ratio": 1.6408839779005524, "no_speech_prob": 9.7215354344371e-07}, {"id": 779, "seek": 375854, "start": 3760.1, "end": 3762.1, "text": " every row", "tokens": [633, 5386], "temperature": 0.0, "avg_logprob": -0.20667403084891184, "compression_ratio": 1.6408839779005524, "no_speech_prob": 9.7215354344371e-07}, {"id": 780, "seek": 375854, "start": 3762.18, "end": 3766.46, "text": " That's it. All right, that's our predictions. So the predictions for a tree are", "tokens": [663, 311, 309, 13, 1057, 558, 11, 300, 311, 527, 21264, 13, 407, 264, 21264, 337, 257, 4230, 366], "temperature": 0.0, "avg_logprob": -0.20667403084891184, "compression_ratio": 1.6408839779005524, "no_speech_prob": 9.7215354344371e-07}, {"id": 781, "seek": 375854, "start": 3767.5, "end": 3769.5, "text": " every rows predictions", "tokens": [633, 13241, 21264], "temperature": 0.0, "avg_logprob": -0.20667403084891184, "compression_ratio": 1.6408839779005524, "no_speech_prob": 9.7215354344371e-07}, {"id": 782, "seek": 375854, "start": 3769.82, "end": 3772.42, "text": " in an array, okay, so again, we're like", "tokens": [294, 364, 10225, 11, 1392, 11, 370, 797, 11, 321, 434, 411], "temperature": 0.0, "avg_logprob": -0.20667403084891184, "compression_ratio": 1.6408839779005524, "no_speech_prob": 9.7215354344371e-07}, {"id": 783, "seek": 375854, "start": 3773.98, "end": 3778.9, "text": " Skipping thinking thinking is hard, you know, so let's just like keep pushing it back", "tokens": [7324, 6297, 1953, 1953, 307, 1152, 11, 291, 458, 11, 370, 718, 311, 445, 411, 1066, 7380, 309, 646], "temperature": 0.0, "avg_logprob": -0.20667403084891184, "compression_ratio": 1.6408839779005524, "no_speech_prob": 9.7215354344371e-07}, {"id": 784, "seek": 375854, "start": 3781.46, "end": 3785.7799999999997, "text": " This is kind of handy right notice that you can do for", "tokens": [639, 307, 733, 295, 13239, 558, 3449, 300, 291, 393, 360, 337], "temperature": 0.0, "avg_logprob": -0.20667403084891184, "compression_ratio": 1.6408839779005524, "no_speech_prob": 9.7215354344371e-07}, {"id": 785, "seek": 378578, "start": 3785.78, "end": 3787.78, "text": " For", "tokens": [1171], "temperature": 0.0, "avg_logprob": -0.26677400094491466, "compression_ratio": 1.7219251336898396, "no_speech_prob": 2.4824732918204973e-06}, {"id": 786, "seek": 378578, "start": 3788.1000000000004, "end": 3793.5400000000004, "text": " La in array with a numpy array regardless of the rank of the array", "tokens": [2369, 294, 10225, 365, 257, 1031, 8200, 10225, 10060, 295, 264, 6181, 295, 264, 10225], "temperature": 0.0, "avg_logprob": -0.26677400094491466, "compression_ratio": 1.7219251336898396, "no_speech_prob": 2.4824732918204973e-06}, {"id": 787, "seek": 378578, "start": 3794.7000000000003, "end": 3796.7000000000003, "text": " regardless of the number of axes in", "tokens": [10060, 295, 264, 1230, 295, 35387, 294], "temperature": 0.0, "avg_logprob": -0.26677400094491466, "compression_ratio": 1.7219251336898396, "no_speech_prob": 2.4824732918204973e-06}, {"id": 788, "seek": 378578, "start": 3797.6600000000003, "end": 3801.98, "text": " The array and what it does is it will loop through the leading axis", "tokens": [440, 10225, 293, 437, 309, 775, 307, 309, 486, 6367, 807, 264, 5775, 10298], "temperature": 0.0, "avg_logprob": -0.26677400094491466, "compression_ratio": 1.7219251336898396, "no_speech_prob": 2.4824732918204973e-06}, {"id": 789, "seek": 378578, "start": 3802.5, "end": 3804.02, "text": " right and these these", "tokens": [558, 293, 613, 613], "temperature": 0.0, "avg_logprob": -0.26677400094491466, "compression_ratio": 1.7219251336898396, "no_speech_prob": 2.4824732918204973e-06}, {"id": 790, "seek": 378578, "start": 3804.02, "end": 3809.46, "text": " Concepts are going to be very very important as we get into more and more neural networks because we're going to be all doing", "tokens": [47482, 82, 366, 516, 281, 312, 588, 588, 1021, 382, 321, 483, 666, 544, 293, 544, 18161, 9590, 570, 321, 434, 516, 281, 312, 439, 884], "temperature": 0.0, "avg_logprob": -0.26677400094491466, "compression_ratio": 1.7219251336898396, "no_speech_prob": 2.4824732918204973e-06}, {"id": 791, "seek": 380946, "start": 3809.46, "end": 3815.54, "text": " Tensor computations all the time. So the leading axis of a vector is the vector itself", "tokens": [34306, 2807, 763, 439, 264, 565, 13, 407, 264, 5775, 10298, 295, 257, 8062, 307, 264, 8062, 2564], "temperature": 0.0, "avg_logprob": -0.17546914021174112, "compression_ratio": 1.8082191780821917, "no_speech_prob": 3.844918865070213e-06}, {"id": 792, "seek": 380946, "start": 3815.9, "end": 3823.18, "text": " The leading axis of a matrix are the rows the leading axis axis of a three-dimensional tensor", "tokens": [440, 5775, 10298, 295, 257, 8141, 366, 264, 13241, 264, 5775, 10298, 10298, 295, 257, 1045, 12, 18759, 40863], "temperature": 0.0, "avg_logprob": -0.17546914021174112, "compression_ratio": 1.8082191780821917, "no_speech_prob": 3.844918865070213e-06}, {"id": 793, "seek": 380946, "start": 3823.7400000000002, "end": 3827.9, "text": " The matrices that represent the slices and so forth, right?", "tokens": [440, 32284, 300, 2906, 264, 19793, 293, 370, 5220, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17546914021174112, "compression_ratio": 1.8082191780821917, "no_speech_prob": 3.844918865070213e-06}, {"id": 794, "seek": 380946, "start": 3827.9, "end": 3833.3, "text": " So in this case because X is a matrix this is going to loop through the rows and if you write your", "tokens": [407, 294, 341, 1389, 570, 1783, 307, 257, 8141, 341, 307, 516, 281, 6367, 807, 264, 13241, 293, 498, 291, 2464, 428], "temperature": 0.0, "avg_logprob": -0.17546914021174112, "compression_ratio": 1.8082191780821917, "no_speech_prob": 3.844918865070213e-06}, {"id": 795, "seek": 383330, "start": 3833.3, "end": 3838.6600000000003, "text": " kind of tensor code this way then it'll kind of tend to", "tokens": [733, 295, 40863, 3089, 341, 636, 550, 309, 603, 733, 295, 3928, 281], "temperature": 0.0, "avg_logprob": -0.18984044628378785, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.8162181731895544e-06}, {"id": 796, "seek": 383330, "start": 3839.54, "end": 3844.6600000000003, "text": " Generalize nicely to higher dimensions like it doesn't really mention matter how many dimensions are in X", "tokens": [6996, 1125, 9594, 281, 2946, 12819, 411, 309, 1177, 380, 534, 2152, 1871, 577, 867, 12819, 366, 294, 1783], "temperature": 0.0, "avg_logprob": -0.18984044628378785, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.8162181731895544e-06}, {"id": 797, "seek": 383330, "start": 3844.6600000000003, "end": 3848.26, "text": " This is going to loop through each of the leading axis, right?", "tokens": [639, 307, 516, 281, 6367, 807, 1184, 295, 264, 5775, 10298, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18984044628378785, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.8162181731895544e-06}, {"id": 798, "seek": 383330, "start": 3850.26, "end": 3853.0600000000004, "text": " Okay, so we can now call that decision tree dot predict", "tokens": [1033, 11, 370, 321, 393, 586, 818, 300, 3537, 4230, 5893, 6069], "temperature": 0.0, "avg_logprob": -0.18984044628378785, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.8162181731895544e-06}, {"id": 799, "seek": 383330, "start": 3856.98, "end": 3860.82, "text": " Right so all I need to do is write predict row", "tokens": [1779, 370, 439, 286, 643, 281, 360, 307, 2464, 6069, 5386], "temperature": 0.0, "avg_logprob": -0.18984044628378785, "compression_ratio": 1.5721153846153846, "no_speech_prob": 1.8162181731895544e-06}, {"id": 800, "seek": 386082, "start": 3860.82, "end": 3866.6600000000003, "text": " Right and I've delayed thinking so much which is great that the actual point. We're actually have to do the work", "tokens": [1779, 293, 286, 600, 20268, 1953, 370, 709, 597, 307, 869, 300, 264, 3539, 935, 13, 492, 434, 767, 362, 281, 360, 264, 589], "temperature": 0.0, "avg_logprob": -0.17914471727736453, "compression_ratio": 1.600896860986547, "no_speech_prob": 5.093682375445496e-06}, {"id": 801, "seek": 386082, "start": 3866.6600000000003, "end": 3868.6600000000003, "text": " It's now basically trivial", "tokens": [467, 311, 586, 1936, 26703], "temperature": 0.0, "avg_logprob": -0.17914471727736453, "compression_ratio": 1.600896860986547, "no_speech_prob": 5.093682375445496e-06}, {"id": 802, "seek": 386082, "start": 3868.86, "end": 3871.36, "text": " So if we're at a leaf", "tokens": [407, 498, 321, 434, 412, 257, 10871], "temperature": 0.0, "avg_logprob": -0.17914471727736453, "compression_ratio": 1.600896860986547, "no_speech_prob": 5.093682375445496e-06}, {"id": 803, "seek": 386082, "start": 3871.9, "end": 3875.1800000000003, "text": " No, then the prediction is just equal to", "tokens": [883, 11, 550, 264, 17630, 307, 445, 2681, 281], "temperature": 0.0, "avg_logprob": -0.17914471727736453, "compression_ratio": 1.600896860986547, "no_speech_prob": 5.093682375445496e-06}, {"id": 804, "seek": 386082, "start": 3875.98, "end": 3877.82, "text": " Whatever that value was", "tokens": [8541, 300, 2158, 390], "temperature": 0.0, "avg_logprob": -0.17914471727736453, "compression_ratio": 1.600896860986547, "no_speech_prob": 5.093682375445496e-06}, {"id": 805, "seek": 386082, "start": 3877.82, "end": 3883.2200000000003, "text": " Which we calculated right back in the original tree constructor. It's just the average of the wise, right?", "tokens": [3013, 321, 15598, 558, 646, 294, 264, 3380, 4230, 47479, 13, 467, 311, 445, 264, 4274, 295, 264, 10829, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17914471727736453, "compression_ratio": 1.600896860986547, "no_speech_prob": 5.093682375445496e-06}, {"id": 806, "seek": 386082, "start": 3883.98, "end": 3885.98, "text": " If it's not a leaf node", "tokens": [759, 309, 311, 406, 257, 10871, 9984], "temperature": 0.0, "avg_logprob": -0.17914471727736453, "compression_ratio": 1.600896860986547, "no_speech_prob": 5.093682375445496e-06}, {"id": 807, "seek": 388598, "start": 3885.98, "end": 3891.94, "text": " Then we have to figure out whether to go down the left-hand path or the right-hand path to get the prediction right so", "tokens": [1396, 321, 362, 281, 2573, 484, 1968, 281, 352, 760, 264, 1411, 12, 5543, 3100, 420, 264, 558, 12, 5543, 3100, 281, 483, 264, 17630, 558, 370], "temperature": 0.0, "avg_logprob": -0.1604017369887408, "compression_ratio": 1.8925233644859814, "no_speech_prob": 1.679728711678763e-06}, {"id": 808, "seek": 388598, "start": 3893.7400000000002, "end": 3895.62, "text": " if", "tokens": [498], "temperature": 0.0, "avg_logprob": -0.1604017369887408, "compression_ratio": 1.8925233644859814, "no_speech_prob": 1.679728711678763e-06}, {"id": 809, "seek": 388598, "start": 3895.62, "end": 3901.9, "text": " This variable in this row is less than or equal to the thing we decide the amount we decided to split on", "tokens": [639, 7006, 294, 341, 5386, 307, 1570, 813, 420, 2681, 281, 264, 551, 321, 4536, 264, 2372, 321, 3047, 281, 7472, 322], "temperature": 0.0, "avg_logprob": -0.1604017369887408, "compression_ratio": 1.8925233644859814, "no_speech_prob": 1.679728711678763e-06}, {"id": 810, "seek": 388598, "start": 3902.54, "end": 3904.54, "text": " Then we go down the left path", "tokens": [1396, 321, 352, 760, 264, 1411, 3100], "temperature": 0.0, "avg_logprob": -0.1604017369887408, "compression_ratio": 1.8925233644859814, "no_speech_prob": 1.679728711678763e-06}, {"id": 811, "seek": 388598, "start": 3905.1, "end": 3907.1, "text": " Otherwise we go down the right path", "tokens": [10328, 321, 352, 760, 264, 558, 3100], "temperature": 0.0, "avg_logprob": -0.1604017369887408, "compression_ratio": 1.8925233644859814, "no_speech_prob": 1.679728711678763e-06}, {"id": 812, "seek": 388598, "start": 3907.38, "end": 3914.3, "text": " Okay, and then having figured out what path we want which tree we want then we can just call predict row on that", "tokens": [1033, 11, 293, 550, 1419, 8932, 484, 437, 3100, 321, 528, 597, 4230, 321, 528, 550, 321, 393, 445, 818, 6069, 5386, 322, 300], "temperature": 0.0, "avg_logprob": -0.1604017369887408, "compression_ratio": 1.8925233644859814, "no_speech_prob": 1.679728711678763e-06}, {"id": 813, "seek": 391430, "start": 3914.3, "end": 3916.3, "text": " right and again", "tokens": [558, 293, 797], "temperature": 0.0, "avg_logprob": -0.17964581080845424, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.1365621048753383e-06}, {"id": 814, "seek": 391430, "start": 3917.3, "end": 3919.3, "text": " We've accidentally created something recursive", "tokens": [492, 600, 15715, 2942, 746, 20560, 488], "temperature": 0.0, "avg_logprob": -0.17964581080845424, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.1365621048753383e-06}, {"id": 815, "seek": 391430, "start": 3920.3, "end": 3922.3, "text": " Again, I don't want to think about", "tokens": [3764, 11, 286, 500, 380, 528, 281, 519, 466], "temperature": 0.0, "avg_logprob": -0.17964581080845424, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.1365621048753383e-06}, {"id": 816, "seek": 391430, "start": 3923.02, "end": 3924.9, "text": " how that", "tokens": [577, 300], "temperature": 0.0, "avg_logprob": -0.17964581080845424, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.1365621048753383e-06}, {"id": 817, "seek": 391430, "start": 3924.9, "end": 3930.0600000000004, "text": " Works control flow wise or whatever, but I don't need to because like I just", "tokens": [27914, 1969, 3095, 10829, 420, 2035, 11, 457, 286, 500, 380, 643, 281, 570, 411, 286, 445], "temperature": 0.0, "avg_logprob": -0.17964581080845424, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.1365621048753383e-06}, {"id": 818, "seek": 391430, "start": 3930.5800000000004, "end": 3936.34, "text": " It just does like I just told it what I wanted so I trust it to work right if it's a leaf return the value", "tokens": [467, 445, 775, 411, 286, 445, 1907, 309, 437, 286, 1415, 370, 286, 3361, 309, 281, 589, 558, 498, 309, 311, 257, 10871, 2736, 264, 2158], "temperature": 0.0, "avg_logprob": -0.17964581080845424, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.1365621048753383e-06}, {"id": 819, "seek": 391430, "start": 3937.1000000000004, "end": 3940.86, "text": " Otherwise return the prediction for the left-hand side or the right-hand side as appropriate", "tokens": [10328, 2736, 264, 17630, 337, 264, 1411, 12, 5543, 1252, 420, 264, 558, 12, 5543, 1252, 382, 6854], "temperature": 0.0, "avg_logprob": -0.17964581080845424, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.1365621048753383e-06}, {"id": 820, "seek": 394086, "start": 3940.86, "end": 3942.86, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 821, "seek": 394086, "start": 3943.1, "end": 3944.82, "text": " Notice this here", "tokens": [13428, 341, 510], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 822, "seek": 394086, "start": 3944.82, "end": 3946.78, "text": " this if", "tokens": [341, 498], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 823, "seek": 394086, "start": 3946.78, "end": 3948.78, "text": " Has nothing to do with", "tokens": [8646, 1825, 281, 360, 365], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 824, "seek": 394086, "start": 3949.34, "end": 3951.34, "text": " this if", "tokens": [341, 498], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 825, "seek": 394086, "start": 3951.34, "end": 3954.3, "text": " All right, this if is a control flow statement", "tokens": [1057, 558, 11, 341, 498, 307, 257, 1969, 3095, 5629], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 826, "seek": 394086, "start": 3955.06, "end": 3959.88, "text": " That tells Python to go down that path or that path to do some calculation", "tokens": [663, 5112, 15329, 281, 352, 760, 300, 3100, 420, 300, 3100, 281, 360, 512, 17108], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 827, "seek": 394086, "start": 3961.1400000000003, "end": 3963.1400000000003, "text": " this if is an", "tokens": [341, 498, 307, 364], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 828, "seek": 394086, "start": 3964.1400000000003, "end": 3965.42, "text": " operator", "tokens": [12973], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 829, "seek": 394086, "start": 3965.42, "end": 3967.42, "text": " That returns a value", "tokens": [663, 11247, 257, 2158], "temperature": 0.0, "avg_logprob": -0.25118659199147986, "compression_ratio": 1.5586206896551724, "no_speech_prob": 1.0348516070735059e-06}, {"id": 830, "seek": 396742, "start": 3967.42, "end": 3975.02, "text": " So those of you that have done C or C++ will recognize it as being identical to that it's called the ternary operator", "tokens": [407, 729, 295, 291, 300, 362, 1096, 383, 420, 383, 25472, 486, 5521, 309, 382, 885, 14800, 281, 300, 309, 311, 1219, 264, 256, 1248, 822, 12973], "temperature": 0.0, "avg_logprob": -0.22375941276550293, "compression_ratio": 1.635, "no_speech_prob": 2.536017404963786e-07}, {"id": 831, "seek": 396742, "start": 3975.3, "end": 3980.1800000000003, "text": " All right, if you haven't that's fine. Basically what we're doing is we're going to get a value", "tokens": [1057, 558, 11, 498, 291, 2378, 380, 300, 311, 2489, 13, 8537, 437, 321, 434, 884, 307, 321, 434, 516, 281, 483, 257, 2158], "temperature": 0.0, "avg_logprob": -0.22375941276550293, "compression_ratio": 1.635, "no_speech_prob": 2.536017404963786e-07}, {"id": 832, "seek": 396742, "start": 3980.78, "end": 3985.26, "text": " Where we're going to say it's this value if this thing is true and", "tokens": [2305, 321, 434, 516, 281, 584, 309, 311, 341, 2158, 498, 341, 551, 307, 2074, 293], "temperature": 0.0, "avg_logprob": -0.22375941276550293, "compression_ratio": 1.635, "no_speech_prob": 2.536017404963786e-07}, {"id": 833, "seek": 396742, "start": 3986.66, "end": 3988.66, "text": " That value otherwise", "tokens": [663, 2158, 5911], "temperature": 0.0, "avg_logprob": -0.22375941276550293, "compression_ratio": 1.635, "no_speech_prob": 2.536017404963786e-07}, {"id": 834, "seek": 396742, "start": 3988.9, "end": 3992.02, "text": " And so you could write it", "tokens": [400, 370, 291, 727, 2464, 309], "temperature": 0.0, "avg_logprob": -0.22375941276550293, "compression_ratio": 1.635, "no_speech_prob": 2.536017404963786e-07}, {"id": 835, "seek": 399202, "start": 3992.02, "end": 3998.98, "text": " This way, right but that would require writing four lines of code to do one thing", "tokens": [639, 636, 11, 558, 457, 300, 576, 3651, 3579, 1451, 3876, 295, 3089, 281, 360, 472, 551], "temperature": 0.0, "avg_logprob": -0.183443512235369, "compression_ratio": 1.836734693877551, "no_speech_prob": 7.690366032875318e-07}, {"id": 836, "seek": 399202, "start": 3999.38, "end": 4005.14, "text": " It also require you to have code that if you read it to yourself or to somebody else is not at all", "tokens": [467, 611, 3651, 291, 281, 362, 3089, 300, 498, 291, 1401, 309, 281, 1803, 420, 281, 2618, 1646, 307, 406, 412, 439], "temperature": 0.0, "avg_logprob": -0.183443512235369, "compression_ratio": 1.836734693877551, "no_speech_prob": 7.690366032875318e-07}, {"id": 837, "seek": 399202, "start": 4005.22, "end": 4009.14, "text": " Naturally the way you would express it right I want to say the tree", "tokens": [34304, 264, 636, 291, 576, 5109, 309, 558, 286, 528, 281, 584, 264, 4230], "temperature": 0.0, "avg_logprob": -0.183443512235369, "compression_ratio": 1.836734693877551, "no_speech_prob": 7.690366032875318e-07}, {"id": 838, "seek": 399202, "start": 4009.14, "end": 4016.02, "text": " I got to go down is the left-hand side if the variables less than the split or the right-hand side otherwise", "tokens": [286, 658, 281, 352, 760, 307, 264, 1411, 12, 5543, 1252, 498, 264, 9102, 1570, 813, 264, 7472, 420, 264, 558, 12, 5543, 1252, 5911], "temperature": 0.0, "avg_logprob": -0.183443512235369, "compression_ratio": 1.836734693877551, "no_speech_prob": 7.690366032875318e-07}, {"id": 839, "seek": 401602, "start": 4016.02, "end": 4021.38, "text": " All right, so I want to write my code the way I would think about or the way I would say my code", "tokens": [1057, 558, 11, 370, 286, 528, 281, 2464, 452, 3089, 264, 636, 286, 576, 519, 466, 420, 264, 636, 286, 576, 584, 452, 3089], "temperature": 0.0, "avg_logprob": -0.21330401771946958, "compression_ratio": 1.6926829268292682, "no_speech_prob": 2.3090704814876517e-07}, {"id": 840, "seek": 401602, "start": 4021.74, "end": 4027.62, "text": " Okay, so this kind of a ternary operator can be quite helpful for that", "tokens": [1033, 11, 370, 341, 733, 295, 257, 256, 1248, 822, 12973, 393, 312, 1596, 4961, 337, 300], "temperature": 0.0, "avg_logprob": -0.21330401771946958, "compression_ratio": 1.6926829268292682, "no_speech_prob": 2.3090704814876517e-07}, {"id": 841, "seek": 401602, "start": 4028.54, "end": 4030.18, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.21330401771946958, "compression_ratio": 1.6926829268292682, "no_speech_prob": 2.3090704814876517e-07}, {"id": 842, "seek": 401602, "start": 4030.18, "end": 4033.5, "text": " So now that I've got a prediction for a row I can dump that into my class", "tokens": [407, 586, 300, 286, 600, 658, 257, 17630, 337, 257, 5386, 286, 393, 11430, 300, 666, 452, 1508], "temperature": 0.0, "avg_logprob": -0.21330401771946958, "compression_ratio": 1.6926829268292682, "no_speech_prob": 2.3090704814876517e-07}, {"id": 843, "seek": 401602, "start": 4034.5, "end": 4035.94, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.21330401771946958, "compression_ratio": 1.6926829268292682, "no_speech_prob": 2.3090704814876517e-07}, {"id": 844, "seek": 401602, "start": 4035.94, "end": 4037.94, "text": " Now I can create calculate predictions", "tokens": [823, 286, 393, 1884, 8873, 21264], "temperature": 0.0, "avg_logprob": -0.21330401771946958, "compression_ratio": 1.6926829268292682, "no_speech_prob": 2.3090704814876517e-07}, {"id": 845, "seek": 401602, "start": 4040.54, "end": 4044.2599999999998, "text": " And I can now plot my actuals against my predictions", "tokens": [400, 286, 393, 586, 7542, 452, 3539, 82, 1970, 452, 21264], "temperature": 0.0, "avg_logprob": -0.21330401771946958, "compression_ratio": 1.6926829268292682, "no_speech_prob": 2.3090704814876517e-07}, {"id": 846, "seek": 404426, "start": 4044.26, "end": 4046.1400000000003, "text": " when", "tokens": [562], "temperature": 0.0, "avg_logprob": -0.1528291614777451, "compression_ratio": 1.6639676113360324, "no_speech_prob": 1.9033808484891779e-06}, {"id": 847, "seek": 404426, "start": 4046.1400000000003, "end": 4048.1400000000003, "text": " You do a scatter plot", "tokens": [509, 360, 257, 34951, 7542], "temperature": 0.0, "avg_logprob": -0.1528291614777451, "compression_ratio": 1.6639676113360324, "no_speech_prob": 1.9033808484891779e-06}, {"id": 848, "seek": 404426, "start": 4048.42, "end": 4051.42, "text": " You'll often have a lot of dots sitting on top of each other", "tokens": [509, 603, 2049, 362, 257, 688, 295, 15026, 3798, 322, 1192, 295, 1184, 661], "temperature": 0.0, "avg_logprob": -0.1528291614777451, "compression_ratio": 1.6639676113360324, "no_speech_prob": 1.9033808484891779e-06}, {"id": 849, "seek": 404426, "start": 4051.82, "end": 4057.6200000000003, "text": " So a good trick is to use alpha alpha means how transparent the things not just in matplotlib", "tokens": [407, 257, 665, 4282, 307, 281, 764, 8961, 8961, 1355, 577, 12737, 264, 721, 406, 445, 294, 3803, 564, 310, 38270], "temperature": 0.0, "avg_logprob": -0.1528291614777451, "compression_ratio": 1.6639676113360324, "no_speech_prob": 1.9033808484891779e-06}, {"id": 850, "seek": 404426, "start": 4057.6200000000003, "end": 4062.1200000000003, "text": " But like in every graphics package in the world pretty much and so if you set alpha to less than one", "tokens": [583, 411, 294, 633, 11837, 7372, 294, 264, 1002, 1238, 709, 293, 370, 498, 291, 992, 8961, 281, 1570, 813, 472], "temperature": 0.0, "avg_logprob": -0.1528291614777451, "compression_ratio": 1.6639676113360324, "no_speech_prob": 1.9033808484891779e-06}, {"id": 851, "seek": 404426, "start": 4062.7400000000002, "end": 4067.4, "text": " Then this is saying you would need 20 dots on top of each other for it to be fully blue", "tokens": [1396, 341, 307, 1566, 291, 576, 643, 945, 15026, 322, 1192, 295, 1184, 661, 337, 309, 281, 312, 4498, 3344], "temperature": 0.0, "avg_logprob": -0.1528291614777451, "compression_ratio": 1.6639676113360324, "no_speech_prob": 1.9033808484891779e-06}, {"id": 852, "seek": 404426, "start": 4067.4, "end": 4069.92, "text": " And so this is a good way to kind of see", "tokens": [400, 370, 341, 307, 257, 665, 636, 281, 733, 295, 536], "temperature": 0.0, "avg_logprob": -0.1528291614777451, "compression_ratio": 1.6639676113360324, "no_speech_prob": 1.9033808484891779e-06}, {"id": 853, "seek": 406992, "start": 4069.92, "end": 4074.6800000000003, "text": " How much things are sitting on top of each other? So it's a good trick good trick for scatter plots", "tokens": [1012, 709, 721, 366, 3798, 322, 1192, 295, 1184, 661, 30, 407, 309, 311, 257, 665, 4282, 665, 4282, 337, 34951, 28609], "temperature": 0.0, "avg_logprob": -0.2960032478707736, "compression_ratio": 1.4662162162162162, "no_speech_prob": 5.955096185061848e-06}, {"id": 854, "seek": 406992, "start": 4077.2000000000003, "end": 4079.36, "text": " There's my r squared not bad", "tokens": [821, 311, 452, 367, 8889, 406, 1578], "temperature": 0.0, "avg_logprob": -0.2960032478707736, "compression_ratio": 1.4662162162162162, "no_speech_prob": 5.955096185061848e-06}, {"id": 855, "seek": 406992, "start": 4080.7200000000003, "end": 4086.52, "text": " And so let's now go ahead and do a random forest", "tokens": [400, 370, 718, 311, 586, 352, 2286, 293, 360, 257, 4974, 6719], "temperature": 0.0, "avg_logprob": -0.2960032478707736, "compression_ratio": 1.4662162162162162, "no_speech_prob": 5.955096185061848e-06}, {"id": 856, "seek": 406992, "start": 4088.84, "end": 4091.58, "text": " With no max amount of splitting", "tokens": [2022, 572, 11469, 2372, 295, 30348], "temperature": 0.0, "avg_logprob": -0.2960032478707736, "compression_ratio": 1.4662162162162162, "no_speech_prob": 5.955096185061848e-06}, {"id": 857, "seek": 406992, "start": 4093.2000000000003, "end": 4095.2000000000003, "text": " And our", "tokens": [400, 527], "temperature": 0.0, "avg_logprob": -0.2960032478707736, "compression_ratio": 1.4662162162162162, "no_speech_prob": 5.955096185061848e-06}, {"id": 858, "seek": 409520, "start": 4095.2, "end": 4100.08, "text": " Tree ensemble had no max amount of splitting we can compare our r squared", "tokens": [22291, 19492, 632, 572, 11469, 2372, 295, 30348, 321, 393, 6794, 527, 367, 8889], "temperature": 0.0, "avg_logprob": -0.2094449652246682, "compression_ratio": 1.5047619047619047, "no_speech_prob": 2.9022962735325564e-06}, {"id": 859, "seek": 409520, "start": 4101.04, "end": 4104.32, "text": " To their r squared and so they're not the same", "tokens": [1407, 641, 367, 8889, 293, 370, 436, 434, 406, 264, 912], "temperature": 0.0, "avg_logprob": -0.2094449652246682, "compression_ratio": 1.5047619047619047, "no_speech_prob": 2.9022962735325564e-06}, {"id": 860, "seek": 409520, "start": 4104.84, "end": 4110.96, "text": " But actually ours is a little better, so I don't know what we did differently, but we'll take it", "tokens": [583, 767, 11896, 307, 257, 707, 1101, 11, 370, 286, 500, 380, 458, 437, 321, 630, 7614, 11, 457, 321, 603, 747, 309], "temperature": 0.0, "avg_logprob": -0.2094449652246682, "compression_ratio": 1.5047619047619047, "no_speech_prob": 2.9022962735325564e-06}, {"id": 861, "seek": 409520, "start": 4111.5599999999995, "end": 4115.679999999999, "text": " Okay, so we have now something which for a", "tokens": [1033, 11, 370, 321, 362, 586, 746, 597, 337, 257], "temperature": 0.0, "avg_logprob": -0.2094449652246682, "compression_ratio": 1.5047619047619047, "no_speech_prob": 2.9022962735325564e-06}, {"id": 862, "seek": 409520, "start": 4116.32, "end": 4120.32, "text": " Forest with a single tree in is giving as good", "tokens": [18124, 365, 257, 2167, 4230, 294, 307, 2902, 382, 665], "temperature": 0.0, "avg_logprob": -0.2094449652246682, "compression_ratio": 1.5047619047619047, "no_speech_prob": 2.9022962735325564e-06}, {"id": 863, "seek": 409520, "start": 4121.16, "end": 4122.24, "text": " accuracy", "tokens": [14170], "temperature": 0.0, "avg_logprob": -0.2094449652246682, "compression_ratio": 1.5047619047619047, "no_speech_prob": 2.9022962735325564e-06}, {"id": 864, "seek": 412224, "start": 4122.24, "end": 4126.98, "text": " On a validation set using an actual real-world data set you know bullbooks for blue doses", "tokens": [1282, 257, 24071, 992, 1228, 364, 3539, 957, 12, 13217, 1412, 992, 291, 458, 4693, 15170, 337, 3344, 22576], "temperature": 0.0, "avg_logprob": -0.20089126214748476, "compression_ratio": 1.7944250871080138, "no_speech_prob": 2.1568109787040157e-06}, {"id": 865, "seek": 412224, "start": 4127.8, "end": 4129.8, "text": " compared to psychic learn", "tokens": [5347, 281, 35406, 1466], "temperature": 0.0, "avg_logprob": -0.20089126214748476, "compression_ratio": 1.7944250871080138, "no_speech_prob": 2.1568109787040157e-06}, {"id": 866, "seek": 412224, "start": 4130.5599999999995, "end": 4133.3, "text": " So let's go ahead and round this out", "tokens": [407, 718, 311, 352, 2286, 293, 3098, 341, 484], "temperature": 0.0, "avg_logprob": -0.20089126214748476, "compression_ratio": 1.7944250871080138, "no_speech_prob": 2.1568109787040157e-06}, {"id": 867, "seek": 412224, "start": 4133.92, "end": 4139.96, "text": " So what I would want to do now is to create a package that has this coding and I created it by like creating a method", "tokens": [407, 437, 286, 576, 528, 281, 360, 586, 307, 281, 1884, 257, 7372, 300, 575, 341, 17720, 293, 286, 2942, 309, 538, 411, 4084, 257, 3170], "temperature": 0.0, "avg_logprob": -0.20089126214748476, "compression_ratio": 1.7944250871080138, "no_speech_prob": 2.1568109787040157e-06}, {"id": 868, "seek": 412224, "start": 4139.96, "end": 4142.48, "text": " Here a method here a method here and patching them together", "tokens": [1692, 257, 3170, 510, 257, 3170, 510, 293, 9972, 278, 552, 1214], "temperature": 0.0, "avg_logprob": -0.20089126214748476, "compression_ratio": 1.7944250871080138, "no_speech_prob": 2.1568109787040157e-06}, {"id": 869, "seek": 412224, "start": 4142.76, "end": 4147.36, "text": " So what I did with now is I went back through my notebook and collected up all the cells", "tokens": [407, 437, 286, 630, 365, 586, 307, 286, 1437, 646, 807, 452, 21060, 293, 11087, 493, 439, 264, 5438], "temperature": 0.0, "avg_logprob": -0.20089126214748476, "compression_ratio": 1.7944250871080138, "no_speech_prob": 2.1568109787040157e-06}, {"id": 870, "seek": 414736, "start": 4147.36, "end": 4152.2, "text": " That implemented methods and pasted them all together right, and I've just pasted them down here", "tokens": [663, 12270, 7150, 293, 1791, 292, 552, 439, 1214, 558, 11, 293, 286, 600, 445, 1791, 292, 552, 760, 510], "temperature": 0.0, "avg_logprob": -0.14748528870669278, "compression_ratio": 1.748768472906404, "no_speech_prob": 1.7330490891254158e-06}, {"id": 871, "seek": 414736, "start": 4152.2, "end": 4157.679999999999, "text": " So here's this is my original tree ensemble and here is all the cells from the decision tree", "tokens": [407, 510, 311, 341, 307, 452, 3380, 4230, 19492, 293, 510, 307, 439, 264, 5438, 490, 264, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.14748528870669278, "compression_ratio": 1.748768472906404, "no_speech_prob": 1.7330490891254158e-06}, {"id": 872, "seek": 414736, "start": 4157.679999999999, "end": 4160.679999999999, "text": " I just dumped them all into one place without any change", "tokens": [286, 445, 32131, 552, 439, 666, 472, 1081, 1553, 604, 1319], "temperature": 0.0, "avg_logprob": -0.14748528870669278, "compression_ratio": 1.748768472906404, "no_speech_prob": 1.7330490891254158e-06}, {"id": 873, "seek": 414736, "start": 4163.48, "end": 4169.28, "text": " So that was it that was the code we wrote together, so now I can go ahead and I can create a", "tokens": [407, 300, 390, 309, 300, 390, 264, 3089, 321, 4114, 1214, 11, 370, 586, 286, 393, 352, 2286, 293, 286, 393, 1884, 257], "temperature": 0.0, "avg_logprob": -0.14748528870669278, "compression_ratio": 1.748768472906404, "no_speech_prob": 1.7330490891254158e-06}, {"id": 874, "seek": 414736, "start": 4172.0599999999995, "end": 4173.92, "text": " Tree ensemble I", "tokens": [22291, 19492, 286], "temperature": 0.0, "avg_logprob": -0.14748528870669278, "compression_ratio": 1.748768472906404, "no_speech_prob": 1.7330490891254158e-06}, {"id": 875, "seek": 417392, "start": 4173.92, "end": 4181.84, "text": " Can calculate my predictions I can do my scatter plot I can get my R squared right and this is now with", "tokens": [1664, 8873, 452, 21264, 286, 393, 360, 452, 34951, 7542, 286, 393, 483, 452, 497, 8889, 558, 293, 341, 307, 586, 365], "temperature": 0.0, "avg_logprob": -0.3084724426269531, "compression_ratio": 1.5027322404371584, "no_speech_prob": 2.9480083867383655e-06}, {"id": 876, "seek": 417392, "start": 4183.04, "end": 4185.04, "text": " five trees", "tokens": [1732, 5852], "temperature": 0.0, "avg_logprob": -0.3084724426269531, "compression_ratio": 1.5027322404371584, "no_speech_prob": 2.9480083867383655e-06}, {"id": 877, "seek": 417392, "start": 4185.04, "end": 4188.36, "text": " Right and here we are we have a model of", "tokens": [1779, 293, 510, 321, 366, 321, 362, 257, 2316, 295], "temperature": 0.0, "avg_logprob": -0.3084724426269531, "compression_ratio": 1.5027322404371584, "no_speech_prob": 2.9480083867383655e-06}, {"id": 878, "seek": 417392, "start": 4189.24, "end": 4194.08, "text": " Blue dook for bulldozers with a 71% R squared with a random forest we wrote", "tokens": [8510, 360, 453, 337, 4693, 2595, 41698, 365, 257, 30942, 4, 497, 8889, 365, 257, 4974, 6719, 321, 4114], "temperature": 0.0, "avg_logprob": -0.3084724426269531, "compression_ratio": 1.5027322404371584, "no_speech_prob": 2.9480083867383655e-06}, {"id": 879, "seek": 417392, "start": 4194.88, "end": 4196.88, "text": " entirely from scratch", "tokens": [7696, 490, 8459], "temperature": 0.0, "avg_logprob": -0.3084724426269531, "compression_ratio": 1.5027322404371584, "no_speech_prob": 2.9480083867383655e-06}, {"id": 880, "seek": 417392, "start": 4197.24, "end": 4199.24, "text": " So that's pretty cool", "tokens": [407, 300, 311, 1238, 1627], "temperature": 0.0, "avg_logprob": -0.3084724426269531, "compression_ratio": 1.5027322404371584, "no_speech_prob": 2.9480083867383655e-06}, {"id": 881, "seek": 419924, "start": 4199.24, "end": 4207.0, "text": " Any questions about that and I know there's like quite a lot to get through so during the week feel free to ask", "tokens": [2639, 1651, 466, 300, 293, 286, 458, 456, 311, 411, 1596, 257, 688, 281, 483, 807, 370, 1830, 264, 1243, 841, 1737, 281, 1029], "temperature": 0.0, "avg_logprob": -0.28401813507080076, "compression_ratio": 1.4777777777777779, "no_speech_prob": 4.1573302951292135e-06}, {"id": 882, "seek": 419924, "start": 4207.36, "end": 4208.96, "text": " on the forum", "tokens": [322, 264, 17542], "temperature": 0.0, "avg_logprob": -0.28401813507080076, "compression_ratio": 1.4777777777777779, "no_speech_prob": 4.1573302951292135e-06}, {"id": 883, "seek": 419924, "start": 4208.96, "end": 4214.28, "text": " About any bits of code you come across can somebody pass the box to Marsha? Oh there is", "tokens": [7769, 604, 9239, 295, 3089, 291, 808, 2108, 393, 2618, 1320, 264, 2424, 281, 9692, 1641, 30, 876, 456, 307], "temperature": 0.0, "avg_logprob": -0.28401813507080076, "compression_ratio": 1.4777777777777779, "no_speech_prob": 4.1573302951292135e-06}, {"id": 884, "seek": 419924, "start": 4218.84, "end": 4222.96, "text": " Can we get back to the probably to the top of maybe a", "tokens": [1664, 321, 483, 646, 281, 264, 1391, 281, 264, 1192, 295, 1310, 257], "temperature": 0.0, "avg_logprob": -0.28401813507080076, "compression_ratio": 1.4777777777777779, "no_speech_prob": 4.1573302951292135e-06}, {"id": 885, "seek": 422296, "start": 4222.96, "end": 4231.4, "text": " The decision tree when we set the score equal to infinity right yes, I do it calculate this car this score", "tokens": [440, 3537, 4230, 562, 321, 992, 264, 6175, 2681, 281, 13202, 558, 2086, 11, 286, 360, 309, 8873, 341, 1032, 341, 6175], "temperature": 0.0, "avg_logprob": -0.308743953704834, "compression_ratio": 1.6723163841807909, "no_speech_prob": 8.479168900521472e-05}, {"id": 886, "seek": 422296, "start": 4232.2, "end": 4237.08, "text": " For that I mean like I lost track of that and specifically I wonder", "tokens": [1171, 300, 286, 914, 411, 286, 2731, 2837, 295, 300, 293, 4682, 286, 2441], "temperature": 0.0, "avg_logprob": -0.308743953704834, "compression_ratio": 1.6723163841807909, "no_speech_prob": 8.479168900521472e-05}, {"id": 887, "seek": 422296, "start": 4238.76, "end": 4240.76, "text": " When we implement", "tokens": [1133, 321, 4445], "temperature": 0.0, "avg_logprob": -0.308743953704834, "compression_ratio": 1.6723163841807909, "no_speech_prob": 8.479168900521472e-05}, {"id": 888, "seek": 422296, "start": 4240.96, "end": 4242.64, "text": " when we implement", "tokens": [562, 321, 4445], "temperature": 0.0, "avg_logprob": -0.308743953704834, "compression_ratio": 1.6723163841807909, "no_speech_prob": 8.479168900521472e-05}, {"id": 889, "seek": 422296, "start": 4242.64, "end": 4249.24, "text": " Find our split we check for self score equal to whether it's equal to infinity or not", "tokens": [11809, 527, 7472, 321, 1520, 337, 2698, 6175, 2681, 281, 1968, 309, 311, 2681, 281, 13202, 420, 406], "temperature": 0.0, "avg_logprob": -0.308743953704834, "compression_ratio": 1.6723163841807909, "no_speech_prob": 8.479168900521472e-05}, {"id": 890, "seek": 424924, "start": 4249.24, "end": 4253.3, "text": " It seems to me it seems like unclear whether we", "tokens": [467, 2544, 281, 385, 309, 2544, 411, 25636, 1968, 321], "temperature": 0.0, "avg_logprob": -0.23375948737649357, "compression_ratio": 1.5812807881773399, "no_speech_prob": 1.2289139021959272e-06}, {"id": 891, "seek": 424924, "start": 4254.04, "end": 4256.04, "text": " fall out of this I", "tokens": [2100, 484, 295, 341, 286], "temperature": 0.0, "avg_logprob": -0.23375948737649357, "compression_ratio": 1.5812807881773399, "no_speech_prob": 1.2289139021959272e-06}, {"id": 892, "seek": 424924, "start": 4256.96, "end": 4259.16, "text": " Mean like if we ever implement", "tokens": [12302, 411, 498, 321, 1562, 4445], "temperature": 0.0, "avg_logprob": -0.23375948737649357, "compression_ratio": 1.5812807881773399, "no_speech_prob": 1.2289139021959272e-06}, {"id": 893, "seek": 424924, "start": 4260.2, "end": 4264.0, "text": " The methods if if our initial value is infinity", "tokens": [440, 7150, 498, 498, 527, 5883, 2158, 307, 13202], "temperature": 0.0, "avg_logprob": -0.23375948737649357, "compression_ratio": 1.5812807881773399, "no_speech_prob": 1.2289139021959272e-06}, {"id": 894, "seek": 424924, "start": 4265.28, "end": 4267.679999999999, "text": " So okay, let's talk through the logic so", "tokens": [407, 1392, 11, 718, 311, 751, 807, 264, 9952, 370], "temperature": 0.0, "avg_logprob": -0.23375948737649357, "compression_ratio": 1.5812807881773399, "no_speech_prob": 1.2289139021959272e-06}, {"id": 895, "seek": 424924, "start": 4268.5199999999995, "end": 4270.5199999999995, "text": " So the decision tree", "tokens": [407, 264, 3537, 4230], "temperature": 0.0, "avg_logprob": -0.23375948737649357, "compression_ratio": 1.5812807881773399, "no_speech_prob": 1.2289139021959272e-06}, {"id": 896, "seek": 424924, "start": 4270.639999999999, "end": 4277.0599999999995, "text": " Starts out with a score at infinity so in other words at this point when we've created the node there is no split", "tokens": [6481, 82, 484, 365, 257, 6175, 412, 13202, 370, 294, 661, 2283, 412, 341, 935, 562, 321, 600, 2942, 264, 9984, 456, 307, 572, 7472], "temperature": 0.0, "avg_logprob": -0.23375948737649357, "compression_ratio": 1.5812807881773399, "no_speech_prob": 1.2289139021959272e-06}, {"id": 897, "seek": 427706, "start": 4277.06, "end": 4279.4800000000005, "text": " So it's infinitely bad", "tokens": [407, 309, 311, 36227, 1578], "temperature": 0.0, "avg_logprob": -0.1916932316569539, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.276348578168836e-07}, {"id": 898, "seek": 427706, "start": 4280.14, "end": 4287.26, "text": " Okay, that's why the score is infinity and then we try to find a variable and a split", "tokens": [1033, 11, 300, 311, 983, 264, 6175, 307, 13202, 293, 550, 321, 853, 281, 915, 257, 7006, 293, 257, 7472], "temperature": 0.0, "avg_logprob": -0.1916932316569539, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.276348578168836e-07}, {"id": 899, "seek": 427706, "start": 4287.780000000001, "end": 4289.780000000001, "text": " that is better and", "tokens": [300, 307, 1101, 293], "temperature": 0.0, "avg_logprob": -0.1916932316569539, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.276348578168836e-07}, {"id": 900, "seek": 427706, "start": 4290.02, "end": 4293.46, "text": " to do that we loop through each column and", "tokens": [281, 360, 300, 321, 6367, 807, 1184, 7738, 293], "temperature": 0.0, "avg_logprob": -0.1916932316569539, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.276348578168836e-07}, {"id": 901, "seek": 427706, "start": 4294.38, "end": 4300.740000000001, "text": " Say hey column. Do you have a split which is better than the best one we have so far and", "tokens": [6463, 4177, 7738, 13, 1144, 291, 362, 257, 7472, 597, 307, 1101, 813, 264, 1151, 472, 321, 362, 370, 1400, 293], "temperature": 0.0, "avg_logprob": -0.1916932316569539, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.276348578168836e-07}, {"id": 902, "seek": 430074, "start": 4300.74, "end": 4306.099999999999, "text": " So then we implement that let's", "tokens": [407, 550, 321, 4445, 300, 718, 311], "temperature": 0.0, "avg_logprob": -0.21050005692702073, "compression_ratio": 1.7428571428571429, "no_speech_prob": 3.844920684059616e-06}, {"id": 903, "seek": 430074, "start": 4308.139999999999, "end": 4310.74, "text": " Do the slow way since it's a bit simpler", "tokens": [1144, 264, 2964, 636, 1670, 309, 311, 257, 857, 18587], "temperature": 0.0, "avg_logprob": -0.21050005692702073, "compression_ratio": 1.7428571428571429, "no_speech_prob": 3.844920684059616e-06}, {"id": 904, "seek": 430074, "start": 4311.46, "end": 4315.7, "text": " find better split we do that by looping through each row and", "tokens": [915, 1101, 7472, 321, 360, 300, 538, 6367, 278, 807, 1184, 5386, 293], "temperature": 0.0, "avg_logprob": -0.21050005692702073, "compression_ratio": 1.7428571428571429, "no_speech_prob": 3.844920684059616e-06}, {"id": 905, "seek": 430074, "start": 4316.66, "end": 4320.46, "text": " Finding out this is the current score if we split here", "tokens": [31947, 484, 341, 307, 264, 2190, 6175, 498, 321, 7472, 510], "temperature": 0.0, "avg_logprob": -0.21050005692702073, "compression_ratio": 1.7428571428571429, "no_speech_prob": 3.844920684059616e-06}, {"id": 906, "seek": 430074, "start": 4320.46, "end": 4327.38, "text": " Is it better than the current score the current score is infinitely bad so yes it is and so now we set the new score", "tokens": [1119, 309, 1101, 813, 264, 2190, 6175, 264, 2190, 6175, 307, 36227, 1578, 370, 2086, 309, 307, 293, 370, 586, 321, 992, 264, 777, 6175], "temperature": 0.0, "avg_logprob": -0.21050005692702073, "compression_ratio": 1.7428571428571429, "no_speech_prob": 3.844920684059616e-06}, {"id": 907, "seek": 432738, "start": 4327.38, "end": 4332.8, "text": " Equal to what we just calculated and we keep track of which variable we chose and the split we spit on", "tokens": [15624, 304, 281, 437, 321, 445, 15598, 293, 321, 1066, 2837, 295, 597, 7006, 321, 5111, 293, 264, 7472, 321, 22127, 322], "temperature": 0.0, "avg_logprob": -0.16412440342689627, "compression_ratio": 1.3954802259887005, "no_speech_prob": 5.507578407559777e-06}, {"id": 908, "seek": 432738, "start": 4333.5, "end": 4335.5, "text": " Okay, no worries", "tokens": [1033, 11, 572, 16340], "temperature": 0.0, "avg_logprob": -0.16412440342689627, "compression_ratio": 1.3954802259887005, "no_speech_prob": 5.507578407559777e-06}, {"id": 909, "seek": 432738, "start": 4341.5, "end": 4345.56, "text": " Okay, great, let's take a five-minute break, and I'll see you back here at 22", "tokens": [1033, 11, 869, 11, 718, 311, 747, 257, 1732, 12, 18256, 1821, 11, 293, 286, 603, 536, 291, 646, 510, 412, 5853], "temperature": 0.0, "avg_logprob": -0.16412440342689627, "compression_ratio": 1.3954802259887005, "no_speech_prob": 5.507578407559777e-06}, {"id": 910, "seek": 432738, "start": 4351.1, "end": 4354.1, "text": " So when I tried comparing the performance of this", "tokens": [407, 562, 286, 3031, 15763, 264, 3389, 295, 341], "temperature": 0.0, "avg_logprob": -0.16412440342689627, "compression_ratio": 1.3954802259887005, "no_speech_prob": 5.507578407559777e-06}, {"id": 911, "seek": 435410, "start": 4354.1, "end": 4356.1, "text": " Against scikit-learn", "tokens": [29995, 2180, 22681, 12, 306, 1083], "temperature": 0.0, "avg_logprob": -0.25703051151373446, "compression_ratio": 1.5416666666666667, "no_speech_prob": 2.0904535631416366e-06}, {"id": 912, "seek": 435410, "start": 4359.34, "end": 4361.34, "text": " This is quite a lot slower", "tokens": [639, 307, 1596, 257, 688, 14009], "temperature": 0.0, "avg_logprob": -0.25703051151373446, "compression_ratio": 1.5416666666666667, "no_speech_prob": 2.0904535631416366e-06}, {"id": 913, "seek": 435410, "start": 4361.900000000001, "end": 4363.900000000001, "text": " and the reason why is", "tokens": [293, 264, 1778, 983, 307], "temperature": 0.0, "avg_logprob": -0.25703051151373446, "compression_ratio": 1.5416666666666667, "no_speech_prob": 2.0904535631416366e-06}, {"id": 914, "seek": 435410, "start": 4364.38, "end": 4369.22, "text": " That although like a lot of the works being done by numpy", "tokens": [663, 4878, 411, 257, 688, 295, 264, 1985, 885, 1096, 538, 1031, 8200], "temperature": 0.0, "avg_logprob": -0.25703051151373446, "compression_ratio": 1.5416666666666667, "no_speech_prob": 2.0904535631416366e-06}, {"id": 915, "seek": 435410, "start": 4369.46, "end": 4377.660000000001, "text": " Which is nicely optimized C code think about like the very bottom level of a tree if we've got a", "tokens": [3013, 307, 9594, 26941, 383, 3089, 519, 466, 411, 264, 588, 2767, 1496, 295, 257, 4230, 498, 321, 600, 658, 257], "temperature": 0.0, "avg_logprob": -0.25703051151373446, "compression_ratio": 1.5416666666666667, "no_speech_prob": 2.0904535631416366e-06}, {"id": 916, "seek": 435410, "start": 4378.46, "end": 4383.18, "text": " million data points and the bottom level of the tree has something like", "tokens": [2459, 1412, 2793, 293, 264, 2767, 1496, 295, 264, 4230, 575, 746, 411], "temperature": 0.0, "avg_logprob": -0.25703051151373446, "compression_ratio": 1.5416666666666667, "no_speech_prob": 2.0904535631416366e-06}, {"id": 917, "seek": 438318, "start": 4383.18, "end": 4385.18, "text": " five hundred thousand", "tokens": [1732, 3262, 4714], "temperature": 0.0, "avg_logprob": -0.2029289293892776, "compression_ratio": 1.6555023923444976, "no_speech_prob": 8.31526222100365e-07}, {"id": 918, "seek": 438318, "start": 4386.02, "end": 4390.860000000001, "text": " decision points with a million leaves underneath right and so that's like", "tokens": [3537, 2793, 365, 257, 2459, 5510, 7223, 558, 293, 370, 300, 311, 411], "temperature": 0.0, "avg_logprob": -0.2029289293892776, "compression_ratio": 1.6555023923444976, "no_speech_prob": 8.31526222100365e-07}, {"id": 919, "seek": 438318, "start": 4392.18, "end": 4399.34, "text": " 500,000 split methods being called each one of contained which contains multiple calls to numpy which only have like", "tokens": [5923, 11, 1360, 7472, 7150, 885, 1219, 1184, 472, 295, 16212, 597, 8306, 3866, 5498, 281, 1031, 8200, 597, 787, 362, 411], "temperature": 0.0, "avg_logprob": -0.2029289293892776, "compression_ratio": 1.6555023923444976, "no_speech_prob": 8.31526222100365e-07}, {"id": 920, "seek": 438318, "start": 4399.9800000000005, "end": 4401.3, "text": " one", "tokens": [472], "temperature": 0.0, "avg_logprob": -0.2029289293892776, "compression_ratio": 1.6555023923444976, "no_speech_prob": 8.31526222100365e-07}, {"id": 921, "seek": 438318, "start": 4401.3, "end": 4408.4800000000005, "text": " Item that's actually being calculated on and so it's like that's like very inefficient, and it's the kind of thing that python is", "tokens": [31066, 300, 311, 767, 885, 15598, 322, 293, 370, 309, 311, 411, 300, 311, 411, 588, 43495, 11, 293, 309, 311, 264, 733, 295, 551, 300, 38797, 307], "temperature": 0.0, "avg_logprob": -0.2029289293892776, "compression_ratio": 1.6555023923444976, "no_speech_prob": 8.31526222100365e-07}, {"id": 922, "seek": 440848, "start": 4408.48, "end": 4414.36, "text": " Particularly not good at performance wise right like calling lots of functions lots of times", "tokens": [32281, 406, 665, 412, 3389, 10829, 558, 411, 5141, 3195, 295, 6828, 3195, 295, 1413], "temperature": 0.0, "avg_logprob": -0.1431245568357868, "compression_ratio": 1.6940639269406392, "no_speech_prob": 1.3709532140637748e-06}, {"id": 923, "seek": 440848, "start": 4414.36, "end": 4421.219999999999, "text": " I mean we can see it's it's not bad right you know for a kind of a random forest which", "tokens": [286, 914, 321, 393, 536, 309, 311, 309, 311, 406, 1578, 558, 291, 458, 337, 257, 733, 295, 257, 4974, 6719, 597], "temperature": 0.0, "avg_logprob": -0.1431245568357868, "compression_ratio": 1.6940639269406392, "no_speech_prob": 1.3709532140637748e-06}, {"id": 924, "seek": 440848, "start": 4422.12, "end": 4428.32, "text": " 15 years ago would have been considered pretty big this would be considered pretty good performance right but nowadays this is", "tokens": [2119, 924, 2057, 576, 362, 668, 4888, 1238, 955, 341, 576, 312, 4888, 1238, 665, 3389, 558, 457, 13434, 341, 307], "temperature": 0.0, "avg_logprob": -0.1431245568357868, "compression_ratio": 1.6940639269406392, "no_speech_prob": 1.3709532140637748e-06}, {"id": 925, "seek": 440848, "start": 4429.04, "end": 4433.099999999999, "text": " some hundreds of times at least slower than that it should be so", "tokens": [512, 6779, 295, 1413, 412, 1935, 14009, 813, 300, 309, 820, 312, 370], "temperature": 0.0, "avg_logprob": -0.1431245568357868, "compression_ratio": 1.6940639269406392, "no_speech_prob": 1.3709532140637748e-06}, {"id": 926, "seek": 443310, "start": 4433.1, "end": 4441.54, "text": " What the scikit-learn folks did to avoid this problem was that they wrote", "tokens": [708, 264, 2180, 22681, 12, 306, 1083, 4024, 630, 281, 5042, 341, 1154, 390, 300, 436, 4114], "temperature": 0.0, "avg_logprob": -0.32973337173461914, "compression_ratio": 1.464968152866242, "no_speech_prob": 4.520931611295964e-07}, {"id": 927, "seek": 443310, "start": 4442.34, "end": 4445.620000000001, "text": " their implementation in something called scython and", "tokens": [641, 11420, 294, 746, 1219, 795, 88, 11943, 293], "temperature": 0.0, "avg_logprob": -0.32973337173461914, "compression_ratio": 1.464968152866242, "no_speech_prob": 4.520931611295964e-07}, {"id": 928, "seek": 443310, "start": 4447.08, "end": 4453.22, "text": " Scython is a super set of python so any python you've written", "tokens": [2747, 88, 11943, 307, 257, 1687, 992, 295, 38797, 370, 604, 38797, 291, 600, 3720], "temperature": 0.0, "avg_logprob": -0.32973337173461914, "compression_ratio": 1.464968152866242, "no_speech_prob": 4.520931611295964e-07}, {"id": 929, "seek": 443310, "start": 4454.5, "end": 4456.5, "text": " pretty much", "tokens": [1238, 709], "temperature": 0.0, "avg_logprob": -0.32973337173461914, "compression_ratio": 1.464968152866242, "no_speech_prob": 4.520931611295964e-07}, {"id": 930, "seek": 443310, "start": 4456.5, "end": 4460.42, "text": " You can use as scython right?", "tokens": [509, 393, 764, 382, 795, 88, 11943, 558, 30], "temperature": 0.0, "avg_logprob": -0.32973337173461914, "compression_ratio": 1.464968152866242, "no_speech_prob": 4.520931611295964e-07}, {"id": 931, "seek": 446042, "start": 4460.42, "end": 4468.18, "text": " But then what happens is scython runs it in a very different way rather than passing it to the kind of the", "tokens": [583, 550, 437, 2314, 307, 795, 88, 11943, 6676, 309, 294, 257, 588, 819, 636, 2831, 813, 8437, 309, 281, 264, 733, 295, 264], "temperature": 0.0, "avg_logprob": -0.165963501058599, "compression_ratio": 1.673913043478261, "no_speech_prob": 6.375533985192305e-07}, {"id": 932, "seek": 446042, "start": 4468.9400000000005, "end": 4472.84, "text": " Python interpreter it instead converts it to C", "tokens": [15329, 34132, 309, 2602, 38874, 309, 281, 383], "temperature": 0.0, "avg_logprob": -0.165963501058599, "compression_ratio": 1.673913043478261, "no_speech_prob": 6.375533985192305e-07}, {"id": 933, "seek": 446042, "start": 4474.14, "end": 4477.1, "text": " Compiles that and then runs that C code", "tokens": [6620, 4680, 300, 293, 550, 6676, 300, 383, 3089], "temperature": 0.0, "avg_logprob": -0.165963501058599, "compression_ratio": 1.673913043478261, "no_speech_prob": 6.375533985192305e-07}, {"id": 934, "seek": 446042, "start": 4477.58, "end": 4482.74, "text": " Right which means the first time you run it it takes a little longer because it has to go through the", "tokens": [1779, 597, 1355, 264, 700, 565, 291, 1190, 309, 309, 2516, 257, 707, 2854, 570, 309, 575, 281, 352, 807, 264], "temperature": 0.0, "avg_logprob": -0.165963501058599, "compression_ratio": 1.673913043478261, "no_speech_prob": 6.375533985192305e-07}, {"id": 935, "seek": 446042, "start": 4483.14, "end": 4487.66, "text": " the kind of translation and compilation, but then after that it can be", "tokens": [264, 733, 295, 12853, 293, 40261, 11, 457, 550, 934, 300, 309, 393, 312], "temperature": 0.0, "avg_logprob": -0.165963501058599, "compression_ratio": 1.673913043478261, "no_speech_prob": 6.375533985192305e-07}, {"id": 936, "seek": 448766, "start": 4487.66, "end": 4490.0199999999995, "text": " quite a bit faster and", "tokens": [1596, 257, 857, 4663, 293], "temperature": 0.0, "avg_logprob": -0.2018961304599799, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.5056963320603245e-06}, {"id": 937, "seek": 448766, "start": 4490.78, "end": 4494.139999999999, "text": " so I wanted just to quickly show you what that looks like because", "tokens": [370, 286, 1415, 445, 281, 2661, 855, 291, 437, 300, 1542, 411, 570], "temperature": 0.0, "avg_logprob": -0.2018961304599799, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.5056963320603245e-06}, {"id": 938, "seek": 448766, "start": 4496.86, "end": 4501.42, "text": " You are absolutely going to be in a position where scython is going to help you with your work and", "tokens": [509, 366, 3122, 516, 281, 312, 294, 257, 2535, 689, 795, 88, 11943, 307, 516, 281, 854, 291, 365, 428, 589, 293], "temperature": 0.0, "avg_logprob": -0.2018961304599799, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.5056963320603245e-06}, {"id": 939, "seek": 448766, "start": 4502.18, "end": 4506.82, "text": " Most of the people you're working with will have never used it may not even know it exists", "tokens": [4534, 295, 264, 561, 291, 434, 1364, 365, 486, 362, 1128, 1143, 309, 815, 406, 754, 458, 309, 8198], "temperature": 0.0, "avg_logprob": -0.2018961304599799, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.5056963320603245e-06}, {"id": 940, "seek": 448766, "start": 4506.82, "end": 4508.82, "text": " And so this is like a great superpower to have", "tokens": [400, 370, 341, 307, 411, 257, 869, 45765, 281, 362], "temperature": 0.0, "avg_logprob": -0.2018961304599799, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.5056963320603245e-06}, {"id": 941, "seek": 448766, "start": 4509.44, "end": 4516.42, "text": " So to use scython in the notebook you say load ext load extension scython right and", "tokens": [407, 281, 764, 795, 88, 11943, 294, 264, 21060, 291, 584, 3677, 1279, 3677, 10320, 795, 88, 11943, 558, 293], "temperature": 0.0, "avg_logprob": -0.2018961304599799, "compression_ratio": 1.6626016260162602, "no_speech_prob": 1.5056963320603245e-06}, {"id": 942, "seek": 451642, "start": 4516.42, "end": 4518.74, "text": " So here's a python function", "tokens": [407, 510, 311, 257, 38797, 2445], "temperature": 0.0, "avg_logprob": -0.20414129354185978, "compression_ratio": 1.564625850340136, "no_speech_prob": 1.6280451973216259e-06}, {"id": 943, "seek": 451642, "start": 4519.9400000000005, "end": 4521.9400000000005, "text": " Fib one", "tokens": [479, 897, 472], "temperature": 0.0, "avg_logprob": -0.20414129354185978, "compression_ratio": 1.564625850340136, "no_speech_prob": 1.6280451973216259e-06}, {"id": 944, "seek": 451642, "start": 4524.46, "end": 4531.7, "text": " Here is the same as a scython function is exactly the same thing with percent percent scython at the top", "tokens": [1692, 307, 264, 912, 382, 257, 795, 88, 11943, 2445, 307, 2293, 264, 912, 551, 365, 3043, 3043, 795, 88, 11943, 412, 264, 1192], "temperature": 0.0, "avg_logprob": -0.20414129354185978, "compression_ratio": 1.564625850340136, "no_speech_prob": 1.6280451973216259e-06}, {"id": 945, "seek": 451642, "start": 4534.22, "end": 4541.16, "text": " This actually runs about twice as fast as this right just because it does the compilation", "tokens": [639, 767, 6676, 466, 6091, 382, 2370, 382, 341, 558, 445, 570, 309, 775, 264, 40261], "temperature": 0.0, "avg_logprob": -0.20414129354185978, "compression_ratio": 1.564625850340136, "no_speech_prob": 1.6280451973216259e-06}, {"id": 946, "seek": 454116, "start": 4541.16, "end": 4547.96, "text": " Here is the same version again where I've used a special scython", "tokens": [1692, 307, 264, 912, 3037, 797, 689, 286, 600, 1143, 257, 2121, 795, 88, 11943], "temperature": 0.0, "avg_logprob": -0.2439226802391342, "compression_ratio": 1.5527638190954773, "no_speech_prob": 4.737896972528688e-07}, {"id": 947, "seek": 454116, "start": 4548.92, "end": 4553.68, "text": " extension called C death which defines the C data type of", "tokens": [10320, 1219, 383, 2966, 597, 23122, 264, 383, 1412, 2010, 295], "temperature": 0.0, "avg_logprob": -0.2439226802391342, "compression_ratio": 1.5527638190954773, "no_speech_prob": 4.737896972528688e-07}, {"id": 948, "seek": 454116, "start": 4554.16, "end": 4557.2, "text": " the return value and of each variable", "tokens": [264, 2736, 2158, 293, 295, 1184, 7006], "temperature": 0.0, "avg_logprob": -0.2439226802391342, "compression_ratio": 1.5527638190954773, "no_speech_prob": 4.737896972528688e-07}, {"id": 949, "seek": 454116, "start": 4558.16, "end": 4560.16, "text": " right and so", "tokens": [558, 293, 370], "temperature": 0.0, "avg_logprob": -0.2439226802391342, "compression_ratio": 1.5527638190954773, "no_speech_prob": 4.737896972528688e-07}, {"id": 950, "seek": 454116, "start": 4560.2, "end": 4563.4, "text": " Basically, that's the trick that you can use to start making things", "tokens": [8537, 11, 300, 311, 264, 4282, 300, 291, 393, 764, 281, 722, 1455, 721], "temperature": 0.0, "avg_logprob": -0.2439226802391342, "compression_ratio": 1.5527638190954773, "no_speech_prob": 4.737896972528688e-07}, {"id": 951, "seek": 454116, "start": 4564.5599999999995, "end": 4568.5199999999995, "text": " Run quickly right and at that point now it knows it's not just some", "tokens": [8950, 2661, 558, 293, 412, 300, 935, 586, 309, 3255, 309, 311, 406, 445, 512], "temperature": 0.0, "avg_logprob": -0.2439226802391342, "compression_ratio": 1.5527638190954773, "no_speech_prob": 4.737896972528688e-07}, {"id": 952, "seek": 456852, "start": 4568.52, "end": 4574.900000000001, "text": " Python object called T. In fact, I probably should put one here as well", "tokens": [15329, 2657, 1219, 314, 13, 682, 1186, 11, 286, 1391, 820, 829, 472, 510, 382, 731], "temperature": 0.0, "avg_logprob": -0.17715228896543203, "compression_ratio": 1.5185185185185186, "no_speech_prob": 3.041583113372326e-06}, {"id": 953, "seek": 456852, "start": 4577.8, "end": 4581.0, "text": " Let's try that so we've got fib 2 we'll call that fib 3", "tokens": [961, 311, 853, 300, 370, 321, 600, 658, 13116, 568, 321, 603, 818, 300, 13116, 805], "temperature": 0.0, "avg_logprob": -0.17715228896543203, "compression_ratio": 1.5185185185185186, "no_speech_prob": 3.041583113372326e-06}, {"id": 954, "seek": 456852, "start": 4584.6, "end": 4586.6, "text": " So for fib 3", "tokens": [407, 337, 13116, 805], "temperature": 0.0, "avg_logprob": -0.17715228896543203, "compression_ratio": 1.5185185185185186, "no_speech_prob": 3.041583113372326e-06}, {"id": 955, "seek": 456852, "start": 4588.84, "end": 4590.84, "text": " Yeah, so it's exactly the same as before", "tokens": [865, 11, 370, 309, 311, 2293, 264, 912, 382, 949], "temperature": 0.0, "avg_logprob": -0.17715228896543203, "compression_ratio": 1.5185185185185186, "no_speech_prob": 3.041583113372326e-06}, {"id": 956, "seek": 456852, "start": 4590.84, "end": 4596.52, "text": " but we say what the data type of the thing we pass to it was is and then define the data types of each of", "tokens": [457, 321, 584, 437, 264, 1412, 2010, 295, 264, 551, 321, 1320, 281, 309, 390, 307, 293, 550, 6964, 264, 1412, 3467, 295, 1184, 295], "temperature": 0.0, "avg_logprob": -0.17715228896543203, "compression_ratio": 1.5185185185185186, "no_speech_prob": 3.041583113372326e-06}, {"id": 957, "seek": 459652, "start": 4596.52, "end": 4599.42, "text": " The variables and so then if we call that", "tokens": [440, 9102, 293, 370, 550, 498, 321, 818, 300], "temperature": 0.0, "avg_logprob": -0.17328027837416704, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.9022962735325564e-06}, {"id": 958, "seek": 459652, "start": 4605.76, "end": 4609.200000000001, "text": " Okay, we've now got something that's ten times faster, right so", "tokens": [1033, 11, 321, 600, 586, 658, 746, 300, 311, 2064, 1413, 4663, 11, 558, 370], "temperature": 0.0, "avg_logprob": -0.17328027837416704, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.9022962735325564e-06}, {"id": 959, "seek": 459652, "start": 4610.360000000001, "end": 4616.400000000001, "text": " Yeah, it doesn't really take that much extra and it's just it's just Python with a few little bits of markup", "tokens": [865, 11, 309, 1177, 380, 534, 747, 300, 709, 2857, 293, 309, 311, 445, 309, 311, 445, 15329, 365, 257, 1326, 707, 9239, 295, 1491, 1010], "temperature": 0.0, "avg_logprob": -0.17328027837416704, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.9022962735325564e-06}, {"id": 960, "seek": 459652, "start": 4616.620000000001, "end": 4620.320000000001, "text": " so that's like it's good to know that that exists because", "tokens": [370, 300, 311, 411, 309, 311, 665, 281, 458, 300, 300, 8198, 570], "temperature": 0.0, "avg_logprob": -0.17328027837416704, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.9022962735325564e-06}, {"id": 961, "seek": 459652, "start": 4621.320000000001, "end": 4623.4800000000005, "text": " If there's something custom you're trying to do", "tokens": [759, 456, 311, 746, 2375, 291, 434, 1382, 281, 360], "temperature": 0.0, "avg_logprob": -0.17328027837416704, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.9022962735325564e-06}, {"id": 962, "seek": 462348, "start": 4623.48, "end": 4627.679999999999, "text": " It's actually I find it kind of painful having to go out and you know", "tokens": [467, 311, 767, 286, 915, 309, 733, 295, 11697, 1419, 281, 352, 484, 293, 291, 458], "temperature": 0.0, "avg_logprob": -0.2422725753028794, "compression_ratio": 1.6051502145922747, "no_speech_prob": 2.994423539348645e-06}, {"id": 963, "seek": 462348, "start": 4627.679999999999, "end": 4631.48, "text": " Go into C and compile it and link it back and all that whereas doing it here is pretty easy", "tokens": [1037, 666, 383, 293, 31413, 309, 293, 2113, 309, 646, 293, 439, 300, 9735, 884, 309, 510, 307, 1238, 1858], "temperature": 0.0, "avg_logprob": -0.2422725753028794, "compression_ratio": 1.6051502145922747, "no_speech_prob": 2.994423539348645e-06}, {"id": 964, "seek": 462348, "start": 4631.48, "end": 4633.48, "text": " Can you pass that just to your right please? Masha?", "tokens": [1664, 291, 1320, 300, 445, 281, 428, 558, 1767, 30, 376, 12137, 30], "temperature": 0.0, "avg_logprob": -0.2422725753028794, "compression_ratio": 1.6051502145922747, "no_speech_prob": 2.994423539348645e-06}, {"id": 965, "seek": 462348, "start": 4636.48, "end": 4642.959999999999, "text": " So when you're doing like for the sit on version of it so in the case of an array for an empty array", "tokens": [407, 562, 291, 434, 884, 411, 337, 264, 1394, 322, 3037, 295, 309, 370, 294, 264, 1389, 295, 364, 10225, 337, 364, 6707, 10225], "temperature": 0.0, "avg_logprob": -0.2422725753028794, "compression_ratio": 1.6051502145922747, "no_speech_prob": 2.994423539348645e-06}, {"id": 966, "seek": 462348, "start": 4643.5599999999995, "end": 4648.5599999999995, "text": " This is a specific C type of yeah, so there's like a lot of", "tokens": [639, 307, 257, 2685, 383, 2010, 295, 1338, 11, 370, 456, 311, 411, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.2422725753028794, "compression_ratio": 1.6051502145922747, "no_speech_prob": 2.994423539348645e-06}, {"id": 967, "seek": 464856, "start": 4648.56, "end": 4654.04, "text": " specific stuff for integrating scython with numpy", "tokens": [2685, 1507, 337, 26889, 795, 88, 11943, 365, 1031, 8200], "temperature": 0.0, "avg_logprob": -0.17445239592134282, "compression_ratio": 1.6325581395348838, "no_speech_prob": 2.684180799406022e-06}, {"id": 968, "seek": 464856, "start": 4655.0, "end": 4658.72, "text": " And there's a whole page about it", "tokens": [400, 456, 311, 257, 1379, 3028, 466, 309], "temperature": 0.0, "avg_logprob": -0.17445239592134282, "compression_ratio": 1.6325581395348838, "no_speech_prob": 2.684180799406022e-06}, {"id": 969, "seek": 464856, "start": 4660.080000000001, "end": 4662.080000000001, "text": " Yeah, so we won't worry about going over it", "tokens": [865, 11, 370, 321, 1582, 380, 3292, 466, 516, 670, 309], "temperature": 0.0, "avg_logprob": -0.17445239592134282, "compression_ratio": 1.6325581395348838, "no_speech_prob": 2.684180799406022e-06}, {"id": 970, "seek": 464856, "start": 4662.080000000001, "end": 4669.280000000001, "text": " But you can read that and you can basically see the basic ideas. There's this C import which basically imports a", "tokens": [583, 291, 393, 1401, 300, 293, 291, 393, 1936, 536, 264, 3875, 3487, 13, 821, 311, 341, 383, 974, 597, 1936, 41596, 257], "temperature": 0.0, "avg_logprob": -0.17445239592134282, "compression_ratio": 1.6325581395348838, "no_speech_prob": 2.684180799406022e-06}, {"id": 971, "seek": 466928, "start": 4669.28, "end": 4677.88, "text": " Certain types of Python library into the kind of the C bit of the code and you can then use it in your scython", "tokens": [13407, 3467, 295, 15329, 6405, 666, 264, 733, 295, 264, 383, 857, 295, 264, 3089, 293, 291, 393, 550, 764, 309, 294, 428, 795, 88, 11943], "temperature": 0.0, "avg_logprob": -0.19344027080233134, "compression_ratio": 1.4099378881987579, "no_speech_prob": 3.5559637581172865e-06}, {"id": 972, "seek": 466928, "start": 4679.08, "end": 4681.08, "text": " Yeah, it's", "tokens": [865, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.19344027080233134, "compression_ratio": 1.4099378881987579, "no_speech_prob": 3.5559637581172865e-06}, {"id": 973, "seek": 466928, "start": 4681.36, "end": 4683.36, "text": " It's pretty straightforward", "tokens": [467, 311, 1238, 15325], "temperature": 0.0, "avg_logprob": -0.19344027080233134, "compression_ratio": 1.4099378881987579, "no_speech_prob": 3.5559637581172865e-06}, {"id": 974, "seek": 466928, "start": 4684.36, "end": 4690.92, "text": " Good question. Thank you. All right, so your your mission now is", "tokens": [2205, 1168, 13, 1044, 291, 13, 1057, 558, 11, 370, 428, 428, 4447, 586, 307], "temperature": 0.0, "avg_logprob": -0.19344027080233134, "compression_ratio": 1.4099378881987579, "no_speech_prob": 3.5559637581172865e-06}, {"id": 975, "seek": 466928, "start": 4694.12, "end": 4696.12, "text": " To implement", "tokens": [1407, 4445], "temperature": 0.0, "avg_logprob": -0.19344027080233134, "compression_ratio": 1.4099378881987579, "no_speech_prob": 3.5559637581172865e-06}, {"id": 976, "seek": 469612, "start": 4696.12, "end": 4704.16, "text": " Confidence based on tree variance feature importance partial dependence and tree interpreter", "tokens": [11701, 2778, 2361, 322, 4230, 21977, 4111, 7379, 14641, 31704, 293, 4230, 34132], "temperature": 0.0, "avg_logprob": -0.18694927381432574, "compression_ratio": 1.900473933649289, "no_speech_prob": 2.0261311419744743e-06}, {"id": 977, "seek": 469612, "start": 4705.08, "end": 4707.08, "text": " for that random first", "tokens": [337, 300, 4974, 700], "temperature": 0.0, "avg_logprob": -0.18694927381432574, "compression_ratio": 1.900473933649289, "no_speech_prob": 2.0261311419744743e-06}, {"id": 978, "seek": 469612, "start": 4708.0, "end": 4711.12, "text": " Removing redundant features doesn't use a random first at all", "tokens": [46445, 798, 40997, 4122, 1177, 380, 764, 257, 4974, 700, 412, 439], "temperature": 0.0, "avg_logprob": -0.18694927381432574, "compression_ratio": 1.900473933649289, "no_speech_prob": 2.0261311419744743e-06}, {"id": 979, "seek": 469612, "start": 4711.76, "end": 4713.76, "text": " So you don't have to worry about that", "tokens": [407, 291, 500, 380, 362, 281, 3292, 466, 300], "temperature": 0.0, "avg_logprob": -0.18694927381432574, "compression_ratio": 1.900473933649289, "no_speech_prob": 2.0261311419744743e-06}, {"id": 980, "seek": 469612, "start": 4713.92, "end": 4718.16, "text": " Extrapolation is not an interpretation technique. So you don't have to worry about that. So it's just the other ones", "tokens": [9881, 4007, 401, 399, 307, 406, 364, 14174, 6532, 13, 407, 291, 500, 380, 362, 281, 3292, 466, 300, 13, 407, 309, 311, 445, 264, 661, 2306], "temperature": 0.0, "avg_logprob": -0.18694927381432574, "compression_ratio": 1.900473933649289, "no_speech_prob": 2.0261311419744743e-06}, {"id": 981, "seek": 469612, "start": 4718.16, "end": 4721.94, "text": " So confidence based on tree variance. We've already written that code", "tokens": [407, 6687, 2361, 322, 4230, 21977, 13, 492, 600, 1217, 3720, 300, 3089], "temperature": 0.0, "avg_logprob": -0.18694927381432574, "compression_ratio": 1.900473933649289, "no_speech_prob": 2.0261311419744743e-06}, {"id": 982, "seek": 472194, "start": 4721.94, "end": 4727.0599999999995, "text": " So I suspect that the exact same code we have in the notebook should continue to work", "tokens": [407, 286, 9091, 300, 264, 1900, 912, 3089, 321, 362, 294, 264, 21060, 820, 2354, 281, 589], "temperature": 0.0, "avg_logprob": -0.20795587392953727, "compression_ratio": 1.703422053231939, "no_speech_prob": 4.860421995545039e-06}, {"id": 983, "seek": 472194, "start": 4727.139999999999, "end": 4729.139999999999, "text": " So you can try and make sure it get that working", "tokens": [407, 291, 393, 853, 293, 652, 988, 309, 483, 300, 1364], "temperature": 0.0, "avg_logprob": -0.20795587392953727, "compression_ratio": 1.703422053231939, "no_speech_prob": 4.860421995545039e-06}, {"id": 984, "seek": 472194, "start": 4730.259999999999, "end": 4735.58, "text": " Feature importance is with the variable shuffling technique and once you have that working", "tokens": [3697, 1503, 7379, 307, 365, 264, 7006, 402, 1245, 1688, 6532, 293, 1564, 291, 362, 300, 1364], "temperature": 0.0, "avg_logprob": -0.20795587392953727, "compression_ratio": 1.703422053231939, "no_speech_prob": 4.860421995545039e-06}, {"id": 985, "seek": 472194, "start": 4736.179999999999, "end": 4741.94, "text": " Partial dependence will just be a couple of lines of code away because rather than you know rather than shuffling", "tokens": [4100, 831, 31704, 486, 445, 312, 257, 1916, 295, 3876, 295, 3089, 1314, 570, 2831, 813, 291, 458, 2831, 813, 402, 1245, 1688], "temperature": 0.0, "avg_logprob": -0.20795587392953727, "compression_ratio": 1.703422053231939, "no_speech_prob": 4.860421995545039e-06}, {"id": 986, "seek": 472194, "start": 4742.46, "end": 4746.62, "text": " Column you're just replacing it with a constant value. That's nearly the same code and", "tokens": [4004, 16449, 291, 434, 445, 19139, 309, 365, 257, 5754, 2158, 13, 663, 311, 6217, 264, 912, 3089, 293], "temperature": 0.0, "avg_logprob": -0.20795587392953727, "compression_ratio": 1.703422053231939, "no_speech_prob": 4.860421995545039e-06}, {"id": 987, "seek": 472194, "start": 4747.66, "end": 4749.66, "text": " then tree interpreter", "tokens": [550, 4230, 34132], "temperature": 0.0, "avg_logprob": -0.20795587392953727, "compression_ratio": 1.703422053231939, "no_speech_prob": 4.860421995545039e-06}, {"id": 988, "seek": 474966, "start": 4749.66, "end": 4752.5, "text": " Is going to require you writing some code and thinking about that", "tokens": [1119, 516, 281, 3651, 291, 3579, 512, 3089, 293, 1953, 466, 300], "temperature": 0.0, "avg_logprob": -0.17888015207618174, "compression_ratio": 1.8130081300813008, "no_speech_prob": 4.425448878464522e-06}, {"id": 989, "seek": 474966, "start": 4752.7, "end": 4759.04, "text": " But once you've written tree interpreter, you're very close if you want to to creating the second approach to", "tokens": [583, 1564, 291, 600, 3720, 4230, 34132, 11, 291, 434, 588, 1998, 498, 291, 528, 281, 281, 4084, 264, 1150, 3109, 281], "temperature": 0.0, "avg_logprob": -0.17888015207618174, "compression_ratio": 1.8130081300813008, "no_speech_prob": 4.425448878464522e-06}, {"id": 990, "seek": 474966, "start": 4761.099999999999, "end": 4764.5, "text": " Feature importance the one where you add up the importance across", "tokens": [3697, 1503, 7379, 264, 472, 689, 291, 909, 493, 264, 7379, 2108], "temperature": 0.0, "avg_logprob": -0.17888015207618174, "compression_ratio": 1.8130081300813008, "no_speech_prob": 4.425448878464522e-06}, {"id": 991, "seek": 474966, "start": 4765.3, "end": 4766.98, "text": " all of the rows", "tokens": [439, 295, 264, 13241], "temperature": 0.0, "avg_logprob": -0.17888015207618174, "compression_ratio": 1.8130081300813008, "no_speech_prob": 4.425448878464522e-06}, {"id": 992, "seek": 474966, "start": 4766.98, "end": 4770.48, "text": " Which means you would then be very close to doing interaction importance", "tokens": [3013, 1355, 291, 576, 550, 312, 588, 1998, 281, 884, 9285, 7379], "temperature": 0.0, "avg_logprob": -0.17888015207618174, "compression_ratio": 1.8130081300813008, "no_speech_prob": 4.425448878464522e-06}, {"id": 993, "seek": 474966, "start": 4771.7, "end": 4778.38, "text": " So it turns out that there are actually there's actually a very good library for interaction importance for XGBoost", "tokens": [407, 309, 4523, 484, 300, 456, 366, 767, 456, 311, 767, 257, 588, 665, 6405, 337, 9285, 7379, 337, 1783, 8769, 78, 555], "temperature": 0.0, "avg_logprob": -0.17888015207618174, "compression_ratio": 1.8130081300813008, "no_speech_prob": 4.425448878464522e-06}, {"id": 994, "seek": 477838, "start": 4778.38, "end": 4781.900000000001, "text": " But there doesn't seem to be one for random forest", "tokens": [583, 456, 1177, 380, 1643, 281, 312, 472, 337, 4974, 6719], "temperature": 0.0, "avg_logprob": -0.17865717613090903, "compression_ratio": 1.8351254480286738, "no_speech_prob": 5.50756476513925e-06}, {"id": 995, "seek": 477838, "start": 4781.900000000001, "end": 4787.84, "text": " So you could like start by getting it working on our version and if you want to do interaction importance", "tokens": [407, 291, 727, 411, 722, 538, 1242, 309, 1364, 322, 527, 3037, 293, 498, 291, 528, 281, 360, 9285, 7379], "temperature": 0.0, "avg_logprob": -0.17865717613090903, "compression_ratio": 1.8351254480286738, "no_speech_prob": 5.50756476513925e-06}, {"id": 996, "seek": 477838, "start": 4787.84, "end": 4790.3, "text": " And then you could like get it working on the original", "tokens": [400, 550, 291, 727, 411, 483, 309, 1364, 322, 264, 3380], "temperature": 0.0, "avg_logprob": -0.17865717613090903, "compression_ratio": 1.8351254480286738, "no_speech_prob": 5.50756476513925e-06}, {"id": 997, "seek": 477838, "start": 4791.26, "end": 4794.22, "text": " SK learn version and that would be a cool", "tokens": [21483, 1466, 3037, 293, 300, 576, 312, 257, 1627], "temperature": 0.0, "avg_logprob": -0.17865717613090903, "compression_ratio": 1.8351254480286738, "no_speech_prob": 5.50756476513925e-06}, {"id": 998, "seek": 477838, "start": 4795.06, "end": 4801.4400000000005, "text": " Contribution like sometimes writing it against your own implementation is kind of nicer because you can see exactly what's going on", "tokens": [4839, 30783, 411, 2171, 3579, 309, 1970, 428, 1065, 11420, 307, 733, 295, 22842, 570, 291, 393, 536, 2293, 437, 311, 516, 322], "temperature": 0.0, "avg_logprob": -0.17865717613090903, "compression_ratio": 1.8351254480286738, "no_speech_prob": 5.50756476513925e-06}, {"id": 999, "seek": 477838, "start": 4801.900000000001, "end": 4803.900000000001, "text": " All right, so that's that's your job", "tokens": [1057, 558, 11, 370, 300, 311, 300, 311, 428, 1691], "temperature": 0.0, "avg_logprob": -0.17865717613090903, "compression_ratio": 1.8351254480286738, "no_speech_prob": 5.50756476513925e-06}, {"id": 1000, "seek": 480390, "start": 4803.9, "end": 4808.339999999999, "text": " You don't have to rewrite the random forest feel free to if you want to you know practice", "tokens": [509, 500, 380, 362, 281, 28132, 264, 4974, 6719, 841, 1737, 281, 498, 291, 528, 281, 291, 458, 3124], "temperature": 0.0, "avg_logprob": -0.20440461184527423, "compression_ratio": 1.509090909090909, "no_speech_prob": 1.136560172199097e-06}, {"id": 1001, "seek": 480390, "start": 4810.9, "end": 4812.9, "text": " So if you", "tokens": [407, 498, 291], "temperature": 0.0, "avg_logprob": -0.20440461184527423, "compression_ratio": 1.509090909090909, "no_speech_prob": 1.136560172199097e-06}, {"id": 1002, "seek": 480390, "start": 4813.42, "end": 4818.259999999999, "text": " Get stuck at any point you know ask on the forum right?", "tokens": [3240, 5541, 412, 604, 935, 291, 458, 1029, 322, 264, 17542, 558, 30], "temperature": 0.0, "avg_logprob": -0.20440461184527423, "compression_ratio": 1.509090909090909, "no_speech_prob": 1.136560172199097e-06}, {"id": 1003, "seek": 480390, "start": 4819.58, "end": 4821.58, "text": " there is a", "tokens": [456, 307, 257], "temperature": 0.0, "avg_logprob": -0.20440461184527423, "compression_ratio": 1.509090909090909, "no_speech_prob": 1.136560172199097e-06}, {"id": 1004, "seek": 480390, "start": 4822.5, "end": 4826.339999999999, "text": " Whole page here on wiki dot fast AI about how to ask for help", "tokens": [30336, 3028, 510, 322, 261, 9850, 5893, 2370, 7318, 466, 577, 281, 1029, 337, 854], "temperature": 0.0, "avg_logprob": -0.20440461184527423, "compression_ratio": 1.509090909090909, "no_speech_prob": 1.136560172199097e-06}, {"id": 1005, "seek": 480390, "start": 4827.139999999999, "end": 4829.139999999999, "text": " so when you", "tokens": [370, 562, 291], "temperature": 0.0, "avg_logprob": -0.20440461184527423, "compression_ratio": 1.509090909090909, "no_speech_prob": 1.136560172199097e-06}, {"id": 1006, "seek": 480390, "start": 4829.139999999999, "end": 4830.9, "text": " ask your", "tokens": [1029, 428], "temperature": 0.0, "avg_logprob": -0.20440461184527423, "compression_ratio": 1.509090909090909, "no_speech_prob": 1.136560172199097e-06}, {"id": 1007, "seek": 483090, "start": 4830.9, "end": 4838.42, "text": " Co-workers on slack for help when you ask people in a technical community on github or discourse for help or whatever", "tokens": [3066, 12, 37101, 322, 29767, 337, 854, 562, 291, 1029, 561, 294, 257, 6191, 1768, 322, 290, 355, 836, 420, 23938, 337, 854, 420, 2035], "temperature": 0.0, "avg_logprob": -0.1683825448501942, "compression_ratio": 1.651376146788991, "no_speech_prob": 3.9669371290074196e-06}, {"id": 1008, "seek": 483090, "start": 4839.86, "end": 4843.46, "text": " Asking for help the right way will go a long way towards", "tokens": [1018, 5092, 337, 854, 264, 558, 636, 486, 352, 257, 938, 636, 3030], "temperature": 0.0, "avg_logprob": -0.1683825448501942, "compression_ratio": 1.651376146788991, "no_speech_prob": 3.9669371290074196e-06}, {"id": 1009, "seek": 483090, "start": 4843.98, "end": 4848.42, "text": " You know having people want to help you and be able to help you right so", "tokens": [509, 458, 1419, 561, 528, 281, 854, 291, 293, 312, 1075, 281, 854, 291, 558, 370], "temperature": 0.0, "avg_logprob": -0.1683825448501942, "compression_ratio": 1.651376146788991, "no_speech_prob": 3.9669371290074196e-06}, {"id": 1010, "seek": 483090, "start": 4849.9, "end": 4855.179999999999, "text": " So like search for your answer like search for the error you're getting see if somebody's already asked about it", "tokens": [407, 411, 3164, 337, 428, 1867, 411, 3164, 337, 264, 6713, 291, 434, 1242, 536, 498, 2618, 311, 1217, 2351, 466, 309], "temperature": 0.0, "avg_logprob": -0.1683825448501942, "compression_ratio": 1.651376146788991, "no_speech_prob": 3.9669371290074196e-06}, {"id": 1011, "seek": 485518, "start": 4855.18, "end": 4857.18, "text": " You", "tokens": [509], "temperature": 0.0, "avg_logprob": -0.2088469337014591, "compression_ratio": 1.5960591133004927, "no_speech_prob": 2.521559508750215e-06}, {"id": 1012, "seek": 485518, "start": 4859.38, "end": 4863.5, "text": " Know how if you tried to fix it already, what do you think's going wrong?", "tokens": [10265, 577, 498, 291, 3031, 281, 3191, 309, 1217, 11, 437, 360, 291, 519, 311, 516, 2085, 30], "temperature": 0.0, "avg_logprob": -0.2088469337014591, "compression_ratio": 1.5960591133004927, "no_speech_prob": 2.521559508750215e-06}, {"id": 1013, "seek": 485518, "start": 4864.3, "end": 4868.22, "text": " What kind of computer are you on? How is it set up? What are the software versions?", "tokens": [708, 733, 295, 3820, 366, 291, 322, 30, 1012, 307, 309, 992, 493, 30, 708, 366, 264, 4722, 9606, 30], "temperature": 0.0, "avg_logprob": -0.2088469337014591, "compression_ratio": 1.5960591133004927, "no_speech_prob": 2.521559508750215e-06}, {"id": 1014, "seek": 485518, "start": 4869.26, "end": 4873.26, "text": " Exactly, what did you type and exactly what happened right now you could?", "tokens": [7587, 11, 437, 630, 291, 2010, 293, 2293, 437, 2011, 558, 586, 291, 727, 30], "temperature": 0.0, "avg_logprob": -0.2088469337014591, "compression_ratio": 1.5960591133004927, "no_speech_prob": 2.521559508750215e-06}, {"id": 1015, "seek": 485518, "start": 4874.58, "end": 4876.58, "text": " do that by", "tokens": [360, 300, 538], "temperature": 0.0, "avg_logprob": -0.2088469337014591, "compression_ratio": 1.5960591133004927, "no_speech_prob": 2.521559508750215e-06}, {"id": 1016, "seek": 485518, "start": 4878.3, "end": 4882.0, "text": " Taking a screenshot so you know make sure you've got some screenshot software", "tokens": [17837, 257, 27712, 370, 291, 458, 652, 988, 291, 600, 658, 512, 27712, 4722], "temperature": 0.0, "avg_logprob": -0.2088469337014591, "compression_ratio": 1.5960591133004927, "no_speech_prob": 2.521559508750215e-06}, {"id": 1017, "seek": 488200, "start": 4882.0, "end": 4885.02, "text": " That's really easy to use so if I were to take a screenshot. I just hit a button", "tokens": [663, 311, 534, 1858, 281, 764, 370, 498, 286, 645, 281, 747, 257, 27712, 13, 286, 445, 2045, 257, 2960], "temperature": 0.0, "avg_logprob": -0.19599789264155368, "compression_ratio": 1.6265560165975104, "no_speech_prob": 3.5559642128646374e-06}, {"id": 1018, "seek": 488200, "start": 4885.78, "end": 4890.74, "text": " Select the area copy to clipboard go to my forum", "tokens": [13638, 264, 1859, 5055, 281, 7353, 3787, 352, 281, 452, 17542], "temperature": 0.0, "avg_logprob": -0.19599789264155368, "compression_ratio": 1.6265560165975104, "no_speech_prob": 3.5559642128646374e-06}, {"id": 1019, "seek": 488200, "start": 4891.3, "end": 4897.38, "text": " Paste it in and there we go right that looks a little bit too big so let's make it a little smaller", "tokens": [43827, 309, 294, 293, 456, 321, 352, 558, 300, 1542, 257, 707, 857, 886, 955, 370, 718, 311, 652, 309, 257, 707, 4356], "temperature": 0.0, "avg_logprob": -0.19599789264155368, "compression_ratio": 1.6265560165975104, "no_speech_prob": 3.5559642128646374e-06}, {"id": 1020, "seek": 488200, "start": 4898.42, "end": 4901.9, "text": " Right and so now I've got a screenshot people can see exactly what happened", "tokens": [1779, 293, 370, 586, 286, 600, 658, 257, 27712, 561, 393, 536, 2293, 437, 2011], "temperature": 0.0, "avg_logprob": -0.19599789264155368, "compression_ratio": 1.6265560165975104, "no_speech_prob": 3.5559642128646374e-06}, {"id": 1021, "seek": 488200, "start": 4902.74, "end": 4904.3, "text": " better still", "tokens": [1101, 920], "temperature": 0.0, "avg_logprob": -0.19599789264155368, "compression_ratio": 1.6265560165975104, "no_speech_prob": 3.5559642128646374e-06}, {"id": 1022, "seek": 488200, "start": 4904.3, "end": 4909.02, "text": " if there's a few lines of code and error messages to look at and create a", "tokens": [498, 456, 311, 257, 1326, 3876, 295, 3089, 293, 6713, 7897, 281, 574, 412, 293, 1884, 257], "temperature": 0.0, "avg_logprob": -0.19599789264155368, "compression_ratio": 1.6265560165975104, "no_speech_prob": 3.5559642128646374e-06}, {"id": 1023, "seek": 490902, "start": 4909.02, "end": 4912.860000000001, "text": " a gist a gist is a handy little", "tokens": [257, 290, 468, 257, 290, 468, 307, 257, 13239, 707], "temperature": 0.0, "avg_logprob": -0.2892282244185327, "compression_ratio": 1.5324675324675325, "no_speech_prob": 2.260313067381503e-06}, {"id": 1024, "seek": 490902, "start": 4913.9400000000005, "end": 4918.780000000001, "text": " GitHub thing which basically lets you share code so if I wanted to", "tokens": [23331, 551, 597, 1936, 6653, 291, 2073, 3089, 370, 498, 286, 1415, 281], "temperature": 0.0, "avg_logprob": -0.2892282244185327, "compression_ratio": 1.5324675324675325, "no_speech_prob": 2.260313067381503e-06}, {"id": 1025, "seek": 490902, "start": 4919.540000000001, "end": 4921.540000000001, "text": " create a gist of this I", "tokens": [1884, 257, 290, 468, 295, 341, 286], "temperature": 0.0, "avg_logprob": -0.2892282244185327, "compression_ratio": 1.5324675324675325, "no_speech_prob": 2.260313067381503e-06}, {"id": 1026, "seek": 490902, "start": 4923.22, "end": 4925.22, "text": " Actually have a", "tokens": [5135, 362, 257], "temperature": 0.0, "avg_logprob": -0.2892282244185327, "compression_ratio": 1.5324675324675325, "no_speech_prob": 2.260313067381503e-06}, {"id": 1027, "seek": 490902, "start": 4925.780000000001, "end": 4927.22, "text": " extension", "tokens": [10320], "temperature": 0.0, "avg_logprob": -0.2892282244185327, "compression_ratio": 1.5324675324675325, "no_speech_prob": 2.260313067381503e-06}, {"id": 1028, "seek": 490902, "start": 4927.22, "end": 4929.740000000001, "text": " There we are that little extension so if I click on here", "tokens": [821, 321, 366, 300, 707, 10320, 370, 498, 286, 2052, 322, 510], "temperature": 0.0, "avg_logprob": -0.2892282244185327, "compression_ratio": 1.5324675324675325, "no_speech_prob": 2.260313067381503e-06}, {"id": 1029, "seek": 490902, "start": 4932.18, "end": 4934.18, "text": " Give it a name", "tokens": [5303, 309, 257, 1315], "temperature": 0.0, "avg_logprob": -0.2892282244185327, "compression_ratio": 1.5324675324675325, "no_speech_prob": 2.260313067381503e-06}, {"id": 1030, "seek": 490902, "start": 4934.34, "end": 4936.34, "text": " Say make public", "tokens": [6463, 652, 1908], "temperature": 0.0, "avg_logprob": -0.2892282244185327, "compression_ratio": 1.5324675324675325, "no_speech_prob": 2.260313067381503e-06}, {"id": 1031, "seek": 493634, "start": 4936.34, "end": 4942.62, "text": " All right, and that takes my Jupiter notebook shares it publicly I can then grab that URL", "tokens": [1057, 558, 11, 293, 300, 2516, 452, 24567, 21060, 12182, 309, 14843, 286, 393, 550, 4444, 300, 12905], "temperature": 0.0, "avg_logprob": -0.24869294464588165, "compression_ratio": 1.4404761904761905, "no_speech_prob": 7.338190926020616e-07}, {"id": 1032, "seek": 493634, "start": 4943.22, "end": 4945.22, "text": " copy link location", "tokens": [5055, 2113, 4914], "temperature": 0.0, "avg_logprob": -0.24869294464588165, "compression_ratio": 1.4404761904761905, "no_speech_prob": 7.338190926020616e-07}, {"id": 1033, "seek": 493634, "start": 4945.5, "end": 4948.1, "text": " Right and paste it into my forum post", "tokens": [1779, 293, 9163, 309, 666, 452, 17542, 2183], "temperature": 0.0, "avg_logprob": -0.24869294464588165, "compression_ratio": 1.4404761904761905, "no_speech_prob": 7.338190926020616e-07}, {"id": 1034, "seek": 493634, "start": 4949.02, "end": 4951.02, "text": " Right and then when people", "tokens": [1779, 293, 550, 562, 561], "temperature": 0.0, "avg_logprob": -0.24869294464588165, "compression_ratio": 1.4404761904761905, "no_speech_prob": 7.338190926020616e-07}, {"id": 1035, "seek": 493634, "start": 4951.1, "end": 4953.1, "text": " Click on it", "tokens": [8230, 322, 309], "temperature": 0.0, "avg_logprob": -0.24869294464588165, "compression_ratio": 1.4404761904761905, "no_speech_prob": 7.338190926020616e-07}, {"id": 1036, "seek": 493634, "start": 4954.62, "end": 4956.62, "text": " Then they'll immediately see", "tokens": [1396, 436, 603, 4258, 536], "temperature": 0.0, "avg_logprob": -0.24869294464588165, "compression_ratio": 1.4404761904761905, "no_speech_prob": 7.338190926020616e-07}, {"id": 1037, "seek": 493634, "start": 4958.22, "end": 4960.900000000001, "text": " My notebook when it renders", "tokens": [1222, 21060, 562, 309, 6125, 433], "temperature": 0.0, "avg_logprob": -0.24869294464588165, "compression_ratio": 1.4404761904761905, "no_speech_prob": 7.338190926020616e-07}, {"id": 1038, "seek": 496090, "start": 4960.9, "end": 4969.179999999999, "text": " Okay, so that's a really good way now that particular button is an extension", "tokens": [1033, 11, 370, 300, 311, 257, 534, 665, 636, 586, 300, 1729, 2960, 307, 364, 10320], "temperature": 0.0, "avg_logprob": -0.2258703253242407, "compression_ratio": 1.6926605504587156, "no_speech_prob": 1.4593686046282528e-06}, {"id": 1039, "seek": 496090, "start": 4969.259999999999, "end": 4974.259999999999, "text": " So on Jupiter you need to click envy extensions and click on", "tokens": [407, 322, 24567, 291, 643, 281, 2052, 30530, 25129, 293, 2052, 322], "temperature": 0.0, "avg_logprob": -0.2258703253242407, "compression_ratio": 1.6926605504587156, "no_speech_prob": 1.4593686046282528e-06}, {"id": 1040, "seek": 496090, "start": 4975.0599999999995, "end": 4979.46, "text": " Just it right while you're there. You should also click on collapsible headings", "tokens": [1449, 309, 558, 1339, 291, 434, 456, 13, 509, 820, 611, 2052, 322, 16567, 964, 1378, 1109], "temperature": 0.0, "avg_logprob": -0.2258703253242407, "compression_ratio": 1.6926605504587156, "no_speech_prob": 1.4593686046282528e-06}, {"id": 1041, "seek": 496090, "start": 4979.46, "end": 4983.42, "text": " That's this really handy thing. I use that lets me collapse things and open them up", "tokens": [663, 311, 341, 534, 13239, 551, 13, 286, 764, 300, 6653, 385, 15584, 721, 293, 1269, 552, 493], "temperature": 0.0, "avg_logprob": -0.2258703253242407, "compression_ratio": 1.6926605504587156, "no_speech_prob": 1.4593686046282528e-06}, {"id": 1042, "seek": 496090, "start": 4983.98, "end": 4988.799999999999, "text": " If you go to your Jupiter and don't see this envy extensions button", "tokens": [759, 291, 352, 281, 428, 24567, 293, 500, 380, 536, 341, 30530, 25129, 2960], "temperature": 0.0, "avg_logprob": -0.2258703253242407, "compression_ratio": 1.6926605504587156, "no_speech_prob": 1.4593686046282528e-06}, {"id": 1043, "seek": 498880, "start": 4988.8, "end": 4994.8, "text": " Then just Google for Jupiter and the extensions that will show you how to pip install it and and get it set up", "tokens": [1396, 445, 3329, 337, 24567, 293, 264, 25129, 300, 486, 855, 291, 577, 281, 8489, 3625, 309, 293, 293, 483, 309, 992, 493], "temperature": 0.0, "avg_logprob": -0.21421092389577842, "compression_ratio": 1.5539906103286385, "no_speech_prob": 1.9033785747524234e-06}, {"id": 1044, "seek": 498880, "start": 4994.8, "end": 4998.4800000000005, "text": " Right, but those two extensions are super duper handy", "tokens": [1779, 11, 457, 729, 732, 25129, 366, 1687, 1581, 610, 13239], "temperature": 0.0, "avg_logprob": -0.21421092389577842, "compression_ratio": 1.5539906103286385, "no_speech_prob": 1.9033785747524234e-06}, {"id": 1045, "seek": 498880, "start": 5000.8, "end": 5002.8, "text": " All right, so", "tokens": [1057, 558, 11, 370], "temperature": 0.0, "avg_logprob": -0.21421092389577842, "compression_ratio": 1.5539906103286385, "no_speech_prob": 1.9033785747524234e-06}, {"id": 1046, "seek": 498880, "start": 5004.0, "end": 5006.0, "text": " Other than that assignment", "tokens": [5358, 813, 300, 15187], "temperature": 0.0, "avg_logprob": -0.21421092389577842, "compression_ratio": 1.5539906103286385, "no_speech_prob": 1.9033785747524234e-06}, {"id": 1047, "seek": 498880, "start": 5006.64, "end": 5014.84, "text": " Where we're done with random forests and until the next course when you look at GBMs. We're done with decision tree ensembles", "tokens": [2305, 321, 434, 1096, 365, 4974, 21700, 293, 1826, 264, 958, 1164, 562, 291, 574, 412, 460, 18345, 82, 13, 492, 434, 1096, 365, 3537, 4230, 12567, 2504, 904], "temperature": 0.0, "avg_logprob": -0.21421092389577842, "compression_ratio": 1.5539906103286385, "no_speech_prob": 1.9033785747524234e-06}, {"id": 1048, "seek": 501484, "start": 5014.84, "end": 5016.84, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.21366965052593184, "compression_ratio": 1.6616915422885572, "no_speech_prob": 5.368737561184389e-07}, {"id": 1049, "seek": 501484, "start": 5017.88, "end": 5024.6, "text": " So we're going to move on to neural networks broadly defined and so", "tokens": [407, 321, 434, 516, 281, 1286, 322, 281, 18161, 9590, 19511, 7642, 293, 370], "temperature": 0.0, "avg_logprob": -0.21366965052593184, "compression_ratio": 1.6616915422885572, "no_speech_prob": 5.368737561184389e-07}, {"id": 1050, "seek": 501484, "start": 5026.84, "end": 5029.04, "text": " Neural networks are going to allow us to", "tokens": [1734, 1807, 9590, 366, 516, 281, 2089, 505, 281], "temperature": 0.0, "avg_logprob": -0.21366965052593184, "compression_ratio": 1.6616915422885572, "no_speech_prob": 5.368737561184389e-07}, {"id": 1051, "seek": 501484, "start": 5029.8, "end": 5035.42, "text": " To go beyond just you know the kind of nearest neighbors approach of random forests", "tokens": [1407, 352, 4399, 445, 291, 458, 264, 733, 295, 23831, 12512, 3109, 295, 4974, 21700], "temperature": 0.0, "avg_logprob": -0.21366965052593184, "compression_ratio": 1.6616915422885572, "no_speech_prob": 5.368737561184389e-07}, {"id": 1052, "seek": 501484, "start": 5035.42, "end": 5039.56, "text": " You know all the random forest can do is to average data that it's already seen", "tokens": [509, 458, 439, 264, 4974, 6719, 393, 360, 307, 281, 4274, 1412, 300, 309, 311, 1217, 1612], "temperature": 0.0, "avg_logprob": -0.21366965052593184, "compression_ratio": 1.6616915422885572, "no_speech_prob": 5.368737561184389e-07}, {"id": 1053, "seek": 503956, "start": 5039.56, "end": 5044.4400000000005, "text": " It can't extrapolate it can't it can't calculate right", "tokens": [467, 393, 380, 48224, 473, 309, 393, 380, 309, 393, 380, 8873, 558], "temperature": 0.0, "avg_logprob": -0.2334897369146347, "compression_ratio": 1.5222929936305734, "no_speech_prob": 1.1365616501279874e-06}, {"id": 1054, "seek": 503956, "start": 5045.6, "end": 5047.280000000001, "text": " linear regression", "tokens": [8213, 24590], "temperature": 0.0, "avg_logprob": -0.2334897369146347, "compression_ratio": 1.5222929936305734, "no_speech_prob": 1.1365616501279874e-06}, {"id": 1055, "seek": 503956, "start": 5047.280000000001, "end": 5052.280000000001, "text": " Can calculate and can extrapolate but only in very limited ways", "tokens": [1664, 8873, 293, 393, 48224, 473, 457, 787, 294, 588, 5567, 2098], "temperature": 0.0, "avg_logprob": -0.2334897369146347, "compression_ratio": 1.5222929936305734, "no_speech_prob": 1.1365616501279874e-06}, {"id": 1056, "seek": 503956, "start": 5053.320000000001, "end": 5057.0, "text": " Neural nets give us the best of both worlds", "tokens": [1734, 1807, 36170, 976, 505, 264, 1151, 295, 1293, 13401], "temperature": 0.0, "avg_logprob": -0.2334897369146347, "compression_ratio": 1.5222929936305734, "no_speech_prob": 1.1365616501279874e-06}, {"id": 1057, "seek": 503956, "start": 5059.240000000001, "end": 5061.72, "text": " We're going to start by applying them to", "tokens": [492, 434, 516, 281, 722, 538, 9275, 552, 281], "temperature": 0.0, "avg_logprob": -0.2334897369146347, "compression_ratio": 1.5222929936305734, "no_speech_prob": 1.1365616501279874e-06}, {"id": 1058, "seek": 503956, "start": 5063.320000000001, "end": 5064.68, "text": " Unstructured data", "tokens": [1156, 372, 46847, 1412], "temperature": 0.0, "avg_logprob": -0.2334897369146347, "compression_ratio": 1.5222929936305734, "no_speech_prob": 1.1365616501279874e-06}, {"id": 1059, "seek": 506468, "start": 5064.68, "end": 5072.68, "text": " Right so unstructured data means like pixels or the amplitudes of sound waves or words you know data where", "tokens": [1779, 370, 18799, 46847, 1412, 1355, 411, 18668, 420, 264, 9731, 16451, 295, 1626, 9417, 420, 2283, 291, 458, 1412, 689], "temperature": 0.0, "avg_logprob": -0.20211540826476446, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.2252693270274904e-06}, {"id": 1060, "seek": 506468, "start": 5073.400000000001, "end": 5074.8, "text": " everything in", "tokens": [1203, 294], "temperature": 0.0, "avg_logprob": -0.20211540826476446, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.2252693270274904e-06}, {"id": 1061, "seek": 506468, "start": 5074.8, "end": 5076.8, "text": " all the columns are", "tokens": [439, 264, 13766, 366], "temperature": 0.0, "avg_logprob": -0.20211540826476446, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.2252693270274904e-06}, {"id": 1062, "seek": 506468, "start": 5077.04, "end": 5078.6, "text": " All the same type", "tokens": [1057, 264, 912, 2010], "temperature": 0.0, "avg_logprob": -0.20211540826476446, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.2252693270274904e-06}, {"id": 1063, "seek": 506468, "start": 5078.6, "end": 5085.06, "text": " You know as opposed to like a database table where you've got like a revenue and a cost and a zip code and as state", "tokens": [509, 458, 382, 8851, 281, 411, 257, 8149, 3199, 689, 291, 600, 658, 411, 257, 9324, 293, 257, 2063, 293, 257, 20730, 3089, 293, 382, 1785], "temperature": 0.0, "avg_logprob": -0.20211540826476446, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.2252693270274904e-06}, {"id": 1064, "seek": 506468, "start": 5085.240000000001, "end": 5087.240000000001, "text": " It should be structured data", "tokens": [467, 820, 312, 18519, 1412], "temperature": 0.0, "avg_logprob": -0.20211540826476446, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.2252693270274904e-06}, {"id": 1065, "seek": 506468, "start": 5088.320000000001, "end": 5092.18, "text": " We're going to use it for structured data as well, but we're going to do that a little bit later", "tokens": [492, 434, 516, 281, 764, 309, 337, 18519, 1412, 382, 731, 11, 457, 321, 434, 516, 281, 360, 300, 257, 707, 857, 1780], "temperature": 0.0, "avg_logprob": -0.20211540826476446, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.2252693270274904e-06}, {"id": 1066, "seek": 509218, "start": 5092.18, "end": 5095.12, "text": " So unstructured data is a little easier", "tokens": [407, 18799, 46847, 1412, 307, 257, 707, 3571], "temperature": 0.0, "avg_logprob": -0.15162410968687476, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.9033740272789146e-06}, {"id": 1067, "seek": 509218, "start": 5095.12, "end": 5100.72, "text": " And it's also the area which more people have been applying deep learning to for longer", "tokens": [400, 309, 311, 611, 264, 1859, 597, 544, 561, 362, 668, 9275, 2452, 2539, 281, 337, 2854], "temperature": 0.0, "avg_logprob": -0.15162410968687476, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.9033740272789146e-06}, {"id": 1068, "seek": 509218, "start": 5106.4400000000005, "end": 5108.240000000001, "text": " The", "tokens": [440], "temperature": 0.0, "avg_logprob": -0.15162410968687476, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.9033740272789146e-06}, {"id": 1069, "seek": 509218, "start": 5108.240000000001, "end": 5111.12, "text": " If you're doing the deep learning course as well", "tokens": [759, 291, 434, 884, 264, 2452, 2539, 1164, 382, 731], "temperature": 0.0, "avg_logprob": -0.15162410968687476, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.9033740272789146e-06}, {"id": 1070, "seek": 509218, "start": 5111.56, "end": 5117.400000000001, "text": " You know you'll see that we're going to be approaching kind of the same conclusion from two different directions", "tokens": [509, 458, 291, 603, 536, 300, 321, 434, 516, 281, 312, 14908, 733, 295, 264, 912, 10063, 490, 732, 819, 11095], "temperature": 0.0, "avg_logprob": -0.15162410968687476, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.9033740272789146e-06}, {"id": 1071, "seek": 509218, "start": 5117.88, "end": 5119.88, "text": " so the deep learning course is", "tokens": [370, 264, 2452, 2539, 1164, 307], "temperature": 0.0, "avg_logprob": -0.15162410968687476, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.9033740272789146e-06}, {"id": 1072, "seek": 509218, "start": 5120.280000000001, "end": 5122.12, "text": " starting out with", "tokens": [2891, 484, 365], "temperature": 0.0, "avg_logprob": -0.15162410968687476, "compression_ratio": 1.6363636363636365, "no_speech_prob": 1.9033740272789146e-06}, {"id": 1073, "seek": 512212, "start": 5122.12, "end": 5123.88, "text": " big", "tokens": [955], "temperature": 0.0, "avg_logprob": -0.1598370746501441, "compression_ratio": 1.7022058823529411, "no_speech_prob": 1.6280421277770074e-06}, {"id": 1074, "seek": 512212, "start": 5123.88, "end": 5127.599999999999, "text": " complicated convolutional neural networks being solved with you know", "tokens": [6179, 45216, 304, 18161, 9590, 885, 13041, 365, 291, 458], "temperature": 0.0, "avg_logprob": -0.1598370746501441, "compression_ratio": 1.7022058823529411, "no_speech_prob": 1.6280421277770074e-06}, {"id": 1075, "seek": 512212, "start": 5128.12, "end": 5133.2, "text": " Sophisticated optimization schemes, and we're going to kind of gradually drill down into like exactly how they work", "tokens": [18921, 3142, 770, 19618, 26954, 11, 293, 321, 434, 516, 281, 733, 295, 13145, 11392, 760, 666, 411, 2293, 577, 436, 589], "temperature": 0.0, "avg_logprob": -0.1598370746501441, "compression_ratio": 1.7022058823529411, "no_speech_prob": 1.6280421277770074e-06}, {"id": 1076, "seek": 512212, "start": 5134.12, "end": 5139.28, "text": " Where else with the machine learning course we're going to be starting out more with like", "tokens": [2305, 1646, 365, 264, 3479, 2539, 1164, 321, 434, 516, 281, 312, 2891, 484, 544, 365, 411], "temperature": 0.0, "avg_logprob": -0.1598370746501441, "compression_ratio": 1.7022058823529411, "no_speech_prob": 1.6280421277770074e-06}, {"id": 1077, "seek": 512212, "start": 5140.0, "end": 5142.72, "text": " How does stochastic gradient descent actually work?", "tokens": [1012, 775, 342, 8997, 2750, 16235, 23475, 767, 589, 30], "temperature": 0.0, "avg_logprob": -0.1598370746501441, "compression_ratio": 1.7022058823529411, "no_speech_prob": 1.6280421277770074e-06}, {"id": 1078, "seek": 512212, "start": 5143.44, "end": 5150.2, "text": " What do we do? What can we do with like one single layer which would allow us to create things like logistic regression when we add?", "tokens": [708, 360, 321, 360, 30, 708, 393, 321, 360, 365, 411, 472, 2167, 4583, 597, 576, 2089, 505, 281, 1884, 721, 411, 3565, 3142, 24590, 562, 321, 909, 30], "temperature": 0.0, "avg_logprob": -0.1598370746501441, "compression_ratio": 1.7022058823529411, "no_speech_prob": 1.6280421277770074e-06}, {"id": 1079, "seek": 515020, "start": 5150.2, "end": 5154.0, "text": " regularization to that how does that give us things like", "tokens": [3890, 2144, 281, 300, 577, 775, 300, 976, 505, 721, 411], "temperature": 0.0, "avg_logprob": -0.19589535733486743, "compression_ratio": 1.7733333333333334, "no_speech_prob": 7.411196293105604e-06}, {"id": 1080, "seek": 515020, "start": 5154.84, "end": 5161.04, "text": " Ridge regression elastic net less oh and then as we add additional layers to that how does that let us?", "tokens": [32313, 24590, 17115, 2533, 1570, 1954, 293, 550, 382, 321, 909, 4497, 7914, 281, 300, 577, 775, 300, 718, 505, 30], "temperature": 0.0, "avg_logprob": -0.19589535733486743, "compression_ratio": 1.7733333333333334, "no_speech_prob": 7.411196293105604e-06}, {"id": 1081, "seek": 515020, "start": 5161.96, "end": 5166.84, "text": " Handle more complex problems, and so we're not going to we're only going to be looking at", "tokens": [8854, 306, 544, 3997, 2740, 11, 293, 370, 321, 434, 406, 516, 281, 321, 434, 787, 516, 281, 312, 1237, 412], "temperature": 0.0, "avg_logprob": -0.19589535733486743, "compression_ratio": 1.7733333333333334, "no_speech_prob": 7.411196293105604e-06}, {"id": 1082, "seek": 515020, "start": 5167.48, "end": 5169.88, "text": " fully connected layers in this", "tokens": [4498, 4582, 7914, 294, 341], "temperature": 0.0, "avg_logprob": -0.19589535733486743, "compression_ratio": 1.7733333333333334, "no_speech_prob": 7.411196293105604e-06}, {"id": 1083, "seek": 515020, "start": 5170.48, "end": 5172.48, "text": " machine learning course and", "tokens": [3479, 2539, 1164, 293], "temperature": 0.0, "avg_logprob": -0.19589535733486743, "compression_ratio": 1.7733333333333334, "no_speech_prob": 7.411196293105604e-06}, {"id": 1084, "seek": 515020, "start": 5172.92, "end": 5177.8, "text": " Then I think next semester with your net you're probably going to be looking at some more", "tokens": [1396, 286, 519, 958, 11894, 365, 428, 2533, 291, 434, 1391, 516, 281, 312, 1237, 412, 512, 544], "temperature": 0.0, "avg_logprob": -0.19589535733486743, "compression_ratio": 1.7733333333333334, "no_speech_prob": 7.411196293105604e-06}, {"id": 1085, "seek": 517780, "start": 5177.8, "end": 5179.28, "text": " more", "tokens": [544], "temperature": 0.0, "avg_logprob": -0.20814425295049493, "compression_ratio": 1.7465437788018434, "no_speech_prob": 1.459370537304494e-06}, {"id": 1086, "seek": 517780, "start": 5179.28, "end": 5185.16, "text": " Sophisticated approaches and so yeah so this machine learning we're going to be looking much more like what's actually happening with the matrices", "tokens": [18921, 3142, 770, 11587, 293, 370, 1338, 370, 341, 3479, 2539, 321, 434, 516, 281, 312, 1237, 709, 544, 411, 437, 311, 767, 2737, 365, 264, 32284], "temperature": 0.0, "avg_logprob": -0.20814425295049493, "compression_ratio": 1.7465437788018434, "no_speech_prob": 1.459370537304494e-06}, {"id": 1087, "seek": 517780, "start": 5185.16, "end": 5190.860000000001, "text": " And how they actually calculate it and the deep learning it's much more like what are the best practices for actually?", "tokens": [400, 577, 436, 767, 8873, 309, 293, 264, 2452, 2539, 309, 311, 709, 544, 411, 437, 366, 264, 1151, 7525, 337, 767, 30], "temperature": 0.0, "avg_logprob": -0.20814425295049493, "compression_ratio": 1.7465437788018434, "no_speech_prob": 1.459370537304494e-06}, {"id": 1088, "seek": 517780, "start": 5192.2, "end": 5198.2, "text": " Solving you know at a world-class level real-world deep learning problems, right so", "tokens": [7026, 798, 291, 458, 412, 257, 1002, 12, 11665, 1496, 957, 12, 13217, 2452, 2539, 2740, 11, 558, 370], "temperature": 0.0, "avg_logprob": -0.20814425295049493, "compression_ratio": 1.7465437788018434, "no_speech_prob": 1.459370537304494e-06}, {"id": 1089, "seek": 517780, "start": 5199.360000000001, "end": 5201.360000000001, "text": " next week we're going to", "tokens": [958, 1243, 321, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.20814425295049493, "compression_ratio": 1.7465437788018434, "no_speech_prob": 1.459370537304494e-06}, {"id": 1090, "seek": 520136, "start": 5201.36, "end": 5208.24, "text": " Be looking at like the classic MNIST problem, which is like how do we?", "tokens": [879, 1237, 412, 411, 264, 7230, 376, 45, 19756, 1154, 11, 597, 307, 411, 577, 360, 321, 30], "temperature": 0.0, "avg_logprob": -0.1825712203979492, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.0030095154434093e-06}, {"id": 1091, "seek": 520136, "start": 5209.36, "end": 5211.36, "text": " recognize digits now", "tokens": [5521, 27011, 586], "temperature": 0.0, "avg_logprob": -0.1825712203979492, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.0030095154434093e-06}, {"id": 1092, "seek": 520136, "start": 5212.28, "end": 5217.099999999999, "text": " If you're interested you can like skip ahead and like try and do this with a random forest", "tokens": [759, 291, 434, 3102, 291, 393, 411, 10023, 2286, 293, 411, 853, 293, 360, 341, 365, 257, 4974, 6719], "temperature": 0.0, "avg_logprob": -0.1825712203979492, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.0030095154434093e-06}, {"id": 1093, "seek": 520136, "start": 5217.099999999999, "end": 5223.04, "text": " And you'll find it's not bad like given that a random forest is basically a type of nearest neighbors, right?", "tokens": [400, 291, 603, 915, 309, 311, 406, 1578, 411, 2212, 300, 257, 4974, 6719, 307, 1936, 257, 2010, 295, 23831, 12512, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1825712203979492, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.0030095154434093e-06}, {"id": 1094, "seek": 520136, "start": 5223.04, "end": 5226.719999999999, "text": " It's finding like what are the nearest neighbors in in tree space?", "tokens": [467, 311, 5006, 411, 437, 366, 264, 23831, 12512, 294, 294, 4230, 1901, 30], "temperature": 0.0, "avg_logprob": -0.1825712203979492, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.0030095154434093e-06}, {"id": 1095, "seek": 522672, "start": 5226.72, "end": 5231.84, "text": " Then a random forest could absolutely recognize that this nine those pixels", "tokens": [1396, 257, 4974, 6719, 727, 3122, 5521, 300, 341, 4949, 729, 18668], "temperature": 0.0, "avg_logprob": -0.17387392434729151, "compression_ratio": 1.6428571428571428, "no_speech_prob": 1.228915607498493e-06}, {"id": 1096, "seek": 522672, "start": 5232.56, "end": 5234.6, "text": " You know are similar to pixels", "tokens": [509, 458, 366, 2531, 281, 18668], "temperature": 0.0, "avg_logprob": -0.17387392434729151, "compression_ratio": 1.6428571428571428, "no_speech_prob": 1.228915607498493e-06}, {"id": 1097, "seek": 522672, "start": 5234.6, "end": 5241.360000000001, "text": " We've seen in these other ones and on average they were nines as well right and so like we can absolutely solve", "tokens": [492, 600, 1612, 294, 613, 661, 2306, 293, 322, 4274, 436, 645, 297, 1652, 382, 731, 558, 293, 370, 411, 321, 393, 3122, 5039], "temperature": 0.0, "avg_logprob": -0.17387392434729151, "compression_ratio": 1.6428571428571428, "no_speech_prob": 1.228915607498493e-06}, {"id": 1098, "seek": 522672, "start": 5242.08, "end": 5244.08, "text": " These kinds of problems to an extent", "tokens": [1981, 3685, 295, 2740, 281, 364, 8396], "temperature": 0.0, "avg_logprob": -0.17387392434729151, "compression_ratio": 1.6428571428571428, "no_speech_prob": 1.228915607498493e-06}, {"id": 1099, "seek": 522672, "start": 5245.08, "end": 5246.88, "text": " using random forests", "tokens": [1228, 4974, 21700], "temperature": 0.0, "avg_logprob": -0.17387392434729151, "compression_ratio": 1.6428571428571428, "no_speech_prob": 1.228915607498493e-06}, {"id": 1100, "seek": 522672, "start": 5246.88, "end": 5252.64, "text": " But we end up being rather data limited because every time we put in another decision point", "tokens": [583, 321, 917, 493, 885, 2831, 1412, 5567, 570, 633, 565, 321, 829, 294, 1071, 3537, 935], "temperature": 0.0, "avg_logprob": -0.17387392434729151, "compression_ratio": 1.6428571428571428, "no_speech_prob": 1.228915607498493e-06}, {"id": 1101, "seek": 525264, "start": 5252.64, "end": 5260.14, "text": " You know we're having our data roughly and so there's this just this limitation and the amount of calculation that we can do", "tokens": [509, 458, 321, 434, 1419, 527, 1412, 9810, 293, 370, 456, 311, 341, 445, 341, 27432, 293, 264, 2372, 295, 17108, 300, 321, 393, 360], "temperature": 0.0, "avg_logprob": -0.19747161865234375, "compression_ratio": 1.871900826446281, "no_speech_prob": 1.933351086336188e-06}, {"id": 1102, "seek": 525264, "start": 5261.04, "end": 5263.04, "text": " Where else with neural nets?", "tokens": [2305, 1646, 365, 18161, 36170, 30], "temperature": 0.0, "avg_logprob": -0.19747161865234375, "compression_ratio": 1.871900826446281, "no_speech_prob": 1.933351086336188e-06}, {"id": 1103, "seek": 525264, "start": 5263.6, "end": 5267.820000000001, "text": " We're going to be able to use lots and lots and lots of parameters", "tokens": [492, 434, 516, 281, 312, 1075, 281, 764, 3195, 293, 3195, 293, 3195, 295, 9834], "temperature": 0.0, "avg_logprob": -0.19747161865234375, "compression_ratio": 1.871900826446281, "no_speech_prob": 1.933351086336188e-06}, {"id": 1104, "seek": 525264, "start": 5268.6, "end": 5271.76, "text": " Using these tricks we're going to learn about with regularization", "tokens": [11142, 613, 11733, 321, 434, 516, 281, 1466, 466, 365, 3890, 2144], "temperature": 0.0, "avg_logprob": -0.19747161865234375, "compression_ratio": 1.871900826446281, "no_speech_prob": 1.933351086336188e-06}, {"id": 1105, "seek": 525264, "start": 5271.76, "end": 5276.88, "text": " And so we're going to be able to do lots of computation, and there's going to be very little limitation on really", "tokens": [400, 370, 321, 434, 516, 281, 312, 1075, 281, 360, 3195, 295, 24903, 11, 293, 456, 311, 516, 281, 312, 588, 707, 27432, 322, 534], "temperature": 0.0, "avg_logprob": -0.19747161865234375, "compression_ratio": 1.871900826446281, "no_speech_prob": 1.933351086336188e-06}, {"id": 1106, "seek": 525264, "start": 5277.96, "end": 5280.68, "text": " What we can actually end up calculating as a result?", "tokens": [708, 321, 393, 767, 917, 493, 28258, 382, 257, 1874, 30], "temperature": 0.0, "avg_logprob": -0.19747161865234375, "compression_ratio": 1.871900826446281, "no_speech_prob": 1.933351086336188e-06}, {"id": 1107, "seek": 528068, "start": 5280.68, "end": 5285.72, "text": " Great good luck with your random forest interpretation, and I will see you next time", "tokens": [50364, 3769, 665, 3668, 365, 428, 4974, 6719, 14174, 11, 293, 286, 486, 536, 291, 958, 565, 50616], "temperature": 0.0, "avg_logprob": -0.18007730182848478, "compression_ratio": 1.0632911392405062, "no_speech_prob": 2.1110121451783925e-05}], "language": "en"}