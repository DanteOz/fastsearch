{"text": " Okay, and so now to change tax, we'll go back to language translation. And so we'll start on that today and then tomorrow we'll have, or not tomorrow, sorry, Tuesday we'll have plenty of time to continue with attention and the transformer and this topic of improving language translation. And so I think with this I want to start with some slides. Let me open. And actually, so I wanted to start with, there's a great blog post. So we're going to start with just talking about attention again. And attention is a key idea of the transformer network for translation. We saw attention previously in Lesson 7, I guess Notebook 7B, Seek to Seek with Attention. And so first we're just going to revisit attention with RNNs, although then we'll move on to Transformer which is not an RNN. So Chris Ola, who's kind of one of the founders of Distill, are you guys familiar with Distill.pub from Google? Okay, they, it's kind of like this online journal that, so Chris Ola is great at doing these like really beautiful visualizations. And so he was kind of used to do this on his blog and then kind of created Distill as this way to kind of have even more an outlet for people to write work that involves kind of beautiful interactive visualizations of deep learning concepts. Let me click on this post. And here he's talking about a few different features of RNNs. I'm just going to go to the one on attentional interfaces. And so kind of the idea is, so here you're translating from English to French and you've got, you know, you're going from one sentence to another. Depending on what word you're on, you want to focus on different parts of the original sentence. So here you can scroll over and see for signed, this is, so we're going kind of from English to French. These are kind of the places it needs to go. Actually, I guess I should start on the French side showing what needs to be pulled in as you're translating. And it's, you know, it's not in a one-to-one order because different languages have different syntax of what order things go in. Where like for a zone, it needs to know about the economic area. Law, knowing kind of the gender of the pronoun is coming from, you know, not just the, but also what's going to be modified, sorry, gender of the noun. And so this is, I think, a nice way of kind of seeing what needs to be, kind of where does information need to go from and to. And the idea of attention is knowing kind of the network wants to, or creating networks that can learn what to focus on at a particular time. So this is a nice visualization. This is also a great one for going from audio to words. So here having input audio, which you can see with these just kind of white and black smudges. And then the output here is text. And this is saying how much wood would a woodchuck, no, just how much would a woodchuck chuck. And so noticing kind of what, you know, which sounds, how many words are they going to. I thought it was interesting. It seems like the word would here, kind of like a single moment in time is going to several different characters in the output, where some of them are a little bit, actually, let me see if I can isolate. No, A has a lot as well. Some are a little bit more distinct, like I guess this is the sound from Chuck, and that's just going to two characters. So this is, I think, a nice way of visualizing attention of kind of what to focus on. And just see if there's any. Oh, and then they also give the example in this post of image captioning and even showing for a particular word how it's focusing on that part of the picture. So in coming up with the caption, a woman is throwing a frisbee in the park, when it's at the point of choosing the word frisbee, it's focused on this part of the picture. So it's pretty neat. And this is also kind of, I think, an example of taking inspiration from how humans work that, you know, we're focusing our attention on different parts and trying to include that structure in a neural network. So go ahead and go back to the slideshow. Yeah, so I wanted to show the interactive versions of those. And so we saw last time, or I guess last week, so this is part of Seek to Seek, our RNNs. They had an encoder and a decoder. And this is the version without attention, and this is the version with attention. And sorry, I meant to do a direct lineup of the lines. You can see to add attention, what we're doing is adding some weights, because basically we want to be able to take a weighted average of the output from the encoder, which is, as well as the hidden state, and we'll call that the context. So we're learning these attention weights, and that's a combination of, we've just taken hyperbolic tan of what's going to go kind of the attention on the encoder and attention for the hidden state, and then learning weights of how much value to give, kind of give the different time steps. So for the transformer, this was introduced in the paper, attention is all you need. And the kind of core idea is to get rid of RNNs and CNNs, so both RNNs and CNNs have been used for text tasks. Jeremy suggested it should have been called attention and positional encoding, and a fully connected neural network is all you need, because it actually does involve more than just attention. It's got several different components, which we'll go through. This paper looked at English to German and English to French translation, and got more accurate, more parallelizable, and faster to train results. This should all have an asterisk, though, because this is still an area of active research, and I don't think it's been settled yet of what's going to be best long term in terms of if you think of attention, RNNs and CNNs as kind of three areas of research and possibility, or even possibilities of are there ways to kind of combine the best aspects of them. Jeremy? Let me throw the catch box to you. Two days ago, I guess, Google came out with a paper called ExcelNet, which has easily beaten the state of the art in 18 out of 20 important NLP problems. And it's interesting because it's based on something called Transformer Excel, which combines a lot of the best features of RNNs and Transformers, and also uses some of the pre-training concepts from the ULM 5050 line. So there's some sign that people are combining these things, and I suspect that the direction is going to keep going. But you've mentioned a few times that this field is changing rapidly. As of two days ago, it changed rapidly again. And it was quite a substantial breakthrough. So knowing something about RNNs and something about attention seems to be important. Yes. And I would say CNNs as well. Yeah, thank you, Jeremy. That's a great example. Oh, it's the letter X, the letter L, net, all the way. OK. And Jeremy's saying for the spelling, it's letter X, letter L, net. Actually, I can even enter that. Second one. Oh, no, that's a medium post. OK. Well, I think this gets you to the name. And you can see all these results are within the last 18 hours. So this seems to be pretty recent. That means our course is 18 hours out of date. And this is, I guess I should say, for the video, June 2019. So depending on when you're watching it, it could be more than 18 hours out of date. And so the motivation they give in the paper is that the inherently sequential nature of RNNs precludes parallelization within training examples, which becomes critical at longer sequence lengths as memory constraints limit batching across examples. Although this is somewhat contestable because new research is coming out using RNNs. There is another, I guess I'll mention it now, paper from earlier this year, I guess February, Pay Less Attention with Lightweight and Dynamic Convolutions. So this is recent research getting better results with convolutions and with attention. So a lot to still kind of be studied and determined here. And so this figure is from the original Attention is All You Need paper showing the model architecture of the transformer. A few things to notice about it. So some of this should look familiar to you. We'll still have an input embedding, something called a positional encoding, which we'll learn about next week. And then attention is used at three different places in the network. There's basically self-attention for the encoder, self-attention for the decoder, and attention kind of going between the encoder and decoder. There are also feedforward, just so layers of kind of standard fully connected neural network, which you then add and take the norm. Over here on the decoder side, you also can have some feedforward layers of fully connected neural networks, adding and taking the norm. And so this is kind of high level, the architecture we are running out of time today, but we'll next time get into kind of what's going on with the kind of what is attention, what is positional encoding, what are these pieces being put together. And then also you'll note over to the side, it says capital NX. Here N is six in the original Attention paper. And so you kind of have six of these stacked up. So the kind of basic operation of attention is to have, so here Q stands for query, K is for key, and V is for value. And basically the idea is that the query is kind of what you're getting. So for two sentences, which could be, so sequence to sequence, the idea is you have two sequences. In our case, we were going from, can't remember, I think French to English. You have kind of your French word, which could be, is kind of represented by the query, and we'll see how in a moment. And then you want to compare that to kind of each word in your output of how much do you need to focus on those. That'll be the key you're looking up. And you'll use those, kind of want to combine those in a way that gives you a score that you multiply then with your output. And so we'll see this more closely, but it's kind of having a key representing kind of word one. You want to be able to compare that to other words as keys. And then you'll get a score, and then basically use those scores to take a weighted average, I guess, of all the values. And we'll see this a little bit better. So Jay Alomar has an excellent blog post called The Illustrated Transformer. Actually, let me ask, Jeremy, do you want to explain the query key and value high level, how you see the meaning of those? Or what? How long do we have? We only have seven minutes. Can I go back a little bit further? I actually found it useful to start back here and think about what happens if you get rid of the orange boxes and just have the blue boxes. This NX means you repeat this a bunch of times, and they repeat it six times. So there's six layers. So this feedforward thing is just a normal, fully connected neural network with a ReLU. So if you remove this add a norm thing, then it's just a six layer neural net here. And then this is a standard like sec to sec thing of going from an encoder to a decoder. And so then again, if you get rid of ignore the attention, you've got N, that's also a six layer neural net. So it really is, it's got a normal neural network in it. But the neural networks only operate on one word at a time. So they don't combine across words. So like if that's all that happened, it wouldn't be able to do very much. So like the first kind of insight for me in understanding this was realizing like this orange thing is all about what the neural network gets fed. And rather than just being fed a word, it's fed a weighted combination of words. So how does it create that weighted combination with this softmax? So the softmax adds up to one. So this gives you the amount of each word that you're going to include. So when you're looking at word one, which of the other words are relevant? Question? What if there's more decay? Why we need to divide them? We'll get to that. Yeah, we'll get to the details of that. It's a normalization. But the key thing is just this idea that this is creating numbers that are going to add up to one. And so therefore when we're saying like how do I translate word one or what other words are relevant, that's the attention part. Those weights are going to add to one because we've got softmax of something. And so then the something is what Rachel was asking about, which is the something is. Oh, I can talk about this part. I was just asked if you wanted to give like intuition on key query. Yeah, that's what I'm going to try to do. So the something is a query, a key, and a value. And they're going to be calculated as per usual by learning weight matrices. And the idea is we're going to try and learn a weight matrix where Q is going to be learnt for the word I'm currently translating. So if I'm looking at word one, then Q is going to be for word one. And then I'm going to look at all the other words in the sentence and say how much attention do I give to H1 when translating word one? And so K is going to be something that I learn for, something I'm going to calculate for all the other words in the sentence, well all of them, including this one. And then Q and K are going to get combined together, as you see, to overall give this sense of like how relevant is the word represented by K to translating the word represented by Q? And having figured out... I was just saying, when they're combined together, this is forming a scalar. So that's kind of important to note that this part that you get out of the softmax is kind of a scalar, which I mean we're going to put this into vectors, but compared to, you know, it's a dimension less than Q and K, where we are kind of combining this into a score. So you can kind of think of this as a scalar score that we're using to take this weighted average, as Jeremy said, of the vectors B. Yeah, so then V is being applied to the same word that K is applied to. So you've figured out how much attention you want to give to the thing for K, given that we're looking at the thing for Q, and then what do you return? You return V. And so the intuition here, the reason I wanted to show those previous two slides, is that V, if we didn't have any of this Q and K stuff, V would just be the weight matrix being fed into the feedforward neural network each time. But we don't just want the weight matrix for the current word, it would be a mix of weight matrices based on how much attention we want to give them. So V is like the weight matrix in the neural network, that's all that is. And then Q and K tell you how much to mix up all the different weight matrices in the different words, I guess. Does that help? Yeah, yeah, that's great. Thank you, Jeremy. That was a good explanation of this intuition of needing a way basically to compare two words, get a score, and then take a weighted average of all your words. And you can even think of that, going back to the pictures of what attention looks like of here. We need a way to actually, let me do the one with words, compare two words and then take this weighted average of what's important and apply that back to each word. And then we'll see this in the code, the square root of DK is just normalizing by the dimension that you're dealing with. And so what's going on here? So this example, which is great, and I highly recommend Jay Alomar's blog post here, is we've got an embedding, say, for the word thinking and an embedding for the word machines. We want to kind of figure out what's the interaction between them in terms of where we should be paying attention. And so we're going to learn a few different weight matrices to get Q, K, and V. And just briefly here, Q1 is this weight matrix for Q times X1 is giving us Q1. The weight matrix for Q times X2 gives us Q2. The weight matrix for K times X1 gives us K1. Weight matrix for K times X2 gives us K2. These are how these are being calculated in practice. They're kind of just taking matrix multiplications with these matrices that we'll be learning the weights for. And then it's 1 o'clock. So we'll stop here, and we'll review this next time as we get started, and then get further into Transformer. Oh, thank you. Yes? Can you talk briefly about the final exam, the four exams on it? The final exam? So it'll be a written exam, and it'll probably be a mix of some questions will involve kind of reading code or maybe modifying it or saying what pieces are doing. There will also be multiple choice questions kind of based on all of the conceptual ideas we've covered. Yeah. And there'll probably also be some short answer, I would say, too. Yeah, so no code. I mean, there might be reading code. And I'll have to see. Like in the past, I've sometimes had like modify this line of code or say kind of how you would change it. But it's not going to be on the computer coding. Any other questions? Great. I'll see you on Tuesday. Or email me if you need to meet before then. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.0, "text": " Okay, and so now to change tax, we'll go back to language translation.", "tokens": [1033, 11, 293, 370, 586, 281, 1319, 3366, 11, 321, 603, 352, 646, 281, 2856, 12853, 13], "temperature": 0.0, "avg_logprob": -0.24109668731689454, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.036194607615470886}, {"id": 1, "seek": 0, "start": 13.0, "end": 17.32, "text": " And so we'll start on that today and then tomorrow we'll have, or not tomorrow, sorry,", "tokens": [400, 370, 321, 603, 722, 322, 300, 965, 293, 550, 4153, 321, 603, 362, 11, 420, 406, 4153, 11, 2597, 11], "temperature": 0.0, "avg_logprob": -0.24109668731689454, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.036194607615470886}, {"id": 2, "seek": 0, "start": 17.32, "end": 22.84, "text": " Tuesday we'll have plenty of time to continue with attention and the transformer and this", "tokens": [10017, 321, 603, 362, 7140, 295, 565, 281, 2354, 365, 3202, 293, 264, 31782, 293, 341], "temperature": 0.0, "avg_logprob": -0.24109668731689454, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.036194607615470886}, {"id": 3, "seek": 0, "start": 22.84, "end": 26.6, "text": " topic of improving language translation.", "tokens": [4829, 295, 11470, 2856, 12853, 13], "temperature": 0.0, "avg_logprob": -0.24109668731689454, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.036194607615470886}, {"id": 4, "seek": 2660, "start": 26.6, "end": 32.6, "text": " And so I think with this I want to start with some slides.", "tokens": [400, 370, 286, 519, 365, 341, 286, 528, 281, 722, 365, 512, 9788, 13], "temperature": 0.0, "avg_logprob": -0.23687192838485926, "compression_ratio": 1.6046511627906976, "no_speech_prob": 8.089262701105326e-05}, {"id": 5, "seek": 2660, "start": 32.6, "end": 38.6, "text": " Let me open.", "tokens": [961, 385, 1269, 13], "temperature": 0.0, "avg_logprob": -0.23687192838485926, "compression_ratio": 1.6046511627906976, "no_speech_prob": 8.089262701105326e-05}, {"id": 6, "seek": 2660, "start": 38.6, "end": 45.480000000000004, "text": " And actually, so I wanted to start with, there's a great blog post.", "tokens": [400, 767, 11, 370, 286, 1415, 281, 722, 365, 11, 456, 311, 257, 869, 6968, 2183, 13], "temperature": 0.0, "avg_logprob": -0.23687192838485926, "compression_ratio": 1.6046511627906976, "no_speech_prob": 8.089262701105326e-05}, {"id": 7, "seek": 2660, "start": 45.480000000000004, "end": 48.480000000000004, "text": " So we're going to start with just talking about attention again.", "tokens": [407, 321, 434, 516, 281, 722, 365, 445, 1417, 466, 3202, 797, 13], "temperature": 0.0, "avg_logprob": -0.23687192838485926, "compression_ratio": 1.6046511627906976, "no_speech_prob": 8.089262701105326e-05}, {"id": 8, "seek": 2660, "start": 48.480000000000004, "end": 55.68000000000001, "text": " And attention is a key idea of the transformer network for translation.", "tokens": [400, 3202, 307, 257, 2141, 1558, 295, 264, 31782, 3209, 337, 12853, 13], "temperature": 0.0, "avg_logprob": -0.23687192838485926, "compression_ratio": 1.6046511627906976, "no_speech_prob": 8.089262701105326e-05}, {"id": 9, "seek": 5568, "start": 55.68, "end": 64.0, "text": " We saw attention previously in Lesson 7, I guess Notebook 7B, Seek to Seek with Attention.", "tokens": [492, 1866, 3202, 8046, 294, 18649, 266, 1614, 11, 286, 2041, 11633, 2939, 1614, 33, 11, 1100, 916, 281, 1100, 916, 365, 31858, 13], "temperature": 0.0, "avg_logprob": -0.15895865574355952, "compression_ratio": 1.554307116104869, "no_speech_prob": 5.827707354910672e-05}, {"id": 10, "seek": 5568, "start": 64.0, "end": 69.2, "text": " And so first we're just going to revisit attention with RNNs, although then we'll move on to", "tokens": [400, 370, 700, 321, 434, 445, 516, 281, 32676, 3202, 365, 45702, 45, 82, 11, 4878, 550, 321, 603, 1286, 322, 281], "temperature": 0.0, "avg_logprob": -0.15895865574355952, "compression_ratio": 1.554307116104869, "no_speech_prob": 5.827707354910672e-05}, {"id": 11, "seek": 5568, "start": 69.2, "end": 72.14, "text": " Transformer which is not an RNN.", "tokens": [27938, 260, 597, 307, 406, 364, 45702, 45, 13], "temperature": 0.0, "avg_logprob": -0.15895865574355952, "compression_ratio": 1.554307116104869, "no_speech_prob": 5.827707354910672e-05}, {"id": 12, "seek": 5568, "start": 72.14, "end": 78.28, "text": " So Chris Ola, who's kind of one of the founders of Distill, are you guys familiar with Distill.pub", "tokens": [407, 6688, 422, 875, 11, 567, 311, 733, 295, 472, 295, 264, 25608, 295, 9840, 373, 11, 366, 291, 1074, 4963, 365, 9840, 373, 13, 79, 836], "temperature": 0.0, "avg_logprob": -0.15895865574355952, "compression_ratio": 1.554307116104869, "no_speech_prob": 5.827707354910672e-05}, {"id": 13, "seek": 5568, "start": 78.28, "end": 79.28, "text": " from Google?", "tokens": [490, 3329, 30], "temperature": 0.0, "avg_logprob": -0.15895865574355952, "compression_ratio": 1.554307116104869, "no_speech_prob": 5.827707354910672e-05}, {"id": 14, "seek": 5568, "start": 79.28, "end": 83.96000000000001, "text": " Okay, they, it's kind of like this online journal that, so Chris Ola is great at doing", "tokens": [1033, 11, 436, 11, 309, 311, 733, 295, 411, 341, 2950, 6708, 300, 11, 370, 6688, 422, 875, 307, 869, 412, 884], "temperature": 0.0, "avg_logprob": -0.15895865574355952, "compression_ratio": 1.554307116104869, "no_speech_prob": 5.827707354910672e-05}, {"id": 15, "seek": 8396, "start": 83.96, "end": 86.47999999999999, "text": " these like really beautiful visualizations.", "tokens": [613, 411, 534, 2238, 5056, 14455, 13], "temperature": 0.0, "avg_logprob": -0.1609929402669271, "compression_ratio": 1.616580310880829, "no_speech_prob": 1.777610850695055e-05}, {"id": 16, "seek": 8396, "start": 86.47999999999999, "end": 90.6, "text": " And so he was kind of used to do this on his blog and then kind of created Distill as this", "tokens": [400, 370, 415, 390, 733, 295, 1143, 281, 360, 341, 322, 702, 6968, 293, 550, 733, 295, 2942, 9840, 373, 382, 341], "temperature": 0.0, "avg_logprob": -0.1609929402669271, "compression_ratio": 1.616580310880829, "no_speech_prob": 1.777610850695055e-05}, {"id": 17, "seek": 8396, "start": 90.6, "end": 96.44, "text": " way to kind of have even more an outlet for people to write work that involves kind of", "tokens": [636, 281, 733, 295, 362, 754, 544, 364, 20656, 337, 561, 281, 2464, 589, 300, 11626, 733, 295], "temperature": 0.0, "avg_logprob": -0.1609929402669271, "compression_ratio": 1.616580310880829, "no_speech_prob": 1.777610850695055e-05}, {"id": 18, "seek": 8396, "start": 96.44, "end": 101.19999999999999, "text": " beautiful interactive visualizations of deep learning concepts.", "tokens": [2238, 15141, 5056, 14455, 295, 2452, 2539, 10392, 13], "temperature": 0.0, "avg_logprob": -0.1609929402669271, "compression_ratio": 1.616580310880829, "no_speech_prob": 1.777610850695055e-05}, {"id": 19, "seek": 8396, "start": 101.19999999999999, "end": 111.96, "text": " Let me click on this post.", "tokens": [961, 385, 2052, 322, 341, 2183, 13], "temperature": 0.0, "avg_logprob": -0.1609929402669271, "compression_ratio": 1.616580310880829, "no_speech_prob": 1.777610850695055e-05}, {"id": 20, "seek": 11196, "start": 111.96, "end": 116.24, "text": " And here he's talking about a few different features of RNNs.", "tokens": [400, 510, 415, 311, 1417, 466, 257, 1326, 819, 4122, 295, 45702, 45, 82, 13], "temperature": 0.0, "avg_logprob": -0.12868019969192976, "compression_ratio": 1.625, "no_speech_prob": 2.2471831471193582e-05}, {"id": 21, "seek": 11196, "start": 116.24, "end": 125.22, "text": " I'm just going to go to the one on attentional interfaces.", "tokens": [286, 478, 445, 516, 281, 352, 281, 264, 472, 322, 3202, 304, 28416, 13], "temperature": 0.0, "avg_logprob": -0.12868019969192976, "compression_ratio": 1.625, "no_speech_prob": 2.2471831471193582e-05}, {"id": 22, "seek": 11196, "start": 125.22, "end": 130.84, "text": " And so kind of the idea is, so here you're translating from English to French and you've", "tokens": [400, 370, 733, 295, 264, 1558, 307, 11, 370, 510, 291, 434, 35030, 490, 3669, 281, 5522, 293, 291, 600], "temperature": 0.0, "avg_logprob": -0.12868019969192976, "compression_ratio": 1.625, "no_speech_prob": 2.2471831471193582e-05}, {"id": 23, "seek": 11196, "start": 130.84, "end": 133.35999999999999, "text": " got, you know, you're going from one sentence to another.", "tokens": [658, 11, 291, 458, 11, 291, 434, 516, 490, 472, 8174, 281, 1071, 13], "temperature": 0.0, "avg_logprob": -0.12868019969192976, "compression_ratio": 1.625, "no_speech_prob": 2.2471831471193582e-05}, {"id": 24, "seek": 11196, "start": 133.35999999999999, "end": 136.7, "text": " Depending on what word you're on, you want to focus on different parts of the original", "tokens": [22539, 322, 437, 1349, 291, 434, 322, 11, 291, 528, 281, 1879, 322, 819, 3166, 295, 264, 3380], "temperature": 0.0, "avg_logprob": -0.12868019969192976, "compression_ratio": 1.625, "no_speech_prob": 2.2471831471193582e-05}, {"id": 25, "seek": 11196, "start": 136.7, "end": 137.7, "text": " sentence.", "tokens": [8174, 13], "temperature": 0.0, "avg_logprob": -0.12868019969192976, "compression_ratio": 1.625, "no_speech_prob": 2.2471831471193582e-05}, {"id": 26, "seek": 13770, "start": 137.7, "end": 143.72, "text": " So here you can scroll over and see for signed, this is, so we're going kind of from English", "tokens": [407, 510, 291, 393, 11369, 670, 293, 536, 337, 8175, 11, 341, 307, 11, 370, 321, 434, 516, 733, 295, 490, 3669], "temperature": 0.0, "avg_logprob": -0.1276194374516325, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.321011536172591e-05}, {"id": 27, "seek": 13770, "start": 143.72, "end": 146.72, "text": " to French.", "tokens": [281, 5522, 13], "temperature": 0.0, "avg_logprob": -0.1276194374516325, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.321011536172591e-05}, {"id": 28, "seek": 13770, "start": 146.72, "end": 148.35999999999999, "text": " These are kind of the places it needs to go.", "tokens": [1981, 366, 733, 295, 264, 3190, 309, 2203, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.1276194374516325, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.321011536172591e-05}, {"id": 29, "seek": 13770, "start": 148.35999999999999, "end": 154.2, "text": " Actually, I guess I should start on the French side showing what needs to be pulled in as", "tokens": [5135, 11, 286, 2041, 286, 820, 722, 322, 264, 5522, 1252, 4099, 437, 2203, 281, 312, 7373, 294, 382], "temperature": 0.0, "avg_logprob": -0.1276194374516325, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.321011536172591e-05}, {"id": 30, "seek": 13770, "start": 154.2, "end": 155.78, "text": " you're translating.", "tokens": [291, 434, 35030, 13], "temperature": 0.0, "avg_logprob": -0.1276194374516325, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.321011536172591e-05}, {"id": 31, "seek": 13770, "start": 155.78, "end": 161.22, "text": " And it's, you know, it's not in a one-to-one order because different languages have different", "tokens": [400, 309, 311, 11, 291, 458, 11, 309, 311, 406, 294, 257, 472, 12, 1353, 12, 546, 1668, 570, 819, 8650, 362, 819], "temperature": 0.0, "avg_logprob": -0.1276194374516325, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.321011536172591e-05}, {"id": 32, "seek": 13770, "start": 161.22, "end": 165.2, "text": " syntax of what order things go in.", "tokens": [28431, 295, 437, 1668, 721, 352, 294, 13], "temperature": 0.0, "avg_logprob": -0.1276194374516325, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.321011536172591e-05}, {"id": 33, "seek": 16520, "start": 165.2, "end": 170.79999999999998, "text": " Where like for a zone, it needs to know about the economic area.", "tokens": [2305, 411, 337, 257, 6668, 11, 309, 2203, 281, 458, 466, 264, 4836, 1859, 13], "temperature": 0.0, "avg_logprob": -0.19125330448150635, "compression_ratio": 1.6411483253588517, "no_speech_prob": 4.7565637942170724e-05}, {"id": 34, "seek": 16520, "start": 170.79999999999998, "end": 177.6, "text": " Law, knowing kind of the gender of the pronoun is coming from, you know, not just the, but", "tokens": [7744, 11, 5276, 733, 295, 264, 7898, 295, 264, 14144, 307, 1348, 490, 11, 291, 458, 11, 406, 445, 264, 11, 457], "temperature": 0.0, "avg_logprob": -0.19125330448150635, "compression_ratio": 1.6411483253588517, "no_speech_prob": 4.7565637942170724e-05}, {"id": 35, "seek": 16520, "start": 177.6, "end": 182.72, "text": " also what's going to be modified, sorry, gender of the noun.", "tokens": [611, 437, 311, 516, 281, 312, 15873, 11, 2597, 11, 7898, 295, 264, 23307, 13], "temperature": 0.0, "avg_logprob": -0.19125330448150635, "compression_ratio": 1.6411483253588517, "no_speech_prob": 4.7565637942170724e-05}, {"id": 36, "seek": 16520, "start": 182.72, "end": 188.39999999999998, "text": " And so this is, I think, a nice way of kind of seeing what needs to be, kind of where", "tokens": [400, 370, 341, 307, 11, 286, 519, 11, 257, 1481, 636, 295, 733, 295, 2577, 437, 2203, 281, 312, 11, 733, 295, 689], "temperature": 0.0, "avg_logprob": -0.19125330448150635, "compression_ratio": 1.6411483253588517, "no_speech_prob": 4.7565637942170724e-05}, {"id": 37, "seek": 16520, "start": 188.39999999999998, "end": 190.6, "text": " does information need to go from and to.", "tokens": [775, 1589, 643, 281, 352, 490, 293, 281, 13], "temperature": 0.0, "avg_logprob": -0.19125330448150635, "compression_ratio": 1.6411483253588517, "no_speech_prob": 4.7565637942170724e-05}, {"id": 38, "seek": 19060, "start": 190.6, "end": 196.32, "text": " And the idea of attention is knowing kind of the network wants to, or creating networks", "tokens": [400, 264, 1558, 295, 3202, 307, 5276, 733, 295, 264, 3209, 2738, 281, 11, 420, 4084, 9590], "temperature": 0.0, "avg_logprob": -0.1404826515599301, "compression_ratio": 1.609865470852018, "no_speech_prob": 1.4284120879892725e-05}, {"id": 39, "seek": 19060, "start": 196.32, "end": 201.44, "text": " that can learn what to focus on at a particular time.", "tokens": [300, 393, 1466, 437, 281, 1879, 322, 412, 257, 1729, 565, 13], "temperature": 0.0, "avg_logprob": -0.1404826515599301, "compression_ratio": 1.609865470852018, "no_speech_prob": 1.4284120879892725e-05}, {"id": 40, "seek": 19060, "start": 201.44, "end": 204.51999999999998, "text": " So this is a nice visualization.", "tokens": [407, 341, 307, 257, 1481, 25801, 13], "temperature": 0.0, "avg_logprob": -0.1404826515599301, "compression_ratio": 1.609865470852018, "no_speech_prob": 1.4284120879892725e-05}, {"id": 41, "seek": 19060, "start": 204.51999999999998, "end": 208.16, "text": " This is also a great one for going from audio to words.", "tokens": [639, 307, 611, 257, 869, 472, 337, 516, 490, 6278, 281, 2283, 13], "temperature": 0.0, "avg_logprob": -0.1404826515599301, "compression_ratio": 1.609865470852018, "no_speech_prob": 1.4284120879892725e-05}, {"id": 42, "seek": 19060, "start": 208.16, "end": 213.28, "text": " So here having input audio, which you can see with these just kind of white and black", "tokens": [407, 510, 1419, 4846, 6278, 11, 597, 291, 393, 536, 365, 613, 445, 733, 295, 2418, 293, 2211], "temperature": 0.0, "avg_logprob": -0.1404826515599301, "compression_ratio": 1.609865470852018, "no_speech_prob": 1.4284120879892725e-05}, {"id": 43, "seek": 19060, "start": 213.28, "end": 214.64, "text": " smudges.", "tokens": [899, 532, 2880, 13], "temperature": 0.0, "avg_logprob": -0.1404826515599301, "compression_ratio": 1.609865470852018, "no_speech_prob": 1.4284120879892725e-05}, {"id": 44, "seek": 19060, "start": 214.64, "end": 216.84, "text": " And then the output here is text.", "tokens": [400, 550, 264, 5598, 510, 307, 2487, 13], "temperature": 0.0, "avg_logprob": -0.1404826515599301, "compression_ratio": 1.609865470852018, "no_speech_prob": 1.4284120879892725e-05}, {"id": 45, "seek": 21684, "start": 216.84, "end": 222.88, "text": " And this is saying how much wood would a woodchuck, no, just how much would a woodchuck chuck.", "tokens": [400, 341, 307, 1566, 577, 709, 4576, 576, 257, 4576, 25340, 11, 572, 11, 445, 577, 709, 576, 257, 4576, 25340, 20870, 13], "temperature": 0.0, "avg_logprob": -0.1703814665476481, "compression_ratio": 1.7093023255813953, "no_speech_prob": 1.4738131540070754e-05}, {"id": 46, "seek": 21684, "start": 222.88, "end": 228.56, "text": " And so noticing kind of what, you know, which sounds, how many words are they going to.", "tokens": [400, 370, 21814, 733, 295, 437, 11, 291, 458, 11, 597, 3263, 11, 577, 867, 2283, 366, 436, 516, 281, 13], "temperature": 0.0, "avg_logprob": -0.1703814665476481, "compression_ratio": 1.7093023255813953, "no_speech_prob": 1.4738131540070754e-05}, {"id": 47, "seek": 21684, "start": 228.56, "end": 229.88, "text": " I thought it was interesting.", "tokens": [286, 1194, 309, 390, 1880, 13], "temperature": 0.0, "avg_logprob": -0.1703814665476481, "compression_ratio": 1.7093023255813953, "no_speech_prob": 1.4738131540070754e-05}, {"id": 48, "seek": 21684, "start": 229.88, "end": 236.32, "text": " It seems like the word would here, kind of like a single moment in time is going to several", "tokens": [467, 2544, 411, 264, 1349, 576, 510, 11, 733, 295, 411, 257, 2167, 1623, 294, 565, 307, 516, 281, 2940], "temperature": 0.0, "avg_logprob": -0.1703814665476481, "compression_ratio": 1.7093023255813953, "no_speech_prob": 1.4738131540070754e-05}, {"id": 49, "seek": 21684, "start": 236.32, "end": 240.72, "text": " different characters in the output, where some of them are a little bit, actually, let", "tokens": [819, 4342, 294, 264, 5598, 11, 689, 512, 295, 552, 366, 257, 707, 857, 11, 767, 11, 718], "temperature": 0.0, "avg_logprob": -0.1703814665476481, "compression_ratio": 1.7093023255813953, "no_speech_prob": 1.4738131540070754e-05}, {"id": 50, "seek": 21684, "start": 240.72, "end": 241.72, "text": " me see if I can isolate.", "tokens": [385, 536, 498, 286, 393, 25660, 13], "temperature": 0.0, "avg_logprob": -0.1703814665476481, "compression_ratio": 1.7093023255813953, "no_speech_prob": 1.4738131540070754e-05}, {"id": 51, "seek": 21684, "start": 241.72, "end": 244.28, "text": " No, A has a lot as well.", "tokens": [883, 11, 316, 575, 257, 688, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1703814665476481, "compression_ratio": 1.7093023255813953, "no_speech_prob": 1.4738131540070754e-05}, {"id": 52, "seek": 24428, "start": 244.28, "end": 248.24, "text": " Some are a little bit more distinct, like I guess this is the sound from Chuck, and", "tokens": [2188, 366, 257, 707, 857, 544, 10644, 11, 411, 286, 2041, 341, 307, 264, 1626, 490, 21607, 11, 293], "temperature": 0.0, "avg_logprob": -0.16830048334030878, "compression_ratio": 1.5823293172690762, "no_speech_prob": 2.046028384938836e-05}, {"id": 53, "seek": 24428, "start": 248.24, "end": 251.28, "text": " that's just going to two characters.", "tokens": [300, 311, 445, 516, 281, 732, 4342, 13], "temperature": 0.0, "avg_logprob": -0.16830048334030878, "compression_ratio": 1.5823293172690762, "no_speech_prob": 2.046028384938836e-05}, {"id": 54, "seek": 24428, "start": 251.28, "end": 258.36, "text": " So this is, I think, a nice way of visualizing attention of kind of what to focus on.", "tokens": [407, 341, 307, 11, 286, 519, 11, 257, 1481, 636, 295, 5056, 3319, 3202, 295, 733, 295, 437, 281, 1879, 322, 13], "temperature": 0.0, "avg_logprob": -0.16830048334030878, "compression_ratio": 1.5823293172690762, "no_speech_prob": 2.046028384938836e-05}, {"id": 55, "seek": 24428, "start": 258.36, "end": 261.36, "text": " And just see if there's any.", "tokens": [400, 445, 536, 498, 456, 311, 604, 13], "temperature": 0.0, "avg_logprob": -0.16830048334030878, "compression_ratio": 1.5823293172690762, "no_speech_prob": 2.046028384938836e-05}, {"id": 56, "seek": 24428, "start": 261.36, "end": 267.4, "text": " Oh, and then they also give the example in this post of image captioning and even showing", "tokens": [876, 11, 293, 550, 436, 611, 976, 264, 1365, 294, 341, 2183, 295, 3256, 31974, 278, 293, 754, 4099], "temperature": 0.0, "avg_logprob": -0.16830048334030878, "compression_ratio": 1.5823293172690762, "no_speech_prob": 2.046028384938836e-05}, {"id": 57, "seek": 24428, "start": 267.4, "end": 271.44, "text": " for a particular word how it's focusing on that part of the picture.", "tokens": [337, 257, 1729, 1349, 577, 309, 311, 8416, 322, 300, 644, 295, 264, 3036, 13], "temperature": 0.0, "avg_logprob": -0.16830048334030878, "compression_ratio": 1.5823293172690762, "no_speech_prob": 2.046028384938836e-05}, {"id": 58, "seek": 27144, "start": 271.44, "end": 278.28, "text": " So in coming up with the caption, a woman is throwing a frisbee in the park, when it's", "tokens": [407, 294, 1348, 493, 365, 264, 31974, 11, 257, 3059, 307, 10238, 257, 431, 271, 24872, 294, 264, 3884, 11, 562, 309, 311], "temperature": 0.0, "avg_logprob": -0.14919429850355487, "compression_ratio": 1.6584362139917694, "no_speech_prob": 8.664384040457662e-06}, {"id": 59, "seek": 27144, "start": 278.28, "end": 283.72, "text": " at the point of choosing the word frisbee, it's focused on this part of the picture.", "tokens": [412, 264, 935, 295, 10875, 264, 1349, 431, 271, 24872, 11, 309, 311, 5178, 322, 341, 644, 295, 264, 3036, 13], "temperature": 0.0, "avg_logprob": -0.14919429850355487, "compression_ratio": 1.6584362139917694, "no_speech_prob": 8.664384040457662e-06}, {"id": 60, "seek": 27144, "start": 283.72, "end": 285.04, "text": " So it's pretty neat.", "tokens": [407, 309, 311, 1238, 10654, 13], "temperature": 0.0, "avg_logprob": -0.14919429850355487, "compression_ratio": 1.6584362139917694, "no_speech_prob": 8.664384040457662e-06}, {"id": 61, "seek": 27144, "start": 285.04, "end": 289.72, "text": " And this is also kind of, I think, an example of taking inspiration from how humans work", "tokens": [400, 341, 307, 611, 733, 295, 11, 286, 519, 11, 364, 1365, 295, 1940, 10249, 490, 577, 6255, 589], "temperature": 0.0, "avg_logprob": -0.14919429850355487, "compression_ratio": 1.6584362139917694, "no_speech_prob": 8.664384040457662e-06}, {"id": 62, "seek": 27144, "start": 289.72, "end": 294.96, "text": " that, you know, we're focusing our attention on different parts and trying to include that", "tokens": [300, 11, 291, 458, 11, 321, 434, 8416, 527, 3202, 322, 819, 3166, 293, 1382, 281, 4090, 300], "temperature": 0.0, "avg_logprob": -0.14919429850355487, "compression_ratio": 1.6584362139917694, "no_speech_prob": 8.664384040457662e-06}, {"id": 63, "seek": 27144, "start": 294.96, "end": 297.15999999999997, "text": " structure in a neural network.", "tokens": [3877, 294, 257, 18161, 3209, 13], "temperature": 0.0, "avg_logprob": -0.14919429850355487, "compression_ratio": 1.6584362139917694, "no_speech_prob": 8.664384040457662e-06}, {"id": 64, "seek": 29716, "start": 297.16, "end": 302.16, "text": " So go ahead and go back to the slideshow.", "tokens": [407, 352, 2286, 293, 352, 646, 281, 264, 9788, 4286, 13], "temperature": 0.0, "avg_logprob": -0.1840535886995085, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.184257780550979e-05}, {"id": 65, "seek": 29716, "start": 302.16, "end": 309.04, "text": " Yeah, so I wanted to show the interactive versions of those.", "tokens": [865, 11, 370, 286, 1415, 281, 855, 264, 15141, 9606, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.1840535886995085, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.184257780550979e-05}, {"id": 66, "seek": 29716, "start": 309.04, "end": 316.84000000000003, "text": " And so we saw last time, or I guess last week, so this is part of Seek to Seek, our RNNs.", "tokens": [400, 370, 321, 1866, 1036, 565, 11, 420, 286, 2041, 1036, 1243, 11, 370, 341, 307, 644, 295, 1100, 916, 281, 1100, 916, 11, 527, 45702, 45, 82, 13], "temperature": 0.0, "avg_logprob": -0.1840535886995085, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.184257780550979e-05}, {"id": 67, "seek": 29716, "start": 316.84000000000003, "end": 320.72, "text": " They had an encoder and a decoder.", "tokens": [814, 632, 364, 2058, 19866, 293, 257, 979, 19866, 13], "temperature": 0.0, "avg_logprob": -0.1840535886995085, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.184257780550979e-05}, {"id": 68, "seek": 29716, "start": 320.72, "end": 326.8, "text": " And this is the version without attention, and this is the version with attention.", "tokens": [400, 341, 307, 264, 3037, 1553, 3202, 11, 293, 341, 307, 264, 3037, 365, 3202, 13], "temperature": 0.0, "avg_logprob": -0.1840535886995085, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.184257780550979e-05}, {"id": 69, "seek": 32680, "start": 326.8, "end": 331.24, "text": " And sorry, I meant to do a direct lineup of the lines.", "tokens": [400, 2597, 11, 286, 4140, 281, 360, 257, 2047, 26461, 295, 264, 3876, 13], "temperature": 0.0, "avg_logprob": -0.14068687879122221, "compression_ratio": 1.5260416666666667, "no_speech_prob": 1.3419354218058288e-05}, {"id": 70, "seek": 32680, "start": 331.24, "end": 338.24, "text": " You can see to add attention, what we're doing is adding some weights, because basically", "tokens": [509, 393, 536, 281, 909, 3202, 11, 437, 321, 434, 884, 307, 5127, 512, 17443, 11, 570, 1936], "temperature": 0.0, "avg_logprob": -0.14068687879122221, "compression_ratio": 1.5260416666666667, "no_speech_prob": 1.3419354218058288e-05}, {"id": 71, "seek": 32680, "start": 338.24, "end": 346.44, "text": " we want to be able to take a weighted average of the output from the encoder, which is,", "tokens": [321, 528, 281, 312, 1075, 281, 747, 257, 32807, 4274, 295, 264, 5598, 490, 264, 2058, 19866, 11, 597, 307, 11], "temperature": 0.0, "avg_logprob": -0.14068687879122221, "compression_ratio": 1.5260416666666667, "no_speech_prob": 1.3419354218058288e-05}, {"id": 72, "seek": 32680, "start": 346.44, "end": 351.56, "text": " as well as the hidden state, and we'll call that the context.", "tokens": [382, 731, 382, 264, 7633, 1785, 11, 293, 321, 603, 818, 300, 264, 4319, 13], "temperature": 0.0, "avg_logprob": -0.14068687879122221, "compression_ratio": 1.5260416666666667, "no_speech_prob": 1.3419354218058288e-05}, {"id": 73, "seek": 35156, "start": 351.56, "end": 357.16, "text": " So we're learning these attention weights, and that's a combination of, we've just taken", "tokens": [407, 321, 434, 2539, 613, 3202, 17443, 11, 293, 300, 311, 257, 6562, 295, 11, 321, 600, 445, 2726], "temperature": 0.0, "avg_logprob": -0.11626422939015858, "compression_ratio": 1.675, "no_speech_prob": 2.9771164918201976e-05}, {"id": 74, "seek": 35156, "start": 357.16, "end": 369.64, "text": " hyperbolic tan of what's going to go kind of the attention on the encoder and attention", "tokens": [9848, 65, 7940, 7603, 295, 437, 311, 516, 281, 352, 733, 295, 264, 3202, 322, 264, 2058, 19866, 293, 3202], "temperature": 0.0, "avg_logprob": -0.11626422939015858, "compression_ratio": 1.675, "no_speech_prob": 2.9771164918201976e-05}, {"id": 75, "seek": 35156, "start": 369.64, "end": 376.32, "text": " for the hidden state, and then learning weights of how much value to give, kind of give the", "tokens": [337, 264, 7633, 1785, 11, 293, 550, 2539, 17443, 295, 577, 709, 2158, 281, 976, 11, 733, 295, 976, 264], "temperature": 0.0, "avg_logprob": -0.11626422939015858, "compression_ratio": 1.675, "no_speech_prob": 2.9771164918201976e-05}, {"id": 76, "seek": 37632, "start": 376.32, "end": 391.96, "text": " different time steps.", "tokens": [819, 565, 4439, 13], "temperature": 0.0, "avg_logprob": -0.20410335063934326, "compression_ratio": 1.164835164835165, "no_speech_prob": 2.0144478185102344e-05}, {"id": 77, "seek": 37632, "start": 391.96, "end": 402.36, "text": " So for the transformer, this was introduced in the paper, attention is all you need.", "tokens": [407, 337, 264, 31782, 11, 341, 390, 7268, 294, 264, 3035, 11, 3202, 307, 439, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.20410335063934326, "compression_ratio": 1.164835164835165, "no_speech_prob": 2.0144478185102344e-05}, {"id": 78, "seek": 40236, "start": 402.36, "end": 409.24, "text": " And the kind of core idea is to get rid of RNNs and CNNs, so both RNNs and CNNs have been", "tokens": [400, 264, 733, 295, 4965, 1558, 307, 281, 483, 3973, 295, 45702, 45, 82, 293, 24859, 82, 11, 370, 1293, 45702, 45, 82, 293, 24859, 82, 362, 668], "temperature": 0.0, "avg_logprob": -0.11068925451725087, "compression_ratio": 1.5665236051502145, "no_speech_prob": 2.4298000425915234e-05}, {"id": 79, "seek": 40236, "start": 409.24, "end": 415.24, "text": " used for text tasks.", "tokens": [1143, 337, 2487, 9608, 13], "temperature": 0.0, "avg_logprob": -0.11068925451725087, "compression_ratio": 1.5665236051502145, "no_speech_prob": 2.4298000425915234e-05}, {"id": 80, "seek": 40236, "start": 415.24, "end": 420.84000000000003, "text": " Jeremy suggested it should have been called attention and positional encoding, and a fully", "tokens": [17809, 10945, 309, 820, 362, 668, 1219, 3202, 293, 2535, 304, 43430, 11, 293, 257, 4498], "temperature": 0.0, "avg_logprob": -0.11068925451725087, "compression_ratio": 1.5665236051502145, "no_speech_prob": 2.4298000425915234e-05}, {"id": 81, "seek": 40236, "start": 420.84000000000003, "end": 425.8, "text": " connected neural network is all you need, because it actually does involve more than", "tokens": [4582, 18161, 3209, 307, 439, 291, 643, 11, 570, 309, 767, 775, 9494, 544, 813], "temperature": 0.0, "avg_logprob": -0.11068925451725087, "compression_ratio": 1.5665236051502145, "no_speech_prob": 2.4298000425915234e-05}, {"id": 82, "seek": 40236, "start": 425.8, "end": 426.8, "text": " just attention.", "tokens": [445, 3202, 13], "temperature": 0.0, "avg_logprob": -0.11068925451725087, "compression_ratio": 1.5665236051502145, "no_speech_prob": 2.4298000425915234e-05}, {"id": 83, "seek": 40236, "start": 426.8, "end": 432.24, "text": " It's got several different components, which we'll go through.", "tokens": [467, 311, 658, 2940, 819, 6677, 11, 597, 321, 603, 352, 807, 13], "temperature": 0.0, "avg_logprob": -0.11068925451725087, "compression_ratio": 1.5665236051502145, "no_speech_prob": 2.4298000425915234e-05}, {"id": 84, "seek": 43224, "start": 432.24, "end": 437.28000000000003, "text": " This paper looked at English to German and English to French translation, and got more", "tokens": [639, 3035, 2956, 412, 3669, 281, 6521, 293, 3669, 281, 5522, 12853, 11, 293, 658, 544], "temperature": 0.0, "avg_logprob": -0.11642951965332031, "compression_ratio": 1.5502392344497609, "no_speech_prob": 5.223504194873385e-05}, {"id": 85, "seek": 43224, "start": 437.28000000000003, "end": 444.2, "text": " accurate, more parallelizable, and faster to train results.", "tokens": [8559, 11, 544, 8952, 22395, 11, 293, 4663, 281, 3847, 3542, 13], "temperature": 0.0, "avg_logprob": -0.11642951965332031, "compression_ratio": 1.5502392344497609, "no_speech_prob": 5.223504194873385e-05}, {"id": 86, "seek": 43224, "start": 444.2, "end": 451.04, "text": " This should all have an asterisk, though, because this is still an area of active research,", "tokens": [639, 820, 439, 362, 364, 257, 3120, 7797, 11, 1673, 11, 570, 341, 307, 920, 364, 1859, 295, 4967, 2132, 11], "temperature": 0.0, "avg_logprob": -0.11642951965332031, "compression_ratio": 1.5502392344497609, "no_speech_prob": 5.223504194873385e-05}, {"id": 87, "seek": 43224, "start": 451.04, "end": 455.36, "text": " and I don't think it's been settled yet of what's going to be best long term in terms", "tokens": [293, 286, 500, 380, 519, 309, 311, 668, 14819, 1939, 295, 437, 311, 516, 281, 312, 1151, 938, 1433, 294, 2115], "temperature": 0.0, "avg_logprob": -0.11642951965332031, "compression_ratio": 1.5502392344497609, "no_speech_prob": 5.223504194873385e-05}, {"id": 88, "seek": 45536, "start": 455.36, "end": 463.0, "text": " of if you think of attention, RNNs and CNNs as kind of three areas of research and possibility,", "tokens": [295, 498, 291, 519, 295, 3202, 11, 45702, 45, 82, 293, 24859, 82, 382, 733, 295, 1045, 3179, 295, 2132, 293, 7959, 11], "temperature": 0.0, "avg_logprob": -0.25823449306800716, "compression_ratio": 1.457516339869281, "no_speech_prob": 2.3919425075291656e-05}, {"id": 89, "seek": 45536, "start": 463.0, "end": 468.08000000000004, "text": " or even possibilities of are there ways to kind of combine the best aspects of them.", "tokens": [420, 754, 12178, 295, 366, 456, 2098, 281, 733, 295, 10432, 264, 1151, 7270, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.25823449306800716, "compression_ratio": 1.457516339869281, "no_speech_prob": 2.3919425075291656e-05}, {"id": 90, "seek": 45536, "start": 468.08000000000004, "end": 469.08000000000004, "text": " Jeremy?", "tokens": [17809, 30], "temperature": 0.0, "avg_logprob": -0.25823449306800716, "compression_ratio": 1.457516339869281, "no_speech_prob": 2.3919425075291656e-05}, {"id": 91, "seek": 45536, "start": 469.08000000000004, "end": 479.36, "text": " Let me throw the catch box to you.", "tokens": [961, 385, 3507, 264, 3745, 2424, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.25823449306800716, "compression_ratio": 1.457516339869281, "no_speech_prob": 2.3919425075291656e-05}, {"id": 92, "seek": 47936, "start": 479.36, "end": 490.36, "text": " Two days ago, I guess, Google came out with a paper called ExcelNet, which has easily", "tokens": [4453, 1708, 2057, 11, 286, 2041, 11, 3329, 1361, 484, 365, 257, 3035, 1219, 19060, 31890, 11, 597, 575, 3612], "temperature": 0.0, "avg_logprob": -0.17464851471314946, "compression_ratio": 1.5023041474654377, "no_speech_prob": 2.2825539417681284e-05}, {"id": 93, "seek": 47936, "start": 490.36, "end": 496.12, "text": " beaten the state of the art in 18 out of 20 important NLP problems.", "tokens": [17909, 264, 1785, 295, 264, 1523, 294, 2443, 484, 295, 945, 1021, 426, 45196, 2740, 13], "temperature": 0.0, "avg_logprob": -0.17464851471314946, "compression_ratio": 1.5023041474654377, "no_speech_prob": 2.2825539417681284e-05}, {"id": 94, "seek": 47936, "start": 496.12, "end": 499.84000000000003, "text": " And it's interesting because it's based on something called Transformer Excel, which", "tokens": [400, 309, 311, 1880, 570, 309, 311, 2361, 322, 746, 1219, 27938, 260, 19060, 11, 597], "temperature": 0.0, "avg_logprob": -0.17464851471314946, "compression_ratio": 1.5023041474654377, "no_speech_prob": 2.2825539417681284e-05}, {"id": 95, "seek": 47936, "start": 499.84000000000003, "end": 505.92, "text": " combines a lot of the best features of RNNs and Transformers, and also uses some of the", "tokens": [29520, 257, 688, 295, 264, 1151, 4122, 295, 45702, 45, 82, 293, 27938, 433, 11, 293, 611, 4960, 512, 295, 264], "temperature": 0.0, "avg_logprob": -0.17464851471314946, "compression_ratio": 1.5023041474654377, "no_speech_prob": 2.2825539417681284e-05}, {"id": 96, "seek": 50592, "start": 505.92, "end": 512.52, "text": " pre-training concepts from the ULM 5050 line.", "tokens": [659, 12, 17227, 1760, 10392, 490, 264, 624, 43, 44, 2625, 2803, 1622, 13], "temperature": 0.0, "avg_logprob": -0.2812355041503906, "compression_ratio": 1.4794520547945205, "no_speech_prob": 3.590672349673696e-05}, {"id": 97, "seek": 50592, "start": 512.52, "end": 518.52, "text": " So there's some sign that people are combining these things, and I suspect that the direction", "tokens": [407, 456, 311, 512, 1465, 300, 561, 366, 21928, 613, 721, 11, 293, 286, 9091, 300, 264, 3513], "temperature": 0.0, "avg_logprob": -0.2812355041503906, "compression_ratio": 1.4794520547945205, "no_speech_prob": 3.590672349673696e-05}, {"id": 98, "seek": 50592, "start": 518.52, "end": 520.64, "text": " is going to keep going.", "tokens": [307, 516, 281, 1066, 516, 13], "temperature": 0.0, "avg_logprob": -0.2812355041503906, "compression_ratio": 1.4794520547945205, "no_speech_prob": 3.590672349673696e-05}, {"id": 99, "seek": 50592, "start": 520.64, "end": 525.4, "text": " But you've mentioned a few times that this field is changing rapidly.", "tokens": [583, 291, 600, 2835, 257, 1326, 1413, 300, 341, 2519, 307, 4473, 12910, 13], "temperature": 0.0, "avg_logprob": -0.2812355041503906, "compression_ratio": 1.4794520547945205, "no_speech_prob": 3.590672349673696e-05}, {"id": 100, "seek": 50592, "start": 525.4, "end": 528.04, "text": " As of two days ago, it changed rapidly again.", "tokens": [1018, 295, 732, 1708, 2057, 11, 309, 3105, 12910, 797, 13], "temperature": 0.0, "avg_logprob": -0.2812355041503906, "compression_ratio": 1.4794520547945205, "no_speech_prob": 3.590672349673696e-05}, {"id": 101, "seek": 50592, "start": 528.04, "end": 531.04, "text": " And it was quite a substantial breakthrough.", "tokens": [400, 309, 390, 1596, 257, 16726, 22397, 13], "temperature": 0.0, "avg_logprob": -0.2812355041503906, "compression_ratio": 1.4794520547945205, "no_speech_prob": 3.590672349673696e-05}, {"id": 102, "seek": 53104, "start": 531.04, "end": 536.12, "text": " So knowing something about RNNs and something about attention seems to be important.", "tokens": [407, 5276, 746, 466, 45702, 45, 82, 293, 746, 466, 3202, 2544, 281, 312, 1021, 13], "temperature": 0.0, "avg_logprob": -0.3119834065437317, "compression_ratio": 1.5691489361702127, "no_speech_prob": 2.177983333240263e-05}, {"id": 103, "seek": 53104, "start": 536.12, "end": 537.12, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3119834065437317, "compression_ratio": 1.5691489361702127, "no_speech_prob": 2.177983333240263e-05}, {"id": 104, "seek": 53104, "start": 537.12, "end": 540.76, "text": " And I would say CNNs as well.", "tokens": [400, 286, 576, 584, 24859, 82, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.3119834065437317, "compression_ratio": 1.5691489361702127, "no_speech_prob": 2.177983333240263e-05}, {"id": 105, "seek": 53104, "start": 540.76, "end": 547.0799999999999, "text": " Yeah, thank you, Jeremy.", "tokens": [865, 11, 1309, 291, 11, 17809, 13], "temperature": 0.0, "avg_logprob": -0.3119834065437317, "compression_ratio": 1.5691489361702127, "no_speech_prob": 2.177983333240263e-05}, {"id": 106, "seek": 53104, "start": 547.0799999999999, "end": 548.0799999999999, "text": " That's a great example.", "tokens": [663, 311, 257, 869, 1365, 13], "temperature": 0.0, "avg_logprob": -0.3119834065437317, "compression_ratio": 1.5691489361702127, "no_speech_prob": 2.177983333240263e-05}, {"id": 107, "seek": 53104, "start": 548.0799999999999, "end": 552.76, "text": " Oh, it's the letter X, the letter L, net, all the way.", "tokens": [876, 11, 309, 311, 264, 5063, 1783, 11, 264, 5063, 441, 11, 2533, 11, 439, 264, 636, 13], "temperature": 0.0, "avg_logprob": -0.3119834065437317, "compression_ratio": 1.5691489361702127, "no_speech_prob": 2.177983333240263e-05}, {"id": 108, "seek": 53104, "start": 552.76, "end": 553.76, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.3119834065437317, "compression_ratio": 1.5691489361702127, "no_speech_prob": 2.177983333240263e-05}, {"id": 109, "seek": 53104, "start": 553.76, "end": 557.24, "text": " And Jeremy's saying for the spelling, it's letter X, letter L, net.", "tokens": [400, 17809, 311, 1566, 337, 264, 22254, 11, 309, 311, 5063, 1783, 11, 5063, 441, 11, 2533, 13], "temperature": 0.0, "avg_logprob": -0.3119834065437317, "compression_ratio": 1.5691489361702127, "no_speech_prob": 2.177983333240263e-05}, {"id": 110, "seek": 55724, "start": 557.24, "end": 569.48, "text": " Actually, I can even enter that.", "tokens": [5135, 11, 286, 393, 754, 3242, 300, 13], "temperature": 0.0, "avg_logprob": -0.2685596096900202, "compression_ratio": 1.297872340425532, "no_speech_prob": 7.76618344389135e-06}, {"id": 111, "seek": 55724, "start": 569.48, "end": 570.48, "text": " Second one.", "tokens": [5736, 472, 13], "temperature": 0.0, "avg_logprob": -0.2685596096900202, "compression_ratio": 1.297872340425532, "no_speech_prob": 7.76618344389135e-06}, {"id": 112, "seek": 55724, "start": 570.48, "end": 573.48, "text": " Oh, no, that's a medium post.", "tokens": [876, 11, 572, 11, 300, 311, 257, 6399, 2183, 13], "temperature": 0.0, "avg_logprob": -0.2685596096900202, "compression_ratio": 1.297872340425532, "no_speech_prob": 7.76618344389135e-06}, {"id": 113, "seek": 55724, "start": 573.48, "end": 574.48, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.2685596096900202, "compression_ratio": 1.297872340425532, "no_speech_prob": 7.76618344389135e-06}, {"id": 114, "seek": 55724, "start": 574.48, "end": 580.36, "text": " Well, I think this gets you to the name.", "tokens": [1042, 11, 286, 519, 341, 2170, 291, 281, 264, 1315, 13], "temperature": 0.0, "avg_logprob": -0.2685596096900202, "compression_ratio": 1.297872340425532, "no_speech_prob": 7.76618344389135e-06}, {"id": 115, "seek": 55724, "start": 580.36, "end": 585.8, "text": " And you can see all these results are within the last 18 hours.", "tokens": [400, 291, 393, 536, 439, 613, 3542, 366, 1951, 264, 1036, 2443, 2496, 13], "temperature": 0.0, "avg_logprob": -0.2685596096900202, "compression_ratio": 1.297872340425532, "no_speech_prob": 7.76618344389135e-06}, {"id": 116, "seek": 58580, "start": 585.8, "end": 588.4799999999999, "text": " So this seems to be pretty recent.", "tokens": [407, 341, 2544, 281, 312, 1238, 5162, 13], "temperature": 0.0, "avg_logprob": -0.17575108437311082, "compression_ratio": 1.5265700483091786, "no_speech_prob": 3.07088193949312e-05}, {"id": 117, "seek": 58580, "start": 588.4799999999999, "end": 595.68, "text": " That means our course is 18 hours out of date.", "tokens": [663, 1355, 527, 1164, 307, 2443, 2496, 484, 295, 4002, 13], "temperature": 0.0, "avg_logprob": -0.17575108437311082, "compression_ratio": 1.5265700483091786, "no_speech_prob": 3.07088193949312e-05}, {"id": 118, "seek": 58580, "start": 595.68, "end": 598.7199999999999, "text": " And this is, I guess I should say, for the video, June 2019.", "tokens": [400, 341, 307, 11, 286, 2041, 286, 820, 584, 11, 337, 264, 960, 11, 6928, 6071, 13], "temperature": 0.0, "avg_logprob": -0.17575108437311082, "compression_ratio": 1.5265700483091786, "no_speech_prob": 3.07088193949312e-05}, {"id": 119, "seek": 58580, "start": 598.7199999999999, "end": 607.76, "text": " So depending on when you're watching it, it could be more than 18 hours out of date.", "tokens": [407, 5413, 322, 562, 291, 434, 1976, 309, 11, 309, 727, 312, 544, 813, 2443, 2496, 484, 295, 4002, 13], "temperature": 0.0, "avg_logprob": -0.17575108437311082, "compression_ratio": 1.5265700483091786, "no_speech_prob": 3.07088193949312e-05}, {"id": 120, "seek": 58580, "start": 607.76, "end": 612.76, "text": " And so the motivation they give in the paper is that the inherently sequential nature of", "tokens": [400, 370, 264, 12335, 436, 976, 294, 264, 3035, 307, 300, 264, 27993, 42881, 3687, 295], "temperature": 0.0, "avg_logprob": -0.17575108437311082, "compression_ratio": 1.5265700483091786, "no_speech_prob": 3.07088193949312e-05}, {"id": 121, "seek": 61276, "start": 612.76, "end": 618.68, "text": " RNNs precludes parallelization within training examples, which becomes critical at longer", "tokens": [45702, 45, 82, 4346, 1471, 279, 8952, 2144, 1951, 3097, 5110, 11, 597, 3643, 4924, 412, 2854], "temperature": 0.0, "avg_logprob": -0.17246505737304688, "compression_ratio": 1.5, "no_speech_prob": 1.0129064321517944e-05}, {"id": 122, "seek": 61276, "start": 618.68, "end": 625.48, "text": " sequence lengths as memory constraints limit batching across examples.", "tokens": [8310, 26329, 382, 4675, 18491, 4948, 15245, 278, 2108, 5110, 13], "temperature": 0.0, "avg_logprob": -0.17246505737304688, "compression_ratio": 1.5, "no_speech_prob": 1.0129064321517944e-05}, {"id": 123, "seek": 61276, "start": 625.48, "end": 632.08, "text": " Although this is somewhat contestable because new research is coming out using RNNs.", "tokens": [5780, 341, 307, 8344, 10287, 712, 570, 777, 2132, 307, 1348, 484, 1228, 45702, 45, 82, 13], "temperature": 0.0, "avg_logprob": -0.17246505737304688, "compression_ratio": 1.5, "no_speech_prob": 1.0129064321517944e-05}, {"id": 124, "seek": 61276, "start": 632.08, "end": 641.28, "text": " There is another, I guess I'll mention it now, paper from earlier this year, I guess", "tokens": [821, 307, 1071, 11, 286, 2041, 286, 603, 2152, 309, 586, 11, 3035, 490, 3071, 341, 1064, 11, 286, 2041], "temperature": 0.0, "avg_logprob": -0.17246505737304688, "compression_ratio": 1.5, "no_speech_prob": 1.0129064321517944e-05}, {"id": 125, "seek": 64128, "start": 641.28, "end": 645.12, "text": " February, Pay Less Attention with Lightweight and Dynamic Convolutions.", "tokens": [8711, 11, 11431, 18649, 31858, 365, 8279, 12329, 293, 45440, 2656, 85, 15892, 13], "temperature": 0.0, "avg_logprob": -0.12187777927943638, "compression_ratio": 1.5458937198067633, "no_speech_prob": 6.745885457348777e-06}, {"id": 126, "seek": 64128, "start": 645.12, "end": 653.36, "text": " So this is recent research getting better results with convolutions and with attention.", "tokens": [407, 341, 307, 5162, 2132, 1242, 1101, 3542, 365, 3754, 15892, 293, 365, 3202, 13], "temperature": 0.0, "avg_logprob": -0.12187777927943638, "compression_ratio": 1.5458937198067633, "no_speech_prob": 6.745885457348777e-06}, {"id": 127, "seek": 64128, "start": 653.36, "end": 661.92, "text": " So a lot to still kind of be studied and determined here.", "tokens": [407, 257, 688, 281, 920, 733, 295, 312, 9454, 293, 9540, 510, 13], "temperature": 0.0, "avg_logprob": -0.12187777927943638, "compression_ratio": 1.5458937198067633, "no_speech_prob": 6.745885457348777e-06}, {"id": 128, "seek": 64128, "start": 661.92, "end": 669.86, "text": " And so this figure is from the original Attention is All You Need paper showing the model architecture", "tokens": [400, 370, 341, 2573, 307, 490, 264, 3380, 31858, 307, 1057, 509, 16984, 3035, 4099, 264, 2316, 9482], "temperature": 0.0, "avg_logprob": -0.12187777927943638, "compression_ratio": 1.5458937198067633, "no_speech_prob": 6.745885457348777e-06}, {"id": 129, "seek": 66986, "start": 669.86, "end": 671.24, "text": " of the transformer.", "tokens": [295, 264, 31782, 13], "temperature": 0.0, "avg_logprob": -0.11657165994449538, "compression_ratio": 1.6771300448430493, "no_speech_prob": 2.586185837571975e-05}, {"id": 130, "seek": 66986, "start": 671.24, "end": 673.6, "text": " A few things to notice about it.", "tokens": [316, 1326, 721, 281, 3449, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.11657165994449538, "compression_ratio": 1.6771300448430493, "no_speech_prob": 2.586185837571975e-05}, {"id": 131, "seek": 66986, "start": 673.6, "end": 677.16, "text": " So some of this should look familiar to you.", "tokens": [407, 512, 295, 341, 820, 574, 4963, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.11657165994449538, "compression_ratio": 1.6771300448430493, "no_speech_prob": 2.586185837571975e-05}, {"id": 132, "seek": 66986, "start": 677.16, "end": 683.0, "text": " We'll still have an input embedding, something called a positional encoding, which we'll", "tokens": [492, 603, 920, 362, 364, 4846, 12240, 3584, 11, 746, 1219, 257, 2535, 304, 43430, 11, 597, 321, 603], "temperature": 0.0, "avg_logprob": -0.11657165994449538, "compression_ratio": 1.6771300448430493, "no_speech_prob": 2.586185837571975e-05}, {"id": 133, "seek": 66986, "start": 683.0, "end": 686.4, "text": " learn about next week.", "tokens": [1466, 466, 958, 1243, 13], "temperature": 0.0, "avg_logprob": -0.11657165994449538, "compression_ratio": 1.6771300448430493, "no_speech_prob": 2.586185837571975e-05}, {"id": 134, "seek": 66986, "start": 686.4, "end": 690.8000000000001, "text": " And then attention is used at three different places in the network.", "tokens": [400, 550, 3202, 307, 1143, 412, 1045, 819, 3190, 294, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.11657165994449538, "compression_ratio": 1.6771300448430493, "no_speech_prob": 2.586185837571975e-05}, {"id": 135, "seek": 66986, "start": 690.8000000000001, "end": 697.44, "text": " There's basically self-attention for the encoder, self-attention for the decoder, and attention", "tokens": [821, 311, 1936, 2698, 12, 1591, 1251, 337, 264, 2058, 19866, 11, 2698, 12, 1591, 1251, 337, 264, 979, 19866, 11, 293, 3202], "temperature": 0.0, "avg_logprob": -0.11657165994449538, "compression_ratio": 1.6771300448430493, "no_speech_prob": 2.586185837571975e-05}, {"id": 136, "seek": 69744, "start": 697.44, "end": 700.1600000000001, "text": " kind of going between the encoder and decoder.", "tokens": [733, 295, 516, 1296, 264, 2058, 19866, 293, 979, 19866, 13], "temperature": 0.0, "avg_logprob": -0.19530857310575597, "compression_ratio": 1.7991266375545851, "no_speech_prob": 1.5688681742176414e-05}, {"id": 137, "seek": 69744, "start": 700.1600000000001, "end": 706.12, "text": " There are also feedforward, just so layers of kind of standard fully connected neural", "tokens": [821, 366, 611, 3154, 13305, 11, 445, 370, 7914, 295, 733, 295, 3832, 4498, 4582, 18161], "temperature": 0.0, "avg_logprob": -0.19530857310575597, "compression_ratio": 1.7991266375545851, "no_speech_prob": 1.5688681742176414e-05}, {"id": 138, "seek": 69744, "start": 706.12, "end": 711.1600000000001, "text": " network, which you then add and take the norm.", "tokens": [3209, 11, 597, 291, 550, 909, 293, 747, 264, 2026, 13], "temperature": 0.0, "avg_logprob": -0.19530857310575597, "compression_ratio": 1.7991266375545851, "no_speech_prob": 1.5688681742176414e-05}, {"id": 139, "seek": 69744, "start": 711.1600000000001, "end": 716.7600000000001, "text": " Over here on the decoder side, you also can have some feedforward layers of fully connected", "tokens": [4886, 510, 322, 264, 979, 19866, 1252, 11, 291, 611, 393, 362, 512, 3154, 13305, 7914, 295, 4498, 4582], "temperature": 0.0, "avg_logprob": -0.19530857310575597, "compression_ratio": 1.7991266375545851, "no_speech_prob": 1.5688681742176414e-05}, {"id": 140, "seek": 69744, "start": 716.7600000000001, "end": 720.24, "text": " neural networks, adding and taking the norm.", "tokens": [18161, 9590, 11, 5127, 293, 1940, 264, 2026, 13], "temperature": 0.0, "avg_logprob": -0.19530857310575597, "compression_ratio": 1.7991266375545851, "no_speech_prob": 1.5688681742176414e-05}, {"id": 141, "seek": 69744, "start": 720.24, "end": 726.32, "text": " And so this is kind of high level, the architecture we are running out of time today, but we'll", "tokens": [400, 370, 341, 307, 733, 295, 1090, 1496, 11, 264, 9482, 321, 366, 2614, 484, 295, 565, 965, 11, 457, 321, 603], "temperature": 0.0, "avg_logprob": -0.19530857310575597, "compression_ratio": 1.7991266375545851, "no_speech_prob": 1.5688681742176414e-05}, {"id": 142, "seek": 72632, "start": 726.32, "end": 733.1600000000001, "text": " next time get into kind of what's going on with the kind of what is attention, what is", "tokens": [958, 565, 483, 666, 733, 295, 437, 311, 516, 322, 365, 264, 733, 295, 437, 307, 3202, 11, 437, 307], "temperature": 0.0, "avg_logprob": -0.1650371551513672, "compression_ratio": 1.6349206349206349, "no_speech_prob": 2.668639353942126e-05}, {"id": 143, "seek": 72632, "start": 733.1600000000001, "end": 737.72, "text": " positional encoding, what are these pieces being put together.", "tokens": [2535, 304, 43430, 11, 437, 366, 613, 3755, 885, 829, 1214, 13], "temperature": 0.0, "avg_logprob": -0.1650371551513672, "compression_ratio": 1.6349206349206349, "no_speech_prob": 2.668639353942126e-05}, {"id": 144, "seek": 72632, "start": 737.72, "end": 742.1600000000001, "text": " And then also you'll note over to the side, it says capital NX.", "tokens": [400, 550, 611, 291, 603, 3637, 670, 281, 264, 1252, 11, 309, 1619, 4238, 426, 55, 13], "temperature": 0.0, "avg_logprob": -0.1650371551513672, "compression_ratio": 1.6349206349206349, "no_speech_prob": 2.668639353942126e-05}, {"id": 145, "seek": 72632, "start": 742.1600000000001, "end": 746.08, "text": " Here N is six in the original Attention paper.", "tokens": [1692, 426, 307, 2309, 294, 264, 3380, 31858, 3035, 13], "temperature": 0.0, "avg_logprob": -0.1650371551513672, "compression_ratio": 1.6349206349206349, "no_speech_prob": 2.668639353942126e-05}, {"id": 146, "seek": 72632, "start": 746.08, "end": 751.6, "text": " And so you kind of have six of these stacked up.", "tokens": [400, 370, 291, 733, 295, 362, 2309, 295, 613, 28867, 493, 13], "temperature": 0.0, "avg_logprob": -0.1650371551513672, "compression_ratio": 1.6349206349206349, "no_speech_prob": 2.668639353942126e-05}, {"id": 147, "seek": 75160, "start": 751.6, "end": 761.96, "text": " So the kind of basic operation of attention is to have, so here Q stands for query, K", "tokens": [407, 264, 733, 295, 3875, 6916, 295, 3202, 307, 281, 362, 11, 370, 510, 1249, 7382, 337, 14581, 11, 591], "temperature": 0.0, "avg_logprob": -0.11751992885883038, "compression_ratio": 1.660919540229885, "no_speech_prob": 1.2606505151779857e-05}, {"id": 148, "seek": 75160, "start": 761.96, "end": 765.6, "text": " is for key, and V is for value.", "tokens": [307, 337, 2141, 11, 293, 691, 307, 337, 2158, 13], "temperature": 0.0, "avg_logprob": -0.11751992885883038, "compression_ratio": 1.660919540229885, "no_speech_prob": 1.2606505151779857e-05}, {"id": 149, "seek": 75160, "start": 765.6, "end": 771.5600000000001, "text": " And basically the idea is that the query is kind of what you're getting.", "tokens": [400, 1936, 264, 1558, 307, 300, 264, 14581, 307, 733, 295, 437, 291, 434, 1242, 13], "temperature": 0.0, "avg_logprob": -0.11751992885883038, "compression_ratio": 1.660919540229885, "no_speech_prob": 1.2606505151779857e-05}, {"id": 150, "seek": 75160, "start": 771.5600000000001, "end": 778.64, "text": " So for two sentences, which could be, so sequence to sequence, the idea is you have two sequences.", "tokens": [407, 337, 732, 16579, 11, 597, 727, 312, 11, 370, 8310, 281, 8310, 11, 264, 1558, 307, 291, 362, 732, 22978, 13], "temperature": 0.0, "avg_logprob": -0.11751992885883038, "compression_ratio": 1.660919540229885, "no_speech_prob": 1.2606505151779857e-05}, {"id": 151, "seek": 77864, "start": 778.64, "end": 783.52, "text": " In our case, we were going from, can't remember, I think French to English.", "tokens": [682, 527, 1389, 11, 321, 645, 516, 490, 11, 393, 380, 1604, 11, 286, 519, 5522, 281, 3669, 13], "temperature": 0.0, "avg_logprob": -0.12223450999614621, "compression_ratio": 1.6953125, "no_speech_prob": 9.080229574465193e-06}, {"id": 152, "seek": 77864, "start": 783.52, "end": 789.88, "text": " You have kind of your French word, which could be, is kind of represented by the query, and", "tokens": [509, 362, 733, 295, 428, 5522, 1349, 11, 597, 727, 312, 11, 307, 733, 295, 10379, 538, 264, 14581, 11, 293], "temperature": 0.0, "avg_logprob": -0.12223450999614621, "compression_ratio": 1.6953125, "no_speech_prob": 9.080229574465193e-06}, {"id": 153, "seek": 77864, "start": 789.88, "end": 791.58, "text": " we'll see how in a moment.", "tokens": [321, 603, 536, 577, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.12223450999614621, "compression_ratio": 1.6953125, "no_speech_prob": 9.080229574465193e-06}, {"id": 154, "seek": 77864, "start": 791.58, "end": 795.3199999999999, "text": " And then you want to compare that to kind of each word in your output of how much do", "tokens": [400, 550, 291, 528, 281, 6794, 300, 281, 733, 295, 1184, 1349, 294, 428, 5598, 295, 577, 709, 360], "temperature": 0.0, "avg_logprob": -0.12223450999614621, "compression_ratio": 1.6953125, "no_speech_prob": 9.080229574465193e-06}, {"id": 155, "seek": 77864, "start": 795.3199999999999, "end": 797.3199999999999, "text": " you need to focus on those.", "tokens": [291, 643, 281, 1879, 322, 729, 13], "temperature": 0.0, "avg_logprob": -0.12223450999614621, "compression_ratio": 1.6953125, "no_speech_prob": 9.080229574465193e-06}, {"id": 156, "seek": 77864, "start": 797.3199999999999, "end": 800.6, "text": " That'll be the key you're looking up.", "tokens": [663, 603, 312, 264, 2141, 291, 434, 1237, 493, 13], "temperature": 0.0, "avg_logprob": -0.12223450999614621, "compression_ratio": 1.6953125, "no_speech_prob": 9.080229574465193e-06}, {"id": 157, "seek": 77864, "start": 800.6, "end": 806.08, "text": " And you'll use those, kind of want to combine those in a way that gives you a score that", "tokens": [400, 291, 603, 764, 729, 11, 733, 295, 528, 281, 10432, 729, 294, 257, 636, 300, 2709, 291, 257, 6175, 300], "temperature": 0.0, "avg_logprob": -0.12223450999614621, "compression_ratio": 1.6953125, "no_speech_prob": 9.080229574465193e-06}, {"id": 158, "seek": 80608, "start": 806.08, "end": 810.1, "text": " you multiply then with your output.", "tokens": [291, 12972, 550, 365, 428, 5598, 13], "temperature": 0.0, "avg_logprob": -0.11760224852451058, "compression_ratio": 1.565, "no_speech_prob": 1.5935789633658715e-05}, {"id": 159, "seek": 80608, "start": 810.1, "end": 820.0400000000001, "text": " And so we'll see this more closely, but it's kind of having a key representing kind of", "tokens": [400, 370, 321, 603, 536, 341, 544, 8185, 11, 457, 309, 311, 733, 295, 1419, 257, 2141, 13460, 733, 295], "temperature": 0.0, "avg_logprob": -0.11760224852451058, "compression_ratio": 1.565, "no_speech_prob": 1.5935789633658715e-05}, {"id": 160, "seek": 80608, "start": 820.0400000000001, "end": 821.0400000000001, "text": " word one.", "tokens": [1349, 472, 13], "temperature": 0.0, "avg_logprob": -0.11760224852451058, "compression_ratio": 1.565, "no_speech_prob": 1.5935789633658715e-05}, {"id": 161, "seek": 80608, "start": 821.0400000000001, "end": 825.36, "text": " You want to be able to compare that to other words as keys.", "tokens": [509, 528, 281, 312, 1075, 281, 6794, 300, 281, 661, 2283, 382, 9317, 13], "temperature": 0.0, "avg_logprob": -0.11760224852451058, "compression_ratio": 1.565, "no_speech_prob": 1.5935789633658715e-05}, {"id": 162, "seek": 80608, "start": 825.36, "end": 830.82, "text": " And then you'll get a score, and then basically use those scores to take a weighted average,", "tokens": [400, 550, 291, 603, 483, 257, 6175, 11, 293, 550, 1936, 764, 729, 13444, 281, 747, 257, 32807, 4274, 11], "temperature": 0.0, "avg_logprob": -0.11760224852451058, "compression_ratio": 1.565, "no_speech_prob": 1.5935789633658715e-05}, {"id": 163, "seek": 80608, "start": 830.82, "end": 834.84, "text": " I guess, of all the values.", "tokens": [286, 2041, 11, 295, 439, 264, 4190, 13], "temperature": 0.0, "avg_logprob": -0.11760224852451058, "compression_ratio": 1.565, "no_speech_prob": 1.5935789633658715e-05}, {"id": 164, "seek": 83484, "start": 834.84, "end": 836.76, "text": " And we'll see this a little bit better.", "tokens": [400, 321, 603, 536, 341, 257, 707, 857, 1101, 13], "temperature": 0.0, "avg_logprob": -0.2999741690499442, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.4265733120264485e-05}, {"id": 165, "seek": 83484, "start": 836.76, "end": 842.32, "text": " So Jay Alomar has an excellent blog post called The Illustrated Transformer.", "tokens": [407, 11146, 967, 298, 289, 575, 364, 7103, 6968, 2183, 1219, 440, 37788, 5468, 27938, 260, 13], "temperature": 0.0, "avg_logprob": -0.2999741690499442, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.4265733120264485e-05}, {"id": 166, "seek": 83484, "start": 842.32, "end": 848.52, "text": " Actually, let me ask, Jeremy, do you want to explain the query key and value high level,", "tokens": [5135, 11, 718, 385, 1029, 11, 17809, 11, 360, 291, 528, 281, 2903, 264, 14581, 2141, 293, 2158, 1090, 1496, 11], "temperature": 0.0, "avg_logprob": -0.2999741690499442, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.4265733120264485e-05}, {"id": 167, "seek": 83484, "start": 848.52, "end": 851.5600000000001, "text": " how you see the meaning of those?", "tokens": [577, 291, 536, 264, 3620, 295, 729, 30], "temperature": 0.0, "avg_logprob": -0.2999741690499442, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.4265733120264485e-05}, {"id": 168, "seek": 83484, "start": 851.5600000000001, "end": 852.5600000000001, "text": " Or what?", "tokens": [1610, 437, 30], "temperature": 0.0, "avg_logprob": -0.2999741690499442, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.4265733120264485e-05}, {"id": 169, "seek": 83484, "start": 852.5600000000001, "end": 857.12, "text": " How long do we have?", "tokens": [1012, 938, 360, 321, 362, 30], "temperature": 0.0, "avg_logprob": -0.2999741690499442, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.4265733120264485e-05}, {"id": 170, "seek": 83484, "start": 857.12, "end": 858.9200000000001, "text": " We only have seven minutes.", "tokens": [492, 787, 362, 3407, 2077, 13], "temperature": 0.0, "avg_logprob": -0.2999741690499442, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.4265733120264485e-05}, {"id": 171, "seek": 83484, "start": 858.9200000000001, "end": 863.96, "text": " Can I go back a little bit further?", "tokens": [1664, 286, 352, 646, 257, 707, 857, 3052, 30], "temperature": 0.0, "avg_logprob": -0.2999741690499442, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.4265733120264485e-05}, {"id": 172, "seek": 86396, "start": 863.96, "end": 872.6800000000001, "text": " I actually found it useful to start back here and think about what happens if you get rid", "tokens": [286, 767, 1352, 309, 4420, 281, 722, 646, 510, 293, 519, 466, 437, 2314, 498, 291, 483, 3973], "temperature": 0.0, "avg_logprob": -0.09636679361032885, "compression_ratio": 1.5255813953488373, "no_speech_prob": 1.8630482372827828e-05}, {"id": 173, "seek": 86396, "start": 872.6800000000001, "end": 876.96, "text": " of the orange boxes and just have the blue boxes.", "tokens": [295, 264, 7671, 9002, 293, 445, 362, 264, 3344, 9002, 13], "temperature": 0.0, "avg_logprob": -0.09636679361032885, "compression_ratio": 1.5255813953488373, "no_speech_prob": 1.8630482372827828e-05}, {"id": 174, "seek": 86396, "start": 876.96, "end": 882.6, "text": " This NX means you repeat this a bunch of times, and they repeat it six times.", "tokens": [639, 426, 55, 1355, 291, 7149, 341, 257, 3840, 295, 1413, 11, 293, 436, 7149, 309, 2309, 1413, 13], "temperature": 0.0, "avg_logprob": -0.09636679361032885, "compression_ratio": 1.5255813953488373, "no_speech_prob": 1.8630482372827828e-05}, {"id": 175, "seek": 86396, "start": 882.6, "end": 884.38, "text": " So there's six layers.", "tokens": [407, 456, 311, 2309, 7914, 13], "temperature": 0.0, "avg_logprob": -0.09636679361032885, "compression_ratio": 1.5255813953488373, "no_speech_prob": 1.8630482372827828e-05}, {"id": 176, "seek": 86396, "start": 884.38, "end": 893.6800000000001, "text": " So this feedforward thing is just a normal, fully connected neural network with a ReLU.", "tokens": [407, 341, 3154, 13305, 551, 307, 445, 257, 2710, 11, 4498, 4582, 18161, 3209, 365, 257, 1300, 43, 52, 13], "temperature": 0.0, "avg_logprob": -0.09636679361032885, "compression_ratio": 1.5255813953488373, "no_speech_prob": 1.8630482372827828e-05}, {"id": 177, "seek": 89368, "start": 893.68, "end": 902.8399999999999, "text": " So if you remove this add a norm thing, then it's just a six layer neural net here.", "tokens": [407, 498, 291, 4159, 341, 909, 257, 2026, 551, 11, 550, 309, 311, 445, 257, 2309, 4583, 18161, 2533, 510, 13], "temperature": 0.0, "avg_logprob": -0.18523090268358772, "compression_ratio": 1.6432748538011697, "no_speech_prob": 4.710827852250077e-06}, {"id": 178, "seek": 89368, "start": 902.8399999999999, "end": 911.04, "text": " And then this is a standard like sec to sec thing of going from an encoder to a decoder.", "tokens": [400, 550, 341, 307, 257, 3832, 411, 907, 281, 907, 551, 295, 516, 490, 364, 2058, 19866, 281, 257, 979, 19866, 13], "temperature": 0.0, "avg_logprob": -0.18523090268358772, "compression_ratio": 1.6432748538011697, "no_speech_prob": 4.710827852250077e-06}, {"id": 179, "seek": 89368, "start": 911.04, "end": 915.7199999999999, "text": " And so then again, if you get rid of ignore the attention, you've got N, that's also a", "tokens": [400, 370, 550, 797, 11, 498, 291, 483, 3973, 295, 11200, 264, 3202, 11, 291, 600, 658, 426, 11, 300, 311, 611, 257], "temperature": 0.0, "avg_logprob": -0.18523090268358772, "compression_ratio": 1.6432748538011697, "no_speech_prob": 4.710827852250077e-06}, {"id": 180, "seek": 89368, "start": 915.7199999999999, "end": 917.04, "text": " six layer neural net.", "tokens": [2309, 4583, 18161, 2533, 13], "temperature": 0.0, "avg_logprob": -0.18523090268358772, "compression_ratio": 1.6432748538011697, "no_speech_prob": 4.710827852250077e-06}, {"id": 181, "seek": 91704, "start": 917.04, "end": 925.8399999999999, "text": " So it really is, it's got a normal neural network in it.", "tokens": [407, 309, 534, 307, 11, 309, 311, 658, 257, 2710, 18161, 3209, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.11257079710443336, "compression_ratio": 1.5888324873096447, "no_speech_prob": 4.710775556304725e-06}, {"id": 182, "seek": 91704, "start": 925.8399999999999, "end": 931.28, "text": " But the neural networks only operate on one word at a time.", "tokens": [583, 264, 18161, 9590, 787, 9651, 322, 472, 1349, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.11257079710443336, "compression_ratio": 1.5888324873096447, "no_speech_prob": 4.710775556304725e-06}, {"id": 183, "seek": 91704, "start": 931.28, "end": 934.4, "text": " So they don't combine across words.", "tokens": [407, 436, 500, 380, 10432, 2108, 2283, 13], "temperature": 0.0, "avg_logprob": -0.11257079710443336, "compression_ratio": 1.5888324873096447, "no_speech_prob": 4.710775556304725e-06}, {"id": 184, "seek": 91704, "start": 934.4, "end": 940.24, "text": " So like if that's all that happened, it wouldn't be able to do very much.", "tokens": [407, 411, 498, 300, 311, 439, 300, 2011, 11, 309, 2759, 380, 312, 1075, 281, 360, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.11257079710443336, "compression_ratio": 1.5888324873096447, "no_speech_prob": 4.710775556304725e-06}, {"id": 185, "seek": 91704, "start": 940.24, "end": 944.88, "text": " So like the first kind of insight for me in understanding this was realizing like this", "tokens": [407, 411, 264, 700, 733, 295, 11269, 337, 385, 294, 3701, 341, 390, 16734, 411, 341], "temperature": 0.0, "avg_logprob": -0.11257079710443336, "compression_ratio": 1.5888324873096447, "no_speech_prob": 4.710775556304725e-06}, {"id": 186, "seek": 94488, "start": 944.88, "end": 951.02, "text": " orange thing is all about what the neural network gets fed.", "tokens": [7671, 551, 307, 439, 466, 437, 264, 18161, 3209, 2170, 4636, 13], "temperature": 0.0, "avg_logprob": -0.09022090435028077, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.696297840680927e-05}, {"id": 187, "seek": 94488, "start": 951.02, "end": 958.26, "text": " And rather than just being fed a word, it's fed a weighted combination of words.", "tokens": [400, 2831, 813, 445, 885, 4636, 257, 1349, 11, 309, 311, 4636, 257, 32807, 6562, 295, 2283, 13], "temperature": 0.0, "avg_logprob": -0.09022090435028077, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.696297840680927e-05}, {"id": 188, "seek": 94488, "start": 958.26, "end": 965.64, "text": " So how does it create that weighted combination with this softmax?", "tokens": [407, 577, 775, 309, 1884, 300, 32807, 6562, 365, 341, 2787, 41167, 30], "temperature": 0.0, "avg_logprob": -0.09022090435028077, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.696297840680927e-05}, {"id": 189, "seek": 94488, "start": 965.64, "end": 967.78, "text": " So the softmax adds up to one.", "tokens": [407, 264, 2787, 41167, 10860, 493, 281, 472, 13], "temperature": 0.0, "avg_logprob": -0.09022090435028077, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.696297840680927e-05}, {"id": 190, "seek": 94488, "start": 967.78, "end": 972.96, "text": " So this gives you the amount of each word that you're going to include.", "tokens": [407, 341, 2709, 291, 264, 2372, 295, 1184, 1349, 300, 291, 434, 516, 281, 4090, 13], "temperature": 0.0, "avg_logprob": -0.09022090435028077, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.696297840680927e-05}, {"id": 191, "seek": 97296, "start": 972.96, "end": 978.0400000000001, "text": " So when you're looking at word one, which of the other words are relevant?", "tokens": [407, 562, 291, 434, 1237, 412, 1349, 472, 11, 597, 295, 264, 661, 2283, 366, 7340, 30], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 192, "seek": 97296, "start": 978.0400000000001, "end": 979.0400000000001, "text": " Question?", "tokens": [14464, 30], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 193, "seek": 97296, "start": 979.0400000000001, "end": 980.0400000000001, "text": " What if there's more decay?", "tokens": [708, 498, 456, 311, 544, 21039, 30], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 194, "seek": 97296, "start": 980.0400000000001, "end": 983.0400000000001, "text": " Why we need to divide them?", "tokens": [1545, 321, 643, 281, 9845, 552, 30], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 195, "seek": 97296, "start": 983.0400000000001, "end": 984.0400000000001, "text": " We'll get to that.", "tokens": [492, 603, 483, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 196, "seek": 97296, "start": 984.0400000000001, "end": 986.6800000000001, "text": " Yeah, we'll get to the details of that.", "tokens": [865, 11, 321, 603, 483, 281, 264, 4365, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 197, "seek": 97296, "start": 986.6800000000001, "end": 991.4000000000001, "text": " It's a normalization.", "tokens": [467, 311, 257, 2710, 2144, 13], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 198, "seek": 97296, "start": 991.4000000000001, "end": 995.52, "text": " But the key thing is just this idea that this is creating numbers that are going to add", "tokens": [583, 264, 2141, 551, 307, 445, 341, 1558, 300, 341, 307, 4084, 3547, 300, 366, 516, 281, 909], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 199, "seek": 97296, "start": 995.52, "end": 996.5600000000001, "text": " up to one.", "tokens": [493, 281, 472, 13], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 200, "seek": 97296, "start": 996.5600000000001, "end": 1002.4000000000001, "text": " And so therefore when we're saying like how do I translate word one or what other words", "tokens": [400, 370, 4412, 562, 321, 434, 1566, 411, 577, 360, 286, 13799, 1349, 472, 420, 437, 661, 2283], "temperature": 0.0, "avg_logprob": -0.2235409849781101, "compression_ratio": 1.6585365853658536, "no_speech_prob": 7.527799425588455e-06}, {"id": 201, "seek": 100240, "start": 1002.4, "end": 1004.9599999999999, "text": " are relevant, that's the attention part.", "tokens": [366, 7340, 11, 300, 311, 264, 3202, 644, 13], "temperature": 0.0, "avg_logprob": -0.25132353933233964, "compression_ratio": 1.6018518518518519, "no_speech_prob": 3.726602471942897e-06}, {"id": 202, "seek": 100240, "start": 1004.9599999999999, "end": 1009.68, "text": " Those weights are going to add to one because we've got softmax of something.", "tokens": [3950, 17443, 366, 516, 281, 909, 281, 472, 570, 321, 600, 658, 2787, 41167, 295, 746, 13], "temperature": 0.0, "avg_logprob": -0.25132353933233964, "compression_ratio": 1.6018518518518519, "no_speech_prob": 3.726602471942897e-06}, {"id": 203, "seek": 100240, "start": 1009.68, "end": 1017.52, "text": " And so then the something is what Rachel was asking about, which is the something is.", "tokens": [400, 370, 550, 264, 746, 307, 437, 14246, 390, 3365, 466, 11, 597, 307, 264, 746, 307, 13], "temperature": 0.0, "avg_logprob": -0.25132353933233964, "compression_ratio": 1.6018518518518519, "no_speech_prob": 3.726602471942897e-06}, {"id": 204, "seek": 100240, "start": 1017.52, "end": 1021.3199999999999, "text": " Oh, I can talk about this part.", "tokens": [876, 11, 286, 393, 751, 466, 341, 644, 13], "temperature": 0.0, "avg_logprob": -0.25132353933233964, "compression_ratio": 1.6018518518518519, "no_speech_prob": 3.726602471942897e-06}, {"id": 205, "seek": 100240, "start": 1021.3199999999999, "end": 1025.8, "text": " I was just asked if you wanted to give like intuition on key query.", "tokens": [286, 390, 445, 2351, 498, 291, 1415, 281, 976, 411, 24002, 322, 2141, 14581, 13], "temperature": 0.0, "avg_logprob": -0.25132353933233964, "compression_ratio": 1.6018518518518519, "no_speech_prob": 3.726602471942897e-06}, {"id": 206, "seek": 100240, "start": 1025.8, "end": 1028.52, "text": " Yeah, that's what I'm going to try to do.", "tokens": [865, 11, 300, 311, 437, 286, 478, 516, 281, 853, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.25132353933233964, "compression_ratio": 1.6018518518518519, "no_speech_prob": 3.726602471942897e-06}, {"id": 207, "seek": 102852, "start": 1028.52, "end": 1035.2, "text": " So the something is a query, a key, and a value.", "tokens": [407, 264, 746, 307, 257, 14581, 11, 257, 2141, 11, 293, 257, 2158, 13], "temperature": 0.0, "avg_logprob": -0.10227560997009277, "compression_ratio": 1.5802469135802468, "no_speech_prob": 2.601587993922294e-06}, {"id": 208, "seek": 102852, "start": 1035.2, "end": 1043.56, "text": " And they're going to be calculated as per usual by learning weight matrices.", "tokens": [400, 436, 434, 516, 281, 312, 15598, 382, 680, 7713, 538, 2539, 3364, 32284, 13], "temperature": 0.0, "avg_logprob": -0.10227560997009277, "compression_ratio": 1.5802469135802468, "no_speech_prob": 2.601587993922294e-06}, {"id": 209, "seek": 102852, "start": 1043.56, "end": 1050.4, "text": " And the idea is we're going to try and learn a weight matrix where Q is going to be learnt", "tokens": [400, 264, 1558, 307, 321, 434, 516, 281, 853, 293, 1466, 257, 3364, 8141, 689, 1249, 307, 516, 281, 312, 18991], "temperature": 0.0, "avg_logprob": -0.10227560997009277, "compression_ratio": 1.5802469135802468, "no_speech_prob": 2.601587993922294e-06}, {"id": 210, "seek": 102852, "start": 1050.4, "end": 1053.9, "text": " for the word I'm currently translating.", "tokens": [337, 264, 1349, 286, 478, 4362, 35030, 13], "temperature": 0.0, "avg_logprob": -0.10227560997009277, "compression_ratio": 1.5802469135802468, "no_speech_prob": 2.601587993922294e-06}, {"id": 211, "seek": 105390, "start": 1053.9, "end": 1060.8000000000002, "text": " So if I'm looking at word one, then Q is going to be for word one.", "tokens": [407, 498, 286, 478, 1237, 412, 1349, 472, 11, 550, 1249, 307, 516, 281, 312, 337, 1349, 472, 13], "temperature": 0.0, "avg_logprob": -0.13379556482488458, "compression_ratio": 1.8578680203045685, "no_speech_prob": 7.766462658764794e-06}, {"id": 212, "seek": 105390, "start": 1060.8000000000002, "end": 1063.76, "text": " And then I'm going to look at all the other words in the sentence and say how much attention", "tokens": [400, 550, 286, 478, 516, 281, 574, 412, 439, 264, 661, 2283, 294, 264, 8174, 293, 584, 577, 709, 3202], "temperature": 0.0, "avg_logprob": -0.13379556482488458, "compression_ratio": 1.8578680203045685, "no_speech_prob": 7.766462658764794e-06}, {"id": 213, "seek": 105390, "start": 1063.76, "end": 1066.8200000000002, "text": " do I give to H1 when translating word one?", "tokens": [360, 286, 976, 281, 389, 16, 562, 35030, 1349, 472, 30], "temperature": 0.0, "avg_logprob": -0.13379556482488458, "compression_ratio": 1.8578680203045685, "no_speech_prob": 7.766462658764794e-06}, {"id": 214, "seek": 105390, "start": 1066.8200000000002, "end": 1073.44, "text": " And so K is going to be something that I learn for, something I'm going to calculate for", "tokens": [400, 370, 591, 307, 516, 281, 312, 746, 300, 286, 1466, 337, 11, 746, 286, 478, 516, 281, 8873, 337], "temperature": 0.0, "avg_logprob": -0.13379556482488458, "compression_ratio": 1.8578680203045685, "no_speech_prob": 7.766462658764794e-06}, {"id": 215, "seek": 105390, "start": 1073.44, "end": 1079.6000000000001, "text": " all the other words in the sentence, well all of them, including this one.", "tokens": [439, 264, 661, 2283, 294, 264, 8174, 11, 731, 439, 295, 552, 11, 3009, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.13379556482488458, "compression_ratio": 1.8578680203045685, "no_speech_prob": 7.766462658764794e-06}, {"id": 216, "seek": 107960, "start": 1079.6, "end": 1087.78, "text": " And then Q and K are going to get combined together, as you see, to overall give this", "tokens": [400, 550, 1249, 293, 591, 366, 516, 281, 483, 9354, 1214, 11, 382, 291, 536, 11, 281, 4787, 976, 341], "temperature": 0.0, "avg_logprob": -0.16837096214294434, "compression_ratio": 1.6391304347826088, "no_speech_prob": 7.4109066190430894e-06}, {"id": 217, "seek": 107960, "start": 1087.78, "end": 1094.04, "text": " sense of like how relevant is the word represented by K to translating the word represented by", "tokens": [2020, 295, 411, 577, 7340, 307, 264, 1349, 10379, 538, 591, 281, 35030, 264, 1349, 10379, 538], "temperature": 0.0, "avg_logprob": -0.16837096214294434, "compression_ratio": 1.6391304347826088, "no_speech_prob": 7.4109066190430894e-06}, {"id": 218, "seek": 107960, "start": 1094.04, "end": 1095.6399999999999, "text": " Q?", "tokens": [1249, 30], "temperature": 0.0, "avg_logprob": -0.16837096214294434, "compression_ratio": 1.6391304347826088, "no_speech_prob": 7.4109066190430894e-06}, {"id": 219, "seek": 107960, "start": 1095.6399999999999, "end": 1096.6399999999999, "text": " And having figured out...", "tokens": [400, 1419, 8932, 484, 485], "temperature": 0.0, "avg_logprob": -0.16837096214294434, "compression_ratio": 1.6391304347826088, "no_speech_prob": 7.4109066190430894e-06}, {"id": 220, "seek": 107960, "start": 1096.6399999999999, "end": 1101.24, "text": " I was just saying, when they're combined together, this is forming a scalar.", "tokens": [286, 390, 445, 1566, 11, 562, 436, 434, 9354, 1214, 11, 341, 307, 15745, 257, 39684, 13], "temperature": 0.0, "avg_logprob": -0.16837096214294434, "compression_ratio": 1.6391304347826088, "no_speech_prob": 7.4109066190430894e-06}, {"id": 221, "seek": 107960, "start": 1101.24, "end": 1106.6799999999998, "text": " So that's kind of important to note that this part that you get out of the softmax is kind", "tokens": [407, 300, 311, 733, 295, 1021, 281, 3637, 300, 341, 644, 300, 291, 483, 484, 295, 264, 2787, 41167, 307, 733], "temperature": 0.0, "avg_logprob": -0.16837096214294434, "compression_ratio": 1.6391304347826088, "no_speech_prob": 7.4109066190430894e-06}, {"id": 222, "seek": 110668, "start": 1106.68, "end": 1112.48, "text": " of a scalar, which I mean we're going to put this into vectors, but compared to, you know,", "tokens": [295, 257, 39684, 11, 597, 286, 914, 321, 434, 516, 281, 829, 341, 666, 18875, 11, 457, 5347, 281, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1490949903215681, "compression_ratio": 1.6637554585152838, "no_speech_prob": 1.6697415048838593e-05}, {"id": 223, "seek": 110668, "start": 1112.48, "end": 1118.48, "text": " it's a dimension less than Q and K, where we are kind of combining this into a score.", "tokens": [309, 311, 257, 10139, 1570, 813, 1249, 293, 591, 11, 689, 321, 366, 733, 295, 21928, 341, 666, 257, 6175, 13], "temperature": 0.0, "avg_logprob": -0.1490949903215681, "compression_ratio": 1.6637554585152838, "no_speech_prob": 1.6697415048838593e-05}, {"id": 224, "seek": 110668, "start": 1118.48, "end": 1122.4, "text": " So you can kind of think of this as a scalar score that we're using to take this weighted", "tokens": [407, 291, 393, 733, 295, 519, 295, 341, 382, 257, 39684, 6175, 300, 321, 434, 1228, 281, 747, 341, 32807], "temperature": 0.0, "avg_logprob": -0.1490949903215681, "compression_ratio": 1.6637554585152838, "no_speech_prob": 1.6697415048838593e-05}, {"id": 225, "seek": 110668, "start": 1122.4, "end": 1126.04, "text": " average, as Jeremy said, of the vectors B.", "tokens": [4274, 11, 382, 17809, 848, 11, 295, 264, 18875, 363, 13], "temperature": 0.0, "avg_logprob": -0.1490949903215681, "compression_ratio": 1.6637554585152838, "no_speech_prob": 1.6697415048838593e-05}, {"id": 226, "seek": 110668, "start": 1126.04, "end": 1132.96, "text": " Yeah, so then V is being applied to the same word that K is applied to.", "tokens": [865, 11, 370, 550, 691, 307, 885, 6456, 281, 264, 912, 1349, 300, 591, 307, 6456, 281, 13], "temperature": 0.0, "avg_logprob": -0.1490949903215681, "compression_ratio": 1.6637554585152838, "no_speech_prob": 1.6697415048838593e-05}, {"id": 227, "seek": 113296, "start": 1132.96, "end": 1139.8400000000001, "text": " So you've figured out how much attention you want to give to the thing for K, given that", "tokens": [407, 291, 600, 8932, 484, 577, 709, 3202, 291, 528, 281, 976, 281, 264, 551, 337, 591, 11, 2212, 300], "temperature": 0.0, "avg_logprob": -0.1027997823861929, "compression_ratio": 1.6081632653061224, "no_speech_prob": 8.52962511999067e-06}, {"id": 228, "seek": 113296, "start": 1139.8400000000001, "end": 1143.3600000000001, "text": " we're looking at the thing for Q, and then what do you return?", "tokens": [321, 434, 1237, 412, 264, 551, 337, 1249, 11, 293, 550, 437, 360, 291, 2736, 30], "temperature": 0.0, "avg_logprob": -0.1027997823861929, "compression_ratio": 1.6081632653061224, "no_speech_prob": 8.52962511999067e-06}, {"id": 229, "seek": 113296, "start": 1143.3600000000001, "end": 1147.1200000000001, "text": " You return V. And so the intuition here, the reason I wanted to show those previous two", "tokens": [509, 2736, 691, 13, 400, 370, 264, 24002, 510, 11, 264, 1778, 286, 1415, 281, 855, 729, 3894, 732], "temperature": 0.0, "avg_logprob": -0.1027997823861929, "compression_ratio": 1.6081632653061224, "no_speech_prob": 8.52962511999067e-06}, {"id": 230, "seek": 113296, "start": 1147.1200000000001, "end": 1154.8, "text": " slides, is that V, if we didn't have any of this Q and K stuff, V would just be the weight", "tokens": [9788, 11, 307, 300, 691, 11, 498, 321, 994, 380, 362, 604, 295, 341, 1249, 293, 591, 1507, 11, 691, 576, 445, 312, 264, 3364], "temperature": 0.0, "avg_logprob": -0.1027997823861929, "compression_ratio": 1.6081632653061224, "no_speech_prob": 8.52962511999067e-06}, {"id": 231, "seek": 113296, "start": 1154.8, "end": 1158.88, "text": " matrix being fed into the feedforward neural network each time.", "tokens": [8141, 885, 4636, 666, 264, 3154, 13305, 18161, 3209, 1184, 565, 13], "temperature": 0.0, "avg_logprob": -0.1027997823861929, "compression_ratio": 1.6081632653061224, "no_speech_prob": 8.52962511999067e-06}, {"id": 232, "seek": 115888, "start": 1158.88, "end": 1164.0800000000002, "text": " But we don't just want the weight matrix for the current word, it would be a mix of weight", "tokens": [583, 321, 500, 380, 445, 528, 264, 3364, 8141, 337, 264, 2190, 1349, 11, 309, 576, 312, 257, 2890, 295, 3364], "temperature": 0.0, "avg_logprob": -0.14927499788301485, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.5559428397391457e-06}, {"id": 233, "seek": 115888, "start": 1164.0800000000002, "end": 1167.5200000000002, "text": " matrices based on how much attention we want to give them.", "tokens": [32284, 2361, 322, 577, 709, 3202, 321, 528, 281, 976, 552, 13], "temperature": 0.0, "avg_logprob": -0.14927499788301485, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.5559428397391457e-06}, {"id": 234, "seek": 115888, "start": 1167.5200000000002, "end": 1172.92, "text": " So V is like the weight matrix in the neural network, that's all that is.", "tokens": [407, 691, 307, 411, 264, 3364, 8141, 294, 264, 18161, 3209, 11, 300, 311, 439, 300, 307, 13], "temperature": 0.0, "avg_logprob": -0.14927499788301485, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.5559428397391457e-06}, {"id": 235, "seek": 115888, "start": 1172.92, "end": 1178.64, "text": " And then Q and K tell you how much to mix up all the different weight matrices in the", "tokens": [400, 550, 1249, 293, 591, 980, 291, 577, 709, 281, 2890, 493, 439, 264, 819, 3364, 32284, 294, 264], "temperature": 0.0, "avg_logprob": -0.14927499788301485, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.5559428397391457e-06}, {"id": 236, "seek": 115888, "start": 1178.64, "end": 1179.64, "text": " different words, I guess.", "tokens": [819, 2283, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.14927499788301485, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.5559428397391457e-06}, {"id": 237, "seek": 115888, "start": 1179.64, "end": 1180.64, "text": " Does that help?", "tokens": [4402, 300, 854, 30], "temperature": 0.0, "avg_logprob": -0.14927499788301485, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.5559428397391457e-06}, {"id": 238, "seek": 115888, "start": 1180.64, "end": 1181.64, "text": " Yeah, yeah, that's great.", "tokens": [865, 11, 1338, 11, 300, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.14927499788301485, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.5559428397391457e-06}, {"id": 239, "seek": 115888, "start": 1181.64, "end": 1182.64, "text": " Thank you, Jeremy.", "tokens": [1044, 291, 11, 17809, 13], "temperature": 0.0, "avg_logprob": -0.14927499788301485, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.5559428397391457e-06}, {"id": 240, "seek": 118264, "start": 1182.64, "end": 1191.5200000000002, "text": " That was a good explanation of this intuition of needing a way basically to compare two", "tokens": [663, 390, 257, 665, 10835, 295, 341, 24002, 295, 18006, 257, 636, 1936, 281, 6794, 732], "temperature": 0.0, "avg_logprob": -0.21569602191448212, "compression_ratio": 1.4970760233918128, "no_speech_prob": 2.0144601876381785e-05}, {"id": 241, "seek": 118264, "start": 1191.5200000000002, "end": 1197.16, "text": " words, get a score, and then take a weighted average of all your words.", "tokens": [2283, 11, 483, 257, 6175, 11, 293, 550, 747, 257, 32807, 4274, 295, 439, 428, 2283, 13], "temperature": 0.0, "avg_logprob": -0.21569602191448212, "compression_ratio": 1.4970760233918128, "no_speech_prob": 2.0144601876381785e-05}, {"id": 242, "seek": 118264, "start": 1197.16, "end": 1204.3600000000001, "text": " And you can even think of that, going back to the pictures of what attention looks like", "tokens": [400, 291, 393, 754, 519, 295, 300, 11, 516, 646, 281, 264, 5242, 295, 437, 3202, 1542, 411], "temperature": 0.0, "avg_logprob": -0.21569602191448212, "compression_ratio": 1.4970760233918128, "no_speech_prob": 2.0144601876381785e-05}, {"id": 243, "seek": 118264, "start": 1204.3600000000001, "end": 1210.3600000000001, "text": " of here.", "tokens": [295, 510, 13], "temperature": 0.0, "avg_logprob": -0.21569602191448212, "compression_ratio": 1.4970760233918128, "no_speech_prob": 2.0144601876381785e-05}, {"id": 244, "seek": 121036, "start": 1210.36, "end": 1216.56, "text": " We need a way to actually, let me do the one with words, compare two words and then take", "tokens": [492, 643, 257, 636, 281, 767, 11, 718, 385, 360, 264, 472, 365, 2283, 11, 6794, 732, 2283, 293, 550, 747], "temperature": 0.0, "avg_logprob": -0.1680013338724772, "compression_ratio": 1.5441176470588236, "no_speech_prob": 1.892346699605696e-05}, {"id": 245, "seek": 121036, "start": 1216.56, "end": 1225.7199999999998, "text": " this weighted average of what's important and apply that back to each word.", "tokens": [341, 32807, 4274, 295, 437, 311, 1021, 293, 3079, 300, 646, 281, 1184, 1349, 13], "temperature": 0.0, "avg_logprob": -0.1680013338724772, "compression_ratio": 1.5441176470588236, "no_speech_prob": 1.892346699605696e-05}, {"id": 246, "seek": 121036, "start": 1225.7199999999998, "end": 1232.6399999999999, "text": " And then we'll see this in the code, the square root of DK is just normalizing by the dimension", "tokens": [400, 550, 321, 603, 536, 341, 294, 264, 3089, 11, 264, 3732, 5593, 295, 31934, 307, 445, 2710, 3319, 538, 264, 10139], "temperature": 0.0, "avg_logprob": -0.1680013338724772, "compression_ratio": 1.5441176470588236, "no_speech_prob": 1.892346699605696e-05}, {"id": 247, "seek": 121036, "start": 1232.6399999999999, "end": 1235.28, "text": " that you're dealing with.", "tokens": [300, 291, 434, 6260, 365, 13], "temperature": 0.0, "avg_logprob": -0.1680013338724772, "compression_ratio": 1.5441176470588236, "no_speech_prob": 1.892346699605696e-05}, {"id": 248, "seek": 121036, "start": 1235.28, "end": 1238.8, "text": " And so what's going on here?", "tokens": [400, 370, 437, 311, 516, 322, 510, 30], "temperature": 0.0, "avg_logprob": -0.1680013338724772, "compression_ratio": 1.5441176470588236, "no_speech_prob": 1.892346699605696e-05}, {"id": 249, "seek": 123880, "start": 1238.8, "end": 1243.96, "text": " So this example, which is great, and I highly recommend Jay Alomar's blog post here, is", "tokens": [407, 341, 1365, 11, 597, 307, 869, 11, 293, 286, 5405, 2748, 11146, 967, 298, 289, 311, 6968, 2183, 510, 11, 307], "temperature": 0.0, "avg_logprob": -0.11868192635330499, "compression_ratio": 1.6050420168067228, "no_speech_prob": 2.668652086867951e-05}, {"id": 250, "seek": 123880, "start": 1243.96, "end": 1249.6399999999999, "text": " we've got an embedding, say, for the word thinking and an embedding for the word machines.", "tokens": [321, 600, 658, 364, 12240, 3584, 11, 584, 11, 337, 264, 1349, 1953, 293, 364, 12240, 3584, 337, 264, 1349, 8379, 13], "temperature": 0.0, "avg_logprob": -0.11868192635330499, "compression_ratio": 1.6050420168067228, "no_speech_prob": 2.668652086867951e-05}, {"id": 251, "seek": 123880, "start": 1249.6399999999999, "end": 1256.72, "text": " We want to kind of figure out what's the interaction between them in terms of where we should be", "tokens": [492, 528, 281, 733, 295, 2573, 484, 437, 311, 264, 9285, 1296, 552, 294, 2115, 295, 689, 321, 820, 312], "temperature": 0.0, "avg_logprob": -0.11868192635330499, "compression_ratio": 1.6050420168067228, "no_speech_prob": 2.668652086867951e-05}, {"id": 252, "seek": 123880, "start": 1256.72, "end": 1258.72, "text": " paying attention.", "tokens": [6229, 3202, 13], "temperature": 0.0, "avg_logprob": -0.11868192635330499, "compression_ratio": 1.6050420168067228, "no_speech_prob": 2.668652086867951e-05}, {"id": 253, "seek": 123880, "start": 1258.72, "end": 1265.6, "text": " And so we're going to learn a few different weight matrices to get Q, K, and V. And just", "tokens": [400, 370, 321, 434, 516, 281, 1466, 257, 1326, 819, 3364, 32284, 281, 483, 1249, 11, 591, 11, 293, 691, 13, 400, 445], "temperature": 0.0, "avg_logprob": -0.11868192635330499, "compression_ratio": 1.6050420168067228, "no_speech_prob": 2.668652086867951e-05}, {"id": 254, "seek": 126560, "start": 1265.6, "end": 1272.28, "text": " briefly here, Q1 is this weight matrix for Q times X1 is giving us Q1.", "tokens": [10515, 510, 11, 1249, 16, 307, 341, 3364, 8141, 337, 1249, 1413, 1783, 16, 307, 2902, 505, 1249, 16, 13], "temperature": 0.0, "avg_logprob": -0.1586981806261786, "compression_ratio": 1.867298578199052, "no_speech_prob": 4.0062284824671224e-05}, {"id": 255, "seek": 126560, "start": 1272.28, "end": 1276.1599999999999, "text": " The weight matrix for Q times X2 gives us Q2.", "tokens": [440, 3364, 8141, 337, 1249, 1413, 1783, 17, 2709, 505, 1249, 17, 13], "temperature": 0.0, "avg_logprob": -0.1586981806261786, "compression_ratio": 1.867298578199052, "no_speech_prob": 4.0062284824671224e-05}, {"id": 256, "seek": 126560, "start": 1276.1599999999999, "end": 1279.56, "text": " The weight matrix for K times X1 gives us K1.", "tokens": [440, 3364, 8141, 337, 591, 1413, 1783, 16, 2709, 505, 591, 16, 13], "temperature": 0.0, "avg_logprob": -0.1586981806261786, "compression_ratio": 1.867298578199052, "no_speech_prob": 4.0062284824671224e-05}, {"id": 257, "seek": 126560, "start": 1279.56, "end": 1282.4399999999998, "text": " Weight matrix for K times X2 gives us K2.", "tokens": [44464, 8141, 337, 591, 1413, 1783, 17, 2709, 505, 591, 17, 13], "temperature": 0.0, "avg_logprob": -0.1586981806261786, "compression_ratio": 1.867298578199052, "no_speech_prob": 4.0062284824671224e-05}, {"id": 258, "seek": 126560, "start": 1282.4399999999998, "end": 1284.9599999999998, "text": " These are how these are being calculated in practice.", "tokens": [1981, 366, 577, 613, 366, 885, 15598, 294, 3124, 13], "temperature": 0.0, "avg_logprob": -0.1586981806261786, "compression_ratio": 1.867298578199052, "no_speech_prob": 4.0062284824671224e-05}, {"id": 259, "seek": 126560, "start": 1284.9599999999998, "end": 1291.7199999999998, "text": " They're kind of just taking matrix multiplications with these matrices that we'll be learning", "tokens": [814, 434, 733, 295, 445, 1940, 8141, 17596, 763, 365, 613, 32284, 300, 321, 603, 312, 2539], "temperature": 0.0, "avg_logprob": -0.1586981806261786, "compression_ratio": 1.867298578199052, "no_speech_prob": 4.0062284824671224e-05}, {"id": 260, "seek": 126560, "start": 1291.7199999999998, "end": 1292.7199999999998, "text": " the weights for.", "tokens": [264, 17443, 337, 13], "temperature": 0.0, "avg_logprob": -0.1586981806261786, "compression_ratio": 1.867298578199052, "no_speech_prob": 4.0062284824671224e-05}, {"id": 261, "seek": 126560, "start": 1292.7199999999998, "end": 1293.7199999999998, "text": " And then it's 1 o'clock.", "tokens": [400, 550, 309, 311, 502, 277, 6, 9023, 13], "temperature": 0.0, "avg_logprob": -0.1586981806261786, "compression_ratio": 1.867298578199052, "no_speech_prob": 4.0062284824671224e-05}, {"id": 262, "seek": 129372, "start": 1293.72, "end": 1297.88, "text": " So we'll stop here, and we'll review this next time as we get started, and then get", "tokens": [407, 321, 603, 1590, 510, 11, 293, 321, 603, 3131, 341, 958, 565, 382, 321, 483, 1409, 11, 293, 550, 483], "temperature": 0.0, "avg_logprob": -0.2596657142210542, "compression_ratio": 1.532994923857868, "no_speech_prob": 1.7778207620722242e-05}, {"id": 263, "seek": 129372, "start": 1297.88, "end": 1299.88, "text": " further into Transformer.", "tokens": [3052, 666, 27938, 260, 13], "temperature": 0.0, "avg_logprob": -0.2596657142210542, "compression_ratio": 1.532994923857868, "no_speech_prob": 1.7778207620722242e-05}, {"id": 264, "seek": 129372, "start": 1299.88, "end": 1302.08, "text": " Oh, thank you.", "tokens": [876, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.2596657142210542, "compression_ratio": 1.532994923857868, "no_speech_prob": 1.7778207620722242e-05}, {"id": 265, "seek": 129372, "start": 1302.08, "end": 1303.08, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.2596657142210542, "compression_ratio": 1.532994923857868, "no_speech_prob": 1.7778207620722242e-05}, {"id": 266, "seek": 129372, "start": 1303.08, "end": 1307.92, "text": " Can you talk briefly about the final exam, the four exams on it?", "tokens": [1664, 291, 751, 10515, 466, 264, 2572, 1139, 11, 264, 1451, 20514, 322, 309, 30], "temperature": 0.0, "avg_logprob": -0.2596657142210542, "compression_ratio": 1.532994923857868, "no_speech_prob": 1.7778207620722242e-05}, {"id": 267, "seek": 129372, "start": 1307.92, "end": 1309.28, "text": " The final exam?", "tokens": [440, 2572, 1139, 30], "temperature": 0.0, "avg_logprob": -0.2596657142210542, "compression_ratio": 1.532994923857868, "no_speech_prob": 1.7778207620722242e-05}, {"id": 268, "seek": 129372, "start": 1309.28, "end": 1321.0, "text": " So it'll be a written exam, and it'll probably be a mix of some questions will involve kind", "tokens": [407, 309, 603, 312, 257, 3720, 1139, 11, 293, 309, 603, 1391, 312, 257, 2890, 295, 512, 1651, 486, 9494, 733], "temperature": 0.0, "avg_logprob": -0.2596657142210542, "compression_ratio": 1.532994923857868, "no_speech_prob": 1.7778207620722242e-05}, {"id": 269, "seek": 132100, "start": 1321.0, "end": 1325.16, "text": " of reading code or maybe modifying it or saying what pieces are doing.", "tokens": [295, 3760, 3089, 420, 1310, 42626, 309, 420, 1566, 437, 3755, 366, 884, 13], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 270, "seek": 132100, "start": 1325.16, "end": 1330.16, "text": " There will also be multiple choice questions kind of based on all of the conceptual ideas", "tokens": [821, 486, 611, 312, 3866, 3922, 1651, 733, 295, 2361, 322, 439, 295, 264, 24106, 3487], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 271, "seek": 132100, "start": 1330.16, "end": 1332.16, "text": " we've covered.", "tokens": [321, 600, 5343, 13], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 272, "seek": 132100, "start": 1332.16, "end": 1334.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 273, "seek": 132100, "start": 1334.0, "end": 1339.04, "text": " And there'll probably also be some short answer, I would say, too.", "tokens": [400, 456, 603, 1391, 611, 312, 512, 2099, 1867, 11, 286, 576, 584, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 274, "seek": 132100, "start": 1339.04, "end": 1340.84, "text": " Yeah, so no code.", "tokens": [865, 11, 370, 572, 3089, 13], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 275, "seek": 132100, "start": 1340.84, "end": 1342.36, "text": " I mean, there might be reading code.", "tokens": [286, 914, 11, 456, 1062, 312, 3760, 3089, 13], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 276, "seek": 132100, "start": 1342.36, "end": 1343.36, "text": " And I'll have to see.", "tokens": [400, 286, 603, 362, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 277, "seek": 132100, "start": 1343.36, "end": 1350.08, "text": " Like in the past, I've sometimes had like modify this line of code or say kind of how", "tokens": [1743, 294, 264, 1791, 11, 286, 600, 2171, 632, 411, 16927, 341, 1622, 295, 3089, 420, 584, 733, 295, 577], "temperature": 0.0, "avg_logprob": -0.25333069918448464, "compression_ratio": 1.6506024096385543, "no_speech_prob": 4.539482688414864e-05}, {"id": 278, "seek": 135008, "start": 1350.08, "end": 1351.08, "text": " you would change it.", "tokens": [291, 576, 1319, 309, 13], "temperature": 0.0, "avg_logprob": -0.29386898622674457, "compression_ratio": 1.2805755395683454, "no_speech_prob": 0.00016592857718933374}, {"id": 279, "seek": 135008, "start": 1351.08, "end": 1354.4399999999998, "text": " But it's not going to be on the computer coding.", "tokens": [583, 309, 311, 406, 516, 281, 312, 322, 264, 3820, 17720, 13], "temperature": 0.0, "avg_logprob": -0.29386898622674457, "compression_ratio": 1.2805755395683454, "no_speech_prob": 0.00016592857718933374}, {"id": 280, "seek": 135008, "start": 1354.4399999999998, "end": 1359.08, "text": " Any other questions?", "tokens": [2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.29386898622674457, "compression_ratio": 1.2805755395683454, "no_speech_prob": 0.00016592857718933374}, {"id": 281, "seek": 135008, "start": 1359.08, "end": 1362.36, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.29386898622674457, "compression_ratio": 1.2805755395683454, "no_speech_prob": 0.00016592857718933374}, {"id": 282, "seek": 135008, "start": 1362.36, "end": 1364.24, "text": " I'll see you on Tuesday.", "tokens": [286, 603, 536, 291, 322, 10017, 13], "temperature": 0.0, "avg_logprob": -0.29386898622674457, "compression_ratio": 1.2805755395683454, "no_speech_prob": 0.00016592857718933374}, {"id": 283, "seek": 135008, "start": 1364.24, "end": 1366.76, "text": " Or email me if you need to meet before then.", "tokens": [1610, 3796, 385, 498, 291, 643, 281, 1677, 949, 550, 13], "temperature": 0.0, "avg_logprob": -0.29386898622674457, "compression_ratio": 1.2805755395683454, "no_speech_prob": 0.00016592857718933374}, {"id": 284, "seek": 136676, "start": 1366.76, "end": 1380.4, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 51046], "temperature": 0.0, "avg_logprob": -0.825232744216919, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00027911868528462946}], "language": "en"}