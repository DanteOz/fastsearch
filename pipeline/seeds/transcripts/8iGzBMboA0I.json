{"text": " Yeah, so I took a kind of very theoretical linear algebra class my first semester of college. It was all proof-based, so no computations basically, and I loved it. It convinced me to be a math major instead of computer science. In hindsight, it might not have been the most practical introduction, but I really enjoyed it. I did a math PhD, and I took numerical linear algebra my first semester and really liked the course. Numerical linear algebra has a very different perspective on linear algebra in general, because it's all about how computers do it. That kind of, in many ways, blew my mind to have this very different perspective on a subject that I liked. It was still a great course. I'll be teaching with a very different approach and focus, though, from a traditional course. I wanted to highlight I had an internship my last year of graduate school in healthcare economics. I think that's the first place where I was really using linear algebra in, like, this is a business where these people are using linear algebra every day. We'll actually see an example pretty similar to some of the stuff I did in a moment. Yeah, I worked as a quant for two years. I was... Oh, question? I was going to ask you about your new software. Oh, that was Stephen Marr. I took his... Oh!...computer and mail for... Oh, that's awesome!...computing and massaging. Very cool. Yeah, that's so great. So, yeah, I was a quant for two years, which is a lot of working with data. And I would say linear algebra, kind of, yeah, having tables of data. And that convinced me to become a data scientist. I was at Uber. And I taught software engineering at Hackbrite. That's... It was mostly software development. I did get to overhaul their machine learning and collaborative filtering lectures, which was exciting. And then one year ago, Jeremy and I started Fast AI to kind of make deep learning easier to use. Yeah, so going into teaching, this is a different... It's a different approach than most math courses. It's going to be top down. So in a bottom-up approach, which is kind of the more common one in math, that's where you first learn all these separate components that you'll need. And then you kind of build things of increasing complexity as time goes on and you know more components. And that's kind of tough because people lose motivation. They don't have a sense of the big picture. And what I'll be doing instead is kind of starting with kind of doing interesting things using algorithms. And then we'll kind of go into more depth and break down the pieces. And I apologize if you heard. I gave a talk on this at the Friday seminar a few weeks ago. So sorry if this is repeat. But there's a wonderful book called Making Learning Whole where a Harvard professor uses an analogy with baseball and says, you know, we don't require kids to memorize all the formal rules of baseball before they're allowed to play. You know, we let them play and then over time they learn more and more of the formal rules. Yeah, and so kind of don't worry if at first you don't understand everything that's going on. That's kind of the point. And focus on what things do as opposed to what they are. So with these matrix decompositions, it's really important to know what type of matrices are you getting back from the decomposition? And then over time, we'll kind of get into how would you program them. So for the course, I have two textbooks. Neither of these is required. And I've asked Kirsten to buy a few copies to have on hand. So my number one choice is Numerical Linear Algebra by Trevathan. It's a really well written book. And I'll say kind of when I'm referencing parts of it. And then kind of a secondary book that I liked is Numerical Methods by Greenbaum and Chartier. And this is actually intended for kind of senior undergrad courses. And it includes numerical linear algebra, but it also includes Monte Carlo methods, numerical differentiation. I think it's a really interesting book and it has a lot of applications. It's a fun fact. Chartier is actually he's a math professor, but he trained as a mime under Marcel Marceau. And I saw him perform at a math conference on how to kind of use miming to teach math. But it's a very kind of accessible book. So I was going to hold office hours from two to four on Friday afternoons after the seminar. If that doesn't work, feel free to email me about another time. Yeah, my email is Rachel at fast.ai. And there's a class Slack channel, although I haven't done anything with that yet. But I'll send you invites. There's the link for the GitHub. Oh, and I wanted to. So this is important to note. Kind of a difficult thing about Jupyter Notebooks is even just running them changes the code. And so you can get merge conflicts if you've cloned the repository. And so it's up to you if you want to deal with those or it might just be easier to kind of download the notebooks. And there are places that I kind of leave blank for exercises. So the idea is you will be doing some coding in them as well. And I just included these to check if you have Mathjacks running, which renders LaTeX. And I believe if you're using Anaconda, that's automatically installed. But let me definitely let me know in sooner rather than later if you're having any trouble with the setup for this or any of the imports or anything, because I definitely want you to be able to run these notebooks at home. So here is a actually I should check any questions so far. Okay, here's a grading room work. So there'll be some homework assignments and I'll give you always a full week to do the homework from when I when I give it. I want there's a writing assignment for this course, and you can choose the topics and I'll say a little bit more about that in a moment. But that's kind of broken into three pieces, just your proposal, your draft, and then the final and then there'll be a final exam. So no cheating or plagiarism is allowed. And you know, we have the standard honor code from USF, which I'm sure you're really familiar with from this point. For laptops, please avoid surfing the web or using social media or messaging during class. Cool. And then here's a syllabus. I'll just say kind of that. The way it'll work is kind of each lesson is mostly centered around an application and then we'll kind of dive into algorithms and tech or techniques that are used for that application but it's kind of this almost application first approach. So we have the introductory lesson, which is a little bit unusual and that'll be less code and is more kind of introducing concepts. But then we'll talk about topic modeling using NMF and SVD, background removal with robust PCA, compressed sensing for CT scans, which are kind of some really interesting looking CT scan like pictures, predicting health outcomes. This is on a diabetes data set, page rank to go through eigen decompositions and how you program those. And then finally the QR factorization, which will have shown up in almost all of the previous lessons as a tool. Okay. So about the writing assignment, yeah, writing about technical concepts is really valuable. I hope that you'll publish it as a blog post. You don't have to. If you do, it's a really good way to get your name out there, something to show to future employers or when you're applying for jobs. Technical writing is also important when you're creating documentation at work, kind of explaining and sharing your ideas with coworkers, applying to speak at conferences, and practicing for interviews, kind of just even practicing like how do you explain what you're doing. So I have a list of ideas. Oh, and I actually, oh yeah, I might have an updated version. Hold on a moment. Yeah, this is the old version. Well, escape is not taking me out of F11. Oh, okay. Well, no, I'm running this from a different repository. Let me just go here. Oh no, that's the issue. And with all these ideas, these are just suggestions. If you have a different idea that's not on the list, feel free to ask me about it. I really want it to be something that you're interested in learning more about. So I have a list of, there are so many numerical in your algebra algorithms, and so we'll get into most of the core ones, but there are a lot that we won't have time to cover, so you could choose one of those. So here's a list of several of them. You could also speed up an algorithm of your choice, and that could either be something that we've covered in the course or not, using the GPU and PyTorch, and we'll be talking about how to do that in the first lesson. Number, Scython, which we'll cover. Parallelization, or randomized projections. So randomized algorithms are a really interesting area that give you a kind of a lot of speed up. You could also find an interesting academic paper that you've been wanting to read and summarize and implement it. And then here, actually let me go to this link, there's something called the matrix factorization jungle, which is just a handy webpage that someone put together with kind of a list of a ton of different matrix algorithms. And so if you scroll, they're kind of whole sections on different concepts. Logistics. Oh, and then I posted a link to... One other thing I wanted to say, so you can do your blog post or your writing assignment as a Jupyter Notebook, and you can also do it as a Kaggle kernel. And you can, Kaggle kernels kind of are Jupyter Notebooks, but that's another kind of great way to share your work, and you can also share data sets that way. And then I've linked to several number of technical blog posts that I like. And I think that's something that's kind of good to get into the habit of, and maybe after you graduate and have more time, but just kind of reading other people's blog post. And so for the proposal, that's just gonna be a brief paragraph about what you wanna do. So I should also say, it could be like an experiment you wanna do. Like if you're curious, how does, I don't know, changing this factor affect this algorithm, you can propose that. And then for sources. Any questions? Okay. So I'll try to review some linear algebra in class. If there are things that you feel like you need extra review in, these are some resources I recommend. One is three blue, one brown. This I would recommend to everybody for any reason. It's just the really fantastic videos. And I'll probably show one in class in a later lesson, but it's a very, very kind of geometric and visual perspective on linear algebra. And so it's very different from how most linear algebra courses are taught. The guy who created these wrote his own graphics library because he wanted to do things that he wasn't able to do otherwise, but they're really beautiful. And so if you're a visual learner, I would definitely recommend them. There's also an immersive linear algebra free online textbook. Chapter two of Ian Goodfellow's Deep Learning Book is all about linear algebra. And that's kind of coming from a machine learning perspective. Yes, I think that's it. So then the USF policies are in here. But again, you should have seen these, I think, in most of your courses about academic integrity, accommodations for disabilities, and so on. All right, you guys ready for the first lesson? And again, this is going to be less code full than future lessons, but it introduces some really interesting concepts, I think. So kind of why are we setting this? Let me go back to full screen. So the key question of this course is how can we do matrix computations with acceptable speed and acceptable accuracy? And this is from a news algorithm, or not a news algorithm, a journal article that came up with the top 10 algorithms of science and engineering during the 20th century. And three of the things on the list we'll cover in this course, which is exciting. And one is the idea of matrix decompositions as an approach to linear algebra itself, because it's such a powerful idea. So a lot of this course is about breaking matrices into other matrices that are going to be easier to work with. And so there are going to be four things to keep in mind broadly when choosing or designing an algorithm. We'll go into each of these in a little bit more depth. Memory use, speed, accuracy, and scalability. And then kind of on the motivation of doing this. So a lot of the things we'll talk about could be done in scikit-learn or sci-pi. It's really great to know kind of how those libraries work in case you want to do a variation that's not accounted for, knowing the trade-offs that you're making when you choose between different options. Also a lot of these fields are moving very quickly, and you might find new results that haven't yet been implemented in one of these libraries, particularly the areas of deep learning, recommendation systems, approximate algorithms, and graph analytics. There's a lot of research happening in all of those right now. And so yeah, knowing how to debug algorithms can really kind of accelerate your work. Or sorry, knowing how they work helps you debug them, but knowing how to debug them also helps accelerate what you're doing. So in this part, we'll probably review. I just wanted to say there are two main types of matrix computations, which are taking products and then decomposition. So putting them together and then pulling them apart. So for an example, here this is a matrix. I'm going to make this a little bit smaller just so it can fit on one screen. This is a matrix of probabilities, but this is a Markov chain with different states of health. And so there's kind of an asymptomatic HIV stage, symptomatic, full-blown AIDS, and death. And these are kind of the different states of the Markov chain. And then this matrix of probabilities is saying what are your chances if you're in one state of moving to each of the other states. And so you'll notice each row sums to one since they're probabilities. And that's kind of the row gives you the state you're starting in. The column gives you the destination state you're moving to. As I mentioned earlier, I had an internship while I was in grad school that was a whole kind of research group that looked at problems like these. They would also take into account kind of the cost of health care and different types of treatment and use that to kind of weigh recommendations. So here I want you to take if this is kind of your starting vector of what, you know, you have a group of people, 85% are in the asymptomatic group, 10% are symptomatic, and so on. And if this matrix kind of is giving you the probabilities of what their health will be like in a year, can you tell me what those probabilities are? So take a few moments to code that just to warm up. Oh, yes. Although I don't want to. So if you go to the answer tab, it should show up as a cell that says exercise. I'm not opening mine because I have the answer written there. It shows you what the correct answer should be. Oh, yes. Yeah, it shows you the output as well. I'll leave it. Oh, wow. Yes? Oh, yes. Okay, yeah. So the question was from someone not registered for the class, so let me pull up the GitHub. Yeah, so on GitHub, it's users fast AI and then numerical-linear-algebra is the repository. Let me make that bigger. And I've also put the syllabus in the README of the repository, kind of with links so you can view the notebooks and we'll be adding to it. Raise your hand if you're done. Raise your hand if you want more time. Oh, yeah, that's a great idea. Okay, let's look at the answer. Let me make this larger again. Yeah, so you can use NumPy to put these in as arrays. This is a two-dimensional array for the matrix, the vectors. Well, actually, I guess I put that as a two-dimensional as well. So I did A.T., which is transpose. The at sign is matrix multiplication in Python 3, I believe you need. So for Python 2, you could be using np.matmul for matrix multiplication, although I highly recommend switching to Python 3. So I want to say, why am I doing A transpose? Yeah, so with Markov chains, you multiply on the left as a row vector and then on the right by the matrix, what you want to get as a column vector in this case, so you just transpose the bottom. Yeah, yeah, and so it would have been fine if you had multiplied on the left. Also, the other way I think about it is, and you can pop it back. Thank you. Just by the way, the reason we're using the microphone is so we can hear it on the recording. Yeah, it works fine. Yeah, yeah, thank you. The other way to think about this is your matrix, kind of the dimensions are basically, let me point, like sources by destinations. And so I kind of think of like when you do the matrix multiplication, you're wanting to multiply it by the sources. So if you want the sources over here, you would need the sources to be the columns to kind of line up. You want, you know, sources by sources. Any questions? I just, I used, I used vector at matrix and it also worked. I just want to mention in case anybody else did that. Oh, no, that that would work as well. That's actually equivalent. The kind of taking two transposes is I can write this like this is equal to like that whole thing transposed. Yeah, thank you. So now for matrix, matrix products. This is a problem that I've taken from kind of this set, this fact sheet that has several different linear algebra problems. And so here this is and a lot of them, I think a lot of times when you're doing things by hand, they look like overly simplified examples. But it's important to remember that the power of matrices is that you can do these on really large data sets and large matrices as well. But here you've got three people who want to buy some different groceries. And they have different prices for two different shops. Each person only wants to go to one shop, which is the better shop for each person to go to. So take a moment to do that. And again, if you go to the answer tab, there'll be a little bit a little bit of space and it should show you what the ideal answer is. Okay. Okay. Okay. Okay. Raise your hand if you're finished. Raise your hand if you want some more time. Okay. Go ahead and look at the answer for this. Yeah, so this is kind of pretty straightforward of entering the matrices as NumPy arrays. And I did A at B or you could do NP.matmol if you're in Python 2. Any questions? And this, if you look at, I think it's even in the part I copied, it's kind of nice how they copied out this example of, you know, the amount spent by person one is this row. And we're multiplying it by this column to get what they would spend in shop one. Oh, so next up is image data. I really like this GIF that illustrates how images can be represented by a matrix of numbers. And so here this is black and white and the values are between 0 and 255. To show that this is the handwritten digit eight and it could be represented by a matrix of, I'm not exactly sure if this is like 20 by 20 or so on. And typically a lot of times what happens is that matrix might be unrolled then into a single row. But now you've got, you know, 400 numbers representing what that picture looked like. And for color images, you just have three matrices, one for red, green and blue. Any questions about that? OK, so we're going to look at convolutions briefly. So this is not a deep learning course, but I think deep learning is a really good illustration of how linear algebra is being heavily used right now. So convolutions are the heart of convolutional neural networks, CNNs. And so basically pretty much any results you hear that have AI or deep learning that are related to images are using CNNs. And then even this is just from a few weeks ago, Facebook's AI team published results for speech translation where they use CNNs instead of RNNs, which are kind of typically what people use for language. And they were nine times faster. So convolutions are very useful. So using convolutions or convolutional neural networks, computers are more accurate than people at classifying images. I should zoom in on these. So some of these I wouldn't get. This is an ultramarathon, not a half marathon. So the computer got the top choice was ultramarathon. Their second guess was half marathon. Third guess was running and fourth guess was marathon. So a lot of times these are very fine grained categories or distinctions. And I like this one of this is a heptathlon, not a decathlon, hurdles or pentathlon. But this is this is what computers are capable of. And then here's an example of an algorithm to kind of find bounding boxes for different objects inside a picture and then identify what the object is. And you can see. Oh, my goodness. OK. Wow. So that's even more impressive. I think this was done in videos is what Jeremy just said. Yeah. So this this one they've identified two different chairs in the picture, you know, including this one, which is kind of you only seeing part of it. And it's in the dark, you know, and a person and a dog. And this one and this is pretty intricate. There are a lot of objects overlapping each other and the algorithms recognizing them. And so we will not be getting into the full details of this. But I wanted to talk a little bit about how convolutions work since they're useful building block for deep learning and an application of linear algebra. So this is some images from a blog post. This opens. Yeah. Written by a student in the deep learning class that was here at the Data Institute. And the idea behind the convolution is that it applies a filter. So here we've got a filter that's just four numbers, alpha, beta, gamma and delta. And it's being applied to a picture. Perhaps it's just three by three. So pretty small. And you kind of put it in each location. So we put it in the top left corner and then we'll multiply alpha by a add that to beta times B plus D times gamma plus E times delta and get a single number out P as the result. And then you slide that filter across the picture and do it at each possible space. So here it is in the top right. We get out one result. Bottom left, bottom right. So this is just with a single filter on a small picture. And so that's kind of one way to think about how a convolution works. Another is and I find these pictures less helpful, but a lot of people like to draw neural networks from this point. So this is a neural network here. The alpha, beta, gamma and delta are the connections. And so those would be the weights on the connections. So whenever you see a red line, that's saying there's a connection between A and P and the weight of that connection is alpha. And so the same operation is happening that we saw before to get P. P has got four connections going into it. A times alpha, B times beta. D times, is that right? Yeah. D times gamma and then what else? E times delta. So that's another perspective. And I really, I really like this approach of thinking about topics from different perspectives because I think that kind of help can help you get a deeper understanding. And then this is neat. Here Matthew's kind of unrolled the filter and put it into this larger sparse matrix and shown, hey, this is actually a matrix multiplication. So now our kind of A, B, C, D, E from our picture is just a single vector. And we've got this sparse matrix and not just sparse means it has a lot of zeros. And those actually show up a lot, kind of matrices that have lots of zeros in a specific structure like this one does with the diagonals. And you can do a matrix multiplication and get the same result. Any questions? OK, so now we're going to look at how we could use this for edge detection in this notebook. And this don't worry, don't worry too much about the setup. But these are kind of the files you need to or libraries you need to import. Yes. This notebook is called Convolution Intro. Yes. Oh, thank you. This is Convolution Intro and this was originally part of the deep learning course. So we'll be looking at MNIST data, which is this really popular data set of lots of handwritten digits. This is very useful for banks being able to automatically identify when you insert your check into the ATM, what the numbers on it are. Post offices automatically sort our mail by zip code using image recognition on the digits. And then I should say Scikit-learn has a lot of built in data sets, which are a really useful feature and we'll be using several of them in this course. Yeah, so we kind of import and here we're so for the larger data sets that Scikit-learn includes, it doesn't include the data set. It includes a data loading utility that you can run to get the actual data. So we run that. You can kind of check what the keys are of what you get back because you're kind of getting back this dictionary like object. We're interested in the data and the target and target is going to be kind of the label of saying this is what the digit is. The data itself and then something else that's always great to do whenever you're kind of starting anything is just check your dimensions to see if they are what you expect. And you can often also kind of find stuff about the meaning based on the dimensions. So here this is seventy thousand by seven hundred and eighty four. So even if you didn't know, you could guess, hey, maybe this is seventy thousand different samples or different digits. And this is a twenty eight by twenty eight if it was put back together. So each row is just a single digit that's kind of been unrolled. And so we're going to reshape them to be twenty eight by twenty eight using num pies reshape. So now we have an often so kind of higher dimensional matrices are referred to as tensors. So you could say this is a tensor that's seventy thousand by twenty eight by twenty eight. So for the labels, we're converting them to integers. And then we're going to it's actually best to probably kind of skip to looking at these places. So here we've plotted images zero. So that's the kind of first entry of images. And you could confirm that's twenty eight by twenty eight. That's our our picture. So we plot it. It's a zero. We check the label and that is also or says zero. Was that a hand over here? OK, so that's a great question. Oh, OK. Yeah. The question was why are we dividing by two fifty five in. I guess input fifty three, which I should probably run again in this. You you wouldn't have to and it would still plot properly. This comes up later. When when we're using correlate, I believe. But yeah, if you plot it, if you. So we're trying to turn these into numbers between zero and one. It would still work if you had them between zero and two fifty five. So kind of just a way of normalizing. Or sorry, I should say the plots would still work. It would still be when you plot it, you'd be like, this is clearly the same image. Some of the computations we're going to use later. We needed it to be normalized for. Here we also have a plots helper function. And so these were the methods that were kind of defined up here. Although I don't worry too much about the details of them unless you're particularly interested. We're using it, it lets us put in a whole array of images and plots them like this, which is really handy for being able to look at our data. And this is also something I would recommend. I think sometimes it can feel kind of finicky writing the helper methods to be able to look at your data. But it's pretty much always worth it, because as you're doing computations, you want to check that things are what you think they are and be able to see what your results are. We can also zoom in on our images. So if you want to see just a plot of part of one here, we're just getting the rows from zero to 14 columns from eight to 22. So this is kind of the middle top of the zero is what this this thing is from this picture. So for edge detection, we're going to have a matrix with a name that kind of gives a lot away called top. That's negative ones along the top row, ones along the middle row and then zeros along the bottom. And this is what what top looks like. And so something to keep in mind and actually here, this is an interesting perspective. This could have been higher up using NumPy. We can look at kind of just a part of the the matrix and see this is so it's not plot plotted. But this is what the matrix looks like. And here the zeros are black. And these numbers between zero and one are giving the intensity of the white part for the handwritten zero. So we're still still kind of looking at this just from different perspectives. And so we're using a method called correlate and this came from its psychic learns image. This. Oh, there it is. Sorry. SciPy's ND image filters provides a correlate. Relate method and then something you can do that's nice feature of Jupyter Notebook is if you're inside the parentheses for a method, if you hit shift tab a few times, it pulls up the method signature and documentation, which is nice to see. And so this gives an array correlated with a given kernel. And so here we pass in images zero and top. And if we plot that. This is what we get. And so you'll kind of notice that they're white, which is the highest value along the tops of the zero and black kind of the lowest values along the bottoms of the edges. So this is picked off the edges. I'm going to talk about kind of what's going on there with this. Negative one, one and zero way to think about that. That's going to be greatest when the negative ones are multiplying by zeros and getting canceled out. We were trying to think about how could we maximize top multiplied by something else. And this is I should be clear. This is element wise multiplication we're doing. So this is not a matrix product, but we're element wise. And if you know, putting the filter on top of something and then multiplying each element on what it's kind of on top of. And so having zeros in a full row and then having like the highest value since this is normalized, which should be ones and another row that would give the biggest value for this. And so that's why it's picking out tops, because it's whenever you go from something small to something large, this this correlation will have the highest values. Questions. I yes. Yeah. OK. So Jeremy asked the question about convolution versus core or suggested that I talk about convolution versus correlation. The key difference is just with convolutions, they're actually flipped. And so this is kind of a mathematical accounting thing. Right. Like there's not a yeah, but it's yeah. So it's really it's the same and kind of in the math you take into account like, oh, the K this has actually been rotated when you're doing a convolution. But it's the same idea as a correlation. And I think correlations are easier to think about. Otherwise, you're just kind of flipping everything, but getting the same result. Let me give you that. So the question is that when you say correlation, are you talking about correlation between columns or between rows or what? So this is actually element wise. So you correlate one element. Oh, yes. Yeah. So this is this is different from a correlation matrix that you hear about of in statistics. Yeah. So kind of overuse of the word correlation. Yeah, this is a different use. Deep learning when they say convolution, they normally do this. Yeah. But yeah, but think about that kind of a separate bucket from the statistics idea of correlation between between different variables. Yes, that was really kind of the key idea of how a matrix can be used for edge detection here. We'll see if we rotate. So remember, top was that three by three matrix. We can rotate it by 90 degrees. Oh, OK. So now it's identical because we've rotated it. So it still does the same thing. I would I would not worry too much about this distinction. The key thing here is just the idea of you can pick up edges by sliding a filter. And then this is kind of nice. We rotate number of times kind of to get these different ones. And this will give us edge detection for bottom, top, left and right. You can also do diagonals. And so if we apply that kind of all these different filters to the picture of the zero here, you see we've picked off the top. This one's picked off the left hand side, since that's where the white marks are picking off the bottom right hand side. This is picking off kind of the diagonals towards the bottom right corner. Why here is kind of on the diagonals. I mean, you can always think of it as like a light shining from the top right corner in this line here from the top left. And then I guess this one is bottom left, although the edges are not as defined. OK, any questions on this? So that's it for putting matrices together. I mean, we'll be using matrix products every day, but kind of in the intro applications. And now I'm just going to very briefly say some of the matrix decompositions we'll be seeing. We'll be covering all of these in a lot of depth in the future lessons. So one is topic modeling, and we'll see it with NMF and SVD. And so a group of documents can be represented by a term document matrix. Here these are works of Shakespeare. Along the top is the particular play. On the left is different words that appear in those plays. And so you can see Anthony and Cleopatra. The word Anthony appears 157 times in Julius Caesar. The word Anthony appears 73 times. And this is a way that you can represent a group of documents as a matrix. And this is notice that nothing about syntax or order or structure is being included. This is treating them as a bag of words, basically, but it can let you figure out different topics. And in matrices, what that looks like. So this is for NMF. So the words are the rows, the documents are the columns, and you can decompose that into a matrix of topics. So that would be topics by words and then topics, importance indicators, kind of by topics. Or I mean, really, that's the kind of documents by how important each topic is for that document. And I think it's always helpful to kind of write out what your dimensions are when thinking about it. But here, topics is kind of going to be your short dimension that you're finding. We'll see background removal, which we'll use robust PCA, which uses SVD and SVD uses QR. So there's kind of some nesting going on, and that's to kind of remove. So we have this surveillance video, and we can kind of pick out what's the background and what are the people, which could be useful. The PageRank algorithm is all based off of eigendecompositions and finding an eigenvector. So we'll look at that, and we'll look at that on a data set of Wikipedia pages. And then that page I linked to before of the matrix factorization jungle has a number of other decompositions. Well, and actually, this is like perfect timing. So it's noon. I was thinking we could take maybe a seven or eight minute break and then come back. Yeah, get some water, go to the bathroom, and then we'll dive into kind of, yeah, these four concepts that I think are pretty fundamental to numerical linear algebra. Great. All right. So it's 1207. We're going to start back. And actually, Jeremy said that everyone is used or that the MSAN recommends Python 2. So he's just going to briefly talk about having both 2 and 3 installed so that you can switch between them. So for those who are interested in trying Python 3, there's only two things you need to really know. The first is that print statements now have parentheses around them. The second is that when you divide an integer by an integer, you get a float rather than integer, which makes a lot more sense. But if you're used to the Python 2 behavior, you'll find that surprising. There's a really fantastic thing called Anaconda, which some of you may have come across. It's a Python distribution that when you install it, it'll offer by default to install it in your home directory rather than replacing your system Python. So you can install Anaconda 3, and that'll give you the latest Python 3.6 that supports all the cool linear algebra stuff virtual showing. And it won't replace your current Python in any way. So then you've got a choice. With Anaconda, you can actually run multiple versions of Python inside Anaconda. So we can help you do that on Slack if you guys want to do that. Or you can just switch between the two by changing your path to add or remove your home directory Python from the path. So that's definitely an option there. I don't suggest you replace your system Python with Python 3. That's going to cause you a lot of confusion. But instead, install Anaconda. And another nice thing about Anaconda is that all of the, well, for example, PyTorch, which we'll be using later for using the GPU, by far the easiest way to install it is with Anaconda. In fact, that's the officially sanctioned method. So there's a number of reasons maybe to try out Anaconda. But definitely don't replace your system Python. Great. Thanks, Jeremy. Yeah. So feel free to ask on Slack or ask either of us if you have questions about that. And then also I want to say Python 3 is not required for this course. So if you want to keep using Python 2, that's fine as well. But it is a neat option. And Anaconda and Jupyter both make it pretty easy. Something that's nice about Jupyter is when you start a new notebook, it'll ask you like which kernel you want to use. And so if you have both installed, you can choose whichever one you want. Rachel's code often won't run as is in Python 2, if you are using Python 2. But we can also show you a couple of lines you can add to the top of every page, which makes a Python 3 file largely compatible with Python 2. So we should probably start adding that to our notebooks. Yeah. And then also, as Jeremy said, many of the things that don't work are very minor. And it's adding parentheses around your print statements or I guess some casting. Or dividing integers by integers to get floats. OK. So, yeah, in this part, I'm going to talk about kind of four huge areas of concern in numerical linear algebra or when doing matrix computations on a computer in general. So the first is, let me go to full screen again. The first is floating point arithmetic. And so to understand accuracy, we need to look at how computers store numbers. Because it's and this is something that really I hadn't thought about until I got to grad school, is when you're doing math, it's continuous and it's infinite. You know, you kind of have this infinite precision as possible. But computers are inherently finite and inherently discrete. So it's really kind of important to think about how computers deal with numbers in math. So for an exercise, I want you to look at this method F that I have defined. So F takes a value. If the value is less than or equal to a half, it returns two times that value. If X is greater than a half, it returns two times the value minus one. And imagine that we feed one tenth into that. And so that would be one tenth is less than a half. So it's going to return two tenths. And now feed that two tenths back into F. And I want you to keep doing that and just write out on paper kind of what you would get for the first 10 iterations of kind of starting with one tenth, doing F of that, and then do F of your answer. And this I definitely want you to kind of write out before you before you run the code. Okay. Okay. Raise your hand if you want more time. All right. Can someone tell me what you got for kind of working this by hand? So I got first one tenth and then two tenths, four tenths, six tenths, and then go back to two tenths. Right. Yeah. So it's a cycle. Great. Thank you. Okay. Yeah. So this is a cycle. So now we're going to try running it for 80 iterations to see what happens. So it starts off point one, point two, point four, point eight, point six, point two, point four, point eight, point six. But what's what's happening as this goes on? And then we actually end up getting one just over and over again. So the method on the computer has converged to one being the answer. I think I think this is pretty cool. Like it's a fairly simple example and it's something that you can work by hand and work on the computer. And you're clearly getting two different things. And so we'll talk about this in a moment. And something to keep in mind is that when you do get kind of these computer kind of numeric errors, it's often happening with repetition when an error is kind of getting multiplied. Because you'll notice that this is going to go back up. You know, this wasn't exactly point six, but it was pretty close. Right. It was point six. I don't know how many 10 zeros or something. And then a one. So that's a pretty small layer. But those got bigger and bigger. Kind of how far it was off. Yeah. And so that kind of the two limitations of how computers represent numbers are numbers can't be arbitrarily large or small. Like there has to be some limit and there have to be gaps between them. They can't be continuous. And so the way that computers store numbers and this is called floating point arithmetic. And I want to specify floating point arithmetic is just one piece of accuracy. So we're kind of talking about the broader concept of accuracy on a computer. And this is one component to consider. But floating point numbers have three parts. There's a sign. This is just a single bit positive or negative. What's called the mantissa are often the significant and that kind of has the digits. If you're familiar with scientific notation, when you have the like one point seven three, that's you know, that's the mantissa. And then in scientific notation, the rate X is 10, which is the base. You know, you have an exponent. So you've actually kind of seen this before of having significant and exponent in computers. The rate X is two. But this is the idea. And that you I mean, the computer has to make space to sort store these things. The sign, the number of digits and are the significant kind of the value or precision of those digits and then the exponent. And so I triple E is a set of standards that came out and I haven't written down. I think it was maybe like mid 80s about how computers should store numbers. And it's really great to have something that's consistent no matter what type of computer you're using, because that could be a big issue. And in the early days of computing, there people were doing different things. So this is just and we will talk about this a little bit. Python's if you've primarily been using Python, Python doesn't require you to say what your types are and kind of hide that from you. Many languages, particularly older languages, you had to say what type something was. And that's what the computer knew how much memory to set aside. And so for what we think of decimal numbers, they're actually, you know, typically a float or a double. Those are both kind of same type of numbers, but double saying you want more space to store it. And so here I've just said and Python is handling all this stuff behind the scenes. It just kind of hides that from you. Yeah. So here are what the requirements for doubles are. Numbers can be as large as this is something 10 to the three hundred and eighth, which is that's pretty big or as small as 10 to the negative three hundred eighth. And then I think I think this is really interesting the way that they're represented. So think about the interval from one to two. You can represent one and then one plus two to the negative fifty two one plus two times two to the negative fifty two one plus three times two to the negative fifty two and so on up to two. And then the interval from the interval from two to four is going. Oh, and this is an error. Change that. See it too. It's going kind of you can represent two and then two plus two to the negative fifty one two plus two times two to the negative fifty one two plus three times two to the negative fifty one. And so the you'll notice the numbers are not equidistant apart. So basically the bigger that the magnitude of the numbers get the kind of the more they're spaced out, which I think is kind of weird and interesting. So this is a nice kind of a graphic showing that that close to kind of for small numbers are closer together. I just thought we were pointing out that the two things that we're using in this class to represent numbers being numpy and pytorch both are types given that the Python isn't. So with numpy if you feed it a float it will create a double position float. If you feed it anything as a float it will create a double position float array. If they're all instead of create a long integer array and then when we use pytorch we're all explicitly saying what type of thing is. So we are using type libraries pretty much exclusively in this course. Thank you. That's a great point. And also even another library will use his number, which lets you add types to Python in general. Oh, just I thought. OK. Sorry. Python is the one that lets you add types to Python. So that is something that comes you will often want to add and that numpy kind of has built in when you're doing scientific computing and also for improving performance. It typically lets you. Kind of go faster to handle it yourself. And so machine epsilon that's kind of defined to be half the distance between one and the next larger number. So for double precision machine epsilon is two to the negative 53. You can kind of see that up here that the thing kind of the next number after one is to the negative 52 more. So half of that is two to the negative 53. And this is kind of a term that you'll hear people people talk about. And then converting from base two to base 10 that's equivalent to about 10 to the negative 16. And we'll see this kind of show up an example later. Any questions. Why does machine epsilon matter. So machine epsilon often you'll talk about your air as a in terms of machine epsilon is that something that's kind of inescapable that you know the computer can't represent something smaller than that. And so you'll just kind of talk about I mean if you have an algorithm that makes that worse stirs in terms of you know the square root of that then that's kind of worse than the computer could be doing. And depending on what you're trying to do it varies what's possible. But this is kind of a good unit to talk about how you're how you're doing. And then two important properties of floating point arithmetic. One is that the difference between a real number and its closest floating point approximation is always smaller than machine epsilon in relative terms. So here f l of acts is the floating point representation and then the X is kind of the true number you're wanting to represent. And it's saying the floating point representation is going to be equal to X times one plus some epsilon and that epsilon is less than or equal to machine epsilon. So it's kind of nice to give you a bound on your accuracy. And then for the kind of key floating point operations which are addition subtraction multiplication and division. So a lot star represent that operation and then circle star is the floating point equivalent of that kind of how it's implemented. Your result is going to be no more than a multiple of one plus epsilon off. And then this next part I included because I just found it was really interesting to read about. I found this book called Handbook of Floating Point Arithmetic and Chapter One is available for free. But it lists a lot of other types of storage schemes that were tried with numbers at various points. And so I don't know what all of these are but I thought it was an interesting list that people tried and possibly infinite strings of rational numbers floating slash number systems. So there have been a lot of different approaches that have tried. And actually let me skip ahead. There's a really nice quote from the book that really you're having to make compromises between speed accuracy dynamic range ease of use implementation and memory. They're kind of like all these different considerations and that floating point arithmetic seem to be a good compromise for kind of all of this and a lot of people kind of converge to accepting this. Here is an interesting history of floating point arithmetic. Donald Newth cites the Babylonians as being the first to have a floating point arithmetic system. And theirs was base 60 and that was 8000 BC and 1630 the slide rule was invented and there you're manipulating only significance. That's base 10 and radix and base are kind of the same thing. 1941 this is interesting was kind of the first real modern implementation. Conrad Zeus made the Z3 computer and Conrad Zeus lived and worked in Nazi Germany and so he was really cut off from the rest of the scientific community and so he built some very interesting computers that kind of nobody else knew about for quite some time. Although many of them were destroyed in bombings but he was the first to kind of kind of implement this in a modern computer. And then yeah 1985 and William Kahan who is I believe at Berkeley played a huge role in kind of pushing for the standardization of wanting different computer manufacturers to be doing the same thing. And then just a real quick. So I think with computers you know kind of zeros and ones radix having base two seems to make a lot of sense. Apparently the Russians were using radix three for a while and there are some benefits to that. And this was in the 50s. Everyone's actually had a whole series of turnery based computers. So that was a hardware level. Yeah and it was I mean it was neat because it says that this does kind of minimize in some ways like the number of symbols times digits you have to use. Also rounding gets nicer. Any questions about floating point. OK so we're still under these up. We're still under the sub point of accuracy right now. But the next thing to think about with accuracy is conditioning and stability. And so since we can't represent numbers exactly on a computer it becomes really important to know how having a small change in your input affects the output because sometimes that's going to happen inevitably with how you're representing your numbers. And so Trevathan had a quote author. Saying a stable algorithm gives nearly the right answer to nearly the right question. And so that kind of nearly the right question is referring to you can't represent your numbers exactly. And then you want your algorithm to be doing nearly the right thing. Conditioning and stability. And I think many people kind of use them as synonyms. Technically conditioning is referring to the problem itself how it behaves under perturbations which are small changes to input. Stability is about the behavior of an algorithm. And so we'll be talking about it in the context of a few different algorithms. And so then a kind of simple example is we look at the matrices A and B. So A is 1,000, 0, 1. B being 1, 1,000, 0.001 and 1. These are very similar matrices right there's only a 0.001 difference in one entry between A and B. If you calculate. So you would actually kind of hope that these would have similar eigenvalues and they don't. And that's not because of how we're calculating them. That's kind of an issue of the problem of finding algorithms. I don't know. I'm so happy about highlighting. So here for A the eigenvalues are 1 and 1. It has a kind of multiplicity 2 for the eigenvalue 1. And then for B they're 2 and 0. So those are very different. That's the J. And J is for the imaginary term. A lot. We are just we're just going to focus on real numbers in this course. But a lot of these problems in general can give complex values. And so real valued matrices can have complex valued eigenvalues or eigenvectors. And then I also just wanted to highlight because I think this command is so useful. NP dot set print options suppress equals true. Otherwise, what happens is and you've probably seen this you get like zero written out with like 15 digits and scientific notation and just zero zero zero zero. So I suppress equals true turns that off and makes make sure zeros just show up is zero. Any questions about the eigenvalue example? And so that is something kind of to keep in mind kind of things you'll see that relate to the math because this is something even if you weren't using a computer and you solved for the eigenvalues by hand, you would still get these different answers for what are fairly similar inputs. And then just looking ahead, this will come up again when we talk about classic versus modified Graham Schmidt, which are methods for the QR factorization also with Graham Schmidt versus householder and conditioning a system of equations. And then another area to kind of think about with accuracy is approximations. It's actually pretty rare that we need to do highly accurate matrix computations at scale, particularly if you are doing machine learning, often being slightly less accurate is a form of regularization that can help you prevent overfitting. And if you are willing to accept some decrease in accuracy, you can often increase your speed by orders of magnitude, which could let you calculate an answer several times and kind of regain some accuracy with that approach. And then I guess the issue that I didn't write down here, but to think about is also the quality of your data. And kind of if you're aware that your data may not be super precise, it's then bizarre to spend a lot of time trying to get the kind of most accurate answer possible when you know that your data wasn't even collected in the most precise way. And I think this happens really a lot in the kind of tech world. And then a kind of popular example. So this idea of kind of inserting randomization or approximation into algorithms is very powerful. And a really kind of popular example is a Bloom filter. And that's something that allows you to search for set membership with 1% false positives. If you were using that uses less than 10 bits per element, the kind of general idea is with a Bloom filter, if it tells you no, it's definitely no, like you know that's correct. If it tells you yes, it's probably right. There could be some error there. And so this is a tweet joke about it. Would you like to learn more about Bloom filters? No, or probably because you can never get a definite yes with that, but you can get a definite no. And then a kind of a place that they're used is looking for kind of if you want a web browser wants to block pages with viruses, it could use a Bloom filter. And if it says no, then it lets you view the web page. No problem. If it says maybe, then it can look it up. And that takes a little bit longer, but it's only having to do it for a small percentage of the pages. Any questions? Okay. Oh, and then this is also kind of just for fun, but kind of expensive, expensive errors. The European Space Agency spent 10 years and $7 billion on the Ariane 5 rocket. But it was trying to fit a 64 bit number into a 16 bit space at one place. And so it exploded. Five, four, three, two, one, fire. This happened I think in the 90s. 94, yeah. There was also, I can say as this is going off, I didn't include it, but the US had a Patriot missile defense system in the Middle East. 37 seconds into the launch, the onboard computers decided 501 was 90 degrees off course. So this stuff can have big implications. But yeah, as I say, a US kind of missile defense system, its clock gradually got more inaccurate. I think 28 people were killed by a missile that it failed to recognize because it was like, you have to look it up. I think the clock was significantly off because it hadn't been reset. Whereas this, yeah, the kind of error accumulated. And then another very expensive error is Intel released a chip in 94 that just in certain cases only had like five digits of accuracy. And so they ended up having to kind of do a recall on that and it cost them close to half a billion dollars. So just to highlight that this stuff does have real world implications. I actually remember when that happened and I remember like a lot of the math libraries that were released had to be humbled because they couldn't rely on this thing. So it was probably more than 475 million because I personally was in awe of using the Wow. Yeah. So that was just the cost to Intel, not to people who, yes. Yeah. So that's the that's it for accuracy and all these concepts will kind of return to as the course goes on. This is just introducing them. So memory use. So we've talked about how numbers are stored now, looking at how matrices are stored. And so a key way to save memory and also computation is not to store all of your matrix. You could just store the non zero elements and then you know anything that you're not storing must be zero. This is called sparse storage, well suited to sparse matrices. Here's an example. And these actually show up a lot in problems where you kind of have some sort of structure and maybe things on the diagonal or tri diagonal are non zero. But that you have zeros elsewhere. This picture is from something called a finite element problem. And those show up in engineering. We won't cover them here, but it's also a multi grid problem. Whenever you're kind of having to model like airflow around a plane engine or some nose of a plane, you get these matrices with sometimes very pretty patterns of where the non zero elements are. And so in this picture, this is like a hundred by a hundred matrices and black squares are non zero values. White squares are zero values. And so we'll come back to this because SciPy in a future lesson will kind of talk about SciPy gives you three different ways to store sparse matrix. So, you know, once you've decided like, OK, I'm not going to have a cell for everything, you do have to kind of talk about like, OK, what are you going to store to keep track of? So we'll return to that. And then the opposite of sparse is dense, which is probably kind of what you're most used to with both matrices and storage. And then kind of as a rule of thumb, some people say that you can consider a matrix sparse if the number of non zero elements scales with either the number of rows or the number of columns, whereas a dense matrix, the number of non zero elements is scaling with the product of the number of rows and the number of columns. Any questions about that? OK, so speed and speed is another one that has several kind of sub sub points underneath it. And things that affect the speed of your algorithm are the computational complexity, vectorization, scaling to multiple cores and nodes and locality. We're not going to I'm really going to get into computational complexity and big O notation in here just to check who's familiar with the notation. OK, I've linked to a few resources. Kind of interview cake has a nice overview. And I went through that kind of the start of Code Academy, I think, has a really nice kind of build up of it has you doing starts with simple problems that kind of get more complex. But I think those are kind of useful tools if you do want to review it or learn about it. And typically mentioning probably every interview you do just about is going to mention computational complexities of this work familiar with even just for that. That's super useful. Yeah. And this is something that in software engineering definitely comes up in every interview. Data science I would see is more mixed, but will come up. But like, yeah, like encoding boot camps, people kind of spend the first 80 percent of the course actually learning to build web develop, you know, build web apps and stuff. And then at the end, it's like just study the theory of computational complexity, because that's what you'll see on interviews. And that kind of idea behind it is that it's giving you just this approximation that's kind of like an order of magnitude. You're not interested in kind of your constant terms or even your coefficients of how how slow things would be. And so if you had an M by N matrix, you might have you might describe an algorithm as being N squared times N if you were having to do that's kind of how many operations you had to do for your algorithm. Vectorization. So modern CPUs and GPUs can apply the same operation to multiple elements at the same time. This is called SIMD, single instruction, multiple data. You will not be explicitly writing SIMD code. And this is typically done in assembly. But libraries like NumPy, which we will use a lot, have been vectorized to do that. And those rely on low level linear algebra libraries such as BLAST and LawPack, which I want to say a little bit about because you'll probably hear about them. And they're they're like everywhere. So BLAST started out as a Fortran library in 1979. And it's a specification for low level matrix and vector arithmetic operations. So kind of very kind of the more basic like you're doing matrix multiplication or matrix vector product. Some examples of it include AMD, Atlas, MKL, and OpenBLAST. So you may hear about these. Then LawPack uses BLAST. And so it's kind of like a layer above it. And LawPack is for matrix factorizations, which is what we'll be seeing in this course. So LU, Tolesky, QR, SVD. Yeah, and LawPack arose out of kind of previously there were two separate libraries, ISEPACK and LINPACK. ISEPACK was for eigenvalue routines. LINPACK was for linear equations. And neither of those were really taking advantage of cache. So they were developed in the 70s and 80s. And I think LawPack came out in the early 90s to kind of take advantage of cache and modern systems. And you'll see like if you're reading the SciPy source code, at many points you'll see it calling LawPack routines. And so there are points where if you want it to go in depth, you can kind of look at that at the LawPack documentation to kind of see, OK, this is what is happening when SciPy calls this LawPack routine. Well, and then the next concept is locality. And so a lot of the kind of slowness from computers nowadays comes from when they're having to move data around from one location to another. And slower ways to access data, such as getting something from the Internet, can be up to a billion times slower than faster ways, such as the register, which is basically the fastest memory. And it's important to remember that basically the faster memory is the less you have of it. And so your fastest types of memory are much more limited in space. And so once you have data in fast storage, it would be great to, I don't know, if you're going to have to do three computations with that data to do all of them while it's in fast storage, as opposed to like putting it back in slow storage, retrieving it, doing your second computation, putting it back in slow storage, doing something else and then retrieving it for your third computation, because it's that having to retrieve it that's slow. And so you really want to minimize those. And so kind of ways that you can group together, you know, times that you're going to use a particular piece of data are really helpful. And so kind of issues in that category are known as locality. This is so Jeff Dean of Google gave a presentation on numbers every programmer should know. And these versions are from and a lot of people still so it's been years, a lot of people still share the slideshow. There's an updated version. I would say actually, let me open this because it's kind of neat. The updated version has like a slider so you can even look at like what the numbers were in different years. So the thing to kind of look at is that an L1 cache reference, one nanosecond, that's kind of the fastest you can do. Main memory reference, and this is also kind of RAM, would be 100 nanoseconds. And here, I don't know if you can read this from there, they're switching colors. So they're kind of saying 100 nanoseconds, you know, 100 black boxes is one blue box. And what's going on with the colors in this picture? So main memory reference, okay, that's 100 times slower. And then if you get to disk seek, that's really slow. So that's 3 million nanoseconds. So it's kind of important to keep these in mind. More the idea of kind of the orders of magnitude that you're seeing as opposed to memorizing specific numbers. Any questions? And I definitely encourage you to check out a lot of these links. I'm now going to show part of this video, and so this video is about a language called Halide, which we will not be using. But it's just a really good illustration of some of the things you would have to think about in kind of thinking about what order to do things in. And so in the video, don't worry about just briefly at the beginning, he shows kind of a bunch of code. There'll be these kind of visualizations, though, with green boxes and green means that you're reading something and red means that you're writing kind of what order things are happening in. And the problem he's looking at is just the blur of a photo. So kind of taking a lot of the developers on Halide work at Adobe. So they do a lot of kind of photo processing. But the idea of just you need to read, you know, a few pixels to be able to give the XY blur. So you're kind of taking this photo and then we want to look at a few pixels around it to get what the blurred version would be. Oh, yes, this is a convolution. So kind of similar to what we saw before, that idea of kind of sliding a filter. Hi, I'm Andrew Adams, and this video is about Halide, a new language and then a vertical blur, which reads and averages three points from intermediate results, which we store in a temporary image. This code takes about 10 milliseconds per megapixel on the quad core x86 that I benchmarked it on. But an optimized implementation, do you think I should turn the volume on for the computer? This machine is more than 10 times faster. The code is hideously complex. All we're trying to do is average together three by three pixels. But an 11x speed up is too much to ignore. So why is this code fast? We've transformed the pipeline to optimize for both parallelism and locality. The parallelism comes from distributing work across threads, and that's what that pragma-OMP parallel four at the top does, and also from computing in eight wide SIMD chunks on each core's SSE units. Exposing parallelism, though, is only half the story. Just as important and often much harder to think about or express is locality. For example, making sure the pixels produced by one stage are still in cache when the next stage reads them. And without locality optimization, even a really well-parallelized pipeline will probably be limited by the available memory bandwidth. So here the optimized code improves locality by computing each stage in tiles, interleaving the computation of tiles across stages. So we compute just a single tile of blur in x and then a single tile of blur in y, and then we go back to compute the next tile of blur in x. So this, hopefully, keeps all that intermediate data in small buffers that never leave cache. But it complicates the code because it's interleaved the computation of each stage. So the execution of the pipeline looks like this. The input image is at the top, flowing down through the blur x and blur y stages below. The earlier stages are evaluated over larger buffers because we're computing filters that have a footprint, so we need more inputs than there are outputs. Each point in blur y, the output stage, depends on three pixels in blur x, which in turn depend on nine pixels total in the input. So the unoptimized version that we looked at first computes every pixel in the first stage, writing them out to memory before computing the next stage, which has to slowly read them back in. The optimized version interleaves the stages instead. To compute a chunk of blur y, we first need the corresponding chunk of blur x, which loads a chunk of the input. The blur x stage filters that input, and then blur y immediately consumes it to compute a chunk of the output. So next we throw away that intermediate data, that chunk of blur x, load the next chunk of the input, compute the next chunk of blur x, followed immediately by that next chunk of blur y. So we've moved the computation of each chunk of pixels in a consumer stage closer in time to the computation of its inputs. This improves producer-consumer locality by keeping all the intermediate data nearby in local caches. But it's made optimization a global problem of carefully interleaving the computation and storage down an entire imaging pipeline. You can't address locality just by optimizing stages in isolation or by just tweaking operations in your interloops. Also, we're making a trade-off here. We're saying that for each chunk of blur y, we should independently compute, consume, and then throw away the required chunk of blur x. This means that neighboring chunks, which depend on overlapping pixels from higher up in the pipeline, do redundant work where they overlap. Now for this pipeline, it made sense to redundantly compute some values in exchange for the increase in locality that we get by never letting the intermediate values move out of cache into main memory. But this is not always the right choice. Let's try to get a full handle on the space of choices we could have made. In general, in an imaging pipeline, there are two questions you must answer for each stage. The first is, in what order should that stage compute its values? Let's look at some choices. The most common way to traverse a region is in scanline order. This means we traverse a region of a function sequentially across y and within that, sequentially across x. This walks down scanlines just like the loops you would typically write in C. We can transpose the x and y dimensions, which gives a column major traversal, which walks down each column in turn. Or we could go back to scanline order, but traverse the x dimension in vectors of width 4. We could distribute the scanlines across parallel threads. Finally, we can split the x and y dimension into tiles, which opens up further recursive choices for the order of the outer and inner components of each dimension. By traversing the outer components outside the inner components, we get a simple tile traversal. That's the first question. The second question is more subtle. When should each stage compute its inputs? Let's look at some options. Here we have a visualization of the blur pipeline. On the left is the input, on the right is the output, and in the middle is the blur in x stage. Green means we're reading, red means we're writing, and blue means we've allocated a temporary buffer. So right now we're reading from the input and using it to write to the blur in x stage. We read three values from the input, one, two, three, to compute a single value of the blur in x stage. We haven't even started writing to the output yet. So the choice we've made here is that we're going to compute all of the blur in x stage before computing any of the blur in y stage. If we phrase this as a decision made by blur in y, that decision is, compute all of my inputs ahead of time before I start computing any of my values. So what's the pitfall with this approach? Why is this slow? The answer is, of course, locality. By the time the blur in y stage goes to read some of the intermediate data, it's probably been evicted from cache. So that load will be slow and will be limited by the system memory bandwidth. So let's look at a different option. Here we compute three values of blur in x by reading nine values from the input, and we immediately use that to compute one value of the output. So here we get maximum locality. We're using data as soon as it's available without giving it any time to be evicted from a cache. What's the pitfall here? Well, if you look carefully at what the blur in x stage is doing, you'll realize that we're doing a lot of wasted work. Each point in blur in x is redundantly recomputed three times. OK, well, maybe we can figure out how to get around that. Here's another choice. First it's going to look similar, but notice that we've allocated enough memory to keep around all of the intermediate stage, and we're not throwing away values as we go. That means when we get to the second scanline, we can start reusing values that we computed earlier. So great, we have locality, and we're not doing any redundant work. What's the pitfall here? We've introduced a serial dependence in the scanlines of the output. We're relying on the fact that we've computed scanline n minus 1 before we can start computing scanline n. This means that we can't paralyze across scanlines with this strategy. With the previous two strategies, we could. So this approach has poor parallelism. I'll go ahead and stop it here. I really like that visual approach if he's showing these different ways of doing the same computation, and that each one has different positives and negatives. In fact, none of them seems ideal because there's a tradeoff no matter what. I just want to mention that later on we are actually going to build an algorithm in all of those different ways in Python and see how they are different. Keep that video in mind because when we get there, it will be useful to think about those pictures. Yeah, thank you. And then something that he said in the video is just locality is really hard because you kind of have tradeoffs. It feels like no matter what you do, sometimes redundant computation can save you memory bandwidth. So computing things multiple times means that you don't have to be pulling them in and out of memory as much. Or you can sacrifice parallelism to get better reuse, but then you can't parallelize. He kind of says the people building this are experts who have been working in Adobe for a long time. They really often just have to try a bunch of different stuff and it can be hard to predict what's going to end up being fastest. And then kind of another... The difference in speed that Rachel's talking about is many orders of magnitude, not a few percent. So this isn't like a minor thing. These are things where like in practice, if you don't run something overnight and it hasn't finished, you'll make one of these small changes and it runs in three seconds. It can be that big of a difference. Yes, thank you. Yeah. If it was a minor difference in speed, it wouldn't be worth the bother. And something even I think in the part I showed you, he mentioned kind of getting an 11x speed up by writing this more complicated version. And I couldn't even see what the code said, but it was a full screen of code just to do this blur in X, blur in Y operation. And then another issue that comes up is temporaries. And that's when you're doing a calculation and kind of temporary variables end up getting stored. And so this can be a lot slower than if you're able to keep all the data in cache. So this is if the temporary variables are stored in RAM. NumPy creates temporaries for kind of every operation it does. So if you were doing A equals B times C squared plus the natural log of D, what NumPy would have to do is calculate C squared, store that, multiply that by B, store that result, take the natural log of D, store that somewhere, and then use those two variables that's stored to add them together and give you the answer you want. And so kind of along the way, NumPy is having to deal with this creating temporary variables and putting them somewhere. And then I'm about to get to the scalability section, but I just want to note that scalability definitely impacts the speed of what you're doing and whether you're kind of fully taking advantage of the resources that you have. So for scalability, kind of there's the one approach is to be able to scale an algorithm across multiple cores within a single computer or scaling across multiple computers in a network, which we will not be covering. But yeah, we will talk about kind of parallelizing, which is scaling across multiple cores in a computer. Yeah, and I think this is great timing. I can take questions. Oh, yes. Just a tip. You'll see that Rachel has used a lot of hierarchical headings, and it's really easy to navigate those and understand her thought process by collapsing sections. You need to install a Jupiter extension called collapsible headings for that to work. So you might want to look at installing that extension. Yes. Yeah, that's a great extension. Any questions? Okay, well, I'll see you on Thursday. Thanks.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.38, "text": " Yeah, so I took a kind of very theoretical linear algebra class my first semester of college.", "tokens": [865, 11, 370, 286, 1890, 257, 733, 295, 588, 20864, 8213, 21989, 1508, 452, 700, 11894, 295, 3859, 13], "temperature": 0.0, "avg_logprob": -0.2403088550941617, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0025897473096847534}, {"id": 1, "seek": 0, "start": 6.38, "end": 10.58, "text": " It was all proof-based, so no computations basically, and I loved it.", "tokens": [467, 390, 439, 8177, 12, 6032, 11, 370, 572, 2807, 763, 1936, 11, 293, 286, 4333, 309, 13], "temperature": 0.0, "avg_logprob": -0.2403088550941617, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0025897473096847534}, {"id": 2, "seek": 0, "start": 10.58, "end": 14.08, "text": " It convinced me to be a math major instead of computer science.", "tokens": [467, 12561, 385, 281, 312, 257, 5221, 2563, 2602, 295, 3820, 3497, 13], "temperature": 0.0, "avg_logprob": -0.2403088550941617, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0025897473096847534}, {"id": 3, "seek": 0, "start": 14.08, "end": 21.18, "text": " In hindsight, it might not have been the most practical introduction, but I really enjoyed it.", "tokens": [682, 44357, 11, 309, 1062, 406, 362, 668, 264, 881, 8496, 9339, 11, 457, 286, 534, 4626, 309, 13], "temperature": 0.0, "avg_logprob": -0.2403088550941617, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0025897473096847534}, {"id": 4, "seek": 0, "start": 21.18, "end": 27.48, "text": " I did a math PhD, and I took numerical linear algebra my first semester and really liked the course.", "tokens": [286, 630, 257, 5221, 14476, 11, 293, 286, 1890, 29054, 8213, 21989, 452, 700, 11894, 293, 534, 4501, 264, 1164, 13], "temperature": 0.0, "avg_logprob": -0.2403088550941617, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.0025897473096847534}, {"id": 5, "seek": 2748, "start": 27.48, "end": 32.18, "text": " Numerical linear algebra has a very different perspective on linear algebra in general,", "tokens": [426, 15583, 804, 8213, 21989, 575, 257, 588, 819, 4585, 322, 8213, 21989, 294, 2674, 11], "temperature": 0.0, "avg_logprob": -0.20067697101169163, "compression_ratio": 1.7074074074074075, "no_speech_prob": 4.356269982963568e-06}, {"id": 6, "seek": 2748, "start": 32.18, "end": 34.34, "text": " because it's all about how computers do it.", "tokens": [570, 309, 311, 439, 466, 577, 10807, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.20067697101169163, "compression_ratio": 1.7074074074074075, "no_speech_prob": 4.356269982963568e-06}, {"id": 7, "seek": 2748, "start": 34.34, "end": 41.18, "text": " That kind of, in many ways, blew my mind to have this very different perspective on a subject that I liked.", "tokens": [663, 733, 295, 11, 294, 867, 2098, 11, 19075, 452, 1575, 281, 362, 341, 588, 819, 4585, 322, 257, 3983, 300, 286, 4501, 13], "temperature": 0.0, "avg_logprob": -0.20067697101169163, "compression_ratio": 1.7074074074074075, "no_speech_prob": 4.356269982963568e-06}, {"id": 8, "seek": 2748, "start": 41.18, "end": 44.08, "text": " It was still a great course.", "tokens": [467, 390, 920, 257, 869, 1164, 13], "temperature": 0.0, "avg_logprob": -0.20067697101169163, "compression_ratio": 1.7074074074074075, "no_speech_prob": 4.356269982963568e-06}, {"id": 9, "seek": 2748, "start": 44.08, "end": 49.1, "text": " I'll be teaching with a very different approach and focus, though, from a traditional course.", "tokens": [286, 603, 312, 4571, 365, 257, 588, 819, 3109, 293, 1879, 11, 1673, 11, 490, 257, 5164, 1164, 13], "temperature": 0.0, "avg_logprob": -0.20067697101169163, "compression_ratio": 1.7074074074074075, "no_speech_prob": 4.356269982963568e-06}, {"id": 10, "seek": 2748, "start": 49.1, "end": 54.7, "text": " I wanted to highlight I had an internship my last year of graduate school in healthcare economics.", "tokens": [286, 1415, 281, 5078, 286, 632, 364, 16861, 452, 1036, 1064, 295, 8080, 1395, 294, 8884, 14564, 13], "temperature": 0.0, "avg_logprob": -0.20067697101169163, "compression_ratio": 1.7074074074074075, "no_speech_prob": 4.356269982963568e-06}, {"id": 11, "seek": 5470, "start": 54.7, "end": 58.68, "text": " I think that's the first place where I was really using linear algebra in, like,", "tokens": [286, 519, 300, 311, 264, 700, 1081, 689, 286, 390, 534, 1228, 8213, 21989, 294, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 12, "seek": 5470, "start": 58.68, "end": 62.080000000000005, "text": " this is a business where these people are using linear algebra every day.", "tokens": [341, 307, 257, 1606, 689, 613, 561, 366, 1228, 8213, 21989, 633, 786, 13], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 13, "seek": 5470, "start": 62.080000000000005, "end": 67.58, "text": " We'll actually see an example pretty similar to some of the stuff I did in a moment.", "tokens": [492, 603, 767, 536, 364, 1365, 1238, 2531, 281, 512, 295, 264, 1507, 286, 630, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 14, "seek": 5470, "start": 67.58, "end": 71.28, "text": " Yeah, I worked as a quant for two years. I was... Oh, question?", "tokens": [865, 11, 286, 2732, 382, 257, 4426, 337, 732, 924, 13, 286, 390, 485, 876, 11, 1168, 30], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 15, "seek": 5470, "start": 71.28, "end": 74.14, "text": " I was going to ask you about your new software.", "tokens": [286, 390, 516, 281, 1029, 291, 466, 428, 777, 4722, 13], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 16, "seek": 5470, "start": 74.14, "end": 77.18, "text": " Oh, that was Stephen Marr.", "tokens": [876, 11, 300, 390, 13391, 2039, 81, 13], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 17, "seek": 5470, "start": 77.18, "end": 78.28, "text": " I took his...", "tokens": [286, 1890, 702, 485], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 18, "seek": 5470, "start": 78.28, "end": 78.78, "text": " Oh!", "tokens": [876, 0], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 19, "seek": 5470, "start": 78.78, "end": 79.78, "text": "...computer and mail for...", "tokens": [1097, 1112, 13849, 293, 10071, 337, 485], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 20, "seek": 5470, "start": 79.78, "end": 80.7, "text": " Oh, that's awesome!", "tokens": [876, 11, 300, 311, 3476, 0], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 21, "seek": 5470, "start": 80.7, "end": 82.28, "text": "...computing and massaging.", "tokens": [1097, 1112, 2582, 278, 293, 2758, 3568, 13], "temperature": 0.0, "avg_logprob": -0.4350796980823544, "compression_ratio": 1.6549295774647887, "no_speech_prob": 1.1477313819341362e-05}, {"id": 22, "seek": 8228, "start": 82.28, "end": 88.54, "text": " Very cool.", "tokens": [4372, 1627, 13], "temperature": 0.0, "avg_logprob": -0.20700510025024413, "compression_ratio": 1.5576036866359446, "no_speech_prob": 3.5553127872844925e-06}, {"id": 23, "seek": 8228, "start": 88.54, "end": 90.1, "text": " Yeah, that's so great.", "tokens": [865, 11, 300, 311, 370, 869, 13], "temperature": 0.0, "avg_logprob": -0.20700510025024413, "compression_ratio": 1.5576036866359446, "no_speech_prob": 3.5553127872844925e-06}, {"id": 24, "seek": 8228, "start": 90.1, "end": 95.64, "text": " So, yeah, I was a quant for two years, which is a lot of working with data.", "tokens": [407, 11, 1338, 11, 286, 390, 257, 4426, 337, 732, 924, 11, 597, 307, 257, 688, 295, 1364, 365, 1412, 13], "temperature": 0.0, "avg_logprob": -0.20700510025024413, "compression_ratio": 1.5576036866359446, "no_speech_prob": 3.5553127872844925e-06}, {"id": 25, "seek": 8228, "start": 95.64, "end": 99.04, "text": " And I would say linear algebra, kind of, yeah, having tables of data.", "tokens": [400, 286, 576, 584, 8213, 21989, 11, 733, 295, 11, 1338, 11, 1419, 8020, 295, 1412, 13], "temperature": 0.0, "avg_logprob": -0.20700510025024413, "compression_ratio": 1.5576036866359446, "no_speech_prob": 3.5553127872844925e-06}, {"id": 26, "seek": 8228, "start": 99.04, "end": 101.1, "text": " And that convinced me to become a data scientist.", "tokens": [400, 300, 12561, 385, 281, 1813, 257, 1412, 12662, 13], "temperature": 0.0, "avg_logprob": -0.20700510025024413, "compression_ratio": 1.5576036866359446, "no_speech_prob": 3.5553127872844925e-06}, {"id": 27, "seek": 8228, "start": 101.1, "end": 102.54, "text": " I was at Uber.", "tokens": [286, 390, 412, 21839, 13], "temperature": 0.0, "avg_logprob": -0.20700510025024413, "compression_ratio": 1.5576036866359446, "no_speech_prob": 3.5553127872844925e-06}, {"id": 28, "seek": 8228, "start": 102.54, "end": 105.14, "text": " And I taught software engineering at Hackbrite.", "tokens": [400, 286, 5928, 4722, 7043, 412, 35170, 1443, 642, 13], "temperature": 0.0, "avg_logprob": -0.20700510025024413, "compression_ratio": 1.5576036866359446, "no_speech_prob": 3.5553127872844925e-06}, {"id": 29, "seek": 8228, "start": 105.14, "end": 108.28, "text": " That's... It was mostly software development.", "tokens": [663, 311, 485, 467, 390, 5240, 4722, 3250, 13], "temperature": 0.0, "avg_logprob": -0.20700510025024413, "compression_ratio": 1.5576036866359446, "no_speech_prob": 3.5553127872844925e-06}, {"id": 30, "seek": 10828, "start": 108.28, "end": 113.4, "text": " I did get to overhaul their machine learning and collaborative filtering lectures, which was exciting.", "tokens": [286, 630, 483, 281, 670, 39423, 641, 3479, 2539, 293, 16555, 30822, 16564, 11, 597, 390, 4670, 13], "temperature": 0.0, "avg_logprob": -0.13928963343302408, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.425091901794076e-06}, {"id": 31, "seek": 10828, "start": 113.4, "end": 121.0, "text": " And then one year ago, Jeremy and I started Fast AI to kind of make deep learning easier to use.", "tokens": [400, 550, 472, 1064, 2057, 11, 17809, 293, 286, 1409, 15968, 7318, 281, 733, 295, 652, 2452, 2539, 3571, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.13928963343302408, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.425091901794076e-06}, {"id": 32, "seek": 10828, "start": 121.0, "end": 126.58, "text": " Yeah, so going into teaching, this is a different...", "tokens": [865, 11, 370, 516, 666, 4571, 11, 341, 307, 257, 819, 485], "temperature": 0.0, "avg_logprob": -0.13928963343302408, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.425091901794076e-06}, {"id": 33, "seek": 10828, "start": 126.58, "end": 128.54, "text": " It's a different approach than most math courses.", "tokens": [467, 311, 257, 819, 3109, 813, 881, 5221, 7712, 13], "temperature": 0.0, "avg_logprob": -0.13928963343302408, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.425091901794076e-06}, {"id": 34, "seek": 10828, "start": 128.54, "end": 130.28, "text": " It's going to be top down.", "tokens": [467, 311, 516, 281, 312, 1192, 760, 13], "temperature": 0.0, "avg_logprob": -0.13928963343302408, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.425091901794076e-06}, {"id": 35, "seek": 10828, "start": 130.28, "end": 134.98, "text": " So in a bottom-up approach, which is kind of the more common one in math,", "tokens": [407, 294, 257, 2767, 12, 1010, 3109, 11, 597, 307, 733, 295, 264, 544, 2689, 472, 294, 5221, 11], "temperature": 0.0, "avg_logprob": -0.13928963343302408, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.425091901794076e-06}, {"id": 36, "seek": 10828, "start": 134.98, "end": 138.14, "text": " that's where you first learn all these separate components that you'll need.", "tokens": [300, 311, 689, 291, 700, 1466, 439, 613, 4994, 6677, 300, 291, 603, 643, 13], "temperature": 0.0, "avg_logprob": -0.13928963343302408, "compression_ratio": 1.6551724137931034, "no_speech_prob": 4.425091901794076e-06}, {"id": 37, "seek": 13814, "start": 138.14, "end": 143.98, "text": " And then you kind of build things of increasing complexity as time goes on and you know more components.", "tokens": [400, 550, 291, 733, 295, 1322, 721, 295, 5662, 14024, 382, 565, 1709, 322, 293, 291, 458, 544, 6677, 13], "temperature": 0.0, "avg_logprob": -0.10908897399902344, "compression_ratio": 1.7182130584192439, "no_speech_prob": 2.2954957330512116e-06}, {"id": 38, "seek": 13814, "start": 143.98, "end": 146.98, "text": " And that's kind of tough because people lose motivation.", "tokens": [400, 300, 311, 733, 295, 4930, 570, 561, 3624, 12335, 13], "temperature": 0.0, "avg_logprob": -0.10908897399902344, "compression_ratio": 1.7182130584192439, "no_speech_prob": 2.2954957330512116e-06}, {"id": 39, "seek": 13814, "start": 146.98, "end": 149.33999999999997, "text": " They don't have a sense of the big picture.", "tokens": [814, 500, 380, 362, 257, 2020, 295, 264, 955, 3036, 13], "temperature": 0.0, "avg_logprob": -0.10908897399902344, "compression_ratio": 1.7182130584192439, "no_speech_prob": 2.2954957330512116e-06}, {"id": 40, "seek": 13814, "start": 149.33999999999997, "end": 155.33999999999997, "text": " And what I'll be doing instead is kind of starting with kind of doing interesting things using algorithms.", "tokens": [400, 437, 286, 603, 312, 884, 2602, 307, 733, 295, 2891, 365, 733, 295, 884, 1880, 721, 1228, 14642, 13], "temperature": 0.0, "avg_logprob": -0.10908897399902344, "compression_ratio": 1.7182130584192439, "no_speech_prob": 2.2954957330512116e-06}, {"id": 41, "seek": 13814, "start": 155.33999999999997, "end": 159.94, "text": " And then we'll kind of go into more depth and break down the pieces.", "tokens": [400, 550, 321, 603, 733, 295, 352, 666, 544, 7161, 293, 1821, 760, 264, 3755, 13], "temperature": 0.0, "avg_logprob": -0.10908897399902344, "compression_ratio": 1.7182130584192439, "no_speech_prob": 2.2954957330512116e-06}, {"id": 42, "seek": 13814, "start": 159.94, "end": 161.54, "text": " And I apologize if you heard.", "tokens": [400, 286, 12328, 498, 291, 2198, 13], "temperature": 0.0, "avg_logprob": -0.10908897399902344, "compression_ratio": 1.7182130584192439, "no_speech_prob": 2.2954957330512116e-06}, {"id": 43, "seek": 13814, "start": 161.54, "end": 163.79999999999998, "text": " I gave a talk on this at the Friday seminar a few weeks ago.", "tokens": [286, 2729, 257, 751, 322, 341, 412, 264, 6984, 29235, 257, 1326, 3259, 2057, 13], "temperature": 0.0, "avg_logprob": -0.10908897399902344, "compression_ratio": 1.7182130584192439, "no_speech_prob": 2.2954957330512116e-06}, {"id": 44, "seek": 13814, "start": 163.79999999999998, "end": 166.73999999999998, "text": " So sorry if this is repeat.", "tokens": [407, 2597, 498, 341, 307, 7149, 13], "temperature": 0.0, "avg_logprob": -0.10908897399902344, "compression_ratio": 1.7182130584192439, "no_speech_prob": 2.2954957330512116e-06}, {"id": 45, "seek": 16674, "start": 166.74, "end": 172.84, "text": " But there's a wonderful book called Making Learning Whole where a Harvard professor uses an analogy with baseball and says,", "tokens": [583, 456, 311, 257, 3715, 1446, 1219, 14595, 15205, 30336, 689, 257, 13378, 8304, 4960, 364, 21663, 365, 14323, 293, 1619, 11], "temperature": 0.0, "avg_logprob": -0.10678672790527344, "compression_ratio": 1.7040816326530612, "no_speech_prob": 1.902976123346889e-06}, {"id": 46, "seek": 16674, "start": 172.84, "end": 178.84, "text": " you know, we don't require kids to memorize all the formal rules of baseball before they're allowed to play.", "tokens": [291, 458, 11, 321, 500, 380, 3651, 2301, 281, 27478, 439, 264, 9860, 4474, 295, 14323, 949, 436, 434, 4350, 281, 862, 13], "temperature": 0.0, "avg_logprob": -0.10678672790527344, "compression_ratio": 1.7040816326530612, "no_speech_prob": 1.902976123346889e-06}, {"id": 47, "seek": 16674, "start": 178.84, "end": 184.14000000000001, "text": " You know, we let them play and then over time they learn more and more of the formal rules.", "tokens": [509, 458, 11, 321, 718, 552, 862, 293, 550, 670, 565, 436, 1466, 544, 293, 544, 295, 264, 9860, 4474, 13], "temperature": 0.0, "avg_logprob": -0.10678672790527344, "compression_ratio": 1.7040816326530612, "no_speech_prob": 1.902976123346889e-06}, {"id": 48, "seek": 16674, "start": 184.14000000000001, "end": 188.08, "text": " Yeah, and so kind of don't worry if at first you don't understand everything that's going on.", "tokens": [865, 11, 293, 370, 733, 295, 500, 380, 3292, 498, 412, 700, 291, 500, 380, 1223, 1203, 300, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.10678672790527344, "compression_ratio": 1.7040816326530612, "no_speech_prob": 1.902976123346889e-06}, {"id": 49, "seek": 16674, "start": 188.08, "end": 189.84, "text": " That's kind of the point.", "tokens": [663, 311, 733, 295, 264, 935, 13], "temperature": 0.0, "avg_logprob": -0.10678672790527344, "compression_ratio": 1.7040816326530612, "no_speech_prob": 1.902976123346889e-06}, {"id": 50, "seek": 16674, "start": 189.84, "end": 193.58, "text": " And focus on what things do as opposed to what they are.", "tokens": [400, 1879, 322, 437, 721, 360, 382, 8851, 281, 437, 436, 366, 13], "temperature": 0.0, "avg_logprob": -0.10678672790527344, "compression_ratio": 1.7040816326530612, "no_speech_prob": 1.902976123346889e-06}, {"id": 51, "seek": 19358, "start": 193.58, "end": 199.88000000000002, "text": " So with these matrix decompositions, it's really important to know what type of matrices are you getting back from the decomposition?", "tokens": [407, 365, 613, 8141, 22867, 329, 2451, 11, 309, 311, 534, 1021, 281, 458, 437, 2010, 295, 32284, 366, 291, 1242, 646, 490, 264, 48356, 30], "temperature": 0.0, "avg_logprob": -0.09768836781129998, "compression_ratio": 1.5667870036101084, "no_speech_prob": 3.2056516374723287e-07}, {"id": 52, "seek": 19358, "start": 199.88000000000002, "end": 203.78, "text": " And then over time, we'll kind of get into how would you program them.", "tokens": [400, 550, 670, 565, 11, 321, 603, 733, 295, 483, 666, 577, 576, 291, 1461, 552, 13], "temperature": 0.0, "avg_logprob": -0.09768836781129998, "compression_ratio": 1.5667870036101084, "no_speech_prob": 3.2056516374723287e-07}, {"id": 53, "seek": 19358, "start": 203.78, "end": 206.98000000000002, "text": " So for the course, I have two textbooks.", "tokens": [407, 337, 264, 1164, 11, 286, 362, 732, 33587, 13], "temperature": 0.0, "avg_logprob": -0.09768836781129998, "compression_ratio": 1.5667870036101084, "no_speech_prob": 3.2056516374723287e-07}, {"id": 54, "seek": 19358, "start": 206.98000000000002, "end": 208.54000000000002, "text": " Neither of these is required.", "tokens": [23956, 295, 613, 307, 4739, 13], "temperature": 0.0, "avg_logprob": -0.09768836781129998, "compression_ratio": 1.5667870036101084, "no_speech_prob": 3.2056516374723287e-07}, {"id": 55, "seek": 19358, "start": 208.54000000000002, "end": 212.88000000000002, "text": " And I've asked Kirsten to buy a few copies to have on hand.", "tokens": [400, 286, 600, 2351, 591, 653, 268, 281, 2256, 257, 1326, 14341, 281, 362, 322, 1011, 13], "temperature": 0.0, "avg_logprob": -0.09768836781129998, "compression_ratio": 1.5667870036101084, "no_speech_prob": 3.2056516374723287e-07}, {"id": 56, "seek": 19358, "start": 212.88000000000002, "end": 218.24, "text": " So my number one choice is Numerical Linear Algebra by Trevathan.", "tokens": [407, 452, 1230, 472, 3922, 307, 426, 15583, 804, 14670, 289, 967, 19983, 538, 8648, 85, 9390, 13], "temperature": 0.0, "avg_logprob": -0.09768836781129998, "compression_ratio": 1.5667870036101084, "no_speech_prob": 3.2056516374723287e-07}, {"id": 57, "seek": 19358, "start": 218.24, "end": 220.44, "text": " It's a really well written book.", "tokens": [467, 311, 257, 534, 731, 3720, 1446, 13], "temperature": 0.0, "avg_logprob": -0.09768836781129998, "compression_ratio": 1.5667870036101084, "no_speech_prob": 3.2056516374723287e-07}, {"id": 58, "seek": 22044, "start": 220.44, "end": 224.04, "text": " And I'll say kind of when I'm referencing parts of it.", "tokens": [400, 286, 603, 584, 733, 295, 562, 286, 478, 40582, 3166, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.11479262935305104, "compression_ratio": 1.6653386454183268, "no_speech_prob": 2.1143749862062577e-08}, {"id": 59, "seek": 22044, "start": 224.04, "end": 230.78, "text": " And then kind of a secondary book that I liked is Numerical Methods by Greenbaum and Chartier.", "tokens": [400, 550, 733, 295, 257, 11396, 1446, 300, 286, 4501, 307, 426, 15583, 804, 25285, 82, 538, 6969, 46641, 293, 49762, 811, 13], "temperature": 0.0, "avg_logprob": -0.11479262935305104, "compression_ratio": 1.6653386454183268, "no_speech_prob": 2.1143749862062577e-08}, {"id": 60, "seek": 22044, "start": 230.78, "end": 235.78, "text": " And this is actually intended for kind of senior undergrad courses.", "tokens": [400, 341, 307, 767, 10226, 337, 733, 295, 7965, 14295, 7712, 13], "temperature": 0.0, "avg_logprob": -0.11479262935305104, "compression_ratio": 1.6653386454183268, "no_speech_prob": 2.1143749862062577e-08}, {"id": 61, "seek": 22044, "start": 235.78, "end": 241.68, "text": " And it includes numerical linear algebra, but it also includes Monte Carlo methods, numerical differentiation.", "tokens": [400, 309, 5974, 29054, 8213, 21989, 11, 457, 309, 611, 5974, 38105, 45112, 7150, 11, 29054, 38902, 13], "temperature": 0.0, "avg_logprob": -0.11479262935305104, "compression_ratio": 1.6653386454183268, "no_speech_prob": 2.1143749862062577e-08}, {"id": 62, "seek": 22044, "start": 241.68, "end": 245.68, "text": " I think it's a really interesting book and it has a lot of applications.", "tokens": [286, 519, 309, 311, 257, 534, 1880, 1446, 293, 309, 575, 257, 688, 295, 5821, 13], "temperature": 0.0, "avg_logprob": -0.11479262935305104, "compression_ratio": 1.6653386454183268, "no_speech_prob": 2.1143749862062577e-08}, {"id": 63, "seek": 22044, "start": 245.68, "end": 247.78, "text": " It's a fun fact.", "tokens": [467, 311, 257, 1019, 1186, 13], "temperature": 0.0, "avg_logprob": -0.11479262935305104, "compression_ratio": 1.6653386454183268, "no_speech_prob": 2.1143749862062577e-08}, {"id": 64, "seek": 24778, "start": 247.78, "end": 254.84, "text": " Chartier is actually he's a math professor, but he trained as a mime under Marcel Marceau.", "tokens": [49762, 811, 307, 767, 415, 311, 257, 5221, 8304, 11, 457, 415, 8895, 382, 257, 275, 1312, 833, 34738, 2039, 384, 1459, 13], "temperature": 0.0, "avg_logprob": -0.11986135594985065, "compression_ratio": 1.5097087378640777, "no_speech_prob": 1.1724702062565484e-06}, {"id": 65, "seek": 24778, "start": 254.84, "end": 263.64, "text": " And I saw him perform at a math conference on how to kind of use miming to teach math.", "tokens": [400, 286, 1866, 796, 2042, 412, 257, 5221, 7586, 322, 577, 281, 733, 295, 764, 12247, 278, 281, 2924, 5221, 13], "temperature": 0.0, "avg_logprob": -0.11986135594985065, "compression_ratio": 1.5097087378640777, "no_speech_prob": 1.1724702062565484e-06}, {"id": 66, "seek": 24778, "start": 263.64, "end": 268.88, "text": " But it's a very kind of accessible book.", "tokens": [583, 309, 311, 257, 588, 733, 295, 9515, 1446, 13], "temperature": 0.0, "avg_logprob": -0.11986135594985065, "compression_ratio": 1.5097087378640777, "no_speech_prob": 1.1724702062565484e-06}, {"id": 67, "seek": 24778, "start": 268.88, "end": 274.84000000000003, "text": " So I was going to hold office hours from two to four on Friday afternoons after the seminar.", "tokens": [407, 286, 390, 516, 281, 1797, 3398, 2496, 490, 732, 281, 1451, 322, 6984, 934, 1771, 892, 934, 264, 29235, 13], "temperature": 0.0, "avg_logprob": -0.11986135594985065, "compression_ratio": 1.5097087378640777, "no_speech_prob": 1.1724702062565484e-06}, {"id": 68, "seek": 27484, "start": 274.84, "end": 279.14, "text": " If that doesn't work, feel free to email me about another time.", "tokens": [759, 300, 1177, 380, 589, 11, 841, 1737, 281, 3796, 385, 466, 1071, 565, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 69, "seek": 27484, "start": 279.14, "end": 281.53999999999996, "text": " Yeah, my email is Rachel at fast.ai.", "tokens": [865, 11, 452, 3796, 307, 14246, 412, 2370, 13, 1301, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 70, "seek": 27484, "start": 281.53999999999996, "end": 285.94, "text": " And there's a class Slack channel, although I haven't done anything with that yet.", "tokens": [400, 456, 311, 257, 1508, 37211, 2269, 11, 4878, 286, 2378, 380, 1096, 1340, 365, 300, 1939, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 71, "seek": 27484, "start": 285.94, "end": 289.67999999999995, "text": " But I'll send you invites.", "tokens": [583, 286, 603, 2845, 291, 35719, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 72, "seek": 27484, "start": 289.67999999999995, "end": 291.12, "text": " There's the link for the GitHub.", "tokens": [821, 311, 264, 2113, 337, 264, 23331, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 73, "seek": 27484, "start": 291.12, "end": 292.28, "text": " Oh, and I wanted to.", "tokens": [876, 11, 293, 286, 1415, 281, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 74, "seek": 27484, "start": 292.28, "end": 294.28, "text": " So this is important to note.", "tokens": [407, 341, 307, 1021, 281, 3637, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 75, "seek": 27484, "start": 294.28, "end": 299.52, "text": " Kind of a difficult thing about Jupyter Notebooks is even just running them changes the code.", "tokens": [9242, 295, 257, 2252, 551, 466, 22125, 88, 391, 11633, 15170, 307, 754, 445, 2614, 552, 2962, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 76, "seek": 27484, "start": 299.52, "end": 304.32, "text": " And so you can get merge conflicts if you've cloned the repository.", "tokens": [400, 370, 291, 393, 483, 22183, 19807, 498, 291, 600, 596, 19009, 264, 25841, 13], "temperature": 0.0, "avg_logprob": -0.15173998475074768, "compression_ratio": 1.5457627118644068, "no_speech_prob": 6.642250355071155e-06}, {"id": 77, "seek": 30432, "start": 304.32, "end": 307.02, "text": " And so it's up to you if you want to deal with those or it might just be easier to kind", "tokens": [400, 370, 309, 311, 493, 281, 291, 498, 291, 528, 281, 2028, 365, 729, 420, 309, 1062, 445, 312, 3571, 281, 733], "temperature": 0.0, "avg_logprob": -0.15960298373004583, "compression_ratio": 1.6464646464646464, "no_speech_prob": 3.412381488487881e-07}, {"id": 78, "seek": 30432, "start": 307.02, "end": 308.71999999999997, "text": " of download the notebooks.", "tokens": [295, 5484, 264, 43782, 13], "temperature": 0.0, "avg_logprob": -0.15960298373004583, "compression_ratio": 1.6464646464646464, "no_speech_prob": 3.412381488487881e-07}, {"id": 79, "seek": 30432, "start": 308.71999999999997, "end": 311.52, "text": " And there are places that I kind of leave blank for exercises.", "tokens": [400, 456, 366, 3190, 300, 286, 733, 295, 1856, 8247, 337, 11900, 13], "temperature": 0.0, "avg_logprob": -0.15960298373004583, "compression_ratio": 1.6464646464646464, "no_speech_prob": 3.412381488487881e-07}, {"id": 80, "seek": 30432, "start": 311.52, "end": 316.71999999999997, "text": " So the idea is you will be doing some coding in them as well.", "tokens": [407, 264, 1558, 307, 291, 486, 312, 884, 512, 17720, 294, 552, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.15960298373004583, "compression_ratio": 1.6464646464646464, "no_speech_prob": 3.412381488487881e-07}, {"id": 81, "seek": 30432, "start": 316.71999999999997, "end": 323.58, "text": " And I just included these to check if you have Mathjacks running, which renders LaTeX.", "tokens": [400, 286, 445, 5556, 613, 281, 1520, 498, 291, 362, 15776, 73, 7424, 2614, 11, 597, 6125, 433, 2369, 14233, 55, 13], "temperature": 0.0, "avg_logprob": -0.15960298373004583, "compression_ratio": 1.6464646464646464, "no_speech_prob": 3.412381488487881e-07}, {"id": 82, "seek": 30432, "start": 323.58, "end": 327.32, "text": " And I believe if you're using Anaconda, that's automatically installed.", "tokens": [400, 286, 1697, 498, 291, 434, 1228, 1107, 326, 12233, 11, 300, 311, 6772, 8899, 13], "temperature": 0.0, "avg_logprob": -0.15960298373004583, "compression_ratio": 1.6464646464646464, "no_speech_prob": 3.412381488487881e-07}, {"id": 83, "seek": 30432, "start": 327.32, "end": 333.02, "text": " But let me definitely let me know in sooner rather than later if you're having any trouble", "tokens": [583, 718, 385, 2138, 718, 385, 458, 294, 15324, 2831, 813, 1780, 498, 291, 434, 1419, 604, 5253], "temperature": 0.0, "avg_logprob": -0.15960298373004583, "compression_ratio": 1.6464646464646464, "no_speech_prob": 3.412381488487881e-07}, {"id": 84, "seek": 33302, "start": 333.02, "end": 337.96, "text": " with the setup for this or any of the imports or anything, because I definitely want you", "tokens": [365, 264, 8657, 337, 341, 420, 604, 295, 264, 41596, 420, 1340, 11, 570, 286, 2138, 528, 291], "temperature": 0.0, "avg_logprob": -0.23658849882042926, "compression_ratio": 1.6009174311926606, "no_speech_prob": 7.337783927141572e-07}, {"id": 85, "seek": 33302, "start": 337.96, "end": 340.76, "text": " to be able to run these notebooks at home.", "tokens": [281, 312, 1075, 281, 1190, 613, 43782, 412, 1280, 13], "temperature": 0.0, "avg_logprob": -0.23658849882042926, "compression_ratio": 1.6009174311926606, "no_speech_prob": 7.337783927141572e-07}, {"id": 86, "seek": 33302, "start": 340.76, "end": 346.4, "text": " So here is a actually I should check any questions so far.", "tokens": [407, 510, 307, 257, 767, 286, 820, 1520, 604, 1651, 370, 1400, 13], "temperature": 0.0, "avg_logprob": -0.23658849882042926, "compression_ratio": 1.6009174311926606, "no_speech_prob": 7.337783927141572e-07}, {"id": 87, "seek": 33302, "start": 346.4, "end": 351.12, "text": " Okay, here's a grading room work.", "tokens": [1033, 11, 510, 311, 257, 35540, 1808, 589, 13], "temperature": 0.0, "avg_logprob": -0.23658849882042926, "compression_ratio": 1.6009174311926606, "no_speech_prob": 7.337783927141572e-07}, {"id": 88, "seek": 33302, "start": 351.12, "end": 356.94, "text": " So there'll be some homework assignments and I'll give you always a full week to do the", "tokens": [407, 456, 603, 312, 512, 14578, 22546, 293, 286, 603, 976, 291, 1009, 257, 1577, 1243, 281, 360, 264], "temperature": 0.0, "avg_logprob": -0.23658849882042926, "compression_ratio": 1.6009174311926606, "no_speech_prob": 7.337783927141572e-07}, {"id": 89, "seek": 33302, "start": 356.94, "end": 359.12, "text": " homework from when I when I give it.", "tokens": [14578, 490, 562, 286, 562, 286, 976, 309, 13], "temperature": 0.0, "avg_logprob": -0.23658849882042926, "compression_ratio": 1.6009174311926606, "no_speech_prob": 7.337783927141572e-07}, {"id": 90, "seek": 35912, "start": 359.12, "end": 363.72, "text": " I want there's a writing assignment for this course, and you can choose the topics and", "tokens": [286, 528, 456, 311, 257, 3579, 15187, 337, 341, 1164, 11, 293, 291, 393, 2826, 264, 8378, 293], "temperature": 0.0, "avg_logprob": -0.19493874332361055, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.653603703744011e-06}, {"id": 91, "seek": 35912, "start": 363.72, "end": 367.6, "text": " I'll say a little bit more about that in a moment.", "tokens": [286, 603, 584, 257, 707, 857, 544, 466, 300, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.19493874332361055, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.653603703744011e-06}, {"id": 92, "seek": 35912, "start": 367.6, "end": 371.2, "text": " But that's kind of broken into three pieces, just your proposal, your draft, and then the", "tokens": [583, 300, 311, 733, 295, 5463, 666, 1045, 3755, 11, 445, 428, 11494, 11, 428, 11206, 11, 293, 550, 264], "temperature": 0.0, "avg_logprob": -0.19493874332361055, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.653603703744011e-06}, {"id": 93, "seek": 35912, "start": 371.2, "end": 375.28000000000003, "text": " final and then there'll be a final exam.", "tokens": [2572, 293, 550, 456, 603, 312, 257, 2572, 1139, 13], "temperature": 0.0, "avg_logprob": -0.19493874332361055, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.653603703744011e-06}, {"id": 94, "seek": 35912, "start": 375.28000000000003, "end": 378.76, "text": " So no cheating or plagiarism is allowed.", "tokens": [407, 572, 18309, 420, 33756, 9448, 1434, 307, 4350, 13], "temperature": 0.0, "avg_logprob": -0.19493874332361055, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.653603703744011e-06}, {"id": 95, "seek": 35912, "start": 378.76, "end": 382.92, "text": " And you know, we have the standard honor code from USF, which I'm sure you're really familiar", "tokens": [400, 291, 458, 11, 321, 362, 264, 3832, 5968, 3089, 490, 2546, 37, 11, 597, 286, 478, 988, 291, 434, 534, 4963], "temperature": 0.0, "avg_logprob": -0.19493874332361055, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.653603703744011e-06}, {"id": 96, "seek": 35912, "start": 382.92, "end": 386.12, "text": " with from this point.", "tokens": [365, 490, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.19493874332361055, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.653603703744011e-06}, {"id": 97, "seek": 38612, "start": 386.12, "end": 391.68, "text": " For laptops, please avoid surfing the web or using social media or messaging during", "tokens": [1171, 27642, 11, 1767, 5042, 34181, 264, 3670, 420, 1228, 2093, 3021, 420, 21812, 1830], "temperature": 0.0, "avg_logprob": -0.23234026772635324, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.0579575448209653e-06}, {"id": 98, "seek": 38612, "start": 391.68, "end": 392.68, "text": " class.", "tokens": [1508, 13], "temperature": 0.0, "avg_logprob": -0.23234026772635324, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.0579575448209653e-06}, {"id": 99, "seek": 38612, "start": 392.68, "end": 393.68, "text": " Cool.", "tokens": [8561, 13], "temperature": 0.0, "avg_logprob": -0.23234026772635324, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.0579575448209653e-06}, {"id": 100, "seek": 38612, "start": 393.68, "end": 396.68, "text": " And then here's a syllabus.", "tokens": [400, 550, 510, 311, 257, 48077, 13], "temperature": 0.0, "avg_logprob": -0.23234026772635324, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.0579575448209653e-06}, {"id": 101, "seek": 38612, "start": 396.68, "end": 400.8, "text": " I'll just say kind of that.", "tokens": [286, 603, 445, 584, 733, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.23234026772635324, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.0579575448209653e-06}, {"id": 102, "seek": 38612, "start": 400.8, "end": 404.48, "text": " The way it'll work is kind of each lesson is mostly centered around an application and", "tokens": [440, 636, 309, 603, 589, 307, 733, 295, 1184, 6898, 307, 5240, 18988, 926, 364, 3861, 293], "temperature": 0.0, "avg_logprob": -0.23234026772635324, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.0579575448209653e-06}, {"id": 103, "seek": 38612, "start": 404.48, "end": 408.72, "text": " then we'll kind of dive into algorithms and tech or techniques that are used for that", "tokens": [550, 321, 603, 733, 295, 9192, 666, 14642, 293, 7553, 420, 7512, 300, 366, 1143, 337, 300], "temperature": 0.0, "avg_logprob": -0.23234026772635324, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.0579575448209653e-06}, {"id": 104, "seek": 38612, "start": 408.72, "end": 413.32, "text": " application but it's kind of this almost application first approach.", "tokens": [3861, 457, 309, 311, 733, 295, 341, 1920, 3861, 700, 3109, 13], "temperature": 0.0, "avg_logprob": -0.23234026772635324, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.0579575448209653e-06}, {"id": 105, "seek": 41332, "start": 413.32, "end": 417.32, "text": " So we have the introductory lesson, which is a little bit unusual and that'll be less", "tokens": [407, 321, 362, 264, 39048, 6898, 11, 597, 307, 257, 707, 857, 10901, 293, 300, 603, 312, 1570], "temperature": 0.0, "avg_logprob": -0.22545942418715534, "compression_ratio": 1.5404255319148936, "no_speech_prob": 3.7262107071001083e-06}, {"id": 106, "seek": 41332, "start": 417.32, "end": 420.64, "text": " code and is more kind of introducing concepts.", "tokens": [3089, 293, 307, 544, 733, 295, 15424, 10392, 13], "temperature": 0.0, "avg_logprob": -0.22545942418715534, "compression_ratio": 1.5404255319148936, "no_speech_prob": 3.7262107071001083e-06}, {"id": 107, "seek": 41332, "start": 420.64, "end": 427.04, "text": " But then we'll talk about topic modeling using NMF and SVD, background removal with robust", "tokens": [583, 550, 321, 603, 751, 466, 4829, 15983, 1228, 426, 44, 37, 293, 31910, 35, 11, 3678, 17933, 365, 13956], "temperature": 0.0, "avg_logprob": -0.22545942418715534, "compression_ratio": 1.5404255319148936, "no_speech_prob": 3.7262107071001083e-06}, {"id": 108, "seek": 41332, "start": 427.04, "end": 433.32, "text": " PCA, compressed sensing for CT scans, which are kind of some really interesting looking", "tokens": [6465, 32, 11, 30353, 30654, 337, 19529, 35116, 11, 597, 366, 733, 295, 512, 534, 1880, 1237], "temperature": 0.0, "avg_logprob": -0.22545942418715534, "compression_ratio": 1.5404255319148936, "no_speech_prob": 3.7262107071001083e-06}, {"id": 109, "seek": 41332, "start": 433.32, "end": 438.6, "text": " CT scan like pictures, predicting health outcomes.", "tokens": [19529, 11049, 411, 5242, 11, 32884, 1585, 10070, 13], "temperature": 0.0, "avg_logprob": -0.22545942418715534, "compression_ratio": 1.5404255319148936, "no_speech_prob": 3.7262107071001083e-06}, {"id": 110, "seek": 43860, "start": 438.6, "end": 444.68, "text": " This is on a diabetes data set, page rank to go through eigen decompositions and how", "tokens": [639, 307, 322, 257, 13881, 1412, 992, 11, 3028, 6181, 281, 352, 807, 10446, 22867, 329, 2451, 293, 577], "temperature": 0.0, "avg_logprob": -0.19427195633992111, "compression_ratio": 1.5099601593625498, "no_speech_prob": 6.276449653341842e-07}, {"id": 111, "seek": 43860, "start": 444.68, "end": 446.92, "text": " you program those.", "tokens": [291, 1461, 729, 13], "temperature": 0.0, "avg_logprob": -0.19427195633992111, "compression_ratio": 1.5099601593625498, "no_speech_prob": 6.276449653341842e-07}, {"id": 112, "seek": 43860, "start": 446.92, "end": 451.56, "text": " And then finally the QR factorization, which will have shown up in almost all of the previous", "tokens": [400, 550, 2721, 264, 32784, 5952, 2144, 11, 597, 486, 362, 4898, 493, 294, 1920, 439, 295, 264, 3894], "temperature": 0.0, "avg_logprob": -0.19427195633992111, "compression_ratio": 1.5099601593625498, "no_speech_prob": 6.276449653341842e-07}, {"id": 113, "seek": 43860, "start": 451.56, "end": 454.84000000000003, "text": " lessons as a tool.", "tokens": [8820, 382, 257, 2290, 13], "temperature": 0.0, "avg_logprob": -0.19427195633992111, "compression_ratio": 1.5099601593625498, "no_speech_prob": 6.276449653341842e-07}, {"id": 114, "seek": 43860, "start": 454.84000000000003, "end": 456.64000000000004, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.19427195633992111, "compression_ratio": 1.5099601593625498, "no_speech_prob": 6.276449653341842e-07}, {"id": 115, "seek": 43860, "start": 456.64000000000004, "end": 463.32000000000005, "text": " So about the writing assignment, yeah, writing about technical concepts is really valuable.", "tokens": [407, 466, 264, 3579, 15187, 11, 1338, 11, 3579, 466, 6191, 10392, 307, 534, 8263, 13], "temperature": 0.0, "avg_logprob": -0.19427195633992111, "compression_ratio": 1.5099601593625498, "no_speech_prob": 6.276449653341842e-07}, {"id": 116, "seek": 43860, "start": 463.32000000000005, "end": 465.64000000000004, "text": " I hope that you'll publish it as a blog post.", "tokens": [286, 1454, 300, 291, 603, 11374, 309, 382, 257, 6968, 2183, 13], "temperature": 0.0, "avg_logprob": -0.19427195633992111, "compression_ratio": 1.5099601593625498, "no_speech_prob": 6.276449653341842e-07}, {"id": 117, "seek": 43860, "start": 465.64000000000004, "end": 466.64000000000004, "text": " You don't have to.", "tokens": [509, 500, 380, 362, 281, 13], "temperature": 0.0, "avg_logprob": -0.19427195633992111, "compression_ratio": 1.5099601593625498, "no_speech_prob": 6.276449653341842e-07}, {"id": 118, "seek": 46664, "start": 466.64, "end": 471.24, "text": " If you do, it's a really good way to get your name out there, something to show to future", "tokens": [759, 291, 360, 11, 309, 311, 257, 534, 665, 636, 281, 483, 428, 1315, 484, 456, 11, 746, 281, 855, 281, 2027], "temperature": 0.0, "avg_logprob": -0.16521175234925514, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.578889492127928e-07}, {"id": 119, "seek": 46664, "start": 471.24, "end": 474.76, "text": " employers or when you're applying for jobs.", "tokens": [16744, 420, 562, 291, 434, 9275, 337, 4782, 13], "temperature": 0.0, "avg_logprob": -0.16521175234925514, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.578889492127928e-07}, {"id": 120, "seek": 46664, "start": 474.76, "end": 478.91999999999996, "text": " Technical writing is also important when you're creating documentation at work, kind of explaining", "tokens": [35512, 3579, 307, 611, 1021, 562, 291, 434, 4084, 14333, 412, 589, 11, 733, 295, 13468], "temperature": 0.0, "avg_logprob": -0.16521175234925514, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.578889492127928e-07}, {"id": 121, "seek": 46664, "start": 478.91999999999996, "end": 484.91999999999996, "text": " and sharing your ideas with coworkers, applying to speak at conferences, and practicing for", "tokens": [293, 5414, 428, 3487, 365, 43465, 11, 9275, 281, 1710, 412, 22032, 11, 293, 11350, 337], "temperature": 0.0, "avg_logprob": -0.16521175234925514, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.578889492127928e-07}, {"id": 122, "seek": 46664, "start": 484.91999999999996, "end": 490.0, "text": " interviews, kind of just even practicing like how do you explain what you're doing.", "tokens": [12318, 11, 733, 295, 445, 754, 11350, 411, 577, 360, 291, 2903, 437, 291, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.16521175234925514, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.578889492127928e-07}, {"id": 123, "seek": 46664, "start": 490.0, "end": 493.28, "text": " So I have a list of ideas.", "tokens": [407, 286, 362, 257, 1329, 295, 3487, 13], "temperature": 0.0, "avg_logprob": -0.16521175234925514, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.578889492127928e-07}, {"id": 124, "seek": 49328, "start": 493.28, "end": 502.11999999999995, "text": " Oh, and I actually, oh yeah, I might have an updated version.", "tokens": [876, 11, 293, 286, 767, 11, 1954, 1338, 11, 286, 1062, 362, 364, 10588, 3037, 13], "temperature": 0.0, "avg_logprob": -0.4785667887905188, "compression_ratio": 1.265625, "no_speech_prob": 1.362836792395683e-05}, {"id": 125, "seek": 49328, "start": 502.11999999999995, "end": 505.11999999999995, "text": " Hold on a moment.", "tokens": [6962, 322, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.4785667887905188, "compression_ratio": 1.265625, "no_speech_prob": 1.362836792395683e-05}, {"id": 126, "seek": 49328, "start": 505.11999999999995, "end": 510.11999999999995, "text": " Yeah, this is the old version.", "tokens": [865, 11, 341, 307, 264, 1331, 3037, 13], "temperature": 0.0, "avg_logprob": -0.4785667887905188, "compression_ratio": 1.265625, "no_speech_prob": 1.362836792395683e-05}, {"id": 127, "seek": 49328, "start": 510.11999999999995, "end": 517.16, "text": " Well, escape is not taking me out of F11.", "tokens": [1042, 11, 7615, 307, 406, 1940, 385, 484, 295, 479, 5348, 13], "temperature": 0.0, "avg_logprob": -0.4785667887905188, "compression_ratio": 1.265625, "no_speech_prob": 1.362836792395683e-05}, {"id": 128, "seek": 49328, "start": 517.16, "end": 520.16, "text": " Oh, okay.", "tokens": [876, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.4785667887905188, "compression_ratio": 1.265625, "no_speech_prob": 1.362836792395683e-05}, {"id": 129, "seek": 52016, "start": 520.16, "end": 526.8399999999999, "text": " Well, no, I'm running this from a different repository.", "tokens": [1042, 11, 572, 11, 286, 478, 2614, 341, 490, 257, 819, 25841, 13], "temperature": 0.0, "avg_logprob": -0.3746822902134487, "compression_ratio": 1.086021505376344, "no_speech_prob": 5.255089945421787e-06}, {"id": 130, "seek": 52016, "start": 526.8399999999999, "end": 531.64, "text": " Let me just go here.", "tokens": [961, 385, 445, 352, 510, 13], "temperature": 0.0, "avg_logprob": -0.3746822902134487, "compression_ratio": 1.086021505376344, "no_speech_prob": 5.255089945421787e-06}, {"id": 131, "seek": 52016, "start": 531.64, "end": 548.4399999999999, "text": " Oh no, that's the issue.", "tokens": [876, 572, 11, 300, 311, 264, 2734, 13], "temperature": 0.0, "avg_logprob": -0.3746822902134487, "compression_ratio": 1.086021505376344, "no_speech_prob": 5.255089945421787e-06}, {"id": 132, "seek": 54844, "start": 548.44, "end": 550.44, "text": " And with all these ideas, these are just suggestions.", "tokens": [400, 365, 439, 613, 3487, 11, 613, 366, 445, 13396, 13], "temperature": 0.0, "avg_logprob": -0.15970191955566407, "compression_ratio": 1.7340823970037453, "no_speech_prob": 8.138875273289159e-06}, {"id": 133, "seek": 54844, "start": 550.44, "end": 555.5200000000001, "text": " If you have a different idea that's not on the list, feel free to ask me about it.", "tokens": [759, 291, 362, 257, 819, 1558, 300, 311, 406, 322, 264, 1329, 11, 841, 1737, 281, 1029, 385, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.15970191955566407, "compression_ratio": 1.7340823970037453, "no_speech_prob": 8.138875273289159e-06}, {"id": 134, "seek": 54844, "start": 555.5200000000001, "end": 559.1600000000001, "text": " I really want it to be something that you're interested in learning more about.", "tokens": [286, 534, 528, 309, 281, 312, 746, 300, 291, 434, 3102, 294, 2539, 544, 466, 13], "temperature": 0.0, "avg_logprob": -0.15970191955566407, "compression_ratio": 1.7340823970037453, "no_speech_prob": 8.138875273289159e-06}, {"id": 135, "seek": 54844, "start": 559.1600000000001, "end": 568.0400000000001, "text": " So I have a list of, there are so many numerical in your algebra algorithms, and so we'll get", "tokens": [407, 286, 362, 257, 1329, 295, 11, 456, 366, 370, 867, 29054, 294, 428, 21989, 14642, 11, 293, 370, 321, 603, 483], "temperature": 0.0, "avg_logprob": -0.15970191955566407, "compression_ratio": 1.7340823970037453, "no_speech_prob": 8.138875273289159e-06}, {"id": 136, "seek": 54844, "start": 568.0400000000001, "end": 571.0, "text": " into most of the core ones, but there are a lot that we won't have time to cover, so", "tokens": [666, 881, 295, 264, 4965, 2306, 11, 457, 456, 366, 257, 688, 300, 321, 1582, 380, 362, 565, 281, 2060, 11, 370], "temperature": 0.0, "avg_logprob": -0.15970191955566407, "compression_ratio": 1.7340823970037453, "no_speech_prob": 8.138875273289159e-06}, {"id": 137, "seek": 54844, "start": 571.0, "end": 573.12, "text": " you could choose one of those.", "tokens": [291, 727, 2826, 472, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.15970191955566407, "compression_ratio": 1.7340823970037453, "no_speech_prob": 8.138875273289159e-06}, {"id": 138, "seek": 54844, "start": 573.12, "end": 575.6800000000001, "text": " So here's a list of several of them.", "tokens": [407, 510, 311, 257, 1329, 295, 2940, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.15970191955566407, "compression_ratio": 1.7340823970037453, "no_speech_prob": 8.138875273289159e-06}, {"id": 139, "seek": 57568, "start": 575.68, "end": 579.56, "text": " You could also speed up an algorithm of your choice, and that could either be something", "tokens": [509, 727, 611, 3073, 493, 364, 9284, 295, 428, 3922, 11, 293, 300, 727, 2139, 312, 746], "temperature": 0.0, "avg_logprob": -0.19372984627696954, "compression_ratio": 1.6296296296296295, "no_speech_prob": 3.0413946205953835e-06}, {"id": 140, "seek": 57568, "start": 579.56, "end": 585.3199999999999, "text": " that we've covered in the course or not, using the GPU and PyTorch, and we'll be talking", "tokens": [300, 321, 600, 5343, 294, 264, 1164, 420, 406, 11, 1228, 264, 18407, 293, 9953, 51, 284, 339, 11, 293, 321, 603, 312, 1417], "temperature": 0.0, "avg_logprob": -0.19372984627696954, "compression_ratio": 1.6296296296296295, "no_speech_prob": 3.0413946205953835e-06}, {"id": 141, "seek": 57568, "start": 585.3199999999999, "end": 587.92, "text": " about how to do that in the first lesson.", "tokens": [466, 577, 281, 360, 300, 294, 264, 700, 6898, 13], "temperature": 0.0, "avg_logprob": -0.19372984627696954, "compression_ratio": 1.6296296296296295, "no_speech_prob": 3.0413946205953835e-06}, {"id": 142, "seek": 57568, "start": 587.92, "end": 591.52, "text": " Number, Scython, which we'll cover.", "tokens": [5118, 11, 318, 1344, 11943, 11, 597, 321, 603, 2060, 13], "temperature": 0.0, "avg_logprob": -0.19372984627696954, "compression_ratio": 1.6296296296296295, "no_speech_prob": 3.0413946205953835e-06}, {"id": 143, "seek": 57568, "start": 591.52, "end": 594.64, "text": " Parallelization, or randomized projections.", "tokens": [3457, 336, 338, 2144, 11, 420, 38513, 32371, 13], "temperature": 0.0, "avg_logprob": -0.19372984627696954, "compression_ratio": 1.6296296296296295, "no_speech_prob": 3.0413946205953835e-06}, {"id": 144, "seek": 57568, "start": 594.64, "end": 599.52, "text": " So randomized algorithms are a really interesting area that give you a kind of a lot of speed", "tokens": [407, 38513, 14642, 366, 257, 534, 1880, 1859, 300, 976, 291, 257, 733, 295, 257, 688, 295, 3073], "temperature": 0.0, "avg_logprob": -0.19372984627696954, "compression_ratio": 1.6296296296296295, "no_speech_prob": 3.0413946205953835e-06}, {"id": 145, "seek": 57568, "start": 599.52, "end": 600.52, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.19372984627696954, "compression_ratio": 1.6296296296296295, "no_speech_prob": 3.0413946205953835e-06}, {"id": 146, "seek": 60052, "start": 600.52, "end": 605.72, "text": " You could also find an interesting academic paper that you've been wanting to read and", "tokens": [509, 727, 611, 915, 364, 1880, 7778, 3035, 300, 291, 600, 668, 7935, 281, 1401, 293], "temperature": 0.0, "avg_logprob": -0.16464596528273362, "compression_ratio": 1.538812785388128, "no_speech_prob": 5.2548593885148875e-06}, {"id": 147, "seek": 60052, "start": 605.72, "end": 608.4399999999999, "text": " summarize and implement it.", "tokens": [20858, 293, 4445, 309, 13], "temperature": 0.0, "avg_logprob": -0.16464596528273362, "compression_ratio": 1.538812785388128, "no_speech_prob": 5.2548593885148875e-06}, {"id": 148, "seek": 60052, "start": 608.4399999999999, "end": 611.92, "text": " And then here, actually let me go to this link, there's something called the matrix", "tokens": [400, 550, 510, 11, 767, 718, 385, 352, 281, 341, 2113, 11, 456, 311, 746, 1219, 264, 8141], "temperature": 0.0, "avg_logprob": -0.16464596528273362, "compression_ratio": 1.538812785388128, "no_speech_prob": 5.2548593885148875e-06}, {"id": 149, "seek": 60052, "start": 611.92, "end": 618.68, "text": " factorization jungle, which is just a handy webpage that someone put together with kind", "tokens": [5952, 2144, 18228, 11, 597, 307, 445, 257, 13239, 37852, 300, 1580, 829, 1214, 365, 733], "temperature": 0.0, "avg_logprob": -0.16464596528273362, "compression_ratio": 1.538812785388128, "no_speech_prob": 5.2548593885148875e-06}, {"id": 150, "seek": 60052, "start": 618.68, "end": 623.88, "text": " of a list of a ton of different matrix algorithms.", "tokens": [295, 257, 1329, 295, 257, 2952, 295, 819, 8141, 14642, 13], "temperature": 0.0, "avg_logprob": -0.16464596528273362, "compression_ratio": 1.538812785388128, "no_speech_prob": 5.2548593885148875e-06}, {"id": 151, "seek": 62388, "start": 623.88, "end": 630.88, "text": " And so if you scroll, they're kind of whole sections on different concepts.", "tokens": [400, 370, 498, 291, 11369, 11, 436, 434, 733, 295, 1379, 10863, 322, 819, 10392, 13], "temperature": 0.0, "avg_logprob": -0.29533164501190184, "compression_ratio": 1.4759358288770053, "no_speech_prob": 3.785165517911082e-06}, {"id": 152, "seek": 62388, "start": 630.88, "end": 632.92, "text": " Logistics.", "tokens": [10824, 6006, 13], "temperature": 0.0, "avg_logprob": -0.29533164501190184, "compression_ratio": 1.4759358288770053, "no_speech_prob": 3.785165517911082e-06}, {"id": 153, "seek": 62388, "start": 632.92, "end": 641.08, "text": " Oh, and then I posted a link to...", "tokens": [876, 11, 293, 550, 286, 9437, 257, 2113, 281, 485], "temperature": 0.0, "avg_logprob": -0.29533164501190184, "compression_ratio": 1.4759358288770053, "no_speech_prob": 3.785165517911082e-06}, {"id": 154, "seek": 62388, "start": 641.08, "end": 645.72, "text": " One other thing I wanted to say, so you can do your blog post or your writing assignment", "tokens": [1485, 661, 551, 286, 1415, 281, 584, 11, 370, 291, 393, 360, 428, 6968, 2183, 420, 428, 3579, 15187], "temperature": 0.0, "avg_logprob": -0.29533164501190184, "compression_ratio": 1.4759358288770053, "no_speech_prob": 3.785165517911082e-06}, {"id": 155, "seek": 62388, "start": 645.72, "end": 649.48, "text": " as a Jupyter Notebook, and you can also do it as a Kaggle kernel.", "tokens": [382, 257, 22125, 88, 391, 11633, 2939, 11, 293, 291, 393, 611, 360, 309, 382, 257, 48751, 22631, 28256, 13], "temperature": 0.0, "avg_logprob": -0.29533164501190184, "compression_ratio": 1.4759358288770053, "no_speech_prob": 3.785165517911082e-06}, {"id": 156, "seek": 64948, "start": 649.48, "end": 654.0, "text": " And you can, Kaggle kernels kind of are Jupyter Notebooks, but that's another kind of great", "tokens": [400, 291, 393, 11, 48751, 22631, 23434, 1625, 733, 295, 366, 22125, 88, 391, 11633, 15170, 11, 457, 300, 311, 1071, 733, 295, 869], "temperature": 0.0, "avg_logprob": -0.1457115056860538, "compression_ratio": 1.7785714285714285, "no_speech_prob": 3.500562570479815e-06}, {"id": 157, "seek": 64948, "start": 654.0, "end": 658.2, "text": " way to share your work, and you can also share data sets that way.", "tokens": [636, 281, 2073, 428, 589, 11, 293, 291, 393, 611, 2073, 1412, 6352, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.1457115056860538, "compression_ratio": 1.7785714285714285, "no_speech_prob": 3.500562570479815e-06}, {"id": 158, "seek": 64948, "start": 658.2, "end": 662.36, "text": " And then I've linked to several number of technical blog posts that I like.", "tokens": [400, 550, 286, 600, 9408, 281, 2940, 1230, 295, 6191, 6968, 12300, 300, 286, 411, 13], "temperature": 0.0, "avg_logprob": -0.1457115056860538, "compression_ratio": 1.7785714285714285, "no_speech_prob": 3.500562570479815e-06}, {"id": 159, "seek": 64948, "start": 662.36, "end": 667.36, "text": " And I think that's something that's kind of good to get into the habit of, and maybe after", "tokens": [400, 286, 519, 300, 311, 746, 300, 311, 733, 295, 665, 281, 483, 666, 264, 7164, 295, 11, 293, 1310, 934], "temperature": 0.0, "avg_logprob": -0.1457115056860538, "compression_ratio": 1.7785714285714285, "no_speech_prob": 3.500562570479815e-06}, {"id": 160, "seek": 64948, "start": 667.36, "end": 674.6, "text": " you graduate and have more time, but just kind of reading other people's blog post.", "tokens": [291, 8080, 293, 362, 544, 565, 11, 457, 445, 733, 295, 3760, 661, 561, 311, 6968, 2183, 13], "temperature": 0.0, "avg_logprob": -0.1457115056860538, "compression_ratio": 1.7785714285714285, "no_speech_prob": 3.500562570479815e-06}, {"id": 161, "seek": 64948, "start": 674.6, "end": 677.8000000000001, "text": " And so for the proposal, that's just gonna be a brief paragraph about what you wanna", "tokens": [400, 370, 337, 264, 11494, 11, 300, 311, 445, 799, 312, 257, 5353, 18865, 466, 437, 291, 1948], "temperature": 0.0, "avg_logprob": -0.1457115056860538, "compression_ratio": 1.7785714285714285, "no_speech_prob": 3.500562570479815e-06}, {"id": 162, "seek": 64948, "start": 677.8000000000001, "end": 678.8000000000001, "text": " do.", "tokens": [360, 13], "temperature": 0.0, "avg_logprob": -0.1457115056860538, "compression_ratio": 1.7785714285714285, "no_speech_prob": 3.500562570479815e-06}, {"id": 163, "seek": 67880, "start": 678.8, "end": 680.9599999999999, "text": " So I should also say, it could be like an experiment you wanna do.", "tokens": [407, 286, 820, 611, 584, 11, 309, 727, 312, 411, 364, 5120, 291, 1948, 360, 13], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 164, "seek": 67880, "start": 680.9599999999999, "end": 686.4799999999999, "text": " Like if you're curious, how does, I don't know, changing this factor affect this algorithm,", "tokens": [1743, 498, 291, 434, 6369, 11, 577, 775, 11, 286, 500, 380, 458, 11, 4473, 341, 5952, 3345, 341, 9284, 11], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 165, "seek": 67880, "start": 686.4799999999999, "end": 688.5999999999999, "text": " you can propose that.", "tokens": [291, 393, 17421, 300, 13], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 166, "seek": 67880, "start": 688.5999999999999, "end": 691.88, "text": " And then for sources.", "tokens": [400, 550, 337, 7139, 13], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 167, "seek": 67880, "start": 691.88, "end": 693.88, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 168, "seek": 67880, "start": 693.88, "end": 696.4799999999999, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 169, "seek": 67880, "start": 696.4799999999999, "end": 700.76, "text": " So I'll try to review some linear algebra in class.", "tokens": [407, 286, 603, 853, 281, 3131, 512, 8213, 21989, 294, 1508, 13], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 170, "seek": 67880, "start": 700.76, "end": 705.4, "text": " If there are things that you feel like you need extra review in, these are some resources", "tokens": [759, 456, 366, 721, 300, 291, 841, 411, 291, 643, 2857, 3131, 294, 11, 613, 366, 512, 3593], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 171, "seek": 67880, "start": 705.4, "end": 707.0, "text": " I recommend.", "tokens": [286, 2748, 13], "temperature": 0.0, "avg_logprob": -0.21441810244605655, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.994687181650079e-06}, {"id": 172, "seek": 70700, "start": 707.0, "end": 709.26, "text": " One is three blue, one brown.", "tokens": [1485, 307, 1045, 3344, 11, 472, 6292, 13], "temperature": 0.0, "avg_logprob": -0.1648437610039344, "compression_ratio": 1.58364312267658, "no_speech_prob": 1.7328645753877936e-06}, {"id": 173, "seek": 70700, "start": 709.26, "end": 714.0, "text": " This I would recommend to everybody for any reason.", "tokens": [639, 286, 576, 2748, 281, 2201, 337, 604, 1778, 13], "temperature": 0.0, "avg_logprob": -0.1648437610039344, "compression_ratio": 1.58364312267658, "no_speech_prob": 1.7328645753877936e-06}, {"id": 174, "seek": 70700, "start": 714.0, "end": 716.04, "text": " It's just the really fantastic videos.", "tokens": [467, 311, 445, 264, 534, 5456, 2145, 13], "temperature": 0.0, "avg_logprob": -0.1648437610039344, "compression_ratio": 1.58364312267658, "no_speech_prob": 1.7328645753877936e-06}, {"id": 175, "seek": 70700, "start": 716.04, "end": 723.68, "text": " And I'll probably show one in class in a later lesson, but it's a very, very kind of geometric", "tokens": [400, 286, 603, 1391, 855, 472, 294, 1508, 294, 257, 1780, 6898, 11, 457, 309, 311, 257, 588, 11, 588, 733, 295, 33246], "temperature": 0.0, "avg_logprob": -0.1648437610039344, "compression_ratio": 1.58364312267658, "no_speech_prob": 1.7328645753877936e-06}, {"id": 176, "seek": 70700, "start": 723.68, "end": 726.12, "text": " and visual perspective on linear algebra.", "tokens": [293, 5056, 4585, 322, 8213, 21989, 13], "temperature": 0.0, "avg_logprob": -0.1648437610039344, "compression_ratio": 1.58364312267658, "no_speech_prob": 1.7328645753877936e-06}, {"id": 177, "seek": 70700, "start": 726.12, "end": 729.88, "text": " And so it's very different from how most linear algebra courses are taught.", "tokens": [400, 370, 309, 311, 588, 819, 490, 577, 881, 8213, 21989, 7712, 366, 5928, 13], "temperature": 0.0, "avg_logprob": -0.1648437610039344, "compression_ratio": 1.58364312267658, "no_speech_prob": 1.7328645753877936e-06}, {"id": 178, "seek": 70700, "start": 729.88, "end": 736.2, "text": " The guy who created these wrote his own graphics library because he wanted to do things that", "tokens": [440, 2146, 567, 2942, 613, 4114, 702, 1065, 11837, 6405, 570, 415, 1415, 281, 360, 721, 300], "temperature": 0.0, "avg_logprob": -0.1648437610039344, "compression_ratio": 1.58364312267658, "no_speech_prob": 1.7328645753877936e-06}, {"id": 179, "seek": 73620, "start": 736.2, "end": 739.1600000000001, "text": " he wasn't able to do otherwise, but they're really beautiful.", "tokens": [415, 2067, 380, 1075, 281, 360, 5911, 11, 457, 436, 434, 534, 2238, 13], "temperature": 0.0, "avg_logprob": -0.25288552219427907, "compression_ratio": 1.5346153846153847, "no_speech_prob": 4.029073352285195e-06}, {"id": 180, "seek": 73620, "start": 739.1600000000001, "end": 748.6, "text": " And so if you're a visual learner, I would definitely recommend them.", "tokens": [400, 370, 498, 291, 434, 257, 5056, 33347, 11, 286, 576, 2138, 2748, 552, 13], "temperature": 0.0, "avg_logprob": -0.25288552219427907, "compression_ratio": 1.5346153846153847, "no_speech_prob": 4.029073352285195e-06}, {"id": 181, "seek": 73620, "start": 748.6, "end": 752.5600000000001, "text": " There's also an immersive linear algebra free online textbook.", "tokens": [821, 311, 611, 364, 35409, 8213, 21989, 1737, 2950, 25591, 13], "temperature": 0.0, "avg_logprob": -0.25288552219427907, "compression_ratio": 1.5346153846153847, "no_speech_prob": 4.029073352285195e-06}, {"id": 182, "seek": 73620, "start": 752.5600000000001, "end": 755.84, "text": " Chapter two of Ian Goodfellow's Deep Learning Book is all about linear algebra.", "tokens": [18874, 732, 295, 19595, 2205, 69, 21348, 311, 14895, 15205, 9476, 307, 439, 466, 8213, 21989, 13], "temperature": 0.0, "avg_logprob": -0.25288552219427907, "compression_ratio": 1.5346153846153847, "no_speech_prob": 4.029073352285195e-06}, {"id": 183, "seek": 73620, "start": 755.84, "end": 758.84, "text": " And that's kind of coming from a machine learning perspective.", "tokens": [400, 300, 311, 733, 295, 1348, 490, 257, 3479, 2539, 4585, 13], "temperature": 0.0, "avg_logprob": -0.25288552219427907, "compression_ratio": 1.5346153846153847, "no_speech_prob": 4.029073352285195e-06}, {"id": 184, "seek": 73620, "start": 758.84, "end": 761.5600000000001, "text": " Yes, I think that's it.", "tokens": [1079, 11, 286, 519, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.25288552219427907, "compression_ratio": 1.5346153846153847, "no_speech_prob": 4.029073352285195e-06}, {"id": 185, "seek": 73620, "start": 761.5600000000001, "end": 764.9200000000001, "text": " So then the USF policies are in here.", "tokens": [407, 550, 264, 2546, 37, 7657, 366, 294, 510, 13], "temperature": 0.0, "avg_logprob": -0.25288552219427907, "compression_ratio": 1.5346153846153847, "no_speech_prob": 4.029073352285195e-06}, {"id": 186, "seek": 76492, "start": 764.92, "end": 771.88, "text": " But again, you should have seen these, I think, in most of your courses about academic integrity,", "tokens": [583, 797, 11, 291, 820, 362, 1612, 613, 11, 286, 519, 11, 294, 881, 295, 428, 7712, 466, 7778, 16000, 11], "temperature": 0.0, "avg_logprob": -0.210438659225685, "compression_ratio": 1.5, "no_speech_prob": 7.410569196508732e-06}, {"id": 187, "seek": 76492, "start": 771.88, "end": 776.04, "text": " accommodations for disabilities, and so on.", "tokens": [38907, 337, 13367, 11, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.210438659225685, "compression_ratio": 1.5, "no_speech_prob": 7.410569196508732e-06}, {"id": 188, "seek": 76492, "start": 776.04, "end": 788.24, "text": " All right, you guys ready for the first lesson?", "tokens": [1057, 558, 11, 291, 1074, 1919, 337, 264, 700, 6898, 30], "temperature": 0.0, "avg_logprob": -0.210438659225685, "compression_ratio": 1.5, "no_speech_prob": 7.410569196508732e-06}, {"id": 189, "seek": 76492, "start": 788.24, "end": 793.4399999999999, "text": " And again, this is going to be less code full than future lessons, but it introduces some", "tokens": [400, 797, 11, 341, 307, 516, 281, 312, 1570, 3089, 1577, 813, 2027, 8820, 11, 457, 309, 31472, 512], "temperature": 0.0, "avg_logprob": -0.210438659225685, "compression_ratio": 1.5, "no_speech_prob": 7.410569196508732e-06}, {"id": 190, "seek": 79344, "start": 793.44, "end": 797.24, "text": " really interesting concepts, I think.", "tokens": [534, 1880, 10392, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.1731310132183606, "compression_ratio": 1.5396039603960396, "no_speech_prob": 8.397159035666846e-06}, {"id": 191, "seek": 79344, "start": 797.24, "end": 800.12, "text": " So kind of why are we setting this?", "tokens": [407, 733, 295, 983, 366, 321, 3287, 341, 30], "temperature": 0.0, "avg_logprob": -0.1731310132183606, "compression_ratio": 1.5396039603960396, "no_speech_prob": 8.397159035666846e-06}, {"id": 192, "seek": 79344, "start": 800.12, "end": 804.36, "text": " Let me go back to full screen.", "tokens": [961, 385, 352, 646, 281, 1577, 2568, 13], "temperature": 0.0, "avg_logprob": -0.1731310132183606, "compression_ratio": 1.5396039603960396, "no_speech_prob": 8.397159035666846e-06}, {"id": 193, "seek": 79344, "start": 804.36, "end": 809.72, "text": " So the key question of this course is how can we do matrix computations with acceptable", "tokens": [407, 264, 2141, 1168, 295, 341, 1164, 307, 577, 393, 321, 360, 8141, 2807, 763, 365, 15513], "temperature": 0.0, "avg_logprob": -0.1731310132183606, "compression_ratio": 1.5396039603960396, "no_speech_prob": 8.397159035666846e-06}, {"id": 194, "seek": 79344, "start": 809.72, "end": 812.9200000000001, "text": " speed and acceptable accuracy?", "tokens": [3073, 293, 15513, 14170, 30], "temperature": 0.0, "avg_logprob": -0.1731310132183606, "compression_ratio": 1.5396039603960396, "no_speech_prob": 8.397159035666846e-06}, {"id": 195, "seek": 79344, "start": 812.9200000000001, "end": 819.08, "text": " And this is from a news algorithm, or not a news algorithm, a journal article that came", "tokens": [400, 341, 307, 490, 257, 2583, 9284, 11, 420, 406, 257, 2583, 9284, 11, 257, 6708, 7222, 300, 1361], "temperature": 0.0, "avg_logprob": -0.1731310132183606, "compression_ratio": 1.5396039603960396, "no_speech_prob": 8.397159035666846e-06}, {"id": 196, "seek": 81908, "start": 819.08, "end": 823.8000000000001, "text": " up with the top 10 algorithms of science and engineering during the 20th century.", "tokens": [493, 365, 264, 1192, 1266, 14642, 295, 3497, 293, 7043, 1830, 264, 945, 392, 4901, 13], "temperature": 0.0, "avg_logprob": -0.13081262549575495, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.637325218936894e-06}, {"id": 197, "seek": 81908, "start": 823.8000000000001, "end": 828.96, "text": " And three of the things on the list we'll cover in this course, which is exciting.", "tokens": [400, 1045, 295, 264, 721, 322, 264, 1329, 321, 603, 2060, 294, 341, 1164, 11, 597, 307, 4670, 13], "temperature": 0.0, "avg_logprob": -0.13081262549575495, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.637325218936894e-06}, {"id": 198, "seek": 81908, "start": 828.96, "end": 833.9200000000001, "text": " And one is the idea of matrix decompositions as an approach to linear algebra itself, because", "tokens": [400, 472, 307, 264, 1558, 295, 8141, 22867, 329, 2451, 382, 364, 3109, 281, 8213, 21989, 2564, 11, 570], "temperature": 0.0, "avg_logprob": -0.13081262549575495, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.637325218936894e-06}, {"id": 199, "seek": 81908, "start": 833.9200000000001, "end": 836.12, "text": " it's such a powerful idea.", "tokens": [309, 311, 1270, 257, 4005, 1558, 13], "temperature": 0.0, "avg_logprob": -0.13081262549575495, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.637325218936894e-06}, {"id": 200, "seek": 81908, "start": 836.12, "end": 840.84, "text": " So a lot of this course is about breaking matrices into other matrices that are going", "tokens": [407, 257, 688, 295, 341, 1164, 307, 466, 7697, 32284, 666, 661, 32284, 300, 366, 516], "temperature": 0.0, "avg_logprob": -0.13081262549575495, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.637325218936894e-06}, {"id": 201, "seek": 81908, "start": 840.84, "end": 842.6, "text": " to be easier to work with.", "tokens": [281, 312, 3571, 281, 589, 365, 13], "temperature": 0.0, "avg_logprob": -0.13081262549575495, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.637325218936894e-06}, {"id": 202, "seek": 84260, "start": 842.6, "end": 850.2, "text": " And so there are going to be four things to keep in mind broadly when choosing or designing", "tokens": [400, 370, 456, 366, 516, 281, 312, 1451, 721, 281, 1066, 294, 1575, 19511, 562, 10875, 420, 14685], "temperature": 0.0, "avg_logprob": -0.11810850846140009, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.905313860741444e-06}, {"id": 203, "seek": 84260, "start": 850.2, "end": 851.2, "text": " an algorithm.", "tokens": [364, 9284, 13], "temperature": 0.0, "avg_logprob": -0.11810850846140009, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.905313860741444e-06}, {"id": 204, "seek": 84260, "start": 851.2, "end": 854.36, "text": " We'll go into each of these in a little bit more depth.", "tokens": [492, 603, 352, 666, 1184, 295, 613, 294, 257, 707, 857, 544, 7161, 13], "temperature": 0.0, "avg_logprob": -0.11810850846140009, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.905313860741444e-06}, {"id": 205, "seek": 84260, "start": 854.36, "end": 862.76, "text": " Memory use, speed, accuracy, and scalability.", "tokens": [38203, 764, 11, 3073, 11, 14170, 11, 293, 15664, 2310, 13], "temperature": 0.0, "avg_logprob": -0.11810850846140009, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.905313860741444e-06}, {"id": 206, "seek": 84260, "start": 862.76, "end": 865.6, "text": " And then kind of on the motivation of doing this.", "tokens": [400, 550, 733, 295, 322, 264, 12335, 295, 884, 341, 13], "temperature": 0.0, "avg_logprob": -0.11810850846140009, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.905313860741444e-06}, {"id": 207, "seek": 84260, "start": 865.6, "end": 871.44, "text": " So a lot of the things we'll talk about could be done in scikit-learn or sci-pi.", "tokens": [407, 257, 688, 295, 264, 721, 321, 603, 751, 466, 727, 312, 1096, 294, 2180, 22681, 12, 306, 1083, 420, 2180, 12, 22630, 13], "temperature": 0.0, "avg_logprob": -0.11810850846140009, "compression_ratio": 1.5294117647058822, "no_speech_prob": 3.905313860741444e-06}, {"id": 208, "seek": 87144, "start": 871.44, "end": 879.8800000000001, "text": " It's really great to know kind of how those libraries work in case you want to do a variation", "tokens": [467, 311, 534, 869, 281, 458, 733, 295, 577, 729, 15148, 589, 294, 1389, 291, 528, 281, 360, 257, 12990], "temperature": 0.0, "avg_logprob": -0.1457390878714767, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.63716924059554e-06}, {"id": 209, "seek": 87144, "start": 879.8800000000001, "end": 884.4000000000001, "text": " that's not accounted for, knowing the trade-offs that you're making when you choose between", "tokens": [300, 311, 406, 43138, 337, 11, 5276, 264, 4923, 12, 19231, 300, 291, 434, 1455, 562, 291, 2826, 1296], "temperature": 0.0, "avg_logprob": -0.1457390878714767, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.63716924059554e-06}, {"id": 210, "seek": 87144, "start": 884.4000000000001, "end": 886.9200000000001, "text": " different options.", "tokens": [819, 3956, 13], "temperature": 0.0, "avg_logprob": -0.1457390878714767, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.63716924059554e-06}, {"id": 211, "seek": 87144, "start": 886.9200000000001, "end": 890.5200000000001, "text": " Also a lot of these fields are moving very quickly, and you might find new results that", "tokens": [2743, 257, 688, 295, 613, 7909, 366, 2684, 588, 2661, 11, 293, 291, 1062, 915, 777, 3542, 300], "temperature": 0.0, "avg_logprob": -0.1457390878714767, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.63716924059554e-06}, {"id": 212, "seek": 87144, "start": 890.5200000000001, "end": 894.96, "text": " haven't yet been implemented in one of these libraries, particularly the areas of deep", "tokens": [2378, 380, 1939, 668, 12270, 294, 472, 295, 613, 15148, 11, 4098, 264, 3179, 295, 2452], "temperature": 0.0, "avg_logprob": -0.1457390878714767, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.63716924059554e-06}, {"id": 213, "seek": 87144, "start": 894.96, "end": 899.8000000000001, "text": " learning, recommendation systems, approximate algorithms, and graph analytics.", "tokens": [2539, 11, 11879, 3652, 11, 30874, 14642, 11, 293, 4295, 15370, 13], "temperature": 0.0, "avg_logprob": -0.1457390878714767, "compression_ratio": 1.6298932384341638, "no_speech_prob": 4.63716924059554e-06}, {"id": 214, "seek": 89980, "start": 899.8, "end": 905.9599999999999, "text": " There's a lot of research happening in all of those right now.", "tokens": [821, 311, 257, 688, 295, 2132, 2737, 294, 439, 295, 729, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.21090953029803375, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.9946828615502454e-06}, {"id": 215, "seek": 89980, "start": 905.9599999999999, "end": 912.56, "text": " And so yeah, knowing how to debug algorithms can really kind of accelerate your work.", "tokens": [400, 370, 1338, 11, 5276, 577, 281, 24083, 14642, 393, 534, 733, 295, 21341, 428, 589, 13], "temperature": 0.0, "avg_logprob": -0.21090953029803375, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.9946828615502454e-06}, {"id": 216, "seek": 89980, "start": 912.56, "end": 918.0, "text": " Or sorry, knowing how they work helps you debug them, but knowing how to debug them", "tokens": [1610, 2597, 11, 5276, 577, 436, 589, 3665, 291, 24083, 552, 11, 457, 5276, 577, 281, 24083, 552], "temperature": 0.0, "avg_logprob": -0.21090953029803375, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.9946828615502454e-06}, {"id": 217, "seek": 89980, "start": 918.0, "end": 927.04, "text": " also helps accelerate what you're doing.", "tokens": [611, 3665, 21341, 437, 291, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.21090953029803375, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.9946828615502454e-06}, {"id": 218, "seek": 92704, "start": 927.04, "end": 929.9599999999999, "text": " So in this part, we'll probably review.", "tokens": [407, 294, 341, 644, 11, 321, 603, 1391, 3131, 13], "temperature": 0.0, "avg_logprob": -0.23633186744921136, "compression_ratio": 1.526946107784431, "no_speech_prob": 3.785188482652302e-06}, {"id": 219, "seek": 92704, "start": 929.9599999999999, "end": 935.4, "text": " I just wanted to say there are two main types of matrix computations, which are taking products", "tokens": [286, 445, 1415, 281, 584, 456, 366, 732, 2135, 3467, 295, 8141, 2807, 763, 11, 597, 366, 1940, 3383], "temperature": 0.0, "avg_logprob": -0.23633186744921136, "compression_ratio": 1.526946107784431, "no_speech_prob": 3.785188482652302e-06}, {"id": 220, "seek": 92704, "start": 935.4, "end": 937.0799999999999, "text": " and then decomposition.", "tokens": [293, 550, 48356, 13], "temperature": 0.0, "avg_logprob": -0.23633186744921136, "compression_ratio": 1.526946107784431, "no_speech_prob": 3.785188482652302e-06}, {"id": 221, "seek": 92704, "start": 937.0799999999999, "end": 945.3199999999999, "text": " So putting them together and then pulling them apart.", "tokens": [407, 3372, 552, 1214, 293, 550, 8407, 552, 4936, 13], "temperature": 0.0, "avg_logprob": -0.23633186744921136, "compression_ratio": 1.526946107784431, "no_speech_prob": 3.785188482652302e-06}, {"id": 222, "seek": 92704, "start": 945.3199999999999, "end": 950.48, "text": " So for an example, here this is a matrix.", "tokens": [407, 337, 364, 1365, 11, 510, 341, 307, 257, 8141, 13], "temperature": 0.0, "avg_logprob": -0.23633186744921136, "compression_ratio": 1.526946107784431, "no_speech_prob": 3.785188482652302e-06}, {"id": 223, "seek": 95048, "start": 950.48, "end": 960.28, "text": " I'm going to make this a little bit smaller just so it can fit on one screen.", "tokens": [286, 478, 516, 281, 652, 341, 257, 707, 857, 4356, 445, 370, 309, 393, 3318, 322, 472, 2568, 13], "temperature": 0.0, "avg_logprob": -0.16049215766821015, "compression_ratio": 1.5797101449275361, "no_speech_prob": 1.5534440080955392e-06}, {"id": 224, "seek": 95048, "start": 960.28, "end": 966.52, "text": " This is a matrix of probabilities, but this is a Markov chain with different states of", "tokens": [639, 307, 257, 8141, 295, 33783, 11, 457, 341, 307, 257, 3934, 5179, 5021, 365, 819, 4368, 295], "temperature": 0.0, "avg_logprob": -0.16049215766821015, "compression_ratio": 1.5797101449275361, "no_speech_prob": 1.5534440080955392e-06}, {"id": 225, "seek": 95048, "start": 966.52, "end": 967.52, "text": " health.", "tokens": [1585, 13], "temperature": 0.0, "avg_logprob": -0.16049215766821015, "compression_ratio": 1.5797101449275361, "no_speech_prob": 1.5534440080955392e-06}, {"id": 226, "seek": 95048, "start": 967.52, "end": 974.16, "text": " And so there's kind of an asymptomatic HIV stage, symptomatic, full-blown AIDS, and death.", "tokens": [400, 370, 456, 311, 733, 295, 364, 35114, 13143, 15907, 3233, 11, 7266, 13143, 11, 1577, 12, 5199, 648, 27929, 11, 293, 2966, 13], "temperature": 0.0, "avg_logprob": -0.16049215766821015, "compression_ratio": 1.5797101449275361, "no_speech_prob": 1.5534440080955392e-06}, {"id": 227, "seek": 95048, "start": 974.16, "end": 977.44, "text": " And these are kind of the different states of the Markov chain.", "tokens": [400, 613, 366, 733, 295, 264, 819, 4368, 295, 264, 3934, 5179, 5021, 13], "temperature": 0.0, "avg_logprob": -0.16049215766821015, "compression_ratio": 1.5797101449275361, "no_speech_prob": 1.5534440080955392e-06}, {"id": 228, "seek": 97744, "start": 977.44, "end": 983.44, "text": " And then this matrix of probabilities is saying what are your chances if you're in one state", "tokens": [400, 550, 341, 8141, 295, 33783, 307, 1566, 437, 366, 428, 10486, 498, 291, 434, 294, 472, 1785], "temperature": 0.0, "avg_logprob": -0.11594638083744975, "compression_ratio": 1.7863247863247864, "no_speech_prob": 2.6994808877134346e-07}, {"id": 229, "seek": 97744, "start": 983.44, "end": 986.32, "text": " of moving to each of the other states.", "tokens": [295, 2684, 281, 1184, 295, 264, 661, 4368, 13], "temperature": 0.0, "avg_logprob": -0.11594638083744975, "compression_ratio": 1.7863247863247864, "no_speech_prob": 2.6994808877134346e-07}, {"id": 230, "seek": 97744, "start": 986.32, "end": 991.6, "text": " And so you'll notice each row sums to one since they're probabilities.", "tokens": [400, 370, 291, 603, 3449, 1184, 5386, 34499, 281, 472, 1670, 436, 434, 33783, 13], "temperature": 0.0, "avg_logprob": -0.11594638083744975, "compression_ratio": 1.7863247863247864, "no_speech_prob": 2.6994808877134346e-07}, {"id": 231, "seek": 97744, "start": 991.6, "end": 994.8800000000001, "text": " And that's kind of the row gives you the state you're starting in.", "tokens": [400, 300, 311, 733, 295, 264, 5386, 2709, 291, 264, 1785, 291, 434, 2891, 294, 13], "temperature": 0.0, "avg_logprob": -0.11594638083744975, "compression_ratio": 1.7863247863247864, "no_speech_prob": 2.6994808877134346e-07}, {"id": 232, "seek": 97744, "start": 994.8800000000001, "end": 998.2, "text": " The column gives you the destination state you're moving to.", "tokens": [440, 7738, 2709, 291, 264, 12236, 1785, 291, 434, 2684, 281, 13], "temperature": 0.0, "avg_logprob": -0.11594638083744975, "compression_ratio": 1.7863247863247864, "no_speech_prob": 2.6994808877134346e-07}, {"id": 233, "seek": 97744, "start": 998.2, "end": 1003.9200000000001, "text": " As I mentioned earlier, I had an internship while I was in grad school that was a whole", "tokens": [1018, 286, 2835, 3071, 11, 286, 632, 364, 16861, 1339, 286, 390, 294, 2771, 1395, 300, 390, 257, 1379], "temperature": 0.0, "avg_logprob": -0.11594638083744975, "compression_ratio": 1.7863247863247864, "no_speech_prob": 2.6994808877134346e-07}, {"id": 234, "seek": 100392, "start": 1003.92, "end": 1007.4399999999999, "text": " kind of research group that looked at problems like these.", "tokens": [733, 295, 2132, 1594, 300, 2956, 412, 2740, 411, 613, 13], "temperature": 0.0, "avg_logprob": -0.14017207213122435, "compression_ratio": 1.63135593220339, "no_speech_prob": 7.570425850644824e-07}, {"id": 235, "seek": 100392, "start": 1007.4399999999999, "end": 1011.12, "text": " They would also take into account kind of the cost of health care and different types", "tokens": [814, 576, 611, 747, 666, 2696, 733, 295, 264, 2063, 295, 1585, 1127, 293, 819, 3467], "temperature": 0.0, "avg_logprob": -0.14017207213122435, "compression_ratio": 1.63135593220339, "no_speech_prob": 7.570425850644824e-07}, {"id": 236, "seek": 100392, "start": 1011.12, "end": 1017.28, "text": " of treatment and use that to kind of weigh recommendations.", "tokens": [295, 5032, 293, 764, 300, 281, 733, 295, 13843, 10434, 13], "temperature": 0.0, "avg_logprob": -0.14017207213122435, "compression_ratio": 1.63135593220339, "no_speech_prob": 7.570425850644824e-07}, {"id": 237, "seek": 100392, "start": 1017.28, "end": 1024.6399999999999, "text": " So here I want you to take if this is kind of your starting vector of what, you know,", "tokens": [407, 510, 286, 528, 291, 281, 747, 498, 341, 307, 733, 295, 428, 2891, 8062, 295, 437, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.14017207213122435, "compression_ratio": 1.63135593220339, "no_speech_prob": 7.570425850644824e-07}, {"id": 238, "seek": 100392, "start": 1024.6399999999999, "end": 1030.92, "text": " you have a group of people, 85% are in the asymptomatic group, 10% are symptomatic, and", "tokens": [291, 362, 257, 1594, 295, 561, 11, 14695, 4, 366, 294, 264, 35114, 13143, 1594, 11, 1266, 4, 366, 7266, 13143, 11, 293], "temperature": 0.0, "avg_logprob": -0.14017207213122435, "compression_ratio": 1.63135593220339, "no_speech_prob": 7.570425850644824e-07}, {"id": 239, "seek": 100392, "start": 1030.92, "end": 1031.92, "text": " so on.", "tokens": [370, 322, 13], "temperature": 0.0, "avg_logprob": -0.14017207213122435, "compression_ratio": 1.63135593220339, "no_speech_prob": 7.570425850644824e-07}, {"id": 240, "seek": 103192, "start": 1031.92, "end": 1035.4, "text": " And if this matrix kind of is giving you the probabilities of what their health will be", "tokens": [400, 498, 341, 8141, 733, 295, 307, 2902, 291, 264, 33783, 295, 437, 641, 1585, 486, 312], "temperature": 0.0, "avg_logprob": -0.29743533347969625, "compression_ratio": 1.4478527607361964, "no_speech_prob": 1.6027007632146706e-06}, {"id": 241, "seek": 103192, "start": 1035.4, "end": 1039.52, "text": " like in a year, can you tell me what those probabilities are?", "tokens": [411, 294, 257, 1064, 11, 393, 291, 980, 385, 437, 729, 33783, 366, 30], "temperature": 0.0, "avg_logprob": -0.29743533347969625, "compression_ratio": 1.4478527607361964, "no_speech_prob": 1.6027007632146706e-06}, {"id": 242, "seek": 103192, "start": 1039.52, "end": 1047.5600000000002, "text": " So take a few moments to code that just to warm up.", "tokens": [407, 747, 257, 1326, 6065, 281, 3089, 300, 445, 281, 4561, 493, 13], "temperature": 0.0, "avg_logprob": -0.29743533347969625, "compression_ratio": 1.4478527607361964, "no_speech_prob": 1.6027007632146706e-06}, {"id": 243, "seek": 103192, "start": 1047.5600000000002, "end": 1050.6000000000001, "text": " Oh, yes.", "tokens": [876, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.29743533347969625, "compression_ratio": 1.4478527607361964, "no_speech_prob": 1.6027007632146706e-06}, {"id": 244, "seek": 103192, "start": 1050.6000000000001, "end": 1055.24, "text": " Although I don't want to.", "tokens": [5780, 286, 500, 380, 528, 281, 13], "temperature": 0.0, "avg_logprob": -0.29743533347969625, "compression_ratio": 1.4478527607361964, "no_speech_prob": 1.6027007632146706e-06}, {"id": 245, "seek": 105524, "start": 1055.24, "end": 1064.6, "text": " So if you go to the answer tab, it should show up as a cell that says exercise.", "tokens": [407, 498, 291, 352, 281, 264, 1867, 4421, 11, 309, 820, 855, 493, 382, 257, 2815, 300, 1619, 5380, 13], "temperature": 0.0, "avg_logprob": -0.26579699308975885, "compression_ratio": 1.5095541401273886, "no_speech_prob": 1.4733973330294248e-05}, {"id": 246, "seek": 105524, "start": 1064.6, "end": 1069.04, "text": " I'm not opening mine because I have the answer written there.", "tokens": [286, 478, 406, 5193, 3892, 570, 286, 362, 264, 1867, 3720, 456, 13], "temperature": 0.0, "avg_logprob": -0.26579699308975885, "compression_ratio": 1.5095541401273886, "no_speech_prob": 1.4733973330294248e-05}, {"id": 247, "seek": 105524, "start": 1069.04, "end": 1072.04, "text": " It shows you what the correct answer should be.", "tokens": [467, 3110, 291, 437, 264, 3006, 1867, 820, 312, 13], "temperature": 0.0, "avg_logprob": -0.26579699308975885, "compression_ratio": 1.5095541401273886, "no_speech_prob": 1.4733973330294248e-05}, {"id": 248, "seek": 105524, "start": 1072.04, "end": 1073.04, "text": " Oh, yes.", "tokens": [876, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.26579699308975885, "compression_ratio": 1.5095541401273886, "no_speech_prob": 1.4733973330294248e-05}, {"id": 249, "seek": 105524, "start": 1073.04, "end": 1082.04, "text": " Yeah, it shows you the output as well.", "tokens": [865, 11, 309, 3110, 291, 264, 5598, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.26579699308975885, "compression_ratio": 1.5095541401273886, "no_speech_prob": 1.4733973330294248e-05}, {"id": 250, "seek": 108204, "start": 1082.04, "end": 1097.36, "text": " I'll leave it.", "tokens": [286, 603, 1856, 309, 13], "temperature": 1.0, "avg_logprob": -2.4426485697428384, "compression_ratio": 0.7419354838709677, "no_speech_prob": 0.01861141063272953}, {"id": 251, "seek": 108204, "start": 1097.36, "end": 1104.84, "text": " Oh, wow.", "tokens": [876, 11, 6076, 13], "temperature": 1.0, "avg_logprob": -2.4426485697428384, "compression_ratio": 0.7419354838709677, "no_speech_prob": 0.01861141063272953}, {"id": 252, "seek": 113484, "start": 1134.84, "end": 1139.84, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.42223589043868215, "compression_ratio": 1.1238095238095238, "no_speech_prob": 0.03306109085679054}, {"id": 253, "seek": 113484, "start": 1139.84, "end": 1144.84, "text": " Oh, yes.", "tokens": [876, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.42223589043868215, "compression_ratio": 1.1238095238095238, "no_speech_prob": 0.03306109085679054}, {"id": 254, "seek": 113484, "start": 1144.84, "end": 1149.84, "text": " Okay, yeah. So the question was from someone not registered for the class, so let me pull up the GitHub.", "tokens": [1033, 11, 1338, 13, 407, 264, 1168, 390, 490, 1580, 406, 13968, 337, 264, 1508, 11, 370, 718, 385, 2235, 493, 264, 23331, 13], "temperature": 0.0, "avg_logprob": -0.42223589043868215, "compression_ratio": 1.1238095238095238, "no_speech_prob": 0.03306109085679054}, {"id": 255, "seek": 114984, "start": 1149.84, "end": 1175.84, "text": " Yeah, so on GitHub, it's users fast AI and then numerical-linear-algebra is the repository.", "tokens": [865, 11, 370, 322, 23331, 11, 309, 311, 5022, 2370, 7318, 293, 550, 29054, 12, 28263, 12, 304, 19983, 307, 264, 25841, 13], "temperature": 0.0, "avg_logprob": -0.34568186159487124, "compression_ratio": 1.0459770114942528, "no_speech_prob": 4.397908924147487e-05}, {"id": 256, "seek": 117584, "start": 1175.84, "end": 1191.84, "text": " Let me make that bigger.", "tokens": [961, 385, 652, 300, 3801, 13], "temperature": 0.0, "avg_logprob": -0.2873891830444336, "compression_ratio": 0.75, "no_speech_prob": 1.5204018382064532e-05}, {"id": 257, "seek": 119184, "start": 1191.84, "end": 1211.84, "text": " And I've also put the syllabus in the README of the repository, kind of with links so you can view the notebooks and we'll be adding to it.", "tokens": [400, 286, 600, 611, 829, 264, 48077, 294, 264, 10869, 6112, 15454, 295, 264, 25841, 11, 733, 295, 365, 6123, 370, 291, 393, 1910, 264, 43782, 293, 321, 603, 312, 5127, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.12287791151749461, "compression_ratio": 1.188034188034188, "no_speech_prob": 7.763878784317058e-06}, {"id": 258, "seek": 121184, "start": 1211.84, "end": 1215.84, "text": " Raise your hand if you're done.", "tokens": [30062, 428, 1011, 498, 291, 434, 1096, 13], "temperature": 0.0, "avg_logprob": -0.09704766670862834, "compression_ratio": 0.8611111111111112, "no_speech_prob": 0.00033361371606588364}, {"id": 259, "seek": 121584, "start": 1215.84, "end": 1241.84, "text": " Raise your hand if you want more time.", "tokens": [30062, 428, 1011, 498, 291, 528, 544, 565, 13], "temperature": 0.0, "avg_logprob": -0.053945527626917913, "compression_ratio": 0.8837209302325582, "no_speech_prob": 0.00026841682847589254}, {"id": 260, "seek": 124184, "start": 1241.84, "end": 1251.84, "text": " Oh, yeah, that's a great idea.", "tokens": [50364, 876, 11, 1338, 11, 300, 311, 257, 869, 1558, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3328549311711238, "compression_ratio": 0.8333333333333334, "no_speech_prob": 0.00035215800744481385}, {"id": 261, "seek": 127184, "start": 1271.84, "end": 1293.84, "text": " Okay, let's look at the answer.", "tokens": [1033, 11, 718, 311, 574, 412, 264, 1867, 13], "temperature": 0.0, "avg_logprob": -0.35013829744779146, "compression_ratio": 0.7948717948717948, "no_speech_prob": 0.06745297461748123}, {"id": 262, "seek": 129384, "start": 1293.84, "end": 1298.84, "text": " Let me make this larger again.", "tokens": [961, 385, 652, 341, 4833, 797, 13], "temperature": 0.0, "avg_logprob": -0.1702047884464264, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.494457243708894e-06}, {"id": 263, "seek": 129384, "start": 1298.84, "end": 1303.84, "text": " Yeah, so you can use NumPy to put these in as arrays.", "tokens": [865, 11, 370, 291, 393, 764, 22592, 47, 88, 281, 829, 613, 294, 382, 41011, 13], "temperature": 0.0, "avg_logprob": -0.1702047884464264, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.494457243708894e-06}, {"id": 264, "seek": 129384, "start": 1303.84, "end": 1307.84, "text": " This is a two-dimensional array for the matrix, the vectors.", "tokens": [639, 307, 257, 732, 12, 18759, 10225, 337, 264, 8141, 11, 264, 18875, 13], "temperature": 0.0, "avg_logprob": -0.1702047884464264, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.494457243708894e-06}, {"id": 265, "seek": 129384, "start": 1307.84, "end": 1314.84, "text": " Well, actually, I guess I put that as a two-dimensional as well.", "tokens": [1042, 11, 767, 11, 286, 2041, 286, 829, 300, 382, 257, 732, 12, 18759, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1702047884464264, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.494457243708894e-06}, {"id": 266, "seek": 131484, "start": 1314.84, "end": 1324.84, "text": " So I did A.T., which is transpose. The at sign is matrix multiplication in Python 3, I believe you need.", "tokens": [407, 286, 630, 316, 13, 51, 7933, 597, 307, 25167, 13, 440, 412, 1465, 307, 8141, 27290, 294, 15329, 805, 11, 286, 1697, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.13158794176780572, "compression_ratio": 1.4522292993630572, "no_speech_prob": 2.642362915139529e-06}, {"id": 267, "seek": 131484, "start": 1324.84, "end": 1341.84, "text": " So for Python 2, you could be using np.matmul for matrix multiplication, although I highly recommend switching to Python 3.", "tokens": [407, 337, 15329, 568, 11, 291, 727, 312, 1228, 33808, 13, 15677, 76, 425, 337, 8141, 27290, 11, 4878, 286, 5405, 2748, 16493, 281, 15329, 805, 13], "temperature": 0.0, "avg_logprob": -0.13158794176780572, "compression_ratio": 1.4522292993630572, "no_speech_prob": 2.642362915139529e-06}, {"id": 268, "seek": 134184, "start": 1341.84, "end": 1365.84, "text": " So I want to say, why am I doing A transpose?", "tokens": [407, 286, 528, 281, 584, 11, 983, 669, 286, 884, 316, 25167, 30], "temperature": 0.0, "avg_logprob": -0.2719651390524471, "compression_ratio": 0.8653846153846154, "no_speech_prob": 4.331297895987518e-05}, {"id": 269, "seek": 136584, "start": 1365.84, "end": 1375.84, "text": " Yeah, so with Markov chains, you multiply on the left as a row vector and then on the right by the matrix, what you want to get as a column vector in this case, so you just transpose the bottom.", "tokens": [865, 11, 370, 365, 3934, 5179, 12626, 11, 291, 12972, 322, 264, 1411, 382, 257, 5386, 8062, 293, 550, 322, 264, 558, 538, 264, 8141, 11, 437, 291, 528, 281, 483, 382, 257, 7738, 8062, 294, 341, 1389, 11, 370, 291, 445, 25167, 264, 2767, 13], "temperature": 0.0, "avg_logprob": -0.1737831196886428, "compression_ratio": 1.6157407407407407, "no_speech_prob": 7.833975541871041e-05}, {"id": 270, "seek": 136584, "start": 1375.84, "end": 1380.84, "text": " Yeah, yeah, and so it would have been fine if you had multiplied on the left.", "tokens": [865, 11, 1338, 11, 293, 370, 309, 576, 362, 668, 2489, 498, 291, 632, 17207, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.1737831196886428, "compression_ratio": 1.6157407407407407, "no_speech_prob": 7.833975541871041e-05}, {"id": 271, "seek": 136584, "start": 1380.84, "end": 1390.84, "text": " Also, the other way I think about it is, and you can pop it back. Thank you.", "tokens": [2743, 11, 264, 661, 636, 286, 519, 466, 309, 307, 11, 293, 291, 393, 1665, 309, 646, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.1737831196886428, "compression_ratio": 1.6157407407407407, "no_speech_prob": 7.833975541871041e-05}, {"id": 272, "seek": 139084, "start": 1390.84, "end": 1397.84, "text": " Just by the way, the reason we're using the microphone is so we can hear it on the recording.", "tokens": [1449, 538, 264, 636, 11, 264, 1778, 321, 434, 1228, 264, 10952, 307, 370, 321, 393, 1568, 309, 322, 264, 6613, 13], "temperature": 0.0, "avg_logprob": -0.13822417898276418, "compression_ratio": 1.6523605150214593, "no_speech_prob": 1.4968613868404645e-05}, {"id": 273, "seek": 139084, "start": 1397.84, "end": 1400.84, "text": " Yeah, it works fine. Yeah, yeah, thank you.", "tokens": [865, 11, 309, 1985, 2489, 13, 865, 11, 1338, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.13822417898276418, "compression_ratio": 1.6523605150214593, "no_speech_prob": 1.4968613868404645e-05}, {"id": 274, "seek": 139084, "start": 1400.84, "end": 1412.84, "text": " The other way to think about this is your matrix, kind of the dimensions are basically, let me point, like sources by destinations.", "tokens": [440, 661, 636, 281, 519, 466, 341, 307, 428, 8141, 11, 733, 295, 264, 12819, 366, 1936, 11, 718, 385, 935, 11, 411, 7139, 538, 37787, 13], "temperature": 0.0, "avg_logprob": -0.13822417898276418, "compression_ratio": 1.6523605150214593, "no_speech_prob": 1.4968613868404645e-05}, {"id": 275, "seek": 139084, "start": 1412.84, "end": 1418.84, "text": " And so I kind of think of like when you do the matrix multiplication, you're wanting to multiply it by the sources.", "tokens": [400, 370, 286, 733, 295, 519, 295, 411, 562, 291, 360, 264, 8141, 27290, 11, 291, 434, 7935, 281, 12972, 309, 538, 264, 7139, 13], "temperature": 0.0, "avg_logprob": -0.13822417898276418, "compression_ratio": 1.6523605150214593, "no_speech_prob": 1.4968613868404645e-05}, {"id": 276, "seek": 141884, "start": 1418.84, "end": 1427.84, "text": " So if you want the sources over here, you would need the sources to be the columns to kind of line up.", "tokens": [407, 498, 291, 528, 264, 7139, 670, 510, 11, 291, 576, 643, 264, 7139, 281, 312, 264, 13766, 281, 733, 295, 1622, 493, 13], "temperature": 0.0, "avg_logprob": -0.17108888626098634, "compression_ratio": 1.4144144144144144, "no_speech_prob": 1.520140085631283e-05}, {"id": 277, "seek": 141884, "start": 1427.84, "end": 1432.84, "text": " You want, you know, sources by sources.", "tokens": [509, 528, 11, 291, 458, 11, 7139, 538, 7139, 13], "temperature": 0.0, "avg_logprob": -0.17108888626098634, "compression_ratio": 1.4144144144144144, "no_speech_prob": 1.520140085631283e-05}, {"id": 278, "seek": 141884, "start": 1432.84, "end": 1439.84, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.17108888626098634, "compression_ratio": 1.4144144144144144, "no_speech_prob": 1.520140085631283e-05}, {"id": 279, "seek": 143984, "start": 1439.84, "end": 1449.84, "text": " I just, I used, I used vector at matrix and it also worked.", "tokens": [286, 445, 11, 286, 1143, 11, 286, 1143, 8062, 412, 8141, 293, 309, 611, 2732, 13], "temperature": 0.0, "avg_logprob": -0.3083813007061298, "compression_ratio": 1.356060606060606, "no_speech_prob": 3.905007815774297e-06}, {"id": 280, "seek": 143984, "start": 1449.84, "end": 1453.84, "text": " I just want to mention in case anybody else did that. Oh, no, that that would work as well.", "tokens": [286, 445, 528, 281, 2152, 294, 1389, 4472, 1646, 630, 300, 13, 876, 11, 572, 11, 300, 300, 576, 589, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.3083813007061298, "compression_ratio": 1.356060606060606, "no_speech_prob": 3.905007815774297e-06}, {"id": 281, "seek": 143984, "start": 1453.84, "end": 1455.84, "text": " That's actually equivalent.", "tokens": [663, 311, 767, 10344, 13], "temperature": 0.0, "avg_logprob": -0.3083813007061298, "compression_ratio": 1.356060606060606, "no_speech_prob": 3.905007815774297e-06}, {"id": 282, "seek": 145584, "start": 1455.84, "end": 1472.84, "text": " The kind of taking two transposes is I can write this like this is equal to like that whole thing transposed.", "tokens": [440, 733, 295, 1940, 732, 7132, 4201, 307, 286, 393, 2464, 341, 411, 341, 307, 2681, 281, 411, 300, 1379, 551, 7132, 1744, 13], "temperature": 0.0, "avg_logprob": -0.12587242126464843, "compression_ratio": 1.2989690721649485, "no_speech_prob": 1.018787088469253e-06}, {"id": 283, "seek": 145584, "start": 1472.84, "end": 1479.84, "text": " Yeah, thank you.", "tokens": [865, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.12587242126464843, "compression_ratio": 1.2989690721649485, "no_speech_prob": 1.018787088469253e-06}, {"id": 284, "seek": 147984, "start": 1479.84, "end": 1491.84, "text": " So now for matrix, matrix products. This is a problem that I've taken from kind of this set, this fact sheet that has several different linear algebra problems.", "tokens": [407, 586, 337, 8141, 11, 8141, 3383, 13, 639, 307, 257, 1154, 300, 286, 600, 2726, 490, 733, 295, 341, 992, 11, 341, 1186, 8193, 300, 575, 2940, 819, 8213, 21989, 2740, 13], "temperature": 0.0, "avg_logprob": -0.08823117171183671, "compression_ratio": 1.6577946768060836, "no_speech_prob": 7.070918400131632e-06}, {"id": 285, "seek": 147984, "start": 1491.84, "end": 1499.84, "text": " And so here this is and a lot of them, I think a lot of times when you're doing things by hand, they look like overly simplified examples.", "tokens": [400, 370, 510, 341, 307, 293, 257, 688, 295, 552, 11, 286, 519, 257, 688, 295, 1413, 562, 291, 434, 884, 721, 538, 1011, 11, 436, 574, 411, 24324, 26335, 5110, 13], "temperature": 0.0, "avg_logprob": -0.08823117171183671, "compression_ratio": 1.6577946768060836, "no_speech_prob": 7.070918400131632e-06}, {"id": 286, "seek": 147984, "start": 1499.84, "end": 1507.84, "text": " But it's important to remember that the power of matrices is that you can do these on really large data sets and large matrices as well.", "tokens": [583, 309, 311, 1021, 281, 1604, 300, 264, 1347, 295, 32284, 307, 300, 291, 393, 360, 613, 322, 534, 2416, 1412, 6352, 293, 2416, 32284, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.08823117171183671, "compression_ratio": 1.6577946768060836, "no_speech_prob": 7.070918400131632e-06}, {"id": 287, "seek": 150784, "start": 1507.84, "end": 1514.84, "text": " But here you've got three people who want to buy some different groceries.", "tokens": [583, 510, 291, 600, 658, 1045, 561, 567, 528, 281, 2256, 512, 819, 31391, 13], "temperature": 0.0, "avg_logprob": -0.03937274759465998, "compression_ratio": 1.5594405594405594, "no_speech_prob": 2.902024789364077e-06}, {"id": 288, "seek": 150784, "start": 1514.84, "end": 1517.84, "text": " And they have different prices for two different shops.", "tokens": [400, 436, 362, 819, 7901, 337, 732, 819, 14457, 13], "temperature": 0.0, "avg_logprob": -0.03937274759465998, "compression_ratio": 1.5594405594405594, "no_speech_prob": 2.902024789364077e-06}, {"id": 289, "seek": 150784, "start": 1517.84, "end": 1524.84, "text": " Each person only wants to go to one shop, which is the better shop for each person to go to.", "tokens": [6947, 954, 787, 2738, 281, 352, 281, 472, 3945, 11, 597, 307, 264, 1101, 3945, 337, 1184, 954, 281, 352, 281, 13], "temperature": 0.0, "avg_logprob": -0.03937274759465998, "compression_ratio": 1.5594405594405594, "no_speech_prob": 2.902024789364077e-06}, {"id": 290, "seek": 152484, "start": 1524.84, "end": 1544.84, "text": " So take a moment to do that. And again, if you go to the answer tab, there'll be a little bit a little bit of space and it should show you what the ideal answer is.", "tokens": [50364, 407, 747, 257, 1623, 281, 360, 300, 13, 400, 797, 11, 498, 291, 352, 281, 264, 1867, 4421, 11, 456, 603, 312, 257, 707, 857, 257, 707, 857, 295, 1901, 293, 309, 820, 855, 291, 437, 264, 7157, 1867, 307, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11299783533269708, "compression_ratio": 1.3781512605042017, "no_speech_prob": 1.9823586626444012e-05}, {"id": 291, "seek": 155484, "start": 1554.84, "end": 1575.84, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.2, "avg_logprob": -0.9017321268717448, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.9790727496147156}, {"id": 292, "seek": 157584, "start": 1575.84, "end": 1603.84, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.4906691312789917, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.0026953578926622868}, {"id": 293, "seek": 160384, "start": 1603.84, "end": 1630.84, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.4793522357940674, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.00611423933878541}, {"id": 294, "seek": 163084, "start": 1630.84, "end": 1657.84, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.38754244645436603, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.0031042667105793953}, {"id": 295, "seek": 165784, "start": 1657.84, "end": 1671.84, "text": " Raise your hand if you're finished.", "tokens": [30062, 428, 1011, 498, 291, 434, 4335, 13], "temperature": 0.0, "avg_logprob": -0.10758638381958008, "compression_ratio": 1.351063829787234, "no_speech_prob": 4.784297289006645e-06}, {"id": 296, "seek": 165784, "start": 1671.84, "end": 1676.84, "text": " Raise your hand if you want some more time.", "tokens": [30062, 428, 1011, 498, 291, 528, 512, 544, 565, 13], "temperature": 0.0, "avg_logprob": -0.10758638381958008, "compression_ratio": 1.351063829787234, "no_speech_prob": 4.784297289006645e-06}, {"id": 297, "seek": 165784, "start": 1676.84, "end": 1681.84, "text": " Okay. Go ahead and look at the answer for this.", "tokens": [1033, 13, 1037, 2286, 293, 574, 412, 264, 1867, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.10758638381958008, "compression_ratio": 1.351063829787234, "no_speech_prob": 4.784297289006645e-06}, {"id": 298, "seek": 168184, "start": 1681.84, "end": 1688.84, "text": " Yeah, so this is kind of pretty straightforward of entering the matrices as NumPy arrays.", "tokens": [865, 11, 370, 341, 307, 733, 295, 1238, 15325, 295, 11104, 264, 32284, 382, 22592, 47, 88, 41011, 13], "temperature": 0.0, "avg_logprob": -0.15501958673650568, "compression_ratio": 1.513157894736842, "no_speech_prob": 2.601489541120827e-06}, {"id": 299, "seek": 168184, "start": 1688.84, "end": 1694.84, "text": " And I did A at B or you could do NP.matmol if you're in Python 2.", "tokens": [400, 286, 630, 316, 412, 363, 420, 291, 727, 360, 38611, 13, 15677, 76, 401, 498, 291, 434, 294, 15329, 568, 13], "temperature": 0.0, "avg_logprob": -0.15501958673650568, "compression_ratio": 1.513157894736842, "no_speech_prob": 2.601489541120827e-06}, {"id": 300, "seek": 168184, "start": 1694.84, "end": 1698.84, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.15501958673650568, "compression_ratio": 1.513157894736842, "no_speech_prob": 2.601489541120827e-06}, {"id": 301, "seek": 168184, "start": 1698.84, "end": 1709.84, "text": " And this, if you look at, I think it's even in the part I copied, it's kind of nice how they copied out this example of, you know, the amount spent by person one is this row.", "tokens": [400, 341, 11, 498, 291, 574, 412, 11, 286, 519, 309, 311, 754, 294, 264, 644, 286, 25365, 11, 309, 311, 733, 295, 1481, 577, 436, 25365, 484, 341, 1365, 295, 11, 291, 458, 11, 264, 2372, 4418, 538, 954, 472, 307, 341, 5386, 13], "temperature": 0.0, "avg_logprob": -0.15501958673650568, "compression_ratio": 1.513157894736842, "no_speech_prob": 2.601489541120827e-06}, {"id": 302, "seek": 170984, "start": 1709.84, "end": 1716.84, "text": " And we're multiplying it by this column to get what they would spend in shop one.", "tokens": [400, 321, 434, 30955, 309, 538, 341, 7738, 281, 483, 437, 436, 576, 3496, 294, 3945, 472, 13], "temperature": 0.0, "avg_logprob": -0.11081991968928157, "compression_ratio": 1.4020100502512562, "no_speech_prob": 1.1842401363537647e-05}, {"id": 303, "seek": 170984, "start": 1716.84, "end": 1721.84, "text": " Oh, so next up is image data.", "tokens": [876, 11, 370, 958, 493, 307, 3256, 1412, 13], "temperature": 0.0, "avg_logprob": -0.11081991968928157, "compression_ratio": 1.4020100502512562, "no_speech_prob": 1.1842401363537647e-05}, {"id": 304, "seek": 170984, "start": 1721.84, "end": 1728.84, "text": " I really like this GIF that illustrates how images can be represented by a matrix of numbers.", "tokens": [286, 534, 411, 341, 460, 12775, 300, 41718, 577, 5267, 393, 312, 10379, 538, 257, 8141, 295, 3547, 13], "temperature": 0.0, "avg_logprob": -0.11081991968928157, "compression_ratio": 1.4020100502512562, "no_speech_prob": 1.1842401363537647e-05}, {"id": 305, "seek": 170984, "start": 1728.84, "end": 1734.84, "text": " And so here this is black and white and the values are between 0 and 255.", "tokens": [400, 370, 510, 341, 307, 2211, 293, 2418, 293, 264, 4190, 366, 1296, 1958, 293, 3552, 20, 13], "temperature": 0.0, "avg_logprob": -0.11081991968928157, "compression_ratio": 1.4020100502512562, "no_speech_prob": 1.1842401363537647e-05}, {"id": 306, "seek": 173484, "start": 1734.84, "end": 1745.84, "text": " To show that this is the handwritten digit eight and it could be represented by a matrix of, I'm not exactly sure if this is like 20 by 20 or so on.", "tokens": [1407, 855, 300, 341, 307, 264, 1011, 26859, 14293, 3180, 293, 309, 727, 312, 10379, 538, 257, 8141, 295, 11, 286, 478, 406, 2293, 988, 498, 341, 307, 411, 945, 538, 945, 420, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.08455932571227293, "compression_ratio": 1.5275229357798166, "no_speech_prob": 1.209826223202981e-06}, {"id": 307, "seek": 173484, "start": 1745.84, "end": 1752.84, "text": " And typically a lot of times what happens is that matrix might be unrolled then into a single row.", "tokens": [400, 5850, 257, 688, 295, 1413, 437, 2314, 307, 300, 8141, 1062, 312, 517, 28850, 550, 666, 257, 2167, 5386, 13], "temperature": 0.0, "avg_logprob": -0.08455932571227293, "compression_ratio": 1.5275229357798166, "no_speech_prob": 1.209826223202981e-06}, {"id": 308, "seek": 173484, "start": 1752.84, "end": 1758.84, "text": " But now you've got, you know, 400 numbers representing what that picture looked like.", "tokens": [583, 586, 291, 600, 658, 11, 291, 458, 11, 8423, 3547, 13460, 437, 300, 3036, 2956, 411, 13], "temperature": 0.0, "avg_logprob": -0.08455932571227293, "compression_ratio": 1.5275229357798166, "no_speech_prob": 1.209826223202981e-06}, {"id": 309, "seek": 175884, "start": 1758.84, "end": 1766.84, "text": " And for color images, you just have three matrices, one for red, green and blue.", "tokens": [400, 337, 2017, 5267, 11, 291, 445, 362, 1045, 32284, 11, 472, 337, 2182, 11, 3092, 293, 3344, 13], "temperature": 0.0, "avg_logprob": -0.061994955137178495, "compression_ratio": 1.4807692307692308, "no_speech_prob": 2.1691467111395468e-07}, {"id": 310, "seek": 175884, "start": 1766.84, "end": 1770.84, "text": " Any questions about that?", "tokens": [2639, 1651, 466, 300, 30], "temperature": 0.0, "avg_logprob": -0.061994955137178495, "compression_ratio": 1.4807692307692308, "no_speech_prob": 2.1691467111395468e-07}, {"id": 311, "seek": 175884, "start": 1770.84, "end": 1773.84, "text": " OK, so we're going to look at convolutions briefly.", "tokens": [2264, 11, 370, 321, 434, 516, 281, 574, 412, 3754, 15892, 10515, 13], "temperature": 0.0, "avg_logprob": -0.061994955137178495, "compression_ratio": 1.4807692307692308, "no_speech_prob": 2.1691467111395468e-07}, {"id": 312, "seek": 175884, "start": 1773.84, "end": 1783.84, "text": " So this is not a deep learning course, but I think deep learning is a really good illustration of how linear algebra is being heavily used right now.", "tokens": [407, 341, 307, 406, 257, 2452, 2539, 1164, 11, 457, 286, 519, 2452, 2539, 307, 257, 534, 665, 22645, 295, 577, 8213, 21989, 307, 885, 10950, 1143, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.061994955137178495, "compression_ratio": 1.4807692307692308, "no_speech_prob": 2.1691467111395468e-07}, {"id": 313, "seek": 178384, "start": 1783.84, "end": 1788.84, "text": " So convolutions are the heart of convolutional neural networks, CNNs.", "tokens": [407, 3754, 15892, 366, 264, 1917, 295, 45216, 304, 18161, 9590, 11, 24859, 82, 13], "temperature": 0.0, "avg_logprob": -0.0948401153087616, "compression_ratio": 1.5363636363636364, "no_speech_prob": 2.521230499041849e-06}, {"id": 314, "seek": 178384, "start": 1788.84, "end": 1797.84, "text": " And so basically pretty much any results you hear that have AI or deep learning that are related to images are using CNNs.", "tokens": [400, 370, 1936, 1238, 709, 604, 3542, 291, 1568, 300, 362, 7318, 420, 2452, 2539, 300, 366, 4077, 281, 5267, 366, 1228, 24859, 82, 13], "temperature": 0.0, "avg_logprob": -0.0948401153087616, "compression_ratio": 1.5363636363636364, "no_speech_prob": 2.521230499041849e-06}, {"id": 315, "seek": 178384, "start": 1797.84, "end": 1810.84, "text": " And then even this is just from a few weeks ago, Facebook's AI team published results for speech translation where they use CNNs instead of RNNs,", "tokens": [400, 550, 754, 341, 307, 445, 490, 257, 1326, 3259, 2057, 11, 4384, 311, 7318, 1469, 6572, 3542, 337, 6218, 12853, 689, 436, 764, 24859, 82, 2602, 295, 45702, 45, 82, 11], "temperature": 0.0, "avg_logprob": -0.0948401153087616, "compression_ratio": 1.5363636363636364, "no_speech_prob": 2.521230499041849e-06}, {"id": 316, "seek": 181084, "start": 1810.84, "end": 1815.84, "text": " which are kind of typically what people use for language. And they were nine times faster.", "tokens": [597, 366, 733, 295, 5850, 437, 561, 764, 337, 2856, 13, 400, 436, 645, 4949, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.0983095426817198, "compression_ratio": 1.556701030927835, "no_speech_prob": 3.089307710979483e-06}, {"id": 317, "seek": 181084, "start": 1815.84, "end": 1819.84, "text": " So convolutions are very useful.", "tokens": [407, 3754, 15892, 366, 588, 4420, 13], "temperature": 0.0, "avg_logprob": -0.0983095426817198, "compression_ratio": 1.556701030927835, "no_speech_prob": 3.089307710979483e-06}, {"id": 318, "seek": 181084, "start": 1819.84, "end": 1826.84, "text": " So using convolutions or convolutional neural networks, computers are more accurate than people at classifying images.", "tokens": [407, 1228, 3754, 15892, 420, 45216, 304, 18161, 9590, 11, 10807, 366, 544, 8559, 813, 561, 412, 1508, 5489, 5267, 13], "temperature": 0.0, "avg_logprob": -0.0983095426817198, "compression_ratio": 1.556701030927835, "no_speech_prob": 3.089307710979483e-06}, {"id": 319, "seek": 181084, "start": 1826.84, "end": 1830.84, "text": " I should zoom in on these.", "tokens": [286, 820, 8863, 294, 322, 613, 13], "temperature": 0.0, "avg_logprob": -0.0983095426817198, "compression_ratio": 1.556701030927835, "no_speech_prob": 3.089307710979483e-06}, {"id": 320, "seek": 181084, "start": 1830.84, "end": 1833.84, "text": " So some of these I wouldn't get.", "tokens": [407, 512, 295, 613, 286, 2759, 380, 483, 13], "temperature": 0.0, "avg_logprob": -0.0983095426817198, "compression_ratio": 1.556701030927835, "no_speech_prob": 3.089307710979483e-06}, {"id": 321, "seek": 183384, "start": 1833.84, "end": 1841.84, "text": " This is an ultramarathon, not a half marathon. So the computer got the top choice was ultramarathon.", "tokens": [639, 307, 364, 3725, 2356, 289, 18660, 11, 406, 257, 1922, 27601, 13, 407, 264, 3820, 658, 264, 1192, 3922, 390, 3725, 2356, 289, 18660, 13], "temperature": 0.0, "avg_logprob": -0.09823336808577827, "compression_ratio": 1.7777777777777777, "no_speech_prob": 2.9020552574365865e-06}, {"id": 322, "seek": 183384, "start": 1841.84, "end": 1847.84, "text": " Their second guess was half marathon. Third guess was running and fourth guess was marathon.", "tokens": [6710, 1150, 2041, 390, 1922, 27601, 13, 12548, 2041, 390, 2614, 293, 6409, 2041, 390, 27601, 13], "temperature": 0.0, "avg_logprob": -0.09823336808577827, "compression_ratio": 1.7777777777777777, "no_speech_prob": 2.9020552574365865e-06}, {"id": 323, "seek": 183384, "start": 1847.84, "end": 1852.84, "text": " So a lot of times these are very fine grained categories or distinctions.", "tokens": [407, 257, 688, 295, 1413, 613, 366, 588, 2489, 1295, 2001, 10479, 420, 1483, 49798, 13], "temperature": 0.0, "avg_logprob": -0.09823336808577827, "compression_ratio": 1.7777777777777777, "no_speech_prob": 2.9020552574365865e-06}, {"id": 324, "seek": 183384, "start": 1852.84, "end": 1861.84, "text": " And I like this one of this is a heptathlon, not a decathlon, hurdles or pentathlon.", "tokens": [400, 286, 411, 341, 472, 295, 341, 307, 257, 415, 662, 41269, 11, 406, 257, 979, 41269, 11, 48387, 420, 16834, 41269, 13], "temperature": 0.0, "avg_logprob": -0.09823336808577827, "compression_ratio": 1.7777777777777777, "no_speech_prob": 2.9020552574365865e-06}, {"id": 325, "seek": 186184, "start": 1861.84, "end": 1867.84, "text": " But this is this is what computers are capable of.", "tokens": [583, 341, 307, 341, 307, 437, 10807, 366, 8189, 295, 13], "temperature": 0.0, "avg_logprob": -0.09339765775001656, "compression_ratio": 1.4596273291925466, "no_speech_prob": 2.9021905447734753e-06}, {"id": 326, "seek": 186184, "start": 1867.84, "end": 1877.84, "text": " And then here's an example of an algorithm to kind of find bounding boxes for different objects inside a picture and then identify what the object is.", "tokens": [400, 550, 510, 311, 364, 1365, 295, 364, 9284, 281, 733, 295, 915, 5472, 278, 9002, 337, 819, 6565, 1854, 257, 3036, 293, 550, 5876, 437, 264, 2657, 307, 13], "temperature": 0.0, "avg_logprob": -0.09339765775001656, "compression_ratio": 1.4596273291925466, "no_speech_prob": 2.9021905447734753e-06}, {"id": 327, "seek": 186184, "start": 1877.84, "end": 1881.84, "text": " And you can see. Oh, my goodness.", "tokens": [400, 291, 393, 536, 13, 876, 11, 452, 8387, 13], "temperature": 0.0, "avg_logprob": -0.09339765775001656, "compression_ratio": 1.4596273291925466, "no_speech_prob": 2.9021905447734753e-06}, {"id": 328, "seek": 188184, "start": 1881.84, "end": 1891.84, "text": " OK. Wow. So that's even more impressive. I think this was done in videos is what Jeremy just said.", "tokens": [2264, 13, 3153, 13, 407, 300, 311, 754, 544, 8992, 13, 286, 519, 341, 390, 1096, 294, 2145, 307, 437, 17809, 445, 848, 13], "temperature": 0.0, "avg_logprob": -0.13196817450567122, "compression_ratio": 1.6343283582089552, "no_speech_prob": 1.933256726260879e-06}, {"id": 329, "seek": 188184, "start": 1891.84, "end": 1899.84, "text": " Yeah. So this this one they've identified two different chairs in the picture, you know, including this one, which is kind of you only seeing part of it.", "tokens": [865, 13, 407, 341, 341, 472, 436, 600, 9234, 732, 819, 18299, 294, 264, 3036, 11, 291, 458, 11, 3009, 341, 472, 11, 597, 307, 733, 295, 291, 787, 2577, 644, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.13196817450567122, "compression_ratio": 1.6343283582089552, "no_speech_prob": 1.933256726260879e-06}, {"id": 330, "seek": 188184, "start": 1899.84, "end": 1903.84, "text": " And it's in the dark, you know, and a person and a dog.", "tokens": [400, 309, 311, 294, 264, 2877, 11, 291, 458, 11, 293, 257, 954, 293, 257, 3000, 13], "temperature": 0.0, "avg_logprob": -0.13196817450567122, "compression_ratio": 1.6343283582089552, "no_speech_prob": 1.933256726260879e-06}, {"id": 331, "seek": 188184, "start": 1903.84, "end": 1910.84, "text": " And this one and this is pretty intricate. There are a lot of objects overlapping each other and the algorithms recognizing them.", "tokens": [400, 341, 472, 293, 341, 307, 1238, 38015, 13, 821, 366, 257, 688, 295, 6565, 33535, 1184, 661, 293, 264, 14642, 18538, 552, 13], "temperature": 0.0, "avg_logprob": -0.13196817450567122, "compression_ratio": 1.6343283582089552, "no_speech_prob": 1.933256726260879e-06}, {"id": 332, "seek": 191084, "start": 1910.84, "end": 1915.84, "text": " And so we will not be getting into the full details of this.", "tokens": [400, 370, 321, 486, 406, 312, 1242, 666, 264, 1577, 4365, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.08611086548351851, "compression_ratio": 1.4406779661016949, "no_speech_prob": 6.276366093516117e-07}, {"id": 333, "seek": 191084, "start": 1915.84, "end": 1924.84, "text": " But I wanted to talk a little bit about how convolutions work since they're useful building block for deep learning and an application of linear algebra.", "tokens": [583, 286, 1415, 281, 751, 257, 707, 857, 466, 577, 3754, 15892, 589, 1670, 436, 434, 4420, 2390, 3461, 337, 2452, 2539, 293, 364, 3861, 295, 8213, 21989, 13], "temperature": 0.0, "avg_logprob": -0.08611086548351851, "compression_ratio": 1.4406779661016949, "no_speech_prob": 6.276366093516117e-07}, {"id": 334, "seek": 191084, "start": 1924.84, "end": 1930.84, "text": " So this is some images from a blog post.", "tokens": [407, 341, 307, 512, 5267, 490, 257, 6968, 2183, 13], "temperature": 0.0, "avg_logprob": -0.08611086548351851, "compression_ratio": 1.4406779661016949, "no_speech_prob": 6.276366093516117e-07}, {"id": 335, "seek": 193084, "start": 1930.84, "end": 1948.84, "text": " This opens. Yeah. Written by a student in the deep learning class that was here at the Data Institute.", "tokens": [639, 9870, 13, 865, 13, 10159, 2987, 538, 257, 3107, 294, 264, 2452, 2539, 1508, 300, 390, 510, 412, 264, 11888, 9446, 13], "temperature": 0.0, "avg_logprob": -0.09645983151027135, "compression_ratio": 1.3253968253968254, "no_speech_prob": 1.611954729696663e-07}, {"id": 336, "seek": 193084, "start": 1948.84, "end": 1951.84, "text": " And the idea behind the convolution is that it applies a filter.", "tokens": [400, 264, 1558, 2261, 264, 45216, 307, 300, 309, 13165, 257, 6608, 13], "temperature": 0.0, "avg_logprob": -0.09645983151027135, "compression_ratio": 1.3253968253968254, "no_speech_prob": 1.611954729696663e-07}, {"id": 337, "seek": 195184, "start": 1951.84, "end": 1960.84, "text": " So here we've got a filter that's just four numbers, alpha, beta, gamma and delta. And it's being applied to a picture.", "tokens": [407, 510, 321, 600, 658, 257, 6608, 300, 311, 445, 1451, 3547, 11, 8961, 11, 9861, 11, 15546, 293, 8289, 13, 400, 309, 311, 885, 6456, 281, 257, 3036, 13], "temperature": 0.0, "avg_logprob": -0.12762094011493758, "compression_ratio": 1.6317991631799162, "no_speech_prob": 1.1015624750143616e-06}, {"id": 338, "seek": 195184, "start": 1960.84, "end": 1963.84, "text": " Perhaps it's just three by three. So pretty small.", "tokens": [10517, 309, 311, 445, 1045, 538, 1045, 13, 407, 1238, 1359, 13], "temperature": 0.0, "avg_logprob": -0.12762094011493758, "compression_ratio": 1.6317991631799162, "no_speech_prob": 1.1015624750143616e-06}, {"id": 339, "seek": 195184, "start": 1963.84, "end": 1980.84, "text": " And you kind of put it in each location. So we put it in the top left corner and then we'll multiply alpha by a add that to beta times B plus D times gamma plus E times delta and get a single number out P as the result.", "tokens": [400, 291, 733, 295, 829, 309, 294, 1184, 4914, 13, 407, 321, 829, 309, 294, 264, 1192, 1411, 4538, 293, 550, 321, 603, 12972, 8961, 538, 257, 909, 300, 281, 9861, 1413, 363, 1804, 413, 1413, 15546, 1804, 462, 1413, 8289, 293, 483, 257, 2167, 1230, 484, 430, 382, 264, 1874, 13], "temperature": 0.0, "avg_logprob": -0.12762094011493758, "compression_ratio": 1.6317991631799162, "no_speech_prob": 1.1015624750143616e-06}, {"id": 340, "seek": 198084, "start": 1980.84, "end": 1985.84, "text": " And then you slide that filter across the picture and do it at each possible space.", "tokens": [400, 550, 291, 4137, 300, 6608, 2108, 264, 3036, 293, 360, 309, 412, 1184, 1944, 1901, 13], "temperature": 0.0, "avg_logprob": -0.07697604906440962, "compression_ratio": 1.6294820717131475, "no_speech_prob": 5.0143839871452656e-06}, {"id": 341, "seek": 198084, "start": 1985.84, "end": 1992.84, "text": " So here it is in the top right. We get out one result. Bottom left, bottom right.", "tokens": [407, 510, 309, 307, 294, 264, 1192, 558, 13, 492, 483, 484, 472, 1874, 13, 38289, 1411, 11, 2767, 558, 13], "temperature": 0.0, "avg_logprob": -0.07697604906440962, "compression_ratio": 1.6294820717131475, "no_speech_prob": 5.0143839871452656e-06}, {"id": 342, "seek": 198084, "start": 1992.84, "end": 2000.84, "text": " So this is just with a single filter on a small picture. And so that's kind of one way to think about how a convolution works.", "tokens": [407, 341, 307, 445, 365, 257, 2167, 6608, 322, 257, 1359, 3036, 13, 400, 370, 300, 311, 733, 295, 472, 636, 281, 519, 466, 577, 257, 45216, 1985, 13], "temperature": 0.0, "avg_logprob": -0.07697604906440962, "compression_ratio": 1.6294820717131475, "no_speech_prob": 5.0143839871452656e-06}, {"id": 343, "seek": 198084, "start": 2000.84, "end": 2006.84, "text": " Another is and I find these pictures less helpful, but a lot of people like to draw neural networks from this point.", "tokens": [3996, 307, 293, 286, 915, 613, 5242, 1570, 4961, 11, 457, 257, 688, 295, 561, 411, 281, 2642, 18161, 9590, 490, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.07697604906440962, "compression_ratio": 1.6294820717131475, "no_speech_prob": 5.0143839871452656e-06}, {"id": 344, "seek": 200684, "start": 2006.84, "end": 2012.84, "text": " So this is a neural network here. The alpha, beta, gamma and delta are the connections.", "tokens": [407, 341, 307, 257, 18161, 3209, 510, 13, 440, 8961, 11, 9861, 11, 15546, 293, 8289, 366, 264, 9271, 13], "temperature": 0.0, "avg_logprob": -0.0640395028250558, "compression_ratio": 1.7409326424870466, "no_speech_prob": 1.0782327990455087e-05}, {"id": 345, "seek": 200684, "start": 2012.84, "end": 2014.84, "text": " And so those would be the weights on the connections.", "tokens": [400, 370, 729, 576, 312, 264, 17443, 322, 264, 9271, 13], "temperature": 0.0, "avg_logprob": -0.0640395028250558, "compression_ratio": 1.7409326424870466, "no_speech_prob": 1.0782327990455087e-05}, {"id": 346, "seek": 200684, "start": 2014.84, "end": 2022.84, "text": " So whenever you see a red line, that's saying there's a connection between A and P and the weight of that connection is alpha.", "tokens": [407, 5699, 291, 536, 257, 2182, 1622, 11, 300, 311, 1566, 456, 311, 257, 4984, 1296, 316, 293, 430, 293, 264, 3364, 295, 300, 4984, 307, 8961, 13], "temperature": 0.0, "avg_logprob": -0.0640395028250558, "compression_ratio": 1.7409326424870466, "no_speech_prob": 1.0782327990455087e-05}, {"id": 347, "seek": 200684, "start": 2022.84, "end": 2028.84, "text": " And so the same operation is happening that we saw before to get P.", "tokens": [400, 370, 264, 912, 6916, 307, 2737, 300, 321, 1866, 949, 281, 483, 430, 13], "temperature": 0.0, "avg_logprob": -0.0640395028250558, "compression_ratio": 1.7409326424870466, "no_speech_prob": 1.0782327990455087e-05}, {"id": 348, "seek": 202884, "start": 2028.84, "end": 2037.84, "text": " P has got four connections going into it. A times alpha, B times beta.", "tokens": [430, 575, 658, 1451, 9271, 516, 666, 309, 13, 316, 1413, 8961, 11, 363, 1413, 9861, 13], "temperature": 0.0, "avg_logprob": -0.13516702090992647, "compression_ratio": 1.583710407239819, "no_speech_prob": 8.315204240716412e-07}, {"id": 349, "seek": 202884, "start": 2037.84, "end": 2047.84, "text": " D times, is that right? Yeah. D times gamma and then what else? E times delta.", "tokens": [413, 1413, 11, 307, 300, 558, 30, 865, 13, 413, 1413, 15546, 293, 550, 437, 1646, 30, 462, 1413, 8289, 13], "temperature": 0.0, "avg_logprob": -0.13516702090992647, "compression_ratio": 1.583710407239819, "no_speech_prob": 8.315204240716412e-07}, {"id": 350, "seek": 202884, "start": 2047.84, "end": 2049.84, "text": " So that's another perspective.", "tokens": [407, 300, 311, 1071, 4585, 13], "temperature": 0.0, "avg_logprob": -0.13516702090992647, "compression_ratio": 1.583710407239819, "no_speech_prob": 8.315204240716412e-07}, {"id": 351, "seek": 202884, "start": 2049.84, "end": 2057.84, "text": " And I really, I really like this approach of thinking about topics from different perspectives because I think that kind of help can help you get a deeper understanding.", "tokens": [400, 286, 534, 11, 286, 534, 411, 341, 3109, 295, 1953, 466, 8378, 490, 819, 16766, 570, 286, 519, 300, 733, 295, 854, 393, 854, 291, 483, 257, 7731, 3701, 13], "temperature": 0.0, "avg_logprob": -0.13516702090992647, "compression_ratio": 1.583710407239819, "no_speech_prob": 8.315204240716412e-07}, {"id": 352, "seek": 205784, "start": 2057.84, "end": 2072.84, "text": " And then this is neat. Here Matthew's kind of unrolled the filter and put it into this larger sparse matrix and shown, hey, this is actually a matrix multiplication.", "tokens": [400, 550, 341, 307, 10654, 13, 1692, 12434, 311, 733, 295, 517, 28850, 264, 6608, 293, 829, 309, 666, 341, 4833, 637, 11668, 8141, 293, 4898, 11, 4177, 11, 341, 307, 767, 257, 8141, 27290, 13], "temperature": 0.0, "avg_logprob": -0.11918896978551691, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.0029731356553384e-06}, {"id": 353, "seek": 205784, "start": 2072.84, "end": 2077.84, "text": " So now our kind of A, B, C, D, E from our picture is just a single vector.", "tokens": [407, 586, 527, 733, 295, 316, 11, 363, 11, 383, 11, 413, 11, 462, 490, 527, 3036, 307, 445, 257, 2167, 8062, 13], "temperature": 0.0, "avg_logprob": -0.11918896978551691, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.0029731356553384e-06}, {"id": 354, "seek": 205784, "start": 2077.84, "end": 2081.84, "text": " And we've got this sparse matrix and not just sparse means it has a lot of zeros.", "tokens": [400, 321, 600, 658, 341, 637, 11668, 8141, 293, 406, 445, 637, 11668, 1355, 309, 575, 257, 688, 295, 35193, 13], "temperature": 0.0, "avg_logprob": -0.11918896978551691, "compression_ratio": 1.5862068965517242, "no_speech_prob": 1.0029731356553384e-06}, {"id": 355, "seek": 208184, "start": 2081.84, "end": 2089.84, "text": " And those actually show up a lot, kind of matrices that have lots of zeros in a specific structure like this one does with the diagonals.", "tokens": [400, 729, 767, 855, 493, 257, 688, 11, 733, 295, 32284, 300, 362, 3195, 295, 35193, 294, 257, 2685, 3877, 411, 341, 472, 775, 365, 264, 17405, 1124, 13], "temperature": 0.0, "avg_logprob": -0.07009772618611654, "compression_ratio": 1.5073170731707317, "no_speech_prob": 2.19074490814819e-06}, {"id": 356, "seek": 208184, "start": 2089.84, "end": 2098.84, "text": " And you can do a matrix multiplication and get the same result. Any questions?", "tokens": [400, 291, 393, 360, 257, 8141, 27290, 293, 483, 264, 912, 1874, 13, 2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.07009772618611654, "compression_ratio": 1.5073170731707317, "no_speech_prob": 2.19074490814819e-06}, {"id": 357, "seek": 208184, "start": 2098.84, "end": 2108.84, "text": " OK, so now we're going to look at how we could use this for edge detection in this notebook.", "tokens": [2264, 11, 370, 586, 321, 434, 516, 281, 574, 412, 577, 321, 727, 764, 341, 337, 4691, 17784, 294, 341, 21060, 13], "temperature": 0.0, "avg_logprob": -0.07009772618611654, "compression_ratio": 1.5073170731707317, "no_speech_prob": 2.19074490814819e-06}, {"id": 358, "seek": 210884, "start": 2108.84, "end": 2112.84, "text": " And this don't worry, don't worry too much about the setup.", "tokens": [400, 341, 500, 380, 3292, 11, 500, 380, 3292, 886, 709, 466, 264, 8657, 13], "temperature": 0.0, "avg_logprob": -0.12792273930140904, "compression_ratio": 1.591160220994475, "no_speech_prob": 7.182485660450766e-06}, {"id": 359, "seek": 210884, "start": 2112.84, "end": 2118.84, "text": " But these are kind of the files you need to or libraries you need to import.", "tokens": [583, 613, 366, 733, 295, 264, 7098, 291, 643, 281, 420, 15148, 291, 643, 281, 974, 13], "temperature": 0.0, "avg_logprob": -0.12792273930140904, "compression_ratio": 1.591160220994475, "no_speech_prob": 7.182485660450766e-06}, {"id": 360, "seek": 210884, "start": 2118.84, "end": 2123.84, "text": " Yes. This notebook is called Convolution Intro. Yes. Oh, thank you.", "tokens": [1079, 13, 639, 21060, 307, 1219, 2656, 85, 3386, 47406, 13, 1079, 13, 876, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.12792273930140904, "compression_ratio": 1.591160220994475, "no_speech_prob": 7.182485660450766e-06}, {"id": 361, "seek": 210884, "start": 2123.84, "end": 2130.84, "text": " This is Convolution Intro and this was originally part of the deep learning course.", "tokens": [639, 307, 2656, 85, 3386, 47406, 293, 341, 390, 7993, 644, 295, 264, 2452, 2539, 1164, 13], "temperature": 0.0, "avg_logprob": -0.12792273930140904, "compression_ratio": 1.591160220994475, "no_speech_prob": 7.182485660450766e-06}, {"id": 362, "seek": 213084, "start": 2130.84, "end": 2138.84, "text": " So we'll be looking at MNIST data, which is this really popular data set of lots of handwritten digits.", "tokens": [407, 321, 603, 312, 1237, 412, 376, 45, 19756, 1412, 11, 597, 307, 341, 534, 3743, 1412, 992, 295, 3195, 295, 1011, 26859, 27011, 13], "temperature": 0.0, "avg_logprob": -0.06107876175328305, "compression_ratio": 1.497737556561086, "no_speech_prob": 3.61138381776982e-06}, {"id": 363, "seek": 213084, "start": 2138.84, "end": 2146.84, "text": " This is very useful for banks being able to automatically identify when you insert your check into the ATM, what the numbers on it are.", "tokens": [639, 307, 588, 4420, 337, 10237, 885, 1075, 281, 6772, 5876, 562, 291, 8969, 428, 1520, 666, 264, 46455, 11, 437, 264, 3547, 322, 309, 366, 13], "temperature": 0.0, "avg_logprob": -0.06107876175328305, "compression_ratio": 1.497737556561086, "no_speech_prob": 3.61138381776982e-06}, {"id": 364, "seek": 213084, "start": 2146.84, "end": 2153.84, "text": " Post offices automatically sort our mail by zip code using image recognition on the digits.", "tokens": [10223, 14434, 6772, 1333, 527, 10071, 538, 20730, 3089, 1228, 3256, 11150, 322, 264, 27011, 13], "temperature": 0.0, "avg_logprob": -0.06107876175328305, "compression_ratio": 1.497737556561086, "no_speech_prob": 3.61138381776982e-06}, {"id": 365, "seek": 215384, "start": 2153.84, "end": 2163.84, "text": " And then I should say Scikit-learn has a lot of built in data sets, which are a really useful feature and we'll be using several of them in this course.", "tokens": [400, 550, 286, 820, 584, 16942, 22681, 12, 306, 1083, 575, 257, 688, 295, 3094, 294, 1412, 6352, 11, 597, 366, 257, 534, 4420, 4111, 293, 321, 603, 312, 1228, 2940, 295, 552, 294, 341, 1164, 13], "temperature": 0.0, "avg_logprob": -0.12416642777463223, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3006017070438247e-05}, {"id": 366, "seek": 215384, "start": 2163.84, "end": 2171.84, "text": " Yeah, so we kind of import and here we're so for the larger data sets that Scikit-learn includes, it doesn't include the data set.", "tokens": [865, 11, 370, 321, 733, 295, 974, 293, 510, 321, 434, 370, 337, 264, 4833, 1412, 6352, 300, 16942, 22681, 12, 306, 1083, 5974, 11, 309, 1177, 380, 4090, 264, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.12416642777463223, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3006017070438247e-05}, {"id": 367, "seek": 215384, "start": 2171.84, "end": 2175.84, "text": " It includes a data loading utility that you can run to get the actual data.", "tokens": [467, 5974, 257, 1412, 15114, 14877, 300, 291, 393, 1190, 281, 483, 264, 3539, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12416642777463223, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3006017070438247e-05}, {"id": 368, "seek": 217584, "start": 2175.84, "end": 2186.84, "text": " So we run that. You can kind of check what the keys are of what you get back because you're kind of getting back this dictionary like object.", "tokens": [407, 321, 1190, 300, 13, 509, 393, 733, 295, 1520, 437, 264, 9317, 366, 295, 437, 291, 483, 646, 570, 291, 434, 733, 295, 1242, 646, 341, 25890, 411, 2657, 13], "temperature": 0.0, "avg_logprob": -0.07724230832392627, "compression_ratio": 1.7959183673469388, "no_speech_prob": 8.938795872381888e-06}, {"id": 369, "seek": 217584, "start": 2186.84, "end": 2195.84, "text": " We're interested in the data and the target and target is going to be kind of the label of saying this is what the digit is.", "tokens": [492, 434, 3102, 294, 264, 1412, 293, 264, 3779, 293, 3779, 307, 516, 281, 312, 733, 295, 264, 7645, 295, 1566, 341, 307, 437, 264, 14293, 307, 13], "temperature": 0.0, "avg_logprob": -0.07724230832392627, "compression_ratio": 1.7959183673469388, "no_speech_prob": 8.938795872381888e-06}, {"id": 370, "seek": 217584, "start": 2195.84, "end": 2203.84, "text": " The data itself and then something else that's always great to do whenever you're kind of starting anything is just check your dimensions to see if they are what you expect.", "tokens": [440, 1412, 2564, 293, 550, 746, 1646, 300, 311, 1009, 869, 281, 360, 5699, 291, 434, 733, 295, 2891, 1340, 307, 445, 1520, 428, 12819, 281, 536, 498, 436, 366, 437, 291, 2066, 13], "temperature": 0.0, "avg_logprob": -0.07724230832392627, "compression_ratio": 1.7959183673469388, "no_speech_prob": 8.938795872381888e-06}, {"id": 371, "seek": 220384, "start": 2203.84, "end": 2208.84, "text": " And you can often also kind of find stuff about the meaning based on the dimensions.", "tokens": [400, 291, 393, 2049, 611, 733, 295, 915, 1507, 466, 264, 3620, 2361, 322, 264, 12819, 13], "temperature": 0.0, "avg_logprob": -0.0659161095667367, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.3496244264388224e-06}, {"id": 372, "seek": 220384, "start": 2208.84, "end": 2214.84, "text": " So here this is seventy thousand by seven hundred and eighty four.", "tokens": [407, 510, 341, 307, 25662, 4714, 538, 3407, 3262, 293, 26348, 1451, 13], "temperature": 0.0, "avg_logprob": -0.0659161095667367, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.3496244264388224e-06}, {"id": 373, "seek": 220384, "start": 2214.84, "end": 2220.84, "text": " So even if you didn't know, you could guess, hey, maybe this is seventy thousand different samples or different digits.", "tokens": [407, 754, 498, 291, 994, 380, 458, 11, 291, 727, 2041, 11, 4177, 11, 1310, 341, 307, 25662, 4714, 819, 10938, 420, 819, 27011, 13], "temperature": 0.0, "avg_logprob": -0.0659161095667367, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.3496244264388224e-06}, {"id": 374, "seek": 220384, "start": 2220.84, "end": 2224.84, "text": " And this is a twenty eight by twenty eight if it was put back together.", "tokens": [400, 341, 307, 257, 7699, 3180, 538, 7699, 3180, 498, 309, 390, 829, 646, 1214, 13], "temperature": 0.0, "avg_logprob": -0.0659161095667367, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.3496244264388224e-06}, {"id": 375, "seek": 220384, "start": 2224.84, "end": 2230.84, "text": " So each row is just a single digit that's kind of been unrolled.", "tokens": [407, 1184, 5386, 307, 445, 257, 2167, 14293, 300, 311, 733, 295, 668, 517, 28850, 13], "temperature": 0.0, "avg_logprob": -0.0659161095667367, "compression_ratio": 1.7361702127659575, "no_speech_prob": 1.3496244264388224e-06}, {"id": 376, "seek": 223084, "start": 2230.84, "end": 2235.84, "text": " And so we're going to reshape them to be twenty eight by twenty eight using num pies reshape.", "tokens": [400, 370, 321, 434, 516, 281, 725, 42406, 552, 281, 312, 7699, 3180, 538, 7699, 3180, 1228, 1031, 29640, 725, 42406, 13], "temperature": 0.0, "avg_logprob": -0.08016975914559714, "compression_ratio": 1.6958762886597938, "no_speech_prob": 5.453122184917447e-07}, {"id": 377, "seek": 223084, "start": 2235.84, "end": 2242.84, "text": " So now we have an often so kind of higher dimensional matrices are referred to as tensors.", "tokens": [407, 586, 321, 362, 364, 2049, 370, 733, 295, 2946, 18795, 32284, 366, 10839, 281, 382, 10688, 830, 13], "temperature": 0.0, "avg_logprob": -0.08016975914559714, "compression_ratio": 1.6958762886597938, "no_speech_prob": 5.453122184917447e-07}, {"id": 378, "seek": 223084, "start": 2242.84, "end": 2252.84, "text": " So you could say this is a tensor that's seventy thousand by twenty eight by twenty eight.", "tokens": [407, 291, 727, 584, 341, 307, 257, 40863, 300, 311, 25662, 4714, 538, 7699, 3180, 538, 7699, 3180, 13], "temperature": 0.0, "avg_logprob": -0.08016975914559714, "compression_ratio": 1.6958762886597938, "no_speech_prob": 5.453122184917447e-07}, {"id": 379, "seek": 223084, "start": 2252.84, "end": 2257.84, "text": " So for the labels, we're converting them to integers.", "tokens": [407, 337, 264, 16949, 11, 321, 434, 29942, 552, 281, 41674, 13], "temperature": 0.0, "avg_logprob": -0.08016975914559714, "compression_ratio": 1.6958762886597938, "no_speech_prob": 5.453122184917447e-07}, {"id": 380, "seek": 225784, "start": 2257.84, "end": 2263.84, "text": " And then we're going to it's actually best to probably kind of skip to looking at these places.", "tokens": [400, 550, 321, 434, 516, 281, 309, 311, 767, 1151, 281, 1391, 733, 295, 10023, 281, 1237, 412, 613, 3190, 13], "temperature": 0.0, "avg_logprob": -0.17105754216512045, "compression_ratio": 1.5194805194805194, "no_speech_prob": 4.05251171287091e-07}, {"id": 381, "seek": 225784, "start": 2263.84, "end": 2270.84, "text": " So here we've plotted images zero. So that's the kind of first entry of images.", "tokens": [407, 510, 321, 600, 43288, 5267, 4018, 13, 407, 300, 311, 264, 733, 295, 700, 8729, 295, 5267, 13], "temperature": 0.0, "avg_logprob": -0.17105754216512045, "compression_ratio": 1.5194805194805194, "no_speech_prob": 4.05251171287091e-07}, {"id": 382, "seek": 225784, "start": 2270.84, "end": 2283.84, "text": " And you could confirm that's twenty eight by twenty eight.", "tokens": [400, 291, 727, 9064, 300, 311, 7699, 3180, 538, 7699, 3180, 13], "temperature": 0.0, "avg_logprob": -0.17105754216512045, "compression_ratio": 1.5194805194805194, "no_speech_prob": 4.05251171287091e-07}, {"id": 383, "seek": 228384, "start": 2283.84, "end": 2287.84, "text": " That's our our picture. So we plot it. It's a zero.", "tokens": [663, 311, 527, 527, 3036, 13, 407, 321, 7542, 309, 13, 467, 311, 257, 4018, 13], "temperature": 0.0, "avg_logprob": -0.16103593190511067, "compression_ratio": 1.3952095808383234, "no_speech_prob": 1.084492396330461e-06}, {"id": 384, "seek": 228384, "start": 2287.84, "end": 2292.84, "text": " We check the label and that is also or says zero.", "tokens": [492, 1520, 264, 7645, 293, 300, 307, 611, 420, 1619, 4018, 13], "temperature": 0.0, "avg_logprob": -0.16103593190511067, "compression_ratio": 1.3952095808383234, "no_speech_prob": 1.084492396330461e-06}, {"id": 385, "seek": 228384, "start": 2292.84, "end": 2300.84, "text": " Was that a hand over here?", "tokens": [3027, 300, 257, 1011, 670, 510, 30], "temperature": 0.0, "avg_logprob": -0.16103593190511067, "compression_ratio": 1.3952095808383234, "no_speech_prob": 1.084492396330461e-06}, {"id": 386, "seek": 228384, "start": 2300.84, "end": 2302.84, "text": " OK, so that's a great question.", "tokens": [2264, 11, 370, 300, 311, 257, 869, 1168, 13], "temperature": 0.0, "avg_logprob": -0.16103593190511067, "compression_ratio": 1.3952095808383234, "no_speech_prob": 1.084492396330461e-06}, {"id": 387, "seek": 228384, "start": 2302.84, "end": 2310.84, "text": " Oh, OK. Yeah. The question was why are we dividing by two fifty five in.", "tokens": [876, 11, 2264, 13, 865, 13, 440, 1168, 390, 983, 366, 321, 26764, 538, 732, 13442, 1732, 294, 13], "temperature": 0.0, "avg_logprob": -0.16103593190511067, "compression_ratio": 1.3952095808383234, "no_speech_prob": 1.084492396330461e-06}, {"id": 388, "seek": 231084, "start": 2310.84, "end": 2315.84, "text": " I guess input fifty three, which I should probably run again in this.", "tokens": [286, 2041, 4846, 13442, 1045, 11, 597, 286, 820, 1391, 1190, 797, 294, 341, 13], "temperature": 0.0, "avg_logprob": -0.11074303358029096, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.1567384465015493e-06}, {"id": 389, "seek": 231084, "start": 2315.84, "end": 2318.84, "text": " You you wouldn't have to and it would still plot properly.", "tokens": [509, 291, 2759, 380, 362, 281, 293, 309, 576, 920, 7542, 6108, 13], "temperature": 0.0, "avg_logprob": -0.11074303358029096, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.1567384465015493e-06}, {"id": 390, "seek": 231084, "start": 2318.84, "end": 2331.84, "text": " This comes up later. When when we're using correlate, I believe.", "tokens": [639, 1487, 493, 1780, 13, 1133, 562, 321, 434, 1228, 48742, 11, 286, 1697, 13], "temperature": 0.0, "avg_logprob": -0.11074303358029096, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.1567384465015493e-06}, {"id": 391, "seek": 231084, "start": 2331.84, "end": 2337.84, "text": " But yeah, if you plot it, if you. So we're trying to turn these into numbers between zero and one.", "tokens": [583, 1338, 11, 498, 291, 7542, 309, 11, 498, 291, 13, 407, 321, 434, 1382, 281, 1261, 613, 666, 3547, 1296, 4018, 293, 472, 13], "temperature": 0.0, "avg_logprob": -0.11074303358029096, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.1567384465015493e-06}, {"id": 392, "seek": 233784, "start": 2337.84, "end": 2341.84, "text": " It would still work if you had them between zero and two fifty five.", "tokens": [467, 576, 920, 589, 498, 291, 632, 552, 1296, 4018, 293, 732, 13442, 1732, 13], "temperature": 0.0, "avg_logprob": -0.07998571925693088, "compression_ratio": 1.5748792270531402, "no_speech_prob": 2.6424941097502597e-06}, {"id": 393, "seek": 233784, "start": 2341.84, "end": 2351.84, "text": " So kind of just a way of normalizing.", "tokens": [407, 733, 295, 445, 257, 636, 295, 2710, 3319, 13], "temperature": 0.0, "avg_logprob": -0.07998571925693088, "compression_ratio": 1.5748792270531402, "no_speech_prob": 2.6424941097502597e-06}, {"id": 394, "seek": 233784, "start": 2351.84, "end": 2354.84, "text": " Or sorry, I should say the plots would still work.", "tokens": [1610, 2597, 11, 286, 820, 584, 264, 28609, 576, 920, 589, 13], "temperature": 0.0, "avg_logprob": -0.07998571925693088, "compression_ratio": 1.5748792270531402, "no_speech_prob": 2.6424941097502597e-06}, {"id": 395, "seek": 233784, "start": 2354.84, "end": 2358.84, "text": " It would still be when you plot it, you'd be like, this is clearly the same image.", "tokens": [467, 576, 920, 312, 562, 291, 7542, 309, 11, 291, 1116, 312, 411, 11, 341, 307, 4448, 264, 912, 3256, 13], "temperature": 0.0, "avg_logprob": -0.07998571925693088, "compression_ratio": 1.5748792270531402, "no_speech_prob": 2.6424941097502597e-06}, {"id": 396, "seek": 233784, "start": 2358.84, "end": 2365.84, "text": " Some of the computations we're going to use later. We needed it to be normalized for.", "tokens": [2188, 295, 264, 2807, 763, 321, 434, 516, 281, 764, 1780, 13, 492, 2978, 309, 281, 312, 48704, 337, 13], "temperature": 0.0, "avg_logprob": -0.07998571925693088, "compression_ratio": 1.5748792270531402, "no_speech_prob": 2.6424941097502597e-06}, {"id": 397, "seek": 236584, "start": 2365.84, "end": 2367.84, "text": " Here we also have a plots helper function.", "tokens": [1692, 321, 611, 362, 257, 28609, 36133, 2445, 13], "temperature": 0.0, "avg_logprob": -0.0854913897630645, "compression_ratio": 1.6938775510204083, "no_speech_prob": 6.643055712629575e-06}, {"id": 398, "seek": 236584, "start": 2367.84, "end": 2371.84, "text": " And so these were the methods that were kind of defined up here.", "tokens": [400, 370, 613, 645, 264, 7150, 300, 645, 733, 295, 7642, 493, 510, 13], "temperature": 0.0, "avg_logprob": -0.0854913897630645, "compression_ratio": 1.6938775510204083, "no_speech_prob": 6.643055712629575e-06}, {"id": 399, "seek": 236584, "start": 2371.84, "end": 2379.84, "text": " Although I don't worry too much about the details of them unless you're particularly interested.", "tokens": [5780, 286, 500, 380, 3292, 886, 709, 466, 264, 4365, 295, 552, 5969, 291, 434, 4098, 3102, 13], "temperature": 0.0, "avg_logprob": -0.0854913897630645, "compression_ratio": 1.6938775510204083, "no_speech_prob": 6.643055712629575e-06}, {"id": 400, "seek": 236584, "start": 2379.84, "end": 2384.84, "text": " We're using it, it lets us put in a whole array of images and plots them like this,", "tokens": [492, 434, 1228, 309, 11, 309, 6653, 505, 829, 294, 257, 1379, 10225, 295, 5267, 293, 28609, 552, 411, 341, 11], "temperature": 0.0, "avg_logprob": -0.0854913897630645, "compression_ratio": 1.6938775510204083, "no_speech_prob": 6.643055712629575e-06}, {"id": 401, "seek": 236584, "start": 2384.84, "end": 2388.84, "text": " which is really handy for being able to look at our data.", "tokens": [597, 307, 534, 13239, 337, 885, 1075, 281, 574, 412, 527, 1412, 13], "temperature": 0.0, "avg_logprob": -0.0854913897630645, "compression_ratio": 1.6938775510204083, "no_speech_prob": 6.643055712629575e-06}, {"id": 402, "seek": 236584, "start": 2388.84, "end": 2389.84, "text": " And this is also something I would recommend.", "tokens": [400, 341, 307, 611, 746, 286, 576, 2748, 13], "temperature": 0.0, "avg_logprob": -0.0854913897630645, "compression_ratio": 1.6938775510204083, "no_speech_prob": 6.643055712629575e-06}, {"id": 403, "seek": 236584, "start": 2389.84, "end": 2394.84, "text": " I think sometimes it can feel kind of finicky writing the helper methods to be able to look at your data.", "tokens": [286, 519, 2171, 309, 393, 841, 733, 295, 962, 20539, 3579, 264, 36133, 7150, 281, 312, 1075, 281, 574, 412, 428, 1412, 13], "temperature": 0.0, "avg_logprob": -0.0854913897630645, "compression_ratio": 1.6938775510204083, "no_speech_prob": 6.643055712629575e-06}, {"id": 404, "seek": 239484, "start": 2394.84, "end": 2399.84, "text": " But it's pretty much always worth it, because as you're doing computations,", "tokens": [583, 309, 311, 1238, 709, 1009, 3163, 309, 11, 570, 382, 291, 434, 884, 2807, 763, 11], "temperature": 0.0, "avg_logprob": -0.07984564277563203, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.6118401567364344e-06}, {"id": 405, "seek": 239484, "start": 2399.84, "end": 2405.84, "text": " you want to check that things are what you think they are and be able to see what your results are.", "tokens": [291, 528, 281, 1520, 300, 721, 366, 437, 291, 519, 436, 366, 293, 312, 1075, 281, 536, 437, 428, 3542, 366, 13], "temperature": 0.0, "avg_logprob": -0.07984564277563203, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.6118401567364344e-06}, {"id": 406, "seek": 239484, "start": 2405.84, "end": 2407.84, "text": " We can also zoom in on our images.", "tokens": [492, 393, 611, 8863, 294, 322, 527, 5267, 13], "temperature": 0.0, "avg_logprob": -0.07984564277563203, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.6118401567364344e-06}, {"id": 407, "seek": 239484, "start": 2407.84, "end": 2415.84, "text": " So if you want to see just a plot of part of one here, we're just getting the rows from zero to 14 columns from eight to 22.", "tokens": [407, 498, 291, 528, 281, 536, 445, 257, 7542, 295, 644, 295, 472, 510, 11, 321, 434, 445, 1242, 264, 13241, 490, 4018, 281, 3499, 13766, 490, 3180, 281, 5853, 13], "temperature": 0.0, "avg_logprob": -0.07984564277563203, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.6118401567364344e-06}, {"id": 408, "seek": 241584, "start": 2415.84, "end": 2427.84, "text": " So this is kind of the middle top of the zero is what this this thing is from this picture.", "tokens": [407, 341, 307, 733, 295, 264, 2808, 1192, 295, 264, 4018, 307, 437, 341, 341, 551, 307, 490, 341, 3036, 13], "temperature": 0.0, "avg_logprob": -0.12516935055072492, "compression_ratio": 1.4592592592592593, "no_speech_prob": 1.5534525346083683e-06}, {"id": 409, "seek": 241584, "start": 2427.84, "end": 2435.84, "text": " So for edge detection, we're going to have a matrix with a name that kind of gives a lot away called top.", "tokens": [407, 337, 4691, 17784, 11, 321, 434, 516, 281, 362, 257, 8141, 365, 257, 1315, 300, 733, 295, 2709, 257, 688, 1314, 1219, 1192, 13], "temperature": 0.0, "avg_logprob": -0.12516935055072492, "compression_ratio": 1.4592592592592593, "no_speech_prob": 1.5534525346083683e-06}, {"id": 410, "seek": 243584, "start": 2435.84, "end": 2445.84, "text": " That's negative ones along the top row, ones along the middle row and then zeros along the bottom.", "tokens": [663, 311, 3671, 2306, 2051, 264, 1192, 5386, 11, 2306, 2051, 264, 2808, 5386, 293, 550, 35193, 2051, 264, 2767, 13], "temperature": 0.0, "avg_logprob": -0.13278443673077753, "compression_ratio": 1.558139534883721, "no_speech_prob": 7.224314231280005e-07}, {"id": 411, "seek": 243584, "start": 2445.84, "end": 2447.84, "text": " And this is what what top looks like.", "tokens": [400, 341, 307, 437, 437, 1192, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.13278443673077753, "compression_ratio": 1.558139534883721, "no_speech_prob": 7.224314231280005e-07}, {"id": 412, "seek": 243584, "start": 2447.84, "end": 2455.84, "text": " And so something to keep in mind and actually here, this is an interesting perspective.", "tokens": [400, 370, 746, 281, 1066, 294, 1575, 293, 767, 510, 11, 341, 307, 364, 1880, 4585, 13], "temperature": 0.0, "avg_logprob": -0.13278443673077753, "compression_ratio": 1.558139534883721, "no_speech_prob": 7.224314231280005e-07}, {"id": 413, "seek": 243584, "start": 2455.84, "end": 2458.84, "text": " This could have been higher up using NumPy.", "tokens": [639, 727, 362, 668, 2946, 493, 1228, 22592, 47, 88, 13], "temperature": 0.0, "avg_logprob": -0.13278443673077753, "compression_ratio": 1.558139534883721, "no_speech_prob": 7.224314231280005e-07}, {"id": 414, "seek": 245884, "start": 2458.84, "end": 2465.84, "text": " We can look at kind of just a part of the the matrix and see this is so it's not plot plotted.", "tokens": [492, 393, 574, 412, 733, 295, 445, 257, 644, 295, 264, 264, 8141, 293, 536, 341, 307, 370, 309, 311, 406, 7542, 43288, 13], "temperature": 0.0, "avg_logprob": -0.05333275144750422, "compression_ratio": 1.6875, "no_speech_prob": 3.576303413410642e-07}, {"id": 415, "seek": 245884, "start": 2465.84, "end": 2467.84, "text": " But this is what the matrix looks like.", "tokens": [583, 341, 307, 437, 264, 8141, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.05333275144750422, "compression_ratio": 1.6875, "no_speech_prob": 3.576303413410642e-07}, {"id": 416, "seek": 245884, "start": 2467.84, "end": 2469.84, "text": " And here the zeros are black.", "tokens": [400, 510, 264, 35193, 366, 2211, 13], "temperature": 0.0, "avg_logprob": -0.05333275144750422, "compression_ratio": 1.6875, "no_speech_prob": 3.576303413410642e-07}, {"id": 417, "seek": 245884, "start": 2469.84, "end": 2476.84, "text": " And these numbers between zero and one are giving the intensity of the white part for the handwritten zero.", "tokens": [400, 613, 3547, 1296, 4018, 293, 472, 366, 2902, 264, 13749, 295, 264, 2418, 644, 337, 264, 1011, 26859, 4018, 13], "temperature": 0.0, "avg_logprob": -0.05333275144750422, "compression_ratio": 1.6875, "no_speech_prob": 3.576303413410642e-07}, {"id": 418, "seek": 245884, "start": 2476.84, "end": 2484.84, "text": " So we're still still kind of looking at this just from different perspectives.", "tokens": [407, 321, 434, 920, 920, 733, 295, 1237, 412, 341, 445, 490, 819, 16766, 13], "temperature": 0.0, "avg_logprob": -0.05333275144750422, "compression_ratio": 1.6875, "no_speech_prob": 3.576303413410642e-07}, {"id": 419, "seek": 248484, "start": 2484.84, "end": 2494.84, "text": " And so we're using a method called correlate and this came from its psychic learns image.", "tokens": [400, 370, 321, 434, 1228, 257, 3170, 1219, 48742, 293, 341, 1361, 490, 1080, 35406, 27152, 3256, 13], "temperature": 0.0, "avg_logprob": -0.27500123393778897, "compression_ratio": 1.2769230769230768, "no_speech_prob": 2.9479472232196713e-06}, {"id": 420, "seek": 248484, "start": 2494.84, "end": 2498.84, "text": " This.", "tokens": [639, 13], "temperature": 0.0, "avg_logprob": -0.27500123393778897, "compression_ratio": 1.2769230769230768, "no_speech_prob": 2.9479472232196713e-06}, {"id": 421, "seek": 248484, "start": 2498.84, "end": 2499.84, "text": " Oh, there it is. Sorry.", "tokens": [876, 11, 456, 309, 307, 13, 4919, 13], "temperature": 0.0, "avg_logprob": -0.27500123393778897, "compression_ratio": 1.2769230769230768, "no_speech_prob": 2.9479472232196713e-06}, {"id": 422, "seek": 248484, "start": 2499.84, "end": 2506.84, "text": " SciPy's ND image filters provides a correlate.", "tokens": [16942, 47, 88, 311, 40709, 3256, 15995, 6417, 257, 48742, 13], "temperature": 0.0, "avg_logprob": -0.27500123393778897, "compression_ratio": 1.2769230769230768, "no_speech_prob": 2.9479472232196713e-06}, {"id": 423, "seek": 250684, "start": 2506.84, "end": 2517.84, "text": " Relate method and then something you can do that's nice feature of Jupyter Notebook is if you're inside the parentheses for a method,", "tokens": [8738, 473, 3170, 293, 550, 746, 291, 393, 360, 300, 311, 1481, 4111, 295, 22125, 88, 391, 11633, 2939, 307, 498, 291, 434, 1854, 264, 34153, 337, 257, 3170, 11], "temperature": 0.0, "avg_logprob": -0.09787069517990639, "compression_ratio": 1.5636363636363637, "no_speech_prob": 8.714191608305555e-07}, {"id": 424, "seek": 250684, "start": 2517.84, "end": 2524.84, "text": " if you hit shift tab a few times, it pulls up the method signature and documentation, which is nice to see.", "tokens": [498, 291, 2045, 5513, 4421, 257, 1326, 1413, 11, 309, 16982, 493, 264, 3170, 13397, 293, 14333, 11, 597, 307, 1481, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.09787069517990639, "compression_ratio": 1.5636363636363637, "no_speech_prob": 8.714191608305555e-07}, {"id": 425, "seek": 250684, "start": 2524.84, "end": 2529.84, "text": " And so this gives an array correlated with a given kernel.", "tokens": [400, 370, 341, 2709, 364, 10225, 38574, 365, 257, 2212, 28256, 13], "temperature": 0.0, "avg_logprob": -0.09787069517990639, "compression_ratio": 1.5636363636363637, "no_speech_prob": 8.714191608305555e-07}, {"id": 426, "seek": 250684, "start": 2529.84, "end": 2533.84, "text": " And so here we pass in images zero and top.", "tokens": [400, 370, 510, 321, 1320, 294, 5267, 4018, 293, 1192, 13], "temperature": 0.0, "avg_logprob": -0.09787069517990639, "compression_ratio": 1.5636363636363637, "no_speech_prob": 8.714191608305555e-07}, {"id": 427, "seek": 253384, "start": 2533.84, "end": 2536.84, "text": " And if we plot that.", "tokens": [400, 498, 321, 7542, 300, 13], "temperature": 0.0, "avg_logprob": -0.10405089638449928, "compression_ratio": 1.723809523809524, "no_speech_prob": 7.64615924708778e-06}, {"id": 428, "seek": 253384, "start": 2536.84, "end": 2537.84, "text": " This is what we get.", "tokens": [639, 307, 437, 321, 483, 13], "temperature": 0.0, "avg_logprob": -0.10405089638449928, "compression_ratio": 1.723809523809524, "no_speech_prob": 7.64615924708778e-06}, {"id": 429, "seek": 253384, "start": 2537.84, "end": 2548.84, "text": " And so you'll kind of notice that they're white, which is the highest value along the tops of the zero and black kind of the lowest values along the bottoms of the edges.", "tokens": [400, 370, 291, 603, 733, 295, 3449, 300, 436, 434, 2418, 11, 597, 307, 264, 6343, 2158, 2051, 264, 22836, 295, 264, 4018, 293, 2211, 733, 295, 264, 12437, 4190, 2051, 264, 43413, 295, 264, 8819, 13], "temperature": 0.0, "avg_logprob": -0.10405089638449928, "compression_ratio": 1.723809523809524, "no_speech_prob": 7.64615924708778e-06}, {"id": 430, "seek": 253384, "start": 2548.84, "end": 2551.84, "text": " So this is picked off the edges.", "tokens": [407, 341, 307, 6183, 766, 264, 8819, 13], "temperature": 0.0, "avg_logprob": -0.10405089638449928, "compression_ratio": 1.723809523809524, "no_speech_prob": 7.64615924708778e-06}, {"id": 431, "seek": 253384, "start": 2551.84, "end": 2557.84, "text": " I'm going to talk about kind of what's going on there with this.", "tokens": [286, 478, 516, 281, 751, 466, 733, 295, 437, 311, 516, 322, 456, 365, 341, 13], "temperature": 0.0, "avg_logprob": -0.10405089638449928, "compression_ratio": 1.723809523809524, "no_speech_prob": 7.64615924708778e-06}, {"id": 432, "seek": 253384, "start": 2557.84, "end": 2560.84, "text": " Negative one, one and zero way to think about that.", "tokens": [43230, 472, 11, 472, 293, 4018, 636, 281, 519, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.10405089638449928, "compression_ratio": 1.723809523809524, "no_speech_prob": 7.64615924708778e-06}, {"id": 433, "seek": 256084, "start": 2560.84, "end": 2567.84, "text": " That's going to be greatest when the negative ones are multiplying by zeros and getting canceled out.", "tokens": [663, 311, 516, 281, 312, 6636, 562, 264, 3671, 2306, 366, 30955, 538, 35193, 293, 1242, 24839, 484, 13], "temperature": 0.0, "avg_logprob": -0.10336405191666041, "compression_ratio": 1.5804878048780489, "no_speech_prob": 1.3787487773697649e-07}, {"id": 434, "seek": 256084, "start": 2567.84, "end": 2574.84, "text": " We were trying to think about how could we maximize top multiplied by something else.", "tokens": [492, 645, 1382, 281, 519, 466, 577, 727, 321, 19874, 1192, 17207, 538, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.10336405191666041, "compression_ratio": 1.5804878048780489, "no_speech_prob": 1.3787487773697649e-07}, {"id": 435, "seek": 256084, "start": 2574.84, "end": 2575.84, "text": " And this is I should be clear.", "tokens": [400, 341, 307, 286, 820, 312, 1850, 13], "temperature": 0.0, "avg_logprob": -0.10336405191666041, "compression_ratio": 1.5804878048780489, "no_speech_prob": 1.3787487773697649e-07}, {"id": 436, "seek": 256084, "start": 2575.84, "end": 2578.84, "text": " This is element wise multiplication we're doing.", "tokens": [639, 307, 4478, 10829, 27290, 321, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.10336405191666041, "compression_ratio": 1.5804878048780489, "no_speech_prob": 1.3787487773697649e-07}, {"id": 437, "seek": 256084, "start": 2578.84, "end": 2582.84, "text": " So this is not a matrix product, but we're element wise.", "tokens": [407, 341, 307, 406, 257, 8141, 1674, 11, 457, 321, 434, 4478, 10829, 13], "temperature": 0.0, "avg_logprob": -0.10336405191666041, "compression_ratio": 1.5804878048780489, "no_speech_prob": 1.3787487773697649e-07}, {"id": 438, "seek": 258284, "start": 2582.84, "end": 2590.84, "text": " And if you know, putting the filter on top of something and then multiplying each element on what it's kind of on top of.", "tokens": [400, 498, 291, 458, 11, 3372, 264, 6608, 322, 1192, 295, 746, 293, 550, 30955, 1184, 4478, 322, 437, 309, 311, 733, 295, 322, 1192, 295, 13], "temperature": 0.0, "avg_logprob": -0.119256475697393, "compression_ratio": 1.618279569892473, "no_speech_prob": 8.059133165261301e-07}, {"id": 439, "seek": 258284, "start": 2590.84, "end": 2602.84, "text": " And so having zeros in a full row and then having like the highest value since this is normalized, which should be ones and another row that would give the biggest value for this.", "tokens": [400, 370, 1419, 35193, 294, 257, 1577, 5386, 293, 550, 1419, 411, 264, 6343, 2158, 1670, 341, 307, 48704, 11, 597, 820, 312, 2306, 293, 1071, 5386, 300, 576, 976, 264, 3880, 2158, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.119256475697393, "compression_ratio": 1.618279569892473, "no_speech_prob": 8.059133165261301e-07}, {"id": 440, "seek": 260284, "start": 2602.84, "end": 2613.84, "text": " And so that's why it's picking out tops, because it's whenever you go from something small to something large, this this correlation will have the highest values.", "tokens": [400, 370, 300, 311, 983, 309, 311, 8867, 484, 22836, 11, 570, 309, 311, 5699, 291, 352, 490, 746, 1359, 281, 746, 2416, 11, 341, 341, 20009, 486, 362, 264, 6343, 4190, 13], "temperature": 0.0, "avg_logprob": -0.14405249167179715, "compression_ratio": 1.6082474226804124, "no_speech_prob": 3.288541847723536e-06}, {"id": 441, "seek": 260284, "start": 2613.84, "end": 2620.84, "text": " Questions.", "tokens": [27738, 13], "temperature": 0.0, "avg_logprob": -0.14405249167179715, "compression_ratio": 1.6082474226804124, "no_speech_prob": 3.288541847723536e-06}, {"id": 442, "seek": 260284, "start": 2620.84, "end": 2629.84, "text": " I yes. Yeah. OK. So Jeremy asked the question about convolution versus core or suggested that I talk about convolution versus correlation.", "tokens": [286, 2086, 13, 865, 13, 2264, 13, 407, 17809, 2351, 264, 1168, 466, 45216, 5717, 4965, 420, 10945, 300, 286, 751, 466, 45216, 5717, 20009, 13], "temperature": 0.0, "avg_logprob": -0.14405249167179715, "compression_ratio": 1.6082474226804124, "no_speech_prob": 3.288541847723536e-06}, {"id": 443, "seek": 262984, "start": 2629.84, "end": 2633.84, "text": " The key difference is just with convolutions, they're actually flipped.", "tokens": [440, 2141, 2649, 307, 445, 365, 3754, 15892, 11, 436, 434, 767, 26273, 13], "temperature": 0.0, "avg_logprob": -0.13314408389004795, "compression_ratio": 1.7154471544715446, "no_speech_prob": 2.2731936155651056e-07}, {"id": 444, "seek": 262984, "start": 2633.84, "end": 2640.84, "text": " And so this is kind of a mathematical accounting thing.", "tokens": [400, 370, 341, 307, 733, 295, 257, 18894, 19163, 551, 13], "temperature": 0.0, "avg_logprob": -0.13314408389004795, "compression_ratio": 1.7154471544715446, "no_speech_prob": 2.2731936155651056e-07}, {"id": 445, "seek": 262984, "start": 2640.84, "end": 2643.84, "text": " Right. Like there's not a yeah, but it's yeah.", "tokens": [1779, 13, 1743, 456, 311, 406, 257, 1338, 11, 457, 309, 311, 1338, 13], "temperature": 0.0, "avg_logprob": -0.13314408389004795, "compression_ratio": 1.7154471544715446, "no_speech_prob": 2.2731936155651056e-07}, {"id": 446, "seek": 262984, "start": 2643.84, "end": 2649.84, "text": " So it's really it's the same and kind of in the math you take into account like, oh, the K this has actually been rotated when you're doing a convolution.", "tokens": [407, 309, 311, 534, 309, 311, 264, 912, 293, 733, 295, 294, 264, 5221, 291, 747, 666, 2696, 411, 11, 1954, 11, 264, 591, 341, 575, 767, 668, 42146, 562, 291, 434, 884, 257, 45216, 13], "temperature": 0.0, "avg_logprob": -0.13314408389004795, "compression_ratio": 1.7154471544715446, "no_speech_prob": 2.2731936155651056e-07}, {"id": 447, "seek": 262984, "start": 2649.84, "end": 2652.84, "text": " But it's the same idea as a correlation.", "tokens": [583, 309, 311, 264, 912, 1558, 382, 257, 20009, 13], "temperature": 0.0, "avg_logprob": -0.13314408389004795, "compression_ratio": 1.7154471544715446, "no_speech_prob": 2.2731936155651056e-07}, {"id": 448, "seek": 262984, "start": 2652.84, "end": 2654.84, "text": " And I think correlations are easier to think about.", "tokens": [400, 286, 519, 13983, 763, 366, 3571, 281, 519, 466, 13], "temperature": 0.0, "avg_logprob": -0.13314408389004795, "compression_ratio": 1.7154471544715446, "no_speech_prob": 2.2731936155651056e-07}, {"id": 449, "seek": 265484, "start": 2654.84, "end": 2659.84, "text": " Otherwise, you're just kind of flipping everything, but getting the same result.", "tokens": [10328, 11, 291, 434, 445, 733, 295, 26886, 1203, 11, 457, 1242, 264, 912, 1874, 13], "temperature": 0.0, "avg_logprob": -0.22411101864230248, "compression_ratio": 1.4745762711864407, "no_speech_prob": 1.723000059428159e-05}, {"id": 450, "seek": 265484, "start": 2659.84, "end": 2662.84, "text": " Let me give you that.", "tokens": [961, 385, 976, 291, 300, 13], "temperature": 0.0, "avg_logprob": -0.22411101864230248, "compression_ratio": 1.4745762711864407, "no_speech_prob": 1.723000059428159e-05}, {"id": 451, "seek": 265484, "start": 2662.84, "end": 2672.84, "text": " So the question is that when you say correlation, are you talking about correlation between columns or between rows or what?", "tokens": [407, 264, 1168, 307, 300, 562, 291, 584, 20009, 11, 366, 291, 1417, 466, 20009, 1296, 13766, 420, 1296, 13241, 420, 437, 30], "temperature": 0.0, "avg_logprob": -0.22411101864230248, "compression_ratio": 1.4745762711864407, "no_speech_prob": 1.723000059428159e-05}, {"id": 452, "seek": 265484, "start": 2672.84, "end": 2675.84, "text": " So this is actually element wise.", "tokens": [407, 341, 307, 767, 4478, 10829, 13], "temperature": 0.0, "avg_logprob": -0.22411101864230248, "compression_ratio": 1.4745762711864407, "no_speech_prob": 1.723000059428159e-05}, {"id": 453, "seek": 267584, "start": 2675.84, "end": 2684.84, "text": " So you correlate one element.", "tokens": [407, 291, 48742, 472, 4478, 13], "temperature": 0.0, "avg_logprob": -0.1573297341664632, "compression_ratio": 1.6029411764705883, "no_speech_prob": 4.194615758024156e-05}, {"id": 454, "seek": 267584, "start": 2684.84, "end": 2691.84, "text": " Oh, yes. Yeah. So this is this is different from a correlation matrix that you hear about of in statistics.", "tokens": [876, 11, 2086, 13, 865, 13, 407, 341, 307, 341, 307, 819, 490, 257, 20009, 8141, 300, 291, 1568, 466, 295, 294, 12523, 13], "temperature": 0.0, "avg_logprob": -0.1573297341664632, "compression_ratio": 1.6029411764705883, "no_speech_prob": 4.194615758024156e-05}, {"id": 455, "seek": 267584, "start": 2691.84, "end": 2695.84, "text": " Yeah. So kind of overuse of the word correlation.", "tokens": [865, 13, 407, 733, 295, 670, 438, 295, 264, 1349, 20009, 13], "temperature": 0.0, "avg_logprob": -0.1573297341664632, "compression_ratio": 1.6029411764705883, "no_speech_prob": 4.194615758024156e-05}, {"id": 456, "seek": 267584, "start": 2695.84, "end": 2697.84, "text": " Yeah, this is a different use.", "tokens": [865, 11, 341, 307, 257, 819, 764, 13], "temperature": 0.0, "avg_logprob": -0.1573297341664632, "compression_ratio": 1.6029411764705883, "no_speech_prob": 4.194615758024156e-05}, {"id": 457, "seek": 269784, "start": 2697.84, "end": 2705.84, "text": " Deep learning when they say convolution, they normally do this.", "tokens": [14895, 2539, 562, 436, 584, 45216, 11, 436, 5646, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.1801251729329427, "compression_ratio": 1.4, "no_speech_prob": 3.942937473766506e-05}, {"id": 458, "seek": 269784, "start": 2705.84, "end": 2706.84, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.1801251729329427, "compression_ratio": 1.4, "no_speech_prob": 3.942937473766506e-05}, {"id": 459, "seek": 269784, "start": 2706.84, "end": 2717.84, "text": " But yeah, but think about that kind of a separate bucket from the statistics idea of correlation between between different variables.", "tokens": [583, 1338, 11, 457, 519, 466, 300, 733, 295, 257, 4994, 13058, 490, 264, 12523, 1558, 295, 20009, 1296, 1296, 819, 9102, 13], "temperature": 0.0, "avg_logprob": -0.1801251729329427, "compression_ratio": 1.4, "no_speech_prob": 3.942937473766506e-05}, {"id": 460, "seek": 271784, "start": 2717.84, "end": 2729.84, "text": " Yes, that was really kind of the key idea of how a matrix can be used for edge detection here. We'll see if we rotate. So remember, top was that three by three matrix.", "tokens": [1079, 11, 300, 390, 534, 733, 295, 264, 2141, 1558, 295, 577, 257, 8141, 393, 312, 1143, 337, 4691, 17784, 510, 13, 492, 603, 536, 498, 321, 13121, 13, 407, 1604, 11, 1192, 390, 300, 1045, 538, 1045, 8141, 13], "temperature": 0.0, "avg_logprob": -0.1102223044947574, "compression_ratio": 1.5422222222222222, "no_speech_prob": 3.966863005189225e-06}, {"id": 461, "seek": 271784, "start": 2729.84, "end": 2736.84, "text": " We can rotate it by 90 degrees.", "tokens": [492, 393, 13121, 309, 538, 4289, 5310, 13], "temperature": 0.0, "avg_logprob": -0.1102223044947574, "compression_ratio": 1.5422222222222222, "no_speech_prob": 3.966863005189225e-06}, {"id": 462, "seek": 271784, "start": 2736.84, "end": 2740.84, "text": " Oh, OK. So now it's identical because we've rotated it.", "tokens": [876, 11, 2264, 13, 407, 586, 309, 311, 14800, 570, 321, 600, 42146, 309, 13], "temperature": 0.0, "avg_logprob": -0.1102223044947574, "compression_ratio": 1.5422222222222222, "no_speech_prob": 3.966863005189225e-06}, {"id": 463, "seek": 271784, "start": 2740.84, "end": 2742.84, "text": " So it still does the same thing.", "tokens": [407, 309, 920, 775, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.1102223044947574, "compression_ratio": 1.5422222222222222, "no_speech_prob": 3.966863005189225e-06}, {"id": 464, "seek": 271784, "start": 2742.84, "end": 2745.84, "text": " I would I would not worry too much about this distinction.", "tokens": [286, 576, 286, 576, 406, 3292, 886, 709, 466, 341, 16844, 13], "temperature": 0.0, "avg_logprob": -0.1102223044947574, "compression_ratio": 1.5422222222222222, "no_speech_prob": 3.966863005189225e-06}, {"id": 465, "seek": 274584, "start": 2745.84, "end": 2753.84, "text": " The key thing here is just the idea of you can pick up edges by sliding a filter.", "tokens": [440, 2141, 551, 510, 307, 445, 264, 1558, 295, 291, 393, 1888, 493, 8819, 538, 21169, 257, 6608, 13], "temperature": 0.0, "avg_logprob": -0.07854042631207091, "compression_ratio": 1.467065868263473, "no_speech_prob": 3.785177341342205e-06}, {"id": 466, "seek": 274584, "start": 2753.84, "end": 2755.84, "text": " And then this is kind of nice.", "tokens": [400, 550, 341, 307, 733, 295, 1481, 13], "temperature": 0.0, "avg_logprob": -0.07854042631207091, "compression_ratio": 1.467065868263473, "no_speech_prob": 3.785177341342205e-06}, {"id": 467, "seek": 274584, "start": 2755.84, "end": 2759.84, "text": " We rotate number of times kind of to get these different ones.", "tokens": [492, 13121, 1230, 295, 1413, 733, 295, 281, 483, 613, 819, 2306, 13], "temperature": 0.0, "avg_logprob": -0.07854042631207091, "compression_ratio": 1.467065868263473, "no_speech_prob": 3.785177341342205e-06}, {"id": 468, "seek": 274584, "start": 2759.84, "end": 2765.84, "text": " And this will give us edge detection for bottom, top, left and right.", "tokens": [400, 341, 486, 976, 505, 4691, 17784, 337, 2767, 11, 1192, 11, 1411, 293, 558, 13], "temperature": 0.0, "avg_logprob": -0.07854042631207091, "compression_ratio": 1.467065868263473, "no_speech_prob": 3.785177341342205e-06}, {"id": 469, "seek": 276584, "start": 2765.84, "end": 2777.84, "text": " You can also do diagonals. And so if we apply that kind of all these different filters to the picture of the zero here, you see we've picked off the top.", "tokens": [509, 393, 611, 360, 17405, 1124, 13, 400, 370, 498, 321, 3079, 300, 733, 295, 439, 613, 819, 15995, 281, 264, 3036, 295, 264, 4018, 510, 11, 291, 536, 321, 600, 6183, 766, 264, 1192, 13], "temperature": 0.0, "avg_logprob": -0.08144302227917839, "compression_ratio": 1.583815028901734, "no_speech_prob": 6.143915015854873e-06}, {"id": 470, "seek": 276584, "start": 2777.84, "end": 2787.84, "text": " This one's picked off the left hand side, since that's where the white marks are picking off the bottom right hand side.", "tokens": [639, 472, 311, 6183, 766, 264, 1411, 1011, 1252, 11, 1670, 300, 311, 689, 264, 2418, 10640, 366, 8867, 766, 264, 2767, 558, 1011, 1252, 13], "temperature": 0.0, "avg_logprob": -0.08144302227917839, "compression_ratio": 1.583815028901734, "no_speech_prob": 6.143915015854873e-06}, {"id": 471, "seek": 278784, "start": 2787.84, "end": 2795.84, "text": " This is picking off kind of the diagonals towards the bottom right corner.", "tokens": [639, 307, 8867, 766, 733, 295, 264, 17405, 1124, 3030, 264, 2767, 558, 4538, 13], "temperature": 0.0, "avg_logprob": -0.13551473028865862, "compression_ratio": 1.6844919786096257, "no_speech_prob": 4.246966511800565e-07}, {"id": 472, "seek": 278784, "start": 2795.84, "end": 2798.84, "text": " Why here is kind of on the diagonals.", "tokens": [1545, 510, 307, 733, 295, 322, 264, 17405, 1124, 13], "temperature": 0.0, "avg_logprob": -0.13551473028865862, "compression_ratio": 1.6844919786096257, "no_speech_prob": 4.246966511800565e-07}, {"id": 473, "seek": 278784, "start": 2798.84, "end": 2804.84, "text": " I mean, you can always think of it as like a light shining from the top right corner in this line here from the top left.", "tokens": [286, 914, 11, 291, 393, 1009, 519, 295, 309, 382, 411, 257, 1442, 18269, 490, 264, 1192, 558, 4538, 294, 341, 1622, 510, 490, 264, 1192, 1411, 13], "temperature": 0.0, "avg_logprob": -0.13551473028865862, "compression_ratio": 1.6844919786096257, "no_speech_prob": 4.246966511800565e-07}, {"id": 474, "seek": 278784, "start": 2804.84, "end": 2815.84, "text": " And then I guess this one is bottom left, although the edges are not as defined.", "tokens": [400, 550, 286, 2041, 341, 472, 307, 2767, 1411, 11, 4878, 264, 8819, 366, 406, 382, 7642, 13], "temperature": 0.0, "avg_logprob": -0.13551473028865862, "compression_ratio": 1.6844919786096257, "no_speech_prob": 4.246966511800565e-07}, {"id": 475, "seek": 281584, "start": 2815.84, "end": 2830.84, "text": " OK, any questions on this?", "tokens": [2264, 11, 604, 1651, 322, 341, 30], "temperature": 0.0, "avg_logprob": -0.13536892154000021, "compression_ratio": 1.2325581395348837, "no_speech_prob": 8.939029612520244e-06}, {"id": 476, "seek": 281584, "start": 2830.84, "end": 2834.84, "text": " So that's it for putting matrices together.", "tokens": [407, 300, 311, 309, 337, 3372, 32284, 1214, 13], "temperature": 0.0, "avg_logprob": -0.13536892154000021, "compression_ratio": 1.2325581395348837, "no_speech_prob": 8.939029612520244e-06}, {"id": 477, "seek": 281584, "start": 2834.84, "end": 2839.84, "text": " I mean, we'll be using matrix products every day, but kind of in the intro applications.", "tokens": [286, 914, 11, 321, 603, 312, 1228, 8141, 3383, 633, 786, 11, 457, 733, 295, 294, 264, 12897, 5821, 13], "temperature": 0.0, "avg_logprob": -0.13536892154000021, "compression_ratio": 1.2325581395348837, "no_speech_prob": 8.939029612520244e-06}, {"id": 478, "seek": 283984, "start": 2839.84, "end": 2848.84, "text": " And now I'm just going to very briefly say some of the matrix decompositions we'll be seeing. We'll be covering all of these in a lot of depth in the future lessons.", "tokens": [400, 586, 286, 478, 445, 516, 281, 588, 10515, 584, 512, 295, 264, 8141, 22867, 329, 2451, 321, 603, 312, 2577, 13, 492, 603, 312, 10322, 439, 295, 613, 294, 257, 688, 295, 7161, 294, 264, 2027, 8820, 13], "temperature": 0.0, "avg_logprob": -0.07661383006037498, "compression_ratio": 1.5368852459016393, "no_speech_prob": 2.2600813736062264e-06}, {"id": 479, "seek": 283984, "start": 2848.84, "end": 2854.84, "text": " So one is topic modeling, and we'll see it with NMF and SVD.", "tokens": [407, 472, 307, 4829, 15983, 11, 293, 321, 603, 536, 309, 365, 426, 44, 37, 293, 31910, 35, 13], "temperature": 0.0, "avg_logprob": -0.07661383006037498, "compression_ratio": 1.5368852459016393, "no_speech_prob": 2.2600813736062264e-06}, {"id": 480, "seek": 283984, "start": 2854.84, "end": 2859.84, "text": " And so a group of documents can be represented by a term document matrix.", "tokens": [400, 370, 257, 1594, 295, 8512, 393, 312, 10379, 538, 257, 1433, 4166, 8141, 13], "temperature": 0.0, "avg_logprob": -0.07661383006037498, "compression_ratio": 1.5368852459016393, "no_speech_prob": 2.2600813736062264e-06}, {"id": 481, "seek": 283984, "start": 2859.84, "end": 2864.84, "text": " Here these are works of Shakespeare. Along the top is the particular play.", "tokens": [1692, 613, 366, 1985, 295, 22825, 13, 17457, 264, 1192, 307, 264, 1729, 862, 13], "temperature": 0.0, "avg_logprob": -0.07661383006037498, "compression_ratio": 1.5368852459016393, "no_speech_prob": 2.2600813736062264e-06}, {"id": 482, "seek": 286484, "start": 2864.84, "end": 2872.84, "text": " On the left is different words that appear in those plays. And so you can see Anthony and Cleopatra.", "tokens": [1282, 264, 1411, 307, 819, 2283, 300, 4204, 294, 729, 5749, 13, 400, 370, 291, 393, 536, 15853, 293, 8834, 404, 33593, 13], "temperature": 0.0, "avg_logprob": -0.08822110153379895, "compression_ratio": 1.6698564593301435, "no_speech_prob": 7.295477644220227e-06}, {"id": 483, "seek": 286484, "start": 2872.84, "end": 2879.84, "text": " The word Anthony appears 157 times in Julius Caesar. The word Anthony appears 73 times.", "tokens": [440, 1349, 15853, 7038, 2119, 22, 1413, 294, 47666, 26678, 13, 440, 1349, 15853, 7038, 28387, 1413, 13], "temperature": 0.0, "avg_logprob": -0.08822110153379895, "compression_ratio": 1.6698564593301435, "no_speech_prob": 7.295477644220227e-06}, {"id": 484, "seek": 286484, "start": 2879.84, "end": 2884.84, "text": " And this is a way that you can represent a group of documents as a matrix.", "tokens": [400, 341, 307, 257, 636, 300, 291, 393, 2906, 257, 1594, 295, 8512, 382, 257, 8141, 13], "temperature": 0.0, "avg_logprob": -0.08822110153379895, "compression_ratio": 1.6698564593301435, "no_speech_prob": 7.295477644220227e-06}, {"id": 485, "seek": 286484, "start": 2884.84, "end": 2890.84, "text": " And this is notice that nothing about syntax or order or structure is being included.", "tokens": [400, 341, 307, 3449, 300, 1825, 466, 28431, 420, 1668, 420, 3877, 307, 885, 5556, 13], "temperature": 0.0, "avg_logprob": -0.08822110153379895, "compression_ratio": 1.6698564593301435, "no_speech_prob": 7.295477644220227e-06}, {"id": 486, "seek": 289084, "start": 2890.84, "end": 2897.84, "text": " This is treating them as a bag of words, basically, but it can let you figure out different topics.", "tokens": [639, 307, 15083, 552, 382, 257, 3411, 295, 2283, 11, 1936, 11, 457, 309, 393, 718, 291, 2573, 484, 819, 8378, 13], "temperature": 0.0, "avg_logprob": -0.08072078227996826, "compression_ratio": 1.4972067039106145, "no_speech_prob": 1.5293484239009558e-06}, {"id": 487, "seek": 289084, "start": 2897.84, "end": 2902.84, "text": " And in matrices, what that looks like. So this is for NMF.", "tokens": [400, 294, 32284, 11, 437, 300, 1542, 411, 13, 407, 341, 307, 337, 426, 44, 37, 13], "temperature": 0.0, "avg_logprob": -0.08072078227996826, "compression_ratio": 1.4972067039106145, "no_speech_prob": 1.5293484239009558e-06}, {"id": 488, "seek": 289084, "start": 2902.84, "end": 2912.84, "text": " So the words are the rows, the documents are the columns, and you can decompose that into a matrix of topics.", "tokens": [407, 264, 2283, 366, 264, 13241, 11, 264, 8512, 366, 264, 13766, 11, 293, 291, 393, 22867, 541, 300, 666, 257, 8141, 295, 8378, 13], "temperature": 0.0, "avg_logprob": -0.08072078227996826, "compression_ratio": 1.4972067039106145, "no_speech_prob": 1.5293484239009558e-06}, {"id": 489, "seek": 291284, "start": 2912.84, "end": 2921.84, "text": " So that would be topics by words and then topics, importance indicators, kind of by topics.", "tokens": [407, 300, 576, 312, 8378, 538, 2283, 293, 550, 8378, 11, 7379, 22176, 11, 733, 295, 538, 8378, 13], "temperature": 0.0, "avg_logprob": -0.09315864018031529, "compression_ratio": 1.5901639344262295, "no_speech_prob": 1.5779223758727312e-06}, {"id": 490, "seek": 291284, "start": 2921.84, "end": 2930.84, "text": " Or I mean, really, that's the kind of documents by how important each topic is for that document.", "tokens": [1610, 286, 914, 11, 534, 11, 300, 311, 264, 733, 295, 8512, 538, 577, 1021, 1184, 4829, 307, 337, 300, 4166, 13], "temperature": 0.0, "avg_logprob": -0.09315864018031529, "compression_ratio": 1.5901639344262295, "no_speech_prob": 1.5779223758727312e-06}, {"id": 491, "seek": 291284, "start": 2930.84, "end": 2935.84, "text": " And I think it's always helpful to kind of write out what your dimensions are when thinking about it.", "tokens": [400, 286, 519, 309, 311, 1009, 4961, 281, 733, 295, 2464, 484, 437, 428, 12819, 366, 562, 1953, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.09315864018031529, "compression_ratio": 1.5901639344262295, "no_speech_prob": 1.5779223758727312e-06}, {"id": 492, "seek": 293584, "start": 2935.84, "end": 2943.84, "text": " But here, topics is kind of going to be your short dimension that you're finding.", "tokens": [583, 510, 11, 8378, 307, 733, 295, 516, 281, 312, 428, 2099, 10139, 300, 291, 434, 5006, 13], "temperature": 0.0, "avg_logprob": -0.09060468535492386, "compression_ratio": 1.463855421686747, "no_speech_prob": 3.119679604424164e-05}, {"id": 493, "seek": 293584, "start": 2943.84, "end": 2951.84, "text": " We'll see background removal, which we'll use robust PCA, which uses SVD and SVD uses QR.", "tokens": [492, 603, 536, 3678, 17933, 11, 597, 321, 603, 764, 13956, 6465, 32, 11, 597, 4960, 31910, 35, 293, 31910, 35, 4960, 32784, 13], "temperature": 0.0, "avg_logprob": -0.09060468535492386, "compression_ratio": 1.463855421686747, "no_speech_prob": 3.119679604424164e-05}, {"id": 494, "seek": 293584, "start": 2951.84, "end": 2955.84, "text": " So there's kind of some nesting going on, and that's to kind of remove.", "tokens": [407, 456, 311, 733, 295, 512, 297, 8714, 516, 322, 11, 293, 300, 311, 281, 733, 295, 4159, 13], "temperature": 0.0, "avg_logprob": -0.09060468535492386, "compression_ratio": 1.463855421686747, "no_speech_prob": 3.119679604424164e-05}, {"id": 495, "seek": 295584, "start": 2955.84, "end": 2966.84, "text": " So we have this surveillance video, and we can kind of pick out what's the background and what are the people, which could be useful.", "tokens": [407, 321, 362, 341, 18475, 960, 11, 293, 321, 393, 733, 295, 1888, 484, 437, 311, 264, 3678, 293, 437, 366, 264, 561, 11, 597, 727, 312, 4420, 13], "temperature": 0.0, "avg_logprob": -0.0674303948879242, "compression_ratio": 1.5510204081632653, "no_speech_prob": 5.255014912108891e-06}, {"id": 496, "seek": 295584, "start": 2966.84, "end": 2972.84, "text": " The PageRank algorithm is all based off of eigendecompositions and finding an eigenvector.", "tokens": [440, 21217, 49, 657, 9284, 307, 439, 2361, 766, 295, 10446, 1479, 21541, 329, 2451, 293, 5006, 364, 10446, 303, 1672, 13], "temperature": 0.0, "avg_logprob": -0.0674303948879242, "compression_ratio": 1.5510204081632653, "no_speech_prob": 5.255014912108891e-06}, {"id": 497, "seek": 295584, "start": 2972.84, "end": 2978.84, "text": " So we'll look at that, and we'll look at that on a data set of Wikipedia pages.", "tokens": [407, 321, 603, 574, 412, 300, 11, 293, 321, 603, 574, 412, 300, 322, 257, 1412, 992, 295, 28999, 7183, 13], "temperature": 0.0, "avg_logprob": -0.0674303948879242, "compression_ratio": 1.5510204081632653, "no_speech_prob": 5.255014912108891e-06}, {"id": 498, "seek": 297884, "start": 2978.84, "end": 2987.84, "text": " And then that page I linked to before of the matrix factorization jungle has a number of other decompositions.", "tokens": [400, 550, 300, 3028, 286, 9408, 281, 949, 295, 264, 8141, 5952, 2144, 18228, 575, 257, 1230, 295, 661, 22867, 329, 2451, 13], "temperature": 0.0, "avg_logprob": -0.10140310780385907, "compression_ratio": 1.5044247787610618, "no_speech_prob": 2.9021900900261244e-06}, {"id": 499, "seek": 297884, "start": 2987.84, "end": 2990.84, "text": " Well, and actually, this is like perfect timing.", "tokens": [1042, 11, 293, 767, 11, 341, 307, 411, 2176, 10822, 13], "temperature": 0.0, "avg_logprob": -0.10140310780385907, "compression_ratio": 1.5044247787610618, "no_speech_prob": 2.9021900900261244e-06}, {"id": 500, "seek": 297884, "start": 2990.84, "end": 2998.84, "text": " So it's noon. I was thinking we could take maybe a seven or eight minute break and then come back.", "tokens": [407, 309, 311, 24040, 13, 286, 390, 1953, 321, 727, 747, 1310, 257, 3407, 420, 3180, 3456, 1821, 293, 550, 808, 646, 13], "temperature": 0.0, "avg_logprob": -0.10140310780385907, "compression_ratio": 1.5044247787610618, "no_speech_prob": 2.9021900900261244e-06}, {"id": 501, "seek": 297884, "start": 2998.84, "end": 3004.84, "text": " Yeah, get some water, go to the bathroom, and then we'll dive into kind of, yeah,", "tokens": [865, 11, 483, 512, 1281, 11, 352, 281, 264, 8687, 11, 293, 550, 321, 603, 9192, 666, 733, 295, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.10140310780385907, "compression_ratio": 1.5044247787610618, "no_speech_prob": 2.9021900900261244e-06}, {"id": 502, "seek": 300484, "start": 3004.84, "end": 3010.84, "text": " these four concepts that I think are pretty fundamental to numerical linear algebra.", "tokens": [613, 1451, 10392, 300, 286, 519, 366, 1238, 8088, 281, 29054, 8213, 21989, 13], "temperature": 0.0, "avg_logprob": -0.13409381193273207, "compression_ratio": 1.4340425531914893, "no_speech_prob": 1.4509076208923943e-05}, {"id": 503, "seek": 300484, "start": 3010.84, "end": 3013.84, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.13409381193273207, "compression_ratio": 1.4340425531914893, "no_speech_prob": 1.4509076208923943e-05}, {"id": 504, "seek": 300484, "start": 3013.84, "end": 3016.84, "text": " All right. So it's 1207. We're going to start back.", "tokens": [1057, 558, 13, 407, 309, 311, 10411, 22, 13, 492, 434, 516, 281, 722, 646, 13], "temperature": 0.0, "avg_logprob": -0.13409381193273207, "compression_ratio": 1.4340425531914893, "no_speech_prob": 1.4509076208923943e-05}, {"id": 505, "seek": 300484, "start": 3016.84, "end": 3024.84, "text": " And actually, Jeremy said that everyone is used or that the MSAN recommends Python 2.", "tokens": [400, 767, 11, 17809, 848, 300, 1518, 307, 1143, 420, 300, 264, 7395, 1770, 34556, 15329, 568, 13], "temperature": 0.0, "avg_logprob": -0.13409381193273207, "compression_ratio": 1.4340425531914893, "no_speech_prob": 1.4509076208923943e-05}, {"id": 506, "seek": 300484, "start": 3024.84, "end": 3032.84, "text": " So he's just going to briefly talk about having both 2 and 3 installed so that you can switch between them.", "tokens": [407, 415, 311, 445, 516, 281, 10515, 751, 466, 1419, 1293, 568, 293, 805, 8899, 370, 300, 291, 393, 3679, 1296, 552, 13], "temperature": 0.0, "avg_logprob": -0.13409381193273207, "compression_ratio": 1.4340425531914893, "no_speech_prob": 1.4509076208923943e-05}, {"id": 507, "seek": 303284, "start": 3032.84, "end": 3038.84, "text": " So for those who are interested in trying Python 3, there's only two things you need to really know.", "tokens": [407, 337, 729, 567, 366, 3102, 294, 1382, 15329, 805, 11, 456, 311, 787, 732, 721, 291, 643, 281, 534, 458, 13], "temperature": 0.0, "avg_logprob": -0.03851020019666283, "compression_ratio": 1.7265917602996255, "no_speech_prob": 6.0136251704534516e-05}, {"id": 508, "seek": 303284, "start": 3038.84, "end": 3042.84, "text": " The first is that print statements now have parentheses around them.", "tokens": [440, 700, 307, 300, 4482, 12363, 586, 362, 34153, 926, 552, 13], "temperature": 0.0, "avg_logprob": -0.03851020019666283, "compression_ratio": 1.7265917602996255, "no_speech_prob": 6.0136251704534516e-05}, {"id": 509, "seek": 303284, "start": 3042.84, "end": 3047.84, "text": " The second is that when you divide an integer by an integer, you get a float rather than integer,", "tokens": [440, 1150, 307, 300, 562, 291, 9845, 364, 24922, 538, 364, 24922, 11, 291, 483, 257, 15706, 2831, 813, 24922, 11], "temperature": 0.0, "avg_logprob": -0.03851020019666283, "compression_ratio": 1.7265917602996255, "no_speech_prob": 6.0136251704534516e-05}, {"id": 510, "seek": 303284, "start": 3047.84, "end": 3049.84, "text": " which makes a lot more sense.", "tokens": [597, 1669, 257, 688, 544, 2020, 13], "temperature": 0.0, "avg_logprob": -0.03851020019666283, "compression_ratio": 1.7265917602996255, "no_speech_prob": 6.0136251704534516e-05}, {"id": 511, "seek": 303284, "start": 3049.84, "end": 3054.84, "text": " But if you're used to the Python 2 behavior, you'll find that surprising.", "tokens": [583, 498, 291, 434, 1143, 281, 264, 15329, 568, 5223, 11, 291, 603, 915, 300, 8830, 13], "temperature": 0.0, "avg_logprob": -0.03851020019666283, "compression_ratio": 1.7265917602996255, "no_speech_prob": 6.0136251704534516e-05}, {"id": 512, "seek": 303284, "start": 3054.84, "end": 3058.84, "text": " There's a really fantastic thing called Anaconda, which some of you may have come across.", "tokens": [821, 311, 257, 534, 5456, 551, 1219, 1107, 326, 12233, 11, 597, 512, 295, 291, 815, 362, 808, 2108, 13], "temperature": 0.0, "avg_logprob": -0.03851020019666283, "compression_ratio": 1.7265917602996255, "no_speech_prob": 6.0136251704534516e-05}, {"id": 513, "seek": 305884, "start": 3058.84, "end": 3064.84, "text": " It's a Python distribution that when you install it, it'll offer by default to install it in your home directory", "tokens": [467, 311, 257, 15329, 7316, 300, 562, 291, 3625, 309, 11, 309, 603, 2626, 538, 7576, 281, 3625, 309, 294, 428, 1280, 21120], "temperature": 0.0, "avg_logprob": -0.07222634712151721, "compression_ratio": 1.7014925373134329, "no_speech_prob": 5.80491700929997e-07}, {"id": 514, "seek": 305884, "start": 3064.84, "end": 3067.84, "text": " rather than replacing your system Python.", "tokens": [2831, 813, 19139, 428, 1185, 15329, 13], "temperature": 0.0, "avg_logprob": -0.07222634712151721, "compression_ratio": 1.7014925373134329, "no_speech_prob": 5.80491700929997e-07}, {"id": 515, "seek": 305884, "start": 3067.84, "end": 3075.84, "text": " So you can install Anaconda 3, and that'll give you the latest Python 3.6 that supports all the cool linear algebra stuff virtual showing.", "tokens": [407, 291, 393, 3625, 1107, 326, 12233, 805, 11, 293, 300, 603, 976, 291, 264, 6792, 15329, 805, 13, 21, 300, 9346, 439, 264, 1627, 8213, 21989, 1507, 6374, 4099, 13], "temperature": 0.0, "avg_logprob": -0.07222634712151721, "compression_ratio": 1.7014925373134329, "no_speech_prob": 5.80491700929997e-07}, {"id": 516, "seek": 305884, "start": 3075.84, "end": 3079.84, "text": " And it won't replace your current Python in any way.", "tokens": [400, 309, 1582, 380, 7406, 428, 2190, 15329, 294, 604, 636, 13], "temperature": 0.0, "avg_logprob": -0.07222634712151721, "compression_ratio": 1.7014925373134329, "no_speech_prob": 5.80491700929997e-07}, {"id": 517, "seek": 305884, "start": 3079.84, "end": 3081.84, "text": " So then you've got a choice.", "tokens": [407, 550, 291, 600, 658, 257, 3922, 13], "temperature": 0.0, "avg_logprob": -0.07222634712151721, "compression_ratio": 1.7014925373134329, "no_speech_prob": 5.80491700929997e-07}, {"id": 518, "seek": 305884, "start": 3081.84, "end": 3087.84, "text": " With Anaconda, you can actually run multiple versions of Python inside Anaconda.", "tokens": [2022, 1107, 326, 12233, 11, 291, 393, 767, 1190, 3866, 9606, 295, 15329, 1854, 1107, 326, 12233, 13], "temperature": 0.0, "avg_logprob": -0.07222634712151721, "compression_ratio": 1.7014925373134329, "no_speech_prob": 5.80491700929997e-07}, {"id": 519, "seek": 308784, "start": 3087.84, "end": 3091.84, "text": " So we can help you do that on Slack if you guys want to do that.", "tokens": [407, 321, 393, 854, 291, 360, 300, 322, 37211, 498, 291, 1074, 528, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.056203530964098476, "compression_ratio": 1.5695652173913044, "no_speech_prob": 1.0129752809007186e-05}, {"id": 520, "seek": 308784, "start": 3091.84, "end": 3099.84, "text": " Or you can just switch between the two by changing your path to add or remove your home directory Python from the path.", "tokens": [1610, 291, 393, 445, 3679, 1296, 264, 732, 538, 4473, 428, 3100, 281, 909, 420, 4159, 428, 1280, 21120, 15329, 490, 264, 3100, 13], "temperature": 0.0, "avg_logprob": -0.056203530964098476, "compression_ratio": 1.5695652173913044, "no_speech_prob": 1.0129752809007186e-05}, {"id": 521, "seek": 308784, "start": 3099.84, "end": 3102.84, "text": " So that's definitely an option there.", "tokens": [407, 300, 311, 2138, 364, 3614, 456, 13], "temperature": 0.0, "avg_logprob": -0.056203530964098476, "compression_ratio": 1.5695652173913044, "no_speech_prob": 1.0129752809007186e-05}, {"id": 522, "seek": 308784, "start": 3102.84, "end": 3106.84, "text": " I don't suggest you replace your system Python with Python 3.", "tokens": [286, 500, 380, 3402, 291, 7406, 428, 1185, 15329, 365, 15329, 805, 13], "temperature": 0.0, "avg_logprob": -0.056203530964098476, "compression_ratio": 1.5695652173913044, "no_speech_prob": 1.0129752809007186e-05}, {"id": 523, "seek": 308784, "start": 3106.84, "end": 3108.84, "text": " That's going to cause you a lot of confusion.", "tokens": [663, 311, 516, 281, 3082, 291, 257, 688, 295, 15075, 13], "temperature": 0.0, "avg_logprob": -0.056203530964098476, "compression_ratio": 1.5695652173913044, "no_speech_prob": 1.0129752809007186e-05}, {"id": 524, "seek": 308784, "start": 3108.84, "end": 3111.84, "text": " But instead, install Anaconda.", "tokens": [583, 2602, 11, 3625, 1107, 326, 12233, 13], "temperature": 0.0, "avg_logprob": -0.056203530964098476, "compression_ratio": 1.5695652173913044, "no_speech_prob": 1.0129752809007186e-05}, {"id": 525, "seek": 311184, "start": 3111.84, "end": 3120.84, "text": " And another nice thing about Anaconda is that all of the, well, for example, PyTorch, which we'll be using later for using the GPU,", "tokens": [400, 1071, 1481, 551, 466, 1107, 326, 12233, 307, 300, 439, 295, 264, 11, 731, 11, 337, 1365, 11, 9953, 51, 284, 339, 11, 597, 321, 603, 312, 1228, 1780, 337, 1228, 264, 18407, 11], "temperature": 0.0, "avg_logprob": -0.0746080783697275, "compression_ratio": 1.525, "no_speech_prob": 6.338903403957374e-06}, {"id": 526, "seek": 311184, "start": 3120.84, "end": 3123.84, "text": " by far the easiest way to install it is with Anaconda.", "tokens": [538, 1400, 264, 12889, 636, 281, 3625, 309, 307, 365, 1107, 326, 12233, 13], "temperature": 0.0, "avg_logprob": -0.0746080783697275, "compression_ratio": 1.525, "no_speech_prob": 6.338903403957374e-06}, {"id": 527, "seek": 311184, "start": 3123.84, "end": 3127.84, "text": " In fact, that's the officially sanctioned method.", "tokens": [682, 1186, 11, 300, 311, 264, 12053, 39830, 292, 3170, 13], "temperature": 0.0, "avg_logprob": -0.0746080783697275, "compression_ratio": 1.525, "no_speech_prob": 6.338903403957374e-06}, {"id": 528, "seek": 311184, "start": 3127.84, "end": 3130.84, "text": " So there's a number of reasons maybe to try out Anaconda.", "tokens": [407, 456, 311, 257, 1230, 295, 4112, 1310, 281, 853, 484, 1107, 326, 12233, 13], "temperature": 0.0, "avg_logprob": -0.0746080783697275, "compression_ratio": 1.525, "no_speech_prob": 6.338903403957374e-06}, {"id": 529, "seek": 311184, "start": 3130.84, "end": 3136.84, "text": " But definitely don't replace your system Python.", "tokens": [583, 2138, 500, 380, 7406, 428, 1185, 15329, 13], "temperature": 0.0, "avg_logprob": -0.0746080783697275, "compression_ratio": 1.525, "no_speech_prob": 6.338903403957374e-06}, {"id": 530, "seek": 311184, "start": 3136.84, "end": 3138.84, "text": " Great. Thanks, Jeremy.", "tokens": [3769, 13, 2561, 11, 17809, 13], "temperature": 0.0, "avg_logprob": -0.0746080783697275, "compression_ratio": 1.525, "no_speech_prob": 6.338903403957374e-06}, {"id": 531, "seek": 313884, "start": 3138.84, "end": 3143.84, "text": " Yeah. So feel free to ask on Slack or ask either of us if you have questions about that.", "tokens": [865, 13, 407, 841, 1737, 281, 1029, 322, 37211, 420, 1029, 2139, 295, 505, 498, 291, 362, 1651, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.040383954546344816, "compression_ratio": 1.7027972027972027, "no_speech_prob": 3.3725707908160985e-05}, {"id": 532, "seek": 313884, "start": 3143.84, "end": 3146.84, "text": " And then also I want to say Python 3 is not required for this course.", "tokens": [400, 550, 611, 286, 528, 281, 584, 15329, 805, 307, 406, 4739, 337, 341, 1164, 13], "temperature": 0.0, "avg_logprob": -0.040383954546344816, "compression_ratio": 1.7027972027972027, "no_speech_prob": 3.3725707908160985e-05}, {"id": 533, "seek": 313884, "start": 3146.84, "end": 3150.84, "text": " So if you want to keep using Python 2, that's fine as well.", "tokens": [407, 498, 291, 528, 281, 1066, 1228, 15329, 568, 11, 300, 311, 2489, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.040383954546344816, "compression_ratio": 1.7027972027972027, "no_speech_prob": 3.3725707908160985e-05}, {"id": 534, "seek": 313884, "start": 3150.84, "end": 3152.84, "text": " But it is a neat option.", "tokens": [583, 309, 307, 257, 10654, 3614, 13], "temperature": 0.0, "avg_logprob": -0.040383954546344816, "compression_ratio": 1.7027972027972027, "no_speech_prob": 3.3725707908160985e-05}, {"id": 535, "seek": 313884, "start": 3152.84, "end": 3156.84, "text": " And Anaconda and Jupyter both make it pretty easy.", "tokens": [400, 1107, 326, 12233, 293, 22125, 88, 391, 1293, 652, 309, 1238, 1858, 13], "temperature": 0.0, "avg_logprob": -0.040383954546344816, "compression_ratio": 1.7027972027972027, "no_speech_prob": 3.3725707908160985e-05}, {"id": 536, "seek": 313884, "start": 3156.84, "end": 3161.84, "text": " Something that's nice about Jupyter is when you start a new notebook, it'll ask you like which kernel you want to use.", "tokens": [6595, 300, 311, 1481, 466, 22125, 88, 391, 307, 562, 291, 722, 257, 777, 21060, 11, 309, 603, 1029, 291, 411, 597, 28256, 291, 528, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.040383954546344816, "compression_ratio": 1.7027972027972027, "no_speech_prob": 3.3725707908160985e-05}, {"id": 537, "seek": 313884, "start": 3161.84, "end": 3167.84, "text": " And so if you have both installed, you can choose whichever one you want.", "tokens": [400, 370, 498, 291, 362, 1293, 8899, 11, 291, 393, 2826, 24123, 472, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.040383954546344816, "compression_ratio": 1.7027972027972027, "no_speech_prob": 3.3725707908160985e-05}, {"id": 538, "seek": 316784, "start": 3167.84, "end": 3172.84, "text": " Rachel's code often won't run as is in Python 2, if you are using Python 2.", "tokens": [14246, 311, 3089, 2049, 1582, 380, 1190, 382, 307, 294, 15329, 568, 11, 498, 291, 366, 1228, 15329, 568, 13], "temperature": 0.0, "avg_logprob": -0.09417092172723067, "compression_ratio": 1.6159420289855073, "no_speech_prob": 1.3003953426959924e-05}, {"id": 539, "seek": 316784, "start": 3172.84, "end": 3176.84, "text": " But we can also show you a couple of lines you can add to the top of every page,", "tokens": [583, 321, 393, 611, 855, 291, 257, 1916, 295, 3876, 291, 393, 909, 281, 264, 1192, 295, 633, 3028, 11], "temperature": 0.0, "avg_logprob": -0.09417092172723067, "compression_ratio": 1.6159420289855073, "no_speech_prob": 1.3003953426959924e-05}, {"id": 540, "seek": 316784, "start": 3176.84, "end": 3180.84, "text": " which makes a Python 3 file largely compatible with Python 2.", "tokens": [597, 1669, 257, 15329, 805, 3991, 11611, 18218, 365, 15329, 568, 13], "temperature": 0.0, "avg_logprob": -0.09417092172723067, "compression_ratio": 1.6159420289855073, "no_speech_prob": 1.3003953426959924e-05}, {"id": 541, "seek": 316784, "start": 3180.84, "end": 3183.84, "text": " So we should probably start adding that to our notebooks.", "tokens": [407, 321, 820, 1391, 722, 5127, 300, 281, 527, 43782, 13], "temperature": 0.0, "avg_logprob": -0.09417092172723067, "compression_ratio": 1.6159420289855073, "no_speech_prob": 1.3003953426959924e-05}, {"id": 542, "seek": 316784, "start": 3183.84, "end": 3188.84, "text": " Yeah. And then also, as Jeremy said, many of the things that don't work are very minor.", "tokens": [865, 13, 400, 550, 611, 11, 382, 17809, 848, 11, 867, 295, 264, 721, 300, 500, 380, 589, 366, 588, 6696, 13], "temperature": 0.0, "avg_logprob": -0.09417092172723067, "compression_ratio": 1.6159420289855073, "no_speech_prob": 1.3003953426959924e-05}, {"id": 543, "seek": 316784, "start": 3188.84, "end": 3196.84, "text": " And it's adding parentheses around your print statements or I guess some casting.", "tokens": [400, 309, 311, 5127, 34153, 926, 428, 4482, 12363, 420, 286, 2041, 512, 17301, 13], "temperature": 0.0, "avg_logprob": -0.09417092172723067, "compression_ratio": 1.6159420289855073, "no_speech_prob": 1.3003953426959924e-05}, {"id": 544, "seek": 319684, "start": 3196.84, "end": 3203.84, "text": " Or dividing integers by integers to get floats.", "tokens": [1610, 26764, 41674, 538, 41674, 281, 483, 37878, 13], "temperature": 0.0, "avg_logprob": -0.14755592346191407, "compression_ratio": 1.5170731707317073, "no_speech_prob": 5.68218138141674e-06}, {"id": 545, "seek": 319684, "start": 3203.84, "end": 3211.84, "text": " OK. So, yeah, in this part, I'm going to talk about kind of four huge areas of concern in numerical linear algebra", "tokens": [2264, 13, 407, 11, 1338, 11, 294, 341, 644, 11, 286, 478, 516, 281, 751, 466, 733, 295, 1451, 2603, 3179, 295, 3136, 294, 29054, 8213, 21989], "temperature": 0.0, "avg_logprob": -0.14755592346191407, "compression_ratio": 1.5170731707317073, "no_speech_prob": 5.68218138141674e-06}, {"id": 546, "seek": 319684, "start": 3211.84, "end": 3217.84, "text": " or when doing matrix computations on a computer in general.", "tokens": [420, 562, 884, 8141, 2807, 763, 322, 257, 3820, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.14755592346191407, "compression_ratio": 1.5170731707317073, "no_speech_prob": 5.68218138141674e-06}, {"id": 547, "seek": 319684, "start": 3217.84, "end": 3221.84, "text": " So the first is, let me go to full screen again.", "tokens": [407, 264, 700, 307, 11, 718, 385, 352, 281, 1577, 2568, 797, 13], "temperature": 0.0, "avg_logprob": -0.14755592346191407, "compression_ratio": 1.5170731707317073, "no_speech_prob": 5.68218138141674e-06}, {"id": 548, "seek": 319684, "start": 3221.84, "end": 3225.84, "text": " The first is floating point arithmetic.", "tokens": [440, 700, 307, 12607, 935, 42973, 13], "temperature": 0.0, "avg_logprob": -0.14755592346191407, "compression_ratio": 1.5170731707317073, "no_speech_prob": 5.68218138141674e-06}, {"id": 549, "seek": 322584, "start": 3225.84, "end": 3231.84, "text": " And so to understand accuracy, we need to look at how computers store numbers.", "tokens": [400, 370, 281, 1223, 14170, 11, 321, 643, 281, 574, 412, 577, 10807, 3531, 3547, 13], "temperature": 0.0, "avg_logprob": -0.10514017593028933, "compression_ratio": 1.6133333333333333, "no_speech_prob": 4.246759885973006e-07}, {"id": 550, "seek": 322584, "start": 3231.84, "end": 3237.84, "text": " Because it's and this is something that really I hadn't thought about until I got to grad school,", "tokens": [1436, 309, 311, 293, 341, 307, 746, 300, 534, 286, 8782, 380, 1194, 466, 1826, 286, 658, 281, 2771, 1395, 11], "temperature": 0.0, "avg_logprob": -0.10514017593028933, "compression_ratio": 1.6133333333333333, "no_speech_prob": 4.246759885973006e-07}, {"id": 551, "seek": 322584, "start": 3237.84, "end": 3243.84, "text": " is when you're doing math, it's continuous and it's infinite.", "tokens": [307, 562, 291, 434, 884, 5221, 11, 309, 311, 10957, 293, 309, 311, 13785, 13], "temperature": 0.0, "avg_logprob": -0.10514017593028933, "compression_ratio": 1.6133333333333333, "no_speech_prob": 4.246759885973006e-07}, {"id": 552, "seek": 322584, "start": 3243.84, "end": 3246.84, "text": " You know, you kind of have this infinite precision as possible.", "tokens": [509, 458, 11, 291, 733, 295, 362, 341, 13785, 18356, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.10514017593028933, "compression_ratio": 1.6133333333333333, "no_speech_prob": 4.246759885973006e-07}, {"id": 553, "seek": 322584, "start": 3246.84, "end": 3251.84, "text": " But computers are inherently finite and inherently discrete.", "tokens": [583, 10807, 366, 27993, 19362, 293, 27993, 27706, 13], "temperature": 0.0, "avg_logprob": -0.10514017593028933, "compression_ratio": 1.6133333333333333, "no_speech_prob": 4.246759885973006e-07}, {"id": 554, "seek": 325184, "start": 3251.84, "end": 3256.84, "text": " So it's really kind of important to think about how computers deal with numbers in math.", "tokens": [407, 309, 311, 534, 733, 295, 1021, 281, 519, 466, 577, 10807, 2028, 365, 3547, 294, 5221, 13], "temperature": 0.0, "avg_logprob": -0.059538251102560814, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.4062440641282592e-05}, {"id": 555, "seek": 325184, "start": 3256.84, "end": 3262.84, "text": " So for an exercise, I want you to look at this method F that I have defined.", "tokens": [407, 337, 364, 5380, 11, 286, 528, 291, 281, 574, 412, 341, 3170, 479, 300, 286, 362, 7642, 13], "temperature": 0.0, "avg_logprob": -0.059538251102560814, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.4062440641282592e-05}, {"id": 556, "seek": 325184, "start": 3262.84, "end": 3269.84, "text": " So F takes a value. If the value is less than or equal to a half, it returns two times that value.", "tokens": [407, 479, 2516, 257, 2158, 13, 759, 264, 2158, 307, 1570, 813, 420, 2681, 281, 257, 1922, 11, 309, 11247, 732, 1413, 300, 2158, 13], "temperature": 0.0, "avg_logprob": -0.059538251102560814, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.4062440641282592e-05}, {"id": 557, "seek": 325184, "start": 3269.84, "end": 3274.84, "text": " If X is greater than a half, it returns two times the value minus one.", "tokens": [759, 1783, 307, 5044, 813, 257, 1922, 11, 309, 11247, 732, 1413, 264, 2158, 3175, 472, 13], "temperature": 0.0, "avg_logprob": -0.059538251102560814, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.4062440641282592e-05}, {"id": 558, "seek": 325184, "start": 3274.84, "end": 3279.84, "text": " And imagine that we feed one tenth into that.", "tokens": [400, 3811, 300, 321, 3154, 472, 27269, 666, 300, 13], "temperature": 0.0, "avg_logprob": -0.059538251102560814, "compression_ratio": 1.6784140969162995, "no_speech_prob": 1.4062440641282592e-05}, {"id": 559, "seek": 327984, "start": 3279.84, "end": 3285.84, "text": " And so that would be one tenth is less than a half. So it's going to return two tenths.", "tokens": [400, 370, 300, 576, 312, 472, 27269, 307, 1570, 813, 257, 1922, 13, 407, 309, 311, 516, 281, 2736, 732, 27269, 82, 13], "temperature": 0.0, "avg_logprob": -0.10932355244954427, "compression_ratio": 1.5754189944134078, "no_speech_prob": 1.4592498018828337e-06}, {"id": 560, "seek": 327984, "start": 3285.84, "end": 3288.84, "text": " And now feed that two tenths back into F.", "tokens": [400, 586, 3154, 300, 732, 27269, 82, 646, 666, 479, 13], "temperature": 0.0, "avg_logprob": -0.10932355244954427, "compression_ratio": 1.5754189944134078, "no_speech_prob": 1.4592498018828337e-06}, {"id": 561, "seek": 327984, "start": 3288.84, "end": 3297.84, "text": " And I want you to keep doing that and just write out on paper kind of what you would get for the first 10 iterations of kind of starting with one tenth,", "tokens": [400, 286, 528, 291, 281, 1066, 884, 300, 293, 445, 2464, 484, 322, 3035, 733, 295, 437, 291, 576, 483, 337, 264, 700, 1266, 36540, 295, 733, 295, 2891, 365, 472, 27269, 11], "temperature": 0.0, "avg_logprob": -0.10932355244954427, "compression_ratio": 1.5754189944134078, "no_speech_prob": 1.4592498018828337e-06}, {"id": 562, "seek": 329784, "start": 3297.84, "end": 3312.84, "text": " doing F of that, and then do F of your answer.", "tokens": [884, 479, 295, 300, 11, 293, 550, 360, 479, 295, 428, 1867, 13], "temperature": 0.0, "avg_logprob": -0.1326291000141817, "compression_ratio": 0.9787234042553191, "no_speech_prob": 6.142884103610413e-06}, {"id": 563, "seek": 331284, "start": 3312.84, "end": 3331.84, "text": " And this I definitely want you to kind of write out before you before you run the code.", "tokens": [400, 341, 286, 2138, 528, 291, 281, 733, 295, 2464, 484, 949, 291, 949, 291, 1190, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.18021882098654043, "compression_ratio": 1.12987012987013, "no_speech_prob": 2.295732883794699e-06}, {"id": 564, "seek": 333184, "start": 3331.84, "end": 3356.84, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.7449359893798828, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.00010868514800677076}, {"id": 565, "seek": 335684, "start": 3356.84, "end": 3384.84, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.46159760157267254, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.007191705051809549}, {"id": 566, "seek": 338484, "start": 3384.84, "end": 3403.84, "text": " Raise your hand if you want more time.", "tokens": [30062, 428, 1011, 498, 291, 528, 544, 565, 13], "temperature": 0.0, "avg_logprob": -0.11466825008392334, "compression_ratio": 0.8837209302325582, "no_speech_prob": 2.295649437655811e-06}, {"id": 567, "seek": 340384, "start": 3403.84, "end": 3425.84, "text": " All right. Can someone tell me what you got for kind of working this by hand?", "tokens": [1057, 558, 13, 1664, 1580, 980, 385, 437, 291, 658, 337, 733, 295, 1364, 341, 538, 1011, 30], "temperature": 0.0, "avg_logprob": -0.12074719775806773, "compression_ratio": 1.0266666666666666, "no_speech_prob": 1.2877929975729785e-06}, {"id": 568, "seek": 342584, "start": 3425.84, "end": 3433.84, "text": " So I got first one tenth and then two tenths, four tenths, six tenths, and then go back to two tenths.", "tokens": [407, 286, 658, 700, 472, 27269, 293, 550, 732, 27269, 82, 11, 1451, 27269, 82, 11, 2309, 27269, 82, 11, 293, 550, 352, 646, 281, 732, 27269, 82, 13], "temperature": 0.0, "avg_logprob": -0.11666640927714686, "compression_ratio": 1.5166666666666666, "no_speech_prob": 8.713959687156603e-07}, {"id": 569, "seek": 342584, "start": 3433.84, "end": 3445.84, "text": " Right. Yeah. So it's a cycle. Great. Thank you.", "tokens": [1779, 13, 865, 13, 407, 309, 311, 257, 6586, 13, 3769, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.11666640927714686, "compression_ratio": 1.5166666666666666, "no_speech_prob": 8.713959687156603e-07}, {"id": 570, "seek": 342584, "start": 3445.84, "end": 3451.84, "text": " Okay. Yeah. So this is a cycle.", "tokens": [1033, 13, 865, 13, 407, 341, 307, 257, 6586, 13], "temperature": 0.0, "avg_logprob": -0.11666640927714686, "compression_ratio": 1.5166666666666666, "no_speech_prob": 8.713959687156603e-07}, {"id": 571, "seek": 345184, "start": 3451.84, "end": 3458.84, "text": " So now we're going to try running it for 80 iterations to see what happens.", "tokens": [407, 586, 321, 434, 516, 281, 853, 2614, 309, 337, 4688, 36540, 281, 536, 437, 2314, 13], "temperature": 0.0, "avg_logprob": -0.09968155533520144, "compression_ratio": 1.7925925925925925, "no_speech_prob": 3.668752697194577e-06}, {"id": 572, "seek": 345184, "start": 3458.84, "end": 3465.84, "text": " So it starts off point one, point two, point four, point eight, point six, point two, point four, point eight, point six.", "tokens": [407, 309, 3719, 766, 935, 472, 11, 935, 732, 11, 935, 1451, 11, 935, 3180, 11, 935, 2309, 11, 935, 732, 11, 935, 1451, 11, 935, 3180, 11, 935, 2309, 13], "temperature": 0.0, "avg_logprob": -0.09968155533520144, "compression_ratio": 1.7925925925925925, "no_speech_prob": 3.668752697194577e-06}, {"id": 573, "seek": 345184, "start": 3465.84, "end": 3475.84, "text": " But what's what's happening as this goes on?", "tokens": [583, 437, 311, 437, 311, 2737, 382, 341, 1709, 322, 30], "temperature": 0.0, "avg_logprob": -0.09968155533520144, "compression_ratio": 1.7925925925925925, "no_speech_prob": 3.668752697194577e-06}, {"id": 574, "seek": 347584, "start": 3475.84, "end": 3488.84, "text": " And then we actually end up getting one just over and over again. So the method on the computer has converged to one being the answer.", "tokens": [400, 550, 321, 767, 917, 493, 1242, 472, 445, 670, 293, 670, 797, 13, 407, 264, 3170, 322, 264, 3820, 575, 9652, 3004, 281, 472, 885, 264, 1867, 13], "temperature": 0.0, "avg_logprob": -0.06858805860026498, "compression_ratio": 1.6457399103139014, "no_speech_prob": 1.0676751571736531e-06}, {"id": 575, "seek": 347584, "start": 3488.84, "end": 3496.84, "text": " I think I think this is pretty cool. Like it's a fairly simple example and it's something that you can work by hand and work on the computer.", "tokens": [286, 519, 286, 519, 341, 307, 1238, 1627, 13, 1743, 309, 311, 257, 6457, 2199, 1365, 293, 309, 311, 746, 300, 291, 393, 589, 538, 1011, 293, 589, 322, 264, 3820, 13], "temperature": 0.0, "avg_logprob": -0.06858805860026498, "compression_ratio": 1.6457399103139014, "no_speech_prob": 1.0676751571736531e-06}, {"id": 576, "seek": 347584, "start": 3496.84, "end": 3502.84, "text": " And you're clearly getting two different things. And so we'll talk about this in a moment.", "tokens": [400, 291, 434, 4448, 1242, 732, 819, 721, 13, 400, 370, 321, 603, 751, 466, 341, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.06858805860026498, "compression_ratio": 1.6457399103139014, "no_speech_prob": 1.0676751571736531e-06}, {"id": 577, "seek": 350284, "start": 3502.84, "end": 3512.84, "text": " And something to keep in mind is that when you do get kind of these computer kind of numeric errors, it's often happening with repetition when an error is kind of getting multiplied.", "tokens": [400, 746, 281, 1066, 294, 1575, 307, 300, 562, 291, 360, 483, 733, 295, 613, 3820, 733, 295, 7866, 299, 13603, 11, 309, 311, 2049, 2737, 365, 30432, 562, 364, 6713, 307, 733, 295, 1242, 17207, 13], "temperature": 0.0, "avg_logprob": -0.13850100496982007, "compression_ratio": 1.6120689655172413, "no_speech_prob": 4.289067419449566e-06}, {"id": 578, "seek": 350284, "start": 3512.84, "end": 3516.84, "text": " Because you'll notice that this is going to go back up.", "tokens": [1436, 291, 603, 3449, 300, 341, 307, 516, 281, 352, 646, 493, 13], "temperature": 0.0, "avg_logprob": -0.13850100496982007, "compression_ratio": 1.6120689655172413, "no_speech_prob": 4.289067419449566e-06}, {"id": 579, "seek": 350284, "start": 3516.84, "end": 3519.84, "text": " You know, this wasn't exactly point six, but it was pretty close. Right.", "tokens": [509, 458, 11, 341, 2067, 380, 2293, 935, 2309, 11, 457, 309, 390, 1238, 1998, 13, 1779, 13], "temperature": 0.0, "avg_logprob": -0.13850100496982007, "compression_ratio": 1.6120689655172413, "no_speech_prob": 4.289067419449566e-06}, {"id": 580, "seek": 350284, "start": 3519.84, "end": 3522.84, "text": " It was point six. I don't know how many 10 zeros or something.", "tokens": [467, 390, 935, 2309, 13, 286, 500, 380, 458, 577, 867, 1266, 35193, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.13850100496982007, "compression_ratio": 1.6120689655172413, "no_speech_prob": 4.289067419449566e-06}, {"id": 581, "seek": 352284, "start": 3522.84, "end": 3533.84, "text": " And then a one. So that's a pretty small layer. But those got bigger and bigger. Kind of how far it was off.", "tokens": [400, 550, 257, 472, 13, 407, 300, 311, 257, 1238, 1359, 4583, 13, 583, 729, 658, 3801, 293, 3801, 13, 9242, 295, 577, 1400, 309, 390, 766, 13], "temperature": 0.0, "avg_logprob": -0.07750271615527925, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.0187795851379633e-06}, {"id": 582, "seek": 352284, "start": 3533.84, "end": 3541.84, "text": " Yeah. And so that kind of the two limitations of how computers represent numbers are numbers can't be arbitrarily large or small.", "tokens": [865, 13, 400, 370, 300, 733, 295, 264, 732, 15705, 295, 577, 10807, 2906, 3547, 366, 3547, 393, 380, 312, 19071, 3289, 2416, 420, 1359, 13], "temperature": 0.0, "avg_logprob": -0.07750271615527925, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.0187795851379633e-06}, {"id": 583, "seek": 352284, "start": 3541.84, "end": 3548.84, "text": " Like there has to be some limit and there have to be gaps between them. They can't be continuous.", "tokens": [1743, 456, 575, 281, 312, 512, 4948, 293, 456, 362, 281, 312, 15031, 1296, 552, 13, 814, 393, 380, 312, 10957, 13], "temperature": 0.0, "avg_logprob": -0.07750271615527925, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.0187795851379633e-06}, {"id": 584, "seek": 354884, "start": 3548.84, "end": 3555.84, "text": " And so the way that computers store numbers and this is called floating point arithmetic.", "tokens": [400, 370, 264, 636, 300, 10807, 3531, 3547, 293, 341, 307, 1219, 12607, 935, 42973, 13], "temperature": 0.0, "avg_logprob": -0.07458828820122612, "compression_ratio": 1.7356828193832599, "no_speech_prob": 2.9943009849375812e-06}, {"id": 585, "seek": 354884, "start": 3555.84, "end": 3560.84, "text": " And I want to specify floating point arithmetic is just one piece of accuracy.", "tokens": [400, 286, 528, 281, 16500, 12607, 935, 42973, 307, 445, 472, 2522, 295, 14170, 13], "temperature": 0.0, "avg_logprob": -0.07458828820122612, "compression_ratio": 1.7356828193832599, "no_speech_prob": 2.9943009849375812e-06}, {"id": 586, "seek": 354884, "start": 3560.84, "end": 3563.84, "text": " So we're kind of talking about the broader concept of accuracy on a computer.", "tokens": [407, 321, 434, 733, 295, 1417, 466, 264, 13227, 3410, 295, 14170, 322, 257, 3820, 13], "temperature": 0.0, "avg_logprob": -0.07458828820122612, "compression_ratio": 1.7356828193832599, "no_speech_prob": 2.9943009849375812e-06}, {"id": 587, "seek": 354884, "start": 3563.84, "end": 3568.84, "text": " And this is one component to consider. But floating point numbers have three parts.", "tokens": [400, 341, 307, 472, 6542, 281, 1949, 13, 583, 12607, 935, 3547, 362, 1045, 3166, 13], "temperature": 0.0, "avg_logprob": -0.07458828820122612, "compression_ratio": 1.7356828193832599, "no_speech_prob": 2.9943009849375812e-06}, {"id": 588, "seek": 354884, "start": 3568.84, "end": 3572.84, "text": " There's a sign. This is just a single bit positive or negative.", "tokens": [821, 311, 257, 1465, 13, 639, 307, 445, 257, 2167, 857, 3353, 420, 3671, 13], "temperature": 0.0, "avg_logprob": -0.07458828820122612, "compression_ratio": 1.7356828193832599, "no_speech_prob": 2.9943009849375812e-06}, {"id": 589, "seek": 357284, "start": 3572.84, "end": 3578.84, "text": " What's called the mantissa are often the significant and that kind of has the digits.", "tokens": [708, 311, 1219, 264, 10845, 10138, 366, 2049, 264, 4776, 293, 300, 733, 295, 575, 264, 27011, 13], "temperature": 0.0, "avg_logprob": -0.12565352699973367, "compression_ratio": 1.7782608695652173, "no_speech_prob": 9.132263585343026e-07}, {"id": 590, "seek": 357284, "start": 3578.84, "end": 3585.84, "text": " If you're familiar with scientific notation, when you have the like one point seven three, that's you know, that's the mantissa.", "tokens": [759, 291, 434, 4963, 365, 8134, 24657, 11, 562, 291, 362, 264, 411, 472, 935, 3407, 1045, 11, 300, 311, 291, 458, 11, 300, 311, 264, 10845, 10138, 13], "temperature": 0.0, "avg_logprob": -0.12565352699973367, "compression_ratio": 1.7782608695652173, "no_speech_prob": 9.132263585343026e-07}, {"id": 591, "seek": 357284, "start": 3585.84, "end": 3589.84, "text": " And then in scientific notation, the rate X is 10, which is the base.", "tokens": [400, 550, 294, 8134, 24657, 11, 264, 3314, 1783, 307, 1266, 11, 597, 307, 264, 3096, 13], "temperature": 0.0, "avg_logprob": -0.12565352699973367, "compression_ratio": 1.7782608695652173, "no_speech_prob": 9.132263585343026e-07}, {"id": 592, "seek": 357284, "start": 3589.84, "end": 3596.84, "text": " You know, you have an exponent. So you've actually kind of seen this before of having significant and exponent in computers.", "tokens": [509, 458, 11, 291, 362, 364, 37871, 13, 407, 291, 600, 767, 733, 295, 1612, 341, 949, 295, 1419, 4776, 293, 37871, 294, 10807, 13], "temperature": 0.0, "avg_logprob": -0.12565352699973367, "compression_ratio": 1.7782608695652173, "no_speech_prob": 9.132263585343026e-07}, {"id": 593, "seek": 359684, "start": 3596.84, "end": 3603.84, "text": " The rate X is two. But this is the idea. And that you I mean, the computer has to make space to sort store these things.", "tokens": [440, 3314, 1783, 307, 732, 13, 583, 341, 307, 264, 1558, 13, 400, 300, 291, 286, 914, 11, 264, 3820, 575, 281, 652, 1901, 281, 1333, 3531, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.12976158096129636, "compression_ratio": 1.5721153846153846, "no_speech_prob": 3.2057690191322763e-07}, {"id": 594, "seek": 359684, "start": 3603.84, "end": 3614.84, "text": " The sign, the number of digits and are the significant kind of the value or precision of those digits and then the exponent.", "tokens": [440, 1465, 11, 264, 1230, 295, 27011, 293, 366, 264, 4776, 733, 295, 264, 2158, 420, 18356, 295, 729, 27011, 293, 550, 264, 37871, 13], "temperature": 0.0, "avg_logprob": -0.12976158096129636, "compression_ratio": 1.5721153846153846, "no_speech_prob": 3.2057690191322763e-07}, {"id": 595, "seek": 359684, "start": 3614.84, "end": 3619.84, "text": " And so I triple E is a set of standards that came out and I haven't written down.", "tokens": [400, 370, 286, 15508, 462, 307, 257, 992, 295, 7787, 300, 1361, 484, 293, 286, 2378, 380, 3720, 760, 13], "temperature": 0.0, "avg_logprob": -0.12976158096129636, "compression_ratio": 1.5721153846153846, "no_speech_prob": 3.2057690191322763e-07}, {"id": 596, "seek": 361984, "start": 3619.84, "end": 3626.84, "text": " I think it was maybe like mid 80s about how computers should store numbers.", "tokens": [286, 519, 309, 390, 1310, 411, 2062, 4688, 82, 466, 577, 10807, 820, 3531, 3547, 13], "temperature": 0.0, "avg_logprob": -0.08498869623456683, "compression_ratio": 1.5695067264573992, "no_speech_prob": 8.579050359003304e-07}, {"id": 597, "seek": 361984, "start": 3626.84, "end": 3632.84, "text": " And it's really great to have something that's consistent no matter what type of computer you're using, because that could be a big issue.", "tokens": [400, 309, 311, 534, 869, 281, 362, 746, 300, 311, 8398, 572, 1871, 437, 2010, 295, 3820, 291, 434, 1228, 11, 570, 300, 727, 312, 257, 955, 2734, 13], "temperature": 0.0, "avg_logprob": -0.08498869623456683, "compression_ratio": 1.5695067264573992, "no_speech_prob": 8.579050359003304e-07}, {"id": 598, "seek": 361984, "start": 3632.84, "end": 3638.84, "text": " And in the early days of computing, there people were doing different things.", "tokens": [400, 294, 264, 2440, 1708, 295, 15866, 11, 456, 561, 645, 884, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.08498869623456683, "compression_ratio": 1.5695067264573992, "no_speech_prob": 8.579050359003304e-07}, {"id": 599, "seek": 361984, "start": 3638.84, "end": 3644.84, "text": " So this is just and we will talk about this a little bit.", "tokens": [407, 341, 307, 445, 293, 321, 486, 751, 466, 341, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.08498869623456683, "compression_ratio": 1.5695067264573992, "no_speech_prob": 8.579050359003304e-07}, {"id": 600, "seek": 364484, "start": 3644.84, "end": 3652.84, "text": " Python's if you've primarily been using Python, Python doesn't require you to say what your types are and kind of hide that from you.", "tokens": [15329, 311, 498, 291, 600, 10029, 668, 1228, 15329, 11, 15329, 1177, 380, 3651, 291, 281, 584, 437, 428, 3467, 366, 293, 733, 295, 6479, 300, 490, 291, 13], "temperature": 0.0, "avg_logprob": -0.1158104682790822, "compression_ratio": 1.7188612099644127, "no_speech_prob": 1.4283526979852468e-05}, {"id": 601, "seek": 364484, "start": 3652.84, "end": 3657.84, "text": " Many languages, particularly older languages, you had to say what type something was.", "tokens": [5126, 8650, 11, 4098, 4906, 8650, 11, 291, 632, 281, 584, 437, 2010, 746, 390, 13], "temperature": 0.0, "avg_logprob": -0.1158104682790822, "compression_ratio": 1.7188612099644127, "no_speech_prob": 1.4283526979852468e-05}, {"id": 602, "seek": 364484, "start": 3657.84, "end": 3660.84, "text": " And that's what the computer knew how much memory to set aside.", "tokens": [400, 300, 311, 437, 264, 3820, 2586, 577, 709, 4675, 281, 992, 7359, 13], "temperature": 0.0, "avg_logprob": -0.1158104682790822, "compression_ratio": 1.7188612099644127, "no_speech_prob": 1.4283526979852468e-05}, {"id": 603, "seek": 364484, "start": 3660.84, "end": 3666.84, "text": " And so for what we think of decimal numbers, they're actually, you know, typically a float or a double.", "tokens": [400, 370, 337, 437, 321, 519, 295, 26601, 3547, 11, 436, 434, 767, 11, 291, 458, 11, 5850, 257, 15706, 420, 257, 3834, 13], "temperature": 0.0, "avg_logprob": -0.1158104682790822, "compression_ratio": 1.7188612099644127, "no_speech_prob": 1.4283526979852468e-05}, {"id": 604, "seek": 364484, "start": 3666.84, "end": 3672.84, "text": " Those are both kind of same type of numbers, but double saying you want more space to store it.", "tokens": [3950, 366, 1293, 733, 295, 912, 2010, 295, 3547, 11, 457, 3834, 1566, 291, 528, 544, 1901, 281, 3531, 309, 13], "temperature": 0.0, "avg_logprob": -0.1158104682790822, "compression_ratio": 1.7188612099644127, "no_speech_prob": 1.4283526979852468e-05}, {"id": 605, "seek": 367284, "start": 3672.84, "end": 3676.84, "text": " And so here I've just said and Python is handling all this stuff behind the scenes.", "tokens": [400, 370, 510, 286, 600, 445, 848, 293, 15329, 307, 13175, 439, 341, 1507, 2261, 264, 8026, 13], "temperature": 0.0, "avg_logprob": -0.10500850677490234, "compression_ratio": 1.5642201834862386, "no_speech_prob": 1.963730937859509e-06}, {"id": 606, "seek": 367284, "start": 3676.84, "end": 3680.84, "text": " It just kind of hides that from you.", "tokens": [467, 445, 733, 295, 35953, 300, 490, 291, 13], "temperature": 0.0, "avg_logprob": -0.10500850677490234, "compression_ratio": 1.5642201834862386, "no_speech_prob": 1.963730937859509e-06}, {"id": 607, "seek": 367284, "start": 3680.84, "end": 3687.84, "text": " Yeah. So here are what the requirements for doubles are.", "tokens": [865, 13, 407, 510, 366, 437, 264, 7728, 337, 31634, 366, 13], "temperature": 0.0, "avg_logprob": -0.10500850677490234, "compression_ratio": 1.5642201834862386, "no_speech_prob": 1.963730937859509e-06}, {"id": 608, "seek": 367284, "start": 3687.84, "end": 3699.84, "text": " Numbers can be as large as this is something 10 to the three hundred and eighth, which is that's pretty big or as small as 10 to the negative three hundred eighth.", "tokens": [22592, 1616, 393, 312, 382, 2416, 382, 341, 307, 746, 1266, 281, 264, 1045, 3262, 293, 19495, 11, 597, 307, 300, 311, 1238, 955, 420, 382, 1359, 382, 1266, 281, 264, 3671, 1045, 3262, 19495, 13], "temperature": 0.0, "avg_logprob": -0.10500850677490234, "compression_ratio": 1.5642201834862386, "no_speech_prob": 1.963730937859509e-06}, {"id": 609, "seek": 369984, "start": 3699.84, "end": 3703.84, "text": " And then I think I think this is really interesting the way that they're represented.", "tokens": [400, 550, 286, 519, 286, 519, 341, 307, 534, 1880, 264, 636, 300, 436, 434, 10379, 13], "temperature": 0.0, "avg_logprob": -0.0854653747458207, "compression_ratio": 2.0980392156862746, "no_speech_prob": 3.6686888051917776e-06}, {"id": 610, "seek": 369984, "start": 3703.84, "end": 3705.84, "text": " So think about the interval from one to two.", "tokens": [407, 519, 466, 264, 15035, 490, 472, 281, 732, 13], "temperature": 0.0, "avg_logprob": -0.0854653747458207, "compression_ratio": 2.0980392156862746, "no_speech_prob": 3.6686888051917776e-06}, {"id": 611, "seek": 369984, "start": 3705.84, "end": 3720.84, "text": " You can represent one and then one plus two to the negative fifty two one plus two times two to the negative fifty two one plus three times two to the negative fifty two and so on up to two.", "tokens": [509, 393, 2906, 472, 293, 550, 472, 1804, 732, 281, 264, 3671, 13442, 732, 472, 1804, 732, 1413, 732, 281, 264, 3671, 13442, 732, 472, 1804, 1045, 1413, 732, 281, 264, 3671, 13442, 732, 293, 370, 322, 493, 281, 732, 13], "temperature": 0.0, "avg_logprob": -0.0854653747458207, "compression_ratio": 2.0980392156862746, "no_speech_prob": 3.6686888051917776e-06}, {"id": 612, "seek": 372084, "start": 3720.84, "end": 3729.84, "text": " And then the interval from the interval from two to four is going.", "tokens": [400, 550, 264, 15035, 490, 264, 15035, 490, 732, 281, 1451, 307, 516, 13], "temperature": 0.0, "avg_logprob": -0.2089565646263861, "compression_ratio": 1.25, "no_speech_prob": 3.1380882319353987e-06}, {"id": 613, "seek": 372084, "start": 3729.84, "end": 3734.84, "text": " Oh, and this is an error. Change that.", "tokens": [876, 11, 293, 341, 307, 364, 6713, 13, 15060, 300, 13], "temperature": 0.0, "avg_logprob": -0.2089565646263861, "compression_ratio": 1.25, "no_speech_prob": 3.1380882319353987e-06}, {"id": 614, "seek": 373484, "start": 3734.84, "end": 3750.84, "text": " See it too. It's going kind of you can represent two and then two plus two to the negative fifty one two plus two times two to the negative fifty one two plus three times two to the negative fifty one.", "tokens": [3008, 309, 886, 13, 467, 311, 516, 733, 295, 291, 393, 2906, 732, 293, 550, 732, 1804, 732, 281, 264, 3671, 13442, 472, 732, 1804, 732, 1413, 732, 281, 264, 3671, 13442, 472, 732, 1804, 1045, 1413, 732, 281, 264, 3671, 13442, 472, 13], "temperature": 0.0, "avg_logprob": -0.16118626227745644, "compression_ratio": 1.9202898550724639, "no_speech_prob": 1.2678339089688961e-06}, {"id": 615, "seek": 373484, "start": 3750.84, "end": 3755.84, "text": " And so the you'll notice the numbers are not equidistant apart.", "tokens": [400, 370, 264, 291, 603, 3449, 264, 3547, 366, 406, 1267, 327, 10329, 4936, 13], "temperature": 0.0, "avg_logprob": -0.16118626227745644, "compression_ratio": 1.9202898550724639, "no_speech_prob": 1.2678339089688961e-06}, {"id": 616, "seek": 375584, "start": 3755.84, "end": 3764.84, "text": " So basically the bigger that the magnitude of the numbers get the kind of the more they're spaced out, which I think is kind of weird and interesting.", "tokens": [407, 1936, 264, 3801, 300, 264, 15668, 295, 264, 3547, 483, 264, 733, 295, 264, 544, 436, 434, 43766, 484, 11, 597, 286, 519, 307, 733, 295, 3657, 293, 1880, 13], "temperature": 0.0, "avg_logprob": -0.1420299212137858, "compression_ratio": 1.6149068322981366, "no_speech_prob": 2.368498144278419e-06}, {"id": 617, "seek": 375584, "start": 3764.84, "end": 3774.84, "text": " So this is a nice kind of a graphic showing that that close to kind of for small numbers are closer together.", "tokens": [407, 341, 307, 257, 1481, 733, 295, 257, 14089, 4099, 300, 300, 1998, 281, 733, 295, 337, 1359, 3547, 366, 4966, 1214, 13], "temperature": 0.0, "avg_logprob": -0.1420299212137858, "compression_ratio": 1.6149068322981366, "no_speech_prob": 2.368498144278419e-06}, {"id": 618, "seek": 377484, "start": 3774.84, "end": 3786.84, "text": " I just thought we were pointing out that the two things that we're using in this class to represent numbers being numpy and pytorch both are types given that the Python isn't.", "tokens": [286, 445, 1194, 321, 645, 12166, 484, 300, 264, 732, 721, 300, 321, 434, 1228, 294, 341, 1508, 281, 2906, 3547, 885, 1031, 8200, 293, 25878, 284, 339, 1293, 366, 3467, 2212, 300, 264, 15329, 1943, 380, 13], "temperature": 0.0, "avg_logprob": -0.3143622315960166, "compression_ratio": 1.7712765957446808, "no_speech_prob": 0.0004707624902948737}, {"id": 619, "seek": 377484, "start": 3786.84, "end": 3792.84, "text": " So with numpy if you feed it a float it will create a double position float.", "tokens": [407, 365, 1031, 8200, 498, 291, 3154, 309, 257, 15706, 309, 486, 1884, 257, 3834, 2535, 15706, 13], "temperature": 0.0, "avg_logprob": -0.3143622315960166, "compression_ratio": 1.7712765957446808, "no_speech_prob": 0.0004707624902948737}, {"id": 620, "seek": 377484, "start": 3792.84, "end": 3797.84, "text": " If you feed it anything as a float it will create a double position float array.", "tokens": [759, 291, 3154, 309, 1340, 382, 257, 15706, 309, 486, 1884, 257, 3834, 2535, 15706, 10225, 13], "temperature": 0.0, "avg_logprob": -0.3143622315960166, "compression_ratio": 1.7712765957446808, "no_speech_prob": 0.0004707624902948737}, {"id": 621, "seek": 379784, "start": 3797.84, "end": 3805.84, "text": " If they're all instead of create a long integer array and then when we use pytorch we're all explicitly saying what type of thing is.", "tokens": [759, 436, 434, 439, 2602, 295, 1884, 257, 938, 24922, 10225, 293, 550, 562, 321, 764, 25878, 284, 339, 321, 434, 439, 20803, 1566, 437, 2010, 295, 551, 307, 13], "temperature": 0.0, "avg_logprob": -0.2642079436260721, "compression_ratio": 1.5313807531380754, "no_speech_prob": 1.2216488357807975e-05}, {"id": 622, "seek": 379784, "start": 3805.84, "end": 3809.84, "text": " So we are using type libraries pretty much exclusively in this course.", "tokens": [407, 321, 366, 1228, 2010, 15148, 1238, 709, 20638, 294, 341, 1164, 13], "temperature": 0.0, "avg_logprob": -0.2642079436260721, "compression_ratio": 1.5313807531380754, "no_speech_prob": 1.2216488357807975e-05}, {"id": 623, "seek": 379784, "start": 3809.84, "end": 3818.84, "text": " Thank you. That's a great point. And also even another library will use his number, which lets you add types to Python in general.", "tokens": [1044, 291, 13, 663, 311, 257, 869, 935, 13, 400, 611, 754, 1071, 6405, 486, 764, 702, 1230, 11, 597, 6653, 291, 909, 3467, 281, 15329, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.2642079436260721, "compression_ratio": 1.5313807531380754, "no_speech_prob": 1.2216488357807975e-05}, {"id": 624, "seek": 379784, "start": 3818.84, "end": 3821.84, "text": " Oh, just I thought. OK. Sorry.", "tokens": [876, 11, 445, 286, 1194, 13, 2264, 13, 4919, 13], "temperature": 0.0, "avg_logprob": -0.2642079436260721, "compression_ratio": 1.5313807531380754, "no_speech_prob": 1.2216488357807975e-05}, {"id": 625, "seek": 382184, "start": 3821.84, "end": 3835.84, "text": " Python is the one that lets you add types to Python. So that is something that comes you will often want to add and that numpy kind of has built in when you're doing scientific computing and also for improving performance.", "tokens": [15329, 307, 264, 472, 300, 6653, 291, 909, 3467, 281, 15329, 13, 407, 300, 307, 746, 300, 1487, 291, 486, 2049, 528, 281, 909, 293, 300, 1031, 8200, 733, 295, 575, 3094, 294, 562, 291, 434, 884, 8134, 15866, 293, 611, 337, 11470, 3389, 13], "temperature": 0.0, "avg_logprob": -0.13508022365285388, "compression_ratio": 1.545945945945946, "no_speech_prob": 1.6535772147108219e-06}, {"id": 626, "seek": 382184, "start": 3835.84, "end": 3839.84, "text": " It typically lets you.", "tokens": [467, 5850, 6653, 291, 13], "temperature": 0.0, "avg_logprob": -0.13508022365285388, "compression_ratio": 1.545945945945946, "no_speech_prob": 1.6535772147108219e-06}, {"id": 627, "seek": 382184, "start": 3839.84, "end": 3844.84, "text": " Kind of go faster to handle it yourself.", "tokens": [9242, 295, 352, 4663, 281, 4813, 309, 1803, 13], "temperature": 0.0, "avg_logprob": -0.13508022365285388, "compression_ratio": 1.545945945945946, "no_speech_prob": 1.6535772147108219e-06}, {"id": 628, "seek": 384484, "start": 3844.84, "end": 3853.84, "text": " And so machine epsilon that's kind of defined to be half the distance between one and the next larger number.", "tokens": [400, 370, 3479, 17889, 300, 311, 733, 295, 7642, 281, 312, 1922, 264, 4560, 1296, 472, 293, 264, 958, 4833, 1230, 13], "temperature": 0.0, "avg_logprob": -0.1221460594850428, "compression_ratio": 1.6627906976744187, "no_speech_prob": 3.784942236961797e-06}, {"id": 629, "seek": 384484, "start": 3853.84, "end": 3859.84, "text": " So for double precision machine epsilon is two to the negative 53.", "tokens": [407, 337, 3834, 18356, 3479, 17889, 307, 732, 281, 264, 3671, 21860, 13], "temperature": 0.0, "avg_logprob": -0.1221460594850428, "compression_ratio": 1.6627906976744187, "no_speech_prob": 3.784942236961797e-06}, {"id": 630, "seek": 384484, "start": 3859.84, "end": 3867.84, "text": " You can kind of see that up here that the thing kind of the next number after one is to the negative 52 more.", "tokens": [509, 393, 733, 295, 536, 300, 493, 510, 300, 264, 551, 733, 295, 264, 958, 1230, 934, 472, 307, 281, 264, 3671, 18079, 544, 13], "temperature": 0.0, "avg_logprob": -0.1221460594850428, "compression_ratio": 1.6627906976744187, "no_speech_prob": 3.784942236961797e-06}, {"id": 631, "seek": 386784, "start": 3867.84, "end": 3875.84, "text": " So half of that is two to the negative 53. And this is kind of a term that you'll hear people people talk about.", "tokens": [407, 1922, 295, 300, 307, 732, 281, 264, 3671, 21860, 13, 400, 341, 307, 733, 295, 257, 1433, 300, 291, 603, 1568, 561, 561, 751, 466, 13], "temperature": 0.0, "avg_logprob": -0.13838065112078632, "compression_ratio": 1.6041666666666667, "no_speech_prob": 7.337849865507451e-07}, {"id": 632, "seek": 386784, "start": 3875.84, "end": 3883.84, "text": " And then converting from base two to base 10 that's equivalent to about 10 to the negative 16.", "tokens": [400, 550, 29942, 490, 3096, 732, 281, 3096, 1266, 300, 311, 10344, 281, 466, 1266, 281, 264, 3671, 3165, 13], "temperature": 0.0, "avg_logprob": -0.13838065112078632, "compression_ratio": 1.6041666666666667, "no_speech_prob": 7.337849865507451e-07}, {"id": 633, "seek": 386784, "start": 3883.84, "end": 3887.84, "text": " And we'll see this kind of show up an example later.", "tokens": [400, 321, 603, 536, 341, 733, 295, 855, 493, 364, 1365, 1780, 13], "temperature": 0.0, "avg_logprob": -0.13838065112078632, "compression_ratio": 1.6041666666666667, "no_speech_prob": 7.337849865507451e-07}, {"id": 634, "seek": 386784, "start": 3887.84, "end": 3890.84, "text": " Any questions.", "tokens": [2639, 1651, 13], "temperature": 0.0, "avg_logprob": -0.13838065112078632, "compression_ratio": 1.6041666666666667, "no_speech_prob": 7.337849865507451e-07}, {"id": 635, "seek": 386784, "start": 3890.84, "end": 3893.84, "text": " Why does machine epsilon matter.", "tokens": [1545, 775, 3479, 17889, 1871, 13], "temperature": 0.0, "avg_logprob": -0.13838065112078632, "compression_ratio": 1.6041666666666667, "no_speech_prob": 7.337849865507451e-07}, {"id": 636, "seek": 389384, "start": 3893.84, "end": 3910.84, "text": " So machine epsilon often you'll talk about your air as a in terms of machine epsilon is that something that's kind of inescapable that you know the computer can't represent something smaller than that.", "tokens": [407, 3479, 17889, 2049, 291, 603, 751, 466, 428, 1988, 382, 257, 294, 2115, 295, 3479, 17889, 307, 300, 746, 300, 311, 733, 295, 294, 279, 9485, 712, 300, 291, 458, 264, 3820, 393, 380, 2906, 746, 4356, 813, 300, 13], "temperature": 0.0, "avg_logprob": -0.10899751451280382, "compression_ratio": 1.534351145038168, "no_speech_prob": 1.9332219380885363e-06}, {"id": 637, "seek": 391084, "start": 3910.84, "end": 3923.84, "text": " And so you'll just kind of talk about I mean if you have an algorithm that makes that worse stirs in terms of you know the square root of that then that's kind of worse than the computer could be doing.", "tokens": [400, 370, 291, 603, 445, 733, 295, 751, 466, 286, 914, 498, 291, 362, 364, 9284, 300, 1669, 300, 5324, 8946, 82, 294, 2115, 295, 291, 458, 264, 3732, 5593, 295, 300, 550, 300, 311, 733, 295, 5324, 813, 264, 3820, 727, 312, 884, 13], "temperature": 0.0, "avg_logprob": -0.09149472400395557, "compression_ratio": 1.7521367521367521, "no_speech_prob": 1.6119615509069263e-07}, {"id": 638, "seek": 391084, "start": 3923.84, "end": 3927.84, "text": " And depending on what you're trying to do it varies what's possible.", "tokens": [400, 5413, 322, 437, 291, 434, 1382, 281, 360, 309, 21716, 437, 311, 1944, 13], "temperature": 0.0, "avg_logprob": -0.09149472400395557, "compression_ratio": 1.7521367521367521, "no_speech_prob": 1.6119615509069263e-07}, {"id": 639, "seek": 391084, "start": 3927.84, "end": 3934.84, "text": " But this is kind of a good unit to talk about how you're how you're doing.", "tokens": [583, 341, 307, 733, 295, 257, 665, 4985, 281, 751, 466, 577, 291, 434, 577, 291, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.09149472400395557, "compression_ratio": 1.7521367521367521, "no_speech_prob": 1.6119615509069263e-07}, {"id": 640, "seek": 391084, "start": 3934.84, "end": 3939.84, "text": " And then two important properties of floating point arithmetic.", "tokens": [400, 550, 732, 1021, 7221, 295, 12607, 935, 42973, 13], "temperature": 0.0, "avg_logprob": -0.09149472400395557, "compression_ratio": 1.7521367521367521, "no_speech_prob": 1.6119615509069263e-07}, {"id": 641, "seek": 393984, "start": 3939.84, "end": 3951.84, "text": " One is that the difference between a real number and its closest floating point approximation is always smaller than machine epsilon in relative terms.", "tokens": [1485, 307, 300, 264, 2649, 1296, 257, 957, 1230, 293, 1080, 13699, 12607, 935, 28023, 307, 1009, 4356, 813, 3479, 17889, 294, 4972, 2115, 13], "temperature": 0.0, "avg_logprob": -0.1506836332123855, "compression_ratio": 1.5674157303370786, "no_speech_prob": 1.9332480860612122e-06}, {"id": 642, "seek": 393984, "start": 3951.84, "end": 3959.84, "text": " So here f l of acts is the floating point representation and then the X is kind of the true number you're wanting to represent.", "tokens": [407, 510, 283, 287, 295, 10672, 307, 264, 12607, 935, 10290, 293, 550, 264, 1783, 307, 733, 295, 264, 2074, 1230, 291, 434, 7935, 281, 2906, 13], "temperature": 0.0, "avg_logprob": -0.1506836332123855, "compression_ratio": 1.5674157303370786, "no_speech_prob": 1.9332480860612122e-06}, {"id": 643, "seek": 395984, "start": 3959.84, "end": 3971.84, "text": " And it's saying the floating point representation is going to be equal to X times one plus some epsilon and that epsilon is less than or equal to machine epsilon.", "tokens": [400, 309, 311, 1566, 264, 12607, 935, 10290, 307, 516, 281, 312, 2681, 281, 1783, 1413, 472, 1804, 512, 17889, 293, 300, 17889, 307, 1570, 813, 420, 2681, 281, 3479, 17889, 13], "temperature": 0.0, "avg_logprob": -0.0809610534358669, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.2678729035542347e-06}, {"id": 644, "seek": 395984, "start": 3971.84, "end": 3975.84, "text": " So it's kind of nice to give you a bound on your accuracy.", "tokens": [407, 309, 311, 733, 295, 1481, 281, 976, 291, 257, 5472, 322, 428, 14170, 13], "temperature": 0.0, "avg_logprob": -0.0809610534358669, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.2678729035542347e-06}, {"id": 645, "seek": 395984, "start": 3975.84, "end": 3982.84, "text": " And then for the kind of key floating point operations which are addition subtraction multiplication and division.", "tokens": [400, 550, 337, 264, 733, 295, 2141, 12607, 935, 7705, 597, 366, 4500, 16390, 313, 27290, 293, 10044, 13], "temperature": 0.0, "avg_logprob": -0.0809610534358669, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.2678729035542347e-06}, {"id": 646, "seek": 398284, "start": 3982.84, "end": 3991.84, "text": " So a lot star represent that operation and then circle star is the floating point equivalent of that kind of how it's implemented.", "tokens": [407, 257, 688, 3543, 2906, 300, 6916, 293, 550, 6329, 3543, 307, 264, 12607, 935, 10344, 295, 300, 733, 295, 577, 309, 311, 12270, 13], "temperature": 0.0, "avg_logprob": -0.10233320792516072, "compression_ratio": 1.4609929078014185, "no_speech_prob": 1.5381472451281297e-07}, {"id": 647, "seek": 398284, "start": 3991.84, "end": 4002.84, "text": " Your result is going to be no more than a multiple of one plus epsilon off.", "tokens": [2260, 1874, 307, 516, 281, 312, 572, 544, 813, 257, 3866, 295, 472, 1804, 17889, 766, 13], "temperature": 0.0, "avg_logprob": -0.10233320792516072, "compression_ratio": 1.4609929078014185, "no_speech_prob": 1.5381472451281297e-07}, {"id": 648, "seek": 400284, "start": 4002.84, "end": 4015.84, "text": " And then this next part I included because I just found it was really interesting to read about. I found this book called Handbook of Floating Point Arithmetic and Chapter One is available for free.", "tokens": [400, 550, 341, 958, 644, 286, 5556, 570, 286, 445, 1352, 309, 390, 534, 1880, 281, 1401, 466, 13, 286, 1352, 341, 1446, 1219, 8854, 2939, 295, 15153, 990, 12387, 1587, 41179, 293, 18874, 1485, 307, 2435, 337, 1737, 13], "temperature": 0.0, "avg_logprob": -0.15039542227080374, "compression_ratio": 1.4729064039408868, "no_speech_prob": 1.7601371382625075e-06}, {"id": 649, "seek": 400284, "start": 4015.84, "end": 4023.84, "text": " But it lists a lot of other types of storage schemes that were tried with numbers at various points.", "tokens": [583, 309, 14511, 257, 688, 295, 661, 3467, 295, 6725, 26954, 300, 645, 3031, 365, 3547, 412, 3683, 2793, 13], "temperature": 0.0, "avg_logprob": -0.15039542227080374, "compression_ratio": 1.4729064039408868, "no_speech_prob": 1.7601371382625075e-06}, {"id": 650, "seek": 402384, "start": 4023.84, "end": 4036.84, "text": " And so I don't know what all of these are but I thought it was an interesting list that people tried and possibly infinite strings of rational numbers floating slash number systems.", "tokens": [400, 370, 286, 500, 380, 458, 437, 439, 295, 613, 366, 457, 286, 1194, 309, 390, 364, 1880, 1329, 300, 561, 3031, 293, 6264, 13785, 13985, 295, 15090, 3547, 12607, 17330, 1230, 3652, 13], "temperature": 0.0, "avg_logprob": -0.10347347674162491, "compression_ratio": 1.6109090909090908, "no_speech_prob": 8.713618058209249e-07}, {"id": 651, "seek": 402384, "start": 4036.84, "end": 4039.84, "text": " So there have been a lot of different approaches that have tried.", "tokens": [407, 456, 362, 668, 257, 688, 295, 819, 11587, 300, 362, 3031, 13], "temperature": 0.0, "avg_logprob": -0.10347347674162491, "compression_ratio": 1.6109090909090908, "no_speech_prob": 8.713618058209249e-07}, {"id": 652, "seek": 402384, "start": 4039.84, "end": 4050.84, "text": " And actually let me skip ahead. There's a really nice quote from the book that really you're having to make compromises between speed accuracy dynamic range ease of use implementation and memory.", "tokens": [400, 767, 718, 385, 10023, 2286, 13, 821, 311, 257, 534, 1481, 6513, 490, 264, 1446, 300, 534, 291, 434, 1419, 281, 652, 11482, 3598, 1296, 3073, 14170, 8546, 3613, 12708, 295, 764, 11420, 293, 4675, 13], "temperature": 0.0, "avg_logprob": -0.10347347674162491, "compression_ratio": 1.6109090909090908, "no_speech_prob": 8.713618058209249e-07}, {"id": 653, "seek": 405084, "start": 4050.84, "end": 4063.84, "text": " They're kind of like all these different considerations and that floating point arithmetic seem to be a good compromise for kind of all of this and a lot of people kind of converge to accepting this.", "tokens": [814, 434, 733, 295, 411, 439, 613, 819, 24070, 293, 300, 12607, 935, 42973, 1643, 281, 312, 257, 665, 18577, 337, 733, 295, 439, 295, 341, 293, 257, 688, 295, 561, 733, 295, 41881, 281, 17391, 341, 13], "temperature": 0.0, "avg_logprob": -0.12853791095592357, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.9032536329177674e-06}, {"id": 654, "seek": 405084, "start": 4063.84, "end": 4066.84, "text": " Here is an interesting history of floating point arithmetic.", "tokens": [1692, 307, 364, 1880, 2503, 295, 12607, 935, 42973, 13], "temperature": 0.0, "avg_logprob": -0.12853791095592357, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.9032536329177674e-06}, {"id": 655, "seek": 406684, "start": 4066.84, "end": 4087.84, "text": " Donald Newth cites the Babylonians as being the first to have a floating point arithmetic system. And theirs was base 60 and that was 8000 BC and 1630 the slide rule was invented and there you're manipulating only significance.", "tokens": [8632, 1873, 392, 269, 3324, 264, 30278, 2567, 382, 885, 264, 700, 281, 362, 257, 12607, 935, 42973, 1185, 13, 400, 22760, 390, 3096, 4060, 293, 300, 390, 1649, 1360, 14359, 293, 3165, 3446, 264, 4137, 4978, 390, 14479, 293, 456, 291, 434, 40805, 787, 17687, 13], "temperature": 0.0, "avg_logprob": -0.16382507655931555, "compression_ratio": 1.4974093264248705, "no_speech_prob": 6.240487891773228e-06}, {"id": 656, "seek": 406684, "start": 4087.84, "end": 4093.84, "text": " That's base 10 and radix and base are kind of the same thing.", "tokens": [663, 311, 3096, 1266, 293, 2843, 970, 293, 3096, 366, 733, 295, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.16382507655931555, "compression_ratio": 1.4974093264248705, "no_speech_prob": 6.240487891773228e-06}, {"id": 657, "seek": 409384, "start": 4093.84, "end": 4098.84, "text": " 1941 this is interesting was kind of the first real modern implementation.", "tokens": [35364, 341, 307, 1880, 390, 733, 295, 264, 700, 957, 4363, 11420, 13], "temperature": 0.0, "avg_logprob": -0.12506590804008588, "compression_ratio": 1.603864734299517, "no_speech_prob": 5.681615220964886e-06}, {"id": 658, "seek": 409384, "start": 4098.84, "end": 4104.84, "text": " Conrad Zeus made the Z3 computer and Conrad Zeus", "tokens": [2656, 6206, 35003, 1027, 264, 1176, 18, 3820, 293, 2656, 6206, 35003], "temperature": 0.0, "avg_logprob": -0.12506590804008588, "compression_ratio": 1.603864734299517, "no_speech_prob": 5.681615220964886e-06}, {"id": 659, "seek": 409384, "start": 4104.84, "end": 4115.84, "text": " lived and worked in Nazi Germany and so he was really cut off from the rest of the scientific community and so he built some very interesting computers that kind of nobody else knew about for quite some time.", "tokens": [5152, 293, 2732, 294, 23592, 7244, 293, 370, 415, 390, 534, 1723, 766, 490, 264, 1472, 295, 264, 8134, 1768, 293, 370, 415, 3094, 512, 588, 1880, 10807, 300, 733, 295, 5079, 1646, 2586, 466, 337, 1596, 512, 565, 13], "temperature": 0.0, "avg_logprob": -0.12506590804008588, "compression_ratio": 1.603864734299517, "no_speech_prob": 5.681615220964886e-06}, {"id": 660, "seek": 411584, "start": 4115.84, "end": 4124.84, "text": " Although many of them were destroyed in bombings but he was the first to kind of kind of implement this in a modern computer.", "tokens": [5780, 867, 295, 552, 645, 8937, 294, 7851, 1109, 457, 415, 390, 264, 700, 281, 733, 295, 733, 295, 4445, 341, 294, 257, 4363, 3820, 13], "temperature": 0.0, "avg_logprob": -0.10908183370317731, "compression_ratio": 1.4976958525345623, "no_speech_prob": 3.040903493456426e-06}, {"id": 661, "seek": 411584, "start": 4124.84, "end": 4139.84, "text": " And then yeah 1985 and William Kahan who is I believe at Berkeley played a huge role in kind of pushing for the standardization of wanting different computer manufacturers to be doing the same thing.", "tokens": [400, 550, 1338, 28962, 293, 6740, 591, 21436, 567, 307, 286, 1697, 412, 23684, 3737, 257, 2603, 3090, 294, 733, 295, 7380, 337, 264, 3832, 2144, 295, 7935, 819, 3820, 18455, 281, 312, 884, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.10908183370317731, "compression_ratio": 1.4976958525345623, "no_speech_prob": 3.040903493456426e-06}, {"id": 662, "seek": 413984, "start": 4139.84, "end": 4150.84, "text": " And then just a real quick. So I think with computers you know kind of zeros and ones radix having base two seems to make a lot of sense.", "tokens": [400, 550, 445, 257, 957, 1702, 13, 407, 286, 519, 365, 10807, 291, 458, 733, 295, 35193, 293, 2306, 2843, 970, 1419, 3096, 732, 2544, 281, 652, 257, 688, 295, 2020, 13], "temperature": 0.0, "avg_logprob": -0.2471265471383427, "compression_ratio": 1.5367965367965368, "no_speech_prob": 0.00012335501378402114}, {"id": 663, "seek": 413984, "start": 4150.84, "end": 4155.84, "text": " Apparently the Russians were using radix three for a while and there are some benefits to that.", "tokens": [16755, 264, 20605, 645, 1228, 2843, 970, 1045, 337, 257, 1339, 293, 456, 366, 512, 5311, 281, 300, 13], "temperature": 0.0, "avg_logprob": -0.2471265471383427, "compression_ratio": 1.5367965367965368, "no_speech_prob": 0.00012335501378402114}, {"id": 664, "seek": 413984, "start": 4155.84, "end": 4160.84, "text": " And this was in the 50s. Everyone's actually had a whole series of turnery based computers.", "tokens": [400, 341, 390, 294, 264, 2625, 82, 13, 5198, 311, 767, 632, 257, 1379, 2638, 295, 1261, 2109, 2361, 10807, 13], "temperature": 0.0, "avg_logprob": -0.2471265471383427, "compression_ratio": 1.5367965367965368, "no_speech_prob": 0.00012335501378402114}, {"id": 665, "seek": 413984, "start": 4160.84, "end": 4166.84, "text": " So that was a hardware level.", "tokens": [407, 300, 390, 257, 8837, 1496, 13], "temperature": 0.0, "avg_logprob": -0.2471265471383427, "compression_ratio": 1.5367965367965368, "no_speech_prob": 0.00012335501378402114}, {"id": 666, "seek": 416684, "start": 4166.84, "end": 4176.84, "text": " Yeah and it was I mean it was neat because it says that this does kind of minimize in some ways like the number of symbols times digits you have to use.", "tokens": [865, 293, 309, 390, 286, 914, 309, 390, 10654, 570, 309, 1619, 300, 341, 775, 733, 295, 17522, 294, 512, 2098, 411, 264, 1230, 295, 16944, 1413, 27011, 291, 362, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.1659075663639949, "compression_ratio": 1.4266666666666667, "no_speech_prob": 5.560917634284124e-05}, {"id": 667, "seek": 416684, "start": 4176.84, "end": 4181.84, "text": " Also rounding gets nicer.", "tokens": [2743, 48237, 2170, 22842, 13], "temperature": 0.0, "avg_logprob": -0.1659075663639949, "compression_ratio": 1.4266666666666667, "no_speech_prob": 5.560917634284124e-05}, {"id": 668, "seek": 416684, "start": 4181.84, "end": 4185.84, "text": " Any questions about floating point.", "tokens": [2639, 1651, 466, 12607, 935, 13], "temperature": 0.0, "avg_logprob": -0.1659075663639949, "compression_ratio": 1.4266666666666667, "no_speech_prob": 5.560917634284124e-05}, {"id": 669, "seek": 418584, "start": 4185.84, "end": 4200.84, "text": " OK so we're still under these up. We're still under the sub point of accuracy right now. But the next thing to think about with accuracy is conditioning and stability.", "tokens": [2264, 370, 321, 434, 920, 833, 613, 493, 13, 492, 434, 920, 833, 264, 1422, 935, 295, 14170, 558, 586, 13, 583, 264, 958, 551, 281, 519, 466, 365, 14170, 307, 21901, 293, 11826, 13], "temperature": 0.0, "avg_logprob": -0.16200681833120492, "compression_ratio": 1.403361344537815, "no_speech_prob": 1.4969704352552071e-05}, {"id": 670, "seek": 420084, "start": 4200.84, "end": 4216.84, "text": " And so since we can't represent numbers exactly on a computer it becomes really important to know how having a small change in your input affects the output because sometimes that's going to happen inevitably with how you're representing your numbers.", "tokens": [400, 370, 1670, 321, 393, 380, 2906, 3547, 2293, 322, 257, 3820, 309, 3643, 534, 1021, 281, 458, 577, 1419, 257, 1359, 1319, 294, 428, 4846, 11807, 264, 5598, 570, 2171, 300, 311, 516, 281, 1051, 28171, 365, 577, 291, 434, 13460, 428, 3547, 13], "temperature": 0.0, "avg_logprob": -0.12375627580236216, "compression_ratio": 1.5078534031413613, "no_speech_prob": 2.684014134501922e-06}, {"id": 671, "seek": 420084, "start": 4216.84, "end": 4223.84, "text": " And so Trevathan had a quote author.", "tokens": [400, 370, 8648, 85, 9390, 632, 257, 6513, 3793, 13], "temperature": 0.0, "avg_logprob": -0.12375627580236216, "compression_ratio": 1.5078534031413613, "no_speech_prob": 2.684014134501922e-06}, {"id": 672, "seek": 422384, "start": 4223.84, "end": 4234.84, "text": " Saying a stable algorithm gives nearly the right answer to nearly the right question. And so that kind of nearly the right question is referring to you can't represent your numbers exactly.", "tokens": [34087, 257, 8351, 9284, 2709, 6217, 264, 558, 1867, 281, 6217, 264, 558, 1168, 13, 400, 370, 300, 733, 295, 6217, 264, 558, 1168, 307, 13761, 281, 291, 393, 380, 2906, 428, 3547, 2293, 13], "temperature": 0.0, "avg_logprob": -0.09203717065235925, "compression_ratio": 1.7439024390243902, "no_speech_prob": 1.0675718158381642e-06}, {"id": 673, "seek": 422384, "start": 4234.84, "end": 4239.84, "text": " And then you want your algorithm to be doing nearly the right thing.", "tokens": [400, 550, 291, 528, 428, 9284, 281, 312, 884, 6217, 264, 558, 551, 13], "temperature": 0.0, "avg_logprob": -0.09203717065235925, "compression_ratio": 1.7439024390243902, "no_speech_prob": 1.0675718158381642e-06}, {"id": 674, "seek": 422384, "start": 4239.84, "end": 4241.84, "text": " Conditioning and stability.", "tokens": [21793, 849, 278, 293, 11826, 13], "temperature": 0.0, "avg_logprob": -0.09203717065235925, "compression_ratio": 1.7439024390243902, "no_speech_prob": 1.0675718158381642e-06}, {"id": 675, "seek": 424184, "start": 4241.84, "end": 4253.84, "text": " And I think many people kind of use them as synonyms. Technically conditioning is referring to the problem itself how it behaves under perturbations which are small changes to input.", "tokens": [400, 286, 519, 867, 561, 733, 295, 764, 552, 382, 5451, 2526, 2592, 13, 42494, 21901, 307, 13761, 281, 264, 1154, 2564, 577, 309, 36896, 833, 40468, 763, 597, 366, 1359, 2962, 281, 4846, 13], "temperature": 0.0, "avg_logprob": -0.06224634987967355, "compression_ratio": 1.5121951219512195, "no_speech_prob": 1.0029853001469746e-06}, {"id": 676, "seek": 424184, "start": 4253.84, "end": 4257.84, "text": " Stability is about the behavior of an algorithm.", "tokens": [745, 2310, 307, 466, 264, 5223, 295, 364, 9284, 13], "temperature": 0.0, "avg_logprob": -0.06224634987967355, "compression_ratio": 1.5121951219512195, "no_speech_prob": 1.0029853001469746e-06}, {"id": 677, "seek": 424184, "start": 4257.84, "end": 4261.84, "text": " And so we'll be talking about it in the context of a few different algorithms.", "tokens": [400, 370, 321, 603, 312, 1417, 466, 309, 294, 264, 4319, 295, 257, 1326, 819, 14642, 13], "temperature": 0.0, "avg_logprob": -0.06224634987967355, "compression_ratio": 1.5121951219512195, "no_speech_prob": 1.0029853001469746e-06}, {"id": 678, "seek": 426184, "start": 4261.84, "end": 4285.84, "text": " And so then a kind of simple example is we look at the matrices A and B. So A is 1,000, 0, 1. B being 1, 1,000, 0.001 and 1. These are very similar matrices right there's only a 0.001 difference in one entry between A and B.", "tokens": [400, 370, 550, 257, 733, 295, 2199, 1365, 307, 321, 574, 412, 264, 32284, 316, 293, 363, 13, 407, 316, 307, 502, 11, 1360, 11, 1958, 11, 502, 13, 363, 885, 502, 11, 502, 11, 1360, 11, 1958, 13, 628, 16, 293, 502, 13, 1981, 366, 588, 2531, 32284, 558, 456, 311, 787, 257, 1958, 13, 628, 16, 2649, 294, 472, 8729, 1296, 316, 293, 363, 13], "temperature": 0.0, "avg_logprob": -0.1896416570099307, "compression_ratio": 1.4451612903225806, "no_speech_prob": 3.46629036585e-07}, {"id": 679, "seek": 428584, "start": 4285.84, "end": 4295.84, "text": " If you calculate. So you would actually kind of hope that these would have similar eigenvalues and they don't.", "tokens": [759, 291, 8873, 13, 407, 291, 576, 767, 733, 295, 1454, 300, 613, 576, 362, 2531, 10446, 46033, 293, 436, 500, 380, 13], "temperature": 0.0, "avg_logprob": -0.10043434743528012, "compression_ratio": 1.4675324675324675, "no_speech_prob": 8.628281733535914e-08}, {"id": 680, "seek": 428584, "start": 4295.84, "end": 4306.84, "text": " And that's not because of how we're calculating them. That's kind of an issue of the problem of finding algorithms.", "tokens": [400, 300, 311, 406, 570, 295, 577, 321, 434, 28258, 552, 13, 663, 311, 733, 295, 364, 2734, 295, 264, 1154, 295, 5006, 14642, 13], "temperature": 0.0, "avg_logprob": -0.10043434743528012, "compression_ratio": 1.4675324675324675, "no_speech_prob": 8.628281733535914e-08}, {"id": 681, "seek": 430684, "start": 4306.84, "end": 4316.84, "text": " I don't know. I'm so happy about highlighting. So here for A the eigenvalues are 1 and 1. It has a kind of multiplicity 2 for the eigenvalue 1.", "tokens": [286, 500, 380, 458, 13, 286, 478, 370, 2055, 466, 26551, 13, 407, 510, 337, 316, 264, 10446, 46033, 366, 502, 293, 502, 13, 467, 575, 257, 733, 295, 17596, 507, 568, 337, 264, 10446, 29155, 502, 13], "temperature": 0.0, "avg_logprob": -0.1648956537246704, "compression_ratio": 1.539906103286385, "no_speech_prob": 4.887925797447679e-07}, {"id": 682, "seek": 430684, "start": 4316.84, "end": 4321.84, "text": " And then for B they're 2 and 0. So those are very different.", "tokens": [400, 550, 337, 363, 436, 434, 568, 293, 1958, 13, 407, 729, 366, 588, 819, 13], "temperature": 0.0, "avg_logprob": -0.1648956537246704, "compression_ratio": 1.539906103286385, "no_speech_prob": 4.887925797447679e-07}, {"id": 683, "seek": 430684, "start": 4321.84, "end": 4323.84, "text": " That's the J.", "tokens": [663, 311, 264, 508, 13], "temperature": 0.0, "avg_logprob": -0.1648956537246704, "compression_ratio": 1.539906103286385, "no_speech_prob": 4.887925797447679e-07}, {"id": 684, "seek": 430684, "start": 4323.84, "end": 4331.84, "text": " And J is for the imaginary term. A lot. We are just we're just going to focus on real numbers in this course.", "tokens": [400, 508, 307, 337, 264, 26164, 1433, 13, 316, 688, 13, 492, 366, 445, 321, 434, 445, 516, 281, 1879, 322, 957, 3547, 294, 341, 1164, 13], "temperature": 0.0, "avg_logprob": -0.1648956537246704, "compression_ratio": 1.539906103286385, "no_speech_prob": 4.887925797447679e-07}, {"id": 685, "seek": 433184, "start": 4331.84, "end": 4344.84, "text": " But a lot of these problems in general can give complex values. And so real valued matrices can have complex valued eigenvalues or eigenvectors.", "tokens": [583, 257, 688, 295, 613, 2740, 294, 2674, 393, 976, 3997, 4190, 13, 400, 370, 957, 22608, 32284, 393, 362, 3997, 22608, 10446, 46033, 420, 10446, 303, 5547, 13], "temperature": 0.0, "avg_logprob": -0.13330670653796586, "compression_ratio": 1.5363128491620113, "no_speech_prob": 1.844686607910262e-06}, {"id": 686, "seek": 433184, "start": 4344.84, "end": 4353.84, "text": " And then I also just wanted to highlight because I think this command is so useful. NP dot set print options suppress equals true.", "tokens": [400, 550, 286, 611, 445, 1415, 281, 5078, 570, 286, 519, 341, 5622, 307, 370, 4420, 13, 38611, 5893, 992, 4482, 3956, 26835, 6915, 2074, 13], "temperature": 0.0, "avg_logprob": -0.13330670653796586, "compression_ratio": 1.5363128491620113, "no_speech_prob": 1.844686607910262e-06}, {"id": 687, "seek": 435384, "start": 4353.84, "end": 4364.84, "text": " Otherwise, what happens is and you've probably seen this you get like zero written out with like 15 digits and scientific notation and just zero zero zero zero.", "tokens": [10328, 11, 437, 2314, 307, 293, 291, 600, 1391, 1612, 341, 291, 483, 411, 4018, 3720, 484, 365, 411, 2119, 27011, 293, 8134, 24657, 293, 445, 4018, 4018, 4018, 4018, 13], "temperature": 0.0, "avg_logprob": -0.16727444619843454, "compression_ratio": 1.5025641025641026, "no_speech_prob": 2.260122755615157e-06}, {"id": 688, "seek": 435384, "start": 4364.84, "end": 4373.84, "text": " So I suppress equals true turns that off and makes make sure zeros just show up is zero.", "tokens": [407, 286, 26835, 6915, 2074, 4523, 300, 766, 293, 1669, 652, 988, 35193, 445, 855, 493, 307, 4018, 13], "temperature": 0.0, "avg_logprob": -0.16727444619843454, "compression_ratio": 1.5025641025641026, "no_speech_prob": 2.260122755615157e-06}, {"id": 689, "seek": 435384, "start": 4373.84, "end": 4379.84, "text": " Any questions about the eigenvalue example?", "tokens": [2639, 1651, 466, 264, 10446, 29155, 1365, 30], "temperature": 0.0, "avg_logprob": -0.16727444619843454, "compression_ratio": 1.5025641025641026, "no_speech_prob": 2.260122755615157e-06}, {"id": 690, "seek": 437984, "start": 4379.84, "end": 4398.84, "text": " And so that is something kind of to keep in mind kind of things you'll see that relate to the math because this is something even if you weren't using a computer and you solved for the eigenvalues by hand, you would still get these different answers for what are fairly similar inputs.", "tokens": [400, 370, 300, 307, 746, 733, 295, 281, 1066, 294, 1575, 733, 295, 721, 291, 603, 536, 300, 10961, 281, 264, 5221, 570, 341, 307, 746, 754, 498, 291, 4999, 380, 1228, 257, 3820, 293, 291, 13041, 337, 264, 10446, 46033, 538, 1011, 11, 291, 576, 920, 483, 613, 819, 6338, 337, 437, 366, 6457, 2531, 15743, 13], "temperature": 0.0, "avg_logprob": -0.08068203156994234, "compression_ratio": 1.5833333333333333, "no_speech_prob": 6.539913101732964e-06}, {"id": 691, "seek": 439884, "start": 4398.84, "end": 4417.84, "text": " And then just looking ahead, this will come up again when we talk about classic versus modified Graham Schmidt, which are methods for the QR factorization also with Graham Schmidt versus householder and conditioning a system of equations.", "tokens": [400, 550, 445, 1237, 2286, 11, 341, 486, 808, 493, 797, 562, 321, 751, 466, 7230, 5717, 15873, 22691, 42621, 11, 597, 366, 7150, 337, 264, 32784, 5952, 2144, 611, 365, 22691, 42621, 5717, 9888, 260, 293, 21901, 257, 1185, 295, 11787, 13], "temperature": 0.0, "avg_logprob": -0.12752282619476318, "compression_ratio": 1.5643564356435644, "no_speech_prob": 5.714744588658505e-07}, {"id": 692, "seek": 439884, "start": 4417.84, "end": 4425.84, "text": " And then another area to kind of think about with accuracy is approximations.", "tokens": [400, 550, 1071, 1859, 281, 733, 295, 519, 466, 365, 14170, 307, 8542, 763, 13], "temperature": 0.0, "avg_logprob": -0.12752282619476318, "compression_ratio": 1.5643564356435644, "no_speech_prob": 5.714744588658505e-07}, {"id": 693, "seek": 442584, "start": 4425.84, "end": 4441.84, "text": " It's actually pretty rare that we need to do highly accurate matrix computations at scale, particularly if you are doing machine learning, often being slightly less accurate is a form of regularization that can help you prevent overfitting.", "tokens": [467, 311, 767, 1238, 5892, 300, 321, 643, 281, 360, 5405, 8559, 8141, 2807, 763, 412, 4373, 11, 4098, 498, 291, 366, 884, 3479, 2539, 11, 2049, 885, 4748, 1570, 8559, 307, 257, 1254, 295, 3890, 2144, 300, 393, 854, 291, 4871, 670, 69, 2414, 13], "temperature": 0.0, "avg_logprob": -0.03856567859649658, "compression_ratio": 1.4545454545454546, "no_speech_prob": 2.902145297412062e-06}, {"id": 694, "seek": 444184, "start": 4441.84, "end": 4456.84, "text": " And if you are willing to accept some decrease in accuracy, you can often increase your speed by orders of magnitude, which could let you calculate an answer several times and kind of regain some accuracy with that approach.", "tokens": [400, 498, 291, 366, 4950, 281, 3241, 512, 11514, 294, 14170, 11, 291, 393, 2049, 3488, 428, 3073, 538, 9470, 295, 15668, 11, 597, 727, 718, 291, 8873, 364, 1867, 2940, 1413, 293, 733, 295, 35336, 512, 14170, 365, 300, 3109, 13], "temperature": 0.0, "avg_logprob": -0.04451289384261421, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.026017000389402e-06}, {"id": 695, "seek": 445684, "start": 4456.84, "end": 4475.84, "text": " And then I guess the issue that I didn't write down here, but to think about is also the quality of your data. And kind of if you're aware that your data may not be super precise, it's then bizarre to spend a lot of time trying to get the kind of most accurate answer possible when you know that your data wasn't even collected in the most precise way.", "tokens": [400, 550, 286, 2041, 264, 2734, 300, 286, 994, 380, 2464, 760, 510, 11, 457, 281, 519, 466, 307, 611, 264, 3125, 295, 428, 1412, 13, 400, 733, 295, 498, 291, 434, 3650, 300, 428, 1412, 815, 406, 312, 1687, 13600, 11, 309, 311, 550, 18265, 281, 3496, 257, 688, 295, 565, 1382, 281, 483, 264, 733, 295, 881, 8559, 1867, 1944, 562, 291, 458, 300, 428, 1412, 2067, 380, 754, 11087, 294, 264, 881, 13600, 636, 13], "temperature": 0.0, "avg_logprob": -0.12042535916723386, "compression_ratio": 1.7160493827160495, "no_speech_prob": 5.01432987221051e-06}, {"id": 696, "seek": 445684, "start": 4475.84, "end": 4484.84, "text": " And I think this happens really a lot in the kind of tech world.", "tokens": [400, 286, 519, 341, 2314, 534, 257, 688, 294, 264, 733, 295, 7553, 1002, 13], "temperature": 0.0, "avg_logprob": -0.12042535916723386, "compression_ratio": 1.7160493827160495, "no_speech_prob": 5.01432987221051e-06}, {"id": 697, "seek": 448484, "start": 4484.84, "end": 4496.84, "text": " And then a kind of popular example. So this idea of kind of inserting randomization or approximation into algorithms is very powerful.", "tokens": [400, 550, 257, 733, 295, 3743, 1365, 13, 407, 341, 1558, 295, 733, 295, 46567, 4974, 2144, 420, 28023, 666, 14642, 307, 588, 4005, 13], "temperature": 0.0, "avg_logprob": -0.10617421885005764, "compression_ratio": 1.5271739130434783, "no_speech_prob": 1.7879077631732798e-06}, {"id": 698, "seek": 448484, "start": 4496.84, "end": 4507.84, "text": " And a really kind of popular example is a Bloom filter. And that's something that allows you to search for set membership with 1% false positives.", "tokens": [400, 257, 534, 733, 295, 3743, 1365, 307, 257, 25927, 6608, 13, 400, 300, 311, 746, 300, 4045, 291, 281, 3164, 337, 992, 16560, 365, 502, 4, 7908, 35127, 13], "temperature": 0.0, "avg_logprob": -0.10617421885005764, "compression_ratio": 1.5271739130434783, "no_speech_prob": 1.7879077631732798e-06}, {"id": 699, "seek": 450784, "start": 4507.84, "end": 4517.84, "text": " If you were using that uses less than 10 bits per element, the kind of general idea is with a Bloom filter, if it tells you no, it's definitely no, like you know that's correct.", "tokens": [759, 291, 645, 1228, 300, 4960, 1570, 813, 1266, 9239, 680, 4478, 11, 264, 733, 295, 2674, 1558, 307, 365, 257, 25927, 6608, 11, 498, 309, 5112, 291, 572, 11, 309, 311, 2138, 572, 11, 411, 291, 458, 300, 311, 3006, 13], "temperature": 0.0, "avg_logprob": -0.11095225703608882, "compression_ratio": 1.71484375, "no_speech_prob": 2.026005859079305e-06}, {"id": 700, "seek": 450784, "start": 4517.84, "end": 4526.84, "text": " If it tells you yes, it's probably right. There could be some error there. And so this is a tweet joke about it.", "tokens": [759, 309, 5112, 291, 2086, 11, 309, 311, 1391, 558, 13, 821, 727, 312, 512, 6713, 456, 13, 400, 370, 341, 307, 257, 15258, 7647, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.11095225703608882, "compression_ratio": 1.71484375, "no_speech_prob": 2.026005859079305e-06}, {"id": 701, "seek": 450784, "start": 4526.84, "end": 4536.84, "text": " Would you like to learn more about Bloom filters? No, or probably because you can never get a definite yes with that, but you can get a definite no.", "tokens": [6068, 291, 411, 281, 1466, 544, 466, 25927, 15995, 30, 883, 11, 420, 1391, 570, 291, 393, 1128, 483, 257, 25131, 2086, 365, 300, 11, 457, 291, 393, 483, 257, 25131, 572, 13], "temperature": 0.0, "avg_logprob": -0.11095225703608882, "compression_ratio": 1.71484375, "no_speech_prob": 2.026005859079305e-06}, {"id": 702, "seek": 453684, "start": 4536.84, "end": 4547.84, "text": " And then a kind of a place that they're used is looking for kind of if you want a web browser wants to block pages with viruses, it could use a Bloom filter.", "tokens": [400, 550, 257, 733, 295, 257, 1081, 300, 436, 434, 1143, 307, 1237, 337, 733, 295, 498, 291, 528, 257, 3670, 11185, 2738, 281, 3461, 7183, 365, 21785, 11, 309, 727, 764, 257, 25927, 6608, 13], "temperature": 0.0, "avg_logprob": -0.08754561871898417, "compression_ratio": 1.6327433628318584, "no_speech_prob": 2.2957738110562786e-06}, {"id": 703, "seek": 453684, "start": 4547.84, "end": 4557.84, "text": " And if it says no, then it lets you view the web page. No problem. If it says maybe, then it can look it up.", "tokens": [400, 498, 309, 1619, 572, 11, 550, 309, 6653, 291, 1910, 264, 3670, 3028, 13, 883, 1154, 13, 759, 309, 1619, 1310, 11, 550, 309, 393, 574, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.08754561871898417, "compression_ratio": 1.6327433628318584, "no_speech_prob": 2.2957738110562786e-06}, {"id": 704, "seek": 453684, "start": 4557.84, "end": 4563.84, "text": " And that takes a little bit longer, but it's only having to do it for a small percentage of the pages.", "tokens": [400, 300, 2516, 257, 707, 857, 2854, 11, 457, 309, 311, 787, 1419, 281, 360, 309, 337, 257, 1359, 9668, 295, 264, 7183, 13], "temperature": 0.0, "avg_logprob": -0.08754561871898417, "compression_ratio": 1.6327433628318584, "no_speech_prob": 2.2957738110562786e-06}, {"id": 705, "seek": 456384, "start": 4563.84, "end": 4567.84, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.1482134571781865, "compression_ratio": 1.2945205479452055, "no_speech_prob": 7.766328963043634e-06}, {"id": 706, "seek": 456384, "start": 4567.84, "end": 4569.84, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.1482134571781865, "compression_ratio": 1.2945205479452055, "no_speech_prob": 7.766328963043634e-06}, {"id": 707, "seek": 456384, "start": 4569.84, "end": 4577.84, "text": " Oh, and then this is also kind of just for fun, but kind of expensive, expensive errors.", "tokens": [876, 11, 293, 550, 341, 307, 611, 733, 295, 445, 337, 1019, 11, 457, 733, 295, 5124, 11, 5124, 13603, 13], "temperature": 0.0, "avg_logprob": -0.1482134571781865, "compression_ratio": 1.2945205479452055, "no_speech_prob": 7.766328963043634e-06}, {"id": 708, "seek": 456384, "start": 4577.84, "end": 4584.84, "text": " The European Space Agency spent 10 years and $7 billion on the Ariane 5 rocket.", "tokens": [440, 6473, 8705, 21649, 4418, 1266, 924, 293, 1848, 22, 5218, 322, 264, 9433, 1929, 1025, 13012, 13], "temperature": 0.0, "avg_logprob": -0.1482134571781865, "compression_ratio": 1.2945205479452055, "no_speech_prob": 7.766328963043634e-06}, {"id": 709, "seek": 458484, "start": 4584.84, "end": 4594.84, "text": " But it was trying to fit a 64 bit number into a 16 bit space at one place. And so it exploded.", "tokens": [583, 309, 390, 1382, 281, 3318, 257, 12145, 857, 1230, 666, 257, 3165, 857, 1901, 412, 472, 1081, 13, 400, 370, 309, 27049, 13], "temperature": 0.0, "avg_logprob": -0.13266432285308838, "compression_ratio": 1.0930232558139534, "no_speech_prob": 1.3825151654600631e-05}, {"id": 710, "seek": 459484, "start": 4594.84, "end": 4616.84, "text": " Five, four, three, two, one, fire.", "tokens": [9436, 11, 1451, 11, 1045, 11, 732, 11, 472, 11, 2610, 13], "temperature": 0.0, "avg_logprob": -0.40952399373054504, "compression_ratio": 0.8947368421052632, "no_speech_prob": 0.0026119051035493612}, {"id": 711, "seek": 461684, "start": 4616.84, "end": 4627.84, "text": " This happened I think in the 90s.", "tokens": [639, 2011, 286, 519, 294, 264, 4289, 82, 13], "temperature": 0.0, "avg_logprob": -0.4193484657689145, "compression_ratio": 0.8775510204081632, "no_speech_prob": 8.606394112575799e-05}, {"id": 712, "seek": 461684, "start": 4627.84, "end": 4634.84, "text": " 94, yeah.", "tokens": [30849, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.4193484657689145, "compression_ratio": 0.8775510204081632, "no_speech_prob": 8.606394112575799e-05}, {"id": 713, "seek": 463484, "start": 4634.84, "end": 4650.84, "text": " There was also, I can say as this is going off, I didn't include it, but the US had a Patriot missile defense system in the Middle East.", "tokens": [821, 390, 611, 11, 286, 393, 584, 382, 341, 307, 516, 766, 11, 286, 994, 380, 4090, 309, 11, 457, 264, 2546, 632, 257, 31071, 310, 19321, 7654, 1185, 294, 264, 10775, 6747, 13], "temperature": 0.0, "avg_logprob": -0.1716642215334136, "compression_ratio": 1.308139534883721, "no_speech_prob": 0.0004947470733895898}, {"id": 714, "seek": 463484, "start": 4650.84, "end": 4660.84, "text": " 37 seconds into the launch, the onboard computers decided 501 was 90 degrees off course.", "tokens": [13435, 3949, 666, 264, 4025, 11, 264, 24033, 10807, 3047, 2625, 16, 390, 4289, 5310, 766, 1164, 13], "temperature": 0.0, "avg_logprob": -0.1716642215334136, "compression_ratio": 1.308139534883721, "no_speech_prob": 0.0004947470733895898}, {"id": 715, "seek": 466084, "start": 4660.84, "end": 4670.84, "text": " So this stuff can have big implications. But yeah, as I say, a US kind of missile defense system, its clock gradually got more inaccurate.", "tokens": [407, 341, 1507, 393, 362, 955, 16602, 13, 583, 1338, 11, 382, 286, 584, 11, 257, 2546, 733, 295, 19321, 7654, 1185, 11, 1080, 7830, 13145, 658, 544, 46443, 13], "temperature": 0.0, "avg_logprob": -0.15931947043772493, "compression_ratio": 1.5560165975103735, "no_speech_prob": 2.796067565213889e-05}, {"id": 716, "seek": 466084, "start": 4670.84, "end": 4677.84, "text": " I think 28 people were killed by a missile that it failed to recognize because it was like, you have to look it up.", "tokens": [286, 519, 7562, 561, 645, 4652, 538, 257, 19321, 300, 309, 7612, 281, 5521, 570, 309, 390, 411, 11, 291, 362, 281, 574, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.15931947043772493, "compression_ratio": 1.5560165975103735, "no_speech_prob": 2.796067565213889e-05}, {"id": 717, "seek": 466084, "start": 4677.84, "end": 4686.84, "text": " I think the clock was significantly off because it hadn't been reset. Whereas this, yeah, the kind of error accumulated.", "tokens": [286, 519, 264, 7830, 390, 10591, 766, 570, 309, 8782, 380, 668, 14322, 13, 13813, 341, 11, 1338, 11, 264, 733, 295, 6713, 31346, 13], "temperature": 0.0, "avg_logprob": -0.15931947043772493, "compression_ratio": 1.5560165975103735, "no_speech_prob": 2.796067565213889e-05}, {"id": 718, "seek": 468684, "start": 4686.84, "end": 4700.84, "text": " And then another very expensive error is Intel released a chip in 94 that just in certain cases only had like five digits of accuracy.", "tokens": [400, 550, 1071, 588, 5124, 6713, 307, 19762, 4736, 257, 11409, 294, 30849, 300, 445, 294, 1629, 3331, 787, 632, 411, 1732, 27011, 295, 14170, 13], "temperature": 0.0, "avg_logprob": -0.06629663043551975, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.047986971680075e-06}, {"id": 719, "seek": 468684, "start": 4700.84, "end": 4706.84, "text": " And so they ended up having to kind of do a recall on that and it cost them close to half a billion dollars.", "tokens": [400, 370, 436, 4590, 493, 1419, 281, 733, 295, 360, 257, 9901, 322, 300, 293, 309, 2063, 552, 1998, 281, 1922, 257, 5218, 3808, 13], "temperature": 0.0, "avg_logprob": -0.06629663043551975, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.047986971680075e-06}, {"id": 720, "seek": 468684, "start": 4706.84, "end": 4711.84, "text": " So just to highlight that this stuff does have real world implications.", "tokens": [407, 445, 281, 5078, 300, 341, 1507, 775, 362, 957, 1002, 16602, 13], "temperature": 0.0, "avg_logprob": -0.06629663043551975, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.047986971680075e-06}, {"id": 721, "seek": 471184, "start": 4711.84, "end": 4720.84, "text": " I actually remember when that happened and I remember like a lot of the math libraries that were released had to be humbled because they couldn't rely on this thing.", "tokens": [286, 767, 1604, 562, 300, 2011, 293, 286, 1604, 411, 257, 688, 295, 264, 5221, 15148, 300, 645, 4736, 632, 281, 312, 46199, 570, 436, 2809, 380, 10687, 322, 341, 551, 13], "temperature": 0.0, "avg_logprob": -0.37061175321921325, "compression_ratio": 1.5406698564593302, "no_speech_prob": 9.75561561062932e-05}, {"id": 722, "seek": 471184, "start": 4720.84, "end": 4728.76, "text": " So it was probably more than 475 million because I personally was in awe of using the", "tokens": [407, 309, 390, 1391, 544, 813, 1017, 11901, 2459, 570, 286, 5665, 390, 294, 30912, 295, 1228, 264], "temperature": 0.0, "avg_logprob": -0.37061175321921325, "compression_ratio": 1.5406698564593302, "no_speech_prob": 9.75561561062932e-05}, {"id": 723, "seek": 471184, "start": 4728.84, "end": 4738.84, "text": " Wow. Yeah. So that was just the cost to Intel, not to people who, yes.", "tokens": [3153, 13, 865, 13, 407, 300, 390, 445, 264, 2063, 281, 19762, 11, 406, 281, 561, 567, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.37061175321921325, "compression_ratio": 1.5406698564593302, "no_speech_prob": 9.75561561062932e-05}, {"id": 724, "seek": 473884, "start": 4738.84, "end": 4745.84, "text": " Yeah. So that's the that's it for accuracy and all these concepts will kind of return to as the course goes on.", "tokens": [865, 13, 407, 300, 311, 264, 300, 311, 309, 337, 14170, 293, 439, 613, 10392, 486, 733, 295, 2736, 281, 382, 264, 1164, 1709, 322, 13], "temperature": 0.0, "avg_logprob": -0.11694182289971246, "compression_ratio": 1.685823754789272, "no_speech_prob": 2.1906878373556538e-06}, {"id": 725, "seek": 473884, "start": 4745.84, "end": 4751.84, "text": " This is just introducing them. So memory use.", "tokens": [639, 307, 445, 15424, 552, 13, 407, 4675, 764, 13], "temperature": 0.0, "avg_logprob": -0.11694182289971246, "compression_ratio": 1.685823754789272, "no_speech_prob": 2.1906878373556538e-06}, {"id": 726, "seek": 473884, "start": 4751.84, "end": 4756.84, "text": " So we've talked about how numbers are stored now, looking at how matrices are stored.", "tokens": [407, 321, 600, 2825, 466, 577, 3547, 366, 12187, 586, 11, 1237, 412, 577, 32284, 366, 12187, 13], "temperature": 0.0, "avg_logprob": -0.11694182289971246, "compression_ratio": 1.685823754789272, "no_speech_prob": 2.1906878373556538e-06}, {"id": 727, "seek": 473884, "start": 4756.84, "end": 4761.84, "text": " And so a key way to save memory and also computation is not to store all of your matrix.", "tokens": [400, 370, 257, 2141, 636, 281, 3155, 4675, 293, 611, 24903, 307, 406, 281, 3531, 439, 295, 428, 8141, 13], "temperature": 0.0, "avg_logprob": -0.11694182289971246, "compression_ratio": 1.685823754789272, "no_speech_prob": 2.1906878373556538e-06}, {"id": 728, "seek": 473884, "start": 4761.84, "end": 4767.84, "text": " You could just store the non zero elements and then you know anything that you're not storing must be zero.", "tokens": [509, 727, 445, 3531, 264, 2107, 4018, 4959, 293, 550, 291, 458, 1340, 300, 291, 434, 406, 26085, 1633, 312, 4018, 13], "temperature": 0.0, "avg_logprob": -0.11694182289971246, "compression_ratio": 1.685823754789272, "no_speech_prob": 2.1906878373556538e-06}, {"id": 729, "seek": 476784, "start": 4767.84, "end": 4772.84, "text": " This is called sparse storage, well suited to sparse matrices.", "tokens": [639, 307, 1219, 637, 11668, 6725, 11, 731, 24736, 281, 637, 11668, 32284, 13], "temperature": 0.0, "avg_logprob": -0.10649599612337872, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.7158885157186887e-07}, {"id": 730, "seek": 476784, "start": 4772.84, "end": 4783.84, "text": " Here's an example. And these actually show up a lot in problems where you kind of have some sort of structure and maybe things on the diagonal or tri diagonal are non zero.", "tokens": [1692, 311, 364, 1365, 13, 400, 613, 767, 855, 493, 257, 688, 294, 2740, 689, 291, 733, 295, 362, 512, 1333, 295, 3877, 293, 1310, 721, 322, 264, 21539, 420, 1376, 21539, 366, 2107, 4018, 13], "temperature": 0.0, "avg_logprob": -0.10649599612337872, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.7158885157186887e-07}, {"id": 731, "seek": 476784, "start": 4783.84, "end": 4787.84, "text": " But that you have zeros elsewhere.", "tokens": [583, 300, 291, 362, 35193, 14517, 13], "temperature": 0.0, "avg_logprob": -0.10649599612337872, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.7158885157186887e-07}, {"id": 732, "seek": 476784, "start": 4787.84, "end": 4790.84, "text": " This picture is from something called a finite element problem.", "tokens": [639, 3036, 307, 490, 746, 1219, 257, 19362, 4478, 1154, 13], "temperature": 0.0, "avg_logprob": -0.10649599612337872, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.7158885157186887e-07}, {"id": 733, "seek": 476784, "start": 4790.84, "end": 4795.84, "text": " And those show up in engineering. We won't cover them here, but it's also a multi grid problem.", "tokens": [400, 729, 855, 493, 294, 7043, 13, 492, 1582, 380, 2060, 552, 510, 11, 457, 309, 311, 611, 257, 4825, 10748, 1154, 13], "temperature": 0.0, "avg_logprob": -0.10649599612337872, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.7158885157186887e-07}, {"id": 734, "seek": 479584, "start": 4795.84, "end": 4803.84, "text": " Whenever you're kind of having to model like airflow around a plane engine or some nose of a plane,", "tokens": [14159, 291, 434, 733, 295, 1419, 281, 2316, 411, 45291, 926, 257, 5720, 2848, 420, 512, 6690, 295, 257, 5720, 11], "temperature": 0.0, "avg_logprob": -0.1296450255753158, "compression_ratio": 1.6733668341708543, "no_speech_prob": 1.228877636094694e-06}, {"id": 735, "seek": 479584, "start": 4803.84, "end": 4808.84, "text": " you get these matrices with sometimes very pretty patterns of where the non zero elements are.", "tokens": [291, 483, 613, 32284, 365, 2171, 588, 1238, 8294, 295, 689, 264, 2107, 4018, 4959, 366, 13], "temperature": 0.0, "avg_logprob": -0.1296450255753158, "compression_ratio": 1.6733668341708543, "no_speech_prob": 1.228877636094694e-06}, {"id": 736, "seek": 479584, "start": 4808.84, "end": 4815.84, "text": " And so in this picture, this is like a hundred by a hundred matrices and black squares are non zero values.", "tokens": [400, 370, 294, 341, 3036, 11, 341, 307, 411, 257, 3262, 538, 257, 3262, 32284, 293, 2211, 19368, 366, 2107, 4018, 4190, 13], "temperature": 0.0, "avg_logprob": -0.1296450255753158, "compression_ratio": 1.6733668341708543, "no_speech_prob": 1.228877636094694e-06}, {"id": 737, "seek": 479584, "start": 4815.84, "end": 4821.84, "text": " White squares are zero values.", "tokens": [5552, 19368, 366, 4018, 4190, 13], "temperature": 0.0, "avg_logprob": -0.1296450255753158, "compression_ratio": 1.6733668341708543, "no_speech_prob": 1.228877636094694e-06}, {"id": 738, "seek": 482184, "start": 4821.84, "end": 4830.84, "text": " And so we'll come back to this because SciPy in a future lesson will kind of talk about SciPy gives you three different ways to store sparse matrix.", "tokens": [400, 370, 321, 603, 808, 646, 281, 341, 570, 16942, 47, 88, 294, 257, 2027, 6898, 486, 733, 295, 751, 466, 16942, 47, 88, 2709, 291, 1045, 819, 2098, 281, 3531, 637, 11668, 8141, 13], "temperature": 0.0, "avg_logprob": -0.10046100616455078, "compression_ratio": 1.685512367491166, "no_speech_prob": 4.356701083452208e-06}, {"id": 739, "seek": 482184, "start": 4830.84, "end": 4837.84, "text": " So, you know, once you've decided like, OK, I'm not going to have a cell for everything, you do have to kind of talk about like, OK, what are you going to store to keep track of?", "tokens": [407, 11, 291, 458, 11, 1564, 291, 600, 3047, 411, 11, 2264, 11, 286, 478, 406, 516, 281, 362, 257, 2815, 337, 1203, 11, 291, 360, 362, 281, 733, 295, 751, 466, 411, 11, 2264, 11, 437, 366, 291, 516, 281, 3531, 281, 1066, 2837, 295, 30], "temperature": 0.0, "avg_logprob": -0.10046100616455078, "compression_ratio": 1.685512367491166, "no_speech_prob": 4.356701083452208e-06}, {"id": 740, "seek": 482184, "start": 4837.84, "end": 4847.84, "text": " So we'll return to that. And then the opposite of sparse is dense, which is probably kind of what you're most used to with both matrices and storage.", "tokens": [407, 321, 603, 2736, 281, 300, 13, 400, 550, 264, 6182, 295, 637, 11668, 307, 18011, 11, 597, 307, 1391, 733, 295, 437, 291, 434, 881, 1143, 281, 365, 1293, 32284, 293, 6725, 13], "temperature": 0.0, "avg_logprob": -0.10046100616455078, "compression_ratio": 1.685512367491166, "no_speech_prob": 4.356701083452208e-06}, {"id": 741, "seek": 484784, "start": 4847.84, "end": 4860.84, "text": " And then kind of as a rule of thumb, some people say that you can consider a matrix sparse if the number of non zero elements scales with either the number of rows or the number of columns,", "tokens": [400, 550, 733, 295, 382, 257, 4978, 295, 9298, 11, 512, 561, 584, 300, 291, 393, 1949, 257, 8141, 637, 11668, 498, 264, 1230, 295, 2107, 4018, 4959, 17408, 365, 2139, 264, 1230, 295, 13241, 420, 264, 1230, 295, 13766, 11], "temperature": 0.0, "avg_logprob": -0.049591048343761546, "compression_ratio": 1.9634146341463414, "no_speech_prob": 4.63761534774676e-06}, {"id": 742, "seek": 484784, "start": 4860.84, "end": 4871.84, "text": " whereas a dense matrix, the number of non zero elements is scaling with the product of the number of rows and the number of columns.", "tokens": [9735, 257, 18011, 8141, 11, 264, 1230, 295, 2107, 4018, 4959, 307, 21589, 365, 264, 1674, 295, 264, 1230, 295, 13241, 293, 264, 1230, 295, 13766, 13], "temperature": 0.0, "avg_logprob": -0.049591048343761546, "compression_ratio": 1.9634146341463414, "no_speech_prob": 4.63761534774676e-06}, {"id": 743, "seek": 487184, "start": 4871.84, "end": 4878.84, "text": " Any questions about that?", "tokens": [2639, 1651, 466, 300, 30], "temperature": 0.0, "avg_logprob": -0.08064361413319905, "compression_ratio": 1.5056179775280898, "no_speech_prob": 3.392977760086069e-06}, {"id": 744, "seek": 487184, "start": 4878.84, "end": 4884.84, "text": " OK, so speed and speed is another one that has several kind of sub sub points underneath it.", "tokens": [2264, 11, 370, 3073, 293, 3073, 307, 1071, 472, 300, 575, 2940, 733, 295, 1422, 1422, 2793, 7223, 309, 13], "temperature": 0.0, "avg_logprob": -0.08064361413319905, "compression_ratio": 1.5056179775280898, "no_speech_prob": 3.392977760086069e-06}, {"id": 745, "seek": 487184, "start": 4884.84, "end": 4897.84, "text": " And things that affect the speed of your algorithm are the computational complexity, vectorization, scaling to multiple cores and nodes and locality.", "tokens": [400, 721, 300, 3345, 264, 3073, 295, 428, 9284, 366, 264, 28270, 14024, 11, 8062, 2144, 11, 21589, 281, 3866, 24826, 293, 13891, 293, 1628, 1860, 13], "temperature": 0.0, "avg_logprob": -0.08064361413319905, "compression_ratio": 1.5056179775280898, "no_speech_prob": 3.392977760086069e-06}, {"id": 746, "seek": 489784, "start": 4897.84, "end": 4907.84, "text": " We're not going to I'm really going to get into computational complexity and big O notation in here just to check who's familiar with the notation.", "tokens": [492, 434, 406, 516, 281, 286, 478, 534, 516, 281, 483, 666, 28270, 14024, 293, 955, 422, 24657, 294, 510, 445, 281, 1520, 567, 311, 4963, 365, 264, 24657, 13], "temperature": 0.0, "avg_logprob": -0.1668364592272826, "compression_ratio": 1.6558704453441295, "no_speech_prob": 5.173505996936001e-06}, {"id": 747, "seek": 489784, "start": 4907.84, "end": 4911.84, "text": " OK, I've linked to a few resources.", "tokens": [2264, 11, 286, 600, 9408, 281, 257, 1326, 3593, 13], "temperature": 0.0, "avg_logprob": -0.1668364592272826, "compression_ratio": 1.6558704453441295, "no_speech_prob": 5.173505996936001e-06}, {"id": 748, "seek": 489784, "start": 4911.84, "end": 4913.84, "text": " Kind of interview cake has a nice overview.", "tokens": [9242, 295, 4049, 5908, 575, 257, 1481, 12492, 13], "temperature": 0.0, "avg_logprob": -0.1668364592272826, "compression_ratio": 1.6558704453441295, "no_speech_prob": 5.173505996936001e-06}, {"id": 749, "seek": 489784, "start": 4913.84, "end": 4921.84, "text": " And I went through that kind of the start of Code Academy, I think, has a really nice kind of build up of it has you doing starts with simple problems that kind of get more complex.", "tokens": [400, 286, 1437, 807, 300, 733, 295, 264, 722, 295, 15549, 11735, 11, 286, 519, 11, 575, 257, 534, 1481, 733, 295, 1322, 493, 295, 309, 575, 291, 884, 3719, 365, 2199, 2740, 300, 733, 295, 483, 544, 3997, 13], "temperature": 0.0, "avg_logprob": -0.1668364592272826, "compression_ratio": 1.6558704453441295, "no_speech_prob": 5.173505996936001e-06}, {"id": 750, "seek": 492184, "start": 4921.84, "end": 4928.84, "text": " But I think those are kind of useful tools if you do want to review it or learn about it.", "tokens": [583, 286, 519, 729, 366, 733, 295, 4420, 3873, 498, 291, 360, 528, 281, 3131, 309, 420, 1466, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.1661230488827354, "compression_ratio": 1.6297709923664123, "no_speech_prob": 1.4061954061617143e-05}, {"id": 751, "seek": 492184, "start": 4928.84, "end": 4938.84, "text": " And typically mentioning probably every interview you do just about is going to mention computational complexities of this work familiar with even just for that.", "tokens": [400, 5850, 18315, 1391, 633, 4049, 291, 360, 445, 466, 307, 516, 281, 2152, 28270, 48705, 295, 341, 589, 4963, 365, 754, 445, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.1661230488827354, "compression_ratio": 1.6297709923664123, "no_speech_prob": 1.4061954061617143e-05}, {"id": 752, "seek": 492184, "start": 4938.84, "end": 4939.84, "text": " That's super useful. Yeah.", "tokens": [663, 311, 1687, 4420, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.1661230488827354, "compression_ratio": 1.6297709923664123, "no_speech_prob": 1.4061954061617143e-05}, {"id": 753, "seek": 492184, "start": 4939.84, "end": 4945.84, "text": " And this is something that in software engineering definitely comes up in every interview.", "tokens": [400, 341, 307, 746, 300, 294, 4722, 7043, 2138, 1487, 493, 294, 633, 4049, 13], "temperature": 0.0, "avg_logprob": -0.1661230488827354, "compression_ratio": 1.6297709923664123, "no_speech_prob": 1.4061954061617143e-05}, {"id": 754, "seek": 492184, "start": 4945.84, "end": 4949.84, "text": " Data science I would see is more mixed, but will come up.", "tokens": [11888, 3497, 286, 576, 536, 307, 544, 7467, 11, 457, 486, 808, 493, 13], "temperature": 0.0, "avg_logprob": -0.1661230488827354, "compression_ratio": 1.6297709923664123, "no_speech_prob": 1.4061954061617143e-05}, {"id": 755, "seek": 494984, "start": 4949.84, "end": 4958.84, "text": " But like, yeah, like encoding boot camps, people kind of spend the first 80 percent of the course actually learning to build web develop, you know, build web apps and stuff.", "tokens": [583, 411, 11, 1338, 11, 411, 43430, 11450, 16573, 11, 561, 733, 295, 3496, 264, 700, 4688, 3043, 295, 264, 1164, 767, 2539, 281, 1322, 3670, 1499, 11, 291, 458, 11, 1322, 3670, 7733, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.10162513110102439, "compression_ratio": 1.6825396825396826, "no_speech_prob": 7.526762601628434e-06}, {"id": 756, "seek": 494984, "start": 4958.84, "end": 4964.84, "text": " And then at the end, it's like just study the theory of computational complexity, because that's what you'll see on interviews.", "tokens": [400, 550, 412, 264, 917, 11, 309, 311, 411, 445, 2979, 264, 5261, 295, 28270, 14024, 11, 570, 300, 311, 437, 291, 603, 536, 322, 12318, 13], "temperature": 0.0, "avg_logprob": -0.10162513110102439, "compression_ratio": 1.6825396825396826, "no_speech_prob": 7.526762601628434e-06}, {"id": 757, "seek": 494984, "start": 4964.84, "end": 4972.84, "text": " And that kind of idea behind it is that it's giving you just this approximation that's kind of like an order of magnitude.", "tokens": [400, 300, 733, 295, 1558, 2261, 309, 307, 300, 309, 311, 2902, 291, 445, 341, 28023, 300, 311, 733, 295, 411, 364, 1668, 295, 15668, 13], "temperature": 0.0, "avg_logprob": -0.10162513110102439, "compression_ratio": 1.6825396825396826, "no_speech_prob": 7.526762601628434e-06}, {"id": 758, "seek": 497284, "start": 4972.84, "end": 4981.84, "text": " You're not interested in kind of your constant terms or even your coefficients of how how slow things would be.", "tokens": [509, 434, 406, 3102, 294, 733, 295, 428, 5754, 2115, 420, 754, 428, 31994, 295, 577, 577, 2964, 721, 576, 312, 13], "temperature": 0.0, "avg_logprob": -0.11839648839589711, "compression_ratio": 1.6237113402061856, "no_speech_prob": 5.507029527507257e-06}, {"id": 759, "seek": 497284, "start": 4981.84, "end": 4998.84, "text": " And so if you had an M by N matrix, you might have you might describe an algorithm as being N squared times N if you were having to do that's kind of how many operations you had to do for your algorithm.", "tokens": [400, 370, 498, 291, 632, 364, 376, 538, 426, 8141, 11, 291, 1062, 362, 291, 1062, 6786, 364, 9284, 382, 885, 426, 8889, 1413, 426, 498, 291, 645, 1419, 281, 360, 300, 311, 733, 295, 577, 867, 7705, 291, 632, 281, 360, 337, 428, 9284, 13], "temperature": 0.0, "avg_logprob": -0.11839648839589711, "compression_ratio": 1.6237113402061856, "no_speech_prob": 5.507029527507257e-06}, {"id": 760, "seek": 499884, "start": 4998.84, "end": 5009.84, "text": " Vectorization. So modern CPUs and GPUs can apply the same operation to multiple elements at the same time.", "tokens": [691, 20814, 2144, 13, 407, 4363, 13199, 82, 293, 18407, 82, 393, 3079, 264, 912, 6916, 281, 3866, 4959, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.09394022551449863, "compression_ratio": 1.4821428571428572, "no_speech_prob": 1.2606114069058094e-05}, {"id": 761, "seek": 499884, "start": 5009.84, "end": 5013.84, "text": " This is called SIMD, single instruction, multiple data.", "tokens": [639, 307, 1219, 24738, 35, 11, 2167, 10951, 11, 3866, 1412, 13], "temperature": 0.0, "avg_logprob": -0.09394022551449863, "compression_ratio": 1.4821428571428572, "no_speech_prob": 1.2606114069058094e-05}, {"id": 762, "seek": 499884, "start": 5013.84, "end": 5016.84, "text": " You will not be explicitly writing SIMD code.", "tokens": [509, 486, 406, 312, 20803, 3579, 24738, 35, 3089, 13], "temperature": 0.0, "avg_logprob": -0.09394022551449863, "compression_ratio": 1.4821428571428572, "no_speech_prob": 1.2606114069058094e-05}, {"id": 763, "seek": 499884, "start": 5016.84, "end": 5020.84, "text": " And this is typically done in assembly.", "tokens": [400, 341, 307, 5850, 1096, 294, 12103, 13], "temperature": 0.0, "avg_logprob": -0.09394022551449863, "compression_ratio": 1.4821428571428572, "no_speech_prob": 1.2606114069058094e-05}, {"id": 764, "seek": 499884, "start": 5020.84, "end": 5026.84, "text": " But libraries like NumPy, which we will use a lot, have been vectorized to do that.", "tokens": [583, 15148, 411, 22592, 47, 88, 11, 597, 321, 486, 764, 257, 688, 11, 362, 668, 8062, 1602, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.09394022551449863, "compression_ratio": 1.4821428571428572, "no_speech_prob": 1.2606114069058094e-05}, {"id": 765, "seek": 502684, "start": 5026.84, "end": 5037.84, "text": " And those rely on low level linear algebra libraries such as BLAST and LawPack, which I want to say a little bit about because you'll probably hear about them.", "tokens": [400, 729, 10687, 322, 2295, 1496, 8213, 21989, 15148, 1270, 382, 15132, 20398, 293, 7744, 47, 501, 11, 597, 286, 528, 281, 584, 257, 707, 857, 466, 570, 291, 603, 1391, 1568, 466, 552, 13], "temperature": 0.0, "avg_logprob": -0.12373286485671997, "compression_ratio": 1.4663677130044843, "no_speech_prob": 9.97230745269917e-06}, {"id": 766, "seek": 502684, "start": 5037.84, "end": 5042.84, "text": " And they're they're like everywhere.", "tokens": [400, 436, 434, 436, 434, 411, 5315, 13], "temperature": 0.0, "avg_logprob": -0.12373286485671997, "compression_ratio": 1.4663677130044843, "no_speech_prob": 9.97230745269917e-06}, {"id": 767, "seek": 502684, "start": 5042.84, "end": 5049.84, "text": " So BLAST started out as a Fortran library in 1979.", "tokens": [407, 15132, 20398, 1409, 484, 382, 257, 11002, 4257, 6405, 294, 30595, 13], "temperature": 0.0, "avg_logprob": -0.12373286485671997, "compression_ratio": 1.4663677130044843, "no_speech_prob": 9.97230745269917e-06}, {"id": 768, "seek": 502684, "start": 5049.84, "end": 5054.84, "text": " And it's a specification for low level matrix and vector arithmetic operations.", "tokens": [400, 309, 311, 257, 31256, 337, 2295, 1496, 8141, 293, 8062, 42973, 7705, 13], "temperature": 0.0, "avg_logprob": -0.12373286485671997, "compression_ratio": 1.4663677130044843, "no_speech_prob": 9.97230745269917e-06}, {"id": 769, "seek": 505484, "start": 5054.84, "end": 5063.84, "text": " So kind of very kind of the more basic like you're doing matrix multiplication or matrix vector product.", "tokens": [407, 733, 295, 588, 733, 295, 264, 544, 3875, 411, 291, 434, 884, 8141, 27290, 420, 8141, 8062, 1674, 13], "temperature": 0.0, "avg_logprob": -0.10955843172575298, "compression_ratio": 1.4108108108108108, "no_speech_prob": 3.138032070637564e-06}, {"id": 770, "seek": 505484, "start": 5063.84, "end": 5068.84, "text": " Some examples of it include AMD, Atlas, MKL, and OpenBLAST.", "tokens": [2188, 5110, 295, 309, 4090, 34808, 11, 32485, 11, 30770, 43, 11, 293, 7238, 17624, 20398, 13], "temperature": 0.0, "avg_logprob": -0.10955843172575298, "compression_ratio": 1.4108108108108108, "no_speech_prob": 3.138032070637564e-06}, {"id": 771, "seek": 505484, "start": 5068.84, "end": 5071.84, "text": " So you may hear about these.", "tokens": [407, 291, 815, 1568, 466, 613, 13], "temperature": 0.0, "avg_logprob": -0.10955843172575298, "compression_ratio": 1.4108108108108108, "no_speech_prob": 3.138032070637564e-06}, {"id": 772, "seek": 505484, "start": 5071.84, "end": 5075.84, "text": " Then LawPack uses BLAST.", "tokens": [1396, 7744, 47, 501, 4960, 15132, 20398, 13], "temperature": 0.0, "avg_logprob": -0.10955843172575298, "compression_ratio": 1.4108108108108108, "no_speech_prob": 3.138032070637564e-06}, {"id": 773, "seek": 505484, "start": 5075.84, "end": 5078.84, "text": " And so it's kind of like a layer above it.", "tokens": [400, 370, 309, 311, 733, 295, 411, 257, 4583, 3673, 309, 13], "temperature": 0.0, "avg_logprob": -0.10955843172575298, "compression_ratio": 1.4108108108108108, "no_speech_prob": 3.138032070637564e-06}, {"id": 774, "seek": 507884, "start": 5078.84, "end": 5084.84, "text": " And LawPack is for matrix factorizations, which is what we'll be seeing in this course.", "tokens": [400, 7744, 47, 501, 307, 337, 8141, 5952, 14455, 11, 597, 307, 437, 321, 603, 312, 2577, 294, 341, 1164, 13], "temperature": 0.0, "avg_logprob": -0.12453828274625019, "compression_ratio": 1.478813559322034, "no_speech_prob": 1.034790670928487e-06}, {"id": 775, "seek": 507884, "start": 5084.84, "end": 5091.84, "text": " So LU, Tolesky, QR, SVD.", "tokens": [407, 31851, 11, 314, 7456, 4133, 11, 32784, 11, 31910, 35, 13], "temperature": 0.0, "avg_logprob": -0.12453828274625019, "compression_ratio": 1.478813559322034, "no_speech_prob": 1.034790670928487e-06}, {"id": 776, "seek": 507884, "start": 5091.84, "end": 5098.84, "text": " Yeah, and LawPack arose out of kind of previously there were two separate libraries, ISEPACK and LINPACK.", "tokens": [865, 11, 293, 7744, 47, 501, 37192, 484, 295, 733, 295, 8046, 456, 645, 732, 4994, 15148, 11, 286, 5879, 47, 11595, 293, 19763, 47, 11595, 13], "temperature": 0.0, "avg_logprob": -0.12453828274625019, "compression_ratio": 1.478813559322034, "no_speech_prob": 1.034790670928487e-06}, {"id": 777, "seek": 507884, "start": 5098.84, "end": 5100.84, "text": " ISEPACK was for eigenvalue routines.", "tokens": [286, 5879, 47, 11595, 390, 337, 10446, 29155, 33827, 13], "temperature": 0.0, "avg_logprob": -0.12453828274625019, "compression_ratio": 1.478813559322034, "no_speech_prob": 1.034790670928487e-06}, {"id": 778, "seek": 507884, "start": 5100.84, "end": 5103.84, "text": " LINPACK was for linear equations.", "tokens": [19763, 47, 11595, 390, 337, 8213, 11787, 13], "temperature": 0.0, "avg_logprob": -0.12453828274625019, "compression_ratio": 1.478813559322034, "no_speech_prob": 1.034790670928487e-06}, {"id": 779, "seek": 507884, "start": 5103.84, "end": 5106.84, "text": " And neither of those were really taking advantage of cache.", "tokens": [400, 9662, 295, 729, 645, 534, 1940, 5002, 295, 19459, 13], "temperature": 0.0, "avg_logprob": -0.12453828274625019, "compression_ratio": 1.478813559322034, "no_speech_prob": 1.034790670928487e-06}, {"id": 780, "seek": 510684, "start": 5106.84, "end": 5108.84, "text": " So they were developed in the 70s and 80s.", "tokens": [407, 436, 645, 4743, 294, 264, 5285, 82, 293, 4688, 82, 13], "temperature": 0.0, "avg_logprob": -0.06887658878608986, "compression_ratio": 1.676595744680851, "no_speech_prob": 3.041412810489419e-06}, {"id": 781, "seek": 510684, "start": 5108.84, "end": 5113.84, "text": " And I think LawPack came out in the early 90s to kind of take advantage of cache and modern systems.", "tokens": [400, 286, 519, 7744, 47, 501, 1361, 484, 294, 264, 2440, 4289, 82, 281, 733, 295, 747, 5002, 295, 19459, 293, 4363, 3652, 13], "temperature": 0.0, "avg_logprob": -0.06887658878608986, "compression_ratio": 1.676595744680851, "no_speech_prob": 3.041412810489419e-06}, {"id": 782, "seek": 510684, "start": 5113.84, "end": 5120.84, "text": " And you'll see like if you're reading the SciPy source code, at many points you'll see it calling LawPack routines.", "tokens": [400, 291, 603, 536, 411, 498, 291, 434, 3760, 264, 16942, 47, 88, 4009, 3089, 11, 412, 867, 2793, 291, 603, 536, 309, 5141, 7744, 47, 501, 33827, 13], "temperature": 0.0, "avg_logprob": -0.06887658878608986, "compression_ratio": 1.676595744680851, "no_speech_prob": 3.041412810489419e-06}, {"id": 783, "seek": 510684, "start": 5120.84, "end": 5127.84, "text": " And so there are points where if you want it to go in depth, you can kind of look at that at the LawPack documentation to kind of see,", "tokens": [400, 370, 456, 366, 2793, 689, 498, 291, 528, 309, 281, 352, 294, 7161, 11, 291, 393, 733, 295, 574, 412, 300, 412, 264, 7744, 47, 501, 14333, 281, 733, 295, 536, 11], "temperature": 0.0, "avg_logprob": -0.06887658878608986, "compression_ratio": 1.676595744680851, "no_speech_prob": 3.041412810489419e-06}, {"id": 784, "seek": 512784, "start": 5127.84, "end": 5138.84, "text": " OK, this is what is happening when SciPy calls this LawPack routine.", "tokens": [2264, 11, 341, 307, 437, 307, 2737, 562, 16942, 47, 88, 5498, 341, 7744, 47, 501, 9927, 13], "temperature": 0.0, "avg_logprob": -0.0655244926908123, "compression_ratio": 1.4488636363636365, "no_speech_prob": 3.446468781476142e-06}, {"id": 785, "seek": 512784, "start": 5138.84, "end": 5144.84, "text": " Well, and then the next concept is locality.", "tokens": [1042, 11, 293, 550, 264, 958, 3410, 307, 1628, 1860, 13], "temperature": 0.0, "avg_logprob": -0.0655244926908123, "compression_ratio": 1.4488636363636365, "no_speech_prob": 3.446468781476142e-06}, {"id": 786, "seek": 512784, "start": 5144.84, "end": 5155.84, "text": " And so a lot of the kind of slowness from computers nowadays comes from when they're having to move data around from one location to another.", "tokens": [400, 370, 257, 688, 295, 264, 733, 295, 1061, 648, 442, 490, 10807, 13434, 1487, 490, 562, 436, 434, 1419, 281, 1286, 1412, 926, 490, 472, 4914, 281, 1071, 13], "temperature": 0.0, "avg_logprob": -0.0655244926908123, "compression_ratio": 1.4488636363636365, "no_speech_prob": 3.446468781476142e-06}, {"id": 787, "seek": 515584, "start": 5155.84, "end": 5162.84, "text": " And slower ways to access data, such as getting something from the Internet, can be up to a billion times slower than faster ways,", "tokens": [400, 14009, 2098, 281, 2105, 1412, 11, 1270, 382, 1242, 746, 490, 264, 7703, 11, 393, 312, 493, 281, 257, 5218, 1413, 14009, 813, 4663, 2098, 11], "temperature": 0.0, "avg_logprob": -0.06372191565377372, "compression_ratio": 1.7842323651452283, "no_speech_prob": 1.5934565453790128e-05}, {"id": 788, "seek": 515584, "start": 5162.84, "end": 5165.84, "text": " such as the register, which is basically the fastest memory.", "tokens": [1270, 382, 264, 7280, 11, 597, 307, 1936, 264, 14573, 4675, 13], "temperature": 0.0, "avg_logprob": -0.06372191565377372, "compression_ratio": 1.7842323651452283, "no_speech_prob": 1.5934565453790128e-05}, {"id": 789, "seek": 515584, "start": 5165.84, "end": 5170.84, "text": " And it's important to remember that basically the faster memory is the less you have of it.", "tokens": [400, 309, 311, 1021, 281, 1604, 300, 1936, 264, 4663, 4675, 307, 264, 1570, 291, 362, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.06372191565377372, "compression_ratio": 1.7842323651452283, "no_speech_prob": 1.5934565453790128e-05}, {"id": 790, "seek": 515584, "start": 5170.84, "end": 5177.84, "text": " And so your fastest types of memory are much more limited in space.", "tokens": [400, 370, 428, 14573, 3467, 295, 4675, 366, 709, 544, 5567, 294, 1901, 13], "temperature": 0.0, "avg_logprob": -0.06372191565377372, "compression_ratio": 1.7842323651452283, "no_speech_prob": 1.5934565453790128e-05}, {"id": 791, "seek": 515584, "start": 5177.84, "end": 5181.84, "text": " And so once you have data in fast storage, it would be great to, I don't know,", "tokens": [400, 370, 1564, 291, 362, 1412, 294, 2370, 6725, 11, 309, 576, 312, 869, 281, 11, 286, 500, 380, 458, 11], "temperature": 0.0, "avg_logprob": -0.06372191565377372, "compression_ratio": 1.7842323651452283, "no_speech_prob": 1.5934565453790128e-05}, {"id": 792, "seek": 518184, "start": 5181.84, "end": 5185.84, "text": " if you're going to have to do three computations with that data to do all of them while it's in fast storage,", "tokens": [498, 291, 434, 516, 281, 362, 281, 360, 1045, 2807, 763, 365, 300, 1412, 281, 360, 439, 295, 552, 1339, 309, 311, 294, 2370, 6725, 11], "temperature": 0.0, "avg_logprob": -0.06515388296108053, "compression_ratio": 1.9107981220657277, "no_speech_prob": 3.668624913188978e-06}, {"id": 793, "seek": 518184, "start": 5185.84, "end": 5191.84, "text": " as opposed to like putting it back in slow storage, retrieving it, doing your second computation,", "tokens": [382, 8851, 281, 411, 3372, 309, 646, 294, 2964, 6725, 11, 19817, 798, 309, 11, 884, 428, 1150, 24903, 11], "temperature": 0.0, "avg_logprob": -0.06515388296108053, "compression_ratio": 1.9107981220657277, "no_speech_prob": 3.668624913188978e-06}, {"id": 794, "seek": 518184, "start": 5191.84, "end": 5196.84, "text": " putting it back in slow storage, doing something else and then retrieving it for your third computation,", "tokens": [3372, 309, 646, 294, 2964, 6725, 11, 884, 746, 1646, 293, 550, 19817, 798, 309, 337, 428, 2636, 24903, 11], "temperature": 0.0, "avg_logprob": -0.06515388296108053, "compression_ratio": 1.9107981220657277, "no_speech_prob": 3.668624913188978e-06}, {"id": 795, "seek": 518184, "start": 5196.84, "end": 5199.84, "text": " because it's that having to retrieve it that's slow.", "tokens": [570, 309, 311, 300, 1419, 281, 30254, 309, 300, 311, 2964, 13], "temperature": 0.0, "avg_logprob": -0.06515388296108053, "compression_ratio": 1.9107981220657277, "no_speech_prob": 3.668624913188978e-06}, {"id": 796, "seek": 518184, "start": 5199.84, "end": 5201.84, "text": " And so you really want to minimize those.", "tokens": [400, 370, 291, 534, 528, 281, 17522, 729, 13], "temperature": 0.0, "avg_logprob": -0.06515388296108053, "compression_ratio": 1.9107981220657277, "no_speech_prob": 3.668624913188978e-06}, {"id": 797, "seek": 520184, "start": 5201.84, "end": 5213.84, "text": " And so kind of ways that you can group together, you know, times that you're going to use a particular piece of data are really helpful.", "tokens": [400, 370, 733, 295, 2098, 300, 291, 393, 1594, 1214, 11, 291, 458, 11, 1413, 300, 291, 434, 516, 281, 764, 257, 1729, 2522, 295, 1412, 366, 534, 4961, 13], "temperature": 0.0, "avg_logprob": -0.0821126924044844, "compression_ratio": 1.4948453608247423, "no_speech_prob": 5.043405622018327e-07}, {"id": 798, "seek": 520184, "start": 5213.84, "end": 5218.84, "text": " And so kind of issues in that category are known as locality.", "tokens": [400, 370, 733, 295, 2663, 294, 300, 7719, 366, 2570, 382, 1628, 1860, 13], "temperature": 0.0, "avg_logprob": -0.0821126924044844, "compression_ratio": 1.4948453608247423, "no_speech_prob": 5.043405622018327e-07}, {"id": 799, "seek": 520184, "start": 5218.84, "end": 5226.84, "text": " This is so Jeff Dean of Google gave a presentation on numbers every programmer should know.", "tokens": [639, 307, 370, 7506, 13324, 295, 3329, 2729, 257, 5860, 322, 3547, 633, 32116, 820, 458, 13], "temperature": 0.0, "avg_logprob": -0.0821126924044844, "compression_ratio": 1.4948453608247423, "no_speech_prob": 5.043405622018327e-07}, {"id": 800, "seek": 522684, "start": 5226.84, "end": 5235.84, "text": " And these versions are from and a lot of people still so it's been years, a lot of people still share the slideshow.", "tokens": [400, 613, 9606, 366, 490, 293, 257, 688, 295, 561, 920, 370, 309, 311, 668, 924, 11, 257, 688, 295, 561, 920, 2073, 264, 9788, 4286, 13], "temperature": 0.0, "avg_logprob": -0.13329450583752292, "compression_ratio": 1.6443298969072164, "no_speech_prob": 4.029313913633814e-06}, {"id": 801, "seek": 522684, "start": 5235.84, "end": 5237.84, "text": " There's an updated version.", "tokens": [821, 311, 364, 10588, 3037, 13], "temperature": 0.0, "avg_logprob": -0.13329450583752292, "compression_ratio": 1.6443298969072164, "no_speech_prob": 4.029313913633814e-06}, {"id": 802, "seek": 522684, "start": 5237.84, "end": 5240.84, "text": " I would say actually, let me open this because it's kind of neat.", "tokens": [286, 576, 584, 767, 11, 718, 385, 1269, 341, 570, 309, 311, 733, 295, 10654, 13], "temperature": 0.0, "avg_logprob": -0.13329450583752292, "compression_ratio": 1.6443298969072164, "no_speech_prob": 4.029313913633814e-06}, {"id": 803, "seek": 522684, "start": 5240.84, "end": 5250.84, "text": " The updated version has like a slider so you can even look at like what the numbers were in different years.", "tokens": [440, 10588, 3037, 575, 411, 257, 26046, 370, 291, 393, 754, 574, 412, 411, 437, 264, 3547, 645, 294, 819, 924, 13], "temperature": 0.0, "avg_logprob": -0.13329450583752292, "compression_ratio": 1.6443298969072164, "no_speech_prob": 4.029313913633814e-06}, {"id": 804, "seek": 525084, "start": 5250.84, "end": 5261.84, "text": " So the thing to kind of look at is that an L1 cache reference, one nanosecond, that's kind of the fastest you can do.", "tokens": [407, 264, 551, 281, 733, 295, 574, 412, 307, 300, 364, 441, 16, 19459, 6408, 11, 472, 14067, 541, 18882, 11, 300, 311, 733, 295, 264, 14573, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.1376619993471632, "compression_ratio": 1.6930232558139535, "no_speech_prob": 1.4822993534835405e-06}, {"id": 805, "seek": 525084, "start": 5261.84, "end": 5267.84, "text": " Main memory reference, and this is also kind of RAM, would be 100 nanoseconds.", "tokens": [12383, 4675, 6408, 11, 293, 341, 307, 611, 733, 295, 14561, 11, 576, 312, 2319, 14067, 541, 28750, 13], "temperature": 0.0, "avg_logprob": -0.1376619993471632, "compression_ratio": 1.6930232558139535, "no_speech_prob": 1.4822993534835405e-06}, {"id": 806, "seek": 525084, "start": 5267.84, "end": 5271.84, "text": " And here, I don't know if you can read this from there, they're switching colors.", "tokens": [400, 510, 11, 286, 500, 380, 458, 498, 291, 393, 1401, 341, 490, 456, 11, 436, 434, 16493, 4577, 13], "temperature": 0.0, "avg_logprob": -0.1376619993471632, "compression_ratio": 1.6930232558139535, "no_speech_prob": 1.4822993534835405e-06}, {"id": 807, "seek": 525084, "start": 5271.84, "end": 5278.84, "text": " So they're kind of saying 100 nanoseconds, you know, 100 black boxes is one blue box.", "tokens": [407, 436, 434, 733, 295, 1566, 2319, 14067, 541, 28750, 11, 291, 458, 11, 2319, 2211, 9002, 307, 472, 3344, 2424, 13], "temperature": 0.0, "avg_logprob": -0.1376619993471632, "compression_ratio": 1.6930232558139535, "no_speech_prob": 1.4822993534835405e-06}, {"id": 808, "seek": 527884, "start": 5278.84, "end": 5281.84, "text": " And what's going on with the colors in this picture?", "tokens": [400, 437, 311, 516, 322, 365, 264, 4577, 294, 341, 3036, 30], "temperature": 0.0, "avg_logprob": -0.14362675613827175, "compression_ratio": 1.4411764705882353, "no_speech_prob": 6.08337586527341e-07}, {"id": 809, "seek": 527884, "start": 5281.84, "end": 5285.84, "text": " So main memory reference, okay, that's 100 times slower.", "tokens": [407, 2135, 4675, 6408, 11, 1392, 11, 300, 311, 2319, 1413, 14009, 13], "temperature": 0.0, "avg_logprob": -0.14362675613827175, "compression_ratio": 1.4411764705882353, "no_speech_prob": 6.08337586527341e-07}, {"id": 810, "seek": 527884, "start": 5285.84, "end": 5295.84, "text": " And then if you get to disk seek, that's really slow.", "tokens": [400, 550, 498, 291, 483, 281, 12355, 8075, 11, 300, 311, 534, 2964, 13], "temperature": 0.0, "avg_logprob": -0.14362675613827175, "compression_ratio": 1.4411764705882353, "no_speech_prob": 6.08337586527341e-07}, {"id": 811, "seek": 527884, "start": 5295.84, "end": 5298.84, "text": " So that's 3 million nanoseconds.", "tokens": [407, 300, 311, 805, 2459, 14067, 541, 28750, 13], "temperature": 0.0, "avg_logprob": -0.14362675613827175, "compression_ratio": 1.4411764705882353, "no_speech_prob": 6.08337586527341e-07}, {"id": 812, "seek": 527884, "start": 5298.84, "end": 5301.84, "text": " So it's kind of important to keep these in mind.", "tokens": [407, 309, 311, 733, 295, 1021, 281, 1066, 613, 294, 1575, 13], "temperature": 0.0, "avg_logprob": -0.14362675613827175, "compression_ratio": 1.4411764705882353, "no_speech_prob": 6.08337586527341e-07}, {"id": 813, "seek": 530184, "start": 5301.84, "end": 5318.84, "text": " More the idea of kind of the orders of magnitude that you're seeing as opposed to memorizing specific numbers.", "tokens": [5048, 264, 1558, 295, 733, 295, 264, 9470, 295, 15668, 300, 291, 434, 2577, 382, 8851, 281, 10560, 3319, 2685, 3547, 13], "temperature": 0.0, "avg_logprob": -0.09432954991117437, "compression_ratio": 1.3450704225352113, "no_speech_prob": 3.726540853676852e-06}, {"id": 814, "seek": 530184, "start": 5318.84, "end": 5322.84, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.09432954991117437, "compression_ratio": 1.3450704225352113, "no_speech_prob": 3.726540853676852e-06}, {"id": 815, "seek": 530184, "start": 5322.84, "end": 5325.84, "text": " And I definitely encourage you to check out a lot of these links.", "tokens": [400, 286, 2138, 5373, 291, 281, 1520, 484, 257, 688, 295, 613, 6123, 13], "temperature": 0.0, "avg_logprob": -0.09432954991117437, "compression_ratio": 1.3450704225352113, "no_speech_prob": 3.726540853676852e-06}, {"id": 816, "seek": 532584, "start": 5325.84, "end": 5335.84, "text": " I'm now going to show part of this video, and so this video is about a language called Halide, which we will not be using.", "tokens": [286, 478, 586, 516, 281, 855, 644, 295, 341, 960, 11, 293, 370, 341, 960, 307, 466, 257, 2856, 1219, 13896, 482, 11, 597, 321, 486, 406, 312, 1228, 13], "temperature": 0.0, "avg_logprob": -0.07443270784743289, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.264004383003339e-05}, {"id": 817, "seek": 532584, "start": 5335.84, "end": 5344.84, "text": " But it's just a really good illustration of some of the things you would have to think about in kind of thinking about what order to do things in.", "tokens": [583, 309, 311, 445, 257, 534, 665, 22645, 295, 512, 295, 264, 721, 291, 576, 362, 281, 519, 466, 294, 733, 295, 1953, 466, 437, 1668, 281, 360, 721, 294, 13], "temperature": 0.0, "avg_logprob": -0.07443270784743289, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.264004383003339e-05}, {"id": 818, "seek": 532584, "start": 5344.84, "end": 5350.84, "text": " And so in the video, don't worry about just briefly at the beginning, he shows kind of a bunch of code.", "tokens": [400, 370, 294, 264, 960, 11, 500, 380, 3292, 466, 445, 10515, 412, 264, 2863, 11, 415, 3110, 733, 295, 257, 3840, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.07443270784743289, "compression_ratio": 1.6504424778761062, "no_speech_prob": 4.264004383003339e-05}, {"id": 819, "seek": 535084, "start": 5350.84, "end": 5360.84, "text": " There'll be these kind of visualizations, though, with green boxes and green means that you're reading something and red means that you're writing kind of what order things are happening in.", "tokens": [821, 603, 312, 613, 733, 295, 5056, 14455, 11, 1673, 11, 365, 3092, 9002, 293, 3092, 1355, 300, 291, 434, 3760, 746, 293, 2182, 1355, 300, 291, 434, 3579, 733, 295, 437, 1668, 721, 366, 2737, 294, 13], "temperature": 0.0, "avg_logprob": -0.08654361300998265, "compression_ratio": 1.7153558052434457, "no_speech_prob": 9.912469249684364e-05}, {"id": 820, "seek": 535084, "start": 5360.84, "end": 5364.84, "text": " And the problem he's looking at is just the blur of a photo.", "tokens": [400, 264, 1154, 415, 311, 1237, 412, 307, 445, 264, 14257, 295, 257, 5052, 13], "temperature": 0.0, "avg_logprob": -0.08654361300998265, "compression_ratio": 1.7153558052434457, "no_speech_prob": 9.912469249684364e-05}, {"id": 821, "seek": 535084, "start": 5364.84, "end": 5368.84, "text": " So kind of taking a lot of the developers on Halide work at Adobe.", "tokens": [407, 733, 295, 1940, 257, 688, 295, 264, 8849, 322, 13896, 482, 589, 412, 24862, 13], "temperature": 0.0, "avg_logprob": -0.08654361300998265, "compression_ratio": 1.7153558052434457, "no_speech_prob": 9.912469249684364e-05}, {"id": 822, "seek": 535084, "start": 5368.84, "end": 5370.84, "text": " So they do a lot of kind of photo processing.", "tokens": [407, 436, 360, 257, 688, 295, 733, 295, 5052, 9007, 13], "temperature": 0.0, "avg_logprob": -0.08654361300998265, "compression_ratio": 1.7153558052434457, "no_speech_prob": 9.912469249684364e-05}, {"id": 823, "seek": 535084, "start": 5370.84, "end": 5375.84, "text": " But the idea of just you need to read, you know, a few pixels to be able to give the XY blur.", "tokens": [583, 264, 1558, 295, 445, 291, 643, 281, 1401, 11, 291, 458, 11, 257, 1326, 18668, 281, 312, 1075, 281, 976, 264, 48826, 14257, 13], "temperature": 0.0, "avg_logprob": -0.08654361300998265, "compression_ratio": 1.7153558052434457, "no_speech_prob": 9.912469249684364e-05}, {"id": 824, "seek": 537584, "start": 5375.84, "end": 5382.84, "text": " So you're kind of taking this photo and then we want to look at a few pixels around it to get what the blurred version would be.", "tokens": [407, 291, 434, 733, 295, 1940, 341, 5052, 293, 550, 321, 528, 281, 574, 412, 257, 1326, 18668, 926, 309, 281, 483, 437, 264, 43525, 3037, 576, 312, 13], "temperature": 0.0, "avg_logprob": -0.11992592767837944, "compression_ratio": 1.6282527881040891, "no_speech_prob": 2.0145049347775057e-05}, {"id": 825, "seek": 537584, "start": 5382.84, "end": 5384.84, "text": " Oh, yes, this is a convolution.", "tokens": [876, 11, 2086, 11, 341, 307, 257, 45216, 13], "temperature": 0.0, "avg_logprob": -0.11992592767837944, "compression_ratio": 1.6282527881040891, "no_speech_prob": 2.0145049347775057e-05}, {"id": 826, "seek": 537584, "start": 5384.84, "end": 5392.84, "text": " So kind of similar to what we saw before, that idea of kind of sliding a filter.", "tokens": [407, 733, 295, 2531, 281, 437, 321, 1866, 949, 11, 300, 1558, 295, 733, 295, 21169, 257, 6608, 13], "temperature": 0.0, "avg_logprob": -0.11992592767837944, "compression_ratio": 1.6282527881040891, "no_speech_prob": 2.0145049347775057e-05}, {"id": 827, "seek": 537584, "start": 5392.84, "end": 5404.84, "text": " Hi, I'm Andrew Adams, and this video is about Halide, a new language and then a vertical blur, which reads and averages three points from intermediate results, which we store in a temporary image.", "tokens": [2421, 11, 286, 478, 10110, 25214, 11, 293, 341, 960, 307, 466, 13896, 482, 11, 257, 777, 2856, 293, 550, 257, 9429, 14257, 11, 597, 15700, 293, 42257, 1045, 2793, 490, 19376, 3542, 11, 597, 321, 3531, 294, 257, 13413, 3256, 13], "temperature": 0.0, "avg_logprob": -0.11992592767837944, "compression_ratio": 1.6282527881040891, "no_speech_prob": 2.0145049347775057e-05}, {"id": 828, "seek": 540484, "start": 5404.84, "end": 5411.84, "text": " This code takes about 10 milliseconds per megapixel on the quad core x86 that I benchmarked it on.", "tokens": [639, 3089, 2516, 466, 1266, 34184, 680, 34733, 34599, 322, 264, 10787, 4965, 2031, 22193, 300, 286, 18927, 292, 309, 322, 13], "temperature": 0.0, "avg_logprob": -0.13156164260137648, "compression_ratio": 1.5525291828793775, "no_speech_prob": 2.627300455060322e-05}, {"id": 829, "seek": 540484, "start": 5411.84, "end": 5416.84, "text": " But an optimized implementation, do you think I should turn the volume on for the computer?", "tokens": [583, 364, 26941, 11420, 11, 360, 291, 519, 286, 820, 1261, 264, 5523, 322, 337, 264, 3820, 30], "temperature": 0.0, "avg_logprob": -0.13156164260137648, "compression_ratio": 1.5525291828793775, "no_speech_prob": 2.627300455060322e-05}, {"id": 830, "seek": 540484, "start": 5416.84, "end": 5420.84, "text": " This machine is more than 10 times faster.", "tokens": [639, 3479, 307, 544, 813, 1266, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.13156164260137648, "compression_ratio": 1.5525291828793775, "no_speech_prob": 2.627300455060322e-05}, {"id": 831, "seek": 540484, "start": 5420.84, "end": 5422.84, "text": " The code is hideously complex.", "tokens": [440, 3089, 307, 6479, 5098, 3997, 13], "temperature": 0.0, "avg_logprob": -0.13156164260137648, "compression_ratio": 1.5525291828793775, "no_speech_prob": 2.627300455060322e-05}, {"id": 832, "seek": 540484, "start": 5422.84, "end": 5425.84, "text": " All we're trying to do is average together three by three pixels.", "tokens": [1057, 321, 434, 1382, 281, 360, 307, 4274, 1214, 1045, 538, 1045, 18668, 13], "temperature": 0.0, "avg_logprob": -0.13156164260137648, "compression_ratio": 1.5525291828793775, "no_speech_prob": 2.627300455060322e-05}, {"id": 833, "seek": 540484, "start": 5425.84, "end": 5428.84, "text": " But an 11x speed up is too much to ignore.", "tokens": [583, 364, 2975, 87, 3073, 493, 307, 886, 709, 281, 11200, 13], "temperature": 0.0, "avg_logprob": -0.13156164260137648, "compression_ratio": 1.5525291828793775, "no_speech_prob": 2.627300455060322e-05}, {"id": 834, "seek": 540484, "start": 5428.84, "end": 5431.84, "text": " So why is this code fast?", "tokens": [407, 983, 307, 341, 3089, 2370, 30], "temperature": 0.0, "avg_logprob": -0.13156164260137648, "compression_ratio": 1.5525291828793775, "no_speech_prob": 2.627300455060322e-05}, {"id": 835, "seek": 543184, "start": 5431.84, "end": 5437.84, "text": " We've transformed the pipeline to optimize for both parallelism and locality.", "tokens": [492, 600, 16894, 264, 15517, 281, 19719, 337, 1293, 8952, 1434, 293, 1628, 1860, 13], "temperature": 0.0, "avg_logprob": -0.11730655821243136, "compression_ratio": 1.5708812260536398, "no_speech_prob": 1.4063518392504193e-05}, {"id": 836, "seek": 543184, "start": 5437.84, "end": 5445.84, "text": " The parallelism comes from distributing work across threads, and that's what that pragma-OMP parallel four at the top does,", "tokens": [440, 8952, 1434, 1487, 490, 41406, 589, 2108, 19314, 11, 293, 300, 311, 437, 300, 33394, 1696, 12, 5251, 47, 8952, 1451, 412, 264, 1192, 775, 11], "temperature": 0.0, "avg_logprob": -0.11730655821243136, "compression_ratio": 1.5708812260536398, "no_speech_prob": 1.4063518392504193e-05}, {"id": 837, "seek": 543184, "start": 5445.84, "end": 5451.84, "text": " and also from computing in eight wide SIMD chunks on each core's SSE units.", "tokens": [293, 611, 490, 15866, 294, 3180, 4874, 24738, 35, 24004, 322, 1184, 4965, 311, 318, 5879, 6815, 13], "temperature": 0.0, "avg_logprob": -0.11730655821243136, "compression_ratio": 1.5708812260536398, "no_speech_prob": 1.4063518392504193e-05}, {"id": 838, "seek": 543184, "start": 5451.84, "end": 5454.84, "text": " Exposing parallelism, though, is only half the story.", "tokens": [21391, 6110, 8952, 1434, 11, 1673, 11, 307, 787, 1922, 264, 1657, 13], "temperature": 0.0, "avg_logprob": -0.11730655821243136, "compression_ratio": 1.5708812260536398, "no_speech_prob": 1.4063518392504193e-05}, {"id": 839, "seek": 543184, "start": 5454.84, "end": 5459.84, "text": " Just as important and often much harder to think about or express is locality.", "tokens": [1449, 382, 1021, 293, 2049, 709, 6081, 281, 519, 466, 420, 5109, 307, 1628, 1860, 13], "temperature": 0.0, "avg_logprob": -0.11730655821243136, "compression_ratio": 1.5708812260536398, "no_speech_prob": 1.4063518392504193e-05}, {"id": 840, "seek": 545984, "start": 5459.84, "end": 5466.84, "text": " For example, making sure the pixels produced by one stage are still in cache when the next stage reads them.", "tokens": [1171, 1365, 11, 1455, 988, 264, 18668, 7126, 538, 472, 3233, 366, 920, 294, 19459, 562, 264, 958, 3233, 15700, 552, 13], "temperature": 0.0, "avg_logprob": -0.05936819830058533, "compression_ratio": 1.6206896551724137, "no_speech_prob": 2.0784906155313365e-05}, {"id": 841, "seek": 545984, "start": 5466.84, "end": 5475.84, "text": " And without locality optimization, even a really well-parallelized pipeline will probably be limited by the available memory bandwidth.", "tokens": [400, 1553, 1628, 1860, 19618, 11, 754, 257, 534, 731, 12, 2181, 336, 338, 1602, 15517, 486, 1391, 312, 5567, 538, 264, 2435, 4675, 23647, 13], "temperature": 0.0, "avg_logprob": -0.05936819830058533, "compression_ratio": 1.6206896551724137, "no_speech_prob": 2.0784906155313365e-05}, {"id": 842, "seek": 545984, "start": 5475.84, "end": 5483.84, "text": " So here the optimized code improves locality by computing each stage in tiles, interleaving the computation of tiles across stages.", "tokens": [407, 510, 264, 26941, 3089, 24771, 1628, 1860, 538, 15866, 1184, 3233, 294, 21982, 11, 728, 306, 6152, 264, 24903, 295, 21982, 2108, 10232, 13], "temperature": 0.0, "avg_logprob": -0.05936819830058533, "compression_ratio": 1.6206896551724137, "no_speech_prob": 2.0784906155313365e-05}, {"id": 843, "seek": 548384, "start": 5483.84, "end": 5491.84, "text": " So we compute just a single tile of blur in x and then a single tile of blur in y, and then we go back to compute the next tile of blur in x.", "tokens": [407, 321, 14722, 445, 257, 2167, 20590, 295, 14257, 294, 2031, 293, 550, 257, 2167, 20590, 295, 14257, 294, 288, 11, 293, 550, 321, 352, 646, 281, 14722, 264, 958, 20590, 295, 14257, 294, 2031, 13], "temperature": 0.0, "avg_logprob": -0.07431350728516938, "compression_ratio": 1.7740384615384615, "no_speech_prob": 4.5659526222152635e-06}, {"id": 844, "seek": 548384, "start": 5491.84, "end": 5498.84, "text": " So this, hopefully, keeps all that intermediate data in small buffers that never leave cache.", "tokens": [407, 341, 11, 4696, 11, 5965, 439, 300, 19376, 1412, 294, 1359, 9204, 433, 300, 1128, 1856, 19459, 13], "temperature": 0.0, "avg_logprob": -0.07431350728516938, "compression_ratio": 1.7740384615384615, "no_speech_prob": 4.5659526222152635e-06}, {"id": 845, "seek": 548384, "start": 5498.84, "end": 5504.84, "text": " But it complicates the code because it's interleaved the computation of each stage.", "tokens": [583, 309, 16060, 1024, 264, 3089, 570, 309, 311, 728, 306, 12865, 264, 24903, 295, 1184, 3233, 13], "temperature": 0.0, "avg_logprob": -0.07431350728516938, "compression_ratio": 1.7740384615384615, "no_speech_prob": 4.5659526222152635e-06}, {"id": 846, "seek": 548384, "start": 5504.84, "end": 5507.84, "text": " So the execution of the pipeline looks like this.", "tokens": [407, 264, 15058, 295, 264, 15517, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.07431350728516938, "compression_ratio": 1.7740384615384615, "no_speech_prob": 4.5659526222152635e-06}, {"id": 847, "seek": 550784, "start": 5507.84, "end": 5513.84, "text": " The input image is at the top, flowing down through the blur x and blur y stages below.", "tokens": [440, 4846, 3256, 307, 412, 264, 1192, 11, 13974, 760, 807, 264, 14257, 2031, 293, 14257, 288, 10232, 2507, 13], "temperature": 0.0, "avg_logprob": -0.039335467349523784, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.1659445590339601e-05}, {"id": 848, "seek": 550784, "start": 5513.84, "end": 5521.84, "text": " The earlier stages are evaluated over larger buffers because we're computing filters that have a footprint, so we need more inputs than there are outputs.", "tokens": [440, 3071, 10232, 366, 25509, 670, 4833, 9204, 433, 570, 321, 434, 15866, 15995, 300, 362, 257, 24222, 11, 370, 321, 643, 544, 15743, 813, 456, 366, 23930, 13], "temperature": 0.0, "avg_logprob": -0.039335467349523784, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.1659445590339601e-05}, {"id": 849, "seek": 550784, "start": 5521.84, "end": 5531.84, "text": " Each point in blur y, the output stage, depends on three pixels in blur x, which in turn depend on nine pixels total in the input.", "tokens": [6947, 935, 294, 14257, 288, 11, 264, 5598, 3233, 11, 5946, 322, 1045, 18668, 294, 14257, 2031, 11, 597, 294, 1261, 5672, 322, 4949, 18668, 3217, 294, 264, 4846, 13], "temperature": 0.0, "avg_logprob": -0.039335467349523784, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.1659445590339601e-05}, {"id": 850, "seek": 553184, "start": 5531.84, "end": 5542.84, "text": " So the unoptimized version that we looked at first computes every pixel in the first stage, writing them out to memory before computing the next stage, which has to slowly read them back in.", "tokens": [407, 264, 517, 5747, 332, 1602, 3037, 300, 321, 2956, 412, 700, 715, 1819, 633, 19261, 294, 264, 700, 3233, 11, 3579, 552, 484, 281, 4675, 949, 15866, 264, 958, 3233, 11, 597, 575, 281, 5692, 1401, 552, 646, 294, 13], "temperature": 0.0, "avg_logprob": -0.06530150245217715, "compression_ratio": 1.7761194029850746, "no_speech_prob": 9.516176760371309e-06}, {"id": 851, "seek": 553184, "start": 5542.84, "end": 5546.84, "text": " The optimized version interleaves the stages instead.", "tokens": [440, 26941, 3037, 728, 306, 5423, 264, 10232, 2602, 13], "temperature": 0.0, "avg_logprob": -0.06530150245217715, "compression_ratio": 1.7761194029850746, "no_speech_prob": 9.516176760371309e-06}, {"id": 852, "seek": 553184, "start": 5546.84, "end": 5553.84, "text": " To compute a chunk of blur y, we first need the corresponding chunk of blur x, which loads a chunk of the input.", "tokens": [1407, 14722, 257, 16635, 295, 14257, 288, 11, 321, 700, 643, 264, 11760, 16635, 295, 14257, 2031, 11, 597, 12668, 257, 16635, 295, 264, 4846, 13], "temperature": 0.0, "avg_logprob": -0.06530150245217715, "compression_ratio": 1.7761194029850746, "no_speech_prob": 9.516176760371309e-06}, {"id": 853, "seek": 555384, "start": 5553.84, "end": 5561.84, "text": " The blur x stage filters that input, and then blur y immediately consumes it to compute a chunk of the output.", "tokens": [440, 14257, 2031, 3233, 15995, 300, 4846, 11, 293, 550, 14257, 288, 4258, 48823, 309, 281, 14722, 257, 16635, 295, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.04356544358389718, "compression_ratio": 1.9285714285714286, "no_speech_prob": 1.0451468369865324e-05}, {"id": 854, "seek": 555384, "start": 5561.84, "end": 5574.84, "text": " So next we throw away that intermediate data, that chunk of blur x, load the next chunk of the input, compute the next chunk of blur x, followed immediately by that next chunk of blur y.", "tokens": [407, 958, 321, 3507, 1314, 300, 19376, 1412, 11, 300, 16635, 295, 14257, 2031, 11, 3677, 264, 958, 16635, 295, 264, 4846, 11, 14722, 264, 958, 16635, 295, 14257, 2031, 11, 6263, 4258, 538, 300, 958, 16635, 295, 14257, 288, 13], "temperature": 0.0, "avg_logprob": -0.04356544358389718, "compression_ratio": 1.9285714285714286, "no_speech_prob": 1.0451468369865324e-05}, {"id": 855, "seek": 557484, "start": 5574.84, "end": 5584.84, "text": " So we've moved the computation of each chunk of pixels in a consumer stage closer in time to the computation of its inputs.", "tokens": [407, 321, 600, 4259, 264, 24903, 295, 1184, 16635, 295, 18668, 294, 257, 9711, 3233, 4966, 294, 565, 281, 264, 24903, 295, 1080, 15743, 13], "temperature": 0.0, "avg_logprob": -0.04471139217677869, "compression_ratio": 1.6330275229357798, "no_speech_prob": 1.0845128599612508e-06}, {"id": 856, "seek": 557484, "start": 5584.84, "end": 5590.84, "text": " This improves producer-consumer locality by keeping all the intermediate data nearby in local caches.", "tokens": [639, 24771, 12314, 12, 21190, 15583, 1628, 1860, 538, 5145, 439, 264, 19376, 1412, 11184, 294, 2654, 269, 13272, 13], "temperature": 0.0, "avg_logprob": -0.04471139217677869, "compression_ratio": 1.6330275229357798, "no_speech_prob": 1.0845128599612508e-06}, {"id": 857, "seek": 557484, "start": 5590.84, "end": 5598.84, "text": " But it's made optimization a global problem of carefully interleaving the computation and storage down an entire imaging pipeline.", "tokens": [583, 309, 311, 1027, 19618, 257, 4338, 1154, 295, 7500, 728, 306, 6152, 264, 24903, 293, 6725, 760, 364, 2302, 25036, 15517, 13], "temperature": 0.0, "avg_logprob": -0.04471139217677869, "compression_ratio": 1.6330275229357798, "no_speech_prob": 1.0845128599612508e-06}, {"id": 858, "seek": 559884, "start": 5598.84, "end": 5607.84, "text": " You can't address locality just by optimizing stages in isolation or by just tweaking operations in your interloops.", "tokens": [509, 393, 380, 2985, 1628, 1860, 445, 538, 40425, 10232, 294, 16001, 420, 538, 445, 6986, 2456, 7705, 294, 428, 728, 752, 3370, 13], "temperature": 0.0, "avg_logprob": -0.05069742497709608, "compression_ratio": 1.6044776119402986, "no_speech_prob": 7.071855634421809e-06}, {"id": 859, "seek": 559884, "start": 5607.84, "end": 5617.84, "text": " Also, we're making a trade-off here. We're saying that for each chunk of blur y, we should independently compute, consume, and then throw away the required chunk of blur x.", "tokens": [2743, 11, 321, 434, 1455, 257, 4923, 12, 4506, 510, 13, 492, 434, 1566, 300, 337, 1184, 16635, 295, 14257, 288, 11, 321, 820, 21761, 14722, 11, 14732, 11, 293, 550, 3507, 1314, 264, 4739, 16635, 295, 14257, 2031, 13], "temperature": 0.0, "avg_logprob": -0.05069742497709608, "compression_ratio": 1.6044776119402986, "no_speech_prob": 7.071855634421809e-06}, {"id": 860, "seek": 559884, "start": 5617.84, "end": 5625.84, "text": " This means that neighboring chunks, which depend on overlapping pixels from higher up in the pipeline, do redundant work where they overlap.", "tokens": [639, 1355, 300, 31521, 24004, 11, 597, 5672, 322, 33535, 18668, 490, 2946, 493, 294, 264, 15517, 11, 360, 40997, 589, 689, 436, 19959, 13], "temperature": 0.0, "avg_logprob": -0.05069742497709608, "compression_ratio": 1.6044776119402986, "no_speech_prob": 7.071855634421809e-06}, {"id": 861, "seek": 562584, "start": 5625.84, "end": 5636.84, "text": " Now for this pipeline, it made sense to redundantly compute some values in exchange for the increase in locality that we get by never letting the intermediate values move out of cache into main memory.", "tokens": [823, 337, 341, 15517, 11, 309, 1027, 2020, 281, 27830, 3627, 14722, 512, 4190, 294, 7742, 337, 264, 3488, 294, 1628, 1860, 300, 321, 483, 538, 1128, 8295, 264, 19376, 4190, 1286, 484, 295, 19459, 666, 2135, 4675, 13], "temperature": 0.0, "avg_logprob": -0.03398753716065003, "compression_ratio": 1.6608391608391608, "no_speech_prob": 1.593645902175922e-05}, {"id": 862, "seek": 562584, "start": 5636.84, "end": 5639.84, "text": " But this is not always the right choice.", "tokens": [583, 341, 307, 406, 1009, 264, 558, 3922, 13], "temperature": 0.0, "avg_logprob": -0.03398753716065003, "compression_ratio": 1.6608391608391608, "no_speech_prob": 1.593645902175922e-05}, {"id": 863, "seek": 562584, "start": 5639.84, "end": 5644.84, "text": " Let's try to get a full handle on the space of choices we could have made.", "tokens": [961, 311, 853, 281, 483, 257, 1577, 4813, 322, 264, 1901, 295, 7994, 321, 727, 362, 1027, 13], "temperature": 0.0, "avg_logprob": -0.03398753716065003, "compression_ratio": 1.6608391608391608, "no_speech_prob": 1.593645902175922e-05}, {"id": 864, "seek": 562584, "start": 5644.84, "end": 5649.84, "text": " In general, in an imaging pipeline, there are two questions you must answer for each stage.", "tokens": [682, 2674, 11, 294, 364, 25036, 15517, 11, 456, 366, 732, 1651, 291, 1633, 1867, 337, 1184, 3233, 13], "temperature": 0.0, "avg_logprob": -0.03398753716065003, "compression_ratio": 1.6608391608391608, "no_speech_prob": 1.593645902175922e-05}, {"id": 865, "seek": 562584, "start": 5649.84, "end": 5654.84, "text": " The first is, in what order should that stage compute its values?", "tokens": [440, 700, 307, 11, 294, 437, 1668, 820, 300, 3233, 14722, 1080, 4190, 30], "temperature": 0.0, "avg_logprob": -0.03398753716065003, "compression_ratio": 1.6608391608391608, "no_speech_prob": 1.593645902175922e-05}, {"id": 866, "seek": 565484, "start": 5654.84, "end": 5656.84, "text": " Let's look at some choices.", "tokens": [961, 311, 574, 412, 512, 7994, 13], "temperature": 0.0, "avg_logprob": -0.07627834379673004, "compression_ratio": 1.7161572052401746, "no_speech_prob": 1.6442418200313114e-05}, {"id": 867, "seek": 565484, "start": 5656.84, "end": 5660.84, "text": " The most common way to traverse a region is in scanline order.", "tokens": [440, 881, 2689, 636, 281, 45674, 257, 4458, 307, 294, 11049, 1889, 1668, 13], "temperature": 0.0, "avg_logprob": -0.07627834379673004, "compression_ratio": 1.7161572052401746, "no_speech_prob": 1.6442418200313114e-05}, {"id": 868, "seek": 565484, "start": 5660.84, "end": 5666.84, "text": " This means we traverse a region of a function sequentially across y and within that, sequentially across x.", "tokens": [639, 1355, 321, 45674, 257, 4458, 295, 257, 2445, 5123, 3137, 2108, 288, 293, 1951, 300, 11, 5123, 3137, 2108, 2031, 13], "temperature": 0.0, "avg_logprob": -0.07627834379673004, "compression_ratio": 1.7161572052401746, "no_speech_prob": 1.6442418200313114e-05}, {"id": 869, "seek": 565484, "start": 5666.84, "end": 5671.84, "text": " This walks down scanlines just like the loops you would typically write in C.", "tokens": [639, 12896, 760, 11049, 11045, 445, 411, 264, 16121, 291, 576, 5850, 2464, 294, 383, 13], "temperature": 0.0, "avg_logprob": -0.07627834379673004, "compression_ratio": 1.7161572052401746, "no_speech_prob": 1.6442418200313114e-05}, {"id": 870, "seek": 565484, "start": 5671.84, "end": 5680.84, "text": " We can transpose the x and y dimensions, which gives a column major traversal, which walks down each column in turn.", "tokens": [492, 393, 25167, 264, 2031, 293, 288, 12819, 11, 597, 2709, 257, 7738, 2563, 23149, 304, 11, 597, 12896, 760, 1184, 7738, 294, 1261, 13], "temperature": 0.0, "avg_logprob": -0.07627834379673004, "compression_ratio": 1.7161572052401746, "no_speech_prob": 1.6442418200313114e-05}, {"id": 871, "seek": 568084, "start": 5680.84, "end": 5689.84, "text": " Or we could go back to scanline order, but traverse the x dimension in vectors of width 4.", "tokens": [1610, 321, 727, 352, 646, 281, 11049, 1889, 1668, 11, 457, 45674, 264, 2031, 10139, 294, 18875, 295, 11402, 1017, 13], "temperature": 0.0, "avg_logprob": -0.07973004049725002, "compression_ratio": 1.6051282051282052, "no_speech_prob": 4.637860911316238e-06}, {"id": 872, "seek": 568084, "start": 5689.84, "end": 5697.84, "text": " We could distribute the scanlines across parallel threads.", "tokens": [492, 727, 20594, 264, 11049, 11045, 2108, 8952, 19314, 13], "temperature": 0.0, "avg_logprob": -0.07973004049725002, "compression_ratio": 1.6051282051282052, "no_speech_prob": 4.637860911316238e-06}, {"id": 873, "seek": 568084, "start": 5697.84, "end": 5707.84, "text": " Finally, we can split the x and y dimension into tiles, which opens up further recursive choices for the order of the outer and inner components of each dimension.", "tokens": [6288, 11, 321, 393, 7472, 264, 2031, 293, 288, 10139, 666, 21982, 11, 597, 9870, 493, 3052, 20560, 488, 7994, 337, 264, 1668, 295, 264, 10847, 293, 7284, 6677, 295, 1184, 10139, 13], "temperature": 0.0, "avg_logprob": -0.07973004049725002, "compression_ratio": 1.6051282051282052, "no_speech_prob": 4.637860911316238e-06}, {"id": 874, "seek": 570784, "start": 5707.84, "end": 5713.84, "text": " By traversing the outer components outside the inner components, we get a simple tile traversal.", "tokens": [3146, 23149, 278, 264, 10847, 6677, 2380, 264, 7284, 6677, 11, 321, 483, 257, 2199, 20590, 23149, 304, 13], "temperature": 0.0, "avg_logprob": -0.04930241633269746, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.3552343918709084e-05}, {"id": 875, "seek": 570784, "start": 5713.84, "end": 5715.84, "text": " That's the first question.", "tokens": [663, 311, 264, 700, 1168, 13], "temperature": 0.0, "avg_logprob": -0.04930241633269746, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.3552343918709084e-05}, {"id": 876, "seek": 570784, "start": 5715.84, "end": 5719.84, "text": " The second question is more subtle. When should each stage compute its inputs?", "tokens": [440, 1150, 1168, 307, 544, 13743, 13, 1133, 820, 1184, 3233, 14722, 1080, 15743, 30], "temperature": 0.0, "avg_logprob": -0.04930241633269746, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.3552343918709084e-05}, {"id": 877, "seek": 570784, "start": 5719.84, "end": 5722.84, "text": " Let's look at some options.", "tokens": [961, 311, 574, 412, 512, 3956, 13], "temperature": 0.0, "avg_logprob": -0.04930241633269746, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.3552343918709084e-05}, {"id": 878, "seek": 570784, "start": 5722.84, "end": 5730.84, "text": " Here we have a visualization of the blur pipeline. On the left is the input, on the right is the output, and in the middle is the blur in x stage.", "tokens": [1692, 321, 362, 257, 25801, 295, 264, 14257, 15517, 13, 1282, 264, 1411, 307, 264, 4846, 11, 322, 264, 558, 307, 264, 5598, 11, 293, 294, 264, 2808, 307, 264, 14257, 294, 2031, 3233, 13], "temperature": 0.0, "avg_logprob": -0.04930241633269746, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.3552343918709084e-05}, {"id": 879, "seek": 570784, "start": 5730.84, "end": 5736.84, "text": " Green means we're reading, red means we're writing, and blue means we've allocated a temporary buffer.", "tokens": [6969, 1355, 321, 434, 3760, 11, 2182, 1355, 321, 434, 3579, 11, 293, 3344, 1355, 321, 600, 29772, 257, 13413, 21762, 13], "temperature": 0.0, "avg_logprob": -0.04930241633269746, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.3552343918709084e-05}, {"id": 880, "seek": 573684, "start": 5736.84, "end": 5742.84, "text": " So right now we're reading from the input and using it to write to the blur in x stage.", "tokens": [407, 558, 586, 321, 434, 3760, 490, 264, 4846, 293, 1228, 309, 281, 2464, 281, 264, 14257, 294, 2031, 3233, 13], "temperature": 0.0, "avg_logprob": -0.03929895343202533, "compression_ratio": 1.9736842105263157, "no_speech_prob": 2.796893568302039e-05}, {"id": 881, "seek": 573684, "start": 5742.84, "end": 5749.84, "text": " We read three values from the input, one, two, three, to compute a single value of the blur in x stage.", "tokens": [492, 1401, 1045, 4190, 490, 264, 4846, 11, 472, 11, 732, 11, 1045, 11, 281, 14722, 257, 2167, 2158, 295, 264, 14257, 294, 2031, 3233, 13], "temperature": 0.0, "avg_logprob": -0.03929895343202533, "compression_ratio": 1.9736842105263157, "no_speech_prob": 2.796893568302039e-05}, {"id": 882, "seek": 573684, "start": 5749.84, "end": 5754.84, "text": " We haven't even started writing to the output yet.", "tokens": [492, 2378, 380, 754, 1409, 3579, 281, 264, 5598, 1939, 13], "temperature": 0.0, "avg_logprob": -0.03929895343202533, "compression_ratio": 1.9736842105263157, "no_speech_prob": 2.796893568302039e-05}, {"id": 883, "seek": 573684, "start": 5754.84, "end": 5762.84, "text": " So the choice we've made here is that we're going to compute all of the blur in x stage before computing any of the blur in y stage.", "tokens": [407, 264, 3922, 321, 600, 1027, 510, 307, 300, 321, 434, 516, 281, 14722, 439, 295, 264, 14257, 294, 2031, 3233, 949, 15866, 604, 295, 264, 14257, 294, 288, 3233, 13], "temperature": 0.0, "avg_logprob": -0.03929895343202533, "compression_ratio": 1.9736842105263157, "no_speech_prob": 2.796893568302039e-05}, {"id": 884, "seek": 576284, "start": 5762.84, "end": 5772.84, "text": " If we phrase this as a decision made by blur in y, that decision is, compute all of my inputs ahead of time before I start computing any of my values.", "tokens": [759, 321, 9535, 341, 382, 257, 3537, 1027, 538, 14257, 294, 288, 11, 300, 3537, 307, 11, 14722, 439, 295, 452, 15743, 2286, 295, 565, 949, 286, 722, 15866, 604, 295, 452, 4190, 13], "temperature": 0.0, "avg_logprob": -0.048737139450876335, "compression_ratio": 1.5627705627705628, "no_speech_prob": 1.1478661690489389e-05}, {"id": 885, "seek": 576284, "start": 5772.84, "end": 5778.84, "text": " So what's the pitfall with this approach? Why is this slow?", "tokens": [407, 437, 311, 264, 10147, 6691, 365, 341, 3109, 30, 1545, 307, 341, 2964, 30], "temperature": 0.0, "avg_logprob": -0.048737139450876335, "compression_ratio": 1.5627705627705628, "no_speech_prob": 1.1478661690489389e-05}, {"id": 886, "seek": 576284, "start": 5778.84, "end": 5784.84, "text": " The answer is, of course, locality.", "tokens": [440, 1867, 307, 11, 295, 1164, 11, 1628, 1860, 13], "temperature": 0.0, "avg_logprob": -0.048737139450876335, "compression_ratio": 1.5627705627705628, "no_speech_prob": 1.1478661690489389e-05}, {"id": 887, "seek": 576284, "start": 5784.84, "end": 5791.84, "text": " By the time the blur in y stage goes to read some of the intermediate data, it's probably been evicted from cache.", "tokens": [3146, 264, 565, 264, 14257, 294, 288, 3233, 1709, 281, 1401, 512, 295, 264, 19376, 1412, 11, 309, 311, 1391, 668, 1073, 11254, 490, 19459, 13], "temperature": 0.0, "avg_logprob": -0.048737139450876335, "compression_ratio": 1.5627705627705628, "no_speech_prob": 1.1478661690489389e-05}, {"id": 888, "seek": 579184, "start": 5791.84, "end": 5797.84, "text": " So that load will be slow and will be limited by the system memory bandwidth.", "tokens": [407, 300, 3677, 486, 312, 2964, 293, 486, 312, 5567, 538, 264, 1185, 4675, 23647, 13], "temperature": 0.0, "avg_logprob": -0.05866172909736633, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.4682507500983775e-05}, {"id": 889, "seek": 579184, "start": 5797.84, "end": 5800.84, "text": " So let's look at a different option.", "tokens": [407, 718, 311, 574, 412, 257, 819, 3614, 13], "temperature": 0.0, "avg_logprob": -0.05866172909736633, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.4682507500983775e-05}, {"id": 890, "seek": 579184, "start": 5800.84, "end": 5810.84, "text": " Here we compute three values of blur in x by reading nine values from the input, and we immediately use that to compute one value of the output.", "tokens": [1692, 321, 14722, 1045, 4190, 295, 14257, 294, 2031, 538, 3760, 4949, 4190, 490, 264, 4846, 11, 293, 321, 4258, 764, 300, 281, 14722, 472, 2158, 295, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.05866172909736633, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.4682507500983775e-05}, {"id": 891, "seek": 579184, "start": 5810.84, "end": 5819.84, "text": " So here we get maximum locality. We're using data as soon as it's available without giving it any time to be evicted from a cache.", "tokens": [407, 510, 321, 483, 6674, 1628, 1860, 13, 492, 434, 1228, 1412, 382, 2321, 382, 309, 311, 2435, 1553, 2902, 309, 604, 565, 281, 312, 1073, 11254, 490, 257, 19459, 13], "temperature": 0.0, "avg_logprob": -0.05866172909736633, "compression_ratio": 1.6317991631799162, "no_speech_prob": 2.4682507500983775e-05}, {"id": 892, "seek": 581984, "start": 5819.84, "end": 5823.84, "text": " What's the pitfall here?", "tokens": [708, 311, 264, 10147, 6691, 510, 30], "temperature": 0.0, "avg_logprob": -0.06626692162938864, "compression_ratio": 1.44, "no_speech_prob": 4.5397388021228835e-05}, {"id": 893, "seek": 581984, "start": 5823.84, "end": 5830.84, "text": " Well, if you look carefully at what the blur in x stage is doing, you'll realize that we're doing a lot of wasted work.", "tokens": [1042, 11, 498, 291, 574, 7500, 412, 437, 264, 14257, 294, 2031, 3233, 307, 884, 11, 291, 603, 4325, 300, 321, 434, 884, 257, 688, 295, 19496, 589, 13], "temperature": 0.0, "avg_logprob": -0.06626692162938864, "compression_ratio": 1.44, "no_speech_prob": 4.5397388021228835e-05}, {"id": 894, "seek": 581984, "start": 5830.84, "end": 5836.84, "text": " Each point in blur in x is redundantly recomputed three times.", "tokens": [6947, 935, 294, 14257, 294, 2031, 307, 27830, 3627, 23334, 2582, 292, 1045, 1413, 13], "temperature": 0.0, "avg_logprob": -0.06626692162938864, "compression_ratio": 1.44, "no_speech_prob": 4.5397388021228835e-05}, {"id": 895, "seek": 581984, "start": 5836.84, "end": 5841.84, "text": " OK, well, maybe we can figure out how to get around that.", "tokens": [2264, 11, 731, 11, 1310, 321, 393, 2573, 484, 577, 281, 483, 926, 300, 13], "temperature": 0.0, "avg_logprob": -0.06626692162938864, "compression_ratio": 1.44, "no_speech_prob": 4.5397388021228835e-05}, {"id": 896, "seek": 581984, "start": 5841.84, "end": 5843.84, "text": " Here's another choice.", "tokens": [1692, 311, 1071, 3922, 13], "temperature": 0.0, "avg_logprob": -0.06626692162938864, "compression_ratio": 1.44, "no_speech_prob": 4.5397388021228835e-05}, {"id": 897, "seek": 584384, "start": 5843.84, "end": 5851.84, "text": " First it's going to look similar, but notice that we've allocated enough memory to keep around all of the intermediate stage, and we're not throwing away values as we go.", "tokens": [2386, 309, 311, 516, 281, 574, 2531, 11, 457, 3449, 300, 321, 600, 29772, 1547, 4675, 281, 1066, 926, 439, 295, 264, 19376, 3233, 11, 293, 321, 434, 406, 10238, 1314, 4190, 382, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.05686650894306324, "compression_ratio": 1.6590038314176245, "no_speech_prob": 1.078326295100851e-05}, {"id": 898, "seek": 584384, "start": 5851.84, "end": 5858.84, "text": " That means when we get to the second scanline, we can start reusing values that we computed earlier.", "tokens": [663, 1355, 562, 321, 483, 281, 264, 1150, 11049, 1889, 11, 321, 393, 722, 319, 7981, 4190, 300, 321, 40610, 3071, 13], "temperature": 0.0, "avg_logprob": -0.05686650894306324, "compression_ratio": 1.6590038314176245, "no_speech_prob": 1.078326295100851e-05}, {"id": 899, "seek": 584384, "start": 5858.84, "end": 5863.84, "text": " So great, we have locality, and we're not doing any redundant work.", "tokens": [407, 869, 11, 321, 362, 1628, 1860, 11, 293, 321, 434, 406, 884, 604, 40997, 589, 13], "temperature": 0.0, "avg_logprob": -0.05686650894306324, "compression_ratio": 1.6590038314176245, "no_speech_prob": 1.078326295100851e-05}, {"id": 900, "seek": 584384, "start": 5863.84, "end": 5866.84, "text": " What's the pitfall here?", "tokens": [708, 311, 264, 10147, 6691, 510, 30], "temperature": 0.0, "avg_logprob": -0.05686650894306324, "compression_ratio": 1.6590038314176245, "no_speech_prob": 1.078326295100851e-05}, {"id": 901, "seek": 584384, "start": 5866.84, "end": 5871.84, "text": " We've introduced a serial dependence in the scanlines of the output.", "tokens": [492, 600, 7268, 257, 17436, 31704, 294, 264, 11049, 11045, 295, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.05686650894306324, "compression_ratio": 1.6590038314176245, "no_speech_prob": 1.078326295100851e-05}, {"id": 902, "seek": 587184, "start": 5871.84, "end": 5878.84, "text": " We're relying on the fact that we've computed scanline n minus 1 before we can start computing scanline n.", "tokens": [492, 434, 24140, 322, 264, 1186, 300, 321, 600, 40610, 11049, 1889, 297, 3175, 502, 949, 321, 393, 722, 15866, 11049, 1889, 297, 13], "temperature": 0.0, "avg_logprob": -0.0693619728088379, "compression_ratio": 1.5449735449735449, "no_speech_prob": 1.6964180758805014e-05}, {"id": 903, "seek": 587184, "start": 5878.84, "end": 5885.84, "text": " This means that we can't paralyze across scanlines with this strategy. With the previous two strategies, we could.", "tokens": [639, 1355, 300, 321, 393, 380, 32645, 1381, 2108, 11049, 11045, 365, 341, 5206, 13, 2022, 264, 3894, 732, 9029, 11, 321, 727, 13], "temperature": 0.0, "avg_logprob": -0.0693619728088379, "compression_ratio": 1.5449735449735449, "no_speech_prob": 1.6964180758805014e-05}, {"id": 904, "seek": 587184, "start": 5885.84, "end": 5891.84, "text": " So this approach has poor parallelism.", "tokens": [407, 341, 3109, 575, 4716, 8952, 1434, 13], "temperature": 0.0, "avg_logprob": -0.0693619728088379, "compression_ratio": 1.5449735449735449, "no_speech_prob": 1.6964180758805014e-05}, {"id": 905, "seek": 587184, "start": 5891.84, "end": 5894.84, "text": " I'll go ahead and stop it here.", "tokens": [286, 603, 352, 2286, 293, 1590, 309, 510, 13], "temperature": 0.0, "avg_logprob": -0.0693619728088379, "compression_ratio": 1.5449735449735449, "no_speech_prob": 1.6964180758805014e-05}, {"id": 906, "seek": 589484, "start": 5894.84, "end": 5902.84, "text": " I really like that visual approach if he's showing these different ways of doing the same computation,", "tokens": [286, 534, 411, 300, 5056, 3109, 498, 415, 311, 4099, 613, 819, 2098, 295, 884, 264, 912, 24903, 11], "temperature": 0.0, "avg_logprob": -0.12010482224551114, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.0001195110016851686}, {"id": 907, "seek": 589484, "start": 5902.84, "end": 5906.84, "text": " and that each one has different positives and negatives.", "tokens": [293, 300, 1184, 472, 575, 819, 35127, 293, 40019, 13], "temperature": 0.0, "avg_logprob": -0.12010482224551114, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.0001195110016851686}, {"id": 908, "seek": 589484, "start": 5906.84, "end": 5911.84, "text": " In fact, none of them seems ideal because there's a tradeoff no matter what.", "tokens": [682, 1186, 11, 6022, 295, 552, 2544, 7157, 570, 456, 311, 257, 4923, 4506, 572, 1871, 437, 13], "temperature": 0.0, "avg_logprob": -0.12010482224551114, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.0001195110016851686}, {"id": 909, "seek": 589484, "start": 5911.84, "end": 5923.84, "text": " I just want to mention that later on we are actually going to build an algorithm in all of those different ways in Python and see how they are different.", "tokens": [286, 445, 528, 281, 2152, 300, 1780, 322, 321, 366, 767, 516, 281, 1322, 364, 9284, 294, 439, 295, 729, 819, 2098, 294, 15329, 293, 536, 577, 436, 366, 819, 13], "temperature": 0.0, "avg_logprob": -0.12010482224551114, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.0001195110016851686}, {"id": 910, "seek": 592384, "start": 5923.84, "end": 5929.84, "text": " Keep that video in mind because when we get there, it will be useful to think about those pictures.", "tokens": [5527, 300, 960, 294, 1575, 570, 562, 321, 483, 456, 11, 309, 486, 312, 4420, 281, 519, 466, 729, 5242, 13], "temperature": 0.0, "avg_logprob": -0.1281118392944336, "compression_ratio": 1.5592417061611374, "no_speech_prob": 2.7524300094228238e-05}, {"id": 911, "seek": 592384, "start": 5929.84, "end": 5932.84, "text": " Yeah, thank you.", "tokens": [865, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.1281118392944336, "compression_ratio": 1.5592417061611374, "no_speech_prob": 2.7524300094228238e-05}, {"id": 912, "seek": 592384, "start": 5932.84, "end": 5938.84, "text": " And then something that he said in the video is just locality is really hard because you kind of have tradeoffs.", "tokens": [400, 550, 746, 300, 415, 848, 294, 264, 960, 307, 445, 1628, 1860, 307, 534, 1152, 570, 291, 733, 295, 362, 4923, 19231, 13], "temperature": 0.0, "avg_logprob": -0.1281118392944336, "compression_ratio": 1.5592417061611374, "no_speech_prob": 2.7524300094228238e-05}, {"id": 913, "seek": 592384, "start": 5938.84, "end": 5945.84, "text": " It feels like no matter what you do, sometimes redundant computation can save you memory bandwidth.", "tokens": [467, 3417, 411, 572, 1871, 437, 291, 360, 11, 2171, 40997, 24903, 393, 3155, 291, 4675, 23647, 13], "temperature": 0.0, "avg_logprob": -0.1281118392944336, "compression_ratio": 1.5592417061611374, "no_speech_prob": 2.7524300094228238e-05}, {"id": 914, "seek": 594584, "start": 5945.84, "end": 5953.84, "text": " So computing things multiple times means that you don't have to be pulling them in and out of memory as much.", "tokens": [407, 15866, 721, 3866, 1413, 1355, 300, 291, 500, 380, 362, 281, 312, 8407, 552, 294, 293, 484, 295, 4675, 382, 709, 13], "temperature": 0.0, "avg_logprob": -0.11818854909547617, "compression_ratio": 1.50253807106599, "no_speech_prob": 6.437700903916266e-06}, {"id": 915, "seek": 594584, "start": 5953.84, "end": 5958.84, "text": " Or you can sacrifice parallelism to get better reuse, but then you can't parallelize.", "tokens": [1610, 291, 393, 11521, 8952, 1434, 281, 483, 1101, 26225, 11, 457, 550, 291, 393, 380, 8952, 1125, 13], "temperature": 0.0, "avg_logprob": -0.11818854909547617, "compression_ratio": 1.50253807106599, "no_speech_prob": 6.437700903916266e-06}, {"id": 916, "seek": 594584, "start": 5958.84, "end": 5965.84, "text": " He kind of says the people building this are experts who have been working in Adobe for a long time.", "tokens": [634, 733, 295, 1619, 264, 561, 2390, 341, 366, 8572, 567, 362, 668, 1364, 294, 24862, 337, 257, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.11818854909547617, "compression_ratio": 1.50253807106599, "no_speech_prob": 6.437700903916266e-06}, {"id": 917, "seek": 596584, "start": 5965.84, "end": 5975.84, "text": " They really often just have to try a bunch of different stuff and it can be hard to predict what's going to end up being fastest.", "tokens": [814, 534, 2049, 445, 362, 281, 853, 257, 3840, 295, 819, 1507, 293, 309, 393, 312, 1152, 281, 6069, 437, 311, 516, 281, 917, 493, 885, 14573, 13], "temperature": 0.0, "avg_logprob": -0.1559555927912394, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.1435427697724663e-05}, {"id": 918, "seek": 596584, "start": 5975.84, "end": 5979.84, "text": " And then kind of another...", "tokens": [400, 550, 733, 295, 1071, 485], "temperature": 0.0, "avg_logprob": -0.1559555927912394, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.1435427697724663e-05}, {"id": 919, "seek": 596584, "start": 5979.84, "end": 5984.84, "text": " The difference in speed that Rachel's talking about is many orders of magnitude, not a few percent.", "tokens": [440, 2649, 294, 3073, 300, 14246, 311, 1417, 466, 307, 867, 9470, 295, 15668, 11, 406, 257, 1326, 3043, 13], "temperature": 0.0, "avg_logprob": -0.1559555927912394, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.1435427697724663e-05}, {"id": 920, "seek": 596584, "start": 5984.84, "end": 5986.84, "text": " So this isn't like a minor thing.", "tokens": [407, 341, 1943, 380, 411, 257, 6696, 551, 13], "temperature": 0.0, "avg_logprob": -0.1559555927912394, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.1435427697724663e-05}, {"id": 921, "seek": 596584, "start": 5986.84, "end": 5990.84, "text": " These are things where like in practice, if you don't run something overnight and it hasn't finished,", "tokens": [1981, 366, 721, 689, 411, 294, 3124, 11, 498, 291, 500, 380, 1190, 746, 13935, 293, 309, 6132, 380, 4335, 11], "temperature": 0.0, "avg_logprob": -0.1559555927912394, "compression_ratio": 1.5975609756097562, "no_speech_prob": 2.1435427697724663e-05}, {"id": 922, "seek": 599084, "start": 5990.84, "end": 5995.84, "text": " you'll make one of these small changes and it runs in three seconds.", "tokens": [291, 603, 652, 472, 295, 613, 1359, 2962, 293, 309, 6676, 294, 1045, 3949, 13], "temperature": 0.0, "avg_logprob": -0.11625965242463399, "compression_ratio": 1.6418439716312057, "no_speech_prob": 7.526925855927402e-06}, {"id": 923, "seek": 599084, "start": 5995.84, "end": 5996.84, "text": " It can be that big of a difference.", "tokens": [467, 393, 312, 300, 955, 295, 257, 2649, 13], "temperature": 0.0, "avg_logprob": -0.11625965242463399, "compression_ratio": 1.6418439716312057, "no_speech_prob": 7.526925855927402e-06}, {"id": 924, "seek": 599084, "start": 5996.84, "end": 5997.84, "text": " Yes, thank you. Yeah.", "tokens": [1079, 11, 1309, 291, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.11625965242463399, "compression_ratio": 1.6418439716312057, "no_speech_prob": 7.526925855927402e-06}, {"id": 925, "seek": 599084, "start": 5997.84, "end": 6001.84, "text": " If it was a minor difference in speed, it wouldn't be worth the bother.", "tokens": [759, 309, 390, 257, 6696, 2649, 294, 3073, 11, 309, 2759, 380, 312, 3163, 264, 8677, 13], "temperature": 0.0, "avg_logprob": -0.11625965242463399, "compression_ratio": 1.6418439716312057, "no_speech_prob": 7.526925855927402e-06}, {"id": 926, "seek": 599084, "start": 6001.84, "end": 6009.84, "text": " And something even I think in the part I showed you, he mentioned kind of getting an 11x speed up by writing this more complicated version.", "tokens": [400, 746, 754, 286, 519, 294, 264, 644, 286, 4712, 291, 11, 415, 2835, 733, 295, 1242, 364, 2975, 87, 3073, 493, 538, 3579, 341, 544, 6179, 3037, 13], "temperature": 0.0, "avg_logprob": -0.11625965242463399, "compression_ratio": 1.6418439716312057, "no_speech_prob": 7.526925855927402e-06}, {"id": 927, "seek": 599084, "start": 6009.84, "end": 6018.84, "text": " And I couldn't even see what the code said, but it was a full screen of code just to do this blur in X, blur in Y operation.", "tokens": [400, 286, 2809, 380, 754, 536, 437, 264, 3089, 848, 11, 457, 309, 390, 257, 1577, 2568, 295, 3089, 445, 281, 360, 341, 14257, 294, 1783, 11, 14257, 294, 398, 6916, 13], "temperature": 0.0, "avg_logprob": -0.11625965242463399, "compression_ratio": 1.6418439716312057, "no_speech_prob": 7.526925855927402e-06}, {"id": 928, "seek": 601884, "start": 6018.84, "end": 6021.84, "text": " And then another issue that comes up is temporaries.", "tokens": [400, 550, 1071, 2734, 300, 1487, 493, 307, 8219, 4889, 13], "temperature": 0.0, "avg_logprob": -0.0348088178741798, "compression_ratio": 1.6729857819905214, "no_speech_prob": 1.1657974027912132e-05}, {"id": 929, "seek": 601884, "start": 6021.84, "end": 6029.84, "text": " And that's when you're doing a calculation and kind of temporary variables end up getting stored.", "tokens": [400, 300, 311, 562, 291, 434, 884, 257, 17108, 293, 733, 295, 13413, 9102, 917, 493, 1242, 12187, 13], "temperature": 0.0, "avg_logprob": -0.0348088178741798, "compression_ratio": 1.6729857819905214, "no_speech_prob": 1.1657974027912132e-05}, {"id": 930, "seek": 601884, "start": 6029.84, "end": 6035.84, "text": " And so this can be a lot slower than if you're able to keep all the data in cache.", "tokens": [400, 370, 341, 393, 312, 257, 688, 14009, 813, 498, 291, 434, 1075, 281, 1066, 439, 264, 1412, 294, 19459, 13], "temperature": 0.0, "avg_logprob": -0.0348088178741798, "compression_ratio": 1.6729857819905214, "no_speech_prob": 1.1657974027912132e-05}, {"id": 931, "seek": 601884, "start": 6035.84, "end": 6038.84, "text": " So this is if the temporary variables are stored in RAM.", "tokens": [407, 341, 307, 498, 264, 13413, 9102, 366, 12187, 294, 14561, 13], "temperature": 0.0, "avg_logprob": -0.0348088178741798, "compression_ratio": 1.6729857819905214, "no_speech_prob": 1.1657974027912132e-05}, {"id": 932, "seek": 601884, "start": 6038.84, "end": 6043.84, "text": " NumPy creates temporaries for kind of every operation it does.", "tokens": [22592, 47, 88, 7829, 8219, 4889, 337, 733, 295, 633, 6916, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.0348088178741798, "compression_ratio": 1.6729857819905214, "no_speech_prob": 1.1657974027912132e-05}, {"id": 933, "seek": 604384, "start": 6043.84, "end": 6052.84, "text": " So if you were doing A equals B times C squared plus the natural log of D, what NumPy would have to do is calculate C squared,", "tokens": [407, 498, 291, 645, 884, 316, 6915, 363, 1413, 383, 8889, 1804, 264, 3303, 3565, 295, 413, 11, 437, 22592, 47, 88, 576, 362, 281, 360, 307, 8873, 383, 8889, 11], "temperature": 0.0, "avg_logprob": -0.08421158503337078, "compression_ratio": 1.64, "no_speech_prob": 1.8447108232066967e-06}, {"id": 934, "seek": 604384, "start": 6052.84, "end": 6060.84, "text": " store that, multiply that by B, store that result, take the natural log of D, store that somewhere,", "tokens": [3531, 300, 11, 12972, 300, 538, 363, 11, 3531, 300, 1874, 11, 747, 264, 3303, 3565, 295, 413, 11, 3531, 300, 4079, 11], "temperature": 0.0, "avg_logprob": -0.08421158503337078, "compression_ratio": 1.64, "no_speech_prob": 1.8447108232066967e-06}, {"id": 935, "seek": 604384, "start": 6060.84, "end": 6065.84, "text": " and then use those two variables that's stored to add them together and give you the answer you want.", "tokens": [293, 550, 764, 729, 732, 9102, 300, 311, 12187, 281, 909, 552, 1214, 293, 976, 291, 264, 1867, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.08421158503337078, "compression_ratio": 1.64, "no_speech_prob": 1.8447108232066967e-06}, {"id": 936, "seek": 606584, "start": 6065.84, "end": 6076.84, "text": " And so kind of along the way, NumPy is having to deal with this creating temporary variables and putting them somewhere.", "tokens": [400, 370, 733, 295, 2051, 264, 636, 11, 22592, 47, 88, 307, 1419, 281, 2028, 365, 341, 4084, 13413, 9102, 293, 3372, 552, 4079, 13], "temperature": 0.0, "avg_logprob": -0.03498332384156018, "compression_ratio": 1.599078341013825, "no_speech_prob": 1.43672502872505e-06}, {"id": 937, "seek": 606584, "start": 6076.84, "end": 6080.84, "text": " And then I'm about to get to the scalability section,", "tokens": [400, 550, 286, 478, 466, 281, 483, 281, 264, 15664, 2310, 3541, 11], "temperature": 0.0, "avg_logprob": -0.03498332384156018, "compression_ratio": 1.599078341013825, "no_speech_prob": 1.43672502872505e-06}, {"id": 938, "seek": 606584, "start": 6080.84, "end": 6087.84, "text": " but I just want to note that scalability definitely impacts the speed of what you're doing", "tokens": [457, 286, 445, 528, 281, 3637, 300, 15664, 2310, 2138, 11606, 264, 3073, 295, 437, 291, 434, 884], "temperature": 0.0, "avg_logprob": -0.03498332384156018, "compression_ratio": 1.599078341013825, "no_speech_prob": 1.43672502872505e-06}, {"id": 939, "seek": 606584, "start": 6087.84, "end": 6094.84, "text": " and whether you're kind of fully taking advantage of the resources that you have.", "tokens": [293, 1968, 291, 434, 733, 295, 4498, 1940, 5002, 295, 264, 3593, 300, 291, 362, 13], "temperature": 0.0, "avg_logprob": -0.03498332384156018, "compression_ratio": 1.599078341013825, "no_speech_prob": 1.43672502872505e-06}, {"id": 940, "seek": 609484, "start": 6094.84, "end": 6103.84, "text": " So for scalability, kind of there's the one approach is to be able to scale an algorithm across multiple cores", "tokens": [407, 337, 15664, 2310, 11, 733, 295, 456, 311, 264, 472, 3109, 307, 281, 312, 1075, 281, 4373, 364, 9284, 2108, 3866, 24826], "temperature": 0.0, "avg_logprob": -0.10276480896832192, "compression_ratio": 1.7459459459459459, "no_speech_prob": 2.521507667552214e-06}, {"id": 941, "seek": 609484, "start": 6103.84, "end": 6111.84, "text": " within a single computer or scaling across multiple computers in a network, which we will not be covering.", "tokens": [1951, 257, 2167, 3820, 420, 21589, 2108, 3866, 10807, 294, 257, 3209, 11, 597, 321, 486, 406, 312, 10322, 13], "temperature": 0.0, "avg_logprob": -0.10276480896832192, "compression_ratio": 1.7459459459459459, "no_speech_prob": 2.521507667552214e-06}, {"id": 942, "seek": 609484, "start": 6111.84, "end": 6120.84, "text": " But yeah, we will talk about kind of parallelizing, which is scaling across multiple cores in a computer.", "tokens": [583, 1338, 11, 321, 486, 751, 466, 733, 295, 8952, 3319, 11, 597, 307, 21589, 2108, 3866, 24826, 294, 257, 3820, 13], "temperature": 0.0, "avg_logprob": -0.10276480896832192, "compression_ratio": 1.7459459459459459, "no_speech_prob": 2.521507667552214e-06}, {"id": 943, "seek": 612084, "start": 6120.84, "end": 6126.84, "text": " Yeah, and I think this is great timing. I can take questions. Oh, yes.", "tokens": [865, 11, 293, 286, 519, 341, 307, 869, 10822, 13, 286, 393, 747, 1651, 13, 876, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.0846348109998201, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.00013545200636144727}, {"id": 944, "seek": 612084, "start": 6126.84, "end": 6131.84, "text": " Just a tip. You'll see that Rachel has used a lot of hierarchical headings,", "tokens": [1449, 257, 4125, 13, 509, 603, 536, 300, 14246, 575, 1143, 257, 688, 295, 35250, 804, 1378, 1109, 11], "temperature": 0.0, "avg_logprob": -0.0846348109998201, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.00013545200636144727}, {"id": 945, "seek": 612084, "start": 6131.84, "end": 6137.84, "text": " and it's really easy to navigate those and understand her thought process by collapsing sections.", "tokens": [293, 309, 311, 534, 1858, 281, 12350, 729, 293, 1223, 720, 1194, 1399, 538, 45339, 10863, 13], "temperature": 0.0, "avg_logprob": -0.0846348109998201, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.00013545200636144727}, {"id": 946, "seek": 612084, "start": 6137.84, "end": 6144.84, "text": " You need to install a Jupiter extension called collapsible headings for that to work.", "tokens": [509, 643, 281, 3625, 257, 24567, 10320, 1219, 16567, 964, 1378, 1109, 337, 300, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.0846348109998201, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.00013545200636144727}, {"id": 947, "seek": 612084, "start": 6144.84, "end": 6147.84, "text": " So you might want to look at installing that extension.", "tokens": [407, 291, 1062, 528, 281, 574, 412, 20762, 300, 10320, 13], "temperature": 0.0, "avg_logprob": -0.0846348109998201, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.00013545200636144727}, {"id": 948, "seek": 614784, "start": 6147.84, "end": 6153.84, "text": " Yes. Yeah, that's a great extension.", "tokens": [1079, 13, 865, 11, 300, 311, 257, 869, 10320, 13], "temperature": 0.0, "avg_logprob": -0.13262866672716642, "compression_ratio": 0.8947368421052632, "no_speech_prob": 3.16897603624966e-05}, {"id": 949, "seek": 614784, "start": 6153.84, "end": 6158.84, "text": " Any questions?", "tokens": [2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.13262866672716642, "compression_ratio": 0.8947368421052632, "no_speech_prob": 3.16897603624966e-05}, {"id": 950, "seek": 615884, "start": 6158.84, "end": 6177.84, "text": " Okay, well, I'll see you on Thursday. Thanks.", "tokens": [50364, 1033, 11, 731, 11, 286, 603, 536, 291, 322, 10383, 13, 2561, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1974596083164215, "compression_ratio": 0.8823529411764706, "no_speech_prob": 3.316709990031086e-05}], "language": "en"}