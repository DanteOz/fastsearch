{"text": " Welcome to the last lesson lesson 14 We're going to be looking at image segmentation today amongst other things but before we do a Bit of show-and-tell from last week Elena Harley did something really interesting which was she tried finding out what would happen if you did cycle GAN on just three or four Hundred images and I really like these projects where people just go to Google image search You know using the the API or one of the libraries out there some of our students have created some very good libraries for interacting with Google images API Download a bunch of stuff that they're interested in in this case some photos and some stained glass windows and Yeah with three or four hundred photos of that she trained a model she trained actually a few different models This is what I particularly liked and as you can see with quite a small number of images, you know, she gets some very nice stained-glass effects So I thought that was a interesting example of using pretty small amounts of data That was readily available that she was able to download pretty quickly And there's more information about that on the forum if you're interested Yeah, it's interesting to wonder about what kinds of things people will come up with with this kind of a Generative model. It's clearly a great artistic medium It's clearly a great medium for forgeries and fakeries I Wonder what other kinds of things people will Realize they can do with these kind of generative models. I think audio is going to be the next big area and also very like interactive type stuff that Nvidia just released a paper showing a interactive kind of photo repair tool where you just like brush over an object and it replaces it with You know a deep learning generated replacement very nicely those kinds of interactive tools. I think will be very interesting, too So before we talk about segmentation we've got some stuff to finish up from last time Which is that we looked at doing style transfer? by actually directly optimizing pixels and you know like with most of the things in part two it's not so much that I'm wanting you to understand Style transfer per se but the kind of idea of Optimizing your input directly and using activations as part of a loss function is really the key kind of takeaway here So it's interesting then to kind of see the What is effectively the follow-up paper? You know not from the same people but the paper that kind of came next in the in the sequence of these kind of vision generative models with this one from Justin Johnson and folks at Stanford and It it actually does the same thing Style transfer, but it does it in a different way rather than optimizing the pixels we're going to go back to something much more familiar and optimize some weights and so specifically we're going to train a model which learns to take a photo and translate it into a photo on this in the style of a particular artwork so each Conv-net will learn to produce one kind of style Now It turns out that getting to that point. There's an intermediate point which is I actually think kind of more More useful and takes us halfway there, which is something called super resolution So we're actually going to start with super resolution Because then we'll build on top of super resolution to finish off the style transfer Conv-net based style transfer and so super resolution is where we take a low res image we're going to take 72 by 72 and Up scale it to a larger image 288 by 288 in our case Trying to create, you know a higher res image that that looks as real as possible and So this is a pretty challenging thing to do because it's 72 by 72 There's not that much information about a lot of the details and the cool thing is that we're going to do it in a way As we tend to do with vision models Which is not tied to the input size so you could totally then take this model that and apply it to a 288 by 288 Image you get something that's Four times bigger on each side so 16 times bigger than that and And often it even kind of works better at that level because you're really introducing a lot of a lot of detail Into the finer details, and you could really print out a high resolution print of something which earlier on was a pixelated So this is the notebook called enhance and It is a lot like that kind of CSI style enhancement where we're going to take something that appears like the information is just not there and we kind of Invent it but the the confidence is going to learn to invent it in a way That's consistent with the information that is there so hopefully you know it's kind of inventing the right information one of the really nice things about this kind of Problem is that we can create our own data set as big as we like without any labeling requirements Because we can easily create a low res image from a high res image just by down sampling our images so Something I would love some of you to try during the week would be to do other types of image to image translation where you can invent kind of late labels invent your dependent variable for example D skewing you know so either recognize things that have been rotated by 90 degrees or better still that have been rotated by 5 degrees and straighten them Colorization so turn make a bunch of images into black and white and learn to put the color back again Noise reduction, you know maybe do a really low quality jpeg save and Learn to put it back to how it should have been and so forth or Yeah, maybe taking something that's like in a 16 color palette and put it back to a higher color palette I think these things are all interesting because they can like be used to take You know pictures that you may have taken back on crappy old digital cameras before they were high resolution Or you may have scanned in some old photos that kind of faded or whatever You know I think it's really useful thing to be able to do and also it's good It's a good project because it's like really similar to what we're doing here But different enough that you'll come come across some interesting challenges on the way. I'm sure So I'm going to use some image net again again, you don't need to use all of image net at all I just happen to have it lying around you can download the 1% sample of image net from faster faster You can use any set of pictures you have lying around honestly and In this case as I say we don't really have labels per se so I'm just going to Give everything a label of zero just so we can use it with our existing infrastructure more easily Now because I'm in this case pointing at a folder that contains all of image net I certainly don't want to wait for all of image net to finish to run an epoch so here I'm just Most of the time I would set Keep percent to like one or two percent and then I just generate a bunch of random numbers And then I just grab those keep those which are less than 0.02 And so that let's be quickly subsample my rows All right, so We're going to use VGG 16 and VGG 16 is something that we haven't really looked at in this class But it's a very simple very simple model where we take a normal presumably three-channel input and we basically run it through a number of three by three convolutions and Then from time to time we put it through a two by two max pull and then we do a few more three by three convolutions Max pull so on so forth and then this is kind of our backbone I guess And Then we we don't do an average pooling layer an adaptive average pooling layer After a few of these we end up with this You know seven by seven grid as usual. I think it's about seven by seven by five twelve something like that And so rather than average pooling we do something different which is we flatten the whole thing so that spits out a very long Vector of activations of size seven times seven times five twelve if memory says correctly and Then that gets fed into Two fully connected layers Each one of which has four oh nine six Activations and then one more fully connected layer which has however many classes So if you think about it the weight matrix Here is Huge it's you know seven by seven by five twelve by four oh nine six and It's because of that weight matrix really that VGG Went out of favor pretty quickly because it takes a lot of memory and takes a lot of computation, and it's really slow and There's a lot of redundant stuff going on here because really those five hundred and twelve activations are Not that specific to which of those seven by seven grid cells They're in right, but when you have this entire weight matrix here of every possible combination It treats all of them uniquely Right and so that can also lead to generalization problems because there's just a lot of weights and so forth My view is that there's you know that the approach that's used in every modern network, which is here. We do an adaptive average pooling Keras that we known as a global average pooling or in fast AI we generally do a concat adaptive concat pooling Which spits it straight down to a 512 long Activation I think that's throwing away too much geometry So to me probably the correct answer is somewhere in between and would involve some kind of um factored convolution or some kind of tensor decomposition Which yeah, maybe some of us can think about in the coming months So for now anyway, we've gone from one extreme Which is the adaptive average pooling to the other extreme which is this huge flattened fully connected player? So a couple of things which are interesting about VGG that make it still useful today The first one is that there's there's more Interesting layers going on here with With most modern networks including the resnet family we the very first layer generally is a 7 by 7 pond or something similar Which means we and that's tried to right which means we throw away half the grid size Straight away, and so there's little opportunity to use the fine Detail because we never do any computation with it and so that's a bit of a problem for Things like segmentation or super resolution models because the fine detail matters right we actually want to restore it And then the second problem is that the adaptive average pooling layer Entirely throws away the geometry in the last few sections which means that the rest of the model Doesn't really have as much interest in kind of learning the geometry as it otherwise might And so therefore for things which are dependent on position any kind of localization based approach to anything that requires generative modeling Is going to be less effective so? One of the things I'm hoping you're hearing as I describe this is that probably none of the existing architectures are actually ideal We can invent a new one that actually I just tried inventing a new one over the week which was to take the the VGG head and attach it to a resnet backbone And interestingly I found I actually got a slightly better classifier than a normal resnet But it also was something with a little bit more Useful information you know it took I don't know five or ten percent longer to train, but nothing worth worrying about Yeah, I think you know maybe we can in resnet replace this as we've talked about briefly before this very early Convolution with something more like an inception stem which does a bit more computation. I think there's definitely room for some nice little tweaks to These architectures so that we can build some models which are maybe more versatile You know at the moment people tend to build architectures that just do one thing They don't really think you know what am I throwing away in terms of opportunity because that's that's how publishing works You know you publish like I've got the state-of-the-art in this one thing rather than the I've created something It's good at lots of things So so for these reasons we're going to use VGG today even though it's it's ancient and it's missing lots of great stuff one thing we are going to do though is use a slightly more modern version which is a version of VGG where batch norm has been added after all the convolutions and so in Fast AI actually when you ask for a VGG network you always get the batch norm one because that's basically always what you want So this is actually about VGG with batch norm There's a 16 and a 19 the 19 is way bigger and heavier and doesn't really isn't really any better So we I know one really uses it Okay, so we're going to go from 72 by 72 LR is low resolution input Size low resolution we're going to initially scale it up by times two With a batch size of 64 to get a 2 times 72 so 1 by 44 by 144 output So that's going to be our stage stage one We'll create our own data set for this and the data set It's very worthwhile looking inside the fast AI dot data set module and seeing what's there because Just about anything you'd want we probably have something that's almost what you want So in this case, I want a data set where my X's are images and my Y's are also images So there's already a files data set we can inherit from where the X's are images And then I just inherit from that and I just copied and pasted the get X and turn that into get Y So it just opens an image So now I've got something where the X is an image and the Y is an image and in both cases what we're passing in Is an array of file names? I'm going to do some data augmentation Obviously with all of image net we don't really need it But this is mainly here for you know anybody who's using smaller data sets to make the most of it random dihedral is referring to every possible 90 degree rotation plus optional left right flipping so that the dihedral group of eight symmetries Normally we don't use this Transformation for image net pictures because like you don't normally flip dogs upside down But in this case, we're not trying to Classify whether it's a dog or a cat. We're just trying to keep the general structure of it So actually, you know every possible flip is a reasonably sensible thing to do for this problem So create a validation set in the usual way And you can see I'm kind of like using a few more slightly lower level functions Generally speaking I just copy and paste them out of the fast AI source code To you know find the bits I want so here's the bit which takes an array of validation set indexes and one or more arrays of variables and simply splits so in this case this into a Training and a validation set and this into a training and a valid it Sorry, it yeah the training and validation set you give us our X's and our Y's Now in this case the trend of the X and the Y are the same Our input image and our output image are the same we're going to use transformations to make one of them lower resolution So that's why these are the same the same thing Okay, so The next thing that we need to do is to create our transformations as per usual and We're going to use this transform y parameter like we did for bounding boxes But rather than use transform type dot coordinate we're going to use transform type dot pixel and so that tells our Transformations framework that your y values are Images with normal pixels in them and so anything you do the X you also need to do to the Y do the same thing Okay, and you need to make sure any data augmentation transforms you use have the same parameter as well, okay So you can see the possible transform types you basically you've got classification which we're about to use the segmentation in the second half of today coordinates No transformation at all or pixel All right, so once we've got a data set class and some X and Y training and validation sets There's a handy little method called get data sets, which basically Runs that constructor over all the different things that you have to return all the data sets you need in exactly the right format to pass Pass to a model data construction as constructor in this case the image data constructor. So we're kind of like going back Under the covers of fast AI a little bit and building it up from scratch and you know in the next few weeks This will all be wrapped up and refactored into something that you can do in a single step in fast AI But the point of this class is to learn you know a bit about going under the covers So Something we've briefly seen before is that when we take images in we transform them not just with data augmentation But we also move the channels dimension up to the start We subtract the mean divide by the standard deviation whatever So if we want to be able to display those pictures that have come out of our data sets or data loaders We need to denormalize them and so the model data objects Data set has a denorm Function that knows how to do that. So I'm just going to give that a short name For convenience. So now I'm going to create a function that can show an image from a data set and If you pass in something saying this is a normalized image Then we'll denote it. Okay, so We can go ahead and have a look at that you'll see here we've passed in size low res as our size for the transforms and Size high res as this is something new The size y parameter. Okay, so the two bits are going to get different sizes And so here you can see the two different resolutions of our X and our Y for a whole bunch of fish Okay As you know as per usual plot dot subplots To create our two plots and then we can just use the different axes that came back to put stuff next to each other So we can then Have a look at a few different versions of the data transformation and you can see them being flipped in all different directions Okay, so let's create our model So we're going to have an image coming in Small image coming in and we want to have a big image coming out Okay, and so we need to do some computation between those two to calculate what the big image would look like and So essentially there's kind of two ways of doing that computation. We could first of all do some up sampling and then do a few stride one kind of layers to do lots of computation or We could first do lots of stride one layers to do all the computation and then at the end do some up sampling We're going to pick the second approach because we want to do lots of computation on something smaller Because it's much faster to do it that way and also like all that computation we get to kind of leverage During the up sampling process So app sampling We know a couple of possible ways to do that. We can use transposed or fractionally strided convolutions Or we can use nearest neighbor up sampling followed by a one by one conv And Then in in the kind of do lots of computation section We could just have a whole bunch of three by three cons, right? But in this case particular It seems likely that resnet blocks are going to be better because really the output and the input are Very very similar, right? So we really want a kind of a flow through path that allows as little fussing around as possible except kind of the minimal amount necessary to do our Super resolution and so if we use resnet blocks Then they have an identity path already. Right? So like you can imagine the most simple version where it does like a you know Bilinear sampling kind of approach or something It could basically just go through identity blocks all the way through and then in the up sampling blocks Just learn to take the averages of the inputs and get something that's like not too terrible So that's what we're going to do we're going to create Something with five resnet blocks and then for each 2x scale up we have to do we'll have one up sampling block So they're all going to consist of Obviously as per usual convolution layers possibly with activation functions after many of them so I kind of like to put my Standard convolution block into a function so I can refactor it more easily As per usual I just won't worry about passing in padding and just calculate it directly as kernel size over 2 So one interesting thing about our little common block here is that there's no batch non Which is pretty unusual for resnet type models And the reason there's no batch norm is because I'm stealing ideas from this fantastic Recent paper which actually won a recent competition in super resolution performance And to see how good this paper is here's kind of a previous state-of-the-art There's SR resnet right and what they've done here is they've zoomed way in to a an up sampled kind of net or or fence right this is the original and you can see in the The kind of previous best approach. There's a whole lot of distortion and blurring going on All right, where else in their approach? It's it's nearly perfect. All right, so like it was a really big step up this paper They call their model EDSR enhanced deep residual networks and they did two things differently to the kind of previous standard approaches One was to take the resnet blocks. This is a regular resnet block and throw away the batch norm So why would they throw away the batch norm? Well, the reason they would throw away the batch norm is because batch norm Changes stuff and we want a nice Straight through path that doesn't change stuff Okay, so the idea basically here is like hey if you don't want to fiddle with the input more than you have to Then don't force it to have to calculate things like batch norm parameters So throw away the batch norm and the second trick we'll see shortly. All right, so here's a con with no batch norm And so then we're going to create a residual block containing as per usual Two convolutions and as you see in their approach they even they don't even have a relu after their second con Okay, so that's why I've only got activation on the first one So a Couple of interesting things here one is that this idea of like having some kind of Main resnet path like conv relu cons and then turning that into a relu block by adding it back to the identity It's something we do so often. I kind of factored it out into a tiny little module called res sequential Which simply takes a bunch of layers that you want to put into your? residual path Turns that into a sequential model It runs it and then adds it back to the input right so with this little module we can now turn anything Like con activation cons into a resnet block just by wrapping it in res sequential But that's not quite all I'm doing because like normally a res block Just has that in its forward, but I also got that What's res scale res scale is the number 0.1? Why is it there? I'm not sure anybody quite knows but the short answer is that the guy who invented batch norm also Somewhat more recently did a paper in which he showed I think the first time the ability to train image net in under an hour and the way he did it was fire up lots and lots of machines and Have them work in parallel to create really large batch sizes Now generally when you increase the batch size by order n You also increase the learning rate by order n to go with it so generally very large batch size training means very high Learning rate training as well, and he found that with these very large batch sizes of like 8,000 plus or even up to 32,000 that at the start of training his activations would basically go straight to infinity and A lot of other people have found that we actually found that when we were competing in dawn bench both on the cipher and the image net competitions that you know we really struggled to make the most of even the 8 GPUs that we were trying to take advantage of because of these kind of Challenges with these larger batch sizes and taking advantage of them So something that Christian found this researcher was that if he in the ResNet blocks if he multiplied them by some number Smaller than one something like point one or point two It really helped stabilize training at the start and That's kind of weird because like mathematically. It's kind of identical right because obviously whatever I'm multiplying it by here You know I could just scale the weights by the opposite amount here and have the same number right so but it's kind of like We're not dealing with abstract math. You know we're dealing with like you know real optimization problems and different initializations and learning rates and whatever else and so The problem of kind of weights disappearing off into infinity I guess generally is really about the kind of the discrete and finite nature of computers in in practice partly and so often yeah, these kind of little tricks can Can make the difference right so in this case. We're just Kind of toning things down On base at least based on our initial initialization, and so there are probably other ways to do this For example one approach From some folks at Nvidia called Lars la RS which I briefly mentioned last week is an approach which uses discriminative learning rates calculated in real time basically looking at the ratio between the gradients and the activations To scale learning rates by layer and so they found that they didn't need this Trick to scale it scale up the batch sizes a lot Maybe a different initialization Would would be all that's necessary The reason I mentioned this is not so much because I think a lot of you are likely to want to train on massive clusters of computers But rather that I think a lot of you want to train models quickly and that means using high learning rates and ideally getting superconvergence and I think these kinds of tricks The tricks that we'll need to be able to get superconvergence across more different architectures and so forth and You know other than Leslie Smith No one else is really working on superconvergence other than some fast AI students nowadays So these kind of things about how do we train at very very high learning rates? we're going to be have to be the ones who figure it out because As far as I can tell nobody else gets yet So so I think these you know the looking at the literature around you know training image net in one hour or more recently There's now a train image net in 15 minutes these papers Actually tell I think have some of the tricks to allow us to train things at high learning rates and so here's one of them and so Interestingly other than the train image net in one hour paper the only other place. I've seen this mentioned was in this EDSR paper, and it's really cool because like I don't know people who win competitions. I just find them to be very Fragmatic and well read you know like they actually have to get things to work and so This paper describes an approach which actually worked better than anybody else's approach and they did these pragmatic things like throw away batch norm and Use this little scaling factor which almost nobody else seems to know about And stuff like that Okay, so that's where the point one comes from So basically our Super resolution resnet is done and do a convolution to go from our three channels to 64 channels Just to richen up the space a little bit then also I've got actually eight not five eight Lots of these res blocks and we're just going to keep you remember every one of these res blocks is Strive one so the grid size doesn't change the number of filters doesn't change. It's just 64 all the way through We'll do one more convolution, and then we'll do our up sampling by however much scale we asked for and then something I've added which is a Little idea is just one batch norm here because it kind of felt like it might be helpful just to scale the last layer And then finally a comm to go back to the three channels we want So you can see that's basically his lots and lots of computation and then a little bit of up sampling Just like we kind of described So the only other piece here then is And also just dimension you know as you can see as I'm tending to do now this whole thing is done by creating Just a list of layers and then at the end turning that into a sequential model And so my forward function is the simplest can be So here's our up sampling and up sampling is a bit interesting because it is not Doing either of these two things so let's talk a bit about up sampling Here's a picture from the paper from not from the competition winning paper from this original paper and So they're saying hey our approach is so much better, but look at their approach. It's got Goddamn artifacts in it All right, these just pop up everywhere And so one of the reasons for this is that they use transposed convolutions, and we all know don't use transposed convolutions So here are transposed convolutions This is from this fantastic convolutional arithmetic paper that was Shown also in the theano docs if we're going from the blue is the original image so three by three image Up to a five by five image right or be six by six if we added a layer of padding Then all a transposed convolution does is it uses a regular three by three conv, but it sticks White you know zero pixels between every pair of pixels right so that makes the input image bigger And when we run this convolution up over it it therefore gives us a larger output Right, but I mean that's obviously stupid because when we get here for example Of the nine pixels coming in eight of them are zero So like we're just wasting a whole lot of computation And then on the other hand if we're slightly off over here then four of our nine and on zero But yet we only have one Filter like one kernel to use so it can't like change depending on how many zeros are coming in so it has to kind of Be suitable for both, and it's just not possible right so we end up with these artifacts so One approach we've learned to make it a bit better is to not put white things here But instead to copy this pixels value to each of these three locations All right, so that's a just a nearest neighbor up sampling. That's certainly a bit better All right, but it's still pretty crappy because now still when we get to these nine here Four of them are exactly the same number Right and when we move across one then now we've got you know a Different situation entirely right and so depending on Where we are so in particular if we're here. You know there's going to be a lot less repetition so again, we have this problem where there's like Wasted computation and too much structure in the data, and it's going to lead to artifacts again So up sampling is better than transposed convolutions It's you know better to copy them rather than replace them with zeros, but it's still not quite good enough so instead We're going to do the pixel shuffle So the pixel shuffle is an operation in this subpixel convolutional neural network, and it's a little bit mind-bending But it's kind of fascinating and so we we start with our input We go through some convolutions to create some feature maps for a while until eventually we get to layer And I we get to this layer I minus one which has n I minus one feature maps We're going to do another three by three conv and our goal here is to go from a seven by seven grid cell We're going to go a three by three up scaling so we're going to go up to a 21 by 21 Grid cell so how do we what's another way we could do that? to Make it simpler. Let's just pick one Face just one filter so we just take the topmost filter and just do a convolution over that just to see what happens and what we're going to do is we're going to use a convolution where the kernel size is is the number of filters is Nine times bigger than we strictly speaking need so if we needed 64 filters we're actually going to do 64 times 9 filters Why is that right and so are here are is the scale factor so 3 right so r squared 3 squared is 9 So here are the 9 filters to cover one Of these input layers one of these input slices And well what we can do is we started with Seven by seven and we turned it into seven by seven by nine right well the output that we want is equal to Seven times three by seven times three so in other words There's an equal number of pixels here or activations here as there are activations here, so we can literally reshuffle These seven by seven by nine activations to create this seven by three by seven by three Map and so what we're going to do is we're going to take one little kind of tube here all the top left hand of each Grid and we're going to put the purple one up in the top left and then the blue one one to the right and then the light blue one one to the right of that and Then the slightly darker blue one and the middle of the far left the green one in the middle and so forth so each of these nine Cells in the top left are going to end up in this little three by three section of our grid and Then we're going to take you know two comma one and take all of those nine and move them to these three by three part of the grid and So on and so forth right and so we're going to end up having every one of these seven by seven by nine activations inside this seven by three by seven by three image So the first thing to realize is Yes, of course this works under some definition of works because we have a learnable convolution here and It's going to get some gradients, which is going to do the best job it can But filling in the correct activation such that this output is the thing we want All right, so the first step is to realize There's nothing particularly magical here You know we can we can create any architecture we like we can move things around anyhow We want to and you know our weights in the convolution will do their best to do all we asked the real question is Is it a good idea? You know is this an easier thing for it to do? You know and a more flexible thing for it to do than the transposed convolution or the up sampling followed by one by one And the short answer is yes it is right and the reason it's better In short is that the convolution here is happening in the low resolution seven by seven space Which is quite efficient where else if we first of all up sampled and then did our cons Then our conf would be happening in the 21 by 21 Space which is a lot of computation Right and furthermore as we discussed there's a lot of Replication and redundancy in the nearest neighbor up sample version So they actually show in this paper They actually is that I think they have a follow-up technical note where they kind of provide some more Mathematical details as to exactly what work is being done and show that the work really is more efficient this way, okay? So that's what we're going to do all right so we're going to have for our up sampling would have two steps the first will Be a three by three cons with R squared times more channels than we originally wanted and Then a pixel shuffle operation which moves everything in each grid cell into the little by our grids that are Located throughout here, okay so Here it is it's one line of code right and so here's the con from number of in to number of filters out Times four because we're doing a scale to up sample right so two squared is four So that's our convolution and then here is our pixel shuffle It's built into pytorch pixel shuffle is the thing that moves each thing into its right spot So that Will increase will up sample by a scale factor of two and so we need to do that log base to scale times so scale is four and we have to do it two times to go to Times two bigger okay, so that's what this up sample here does Great Guess what? That does not get rid of the checkerboard patterns We still have checkerboard patterns So I'm sure in great fury and frustration this same team from Twitter I think this is back when they used to be at a startup called magic pony that Twitter bought Came back again with another paper saying okay This time we've got rid of the checkerboard Okay, so So why did we still have as you can see here? We still have a checkerboard All right, and so the reason we still have a checkerboard Even after doing this is that when we randomly initialize this convolutional kernel at the start It means that each of these nine pixels in this little three by three grid over here are going to be totally randomly different But then the next set of three pixels will be randomly different to each other But will be very similar to their corresponding pixel in the previous three by three section So we're going to have repeating Three by three things all the way across and so then as we try to learn Something better. It's starting from this like repeating three by three starting point, which is not what we want What we actually would want is for these three by three pixels to be the same To start with so to make these three by three pixels the same we would need to make these nine channels the same Yeah, right for each filter and so the solution And this paper is very simple It's that when we actually start to make these three by three pixels And this paper is very simple. It's that when we initialize This convolution at the start when we randomly initialize it. We don't totally randomly initialize it we randomly initialize one of the R-squared sets of channels, and then we copy that to the other R-squared so they're all the same and that way initially each of these three by threes will be the same and so that Is called I see enough okay, and that's what we're going to use in a moment So before we do let's take a quick look so we've got this super resolution resnet Which just does lots of computation you know with lots of resnet blocks, and then it does some up sampling and gets our final three channels out and Then to make life faster we're going to run this in parallel One Reason we want to run it in parallel is because Dorado told us that he has six GPUs And this is what his computer looks like right now And so I'm sure anybody who has more than one GPU is had this experience before So how do we get how do we get these men working in together? All you need to do is to take your pytorch module and Wrap it with an end data parallel Okay, and once you've done that it copies it to each of your GPUs and will automatically run it in parallel It scales pretty well to two GPUs Okay to three GPUs I'm better than nothing to four GPUs and beyond that performance starts to go backwards The by default it'll copy it to all of your GPUs you can add an array of GPUs otherwise If you want to avoid getting in trouble for example I have to share our box with your net and if I didn't put this here Then she would be yelling at me right now or maybe you know boycotting my class So this is how you avoid getting into trouble with your net so One thing to be aware of here is that once you do this it actually modifies your module So if you now print out your module, let's say previously it was just an n n dot sequential now you'll find it's an n n dot sequential embedded inside a Module called module right and so in other words if you Save something which you had an end up data paralleled and then try to load it back into something that you hadn't And end up data paralleled it'll say it doesn't match up because one of them is embedded inside this Module attribute and the other one isn't It may also depend even on which GPU IDs you had had it copy to so two possible solutions One is don't save the module M but instead save the module attribute M dot module because that's actually the the non data parallel bit or Always put it on the same GPU IDs and this then use data parallel and load and save that every time That's what I was using This would be an easy thing for me to fix automatically in fast AI and I'll do it pretty soon So it'll look for that module attribution and deal with it automatically But for now we have to do it manually. It's probably useful to know what's going on behind the scenes anyway All right, so we've got our module You know I find it'll run like 50 or 60 percent faster on a 1080 TI If you're running on Volta, it actually parallelizes a bit better There's a there are much faster ways to parallel parallelize, but this is like a super super easy way All right, so we create our learner in the usual way we could use MSE loss here So that's just going to compare the pixels of the output to the pixels, you know that we expected and we can run our learning rate finder and we can train it for a while and Here's our input and here's our output and You can see that what we've managed to do is to train a very advanced residual convolutional network. That's learned to blur things and Why is that well because it's what we asked for we said to Minimize MSE loss right an MSE loss between pixels Really the best way to do that is just average the pixels I eat a blur So that's why pixel loss is no good. So we want to use our perceptual loss So let's try perceptual loss, right? So with perceptual loss, we're basically going to take our VGG network and just like we did last week. We're going to find the the block index Just before we get a max pull okay, so here are the ends of each of each kind of block of the same grid size and If we just print them out as we'd expect every one of those is a value module and So in this case these last two blocks Are less interesting to us the kind of the grid size there is small enough You know kind of coarse enough that it's not as useful for super resolution So we're just going to use the first three and so just to save unnecessary computation We're just going to use those first 23 layers for VGG. We'll throw away the rest We'll stick it on the GPU We're not going to be training this VGG model at all. We're just using it to compare activations So we'll stick it in eval mode and we will set it to not trainable Okay Just like last week We'll use a save features class to through a forward hook which saves the output activations at each of those layers And so now we've got everything we need to create our Perceptual loss or as I call it here feature loss class, right? And so we're going to pass in a list of layer IDs You know the layers where we want the content loss to be calculated an array of weights Or a list of weights for each of those layers So we can just go through each of those layer IDs And create an object which is going to store which is you know got the hook function forward hook function to store the activations and so in our Forward then we can just go ahead and call the forward paths of our model With the target so the target is the high res image we're trying to create right and so the reason we do that is because that's going to then call that hook function and store in self dot save features the Activations we want right now. We're going to need to do that for our Confinet output as well Right so we need to clone these because otherwise the confinet output is going to go ahead and just plobber what we already had Okay, so now we can do the same thing for the confinet output which is the input to the loss function All right, and so now we've got those two things We can zip them all together along with the weights So we've got inputs targets and weights, and then we can do the L1 loss between the inputs and the targets and multiply by the layer weights the only other thing I do is I also grab the Pixel loss right, but I weight it down quite a bit right and most people don't do this I haven't seen papers that do this, but in my opinion It's maybe a little bit better Because you've got you know The perceptual content loss activation stuff, but you know at the really finest level it also cares about the individual pixels Okay, so that's our loss function we create our super resolution resnet telling it how much to scale up by and Then we're going to do our ICNR initialization Of that pixel shuffle Convolution right so there's really like it. This is very very boring code. I actually stole it from from somebody else Like literally all it does is just say okay. You've got some weight tensor X That you want to initialize So we're going to treat it as if it had shape divided by so number of features divided by scale squared features in practice so like you know This might be two squared before because we actually want to copy You know we want to just keep one set of them and then copy them four times So we divide it by four and we create something of that size and we initialize that with by default timing normal initialization and Then we just make scale squared copies of it Okay, and the rest of it's just Kind of moving axes around a little bit alright, so that's going to return a new weight matrix where each Each initialized sub kernel is repeated r squared or scale squared times So that details don't matter very much all that matters here is that I just looked through to find what was the actual layer the conf layer just before the pixel shuffle and Stored it away, and then I called IC and R on its weight matrix To get my new weight matrix, and then I copied that new weight matrix back into that layer Okay so as you can see I Went to quite a bit of trouble I went to quite a lot of trouble in this exercise to really try to implement all the best practices Right and I kind of tend to do things a bit one extreme or the other I show you like a really hacky version That only slightly works or I go to the nth degree to make it work really well right and So this is a version where I'm claiming that this is pretty much a state-of-the-art Implementation it's a competition winning or at least my re-implementation of a competition winning approach And the reason I'm doing that is because I think like this is one of those rare papers where they actually Get a lot of the details right, and I kind of want you to get a feel of What does it feel like to get all the details right? And you know remember getting the details right is the difference between this hideous blurry mess You know and this really pretty exquisite result Okay, so So we're gonna have a to do data parallel on that again We're going to set our criterion to be feature loss using our VGG model grab the first few blocks And these are a set of layer weights that I found worked pretty well Do a learning rate finder Fit it for a while And I feel it around for a little while trying to kind of get some of these details, right? But here's the my favorite part of the paper Is what happens next now that we've done it for Scale equals to progressive resizing Alright, so progressive resizing is the trick that let us get the best single computer result for image net training on Dawn bench So this idea is starting small gradually making bigger I only know of two papers that have used this idea one is the progressive resizing of GANs paper Which allows training of very high resolution GANs and the other one? Is the EDSR paper and the cool thing about progressive resizing is not only are your Earlier epochs assuming you've got two by two smaller four times faster You can also make the batch size maybe three or four times bigger But more importantly, they're going to generalize better because you're feeding your model different size images during training right So we were able to train like half as many epochs For image net as most people so our epochs were faster and there were fewer of them So progressive resizing is something that You know, particularly if you're training from scratch I'm not so sure if it's useful for fine-tuning transfer learning, but if you're training from scratch You probably want to do nearly all the time So the next step is to go all the way back to the top right and change to For scale 32 batch size Right like restart so I saved the model before I do that go back and that's why there's a little bit of Fussing around in here with reloading because what I needed to do now is I needed to load my saved model back in But there's a slight issue Which is I now have one more up sampling layer than I used to have to go from two by two to four by four my little My little loop here is Now looping through twice Is now looping through twice not once and therefore it's added an extra con but an extra pixel shuffle so how am I going to load in weights through a different network and The answer is that I use a very handy thing in pytorch, which is if I call that this is what this is basically what Learn load calls behind the scenes Load state dict if I pass this parameter strict equals false If I pass in this parameter strict equals false Then it says okay if you can't Fill in all of the layers just fill in the layers you can So after loading the model back in this way We're going to end up with something where it's loaded in all the layers that it can and the that one comb layer That's new is going to be randomly initialized right and so then I Freeze all my layers and then unfreeze that up sampling part Right and then use ICNR on my newly added extra layer Right and then I can go ahead and learn again And so then the rest is the same so if you're trying to replicate this don't just run this top to bottom Okay, realize it involves a bit of jumping around Okay Yeah, the longer you train the better it gets I Ended up training it for about 10 hours, but you'll still get very good results Much more quickly if you're less patient And so we can try it out and here is the result here is my pixelated bird and look here It's like totally random e pixels and here's the up sampled version It's like it's literally invented Color at coloration, but it figured out what kind of bird it is right and it knows what these feathers are meant to look like and So it has imagined a set of feathers which are compatible with these exact pixels Which is like genius like same here, right? There's no way you can tell what these blue dots are meant to represent But if you know that this kind of bird has an array of feathers here You know that's what they must be right and then you can figure out where the feathers would have to be such that when they were Pixilated they'll end up in these spots All right, so it's like literally reverse engineered Like given its knowledge of this exact species of bird how it would have to have looked to create this output and so this is like So amazing it also knows From all the kind of signs around it that this area here Was was almost certainly blurred out. So it's actually reconstructed blurred vegetation And you know if it if it hadn't have done all of those things It wouldn't have got such a good loss function right because in the end it had to match You know the the activations saying like oh, there's a feather over here And it's kind of fluffy looking and it's you know in this direction and all that All right, well that brings us to the end of super resolution Don't forget to check out the ask Jeremy anything thread and we will do some ask Jeremy anything after the break Let's see you back here at quarter to eight. I Okay So we are going to do Ask Jeremy anything Rachel will tell me the most voted up of your questions. Yes, Rachel What are the future plans for fast AI in this course will there be a part three if there is a part three I would really love to take it Oh, I'm not quite sure I it's always hard to guess I Hope there'll be some kind of follow-up last year after part two one of the students Started up a weekly book club going through the Ian Goodfellow deep learning book and Ian actually came in and Presented quite a few of the chapters and other people like there's somebody an expert who presented every chapter That was really that was like a really cool part three and for a large extent it will depend on on you the community to come up with ideas and help make them happen and Yeah, and I'm definitely keen to To help I've got a bunch of ideas, but I'm nervous about saying them because I'm not sure which ones will happen in which ones won't but the more Support I have in making things happen that you want to happen from you the more likely they are To happen what was your experience like starting down the path of entrepreneurship? Have you always been an entrepreneur did you start out at a start out at a big company and transition to a startup? Did you go from academia to startups or startups to academia? No, I was definitely not in academia. I'm totally a fake academic I I I started at McKinsey and Company, which is a strategy firm when I was 18 Which meant I couldn't really go to university so I didn't really turn up and then yeah I spent eight years in business helping really big companies on strategic questions Always wanted to be an entrepreneur plan to only spend two years in McKinsey Only thing I really regret in my life was not sticking to that plan and wasting eight years instead So two years would have been perfect but yeah, then I went into entrepreneurship started two companies in Australia and The best part about that was that I didn't get any funding So all the money that I made was mine or the decisions were mine and my you know in my partners You know, I focused entirely on on profit and product and customer and service Where else I find in San Francisco, I'm glad you know, I'm glad I came here and so The two of us from you know came here for Kaggle Anthony and I and raised, you know Ridiculous amount of money 11 million dollars for this really new company That was really interesting, but it's also really distracting, you know trying to worry about scaling and These sees wanting to see what your business development plans are and also just not having any real need to actually make a profit And yeah So I had a bit of the same problem at analytic Where I again raised a lot of money 15 million dollars pretty quickly And yeah a lot of distractions So yeah, I think you know trying to Bootstrap your own company And focus on making money by selling something at a profit at a profit and then you know Plowing that back into the company. It worked really well, right because Within like five years You know, we were making a profit from three months in and within five years We were making you know enough of a profit not just to pay all of us in their own wages but also to see my bank account growing and after ten years sold it for a big chunk of money not enough that a VC would be excited but Enough that I didn't have to worry about money again, you know So I think yeah bootstrapping a company is something which people in the Bay Area at least don't seem to appreciate how good our idea that is If you were 25 years old today and still know what you know, where would you be looking to use AI? What are you working on right now or looking to work on in the next two years? You should ignore the last part of that I won't even answer it It doesn't matter where I'm looking like the what you should do is Leverage your knowledge about your domain. So like one of the main reasons we do this is to get people who have backgrounds in Whatever recruiting, you know oilfield surveys Journalism activism, whatever right and solve your problems It'll be really obvious to you what your problems are and it'll be really obvious to you what data you have and where to find it Those are all the bits that for everybody else. It's really hard So people who start out with like, oh, I know deep learning now I'll go and find something to apply it to Basically never succeed Where else people who are like, oh, I've been spending 25 years doing specialized recruiting for legal firms And I know that the key issue is this thing and I know that this piece of data totally solves it And so I'm just going to do that now and I already know who to call to actually start selling it to you know, they're the ones who who tend to win so Yeah, and and and you know if you if you've done nothing but like Academic stuff then it's more maybe about your your hobbies and interests, you know, so everybody has hobbies the main thing I would say is Please don't focus on building tools for data scientists to use or for software engineers to use because every data scientist Knows about the market of data scientists for us only you know about the market for you know Analyzing oil survey well logs or you know understanding audiology studies or Whatever it is that you do Given what you've shown us about applying transfer learning from image recognition to NLP There looks to be a lot of value in paying attention to all of the developments that happen across the whole Machine learning field and that if you were to focus in one area you might miss out on some great advances in other concentrations How do you stay aware of all the advancements across the field while still having time to dig in deep to your specific domains? Yeah, that's awesome. I mean that's kind of the message of this course one of the key messages this course. Yeah, it's like Lots of good works being done in different places and people are so specialized most people don't know about it Like if I can get state-of-the-art results in NLP within six months of starting to look at NLP and I Think that says more about NLP than it does about me frankly So Yeah, it's kind of like the entrepreneurship thing It's like you you pick the areas that you see that you know about and kind of Transfer stuff like oh we could use deep learning to solve this problem or in this case like we could use You know This can idea of computer vision to solve that problem So things like Trent the other may transfer learning I'm sure there's like a thousand things opportunities for you to do in other fields to do what Sebastian and I did NLP with NLP classification So the short answer to your question is the way to stay ahead of what's going on would be to follow my feed of Twitter favorites and My approach is to follow lots and lots of people on Twitter and put them into the Twitter favorites for you but literally I every time I come across something interesting I click favorite and There are two reasons I do it The first is that when the next course comes along I go through my favorites to find which things I want to study The second is so that you know you can do the same thing and then You know, which do you go deep into it almost doesn't matter like I find every time I look at something it turns out to Be super interesting and important. So it was like pick something which is like You feel like solving that problem would be actually useful for some reason and it doesn't seem to be very popular which is kind of the opposite of what everybody else does everybody else works on the problems which everybody else is already working on because they're the ones that seem popular and I Don't know. I can't quite understand this chain of thinking but it seems to be very common Is deep learning and overkill to use on tabular data when is it better to use deep learning instead of machine learning on tabular data? Is that a real question or did you just put that there so that I would point out that Rachel Thomas just wrote an article So Yes, so Rachel's just written about this and and Rachel and I spent a long time talking about it and short answer is we think it's great to use deep learning on tabular data Actually of all the rich complex important and interesting things that appear in Rachel's Twitter stream covering everything from the genocide of the Hringa Through to the latest ethics violations in AI companies the one by far that got the most Attention and engagement from the community was her question about is it called tabular data or structured data? So Yeah, ask computer buys people how to name things and you'll get plenty of interest Yeah, and there's some really good links here to stuff from instacart and Pinterest and other folks who have done some good work in this area Any of you that went to the Data Institute conference will have seen Jeremy Stanley's presentation about the really cool work they did at instacart Yes, Rachel. So I relied heavily on lessons three and four from part one and writing this post. So yes Much of it may be familiar to you. Yeah um Rachel asked me during the post like how to tell whether you should use a Decision tree ensemble like GBM or random forest or or a neural net and my answer is I still don't know Nobody to my nobody I'm aware of has done that research in any particularly meaningful way so there's a Question to be answered there. I guess My approach has been to try to make both of those things as accessible as possible through the faster Yeah library so you can try them both to both and see what works. That's that's what I do And that was it for the top-loaded questions, thank you Okay, so just quickly to go from Super resolution to style transfer is kind of oh Oh, I think I missed the one on reinforcement learning and Reinforcement learning popularity has been on a gradual rise in the recent past What's your take on reinforcement learning? Would fast AI consider covering some ground and popular RL techniques in the future? I'm still not a believer in reinforcement learning I think it's a An interesting problem to solve but it's not at all clear that we have a good way of solving this problem So the problem it really is that delayed credit problem So, you know, I want to learn to play pong I've moved up or down and three minutes later. I find out whether I won the game of pong Which actions I took were actually useful and so to me the idea of calculating the gradients of those inputs with respect You know the app sorry the greatest of the output with respect to those inputs The credit is so delayed that those derivatives don't seem very interesting And there's been you know, they're kind of been I get this question quite regularly in every one of these four courses so far I've always said the same thing I'm rather pleased that finally recently there's been some results showing that actually basically random search often does better than reinforcement learning So basically what's happened is? very well funded companies with vast amounts of computational power throw all of it at reinforcement learning problems and get good results and people then say oh it's because of the reinforcement learning rather than the vast amounts of compute power or They use extremely thoughtful and clever algorithms like a combination of convolutional neural nets and Monte Carlo tree search like they did with the AlphaGo stuff To get great results and people Incorrectly say oh, that's because of reinforcement learning when it wasn't really reinforcement learning at all so I'm very interested like in solving these kind of More generic optimization type problems rather than just prediction problems, and that's what these delayed credit problems tend to look like But I don't think we've yet got Good enough best practices that I have anything I'm Ready to teach and say like I'm going to teach you this thing because I think it's still going to be useful next year so we'll keep watching and And yeah, see see what happens Okay So we're going to now turn the super resolution network basically into a Style transfer network, and we'll do this pretty quickly We basically already have something so here's my input image, and I'm going to have some loss function And I've got some neural net again So instead of a neural net that does a whole lot of compute and then does up sampling at the end Our input this time is just as big as our output So we're going to do some down sampling first and then our compute and then our ups Okay, so that's the first change we're going to make is going to add some down sampling So some stride to convolution layers to the front of our network The second is rather than just comparing Y C and X to the same thing here right so we're going to basically say Our input image should look like itself By the end and so specifically we're going to compare it by checking it through VGG and comparing it at one of the content at one of the activation layers and Then its style should look like some Painting which brought to you just like we did with the Gatties approach by looking at the gram matrix correspondence at a number of layers So that's basically it and so that That ought to be super straightforward It's really just combining two things we've already done And so all this code at the start is identical except. We don't have high res and low res We just have one size 256 All this is the same My model is the same one thing I did here is I Made I did not Do any kind of fancy best practices for this one at all? I'm partly because there doesn't seem to be any like there's been very little follow-up in this approach compared to This the super resolution stuff and we'll talk about why in a moment So you'll see this is like much more normal looking, you know, I've got batch norm layers I Don't have the scaling factor here You know, I don't have a pixel shuffle It's just using a normal up sampling followed by one by one conge Right, so it's kind of it's just more normal one thing they mentioned in the paper is they had a lot of problems with Zero padding creating artifacts and the way they solved that was by adding 40 pixels of reflection padding at the start So I did the same thing and then they used zero padding in their convolutions in their res blocks Now if you've got zero padding in your convolution in your res blocks Then that means that your the two parts of your resnet won't add up anymore Because you've lost a pixel from each side on each of your two convolutions So my my res sequential has become res sequential center and I've removed the last two pixels On each side of those good cells. Okay. So other than that, this is basically the same as what we had before So then we can bring in our starry night picture we can resize it We can throw it through our transformations Just to make the Method a little bit easier for my brain to handle. I took my Transformation image which after transform transform style image which after transformations is 3 by 2 5 6 by 2 5 6 and I made a mini batch My batch size is 24 24 copies of it that just makes it a little bit easier to do the kind of batch Arithmetic and without worrying about some of the broadcasting. They're not really 24 copies. I used NP broadcast to to Basically fake 24 piece Okay, so just like before we create a VGG grab the last block This time we're going to use all of these layers so we keep everything up to the 43rd layer And so now our combined loss is going to add together a content loss for the third block plus the gram loss for all of our blocks with different weights and so the gram loss and again kind of going back to everything being as like Normal as possible. I've gone back to using MSE here Basically what happened is I had a lot of trouble getting this to train properly So I gradually removed trick after trick and eventually just went okay. I'm just going to leave make it as as bland as possible Last Week's gram matrix Was wrong by the way it only worked for a batch size of one and we only had a batch size of one so that was fine I was using matrix multiply Which meant that every batch was big being compared to every other batch You actually need to use batch matrix multiply, which does a matrix multiply per batch So that's something to be aware of there, okay So so I've got my gram matrices. I do my MSE loss between the gram matrices. I weight them my style weights So I create that ResNet so I create my style my combined loss So I create my style my combined loss passing in the VGG network Passing in the block IDs passing in the transformed Starry night image and so you'll see the very start here I do a forward pass through my VGG model with that starry night image in order that I can save The features for it. Okay now notice It's really important now that I don't do any data augmentation augmentation because I've saved the style features for a particular You know non augmented version And so if I augmented it it might make some minor problems But that's fine because I've got all of image net to deal with I don't really need to do data augmentation anyway Okay, so I've got my loss function and I can go ahead and fit and there's really nothing clever here at all at the end I Have my sum layers equals false so I can see what each part looks like and see that they're reasonably balanced and I can finally Pop it out So I mentioned that should be pretty easy and yet it took me about four days because it just I Just found this incredibly Fiddly to actually get it to work So like when I finally got up in the morning, I said to Rachel guess what? They're trained correctly Rachel was like I never thought that was gonna happen It just it just looked awful all the time and it's really about getting the exact right mix of content I'll say the style loss of the mix of the layers of the style loss and that the worst part was it takes a really long time to train the damn CNN and I don't didn't really know how long to train it before before I decided it wasn't doing well like should I just train it for longer or What? And I don't know all the little details Didn't seem to like slightly change it but just like it would totally fall apart all the time. So I kind of mentioned this partly to say like Just remember the final answer you see here is After me driving myself crazy or weak of it nearly always not working until finally the last minute it finally does even for things which just seemed like they couldn't possibly be difficult because they're just combining two things we already have working The other is like to be careful about how we interpret what authors claim Yeah, so It was so fiddly getting this style transfer To work and like after doing it it left me thinking Why did I bother because now I've got something that takes hours? to create a network that can turn any kind of photo into one specific style It just seems very unlikely I would want that for anything like about the only reason I could think that being useful Would be to like do some arty stuff on a video we're able to turn every frame into some style like it's incredibly Neat thing to what to do But you know when I looked at the paper that you know the table saying like oh, we're a thousand times faster than the Gaddy's approach Which is like it's just such an obviously meaningless thing to say and such an incredibly kind of Misleading thing to say because it ignores all the hours of training for each individual style and I don't know I find this frustrating because like a Groups like this Stanford group clearly no better or ought to know better, but still I guess the academic community kind of encourages people to make these ridiculously grand claims and it also completely ignores this incredibly sensitive fiddly training process so You know this paper was just so well accepted when it came out you know I remember everybody getting on Twitter and being like wow you know these Stanford people have found this way of doing style transfer a thousand times faster and Clearly you know all the people saying this were like all like top researchers in the field but clearly like none of them actually understood it because nobody said You know I don't see why this is remotely useful and also I tried it and it was incredibly fiddly to get it all to work And so it's not until like what is this now like 18 months later or something that I finally coming back to earth and kind Of thinking like wait a minute this is kind of stupid and so So this is the answer I think to the question of like well Why haven't people done follow-ups on this to like create really amazing best practices and better approaches like with a super resolution part of the paper? And I think the answer is because it's done So I think This part of the paper is clearly not done You know and it's been improved and improved and improved and now We have great super resolution, and I think we can derive from that great noise reduction great colorization great You know slant removal Great Interactive artifact removal or whatever else so I think There's a lot of really cool Techniques here. It's also leveraging a lot of stuff that we've been learning and getting better and better at Okay, so then finally let's talk about Segmentation this is from the famous cam vid Data set which is a classic example of an academic segmentation data set and basically you can see what we do is we start with a picture there actually video frames in this data set like here and We construct we have some labels where They're not actually colors that each one has an ID and the IDs are matched colors So like red might be one purple might be two light pink might be Three and so all the buildings You know one class or the cars or another class all the people or another class All the road is another class and so what we're actually doing here is multi-class classification for every pixel Okay, and so you can see sometimes that multi-class classification Really is quite tricky. There's you know like like these branches Although sometimes the labels are really not that great. You know, this is very coarse as you can see So here are traffic lights So that's what we're gonna do we're gonna do this is a segmentation and so it's a lot like bounding boxes Okay, but you know rather than just finding, you know a box around each thing We're actually going to label every single pixel with its class and really that's actually a lot easier because It fits our CNN style so nicely that we basically we could create any CNN Where the output is an n by m grid? Containing the integers from 0 to C where there are C categories and then we can use cross entropy loss with a softmax activation And we're done Right. So like I could actually stop the class there and you can go and use exactly the approaches you've learned in like lessons one And two and you'll get a perfectly okay result Right. So the first thing to say is like this is not actually a terribly hard thing to do But we're gonna try and do it really well And so let's start by doing it the really simple way and we're going to use the Kaggle carvana Competition so you Google capital carvana to find it. You can download it with the Kaggle API as per usual And basically there's a train folder containing a bunch of images Which is the independent variable and a train masks folder that contains a dependent variable and they look like this Here's the is one of the independent variable And Here's one of the dependent variable. Okay. So in this case just like cats and dogs we're going simple rather than doing multi-class classification We're going to do binary classification that of course multi-class is just the more general version, you know Categorical cross entropy your binary cross entropy. Okay, so there's no differences conceptually. So we've got this is just you know zeros and ones Where else this is a regular image? So in order to do this well It would really help to know what cars look like right because you know really what we just want to do is Figure out this is a car and this orientation and then color You know white pixels where we expect the car to be based on the picture and our understanding of what cars look like The original data set came with these CSV files as well I don't really use them for very much other than getting a list of images from them Each each image after the car ID has a 0 1 0 2 etc Of which I've printed out all 16 of them for one car and as you can see if basically those numbers are the 16 orientations of one car So there that is I don't think anybody in this competition actually used this Orientation information, I believe they all kept the cars Images just treated them separately These images are pretty big like over a thousand by a thousand in size and Just opening the JPEGs and resizing them is slow so I Processed them all also open CV can't handle Gift files so I converted them. Yes, Rachel the question How would somebody get these masks for training initially mechanical Turk or something? Yeah Yeah, just a lot of boring work You know probably some tools that help you with a bit of edge snapping and stuff so that the human can kind of do it Roughly and then just fine-tune the bits it gets wrong Yeah These kinds of labels are expensive, you know, and so one of the things I really want to work on is deep learning enhanced interactive labeling tools because You know, that's clearly something that would help a lot of people Yes, I've got a little section here that you can run if you want to you probably want to which converts the gifts into PNGs So just open it up with a PIL and then save it as PNG because open CV doesn't have gift support And as per usual for this kind of stuff, I do it with a thread pool so I can take advantage of parallel processing and then also Create a separate directory train dash 128 and train masks 128 which contains the 128 by 128 Resized versions of them and this is the kind of stuff that keeps you sane if you do it early in the process So anytime you get a new data set, you know seriously think about creating a you know smaller version to make life Fast anytime you find yourself waiting on your computer, you know, try and think of a way to create a smaller version So yeah, after you grab it from Kaggle, you probably want to run this stuff go away have lunch come back and when you're done You'll have these smaller directories, which we're going to use here 128 by 128 pixel versions to start with So Here's a cool trick if you use the same axis object to plot an image twice and the second time you use alpha which as you might know means Transparency in the computer vision world then you can actually plot the mask over the top of the photo And so there is a nice way to see all the masks on top of the photos for all of the cars in one group This is the same match files data set. We've seen twice already This is all the same code we're used to and here's something important though if we had something that was in the training set good at this image and Then the validation had that image that would kind of be cheating because it's the same car so we use a contiguous set of Car IDs and since each set is a set of 16 we make sure that's evenly divisible by 16 So we make sure that our validation set contains different car IDs to our training set This is the kind of stuff which you've got to be careful of on Kaggle, it's not so bad You'll know about it because you'll submit your result and you'll get a very different result on your leaderboard compared to your validation set but in the real world You won't know until you put it in production and send your company bankrupt and lose your job So you might want to think carefully about your validation set in that case So here we're going to use transform type dot classification It's basically the same as transform type dot pixel But if you think about it we with a pixel version if we rotate a little bit Then we probably want to like average the pixels in between the two but the classification obviously we we don't we use nearest neighbor So the slight difference there Also for classification, you know lighting doesn't kick in normalization doesn't kick in to the dependent variable Okay, they're already square images so we don't have to do any cropping So here you can see different versions of the augmented, you know, they're moving around a bit and they're rotating a bit and so forth Yeah, I get a lot of questions kind of like during our study group and stuff about like how do I debug things and fix things that aren't working and like I I Never have a great answer other than like every time I fix a problem It's because of stuff like this that I do all the time, you know I just always print out everything as I go And then the one thing that I screw up always turns out to be the one thing that I forgot to check So yeah, the more of this kind of thing you can do the better if you're not looking at all of your intermediate results You're gonna have troubles. Okay So given that we want Something that knows what cars look like we probably want to start with a pre-trained image net network So we're gonna start with resnet 34 and so with cognitive builder We can grab our resnet 34 and we can add a custom head and so the custom head is going to be something that up samples a bunch of times and We're going to do things really dumb for now, which is we're just going to do comm transpose 2d batch norm value, okay and so here's like This is what I'm saying. Like you could any of you could have built this without looking at any of this Or at least like you have the information from previous classes. There's nothing new at all Okay, and so at the very end we have a single filter Okay, and now that's going to give us something which is batch size by 1 by 128 by 128 But we want something which is batch size by 128 by 128. So we have to remove that unit axis So I've got a lambda layer here lambda layers are incredibly helpful, right? Because without the lambda layer here, which is simply removing that unit axis by just indexing into it at 0 Without the lambda layer. I would have to have created a custom class with a custom forward method and so forth But by creating a lambda layer that does like the one custom bit I can now just chuck it in the sequential and so that just makes life easier. So The pytorch people are kind of snooty about This approach lambda layer is actually something that's part of the fast AI library Not part of the pytorch library and like literally people on the pytorch discussion board like yes, we could give people this yes, it is only a single line of code, but then it would like encourage them to use sequential too often so There you go. Okay so So this is our custom head, right? so we're gonna have a resident 34 that goes down sample and then a really simple custom head that very quickly up samples and that hopefully will do something and We're going to use accuracy with a threshold of 0.5 to print out metrics And so after a few epochs, we've got 96% accurate. Okay, so is that good is 96% accurate good and Hopefully the answer to your quest that question is it depends What's it for? right and the answer is Kovana wanted this because they wanted to be able to take their car images and Cut them out and paste them on you know, exotic Monte Carlo backgrounds That's Monte Carlo the place not the simulation So To do that. You need a really good mask Right. You don't want to like leave the rear view mirrors behind or like, you know Kind of have one wheel missing or include a little bit of background or something that would look stupid So you would need something very good. So only having 96% of the pixels correct doesn't sound great Right, but we won't really know until we look at it So let's look at it So there's the correct version that we want to cut out That's the 96% accurate version Okay, so like When you look at it, you realize oh, yeah Getting 90% 96% of the pixels accurate is actually easy because like all the outside bits not car and all the inside bit is car And really very interesting bit is the edge Okay, so we need to do better So let's unfreeze because all we've done so far is train the custom here Okay, and let's do more and so after a bit more we've got 99.1% Okay, so is that good? I don't know. Let's take a look and And so actually no, it's totally missed the rear-view vision mirror here and Missed a lot of it here and it's clearly got an edge wrong here. And these things are totally going to matter When we try to cut it out, so it's still not good enough So let's try up scaling and the nice thing is that when we upscale to 512 by 512 Make sure you decrease the batch size because you'll run out of memory You know, here's the true ones And it's quite a lot more This is all identical. It's quite a lot more information there for it to go on so our accuracy increases to 99.4% And things keep getting better, but we've still got quite a few little black blocky bits So let's go to 124 by 124 down to batch size of 4 This is pretty high res now and train a bit more 99.6 99.8 and So now if we look at the masks, they're actually looking Not bad. Okay, that's looking pretty good. All right, so can we do better and the answer is Yes, we can So we're moving from the carvana notebook to the carvana unit notebook now and the unit network is quite magnificent Right, you see With that previous approach our pre trained image net network was being squished down all the way down to 7 by 7 And then expanded out all the way back up to you know, well, it's 2 2 4 Go to 7 by 7 for 1 or 2 4. It's going quite a bit bigger and then expanded out Again all this way which means it has to somehow store all the information about the much bigger version in the small version right and actually Most of the information about the bigger version was really in the original picture anyway So it doesn't seem like a great approach this squishing and unsquishing so the unit idea comes from this fantastic paper where like it was literally invented in this You know very domain specific area of biomedical image segmentation But in fact basically every Kaggle winner in in anything even vaguely related to segmentation has ended up Using unit it's one of these things that like everybody in Kaggle knows is the best practice but in more of academic circles Like even now this has been around for a couple of years at least a lot of people still don't realize But it's like this is by far the best approach And here's the basic idea here's the downward path right where we basically start Start at 572 by 532 in this case and then kind of half the grid size half the grid size half the grid size half the grid size right and then here's the upward path where we double the grid size double double double double But the Thing that we also do is we take You know at every point where we've halved the grid size We actually copy those activations over to the upward path and and concatenate them together And so you can see here these red blobs of max pooling operations the green blobs are upward sampling and then these gray bits here are copying Right and so we copy and concat so basically in other words the input image after a couple of Poms is copied over to the output Concatenated together and so now we get to use all of the information has gone through all the down and all the up Plus also a slightly modified version of the input pixels Right and a slightly modified version of one thing down from the input pixels because they came out through here right, so we have like all of the richness of going all the way down and up but also like a Slightly less cost version and a slightly less cost version and then it's really kind of simple version and they can all be combined together Okay, and so that's unit such a cool idea so here we are in the in the Carvana unit notebook. Well, this is the same code as before and at the start I've got a Simple up sample version just to kind of show you again the non unit version this time I'm going to add in something called the dice metric dice is very similar as you see to Jakarta or I over you it's just a minor difference. It's basically intersection over union with a Minor tweak and the reason we're going to use dice is that's the metric that the Kaggle competition used and it's kind of It's a little bit harder to get a high dice score than a high accuracy Because it's really looking at like what the overlap of the correct pixels are with with your pixels It's pretty similar So in the Kaggle competition people that were doing okay We're getting about 99.6 dice and the winners were about 99.7 dice So here's our standard up sample This is all as before and so now we can check our dice metric and so you can see on dice metric We're getting like nine six eight at 128 by 128 and so that's not Great. Okay, so that's the real So let's try unit and I'm calling it unit ish because as per usual I'm creating my own Somewhat hacky version right kind of trying to keep things as similar to what you're used to as possible and doing things that I think makes sense and So there should be plenty of opportunity for you to At least make this more authentically unit by looking at the exact kind of grid sizes and like see how here The size is going down a little bit. So they're obviously not adding any padding And then they're doing here. They've got some cropping going on. There's a few differences, right? But one of the things is because I want to take advantage of transfer learning That means I can't quite use unit. So here's another big opportunity is what if you create the unit down path and then add a classifier on the end and then train that on image net and You've now got an image net trained classifier Which is specifically designed to be a good backbone for unit right, and then you should be able to now come back and Get pretty close to winning this old competition That's not it's actually not that old. It's fairly recent competition because you know that pre-trained network Didn't exist before but if you think about like what Yolo v3 did it's basically that right then they created dark net They pre-trained it on image net and then they used it as the basis for their founding boxes so again this kind of idea of Pre-training things which are designed not just for Your classification but defined for other things is just something that nobody's nobody's done yet. And as we've shown But as we've shown, you know, you can train image net for 25 bucks in three hours Yeah, so And if people in the community are interested in doing this, you know, hopefully I'll have credits I can help you with as well So if you do, you know the work to get it set up and give me a script I can probably run it for you So for now though, we don't have that so we're going to use resnet So So we're basically going to start with this With get base and so base is our base network and that was defined back up in this first section, right so get base Is going to be something that calls whatever this is and this is resnet 34 so we're going to grab our resnet 34 and Cut model is the first thing that our con net builder does it basically removes everything from the adaptive pulling onwards And so that gives us back the backbone of resnet 34. Okay, so get base is going to give us back our resnet 34 Backbone okay And then we're going to take that resnet 34 backbone and turn it into a I call it a unit 34 right, so what that's going to do is it's going to save that resnet that we passed in and Then we're going to use a forward hook just like before to save the results at the second fourth fifth and sixth blocks Which as before is the basically before each stride to convolution? Then we're going to create a bunch of these things We're calling unit blocks and the unit block basically says so these unit blocks are these things these unit blocks So the the unit block tells us you know well we have to tell it how many things are coming from the from the kind of Previous layer that we're up sampling how many are coming across and then how many do we want to come out? right and so the amount coming across is entirely defined by Whatever the base network was right it's like whatever whatever the downward path was We need that many layers And so this is a little bit awkward and actually one of our Master students here Karam has actually created something called a Dynamic unit that you'll find in fastai Unit dynamic unit and it actually calculates this all for you and automatically creates the whole unit from your base model It's got some minor quirk still that I want to fix by the time the videos out It'll definitely be working and I will at least have a notebook showing how to use it and possibly a traditional video but For now, you know you'll just have to go through and do it yourself You can easily see it just by once you've got a resnet You can just go you know just type in its name, and it'll print out all the layers, and you can see how big How many activations there are in each block? Or you could even Have it printed out for you for each for each block automatically anyway. I just did this manually and so the unit block is Works like this So you said okay about this penny coming up from the previous layer I've got this penny coming across this X. I'm using across across from the downward path This is the amount I want coming out now What I do is I then say okay We're going to create a certain amount of convolutions from the upward path and a certain amount from the cross path And so I'm going to be concatenating them together, so let's divide the number we want out by 2 Right and so we're going to have our cross convolution take our cross path and create number out divided by 2 and Then the upward path is going to be a comm transpose 2d right because we want to increase up sample and again here we've got the number in divided by 2 and Then at the end I just concatenate those together All right, so I've got an upward sample. I've got a cross convolution. I concatenate the two together right and so that's all a unit block is and so that's actually a pretty easy module to create and so then in my forward path I Need to pass to the forward of the of the unit block the upward path and the cross path So the upward path is just wherever I'm up to so far All right, but then the cross path is Whatever the value is of whatever the activations are that I stored on the way down, right? So as I come up, it's the last set of saved features that I need first And then as I gradually keep going up further and further and further eventually. It's the first set of features Okay, and so There are some more tricks we can do to make this a little bit better, but this is this is a good start, right? So if we try this so the simple up sampling approach looked horrible right and had a dice of 968 a Unit with everything else identical except we've now got these unit blocks has a dice of 985 right so that's like we've kind of halved the error With with everything else exactly the same and more to the point you can look at it. This is actually looking somewhat car-like compared to our non unit equivalent, which is just a blog no because You know trying to do this through down and up paths. Just it's just asking too much. You know where else when we actually provide The downward path pixels at every point it can actually start to create something car ish so At the end of that we'll go dot close to again remove those SFS Features taking up GPU memory go to a smaller batch size a higher size And you can see the dice coefficients really going up. This is just so notice here. I'm learning. I'm loading in Right the 128 by 128 Version of the network okay, so we're doing this progressive resizing trick again So that gets us 99 3 and then unfreeze to get to 99 4 and you can see it's now Looking pretty good. Okay go down to a batch size of 4 size of 1 or 2 4 Load in what we just did with the 512 Takes us to 99 5 unfreeze Texas to 99 we'll call that 99 6 5 9 9 and as You can see that actually looks good right in accuracy terms 99.8 to You know you can see this is Looking like something you could just about use to cut out. I think To you know at this point. There's a couple of minor tweaks. We can do to get up to 99.7 But really the key thing then I think is just maybe to do a little a few Bit of smoothing maybe or a little bit of post-processing You can go and have a look at the Carvana winners blogs And see some of these tricks, but as I say the difference between where we're at 99.6 and What the winners got of 99.7? You know is it's not heaps and So really that just the unit on its own pretty much Pretty much solves that problem Okay, so that's it so the last thing I wanted to mention is now to come all the way back to bounding boxes Because you might remember I said our our bounding box Model was still not doing very well on small objects So hopefully you might be able to guess where I'm going to go with this which is that for the bounding box model Remember how we we we had at different grid cells we spat out outputs of their model and It was those earlier ones with the small grids sizes that weren't very good Well, how do we fix it? You net it right let's have an upward path with cross connections right and so then we're just going to do a unit and then spit them out of that because now those those finer grid cells Have all of the information of that path and that path and that path and that path to leverage now of course This is deep learning so that means you can't write a paper saying We just used you net for bounding boxes you have to invent a new word So this is called feature pyramid networks or FPNs. Okay, and like That literally the paper this is part of the retina net paper, which is actually a no It's not the retina bit paper that was used in the retina net paper it was you it was it created an earlier paper specifically about FPNs and like If memory says correctly, they did briefly cite the unit paper, but they kind of made it sound like it was this vaguely slightly connected thing that maybe some people could consider slightly useful, but it really FPNs as units, okay I don't have an implementation of it to show you But you know it'll be a fun thing maybe for some of us to try and some of us have already some I Haven't yet, but I know some of the students have been trying so to get it working well on the forums So yeah interesting thing to try so I think a couple of couple of things to look at after this class As well as the other things I mentioned would be playing around with FPNs And also maybe trying Kerim's dynamic unit They would both be interesting things to look at. All right, so So you guys have all been through 14 lessons of me talking at you now, so I'm sorry about that Thanks for putting up with me You know, I think It's it it's you're going to find it hard to find people who actually are as know as much about Training neural networks and practice as you do It'll be really easy for you to overestimate how Capable all these other people are and underestimate how capable you are. So like the main thing I say is like please practice please just because You don't have this constant thing getting you to come back here every Monday night now It's very easy to kind of lose that momentum So find ways to keep it, you know you know organize a study group, you know or a book reading group or get together some friends and work on a project or You know do something More than just deciding I want to keep working on X like it's going to need to involve probably unless you're the kind of person Who's super motivated and you know that whenever you decide to do something it happens That's not me. Right? It's like I know something to happen. I have to like say Yes, David in October. I will absolutely teach that course And it's like okay Better actually write some material like that's the only way I can get stuff to happen So we've got a great community there on the forums if people have ideas two ways to make it better Please tell me you know if you think you can help with You know if you want to create some new forum or moderate it in some different way or whatever just let me know Right you can always PM me And there's a lot of projects going on through github as well lots of stuff So yeah, I hope to see you all back here at something else and thanks so much for joining me on this journey", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.76, "text": " Welcome to the last lesson lesson 14", "tokens": [4027, 281, 264, 1036, 6898, 6898, 3499], "temperature": 0.0, "avg_logprob": -0.23475451012180276, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.022619016468524933}, {"id": 1, "seek": 0, "start": 7.6000000000000005, "end": 13.8, "text": " We're going to be looking at image segmentation today amongst other things but before we do a", "tokens": [492, 434, 516, 281, 312, 1237, 412, 3256, 9469, 399, 965, 12918, 661, 721, 457, 949, 321, 360, 257], "temperature": 0.0, "avg_logprob": -0.23475451012180276, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.022619016468524933}, {"id": 2, "seek": 0, "start": 15.36, "end": 17.76, "text": " Bit of show-and-tell from last week", "tokens": [9101, 295, 855, 12, 474, 12, 83, 898, 490, 1036, 1243], "temperature": 0.0, "avg_logprob": -0.23475451012180276, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.022619016468524933}, {"id": 3, "seek": 0, "start": 19.76, "end": 26.92, "text": " Elena Harley did something really interesting which was she tried finding out what would happen if you did cycle GAN on just three or four", "tokens": [39603, 34921, 630, 746, 534, 1880, 597, 390, 750, 3031, 5006, 484, 437, 576, 1051, 498, 291, 630, 6586, 460, 1770, 322, 445, 1045, 420, 1451], "temperature": 0.0, "avg_logprob": -0.23475451012180276, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.022619016468524933}, {"id": 4, "seek": 2692, "start": 26.92, "end": 31.8, "text": " Hundred images and I really like these projects where people just go to Google image search", "tokens": [32869, 5267, 293, 286, 534, 411, 613, 4455, 689, 561, 445, 352, 281, 3329, 3256, 3164], "temperature": 0.0, "avg_logprob": -0.17732384740089885, "compression_ratio": 1.762081784386617, "no_speech_prob": 5.649079321301542e-05}, {"id": 5, "seek": 2692, "start": 31.8, "end": 37.5, "text": " You know using the the API or one of the libraries out there some of our students have created some very good libraries for", "tokens": [509, 458, 1228, 264, 264, 9362, 420, 472, 295, 264, 15148, 484, 456, 512, 295, 527, 1731, 362, 2942, 512, 588, 665, 15148, 337], "temperature": 0.0, "avg_logprob": -0.17732384740089885, "compression_ratio": 1.762081784386617, "no_speech_prob": 5.649079321301542e-05}, {"id": 6, "seek": 2692, "start": 37.800000000000004, "end": 39.800000000000004, "text": " interacting with Google images API", "tokens": [18017, 365, 3329, 5267, 9362], "temperature": 0.0, "avg_logprob": -0.17732384740089885, "compression_ratio": 1.762081784386617, "no_speech_prob": 5.649079321301542e-05}, {"id": 7, "seek": 2692, "start": 39.88, "end": 46.260000000000005, "text": " Download a bunch of stuff that they're interested in in this case some photos and some stained glass windows and", "tokens": [32282, 257, 3840, 295, 1507, 300, 436, 434, 3102, 294, 294, 341, 1389, 512, 5787, 293, 512, 39924, 4276, 9309, 293], "temperature": 0.0, "avg_logprob": -0.17732384740089885, "compression_ratio": 1.762081784386617, "no_speech_prob": 5.649079321301542e-05}, {"id": 8, "seek": 2692, "start": 47.88, "end": 53.06, "text": " Yeah with three or four hundred photos of that she trained a model she trained actually a few different models", "tokens": [865, 365, 1045, 420, 1451, 3262, 5787, 295, 300, 750, 8895, 257, 2316, 750, 8895, 767, 257, 1326, 819, 5245], "temperature": 0.0, "avg_logprob": -0.17732384740089885, "compression_ratio": 1.762081784386617, "no_speech_prob": 5.649079321301542e-05}, {"id": 9, "seek": 5306, "start": 53.06, "end": 58.36, "text": " This is what I particularly liked and as you can see with quite a small number of images, you know, she gets some very nice", "tokens": [639, 307, 437, 286, 4098, 4501, 293, 382, 291, 393, 536, 365, 1596, 257, 1359, 1230, 295, 5267, 11, 291, 458, 11, 750, 2170, 512, 588, 1481], "temperature": 0.0, "avg_logprob": -0.17706250698766976, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.3630993635160848e-05}, {"id": 10, "seek": 5306, "start": 59.300000000000004, "end": 61.06, "text": " stained-glass effects", "tokens": [39924, 12, 28851, 5065], "temperature": 0.0, "avg_logprob": -0.17706250698766976, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.3630993635160848e-05}, {"id": 11, "seek": 5306, "start": 61.06, "end": 66.18, "text": " So I thought that was a interesting example of using pretty small amounts of data", "tokens": [407, 286, 1194, 300, 390, 257, 1880, 1365, 295, 1228, 1238, 1359, 11663, 295, 1412], "temperature": 0.0, "avg_logprob": -0.17706250698766976, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.3630993635160848e-05}, {"id": 12, "seek": 5306, "start": 66.18, "end": 69.34, "text": " That was readily available that she was able to download pretty quickly", "tokens": [663, 390, 26336, 2435, 300, 750, 390, 1075, 281, 5484, 1238, 2661], "temperature": 0.0, "avg_logprob": -0.17706250698766976, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.3630993635160848e-05}, {"id": 13, "seek": 5306, "start": 70.16, "end": 73.38, "text": " And there's more information about that on the forum if you're interested", "tokens": [400, 456, 311, 544, 1589, 466, 300, 322, 264, 17542, 498, 291, 434, 3102], "temperature": 0.0, "avg_logprob": -0.17706250698766976, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.3630993635160848e-05}, {"id": 14, "seek": 5306, "start": 76.08, "end": 80.76, "text": " Yeah, it's interesting to wonder about what kinds of things people will come up with with this kind of", "tokens": [865, 11, 309, 311, 1880, 281, 2441, 466, 437, 3685, 295, 721, 561, 486, 808, 493, 365, 365, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.17706250698766976, "compression_ratio": 1.6527777777777777, "no_speech_prob": 1.3630993635160848e-05}, {"id": 15, "seek": 8076, "start": 80.76, "end": 81.92, "text": " a", "tokens": [257], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 16, "seek": 8076, "start": 81.92, "end": 85.52000000000001, "text": " Generative model. It's clearly a great artistic medium", "tokens": [15409, 1166, 2316, 13, 467, 311, 4448, 257, 869, 17090, 6399], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 17, "seek": 8076, "start": 86.48, "end": 88.48, "text": " It's clearly a great medium for", "tokens": [467, 311, 4448, 257, 869, 6399, 337], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 18, "seek": 8076, "start": 89.16000000000001, "end": 91.16000000000001, "text": " forgeries and fakeries I", "tokens": [337, 32217, 293, 33647, 21659, 286], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 19, "seek": 8076, "start": 92.2, "end": 94.2, "text": " Wonder what other kinds of things people will", "tokens": [13224, 437, 661, 3685, 295, 721, 561, 486], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 20, "seek": 8076, "start": 94.80000000000001, "end": 99.80000000000001, "text": " Realize they can do with these kind of generative models. I think audio is going to be the next big", "tokens": [8467, 1125, 436, 393, 360, 365, 613, 733, 295, 1337, 1166, 5245, 13, 286, 519, 6278, 307, 516, 281, 312, 264, 958, 955], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 21, "seek": 8076, "start": 100.64, "end": 102.72, "text": " area and also very like", "tokens": [1859, 293, 611, 588, 411], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 22, "seek": 8076, "start": 103.52000000000001, "end": 106.38000000000001, "text": " interactive type stuff that Nvidia just", "tokens": [15141, 2010, 1507, 300, 46284, 445], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 23, "seek": 8076, "start": 106.96000000000001, "end": 108.96000000000001, "text": " released a paper showing a", "tokens": [4736, 257, 3035, 4099, 257], "temperature": 0.0, "avg_logprob": -0.2176297851230787, "compression_ratio": 1.6203703703703705, "no_speech_prob": 1.7502197806607e-05}, {"id": 24, "seek": 10896, "start": 108.96, "end": 112.88, "text": " interactive kind of photo repair tool where you just like", "tokens": [15141, 733, 295, 5052, 10535, 2290, 689, 291, 445, 411], "temperature": 0.0, "avg_logprob": -0.23330721041051353, "compression_ratio": 1.5659574468085107, "no_speech_prob": 1.473831980547402e-05}, {"id": 25, "seek": 10896, "start": 113.6, "end": 116.83999999999999, "text": " brush over an object and it replaces it with", "tokens": [5287, 670, 364, 2657, 293, 309, 46734, 309, 365], "temperature": 0.0, "avg_logprob": -0.23330721041051353, "compression_ratio": 1.5659574468085107, "no_speech_prob": 1.473831980547402e-05}, {"id": 26, "seek": 10896, "start": 117.63999999999999, "end": 124.0, "text": " You know a deep learning generated replacement very nicely those kinds of interactive tools. I think will be very interesting, too", "tokens": [509, 458, 257, 2452, 2539, 10833, 14419, 588, 9594, 729, 3685, 295, 15141, 3873, 13, 286, 519, 486, 312, 588, 1880, 11, 886], "temperature": 0.0, "avg_logprob": -0.23330721041051353, "compression_ratio": 1.5659574468085107, "no_speech_prob": 1.473831980547402e-05}, {"id": 27, "seek": 10896, "start": 126.6, "end": 131.32, "text": " So before we talk about segmentation we've got some stuff to finish up from last time", "tokens": [407, 949, 321, 751, 466, 9469, 399, 321, 600, 658, 512, 1507, 281, 2413, 493, 490, 1036, 565], "temperature": 0.0, "avg_logprob": -0.23330721041051353, "compression_ratio": 1.5659574468085107, "no_speech_prob": 1.473831980547402e-05}, {"id": 28, "seek": 10896, "start": 131.88, "end": 135.16, "text": " Which is that we looked at doing style transfer?", "tokens": [3013, 307, 300, 321, 2956, 412, 884, 3758, 5003, 30], "temperature": 0.0, "avg_logprob": -0.23330721041051353, "compression_ratio": 1.5659574468085107, "no_speech_prob": 1.473831980547402e-05}, {"id": 29, "seek": 13516, "start": 135.16, "end": 137.32, "text": " by actually directly", "tokens": [538, 767, 3838], "temperature": 0.0, "avg_logprob": -0.3034654235839844, "compression_ratio": 1.5816326530612246, "no_speech_prob": 6.048800969438162e-06}, {"id": 30, "seek": 13516, "start": 138.32, "end": 140.32, "text": " optimizing", "tokens": [40425], "temperature": 0.0, "avg_logprob": -0.3034654235839844, "compression_ratio": 1.5816326530612246, "no_speech_prob": 6.048800969438162e-06}, {"id": 31, "seek": 13516, "start": 141.0, "end": 146.56, "text": " pixels and you know like with most of the things in part two it's not so much that I'm wanting you to", "tokens": [18668, 293, 291, 458, 411, 365, 881, 295, 264, 721, 294, 644, 732, 309, 311, 406, 370, 709, 300, 286, 478, 7935, 291, 281], "temperature": 0.0, "avg_logprob": -0.3034654235839844, "compression_ratio": 1.5816326530612246, "no_speech_prob": 6.048800969438162e-06}, {"id": 32, "seek": 13516, "start": 147.8, "end": 149.8, "text": " understand", "tokens": [1223], "temperature": 0.0, "avg_logprob": -0.3034654235839844, "compression_ratio": 1.5816326530612246, "no_speech_prob": 6.048800969438162e-06}, {"id": 33, "seek": 13516, "start": 150.24, "end": 153.2, "text": " Style transfer per se but the kind of idea of", "tokens": [27004, 5003, 680, 369, 457, 264, 733, 295, 1558, 295], "temperature": 0.0, "avg_logprob": -0.3034654235839844, "compression_ratio": 1.5816326530612246, "no_speech_prob": 6.048800969438162e-06}, {"id": 34, "seek": 15320, "start": 153.2, "end": 165.11999999999998, "text": " Optimizing your input directly and using activations as part of a loss function is really the key kind of takeaway here", "tokens": [35013, 3319, 428, 4846, 3838, 293, 1228, 2430, 763, 382, 644, 295, 257, 4470, 2445, 307, 534, 264, 2141, 733, 295, 30681, 510], "temperature": 0.0, "avg_logprob": -0.20056837348527806, "compression_ratio": 1.6363636363636365, "no_speech_prob": 7.071658728818875e-06}, {"id": 35, "seek": 15320, "start": 166.44, "end": 169.07999999999998, "text": " So it's interesting then to kind of see the", "tokens": [407, 309, 311, 1880, 550, 281, 733, 295, 536, 264], "temperature": 0.0, "avg_logprob": -0.20056837348527806, "compression_ratio": 1.6363636363636365, "no_speech_prob": 7.071658728818875e-06}, {"id": 36, "seek": 15320, "start": 169.88, "end": 171.88, "text": " What is effectively the follow-up paper?", "tokens": [708, 307, 8659, 264, 1524, 12, 1010, 3035, 30], "temperature": 0.0, "avg_logprob": -0.20056837348527806, "compression_ratio": 1.6363636363636365, "no_speech_prob": 7.071658728818875e-06}, {"id": 37, "seek": 15320, "start": 171.88, "end": 177.56, "text": " You know not from the same people but the paper that kind of came next in the in the sequence of these kind of vision", "tokens": [509, 458, 406, 490, 264, 912, 561, 457, 264, 3035, 300, 733, 295, 1361, 958, 294, 264, 294, 264, 8310, 295, 613, 733, 295, 5201], "temperature": 0.0, "avg_logprob": -0.20056837348527806, "compression_ratio": 1.6363636363636365, "no_speech_prob": 7.071658728818875e-06}, {"id": 38, "seek": 15320, "start": 177.56, "end": 179.56, "text": " generative models with this one from", "tokens": [1337, 1166, 5245, 365, 341, 472, 490], "temperature": 0.0, "avg_logprob": -0.20056837348527806, "compression_ratio": 1.6363636363636365, "no_speech_prob": 7.071658728818875e-06}, {"id": 39, "seek": 17956, "start": 179.56, "end": 183.44, "text": " Justin Johnson and folks at Stanford and", "tokens": [11320, 9779, 293, 4024, 412, 20374, 293], "temperature": 0.0, "avg_logprob": -0.1953513503074646, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.8448132550474838e-06}, {"id": 40, "seek": 17956, "start": 184.96, "end": 187.16, "text": " It it actually does the same thing", "tokens": [467, 309, 767, 775, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.1953513503074646, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.8448132550474838e-06}, {"id": 41, "seek": 17956, "start": 187.96, "end": 193.68, "text": " Style transfer, but it does it in a different way rather than optimizing the pixels", "tokens": [27004, 5003, 11, 457, 309, 775, 309, 294, 257, 819, 636, 2831, 813, 40425, 264, 18668], "temperature": 0.0, "avg_logprob": -0.1953513503074646, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.8448132550474838e-06}, {"id": 42, "seek": 17956, "start": 194.12, "end": 201.32, "text": " we're going to go back to something much more familiar and optimize some weights and so specifically we're going to train a model which", "tokens": [321, 434, 516, 281, 352, 646, 281, 746, 709, 544, 4963, 293, 19719, 512, 17443, 293, 370, 4682, 321, 434, 516, 281, 3847, 257, 2316, 597], "temperature": 0.0, "avg_logprob": -0.1953513503074646, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.8448132550474838e-06}, {"id": 43, "seek": 17956, "start": 201.64000000000001, "end": 203.64000000000001, "text": " learns to take a photo and", "tokens": [27152, 281, 747, 257, 5052, 293], "temperature": 0.0, "avg_logprob": -0.1953513503074646, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.8448132550474838e-06}, {"id": 44, "seek": 17956, "start": 204.52, "end": 206.52, "text": " translate it into a", "tokens": [13799, 309, 666, 257], "temperature": 0.0, "avg_logprob": -0.1953513503074646, "compression_ratio": 1.6682926829268292, "no_speech_prob": 1.8448132550474838e-06}, {"id": 45, "seek": 20652, "start": 206.52, "end": 210.64000000000001, "text": " photo on this in the style of a particular artwork so each", "tokens": [5052, 322, 341, 294, 264, 3758, 295, 257, 1729, 15829, 370, 1184], "temperature": 0.0, "avg_logprob": -0.22010301173418417, "compression_ratio": 1.609865470852018, "no_speech_prob": 3.6688400086859474e-06}, {"id": 46, "seek": 20652, "start": 211.4, "end": 214.12, "text": " Conv-net will learn to produce one", "tokens": [2656, 85, 12, 7129, 486, 1466, 281, 5258, 472], "temperature": 0.0, "avg_logprob": -0.22010301173418417, "compression_ratio": 1.609865470852018, "no_speech_prob": 3.6688400086859474e-06}, {"id": 47, "seek": 20652, "start": 214.76000000000002, "end": 216.76000000000002, "text": " kind of style", "tokens": [733, 295, 3758], "temperature": 0.0, "avg_logprob": -0.22010301173418417, "compression_ratio": 1.609865470852018, "no_speech_prob": 3.6688400086859474e-06}, {"id": 48, "seek": 20652, "start": 218.8, "end": 220.04000000000002, "text": " Now", "tokens": [823], "temperature": 0.0, "avg_logprob": -0.22010301173418417, "compression_ratio": 1.609865470852018, "no_speech_prob": 3.6688400086859474e-06}, {"id": 49, "seek": 20652, "start": 220.04000000000002, "end": 225.84, "text": " It turns out that getting to that point. There's an intermediate point which is I actually think kind of more", "tokens": [467, 4523, 484, 300, 1242, 281, 300, 935, 13, 821, 311, 364, 19376, 935, 597, 307, 286, 767, 519, 733, 295, 544], "temperature": 0.0, "avg_logprob": -0.22010301173418417, "compression_ratio": 1.609865470852018, "no_speech_prob": 3.6688400086859474e-06}, {"id": 50, "seek": 20652, "start": 226.8, "end": 231.86, "text": " More useful and takes us halfway there, which is something called super resolution", "tokens": [5048, 4420, 293, 2516, 505, 15461, 456, 11, 597, 307, 746, 1219, 1687, 8669], "temperature": 0.0, "avg_logprob": -0.22010301173418417, "compression_ratio": 1.609865470852018, "no_speech_prob": 3.6688400086859474e-06}, {"id": 51, "seek": 20652, "start": 232.04000000000002, "end": 234.76000000000002, "text": " So we're actually going to start with super resolution", "tokens": [407, 321, 434, 767, 516, 281, 722, 365, 1687, 8669], "temperature": 0.0, "avg_logprob": -0.22010301173418417, "compression_ratio": 1.609865470852018, "no_speech_prob": 3.6688400086859474e-06}, {"id": 52, "seek": 23476, "start": 234.76, "end": 238.92, "text": " Because then we'll build on top of super resolution to finish off the style transfer", "tokens": [1436, 550, 321, 603, 1322, 322, 1192, 295, 1687, 8669, 281, 2413, 766, 264, 3758, 5003], "temperature": 0.0, "avg_logprob": -0.20310174335132947, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.6797189346107189e-06}, {"id": 53, "seek": 23476, "start": 240.0, "end": 245.95999999999998, "text": " Conv-net based style transfer and so super resolution is where we take a low res image", "tokens": [2656, 85, 12, 7129, 2361, 3758, 5003, 293, 370, 1687, 8669, 307, 689, 321, 747, 257, 2295, 725, 3256], "temperature": 0.0, "avg_logprob": -0.20310174335132947, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.6797189346107189e-06}, {"id": 54, "seek": 23476, "start": 245.95999999999998, "end": 248.04, "text": " we're going to take 72 by 72 and", "tokens": [321, 434, 516, 281, 747, 18731, 538, 18731, 293], "temperature": 0.0, "avg_logprob": -0.20310174335132947, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.6797189346107189e-06}, {"id": 55, "seek": 23476, "start": 248.88, "end": 253.28, "text": " Up scale it to a larger image 288 by 288 in our case", "tokens": [5858, 4373, 309, 281, 257, 4833, 3256, 7562, 23, 538, 7562, 23, 294, 527, 1389], "temperature": 0.0, "avg_logprob": -0.20310174335132947, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.6797189346107189e-06}, {"id": 56, "seek": 23476, "start": 255.28, "end": 262.08, "text": " Trying to create, you know a higher res image that that looks as real as possible", "tokens": [20180, 281, 1884, 11, 291, 458, 257, 2946, 725, 3256, 300, 300, 1542, 382, 957, 382, 1944], "temperature": 0.0, "avg_logprob": -0.20310174335132947, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.6797189346107189e-06}, {"id": 57, "seek": 26208, "start": 262.08, "end": 264.03999999999996, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.19350223881857737, "compression_ratio": 1.6575875486381324, "no_speech_prob": 1.963788918146747e-06}, {"id": 58, "seek": 26208, "start": 264.03999999999996, "end": 267.32, "text": " So this is a pretty challenging thing to do because it's 72 by 72", "tokens": [407, 341, 307, 257, 1238, 7595, 551, 281, 360, 570, 309, 311, 18731, 538, 18731], "temperature": 0.0, "avg_logprob": -0.19350223881857737, "compression_ratio": 1.6575875486381324, "no_speech_prob": 1.963788918146747e-06}, {"id": 59, "seek": 26208, "start": 267.32, "end": 273.88, "text": " There's not that much information about a lot of the details and the cool thing is that we're going to do it in a way", "tokens": [821, 311, 406, 300, 709, 1589, 466, 257, 688, 295, 264, 4365, 293, 264, 1627, 551, 307, 300, 321, 434, 516, 281, 360, 309, 294, 257, 636], "temperature": 0.0, "avg_logprob": -0.19350223881857737, "compression_ratio": 1.6575875486381324, "no_speech_prob": 1.963788918146747e-06}, {"id": 60, "seek": 26208, "start": 274.12, "end": 276.12, "text": " As we tend to do with vision models", "tokens": [1018, 321, 3928, 281, 360, 365, 5201, 5245], "temperature": 0.0, "avg_logprob": -0.19350223881857737, "compression_ratio": 1.6575875486381324, "no_speech_prob": 1.963788918146747e-06}, {"id": 61, "seek": 26208, "start": 276.52, "end": 284.0, "text": " Which is not tied to the input size so you could totally then take this model that and apply it to a 288 by 288", "tokens": [3013, 307, 406, 9601, 281, 264, 4846, 2744, 370, 291, 727, 3879, 550, 747, 341, 2316, 300, 293, 3079, 309, 281, 257, 7562, 23, 538, 7562, 23], "temperature": 0.0, "avg_logprob": -0.19350223881857737, "compression_ratio": 1.6575875486381324, "no_speech_prob": 1.963788918146747e-06}, {"id": 62, "seek": 26208, "start": 284.0, "end": 286.0, "text": " Image you get something that's", "tokens": [29903, 291, 483, 746, 300, 311], "temperature": 0.0, "avg_logprob": -0.19350223881857737, "compression_ratio": 1.6575875486381324, "no_speech_prob": 1.963788918146747e-06}, {"id": 63, "seek": 26208, "start": 286.08, "end": 289.76, "text": " Four times bigger on each side so 16 times bigger than that", "tokens": [7451, 1413, 3801, 322, 1184, 1252, 370, 3165, 1413, 3801, 813, 300], "temperature": 0.0, "avg_logprob": -0.19350223881857737, "compression_ratio": 1.6575875486381324, "no_speech_prob": 1.963788918146747e-06}, {"id": 64, "seek": 28976, "start": 289.76, "end": 291.36, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.2779954657497176, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.2252595499594463e-06}, {"id": 65, "seek": 28976, "start": 291.36, "end": 297.88, "text": " And often it even kind of works better at that level because you're really introducing a lot of a lot of detail", "tokens": [400, 2049, 309, 754, 733, 295, 1985, 1101, 412, 300, 1496, 570, 291, 434, 534, 15424, 257, 688, 295, 257, 688, 295, 2607], "temperature": 0.0, "avg_logprob": -0.2779954657497176, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.2252595499594463e-06}, {"id": 66, "seek": 28976, "start": 297.88, "end": 304.15999999999997, "text": " Into the finer details, and you could really print out a high resolution print of something which earlier on was a pixelated", "tokens": [23373, 264, 39130, 4365, 11, 293, 291, 727, 534, 4482, 484, 257, 1090, 8669, 4482, 295, 746, 597, 3071, 322, 390, 257, 19261, 770], "temperature": 0.0, "avg_logprob": -0.2779954657497176, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.2252595499594463e-06}, {"id": 67, "seek": 28976, "start": 307.12, "end": 309.12, "text": " So this is the", "tokens": [407, 341, 307, 264], "temperature": 0.0, "avg_logprob": -0.2779954657497176, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.2252595499594463e-06}, {"id": 68, "seek": 28976, "start": 309.15999999999997, "end": 311.15999999999997, "text": " notebook called enhance and", "tokens": [21060, 1219, 11985, 293], "temperature": 0.0, "avg_logprob": -0.2779954657497176, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.2252595499594463e-06}, {"id": 69, "seek": 28976, "start": 312.24, "end": 314.24, "text": " It is a lot like that kind of", "tokens": [467, 307, 257, 688, 411, 300, 733, 295], "temperature": 0.0, "avg_logprob": -0.2779954657497176, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.2252595499594463e-06}, {"id": 70, "seek": 28976, "start": 315.2, "end": 317.2, "text": " CSI style", "tokens": [9460, 40, 3758], "temperature": 0.0, "avg_logprob": -0.2779954657497176, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.2252595499594463e-06}, {"id": 71, "seek": 31720, "start": 317.2, "end": 322.71999999999997, "text": " enhancement where we're going to take something that appears like the information is just not there and we kind of", "tokens": [40776, 689, 321, 434, 516, 281, 747, 746, 300, 7038, 411, 264, 1589, 307, 445, 406, 456, 293, 321, 733, 295], "temperature": 0.0, "avg_logprob": -0.17236186490200534, "compression_ratio": 1.8055555555555556, "no_speech_prob": 1.1478639862616546e-05}, {"id": 72, "seek": 31720, "start": 323.32, "end": 327.71999999999997, "text": " Invent it but the the confidence is going to learn to invent it in a way", "tokens": [682, 2475, 309, 457, 264, 264, 6687, 307, 516, 281, 1466, 281, 7962, 309, 294, 257, 636], "temperature": 0.0, "avg_logprob": -0.17236186490200534, "compression_ratio": 1.8055555555555556, "no_speech_prob": 1.1478639862616546e-05}, {"id": 73, "seek": 31720, "start": 327.71999999999997, "end": 332.84, "text": " That's consistent with the information that is there so hopefully you know it's kind of inventing the right information", "tokens": [663, 311, 8398, 365, 264, 1589, 300, 307, 456, 370, 4696, 291, 458, 309, 311, 733, 295, 7962, 278, 264, 558, 1589], "temperature": 0.0, "avg_logprob": -0.17236186490200534, "compression_ratio": 1.8055555555555556, "no_speech_prob": 1.1478639862616546e-05}, {"id": 74, "seek": 31720, "start": 333.52, "end": 336.48, "text": " one of the really nice things about this kind of", "tokens": [472, 295, 264, 534, 1481, 721, 466, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.17236186490200534, "compression_ratio": 1.8055555555555556, "no_speech_prob": 1.1478639862616546e-05}, {"id": 75, "seek": 31720, "start": 337.0, "end": 344.08, "text": " Problem is that we can create our own data set as big as we like without any labeling requirements", "tokens": [11676, 307, 300, 321, 393, 1884, 527, 1065, 1412, 992, 382, 955, 382, 321, 411, 1553, 604, 40244, 7728], "temperature": 0.0, "avg_logprob": -0.17236186490200534, "compression_ratio": 1.8055555555555556, "no_speech_prob": 1.1478639862616546e-05}, {"id": 76, "seek": 34408, "start": 344.08, "end": 349.96, "text": " Because we can easily create a low res image from a high res image just by down sampling our images", "tokens": [1436, 321, 393, 3612, 1884, 257, 2295, 725, 3256, 490, 257, 1090, 725, 3256, 445, 538, 760, 21179, 527, 5267], "temperature": 0.0, "avg_logprob": -0.24037303924560546, "compression_ratio": 1.6096256684491979, "no_speech_prob": 1.3287708497955464e-06}, {"id": 77, "seek": 34408, "start": 350.71999999999997, "end": 352.35999999999996, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.24037303924560546, "compression_ratio": 1.6096256684491979, "no_speech_prob": 1.3287708497955464e-06}, {"id": 78, "seek": 34408, "start": 352.35999999999996, "end": 357.71999999999997, "text": " Something I would love some of you to try during the week would be to do other types of", "tokens": [6595, 286, 576, 959, 512, 295, 291, 281, 853, 1830, 264, 1243, 576, 312, 281, 360, 661, 3467, 295], "temperature": 0.0, "avg_logprob": -0.24037303924560546, "compression_ratio": 1.6096256684491979, "no_speech_prob": 1.3287708497955464e-06}, {"id": 79, "seek": 34408, "start": 358.4, "end": 361.24, "text": " image to image translation where you can invent", "tokens": [3256, 281, 3256, 12853, 689, 291, 393, 7962], "temperature": 0.0, "avg_logprob": -0.24037303924560546, "compression_ratio": 1.6096256684491979, "no_speech_prob": 1.3287708497955464e-06}, {"id": 80, "seek": 34408, "start": 362.03999999999996, "end": 365.88, "text": " kind of late labels invent your dependent variable for example", "tokens": [733, 295, 3469, 16949, 7962, 428, 12334, 7006, 337, 1365], "temperature": 0.0, "avg_logprob": -0.24037303924560546, "compression_ratio": 1.6096256684491979, "no_speech_prob": 1.3287708497955464e-06}, {"id": 81, "seek": 36588, "start": 365.88, "end": 373.28, "text": " D skewing you know so either recognize things that have been rotated by 90 degrees or better still", "tokens": [413, 8756, 7904, 291, 458, 370, 2139, 5521, 721, 300, 362, 668, 42146, 538, 4289, 5310, 420, 1101, 920], "temperature": 0.0, "avg_logprob": -0.25112535924087337, "compression_ratio": 1.599009900990099, "no_speech_prob": 4.565907602227526e-06}, {"id": 82, "seek": 36588, "start": 373.44, "end": 376.08, "text": " that have been rotated by 5 degrees and", "tokens": [300, 362, 668, 42146, 538, 1025, 5310, 293], "temperature": 0.0, "avg_logprob": -0.25112535924087337, "compression_ratio": 1.599009900990099, "no_speech_prob": 4.565907602227526e-06}, {"id": 83, "seek": 36588, "start": 376.96, "end": 378.6, "text": " straighten them", "tokens": [32777, 552], "temperature": 0.0, "avg_logprob": -0.25112535924087337, "compression_ratio": 1.599009900990099, "no_speech_prob": 4.565907602227526e-06}, {"id": 84, "seek": 36588, "start": 378.6, "end": 384.9, "text": " Colorization so turn make a bunch of images into black and white and learn to put the color back again", "tokens": [10458, 2144, 370, 1261, 652, 257, 3840, 295, 5267, 666, 2211, 293, 2418, 293, 1466, 281, 829, 264, 2017, 646, 797], "temperature": 0.0, "avg_logprob": -0.25112535924087337, "compression_ratio": 1.599009900990099, "no_speech_prob": 4.565907602227526e-06}, {"id": 85, "seek": 36588, "start": 386.96, "end": 389.08, "text": " Noise reduction, you know maybe", "tokens": [44821, 11004, 11, 291, 458, 1310], "temperature": 0.0, "avg_logprob": -0.25112535924087337, "compression_ratio": 1.599009900990099, "no_speech_prob": 4.565907602227526e-06}, {"id": 86, "seek": 36588, "start": 390.08, "end": 391.4, "text": " do a", "tokens": [360, 257], "temperature": 0.0, "avg_logprob": -0.25112535924087337, "compression_ratio": 1.599009900990099, "no_speech_prob": 4.565907602227526e-06}, {"id": 87, "seek": 36588, "start": 391.4, "end": 393.68, "text": " really low quality jpeg save", "tokens": [534, 2295, 3125, 361, 494, 70, 3155], "temperature": 0.0, "avg_logprob": -0.25112535924087337, "compression_ratio": 1.599009900990099, "no_speech_prob": 4.565907602227526e-06}, {"id": 88, "seek": 39368, "start": 393.68, "end": 395.68, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.25082219730723987, "compression_ratio": 1.6712962962962963, "no_speech_prob": 5.594263711827807e-06}, {"id": 89, "seek": 39368, "start": 395.68, "end": 398.68, "text": " Learn to put it back to how it should have been", "tokens": [17216, 281, 829, 309, 646, 281, 577, 309, 820, 362, 668], "temperature": 0.0, "avg_logprob": -0.25082219730723987, "compression_ratio": 1.6712962962962963, "no_speech_prob": 5.594263711827807e-06}, {"id": 90, "seek": 39368, "start": 399.2, "end": 401.2, "text": " and so forth or", "tokens": [293, 370, 5220, 420], "temperature": 0.0, "avg_logprob": -0.25082219730723987, "compression_ratio": 1.6712962962962963, "no_speech_prob": 5.594263711827807e-06}, {"id": 91, "seek": 39368, "start": 402.64, "end": 408.40000000000003, "text": " Yeah, maybe taking something that's like in a 16 color palette and put it back to a higher color palette", "tokens": [865, 11, 1310, 1940, 746, 300, 311, 411, 294, 257, 3165, 2017, 15851, 293, 829, 309, 646, 281, 257, 2946, 2017, 15851], "temperature": 0.0, "avg_logprob": -0.25082219730723987, "compression_ratio": 1.6712962962962963, "no_speech_prob": 5.594263711827807e-06}, {"id": 92, "seek": 39368, "start": 408.40000000000003, "end": 412.66, "text": " I think these things are all interesting because they can like be used to", "tokens": [286, 519, 613, 721, 366, 439, 1880, 570, 436, 393, 411, 312, 1143, 281], "temperature": 0.0, "avg_logprob": -0.25082219730723987, "compression_ratio": 1.6712962962962963, "no_speech_prob": 5.594263711827807e-06}, {"id": 93, "seek": 39368, "start": 413.28000000000003, "end": 415.2, "text": " take", "tokens": [747], "temperature": 0.0, "avg_logprob": -0.25082219730723987, "compression_ratio": 1.6712962962962963, "no_speech_prob": 5.594263711827807e-06}, {"id": 94, "seek": 39368, "start": 415.2, "end": 420.44, "text": " You know pictures that you may have taken back on crappy old digital cameras before they were high resolution", "tokens": [509, 458, 5242, 300, 291, 815, 362, 2726, 646, 322, 36531, 1331, 4562, 8622, 949, 436, 645, 1090, 8669], "temperature": 0.0, "avg_logprob": -0.25082219730723987, "compression_ratio": 1.6712962962962963, "no_speech_prob": 5.594263711827807e-06}, {"id": 95, "seek": 42044, "start": 420.44, "end": 425.12, "text": " Or you may have scanned in some old photos that kind of faded or whatever", "tokens": [1610, 291, 815, 362, 45089, 294, 512, 1331, 5787, 300, 733, 295, 36352, 420, 2035], "temperature": 0.0, "avg_logprob": -0.148499984149785, "compression_ratio": 1.7147540983606557, "no_speech_prob": 3.2887221550481627e-06}, {"id": 96, "seek": 42044, "start": 425.12, "end": 429.06, "text": " You know I think it's really useful thing to be able to do and also it's good", "tokens": [509, 458, 286, 519, 309, 311, 534, 4420, 551, 281, 312, 1075, 281, 360, 293, 611, 309, 311, 665], "temperature": 0.0, "avg_logprob": -0.148499984149785, "compression_ratio": 1.7147540983606557, "no_speech_prob": 3.2887221550481627e-06}, {"id": 97, "seek": 42044, "start": 429.06, "end": 432.44, "text": " It's a good project because it's like really similar to what we're doing here", "tokens": [467, 311, 257, 665, 1716, 570, 309, 311, 411, 534, 2531, 281, 437, 321, 434, 884, 510], "temperature": 0.0, "avg_logprob": -0.148499984149785, "compression_ratio": 1.7147540983606557, "no_speech_prob": 3.2887221550481627e-06}, {"id": 98, "seek": 42044, "start": 432.44, "end": 436.48, "text": " But different enough that you'll come come across some interesting challenges on the way. I'm sure", "tokens": [583, 819, 1547, 300, 291, 603, 808, 808, 2108, 512, 1880, 4759, 322, 264, 636, 13, 286, 478, 988], "temperature": 0.0, "avg_logprob": -0.148499984149785, "compression_ratio": 1.7147540983606557, "no_speech_prob": 3.2887221550481627e-06}, {"id": 99, "seek": 42044, "start": 438.76, "end": 444.52, "text": " So I'm going to use some image net again again, you don't need to use all of image net at all", "tokens": [407, 286, 478, 516, 281, 764, 512, 3256, 2533, 797, 797, 11, 291, 500, 380, 643, 281, 764, 439, 295, 3256, 2533, 412, 439], "temperature": 0.0, "avg_logprob": -0.148499984149785, "compression_ratio": 1.7147540983606557, "no_speech_prob": 3.2887221550481627e-06}, {"id": 100, "seek": 42044, "start": 444.52, "end": 449.36, "text": " I just happen to have it lying around you can download the 1% sample of image net from faster faster", "tokens": [286, 445, 1051, 281, 362, 309, 8493, 926, 291, 393, 5484, 264, 502, 4, 6889, 295, 3256, 2533, 490, 4663, 4663], "temperature": 0.0, "avg_logprob": -0.148499984149785, "compression_ratio": 1.7147540983606557, "no_speech_prob": 3.2887221550481627e-06}, {"id": 101, "seek": 44936, "start": 449.36, "end": 453.32, "text": " You can use any set of pictures you have lying around honestly", "tokens": [509, 393, 764, 604, 992, 295, 5242, 291, 362, 8493, 926, 6095], "temperature": 0.0, "avg_logprob": -0.1594075873346612, "compression_ratio": 1.675, "no_speech_prob": 7.183126854215516e-06}, {"id": 102, "seek": 44936, "start": 454.04, "end": 455.6, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.1594075873346612, "compression_ratio": 1.675, "no_speech_prob": 7.183126854215516e-06}, {"id": 103, "seek": 44936, "start": 455.6, "end": 460.96000000000004, "text": " In this case as I say we don't really have labels per se so I'm just going to", "tokens": [682, 341, 1389, 382, 286, 584, 321, 500, 380, 534, 362, 16949, 680, 369, 370, 286, 478, 445, 516, 281], "temperature": 0.0, "avg_logprob": -0.1594075873346612, "compression_ratio": 1.675, "no_speech_prob": 7.183126854215516e-06}, {"id": 104, "seek": 44936, "start": 461.72, "end": 467.56, "text": " Give everything a label of zero just so we can use it with our existing infrastructure more easily", "tokens": [5303, 1203, 257, 7645, 295, 4018, 445, 370, 321, 393, 764, 309, 365, 527, 6741, 6896, 544, 3612], "temperature": 0.0, "avg_logprob": -0.1594075873346612, "compression_ratio": 1.675, "no_speech_prob": 7.183126854215516e-06}, {"id": 105, "seek": 44936, "start": 469.92, "end": 474.32, "text": " Now because I'm in this case pointing at a folder that contains all of image net", "tokens": [823, 570, 286, 478, 294, 341, 1389, 12166, 412, 257, 10820, 300, 8306, 439, 295, 3256, 2533], "temperature": 0.0, "avg_logprob": -0.1594075873346612, "compression_ratio": 1.675, "no_speech_prob": 7.183126854215516e-06}, {"id": 106, "seek": 44936, "start": 474.32, "end": 477.72, "text": " I certainly don't want to wait for all of image net to finish to run an epoch", "tokens": [286, 3297, 500, 380, 528, 281, 1699, 337, 439, 295, 3256, 2533, 281, 2413, 281, 1190, 364, 30992, 339], "temperature": 0.0, "avg_logprob": -0.1594075873346612, "compression_ratio": 1.675, "no_speech_prob": 7.183126854215516e-06}, {"id": 107, "seek": 47772, "start": 477.72, "end": 479.72, "text": " so here I'm just", "tokens": [370, 510, 286, 478, 445], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 108, "seek": 47772, "start": 480.12, "end": 482.12, "text": " Most of the time I would set", "tokens": [4534, 295, 264, 565, 286, 576, 992], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 109, "seek": 47772, "start": 482.28000000000003, "end": 487.56, "text": " Keep percent to like one or two percent and then I just generate a bunch of random numbers", "tokens": [5527, 3043, 281, 411, 472, 420, 732, 3043, 293, 550, 286, 445, 8460, 257, 3840, 295, 4974, 3547], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 110, "seek": 47772, "start": 487.56, "end": 492.32000000000005, "text": " And then I just grab those keep those which are less than 0.02", "tokens": [400, 550, 286, 445, 4444, 729, 1066, 729, 597, 366, 1570, 813, 1958, 13, 12756], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 111, "seek": 47772, "start": 493.04, "end": 495.04, "text": " And so that let's be quickly", "tokens": [400, 370, 300, 718, 311, 312, 2661], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 112, "seek": 47772, "start": 495.48, "end": 496.92, "text": " subsample", "tokens": [2090, 335, 781], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 113, "seek": 47772, "start": 496.92, "end": 498.92, "text": " my rows", "tokens": [452, 13241], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 114, "seek": 47772, "start": 500.76000000000005, "end": 502.76000000000005, "text": " All right, so", "tokens": [1057, 558, 11, 370], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 115, "seek": 47772, "start": 502.96000000000004, "end": 504.96000000000004, "text": " We're going to use", "tokens": [492, 434, 516, 281, 764], "temperature": 0.0, "avg_logprob": -0.2034550772772895, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.157298917562002e-06}, {"id": 116, "seek": 50496, "start": 504.96, "end": 507.68, "text": " VGG 16 and", "tokens": [691, 27561, 3165, 293], "temperature": 0.0, "avg_logprob": -0.2873349598475865, "compression_ratio": 1.4588235294117646, "no_speech_prob": 2.947994744317839e-06}, {"id": 117, "seek": 50496, "start": 508.71999999999997, "end": 514.12, "text": " VGG 16 is something that we haven't really looked at in this class", "tokens": [691, 27561, 3165, 307, 746, 300, 321, 2378, 380, 534, 2956, 412, 294, 341, 1508], "temperature": 0.0, "avg_logprob": -0.2873349598475865, "compression_ratio": 1.4588235294117646, "no_speech_prob": 2.947994744317839e-06}, {"id": 118, "seek": 50496, "start": 515.48, "end": 520.04, "text": " But it's a very simple very simple model where we take a", "tokens": [583, 309, 311, 257, 588, 2199, 588, 2199, 2316, 689, 321, 747, 257], "temperature": 0.0, "avg_logprob": -0.2873349598475865, "compression_ratio": 1.4588235294117646, "no_speech_prob": 2.947994744317839e-06}, {"id": 119, "seek": 50496, "start": 521.3199999999999, "end": 523.0799999999999, "text": " normal", "tokens": [2710], "temperature": 0.0, "avg_logprob": -0.2873349598475865, "compression_ratio": 1.4588235294117646, "no_speech_prob": 2.947994744317839e-06}, {"id": 120, "seek": 50496, "start": 523.0799999999999, "end": 525.0799999999999, "text": " presumably three-channel input and", "tokens": [26742, 1045, 12, 339, 11444, 4846, 293], "temperature": 0.0, "avg_logprob": -0.2873349598475865, "compression_ratio": 1.4588235294117646, "no_speech_prob": 2.947994744317839e-06}, {"id": 121, "seek": 50496, "start": 525.84, "end": 527.84, "text": " we basically run it through a", "tokens": [321, 1936, 1190, 309, 807, 257], "temperature": 0.0, "avg_logprob": -0.2873349598475865, "compression_ratio": 1.4588235294117646, "no_speech_prob": 2.947994744317839e-06}, {"id": 122, "seek": 50496, "start": 529.36, "end": 531.76, "text": " number of three by three convolutions and", "tokens": [1230, 295, 1045, 538, 1045, 3754, 15892, 293], "temperature": 0.0, "avg_logprob": -0.2873349598475865, "compression_ratio": 1.4588235294117646, "no_speech_prob": 2.947994744317839e-06}, {"id": 123, "seek": 53176, "start": 531.76, "end": 535.88, "text": " Then from time to time we put it through a", "tokens": [1396, 490, 565, 281, 565, 321, 829, 309, 807, 257], "temperature": 0.0, "avg_logprob": -0.27978889614928004, "compression_ratio": 1.453125, "no_speech_prob": 2.521558371881838e-06}, {"id": 124, "seek": 53176, "start": 537.28, "end": 542.24, "text": " two by two max pull and then we do a few more three by three convolutions", "tokens": [732, 538, 732, 11469, 2235, 293, 550, 321, 360, 257, 1326, 544, 1045, 538, 1045, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.27978889614928004, "compression_ratio": 1.453125, "no_speech_prob": 2.521558371881838e-06}, {"id": 125, "seek": 53176, "start": 546.0, "end": 554.4399999999999, "text": " Max pull so on so forth and then this is kind of our backbone I guess", "tokens": [7402, 2235, 370, 322, 370, 5220, 293, 550, 341, 307, 733, 295, 527, 34889, 286, 2041], "temperature": 0.0, "avg_logprob": -0.27978889614928004, "compression_ratio": 1.453125, "no_speech_prob": 2.521558371881838e-06}, {"id": 126, "seek": 55444, "start": 554.44, "end": 556.44, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.17924416202238236, "compression_ratio": 1.7386934673366834, "no_speech_prob": 1.436738898519252e-06}, {"id": 127, "seek": 55444, "start": 561.2, "end": 566.44, "text": " Then we we don't do an average pooling layer an adaptive average pooling layer", "tokens": [1396, 321, 321, 500, 380, 360, 364, 4274, 7005, 278, 4583, 364, 27912, 4274, 7005, 278, 4583], "temperature": 0.0, "avg_logprob": -0.17924416202238236, "compression_ratio": 1.7386934673366834, "no_speech_prob": 1.436738898519252e-06}, {"id": 128, "seek": 55444, "start": 567.12, "end": 569.12, "text": " After a few of these we end up with this", "tokens": [2381, 257, 1326, 295, 613, 321, 917, 493, 365, 341], "temperature": 0.0, "avg_logprob": -0.17924416202238236, "compression_ratio": 1.7386934673366834, "no_speech_prob": 1.436738898519252e-06}, {"id": 129, "seek": 55444, "start": 569.6, "end": 575.6400000000001, "text": " You know seven by seven grid as usual. I think it's about seven by seven by five twelve something like that", "tokens": [509, 458, 3407, 538, 3407, 10748, 382, 7713, 13, 286, 519, 309, 311, 466, 3407, 538, 3407, 538, 1732, 14390, 746, 411, 300], "temperature": 0.0, "avg_logprob": -0.17924416202238236, "compression_ratio": 1.7386934673366834, "no_speech_prob": 1.436738898519252e-06}, {"id": 130, "seek": 55444, "start": 576.24, "end": 579.8000000000001, "text": " And so rather than average pooling we do something different which is we flatten", "tokens": [400, 370, 2831, 813, 4274, 7005, 278, 321, 360, 746, 819, 597, 307, 321, 24183], "temperature": 0.0, "avg_logprob": -0.17924416202238236, "compression_ratio": 1.7386934673366834, "no_speech_prob": 1.436738898519252e-06}, {"id": 131, "seek": 57980, "start": 579.8, "end": 583.92, "text": " the whole thing so that spits out a", "tokens": [264, 1379, 551, 370, 300, 637, 1208, 484, 257], "temperature": 0.0, "avg_logprob": -0.2629941137213456, "compression_ratio": 1.7197802197802199, "no_speech_prob": 2.1568082502199104e-06}, {"id": 132, "seek": 57980, "start": 584.68, "end": 586.0, "text": " very long", "tokens": [588, 938], "temperature": 0.0, "avg_logprob": -0.2629941137213456, "compression_ratio": 1.7197802197802199, "no_speech_prob": 2.1568082502199104e-06}, {"id": 133, "seek": 57980, "start": 586.0, "end": 591.8399999999999, "text": " Vector of activations of size seven times seven times five twelve if memory says correctly and", "tokens": [691, 20814, 295, 2430, 763, 295, 2744, 3407, 1413, 3407, 1413, 1732, 14390, 498, 4675, 1619, 8944, 293], "temperature": 0.0, "avg_logprob": -0.2629941137213456, "compression_ratio": 1.7197802197802199, "no_speech_prob": 2.1568082502199104e-06}, {"id": 134, "seek": 57980, "start": 592.5999999999999, "end": 594.5999999999999, "text": " Then that gets fed into", "tokens": [1396, 300, 2170, 4636, 666], "temperature": 0.0, "avg_logprob": -0.2629941137213456, "compression_ratio": 1.7197802197802199, "no_speech_prob": 2.1568082502199104e-06}, {"id": 135, "seek": 57980, "start": 595.76, "end": 597.76, "text": " Two fully connected layers", "tokens": [4453, 4498, 4582, 7914], "temperature": 0.0, "avg_logprob": -0.2629941137213456, "compression_ratio": 1.7197802197802199, "no_speech_prob": 2.1568082502199104e-06}, {"id": 136, "seek": 57980, "start": 598.3199999999999, "end": 601.3199999999999, "text": " Each one of which has four oh nine six", "tokens": [6947, 472, 295, 597, 575, 1451, 1954, 4949, 2309], "temperature": 0.0, "avg_logprob": -0.2629941137213456, "compression_ratio": 1.7197802197802199, "no_speech_prob": 2.1568082502199104e-06}, {"id": 137, "seek": 60132, "start": 601.32, "end": 609.24, "text": " Activations and then one more fully connected layer which has however many classes", "tokens": [28550, 763, 293, 550, 472, 544, 4498, 4582, 4583, 597, 575, 4461, 867, 5359], "temperature": 0.0, "avg_logprob": -0.2599266639122596, "compression_ratio": 1.494186046511628, "no_speech_prob": 1.2098624893042143e-06}, {"id": 138, "seek": 60132, "start": 610.4000000000001, "end": 613.2800000000001, "text": " So if you think about it the weight matrix", "tokens": [407, 498, 291, 519, 466, 309, 264, 3364, 8141], "temperature": 0.0, "avg_logprob": -0.2599266639122596, "compression_ratio": 1.494186046511628, "no_speech_prob": 1.2098624893042143e-06}, {"id": 139, "seek": 60132, "start": 614.72, "end": 616.72, "text": " Here is", "tokens": [1692, 307], "temperature": 0.0, "avg_logprob": -0.2599266639122596, "compression_ratio": 1.494186046511628, "no_speech_prob": 1.2098624893042143e-06}, {"id": 140, "seek": 60132, "start": 616.7600000000001, "end": 624.08, "text": " Huge it's you know seven by seven by five twelve by four oh nine six and", "tokens": [37043, 309, 311, 291, 458, 3407, 538, 3407, 538, 1732, 14390, 538, 1451, 1954, 4949, 2309, 293], "temperature": 0.0, "avg_logprob": -0.2599266639122596, "compression_ratio": 1.494186046511628, "no_speech_prob": 1.2098624893042143e-06}, {"id": 141, "seek": 60132, "start": 624.5600000000001, "end": 628.44, "text": " It's because of that weight matrix really that VGG", "tokens": [467, 311, 570, 295, 300, 3364, 8141, 534, 300, 691, 27561], "temperature": 0.0, "avg_logprob": -0.2599266639122596, "compression_ratio": 1.494186046511628, "no_speech_prob": 1.2098624893042143e-06}, {"id": 142, "seek": 62844, "start": 628.44, "end": 636.0, "text": " Went out of favor pretty quickly because it takes a lot of memory and takes a lot of computation, and it's really slow and", "tokens": [31809, 484, 295, 2294, 1238, 2661, 570, 309, 2516, 257, 688, 295, 4675, 293, 2516, 257, 688, 295, 24903, 11, 293, 309, 311, 534, 2964, 293], "temperature": 0.0, "avg_logprob": -0.14205267263013263, "compression_ratio": 1.6623931623931625, "no_speech_prob": 9.874604529613862e-07}, {"id": 143, "seek": 62844, "start": 637.2800000000001, "end": 644.32, "text": " There's a lot of redundant stuff going on here because really those five hundred and twelve activations are", "tokens": [821, 311, 257, 688, 295, 40997, 1507, 516, 322, 510, 570, 534, 729, 1732, 3262, 293, 14390, 2430, 763, 366], "temperature": 0.0, "avg_logprob": -0.14205267263013263, "compression_ratio": 1.6623931623931625, "no_speech_prob": 9.874604529613862e-07}, {"id": 144, "seek": 62844, "start": 646.0, "end": 649.4000000000001, "text": " Not that specific to which of those seven by seven grid cells", "tokens": [1726, 300, 2685, 281, 597, 295, 729, 3407, 538, 3407, 10748, 5438], "temperature": 0.0, "avg_logprob": -0.14205267263013263, "compression_ratio": 1.6623931623931625, "no_speech_prob": 9.874604529613862e-07}, {"id": 145, "seek": 62844, "start": 649.4000000000001, "end": 655.84, "text": " They're in right, but when you have this entire weight matrix here of every possible combination", "tokens": [814, 434, 294, 558, 11, 457, 562, 291, 362, 341, 2302, 3364, 8141, 510, 295, 633, 1944, 6562], "temperature": 0.0, "avg_logprob": -0.14205267263013263, "compression_ratio": 1.6623931623931625, "no_speech_prob": 9.874604529613862e-07}, {"id": 146, "seek": 65584, "start": 655.84, "end": 659.08, "text": " It treats all of them uniquely", "tokens": [467, 19566, 439, 295, 552, 31474], "temperature": 0.0, "avg_logprob": -0.24778280153379337, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.2959138732403517e-06}, {"id": 147, "seek": 65584, "start": 659.6, "end": 665.2, "text": " Right and so that can also lead to generalization problems because there's just a lot of weights and so forth", "tokens": [1779, 293, 370, 300, 393, 611, 1477, 281, 2674, 2144, 2740, 570, 456, 311, 445, 257, 688, 295, 17443, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.24778280153379337, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.2959138732403517e-06}, {"id": 148, "seek": 65584, "start": 667.44, "end": 675.4, "text": " My view is that there's you know that the approach that's used in every modern network, which is here. We do an adaptive", "tokens": [1222, 1910, 307, 300, 456, 311, 291, 458, 300, 264, 3109, 300, 311, 1143, 294, 633, 4363, 3209, 11, 597, 307, 510, 13, 492, 360, 364, 27912], "temperature": 0.0, "avg_logprob": -0.24778280153379337, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.2959138732403517e-06}, {"id": 149, "seek": 65584, "start": 676.8000000000001, "end": 678.52, "text": " average pooling", "tokens": [4274, 7005, 278], "temperature": 0.0, "avg_logprob": -0.24778280153379337, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.2959138732403517e-06}, {"id": 150, "seek": 65584, "start": 678.52, "end": 683.84, "text": " Keras that we known as a global average pooling or in fast AI we generally do a concat", "tokens": [591, 6985, 300, 321, 2570, 382, 257, 4338, 4274, 7005, 278, 420, 294, 2370, 7318, 321, 5101, 360, 257, 1588, 267], "temperature": 0.0, "avg_logprob": -0.24778280153379337, "compression_ratio": 1.6106194690265487, "no_speech_prob": 2.2959138732403517e-06}, {"id": 151, "seek": 68384, "start": 683.84, "end": 685.84, "text": " adaptive concat pooling", "tokens": [27912, 1588, 267, 7005, 278], "temperature": 0.0, "avg_logprob": -0.19882293080174646, "compression_ratio": 1.559090909090909, "no_speech_prob": 5.955096639809199e-06}, {"id": 152, "seek": 68384, "start": 687.08, "end": 689.8000000000001, "text": " Which spits it straight down to a 512 long", "tokens": [3013, 637, 1208, 309, 2997, 760, 281, 257, 1025, 4762, 938], "temperature": 0.0, "avg_logprob": -0.19882293080174646, "compression_ratio": 1.559090909090909, "no_speech_prob": 5.955096639809199e-06}, {"id": 153, "seek": 68384, "start": 690.96, "end": 694.0, "text": " Activation I think that's throwing away too much", "tokens": [28550, 399, 286, 519, 300, 311, 10238, 1314, 886, 709], "temperature": 0.0, "avg_logprob": -0.19882293080174646, "compression_ratio": 1.559090909090909, "no_speech_prob": 5.955096639809199e-06}, {"id": 154, "seek": 68384, "start": 695.2800000000001, "end": 696.44, "text": " geometry", "tokens": [18426], "temperature": 0.0, "avg_logprob": -0.19882293080174646, "compression_ratio": 1.559090909090909, "no_speech_prob": 5.955096639809199e-06}, {"id": 155, "seek": 68384, "start": 696.44, "end": 701.32, "text": " So to me probably the correct answer is somewhere in between and would involve some kind of um", "tokens": [407, 281, 385, 1391, 264, 3006, 1867, 307, 4079, 294, 1296, 293, 576, 9494, 512, 733, 295, 1105], "temperature": 0.0, "avg_logprob": -0.19882293080174646, "compression_ratio": 1.559090909090909, "no_speech_prob": 5.955096639809199e-06}, {"id": 156, "seek": 68384, "start": 702.0, "end": 704.0, "text": " factored convolution or some kind of", "tokens": [1186, 2769, 45216, 420, 512, 733, 295], "temperature": 0.0, "avg_logprob": -0.19882293080174646, "compression_ratio": 1.559090909090909, "no_speech_prob": 5.955096639809199e-06}, {"id": 157, "seek": 68384, "start": 704.8000000000001, "end": 706.5600000000001, "text": " tensor decomposition", "tokens": [40863, 48356], "temperature": 0.0, "avg_logprob": -0.19882293080174646, "compression_ratio": 1.559090909090909, "no_speech_prob": 5.955096639809199e-06}, {"id": 158, "seek": 68384, "start": 706.5600000000001, "end": 710.12, "text": " Which yeah, maybe some of us can think about in the coming months", "tokens": [3013, 1338, 11, 1310, 512, 295, 505, 393, 519, 466, 294, 264, 1348, 2493], "temperature": 0.0, "avg_logprob": -0.19882293080174646, "compression_ratio": 1.559090909090909, "no_speech_prob": 5.955096639809199e-06}, {"id": 159, "seek": 71012, "start": 710.12, "end": 713.92, "text": " So for now anyway, we've gone from one extreme", "tokens": [407, 337, 586, 4033, 11, 321, 600, 2780, 490, 472, 8084], "temperature": 0.0, "avg_logprob": -0.20317836191462374, "compression_ratio": 1.6059322033898304, "no_speech_prob": 2.3320601485465886e-06}, {"id": 160, "seek": 71012, "start": 713.92, "end": 719.72, "text": " Which is the adaptive average pooling to the other extreme which is this huge flattened fully connected player?", "tokens": [3013, 307, 264, 27912, 4274, 7005, 278, 281, 264, 661, 8084, 597, 307, 341, 2603, 24183, 292, 4498, 4582, 4256, 30], "temperature": 0.0, "avg_logprob": -0.20317836191462374, "compression_ratio": 1.6059322033898304, "no_speech_prob": 2.3320601485465886e-06}, {"id": 161, "seek": 71012, "start": 720.0, "end": 726.44, "text": " So a couple of things which are interesting about VGG that make it still useful today", "tokens": [407, 257, 1916, 295, 721, 597, 366, 1880, 466, 691, 27561, 300, 652, 309, 920, 4420, 965], "temperature": 0.0, "avg_logprob": -0.20317836191462374, "compression_ratio": 1.6059322033898304, "no_speech_prob": 2.3320601485465886e-06}, {"id": 162, "seek": 71012, "start": 727.8, "end": 730.28, "text": " The first one is that there's there's more", "tokens": [440, 700, 472, 307, 300, 456, 311, 456, 311, 544], "temperature": 0.0, "avg_logprob": -0.20317836191462374, "compression_ratio": 1.6059322033898304, "no_speech_prob": 2.3320601485465886e-06}, {"id": 163, "seek": 71012, "start": 732.12, "end": 735.1, "text": " Interesting layers going on here with", "tokens": [14711, 7914, 516, 322, 510, 365], "temperature": 0.0, "avg_logprob": -0.20317836191462374, "compression_ratio": 1.6059322033898304, "no_speech_prob": 2.3320601485465886e-06}, {"id": 164, "seek": 73510, "start": 735.1, "end": 743.3000000000001, "text": " With most modern networks including the resnet family we the very first layer generally is a 7 by 7", "tokens": [2022, 881, 4363, 9590, 3009, 264, 725, 7129, 1605, 321, 264, 588, 700, 4583, 5101, 307, 257, 1614, 538, 1614], "temperature": 0.0, "avg_logprob": -0.2979233671979206, "compression_ratio": 1.5613207547169812, "no_speech_prob": 2.0261302324797725e-06}, {"id": 165, "seek": 73510, "start": 744.02, "end": 745.94, "text": " pond or", "tokens": [17384, 420], "temperature": 0.0, "avg_logprob": -0.2979233671979206, "compression_ratio": 1.5613207547169812, "no_speech_prob": 2.0261302324797725e-06}, {"id": 166, "seek": 73510, "start": 745.94, "end": 747.26, "text": " something similar", "tokens": [746, 2531], "temperature": 0.0, "avg_logprob": -0.2979233671979206, "compression_ratio": 1.5613207547169812, "no_speech_prob": 2.0261302324797725e-06}, {"id": 167, "seek": 73510, "start": 747.26, "end": 752.8000000000001, "text": " Which means we and that's tried to right which means we throw away half the grid size", "tokens": [3013, 1355, 321, 293, 300, 311, 3031, 281, 558, 597, 1355, 321, 3507, 1314, 1922, 264, 10748, 2744], "temperature": 0.0, "avg_logprob": -0.2979233671979206, "compression_ratio": 1.5613207547169812, "no_speech_prob": 2.0261302324797725e-06}, {"id": 168, "seek": 73510, "start": 753.38, "end": 758.12, "text": " Straight away, and so there's little opportunity to use the fine", "tokens": [26908, 1314, 11, 293, 370, 456, 311, 707, 2650, 281, 764, 264, 2489], "temperature": 0.0, "avg_logprob": -0.2979233671979206, "compression_ratio": 1.5613207547169812, "no_speech_prob": 2.0261302324797725e-06}, {"id": 169, "seek": 73510, "start": 759.02, "end": 762.12, "text": " Detail because we never do any computation with it", "tokens": [4237, 864, 570, 321, 1128, 360, 604, 24903, 365, 309], "temperature": 0.0, "avg_logprob": -0.2979233671979206, "compression_ratio": 1.5613207547169812, "no_speech_prob": 2.0261302324797725e-06}, {"id": 170, "seek": 73510, "start": 762.94, "end": 764.38, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.2979233671979206, "compression_ratio": 1.5613207547169812, "no_speech_prob": 2.0261302324797725e-06}, {"id": 171, "seek": 76438, "start": 764.38, "end": 766.98, "text": " so that's a bit of a problem for", "tokens": [370, 300, 311, 257, 857, 295, 257, 1154, 337], "temperature": 0.0, "avg_logprob": -0.18089202210143374, "compression_ratio": 1.6761133603238867, "no_speech_prob": 2.443971652610344e-06}, {"id": 172, "seek": 76438, "start": 768.86, "end": 775.68, "text": " Things like segmentation or super resolution models because the fine detail matters right we actually want to restore it", "tokens": [9514, 411, 9469, 399, 420, 1687, 8669, 5245, 570, 264, 2489, 2607, 7001, 558, 321, 767, 528, 281, 15227, 309], "temperature": 0.0, "avg_logprob": -0.18089202210143374, "compression_ratio": 1.6761133603238867, "no_speech_prob": 2.443971652610344e-06}, {"id": 173, "seek": 76438, "start": 776.34, "end": 781.66, "text": " And then the second problem is that the adaptive average pooling layer", "tokens": [400, 550, 264, 1150, 1154, 307, 300, 264, 27912, 4274, 7005, 278, 4583], "temperature": 0.0, "avg_logprob": -0.18089202210143374, "compression_ratio": 1.6761133603238867, "no_speech_prob": 2.443971652610344e-06}, {"id": 174, "seek": 76438, "start": 782.78, "end": 787.58, "text": " Entirely throws away the geometry in the last few sections which means that the rest of the model", "tokens": [3951, 621, 356, 19251, 1314, 264, 18426, 294, 264, 1036, 1326, 10863, 597, 1355, 300, 264, 1472, 295, 264, 2316], "temperature": 0.0, "avg_logprob": -0.18089202210143374, "compression_ratio": 1.6761133603238867, "no_speech_prob": 2.443971652610344e-06}, {"id": 175, "seek": 76438, "start": 788.1, "end": 792.3, "text": " Doesn't really have as much interest in kind of learning the geometry as it otherwise might", "tokens": [12955, 380, 534, 362, 382, 709, 1179, 294, 733, 295, 2539, 264, 18426, 382, 309, 5911, 1062], "temperature": 0.0, "avg_logprob": -0.18089202210143374, "compression_ratio": 1.6761133603238867, "no_speech_prob": 2.443971652610344e-06}, {"id": 176, "seek": 79230, "start": 792.3, "end": 800.5799999999999, "text": " And so therefore for things which are dependent on position any kind of localization based approach to anything that requires generative modeling", "tokens": [400, 370, 4412, 337, 721, 597, 366, 12334, 322, 2535, 604, 733, 295, 2654, 2144, 2361, 3109, 281, 1340, 300, 7029, 1337, 1166, 15983], "temperature": 0.0, "avg_logprob": -0.174088361311932, "compression_ratio": 1.6784313725490196, "no_speech_prob": 4.22279617851018e-06}, {"id": 177, "seek": 79230, "start": 800.5799999999999, "end": 802.8599999999999, "text": " Is going to be less effective so?", "tokens": [1119, 516, 281, 312, 1570, 4942, 370, 30], "temperature": 0.0, "avg_logprob": -0.174088361311932, "compression_ratio": 1.6784313725490196, "no_speech_prob": 4.22279617851018e-06}, {"id": 178, "seek": 79230, "start": 803.9399999999999, "end": 809.9799999999999, "text": " One of the things I'm hoping you're hearing as I describe this is that probably none of the existing architectures are actually", "tokens": [1485, 295, 264, 721, 286, 478, 7159, 291, 434, 4763, 382, 286, 6786, 341, 307, 300, 1391, 6022, 295, 264, 6741, 6331, 1303, 366, 767], "temperature": 0.0, "avg_logprob": -0.174088361311932, "compression_ratio": 1.6784313725490196, "no_speech_prob": 4.22279617851018e-06}, {"id": 179, "seek": 79230, "start": 810.66, "end": 811.9, "text": " ideal", "tokens": [7157], "temperature": 0.0, "avg_logprob": -0.174088361311932, "compression_ratio": 1.6784313725490196, "no_speech_prob": 4.22279617851018e-06}, {"id": 180, "seek": 79230, "start": 811.9, "end": 818.4799999999999, "text": " We can invent a new one that actually I just tried inventing a new one over the week which was to take the", "tokens": [492, 393, 7962, 257, 777, 472, 300, 767, 286, 445, 3031, 7962, 278, 257, 777, 472, 670, 264, 1243, 597, 390, 281, 747, 264], "temperature": 0.0, "avg_logprob": -0.174088361311932, "compression_ratio": 1.6784313725490196, "no_speech_prob": 4.22279617851018e-06}, {"id": 181, "seek": 81848, "start": 818.48, "end": 826.32, "text": " the VGG head and attach it to a resnet backbone", "tokens": [264, 691, 27561, 1378, 293, 5085, 309, 281, 257, 725, 7129, 34889], "temperature": 0.0, "avg_logprob": -0.23824254353841146, "compression_ratio": 1.5148514851485149, "no_speech_prob": 1.2218725714774337e-05}, {"id": 182, "seek": 81848, "start": 827.24, "end": 833.6, "text": " And interestingly I found I actually got a slightly better classifier than a normal resnet", "tokens": [400, 25873, 286, 1352, 286, 767, 658, 257, 4748, 1101, 1508, 9902, 813, 257, 2710, 725, 7129], "temperature": 0.0, "avg_logprob": -0.23824254353841146, "compression_ratio": 1.5148514851485149, "no_speech_prob": 1.2218725714774337e-05}, {"id": 183, "seek": 81848, "start": 833.9200000000001, "end": 835.9200000000001, "text": " But it also was something with a little bit more", "tokens": [583, 309, 611, 390, 746, 365, 257, 707, 857, 544], "temperature": 0.0, "avg_logprob": -0.23824254353841146, "compression_ratio": 1.5148514851485149, "no_speech_prob": 1.2218725714774337e-05}, {"id": 184, "seek": 81848, "start": 836.32, "end": 841.16, "text": " Useful information you know it took I don't know five or ten percent longer to train, but nothing", "tokens": [8278, 906, 1589, 291, 458, 309, 1890, 286, 500, 380, 458, 1732, 420, 2064, 3043, 2854, 281, 3847, 11, 457, 1825], "temperature": 0.0, "avg_logprob": -0.23824254353841146, "compression_ratio": 1.5148514851485149, "no_speech_prob": 1.2218725714774337e-05}, {"id": 185, "seek": 81848, "start": 841.6800000000001, "end": 843.6800000000001, "text": " worth worrying about", "tokens": [3163, 18788, 466], "temperature": 0.0, "avg_logprob": -0.23824254353841146, "compression_ratio": 1.5148514851485149, "no_speech_prob": 1.2218725714774337e-05}, {"id": 186, "seek": 84368, "start": 843.68, "end": 850.8399999999999, "text": " Yeah, I think you know maybe we can in resnet replace this as we've talked about briefly before this very early", "tokens": [865, 11, 286, 519, 291, 458, 1310, 321, 393, 294, 725, 7129, 7406, 341, 382, 321, 600, 2825, 466, 10515, 949, 341, 588, 2440], "temperature": 0.0, "avg_logprob": -0.21465317408243814, "compression_ratio": 1.6823529411764706, "no_speech_prob": 6.0487855080282316e-06}, {"id": 187, "seek": 84368, "start": 851.56, "end": 857.9599999999999, "text": " Convolution with something more like an inception stem which does a bit more computation. I think there's definitely room for some", "tokens": [2656, 85, 3386, 365, 746, 544, 411, 364, 49834, 12312, 597, 775, 257, 857, 544, 24903, 13, 286, 519, 456, 311, 2138, 1808, 337, 512], "temperature": 0.0, "avg_logprob": -0.21465317408243814, "compression_ratio": 1.6823529411764706, "no_speech_prob": 6.0487855080282316e-06}, {"id": 188, "seek": 84368, "start": 858.76, "end": 860.76, "text": " nice little tweaks to", "tokens": [1481, 707, 46664, 281], "temperature": 0.0, "avg_logprob": -0.21465317408243814, "compression_ratio": 1.6823529411764706, "no_speech_prob": 6.0487855080282316e-06}, {"id": 189, "seek": 84368, "start": 861.0, "end": 866.3599999999999, "text": " These architectures so that we can build some models which are maybe more versatile", "tokens": [1981, 6331, 1303, 370, 300, 321, 393, 1322, 512, 5245, 597, 366, 1310, 544, 25057], "temperature": 0.0, "avg_logprob": -0.21465317408243814, "compression_ratio": 1.6823529411764706, "no_speech_prob": 6.0487855080282316e-06}, {"id": 190, "seek": 84368, "start": 866.4799999999999, "end": 869.7199999999999, "text": " You know at the moment people tend to build architectures that just do one thing", "tokens": [509, 458, 412, 264, 1623, 561, 3928, 281, 1322, 6331, 1303, 300, 445, 360, 472, 551], "temperature": 0.0, "avg_logprob": -0.21465317408243814, "compression_ratio": 1.6823529411764706, "no_speech_prob": 6.0487855080282316e-06}, {"id": 191, "seek": 86972, "start": 869.72, "end": 875.96, "text": " They don't really think you know what am I throwing away in terms of opportunity because that's that's how publishing works", "tokens": [814, 500, 380, 534, 519, 291, 458, 437, 669, 286, 10238, 1314, 294, 2115, 295, 2650, 570, 300, 311, 300, 311, 577, 17832, 1985], "temperature": 0.0, "avg_logprob": -0.14585882930432337, "compression_ratio": 1.7306273062730628, "no_speech_prob": 1.983290167117957e-05}, {"id": 192, "seek": 86972, "start": 875.96, "end": 880.5600000000001, "text": " You know you publish like I've got the state-of-the-art in this one thing rather than the I've created something", "tokens": [509, 458, 291, 11374, 411, 286, 600, 658, 264, 1785, 12, 2670, 12, 3322, 12, 446, 294, 341, 472, 551, 2831, 813, 264, 286, 600, 2942, 746], "temperature": 0.0, "avg_logprob": -0.14585882930432337, "compression_ratio": 1.7306273062730628, "no_speech_prob": 1.983290167117957e-05}, {"id": 193, "seek": 86972, "start": 880.5600000000001, "end": 882.5600000000001, "text": " It's good at lots of things", "tokens": [467, 311, 665, 412, 3195, 295, 721], "temperature": 0.0, "avg_logprob": -0.14585882930432337, "compression_ratio": 1.7306273062730628, "no_speech_prob": 1.983290167117957e-05}, {"id": 194, "seek": 86972, "start": 883.0400000000001, "end": 889.88, "text": " So so for these reasons we're going to use VGG today even though it's it's ancient and it's missing lots of great stuff", "tokens": [407, 370, 337, 613, 4112, 321, 434, 516, 281, 764, 691, 27561, 965, 754, 1673, 309, 311, 309, 311, 7832, 293, 309, 311, 5361, 3195, 295, 869, 1507], "temperature": 0.0, "avg_logprob": -0.14585882930432337, "compression_ratio": 1.7306273062730628, "no_speech_prob": 1.983290167117957e-05}, {"id": 195, "seek": 86972, "start": 890.32, "end": 892.32, "text": " one thing we are going to do though is use a", "tokens": [472, 551, 321, 366, 516, 281, 360, 1673, 307, 764, 257], "temperature": 0.0, "avg_logprob": -0.14585882930432337, "compression_ratio": 1.7306273062730628, "no_speech_prob": 1.983290167117957e-05}, {"id": 196, "seek": 86972, "start": 892.8000000000001, "end": 894.8000000000001, "text": " slightly more modern version which is a", "tokens": [4748, 544, 4363, 3037, 597, 307, 257], "temperature": 0.0, "avg_logprob": -0.14585882930432337, "compression_ratio": 1.7306273062730628, "no_speech_prob": 1.983290167117957e-05}, {"id": 197, "seek": 89480, "start": 894.8, "end": 900.7199999999999, "text": " version of VGG where batch norm has been added after all the convolutions and so in", "tokens": [3037, 295, 691, 27561, 689, 15245, 2026, 575, 668, 3869, 934, 439, 264, 3754, 15892, 293, 370, 294], "temperature": 0.0, "avg_logprob": -0.2232209431756403, "compression_ratio": 1.6973684210526316, "no_speech_prob": 3.120089604635723e-05}, {"id": 198, "seek": 89480, "start": 901.12, "end": 908.12, "text": " Fast AI actually when you ask for a VGG network you always get the batch norm one because that's basically always what you want", "tokens": [15968, 7318, 767, 562, 291, 1029, 337, 257, 691, 27561, 3209, 291, 1009, 483, 264, 15245, 2026, 472, 570, 300, 311, 1936, 1009, 437, 291, 528], "temperature": 0.0, "avg_logprob": -0.2232209431756403, "compression_ratio": 1.6973684210526316, "no_speech_prob": 3.120089604635723e-05}, {"id": 199, "seek": 89480, "start": 908.8, "end": 911.12, "text": " So this is actually about VGG with batch norm", "tokens": [407, 341, 307, 767, 466, 691, 27561, 365, 15245, 2026], "temperature": 0.0, "avg_logprob": -0.2232209431756403, "compression_ratio": 1.6973684210526316, "no_speech_prob": 3.120089604635723e-05}, {"id": 200, "seek": 89480, "start": 912.0, "end": 918.4, "text": " There's a 16 and a 19 the 19 is way bigger and heavier and doesn't really isn't really any better", "tokens": [821, 311, 257, 3165, 293, 257, 1294, 264, 1294, 307, 636, 3801, 293, 18279, 293, 1177, 380, 534, 1943, 380, 534, 604, 1101], "temperature": 0.0, "avg_logprob": -0.2232209431756403, "compression_ratio": 1.6973684210526316, "no_speech_prob": 3.120089604635723e-05}, {"id": 201, "seek": 89480, "start": 918.4, "end": 921.0, "text": " So we I know one really uses it", "tokens": [407, 321, 286, 458, 472, 534, 4960, 309], "temperature": 0.0, "avg_logprob": -0.2232209431756403, "compression_ratio": 1.6973684210526316, "no_speech_prob": 3.120089604635723e-05}, {"id": 202, "seek": 92100, "start": 921.0, "end": 925.12, "text": " Okay, so we're going to go from 72 by 72", "tokens": [1033, 11, 370, 321, 434, 516, 281, 352, 490, 18731, 538, 18731], "temperature": 0.0, "avg_logprob": -0.2420822779337565, "compression_ratio": 1.5916230366492146, "no_speech_prob": 3.4465485896362225e-06}, {"id": 203, "seek": 92100, "start": 925.96, "end": 928.04, "text": " LR is low resolution input", "tokens": [441, 49, 307, 2295, 8669, 4846], "temperature": 0.0, "avg_logprob": -0.2420822779337565, "compression_ratio": 1.5916230366492146, "no_speech_prob": 3.4465485896362225e-06}, {"id": 204, "seek": 92100, "start": 928.6, "end": 932.3, "text": " Size low resolution we're going to initially scale it up by times two", "tokens": [35818, 2295, 8669, 321, 434, 516, 281, 9105, 4373, 309, 493, 538, 1413, 732], "temperature": 0.0, "avg_logprob": -0.2420822779337565, "compression_ratio": 1.5916230366492146, "no_speech_prob": 3.4465485896362225e-06}, {"id": 205, "seek": 92100, "start": 932.64, "end": 938.66, "text": " With a batch size of 64 to get a 2 times 72 so 1 by 44 by 144", "tokens": [2022, 257, 15245, 2744, 295, 12145, 281, 483, 257, 568, 1413, 18731, 370, 502, 538, 16408, 538, 45218], "temperature": 0.0, "avg_logprob": -0.2420822779337565, "compression_ratio": 1.5916230366492146, "no_speech_prob": 3.4465485896362225e-06}, {"id": 206, "seek": 92100, "start": 939.56, "end": 941.12, "text": " output", "tokens": [5598], "temperature": 0.0, "avg_logprob": -0.2420822779337565, "compression_ratio": 1.5916230366492146, "no_speech_prob": 3.4465485896362225e-06}, {"id": 207, "seek": 92100, "start": 941.12, "end": 943.44, "text": " So that's going to be our stage stage one", "tokens": [407, 300, 311, 516, 281, 312, 527, 3233, 3233, 472], "temperature": 0.0, "avg_logprob": -0.2420822779337565, "compression_ratio": 1.5916230366492146, "no_speech_prob": 3.4465485896362225e-06}, {"id": 208, "seek": 92100, "start": 945.68, "end": 949.0, "text": " We'll create our own data set for this and the data set", "tokens": [492, 603, 1884, 527, 1065, 1412, 992, 337, 341, 293, 264, 1412, 992], "temperature": 0.0, "avg_logprob": -0.2420822779337565, "compression_ratio": 1.5916230366492146, "no_speech_prob": 3.4465485896362225e-06}, {"id": 209, "seek": 94900, "start": 949.0, "end": 951.28, "text": " It's very worthwhile", "tokens": [467, 311, 588, 28159], "temperature": 0.0, "avg_logprob": -0.19829728386618875, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.255361429590266e-06}, {"id": 210, "seek": 94900, "start": 952.36, "end": 956.92, "text": " looking inside the fast AI dot data set module and seeing what's there because", "tokens": [1237, 1854, 264, 2370, 7318, 5893, 1412, 992, 10088, 293, 2577, 437, 311, 456, 570], "temperature": 0.0, "avg_logprob": -0.19829728386618875, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.255361429590266e-06}, {"id": 211, "seek": 94900, "start": 958.84, "end": 963.58, "text": " Just about anything you'd want we probably have something that's almost what you want", "tokens": [1449, 466, 1340, 291, 1116, 528, 321, 1391, 362, 746, 300, 311, 1920, 437, 291, 528], "temperature": 0.0, "avg_logprob": -0.19829728386618875, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.255361429590266e-06}, {"id": 212, "seek": 94900, "start": 963.68, "end": 970.3, "text": " So in this case, I want a data set where my X's are images and my Y's are also images", "tokens": [407, 294, 341, 1389, 11, 286, 528, 257, 1412, 992, 689, 452, 1783, 311, 366, 5267, 293, 452, 398, 311, 366, 611, 5267], "temperature": 0.0, "avg_logprob": -0.19829728386618875, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.255361429590266e-06}, {"id": 213, "seek": 94900, "start": 970.48, "end": 974.52, "text": " So there's already a files data set we can inherit from where the X's are images", "tokens": [407, 456, 311, 1217, 257, 7098, 1412, 992, 321, 393, 21389, 490, 689, 264, 1783, 311, 366, 5267], "temperature": 0.0, "avg_logprob": -0.19829728386618875, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.255361429590266e-06}, {"id": 214, "seek": 97452, "start": 974.52, "end": 980.68, "text": " And then I just inherit from that and I just copied and pasted the get X and turn that into get Y", "tokens": [400, 550, 286, 445, 21389, 490, 300, 293, 286, 445, 25365, 293, 1791, 292, 264, 483, 1783, 293, 1261, 300, 666, 483, 398], "temperature": 0.0, "avg_logprob": -0.1341879190492236, "compression_ratio": 1.7169811320754718, "no_speech_prob": 5.014691851101816e-06}, {"id": 215, "seek": 97452, "start": 980.88, "end": 983.04, "text": " So it just opens an image", "tokens": [407, 309, 445, 9870, 364, 3256], "temperature": 0.0, "avg_logprob": -0.1341879190492236, "compression_ratio": 1.7169811320754718, "no_speech_prob": 5.014691851101816e-06}, {"id": 216, "seek": 97452, "start": 983.12, "end": 988.68, "text": " So now I've got something where the X is an image and the Y is an image and in both cases what we're passing in", "tokens": [407, 586, 286, 600, 658, 746, 689, 264, 1783, 307, 364, 3256, 293, 264, 398, 307, 364, 3256, 293, 294, 1293, 3331, 437, 321, 434, 8437, 294], "temperature": 0.0, "avg_logprob": -0.1341879190492236, "compression_ratio": 1.7169811320754718, "no_speech_prob": 5.014691851101816e-06}, {"id": 217, "seek": 97452, "start": 988.68, "end": 990.68, "text": " Is an array of file names?", "tokens": [1119, 364, 10225, 295, 3991, 5288, 30], "temperature": 0.0, "avg_logprob": -0.1341879190492236, "compression_ratio": 1.7169811320754718, "no_speech_prob": 5.014691851101816e-06}, {"id": 218, "seek": 97452, "start": 992.76, "end": 994.76, "text": " I'm going to do some data augmentation", "tokens": [286, 478, 516, 281, 360, 512, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.1341879190492236, "compression_ratio": 1.7169811320754718, "no_speech_prob": 5.014691851101816e-06}, {"id": 219, "seek": 97452, "start": 995.28, "end": 997.36, "text": " Obviously with all of image net we don't really need it", "tokens": [7580, 365, 439, 295, 3256, 2533, 321, 500, 380, 534, 643, 309], "temperature": 0.0, "avg_logprob": -0.1341879190492236, "compression_ratio": 1.7169811320754718, "no_speech_prob": 5.014691851101816e-06}, {"id": 220, "seek": 97452, "start": 997.36, "end": 1001.72, "text": " But this is mainly here for you know anybody who's using smaller data sets to make the most of it", "tokens": [583, 341, 307, 8704, 510, 337, 291, 458, 4472, 567, 311, 1228, 4356, 1412, 6352, 281, 652, 264, 881, 295, 309], "temperature": 0.0, "avg_logprob": -0.1341879190492236, "compression_ratio": 1.7169811320754718, "no_speech_prob": 5.014691851101816e-06}, {"id": 221, "seek": 100172, "start": 1001.72, "end": 1003.72, "text": " random", "tokens": [4974], "temperature": 0.0, "avg_logprob": -0.2765437588833346, "compression_ratio": 1.6122448979591837, "no_speech_prob": 2.90229559141153e-06}, {"id": 222, "seek": 100172, "start": 1004.0400000000001, "end": 1006.1600000000001, "text": " dihedral is referring to", "tokens": [1026, 71, 24764, 307, 13761, 281], "temperature": 0.0, "avg_logprob": -0.2765437588833346, "compression_ratio": 1.6122448979591837, "no_speech_prob": 2.90229559141153e-06}, {"id": 223, "seek": 100172, "start": 1006.9200000000001, "end": 1011.0400000000001, "text": " every possible 90 degree rotation plus optional left right flipping so that", "tokens": [633, 1944, 4289, 4314, 12447, 1804, 17312, 1411, 558, 26886, 370, 300], "temperature": 0.0, "avg_logprob": -0.2765437588833346, "compression_ratio": 1.6122448979591837, "no_speech_prob": 2.90229559141153e-06}, {"id": 224, "seek": 100172, "start": 1011.84, "end": 1014.36, "text": " the dihedral group of eight symmetries", "tokens": [264, 1026, 71, 24764, 1594, 295, 3180, 14232, 302, 2244], "temperature": 0.0, "avg_logprob": -0.2765437588833346, "compression_ratio": 1.6122448979591837, "no_speech_prob": 2.90229559141153e-06}, {"id": 225, "seek": 100172, "start": 1016.1600000000001, "end": 1018.1600000000001, "text": " Normally we don't use this", "tokens": [17424, 321, 500, 380, 764, 341], "temperature": 0.0, "avg_logprob": -0.2765437588833346, "compression_ratio": 1.6122448979591837, "no_speech_prob": 2.90229559141153e-06}, {"id": 226, "seek": 100172, "start": 1018.6, "end": 1023.0, "text": " Transformation for image net pictures because like you don't normally flip dogs upside down", "tokens": [6531, 8663, 337, 3256, 2533, 5242, 570, 411, 291, 500, 380, 5646, 7929, 7197, 14119, 760], "temperature": 0.0, "avg_logprob": -0.2765437588833346, "compression_ratio": 1.6122448979591837, "no_speech_prob": 2.90229559141153e-06}, {"id": 227, "seek": 100172, "start": 1023.64, "end": 1025.64, "text": " But in this case, we're not trying to", "tokens": [583, 294, 341, 1389, 11, 321, 434, 406, 1382, 281], "temperature": 0.0, "avg_logprob": -0.2765437588833346, "compression_ratio": 1.6122448979591837, "no_speech_prob": 2.90229559141153e-06}, {"id": 228, "seek": 100172, "start": 1026.3600000000001, "end": 1030.48, "text": " Classify whether it's a dog or a cat. We're just trying to keep the general structure of it", "tokens": [9471, 2505, 1968, 309, 311, 257, 3000, 420, 257, 3857, 13, 492, 434, 445, 1382, 281, 1066, 264, 2674, 3877, 295, 309], "temperature": 0.0, "avg_logprob": -0.2765437588833346, "compression_ratio": 1.6122448979591837, "no_speech_prob": 2.90229559141153e-06}, {"id": 229, "seek": 103048, "start": 1030.48, "end": 1037.56, "text": " So actually, you know every possible flip is a reasonably sensible thing to do for this problem", "tokens": [407, 767, 11, 291, 458, 633, 1944, 7929, 307, 257, 23551, 25380, 551, 281, 360, 337, 341, 1154], "temperature": 0.0, "avg_logprob": -0.15868425871196545, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.495153916650452e-06}, {"id": 230, "seek": 103048, "start": 1039.88, "end": 1042.8, "text": " So create a validation set in the usual way", "tokens": [407, 1884, 257, 24071, 992, 294, 264, 7713, 636], "temperature": 0.0, "avg_logprob": -0.15868425871196545, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.495153916650452e-06}, {"id": 231, "seek": 103048, "start": 1043.3600000000001, "end": 1047.72, "text": " And you can see I'm kind of like using a few more slightly lower level functions", "tokens": [400, 291, 393, 536, 286, 478, 733, 295, 411, 1228, 257, 1326, 544, 4748, 3126, 1496, 6828], "temperature": 0.0, "avg_logprob": -0.15868425871196545, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.495153916650452e-06}, {"id": 232, "seek": 103048, "start": 1047.72, "end": 1051.68, "text": " Generally speaking I just copy and paste them out of the fast AI source code", "tokens": [21082, 4124, 286, 445, 5055, 293, 9163, 552, 484, 295, 264, 2370, 7318, 4009, 3089], "temperature": 0.0, "avg_logprob": -0.15868425871196545, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.495153916650452e-06}, {"id": 233, "seek": 103048, "start": 1052.24, "end": 1057.1200000000001, "text": " To you know find the bits I want so here's the bit which takes an array of", "tokens": [1407, 291, 458, 915, 264, 9239, 286, 528, 370, 510, 311, 264, 857, 597, 2516, 364, 10225, 295], "temperature": 0.0, "avg_logprob": -0.15868425871196545, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.495153916650452e-06}, {"id": 234, "seek": 105712, "start": 1057.12, "end": 1059.6, "text": " validation set indexes and", "tokens": [24071, 992, 8186, 279, 293], "temperature": 0.0, "avg_logprob": -0.3108466044965997, "compression_ratio": 1.8795180722891567, "no_speech_prob": 2.6425673240737524e-06}, {"id": 235, "seek": 105712, "start": 1061.12, "end": 1064.36, "text": " one or more arrays of variables and", "tokens": [472, 420, 544, 41011, 295, 9102, 293], "temperature": 0.0, "avg_logprob": -0.3108466044965997, "compression_ratio": 1.8795180722891567, "no_speech_prob": 2.6425673240737524e-06}, {"id": 236, "seek": 105712, "start": 1065.4399999999998, "end": 1068.3999999999999, "text": " simply splits so in this case this into a", "tokens": [2935, 37741, 370, 294, 341, 1389, 341, 666, 257], "temperature": 0.0, "avg_logprob": -0.3108466044965997, "compression_ratio": 1.8795180722891567, "no_speech_prob": 2.6425673240737524e-06}, {"id": 237, "seek": 105712, "start": 1069.32, "end": 1073.4799999999998, "text": " Training and a validation set and this into a training and a valid it", "tokens": [20620, 293, 257, 24071, 992, 293, 341, 666, 257, 3097, 293, 257, 7363, 309], "temperature": 0.0, "avg_logprob": -0.3108466044965997, "compression_ratio": 1.8795180722891567, "no_speech_prob": 2.6425673240737524e-06}, {"id": 238, "seek": 105712, "start": 1073.4799999999998, "end": 1077.4399999999998, "text": " Sorry, it yeah the training and validation set you give us our X's and our Y's", "tokens": [4919, 11, 309, 1338, 264, 3097, 293, 24071, 992, 291, 976, 505, 527, 1783, 311, 293, 527, 398, 311], "temperature": 0.0, "avg_logprob": -0.3108466044965997, "compression_ratio": 1.8795180722891567, "no_speech_prob": 2.6425673240737524e-06}, {"id": 239, "seek": 105712, "start": 1078.32, "end": 1081.9399999999998, "text": " Now in this case the trend of the X and the Y are the same", "tokens": [823, 294, 341, 1389, 264, 6028, 295, 264, 1783, 293, 264, 398, 366, 264, 912], "temperature": 0.0, "avg_logprob": -0.3108466044965997, "compression_ratio": 1.8795180722891567, "no_speech_prob": 2.6425673240737524e-06}, {"id": 240, "seek": 108194, "start": 1081.94, "end": 1089.66, "text": " Our input image and our output image are the same we're going to use transformations to make one of them lower resolution", "tokens": [2621, 4846, 3256, 293, 527, 5598, 3256, 366, 264, 912, 321, 434, 516, 281, 764, 34852, 281, 652, 472, 295, 552, 3126, 8669], "temperature": 0.0, "avg_logprob": -0.18773967463795732, "compression_ratio": 1.7936507936507937, "no_speech_prob": 5.0936737352458294e-06}, {"id": 241, "seek": 108194, "start": 1089.8200000000002, "end": 1092.4, "text": " So that's why these are the same the same thing", "tokens": [407, 300, 311, 983, 613, 366, 264, 912, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.18773967463795732, "compression_ratio": 1.7936507936507937, "no_speech_prob": 5.0936737352458294e-06}, {"id": 242, "seek": 108194, "start": 1093.5800000000002, "end": 1095.5800000000002, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.18773967463795732, "compression_ratio": 1.7936507936507937, "no_speech_prob": 5.0936737352458294e-06}, {"id": 243, "seek": 108194, "start": 1097.7, "end": 1103.5, "text": " The next thing that we need to do is to create our transformations as per usual and", "tokens": [440, 958, 551, 300, 321, 643, 281, 360, 307, 281, 1884, 527, 34852, 382, 680, 7713, 293], "temperature": 0.0, "avg_logprob": -0.18773967463795732, "compression_ratio": 1.7936507936507937, "no_speech_prob": 5.0936737352458294e-06}, {"id": 244, "seek": 108194, "start": 1104.5, "end": 1109.3600000000001, "text": " We're going to use this transform y parameter like we did for bounding boxes", "tokens": [492, 434, 516, 281, 764, 341, 4088, 288, 13075, 411, 321, 630, 337, 5472, 278, 9002], "temperature": 0.0, "avg_logprob": -0.18773967463795732, "compression_ratio": 1.7936507936507937, "no_speech_prob": 5.0936737352458294e-06}, {"id": 245, "seek": 110936, "start": 1109.36, "end": 1111.9799999999998, "text": " But rather than use transform type dot", "tokens": [583, 2831, 813, 764, 4088, 2010, 5893], "temperature": 0.0, "avg_logprob": -0.20992997487386067, "compression_ratio": 1.7609756097560976, "no_speech_prob": 1.3925431403549737e-06}, {"id": 246, "seek": 110936, "start": 1112.5, "end": 1113.6, "text": " coordinate", "tokens": [15670], "temperature": 0.0, "avg_logprob": -0.20992997487386067, "compression_ratio": 1.7609756097560976, "no_speech_prob": 1.3925431403549737e-06}, {"id": 247, "seek": 110936, "start": 1113.6, "end": 1116.8799999999999, "text": " we're going to use transform type dot pixel and so", "tokens": [321, 434, 516, 281, 764, 4088, 2010, 5893, 19261, 293, 370], "temperature": 0.0, "avg_logprob": -0.20992997487386067, "compression_ratio": 1.7609756097560976, "no_speech_prob": 1.3925431403549737e-06}, {"id": 248, "seek": 110936, "start": 1117.8, "end": 1119.8, "text": " that tells our", "tokens": [300, 5112, 527], "temperature": 0.0, "avg_logprob": -0.20992997487386067, "compression_ratio": 1.7609756097560976, "no_speech_prob": 1.3925431403549737e-06}, {"id": 249, "seek": 110936, "start": 1120.8799999999999, "end": 1124.6399999999999, "text": " Transformations framework that your y values are", "tokens": [27938, 763, 8388, 300, 428, 288, 4190, 366], "temperature": 0.0, "avg_logprob": -0.20992997487386067, "compression_ratio": 1.7609756097560976, "no_speech_prob": 1.3925431403549737e-06}, {"id": 250, "seek": 110936, "start": 1125.56, "end": 1132.8799999999999, "text": " Images with normal pixels in them and so anything you do the X you also need to do to the Y do the same thing", "tokens": [4331, 1660, 365, 2710, 18668, 294, 552, 293, 370, 1340, 291, 360, 264, 1783, 291, 611, 643, 281, 360, 281, 264, 398, 360, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.20992997487386067, "compression_ratio": 1.7609756097560976, "no_speech_prob": 1.3925431403549737e-06}, {"id": 251, "seek": 110936, "start": 1133.04, "end": 1138.28, "text": " Okay, and you need to make sure any data augmentation transforms you use have the same", "tokens": [1033, 11, 293, 291, 643, 281, 652, 988, 604, 1412, 14501, 19631, 35592, 291, 764, 362, 264, 912], "temperature": 0.0, "avg_logprob": -0.20992997487386067, "compression_ratio": 1.7609756097560976, "no_speech_prob": 1.3925431403549737e-06}, {"id": 252, "seek": 113828, "start": 1138.28, "end": 1140.28, "text": " parameter as well, okay", "tokens": [13075, 382, 731, 11, 1392], "temperature": 0.0, "avg_logprob": -0.23257042811467096, "compression_ratio": 1.5829145728643217, "no_speech_prob": 4.42546343037975e-06}, {"id": 253, "seek": 113828, "start": 1146.0, "end": 1152.04, "text": " So you can see the possible transform types you basically you've got classification which we're about to use the segmentation in the second half", "tokens": [407, 291, 393, 536, 264, 1944, 4088, 3467, 291, 1936, 291, 600, 658, 21538, 597, 321, 434, 466, 281, 764, 264, 9469, 399, 294, 264, 1150, 1922], "temperature": 0.0, "avg_logprob": -0.23257042811467096, "compression_ratio": 1.5829145728643217, "no_speech_prob": 4.42546343037975e-06}, {"id": 254, "seek": 113828, "start": 1152.04, "end": 1153.72, "text": " of today coordinates", "tokens": [295, 965, 21056], "temperature": 0.0, "avg_logprob": -0.23257042811467096, "compression_ratio": 1.5829145728643217, "no_speech_prob": 4.42546343037975e-06}, {"id": 255, "seek": 113828, "start": 1153.72, "end": 1155.72, "text": " No transformation at all", "tokens": [883, 9887, 412, 439], "temperature": 0.0, "avg_logprob": -0.23257042811467096, "compression_ratio": 1.5829145728643217, "no_speech_prob": 4.42546343037975e-06}, {"id": 256, "seek": 113828, "start": 1156.12, "end": 1158.12, "text": " or pixel", "tokens": [420, 19261], "temperature": 0.0, "avg_logprob": -0.23257042811467096, "compression_ratio": 1.5829145728643217, "no_speech_prob": 4.42546343037975e-06}, {"id": 257, "seek": 113828, "start": 1159.32, "end": 1162.04, "text": " All right, so once we've got a", "tokens": [1057, 558, 11, 370, 1564, 321, 600, 658, 257], "temperature": 0.0, "avg_logprob": -0.23257042811467096, "compression_ratio": 1.5829145728643217, "no_speech_prob": 4.42546343037975e-06}, {"id": 258, "seek": 113828, "start": 1162.8799999999999, "end": 1167.48, "text": " data set class and some X and Y training and validation sets", "tokens": [1412, 992, 1508, 293, 512, 1783, 293, 398, 3097, 293, 24071, 6352], "temperature": 0.0, "avg_logprob": -0.23257042811467096, "compression_ratio": 1.5829145728643217, "no_speech_prob": 4.42546343037975e-06}, {"id": 259, "seek": 116748, "start": 1167.48, "end": 1171.64, "text": " There's a handy little method called get data sets, which basically", "tokens": [821, 311, 257, 13239, 707, 3170, 1219, 483, 1412, 6352, 11, 597, 1936], "temperature": 0.0, "avg_logprob": -0.21434188134891471, "compression_ratio": 1.6807692307692308, "no_speech_prob": 4.029431693197694e-06}, {"id": 260, "seek": 116748, "start": 1173.16, "end": 1180.52, "text": " Runs that constructor over all the different things that you have to return all the data sets you need in exactly the right format to pass", "tokens": [8950, 82, 300, 47479, 670, 439, 264, 819, 721, 300, 291, 362, 281, 2736, 439, 264, 1412, 6352, 291, 643, 294, 2293, 264, 558, 7877, 281, 1320], "temperature": 0.0, "avg_logprob": -0.21434188134891471, "compression_ratio": 1.6807692307692308, "no_speech_prob": 4.029431693197694e-06}, {"id": 261, "seek": 116748, "start": 1180.52, "end": 1187.8, "text": " Pass to a model data construction as constructor in this case the image data constructor. So we're kind of like going back", "tokens": [10319, 281, 257, 2316, 1412, 6435, 382, 47479, 294, 341, 1389, 264, 3256, 1412, 47479, 13, 407, 321, 434, 733, 295, 411, 516, 646], "temperature": 0.0, "avg_logprob": -0.21434188134891471, "compression_ratio": 1.6807692307692308, "no_speech_prob": 4.029431693197694e-06}, {"id": 262, "seek": 116748, "start": 1188.64, "end": 1194.92, "text": " Under the covers of fast AI a little bit and building it up from scratch and you know in the next few weeks", "tokens": [6974, 264, 10538, 295, 2370, 7318, 257, 707, 857, 293, 2390, 309, 493, 490, 8459, 293, 291, 458, 294, 264, 958, 1326, 3259], "temperature": 0.0, "avg_logprob": -0.21434188134891471, "compression_ratio": 1.6807692307692308, "no_speech_prob": 4.029431693197694e-06}, {"id": 263, "seek": 119492, "start": 1194.92, "end": 1200.0800000000002, "text": " This will all be wrapped up and refactored into something that you can do in a single step in fast AI", "tokens": [639, 486, 439, 312, 14226, 493, 293, 1895, 578, 2769, 666, 746, 300, 291, 393, 360, 294, 257, 2167, 1823, 294, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.1780649356627732, "compression_ratio": 1.5764192139737991, "no_speech_prob": 4.1573184716980904e-06}, {"id": 264, "seek": 119492, "start": 1200.0800000000002, "end": 1204.72, "text": " But the point of this class is to learn you know a bit about going under the covers", "tokens": [583, 264, 935, 295, 341, 1508, 307, 281, 1466, 291, 458, 257, 857, 466, 516, 833, 264, 10538], "temperature": 0.0, "avg_logprob": -0.1780649356627732, "compression_ratio": 1.5764192139737991, "no_speech_prob": 4.1573184716980904e-06}, {"id": 265, "seek": 119492, "start": 1207.92, "end": 1209.92, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.1780649356627732, "compression_ratio": 1.5764192139737991, "no_speech_prob": 4.1573184716980904e-06}, {"id": 266, "seek": 119492, "start": 1210.68, "end": 1218.16, "text": " Something we've briefly seen before is that when we take images in we transform them not just with data augmentation", "tokens": [6595, 321, 600, 10515, 1612, 949, 307, 300, 562, 321, 747, 5267, 294, 321, 4088, 552, 406, 445, 365, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.1780649356627732, "compression_ratio": 1.5764192139737991, "no_speech_prob": 4.1573184716980904e-06}, {"id": 267, "seek": 119492, "start": 1218.6000000000001, "end": 1220.6000000000001, "text": " But we also move", "tokens": [583, 321, 611, 1286], "temperature": 0.0, "avg_logprob": -0.1780649356627732, "compression_ratio": 1.5764192139737991, "no_speech_prob": 4.1573184716980904e-06}, {"id": 268, "seek": 119492, "start": 1220.6000000000001, "end": 1222.8000000000002, "text": " the channels dimension up to the start", "tokens": [264, 9235, 10139, 493, 281, 264, 722], "temperature": 0.0, "avg_logprob": -0.1780649356627732, "compression_ratio": 1.5764192139737991, "no_speech_prob": 4.1573184716980904e-06}, {"id": 269, "seek": 122280, "start": 1222.8, "end": 1226.48, "text": " We subtract the mean divide by the standard deviation whatever", "tokens": [492, 16390, 264, 914, 9845, 538, 264, 3832, 25163, 2035], "temperature": 0.0, "avg_logprob": -0.30371277420609083, "compression_ratio": 1.692, "no_speech_prob": 6.643341293965932e-06}, {"id": 270, "seek": 122280, "start": 1227.0, "end": 1232.72, "text": " So if we want to be able to display those pictures that have come out of our data sets or data loaders", "tokens": [407, 498, 321, 528, 281, 312, 1075, 281, 4674, 729, 5242, 300, 362, 808, 484, 295, 527, 1412, 6352, 420, 1412, 3677, 433], "temperature": 0.0, "avg_logprob": -0.30371277420609083, "compression_ratio": 1.692, "no_speech_prob": 6.643341293965932e-06}, {"id": 271, "seek": 122280, "start": 1232.72, "end": 1236.3999999999999, "text": " We need to denormalize them and so the model data objects", "tokens": [492, 643, 281, 1441, 24440, 1125, 552, 293, 370, 264, 2316, 1412, 6565], "temperature": 0.0, "avg_logprob": -0.30371277420609083, "compression_ratio": 1.692, "no_speech_prob": 6.643341293965932e-06}, {"id": 272, "seek": 122280, "start": 1237.12, "end": 1239.12, "text": " Data set has a denorm", "tokens": [11888, 992, 575, 257, 1441, 687], "temperature": 0.0, "avg_logprob": -0.30371277420609083, "compression_ratio": 1.692, "no_speech_prob": 6.643341293965932e-06}, {"id": 273, "seek": 122280, "start": 1240.32, "end": 1243.28, "text": " Function that knows how to do that. So I'm just going to give that a short name", "tokens": [11166, 882, 300, 3255, 577, 281, 360, 300, 13, 407, 286, 478, 445, 516, 281, 976, 300, 257, 2099, 1315], "temperature": 0.0, "avg_logprob": -0.30371277420609083, "compression_ratio": 1.692, "no_speech_prob": 6.643341293965932e-06}, {"id": 274, "seek": 122280, "start": 1244.24, "end": 1248.8, "text": " For convenience. So now I'm going to create a function that can show an image from a data set and", "tokens": [1171, 19283, 13, 407, 586, 286, 478, 516, 281, 1884, 257, 2445, 300, 393, 855, 364, 3256, 490, 257, 1412, 992, 293], "temperature": 0.0, "avg_logprob": -0.30371277420609083, "compression_ratio": 1.692, "no_speech_prob": 6.643341293965932e-06}, {"id": 275, "seek": 124880, "start": 1248.8, "end": 1252.52, "text": " If you pass in something saying this is a normalized image", "tokens": [759, 291, 1320, 294, 746, 1566, 341, 307, 257, 48704, 3256], "temperature": 0.0, "avg_logprob": -0.21151040332152113, "compression_ratio": 1.6869565217391305, "no_speech_prob": 4.0928925955086015e-06}, {"id": 276, "seek": 124880, "start": 1253.24, "end": 1255.6399999999999, "text": " Then we'll denote it. Okay, so", "tokens": [1396, 321, 603, 45708, 309, 13, 1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.21151040332152113, "compression_ratio": 1.6869565217391305, "no_speech_prob": 4.0928925955086015e-06}, {"id": 277, "seek": 124880, "start": 1256.96, "end": 1259.8799999999999, "text": " We can go ahead and have a look at that you'll see here", "tokens": [492, 393, 352, 2286, 293, 362, 257, 574, 412, 300, 291, 603, 536, 510], "temperature": 0.0, "avg_logprob": -0.21151040332152113, "compression_ratio": 1.6869565217391305, "no_speech_prob": 4.0928925955086015e-06}, {"id": 278, "seek": 124880, "start": 1260.72, "end": 1265.12, "text": " we've passed in size low res as our size for the transforms and", "tokens": [321, 600, 4678, 294, 2744, 2295, 725, 382, 527, 2744, 337, 264, 35592, 293], "temperature": 0.0, "avg_logprob": -0.21151040332152113, "compression_ratio": 1.6869565217391305, "no_speech_prob": 4.0928925955086015e-06}, {"id": 279, "seek": 124880, "start": 1265.8799999999999, "end": 1268.3999999999999, "text": " Size high res as this is something new", "tokens": [35818, 1090, 725, 382, 341, 307, 746, 777], "temperature": 0.0, "avg_logprob": -0.21151040332152113, "compression_ratio": 1.6869565217391305, "no_speech_prob": 4.0928925955086015e-06}, {"id": 280, "seek": 124880, "start": 1268.96, "end": 1273.96, "text": " The size y parameter. Okay, so the two bits are going to get different sizes", "tokens": [440, 2744, 288, 13075, 13, 1033, 11, 370, 264, 732, 9239, 366, 516, 281, 483, 819, 11602], "temperature": 0.0, "avg_logprob": -0.21151040332152113, "compression_ratio": 1.6869565217391305, "no_speech_prob": 4.0928925955086015e-06}, {"id": 281, "seek": 127396, "start": 1273.96, "end": 1280.8, "text": " And so here you can see the two different resolutions of our X and our Y for a whole bunch of fish", "tokens": [400, 370, 510, 291, 393, 536, 264, 732, 819, 32179, 295, 527, 1783, 293, 527, 398, 337, 257, 1379, 3840, 295, 3506], "temperature": 0.0, "avg_logprob": -0.1486257502907201, "compression_ratio": 1.5681818181818181, "no_speech_prob": 4.495151642913697e-06}, {"id": 282, "seek": 127396, "start": 1282.2, "end": 1283.32, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.1486257502907201, "compression_ratio": 1.5681818181818181, "no_speech_prob": 4.495151642913697e-06}, {"id": 283, "seek": 127396, "start": 1283.32, "end": 1285.92, "text": " As you know as per usual plot dot subplots", "tokens": [1018, 291, 458, 382, 680, 7713, 7542, 5893, 1422, 564, 1971], "temperature": 0.0, "avg_logprob": -0.1486257502907201, "compression_ratio": 1.5681818181818181, "no_speech_prob": 4.495151642913697e-06}, {"id": 284, "seek": 127396, "start": 1286.44, "end": 1291.92, "text": " To create our two plots and then we can just use the different axes that came back to put stuff", "tokens": [1407, 1884, 527, 732, 28609, 293, 550, 321, 393, 445, 764, 264, 819, 35387, 300, 1361, 646, 281, 829, 1507], "temperature": 0.0, "avg_logprob": -0.1486257502907201, "compression_ratio": 1.5681818181818181, "no_speech_prob": 4.495151642913697e-06}, {"id": 285, "seek": 127396, "start": 1292.44, "end": 1294.44, "text": " next to each other", "tokens": [958, 281, 1184, 661], "temperature": 0.0, "avg_logprob": -0.1486257502907201, "compression_ratio": 1.5681818181818181, "no_speech_prob": 4.495151642913697e-06}, {"id": 286, "seek": 127396, "start": 1297.56, "end": 1299.56, "text": " So we can then", "tokens": [407, 321, 393, 550], "temperature": 0.0, "avg_logprob": -0.1486257502907201, "compression_ratio": 1.5681818181818181, "no_speech_prob": 4.495151642913697e-06}, {"id": 287, "seek": 129956, "start": 1299.56, "end": 1305.6799999999998, "text": " Have a look at a few different versions of the data transformation and you can see them being flipped in all different directions", "tokens": [3560, 257, 574, 412, 257, 1326, 819, 9606, 295, 264, 1412, 9887, 293, 291, 393, 536, 552, 885, 26273, 294, 439, 819, 11095], "temperature": 0.0, "avg_logprob": -0.14097769558429718, "compression_ratio": 1.6144578313253013, "no_speech_prob": 8.990938340502908e-07}, {"id": 288, "seek": 129956, "start": 1307.6399999999999, "end": 1312.8, "text": " Okay, so let's create our model", "tokens": [1033, 11, 370, 718, 311, 1884, 527, 2316], "temperature": 0.0, "avg_logprob": -0.14097769558429718, "compression_ratio": 1.6144578313253013, "no_speech_prob": 8.990938340502908e-07}, {"id": 289, "seek": 129956, "start": 1316.8, "end": 1320.76, "text": " So we're going to have an image coming in", "tokens": [407, 321, 434, 516, 281, 362, 364, 3256, 1348, 294], "temperature": 0.0, "avg_logprob": -0.14097769558429718, "compression_ratio": 1.6144578313253013, "no_speech_prob": 8.990938340502908e-07}, {"id": 290, "seek": 132076, "start": 1320.76, "end": 1329.0, "text": " Small image coming in and we want to have a big image coming out", "tokens": [15287, 3256, 1348, 294, 293, 321, 528, 281, 362, 257, 955, 3256, 1348, 484], "temperature": 0.0, "avg_logprob": -0.21160308938277395, "compression_ratio": 1.6397849462365592, "no_speech_prob": 2.058043037322932e-06}, {"id": 291, "seek": 132076, "start": 1331.24, "end": 1334.36, "text": " Okay, and so we need to do some computation", "tokens": [1033, 11, 293, 370, 321, 643, 281, 360, 512, 24903], "temperature": 0.0, "avg_logprob": -0.21160308938277395, "compression_ratio": 1.6397849462365592, "no_speech_prob": 2.058043037322932e-06}, {"id": 292, "seek": 132076, "start": 1335.28, "end": 1339.36, "text": " between those two to calculate what the big image would look like and", "tokens": [1296, 729, 732, 281, 8873, 437, 264, 955, 3256, 576, 574, 411, 293], "temperature": 0.0, "avg_logprob": -0.21160308938277395, "compression_ratio": 1.6397849462365592, "no_speech_prob": 2.058043037322932e-06}, {"id": 293, "seek": 132076, "start": 1339.68, "end": 1346.24, "text": " So essentially there's kind of two ways of doing that computation. We could first of all do some up sampling and", "tokens": [407, 4476, 456, 311, 733, 295, 732, 2098, 295, 884, 300, 24903, 13, 492, 727, 700, 295, 439, 360, 512, 493, 21179, 293], "temperature": 0.0, "avg_logprob": -0.21160308938277395, "compression_ratio": 1.6397849462365592, "no_speech_prob": 2.058043037322932e-06}, {"id": 294, "seek": 132076, "start": 1346.84, "end": 1348.84, "text": " then do a few", "tokens": [550, 360, 257, 1326], "temperature": 0.0, "avg_logprob": -0.21160308938277395, "compression_ratio": 1.6397849462365592, "no_speech_prob": 2.058043037322932e-06}, {"id": 295, "seek": 134884, "start": 1348.84, "end": 1350.52, "text": " stride one", "tokens": [1056, 482, 472], "temperature": 0.0, "avg_logprob": -0.1611454813103927, "compression_ratio": 1.9375, "no_speech_prob": 2.090454245262663e-06}, {"id": 296, "seek": 134884, "start": 1350.52, "end": 1353.08, "text": " kind of layers to do lots of computation or", "tokens": [733, 295, 7914, 281, 360, 3195, 295, 24903, 420], "temperature": 0.0, "avg_logprob": -0.1611454813103927, "compression_ratio": 1.9375, "no_speech_prob": 2.090454245262663e-06}, {"id": 297, "seek": 134884, "start": 1354.6399999999999, "end": 1361.0, "text": " We could first do lots of stride one layers to do all the computation and then at the end do some up sampling", "tokens": [492, 727, 700, 360, 3195, 295, 1056, 482, 472, 7914, 281, 360, 439, 264, 24903, 293, 550, 412, 264, 917, 360, 512, 493, 21179], "temperature": 0.0, "avg_logprob": -0.1611454813103927, "compression_ratio": 1.9375, "no_speech_prob": 2.090454245262663e-06}, {"id": 298, "seek": 134884, "start": 1362.32, "end": 1368.6399999999999, "text": " We're going to pick the second approach because we want to do lots of computation on something smaller", "tokens": [492, 434, 516, 281, 1888, 264, 1150, 3109, 570, 321, 528, 281, 360, 3195, 295, 24903, 322, 746, 4356], "temperature": 0.0, "avg_logprob": -0.1611454813103927, "compression_ratio": 1.9375, "no_speech_prob": 2.090454245262663e-06}, {"id": 299, "seek": 134884, "start": 1370.08, "end": 1375.6799999999998, "text": " Because it's much faster to do it that way and also like all that computation we get to kind of leverage", "tokens": [1436, 309, 311, 709, 4663, 281, 360, 309, 300, 636, 293, 611, 411, 439, 300, 24903, 321, 483, 281, 733, 295, 13982], "temperature": 0.0, "avg_logprob": -0.1611454813103927, "compression_ratio": 1.9375, "no_speech_prob": 2.090454245262663e-06}, {"id": 300, "seek": 137568, "start": 1375.68, "end": 1378.1200000000001, "text": " During the up sampling process", "tokens": [6842, 264, 493, 21179, 1399], "temperature": 0.0, "avg_logprob": -0.2968088590181791, "compression_ratio": 1.5, "no_speech_prob": 2.3320658328884747e-06}, {"id": 301, "seek": 137568, "start": 1381.3200000000002, "end": 1383.3200000000002, "text": " So app sampling", "tokens": [407, 724, 21179], "temperature": 0.0, "avg_logprob": -0.2968088590181791, "compression_ratio": 1.5, "no_speech_prob": 2.3320658328884747e-06}, {"id": 302, "seek": 137568, "start": 1383.6000000000001, "end": 1386.52, "text": " We know a couple of possible ways to do that. We can use", "tokens": [492, 458, 257, 1916, 295, 1944, 2098, 281, 360, 300, 13, 492, 393, 764], "temperature": 0.0, "avg_logprob": -0.2968088590181791, "compression_ratio": 1.5, "no_speech_prob": 2.3320658328884747e-06}, {"id": 303, "seek": 137568, "start": 1387.2, "end": 1389.2, "text": " transposed or", "tokens": [7132, 1744, 420], "temperature": 0.0, "avg_logprob": -0.2968088590181791, "compression_ratio": 1.5, "no_speech_prob": 2.3320658328884747e-06}, {"id": 304, "seek": 137568, "start": 1389.28, "end": 1391.28, "text": " fractionally strided convolutions", "tokens": [14135, 379, 1056, 2112, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.2968088590181791, "compression_ratio": 1.5, "no_speech_prob": 2.3320658328884747e-06}, {"id": 305, "seek": 137568, "start": 1392.16, "end": 1395.28, "text": " Or we can use nearest neighbor up sampling", "tokens": [1610, 321, 393, 764, 23831, 5987, 493, 21179], "temperature": 0.0, "avg_logprob": -0.2968088590181791, "compression_ratio": 1.5, "no_speech_prob": 2.3320658328884747e-06}, {"id": 306, "seek": 137568, "start": 1396.68, "end": 1398.68, "text": " followed by a one by one conv", "tokens": [6263, 538, 257, 472, 538, 472, 3754], "temperature": 0.0, "avg_logprob": -0.2968088590181791, "compression_ratio": 1.5, "no_speech_prob": 2.3320658328884747e-06}, {"id": 307, "seek": 137568, "start": 1400.28, "end": 1401.64, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.2968088590181791, "compression_ratio": 1.5, "no_speech_prob": 2.3320658328884747e-06}, {"id": 308, "seek": 140164, "start": 1401.64, "end": 1405.68, "text": " Then in in the kind of do lots of computation section", "tokens": [1396, 294, 294, 264, 733, 295, 360, 3195, 295, 24903, 3541], "temperature": 0.0, "avg_logprob": -0.23143845862084692, "compression_ratio": 1.6228070175438596, "no_speech_prob": 1.8448193941367208e-06}, {"id": 309, "seek": 140164, "start": 1406.44, "end": 1411.3200000000002, "text": " We could just have a whole bunch of three by three cons, right? But in this case particular", "tokens": [492, 727, 445, 362, 257, 1379, 3840, 295, 1045, 538, 1045, 1014, 11, 558, 30, 583, 294, 341, 1389, 1729], "temperature": 0.0, "avg_logprob": -0.23143845862084692, "compression_ratio": 1.6228070175438596, "no_speech_prob": 1.8448193941367208e-06}, {"id": 310, "seek": 140164, "start": 1412.3200000000002, "end": 1418.4, "text": " It seems likely that resnet blocks are going to be better because really the output", "tokens": [467, 2544, 3700, 300, 725, 7129, 8474, 366, 516, 281, 312, 1101, 570, 534, 264, 5598], "temperature": 0.0, "avg_logprob": -0.23143845862084692, "compression_ratio": 1.6228070175438596, "no_speech_prob": 1.8448193941367208e-06}, {"id": 311, "seek": 140164, "start": 1419.5600000000002, "end": 1422.0, "text": " and the input are", "tokens": [293, 264, 4846, 366], "temperature": 0.0, "avg_logprob": -0.23143845862084692, "compression_ratio": 1.6228070175438596, "no_speech_prob": 1.8448193941367208e-06}, {"id": 312, "seek": 140164, "start": 1422.92, "end": 1425.0800000000002, "text": " Very very similar, right?", "tokens": [4372, 588, 2531, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23143845862084692, "compression_ratio": 1.6228070175438596, "no_speech_prob": 1.8448193941367208e-06}, {"id": 313, "seek": 140164, "start": 1425.0800000000002, "end": 1430.64, "text": " So we really want a kind of a flow through path that allows as little fussing around as possible", "tokens": [407, 321, 534, 528, 257, 733, 295, 257, 3095, 807, 3100, 300, 4045, 382, 707, 34792, 278, 926, 382, 1944], "temperature": 0.0, "avg_logprob": -0.23143845862084692, "compression_ratio": 1.6228070175438596, "no_speech_prob": 1.8448193941367208e-06}, {"id": 314, "seek": 143064, "start": 1430.64, "end": 1433.5200000000002, "text": " except kind of the minimal amount necessary to do our", "tokens": [3993, 733, 295, 264, 13206, 2372, 4818, 281, 360, 527], "temperature": 0.0, "avg_logprob": -0.18174256824311755, "compression_ratio": 1.711191335740072, "no_speech_prob": 2.3454325059901748e-07}, {"id": 315, "seek": 143064, "start": 1434.24, "end": 1437.24, "text": " Super resolution and so if we use resnet blocks", "tokens": [4548, 8669, 293, 370, 498, 321, 764, 725, 7129, 8474], "temperature": 0.0, "avg_logprob": -0.18174256824311755, "compression_ratio": 1.711191335740072, "no_speech_prob": 2.3454325059901748e-07}, {"id": 316, "seek": 143064, "start": 1438.44, "end": 1446.1200000000001, "text": " Then they have an identity path already. Right? So like you can imagine the most simple version where it does like a you know", "tokens": [1396, 436, 362, 364, 6575, 3100, 1217, 13, 1779, 30, 407, 411, 291, 393, 3811, 264, 881, 2199, 3037, 689, 309, 775, 411, 257, 291, 458], "temperature": 0.0, "avg_logprob": -0.18174256824311755, "compression_ratio": 1.711191335740072, "no_speech_prob": 2.3454325059901748e-07}, {"id": 317, "seek": 143064, "start": 1448.2800000000002, "end": 1450.76, "text": " Bilinear sampling kind of approach or something", "tokens": [22879, 533, 289, 21179, 733, 295, 3109, 420, 746], "temperature": 0.0, "avg_logprob": -0.18174256824311755, "compression_ratio": 1.711191335740072, "no_speech_prob": 2.3454325059901748e-07}, {"id": 318, "seek": 143064, "start": 1450.76, "end": 1455.0, "text": " It could basically just go through identity blocks all the way through and then in the up sampling blocks", "tokens": [467, 727, 1936, 445, 352, 807, 6575, 8474, 439, 264, 636, 807, 293, 550, 294, 264, 493, 21179, 8474], "temperature": 0.0, "avg_logprob": -0.18174256824311755, "compression_ratio": 1.711191335740072, "no_speech_prob": 2.3454325059901748e-07}, {"id": 319, "seek": 145500, "start": 1455.0, "end": 1461.44, "text": " Just learn to take the averages of the inputs and get something that's like not too terrible", "tokens": [1449, 1466, 281, 747, 264, 42257, 295, 264, 15743, 293, 483, 746, 300, 311, 411, 406, 886, 6237], "temperature": 0.0, "avg_logprob": -0.20453700771579494, "compression_ratio": 1.6647727272727273, "no_speech_prob": 2.2959095531405183e-06}, {"id": 320, "seek": 145500, "start": 1461.76, "end": 1463.76, "text": " So that's what we're going to do we're going to create", "tokens": [407, 300, 311, 437, 321, 434, 516, 281, 360, 321, 434, 516, 281, 1884], "temperature": 0.0, "avg_logprob": -0.20453700771579494, "compression_ratio": 1.6647727272727273, "no_speech_prob": 2.2959095531405183e-06}, {"id": 321, "seek": 145500, "start": 1465.2, "end": 1468.68, "text": " Something with five resnet blocks and then for each", "tokens": [6595, 365, 1732, 725, 7129, 8474, 293, 550, 337, 1184], "temperature": 0.0, "avg_logprob": -0.20453700771579494, "compression_ratio": 1.6647727272727273, "no_speech_prob": 2.2959095531405183e-06}, {"id": 322, "seek": 145500, "start": 1470.16, "end": 1474.88, "text": " 2x scale up we have to do we'll have one up sampling block", "tokens": [568, 87, 4373, 493, 321, 362, 281, 360, 321, 603, 362, 472, 493, 21179, 3461], "temperature": 0.0, "avg_logprob": -0.20453700771579494, "compression_ratio": 1.6647727272727273, "no_speech_prob": 2.2959095531405183e-06}, {"id": 323, "seek": 145500, "start": 1478.04, "end": 1480.04, "text": " So they're all going to consist of", "tokens": [407, 436, 434, 439, 516, 281, 4603, 295], "temperature": 0.0, "avg_logprob": -0.20453700771579494, "compression_ratio": 1.6647727272727273, "no_speech_prob": 2.2959095531405183e-06}, {"id": 324, "seek": 148004, "start": 1480.04, "end": 1485.84, "text": " Obviously as per usual convolution layers possibly with activation functions after many of them", "tokens": [7580, 382, 680, 7713, 45216, 7914, 6264, 365, 24433, 6828, 934, 867, 295, 552], "temperature": 0.0, "avg_logprob": -0.2184424564756196, "compression_ratio": 1.6446280991735538, "no_speech_prob": 5.862753369001439e-06}, {"id": 325, "seek": 148004, "start": 1486.36, "end": 1488.8, "text": " so I kind of like to put my", "tokens": [370, 286, 733, 295, 411, 281, 829, 452], "temperature": 0.0, "avg_logprob": -0.2184424564756196, "compression_ratio": 1.6446280991735538, "no_speech_prob": 5.862753369001439e-06}, {"id": 326, "seek": 148004, "start": 1489.68, "end": 1494.1599999999999, "text": " Standard convolution block into a function so I can refactor it more easily", "tokens": [21298, 45216, 3461, 666, 257, 2445, 370, 286, 393, 1895, 15104, 309, 544, 3612], "temperature": 0.0, "avg_logprob": -0.2184424564756196, "compression_ratio": 1.6446280991735538, "no_speech_prob": 5.862753369001439e-06}, {"id": 327, "seek": 148004, "start": 1495.68, "end": 1502.1599999999999, "text": " As per usual I just won't worry about passing in padding and just calculate it directly as kernel size over 2", "tokens": [1018, 680, 7713, 286, 445, 1582, 380, 3292, 466, 8437, 294, 39562, 293, 445, 8873, 309, 3838, 382, 28256, 2744, 670, 568], "temperature": 0.0, "avg_logprob": -0.2184424564756196, "compression_ratio": 1.6446280991735538, "no_speech_prob": 5.862753369001439e-06}, {"id": 328, "seek": 148004, "start": 1503.8799999999999, "end": 1508.74, "text": " So one interesting thing about our little common block here is that there's no batch non", "tokens": [407, 472, 1880, 551, 466, 527, 707, 2689, 3461, 510, 307, 300, 456, 311, 572, 15245, 2107], "temperature": 0.0, "avg_logprob": -0.2184424564756196, "compression_ratio": 1.6446280991735538, "no_speech_prob": 5.862753369001439e-06}, {"id": 329, "seek": 150874, "start": 1508.74, "end": 1513.06, "text": " Which is pretty unusual for resnet type models", "tokens": [3013, 307, 1238, 10901, 337, 725, 7129, 2010, 5245], "temperature": 0.0, "avg_logprob": -0.21231105479788273, "compression_ratio": 1.5932203389830508, "no_speech_prob": 1.6797255284473067e-06}, {"id": 330, "seek": 150874, "start": 1514.42, "end": 1519.5, "text": " And the reason there's no batch norm is because I'm stealing ideas from this fantastic", "tokens": [400, 264, 1778, 456, 311, 572, 15245, 2026, 307, 570, 286, 478, 19757, 3487, 490, 341, 5456], "temperature": 0.0, "avg_logprob": -0.21231105479788273, "compression_ratio": 1.5932203389830508, "no_speech_prob": 1.6797255284473067e-06}, {"id": 331, "seek": 150874, "start": 1520.14, "end": 1526.1, "text": " Recent paper which actually won a recent competition in super resolution", "tokens": [17553, 3035, 597, 767, 1582, 257, 5162, 6211, 294, 1687, 8669], "temperature": 0.0, "avg_logprob": -0.21231105479788273, "compression_ratio": 1.5932203389830508, "no_speech_prob": 1.6797255284473067e-06}, {"id": 332, "seek": 150874, "start": 1527.14, "end": 1528.26, "text": " performance", "tokens": [3389], "temperature": 0.0, "avg_logprob": -0.21231105479788273, "compression_ratio": 1.5932203389830508, "no_speech_prob": 1.6797255284473067e-06}, {"id": 333, "seek": 150874, "start": 1528.26, "end": 1532.22, "text": " And to see how good this paper is here's kind of a previous state-of-the-art", "tokens": [400, 281, 536, 577, 665, 341, 3035, 307, 510, 311, 733, 295, 257, 3894, 1785, 12, 2670, 12, 3322, 12, 446], "temperature": 0.0, "avg_logprob": -0.21231105479788273, "compression_ratio": 1.5932203389830508, "no_speech_prob": 1.6797255284473067e-06}, {"id": 334, "seek": 150874, "start": 1532.22, "end": 1537.3, "text": " There's SR resnet right and what they've done here is they've zoomed way in to a", "tokens": [821, 311, 20840, 725, 7129, 558, 293, 437, 436, 600, 1096, 510, 307, 436, 600, 8863, 292, 636, 294, 281, 257], "temperature": 0.0, "avg_logprob": -0.21231105479788273, "compression_ratio": 1.5932203389830508, "no_speech_prob": 1.6797255284473067e-06}, {"id": 335, "seek": 153730, "start": 1537.3, "end": 1544.4199999999998, "text": " an up sampled kind of net or or fence right this is the original and you can see in the", "tokens": [364, 493, 3247, 15551, 733, 295, 2533, 420, 420, 15422, 558, 341, 307, 264, 3380, 293, 291, 393, 536, 294, 264], "temperature": 0.0, "avg_logprob": -0.24033063771773358, "compression_ratio": 1.5991735537190082, "no_speech_prob": 1.9033760736419936e-06}, {"id": 336, "seek": 153730, "start": 1545.06, "end": 1549.54, "text": " The kind of previous best approach. There's a whole lot of distortion and blurring going on", "tokens": [440, 733, 295, 3894, 1151, 3109, 13, 821, 311, 257, 1379, 688, 295, 28426, 293, 14257, 2937, 516, 322], "temperature": 0.0, "avg_logprob": -0.24033063771773358, "compression_ratio": 1.5991735537190082, "no_speech_prob": 1.9033760736419936e-06}, {"id": 337, "seek": 153730, "start": 1549.98, "end": 1551.98, "text": " All right, where else in their approach?", "tokens": [1057, 558, 11, 689, 1646, 294, 641, 3109, 30], "temperature": 0.0, "avg_logprob": -0.24033063771773358, "compression_ratio": 1.5991735537190082, "no_speech_prob": 1.9033760736419936e-06}, {"id": 338, "seek": 153730, "start": 1552.1399999999999, "end": 1558.3799999999999, "text": " It's it's nearly perfect. All right, so like it was a really big step up this paper", "tokens": [467, 311, 309, 311, 6217, 2176, 13, 1057, 558, 11, 370, 411, 309, 390, 257, 534, 955, 1823, 493, 341, 3035], "temperature": 0.0, "avg_logprob": -0.24033063771773358, "compression_ratio": 1.5991735537190082, "no_speech_prob": 1.9033760736419936e-06}, {"id": 339, "seek": 153730, "start": 1559.1, "end": 1564.4199999999998, "text": " They call their model EDSR enhanced deep residual networks and they did two things", "tokens": [814, 818, 641, 2316, 462, 11844, 49, 21191, 2452, 27980, 9590, 293, 436, 630, 732, 721], "temperature": 0.0, "avg_logprob": -0.24033063771773358, "compression_ratio": 1.5991735537190082, "no_speech_prob": 1.9033760736419936e-06}, {"id": 340, "seek": 156442, "start": 1564.42, "end": 1569.02, "text": " differently to the kind of previous standard approaches", "tokens": [7614, 281, 264, 733, 295, 3894, 3832, 11587], "temperature": 0.0, "avg_logprob": -0.21108613531273532, "compression_ratio": 1.765, "no_speech_prob": 2.156809159714612e-06}, {"id": 341, "seek": 156442, "start": 1569.78, "end": 1575.3000000000002, "text": " One was to take the resnet blocks. This is a regular resnet block and throw away the batch norm", "tokens": [1485, 390, 281, 747, 264, 725, 7129, 8474, 13, 639, 307, 257, 3890, 725, 7129, 3461, 293, 3507, 1314, 264, 15245, 2026], "temperature": 0.0, "avg_logprob": -0.21108613531273532, "compression_ratio": 1.765, "no_speech_prob": 2.156809159714612e-06}, {"id": 342, "seek": 156442, "start": 1576.98, "end": 1583.7, "text": " So why would they throw away the batch norm? Well, the reason they would throw away the batch norm is because batch norm", "tokens": [407, 983, 576, 436, 3507, 1314, 264, 15245, 2026, 30, 1042, 11, 264, 1778, 436, 576, 3507, 1314, 264, 15245, 2026, 307, 570, 15245, 2026], "temperature": 0.0, "avg_logprob": -0.21108613531273532, "compression_ratio": 1.765, "no_speech_prob": 2.156809159714612e-06}, {"id": 343, "seek": 156442, "start": 1584.42, "end": 1586.96, "text": " Changes stuff and we want a nice", "tokens": [761, 10350, 1507, 293, 321, 528, 257, 1481], "temperature": 0.0, "avg_logprob": -0.21108613531273532, "compression_ratio": 1.765, "no_speech_prob": 2.156809159714612e-06}, {"id": 344, "seek": 156442, "start": 1587.74, "end": 1590.22, "text": " Straight through path that doesn't change stuff", "tokens": [26908, 807, 3100, 300, 1177, 380, 1319, 1507], "temperature": 0.0, "avg_logprob": -0.21108613531273532, "compression_ratio": 1.765, "no_speech_prob": 2.156809159714612e-06}, {"id": 345, "seek": 159022, "start": 1590.22, "end": 1596.74, "text": " Okay, so the idea basically here is like hey if you don't want to fiddle with the input more than you have to", "tokens": [1033, 11, 370, 264, 1558, 1936, 510, 307, 411, 4177, 498, 291, 500, 380, 528, 281, 24553, 2285, 365, 264, 4846, 544, 813, 291, 362, 281], "temperature": 0.0, "avg_logprob": -0.19049189488093057, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.1189400765942992e-06}, {"id": 346, "seek": 159022, "start": 1596.78, "end": 1600.58, "text": " Then don't force it to have to calculate things like batch norm parameters", "tokens": [1396, 500, 380, 3464, 309, 281, 362, 281, 8873, 721, 411, 15245, 2026, 9834], "temperature": 0.0, "avg_logprob": -0.19049189488093057, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.1189400765942992e-06}, {"id": 347, "seek": 159022, "start": 1600.7, "end": 1607.46, "text": " So throw away the batch norm and the second trick we'll see shortly. All right, so here's a con with no batch norm", "tokens": [407, 3507, 1314, 264, 15245, 2026, 293, 264, 1150, 4282, 321, 603, 536, 13392, 13, 1057, 558, 11, 370, 510, 311, 257, 416, 365, 572, 15245, 2026], "temperature": 0.0, "avg_logprob": -0.19049189488093057, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.1189400765942992e-06}, {"id": 348, "seek": 159022, "start": 1609.1000000000001, "end": 1611.26, "text": " And so then we're going to create a", "tokens": [400, 370, 550, 321, 434, 516, 281, 1884, 257], "temperature": 0.0, "avg_logprob": -0.19049189488093057, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.1189400765942992e-06}, {"id": 349, "seek": 159022, "start": 1612.38, "end": 1614.38, "text": " residual block", "tokens": [27980, 3461], "temperature": 0.0, "avg_logprob": -0.19049189488093057, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.1189400765942992e-06}, {"id": 350, "seek": 159022, "start": 1614.42, "end": 1616.22, "text": " containing as per usual", "tokens": [19273, 382, 680, 7713], "temperature": 0.0, "avg_logprob": -0.19049189488093057, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.1189400765942992e-06}, {"id": 351, "seek": 161622, "start": 1616.22, "end": 1622.7, "text": " Two convolutions and as you see in their approach they even they don't even have a relu after their second con", "tokens": [4453, 3754, 15892, 293, 382, 291, 536, 294, 641, 3109, 436, 754, 436, 500, 380, 754, 362, 257, 1039, 84, 934, 641, 1150, 416], "temperature": 0.0, "avg_logprob": -0.171110010858792, "compression_ratio": 1.4914285714285713, "no_speech_prob": 1.5534908470726805e-06}, {"id": 352, "seek": 161622, "start": 1622.82, "end": 1626.02, "text": " Okay, so that's why I've only got activation on the first one", "tokens": [1033, 11, 370, 300, 311, 983, 286, 600, 787, 658, 24433, 322, 264, 700, 472], "temperature": 0.0, "avg_logprob": -0.171110010858792, "compression_ratio": 1.4914285714285713, "no_speech_prob": 1.5534908470726805e-06}, {"id": 353, "seek": 161622, "start": 1631.26, "end": 1633.26, "text": " So a", "tokens": [407, 257], "temperature": 0.0, "avg_logprob": -0.171110010858792, "compression_ratio": 1.4914285714285713, "no_speech_prob": 1.5534908470726805e-06}, {"id": 354, "seek": 161622, "start": 1634.1000000000001, "end": 1639.94, "text": " Couple of interesting things here one is that this idea of like having some kind of", "tokens": [38266, 295, 1880, 721, 510, 472, 307, 300, 341, 1558, 295, 411, 1419, 512, 733, 295], "temperature": 0.0, "avg_logprob": -0.171110010858792, "compression_ratio": 1.4914285714285713, "no_speech_prob": 1.5534908470726805e-06}, {"id": 355, "seek": 163994, "start": 1639.94, "end": 1649.98, "text": " Main resnet path like conv relu cons and then turning that into a relu block by adding it back to the identity", "tokens": [12383, 725, 7129, 3100, 411, 3754, 1039, 84, 1014, 293, 550, 6246, 300, 666, 257, 1039, 84, 3461, 538, 5127, 309, 646, 281, 264, 6575], "temperature": 0.0, "avg_logprob": -0.18609842047633895, "compression_ratio": 1.6009615384615385, "no_speech_prob": 2.4439832486677915e-06}, {"id": 356, "seek": 163994, "start": 1649.98, "end": 1656.14, "text": " It's something we do so often. I kind of factored it out into a tiny little module called res sequential", "tokens": [467, 311, 746, 321, 360, 370, 2049, 13, 286, 733, 295, 1186, 2769, 309, 484, 666, 257, 5870, 707, 10088, 1219, 725, 42881], "temperature": 0.0, "avg_logprob": -0.18609842047633895, "compression_ratio": 1.6009615384615385, "no_speech_prob": 2.4439832486677915e-06}, {"id": 357, "seek": 163994, "start": 1656.42, "end": 1661.02, "text": " Which simply takes a bunch of layers that you want to put into your?", "tokens": [3013, 2935, 2516, 257, 3840, 295, 7914, 300, 291, 528, 281, 829, 666, 428, 30], "temperature": 0.0, "avg_logprob": -0.18609842047633895, "compression_ratio": 1.6009615384615385, "no_speech_prob": 2.4439832486677915e-06}, {"id": 358, "seek": 163994, "start": 1662.14, "end": 1664.02, "text": " residual path", "tokens": [27980, 3100], "temperature": 0.0, "avg_logprob": -0.18609842047633895, "compression_ratio": 1.6009615384615385, "no_speech_prob": 2.4439832486677915e-06}, {"id": 359, "seek": 163994, "start": 1664.02, "end": 1666.02, "text": " Turns that into a sequential model", "tokens": [29524, 300, 666, 257, 42881, 2316], "temperature": 0.0, "avg_logprob": -0.18609842047633895, "compression_ratio": 1.6009615384615385, "no_speech_prob": 2.4439832486677915e-06}, {"id": 360, "seek": 166602, "start": 1666.02, "end": 1673.86, "text": " It runs it and then adds it back to the input right so with this little module we can now turn anything", "tokens": [467, 6676, 309, 293, 550, 10860, 309, 646, 281, 264, 4846, 558, 370, 365, 341, 707, 10088, 321, 393, 586, 1261, 1340], "temperature": 0.0, "avg_logprob": -0.2259371621268136, "compression_ratio": 1.5326633165829147, "no_speech_prob": 8.851556003719452e-07}, {"id": 361, "seek": 166602, "start": 1674.66, "end": 1681.6, "text": " Like con activation cons into a resnet block just by wrapping it in res sequential", "tokens": [1743, 416, 24433, 1014, 666, 257, 725, 7129, 3461, 445, 538, 21993, 309, 294, 725, 42881], "temperature": 0.0, "avg_logprob": -0.2259371621268136, "compression_ratio": 1.5326633165829147, "no_speech_prob": 8.851556003719452e-07}, {"id": 362, "seek": 166602, "start": 1684.42, "end": 1688.08, "text": " But that's not quite all I'm doing because like normally a res block", "tokens": [583, 300, 311, 406, 1596, 439, 286, 478, 884, 570, 411, 5646, 257, 725, 3461], "temperature": 0.0, "avg_logprob": -0.2259371621268136, "compression_ratio": 1.5326633165829147, "no_speech_prob": 8.851556003719452e-07}, {"id": 363, "seek": 166602, "start": 1688.98, "end": 1692.82, "text": " Just has that in its forward, but I also got", "tokens": [1449, 575, 300, 294, 1080, 2128, 11, 457, 286, 611, 658], "temperature": 0.0, "avg_logprob": -0.2259371621268136, "compression_ratio": 1.5326633165829147, "no_speech_prob": 8.851556003719452e-07}, {"id": 364, "seek": 166602, "start": 1693.66, "end": 1695.26, "text": " that", "tokens": [300], "temperature": 0.0, "avg_logprob": -0.2259371621268136, "compression_ratio": 1.5326633165829147, "no_speech_prob": 8.851556003719452e-07}, {"id": 365, "seek": 169526, "start": 1695.26, "end": 1698.3799999999999, "text": " What's res scale res scale is the number 0.1?", "tokens": [708, 311, 725, 4373, 725, 4373, 307, 264, 1230, 1958, 13, 16, 30], "temperature": 0.0, "avg_logprob": -0.21700606949027929, "compression_ratio": 1.5369458128078817, "no_speech_prob": 2.058040536212502e-06}, {"id": 366, "seek": 169526, "start": 1699.62, "end": 1701.62, "text": " Why is it there?", "tokens": [1545, 307, 309, 456, 30], "temperature": 0.0, "avg_logprob": -0.21700606949027929, "compression_ratio": 1.5369458128078817, "no_speech_prob": 2.058040536212502e-06}, {"id": 367, "seek": 169526, "start": 1701.98, "end": 1704.1, "text": " I'm not sure anybody quite knows", "tokens": [286, 478, 406, 988, 4472, 1596, 3255], "temperature": 0.0, "avg_logprob": -0.21700606949027929, "compression_ratio": 1.5369458128078817, "no_speech_prob": 2.058040536212502e-06}, {"id": 368, "seek": 169526, "start": 1704.86, "end": 1706.86, "text": " but the short answer is that", "tokens": [457, 264, 2099, 1867, 307, 300], "temperature": 0.0, "avg_logprob": -0.21700606949027929, "compression_ratio": 1.5369458128078817, "no_speech_prob": 2.058040536212502e-06}, {"id": 369, "seek": 169526, "start": 1707.86, "end": 1711.22, "text": " the guy who invented batch norm also", "tokens": [264, 2146, 567, 14479, 15245, 2026, 611], "temperature": 0.0, "avg_logprob": -0.21700606949027929, "compression_ratio": 1.5369458128078817, "no_speech_prob": 2.058040536212502e-06}, {"id": 370, "seek": 169526, "start": 1712.22, "end": 1714.58, "text": " Somewhat more recently did a paper in which he showed", "tokens": [2188, 5479, 544, 3938, 630, 257, 3035, 294, 597, 415, 4712], "temperature": 0.0, "avg_logprob": -0.21700606949027929, "compression_ratio": 1.5369458128078817, "no_speech_prob": 2.058040536212502e-06}, {"id": 371, "seek": 169526, "start": 1715.1, "end": 1722.86, "text": " I think the first time the ability to train image net in under an hour and the way he did it was", "tokens": [286, 519, 264, 700, 565, 264, 3485, 281, 3847, 3256, 2533, 294, 833, 364, 1773, 293, 264, 636, 415, 630, 309, 390], "temperature": 0.0, "avg_logprob": -0.21700606949027929, "compression_ratio": 1.5369458128078817, "no_speech_prob": 2.058040536212502e-06}, {"id": 372, "seek": 172286, "start": 1722.86, "end": 1725.54, "text": " fire up lots and lots of machines and", "tokens": [2610, 493, 3195, 293, 3195, 295, 8379, 293], "temperature": 0.0, "avg_logprob": -0.21130430287328258, "compression_ratio": 1.8405797101449275, "no_speech_prob": 1.7330451100860955e-06}, {"id": 373, "seek": 172286, "start": 1726.6599999999999, "end": 1730.34, "text": " Have them work in parallel to create really large batch sizes", "tokens": [3560, 552, 589, 294, 8952, 281, 1884, 534, 2416, 15245, 11602], "temperature": 0.0, "avg_logprob": -0.21130430287328258, "compression_ratio": 1.8405797101449275, "no_speech_prob": 1.7330451100860955e-06}, {"id": 374, "seek": 172286, "start": 1730.9399999999998, "end": 1734.9399999999998, "text": " Now generally when you increase the batch size by order n", "tokens": [823, 5101, 562, 291, 3488, 264, 15245, 2744, 538, 1668, 297], "temperature": 0.0, "avg_logprob": -0.21130430287328258, "compression_ratio": 1.8405797101449275, "no_speech_prob": 1.7330451100860955e-06}, {"id": 375, "seek": 172286, "start": 1735.3, "end": 1742.34, "text": " You also increase the learning rate by order n to go with it so generally very large batch size training means very high", "tokens": [509, 611, 3488, 264, 2539, 3314, 538, 1668, 297, 281, 352, 365, 309, 370, 5101, 588, 2416, 15245, 2744, 3097, 1355, 588, 1090], "temperature": 0.0, "avg_logprob": -0.21130430287328258, "compression_ratio": 1.8405797101449275, "no_speech_prob": 1.7330451100860955e-06}, {"id": 376, "seek": 172286, "start": 1742.86, "end": 1749.6999999999998, "text": " Learning rate training as well, and he found that with these very large batch sizes of like 8,000 plus", "tokens": [15205, 3314, 3097, 382, 731, 11, 293, 415, 1352, 300, 365, 613, 588, 2416, 15245, 11602, 295, 411, 1649, 11, 1360, 1804], "temperature": 0.0, "avg_logprob": -0.21130430287328258, "compression_ratio": 1.8405797101449275, "no_speech_prob": 1.7330451100860955e-06}, {"id": 377, "seek": 174970, "start": 1749.7, "end": 1757.22, "text": " or even up to 32,000 that at the start of training his activations would basically go straight to infinity and", "tokens": [420, 754, 493, 281, 8858, 11, 1360, 300, 412, 264, 722, 295, 3097, 702, 2430, 763, 576, 1936, 352, 2997, 281, 13202, 293], "temperature": 0.0, "avg_logprob": -0.17113153366815476, "compression_ratio": 1.6934306569343065, "no_speech_prob": 2.332053782083676e-06}, {"id": 378, "seek": 174970, "start": 1758.42, "end": 1764.8600000000001, "text": " A lot of other people have found that we actually found that when we were competing in dawn bench both on the cipher and the image", "tokens": [316, 688, 295, 661, 561, 362, 1352, 300, 321, 767, 1352, 300, 562, 321, 645, 15439, 294, 18192, 10638, 1293, 322, 264, 269, 21240, 293, 264, 3256], "temperature": 0.0, "avg_logprob": -0.17113153366815476, "compression_ratio": 1.6934306569343065, "no_speech_prob": 2.332053782083676e-06}, {"id": 379, "seek": 174970, "start": 1764.8600000000001, "end": 1766.94, "text": " net competitions that you know we really", "tokens": [2533, 26185, 300, 291, 458, 321, 534], "temperature": 0.0, "avg_logprob": -0.17113153366815476, "compression_ratio": 1.6934306569343065, "no_speech_prob": 2.332053782083676e-06}, {"id": 380, "seek": 174970, "start": 1767.7, "end": 1772.6200000000001, "text": " struggled to make the most of even the 8 GPUs that we were trying to take advantage of because of these kind of", "tokens": [19023, 281, 652, 264, 881, 295, 754, 264, 1649, 18407, 82, 300, 321, 645, 1382, 281, 747, 5002, 295, 570, 295, 613, 733, 295], "temperature": 0.0, "avg_logprob": -0.17113153366815476, "compression_ratio": 1.6934306569343065, "no_speech_prob": 2.332053782083676e-06}, {"id": 381, "seek": 174970, "start": 1774.3400000000001, "end": 1777.26, "text": " Challenges with these larger batch sizes and taking advantage of them", "tokens": [14398, 47077, 365, 613, 4833, 15245, 11602, 293, 1940, 5002, 295, 552], "temperature": 0.0, "avg_logprob": -0.17113153366815476, "compression_ratio": 1.6934306569343065, "no_speech_prob": 2.332053782083676e-06}, {"id": 382, "seek": 177726, "start": 1777.26, "end": 1784.78, "text": " So something that Christian found this researcher was that if he in the ResNet blocks if he multiplied them by some number", "tokens": [407, 746, 300, 5778, 1352, 341, 21751, 390, 300, 498, 415, 294, 264, 5015, 31890, 8474, 498, 415, 17207, 552, 538, 512, 1230], "temperature": 0.0, "avg_logprob": -0.2692122282805266, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.9637886907730717e-06}, {"id": 383, "seek": 177726, "start": 1784.94, "end": 1788.14, "text": " Smaller than one something like point one or point two", "tokens": [15287, 260, 813, 472, 746, 411, 935, 472, 420, 935, 732], "temperature": 0.0, "avg_logprob": -0.2692122282805266, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.9637886907730717e-06}, {"id": 384, "seek": 177726, "start": 1788.78, "end": 1790.78, "text": " It really helped stabilize training", "tokens": [467, 534, 4254, 31870, 3097], "temperature": 0.0, "avg_logprob": -0.2692122282805266, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.9637886907730717e-06}, {"id": 385, "seek": 177726, "start": 1791.5, "end": 1793.5, "text": " at the start and", "tokens": [412, 264, 722, 293], "temperature": 0.0, "avg_logprob": -0.2692122282805266, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.9637886907730717e-06}, {"id": 386, "seek": 177726, "start": 1793.86, "end": 1802.18, "text": " That's kind of weird because like mathematically. It's kind of identical right because obviously whatever I'm multiplying it by", "tokens": [663, 311, 733, 295, 3657, 570, 411, 44003, 13, 467, 311, 733, 295, 14800, 558, 570, 2745, 2035, 286, 478, 30955, 309, 538], "temperature": 0.0, "avg_logprob": -0.2692122282805266, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.9637886907730717e-06}, {"id": 387, "seek": 177726, "start": 1802.7, "end": 1804.7, "text": " here", "tokens": [510], "temperature": 0.0, "avg_logprob": -0.2692122282805266, "compression_ratio": 1.6133333333333333, "no_speech_prob": 1.9637886907730717e-06}, {"id": 388, "seek": 180470, "start": 1804.7, "end": 1808.98, "text": " You know I could just scale the weights by the opposite amount here and have the same number", "tokens": [509, 458, 286, 727, 445, 4373, 264, 17443, 538, 264, 6182, 2372, 510, 293, 362, 264, 912, 1230], "temperature": 0.0, "avg_logprob": -0.20470102855137418, "compression_ratio": 1.5916230366492146, "no_speech_prob": 8.990894571070385e-07}, {"id": 389, "seek": 180470, "start": 1809.42, "end": 1812.38, "text": " right so but it's kind of like", "tokens": [558, 370, 457, 309, 311, 733, 295, 411], "temperature": 0.0, "avg_logprob": -0.20470102855137418, "compression_ratio": 1.5916230366492146, "no_speech_prob": 8.990894571070385e-07}, {"id": 390, "seek": 180470, "start": 1813.94, "end": 1817.6200000000001, "text": " We're not dealing with abstract math. You know we're dealing with like", "tokens": [492, 434, 406, 6260, 365, 12649, 5221, 13, 509, 458, 321, 434, 6260, 365, 411], "temperature": 0.0, "avg_logprob": -0.20470102855137418, "compression_ratio": 1.5916230366492146, "no_speech_prob": 8.990894571070385e-07}, {"id": 391, "seek": 180470, "start": 1818.5, "end": 1822.3, "text": " you know real optimization problems and", "tokens": [291, 458, 957, 19618, 2740, 293], "temperature": 0.0, "avg_logprob": -0.20470102855137418, "compression_ratio": 1.5916230366492146, "no_speech_prob": 8.990894571070385e-07}, {"id": 392, "seek": 180470, "start": 1823.5800000000002, "end": 1828.22, "text": " different initializations and learning rates and whatever else and so", "tokens": [819, 5883, 14455, 293, 2539, 6846, 293, 2035, 1646, 293, 370], "temperature": 0.0, "avg_logprob": -0.20470102855137418, "compression_ratio": 1.5916230366492146, "no_speech_prob": 8.990894571070385e-07}, {"id": 393, "seek": 182822, "start": 1828.22, "end": 1833.94, "text": " The problem of kind of weights disappearing off into infinity", "tokens": [440, 1154, 295, 733, 295, 17443, 34900, 766, 666, 13202], "temperature": 0.0, "avg_logprob": -0.20941617411951866, "compression_ratio": 1.6626016260162602, "no_speech_prob": 2.090447196678724e-06}, {"id": 394, "seek": 182822, "start": 1833.94, "end": 1840.5, "text": " I guess generally is really about the kind of the discrete and finite nature of computers in in practice partly", "tokens": [286, 2041, 5101, 307, 534, 466, 264, 733, 295, 264, 27706, 293, 19362, 3687, 295, 10807, 294, 294, 3124, 17031], "temperature": 0.0, "avg_logprob": -0.20941617411951866, "compression_ratio": 1.6626016260162602, "no_speech_prob": 2.090447196678724e-06}, {"id": 395, "seek": 182822, "start": 1841.02, "end": 1844.94, "text": " and so often yeah, these kind of little tricks can", "tokens": [293, 370, 2049, 1338, 11, 613, 733, 295, 707, 11733, 393], "temperature": 0.0, "avg_logprob": -0.20941617411951866, "compression_ratio": 1.6626016260162602, "no_speech_prob": 2.090447196678724e-06}, {"id": 396, "seek": 182822, "start": 1845.58, "end": 1848.26, "text": " Can make the difference right so in this case. We're just", "tokens": [1664, 652, 264, 2649, 558, 370, 294, 341, 1389, 13, 492, 434, 445], "temperature": 0.0, "avg_logprob": -0.20941617411951866, "compression_ratio": 1.6626016260162602, "no_speech_prob": 2.090447196678724e-06}, {"id": 397, "seek": 182822, "start": 1849.02, "end": 1851.02, "text": " Kind of toning things down", "tokens": [9242, 295, 2952, 278, 721, 760], "temperature": 0.0, "avg_logprob": -0.20941617411951866, "compression_ratio": 1.6626016260162602, "no_speech_prob": 2.090447196678724e-06}, {"id": 398, "seek": 185102, "start": 1851.02, "end": 1857.34, "text": " On base at least based on our initial initialization, and so there are probably other ways to do this", "tokens": [1282, 3096, 412, 1935, 2361, 322, 527, 5883, 5883, 2144, 11, 293, 370, 456, 366, 1391, 661, 2098, 281, 360, 341], "temperature": 0.0, "avg_logprob": -0.20857572555541992, "compression_ratio": 1.5608695652173914, "no_speech_prob": 4.565922608890105e-06}, {"id": 399, "seek": 185102, "start": 1858.02, "end": 1860.02, "text": " For example one approach", "tokens": [1171, 1365, 472, 3109], "temperature": 0.0, "avg_logprob": -0.20857572555541992, "compression_ratio": 1.5608695652173914, "no_speech_prob": 4.565922608890105e-06}, {"id": 400, "seek": 185102, "start": 1860.54, "end": 1868.32, "text": " From some folks at Nvidia called Lars la RS which I briefly mentioned last week is an approach which uses discriminative learning rates", "tokens": [3358, 512, 4024, 412, 46284, 1219, 41563, 635, 25855, 597, 286, 10515, 2835, 1036, 1243, 307, 364, 3109, 597, 4960, 20828, 1166, 2539, 6846], "temperature": 0.0, "avg_logprob": -0.20857572555541992, "compression_ratio": 1.5608695652173914, "no_speech_prob": 4.565922608890105e-06}, {"id": 401, "seek": 185102, "start": 1869.34, "end": 1871.34, "text": " calculated in real time", "tokens": [15598, 294, 957, 565], "temperature": 0.0, "avg_logprob": -0.20857572555541992, "compression_ratio": 1.5608695652173914, "no_speech_prob": 4.565922608890105e-06}, {"id": 402, "seek": 185102, "start": 1871.42, "end": 1873.42, "text": " basically looking at the ratio between the", "tokens": [1936, 1237, 412, 264, 8509, 1296, 264], "temperature": 0.0, "avg_logprob": -0.20857572555541992, "compression_ratio": 1.5608695652173914, "no_speech_prob": 4.565922608890105e-06}, {"id": 403, "seek": 185102, "start": 1874.9, "end": 1876.9, "text": " gradients and the activations", "tokens": [2771, 2448, 293, 264, 2430, 763], "temperature": 0.0, "avg_logprob": -0.20857572555541992, "compression_ratio": 1.5608695652173914, "no_speech_prob": 4.565922608890105e-06}, {"id": 404, "seek": 187690, "start": 1876.9, "end": 1883.42, "text": " To scale learning rates by layer and so they found that they didn't need this", "tokens": [1407, 4373, 2539, 6846, 538, 4583, 293, 370, 436, 1352, 300, 436, 994, 380, 643, 341], "temperature": 0.0, "avg_logprob": -0.16792839001386595, "compression_ratio": 1.569377990430622, "no_speech_prob": 4.63783590021194e-06}, {"id": 405, "seek": 187690, "start": 1883.8200000000002, "end": 1886.7, "text": " Trick to scale it scale up the batch sizes a lot", "tokens": [43367, 281, 4373, 309, 4373, 493, 264, 15245, 11602, 257, 688], "temperature": 0.0, "avg_logprob": -0.16792839001386595, "compression_ratio": 1.569377990430622, "no_speech_prob": 4.63783590021194e-06}, {"id": 406, "seek": 187690, "start": 1889.46, "end": 1891.46, "text": " Maybe a different initialization", "tokens": [2704, 257, 819, 5883, 2144], "temperature": 0.0, "avg_logprob": -0.16792839001386595, "compression_ratio": 1.569377990430622, "no_speech_prob": 4.63783590021194e-06}, {"id": 407, "seek": 187690, "start": 1892.02, "end": 1894.02, "text": " Would would be all that's necessary", "tokens": [6068, 576, 312, 439, 300, 311, 4818], "temperature": 0.0, "avg_logprob": -0.16792839001386595, "compression_ratio": 1.569377990430622, "no_speech_prob": 4.63783590021194e-06}, {"id": 408, "seek": 187690, "start": 1894.6200000000001, "end": 1901.9, "text": " The reason I mentioned this is not so much because I think a lot of you are likely to want to train on massive clusters of computers", "tokens": [440, 1778, 286, 2835, 341, 307, 406, 370, 709, 570, 286, 519, 257, 688, 295, 291, 366, 3700, 281, 528, 281, 3847, 322, 5994, 23313, 295, 10807], "temperature": 0.0, "avg_logprob": -0.16792839001386595, "compression_ratio": 1.569377990430622, "no_speech_prob": 4.63783590021194e-06}, {"id": 409, "seek": 190190, "start": 1901.9, "end": 1909.26, "text": " But rather that I think a lot of you want to train models quickly and that means using high learning rates and ideally", "tokens": [583, 2831, 300, 286, 519, 257, 688, 295, 291, 528, 281, 3847, 5245, 2661, 293, 300, 1355, 1228, 1090, 2539, 6846, 293, 22915], "temperature": 0.0, "avg_logprob": -0.19939150991319102, "compression_ratio": 1.6169154228855722, "no_speech_prob": 6.3391194089490455e-06}, {"id": 410, "seek": 190190, "start": 1909.38, "end": 1911.38, "text": " getting superconvergence and", "tokens": [1242, 1687, 1671, 331, 15260, 293], "temperature": 0.0, "avg_logprob": -0.19939150991319102, "compression_ratio": 1.6169154228855722, "no_speech_prob": 6.3391194089490455e-06}, {"id": 411, "seek": 190190, "start": 1911.5800000000002, "end": 1914.1000000000001, "text": " I think these kinds of tricks", "tokens": [286, 519, 613, 3685, 295, 11733], "temperature": 0.0, "avg_logprob": -0.19939150991319102, "compression_ratio": 1.6169154228855722, "no_speech_prob": 6.3391194089490455e-06}, {"id": 412, "seek": 190190, "start": 1914.8600000000001, "end": 1922.18, "text": " The tricks that we'll need to be able to get superconvergence across more different architectures and so forth and", "tokens": [440, 11733, 300, 321, 603, 643, 281, 312, 1075, 281, 483, 1687, 1671, 331, 15260, 2108, 544, 819, 6331, 1303, 293, 370, 5220, 293], "temperature": 0.0, "avg_logprob": -0.19939150991319102, "compression_ratio": 1.6169154228855722, "no_speech_prob": 6.3391194089490455e-06}, {"id": 413, "seek": 190190, "start": 1923.26, "end": 1925.26, "text": " You know other than", "tokens": [509, 458, 661, 813], "temperature": 0.0, "avg_logprob": -0.19939150991319102, "compression_ratio": 1.6169154228855722, "no_speech_prob": 6.3391194089490455e-06}, {"id": 414, "seek": 190190, "start": 1925.38, "end": 1927.38, "text": " Leslie Smith", "tokens": [28140, 8538], "temperature": 0.0, "avg_logprob": -0.19939150991319102, "compression_ratio": 1.6169154228855722, "no_speech_prob": 6.3391194089490455e-06}, {"id": 415, "seek": 192738, "start": 1927.38, "end": 1932.3400000000001, "text": " No one else is really working on superconvergence other than some fast AI students nowadays", "tokens": [883, 472, 1646, 307, 534, 1364, 322, 1687, 1671, 331, 15260, 661, 813, 512, 2370, 7318, 1731, 13434], "temperature": 0.0, "avg_logprob": -0.1836891521107067, "compression_ratio": 1.6557971014492754, "no_speech_prob": 7.646366611879785e-06}, {"id": 416, "seek": 192738, "start": 1932.3400000000001, "end": 1936.42, "text": " So these kind of things about how do we train at very very high learning rates?", "tokens": [407, 613, 733, 295, 721, 466, 577, 360, 321, 3847, 412, 588, 588, 1090, 2539, 6846, 30], "temperature": 0.0, "avg_logprob": -0.1836891521107067, "compression_ratio": 1.6557971014492754, "no_speech_prob": 7.646366611879785e-06}, {"id": 417, "seek": 192738, "start": 1936.5400000000002, "end": 1939.3000000000002, "text": " we're going to be have to be the ones who figure it out because", "tokens": [321, 434, 516, 281, 312, 362, 281, 312, 264, 2306, 567, 2573, 309, 484, 570], "temperature": 0.0, "avg_logprob": -0.1836891521107067, "compression_ratio": 1.6557971014492754, "no_speech_prob": 7.646366611879785e-06}, {"id": 418, "seek": 192738, "start": 1940.0600000000002, "end": 1942.94, "text": " As far as I can tell nobody else gets yet", "tokens": [1018, 1400, 382, 286, 393, 980, 5079, 1646, 2170, 1939], "temperature": 0.0, "avg_logprob": -0.1836891521107067, "compression_ratio": 1.6557971014492754, "no_speech_prob": 7.646366611879785e-06}, {"id": 419, "seek": 192738, "start": 1943.8600000000001, "end": 1951.2, "text": " So so I think these you know the looking at the literature around you know training image net in one hour or more recently", "tokens": [407, 370, 286, 519, 613, 291, 458, 264, 1237, 412, 264, 10394, 926, 291, 458, 3097, 3256, 2533, 294, 472, 1773, 420, 544, 3938], "temperature": 0.0, "avg_logprob": -0.1836891521107067, "compression_ratio": 1.6557971014492754, "no_speech_prob": 7.646366611879785e-06}, {"id": 420, "seek": 192738, "start": 1951.2, "end": 1953.98, "text": " There's now a train image net in 15 minutes these papers", "tokens": [821, 311, 586, 257, 3847, 3256, 2533, 294, 2119, 2077, 613, 10577], "temperature": 0.0, "avg_logprob": -0.1836891521107067, "compression_ratio": 1.6557971014492754, "no_speech_prob": 7.646366611879785e-06}, {"id": 421, "seek": 195398, "start": 1953.98, "end": 1960.38, "text": " Actually tell I think have some of the tricks to allow us to train things at high learning rates", "tokens": [5135, 980, 286, 519, 362, 512, 295, 264, 11733, 281, 2089, 505, 281, 3847, 721, 412, 1090, 2539, 6846], "temperature": 0.0, "avg_logprob": -0.20427633368450662, "compression_ratio": 1.6096491228070176, "no_speech_prob": 3.6119506603427e-06}, {"id": 422, "seek": 195398, "start": 1960.38, "end": 1962.46, "text": " and so here's one of them and so", "tokens": [293, 370, 510, 311, 472, 295, 552, 293, 370], "temperature": 0.0, "avg_logprob": -0.20427633368450662, "compression_ratio": 1.6096491228070176, "no_speech_prob": 3.6119506603427e-06}, {"id": 423, "seek": 195398, "start": 1963.78, "end": 1970.28, "text": " Interestingly other than the train image net in one hour paper the only other place. I've seen this mentioned was in this", "tokens": [30564, 661, 813, 264, 3847, 3256, 2533, 294, 472, 1773, 3035, 264, 787, 661, 1081, 13, 286, 600, 1612, 341, 2835, 390, 294, 341], "temperature": 0.0, "avg_logprob": -0.20427633368450662, "compression_ratio": 1.6096491228070176, "no_speech_prob": 3.6119506603427e-06}, {"id": 424, "seek": 195398, "start": 1971.34, "end": 1974.46, "text": " EDSR paper, and it's really cool because like", "tokens": [462, 11844, 49, 3035, 11, 293, 309, 311, 534, 1627, 570, 411], "temperature": 0.0, "avg_logprob": -0.20427633368450662, "compression_ratio": 1.6096491228070176, "no_speech_prob": 3.6119506603427e-06}, {"id": 425, "seek": 195398, "start": 1975.46, "end": 1980.06, "text": " I don't know people who win competitions. I just find them to be very", "tokens": [286, 500, 380, 458, 561, 567, 1942, 26185, 13, 286, 445, 915, 552, 281, 312, 588], "temperature": 0.0, "avg_logprob": -0.20427633368450662, "compression_ratio": 1.6096491228070176, "no_speech_prob": 3.6119506603427e-06}, {"id": 426, "seek": 198006, "start": 1980.06, "end": 1985.7, "text": " Fragmatic and well read you know like they actually have to get things to work and so", "tokens": [479, 3731, 25915, 293, 731, 1401, 291, 458, 411, 436, 767, 362, 281, 483, 721, 281, 589, 293, 370], "temperature": 0.0, "avg_logprob": -0.18940861328788425, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.8162119204134797e-06}, {"id": 427, "seek": 198006, "start": 1986.58, "end": 1990.86, "text": " This paper describes an approach which actually worked better than anybody else's approach", "tokens": [639, 3035, 15626, 364, 3109, 597, 767, 2732, 1101, 813, 4472, 1646, 311, 3109], "temperature": 0.0, "avg_logprob": -0.18940861328788425, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.8162119204134797e-06}, {"id": 428, "seek": 198006, "start": 1990.86, "end": 1994.1799999999998, "text": " and they did these pragmatic things like throw away batch norm and", "tokens": [293, 436, 630, 613, 46904, 721, 411, 3507, 1314, 15245, 2026, 293], "temperature": 0.0, "avg_logprob": -0.18940861328788425, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.8162119204134797e-06}, {"id": 429, "seek": 198006, "start": 1995.82, "end": 1999.34, "text": " Use this little scaling factor which almost nobody else seems to know about", "tokens": [8278, 341, 707, 21589, 5952, 597, 1920, 5079, 1646, 2544, 281, 458, 466], "temperature": 0.0, "avg_logprob": -0.18940861328788425, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.8162119204134797e-06}, {"id": 430, "seek": 198006, "start": 2000.1799999999998, "end": 2002.1799999999998, "text": " And stuff like that", "tokens": [400, 1507, 411, 300], "temperature": 0.0, "avg_logprob": -0.18940861328788425, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.8162119204134797e-06}, {"id": 431, "seek": 198006, "start": 2002.3, "end": 2004.3, "text": " Okay, so that's where the point one comes from", "tokens": [1033, 11, 370, 300, 311, 689, 264, 935, 472, 1487, 490], "temperature": 0.0, "avg_logprob": -0.18940861328788425, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.8162119204134797e-06}, {"id": 432, "seek": 198006, "start": 2005.94, "end": 2007.94, "text": " So basically our", "tokens": [407, 1936, 527], "temperature": 0.0, "avg_logprob": -0.18940861328788425, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.8162119204134797e-06}, {"id": 433, "seek": 200794, "start": 2007.94, "end": 2014.44, "text": " Super resolution resnet is done and do a convolution to go from our three channels to 64 channels", "tokens": [4548, 8669, 725, 7129, 307, 1096, 293, 360, 257, 45216, 281, 352, 490, 527, 1045, 9235, 281, 12145, 9235], "temperature": 0.0, "avg_logprob": -0.24007781346638998, "compression_ratio": 1.6778242677824269, "no_speech_prob": 8.530247214366682e-06}, {"id": 434, "seek": 200794, "start": 2014.44, "end": 2019.8600000000001, "text": " Just to richen up the space a little bit then also I've got actually eight not five eight", "tokens": [1449, 281, 4593, 268, 493, 264, 1901, 257, 707, 857, 550, 611, 286, 600, 658, 767, 3180, 406, 1732, 3180], "temperature": 0.0, "avg_logprob": -0.24007781346638998, "compression_ratio": 1.6778242677824269, "no_speech_prob": 8.530247214366682e-06}, {"id": 435, "seek": 200794, "start": 2020.18, "end": 2024.94, "text": " Lots of these res blocks and we're just going to keep you remember every one of these res blocks is", "tokens": [15908, 295, 613, 725, 8474, 293, 321, 434, 445, 516, 281, 1066, 291, 1604, 633, 472, 295, 613, 725, 8474, 307], "temperature": 0.0, "avg_logprob": -0.24007781346638998, "compression_ratio": 1.6778242677824269, "no_speech_prob": 8.530247214366682e-06}, {"id": 436, "seek": 200794, "start": 2026.06, "end": 2031.74, "text": " Strive one so the grid size doesn't change the number of filters doesn't change. It's just 64 all the way through", "tokens": [745, 8003, 472, 370, 264, 10748, 2744, 1177, 380, 1319, 264, 1230, 295, 15995, 1177, 380, 1319, 13, 467, 311, 445, 12145, 439, 264, 636, 807], "temperature": 0.0, "avg_logprob": -0.24007781346638998, "compression_ratio": 1.6778242677824269, "no_speech_prob": 8.530247214366682e-06}, {"id": 437, "seek": 203174, "start": 2031.74, "end": 2039.6200000000001, "text": " We'll do one more convolution, and then we'll do our up sampling by however much scale we asked for", "tokens": [492, 603, 360, 472, 544, 45216, 11, 293, 550, 321, 603, 360, 527, 493, 21179, 538, 4461, 709, 4373, 321, 2351, 337], "temperature": 0.0, "avg_logprob": -0.20710331880593602, "compression_ratio": 1.5603864734299517, "no_speech_prob": 4.637847723643063e-06}, {"id": 438, "seek": 203174, "start": 2040.22, "end": 2042.9, "text": " and then something I've added which is a", "tokens": [293, 550, 746, 286, 600, 3869, 597, 307, 257], "temperature": 0.0, "avg_logprob": -0.20710331880593602, "compression_ratio": 1.5603864734299517, "no_speech_prob": 4.637847723643063e-06}, {"id": 439, "seek": 203174, "start": 2043.6200000000001, "end": 2050.26, "text": " Little idea is just one batch norm here because it kind of felt like it might be helpful just to scale the last layer", "tokens": [8022, 1558, 307, 445, 472, 15245, 2026, 510, 570, 309, 733, 295, 2762, 411, 309, 1062, 312, 4961, 445, 281, 4373, 264, 1036, 4583], "temperature": 0.0, "avg_logprob": -0.20710331880593602, "compression_ratio": 1.5603864734299517, "no_speech_prob": 4.637847723643063e-06}, {"id": 440, "seek": 203174, "start": 2051.02, "end": 2054.3, "text": " And then finally a comm to go back to the three channels we want", "tokens": [400, 550, 2721, 257, 800, 281, 352, 646, 281, 264, 1045, 9235, 321, 528], "temperature": 0.0, "avg_logprob": -0.20710331880593602, "compression_ratio": 1.5603864734299517, "no_speech_prob": 4.637847723643063e-06}, {"id": 441, "seek": 205430, "start": 2054.3, "end": 2061.86, "text": " So you can see that's basically his lots and lots of computation and then a little bit of up sampling", "tokens": [407, 291, 393, 536, 300, 311, 1936, 702, 3195, 293, 3195, 295, 24903, 293, 550, 257, 707, 857, 295, 493, 21179], "temperature": 0.0, "avg_logprob": -0.20898286274501254, "compression_ratio": 1.55, "no_speech_prob": 3.7853026242373744e-06}, {"id": 442, "seek": 205430, "start": 2063.34, "end": 2065.34, "text": " Just like we kind of described", "tokens": [1449, 411, 321, 733, 295, 7619], "temperature": 0.0, "avg_logprob": -0.20898286274501254, "compression_ratio": 1.55, "no_speech_prob": 3.7853026242373744e-06}, {"id": 443, "seek": 205430, "start": 2071.78, "end": 2074.0600000000004, "text": " So the only other piece here then is", "tokens": [407, 264, 787, 661, 2522, 510, 550, 307], "temperature": 0.0, "avg_logprob": -0.20898286274501254, "compression_ratio": 1.55, "no_speech_prob": 3.7853026242373744e-06}, {"id": 444, "seek": 205430, "start": 2075.3, "end": 2081.38, "text": " And also just dimension you know as you can see as I'm tending to do now this whole thing is done by creating", "tokens": [400, 611, 445, 10139, 291, 458, 382, 291, 393, 536, 382, 286, 478, 256, 2029, 281, 360, 586, 341, 1379, 551, 307, 1096, 538, 4084], "temperature": 0.0, "avg_logprob": -0.20898286274501254, "compression_ratio": 1.55, "no_speech_prob": 3.7853026242373744e-06}, {"id": 445, "seek": 208138, "start": 2081.38, "end": 2087.1800000000003, "text": " Just a list of layers and then at the end turning that into a sequential model", "tokens": [1449, 257, 1329, 295, 7914, 293, 550, 412, 264, 917, 6246, 300, 666, 257, 42881, 2316], "temperature": 0.0, "avg_logprob": -0.16233512536803288, "compression_ratio": 1.6184971098265897, "no_speech_prob": 4.157336206844775e-06}, {"id": 446, "seek": 208138, "start": 2087.1800000000003, "end": 2090.32, "text": " And so my forward function is the simplest can be", "tokens": [400, 370, 452, 2128, 2445, 307, 264, 22811, 393, 312], "temperature": 0.0, "avg_logprob": -0.16233512536803288, "compression_ratio": 1.6184971098265897, "no_speech_prob": 4.157336206844775e-06}, {"id": 447, "seek": 208138, "start": 2092.6600000000003, "end": 2100.2200000000003, "text": " So here's our up sampling and up sampling is a bit interesting because it is not", "tokens": [407, 510, 311, 527, 493, 21179, 293, 493, 21179, 307, 257, 857, 1880, 570, 309, 307, 406], "temperature": 0.0, "avg_logprob": -0.16233512536803288, "compression_ratio": 1.6184971098265897, "no_speech_prob": 4.157336206844775e-06}, {"id": 448, "seek": 210022, "start": 2100.22, "end": 2109.54, "text": " Doing either of these two things so let's talk a bit about up sampling", "tokens": [18496, 2139, 295, 613, 732, 721, 370, 718, 311, 751, 257, 857, 466, 493, 21179], "temperature": 0.0, "avg_logprob": -0.20557914461408341, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.1911046158274985e-06}, {"id": 449, "seek": 210022, "start": 2113.3799999999997, "end": 2118.98, "text": " Here's a picture from the paper from not from the competition winning paper from this original paper and", "tokens": [1692, 311, 257, 3036, 490, 264, 3035, 490, 406, 490, 264, 6211, 8224, 3035, 490, 341, 3380, 3035, 293], "temperature": 0.0, "avg_logprob": -0.20557914461408341, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.1911046158274985e-06}, {"id": 450, "seek": 210022, "start": 2120.22, "end": 2125.3199999999997, "text": " So they're saying hey our approach is so much better, but look at their approach. It's got", "tokens": [407, 436, 434, 1566, 4177, 527, 3109, 307, 370, 709, 1101, 11, 457, 574, 412, 641, 3109, 13, 467, 311, 658], "temperature": 0.0, "avg_logprob": -0.20557914461408341, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.1911046158274985e-06}, {"id": 451, "seek": 210022, "start": 2126.7799999999997, "end": 2128.7799999999997, "text": " Goddamn artifacts in it", "tokens": [1265, 25324, 24617, 294, 309], "temperature": 0.0, "avg_logprob": -0.20557914461408341, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.1911046158274985e-06}, {"id": 452, "seek": 212878, "start": 2128.78, "end": 2131.1800000000003, "text": " All right, these just pop up everywhere", "tokens": [1057, 558, 11, 613, 445, 1665, 493, 5315], "temperature": 0.0, "avg_logprob": -0.19787328583853586, "compression_ratio": 1.824, "no_speech_prob": 5.862759735464351e-06}, {"id": 453, "seek": 212878, "start": 2131.1800000000003, "end": 2138.02, "text": " And so one of the reasons for this is that they use transposed convolutions, and we all know don't use transposed convolutions", "tokens": [400, 370, 472, 295, 264, 4112, 337, 341, 307, 300, 436, 764, 7132, 1744, 3754, 15892, 11, 293, 321, 439, 458, 500, 380, 764, 7132, 1744, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.19787328583853586, "compression_ratio": 1.824, "no_speech_prob": 5.862759735464351e-06}, {"id": 454, "seek": 212878, "start": 2140.38, "end": 2142.46, "text": " So here are transposed convolutions", "tokens": [407, 510, 366, 7132, 1744, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.19787328583853586, "compression_ratio": 1.824, "no_speech_prob": 5.862759735464351e-06}, {"id": 455, "seek": 212878, "start": 2142.46, "end": 2146.1800000000003, "text": " This is from this fantastic convolutional arithmetic paper that was", "tokens": [639, 307, 490, 341, 5456, 45216, 304, 42973, 3035, 300, 390], "temperature": 0.0, "avg_logprob": -0.19787328583853586, "compression_ratio": 1.824, "no_speech_prob": 5.862759735464351e-06}, {"id": 456, "seek": 212878, "start": 2146.7000000000003, "end": 2152.8, "text": " Shown also in the theano docs if we're going from the blue is the original image so three by three image", "tokens": [1160, 648, 611, 294, 264, 264, 3730, 45623, 498, 321, 434, 516, 490, 264, 3344, 307, 264, 3380, 3256, 370, 1045, 538, 1045, 3256], "temperature": 0.0, "avg_logprob": -0.19787328583853586, "compression_ratio": 1.824, "no_speech_prob": 5.862759735464351e-06}, {"id": 457, "seek": 212878, "start": 2152.98, "end": 2157.7000000000003, "text": " Up to a five by five image right or be six by six if we added a layer of padding", "tokens": [5858, 281, 257, 1732, 538, 1732, 3256, 558, 420, 312, 2309, 538, 2309, 498, 321, 3869, 257, 4583, 295, 39562], "temperature": 0.0, "avg_logprob": -0.19787328583853586, "compression_ratio": 1.824, "no_speech_prob": 5.862759735464351e-06}, {"id": 458, "seek": 215770, "start": 2157.7, "end": 2164.2799999999997, "text": " Then all a transposed convolution does is it uses a regular three by three conv, but it sticks", "tokens": [1396, 439, 257, 7132, 1744, 45216, 775, 307, 309, 4960, 257, 3890, 1045, 538, 1045, 3754, 11, 457, 309, 12518], "temperature": 0.0, "avg_logprob": -0.2425907709265268, "compression_ratio": 1.624, "no_speech_prob": 1.8448154150974005e-06}, {"id": 459, "seek": 215770, "start": 2164.8199999999997, "end": 2171.8199999999997, "text": " White you know zero pixels between every pair of pixels right so that makes the input image bigger", "tokens": [5552, 291, 458, 4018, 18668, 1296, 633, 6119, 295, 18668, 558, 370, 300, 1669, 264, 4846, 3256, 3801], "temperature": 0.0, "avg_logprob": -0.2425907709265268, "compression_ratio": 1.624, "no_speech_prob": 1.8448154150974005e-06}, {"id": 460, "seek": 215770, "start": 2171.8199999999997, "end": 2175.98, "text": " And when we run this convolution up over it it therefore gives us a larger output", "tokens": [400, 562, 321, 1190, 341, 45216, 493, 670, 309, 309, 4412, 2709, 505, 257, 4833, 5598], "temperature": 0.0, "avg_logprob": -0.2425907709265268, "compression_ratio": 1.624, "no_speech_prob": 1.8448154150974005e-06}, {"id": 461, "seek": 215770, "start": 2176.3799999999997, "end": 2181.1, "text": " Right, but I mean that's obviously stupid because when we get here for example", "tokens": [1779, 11, 457, 286, 914, 300, 311, 2745, 6631, 570, 562, 321, 483, 510, 337, 1365], "temperature": 0.0, "avg_logprob": -0.2425907709265268, "compression_ratio": 1.624, "no_speech_prob": 1.8448154150974005e-06}, {"id": 462, "seek": 215770, "start": 2181.74, "end": 2184.58, "text": " Of the nine pixels coming in eight of them are zero", "tokens": [2720, 264, 4949, 18668, 1348, 294, 3180, 295, 552, 366, 4018], "temperature": 0.0, "avg_logprob": -0.2425907709265268, "compression_ratio": 1.624, "no_speech_prob": 1.8448154150974005e-06}, {"id": 463, "seek": 218458, "start": 2184.58, "end": 2188.54, "text": " So like we're just wasting a whole lot of computation", "tokens": [407, 411, 321, 434, 445, 20457, 257, 1379, 688, 295, 24903], "temperature": 0.0, "avg_logprob": -0.1442975596377724, "compression_ratio": 1.6042553191489362, "no_speech_prob": 1.9033799389944761e-06}, {"id": 464, "seek": 218458, "start": 2188.54, "end": 2194.5, "text": " And then on the other hand if we're slightly off over here then four of our nine and on zero", "tokens": [400, 550, 322, 264, 661, 1011, 498, 321, 434, 4748, 766, 670, 510, 550, 1451, 295, 527, 4949, 293, 322, 4018], "temperature": 0.0, "avg_logprob": -0.1442975596377724, "compression_ratio": 1.6042553191489362, "no_speech_prob": 1.9033799389944761e-06}, {"id": 465, "seek": 218458, "start": 2194.62, "end": 2196.62, "text": " But yet we only have one", "tokens": [583, 1939, 321, 787, 362, 472], "temperature": 0.0, "avg_logprob": -0.1442975596377724, "compression_ratio": 1.6042553191489362, "no_speech_prob": 1.9033799389944761e-06}, {"id": 466, "seek": 218458, "start": 2198.62, "end": 2204.98, "text": " Filter like one kernel to use so it can't like change depending on how many zeros are coming in so it has to kind of", "tokens": [39592, 411, 472, 28256, 281, 764, 370, 309, 393, 380, 411, 1319, 5413, 322, 577, 867, 35193, 366, 1348, 294, 370, 309, 575, 281, 733, 295], "temperature": 0.0, "avg_logprob": -0.1442975596377724, "compression_ratio": 1.6042553191489362, "no_speech_prob": 1.9033799389944761e-06}, {"id": 467, "seek": 218458, "start": 2206.2599999999998, "end": 2212.42, "text": " Be suitable for both, and it's just not possible right so we end up with these artifacts", "tokens": [879, 12873, 337, 1293, 11, 293, 309, 311, 445, 406, 1944, 558, 370, 321, 917, 493, 365, 613, 24617], "temperature": 0.0, "avg_logprob": -0.1442975596377724, "compression_ratio": 1.6042553191489362, "no_speech_prob": 1.9033799389944761e-06}, {"id": 468, "seek": 221242, "start": 2212.42, "end": 2213.9, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.18065494572350738, "compression_ratio": 1.6528301886792454, "no_speech_prob": 7.338200589401822e-07}, {"id": 469, "seek": 221242, "start": 2213.9, "end": 2218.94, "text": " One approach we've learned to make it a bit better is to not put white things here", "tokens": [1485, 3109, 321, 600, 3264, 281, 652, 309, 257, 857, 1101, 307, 281, 406, 829, 2418, 721, 510], "temperature": 0.0, "avg_logprob": -0.18065494572350738, "compression_ratio": 1.6528301886792454, "no_speech_prob": 7.338200589401822e-07}, {"id": 470, "seek": 221242, "start": 2218.94, "end": 2223.7400000000002, "text": " But instead to copy this pixels value to each of these three locations", "tokens": [583, 2602, 281, 5055, 341, 18668, 2158, 281, 1184, 295, 613, 1045, 9253], "temperature": 0.0, "avg_logprob": -0.18065494572350738, "compression_ratio": 1.6528301886792454, "no_speech_prob": 7.338200589401822e-07}, {"id": 471, "seek": 221242, "start": 2223.94, "end": 2227.94, "text": " All right, so that's a just a nearest neighbor up sampling. That's certainly a bit better", "tokens": [1057, 558, 11, 370, 300, 311, 257, 445, 257, 23831, 5987, 493, 21179, 13, 663, 311, 3297, 257, 857, 1101], "temperature": 0.0, "avg_logprob": -0.18065494572350738, "compression_ratio": 1.6528301886792454, "no_speech_prob": 7.338200589401822e-07}, {"id": 472, "seek": 221242, "start": 2228.46, "end": 2232.7000000000003, "text": " All right, but it's still pretty crappy because now still when we get to these nine here", "tokens": [1057, 558, 11, 457, 309, 311, 920, 1238, 36531, 570, 586, 920, 562, 321, 483, 281, 613, 4949, 510], "temperature": 0.0, "avg_logprob": -0.18065494572350738, "compression_ratio": 1.6528301886792454, "no_speech_prob": 7.338200589401822e-07}, {"id": 473, "seek": 221242, "start": 2233.46, "end": 2235.46, "text": " Four of them are exactly the same number", "tokens": [7451, 295, 552, 366, 2293, 264, 912, 1230], "temperature": 0.0, "avg_logprob": -0.18065494572350738, "compression_ratio": 1.6528301886792454, "no_speech_prob": 7.338200589401822e-07}, {"id": 474, "seek": 221242, "start": 2236.02, "end": 2240.5, "text": " Right and when we move across one then now we've got you know", "tokens": [1779, 293, 562, 321, 1286, 2108, 472, 550, 586, 321, 600, 658, 291, 458], "temperature": 0.0, "avg_logprob": -0.18065494572350738, "compression_ratio": 1.6528301886792454, "no_speech_prob": 7.338200589401822e-07}, {"id": 475, "seek": 224050, "start": 2240.5, "end": 2242.5, "text": " a", "tokens": [257], "temperature": 0.0, "avg_logprob": -0.16813082308382601, "compression_ratio": 1.6702898550724639, "no_speech_prob": 2.7693974971043644e-06}, {"id": 476, "seek": 224050, "start": 2242.66, "end": 2246.06, "text": " Different situation entirely right and so depending on", "tokens": [20825, 2590, 7696, 558, 293, 370, 5413, 322], "temperature": 0.0, "avg_logprob": -0.16813082308382601, "compression_ratio": 1.6702898550724639, "no_speech_prob": 2.7693974971043644e-06}, {"id": 477, "seek": 224050, "start": 2246.7, "end": 2251.02, "text": " Where we are so in particular if we're here. You know there's going to be a lot less repetition", "tokens": [2305, 321, 366, 370, 294, 1729, 498, 321, 434, 510, 13, 509, 458, 456, 311, 516, 281, 312, 257, 688, 1570, 30432], "temperature": 0.0, "avg_logprob": -0.16813082308382601, "compression_ratio": 1.6702898550724639, "no_speech_prob": 2.7693974971043644e-06}, {"id": 478, "seek": 224050, "start": 2251.06, "end": 2253.3, "text": " so again, we have this problem where there's like", "tokens": [370, 797, 11, 321, 362, 341, 1154, 689, 456, 311, 411], "temperature": 0.0, "avg_logprob": -0.16813082308382601, "compression_ratio": 1.6702898550724639, "no_speech_prob": 2.7693974971043644e-06}, {"id": 479, "seek": 224050, "start": 2254.18, "end": 2259.1, "text": " Wasted computation and too much structure in the data, and it's going to lead to artifacts again", "tokens": [343, 34440, 24903, 293, 886, 709, 3877, 294, 264, 1412, 11, 293, 309, 311, 516, 281, 1477, 281, 24617, 797], "temperature": 0.0, "avg_logprob": -0.16813082308382601, "compression_ratio": 1.6702898550724639, "no_speech_prob": 2.7693974971043644e-06}, {"id": 480, "seek": 224050, "start": 2259.1, "end": 2262.96, "text": " So up sampling is better than transposed convolutions", "tokens": [407, 493, 21179, 307, 1101, 813, 7132, 1744, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.16813082308382601, "compression_ratio": 1.6702898550724639, "no_speech_prob": 2.7693974971043644e-06}, {"id": 481, "seek": 224050, "start": 2262.96, "end": 2268.42, "text": " It's you know better to copy them rather than replace them with zeros, but it's still not quite good enough", "tokens": [467, 311, 291, 458, 1101, 281, 5055, 552, 2831, 813, 7406, 552, 365, 35193, 11, 457, 309, 311, 920, 406, 1596, 665, 1547], "temperature": 0.0, "avg_logprob": -0.16813082308382601, "compression_ratio": 1.6702898550724639, "no_speech_prob": 2.7693974971043644e-06}, {"id": 482, "seek": 226842, "start": 2268.42, "end": 2270.42, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.24766549067710764, "compression_ratio": 1.52, "no_speech_prob": 9.72151156020118e-07}, {"id": 483, "seek": 226842, "start": 2270.46, "end": 2272.46, "text": " instead", "tokens": [2602], "temperature": 0.0, "avg_logprob": -0.24766549067710764, "compression_ratio": 1.52, "no_speech_prob": 9.72151156020118e-07}, {"id": 484, "seek": 226842, "start": 2277.02, "end": 2279.38, "text": " We're going to do the pixel shuffle", "tokens": [492, 434, 516, 281, 360, 264, 19261, 39426], "temperature": 0.0, "avg_logprob": -0.24766549067710764, "compression_ratio": 1.52, "no_speech_prob": 9.72151156020118e-07}, {"id": 485, "seek": 226842, "start": 2280.1800000000003, "end": 2283.82, "text": " So the pixel shuffle is an operation in this", "tokens": [407, 264, 19261, 39426, 307, 364, 6916, 294, 341], "temperature": 0.0, "avg_logprob": -0.24766549067710764, "compression_ratio": 1.52, "no_speech_prob": 9.72151156020118e-07}, {"id": 486, "seek": 226842, "start": 2284.78, "end": 2287.58, "text": " subpixel convolutional neural network, and it's a", "tokens": [1422, 79, 34599, 45216, 304, 18161, 3209, 11, 293, 309, 311, 257], "temperature": 0.0, "avg_logprob": -0.24766549067710764, "compression_ratio": 1.52, "no_speech_prob": 9.72151156020118e-07}, {"id": 487, "seek": 226842, "start": 2288.46, "end": 2290.46, "text": " little bit mind-bending", "tokens": [707, 857, 1575, 12, 65, 2029], "temperature": 0.0, "avg_logprob": -0.24766549067710764, "compression_ratio": 1.52, "no_speech_prob": 9.72151156020118e-07}, {"id": 488, "seek": 226842, "start": 2290.46, "end": 2294.7000000000003, "text": " But it's kind of fascinating and so we we start with our input", "tokens": [583, 309, 311, 733, 295, 10343, 293, 370, 321, 321, 722, 365, 527, 4846], "temperature": 0.0, "avg_logprob": -0.24766549067710764, "compression_ratio": 1.52, "no_speech_prob": 9.72151156020118e-07}, {"id": 489, "seek": 229470, "start": 2294.7, "end": 2300.62, "text": " We go through some convolutions to create some feature maps for a while until eventually we get to layer", "tokens": [492, 352, 807, 512, 3754, 15892, 281, 1884, 512, 4111, 11317, 337, 257, 1339, 1826, 4728, 321, 483, 281, 4583], "temperature": 0.0, "avg_logprob": -0.19836020469665527, "compression_ratio": 1.8733624454148472, "no_speech_prob": 5.255337327980669e-06}, {"id": 490, "seek": 229470, "start": 2301.1, "end": 2306.58, "text": " And I we get to this layer I minus one which has n I minus one feature maps", "tokens": [400, 286, 321, 483, 281, 341, 4583, 286, 3175, 472, 597, 575, 297, 286, 3175, 472, 4111, 11317], "temperature": 0.0, "avg_logprob": -0.19836020469665527, "compression_ratio": 1.8733624454148472, "no_speech_prob": 5.255337327980669e-06}, {"id": 491, "seek": 229470, "start": 2307.3399999999997, "end": 2313.7799999999997, "text": " We're going to do another three by three conv and our goal here is to go from a seven by seven grid cell", "tokens": [492, 434, 516, 281, 360, 1071, 1045, 538, 1045, 3754, 293, 527, 3387, 510, 307, 281, 352, 490, 257, 3407, 538, 3407, 10748, 2815], "temperature": 0.0, "avg_logprob": -0.19836020469665527, "compression_ratio": 1.8733624454148472, "no_speech_prob": 5.255337327980669e-06}, {"id": 492, "seek": 229470, "start": 2314.46, "end": 2319.3799999999997, "text": " We're going to go a three by three up scaling so we're going to go up to a 21 by 21", "tokens": [492, 434, 516, 281, 352, 257, 1045, 538, 1045, 493, 21589, 370, 321, 434, 516, 281, 352, 493, 281, 257, 5080, 538, 5080], "temperature": 0.0, "avg_logprob": -0.19836020469665527, "compression_ratio": 1.8733624454148472, "no_speech_prob": 5.255337327980669e-06}, {"id": 493, "seek": 229470, "start": 2320.14, "end": 2323.54, "text": " Grid cell so how do we what's another way we could do that?", "tokens": [42905, 2815, 370, 577, 360, 321, 437, 311, 1071, 636, 321, 727, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.19836020469665527, "compression_ratio": 1.8733624454148472, "no_speech_prob": 5.255337327980669e-06}, {"id": 494, "seek": 232354, "start": 2323.54, "end": 2325.14, "text": " to", "tokens": [281], "temperature": 0.0, "avg_logprob": -0.25786423984962176, "compression_ratio": 1.7126436781609196, "no_speech_prob": 3.3405265185137978e-06}, {"id": 495, "seek": 232354, "start": 2325.14, "end": 2328.2599999999998, "text": " Make it simpler. Let's just pick one", "tokens": [4387, 309, 18587, 13, 961, 311, 445, 1888, 472], "temperature": 0.0, "avg_logprob": -0.25786423984962176, "compression_ratio": 1.7126436781609196, "no_speech_prob": 3.3405265185137978e-06}, {"id": 496, "seek": 232354, "start": 2328.9, "end": 2335.22, "text": " Face just one filter so we just take the topmost filter and just do a convolution over that just to see what happens", "tokens": [4047, 445, 472, 6608, 370, 321, 445, 747, 264, 1192, 1761, 6608, 293, 445, 360, 257, 45216, 670, 300, 445, 281, 536, 437, 2314], "temperature": 0.0, "avg_logprob": -0.25786423984962176, "compression_ratio": 1.7126436781609196, "no_speech_prob": 3.3405265185137978e-06}, {"id": 497, "seek": 232354, "start": 2335.22, "end": 2337.94, "text": " and what we're going to do is we're going to use a", "tokens": [293, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 764, 257], "temperature": 0.0, "avg_logprob": -0.25786423984962176, "compression_ratio": 1.7126436781609196, "no_speech_prob": 3.3405265185137978e-06}, {"id": 498, "seek": 232354, "start": 2339.3, "end": 2343.9, "text": " convolution where the kernel size is is the number of filters is", "tokens": [45216, 689, 264, 28256, 2744, 307, 307, 264, 1230, 295, 15995, 307], "temperature": 0.0, "avg_logprob": -0.25786423984962176, "compression_ratio": 1.7126436781609196, "no_speech_prob": 3.3405265185137978e-06}, {"id": 499, "seek": 232354, "start": 2346.66, "end": 2349.18, "text": " Nine times bigger than we", "tokens": [18939, 1413, 3801, 813, 321], "temperature": 0.0, "avg_logprob": -0.25786423984962176, "compression_ratio": 1.7126436781609196, "no_speech_prob": 3.3405265185137978e-06}, {"id": 500, "seek": 234918, "start": 2349.18, "end": 2352.8199999999997, "text": " strictly speaking need so if we needed", "tokens": [20792, 4124, 643, 370, 498, 321, 2978], "temperature": 0.0, "avg_logprob": -0.2830260508769267, "compression_ratio": 1.650887573964497, "no_speech_prob": 2.6425734631629894e-06}, {"id": 501, "seek": 234918, "start": 2353.7799999999997, "end": 2359.22, "text": " 64 filters we're actually going to do 64 times 9 filters", "tokens": [12145, 15995, 321, 434, 767, 516, 281, 360, 12145, 1413, 1722, 15995], "temperature": 0.0, "avg_logprob": -0.2830260508769267, "compression_ratio": 1.650887573964497, "no_speech_prob": 2.6425734631629894e-06}, {"id": 502, "seek": 234918, "start": 2360.18, "end": 2367.16, "text": " Why is that right and so are here are is the scale factor so 3 right so r squared 3 squared is 9", "tokens": [1545, 307, 300, 558, 293, 370, 366, 510, 366, 307, 264, 4373, 5952, 370, 805, 558, 370, 367, 8889, 805, 8889, 307, 1722], "temperature": 0.0, "avg_logprob": -0.2830260508769267, "compression_ratio": 1.650887573964497, "no_speech_prob": 2.6425734631629894e-06}, {"id": 503, "seek": 234918, "start": 2367.54, "end": 2369.54, "text": " So here are the 9", "tokens": [407, 510, 366, 264, 1722], "temperature": 0.0, "avg_logprob": -0.2830260508769267, "compression_ratio": 1.650887573964497, "no_speech_prob": 2.6425734631629894e-06}, {"id": 504, "seek": 234918, "start": 2370.2999999999997, "end": 2372.2999999999997, "text": " filters to cover one", "tokens": [15995, 281, 2060, 472], "temperature": 0.0, "avg_logprob": -0.2830260508769267, "compression_ratio": 1.650887573964497, "no_speech_prob": 2.6425734631629894e-06}, {"id": 505, "seek": 234918, "start": 2372.8999999999996, "end": 2376.14, "text": " Of these input layers one of these input slices", "tokens": [2720, 613, 4846, 7914, 472, 295, 613, 4846, 19793], "temperature": 0.0, "avg_logprob": -0.2830260508769267, "compression_ratio": 1.650887573964497, "no_speech_prob": 2.6425734631629894e-06}, {"id": 506, "seek": 237614, "start": 2376.14, "end": 2380.6, "text": " And well what we can do is we started with", "tokens": [400, 731, 437, 321, 393, 360, 307, 321, 1409, 365], "temperature": 0.0, "avg_logprob": -0.2360017800036772, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.083576522541989e-07}, {"id": 507, "seek": 237614, "start": 2381.14, "end": 2385.3799999999997, "text": " Seven by seven and we turned it into seven by seven by nine", "tokens": [14868, 538, 3407, 293, 321, 3574, 309, 666, 3407, 538, 3407, 538, 4949], "temperature": 0.0, "avg_logprob": -0.2360017800036772, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.083576522541989e-07}, {"id": 508, "seek": 237614, "start": 2386.3399999999997, "end": 2388.8599999999997, "text": " right well the output that we want is", "tokens": [558, 731, 264, 5598, 300, 321, 528, 307], "temperature": 0.0, "avg_logprob": -0.2360017800036772, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.083576522541989e-07}, {"id": 509, "seek": 237614, "start": 2389.74, "end": 2391.74, "text": " equal to", "tokens": [2681, 281], "temperature": 0.0, "avg_logprob": -0.2360017800036772, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.083576522541989e-07}, {"id": 510, "seek": 237614, "start": 2392.14, "end": 2397.42, "text": " Seven times three by seven times three so in other words", "tokens": [14868, 1413, 1045, 538, 3407, 1413, 1045, 370, 294, 661, 2283], "temperature": 0.0, "avg_logprob": -0.2360017800036772, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.083576522541989e-07}, {"id": 511, "seek": 237614, "start": 2397.42, "end": 2404.7, "text": " There's an equal number of pixels here or activations here as there are activations here, so we can literally", "tokens": [821, 311, 364, 2681, 1230, 295, 18668, 510, 420, 2430, 763, 510, 382, 456, 366, 2430, 763, 510, 11, 370, 321, 393, 3736], "temperature": 0.0, "avg_logprob": -0.2360017800036772, "compression_ratio": 1.7752808988764044, "no_speech_prob": 6.083576522541989e-07}, {"id": 512, "seek": 240470, "start": 2404.7, "end": 2406.7, "text": " reshuffle", "tokens": [725, 71, 21665], "temperature": 0.0, "avg_logprob": -0.16892345584168725, "compression_ratio": 1.9891891891891893, "no_speech_prob": 2.0261375084373867e-06}, {"id": 513, "seek": 240470, "start": 2407.06, "end": 2411.98, "text": " These seven by seven by nine activations to create this", "tokens": [1981, 3407, 538, 3407, 538, 4949, 2430, 763, 281, 1884, 341], "temperature": 0.0, "avg_logprob": -0.16892345584168725, "compression_ratio": 1.9891891891891893, "no_speech_prob": 2.0261375084373867e-06}, {"id": 514, "seek": 240470, "start": 2412.66, "end": 2414.66, "text": " seven by three by seven by three", "tokens": [3407, 538, 1045, 538, 3407, 538, 1045], "temperature": 0.0, "avg_logprob": -0.16892345584168725, "compression_ratio": 1.9891891891891893, "no_speech_prob": 2.0261375084373867e-06}, {"id": 515, "seek": 240470, "start": 2416.18, "end": 2422.98, "text": " Map and so what we're going to do is we're going to take one little kind of tube here all the top left hand of each", "tokens": [22053, 293, 370, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 747, 472, 707, 733, 295, 9917, 510, 439, 264, 1192, 1411, 1011, 295, 1184], "temperature": 0.0, "avg_logprob": -0.16892345584168725, "compression_ratio": 1.9891891891891893, "no_speech_prob": 2.0261375084373867e-06}, {"id": 516, "seek": 240470, "start": 2423.98, "end": 2429.98, "text": " Grid and we're going to put the purple one up in the top left and then the blue one", "tokens": [42905, 293, 321, 434, 516, 281, 829, 264, 9656, 472, 493, 294, 264, 1192, 1411, 293, 550, 264, 3344, 472], "temperature": 0.0, "avg_logprob": -0.16892345584168725, "compression_ratio": 1.9891891891891893, "no_speech_prob": 2.0261375084373867e-06}, {"id": 517, "seek": 242998, "start": 2429.98, "end": 2434.5, "text": " one to the right and then the light blue one one to the right of that and", "tokens": [472, 281, 264, 558, 293, 550, 264, 1442, 3344, 472, 472, 281, 264, 558, 295, 300, 293], "temperature": 0.0, "avg_logprob": -0.14888506309658872, "compression_ratio": 1.9651741293532339, "no_speech_prob": 1.6536862403881969e-06}, {"id": 518, "seek": 242998, "start": 2435.06, "end": 2442.38, "text": " Then the slightly darker blue one and the middle of the far left the green one in the middle and so forth so each of these", "tokens": [1396, 264, 4748, 12741, 3344, 472, 293, 264, 2808, 295, 264, 1400, 1411, 264, 3092, 472, 294, 264, 2808, 293, 370, 5220, 370, 1184, 295, 613], "temperature": 0.0, "avg_logprob": -0.14888506309658872, "compression_ratio": 1.9651741293532339, "no_speech_prob": 1.6536862403881969e-06}, {"id": 519, "seek": 242998, "start": 2442.38, "end": 2444.14, "text": " nine", "tokens": [4949], "temperature": 0.0, "avg_logprob": -0.14888506309658872, "compression_ratio": 1.9651741293532339, "no_speech_prob": 1.6536862403881969e-06}, {"id": 520, "seek": 242998, "start": 2444.14, "end": 2448.06, "text": " Cells in the top left are going to end up in this little three by three", "tokens": [383, 13677, 294, 264, 1192, 1411, 366, 516, 281, 917, 493, 294, 341, 707, 1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.14888506309658872, "compression_ratio": 1.9651741293532339, "no_speech_prob": 1.6536862403881969e-06}, {"id": 521, "seek": 242998, "start": 2448.86, "end": 2450.86, "text": " section of our grid and", "tokens": [3541, 295, 527, 10748, 293], "temperature": 0.0, "avg_logprob": -0.14888506309658872, "compression_ratio": 1.9651741293532339, "no_speech_prob": 1.6536862403881969e-06}, {"id": 522, "seek": 242998, "start": 2451.26, "end": 2456.94, "text": " Then we're going to take you know two comma one and take all of those nine and move them to these", "tokens": [1396, 321, 434, 516, 281, 747, 291, 458, 732, 22117, 472, 293, 747, 439, 295, 729, 4949, 293, 1286, 552, 281, 613], "temperature": 0.0, "avg_logprob": -0.14888506309658872, "compression_ratio": 1.9651741293532339, "no_speech_prob": 1.6536862403881969e-06}, {"id": 523, "seek": 245694, "start": 2456.94, "end": 2460.06, "text": " three by three part of the grid and", "tokens": [1045, 538, 1045, 644, 295, 264, 10748, 293], "temperature": 0.0, "avg_logprob": -0.17363917406867532, "compression_ratio": 1.7171717171717171, "no_speech_prob": 1.0511470236451714e-06}, {"id": 524, "seek": 245694, "start": 2460.54, "end": 2465.62, "text": " So on and so forth right and so we're going to end up having every one of these seven by seven by nine", "tokens": [407, 322, 293, 370, 5220, 558, 293, 370, 321, 434, 516, 281, 917, 493, 1419, 633, 472, 295, 613, 3407, 538, 3407, 538, 4949], "temperature": 0.0, "avg_logprob": -0.17363917406867532, "compression_ratio": 1.7171717171717171, "no_speech_prob": 1.0511470236451714e-06}, {"id": 525, "seek": 245694, "start": 2466.62, "end": 2469.78, "text": " activations inside this seven by three by seven by three", "tokens": [2430, 763, 1854, 341, 3407, 538, 1045, 538, 3407, 538, 1045], "temperature": 0.0, "avg_logprob": -0.17363917406867532, "compression_ratio": 1.7171717171717171, "no_speech_prob": 1.0511470236451714e-06}, {"id": 526, "seek": 245694, "start": 2470.9, "end": 2472.9, "text": " image", "tokens": [3256], "temperature": 0.0, "avg_logprob": -0.17363917406867532, "compression_ratio": 1.7171717171717171, "no_speech_prob": 1.0511470236451714e-06}, {"id": 527, "seek": 245694, "start": 2472.94, "end": 2474.94, "text": " So the first thing to realize is", "tokens": [407, 264, 700, 551, 281, 4325, 307], "temperature": 0.0, "avg_logprob": -0.17363917406867532, "compression_ratio": 1.7171717171717171, "no_speech_prob": 1.0511470236451714e-06}, {"id": 528, "seek": 245694, "start": 2475.3, "end": 2482.14, "text": " Yes, of course this works under some definition of works because we have a learnable convolution here and", "tokens": [1079, 11, 295, 1164, 341, 1985, 833, 512, 7123, 295, 1985, 570, 321, 362, 257, 1466, 712, 45216, 510, 293], "temperature": 0.0, "avg_logprob": -0.17363917406867532, "compression_ratio": 1.7171717171717171, "no_speech_prob": 1.0511470236451714e-06}, {"id": 529, "seek": 248214, "start": 2482.14, "end": 2486.66, "text": " It's going to get some gradients, which is going to do the best job it can", "tokens": [467, 311, 516, 281, 483, 512, 2771, 2448, 11, 597, 307, 516, 281, 360, 264, 1151, 1691, 309, 393], "temperature": 0.0, "avg_logprob": -0.19005931672595797, "compression_ratio": 1.7065637065637065, "no_speech_prob": 6.3391676121682394e-06}, {"id": 530, "seek": 248214, "start": 2487.06, "end": 2491.7, "text": " But filling in the correct activation such that this output is the thing we want", "tokens": [583, 10623, 294, 264, 3006, 24433, 1270, 300, 341, 5598, 307, 264, 551, 321, 528], "temperature": 0.0, "avg_logprob": -0.19005931672595797, "compression_ratio": 1.7065637065637065, "no_speech_prob": 6.3391676121682394e-06}, {"id": 531, "seek": 248214, "start": 2492.8199999999997, "end": 2495.2599999999998, "text": " All right, so the first step is to realize", "tokens": [1057, 558, 11, 370, 264, 700, 1823, 307, 281, 4325], "temperature": 0.0, "avg_logprob": -0.19005931672595797, "compression_ratio": 1.7065637065637065, "no_speech_prob": 6.3391676121682394e-06}, {"id": 532, "seek": 248214, "start": 2495.9, "end": 2498.02, "text": " There's nothing particularly magical here", "tokens": [821, 311, 1825, 4098, 12066, 510], "temperature": 0.0, "avg_logprob": -0.19005931672595797, "compression_ratio": 1.7065637065637065, "no_speech_prob": 6.3391676121682394e-06}, {"id": 533, "seek": 248214, "start": 2498.02, "end": 2502.62, "text": " You know we can we can create any architecture we like we can move things around anyhow", "tokens": [509, 458, 321, 393, 321, 393, 1884, 604, 9482, 321, 411, 321, 393, 1286, 721, 926, 44995], "temperature": 0.0, "avg_logprob": -0.19005931672595797, "compression_ratio": 1.7065637065637065, "no_speech_prob": 6.3391676121682394e-06}, {"id": 534, "seek": 248214, "start": 2502.62, "end": 2509.96, "text": " We want to and you know our weights in the convolution will do their best to do all we asked the real question is", "tokens": [492, 528, 281, 293, 291, 458, 527, 17443, 294, 264, 45216, 486, 360, 641, 1151, 281, 360, 439, 321, 2351, 264, 957, 1168, 307], "temperature": 0.0, "avg_logprob": -0.19005931672595797, "compression_ratio": 1.7065637065637065, "no_speech_prob": 6.3391676121682394e-06}, {"id": 535, "seek": 250996, "start": 2509.96, "end": 2511.96, "text": " Is it a good idea?", "tokens": [1119, 309, 257, 665, 1558, 30], "temperature": 0.0, "avg_logprob": -0.21335430802970096, "compression_ratio": 1.7313432835820894, "no_speech_prob": 7.453756438735581e-07}, {"id": 536, "seek": 250996, "start": 2512.0, "end": 2514.84, "text": " You know is this an easier thing for it to do?", "tokens": [509, 458, 307, 341, 364, 3571, 551, 337, 309, 281, 360, 30], "temperature": 0.0, "avg_logprob": -0.21335430802970096, "compression_ratio": 1.7313432835820894, "no_speech_prob": 7.453756438735581e-07}, {"id": 537, "seek": 250996, "start": 2515.28, "end": 2522.44, "text": " You know and a more flexible thing for it to do than the transposed convolution or the up sampling followed by one by one", "tokens": [509, 458, 293, 257, 544, 11358, 551, 337, 309, 281, 360, 813, 264, 7132, 1744, 45216, 420, 264, 493, 21179, 6263, 538, 472, 538, 472], "temperature": 0.0, "avg_logprob": -0.21335430802970096, "compression_ratio": 1.7313432835820894, "no_speech_prob": 7.453756438735581e-07}, {"id": 538, "seek": 250996, "start": 2523.2, "end": 2528.44, "text": " And the short answer is yes it is right and the reason it's better", "tokens": [400, 264, 2099, 1867, 307, 2086, 309, 307, 558, 293, 264, 1778, 309, 311, 1101], "temperature": 0.0, "avg_logprob": -0.21335430802970096, "compression_ratio": 1.7313432835820894, "no_speech_prob": 7.453756438735581e-07}, {"id": 539, "seek": 250996, "start": 2529.2400000000002, "end": 2535.88, "text": " In short is that the convolution here is happening in the low resolution seven by seven space", "tokens": [682, 2099, 307, 300, 264, 45216, 510, 307, 2737, 294, 264, 2295, 8669, 3407, 538, 3407, 1901], "temperature": 0.0, "avg_logprob": -0.21335430802970096, "compression_ratio": 1.7313432835820894, "no_speech_prob": 7.453756438735581e-07}, {"id": 540, "seek": 253588, "start": 2535.88, "end": 2541.8, "text": " Which is quite efficient where else if we first of all up sampled and then did our cons", "tokens": [3013, 307, 1596, 7148, 689, 1646, 498, 321, 700, 295, 439, 493, 3247, 15551, 293, 550, 630, 527, 1014], "temperature": 0.0, "avg_logprob": -0.23869530551404838, "compression_ratio": 1.603864734299517, "no_speech_prob": 2.2959106900088955e-06}, {"id": 541, "seek": 253588, "start": 2542.56, "end": 2545.52, "text": " Then our conf would be happening in the 21 by 21", "tokens": [1396, 527, 1497, 576, 312, 2737, 294, 264, 5080, 538, 5080], "temperature": 0.0, "avg_logprob": -0.23869530551404838, "compression_ratio": 1.603864734299517, "no_speech_prob": 2.2959106900088955e-06}, {"id": 542, "seek": 253588, "start": 2546.2400000000002, "end": 2548.92, "text": " Space which is a lot of computation", "tokens": [8705, 597, 307, 257, 688, 295, 24903], "temperature": 0.0, "avg_logprob": -0.23869530551404838, "compression_ratio": 1.603864734299517, "no_speech_prob": 2.2959106900088955e-06}, {"id": 543, "seek": 253588, "start": 2549.7200000000003, "end": 2552.7200000000003, "text": " Right and furthermore as we discussed there's a lot of", "tokens": [1779, 293, 3052, 3138, 382, 321, 7152, 456, 311, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.23869530551404838, "compression_ratio": 1.603864734299517, "no_speech_prob": 2.2959106900088955e-06}, {"id": 544, "seek": 253588, "start": 2553.6400000000003, "end": 2557.1600000000003, "text": " Replication and redundancy in the nearest neighbor up sample version", "tokens": [1300, 4770, 399, 293, 27830, 6717, 294, 264, 23831, 5987, 493, 6889, 3037], "temperature": 0.0, "avg_logprob": -0.23869530551404838, "compression_ratio": 1.603864734299517, "no_speech_prob": 2.2959106900088955e-06}, {"id": 545, "seek": 253588, "start": 2560.4, "end": 2562.28, "text": " So they actually show in this paper", "tokens": [407, 436, 767, 855, 294, 341, 3035], "temperature": 0.0, "avg_logprob": -0.23869530551404838, "compression_ratio": 1.603864734299517, "no_speech_prob": 2.2959106900088955e-06}, {"id": 546, "seek": 256228, "start": 2562.28, "end": 2567.02, "text": " They actually is that I think they have a follow-up technical note where they kind of provide some more", "tokens": [814, 767, 307, 300, 286, 519, 436, 362, 257, 1524, 12, 1010, 6191, 3637, 689, 436, 733, 295, 2893, 512, 544], "temperature": 0.0, "avg_logprob": -0.1932678956251878, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.2289152664379799e-06}, {"id": 547, "seek": 256228, "start": 2567.28, "end": 2574.6800000000003, "text": " Mathematical details as to exactly what work is being done and show that the work really is more efficient this way, okay?", "tokens": [15776, 8615, 804, 4365, 382, 281, 2293, 437, 589, 307, 885, 1096, 293, 855, 300, 264, 589, 534, 307, 544, 7148, 341, 636, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.1932678956251878, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.2289152664379799e-06}, {"id": 548, "seek": 256228, "start": 2578.0400000000004, "end": 2583.44, "text": " So that's what we're going to do all right so we're going to have for our up sampling would have two steps the first will", "tokens": [407, 300, 311, 437, 321, 434, 516, 281, 360, 439, 558, 370, 321, 434, 516, 281, 362, 337, 527, 493, 21179, 576, 362, 732, 4439, 264, 700, 486], "temperature": 0.0, "avg_logprob": -0.1932678956251878, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.2289152664379799e-06}, {"id": 549, "seek": 256228, "start": 2583.44, "end": 2585.44, "text": " Be a three by three cons", "tokens": [879, 257, 1045, 538, 1045, 1014], "temperature": 0.0, "avg_logprob": -0.1932678956251878, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.2289152664379799e-06}, {"id": 550, "seek": 256228, "start": 2586.52, "end": 2591.0400000000004, "text": " with R squared times more channels than we originally wanted and", "tokens": [365, 497, 8889, 1413, 544, 9235, 813, 321, 7993, 1415, 293], "temperature": 0.0, "avg_logprob": -0.1932678956251878, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.2289152664379799e-06}, {"id": 551, "seek": 259104, "start": 2591.04, "end": 2598.52, "text": " Then a pixel shuffle operation which moves everything in each grid cell into the little", "tokens": [1396, 257, 19261, 39426, 6916, 597, 6067, 1203, 294, 1184, 10748, 2815, 666, 264, 707], "temperature": 0.0, "avg_logprob": -0.23534934128387064, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.1726399407052668e-06}, {"id": 552, "seek": 259104, "start": 2599.04, "end": 2600.32, "text": " by our", "tokens": [538, 527], "temperature": 0.0, "avg_logprob": -0.23534934128387064, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.1726399407052668e-06}, {"id": 553, "seek": 259104, "start": 2600.32, "end": 2602.32, "text": " grids that are", "tokens": [677, 3742, 300, 366], "temperature": 0.0, "avg_logprob": -0.23534934128387064, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.1726399407052668e-06}, {"id": 554, "seek": 259104, "start": 2602.36, "end": 2604.36, "text": " Located throughout here, okay", "tokens": [12859, 770, 3710, 510, 11, 1392], "temperature": 0.0, "avg_logprob": -0.23534934128387064, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.1726399407052668e-06}, {"id": 555, "seek": 259104, "start": 2605.44, "end": 2607.44, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.23534934128387064, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.1726399407052668e-06}, {"id": 556, "seek": 259104, "start": 2607.68, "end": 2615.56, "text": " Here it is it's one line of code right and so here's the con from number of in to number of filters out", "tokens": [1692, 309, 307, 309, 311, 472, 1622, 295, 3089, 558, 293, 370, 510, 311, 264, 416, 490, 1230, 295, 294, 281, 1230, 295, 15995, 484], "temperature": 0.0, "avg_logprob": -0.23534934128387064, "compression_ratio": 1.505050505050505, "no_speech_prob": 1.1726399407052668e-06}, {"id": 557, "seek": 261556, "start": 2615.56, "end": 2622.36, "text": " Times four because we're doing a scale to up sample right so two squared is four", "tokens": [11366, 1451, 570, 321, 434, 884, 257, 4373, 281, 493, 6889, 558, 370, 732, 8889, 307, 1451], "temperature": 0.0, "avg_logprob": -0.21473663154689746, "compression_ratio": 1.696078431372549, "no_speech_prob": 2.443984612909844e-06}, {"id": 558, "seek": 261556, "start": 2623.12, "end": 2627.2, "text": " So that's our convolution and then here is our pixel shuffle", "tokens": [407, 300, 311, 527, 45216, 293, 550, 510, 307, 527, 19261, 39426], "temperature": 0.0, "avg_logprob": -0.21473663154689746, "compression_ratio": 1.696078431372549, "no_speech_prob": 2.443984612909844e-06}, {"id": 559, "seek": 261556, "start": 2627.2, "end": 2632.7599999999998, "text": " It's built into pytorch pixel shuffle is the thing that moves each thing into its right spot", "tokens": [467, 311, 3094, 666, 25878, 284, 339, 19261, 39426, 307, 264, 551, 300, 6067, 1184, 551, 666, 1080, 558, 4008], "temperature": 0.0, "avg_logprob": -0.21473663154689746, "compression_ratio": 1.696078431372549, "no_speech_prob": 2.443984612909844e-06}, {"id": 560, "seek": 261556, "start": 2634.52, "end": 2636.52, "text": " So that", "tokens": [407, 300], "temperature": 0.0, "avg_logprob": -0.21473663154689746, "compression_ratio": 1.696078431372549, "no_speech_prob": 2.443984612909844e-06}, {"id": 561, "seek": 261556, "start": 2636.68, "end": 2641.72, "text": " Will increase will up sample by a scale factor of two and so we need to do that", "tokens": [3099, 3488, 486, 493, 6889, 538, 257, 4373, 5952, 295, 732, 293, 370, 321, 643, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.21473663154689746, "compression_ratio": 1.696078431372549, "no_speech_prob": 2.443984612909844e-06}, {"id": 562, "seek": 264172, "start": 2641.72, "end": 2648.7999999999997, "text": " log base to scale times so scale is four and we have to do it two times to go to", "tokens": [3565, 3096, 281, 4373, 1413, 370, 4373, 307, 1451, 293, 321, 362, 281, 360, 309, 732, 1413, 281, 352, 281], "temperature": 0.0, "avg_logprob": -0.3282827377319336, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.8162176047553658e-06}, {"id": 563, "seek": 264172, "start": 2649.4399999999996, "end": 2655.9199999999996, "text": " Times two bigger okay, so that's what this up sample here does", "tokens": [11366, 732, 3801, 1392, 11, 370, 300, 311, 437, 341, 493, 6889, 510, 775], "temperature": 0.0, "avg_logprob": -0.3282827377319336, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.8162176047553658e-06}, {"id": 564, "seek": 264172, "start": 2660.08, "end": 2662.08, "text": " Great", "tokens": [3769], "temperature": 0.0, "avg_logprob": -0.3282827377319336, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.8162176047553658e-06}, {"id": 565, "seek": 264172, "start": 2662.08, "end": 2663.72, "text": " Guess what?", "tokens": [17795, 437, 30], "temperature": 0.0, "avg_logprob": -0.3282827377319336, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.8162176047553658e-06}, {"id": 566, "seek": 264172, "start": 2663.72, "end": 2665.8399999999997, "text": " That does not get rid of the checkerboard patterns", "tokens": [663, 775, 406, 483, 3973, 295, 264, 1520, 260, 3787, 8294], "temperature": 0.0, "avg_logprob": -0.3282827377319336, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.8162176047553658e-06}, {"id": 567, "seek": 264172, "start": 2667.0, "end": 2669.0, "text": " We still have checkerboard patterns", "tokens": [492, 920, 362, 1520, 260, 3787, 8294], "temperature": 0.0, "avg_logprob": -0.3282827377319336, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.8162176047553658e-06}, {"id": 568, "seek": 266900, "start": 2669.0, "end": 2674.6, "text": " So I'm sure in great fury and frustration this same team from Twitter", "tokens": [407, 286, 478, 988, 294, 869, 48887, 293, 20491, 341, 912, 1469, 490, 5794], "temperature": 0.0, "avg_logprob": -0.16611781231192654, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.42545297119068e-06}, {"id": 569, "seek": 266900, "start": 2674.6, "end": 2678.4, "text": " I think this is back when they used to be at a startup called magic pony that Twitter bought", "tokens": [286, 519, 341, 307, 646, 562, 436, 1143, 281, 312, 412, 257, 18578, 1219, 5585, 27342, 300, 5794, 4243], "temperature": 0.0, "avg_logprob": -0.16611781231192654, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.42545297119068e-06}, {"id": 570, "seek": 266900, "start": 2679.04, "end": 2682.7, "text": " Came back again with another paper saying okay", "tokens": [36042, 646, 797, 365, 1071, 3035, 1566, 1392], "temperature": 0.0, "avg_logprob": -0.16611781231192654, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.42545297119068e-06}, {"id": 571, "seek": 266900, "start": 2683.44, "end": 2685.44, "text": " This time we've got rid of the checkerboard", "tokens": [639, 565, 321, 600, 658, 3973, 295, 264, 1520, 260, 3787], "temperature": 0.0, "avg_logprob": -0.16611781231192654, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.42545297119068e-06}, {"id": 572, "seek": 266900, "start": 2686.44, "end": 2688.44, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.16611781231192654, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.42545297119068e-06}, {"id": 573, "seek": 268844, "start": 2688.44, "end": 2695.48, "text": " So why did we still have as you can see here? We still have a checkerboard", "tokens": [407, 983, 630, 321, 920, 362, 382, 291, 393, 536, 510, 30, 492, 920, 362, 257, 1520, 260, 3787], "temperature": 0.0, "avg_logprob": -0.3886278040268842, "compression_ratio": 1.6682242990654206, "no_speech_prob": 9.874606803350616e-07}, {"id": 574, "seek": 268844, "start": 2695.48, "end": 2698.48, "text": " All right, and so the reason we still have a checkerboard", "tokens": [1057, 558, 11, 293, 370, 264, 1778, 321, 920, 362, 257, 1520, 260, 3787], "temperature": 0.0, "avg_logprob": -0.3886278040268842, "compression_ratio": 1.6682242990654206, "no_speech_prob": 9.874606803350616e-07}, {"id": 575, "seek": 268844, "start": 2699.8, "end": 2706.7200000000003, "text": " Even after doing this is that when we randomly initialize this convolutional kernel at the start", "tokens": [2754, 934, 884, 341, 307, 300, 562, 321, 16979, 5883, 1125, 341, 45216, 304, 28256, 412, 264, 722], "temperature": 0.0, "avg_logprob": -0.3886278040268842, "compression_ratio": 1.6682242990654206, "no_speech_prob": 9.874606803350616e-07}, {"id": 576, "seek": 268844, "start": 2707.2400000000002, "end": 2714.12, "text": " It means that each of these nine pixels in this little three by three grid over here are going to be totally randomly different", "tokens": [467, 1355, 300, 1184, 295, 613, 4949, 18668, 294, 341, 707, 1045, 538, 1045, 10748, 670, 510, 366, 516, 281, 312, 3879, 16979, 819], "temperature": 0.0, "avg_logprob": -0.3886278040268842, "compression_ratio": 1.6682242990654206, "no_speech_prob": 9.874606803350616e-07}, {"id": 577, "seek": 271412, "start": 2714.12, "end": 2718.88, "text": " But then the next set of three pixels will be randomly different to each other", "tokens": [583, 550, 264, 958, 992, 295, 1045, 18668, 486, 312, 16979, 819, 281, 1184, 661], "temperature": 0.0, "avg_logprob": -0.29839782281355426, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.4439782464469317e-06}, {"id": 578, "seek": 271412, "start": 2719.6, "end": 2724.16, "text": " But will be very similar to their corresponding pixel in the previous three by three section", "tokens": [583, 486, 312, 588, 2531, 281, 641, 11760, 19261, 294, 264, 3894, 1045, 538, 1045, 3541], "temperature": 0.0, "avg_logprob": -0.29839782281355426, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.4439782464469317e-06}, {"id": 579, "seek": 271412, "start": 2724.16, "end": 2726.16, "text": " So we're going to have repeating", "tokens": [407, 321, 434, 516, 281, 362, 18617], "temperature": 0.0, "avg_logprob": -0.29839782281355426, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.4439782464469317e-06}, {"id": 580, "seek": 271412, "start": 2726.48, "end": 2730.4, "text": " Three by three things all the way across and so then as we try to learn", "tokens": [6244, 538, 1045, 721, 439, 264, 636, 2108, 293, 370, 550, 382, 321, 853, 281, 1466], "temperature": 0.0, "avg_logprob": -0.29839782281355426, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.4439782464469317e-06}, {"id": 581, "seek": 271412, "start": 2731.2, "end": 2738.08, "text": " Something better. It's starting from this like repeating three by three starting point, which is not what we want", "tokens": [6595, 1101, 13, 467, 311, 2891, 490, 341, 411, 18617, 1045, 538, 1045, 2891, 935, 11, 597, 307, 406, 437, 321, 528], "temperature": 0.0, "avg_logprob": -0.29839782281355426, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.4439782464469317e-06}, {"id": 582, "seek": 273808, "start": 2738.08, "end": 2743.72, "text": " What we actually would want is for these three by three pixels to be the same", "tokens": [708, 321, 767, 576, 528, 307, 337, 613, 1045, 538, 1045, 18668, 281, 312, 264, 912], "temperature": 0.0, "avg_logprob": -0.5177223021725574, "compression_ratio": 1.9367816091954022, "no_speech_prob": 2.123369768014527e-06}, {"id": 583, "seek": 273808, "start": 2744.2, "end": 2750.16, "text": " To start with so to make these three by three pixels the same we would need to make these nine", "tokens": [1407, 722, 365, 370, 281, 652, 613, 1045, 538, 1045, 18668, 264, 912, 321, 576, 643, 281, 652, 613, 4949], "temperature": 0.0, "avg_logprob": -0.5177223021725574, "compression_ratio": 1.9367816091954022, "no_speech_prob": 2.123369768014527e-06}, {"id": 584, "seek": 273808, "start": 2751.2, "end": 2753.2, "text": " channels the same", "tokens": [9235, 264, 912], "temperature": 0.0, "avg_logprob": -0.5177223021725574, "compression_ratio": 1.9367816091954022, "no_speech_prob": 2.123369768014527e-06}, {"id": 585, "seek": 273808, "start": 2753.24, "end": 2758.04, "text": " Yeah, right for each filter and so the solution", "tokens": [865, 11, 558, 337, 1184, 6608, 293, 370, 264, 3827], "temperature": 0.0, "avg_logprob": -0.5177223021725574, "compression_ratio": 1.9367816091954022, "no_speech_prob": 2.123369768014527e-06}, {"id": 586, "seek": 273808, "start": 2759.08, "end": 2761.08, "text": " And this paper is very simple", "tokens": [400, 341, 3035, 307, 588, 2199], "temperature": 0.0, "avg_logprob": -0.5177223021725574, "compression_ratio": 1.9367816091954022, "no_speech_prob": 2.123369768014527e-06}, {"id": 587, "seek": 273808, "start": 2761.36, "end": 2765.08, "text": " It's that when we actually start to make these three by three pixels", "tokens": [467, 311, 300, 562, 321, 767, 722, 281, 652, 613, 1045, 538, 1045, 18668], "temperature": 0.0, "avg_logprob": -0.5177223021725574, "compression_ratio": 1.9367816091954022, "no_speech_prob": 2.123369768014527e-06}, {"id": 588, "seek": 276508, "start": 2765.08, "end": 2768.64, "text": " And this paper is very simple. It's that when we initialize", "tokens": [400, 341, 3035, 307, 588, 2199, 13, 467, 311, 300, 562, 321, 5883, 1125], "temperature": 0.0, "avg_logprob": -0.19581586664373224, "compression_ratio": 1.87, "no_speech_prob": 1.034850697578804e-06}, {"id": 589, "seek": 276508, "start": 2769.36, "end": 2776.92, "text": " This convolution at the start when we randomly initialize it. We don't totally randomly initialize it we randomly initialize", "tokens": [639, 45216, 412, 264, 722, 562, 321, 16979, 5883, 1125, 309, 13, 492, 500, 380, 3879, 16979, 5883, 1125, 309, 321, 16979, 5883, 1125], "temperature": 0.0, "avg_logprob": -0.19581586664373224, "compression_ratio": 1.87, "no_speech_prob": 1.034850697578804e-06}, {"id": 590, "seek": 276508, "start": 2777.4, "end": 2779.4, "text": " one of the", "tokens": [472, 295, 264], "temperature": 0.0, "avg_logprob": -0.19581586664373224, "compression_ratio": 1.87, "no_speech_prob": 1.034850697578804e-06}, {"id": 591, "seek": 276508, "start": 2779.44, "end": 2783.88, "text": " R-squared sets of channels, and then we copy that to the other", "tokens": [497, 12, 33292, 1642, 6352, 295, 9235, 11, 293, 550, 321, 5055, 300, 281, 264, 661], "temperature": 0.0, "avg_logprob": -0.19581586664373224, "compression_ratio": 1.87, "no_speech_prob": 1.034850697578804e-06}, {"id": 592, "seek": 276508, "start": 2784.52, "end": 2790.48, "text": " R-squared so they're all the same and that way initially each of these three by threes will be the same", "tokens": [497, 12, 33292, 1642, 370, 436, 434, 439, 264, 912, 293, 300, 636, 9105, 1184, 295, 613, 1045, 538, 258, 4856, 486, 312, 264, 912], "temperature": 0.0, "avg_logprob": -0.19581586664373224, "compression_ratio": 1.87, "no_speech_prob": 1.034850697578804e-06}, {"id": 593, "seek": 276508, "start": 2791.04, "end": 2793.04, "text": " and so that", "tokens": [293, 370, 300], "temperature": 0.0, "avg_logprob": -0.19581586664373224, "compression_ratio": 1.87, "no_speech_prob": 1.034850697578804e-06}, {"id": 594, "seek": 279304, "start": 2793.04, "end": 2800.12, "text": " Is called I see enough okay, and that's what we're going to use in a moment", "tokens": [1119, 1219, 286, 536, 1547, 1392, 11, 293, 300, 311, 437, 321, 434, 516, 281, 764, 294, 257, 1623], "temperature": 0.0, "avg_logprob": -0.22346808320732528, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4465599583199946e-06}, {"id": 595, "seek": 279304, "start": 2802.04, "end": 2807.68, "text": " So before we do let's take a quick look so we've got this super resolution resnet", "tokens": [407, 949, 321, 360, 718, 311, 747, 257, 1702, 574, 370, 321, 600, 658, 341, 1687, 8669, 725, 7129], "temperature": 0.0, "avg_logprob": -0.22346808320732528, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4465599583199946e-06}, {"id": 596, "seek": 279304, "start": 2807.68, "end": 2813.7, "text": " Which just does lots of computation you know with lots of resnet blocks, and then it does some up sampling and gets our final", "tokens": [3013, 445, 775, 3195, 295, 24903, 291, 458, 365, 3195, 295, 725, 7129, 8474, 11, 293, 550, 309, 775, 512, 493, 21179, 293, 2170, 527, 2572], "temperature": 0.0, "avg_logprob": -0.22346808320732528, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4465599583199946e-06}, {"id": 597, "seek": 279304, "start": 2813.7, "end": 2815.7, "text": " three channels out and", "tokens": [1045, 9235, 484, 293], "temperature": 0.0, "avg_logprob": -0.22346808320732528, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4465599583199946e-06}, {"id": 598, "seek": 279304, "start": 2816.72, "end": 2821.0, "text": " Then to make life faster we're going to run this in parallel", "tokens": [1396, 281, 652, 993, 4663, 321, 434, 516, 281, 1190, 341, 294, 8952], "temperature": 0.0, "avg_logprob": -0.22346808320732528, "compression_ratio": 1.6311111111111112, "no_speech_prob": 3.4465599583199946e-06}, {"id": 599, "seek": 282100, "start": 2821.0, "end": 2823.0, "text": " One", "tokens": [1485], "temperature": 0.0, "avg_logprob": -0.22062143961588543, "compression_ratio": 1.4814814814814814, "no_speech_prob": 6.643374945269898e-06}, {"id": 600, "seek": 282100, "start": 2823.04, "end": 2828.08, "text": " Reason we want to run it in parallel is because Dorado told us that he has six GPUs", "tokens": [39693, 321, 528, 281, 1190, 309, 294, 8952, 307, 570, 13643, 1573, 1907, 505, 300, 415, 575, 2309, 18407, 82], "temperature": 0.0, "avg_logprob": -0.22062143961588543, "compression_ratio": 1.4814814814814814, "no_speech_prob": 6.643374945269898e-06}, {"id": 601, "seek": 282100, "start": 2828.08, "end": 2830.84, "text": " And this is what his computer looks like right now", "tokens": [400, 341, 307, 437, 702, 3820, 1542, 411, 558, 586], "temperature": 0.0, "avg_logprob": -0.22062143961588543, "compression_ratio": 1.4814814814814814, "no_speech_prob": 6.643374945269898e-06}, {"id": 602, "seek": 282100, "start": 2832.52, "end": 2837.88, "text": " And so I'm sure anybody who has more than one GPU is had this experience before", "tokens": [400, 370, 286, 478, 988, 4472, 567, 575, 544, 813, 472, 18407, 307, 632, 341, 1752, 949], "temperature": 0.0, "avg_logprob": -0.22062143961588543, "compression_ratio": 1.4814814814814814, "no_speech_prob": 6.643374945269898e-06}, {"id": 603, "seek": 282100, "start": 2839.44, "end": 2845.4, "text": " So how do we get how do we get these men working in together?", "tokens": [407, 577, 360, 321, 483, 577, 360, 321, 483, 613, 1706, 1364, 294, 1214, 30], "temperature": 0.0, "avg_logprob": -0.22062143961588543, "compression_ratio": 1.4814814814814814, "no_speech_prob": 6.643374945269898e-06}, {"id": 604, "seek": 284540, "start": 2845.4, "end": 2851.6, "text": " All you need to do is to take your pytorch module and", "tokens": [1057, 291, 643, 281, 360, 307, 281, 747, 428, 25878, 284, 339, 10088, 293], "temperature": 0.0, "avg_logprob": -0.24898515428815568, "compression_ratio": 1.503030303030303, "no_speech_prob": 1.963793920367607e-06}, {"id": 605, "seek": 284540, "start": 2853.12, "end": 2855.4, "text": " Wrap it with an end data parallel", "tokens": [41291, 309, 365, 364, 917, 1412, 8952], "temperature": 0.0, "avg_logprob": -0.24898515428815568, "compression_ratio": 1.503030303030303, "no_speech_prob": 1.963793920367607e-06}, {"id": 606, "seek": 284540, "start": 2856.2000000000003, "end": 2864.32, "text": " Okay, and once you've done that it copies it to each of your GPUs and will automatically run it in parallel", "tokens": [1033, 11, 293, 1564, 291, 600, 1096, 300, 309, 14341, 309, 281, 1184, 295, 428, 18407, 82, 293, 486, 6772, 1190, 309, 294, 8952], "temperature": 0.0, "avg_logprob": -0.24898515428815568, "compression_ratio": 1.503030303030303, "no_speech_prob": 1.963793920367607e-06}, {"id": 607, "seek": 284540, "start": 2865.32, "end": 2867.6800000000003, "text": " It scales pretty well to two GPUs", "tokens": [467, 17408, 1238, 731, 281, 732, 18407, 82], "temperature": 0.0, "avg_logprob": -0.24898515428815568, "compression_ratio": 1.503030303030303, "no_speech_prob": 1.963793920367607e-06}, {"id": 608, "seek": 284540, "start": 2868.8, "end": 2870.8, "text": " Okay to three GPUs", "tokens": [1033, 281, 1045, 18407, 82], "temperature": 0.0, "avg_logprob": -0.24898515428815568, "compression_ratio": 1.503030303030303, "no_speech_prob": 1.963793920367607e-06}, {"id": 609, "seek": 287080, "start": 2870.8, "end": 2875.92, "text": " I'm better than nothing to four GPUs and beyond that performance starts to go", "tokens": [286, 478, 1101, 813, 1825, 281, 1451, 18407, 82, 293, 4399, 300, 3389, 3719, 281, 352], "temperature": 0.0, "avg_logprob": -0.1663831983293806, "compression_ratio": 1.69921875, "no_speech_prob": 7.296275271073682e-06}, {"id": 610, "seek": 287080, "start": 2876.92, "end": 2878.92, "text": " backwards", "tokens": [12204], "temperature": 0.0, "avg_logprob": -0.1663831983293806, "compression_ratio": 1.69921875, "no_speech_prob": 7.296275271073682e-06}, {"id": 611, "seek": 287080, "start": 2879.04, "end": 2885.36, "text": " The by default it'll copy it to all of your GPUs you can add an array of GPUs otherwise", "tokens": [440, 538, 7576, 309, 603, 5055, 309, 281, 439, 295, 428, 18407, 82, 291, 393, 909, 364, 10225, 295, 18407, 82, 5911], "temperature": 0.0, "avg_logprob": -0.1663831983293806, "compression_ratio": 1.69921875, "no_speech_prob": 7.296275271073682e-06}, {"id": 612, "seek": 287080, "start": 2886.44, "end": 2889.4, "text": " If you want to avoid getting in trouble for example", "tokens": [759, 291, 528, 281, 5042, 1242, 294, 5253, 337, 1365], "temperature": 0.0, "avg_logprob": -0.1663831983293806, "compression_ratio": 1.69921875, "no_speech_prob": 7.296275271073682e-06}, {"id": 613, "seek": 287080, "start": 2889.4, "end": 2892.6000000000004, "text": " I have to share our box with your net and if I didn't put this here", "tokens": [286, 362, 281, 2073, 527, 2424, 365, 428, 2533, 293, 498, 286, 994, 380, 829, 341, 510], "temperature": 0.0, "avg_logprob": -0.1663831983293806, "compression_ratio": 1.69921875, "no_speech_prob": 7.296275271073682e-06}, {"id": 614, "seek": 287080, "start": 2892.6000000000004, "end": 2897.1600000000003, "text": " Then she would be yelling at me right now or maybe you know boycotting my class", "tokens": [1396, 750, 576, 312, 18381, 412, 385, 558, 586, 420, 1310, 291, 458, 3237, 48477, 783, 452, 1508], "temperature": 0.0, "avg_logprob": -0.1663831983293806, "compression_ratio": 1.69921875, "no_speech_prob": 7.296275271073682e-06}, {"id": 615, "seek": 287080, "start": 2897.28, "end": 2900.1600000000003, "text": " So this is how you avoid getting into trouble with your net", "tokens": [407, 341, 307, 577, 291, 5042, 1242, 666, 5253, 365, 428, 2533], "temperature": 0.0, "avg_logprob": -0.1663831983293806, "compression_ratio": 1.69921875, "no_speech_prob": 7.296275271073682e-06}, {"id": 616, "seek": 290016, "start": 2900.16, "end": 2902.16, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.21539839720114684, "compression_ratio": 1.6428571428571428, "no_speech_prob": 9.972830412152689e-06}, {"id": 617, "seek": 290016, "start": 2903.44, "end": 2909.04, "text": " One thing to be aware of here is that once you do this it actually modifies your module", "tokens": [1485, 551, 281, 312, 3650, 295, 510, 307, 300, 1564, 291, 360, 341, 309, 767, 1072, 11221, 428, 10088], "temperature": 0.0, "avg_logprob": -0.21539839720114684, "compression_ratio": 1.6428571428571428, "no_speech_prob": 9.972830412152689e-06}, {"id": 618, "seek": 290016, "start": 2909.04, "end": 2914.24, "text": " So if you now print out your module, let's say previously it was just an n n dot sequential now", "tokens": [407, 498, 291, 586, 4482, 484, 428, 10088, 11, 718, 311, 584, 8046, 309, 390, 445, 364, 297, 297, 5893, 42881, 586], "temperature": 0.0, "avg_logprob": -0.21539839720114684, "compression_ratio": 1.6428571428571428, "no_speech_prob": 9.972830412152689e-06}, {"id": 619, "seek": 290016, "start": 2914.24, "end": 2917.8399999999997, "text": " you'll find it's an n n dot sequential embedded inside a", "tokens": [291, 603, 915, 309, 311, 364, 297, 297, 5893, 42881, 16741, 1854, 257], "temperature": 0.0, "avg_logprob": -0.21539839720114684, "compression_ratio": 1.6428571428571428, "no_speech_prob": 9.972830412152689e-06}, {"id": 620, "seek": 290016, "start": 2919.92, "end": 2924.08, "text": " Module called module right and so in other words if you", "tokens": [48251, 1219, 10088, 558, 293, 370, 294, 661, 2283, 498, 291], "temperature": 0.0, "avg_logprob": -0.21539839720114684, "compression_ratio": 1.6428571428571428, "no_speech_prob": 9.972830412152689e-06}, {"id": 621, "seek": 292408, "start": 2924.08, "end": 2931.7999999999997, "text": " Save something which you had an end up data paralleled and then try to load it back into something that you hadn't", "tokens": [15541, 746, 597, 291, 632, 364, 917, 493, 1412, 8952, 292, 293, 550, 853, 281, 3677, 309, 646, 666, 746, 300, 291, 8782, 380], "temperature": 0.0, "avg_logprob": -0.24831980124287223, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.6028049003580236e-06}, {"id": 622, "seek": 292408, "start": 2931.96, "end": 2936.7599999999998, "text": " And end up data paralleled it'll say it doesn't match up because one of them is embedded inside this", "tokens": [400, 917, 493, 1412, 8952, 292, 309, 603, 584, 309, 1177, 380, 2995, 493, 570, 472, 295, 552, 307, 16741, 1854, 341], "temperature": 0.0, "avg_logprob": -0.24831980124287223, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.6028049003580236e-06}, {"id": 623, "seek": 292408, "start": 2937.12, "end": 2939.6, "text": " Module attribute and the other one isn't", "tokens": [48251, 19667, 293, 264, 661, 472, 1943, 380], "temperature": 0.0, "avg_logprob": -0.24831980124287223, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.6028049003580236e-06}, {"id": 624, "seek": 292408, "start": 2940.36, "end": 2945.52, "text": " It may also depend even on which GPU IDs you had had it copy to", "tokens": [467, 815, 611, 5672, 754, 322, 597, 18407, 48212, 291, 632, 632, 309, 5055, 281], "temperature": 0.0, "avg_logprob": -0.24831980124287223, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.6028049003580236e-06}, {"id": 625, "seek": 292408, "start": 2946.56, "end": 2948.36, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.24831980124287223, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.6028049003580236e-06}, {"id": 626, "seek": 292408, "start": 2948.36, "end": 2950.36, "text": " two possible solutions", "tokens": [732, 1944, 6547], "temperature": 0.0, "avg_logprob": -0.24831980124287223, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.6028049003580236e-06}, {"id": 627, "seek": 295036, "start": 2950.36, "end": 2957.36, "text": " One is don't save the module M but instead save the module attribute M dot module", "tokens": [1485, 307, 500, 380, 3155, 264, 10088, 376, 457, 2602, 3155, 264, 10088, 19667, 376, 5893, 10088], "temperature": 0.0, "avg_logprob": -0.19669972933255708, "compression_ratio": 1.7654320987654322, "no_speech_prob": 1.4144716260489076e-06}, {"id": 628, "seek": 295036, "start": 2957.84, "end": 2960.76, "text": " because that's actually the the non data parallel bit or", "tokens": [570, 300, 311, 767, 264, 264, 2107, 1412, 8952, 857, 420], "temperature": 0.0, "avg_logprob": -0.19669972933255708, "compression_ratio": 1.7654320987654322, "no_speech_prob": 1.4144716260489076e-06}, {"id": 629, "seek": 295036, "start": 2962.2000000000003, "end": 2968.76, "text": " Always put it on the same GPU IDs and this then use data parallel and load and save that every time", "tokens": [11270, 829, 309, 322, 264, 912, 18407, 48212, 293, 341, 550, 764, 1412, 8952, 293, 3677, 293, 3155, 300, 633, 565], "temperature": 0.0, "avg_logprob": -0.19669972933255708, "compression_ratio": 1.7654320987654322, "no_speech_prob": 1.4144716260489076e-06}, {"id": 630, "seek": 295036, "start": 2968.76, "end": 2970.76, "text": " That's what I was using", "tokens": [663, 311, 437, 286, 390, 1228], "temperature": 0.0, "avg_logprob": -0.19669972933255708, "compression_ratio": 1.7654320987654322, "no_speech_prob": 1.4144716260489076e-06}, {"id": 631, "seek": 295036, "start": 2970.8, "end": 2975.36, "text": " This would be an easy thing for me to fix automatically in fast AI and I'll do it pretty soon", "tokens": [639, 576, 312, 364, 1858, 551, 337, 385, 281, 3191, 6772, 294, 2370, 7318, 293, 286, 603, 360, 309, 1238, 2321], "temperature": 0.0, "avg_logprob": -0.19669972933255708, "compression_ratio": 1.7654320987654322, "no_speech_prob": 1.4144716260489076e-06}, {"id": 632, "seek": 295036, "start": 2975.36, "end": 2978.88, "text": " So it'll look for that module attribution and deal with it automatically", "tokens": [407, 309, 603, 574, 337, 300, 10088, 9080, 1448, 293, 2028, 365, 309, 6772], "temperature": 0.0, "avg_logprob": -0.19669972933255708, "compression_ratio": 1.7654320987654322, "no_speech_prob": 1.4144716260489076e-06}, {"id": 633, "seek": 297888, "start": 2978.88, "end": 2984.7200000000003, "text": " But for now we have to do it manually. It's probably useful to know what's going on behind the scenes anyway", "tokens": [583, 337, 586, 321, 362, 281, 360, 309, 16945, 13, 467, 311, 1391, 4420, 281, 458, 437, 311, 516, 322, 2261, 264, 8026, 4033], "temperature": 0.0, "avg_logprob": -0.19243109763205588, "compression_ratio": 1.628787878787879, "no_speech_prob": 2.4439821117994143e-06}, {"id": 634, "seek": 297888, "start": 2985.48, "end": 2987.48, "text": " All right, so we've got our module", "tokens": [1057, 558, 11, 370, 321, 600, 658, 527, 10088], "temperature": 0.0, "avg_logprob": -0.19243109763205588, "compression_ratio": 1.628787878787879, "no_speech_prob": 2.4439821117994143e-06}, {"id": 635, "seek": 297888, "start": 2988.28, "end": 2993.44, "text": " You know I find it'll run like 50 or 60 percent faster on a 1080 TI", "tokens": [509, 458, 286, 915, 309, 603, 1190, 411, 2625, 420, 4060, 3043, 4663, 322, 257, 24547, 28819], "temperature": 0.0, "avg_logprob": -0.19243109763205588, "compression_ratio": 1.628787878787879, "no_speech_prob": 2.4439821117994143e-06}, {"id": 636, "seek": 297888, "start": 2993.88, "end": 2997.6, "text": " If you're running on Volta, it actually parallelizes a bit better", "tokens": [759, 291, 434, 2614, 322, 8911, 1328, 11, 309, 767, 8952, 5660, 257, 857, 1101], "temperature": 0.0, "avg_logprob": -0.19243109763205588, "compression_ratio": 1.628787878787879, "no_speech_prob": 2.4439821117994143e-06}, {"id": 637, "seek": 297888, "start": 2999.48, "end": 3004.84, "text": " There's a there are much faster ways to parallel parallelize, but this is like a super super easy way", "tokens": [821, 311, 257, 456, 366, 709, 4663, 2098, 281, 8952, 8952, 1125, 11, 457, 341, 307, 411, 257, 1687, 1687, 1858, 636], "temperature": 0.0, "avg_logprob": -0.19243109763205588, "compression_ratio": 1.628787878787879, "no_speech_prob": 2.4439821117994143e-06}, {"id": 638, "seek": 300484, "start": 3004.84, "end": 3010.6000000000004, "text": " All right, so we create our learner in the usual way we could use MSE loss here", "tokens": [1057, 558, 11, 370, 321, 1884, 527, 33347, 294, 264, 7713, 636, 321, 727, 764, 376, 5879, 4470, 510], "temperature": 0.0, "avg_logprob": -0.1990696559442538, "compression_ratio": 1.6984126984126984, "no_speech_prob": 9.874607940218993e-07}, {"id": 639, "seek": 300484, "start": 3011.0, "end": 3015.6000000000004, "text": " So that's just going to compare the pixels of the output to the pixels, you know that we expected", "tokens": [407, 300, 311, 445, 516, 281, 6794, 264, 18668, 295, 264, 5598, 281, 264, 18668, 11, 291, 458, 300, 321, 5176], "temperature": 0.0, "avg_logprob": -0.1990696559442538, "compression_ratio": 1.6984126984126984, "no_speech_prob": 9.874607940218993e-07}, {"id": 640, "seek": 300484, "start": 3017.0, "end": 3020.4, "text": " and we can run our learning rate finder and we can train it for a while and", "tokens": [293, 321, 393, 1190, 527, 2539, 3314, 915, 260, 293, 321, 393, 3847, 309, 337, 257, 1339, 293], "temperature": 0.0, "avg_logprob": -0.1990696559442538, "compression_ratio": 1.6984126984126984, "no_speech_prob": 9.874607940218993e-07}, {"id": 641, "seek": 300484, "start": 3021.76, "end": 3025.36, "text": " Here's our input and here's our output and", "tokens": [1692, 311, 527, 4846, 293, 510, 311, 527, 5598, 293], "temperature": 0.0, "avg_logprob": -0.1990696559442538, "compression_ratio": 1.6984126984126984, "no_speech_prob": 9.874607940218993e-07}, {"id": 642, "seek": 300484, "start": 3026.04, "end": 3033.1800000000003, "text": " You can see that what we've managed to do is to train a very advanced residual convolutional network. That's learned to blur things", "tokens": [509, 393, 536, 300, 437, 321, 600, 6453, 281, 360, 307, 281, 3847, 257, 588, 7339, 27980, 45216, 304, 3209, 13, 663, 311, 3264, 281, 14257, 721], "temperature": 0.0, "avg_logprob": -0.1990696559442538, "compression_ratio": 1.6984126984126984, "no_speech_prob": 9.874607940218993e-07}, {"id": 643, "seek": 303318, "start": 3033.18, "end": 3035.18, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.23631460016424005, "compression_ratio": 1.5828877005347595, "no_speech_prob": 3.288735115347663e-06}, {"id": 644, "seek": 303318, "start": 3035.7, "end": 3039.18, "text": " Why is that well because it's what we asked for we said to", "tokens": [1545, 307, 300, 731, 570, 309, 311, 437, 321, 2351, 337, 321, 848, 281], "temperature": 0.0, "avg_logprob": -0.23631460016424005, "compression_ratio": 1.5828877005347595, "no_speech_prob": 3.288735115347663e-06}, {"id": 645, "seek": 303318, "start": 3040.06, "end": 3043.96, "text": " Minimize MSE loss right an MSE loss between pixels", "tokens": [2829, 43890, 376, 5879, 4470, 558, 364, 376, 5879, 4470, 1296, 18668], "temperature": 0.0, "avg_logprob": -0.23631460016424005, "compression_ratio": 1.5828877005347595, "no_speech_prob": 3.288735115347663e-06}, {"id": 646, "seek": 303318, "start": 3044.58, "end": 3049.06, "text": " Really the best way to do that is just average the pixels I eat a blur", "tokens": [4083, 264, 1151, 636, 281, 360, 300, 307, 445, 4274, 264, 18668, 286, 1862, 257, 14257], "temperature": 0.0, "avg_logprob": -0.23631460016424005, "compression_ratio": 1.5828877005347595, "no_speech_prob": 3.288735115347663e-06}, {"id": 647, "seek": 303318, "start": 3049.98, "end": 3053.74, "text": " So that's why pixel loss is no good. So we want to use our", "tokens": [407, 300, 311, 983, 19261, 4470, 307, 572, 665, 13, 407, 321, 528, 281, 764, 527], "temperature": 0.0, "avg_logprob": -0.23631460016424005, "compression_ratio": 1.5828877005347595, "no_speech_prob": 3.288735115347663e-06}, {"id": 648, "seek": 303318, "start": 3054.62, "end": 3056.54, "text": " perceptual loss", "tokens": [43276, 901, 4470], "temperature": 0.0, "avg_logprob": -0.23631460016424005, "compression_ratio": 1.5828877005347595, "no_speech_prob": 3.288735115347663e-06}, {"id": 649, "seek": 303318, "start": 3056.54, "end": 3059.24, "text": " So let's try perceptual loss, right?", "tokens": [407, 718, 311, 853, 43276, 901, 4470, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23631460016424005, "compression_ratio": 1.5828877005347595, "no_speech_prob": 3.288735115347663e-06}, {"id": 650, "seek": 305924, "start": 3059.24, "end": 3063.14, "text": " So with perceptual loss, we're basically going to take our", "tokens": [407, 365, 43276, 901, 4470, 11, 321, 434, 1936, 516, 281, 747, 527], "temperature": 0.0, "avg_logprob": -0.2201047097482989, "compression_ratio": 1.5458715596330275, "no_speech_prob": 2.0580412183335284e-06}, {"id": 651, "seek": 305924, "start": 3063.9199999999996, "end": 3070.52, "text": " VGG network and just like we did last week. We're going to find the the block index", "tokens": [691, 27561, 3209, 293, 445, 411, 321, 630, 1036, 1243, 13, 492, 434, 516, 281, 915, 264, 264, 3461, 8186], "temperature": 0.0, "avg_logprob": -0.2201047097482989, "compression_ratio": 1.5458715596330275, "no_speech_prob": 2.0580412183335284e-06}, {"id": 652, "seek": 305924, "start": 3071.24, "end": 3073.24, "text": " Just before we get a max pull", "tokens": [1449, 949, 321, 483, 257, 11469, 2235], "temperature": 0.0, "avg_logprob": -0.2201047097482989, "compression_ratio": 1.5458715596330275, "no_speech_prob": 2.0580412183335284e-06}, {"id": 653, "seek": 305924, "start": 3073.56, "end": 3078.6, "text": " okay, so here are the ends of each of each kind of block of the same grid size and", "tokens": [1392, 11, 370, 510, 366, 264, 5314, 295, 1184, 295, 1184, 733, 295, 3461, 295, 264, 912, 10748, 2744, 293], "temperature": 0.0, "avg_logprob": -0.2201047097482989, "compression_ratio": 1.5458715596330275, "no_speech_prob": 2.0580412183335284e-06}, {"id": 654, "seek": 305924, "start": 3079.52, "end": 3083.72, "text": " If we just print them out as we'd expect every one of those is a value module", "tokens": [759, 321, 445, 4482, 552, 484, 382, 321, 1116, 2066, 633, 472, 295, 729, 307, 257, 2158, 10088], "temperature": 0.0, "avg_logprob": -0.2201047097482989, "compression_ratio": 1.5458715596330275, "no_speech_prob": 2.0580412183335284e-06}, {"id": 655, "seek": 305924, "start": 3084.52, "end": 3085.8399999999997, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.2201047097482989, "compression_ratio": 1.5458715596330275, "no_speech_prob": 2.0580412183335284e-06}, {"id": 656, "seek": 308584, "start": 3085.84, "end": 3089.4, "text": " So in this case these last two blocks", "tokens": [407, 294, 341, 1389, 613, 1036, 732, 8474], "temperature": 0.0, "avg_logprob": -0.1507106920083364, "compression_ratio": 1.6608695652173913, "no_speech_prob": 3.3931310099433176e-06}, {"id": 657, "seek": 308584, "start": 3089.92, "end": 3094.2400000000002, "text": " Are less interesting to us the kind of the grid size there is small enough", "tokens": [2014, 1570, 1880, 281, 505, 264, 733, 295, 264, 10748, 2744, 456, 307, 1359, 1547], "temperature": 0.0, "avg_logprob": -0.1507106920083364, "compression_ratio": 1.6608695652173913, "no_speech_prob": 3.3931310099433176e-06}, {"id": 658, "seek": 308584, "start": 3095.08, "end": 3099.48, "text": " You know kind of coarse enough that it's not as useful for super resolution", "tokens": [509, 458, 733, 295, 39312, 1547, 300, 309, 311, 406, 382, 4420, 337, 1687, 8669], "temperature": 0.0, "avg_logprob": -0.1507106920083364, "compression_ratio": 1.6608695652173913, "no_speech_prob": 3.3931310099433176e-06}, {"id": 659, "seek": 308584, "start": 3099.48, "end": 3104.5, "text": " So we're just going to use the first three and so just to save unnecessary computation", "tokens": [407, 321, 434, 445, 516, 281, 764, 264, 700, 1045, 293, 370, 445, 281, 3155, 19350, 24903], "temperature": 0.0, "avg_logprob": -0.1507106920083364, "compression_ratio": 1.6608695652173913, "no_speech_prob": 3.3931310099433176e-06}, {"id": 660, "seek": 308584, "start": 3104.76, "end": 3109.84, "text": " We're just going to use those first 23 layers for VGG. We'll throw away the rest", "tokens": [492, 434, 445, 516, 281, 764, 729, 700, 6673, 7914, 337, 691, 27561, 13, 492, 603, 3507, 1314, 264, 1472], "temperature": 0.0, "avg_logprob": -0.1507106920083364, "compression_ratio": 1.6608695652173913, "no_speech_prob": 3.3931310099433176e-06}, {"id": 661, "seek": 308584, "start": 3110.6000000000004, "end": 3112.6000000000004, "text": " We'll stick it on the GPU", "tokens": [492, 603, 2897, 309, 322, 264, 18407], "temperature": 0.0, "avg_logprob": -0.1507106920083364, "compression_ratio": 1.6608695652173913, "no_speech_prob": 3.3931310099433176e-06}, {"id": 662, "seek": 311260, "start": 3112.6, "end": 3119.2, "text": " We're not going to be training this VGG model at all. We're just using it to compare activations", "tokens": [492, 434, 406, 516, 281, 312, 3097, 341, 691, 27561, 2316, 412, 439, 13, 492, 434, 445, 1228, 309, 281, 6794, 2430, 763], "temperature": 0.0, "avg_logprob": -0.14818041412918656, "compression_ratio": 1.603921568627451, "no_speech_prob": 2.332061967535992e-06}, {"id": 663, "seek": 311260, "start": 3119.3199999999997, "end": 3123.3399999999997, "text": " So we'll stick it in eval mode and we will set it to not trainable", "tokens": [407, 321, 603, 2897, 309, 294, 1073, 304, 4391, 293, 321, 486, 992, 309, 281, 406, 3847, 712], "temperature": 0.0, "avg_logprob": -0.14818041412918656, "compression_ratio": 1.603921568627451, "no_speech_prob": 2.332061967535992e-06}, {"id": 664, "seek": 311260, "start": 3123.88, "end": 3125.88, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.14818041412918656, "compression_ratio": 1.603921568627451, "no_speech_prob": 2.332061967535992e-06}, {"id": 665, "seek": 311260, "start": 3127.08, "end": 3128.3199999999997, "text": " Just like last week", "tokens": [1449, 411, 1036, 1243], "temperature": 0.0, "avg_logprob": -0.14818041412918656, "compression_ratio": 1.603921568627451, "no_speech_prob": 2.332061967535992e-06}, {"id": 666, "seek": 311260, "start": 3128.3199999999997, "end": 3135.96, "text": " We'll use a save features class to through a forward hook which saves the output activations at each of those layers", "tokens": [492, 603, 764, 257, 3155, 4122, 1508, 281, 807, 257, 2128, 6328, 597, 19155, 264, 5598, 2430, 763, 412, 1184, 295, 729, 7914], "temperature": 0.0, "avg_logprob": -0.14818041412918656, "compression_ratio": 1.603921568627451, "no_speech_prob": 2.332061967535992e-06}, {"id": 667, "seek": 311260, "start": 3136.8399999999997, "end": 3139.12, "text": " And so now we've got everything we need to create our", "tokens": [400, 370, 586, 321, 600, 658, 1203, 321, 643, 281, 1884, 527], "temperature": 0.0, "avg_logprob": -0.14818041412918656, "compression_ratio": 1.603921568627451, "no_speech_prob": 2.332061967535992e-06}, {"id": 668, "seek": 313912, "start": 3139.12, "end": 3144.04, "text": " Perceptual loss or as I call it here feature loss class, right?", "tokens": [3026, 1336, 901, 4470, 420, 382, 286, 818, 309, 510, 4111, 4470, 1508, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21368595304943266, "compression_ratio": 1.794979079497908, "no_speech_prob": 5.682364644599147e-06}, {"id": 669, "seek": 313912, "start": 3144.04, "end": 3147.38, "text": " And so we're going to pass in a list of layer IDs", "tokens": [400, 370, 321, 434, 516, 281, 1320, 294, 257, 1329, 295, 4583, 48212], "temperature": 0.0, "avg_logprob": -0.21368595304943266, "compression_ratio": 1.794979079497908, "no_speech_prob": 5.682364644599147e-06}, {"id": 670, "seek": 313912, "start": 3148.92, "end": 3154.48, "text": " You know the layers where we want the content loss to be calculated an array of weights", "tokens": [509, 458, 264, 7914, 689, 321, 528, 264, 2701, 4470, 281, 312, 15598, 364, 10225, 295, 17443], "temperature": 0.0, "avg_logprob": -0.21368595304943266, "compression_ratio": 1.794979079497908, "no_speech_prob": 5.682364644599147e-06}, {"id": 671, "seek": 313912, "start": 3155.3199999999997, "end": 3157.52, "text": " Or a list of weights for each of those layers", "tokens": [1610, 257, 1329, 295, 17443, 337, 1184, 295, 729, 7914], "temperature": 0.0, "avg_logprob": -0.21368595304943266, "compression_ratio": 1.794979079497908, "no_speech_prob": 5.682364644599147e-06}, {"id": 672, "seek": 313912, "start": 3159.16, "end": 3161.3599999999997, "text": " So we can just go through each of those layer IDs", "tokens": [407, 321, 393, 445, 352, 807, 1184, 295, 729, 4583, 48212], "temperature": 0.0, "avg_logprob": -0.21368595304943266, "compression_ratio": 1.794979079497908, "no_speech_prob": 5.682364644599147e-06}, {"id": 673, "seek": 316136, "start": 3161.36, "end": 3169.1600000000003, "text": " And create an object which is going to store which is you know got the hook function forward hook function to store the activations and", "tokens": [400, 1884, 364, 2657, 597, 307, 516, 281, 3531, 597, 307, 291, 458, 658, 264, 6328, 2445, 2128, 6328, 2445, 281, 3531, 264, 2430, 763, 293], "temperature": 0.0, "avg_logprob": -0.23636621417421283, "compression_ratio": 1.9049773755656108, "no_speech_prob": 2.769394086499233e-06}, {"id": 674, "seek": 316136, "start": 3169.6, "end": 3171.2400000000002, "text": " so in our", "tokens": [370, 294, 527], "temperature": 0.0, "avg_logprob": -0.23636621417421283, "compression_ratio": 1.9049773755656108, "no_speech_prob": 2.769394086499233e-06}, {"id": 675, "seek": 316136, "start": 3171.2400000000002, "end": 3177.0, "text": " Forward then we can just go ahead and call the forward paths of our model", "tokens": [35524, 550, 321, 393, 445, 352, 2286, 293, 818, 264, 2128, 14518, 295, 527, 2316], "temperature": 0.0, "avg_logprob": -0.23636621417421283, "compression_ratio": 1.9049773755656108, "no_speech_prob": 2.769394086499233e-06}, {"id": 676, "seek": 316136, "start": 3177.8, "end": 3181.2400000000002, "text": " With the target so the target is the high res image we're trying to create", "tokens": [2022, 264, 3779, 370, 264, 3779, 307, 264, 1090, 725, 3256, 321, 434, 1382, 281, 1884], "temperature": 0.0, "avg_logprob": -0.23636621417421283, "compression_ratio": 1.9049773755656108, "no_speech_prob": 2.769394086499233e-06}, {"id": 677, "seek": 316136, "start": 3181.6, "end": 3187.6800000000003, "text": " right and so the reason we do that is because that's going to then call that hook function and store in", "tokens": [558, 293, 370, 264, 1778, 321, 360, 300, 307, 570, 300, 311, 516, 281, 550, 818, 300, 6328, 2445, 293, 3531, 294], "temperature": 0.0, "avg_logprob": -0.23636621417421283, "compression_ratio": 1.9049773755656108, "no_speech_prob": 2.769394086499233e-06}, {"id": 678, "seek": 318768, "start": 3187.68, "end": 3190.7599999999998, "text": " self dot save features the", "tokens": [2698, 5893, 3155, 4122, 264], "temperature": 0.0, "avg_logprob": -0.22232837121463517, "compression_ratio": 1.74235807860262, "no_speech_prob": 1.7603396145204897e-06}, {"id": 679, "seek": 318768, "start": 3192.12, "end": 3195.7599999999998, "text": " Activations we want right now. We're going to need to do that for our", "tokens": [28550, 763, 321, 528, 558, 586, 13, 492, 434, 516, 281, 643, 281, 360, 300, 337, 527], "temperature": 0.0, "avg_logprob": -0.22232837121463517, "compression_ratio": 1.74235807860262, "no_speech_prob": 1.7603396145204897e-06}, {"id": 680, "seek": 318768, "start": 3197.7999999999997, "end": 3199.68, "text": " Confinet output as well", "tokens": [11701, 21370, 5598, 382, 731], "temperature": 0.0, "avg_logprob": -0.22232837121463517, "compression_ratio": 1.74235807860262, "no_speech_prob": 1.7603396145204897e-06}, {"id": 681, "seek": 318768, "start": 3199.68, "end": 3206.2, "text": " Right so we need to clone these because otherwise the confinet output is going to go ahead and just plobber what we already had", "tokens": [1779, 370, 321, 643, 281, 26506, 613, 570, 5911, 264, 1497, 21370, 5598, 307, 516, 281, 352, 2286, 293, 445, 499, 996, 607, 437, 321, 1217, 632], "temperature": 0.0, "avg_logprob": -0.22232837121463517, "compression_ratio": 1.74235807860262, "no_speech_prob": 1.7603396145204897e-06}, {"id": 682, "seek": 318768, "start": 3207.12, "end": 3212.52, "text": " Okay, so now we can do the same thing for the confinet output which is the input to the loss function", "tokens": [1033, 11, 370, 586, 321, 393, 360, 264, 912, 551, 337, 264, 1497, 21370, 5598, 597, 307, 264, 4846, 281, 264, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.22232837121463517, "compression_ratio": 1.74235807860262, "no_speech_prob": 1.7603396145204897e-06}, {"id": 683, "seek": 318768, "start": 3213.16, "end": 3215.68, "text": " All right, and so now we've got those two things", "tokens": [1057, 558, 11, 293, 370, 586, 321, 600, 658, 729, 732, 721], "temperature": 0.0, "avg_logprob": -0.22232837121463517, "compression_ratio": 1.74235807860262, "no_speech_prob": 1.7603396145204897e-06}, {"id": 684, "seek": 321568, "start": 3215.68, "end": 3219.12, "text": " We can zip them all together along with the weights", "tokens": [492, 393, 20730, 552, 439, 1214, 2051, 365, 264, 17443], "temperature": 0.0, "avg_logprob": -0.1828559625928647, "compression_ratio": 1.7404255319148936, "no_speech_prob": 6.9622224145859946e-06}, {"id": 685, "seek": 321568, "start": 3220.08, "end": 3227.08, "text": " So we've got inputs targets and weights, and then we can do the L1 loss between the inputs and the targets and multiply by the layer", "tokens": [407, 321, 600, 658, 15743, 12911, 293, 17443, 11, 293, 550, 321, 393, 360, 264, 441, 16, 4470, 1296, 264, 15743, 293, 264, 12911, 293, 12972, 538, 264, 4583], "temperature": 0.0, "avg_logprob": -0.1828559625928647, "compression_ratio": 1.7404255319148936, "no_speech_prob": 6.9622224145859946e-06}, {"id": 686, "seek": 321568, "start": 3227.08, "end": 3228.3999999999996, "text": " weights", "tokens": [17443], "temperature": 0.0, "avg_logprob": -0.1828559625928647, "compression_ratio": 1.7404255319148936, "no_speech_prob": 6.9622224145859946e-06}, {"id": 687, "seek": 321568, "start": 3228.3999999999996, "end": 3231.64, "text": " the only other thing I do is I also grab the", "tokens": [264, 787, 661, 551, 286, 360, 307, 286, 611, 4444, 264], "temperature": 0.0, "avg_logprob": -0.1828559625928647, "compression_ratio": 1.7404255319148936, "no_speech_prob": 6.9622224145859946e-06}, {"id": 688, "seek": 321568, "start": 3232.6, "end": 3238.58, "text": " Pixel loss right, but I weight it down quite a bit right and most people don't do this", "tokens": [28323, 4470, 558, 11, 457, 286, 3364, 309, 760, 1596, 257, 857, 558, 293, 881, 561, 500, 380, 360, 341], "temperature": 0.0, "avg_logprob": -0.1828559625928647, "compression_ratio": 1.7404255319148936, "no_speech_prob": 6.9622224145859946e-06}, {"id": 689, "seek": 321568, "start": 3238.58, "end": 3240.72, "text": " I haven't seen papers that do this, but in my opinion", "tokens": [286, 2378, 380, 1612, 10577, 300, 360, 341, 11, 457, 294, 452, 4800], "temperature": 0.0, "avg_logprob": -0.1828559625928647, "compression_ratio": 1.7404255319148936, "no_speech_prob": 6.9622224145859946e-06}, {"id": 690, "seek": 321568, "start": 3241.64, "end": 3243.64, "text": " It's maybe a little bit better", "tokens": [467, 311, 1310, 257, 707, 857, 1101], "temperature": 0.0, "avg_logprob": -0.1828559625928647, "compression_ratio": 1.7404255319148936, "no_speech_prob": 6.9622224145859946e-06}, {"id": 691, "seek": 324364, "start": 3243.64, "end": 3245.64, "text": " Because you've got you know", "tokens": [1436, 291, 600, 658, 291, 458], "temperature": 0.0, "avg_logprob": -0.22681650362516703, "compression_ratio": 1.4974874371859297, "no_speech_prob": 3.0894730116415303e-06}, {"id": 692, "seek": 324364, "start": 3245.7599999999998, "end": 3253.7599999999998, "text": " The perceptual content loss activation stuff, but you know at the really finest level it also cares about the individual", "tokens": [440, 43276, 901, 2701, 4470, 24433, 1507, 11, 457, 291, 458, 412, 264, 534, 28141, 1496, 309, 611, 12310, 466, 264, 2609], "temperature": 0.0, "avg_logprob": -0.22681650362516703, "compression_ratio": 1.4974874371859297, "no_speech_prob": 3.0894730116415303e-06}, {"id": 693, "seek": 324364, "start": 3254.4, "end": 3256.4, "text": " pixels", "tokens": [18668], "temperature": 0.0, "avg_logprob": -0.22681650362516703, "compression_ratio": 1.4974874371859297, "no_speech_prob": 3.0894730116415303e-06}, {"id": 694, "seek": 324364, "start": 3257.8399999999997, "end": 3264.92, "text": " Okay, so that's our loss function we create our super resolution resnet telling it how much to scale up by", "tokens": [1033, 11, 370, 300, 311, 527, 4470, 2445, 321, 1884, 527, 1687, 8669, 725, 7129, 3585, 309, 577, 709, 281, 4373, 493, 538], "temperature": 0.0, "avg_logprob": -0.22681650362516703, "compression_ratio": 1.4974874371859297, "no_speech_prob": 3.0894730116415303e-06}, {"id": 695, "seek": 324364, "start": 3266.04, "end": 3267.7999999999997, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.22681650362516703, "compression_ratio": 1.4974874371859297, "no_speech_prob": 3.0894730116415303e-06}, {"id": 696, "seek": 326780, "start": 3267.8, "end": 3274.2000000000003, "text": " Then we're going to do our ICNR initialization", "tokens": [1396, 321, 434, 516, 281, 360, 527, 14360, 45, 49, 5883, 2144], "temperature": 0.0, "avg_logprob": -0.2029351197279893, "compression_ratio": 1.47979797979798, "no_speech_prob": 1.5056975826155394e-06}, {"id": 697, "seek": 326780, "start": 3274.4, "end": 3276.4, "text": " Of that pixel shuffle", "tokens": [2720, 300, 19261, 39426], "temperature": 0.0, "avg_logprob": -0.2029351197279893, "compression_ratio": 1.47979797979798, "no_speech_prob": 1.5056975826155394e-06}, {"id": 698, "seek": 326780, "start": 3277.1600000000003, "end": 3284.52, "text": " Convolution right so there's really like it. This is very very boring code. I actually stole it from from somebody else", "tokens": [2656, 85, 3386, 558, 370, 456, 311, 534, 411, 309, 13, 639, 307, 588, 588, 9989, 3089, 13, 286, 767, 16326, 309, 490, 490, 2618, 1646], "temperature": 0.0, "avg_logprob": -0.2029351197279893, "compression_ratio": 1.47979797979798, "no_speech_prob": 1.5056975826155394e-06}, {"id": 699, "seek": 326780, "start": 3285.88, "end": 3291.48, "text": " Like literally all it does is just say okay. You've got some weight tensor X", "tokens": [1743, 3736, 439, 309, 775, 307, 445, 584, 1392, 13, 509, 600, 658, 512, 3364, 40863, 1783], "temperature": 0.0, "avg_logprob": -0.2029351197279893, "compression_ratio": 1.47979797979798, "no_speech_prob": 1.5056975826155394e-06}, {"id": 700, "seek": 326780, "start": 3292.52, "end": 3294.52, "text": " That you want to initialize", "tokens": [663, 291, 528, 281, 5883, 1125], "temperature": 0.0, "avg_logprob": -0.2029351197279893, "compression_ratio": 1.47979797979798, "no_speech_prob": 1.5056975826155394e-06}, {"id": 701, "seek": 329452, "start": 3294.52, "end": 3297.6, "text": " So we're going to treat it as if it had", "tokens": [407, 321, 434, 516, 281, 2387, 309, 382, 498, 309, 632], "temperature": 0.0, "avg_logprob": -0.18603607980828535, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8130057216912974e-06}, {"id": 702, "seek": 329452, "start": 3298.28, "end": 3301.48, "text": " shape divided by so number of features divided by", "tokens": [3909, 6666, 538, 370, 1230, 295, 4122, 6666, 538], "temperature": 0.0, "avg_logprob": -0.18603607980828535, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8130057216912974e-06}, {"id": 703, "seek": 329452, "start": 3302.32, "end": 3304.12, "text": " scale squared", "tokens": [4373, 8889], "temperature": 0.0, "avg_logprob": -0.18603607980828535, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8130057216912974e-06}, {"id": 704, "seek": 329452, "start": 3304.12, "end": 3306.4, "text": " features in practice so like you know", "tokens": [4122, 294, 3124, 370, 411, 291, 458], "temperature": 0.0, "avg_logprob": -0.18603607980828535, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8130057216912974e-06}, {"id": 705, "seek": 329452, "start": 3307.64, "end": 3312.08, "text": " This might be two squared before because we actually want to copy", "tokens": [639, 1062, 312, 732, 8889, 949, 570, 321, 767, 528, 281, 5055], "temperature": 0.0, "avg_logprob": -0.18603607980828535, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8130057216912974e-06}, {"id": 706, "seek": 329452, "start": 3312.08, "end": 3316.24, "text": " You know we want to just keep one set of them and then copy them four times", "tokens": [509, 458, 321, 528, 281, 445, 1066, 472, 992, 295, 552, 293, 550, 5055, 552, 1451, 1413], "temperature": 0.0, "avg_logprob": -0.18603607980828535, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8130057216912974e-06}, {"id": 707, "seek": 329452, "start": 3316.52, "end": 3323.24, "text": " So we divide it by four and we create something of that size and we initialize that with by default", "tokens": [407, 321, 9845, 309, 538, 1451, 293, 321, 1884, 746, 295, 300, 2744, 293, 321, 5883, 1125, 300, 365, 538, 7576], "temperature": 0.0, "avg_logprob": -0.18603607980828535, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8130057216912974e-06}, {"id": 708, "seek": 332324, "start": 3323.24, "end": 3324.9599999999996, "text": " timing", "tokens": [10822], "temperature": 0.0, "avg_logprob": -0.23197320989660314, "compression_ratio": 1.5401069518716577, "no_speech_prob": 1.1365603995727724e-06}, {"id": 709, "seek": 332324, "start": 3324.9599999999996, "end": 3326.9599999999996, "text": " normal initialization and", "tokens": [2710, 5883, 2144, 293], "temperature": 0.0, "avg_logprob": -0.23197320989660314, "compression_ratio": 1.5401069518716577, "no_speech_prob": 1.1365603995727724e-06}, {"id": 710, "seek": 332324, "start": 3327.4799999999996, "end": 3329.68, "text": " Then we just make scale squared copies of it", "tokens": [1396, 321, 445, 652, 4373, 8889, 14341, 295, 309], "temperature": 0.0, "avg_logprob": -0.23197320989660314, "compression_ratio": 1.5401069518716577, "no_speech_prob": 1.1365603995727724e-06}, {"id": 711, "seek": 332324, "start": 3330.64, "end": 3332.64, "text": " Okay, and the rest of it's just", "tokens": [1033, 11, 293, 264, 1472, 295, 309, 311, 445], "temperature": 0.0, "avg_logprob": -0.23197320989660314, "compression_ratio": 1.5401069518716577, "no_speech_prob": 1.1365603995727724e-06}, {"id": 712, "seek": 332324, "start": 3332.9199999999996, "end": 3337.72, "text": " Kind of moving axes around a little bit alright, so that's going to return a new weight matrix", "tokens": [9242, 295, 2684, 35387, 926, 257, 707, 857, 5845, 11, 370, 300, 311, 516, 281, 2736, 257, 777, 3364, 8141], "temperature": 0.0, "avg_logprob": -0.23197320989660314, "compression_ratio": 1.5401069518716577, "no_speech_prob": 1.1365603995727724e-06}, {"id": 713, "seek": 332324, "start": 3338.52, "end": 3340.52, "text": " where each", "tokens": [689, 1184], "temperature": 0.0, "avg_logprob": -0.23197320989660314, "compression_ratio": 1.5401069518716577, "no_speech_prob": 1.1365603995727724e-06}, {"id": 714, "seek": 332324, "start": 3341.6, "end": 3347.3599999999997, "text": " Each initialized sub kernel is repeated r squared or scale squared times", "tokens": [6947, 5883, 1602, 1422, 28256, 307, 10477, 367, 8889, 420, 4373, 8889, 1413], "temperature": 0.0, "avg_logprob": -0.23197320989660314, "compression_ratio": 1.5401069518716577, "no_speech_prob": 1.1365603995727724e-06}, {"id": 715, "seek": 334736, "start": 3347.36, "end": 3353.44, "text": " So that details don't matter very much all that matters here is that I just looked through to find what was the actual", "tokens": [407, 300, 4365, 500, 380, 1871, 588, 709, 439, 300, 7001, 510, 307, 300, 286, 445, 2956, 807, 281, 915, 437, 390, 264, 3539], "temperature": 0.0, "avg_logprob": -0.45987852493135056, "compression_ratio": 1.6991150442477876, "no_speech_prob": 3.3931310099433176e-06}, {"id": 716, "seek": 334736, "start": 3354.1600000000003, "end": 3355.28, "text": " layer", "tokens": [4583], "temperature": 0.0, "avg_logprob": -0.45987852493135056, "compression_ratio": 1.6991150442477876, "no_speech_prob": 3.3931310099433176e-06}, {"id": 717, "seek": 334736, "start": 3355.28, "end": 3358.0, "text": " the conf layer just before the pixel shuffle and", "tokens": [264, 1497, 4583, 445, 949, 264, 19261, 39426, 293], "temperature": 0.0, "avg_logprob": -0.45987852493135056, "compression_ratio": 1.6991150442477876, "no_speech_prob": 3.3931310099433176e-06}, {"id": 718, "seek": 334736, "start": 3358.6400000000003, "end": 3362.88, "text": " Stored it away, and then I called IC and R on its weight matrix", "tokens": [745, 2769, 309, 1314, 11, 293, 550, 286, 1219, 14360, 293, 497, 322, 1080, 3364, 8141], "temperature": 0.0, "avg_logprob": -0.45987852493135056, "compression_ratio": 1.6991150442477876, "no_speech_prob": 3.3931310099433176e-06}, {"id": 719, "seek": 334736, "start": 3363.28, "end": 3368.56, "text": " To get my new weight matrix, and then I copied that new weight matrix back into that layer", "tokens": [1407, 483, 452, 777, 3364, 8141, 11, 293, 550, 286, 25365, 300, 777, 3364, 8141, 646, 666, 300, 4583], "temperature": 0.0, "avg_logprob": -0.45987852493135056, "compression_ratio": 1.6991150442477876, "no_speech_prob": 3.3931310099433176e-06}, {"id": 720, "seek": 334736, "start": 3369.28, "end": 3370.7200000000003, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.45987852493135056, "compression_ratio": 1.6991150442477876, "no_speech_prob": 3.3931310099433176e-06}, {"id": 721, "seek": 334736, "start": 3370.7200000000003, "end": 3373.76, "text": " so as you can see I", "tokens": [370, 382, 291, 393, 536, 286], "temperature": 0.0, "avg_logprob": -0.45987852493135056, "compression_ratio": 1.6991150442477876, "no_speech_prob": 3.3931310099433176e-06}, {"id": 722, "seek": 334736, "start": 3374.6400000000003, "end": 3376.6400000000003, "text": " Went to quite a bit of trouble", "tokens": [31809, 281, 1596, 257, 857, 295, 5253], "temperature": 0.0, "avg_logprob": -0.45987852493135056, "compression_ratio": 1.6991150442477876, "no_speech_prob": 3.3931310099433176e-06}, {"id": 723, "seek": 337664, "start": 3376.64, "end": 3383.06, "text": " I went to quite a lot of trouble in this exercise to really try to implement all the best practices", "tokens": [286, 1437, 281, 1596, 257, 688, 295, 5253, 294, 341, 5380, 281, 534, 853, 281, 4445, 439, 264, 1151, 7525], "temperature": 0.0, "avg_logprob": -0.15990284060643725, "compression_ratio": 1.778181818181818, "no_speech_prob": 4.0294366954185534e-06}, {"id": 724, "seek": 337664, "start": 3383.08, "end": 3387.8799999999997, "text": " Right and I kind of tend to do things a bit one extreme or the other I show you like a really hacky version", "tokens": [1779, 293, 286, 733, 295, 3928, 281, 360, 721, 257, 857, 472, 8084, 420, 264, 661, 286, 855, 291, 411, 257, 534, 10339, 88, 3037], "temperature": 0.0, "avg_logprob": -0.15990284060643725, "compression_ratio": 1.778181818181818, "no_speech_prob": 4.0294366954185534e-06}, {"id": 725, "seek": 337664, "start": 3387.8799999999997, "end": 3392.04, "text": " That only slightly works or I go to the nth degree to make it work really well right and", "tokens": [663, 787, 4748, 1985, 420, 286, 352, 281, 264, 297, 392, 4314, 281, 652, 309, 589, 534, 731, 558, 293], "temperature": 0.0, "avg_logprob": -0.15990284060643725, "compression_ratio": 1.778181818181818, "no_speech_prob": 4.0294366954185534e-06}, {"id": 726, "seek": 337664, "start": 3392.4, "end": 3396.44, "text": " So this is a version where I'm claiming that this is pretty much a state-of-the-art", "tokens": [407, 341, 307, 257, 3037, 689, 286, 478, 19232, 300, 341, 307, 1238, 709, 257, 1785, 12, 2670, 12, 3322, 12, 446], "temperature": 0.0, "avg_logprob": -0.15990284060643725, "compression_ratio": 1.778181818181818, "no_speech_prob": 4.0294366954185534e-06}, {"id": 727, "seek": 337664, "start": 3397.3199999999997, "end": 3402.8799999999997, "text": " Implementation it's a competition winning or at least my re-implementation of a competition winning approach", "tokens": [4331, 781, 19631, 309, 311, 257, 6211, 8224, 420, 412, 1935, 452, 319, 12, 332, 781, 19631, 295, 257, 6211, 8224, 3109], "temperature": 0.0, "avg_logprob": -0.15990284060643725, "compression_ratio": 1.778181818181818, "no_speech_prob": 4.0294366954185534e-06}, {"id": 728, "seek": 340288, "start": 3402.88, "end": 3408.36, "text": " And the reason I'm doing that is because I think like this is one of those rare papers where they actually", "tokens": [400, 264, 1778, 286, 478, 884, 300, 307, 570, 286, 519, 411, 341, 307, 472, 295, 729, 5892, 10577, 689, 436, 767], "temperature": 0.0, "avg_logprob": -0.1559443524009303, "compression_ratio": 1.6724137931034482, "no_speech_prob": 9.516175850876607e-06}, {"id": 729, "seek": 340288, "start": 3409.08, "end": 3412.12, "text": " Get a lot of the details right, and I kind of want you to get a feel of", "tokens": [3240, 257, 688, 295, 264, 4365, 558, 11, 293, 286, 733, 295, 528, 291, 281, 483, 257, 841, 295], "temperature": 0.0, "avg_logprob": -0.1559443524009303, "compression_ratio": 1.6724137931034482, "no_speech_prob": 9.516175850876607e-06}, {"id": 730, "seek": 340288, "start": 3412.88, "end": 3416.04, "text": " What does it feel like to get all the details right?", "tokens": [708, 775, 309, 841, 411, 281, 483, 439, 264, 4365, 558, 30], "temperature": 0.0, "avg_logprob": -0.1559443524009303, "compression_ratio": 1.6724137931034482, "no_speech_prob": 9.516175850876607e-06}, {"id": 731, "seek": 340288, "start": 3416.04, "end": 3422.52, "text": " And you know remember getting the details right is the difference between this hideous blurry mess", "tokens": [400, 291, 458, 1604, 1242, 264, 4365, 558, 307, 264, 2649, 1296, 341, 6479, 563, 37644, 2082], "temperature": 0.0, "avg_logprob": -0.1559443524009303, "compression_ratio": 1.6724137931034482, "no_speech_prob": 9.516175850876607e-06}, {"id": 732, "seek": 340288, "start": 3422.78, "end": 3425.96, "text": " You know and this really pretty exquisite result", "tokens": [509, 458, 293, 341, 534, 1238, 454, 34152, 1874], "temperature": 0.0, "avg_logprob": -0.1559443524009303, "compression_ratio": 1.6724137931034482, "no_speech_prob": 9.516175850876607e-06}, {"id": 733, "seek": 342596, "start": 3425.96, "end": 3431.16, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.29052553678813736, "compression_ratio": 1.4603174603174602, "no_speech_prob": 3.138097099508741e-06}, {"id": 734, "seek": 342596, "start": 3434.36, "end": 3436.96, "text": " So we're gonna have a to do data parallel on that again", "tokens": [407, 321, 434, 799, 362, 257, 281, 360, 1412, 8952, 322, 300, 797], "temperature": 0.0, "avg_logprob": -0.29052553678813736, "compression_ratio": 1.4603174603174602, "no_speech_prob": 3.138097099508741e-06}, {"id": 735, "seek": 342596, "start": 3437.52, "end": 3443.44, "text": " We're going to set our criterion to be feature loss using our VGG model grab the first few blocks", "tokens": [492, 434, 516, 281, 992, 527, 46691, 281, 312, 4111, 4470, 1228, 527, 691, 27561, 2316, 4444, 264, 700, 1326, 8474], "temperature": 0.0, "avg_logprob": -0.29052553678813736, "compression_ratio": 1.4603174603174602, "no_speech_prob": 3.138097099508741e-06}, {"id": 736, "seek": 342596, "start": 3443.44, "end": 3447.48, "text": " And these are a set of layer weights that I found worked pretty well", "tokens": [400, 613, 366, 257, 992, 295, 4583, 17443, 300, 286, 1352, 2732, 1238, 731], "temperature": 0.0, "avg_logprob": -0.29052553678813736, "compression_ratio": 1.4603174603174602, "no_speech_prob": 3.138097099508741e-06}, {"id": 737, "seek": 342596, "start": 3449.36, "end": 3451.36, "text": " Do a learning rate finder", "tokens": [1144, 257, 2539, 3314, 915, 260], "temperature": 0.0, "avg_logprob": -0.29052553678813736, "compression_ratio": 1.4603174603174602, "no_speech_prob": 3.138097099508741e-06}, {"id": 738, "seek": 342596, "start": 3451.56, "end": 3453.56, "text": " Fit it for a while", "tokens": [29263, 309, 337, 257, 1339], "temperature": 0.0, "avg_logprob": -0.29052553678813736, "compression_ratio": 1.4603174603174602, "no_speech_prob": 3.138097099508741e-06}, {"id": 739, "seek": 345356, "start": 3453.56, "end": 3458.24, "text": " And I feel it around for a little while trying to kind of get some of these details, right?", "tokens": [400, 286, 841, 309, 926, 337, 257, 707, 1339, 1382, 281, 733, 295, 483, 512, 295, 613, 4365, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2235797794385888, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.173886165721342e-06}, {"id": 740, "seek": 345356, "start": 3460.2, "end": 3463.4, "text": " But here's the my favorite part of the paper", "tokens": [583, 510, 311, 264, 452, 2954, 644, 295, 264, 3035], "temperature": 0.0, "avg_logprob": -0.2235797794385888, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.173886165721342e-06}, {"id": 741, "seek": 345356, "start": 3465.44, "end": 3468.54, "text": " Is what happens next now that we've done it for", "tokens": [1119, 437, 2314, 958, 586, 300, 321, 600, 1096, 309, 337], "temperature": 0.0, "avg_logprob": -0.2235797794385888, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.173886165721342e-06}, {"id": 742, "seek": 345356, "start": 3470.36, "end": 3472.36, "text": " Scale equals to", "tokens": [42999, 6915, 281], "temperature": 0.0, "avg_logprob": -0.2235797794385888, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.173886165721342e-06}, {"id": 743, "seek": 345356, "start": 3472.7999999999997, "end": 3474.48, "text": " progressive resizing", "tokens": [16131, 725, 3319], "temperature": 0.0, "avg_logprob": -0.2235797794385888, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.173886165721342e-06}, {"id": 744, "seek": 345356, "start": 3474.48, "end": 3482.12, "text": " Alright, so progressive resizing is the trick that let us get the best single computer result for image net training on Dawn bench", "tokens": [2798, 11, 370, 16131, 725, 3319, 307, 264, 4282, 300, 718, 505, 483, 264, 1151, 2167, 3820, 1874, 337, 3256, 2533, 3097, 322, 26001, 10638], "temperature": 0.0, "avg_logprob": -0.2235797794385888, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.173886165721342e-06}, {"id": 745, "seek": 348212, "start": 3482.12, "end": 3485.2799999999997, "text": " So this idea is starting small gradually making bigger", "tokens": [407, 341, 1558, 307, 2891, 1359, 13145, 1455, 3801], "temperature": 0.0, "avg_logprob": -0.2019909449986049, "compression_ratio": 1.6506550218340612, "no_speech_prob": 5.014695034333272e-06}, {"id": 746, "seek": 348212, "start": 3485.2799999999997, "end": 3492.44, "text": " I only know of two papers that have used this idea one is the progressive resizing of GANs paper", "tokens": [286, 787, 458, 295, 732, 10577, 300, 362, 1143, 341, 1558, 472, 307, 264, 16131, 725, 3319, 295, 460, 1770, 82, 3035], "temperature": 0.0, "avg_logprob": -0.2019909449986049, "compression_ratio": 1.6506550218340612, "no_speech_prob": 5.014695034333272e-06}, {"id": 747, "seek": 348212, "start": 3492.44, "end": 3496.62, "text": " Which allows training of very high resolution GANs and the other one?", "tokens": [3013, 4045, 3097, 295, 588, 1090, 8669, 460, 1770, 82, 293, 264, 661, 472, 30], "temperature": 0.0, "avg_logprob": -0.2019909449986049, "compression_ratio": 1.6506550218340612, "no_speech_prob": 5.014695034333272e-06}, {"id": 748, "seek": 348212, "start": 3497.3599999999997, "end": 3504.3599999999997, "text": " Is the EDSR paper and the cool thing about progressive resizing is not only are your", "tokens": [1119, 264, 462, 11844, 49, 3035, 293, 264, 1627, 551, 466, 16131, 725, 3319, 307, 406, 787, 366, 428], "temperature": 0.0, "avg_logprob": -0.2019909449986049, "compression_ratio": 1.6506550218340612, "no_speech_prob": 5.014695034333272e-06}, {"id": 749, "seek": 348212, "start": 3505.0, "end": 3509.68, "text": " Earlier epochs assuming you've got two by two smaller four times faster", "tokens": [24552, 30992, 28346, 11926, 291, 600, 658, 732, 538, 732, 4356, 1451, 1413, 4663], "temperature": 0.0, "avg_logprob": -0.2019909449986049, "compression_ratio": 1.6506550218340612, "no_speech_prob": 5.014695034333272e-06}, {"id": 750, "seek": 350968, "start": 3509.68, "end": 3514.16, "text": " You can also make the batch size maybe three or four times bigger", "tokens": [509, 393, 611, 652, 264, 15245, 2744, 1310, 1045, 420, 1451, 1413, 3801], "temperature": 0.0, "avg_logprob": -0.1972992865593879, "compression_ratio": 1.606837606837607, "no_speech_prob": 1.9947162854805356e-06}, {"id": 751, "seek": 350968, "start": 3514.7599999999998, "end": 3521.7999999999997, "text": " But more importantly, they're going to generalize better because you're feeding your model different size images", "tokens": [583, 544, 8906, 11, 436, 434, 516, 281, 2674, 1125, 1101, 570, 291, 434, 12919, 428, 2316, 819, 2744, 5267], "temperature": 0.0, "avg_logprob": -0.1972992865593879, "compression_ratio": 1.606837606837607, "no_speech_prob": 1.9947162854805356e-06}, {"id": 752, "seek": 350968, "start": 3522.24, "end": 3523.48, "text": " during training", "tokens": [1830, 3097], "temperature": 0.0, "avg_logprob": -0.1972992865593879, "compression_ratio": 1.606837606837607, "no_speech_prob": 1.9947162854805356e-06}, {"id": 753, "seek": 350968, "start": 3523.48, "end": 3524.6, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.1972992865593879, "compression_ratio": 1.606837606837607, "no_speech_prob": 1.9947162854805356e-06}, {"id": 754, "seek": 350968, "start": 3524.6, "end": 3527.62, "text": " So we were able to train like half as many epochs", "tokens": [407, 321, 645, 1075, 281, 3847, 411, 1922, 382, 867, 30992, 28346], "temperature": 0.0, "avg_logprob": -0.1972992865593879, "compression_ratio": 1.606837606837607, "no_speech_prob": 1.9947162854805356e-06}, {"id": 755, "seek": 350968, "start": 3528.48, "end": 3533.64, "text": " For image net as most people so our epochs were faster and there were fewer of them", "tokens": [1171, 3256, 2533, 382, 881, 561, 370, 527, 30992, 28346, 645, 4663, 293, 456, 645, 13366, 295, 552], "temperature": 0.0, "avg_logprob": -0.1972992865593879, "compression_ratio": 1.606837606837607, "no_speech_prob": 1.9947162854805356e-06}, {"id": 756, "seek": 350968, "start": 3534.24, "end": 3536.3599999999997, "text": " So progressive resizing is something", "tokens": [407, 16131, 725, 3319, 307, 746], "temperature": 0.0, "avg_logprob": -0.1972992865593879, "compression_ratio": 1.606837606837607, "no_speech_prob": 1.9947162854805356e-06}, {"id": 757, "seek": 350968, "start": 3537.08, "end": 3538.7599999999998, "text": " that", "tokens": [300], "temperature": 0.0, "avg_logprob": -0.1972992865593879, "compression_ratio": 1.606837606837607, "no_speech_prob": 1.9947162854805356e-06}, {"id": 758, "seek": 353876, "start": 3538.76, "end": 3541.2400000000002, "text": " You know, particularly if you're training from scratch", "tokens": [509, 458, 11, 4098, 498, 291, 434, 3097, 490, 8459], "temperature": 0.0, "avg_logprob": -0.16031754691645783, "compression_ratio": 1.654320987654321, "no_speech_prob": 5.955066171736689e-06}, {"id": 759, "seek": 353876, "start": 3541.2400000000002, "end": 3545.28, "text": " I'm not so sure if it's useful for fine-tuning transfer learning, but if you're training from scratch", "tokens": [286, 478, 406, 370, 988, 498, 309, 311, 4420, 337, 2489, 12, 83, 37726, 5003, 2539, 11, 457, 498, 291, 434, 3097, 490, 8459], "temperature": 0.0, "avg_logprob": -0.16031754691645783, "compression_ratio": 1.654320987654321, "no_speech_prob": 5.955066171736689e-06}, {"id": 760, "seek": 353876, "start": 3545.28, "end": 3547.28, "text": " You probably want to do nearly all the time", "tokens": [509, 1391, 528, 281, 360, 6217, 439, 264, 565], "temperature": 0.0, "avg_logprob": -0.16031754691645783, "compression_ratio": 1.654320987654321, "no_speech_prob": 5.955066171736689e-06}, {"id": 761, "seek": 353876, "start": 3548.32, "end": 3550.5400000000004, "text": " So the next step is to go all the way back to the top", "tokens": [407, 264, 958, 1823, 307, 281, 352, 439, 264, 636, 646, 281, 264, 1192], "temperature": 0.0, "avg_logprob": -0.16031754691645783, "compression_ratio": 1.654320987654321, "no_speech_prob": 5.955066171736689e-06}, {"id": 762, "seek": 353876, "start": 3551.2400000000002, "end": 3553.6600000000003, "text": " right and change to", "tokens": [558, 293, 1319, 281], "temperature": 0.0, "avg_logprob": -0.16031754691645783, "compression_ratio": 1.654320987654321, "no_speech_prob": 5.955066171736689e-06}, {"id": 763, "seek": 353876, "start": 3554.5600000000004, "end": 3556.5600000000004, "text": " For scale 32 batch size", "tokens": [1171, 4373, 8858, 15245, 2744], "temperature": 0.0, "avg_logprob": -0.16031754691645783, "compression_ratio": 1.654320987654321, "no_speech_prob": 5.955066171736689e-06}, {"id": 764, "seek": 353876, "start": 3557.5600000000004, "end": 3562.92, "text": " Right like restart so I saved the model before I do that go back and that's why there's a little bit of", "tokens": [1779, 411, 21022, 370, 286, 6624, 264, 2316, 949, 286, 360, 300, 352, 646, 293, 300, 311, 983, 456, 311, 257, 707, 857, 295], "temperature": 0.0, "avg_logprob": -0.16031754691645783, "compression_ratio": 1.654320987654321, "no_speech_prob": 5.955066171736689e-06}, {"id": 765, "seek": 356292, "start": 3562.92, "end": 3569.92, "text": " Fussing around in here with reloading because what I needed to do now is I needed to load my saved model back in", "tokens": [479, 2023, 278, 926, 294, 510, 365, 25628, 278, 570, 437, 286, 2978, 281, 360, 586, 307, 286, 2978, 281, 3677, 452, 6624, 2316, 646, 294], "temperature": 0.0, "avg_logprob": -0.40114579717796967, "compression_ratio": 1.578125, "no_speech_prob": 4.637818165065255e-06}, {"id": 766, "seek": 356292, "start": 3569.92, "end": 3572.7200000000003, "text": " But there's a slight issue", "tokens": [583, 456, 311, 257, 4036, 2734], "temperature": 0.0, "avg_logprob": -0.40114579717796967, "compression_ratio": 1.578125, "no_speech_prob": 4.637818165065255e-06}, {"id": 767, "seek": 356292, "start": 3573.2400000000002, "end": 3580.2400000000002, "text": " Which is I now have one more up sampling layer than I used to have to go from two by two to four by four", "tokens": [3013, 307, 286, 586, 362, 472, 544, 493, 21179, 4583, 813, 286, 1143, 281, 362, 281, 352, 490, 732, 538, 732, 281, 1451, 538, 1451], "temperature": 0.0, "avg_logprob": -0.40114579717796967, "compression_ratio": 1.578125, "no_speech_prob": 4.637818165065255e-06}, {"id": 768, "seek": 356292, "start": 3580.84, "end": 3582.84, "text": " my little", "tokens": [452, 707], "temperature": 0.0, "avg_logprob": -0.40114579717796967, "compression_ratio": 1.578125, "no_speech_prob": 4.637818165065255e-06}, {"id": 769, "seek": 356292, "start": 3585.7200000000003, "end": 3587.7200000000003, "text": " My little loop here is", "tokens": [1222, 707, 6367, 510, 307], "temperature": 0.0, "avg_logprob": -0.40114579717796967, "compression_ratio": 1.578125, "no_speech_prob": 4.637818165065255e-06}, {"id": 770, "seek": 356292, "start": 3588.2000000000003, "end": 3590.2000000000003, "text": " Now looping through twice", "tokens": [823, 6367, 278, 807, 6091], "temperature": 0.0, "avg_logprob": -0.40114579717796967, "compression_ratio": 1.578125, "no_speech_prob": 4.637818165065255e-06}, {"id": 771, "seek": 359020, "start": 3590.2, "end": 3597.3599999999997, "text": " Is now looping through twice not once and therefore it's added an extra con but an extra pixel shuffle", "tokens": [1119, 586, 6367, 278, 807, 6091, 406, 1564, 293, 4412, 309, 311, 3869, 364, 2857, 416, 457, 364, 2857, 19261, 39426], "temperature": 0.0, "avg_logprob": -0.2491557980761116, "compression_ratio": 1.634517766497462, "no_speech_prob": 3.726616341737099e-06}, {"id": 772, "seek": 359020, "start": 3597.72, "end": 3602.8799999999997, "text": " so how am I going to load in weights through a different network and", "tokens": [370, 577, 669, 286, 516, 281, 3677, 294, 17443, 807, 257, 819, 3209, 293], "temperature": 0.0, "avg_logprob": -0.2491557980761116, "compression_ratio": 1.634517766497462, "no_speech_prob": 3.726616341737099e-06}, {"id": 773, "seek": 359020, "start": 3603.56, "end": 3611.3199999999997, "text": " The answer is that I use a very handy thing in pytorch, which is if I call that this is what this is", "tokens": [440, 1867, 307, 300, 286, 764, 257, 588, 13239, 551, 294, 25878, 284, 339, 11, 597, 307, 498, 286, 818, 300, 341, 307, 437, 341, 307], "temperature": 0.0, "avg_logprob": -0.2491557980761116, "compression_ratio": 1.634517766497462, "no_speech_prob": 3.726616341737099e-06}, {"id": 774, "seek": 359020, "start": 3612.24, "end": 3613.9199999999996, "text": " basically what", "tokens": [1936, 437], "temperature": 0.0, "avg_logprob": -0.2491557980761116, "compression_ratio": 1.634517766497462, "no_speech_prob": 3.726616341737099e-06}, {"id": 775, "seek": 359020, "start": 3613.9199999999996, "end": 3616.4399999999996, "text": " Learn load calls behind the scenes", "tokens": [17216, 3677, 5498, 2261, 264, 8026], "temperature": 0.0, "avg_logprob": -0.2491557980761116, "compression_ratio": 1.634517766497462, "no_speech_prob": 3.726616341737099e-06}, {"id": 776, "seek": 361644, "start": 3616.44, "end": 3621.28, "text": " Load state dict if I pass this parameter strict equals false", "tokens": [48408, 1785, 12569, 498, 286, 1320, 341, 13075, 10910, 6915, 7908], "temperature": 0.0, "avg_logprob": -0.22017881185701577, "compression_ratio": 1.8310502283105023, "no_speech_prob": 2.9944246762170224e-06}, {"id": 777, "seek": 361644, "start": 3622.2400000000002, "end": 3625.4, "text": " If I pass in this parameter strict equals false", "tokens": [759, 286, 1320, 294, 341, 13075, 10910, 6915, 7908], "temperature": 0.0, "avg_logprob": -0.22017881185701577, "compression_ratio": 1.8310502283105023, "no_speech_prob": 2.9944246762170224e-06}, {"id": 778, "seek": 361644, "start": 3626.32, "end": 3628.44, "text": " Then it says okay if you can't", "tokens": [1396, 309, 1619, 1392, 498, 291, 393, 380], "temperature": 0.0, "avg_logprob": -0.22017881185701577, "compression_ratio": 1.8310502283105023, "no_speech_prob": 2.9944246762170224e-06}, {"id": 779, "seek": 361644, "start": 3629.56, "end": 3632.92, "text": " Fill in all of the layers just fill in the layers you can", "tokens": [25315, 294, 439, 295, 264, 7914, 445, 2836, 294, 264, 7914, 291, 393], "temperature": 0.0, "avg_logprob": -0.22017881185701577, "compression_ratio": 1.8310502283105023, "no_speech_prob": 2.9944246762170224e-06}, {"id": 780, "seek": 361644, "start": 3634.12, "end": 3636.8, "text": " So after loading the model back in this way", "tokens": [407, 934, 15114, 264, 2316, 646, 294, 341, 636], "temperature": 0.0, "avg_logprob": -0.22017881185701577, "compression_ratio": 1.8310502283105023, "no_speech_prob": 2.9944246762170224e-06}, {"id": 781, "seek": 361644, "start": 3637.16, "end": 3642.88, "text": " We're going to end up with something where it's loaded in all the layers that it can and the that one comb layer", "tokens": [492, 434, 516, 281, 917, 493, 365, 746, 689, 309, 311, 13210, 294, 439, 264, 7914, 300, 309, 393, 293, 264, 300, 472, 2512, 4583], "temperature": 0.0, "avg_logprob": -0.22017881185701577, "compression_ratio": 1.8310502283105023, "no_speech_prob": 2.9944246762170224e-06}, {"id": 782, "seek": 361644, "start": 3642.96, "end": 3645.62, "text": " That's new is going to be randomly initialized", "tokens": [663, 311, 777, 307, 516, 281, 312, 16979, 5883, 1602], "temperature": 0.0, "avg_logprob": -0.22017881185701577, "compression_ratio": 1.8310502283105023, "no_speech_prob": 2.9944246762170224e-06}, {"id": 783, "seek": 364562, "start": 3645.62, "end": 3647.62, "text": " right and so then I", "tokens": [558, 293, 370, 550, 286], "temperature": 0.0, "avg_logprob": -0.22946636328536474, "compression_ratio": 1.5763546798029557, "no_speech_prob": 1.4593737205359503e-06}, {"id": 784, "seek": 364562, "start": 3648.62, "end": 3653.9, "text": " Freeze all my layers and then unfreeze that up sampling part", "tokens": [48096, 439, 452, 7914, 293, 550, 3971, 701, 1381, 300, 493, 21179, 644], "temperature": 0.0, "avg_logprob": -0.22946636328536474, "compression_ratio": 1.5763546798029557, "no_speech_prob": 1.4593737205359503e-06}, {"id": 785, "seek": 364562, "start": 3654.62, "end": 3659.42, "text": " Right and then use ICNR on my newly added", "tokens": [1779, 293, 550, 764, 14360, 45, 49, 322, 452, 15109, 3869], "temperature": 0.0, "avg_logprob": -0.22946636328536474, "compression_ratio": 1.5763546798029557, "no_speech_prob": 1.4593737205359503e-06}, {"id": 786, "seek": 364562, "start": 3660.5, "end": 3661.94, "text": " extra layer", "tokens": [2857, 4583], "temperature": 0.0, "avg_logprob": -0.22946636328536474, "compression_ratio": 1.5763546798029557, "no_speech_prob": 1.4593737205359503e-06}, {"id": 787, "seek": 364562, "start": 3661.94, "end": 3664.06, "text": " Right and then I can go ahead and learn again", "tokens": [1779, 293, 550, 286, 393, 352, 2286, 293, 1466, 797], "temperature": 0.0, "avg_logprob": -0.22946636328536474, "compression_ratio": 1.5763546798029557, "no_speech_prob": 1.4593737205359503e-06}, {"id": 788, "seek": 364562, "start": 3666.2599999999998, "end": 3672.2599999999998, "text": " And so then the rest is the same so if you're trying to replicate this don't just run this top to bottom", "tokens": [400, 370, 550, 264, 1472, 307, 264, 912, 370, 498, 291, 434, 1382, 281, 25356, 341, 500, 380, 445, 1190, 341, 1192, 281, 2767], "temperature": 0.0, "avg_logprob": -0.22946636328536474, "compression_ratio": 1.5763546798029557, "no_speech_prob": 1.4593737205359503e-06}, {"id": 789, "seek": 364562, "start": 3672.38, "end": 3674.38, "text": " Okay, realize it involves a bit of", "tokens": [1033, 11, 4325, 309, 11626, 257, 857, 295], "temperature": 0.0, "avg_logprob": -0.22946636328536474, "compression_ratio": 1.5763546798029557, "no_speech_prob": 1.4593737205359503e-06}, {"id": 790, "seek": 367438, "start": 3674.38, "end": 3676.38, "text": " jumping around", "tokens": [11233, 926], "temperature": 0.0, "avg_logprob": -0.19481153073518173, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8162186279369052e-06}, {"id": 791, "seek": 367438, "start": 3677.7400000000002, "end": 3679.7400000000002, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.19481153073518173, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8162186279369052e-06}, {"id": 792, "seek": 367438, "start": 3680.6600000000003, "end": 3683.42, "text": " Yeah, the longer you train the better it gets I", "tokens": [865, 11, 264, 2854, 291, 3847, 264, 1101, 309, 2170, 286], "temperature": 0.0, "avg_logprob": -0.19481153073518173, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8162186279369052e-06}, {"id": 793, "seek": 367438, "start": 3684.3, "end": 3687.5, "text": " Ended up training it for about 10 hours, but you'll still get very good results", "tokens": [6967, 292, 493, 3097, 309, 337, 466, 1266, 2496, 11, 457, 291, 603, 920, 483, 588, 665, 3542], "temperature": 0.0, "avg_logprob": -0.19481153073518173, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8162186279369052e-06}, {"id": 794, "seek": 367438, "start": 3688.1, "end": 3690.58, "text": " Much more quickly if you're less patient", "tokens": [12313, 544, 2661, 498, 291, 434, 1570, 4537], "temperature": 0.0, "avg_logprob": -0.19481153073518173, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8162186279369052e-06}, {"id": 795, "seek": 367438, "start": 3691.42, "end": 3697.98, "text": " And so we can try it out and here is the result here is my pixelated bird and look here", "tokens": [400, 370, 321, 393, 853, 309, 484, 293, 510, 307, 264, 1874, 510, 307, 452, 19261, 770, 5255, 293, 574, 510], "temperature": 0.0, "avg_logprob": -0.19481153073518173, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8162186279369052e-06}, {"id": 796, "seek": 367438, "start": 3697.98, "end": 3702.42, "text": " It's like totally random e pixels and here's the up sampled version", "tokens": [467, 311, 411, 3879, 4974, 308, 18668, 293, 510, 311, 264, 493, 3247, 15551, 3037], "temperature": 0.0, "avg_logprob": -0.19481153073518173, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8162186279369052e-06}, {"id": 797, "seek": 370242, "start": 3702.42, "end": 3704.7000000000003, "text": " It's like it's literally", "tokens": [467, 311, 411, 309, 311, 3736], "temperature": 0.0, "avg_logprob": -0.21886991144536616, "compression_ratio": 1.6790697674418604, "no_speech_prob": 7.811465252416383e-07}, {"id": 798, "seek": 370242, "start": 3705.7400000000002, "end": 3707.14, "text": " invented", "tokens": [14479], "temperature": 0.0, "avg_logprob": -0.21886991144536616, "compression_ratio": 1.6790697674418604, "no_speech_prob": 7.811465252416383e-07}, {"id": 799, "seek": 370242, "start": 3707.14, "end": 3711.7400000000002, "text": " Color at coloration, but it figured out what kind of bird it is", "tokens": [10458, 412, 2017, 399, 11, 457, 309, 8932, 484, 437, 733, 295, 5255, 309, 307], "temperature": 0.0, "avg_logprob": -0.21886991144536616, "compression_ratio": 1.6790697674418604, "no_speech_prob": 7.811465252416383e-07}, {"id": 800, "seek": 370242, "start": 3712.5, "end": 3716.06, "text": " right and it knows what these feathers are meant to look like and", "tokens": [558, 293, 309, 3255, 437, 613, 27044, 366, 4140, 281, 574, 411, 293], "temperature": 0.0, "avg_logprob": -0.21886991144536616, "compression_ratio": 1.6790697674418604, "no_speech_prob": 7.811465252416383e-07}, {"id": 801, "seek": 370242, "start": 3716.46, "end": 3722.1800000000003, "text": " So it has imagined a set of feathers which are compatible with these exact pixels", "tokens": [407, 309, 575, 16590, 257, 992, 295, 27044, 597, 366, 18218, 365, 613, 1900, 18668], "temperature": 0.0, "avg_logprob": -0.21886991144536616, "compression_ratio": 1.6790697674418604, "no_speech_prob": 7.811465252416383e-07}, {"id": 802, "seek": 370242, "start": 3723.1, "end": 3725.62, "text": " Which is like genius like same here, right?", "tokens": [3013, 307, 411, 14017, 411, 912, 510, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21886991144536616, "compression_ratio": 1.6790697674418604, "no_speech_prob": 7.811465252416383e-07}, {"id": 803, "seek": 370242, "start": 3726.14, "end": 3729.9, "text": " There's no way you can tell what these blue dots are meant to represent", "tokens": [821, 311, 572, 636, 291, 393, 980, 437, 613, 3344, 15026, 366, 4140, 281, 2906], "temperature": 0.0, "avg_logprob": -0.21886991144536616, "compression_ratio": 1.6790697674418604, "no_speech_prob": 7.811465252416383e-07}, {"id": 804, "seek": 372990, "start": 3729.9, "end": 3734.62, "text": " But if you know that this kind of bird has an array of feathers here", "tokens": [583, 498, 291, 458, 300, 341, 733, 295, 5255, 575, 364, 10225, 295, 27044, 510], "temperature": 0.0, "avg_logprob": -0.19206185113816035, "compression_ratio": 1.7427385892116183, "no_speech_prob": 1.4593696278097923e-06}, {"id": 805, "seek": 372990, "start": 3735.1, "end": 3740.42, "text": " You know that's what they must be right and then you can figure out where the feathers would have to be such that when they were", "tokens": [509, 458, 300, 311, 437, 436, 1633, 312, 558, 293, 550, 291, 393, 2573, 484, 689, 264, 27044, 576, 362, 281, 312, 1270, 300, 562, 436, 645], "temperature": 0.0, "avg_logprob": -0.19206185113816035, "compression_ratio": 1.7427385892116183, "no_speech_prob": 1.4593696278097923e-06}, {"id": 806, "seek": 372990, "start": 3740.42, "end": 3742.42, "text": " Pixilated they'll end up in these spots", "tokens": [18652, 45678, 436, 603, 917, 493, 294, 613, 10681], "temperature": 0.0, "avg_logprob": -0.19206185113816035, "compression_ratio": 1.7427385892116183, "no_speech_prob": 1.4593696278097923e-06}, {"id": 807, "seek": 372990, "start": 3742.46, "end": 3744.46, "text": " All right, so it's like literally", "tokens": [1057, 558, 11, 370, 309, 311, 411, 3736], "temperature": 0.0, "avg_logprob": -0.19206185113816035, "compression_ratio": 1.7427385892116183, "no_speech_prob": 1.4593696278097923e-06}, {"id": 808, "seek": 372990, "start": 3745.14, "end": 3747.14, "text": " reverse engineered", "tokens": [9943, 38648], "temperature": 0.0, "avg_logprob": -0.19206185113816035, "compression_ratio": 1.7427385892116183, "no_speech_prob": 1.4593696278097923e-06}, {"id": 809, "seek": 372990, "start": 3747.46, "end": 3751.2200000000003, "text": " Like given its knowledge of this exact species of bird", "tokens": [1743, 2212, 1080, 3601, 295, 341, 1900, 6172, 295, 5255], "temperature": 0.0, "avg_logprob": -0.19206185113816035, "compression_ratio": 1.7427385892116183, "no_speech_prob": 1.4593696278097923e-06}, {"id": 810, "seek": 372990, "start": 3752.38, "end": 3755.78, "text": " how it would have to have looked to create this output and", "tokens": [577, 309, 576, 362, 281, 362, 2956, 281, 1884, 341, 5598, 293], "temperature": 0.0, "avg_logprob": -0.19206185113816035, "compression_ratio": 1.7427385892116183, "no_speech_prob": 1.4593696278097923e-06}, {"id": 811, "seek": 372990, "start": 3756.34, "end": 3758.26, "text": " so this is like", "tokens": [370, 341, 307, 411], "temperature": 0.0, "avg_logprob": -0.19206185113816035, "compression_ratio": 1.7427385892116183, "no_speech_prob": 1.4593696278097923e-06}, {"id": 812, "seek": 375826, "start": 3758.26, "end": 3760.38, "text": " So amazing it also knows", "tokens": [407, 2243, 309, 611, 3255], "temperature": 0.0, "avg_logprob": -0.20677996844780155, "compression_ratio": 1.5336538461538463, "no_speech_prob": 1.287893269363849e-06}, {"id": 813, "seek": 375826, "start": 3761.5800000000004, "end": 3765.34, "text": " From all the kind of signs around it that this area here", "tokens": [3358, 439, 264, 733, 295, 7880, 926, 309, 300, 341, 1859, 510], "temperature": 0.0, "avg_logprob": -0.20677996844780155, "compression_ratio": 1.5336538461538463, "no_speech_prob": 1.287893269363849e-06}, {"id": 814, "seek": 375826, "start": 3766.3, "end": 3770.0600000000004, "text": " Was was almost certainly blurred out. So it's actually", "tokens": [3027, 390, 1920, 3297, 43525, 484, 13, 407, 309, 311, 767], "temperature": 0.0, "avg_logprob": -0.20677996844780155, "compression_ratio": 1.5336538461538463, "no_speech_prob": 1.287893269363849e-06}, {"id": 815, "seek": 375826, "start": 3771.1800000000003, "end": 3772.42, "text": " reconstructed", "tokens": [31499, 292], "temperature": 0.0, "avg_logprob": -0.20677996844780155, "compression_ratio": 1.5336538461538463, "no_speech_prob": 1.287893269363849e-06}, {"id": 816, "seek": 375826, "start": 3772.42, "end": 3774.42, "text": " blurred vegetation", "tokens": [43525, 28769], "temperature": 0.0, "avg_logprob": -0.20677996844780155, "compression_ratio": 1.5336538461538463, "no_speech_prob": 1.287893269363849e-06}, {"id": 817, "seek": 375826, "start": 3774.7000000000003, "end": 3777.6600000000003, "text": " And you know if it if it hadn't have done all of those things", "tokens": [400, 291, 458, 498, 309, 498, 309, 8782, 380, 362, 1096, 439, 295, 729, 721], "temperature": 0.0, "avg_logprob": -0.20677996844780155, "compression_ratio": 1.5336538461538463, "no_speech_prob": 1.287893269363849e-06}, {"id": 818, "seek": 375826, "start": 3778.38, "end": 3783.26, "text": " It wouldn't have got such a good loss function right because in the end it had to match", "tokens": [467, 2759, 380, 362, 658, 1270, 257, 665, 4470, 2445, 558, 570, 294, 264, 917, 309, 632, 281, 2995], "temperature": 0.0, "avg_logprob": -0.20677996844780155, "compression_ratio": 1.5336538461538463, "no_speech_prob": 1.287893269363849e-06}, {"id": 819, "seek": 378326, "start": 3783.26, "end": 3788.3, "text": " You know the the activations saying like oh, there's a feather over here", "tokens": [509, 458, 264, 264, 2430, 763, 1566, 411, 1954, 11, 456, 311, 257, 25852, 670, 510], "temperature": 0.0, "avg_logprob": -0.15797211329142252, "compression_ratio": 1.6832579185520362, "no_speech_prob": 1.544600490888115e-05}, {"id": 820, "seek": 378326, "start": 3788.3, "end": 3791.9, "text": " And it's kind of fluffy looking and it's you know in this direction and all that", "tokens": [400, 309, 311, 733, 295, 22778, 1237, 293, 309, 311, 291, 458, 294, 341, 3513, 293, 439, 300], "temperature": 0.0, "avg_logprob": -0.15797211329142252, "compression_ratio": 1.6832579185520362, "no_speech_prob": 1.544600490888115e-05}, {"id": 821, "seek": 378326, "start": 3797.5800000000004, "end": 3801.0600000000004, "text": " All right, well that brings us to the end of super resolution", "tokens": [1057, 558, 11, 731, 300, 5607, 505, 281, 264, 917, 295, 1687, 8669], "temperature": 0.0, "avg_logprob": -0.15797211329142252, "compression_ratio": 1.6832579185520362, "no_speech_prob": 1.544600490888115e-05}, {"id": 822, "seek": 378326, "start": 3802.0200000000004, "end": 3808.7000000000003, "text": " Don't forget to check out the ask Jeremy anything thread and we will do some ask Jeremy anything after the break", "tokens": [1468, 380, 2870, 281, 1520, 484, 264, 1029, 17809, 1340, 7207, 293, 321, 486, 360, 512, 1029, 17809, 1340, 934, 264, 1821], "temperature": 0.0, "avg_logprob": -0.15797211329142252, "compression_ratio": 1.6832579185520362, "no_speech_prob": 1.544600490888115e-05}, {"id": 823, "seek": 380870, "start": 3808.7, "end": 3813.3399999999997, "text": " Let's see you back here at quarter to eight. I", "tokens": [961, 311, 536, 291, 646, 510, 412, 6555, 281, 3180, 13, 286], "temperature": 0.0, "avg_logprob": -0.32680755191379124, "compression_ratio": 0.9733333333333334, "no_speech_prob": 1.7777440007193945e-05}, {"id": 824, "seek": 380870, "start": 3828.9399999999996, "end": 3830.9399999999996, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.32680755191379124, "compression_ratio": 0.9733333333333334, "no_speech_prob": 1.7777440007193945e-05}, {"id": 825, "seek": 380870, "start": 3833.58, "end": 3835.62, "text": " So we are going to do", "tokens": [407, 321, 366, 516, 281, 360], "temperature": 0.0, "avg_logprob": -0.32680755191379124, "compression_ratio": 0.9733333333333334, "no_speech_prob": 1.7777440007193945e-05}, {"id": 826, "seek": 383562, "start": 3835.62, "end": 3838.7799999999997, "text": " Ask Jeremy anything", "tokens": [12320, 17809, 1340], "temperature": 0.0, "avg_logprob": -0.24671213785807292, "compression_ratio": 1.481283422459893, "no_speech_prob": 8.664178494655062e-06}, {"id": 827, "seek": 383562, "start": 3840.06, "end": 3846.6, "text": " Rachel will tell me the most voted up of your questions. Yes, Rachel", "tokens": [14246, 486, 980, 385, 264, 881, 13415, 493, 295, 428, 1651, 13, 1079, 11, 14246], "temperature": 0.0, "avg_logprob": -0.24671213785807292, "compression_ratio": 1.481283422459893, "no_speech_prob": 8.664178494655062e-06}, {"id": 828, "seek": 383562, "start": 3851.18, "end": 3857.8199999999997, "text": " What are the future plans for fast AI in this course will there be a part three if there is a part three", "tokens": [708, 366, 264, 2027, 5482, 337, 2370, 7318, 294, 341, 1164, 486, 456, 312, 257, 644, 1045, 498, 456, 307, 257, 644, 1045], "temperature": 0.0, "avg_logprob": -0.24671213785807292, "compression_ratio": 1.481283422459893, "no_speech_prob": 8.664178494655062e-06}, {"id": 829, "seek": 383562, "start": 3857.8199999999997, "end": 3859.8199999999997, "text": " I would really love to take it", "tokens": [286, 576, 534, 959, 281, 747, 309], "temperature": 0.0, "avg_logprob": -0.24671213785807292, "compression_ratio": 1.481283422459893, "no_speech_prob": 8.664178494655062e-06}, {"id": 830, "seek": 383562, "start": 3860.62, "end": 3864.7, "text": " Oh, I'm not quite sure I it's always hard to guess I", "tokens": [876, 11, 286, 478, 406, 1596, 988, 286, 309, 311, 1009, 1152, 281, 2041, 286], "temperature": 0.0, "avg_logprob": -0.24671213785807292, "compression_ratio": 1.481283422459893, "no_speech_prob": 8.664178494655062e-06}, {"id": 831, "seek": 386470, "start": 3864.7, "end": 3870.52, "text": " Hope there'll be some kind of follow-up last year after part two one of the students", "tokens": [6483, 456, 603, 312, 512, 733, 295, 1524, 12, 1010, 1036, 1064, 934, 644, 732, 472, 295, 264, 1731], "temperature": 0.0, "avg_logprob": -0.21038682884145005, "compression_ratio": 1.7564575645756457, "no_speech_prob": 1.4063546586839948e-05}, {"id": 832, "seek": 386470, "start": 3870.8799999999997, "end": 3877.2999999999997, "text": " Started up a weekly book club going through the Ian Goodfellow deep learning book and Ian actually came in and", "tokens": [39715, 493, 257, 12460, 1446, 6482, 516, 807, 264, 19595, 2205, 69, 21348, 2452, 2539, 1446, 293, 19595, 767, 1361, 294, 293], "temperature": 0.0, "avg_logprob": -0.21038682884145005, "compression_ratio": 1.7564575645756457, "no_speech_prob": 1.4063546586839948e-05}, {"id": 833, "seek": 386470, "start": 3878.5, "end": 3883.7799999999997, "text": " Presented quite a few of the chapters and other people like there's somebody an expert who presented every chapter", "tokens": [2718, 6003, 1596, 257, 1326, 295, 264, 20013, 293, 661, 561, 411, 456, 311, 2618, 364, 5844, 567, 8212, 633, 7187], "temperature": 0.0, "avg_logprob": -0.21038682884145005, "compression_ratio": 1.7564575645756457, "no_speech_prob": 1.4063546586839948e-05}, {"id": 834, "seek": 386470, "start": 3883.7799999999997, "end": 3888.2599999999998, "text": " That was really that was like a really cool part three and for a large extent it will depend on", "tokens": [663, 390, 534, 300, 390, 411, 257, 534, 1627, 644, 1045, 293, 337, 257, 2416, 8396, 309, 486, 5672, 322], "temperature": 0.0, "avg_logprob": -0.21038682884145005, "compression_ratio": 1.7564575645756457, "no_speech_prob": 1.4063546586839948e-05}, {"id": 835, "seek": 388826, "start": 3888.26, "end": 3893.78, "text": " on you the community to come up with ideas and help make them happen and", "tokens": [322, 291, 264, 1768, 281, 808, 493, 365, 3487, 293, 854, 652, 552, 1051, 293], "temperature": 0.0, "avg_logprob": -0.17540459199385208, "compression_ratio": 1.6893203883495145, "no_speech_prob": 1.3630454304802697e-05}, {"id": 836, "seek": 388826, "start": 3895.38, "end": 3897.38, "text": " Yeah, and I'm definitely keen to", "tokens": [865, 11, 293, 286, 478, 2138, 20297, 281], "temperature": 0.0, "avg_logprob": -0.17540459199385208, "compression_ratio": 1.6893203883495145, "no_speech_prob": 1.3630454304802697e-05}, {"id": 837, "seek": 388826, "start": 3897.38, "end": 3902.2200000000003, "text": " To help I've got a bunch of ideas, but I'm nervous about saying them because I'm not sure which ones will happen in which ones", "tokens": [1407, 854, 286, 600, 658, 257, 3840, 295, 3487, 11, 457, 286, 478, 6296, 466, 1566, 552, 570, 286, 478, 406, 988, 597, 2306, 486, 1051, 294, 597, 2306], "temperature": 0.0, "avg_logprob": -0.17540459199385208, "compression_ratio": 1.6893203883495145, "no_speech_prob": 1.3630454304802697e-05}, {"id": 838, "seek": 388826, "start": 3902.42, "end": 3904.42, "text": " won't but the more", "tokens": [1582, 380, 457, 264, 544], "temperature": 0.0, "avg_logprob": -0.17540459199385208, "compression_ratio": 1.6893203883495145, "no_speech_prob": 1.3630454304802697e-05}, {"id": 839, "seek": 388826, "start": 3905.2200000000003, "end": 3909.7400000000002, "text": " Support I have in making things happen that you want to happen from you the more likely they are", "tokens": [18073, 286, 362, 294, 1455, 721, 1051, 300, 291, 528, 281, 1051, 490, 291, 264, 544, 3700, 436, 366], "temperature": 0.0, "avg_logprob": -0.17540459199385208, "compression_ratio": 1.6893203883495145, "no_speech_prob": 1.3630454304802697e-05}, {"id": 840, "seek": 390974, "start": 3909.74, "end": 3916.7, "text": " To happen what was your experience like starting down the path of entrepreneurship?", "tokens": [1407, 1051, 437, 390, 428, 1752, 411, 2891, 760, 264, 3100, 295, 26582, 30], "temperature": 0.0, "avg_logprob": -0.24377134222733346, "compression_ratio": 1.6804979253112033, "no_speech_prob": 9.51568472373765e-06}, {"id": 841, "seek": 390974, "start": 3917.02, "end": 3922.62, "text": " Have you always been an entrepreneur did you start out at a start out at a big company and transition to a startup?", "tokens": [3560, 291, 1009, 668, 364, 14307, 630, 291, 722, 484, 412, 257, 722, 484, 412, 257, 955, 2237, 293, 6034, 281, 257, 18578, 30], "temperature": 0.0, "avg_logprob": -0.24377134222733346, "compression_ratio": 1.6804979253112033, "no_speech_prob": 9.51568472373765e-06}, {"id": 842, "seek": 390974, "start": 3922.62, "end": 3930.58, "text": " Did you go from academia to startups or startups to academia? No, I was definitely not in academia. I'm totally a fake academic I", "tokens": [2589, 291, 352, 490, 28937, 281, 28041, 420, 28041, 281, 28937, 30, 883, 11, 286, 390, 2138, 406, 294, 28937, 13, 286, 478, 3879, 257, 7592, 7778, 286], "temperature": 0.0, "avg_logprob": -0.24377134222733346, "compression_ratio": 1.6804979253112033, "no_speech_prob": 9.51568472373765e-06}, {"id": 843, "seek": 390974, "start": 3931.7, "end": 3936.2999999999997, "text": " I I started at McKinsey and Company, which is a strategy firm when I was 18", "tokens": [286, 286, 1409, 412, 21765, 259, 7399, 293, 13918, 11, 597, 307, 257, 5206, 6174, 562, 286, 390, 2443], "temperature": 0.0, "avg_logprob": -0.24377134222733346, "compression_ratio": 1.6804979253112033, "no_speech_prob": 9.51568472373765e-06}, {"id": 844, "seek": 393630, "start": 3936.3, "end": 3942.6400000000003, "text": " Which meant I couldn't really go to university so I didn't really turn up and then yeah", "tokens": [3013, 4140, 286, 2809, 380, 534, 352, 281, 5454, 370, 286, 994, 380, 534, 1261, 493, 293, 550, 1338], "temperature": 0.0, "avg_logprob": -0.18545513374860897, "compression_ratio": 1.673913043478261, "no_speech_prob": 1.6700816559023224e-05}, {"id": 845, "seek": 393630, "start": 3942.6400000000003, "end": 3947.5800000000004, "text": " I spent eight years in business helping really big companies on strategic questions", "tokens": [286, 4418, 3180, 924, 294, 1606, 4315, 534, 955, 3431, 322, 10924, 1651], "temperature": 0.0, "avg_logprob": -0.18545513374860897, "compression_ratio": 1.673913043478261, "no_speech_prob": 1.6700816559023224e-05}, {"id": 846, "seek": 393630, "start": 3948.8, "end": 3952.52, "text": " Always wanted to be an entrepreneur plan to only spend two years in McKinsey", "tokens": [11270, 1415, 281, 312, 364, 14307, 1393, 281, 787, 3496, 732, 924, 294, 21765, 259, 7399], "temperature": 0.0, "avg_logprob": -0.18545513374860897, "compression_ratio": 1.673913043478261, "no_speech_prob": 1.6700816559023224e-05}, {"id": 847, "seek": 393630, "start": 3953.04, "end": 3958.6800000000003, "text": " Only thing I really regret in my life was not sticking to that plan and wasting eight years instead", "tokens": [5686, 551, 286, 534, 10879, 294, 452, 993, 390, 406, 13465, 281, 300, 1393, 293, 20457, 3180, 924, 2602], "temperature": 0.0, "avg_logprob": -0.18545513374860897, "compression_ratio": 1.673913043478261, "no_speech_prob": 1.6700816559023224e-05}, {"id": 848, "seek": 393630, "start": 3959.2000000000003, "end": 3961.2000000000003, "text": " So two years would have been perfect", "tokens": [407, 732, 924, 576, 362, 668, 2176], "temperature": 0.0, "avg_logprob": -0.18545513374860897, "compression_ratio": 1.673913043478261, "no_speech_prob": 1.6700816559023224e-05}, {"id": 849, "seek": 396120, "start": 3961.2, "end": 3966.68, "text": " but yeah, then I went into entrepreneurship started two companies in Australia and", "tokens": [457, 1338, 11, 550, 286, 1437, 666, 26582, 1409, 732, 3431, 294, 7060, 293], "temperature": 0.0, "avg_logprob": -0.17588303486506143, "compression_ratio": 1.6337448559670782, "no_speech_prob": 7.646282938367222e-06}, {"id": 850, "seek": 396120, "start": 3967.6, "end": 3971.3599999999997, "text": " The best part about that was that I didn't get any funding", "tokens": [440, 1151, 644, 466, 300, 390, 300, 286, 994, 380, 483, 604, 6137], "temperature": 0.0, "avg_logprob": -0.17588303486506143, "compression_ratio": 1.6337448559670782, "no_speech_prob": 7.646282938367222e-06}, {"id": 851, "seek": 396120, "start": 3972.08, "end": 3977.56, "text": " So all the money that I made was mine or the decisions were mine and my you know in my partners", "tokens": [407, 439, 264, 1460, 300, 286, 1027, 390, 3892, 420, 264, 5327, 645, 3892, 293, 452, 291, 458, 294, 452, 4462], "temperature": 0.0, "avg_logprob": -0.17588303486506143, "compression_ratio": 1.6337448559670782, "no_speech_prob": 7.646282938367222e-06}, {"id": 852, "seek": 396120, "start": 3979.0, "end": 3984.9399999999996, "text": " You know, I focused entirely on on profit and product and customer and service", "tokens": [509, 458, 11, 286, 5178, 7696, 322, 322, 7475, 293, 1674, 293, 5474, 293, 2643], "temperature": 0.0, "avg_logprob": -0.17588303486506143, "compression_ratio": 1.6337448559670782, "no_speech_prob": 7.646282938367222e-06}, {"id": 853, "seek": 398494, "start": 3984.94, "end": 3990.62, "text": " Where else I find in San Francisco, I'm glad you know, I'm glad I came here and so", "tokens": [2305, 1646, 286, 915, 294, 5271, 12279, 11, 286, 478, 5404, 291, 458, 11, 286, 478, 5404, 286, 1361, 510, 293, 370], "temperature": 0.0, "avg_logprob": -0.17370057106018066, "compression_ratio": 1.6093023255813954, "no_speech_prob": 4.0294085010827985e-06}, {"id": 854, "seek": 398494, "start": 3992.26, "end": 3996.1, "text": " The two of us from you know came here for Kaggle", "tokens": [440, 732, 295, 505, 490, 291, 458, 1361, 510, 337, 48751, 22631], "temperature": 0.0, "avg_logprob": -0.17370057106018066, "compression_ratio": 1.6093023255813954, "no_speech_prob": 4.0294085010827985e-06}, {"id": 855, "seek": 398494, "start": 3997.54, "end": 4000.32, "text": " Anthony and I and raised, you know", "tokens": [15853, 293, 286, 293, 6005, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.17370057106018066, "compression_ratio": 1.6093023255813954, "no_speech_prob": 4.0294085010827985e-06}, {"id": 856, "seek": 398494, "start": 4001.46, "end": 4006.02, "text": " Ridiculous amount of money 11 million dollars for this really new company", "tokens": [30619, 299, 6893, 2372, 295, 1460, 2975, 2459, 3808, 337, 341, 534, 777, 2237], "temperature": 0.0, "avg_logprob": -0.17370057106018066, "compression_ratio": 1.6093023255813954, "no_speech_prob": 4.0294085010827985e-06}, {"id": 857, "seek": 398494, "start": 4006.86, "end": 4012.86, "text": " That was really interesting, but it's also really distracting, you know trying to worry about scaling and", "tokens": [663, 390, 534, 1880, 11, 457, 309, 311, 611, 534, 36689, 11, 291, 458, 1382, 281, 3292, 466, 21589, 293], "temperature": 0.0, "avg_logprob": -0.17370057106018066, "compression_ratio": 1.6093023255813954, "no_speech_prob": 4.0294085010827985e-06}, {"id": 858, "seek": 401286, "start": 4012.86, "end": 4020.34, "text": " These sees wanting to see what your business development plans are and also just not having any real need to actually make a profit", "tokens": [1981, 8194, 7935, 281, 536, 437, 428, 1606, 3250, 5482, 366, 293, 611, 445, 406, 1419, 604, 957, 643, 281, 767, 652, 257, 7475], "temperature": 0.0, "avg_logprob": -0.28035972118377683, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.9832623365800828e-05}, {"id": 859, "seek": 401286, "start": 4020.34, "end": 4022.34, "text": " And yeah", "tokens": [400, 1338], "temperature": 0.0, "avg_logprob": -0.28035972118377683, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.9832623365800828e-05}, {"id": 860, "seek": 401286, "start": 4022.42, "end": 4024.42, "text": " So I had a bit of the same problem at analytic", "tokens": [407, 286, 632, 257, 857, 295, 264, 912, 1154, 412, 40358], "temperature": 0.0, "avg_logprob": -0.28035972118377683, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.9832623365800828e-05}, {"id": 861, "seek": 401286, "start": 4026.26, "end": 4028.38, "text": " Where I again raised a lot of money", "tokens": [2305, 286, 797, 6005, 257, 688, 295, 1460], "temperature": 0.0, "avg_logprob": -0.28035972118377683, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.9832623365800828e-05}, {"id": 862, "seek": 401286, "start": 4029.82, "end": 4031.82, "text": " 15 million dollars pretty quickly", "tokens": [2119, 2459, 3808, 1238, 2661], "temperature": 0.0, "avg_logprob": -0.28035972118377683, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.9832623365800828e-05}, {"id": 863, "seek": 401286, "start": 4032.7400000000002, "end": 4034.7400000000002, "text": " And yeah a lot of distractions", "tokens": [400, 1338, 257, 688, 295, 37887], "temperature": 0.0, "avg_logprob": -0.28035972118377683, "compression_ratio": 1.514018691588785, "no_speech_prob": 1.9832623365800828e-05}, {"id": 864, "seek": 403474, "start": 4034.74, "end": 4040.7799999999997, "text": " So yeah, I think you know trying to", "tokens": [407, 1338, 11, 286, 519, 291, 458, 1382, 281], "temperature": 0.0, "avg_logprob": -0.2350153806732922, "compression_ratio": 1.6119402985074627, "no_speech_prob": 8.530095328751486e-06}, {"id": 865, "seek": 403474, "start": 4042.8199999999997, "end": 4044.8199999999997, "text": " Bootstrap your own company", "tokens": [37263, 372, 4007, 428, 1065, 2237], "temperature": 0.0, "avg_logprob": -0.2350153806732922, "compression_ratio": 1.6119402985074627, "no_speech_prob": 8.530095328751486e-06}, {"id": 866, "seek": 403474, "start": 4045.2599999999998, "end": 4051.58, "text": " And focus on making money by selling something at a profit at a profit and then you know", "tokens": [400, 1879, 322, 1455, 1460, 538, 6511, 746, 412, 257, 7475, 412, 257, 7475, 293, 550, 291, 458], "temperature": 0.0, "avg_logprob": -0.2350153806732922, "compression_ratio": 1.6119402985074627, "no_speech_prob": 8.530095328751486e-06}, {"id": 867, "seek": 403474, "start": 4052.14, "end": 4055.58, "text": " Plowing that back into the company. It worked really well, right because", "tokens": [2149, 9637, 300, 646, 666, 264, 2237, 13, 467, 2732, 534, 731, 11, 558, 570], "temperature": 0.0, "avg_logprob": -0.2350153806732922, "compression_ratio": 1.6119402985074627, "no_speech_prob": 8.530095328751486e-06}, {"id": 868, "seek": 403474, "start": 4056.58, "end": 4058.58, "text": " Within like five years", "tokens": [15996, 411, 1732, 924], "temperature": 0.0, "avg_logprob": -0.2350153806732922, "compression_ratio": 1.6119402985074627, "no_speech_prob": 8.530095328751486e-06}, {"id": 869, "seek": 403474, "start": 4059.3799999999997, "end": 4062.4599999999996, "text": " You know, we were making a profit from three months in and within five years", "tokens": [509, 458, 11, 321, 645, 1455, 257, 7475, 490, 1045, 2493, 294, 293, 1951, 1732, 924], "temperature": 0.0, "avg_logprob": -0.2350153806732922, "compression_ratio": 1.6119402985074627, "no_speech_prob": 8.530095328751486e-06}, {"id": 870, "seek": 406246, "start": 4062.46, "end": 4067.14, "text": " We were making you know enough of a profit not just to pay all of us in their own wages", "tokens": [492, 645, 1455, 291, 458, 1547, 295, 257, 7475, 406, 445, 281, 1689, 439, 295, 505, 294, 641, 1065, 20097], "temperature": 0.0, "avg_logprob": -0.19881177171368467, "compression_ratio": 1.6174242424242424, "no_speech_prob": 1.593632077856455e-05}, {"id": 871, "seek": 406246, "start": 4067.14, "end": 4069.14, "text": " but also to see my bank account growing and", "tokens": [457, 611, 281, 536, 452, 3765, 2696, 4194, 293], "temperature": 0.0, "avg_logprob": -0.19881177171368467, "compression_ratio": 1.6174242424242424, "no_speech_prob": 1.593632077856455e-05}, {"id": 872, "seek": 406246, "start": 4069.7, "end": 4074.7400000000002, "text": " after ten years sold it for a big chunk of money not enough that a VC would be excited but", "tokens": [934, 2064, 924, 3718, 309, 337, 257, 955, 16635, 295, 1460, 406, 1547, 300, 257, 41922, 576, 312, 2919, 457], "temperature": 0.0, "avg_logprob": -0.19881177171368467, "compression_ratio": 1.6174242424242424, "no_speech_prob": 1.593632077856455e-05}, {"id": 873, "seek": 406246, "start": 4075.46, "end": 4078.5, "text": " Enough that I didn't have to worry about money again, you know", "tokens": [19401, 300, 286, 994, 380, 362, 281, 3292, 466, 1460, 797, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.19881177171368467, "compression_ratio": 1.6174242424242424, "no_speech_prob": 1.593632077856455e-05}, {"id": 874, "seek": 406246, "start": 4079.1, "end": 4086.58, "text": " So I think yeah bootstrapping a company is something which people in the Bay Area at least don't seem to appreciate how", "tokens": [407, 286, 519, 1338, 11450, 19639, 3759, 257, 2237, 307, 746, 597, 561, 294, 264, 7840, 19405, 412, 1935, 500, 380, 1643, 281, 4449, 577], "temperature": 0.0, "avg_logprob": -0.19881177171368467, "compression_ratio": 1.6174242424242424, "no_speech_prob": 1.593632077856455e-05}, {"id": 875, "seek": 406246, "start": 4087.2200000000003, "end": 4089.2200000000003, "text": " good our idea that is", "tokens": [665, 527, 1558, 300, 307], "temperature": 0.0, "avg_logprob": -0.19881177171368467, "compression_ratio": 1.6174242424242424, "no_speech_prob": 1.593632077856455e-05}, {"id": 876, "seek": 408922, "start": 4089.22, "end": 4095.8999999999996, "text": " If you were 25 years old today and still know what you know, where would you be looking to use AI?", "tokens": [759, 291, 645, 3552, 924, 1331, 965, 293, 920, 458, 437, 291, 458, 11, 689, 576, 291, 312, 1237, 281, 764, 7318, 30], "temperature": 0.0, "avg_logprob": -0.15993245442708334, "compression_ratio": 1.682170542635659, "no_speech_prob": 1.4063705748412758e-05}, {"id": 877, "seek": 408922, "start": 4096.219999999999, "end": 4099.42, "text": " What are you working on right now or looking to work on in the next two years?", "tokens": [708, 366, 291, 1364, 322, 558, 586, 420, 1237, 281, 589, 322, 294, 264, 958, 732, 924, 30], "temperature": 0.0, "avg_logprob": -0.15993245442708334, "compression_ratio": 1.682170542635659, "no_speech_prob": 1.4063705748412758e-05}, {"id": 878, "seek": 408922, "start": 4101.139999999999, "end": 4104.3, "text": " You should ignore the last part of that I won't even answer it", "tokens": [509, 820, 11200, 264, 1036, 644, 295, 300, 286, 1582, 380, 754, 1867, 309], "temperature": 0.0, "avg_logprob": -0.15993245442708334, "compression_ratio": 1.682170542635659, "no_speech_prob": 1.4063705748412758e-05}, {"id": 879, "seek": 408922, "start": 4104.3, "end": 4108.26, "text": " It doesn't matter where I'm looking like the what you should do is", "tokens": [467, 1177, 380, 1871, 689, 286, 478, 1237, 411, 264, 437, 291, 820, 360, 307], "temperature": 0.0, "avg_logprob": -0.15993245442708334, "compression_ratio": 1.682170542635659, "no_speech_prob": 1.4063705748412758e-05}, {"id": 880, "seek": 408922, "start": 4108.94, "end": 4116.0599999999995, "text": " Leverage your knowledge about your domain. So like one of the main reasons we do this is to get people who have", "tokens": [441, 1054, 609, 428, 3601, 466, 428, 9274, 13, 407, 411, 472, 295, 264, 2135, 4112, 321, 360, 341, 307, 281, 483, 561, 567, 362], "temperature": 0.0, "avg_logprob": -0.15993245442708334, "compression_ratio": 1.682170542635659, "no_speech_prob": 1.4063705748412758e-05}, {"id": 881, "seek": 408922, "start": 4117.0199999999995, "end": 4118.219999999999, "text": " backgrounds in", "tokens": [17336, 294], "temperature": 0.0, "avg_logprob": -0.15993245442708334, "compression_ratio": 1.682170542635659, "no_speech_prob": 1.4063705748412758e-05}, {"id": 882, "seek": 411822, "start": 4118.22, "end": 4120.62, "text": " Whatever recruiting, you know", "tokens": [8541, 25987, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.20292454381142894, "compression_ratio": 1.7251184834123223, "no_speech_prob": 9.080283234652597e-06}, {"id": 883, "seek": 411822, "start": 4121.3, "end": 4123.3, "text": " oilfield surveys", "tokens": [3184, 7610, 22711], "temperature": 0.0, "avg_logprob": -0.20292454381142894, "compression_ratio": 1.7251184834123223, "no_speech_prob": 9.080283234652597e-06}, {"id": 884, "seek": 411822, "start": 4124.38, "end": 4127.02, "text": " Journalism activism, whatever right and", "tokens": [16936, 1434, 29040, 11, 2035, 558, 293], "temperature": 0.0, "avg_logprob": -0.20292454381142894, "compression_ratio": 1.7251184834123223, "no_speech_prob": 9.080283234652597e-06}, {"id": 885, "seek": 411822, "start": 4128.46, "end": 4130.46, "text": " solve your", "tokens": [5039, 428], "temperature": 0.0, "avg_logprob": -0.20292454381142894, "compression_ratio": 1.7251184834123223, "no_speech_prob": 9.080283234652597e-06}, {"id": 886, "seek": 411822, "start": 4130.62, "end": 4132.62, "text": " problems", "tokens": [2740], "temperature": 0.0, "avg_logprob": -0.20292454381142894, "compression_ratio": 1.7251184834123223, "no_speech_prob": 9.080283234652597e-06}, {"id": 887, "seek": 411822, "start": 4132.66, "end": 4138.860000000001, "text": " It'll be really obvious to you what your problems are and it'll be really obvious to you what data you have and where to find it", "tokens": [467, 603, 312, 534, 6322, 281, 291, 437, 428, 2740, 366, 293, 309, 603, 312, 534, 6322, 281, 291, 437, 1412, 291, 362, 293, 689, 281, 915, 309], "temperature": 0.0, "avg_logprob": -0.20292454381142894, "compression_ratio": 1.7251184834123223, "no_speech_prob": 9.080283234652597e-06}, {"id": 888, "seek": 411822, "start": 4139.54, "end": 4142.06, "text": " Those are all the bits that for everybody else. It's really hard", "tokens": [3950, 366, 439, 264, 9239, 300, 337, 2201, 1646, 13, 467, 311, 534, 1152], "temperature": 0.0, "avg_logprob": -0.20292454381142894, "compression_ratio": 1.7251184834123223, "no_speech_prob": 9.080283234652597e-06}, {"id": 889, "seek": 411822, "start": 4142.06, "end": 4146.18, "text": " So people who start out with like, oh, I know deep learning now", "tokens": [407, 561, 567, 722, 484, 365, 411, 11, 1954, 11, 286, 458, 2452, 2539, 586], "temperature": 0.0, "avg_logprob": -0.20292454381142894, "compression_ratio": 1.7251184834123223, "no_speech_prob": 9.080283234652597e-06}, {"id": 890, "seek": 414618, "start": 4146.18, "end": 4148.18, "text": " I'll go and find something to apply it to", "tokens": [286, 603, 352, 293, 915, 746, 281, 3079, 309, 281], "temperature": 0.0, "avg_logprob": -0.16290386444931731, "compression_ratio": 1.64453125, "no_speech_prob": 1.6964144379016943e-05}, {"id": 891, "seek": 414618, "start": 4148.820000000001, "end": 4150.820000000001, "text": " Basically never succeed", "tokens": [8537, 1128, 7754], "temperature": 0.0, "avg_logprob": -0.16290386444931731, "compression_ratio": 1.64453125, "no_speech_prob": 1.6964144379016943e-05}, {"id": 892, "seek": 414618, "start": 4151.22, "end": 4153.38, "text": " Where else people who are like, oh, I've been spending", "tokens": [2305, 1646, 561, 567, 366, 411, 11, 1954, 11, 286, 600, 668, 6434], "temperature": 0.0, "avg_logprob": -0.16290386444931731, "compression_ratio": 1.64453125, "no_speech_prob": 1.6964144379016943e-05}, {"id": 893, "seek": 414618, "start": 4154.18, "end": 4157.54, "text": " 25 years doing specialized recruiting for legal firms", "tokens": [3552, 924, 884, 19813, 25987, 337, 5089, 18055], "temperature": 0.0, "avg_logprob": -0.16290386444931731, "compression_ratio": 1.64453125, "no_speech_prob": 1.6964144379016943e-05}, {"id": 894, "seek": 414618, "start": 4157.54, "end": 4162.740000000001, "text": " And I know that the key issue is this thing and I know that this piece of data totally solves it", "tokens": [400, 286, 458, 300, 264, 2141, 2734, 307, 341, 551, 293, 286, 458, 300, 341, 2522, 295, 1412, 3879, 39890, 309], "temperature": 0.0, "avg_logprob": -0.16290386444931731, "compression_ratio": 1.64453125, "no_speech_prob": 1.6964144379016943e-05}, {"id": 895, "seek": 414618, "start": 4162.740000000001, "end": 4167.58, "text": " And so I'm just going to do that now and I already know who to call to actually start selling it to", "tokens": [400, 370, 286, 478, 445, 516, 281, 360, 300, 586, 293, 286, 1217, 458, 567, 281, 818, 281, 767, 722, 6511, 309, 281], "temperature": 0.0, "avg_logprob": -0.16290386444931731, "compression_ratio": 1.64453125, "no_speech_prob": 1.6964144379016943e-05}, {"id": 896, "seek": 414618, "start": 4167.900000000001, "end": 4169.900000000001, "text": " you know, they're the ones who", "tokens": [291, 458, 11, 436, 434, 264, 2306, 567], "temperature": 0.0, "avg_logprob": -0.16290386444931731, "compression_ratio": 1.64453125, "no_speech_prob": 1.6964144379016943e-05}, {"id": 897, "seek": 414618, "start": 4169.9400000000005, "end": 4171.9400000000005, "text": " who tend to win so", "tokens": [567, 3928, 281, 1942, 370], "temperature": 0.0, "avg_logprob": -0.16290386444931731, "compression_ratio": 1.64453125, "no_speech_prob": 1.6964144379016943e-05}, {"id": 898, "seek": 417194, "start": 4171.94, "end": 4176.66, "text": " Yeah, and and and you know if you if you've done nothing but like", "tokens": [865, 11, 293, 293, 293, 291, 458, 498, 291, 498, 291, 600, 1096, 1825, 457, 411], "temperature": 0.0, "avg_logprob": -0.226456692344264, "compression_ratio": 1.6633165829145728, "no_speech_prob": 3.089466645178618e-06}, {"id": 899, "seek": 417194, "start": 4179.78, "end": 4186.419999999999, "text": " Academic stuff then it's more maybe about your your hobbies and interests, you know, so everybody has hobbies", "tokens": [36139, 1507, 550, 309, 311, 544, 1310, 466, 428, 428, 35750, 293, 8847, 11, 291, 458, 11, 370, 2201, 575, 35750], "temperature": 0.0, "avg_logprob": -0.226456692344264, "compression_ratio": 1.6633165829145728, "no_speech_prob": 3.089466645178618e-06}, {"id": 900, "seek": 417194, "start": 4187.299999999999, "end": 4189.299999999999, "text": " the main thing I would say is", "tokens": [264, 2135, 551, 286, 576, 584, 307], "temperature": 0.0, "avg_logprob": -0.226456692344264, "compression_ratio": 1.6633165829145728, "no_speech_prob": 3.089466645178618e-06}, {"id": 901, "seek": 417194, "start": 4189.7, "end": 4197.9, "text": " Please don't focus on building tools for data scientists to use or for software engineers to use because every data scientist", "tokens": [2555, 500, 380, 1879, 322, 2390, 3873, 337, 1412, 7708, 281, 764, 420, 337, 4722, 11955, 281, 764, 570, 633, 1412, 12662], "temperature": 0.0, "avg_logprob": -0.226456692344264, "compression_ratio": 1.6633165829145728, "no_speech_prob": 3.089466645178618e-06}, {"id": 902, "seek": 419790, "start": 4197.9, "end": 4204.94, "text": " Knows about the market of data scientists for us only you know about the market for you know", "tokens": [10519, 1509, 466, 264, 2142, 295, 1412, 7708, 337, 505, 787, 291, 458, 466, 264, 2142, 337, 291, 458], "temperature": 0.0, "avg_logprob": -0.24099992303287282, "compression_ratio": 1.5683060109289617, "no_speech_prob": 3.237717237425386e-06}, {"id": 903, "seek": 419790, "start": 4206.58, "end": 4209.98, "text": " Analyzing oil survey well logs or you know", "tokens": [1107, 5222, 8781, 3184, 8984, 731, 20820, 420, 291, 458], "temperature": 0.0, "avg_logprob": -0.24099992303287282, "compression_ratio": 1.5683060109289617, "no_speech_prob": 3.237717237425386e-06}, {"id": 904, "seek": 419790, "start": 4210.98, "end": 4213.379999999999, "text": " understanding audiology studies or", "tokens": [3701, 27435, 1793, 5313, 420], "temperature": 0.0, "avg_logprob": -0.24099992303287282, "compression_ratio": 1.5683060109289617, "no_speech_prob": 3.237717237425386e-06}, {"id": 905, "seek": 419790, "start": 4214.42, "end": 4216.42, "text": " Whatever it is that you do", "tokens": [8541, 309, 307, 300, 291, 360], "temperature": 0.0, "avg_logprob": -0.24099992303287282, "compression_ratio": 1.5683060109289617, "no_speech_prob": 3.237717237425386e-06}, {"id": 906, "seek": 419790, "start": 4219.139999999999, "end": 4223.94, "text": " Given what you've shown us about applying transfer learning from image recognition to NLP", "tokens": [18600, 437, 291, 600, 4898, 505, 466, 9275, 5003, 2539, 490, 3256, 11150, 281, 426, 45196], "temperature": 0.0, "avg_logprob": -0.24099992303287282, "compression_ratio": 1.5683060109289617, "no_speech_prob": 3.237717237425386e-06}, {"id": 907, "seek": 422394, "start": 4223.94, "end": 4228.94, "text": " There looks to be a lot of value in paying attention to all of the developments that happen across the whole", "tokens": [821, 1542, 281, 312, 257, 688, 295, 2158, 294, 6229, 3202, 281, 439, 295, 264, 20862, 300, 1051, 2108, 264, 1379], "temperature": 0.0, "avg_logprob": -0.11774496130041175, "compression_ratio": 1.7535714285714286, "no_speech_prob": 2.178036083932966e-05}, {"id": 908, "seek": 422394, "start": 4229.0199999999995, "end": 4235.0199999999995, "text": " Machine learning field and that if you were to focus in one area you might miss out on some great advances in other concentrations", "tokens": [22155, 2539, 2519, 293, 300, 498, 291, 645, 281, 1879, 294, 472, 1859, 291, 1062, 1713, 484, 322, 512, 869, 25297, 294, 661, 33512], "temperature": 0.0, "avg_logprob": -0.11774496130041175, "compression_ratio": 1.7535714285714286, "no_speech_prob": 2.178036083932966e-05}, {"id": 909, "seek": 422394, "start": 4235.46, "end": 4241.679999999999, "text": " How do you stay aware of all the advancements across the field while still having time to dig in deep to your specific domains?", "tokens": [1012, 360, 291, 1754, 3650, 295, 439, 264, 7295, 1117, 2108, 264, 2519, 1339, 920, 1419, 565, 281, 2528, 294, 2452, 281, 428, 2685, 25514, 30], "temperature": 0.0, "avg_logprob": -0.11774496130041175, "compression_ratio": 1.7535714285714286, "no_speech_prob": 2.178036083932966e-05}, {"id": 910, "seek": 422394, "start": 4242.139999999999, "end": 4248.54, "text": " Yeah, that's awesome. I mean that's kind of the message of this course one of the key messages this course. Yeah, it's like", "tokens": [865, 11, 300, 311, 3476, 13, 286, 914, 300, 311, 733, 295, 264, 3636, 295, 341, 1164, 472, 295, 264, 2141, 7897, 341, 1164, 13, 865, 11, 309, 311, 411], "temperature": 0.0, "avg_logprob": -0.11774496130041175, "compression_ratio": 1.7535714285714286, "no_speech_prob": 2.178036083932966e-05}, {"id": 911, "seek": 424854, "start": 4248.54, "end": 4254.68, "text": " Lots of good works being done in different places and people are so specialized most people don't know about it", "tokens": [15908, 295, 665, 1985, 885, 1096, 294, 819, 3190, 293, 561, 366, 370, 19813, 881, 561, 500, 380, 458, 466, 309], "temperature": 0.0, "avg_logprob": -0.17540515718005953, "compression_ratio": 1.6135458167330676, "no_speech_prob": 1.593620800122153e-05}, {"id": 912, "seek": 424854, "start": 4255.14, "end": 4260.98, "text": " Like if I can get state-of-the-art results in NLP within six months of starting to look at NLP and I", "tokens": [1743, 498, 286, 393, 483, 1785, 12, 2670, 12, 3322, 12, 446, 3542, 294, 426, 45196, 1951, 2309, 2493, 295, 2891, 281, 574, 412, 426, 45196, 293, 286], "temperature": 0.0, "avg_logprob": -0.17540515718005953, "compression_ratio": 1.6135458167330676, "no_speech_prob": 1.593620800122153e-05}, {"id": 913, "seek": 424854, "start": 4261.54, "end": 4264.5199999999995, "text": " Think that says more about NLP than it does about me frankly", "tokens": [6557, 300, 1619, 544, 466, 426, 45196, 813, 309, 775, 466, 385, 11939], "temperature": 0.0, "avg_logprob": -0.17540515718005953, "compression_ratio": 1.6135458167330676, "no_speech_prob": 1.593620800122153e-05}, {"id": 914, "seek": 424854, "start": 4266.3, "end": 4267.62, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.17540515718005953, "compression_ratio": 1.6135458167330676, "no_speech_prob": 1.593620800122153e-05}, {"id": 915, "seek": 424854, "start": 4267.62, "end": 4269.86, "text": " Yeah, it's kind of like the entrepreneurship thing", "tokens": [865, 11, 309, 311, 733, 295, 411, 264, 26582, 551], "temperature": 0.0, "avg_logprob": -0.17540515718005953, "compression_ratio": 1.6135458167330676, "no_speech_prob": 1.593620800122153e-05}, {"id": 916, "seek": 424854, "start": 4269.86, "end": 4274.9, "text": " It's like you you pick the areas that you see that you know about and kind of", "tokens": [467, 311, 411, 291, 291, 1888, 264, 3179, 300, 291, 536, 300, 291, 458, 466, 293, 733, 295], "temperature": 0.0, "avg_logprob": -0.17540515718005953, "compression_ratio": 1.6135458167330676, "no_speech_prob": 1.593620800122153e-05}, {"id": 917, "seek": 427490, "start": 4274.9, "end": 4280.74, "text": " Transfer stuff like oh we could use deep learning to solve this problem or in this case like we could use", "tokens": [35025, 1507, 411, 1954, 321, 727, 764, 2452, 2539, 281, 5039, 341, 1154, 420, 294, 341, 1389, 411, 321, 727, 764], "temperature": 0.0, "avg_logprob": -0.21883119355647937, "compression_ratio": 1.728301886792453, "no_speech_prob": 3.844877937808633e-06}, {"id": 918, "seek": 427490, "start": 4281.379999999999, "end": 4282.66, "text": " You know", "tokens": [509, 458], "temperature": 0.0, "avg_logprob": -0.21883119355647937, "compression_ratio": 1.728301886792453, "no_speech_prob": 3.844877937808633e-06}, {"id": 919, "seek": 427490, "start": 4282.66, "end": 4285.78, "text": " This can idea of computer vision to solve that problem", "tokens": [639, 393, 1558, 295, 3820, 5201, 281, 5039, 300, 1154], "temperature": 0.0, "avg_logprob": -0.21883119355647937, "compression_ratio": 1.728301886792453, "no_speech_prob": 3.844877937808633e-06}, {"id": 920, "seek": 427490, "start": 4286.94, "end": 4289.139999999999, "text": " So things like Trent the other may transfer learning", "tokens": [407, 721, 411, 40119, 264, 661, 815, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.21883119355647937, "compression_ratio": 1.728301886792453, "no_speech_prob": 3.844877937808633e-06}, {"id": 921, "seek": 427490, "start": 4289.139999999999, "end": 4295.98, "text": " I'm sure there's like a thousand things opportunities for you to do in other fields to do what Sebastian and I did", "tokens": [286, 478, 988, 456, 311, 411, 257, 4714, 721, 4786, 337, 291, 281, 360, 294, 661, 7909, 281, 360, 437, 31102, 293, 286, 630], "temperature": 0.0, "avg_logprob": -0.21883119355647937, "compression_ratio": 1.728301886792453, "no_speech_prob": 3.844877937808633e-06}, {"id": 922, "seek": 427490, "start": 4296.7, "end": 4298.7, "text": " NLP with NLP classification", "tokens": [426, 45196, 365, 426, 45196, 21538], "temperature": 0.0, "avg_logprob": -0.21883119355647937, "compression_ratio": 1.728301886792453, "no_speech_prob": 3.844877937808633e-06}, {"id": 923, "seek": 427490, "start": 4299.179999999999, "end": 4304.04, "text": " So the short answer to your question is the way to stay ahead of what's going on would be to", "tokens": [407, 264, 2099, 1867, 281, 428, 1168, 307, 264, 636, 281, 1754, 2286, 295, 437, 311, 516, 322, 576, 312, 281], "temperature": 0.0, "avg_logprob": -0.21883119355647937, "compression_ratio": 1.728301886792453, "no_speech_prob": 3.844877937808633e-06}, {"id": 924, "seek": 430404, "start": 4304.04, "end": 4306.96, "text": " follow my feed of Twitter favorites and", "tokens": [1524, 452, 3154, 295, 5794, 16907, 293], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 925, "seek": 430404, "start": 4307.64, "end": 4313.4, "text": " My approach is to follow lots and lots of people on Twitter and put them into the Twitter favorites for you", "tokens": [1222, 3109, 307, 281, 1524, 3195, 293, 3195, 295, 561, 322, 5794, 293, 829, 552, 666, 264, 5794, 16907, 337, 291], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 926, "seek": 430404, "start": 4313.4, "end": 4314.6, "text": " but literally I", "tokens": [457, 3736, 286], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 927, "seek": 430404, "start": 4314.6, "end": 4317.6, "text": " every time I come across something interesting I click favorite and", "tokens": [633, 565, 286, 808, 2108, 746, 1880, 286, 2052, 2954, 293], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 928, "seek": 430404, "start": 4318.04, "end": 4319.5199999999995, "text": " There are two reasons I do it", "tokens": [821, 366, 732, 4112, 286, 360, 309], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 929, "seek": 430404, "start": 4319.5199999999995, "end": 4324.76, "text": " The first is that when the next course comes along I go through my favorites to find which things I want to study", "tokens": [440, 700, 307, 300, 562, 264, 958, 1164, 1487, 2051, 286, 352, 807, 452, 16907, 281, 915, 597, 721, 286, 528, 281, 2979], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 930, "seek": 430404, "start": 4324.96, "end": 4328.96, "text": " The second is so that you know you can do the same thing", "tokens": [440, 1150, 307, 370, 300, 291, 458, 291, 393, 360, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 931, "seek": 430404, "start": 4329.96, "end": 4331.16, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 932, "seek": 430404, "start": 4331.16, "end": 4332.56, "text": " then", "tokens": [550], "temperature": 0.0, "avg_logprob": -0.2154943876177351, "compression_ratio": 1.8, "no_speech_prob": 3.219050995539874e-05}, {"id": 933, "seek": 433256, "start": 4332.56, "end": 4338.240000000001, "text": " You know, which do you go deep into it almost doesn't matter like I find every time I look at something it turns out to", "tokens": [509, 458, 11, 597, 360, 291, 352, 2452, 666, 309, 1920, 1177, 380, 1871, 411, 286, 915, 633, 565, 286, 574, 412, 746, 309, 4523, 484, 281], "temperature": 0.0, "avg_logprob": -0.171340612931685, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0289285455655772e-05}, {"id": 934, "seek": 433256, "start": 4338.240000000001, "end": 4341.72, "text": " Be super interesting and important. So it was like pick something which is like", "tokens": [879, 1687, 1880, 293, 1021, 13, 407, 309, 390, 411, 1888, 746, 597, 307, 411], "temperature": 0.0, "avg_logprob": -0.171340612931685, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0289285455655772e-05}, {"id": 935, "seek": 433256, "start": 4344.240000000001, "end": 4349.76, "text": " You feel like solving that problem would be actually useful for some reason and it doesn't seem to be very popular", "tokens": [509, 841, 411, 12606, 300, 1154, 576, 312, 767, 4420, 337, 512, 1778, 293, 309, 1177, 380, 1643, 281, 312, 588, 3743], "temperature": 0.0, "avg_logprob": -0.171340612931685, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0289285455655772e-05}, {"id": 936, "seek": 433256, "start": 4350.080000000001, "end": 4354.64, "text": " which is kind of the opposite of what everybody else does everybody else works on the problems which", "tokens": [597, 307, 733, 295, 264, 6182, 295, 437, 2201, 1646, 775, 2201, 1646, 1985, 322, 264, 2740, 597], "temperature": 0.0, "avg_logprob": -0.171340612931685, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0289285455655772e-05}, {"id": 937, "seek": 433256, "start": 4356.080000000001, "end": 4360.04, "text": " everybody else is already working on because they're the ones that seem popular and I", "tokens": [2201, 1646, 307, 1217, 1364, 322, 570, 436, 434, 264, 2306, 300, 1643, 3743, 293, 286], "temperature": 0.0, "avg_logprob": -0.171340612931685, "compression_ratio": 1.8284671532846715, "no_speech_prob": 1.0289285455655772e-05}, {"id": 938, "seek": 436004, "start": 4360.04, "end": 4364.36, "text": " Don't know. I can't quite understand this chain of thinking but it seems to be very common", "tokens": [1468, 380, 458, 13, 286, 393, 380, 1596, 1223, 341, 5021, 295, 1953, 457, 309, 2544, 281, 312, 588, 2689], "temperature": 0.0, "avg_logprob": -0.18524835167861567, "compression_ratio": 1.661904761904762, "no_speech_prob": 5.9549533943936694e-06}, {"id": 939, "seek": 436004, "start": 4366.28, "end": 4373.54, "text": " Is deep learning and overkill to use on tabular data when is it better to use deep learning instead of machine learning on tabular data?", "tokens": [1119, 2452, 2539, 293, 670, 34213, 281, 764, 322, 4421, 1040, 1412, 562, 307, 309, 1101, 281, 764, 2452, 2539, 2602, 295, 3479, 2539, 322, 4421, 1040, 1412, 30], "temperature": 0.0, "avg_logprob": -0.18524835167861567, "compression_ratio": 1.661904761904762, "no_speech_prob": 5.9549533943936694e-06}, {"id": 940, "seek": 436004, "start": 4378.84, "end": 4384.76, "text": " Is that a real question or did you just put that there so that I would point out that Rachel Thomas just wrote an article", "tokens": [1119, 300, 257, 957, 1168, 420, 630, 291, 445, 829, 300, 456, 370, 300, 286, 576, 935, 484, 300, 14246, 8500, 445, 4114, 364, 7222], "temperature": 0.0, "avg_logprob": -0.18524835167861567, "compression_ratio": 1.661904761904762, "no_speech_prob": 5.9549533943936694e-06}, {"id": 941, "seek": 438476, "start": 4384.76, "end": 4386.76, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.18750488925987566, "compression_ratio": 1.5532994923857868, "no_speech_prob": 1.4737861420144327e-05}, {"id": 942, "seek": 438476, "start": 4391.12, "end": 4393.96, "text": " Yes, so Rachel's just written about this and and", "tokens": [1079, 11, 370, 14246, 311, 445, 3720, 466, 341, 293, 293], "temperature": 0.0, "avg_logprob": -0.18750488925987566, "compression_ratio": 1.5532994923857868, "no_speech_prob": 1.4737861420144327e-05}, {"id": 943, "seek": 438476, "start": 4394.72, "end": 4402.12, "text": " Rachel and I spent a long time talking about it and short answer is we think it's great to use deep learning on tabular data", "tokens": [14246, 293, 286, 4418, 257, 938, 565, 1417, 466, 309, 293, 2099, 1867, 307, 321, 519, 309, 311, 869, 281, 764, 2452, 2539, 322, 4421, 1040, 1412], "temperature": 0.0, "avg_logprob": -0.18750488925987566, "compression_ratio": 1.5532994923857868, "no_speech_prob": 1.4737861420144327e-05}, {"id": 944, "seek": 438476, "start": 4403.88, "end": 4405.88, "text": " Actually of all the", "tokens": [5135, 295, 439, 264], "temperature": 0.0, "avg_logprob": -0.18750488925987566, "compression_ratio": 1.5532994923857868, "no_speech_prob": 1.4737861420144327e-05}, {"id": 945, "seek": 438476, "start": 4406.4400000000005, "end": 4412.88, "text": " rich complex important and interesting things that appear in Rachel's Twitter stream covering everything from", "tokens": [4593, 3997, 1021, 293, 1880, 721, 300, 4204, 294, 14246, 311, 5794, 4309, 10322, 1203, 490], "temperature": 0.0, "avg_logprob": -0.18750488925987566, "compression_ratio": 1.5532994923857868, "no_speech_prob": 1.4737861420144327e-05}, {"id": 946, "seek": 441288, "start": 4412.88, "end": 4415.52, "text": " the genocide of the Hringa", "tokens": [264, 31867, 295, 264, 389, 2937, 64], "temperature": 0.0, "avg_logprob": -0.23109534051683214, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.240729817363899e-06}, {"id": 947, "seek": 441288, "start": 4416.08, "end": 4422.72, "text": " Through to the latest ethics violations in AI companies the one by far that got the most", "tokens": [8927, 281, 264, 6792, 19769, 30405, 294, 7318, 3431, 264, 472, 538, 1400, 300, 658, 264, 881], "temperature": 0.0, "avg_logprob": -0.23109534051683214, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.240729817363899e-06}, {"id": 948, "seek": 441288, "start": 4423.4400000000005, "end": 4429.9400000000005, "text": " Attention and engagement from the community was her question about is it called tabular data or structured data? So", "tokens": [31858, 293, 8742, 490, 264, 1768, 390, 720, 1168, 466, 307, 309, 1219, 4421, 1040, 1412, 420, 18519, 1412, 30, 407], "temperature": 0.0, "avg_logprob": -0.23109534051683214, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.240729817363899e-06}, {"id": 949, "seek": 441288, "start": 4431.04, "end": 4436.84, "text": " Yeah, ask computer buys people how to name things and you'll get plenty of interest", "tokens": [865, 11, 1029, 3820, 28153, 561, 577, 281, 1315, 721, 293, 291, 603, 483, 7140, 295, 1179], "temperature": 0.0, "avg_logprob": -0.23109534051683214, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.240729817363899e-06}, {"id": 950, "seek": 443684, "start": 4436.84, "end": 4443.84, "text": " Yeah, and there's some really good links here to stuff from instacart and Pinterest and other folks who have done some good work in this area", "tokens": [865, 11, 293, 456, 311, 512, 534, 665, 6123, 510, 281, 1507, 490, 1058, 326, 446, 293, 37986, 293, 661, 4024, 567, 362, 1096, 512, 665, 589, 294, 341, 1859], "temperature": 0.0, "avg_logprob": -0.29793051917954244, "compression_ratio": 1.6059479553903346, "no_speech_prob": 1.922243791341316e-05}, {"id": 951, "seek": 443684, "start": 4443.84, "end": 4450.76, "text": " Any of you that went to the Data Institute conference will have seen Jeremy Stanley's presentation about the really cool work they did at instacart", "tokens": [2639, 295, 291, 300, 1437, 281, 264, 11888, 9446, 7586, 486, 362, 1612, 17809, 28329, 311, 5860, 466, 264, 534, 1627, 589, 436, 630, 412, 1058, 326, 446], "temperature": 0.0, "avg_logprob": -0.29793051917954244, "compression_ratio": 1.6059479553903346, "no_speech_prob": 1.922243791341316e-05}, {"id": 952, "seek": 443684, "start": 4452.96, "end": 4459.4800000000005, "text": " Yes, Rachel. So I relied heavily on lessons three and four from part one and writing this post. So yes", "tokens": [1079, 11, 14246, 13, 407, 286, 35463, 10950, 322, 8820, 1045, 293, 1451, 490, 644, 472, 293, 3579, 341, 2183, 13, 407, 2086], "temperature": 0.0, "avg_logprob": -0.29793051917954244, "compression_ratio": 1.6059479553903346, "no_speech_prob": 1.922243791341316e-05}, {"id": 953, "seek": 443684, "start": 4459.4800000000005, "end": 4461.68, "text": " Much of it may be familiar to you. Yeah", "tokens": [12313, 295, 309, 815, 312, 4963, 281, 291, 13, 865], "temperature": 0.0, "avg_logprob": -0.29793051917954244, "compression_ratio": 1.6059479553903346, "no_speech_prob": 1.922243791341316e-05}, {"id": 954, "seek": 446168, "start": 4461.68, "end": 4468.4400000000005, "text": " um Rachel asked me during the post like how to tell whether you should use a", "tokens": [1105, 14246, 2351, 385, 1830, 264, 2183, 411, 577, 281, 980, 1968, 291, 820, 764, 257], "temperature": 0.0, "avg_logprob": -0.18203165016922296, "compression_ratio": 1.579925650557621, "no_speech_prob": 1.644195435801521e-05}, {"id": 955, "seek": 446168, "start": 4469.0, "end": 4474.88, "text": " Decision tree ensemble like GBM or random forest or or a neural net and my answer is I still don't know", "tokens": [12427, 1991, 4230, 19492, 411, 460, 18345, 420, 4974, 6719, 420, 420, 257, 18161, 2533, 293, 452, 1867, 307, 286, 920, 500, 380, 458], "temperature": 0.0, "avg_logprob": -0.18203165016922296, "compression_ratio": 1.579925650557621, "no_speech_prob": 1.644195435801521e-05}, {"id": 956, "seek": 446168, "start": 4475.72, "end": 4481.280000000001, "text": " Nobody to my nobody I'm aware of has done that research in any particularly meaningful way", "tokens": [9297, 281, 452, 5079, 286, 478, 3650, 295, 575, 1096, 300, 2132, 294, 604, 4098, 10995, 636], "temperature": 0.0, "avg_logprob": -0.18203165016922296, "compression_ratio": 1.579925650557621, "no_speech_prob": 1.644195435801521e-05}, {"id": 957, "seek": 446168, "start": 4481.84, "end": 4483.400000000001, "text": " so there's a", "tokens": [370, 456, 311, 257], "temperature": 0.0, "avg_logprob": -0.18203165016922296, "compression_ratio": 1.579925650557621, "no_speech_prob": 1.644195435801521e-05}, {"id": 958, "seek": 446168, "start": 4483.400000000001, "end": 4485.400000000001, "text": " Question to be answered there. I guess", "tokens": [14464, 281, 312, 10103, 456, 13, 286, 2041], "temperature": 0.0, "avg_logprob": -0.18203165016922296, "compression_ratio": 1.579925650557621, "no_speech_prob": 1.644195435801521e-05}, {"id": 959, "seek": 446168, "start": 4486.280000000001, "end": 4490.64, "text": " My approach has been to try to make both of those things as accessible as possible through the faster", "tokens": [1222, 3109, 575, 668, 281, 853, 281, 652, 1293, 295, 729, 721, 382, 9515, 382, 1944, 807, 264, 4663], "temperature": 0.0, "avg_logprob": -0.18203165016922296, "compression_ratio": 1.579925650557621, "no_speech_prob": 1.644195435801521e-05}, {"id": 960, "seek": 449064, "start": 4490.64, "end": 4494.900000000001, "text": " Yeah library so you can try them both to both and see what works. That's that's what I do", "tokens": [865, 6405, 370, 291, 393, 853, 552, 1293, 281, 1293, 293, 536, 437, 1985, 13, 663, 311, 300, 311, 437, 286, 360], "temperature": 0.0, "avg_logprob": -0.3260753873794798, "compression_ratio": 1.4099378881987579, "no_speech_prob": 1.0289393685525283e-05}, {"id": 961, "seek": 449064, "start": 4500.240000000001, "end": 4503.740000000001, "text": " And that was it for the top-loaded questions, thank you", "tokens": [400, 300, 390, 309, 337, 264, 1192, 12, 2907, 292, 1651, 11, 1309, 291], "temperature": 0.0, "avg_logprob": -0.3260753873794798, "compression_ratio": 1.4099378881987579, "no_speech_prob": 1.0289393685525283e-05}, {"id": 962, "seek": 449064, "start": 4507.160000000001, "end": 4510.320000000001, "text": " Okay, so just quickly to go from", "tokens": [1033, 11, 370, 445, 2661, 281, 352, 490], "temperature": 0.0, "avg_logprob": -0.3260753873794798, "compression_ratio": 1.4099378881987579, "no_speech_prob": 1.0289393685525283e-05}, {"id": 963, "seek": 449064, "start": 4512.08, "end": 4515.96, "text": " Super resolution to style transfer is kind of oh", "tokens": [4548, 8669, 281, 3758, 5003, 307, 733, 295, 1954], "temperature": 0.0, "avg_logprob": -0.3260753873794798, "compression_ratio": 1.4099378881987579, "no_speech_prob": 1.0289393685525283e-05}, {"id": 964, "seek": 451596, "start": 4515.96, "end": 4520.52, "text": " Oh, I think I missed the one on reinforcement learning and", "tokens": [876, 11, 286, 519, 286, 6721, 264, 472, 322, 29280, 2539, 293], "temperature": 0.0, "avg_logprob": -0.28413968208508616, "compression_ratio": 1.734375, "no_speech_prob": 8.530124432581943e-06}, {"id": 965, "seek": 451596, "start": 4521.68, "end": 4525.12, "text": " Reinforcement learning popularity has been on a gradual rise in the recent past", "tokens": [42116, 9382, 2539, 19301, 575, 668, 322, 257, 32890, 6272, 294, 264, 5162, 1791], "temperature": 0.0, "avg_logprob": -0.28413968208508616, "compression_ratio": 1.734375, "no_speech_prob": 8.530124432581943e-06}, {"id": 966, "seek": 451596, "start": 4526.4800000000005, "end": 4533.16, "text": " What's your take on reinforcement learning? Would fast AI consider covering some ground and popular RL techniques in the future?", "tokens": [708, 311, 428, 747, 322, 29280, 2539, 30, 6068, 2370, 7318, 1949, 10322, 512, 2727, 293, 3743, 497, 43, 7512, 294, 264, 2027, 30], "temperature": 0.0, "avg_logprob": -0.28413968208508616, "compression_ratio": 1.734375, "no_speech_prob": 8.530124432581943e-06}, {"id": 967, "seek": 451596, "start": 4535.84, "end": 4538.68, "text": " I'm still not a believer in reinforcement learning", "tokens": [286, 478, 920, 406, 257, 23892, 294, 29280, 2539], "temperature": 0.0, "avg_logprob": -0.28413968208508616, "compression_ratio": 1.734375, "no_speech_prob": 8.530124432581943e-06}, {"id": 968, "seek": 451596, "start": 4539.6, "end": 4541.4, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.28413968208508616, "compression_ratio": 1.734375, "no_speech_prob": 8.530124432581943e-06}, {"id": 969, "seek": 451596, "start": 4541.4, "end": 4542.64, "text": " think it's a", "tokens": [519, 309, 311, 257], "temperature": 0.0, "avg_logprob": -0.28413968208508616, "compression_ratio": 1.734375, "no_speech_prob": 8.530124432581943e-06}, {"id": 970, "seek": 454264, "start": 4542.64, "end": 4548.4800000000005, "text": " An interesting problem to solve but it's not at all clear that we have a good way of solving this problem", "tokens": [1107, 1880, 1154, 281, 5039, 457, 309, 311, 406, 412, 439, 1850, 300, 321, 362, 257, 665, 636, 295, 12606, 341, 1154], "temperature": 0.0, "avg_logprob": -0.12530980110168458, "compression_ratio": 1.640316205533597, "no_speech_prob": 8.397691090067383e-06}, {"id": 971, "seek": 454264, "start": 4548.4800000000005, "end": 4551.76, "text": " So the problem it really is that delayed credit problem", "tokens": [407, 264, 1154, 309, 534, 307, 300, 20268, 5397, 1154], "temperature": 0.0, "avg_logprob": -0.12530980110168458, "compression_ratio": 1.640316205533597, "no_speech_prob": 8.397691090067383e-06}, {"id": 972, "seek": 454264, "start": 4551.76, "end": 4554.240000000001, "text": " So, you know, I want to learn to play pong", "tokens": [407, 11, 291, 458, 11, 286, 528, 281, 1466, 281, 862, 36164], "temperature": 0.0, "avg_logprob": -0.12530980110168458, "compression_ratio": 1.640316205533597, "no_speech_prob": 8.397691090067383e-06}, {"id": 973, "seek": 454264, "start": 4554.240000000001, "end": 4560.360000000001, "text": " I've moved up or down and three minutes later. I find out whether I won the game of pong", "tokens": [286, 600, 4259, 493, 420, 760, 293, 1045, 2077, 1780, 13, 286, 915, 484, 1968, 286, 1582, 264, 1216, 295, 36164], "temperature": 0.0, "avg_logprob": -0.12530980110168458, "compression_ratio": 1.640316205533597, "no_speech_prob": 8.397691090067383e-06}, {"id": 974, "seek": 454264, "start": 4561.96, "end": 4569.200000000001, "text": " Which actions I took were actually useful and so to me the idea of calculating the gradients of those inputs with respect", "tokens": [3013, 5909, 286, 1890, 645, 767, 4420, 293, 370, 281, 385, 264, 1558, 295, 28258, 264, 2771, 2448, 295, 729, 15743, 365, 3104], "temperature": 0.0, "avg_logprob": -0.12530980110168458, "compression_ratio": 1.640316205533597, "no_speech_prob": 8.397691090067383e-06}, {"id": 975, "seek": 456920, "start": 4569.2, "end": 4572.72, "text": " You know the app sorry the greatest of the output with respect to those inputs", "tokens": [509, 458, 264, 724, 2597, 264, 6636, 295, 264, 5598, 365, 3104, 281, 729, 15743], "temperature": 0.0, "avg_logprob": -0.21495387133430033, "compression_ratio": 1.6942446043165467, "no_speech_prob": 1.3419732567854226e-05}, {"id": 976, "seek": 456920, "start": 4572.84, "end": 4577.24, "text": " The credit is so delayed that those derivatives don't seem very interesting", "tokens": [440, 5397, 307, 370, 20268, 300, 729, 33733, 500, 380, 1643, 588, 1880], "temperature": 0.0, "avg_logprob": -0.21495387133430033, "compression_ratio": 1.6942446043165467, "no_speech_prob": 1.3419732567854226e-05}, {"id": 977, "seek": 456920, "start": 4577.88, "end": 4585.72, "text": " And there's been you know, they're kind of been I get this question quite regularly in every one of these four courses so far", "tokens": [400, 456, 311, 668, 291, 458, 11, 436, 434, 733, 295, 668, 286, 483, 341, 1168, 1596, 11672, 294, 633, 472, 295, 613, 1451, 7712, 370, 1400], "temperature": 0.0, "avg_logprob": -0.21495387133430033, "compression_ratio": 1.6942446043165467, "no_speech_prob": 1.3419732567854226e-05}, {"id": 978, "seek": 456920, "start": 4585.72, "end": 4587.599999999999, "text": " I've always said the same thing", "tokens": [286, 600, 1009, 848, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.21495387133430033, "compression_ratio": 1.6942446043165467, "no_speech_prob": 1.3419732567854226e-05}, {"id": 979, "seek": 456920, "start": 4587.599999999999, "end": 4593.88, "text": " I'm rather pleased that finally recently there's been some results showing that actually basically random search", "tokens": [286, 478, 2831, 10587, 300, 2721, 3938, 456, 311, 668, 512, 3542, 4099, 300, 767, 1936, 4974, 3164], "temperature": 0.0, "avg_logprob": -0.21495387133430033, "compression_ratio": 1.6942446043165467, "no_speech_prob": 1.3419732567854226e-05}, {"id": 980, "seek": 456920, "start": 4594.5199999999995, "end": 4596.5199999999995, "text": " often does better than", "tokens": [2049, 775, 1101, 813], "temperature": 0.0, "avg_logprob": -0.21495387133430033, "compression_ratio": 1.6942446043165467, "no_speech_prob": 1.3419732567854226e-05}, {"id": 981, "seek": 456920, "start": 4597.12, "end": 4598.5199999999995, "text": " reinforcement learning", "tokens": [29280, 2539], "temperature": 0.0, "avg_logprob": -0.21495387133430033, "compression_ratio": 1.6942446043165467, "no_speech_prob": 1.3419732567854226e-05}, {"id": 982, "seek": 459852, "start": 4598.52, "end": 4600.52, "text": " So basically what's happened is?", "tokens": [407, 1936, 437, 311, 2011, 307, 30], "temperature": 0.0, "avg_logprob": -0.2002918107169015, "compression_ratio": 1.6994818652849741, "no_speech_prob": 5.422123649623245e-06}, {"id": 983, "seek": 459852, "start": 4601.200000000001, "end": 4606.64, "text": " very well funded companies with vast amounts of computational power throw all of it at", "tokens": [588, 731, 14385, 3431, 365, 8369, 11663, 295, 28270, 1347, 3507, 439, 295, 309, 412], "temperature": 0.0, "avg_logprob": -0.2002918107169015, "compression_ratio": 1.6994818652849741, "no_speech_prob": 5.422123649623245e-06}, {"id": 984, "seek": 459852, "start": 4607.080000000001, "end": 4614.280000000001, "text": " reinforcement learning problems and get good results and people then say oh it's because of the reinforcement learning rather than", "tokens": [29280, 2539, 2740, 293, 483, 665, 3542, 293, 561, 550, 584, 1954, 309, 311, 570, 295, 264, 29280, 2539, 2831, 813], "temperature": 0.0, "avg_logprob": -0.2002918107169015, "compression_ratio": 1.6994818652849741, "no_speech_prob": 5.422123649623245e-06}, {"id": 985, "seek": 459852, "start": 4614.56, "end": 4616.76, "text": " the vast amounts of compute power or", "tokens": [264, 8369, 11663, 295, 14722, 1347, 420], "temperature": 0.0, "avg_logprob": -0.2002918107169015, "compression_ratio": 1.6994818652849741, "no_speech_prob": 5.422123649623245e-06}, {"id": 986, "seek": 459852, "start": 4617.88, "end": 4619.88, "text": " They use extremely", "tokens": [814, 764, 4664], "temperature": 0.0, "avg_logprob": -0.2002918107169015, "compression_ratio": 1.6994818652849741, "no_speech_prob": 5.422123649623245e-06}, {"id": 987, "seek": 459852, "start": 4620.6, "end": 4622.4800000000005, "text": " thoughtful and clever", "tokens": [21566, 293, 13494], "temperature": 0.0, "avg_logprob": -0.2002918107169015, "compression_ratio": 1.6994818652849741, "no_speech_prob": 5.422123649623245e-06}, {"id": 988, "seek": 462248, "start": 4622.48, "end": 4628.879999999999, "text": " algorithms like a combination of convolutional neural nets and Monte Carlo tree search like they did with the AlphaGo stuff", "tokens": [14642, 411, 257, 6562, 295, 45216, 304, 18161, 36170, 293, 38105, 45112, 4230, 3164, 411, 436, 630, 365, 264, 20588, 12104, 1507], "temperature": 0.0, "avg_logprob": -0.18175127195275348, "compression_ratio": 1.6851851851851851, "no_speech_prob": 3.1875317745289067e-06}, {"id": 989, "seek": 462248, "start": 4629.12, "end": 4631.12, "text": " To get great results and people", "tokens": [1407, 483, 869, 3542, 293, 561], "temperature": 0.0, "avg_logprob": -0.18175127195275348, "compression_ratio": 1.6851851851851851, "no_speech_prob": 3.1875317745289067e-06}, {"id": 990, "seek": 462248, "start": 4631.719999999999, "end": 4638.2, "text": " Incorrectly say oh, that's because of reinforcement learning when it wasn't really reinforcement learning at all so", "tokens": [39120, 2554, 356, 584, 1954, 11, 300, 311, 570, 295, 29280, 2539, 562, 309, 2067, 380, 534, 29280, 2539, 412, 439, 370], "temperature": 0.0, "avg_logprob": -0.18175127195275348, "compression_ratio": 1.6851851851851851, "no_speech_prob": 3.1875317745289067e-06}, {"id": 991, "seek": 462248, "start": 4639.48, "end": 4643.16, "text": " I'm very interested like in solving these kind of", "tokens": [286, 478, 588, 3102, 411, 294, 12606, 613, 733, 295], "temperature": 0.0, "avg_logprob": -0.18175127195275348, "compression_ratio": 1.6851851851851851, "no_speech_prob": 3.1875317745289067e-06}, {"id": 992, "seek": 464316, "start": 4643.16, "end": 4651.16, "text": " More generic optimization type problems rather than just prediction problems, and that's what these delayed credit problems tend to look like", "tokens": [5048, 19577, 19618, 2010, 2740, 2831, 813, 445, 17630, 2740, 11, 293, 300, 311, 437, 613, 20268, 5397, 2740, 3928, 281, 574, 411], "temperature": 0.0, "avg_logprob": -0.1502881101382676, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.936915956932353e-06}, {"id": 993, "seek": 464316, "start": 4653.4, "end": 4655.4, "text": " But I don't think we've yet got", "tokens": [583, 286, 500, 380, 519, 321, 600, 1939, 658], "temperature": 0.0, "avg_logprob": -0.1502881101382676, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.936915956932353e-06}, {"id": 994, "seek": 464316, "start": 4655.88, "end": 4658.66, "text": " Good enough best practices that I have anything I'm", "tokens": [2205, 1547, 1151, 7525, 300, 286, 362, 1340, 286, 478], "temperature": 0.0, "avg_logprob": -0.1502881101382676, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.936915956932353e-06}, {"id": 995, "seek": 464316, "start": 4659.68, "end": 4664.96, "text": " Ready to teach and say like I'm going to teach you this thing because I think it's still going to be useful next year", "tokens": [9944, 281, 2924, 293, 584, 411, 286, 478, 516, 281, 2924, 291, 341, 551, 570, 286, 519, 309, 311, 920, 516, 281, 312, 4420, 958, 1064], "temperature": 0.0, "avg_logprob": -0.1502881101382676, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.936915956932353e-06}, {"id": 996, "seek": 464316, "start": 4666.16, "end": 4668.16, "text": " so we'll keep watching and", "tokens": [370, 321, 603, 1066, 1976, 293], "temperature": 0.0, "avg_logprob": -0.1502881101382676, "compression_ratio": 1.6610878661087867, "no_speech_prob": 4.936915956932353e-06}, {"id": 997, "seek": 466816, "start": 4668.16, "end": 4672.48, "text": " And yeah, see see what happens", "tokens": [400, 1338, 11, 536, 536, 437, 2314], "temperature": 0.0, "avg_logprob": -0.22336518137078537, "compression_ratio": 1.5459183673469388, "no_speech_prob": 8.013356818992179e-06}, {"id": 998, "seek": 466816, "start": 4675.44, "end": 4677.44, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.22336518137078537, "compression_ratio": 1.5459183673469388, "no_speech_prob": 8.013356818992179e-06}, {"id": 999, "seek": 466816, "start": 4677.599999999999, "end": 4682.48, "text": " So we're going to now turn the super resolution network basically into a", "tokens": [407, 321, 434, 516, 281, 586, 1261, 264, 1687, 8669, 3209, 1936, 666, 257], "temperature": 0.0, "avg_logprob": -0.22336518137078537, "compression_ratio": 1.5459183673469388, "no_speech_prob": 8.013356818992179e-06}, {"id": 1000, "seek": 466816, "start": 4683.599999999999, "end": 4685.599999999999, "text": " Style transfer network, and we'll do this pretty quickly", "tokens": [27004, 5003, 3209, 11, 293, 321, 603, 360, 341, 1238, 2661], "temperature": 0.0, "avg_logprob": -0.22336518137078537, "compression_ratio": 1.5459183673469388, "no_speech_prob": 8.013356818992179e-06}, {"id": 1001, "seek": 466816, "start": 4686.4, "end": 4692.68, "text": " We basically already have something so here's my input image, and I'm going to have some loss function", "tokens": [492, 1936, 1217, 362, 746, 370, 510, 311, 452, 4846, 3256, 11, 293, 286, 478, 516, 281, 362, 512, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.22336518137078537, "compression_ratio": 1.5459183673469388, "no_speech_prob": 8.013356818992179e-06}, {"id": 1002, "seek": 466816, "start": 4693.0, "end": 4695.92, "text": " And I've got some neural net again", "tokens": [400, 286, 600, 658, 512, 18161, 2533, 797], "temperature": 0.0, "avg_logprob": -0.22336518137078537, "compression_ratio": 1.5459183673469388, "no_speech_prob": 8.013356818992179e-06}, {"id": 1003, "seek": 469592, "start": 4695.92, "end": 4700.86, "text": " So instead of a neural net that does a whole lot of compute and then does up sampling at the end", "tokens": [407, 2602, 295, 257, 18161, 2533, 300, 775, 257, 1379, 688, 295, 14722, 293, 550, 775, 493, 21179, 412, 264, 917], "temperature": 0.0, "avg_logprob": -0.1949289833627096, "compression_ratio": 1.9, "no_speech_prob": 3.5008297345484607e-06}, {"id": 1004, "seek": 469592, "start": 4701.52, "end": 4704.52, "text": " Our input this time is just as big as our output", "tokens": [2621, 4846, 341, 565, 307, 445, 382, 955, 382, 527, 5598], "temperature": 0.0, "avg_logprob": -0.1949289833627096, "compression_ratio": 1.9, "no_speech_prob": 3.5008297345484607e-06}, {"id": 1005, "seek": 469592, "start": 4704.6, "end": 4709.2, "text": " So we're going to do some down sampling first and then our compute and then our ups", "tokens": [407, 321, 434, 516, 281, 360, 512, 760, 21179, 700, 293, 550, 527, 14722, 293, 550, 527, 15497], "temperature": 0.0, "avg_logprob": -0.1949289833627096, "compression_ratio": 1.9, "no_speech_prob": 3.5008297345484607e-06}, {"id": 1006, "seek": 469592, "start": 4709.68, "end": 4713.4, "text": " Okay, so that's the first change we're going to make is going to add some down sampling", "tokens": [1033, 11, 370, 300, 311, 264, 700, 1319, 321, 434, 516, 281, 652, 307, 516, 281, 909, 512, 760, 21179], "temperature": 0.0, "avg_logprob": -0.1949289833627096, "compression_ratio": 1.9, "no_speech_prob": 3.5008297345484607e-06}, {"id": 1007, "seek": 469592, "start": 4713.76, "end": 4716.56, "text": " So some stride to convolution layers to the front of our network", "tokens": [407, 512, 1056, 482, 281, 45216, 7914, 281, 264, 1868, 295, 527, 3209], "temperature": 0.0, "avg_logprob": -0.1949289833627096, "compression_ratio": 1.9, "no_speech_prob": 3.5008297345484607e-06}, {"id": 1008, "seek": 469592, "start": 4717.28, "end": 4719.62, "text": " The second is rather than just comparing", "tokens": [440, 1150, 307, 2831, 813, 445, 15763], "temperature": 0.0, "avg_logprob": -0.1949289833627096, "compression_ratio": 1.9, "no_speech_prob": 3.5008297345484607e-06}, {"id": 1009, "seek": 469592, "start": 4720.24, "end": 4724.36, "text": " Y C and X to the same thing here right so we're going to basically say", "tokens": [398, 383, 293, 1783, 281, 264, 912, 551, 510, 558, 370, 321, 434, 516, 281, 1936, 584], "temperature": 0.0, "avg_logprob": -0.1949289833627096, "compression_ratio": 1.9, "no_speech_prob": 3.5008297345484607e-06}, {"id": 1010, "seek": 472436, "start": 4724.36, "end": 4728.36, "text": " Our input image should look like itself", "tokens": [2621, 4846, 3256, 820, 574, 411, 2564], "temperature": 0.0, "avg_logprob": -0.24800638808417566, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.092882591066882e-06}, {"id": 1011, "seek": 472436, "start": 4728.88, "end": 4735.16, "text": " By the end and so specifically we're going to compare it by checking it through VGG and comparing it at one of the content", "tokens": [3146, 264, 917, 293, 370, 4682, 321, 434, 516, 281, 6794, 309, 538, 8568, 309, 807, 691, 27561, 293, 15763, 309, 412, 472, 295, 264, 2701], "temperature": 0.0, "avg_logprob": -0.24800638808417566, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.092882591066882e-06}, {"id": 1012, "seek": 472436, "start": 4735.16, "end": 4737.16, "text": " at one of the activation layers and", "tokens": [412, 472, 295, 264, 24433, 7914, 293], "temperature": 0.0, "avg_logprob": -0.24800638808417566, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.092882591066882e-06}, {"id": 1013, "seek": 472436, "start": 4738.04, "end": 4740.599999999999, "text": " Then its style should look like some", "tokens": [1396, 1080, 3758, 820, 574, 411, 512], "temperature": 0.0, "avg_logprob": -0.24800638808417566, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.092882591066882e-06}, {"id": 1014, "seek": 472436, "start": 4741.639999999999, "end": 4748.92, "text": " Painting which brought to you just like we did with the Gatties approach by looking at the gram matrix correspondence at a number of layers", "tokens": [24943, 783, 597, 3038, 281, 291, 445, 411, 321, 630, 365, 264, 460, 1591, 530, 3109, 538, 1237, 412, 264, 21353, 8141, 38135, 412, 257, 1230, 295, 7914], "temperature": 0.0, "avg_logprob": -0.24800638808417566, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.092882591066882e-06}, {"id": 1015, "seek": 472436, "start": 4749.92, "end": 4752.48, "text": " So that's basically it and so that", "tokens": [407, 300, 311, 1936, 309, 293, 370, 300], "temperature": 0.0, "avg_logprob": -0.24800638808417566, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.092882591066882e-06}, {"id": 1016, "seek": 475248, "start": 4752.48, "end": 4754.48, "text": " That ought to be super straightforward", "tokens": [663, 13416, 281, 312, 1687, 15325], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1017, "seek": 475248, "start": 4755.599999999999, "end": 4758.179999999999, "text": " It's really just combining two things we've already done", "tokens": [467, 311, 534, 445, 21928, 732, 721, 321, 600, 1217, 1096], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1018, "seek": 475248, "start": 4759.04, "end": 4764.0, "text": " And so all this code at the start is identical except. We don't have high res and low res", "tokens": [400, 370, 439, 341, 3089, 412, 264, 722, 307, 14800, 3993, 13, 492, 500, 380, 362, 1090, 725, 293, 2295, 725], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1019, "seek": 475248, "start": 4764.0, "end": 4766.0, "text": " We just have one size 256", "tokens": [492, 445, 362, 472, 2744, 38882], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1020, "seek": 475248, "start": 4766.919999999999, "end": 4768.919999999999, "text": " All this is the same", "tokens": [1057, 341, 307, 264, 912], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1021, "seek": 475248, "start": 4770.759999999999, "end": 4772.759999999999, "text": " My model is the same", "tokens": [1222, 2316, 307, 264, 912], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1022, "seek": 475248, "start": 4772.839999999999, "end": 4774.839999999999, "text": " one thing I did here is I", "tokens": [472, 551, 286, 630, 510, 307, 286], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1023, "seek": 475248, "start": 4775.12, "end": 4777.12, "text": " Made I did not", "tokens": [18330, 286, 630, 406], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1024, "seek": 475248, "start": 4777.839999999999, "end": 4781.08, "text": " Do any kind of fancy best practices for this one at all?", "tokens": [1144, 604, 733, 295, 10247, 1151, 7525, 337, 341, 472, 412, 439, 30], "temperature": 0.0, "avg_logprob": -0.21080342117620973, "compression_ratio": 1.5327510917030567, "no_speech_prob": 7.112406024134543e-07}, {"id": 1025, "seek": 478108, "start": 4781.08, "end": 4786.08, "text": " I'm partly because there doesn't seem to be any like there's been very little follow-up", "tokens": [286, 478, 17031, 570, 456, 1177, 380, 1643, 281, 312, 604, 411, 456, 311, 668, 588, 707, 1524, 12, 1010], "temperature": 0.0, "avg_logprob": -0.21767858664194742, "compression_ratio": 1.5530973451327434, "no_speech_prob": 4.09288668379304e-06}, {"id": 1026, "seek": 478108, "start": 4786.8, "end": 4788.8, "text": " in this approach", "tokens": [294, 341, 3109], "temperature": 0.0, "avg_logprob": -0.21767858664194742, "compression_ratio": 1.5530973451327434, "no_speech_prob": 4.09288668379304e-06}, {"id": 1027, "seek": 478108, "start": 4788.88, "end": 4790.16, "text": " compared to", "tokens": [5347, 281], "temperature": 0.0, "avg_logprob": -0.21767858664194742, "compression_ratio": 1.5530973451327434, "no_speech_prob": 4.09288668379304e-06}, {"id": 1028, "seek": 478108, "start": 4790.16, "end": 4794.36, "text": " This the super resolution stuff and we'll talk about why in a moment", "tokens": [639, 264, 1687, 8669, 1507, 293, 321, 603, 751, 466, 983, 294, 257, 1623], "temperature": 0.0, "avg_logprob": -0.21767858664194742, "compression_ratio": 1.5530973451327434, "no_speech_prob": 4.09288668379304e-06}, {"id": 1029, "seek": 478108, "start": 4794.6, "end": 4799.2, "text": " So you'll see this is like much more normal looking, you know, I've got batch norm layers", "tokens": [407, 291, 603, 536, 341, 307, 411, 709, 544, 2710, 1237, 11, 291, 458, 11, 286, 600, 658, 15245, 2026, 7914], "temperature": 0.0, "avg_logprob": -0.21767858664194742, "compression_ratio": 1.5530973451327434, "no_speech_prob": 4.09288668379304e-06}, {"id": 1030, "seek": 478108, "start": 4800.04, "end": 4801.6, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.21767858664194742, "compression_ratio": 1.5530973451327434, "no_speech_prob": 4.09288668379304e-06}, {"id": 1031, "seek": 478108, "start": 4801.6, "end": 4804.64, "text": " Don't have the scaling factor here", "tokens": [1468, 380, 362, 264, 21589, 5952, 510], "temperature": 0.0, "avg_logprob": -0.21767858664194742, "compression_ratio": 1.5530973451327434, "no_speech_prob": 4.09288668379304e-06}, {"id": 1032, "seek": 478108, "start": 4806.32, "end": 4808.36, "text": " You know, I don't have a pixel shuffle", "tokens": [509, 458, 11, 286, 500, 380, 362, 257, 19261, 39426], "temperature": 0.0, "avg_logprob": -0.21767858664194742, "compression_ratio": 1.5530973451327434, "no_speech_prob": 4.09288668379304e-06}, {"id": 1033, "seek": 480836, "start": 4808.36, "end": 4811.16, "text": " It's just using a normal up sampling followed by one by one conge", "tokens": [467, 311, 445, 1228, 257, 2710, 493, 21179, 6263, 538, 472, 538, 472, 416, 432], "temperature": 0.0, "avg_logprob": -0.1573793511641653, "compression_ratio": 1.7359307359307359, "no_speech_prob": 7.889159860496875e-06}, {"id": 1034, "seek": 480836, "start": 4811.92, "end": 4814.799999999999, "text": " Right, so it's kind of it's just more normal", "tokens": [1779, 11, 370, 309, 311, 733, 295, 309, 311, 445, 544, 2710], "temperature": 0.0, "avg_logprob": -0.1573793511641653, "compression_ratio": 1.7359307359307359, "no_speech_prob": 7.889159860496875e-06}, {"id": 1035, "seek": 480836, "start": 4815.48, "end": 4818.839999999999, "text": " one thing they mentioned in the paper is they had a lot of problems with", "tokens": [472, 551, 436, 2835, 294, 264, 3035, 307, 436, 632, 257, 688, 295, 2740, 365], "temperature": 0.0, "avg_logprob": -0.1573793511641653, "compression_ratio": 1.7359307359307359, "no_speech_prob": 7.889159860496875e-06}, {"id": 1036, "seek": 480836, "start": 4820.719999999999, "end": 4827.759999999999, "text": " Zero padding creating artifacts and the way they solved that was by adding 40 pixels of reflection padding at the start", "tokens": [17182, 39562, 4084, 24617, 293, 264, 636, 436, 13041, 300, 390, 538, 5127, 3356, 18668, 295, 12914, 39562, 412, 264, 722], "temperature": 0.0, "avg_logprob": -0.1573793511641653, "compression_ratio": 1.7359307359307359, "no_speech_prob": 7.889159860496875e-06}, {"id": 1037, "seek": 480836, "start": 4828.4, "end": 4835.0, "text": " So I did the same thing and then they used zero padding in their convolutions in their res blocks", "tokens": [407, 286, 630, 264, 912, 551, 293, 550, 436, 1143, 4018, 39562, 294, 641, 3754, 15892, 294, 641, 725, 8474], "temperature": 0.0, "avg_logprob": -0.1573793511641653, "compression_ratio": 1.7359307359307359, "no_speech_prob": 7.889159860496875e-06}, {"id": 1038, "seek": 483500, "start": 4835.0, "end": 4839.0, "text": " Now if you've got zero padding in your convolution in your res blocks", "tokens": [823, 498, 291, 600, 658, 4018, 39562, 294, 428, 45216, 294, 428, 725, 8474], "temperature": 0.0, "avg_logprob": -0.17563516953412225, "compression_ratio": 1.7028112449799198, "no_speech_prob": 2.994418764501461e-06}, {"id": 1039, "seek": 483500, "start": 4839.32, "end": 4843.24, "text": " Then that means that your the two parts of your resnet won't add up anymore", "tokens": [1396, 300, 1355, 300, 428, 264, 732, 3166, 295, 428, 725, 7129, 1582, 380, 909, 493, 3602], "temperature": 0.0, "avg_logprob": -0.17563516953412225, "compression_ratio": 1.7028112449799198, "no_speech_prob": 2.994418764501461e-06}, {"id": 1040, "seek": 483500, "start": 4844.32, "end": 4848.44, "text": " Because you've lost a pixel from each side on each of your two convolutions", "tokens": [1436, 291, 600, 2731, 257, 19261, 490, 1184, 1252, 322, 1184, 295, 428, 732, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.17563516953412225, "compression_ratio": 1.7028112449799198, "no_speech_prob": 2.994418764501461e-06}, {"id": 1041, "seek": 483500, "start": 4848.68, "end": 4855.84, "text": " So my my res sequential has become res sequential center and I've removed the last two pixels", "tokens": [407, 452, 452, 725, 42881, 575, 1813, 725, 42881, 3056, 293, 286, 600, 7261, 264, 1036, 732, 18668], "temperature": 0.0, "avg_logprob": -0.17563516953412225, "compression_ratio": 1.7028112449799198, "no_speech_prob": 2.994418764501461e-06}, {"id": 1042, "seek": 483500, "start": 4855.92, "end": 4862.12, "text": " On each side of those good cells. Okay. So other than that, this is basically the same as what we had before", "tokens": [1282, 1184, 1252, 295, 729, 665, 5438, 13, 1033, 13, 407, 661, 813, 300, 11, 341, 307, 1936, 264, 912, 382, 437, 321, 632, 949], "temperature": 0.0, "avg_logprob": -0.17563516953412225, "compression_ratio": 1.7028112449799198, "no_speech_prob": 2.994418764501461e-06}, {"id": 1043, "seek": 486212, "start": 4862.12, "end": 4868.68, "text": " So then we can bring in our starry night picture we can resize it", "tokens": [407, 550, 321, 393, 1565, 294, 527, 3543, 627, 1818, 3036, 321, 393, 50069, 309], "temperature": 0.0, "avg_logprob": -0.22358989715576172, "compression_ratio": 1.7122641509433962, "no_speech_prob": 2.684190121726715e-06}, {"id": 1044, "seek": 486212, "start": 4869.599999999999, "end": 4871.68, "text": " We can throw it through our transformations", "tokens": [492, 393, 3507, 309, 807, 527, 34852], "temperature": 0.0, "avg_logprob": -0.22358989715576172, "compression_ratio": 1.7122641509433962, "no_speech_prob": 2.684190121726715e-06}, {"id": 1045, "seek": 486212, "start": 4873.5599999999995, "end": 4875.5599999999995, "text": " Just to make the", "tokens": [1449, 281, 652, 264], "temperature": 0.0, "avg_logprob": -0.22358989715576172, "compression_ratio": 1.7122641509433962, "no_speech_prob": 2.684190121726715e-06}, {"id": 1046, "seek": 486212, "start": 4876.4, "end": 4879.96, "text": " Method a little bit easier for my brain to handle. I took my", "tokens": [25285, 257, 707, 857, 3571, 337, 452, 3567, 281, 4813, 13, 286, 1890, 452], "temperature": 0.0, "avg_logprob": -0.22358989715576172, "compression_ratio": 1.7122641509433962, "no_speech_prob": 2.684190121726715e-06}, {"id": 1047, "seek": 486212, "start": 4880.88, "end": 4887.92, "text": " Transformation image which after transform transform style image which after transformations is 3 by 2 5 6 by 2 5 6 and I made", "tokens": [6531, 8663, 3256, 597, 934, 4088, 4088, 3758, 3256, 597, 934, 34852, 307, 805, 538, 568, 1025, 1386, 538, 568, 1025, 1386, 293, 286, 1027], "temperature": 0.0, "avg_logprob": -0.22358989715576172, "compression_ratio": 1.7122641509433962, "no_speech_prob": 2.684190121726715e-06}, {"id": 1048, "seek": 486212, "start": 4887.92, "end": 4889.24, "text": " a mini batch", "tokens": [257, 8382, 15245], "temperature": 0.0, "avg_logprob": -0.22358989715576172, "compression_ratio": 1.7122641509433962, "no_speech_prob": 2.684190121726715e-06}, {"id": 1049, "seek": 488924, "start": 4889.24, "end": 4895.28, "text": " My batch size is 24 24 copies of it that just makes it a little bit easier to do the kind of batch", "tokens": [1222, 15245, 2744, 307, 4022, 4022, 14341, 295, 309, 300, 445, 1669, 309, 257, 707, 857, 3571, 281, 360, 264, 733, 295, 15245], "temperature": 0.0, "avg_logprob": -0.23918806879143967, "compression_ratio": 1.4757281553398058, "no_speech_prob": 6.747996394551592e-06}, {"id": 1050, "seek": 488924, "start": 4895.5599999999995, "end": 4903.12, "text": " Arithmetic and without worrying about some of the broadcasting. They're not really 24 copies. I used NP broadcast to to", "tokens": [1587, 41179, 293, 1553, 18788, 466, 512, 295, 264, 30024, 13, 814, 434, 406, 534, 4022, 14341, 13, 286, 1143, 38611, 9975, 281, 281], "temperature": 0.0, "avg_logprob": -0.23918806879143967, "compression_ratio": 1.4757281553398058, "no_speech_prob": 6.747996394551592e-06}, {"id": 1051, "seek": 488924, "start": 4904.8, "end": 4907.84, "text": " Basically fake 24 piece", "tokens": [8537, 7592, 4022, 2522], "temperature": 0.0, "avg_logprob": -0.23918806879143967, "compression_ratio": 1.4757281553398058, "no_speech_prob": 6.747996394551592e-06}, {"id": 1052, "seek": 488924, "start": 4911.44, "end": 4914.84, "text": " Okay, so just like before we create a VGG grab the last block", "tokens": [1033, 11, 370, 445, 411, 949, 321, 1884, 257, 691, 27561, 4444, 264, 1036, 3461], "temperature": 0.0, "avg_logprob": -0.23918806879143967, "compression_ratio": 1.4757281553398058, "no_speech_prob": 6.747996394551592e-06}, {"id": 1053, "seek": 491484, "start": 4914.84, "end": 4922.52, "text": " This time we're going to use all of these layers so we keep everything up to the 43rd layer", "tokens": [639, 565, 321, 434, 516, 281, 764, 439, 295, 613, 7914, 370, 321, 1066, 1203, 493, 281, 264, 17914, 7800, 4583], "temperature": 0.0, "avg_logprob": -0.20194874800644913, "compression_ratio": 1.6858638743455496, "no_speech_prob": 6.5403587541368324e-06}, {"id": 1054, "seek": 491484, "start": 4925.08, "end": 4931.2, "text": " And so now our combined loss is going to add together a content loss for the third block", "tokens": [400, 370, 586, 527, 9354, 4470, 307, 516, 281, 909, 1214, 257, 2701, 4470, 337, 264, 2636, 3461], "temperature": 0.0, "avg_logprob": -0.20194874800644913, "compression_ratio": 1.6858638743455496, "no_speech_prob": 6.5403587541368324e-06}, {"id": 1055, "seek": 491484, "start": 4931.8, "end": 4936.24, "text": " plus the gram loss for all of our blocks with different weights and", "tokens": [1804, 264, 21353, 4470, 337, 439, 295, 527, 8474, 365, 819, 17443, 293], "temperature": 0.0, "avg_logprob": -0.20194874800644913, "compression_ratio": 1.6858638743455496, "no_speech_prob": 6.5403587541368324e-06}, {"id": 1056, "seek": 491484, "start": 4936.56, "end": 4940.92, "text": " so the gram loss and again kind of going back to everything being as like", "tokens": [370, 264, 21353, 4470, 293, 797, 733, 295, 516, 646, 281, 1203, 885, 382, 411], "temperature": 0.0, "avg_logprob": -0.20194874800644913, "compression_ratio": 1.6858638743455496, "no_speech_prob": 6.5403587541368324e-06}, {"id": 1057, "seek": 494092, "start": 4940.92, "end": 4943.96, "text": " Normal as possible. I've gone back to using MSE here", "tokens": [21277, 382, 1944, 13, 286, 600, 2780, 646, 281, 1228, 376, 5879, 510], "temperature": 0.0, "avg_logprob": -0.4077587662456192, "compression_ratio": 1.6447876447876448, "no_speech_prob": 3.2377447496401146e-06}, {"id": 1058, "seek": 494092, "start": 4945.0, "end": 4947.96, "text": " Basically what happened is I had a lot of trouble getting this to train properly", "tokens": [8537, 437, 2011, 307, 286, 632, 257, 688, 295, 5253, 1242, 341, 281, 3847, 6108], "temperature": 0.0, "avg_logprob": -0.4077587662456192, "compression_ratio": 1.6447876447876448, "no_speech_prob": 3.2377447496401146e-06}, {"id": 1059, "seek": 494092, "start": 4947.96, "end": 4953.72, "text": " So I gradually removed trick after trick and eventually just went okay. I'm just going to leave make it as as bland as possible", "tokens": [407, 286, 13145, 7261, 4282, 934, 4282, 293, 4728, 445, 1437, 1392, 13, 286, 478, 445, 516, 281, 1856, 652, 309, 382, 382, 29849, 382, 1944], "temperature": 0.0, "avg_logprob": -0.4077587662456192, "compression_ratio": 1.6447876447876448, "no_speech_prob": 3.2377447496401146e-06}, {"id": 1060, "seek": 494092, "start": 4956.28, "end": 4957.88, "text": " Last", "tokens": [5264], "temperature": 0.0, "avg_logprob": -0.4077587662456192, "compression_ratio": 1.6447876447876448, "no_speech_prob": 3.2377447496401146e-06}, {"id": 1061, "seek": 494092, "start": 4957.88, "end": 4959.88, "text": " Week's gram matrix", "tokens": [12615, 311, 21353, 8141], "temperature": 0.0, "avg_logprob": -0.4077587662456192, "compression_ratio": 1.6447876447876448, "no_speech_prob": 3.2377447496401146e-06}, {"id": 1062, "seek": 494092, "start": 4960.32, "end": 4966.08, "text": " Was wrong by the way it only worked for a batch size of one and we only had a batch size of one so that was fine", "tokens": [3027, 2085, 538, 264, 636, 309, 787, 2732, 337, 257, 15245, 2744, 295, 472, 293, 321, 787, 632, 257, 15245, 2744, 295, 472, 370, 300, 390, 2489], "temperature": 0.0, "avg_logprob": -0.4077587662456192, "compression_ratio": 1.6447876447876448, "no_speech_prob": 3.2377447496401146e-06}, {"id": 1063, "seek": 494092, "start": 4966.68, "end": 4969.4, "text": " I was using matrix multiply", "tokens": [286, 390, 1228, 8141, 12972], "temperature": 0.0, "avg_logprob": -0.4077587662456192, "compression_ratio": 1.6447876447876448, "no_speech_prob": 3.2377447496401146e-06}, {"id": 1064, "seek": 496940, "start": 4969.4, "end": 4973.759999999999, "text": " Which meant that every batch was big being compared to every other batch", "tokens": [3013, 4140, 300, 633, 15245, 390, 955, 885, 5347, 281, 633, 661, 15245], "temperature": 0.0, "avg_logprob": -0.40709615790325665, "compression_ratio": 1.724770642201835, "no_speech_prob": 3.0415737910516327e-06}, {"id": 1065, "seek": 496940, "start": 4973.759999999999, "end": 4979.5199999999995, "text": " You actually need to use batch matrix multiply, which does a matrix multiply per batch", "tokens": [509, 767, 643, 281, 764, 15245, 8141, 12972, 11, 597, 775, 257, 8141, 12972, 680, 15245], "temperature": 0.0, "avg_logprob": -0.40709615790325665, "compression_ratio": 1.724770642201835, "no_speech_prob": 3.0415737910516327e-06}, {"id": 1066, "seek": 496940, "start": 4980.759999999999, "end": 4983.5599999999995, "text": " So that's something to be aware of there, okay", "tokens": [407, 300, 311, 746, 281, 312, 3650, 295, 456, 11, 1392], "temperature": 0.0, "avg_logprob": -0.40709615790325665, "compression_ratio": 1.724770642201835, "no_speech_prob": 3.0415737910516327e-06}, {"id": 1067, "seek": 496940, "start": 4984.36, "end": 4991.48, "text": " So so I've got my gram matrices. I do my MSE loss between the gram matrices. I weight them my style weights", "tokens": [407, 370, 286, 600, 658, 452, 21353, 32284, 13, 286, 360, 452, 376, 5879, 4470, 1296, 264, 21353, 32284, 13, 286, 3364, 552, 452, 3758, 17443], "temperature": 0.0, "avg_logprob": -0.40709615790325665, "compression_ratio": 1.724770642201835, "no_speech_prob": 3.0415737910516327e-06}, {"id": 1068, "seek": 496940, "start": 4993.08, "end": 4997.719999999999, "text": " So I create that ResNet so I create my style my combined loss", "tokens": [407, 286, 1884, 300, 5015, 31890, 370, 286, 1884, 452, 3758, 452, 9354, 4470], "temperature": 0.0, "avg_logprob": -0.40709615790325665, "compression_ratio": 1.724770642201835, "no_speech_prob": 3.0415737910516327e-06}, {"id": 1069, "seek": 499772, "start": 4997.72, "end": 5001.52, "text": " So I create my style my combined loss passing in the VGG network", "tokens": [407, 286, 1884, 452, 3758, 452, 9354, 4470, 8437, 294, 264, 691, 27561, 3209], "temperature": 0.0, "avg_logprob": -0.19799311136462025, "compression_ratio": 1.6327433628318584, "no_speech_prob": 4.289303888072027e-06}, {"id": 1070, "seek": 499772, "start": 5002.04, "end": 5004.04, "text": " Passing in the block IDs", "tokens": [10319, 278, 294, 264, 3461, 48212], "temperature": 0.0, "avg_logprob": -0.19799311136462025, "compression_ratio": 1.6327433628318584, "no_speech_prob": 4.289303888072027e-06}, {"id": 1071, "seek": 499772, "start": 5004.280000000001, "end": 5006.280000000001, "text": " passing in the transformed", "tokens": [8437, 294, 264, 16894], "temperature": 0.0, "avg_logprob": -0.19799311136462025, "compression_ratio": 1.6327433628318584, "no_speech_prob": 4.289303888072027e-06}, {"id": 1072, "seek": 499772, "start": 5007.360000000001, "end": 5011.12, "text": " Starry night image and so you'll see the very start here", "tokens": [5705, 627, 1818, 3256, 293, 370, 291, 603, 536, 264, 588, 722, 510], "temperature": 0.0, "avg_logprob": -0.19799311136462025, "compression_ratio": 1.6327433628318584, "no_speech_prob": 4.289303888072027e-06}, {"id": 1073, "seek": 499772, "start": 5011.12, "end": 5018.240000000001, "text": " I do a forward pass through my VGG model with that starry night image in order that I can save", "tokens": [286, 360, 257, 2128, 1320, 807, 452, 691, 27561, 2316, 365, 300, 3543, 627, 1818, 3256, 294, 1668, 300, 286, 393, 3155], "temperature": 0.0, "avg_logprob": -0.19799311136462025, "compression_ratio": 1.6327433628318584, "no_speech_prob": 4.289303888072027e-06}, {"id": 1074, "seek": 499772, "start": 5018.72, "end": 5021.4800000000005, "text": " The features for it. Okay now notice", "tokens": [440, 4122, 337, 309, 13, 1033, 586, 3449], "temperature": 0.0, "avg_logprob": -0.19799311136462025, "compression_ratio": 1.6327433628318584, "no_speech_prob": 4.289303888072027e-06}, {"id": 1075, "seek": 499772, "start": 5022.12, "end": 5024.64, "text": " It's really important now that I don't do any data augmentation", "tokens": [467, 311, 534, 1021, 586, 300, 286, 500, 380, 360, 604, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.19799311136462025, "compression_ratio": 1.6327433628318584, "no_speech_prob": 4.289303888072027e-06}, {"id": 1076, "seek": 502464, "start": 5024.64, "end": 5029.280000000001, "text": " augmentation because I've saved the style features for a particular", "tokens": [14501, 19631, 570, 286, 600, 6624, 264, 3758, 4122, 337, 257, 1729], "temperature": 0.0, "avg_logprob": -0.18709848324457803, "compression_ratio": 1.6595744680851063, "no_speech_prob": 6.048876457498409e-06}, {"id": 1077, "seek": 502464, "start": 5030.240000000001, "end": 5032.860000000001, "text": " You know non augmented version", "tokens": [509, 458, 2107, 36155, 3037], "temperature": 0.0, "avg_logprob": -0.18709848324457803, "compression_ratio": 1.6595744680851063, "no_speech_prob": 6.048876457498409e-06}, {"id": 1078, "seek": 502464, "start": 5033.4800000000005, "end": 5037.320000000001, "text": " And so if I augmented it it might make some minor problems", "tokens": [400, 370, 498, 286, 36155, 309, 309, 1062, 652, 512, 6696, 2740], "temperature": 0.0, "avg_logprob": -0.18709848324457803, "compression_ratio": 1.6595744680851063, "no_speech_prob": 6.048876457498409e-06}, {"id": 1079, "seek": 502464, "start": 5038.4400000000005, "end": 5043.780000000001, "text": " But that's fine because I've got all of image net to deal with I don't really need to do data augmentation", "tokens": [583, 300, 311, 2489, 570, 286, 600, 658, 439, 295, 3256, 2533, 281, 2028, 365, 286, 500, 380, 534, 643, 281, 360, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.18709848324457803, "compression_ratio": 1.6595744680851063, "no_speech_prob": 6.048876457498409e-06}, {"id": 1080, "seek": 502464, "start": 5044.56, "end": 5046.280000000001, "text": " anyway", "tokens": [4033], "temperature": 0.0, "avg_logprob": -0.18709848324457803, "compression_ratio": 1.6595744680851063, "no_speech_prob": 6.048876457498409e-06}, {"id": 1081, "seek": 504628, "start": 5046.28, "end": 5055.04, "text": " Okay, so I've got my loss function and I can go ahead and fit and there's really nothing clever here at all at the end I", "tokens": [1033, 11, 370, 286, 600, 658, 452, 4470, 2445, 293, 286, 393, 352, 2286, 293, 3318, 293, 456, 311, 534, 1825, 13494, 510, 412, 439, 412, 264, 917, 286], "temperature": 0.0, "avg_logprob": -0.16288636979602633, "compression_ratio": 1.5794392523364487, "no_speech_prob": 2.8130036753282184e-06}, {"id": 1082, "seek": 504628, "start": 5055.44, "end": 5062.92, "text": " Have my sum layers equals false so I can see what each part looks like and see that they're reasonably balanced and I can finally", "tokens": [3560, 452, 2408, 7914, 6915, 7908, 370, 286, 393, 536, 437, 1184, 644, 1542, 411, 293, 536, 300, 436, 434, 23551, 13902, 293, 286, 393, 2721], "temperature": 0.0, "avg_logprob": -0.16288636979602633, "compression_ratio": 1.5794392523364487, "no_speech_prob": 2.8130036753282184e-06}, {"id": 1083, "seek": 504628, "start": 5064.16, "end": 5066.16, "text": " Pop it out", "tokens": [10215, 309, 484], "temperature": 0.0, "avg_logprob": -0.16288636979602633, "compression_ratio": 1.5794392523364487, "no_speech_prob": 2.8130036753282184e-06}, {"id": 1084, "seek": 504628, "start": 5067.08, "end": 5073.24, "text": " So I mentioned that should be pretty easy and yet it took me about four days", "tokens": [407, 286, 2835, 300, 820, 312, 1238, 1858, 293, 1939, 309, 1890, 385, 466, 1451, 1708], "temperature": 0.0, "avg_logprob": -0.16288636979602633, "compression_ratio": 1.5794392523364487, "no_speech_prob": 2.8130036753282184e-06}, {"id": 1085, "seek": 507324, "start": 5073.24, "end": 5076.24, "text": " because it just I", "tokens": [570, 309, 445, 286], "temperature": 0.0, "avg_logprob": -0.2482302983601888, "compression_ratio": 1.5272727272727273, "no_speech_prob": 9.368623977934476e-06}, {"id": 1086, "seek": 507324, "start": 5077.28, "end": 5079.28, "text": " Just found this incredibly", "tokens": [1449, 1352, 341, 6252], "temperature": 0.0, "avg_logprob": -0.2482302983601888, "compression_ratio": 1.5272727272727273, "no_speech_prob": 9.368623977934476e-06}, {"id": 1087, "seek": 507324, "start": 5079.599999999999, "end": 5081.92, "text": " Fiddly to actually get it to work", "tokens": [479, 14273, 356, 281, 767, 483, 309, 281, 589], "temperature": 0.0, "avg_logprob": -0.2482302983601888, "compression_ratio": 1.5272727272727273, "no_speech_prob": 9.368623977934476e-06}, {"id": 1088, "seek": 507324, "start": 5082.28, "end": 5086.36, "text": " So like when I finally got up in the morning, I said to Rachel guess what?", "tokens": [407, 411, 562, 286, 2721, 658, 493, 294, 264, 2446, 11, 286, 848, 281, 14246, 2041, 437, 30], "temperature": 0.0, "avg_logprob": -0.2482302983601888, "compression_ratio": 1.5272727272727273, "no_speech_prob": 9.368623977934476e-06}, {"id": 1089, "seek": 507324, "start": 5086.5599999999995, "end": 5091.2, "text": " They're trained correctly Rachel was like I never thought that was gonna happen", "tokens": [814, 434, 8895, 8944, 14246, 390, 411, 286, 1128, 1194, 300, 390, 799, 1051], "temperature": 0.0, "avg_logprob": -0.2482302983601888, "compression_ratio": 1.5272727272727273, "no_speech_prob": 9.368623977934476e-06}, {"id": 1090, "seek": 507324, "start": 5093.599999999999, "end": 5100.719999999999, "text": " It just it just looked awful all the time and it's really about getting the exact right mix of content", "tokens": [467, 445, 309, 445, 2956, 11232, 439, 264, 565, 293, 309, 311, 534, 466, 1242, 264, 1900, 558, 2890, 295, 2701], "temperature": 0.0, "avg_logprob": -0.2482302983601888, "compression_ratio": 1.5272727272727273, "no_speech_prob": 9.368623977934476e-06}, {"id": 1091, "seek": 510072, "start": 5100.72, "end": 5107.320000000001, "text": " I'll say the style loss of the mix of the layers of the style loss and that the worst part was it takes a really long time", "tokens": [286, 603, 584, 264, 3758, 4470, 295, 264, 2890, 295, 264, 7914, 295, 264, 3758, 4470, 293, 300, 264, 5855, 644, 390, 309, 2516, 257, 534, 938, 565], "temperature": 0.0, "avg_logprob": -0.2022337698721671, "compression_ratio": 1.7941176470588236, "no_speech_prob": 5.01469912705943e-06}, {"id": 1092, "seek": 510072, "start": 5108.240000000001, "end": 5110.240000000001, "text": " to train the damn CNN and", "tokens": [281, 3847, 264, 8151, 24859, 293], "temperature": 0.0, "avg_logprob": -0.2022337698721671, "compression_ratio": 1.7941176470588236, "no_speech_prob": 5.01469912705943e-06}, {"id": 1093, "seek": 510072, "start": 5110.6, "end": 5116.84, "text": " I don't didn't really know how long to train it before before I decided it wasn't doing well", "tokens": [286, 500, 380, 994, 380, 534, 458, 577, 938, 281, 3847, 309, 949, 949, 286, 3047, 309, 2067, 380, 884, 731], "temperature": 0.0, "avg_logprob": -0.2022337698721671, "compression_ratio": 1.7941176470588236, "no_speech_prob": 5.01469912705943e-06}, {"id": 1094, "seek": 510072, "start": 5116.84, "end": 5118.84, "text": " like should I just train it for longer or", "tokens": [411, 820, 286, 445, 3847, 309, 337, 2854, 420], "temperature": 0.0, "avg_logprob": -0.2022337698721671, "compression_ratio": 1.7941176470588236, "no_speech_prob": 5.01469912705943e-06}, {"id": 1095, "seek": 510072, "start": 5119.4400000000005, "end": 5121.4400000000005, "text": " What?", "tokens": [708, 30], "temperature": 0.0, "avg_logprob": -0.2022337698721671, "compression_ratio": 1.7941176470588236, "no_speech_prob": 5.01469912705943e-06}, {"id": 1096, "seek": 510072, "start": 5121.8, "end": 5123.92, "text": " And I don't know all the little details", "tokens": [400, 286, 500, 380, 458, 439, 264, 707, 4365], "temperature": 0.0, "avg_logprob": -0.2022337698721671, "compression_ratio": 1.7941176470588236, "no_speech_prob": 5.01469912705943e-06}, {"id": 1097, "seek": 512392, "start": 5123.92, "end": 5129.92, "text": " Didn't seem to like slightly change it but just like it would totally fall apart all the time. So", "tokens": [11151, 380, 1643, 281, 411, 4748, 1319, 309, 457, 445, 411, 309, 576, 3879, 2100, 4936, 439, 264, 565, 13, 407], "temperature": 0.0, "avg_logprob": -0.22357412286706874, "compression_ratio": 1.504950495049505, "no_speech_prob": 6.048864179319935e-06}, {"id": 1098, "seek": 512392, "start": 5130.8, "end": 5132.4, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.22357412286706874, "compression_ratio": 1.504950495049505, "no_speech_prob": 6.048864179319935e-06}, {"id": 1099, "seek": 512392, "start": 5132.4, "end": 5134.4, "text": " kind of mentioned this", "tokens": [733, 295, 2835, 341], "temperature": 0.0, "avg_logprob": -0.22357412286706874, "compression_ratio": 1.504950495049505, "no_speech_prob": 6.048864179319935e-06}, {"id": 1100, "seek": 512392, "start": 5134.4400000000005, "end": 5136.28, "text": " partly to say like", "tokens": [17031, 281, 584, 411], "temperature": 0.0, "avg_logprob": -0.22357412286706874, "compression_ratio": 1.504950495049505, "no_speech_prob": 6.048864179319935e-06}, {"id": 1101, "seek": 512392, "start": 5136.28, "end": 5139.36, "text": " Just remember the final answer you see here is", "tokens": [1449, 1604, 264, 2572, 1867, 291, 536, 510, 307], "temperature": 0.0, "avg_logprob": -0.22357412286706874, "compression_ratio": 1.504950495049505, "no_speech_prob": 6.048864179319935e-06}, {"id": 1102, "seek": 512392, "start": 5140.12, "end": 5146.36, "text": " After me driving myself crazy or weak of it nearly always not working until finally the last minute it finally does", "tokens": [2381, 385, 4840, 2059, 3219, 420, 5336, 295, 309, 6217, 1009, 406, 1364, 1826, 2721, 264, 1036, 3456, 309, 2721, 775], "temperature": 0.0, "avg_logprob": -0.22357412286706874, "compression_ratio": 1.504950495049505, "no_speech_prob": 6.048864179319935e-06}, {"id": 1103, "seek": 514636, "start": 5146.36, "end": 5155.08, "text": " even for things which just seemed like they couldn't possibly be difficult because they're just combining two things we already have working", "tokens": [754, 337, 721, 597, 445, 6576, 411, 436, 2809, 380, 6264, 312, 2252, 570, 436, 434, 445, 21928, 732, 721, 321, 1217, 362, 1364], "temperature": 0.0, "avg_logprob": -0.17437897031269375, "compression_ratio": 1.4806629834254144, "no_speech_prob": 2.225267508038087e-06}, {"id": 1104, "seek": 514636, "start": 5155.799999999999, "end": 5160.759999999999, "text": " The other is like to be careful about how we interpret what authors claim", "tokens": [440, 661, 307, 411, 281, 312, 5026, 466, 577, 321, 7302, 437, 16552, 3932], "temperature": 0.0, "avg_logprob": -0.17437897031269375, "compression_ratio": 1.4806629834254144, "no_speech_prob": 2.225267508038087e-06}, {"id": 1105, "seek": 514636, "start": 5166.599999999999, "end": 5168.599999999999, "text": " Yeah, so", "tokens": [865, 11, 370], "temperature": 0.0, "avg_logprob": -0.17437897031269375, "compression_ratio": 1.4806629834254144, "no_speech_prob": 2.225267508038087e-06}, {"id": 1106, "seek": 514636, "start": 5170.88, "end": 5172.88, "text": " It was so fiddly getting", "tokens": [467, 390, 370, 283, 14273, 356, 1242], "temperature": 0.0, "avg_logprob": -0.17437897031269375, "compression_ratio": 1.4806629834254144, "no_speech_prob": 2.225267508038087e-06}, {"id": 1107, "seek": 514636, "start": 5173.5599999999995, "end": 5175.5599999999995, "text": " this style transfer", "tokens": [341, 3758, 5003], "temperature": 0.0, "avg_logprob": -0.17437897031269375, "compression_ratio": 1.4806629834254144, "no_speech_prob": 2.225267508038087e-06}, {"id": 1108, "seek": 517556, "start": 5175.56, "end": 5179.120000000001, "text": " To work and like after doing it it left me thinking", "tokens": [1407, 589, 293, 411, 934, 884, 309, 309, 1411, 385, 1953], "temperature": 0.0, "avg_logprob": -0.28700993107814415, "compression_ratio": 1.6865079365079365, "no_speech_prob": 1.0129788279300556e-05}, {"id": 1109, "seek": 517556, "start": 5180.160000000001, "end": 5184.04, "text": " Why did I bother because now I've got something that takes hours?", "tokens": [1545, 630, 286, 8677, 570, 586, 286, 600, 658, 746, 300, 2516, 2496, 30], "temperature": 0.0, "avg_logprob": -0.28700993107814415, "compression_ratio": 1.6865079365079365, "no_speech_prob": 1.0129788279300556e-05}, {"id": 1110, "seek": 517556, "start": 5184.8, "end": 5188.84, "text": " to create a network that can turn any kind of photo into", "tokens": [281, 1884, 257, 3209, 300, 393, 1261, 604, 733, 295, 5052, 666], "temperature": 0.0, "avg_logprob": -0.28700993107814415, "compression_ratio": 1.6865079365079365, "no_speech_prob": 1.0129788279300556e-05}, {"id": 1111, "seek": 517556, "start": 5189.68, "end": 5191.68, "text": " one specific style", "tokens": [472, 2685, 3758], "temperature": 0.0, "avg_logprob": -0.28700993107814415, "compression_ratio": 1.6865079365079365, "no_speech_prob": 1.0129788279300556e-05}, {"id": 1112, "seek": 517556, "start": 5191.68, "end": 5193.4400000000005, "text": " It just seems very unlikely", "tokens": [467, 445, 2544, 588, 17518], "temperature": 0.0, "avg_logprob": -0.28700993107814415, "compression_ratio": 1.6865079365079365, "no_speech_prob": 1.0129788279300556e-05}, {"id": 1113, "seek": 517556, "start": 5193.4400000000005, "end": 5197.6, "text": " I would want that for anything like about the only reason I could think that being useful", "tokens": [286, 576, 528, 300, 337, 1340, 411, 466, 264, 787, 1778, 286, 727, 519, 300, 885, 4420], "temperature": 0.0, "avg_logprob": -0.28700993107814415, "compression_ratio": 1.6865079365079365, "no_speech_prob": 1.0129788279300556e-05}, {"id": 1114, "seek": 519760, "start": 5197.6, "end": 5204.96, "text": " Would be to like do some arty stuff on a video we're able to turn every frame into some style like it's incredibly", "tokens": [6068, 312, 281, 411, 360, 512, 594, 874, 1507, 322, 257, 960, 321, 434, 1075, 281, 1261, 633, 3920, 666, 512, 3758, 411, 309, 311, 6252], "temperature": 0.0, "avg_logprob": -0.26052798827489215, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.20294134831056e-05}, {"id": 1115, "seek": 519760, "start": 5205.64, "end": 5207.400000000001, "text": " Neat thing to what to do", "tokens": [1734, 267, 551, 281, 437, 281, 360], "temperature": 0.0, "avg_logprob": -0.26052798827489215, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.20294134831056e-05}, {"id": 1116, "seek": 519760, "start": 5207.400000000001, "end": 5214.4400000000005, "text": " But you know when I looked at the paper that you know the table saying like oh, we're a thousand times faster", "tokens": [583, 291, 458, 562, 286, 2956, 412, 264, 3035, 300, 291, 458, 264, 3199, 1566, 411, 1954, 11, 321, 434, 257, 4714, 1413, 4663], "temperature": 0.0, "avg_logprob": -0.26052798827489215, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.20294134831056e-05}, {"id": 1117, "seek": 519760, "start": 5214.84, "end": 5216.84, "text": " than the Gaddy's approach", "tokens": [813, 264, 37171, 3173, 311, 3109], "temperature": 0.0, "avg_logprob": -0.26052798827489215, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.20294134831056e-05}, {"id": 1118, "seek": 519760, "start": 5216.88, "end": 5218.88, "text": " Which is like it's just", "tokens": [3013, 307, 411, 309, 311, 445], "temperature": 0.0, "avg_logprob": -0.26052798827489215, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.20294134831056e-05}, {"id": 1119, "seek": 519760, "start": 5219.4400000000005, "end": 5223.92, "text": " such an obviously meaningless thing to say and such an incredibly kind of", "tokens": [1270, 364, 2745, 33232, 551, 281, 584, 293, 1270, 364, 6252, 733, 295], "temperature": 0.0, "avg_logprob": -0.26052798827489215, "compression_ratio": 1.7031963470319635, "no_speech_prob": 1.20294134831056e-05}, {"id": 1120, "seek": 522392, "start": 5223.92, "end": 5230.2, "text": " Misleading thing to say because it ignores all the hours of training for each individual", "tokens": [23240, 28012, 551, 281, 584, 570, 309, 5335, 2706, 439, 264, 2496, 295, 3097, 337, 1184, 2609], "temperature": 0.0, "avg_logprob": -0.25615242381154757, "compression_ratio": 1.6, "no_speech_prob": 5.594283265963895e-06}, {"id": 1121, "seek": 522392, "start": 5231.12, "end": 5234.84, "text": " style and I don't know I find this frustrating because like a", "tokens": [3758, 293, 286, 500, 380, 458, 286, 915, 341, 16522, 570, 411, 257], "temperature": 0.0, "avg_logprob": -0.25615242381154757, "compression_ratio": 1.6, "no_speech_prob": 5.594283265963895e-06}, {"id": 1122, "seek": 522392, "start": 5235.88, "end": 5242.12, "text": " Groups like this Stanford group clearly no better or ought to know better, but still I guess the academic", "tokens": [10500, 82, 411, 341, 20374, 1594, 4448, 572, 1101, 420, 13416, 281, 458, 1101, 11, 457, 920, 286, 2041, 264, 7778], "temperature": 0.0, "avg_logprob": -0.25615242381154757, "compression_ratio": 1.6, "no_speech_prob": 5.594283265963895e-06}, {"id": 1123, "seek": 522392, "start": 5243.0, "end": 5245.58, "text": " community kind of encourages people to make these", "tokens": [1768, 733, 295, 28071, 561, 281, 652, 613], "temperature": 0.0, "avg_logprob": -0.25615242381154757, "compression_ratio": 1.6, "no_speech_prob": 5.594283265963895e-06}, {"id": 1124, "seek": 522392, "start": 5246.84, "end": 5251.12, "text": " ridiculously grand claims and it also completely ignores this", "tokens": [41358, 2697, 9441, 293, 309, 611, 2584, 5335, 2706, 341], "temperature": 0.0, "avg_logprob": -0.25615242381154757, "compression_ratio": 1.6, "no_speech_prob": 5.594283265963895e-06}, {"id": 1125, "seek": 525112, "start": 5251.12, "end": 5252.96, "text": " incredibly", "tokens": [6252], "temperature": 0.0, "avg_logprob": -0.2474248700025605, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.5559560274123214e-06}, {"id": 1126, "seek": 525112, "start": 5252.96, "end": 5254.5199999999995, "text": " sensitive", "tokens": [9477], "temperature": 0.0, "avg_logprob": -0.2474248700025605, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.5559560274123214e-06}, {"id": 1127, "seek": 525112, "start": 5254.5199999999995, "end": 5256.76, "text": " fiddly training process", "tokens": [283, 14273, 356, 3097, 1399], "temperature": 0.0, "avg_logprob": -0.2474248700025605, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.5559560274123214e-06}, {"id": 1128, "seek": 525112, "start": 5257.8, "end": 5259.8, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.2474248700025605, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.5559560274123214e-06}, {"id": 1129, "seek": 525112, "start": 5260.2, "end": 5264.48, "text": " You know this paper was just so well accepted when it came out", "tokens": [509, 458, 341, 3035, 390, 445, 370, 731, 9035, 562, 309, 1361, 484], "temperature": 0.0, "avg_logprob": -0.2474248700025605, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.5559560274123214e-06}, {"id": 1130, "seek": 525112, "start": 5264.48, "end": 5269.28, "text": " you know I remember everybody getting on Twitter and being like wow you know these Stanford people have found this way of", "tokens": [291, 458, 286, 1604, 2201, 1242, 322, 5794, 293, 885, 411, 6076, 291, 458, 613, 20374, 561, 362, 1352, 341, 636, 295], "temperature": 0.0, "avg_logprob": -0.2474248700025605, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.5559560274123214e-06}, {"id": 1131, "seek": 525112, "start": 5269.5199999999995, "end": 5272.32, "text": " doing style transfer a thousand times faster and", "tokens": [884, 3758, 5003, 257, 4714, 1413, 4663, 293], "temperature": 0.0, "avg_logprob": -0.2474248700025605, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.5559560274123214e-06}, {"id": 1132, "seek": 525112, "start": 5273.8, "end": 5277.7, "text": " Clearly you know all the people saying this were like all like top", "tokens": [24120, 291, 458, 439, 264, 561, 1566, 341, 645, 411, 439, 411, 1192], "temperature": 0.0, "avg_logprob": -0.2474248700025605, "compression_ratio": 1.6338028169014085, "no_speech_prob": 3.5559560274123214e-06}, {"id": 1133, "seek": 527770, "start": 5277.7, "end": 5283.0599999999995, "text": " researchers in the field but clearly like none of them actually understood it because nobody said", "tokens": [10309, 294, 264, 2519, 457, 4448, 411, 6022, 295, 552, 767, 7320, 309, 570, 5079, 848], "temperature": 0.0, "avg_logprob": -0.1629759814288165, "compression_ratio": 1.6974169741697418, "no_speech_prob": 8.267742487078067e-06}, {"id": 1134, "seek": 527770, "start": 5284.38, "end": 5290.22, "text": " You know I don't see why this is remotely useful and also I tried it and it was incredibly fiddly to get it all to work", "tokens": [509, 458, 286, 500, 380, 536, 983, 341, 307, 20824, 4420, 293, 611, 286, 3031, 309, 293, 309, 390, 6252, 283, 14273, 356, 281, 483, 309, 439, 281, 589], "temperature": 0.0, "avg_logprob": -0.1629759814288165, "compression_ratio": 1.6974169741697418, "no_speech_prob": 8.267742487078067e-06}, {"id": 1135, "seek": 527770, "start": 5290.22, "end": 5297.179999999999, "text": " And so it's not until like what is this now like 18 months later or something that I finally coming back to earth and kind", "tokens": [400, 370, 309, 311, 406, 1826, 411, 437, 307, 341, 586, 411, 2443, 2493, 1780, 420, 746, 300, 286, 2721, 1348, 646, 281, 4120, 293, 733], "temperature": 0.0, "avg_logprob": -0.1629759814288165, "compression_ratio": 1.6974169741697418, "no_speech_prob": 8.267742487078067e-06}, {"id": 1136, "seek": 527770, "start": 5297.179999999999, "end": 5299.179999999999, "text": " Of thinking like wait a minute", "tokens": [2720, 1953, 411, 1699, 257, 3456], "temperature": 0.0, "avg_logprob": -0.1629759814288165, "compression_ratio": 1.6974169741697418, "no_speech_prob": 8.267742487078067e-06}, {"id": 1137, "seek": 527770, "start": 5299.38, "end": 5301.94, "text": " this is kind of stupid and so", "tokens": [341, 307, 733, 295, 6631, 293, 370], "temperature": 0.0, "avg_logprob": -0.1629759814288165, "compression_ratio": 1.6974169741697418, "no_speech_prob": 8.267742487078067e-06}, {"id": 1138, "seek": 527770, "start": 5303.34, "end": 5305.66, "text": " So this is the answer I think to the question of like well", "tokens": [407, 341, 307, 264, 1867, 286, 519, 281, 264, 1168, 295, 411, 731], "temperature": 0.0, "avg_logprob": -0.1629759814288165, "compression_ratio": 1.6974169741697418, "no_speech_prob": 8.267742487078067e-06}, {"id": 1139, "seek": 530566, "start": 5305.66, "end": 5312.42, "text": " Why haven't people done follow-ups on this to like create really amazing best practices and better approaches like with a super resolution part of the paper?", "tokens": [1545, 2378, 380, 561, 1096, 1524, 12, 7528, 322, 341, 281, 411, 1884, 534, 2243, 1151, 7525, 293, 1101, 11587, 411, 365, 257, 1687, 8669, 644, 295, 264, 3035, 30], "temperature": 0.0, "avg_logprob": -0.14339240074157714, "compression_ratio": 1.794238683127572, "no_speech_prob": 2.2827201973996125e-05}, {"id": 1140, "seek": 530566, "start": 5312.42, "end": 5314.42, "text": " And I think the answer is because it's done", "tokens": [400, 286, 519, 264, 1867, 307, 570, 309, 311, 1096], "temperature": 0.0, "avg_logprob": -0.14339240074157714, "compression_ratio": 1.794238683127572, "no_speech_prob": 2.2827201973996125e-05}, {"id": 1141, "seek": 530566, "start": 5316.3, "end": 5318.3, "text": " So I think", "tokens": [407, 286, 519], "temperature": 0.0, "avg_logprob": -0.14339240074157714, "compression_ratio": 1.794238683127572, "no_speech_prob": 2.2827201973996125e-05}, {"id": 1142, "seek": 530566, "start": 5319.62, "end": 5321.76, "text": " This part of the paper is clearly not done", "tokens": [639, 644, 295, 264, 3035, 307, 4448, 406, 1096], "temperature": 0.0, "avg_logprob": -0.14339240074157714, "compression_ratio": 1.794238683127572, "no_speech_prob": 2.2827201973996125e-05}, {"id": 1143, "seek": 530566, "start": 5321.98, "end": 5326.38, "text": " You know and it's been improved and improved and improved and now", "tokens": [509, 458, 293, 309, 311, 668, 9689, 293, 9689, 293, 9689, 293, 586], "temperature": 0.0, "avg_logprob": -0.14339240074157714, "compression_ratio": 1.794238683127572, "no_speech_prob": 2.2827201973996125e-05}, {"id": 1144, "seek": 530566, "start": 5326.84, "end": 5333.26, "text": " We have great super resolution, and I think we can derive from that great noise reduction great colorization great", "tokens": [492, 362, 869, 1687, 8669, 11, 293, 286, 519, 321, 393, 28446, 490, 300, 869, 5658, 11004, 869, 2017, 2144, 869], "temperature": 0.0, "avg_logprob": -0.14339240074157714, "compression_ratio": 1.794238683127572, "no_speech_prob": 2.2827201973996125e-05}, {"id": 1145, "seek": 533326, "start": 5333.26, "end": 5335.26, "text": " You know slant removal", "tokens": [509, 458, 1061, 394, 17933], "temperature": 0.0, "avg_logprob": -0.2184162375367718, "compression_ratio": 1.5147058823529411, "no_speech_prob": 1.1125382116006222e-05}, {"id": 1146, "seek": 533326, "start": 5337.46, "end": 5339.18, "text": " Great", "tokens": [3769], "temperature": 0.0, "avg_logprob": -0.2184162375367718, "compression_ratio": 1.5147058823529411, "no_speech_prob": 1.1125382116006222e-05}, {"id": 1147, "seek": 533326, "start": 5339.18, "end": 5342.820000000001, "text": " Interactive artifact removal or whatever else so I think", "tokens": [5751, 12596, 34806, 17933, 420, 2035, 1646, 370, 286, 519], "temperature": 0.0, "avg_logprob": -0.2184162375367718, "compression_ratio": 1.5147058823529411, "no_speech_prob": 1.1125382116006222e-05}, {"id": 1148, "seek": 533326, "start": 5344.3, "end": 5346.3, "text": " There's a lot of really cool", "tokens": [821, 311, 257, 688, 295, 534, 1627], "temperature": 0.0, "avg_logprob": -0.2184162375367718, "compression_ratio": 1.5147058823529411, "no_speech_prob": 1.1125382116006222e-05}, {"id": 1149, "seek": 533326, "start": 5346.34, "end": 5350.58, "text": " Techniques here. It's also leveraging a lot of stuff that we've been learning and getting better and better at", "tokens": [8337, 4911, 510, 13, 467, 311, 611, 32666, 257, 688, 295, 1507, 300, 321, 600, 668, 2539, 293, 1242, 1101, 293, 1101, 412], "temperature": 0.0, "avg_logprob": -0.2184162375367718, "compression_ratio": 1.5147058823529411, "no_speech_prob": 1.1125382116006222e-05}, {"id": 1150, "seek": 533326, "start": 5352.22, "end": 5354.62, "text": " Okay, so then finally let's talk about", "tokens": [1033, 11, 370, 550, 2721, 718, 311, 751, 466], "temperature": 0.0, "avg_logprob": -0.2184162375367718, "compression_ratio": 1.5147058823529411, "no_speech_prob": 1.1125382116006222e-05}, {"id": 1151, "seek": 533326, "start": 5356.22, "end": 5358.860000000001, "text": " Segmentation this is from the famous cam vid", "tokens": [1100, 10433, 399, 341, 307, 490, 264, 4618, 1945, 7217], "temperature": 0.0, "avg_logprob": -0.2184162375367718, "compression_ratio": 1.5147058823529411, "no_speech_prob": 1.1125382116006222e-05}, {"id": 1152, "seek": 535886, "start": 5358.86, "end": 5365.74, "text": " Data set which is a classic example of an academic segmentation data set and basically you can see what we do is we start with a", "tokens": [11888, 992, 597, 307, 257, 7230, 1365, 295, 364, 7778, 9469, 399, 1412, 992, 293, 1936, 291, 393, 536, 437, 321, 360, 307, 321, 722, 365, 257], "temperature": 0.0, "avg_logprob": -0.1968659201821128, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.3630988178192638e-05}, {"id": 1153, "seek": 535886, "start": 5366.0599999999995, "end": 5369.099999999999, "text": " picture there actually video frames in this data set like here and", "tokens": [3036, 456, 767, 960, 12083, 294, 341, 1412, 992, 411, 510, 293], "temperature": 0.0, "avg_logprob": -0.1968659201821128, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.3630988178192638e-05}, {"id": 1154, "seek": 535886, "start": 5370.5, "end": 5373.299999999999, "text": " We construct we have some labels", "tokens": [492, 7690, 321, 362, 512, 16949], "temperature": 0.0, "avg_logprob": -0.1968659201821128, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.3630988178192638e-05}, {"id": 1155, "seek": 535886, "start": 5374.42, "end": 5376.42, "text": " where", "tokens": [689], "temperature": 0.0, "avg_logprob": -0.1968659201821128, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.3630988178192638e-05}, {"id": 1156, "seek": 535886, "start": 5376.78, "end": 5381.74, "text": " They're not actually colors that each one has an ID and the IDs are matched colors", "tokens": [814, 434, 406, 767, 4577, 300, 1184, 472, 575, 364, 7348, 293, 264, 48212, 366, 21447, 4577], "temperature": 0.0, "avg_logprob": -0.1968659201821128, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.3630988178192638e-05}, {"id": 1157, "seek": 535886, "start": 5381.74, "end": 5386.099999999999, "text": " So like red might be one purple might be two light pink might be", "tokens": [407, 411, 2182, 1062, 312, 472, 9656, 1062, 312, 732, 1442, 7022, 1062, 312], "temperature": 0.0, "avg_logprob": -0.1968659201821128, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.3630988178192638e-05}, {"id": 1158, "seek": 538610, "start": 5386.1, "end": 5389.14, "text": " Three and so all the buildings", "tokens": [6244, 293, 370, 439, 264, 7446], "temperature": 0.0, "avg_logprob": -0.2651674137559048, "compression_ratio": 1.7673267326732673, "no_speech_prob": 7.4111749199801125e-06}, {"id": 1159, "seek": 538610, "start": 5389.660000000001, "end": 5395.9800000000005, "text": " You know one class or the cars or another class all the people or another class", "tokens": [509, 458, 472, 1508, 420, 264, 5163, 420, 1071, 1508, 439, 264, 561, 420, 1071, 1508], "temperature": 0.0, "avg_logprob": -0.2651674137559048, "compression_ratio": 1.7673267326732673, "no_speech_prob": 7.4111749199801125e-06}, {"id": 1160, "seek": 538610, "start": 5396.18, "end": 5401.34, "text": " All the road is another class and so what we're actually doing here is multi-class", "tokens": [1057, 264, 3060, 307, 1071, 1508, 293, 370, 437, 321, 434, 767, 884, 510, 307, 4825, 12, 11665], "temperature": 0.0, "avg_logprob": -0.2651674137559048, "compression_ratio": 1.7673267326732673, "no_speech_prob": 7.4111749199801125e-06}, {"id": 1161, "seek": 538610, "start": 5401.9800000000005, "end": 5403.02, "text": " classification", "tokens": [21538], "temperature": 0.0, "avg_logprob": -0.2651674137559048, "compression_ratio": 1.7673267326732673, "no_speech_prob": 7.4111749199801125e-06}, {"id": 1162, "seek": 538610, "start": 5403.02, "end": 5405.02, "text": " for every pixel", "tokens": [337, 633, 19261], "temperature": 0.0, "avg_logprob": -0.2651674137559048, "compression_ratio": 1.7673267326732673, "no_speech_prob": 7.4111749199801125e-06}, {"id": 1163, "seek": 538610, "start": 5405.42, "end": 5409.14, "text": " Okay, and so you can see sometimes that multi-class classification", "tokens": [1033, 11, 293, 370, 291, 393, 536, 2171, 300, 4825, 12, 11665, 21538], "temperature": 0.0, "avg_logprob": -0.2651674137559048, "compression_ratio": 1.7673267326732673, "no_speech_prob": 7.4111749199801125e-06}, {"id": 1164, "seek": 538610, "start": 5409.700000000001, "end": 5413.18, "text": " Really is quite tricky. There's you know like like these branches", "tokens": [4083, 307, 1596, 12414, 13, 821, 311, 291, 458, 411, 411, 613, 14770], "temperature": 0.0, "avg_logprob": -0.2651674137559048, "compression_ratio": 1.7673267326732673, "no_speech_prob": 7.4111749199801125e-06}, {"id": 1165, "seek": 541318, "start": 5413.18, "end": 5418.900000000001, "text": " Although sometimes the labels are really not that great. You know, this is very coarse as you can see", "tokens": [5780, 2171, 264, 16949, 366, 534, 406, 300, 869, 13, 509, 458, 11, 341, 307, 588, 39312, 382, 291, 393, 536], "temperature": 0.0, "avg_logprob": -0.17069008326766513, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.966955318901455e-06}, {"id": 1166, "seek": 541318, "start": 5421.02, "end": 5423.02, "text": " So here are traffic lights", "tokens": [407, 510, 366, 6419, 5811], "temperature": 0.0, "avg_logprob": -0.17069008326766513, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.966955318901455e-06}, {"id": 1167, "seek": 541318, "start": 5424.860000000001, "end": 5430.4400000000005, "text": " So that's what we're gonna do we're gonna do this is a segmentation and so it's a lot like bounding boxes", "tokens": [407, 300, 311, 437, 321, 434, 799, 360, 321, 434, 799, 360, 341, 307, 257, 9469, 399, 293, 370, 309, 311, 257, 688, 411, 5472, 278, 9002], "temperature": 0.0, "avg_logprob": -0.17069008326766513, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.966955318901455e-06}, {"id": 1168, "seek": 541318, "start": 5431.1, "end": 5436.9400000000005, "text": " Okay, but you know rather than just finding, you know a box around each thing", "tokens": [1033, 11, 457, 291, 458, 2831, 813, 445, 5006, 11, 291, 458, 257, 2424, 926, 1184, 551], "temperature": 0.0, "avg_logprob": -0.17069008326766513, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.966955318901455e-06}, {"id": 1169, "seek": 543694, "start": 5436.94, "end": 5443.219999999999, "text": " We're actually going to label every single pixel with its class and really that's actually a lot easier", "tokens": [492, 434, 767, 516, 281, 7645, 633, 2167, 19261, 365, 1080, 1508, 293, 534, 300, 311, 767, 257, 688, 3571], "temperature": 0.0, "avg_logprob": -0.24328458574083117, "compression_ratio": 1.5708154506437768, "no_speech_prob": 7.183201432781061e-06}, {"id": 1170, "seek": 543694, "start": 5444.219999999999, "end": 5445.5, "text": " because", "tokens": [570], "temperature": 0.0, "avg_logprob": -0.24328458574083117, "compression_ratio": 1.5708154506437768, "no_speech_prob": 7.183201432781061e-06}, {"id": 1171, "seek": 543694, "start": 5445.5, "end": 5452.2, "text": " It fits our CNN style so nicely that we basically we could create any CNN", "tokens": [467, 9001, 527, 24859, 3758, 370, 9594, 300, 321, 1936, 321, 727, 1884, 604, 24859], "temperature": 0.0, "avg_logprob": -0.24328458574083117, "compression_ratio": 1.5708154506437768, "no_speech_prob": 7.183201432781061e-06}, {"id": 1172, "seek": 543694, "start": 5452.46, "end": 5456.219999999999, "text": " Where the output is an n by m grid?", "tokens": [2305, 264, 5598, 307, 364, 297, 538, 275, 10748, 30], "temperature": 0.0, "avg_logprob": -0.24328458574083117, "compression_ratio": 1.5708154506437768, "no_speech_prob": 7.183201432781061e-06}, {"id": 1173, "seek": 543694, "start": 5457.94, "end": 5464.66, "text": " Containing the integers from 0 to C where there are C categories and then we can use cross entropy loss with a softmax activation", "tokens": [4839, 3686, 264, 41674, 490, 1958, 281, 383, 689, 456, 366, 383, 10479, 293, 550, 321, 393, 764, 3278, 30867, 4470, 365, 257, 2787, 41167, 24433], "temperature": 0.0, "avg_logprob": -0.24328458574083117, "compression_ratio": 1.5708154506437768, "no_speech_prob": 7.183201432781061e-06}, {"id": 1174, "seek": 543694, "start": 5464.9, "end": 5466.219999999999, "text": " And we're done", "tokens": [400, 321, 434, 1096], "temperature": 0.0, "avg_logprob": -0.24328458574083117, "compression_ratio": 1.5708154506437768, "no_speech_prob": 7.183201432781061e-06}, {"id": 1175, "seek": 546622, "start": 5466.22, "end": 5472.860000000001, "text": " Right. So like I could actually stop the class there and you can go and use exactly the approaches you've learned in like lessons one", "tokens": [1779, 13, 407, 411, 286, 727, 767, 1590, 264, 1508, 456, 293, 291, 393, 352, 293, 764, 2293, 264, 11587, 291, 600, 3264, 294, 411, 8820, 472], "temperature": 0.0, "avg_logprob": -0.2053233127967984, "compression_ratio": 1.702928870292887, "no_speech_prob": 8.139596502587665e-06}, {"id": 1176, "seek": 546622, "start": 5472.860000000001, "end": 5476.46, "text": " And two and you'll get a perfectly okay result", "tokens": [400, 732, 293, 291, 603, 483, 257, 6239, 1392, 1874], "temperature": 0.0, "avg_logprob": -0.2053233127967984, "compression_ratio": 1.702928870292887, "no_speech_prob": 8.139596502587665e-06}, {"id": 1177, "seek": 546622, "start": 5476.66, "end": 5481.66, "text": " Right. So the first thing to say is like this is not actually a terribly hard thing to do", "tokens": [1779, 13, 407, 264, 700, 551, 281, 584, 307, 411, 341, 307, 406, 767, 257, 22903, 1152, 551, 281, 360], "temperature": 0.0, "avg_logprob": -0.2053233127967984, "compression_ratio": 1.702928870292887, "no_speech_prob": 8.139596502587665e-06}, {"id": 1178, "seek": 546622, "start": 5481.7, "end": 5483.8, "text": " But we're gonna try and do it really well", "tokens": [583, 321, 434, 799, 853, 293, 360, 309, 534, 731], "temperature": 0.0, "avg_logprob": -0.2053233127967984, "compression_ratio": 1.702928870292887, "no_speech_prob": 8.139596502587665e-06}, {"id": 1179, "seek": 546622, "start": 5485.26, "end": 5492.42, "text": " And so let's start by doing it the really simple way and we're going to use the Kaggle carvana", "tokens": [400, 370, 718, 311, 722, 538, 884, 309, 264, 534, 2199, 636, 293, 321, 434, 516, 281, 764, 264, 48751, 22631, 1032, 39259], "temperature": 0.0, "avg_logprob": -0.2053233127967984, "compression_ratio": 1.702928870292887, "no_speech_prob": 8.139596502587665e-06}, {"id": 1180, "seek": 549242, "start": 5492.42, "end": 5497.74, "text": " Competition so you Google capital carvana to find it. You can download it with the Kaggle API as per usual", "tokens": [43634, 370, 291, 3329, 4238, 1032, 39259, 281, 915, 309, 13, 509, 393, 5484, 309, 365, 264, 48751, 22631, 9362, 382, 680, 7713], "temperature": 0.0, "avg_logprob": -0.27442499534370973, "compression_ratio": 1.7966101694915255, "no_speech_prob": 2.601603910079575e-06}, {"id": 1181, "seek": 549242, "start": 5498.46, "end": 5502.66, "text": " And basically there's a train folder containing a bunch of images", "tokens": [400, 1936, 456, 311, 257, 3847, 10820, 19273, 257, 3840, 295, 5267], "temperature": 0.0, "avg_logprob": -0.27442499534370973, "compression_ratio": 1.7966101694915255, "no_speech_prob": 2.601603910079575e-06}, {"id": 1182, "seek": 549242, "start": 5502.66, "end": 5508.58, "text": " Which is the independent variable and a train masks folder that contains a dependent variable and they look like this", "tokens": [3013, 307, 264, 6695, 7006, 293, 257, 3847, 11830, 10820, 300, 8306, 257, 12334, 7006, 293, 436, 574, 411, 341], "temperature": 0.0, "avg_logprob": -0.27442499534370973, "compression_ratio": 1.7966101694915255, "no_speech_prob": 2.601603910079575e-06}, {"id": 1183, "seek": 549242, "start": 5508.9400000000005, "end": 5511.22, "text": " Here's the is one of the independent variable", "tokens": [1692, 311, 264, 307, 472, 295, 264, 6695, 7006], "temperature": 0.0, "avg_logprob": -0.27442499534370973, "compression_ratio": 1.7966101694915255, "no_speech_prob": 2.601603910079575e-06}, {"id": 1184, "seek": 549242, "start": 5514.9, "end": 5516.74, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.27442499534370973, "compression_ratio": 1.7966101694915255, "no_speech_prob": 2.601603910079575e-06}, {"id": 1185, "seek": 551674, "start": 5516.74, "end": 5525.78, "text": " Here's one of the dependent variable. Okay. So in this case just like cats and dogs we're going simple rather than doing multi-class classification", "tokens": [1692, 311, 472, 295, 264, 12334, 7006, 13, 1033, 13, 407, 294, 341, 1389, 445, 411, 11111, 293, 7197, 321, 434, 516, 2199, 2831, 813, 884, 4825, 12, 11665, 21538], "temperature": 0.0, "avg_logprob": -0.18697823830021237, "compression_ratio": 1.7265625, "no_speech_prob": 4.637840902432799e-06}, {"id": 1186, "seek": 551674, "start": 5525.78, "end": 5531.7, "text": " We're going to do binary classification that of course multi-class is just the more general version, you know", "tokens": [492, 434, 516, 281, 360, 17434, 21538, 300, 295, 1164, 4825, 12, 11665, 307, 445, 264, 544, 2674, 3037, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.18697823830021237, "compression_ratio": 1.7265625, "no_speech_prob": 4.637840902432799e-06}, {"id": 1187, "seek": 551674, "start": 5532.3, "end": 5539.98, "text": " Categorical cross entropy your binary cross entropy. Okay, so there's no differences conceptually. So we've got this is just you know zeros and ones", "tokens": [383, 2968, 284, 804, 3278, 30867, 428, 17434, 3278, 30867, 13, 1033, 11, 370, 456, 311, 572, 7300, 3410, 671, 13, 407, 321, 600, 658, 341, 307, 445, 291, 458, 35193, 293, 2306], "temperature": 0.0, "avg_logprob": -0.18697823830021237, "compression_ratio": 1.7265625, "no_speech_prob": 4.637840902432799e-06}, {"id": 1188, "seek": 551674, "start": 5541.219999999999, "end": 5543.219999999999, "text": " Where else this is a regular image?", "tokens": [2305, 1646, 341, 307, 257, 3890, 3256, 30], "temperature": 0.0, "avg_logprob": -0.18697823830021237, "compression_ratio": 1.7265625, "no_speech_prob": 4.637840902432799e-06}, {"id": 1189, "seek": 554322, "start": 5543.22, "end": 5546.3, "text": " So in order to do this well", "tokens": [407, 294, 1668, 281, 360, 341, 731], "temperature": 0.0, "avg_logprob": -0.23827764961156953, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.7852878449484706e-06}, {"id": 1190, "seek": 554322, "start": 5547.1, "end": 5549.54, "text": " It would really help to know what cars look like", "tokens": [467, 576, 534, 854, 281, 458, 437, 5163, 574, 411], "temperature": 0.0, "avg_logprob": -0.23827764961156953, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.7852878449484706e-06}, {"id": 1191, "seek": 554322, "start": 5549.900000000001, "end": 5552.54, "text": " right because you know really what we just want to do is", "tokens": [558, 570, 291, 458, 534, 437, 321, 445, 528, 281, 360, 307], "temperature": 0.0, "avg_logprob": -0.23827764961156953, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.7852878449484706e-06}, {"id": 1192, "seek": 554322, "start": 5553.06, "end": 5556.22, "text": " Figure out this is a car and this orientation and then color", "tokens": [43225, 484, 341, 307, 257, 1032, 293, 341, 14764, 293, 550, 2017], "temperature": 0.0, "avg_logprob": -0.23827764961156953, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.7852878449484706e-06}, {"id": 1193, "seek": 554322, "start": 5556.22, "end": 5562.34, "text": " You know white pixels where we expect the car to be based on the picture and our understanding of what cars look like", "tokens": [509, 458, 2418, 18668, 689, 321, 2066, 264, 1032, 281, 312, 2361, 322, 264, 3036, 293, 527, 3701, 295, 437, 5163, 574, 411], "temperature": 0.0, "avg_logprob": -0.23827764961156953, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.7852878449484706e-06}, {"id": 1194, "seek": 554322, "start": 5564.66, "end": 5568.4400000000005, "text": " The original data set came with these CSV files as well", "tokens": [440, 3380, 1412, 992, 1361, 365, 613, 48814, 7098, 382, 731], "temperature": 0.0, "avg_logprob": -0.23827764961156953, "compression_ratio": 1.6727272727272726, "no_speech_prob": 3.7852878449484706e-06}, {"id": 1195, "seek": 556844, "start": 5568.44, "end": 5573.46, "text": " I don't really use them for very much other than getting a list of images from them", "tokens": [286, 500, 380, 534, 764, 552, 337, 588, 709, 661, 813, 1242, 257, 1329, 295, 5267, 490, 552], "temperature": 0.0, "avg_logprob": -0.21285258112726985, "compression_ratio": 1.488888888888889, "no_speech_prob": 1.1300602636765689e-05}, {"id": 1196, "seek": 556844, "start": 5578.86, "end": 5582.78, "text": " Each each image after the car ID has a", "tokens": [6947, 1184, 3256, 934, 264, 1032, 7348, 575, 257], "temperature": 0.0, "avg_logprob": -0.21285258112726985, "compression_ratio": 1.488888888888889, "no_speech_prob": 1.1300602636765689e-05}, {"id": 1197, "seek": 556844, "start": 5583.299999999999, "end": 5585.299999999999, "text": " 0 1 0 2 etc", "tokens": [1958, 502, 1958, 568, 5183], "temperature": 0.0, "avg_logprob": -0.21285258112726985, "compression_ratio": 1.488888888888889, "no_speech_prob": 1.1300602636765689e-05}, {"id": 1198, "seek": 556844, "start": 5585.299999999999, "end": 5590.919999999999, "text": " Of which I've printed out all 16 of them for one car and as you can see if basically those numbers are the 16", "tokens": [2720, 597, 286, 600, 13567, 484, 439, 3165, 295, 552, 337, 472, 1032, 293, 382, 291, 393, 536, 498, 1936, 729, 3547, 366, 264, 3165], "temperature": 0.0, "avg_logprob": -0.21285258112726985, "compression_ratio": 1.488888888888889, "no_speech_prob": 1.1300602636765689e-05}, {"id": 1199, "seek": 556844, "start": 5591.78, "end": 5593.78, "text": " orientations of one car", "tokens": [8579, 763, 295, 472, 1032], "temperature": 0.0, "avg_logprob": -0.21285258112726985, "compression_ratio": 1.488888888888889, "no_speech_prob": 1.1300602636765689e-05}, {"id": 1200, "seek": 559378, "start": 5593.78, "end": 5599.54, "text": " So there that is I don't think anybody in this competition actually used this", "tokens": [407, 456, 300, 307, 286, 500, 380, 519, 4472, 294, 341, 6211, 767, 1143, 341], "temperature": 0.0, "avg_logprob": -0.20123853047688803, "compression_ratio": 1.5228426395939085, "no_speech_prob": 6.144115104689263e-06}, {"id": 1201, "seek": 559378, "start": 5600.3, "end": 5603.34, "text": " Orientation information, I believe they all kept the cars", "tokens": [49544, 399, 1589, 11, 286, 1697, 436, 439, 4305, 264, 5163], "temperature": 0.0, "avg_logprob": -0.20123853047688803, "compression_ratio": 1.5228426395939085, "no_speech_prob": 6.144115104689263e-06}, {"id": 1202, "seek": 559378, "start": 5604.099999999999, "end": 5606.099999999999, "text": " Images just treated them separately", "tokens": [4331, 1660, 445, 8668, 552, 14759], "temperature": 0.0, "avg_logprob": -0.20123853047688803, "compression_ratio": 1.5228426395939085, "no_speech_prob": 6.144115104689263e-06}, {"id": 1203, "seek": 559378, "start": 5607.38, "end": 5612.62, "text": " These images are pretty big like over a thousand by a thousand in size and", "tokens": [1981, 5267, 366, 1238, 955, 411, 670, 257, 4714, 538, 257, 4714, 294, 2744, 293], "temperature": 0.0, "avg_logprob": -0.20123853047688803, "compression_ratio": 1.5228426395939085, "no_speech_prob": 6.144115104689263e-06}, {"id": 1204, "seek": 559378, "start": 5613.46, "end": 5618.96, "text": " Just opening the JPEGs and resizing them is slow", "tokens": [1449, 5193, 264, 508, 5208, 33715, 293, 725, 3319, 552, 307, 2964], "temperature": 0.0, "avg_logprob": -0.20123853047688803, "compression_ratio": 1.5228426395939085, "no_speech_prob": 6.144115104689263e-06}, {"id": 1205, "seek": 559378, "start": 5620.34, "end": 5621.86, "text": " so I", "tokens": [370, 286], "temperature": 0.0, "avg_logprob": -0.20123853047688803, "compression_ratio": 1.5228426395939085, "no_speech_prob": 6.144115104689263e-06}, {"id": 1206, "seek": 562186, "start": 5621.86, "end": 5625.46, "text": " Processed them all also open CV can't handle", "tokens": [31093, 292, 552, 439, 611, 1269, 22995, 393, 380, 4813], "temperature": 0.0, "avg_logprob": -0.1999010942420181, "compression_ratio": 1.524904214559387, "no_speech_prob": 2.429941378068179e-05}, {"id": 1207, "seek": 562186, "start": 5625.98, "end": 5629.46, "text": " Gift files so I converted them. Yes, Rachel the question", "tokens": [44890, 7098, 370, 286, 16424, 552, 13, 1079, 11, 14246, 264, 1168], "temperature": 0.0, "avg_logprob": -0.1999010942420181, "compression_ratio": 1.524904214559387, "no_speech_prob": 2.429941378068179e-05}, {"id": 1208, "seek": 562186, "start": 5629.54, "end": 5634.179999999999, "text": " How would somebody get these masks for training initially mechanical Turk or something? Yeah", "tokens": [1012, 576, 2618, 483, 613, 11830, 337, 3097, 9105, 12070, 15714, 420, 746, 30, 865], "temperature": 0.0, "avg_logprob": -0.1999010942420181, "compression_ratio": 1.524904214559387, "no_speech_prob": 2.429941378068179e-05}, {"id": 1209, "seek": 562186, "start": 5634.94, "end": 5636.94, "text": " Yeah, just a lot of boring work", "tokens": [865, 11, 445, 257, 688, 295, 9989, 589], "temperature": 0.0, "avg_logprob": -0.1999010942420181, "compression_ratio": 1.524904214559387, "no_speech_prob": 2.429941378068179e-05}, {"id": 1210, "seek": 562186, "start": 5641.0199999999995, "end": 5646.38, "text": " You know probably some tools that help you with a bit of edge snapping and stuff so that the human can kind of do it", "tokens": [509, 458, 1391, 512, 3873, 300, 854, 291, 365, 257, 857, 295, 4691, 42727, 293, 1507, 370, 300, 264, 1952, 393, 733, 295, 360, 309], "temperature": 0.0, "avg_logprob": -0.1999010942420181, "compression_ratio": 1.524904214559387, "no_speech_prob": 2.429941378068179e-05}, {"id": 1211, "seek": 562186, "start": 5646.38, "end": 5648.5199999999995, "text": " Roughly and then just fine-tune the bits it gets wrong", "tokens": [42791, 356, 293, 550, 445, 2489, 12, 83, 2613, 264, 9239, 309, 2170, 2085], "temperature": 0.0, "avg_logprob": -0.1999010942420181, "compression_ratio": 1.524904214559387, "no_speech_prob": 2.429941378068179e-05}, {"id": 1212, "seek": 564852, "start": 5648.52, "end": 5650.52, "text": " Yeah", "tokens": [865], "temperature": 0.0, "avg_logprob": -0.1893135115157726, "compression_ratio": 1.5758928571428572, "no_speech_prob": 1.3211631085141562e-05}, {"id": 1213, "seek": 564852, "start": 5653.64, "end": 5660.200000000001, "text": " These kinds of labels are expensive, you know, and so one of the things I really want to work on is deep learning", "tokens": [1981, 3685, 295, 16949, 366, 5124, 11, 291, 458, 11, 293, 370, 472, 295, 264, 721, 286, 534, 528, 281, 589, 322, 307, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.1893135115157726, "compression_ratio": 1.5758928571428572, "no_speech_prob": 1.3211631085141562e-05}, {"id": 1214, "seek": 564852, "start": 5661.72, "end": 5664.84, "text": " enhanced interactive labeling tools because", "tokens": [21191, 15141, 40244, 3873, 570], "temperature": 0.0, "avg_logprob": -0.1893135115157726, "compression_ratio": 1.5758928571428572, "no_speech_prob": 1.3211631085141562e-05}, {"id": 1215, "seek": 564852, "start": 5665.64, "end": 5668.96, "text": " You know, that's clearly something that would help a lot of people", "tokens": [509, 458, 11, 300, 311, 4448, 746, 300, 576, 854, 257, 688, 295, 561], "temperature": 0.0, "avg_logprob": -0.1893135115157726, "compression_ratio": 1.5758928571428572, "no_speech_prob": 1.3211631085141562e-05}, {"id": 1216, "seek": 564852, "start": 5670.6, "end": 5676.42, "text": " Yes, I've got a little section here that you can run if you want to you probably want to which converts the gifts into PNGs", "tokens": [1079, 11, 286, 600, 658, 257, 707, 3541, 510, 300, 291, 393, 1190, 498, 291, 528, 281, 291, 1391, 528, 281, 597, 38874, 264, 11449, 666, 430, 30237, 82], "temperature": 0.0, "avg_logprob": -0.1893135115157726, "compression_ratio": 1.5758928571428572, "no_speech_prob": 1.3211631085141562e-05}, {"id": 1217, "seek": 567642, "start": 5676.42, "end": 5682.9, "text": " So just open it up with a PIL and then save it as PNG because open CV doesn't have gift support", "tokens": [407, 445, 1269, 309, 493, 365, 257, 430, 4620, 293, 550, 3155, 309, 382, 430, 30237, 570, 1269, 22995, 1177, 380, 362, 5306, 1406], "temperature": 0.0, "avg_logprob": -0.20277549225149802, "compression_ratio": 1.6075471698113208, "no_speech_prob": 7.14108464308083e-05}, {"id": 1218, "seek": 567642, "start": 5683.62, "end": 5690.5, "text": " And as per usual for this kind of stuff, I do it with a thread pool so I can take advantage of parallel processing and then also", "tokens": [400, 382, 680, 7713, 337, 341, 733, 295, 1507, 11, 286, 360, 309, 365, 257, 7207, 7005, 370, 286, 393, 747, 5002, 295, 8952, 9007, 293, 550, 611], "temperature": 0.0, "avg_logprob": -0.20277549225149802, "compression_ratio": 1.6075471698113208, "no_speech_prob": 7.14108464308083e-05}, {"id": 1219, "seek": 567642, "start": 5691.26, "end": 5697.22, "text": " Create a separate directory train dash 128 and train masks 128 which contains the 128 by 128", "tokens": [20248, 257, 4994, 21120, 3847, 8240, 29810, 293, 3847, 11830, 29810, 597, 8306, 264, 29810, 538, 29810], "temperature": 0.0, "avg_logprob": -0.20277549225149802, "compression_ratio": 1.6075471698113208, "no_speech_prob": 7.14108464308083e-05}, {"id": 1220, "seek": 567642, "start": 5697.54, "end": 5704.7, "text": " Resized versions of them and this is the kind of stuff that keeps you sane if you do it early in the process", "tokens": [5015, 1602, 9606, 295, 552, 293, 341, 307, 264, 733, 295, 1507, 300, 5965, 291, 45610, 498, 291, 360, 309, 2440, 294, 264, 1399], "temperature": 0.0, "avg_logprob": -0.20277549225149802, "compression_ratio": 1.6075471698113208, "no_speech_prob": 7.14108464308083e-05}, {"id": 1221, "seek": 570470, "start": 5704.7, "end": 5712.34, "text": " So anytime you get a new data set, you know seriously think about creating a you know smaller version to make life", "tokens": [407, 13038, 291, 483, 257, 777, 1412, 992, 11, 291, 458, 6638, 519, 466, 4084, 257, 291, 458, 4356, 3037, 281, 652, 993], "temperature": 0.0, "avg_logprob": -0.18458969528610641, "compression_ratio": 1.7169117647058822, "no_speech_prob": 2.4682303774170578e-05}, {"id": 1222, "seek": 570470, "start": 5712.46, "end": 5718.58, "text": " Fast anytime you find yourself waiting on your computer, you know, try and think of a way to create a smaller version", "tokens": [15968, 13038, 291, 915, 1803, 3806, 322, 428, 3820, 11, 291, 458, 11, 853, 293, 519, 295, 257, 636, 281, 1884, 257, 4356, 3037], "temperature": 0.0, "avg_logprob": -0.18458969528610641, "compression_ratio": 1.7169117647058822, "no_speech_prob": 2.4682303774170578e-05}, {"id": 1223, "seek": 570470, "start": 5719.82, "end": 5725.179999999999, "text": " So yeah, after you grab it from Kaggle, you probably want to run this stuff go away have lunch come back and when you're done", "tokens": [407, 1338, 11, 934, 291, 4444, 309, 490, 48751, 22631, 11, 291, 1391, 528, 281, 1190, 341, 1507, 352, 1314, 362, 6349, 808, 646, 293, 562, 291, 434, 1096], "temperature": 0.0, "avg_logprob": -0.18458969528610641, "compression_ratio": 1.7169117647058822, "no_speech_prob": 2.4682303774170578e-05}, {"id": 1224, "seek": 570470, "start": 5725.98, "end": 5727.7, "text": " You'll have these smaller", "tokens": [509, 603, 362, 613, 4356], "temperature": 0.0, "avg_logprob": -0.18458969528610641, "compression_ratio": 1.7169117647058822, "no_speech_prob": 2.4682303774170578e-05}, {"id": 1225, "seek": 570470, "start": 5727.7, "end": 5732.0599999999995, "text": " directories, which we're going to use here 128 by 128 pixel versions to start with", "tokens": [5391, 530, 11, 597, 321, 434, 516, 281, 764, 510, 29810, 538, 29810, 19261, 9606, 281, 722, 365], "temperature": 0.0, "avg_logprob": -0.18458969528610641, "compression_ratio": 1.7169117647058822, "no_speech_prob": 2.4682303774170578e-05}, {"id": 1226, "seek": 573206, "start": 5732.06, "end": 5733.660000000001, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.17069185045030383, "compression_ratio": 1.6682692307692308, "no_speech_prob": 4.425456609169487e-06}, {"id": 1227, "seek": 573206, "start": 5733.660000000001, "end": 5735.660000000001, "text": " Here's a cool trick if you", "tokens": [1692, 311, 257, 1627, 4282, 498, 291], "temperature": 0.0, "avg_logprob": -0.17069185045030383, "compression_ratio": 1.6682692307692308, "no_speech_prob": 4.425456609169487e-06}, {"id": 1228, "seek": 573206, "start": 5736.740000000001, "end": 5744.900000000001, "text": " use the same axis object to plot an image twice and the second time you use alpha which as you might know means", "tokens": [764, 264, 912, 10298, 2657, 281, 7542, 364, 3256, 6091, 293, 264, 1150, 565, 291, 764, 8961, 597, 382, 291, 1062, 458, 1355], "temperature": 0.0, "avg_logprob": -0.17069185045030383, "compression_ratio": 1.6682692307692308, "no_speech_prob": 4.425456609169487e-06}, {"id": 1229, "seek": 573206, "start": 5745.38, "end": 5751.780000000001, "text": " Transparency in the computer vision world then you can actually plot the mask over the top of the photo", "tokens": [6531, 79, 4484, 1344, 294, 264, 3820, 5201, 1002, 550, 291, 393, 767, 7542, 264, 6094, 670, 264, 1192, 295, 264, 5052], "temperature": 0.0, "avg_logprob": -0.17069185045030383, "compression_ratio": 1.6682692307692308, "no_speech_prob": 4.425456609169487e-06}, {"id": 1230, "seek": 573206, "start": 5752.26, "end": 5758.54, "text": " And so there is a nice way to see all the masks on top of the photos for all of the cars in one group", "tokens": [400, 370, 456, 307, 257, 1481, 636, 281, 536, 439, 264, 11830, 322, 1192, 295, 264, 5787, 337, 439, 295, 264, 5163, 294, 472, 1594], "temperature": 0.0, "avg_logprob": -0.17069185045030383, "compression_ratio": 1.6682692307692308, "no_speech_prob": 4.425456609169487e-06}, {"id": 1231, "seek": 575854, "start": 5758.54, "end": 5761.86, "text": " This is the same match files data set. We've seen twice already", "tokens": [639, 307, 264, 912, 2995, 7098, 1412, 992, 13, 492, 600, 1612, 6091, 1217], "temperature": 0.0, "avg_logprob": -0.20887267168830423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565933522826526e-06}, {"id": 1232, "seek": 575854, "start": 5762.78, "end": 5766.88, "text": " This is all the same code we're used to and here's something important though", "tokens": [639, 307, 439, 264, 912, 3089, 321, 434, 1143, 281, 293, 510, 311, 746, 1021, 1673], "temperature": 0.0, "avg_logprob": -0.20887267168830423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565933522826526e-06}, {"id": 1233, "seek": 575854, "start": 5767.86, "end": 5772.82, "text": " if we had something that was in the training set good at this image and", "tokens": [498, 321, 632, 746, 300, 390, 294, 264, 3097, 992, 665, 412, 341, 3256, 293], "temperature": 0.0, "avg_logprob": -0.20887267168830423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565933522826526e-06}, {"id": 1234, "seek": 575854, "start": 5773.14, "end": 5778.2, "text": " Then the validation had that image that would kind of be cheating because it's the same car", "tokens": [1396, 264, 24071, 632, 300, 3256, 300, 576, 733, 295, 312, 18309, 570, 309, 311, 264, 912, 1032], "temperature": 0.0, "avg_logprob": -0.20887267168830423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565933522826526e-06}, {"id": 1235, "seek": 575854, "start": 5778.98, "end": 5780.98, "text": " so we use a", "tokens": [370, 321, 764, 257], "temperature": 0.0, "avg_logprob": -0.20887267168830423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565933522826526e-06}, {"id": 1236, "seek": 575854, "start": 5782.22, "end": 5784.22, "text": " contiguous set of", "tokens": [660, 30525, 992, 295], "temperature": 0.0, "avg_logprob": -0.20887267168830423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565933522826526e-06}, {"id": 1237, "seek": 578422, "start": 5784.22, "end": 5791.18, "text": " Car IDs and since each set is a set of 16 we make sure that's evenly divisible by 16", "tokens": [2741, 48212, 293, 1670, 1184, 992, 307, 257, 992, 295, 3165, 321, 652, 988, 300, 311, 17658, 25974, 964, 538, 3165], "temperature": 0.0, "avg_logprob": -0.17154066139292495, "compression_ratio": 1.683794466403162, "no_speech_prob": 1.9525454263202846e-05}, {"id": 1238, "seek": 578422, "start": 5791.860000000001, "end": 5797.56, "text": " So we make sure that our validation set contains different car IDs to our training set", "tokens": [407, 321, 652, 988, 300, 527, 24071, 992, 8306, 819, 1032, 48212, 281, 527, 3097, 992], "temperature": 0.0, "avg_logprob": -0.17154066139292495, "compression_ratio": 1.683794466403162, "no_speech_prob": 1.9525454263202846e-05}, {"id": 1239, "seek": 578422, "start": 5797.780000000001, "end": 5800.54, "text": " This is the kind of stuff which you've got to be careful of on", "tokens": [639, 307, 264, 733, 295, 1507, 597, 291, 600, 658, 281, 312, 5026, 295, 322], "temperature": 0.0, "avg_logprob": -0.17154066139292495, "compression_ratio": 1.683794466403162, "no_speech_prob": 1.9525454263202846e-05}, {"id": 1240, "seek": 578422, "start": 5801.2, "end": 5802.46, "text": " Kaggle, it's not so bad", "tokens": [48751, 22631, 11, 309, 311, 406, 370, 1578], "temperature": 0.0, "avg_logprob": -0.17154066139292495, "compression_ratio": 1.683794466403162, "no_speech_prob": 1.9525454263202846e-05}, {"id": 1241, "seek": 578422, "start": 5802.46, "end": 5808.62, "text": " You'll know about it because you'll submit your result and you'll get a very different result on your leaderboard compared to your", "tokens": [509, 603, 458, 466, 309, 570, 291, 603, 10315, 428, 1874, 293, 291, 603, 483, 257, 588, 819, 1874, 322, 428, 5263, 3787, 5347, 281, 428], "temperature": 0.0, "avg_logprob": -0.17154066139292495, "compression_ratio": 1.683794466403162, "no_speech_prob": 1.9525454263202846e-05}, {"id": 1242, "seek": 578422, "start": 5809.42, "end": 5811.7, "text": " validation set but in the real world", "tokens": [24071, 992, 457, 294, 264, 957, 1002], "temperature": 0.0, "avg_logprob": -0.17154066139292495, "compression_ratio": 1.683794466403162, "no_speech_prob": 1.9525454263202846e-05}, {"id": 1243, "seek": 581170, "start": 5811.7, "end": 5817.7, "text": " You won't know until you put it in production and send your company bankrupt and lose your job", "tokens": [509, 1582, 380, 458, 1826, 291, 829, 309, 294, 4265, 293, 2845, 428, 2237, 21780, 293, 3624, 428, 1691], "temperature": 0.0, "avg_logprob": -0.14053799765450614, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.646445737918839e-06}, {"id": 1244, "seek": 581170, "start": 5818.78, "end": 5823.0, "text": " So you might want to think carefully about your validation set in that case", "tokens": [407, 291, 1062, 528, 281, 519, 7500, 466, 428, 24071, 992, 294, 300, 1389], "temperature": 0.0, "avg_logprob": -0.14053799765450614, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.646445737918839e-06}, {"id": 1245, "seek": 581170, "start": 5824.34, "end": 5827.38, "text": " So here we're going to use transform type dot classification", "tokens": [407, 510, 321, 434, 516, 281, 764, 4088, 2010, 5893, 21538], "temperature": 0.0, "avg_logprob": -0.14053799765450614, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.646445737918839e-06}, {"id": 1246, "seek": 581170, "start": 5828.58, "end": 5831.62, "text": " It's basically the same as transform type dot pixel", "tokens": [467, 311, 1936, 264, 912, 382, 4088, 2010, 5893, 19261], "temperature": 0.0, "avg_logprob": -0.14053799765450614, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.646445737918839e-06}, {"id": 1247, "seek": 581170, "start": 5831.62, "end": 5835.24, "text": " But if you think about it we with a pixel version if we rotate a little bit", "tokens": [583, 498, 291, 519, 466, 309, 321, 365, 257, 19261, 3037, 498, 321, 13121, 257, 707, 857], "temperature": 0.0, "avg_logprob": -0.14053799765450614, "compression_ratio": 1.7481481481481482, "no_speech_prob": 7.646445737918839e-06}, {"id": 1248, "seek": 583524, "start": 5835.24, "end": 5842.639999999999, "text": " Then we probably want to like average the pixels in between the two but the classification obviously we we don't we use nearest neighbor", "tokens": [1396, 321, 1391, 528, 281, 411, 4274, 264, 18668, 294, 1296, 264, 732, 457, 264, 21538, 2745, 321, 321, 500, 380, 321, 764, 23831, 5987], "temperature": 0.0, "avg_logprob": -0.2265153298011193, "compression_ratio": 1.5874439461883407, "no_speech_prob": 6.339123956422554e-06}, {"id": 1249, "seek": 583524, "start": 5842.639999999999, "end": 5844.639999999999, "text": " So the slight difference there", "tokens": [407, 264, 4036, 2649, 456], "temperature": 0.0, "avg_logprob": -0.2265153298011193, "compression_ratio": 1.5874439461883407, "no_speech_prob": 6.339123956422554e-06}, {"id": 1250, "seek": 583524, "start": 5845.24, "end": 5851.46, "text": " Also for classification, you know lighting doesn't kick in normalization doesn't kick in to the dependent variable", "tokens": [2743, 337, 21538, 11, 291, 458, 9577, 1177, 380, 4437, 294, 2710, 2144, 1177, 380, 4437, 294, 281, 264, 12334, 7006], "temperature": 0.0, "avg_logprob": -0.2265153298011193, "compression_ratio": 1.5874439461883407, "no_speech_prob": 6.339123956422554e-06}, {"id": 1251, "seek": 583524, "start": 5854.76, "end": 5858.5599999999995, "text": " Okay, they're already square images so we don't have to do any cropping", "tokens": [1033, 11, 436, 434, 1217, 3732, 5267, 370, 321, 500, 380, 362, 281, 360, 604, 4848, 3759], "temperature": 0.0, "avg_logprob": -0.2265153298011193, "compression_ratio": 1.5874439461883407, "no_speech_prob": 6.339123956422554e-06}, {"id": 1252, "seek": 585856, "start": 5858.56, "end": 5865.56, "text": " So here you can see different versions of the augmented, you know, they're moving around a bit and they're rotating a bit and so forth", "tokens": [407, 510, 291, 393, 536, 819, 9606, 295, 264, 36155, 11, 291, 458, 11, 436, 434, 2684, 926, 257, 857, 293, 436, 434, 19627, 257, 857, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.2365370880473744, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.1478558917588089e-05}, {"id": 1253, "seek": 585856, "start": 5871.56, "end": 5876.6, "text": " Yeah, I get a lot of questions kind of like during our study group and stuff about like how do I", "tokens": [865, 11, 286, 483, 257, 688, 295, 1651, 733, 295, 411, 1830, 527, 2979, 1594, 293, 1507, 466, 411, 577, 360, 286], "temperature": 0.0, "avg_logprob": -0.2365370880473744, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.1478558917588089e-05}, {"id": 1254, "seek": 585856, "start": 5877.72, "end": 5880.96, "text": " debug things and fix things that aren't working and like I I", "tokens": [24083, 721, 293, 3191, 721, 300, 3212, 380, 1364, 293, 411, 286, 286], "temperature": 0.0, "avg_logprob": -0.2365370880473744, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.1478558917588089e-05}, {"id": 1255, "seek": 585856, "start": 5881.88, "end": 5886.04, "text": " Never have a great answer other than like every time I fix a problem", "tokens": [7344, 362, 257, 869, 1867, 661, 813, 411, 633, 565, 286, 3191, 257, 1154], "temperature": 0.0, "avg_logprob": -0.2365370880473744, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.1478558917588089e-05}, {"id": 1256, "seek": 588604, "start": 5886.04, "end": 5890.24, "text": " It's because of stuff like this that I do all the time, you know", "tokens": [467, 311, 570, 295, 1507, 411, 341, 300, 286, 360, 439, 264, 565, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.15233615913776435, "compression_ratio": 1.6858407079646018, "no_speech_prob": 3.120140536339022e-05}, {"id": 1257, "seek": 588604, "start": 5890.24, "end": 5894.68, "text": " I just always print out everything as I go", "tokens": [286, 445, 1009, 4482, 484, 1203, 382, 286, 352], "temperature": 0.0, "avg_logprob": -0.15233615913776435, "compression_ratio": 1.6858407079646018, "no_speech_prob": 3.120140536339022e-05}, {"id": 1258, "seek": 588604, "start": 5894.68, "end": 5899.48, "text": " And then the one thing that I screw up always turns out to be the one thing that I forgot to check", "tokens": [400, 550, 264, 472, 551, 300, 286, 5630, 493, 1009, 4523, 484, 281, 312, 264, 472, 551, 300, 286, 5298, 281, 1520], "temperature": 0.0, "avg_logprob": -0.15233615913776435, "compression_ratio": 1.6858407079646018, "no_speech_prob": 3.120140536339022e-05}, {"id": 1259, "seek": 588604, "start": 5900.24, "end": 5905.5199999999995, "text": " So yeah, the more of this kind of thing you can do the better if you're not looking at all of your intermediate results", "tokens": [407, 1338, 11, 264, 544, 295, 341, 733, 295, 551, 291, 393, 360, 264, 1101, 498, 291, 434, 406, 1237, 412, 439, 295, 428, 19376, 3542], "temperature": 0.0, "avg_logprob": -0.15233615913776435, "compression_ratio": 1.6858407079646018, "no_speech_prob": 3.120140536339022e-05}, {"id": 1260, "seek": 588604, "start": 5905.96, "end": 5907.96, "text": " You're gonna have troubles. Okay", "tokens": [509, 434, 799, 362, 15379, 13, 1033], "temperature": 0.0, "avg_logprob": -0.15233615913776435, "compression_ratio": 1.6858407079646018, "no_speech_prob": 3.120140536339022e-05}, {"id": 1261, "seek": 588604, "start": 5910.36, "end": 5912.36, "text": " So given that we want", "tokens": [407, 2212, 300, 321, 528], "temperature": 0.0, "avg_logprob": -0.15233615913776435, "compression_ratio": 1.6858407079646018, "no_speech_prob": 3.120140536339022e-05}, {"id": 1262, "seek": 591236, "start": 5912.36, "end": 5918.04, "text": " Something that knows what cars look like we probably want to start with a pre-trained image net network", "tokens": [6595, 300, 3255, 437, 5163, 574, 411, 321, 1391, 528, 281, 722, 365, 257, 659, 12, 17227, 2001, 3256, 2533, 3209], "temperature": 0.0, "avg_logprob": -0.21678194318498883, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.2218951269460376e-05}, {"id": 1263, "seek": 591236, "start": 5918.88, "end": 5924.36, "text": " So we're gonna start with resnet 34 and so with cognitive builder", "tokens": [407, 321, 434, 799, 722, 365, 725, 7129, 12790, 293, 370, 365, 15605, 27377], "temperature": 0.0, "avg_logprob": -0.21678194318498883, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.2218951269460376e-05}, {"id": 1264, "seek": 591236, "start": 5924.36, "end": 5927.96, "text": " We can grab our resnet 34 and we can add a custom head", "tokens": [492, 393, 4444, 527, 725, 7129, 12790, 293, 321, 393, 909, 257, 2375, 1378], "temperature": 0.0, "avg_logprob": -0.21678194318498883, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.2218951269460376e-05}, {"id": 1265, "seek": 591236, "start": 5928.96, "end": 5933.5199999999995, "text": " and so the custom head is going to be something that up samples a bunch of times and", "tokens": [293, 370, 264, 2375, 1378, 307, 516, 281, 312, 746, 300, 493, 10938, 257, 3840, 295, 1413, 293], "temperature": 0.0, "avg_logprob": -0.21678194318498883, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.2218951269460376e-05}, {"id": 1266, "seek": 591236, "start": 5934.28, "end": 5939.08, "text": " We're going to do things really dumb for now, which is we're just going to do comm transpose 2d", "tokens": [492, 434, 516, 281, 360, 721, 534, 10316, 337, 586, 11, 597, 307, 321, 434, 445, 516, 281, 360, 800, 25167, 568, 67], "temperature": 0.0, "avg_logprob": -0.21678194318498883, "compression_ratio": 1.7333333333333334, "no_speech_prob": 1.2218951269460376e-05}, {"id": 1267, "seek": 593908, "start": 5939.08, "end": 5942.48, "text": " batch norm value, okay", "tokens": [15245, 2026, 2158, 11, 1392], "temperature": 0.0, "avg_logprob": -0.2456204341008113, "compression_ratio": 1.5425531914893618, "no_speech_prob": 1.0616015060804784e-05}, {"id": 1268, "seek": 593908, "start": 5943.28, "end": 5945.28, "text": " and so here's like", "tokens": [293, 370, 510, 311, 411], "temperature": 0.0, "avg_logprob": -0.2456204341008113, "compression_ratio": 1.5425531914893618, "no_speech_prob": 1.0616015060804784e-05}, {"id": 1269, "seek": 593908, "start": 5945.84, "end": 5950.92, "text": " This is what I'm saying. Like you could any of you could have built this without looking at any of this", "tokens": [639, 307, 437, 286, 478, 1566, 13, 1743, 291, 727, 604, 295, 291, 727, 362, 3094, 341, 1553, 1237, 412, 604, 295, 341], "temperature": 0.0, "avg_logprob": -0.2456204341008113, "compression_ratio": 1.5425531914893618, "no_speech_prob": 1.0616015060804784e-05}, {"id": 1270, "seek": 593908, "start": 5951.8, "end": 5957.76, "text": " Or at least like you have the information from previous classes. There's nothing new at all", "tokens": [1610, 412, 1935, 411, 291, 362, 264, 1589, 490, 3894, 5359, 13, 821, 311, 1825, 777, 412, 439], "temperature": 0.0, "avg_logprob": -0.2456204341008113, "compression_ratio": 1.5425531914893618, "no_speech_prob": 1.0616015060804784e-05}, {"id": 1271, "seek": 593908, "start": 5958.68, "end": 5964.26, "text": " Okay, and so at the very end we have a single", "tokens": [1033, 11, 293, 370, 412, 264, 588, 917, 321, 362, 257, 2167], "temperature": 0.0, "avg_logprob": -0.2456204341008113, "compression_ratio": 1.5425531914893618, "no_speech_prob": 1.0616015060804784e-05}, {"id": 1272, "seek": 593908, "start": 5965.68, "end": 5967.04, "text": " filter", "tokens": [6608], "temperature": 0.0, "avg_logprob": -0.2456204341008113, "compression_ratio": 1.5425531914893618, "no_speech_prob": 1.0616015060804784e-05}, {"id": 1273, "seek": 596704, "start": 5967.04, "end": 5973.6, "text": " Okay, and now that's going to give us something which is batch size by 1 by 128 by 128", "tokens": [1033, 11, 293, 586, 300, 311, 516, 281, 976, 505, 746, 597, 307, 15245, 2744, 538, 502, 538, 29810, 538, 29810], "temperature": 0.0, "avg_logprob": -0.17199330859714085, "compression_ratio": 1.8786610878661087, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1274, "seek": 596704, "start": 5974.12, "end": 5979.08, "text": " But we want something which is batch size by 128 by 128. So we have to remove that unit axis", "tokens": [583, 321, 528, 746, 597, 307, 15245, 2744, 538, 29810, 538, 29810, 13, 407, 321, 362, 281, 4159, 300, 4985, 10298], "temperature": 0.0, "avg_logprob": -0.17199330859714085, "compression_ratio": 1.8786610878661087, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1275, "seek": 596704, "start": 5979.28, "end": 5984.4, "text": " So I've got a lambda layer here lambda layers are incredibly helpful, right?", "tokens": [407, 286, 600, 658, 257, 13607, 4583, 510, 13607, 7914, 366, 6252, 4961, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17199330859714085, "compression_ratio": 1.8786610878661087, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1276, "seek": 596704, "start": 5984.4, "end": 5991.66, "text": " Because without the lambda layer here, which is simply removing that unit axis by just indexing into it at 0", "tokens": [1436, 1553, 264, 13607, 4583, 510, 11, 597, 307, 2935, 12720, 300, 4985, 10298, 538, 445, 8186, 278, 666, 309, 412, 1958], "temperature": 0.0, "avg_logprob": -0.17199330859714085, "compression_ratio": 1.8786610878661087, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1277, "seek": 599166, "start": 5991.66, "end": 5998.7, "text": " Without the lambda layer. I would have to have created a custom class with a custom forward method and so forth", "tokens": [9129, 264, 13607, 4583, 13, 286, 576, 362, 281, 362, 2942, 257, 2375, 1508, 365, 257, 2375, 2128, 3170, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.16057416742498223, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1278, "seek": 599166, "start": 5999.58, "end": 6002.66, "text": " But by creating a lambda layer that does like the one custom bit", "tokens": [583, 538, 4084, 257, 13607, 4583, 300, 775, 411, 264, 472, 2375, 857], "temperature": 0.0, "avg_logprob": -0.16057416742498223, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1279, "seek": 599166, "start": 6002.66, "end": 6007.5, "text": " I can now just chuck it in the sequential and so that just makes life easier. So", "tokens": [286, 393, 586, 445, 20870, 309, 294, 264, 42881, 293, 370, 300, 445, 1669, 993, 3571, 13, 407], "temperature": 0.0, "avg_logprob": -0.16057416742498223, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1280, "seek": 599166, "start": 6008.099999999999, "end": 6011.26, "text": " The pytorch people are kind of snooty about", "tokens": [440, 25878, 284, 339, 561, 366, 733, 295, 43287, 6737, 466], "temperature": 0.0, "avg_logprob": -0.16057416742498223, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1281, "seek": 599166, "start": 6011.86, "end": 6015.38, "text": " This approach lambda layer is actually something that's part of the fast AI library", "tokens": [639, 3109, 13607, 4583, 307, 767, 746, 300, 311, 644, 295, 264, 2370, 7318, 6405], "temperature": 0.0, "avg_logprob": -0.16057416742498223, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1282, "seek": 599166, "start": 6015.38, "end": 6019.62, "text": " Not part of the pytorch library and like literally people on the pytorch", "tokens": [1726, 644, 295, 264, 25878, 284, 339, 6405, 293, 411, 3736, 561, 322, 264, 25878, 284, 339], "temperature": 0.0, "avg_logprob": -0.16057416742498223, "compression_ratio": 1.796078431372549, "no_speech_prob": 1.0783245670609176e-05}, {"id": 1283, "seek": 601962, "start": 6019.62, "end": 6027.34, "text": " discussion board like yes, we could give people this yes, it is only a single line of code, but then it would like encourage them to use", "tokens": [5017, 3150, 411, 2086, 11, 321, 727, 976, 561, 341, 2086, 11, 309, 307, 787, 257, 2167, 1622, 295, 3089, 11, 457, 550, 309, 576, 411, 5373, 552, 281, 764], "temperature": 0.0, "avg_logprob": -0.23644525177624762, "compression_ratio": 1.6033755274261603, "no_speech_prob": 1.0952997399726883e-05}, {"id": 1284, "seek": 601962, "start": 6028.34, "end": 6029.9, "text": " sequential too often", "tokens": [42881, 886, 2049], "temperature": 0.0, "avg_logprob": -0.23644525177624762, "compression_ratio": 1.6033755274261603, "no_speech_prob": 1.0952997399726883e-05}, {"id": 1285, "seek": 601962, "start": 6029.9, "end": 6031.22, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.23644525177624762, "compression_ratio": 1.6033755274261603, "no_speech_prob": 1.0952997399726883e-05}, {"id": 1286, "seek": 601962, "start": 6031.22, "end": 6033.22, "text": " There you go. Okay", "tokens": [821, 291, 352, 13, 1033], "temperature": 0.0, "avg_logprob": -0.23644525177624762, "compression_ratio": 1.6033755274261603, "no_speech_prob": 1.0952997399726883e-05}, {"id": 1287, "seek": 601962, "start": 6033.78, "end": 6035.78, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.23644525177624762, "compression_ratio": 1.6033755274261603, "no_speech_prob": 1.0952997399726883e-05}, {"id": 1288, "seek": 601962, "start": 6036.78, "end": 6038.86, "text": " So this is our custom head, right?", "tokens": [407, 341, 307, 527, 2375, 1378, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23644525177624762, "compression_ratio": 1.6033755274261603, "no_speech_prob": 1.0952997399726883e-05}, {"id": 1289, "seek": 601962, "start": 6038.86, "end": 6044.62, "text": " so we're gonna have a resident 34 that goes down sample and then a really simple custom head that very quickly up samples and", "tokens": [370, 321, 434, 799, 362, 257, 10832, 12790, 300, 1709, 760, 6889, 293, 550, 257, 534, 2199, 2375, 1378, 300, 588, 2661, 493, 10938, 293], "temperature": 0.0, "avg_logprob": -0.23644525177624762, "compression_ratio": 1.6033755274261603, "no_speech_prob": 1.0952997399726883e-05}, {"id": 1290, "seek": 601962, "start": 6045.0199999999995, "end": 6047.3, "text": " that hopefully will do something and", "tokens": [300, 4696, 486, 360, 746, 293], "temperature": 0.0, "avg_logprob": -0.23644525177624762, "compression_ratio": 1.6033755274261603, "no_speech_prob": 1.0952997399726883e-05}, {"id": 1291, "seek": 604730, "start": 6047.3, "end": 6052.02, "text": " We're going to use accuracy with a threshold of 0.5 to print out metrics", "tokens": [492, 434, 516, 281, 764, 14170, 365, 257, 14678, 295, 1958, 13, 20, 281, 4482, 484, 16367], "temperature": 0.0, "avg_logprob": -0.23274014920604472, "compression_ratio": 1.5530973451327434, "no_speech_prob": 3.844909315375844e-06}, {"id": 1292, "seek": 604730, "start": 6052.02, "end": 6058.1, "text": " And so after a few epochs, we've got 96% accurate. Okay, so is that good is", "tokens": [400, 370, 934, 257, 1326, 30992, 28346, 11, 321, 600, 658, 24124, 4, 8559, 13, 1033, 11, 370, 307, 300, 665, 307], "temperature": 0.0, "avg_logprob": -0.23274014920604472, "compression_ratio": 1.5530973451327434, "no_speech_prob": 3.844909315375844e-06}, {"id": 1293, "seek": 604730, "start": 6058.74, "end": 6060.74, "text": " 96% accurate good and", "tokens": [24124, 4, 8559, 665, 293], "temperature": 0.0, "avg_logprob": -0.23274014920604472, "compression_ratio": 1.5530973451327434, "no_speech_prob": 3.844909315375844e-06}, {"id": 1294, "seek": 604730, "start": 6061.54, "end": 6065.06, "text": " Hopefully the answer to your quest that question is it depends", "tokens": [10429, 264, 1867, 281, 428, 866, 300, 1168, 307, 309, 5946], "temperature": 0.0, "avg_logprob": -0.23274014920604472, "compression_ratio": 1.5530973451327434, "no_speech_prob": 3.844909315375844e-06}, {"id": 1295, "seek": 604730, "start": 6066.06, "end": 6067.3, "text": " What's it for?", "tokens": [708, 311, 309, 337, 30], "temperature": 0.0, "avg_logprob": -0.23274014920604472, "compression_ratio": 1.5530973451327434, "no_speech_prob": 3.844909315375844e-06}, {"id": 1296, "seek": 604730, "start": 6067.3, "end": 6071.900000000001, "text": " right and the answer is Kovana wanted this because they wanted to be able to take", "tokens": [558, 293, 264, 1867, 307, 591, 5179, 2095, 1415, 341, 570, 436, 1415, 281, 312, 1075, 281, 747], "temperature": 0.0, "avg_logprob": -0.23274014920604472, "compression_ratio": 1.5530973451327434, "no_speech_prob": 3.844909315375844e-06}, {"id": 1297, "seek": 604730, "start": 6072.58, "end": 6074.860000000001, "text": " their car images and", "tokens": [641, 1032, 5267, 293], "temperature": 0.0, "avg_logprob": -0.23274014920604472, "compression_ratio": 1.5530973451327434, "no_speech_prob": 3.844909315375844e-06}, {"id": 1298, "seek": 607486, "start": 6074.86, "end": 6081.339999999999, "text": " Cut them out and paste them on you know, exotic Monte Carlo backgrounds", "tokens": [9431, 552, 484, 293, 9163, 552, 322, 291, 458, 11, 27063, 38105, 45112, 17336], "temperature": 0.0, "avg_logprob": -0.2233893594076467, "compression_ratio": 1.583710407239819, "no_speech_prob": 9.972763109544758e-06}, {"id": 1299, "seek": 607486, "start": 6082.339999999999, "end": 6085.08, "text": " That's Monte Carlo the place not the simulation", "tokens": [663, 311, 38105, 45112, 264, 1081, 406, 264, 16575], "temperature": 0.0, "avg_logprob": -0.2233893594076467, "compression_ratio": 1.583710407239819, "no_speech_prob": 9.972763109544758e-06}, {"id": 1300, "seek": 607486, "start": 6087.0599999999995, "end": 6088.299999999999, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.2233893594076467, "compression_ratio": 1.583710407239819, "no_speech_prob": 9.972763109544758e-06}, {"id": 1301, "seek": 607486, "start": 6088.299999999999, "end": 6091.08, "text": " To do that. You need a really good mask", "tokens": [1407, 360, 300, 13, 509, 643, 257, 534, 665, 6094], "temperature": 0.0, "avg_logprob": -0.2233893594076467, "compression_ratio": 1.583710407239819, "no_speech_prob": 9.972763109544758e-06}, {"id": 1302, "seek": 607486, "start": 6091.66, "end": 6096.86, "text": " Right. You don't want to like leave the rear view mirrors behind or like, you know", "tokens": [1779, 13, 509, 500, 380, 528, 281, 411, 1856, 264, 8250, 1910, 24238, 2261, 420, 411, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.2233893594076467, "compression_ratio": 1.583710407239819, "no_speech_prob": 9.972763109544758e-06}, {"id": 1303, "seek": 607486, "start": 6096.86, "end": 6102.82, "text": " Kind of have one wheel missing or include a little bit of background or something that would look stupid", "tokens": [9242, 295, 362, 472, 5589, 5361, 420, 4090, 257, 707, 857, 295, 3678, 420, 746, 300, 576, 574, 6631], "temperature": 0.0, "avg_logprob": -0.2233893594076467, "compression_ratio": 1.583710407239819, "no_speech_prob": 9.972763109544758e-06}, {"id": 1304, "seek": 610282, "start": 6102.82, "end": 6109.34, "text": " So you would need something very good. So only having 96% of the pixels correct doesn't sound great", "tokens": [407, 291, 576, 643, 746, 588, 665, 13, 407, 787, 1419, 24124, 4, 295, 264, 18668, 3006, 1177, 380, 1626, 869], "temperature": 0.0, "avg_logprob": -0.17896251020760373, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411211299768183e-06}, {"id": 1305, "seek": 610282, "start": 6109.86, "end": 6111.86, "text": " Right, but we won't really know until we look at it", "tokens": [1779, 11, 457, 321, 1582, 380, 534, 458, 1826, 321, 574, 412, 309], "temperature": 0.0, "avg_logprob": -0.17896251020760373, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411211299768183e-06}, {"id": 1306, "seek": 610282, "start": 6112.46, "end": 6114.46, "text": " So let's look at it", "tokens": [407, 718, 311, 574, 412, 309], "temperature": 0.0, "avg_logprob": -0.17896251020760373, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411211299768183e-06}, {"id": 1307, "seek": 610282, "start": 6114.86, "end": 6118.299999999999, "text": " So there's the correct version that we want to cut out", "tokens": [407, 456, 311, 264, 3006, 3037, 300, 321, 528, 281, 1723, 484], "temperature": 0.0, "avg_logprob": -0.17896251020760373, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411211299768183e-06}, {"id": 1308, "seek": 610282, "start": 6119.179999999999, "end": 6121.179999999999, "text": " That's the 96% accurate version", "tokens": [663, 311, 264, 24124, 4, 8559, 3037], "temperature": 0.0, "avg_logprob": -0.17896251020760373, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411211299768183e-06}, {"id": 1309, "seek": 610282, "start": 6122.42, "end": 6124.42, "text": " Okay, so like", "tokens": [1033, 11, 370, 411], "temperature": 0.0, "avg_logprob": -0.17896251020760373, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411211299768183e-06}, {"id": 1310, "seek": 610282, "start": 6124.42, "end": 6126.42, "text": " When you look at it, you realize oh, yeah", "tokens": [1133, 291, 574, 412, 309, 11, 291, 4325, 1954, 11, 1338], "temperature": 0.0, "avg_logprob": -0.17896251020760373, "compression_ratio": 1.7142857142857142, "no_speech_prob": 7.411211299768183e-06}, {"id": 1311, "seek": 612642, "start": 6126.42, "end": 6133.62, "text": " Getting 90% 96% of the pixels accurate is actually easy because like all the outside bits not car and all the inside bit is car", "tokens": [13674, 4289, 4, 24124, 4, 295, 264, 18668, 8559, 307, 767, 1858, 570, 411, 439, 264, 2380, 9239, 406, 1032, 293, 439, 264, 1854, 857, 307, 1032], "temperature": 0.0, "avg_logprob": -0.19381567018221965, "compression_ratio": 1.6337448559670782, "no_speech_prob": 1.2411294846970122e-05}, {"id": 1312, "seek": 612642, "start": 6133.62, "end": 6135.62, "text": " And really very interesting bit is the edge", "tokens": [400, 534, 588, 1880, 857, 307, 264, 4691], "temperature": 0.0, "avg_logprob": -0.19381567018221965, "compression_ratio": 1.6337448559670782, "no_speech_prob": 1.2411294846970122e-05}, {"id": 1313, "seek": 612642, "start": 6136.18, "end": 6138.18, "text": " Okay, so we need to do better", "tokens": [1033, 11, 370, 321, 643, 281, 360, 1101], "temperature": 0.0, "avg_logprob": -0.19381567018221965, "compression_ratio": 1.6337448559670782, "no_speech_prob": 1.2411294846970122e-05}, {"id": 1314, "seek": 612642, "start": 6139.66, "end": 6143.9800000000005, "text": " So let's unfreeze because all we've done so far is train the custom here", "tokens": [407, 718, 311, 3971, 701, 1381, 570, 439, 321, 600, 1096, 370, 1400, 307, 3847, 264, 2375, 510], "temperature": 0.0, "avg_logprob": -0.19381567018221965, "compression_ratio": 1.6337448559670782, "no_speech_prob": 1.2411294846970122e-05}, {"id": 1315, "seek": 612642, "start": 6144.3, "end": 6148.64, "text": " Okay, and let's do more and so after a bit more we've got 99.1%", "tokens": [1033, 11, 293, 718, 311, 360, 544, 293, 370, 934, 257, 857, 544, 321, 600, 658, 11803, 13, 16, 4], "temperature": 0.0, "avg_logprob": -0.19381567018221965, "compression_ratio": 1.6337448559670782, "no_speech_prob": 1.2411294846970122e-05}, {"id": 1316, "seek": 612642, "start": 6149.38, "end": 6154.34, "text": " Okay, so is that good? I don't know. Let's take a look and", "tokens": [1033, 11, 370, 307, 300, 665, 30, 286, 500, 380, 458, 13, 961, 311, 747, 257, 574, 293], "temperature": 0.0, "avg_logprob": -0.19381567018221965, "compression_ratio": 1.6337448559670782, "no_speech_prob": 1.2411294846970122e-05}, {"id": 1317, "seek": 615434, "start": 6154.34, "end": 6158.46, "text": " And so actually no, it's totally missed", "tokens": [400, 370, 767, 572, 11, 309, 311, 3879, 6721], "temperature": 0.0, "avg_logprob": -0.17409855319607642, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.5612716854084283e-06}, {"id": 1318, "seek": 615434, "start": 6159.14, "end": 6161.14, "text": " the rear-view vision mirror here and", "tokens": [264, 8250, 12, 1759, 5201, 8013, 510, 293], "temperature": 0.0, "avg_logprob": -0.17409855319607642, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.5612716854084283e-06}, {"id": 1319, "seek": 615434, "start": 6161.46, "end": 6166.860000000001, "text": " Missed a lot of it here and it's clearly got an edge wrong here. And these things are totally going to matter", "tokens": [5275, 292, 257, 688, 295, 309, 510, 293, 309, 311, 4448, 658, 364, 4691, 2085, 510, 13, 400, 613, 721, 366, 3879, 516, 281, 1871], "temperature": 0.0, "avg_logprob": -0.17409855319607642, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.5612716854084283e-06}, {"id": 1320, "seek": 615434, "start": 6167.42, "end": 6170.02, "text": " When we try to cut it out, so it's still not good enough", "tokens": [1133, 321, 853, 281, 1723, 309, 484, 11, 370, 309, 311, 920, 406, 665, 1547], "temperature": 0.0, "avg_logprob": -0.17409855319607642, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.5612716854084283e-06}, {"id": 1321, "seek": 615434, "start": 6170.26, "end": 6175.06, "text": " So let's try up scaling and the nice thing is that when we upscale to 512 by 512", "tokens": [407, 718, 311, 853, 493, 21589, 293, 264, 1481, 551, 307, 300, 562, 321, 493, 20033, 281, 1025, 4762, 538, 1025, 4762], "temperature": 0.0, "avg_logprob": -0.17409855319607642, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.5612716854084283e-06}, {"id": 1322, "seek": 615434, "start": 6175.06, "end": 6177.9800000000005, "text": " Make sure you decrease the batch size because you'll run out of memory", "tokens": [4387, 988, 291, 11514, 264, 15245, 2744, 570, 291, 603, 1190, 484, 295, 4675], "temperature": 0.0, "avg_logprob": -0.17409855319607642, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.5612716854084283e-06}, {"id": 1323, "seek": 615434, "start": 6179.18, "end": 6181.18, "text": " You know, here's the true ones", "tokens": [509, 458, 11, 510, 311, 264, 2074, 2306], "temperature": 0.0, "avg_logprob": -0.17409855319607642, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.5612716854084283e-06}, {"id": 1324, "seek": 618118, "start": 6181.18, "end": 6183.46, "text": " And it's quite a lot more", "tokens": [400, 309, 311, 1596, 257, 688, 544], "temperature": 0.0, "avg_logprob": -0.23888850448155166, "compression_ratio": 1.5112107623318385, "no_speech_prob": 1.4063870366953779e-05}, {"id": 1325, "seek": 618118, "start": 6184.06, "end": 6190.3, "text": " This is all identical. It's quite a lot more information there for it to go on so our accuracy increases to 99.4%", "tokens": [639, 307, 439, 14800, 13, 467, 311, 1596, 257, 688, 544, 1589, 456, 337, 309, 281, 352, 322, 370, 527, 14170, 8637, 281, 11803, 13, 19, 4], "temperature": 0.0, "avg_logprob": -0.23888850448155166, "compression_ratio": 1.5112107623318385, "no_speech_prob": 1.4063870366953779e-05}, {"id": 1326, "seek": 618118, "start": 6191.1, "end": 6195.780000000001, "text": " And things keep getting better, but we've still got quite a few little black blocky bits", "tokens": [400, 721, 1066, 1242, 1101, 11, 457, 321, 600, 920, 658, 1596, 257, 1326, 707, 2211, 3461, 88, 9239], "temperature": 0.0, "avg_logprob": -0.23888850448155166, "compression_ratio": 1.5112107623318385, "no_speech_prob": 1.4063870366953779e-05}, {"id": 1327, "seek": 618118, "start": 6196.9400000000005, "end": 6200.46, "text": " So let's go to 124 by 124 down to batch size of 4", "tokens": [407, 718, 311, 352, 281, 2272, 19, 538, 2272, 19, 760, 281, 15245, 2744, 295, 1017], "temperature": 0.0, "avg_logprob": -0.23888850448155166, "compression_ratio": 1.5112107623318385, "no_speech_prob": 1.4063870366953779e-05}, {"id": 1328, "seek": 618118, "start": 6201.5, "end": 6204.9400000000005, "text": " This is pretty high res now and train a bit more", "tokens": [639, 307, 1238, 1090, 725, 586, 293, 3847, 257, 857, 544], "temperature": 0.0, "avg_logprob": -0.23888850448155166, "compression_ratio": 1.5112107623318385, "no_speech_prob": 1.4063870366953779e-05}, {"id": 1329, "seek": 618118, "start": 6206.02, "end": 6208.02, "text": " 99.6", "tokens": [11803, 13, 21], "temperature": 0.0, "avg_logprob": -0.23888850448155166, "compression_ratio": 1.5112107623318385, "no_speech_prob": 1.4063870366953779e-05}, {"id": 1330, "seek": 620802, "start": 6208.02, "end": 6211.02, "text": " 99.8 and", "tokens": [11803, 13, 23, 293], "temperature": 0.0, "avg_logprob": -0.27046504301183366, "compression_ratio": 1.5595854922279793, "no_speech_prob": 5.507539754034951e-06}, {"id": 1331, "seek": 620802, "start": 6211.5, "end": 6215.660000000001, "text": " So now if we look at the masks, they're actually looking", "tokens": [407, 586, 498, 321, 574, 412, 264, 11830, 11, 436, 434, 767, 1237], "temperature": 0.0, "avg_logprob": -0.27046504301183366, "compression_ratio": 1.5595854922279793, "no_speech_prob": 5.507539754034951e-06}, {"id": 1332, "seek": 620802, "start": 6216.620000000001, "end": 6223.620000000001, "text": " Not bad. Okay, that's looking pretty good. All right, so can we do better and the answer is", "tokens": [1726, 1578, 13, 1033, 11, 300, 311, 1237, 1238, 665, 13, 1057, 558, 11, 370, 393, 321, 360, 1101, 293, 264, 1867, 307], "temperature": 0.0, "avg_logprob": -0.27046504301183366, "compression_ratio": 1.5595854922279793, "no_speech_prob": 5.507539754034951e-06}, {"id": 1333, "seek": 620802, "start": 6224.38, "end": 6226.38, "text": " Yes, we can", "tokens": [1079, 11, 321, 393], "temperature": 0.0, "avg_logprob": -0.27046504301183366, "compression_ratio": 1.5595854922279793, "no_speech_prob": 5.507539754034951e-06}, {"id": 1334, "seek": 620802, "start": 6226.740000000001, "end": 6234.540000000001, "text": " So we're moving from the carvana notebook to the carvana unit notebook now and the unit network is quite magnificent", "tokens": [407, 321, 434, 2684, 490, 264, 1032, 39259, 21060, 281, 264, 1032, 39259, 4985, 21060, 586, 293, 264, 4985, 3209, 307, 1596, 23690], "temperature": 0.0, "avg_logprob": -0.27046504301183366, "compression_ratio": 1.5595854922279793, "no_speech_prob": 5.507539754034951e-06}, {"id": 1335, "seek": 620802, "start": 6234.540000000001, "end": 6236.46, "text": " Right, you see", "tokens": [1779, 11, 291, 536], "temperature": 0.0, "avg_logprob": -0.27046504301183366, "compression_ratio": 1.5595854922279793, "no_speech_prob": 5.507539754034951e-06}, {"id": 1336, "seek": 623646, "start": 6236.46, "end": 6243.2, "text": " With that previous approach our pre trained image net network was being squished down all the way down to 7 by 7", "tokens": [2022, 300, 3894, 3109, 527, 659, 8895, 3256, 2533, 3209, 390, 885, 2339, 4729, 760, 439, 264, 636, 760, 281, 1614, 538, 1614], "temperature": 0.0, "avg_logprob": -0.2747657368484053, "compression_ratio": 1.6790123456790123, "no_speech_prob": 9.66598599916324e-06}, {"id": 1337, "seek": 623646, "start": 6243.2, "end": 6248.18, "text": " And then expanded out all the way back up to you know, well, it's 2 2 4", "tokens": [400, 550, 14342, 484, 439, 264, 636, 646, 493, 281, 291, 458, 11, 731, 11, 309, 311, 568, 568, 1017], "temperature": 0.0, "avg_logprob": -0.2747657368484053, "compression_ratio": 1.6790123456790123, "no_speech_prob": 9.66598599916324e-06}, {"id": 1338, "seek": 623646, "start": 6248.18, "end": 6252.58, "text": " Go to 7 by 7 for 1 or 2 4. It's going quite a bit bigger and then expanded out", "tokens": [1037, 281, 1614, 538, 1614, 337, 502, 420, 568, 1017, 13, 467, 311, 516, 1596, 257, 857, 3801, 293, 550, 14342, 484], "temperature": 0.0, "avg_logprob": -0.2747657368484053, "compression_ratio": 1.6790123456790123, "no_speech_prob": 9.66598599916324e-06}, {"id": 1339, "seek": 623646, "start": 6253.54, "end": 6260.78, "text": " Again all this way which means it has to somehow store all the information about the much bigger version in the small version", "tokens": [3764, 439, 341, 636, 597, 1355, 309, 575, 281, 6063, 3531, 439, 264, 1589, 466, 264, 709, 3801, 3037, 294, 264, 1359, 3037], "temperature": 0.0, "avg_logprob": -0.2747657368484053, "compression_ratio": 1.6790123456790123, "no_speech_prob": 9.66598599916324e-06}, {"id": 1340, "seek": 623646, "start": 6260.9800000000005, "end": 6262.9800000000005, "text": " right and actually", "tokens": [558, 293, 767], "temperature": 0.0, "avg_logprob": -0.2747657368484053, "compression_ratio": 1.6790123456790123, "no_speech_prob": 9.66598599916324e-06}, {"id": 1341, "seek": 626298, "start": 6262.98, "end": 6266.78, "text": " Most of the information about the bigger version was really in the original picture anyway", "tokens": [4534, 295, 264, 1589, 466, 264, 3801, 3037, 390, 534, 294, 264, 3380, 3036, 4033], "temperature": 0.0, "avg_logprob": -0.16272727302882983, "compression_ratio": 1.6450381679389312, "no_speech_prob": 6.048819614079548e-06}, {"id": 1342, "seek": 626298, "start": 6267.459999999999, "end": 6271.74, "text": " So it doesn't seem like a great approach this squishing and unsquishing", "tokens": [407, 309, 1177, 380, 1643, 411, 257, 869, 3109, 341, 2339, 3807, 293, 2693, 358, 3807], "temperature": 0.0, "avg_logprob": -0.16272727302882983, "compression_ratio": 1.6450381679389312, "no_speech_prob": 6.048819614079548e-06}, {"id": 1343, "seek": 626298, "start": 6272.9, "end": 6279.7, "text": " so the unit idea comes from this fantastic paper where like it was literally invented in this", "tokens": [370, 264, 4985, 1558, 1487, 490, 341, 5456, 3035, 689, 411, 309, 390, 3736, 14479, 294, 341], "temperature": 0.0, "avg_logprob": -0.16272727302882983, "compression_ratio": 1.6450381679389312, "no_speech_prob": 6.048819614079548e-06}, {"id": 1344, "seek": 626298, "start": 6280.259999999999, "end": 6284.459999999999, "text": " You know very domain specific area of biomedical image segmentation", "tokens": [509, 458, 588, 9274, 2685, 1859, 295, 49775, 3256, 9469, 399], "temperature": 0.0, "avg_logprob": -0.16272727302882983, "compression_ratio": 1.6450381679389312, "no_speech_prob": 6.048819614079548e-06}, {"id": 1345, "seek": 626298, "start": 6284.459999999999, "end": 6291.62, "text": " But in fact basically every Kaggle winner in in anything even vaguely related to segmentation has ended up", "tokens": [583, 294, 1186, 1936, 633, 48751, 22631, 8507, 294, 294, 1340, 754, 13501, 48863, 4077, 281, 9469, 399, 575, 4590, 493], "temperature": 0.0, "avg_logprob": -0.16272727302882983, "compression_ratio": 1.6450381679389312, "no_speech_prob": 6.048819614079548e-06}, {"id": 1346, "seek": 629162, "start": 6291.62, "end": 6299.7, "text": " Using unit it's one of these things that like everybody in Kaggle knows is the best practice but in more of academic circles", "tokens": [11142, 4985, 309, 311, 472, 295, 613, 721, 300, 411, 2201, 294, 48751, 22631, 3255, 307, 264, 1151, 3124, 457, 294, 544, 295, 7778, 13040], "temperature": 0.0, "avg_logprob": -0.17055763517107284, "compression_ratio": 1.6359447004608294, "no_speech_prob": 8.013422302610707e-06}, {"id": 1347, "seek": 629162, "start": 6300.38, "end": 6305.0599999999995, "text": " Like even now this has been around for a couple of years at least a lot of people still don't realize", "tokens": [1743, 754, 586, 341, 575, 668, 926, 337, 257, 1916, 295, 924, 412, 1935, 257, 688, 295, 561, 920, 500, 380, 4325], "temperature": 0.0, "avg_logprob": -0.17055763517107284, "compression_ratio": 1.6359447004608294, "no_speech_prob": 8.013422302610707e-06}, {"id": 1348, "seek": 629162, "start": 6305.0599999999995, "end": 6308.34, "text": " But it's like this is by far the best approach", "tokens": [583, 309, 311, 411, 341, 307, 538, 1400, 264, 1151, 3109], "temperature": 0.0, "avg_logprob": -0.17055763517107284, "compression_ratio": 1.6359447004608294, "no_speech_prob": 8.013422302610707e-06}, {"id": 1349, "seek": 629162, "start": 6310.7, "end": 6315.84, "text": " And here's the basic idea here's the downward path right where we basically start", "tokens": [400, 510, 311, 264, 3875, 1558, 510, 311, 264, 24805, 3100, 558, 689, 321, 1936, 722], "temperature": 0.0, "avg_logprob": -0.17055763517107284, "compression_ratio": 1.6359447004608294, "no_speech_prob": 8.013422302610707e-06}, {"id": 1350, "seek": 631584, "start": 6315.84, "end": 6322.84, "text": " Start at 572 by 532 in this case and then kind of half the grid size half the grid size half the grid size half the grid size right and then here's the upward path where we double the grid size double double double double", "tokens": [6481, 412, 21423, 17, 538, 1025, 11440, 294, 341, 1389, 293, 550, 733, 295, 1922, 264, 10748, 2744, 1922, 264, 10748, 2744, 1922, 264, 10748, 2744, 1922, 264, 10748, 2744, 558, 293, 550, 510, 311, 264, 23452, 3100, 689, 321, 3834, 264, 10748, 2744, 3834, 3834, 3834, 3834], "temperature": 0.0, "avg_logprob": -0.29582113101158614, "compression_ratio": 1.9691358024691359, "no_speech_prob": 8.397971214435529e-06}, {"id": 1351, "seek": 631584, "start": 6335.64, "end": 6337.28, "text": " But the", "tokens": [583, 264], "temperature": 0.0, "avg_logprob": -0.29582113101158614, "compression_ratio": 1.9691358024691359, "no_speech_prob": 8.397971214435529e-06}, {"id": 1352, "seek": 631584, "start": 6337.28, "end": 6340.22, "text": " Thing that we also do is we take", "tokens": [30902, 300, 321, 611, 360, 307, 321, 747], "temperature": 0.0, "avg_logprob": -0.29582113101158614, "compression_ratio": 1.9691358024691359, "no_speech_prob": 8.397971214435529e-06}, {"id": 1353, "seek": 631584, "start": 6340.78, "end": 6343.72, "text": " You know at every point where we've halved the grid size", "tokens": [509, 458, 412, 633, 935, 689, 321, 600, 7523, 937, 264, 10748, 2744], "temperature": 0.0, "avg_logprob": -0.29582113101158614, "compression_ratio": 1.9691358024691359, "no_speech_prob": 8.397971214435529e-06}, {"id": 1354, "seek": 634372, "start": 6343.72, "end": 6351.240000000001, "text": " We actually copy those activations over to the upward path and and concatenate them together", "tokens": [492, 767, 5055, 729, 2430, 763, 670, 281, 264, 23452, 3100, 293, 293, 1588, 7186, 473, 552, 1214], "temperature": 0.0, "avg_logprob": -0.2690659267146413, "compression_ratio": 1.683673469387755, "no_speech_prob": 4.425457063916838e-06}, {"id": 1355, "seek": 634372, "start": 6352.72, "end": 6359.360000000001, "text": " And so you can see here these red blobs of max pooling operations the green blobs are", "tokens": [400, 370, 291, 393, 536, 510, 613, 2182, 1749, 929, 295, 11469, 7005, 278, 7705, 264, 3092, 1749, 929, 366], "temperature": 0.0, "avg_logprob": -0.2690659267146413, "compression_ratio": 1.683673469387755, "no_speech_prob": 4.425457063916838e-06}, {"id": 1356, "seek": 634372, "start": 6359.84, "end": 6362.52, "text": " upward sampling and then these", "tokens": [23452, 21179, 293, 550, 613], "temperature": 0.0, "avg_logprob": -0.2690659267146413, "compression_ratio": 1.683673469387755, "no_speech_prob": 4.425457063916838e-06}, {"id": 1357, "seek": 634372, "start": 6362.96, "end": 6364.76, "text": " gray bits here are", "tokens": [10855, 9239, 510, 366], "temperature": 0.0, "avg_logprob": -0.2690659267146413, "compression_ratio": 1.683673469387755, "no_speech_prob": 4.425457063916838e-06}, {"id": 1358, "seek": 634372, "start": 6364.76, "end": 6365.96, "text": " copying", "tokens": [27976], "temperature": 0.0, "avg_logprob": -0.2690659267146413, "compression_ratio": 1.683673469387755, "no_speech_prob": 4.425457063916838e-06}, {"id": 1359, "seek": 634372, "start": 6365.96, "end": 6371.64, "text": " Right and so we copy and concat so basically in other words the input image after a couple of", "tokens": [1779, 293, 370, 321, 5055, 293, 1588, 267, 370, 1936, 294, 661, 2283, 264, 4846, 3256, 934, 257, 1916, 295], "temperature": 0.0, "avg_logprob": -0.2690659267146413, "compression_ratio": 1.683673469387755, "no_speech_prob": 4.425457063916838e-06}, {"id": 1360, "seek": 637164, "start": 6371.64, "end": 6374.84, "text": " Poms is copied over to the output", "tokens": [430, 4785, 307, 25365, 670, 281, 264, 5598], "temperature": 0.0, "avg_logprob": -0.20342035004586884, "compression_ratio": 1.885321100917431, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1361, "seek": 637164, "start": 6376.240000000001, "end": 6382.04, "text": " Concatenated together and so now we get to use all of the information has gone through all the down and all the up", "tokens": [18200, 7186, 770, 1214, 293, 370, 586, 321, 483, 281, 764, 439, 295, 264, 1589, 575, 2780, 807, 439, 264, 760, 293, 439, 264, 493], "temperature": 0.0, "avg_logprob": -0.20342035004586884, "compression_ratio": 1.885321100917431, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1362, "seek": 637164, "start": 6382.240000000001, "end": 6385.64, "text": " Plus also a slightly modified version of the input pixels", "tokens": [7721, 611, 257, 4748, 15873, 3037, 295, 264, 4846, 18668], "temperature": 0.0, "avg_logprob": -0.20342035004586884, "compression_ratio": 1.885321100917431, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1363, "seek": 637164, "start": 6385.96, "end": 6391.5, "text": " Right and a slightly modified version of one thing down from the input pixels because they came out through here", "tokens": [1779, 293, 257, 4748, 15873, 3037, 295, 472, 551, 760, 490, 264, 4846, 18668, 570, 436, 1361, 484, 807, 510], "temperature": 0.0, "avg_logprob": -0.20342035004586884, "compression_ratio": 1.885321100917431, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1364, "seek": 637164, "start": 6391.5, "end": 6393.5, "text": " right, so we have like", "tokens": [558, 11, 370, 321, 362, 411], "temperature": 0.0, "avg_logprob": -0.20342035004586884, "compression_ratio": 1.885321100917431, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1365, "seek": 637164, "start": 6394.08, "end": 6398.6, "text": " all of the richness of going all the way down and up but also like a", "tokens": [439, 295, 264, 44506, 295, 516, 439, 264, 636, 760, 293, 493, 457, 611, 411, 257], "temperature": 0.0, "avg_logprob": -0.20342035004586884, "compression_ratio": 1.885321100917431, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1366, "seek": 639860, "start": 6398.6, "end": 6405.76, "text": " Slightly less cost version and a slightly less cost version and then it's really kind of simple version and they can all be combined together", "tokens": [318, 44872, 1570, 2063, 3037, 293, 257, 4748, 1570, 2063, 3037, 293, 550, 309, 311, 534, 733, 295, 2199, 3037, 293, 436, 393, 439, 312, 9354, 1214], "temperature": 0.0, "avg_logprob": -0.28691071555728004, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.644226176722441e-05}, {"id": 1367, "seek": 639860, "start": 6406.280000000001, "end": 6408.280000000001, "text": " Okay, and so that's unit", "tokens": [1033, 11, 293, 370, 300, 311, 4985], "temperature": 0.0, "avg_logprob": -0.28691071555728004, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.644226176722441e-05}, {"id": 1368, "seek": 639860, "start": 6408.8, "end": 6410.8, "text": " such a cool idea", "tokens": [1270, 257, 1627, 1558], "temperature": 0.0, "avg_logprob": -0.28691071555728004, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.644226176722441e-05}, {"id": 1369, "seek": 639860, "start": 6411.08, "end": 6413.08, "text": " so here we are in the in the", "tokens": [370, 510, 321, 366, 294, 264, 294, 264], "temperature": 0.0, "avg_logprob": -0.28691071555728004, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.644226176722441e-05}, {"id": 1370, "seek": 639860, "start": 6413.6, "end": 6416.160000000001, "text": " Carvana unit notebook. Well, this is the same code as before", "tokens": [2741, 39259, 4985, 21060, 13, 1042, 11, 341, 307, 264, 912, 3089, 382, 949], "temperature": 0.0, "avg_logprob": -0.28691071555728004, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.644226176722441e-05}, {"id": 1371, "seek": 639860, "start": 6417.360000000001, "end": 6419.360000000001, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.28691071555728004, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.644226176722441e-05}, {"id": 1372, "seek": 639860, "start": 6419.6, "end": 6421.6, "text": " at the start I've got a", "tokens": [412, 264, 722, 286, 600, 658, 257], "temperature": 0.0, "avg_logprob": -0.28691071555728004, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.644226176722441e-05}, {"id": 1373, "seek": 642160, "start": 6421.6, "end": 6428.76, "text": " Simple up sample version just to kind of show you again the non unit version this time", "tokens": [21532, 493, 6889, 3037, 445, 281, 733, 295, 855, 291, 797, 264, 2107, 4985, 3037, 341, 565], "temperature": 0.0, "avg_logprob": -0.2876879650613536, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.4063851267565042e-05}, {"id": 1374, "seek": 642160, "start": 6428.76, "end": 6434.56, "text": " I'm going to add in something called the dice metric dice is very similar as you see to", "tokens": [286, 478, 516, 281, 909, 294, 746, 1219, 264, 10313, 20678, 10313, 307, 588, 2531, 382, 291, 536, 281], "temperature": 0.0, "avg_logprob": -0.2876879650613536, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.4063851267565042e-05}, {"id": 1375, "seek": 642160, "start": 6435.6, "end": 6439.8, "text": " Jakarta or I over you it's just a minor difference. It's basically", "tokens": [15029, 19061, 420, 286, 670, 291, 309, 311, 445, 257, 6696, 2649, 13, 467, 311, 1936], "temperature": 0.0, "avg_logprob": -0.2876879650613536, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.4063851267565042e-05}, {"id": 1376, "seek": 642160, "start": 6441.200000000001, "end": 6443.400000000001, "text": " intersection over union", "tokens": [15236, 670, 11671], "temperature": 0.0, "avg_logprob": -0.2876879650613536, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.4063851267565042e-05}, {"id": 1377, "seek": 642160, "start": 6444.360000000001, "end": 6445.64, "text": " with a", "tokens": [365, 257], "temperature": 0.0, "avg_logprob": -0.2876879650613536, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.4063851267565042e-05}, {"id": 1378, "seek": 644564, "start": 6445.64, "end": 6453.72, "text": " Minor tweak and the reason we're going to use dice is that's the metric that the Kaggle competition used and it's kind of", "tokens": [36117, 29879, 293, 264, 1778, 321, 434, 516, 281, 764, 10313, 307, 300, 311, 264, 20678, 300, 264, 48751, 22631, 6211, 1143, 293, 309, 311, 733, 295], "temperature": 0.0, "avg_logprob": -0.16295571597117298, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.3006815606786404e-05}, {"id": 1379, "seek": 644564, "start": 6454.08, "end": 6457.68, "text": " It's a little bit harder to get a high dice score than a high accuracy", "tokens": [467, 311, 257, 707, 857, 6081, 281, 483, 257, 1090, 10313, 6175, 813, 257, 1090, 14170], "temperature": 0.0, "avg_logprob": -0.16295571597117298, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.3006815606786404e-05}, {"id": 1380, "seek": 644564, "start": 6458.240000000001, "end": 6463.52, "text": " Because it's really looking at like what the overlap of the correct pixels are with with your pixels", "tokens": [1436, 309, 311, 534, 1237, 412, 411, 437, 264, 19959, 295, 264, 3006, 18668, 366, 365, 365, 428, 18668], "temperature": 0.0, "avg_logprob": -0.16295571597117298, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.3006815606786404e-05}, {"id": 1381, "seek": 644564, "start": 6464.400000000001, "end": 6466.400000000001, "text": " It's pretty similar", "tokens": [467, 311, 1238, 2531], "temperature": 0.0, "avg_logprob": -0.16295571597117298, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.3006815606786404e-05}, {"id": 1382, "seek": 644564, "start": 6466.52, "end": 6470.72, "text": " So in the Kaggle competition people that were doing okay", "tokens": [407, 294, 264, 48751, 22631, 6211, 561, 300, 645, 884, 1392], "temperature": 0.0, "avg_logprob": -0.16295571597117298, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.3006815606786404e-05}, {"id": 1383, "seek": 647072, "start": 6470.72, "end": 6475.88, "text": " We're getting about 99.6 dice and the winners were about 99.7 dice", "tokens": [492, 434, 1242, 466, 11803, 13, 21, 10313, 293, 264, 17193, 645, 466, 11803, 13, 22, 10313], "temperature": 0.0, "avg_logprob": -0.172959568988846, "compression_ratio": 1.5668449197860963, "no_speech_prob": 9.818163562158588e-06}, {"id": 1384, "seek": 647072, "start": 6477.56, "end": 6479.360000000001, "text": " So here's our standard up sample", "tokens": [407, 510, 311, 527, 3832, 493, 6889], "temperature": 0.0, "avg_logprob": -0.172959568988846, "compression_ratio": 1.5668449197860963, "no_speech_prob": 9.818163562158588e-06}, {"id": 1385, "seek": 647072, "start": 6479.360000000001, "end": 6485.740000000001, "text": " This is all as before and so now we can check our dice metric and so you can see on dice metric", "tokens": [639, 307, 439, 382, 949, 293, 370, 586, 321, 393, 1520, 527, 10313, 20678, 293, 370, 291, 393, 536, 322, 10313, 20678], "temperature": 0.0, "avg_logprob": -0.172959568988846, "compression_ratio": 1.5668449197860963, "no_speech_prob": 9.818163562158588e-06}, {"id": 1386, "seek": 647072, "start": 6486.240000000001, "end": 6491.92, "text": " We're getting like nine six eight at 128 by 128 and so that's not", "tokens": [492, 434, 1242, 411, 4949, 2309, 3180, 412, 29810, 538, 29810, 293, 370, 300, 311, 406], "temperature": 0.0, "avg_logprob": -0.172959568988846, "compression_ratio": 1.5668449197860963, "no_speech_prob": 9.818163562158588e-06}, {"id": 1387, "seek": 647072, "start": 6492.84, "end": 6495.84, "text": " Great. Okay, so that's the real", "tokens": [3769, 13, 1033, 11, 370, 300, 311, 264, 957], "temperature": 0.0, "avg_logprob": -0.172959568988846, "compression_ratio": 1.5668449197860963, "no_speech_prob": 9.818163562158588e-06}, {"id": 1388, "seek": 649584, "start": 6495.84, "end": 6502.22, "text": " So let's try unit and I'm calling it unit ish because as per usual I'm creating my own", "tokens": [407, 718, 311, 853, 4985, 293, 286, 478, 5141, 309, 4985, 307, 71, 570, 382, 680, 7713, 286, 478, 4084, 452, 1065], "temperature": 0.0, "avg_logprob": -0.19688214960786485, "compression_ratio": 1.6610878661087867, "no_speech_prob": 1.644214898988139e-05}, {"id": 1389, "seek": 649584, "start": 6503.1, "end": 6509.56, "text": " Somewhat hacky version right kind of trying to keep things as similar to what you're used to as possible and doing things that I think", "tokens": [2188, 5479, 10339, 88, 3037, 558, 733, 295, 1382, 281, 1066, 721, 382, 2531, 281, 437, 291, 434, 1143, 281, 382, 1944, 293, 884, 721, 300, 286, 519], "temperature": 0.0, "avg_logprob": -0.19688214960786485, "compression_ratio": 1.6610878661087867, "no_speech_prob": 1.644214898988139e-05}, {"id": 1390, "seek": 649584, "start": 6509.56, "end": 6511.56, "text": " makes sense and", "tokens": [1669, 2020, 293], "temperature": 0.0, "avg_logprob": -0.19688214960786485, "compression_ratio": 1.6610878661087867, "no_speech_prob": 1.644214898988139e-05}, {"id": 1391, "seek": 649584, "start": 6511.58, "end": 6514.06, "text": " So there should be plenty of opportunity for you to", "tokens": [407, 456, 820, 312, 7140, 295, 2650, 337, 291, 281], "temperature": 0.0, "avg_logprob": -0.19688214960786485, "compression_ratio": 1.6610878661087867, "no_speech_prob": 1.644214898988139e-05}, {"id": 1392, "seek": 649584, "start": 6514.54, "end": 6521.34, "text": " At least make this more authentically unit by looking at the exact kind of grid sizes and like see how here", "tokens": [1711, 1935, 652, 341, 544, 9214, 984, 4985, 538, 1237, 412, 264, 1900, 733, 295, 10748, 11602, 293, 411, 536, 577, 510], "temperature": 0.0, "avg_logprob": -0.19688214960786485, "compression_ratio": 1.6610878661087867, "no_speech_prob": 1.644214898988139e-05}, {"id": 1393, "seek": 652134, "start": 6521.34, "end": 6526.18, "text": " The size is going down a little bit. So they're obviously not adding any padding", "tokens": [440, 2744, 307, 516, 760, 257, 707, 857, 13, 407, 436, 434, 2745, 406, 5127, 604, 39562], "temperature": 0.0, "avg_logprob": -0.15502447723060525, "compression_ratio": 1.5965665236051503, "no_speech_prob": 4.029438514407957e-06}, {"id": 1394, "seek": 652134, "start": 6526.78, "end": 6532.1, "text": " And then they're doing here. They've got some cropping going on. There's a few differences, right?", "tokens": [400, 550, 436, 434, 884, 510, 13, 814, 600, 658, 512, 4848, 3759, 516, 322, 13, 821, 311, 257, 1326, 7300, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15502447723060525, "compression_ratio": 1.5965665236051503, "no_speech_prob": 4.029438514407957e-06}, {"id": 1395, "seek": 652134, "start": 6533.74, "end": 6537.1, "text": " But one of the things is because I want to take advantage of transfer learning", "tokens": [583, 472, 295, 264, 721, 307, 570, 286, 528, 281, 747, 5002, 295, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.15502447723060525, "compression_ratio": 1.5965665236051503, "no_speech_prob": 4.029438514407957e-06}, {"id": 1396, "seek": 652134, "start": 6537.78, "end": 6542.78, "text": " That means I can't quite use unit. So here's another big opportunity is", "tokens": [663, 1355, 286, 393, 380, 1596, 764, 4985, 13, 407, 510, 311, 1071, 955, 2650, 307], "temperature": 0.0, "avg_logprob": -0.15502447723060525, "compression_ratio": 1.5965665236051503, "no_speech_prob": 4.029438514407957e-06}, {"id": 1397, "seek": 652134, "start": 6543.82, "end": 6548.02, "text": " what if you create the unit down path and", "tokens": [437, 498, 291, 1884, 264, 4985, 760, 3100, 293], "temperature": 0.0, "avg_logprob": -0.15502447723060525, "compression_ratio": 1.5965665236051503, "no_speech_prob": 4.029438514407957e-06}, {"id": 1398, "seek": 654802, "start": 6548.02, "end": 6553.820000000001, "text": " then add a classifier on the end and then train that on image net and", "tokens": [550, 909, 257, 1508, 9902, 322, 264, 917, 293, 550, 3847, 300, 322, 3256, 2533, 293], "temperature": 0.0, "avg_logprob": -0.26651612917582196, "compression_ratio": 1.70995670995671, "no_speech_prob": 5.682394203176955e-06}, {"id": 1399, "seek": 654802, "start": 6554.780000000001, "end": 6557.9800000000005, "text": " You've now got an image net trained classifier", "tokens": [509, 600, 586, 658, 364, 3256, 2533, 8895, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.26651612917582196, "compression_ratio": 1.70995670995671, "no_speech_prob": 5.682394203176955e-06}, {"id": 1400, "seek": 654802, "start": 6558.580000000001, "end": 6561.820000000001, "text": " Which is specifically designed to be a good backbone for unit", "tokens": [3013, 307, 4682, 4761, 281, 312, 257, 665, 34889, 337, 4985], "temperature": 0.0, "avg_logprob": -0.26651612917582196, "compression_ratio": 1.70995670995671, "no_speech_prob": 5.682394203176955e-06}, {"id": 1401, "seek": 654802, "start": 6562.46, "end": 6565.1, "text": " right, and then you should be able to now come back and", "tokens": [558, 11, 293, 550, 291, 820, 312, 1075, 281, 586, 808, 646, 293], "temperature": 0.0, "avg_logprob": -0.26651612917582196, "compression_ratio": 1.70995670995671, "no_speech_prob": 5.682394203176955e-06}, {"id": 1402, "seek": 654802, "start": 6566.42, "end": 6569.18, "text": " Get pretty close to winning this old competition", "tokens": [3240, 1238, 1998, 281, 8224, 341, 1331, 6211], "temperature": 0.0, "avg_logprob": -0.26651612917582196, "compression_ratio": 1.70995670995671, "no_speech_prob": 5.682394203176955e-06}, {"id": 1403, "seek": 654802, "start": 6569.700000000001, "end": 6575.38, "text": " That's not it's actually not that old. It's fairly recent competition because you know that pre-trained network", "tokens": [663, 311, 406, 309, 311, 767, 406, 300, 1331, 13, 467, 311, 6457, 5162, 6211, 570, 291, 458, 300, 659, 12, 17227, 2001, 3209], "temperature": 0.0, "avg_logprob": -0.26651612917582196, "compression_ratio": 1.70995670995671, "no_speech_prob": 5.682394203176955e-06}, {"id": 1404, "seek": 657538, "start": 6575.38, "end": 6583.38, "text": " Didn't exist before but if you think about like what Yolo v3 did it's basically that right then they created dark net", "tokens": [11151, 380, 2514, 949, 457, 498, 291, 519, 466, 411, 437, 398, 7902, 371, 18, 630, 309, 311, 1936, 300, 558, 550, 436, 2942, 2877, 2533], "temperature": 0.0, "avg_logprob": -0.2906924027663011, "compression_ratio": 1.657258064516129, "no_speech_prob": 5.338100891094655e-06}, {"id": 1405, "seek": 657538, "start": 6583.46, "end": 6587.0, "text": " They pre-trained it on image net and then they used it as the basis for their", "tokens": [814, 659, 12, 17227, 2001, 309, 322, 3256, 2533, 293, 550, 436, 1143, 309, 382, 264, 5143, 337, 641], "temperature": 0.0, "avg_logprob": -0.2906924027663011, "compression_ratio": 1.657258064516129, "no_speech_prob": 5.338100891094655e-06}, {"id": 1406, "seek": 657538, "start": 6587.66, "end": 6589.22, "text": " founding boxes", "tokens": [22223, 9002], "temperature": 0.0, "avg_logprob": -0.2906924027663011, "compression_ratio": 1.657258064516129, "no_speech_prob": 5.338100891094655e-06}, {"id": 1407, "seek": 657538, "start": 6589.22, "end": 6590.78, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.2906924027663011, "compression_ratio": 1.657258064516129, "no_speech_prob": 5.338100891094655e-06}, {"id": 1408, "seek": 657538, "start": 6590.78, "end": 6592.78, "text": " again this kind of idea of", "tokens": [797, 341, 733, 295, 1558, 295], "temperature": 0.0, "avg_logprob": -0.2906924027663011, "compression_ratio": 1.657258064516129, "no_speech_prob": 5.338100891094655e-06}, {"id": 1409, "seek": 657538, "start": 6594.18, "end": 6597.14, "text": " Pre-training things which are designed not just for", "tokens": [6001, 12, 17227, 1760, 721, 597, 366, 4761, 406, 445, 337], "temperature": 0.0, "avg_logprob": -0.2906924027663011, "compression_ratio": 1.657258064516129, "no_speech_prob": 5.338100891094655e-06}, {"id": 1410, "seek": 659714, "start": 6597.14, "end": 6604.3, "text": " Your classification but defined for other things is just something that nobody's nobody's done yet. And as we've shown", "tokens": [2260, 21538, 457, 7642, 337, 661, 721, 307, 445, 746, 300, 5079, 311, 5079, 311, 1096, 1939, 13, 400, 382, 321, 600, 4898], "temperature": 0.0, "avg_logprob": -0.22724517373477712, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.637814527086448e-06}, {"id": 1411, "seek": 659714, "start": 6608.3, "end": 6613.42, "text": " But as we've shown, you know, you can train image net for 25 bucks in three hours", "tokens": [583, 382, 321, 600, 4898, 11, 291, 458, 11, 291, 393, 3847, 3256, 2533, 337, 3552, 11829, 294, 1045, 2496], "temperature": 0.0, "avg_logprob": -0.22724517373477712, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.637814527086448e-06}, {"id": 1412, "seek": 659714, "start": 6614.46, "end": 6616.46, "text": " Yeah, so", "tokens": [865, 11, 370], "temperature": 0.0, "avg_logprob": -0.22724517373477712, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.637814527086448e-06}, {"id": 1413, "seek": 659714, "start": 6616.9400000000005, "end": 6621.42, "text": " And if people in the community are interested in doing this, you know, hopefully I'll have credits", "tokens": [400, 498, 561, 294, 264, 1768, 366, 3102, 294, 884, 341, 11, 291, 458, 11, 4696, 286, 603, 362, 16816], "temperature": 0.0, "avg_logprob": -0.22724517373477712, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.637814527086448e-06}, {"id": 1414, "seek": 659714, "start": 6621.42, "end": 6622.62, "text": " I can help you with as well", "tokens": [286, 393, 854, 291, 365, 382, 731], "temperature": 0.0, "avg_logprob": -0.22724517373477712, "compression_ratio": 1.5849056603773586, "no_speech_prob": 4.637814527086448e-06}, {"id": 1415, "seek": 662262, "start": 6622.62, "end": 6627.46, "text": " So if you do, you know the work to get it set up and give me a script I can probably run it for you", "tokens": [407, 498, 291, 360, 11, 291, 458, 264, 589, 281, 483, 309, 992, 493, 293, 976, 385, 257, 5755, 286, 393, 1391, 1190, 309, 337, 291], "temperature": 0.0, "avg_logprob": -0.1506949414263715, "compression_ratio": 1.645, "no_speech_prob": 1.4510129403788596e-05}, {"id": 1416, "seek": 662262, "start": 6629.94, "end": 6633.18, "text": " So for now though, we don't have that so we're going to use resnet", "tokens": [407, 337, 586, 1673, 11, 321, 500, 380, 362, 300, 370, 321, 434, 516, 281, 764, 725, 7129], "temperature": 0.0, "avg_logprob": -0.1506949414263715, "compression_ratio": 1.645, "no_speech_prob": 1.4510129403788596e-05}, {"id": 1417, "seek": 662262, "start": 6635.78, "end": 6637.66, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.1506949414263715, "compression_ratio": 1.645, "no_speech_prob": 1.4510129403788596e-05}, {"id": 1418, "seek": 662262, "start": 6637.66, "end": 6640.0199999999995, "text": " So we're basically going to start with this", "tokens": [407, 321, 434, 1936, 516, 281, 722, 365, 341], "temperature": 0.0, "avg_logprob": -0.1506949414263715, "compression_ratio": 1.645, "no_speech_prob": 1.4510129403788596e-05}, {"id": 1419, "seek": 662262, "start": 6642.86, "end": 6650.38, "text": " With get base and so base is our base network and that was defined back up in this first section, right so get base", "tokens": [2022, 483, 3096, 293, 370, 3096, 307, 527, 3096, 3209, 293, 300, 390, 7642, 646, 493, 294, 341, 700, 3541, 11, 558, 370, 483, 3096], "temperature": 0.0, "avg_logprob": -0.1506949414263715, "compression_ratio": 1.645, "no_speech_prob": 1.4510129403788596e-05}, {"id": 1420, "seek": 665038, "start": 6650.38, "end": 6655.900000000001, "text": " Is going to be something that calls whatever this is and this is resnet 34", "tokens": [1119, 516, 281, 312, 746, 300, 5498, 2035, 341, 307, 293, 341, 307, 725, 7129, 12790], "temperature": 0.0, "avg_logprob": -0.2550020883249682, "compression_ratio": 1.7412935323383085, "no_speech_prob": 1.3211649275035597e-05}, {"id": 1421, "seek": 665038, "start": 6655.900000000001, "end": 6658.06, "text": " so we're going to grab our resnet 34 and", "tokens": [370, 321, 434, 516, 281, 4444, 527, 725, 7129, 12790, 293], "temperature": 0.0, "avg_logprob": -0.2550020883249682, "compression_ratio": 1.7412935323383085, "no_speech_prob": 1.3211649275035597e-05}, {"id": 1422, "seek": 665038, "start": 6658.38, "end": 6665.26, "text": " Cut model is the first thing that our con net builder does it basically removes everything from the adaptive pulling onwards", "tokens": [9431, 2316, 307, 264, 700, 551, 300, 527, 416, 2533, 27377, 775, 309, 1936, 30445, 1203, 490, 264, 27912, 8407, 34230], "temperature": 0.0, "avg_logprob": -0.2550020883249682, "compression_ratio": 1.7412935323383085, "no_speech_prob": 1.3211649275035597e-05}, {"id": 1423, "seek": 665038, "start": 6665.26, "end": 6672.4400000000005, "text": " And so that gives us back the backbone of resnet 34. Okay, so get base is going to give us back our resnet 34", "tokens": [400, 370, 300, 2709, 505, 646, 264, 34889, 295, 725, 7129, 12790, 13, 1033, 11, 370, 483, 3096, 307, 516, 281, 976, 505, 646, 527, 725, 7129, 12790], "temperature": 0.0, "avg_logprob": -0.2550020883249682, "compression_ratio": 1.7412935323383085, "no_speech_prob": 1.3211649275035597e-05}, {"id": 1424, "seek": 667244, "start": 6672.44, "end": 6676.44, "text": " Backbone okay", "tokens": [5833, 19782, 1392], "temperature": 0.0, "avg_logprob": -0.24925584902708559, "compression_ratio": 1.675531914893617, "no_speech_prob": 3.7266197523422306e-06}, {"id": 1425, "seek": 667244, "start": 6677.44, "end": 6683.679999999999, "text": " And then we're going to take that resnet 34 backbone and turn it into a I call it a unit 34", "tokens": [400, 550, 321, 434, 516, 281, 747, 300, 725, 7129, 12790, 34889, 293, 1261, 309, 666, 257, 286, 818, 309, 257, 4985, 12790], "temperature": 0.0, "avg_logprob": -0.24925584902708559, "compression_ratio": 1.675531914893617, "no_speech_prob": 3.7266197523422306e-06}, {"id": 1426, "seek": 667244, "start": 6684.0, "end": 6686.5, "text": " right, so what that's going to do is", "tokens": [558, 11, 370, 437, 300, 311, 516, 281, 360, 307], "temperature": 0.0, "avg_logprob": -0.24925584902708559, "compression_ratio": 1.675531914893617, "no_speech_prob": 3.7266197523422306e-06}, {"id": 1427, "seek": 667244, "start": 6687.48, "end": 6689.12, "text": " it's going to", "tokens": [309, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.24925584902708559, "compression_ratio": 1.675531914893617, "no_speech_prob": 3.7266197523422306e-06}, {"id": 1428, "seek": 667244, "start": 6689.12, "end": 6691.719999999999, "text": " save that resnet that we passed in and", "tokens": [3155, 300, 725, 7129, 300, 321, 4678, 294, 293], "temperature": 0.0, "avg_logprob": -0.24925584902708559, "compression_ratio": 1.675531914893617, "no_speech_prob": 3.7266197523422306e-06}, {"id": 1429, "seek": 667244, "start": 6692.44, "end": 6699.4, "text": " Then we're going to use a forward hook just like before to save the results at the second fourth fifth and sixth blocks", "tokens": [1396, 321, 434, 516, 281, 764, 257, 2128, 6328, 445, 411, 949, 281, 3155, 264, 3542, 412, 264, 1150, 6409, 9266, 293, 15102, 8474], "temperature": 0.0, "avg_logprob": -0.24925584902708559, "compression_ratio": 1.675531914893617, "no_speech_prob": 3.7266197523422306e-06}, {"id": 1430, "seek": 669940, "start": 6699.4, "end": 6705.4, "text": " Which as before is the basically before each stride to convolution?", "tokens": [3013, 382, 949, 307, 264, 1936, 949, 1184, 1056, 482, 281, 45216, 30], "temperature": 0.0, "avg_logprob": -0.1683647014476635, "compression_ratio": 1.9076086956521738, "no_speech_prob": 5.862768830411369e-06}, {"id": 1431, "seek": 669940, "start": 6707.2, "end": 6709.0, "text": " Then we're going to create a bunch of these things", "tokens": [1396, 321, 434, 516, 281, 1884, 257, 3840, 295, 613, 721], "temperature": 0.0, "avg_logprob": -0.1683647014476635, "compression_ratio": 1.9076086956521738, "no_speech_prob": 5.862768830411369e-06}, {"id": 1432, "seek": 669940, "start": 6709.0, "end": 6716.28, "text": " We're calling unit blocks and the unit block basically says so these unit blocks are these things these unit blocks", "tokens": [492, 434, 5141, 4985, 8474, 293, 264, 4985, 3461, 1936, 1619, 370, 613, 4985, 8474, 366, 613, 721, 613, 4985, 8474], "temperature": 0.0, "avg_logprob": -0.1683647014476635, "compression_ratio": 1.9076086956521738, "no_speech_prob": 5.862768830411369e-06}, {"id": 1433, "seek": 669940, "start": 6717.28, "end": 6724.799999999999, "text": " So the the unit block tells us you know well we have to tell it how many things are coming from the from the kind of", "tokens": [407, 264, 264, 4985, 3461, 5112, 505, 291, 458, 731, 321, 362, 281, 980, 309, 577, 867, 721, 366, 1348, 490, 264, 490, 264, 733, 295], "temperature": 0.0, "avg_logprob": -0.1683647014476635, "compression_ratio": 1.9076086956521738, "no_speech_prob": 5.862768830411369e-06}, {"id": 1434, "seek": 672480, "start": 6724.8, "end": 6731.24, "text": " Previous layer that we're up sampling how many are coming across and then how many do we want to come out?", "tokens": [6001, 1502, 4583, 300, 321, 434, 493, 21179, 577, 867, 366, 1348, 2108, 293, 550, 577, 867, 360, 321, 528, 281, 808, 484, 30], "temperature": 0.0, "avg_logprob": -0.22651590952059117, "compression_ratio": 1.681592039800995, "no_speech_prob": 3.74798361235662e-07}, {"id": 1435, "seek": 672480, "start": 6732.400000000001, "end": 6734.400000000001, "text": " right and", "tokens": [558, 293], "temperature": 0.0, "avg_logprob": -0.22651590952059117, "compression_ratio": 1.681592039800995, "no_speech_prob": 3.74798361235662e-07}, {"id": 1436, "seek": 672480, "start": 6734.6, "end": 6738.8, "text": " so the amount coming across is entirely defined by", "tokens": [370, 264, 2372, 1348, 2108, 307, 7696, 7642, 538], "temperature": 0.0, "avg_logprob": -0.22651590952059117, "compression_ratio": 1.681592039800995, "no_speech_prob": 3.74798361235662e-07}, {"id": 1437, "seek": 672480, "start": 6739.92, "end": 6744.08, "text": " Whatever the base network was right it's like whatever whatever the downward path was", "tokens": [8541, 264, 3096, 3209, 390, 558, 309, 311, 411, 2035, 2035, 264, 24805, 3100, 390], "temperature": 0.0, "avg_logprob": -0.22651590952059117, "compression_ratio": 1.681592039800995, "no_speech_prob": 3.74798361235662e-07}, {"id": 1438, "seek": 672480, "start": 6745.72, "end": 6747.72, "text": " We need that many layers", "tokens": [492, 643, 300, 867, 7914], "temperature": 0.0, "avg_logprob": -0.22651590952059117, "compression_ratio": 1.681592039800995, "no_speech_prob": 3.74798361235662e-07}, {"id": 1439, "seek": 672480, "start": 6747.88, "end": 6751.76, "text": " And so this is a little bit awkward and actually one of our", "tokens": [400, 370, 341, 307, 257, 707, 857, 11411, 293, 767, 472, 295, 527], "temperature": 0.0, "avg_logprob": -0.22651590952059117, "compression_ratio": 1.681592039800995, "no_speech_prob": 3.74798361235662e-07}, {"id": 1440, "seek": 675176, "start": 6751.76, "end": 6755.68, "text": " Master students here Karam has actually created something called a", "tokens": [6140, 1731, 510, 8009, 335, 575, 767, 2942, 746, 1219, 257], "temperature": 0.0, "avg_logprob": -0.2252172827720642, "compression_ratio": 1.6811023622047243, "no_speech_prob": 4.425449787959224e-06}, {"id": 1441, "seek": 675176, "start": 6756.64, "end": 6759.4800000000005, "text": " Dynamic unit that you'll find in fastai", "tokens": [45440, 4985, 300, 291, 603, 915, 294, 2370, 1301], "temperature": 0.0, "avg_logprob": -0.2252172827720642, "compression_ratio": 1.6811023622047243, "no_speech_prob": 4.425449787959224e-06}, {"id": 1442, "seek": 675176, "start": 6759.84, "end": 6767.52, "text": " Unit dynamic unit and it actually calculates this all for you and automatically creates the whole unit from your base model", "tokens": [27894, 8546, 4985, 293, 309, 767, 4322, 1024, 341, 439, 337, 291, 293, 6772, 7829, 264, 1379, 4985, 490, 428, 3096, 2316], "temperature": 0.0, "avg_logprob": -0.2252172827720642, "compression_ratio": 1.6811023622047243, "no_speech_prob": 4.425449787959224e-06}, {"id": 1443, "seek": 675176, "start": 6768.64, "end": 6773.24, "text": " It's got some minor quirk still that I want to fix by the time the videos out", "tokens": [467, 311, 658, 512, 6696, 421, 18610, 920, 300, 286, 528, 281, 3191, 538, 264, 565, 264, 2145, 484], "temperature": 0.0, "avg_logprob": -0.2252172827720642, "compression_ratio": 1.6811023622047243, "no_speech_prob": 4.425449787959224e-06}, {"id": 1444, "seek": 675176, "start": 6773.24, "end": 6780.360000000001, "text": " It'll definitely be working and I will at least have a notebook showing how to use it and possibly a traditional video", "tokens": [467, 603, 2138, 312, 1364, 293, 286, 486, 412, 1935, 362, 257, 21060, 4099, 577, 281, 764, 309, 293, 6264, 257, 5164, 960], "temperature": 0.0, "avg_logprob": -0.2252172827720642, "compression_ratio": 1.6811023622047243, "no_speech_prob": 4.425449787959224e-06}, {"id": 1445, "seek": 678036, "start": 6780.36, "end": 6781.88, "text": " but", "tokens": [457], "temperature": 0.0, "avg_logprob": -0.22678637281756533, "compression_ratio": 1.6893617021276597, "no_speech_prob": 4.222786628815811e-06}, {"id": 1446, "seek": 678036, "start": 6781.88, "end": 6785.24, "text": " For now, you know you'll just have to go through and do it yourself", "tokens": [1171, 586, 11, 291, 458, 291, 603, 445, 362, 281, 352, 807, 293, 360, 309, 1803], "temperature": 0.0, "avg_logprob": -0.22678637281756533, "compression_ratio": 1.6893617021276597, "no_speech_prob": 4.222786628815811e-06}, {"id": 1447, "seek": 678036, "start": 6785.24, "end": 6788.7, "text": " You can easily see it just by once you've got a resnet", "tokens": [509, 393, 3612, 536, 309, 445, 538, 1564, 291, 600, 658, 257, 725, 7129], "temperature": 0.0, "avg_logprob": -0.22678637281756533, "compression_ratio": 1.6893617021276597, "no_speech_prob": 4.222786628815811e-06}, {"id": 1448, "seek": 678036, "start": 6788.7, "end": 6794.08, "text": " You can just go you know just type in its name, and it'll print out all the layers, and you can see how big", "tokens": [509, 393, 445, 352, 291, 458, 445, 2010, 294, 1080, 1315, 11, 293, 309, 603, 4482, 484, 439, 264, 7914, 11, 293, 291, 393, 536, 577, 955], "temperature": 0.0, "avg_logprob": -0.22678637281756533, "compression_ratio": 1.6893617021276597, "no_speech_prob": 4.222786628815811e-06}, {"id": 1449, "seek": 678036, "start": 6794.759999999999, "end": 6797.36, "text": " How many activations there are in each block?", "tokens": [1012, 867, 2430, 763, 456, 366, 294, 1184, 3461, 30], "temperature": 0.0, "avg_logprob": -0.22678637281756533, "compression_ratio": 1.6893617021276597, "no_speech_prob": 4.222786628815811e-06}, {"id": 1450, "seek": 678036, "start": 6799.799999999999, "end": 6801.799999999999, "text": " Or you could even", "tokens": [1610, 291, 727, 754], "temperature": 0.0, "avg_logprob": -0.22678637281756533, "compression_ratio": 1.6893617021276597, "no_speech_prob": 4.222786628815811e-06}, {"id": 1451, "seek": 678036, "start": 6802.16, "end": 6807.639999999999, "text": " Have it printed out for you for each for each block automatically anyway. I just did this manually", "tokens": [3560, 309, 13567, 484, 337, 291, 337, 1184, 337, 1184, 3461, 6772, 4033, 13, 286, 445, 630, 341, 16945], "temperature": 0.0, "avg_logprob": -0.22678637281756533, "compression_ratio": 1.6893617021276597, "no_speech_prob": 4.222786628815811e-06}, {"id": 1452, "seek": 680764, "start": 6807.64, "end": 6809.400000000001, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.16232469346788195, "compression_ratio": 1.8373205741626795, "no_speech_prob": 2.368753939663293e-06}, {"id": 1453, "seek": 680764, "start": 6809.400000000001, "end": 6811.400000000001, "text": " so the unit block is", "tokens": [370, 264, 4985, 3461, 307], "temperature": 0.0, "avg_logprob": -0.16232469346788195, "compression_ratio": 1.8373205741626795, "no_speech_prob": 2.368753939663293e-06}, {"id": 1454, "seek": 680764, "start": 6812.56, "end": 6814.360000000001, "text": " Works like this", "tokens": [27914, 411, 341], "temperature": 0.0, "avg_logprob": -0.16232469346788195, "compression_ratio": 1.8373205741626795, "no_speech_prob": 2.368753939663293e-06}, {"id": 1455, "seek": 680764, "start": 6814.360000000001, "end": 6817.360000000001, "text": " So you said okay about this penny coming up from the previous layer", "tokens": [407, 291, 848, 1392, 466, 341, 24178, 1348, 493, 490, 264, 3894, 4583], "temperature": 0.0, "avg_logprob": -0.16232469346788195, "compression_ratio": 1.8373205741626795, "no_speech_prob": 2.368753939663293e-06}, {"id": 1456, "seek": 680764, "start": 6817.360000000001, "end": 6822.76, "text": " I've got this penny coming across this X. I'm using across across from the downward path", "tokens": [286, 600, 658, 341, 24178, 1348, 2108, 341, 1783, 13, 286, 478, 1228, 2108, 2108, 490, 264, 24805, 3100], "temperature": 0.0, "avg_logprob": -0.16232469346788195, "compression_ratio": 1.8373205741626795, "no_speech_prob": 2.368753939663293e-06}, {"id": 1457, "seek": 680764, "start": 6822.8, "end": 6825.56, "text": " This is the amount I want coming out now", "tokens": [639, 307, 264, 2372, 286, 528, 1348, 484, 586], "temperature": 0.0, "avg_logprob": -0.16232469346788195, "compression_ratio": 1.8373205741626795, "no_speech_prob": 2.368753939663293e-06}, {"id": 1458, "seek": 680764, "start": 6826.76, "end": 6828.68, "text": " What I do is I then say okay", "tokens": [708, 286, 360, 307, 286, 550, 584, 1392], "temperature": 0.0, "avg_logprob": -0.16232469346788195, "compression_ratio": 1.8373205741626795, "no_speech_prob": 2.368753939663293e-06}, {"id": 1459, "seek": 680764, "start": 6828.68, "end": 6833.56, "text": " We're going to create a certain amount of convolutions from the upward path and a certain amount from the cross path", "tokens": [492, 434, 516, 281, 1884, 257, 1629, 2372, 295, 3754, 15892, 490, 264, 23452, 3100, 293, 257, 1629, 2372, 490, 264, 3278, 3100], "temperature": 0.0, "avg_logprob": -0.16232469346788195, "compression_ratio": 1.8373205741626795, "no_speech_prob": 2.368753939663293e-06}, {"id": 1460, "seek": 683356, "start": 6833.56, "end": 6839.580000000001, "text": " And so I'm going to be concatenating them together, so let's divide the number we want out by 2", "tokens": [400, 370, 286, 478, 516, 281, 312, 1588, 7186, 990, 552, 1214, 11, 370, 718, 311, 9845, 264, 1230, 321, 528, 484, 538, 568], "temperature": 0.0, "avg_logprob": -0.1883028091922883, "compression_ratio": 1.7632850241545894, "no_speech_prob": 2.22527432924835e-06}, {"id": 1461, "seek": 683356, "start": 6840.360000000001, "end": 6846.68, "text": " Right and so we're going to have our cross convolution take our cross path and create", "tokens": [1779, 293, 370, 321, 434, 516, 281, 362, 527, 3278, 45216, 747, 527, 3278, 3100, 293, 1884], "temperature": 0.0, "avg_logprob": -0.1883028091922883, "compression_ratio": 1.7632850241545894, "no_speech_prob": 2.22527432924835e-06}, {"id": 1462, "seek": 683356, "start": 6847.4800000000005, "end": 6849.4800000000005, "text": " number out divided by 2 and", "tokens": [1230, 484, 6666, 538, 568, 293], "temperature": 0.0, "avg_logprob": -0.1883028091922883, "compression_ratio": 1.7632850241545894, "no_speech_prob": 2.22527432924835e-06}, {"id": 1463, "seek": 683356, "start": 6849.76, "end": 6857.240000000001, "text": " Then the upward path is going to be a comm transpose 2d right because we want to increase up sample and", "tokens": [1396, 264, 23452, 3100, 307, 516, 281, 312, 257, 800, 25167, 568, 67, 558, 570, 321, 528, 281, 3488, 493, 6889, 293], "temperature": 0.0, "avg_logprob": -0.1883028091922883, "compression_ratio": 1.7632850241545894, "no_speech_prob": 2.22527432924835e-06}, {"id": 1464, "seek": 683356, "start": 6857.72, "end": 6861.52, "text": " again here we've got the number in divided by 2 and", "tokens": [797, 510, 321, 600, 658, 264, 1230, 294, 6666, 538, 568, 293], "temperature": 0.0, "avg_logprob": -0.1883028091922883, "compression_ratio": 1.7632850241545894, "no_speech_prob": 2.22527432924835e-06}, {"id": 1465, "seek": 686152, "start": 6861.52, "end": 6864.320000000001, "text": " Then at the end I just concatenate those together", "tokens": [1396, 412, 264, 917, 286, 445, 1588, 7186, 473, 729, 1214], "temperature": 0.0, "avg_logprob": -0.21608122189839682, "compression_ratio": 1.811881188118812, "no_speech_prob": 3.0415828859986505e-06}, {"id": 1466, "seek": 686152, "start": 6865.92, "end": 6871.6, "text": " All right, so I've got an upward sample. I've got a cross convolution. I concatenate the two together", "tokens": [1057, 558, 11, 370, 286, 600, 658, 364, 23452, 6889, 13, 286, 600, 658, 257, 3278, 45216, 13, 286, 1588, 7186, 473, 264, 732, 1214], "temperature": 0.0, "avg_logprob": -0.21608122189839682, "compression_ratio": 1.811881188118812, "no_speech_prob": 3.0415828859986505e-06}, {"id": 1467, "seek": 686152, "start": 6872.200000000001, "end": 6874.68, "text": " right and so that's all a unit block is and", "tokens": [558, 293, 370, 300, 311, 439, 257, 4985, 3461, 307, 293], "temperature": 0.0, "avg_logprob": -0.21608122189839682, "compression_ratio": 1.811881188118812, "no_speech_prob": 3.0415828859986505e-06}, {"id": 1468, "seek": 686152, "start": 6875.8, "end": 6882.84, "text": " so that's actually a pretty easy module to create and so then in my forward path I", "tokens": [370, 300, 311, 767, 257, 1238, 1858, 10088, 281, 1884, 293, 370, 550, 294, 452, 2128, 3100, 286], "temperature": 0.0, "avg_logprob": -0.21608122189839682, "compression_ratio": 1.811881188118812, "no_speech_prob": 3.0415828859986505e-06}, {"id": 1469, "seek": 686152, "start": 6883.52, "end": 6889.92, "text": " Need to pass to the forward of the of the unit block the upward path and the cross path", "tokens": [16984, 281, 1320, 281, 264, 2128, 295, 264, 295, 264, 4985, 3461, 264, 23452, 3100, 293, 264, 3278, 3100], "temperature": 0.0, "avg_logprob": -0.21608122189839682, "compression_ratio": 1.811881188118812, "no_speech_prob": 3.0415828859986505e-06}, {"id": 1470, "seek": 688992, "start": 6889.92, "end": 6893.72, "text": " So the upward path is just wherever I'm up to so far", "tokens": [407, 264, 23452, 3100, 307, 445, 8660, 286, 478, 493, 281, 370, 1400], "temperature": 0.0, "avg_logprob": -0.160943660736084, "compression_ratio": 1.7149321266968325, "no_speech_prob": 2.4824657884892076e-06}, {"id": 1471, "seek": 688992, "start": 6894.4400000000005, "end": 6896.4400000000005, "text": " All right, but then the cross path is", "tokens": [1057, 558, 11, 457, 550, 264, 3278, 3100, 307], "temperature": 0.0, "avg_logprob": -0.160943660736084, "compression_ratio": 1.7149321266968325, "no_speech_prob": 2.4824657884892076e-06}, {"id": 1472, "seek": 688992, "start": 6897.16, "end": 6904.2, "text": " Whatever the value is of whatever the activations are that I stored on the way down, right?", "tokens": [8541, 264, 2158, 307, 295, 2035, 264, 2430, 763, 366, 300, 286, 12187, 322, 264, 636, 760, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.160943660736084, "compression_ratio": 1.7149321266968325, "no_speech_prob": 2.4824657884892076e-06}, {"id": 1473, "seek": 688992, "start": 6904.2, "end": 6908.36, "text": " So as I come up, it's the last set of saved features that I need first", "tokens": [407, 382, 286, 808, 493, 11, 309, 311, 264, 1036, 992, 295, 6624, 4122, 300, 286, 643, 700], "temperature": 0.0, "avg_logprob": -0.160943660736084, "compression_ratio": 1.7149321266968325, "no_speech_prob": 2.4824657884892076e-06}, {"id": 1474, "seek": 688992, "start": 6908.36, "end": 6914.24, "text": " And then as I gradually keep going up further and further and further eventually. It's the first set of features", "tokens": [400, 550, 382, 286, 13145, 1066, 516, 493, 3052, 293, 3052, 293, 3052, 4728, 13, 467, 311, 264, 700, 992, 295, 4122], "temperature": 0.0, "avg_logprob": -0.160943660736084, "compression_ratio": 1.7149321266968325, "no_speech_prob": 2.4824657884892076e-06}, {"id": 1475, "seek": 688992, "start": 6915.4800000000005, "end": 6917.4800000000005, "text": " Okay, and so", "tokens": [1033, 11, 293, 370], "temperature": 0.0, "avg_logprob": -0.160943660736084, "compression_ratio": 1.7149321266968325, "no_speech_prob": 2.4824657884892076e-06}, {"id": 1476, "seek": 691748, "start": 6917.48, "end": 6922.759999999999, "text": " There are some more tricks we can do to make this a little bit better, but this is this is a good start, right?", "tokens": [821, 366, 512, 544, 11733, 321, 393, 360, 281, 652, 341, 257, 707, 857, 1101, 11, 457, 341, 307, 341, 307, 257, 665, 722, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18183833199578361, "compression_ratio": 1.4875621890547264, "no_speech_prob": 2.813005494317622e-06}, {"id": 1477, "seek": 691748, "start": 6924.44, "end": 6931.599999999999, "text": " So if we try this so the simple up sampling approach looked horrible right and had a dice of 968 a", "tokens": [407, 498, 321, 853, 341, 370, 264, 2199, 493, 21179, 3109, 2956, 9263, 558, 293, 632, 257, 10313, 295, 24124, 23, 257], "temperature": 0.0, "avg_logprob": -0.18183833199578361, "compression_ratio": 1.4875621890547264, "no_speech_prob": 2.813005494317622e-06}, {"id": 1478, "seek": 691748, "start": 6933.839999999999, "end": 6939.919999999999, "text": " Unit with everything else identical except we've now got these unit blocks has a dice of", "tokens": [27894, 365, 1203, 1646, 14800, 3993, 321, 600, 586, 658, 613, 4985, 8474, 575, 257, 10313, 295], "temperature": 0.0, "avg_logprob": -0.18183833199578361, "compression_ratio": 1.4875621890547264, "no_speech_prob": 2.813005494317622e-06}, {"id": 1479, "seek": 693992, "start": 6939.92, "end": 6947.0, "text": " 985 right so that's like we've kind of halved the error", "tokens": [20860, 20, 558, 370, 300, 311, 411, 321, 600, 733, 295, 7523, 937, 264, 6713], "temperature": 0.0, "avg_logprob": -0.2338813076848569, "compression_ratio": 1.5432098765432098, "no_speech_prob": 2.225271600764245e-06}, {"id": 1480, "seek": 693992, "start": 6947.96, "end": 6954.4400000000005, "text": " With with everything else exactly the same and more to the point you can look at it. This is actually looking somewhat car-like", "tokens": [2022, 365, 1203, 1646, 2293, 264, 912, 293, 544, 281, 264, 935, 291, 393, 574, 412, 309, 13, 639, 307, 767, 1237, 8344, 1032, 12, 4092], "temperature": 0.0, "avg_logprob": -0.2338813076848569, "compression_ratio": 1.5432098765432098, "no_speech_prob": 2.225271600764245e-06}, {"id": 1481, "seek": 693992, "start": 6955.92, "end": 6960.3, "text": " compared to our non unit equivalent, which is just a blog no because", "tokens": [5347, 281, 527, 2107, 4985, 10344, 11, 597, 307, 445, 257, 6968, 572, 570], "temperature": 0.0, "avg_logprob": -0.2338813076848569, "compression_ratio": 1.5432098765432098, "no_speech_prob": 2.225271600764245e-06}, {"id": 1482, "seek": 693992, "start": 6961.24, "end": 6968.5, "text": " You know trying to do this through down and up paths. Just it's just asking too much. You know where else when we actually", "tokens": [509, 458, 1382, 281, 360, 341, 807, 760, 293, 493, 14518, 13, 1449, 309, 311, 445, 3365, 886, 709, 13, 509, 458, 689, 1646, 562, 321, 767], "temperature": 0.0, "avg_logprob": -0.2338813076848569, "compression_ratio": 1.5432098765432098, "no_speech_prob": 2.225271600764245e-06}, {"id": 1483, "seek": 696850, "start": 6968.5, "end": 6970.06, "text": " provide", "tokens": [2893], "temperature": 0.0, "avg_logprob": -0.204903169111772, "compression_ratio": 1.5064935064935066, "no_speech_prob": 3.90546074413578e-06}, {"id": 1484, "seek": 696850, "start": 6970.06, "end": 6976.66, "text": " The downward path pixels at every point it can actually start to create something car ish so", "tokens": [440, 24805, 3100, 18668, 412, 633, 935, 309, 393, 767, 722, 281, 1884, 746, 1032, 307, 71, 370], "temperature": 0.0, "avg_logprob": -0.204903169111772, "compression_ratio": 1.5064935064935066, "no_speech_prob": 3.90546074413578e-06}, {"id": 1485, "seek": 696850, "start": 6977.86, "end": 6982.26, "text": " At the end of that we'll go dot close to again remove those SFS", "tokens": [1711, 264, 917, 295, 300, 321, 603, 352, 5893, 1998, 281, 797, 4159, 729, 318, 29318], "temperature": 0.0, "avg_logprob": -0.204903169111772, "compression_ratio": 1.5064935064935066, "no_speech_prob": 3.90546074413578e-06}, {"id": 1486, "seek": 696850, "start": 6983.14, "end": 6989.04, "text": " Features taking up GPU memory go to a smaller batch size a higher size", "tokens": [3697, 3377, 1940, 493, 18407, 4675, 352, 281, 257, 4356, 15245, 2744, 257, 2946, 2744], "temperature": 0.0, "avg_logprob": -0.204903169111772, "compression_ratio": 1.5064935064935066, "no_speech_prob": 3.90546074413578e-06}, {"id": 1487, "seek": 696850, "start": 6990.14, "end": 6995.78, "text": " And you can see the dice coefficients really going up. This is just so notice here. I'm learning. I'm loading in", "tokens": [400, 291, 393, 536, 264, 10313, 31994, 534, 516, 493, 13, 639, 307, 445, 370, 3449, 510, 13, 286, 478, 2539, 13, 286, 478, 15114, 294], "temperature": 0.0, "avg_logprob": -0.204903169111772, "compression_ratio": 1.5064935064935066, "no_speech_prob": 3.90546074413578e-06}, {"id": 1488, "seek": 699578, "start": 6995.78, "end": 6999.0599999999995, "text": " Right the 128 by 128", "tokens": [1779, 264, 29810, 538, 29810], "temperature": 0.0, "avg_logprob": -0.2255798630092455, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.7693945412465837e-06}, {"id": 1489, "seek": 699578, "start": 6999.78, "end": 7004.179999999999, "text": " Version of the network okay, so we're doing this progressive resizing trick again", "tokens": [35965, 295, 264, 3209, 1392, 11, 370, 321, 434, 884, 341, 16131, 725, 3319, 4282, 797], "temperature": 0.0, "avg_logprob": -0.2255798630092455, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.7693945412465837e-06}, {"id": 1490, "seek": 699578, "start": 7004.179999999999, "end": 7011.5199999999995, "text": " So that gets us 99 3 and then unfreeze to get to 99 4 and you can see it's now", "tokens": [407, 300, 2170, 505, 11803, 805, 293, 550, 3971, 701, 1381, 281, 483, 281, 11803, 1017, 293, 291, 393, 536, 309, 311, 586], "temperature": 0.0, "avg_logprob": -0.2255798630092455, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.7693945412465837e-06}, {"id": 1491, "seek": 699578, "start": 7012.54, "end": 7018.139999999999, "text": " Looking pretty good. Okay go down to a batch size of 4 size of 1 or 2 4", "tokens": [11053, 1238, 665, 13, 1033, 352, 760, 281, 257, 15245, 2744, 295, 1017, 2744, 295, 502, 420, 568, 1017], "temperature": 0.0, "avg_logprob": -0.2255798630092455, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.7693945412465837e-06}, {"id": 1492, "seek": 699578, "start": 7020.179999999999, "end": 7022.5, "text": " Load in what we just did with the 512", "tokens": [48408, 294, 437, 321, 445, 630, 365, 264, 1025, 4762], "temperature": 0.0, "avg_logprob": -0.2255798630092455, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.7693945412465837e-06}, {"id": 1493, "seek": 699578, "start": 7023.34, "end": 7025.34, "text": " Takes us to 99 5", "tokens": [44347, 505, 281, 11803, 1025], "temperature": 0.0, "avg_logprob": -0.2255798630092455, "compression_ratio": 1.4736842105263157, "no_speech_prob": 2.7693945412465837e-06}, {"id": 1494, "seek": 702534, "start": 7025.34, "end": 7027.34, "text": " unfreeze", "tokens": [3971, 701, 1381], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1495, "seek": 702534, "start": 7027.54, "end": 7029.46, "text": " Texas to", "tokens": [7885, 281], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1496, "seek": 702534, "start": 7029.46, "end": 7031.66, "text": " 99 we'll call that 99 6", "tokens": [11803, 321, 603, 818, 300, 11803, 1386], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1497, "seek": 702534, "start": 7032.7, "end": 7034.7, "text": " 5 9 9 and", "tokens": [1025, 1722, 1722, 293], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1498, "seek": 702534, "start": 7035.860000000001, "end": 7037.46, "text": " as", "tokens": [382], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1499, "seek": 702534, "start": 7037.46, "end": 7042.34, "text": " You can see that actually looks good right in accuracy terms", "tokens": [509, 393, 536, 300, 767, 1542, 665, 558, 294, 14170, 2115], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1500, "seek": 702534, "start": 7043.34, "end": 7045.34, "text": " 99.8 to", "tokens": [11803, 13, 23, 281], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1501, "seek": 702534, "start": 7045.5, "end": 7047.5, "text": " You know you can see this is", "tokens": [509, 458, 291, 393, 536, 341, 307], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1502, "seek": 702534, "start": 7047.78, "end": 7050.9800000000005, "text": " Looking like something you could just about use to cut out. I think", "tokens": [11053, 411, 746, 291, 727, 445, 466, 764, 281, 1723, 484, 13, 286, 519], "temperature": 0.0, "avg_logprob": -0.39453386280634634, "compression_ratio": 1.4102564102564104, "no_speech_prob": 6.048880095477216e-06}, {"id": 1503, "seek": 705098, "start": 7050.98, "end": 7058.299999999999, "text": " To you know at this point. There's a couple of minor tweaks. We can do to get up to 99.7", "tokens": [1407, 291, 458, 412, 341, 935, 13, 821, 311, 257, 1916, 295, 6696, 46664, 13, 492, 393, 360, 281, 483, 493, 281, 11803, 13, 22], "temperature": 0.0, "avg_logprob": -0.1920648171351506, "compression_ratio": 1.5208333333333333, "no_speech_prob": 3.041579475393519e-06}, {"id": 1504, "seek": 705098, "start": 7058.94, "end": 7062.94, "text": " But really the key thing then I think is just maybe to do a little a few", "tokens": [583, 534, 264, 2141, 551, 550, 286, 519, 307, 445, 1310, 281, 360, 257, 707, 257, 1326], "temperature": 0.0, "avg_logprob": -0.1920648171351506, "compression_ratio": 1.5208333333333333, "no_speech_prob": 3.041579475393519e-06}, {"id": 1505, "seek": 705098, "start": 7063.139999999999, "end": 7066.9, "text": " Bit of smoothing maybe or a little bit of post-processing", "tokens": [9101, 295, 899, 6259, 571, 1310, 420, 257, 707, 857, 295, 2183, 12, 41075, 278], "temperature": 0.0, "avg_logprob": -0.1920648171351506, "compression_ratio": 1.5208333333333333, "no_speech_prob": 3.041579475393519e-06}, {"id": 1506, "seek": 705098, "start": 7067.62, "end": 7071.419999999999, "text": " You can go and have a look at the Carvana winners blogs", "tokens": [509, 393, 352, 293, 362, 257, 574, 412, 264, 2741, 39259, 17193, 31038], "temperature": 0.0, "avg_logprob": -0.1920648171351506, "compression_ratio": 1.5208333333333333, "no_speech_prob": 3.041579475393519e-06}, {"id": 1507, "seek": 705098, "start": 7072.139999999999, "end": 7078.379999999999, "text": " And see some of these tricks, but as I say the difference between where we're at 99.6 and", "tokens": [400, 536, 512, 295, 613, 11733, 11, 457, 382, 286, 584, 264, 2649, 1296, 689, 321, 434, 412, 11803, 13, 21, 293], "temperature": 0.0, "avg_logprob": -0.1920648171351506, "compression_ratio": 1.5208333333333333, "no_speech_prob": 3.041579475393519e-06}, {"id": 1508, "seek": 707838, "start": 7078.38, "end": 7080.9800000000005, "text": " What the winners got of 99.7?", "tokens": [708, 264, 17193, 658, 295, 11803, 13, 22, 30], "temperature": 0.0, "avg_logprob": -0.23363854419225935, "compression_ratio": 1.4926829268292683, "no_speech_prob": 2.9479981549229706e-06}, {"id": 1509, "seek": 707838, "start": 7081.900000000001, "end": 7084.78, "text": " You know is it's not heaps and", "tokens": [509, 458, 307, 309, 311, 406, 415, 2382, 293], "temperature": 0.0, "avg_logprob": -0.23363854419225935, "compression_ratio": 1.4926829268292683, "no_speech_prob": 2.9479981549229706e-06}, {"id": 1510, "seek": 707838, "start": 7085.54, "end": 7090.14, "text": " So really that just the unit on its own pretty much", "tokens": [407, 534, 300, 445, 264, 4985, 322, 1080, 1065, 1238, 709], "temperature": 0.0, "avg_logprob": -0.23363854419225935, "compression_ratio": 1.4926829268292683, "no_speech_prob": 2.9479981549229706e-06}, {"id": 1511, "seek": 707838, "start": 7091.14, "end": 7093.14, "text": " Pretty much solves that problem", "tokens": [10693, 709, 39890, 300, 1154], "temperature": 0.0, "avg_logprob": -0.23363854419225935, "compression_ratio": 1.4926829268292683, "no_speech_prob": 2.9479981549229706e-06}, {"id": 1512, "seek": 707838, "start": 7095.22, "end": 7101.06, "text": " Okay, so that's it so the last thing I wanted to mention is now to come all the way back to", "tokens": [1033, 11, 370, 300, 311, 309, 370, 264, 1036, 551, 286, 1415, 281, 2152, 307, 586, 281, 808, 439, 264, 636, 646, 281], "temperature": 0.0, "avg_logprob": -0.23363854419225935, "compression_ratio": 1.4926829268292683, "no_speech_prob": 2.9479981549229706e-06}, {"id": 1513, "seek": 707838, "start": 7101.66, "end": 7102.9400000000005, "text": " bounding boxes", "tokens": [5472, 278, 9002], "temperature": 0.0, "avg_logprob": -0.23363854419225935, "compression_ratio": 1.4926829268292683, "no_speech_prob": 2.9479981549229706e-06}, {"id": 1514, "seek": 707838, "start": 7102.9400000000005, "end": 7106.82, "text": " Because you might remember I said our our bounding box", "tokens": [1436, 291, 1062, 1604, 286, 848, 527, 527, 5472, 278, 2424], "temperature": 0.0, "avg_logprob": -0.23363854419225935, "compression_ratio": 1.4926829268292683, "no_speech_prob": 2.9479981549229706e-06}, {"id": 1515, "seek": 710682, "start": 7106.82, "end": 7111.98, "text": " Model was still not doing very well on small objects", "tokens": [17105, 390, 920, 406, 884, 588, 731, 322, 1359, 6565], "temperature": 0.0, "avg_logprob": -0.23225884321259288, "compression_ratio": 1.5942028985507246, "no_speech_prob": 1.0783198376884684e-05}, {"id": 1516, "seek": 710682, "start": 7112.98, "end": 7118.98, "text": " So hopefully you might be able to guess where I'm going to go with this which is that for the bounding box", "tokens": [407, 4696, 291, 1062, 312, 1075, 281, 2041, 689, 286, 478, 516, 281, 352, 365, 341, 597, 307, 300, 337, 264, 5472, 278, 2424], "temperature": 0.0, "avg_logprob": -0.23225884321259288, "compression_ratio": 1.5942028985507246, "no_speech_prob": 1.0783198376884684e-05}, {"id": 1517, "seek": 710682, "start": 7119.74, "end": 7121.5, "text": " model", "tokens": [2316], "temperature": 0.0, "avg_logprob": -0.23225884321259288, "compression_ratio": 1.5942028985507246, "no_speech_prob": 1.0783198376884684e-05}, {"id": 1518, "seek": 710682, "start": 7121.5, "end": 7126.46, "text": " Remember how we we we had at different grid cells we spat out", "tokens": [5459, 577, 321, 321, 321, 632, 412, 819, 10748, 5438, 321, 15000, 484], "temperature": 0.0, "avg_logprob": -0.23225884321259288, "compression_ratio": 1.5942028985507246, "no_speech_prob": 1.0783198376884684e-05}, {"id": 1519, "seek": 710682, "start": 7127.0599999999995, "end": 7130.0599999999995, "text": " outputs of their model and", "tokens": [23930, 295, 641, 2316, 293], "temperature": 0.0, "avg_logprob": -0.23225884321259288, "compression_ratio": 1.5942028985507246, "no_speech_prob": 1.0783198376884684e-05}, {"id": 1520, "seek": 713006, "start": 7130.06, "end": 7136.26, "text": " It was those earlier ones with the small grids sizes that weren't very good", "tokens": [467, 390, 729, 3071, 2306, 365, 264, 1359, 677, 3742, 11602, 300, 4999, 380, 588, 665], "temperature": 0.0, "avg_logprob": -0.22578704833984375, "compression_ratio": 1.507936507936508, "no_speech_prob": 5.594299636868527e-06}, {"id": 1521, "seek": 713006, "start": 7136.780000000001, "end": 7138.780000000001, "text": " Well, how do we fix it?", "tokens": [1042, 11, 577, 360, 321, 3191, 309, 30], "temperature": 0.0, "avg_logprob": -0.22578704833984375, "compression_ratio": 1.507936507936508, "no_speech_prob": 5.594299636868527e-06}, {"id": 1522, "seek": 713006, "start": 7139.14, "end": 7144.700000000001, "text": " You net it right let's have an upward path with cross connections", "tokens": [509, 2533, 309, 558, 718, 311, 362, 364, 23452, 3100, 365, 3278, 9271], "temperature": 0.0, "avg_logprob": -0.22578704833984375, "compression_ratio": 1.507936507936508, "no_speech_prob": 5.594299636868527e-06}, {"id": 1523, "seek": 713006, "start": 7145.18, "end": 7152.9400000000005, "text": " right and so then we're just going to do a unit and then spit them out of that because now those those", "tokens": [558, 293, 370, 550, 321, 434, 445, 516, 281, 360, 257, 4985, 293, 550, 22127, 552, 484, 295, 300, 570, 586, 729, 729], "temperature": 0.0, "avg_logprob": -0.22578704833984375, "compression_ratio": 1.507936507936508, "no_speech_prob": 5.594299636868527e-06}, {"id": 1524, "seek": 713006, "start": 7153.54, "end": 7155.3, "text": " finer grid cells", "tokens": [39130, 10748, 5438], "temperature": 0.0, "avg_logprob": -0.22578704833984375, "compression_ratio": 1.507936507936508, "no_speech_prob": 5.594299636868527e-06}, {"id": 1525, "seek": 715530, "start": 7155.3, "end": 7160.9400000000005, "text": " Have all of the information of that path and that path and that path and that path to leverage", "tokens": [3560, 439, 295, 264, 1589, 295, 300, 3100, 293, 300, 3100, 293, 300, 3100, 293, 300, 3100, 281, 13982], "temperature": 0.0, "avg_logprob": -0.21437861919403076, "compression_ratio": 1.6082474226804124, "no_speech_prob": 3.966948042943841e-06}, {"id": 1526, "seek": 715530, "start": 7161.54, "end": 7163.54, "text": " now of course", "tokens": [586, 295, 1164], "temperature": 0.0, "avg_logprob": -0.21437861919403076, "compression_ratio": 1.6082474226804124, "no_speech_prob": 3.966948042943841e-06}, {"id": 1527, "seek": 715530, "start": 7163.7, "end": 7167.820000000001, "text": " This is deep learning so that means you can't write a paper saying", "tokens": [639, 307, 2452, 2539, 370, 300, 1355, 291, 393, 380, 2464, 257, 3035, 1566], "temperature": 0.0, "avg_logprob": -0.21437861919403076, "compression_ratio": 1.6082474226804124, "no_speech_prob": 3.966948042943841e-06}, {"id": 1528, "seek": 715530, "start": 7168.34, "end": 7172.900000000001, "text": " We just used you net for bounding boxes you have to invent a new word", "tokens": [492, 445, 1143, 291, 2533, 337, 5472, 278, 9002, 291, 362, 281, 7962, 257, 777, 1349], "temperature": 0.0, "avg_logprob": -0.21437861919403076, "compression_ratio": 1.6082474226804124, "no_speech_prob": 3.966948042943841e-06}, {"id": 1529, "seek": 715530, "start": 7173.06, "end": 7179.84, "text": " So this is called feature pyramid networks or FPNs. Okay, and like", "tokens": [407, 341, 307, 1219, 4111, 25950, 9590, 420, 479, 15466, 82, 13, 1033, 11, 293, 411], "temperature": 0.0, "avg_logprob": -0.21437861919403076, "compression_ratio": 1.6082474226804124, "no_speech_prob": 3.966948042943841e-06}, {"id": 1530, "seek": 717984, "start": 7179.84, "end": 7185.28, "text": " That literally the paper this is part of the retina net paper, which is actually a no", "tokens": [663, 3736, 264, 3035, 341, 307, 644, 295, 264, 1533, 1426, 2533, 3035, 11, 597, 307, 767, 257, 572], "temperature": 0.0, "avg_logprob": -0.22298309038270195, "compression_ratio": 1.784, "no_speech_prob": 1.4823491483184625e-06}, {"id": 1531, "seek": 717984, "start": 7185.28, "end": 7187.56, "text": " It's not the retina bit paper that was used in the retina net paper", "tokens": [467, 311, 406, 264, 1533, 1426, 857, 3035, 300, 390, 1143, 294, 264, 1533, 1426, 2533, 3035], "temperature": 0.0, "avg_logprob": -0.22298309038270195, "compression_ratio": 1.784, "no_speech_prob": 1.4823491483184625e-06}, {"id": 1532, "seek": 717984, "start": 7187.56, "end": 7192.18, "text": " it was you it was it created an earlier paper specifically about FPNs and like", "tokens": [309, 390, 291, 309, 390, 309, 2942, 364, 3071, 3035, 4682, 466, 479, 15466, 82, 293, 411], "temperature": 0.0, "avg_logprob": -0.22298309038270195, "compression_ratio": 1.784, "no_speech_prob": 1.4823491483184625e-06}, {"id": 1533, "seek": 717984, "start": 7193.0, "end": 7199.6, "text": " If memory says correctly, they did briefly cite the unit paper, but they kind of made it sound like it was this", "tokens": [759, 4675, 1619, 8944, 11, 436, 630, 10515, 37771, 264, 4985, 3035, 11, 457, 436, 733, 295, 1027, 309, 1626, 411, 309, 390, 341], "temperature": 0.0, "avg_logprob": -0.22298309038270195, "compression_ratio": 1.784, "no_speech_prob": 1.4823491483184625e-06}, {"id": 1534, "seek": 717984, "start": 7200.8, "end": 7207.68, "text": " vaguely slightly connected thing that maybe some people could consider slightly useful, but it really", "tokens": [13501, 48863, 4748, 4582, 551, 300, 1310, 512, 561, 727, 1949, 4748, 4420, 11, 457, 309, 534], "temperature": 0.0, "avg_logprob": -0.22298309038270195, "compression_ratio": 1.784, "no_speech_prob": 1.4823491483184625e-06}, {"id": 1535, "seek": 720768, "start": 7207.68, "end": 7210.26, "text": " FPNs as units, okay", "tokens": [479, 15466, 82, 382, 6815, 11, 1392], "temperature": 0.0, "avg_logprob": -0.20858801627645687, "compression_ratio": 1.665158371040724, "no_speech_prob": 8.397820238315035e-06}, {"id": 1536, "seek": 720768, "start": 7210.72, "end": 7214.92, "text": " I don't have an implementation of it to show you", "tokens": [286, 500, 380, 362, 364, 11420, 295, 309, 281, 855, 291], "temperature": 0.0, "avg_logprob": -0.20858801627645687, "compression_ratio": 1.665158371040724, "no_speech_prob": 8.397820238315035e-06}, {"id": 1537, "seek": 720768, "start": 7215.56, "end": 7220.16, "text": " But you know it'll be a fun thing maybe for some of us to try and some of us have already some I", "tokens": [583, 291, 458, 309, 603, 312, 257, 1019, 551, 1310, 337, 512, 295, 505, 281, 853, 293, 512, 295, 505, 362, 1217, 512, 286], "temperature": 0.0, "avg_logprob": -0.20858801627645687, "compression_ratio": 1.665158371040724, "no_speech_prob": 8.397820238315035e-06}, {"id": 1538, "seek": 720768, "start": 7220.400000000001, "end": 7226.04, "text": " Haven't yet, but I know some of the students have been trying so to get it working well on the forums", "tokens": [23770, 380, 1939, 11, 457, 286, 458, 512, 295, 264, 1731, 362, 668, 1382, 370, 281, 483, 309, 1364, 731, 322, 264, 26998], "temperature": 0.0, "avg_logprob": -0.20858801627645687, "compression_ratio": 1.665158371040724, "no_speech_prob": 8.397820238315035e-06}, {"id": 1539, "seek": 720768, "start": 7227.76, "end": 7232.88, "text": " So yeah interesting thing to try so I think a couple of couple of things to look at after this class", "tokens": [407, 1338, 1880, 551, 281, 853, 370, 286, 519, 257, 1916, 295, 1916, 295, 721, 281, 574, 412, 934, 341, 1508], "temperature": 0.0, "avg_logprob": -0.20858801627645687, "compression_ratio": 1.665158371040724, "no_speech_prob": 8.397820238315035e-06}, {"id": 1540, "seek": 723288, "start": 7232.88, "end": 7237.96, "text": " As well as the other things I mentioned would be playing around with FPNs", "tokens": [1018, 731, 382, 264, 661, 721, 286, 2835, 576, 312, 2433, 926, 365, 479, 15466, 82], "temperature": 0.0, "avg_logprob": -0.20475593833036201, "compression_ratio": 1.4748858447488584, "no_speech_prob": 4.860379249294056e-06}, {"id": 1541, "seek": 723288, "start": 7238.72, "end": 7241.88, "text": " And also maybe trying Kerim's dynamic unit", "tokens": [400, 611, 1310, 1382, 20706, 332, 311, 8546, 4985], "temperature": 0.0, "avg_logprob": -0.20475593833036201, "compression_ratio": 1.4748858447488584, "no_speech_prob": 4.860379249294056e-06}, {"id": 1542, "seek": 723288, "start": 7243.16, "end": 7246.400000000001, "text": " They would both be interesting things to look at. All right, so", "tokens": [814, 576, 1293, 312, 1880, 721, 281, 574, 412, 13, 1057, 558, 11, 370], "temperature": 0.0, "avg_logprob": -0.20475593833036201, "compression_ratio": 1.4748858447488584, "no_speech_prob": 4.860379249294056e-06}, {"id": 1543, "seek": 723288, "start": 7247.92, "end": 7253.64, "text": " So you guys have all been through 14 lessons of me talking at you now, so I'm sorry about that", "tokens": [407, 291, 1074, 362, 439, 668, 807, 3499, 8820, 295, 385, 1417, 412, 291, 586, 11, 370, 286, 478, 2597, 466, 300], "temperature": 0.0, "avg_logprob": -0.20475593833036201, "compression_ratio": 1.4748858447488584, "no_speech_prob": 4.860379249294056e-06}, {"id": 1544, "seek": 723288, "start": 7254.8, "end": 7256.96, "text": " Thanks for putting up with me", "tokens": [2561, 337, 3372, 493, 365, 385], "temperature": 0.0, "avg_logprob": -0.20475593833036201, "compression_ratio": 1.4748858447488584, "no_speech_prob": 4.860379249294056e-06}, {"id": 1545, "seek": 723288, "start": 7256.96, "end": 7258.96, "text": " You know, I think", "tokens": [509, 458, 11, 286, 519], "temperature": 0.0, "avg_logprob": -0.20475593833036201, "compression_ratio": 1.4748858447488584, "no_speech_prob": 4.860379249294056e-06}, {"id": 1546, "seek": 725896, "start": 7258.96, "end": 7267.12, "text": " It's it it's you're going to find it hard to find people who actually are as know as much about", "tokens": [467, 311, 309, 309, 311, 291, 434, 516, 281, 915, 309, 1152, 281, 915, 561, 567, 767, 366, 382, 458, 382, 709, 466], "temperature": 0.0, "avg_logprob": -0.2582268018401071, "compression_ratio": 1.661764705882353, "no_speech_prob": 7.411097158183111e-06}, {"id": 1547, "seek": 725896, "start": 7267.8, "end": 7270.24, "text": " Training neural networks and practice as you do", "tokens": [20620, 18161, 9590, 293, 3124, 382, 291, 360], "temperature": 0.0, "avg_logprob": -0.2582268018401071, "compression_ratio": 1.661764705882353, "no_speech_prob": 7.411097158183111e-06}, {"id": 1548, "seek": 725896, "start": 7271.32, "end": 7273.32, "text": " It'll be really easy for you to", "tokens": [467, 603, 312, 534, 1858, 337, 291, 281], "temperature": 0.0, "avg_logprob": -0.2582268018401071, "compression_ratio": 1.661764705882353, "no_speech_prob": 7.411097158183111e-06}, {"id": 1549, "seek": 725896, "start": 7274.52, "end": 7276.52, "text": " overestimate how", "tokens": [670, 377, 2905, 577], "temperature": 0.0, "avg_logprob": -0.2582268018401071, "compression_ratio": 1.661764705882353, "no_speech_prob": 7.411097158183111e-06}, {"id": 1550, "seek": 725896, "start": 7276.6, "end": 7281.96, "text": " Capable all these other people are and underestimate how capable you are. So like the main thing I say is like please", "tokens": [8363, 712, 439, 613, 661, 561, 366, 293, 35826, 577, 8189, 291, 366, 13, 407, 411, 264, 2135, 551, 286, 584, 307, 411, 1767], "temperature": 0.0, "avg_logprob": -0.2582268018401071, "compression_ratio": 1.661764705882353, "no_speech_prob": 7.411097158183111e-06}, {"id": 1551, "seek": 725896, "start": 7282.76, "end": 7284.16, "text": " practice", "tokens": [3124], "temperature": 0.0, "avg_logprob": -0.2582268018401071, "compression_ratio": 1.661764705882353, "no_speech_prob": 7.411097158183111e-06}, {"id": 1552, "seek": 725896, "start": 7284.16, "end": 7285.44, "text": " please", "tokens": [1767], "temperature": 0.0, "avg_logprob": -0.2582268018401071, "compression_ratio": 1.661764705882353, "no_speech_prob": 7.411097158183111e-06}, {"id": 1553, "seek": 725896, "start": 7285.44, "end": 7287.12, "text": " just because", "tokens": [445, 570], "temperature": 0.0, "avg_logprob": -0.2582268018401071, "compression_ratio": 1.661764705882353, "no_speech_prob": 7.411097158183111e-06}, {"id": 1554, "seek": 728712, "start": 7287.12, "end": 7291.86, "text": " You don't have this constant thing getting you to come back here every Monday night now", "tokens": [509, 500, 380, 362, 341, 5754, 551, 1242, 291, 281, 808, 646, 510, 633, 8138, 1818, 586], "temperature": 0.0, "avg_logprob": -0.17891140225567395, "compression_ratio": 1.5958549222797926, "no_speech_prob": 5.507516107172705e-06}, {"id": 1555, "seek": 728712, "start": 7292.44, "end": 7296.0, "text": " It's very easy to kind of lose that momentum", "tokens": [467, 311, 588, 1858, 281, 733, 295, 3624, 300, 11244], "temperature": 0.0, "avg_logprob": -0.17891140225567395, "compression_ratio": 1.5958549222797926, "no_speech_prob": 5.507516107172705e-06}, {"id": 1556, "seek": 728712, "start": 7296.48, "end": 7299.68, "text": " So find ways to keep it, you know", "tokens": [407, 915, 2098, 281, 1066, 309, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.17891140225567395, "compression_ratio": 1.5958549222797926, "no_speech_prob": 5.507516107172705e-06}, {"id": 1557, "seek": 728712, "start": 7300.24, "end": 7304.88, "text": " you know organize a study group, you know or a book reading group or", "tokens": [291, 458, 13859, 257, 2979, 1594, 11, 291, 458, 420, 257, 1446, 3760, 1594, 420], "temperature": 0.0, "avg_logprob": -0.17891140225567395, "compression_ratio": 1.5958549222797926, "no_speech_prob": 5.507516107172705e-06}, {"id": 1558, "seek": 728712, "start": 7306.24, "end": 7308.84, "text": " get together some friends and work on a project or", "tokens": [483, 1214, 512, 1855, 293, 589, 322, 257, 1716, 420], "temperature": 0.0, "avg_logprob": -0.17891140225567395, "compression_ratio": 1.5958549222797926, "no_speech_prob": 5.507516107172705e-06}, {"id": 1559, "seek": 728712, "start": 7309.72, "end": 7311.5599999999995, "text": " You know do something", "tokens": [509, 458, 360, 746], "temperature": 0.0, "avg_logprob": -0.17891140225567395, "compression_ratio": 1.5958549222797926, "no_speech_prob": 5.507516107172705e-06}, {"id": 1560, "seek": 731156, "start": 7311.56, "end": 7318.280000000001, "text": " More than just deciding I want to keep working on X like it's going to need to involve probably unless you're the kind of person", "tokens": [5048, 813, 445, 17990, 286, 528, 281, 1066, 1364, 322, 1783, 411, 309, 311, 516, 281, 643, 281, 9494, 1391, 5969, 291, 434, 264, 733, 295, 954], "temperature": 0.0, "avg_logprob": -0.18082870755876815, "compression_ratio": 1.6219081272084805, "no_speech_prob": 4.637735401047394e-06}, {"id": 1561, "seek": 731156, "start": 7318.280000000001, "end": 7322.360000000001, "text": " Who's super motivated and you know that whenever you decide to do something it happens", "tokens": [2102, 311, 1687, 14515, 293, 291, 458, 300, 5699, 291, 4536, 281, 360, 746, 309, 2314], "temperature": 0.0, "avg_logprob": -0.18082870755876815, "compression_ratio": 1.6219081272084805, "no_speech_prob": 4.637735401047394e-06}, {"id": 1562, "seek": 731156, "start": 7323.0, "end": 7327.84, "text": " That's not me. Right? It's like I know something to happen. I have to like say", "tokens": [663, 311, 406, 385, 13, 1779, 30, 467, 311, 411, 286, 458, 746, 281, 1051, 13, 286, 362, 281, 411, 584], "temperature": 0.0, "avg_logprob": -0.18082870755876815, "compression_ratio": 1.6219081272084805, "no_speech_prob": 4.637735401047394e-06}, {"id": 1563, "seek": 731156, "start": 7328.76, "end": 7331.96, "text": " Yes, David in October. I will absolutely teach that course", "tokens": [1079, 11, 4389, 294, 7617, 13, 286, 486, 3122, 2924, 300, 1164], "temperature": 0.0, "avg_logprob": -0.18082870755876815, "compression_ratio": 1.6219081272084805, "no_speech_prob": 4.637735401047394e-06}, {"id": 1564, "seek": 731156, "start": 7332.96, "end": 7334.96, "text": " And it's like okay", "tokens": [400, 309, 311, 411, 1392], "temperature": 0.0, "avg_logprob": -0.18082870755876815, "compression_ratio": 1.6219081272084805, "no_speech_prob": 4.637735401047394e-06}, {"id": 1565, "seek": 731156, "start": 7335.0, "end": 7339.280000000001, "text": " Better actually write some material like that's the only way I can get stuff to happen", "tokens": [15753, 767, 2464, 512, 2527, 411, 300, 311, 264, 787, 636, 286, 393, 483, 1507, 281, 1051], "temperature": 0.0, "avg_logprob": -0.18082870755876815, "compression_ratio": 1.6219081272084805, "no_speech_prob": 4.637735401047394e-06}, {"id": 1566, "seek": 733928, "start": 7339.28, "end": 7344.12, "text": " So we've got a great community there on the forums if people have ideas two ways to make it better", "tokens": [407, 321, 600, 658, 257, 869, 1768, 456, 322, 264, 26998, 498, 561, 362, 3487, 732, 2098, 281, 652, 309, 1101], "temperature": 0.0, "avg_logprob": -0.13852957375029212, "compression_ratio": 1.6620209059233448, "no_speech_prob": 1.300644453294808e-05}, {"id": 1567, "seek": 733928, "start": 7344.5599999999995, "end": 7347.5199999999995, "text": " Please tell me you know if you think you can help with", "tokens": [2555, 980, 385, 291, 458, 498, 291, 519, 291, 393, 854, 365], "temperature": 0.0, "avg_logprob": -0.13852957375029212, "compression_ratio": 1.6620209059233448, "no_speech_prob": 1.300644453294808e-05}, {"id": 1568, "seek": 733928, "start": 7348.24, "end": 7354.179999999999, "text": " You know if you want to create some new forum or moderate it in some different way or whatever just let me know", "tokens": [509, 458, 498, 291, 528, 281, 1884, 512, 777, 17542, 420, 18174, 309, 294, 512, 819, 636, 420, 2035, 445, 718, 385, 458], "temperature": 0.0, "avg_logprob": -0.13852957375029212, "compression_ratio": 1.6620209059233448, "no_speech_prob": 1.300644453294808e-05}, {"id": 1569, "seek": 733928, "start": 7354.179999999999, "end": 7356.179999999999, "text": " Right you can always PM me", "tokens": [1779, 291, 393, 1009, 12499, 385], "temperature": 0.0, "avg_logprob": -0.13852957375029212, "compression_ratio": 1.6620209059233448, "no_speech_prob": 1.300644453294808e-05}, {"id": 1570, "seek": 733928, "start": 7356.48, "end": 7360.46, "text": " And there's a lot of projects going on through github as well lots of stuff", "tokens": [400, 456, 311, 257, 688, 295, 4455, 516, 322, 807, 290, 355, 836, 382, 731, 3195, 295, 1507], "temperature": 0.0, "avg_logprob": -0.13852957375029212, "compression_ratio": 1.6620209059233448, "no_speech_prob": 1.300644453294808e-05}, {"id": 1571, "seek": 736046, "start": 7360.46, "end": 7369.4, "text": " So yeah, I hope to see you all back here at something else and thanks so much for joining me on this journey", "tokens": [50364, 407, 1338, 11, 286, 1454, 281, 536, 291, 439, 646, 510, 412, 746, 1646, 293, 3231, 370, 709, 337, 5549, 385, 322, 341, 4671, 50811], "temperature": 0.0, "avg_logprob": -0.1543479495578342, "compression_ratio": 1.173913043478261, "no_speech_prob": 2.3176695322035812e-05}], "language": "en"}