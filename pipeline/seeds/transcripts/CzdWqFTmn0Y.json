{"text": " Okay, so let me introduce everybody to everybody else first of all So we're here at the University of San Francisco learning machine learning or you might be at home watching this on video So hey everybody wave here is the University of San Francisco graduate students Thank you everybody and you know wave back from the future and from home to all the students here if You're watching this on YouTube, please stop And instead go to course dot fast AI and watch it from there instead There's nothing wrong with YouTube, but I can't edit these videos after I've created them So I need to be able to like if you updated information about like what? Environments to use how the technology changes and so you need to go here right so you can also watch the lessons from here Here's lots of lessons and so forth right so That's tip number one for the video Tip number two for the video is because I can't edit them all I can do is add these things called cards and Cards are little things that appear in the top corner the top right hand corner of the screen So by the time this video comes out, I'm going to put a little card there right now For you to click on and try that out Unfortunately, they're not easy to notice so keep an eye out for that because that's going to be important updates to the video All right, so welcome. We're going to be learning about machine learning today And so for everybody in the class here you all have Amazon web services set up So you might want to go ahead and launch your AWS instance now Or go ahead and create launch your Jupiter notebook on your own computer if You don't have Jupiter notebook set up Then what I recommend is you go to Cressel comm com sign in there sign up And You can then turn off enable GPU and click start Jupiter and you'll have a Jupiter notebook instantly that costs you some money It's three cents an hour Okay, so if you don't mind spending three cents an hour to learn machine learning. Here's a good way So I'm going to go ahead and say start Jupiter And so whatever technique you use There you go one of the things that you'll find on on the website is Links to lots of information about the costs and benefits and approaches to setting up lots of different environments for Jupiter notebook Both the deep learning and for regular machine learning so check them out because there's lots of options so If I then go open a Jupiter in open Jupiter in a new tab Here I am in Cressel or on AWS all your own computer We use the Anaconda Python distribution for basically everything you can install that yourself And again, there's lots of information on the website about how to set that up We're also assuming that either you're using Cressel or There's something else which I really like called paper space comm which is another place You can fire up if you put a notebook pretty much instantly both of these have Already have all of the fast AI stuff pre-installed for you So as soon as you open up Cressel or paper space assuming you chose the paper space fast AI Template you'll see that there's a fast AI template You'll see that there's a fast AI Folder okay, if you are using your own computer or AWS You'll need to go to our github repo fast AI fast AI And clone it okay, and then you'll need to do a conda and update to install the libraries And again, that's all information we've got on the website And we've got some previous workshop videos to help you through all of those steps so for this Class I'm assuming that you have a jupyter notebook running, okay So here we are in the in the jupyter notebook and If I click on fast AI, that's what you get if you get clone or if you're on Cressel you can see our repo here all of our Lessons are inside the courses folder and The machine learning part one is in the ml1 folder If you're ever looking at my screen and wondering where are you look up here, and you'll see It tells you the path fast AI courses ml1 And today we're going to be looking at lesson one random forests, so here is lesson one RF So there's a couple of different ways you can do this both here in person or on the video you can either Attempt to follow along as you watch or you can just watch and then follow along later with the video It's up to you I would Maybe have a loose recommendation to say to Watch now and follow along with the video later Just because it's quite hard to multitask and if you're working on something you might miss a key piece of information Which you're welcome to ask about okay, but if you follow along with the video afterwards, then you can pause stop Experiment and so forth but anyway you can choose either way I'm gonna Go view toggle header view toggle toolbar and then full screen it So to get a bit more space So the basic approach we're going to be teaching here tracking here is to Get straight into code start building models Not to look at theory we're going to get to all the theory okay But at the point where you deeply understand what it's for and at the point that you're able to be an effective practitioner So my hope is that you're going to spend your time focusing on Experimenting so if you take these notebooks and try different variations of what I show you Try it with your own data sets the more coding you can do The better the more you'll learn okay Don't it you know my suggestion or at least all of my students have told me the ones who have gone away and spent time studying Books of theory rather than coding found that they learned less machine learning and that they often tell me they wish that's one more time coding The stuff that we're showing in this course a lot of it's never been shown before this is not a summary of Other people's research. This is more a summary of 25 years of work that I've been doing in machine learning So a lot of this is is going to be shown for the first time and so that's kind of cool because if you want to Write a blog post about something that you learn here. You might be building something that a lot of people find super useful right so There's a great opportunity to practice your technical writing and here's some examples of good technical writing Okay by showing people stuff, but you've it's not like hey. I just learned this thing I bet you all know it often it'll be I just learned this thing and I'm going to tell you about it and other people Haven't seen it in fact This is the first course ever that's been built on top of the fast AI library So even just stuff in the library is going to be new to like everybody Okay, so when we use a Jupiter notebook or anything else in Python we have to Import the the libraries that we're going to use Something that's quite convenient is if you use these two auto reload commands at the top of your notebook You can go in and edit the source code of the modules and your notebook will automatically update with those new modules You won't have to like restart anything so that's super handy Then to show your plots inside the notebook you'll want map plot inline so these three lines Appear at the top of all of my notebooks You'll notice when I import the libraries that for anybody here who is a experienced Python programmer I am doing something that would be widely considered very inappropriate. I'm importing start Okay, generally speaking in software engineering. We're taught to like specifically figure out what we need and import those things The more experienced you are as a Python programmer the more extremely offensive practices You're going to see me use for example. I don't follow. What's called perp 8 Which is the normal style method style of code used in Python? So I'm going to mention a couple of the things first is Go along with it for a while. Don't judge me just yet right there's reasons that I do these things And if it really bothers you then feel free to change it right, but the basic idea is Data science is not software engineering right there's a lot of overlap. You know we're using the same languages And in the end these things will may become Software engineering projects, but what we're doing right now is we're prototyping models and prototyping models Has a very different set of best practices that are taught basically nowhere right? They're not really even really written down But the key is to be able to do things very interactively and very iteratively right so for example From library import star means you don't have to figure out ahead of time what you're going to need from that library It's it's all there okay Also because we're in this wonderful interactive Jupiter environment it lets us understand What's in the libraries really well so for example later on? I'm using a function called display right so an obvious question is like well What is display so you can just type the name of a function and? Press shift enter remember shift enter is is to run a cell and it will tell you where it's from Right so anytime you see a function you're not familiar with you can find out Where it's from and then if you want to find out what it does Put a question mark at the start Okay, and here you have the documentation and Then particularly helpful for the fast AI library so the fast AI library I try to make as many Functions as possible be like no more than about five lines of code It's designed to be really easy to read right if you put a second question mark at the start It shows you the source code of the function Right so all the documentation plus the source code so you can see like nothing has to be mysterious and We're going to be using the other library. We'll use a lot is scikit-learn Which is kind of implements a lot of machine learning stuff in Python the scikit-learn Source code is often pretty readable and so very often if I want to really understand something I'll just go question mark question mark and the name of the scikit-learn function I'm typing and I'll just go ahead and read the source code As I say the fast AI library in particular is designed to have source code That's very easy to read and we're going to be reading it a lot All right, so today we're going to be working on a Kaggle competition called blue book for bulldozers So the first thing we need is to get that data so if you go Kaggle bulldozers then you can find it so Kaggle competitions allow you to download a real world data set that somebody a real problem that somebody's trying to solve and Solve it according to a specification that that actual person with that actual problem decided would be actually helpful to them, right? So these are pretty authentic Experiences for applied machine learning now, of course, you're missing all the bit that went before which was why did this company to start up? Decide that predicting the auction sale price of bulldozers was important. Where did they get the data from? How did they clean the data and so forth? Okay, and that's all important stuff as well But the focus of this course is really on what happens next which is like how do you actually build the model? One of the great things about you working on Kaggle competitions Whether they be running now or whether they be old ones is that you can submit yours to the leaderboard Even old closed competitions you can submit to the leaderboard and find out how would you have gone? Right and there's really no other way in the world of knowing whether you're Competent at this kind of data in this kind of model than doing that right because otherwise If your accuracy is really bad, is it because this is just very hard like it's just not possible than the the the Data is so noisy. You can't do better or is it actually that it's an easy data set and you made a mistake and like when you Finish this course and apply this to your own projects. This is going to be something you're going to find very hard and there isn't a simple solution to it, which is You're now using something that hasn't been on Kaggle. It's your own data set Do you have a good enough answer or not? Okay, so we'll talk about that more during the course and in the end We just have to know that we have good effective techniques reliably building baseline models otherwise Yeah, there's really no way to know there's no way other than creating a Kaggle competition Or getting you know a hundred top data scientists to work at your problem to really know what's possible so Kaggle competitions are fantastic for learning and As I've said many times I've learned more from from competing in Kaggle competitions and everything else I've done in my life So to compete in a Kaggle competition you need the data this one's an old competition, so it's not running now, but we can still access everything So we first of all want to understand what the goal is and I suggest that you read this later but basically we're to try and predict the sale price of heavy equipment and And one of the nice things about this competition is that if you're like me you probably don't know very much about Heavy heavy industrial equipment options right I actually know more than I used to because my toddler loves Building equipment so we actually like watch YouTube videos about front-end loaders and forklifts But you know two months ago. I was You know a real layman so one of the nice things is that Machine learning should help us understand a data set not just make predictions about it So by picking an area which we're not familiar with it's a good test of whether we can build an understanding All right Because otherwise what can happen is that your? Intuition about the data can make it very difficult for you to be open-minded enough to see what does the data really say? It's easy enough to download the computer sorry to download the data to your computer You just have to click on the data set so here is train dot zip And click download right and so you can go ahead and do that if you're running on your own computer right now if you're running on AWS It's a little bit harder right because unless you're familiar with text mode browsers like a links or links It's quite tricky to get the data set to Kaggle so a couple of options One is you could download it to your computer and then scp it to AWS so scp works just like SSH, but it copies data rather than logging in I'll show you a trick though that I really like and it relies on using Firefox For some reason Chrome doesn't work correctly with Kaggle for this So if I go on Firefox To the website eventually And what we're going to do is we're going to use something called the JavaScript Console so every web browser comes with a set of tools for web developers To help them see what's going on and you can hit Developer Control shift I okay, so you can hit ctrl shift I to bring up This this web developer tools and one of the tabs is network Okay, and so then if I click on train dot zip and I click on download Okay, and I'm not even going to download I'm just going to say cancel But you'll see down here. It's shown me all of the network connections that were just initiated right and so here's one Which is downloading a zip file from storage Google api's calm blah blah blah. That's probably what I want All right, that looks good. So what you can do is you can right-click on that and say copy Copy as curl so curl is a unix command like W get that downloads stuff Right, so if I go copy as curl That's going to create a command that has all of my cookies headers everything in it necessary to download this authenticated data set so if I now go into my Server right and if I paste that you can see a really really long curl command One thing I notice is that at least recent versions have started adding this minus minus 2.0 thing to the command that doesn't seem to work with all versions of curl so something you might want to do is to Okay Is to pop that into an editor find that to Get rid of it and then use that instead Okay now one thing to be very careful about by default curl downloads The file and displays it in your terminal So if I try to display this it's going to display gigabytes of binary data in my terminal and crash it okay So to say that I want to output it using some different file name I always type minus O for output file name and then the name of the file bulldozers Dot and make sure you give it a suitable a Suitable extension so in this case the file was Train zip okay, so bulldozers dot zip And there it is okay, and so there it all is so I could make directory bulldozers I could move my zip file into there Oops wrong way around Yes Thank you Okay, and then you if you don't have unzip installed you may need to To pseudo apt install unzip or if then you're on a Mac That would be brew install unzip if brew doesn't work you haven't got home brew installed so make sure you install it And then unzip Okay, and so they're the basic steps One nice thing is that if you're using Cressell most of the Data sets should already be pre-installed for you So what I can do here is I can say open a new tab Here's a cool trick in Jupiter you can actually say new terminal and You can actually get a web-based terminal right and so you'll find on Cressell. There's a slash data sets folder slash data set slash kaggle slash data set slash fast AI often the things you need are going to be in one of those places Okay, so assuming that we don't have it already downloaded in paper actually paper space should have most of them as well Then we would need to go to fast AI. Let's go into the courses machine learning Folder and what I tend to do is I tend to put all of my data for a course into a folder called data You'll find that if you try and if you're using where we using get right you'll find that that doesn't get added To get because it's in the git ignore right so So don't worry about creating the data folder. It's not going to screw anything up So I generally make a folder called data, and then I tend to create folders for everything I need there So in this case I'll make the bulldozers CD and remember the last word of the last command is exclamation mark dollar I'll go ahead and grab that curl command again And then okay Zip bulldozers There we go, okay, so You Can now see I generally have like anything that would change that might change from person to person I kind of put in a constant so here. I just define saying called path but if you've used the same path, I just did you should just be able to go ahead and run that and Let's go ahead and keep moving along so we've now got all of our libraries imported, and we've set the path to the data You can run Shell commands from within jupyter notebook by using an exclamation mark so if I want to check what's inside that path I can go LS data slash bulldozers Okay, and you can see that works, or you can even use Python variables if you use a Python variable inside a jupyter shell command You have to put it in curlies Okay So that makes me feel good that my path is pointing at the right place if you say LS Curly capitals path and you get nothing at all then you're pointing at the wrong spot. Yes Yeah, so the curly brackets refer to the fact that I put an exclamation mark at the front which means the rest of this is not a Python command it's a bash command and bash doesn't know about capital path because capital path is part of Python so this is a special Jupiter thing which says expand this Python thing please before you pass it to the shelf So The goal here is to use the training set which contains data through the end of 2011 to predict the sale price of bulldozers and so The main thing to start with then is of course to look at the data Now the data is in csv format right so one easy way to look at the data would be to use shell command head to look at the first two lines head Bulldozers and even tab completion works here Jupiter does everything Right so here's the first few five lines, okay? So there's like a bunch of column headers, and then there's a bunch of data, so that's pretty hard to look at So what we want to do is take this and read it into a nice tabular format, okay, so Does Terrence put in glasses on me, and I should make this bigger or is it okay? Is this big enough font size? So This kind of data where you've got columns representing a wide range of different types of things such as an identifier value a currency a date a size I refer to this as structured data now I say I refer to this as structured data because like there's there's been many arguments in the machine learning community on Twitter about What is structured data? Weirdly enough this is like the most important type of distinction is between data that looks like this and data like Images where every column is of the same type like that's the most important distinction in machine learning Yet we don't have standard accepted terms, so I'm going to use the term structured and unstructured But note that other people you talk to particularly in NLP and NLP people use structured to mean something totally different, right so When I refer to structured data, I mean columns of data that can have varying different types of data in them By far the most important tool in Python for you working with structured data is pandas Pandas is so important that it's one of the few libraries that everybody uses the same abbreviation for it, which is PD so you'll find that One of the things I've got here is from fast AI imports import star, right? The fast AI imports Module has nothing but imports of a bunch of hopefully useful tools so all Of the code for fast AI is inside the fast AI directory inside the fast AI repo and so you can have a look at imports and You'll see it's just literally a list of imports and you'll find there Pandas as PD and so everybody does this right so you'll see lots of people using PD dot something They're always talking about pandas so pandas lets us read a CSV file and So when we read the CSV file We just tell it the path to the CSV file a list of any columns that contain dates And I always add this low memory equals false. That's going to actually make it read more of the file to decide what the types are This here is Something called a Python 3.6 format string. It's one of the coolest parts of Python 3.6 You've probably used lots of different ways in the past in Python of interpolating variables into your strings Python 3.6 has a very simple way that you'll probably always want to use from now on and it's you to create a normal string You type in F at the start And then if I define a variable Then I can say hello Curly's Python function Okay This is kind of confusing these are not the same curlies that we saw earlier on in that LS command right that LS command is specific to Jupiter and it interpolates Python code into shell code These curlies are Python 3.6 format string curlies they require an F at the start so if I get rid of the F It doesn't interpolate Okay, so the F tells it to interpolate and the cool thing is inside that Curly's you can write any Python code you like just about so for example name dot upper Hello Jeremy Okay, so I use this all the time And it doesn't matter because it's a format string. It doesn't matter if the thing was They always forget my age, I think I'm 43 It doesn't matter if it's an integer right normally if you like to string concatenation with integers Python complains No such problem here, okay, so So this is going to read paths train dot CSV into a thing called a data frame Pandas data frames and ours data frames are kind of pretty similar so if you've used our before Then you'll find that this is a you know reasonably comfortable so this file Is 9.3 Meg and its size is Sorry 112 Meg 112 Meg and it has 400,000 rows in it okay, so it takes a moment to import it But when it's done We Can Type the name of the data frame DF raw And then use various methods on it so for example DF raw dot tail Will show us the last few rows of the data frame By default it's going to show the columns along the top and the rows down the side But in this case there's a lot of columns, so I've just said dot transpose to show it the other way around I've created one extra function here display all normally if you just type DF raw If it's too big to show conveniently it truncates it and puts like little lips is in the middle So the details don't matter, but this is just changing a couple of settings to say even if it's got a thousand rows and a Thousand columns, please still show the whole thing Okay, so this is finished. I can actually show you that so if I just type this is really cool in in Jupiter notebook you can type a variable of almost any kind a video HTML an image whatever and it'll generally figure out a way of displaying it for you okay So in this case it's a pandas data frame it figures it out a way of displaying it for me And so you can see here that by default. It's actually doesn't show me the whole thing so So here's the data set We've got a few different rows. This is the last bit the tail of it right last few rows This is the thing we want to predict Price okay, and then all of the other so we call this the dependent variable The dependent variable is the price And then we've got a whole bunch of things we could predict it with and when I start with a data set I tend To be a little bit more careful and yes Terrence can I give you this? Hello Jeremy hi Terrence I've read in books that you should never look at the data because of the risk of overfit Why do you start by looking at the data? Yeah, so I was actually going to mention I actually kind of don't like I I want to find out at least enough to know that Okay, but I tend not to really study it at all at this point Because I don't want to make too many assumptions about it. I would actually say Most books say the opposite most books do a whole lot of EDA expiratory data analysis first Yeah academic books The academic books I've read Say that's that's one of the biggest risks of overfitting but the practical books say let's do some EDA first Yeah, so that the truth is kind of somewhere in between and I generally I generally try to do machine learning driven EDA And that's what we're going to learn today, okay? So the do thing I do care about though is What's the purpose of the project and for Kaggle projects the purpose is very easy We can just look and find out there's always an evaluation section How is it evaluated and this is evaluated on root mean squared log error? so this means they're going to look at the difference between the log of our prediction of price and the log of the actual price and Then they're going to square it and add them up Okay, so because they're going to be focusing on the difference of the logs That means that we should focus on the logs as well, and this is pretty common like for a price Generally you care not so much about did I miss by $10, but did I miss by 10% right? So if it was a million dollar thing and you're a hundred thousand dollars off or if you're it's a ten thousand dollar thing and you're A thousand dollars off often we would consider those equivalent scale issues and so for this auction problem The organizers are telling us they care about ratios more than differences and so the log is the thing we care about So the first thing I do is to take the log Okay, now NP is numpy I'm assuming that you have some familiarity with numpy if you don't we've got a video called deep learning workshop Which actually isn't just for deep learning it's for a whole basically for this as well and one of the parts there Which we've got a time coded link to is a quick introduction to numpy Okay, but basically numpy lets us treat arrays matrices vectors high dimensional tensors as if they're Python variables and we can do stuff like log to them and it'll apply it to Everything numpy and pandas work together very nicely So in this case DF raw dot sale price is pulling a column out of a pandas data frame which gives us a Pandas series right it shows us the sale prices and their indexes right and A series can be passed to a numpy Function okay, which is pretty handy and so you can see here. This is how I can replace a column with a new column pretty easy So okay now that we've replaced its sale price with its log we can go ahead and try to create a random forest What's a random first? we'll find out in detail, but in brief a random forest is a Kind of universal machine learning technique. It's a way of predicting something that can be of any kind It could be a category Like is it a dog or a cat or it could be a continuous? continuous continuous variable like price It can predict it with columns of pretty much any kind pixel data zip codes revenues whatever in General it doesn't overfit it can and we'll learn to check whether it is but it doesn't generally overfit too badly And it's very very easy to make to stop it from overfitting You don't need and we'll talk more about this you don't need a separate validation set in general It can tell you how well it generalizes even if you only have one data set It has few if any statistical assumptions. It doesn't assume that your data is normally distributed It doesn't assume that the relationships are linear. It doesn't assume that you've just specified the interactions it requires Very few pieces of feature engineering for many different types of situation You don't have to take the log of the data. You don't have to model play interactions together. So in other words It's a great place to start right if your first random forest Does very little useful then that's a sign that there might be problems with your data like it's designed to work pretty much First off, can you please throw it at or towards this gentleman? Thank you What about curse of the national? Yeah Yeah, great question. So there's this concept of curse of dimensionality In fact, there's two concepts I'll touch on curse of dimensionality and the no free lunch theorem These are two concepts. You'll often hear a lot about They're both largely meaningless and basically stupid and yet I Would say maybe the majority of people in the field Not only don't know that but think the opposite so it's well worth explaining The curse of dimensionality is this idea that the more columns you have It basically creates a space that's more and more empty and there's this kind of fascinating mathematical Idea, which is the more dimensions you have the more all of the points sit on the edge of that space All right So if you've just got a single dimension where things are like random then they're spread out all over Right where else if it's a square then the probability that they're in the middle means that they can't have been on the edge of either Dimension so it's a little bit less likely that they're not on the edge Each dimension you add it becomes more applicatively less likely that the point isn't on the edge of at least one dimension right and so basically in high dimensions everything sits on the edge and What that means in theory is that the distance between points is much less meaningful? and so if we assume that somehow that matters then it would suggest that when you've got lots and lots of Columns and you just use them without being very careful to remove the ones you don't care about that somehow things won't work That turns out just not to be the case It's not the case for a number of reasons One is that the points still do have different distances away from each other just because they're on the edge They still do vary in how far away they are from each other and so this point is more similar to this point Than it is to that point so even things will learn about k nearest neighbors actually work really well Really really well in high dimensions despite what the theoreticians claimed and what really happened here was that in the 90s? theory totally took over Machine learning and so particularly there was this concept of these things called support vector machines that were Theoretically very well justified extremely easy to analyze mathematically and you could like kind of prove things about them and We kind of lost a decade of real practical development in my opinion and all these theories Became very popular like the curse of dimensionality nowadays And a lot of theoreticians hate this the the world of machine learning has become very empirical Which is like which techniques actually work and it turns out that in practice Building models on lots and lots of columns works really really well So yeah, the other thing to quickly mention is the no free lunch theorem There's a mathematical theorem by that name that you will often hear about that claims that There is no type of model that works well for any kind of data set Which is true and is obviously true if you think about it in the mathematical sense Any random data set by definition? It's random right so there isn't going to be some way of looking at every possible random data set That's in some way more useful than any other approach in the real world we look at data Which is not random Mathematically we'd say it sits on some lower dimensional manifold. It was created by some kind of Cause all structure right there are some relationships in there So the truth is that we're not using random data sets and so the truth is in the real world There are actually techniques that work much better than other techniques for nearly all of the data sets you look at and nowadays there are empirical researchers who spend a lot of time studying this which is which techniques work a lot of the time and On some balls of decision trees of which random forests are one It is perhaps the technique which most often comes up the top and that is despite the fact that Until the library that we're showing you today fast AI came along there wasn't really any standard way to pre process them properly And to properly set their parameters, so I think it's even more strong than that so Yeah, I think this is where the difference between theory and practice is is is huge So when I try to create a random forest regressor, what is that random forest regressor? Okay, it's part of something called SK learn SK learn is scikit-learn It is by far the most popular and important package for machine learning in Python. It does nearly everything It's not the best at nearly everything, but it's perfectly good at nearly everything So like you might find in the next part of this course with your net You're going to look at a different kind of decision tree ensemble called gradient boosting trees Where actually there's something called XG boost which is better than gradient boosting trees and scikit-learn But it's pretty good at everything so we're I'm really going to focus on scikit-learn Random forest you can do two kinds of things with a random forest if I hit tab I Haven't imported it, so let's go back to where we import So you can hit tab in Jupyter Notebook to get tab completion for anything that's In your environment, and you'll see that there's also a random forest classifier so in general there's an important distinction between things which can predict continuous variables and that's called regression and Therefore a method for doing that would be a regressor and things that predict categorical variables And that is called classification and the things that do that are called classifiers So in our case we're trying to predict a continuous variable price so therefore we are doing regression And therefore we need a regressor a Lot of people incorrectly use the word regression to refer to linear regression Which is just not at all true or appropriate regression means a machine learning model It's trying to predict some kind of continuous outcome. It has a continuous dependent variable So pretty much everything in scikit-learn has the same form you first of all create an instance of an object for the machine learning model you want you then call fit passing in the Independent variables the things you're going to use to predict and the dependent variable the thing that you want to predict so in our case the dependent variable is Is The data frames sale price column and So we the thing we want to use to predict is everything except that in pandas the drop method Returns a new data frame with a list of columns removed Right well a list of rows or columns removed so axis equals one means remove columns So this here is the data frame containing everything except for sale price Okay I Let's find out so to find out I could hit shift tab and That will bring up the you know a quick inspection of the parameters in this case. It doesn't quite tell me what I want So if I hit shift tab twice It gives me a bit more information ah yes, and that tells me it's a single label or list like List like means like anything you can index in Python there's lots of things by the way if I hit three times It will give me a whole little window at the bottom okay, so that was shift tab Another way of doing that of course which we learned would be question mark question mark DF raw drop Okay Sorry question mark question mark would be the source code for it For a single question mark is the documentation So I think that trick of like tab complete shift tab parameters Question mark and double question mark for the docs and the source code like if you know nothing else about using Python libraries Know that because now you know how to find out everything else Okay So we try to run it and it doesn't work Okay, so why didn't it work so anytime you get a? Stack trace like this so an error the trick is to go to the bottom because the bottom tells you what went wrong Above it it tells you all of the functions that called other function could cause other functions to get there Could not convert string to float Conventional so there was a column name Sorry a there was a value rather inside my data set conventional the word conventional And it didn't know how to create a model using that string Now that's true. We have to pass numbers to most machine learning Models and certainly to random forests so step one is to convert everything into numbers So our data set contains both continuous variables so numbers where the meaning is numeric like price and It contains categorical variables which could either be numbers where the meaning is not continuous like a zip code or it could be a String like large small and medium so categorical and continuous variables We want to basically get to a point where we have a data set where we can use all of these variables So they have to all be numeric and they have to be usable in some way So one issue is that we've got something called sale date Which you might remember right at the top we told it that that's a date So it's been passed as a date and so you can see here. It's data type D type very important thing data type is date time 64 bit So that's not a number Right and this is actually where we need to do our first piece of feature engineering right inside a date There's a lot of interesting stuff All right, so since you've got the catch box, can you tell me what are some of the interesting bits of information inside a date? Well, you can see like a time series pattern That's true, I'm having didn't express very well, what are some columns that we could pull out of this year month The date as in like it tell me a not at least be a number yeah Month order you want to pass it to your right and get some more behind you just pass it to your right You go you got some more columns for us Day of month, yeah, keep going to the right day of week day of week. Yeah Week of year. Yeah, okay. I'll give you a few more like that You might want to think about would be like is it a holiday? Is it a weekend Was it raining that day? Was there a sports event that day? Like it depends a bit on what you're doing right so like if you're predicting soda sales in Soma you would probably want to know was there a San Francisco Giants ballgame on that day All right, so like what's in a date is one of the most important pieces of feature engineering you can do and no machine learning Algorithm can tell you whether the Giants were playing that day and that it was important All right, so this is where you need to do feature engineering So I do as much things as many things automatically as I can for you Right so here. I've got something called add date part What is that? It's something inside fast AI dot structured Okay, and what is it? Well, let's read the source code Here it is so you'll find most of my functions are Less than half a page of code right so here is something It's gonna so rather than often rather than having docs I'm gonna try to add docs over time, but they're designed that you can understand them are reading the code So we're passing in a data frame and the name of some field okay, which in this case was sale date and so In this case we can't go DF dot field name because that would actually find a field called field name Literally so DF square bracket field name is how we grab a column where that column name is stored in this variable Okay, so we've now got the field itself the series And so what we're going to do is we're going to go through all of these different strings right, and this is a piece of Python which actually looks inside an object and finds a Attribute with that name, so this is going to go through and you can again you can google for Python get attribute It's a cool little advanced technique, but this is going to go through and it's going to find for this field It's going to find its year attribute Now pandas has got this interesting idea, which is if I actually look inside Let's go field equals. This is the kind of experiment. I want you to do right play around say okay? So I've now got that in a field object and so I can go field Right and I can go field dot tab Right and let's see is year in there. Oh It's not okay. Why not well That's because year is only going to apply to pandas series that are date-time objects So what pandas does is it splits out different methods? Inside attributes that are specific to what they are so date-time objects will have a DT attribute defined and At that is where you'll find all the date-time specific stuff So what I went through was I went through all of these and Picked out all of the ones that could ever be interesting for ever any reason right and this is like the opposite of the curse of Dimensionality it's like if there is any column or any variant of that column that could be ever be interesting at all Add that to your data set and every variation of it you can think of there's no harm in adding more columns Nearly all the time right so in this case We're going to go ahead and add all of these different attributes and so for every one I'm going to create a new field That's going to be called The name of your field with the word date removed so it'll be sale and then the name of the attribute So we're going to get a sale year sale month sale week sale day etc etc Okay, and then at the very end. I'm going to remove the original field right because remember we can't use Sale date directly because it's not a number So you're saying this only work because it was a date type did you make it again? Or was already saved as one in the original yeah, it's already a date type and the reason it was a date type Is because when we imported it? We said pause dates equals and told pandas It's a date type so as long as it looks date ish and we tell it to pause it as a date I I think there might be but for some reason it wasn't ideal like maybe it took lots of time Or it didn't always work or for some reason I had to list it here I would suggest checking out the docs to pandas dot read CSV and maybe on the forum you can tell us what you find Because I can't remember offhand I Let's do that one on the same forum thread that's Anna creates because I think it's a reasonably advanced question, but generally speaking the time zone in a properly formatted date will be included in the string and it should Format it should pull it out correctly and turn it into a universal time zone so generally speaking it should handle it for you So notice you for indexing a column you think to shape only use the dot The square brackets one is safer Particularly if you're assigning to a column if it didn't already exist You need to use the square brackets format otherwise you'll get weird errors So the square brackets format is safer the dot version saves me like a couple of keystrokes So I probably use it more than I should in this particular case Because I wanted to grab something that was had field name was had something inside it wasn't the name itself I have to use square brackets So square brackets is going to be your your safe bet if in doubt so After I run that You'll notice that DF raw Dot columns gives me a list of all of the columns Just as strings and at the end there they all are right, so it's removed sale date, and it's added all those So that's not quite enough The other problem is that we've got a whole bunch of strings in there right so You can just leave that there do you want to pass it back? So Is like low high medium, thank you All right, so pandas actually has a concept of a category data type But by default it doesn't turn anything into a category for you, so I've created something called train cats Which creates categorical variables for everything that's a string Okay, and so what that's going to do is behind the scenes is going to create a column That's actually a number right as an integer, and it's going to store a mapping from the integers to the strings Okay The reason it's train cats is that you use this for the training set More advanced usage is that when we get to looking at the test and validation sets this is really important idea In fact Terrence came to me the other day, and he said my models not working Why not and he figured it out for himself it turned out the reason Why was because the mappings he was using from string to number in the training set were different to the mappings He was using from string to number in the test set so therefore in the training set High might have been three, but in the trait test set it might have been two so the two were totally different And so the model was basically non predictive okay, so I have another function Called apply categories Where you can pass in your existing training set and it'll use the same? Mappings to let you'll make sure your test set of validation set uses the same mappings okay? So when I go train cats it's actually not going to make the data frame look different at all Behind the scenes it's going to turn them all into numbers We finish at 12 1150 and then our Let's see how we go I'll try and finish on time So you'll see now remember I mentioned there was this dot DT attribute that gives you access to everything assuming It's a date time about the date time There's a dot cat attribute that gives you access to things assuming something's a category right and so usage band was a string And so now that I've run train cats it's turned it into a category So I can go df raw dot usage band cat Right and there's a whole bunch of other things we've got there, okay? So one of the things we've got there is dot categories, and you can see here is the list Now one of the things you might notice is that this list is in a bit of a weird order high low medium The truth is it doesn't matter too much But what's going to happen when we use the random forest is it's actually going to this is going to be zero This is going to be one this is going to be two and we're going to be creating decision trees And so we're going to have a decision tree that can split things at a single point so it either be high Versus low and medium or medium versus high and low that would be kind of weird right it actually turns out not to work Too badly, but it'll work a little bit better if you have these insensible orders Okay, so if you want to reorder a category, then you can just go cat dot set categories and pass in The order you want until it is ordered and almost every pandas method has an in place Parameter which rather than returning a new data frame. It's going to change that data frame Okay, so I'm not going to do that like I didn't check that carefully for categories It should be ordered, but this seems like a pretty obvious one Can you reiterate that issue? I don't understand what the problem is Sure, so the usage band column Is actually going to be This is actually what our random forest is going to see these numbers 1 0 2 1 Okay, and they map to the position in this array and as we're going to learn shortly a random forest consists of a bunch of trees That's going to make a single split and the single split is going to be either Greater than or less than one or greater than or less than two right so we could split it into high Versus low and medium which that semantically makes sense like is it big or we could split it into Medium versus high and low it doesn't make much sense Right so in practice the decision tree could then make a second split to say like Medium versus high and low and then within the high and low into high and low But by putting it in a sensible order if it wants to split out low it can do it in One decision rather than two and we'll be learning more about this shortly It's it honestly it's not a big deal, but I just wanted to mention. It's there and It's also good to know that people when they talk about like different types of categorical variable Specifically you need to know there's a kind of categorical variable called ordinal and an ordinal Categorical variable is one that has some kind of order like high medium and low right and random forests aren't terribly sensitive to that fact But it's worth knowing it's there and trying it out That's what I'm saying it helps a little bit right it means you can get there with one decision rather than two I Notice there is a negative one in that list of categories is that like an NA or yeah exactly so for free we get A negative one which refers to missing and one of the things we're going to do is we're going to actually add one Can somebody pass it back to Paul is we're going to add one to our codes maybe in two goes Let people know it's coming Yeah, so let people so we're going to add one to all of our codes to make missing zero later on So Yeah, we're gonna get to that yeah Yeah, so get dummies which we'll get to in a moment is going to create three separate columns Ones and zeros for high ones there's a medium one is very slow Where else this one creates a single column with an integer zero one or two? We're going to get to that one shortly yep, did you have a question to Paul or you're just putting out, okay? Okay, so at this point as long as we always make sure we use dot cat dot codes the thing with the numbers in We're basically done all of our strings have been turned into numbers at dates been turned into a bunch of numeric columns and everything else Is already a number okay? The only other main thing we have to do is notice that we have lots of missing values so here is Thea for all dot is null that's going to return true or false Depending on whether something is empty Dot sum is going to add up how many empty for each series And then I'm going to sort them and divide by the size of the data set so here we have some things which have like quite high percentages of Nulls so so missing values we call them in I Okay so We're going to get to that in a moment, but I will point something out which is reading the CSV took a minute or so The processing took another 10 seconds or so from time to time when I've done a little bit of work I don't want to wait for again. I will tend to save where I'm at so here I'm going to save it and I'm going to save it in a format called feather format This is very very new right but what this is going to do is it's going to save it to disk in Exactly the same basic format that it's actually in RAM This is by far the fastest way to save something and the fastest way to read it back right so most of the folks you deal With unless they're on the cutting edge won't be familiar with this format, so this would be something you can teach them about It's becoming the standard Right it's actually becoming something that's going to be used not just in pandas, but in Java In spark in lots of like things for like communicating across computers because it's incredibly fast And it's actually co-designed by the guy that made panthers by Wes McKinney So we can just go dear for all dot to feather and pass in some name I tend to have a folder called temp for all of my like as I'm going along stuff And so when you go OS dot make dirs you can path in any path path here You like it won't complain if it's already there because I've got exists okay equals true if there are some sub directories It'll create them for you, so this is a super handy little function Okay, so it's not installed So because I'm using Cressel for the first time it's complaining about that so if you get a message that something's not installed If you're using anaconda you can conda install Cressel actually doesn't use anaconda it uses pip And So we wait for that to go along okay, and so now if I run it And so sometimes You may find you actually have to Restart Jupiter, so I won't do that now because we're nearly out of time So if you restart Jupiter you'll be able to keep moving along so from now on You don't have to rerun all the stuff above you could just say PD dot read feather, and we've got our data frame back So the last step we're going to do is to Actually replace the strings with their numeric codes And we're going to pull out the dependent variable sale price into a separate variable And we're going to also handle missing continuous values, and so how are we going to do that? So you'll see here. We've got a function called proc DF What is that proc DF? So it's inside fast AI dot structured again and Here it is So quite a lot of the functions have a few additional parameters that you can provide and we'll talk about them later But basically we're providing the data frame to process and the name of the dependent variable the y Field name okay, and so all it's going to do is it's going to make a copy of the data frame It's going to grab the y value. It's going to drop the dependent variable from the original and Then it's going to Fix missing so how do we fix missing? So what we do to fix missing is pretty simple if it's numeric Then we fix it by basically saying let's first of all check that it does have some missing right So if it does have some missing values, so in other words the is null dot sum is non-zero Then we're going to create a new column called with the same name as the original plus underscore NA And it's going to be a Boolean column with a 1 anytime that was missing and a 0 anytime it wasn't We're going to talk about this again next week, but this is you know I'll give you the quick version having done that we're then going to replace the Nase the missing with the median Okay, so anywhere that used to be missing will be replaced with the median or add a new column to tell us which ones were missing We only do that for numeric We don't need it for categories because pandas had his handles categorical variables automatically by setting them to minus 1 so What we're going to do is If it's not numeric and It's a categorical type we'll talk about the maximum number of categories later, but let's assume this is always true So if it's not a numeric type we're going to replace the column with its codes the integers okay plus one Right so the by default Pandas uses minus one for missing so now zero will be missing and One two three four will be all the other categories So we're going to talk about dummies later on in the course But basically optionally you can say that if you already know about dummy values They're columns with a small number of possible values you can turn into dummies instead of numericalizing them But we're not going to do that for now okay, so for now all we're doing is we're using the categorical codes plus one Replacing missing values with the median adding an additional column telling us which ones were replaced and removing the dependent variable So that's what Proc DF does runs very quickly okay, so you'll see now Sale price is no longer here. Okay. We've now got a whole new color a whole new variable called y that contains sale price You'll see we've got a couple of extra blah Underscore N a's at the end okay, and if I look at that Everything is a number Okay These Booleans are treated as numbers. They're just considered treated as zero or one. They're just displayed as false and true They can see here is at the end of a month is at the start of a month is at the end of a quarter it's Kind of funny right because we've got things like a model ID which presumably is something like I don't it could be a serial number It could be like the model identifier. That's created by the factory or something We've got like a data source ID like some of these are numbers, but they're not continuous It turns out actually random forests work fine with those We'll talk about why and how and a lot about that in detail, but for now all you need to know is No problem, okay, so as long as this is all numbers which it now is we can now go ahead and create a random forest so M dot random first regressor Random forests are trivially Paralyzable so what that means is that they if you've got more than one CPU which everybody will basically on their Computers at home, and if you've got a t2 dot medium or bigger at AWS You've got multiple CPUs trivially paralyzable means that it will split up the data Across your different CPUs and basically linearly scale right so the more CPUs you have Pretty much it will divide the time it takes by that number not exactly but roughly So n jobs equals minus 1 tells the random forest regressor to create a separate job So separate process basically for each CPU you have so that's pretty much what you want all the time Fit the model using this new data frame we created using that y value We pulled out and then get the score okay the score is going to be the R squared We'll define that next week hopefully some of you already know about the R squared one is very good Zero is very bad so as you can see we've immediately got a very high score Okay, so That looks great, but what we'll talk about next week a lot more is that it's not quite great Because maybe we had data that had points that looked like this and we fitted a line that looks like this When actually we want to want one that looks like that okay the only way to know Whether we've actually done a good job is by having some other data set that we didn't use to train the model now We're going to learn about some ways with random forests We can kind of get away without even having that other data set but for now What we're going to do is we're going to split into 12,000 Rows which we're going to put in a separate data set called the validation set Versus the training set is going to contain everything else right and our data set is It's going to be sorted by date And so that means that the most recent 12,000 rows are going to be our validation set again We'll talk more about this next week. It's a really important idea, but for now We can just recognize that if we do that and run it I've created a little thing called print score, and it's going to Print out the root mean squared error between the predictions and actuals for the training set for the validation set The R squared for the training set and the validation set and you'll see that actually the R squared for the training was 0.98 But for the validation was 0.89 9 okay, then the RMSE and remember this is on the logs was 0.09 for the training set 0.25 for the validation set now if you actually go to kaggle and go to the leaderboard In fact, let's do it right now He's got private and public I'll check on public leaderboard and We can go down and find out where is point two five so there are 475 teams And generally speaking if you're in the top half of a Kaggle competition you're doing pretty well So point two five here. We are point two five. What was it exactly point two five? Went to five oh seven Yeah about a hundred and tenth so we're about in the top 25% 25% so so the idea like this is pretty cool right with with like with no thinking at all Using the defaults of everything we're in the top 25% of a Kaggle competition so like random forests are insanely Powerful and this totally standardized process is insanely good for like any data set so We're going to wrap up, but what I'm going to ask you to do for Tuesday it's like take as many Kaggle competitions as you can whether they be running now or old ones or data sets that you're interested in for hobbies or work and And please try it right try this process and if it doesn't work You know tell us on the forum. Here's the data set. I'm using here's where I got it from Here's like the stack trace of where I got an error or here's like you know if you use my my print score function or something like it like you know show us what the training versus test set looks like We'll try and figure it out right, but what I'm hoping we'll find is that all of you will be pleasantly surprised that with with the you know Our or two with information you got today You can already get better models than most of the very serious practicing data scientists that compete in Kaggle competitions Okay, great. Good luck, and I'll see you on the forums. Oh One more thing Friday The other class said a lot of them had class during my office hours So if I made them one till three instead of two till four on Fridays is that okay? seminar oh Okay, I have to find a whole nother time all right I will talk to somebody who actually knows what they're doing unlike me about finding office hours. Thank you absolutely", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.72, "text": " Okay, so let me introduce everybody to everybody else first of all", "tokens": [1033, 11, 370, 718, 385, 5366, 2201, 281, 2201, 1646, 700, 295, 439], "temperature": 0.0, "avg_logprob": -0.20117100374198255, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.04599917307496071}, {"id": 1, "seek": 0, "start": 10.72, "end": 16.8, "text": " So we're here at the University of San Francisco learning machine learning or you might be at home watching this on video", "tokens": [407, 321, 434, 510, 412, 264, 3535, 295, 5271, 12279, 2539, 3479, 2539, 420, 291, 1062, 312, 412, 1280, 1976, 341, 322, 960], "temperature": 0.0, "avg_logprob": -0.20117100374198255, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.04599917307496071}, {"id": 2, "seek": 0, "start": 16.84, "end": 21.56, "text": " So hey everybody wave here is the University of San Francisco graduate students", "tokens": [407, 4177, 2201, 5772, 510, 307, 264, 3535, 295, 5271, 12279, 8080, 1731], "temperature": 0.0, "avg_logprob": -0.20117100374198255, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.04599917307496071}, {"id": 3, "seek": 0, "start": 21.8, "end": 27.5, "text": " Thank you everybody and you know wave back from the future and from home to all the students here", "tokens": [1044, 291, 2201, 293, 291, 458, 5772, 646, 490, 264, 2027, 293, 490, 1280, 281, 439, 264, 1731, 510], "temperature": 0.0, "avg_logprob": -0.20117100374198255, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.04599917307496071}, {"id": 4, "seek": 0, "start": 27.96, "end": 29.68, "text": " if", "tokens": [498], "temperature": 0.0, "avg_logprob": -0.20117100374198255, "compression_ratio": 1.7912621359223302, "no_speech_prob": 0.04599917307496071}, {"id": 5, "seek": 2968, "start": 29.68, "end": 33.84, "text": " You're watching this on YouTube, please stop", "tokens": [509, 434, 1976, 341, 322, 3088, 11, 1767, 1590], "temperature": 0.0, "avg_logprob": -0.19408677419026693, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00016087213589344174}, {"id": 6, "seek": 2968, "start": 34.48, "end": 39.96, "text": " And instead go to course dot fast AI and watch it from there instead", "tokens": [400, 2602, 352, 281, 1164, 5893, 2370, 7318, 293, 1159, 309, 490, 456, 2602], "temperature": 0.0, "avg_logprob": -0.19408677419026693, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00016087213589344174}, {"id": 7, "seek": 2968, "start": 40.36, "end": 45.6, "text": " There's nothing wrong with YouTube, but I can't edit these videos after I've created them", "tokens": [821, 311, 1825, 2085, 365, 3088, 11, 457, 286, 393, 380, 8129, 613, 2145, 934, 286, 600, 2942, 552], "temperature": 0.0, "avg_logprob": -0.19408677419026693, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00016087213589344174}, {"id": 8, "seek": 2968, "start": 46.760000000000005, "end": 52.08, "text": " So I need to be able to like if you updated information about like what?", "tokens": [407, 286, 643, 281, 312, 1075, 281, 411, 498, 291, 10588, 1589, 466, 411, 437, 30], "temperature": 0.0, "avg_logprob": -0.19408677419026693, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00016087213589344174}, {"id": 9, "seek": 2968, "start": 52.6, "end": 57.92, "text": " Environments to use how the technology changes and so you need to go here right so you can also", "tokens": [19286, 1117, 281, 764, 577, 264, 2899, 2962, 293, 370, 291, 643, 281, 352, 510, 558, 370, 291, 393, 611], "temperature": 0.0, "avg_logprob": -0.19408677419026693, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00016087213589344174}, {"id": 10, "seek": 5792, "start": 57.92, "end": 61.08, "text": " watch the lessons from here", "tokens": [1159, 264, 8820, 490, 510], "temperature": 0.0, "avg_logprob": -0.16822136200226104, "compression_ratio": 1.7883817427385893, "no_speech_prob": 1.2218546544318087e-05}, {"id": 11, "seek": 5792, "start": 62.04, "end": 65.44, "text": " Here's lots of lessons and so forth right so", "tokens": [1692, 311, 3195, 295, 8820, 293, 370, 5220, 558, 370], "temperature": 0.0, "avg_logprob": -0.16822136200226104, "compression_ratio": 1.7883817427385893, "no_speech_prob": 1.2218546544318087e-05}, {"id": 12, "seek": 5792, "start": 66.44, "end": 68.4, "text": " That's tip number one for the video", "tokens": [663, 311, 4125, 1230, 472, 337, 264, 960], "temperature": 0.0, "avg_logprob": -0.16822136200226104, "compression_ratio": 1.7883817427385893, "no_speech_prob": 1.2218546544318087e-05}, {"id": 13, "seek": 5792, "start": 68.4, "end": 74.44, "text": " Tip number two for the video is because I can't edit them all I can do is add these things called cards and", "tokens": [18210, 1230, 732, 337, 264, 960, 307, 570, 286, 393, 380, 8129, 552, 439, 286, 393, 360, 307, 909, 613, 721, 1219, 5632, 293], "temperature": 0.0, "avg_logprob": -0.16822136200226104, "compression_ratio": 1.7883817427385893, "no_speech_prob": 1.2218546544318087e-05}, {"id": 14, "seek": 5792, "start": 74.88, "end": 79.16, "text": " Cards are little things that appear in the top corner the top right hand corner of the screen", "tokens": [383, 2287, 366, 707, 721, 300, 4204, 294, 264, 1192, 4538, 264, 1192, 558, 1011, 4538, 295, 264, 2568], "temperature": 0.0, "avg_logprob": -0.16822136200226104, "compression_ratio": 1.7883817427385893, "no_speech_prob": 1.2218546544318087e-05}, {"id": 15, "seek": 5792, "start": 79.52000000000001, "end": 82.84, "text": " So by the time this video comes out, I'm going to put a little card there right now", "tokens": [407, 538, 264, 565, 341, 960, 1487, 484, 11, 286, 478, 516, 281, 829, 257, 707, 2920, 456, 558, 586], "temperature": 0.0, "avg_logprob": -0.16822136200226104, "compression_ratio": 1.7883817427385893, "no_speech_prob": 1.2218546544318087e-05}, {"id": 16, "seek": 5792, "start": 83.32000000000001, "end": 85.48, "text": " For you to click on and try that out", "tokens": [1171, 291, 281, 2052, 322, 293, 853, 300, 484], "temperature": 0.0, "avg_logprob": -0.16822136200226104, "compression_ratio": 1.7883817427385893, "no_speech_prob": 1.2218546544318087e-05}, {"id": 17, "seek": 8548, "start": 85.48, "end": 92.56, "text": " Unfortunately, they're not easy to notice so keep an eye out for that because that's going to be important updates to the video", "tokens": [8590, 11, 436, 434, 406, 1858, 281, 3449, 370, 1066, 364, 3313, 484, 337, 300, 570, 300, 311, 516, 281, 312, 1021, 9205, 281, 264, 960], "temperature": 0.0, "avg_logprob": -0.19595163695666254, "compression_ratio": 1.6706349206349207, "no_speech_prob": 4.936769983032718e-06}, {"id": 18, "seek": 8548, "start": 92.76, "end": 95.76, "text": " All right, so welcome. We're going to be learning about", "tokens": [1057, 558, 11, 370, 2928, 13, 492, 434, 516, 281, 312, 2539, 466], "temperature": 0.0, "avg_logprob": -0.19595163695666254, "compression_ratio": 1.6706349206349207, "no_speech_prob": 4.936769983032718e-06}, {"id": 19, "seek": 8548, "start": 96.72, "end": 98.72, "text": " machine learning today", "tokens": [3479, 2539, 965], "temperature": 0.0, "avg_logprob": -0.19595163695666254, "compression_ratio": 1.6706349206349207, "no_speech_prob": 4.936769983032718e-06}, {"id": 20, "seek": 8548, "start": 99.56, "end": 104.80000000000001, "text": " And so for everybody in the class here you all have Amazon web services set up", "tokens": [400, 370, 337, 2201, 294, 264, 1508, 510, 291, 439, 362, 6795, 3670, 3328, 992, 493], "temperature": 0.0, "avg_logprob": -0.19595163695666254, "compression_ratio": 1.6706349206349207, "no_speech_prob": 4.936769983032718e-06}, {"id": 21, "seek": 8548, "start": 104.80000000000001, "end": 108.64, "text": " So you might want to go ahead and launch your AWS instance now", "tokens": [407, 291, 1062, 528, 281, 352, 2286, 293, 4025, 428, 17650, 5197, 586], "temperature": 0.0, "avg_logprob": -0.19595163695666254, "compression_ratio": 1.6706349206349207, "no_speech_prob": 4.936769983032718e-06}, {"id": 22, "seek": 8548, "start": 110.12, "end": 114.24000000000001, "text": " Or go ahead and create launch your Jupiter notebook on your own computer", "tokens": [1610, 352, 2286, 293, 1884, 4025, 428, 24567, 21060, 322, 428, 1065, 3820], "temperature": 0.0, "avg_logprob": -0.19595163695666254, "compression_ratio": 1.6706349206349207, "no_speech_prob": 4.936769983032718e-06}, {"id": 23, "seek": 11424, "start": 114.24, "end": 116.24, "text": " if", "tokens": [498], "temperature": 0.0, "avg_logprob": -0.3637868004876214, "compression_ratio": 1.536723163841808, "no_speech_prob": 9.515943020232953e-06}, {"id": 24, "seek": 11424, "start": 116.24, "end": 119.56, "text": " You don't have Jupiter notebook set up", "tokens": [509, 500, 380, 362, 24567, 21060, 992, 493], "temperature": 0.0, "avg_logprob": -0.3637868004876214, "compression_ratio": 1.536723163841808, "no_speech_prob": 9.515943020232953e-06}, {"id": 25, "seek": 11424, "start": 120.16, "end": 123.53999999999999, "text": " Then what I recommend is you go to Cressel comm", "tokens": [1396, 437, 286, 2748, 307, 291, 352, 281, 383, 735, 338, 800], "temperature": 0.0, "avg_logprob": -0.3637868004876214, "compression_ratio": 1.536723163841808, "no_speech_prob": 9.515943020232953e-06}, {"id": 26, "seek": 11424, "start": 124.8, "end": 127.47999999999999, "text": " com sign in there sign up", "tokens": [395, 1465, 294, 456, 1465, 493], "temperature": 0.0, "avg_logprob": -0.3637868004876214, "compression_ratio": 1.536723163841808, "no_speech_prob": 9.515943020232953e-06}, {"id": 27, "seek": 11424, "start": 129.72, "end": 131.48, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.3637868004876214, "compression_ratio": 1.536723163841808, "no_speech_prob": 9.515943020232953e-06}, {"id": 28, "seek": 11424, "start": 131.48, "end": 138.88, "text": " You can then turn off enable GPU and click start Jupiter and you'll have a Jupiter notebook instantly that costs you some money", "tokens": [509, 393, 550, 1261, 766, 9528, 18407, 293, 2052, 722, 24567, 293, 291, 603, 362, 257, 24567, 21060, 13518, 300, 5497, 291, 512, 1460], "temperature": 0.0, "avg_logprob": -0.3637868004876214, "compression_ratio": 1.536723163841808, "no_speech_prob": 9.515943020232953e-06}, {"id": 29, "seek": 11424, "start": 138.88, "end": 140.88, "text": " It's three cents an hour", "tokens": [467, 311, 1045, 14941, 364, 1773], "temperature": 0.0, "avg_logprob": -0.3637868004876214, "compression_ratio": 1.536723163841808, "no_speech_prob": 9.515943020232953e-06}, {"id": 30, "seek": 14088, "start": 140.88, "end": 145.68, "text": " Okay, so if you don't mind spending three cents an hour to learn machine learning. Here's a good way", "tokens": [1033, 11, 370, 498, 291, 500, 380, 1575, 6434, 1045, 14941, 364, 1773, 281, 1466, 3479, 2539, 13, 1692, 311, 257, 665, 636], "temperature": 0.0, "avg_logprob": -0.1357822675962706, "compression_ratio": 1.71280276816609, "no_speech_prob": 2.9943303161417134e-06}, {"id": 31, "seek": 14088, "start": 145.68, "end": 147.68, "text": " So I'm going to go ahead and say start Jupiter", "tokens": [407, 286, 478, 516, 281, 352, 2286, 293, 584, 722, 24567], "temperature": 0.0, "avg_logprob": -0.1357822675962706, "compression_ratio": 1.71280276816609, "no_speech_prob": 2.9943303161417134e-06}, {"id": 32, "seek": 14088, "start": 148.84, "end": 150.84, "text": " And so whatever technique you use", "tokens": [400, 370, 2035, 6532, 291, 764], "temperature": 0.0, "avg_logprob": -0.1357822675962706, "compression_ratio": 1.71280276816609, "no_speech_prob": 2.9943303161417134e-06}, {"id": 33, "seek": 14088, "start": 151.56, "end": 156.6, "text": " There you go one of the things that you'll find on on the website is", "tokens": [821, 291, 352, 472, 295, 264, 721, 300, 291, 603, 915, 322, 322, 264, 3144, 307], "temperature": 0.0, "avg_logprob": -0.1357822675962706, "compression_ratio": 1.71280276816609, "no_speech_prob": 2.9943303161417134e-06}, {"id": 34, "seek": 14088, "start": 156.96, "end": 163.64, "text": " Links to lots of information about the costs and benefits and approaches to setting up lots of different environments for Jupiter notebook", "tokens": [37156, 281, 3195, 295, 1589, 466, 264, 5497, 293, 5311, 293, 11587, 281, 3287, 493, 3195, 295, 819, 12388, 337, 24567, 21060], "temperature": 0.0, "avg_logprob": -0.1357822675962706, "compression_ratio": 1.71280276816609, "no_speech_prob": 2.9943303161417134e-06}, {"id": 35, "seek": 14088, "start": 164.4, "end": 169.48, "text": " Both the deep learning and for regular machine learning so check them out because there's lots of options", "tokens": [6767, 264, 2452, 2539, 293, 337, 3890, 3479, 2539, 370, 1520, 552, 484, 570, 456, 311, 3195, 295, 3956], "temperature": 0.0, "avg_logprob": -0.1357822675962706, "compression_ratio": 1.71280276816609, "no_speech_prob": 2.9943303161417134e-06}, {"id": 36, "seek": 16948, "start": 169.48, "end": 171.48, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.221775467331345, "compression_ratio": 1.4973821989528795, "no_speech_prob": 4.936887307849247e-06}, {"id": 37, "seek": 16948, "start": 172.67999999999998, "end": 175.95999999999998, "text": " If I then go open a Jupiter in open Jupiter in a new tab", "tokens": [759, 286, 550, 352, 1269, 257, 24567, 294, 1269, 24567, 294, 257, 777, 4421], "temperature": 0.0, "avg_logprob": -0.221775467331345, "compression_ratio": 1.4973821989528795, "no_speech_prob": 4.936887307849247e-06}, {"id": 38, "seek": 16948, "start": 178.35999999999999, "end": 183.42, "text": " Here I am in Cressel or on AWS all your own computer", "tokens": [1692, 286, 669, 294, 383, 735, 338, 420, 322, 17650, 439, 428, 1065, 3820], "temperature": 0.0, "avg_logprob": -0.221775467331345, "compression_ratio": 1.4973821989528795, "no_speech_prob": 4.936887307849247e-06}, {"id": 39, "seek": 16948, "start": 183.88, "end": 190.72, "text": " We use the Anaconda Python distribution for basically everything you can install that yourself", "tokens": [492, 764, 264, 1107, 326, 12233, 15329, 7316, 337, 1936, 1203, 291, 393, 3625, 300, 1803], "temperature": 0.0, "avg_logprob": -0.221775467331345, "compression_ratio": 1.4973821989528795, "no_speech_prob": 4.936887307849247e-06}, {"id": 40, "seek": 16948, "start": 191.0, "end": 194.17999999999998, "text": " And again, there's lots of information on the website about how to set that up", "tokens": [400, 797, 11, 456, 311, 3195, 295, 1589, 322, 264, 3144, 466, 577, 281, 992, 300, 493], "temperature": 0.0, "avg_logprob": -0.221775467331345, "compression_ratio": 1.4973821989528795, "no_speech_prob": 4.936887307849247e-06}, {"id": 41, "seek": 19418, "start": 194.18, "end": 198.74, "text": " We're also assuming that either you're using Cressel or", "tokens": [492, 434, 611, 11926, 300, 2139, 291, 434, 1228, 383, 735, 338, 420], "temperature": 0.0, "avg_logprob": -0.3788582483927409, "compression_ratio": 1.790794979079498, "no_speech_prob": 3.5007399219466606e-06}, {"id": 42, "seek": 19418, "start": 199.46, "end": 204.14000000000001, "text": " There's something else which I really like called paper space comm which is another place", "tokens": [821, 311, 746, 1646, 597, 286, 534, 411, 1219, 3035, 1901, 800, 597, 307, 1071, 1081], "temperature": 0.0, "avg_logprob": -0.3788582483927409, "compression_ratio": 1.790794979079498, "no_speech_prob": 3.5007399219466606e-06}, {"id": 43, "seek": 19418, "start": 204.14000000000001, "end": 206.98000000000002, "text": " You can fire up if you put a notebook pretty much instantly", "tokens": [509, 393, 2610, 493, 498, 291, 829, 257, 21060, 1238, 709, 13518], "temperature": 0.0, "avg_logprob": -0.3788582483927409, "compression_ratio": 1.790794979079498, "no_speech_prob": 3.5007399219466606e-06}, {"id": 44, "seek": 19418, "start": 207.5, "end": 209.5, "text": " both of these have", "tokens": [1293, 295, 613, 362], "temperature": 0.0, "avg_logprob": -0.3788582483927409, "compression_ratio": 1.790794979079498, "no_speech_prob": 3.5007399219466606e-06}, {"id": 45, "seek": 19418, "start": 210.54000000000002, "end": 214.34, "text": " Already have all of the fast AI stuff pre-installed for you", "tokens": [23741, 362, 439, 295, 264, 2370, 7318, 1507, 659, 12, 13911, 8907, 337, 291], "temperature": 0.0, "avg_logprob": -0.3788582483927409, "compression_ratio": 1.790794979079498, "no_speech_prob": 3.5007399219466606e-06}, {"id": 46, "seek": 19418, "start": 214.34, "end": 218.98000000000002, "text": " So as soon as you open up Cressel or paper space assuming you chose the paper space fast AI", "tokens": [407, 382, 2321, 382, 291, 1269, 493, 383, 735, 338, 420, 3035, 1901, 11926, 291, 5111, 264, 3035, 1901, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.3788582483927409, "compression_ratio": 1.790794979079498, "no_speech_prob": 3.5007399219466606e-06}, {"id": 47, "seek": 19418, "start": 219.78, "end": 223.06, "text": " Template you'll see that there's a fast AI template", "tokens": [39563, 473, 291, 603, 536, 300, 456, 311, 257, 2370, 7318, 12379], "temperature": 0.0, "avg_logprob": -0.3788582483927409, "compression_ratio": 1.790794979079498, "no_speech_prob": 3.5007399219466606e-06}, {"id": 48, "seek": 22306, "start": 223.06, "end": 225.06, "text": " You'll see that there's a fast AI", "tokens": [509, 603, 536, 300, 456, 311, 257, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.1883525298191951, "compression_ratio": 1.6382978723404256, "no_speech_prob": 1.280502419831464e-05}, {"id": 49, "seek": 22306, "start": 225.18, "end": 229.04, "text": " Folder okay, if you are using your own computer or AWS", "tokens": [24609, 260, 1392, 11, 498, 291, 366, 1228, 428, 1065, 3820, 420, 17650], "temperature": 0.0, "avg_logprob": -0.1883525298191951, "compression_ratio": 1.6382978723404256, "no_speech_prob": 1.280502419831464e-05}, {"id": 50, "seek": 22306, "start": 229.54, "end": 234.26, "text": " You'll need to go to our github repo fast AI fast AI", "tokens": [509, 603, 643, 281, 352, 281, 527, 290, 355, 836, 49040, 2370, 7318, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.1883525298191951, "compression_ratio": 1.6382978723404256, "no_speech_prob": 1.280502419831464e-05}, {"id": 51, "seek": 22306, "start": 234.94, "end": 241.54, "text": " And clone it okay, and then you'll need to do a conda and update to install the libraries", "tokens": [400, 26506, 309, 1392, 11, 293, 550, 291, 603, 643, 281, 360, 257, 2224, 64, 293, 5623, 281, 3625, 264, 15148], "temperature": 0.0, "avg_logprob": -0.1883525298191951, "compression_ratio": 1.6382978723404256, "no_speech_prob": 1.280502419831464e-05}, {"id": 52, "seek": 22306, "start": 242.18, "end": 245.14000000000001, "text": " And again, that's all information we've got on the website", "tokens": [400, 797, 11, 300, 311, 439, 1589, 321, 600, 658, 322, 264, 3144], "temperature": 0.0, "avg_logprob": -0.1883525298191951, "compression_ratio": 1.6382978723404256, "no_speech_prob": 1.280502419831464e-05}, {"id": 53, "seek": 22306, "start": 245.14000000000001, "end": 249.9, "text": " And we've got some previous workshop videos to help you through all of those steps so for this", "tokens": [400, 321, 600, 658, 512, 3894, 13541, 2145, 281, 854, 291, 807, 439, 295, 729, 4439, 370, 337, 341], "temperature": 0.0, "avg_logprob": -0.1883525298191951, "compression_ratio": 1.6382978723404256, "no_speech_prob": 1.280502419831464e-05}, {"id": 54, "seek": 24990, "start": 249.9, "end": 255.66, "text": " Class I'm assuming that you have a jupyter notebook running, okay", "tokens": [9471, 286, 478, 11926, 300, 291, 362, 257, 361, 1010, 88, 391, 21060, 2614, 11, 1392], "temperature": 0.0, "avg_logprob": -0.21716039321001837, "compression_ratio": 1.6162790697674418, "no_speech_prob": 6.747897259629099e-06}, {"id": 55, "seek": 24990, "start": 257.98, "end": 262.22, "text": " So here we are in the in the jupyter notebook and", "tokens": [407, 510, 321, 366, 294, 264, 294, 264, 361, 1010, 88, 391, 21060, 293], "temperature": 0.0, "avg_logprob": -0.21716039321001837, "compression_ratio": 1.6162790697674418, "no_speech_prob": 6.747897259629099e-06}, {"id": 56, "seek": 24990, "start": 262.98, "end": 269.22, "text": " If I click on fast AI, that's what you get if you get clone or if you're on Cressel you can see our", "tokens": [759, 286, 2052, 322, 2370, 7318, 11, 300, 311, 437, 291, 483, 498, 291, 483, 26506, 420, 498, 291, 434, 322, 383, 735, 338, 291, 393, 536, 527], "temperature": 0.0, "avg_logprob": -0.21716039321001837, "compression_ratio": 1.6162790697674418, "no_speech_prob": 6.747897259629099e-06}, {"id": 57, "seek": 24990, "start": 270.06, "end": 271.62, "text": " repo here", "tokens": [49040, 510], "temperature": 0.0, "avg_logprob": -0.21716039321001837, "compression_ratio": 1.6162790697674418, "no_speech_prob": 6.747897259629099e-06}, {"id": 58, "seek": 24990, "start": 271.62, "end": 273.62, "text": " all of our", "tokens": [439, 295, 527], "temperature": 0.0, "avg_logprob": -0.21716039321001837, "compression_ratio": 1.6162790697674418, "no_speech_prob": 6.747897259629099e-06}, {"id": 59, "seek": 24990, "start": 274.78000000000003, "end": 277.7, "text": " Lessons are inside the courses folder and", "tokens": [18649, 892, 366, 1854, 264, 7712, 10820, 293], "temperature": 0.0, "avg_logprob": -0.21716039321001837, "compression_ratio": 1.6162790697674418, "no_speech_prob": 6.747897259629099e-06}, {"id": 60, "seek": 27770, "start": 277.7, "end": 283.38, "text": " The machine learning part one is in the ml1 folder", "tokens": [440, 3479, 2539, 644, 472, 307, 294, 264, 23271, 16, 10820], "temperature": 0.0, "avg_logprob": -0.3033424534209787, "compression_ratio": 1.550561797752809, "no_speech_prob": 5.954996140644653e-06}, {"id": 61, "seek": 27770, "start": 284.42, "end": 290.06, "text": " If you're ever looking at my screen and wondering where are you look up here, and you'll see", "tokens": [759, 291, 434, 1562, 1237, 412, 452, 2568, 293, 6359, 689, 366, 291, 574, 493, 510, 11, 293, 291, 603, 536], "temperature": 0.0, "avg_logprob": -0.3033424534209787, "compression_ratio": 1.550561797752809, "no_speech_prob": 5.954996140644653e-06}, {"id": 62, "seek": 27770, "start": 290.53999999999996, "end": 292.53999999999996, "text": " It tells you the path fast AI", "tokens": [467, 5112, 291, 264, 3100, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.3033424534209787, "compression_ratio": 1.550561797752809, "no_speech_prob": 5.954996140644653e-06}, {"id": 63, "seek": 27770, "start": 293.21999999999997, "end": 295.21999999999997, "text": " courses ml1", "tokens": [7712, 23271, 16], "temperature": 0.0, "avg_logprob": -0.3033424534209787, "compression_ratio": 1.550561797752809, "no_speech_prob": 5.954996140644653e-06}, {"id": 64, "seek": 29522, "start": 295.22, "end": 307.42, "text": " And today we're going to be looking at lesson one random forests, so here is lesson one RF", "tokens": [400, 965, 321, 434, 516, 281, 312, 1237, 412, 6898, 472, 4974, 21700, 11, 370, 510, 307, 6898, 472, 26204], "temperature": 0.0, "avg_logprob": -0.21281993632413904, "compression_ratio": 1.455223880597015, "no_speech_prob": 6.240820312086726e-06}, {"id": 65, "seek": 29522, "start": 315.98, "end": 322.3, "text": " So there's a couple of different ways you can do this both here in person or on the video you can either", "tokens": [407, 456, 311, 257, 1916, 295, 819, 2098, 291, 393, 360, 341, 1293, 510, 294, 954, 420, 322, 264, 960, 291, 393, 2139], "temperature": 0.0, "avg_logprob": -0.21281993632413904, "compression_ratio": 1.455223880597015, "no_speech_prob": 6.240820312086726e-06}, {"id": 66, "seek": 32230, "start": 322.3, "end": 329.42, "text": " Attempt to follow along as you watch or you can just watch and then follow along later with the video", "tokens": [7298, 4543, 281, 1524, 2051, 382, 291, 1159, 420, 291, 393, 445, 1159, 293, 550, 1524, 2051, 1780, 365, 264, 960], "temperature": 0.0, "avg_logprob": -0.14443046345430263, "compression_ratio": 1.6834170854271358, "no_speech_prob": 8.139463716361206e-06}, {"id": 67, "seek": 32230, "start": 330.74, "end": 332.74, "text": " It's up to you", "tokens": [467, 311, 493, 281, 291], "temperature": 0.0, "avg_logprob": -0.14443046345430263, "compression_ratio": 1.6834170854271358, "no_speech_prob": 8.139463716361206e-06}, {"id": 68, "seek": 32230, "start": 332.74, "end": 334.46000000000004, "text": " I would", "tokens": [286, 576], "temperature": 0.0, "avg_logprob": -0.14443046345430263, "compression_ratio": 1.6834170854271358, "no_speech_prob": 8.139463716361206e-06}, {"id": 69, "seek": 32230, "start": 334.46000000000004, "end": 337.34000000000003, "text": " Maybe have a loose recommendation to say", "tokens": [2704, 362, 257, 9612, 11879, 281, 584], "temperature": 0.0, "avg_logprob": -0.14443046345430263, "compression_ratio": 1.6834170854271358, "no_speech_prob": 8.139463716361206e-06}, {"id": 70, "seek": 32230, "start": 338.18, "end": 339.26, "text": " to", "tokens": [281], "temperature": 0.0, "avg_logprob": -0.14443046345430263, "compression_ratio": 1.6834170854271358, "no_speech_prob": 8.139463716361206e-06}, {"id": 71, "seek": 32230, "start": 339.26, "end": 342.90000000000003, "text": " Watch now and follow along with the video later", "tokens": [7277, 586, 293, 1524, 2051, 365, 264, 960, 1780], "temperature": 0.0, "avg_logprob": -0.14443046345430263, "compression_ratio": 1.6834170854271358, "no_speech_prob": 8.139463716361206e-06}, {"id": 72, "seek": 32230, "start": 343.42, "end": 349.98, "text": " Just because it's quite hard to multitask and if you're working on something you might miss a key piece of information", "tokens": [1449, 570, 309, 311, 1596, 1152, 281, 42338, 3863, 293, 498, 291, 434, 1364, 322, 746, 291, 1062, 1713, 257, 2141, 2522, 295, 1589], "temperature": 0.0, "avg_logprob": -0.14443046345430263, "compression_ratio": 1.6834170854271358, "no_speech_prob": 8.139463716361206e-06}, {"id": 73, "seek": 34998, "start": 349.98, "end": 358.06, "text": " Which you're welcome to ask about okay, but if you follow along with the video afterwards, then you can pause stop", "tokens": [3013, 291, 434, 2928, 281, 1029, 466, 1392, 11, 457, 498, 291, 1524, 2051, 365, 264, 960, 10543, 11, 550, 291, 393, 10465, 1590], "temperature": 0.0, "avg_logprob": -0.22144122745679773, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.1842608728329651e-05}, {"id": 74, "seek": 34998, "start": 358.78000000000003, "end": 362.46000000000004, "text": " Experiment and so forth but anyway you can choose either way", "tokens": [37933, 293, 370, 5220, 457, 4033, 291, 393, 2826, 2139, 636], "temperature": 0.0, "avg_logprob": -0.22144122745679773, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.1842608728329651e-05}, {"id": 75, "seek": 34998, "start": 363.34000000000003, "end": 364.78000000000003, "text": " I'm gonna", "tokens": [286, 478, 799], "temperature": 0.0, "avg_logprob": -0.22144122745679773, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.1842608728329651e-05}, {"id": 76, "seek": 34998, "start": 364.78000000000003, "end": 370.40000000000003, "text": " Go view toggle header view toggle toolbar and then full screen it", "tokens": [1037, 1910, 31225, 23117, 1910, 31225, 47715, 293, 550, 1577, 2568, 309], "temperature": 0.0, "avg_logprob": -0.22144122745679773, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.1842608728329651e-05}, {"id": 77, "seek": 34998, "start": 371.18, "end": 373.18, "text": " So to get a bit more space", "tokens": [407, 281, 483, 257, 857, 544, 1901], "temperature": 0.0, "avg_logprob": -0.22144122745679773, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.1842608728329651e-05}, {"id": 78, "seek": 37318, "start": 373.18, "end": 381.54, "text": " So the basic approach we're going to be teaching here tracking here is to", "tokens": [407, 264, 3875, 3109, 321, 434, 516, 281, 312, 4571, 510, 11603, 510, 307, 281], "temperature": 0.0, "avg_logprob": -0.16299276881747776, "compression_ratio": 1.6868131868131868, "no_speech_prob": 9.368231985718012e-06}, {"id": 79, "seek": 37318, "start": 382.46, "end": 385.06, "text": " Get straight into code start building models", "tokens": [3240, 2997, 666, 3089, 722, 2390, 5245], "temperature": 0.0, "avg_logprob": -0.16299276881747776, "compression_ratio": 1.6868131868131868, "no_speech_prob": 9.368231985718012e-06}, {"id": 80, "seek": 37318, "start": 386.94, "end": 390.82, "text": " Not to look at theory we're going to get to all the theory okay", "tokens": [1726, 281, 574, 412, 5261, 321, 434, 516, 281, 483, 281, 439, 264, 5261, 1392], "temperature": 0.0, "avg_logprob": -0.16299276881747776, "compression_ratio": 1.6868131868131868, "no_speech_prob": 9.368231985718012e-06}, {"id": 81, "seek": 37318, "start": 390.82, "end": 397.18, "text": " But at the point where you deeply understand what it's for and at the point that you're able to be an effective practitioner", "tokens": [583, 412, 264, 935, 689, 291, 8760, 1223, 437, 309, 311, 337, 293, 412, 264, 935, 300, 291, 434, 1075, 281, 312, 364, 4942, 32125], "temperature": 0.0, "avg_logprob": -0.16299276881747776, "compression_ratio": 1.6868131868131868, "no_speech_prob": 9.368231985718012e-06}, {"id": 82, "seek": 39718, "start": 397.18, "end": 402.46, "text": " So my hope is that you're going to spend your time focusing on", "tokens": [407, 452, 1454, 307, 300, 291, 434, 516, 281, 3496, 428, 565, 8416, 322], "temperature": 0.0, "avg_logprob": -0.14051791160337387, "compression_ratio": 1.6406926406926408, "no_speech_prob": 7.64636934036389e-06}, {"id": 83, "seek": 39718, "start": 403.3, "end": 408.3, "text": " Experimenting so if you take these notebooks and try different variations of what I show you", "tokens": [37933, 278, 370, 498, 291, 747, 613, 43782, 293, 853, 819, 17840, 295, 437, 286, 855, 291], "temperature": 0.0, "avg_logprob": -0.14051791160337387, "compression_ratio": 1.6406926406926408, "no_speech_prob": 7.64636934036389e-06}, {"id": 84, "seek": 39718, "start": 408.98, "end": 412.62, "text": " Try it with your own data sets the more coding you can do", "tokens": [6526, 309, 365, 428, 1065, 1412, 6352, 264, 544, 17720, 291, 393, 360], "temperature": 0.0, "avg_logprob": -0.14051791160337387, "compression_ratio": 1.6406926406926408, "no_speech_prob": 7.64636934036389e-06}, {"id": 85, "seek": 39718, "start": 413.3, "end": 415.5, "text": " The better the more you'll learn okay", "tokens": [440, 1101, 264, 544, 291, 603, 1466, 1392], "temperature": 0.0, "avg_logprob": -0.14051791160337387, "compression_ratio": 1.6406926406926408, "no_speech_prob": 7.64636934036389e-06}, {"id": 86, "seek": 39718, "start": 415.5, "end": 421.38, "text": " Don't it you know my suggestion or at least all of my students have told me the ones who have gone away and spent time", "tokens": [1468, 380, 309, 291, 458, 452, 16541, 420, 412, 1935, 439, 295, 452, 1731, 362, 1907, 385, 264, 2306, 567, 362, 2780, 1314, 293, 4418, 565], "temperature": 0.0, "avg_logprob": -0.14051791160337387, "compression_ratio": 1.6406926406926408, "no_speech_prob": 7.64636934036389e-06}, {"id": 87, "seek": 39718, "start": 421.38, "end": 422.74, "text": " studying", "tokens": [7601], "temperature": 0.0, "avg_logprob": -0.14051791160337387, "compression_ratio": 1.6406926406926408, "no_speech_prob": 7.64636934036389e-06}, {"id": 88, "seek": 42274, "start": 422.74, "end": 430.5, "text": " Books of theory rather than coding found that they learned less machine learning and that they often tell me they wish that's one more time", "tokens": [33843, 295, 5261, 2831, 813, 17720, 1352, 300, 436, 3264, 1570, 3479, 2539, 293, 300, 436, 2049, 980, 385, 436, 3172, 300, 311, 472, 544, 565], "temperature": 0.0, "avg_logprob": -0.1331779766926723, "compression_ratio": 1.8294573643410852, "no_speech_prob": 1.0129802831215784e-05}, {"id": 89, "seek": 42274, "start": 430.5, "end": 432.5, "text": " coding", "tokens": [17720], "temperature": 0.0, "avg_logprob": -0.1331779766926723, "compression_ratio": 1.8294573643410852, "no_speech_prob": 1.0129802831215784e-05}, {"id": 90, "seek": 42274, "start": 434.5, "end": 439.74, "text": " The stuff that we're showing in this course a lot of it's never been shown before this is not a summary of", "tokens": [440, 1507, 300, 321, 434, 4099, 294, 341, 1164, 257, 688, 295, 309, 311, 1128, 668, 4898, 949, 341, 307, 406, 257, 12691, 295], "temperature": 0.0, "avg_logprob": -0.1331779766926723, "compression_ratio": 1.8294573643410852, "no_speech_prob": 1.0129802831215784e-05}, {"id": 91, "seek": 42274, "start": 440.42, "end": 445.98, "text": " Other people's research. This is more a summary of 25 years of work that I've been doing in machine learning", "tokens": [5358, 561, 311, 2132, 13, 639, 307, 544, 257, 12691, 295, 3552, 924, 295, 589, 300, 286, 600, 668, 884, 294, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.1331779766926723, "compression_ratio": 1.8294573643410852, "no_speech_prob": 1.0129802831215784e-05}, {"id": 92, "seek": 42274, "start": 446.66, "end": 451.78000000000003, "text": " So a lot of this is is going to be shown for the first time and so that's kind of cool because if you want to", "tokens": [407, 257, 688, 295, 341, 307, 307, 516, 281, 312, 4898, 337, 264, 700, 565, 293, 370, 300, 311, 733, 295, 1627, 570, 498, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.1331779766926723, "compression_ratio": 1.8294573643410852, "no_speech_prob": 1.0129802831215784e-05}, {"id": 93, "seek": 45178, "start": 451.78, "end": 458.4, "text": " Write a blog post about something that you learn here. You might be building something that a lot of people find super useful right so", "tokens": [23499, 257, 6968, 2183, 466, 746, 300, 291, 1466, 510, 13, 509, 1062, 312, 2390, 746, 300, 257, 688, 295, 561, 915, 1687, 4420, 558, 370], "temperature": 0.0, "avg_logprob": -0.1631377611973489, "compression_ratio": 1.7889610389610389, "no_speech_prob": 1.8056756744044833e-05}, {"id": 94, "seek": 45178, "start": 459.38, "end": 463.79999999999995, "text": " There's a great opportunity to practice your technical writing and here's some examples of good technical writing", "tokens": [821, 311, 257, 869, 2650, 281, 3124, 428, 6191, 3579, 293, 510, 311, 512, 5110, 295, 665, 6191, 3579], "temperature": 0.0, "avg_logprob": -0.1631377611973489, "compression_ratio": 1.7889610389610389, "no_speech_prob": 1.8056756744044833e-05}, {"id": 95, "seek": 45178, "start": 463.94, "end": 469.17999999999995, "text": " Okay by showing people stuff, but you've it's not like hey. I just learned this thing", "tokens": [1033, 538, 4099, 561, 1507, 11, 457, 291, 600, 309, 311, 406, 411, 4177, 13, 286, 445, 3264, 341, 551], "temperature": 0.0, "avg_logprob": -0.1631377611973489, "compression_ratio": 1.7889610389610389, "no_speech_prob": 1.8056756744044833e-05}, {"id": 96, "seek": 45178, "start": 469.17999999999995, "end": 473.7, "text": " I bet you all know it often it'll be I just learned this thing and I'm going to tell you about it and other people", "tokens": [286, 778, 291, 439, 458, 309, 2049, 309, 603, 312, 286, 445, 3264, 341, 551, 293, 286, 478, 516, 281, 980, 291, 466, 309, 293, 661, 561], "temperature": 0.0, "avg_logprob": -0.1631377611973489, "compression_ratio": 1.7889610389610389, "no_speech_prob": 1.8056756744044833e-05}, {"id": 97, "seek": 45178, "start": 473.7, "end": 475.7, "text": " Haven't seen it in fact", "tokens": [23770, 380, 1612, 309, 294, 1186], "temperature": 0.0, "avg_logprob": -0.1631377611973489, "compression_ratio": 1.7889610389610389, "no_speech_prob": 1.8056756744044833e-05}, {"id": 98, "seek": 45178, "start": 475.7, "end": 480.73999999999995, "text": " This is the first course ever that's been built on top of the fast AI library", "tokens": [639, 307, 264, 700, 1164, 1562, 300, 311, 668, 3094, 322, 1192, 295, 264, 2370, 7318, 6405], "temperature": 0.0, "avg_logprob": -0.1631377611973489, "compression_ratio": 1.7889610389610389, "no_speech_prob": 1.8056756744044833e-05}, {"id": 99, "seek": 48074, "start": 480.74, "end": 484.22, "text": " So even just stuff in the library is going to be new to like everybody", "tokens": [407, 754, 445, 1507, 294, 264, 6405, 307, 516, 281, 312, 777, 281, 411, 2201], "temperature": 0.0, "avg_logprob": -0.15763579805692038, "compression_ratio": 1.7206477732793521, "no_speech_prob": 4.637837264453992e-06}, {"id": 100, "seek": 48074, "start": 486.26, "end": 490.86, "text": " Okay, so when we use a Jupiter notebook or anything else in Python we have to", "tokens": [1033, 11, 370, 562, 321, 764, 257, 24567, 21060, 420, 1340, 1646, 294, 15329, 321, 362, 281], "temperature": 0.0, "avg_logprob": -0.15763579805692038, "compression_ratio": 1.7206477732793521, "no_speech_prob": 4.637837264453992e-06}, {"id": 101, "seek": 48074, "start": 491.5, "end": 494.24, "text": " Import the the libraries that we're going to use", "tokens": [26391, 264, 264, 15148, 300, 321, 434, 516, 281, 764], "temperature": 0.0, "avg_logprob": -0.15763579805692038, "compression_ratio": 1.7206477732793521, "no_speech_prob": 4.637837264453992e-06}, {"id": 102, "seek": 48074, "start": 496.38, "end": 501.5, "text": " Something that's quite convenient is if you use these two auto reload commands at the top of your notebook", "tokens": [6595, 300, 311, 1596, 10851, 307, 498, 291, 764, 613, 732, 8399, 25628, 16901, 412, 264, 1192, 295, 428, 21060], "temperature": 0.0, "avg_logprob": -0.15763579805692038, "compression_ratio": 1.7206477732793521, "no_speech_prob": 4.637837264453992e-06}, {"id": 103, "seek": 48074, "start": 501.7, "end": 509.26, "text": " You can go in and edit the source code of the modules and your notebook will automatically update with those new modules", "tokens": [509, 393, 352, 294, 293, 8129, 264, 4009, 3089, 295, 264, 16679, 293, 428, 21060, 486, 6772, 5623, 365, 729, 777, 16679], "temperature": 0.0, "avg_logprob": -0.15763579805692038, "compression_ratio": 1.7206477732793521, "no_speech_prob": 4.637837264453992e-06}, {"id": 104, "seek": 50926, "start": 509.26, "end": 511.5, "text": " You won't have to like restart anything so that's super handy", "tokens": [509, 1582, 380, 362, 281, 411, 21022, 1340, 370, 300, 311, 1687, 13239], "temperature": 0.0, "avg_logprob": -0.19986590472134677, "compression_ratio": 1.6224066390041494, "no_speech_prob": 1.0845076303667156e-06}, {"id": 105, "seek": 50926, "start": 512.3, "end": 517.9, "text": " Then to show your plots inside the notebook you'll want map plot inline so these three lines", "tokens": [1396, 281, 855, 428, 28609, 1854, 264, 21060, 291, 603, 528, 4471, 7542, 294, 1889, 370, 613, 1045, 3876], "temperature": 0.0, "avg_logprob": -0.19986590472134677, "compression_ratio": 1.6224066390041494, "no_speech_prob": 1.0845076303667156e-06}, {"id": 106, "seek": 50926, "start": 518.38, "end": 520.54, "text": " Appear at the top of all of my notebooks", "tokens": [3132, 14881, 412, 264, 1192, 295, 439, 295, 452, 43782], "temperature": 0.0, "avg_logprob": -0.19986590472134677, "compression_ratio": 1.6224066390041494, "no_speech_prob": 1.0845076303667156e-06}, {"id": 107, "seek": 50926, "start": 523.74, "end": 529.34, "text": " You'll notice when I import the libraries that for anybody here who is a experienced Python programmer", "tokens": [509, 603, 3449, 562, 286, 974, 264, 15148, 300, 337, 4472, 510, 567, 307, 257, 6751, 15329, 32116], "temperature": 0.0, "avg_logprob": -0.19986590472134677, "compression_ratio": 1.6224066390041494, "no_speech_prob": 1.0845076303667156e-06}, {"id": 108, "seek": 50926, "start": 529.34, "end": 535.06, "text": " I am doing something that would be widely considered very inappropriate. I'm importing start", "tokens": [286, 669, 884, 746, 300, 576, 312, 13371, 4888, 588, 26723, 13, 286, 478, 43866, 722], "temperature": 0.0, "avg_logprob": -0.19986590472134677, "compression_ratio": 1.6224066390041494, "no_speech_prob": 1.0845076303667156e-06}, {"id": 109, "seek": 53506, "start": 535.06, "end": 541.8599999999999, "text": " Okay, generally speaking in software engineering. We're taught to like specifically figure out what we need and import those things", "tokens": [1033, 11, 5101, 4124, 294, 4722, 7043, 13, 492, 434, 5928, 281, 411, 4682, 2573, 484, 437, 321, 643, 293, 974, 729, 721], "temperature": 0.0, "avg_logprob": -0.15794607003529867, "compression_ratio": 1.5833333333333333, "no_speech_prob": 2.2959065972827375e-06}, {"id": 110, "seek": 53506, "start": 545.2199999999999, "end": 550.1199999999999, "text": " The more experienced you are as a Python programmer the more extremely offensive practices", "tokens": [440, 544, 6751, 291, 366, 382, 257, 15329, 32116, 264, 544, 4664, 15710, 7525], "temperature": 0.0, "avg_logprob": -0.15794607003529867, "compression_ratio": 1.5833333333333333, "no_speech_prob": 2.2959065972827375e-06}, {"id": 111, "seek": 53506, "start": 550.1199999999999, "end": 553.38, "text": " You're going to see me use for example. I don't follow. What's called perp 8", "tokens": [509, 434, 516, 281, 536, 385, 764, 337, 1365, 13, 286, 500, 380, 1524, 13, 708, 311, 1219, 680, 79, 1649], "temperature": 0.0, "avg_logprob": -0.15794607003529867, "compression_ratio": 1.5833333333333333, "no_speech_prob": 2.2959065972827375e-06}, {"id": 112, "seek": 53506, "start": 553.38, "end": 558.18, "text": " Which is the normal style method style of code used in Python?", "tokens": [3013, 307, 264, 2710, 3758, 3170, 3758, 295, 3089, 1143, 294, 15329, 30], "temperature": 0.0, "avg_logprob": -0.15794607003529867, "compression_ratio": 1.5833333333333333, "no_speech_prob": 2.2959065972827375e-06}, {"id": 113, "seek": 53506, "start": 559.26, "end": 561.3, "text": " So I'm going to mention a couple of the things first is", "tokens": [407, 286, 478, 516, 281, 2152, 257, 1916, 295, 264, 721, 700, 307], "temperature": 0.0, "avg_logprob": -0.15794607003529867, "compression_ratio": 1.5833333333333333, "no_speech_prob": 2.2959065972827375e-06}, {"id": 114, "seek": 56130, "start": 561.3, "end": 567.14, "text": " Go along with it for a while. Don't judge me just yet right there's reasons that I do these things", "tokens": [1037, 2051, 365, 309, 337, 257, 1339, 13, 1468, 380, 6995, 385, 445, 1939, 558, 456, 311, 4112, 300, 286, 360, 613, 721], "temperature": 0.0, "avg_logprob": -0.18961913630647478, "compression_ratio": 1.7734375, "no_speech_prob": 3.4465608678146964e-06}, {"id": 115, "seek": 56130, "start": 567.9399999999999, "end": 572.42, "text": " And if it really bothers you then feel free to change it right, but the basic idea is", "tokens": [400, 498, 309, 534, 33980, 291, 550, 841, 1737, 281, 1319, 309, 558, 11, 457, 264, 3875, 1558, 307], "temperature": 0.0, "avg_logprob": -0.18961913630647478, "compression_ratio": 1.7734375, "no_speech_prob": 3.4465608678146964e-06}, {"id": 116, "seek": 56130, "start": 573.0999999999999, "end": 579.66, "text": " Data science is not software engineering right there's a lot of overlap. You know we're using the same languages", "tokens": [11888, 3497, 307, 406, 4722, 7043, 558, 456, 311, 257, 688, 295, 19959, 13, 509, 458, 321, 434, 1228, 264, 912, 8650], "temperature": 0.0, "avg_logprob": -0.18961913630647478, "compression_ratio": 1.7734375, "no_speech_prob": 3.4465608678146964e-06}, {"id": 117, "seek": 56130, "start": 580.0999999999999, "end": 582.6999999999999, "text": " And in the end these things will may become", "tokens": [400, 294, 264, 917, 613, 721, 486, 815, 1813], "temperature": 0.0, "avg_logprob": -0.18961913630647478, "compression_ratio": 1.7734375, "no_speech_prob": 3.4465608678146964e-06}, {"id": 118, "seek": 56130, "start": 584.14, "end": 590.18, "text": " Software engineering projects, but what we're doing right now is we're prototyping models and prototyping models", "tokens": [27428, 7043, 4455, 11, 457, 437, 321, 434, 884, 558, 586, 307, 321, 434, 46219, 3381, 5245, 293, 46219, 3381, 5245], "temperature": 0.0, "avg_logprob": -0.18961913630647478, "compression_ratio": 1.7734375, "no_speech_prob": 3.4465608678146964e-06}, {"id": 119, "seek": 59018, "start": 590.18, "end": 595.6999999999999, "text": " Has a very different set of best practices that are taught basically nowhere right?", "tokens": [8646, 257, 588, 819, 992, 295, 1151, 7525, 300, 366, 5928, 1936, 11159, 558, 30], "temperature": 0.0, "avg_logprob": -0.14924191012240873, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.2679215615207795e-06}, {"id": 120, "seek": 59018, "start": 595.6999999999999, "end": 597.6999999999999, "text": " They're not really even really written down", "tokens": [814, 434, 406, 534, 754, 534, 3720, 760], "temperature": 0.0, "avg_logprob": -0.14924191012240873, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.2679215615207795e-06}, {"id": 121, "seek": 59018, "start": 597.78, "end": 604.3, "text": " But the key is to be able to do things very interactively and very iteratively right so for example", "tokens": [583, 264, 2141, 307, 281, 312, 1075, 281, 360, 721, 588, 4648, 3413, 293, 588, 17138, 19020, 558, 370, 337, 1365], "temperature": 0.0, "avg_logprob": -0.14924191012240873, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.2679215615207795e-06}, {"id": 122, "seek": 59018, "start": 604.8199999999999, "end": 611.0799999999999, "text": " From library import star means you don't have to figure out ahead of time what you're going to need from that library", "tokens": [3358, 6405, 974, 3543, 1355, 291, 500, 380, 362, 281, 2573, 484, 2286, 295, 565, 437, 291, 434, 516, 281, 643, 490, 300, 6405], "temperature": 0.0, "avg_logprob": -0.14924191012240873, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.2679215615207795e-06}, {"id": 123, "seek": 59018, "start": 611.0799999999999, "end": 613.0799999999999, "text": " It's it's all there okay", "tokens": [467, 311, 309, 311, 439, 456, 1392], "temperature": 0.0, "avg_logprob": -0.14924191012240873, "compression_ratio": 1.6605166051660516, "no_speech_prob": 1.2679215615207795e-06}, {"id": 124, "seek": 61308, "start": 613.08, "end": 620.48, "text": " Also because we're in this wonderful interactive Jupiter environment it lets us understand", "tokens": [2743, 570, 321, 434, 294, 341, 3715, 15141, 24567, 2823, 309, 6653, 505, 1223], "temperature": 0.0, "avg_logprob": -0.22673287552394225, "compression_ratio": 1.6115702479338843, "no_speech_prob": 4.2892856981779914e-06}, {"id": 125, "seek": 61308, "start": 621.64, "end": 625.5200000000001, "text": " What's in the libraries really well so for example later on?", "tokens": [708, 311, 294, 264, 15148, 534, 731, 370, 337, 1365, 1780, 322, 30], "temperature": 0.0, "avg_logprob": -0.22673287552394225, "compression_ratio": 1.6115702479338843, "no_speech_prob": 4.2892856981779914e-06}, {"id": 126, "seek": 61308, "start": 627.44, "end": 632.5600000000001, "text": " I'm using a function called display right so an obvious question is like well", "tokens": [286, 478, 1228, 257, 2445, 1219, 4674, 558, 370, 364, 6322, 1168, 307, 411, 731], "temperature": 0.0, "avg_logprob": -0.22673287552394225, "compression_ratio": 1.6115702479338843, "no_speech_prob": 4.2892856981779914e-06}, {"id": 127, "seek": 61308, "start": 632.5600000000001, "end": 636.0400000000001, "text": " What is display so you can just type the name of a function and?", "tokens": [708, 307, 4674, 370, 291, 393, 445, 2010, 264, 1315, 295, 257, 2445, 293, 30], "temperature": 0.0, "avg_logprob": -0.22673287552394225, "compression_ratio": 1.6115702479338843, "no_speech_prob": 4.2892856981779914e-06}, {"id": 128, "seek": 63604, "start": 636.04, "end": 642.68, "text": " Press shift enter remember shift enter is is to run a cell and it will tell you where it's from", "tokens": [6776, 5513, 3242, 1604, 5513, 3242, 307, 307, 281, 1190, 257, 2815, 293, 309, 486, 980, 291, 689, 309, 311, 490], "temperature": 0.0, "avg_logprob": -0.19461615492657916, "compression_ratio": 1.643979057591623, "no_speech_prob": 6.339104857033817e-06}, {"id": 129, "seek": 63604, "start": 643.0799999999999, "end": 646.92, "text": " Right so anytime you see a function you're not familiar with you can find out", "tokens": [1779, 370, 13038, 291, 536, 257, 2445, 291, 434, 406, 4963, 365, 291, 393, 915, 484], "temperature": 0.0, "avg_logprob": -0.19461615492657916, "compression_ratio": 1.643979057591623, "no_speech_prob": 6.339104857033817e-06}, {"id": 130, "seek": 63604, "start": 647.48, "end": 651.9, "text": " Where it's from and then if you want to find out what it does", "tokens": [2305, 309, 311, 490, 293, 550, 498, 291, 528, 281, 915, 484, 437, 309, 775], "temperature": 0.0, "avg_logprob": -0.19461615492657916, "compression_ratio": 1.643979057591623, "no_speech_prob": 6.339104857033817e-06}, {"id": 131, "seek": 63604, "start": 652.8399999999999, "end": 654.8399999999999, "text": " Put a question mark at the start", "tokens": [4935, 257, 1168, 1491, 412, 264, 722], "temperature": 0.0, "avg_logprob": -0.19461615492657916, "compression_ratio": 1.643979057591623, "no_speech_prob": 6.339104857033817e-06}, {"id": 132, "seek": 63604, "start": 656.8399999999999, "end": 658.52, "text": " Okay, and", "tokens": [1033, 11, 293], "temperature": 0.0, "avg_logprob": -0.19461615492657916, "compression_ratio": 1.643979057591623, "no_speech_prob": 6.339104857033817e-06}, {"id": 133, "seek": 63604, "start": 658.52, "end": 660.68, "text": " here you have the documentation and", "tokens": [510, 291, 362, 264, 14333, 293], "temperature": 0.0, "avg_logprob": -0.19461615492657916, "compression_ratio": 1.643979057591623, "no_speech_prob": 6.339104857033817e-06}, {"id": 134, "seek": 66068, "start": 660.68, "end": 666.8199999999999, "text": " Then particularly helpful for the fast AI library so the fast AI library I try to make as many", "tokens": [1396, 4098, 4961, 337, 264, 2370, 7318, 6405, 370, 264, 2370, 7318, 6405, 286, 853, 281, 652, 382, 867], "temperature": 0.0, "avg_logprob": -0.15980277890744415, "compression_ratio": 1.7063829787234042, "no_speech_prob": 2.2603103388973977e-06}, {"id": 135, "seek": 66068, "start": 667.4399999999999, "end": 671.02, "text": " Functions as possible be like no more than about five lines of code", "tokens": [11166, 3916, 382, 1944, 312, 411, 572, 544, 813, 466, 1732, 3876, 295, 3089], "temperature": 0.0, "avg_logprob": -0.15980277890744415, "compression_ratio": 1.7063829787234042, "no_speech_prob": 2.2603103388973977e-06}, {"id": 136, "seek": 66068, "start": 671.02, "end": 676.1999999999999, "text": " It's designed to be really easy to read right if you put a second question mark at the start", "tokens": [467, 311, 4761, 281, 312, 534, 1858, 281, 1401, 558, 498, 291, 829, 257, 1150, 1168, 1491, 412, 264, 722], "temperature": 0.0, "avg_logprob": -0.15980277890744415, "compression_ratio": 1.7063829787234042, "no_speech_prob": 2.2603103388973977e-06}, {"id": 137, "seek": 66068, "start": 678.28, "end": 682.04, "text": " It shows you the source code of the function", "tokens": [467, 3110, 291, 264, 4009, 3089, 295, 264, 2445], "temperature": 0.0, "avg_logprob": -0.15980277890744415, "compression_ratio": 1.7063829787234042, "no_speech_prob": 2.2603103388973977e-06}, {"id": 138, "seek": 68204, "start": 682.04, "end": 690.48, "text": " Right so all the documentation plus the source code so you can see like nothing has to be mysterious and", "tokens": [1779, 370, 439, 264, 14333, 1804, 264, 4009, 3089, 370, 291, 393, 536, 411, 1825, 575, 281, 312, 13831, 293], "temperature": 0.0, "avg_logprob": -0.14216960242035193, "compression_ratio": 1.7519685039370079, "no_speech_prob": 3.844897491944721e-06}, {"id": 139, "seek": 68204, "start": 691.16, "end": 694.36, "text": " We're going to be using the other library. We'll use a lot is scikit-learn", "tokens": [492, 434, 516, 281, 312, 1228, 264, 661, 6405, 13, 492, 603, 764, 257, 688, 307, 2180, 22681, 12, 306, 1083], "temperature": 0.0, "avg_logprob": -0.14216960242035193, "compression_ratio": 1.7519685039370079, "no_speech_prob": 3.844897491944721e-06}, {"id": 140, "seek": 68204, "start": 695.0799999999999, "end": 700.8, "text": " Which is kind of implements a lot of machine learning stuff in Python the scikit-learn", "tokens": [3013, 307, 733, 295, 704, 17988, 257, 688, 295, 3479, 2539, 1507, 294, 15329, 264, 2180, 22681, 12, 306, 1083], "temperature": 0.0, "avg_logprob": -0.14216960242035193, "compression_ratio": 1.7519685039370079, "no_speech_prob": 3.844897491944721e-06}, {"id": 141, "seek": 68204, "start": 701.9599999999999, "end": 706.5999999999999, "text": " Source code is often pretty readable and so very often if I want to really understand something", "tokens": [29629, 3089, 307, 2049, 1238, 49857, 293, 370, 588, 2049, 498, 286, 528, 281, 534, 1223, 746], "temperature": 0.0, "avg_logprob": -0.14216960242035193, "compression_ratio": 1.7519685039370079, "no_speech_prob": 3.844897491944721e-06}, {"id": 142, "seek": 68204, "start": 706.5999999999999, "end": 710.5799999999999, "text": " I'll just go question mark question mark and the name of the scikit-learn function", "tokens": [286, 603, 445, 352, 1168, 1491, 1168, 1491, 293, 264, 1315, 295, 264, 2180, 22681, 12, 306, 1083, 2445], "temperature": 0.0, "avg_logprob": -0.14216960242035193, "compression_ratio": 1.7519685039370079, "no_speech_prob": 3.844897491944721e-06}, {"id": 143, "seek": 71058, "start": 710.58, "end": 712.58, "text": " I'm typing and I'll just go ahead and read the source code", "tokens": [286, 478, 18444, 293, 286, 603, 445, 352, 2286, 293, 1401, 264, 4009, 3089], "temperature": 0.0, "avg_logprob": -0.15228336025970152, "compression_ratio": 1.6607929515418502, "no_speech_prob": 2.902293999795802e-06}, {"id": 144, "seek": 71058, "start": 714.32, "end": 719.88, "text": " As I say the fast AI library in particular is designed to have source code", "tokens": [1018, 286, 584, 264, 2370, 7318, 6405, 294, 1729, 307, 4761, 281, 362, 4009, 3089], "temperature": 0.0, "avg_logprob": -0.15228336025970152, "compression_ratio": 1.6607929515418502, "no_speech_prob": 2.902293999795802e-06}, {"id": 145, "seek": 71058, "start": 719.88, "end": 722.2, "text": " That's very easy to read and we're going to be reading it a lot", "tokens": [663, 311, 588, 1858, 281, 1401, 293, 321, 434, 516, 281, 312, 3760, 309, 257, 688], "temperature": 0.0, "avg_logprob": -0.15228336025970152, "compression_ratio": 1.6607929515418502, "no_speech_prob": 2.902293999795802e-06}, {"id": 146, "seek": 71058, "start": 726.32, "end": 731.6, "text": " All right, so today we're going to be working on a Kaggle competition called blue book for bulldozers", "tokens": [1057, 558, 11, 370, 965, 321, 434, 516, 281, 312, 1364, 322, 257, 48751, 22631, 6211, 1219, 3344, 1446, 337, 4693, 2595, 41698], "temperature": 0.0, "avg_logprob": -0.15228336025970152, "compression_ratio": 1.6607929515418502, "no_speech_prob": 2.902293999795802e-06}, {"id": 147, "seek": 73160, "start": 731.6, "end": 742.82, "text": " So the first thing we need is to get that data so if you go Kaggle bulldozers then you can find it", "tokens": [407, 264, 700, 551, 321, 643, 307, 281, 483, 300, 1412, 370, 498, 291, 352, 48751, 22631, 4693, 2595, 41698, 550, 291, 393, 915, 309], "temperature": 0.0, "avg_logprob": -0.2102998940341444, "compression_ratio": 1.751219512195122, "no_speech_prob": 3.041578111151466e-06}, {"id": 148, "seek": 73160, "start": 744.12, "end": 745.66, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.2102998940341444, "compression_ratio": 1.751219512195122, "no_speech_prob": 3.041578111151466e-06}, {"id": 149, "seek": 73160, "start": 745.66, "end": 749.16, "text": " Kaggle competitions allow you to download a", "tokens": [48751, 22631, 26185, 2089, 291, 281, 5484, 257], "temperature": 0.0, "avg_logprob": -0.2102998940341444, "compression_ratio": 1.751219512195122, "no_speech_prob": 3.041578111151466e-06}, {"id": 150, "seek": 73160, "start": 749.64, "end": 754.2, "text": " real world data set that somebody a real problem that somebody's trying to solve and", "tokens": [957, 1002, 1412, 992, 300, 2618, 257, 957, 1154, 300, 2618, 311, 1382, 281, 5039, 293], "temperature": 0.0, "avg_logprob": -0.2102998940341444, "compression_ratio": 1.751219512195122, "no_speech_prob": 3.041578111151466e-06}, {"id": 151, "seek": 75420, "start": 754.2, "end": 761.96, "text": " Solve it according to a specification that that actual person with that actual problem decided would be actually helpful to them, right?", "tokens": [7026, 303, 309, 4650, 281, 257, 31256, 300, 300, 3539, 954, 365, 300, 3539, 1154, 3047, 576, 312, 767, 4961, 281, 552, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14920967881397534, "compression_ratio": 1.6030534351145038, "no_speech_prob": 4.860376975557301e-06}, {"id": 152, "seek": 75420, "start": 761.96, "end": 763.96, "text": " So these are pretty authentic", "tokens": [407, 613, 366, 1238, 12466], "temperature": 0.0, "avg_logprob": -0.14920967881397534, "compression_ratio": 1.6030534351145038, "no_speech_prob": 4.860376975557301e-06}, {"id": 153, "seek": 75420, "start": 765.44, "end": 773.4000000000001, "text": " Experiences for applied machine learning now, of course, you're missing all the bit that went before which was why did this company to start up?", "tokens": [12522, 14004, 337, 6456, 3479, 2539, 586, 11, 295, 1164, 11, 291, 434, 5361, 439, 264, 857, 300, 1437, 949, 597, 390, 983, 630, 341, 2237, 281, 722, 493, 30], "temperature": 0.0, "avg_logprob": -0.14920967881397534, "compression_ratio": 1.6030534351145038, "no_speech_prob": 4.860376975557301e-06}, {"id": 154, "seek": 75420, "start": 773.9200000000001, "end": 779.6800000000001, "text": " Decide that predicting the auction sale price of bulldozers was important. Where did they get the data from?", "tokens": [12427, 482, 300, 32884, 264, 24139, 8680, 3218, 295, 4693, 2595, 41698, 390, 1021, 13, 2305, 630, 436, 483, 264, 1412, 490, 30], "temperature": 0.0, "avg_logprob": -0.14920967881397534, "compression_ratio": 1.6030534351145038, "no_speech_prob": 4.860376975557301e-06}, {"id": 155, "seek": 77968, "start": 779.68, "end": 785.0799999999999, "text": " How did they clean the data and so forth? Okay, and that's all important stuff as well", "tokens": [1012, 630, 436, 2541, 264, 1412, 293, 370, 5220, 30, 1033, 11, 293, 300, 311, 439, 1021, 1507, 382, 731], "temperature": 0.0, "avg_logprob": -0.13335736592610678, "compression_ratio": 1.7692307692307692, "no_speech_prob": 6.747910447302274e-06}, {"id": 156, "seek": 77968, "start": 785.4399999999999, "end": 790.92, "text": " But the focus of this course is really on what happens next which is like how do you actually build the model?", "tokens": [583, 264, 1879, 295, 341, 1164, 307, 534, 322, 437, 2314, 958, 597, 307, 411, 577, 360, 291, 767, 1322, 264, 2316, 30], "temperature": 0.0, "avg_logprob": -0.13335736592610678, "compression_ratio": 1.7692307692307692, "no_speech_prob": 6.747910447302274e-06}, {"id": 157, "seek": 77968, "start": 792.04, "end": 795.1999999999999, "text": " One of the great things about you working on Kaggle competitions", "tokens": [1485, 295, 264, 869, 721, 466, 291, 1364, 322, 48751, 22631, 26185], "temperature": 0.0, "avg_logprob": -0.13335736592610678, "compression_ratio": 1.7692307692307692, "no_speech_prob": 6.747910447302274e-06}, {"id": 158, "seek": 77968, "start": 795.1999999999999, "end": 800.5999999999999, "text": " Whether they be running now or whether they be old ones is that you can submit yours to the leaderboard", "tokens": [8503, 436, 312, 2614, 586, 420, 1968, 436, 312, 1331, 2306, 307, 300, 291, 393, 10315, 6342, 281, 264, 5263, 3787], "temperature": 0.0, "avg_logprob": -0.13335736592610678, "compression_ratio": 1.7692307692307692, "no_speech_prob": 6.747910447302274e-06}, {"id": 159, "seek": 77968, "start": 800.8, "end": 805.28, "text": " Even old closed competitions you can submit to the leaderboard and find out how would you have gone?", "tokens": [2754, 1331, 5395, 26185, 291, 393, 10315, 281, 264, 5263, 3787, 293, 915, 484, 577, 576, 291, 362, 2780, 30], "temperature": 0.0, "avg_logprob": -0.13335736592610678, "compression_ratio": 1.7692307692307692, "no_speech_prob": 6.747910447302274e-06}, {"id": 160, "seek": 77968, "start": 805.4399999999999, "end": 808.4399999999999, "text": " Right and there's really no other way in the world of knowing", "tokens": [1779, 293, 456, 311, 534, 572, 661, 636, 294, 264, 1002, 295, 5276], "temperature": 0.0, "avg_logprob": -0.13335736592610678, "compression_ratio": 1.7692307692307692, "no_speech_prob": 6.747910447302274e-06}, {"id": 161, "seek": 80844, "start": 808.44, "end": 810.44, "text": " whether you're", "tokens": [1968, 291, 434], "temperature": 0.0, "avg_logprob": -0.24283573844216086, "compression_ratio": 1.6507177033492824, "no_speech_prob": 1.568924380990211e-05}, {"id": 162, "seek": 80844, "start": 811.08, "end": 815.96, "text": " Competent at this kind of data in this kind of model than doing that right because otherwise", "tokens": [32216, 317, 412, 341, 733, 295, 1412, 294, 341, 733, 295, 2316, 813, 884, 300, 558, 570, 5911], "temperature": 0.0, "avg_logprob": -0.24283573844216086, "compression_ratio": 1.6507177033492824, "no_speech_prob": 1.568924380990211e-05}, {"id": 163, "seek": 80844, "start": 816.6400000000001, "end": 822.9200000000001, "text": " If your accuracy is really bad, is it because this is just very hard like it's just not possible than the the the", "tokens": [759, 428, 14170, 307, 534, 1578, 11, 307, 309, 570, 341, 307, 445, 588, 1152, 411, 309, 311, 445, 406, 1944, 813, 264, 264, 264], "temperature": 0.0, "avg_logprob": -0.24283573844216086, "compression_ratio": 1.6507177033492824, "no_speech_prob": 1.568924380990211e-05}, {"id": 164, "seek": 80844, "start": 823.5200000000001, "end": 831.9200000000001, "text": " Data is so noisy. You can't do better or is it actually that it's an easy data set and you made a mistake and like", "tokens": [11888, 307, 370, 24518, 13, 509, 393, 380, 360, 1101, 420, 307, 309, 767, 300, 309, 311, 364, 1858, 1412, 992, 293, 291, 1027, 257, 6146, 293, 411], "temperature": 0.0, "avg_logprob": -0.24283573844216086, "compression_ratio": 1.6507177033492824, "no_speech_prob": 1.568924380990211e-05}, {"id": 165, "seek": 80844, "start": 832.84, "end": 834.6800000000001, "text": " when you", "tokens": [562, 291], "temperature": 0.0, "avg_logprob": -0.24283573844216086, "compression_ratio": 1.6507177033492824, "no_speech_prob": 1.568924380990211e-05}, {"id": 166, "seek": 83468, "start": 834.68, "end": 840.0, "text": " Finish this course and apply this to your own projects. This is going to be something you're going to find very hard", "tokens": [31583, 341, 1164, 293, 3079, 341, 281, 428, 1065, 4455, 13, 639, 307, 516, 281, 312, 746, 291, 434, 516, 281, 915, 588, 1152], "temperature": 0.0, "avg_logprob": -0.12327854912560265, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.769370667010662e-06}, {"id": 167, "seek": 83468, "start": 840.0, "end": 843.54, "text": " and there isn't a simple solution to it, which is", "tokens": [293, 456, 1943, 380, 257, 2199, 3827, 281, 309, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.12327854912560265, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.769370667010662e-06}, {"id": 168, "seek": 83468, "start": 844.3599999999999, "end": 847.92, "text": " You're now using something that hasn't been on Kaggle. It's your own data set", "tokens": [509, 434, 586, 1228, 746, 300, 6132, 380, 668, 322, 48751, 22631, 13, 467, 311, 428, 1065, 1412, 992], "temperature": 0.0, "avg_logprob": -0.12327854912560265, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.769370667010662e-06}, {"id": 169, "seek": 83468, "start": 848.4799999999999, "end": 854.3199999999999, "text": " Do you have a good enough answer or not? Okay, so we'll talk about that more during the course", "tokens": [1144, 291, 362, 257, 665, 1547, 1867, 420, 406, 30, 1033, 11, 370, 321, 603, 751, 466, 300, 544, 1830, 264, 1164], "temperature": 0.0, "avg_logprob": -0.12327854912560265, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.769370667010662e-06}, {"id": 170, "seek": 83468, "start": 855.12, "end": 856.1999999999999, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.12327854912560265, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.769370667010662e-06}, {"id": 171, "seek": 83468, "start": 856.1999999999999, "end": 857.64, "text": " in the end", "tokens": [294, 264, 917], "temperature": 0.0, "avg_logprob": -0.12327854912560265, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.769370667010662e-06}, {"id": 172, "seek": 85764, "start": 857.64, "end": 865.56, "text": " We just have to know that we have good effective techniques reliably building baseline models otherwise", "tokens": [492, 445, 362, 281, 458, 300, 321, 362, 665, 4942, 7512, 49927, 2390, 20518, 5245, 5911], "temperature": 0.0, "avg_logprob": -0.20800111808028876, "compression_ratio": 1.791044776119403, "no_speech_prob": 1.3006412700633518e-05}, {"id": 173, "seek": 85764, "start": 865.88, "end": 869.72, "text": " Yeah, there's really no way to know there's no way other than creating a Kaggle competition", "tokens": [865, 11, 456, 311, 534, 572, 636, 281, 458, 456, 311, 572, 636, 661, 813, 4084, 257, 48751, 22631, 6211], "temperature": 0.0, "avg_logprob": -0.20800111808028876, "compression_ratio": 1.791044776119403, "no_speech_prob": 1.3006412700633518e-05}, {"id": 174, "seek": 85764, "start": 870.52, "end": 875.68, "text": " Or getting you know a hundred top data scientists to work at your problem to really know what's possible", "tokens": [1610, 1242, 291, 458, 257, 3262, 1192, 1412, 7708, 281, 589, 412, 428, 1154, 281, 534, 458, 437, 311, 1944], "temperature": 0.0, "avg_logprob": -0.20800111808028876, "compression_ratio": 1.791044776119403, "no_speech_prob": 1.3006412700633518e-05}, {"id": 175, "seek": 85764, "start": 876.6, "end": 881.1999999999999, "text": " so Kaggle competitions are fantastic for learning and", "tokens": [370, 48751, 22631, 26185, 366, 5456, 337, 2539, 293], "temperature": 0.0, "avg_logprob": -0.20800111808028876, "compression_ratio": 1.791044776119403, "no_speech_prob": 1.3006412700633518e-05}, {"id": 176, "seek": 88120, "start": 881.2, "end": 887.4000000000001, "text": " As I've said many times I've learned more from from competing in Kaggle competitions and everything else I've done in my life", "tokens": [1018, 286, 600, 848, 867, 1413, 286, 600, 3264, 544, 490, 490, 15439, 294, 48751, 22631, 26185, 293, 1203, 1646, 286, 600, 1096, 294, 452, 993], "temperature": 0.0, "avg_logprob": -0.1596654982793899, "compression_ratio": 1.7440944881889764, "no_speech_prob": 9.223096640198492e-06}, {"id": 177, "seek": 88120, "start": 888.88, "end": 896.2800000000001, "text": " So to compete in a Kaggle competition you need the data this one's an old competition, so it's not running now, but we can still", "tokens": [407, 281, 11831, 294, 257, 48751, 22631, 6211, 291, 643, 264, 1412, 341, 472, 311, 364, 1331, 6211, 11, 370, 309, 311, 406, 2614, 586, 11, 457, 321, 393, 920], "temperature": 0.0, "avg_logprob": -0.1596654982793899, "compression_ratio": 1.7440944881889764, "no_speech_prob": 9.223096640198492e-06}, {"id": 178, "seek": 88120, "start": 897.12, "end": 899.12, "text": " access everything", "tokens": [2105, 1203], "temperature": 0.0, "avg_logprob": -0.1596654982793899, "compression_ratio": 1.7440944881889764, "no_speech_prob": 9.223096640198492e-06}, {"id": 179, "seek": 88120, "start": 899.6400000000001, "end": 905.58, "text": " So we first of all want to understand what the goal is and I suggest that you read this later", "tokens": [407, 321, 700, 295, 439, 528, 281, 1223, 437, 264, 3387, 307, 293, 286, 3402, 300, 291, 1401, 341, 1780], "temperature": 0.0, "avg_logprob": -0.1596654982793899, "compression_ratio": 1.7440944881889764, "no_speech_prob": 9.223096640198492e-06}, {"id": 180, "seek": 88120, "start": 905.58, "end": 909.6, "text": " but basically we're to try and predict the sale price of heavy equipment and", "tokens": [457, 1936, 321, 434, 281, 853, 293, 6069, 264, 8680, 3218, 295, 4676, 5927, 293], "temperature": 0.0, "avg_logprob": -0.1596654982793899, "compression_ratio": 1.7440944881889764, "no_speech_prob": 9.223096640198492e-06}, {"id": 181, "seek": 90960, "start": 909.6, "end": 917.24, "text": " And one of the nice things about this competition is that if you're like me you probably don't know very much about", "tokens": [400, 472, 295, 264, 1481, 721, 466, 341, 6211, 307, 300, 498, 291, 434, 411, 385, 291, 1391, 500, 380, 458, 588, 709, 466], "temperature": 0.0, "avg_logprob": -0.16481621411381936, "compression_ratio": 1.6720647773279351, "no_speech_prob": 6.643330380029511e-06}, {"id": 182, "seek": 90960, "start": 917.6, "end": 924.24, "text": " Heavy heavy industrial equipment options right I actually know more than I used to because my toddler loves", "tokens": [26473, 4676, 9987, 5927, 3956, 558, 286, 767, 458, 544, 813, 286, 1143, 281, 570, 452, 44348, 6752], "temperature": 0.0, "avg_logprob": -0.16481621411381936, "compression_ratio": 1.6720647773279351, "no_speech_prob": 6.643330380029511e-06}, {"id": 183, "seek": 90960, "start": 924.6800000000001, "end": 930.32, "text": " Building equipment so we actually like watch YouTube videos about front-end loaders and forklifts", "tokens": [18974, 5927, 370, 321, 767, 411, 1159, 3088, 2145, 466, 1868, 12, 521, 3677, 433, 293, 337, 7837, 8065], "temperature": 0.0, "avg_logprob": -0.16481621411381936, "compression_ratio": 1.6720647773279351, "no_speech_prob": 6.643330380029511e-06}, {"id": 184, "seek": 90960, "start": 930.9200000000001, "end": 932.9200000000001, "text": " But you know two months ago. I was", "tokens": [583, 291, 458, 732, 2493, 2057, 13, 286, 390], "temperature": 0.0, "avg_logprob": -0.16481621411381936, "compression_ratio": 1.6720647773279351, "no_speech_prob": 6.643330380029511e-06}, {"id": 185, "seek": 90960, "start": 933.76, "end": 935.76, "text": " You know a real layman", "tokens": [509, 458, 257, 957, 2360, 1601], "temperature": 0.0, "avg_logprob": -0.16481621411381936, "compression_ratio": 1.6720647773279351, "no_speech_prob": 6.643330380029511e-06}, {"id": 186, "seek": 90960, "start": 936.64, "end": 938.64, "text": " so one of the nice things is that", "tokens": [370, 472, 295, 264, 1481, 721, 307, 300], "temperature": 0.0, "avg_logprob": -0.16481621411381936, "compression_ratio": 1.6720647773279351, "no_speech_prob": 6.643330380029511e-06}, {"id": 187, "seek": 93864, "start": 938.64, "end": 943.6999999999999, "text": " Machine learning should help us understand a data set not just make predictions about it", "tokens": [22155, 2539, 820, 854, 505, 1223, 257, 1412, 992, 406, 445, 652, 21264, 466, 309], "temperature": 0.0, "avg_logprob": -0.188149002363097, "compression_ratio": 1.7222222222222223, "no_speech_prob": 8.530111699656118e-06}, {"id": 188, "seek": 93864, "start": 943.6999999999999, "end": 949.98, "text": " So by picking an area which we're not familiar with it's a good test of whether we can build an understanding", "tokens": [407, 538, 8867, 364, 1859, 597, 321, 434, 406, 4963, 365, 309, 311, 257, 665, 1500, 295, 1968, 321, 393, 1322, 364, 3701], "temperature": 0.0, "avg_logprob": -0.188149002363097, "compression_ratio": 1.7222222222222223, "no_speech_prob": 8.530111699656118e-06}, {"id": 189, "seek": 93864, "start": 949.98, "end": 950.8, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.188149002363097, "compression_ratio": 1.7222222222222223, "no_speech_prob": 8.530111699656118e-06}, {"id": 190, "seek": 93864, "start": 950.8, "end": 953.0, "text": " Because otherwise what can happen is that your?", "tokens": [1436, 5911, 437, 393, 1051, 307, 300, 428, 30], "temperature": 0.0, "avg_logprob": -0.188149002363097, "compression_ratio": 1.7222222222222223, "no_speech_prob": 8.530111699656118e-06}, {"id": 191, "seek": 93864, "start": 953.52, "end": 959.0, "text": " Intuition about the data can make it very difficult for you to be open-minded enough to see what does the data really say?", "tokens": [5681, 19080, 466, 264, 1412, 393, 652, 309, 588, 2252, 337, 291, 281, 312, 1269, 12, 23310, 1547, 281, 536, 437, 775, 264, 1412, 534, 584, 30], "temperature": 0.0, "avg_logprob": -0.188149002363097, "compression_ratio": 1.7222222222222223, "no_speech_prob": 8.530111699656118e-06}, {"id": 192, "seek": 93864, "start": 960.4, "end": 965.1, "text": " It's easy enough to download the computer sorry to download the data to your computer", "tokens": [467, 311, 1858, 1547, 281, 5484, 264, 3820, 2597, 281, 5484, 264, 1412, 281, 428, 3820], "temperature": 0.0, "avg_logprob": -0.188149002363097, "compression_ratio": 1.7222222222222223, "no_speech_prob": 8.530111699656118e-06}, {"id": 193, "seek": 96510, "start": 965.1, "end": 970.82, "text": " You just have to click on the data set so here is train dot zip", "tokens": [509, 445, 362, 281, 2052, 322, 264, 1412, 992, 370, 510, 307, 3847, 5893, 20730], "temperature": 0.0, "avg_logprob": -0.18143540240348655, "compression_ratio": 1.6607929515418502, "no_speech_prob": 1.7330430637230165e-06}, {"id": 194, "seek": 96510, "start": 972.0400000000001, "end": 978.96, "text": " And click download right and so you can go ahead and do that if you're running on your own computer right now if you're running", "tokens": [400, 2052, 5484, 558, 293, 370, 291, 393, 352, 2286, 293, 360, 300, 498, 291, 434, 2614, 322, 428, 1065, 3820, 558, 586, 498, 291, 434, 2614], "temperature": 0.0, "avg_logprob": -0.18143540240348655, "compression_ratio": 1.6607929515418502, "no_speech_prob": 1.7330430637230165e-06}, {"id": 195, "seek": 96510, "start": 978.96, "end": 980.72, "text": " on AWS", "tokens": [322, 17650], "temperature": 0.0, "avg_logprob": -0.18143540240348655, "compression_ratio": 1.6607929515418502, "no_speech_prob": 1.7330430637230165e-06}, {"id": 196, "seek": 96510, "start": 980.72, "end": 987.0400000000001, "text": " It's a little bit harder right because unless you're familiar with text mode browsers like a links or links", "tokens": [467, 311, 257, 707, 857, 6081, 558, 570, 5969, 291, 434, 4963, 365, 2487, 4391, 36069, 411, 257, 6123, 420, 6123], "temperature": 0.0, "avg_logprob": -0.18143540240348655, "compression_ratio": 1.6607929515418502, "no_speech_prob": 1.7330430637230165e-06}, {"id": 197, "seek": 96510, "start": 987.08, "end": 992.26, "text": " It's quite tricky to get the data set to Kaggle so a couple of options", "tokens": [467, 311, 1596, 12414, 281, 483, 264, 1412, 992, 281, 48751, 22631, 370, 257, 1916, 295, 3956], "temperature": 0.0, "avg_logprob": -0.18143540240348655, "compression_ratio": 1.6607929515418502, "no_speech_prob": 1.7330430637230165e-06}, {"id": 198, "seek": 99226, "start": 992.26, "end": 997.56, "text": " One is you could download it to your computer and then scp it to", "tokens": [1485, 307, 291, 727, 5484, 309, 281, 428, 3820, 293, 550, 795, 79, 309, 281], "temperature": 0.0, "avg_logprob": -0.19968795776367188, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.653669073675701e-06}, {"id": 199, "seek": 99226, "start": 998.18, "end": 1002.98, "text": " AWS so scp works just like SSH, but it copies data rather than logging in", "tokens": [17650, 370, 795, 79, 1985, 445, 411, 12238, 39, 11, 457, 309, 14341, 1412, 2831, 813, 27991, 294], "temperature": 0.0, "avg_logprob": -0.19968795776367188, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.653669073675701e-06}, {"id": 200, "seek": 99226, "start": 1003.22, "end": 1007.34, "text": " I'll show you a trick though that I really like and it relies on using Firefox", "tokens": [286, 603, 855, 291, 257, 4282, 1673, 300, 286, 534, 411, 293, 309, 30910, 322, 1228, 46613], "temperature": 0.0, "avg_logprob": -0.19968795776367188, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.653669073675701e-06}, {"id": 201, "seek": 99226, "start": 1008.62, "end": 1012.78, "text": " For some reason Chrome doesn't work correctly with Kaggle for this", "tokens": [1171, 512, 1778, 15327, 1177, 380, 589, 8944, 365, 48751, 22631, 337, 341], "temperature": 0.0, "avg_logprob": -0.19968795776367188, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.653669073675701e-06}, {"id": 202, "seek": 99226, "start": 1015.02, "end": 1017.46, "text": " So if I go on Firefox", "tokens": [407, 498, 286, 352, 322, 46613], "temperature": 0.0, "avg_logprob": -0.19968795776367188, "compression_ratio": 1.4861111111111112, "no_speech_prob": 1.653669073675701e-06}, {"id": 203, "seek": 101746, "start": 1017.46, "end": 1022.86, "text": " To the website eventually", "tokens": [1407, 264, 3144, 4728], "temperature": 0.0, "avg_logprob": -0.22812083789280482, "compression_ratio": 1.4967320261437909, "no_speech_prob": 5.955043434369145e-06}, {"id": 204, "seek": 101746, "start": 1028.5, "end": 1032.94, "text": " And what we're going to do is we're going to use something called the JavaScript", "tokens": [400, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 764, 746, 1219, 264, 15778], "temperature": 0.0, "avg_logprob": -0.22812083789280482, "compression_ratio": 1.4967320261437909, "no_speech_prob": 5.955043434369145e-06}, {"id": 205, "seek": 101746, "start": 1033.5, "end": 1039.14, "text": " Console so every web browser comes with a set of tools for web developers", "tokens": [44152, 370, 633, 3670, 11185, 1487, 365, 257, 992, 295, 3873, 337, 3670, 8849], "temperature": 0.0, "avg_logprob": -0.22812083789280482, "compression_ratio": 1.4967320261437909, "no_speech_prob": 5.955043434369145e-06}, {"id": 206, "seek": 103914, "start": 1039.14, "end": 1047.14, "text": " To help them see what's going on and you can hit", "tokens": [1407, 854, 552, 536, 437, 311, 516, 322, 293, 291, 393, 2045], "temperature": 0.0, "avg_logprob": -0.33795193263462614, "compression_ratio": 1.4689655172413794, "no_speech_prob": 2.6425693704368314e-06}, {"id": 207, "seek": 103914, "start": 1050.7800000000002, "end": 1052.7800000000002, "text": " Developer", "tokens": [44915], "temperature": 0.0, "avg_logprob": -0.33795193263462614, "compression_ratio": 1.4689655172413794, "no_speech_prob": 2.6425693704368314e-06}, {"id": 208, "seek": 103914, "start": 1052.98, "end": 1056.1000000000001, "text": " Control shift I okay, so you can hit ctrl shift I", "tokens": [12912, 5513, 286, 1392, 11, 370, 291, 393, 2045, 269, 28269, 5513, 286], "temperature": 0.0, "avg_logprob": -0.33795193263462614, "compression_ratio": 1.4689655172413794, "no_speech_prob": 2.6425693704368314e-06}, {"id": 209, "seek": 103914, "start": 1056.8600000000001, "end": 1058.6200000000001, "text": " to bring up", "tokens": [281, 1565, 493], "temperature": 0.0, "avg_logprob": -0.33795193263462614, "compression_ratio": 1.4689655172413794, "no_speech_prob": 2.6425693704368314e-06}, {"id": 210, "seek": 103914, "start": 1058.6200000000001, "end": 1063.5800000000002, "text": " This this web developer tools and one of the tabs is network", "tokens": [639, 341, 3670, 10754, 3873, 293, 472, 295, 264, 20743, 307, 3209], "temperature": 0.0, "avg_logprob": -0.33795193263462614, "compression_ratio": 1.4689655172413794, "no_speech_prob": 2.6425693704368314e-06}, {"id": 211, "seek": 106358, "start": 1063.58, "end": 1070.1799999999998, "text": " Okay, and so then if I click on train dot zip and", "tokens": [1033, 11, 293, 370, 550, 498, 286, 2052, 322, 3847, 5893, 20730, 293], "temperature": 0.0, "avg_logprob": -0.2115698764198705, "compression_ratio": 1.6486486486486487, "no_speech_prob": 3.089461642957758e-06}, {"id": 212, "seek": 106358, "start": 1071.4199999999998, "end": 1073.4199999999998, "text": " I click on download", "tokens": [286, 2052, 322, 5484], "temperature": 0.0, "avg_logprob": -0.2115698764198705, "compression_ratio": 1.6486486486486487, "no_speech_prob": 3.089461642957758e-06}, {"id": 213, "seek": 106358, "start": 1075.74, "end": 1078.22, "text": " Okay, and I'm not even going to download I'm just going to say cancel", "tokens": [1033, 11, 293, 286, 478, 406, 754, 516, 281, 5484, 286, 478, 445, 516, 281, 584, 10373], "temperature": 0.0, "avg_logprob": -0.2115698764198705, "compression_ratio": 1.6486486486486487, "no_speech_prob": 3.089461642957758e-06}, {"id": 214, "seek": 106358, "start": 1078.5, "end": 1085.86, "text": " But you'll see down here. It's shown me all of the network connections that were just initiated right and so here's one", "tokens": [583, 291, 603, 536, 760, 510, 13, 467, 311, 4898, 385, 439, 295, 264, 3209, 9271, 300, 645, 445, 28578, 558, 293, 370, 510, 311, 472], "temperature": 0.0, "avg_logprob": -0.2115698764198705, "compression_ratio": 1.6486486486486487, "no_speech_prob": 3.089461642957758e-06}, {"id": 215, "seek": 106358, "start": 1085.86, "end": 1091.9399999999998, "text": " Which is downloading a zip file from storage Google api's calm blah blah blah. That's probably what I want", "tokens": [3013, 307, 32529, 257, 20730, 3991, 490, 6725, 3329, 1882, 72, 311, 7151, 12288, 12288, 12288, 13, 663, 311, 1391, 437, 286, 528], "temperature": 0.0, "avg_logprob": -0.2115698764198705, "compression_ratio": 1.6486486486486487, "no_speech_prob": 3.089461642957758e-06}, {"id": 216, "seek": 109194, "start": 1091.94, "end": 1097.3, "text": " All right, that looks good. So what you can do is you can right-click on that and say copy", "tokens": [1057, 558, 11, 300, 1542, 665, 13, 407, 437, 291, 393, 360, 307, 291, 393, 558, 12, 18548, 322, 300, 293, 584, 5055], "temperature": 0.0, "avg_logprob": -0.1636252506919529, "compression_ratio": 1.6367924528301887, "no_speech_prob": 1.5534899375779787e-06}, {"id": 217, "seek": 109194, "start": 1099.3400000000001, "end": 1105.8200000000002, "text": " Copy as curl so curl is a unix command like W get that downloads stuff", "tokens": [25653, 382, 22591, 370, 22591, 307, 257, 517, 970, 5622, 411, 343, 483, 300, 36553, 1507], "temperature": 0.0, "avg_logprob": -0.1636252506919529, "compression_ratio": 1.6367924528301887, "no_speech_prob": 1.5534899375779787e-06}, {"id": 218, "seek": 109194, "start": 1106.38, "end": 1108.5800000000002, "text": " Right, so if I go copy as curl", "tokens": [1779, 11, 370, 498, 286, 352, 5055, 382, 22591], "temperature": 0.0, "avg_logprob": -0.1636252506919529, "compression_ratio": 1.6367924528301887, "no_speech_prob": 1.5534899375779787e-06}, {"id": 219, "seek": 109194, "start": 1109.74, "end": 1116.7, "text": " That's going to create a command that has all of my cookies headers everything in it necessary to download this", "tokens": [663, 311, 516, 281, 1884, 257, 5622, 300, 575, 439, 295, 452, 13670, 45101, 1203, 294, 309, 4818, 281, 5484, 341], "temperature": 0.0, "avg_logprob": -0.1636252506919529, "compression_ratio": 1.6367924528301887, "no_speech_prob": 1.5534899375779787e-06}, {"id": 220, "seek": 109194, "start": 1117.46, "end": 1119.18, "text": " authenticated data set", "tokens": [9214, 3587, 1412, 992], "temperature": 0.0, "avg_logprob": -0.1636252506919529, "compression_ratio": 1.6367924528301887, "no_speech_prob": 1.5534899375779787e-06}, {"id": 221, "seek": 111918, "start": 1119.18, "end": 1122.18, "text": " so if I now go into my", "tokens": [370, 498, 286, 586, 352, 666, 452], "temperature": 0.0, "avg_logprob": -0.1533693156830252, "compression_ratio": 1.618279569892473, "no_speech_prob": 2.7693918127624784e-06}, {"id": 222, "seek": 111918, "start": 1123.78, "end": 1130.14, "text": " Server right and if I paste that you can see a really really long curl command", "tokens": [25684, 558, 293, 498, 286, 9163, 300, 291, 393, 536, 257, 534, 534, 938, 22591, 5622], "temperature": 0.0, "avg_logprob": -0.1533693156830252, "compression_ratio": 1.618279569892473, "no_speech_prob": 2.7693918127624784e-06}, {"id": 223, "seek": 111918, "start": 1136.46, "end": 1140.94, "text": " One thing I notice is that at least recent versions have started adding this minus minus", "tokens": [1485, 551, 286, 3449, 307, 300, 412, 1935, 5162, 9606, 362, 1409, 5127, 341, 3175, 3175], "temperature": 0.0, "avg_logprob": -0.1533693156830252, "compression_ratio": 1.618279569892473, "no_speech_prob": 2.7693918127624784e-06}, {"id": 224, "seek": 114094, "start": 1140.94, "end": 1148.54, "text": " 2.0 thing to the command that doesn't seem to work with all versions of curl so something you might want to do is", "tokens": [568, 13, 15, 551, 281, 264, 5622, 300, 1177, 380, 1643, 281, 589, 365, 439, 9606, 295, 22591, 370, 746, 291, 1062, 528, 281, 360, 307], "temperature": 0.0, "avg_logprob": -0.30805484319137316, "compression_ratio": 1.4366197183098592, "no_speech_prob": 2.1907660539000062e-06}, {"id": 225, "seek": 114094, "start": 1149.5, "end": 1151.5, "text": " to", "tokens": [281], "temperature": 0.0, "avg_logprob": -0.30805484319137316, "compression_ratio": 1.4366197183098592, "no_speech_prob": 2.1907660539000062e-06}, {"id": 226, "seek": 114094, "start": 1152.8200000000002, "end": 1154.8200000000002, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.30805484319137316, "compression_ratio": 1.4366197183098592, "no_speech_prob": 2.1907660539000062e-06}, {"id": 227, "seek": 114094, "start": 1156.94, "end": 1160.02, "text": " Is to pop that into an editor find that to", "tokens": [1119, 281, 1665, 300, 666, 364, 9839, 915, 300, 281], "temperature": 0.0, "avg_logprob": -0.30805484319137316, "compression_ratio": 1.4366197183098592, "no_speech_prob": 2.1907660539000062e-06}, {"id": 228, "seek": 114094, "start": 1162.02, "end": 1165.42, "text": " Get rid of it and then use that instead", "tokens": [3240, 3973, 295, 309, 293, 550, 764, 300, 2602], "temperature": 0.0, "avg_logprob": -0.30805484319137316, "compression_ratio": 1.4366197183098592, "no_speech_prob": 2.1907660539000062e-06}, {"id": 229, "seek": 116542, "start": 1165.42, "end": 1171.8200000000002, "text": " Okay now one thing to be very careful about by default curl downloads", "tokens": [1033, 586, 472, 551, 281, 312, 588, 5026, 466, 538, 7576, 22591, 36553], "temperature": 0.0, "avg_logprob": -0.1809121855012663, "compression_ratio": 1.6772727272727272, "no_speech_prob": 1.1382766951228973e-09}, {"id": 230, "seek": 116542, "start": 1172.5, "end": 1176.22, "text": " The file and displays it in your terminal", "tokens": [440, 3991, 293, 20119, 309, 294, 428, 14709], "temperature": 0.0, "avg_logprob": -0.1809121855012663, "compression_ratio": 1.6772727272727272, "no_speech_prob": 1.1382766951228973e-09}, {"id": 231, "seek": 116542, "start": 1176.22, "end": 1182.18, "text": " So if I try to display this it's going to display gigabytes of binary data in my terminal and crash it okay", "tokens": [407, 498, 286, 853, 281, 4674, 341, 309, 311, 516, 281, 4674, 42741, 295, 17434, 1412, 294, 452, 14709, 293, 8252, 309, 1392], "temperature": 0.0, "avg_logprob": -0.1809121855012663, "compression_ratio": 1.6772727272727272, "no_speech_prob": 1.1382766951228973e-09}, {"id": 232, "seek": 116542, "start": 1182.18, "end": 1186.6000000000001, "text": " So to say that I want to output it using some different file name", "tokens": [407, 281, 584, 300, 286, 528, 281, 5598, 309, 1228, 512, 819, 3991, 1315], "temperature": 0.0, "avg_logprob": -0.1809121855012663, "compression_ratio": 1.6772727272727272, "no_speech_prob": 1.1382766951228973e-09}, {"id": 233, "seek": 116542, "start": 1186.6000000000001, "end": 1191.22, "text": " I always type minus O for output file name and then the name of the file", "tokens": [286, 1009, 2010, 3175, 422, 337, 5598, 3991, 1315, 293, 550, 264, 1315, 295, 264, 3991], "temperature": 0.0, "avg_logprob": -0.1809121855012663, "compression_ratio": 1.6772727272727272, "no_speech_prob": 1.1382766951228973e-09}, {"id": 234, "seek": 116542, "start": 1192.14, "end": 1194.14, "text": " bulldozers", "tokens": [4693, 2595, 41698], "temperature": 0.0, "avg_logprob": -0.1809121855012663, "compression_ratio": 1.6772727272727272, "no_speech_prob": 1.1382766951228973e-09}, {"id": 235, "seek": 119414, "start": 1194.14, "end": 1198.3000000000002, "text": " Dot and make sure you give it a suitable a", "tokens": [38753, 293, 652, 988, 291, 976, 309, 257, 12873, 257], "temperature": 0.0, "avg_logprob": -0.26973890489147556, "compression_ratio": 1.4927536231884058, "no_speech_prob": 6.438977834477555e-06}, {"id": 236, "seek": 119414, "start": 1199.38, "end": 1201.7, "text": " Suitable extension so in this case", "tokens": [48854, 712, 10320, 370, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.26973890489147556, "compression_ratio": 1.4927536231884058, "no_speech_prob": 6.438977834477555e-06}, {"id": 237, "seek": 119414, "start": 1202.5800000000002, "end": 1204.5800000000002, "text": " the file was", "tokens": [264, 3991, 390], "temperature": 0.0, "avg_logprob": -0.26973890489147556, "compression_ratio": 1.4927536231884058, "no_speech_prob": 6.438977834477555e-06}, {"id": 238, "seek": 119414, "start": 1205.22, "end": 1207.22, "text": " Train zip okay, so", "tokens": [28029, 20730, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.26973890489147556, "compression_ratio": 1.4927536231884058, "no_speech_prob": 6.438977834477555e-06}, {"id": 239, "seek": 119414, "start": 1208.0600000000002, "end": 1210.0600000000002, "text": " bulldozers dot zip", "tokens": [4693, 2595, 41698, 5893, 20730], "temperature": 0.0, "avg_logprob": -0.26973890489147556, "compression_ratio": 1.4927536231884058, "no_speech_prob": 6.438977834477555e-06}, {"id": 240, "seek": 121006, "start": 1210.06, "end": 1223.7, "text": " And there it is okay, and so there it all is so I could make directory bulldozers", "tokens": [400, 456, 309, 307, 1392, 11, 293, 370, 456, 309, 439, 307, 370, 286, 727, 652, 21120, 4693, 2595, 41698], "temperature": 0.0, "avg_logprob": -0.2575434529504111, "compression_ratio": 1.3, "no_speech_prob": 1.723080458759796e-05}, {"id": 241, "seek": 121006, "start": 1223.7, "end": 1225.7, "text": " I could move my zip file into there", "tokens": [286, 727, 1286, 452, 20730, 3991, 666, 456], "temperature": 0.0, "avg_logprob": -0.2575434529504111, "compression_ratio": 1.3, "no_speech_prob": 1.723080458759796e-05}, {"id": 242, "seek": 121006, "start": 1229.22, "end": 1231.22, "text": " Oops wrong way around", "tokens": [21726, 2085, 636, 926], "temperature": 0.0, "avg_logprob": -0.2575434529504111, "compression_ratio": 1.3, "no_speech_prob": 1.723080458759796e-05}, {"id": 243, "seek": 121006, "start": 1235.62, "end": 1237.62, "text": " Yes", "tokens": [1079], "temperature": 0.0, "avg_logprob": -0.2575434529504111, "compression_ratio": 1.3, "no_speech_prob": 1.723080458759796e-05}, {"id": 244, "seek": 123762, "start": 1237.62, "end": 1239.62, "text": " Thank you", "tokens": [1044, 291], "temperature": 0.0, "avg_logprob": -0.22713109970092774, "compression_ratio": 1.054054054054054, "no_speech_prob": 4.399531098897569e-05}, {"id": 245, "seek": 123762, "start": 1258.7399999999998, "end": 1262.82, "text": " Okay, and then you if you don't have unzip installed you may need to", "tokens": [1033, 11, 293, 550, 291, 498, 291, 500, 380, 362, 517, 27268, 8899, 291, 815, 643, 281], "temperature": 0.0, "avg_logprob": -0.22713109970092774, "compression_ratio": 1.054054054054054, "no_speech_prob": 4.399531098897569e-05}, {"id": 246, "seek": 126282, "start": 1262.82, "end": 1267.58, "text": " To pseudo apt install unzip or if then you're on a Mac", "tokens": [1407, 35899, 29427, 3625, 517, 27268, 420, 498, 550, 291, 434, 322, 257, 5707], "temperature": 0.0, "avg_logprob": -0.25316751739125193, "compression_ratio": 1.6045197740112995, "no_speech_prob": 3.6119274682278046e-06}, {"id": 247, "seek": 126282, "start": 1268.8999999999999, "end": 1274.9399999999998, "text": " That would be brew install unzip if brew doesn't work you haven't got home brew installed so make sure you install it", "tokens": [663, 576, 312, 34619, 3625, 517, 27268, 498, 34619, 1177, 380, 589, 291, 2378, 380, 658, 1280, 34619, 8899, 370, 652, 988, 291, 3625, 309], "temperature": 0.0, "avg_logprob": -0.25316751739125193, "compression_ratio": 1.6045197740112995, "no_speech_prob": 3.6119274682278046e-06}, {"id": 248, "seek": 126282, "start": 1275.3799999999999, "end": 1277.3799999999999, "text": " And then unzip", "tokens": [400, 550, 517, 27268], "temperature": 0.0, "avg_logprob": -0.25316751739125193, "compression_ratio": 1.6045197740112995, "no_speech_prob": 3.6119274682278046e-06}, {"id": 249, "seek": 126282, "start": 1278.22, "end": 1280.22, "text": " Okay, and so they're the basic steps", "tokens": [1033, 11, 293, 370, 436, 434, 264, 3875, 4439], "temperature": 0.0, "avg_logprob": -0.25316751739125193, "compression_ratio": 1.6045197740112995, "no_speech_prob": 3.6119274682278046e-06}, {"id": 250, "seek": 126282, "start": 1281.48, "end": 1284.62, "text": " One nice thing is that if you're using", "tokens": [1485, 1481, 551, 307, 300, 498, 291, 434, 1228], "temperature": 0.0, "avg_logprob": -0.25316751739125193, "compression_ratio": 1.6045197740112995, "no_speech_prob": 3.6119274682278046e-06}, {"id": 251, "seek": 126282, "start": 1287.1399999999999, "end": 1289.1399999999999, "text": " Cressell most of the", "tokens": [383, 495, 14555, 881, 295, 264], "temperature": 0.0, "avg_logprob": -0.25316751739125193, "compression_ratio": 1.6045197740112995, "no_speech_prob": 3.6119274682278046e-06}, {"id": 252, "seek": 128914, "start": 1289.14, "end": 1292.3400000000001, "text": " Data sets should already be pre-installed for you", "tokens": [11888, 6352, 820, 1217, 312, 659, 12, 13911, 8907, 337, 291], "temperature": 0.0, "avg_logprob": -0.18717893712660846, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.4063695743971039e-05}, {"id": 253, "seek": 128914, "start": 1293.38, "end": 1296.66, "text": " So what I can do here is I can say open a new tab", "tokens": [407, 437, 286, 393, 360, 510, 307, 286, 393, 584, 1269, 257, 777, 4421], "temperature": 0.0, "avg_logprob": -0.18717893712660846, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.4063695743971039e-05}, {"id": 254, "seek": 128914, "start": 1299.18, "end": 1302.5, "text": " Here's a cool trick in Jupiter you can actually say new terminal and", "tokens": [1692, 311, 257, 1627, 4282, 294, 24567, 291, 393, 767, 584, 777, 14709, 293], "temperature": 0.0, "avg_logprob": -0.18717893712660846, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.4063695743971039e-05}, {"id": 255, "seek": 128914, "start": 1303.5800000000002, "end": 1311.5, "text": " You can actually get a web-based terminal right and so you'll find on Cressell. There's a slash data sets folder", "tokens": [509, 393, 767, 483, 257, 3670, 12, 6032, 14709, 558, 293, 370, 291, 603, 915, 322, 383, 495, 14555, 13, 821, 311, 257, 17330, 1412, 6352, 10820], "temperature": 0.0, "avg_logprob": -0.18717893712660846, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.4063695743971039e-05}, {"id": 256, "seek": 128914, "start": 1312.6200000000001, "end": 1314.6200000000001, "text": " slash data set slash kaggle", "tokens": [17330, 1412, 992, 17330, 350, 559, 22631], "temperature": 0.0, "avg_logprob": -0.18717893712660846, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.4063695743971039e-05}, {"id": 257, "seek": 131462, "start": 1314.62, "end": 1321.06, "text": " slash data set slash fast AI often the things you need are going to be in one of those places", "tokens": [17330, 1412, 992, 17330, 2370, 7318, 2049, 264, 721, 291, 643, 366, 516, 281, 312, 294, 472, 295, 729, 3190], "temperature": 0.0, "avg_logprob": -0.14712937672932944, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.422150479716947e-06}, {"id": 258, "seek": 131462, "start": 1323.82, "end": 1329.8999999999999, "text": " Okay, so assuming that we don't have it already downloaded in paper actually paper space should have most of them as well", "tokens": [1033, 11, 370, 11926, 300, 321, 500, 380, 362, 309, 1217, 21748, 294, 3035, 767, 3035, 1901, 820, 362, 881, 295, 552, 382, 731], "temperature": 0.0, "avg_logprob": -0.14712937672932944, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.422150479716947e-06}, {"id": 259, "seek": 131462, "start": 1330.3799999999999, "end": 1333.7399999999998, "text": " Then we would need to go to fast AI. Let's go into the courses", "tokens": [1396, 321, 576, 643, 281, 352, 281, 2370, 7318, 13, 961, 311, 352, 666, 264, 7712], "temperature": 0.0, "avg_logprob": -0.14712937672932944, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.422150479716947e-06}, {"id": 260, "seek": 131462, "start": 1334.34, "end": 1335.78, "text": " machine learning", "tokens": [3479, 2539], "temperature": 0.0, "avg_logprob": -0.14712937672932944, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.422150479716947e-06}, {"id": 261, "seek": 131462, "start": 1335.78, "end": 1342.82, "text": " Folder and what I tend to do is I tend to put all of my data for a course into a folder called data", "tokens": [24609, 260, 293, 437, 286, 3928, 281, 360, 307, 286, 3928, 281, 829, 439, 295, 452, 1412, 337, 257, 1164, 666, 257, 10820, 1219, 1412], "temperature": 0.0, "avg_logprob": -0.14712937672932944, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.422150479716947e-06}, {"id": 262, "seek": 134282, "start": 1342.82, "end": 1348.78, "text": " You'll find that if you try and if you're using where we using get right you'll find that that doesn't get added", "tokens": [509, 603, 915, 300, 498, 291, 853, 293, 498, 291, 434, 1228, 689, 321, 1228, 483, 558, 291, 603, 915, 300, 300, 1177, 380, 483, 3869], "temperature": 0.0, "avg_logprob": -0.2157398828185431, "compression_ratio": 1.7123893805309736, "no_speech_prob": 1.1659374649752863e-05}, {"id": 263, "seek": 134282, "start": 1348.8999999999999, "end": 1351.98, "text": " To get because it's in the git ignore right so", "tokens": [1407, 483, 570, 309, 311, 294, 264, 18331, 11200, 558, 370], "temperature": 0.0, "avg_logprob": -0.2157398828185431, "compression_ratio": 1.7123893805309736, "no_speech_prob": 1.1659374649752863e-05}, {"id": 264, "seek": 134282, "start": 1353.4199999999998, "end": 1356.78, "text": " So don't worry about creating the data folder. It's not going to screw anything up", "tokens": [407, 500, 380, 3292, 466, 4084, 264, 1412, 10820, 13, 467, 311, 406, 516, 281, 5630, 1340, 493], "temperature": 0.0, "avg_logprob": -0.2157398828185431, "compression_ratio": 1.7123893805309736, "no_speech_prob": 1.1659374649752863e-05}, {"id": 265, "seek": 134282, "start": 1356.78, "end": 1362.26, "text": " So I generally make a folder called data, and then I tend to create folders for everything I need there", "tokens": [407, 286, 5101, 652, 257, 10820, 1219, 1412, 11, 293, 550, 286, 3928, 281, 1884, 31082, 337, 1203, 286, 643, 456], "temperature": 0.0, "avg_logprob": -0.2157398828185431, "compression_ratio": 1.7123893805309736, "no_speech_prob": 1.1659374649752863e-05}, {"id": 266, "seek": 134282, "start": 1362.98, "end": 1366.26, "text": " So in this case I'll make the", "tokens": [407, 294, 341, 1389, 286, 603, 652, 264], "temperature": 0.0, "avg_logprob": -0.2157398828185431, "compression_ratio": 1.7123893805309736, "no_speech_prob": 1.1659374649752863e-05}, {"id": 267, "seek": 134282, "start": 1367.1799999999998, "end": 1369.1799999999998, "text": " bulldozers", "tokens": [4693, 2595, 41698], "temperature": 0.0, "avg_logprob": -0.2157398828185431, "compression_ratio": 1.7123893805309736, "no_speech_prob": 1.1659374649752863e-05}, {"id": 268, "seek": 136918, "start": 1369.18, "end": 1375.66, "text": " CD and remember the last word of the last command is exclamation mark dollar", "tokens": [6743, 293, 1604, 264, 1036, 1349, 295, 264, 1036, 5622, 307, 1624, 43233, 1491, 7241], "temperature": 0.0, "avg_logprob": -0.22463814417521158, "compression_ratio": 1.2685185185185186, "no_speech_prob": 4.331714808358811e-05}, {"id": 269, "seek": 136918, "start": 1377.78, "end": 1380.26, "text": " I'll go ahead and grab that curl command again", "tokens": [286, 603, 352, 2286, 293, 4444, 300, 22591, 5622, 797], "temperature": 0.0, "avg_logprob": -0.22463814417521158, "compression_ratio": 1.2685185185185186, "no_speech_prob": 4.331714808358811e-05}, {"id": 270, "seek": 138026, "start": 1380.26, "end": 1383.3, "text": " And then okay", "tokens": [400, 550, 1392], "temperature": 0.0, "avg_logprob": -0.6164682222449261, "compression_ratio": 0.9090909090909091, "no_speech_prob": 6.920321175130084e-05}, {"id": 271, "seek": 138026, "start": 1397.74, "end": 1399.74, "text": " Zip bulldozers", "tokens": [1176, 647, 4693, 2595, 41698], "temperature": 0.0, "avg_logprob": -0.6164682222449261, "compression_ratio": 0.9090909090909091, "no_speech_prob": 6.920321175130084e-05}, {"id": 272, "seek": 138026, "start": 1402.02, "end": 1405.42, "text": " There we go, okay, so", "tokens": [821, 321, 352, 11, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.6164682222449261, "compression_ratio": 0.9090909090909091, "no_speech_prob": 6.920321175130084e-05}, {"id": 273, "seek": 140542, "start": 1405.42, "end": 1407.42, "text": " You", "tokens": [509], "temperature": 0.0, "avg_logprob": -0.1660147361385012, "compression_ratio": 1.646090534979424, "no_speech_prob": 2.9479556360456627e-06}, {"id": 274, "seek": 140542, "start": 1409.38, "end": 1414.74, "text": " Can now see I generally have like anything that would change that might change from person to person", "tokens": [1664, 586, 536, 286, 5101, 362, 411, 1340, 300, 576, 1319, 300, 1062, 1319, 490, 954, 281, 954], "temperature": 0.0, "avg_logprob": -0.1660147361385012, "compression_ratio": 1.646090534979424, "no_speech_prob": 2.9479556360456627e-06}, {"id": 275, "seek": 140542, "start": 1414.74, "end": 1417.94, "text": " I kind of put in a constant so here. I just define saying called path", "tokens": [286, 733, 295, 829, 294, 257, 5754, 370, 510, 13, 286, 445, 6964, 1566, 1219, 3100], "temperature": 0.0, "avg_logprob": -0.1660147361385012, "compression_ratio": 1.646090534979424, "no_speech_prob": 2.9479556360456627e-06}, {"id": 276, "seek": 140542, "start": 1417.94, "end": 1421.42, "text": " but if you've used the same path, I just did you should just be able to go ahead and run that and", "tokens": [457, 498, 291, 600, 1143, 264, 912, 3100, 11, 286, 445, 630, 291, 820, 445, 312, 1075, 281, 352, 2286, 293, 1190, 300, 293], "temperature": 0.0, "avg_logprob": -0.1660147361385012, "compression_ratio": 1.646090534979424, "no_speech_prob": 2.9479556360456627e-06}, {"id": 277, "seek": 140542, "start": 1422.74, "end": 1429.3000000000002, "text": " Let's go ahead and keep moving along so we've now got all of our libraries imported, and we've set the path to the data", "tokens": [961, 311, 352, 2286, 293, 1066, 2684, 2051, 370, 321, 600, 586, 658, 439, 295, 527, 15148, 25524, 11, 293, 321, 600, 992, 264, 3100, 281, 264, 1412], "temperature": 0.0, "avg_logprob": -0.1660147361385012, "compression_ratio": 1.646090534979424, "no_speech_prob": 2.9479556360456627e-06}, {"id": 278, "seek": 140542, "start": 1432.02, "end": 1434.02, "text": " You can", "tokens": [509, 393], "temperature": 0.0, "avg_logprob": -0.1660147361385012, "compression_ratio": 1.646090534979424, "no_speech_prob": 2.9479556360456627e-06}, {"id": 279, "seek": 143402, "start": 1434.02, "end": 1436.02, "text": " run", "tokens": [1190], "temperature": 0.0, "avg_logprob": -0.2017380801114169, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.8058230125461705e-05}, {"id": 280, "seek": 143402, "start": 1436.06, "end": 1443.26, "text": " Shell commands from within jupyter notebook by using an exclamation mark so if I want to check what's inside that path I can go LS", "tokens": [22863, 16901, 490, 1951, 361, 1010, 88, 391, 21060, 538, 1228, 364, 1624, 43233, 1491, 370, 498, 286, 528, 281, 1520, 437, 311, 1854, 300, 3100, 286, 393, 352, 36657], "temperature": 0.0, "avg_logprob": -0.2017380801114169, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.8058230125461705e-05}, {"id": 281, "seek": 143402, "start": 1443.82, "end": 1445.82, "text": " data slash bulldozers", "tokens": [1412, 17330, 4693, 2595, 41698], "temperature": 0.0, "avg_logprob": -0.2017380801114169, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.8058230125461705e-05}, {"id": 282, "seek": 143402, "start": 1446.26, "end": 1453.94, "text": " Okay, and you can see that works, or you can even use Python variables if you use a Python variable inside a jupyter shell command", "tokens": [1033, 11, 293, 291, 393, 536, 300, 1985, 11, 420, 291, 393, 754, 764, 15329, 9102, 498, 291, 764, 257, 15329, 7006, 1854, 257, 361, 1010, 88, 391, 8720, 5622], "temperature": 0.0, "avg_logprob": -0.2017380801114169, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.8058230125461705e-05}, {"id": 283, "seek": 143402, "start": 1453.94, "end": 1455.94, "text": " You have to put it in curlies", "tokens": [509, 362, 281, 829, 309, 294, 22591, 530], "temperature": 0.0, "avg_logprob": -0.2017380801114169, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.8058230125461705e-05}, {"id": 284, "seek": 143402, "start": 1456.94, "end": 1458.46, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.2017380801114169, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.8058230125461705e-05}, {"id": 285, "seek": 143402, "start": 1458.46, "end": 1462.94, "text": " So that makes me feel good that my path is pointing at the right place if you say LS", "tokens": [407, 300, 1669, 385, 841, 665, 300, 452, 3100, 307, 12166, 412, 264, 558, 1081, 498, 291, 584, 36657], "temperature": 0.0, "avg_logprob": -0.2017380801114169, "compression_ratio": 1.6477732793522266, "no_speech_prob": 1.8058230125461705e-05}, {"id": 286, "seek": 146294, "start": 1462.94, "end": 1469.26, "text": " Curly capitals path and you get nothing at all then you're pointing at the wrong spot. Yes", "tokens": [7907, 356, 1410, 11118, 3100, 293, 291, 483, 1825, 412, 439, 550, 291, 434, 12166, 412, 264, 2085, 4008, 13, 1079], "temperature": 0.0, "avg_logprob": -0.15203918218612672, "compression_ratio": 1.6059113300492611, "no_speech_prob": 4.356837962404825e-06}, {"id": 287, "seek": 146294, "start": 1477.22, "end": 1483.3, "text": " Yeah, so the curly brackets refer to the fact that I put an exclamation mark at the front which means the rest of this", "tokens": [865, 11, 370, 264, 32066, 26179, 2864, 281, 264, 1186, 300, 286, 829, 364, 1624, 43233, 1491, 412, 264, 1868, 597, 1355, 264, 1472, 295, 341], "temperature": 0.0, "avg_logprob": -0.15203918218612672, "compression_ratio": 1.6059113300492611, "no_speech_prob": 4.356837962404825e-06}, {"id": 288, "seek": 146294, "start": 1483.5800000000002, "end": 1485.5800000000002, "text": " is not a", "tokens": [307, 406, 257], "temperature": 0.0, "avg_logprob": -0.15203918218612672, "compression_ratio": 1.6059113300492611, "no_speech_prob": 4.356837962404825e-06}, {"id": 289, "seek": 148558, "start": 1485.58, "end": 1492.62, "text": " Python command it's a bash command and bash doesn't know about capital path because capital path is part of", "tokens": [15329, 5622, 309, 311, 257, 46183, 5622, 293, 46183, 1177, 380, 458, 466, 4238, 3100, 570, 4238, 3100, 307, 644, 295], "temperature": 0.0, "avg_logprob": -0.15314805750944177, "compression_ratio": 1.5448275862068965, "no_speech_prob": 1.7330316950392444e-06}, {"id": 290, "seek": 148558, "start": 1493.1799999999998, "end": 1501.02, "text": " Python so this is a special Jupiter thing which says expand this Python thing please before you pass it to the shelf", "tokens": [15329, 370, 341, 307, 257, 2121, 24567, 551, 597, 1619, 5268, 341, 15329, 551, 1767, 949, 291, 1320, 309, 281, 264, 15222], "temperature": 0.0, "avg_logprob": -0.15314805750944177, "compression_ratio": 1.5448275862068965, "no_speech_prob": 1.7330316950392444e-06}, {"id": 291, "seek": 150102, "start": 1501.02, "end": 1503.02, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.1846607526143392, "compression_ratio": 1.467153284671533, "no_speech_prob": 2.857256049537682e-06}, {"id": 292, "seek": 150102, "start": 1514.5, "end": 1523.1, "text": " The goal here is to use the training set which contains data through the end of 2011 to predict the sale price of bulldozers and", "tokens": [440, 3387, 510, 307, 281, 764, 264, 3097, 992, 597, 8306, 1412, 807, 264, 917, 295, 10154, 281, 6069, 264, 8680, 3218, 295, 4693, 2595, 41698, 293], "temperature": 0.0, "avg_logprob": -0.1846607526143392, "compression_ratio": 1.467153284671533, "no_speech_prob": 2.857256049537682e-06}, {"id": 293, "seek": 150102, "start": 1523.9, "end": 1525.82, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.1846607526143392, "compression_ratio": 1.467153284671533, "no_speech_prob": 2.857256049537682e-06}, {"id": 294, "seek": 150102, "start": 1525.82, "end": 1529.1, "text": " The main thing to start with then is of course to look at the data", "tokens": [440, 2135, 551, 281, 722, 365, 550, 307, 295, 1164, 281, 574, 412, 264, 1412], "temperature": 0.0, "avg_logprob": -0.1846607526143392, "compression_ratio": 1.467153284671533, "no_speech_prob": 2.857256049537682e-06}, {"id": 295, "seek": 152910, "start": 1529.1, "end": 1538.34, "text": " Now the data is in csv format right so one easy way to look at the data would be to use shell command", "tokens": [823, 264, 1412, 307, 294, 28277, 85, 7877, 558, 370, 472, 1858, 636, 281, 574, 412, 264, 1412, 576, 312, 281, 764, 8720, 5622], "temperature": 0.0, "avg_logprob": -0.22924063603083292, "compression_ratio": 1.705069124423963, "no_speech_prob": 3.4465497265045997e-06}, {"id": 296, "seek": 152910, "start": 1538.34, "end": 1540.8999999999999, "text": " head to look at the first two lines head", "tokens": [1378, 281, 574, 412, 264, 700, 732, 3876, 1378], "temperature": 0.0, "avg_logprob": -0.22924063603083292, "compression_ratio": 1.705069124423963, "no_speech_prob": 3.4465497265045997e-06}, {"id": 297, "seek": 152910, "start": 1541.9399999999998, "end": 1546.28, "text": " Bulldozers and even tab completion works here Jupiter does everything", "tokens": [14131, 2595, 41698, 293, 754, 4421, 19372, 1985, 510, 24567, 775, 1203], "temperature": 0.0, "avg_logprob": -0.22924063603083292, "compression_ratio": 1.705069124423963, "no_speech_prob": 3.4465497265045997e-06}, {"id": 298, "seek": 152910, "start": 1547.02, "end": 1550.6599999999999, "text": " Right so here's the first few five lines, okay?", "tokens": [1779, 370, 510, 311, 264, 700, 1326, 1732, 3876, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.22924063603083292, "compression_ratio": 1.705069124423963, "no_speech_prob": 3.4465497265045997e-06}, {"id": 299, "seek": 152910, "start": 1550.6599999999999, "end": 1555.9399999999998, "text": " So there's like a bunch of column headers, and then there's a bunch of data, so that's pretty hard to look at", "tokens": [407, 456, 311, 411, 257, 3840, 295, 7738, 45101, 11, 293, 550, 456, 311, 257, 3840, 295, 1412, 11, 370, 300, 311, 1238, 1152, 281, 574, 412], "temperature": 0.0, "avg_logprob": -0.22924063603083292, "compression_ratio": 1.705069124423963, "no_speech_prob": 3.4465497265045997e-06}, {"id": 300, "seek": 155594, "start": 1555.94, "end": 1561.96, "text": " So what we want to do is take this and read it into a nice tabular format, okay, so", "tokens": [407, 437, 321, 528, 281, 360, 307, 747, 341, 293, 1401, 309, 666, 257, 1481, 4421, 1040, 7877, 11, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.25392383077870245, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.637807251128834e-06}, {"id": 301, "seek": 155594, "start": 1563.54, "end": 1568.26, "text": " Does Terrence put in glasses on me, and I should make this bigger or is it okay? Is this big enough font size?", "tokens": [4402, 6564, 10760, 829, 294, 10812, 322, 385, 11, 293, 286, 820, 652, 341, 3801, 420, 307, 309, 1392, 30, 1119, 341, 955, 1547, 10703, 2744, 30], "temperature": 0.0, "avg_logprob": -0.25392383077870245, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.637807251128834e-06}, {"id": 302, "seek": 155594, "start": 1570.9, "end": 1572.02, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.25392383077870245, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.637807251128834e-06}, {"id": 303, "seek": 155594, "start": 1572.02, "end": 1579.18, "text": " This kind of data where you've got columns representing a wide range of different types of things such as an identifier", "tokens": [639, 733, 295, 1412, 689, 291, 600, 658, 13766, 13460, 257, 4874, 3613, 295, 819, 3467, 295, 721, 1270, 382, 364, 45690], "temperature": 0.0, "avg_logprob": -0.25392383077870245, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.637807251128834e-06}, {"id": 304, "seek": 155594, "start": 1579.94, "end": 1583.8600000000001, "text": " value a currency a date a size I", "tokens": [2158, 257, 13346, 257, 4002, 257, 2744, 286], "temperature": 0.0, "avg_logprob": -0.25392383077870245, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.637807251128834e-06}, {"id": 305, "seek": 158386, "start": 1583.86, "end": 1587.62, "text": " refer to this as structured data now", "tokens": [2864, 281, 341, 382, 18519, 1412, 586], "temperature": 0.0, "avg_logprob": -0.18996780087249449, "compression_ratio": 1.9145299145299146, "no_speech_prob": 4.092872131877812e-06}, {"id": 306, "seek": 158386, "start": 1587.62, "end": 1594.4199999999998, "text": " I say I refer to this as structured data because like there's there's been many arguments in the machine learning community on Twitter about", "tokens": [286, 584, 286, 2864, 281, 341, 382, 18519, 1412, 570, 411, 456, 311, 456, 311, 668, 867, 12869, 294, 264, 3479, 2539, 1768, 322, 5794, 466], "temperature": 0.0, "avg_logprob": -0.18996780087249449, "compression_ratio": 1.9145299145299146, "no_speech_prob": 4.092872131877812e-06}, {"id": 307, "seek": 158386, "start": 1594.74, "end": 1596.74, "text": " What is structured data?", "tokens": [708, 307, 18519, 1412, 30], "temperature": 0.0, "avg_logprob": -0.18996780087249449, "compression_ratio": 1.9145299145299146, "no_speech_prob": 4.092872131877812e-06}, {"id": 308, "seek": 158386, "start": 1596.78, "end": 1604.6399999999999, "text": " Weirdly enough this is like the most important type of distinction is between data that looks like this and data like", "tokens": [32033, 356, 1547, 341, 307, 411, 264, 881, 1021, 2010, 295, 16844, 307, 1296, 1412, 300, 1542, 411, 341, 293, 1412, 411], "temperature": 0.0, "avg_logprob": -0.18996780087249449, "compression_ratio": 1.9145299145299146, "no_speech_prob": 4.092872131877812e-06}, {"id": 309, "seek": 158386, "start": 1605.1399999999999, "end": 1611.1, "text": " Images where every column is of the same type like that's the most important distinction in machine learning", "tokens": [4331, 1660, 689, 633, 7738, 307, 295, 264, 912, 2010, 411, 300, 311, 264, 881, 1021, 16844, 294, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.18996780087249449, "compression_ratio": 1.9145299145299146, "no_speech_prob": 4.092872131877812e-06}, {"id": 310, "seek": 161110, "start": 1611.1, "end": 1617.78, "text": " Yet we don't have standard accepted terms, so I'm going to use the term structured and unstructured", "tokens": [10890, 321, 500, 380, 362, 3832, 9035, 2115, 11, 370, 286, 478, 516, 281, 764, 264, 1433, 18519, 293, 18799, 46847], "temperature": 0.0, "avg_logprob": -0.18119271596272787, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.9333394902787404e-06}, {"id": 311, "seek": 161110, "start": 1618.4599999999998, "end": 1627.1, "text": " But note that other people you talk to particularly in NLP and NLP people use structured to mean something totally different, right so", "tokens": [583, 3637, 300, 661, 561, 291, 751, 281, 4098, 294, 426, 45196, 293, 426, 45196, 561, 764, 18519, 281, 914, 746, 3879, 819, 11, 558, 370], "temperature": 0.0, "avg_logprob": -0.18119271596272787, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.9333394902787404e-06}, {"id": 312, "seek": 161110, "start": 1627.86, "end": 1633.48, "text": " When I refer to structured data, I mean columns of data that can have varying different types of data in them", "tokens": [1133, 286, 2864, 281, 18519, 1412, 11, 286, 914, 13766, 295, 1412, 300, 393, 362, 22984, 819, 3467, 295, 1412, 294, 552], "temperature": 0.0, "avg_logprob": -0.18119271596272787, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.9333394902787404e-06}, {"id": 313, "seek": 161110, "start": 1634.3, "end": 1639.1999999999998, "text": " By far the most important tool in Python for you working with structured data is pandas", "tokens": [3146, 1400, 264, 881, 1021, 2290, 294, 15329, 337, 291, 1364, 365, 18519, 1412, 307, 4565, 296], "temperature": 0.0, "avg_logprob": -0.18119271596272787, "compression_ratio": 1.7349397590361446, "no_speech_prob": 1.9333394902787404e-06}, {"id": 314, "seek": 163920, "start": 1639.2, "end": 1647.1200000000001, "text": " Pandas is so important that it's one of the few libraries that everybody uses the same abbreviation for it, which is PD", "tokens": [16995, 296, 307, 370, 1021, 300, 309, 311, 472, 295, 264, 1326, 15148, 300, 2201, 4960, 264, 912, 35839, 399, 337, 309, 11, 597, 307, 10464], "temperature": 0.0, "avg_logprob": -0.18101891384849064, "compression_ratio": 1.5454545454545454, "no_speech_prob": 3.1875363220024155e-06}, {"id": 315, "seek": 163920, "start": 1647.48, "end": 1649.48, "text": " so you'll find that", "tokens": [370, 291, 603, 915, 300], "temperature": 0.0, "avg_logprob": -0.18101891384849064, "compression_ratio": 1.5454545454545454, "no_speech_prob": 3.1875363220024155e-06}, {"id": 316, "seek": 163920, "start": 1650.0, "end": 1654.88, "text": " One of the things I've got here is from fast AI imports import star, right?", "tokens": [1485, 295, 264, 721, 286, 600, 658, 510, 307, 490, 2370, 7318, 41596, 974, 3543, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18101891384849064, "compression_ratio": 1.5454545454545454, "no_speech_prob": 3.1875363220024155e-06}, {"id": 317, "seek": 163920, "start": 1656.72, "end": 1658.8, "text": " The fast AI imports", "tokens": [440, 2370, 7318, 41596], "temperature": 0.0, "avg_logprob": -0.18101891384849064, "compression_ratio": 1.5454545454545454, "no_speech_prob": 3.1875363220024155e-06}, {"id": 318, "seek": 163920, "start": 1660.24, "end": 1665.44, "text": " Module has nothing but imports of a bunch of hopefully useful tools", "tokens": [48251, 575, 1825, 457, 41596, 295, 257, 3840, 295, 4696, 4420, 3873], "temperature": 0.0, "avg_logprob": -0.18101891384849064, "compression_ratio": 1.5454545454545454, "no_speech_prob": 3.1875363220024155e-06}, {"id": 319, "seek": 166544, "start": 1665.44, "end": 1668.0, "text": " so all", "tokens": [370, 439], "temperature": 0.0, "avg_logprob": -0.2170556875375601, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.7603089190743049e-06}, {"id": 320, "seek": 166544, "start": 1670.16, "end": 1677.8400000000001, "text": " Of the code for fast AI is inside the fast AI directory inside the fast AI repo and so you can have a look at", "tokens": [2720, 264, 3089, 337, 2370, 7318, 307, 1854, 264, 2370, 7318, 21120, 1854, 264, 2370, 7318, 49040, 293, 370, 291, 393, 362, 257, 574, 412], "temperature": 0.0, "avg_logprob": -0.2170556875375601, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.7603089190743049e-06}, {"id": 321, "seek": 166544, "start": 1679.16, "end": 1681.16, "text": " imports and", "tokens": [41596, 293], "temperature": 0.0, "avg_logprob": -0.2170556875375601, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.7603089190743049e-06}, {"id": 322, "seek": 166544, "start": 1682.44, "end": 1686.1200000000001, "text": " You'll see it's just literally a list of imports and you'll find there", "tokens": [509, 603, 536, 309, 311, 445, 3736, 257, 1329, 295, 41596, 293, 291, 603, 915, 456], "temperature": 0.0, "avg_logprob": -0.2170556875375601, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.7603089190743049e-06}, {"id": 323, "seek": 166544, "start": 1687.56, "end": 1693.8, "text": " Pandas as PD and so everybody does this right so you'll see lots of people using PD dot something", "tokens": [16995, 296, 382, 10464, 293, 370, 2201, 775, 341, 558, 370, 291, 603, 536, 3195, 295, 561, 1228, 10464, 5893, 746], "temperature": 0.0, "avg_logprob": -0.2170556875375601, "compression_ratio": 1.6779661016949152, "no_speech_prob": 1.7603089190743049e-06}, {"id": 324, "seek": 169380, "start": 1693.8, "end": 1695.8, "text": " They're always talking about pandas", "tokens": [814, 434, 1009, 1417, 466, 4565, 296], "temperature": 0.0, "avg_logprob": -0.12837619995802976, "compression_ratio": 1.5922330097087378, "no_speech_prob": 3.726602017195546e-06}, {"id": 325, "seek": 169380, "start": 1695.9199999999998, "end": 1698.12, "text": " so pandas lets us", "tokens": [370, 4565, 296, 6653, 505], "temperature": 0.0, "avg_logprob": -0.12837619995802976, "compression_ratio": 1.5922330097087378, "no_speech_prob": 3.726602017195546e-06}, {"id": 326, "seek": 169380, "start": 1699.08, "end": 1701.08, "text": " read a CSV file and", "tokens": [1401, 257, 48814, 3991, 293], "temperature": 0.0, "avg_logprob": -0.12837619995802976, "compression_ratio": 1.5922330097087378, "no_speech_prob": 3.726602017195546e-06}, {"id": 327, "seek": 169380, "start": 1701.24, "end": 1703.24, "text": " So when we read the CSV file", "tokens": [407, 562, 321, 1401, 264, 48814, 3991], "temperature": 0.0, "avg_logprob": -0.12837619995802976, "compression_ratio": 1.5922330097087378, "no_speech_prob": 3.726602017195546e-06}, {"id": 328, "seek": 169380, "start": 1704.36, "end": 1710.12, "text": " We just tell it the path to the CSV file a list of any columns that contain dates", "tokens": [492, 445, 980, 309, 264, 3100, 281, 264, 48814, 3991, 257, 1329, 295, 604, 13766, 300, 5304, 11691], "temperature": 0.0, "avg_logprob": -0.12837619995802976, "compression_ratio": 1.5922330097087378, "no_speech_prob": 3.726602017195546e-06}, {"id": 329, "seek": 169380, "start": 1710.6399999999999, "end": 1717.52, "text": " And I always add this low memory equals false. That's going to actually make it read more of the file to decide what the types are", "tokens": [400, 286, 1009, 909, 341, 2295, 4675, 6915, 7908, 13, 663, 311, 516, 281, 767, 652, 309, 1401, 544, 295, 264, 3991, 281, 4536, 437, 264, 3467, 366], "temperature": 0.0, "avg_logprob": -0.12837619995802976, "compression_ratio": 1.5922330097087378, "no_speech_prob": 3.726602017195546e-06}, {"id": 330, "seek": 169380, "start": 1718.8799999999999, "end": 1720.8, "text": " This here is", "tokens": [639, 510, 307], "temperature": 0.0, "avg_logprob": -0.12837619995802976, "compression_ratio": 1.5922330097087378, "no_speech_prob": 3.726602017195546e-06}, {"id": 331, "seek": 172080, "start": 1720.8, "end": 1727.32, "text": " Something called a Python 3.6 format string. It's one of the coolest parts of Python 3.6", "tokens": [6595, 1219, 257, 15329, 805, 13, 21, 7877, 6798, 13, 467, 311, 472, 295, 264, 22013, 3166, 295, 15329, 805, 13, 21], "temperature": 0.0, "avg_logprob": -0.12376334003566467, "compression_ratio": 1.6394849785407726, "no_speech_prob": 8.939521649153903e-06}, {"id": 332, "seek": 172080, "start": 1728.3999999999999, "end": 1733.9199999999998, "text": " You've probably used lots of different ways in the past in Python of interpolating variables into your strings", "tokens": [509, 600, 1391, 1143, 3195, 295, 819, 2098, 294, 264, 1791, 294, 15329, 295, 44902, 990, 9102, 666, 428, 13985], "temperature": 0.0, "avg_logprob": -0.12376334003566467, "compression_ratio": 1.6394849785407726, "no_speech_prob": 8.939521649153903e-06}, {"id": 333, "seek": 172080, "start": 1734.6, "end": 1741.1599999999999, "text": " Python 3.6 has a very simple way that you'll probably always want to use from now on and it's you to create a normal string", "tokens": [15329, 805, 13, 21, 575, 257, 588, 2199, 636, 300, 291, 603, 1391, 1009, 528, 281, 764, 490, 586, 322, 293, 309, 311, 291, 281, 1884, 257, 2710, 6798], "temperature": 0.0, "avg_logprob": -0.12376334003566467, "compression_ratio": 1.6394849785407726, "no_speech_prob": 8.939521649153903e-06}, {"id": 334, "seek": 172080, "start": 1741.8, "end": 1743.8, "text": " You type in F at the start", "tokens": [509, 2010, 294, 479, 412, 264, 722], "temperature": 0.0, "avg_logprob": -0.12376334003566467, "compression_ratio": 1.6394849785407726, "no_speech_prob": 8.939521649153903e-06}, {"id": 335, "seek": 172080, "start": 1744.24, "end": 1746.24, "text": " And then if I define a variable", "tokens": [400, 550, 498, 286, 6964, 257, 7006], "temperature": 0.0, "avg_logprob": -0.12376334003566467, "compression_ratio": 1.6394849785407726, "no_speech_prob": 8.939521649153903e-06}, {"id": 336, "seek": 174624, "start": 1746.24, "end": 1751.56, "text": " Then I can say hello", "tokens": [1396, 286, 393, 584, 7751], "temperature": 0.0, "avg_logprob": -0.2828141682183565, "compression_ratio": 1.4968944099378882, "no_speech_prob": 2.2252647795539815e-06}, {"id": 337, "seek": 174624, "start": 1753.6, "end": 1756.28, "text": " Curly's Python function", "tokens": [7907, 356, 311, 15329, 2445], "temperature": 0.0, "avg_logprob": -0.2828141682183565, "compression_ratio": 1.4968944099378882, "no_speech_prob": 2.2252647795539815e-06}, {"id": 338, "seek": 174624, "start": 1758.56, "end": 1759.96, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.2828141682183565, "compression_ratio": 1.4968944099378882, "no_speech_prob": 2.2252647795539815e-06}, {"id": 339, "seek": 174624, "start": 1759.96, "end": 1766.88, "text": " This is kind of confusing these are not the same curlies that we saw earlier on in that LS command right that LS command is specific", "tokens": [639, 307, 733, 295, 13181, 613, 366, 406, 264, 912, 22591, 530, 300, 321, 1866, 3071, 322, 294, 300, 36657, 5622, 558, 300, 36657, 5622, 307, 2685], "temperature": 0.0, "avg_logprob": -0.2828141682183565, "compression_ratio": 1.4968944099378882, "no_speech_prob": 2.2252647795539815e-06}, {"id": 340, "seek": 174624, "start": 1766.88, "end": 1768.64, "text": " to Jupiter and it", "tokens": [281, 24567, 293, 309], "temperature": 0.0, "avg_logprob": -0.2828141682183565, "compression_ratio": 1.4968944099378882, "no_speech_prob": 2.2252647795539815e-06}, {"id": 341, "seek": 174624, "start": 1768.64, "end": 1769.88, "text": " interpolates", "tokens": [44902, 1024], "temperature": 0.0, "avg_logprob": -0.2828141682183565, "compression_ratio": 1.4968944099378882, "no_speech_prob": 2.2252647795539815e-06}, {"id": 342, "seek": 174624, "start": 1769.88, "end": 1772.28, "text": " Python code into shell", "tokens": [15329, 3089, 666, 8720], "temperature": 0.0, "avg_logprob": -0.2828141682183565, "compression_ratio": 1.4968944099378882, "no_speech_prob": 2.2252647795539815e-06}, {"id": 343, "seek": 174624, "start": 1772.88, "end": 1774.04, "text": " code", "tokens": [3089], "temperature": 0.0, "avg_logprob": -0.2828141682183565, "compression_ratio": 1.4968944099378882, "no_speech_prob": 2.2252647795539815e-06}, {"id": 344, "seek": 177404, "start": 1774.04, "end": 1780.56, "text": " These curlies are Python 3.6 format string curlies they require an F at the start so if I get rid of the F", "tokens": [1981, 22591, 530, 366, 15329, 805, 13, 21, 7877, 6798, 22591, 530, 436, 3651, 364, 479, 412, 264, 722, 370, 498, 286, 483, 3973, 295, 264, 479], "temperature": 0.0, "avg_logprob": -0.20059284410978617, "compression_ratio": 1.5627906976744186, "no_speech_prob": 8.059398055593192e-07}, {"id": 345, "seek": 177404, "start": 1782.32, "end": 1783.8799999999999, "text": " It doesn't interpolate", "tokens": [467, 1177, 380, 44902, 473], "temperature": 0.0, "avg_logprob": -0.20059284410978617, "compression_ratio": 1.5627906976744186, "no_speech_prob": 8.059398055593192e-07}, {"id": 346, "seek": 177404, "start": 1783.8799999999999, "end": 1788.68, "text": " Okay, so the F tells it to interpolate and the cool thing is inside that", "tokens": [1033, 11, 370, 264, 479, 5112, 309, 281, 44902, 473, 293, 264, 1627, 551, 307, 1854, 300], "temperature": 0.0, "avg_logprob": -0.20059284410978617, "compression_ratio": 1.5627906976744186, "no_speech_prob": 8.059398055593192e-07}, {"id": 347, "seek": 177404, "start": 1789.3999999999999, "end": 1794.6399999999999, "text": " Curly's you can write any Python code you like just about so for example name dot", "tokens": [7907, 356, 311, 291, 393, 2464, 604, 15329, 3089, 291, 411, 445, 466, 370, 337, 1365, 1315, 5893], "temperature": 0.0, "avg_logprob": -0.20059284410978617, "compression_ratio": 1.5627906976744186, "no_speech_prob": 8.059398055593192e-07}, {"id": 348, "seek": 177404, "start": 1795.1599999999999, "end": 1797.1599999999999, "text": " upper", "tokens": [6597], "temperature": 0.0, "avg_logprob": -0.20059284410978617, "compression_ratio": 1.5627906976744186, "no_speech_prob": 8.059398055593192e-07}, {"id": 349, "seek": 177404, "start": 1797.24, "end": 1799.2, "text": " Hello Jeremy", "tokens": [2425, 17809], "temperature": 0.0, "avg_logprob": -0.20059284410978617, "compression_ratio": 1.5627906976744186, "no_speech_prob": 8.059398055593192e-07}, {"id": 350, "seek": 177404, "start": 1799.2, "end": 1802.06, "text": " Okay, so I use this all the time", "tokens": [1033, 11, 370, 286, 764, 341, 439, 264, 565], "temperature": 0.0, "avg_logprob": -0.20059284410978617, "compression_ratio": 1.5627906976744186, "no_speech_prob": 8.059398055593192e-07}, {"id": 351, "seek": 180206, "start": 1802.06, "end": 1807.22, "text": " And it doesn't matter because it's a format string. It doesn't matter if the thing was", "tokens": [400, 309, 1177, 380, 1871, 570, 309, 311, 257, 7877, 6798, 13, 467, 1177, 380, 1871, 498, 264, 551, 390], "temperature": 0.0, "avg_logprob": -0.21009614965417883, "compression_ratio": 1.5964125560538116, "no_speech_prob": 5.093642357678618e-06}, {"id": 352, "seek": 180206, "start": 1810.46, "end": 1812.46, "text": " They always forget my age, I think I'm 43", "tokens": [814, 1009, 2870, 452, 3205, 11, 286, 519, 286, 478, 17914], "temperature": 0.0, "avg_logprob": -0.21009614965417883, "compression_ratio": 1.5964125560538116, "no_speech_prob": 5.093642357678618e-06}, {"id": 353, "seek": 180206, "start": 1813.46, "end": 1818.3799999999999, "text": " It doesn't matter if it's an integer right normally if you like to string concatenation with integers Python complains", "tokens": [467, 1177, 380, 1871, 498, 309, 311, 364, 24922, 558, 5646, 498, 291, 411, 281, 6798, 1588, 7186, 399, 365, 41674, 15329, 1209, 2315], "temperature": 0.0, "avg_logprob": -0.21009614965417883, "compression_ratio": 1.5964125560538116, "no_speech_prob": 5.093642357678618e-06}, {"id": 354, "seek": 180206, "start": 1821.3799999999999, "end": 1824.02, "text": " No such problem here, okay, so", "tokens": [883, 1270, 1154, 510, 11, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.21009614965417883, "compression_ratio": 1.5964125560538116, "no_speech_prob": 5.093642357678618e-06}, {"id": 355, "seek": 182402, "start": 1824.02, "end": 1831.18, "text": " So this is going to read paths train dot CSV into a thing called a data frame", "tokens": [407, 341, 307, 516, 281, 1401, 14518, 3847, 5893, 48814, 666, 257, 551, 1219, 257, 1412, 3920], "temperature": 0.0, "avg_logprob": -0.31514752100384424, "compression_ratio": 1.5617283950617284, "no_speech_prob": 2.2252606868278235e-06}, {"id": 356, "seek": 182402, "start": 1833.3, "end": 1840.1399999999999, "text": " Pandas data frames and ours data frames are kind of pretty similar so if you've used our before", "tokens": [16995, 296, 1412, 12083, 293, 11896, 1412, 12083, 366, 733, 295, 1238, 2531, 370, 498, 291, 600, 1143, 527, 949], "temperature": 0.0, "avg_logprob": -0.31514752100384424, "compression_ratio": 1.5617283950617284, "no_speech_prob": 2.2252606868278235e-06}, {"id": 357, "seek": 182402, "start": 1840.7, "end": 1846.98, "text": " Then you'll find that this is a you know reasonably comfortable so this file", "tokens": [1396, 291, 603, 915, 300, 341, 307, 257, 291, 458, 23551, 4619, 370, 341, 3991], "temperature": 0.0, "avg_logprob": -0.31514752100384424, "compression_ratio": 1.5617283950617284, "no_speech_prob": 2.2252606868278235e-06}, {"id": 358, "seek": 182402, "start": 1849.9, "end": 1851.9, "text": " Is", "tokens": [1119], "temperature": 0.0, "avg_logprob": -0.31514752100384424, "compression_ratio": 1.5617283950617284, "no_speech_prob": 2.2252606868278235e-06}, {"id": 359, "seek": 185190, "start": 1851.9, "end": 1855.94, "text": " 9.3 Meg and its size is", "tokens": [1722, 13, 18, 9986, 293, 1080, 2744, 307], "temperature": 0.0, "avg_logprob": -0.24624114340924202, "compression_ratio": 1.2181818181818183, "no_speech_prob": 1.3419778042589314e-05}, {"id": 360, "seek": 185190, "start": 1858.38, "end": 1862.3400000000001, "text": " Sorry 112 Meg 112 Meg and it has", "tokens": [4919, 45835, 9986, 45835, 9986, 293, 309, 575], "temperature": 0.0, "avg_logprob": -0.24624114340924202, "compression_ratio": 1.2181818181818183, "no_speech_prob": 1.3419778042589314e-05}, {"id": 361, "seek": 185190, "start": 1864.5800000000002, "end": 1869.0600000000002, "text": " 400,000 rows in it okay, so it takes a moment to import it", "tokens": [8423, 11, 1360, 13241, 294, 309, 1392, 11, 370, 309, 2516, 257, 1623, 281, 974, 309], "temperature": 0.0, "avg_logprob": -0.24624114340924202, "compression_ratio": 1.2181818181818183, "no_speech_prob": 1.3419778042589314e-05}, {"id": 362, "seek": 185190, "start": 1873.5400000000002, "end": 1875.5400000000002, "text": " But when it's done", "tokens": [583, 562, 309, 311, 1096], "temperature": 0.0, "avg_logprob": -0.24624114340924202, "compression_ratio": 1.2181818181818183, "no_speech_prob": 1.3419778042589314e-05}, {"id": 363, "seek": 187554, "start": 1875.54, "end": 1877.54, "text": " We", "tokens": [492], "temperature": 0.0, "avg_logprob": -0.15688515724019803, "compression_ratio": 1.650943396226415, "no_speech_prob": 7.766813723719679e-06}, {"id": 364, "seek": 187554, "start": 1880.34, "end": 1881.82, "text": " Can", "tokens": [1664], "temperature": 0.0, "avg_logprob": -0.15688515724019803, "compression_ratio": 1.650943396226415, "no_speech_prob": 7.766813723719679e-06}, {"id": 365, "seek": 187554, "start": 1881.82, "end": 1884.98, "text": " Type the name of the data frame DF raw", "tokens": [15576, 264, 1315, 295, 264, 1412, 3920, 48336, 8936], "temperature": 0.0, "avg_logprob": -0.15688515724019803, "compression_ratio": 1.650943396226415, "no_speech_prob": 7.766813723719679e-06}, {"id": 366, "seek": 187554, "start": 1885.82, "end": 1889.82, "text": " And then use various methods on it so for example DF raw dot tail", "tokens": [400, 550, 764, 3683, 7150, 322, 309, 370, 337, 1365, 48336, 8936, 5893, 6838], "temperature": 0.0, "avg_logprob": -0.15688515724019803, "compression_ratio": 1.650943396226415, "no_speech_prob": 7.766813723719679e-06}, {"id": 367, "seek": 187554, "start": 1890.3, "end": 1893.58, "text": " Will show us the last few rows of the data frame", "tokens": [3099, 855, 505, 264, 1036, 1326, 13241, 295, 264, 1412, 3920], "temperature": 0.0, "avg_logprob": -0.15688515724019803, "compression_ratio": 1.650943396226415, "no_speech_prob": 7.766813723719679e-06}, {"id": 368, "seek": 187554, "start": 1894.22, "end": 1898.3, "text": " By default it's going to show the columns along the top and the rows down the side", "tokens": [3146, 7576, 309, 311, 516, 281, 855, 264, 13766, 2051, 264, 1192, 293, 264, 13241, 760, 264, 1252], "temperature": 0.0, "avg_logprob": -0.15688515724019803, "compression_ratio": 1.650943396226415, "no_speech_prob": 7.766813723719679e-06}, {"id": 369, "seek": 189830, "start": 1898.3, "end": 1905.18, "text": " But in this case there's a lot of columns, so I've just said dot transpose to show it the other way around", "tokens": [583, 294, 341, 1389, 456, 311, 257, 688, 295, 13766, 11, 370, 286, 600, 445, 848, 5893, 25167, 281, 855, 309, 264, 661, 636, 926], "temperature": 0.0, "avg_logprob": -0.1601719103361431, "compression_ratio": 1.6594202898550725, "no_speech_prob": 6.540339200000744e-06}, {"id": 370, "seek": 189830, "start": 1906.8999999999999, "end": 1911.6599999999999, "text": " I've created one extra function here display all normally if you just type DF raw", "tokens": [286, 600, 2942, 472, 2857, 2445, 510, 4674, 439, 5646, 498, 291, 445, 2010, 48336, 8936], "temperature": 0.0, "avg_logprob": -0.1601719103361431, "compression_ratio": 1.6594202898550725, "no_speech_prob": 6.540339200000744e-06}, {"id": 371, "seek": 189830, "start": 1912.1, "end": 1917.62, "text": " If it's too big to show conveniently it truncates it and puts like little lips is in the middle", "tokens": [759, 309, 311, 886, 955, 281, 855, 44375, 309, 504, 409, 66, 1024, 309, 293, 8137, 411, 707, 10118, 307, 294, 264, 2808], "temperature": 0.0, "avg_logprob": -0.1601719103361431, "compression_ratio": 1.6594202898550725, "no_speech_prob": 6.540339200000744e-06}, {"id": 372, "seek": 189830, "start": 1917.74, "end": 1923.94, "text": " So the details don't matter, but this is just changing a couple of settings to say even if it's got a thousand rows and a", "tokens": [407, 264, 4365, 500, 380, 1871, 11, 457, 341, 307, 445, 4473, 257, 1916, 295, 6257, 281, 584, 754, 498, 309, 311, 658, 257, 4714, 13241, 293, 257], "temperature": 0.0, "avg_logprob": -0.1601719103361431, "compression_ratio": 1.6594202898550725, "no_speech_prob": 6.540339200000744e-06}, {"id": 373, "seek": 189830, "start": 1923.94, "end": 1926.3999999999999, "text": " Thousand columns, please still show the whole thing", "tokens": [29852, 474, 13766, 11, 1767, 920, 855, 264, 1379, 551], "temperature": 0.0, "avg_logprob": -0.1601719103361431, "compression_ratio": 1.6594202898550725, "no_speech_prob": 6.540339200000744e-06}, {"id": 374, "seek": 192640, "start": 1926.4, "end": 1932.5600000000002, "text": " Okay, so this is finished. I can actually show you that so if I just type this is really cool in in", "tokens": [1033, 11, 370, 341, 307, 4335, 13, 286, 393, 767, 855, 291, 300, 370, 498, 286, 445, 2010, 341, 307, 534, 1627, 294, 294], "temperature": 0.0, "avg_logprob": -0.18965440137045725, "compression_ratio": 1.7165354330708662, "no_speech_prob": 2.260307383039617e-06}, {"id": 375, "seek": 192640, "start": 1933.0, "end": 1937.3600000000001, "text": " Jupiter notebook you can type a variable of almost any kind a video", "tokens": [24567, 21060, 291, 393, 2010, 257, 7006, 295, 1920, 604, 733, 257, 960], "temperature": 0.0, "avg_logprob": -0.18965440137045725, "compression_ratio": 1.7165354330708662, "no_speech_prob": 2.260307383039617e-06}, {"id": 376, "seek": 192640, "start": 1937.92, "end": 1943.24, "text": " HTML an image whatever and it'll generally figure out a way of displaying it for you okay", "tokens": [17995, 364, 3256, 2035, 293, 309, 603, 5101, 2573, 484, 257, 636, 295, 36834, 309, 337, 291, 1392], "temperature": 0.0, "avg_logprob": -0.18965440137045725, "compression_ratio": 1.7165354330708662, "no_speech_prob": 2.260307383039617e-06}, {"id": 377, "seek": 192640, "start": 1943.24, "end": 1947.14, "text": " So in this case it's a pandas data frame it figures it out a way of displaying it for me", "tokens": [407, 294, 341, 1389, 309, 311, 257, 4565, 296, 1412, 3920, 309, 9624, 309, 484, 257, 636, 295, 36834, 309, 337, 385], "temperature": 0.0, "avg_logprob": -0.18965440137045725, "compression_ratio": 1.7165354330708662, "no_speech_prob": 2.260307383039617e-06}, {"id": 378, "seek": 192640, "start": 1947.14, "end": 1952.16, "text": " And so you can see here that by default. It's actually doesn't show me the whole thing", "tokens": [400, 370, 291, 393, 536, 510, 300, 538, 7576, 13, 467, 311, 767, 1177, 380, 855, 385, 264, 1379, 551], "temperature": 0.0, "avg_logprob": -0.18965440137045725, "compression_ratio": 1.7165354330708662, "no_speech_prob": 2.260307383039617e-06}, {"id": 379, "seek": 192640, "start": 1952.88, "end": 1954.88, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.18965440137045725, "compression_ratio": 1.7165354330708662, "no_speech_prob": 2.260307383039617e-06}, {"id": 380, "seek": 195488, "start": 1954.88, "end": 1956.88, "text": " So here's the data set", "tokens": [407, 510, 311, 264, 1412, 992], "temperature": 0.0, "avg_logprob": -0.1652618444190835, "compression_ratio": 1.7866666666666666, "no_speech_prob": 6.540248250530567e-06}, {"id": 381, "seek": 195488, "start": 1957.8400000000001, "end": 1963.2800000000002, "text": " We've got a few different rows. This is the last bit the tail of it right last few rows", "tokens": [492, 600, 658, 257, 1326, 819, 13241, 13, 639, 307, 264, 1036, 857, 264, 6838, 295, 309, 558, 1036, 1326, 13241], "temperature": 0.0, "avg_logprob": -0.1652618444190835, "compression_ratio": 1.7866666666666666, "no_speech_prob": 6.540248250530567e-06}, {"id": 382, "seek": 195488, "start": 1964.48, "end": 1966.48, "text": " This is the thing we want to predict", "tokens": [639, 307, 264, 551, 321, 528, 281, 6069], "temperature": 0.0, "avg_logprob": -0.1652618444190835, "compression_ratio": 1.7866666666666666, "no_speech_prob": 6.540248250530567e-06}, {"id": 383, "seek": 195488, "start": 1966.68, "end": 1971.4, "text": " Price okay, and then all of the other so we call this the dependent variable", "tokens": [25803, 1392, 11, 293, 550, 439, 295, 264, 661, 370, 321, 818, 341, 264, 12334, 7006], "temperature": 0.0, "avg_logprob": -0.1652618444190835, "compression_ratio": 1.7866666666666666, "no_speech_prob": 6.540248250530567e-06}, {"id": 384, "seek": 195488, "start": 1972.0, "end": 1974.0, "text": " The dependent variable is the price", "tokens": [440, 12334, 7006, 307, 264, 3218], "temperature": 0.0, "avg_logprob": -0.1652618444190835, "compression_ratio": 1.7866666666666666, "no_speech_prob": 6.540248250530567e-06}, {"id": 385, "seek": 195488, "start": 1974.7600000000002, "end": 1981.0800000000002, "text": " And then we've got a whole bunch of things we could predict it with and when I start with a data set I tend", "tokens": [400, 550, 321, 600, 658, 257, 1379, 3840, 295, 721, 321, 727, 6069, 309, 365, 293, 562, 286, 722, 365, 257, 1412, 992, 286, 3928], "temperature": 0.0, "avg_logprob": -0.1652618444190835, "compression_ratio": 1.7866666666666666, "no_speech_prob": 6.540248250530567e-06}, {"id": 386, "seek": 198108, "start": 1981.08, "end": 1985.28, "text": " To be a little bit more careful and yes Terrence can I give you this?", "tokens": [1407, 312, 257, 707, 857, 544, 5026, 293, 2086, 6564, 10760, 393, 286, 976, 291, 341, 30], "temperature": 0.0, "avg_logprob": -0.5113610392031462, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.1738520596700255e-06}, {"id": 387, "seek": 198108, "start": 1990.8, "end": 1992.8, "text": " Hello Jeremy hi Terrence", "tokens": [2425, 17809, 4879, 6564, 10760], "temperature": 0.0, "avg_logprob": -0.5113610392031462, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.1738520596700255e-06}, {"id": 388, "seek": 198108, "start": 1994.12, "end": 1998.3999999999999, "text": " I've read in books that you should never look at the data because of the risk of overfit", "tokens": [286, 600, 1401, 294, 3642, 300, 291, 820, 1128, 574, 412, 264, 1412, 570, 295, 264, 3148, 295, 670, 6845], "temperature": 0.0, "avg_logprob": -0.5113610392031462, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.1738520596700255e-06}, {"id": 389, "seek": 198108, "start": 1998.3999999999999, "end": 2001.3999999999999, "text": " Why do you start by looking at the data? Yeah, so", "tokens": [1545, 360, 291, 722, 538, 1237, 412, 264, 1412, 30, 865, 11, 370], "temperature": 0.0, "avg_logprob": -0.5113610392031462, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.1738520596700255e-06}, {"id": 390, "seek": 198108, "start": 2002.12, "end": 2007.6, "text": " I was actually going to mention I actually kind of don't like I I want to find out at least enough to know that", "tokens": [286, 390, 767, 516, 281, 2152, 286, 767, 733, 295, 500, 380, 411, 286, 286, 528, 281, 915, 484, 412, 1935, 1547, 281, 458, 300], "temperature": 0.0, "avg_logprob": -0.5113610392031462, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.1738520596700255e-06}, {"id": 391, "seek": 200760, "start": 2007.6, "end": 2011.2199999999998, "text": " Okay, but I tend not to really study it at all at this point", "tokens": [1033, 11, 457, 286, 3928, 406, 281, 534, 2979, 309, 412, 439, 412, 341, 935], "temperature": 0.0, "avg_logprob": -0.22011760600562236, "compression_ratio": 1.6065573770491803, "no_speech_prob": 5.3380986173579e-06}, {"id": 392, "seek": 200760, "start": 2012.6, "end": 2016.6799999999998, "text": " Because I don't want to make too many assumptions about it. I would actually say", "tokens": [1436, 286, 500, 380, 528, 281, 652, 886, 867, 17695, 466, 309, 13, 286, 576, 767, 584], "temperature": 0.0, "avg_logprob": -0.22011760600562236, "compression_ratio": 1.6065573770491803, "no_speech_prob": 5.3380986173579e-06}, {"id": 393, "seek": 200760, "start": 2017.1999999999998, "end": 2020.6, "text": " Most books say the opposite most books do a whole lot of", "tokens": [4534, 3642, 584, 264, 6182, 881, 3642, 360, 257, 1379, 688, 295], "temperature": 0.0, "avg_logprob": -0.22011760600562236, "compression_ratio": 1.6065573770491803, "no_speech_prob": 5.3380986173579e-06}, {"id": 394, "seek": 200760, "start": 2021.08, "end": 2023.4399999999998, "text": " EDA expiratory data analysis first", "tokens": [462, 7509, 1278, 347, 4745, 1412, 5215, 700], "temperature": 0.0, "avg_logprob": -0.22011760600562236, "compression_ratio": 1.6065573770491803, "no_speech_prob": 5.3380986173579e-06}, {"id": 395, "seek": 200760, "start": 2023.9599999999998, "end": 2025.9599999999998, "text": " Yeah academic books", "tokens": [865, 7778, 3642], "temperature": 0.0, "avg_logprob": -0.22011760600562236, "compression_ratio": 1.6065573770491803, "no_speech_prob": 5.3380986173579e-06}, {"id": 396, "seek": 200760, "start": 2026.9599999999998, "end": 2028.9599999999998, "text": " The academic books I've read", "tokens": [440, 7778, 3642, 286, 600, 1401], "temperature": 0.0, "avg_logprob": -0.22011760600562236, "compression_ratio": 1.6065573770491803, "no_speech_prob": 5.3380986173579e-06}, {"id": 397, "seek": 200760, "start": 2029.04, "end": 2034.56, "text": " Say that's that's one of the biggest risks of overfitting but the practical books say let's do some EDA first", "tokens": [6463, 300, 311, 300, 311, 472, 295, 264, 3880, 10888, 295, 670, 69, 2414, 457, 264, 8496, 3642, 584, 718, 311, 360, 512, 462, 7509, 700], "temperature": 0.0, "avg_logprob": -0.22011760600562236, "compression_ratio": 1.6065573770491803, "no_speech_prob": 5.3380986173579e-06}, {"id": 398, "seek": 203456, "start": 2034.56, "end": 2040.32, "text": " Yeah, so that the truth is kind of somewhere in between and I generally I generally try to do machine learning driven EDA", "tokens": [865, 11, 370, 300, 264, 3494, 307, 733, 295, 4079, 294, 1296, 293, 286, 5101, 286, 5101, 853, 281, 360, 3479, 2539, 9555, 462, 7509], "temperature": 0.0, "avg_logprob": -0.15377608405219184, "compression_ratio": 1.6205357142857142, "no_speech_prob": 2.5215560981450835e-06}, {"id": 399, "seek": 203456, "start": 2040.32, "end": 2042.62, "text": " And that's what we're going to learn today, okay?", "tokens": [400, 300, 311, 437, 321, 434, 516, 281, 1466, 965, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.15377608405219184, "compression_ratio": 1.6205357142857142, "no_speech_prob": 2.5215560981450835e-06}, {"id": 400, "seek": 203456, "start": 2046.96, "end": 2049.48, "text": " So the do thing I do care about though is", "tokens": [407, 264, 360, 551, 286, 360, 1127, 466, 1673, 307], "temperature": 0.0, "avg_logprob": -0.15377608405219184, "compression_ratio": 1.6205357142857142, "no_speech_prob": 2.5215560981450835e-06}, {"id": 401, "seek": 203456, "start": 2050.16, "end": 2055.04, "text": " What's the purpose of the project and for Kaggle projects the purpose is very easy", "tokens": [708, 311, 264, 4334, 295, 264, 1716, 293, 337, 48751, 22631, 4455, 264, 4334, 307, 588, 1858], "temperature": 0.0, "avg_logprob": -0.15377608405219184, "compression_ratio": 1.6205357142857142, "no_speech_prob": 2.5215560981450835e-06}, {"id": 402, "seek": 203456, "start": 2055.36, "end": 2059.62, "text": " We can just look and find out there's always an evaluation section", "tokens": [492, 393, 445, 574, 293, 915, 484, 456, 311, 1009, 364, 13344, 3541], "temperature": 0.0, "avg_logprob": -0.15377608405219184, "compression_ratio": 1.6205357142857142, "no_speech_prob": 2.5215560981450835e-06}, {"id": 403, "seek": 205962, "start": 2059.62, "end": 2065.64, "text": " How is it evaluated and this is evaluated on root mean squared log error?", "tokens": [1012, 307, 309, 25509, 293, 341, 307, 25509, 322, 5593, 914, 8889, 3565, 6713, 30], "temperature": 0.0, "avg_logprob": -0.11779091404933556, "compression_ratio": 1.9276018099547512, "no_speech_prob": 4.7108810576901305e-06}, {"id": 404, "seek": 205962, "start": 2065.96, "end": 2073.08, "text": " so this means they're going to look at the difference between the log of our prediction of price and the log of the actual price and", "tokens": [370, 341, 1355, 436, 434, 516, 281, 574, 412, 264, 2649, 1296, 264, 3565, 295, 527, 17630, 295, 3218, 293, 264, 3565, 295, 264, 3539, 3218, 293], "temperature": 0.0, "avg_logprob": -0.11779091404933556, "compression_ratio": 1.9276018099547512, "no_speech_prob": 4.7108810576901305e-06}, {"id": 405, "seek": 205962, "start": 2073.4, "end": 2075.7, "text": " Then they're going to square it and add them up", "tokens": [1396, 436, 434, 516, 281, 3732, 309, 293, 909, 552, 493], "temperature": 0.0, "avg_logprob": -0.11779091404933556, "compression_ratio": 1.9276018099547512, "no_speech_prob": 4.7108810576901305e-06}, {"id": 406, "seek": 205962, "start": 2076.44, "end": 2080.96, "text": " Okay, so because they're going to be focusing on the difference of the logs", "tokens": [1033, 11, 370, 570, 436, 434, 516, 281, 312, 8416, 322, 264, 2649, 295, 264, 20820], "temperature": 0.0, "avg_logprob": -0.11779091404933556, "compression_ratio": 1.9276018099547512, "no_speech_prob": 4.7108810576901305e-06}, {"id": 407, "seek": 205962, "start": 2081.3399999999997, "end": 2087.08, "text": " That means that we should focus on the logs as well, and this is pretty common like for a price", "tokens": [663, 1355, 300, 321, 820, 1879, 322, 264, 20820, 382, 731, 11, 293, 341, 307, 1238, 2689, 411, 337, 257, 3218], "temperature": 0.0, "avg_logprob": -0.11779091404933556, "compression_ratio": 1.9276018099547512, "no_speech_prob": 4.7108810576901305e-06}, {"id": 408, "seek": 208708, "start": 2087.08, "end": 2093.2, "text": " Generally you care not so much about did I miss by $10, but did I miss by 10% right?", "tokens": [21082, 291, 1127, 406, 370, 709, 466, 630, 286, 1713, 538, 1848, 3279, 11, 457, 630, 286, 1713, 538, 1266, 4, 558, 30], "temperature": 0.0, "avg_logprob": -0.1752751179230519, "compression_ratio": 1.8415094339622642, "no_speech_prob": 6.513003114605453e-08}, {"id": 409, "seek": 208708, "start": 2093.2, "end": 2098.44, "text": " So if it was a million dollar thing and you're a hundred thousand dollars off or if you're it's a ten thousand dollar thing and you're", "tokens": [407, 498, 309, 390, 257, 2459, 7241, 551, 293, 291, 434, 257, 3262, 4714, 3808, 766, 420, 498, 291, 434, 309, 311, 257, 2064, 4714, 7241, 551, 293, 291, 434], "temperature": 0.0, "avg_logprob": -0.1752751179230519, "compression_ratio": 1.8415094339622642, "no_speech_prob": 6.513003114605453e-08}, {"id": 410, "seek": 208708, "start": 2098.44, "end": 2103.66, "text": " A thousand dollars off often we would consider those equivalent scale issues and so for this", "tokens": [316, 4714, 3808, 766, 2049, 321, 576, 1949, 729, 10344, 4373, 2663, 293, 370, 337, 341], "temperature": 0.0, "avg_logprob": -0.1752751179230519, "compression_ratio": 1.8415094339622642, "no_speech_prob": 6.513003114605453e-08}, {"id": 411, "seek": 208708, "start": 2104.44, "end": 2105.88, "text": " auction problem", "tokens": [24139, 1154], "temperature": 0.0, "avg_logprob": -0.1752751179230519, "compression_ratio": 1.8415094339622642, "no_speech_prob": 6.513003114605453e-08}, {"id": 412, "seek": 208708, "start": 2105.88, "end": 2112.66, "text": " The organizers are telling us they care about ratios more than differences and so the log is the thing we care about", "tokens": [440, 35071, 366, 3585, 505, 436, 1127, 466, 32435, 544, 813, 7300, 293, 370, 264, 3565, 307, 264, 551, 321, 1127, 466], "temperature": 0.0, "avg_logprob": -0.1752751179230519, "compression_ratio": 1.8415094339622642, "no_speech_prob": 6.513003114605453e-08}, {"id": 413, "seek": 211266, "start": 2112.66, "end": 2116.5, "text": " So the first thing I do is to take the log", "tokens": [407, 264, 700, 551, 286, 360, 307, 281, 747, 264, 3565], "temperature": 0.0, "avg_logprob": -0.18167999198844842, "compression_ratio": 1.6940298507462686, "no_speech_prob": 1.1015866903107963e-06}, {"id": 414, "seek": 211266, "start": 2117.08, "end": 2120.24, "text": " Okay, now NP is numpy", "tokens": [1033, 11, 586, 38611, 307, 1031, 8200], "temperature": 0.0, "avg_logprob": -0.18167999198844842, "compression_ratio": 1.6940298507462686, "no_speech_prob": 1.1015866903107963e-06}, {"id": 415, "seek": 211266, "start": 2120.24, "end": 2127.18, "text": " I'm assuming that you have some familiarity with numpy if you don't we've got a video called deep learning workshop", "tokens": [286, 478, 11926, 300, 291, 362, 512, 49828, 365, 1031, 8200, 498, 291, 500, 380, 321, 600, 658, 257, 960, 1219, 2452, 2539, 13541], "temperature": 0.0, "avg_logprob": -0.18167999198844842, "compression_ratio": 1.6940298507462686, "no_speech_prob": 1.1015866903107963e-06}, {"id": 416, "seek": 211266, "start": 2127.18, "end": 2132.6, "text": " Which actually isn't just for deep learning it's for a whole basically for this as well and one of the parts there", "tokens": [3013, 767, 1943, 380, 445, 337, 2452, 2539, 309, 311, 337, 257, 1379, 1936, 337, 341, 382, 731, 293, 472, 295, 264, 3166, 456], "temperature": 0.0, "avg_logprob": -0.18167999198844842, "compression_ratio": 1.6940298507462686, "no_speech_prob": 1.1015866903107963e-06}, {"id": 417, "seek": 211266, "start": 2132.7599999999998, "end": 2136.46, "text": " Which we've got a time coded link to is a quick introduction to numpy", "tokens": [3013, 321, 600, 658, 257, 565, 34874, 2113, 281, 307, 257, 1702, 9339, 281, 1031, 8200], "temperature": 0.0, "avg_logprob": -0.18167999198844842, "compression_ratio": 1.6940298507462686, "no_speech_prob": 1.1015866903107963e-06}, {"id": 418, "seek": 213646, "start": 2136.46, "end": 2144.2200000000003, "text": " Okay, but basically numpy lets us treat arrays matrices vectors high dimensional tensors as if they're Python", "tokens": [1033, 11, 457, 1936, 1031, 8200, 6653, 505, 2387, 41011, 32284, 18875, 1090, 18795, 10688, 830, 382, 498, 436, 434, 15329], "temperature": 0.0, "avg_logprob": -0.2146343370763267, "compression_ratio": 1.5, "no_speech_prob": 2.3687907741987146e-06}, {"id": 419, "seek": 213646, "start": 2144.58, "end": 2148.48, "text": " variables and we can do stuff like log to them and it'll apply it to", "tokens": [9102, 293, 321, 393, 360, 1507, 411, 3565, 281, 552, 293, 309, 603, 3079, 309, 281], "temperature": 0.0, "avg_logprob": -0.2146343370763267, "compression_ratio": 1.5, "no_speech_prob": 2.3687907741987146e-06}, {"id": 420, "seek": 213646, "start": 2149.78, "end": 2154.06, "text": " Everything numpy and pandas work together very nicely", "tokens": [5471, 1031, 8200, 293, 4565, 296, 589, 1214, 588, 9594], "temperature": 0.0, "avg_logprob": -0.2146343370763267, "compression_ratio": 1.5, "no_speech_prob": 2.3687907741987146e-06}, {"id": 421, "seek": 213646, "start": 2154.26, "end": 2160.96, "text": " So in this case DF raw dot sale price is pulling a column out of a pandas data frame", "tokens": [407, 294, 341, 1389, 48336, 8936, 5893, 8680, 3218, 307, 8407, 257, 7738, 484, 295, 257, 4565, 296, 1412, 3920], "temperature": 0.0, "avg_logprob": -0.2146343370763267, "compression_ratio": 1.5, "no_speech_prob": 2.3687907741987146e-06}, {"id": 422, "seek": 216096, "start": 2160.96, "end": 2165.96, "text": " which gives us a", "tokens": [597, 2709, 505, 257], "temperature": 0.0, "avg_logprob": -0.2589992915882784, "compression_ratio": 1.4968944099378882, "no_speech_prob": 6.786717676732223e-07}, {"id": 423, "seek": 216096, "start": 2169.04, "end": 2175.08, "text": " Pandas series right it shows us the sale prices and their indexes right and", "tokens": [16995, 296, 2638, 558, 309, 3110, 505, 264, 8680, 7901, 293, 641, 8186, 279, 558, 293], "temperature": 0.0, "avg_logprob": -0.2589992915882784, "compression_ratio": 1.4968944099378882, "no_speech_prob": 6.786717676732223e-07}, {"id": 424, "seek": 216096, "start": 2176.92, "end": 2179.8, "text": " A series can be passed to a numpy", "tokens": [316, 2638, 393, 312, 4678, 281, 257, 1031, 8200], "temperature": 0.0, "avg_logprob": -0.2589992915882784, "compression_ratio": 1.4968944099378882, "no_speech_prob": 6.786717676732223e-07}, {"id": 425, "seek": 216096, "start": 2180.7200000000003, "end": 2185.48, "text": " Function okay, which is pretty handy and so you can see here. This is how I can replace a", "tokens": [11166, 882, 1392, 11, 597, 307, 1238, 13239, 293, 370, 291, 393, 536, 510, 13, 639, 307, 577, 286, 393, 7406, 257], "temperature": 0.0, "avg_logprob": -0.2589992915882784, "compression_ratio": 1.4968944099378882, "no_speech_prob": 6.786717676732223e-07}, {"id": 426, "seek": 216096, "start": 2186.68, "end": 2188.68, "text": " column with a new column", "tokens": [7738, 365, 257, 777, 7738], "temperature": 0.0, "avg_logprob": -0.2589992915882784, "compression_ratio": 1.4968944099378882, "no_speech_prob": 6.786717676732223e-07}, {"id": 427, "seek": 218868, "start": 2188.68, "end": 2190.68, "text": " pretty easy", "tokens": [1238, 1858], "temperature": 0.0, "avg_logprob": -0.20409202575683594, "compression_ratio": 1.6538461538461537, "no_speech_prob": 2.726456386881182e-06}, {"id": 428, "seek": 218868, "start": 2190.7599999999998, "end": 2197.16, "text": " So okay now that we've replaced its sale price with its log we can go ahead and try to create a random forest", "tokens": [407, 1392, 586, 300, 321, 600, 10772, 1080, 8680, 3218, 365, 1080, 3565, 321, 393, 352, 2286, 293, 853, 281, 1884, 257, 4974, 6719], "temperature": 0.0, "avg_logprob": -0.20409202575683594, "compression_ratio": 1.6538461538461537, "no_speech_prob": 2.726456386881182e-06}, {"id": 429, "seek": 218868, "start": 2197.52, "end": 2199.52, "text": " What's a random first?", "tokens": [708, 311, 257, 4974, 700, 30], "temperature": 0.0, "avg_logprob": -0.20409202575683594, "compression_ratio": 1.6538461538461537, "no_speech_prob": 2.726456386881182e-06}, {"id": 430, "seek": 218868, "start": 2199.68, "end": 2204.2599999999998, "text": " we'll find out in detail, but in brief a random forest is a", "tokens": [321, 603, 915, 484, 294, 2607, 11, 457, 294, 5353, 257, 4974, 6719, 307, 257], "temperature": 0.0, "avg_logprob": -0.20409202575683594, "compression_ratio": 1.6538461538461537, "no_speech_prob": 2.726456386881182e-06}, {"id": 431, "seek": 218868, "start": 2205.0, "end": 2211.56, "text": " Kind of universal machine learning technique. It's a way of predicting something that can be of any kind", "tokens": [9242, 295, 11455, 3479, 2539, 6532, 13, 467, 311, 257, 636, 295, 32884, 746, 300, 393, 312, 295, 604, 733], "temperature": 0.0, "avg_logprob": -0.20409202575683594, "compression_ratio": 1.6538461538461537, "no_speech_prob": 2.726456386881182e-06}, {"id": 432, "seek": 218868, "start": 2211.7599999999998, "end": 2213.7599999999998, "text": " It could be a category", "tokens": [467, 727, 312, 257, 7719], "temperature": 0.0, "avg_logprob": -0.20409202575683594, "compression_ratio": 1.6538461538461537, "no_speech_prob": 2.726456386881182e-06}, {"id": 433, "seek": 218868, "start": 2213.7999999999997, "end": 2217.8399999999997, "text": " Like is it a dog or a cat or it could be a continuous?", "tokens": [1743, 307, 309, 257, 3000, 420, 257, 3857, 420, 309, 727, 312, 257, 10957, 30], "temperature": 0.0, "avg_logprob": -0.20409202575683594, "compression_ratio": 1.6538461538461537, "no_speech_prob": 2.726456386881182e-06}, {"id": 434, "seek": 221784, "start": 2217.84, "end": 2218.88, "text": " continuous", "tokens": [10957], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 435, "seek": 221784, "start": 2218.88, "end": 2220.88, "text": " continuous variable like price", "tokens": [10957, 7006, 411, 3218], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 436, "seek": 221784, "start": 2221.44, "end": 2225.44, "text": " It can predict it with columns of pretty much any kind", "tokens": [467, 393, 6069, 309, 365, 13766, 295, 1238, 709, 604, 733], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 437, "seek": 221784, "start": 2226.44, "end": 2227.8, "text": " pixel data", "tokens": [19261, 1412], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 438, "seek": 221784, "start": 2227.8, "end": 2229.8, "text": " zip codes", "tokens": [20730, 14211], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 439, "seek": 221784, "start": 2229.88, "end": 2231.88, "text": " revenues whatever", "tokens": [27299, 2035], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 440, "seek": 221784, "start": 2232.2000000000003, "end": 2233.6000000000004, "text": " in", "tokens": [294], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 441, "seek": 221784, "start": 2233.6000000000004, "end": 2241.1200000000003, "text": " General it doesn't overfit it can and we'll learn to check whether it is but it doesn't generally overfit too badly", "tokens": [6996, 309, 1177, 380, 670, 6845, 309, 393, 293, 321, 603, 1466, 281, 1520, 1968, 309, 307, 457, 309, 1177, 380, 5101, 670, 6845, 886, 13425], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 442, "seek": 221784, "start": 2241.1200000000003, "end": 2243.88, "text": " And it's very very easy to make to stop it from overfitting", "tokens": [400, 309, 311, 588, 588, 1858, 281, 652, 281, 1590, 309, 490, 670, 69, 2414], "temperature": 0.0, "avg_logprob": -0.2541564532688686, "compression_ratio": 1.6020408163265305, "no_speech_prob": 9.97283132164739e-06}, {"id": 443, "seek": 224388, "start": 2243.88, "end": 2249.8, "text": " You don't need and we'll talk more about this you don't need a separate validation set in general", "tokens": [509, 500, 380, 643, 293, 321, 603, 751, 544, 466, 341, 291, 500, 380, 643, 257, 4994, 24071, 992, 294, 2674], "temperature": 0.0, "avg_logprob": -0.14974007239708534, "compression_ratio": 1.8054298642533937, "no_speech_prob": 2.6425725536682876e-06}, {"id": 444, "seek": 224388, "start": 2249.8, "end": 2254.1600000000003, "text": " It can tell you how well it generalizes even if you only have one data set", "tokens": [467, 393, 980, 291, 577, 731, 309, 2674, 5660, 754, 498, 291, 787, 362, 472, 1412, 992], "temperature": 0.0, "avg_logprob": -0.14974007239708534, "compression_ratio": 1.8054298642533937, "no_speech_prob": 2.6425725536682876e-06}, {"id": 445, "seek": 224388, "start": 2254.92, "end": 2261.36, "text": " It has few if any statistical assumptions. It doesn't assume that your data is normally distributed", "tokens": [467, 575, 1326, 498, 604, 22820, 17695, 13, 467, 1177, 380, 6552, 300, 428, 1412, 307, 5646, 12631], "temperature": 0.0, "avg_logprob": -0.14974007239708534, "compression_ratio": 1.8054298642533937, "no_speech_prob": 2.6425725536682876e-06}, {"id": 446, "seek": 224388, "start": 2261.36, "end": 2267.1400000000003, "text": " It doesn't assume that the relationships are linear. It doesn't assume that you've just specified the interactions", "tokens": [467, 1177, 380, 6552, 300, 264, 6159, 366, 8213, 13, 467, 1177, 380, 6552, 300, 291, 600, 445, 22206, 264, 13280], "temperature": 0.0, "avg_logprob": -0.14974007239708534, "compression_ratio": 1.8054298642533937, "no_speech_prob": 2.6425725536682876e-06}, {"id": 447, "seek": 224388, "start": 2267.84, "end": 2269.84, "text": " it requires", "tokens": [309, 7029], "temperature": 0.0, "avg_logprob": -0.14974007239708534, "compression_ratio": 1.8054298642533937, "no_speech_prob": 2.6425725536682876e-06}, {"id": 448, "seek": 226984, "start": 2269.84, "end": 2275.4, "text": " Very few pieces of feature engineering for many different types of situation", "tokens": [4372, 1326, 3755, 295, 4111, 7043, 337, 867, 819, 3467, 295, 2590], "temperature": 0.0, "avg_logprob": -0.1977498701640538, "compression_ratio": 1.6564625850340136, "no_speech_prob": 4.784978955285624e-06}, {"id": 449, "seek": 226984, "start": 2275.4, "end": 2280.2400000000002, "text": " You don't have to take the log of the data. You don't have to model play interactions together. So in other words", "tokens": [509, 500, 380, 362, 281, 747, 264, 3565, 295, 264, 1412, 13, 509, 500, 380, 362, 281, 2316, 862, 13280, 1214, 13, 407, 294, 661, 2283], "temperature": 0.0, "avg_logprob": -0.1977498701640538, "compression_ratio": 1.6564625850340136, "no_speech_prob": 4.784978955285624e-06}, {"id": 450, "seek": 226984, "start": 2280.88, "end": 2285.1200000000003, "text": " It's a great place to start right if your first random forest", "tokens": [467, 311, 257, 869, 1081, 281, 722, 558, 498, 428, 700, 4974, 6719], "temperature": 0.0, "avg_logprob": -0.1977498701640538, "compression_ratio": 1.6564625850340136, "no_speech_prob": 4.784978955285624e-06}, {"id": 451, "seek": 226984, "start": 2285.56, "end": 2292.36, "text": " Does very little useful then that's a sign that there might be problems with your data like it's designed to work pretty much", "tokens": [4402, 588, 707, 4420, 550, 300, 311, 257, 1465, 300, 456, 1062, 312, 2740, 365, 428, 1412, 411, 309, 311, 4761, 281, 589, 1238, 709], "temperature": 0.0, "avg_logprob": -0.1977498701640538, "compression_ratio": 1.6564625850340136, "no_speech_prob": 4.784978955285624e-06}, {"id": 452, "seek": 226984, "start": 2292.36, "end": 2295.52, "text": " First off, can you please throw it at or towards this gentleman? Thank you", "tokens": [2386, 766, 11, 393, 291, 1767, 3507, 309, 412, 420, 3030, 341, 15761, 30, 1044, 291], "temperature": 0.0, "avg_logprob": -0.1977498701640538, "compression_ratio": 1.6564625850340136, "no_speech_prob": 4.784978955285624e-06}, {"id": 453, "seek": 229552, "start": 2295.52, "end": 2299.92, "text": " What about curse of the national? Yeah", "tokens": [708, 466, 17139, 295, 264, 4048, 30, 865], "temperature": 0.0, "avg_logprob": -0.3037787611766528, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.5007712995138718e-06}, {"id": 454, "seek": 229552, "start": 2300.8, "end": 2304.84, "text": " Yeah, great question. So there's this concept of curse of dimensionality", "tokens": [865, 11, 869, 1168, 13, 407, 456, 311, 341, 3410, 295, 17139, 295, 10139, 1860], "temperature": 0.0, "avg_logprob": -0.3037787611766528, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.5007712995138718e-06}, {"id": 455, "seek": 229552, "start": 2304.84, "end": 2310.04, "text": " In fact, there's two concepts I'll touch on curse of dimensionality and the no free lunch theorem", "tokens": [682, 1186, 11, 456, 311, 732, 10392, 286, 603, 2557, 322, 17139, 295, 10139, 1860, 293, 264, 572, 1737, 6349, 20904], "temperature": 0.0, "avg_logprob": -0.3037787611766528, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.5007712995138718e-06}, {"id": 456, "seek": 229552, "start": 2310.04, "end": 2312.8, "text": " These are two concepts. You'll often hear a lot about", "tokens": [1981, 366, 732, 10392, 13, 509, 603, 2049, 1568, 257, 688, 466], "temperature": 0.0, "avg_logprob": -0.3037787611766528, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.5007712995138718e-06}, {"id": 457, "seek": 229552, "start": 2314.2, "end": 2317.86, "text": " They're both largely meaningless and basically stupid", "tokens": [814, 434, 1293, 11611, 33232, 293, 1936, 6631], "temperature": 0.0, "avg_logprob": -0.3037787611766528, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.5007712995138718e-06}, {"id": 458, "seek": 229552, "start": 2319.04, "end": 2321.04, "text": " and yet I", "tokens": [293, 1939, 286], "temperature": 0.0, "avg_logprob": -0.3037787611766528, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.5007712995138718e-06}, {"id": 459, "seek": 229552, "start": 2321.12, "end": 2323.6, "text": " Would say maybe the majority of people in the field", "tokens": [6068, 584, 1310, 264, 6286, 295, 561, 294, 264, 2519], "temperature": 0.0, "avg_logprob": -0.3037787611766528, "compression_ratio": 1.6995515695067265, "no_speech_prob": 3.5007712995138718e-06}, {"id": 460, "seek": 232360, "start": 2323.6, "end": 2327.7599999999998, "text": " Not only don't know that but think the opposite so it's well worth explaining", "tokens": [1726, 787, 500, 380, 458, 300, 457, 519, 264, 6182, 370, 309, 311, 731, 3163, 13468], "temperature": 0.0, "avg_logprob": -0.17817468996401187, "compression_ratio": 1.7116788321167884, "no_speech_prob": 1.7880520317703485e-06}, {"id": 461, "seek": 232360, "start": 2328.2, "end": 2332.0, "text": " The curse of dimensionality is this idea that the more columns you have", "tokens": [440, 17139, 295, 10139, 1860, 307, 341, 1558, 300, 264, 544, 13766, 291, 362], "temperature": 0.0, "avg_logprob": -0.17817468996401187, "compression_ratio": 1.7116788321167884, "no_speech_prob": 1.7880520317703485e-06}, {"id": 462, "seek": 232360, "start": 2332.7599999999998, "end": 2339.08, "text": " It basically creates a space that's more and more empty and there's this kind of fascinating mathematical", "tokens": [467, 1936, 7829, 257, 1901, 300, 311, 544, 293, 544, 6707, 293, 456, 311, 341, 733, 295, 10343, 18894], "temperature": 0.0, "avg_logprob": -0.17817468996401187, "compression_ratio": 1.7116788321167884, "no_speech_prob": 1.7880520317703485e-06}, {"id": 463, "seek": 232360, "start": 2339.64, "end": 2345.48, "text": " Idea, which is the more dimensions you have the more all of the points sit on the edge of that space", "tokens": [47245, 11, 597, 307, 264, 544, 12819, 291, 362, 264, 544, 439, 295, 264, 2793, 1394, 322, 264, 4691, 295, 300, 1901], "temperature": 0.0, "avg_logprob": -0.17817468996401187, "compression_ratio": 1.7116788321167884, "no_speech_prob": 1.7880520317703485e-06}, {"id": 464, "seek": 232360, "start": 2345.72, "end": 2346.2799999999997, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.17817468996401187, "compression_ratio": 1.7116788321167884, "no_speech_prob": 1.7880520317703485e-06}, {"id": 465, "seek": 232360, "start": 2346.2799999999997, "end": 2352.0, "text": " So if you've just got a single dimension where things are like random then they're spread out all over", "tokens": [407, 498, 291, 600, 445, 658, 257, 2167, 10139, 689, 721, 366, 411, 4974, 550, 436, 434, 3974, 484, 439, 670], "temperature": 0.0, "avg_logprob": -0.17817468996401187, "compression_ratio": 1.7116788321167884, "no_speech_prob": 1.7880520317703485e-06}, {"id": 466, "seek": 235200, "start": 2352.0, "end": 2358.8, "text": " Right where else if it's a square then the probability that they're in the middle means that they can't have been on the edge of either", "tokens": [1779, 689, 1646, 498, 309, 311, 257, 3732, 550, 264, 8482, 300, 436, 434, 294, 264, 2808, 1355, 300, 436, 393, 380, 362, 668, 322, 264, 4691, 295, 2139], "temperature": 0.0, "avg_logprob": -0.17907916893393305, "compression_ratio": 1.9657794676806084, "no_speech_prob": 3.668796807687613e-06}, {"id": 467, "seek": 235200, "start": 2358.92, "end": 2361.88, "text": " Dimension so it's a little bit less likely that they're not on the edge", "tokens": [20975, 3378, 370, 309, 311, 257, 707, 857, 1570, 3700, 300, 436, 434, 406, 322, 264, 4691], "temperature": 0.0, "avg_logprob": -0.17907916893393305, "compression_ratio": 1.9657794676806084, "no_speech_prob": 3.668796807687613e-06}, {"id": 468, "seek": 235200, "start": 2362.32, "end": 2369.48, "text": " Each dimension you add it becomes more applicatively less likely that the point isn't on the edge of at least one dimension", "tokens": [6947, 10139, 291, 909, 309, 3643, 544, 2580, 19020, 1570, 3700, 300, 264, 935, 1943, 380, 322, 264, 4691, 295, 412, 1935, 472, 10139], "temperature": 0.0, "avg_logprob": -0.17907916893393305, "compression_ratio": 1.9657794676806084, "no_speech_prob": 3.668796807687613e-06}, {"id": 469, "seek": 235200, "start": 2369.48, "end": 2373.6, "text": " right and so basically in high dimensions everything sits on the edge and", "tokens": [558, 293, 370, 1936, 294, 1090, 12819, 1203, 12696, 322, 264, 4691, 293], "temperature": 0.0, "avg_logprob": -0.17907916893393305, "compression_ratio": 1.9657794676806084, "no_speech_prob": 3.668796807687613e-06}, {"id": 470, "seek": 235200, "start": 2374.0, "end": 2379.28, "text": " What that means in theory is that the distance between points is much less meaningful?", "tokens": [708, 300, 1355, 294, 5261, 307, 300, 264, 4560, 1296, 2793, 307, 709, 1570, 10995, 30], "temperature": 0.0, "avg_logprob": -0.17907916893393305, "compression_ratio": 1.9657794676806084, "no_speech_prob": 3.668796807687613e-06}, {"id": 471, "seek": 237928, "start": 2379.28, "end": 2385.52, "text": " and so if we assume that somehow that matters then it would suggest that when you've got lots and lots of", "tokens": [293, 370, 498, 321, 6552, 300, 6063, 300, 7001, 550, 309, 576, 3402, 300, 562, 291, 600, 658, 3195, 293, 3195, 295], "temperature": 0.0, "avg_logprob": -0.11416156693260268, "compression_ratio": 1.7206477732793521, "no_speech_prob": 7.766838280076627e-06}, {"id": 472, "seek": 237928, "start": 2385.96, "end": 2393.0800000000004, "text": " Columns and you just use them without being very careful to remove the ones you don't care about that somehow things won't work", "tokens": [4004, 449, 3695, 293, 291, 445, 764, 552, 1553, 885, 588, 5026, 281, 4159, 264, 2306, 291, 500, 380, 1127, 466, 300, 6063, 721, 1582, 380, 589], "temperature": 0.0, "avg_logprob": -0.11416156693260268, "compression_ratio": 1.7206477732793521, "no_speech_prob": 7.766838280076627e-06}, {"id": 473, "seek": 237928, "start": 2394.36, "end": 2396.86, "text": " That turns out just not to be the case", "tokens": [663, 4523, 484, 445, 406, 281, 312, 264, 1389], "temperature": 0.0, "avg_logprob": -0.11416156693260268, "compression_ratio": 1.7206477732793521, "no_speech_prob": 7.766838280076627e-06}, {"id": 474, "seek": 237928, "start": 2398.4, "end": 2400.4, "text": " It's not the case for a number of reasons", "tokens": [467, 311, 406, 264, 1389, 337, 257, 1230, 295, 4112], "temperature": 0.0, "avg_logprob": -0.11416156693260268, "compression_ratio": 1.7206477732793521, "no_speech_prob": 7.766838280076627e-06}, {"id": 475, "seek": 237928, "start": 2400.7200000000003, "end": 2406.92, "text": " One is that the points still do have different distances away from each other just because they're on the edge", "tokens": [1485, 307, 300, 264, 2793, 920, 360, 362, 819, 22182, 1314, 490, 1184, 661, 445, 570, 436, 434, 322, 264, 4691], "temperature": 0.0, "avg_logprob": -0.11416156693260268, "compression_ratio": 1.7206477732793521, "no_speech_prob": 7.766838280076627e-06}, {"id": 476, "seek": 240692, "start": 2406.92, "end": 2412.52, "text": " They still do vary in how far away they are from each other and so this point is more similar to this point", "tokens": [814, 920, 360, 10559, 294, 577, 1400, 1314, 436, 366, 490, 1184, 661, 293, 370, 341, 935, 307, 544, 2531, 281, 341, 935], "temperature": 0.0, "avg_logprob": -0.18470991134643555, "compression_ratio": 1.7843866171003717, "no_speech_prob": 2.8291199782870535e-07}, {"id": 477, "seek": 240692, "start": 2412.56, "end": 2417.88, "text": " Than it is to that point so even things will learn about k nearest neighbors actually work really well", "tokens": [18289, 309, 307, 281, 300, 935, 370, 754, 721, 486, 1466, 466, 350, 23831, 12512, 767, 589, 534, 731], "temperature": 0.0, "avg_logprob": -0.18470991134643555, "compression_ratio": 1.7843866171003717, "no_speech_prob": 2.8291199782870535e-07}, {"id": 478, "seek": 240692, "start": 2418.16, "end": 2425.84, "text": " Really really well in high dimensions despite what the theoreticians claimed and what really happened here was that in the 90s?", "tokens": [4083, 534, 731, 294, 1090, 12819, 7228, 437, 264, 14308, 8455, 12941, 293, 437, 534, 2011, 510, 390, 300, 294, 264, 4289, 82, 30], "temperature": 0.0, "avg_logprob": -0.18470991134643555, "compression_ratio": 1.7843866171003717, "no_speech_prob": 2.8291199782870535e-07}, {"id": 479, "seek": 240692, "start": 2426.56, "end": 2428.56, "text": " theory totally took over", "tokens": [5261, 3879, 1890, 670], "temperature": 0.0, "avg_logprob": -0.18470991134643555, "compression_ratio": 1.7843866171003717, "no_speech_prob": 2.8291199782870535e-07}, {"id": 480, "seek": 240692, "start": 2429.84, "end": 2434.96, "text": " Machine learning and so particularly there was this concept of these things called support vector machines that were", "tokens": [22155, 2539, 293, 370, 4098, 456, 390, 341, 3410, 295, 613, 721, 1219, 1406, 8062, 8379, 300, 645], "temperature": 0.0, "avg_logprob": -0.18470991134643555, "compression_ratio": 1.7843866171003717, "no_speech_prob": 2.8291199782870535e-07}, {"id": 481, "seek": 243496, "start": 2434.96, "end": 2442.48, "text": " Theoretically very well justified extremely easy to analyze mathematically and you could like kind of prove things about them and", "tokens": [440, 26262, 984, 588, 731, 27808, 4664, 1858, 281, 12477, 44003, 293, 291, 727, 411, 733, 295, 7081, 721, 466, 552, 293], "temperature": 0.0, "avg_logprob": -0.22348399957021078, "compression_ratio": 1.7191011235955056, "no_speech_prob": 5.338104983820813e-06}, {"id": 482, "seek": 243496, "start": 2442.8, "end": 2447.86, "text": " We kind of lost a decade of real practical development in my opinion and all these theories", "tokens": [492, 733, 295, 2731, 257, 10378, 295, 957, 8496, 3250, 294, 452, 4800, 293, 439, 613, 13667], "temperature": 0.0, "avg_logprob": -0.22348399957021078, "compression_ratio": 1.7191011235955056, "no_speech_prob": 5.338104983820813e-06}, {"id": 483, "seek": 243496, "start": 2448.44, "end": 2450.7200000000003, "text": " Became very popular like the curse of dimensionality", "tokens": [879, 3005, 588, 3743, 411, 264, 17139, 295, 10139, 1860], "temperature": 0.0, "avg_logprob": -0.22348399957021078, "compression_ratio": 1.7191011235955056, "no_speech_prob": 5.338104983820813e-06}, {"id": 484, "seek": 243496, "start": 2451.96, "end": 2453.16, "text": " nowadays", "tokens": [13434], "temperature": 0.0, "avg_logprob": -0.22348399957021078, "compression_ratio": 1.7191011235955056, "no_speech_prob": 5.338104983820813e-06}, {"id": 485, "seek": 243496, "start": 2453.16, "end": 2459.16, "text": " And a lot of theoreticians hate this the the world of machine learning has become very empirical", "tokens": [400, 257, 688, 295, 14308, 8455, 4700, 341, 264, 264, 1002, 295, 3479, 2539, 575, 1813, 588, 31886], "temperature": 0.0, "avg_logprob": -0.22348399957021078, "compression_ratio": 1.7191011235955056, "no_speech_prob": 5.338104983820813e-06}, {"id": 486, "seek": 243496, "start": 2459.16, "end": 2462.88, "text": " Which is like which techniques actually work and it turns out that in practice", "tokens": [3013, 307, 411, 597, 7512, 767, 589, 293, 309, 4523, 484, 300, 294, 3124], "temperature": 0.0, "avg_logprob": -0.22348399957021078, "compression_ratio": 1.7191011235955056, "no_speech_prob": 5.338104983820813e-06}, {"id": 487, "seek": 246288, "start": 2462.88, "end": 2466.76, "text": " Building models on lots and lots of columns works really really well", "tokens": [18974, 5245, 322, 3195, 293, 3195, 295, 13766, 1985, 534, 534, 731], "temperature": 0.0, "avg_logprob": -0.14383217384075297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7264500204182696e-06}, {"id": 488, "seek": 246288, "start": 2468.6, "end": 2472.2000000000003, "text": " So yeah, the other thing to quickly mention is the no free lunch theorem", "tokens": [407, 1338, 11, 264, 661, 551, 281, 2661, 2152, 307, 264, 572, 1737, 6349, 20904], "temperature": 0.0, "avg_logprob": -0.14383217384075297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7264500204182696e-06}, {"id": 489, "seek": 246288, "start": 2472.6, "end": 2478.1600000000003, "text": " There's a mathematical theorem by that name that you will often hear about that claims that", "tokens": [821, 311, 257, 18894, 20904, 538, 300, 1315, 300, 291, 486, 2049, 1568, 466, 300, 9441, 300], "temperature": 0.0, "avg_logprob": -0.14383217384075297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7264500204182696e-06}, {"id": 490, "seek": 246288, "start": 2479.2000000000003, "end": 2484.84, "text": " There is no type of model that works well for any kind of data set", "tokens": [821, 307, 572, 2010, 295, 2316, 300, 1985, 731, 337, 604, 733, 295, 1412, 992], "temperature": 0.0, "avg_logprob": -0.14383217384075297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7264500204182696e-06}, {"id": 491, "seek": 246288, "start": 2486.0, "end": 2490.84, "text": " Which is true and is obviously true if you think about it in the mathematical sense", "tokens": [3013, 307, 2074, 293, 307, 2745, 2074, 498, 291, 519, 466, 309, 294, 264, 18894, 2020], "temperature": 0.0, "avg_logprob": -0.14383217384075297, "compression_ratio": 1.7142857142857142, "no_speech_prob": 2.7264500204182696e-06}, {"id": 492, "seek": 249084, "start": 2490.84, "end": 2499.08, "text": " Any random data set by definition? It's random right so there isn't going to be some way of looking at every possible random data set", "tokens": [2639, 4974, 1412, 992, 538, 7123, 30, 467, 311, 4974, 558, 370, 456, 1943, 380, 516, 281, 312, 512, 636, 295, 1237, 412, 633, 1944, 4974, 1412, 992], "temperature": 0.0, "avg_logprob": -0.19881781711373278, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.144109192973701e-06}, {"id": 493, "seek": 249084, "start": 2499.08, "end": 2504.7200000000003, "text": " That's in some way more useful than any other approach in the real world we look at data", "tokens": [663, 311, 294, 512, 636, 544, 4420, 813, 604, 661, 3109, 294, 264, 957, 1002, 321, 574, 412, 1412], "temperature": 0.0, "avg_logprob": -0.19881781711373278, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.144109192973701e-06}, {"id": 494, "seek": 249084, "start": 2504.8, "end": 2506.8, "text": " Which is not random", "tokens": [3013, 307, 406, 4974], "temperature": 0.0, "avg_logprob": -0.19881781711373278, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.144109192973701e-06}, {"id": 495, "seek": 249084, "start": 2506.84, "end": 2511.76, "text": " Mathematically we'd say it sits on some lower dimensional manifold. It was created by some kind of", "tokens": [15776, 40197, 321, 1116, 584, 309, 12696, 322, 512, 3126, 18795, 47138, 13, 467, 390, 2942, 538, 512, 733, 295], "temperature": 0.0, "avg_logprob": -0.19881781711373278, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.144109192973701e-06}, {"id": 496, "seek": 249084, "start": 2512.88, "end": 2516.2400000000002, "text": " Cause all structure right there are some relationships in there", "tokens": [10865, 439, 3877, 558, 456, 366, 512, 6159, 294, 456], "temperature": 0.0, "avg_logprob": -0.19881781711373278, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.144109192973701e-06}, {"id": 497, "seek": 251624, "start": 2516.24, "end": 2522.3999999999996, "text": " So the truth is that we're not using random data sets and so the truth is in the real world", "tokens": [407, 264, 3494, 307, 300, 321, 434, 406, 1228, 4974, 1412, 6352, 293, 370, 264, 3494, 307, 294, 264, 957, 1002], "temperature": 0.0, "avg_logprob": -0.16770283381144205, "compression_ratio": 1.8080357142857142, "no_speech_prob": 2.5612271201680414e-06}, {"id": 498, "seek": 251624, "start": 2522.4799999999996, "end": 2529.08, "text": " There are actually techniques that work much better than other techniques for nearly all of the data sets you look at", "tokens": [821, 366, 767, 7512, 300, 589, 709, 1101, 813, 661, 7512, 337, 6217, 439, 295, 264, 1412, 6352, 291, 574, 412], "temperature": 0.0, "avg_logprob": -0.16770283381144205, "compression_ratio": 1.8080357142857142, "no_speech_prob": 2.5612271201680414e-06}, {"id": 499, "seek": 251624, "start": 2529.8799999999997, "end": 2531.8799999999997, "text": " and nowadays there are", "tokens": [293, 13434, 456, 366], "temperature": 0.0, "avg_logprob": -0.16770283381144205, "compression_ratio": 1.8080357142857142, "no_speech_prob": 2.5612271201680414e-06}, {"id": 500, "seek": 251624, "start": 2532.4799999999996, "end": 2539.4799999999996, "text": " empirical researchers who spend a lot of time studying this which is which techniques work a lot of the time and", "tokens": [31886, 10309, 567, 3496, 257, 688, 295, 565, 7601, 341, 597, 307, 597, 7512, 589, 257, 688, 295, 264, 565, 293], "temperature": 0.0, "avg_logprob": -0.16770283381144205, "compression_ratio": 1.8080357142857142, "no_speech_prob": 2.5612271201680414e-06}, {"id": 501, "seek": 253948, "start": 2539.48, "end": 2544.78, "text": " On some balls of decision trees of which random forests are one", "tokens": [1282, 512, 9803, 295, 3537, 5852, 295, 597, 4974, 21700, 366, 472], "temperature": 0.0, "avg_logprob": -0.23169211454169694, "compression_ratio": 1.6304347826086956, "no_speech_prob": 1.184280790766934e-05}, {"id": 502, "seek": 253948, "start": 2545.36, "end": 2551.3, "text": " It is perhaps the technique which most often comes up the top and that is despite the fact that", "tokens": [467, 307, 4317, 264, 6532, 597, 881, 2049, 1487, 493, 264, 1192, 293, 300, 307, 7228, 264, 1186, 300], "temperature": 0.0, "avg_logprob": -0.23169211454169694, "compression_ratio": 1.6304347826086956, "no_speech_prob": 1.184280790766934e-05}, {"id": 503, "seek": 253948, "start": 2552.56, "end": 2558.98, "text": " Until the library that we're showing you today fast AI came along there wasn't really any standard way to pre process them properly", "tokens": [9088, 264, 6405, 300, 321, 434, 4099, 291, 965, 2370, 7318, 1361, 2051, 456, 2067, 380, 534, 604, 3832, 636, 281, 659, 1399, 552, 6108], "temperature": 0.0, "avg_logprob": -0.23169211454169694, "compression_ratio": 1.6304347826086956, "no_speech_prob": 1.184280790766934e-05}, {"id": 504, "seek": 253948, "start": 2559.4, "end": 2565.18, "text": " And to properly set their parameters, so I think it's even more strong than that", "tokens": [400, 281, 6108, 992, 641, 9834, 11, 370, 286, 519, 309, 311, 754, 544, 2068, 813, 300], "temperature": 0.0, "avg_logprob": -0.23169211454169694, "compression_ratio": 1.6304347826086956, "no_speech_prob": 1.184280790766934e-05}, {"id": 505, "seek": 253948, "start": 2566.48, "end": 2567.76, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.23169211454169694, "compression_ratio": 1.6304347826086956, "no_speech_prob": 1.184280790766934e-05}, {"id": 506, "seek": 256776, "start": 2567.76, "end": 2572.5600000000004, "text": " Yeah, I think this is where the difference between theory and practice is is is huge", "tokens": [865, 11, 286, 519, 341, 307, 689, 264, 2649, 1296, 5261, 293, 3124, 307, 307, 307, 2603], "temperature": 0.0, "avg_logprob": -0.1953771525415881, "compression_ratio": 1.6192660550458715, "no_speech_prob": 6.540325557580218e-06}, {"id": 507, "seek": 256776, "start": 2574.5600000000004, "end": 2580.36, "text": " So when I try to create a random forest regressor, what is that random forest regressor?", "tokens": [407, 562, 286, 853, 281, 1884, 257, 4974, 6719, 1121, 735, 284, 11, 437, 307, 300, 4974, 6719, 1121, 735, 284, 30], "temperature": 0.0, "avg_logprob": -0.1953771525415881, "compression_ratio": 1.6192660550458715, "no_speech_prob": 6.540325557580218e-06}, {"id": 508, "seek": 256776, "start": 2580.88, "end": 2585.48, "text": " Okay, it's part of something called SK learn SK learn is scikit-learn", "tokens": [1033, 11, 309, 311, 644, 295, 746, 1219, 21483, 1466, 21483, 1466, 307, 2180, 22681, 12, 306, 1083], "temperature": 0.0, "avg_logprob": -0.1953771525415881, "compression_ratio": 1.6192660550458715, "no_speech_prob": 6.540325557580218e-06}, {"id": 509, "seek": 256776, "start": 2585.48, "end": 2592.0800000000004, "text": " It is by far the most popular and important package for machine learning in Python. It does nearly everything", "tokens": [467, 307, 538, 1400, 264, 881, 3743, 293, 1021, 7372, 337, 3479, 2539, 294, 15329, 13, 467, 775, 6217, 1203], "temperature": 0.0, "avg_logprob": -0.1953771525415881, "compression_ratio": 1.6192660550458715, "no_speech_prob": 6.540325557580218e-06}, {"id": 510, "seek": 259208, "start": 2592.08, "end": 2598.38, "text": " It's not the best at nearly everything, but it's perfectly good at nearly everything", "tokens": [467, 311, 406, 264, 1151, 412, 6217, 1203, 11, 457, 309, 311, 6239, 665, 412, 6217, 1203], "temperature": 0.0, "avg_logprob": -0.1578614422094042, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.136558125836018e-06}, {"id": 511, "seek": 259208, "start": 2598.38, "end": 2602.48, "text": " So like you might find in the next part of this course with your net", "tokens": [407, 411, 291, 1062, 915, 294, 264, 958, 644, 295, 341, 1164, 365, 428, 2533], "temperature": 0.0, "avg_logprob": -0.1578614422094042, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.136558125836018e-06}, {"id": 512, "seek": 259208, "start": 2602.48, "end": 2606.2, "text": " You're going to look at a different kind of decision tree ensemble called gradient boosting trees", "tokens": [509, 434, 516, 281, 574, 412, 257, 819, 733, 295, 3537, 4230, 19492, 1219, 16235, 43117, 5852], "temperature": 0.0, "avg_logprob": -0.1578614422094042, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.136558125836018e-06}, {"id": 513, "seek": 259208, "start": 2607.36, "end": 2609.36, "text": " Where actually there's something called", "tokens": [2305, 767, 456, 311, 746, 1219], "temperature": 0.0, "avg_logprob": -0.1578614422094042, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.136558125836018e-06}, {"id": 514, "seek": 259208, "start": 2610.16, "end": 2613.4, "text": " XG boost which is better than gradient boosting trees and scikit-learn", "tokens": [1783, 38, 9194, 597, 307, 1101, 813, 16235, 43117, 5852, 293, 2180, 22681, 12, 306, 1083], "temperature": 0.0, "avg_logprob": -0.1578614422094042, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.136558125836018e-06}, {"id": 515, "seek": 259208, "start": 2614.84, "end": 2619.24, "text": " But it's pretty good at everything so we're I'm really going to focus on scikit-learn", "tokens": [583, 309, 311, 1238, 665, 412, 1203, 370, 321, 434, 286, 478, 534, 516, 281, 1879, 322, 2180, 22681, 12, 306, 1083], "temperature": 0.0, "avg_logprob": -0.1578614422094042, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.136558125836018e-06}, {"id": 516, "seek": 261924, "start": 2619.24, "end": 2625.4399999999996, "text": " Random forest you can do two kinds of things with a random forest if I hit tab", "tokens": [37603, 6719, 291, 393, 360, 732, 3685, 295, 721, 365, 257, 4974, 6719, 498, 286, 2045, 4421], "temperature": 0.0, "avg_logprob": -0.23710253238677978, "compression_ratio": 1.60752688172043, "no_speech_prob": 6.747927272954257e-06}, {"id": 517, "seek": 261924, "start": 2626.24, "end": 2627.2, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.23710253238677978, "compression_ratio": 1.60752688172043, "no_speech_prob": 6.747927272954257e-06}, {"id": 518, "seek": 261924, "start": 2627.2, "end": 2631.2799999999997, "text": " Haven't imported it, so let's go back to where we import", "tokens": [23770, 380, 25524, 309, 11, 370, 718, 311, 352, 646, 281, 689, 321, 974], "temperature": 0.0, "avg_logprob": -0.23710253238677978, "compression_ratio": 1.60752688172043, "no_speech_prob": 6.747927272954257e-06}, {"id": 519, "seek": 261924, "start": 2638.14, "end": 2643.08, "text": " So you can hit tab in Jupyter Notebook to get tab completion for anything that's", "tokens": [407, 291, 393, 2045, 4421, 294, 22125, 88, 391, 11633, 2939, 281, 483, 4421, 19372, 337, 1340, 300, 311], "temperature": 0.0, "avg_logprob": -0.23710253238677978, "compression_ratio": 1.60752688172043, "no_speech_prob": 6.747927272954257e-06}, {"id": 520, "seek": 261924, "start": 2643.8799999999997, "end": 2647.56, "text": " In your environment, and you'll see that there's also a random forest classifier", "tokens": [682, 428, 2823, 11, 293, 291, 603, 536, 300, 456, 311, 611, 257, 4974, 6719, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.23710253238677978, "compression_ratio": 1.60752688172043, "no_speech_prob": 6.747927272954257e-06}, {"id": 521, "seek": 264756, "start": 2647.56, "end": 2657.24, "text": " so in general there's an important distinction between things which can predict continuous variables and that's called regression and", "tokens": [370, 294, 2674, 456, 311, 364, 1021, 16844, 1296, 721, 597, 393, 6069, 10957, 9102, 293, 300, 311, 1219, 24590, 293], "temperature": 0.0, "avg_logprob": -0.22952433065934616, "compression_ratio": 1.9315068493150684, "no_speech_prob": 3.50078835253953e-06}, {"id": 522, "seek": 264756, "start": 2657.48, "end": 2660.44, "text": " Therefore a method for doing that would be a regressor and", "tokens": [7504, 257, 3170, 337, 884, 300, 576, 312, 257, 1121, 735, 284, 293], "temperature": 0.0, "avg_logprob": -0.22952433065934616, "compression_ratio": 1.9315068493150684, "no_speech_prob": 3.50078835253953e-06}, {"id": 523, "seek": 264756, "start": 2661.16, "end": 2663.0, "text": " things that predict", "tokens": [721, 300, 6069], "temperature": 0.0, "avg_logprob": -0.22952433065934616, "compression_ratio": 1.9315068493150684, "no_speech_prob": 3.50078835253953e-06}, {"id": 524, "seek": 264756, "start": 2663.0, "end": 2664.64, "text": " categorical variables", "tokens": [19250, 804, 9102], "temperature": 0.0, "avg_logprob": -0.22952433065934616, "compression_ratio": 1.9315068493150684, "no_speech_prob": 3.50078835253953e-06}, {"id": 525, "seek": 264756, "start": 2664.64, "end": 2669.44, "text": " And that is called classification and the things that do that are called classifiers", "tokens": [400, 300, 307, 1219, 21538, 293, 264, 721, 300, 360, 300, 366, 1219, 1508, 23463], "temperature": 0.0, "avg_logprob": -0.22952433065934616, "compression_ratio": 1.9315068493150684, "no_speech_prob": 3.50078835253953e-06}, {"id": 526, "seek": 264756, "start": 2670.2, "end": 2676.16, "text": " So in our case we're trying to predict a continuous variable price so therefore we are doing regression", "tokens": [407, 294, 527, 1389, 321, 434, 1382, 281, 6069, 257, 10957, 7006, 3218, 370, 4412, 321, 366, 884, 24590], "temperature": 0.0, "avg_logprob": -0.22952433065934616, "compression_ratio": 1.9315068493150684, "no_speech_prob": 3.50078835253953e-06}, {"id": 527, "seek": 267616, "start": 2676.16, "end": 2678.8799999999997, "text": " And therefore we need a regressor a", "tokens": [400, 4412, 321, 643, 257, 1121, 735, 284, 257], "temperature": 0.0, "avg_logprob": -0.15587647417758374, "compression_ratio": 1.7103174603174602, "no_speech_prob": 4.637845904653659e-06}, {"id": 528, "seek": 267616, "start": 2679.72, "end": 2684.5, "text": " Lot of people incorrectly use the word regression to refer to linear regression", "tokens": [20131, 295, 561, 42892, 764, 264, 1349, 24590, 281, 2864, 281, 8213, 24590], "temperature": 0.0, "avg_logprob": -0.15587647417758374, "compression_ratio": 1.7103174603174602, "no_speech_prob": 4.637845904653659e-06}, {"id": 529, "seek": 267616, "start": 2684.64, "end": 2690.24, "text": " Which is just not at all true or appropriate regression means a machine learning model", "tokens": [3013, 307, 445, 406, 412, 439, 2074, 420, 6854, 24590, 1355, 257, 3479, 2539, 2316], "temperature": 0.0, "avg_logprob": -0.15587647417758374, "compression_ratio": 1.7103174603174602, "no_speech_prob": 4.637845904653659e-06}, {"id": 530, "seek": 267616, "start": 2690.24, "end": 2695.52, "text": " It's trying to predict some kind of continuous outcome. It has a continuous dependent variable", "tokens": [467, 311, 1382, 281, 6069, 512, 733, 295, 10957, 9700, 13, 467, 575, 257, 10957, 12334, 7006], "temperature": 0.0, "avg_logprob": -0.15587647417758374, "compression_ratio": 1.7103174603174602, "no_speech_prob": 4.637845904653659e-06}, {"id": 531, "seek": 267616, "start": 2696.8799999999997, "end": 2703.44, "text": " So pretty much everything in scikit-learn has the same form you first of all create an instance of an object for the machine learning", "tokens": [407, 1238, 709, 1203, 294, 2180, 22681, 12, 306, 1083, 575, 264, 912, 1254, 291, 700, 295, 439, 1884, 364, 5197, 295, 364, 2657, 337, 264, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.15587647417758374, "compression_ratio": 1.7103174603174602, "no_speech_prob": 4.637845904653659e-06}, {"id": 532, "seek": 270344, "start": 2703.44, "end": 2707.2000000000003, "text": " model you want you then call fit passing in the", "tokens": [2316, 291, 528, 291, 550, 818, 3318, 8437, 294, 264], "temperature": 0.0, "avg_logprob": -0.2268627678475729, "compression_ratio": 1.9281767955801106, "no_speech_prob": 2.058040990959853e-06}, {"id": 533, "seek": 270344, "start": 2708.52, "end": 2713.48, "text": " Independent variables the things you're going to use to predict and the dependent variable the thing that you want to predict", "tokens": [40310, 9102, 264, 721, 291, 434, 516, 281, 764, 281, 6069, 293, 264, 12334, 7006, 264, 551, 300, 291, 528, 281, 6069], "temperature": 0.0, "avg_logprob": -0.2268627678475729, "compression_ratio": 1.9281767955801106, "no_speech_prob": 2.058040990959853e-06}, {"id": 534, "seek": 270344, "start": 2713.52, "end": 2715.68, "text": " so in our case the dependent variable is", "tokens": [370, 294, 527, 1389, 264, 12334, 7006, 307], "temperature": 0.0, "avg_logprob": -0.2268627678475729, "compression_ratio": 1.9281767955801106, "no_speech_prob": 2.058040990959853e-06}, {"id": 535, "seek": 270344, "start": 2717.48, "end": 2719.48, "text": " Is", "tokens": [1119], "temperature": 0.0, "avg_logprob": -0.2268627678475729, "compression_ratio": 1.9281767955801106, "no_speech_prob": 2.058040990959853e-06}, {"id": 536, "seek": 270344, "start": 2719.64, "end": 2723.12, "text": " The data frames sale price column and", "tokens": [440, 1412, 12083, 8680, 3218, 7738, 293], "temperature": 0.0, "avg_logprob": -0.2268627678475729, "compression_ratio": 1.9281767955801106, "no_speech_prob": 2.058040990959853e-06}, {"id": 537, "seek": 270344, "start": 2723.76, "end": 2730.32, "text": " So we the thing we want to use to predict is everything except that in pandas the drop method", "tokens": [407, 321, 264, 551, 321, 528, 281, 764, 281, 6069, 307, 1203, 3993, 300, 294, 4565, 296, 264, 3270, 3170], "temperature": 0.0, "avg_logprob": -0.2268627678475729, "compression_ratio": 1.9281767955801106, "no_speech_prob": 2.058040990959853e-06}, {"id": 538, "seek": 273032, "start": 2730.32, "end": 2733.96, "text": " Returns a new data frame with a list of columns removed", "tokens": [24350, 82, 257, 777, 1412, 3920, 365, 257, 1329, 295, 13766, 7261], "temperature": 0.0, "avg_logprob": -0.20279313967778131, "compression_ratio": 1.6176470588235294, "no_speech_prob": 7.183170509961201e-06}, {"id": 539, "seek": 273032, "start": 2734.76, "end": 2740.2400000000002, "text": " Right well a list of rows or columns removed so axis equals one means remove columns", "tokens": [1779, 731, 257, 1329, 295, 13241, 420, 13766, 7261, 370, 10298, 6915, 472, 1355, 4159, 13766], "temperature": 0.0, "avg_logprob": -0.20279313967778131, "compression_ratio": 1.6176470588235294, "no_speech_prob": 7.183170509961201e-06}, {"id": 540, "seek": 273032, "start": 2740.36, "end": 2745.2000000000003, "text": " So this here is the data frame containing everything except for sale price", "tokens": [407, 341, 510, 307, 264, 1412, 3920, 19273, 1203, 3993, 337, 8680, 3218], "temperature": 0.0, "avg_logprob": -0.20279313967778131, "compression_ratio": 1.6176470588235294, "no_speech_prob": 7.183170509961201e-06}, {"id": 541, "seek": 273032, "start": 2745.92, "end": 2747.92, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.20279313967778131, "compression_ratio": 1.6176470588235294, "no_speech_prob": 7.183170509961201e-06}, {"id": 542, "seek": 274792, "start": 2747.92, "end": 2749.92, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.19070049812053813, "compression_ratio": 1.4335664335664335, "no_speech_prob": 7.296200237760786e-06}, {"id": 543, "seek": 274792, "start": 2759.0, "end": 2763.36, "text": " Let's find out so to find out I could hit shift tab and", "tokens": [961, 311, 915, 484, 370, 281, 915, 484, 286, 727, 2045, 5513, 4421, 293], "temperature": 0.0, "avg_logprob": -0.19070049812053813, "compression_ratio": 1.4335664335664335, "no_speech_prob": 7.296200237760786e-06}, {"id": 544, "seek": 274792, "start": 2764.2400000000002, "end": 2770.7200000000003, "text": " That will bring up the you know a quick inspection of the parameters in this case. It doesn't quite tell me what I want", "tokens": [663, 486, 1565, 493, 264, 291, 458, 257, 1702, 22085, 295, 264, 9834, 294, 341, 1389, 13, 467, 1177, 380, 1596, 980, 385, 437, 286, 528], "temperature": 0.0, "avg_logprob": -0.19070049812053813, "compression_ratio": 1.4335664335664335, "no_speech_prob": 7.296200237760786e-06}, {"id": 545, "seek": 274792, "start": 2771.6800000000003, "end": 2773.6800000000003, "text": " So if I hit shift tab twice", "tokens": [407, 498, 286, 2045, 5513, 4421, 6091], "temperature": 0.0, "avg_logprob": -0.19070049812053813, "compression_ratio": 1.4335664335664335, "no_speech_prob": 7.296200237760786e-06}, {"id": 546, "seek": 277368, "start": 2773.68, "end": 2780.3199999999997, "text": " It gives me a bit more information ah yes, and that tells me it's a single label or list like", "tokens": [467, 2709, 385, 257, 857, 544, 1589, 3716, 2086, 11, 293, 300, 5112, 385, 309, 311, 257, 2167, 7645, 420, 1329, 411], "temperature": 0.0, "avg_logprob": -0.18033004336886935, "compression_ratio": 1.6127659574468085, "no_speech_prob": 5.682330538547831e-06}, {"id": 547, "seek": 277368, "start": 2780.64, "end": 2786.56, "text": " List like means like anything you can index in Python there's lots of things by the way if I hit three times", "tokens": [17668, 411, 1355, 411, 1340, 291, 393, 8186, 294, 15329, 456, 311, 3195, 295, 721, 538, 264, 636, 498, 286, 2045, 1045, 1413], "temperature": 0.0, "avg_logprob": -0.18033004336886935, "compression_ratio": 1.6127659574468085, "no_speech_prob": 5.682330538547831e-06}, {"id": 548, "seek": 277368, "start": 2787.16, "end": 2791.04, "text": " It will give me a whole little window at the bottom okay, so that was shift tab", "tokens": [467, 486, 976, 385, 257, 1379, 707, 4910, 412, 264, 2767, 1392, 11, 370, 300, 390, 5513, 4421], "temperature": 0.0, "avg_logprob": -0.18033004336886935, "compression_ratio": 1.6127659574468085, "no_speech_prob": 5.682330538547831e-06}, {"id": 549, "seek": 279104, "start": 2791.04, "end": 2801.4, "text": " Another way of doing that of course which we learned would be question mark question mark DF raw drop", "tokens": [3996, 636, 295, 884, 300, 295, 1164, 597, 321, 3264, 576, 312, 1168, 1491, 1168, 1491, 48336, 8936, 3270], "temperature": 0.0, "avg_logprob": -0.27989572286605835, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.3568429646256845e-06}, {"id": 550, "seek": 279104, "start": 2803.72, "end": 2804.96, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.27989572286605835, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.3568429646256845e-06}, {"id": 551, "seek": 279104, "start": 2804.96, "end": 2807.54, "text": " Sorry question mark question mark would be the source code for it", "tokens": [4919, 1168, 1491, 1168, 1491, 576, 312, 264, 4009, 3089, 337, 309], "temperature": 0.0, "avg_logprob": -0.27989572286605835, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.3568429646256845e-06}, {"id": 552, "seek": 279104, "start": 2808.32, "end": 2811.9, "text": " For a single question mark is the documentation", "tokens": [1171, 257, 2167, 1168, 1491, 307, 264, 14333], "temperature": 0.0, "avg_logprob": -0.27989572286605835, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.3568429646256845e-06}, {"id": 553, "seek": 279104, "start": 2814.04, "end": 2818.7599999999998, "text": " So I think that trick of like tab complete shift tab parameters", "tokens": [407, 286, 519, 300, 4282, 295, 411, 4421, 3566, 5513, 4421, 9834], "temperature": 0.0, "avg_logprob": -0.27989572286605835, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.3568429646256845e-06}, {"id": 554, "seek": 281876, "start": 2818.76, "end": 2826.2400000000002, "text": " Question mark and double question mark for the docs and the source code like if you know nothing else about using Python libraries", "tokens": [14464, 1491, 293, 3834, 1168, 1491, 337, 264, 45623, 293, 264, 4009, 3089, 411, 498, 291, 458, 1825, 1646, 466, 1228, 15329, 15148], "temperature": 0.0, "avg_logprob": -0.14980006704525073, "compression_ratio": 1.7316017316017316, "no_speech_prob": 4.3568511500780005e-06}, {"id": 555, "seek": 281876, "start": 2826.6400000000003, "end": 2829.3, "text": " Know that because now you know how to find out everything else", "tokens": [10265, 300, 570, 586, 291, 458, 577, 281, 915, 484, 1203, 1646], "temperature": 0.0, "avg_logprob": -0.14980006704525073, "compression_ratio": 1.7316017316017316, "no_speech_prob": 4.3568511500780005e-06}, {"id": 556, "seek": 281876, "start": 2830.0, "end": 2831.28, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.14980006704525073, "compression_ratio": 1.7316017316017316, "no_speech_prob": 4.3568511500780005e-06}, {"id": 557, "seek": 281876, "start": 2831.28, "end": 2834.36, "text": " So we try to run it and it doesn't work", "tokens": [407, 321, 853, 281, 1190, 309, 293, 309, 1177, 380, 589], "temperature": 0.0, "avg_logprob": -0.14980006704525073, "compression_ratio": 1.7316017316017316, "no_speech_prob": 4.3568511500780005e-06}, {"id": 558, "seek": 281876, "start": 2835.6000000000004, "end": 2839.32, "text": " Okay, so why didn't it work so anytime you get a?", "tokens": [1033, 11, 370, 983, 994, 380, 309, 589, 370, 13038, 291, 483, 257, 30], "temperature": 0.0, "avg_logprob": -0.14980006704525073, "compression_ratio": 1.7316017316017316, "no_speech_prob": 4.3568511500780005e-06}, {"id": 559, "seek": 281876, "start": 2840.0800000000004, "end": 2846.1200000000003, "text": " Stack trace like this so an error the trick is to go to the bottom because the bottom tells you what went wrong", "tokens": [37649, 13508, 411, 341, 370, 364, 6713, 264, 4282, 307, 281, 352, 281, 264, 2767, 570, 264, 2767, 5112, 291, 437, 1437, 2085], "temperature": 0.0, "avg_logprob": -0.14980006704525073, "compression_ratio": 1.7316017316017316, "no_speech_prob": 4.3568511500780005e-06}, {"id": 560, "seek": 284612, "start": 2846.12, "end": 2851.3599999999997, "text": " Above it it tells you all of the functions that called other function could cause other functions to get there", "tokens": [32691, 309, 309, 5112, 291, 439, 295, 264, 6828, 300, 1219, 661, 2445, 727, 3082, 661, 6828, 281, 483, 456], "temperature": 0.0, "avg_logprob": -0.154992855919732, "compression_ratio": 1.7292576419213974, "no_speech_prob": 8.315255399793386e-07}, {"id": 561, "seek": 284612, "start": 2852.04, "end": 2854.18, "text": " Could not convert string to float", "tokens": [7497, 406, 7620, 6798, 281, 15706], "temperature": 0.0, "avg_logprob": -0.154992855919732, "compression_ratio": 1.7292576419213974, "no_speech_prob": 8.315255399793386e-07}, {"id": 562, "seek": 284612, "start": 2854.8399999999997, "end": 2856.8399999999997, "text": " Conventional so there was a column name", "tokens": [26793, 304, 370, 456, 390, 257, 7738, 1315], "temperature": 0.0, "avg_logprob": -0.154992855919732, "compression_ratio": 1.7292576419213974, "no_speech_prob": 8.315255399793386e-07}, {"id": 563, "seek": 284612, "start": 2857.48, "end": 2862.7599999999998, "text": " Sorry a there was a value rather inside my data set conventional the word conventional", "tokens": [4919, 257, 456, 390, 257, 2158, 2831, 1854, 452, 1412, 992, 16011, 264, 1349, 16011], "temperature": 0.0, "avg_logprob": -0.154992855919732, "compression_ratio": 1.7292576419213974, "no_speech_prob": 8.315255399793386e-07}, {"id": 564, "seek": 284612, "start": 2862.7599999999998, "end": 2866.7599999999998, "text": " And it didn't know how to create a model using that string", "tokens": [400, 309, 994, 380, 458, 577, 281, 1884, 257, 2316, 1228, 300, 6798], "temperature": 0.0, "avg_logprob": -0.154992855919732, "compression_ratio": 1.7292576419213974, "no_speech_prob": 8.315255399793386e-07}, {"id": 565, "seek": 284612, "start": 2867.44, "end": 2873.12, "text": " Now that's true. We have to pass numbers to most machine learning", "tokens": [823, 300, 311, 2074, 13, 492, 362, 281, 1320, 3547, 281, 881, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.154992855919732, "compression_ratio": 1.7292576419213974, "no_speech_prob": 8.315255399793386e-07}, {"id": 566, "seek": 287312, "start": 2873.12, "end": 2879.04, "text": " Models and certainly to random forests so step one is to convert everything into numbers", "tokens": [6583, 1625, 293, 3297, 281, 4974, 21700, 370, 1823, 472, 307, 281, 7620, 1203, 666, 3547], "temperature": 0.0, "avg_logprob": -0.22418207592434353, "compression_ratio": 1.8066298342541436, "no_speech_prob": 1.1015910104106297e-06}, {"id": 567, "seek": 287312, "start": 2882.04, "end": 2889.48, "text": " So our data set contains both continuous variables so numbers where the meaning is numeric like", "tokens": [407, 527, 1412, 992, 8306, 1293, 10957, 9102, 370, 3547, 689, 264, 3620, 307, 7866, 299, 411], "temperature": 0.0, "avg_logprob": -0.22418207592434353, "compression_ratio": 1.8066298342541436, "no_speech_prob": 1.1015910104106297e-06}, {"id": 568, "seek": 287312, "start": 2889.92, "end": 2891.92, "text": " price and", "tokens": [3218, 293], "temperature": 0.0, "avg_logprob": -0.22418207592434353, "compression_ratio": 1.8066298342541436, "no_speech_prob": 1.1015910104106297e-06}, {"id": 569, "seek": 287312, "start": 2892.2, "end": 2900.04, "text": " It contains categorical variables which could either be numbers where the meaning is not continuous like a zip code", "tokens": [467, 8306, 19250, 804, 9102, 597, 727, 2139, 312, 3547, 689, 264, 3620, 307, 406, 10957, 411, 257, 20730, 3089], "temperature": 0.0, "avg_logprob": -0.22418207592434353, "compression_ratio": 1.8066298342541436, "no_speech_prob": 1.1015910104106297e-06}, {"id": 570, "seek": 287312, "start": 2900.04, "end": 2902.04, "text": " or it could be a", "tokens": [420, 309, 727, 312, 257], "temperature": 0.0, "avg_logprob": -0.22418207592434353, "compression_ratio": 1.8066298342541436, "no_speech_prob": 1.1015910104106297e-06}, {"id": 571, "seek": 290204, "start": 2902.04, "end": 2907.32, "text": " String like large small and medium so categorical and continuous variables", "tokens": [745, 2937, 411, 2416, 1359, 293, 6399, 370, 19250, 804, 293, 10957, 9102], "temperature": 0.0, "avg_logprob": -0.11978753753330397, "compression_ratio": 1.728110599078341, "no_speech_prob": 3.041580612261896e-06}, {"id": 572, "seek": 290204, "start": 2908.2799999999997, "end": 2913.56, "text": " We want to basically get to a point where we have a data set where we can use all of these variables", "tokens": [492, 528, 281, 1936, 483, 281, 257, 935, 689, 321, 362, 257, 1412, 992, 689, 321, 393, 764, 439, 295, 613, 9102], "temperature": 0.0, "avg_logprob": -0.11978753753330397, "compression_ratio": 1.728110599078341, "no_speech_prob": 3.041580612261896e-06}, {"id": 573, "seek": 290204, "start": 2913.56, "end": 2916.64, "text": " So they have to all be numeric and they have to be usable in some way", "tokens": [407, 436, 362, 281, 439, 312, 7866, 299, 293, 436, 362, 281, 312, 29975, 294, 512, 636], "temperature": 0.0, "avg_logprob": -0.11978753753330397, "compression_ratio": 1.728110599078341, "no_speech_prob": 3.041580612261896e-06}, {"id": 574, "seek": 290204, "start": 2917.02, "end": 2920.68, "text": " So one issue is that we've got something called sale date", "tokens": [407, 472, 2734, 307, 300, 321, 600, 658, 746, 1219, 8680, 4002], "temperature": 0.0, "avg_logprob": -0.11978753753330397, "compression_ratio": 1.728110599078341, "no_speech_prob": 3.041580612261896e-06}, {"id": 575, "seek": 290204, "start": 2923.16, "end": 2926.48, "text": " Which you might remember right at the top we told it that that's a date", "tokens": [3013, 291, 1062, 1604, 558, 412, 264, 1192, 321, 1907, 309, 300, 300, 311, 257, 4002], "temperature": 0.0, "avg_logprob": -0.11978753753330397, "compression_ratio": 1.728110599078341, "no_speech_prob": 3.041580612261896e-06}, {"id": 576, "seek": 292648, "start": 2926.48, "end": 2934.64, "text": " So it's been passed as a date and so you can see here. It's data type D type very important thing data type is date time", "tokens": [407, 309, 311, 668, 4678, 382, 257, 4002, 293, 370, 291, 393, 536, 510, 13, 467, 311, 1412, 2010, 413, 2010, 588, 1021, 551, 1412, 2010, 307, 4002, 565], "temperature": 0.0, "avg_logprob": -0.2062097458612351, "compression_ratio": 1.6431372549019607, "no_speech_prob": 5.6823660088412e-06}, {"id": 577, "seek": 292648, "start": 2935.36, "end": 2936.68, "text": " 64 bit", "tokens": [12145, 857], "temperature": 0.0, "avg_logprob": -0.2062097458612351, "compression_ratio": 1.6431372549019607, "no_speech_prob": 5.6823660088412e-06}, {"id": 578, "seek": 292648, "start": 2936.68, "end": 2938.68, "text": " So that's not a number", "tokens": [407, 300, 311, 406, 257, 1230], "temperature": 0.0, "avg_logprob": -0.2062097458612351, "compression_ratio": 1.6431372549019607, "no_speech_prob": 5.6823660088412e-06}, {"id": 579, "seek": 292648, "start": 2939.4, "end": 2945.48, "text": " Right and this is actually where we need to do our first piece of feature engineering right inside a date", "tokens": [1779, 293, 341, 307, 767, 689, 321, 643, 281, 360, 527, 700, 2522, 295, 4111, 7043, 558, 1854, 257, 4002], "temperature": 0.0, "avg_logprob": -0.2062097458612351, "compression_ratio": 1.6431372549019607, "no_speech_prob": 5.6823660088412e-06}, {"id": 580, "seek": 292648, "start": 2945.48, "end": 2947.48, "text": " There's a lot of interesting stuff", "tokens": [821, 311, 257, 688, 295, 1880, 1507], "temperature": 0.0, "avg_logprob": -0.2062097458612351, "compression_ratio": 1.6431372549019607, "no_speech_prob": 5.6823660088412e-06}, {"id": 581, "seek": 294748, "start": 2947.48, "end": 2956.1, "text": " All right, so since you've got the catch box, can you tell me what are some of the interesting bits of information inside a date?", "tokens": [1057, 558, 11, 370, 1670, 291, 600, 658, 264, 3745, 2424, 11, 393, 291, 980, 385, 437, 366, 512, 295, 264, 1880, 9239, 295, 1589, 1854, 257, 4002, 30], "temperature": 0.0, "avg_logprob": -0.27137735387781164, "compression_ratio": 1.5954545454545455, "no_speech_prob": 6.240834409254603e-06}, {"id": 582, "seek": 294748, "start": 2957.1, "end": 2959.1, "text": " Well, you can see like a time series pattern", "tokens": [1042, 11, 291, 393, 536, 411, 257, 565, 2638, 5102], "temperature": 0.0, "avg_logprob": -0.27137735387781164, "compression_ratio": 1.5954545454545455, "no_speech_prob": 6.240834409254603e-06}, {"id": 583, "seek": 294748, "start": 2961.28, "end": 2967.88, "text": " That's true, I'm having didn't express very well, what are some columns that we could pull out of this year month", "tokens": [663, 311, 2074, 11, 286, 478, 1419, 994, 380, 5109, 588, 731, 11, 437, 366, 512, 13766, 300, 321, 727, 2235, 484, 295, 341, 1064, 1618], "temperature": 0.0, "avg_logprob": -0.27137735387781164, "compression_ratio": 1.5954545454545455, "no_speech_prob": 6.240834409254603e-06}, {"id": 584, "seek": 294748, "start": 2969.88, "end": 2974.0, "text": " The date as in like it tell me a not at least be a number yeah", "tokens": [440, 4002, 382, 294, 411, 309, 980, 385, 257, 406, 412, 1935, 312, 257, 1230, 1338], "temperature": 0.0, "avg_logprob": -0.27137735387781164, "compression_ratio": 1.5954545454545455, "no_speech_prob": 6.240834409254603e-06}, {"id": 585, "seek": 297400, "start": 2974.0, "end": 2979.82, "text": " Month order you want to pass it to your right and get some more behind you just pass it to your right", "tokens": [24255, 1668, 291, 528, 281, 1320, 309, 281, 428, 558, 293, 483, 512, 544, 2261, 291, 445, 1320, 309, 281, 428, 558], "temperature": 0.0, "avg_logprob": -0.2613768887210202, "compression_ratio": 1.652694610778443, "no_speech_prob": 1.3006815606786404e-05}, {"id": 586, "seek": 297400, "start": 2980.12, "end": 2982.12, "text": " You go you got some more columns for us", "tokens": [509, 352, 291, 658, 512, 544, 13766, 337, 505], "temperature": 0.0, "avg_logprob": -0.2613768887210202, "compression_ratio": 1.652694610778443, "no_speech_prob": 1.3006815606786404e-05}, {"id": 587, "seek": 297400, "start": 2985.48, "end": 2991.28, "text": " Day of month, yeah, keep going to the right day of week day of week. Yeah", "tokens": [5226, 295, 1618, 11, 1338, 11, 1066, 516, 281, 264, 558, 786, 295, 1243, 786, 295, 1243, 13, 865], "temperature": 0.0, "avg_logprob": -0.2613768887210202, "compression_ratio": 1.652694610778443, "no_speech_prob": 1.3006815606786404e-05}, {"id": 588, "seek": 297400, "start": 2998.04, "end": 3001.92, "text": " Week of year. Yeah, okay. I'll give you a few more like that", "tokens": [12615, 295, 1064, 13, 865, 11, 1392, 13, 286, 603, 976, 291, 257, 1326, 544, 411, 300], "temperature": 0.0, "avg_logprob": -0.2613768887210202, "compression_ratio": 1.652694610778443, "no_speech_prob": 1.3006815606786404e-05}, {"id": 589, "seek": 300192, "start": 3001.92, "end": 3005.2000000000003, "text": " You might want to think about would be like is it a holiday?", "tokens": [509, 1062, 528, 281, 519, 466, 576, 312, 411, 307, 309, 257, 9960, 30], "temperature": 0.0, "avg_logprob": -0.2005098733035001, "compression_ratio": 1.6275510204081634, "no_speech_prob": 2.260313522128854e-06}, {"id": 590, "seek": 300192, "start": 3007.2000000000003, "end": 3009.2000000000003, "text": " Is it a weekend", "tokens": [1119, 309, 257, 6711], "temperature": 0.0, "avg_logprob": -0.2005098733035001, "compression_ratio": 1.6275510204081634, "no_speech_prob": 2.260313522128854e-06}, {"id": 591, "seek": 300192, "start": 3009.8, "end": 3011.92, "text": " Was it raining that day?", "tokens": [3027, 309, 18441, 300, 786, 30], "temperature": 0.0, "avg_logprob": -0.2005098733035001, "compression_ratio": 1.6275510204081634, "no_speech_prob": 2.260313522128854e-06}, {"id": 592, "seek": 300192, "start": 3011.92, "end": 3013.92, "text": " Was there a sports event that day?", "tokens": [3027, 456, 257, 6573, 2280, 300, 786, 30], "temperature": 0.0, "avg_logprob": -0.2005098733035001, "compression_ratio": 1.6275510204081634, "no_speech_prob": 2.260313522128854e-06}, {"id": 593, "seek": 300192, "start": 3015.2400000000002, "end": 3019.6, "text": " Like it depends a bit on what you're doing right so like if you're predicting", "tokens": [1743, 309, 5946, 257, 857, 322, 437, 291, 434, 884, 558, 370, 411, 498, 291, 434, 32884], "temperature": 0.0, "avg_logprob": -0.2005098733035001, "compression_ratio": 1.6275510204081634, "no_speech_prob": 2.260313522128854e-06}, {"id": 594, "seek": 300192, "start": 3020.2400000000002, "end": 3022.2400000000002, "text": " soda sales in", "tokens": [17192, 5763, 294], "temperature": 0.0, "avg_logprob": -0.2005098733035001, "compression_ratio": 1.6275510204081634, "no_speech_prob": 2.260313522128854e-06}, {"id": 595, "seek": 300192, "start": 3022.64, "end": 3027.92, "text": " Soma you would probably want to know was there a San Francisco Giants ballgame on that day", "tokens": [318, 6440, 291, 576, 1391, 528, 281, 458, 390, 456, 257, 5271, 12279, 15334, 1719, 2594, 15038, 322, 300, 786], "temperature": 0.0, "avg_logprob": -0.2005098733035001, "compression_ratio": 1.6275510204081634, "no_speech_prob": 2.260313522128854e-06}, {"id": 596, "seek": 302792, "start": 3027.92, "end": 3035.2400000000002, "text": " All right, so like what's in a date is one of the most important pieces of feature engineering you can do and no machine learning", "tokens": [1057, 558, 11, 370, 411, 437, 311, 294, 257, 4002, 307, 472, 295, 264, 881, 1021, 3755, 295, 4111, 7043, 291, 393, 360, 293, 572, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.17060003928767825, "compression_ratio": 1.721311475409836, "no_speech_prob": 1.1911025694644195e-06}, {"id": 597, "seek": 302792, "start": 3036.16, "end": 3040.7200000000003, "text": " Algorithm can tell you whether the Giants were playing that day and that it was important", "tokens": [35014, 6819, 76, 393, 980, 291, 1968, 264, 15334, 1719, 645, 2433, 300, 786, 293, 300, 309, 390, 1021], "temperature": 0.0, "avg_logprob": -0.17060003928767825, "compression_ratio": 1.721311475409836, "no_speech_prob": 1.1911025694644195e-06}, {"id": 598, "seek": 302792, "start": 3041.08, "end": 3044.2000000000003, "text": " All right, so this is where you need to do feature engineering", "tokens": [1057, 558, 11, 370, 341, 307, 689, 291, 643, 281, 360, 4111, 7043], "temperature": 0.0, "avg_logprob": -0.17060003928767825, "compression_ratio": 1.721311475409836, "no_speech_prob": 1.1911025694644195e-06}, {"id": 599, "seek": 302792, "start": 3044.2000000000003, "end": 3051.16, "text": " So I do as much things as many things automatically as I can for you", "tokens": [407, 286, 360, 382, 709, 721, 382, 867, 721, 6772, 382, 286, 393, 337, 291], "temperature": 0.0, "avg_logprob": -0.17060003928767825, "compression_ratio": 1.721311475409836, "no_speech_prob": 1.1911025694644195e-06}, {"id": 600, "seek": 302792, "start": 3051.28, "end": 3054.92, "text": " Right so here. I've got something called add date part", "tokens": [1779, 370, 510, 13, 286, 600, 658, 746, 1219, 909, 4002, 644], "temperature": 0.0, "avg_logprob": -0.17060003928767825, "compression_ratio": 1.721311475409836, "no_speech_prob": 1.1911025694644195e-06}, {"id": 601, "seek": 305492, "start": 3054.92, "end": 3060.64, "text": " What is that? It's something inside fast AI dot structured", "tokens": [708, 307, 300, 30, 467, 311, 746, 1854, 2370, 7318, 5893, 18519], "temperature": 0.0, "avg_logprob": -0.19921977110583372, "compression_ratio": 1.6382978723404256, "no_speech_prob": 3.138128931823303e-06}, {"id": 602, "seek": 305492, "start": 3061.6800000000003, "end": 3065.92, "text": " Okay, and what is it? Well, let's read the source code", "tokens": [1033, 11, 293, 437, 307, 309, 30, 1042, 11, 718, 311, 1401, 264, 4009, 3089], "temperature": 0.0, "avg_logprob": -0.19921977110583372, "compression_ratio": 1.6382978723404256, "no_speech_prob": 3.138128931823303e-06}, {"id": 603, "seek": 305492, "start": 3067.6800000000003, "end": 3071.7200000000003, "text": " Here it is so you'll find most of my functions are", "tokens": [1692, 309, 307, 370, 291, 603, 915, 881, 295, 452, 6828, 366], "temperature": 0.0, "avg_logprob": -0.19921977110583372, "compression_ratio": 1.6382978723404256, "no_speech_prob": 3.138128931823303e-06}, {"id": 604, "seek": 305492, "start": 3072.52, "end": 3075.7200000000003, "text": " Less than half a page of code right so here is something", "tokens": [18649, 813, 1922, 257, 3028, 295, 3089, 558, 370, 510, 307, 746], "temperature": 0.0, "avg_logprob": -0.19921977110583372, "compression_ratio": 1.6382978723404256, "no_speech_prob": 3.138128931823303e-06}, {"id": 605, "seek": 305492, "start": 3075.7200000000003, "end": 3078.36, "text": " It's gonna so rather than often rather than having docs", "tokens": [467, 311, 799, 370, 2831, 813, 2049, 2831, 813, 1419, 45623], "temperature": 0.0, "avg_logprob": -0.19921977110583372, "compression_ratio": 1.6382978723404256, "no_speech_prob": 3.138128931823303e-06}, {"id": 606, "seek": 305492, "start": 3078.36, "end": 3082.56, "text": " I'm gonna try to add docs over time, but they're designed that you can understand them are reading the code", "tokens": [286, 478, 799, 853, 281, 909, 45623, 670, 565, 11, 457, 436, 434, 4761, 300, 291, 393, 1223, 552, 366, 3760, 264, 3089], "temperature": 0.0, "avg_logprob": -0.19921977110583372, "compression_ratio": 1.6382978723404256, "no_speech_prob": 3.138128931823303e-06}, {"id": 607, "seek": 308256, "start": 3082.56, "end": 3089.6, "text": " So we're passing in a data frame and the name of some field okay, which in this case was sale date and so", "tokens": [407, 321, 434, 8437, 294, 257, 1412, 3920, 293, 264, 1315, 295, 512, 2519, 1392, 11, 597, 294, 341, 1389, 390, 8680, 4002, 293, 370], "temperature": 0.0, "avg_logprob": -0.15639042209934545, "compression_ratio": 1.7846153846153847, "no_speech_prob": 2.5612619083403843e-06}, {"id": 608, "seek": 308256, "start": 3090.48, "end": 3097.02, "text": " In this case we can't go DF dot field name because that would actually find a field called field name", "tokens": [682, 341, 1389, 321, 393, 380, 352, 48336, 5893, 2519, 1315, 570, 300, 576, 767, 915, 257, 2519, 1219, 2519, 1315], "temperature": 0.0, "avg_logprob": -0.15639042209934545, "compression_ratio": 1.7846153846153847, "no_speech_prob": 2.5612619083403843e-06}, {"id": 609, "seek": 308256, "start": 3097.48, "end": 3104.2599999999998, "text": " Literally so DF square bracket field name is how we grab a column where that column name is stored in this variable", "tokens": [23768, 370, 48336, 3732, 16904, 2519, 1315, 307, 577, 321, 4444, 257, 7738, 689, 300, 7738, 1315, 307, 12187, 294, 341, 7006], "temperature": 0.0, "avg_logprob": -0.15639042209934545, "compression_ratio": 1.7846153846153847, "no_speech_prob": 2.5612619083403843e-06}, {"id": 610, "seek": 308256, "start": 3104.2599999999998, "end": 3106.7799999999997, "text": " Okay, so we've now got the field itself the series", "tokens": [1033, 11, 370, 321, 600, 586, 658, 264, 2519, 2564, 264, 2638], "temperature": 0.0, "avg_logprob": -0.15639042209934545, "compression_ratio": 1.7846153846153847, "no_speech_prob": 2.5612619083403843e-06}, {"id": 611, "seek": 310678, "start": 3106.78, "end": 3112.46, "text": " And so what we're going to do is we're going to go through all of these different strings", "tokens": [400, 370, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 352, 807, 439, 295, 613, 819, 13985], "temperature": 0.0, "avg_logprob": -0.15971981713531214, "compression_ratio": 1.9380530973451326, "no_speech_prob": 1.4823491483184625e-06}, {"id": 612, "seek": 310678, "start": 3113.26, "end": 3119.94, "text": " right, and this is a piece of Python which actually looks inside an object and finds a", "tokens": [558, 11, 293, 341, 307, 257, 2522, 295, 15329, 597, 767, 1542, 1854, 364, 2657, 293, 10704, 257], "temperature": 0.0, "avg_logprob": -0.15971981713531214, "compression_ratio": 1.9380530973451326, "no_speech_prob": 1.4823491483184625e-06}, {"id": 613, "seek": 310678, "start": 3120.82, "end": 3126.26, "text": " Attribute with that name, so this is going to go through and you can again you can google for Python get attribute", "tokens": [7298, 2024, 1169, 365, 300, 1315, 11, 370, 341, 307, 516, 281, 352, 807, 293, 291, 393, 797, 291, 393, 20742, 337, 15329, 483, 19667], "temperature": 0.0, "avg_logprob": -0.15971981713531214, "compression_ratio": 1.9380530973451326, "no_speech_prob": 1.4823491483184625e-06}, {"id": 614, "seek": 310678, "start": 3126.26, "end": 3131.5800000000004, "text": " It's a cool little advanced technique, but this is going to go through and it's going to find for this field", "tokens": [467, 311, 257, 1627, 707, 7339, 6532, 11, 457, 341, 307, 516, 281, 352, 807, 293, 309, 311, 516, 281, 915, 337, 341, 2519], "temperature": 0.0, "avg_logprob": -0.15971981713531214, "compression_ratio": 1.9380530973451326, "no_speech_prob": 1.4823491483184625e-06}, {"id": 615, "seek": 310678, "start": 3132.1000000000004, "end": 3134.1000000000004, "text": " It's going to find its", "tokens": [467, 311, 516, 281, 915, 1080], "temperature": 0.0, "avg_logprob": -0.15971981713531214, "compression_ratio": 1.9380530973451326, "no_speech_prob": 1.4823491483184625e-06}, {"id": 616, "seek": 310678, "start": 3134.42, "end": 3136.42, "text": " year attribute", "tokens": [1064, 19667], "temperature": 0.0, "avg_logprob": -0.15971981713531214, "compression_ratio": 1.9380530973451326, "no_speech_prob": 1.4823491483184625e-06}, {"id": 617, "seek": 313642, "start": 3136.42, "end": 3140.34, "text": " Now pandas has got this interesting idea, which is if I actually look inside", "tokens": [823, 4565, 296, 575, 658, 341, 1880, 1558, 11, 597, 307, 498, 286, 767, 574, 1854], "temperature": 0.0, "avg_logprob": -0.22430166264170223, "compression_ratio": 1.5767441860465117, "no_speech_prob": 4.710877874458674e-06}, {"id": 618, "seek": 313642, "start": 3141.58, "end": 3147.5, "text": " Let's go field equals. This is the kind of experiment. I want you to do right play around say okay?", "tokens": [961, 311, 352, 2519, 6915, 13, 639, 307, 264, 733, 295, 5120, 13, 286, 528, 291, 281, 360, 558, 862, 926, 584, 1392, 30], "temperature": 0.0, "avg_logprob": -0.22430166264170223, "compression_ratio": 1.5767441860465117, "no_speech_prob": 4.710877874458674e-06}, {"id": 619, "seek": 313642, "start": 3147.5, "end": 3150.7000000000003, "text": " So I've now got that in a field object and so I can go field", "tokens": [407, 286, 600, 586, 658, 300, 294, 257, 2519, 2657, 293, 370, 286, 393, 352, 2519], "temperature": 0.0, "avg_logprob": -0.22430166264170223, "compression_ratio": 1.5767441860465117, "no_speech_prob": 4.710877874458674e-06}, {"id": 620, "seek": 313642, "start": 3151.46, "end": 3154.2200000000003, "text": " Right and I can go field dot tab", "tokens": [1779, 293, 286, 393, 352, 2519, 5893, 4421], "temperature": 0.0, "avg_logprob": -0.22430166264170223, "compression_ratio": 1.5767441860465117, "no_speech_prob": 4.710877874458674e-06}, {"id": 621, "seek": 313642, "start": 3155.1, "end": 3157.86, "text": " Right and let's see is year in there. Oh", "tokens": [1779, 293, 718, 311, 536, 307, 1064, 294, 456, 13, 876], "temperature": 0.0, "avg_logprob": -0.22430166264170223, "compression_ratio": 1.5767441860465117, "no_speech_prob": 4.710877874458674e-06}, {"id": 622, "seek": 313642, "start": 3158.7400000000002, "end": 3161.2400000000002, "text": " It's not okay. Why not well", "tokens": [467, 311, 406, 1392, 13, 1545, 406, 731], "temperature": 0.0, "avg_logprob": -0.22430166264170223, "compression_ratio": 1.5767441860465117, "no_speech_prob": 4.710877874458674e-06}, {"id": 623, "seek": 316124, "start": 3161.24, "end": 3167.3399999999997, "text": " That's because year is only going to apply to pandas series that are date-time objects", "tokens": [663, 311, 570, 1064, 307, 787, 516, 281, 3079, 281, 4565, 296, 2638, 300, 366, 4002, 12, 3766, 6565], "temperature": 0.0, "avg_logprob": -0.1937592542624172, "compression_ratio": 1.649214659685864, "no_speech_prob": 2.6015975436166627e-06}, {"id": 624, "seek": 316124, "start": 3167.5, "end": 3171.3399999999997, "text": " So what pandas does is it splits out different methods?", "tokens": [407, 437, 4565, 296, 775, 307, 309, 37741, 484, 819, 7150, 30], "temperature": 0.0, "avg_logprob": -0.1937592542624172, "compression_ratio": 1.649214659685864, "no_speech_prob": 2.6015975436166627e-06}, {"id": 625, "seek": 316124, "start": 3171.8599999999997, "end": 3178.02, "text": " Inside attributes that are specific to what they are so date-time objects will have a DT", "tokens": [15123, 17212, 300, 366, 2685, 281, 437, 436, 366, 370, 4002, 12, 3766, 6565, 486, 362, 257, 413, 51], "temperature": 0.0, "avg_logprob": -0.1937592542624172, "compression_ratio": 1.649214659685864, "no_speech_prob": 2.6015975436166627e-06}, {"id": 626, "seek": 316124, "start": 3178.7799999999997, "end": 3180.66, "text": " attribute defined and", "tokens": [19667, 7642, 293], "temperature": 0.0, "avg_logprob": -0.1937592542624172, "compression_ratio": 1.649214659685864, "no_speech_prob": 2.6015975436166627e-06}, {"id": 627, "seek": 316124, "start": 3180.66, "end": 3184.18, "text": " At that is where you'll find all the date-time specific stuff", "tokens": [1711, 300, 307, 689, 291, 603, 915, 439, 264, 4002, 12, 3766, 2685, 1507], "temperature": 0.0, "avg_logprob": -0.1937592542624172, "compression_ratio": 1.649214659685864, "no_speech_prob": 2.6015975436166627e-06}, {"id": 628, "seek": 318418, "start": 3184.18, "end": 3189.54, "text": " So what I went through was I went through all of these and", "tokens": [407, 437, 286, 1437, 807, 390, 286, 1437, 807, 439, 295, 613, 293], "temperature": 0.0, "avg_logprob": -0.13753741378084236, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.7061694279618678e-06}, {"id": 629, "seek": 318418, "start": 3189.8599999999997, "end": 3195.66, "text": " Picked out all of the ones that could ever be interesting for ever any reason right and this is like the opposite of the curse of", "tokens": [430, 12598, 484, 439, 295, 264, 2306, 300, 727, 1562, 312, 1880, 337, 1562, 604, 1778, 558, 293, 341, 307, 411, 264, 6182, 295, 264, 17139, 295], "temperature": 0.0, "avg_logprob": -0.13753741378084236, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.7061694279618678e-06}, {"id": 630, "seek": 318418, "start": 3195.8199999999997, "end": 3202.3599999999997, "text": " Dimensionality it's like if there is any column or any variant of that column that could be ever be interesting at all", "tokens": [20975, 3378, 1860, 309, 311, 411, 498, 456, 307, 604, 7738, 420, 604, 17501, 295, 300, 7738, 300, 727, 312, 1562, 312, 1880, 412, 439], "temperature": 0.0, "avg_logprob": -0.13753741378084236, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.7061694279618678e-06}, {"id": 631, "seek": 318418, "start": 3202.62, "end": 3209.4199999999996, "text": " Add that to your data set and every variation of it you can think of there's no harm in adding more columns", "tokens": [5349, 300, 281, 428, 1412, 992, 293, 633, 12990, 295, 309, 291, 393, 519, 295, 456, 311, 572, 6491, 294, 5127, 544, 13766], "temperature": 0.0, "avg_logprob": -0.13753741378084236, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.7061694279618678e-06}, {"id": 632, "seek": 318418, "start": 3209.98, "end": 3212.46, "text": " Nearly all the time right so in this case", "tokens": [38000, 439, 264, 565, 558, 370, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.13753741378084236, "compression_ratio": 1.8653061224489795, "no_speech_prob": 1.7061694279618678e-06}, {"id": 633, "seek": 321246, "start": 3212.46, "end": 3219.98, "text": " We're going to go ahead and add all of these different attributes and so for every one I'm going to create a new field", "tokens": [492, 434, 516, 281, 352, 2286, 293, 909, 439, 295, 613, 819, 17212, 293, 370, 337, 633, 472, 286, 478, 516, 281, 1884, 257, 777, 2519], "temperature": 0.0, "avg_logprob": -0.18982324895170546, "compression_ratio": 1.8226600985221675, "no_speech_prob": 8.800967407296412e-06}, {"id": 634, "seek": 321246, "start": 3220.26, "end": 3222.26, "text": " That's going to be called", "tokens": [663, 311, 516, 281, 312, 1219], "temperature": 0.0, "avg_logprob": -0.18982324895170546, "compression_ratio": 1.8226600985221675, "no_speech_prob": 8.800967407296412e-06}, {"id": 635, "seek": 321246, "start": 3224.34, "end": 3230.98, "text": " The name of your field with the word date removed so it'll be sale and then the name of the attribute", "tokens": [440, 1315, 295, 428, 2519, 365, 264, 1349, 4002, 7261, 370, 309, 603, 312, 8680, 293, 550, 264, 1315, 295, 264, 19667], "temperature": 0.0, "avg_logprob": -0.18982324895170546, "compression_ratio": 1.8226600985221675, "no_speech_prob": 8.800967407296412e-06}, {"id": 636, "seek": 321246, "start": 3230.98, "end": 3235.06, "text": " So we're going to get a sale year sale month sale week sale day etc etc", "tokens": [407, 321, 434, 516, 281, 483, 257, 8680, 1064, 8680, 1618, 8680, 1243, 8680, 786, 5183, 5183], "temperature": 0.0, "avg_logprob": -0.18982324895170546, "compression_ratio": 1.8226600985221675, "no_speech_prob": 8.800967407296412e-06}, {"id": 637, "seek": 321246, "start": 3235.78, "end": 3238.7, "text": " Okay, and then at the very end. I'm going to remove", "tokens": [1033, 11, 293, 550, 412, 264, 588, 917, 13, 286, 478, 516, 281, 4159], "temperature": 0.0, "avg_logprob": -0.18982324895170546, "compression_ratio": 1.8226600985221675, "no_speech_prob": 8.800967407296412e-06}, {"id": 638, "seek": 323870, "start": 3238.7, "end": 3242.5, "text": " the original field right because remember we can't use", "tokens": [264, 3380, 2519, 558, 570, 1604, 321, 393, 380, 764], "temperature": 0.0, "avg_logprob": -0.25906174357344464, "compression_ratio": 1.7127659574468086, "no_speech_prob": 1.994691956497263e-06}, {"id": 639, "seek": 323870, "start": 3243.3399999999997, "end": 3245.3399999999997, "text": " Sale date directly because it's not a number", "tokens": [48922, 4002, 3838, 570, 309, 311, 406, 257, 1230], "temperature": 0.0, "avg_logprob": -0.25906174357344464, "compression_ratio": 1.7127659574468086, "no_speech_prob": 1.994691956497263e-06}, {"id": 640, "seek": 323870, "start": 3252.14, "end": 3256.1, "text": " So you're saying this only work because it was a date type did you make it again?", "tokens": [407, 291, 434, 1566, 341, 787, 589, 570, 309, 390, 257, 4002, 2010, 630, 291, 652, 309, 797, 30], "temperature": 0.0, "avg_logprob": -0.25906174357344464, "compression_ratio": 1.7127659574468086, "no_speech_prob": 1.994691956497263e-06}, {"id": 641, "seek": 323870, "start": 3256.1, "end": 3261.7799999999997, "text": " Or was already saved as one in the original yeah, it's already a date type and the reason it was a date type", "tokens": [1610, 390, 1217, 6624, 382, 472, 294, 264, 3380, 1338, 11, 309, 311, 1217, 257, 4002, 2010, 293, 264, 1778, 309, 390, 257, 4002, 2010], "temperature": 0.0, "avg_logprob": -0.25906174357344464, "compression_ratio": 1.7127659574468086, "no_speech_prob": 1.994691956497263e-06}, {"id": 642, "seek": 323870, "start": 3262.8599999999997, "end": 3264.8599999999997, "text": " Is because when we imported it?", "tokens": [1119, 570, 562, 321, 25524, 309, 30], "temperature": 0.0, "avg_logprob": -0.25906174357344464, "compression_ratio": 1.7127659574468086, "no_speech_prob": 1.994691956497263e-06}, {"id": 643, "seek": 326486, "start": 3264.86, "end": 3269.98, "text": " We said pause dates equals and told pandas", "tokens": [492, 848, 10465, 11691, 6915, 293, 1907, 4565, 296], "temperature": 0.0, "avg_logprob": -0.1964007467031479, "compression_ratio": 1.5241379310344827, "no_speech_prob": 3.966932581533911e-06}, {"id": 644, "seek": 326486, "start": 3269.98, "end": 3276.3, "text": " It's a date type so as long as it looks date ish and we tell it to pause it as a date", "tokens": [467, 311, 257, 4002, 2010, 370, 382, 938, 382, 309, 1542, 4002, 307, 71, 293, 321, 980, 309, 281, 10465, 309, 382, 257, 4002], "temperature": 0.0, "avg_logprob": -0.1964007467031479, "compression_ratio": 1.5241379310344827, "no_speech_prob": 3.966932581533911e-06}, {"id": 645, "seek": 326486, "start": 3284.3, "end": 3285.5, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.1964007467031479, "compression_ratio": 1.5241379310344827, "no_speech_prob": 3.966932581533911e-06}, {"id": 646, "seek": 326486, "start": 3285.5, "end": 3291.1400000000003, "text": " I think there might be but for some reason it wasn't ideal like maybe it took lots of time", "tokens": [286, 519, 456, 1062, 312, 457, 337, 512, 1778, 309, 2067, 380, 7157, 411, 1310, 309, 1890, 3195, 295, 565], "temperature": 0.0, "avg_logprob": -0.1964007467031479, "compression_ratio": 1.5241379310344827, "no_speech_prob": 3.966932581533911e-06}, {"id": 647, "seek": 329114, "start": 3291.14, "end": 3295.6, "text": " Or it didn't always work or for some reason I had to list it here", "tokens": [1610, 309, 994, 380, 1009, 589, 420, 337, 512, 1778, 286, 632, 281, 1329, 309, 510], "temperature": 0.0, "avg_logprob": -0.1535222019468035, "compression_ratio": 1.3856209150326797, "no_speech_prob": 4.198341048322618e-05}, {"id": 648, "seek": 329114, "start": 3295.6, "end": 3302.22, "text": " I would suggest checking out the docs to pandas dot read CSV and maybe on the forum you can tell us what you find", "tokens": [286, 576, 3402, 8568, 484, 264, 45623, 281, 4565, 296, 5893, 1401, 48814, 293, 1310, 322, 264, 17542, 291, 393, 980, 505, 437, 291, 915], "temperature": 0.0, "avg_logprob": -0.1535222019468035, "compression_ratio": 1.3856209150326797, "no_speech_prob": 4.198341048322618e-05}, {"id": 649, "seek": 329114, "start": 3302.22, "end": 3304.22, "text": " Because I can't remember offhand", "tokens": [1436, 286, 393, 380, 1604, 766, 5543], "temperature": 0.0, "avg_logprob": -0.1535222019468035, "compression_ratio": 1.3856209150326797, "no_speech_prob": 4.198341048322618e-05}, {"id": 650, "seek": 330422, "start": 3304.22, "end": 3306.22, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.21959898206922743, "compression_ratio": 1.425, "no_speech_prob": 6.1438718148565385e-06}, {"id": 651, "seek": 330422, "start": 3319.18, "end": 3326.02, "text": " Let's do that one on the same forum thread that's Anna creates because I think it's a reasonably advanced question, but generally speaking the", "tokens": [961, 311, 360, 300, 472, 322, 264, 912, 17542, 7207, 300, 311, 12899, 7829, 570, 286, 519, 309, 311, 257, 23551, 7339, 1168, 11, 457, 5101, 4124, 264], "temperature": 0.0, "avg_logprob": -0.21959898206922743, "compression_ratio": 1.425, "no_speech_prob": 6.1438718148565385e-06}, {"id": 652, "seek": 330422, "start": 3326.74, "end": 3331.66, "text": " time zone in a properly formatted date will be included in the string and it should", "tokens": [565, 6668, 294, 257, 6108, 1254, 32509, 4002, 486, 312, 5556, 294, 264, 6798, 293, 309, 820], "temperature": 0.0, "avg_logprob": -0.21959898206922743, "compression_ratio": 1.425, "no_speech_prob": 6.1438718148565385e-06}, {"id": 653, "seek": 333166, "start": 3331.66, "end": 3338.3999999999996, "text": " Format it should pull it out correctly and turn it into a universal time zone so generally speaking it should handle it for you", "tokens": [10126, 267, 309, 820, 2235, 309, 484, 8944, 293, 1261, 309, 666, 257, 11455, 565, 6668, 370, 5101, 4124, 309, 820, 4813, 309, 337, 291], "temperature": 0.0, "avg_logprob": -0.30895493735729807, "compression_ratio": 1.5510204081632653, "no_speech_prob": 6.643341293965932e-06}, {"id": 654, "seek": 333166, "start": 3341.8199999999997, "end": 3347.56, "text": " So notice you for indexing a column you think to shape only use the dot", "tokens": [407, 3449, 291, 337, 8186, 278, 257, 7738, 291, 519, 281, 3909, 787, 764, 264, 5893], "temperature": 0.0, "avg_logprob": -0.30895493735729807, "compression_ratio": 1.5510204081632653, "no_speech_prob": 6.643341293965932e-06}, {"id": 655, "seek": 333166, "start": 3353.54, "end": 3355.54, "text": " The square brackets one is safer", "tokens": [440, 3732, 26179, 472, 307, 15856], "temperature": 0.0, "avg_logprob": -0.30895493735729807, "compression_ratio": 1.5510204081632653, "no_speech_prob": 6.643341293965932e-06}, {"id": 656, "seek": 333166, "start": 3356.5, "end": 3360.06, "text": " Particularly if you're assigning to a column if it didn't already exist", "tokens": [32281, 498, 291, 434, 49602, 281, 257, 7738, 498, 309, 994, 380, 1217, 2514], "temperature": 0.0, "avg_logprob": -0.30895493735729807, "compression_ratio": 1.5510204081632653, "no_speech_prob": 6.643341293965932e-06}, {"id": 657, "seek": 336006, "start": 3360.06, "end": 3363.66, "text": " You need to use the square brackets format otherwise you'll get weird errors", "tokens": [509, 643, 281, 764, 264, 3732, 26179, 7877, 5911, 291, 603, 483, 3657, 13603], "temperature": 0.0, "avg_logprob": -0.15440056370753868, "compression_ratio": 1.8208333333333333, "no_speech_prob": 7.296257081179647e-06}, {"id": 658, "seek": 336006, "start": 3364.2599999999998, "end": 3369.7, "text": " So the square brackets format is safer the dot version saves me like a couple of keystrokes", "tokens": [407, 264, 3732, 26179, 7877, 307, 15856, 264, 5893, 3037, 19155, 385, 411, 257, 1916, 295, 2141, 27616, 5993], "temperature": 0.0, "avg_logprob": -0.15440056370753868, "compression_ratio": 1.8208333333333333, "no_speech_prob": 7.296257081179647e-06}, {"id": 659, "seek": 336006, "start": 3369.74, "end": 3371.74, "text": " So I probably use it more than I should", "tokens": [407, 286, 1391, 764, 309, 544, 813, 286, 820], "temperature": 0.0, "avg_logprob": -0.15440056370753868, "compression_ratio": 1.8208333333333333, "no_speech_prob": 7.296257081179647e-06}, {"id": 660, "seek": 336006, "start": 3372.94, "end": 3374.94, "text": " in this particular case", "tokens": [294, 341, 1729, 1389], "temperature": 0.0, "avg_logprob": -0.15440056370753868, "compression_ratio": 1.8208333333333333, "no_speech_prob": 7.296257081179647e-06}, {"id": 661, "seek": 336006, "start": 3376.34, "end": 3383.6, "text": " Because I wanted to grab something that was had field name was had something inside it wasn't the name itself", "tokens": [1436, 286, 1415, 281, 4444, 746, 300, 390, 632, 2519, 1315, 390, 632, 746, 1854, 309, 2067, 380, 264, 1315, 2564], "temperature": 0.0, "avg_logprob": -0.15440056370753868, "compression_ratio": 1.8208333333333333, "no_speech_prob": 7.296257081179647e-06}, {"id": 662, "seek": 336006, "start": 3383.6, "end": 3385.5, "text": " I have to use square brackets", "tokens": [286, 362, 281, 764, 3732, 26179], "temperature": 0.0, "avg_logprob": -0.15440056370753868, "compression_ratio": 1.8208333333333333, "no_speech_prob": 7.296257081179647e-06}, {"id": 663, "seek": 338550, "start": 3385.5, "end": 3390.26, "text": " So square brackets is going to be your your safe bet if in doubt so", "tokens": [407, 3732, 26179, 307, 516, 281, 312, 428, 428, 3273, 778, 498, 294, 6385, 370], "temperature": 0.0, "avg_logprob": -0.20287684031895228, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.7061739754353766e-06}, {"id": 664, "seek": 338550, "start": 3391.94, "end": 3393.94, "text": " After I run that", "tokens": [2381, 286, 1190, 300], "temperature": 0.0, "avg_logprob": -0.20287684031895228, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.7061739754353766e-06}, {"id": 665, "seek": 338550, "start": 3396.18, "end": 3398.18, "text": " You'll notice that", "tokens": [509, 603, 3449, 300], "temperature": 0.0, "avg_logprob": -0.20287684031895228, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.7061739754353766e-06}, {"id": 666, "seek": 338550, "start": 3398.66, "end": 3400.3, "text": " DF raw", "tokens": [48336, 8936], "temperature": 0.0, "avg_logprob": -0.20287684031895228, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.7061739754353766e-06}, {"id": 667, "seek": 338550, "start": 3400.3, "end": 3402.98, "text": " Dot columns gives me a list of all of the columns", "tokens": [38753, 13766, 2709, 385, 257, 1329, 295, 439, 295, 264, 13766], "temperature": 0.0, "avg_logprob": -0.20287684031895228, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.7061739754353766e-06}, {"id": 668, "seek": 338550, "start": 3403.7, "end": 3409.78, "text": " Just as strings and at the end there they all are right, so it's removed sale date, and it's added all those", "tokens": [1449, 382, 13985, 293, 412, 264, 917, 456, 436, 439, 366, 558, 11, 370, 309, 311, 7261, 8680, 4002, 11, 293, 309, 311, 3869, 439, 729], "temperature": 0.0, "avg_logprob": -0.20287684031895228, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.7061739754353766e-06}, {"id": 669, "seek": 338550, "start": 3410.54, "end": 3412.54, "text": " So that's not quite enough", "tokens": [407, 300, 311, 406, 1596, 1547], "temperature": 0.0, "avg_logprob": -0.20287684031895228, "compression_ratio": 1.50253807106599, "no_speech_prob": 1.7061739754353766e-06}, {"id": 670, "seek": 341254, "start": 3412.54, "end": 3418.7, "text": " The other problem is that we've got a whole bunch of strings in there right so", "tokens": [440, 661, 1154, 307, 300, 321, 600, 658, 257, 1379, 3840, 295, 13985, 294, 456, 558, 370], "temperature": 0.0, "avg_logprob": -0.29200321197509765, "compression_ratio": 1.3257575757575757, "no_speech_prob": 2.190760824305471e-06}, {"id": 671, "seek": 341254, "start": 3422.06, "end": 3424.06, "text": " You can just leave that there do you want to pass it back?", "tokens": [509, 393, 445, 1856, 300, 456, 360, 291, 528, 281, 1320, 309, 646, 30], "temperature": 0.0, "avg_logprob": -0.29200321197509765, "compression_ratio": 1.3257575757575757, "no_speech_prob": 2.190760824305471e-06}, {"id": 672, "seek": 341254, "start": 3430.22, "end": 3432.22, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.29200321197509765, "compression_ratio": 1.3257575757575757, "no_speech_prob": 2.190760824305471e-06}, {"id": 673, "seek": 341254, "start": 3432.86, "end": 3436.42, "text": " Is like low high medium, thank you", "tokens": [1119, 411, 2295, 1090, 6399, 11, 1309, 291], "temperature": 0.0, "avg_logprob": -0.29200321197509765, "compression_ratio": 1.3257575757575757, "no_speech_prob": 2.190760824305471e-06}, {"id": 674, "seek": 343642, "start": 3436.42, "end": 3442.02, "text": " All right, so pandas actually has a concept of a category data type", "tokens": [1057, 558, 11, 370, 4565, 296, 767, 575, 257, 3410, 295, 257, 7719, 1412, 2010], "temperature": 0.0, "avg_logprob": -0.13805321972779552, "compression_ratio": 1.782426778242678, "no_speech_prob": 8.315239483636105e-07}, {"id": 675, "seek": 343642, "start": 3442.02, "end": 3448.3, "text": " But by default it doesn't turn anything into a category for you, so I've created something called train cats", "tokens": [583, 538, 7576, 309, 1177, 380, 1261, 1340, 666, 257, 7719, 337, 291, 11, 370, 286, 600, 2942, 746, 1219, 3847, 11111], "temperature": 0.0, "avg_logprob": -0.13805321972779552, "compression_ratio": 1.782426778242678, "no_speech_prob": 8.315239483636105e-07}, {"id": 676, "seek": 343642, "start": 3450.86, "end": 3455.52, "text": " Which creates categorical variables for everything that's a string", "tokens": [3013, 7829, 19250, 804, 9102, 337, 1203, 300, 311, 257, 6798], "temperature": 0.0, "avg_logprob": -0.13805321972779552, "compression_ratio": 1.782426778242678, "no_speech_prob": 8.315239483636105e-07}, {"id": 677, "seek": 343642, "start": 3456.1, "end": 3460.82, "text": " Okay, and so what that's going to do is behind the scenes is going to create a column", "tokens": [1033, 11, 293, 370, 437, 300, 311, 516, 281, 360, 307, 2261, 264, 8026, 307, 516, 281, 1884, 257, 7738], "temperature": 0.0, "avg_logprob": -0.13805321972779552, "compression_ratio": 1.782426778242678, "no_speech_prob": 8.315239483636105e-07}, {"id": 678, "seek": 346082, "start": 3460.82, "end": 3467.44, "text": " That's actually a number right as an integer, and it's going to store a mapping from the integers to the strings", "tokens": [663, 311, 767, 257, 1230, 558, 382, 364, 24922, 11, 293, 309, 311, 516, 281, 3531, 257, 18350, 490, 264, 41674, 281, 264, 13985], "temperature": 0.0, "avg_logprob": -0.17387267139470466, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.7880520317703485e-06}, {"id": 679, "seek": 346082, "start": 3467.98, "end": 3469.78, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.17387267139470466, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.7880520317703485e-06}, {"id": 680, "seek": 346082, "start": 3469.78, "end": 3473.06, "text": " The reason it's train cats is that you use this for the training set", "tokens": [440, 1778, 309, 311, 3847, 11111, 307, 300, 291, 764, 341, 337, 264, 3097, 992], "temperature": 0.0, "avg_logprob": -0.17387267139470466, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.7880520317703485e-06}, {"id": 681, "seek": 346082, "start": 3473.34, "end": 3479.04, "text": " More advanced usage is that when we get to looking at the test and validation sets this is really important idea", "tokens": [5048, 7339, 14924, 307, 300, 562, 321, 483, 281, 1237, 412, 264, 1500, 293, 24071, 6352, 341, 307, 534, 1021, 1558], "temperature": 0.0, "avg_logprob": -0.17387267139470466, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.7880520317703485e-06}, {"id": 682, "seek": 346082, "start": 3480.7400000000002, "end": 3484.9, "text": " In fact Terrence came to me the other day, and he said my models not working", "tokens": [682, 1186, 6564, 10760, 1361, 281, 385, 264, 661, 786, 11, 293, 415, 848, 452, 5245, 406, 1364], "temperature": 0.0, "avg_logprob": -0.17387267139470466, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.7880520317703485e-06}, {"id": 683, "seek": 346082, "start": 3485.1800000000003, "end": 3489.26, "text": " Why not and he figured it out for himself it turned out the reason", "tokens": [1545, 406, 293, 415, 8932, 309, 484, 337, 3647, 309, 3574, 484, 264, 1778], "temperature": 0.0, "avg_logprob": -0.17387267139470466, "compression_ratio": 1.7038461538461538, "no_speech_prob": 1.7880520317703485e-06}, {"id": 684, "seek": 348926, "start": 3489.26, "end": 3495.0200000000004, "text": " Why was because the mappings he was using from string to number in the training set were different to the mappings", "tokens": [1545, 390, 570, 264, 463, 28968, 415, 390, 1228, 490, 6798, 281, 1230, 294, 264, 3097, 992, 645, 819, 281, 264, 463, 28968], "temperature": 0.0, "avg_logprob": -0.14563902988228747, "compression_ratio": 2.0, "no_speech_prob": 1.3081679526294465e-06}, {"id": 685, "seek": 348926, "start": 3495.0200000000004, "end": 3499.38, "text": " He was using from string to number in the test set so therefore in the training set", "tokens": [634, 390, 1228, 490, 6798, 281, 1230, 294, 264, 1500, 992, 370, 4412, 294, 264, 3097, 992], "temperature": 0.0, "avg_logprob": -0.14563902988228747, "compression_ratio": 2.0, "no_speech_prob": 1.3081679526294465e-06}, {"id": 686, "seek": 348926, "start": 3499.94, "end": 3507.2200000000003, "text": " High might have been three, but in the trait test set it might have been two so the two were totally different", "tokens": [5229, 1062, 362, 668, 1045, 11, 457, 294, 264, 22538, 1500, 992, 309, 1062, 362, 668, 732, 370, 264, 732, 645, 3879, 819], "temperature": 0.0, "avg_logprob": -0.14563902988228747, "compression_ratio": 2.0, "no_speech_prob": 1.3081679526294465e-06}, {"id": 687, "seek": 348926, "start": 3507.2200000000003, "end": 3511.86, "text": " And so the model was basically non predictive okay, so I have another function", "tokens": [400, 370, 264, 2316, 390, 1936, 2107, 35521, 1392, 11, 370, 286, 362, 1071, 2445], "temperature": 0.0, "avg_logprob": -0.14563902988228747, "compression_ratio": 2.0, "no_speech_prob": 1.3081679526294465e-06}, {"id": 688, "seek": 348926, "start": 3514.1400000000003, "end": 3516.1400000000003, "text": " Called apply categories", "tokens": [45001, 3079, 10479], "temperature": 0.0, "avg_logprob": -0.14563902988228747, "compression_ratio": 2.0, "no_speech_prob": 1.3081679526294465e-06}, {"id": 689, "seek": 351614, "start": 3516.14, "end": 3521.22, "text": " Where you can pass in your existing training set and it'll use the same?", "tokens": [2305, 291, 393, 1320, 294, 428, 6741, 3097, 992, 293, 309, 603, 764, 264, 912, 30], "temperature": 0.0, "avg_logprob": -0.18468993969177933, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.4060821033344837e-06}, {"id": 690, "seek": 351614, "start": 3521.74, "end": 3526.42, "text": " Mappings to let you'll make sure your test set of validation set uses the same mappings okay?", "tokens": [376, 1746, 1109, 281, 718, 291, 603, 652, 988, 428, 1500, 992, 295, 24071, 992, 4960, 264, 912, 463, 28968, 1392, 30], "temperature": 0.0, "avg_logprob": -0.18468993969177933, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.4060821033344837e-06}, {"id": 691, "seek": 351614, "start": 3526.46, "end": 3532.22, "text": " So when I go train cats it's actually not going to make the data frame look different at all", "tokens": [407, 562, 286, 352, 3847, 11111, 309, 311, 767, 406, 516, 281, 652, 264, 1412, 3920, 574, 819, 412, 439], "temperature": 0.0, "avg_logprob": -0.18468993969177933, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.4060821033344837e-06}, {"id": 692, "seek": 351614, "start": 3532.9, "end": 3535.9, "text": " Behind the scenes it's going to turn them all into numbers", "tokens": [20475, 264, 8026, 309, 311, 516, 281, 1261, 552, 439, 666, 3547], "temperature": 0.0, "avg_logprob": -0.18468993969177933, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.4060821033344837e-06}, {"id": 693, "seek": 351614, "start": 3538.94, "end": 3540.94, "text": " We finish at 12", "tokens": [492, 2413, 412, 2272], "temperature": 0.0, "avg_logprob": -0.18468993969177933, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.4060821033344837e-06}, {"id": 694, "seek": 354094, "start": 3540.94, "end": 3545.1, "text": " 1150 and then our", "tokens": [2975, 2803, 293, 550, 527], "temperature": 0.0, "avg_logprob": -0.2171342006096473, "compression_ratio": 1.7768240343347639, "no_speech_prob": 4.860339231527178e-06}, {"id": 695, "seek": 354094, "start": 3549.5, "end": 3551.5, "text": " Let's see how we go I'll try and finish on time", "tokens": [961, 311, 536, 577, 321, 352, 286, 603, 853, 293, 2413, 322, 565], "temperature": 0.0, "avg_logprob": -0.2171342006096473, "compression_ratio": 1.7768240343347639, "no_speech_prob": 4.860339231527178e-06}, {"id": 696, "seek": 354094, "start": 3551.54, "end": 3557.9, "text": " So you'll see now remember I mentioned there was this dot DT attribute that gives you access to everything assuming", "tokens": [407, 291, 603, 536, 586, 1604, 286, 2835, 456, 390, 341, 5893, 413, 51, 19667, 300, 2709, 291, 2105, 281, 1203, 11926], "temperature": 0.0, "avg_logprob": -0.2171342006096473, "compression_ratio": 1.7768240343347639, "no_speech_prob": 4.860339231527178e-06}, {"id": 697, "seek": 354094, "start": 3557.9, "end": 3559.46, "text": " It's a date time about the date time", "tokens": [467, 311, 257, 4002, 565, 466, 264, 4002, 565], "temperature": 0.0, "avg_logprob": -0.2171342006096473, "compression_ratio": 1.7768240343347639, "no_speech_prob": 4.860339231527178e-06}, {"id": 698, "seek": 354094, "start": 3559.46, "end": 3566.9, "text": " There's a dot cat attribute that gives you access to things assuming something's a category right and so usage band was a string", "tokens": [821, 311, 257, 5893, 3857, 19667, 300, 2709, 291, 2105, 281, 721, 11926, 746, 311, 257, 7719, 558, 293, 370, 14924, 4116, 390, 257, 6798], "temperature": 0.0, "avg_logprob": -0.2171342006096473, "compression_ratio": 1.7768240343347639, "no_speech_prob": 4.860339231527178e-06}, {"id": 699, "seek": 354094, "start": 3566.9, "end": 3570.26, "text": " And so now that I've run train cats it's turned it into a category", "tokens": [400, 370, 586, 300, 286, 600, 1190, 3847, 11111, 309, 311, 3574, 309, 666, 257, 7719], "temperature": 0.0, "avg_logprob": -0.2171342006096473, "compression_ratio": 1.7768240343347639, "no_speech_prob": 4.860339231527178e-06}, {"id": 700, "seek": 357026, "start": 3570.26, "end": 3572.26, "text": " So I can go", "tokens": [407, 286, 393, 352], "temperature": 0.0, "avg_logprob": -0.20020822618828446, "compression_ratio": 1.7808764940239044, "no_speech_prob": 1.3496978681359906e-06}, {"id": 701, "seek": 357026, "start": 3572.38, "end": 3574.46, "text": " df raw dot usage band", "tokens": [274, 69, 8936, 5893, 14924, 4116], "temperature": 0.0, "avg_logprob": -0.20020822618828446, "compression_ratio": 1.7808764940239044, "no_speech_prob": 1.3496978681359906e-06}, {"id": 702, "seek": 357026, "start": 3575.46, "end": 3576.5800000000004, "text": " cat", "tokens": [3857], "temperature": 0.0, "avg_logprob": -0.20020822618828446, "compression_ratio": 1.7808764940239044, "no_speech_prob": 1.3496978681359906e-06}, {"id": 703, "seek": 357026, "start": 3576.5800000000004, "end": 3579.5, "text": " Right and there's a whole bunch of other things we've got there, okay?", "tokens": [1779, 293, 456, 311, 257, 1379, 3840, 295, 661, 721, 321, 600, 658, 456, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.20020822618828446, "compression_ratio": 1.7808764940239044, "no_speech_prob": 1.3496978681359906e-06}, {"id": 704, "seek": 357026, "start": 3580.5800000000004, "end": 3584.42, "text": " So one of the things we've got there is dot categories, and you can see here is the list", "tokens": [407, 472, 295, 264, 721, 321, 600, 658, 456, 307, 5893, 10479, 11, 293, 291, 393, 536, 510, 307, 264, 1329], "temperature": 0.0, "avg_logprob": -0.20020822618828446, "compression_ratio": 1.7808764940239044, "no_speech_prob": 1.3496978681359906e-06}, {"id": 705, "seek": 357026, "start": 3585.94, "end": 3591.7400000000002, "text": " Now one of the things you might notice is that this list is in a bit of a weird order high low medium", "tokens": [823, 472, 295, 264, 721, 291, 1062, 3449, 307, 300, 341, 1329, 307, 294, 257, 857, 295, 257, 3657, 1668, 1090, 2295, 6399], "temperature": 0.0, "avg_logprob": -0.20020822618828446, "compression_ratio": 1.7808764940239044, "no_speech_prob": 1.3496978681359906e-06}, {"id": 706, "seek": 357026, "start": 3592.2200000000003, "end": 3594.6200000000003, "text": " The truth is it doesn't matter too much", "tokens": [440, 3494, 307, 309, 1177, 380, 1871, 886, 709], "temperature": 0.0, "avg_logprob": -0.20020822618828446, "compression_ratio": 1.7808764940239044, "no_speech_prob": 1.3496978681359906e-06}, {"id": 707, "seek": 359462, "start": 3594.62, "end": 3599.9, "text": " But what's going to happen when we use the random forest is it's actually going to this is going to be zero", "tokens": [583, 437, 311, 516, 281, 1051, 562, 321, 764, 264, 4974, 6719, 307, 309, 311, 767, 516, 281, 341, 307, 516, 281, 312, 4018], "temperature": 0.0, "avg_logprob": -0.1263066888824711, "compression_ratio": 1.906015037593985, "no_speech_prob": 6.179377010084863e-07}, {"id": 708, "seek": 359462, "start": 3599.9, "end": 3603.7799999999997, "text": " This is going to be one this is going to be two and we're going to be creating decision trees", "tokens": [639, 307, 516, 281, 312, 472, 341, 307, 516, 281, 312, 732, 293, 321, 434, 516, 281, 312, 4084, 3537, 5852], "temperature": 0.0, "avg_logprob": -0.1263066888824711, "compression_ratio": 1.906015037593985, "no_speech_prob": 6.179377010084863e-07}, {"id": 709, "seek": 359462, "start": 3603.7799999999997, "end": 3609.24, "text": " And so we're going to have a decision tree that can split things at a single point so it either be high", "tokens": [400, 370, 321, 434, 516, 281, 362, 257, 3537, 4230, 300, 393, 7472, 721, 412, 257, 2167, 935, 370, 309, 2139, 312, 1090], "temperature": 0.0, "avg_logprob": -0.1263066888824711, "compression_ratio": 1.906015037593985, "no_speech_prob": 6.179377010084863e-07}, {"id": 710, "seek": 359462, "start": 3609.7799999999997, "end": 3617.02, "text": " Versus low and medium or medium versus high and low that would be kind of weird right it actually turns out not to work", "tokens": [12226, 301, 2295, 293, 6399, 420, 6399, 5717, 1090, 293, 2295, 300, 576, 312, 733, 295, 3657, 558, 309, 767, 4523, 484, 406, 281, 589], "temperature": 0.0, "avg_logprob": -0.1263066888824711, "compression_ratio": 1.906015037593985, "no_speech_prob": 6.179377010084863e-07}, {"id": 711, "seek": 359462, "start": 3617.02, "end": 3621.48, "text": " Too badly, but it'll work a little bit better if you have these insensible orders", "tokens": [11395, 13425, 11, 457, 309, 603, 589, 257, 707, 857, 1101, 498, 291, 362, 613, 1028, 30633, 9470], "temperature": 0.0, "avg_logprob": -0.1263066888824711, "compression_ratio": 1.906015037593985, "no_speech_prob": 6.179377010084863e-07}, {"id": 712, "seek": 362148, "start": 3621.48, "end": 3627.64, "text": " Okay, so if you want to reorder a category, then you can just go cat dot set categories and pass in", "tokens": [1033, 11, 370, 498, 291, 528, 281, 319, 4687, 257, 7719, 11, 550, 291, 393, 445, 352, 3857, 5893, 992, 10479, 293, 1320, 294], "temperature": 0.0, "avg_logprob": -0.11315328341263992, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.5215590540028643e-06}, {"id": 713, "seek": 362148, "start": 3628.28, "end": 3634.6, "text": " The order you want until it is ordered and almost every pandas method has an in place", "tokens": [440, 1668, 291, 528, 1826, 309, 307, 8866, 293, 1920, 633, 4565, 296, 3170, 575, 364, 294, 1081], "temperature": 0.0, "avg_logprob": -0.11315328341263992, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.5215590540028643e-06}, {"id": 714, "seek": 362148, "start": 3636.28, "end": 3640.4, "text": " Parameter which rather than returning a new data frame. It's going to change that data frame", "tokens": [34882, 2398, 597, 2831, 813, 12678, 257, 777, 1412, 3920, 13, 467, 311, 516, 281, 1319, 300, 1412, 3920], "temperature": 0.0, "avg_logprob": -0.11315328341263992, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.5215590540028643e-06}, {"id": 715, "seek": 362148, "start": 3641.16, "end": 3645.0, "text": " Okay, so I'm not going to do that like I didn't check that carefully for categories", "tokens": [1033, 11, 370, 286, 478, 406, 516, 281, 360, 300, 411, 286, 994, 380, 1520, 300, 7500, 337, 10479], "temperature": 0.0, "avg_logprob": -0.11315328341263992, "compression_ratio": 1.7137096774193548, "no_speech_prob": 2.5215590540028643e-06}, {"id": 716, "seek": 364500, "start": 3645.0, "end": 3651.72, "text": " It should be ordered, but this seems like a pretty obvious one", "tokens": [467, 820, 312, 8866, 11, 457, 341, 2544, 411, 257, 1238, 6322, 472], "temperature": 0.0, "avg_logprob": -0.312739992898608, "compression_ratio": 1.4666666666666666, "no_speech_prob": 3.1875408694759244e-06}, {"id": 717, "seek": 364500, "start": 3651.72, "end": 3655.72, "text": " Can you reiterate that issue? I don't understand what the problem is", "tokens": [1664, 291, 33528, 300, 2734, 30, 286, 500, 380, 1223, 437, 264, 1154, 307], "temperature": 0.0, "avg_logprob": -0.312739992898608, "compression_ratio": 1.4666666666666666, "no_speech_prob": 3.1875408694759244e-06}, {"id": 718, "seek": 364500, "start": 3655.92, "end": 3657.92, "text": " Sure, so", "tokens": [4894, 11, 370], "temperature": 0.0, "avg_logprob": -0.312739992898608, "compression_ratio": 1.4666666666666666, "no_speech_prob": 3.1875408694759244e-06}, {"id": 719, "seek": 364500, "start": 3658.36, "end": 3660.36, "text": " the usage band column", "tokens": [264, 14924, 4116, 7738], "temperature": 0.0, "avg_logprob": -0.312739992898608, "compression_ratio": 1.4666666666666666, "no_speech_prob": 3.1875408694759244e-06}, {"id": 720, "seek": 364500, "start": 3664.88, "end": 3666.88, "text": " Is actually going to be", "tokens": [1119, 767, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.312739992898608, "compression_ratio": 1.4666666666666666, "no_speech_prob": 3.1875408694759244e-06}, {"id": 721, "seek": 366688, "start": 3666.88, "end": 3676.88, "text": " This is actually what our random forest is going to see these numbers 1 0 2 1", "tokens": [639, 307, 767, 437, 527, 4974, 6719, 307, 516, 281, 536, 613, 3547, 502, 1958, 568, 502], "temperature": 0.0, "avg_logprob": -0.1940865309342094, "compression_ratio": 1.8142857142857143, "no_speech_prob": 1.7603259720999631e-06}, {"id": 722, "seek": 366688, "start": 3676.88, "end": 3683.86, "text": " Okay, and they map to the position in this array and as we're going to learn shortly a random forest consists of a bunch of trees", "tokens": [1033, 11, 293, 436, 4471, 281, 264, 2535, 294, 341, 10225, 293, 382, 321, 434, 516, 281, 1466, 13392, 257, 4974, 6719, 14689, 295, 257, 3840, 295, 5852], "temperature": 0.0, "avg_logprob": -0.1940865309342094, "compression_ratio": 1.8142857142857143, "no_speech_prob": 1.7603259720999631e-06}, {"id": 723, "seek": 366688, "start": 3684.08, "end": 3688.04, "text": " That's going to make a single split and the single split is going to be either", "tokens": [663, 311, 516, 281, 652, 257, 2167, 7472, 293, 264, 2167, 7472, 307, 516, 281, 312, 2139], "temperature": 0.0, "avg_logprob": -0.1940865309342094, "compression_ratio": 1.8142857142857143, "no_speech_prob": 1.7603259720999631e-06}, {"id": 724, "seek": 366688, "start": 3688.6, "end": 3695.04, "text": " Greater than or less than one or greater than or less than two right so we could split it into", "tokens": [38410, 813, 420, 1570, 813, 472, 420, 5044, 813, 420, 1570, 813, 732, 558, 370, 321, 727, 7472, 309, 666], "temperature": 0.0, "avg_logprob": -0.1940865309342094, "compression_ratio": 1.8142857142857143, "no_speech_prob": 1.7603259720999631e-06}, {"id": 725, "seek": 369504, "start": 3695.04, "end": 3697.04, "text": " high", "tokens": [1090], "temperature": 0.0, "avg_logprob": -0.19024531046549478, "compression_ratio": 1.8518518518518519, "no_speech_prob": 7.071819709381089e-06}, {"id": 726, "seek": 369504, "start": 3697.12, "end": 3702.94, "text": " Versus low and medium which that semantically makes sense like is it big or we could split it into", "tokens": [12226, 301, 2295, 293, 6399, 597, 300, 4361, 49505, 1669, 2020, 411, 307, 309, 955, 420, 321, 727, 7472, 309, 666], "temperature": 0.0, "avg_logprob": -0.19024531046549478, "compression_ratio": 1.8518518518518519, "no_speech_prob": 7.071819709381089e-06}, {"id": 727, "seek": 369504, "start": 3703.56, "end": 3707.24, "text": " Medium versus high and low it doesn't make much sense", "tokens": [38915, 5717, 1090, 293, 2295, 309, 1177, 380, 652, 709, 2020], "temperature": 0.0, "avg_logprob": -0.19024531046549478, "compression_ratio": 1.8518518518518519, "no_speech_prob": 7.071819709381089e-06}, {"id": 728, "seek": 369504, "start": 3707.72, "end": 3712.62, "text": " Right so in practice the decision tree could then make a second split to say like", "tokens": [1779, 370, 294, 3124, 264, 3537, 4230, 727, 550, 652, 257, 1150, 7472, 281, 584, 411], "temperature": 0.0, "avg_logprob": -0.19024531046549478, "compression_ratio": 1.8518518518518519, "no_speech_prob": 7.071819709381089e-06}, {"id": 729, "seek": 369504, "start": 3712.84, "end": 3716.0, "text": " Medium versus high and low and then within the high and low into high and low", "tokens": [38915, 5717, 1090, 293, 2295, 293, 550, 1951, 264, 1090, 293, 2295, 666, 1090, 293, 2295], "temperature": 0.0, "avg_logprob": -0.19024531046549478, "compression_ratio": 1.8518518518518519, "no_speech_prob": 7.071819709381089e-06}, {"id": 730, "seek": 369504, "start": 3716.12, "end": 3721.2, "text": " But by putting it in a sensible order if it wants to split out low it can do it in", "tokens": [583, 538, 3372, 309, 294, 257, 25380, 1668, 498, 309, 2738, 281, 7472, 484, 2295, 309, 393, 360, 309, 294], "temperature": 0.0, "avg_logprob": -0.19024531046549478, "compression_ratio": 1.8518518518518519, "no_speech_prob": 7.071819709381089e-06}, {"id": 731, "seek": 372120, "start": 3721.2, "end": 3725.68, "text": " One decision rather than two and we'll be learning more about this shortly", "tokens": [1485, 3537, 2831, 813, 732, 293, 321, 603, 312, 2539, 544, 466, 341, 13392], "temperature": 0.0, "avg_logprob": -0.20176220784145119, "compression_ratio": 1.7589928057553956, "no_speech_prob": 3.3405053727619816e-06}, {"id": 732, "seek": 372120, "start": 3727.0, "end": 3730.3999999999996, "text": " It's it honestly it's not a big deal, but I just wanted to mention. It's there and", "tokens": [467, 311, 309, 6095, 309, 311, 406, 257, 955, 2028, 11, 457, 286, 445, 1415, 281, 2152, 13, 467, 311, 456, 293], "temperature": 0.0, "avg_logprob": -0.20176220784145119, "compression_ratio": 1.7589928057553956, "no_speech_prob": 3.3405053727619816e-06}, {"id": 733, "seek": 372120, "start": 3731.64, "end": 3736.9399999999996, "text": " It's also good to know that people when they talk about like different types of categorical variable", "tokens": [467, 311, 611, 665, 281, 458, 300, 561, 562, 436, 751, 466, 411, 819, 3467, 295, 19250, 804, 7006], "temperature": 0.0, "avg_logprob": -0.20176220784145119, "compression_ratio": 1.7589928057553956, "no_speech_prob": 3.3405053727619816e-06}, {"id": 734, "seek": 372120, "start": 3737.7599999999998, "end": 3741.7999999999997, "text": " Specifically you need to know there's a kind of categorical variable called ordinal and an ordinal", "tokens": [26058, 291, 643, 281, 458, 456, 311, 257, 733, 295, 19250, 804, 7006, 1219, 4792, 2071, 293, 364, 4792, 2071], "temperature": 0.0, "avg_logprob": -0.20176220784145119, "compression_ratio": 1.7589928057553956, "no_speech_prob": 3.3405053727619816e-06}, {"id": 735, "seek": 372120, "start": 3742.08, "end": 3750.52, "text": " Categorical variable is one that has some kind of order like high medium and low right and random forests aren't terribly sensitive", "tokens": [383, 2968, 284, 804, 7006, 307, 472, 300, 575, 512, 733, 295, 1668, 411, 1090, 6399, 293, 2295, 558, 293, 4974, 21700, 3212, 380, 22903, 9477], "temperature": 0.0, "avg_logprob": -0.20176220784145119, "compression_ratio": 1.7589928057553956, "no_speech_prob": 3.3405053727619816e-06}, {"id": 736, "seek": 375052, "start": 3750.52, "end": 3752.52, "text": " to that fact", "tokens": [281, 300, 1186], "temperature": 0.0, "avg_logprob": -0.21239946983956, "compression_ratio": 1.5934065934065933, "no_speech_prob": 4.356813860795228e-06}, {"id": 737, "seek": 375052, "start": 3752.92, "end": 3755.4, "text": " But it's worth knowing it's there and trying it out", "tokens": [583, 309, 311, 3163, 5276, 309, 311, 456, 293, 1382, 309, 484], "temperature": 0.0, "avg_logprob": -0.21239946983956, "compression_ratio": 1.5934065934065933, "no_speech_prob": 4.356813860795228e-06}, {"id": 738, "seek": 375052, "start": 3762.12, "end": 3766.7599999999998, "text": " That's what I'm saying it helps a little bit right it means you can get there with one decision rather than two I", "tokens": [663, 311, 437, 286, 478, 1566, 309, 3665, 257, 707, 857, 558, 309, 1355, 291, 393, 483, 456, 365, 472, 3537, 2831, 813, 732, 286], "temperature": 0.0, "avg_logprob": -0.21239946983956, "compression_ratio": 1.5934065934065933, "no_speech_prob": 4.356813860795228e-06}, {"id": 739, "seek": 375052, "start": 3769.72, "end": 3777.2, "text": " Notice there is a negative one in that list of categories is that like an NA or yeah exactly so for free we get", "tokens": [13428, 456, 307, 257, 3671, 472, 294, 300, 1329, 295, 10479, 307, 300, 411, 364, 16585, 420, 1338, 2293, 370, 337, 1737, 321, 483], "temperature": 0.0, "avg_logprob": -0.21239946983956, "compression_ratio": 1.5934065934065933, "no_speech_prob": 4.356813860795228e-06}, {"id": 740, "seek": 377720, "start": 3777.2, "end": 3783.4399999999996, "text": " A negative one which refers to missing and one of the things we're going to do is we're going to actually add one", "tokens": [316, 3671, 472, 597, 14942, 281, 5361, 293, 472, 295, 264, 721, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 767, 909, 472], "temperature": 0.0, "avg_logprob": -0.15523000604966108, "compression_ratio": 1.7634408602150538, "no_speech_prob": 1.9221875845687464e-05}, {"id": 741, "seek": 377720, "start": 3783.4399999999996, "end": 3787.74, "text": " Can somebody pass it back to Paul is we're going to add one to our codes maybe in two goes", "tokens": [1664, 2618, 1320, 309, 646, 281, 4552, 307, 321, 434, 516, 281, 909, 472, 281, 527, 14211, 1310, 294, 732, 1709], "temperature": 0.0, "avg_logprob": -0.15523000604966108, "compression_ratio": 1.7634408602150538, "no_speech_prob": 1.9221875845687464e-05}, {"id": 742, "seek": 377720, "start": 3789.8399999999997, "end": 3791.8399999999997, "text": " Let people know it's coming", "tokens": [961, 561, 458, 309, 311, 1348], "temperature": 0.0, "avg_logprob": -0.15523000604966108, "compression_ratio": 1.7634408602150538, "no_speech_prob": 1.9221875845687464e-05}, {"id": 743, "seek": 377720, "start": 3792.3999999999996, "end": 3797.7999999999997, "text": " Yeah, so let people so we're going to add one to all of our codes to make missing zero later on", "tokens": [865, 11, 370, 718, 561, 370, 321, 434, 516, 281, 909, 472, 281, 439, 295, 527, 14211, 281, 652, 5361, 4018, 1780, 322], "temperature": 0.0, "avg_logprob": -0.15523000604966108, "compression_ratio": 1.7634408602150538, "no_speech_prob": 1.9221875845687464e-05}, {"id": 744, "seek": 379780, "start": 3797.8, "end": 3799.8, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.45099295888628277, "compression_ratio": 1.4264705882352942, "no_speech_prob": 6.540280082845129e-06}, {"id": 745, "seek": 379780, "start": 3813.28, "end": 3815.9, "text": " Yeah, we're gonna get to that yeah", "tokens": [865, 11, 321, 434, 799, 483, 281, 300, 1338], "temperature": 0.0, "avg_logprob": -0.45099295888628277, "compression_ratio": 1.4264705882352942, "no_speech_prob": 6.540280082845129e-06}, {"id": 746, "seek": 379780, "start": 3816.4, "end": 3819.9, "text": " Yeah, so get dummies which we'll get to in a moment is going to create three separate columns", "tokens": [865, 11, 370, 483, 16784, 38374, 597, 321, 603, 483, 281, 294, 257, 1623, 307, 516, 281, 1884, 1045, 4994, 13766], "temperature": 0.0, "avg_logprob": -0.45099295888628277, "compression_ratio": 1.4264705882352942, "no_speech_prob": 6.540280082845129e-06}, {"id": 747, "seek": 379780, "start": 3820.4, "end": 3823.44, "text": " Ones and zeros for high ones there's a medium one is very slow", "tokens": [1282, 279, 293, 35193, 337, 1090, 2306, 456, 311, 257, 6399, 472, 307, 588, 2964], "temperature": 0.0, "avg_logprob": -0.45099295888628277, "compression_ratio": 1.4264705882352942, "no_speech_prob": 6.540280082845129e-06}, {"id": 748, "seek": 382344, "start": 3823.44, "end": 3827.56, "text": " Where else this one creates a single column with an integer zero one or two?", "tokens": [2305, 1646, 341, 472, 7829, 257, 2167, 7738, 365, 364, 24922, 4018, 472, 420, 732, 30], "temperature": 0.0, "avg_logprob": -0.18260309128534227, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.6687893043563236e-06}, {"id": 749, "seek": 382344, "start": 3830.4, "end": 3834.66, "text": " We're going to get to that one shortly yep, did you have a question to Paul or you're just putting out, okay?", "tokens": [492, 434, 516, 281, 483, 281, 300, 472, 13392, 18633, 11, 630, 291, 362, 257, 1168, 281, 4552, 420, 291, 434, 445, 3372, 484, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.18260309128534227, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.6687893043563236e-06}, {"id": 750, "seek": 382344, "start": 3836.8, "end": 3845.2000000000003, "text": " Okay, so at this point as long as we always make sure we use dot cat dot codes the thing with the numbers in", "tokens": [1033, 11, 370, 412, 341, 935, 382, 938, 382, 321, 1009, 652, 988, 321, 764, 5893, 3857, 5893, 14211, 264, 551, 365, 264, 3547, 294], "temperature": 0.0, "avg_logprob": -0.18260309128534227, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.6687893043563236e-06}, {"id": 751, "seek": 382344, "start": 3846.2400000000002, "end": 3852.7200000000003, "text": " We're basically done all of our strings have been turned into numbers at dates been turned into a bunch of numeric columns and everything else", "tokens": [492, 434, 1936, 1096, 439, 295, 527, 13985, 362, 668, 3574, 666, 3547, 412, 11691, 668, 3574, 666, 257, 3840, 295, 7866, 299, 13766, 293, 1203, 1646], "temperature": 0.0, "avg_logprob": -0.18260309128534227, "compression_ratio": 1.6846153846153846, "no_speech_prob": 3.6687893043563236e-06}, {"id": 752, "seek": 385272, "start": 3852.72, "end": 3854.72, "text": " Is already a number okay?", "tokens": [1119, 1217, 257, 1230, 1392, 30], "temperature": 0.0, "avg_logprob": -0.19957538403962788, "compression_ratio": 1.654708520179372, "no_speech_prob": 4.8603915274725296e-06}, {"id": 753, "seek": 385272, "start": 3855.9199999999996, "end": 3862.16, "text": " The only other main thing we have to do is notice that we have lots of missing values so here is", "tokens": [440, 787, 661, 2135, 551, 321, 362, 281, 360, 307, 3449, 300, 321, 362, 3195, 295, 5361, 4190, 370, 510, 307], "temperature": 0.0, "avg_logprob": -0.19957538403962788, "compression_ratio": 1.654708520179372, "no_speech_prob": 4.8603915274725296e-06}, {"id": 754, "seek": 385272, "start": 3862.7599999999998, "end": 3866.12, "text": " Thea for all dot is null that's going to return true or false", "tokens": [440, 64, 337, 439, 5893, 307, 18184, 300, 311, 516, 281, 2736, 2074, 420, 7908], "temperature": 0.0, "avg_logprob": -0.19957538403962788, "compression_ratio": 1.654708520179372, "no_speech_prob": 4.8603915274725296e-06}, {"id": 755, "seek": 385272, "start": 3866.9599999999996, "end": 3868.9599999999996, "text": " Depending on whether something is empty", "tokens": [22539, 322, 1968, 746, 307, 6707], "temperature": 0.0, "avg_logprob": -0.19957538403962788, "compression_ratio": 1.654708520179372, "no_speech_prob": 4.8603915274725296e-06}, {"id": 756, "seek": 385272, "start": 3870.3999999999996, "end": 3875.7999999999997, "text": " Dot sum is going to add up how many empty for each series", "tokens": [38753, 2408, 307, 516, 281, 909, 493, 577, 867, 6707, 337, 1184, 2638], "temperature": 0.0, "avg_logprob": -0.19957538403962788, "compression_ratio": 1.654708520179372, "no_speech_prob": 4.8603915274725296e-06}, {"id": 757, "seek": 387580, "start": 3875.8, "end": 3885.7200000000003, "text": " And then I'm going to sort them and divide by the size of the data set so here we have some things which have like quite high percentages of", "tokens": [400, 550, 286, 478, 516, 281, 1333, 552, 293, 9845, 538, 264, 2744, 295, 264, 1412, 992, 370, 510, 321, 362, 512, 721, 597, 362, 411, 1596, 1090, 42270, 295], "temperature": 0.0, "avg_logprob": -0.24496238789659866, "compression_ratio": 1.3656716417910448, "no_speech_prob": 2.9479956538125407e-06}, {"id": 758, "seek": 387580, "start": 3887.8, "end": 3891.6400000000003, "text": " Nulls so so missing values we call them in", "tokens": [426, 858, 82, 370, 370, 5361, 4190, 321, 818, 552, 294], "temperature": 0.0, "avg_logprob": -0.24496238789659866, "compression_ratio": 1.3656716417910448, "no_speech_prob": 2.9479956538125407e-06}, {"id": 759, "seek": 389164, "start": 3891.64, "end": 3893.64, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.19948689899747335, "compression_ratio": 1.4, "no_speech_prob": 2.1907103473495226e-06}, {"id": 760, "seek": 389164, "start": 3906.7999999999997, "end": 3907.8399999999997, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.19948689899747335, "compression_ratio": 1.4, "no_speech_prob": 2.1907103473495226e-06}, {"id": 761, "seek": 389164, "start": 3907.8399999999997, "end": 3909.64, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.19948689899747335, "compression_ratio": 1.4, "no_speech_prob": 2.1907103473495226e-06}, {"id": 762, "seek": 389164, "start": 3909.64, "end": 3915.04, "text": " We're going to get to that in a moment, but I will point something out which is reading the CSV took a minute or so", "tokens": [492, 434, 516, 281, 483, 281, 300, 294, 257, 1623, 11, 457, 286, 486, 935, 746, 484, 597, 307, 3760, 264, 48814, 1890, 257, 3456, 420, 370], "temperature": 0.0, "avg_logprob": -0.19948689899747335, "compression_ratio": 1.4, "no_speech_prob": 2.1907103473495226e-06}, {"id": 763, "seek": 389164, "start": 3915.64, "end": 3920.64, "text": " The processing took another 10 seconds or so from time to time when I've done a little bit of work", "tokens": [440, 9007, 1890, 1071, 1266, 3949, 420, 370, 490, 565, 281, 565, 562, 286, 600, 1096, 257, 707, 857, 295, 589], "temperature": 0.0, "avg_logprob": -0.19948689899747335, "compression_ratio": 1.4, "no_speech_prob": 2.1907103473495226e-06}, {"id": 764, "seek": 392064, "start": 3920.64, "end": 3924.16, "text": " I don't want to wait for again. I will tend to save where I'm at so here", "tokens": [286, 500, 380, 528, 281, 1699, 337, 797, 13, 286, 486, 3928, 281, 3155, 689, 286, 478, 412, 370, 510], "temperature": 0.0, "avg_logprob": -0.1235241955273772, "compression_ratio": 1.9169435215946844, "no_speech_prob": 6.962133738852572e-06}, {"id": 765, "seek": 392064, "start": 3924.16, "end": 3927.44, "text": " I'm going to save it and I'm going to save it in a format called feather format", "tokens": [286, 478, 516, 281, 3155, 309, 293, 286, 478, 516, 281, 3155, 309, 294, 257, 7877, 1219, 25852, 7877], "temperature": 0.0, "avg_logprob": -0.1235241955273772, "compression_ratio": 1.9169435215946844, "no_speech_prob": 6.962133738852572e-06}, {"id": 766, "seek": 392064, "start": 3927.44, "end": 3931.7999999999997, "text": " This is very very new right but what this is going to do is it's going to save it to disk in", "tokens": [639, 307, 588, 588, 777, 558, 457, 437, 341, 307, 516, 281, 360, 307, 309, 311, 516, 281, 3155, 309, 281, 12355, 294], "temperature": 0.0, "avg_logprob": -0.1235241955273772, "compression_ratio": 1.9169435215946844, "no_speech_prob": 6.962133738852572e-06}, {"id": 767, "seek": 392064, "start": 3932.2, "end": 3934.8199999999997, "text": " Exactly the same basic format that it's actually in RAM", "tokens": [7587, 264, 912, 3875, 7877, 300, 309, 311, 767, 294, 14561], "temperature": 0.0, "avg_logprob": -0.1235241955273772, "compression_ratio": 1.9169435215946844, "no_speech_prob": 6.962133738852572e-06}, {"id": 768, "seek": 392064, "start": 3935.08, "end": 3941.04, "text": " This is by far the fastest way to save something and the fastest way to read it back right so most of the folks you deal", "tokens": [639, 307, 538, 1400, 264, 14573, 636, 281, 3155, 746, 293, 264, 14573, 636, 281, 1401, 309, 646, 558, 370, 881, 295, 264, 4024, 291, 2028], "temperature": 0.0, "avg_logprob": -0.1235241955273772, "compression_ratio": 1.9169435215946844, "no_speech_prob": 6.962133738852572e-06}, {"id": 769, "seek": 392064, "start": 3941.04, "end": 3946.72, "text": " With unless they're on the cutting edge won't be familiar with this format, so this would be something you can teach them about", "tokens": [2022, 5969, 436, 434, 322, 264, 6492, 4691, 1582, 380, 312, 4963, 365, 341, 7877, 11, 370, 341, 576, 312, 746, 291, 393, 2924, 552, 466], "temperature": 0.0, "avg_logprob": -0.1235241955273772, "compression_ratio": 1.9169435215946844, "no_speech_prob": 6.962133738852572e-06}, {"id": 770, "seek": 392064, "start": 3946.92, "end": 3948.92, "text": " It's becoming the standard", "tokens": [467, 311, 5617, 264, 3832], "temperature": 0.0, "avg_logprob": -0.1235241955273772, "compression_ratio": 1.9169435215946844, "no_speech_prob": 6.962133738852572e-06}, {"id": 771, "seek": 394892, "start": 3948.92, "end": 3954.54, "text": " Right it's actually becoming something that's going to be used not just in pandas, but in Java", "tokens": [1779, 309, 311, 767, 5617, 746, 300, 311, 516, 281, 312, 1143, 406, 445, 294, 4565, 296, 11, 457, 294, 10745], "temperature": 0.0, "avg_logprob": -0.22404993148077101, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.561249402788235e-06}, {"id": 772, "seek": 394892, "start": 3956.08, "end": 3963.0, "text": " In spark in lots of like things for like communicating across computers because it's incredibly fast", "tokens": [682, 9908, 294, 3195, 295, 411, 721, 337, 411, 17559, 2108, 10807, 570, 309, 311, 6252, 2370], "temperature": 0.0, "avg_logprob": -0.22404993148077101, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.561249402788235e-06}, {"id": 773, "seek": 394892, "start": 3963.56, "end": 3967.2400000000002, "text": " And it's actually co-designed by the guy that made panthers by Wes McKinney", "tokens": [400, 309, 311, 767, 598, 12, 14792, 16690, 538, 264, 2146, 300, 1027, 2462, 2273, 538, 23843, 21765, 259, 2397], "temperature": 0.0, "avg_logprob": -0.22404993148077101, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.561249402788235e-06}, {"id": 774, "seek": 394892, "start": 3967.8, "end": 3973.16, "text": " So we can just go dear for all dot to feather and pass in some name", "tokens": [407, 321, 393, 445, 352, 6875, 337, 439, 5893, 281, 25852, 293, 1320, 294, 512, 1315], "temperature": 0.0, "avg_logprob": -0.22404993148077101, "compression_ratio": 1.5767441860465117, "no_speech_prob": 2.561249402788235e-06}, {"id": 775, "seek": 397316, "start": 3973.16, "end": 3979.92, "text": " I tend to have a folder called temp for all of my like as I'm going along stuff", "tokens": [286, 3928, 281, 362, 257, 10820, 1219, 18274, 337, 439, 295, 452, 411, 382, 286, 478, 516, 2051, 1507], "temperature": 0.0, "avg_logprob": -0.23071884863155404, "compression_ratio": 1.574468085106383, "no_speech_prob": 1.520637670182623e-05}, {"id": 776, "seek": 397316, "start": 3981.16, "end": 3985.72, "text": " And so when you go OS dot make dirs you can path in any path path here", "tokens": [400, 370, 562, 291, 352, 12731, 5893, 652, 4746, 82, 291, 393, 3100, 294, 604, 3100, 3100, 510], "temperature": 0.0, "avg_logprob": -0.23071884863155404, "compression_ratio": 1.574468085106383, "no_speech_prob": 1.520637670182623e-05}, {"id": 777, "seek": 397316, "start": 3985.72, "end": 3991.72, "text": " You like it won't complain if it's already there because I've got exists okay equals true if there are some sub directories", "tokens": [509, 411, 309, 1582, 380, 11024, 498, 309, 311, 1217, 456, 570, 286, 600, 658, 8198, 1392, 6915, 2074, 498, 456, 366, 512, 1422, 5391, 530], "temperature": 0.0, "avg_logprob": -0.23071884863155404, "compression_ratio": 1.574468085106383, "no_speech_prob": 1.520637670182623e-05}, {"id": 778, "seek": 397316, "start": 3991.72, "end": 3995.08, "text": " It'll create them for you, so this is a super handy little function", "tokens": [467, 603, 1884, 552, 337, 291, 11, 370, 341, 307, 257, 1687, 13239, 707, 2445], "temperature": 0.0, "avg_logprob": -0.23071884863155404, "compression_ratio": 1.574468085106383, "no_speech_prob": 1.520637670182623e-05}, {"id": 779, "seek": 397316, "start": 3996.96, "end": 3999.7599999999998, "text": " Okay, so it's not installed", "tokens": [1033, 11, 370, 309, 311, 406, 8899], "temperature": 0.0, "avg_logprob": -0.23071884863155404, "compression_ratio": 1.574468085106383, "no_speech_prob": 1.520637670182623e-05}, {"id": 780, "seek": 399976, "start": 3999.76, "end": 4002.44, "text": " So because I'm using", "tokens": [407, 570, 286, 478, 1228], "temperature": 0.0, "avg_logprob": -0.26140085856119794, "compression_ratio": 1.5763888888888888, "no_speech_prob": 1.5206196621875279e-05}, {"id": 781, "seek": 399976, "start": 4003.36, "end": 4008.92, "text": " Cressel for the first time it's complaining about that so if you get a message that something's not installed", "tokens": [383, 735, 338, 337, 264, 700, 565, 309, 311, 20740, 466, 300, 370, 498, 291, 483, 257, 3636, 300, 746, 311, 406, 8899], "temperature": 0.0, "avg_logprob": -0.26140085856119794, "compression_ratio": 1.5763888888888888, "no_speech_prob": 1.5206196621875279e-05}, {"id": 782, "seek": 399976, "start": 4009.5200000000004, "end": 4012.1200000000003, "text": " If you're using anaconda you can conda install", "tokens": [759, 291, 434, 1228, 364, 326, 12233, 291, 393, 2224, 64, 3625], "temperature": 0.0, "avg_logprob": -0.26140085856119794, "compression_ratio": 1.5763888888888888, "no_speech_prob": 1.5206196621875279e-05}, {"id": 783, "seek": 399976, "start": 4013.38, "end": 4016.0800000000004, "text": " Cressel actually doesn't use anaconda it uses pip", "tokens": [383, 735, 338, 767, 1177, 380, 764, 364, 326, 12233, 309, 4960, 8489], "temperature": 0.0, "avg_logprob": -0.26140085856119794, "compression_ratio": 1.5763888888888888, "no_speech_prob": 1.5206196621875279e-05}, {"id": 784, "seek": 401608, "start": 4016.08, "end": 4018.08, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.19198627220956901, "compression_ratio": 1.1616161616161615, "no_speech_prob": 2.123331341863377e-06}, {"id": 785, "seek": 401608, "start": 4028.7999999999997, "end": 4032.56, "text": " So we wait for that to go along okay, and so now if I run it", "tokens": [407, 321, 1699, 337, 300, 281, 352, 2051, 1392, 11, 293, 370, 586, 498, 286, 1190, 309], "temperature": 0.0, "avg_logprob": -0.19198627220956901, "compression_ratio": 1.1616161616161615, "no_speech_prob": 2.123331341863377e-06}, {"id": 786, "seek": 401608, "start": 4035.92, "end": 4037.92, "text": " And so sometimes", "tokens": [400, 370, 2171], "temperature": 0.0, "avg_logprob": -0.19198627220956901, "compression_ratio": 1.1616161616161615, "no_speech_prob": 2.123331341863377e-06}, {"id": 787, "seek": 401608, "start": 4038.84, "end": 4040.84, "text": " You may find you actually have to", "tokens": [509, 815, 915, 291, 767, 362, 281], "temperature": 0.0, "avg_logprob": -0.19198627220956901, "compression_ratio": 1.1616161616161615, "no_speech_prob": 2.123331341863377e-06}, {"id": 788, "seek": 404084, "start": 4040.84, "end": 4045.4, "text": " Restart Jupiter, so I won't do that now because we're nearly out of time", "tokens": [13094, 446, 24567, 11, 370, 286, 1582, 380, 360, 300, 586, 570, 321, 434, 6217, 484, 295, 565], "temperature": 0.0, "avg_logprob": -0.1870665700812089, "compression_ratio": 1.547008547008547, "no_speech_prob": 4.3568234104895964e-06}, {"id": 789, "seek": 404084, "start": 4045.4, "end": 4048.92, "text": " So if you restart Jupiter you'll be able to keep moving along so from now on", "tokens": [407, 498, 291, 21022, 24567, 291, 603, 312, 1075, 281, 1066, 2684, 2051, 370, 490, 586, 322], "temperature": 0.0, "avg_logprob": -0.1870665700812089, "compression_ratio": 1.547008547008547, "no_speech_prob": 4.3568234104895964e-06}, {"id": 790, "seek": 404084, "start": 4049.52, "end": 4056.32, "text": " You don't have to rerun all the stuff above you could just say PD dot read feather, and we've got our data frame back", "tokens": [509, 500, 380, 362, 281, 43819, 409, 439, 264, 1507, 3673, 291, 727, 445, 584, 10464, 5893, 1401, 25852, 11, 293, 321, 600, 658, 527, 1412, 3920, 646], "temperature": 0.0, "avg_logprob": -0.1870665700812089, "compression_ratio": 1.547008547008547, "no_speech_prob": 4.3568234104895964e-06}, {"id": 791, "seek": 404084, "start": 4057.7200000000003, "end": 4061.6000000000004, "text": " So the last step we're going to do is to", "tokens": [407, 264, 1036, 1823, 321, 434, 516, 281, 360, 307, 281], "temperature": 0.0, "avg_logprob": -0.1870665700812089, "compression_ratio": 1.547008547008547, "no_speech_prob": 4.3568234104895964e-06}, {"id": 792, "seek": 404084, "start": 4062.96, "end": 4065.8, "text": " Actually replace the strings with their numeric codes", "tokens": [5135, 7406, 264, 13985, 365, 641, 7866, 299, 14211], "temperature": 0.0, "avg_logprob": -0.1870665700812089, "compression_ratio": 1.547008547008547, "no_speech_prob": 4.3568234104895964e-06}, {"id": 793, "seek": 406580, "start": 4065.8, "end": 4072.8, "text": " And we're going to pull out the dependent variable sale price into a separate variable", "tokens": [400, 321, 434, 516, 281, 2235, 484, 264, 12334, 7006, 8680, 3218, 666, 257, 4994, 7006], "temperature": 0.0, "avg_logprob": -0.17428629738943918, "compression_ratio": 1.5487179487179488, "no_speech_prob": 3.9054275475791655e-06}, {"id": 794, "seek": 406580, "start": 4072.8, "end": 4078.04, "text": " And we're going to also handle missing continuous values, and so how are we going to do that?", "tokens": [400, 321, 434, 516, 281, 611, 4813, 5361, 10957, 4190, 11, 293, 370, 577, 366, 321, 516, 281, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.17428629738943918, "compression_ratio": 1.5487179487179488, "no_speech_prob": 3.9054275475791655e-06}, {"id": 795, "seek": 406580, "start": 4079.44, "end": 4084.1000000000004, "text": " So you'll see here. We've got a function called proc DF", "tokens": [407, 291, 603, 536, 510, 13, 492, 600, 658, 257, 2445, 1219, 9510, 48336], "temperature": 0.0, "avg_logprob": -0.17428629738943918, "compression_ratio": 1.5487179487179488, "no_speech_prob": 3.9054275475791655e-06}, {"id": 796, "seek": 406580, "start": 4085.0, "end": 4087.0, "text": " What is that proc DF?", "tokens": [708, 307, 300, 9510, 48336, 30], "temperature": 0.0, "avg_logprob": -0.17428629738943918, "compression_ratio": 1.5487179487179488, "no_speech_prob": 3.9054275475791655e-06}, {"id": 797, "seek": 408700, "start": 4087.0, "end": 4095.0, "text": " So it's inside fast AI dot structured again and", "tokens": [407, 309, 311, 1854, 2370, 7318, 5893, 18519, 797, 293], "temperature": 0.0, "avg_logprob": -0.1909573481633113, "compression_ratio": 1.547486033519553, "no_speech_prob": 2.994402393596829e-06}, {"id": 798, "seek": 408700, "start": 4100.76, "end": 4102.36, "text": " Here it is", "tokens": [1692, 309, 307], "temperature": 0.0, "avg_logprob": -0.1909573481633113, "compression_ratio": 1.547486033519553, "no_speech_prob": 2.994402393596829e-06}, {"id": 799, "seek": 408700, "start": 4102.36, "end": 4108.04, "text": " So quite a lot of the functions have a few additional parameters that you can provide and we'll talk about them later", "tokens": [407, 1596, 257, 688, 295, 264, 6828, 362, 257, 1326, 4497, 9834, 300, 291, 393, 2893, 293, 321, 603, 751, 466, 552, 1780], "temperature": 0.0, "avg_logprob": -0.1909573481633113, "compression_ratio": 1.547486033519553, "no_speech_prob": 2.994402393596829e-06}, {"id": 800, "seek": 408700, "start": 4108.04, "end": 4113.24, "text": " But basically we're providing the data frame to process and the name of the dependent variable the y", "tokens": [583, 1936, 321, 434, 6530, 264, 1412, 3920, 281, 1399, 293, 264, 1315, 295, 264, 12334, 7006, 264, 288], "temperature": 0.0, "avg_logprob": -0.1909573481633113, "compression_ratio": 1.547486033519553, "no_speech_prob": 2.994402393596829e-06}, {"id": 801, "seek": 411324, "start": 4113.24, "end": 4119.08, "text": " Field name okay, and so all it's going to do is it's going to make a copy of the data frame", "tokens": [17952, 1315, 1392, 11, 293, 370, 439, 309, 311, 516, 281, 360, 307, 309, 311, 516, 281, 652, 257, 5055, 295, 264, 1412, 3920], "temperature": 0.0, "avg_logprob": -0.19103012555911217, "compression_ratio": 1.7261904761904763, "no_speech_prob": 6.438962373067625e-06}, {"id": 802, "seek": 411324, "start": 4120.44, "end": 4128.44, "text": " It's going to grab the y value. It's going to drop the dependent variable from the original and", "tokens": [467, 311, 516, 281, 4444, 264, 288, 2158, 13, 467, 311, 516, 281, 3270, 264, 12334, 7006, 490, 264, 3380, 293], "temperature": 0.0, "avg_logprob": -0.19103012555911217, "compression_ratio": 1.7261904761904763, "no_speech_prob": 6.438962373067625e-06}, {"id": 803, "seek": 411324, "start": 4129.2, "end": 4131.2, "text": " Then it's going to", "tokens": [1396, 309, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.19103012555911217, "compression_ratio": 1.7261904761904763, "no_speech_prob": 6.438962373067625e-06}, {"id": 804, "seek": 411324, "start": 4132.679999999999, "end": 4136.0, "text": " Fix missing so how do we fix missing?", "tokens": [25538, 5361, 370, 577, 360, 321, 3191, 5361, 30], "temperature": 0.0, "avg_logprob": -0.19103012555911217, "compression_ratio": 1.7261904761904763, "no_speech_prob": 6.438962373067625e-06}, {"id": 805, "seek": 411324, "start": 4138.24, "end": 4141.16, "text": " So what we do to fix missing is pretty simple", "tokens": [407, 437, 321, 360, 281, 3191, 5361, 307, 1238, 2199], "temperature": 0.0, "avg_logprob": -0.19103012555911217, "compression_ratio": 1.7261904761904763, "no_speech_prob": 6.438962373067625e-06}, {"id": 806, "seek": 414116, "start": 4141.16, "end": 4143.16, "text": " if it's numeric", "tokens": [498, 309, 311, 7866, 299], "temperature": 0.0, "avg_logprob": -0.22858045633556773, "compression_ratio": 1.6991525423728813, "no_speech_prob": 1.5056906477184384e-06}, {"id": 807, "seek": 414116, "start": 4144.16, "end": 4151.04, "text": " Then we fix it by basically saying let's first of all check that it does have some missing right", "tokens": [1396, 321, 3191, 309, 538, 1936, 1566, 718, 311, 700, 295, 439, 1520, 300, 309, 775, 362, 512, 5361, 558], "temperature": 0.0, "avg_logprob": -0.22858045633556773, "compression_ratio": 1.6991525423728813, "no_speech_prob": 1.5056906477184384e-06}, {"id": 808, "seek": 414116, "start": 4151.04, "end": 4155.44, "text": " So if it does have some missing values, so in other words the is null dot sum is non-zero", "tokens": [407, 498, 309, 775, 362, 512, 5361, 4190, 11, 370, 294, 661, 2283, 264, 307, 18184, 5893, 2408, 307, 2107, 12, 32226], "temperature": 0.0, "avg_logprob": -0.22858045633556773, "compression_ratio": 1.6991525423728813, "no_speech_prob": 1.5056906477184384e-06}, {"id": 809, "seek": 414116, "start": 4156.12, "end": 4161.5199999999995, "text": " Then we're going to create a new column called with the same name as the original plus underscore NA", "tokens": [1396, 321, 434, 516, 281, 1884, 257, 777, 7738, 1219, 365, 264, 912, 1315, 382, 264, 3380, 1804, 37556, 16585], "temperature": 0.0, "avg_logprob": -0.22858045633556773, "compression_ratio": 1.6991525423728813, "no_speech_prob": 1.5056906477184384e-06}, {"id": 810, "seek": 414116, "start": 4162.0, "end": 4168.28, "text": " And it's going to be a Boolean column with a 1 anytime that was missing and a 0 anytime it wasn't", "tokens": [400, 309, 311, 516, 281, 312, 257, 23351, 28499, 7738, 365, 257, 502, 13038, 300, 390, 5361, 293, 257, 1958, 13038, 309, 2067, 380], "temperature": 0.0, "avg_logprob": -0.22858045633556773, "compression_ratio": 1.6991525423728813, "no_speech_prob": 1.5056906477184384e-06}, {"id": 811, "seek": 416828, "start": 4168.28, "end": 4171.88, "text": " We're going to talk about this again next week, but this is you know", "tokens": [492, 434, 516, 281, 751, 466, 341, 797, 958, 1243, 11, 457, 341, 307, 291, 458], "temperature": 0.0, "avg_logprob": -0.19681396818997568, "compression_ratio": 1.75, "no_speech_prob": 1.414467760696425e-06}, {"id": 812, "seek": 416828, "start": 4171.88, "end": 4175.4, "text": " I'll give you the quick version having done that we're then going to replace the", "tokens": [286, 603, 976, 291, 264, 1702, 3037, 1419, 1096, 300, 321, 434, 550, 516, 281, 7406, 264], "temperature": 0.0, "avg_logprob": -0.19681396818997568, "compression_ratio": 1.75, "no_speech_prob": 1.414467760696425e-06}, {"id": 813, "seek": 416828, "start": 4176.0, "end": 4178.42, "text": " Nase the missing with the median", "tokens": [426, 651, 264, 5361, 365, 264, 26779], "temperature": 0.0, "avg_logprob": -0.19681396818997568, "compression_ratio": 1.75, "no_speech_prob": 1.414467760696425e-06}, {"id": 814, "seek": 416828, "start": 4178.8, "end": 4185.759999999999, "text": " Okay, so anywhere that used to be missing will be replaced with the median or add a new column to tell us which ones were missing", "tokens": [1033, 11, 370, 4992, 300, 1143, 281, 312, 5361, 486, 312, 10772, 365, 264, 26779, 420, 909, 257, 777, 7738, 281, 980, 505, 597, 2306, 645, 5361], "temperature": 0.0, "avg_logprob": -0.19681396818997568, "compression_ratio": 1.75, "no_speech_prob": 1.414467760696425e-06}, {"id": 815, "seek": 416828, "start": 4186.12, "end": 4187.5199999999995, "text": " We only do that for numeric", "tokens": [492, 787, 360, 300, 337, 7866, 299], "temperature": 0.0, "avg_logprob": -0.19681396818997568, "compression_ratio": 1.75, "no_speech_prob": 1.414467760696425e-06}, {"id": 816, "seek": 416828, "start": 4187.5199999999995, "end": 4194.0, "text": " We don't need it for categories because pandas had his handles categorical variables automatically by setting them to minus 1", "tokens": [492, 500, 380, 643, 309, 337, 10479, 570, 4565, 296, 632, 702, 18722, 19250, 804, 9102, 6772, 538, 3287, 552, 281, 3175, 502], "temperature": 0.0, "avg_logprob": -0.19681396818997568, "compression_ratio": 1.75, "no_speech_prob": 1.414467760696425e-06}, {"id": 817, "seek": 416828, "start": 4195.44, "end": 4197.44, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.19681396818997568, "compression_ratio": 1.75, "no_speech_prob": 1.414467760696425e-06}, {"id": 818, "seek": 419744, "start": 4197.44, "end": 4199.44, "text": " What we're going to do is", "tokens": [708, 321, 434, 516, 281, 360, 307], "temperature": 0.0, "avg_logprob": -0.18942479292551676, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.4144663964543724e-06}, {"id": 819, "seek": 419744, "start": 4201.28, "end": 4203.28, "text": " If it's not numeric and", "tokens": [759, 309, 311, 406, 7866, 299, 293], "temperature": 0.0, "avg_logprob": -0.18942479292551676, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.4144663964543724e-06}, {"id": 820, "seek": 419744, "start": 4205.0, "end": 4210.4, "text": " It's a categorical type we'll talk about the maximum number of categories later, but let's assume this is always true", "tokens": [467, 311, 257, 19250, 804, 2010, 321, 603, 751, 466, 264, 6674, 1230, 295, 10479, 1780, 11, 457, 718, 311, 6552, 341, 307, 1009, 2074], "temperature": 0.0, "avg_logprob": -0.18942479292551676, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.4144663964543724e-06}, {"id": 821, "seek": 419744, "start": 4210.4, "end": 4217.16, "text": " So if it's not a numeric type we're going to replace the column with its codes the integers okay plus one", "tokens": [407, 498, 309, 311, 406, 257, 7866, 299, 2010, 321, 434, 516, 281, 7406, 264, 7738, 365, 1080, 14211, 264, 41674, 1392, 1804, 472], "temperature": 0.0, "avg_logprob": -0.18942479292551676, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.4144663964543724e-06}, {"id": 822, "seek": 419744, "start": 4217.48, "end": 4219.48, "text": " Right so the by default", "tokens": [1779, 370, 264, 538, 7576], "temperature": 0.0, "avg_logprob": -0.18942479292551676, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.4144663964543724e-06}, {"id": 823, "seek": 419744, "start": 4220.48, "end": 4225.12, "text": " Pandas uses minus one for missing so now zero will be missing and", "tokens": [16995, 296, 4960, 3175, 472, 337, 5361, 370, 586, 4018, 486, 312, 5361, 293], "temperature": 0.0, "avg_logprob": -0.18942479292551676, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.4144663964543724e-06}, {"id": 824, "seek": 422512, "start": 4225.12, "end": 4227.599999999999, "text": " One two three four will be all the other", "tokens": [1485, 732, 1045, 1451, 486, 312, 439, 264, 661], "temperature": 0.0, "avg_logprob": -0.1250300268525059, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.812994353007525e-06}, {"id": 825, "seek": 422512, "start": 4228.36, "end": 4230.36, "text": " categories", "tokens": [10479], "temperature": 0.0, "avg_logprob": -0.1250300268525059, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.812994353007525e-06}, {"id": 826, "seek": 422512, "start": 4232.5199999999995, "end": 4235.5599999999995, "text": " So we're going to talk about dummies later on in the course", "tokens": [407, 321, 434, 516, 281, 751, 466, 16784, 38374, 1780, 322, 294, 264, 1164], "temperature": 0.0, "avg_logprob": -0.1250300268525059, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.812994353007525e-06}, {"id": 827, "seek": 422512, "start": 4235.5599999999995, "end": 4239.92, "text": " But basically optionally you can say that if you already know about dummy values", "tokens": [583, 1936, 3614, 379, 291, 393, 584, 300, 498, 291, 1217, 458, 466, 35064, 4190], "temperature": 0.0, "avg_logprob": -0.1250300268525059, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.812994353007525e-06}, {"id": 828, "seek": 422512, "start": 4239.92, "end": 4245.76, "text": " They're columns with a small number of possible values you can turn into dummies instead of numericalizing them", "tokens": [814, 434, 13766, 365, 257, 1359, 1230, 295, 1944, 4190, 291, 393, 1261, 666, 16784, 38374, 2602, 295, 29054, 3319, 552], "temperature": 0.0, "avg_logprob": -0.1250300268525059, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.812994353007525e-06}, {"id": 829, "seek": 422512, "start": 4245.76, "end": 4251.32, "text": " But we're not going to do that for now okay, so for now all we're doing is we're using the categorical codes plus one", "tokens": [583, 321, 434, 406, 516, 281, 360, 300, 337, 586, 1392, 11, 370, 337, 586, 439, 321, 434, 884, 307, 321, 434, 1228, 264, 19250, 804, 14211, 1804, 472], "temperature": 0.0, "avg_logprob": -0.1250300268525059, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.812994353007525e-06}, {"id": 830, "seek": 425132, "start": 4251.32, "end": 4259.88, "text": " Replacing missing values with the median adding an additional column telling us which ones were replaced and removing the dependent variable", "tokens": [47762, 5615, 5361, 4190, 365, 264, 26779, 5127, 364, 4497, 7738, 3585, 505, 597, 2306, 645, 10772, 293, 12720, 264, 12334, 7006], "temperature": 0.0, "avg_logprob": -0.18860198126898872, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.966968961321982e-06}, {"id": 831, "seek": 425132, "start": 4261.96, "end": 4263.96, "text": " So that's what", "tokens": [407, 300, 311, 437], "temperature": 0.0, "avg_logprob": -0.18860198126898872, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.966968961321982e-06}, {"id": 832, "seek": 425132, "start": 4264.36, "end": 4267.9, "text": " Proc DF does runs very quickly okay, so you'll see now", "tokens": [1705, 66, 48336, 775, 6676, 588, 2661, 1392, 11, 370, 291, 603, 536, 586], "temperature": 0.0, "avg_logprob": -0.18860198126898872, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.966968961321982e-06}, {"id": 833, "seek": 425132, "start": 4268.799999999999, "end": 4275.36, "text": " Sale price is no longer here. Okay. We've now got a whole new color a whole new variable called y that contains sale price", "tokens": [48922, 3218, 307, 572, 2854, 510, 13, 1033, 13, 492, 600, 586, 658, 257, 1379, 777, 2017, 257, 1379, 777, 7006, 1219, 288, 300, 8306, 8680, 3218], "temperature": 0.0, "avg_logprob": -0.18860198126898872, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.966968961321982e-06}, {"id": 834, "seek": 425132, "start": 4276.719999999999, "end": 4278.719999999999, "text": " You'll see we've got a couple of extra blah", "tokens": [509, 603, 536, 321, 600, 658, 257, 1916, 295, 2857, 12288], "temperature": 0.0, "avg_logprob": -0.18860198126898872, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.966968961321982e-06}, {"id": 835, "seek": 427872, "start": 4278.72, "end": 4284.4400000000005, "text": " Underscore N a's at the end okay, and if I look at that", "tokens": [2719, 433, 12352, 426, 257, 311, 412, 264, 917, 1392, 11, 293, 498, 286, 574, 412, 300], "temperature": 0.0, "avg_logprob": -0.22370397476922899, "compression_ratio": 1.711111111111111, "no_speech_prob": 8.31524573641218e-07}, {"id": 836, "seek": 427872, "start": 4289.4400000000005, "end": 4291.4400000000005, "text": " Everything is a number", "tokens": [5471, 307, 257, 1230], "temperature": 0.0, "avg_logprob": -0.22370397476922899, "compression_ratio": 1.711111111111111, "no_speech_prob": 8.31524573641218e-07}, {"id": 837, "seek": 427872, "start": 4292.64, "end": 4294.360000000001, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.22370397476922899, "compression_ratio": 1.711111111111111, "no_speech_prob": 8.31524573641218e-07}, {"id": 838, "seek": 427872, "start": 4294.360000000001, "end": 4301.12, "text": " These Booleans are treated as numbers. They're just considered treated as zero or one. They're just displayed as false and true", "tokens": [1981, 23351, 24008, 366, 8668, 382, 3547, 13, 814, 434, 445, 4888, 8668, 382, 4018, 420, 472, 13, 814, 434, 445, 16372, 382, 7908, 293, 2074], "temperature": 0.0, "avg_logprob": -0.22370397476922899, "compression_ratio": 1.711111111111111, "no_speech_prob": 8.31524573641218e-07}, {"id": 839, "seek": 430112, "start": 4301.12, "end": 4307.4, "text": " They can see here is at the end of a month is at the start of a month is at the end of a quarter it's", "tokens": [814, 393, 536, 510, 307, 412, 264, 917, 295, 257, 1618, 307, 412, 264, 722, 295, 257, 1618, 307, 412, 264, 917, 295, 257, 6555, 309, 311], "temperature": 0.0, "avg_logprob": -0.19042864867619105, "compression_ratio": 1.7642585551330798, "no_speech_prob": 2.813010041791131e-06}, {"id": 840, "seek": 430112, "start": 4309.68, "end": 4315.2, "text": " Kind of funny right because we've got things like a model ID which presumably is something like I don't it could be a serial number", "tokens": [9242, 295, 4074, 558, 570, 321, 600, 658, 721, 411, 257, 2316, 7348, 597, 26742, 307, 746, 411, 286, 500, 380, 309, 727, 312, 257, 17436, 1230], "temperature": 0.0, "avg_logprob": -0.19042864867619105, "compression_ratio": 1.7642585551330798, "no_speech_prob": 2.813010041791131e-06}, {"id": 841, "seek": 430112, "start": 4315.32, "end": 4319.44, "text": " It could be like the model identifier. That's created by the factory or something", "tokens": [467, 727, 312, 411, 264, 2316, 45690, 13, 663, 311, 2942, 538, 264, 9265, 420, 746], "temperature": 0.0, "avg_logprob": -0.19042864867619105, "compression_ratio": 1.7642585551330798, "no_speech_prob": 2.813010041791131e-06}, {"id": 842, "seek": 430112, "start": 4319.44, "end": 4324.04, "text": " We've got like a data source ID like some of these are numbers, but they're not continuous", "tokens": [492, 600, 658, 411, 257, 1412, 4009, 7348, 411, 512, 295, 613, 366, 3547, 11, 457, 436, 434, 406, 10957], "temperature": 0.0, "avg_logprob": -0.19042864867619105, "compression_ratio": 1.7642585551330798, "no_speech_prob": 2.813010041791131e-06}, {"id": 843, "seek": 430112, "start": 4324.5599999999995, "end": 4328.64, "text": " It turns out actually random forests work fine with those", "tokens": [467, 4523, 484, 767, 4974, 21700, 589, 2489, 365, 729], "temperature": 0.0, "avg_logprob": -0.19042864867619105, "compression_ratio": 1.7642585551330798, "no_speech_prob": 2.813010041791131e-06}, {"id": 844, "seek": 432864, "start": 4328.64, "end": 4333.04, "text": " We'll talk about why and how and a lot about that in detail, but for now all you need to know is", "tokens": [492, 603, 751, 466, 983, 293, 577, 293, 257, 688, 466, 300, 294, 2607, 11, 457, 337, 586, 439, 291, 643, 281, 458, 307], "temperature": 0.0, "avg_logprob": -0.18166655760544997, "compression_ratio": 1.6302521008403361, "no_speech_prob": 5.50756976736011e-06}, {"id": 845, "seek": 432864, "start": 4333.4800000000005, "end": 4339.46, "text": " No problem, okay, so as long as this is all numbers which it now is we can now go ahead and create a random forest", "tokens": [883, 1154, 11, 1392, 11, 370, 382, 938, 382, 341, 307, 439, 3547, 597, 309, 586, 307, 321, 393, 586, 352, 2286, 293, 1884, 257, 4974, 6719], "temperature": 0.0, "avg_logprob": -0.18166655760544997, "compression_ratio": 1.6302521008403361, "no_speech_prob": 5.50756976736011e-06}, {"id": 846, "seek": 432864, "start": 4340.64, "end": 4341.88, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.18166655760544997, "compression_ratio": 1.6302521008403361, "no_speech_prob": 5.50756976736011e-06}, {"id": 847, "seek": 432864, "start": 4341.88, "end": 4343.88, "text": " M dot random first regressor", "tokens": [376, 5893, 4974, 700, 1121, 735, 284], "temperature": 0.0, "avg_logprob": -0.18166655760544997, "compression_ratio": 1.6302521008403361, "no_speech_prob": 5.50756976736011e-06}, {"id": 848, "seek": 432864, "start": 4344.4400000000005, "end": 4346.4400000000005, "text": " Random forests are trivially", "tokens": [37603, 21700, 366, 1376, 85, 2270], "temperature": 0.0, "avg_logprob": -0.18166655760544997, "compression_ratio": 1.6302521008403361, "no_speech_prob": 5.50756976736011e-06}, {"id": 849, "seek": 432864, "start": 4346.68, "end": 4353.64, "text": " Paralyzable so what that means is that they if you've got more than one CPU which everybody will basically on their", "tokens": [3457, 5222, 89, 712, 370, 437, 300, 1355, 307, 300, 436, 498, 291, 600, 658, 544, 813, 472, 13199, 597, 2201, 486, 1936, 322, 641], "temperature": 0.0, "avg_logprob": -0.18166655760544997, "compression_ratio": 1.6302521008403361, "no_speech_prob": 5.50756976736011e-06}, {"id": 850, "seek": 435364, "start": 4353.64, "end": 4359.240000000001, "text": " Computers at home, and if you've got a t2 dot medium or bigger at AWS", "tokens": [37804, 433, 412, 1280, 11, 293, 498, 291, 600, 658, 257, 256, 17, 5893, 6399, 420, 3801, 412, 17650], "temperature": 0.0, "avg_logprob": -0.17226363163368374, "compression_ratio": 1.5551330798479088, "no_speech_prob": 3.668840918180649e-06}, {"id": 851, "seek": 435364, "start": 4359.240000000001, "end": 4364.320000000001, "text": " You've got multiple CPUs trivially paralyzable means that it will split up the data", "tokens": [509, 600, 658, 3866, 13199, 82, 1376, 85, 2270, 32645, 89, 712, 1355, 300, 309, 486, 7472, 493, 264, 1412], "temperature": 0.0, "avg_logprob": -0.17226363163368374, "compression_ratio": 1.5551330798479088, "no_speech_prob": 3.668840918180649e-06}, {"id": 852, "seek": 435364, "start": 4364.68, "end": 4369.88, "text": " Across your different CPUs and basically linearly scale right so the more CPUs you have", "tokens": [34527, 428, 819, 13199, 82, 293, 1936, 43586, 4373, 558, 370, 264, 544, 13199, 82, 291, 362], "temperature": 0.0, "avg_logprob": -0.17226363163368374, "compression_ratio": 1.5551330798479088, "no_speech_prob": 3.668840918180649e-06}, {"id": 853, "seek": 435364, "start": 4370.12, "end": 4375.4800000000005, "text": " Pretty much it will divide the time it takes by that number not exactly but roughly", "tokens": [10693, 709, 309, 486, 9845, 264, 565, 309, 2516, 538, 300, 1230, 406, 2293, 457, 9810], "temperature": 0.0, "avg_logprob": -0.17226363163368374, "compression_ratio": 1.5551330798479088, "no_speech_prob": 3.668840918180649e-06}, {"id": 854, "seek": 435364, "start": 4375.76, "end": 4381.160000000001, "text": " So n jobs equals minus 1 tells the random forest regressor to create a separate job", "tokens": [407, 297, 4782, 6915, 3175, 502, 5112, 264, 4974, 6719, 1121, 735, 284, 281, 1884, 257, 4994, 1691], "temperature": 0.0, "avg_logprob": -0.17226363163368374, "compression_ratio": 1.5551330798479088, "no_speech_prob": 3.668840918180649e-06}, {"id": 855, "seek": 438116, "start": 4381.16, "end": 4386.98, "text": " So separate process basically for each CPU you have so that's pretty much what you want all the time", "tokens": [407, 4994, 1399, 1936, 337, 1184, 13199, 291, 362, 370, 300, 311, 1238, 709, 437, 291, 528, 439, 264, 565], "temperature": 0.0, "avg_logprob": -0.17658426176826908, "compression_ratio": 1.6730769230769231, "no_speech_prob": 1.679726210568333e-06}, {"id": 856, "seek": 438116, "start": 4388.599999999999, "end": 4392.76, "text": " Fit the model using this new data frame we created using that y value", "tokens": [29263, 264, 2316, 1228, 341, 777, 1412, 3920, 321, 2942, 1228, 300, 288, 2158], "temperature": 0.0, "avg_logprob": -0.17658426176826908, "compression_ratio": 1.6730769230769231, "no_speech_prob": 1.679726210568333e-06}, {"id": 857, "seek": 438116, "start": 4392.76, "end": 4397.0, "text": " We pulled out and then get the score okay the score is going to be the R squared", "tokens": [492, 7373, 484, 293, 550, 483, 264, 6175, 1392, 264, 6175, 307, 516, 281, 312, 264, 497, 8889], "temperature": 0.0, "avg_logprob": -0.17658426176826908, "compression_ratio": 1.6730769230769231, "no_speech_prob": 1.679726210568333e-06}, {"id": 858, "seek": 438116, "start": 4397.0, "end": 4401.5599999999995, "text": " We'll define that next week hopefully some of you already know about the R squared one is very good", "tokens": [492, 603, 6964, 300, 958, 1243, 4696, 512, 295, 291, 1217, 458, 466, 264, 497, 8889, 472, 307, 588, 665], "temperature": 0.0, "avg_logprob": -0.17658426176826908, "compression_ratio": 1.6730769230769231, "no_speech_prob": 1.679726210568333e-06}, {"id": 859, "seek": 438116, "start": 4402.04, "end": 4406.5199999999995, "text": " Zero is very bad so as you can see we've immediately got a very high score", "tokens": [17182, 307, 588, 1578, 370, 382, 291, 393, 536, 321, 600, 4258, 658, 257, 588, 1090, 6175], "temperature": 0.0, "avg_logprob": -0.17658426176826908, "compression_ratio": 1.6730769230769231, "no_speech_prob": 1.679726210568333e-06}, {"id": 860, "seek": 438116, "start": 4407.2, "end": 4409.2, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.17658426176826908, "compression_ratio": 1.6730769230769231, "no_speech_prob": 1.679726210568333e-06}, {"id": 861, "seek": 440920, "start": 4409.2, "end": 4415.44, "text": " That looks great, but what we'll talk about next week a lot more is that it's not quite great", "tokens": [663, 1542, 869, 11, 457, 437, 321, 603, 751, 466, 958, 1243, 257, 688, 544, 307, 300, 309, 311, 406, 1596, 869], "temperature": 0.0, "avg_logprob": -0.14938637062355323, "compression_ratio": 1.8112449799196788, "no_speech_prob": 2.8572942483151564e-06}, {"id": 862, "seek": 440920, "start": 4415.96, "end": 4422.3, "text": " Because maybe we had data that had points that looked like this and we fitted a line that looks like this", "tokens": [1436, 1310, 321, 632, 1412, 300, 632, 2793, 300, 2956, 411, 341, 293, 321, 26321, 257, 1622, 300, 1542, 411, 341], "temperature": 0.0, "avg_logprob": -0.14938637062355323, "compression_ratio": 1.8112449799196788, "no_speech_prob": 2.8572942483151564e-06}, {"id": 863, "seek": 440920, "start": 4422.92, "end": 4427.099999999999, "text": " When actually we want to want one that looks like that okay the only way to know", "tokens": [1133, 767, 321, 528, 281, 528, 472, 300, 1542, 411, 300, 1392, 264, 787, 636, 281, 458], "temperature": 0.0, "avg_logprob": -0.14938637062355323, "compression_ratio": 1.8112449799196788, "no_speech_prob": 2.8572942483151564e-06}, {"id": 864, "seek": 440920, "start": 4427.76, "end": 4434.4, "text": " Whether we've actually done a good job is by having some other data set that we didn't use to train the model now", "tokens": [8503, 321, 600, 767, 1096, 257, 665, 1691, 307, 538, 1419, 512, 661, 1412, 992, 300, 321, 994, 380, 764, 281, 3847, 264, 2316, 586], "temperature": 0.0, "avg_logprob": -0.14938637062355323, "compression_ratio": 1.8112449799196788, "no_speech_prob": 2.8572942483151564e-06}, {"id": 865, "seek": 440920, "start": 4434.4, "end": 4436.44, "text": " We're going to learn about some ways with random forests", "tokens": [492, 434, 516, 281, 1466, 466, 512, 2098, 365, 4974, 21700], "temperature": 0.0, "avg_logprob": -0.14938637062355323, "compression_ratio": 1.8112449799196788, "no_speech_prob": 2.8572942483151564e-06}, {"id": 866, "seek": 443644, "start": 4436.44, "end": 4440.48, "text": " We can kind of get away without even having that other data set but for now", "tokens": [492, 393, 733, 295, 483, 1314, 1553, 754, 1419, 300, 661, 1412, 992, 457, 337, 586], "temperature": 0.0, "avg_logprob": -0.16045265538351877, "compression_ratio": 1.8391304347826087, "no_speech_prob": 6.240851689653937e-06}, {"id": 867, "seek": 443644, "start": 4440.879999999999, "end": 4443.48, "text": " What we're going to do is we're going to split into", "tokens": [708, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 7472, 666], "temperature": 0.0, "avg_logprob": -0.16045265538351877, "compression_ratio": 1.8391304347826087, "no_speech_prob": 6.240851689653937e-06}, {"id": 868, "seek": 443644, "start": 4444.879999999999, "end": 4445.919999999999, "text": " 12,000", "tokens": [2272, 11, 1360], "temperature": 0.0, "avg_logprob": -0.16045265538351877, "compression_ratio": 1.8391304347826087, "no_speech_prob": 6.240851689653937e-06}, {"id": 869, "seek": 443644, "start": 4445.919999999999, "end": 4449.759999999999, "text": " Rows which we're going to put in a separate data set called the validation set", "tokens": [497, 1509, 597, 321, 434, 516, 281, 829, 294, 257, 4994, 1412, 992, 1219, 264, 24071, 992], "temperature": 0.0, "avg_logprob": -0.16045265538351877, "compression_ratio": 1.8391304347826087, "no_speech_prob": 6.240851689653937e-06}, {"id": 870, "seek": 443644, "start": 4450.44, "end": 4453.08, "text": " Versus the training set is going to contain everything else", "tokens": [12226, 301, 264, 3097, 992, 307, 516, 281, 5304, 1203, 1646], "temperature": 0.0, "avg_logprob": -0.16045265538351877, "compression_ratio": 1.8391304347826087, "no_speech_prob": 6.240851689653937e-06}, {"id": 871, "seek": 443644, "start": 4453.96, "end": 4455.96, "text": " right and our data set is", "tokens": [558, 293, 527, 1412, 992, 307], "temperature": 0.0, "avg_logprob": -0.16045265538351877, "compression_ratio": 1.8391304347826087, "no_speech_prob": 6.240851689653937e-06}, {"id": 872, "seek": 443644, "start": 4456.679999999999, "end": 4458.839999999999, "text": " It's going to be sorted by date", "tokens": [467, 311, 516, 281, 312, 25462, 538, 4002], "temperature": 0.0, "avg_logprob": -0.16045265538351877, "compression_ratio": 1.8391304347826087, "no_speech_prob": 6.240851689653937e-06}, {"id": 873, "seek": 443644, "start": 4458.839999999999, "end": 4464.299999999999, "text": " And so that means that the most recent 12,000 rows are going to be our validation set again", "tokens": [400, 370, 300, 1355, 300, 264, 881, 5162, 2272, 11, 1360, 13241, 366, 516, 281, 312, 527, 24071, 992, 797], "temperature": 0.0, "avg_logprob": -0.16045265538351877, "compression_ratio": 1.8391304347826087, "no_speech_prob": 6.240851689653937e-06}, {"id": 874, "seek": 446430, "start": 4464.3, "end": 4467.54, "text": " We'll talk more about this next week. It's a really important idea, but for now", "tokens": [492, 603, 751, 544, 466, 341, 958, 1243, 13, 467, 311, 257, 534, 1021, 1558, 11, 457, 337, 586], "temperature": 0.0, "avg_logprob": -0.14022658164041085, "compression_ratio": 1.880952380952381, "no_speech_prob": 3.089470737904776e-06}, {"id": 875, "seek": 446430, "start": 4468.24, "end": 4474.92, "text": " We can just recognize that if we do that and run it I've created a little thing called print score, and it's going to", "tokens": [492, 393, 445, 5521, 300, 498, 321, 360, 300, 293, 1190, 309, 286, 600, 2942, 257, 707, 551, 1219, 4482, 6175, 11, 293, 309, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.14022658164041085, "compression_ratio": 1.880952380952381, "no_speech_prob": 3.089470737904776e-06}, {"id": 876, "seek": 446430, "start": 4475.64, "end": 4482.52, "text": " Print out the root mean squared error between the predictions and actuals for the training set for the validation set", "tokens": [34439, 484, 264, 5593, 914, 8889, 6713, 1296, 264, 21264, 293, 3539, 82, 337, 264, 3097, 992, 337, 264, 24071, 992], "temperature": 0.0, "avg_logprob": -0.14022658164041085, "compression_ratio": 1.880952380952381, "no_speech_prob": 3.089470737904776e-06}, {"id": 877, "seek": 446430, "start": 4482.64, "end": 4489.24, "text": " The R squared for the training set and the validation set and you'll see that actually the R squared for the training was 0.98", "tokens": [440, 497, 8889, 337, 264, 3097, 992, 293, 264, 24071, 992, 293, 291, 603, 536, 300, 767, 264, 497, 8889, 337, 264, 3097, 390, 1958, 13, 22516], "temperature": 0.0, "avg_logprob": -0.14022658164041085, "compression_ratio": 1.880952380952381, "no_speech_prob": 3.089470737904776e-06}, {"id": 878, "seek": 446430, "start": 4490.0, "end": 4492.0, "text": " But for the validation was 0.89", "tokens": [583, 337, 264, 24071, 390, 1958, 13, 21115], "temperature": 0.0, "avg_logprob": -0.14022658164041085, "compression_ratio": 1.880952380952381, "no_speech_prob": 3.089470737904776e-06}, {"id": 879, "seek": 449200, "start": 4492.0, "end": 4499.1, "text": " 9 okay, then the RMSE and remember this is on the logs was 0.09 for the training set", "tokens": [1722, 1392, 11, 550, 264, 23790, 5879, 293, 1604, 341, 307, 322, 264, 20820, 390, 1958, 13, 13811, 337, 264, 3097, 992], "temperature": 0.0, "avg_logprob": -0.25599242271261013, "compression_ratio": 1.5299539170506913, "no_speech_prob": 2.090446514557698e-06}, {"id": 880, "seek": 449200, "start": 4500.2, "end": 4505.08, "text": " 0.25 for the validation set now if you actually go to kaggle and go to the leaderboard", "tokens": [1958, 13, 6074, 337, 264, 24071, 992, 586, 498, 291, 767, 352, 281, 350, 559, 22631, 293, 352, 281, 264, 5263, 3787], "temperature": 0.0, "avg_logprob": -0.25599242271261013, "compression_ratio": 1.5299539170506913, "no_speech_prob": 2.090446514557698e-06}, {"id": 881, "seek": 449200, "start": 4505.8, "end": 4507.8, "text": " In fact, let's do it right now", "tokens": [682, 1186, 11, 718, 311, 360, 309, 558, 586], "temperature": 0.0, "avg_logprob": -0.25599242271261013, "compression_ratio": 1.5299539170506913, "no_speech_prob": 2.090446514557698e-06}, {"id": 882, "seek": 449200, "start": 4509.4, "end": 4512.84, "text": " He's got private and public I'll check on public leaderboard and", "tokens": [634, 311, 658, 4551, 293, 1908, 286, 603, 1520, 322, 1908, 5263, 3787, 293], "temperature": 0.0, "avg_logprob": -0.25599242271261013, "compression_ratio": 1.5299539170506913, "no_speech_prob": 2.090446514557698e-06}, {"id": 883, "seek": 449200, "start": 4514.16, "end": 4518.24, "text": " We can go down and find out where is point two five so there are", "tokens": [492, 393, 352, 760, 293, 915, 484, 689, 307, 935, 732, 1732, 370, 456, 366], "temperature": 0.0, "avg_logprob": -0.25599242271261013, "compression_ratio": 1.5299539170506913, "no_speech_prob": 2.090446514557698e-06}, {"id": 884, "seek": 451824, "start": 4518.24, "end": 4520.88, "text": " 475 teams", "tokens": [1017, 11901, 5491], "temperature": 0.0, "avg_logprob": -0.31368799845377604, "compression_ratio": 1.5251396648044693, "no_speech_prob": 4.356802492111456e-06}, {"id": 885, "seek": 451824, "start": 4524.08, "end": 4529.0, "text": " And generally speaking if you're in the top half of a Kaggle competition you're doing pretty well", "tokens": [400, 5101, 4124, 498, 291, 434, 294, 264, 1192, 1922, 295, 257, 48751, 22631, 6211, 291, 434, 884, 1238, 731], "temperature": 0.0, "avg_logprob": -0.31368799845377604, "compression_ratio": 1.5251396648044693, "no_speech_prob": 4.356802492111456e-06}, {"id": 886, "seek": 451824, "start": 4531.4, "end": 4535.8, "text": " So point two five here. We are point two five. What was it exactly point two five?", "tokens": [407, 935, 732, 1732, 510, 13, 492, 366, 935, 732, 1732, 13, 708, 390, 309, 2293, 935, 732, 1732, 30], "temperature": 0.0, "avg_logprob": -0.31368799845377604, "compression_ratio": 1.5251396648044693, "no_speech_prob": 4.356802492111456e-06}, {"id": 887, "seek": 451824, "start": 4537.44, "end": 4539.44, "text": " Went to five oh seven", "tokens": [31809, 281, 1732, 1954, 3407], "temperature": 0.0, "avg_logprob": -0.31368799845377604, "compression_ratio": 1.5251396648044693, "no_speech_prob": 4.356802492111456e-06}, {"id": 888, "seek": 451824, "start": 4541.92, "end": 4545.719999999999, "text": " Yeah about a hundred and tenth so we're about in the top 25%", "tokens": [865, 466, 257, 3262, 293, 27269, 370, 321, 434, 466, 294, 264, 1192, 3552, 4], "temperature": 0.0, "avg_logprob": -0.31368799845377604, "compression_ratio": 1.5251396648044693, "no_speech_prob": 4.356802492111456e-06}, {"id": 889, "seek": 454572, "start": 4545.72, "end": 4552.52, "text": " 25% so so the idea like this is pretty cool right with with like with no thinking at all", "tokens": [3552, 4, 370, 370, 264, 1558, 411, 341, 307, 1238, 1627, 558, 365, 365, 411, 365, 572, 1953, 412, 439], "temperature": 0.0, "avg_logprob": -0.2134236346234332, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.276653721215553e-07}, {"id": 890, "seek": 454572, "start": 4552.76, "end": 4558.740000000001, "text": " Using the defaults of everything we're in the top 25% of a Kaggle competition so like", "tokens": [11142, 264, 7576, 82, 295, 1203, 321, 434, 294, 264, 1192, 3552, 4, 295, 257, 48751, 22631, 6211, 370, 411], "temperature": 0.0, "avg_logprob": -0.2134236346234332, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.276653721215553e-07}, {"id": 891, "seek": 454572, "start": 4559.22, "end": 4561.22, "text": " random forests are insanely", "tokens": [4974, 21700, 366, 40965], "temperature": 0.0, "avg_logprob": -0.2134236346234332, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.276653721215553e-07}, {"id": 892, "seek": 454572, "start": 4561.8, "end": 4565.400000000001, "text": " Powerful and this totally standardized process is", "tokens": [7086, 906, 293, 341, 3879, 31677, 1399, 307], "temperature": 0.0, "avg_logprob": -0.2134236346234332, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.276653721215553e-07}, {"id": 893, "seek": 454572, "start": 4566.04, "end": 4569.400000000001, "text": " insanely good for like any data set so", "tokens": [40965, 665, 337, 411, 604, 1412, 992, 370], "temperature": 0.0, "avg_logprob": -0.2134236346234332, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.276653721215553e-07}, {"id": 894, "seek": 454572, "start": 4570.2, "end": 4573.22, "text": " We're going to wrap up, but what I'm going to ask you to do", "tokens": [492, 434, 516, 281, 7019, 493, 11, 457, 437, 286, 478, 516, 281, 1029, 291, 281, 360], "temperature": 0.0, "avg_logprob": -0.2134236346234332, "compression_ratio": 1.588235294117647, "no_speech_prob": 6.276653721215553e-07}, {"id": 895, "seek": 457322, "start": 4573.22, "end": 4574.740000000001, "text": " for", "tokens": [337], "temperature": 0.0, "avg_logprob": -0.20165805641664278, "compression_ratio": 1.6775510204081632, "no_speech_prob": 2.123351805494167e-06}, {"id": 896, "seek": 457322, "start": 4574.740000000001, "end": 4577.22, "text": " Tuesday it's like take as many", "tokens": [10017, 309, 311, 411, 747, 382, 867], "temperature": 0.0, "avg_logprob": -0.20165805641664278, "compression_ratio": 1.6775510204081632, "no_speech_prob": 2.123351805494167e-06}, {"id": 897, "seek": 457322, "start": 4577.780000000001, "end": 4585.38, "text": " Kaggle competitions as you can whether they be running now or old ones or data sets that you're interested in for hobbies or work and", "tokens": [48751, 22631, 26185, 382, 291, 393, 1968, 436, 312, 2614, 586, 420, 1331, 2306, 420, 1412, 6352, 300, 291, 434, 3102, 294, 337, 35750, 420, 589, 293], "temperature": 0.0, "avg_logprob": -0.20165805641664278, "compression_ratio": 1.6775510204081632, "no_speech_prob": 2.123351805494167e-06}, {"id": 898, "seek": 457322, "start": 4585.46, "end": 4590.54, "text": " And please try it right try this process and if it doesn't work", "tokens": [400, 1767, 853, 309, 558, 853, 341, 1399, 293, 498, 309, 1177, 380, 589], "temperature": 0.0, "avg_logprob": -0.20165805641664278, "compression_ratio": 1.6775510204081632, "no_speech_prob": 2.123351805494167e-06}, {"id": 899, "seek": 457322, "start": 4590.740000000001, "end": 4594.6, "text": " You know tell us on the forum. Here's the data set. I'm using here's where I got it from", "tokens": [509, 458, 980, 505, 322, 264, 17542, 13, 1692, 311, 264, 1412, 992, 13, 286, 478, 1228, 510, 311, 689, 286, 658, 309, 490], "temperature": 0.0, "avg_logprob": -0.20165805641664278, "compression_ratio": 1.6775510204081632, "no_speech_prob": 2.123351805494167e-06}, {"id": 900, "seek": 457322, "start": 4594.9400000000005, "end": 4600.22, "text": " Here's like the stack trace of where I got an error or here's like you know if you use my", "tokens": [1692, 311, 411, 264, 8630, 13508, 295, 689, 286, 658, 364, 6713, 420, 510, 311, 411, 291, 458, 498, 291, 764, 452], "temperature": 0.0, "avg_logprob": -0.20165805641664278, "compression_ratio": 1.6775510204081632, "no_speech_prob": 2.123351805494167e-06}, {"id": 901, "seek": 460022, "start": 4600.22, "end": 4607.3, "text": " my print score function or something like it like you know show us what the training versus test set looks like", "tokens": [452, 4482, 6175, 2445, 420, 746, 411, 309, 411, 291, 458, 855, 505, 437, 264, 3097, 5717, 1500, 992, 1542, 411], "temperature": 0.0, "avg_logprob": -0.19310888993112665, "compression_ratio": 1.6484375, "no_speech_prob": 3.1380761811306e-06}, {"id": 902, "seek": 460022, "start": 4607.54, "end": 4614.08, "text": " We'll try and figure it out right, but what I'm hoping we'll find is that all of you will be pleasantly surprised that with", "tokens": [492, 603, 853, 293, 2573, 309, 484, 558, 11, 457, 437, 286, 478, 7159, 321, 603, 915, 307, 300, 439, 295, 291, 486, 312, 35122, 3627, 6100, 300, 365], "temperature": 0.0, "avg_logprob": -0.19310888993112665, "compression_ratio": 1.6484375, "no_speech_prob": 3.1380761811306e-06}, {"id": 903, "seek": 460022, "start": 4614.5, "end": 4616.5, "text": " with the you know", "tokens": [365, 264, 291, 458], "temperature": 0.0, "avg_logprob": -0.19310888993112665, "compression_ratio": 1.6484375, "no_speech_prob": 3.1380761811306e-06}, {"id": 904, "seek": 460022, "start": 4616.5, "end": 4618.900000000001, "text": " Our or two with information you got today", "tokens": [2621, 420, 732, 365, 1589, 291, 658, 965], "temperature": 0.0, "avg_logprob": -0.19310888993112665, "compression_ratio": 1.6484375, "no_speech_prob": 3.1380761811306e-06}, {"id": 905, "seek": 460022, "start": 4618.900000000001, "end": 4627.280000000001, "text": " You can already get better models than most of the very serious practicing data scientists that compete in Kaggle competitions", "tokens": [509, 393, 1217, 483, 1101, 5245, 813, 881, 295, 264, 588, 3156, 11350, 1412, 7708, 300, 11831, 294, 48751, 22631, 26185], "temperature": 0.0, "avg_logprob": -0.19310888993112665, "compression_ratio": 1.6484375, "no_speech_prob": 3.1380761811306e-06}, {"id": 906, "seek": 462728, "start": 4627.28, "end": 4631.4, "text": " Okay, great. Good luck, and I'll see you on the forums. Oh", "tokens": [1033, 11, 869, 13, 2205, 3668, 11, 293, 286, 603, 536, 291, 322, 264, 26998, 13, 876], "temperature": 0.0, "avg_logprob": -0.1794744753370098, "compression_ratio": 1.6065573770491803, "no_speech_prob": 6.0486413531180006e-06}, {"id": 907, "seek": 462728, "start": 4632.42, "end": 4634.42, "text": " One more thing Friday", "tokens": [1485, 544, 551, 6984], "temperature": 0.0, "avg_logprob": -0.1794744753370098, "compression_ratio": 1.6065573770491803, "no_speech_prob": 6.0486413531180006e-06}, {"id": 908, "seek": 462728, "start": 4635.98, "end": 4639.3, "text": " The other class said a lot of them had class during my office hours", "tokens": [440, 661, 1508, 848, 257, 688, 295, 552, 632, 1508, 1830, 452, 3398, 2496], "temperature": 0.0, "avg_logprob": -0.1794744753370098, "compression_ratio": 1.6065573770491803, "no_speech_prob": 6.0486413531180006e-06}, {"id": 909, "seek": 462728, "start": 4639.3, "end": 4644.5, "text": " So if I made them one till three instead of two till four on Fridays is that okay?", "tokens": [407, 498, 286, 1027, 552, 472, 4288, 1045, 2602, 295, 732, 4288, 1451, 322, 46306, 307, 300, 1392, 30], "temperature": 0.0, "avg_logprob": -0.1794744753370098, "compression_ratio": 1.6065573770491803, "no_speech_prob": 6.0486413531180006e-06}, {"id": 910, "seek": 462728, "start": 4645.98, "end": 4647.98, "text": " seminar oh", "tokens": [29235, 1954], "temperature": 0.0, "avg_logprob": -0.1794744753370098, "compression_ratio": 1.6065573770491803, "no_speech_prob": 6.0486413531180006e-06}, {"id": 911, "seek": 462728, "start": 4648.46, "end": 4650.96, "text": " Okay, I have to find a whole nother time all right", "tokens": [1033, 11, 286, 362, 281, 915, 257, 1379, 406, 511, 565, 439, 558], "temperature": 0.0, "avg_logprob": -0.1794744753370098, "compression_ratio": 1.6065573770491803, "no_speech_prob": 6.0486413531180006e-06}, {"id": 912, "seek": 465096, "start": 4650.96, "end": 4657.08, "text": " I will talk to somebody who actually knows what they're doing unlike me about finding office hours. Thank you", "tokens": [286, 486, 751, 281, 2618, 567, 767, 3255, 437, 436, 434, 884, 8343, 385, 466, 5006, 3398, 2496, 13, 1044, 291], "temperature": 0.0, "avg_logprob": -0.18217083259865088, "compression_ratio": 1.1650485436893203, "no_speech_prob": 3.761830157600343e-05}, {"id": 913, "seek": 465708, "start": 4657.08, "end": 4680.78, "text": " absolutely", "tokens": [50364, 3122, 51549], "temperature": 1.0, "avg_logprob": -1.9718694686889648, "compression_ratio": 0.5555555555555556, "no_speech_prob": 8.473911293549463e-05}], "language": "en"}