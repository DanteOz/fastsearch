{"text": " Okay So Welcome Practical deep learning for coders less than one it's kind of lesson two because There's a lesson zero and lesson zero is is why do you need a GPU and how do you get it set up? So if you haven't got a GPU running yet then go back and do that make sure that you can access a Jupiter notebook and And then you're ready to start the real lesson one. So if you're ready You will be able to see something like this and In particular, hopefully you have gone to notebook tutorial. It's at the top That's why we're zero zero here as this grows. You'll see more and more files, but we'll keep notebook tutorial at the top and You will have used your Jupiter notebook to add one and one together get in the expected result Let's make that a bit bigger And hopefully you've learned these four keyboard shortcuts so The basic idea is that your Jupiter notebook has pros in it it can have pictures in it it can have Charts in it And most importantly it can have code in it So the code is in Python How many people have used Python before so nearly all of you that's great If you haven't used Python, that's totally okay. All right It's a pretty easy language to pick up but if you haven't used Python This will feel a little bit more intimidating because the code that you're seeing will be unfamiliar to you. Yes, Rachel No, cuz I Yeah, okay. Well now that we're here I'll edit this bit out. So as I say there are things like this where People in the room in person. This is one of those bits. It's like this is really for the MOOC audience Not for you. That's I think this will be the only time like this in the in the lesson where we've assumed You've got this set up Thanks, okay All right, so yeah for those of you in the room or on for on fast AI live You can go back after this and make sure that you can get this running using the information in course v3.fast.ai Okay, okay Okay, so a Jupiter notebook is a really interesting device for a data scientist because it kind of lets you run interactive experiments and it lets us give you not just a Static piece of information, but it let us let's ask if you something that you can actually interactively experiment with so Let me explain how we Think works well to use these notebooks and to use this material and this is based on the kind of last three years of experience We've had with the students who have gone through this course First of all, it works pretty well just to watch a lesson end to end Don't try and follow along because it's not really designed to go at a speed where you can follow along It's designed to be something where you just take in the information You get a general sense of all of the pieces how it all fits together right and Then you can go back and go through it more slowly pausing on in the video And trying things out making sure that you can do the things that I'm doing And that you can try and extend them to do it things in your own way. Okay, so don't worry if Things are zipping along Faster than you can do them. That's normal Also, don't try and stop and understand everything the first time if you do understand everything the first time good for you But most people don't particularly as the lessons go on they get faster and they get more difficult. Okay So at this point we've got our notebooks going we're ready to start doing deep learning and so the main thing that hopefully you're Going to agree at the end of this is that you can do deep learning regardless of who you are And we don't just mean do we mean do at a very high level. I mean world-class practitioner level deep learning So Your main place to be looking for things is course v3.fast.ai Where you can find out how to get a GPU? other information and You can also access our forums You can also access our forums and on our forums you'll find things like how do you build a Deep learning box yourself and that's something that you can do after you know later on once you've kind of got going Who am I? So why should you listen to me? Well, maybe you shouldn't but I'll try and justify why you should listen to me I've been doing stuff with machine learning for over 25 years I started out in management consulting where actually initially I was I think McKinsey and companies first analytical Specialist and went into general consulting ran a number of startups for a long time eventually became The president of Kaggle But actually the thing I'm probably most proud of in my life is that I got to be the number one ranked contestant in Kaggle competitions globally. So I think that's a good Practical like can you actually train a predictive model that predicts things pretty important aspect of data science I then founded a company called in litic, which was the first kind of medical deep learning company Nowadays I'm on the faculty at University of San Francisco and also co-founder with Rachel of fast AI So I've used Machine learning throughout that time and I guess I'm not really although I am at USS at a university I'm not really an academic type. I'm much more interested in in using this tool to do useful things Specifically through fast AI we are trying to help people use deep learning to do useful things through I'm creating software to make deep learning easier to use at a very high level Through education such as the thing you're watching now Through research which is where we spend a very large amount of our time which is researching to figure out How can you make deep learning easier to use at a very high level? Which ends up in as you'll see in the software and the education and by helping to build a community Which is mainly through the forums so that practitioners can find each other and work together So that's what we're doing So this lesson practical deep learning for coders is kind of the starting point in this journey It contains seven lessons each one's about two hours long We're then expecting you to do about eight to ten hours of homework during the week So it'll end up being something around 70 or 80 hours of work I will say it varies a lot as to how much people put into this I know a lot of people who work full-time on fast AI I Some folks who's do the two parts can spend a whole year doing it really intensively I know some folks watch the videos on double speed and never do any homework and come at the end of it with you know A general sense of what's going on. So there's lots of different ways you can do this but if you follow along with this kind of Ten hours a week or so approach for the seven weeks by the end you will be able to build an image classification Model on pictures that you choose that will work at a world-class level You'll be able to classify text again using whatever data sets you're interested in You'll be able to make predictions of kind of commercial applications like sales You'll be able to build recommendation systems. That's just the one used by Netflix Not toy examples of any of these but actually things that can Come top 10 and Kaggle competitions that come beat everything that's in the academic community Very very high-level versions of these things. So that might surprise you that's not you know, the prerequisite here is Literally one year of coding and high school math, but we have thousands of students now who have done this and shown it to be true You will probably hear a lot of naysayers Less now than a couple of years ago than we started but a lot of naysayers telling you that you can't do it Or that you shouldn't be doing it or the deep learnings got all these problems It's not perfect. But these are all things that people claim about deep learning which are either pointless or untrue It's not a black box as you'll see it's really great for interpret interpreting what's going on It does not need much data for most practical applications. You certainly don't need a PhD Rachel has one so it doesn't actually stop you from doing deep learning if you have a PhD I certainly don't I have a philosophy degree and nothing else It can be used very widely for lots of different applications not just for vision, which is where it's most well known You don't need lots of hardware You know that 36 cent an hour server is more than enough to get world-class results for most problems It's true that maybe this is not going to help you to build a sentient brain, but that's not our focus. Okay, so For all the people who say deep learning is not interesting because it's not really AI Not really a conversation that I'm interested in we're focused on solving interesting real-world problems What are you going to be able to do by the end of lesson one? Well, this was an example from Nick you're who's actually in the audience now because he was in last year's course as well This is an example of something he did which is he downloaded 30 images of people playing cricket and people playing baseball and ran the code you'll see today and built a nearly perfect classifier of Which is which? So this kind of it's kind of stuff that you can build with some fun hobby examples like this Or you can try stuff as we'll see in the workplace that could be of direct commercial value So this is the idea of where we're going to get to by the end of lesson one We're going to start by looking at code which is very different to Many of the academic courses so for those of you who have a kind of an engineering or math or computer science background This is very different to the approach where you start with lots and lots of theory And then eventually you get to a postgraduate degree and you finally are at the point where you can build something useful We're going to learn to build the useful thing today Now that means that at the end of today You won't know all the theory Okay, there will be lots of aspects of what we do that you don't know why or how it works. That's okay You will learn why and how it works over the next seven weeks But for now we found that what works really well is to actually get your hands dirty coding not focusing on theory because There's still a lot of Artisanship in deep learning. Unfortunately, it's still a situation where people who are good practitioners Have a really good feel for how to work with the code and how to work with the data and you can only get that through experience and So the best way to get that that that feel of how to get good models is to create lots of models through lots of coding and Study them carefully and it's a jupyter notebook provides a really great way to study them. So Let's try that. Let's try getting started. So to get started you will open your jupyter notebook and You'll click on lesson one lesson one pets and it will pop open looking something like this And so here it is. So you can run a cell in a jupyter notebook by clicking on it and pressing run But if you do so everybody will know that you're not a real deep learning practitioner because real deep learning practitioners know the keyboard shortcuts And the keyboard shortcut is shift enter given how often you have to run a cell Don't be Going all the way up here finding it clicking it just shift enter. Okay, so type type type shift enter type type shift enter Up and down to move around to pick something to run shift enter to run it So we're going to go through this quickly and then later on we're going to go back over it more carefully So here's the quick version to get a sense of what's going on So here we are in lesson one and these three lines is what we start every notebook with These things starting with percent are special directives to jupyter notebook itself. They're not Python code They're called magic's Which is kind of a cool name and these three directives the details aren't very important But basically it says hey if somebody changes the underlying library code while I'm running this, please reload it automatically If somebody asks to plot something then please plot it here in this jupyter notebook So just put those three lines at the top of everything The next two lines load up the fast AI library What is the fast AI library? So it's a little bit confusing fast AI with no dot It's the name of our software and then fast dot AI with the dot is the name of our organization So if you go to docs dot fast dot AI This is the fast AI library Okay, we'll learn more about it in a moment But for now just realize everything we are going to do is going to be using basically either fast AI or the thing that fast AI sits on top of which is pi torch Pi torch is one of the most popular Libraries for deep learning in the world It's a bit newer than tensorflow. So in a lot of ways, it's more modern than tensorflow It's extremely fast growing extremely popular and we use it because Well, we used to use tensorflow a couple of years ago and we found we can just do a lot more a lot more quickly with pi torch And then we have this software that sits on top of pi torch unless you do Far far far more things far far far more easily than you can with pi torch alone So it's a good combination. We'll be talking a lot about it. But for now just know that you can use fast AI by doing two things importing star from fast AI and then importing star from fast AI dot Something where something is the application you want and currently fast AI supports four applications computer vision natural language text tabular data and Collaborative filtering and we're going to see lots of examples of all of those during the seven weeks So we're going to be doing some computer vision At this point if you are a Python software engineer, you are probably Feeling sick because you've seen me go import star which is something that you've all been told to never ever do Okay, and there's very good reasons to not use import star in standard production code with most libraries But you might have also seen for those of you that have used something like matlab It's kind of the opposite everything's there for you all the time. You don't even have to import things a lot of the time It's kind of funny. We've got these two extremes of like how do I code? You've got a scientific programming community that has one way and then you've got the software engineering community that has the other Both have really good reasons for doing things and with the fast AI library. We actually support both approaches Any Jupiter notebook where you want to be able to quickly interactively try stuff out? You don't want to be constantly going back up to the top and importing more stuff and trying to figure out where things are You want to be able to use lots of tab complete be you know, very experimental. So import star is great Then when you're building stuff in production you can do the normal pep 8 style, you know proper software engineering practices so So don't worry When you see me doing stuff which at your workplace is found upon. Okay, it's it's this is a different style of coding It's not that There are no rules in data science programming is that the rules are different right when you're training models The most important thing is to be able to interactively experiment quickly. Okay, so you'll see we use a lot of very different Processes styles and stuff to what you're used to but they're there for a reason And you'll learn about them over time You can choose to use a similar approach or not. It's entirely up to you The other thing to mention is that the faster AI libraries? in a real designed in a very interesting modular way and you'll find over time that when you do use import star there's Far less plobbering of things than you might expect It's all explicitly designed to allow you to pull in things and use them quickly without having problems Okay so we're going to look at some data and There's two main places that we'll be tending to get data from for the course one is from academic data sets Academic data sets are really important. They're really interesting There are things where academics spend a lot of time Curating and gathering a data set so that they can show how well different kinds of approaches work with that data And the idea is they try to design data sets that are Challenging in some way and require some kind of breakthrough to do them. Well So we're going to be starting with an academic data set called the pet data set The other kind of data set will be using during the course is data sets from the Kaggle competitions platform Both academic data sets and Kaggle data sets are interesting for us Particularly because they provide strong baselines that is to say you want to know if you're doing a good job So with kakal data sets that have come from a competition You can actually submit your results to Kaggle and see how well would you have gone in that competition? And if you can get in about the top 10% that I'd say you're doing pretty well for academic data sets Academics write down in papers what the state of the art is so how well did they go with using models on that data set? Okay, so this is this is what we're going to do. We're going to try and create Models that get right up towards the top of Kaggle competitions preferably actually in the top 10 not just the top 10% Or that meet or exceed academic state-of-the-art published results so the When you use an academic data set it's important to cite it So you'll see here there's a link to the paper that it's from you definitely don't need to read that paper right now But if you're interested in learning more about it, and why it was created and how it was created all the details there So in this case, this is a pretty difficult challenge The pet data sets going to ask us to distinguish between 37 different categories of dog breed and cat breed So that's really hard in fact The every course until this one we've used a different data set Which is one where you just have to decide is something a dog or is it a cat? So you've got a 50-50 chance right away right and dogs and cats look really different There are lots of dog breeds and cat breeds look pretty much the same so why if we change that data set We've got to the point now where deep learning is so fast and so easy that the dog's versus cat's problem Which a few years ago was considered extremely difficult Or 80% accuracy was a state-of-the-art. It's now too easy Our models were basically getting everything right all the time without any tuning and so they want you know really a lot of Opportunities for me to show you how to do more sophisticated stuff, so we've picked a harder problem this year So this is the first class where we're going to be learning how to do this difficult problem and this kind of thing where you Have to distinguish between similar categories is caught in the academic context It's called fine-grained classification. So we're going to do the fine-grained classification task of figuring out a particular kind of pet So the first thing we have to do is download and extract the data that we want We're going to be using this function called and tar data Which will download it automatically and will untie it automatically AWS has been kind enough to give us lots of space and bandwidth for these data sets So they'll download super quickly for you And so the first question then would be how do I know what untie data? does So you can just type help and you will find out What module did it come from because since we imported star we don't necessarily know that What does it do and something you might not have seen before even if you're an experienced programmer is What exactly do you pass to it? You're probably used to seeing the names URL file name Destination that you might not be used to seeing These bits these bits of types can if you've used a type programming language, you'll be used to seeing them But Python programmers are less used to it But if you think about it You don't actually know how to use a function unless you know what type each thing is that you're providing it So we make sure that we give you that type information Directly here in the help. So in this case, the URL is a string and the file name is either Union means either either a path or a string and it defaults to nothing and the Destination is either a path or a string that defaults to nothing So we'll learn more shortly about how to get more documentation about the details of this But for now we can see we don't have to pass in a file name or a destination It'll figure them out for us from the URL so and for all the data sets will be using in the course We already have constants to find For all of them, right so in this URLs module class actually You can see That's where it's going to grab it from. Okay, so it's going to download that to some Convenient path and untie it for us and will then return the value of path Okay, and then in Jupyter notebook, it's kind of handy You can just write a variable on its own and semicolon is just a end of statement marker in Python So it's the same as doing this you can write it on phone and it fits it You can also say print right? But again, we're trying to do everything fast and interactively just write it and here is the path Where it's given us our data? Next time you run this since you've already downloaded it It won't download it again since you've already untied it it won't untie it again So everything is kind of designed to be pretty automatic pretty easy There are some things in Python that are less convenient for interactive use than they should be for example when you do have a path object Seeing what's in it actually is takes a lot more typing than I would like. So sometimes we add Functionality into existing Python stuff. One of the things we do is we add an LS method to paths. So if you go path.ls Here is what's inside This path so that's what we just downloaded. So when you try this yourself You wait a couple minutes for it to download Unzip and then you can see what's in there If you're an experienced Python programmer you may not be familiar with this approach of using a slash like this Now this is a really convenient function that's part of Python 3 its functionality from something called pathlib These are path objects path objects are much better to use than strings that lets you basically create Subpaths like this doesn't matter if you're on Windows Linux Mac. It's always going to work exactly the same way So here's a path to the images in that data set All right, so if you're starting with a brand new data set trying to do some deep learning on it What do you do? Well, the first thing you would want to do is probably see what's in there. So we found that these are the Directories that are in there. So what's in this images? There's a lot of functions in fast AI for you there's one called get image files that will just grab a Array of all of the image files based on extension in a path And so here you can see We've got lots of different files. Okay, so this is a pretty Common way to for image computer vision data sets to get passed around is that there's just one folder with a whole bunch of files in so the interesting bit then is How do we get the labels? So in machine learning the labels refer to the thing we're trying to predict and if we just eyeball this We could immediately see that the labels Actually part of the file name you see that right? It's kind of like path slash label underscore number extension so we need to somehow get a list of These bits of each file name and that will give us our labels Because that's all you need to build a deep learning model in its in pictures. So files containing the images and you need some labels so in fast AI This is made really easy. There's a Object called image data bunch and an image data bunch represents all of the data you need to build a model And there's basically some factory methods which try to make it really easy for you to create that data bunch Try we'll talk more about this shortly but a training set and a validation set with images and labels for you Now in this case we can see we need to extract the labels from the names Okay, so we're going to use from name RE So for those of you that use Python your know RE is the module in Python that does regular expressions things That's really useful for extracting Text I just went ahead and created the regular expression that would extract the label from this text so those of you who Not familiar with regular expressions super useful tool It'd be very useful to spend some time figuring out how and why that particular regular expression is going to extract the label From this text. Okay, so with this factory method we can basically say okay. I've got this path containing images This is a list of file names. Remember I got them back here This is the regular expression pattern that is going to be used to extract the label from the file name We'll talk about transforms later And then you also need to say what size images do you want to work with? So that might seem weird Why do I need to say what size images I want to work with? Because the images have a size we can see what size the images are and I guess honestly This is a shortcoming of current deep learning technology, which is that a GPU? Has to apply the exact same instruction to a whole bunch of things at the same time in order to be fast and So if the images are different shapes and sizes, they can't do that Okay, so we actually have to make all of the images the same shape and size In part one of the course, we're always going to be making images Square shapes in part two will learn how to use rectangles as well. It turns out to be surprisingly nuanced That pretty much everybody in pretty much all computer vision modeling nearly all of it uses this approach of square And 224 by 224 for reasons we'll learn about is an extremely common size that most models tend to use So if you just use size equals 224 You're probably going to get pretty good results most of the time and this is kind of The little bits of artisan ship that I want to teach you folks, which is like what generally just works Okay, so if you just use size equals 224 that'll generally just work for most things most of the time So this is going to return a Data bunch object and in fast AI everything you model with is going to be a data bunch object We're going to learn all about them and what's in them and how do we look at them and so forth? But basically a data bunch object contains two or three Datasets it contains your training data We'll learn about this shortly. It'll contain your validation data and optionally it contains your test data and for each of those it contains your Your images and your labels or your texts and your labels or your tabular data and your labels or so forth And that all sits there in this one place Something we'll learn more about a little bit is Normalization but generally in all nearly all machine learning tasks you have to make all of your data About the same size specifically about the same mean and about the same standard deviation So there's a normalize function that we can use to normalize our data bunch in that way Okay Okay, Rachel come and ask the question What is the function do if the image size is not 224 Great so This is what we're going to learn about shortly Basically this thing called transforms is is used to do a number of things and one of the things it does is to make something size 224 Let's take a look at a few pictures. Here are a few pictures of things from my data from my data bunch So you can see data dot show batch Can be used to show me the contents of some of the contents of my data bunch So this is going to be three by three And you can see roughly what's happened is that they all seem to have been kind of zoomed and cropped in a reasonably nice way So basically what it'll do is something called by default center cropping Which means it'll kind of grab the middle bit and it will also resize it So we'll talk more about the detail of this because it turns out to actually be quite important But basically a combination of cropping and resizing is used Something else we'll learn about is we also use this to do something called data augmentation So there's actually some randomization in how much and where it crops and stuff like that Okay, but that's the basic idea is some cropping and some resizing often We also also do some some padding so there's all kinds of different ways and it depends on data augmentation Which we're going to learn about shortly And what does it mean to normalize the images So normalizing the images we're going to be learning more about later in the course But in short it means that the the pixel values and we're going to be learning more about pixel values the pixel values start out from more to 255 and some pixel values might tend to be Really I Should say some channels because there's red green and blue so some channels might tend to be Really bright and some might tend to be really not right at all and some might vary a lot and some might not very much At all it really helps train a deep learning model if each one of those red green and blue channels has a mean of zero In a standard deviation of one. Okay, we'll learn more about that if you haven't studied or don't remember means and standard deviations We'll get back to some of that later, but that's the basic idea That's what normalization does if your data and again, we'll learn much more about the details But if your data is not normalized, it can be quite difficult for your model to train Well, so if you do have trouble training a model one thing to check is that you've normalized it as GPU man will be empowered to doesn't size 256 sound more practical considering GPU little utilization So we're going to be getting into that shortly, but the brief answer is that the Models are designed so that the final layer is of size 7 by 7 So we actually want something where if you go 7 times to a bunch of times then you end up with something. It's a good size Yeah, all of these details we are gonna you are going to get to but the key thing is I wanted to get you training A model as quickly as possible But you know, one of the most important things to be a really good practitioner is to be able to look at your data Okay, so it's really important to remember to go data dot show batch and take a look It's surprising how often when you actually look at the data set you've been given that you realize it's got weird black borders on It or some of the things have text covering up some of it or some of its rotated in odd ways So make sure you take a look. Okay And then the other thing we want to look at do is not just look at the pictures But also look at the labels and so all of the possible label names Accord your classes that's where the data bunch you can print out your data dot classes And so here they are That's all of the possible labels that we found by using that regular expression on the file names And we learned earlier on in that prose I wrote at the top that there are 37 Possible categories and so just checking length data classes. It is indeed 37 a Data bunch will always have a property called C And that property called C the technical details will kind of get to later But for now you can kind of think of it as being the number of classes For things like regression problems and multi-label classification and stuff. That's not exactly accurate But it'll do for now It's it's important to know that data dot C Is a really important piece of information that is something like or at least for classification problems It is the number of classes Right believe it or not we're now ready to train a model and So a model is trained in fast AI using something called a learner and Just like a data bunch is a general fast AI concept for your data And from there there are subclasses for particular applications like image data bunch a Learner is a general concept for things that can learn To fit the model and from that there are various subclasses to make things easier and in particular There's one called comms learner, which is something that will create a convolutional neural network for you We'll be learning a lot about that over the next few lessons But for now just know that to create a learner for a convolutional neural network You just have to tell it two things. The first is What's your data and not surprisingly it takes a data bunch and the second thing you need to tell it is What's your model? What's your architecture? So as we'll learn there are lots of different ways of constructing a convolutional neural network But for now the most important thing for you to know is that there's a particular kind of model called a resnet which works extremely well nearly all the time and So for a while at least you really only need to be doing Choosing between two things which is what size resnet do you want? It's just basically how big is it and we'll learn them all about the details of what that means But there's that one quarter resnet 34 and there's one quarter resnet 50 and so when we're getting started with something I'll pick a smaller one because it'll train faster so That's kind of it. That's as much as you need to know to be a pretty good practitioner about architectures for now Which is that there's two architectures or two variants of one architecture that work pretty well Resnet 34 and resnet 50 start with a smaller one and see if it's good enough So that is all the information we need to create a convolutional neural network learner There's one other thing I'm going to give it though, which is a list of metrics Metrics are literally just things that get printed out as it's training So I've saying I would like you to print out the error rate, please Now you can see the first time I ran this on a newly installed box It downloaded something What's it downloading? It's downloading the Resnet 34 pre-trained weights Now what this means is that this particular model has actually already been trained For a particular task and that particular task is that it was trained on looking at about one and a half million Pictures of all kinds of different things a thousand different categories of things using an image a data set called image net and So we can download those pre-trained weights so that we start start with a model that knows nothing about anything But we actually start with a model that knows how to recognize the a thousand categories of things in image net Now I don't think I'm not sure but I don't think all of these 37 categories of pet Were in image net, but there were certainly some kinds of dog. There's certainly some kinds of cat So this pre-trained model already knows quite a little bit about what pets look like And it certainly knows quite a lot about what animals look like and what photos look like so the idea is that we don't start With a model that knows nothing at all But we start by downloading a model that knows Something about recognizing images already So it downloads for us automatically the first time we use it a pre-trained model and then from now on it won't need to download It again, it'll just use the one we've got This is really important. We're learning to learn a lot about this It's kind of the focus of the whole course which is how to do this is called transfer learning How to take a model that already knows how to do something pretty well and make it so that it can do your thing Really? Well, I take a pre-trained model and then we fit it So that instead of predicting the a thousand categories of image net with the image net data It predicts the 37 categories of pets using your pet data And it turns out that by doing this you can train models in 1-100 or less of the time of regular model training with 1-100 or less of the data of regular model training in fact potentially many thousands of times less Remember I showed you the slide of Nichols lesson one project from last year He used 30 images and there's not cricket and baseball images in image net Right, but it just turns out that image nets already so good at recognizing things in the world They're just 30 examples of people playing baseball and cricket was enough to build a nearly perfect classifier Okay now You would naturally be Potentially saying well, wait a minute How do you know that it was going to actually that it can actually recognize pictures of people playing cricket versus baseball In general, maybe it just learned to recognize those 30 Maybe it's just cheating right and that's called overfitting We'll be going talking a lot about that during this course, right? But overfitting is where you don't learn to recognize pictures of say cricket versus baseball But just these particular Cricketers in these particular photos and these particular baseball players and these particular photos we have to make sure that we don't know the theater and so the way we do that is using something called a validation set a Validation set is a set of images that your model does not get to look at and so these metrics Like in this case error rate get printed out automatically using the validation set a set of images that our model never got to see When we created our data bunch it automatically created a validation set for us Okay, and we'll learn lots of ways of creating and using validation sets But because we try to bake in all of the best practices We actually make it nearly impossible for you not to use a validation set because if you're not using a validation set You don't know if you're overfitting. Okay, so we always print out the metrics on a validation set We always hold it out. We always make sure that the model doesn't touch it. That's all done for you Okay, and that's all built into this data bunch object So now that we have a conv learner We can fit it You can just use a method called fit But in practice, you should nearly always use a method called fit one cycle We'll learn more about this during the course, but in short one cycle learning is a paper that was released I'm trying to think few months ago less than a year ago Yeah, so a few months ago And it turned out to be dramatically better both more accurate and faster than any previous approach So again, I don't want to teach you how to do 2017 deep learning right in 2018 the best way to fit models is to use something called one cycle We'll learn all about it But for now just know you should probably type my own dot fit one cycle. Okay If you forget how to type it you can start typing a few letters and hit tab Okay, and you'll get a list of potential options right, and then if you forget what to pass it you can press shift tab and It'll show you exactly what to pass it. So you don't actually have to type help And again, this is kind of nice that we have all the types here because we can see cycle length I will learn more about what that is shortly is an integer and then max learning rate could either be a float or a collection Or whatever and so forth and you can see that momentums will default to this couple Okay, so For now just know that this number four basically decides How many times do we go through the entire data set? How many times do we show the data set to the model so that it can learn from it each time? It sees a picture. It's going to get a little bit better But it's going to take time and It means it could overfit it sees the same picture too many times It'll just learn to recognize that picture not pets in general so we'll learn all about how to tune this number during the next couple of lessons but Starting out with four is a pretty good start just to see how it goes and you can actually see after four epochs or four cycles we've got an error rate of six percent So a natural question is how long did that took that took a minute and 56 seconds Yeah, so we're paying, you know 60 cents an hour We just paid for two minutes of time. I mean we actually pay for the whole time that it's on and running but we use two minutes of compute time and we got an error rate of six percent, so 94 percent of the time we correctly picked the exact right one of Those 94 dog and cat breeds which feels pretty good to me But to get a sense of how good it is. Maybe we should go back and look at the paper Just remember I said the nice thing about using academic papers or capital data sets Is we can compare? our solution to whatever the best people in Kaggle did or whatever the academics did so this particular data set of pet breeds is from 2012 and If I scroll through the paper, you'll generally find in any academic paper There'll be a section called experiments about two-thirds of the way through and if you find the section on experiments Then you can find the section on accuracy and they've got lots of different Models and their models as you'll read about in the paper are extremely kind of pet specific They learn something about how pet heads look and how pet bodies look and pet images in general look they combine them all together And once they use all of this complex code and math they got an accuracy of 59 percent Okay, so in 2012 this highly pet specific Analysis got an accuracy of 59 percent least were the top researchers from Oxford University today in 2018 with Basically if you go back and look at actually how much code we just wrote it's about Three lines of code the other stuff is just printing out things to see what we're doing we got 94 percent so 6 percent error so like that gives you a sense of You know how far we've come with deep learning and particularly with pytorch and fast AI how easy things are Yeah, so Before we take a break. I just want to check to see if we've got any And just remember if you're in the audience and you see a question that you want asked Please click the love heart next to it so that Rachel knows that you want to hear about it Also, if there is something with six likes and Rachel didn't notice it, which is quite possible just just Quote it in a reply and say hey at Rachel. This one's got six likes. Okay, so what we're going to do is we're going to take a Eight-minute break so we'll come back at five past eight So where we got to was we just we just trained a model We don't exactly know what that involved or how it happened But we do know that with three or four lines of code We built something which smashed the accuracy of the state-of-the-art of 2012 six percent error certainly sounds like pretty impressive for something that can recognize different dog breeds and cat breeds But we don't really know why it works that we will that's okay that and In terms of getting the most out of this course We Very very regularly here after the course is finished the same basic feedback Which this is literally copy and pasted for them forum I fell into the habit of watching the lectures too much and googling too much about concepts without running the code Now first I thought I should just read it and then research the theory And we keep hearing people saying my number one regret is I just spent 70 hours doing that And at the very end I started running the code and oh it turned out I learned a lot more So please run the code Really run the code I should have spent the majority of my time on the actual code in the notebooks running it seeing what goes in and Seeing what comes out so your most important skills to practice are learning and we're going to show you how to do this in A lot more detail, but understanding what goes in and what goes out So we've already seen an example of looking at what goes in which is data dot show batch and that's going to show you examples of labels and images and So next we're going to be seeing how to look at what came out That's the most important thing to study as I said The reason we've been able to do this so quickly is heavily because of the fast AI library now fast AI library is pretty new But it's already getting an extraordinary amount of traction as you've seen all of the major cloud providers either support it or about to support it a lot of researchers are starting to use it it's it's Doing making a lot of things a lot easier, but it's also making new things possible and so Really understanding the fast AI software is something which is going to take you a long way and the best way to really understand the faster You're software. Well is by using the fast AI Documentation and we'll be learning more about the fast AI documentation shortly So, how does it compare I mean there's really only one major other piece of software like fast AI That is something that tries to make deep learning easy to use and that's Keras Our Keras is a really terrific piece of software. We actually used it for the previous courses until we switched to fast AI It runs on top of tensorflow It was kind of the gold standard for making deep learning easy to use before but life is much easier with fast AI So if you look for example at the last year's course Exercise which is getting dogs versus cats Fast AI lets you get More much more accurate less than half the error on a validation set, of course training time is less than half the time Lines of code is about a sixth of the lines of code and the lines of code More important than you might realize because those 31 lines of Keras code involve you making a lot of decisions Setting lots of parameters doing lots of configuration So that's all stuff where you have to know how to set those things to get kind of best practice results Where else these five lines of code? Anytime we know what to do for you. We do it for you anytime we can pick a good default we pick it for you Okay, so Hopefully you'll find this a really useful library not just for learning deep learning but for taking it a very long way How far can you take it? Well as you'll see all of the research that we do at fast AI uses the library and An example of the research we did which was recently featured in wired describes a new breakthrough in a natural language processing processing which people are calling the image net moment Which is basically we broke a new state-of-the-art result in text classification Which open AI then built on top of our paper to do with more compute and more data and some different tasks to take it even further I Like this is an example of something that we've done in the last six months in conjunction actually with my colleagues Sebastian Ruda Example of something that's being built in the fast AI library and you're going to learn how to use this brand new model in Three lessons time and you're actually going to get this exact result from this exact paper yourself Another example one of our alums Hamel Hussein Who you'll come across on the forum plenty because he's a great guy very active built a new system for natural language semantic code search You can find it on github Where you can actually type in English sentences and find snippets of code that do the thing you ask for and again That's being built with the fast AI library using the techniques. You'll be learning in the next seven weeks In production in production. Yeah. Well, it's it's I think at this stage. It's a part of their experiments platform So it's kind of pre production I guess and so the best place to Learn about these things and get involved from these things is on the forums Where as well as categories for each part of the course, there's also a general category for deep learning where people talk about research papers applications so on and so forth so Even though today We're kind of going to focus on a small number of lines of code to do a particular thing, which is image classification And we're not learning much math or theory or whatever over these seven weeks and then part two another seven weeks We're going to go deeper and deeper and deeper. And so where can that take you? I want to give you some examples That there is Sarah Hooker. She did our first course a couple of years ago Her background was Economics didn't have a background in coding math computer science. I think she started learning to code two years before she took our course She helped develop something at she started a nonprofit called Delta analytics They helped build this amazing system where they attached old mobile phones to trees in the Kenyan rainforests and Used it to listen for chainsaw noises and then they used deep learning to figure out when there was a chainsaw being used And then they had a system set up to alert ranges to go out and stop a legal deforestation in the rainforests So that was something that she was doing while she was in the course as part of her kind of class projects What's she doing now? She is now a Google brain researcher, which I guess is one of the top if not the top place to do deep learning She's just been publishing some papers Now she is going to Africa to set up Google brains first deep learning AI research center in Africa Now I'll say like she worked her ass off, you know She really really invested in this course not just doing all of the assignments But also going out and reading Ian Goodfellow's book and doing lots of other things, but it really shows Where somebody who has no computer science or math background at all can be now one of the world's top deep-learning researchers and doing very valuable work Another example from our most recent course Christine pain she Is now at open AI AI And you can find her post and actually listen to her music samples of she actually built something to do Automatically create chamber music compositions that you can play and you can listen to online And so again, it's her background math and computer science Actually, that's her there classical pianist Now I will say she's not your average classical pianist She's a classical pianist who also has a master's in medical research from Stanford and studied neuroscience And was a high-performance computing expert at the shore and was about a Victorian at Princeton Anyway, she you know very annoying person good at everything she does But you know, I think it's really cool to see how a kind of a domain expert in this case the domain of playing piano can go through the fast AI course and Come out the other end and I guess open AI would be You know of the three top research institutes Google Blaine or open AI would be two of them probably along with deep learning And interestingly actually one of our other students or should say alumni of the course recently interviewed Her for a blog post series. He's doing on top AI researchers And she said one of the most important pieces of advice she got was for me And she said the piece of advice was pick one project Do it really well make it fantastic Okay, so that was the piece of advice she found the most useful and we're going to be talking a lot about you Doing projects and making them fantastic during this course Having said that I don't really want you to go to AI or Google brain What I really want you to do is go back to your workplace or your passion project and apply these skills There right let me give you an example MIT released a deep learning course and they highlighted in their announcement for this deep learning course this medical imaging example and One of our students Alex who is a radiologist? said You guys just showed model overfitting. I can tell Because I'm a radiologist and this is not what this would look like on a chest film This is what it should look like and this as a deep learning practitioner. This is how I know This is what happened in your model. So Alex is combining his knowledge of radiology and his knowledge of deep learning to assess MIT's model from just two images very accurately All right, and so this is actually what I want most of you to be doing is to take your domain expertise And combine it with the deep learning Practical aspects that you'll learn in this course and bring them together like Alex is doing here and so a lot of radiologists have actually gone through this course now and have built journal clubs and American Council of Radiology practice groups There's a data science institute at the ACR now and so forth and Alex is one of the people who's providing kind of a lot Of leadership in this area I would love you to do the same kind of thing that Alex is doing which is to really bring deep learning later leadership into your Industry and just your social impact project whatever it is that you're trying to do So another great example was this was Melissa Fabros who was a English literature PhD He just studied like gendered language in English literature or something and actually Rachel in a previous job taught her to code I think and then she came into the fast AI course and she helped Kiva a micro lending social impact organization to build a system that can recognize Faces why is that necessary? Well, we're going to be talking a lot about this but because most AI researchers are white men most computer vision software Can only recognize white male faces effectively in fact I think of this IBM system is like ninety nine point eight percent accurate on common white face men versus 60 percent accurate 65 percent accurate on dark fate dark skinned women So it's like what is that like 30 or 40 times worse? For black women versus white men and this is really important because for Kiva Black women are you know, perhaps the most common user base for their micro lending platform So Melissa after taking our course and again working her ass off and being super intense in her study and her work Won this 1 million dollar AI challenge for her work for Kiva I Think did our course and realized that the thing he wanted to do wasn't at his company It was something else which is to help blind people to understand the world around them So he started a new startup you can find it now. It's called in vision You can download the app you can point your phone at things and it will tell you what it sees And I actually talked to a blind lady about these kinds of apps the other day and she confirmed to me This is a super useful thing for visually disabled users And it's not it's the level that you can get to With with the content that you're going to get over these seven weeks and with this software Can get you right to the cutting edge in areas you might find surprising For example, I helped a team of some of our students and some collaborators on actually breaking the world record for training remember I mentioned the image net data set lots of people want to train on the image net data set We smashed the world record for how quickly you can train it. We use standard AWS cloud infrastructure Cost of $40 of compute to train this model Using again fast AI library the techniques that we learn in this course So it can really take you a long way. So don't be kind of put off by this What might seem pretty simple at first we're going to get deeper and deeper You can also use it for other kinds of passion project So Helena sarin actually you should definitely check out her Twitter account like a list This art is a basically a new style of art that she's developed Which combines her painting and drawing with generative adversarial models to create these extraordinary? Results and so I think this is super cool. I mean, she's not a professional artist. She is a professional software developer but she just keeps on producing these beautiful results and when she started you know her Her art had not really been shown anywhere or discussed anywhere now There's recently been some quite high profile articles describing how she is creating a new form of art again this has come out of the fast AI course that she developed these skills or Equally important Brad Kensler who figured out how to make a picture of Kanye out of pictures of Patrick Stewart's head Also something you will learn to do if you wish to This particular style this particular type of what's called style transfer was a really interesting tweak that allowed him to do some things that hadn't quite been done before and And this particular picture helped him to get a job as a deep learning specialist at AWS. So Another interesting example another alumni actually worked at Splunk as a software engineer and He'd signed an algorithm after like lesson three Which basically turned out at Splunk to be fantastically good at identifying fraud and we'll talk more about it shortly If you've seen Silicon Valley the HBO series the hot dog not hot dog app That's actually a real app you can download and it was actually built by Tim on blade as a fast AI student project So there's a lot of cool stuff that you can do Yes, it was it any nominated. So I think we only have one any nominated deep fast AI alumni at this stage So, please help change that All Right The other thing, you know is is is the forum threads can kind of turn into these really cool things So Francisco is actually here in the audience. He's a really Boring McKinsey consultant like me right so Francisco and I both have this shameful past that we were McKinsey consultants but we left and we're okay now and He started this thread saying like oh this stuff. We've just been learning about building NLP and different languages. Let's try and do lots of different languages We started this thing called the language model zoo and out of that there's now been an academic Competition was one in Polish that led to an academic paper Thai state of the art German state of the art Basically as students have been coming up with new study that results across lots of different languages and this all is entirely being done By students working together through the forum. So please get on the forum but Don't be intimidated because remember a lot of the people everybody you see on the forum the vast majority posting Post all the damn time right? They've been doing this a lot and they do it a lot of the time and so at first it can feel Intimidating because it can feel like you're the only new person there But you're not right all of you people in the audience everybody who's watching everybody He's listening you're all new people that and so when you just get out there and say like Okay, all you people getting used out of the art results in German language modeling. I Can't start my server. I try to click the notebook and I get an error What do I do people will help you? Okay, just make sure you provide all the information. This is though. You know, I'm using paper space This was the particular instance. I tried to use here's a screenshot of my error People will help you. Okay, or if you've got something to add so if people are talking about Crop yield analysis and you're a farmer and you think you know, oh, I've got something to add Please Mention it even even if you're not sure it's exactly relevant. It's fine You know just get involved and because remember everybody else in the forum started out Also intimidated. All right, we all start out Not knowing things and so just get out there and try it. Okay So Let's get back and do some more coding Yes, Richard, we have some questions So the question is about this architecture So there are lots of architectures to choose from and it would be fair to say there isn't one best one but if you look at things like the Stanford dawn bench benchmark or image net classification You'll see in first place in second place in third place in fourth place is fast AI Jeremy had and fast AI Jeremy had fast AI here's gloves from the Department of Defense Innovation team Google Resnet resnet resnet resnet resnet. It's good enough. Okay, so it's fun There are other architectures the main reason you might want a different architecture is if you want to do edge computing So if you want to create a model that's going to sit on somebody's mobile phone Having said that even there most of the time I reckon the best way to get a model onto somebody's mobile phone is to run It on your server and then have your mobile phone app talk to it It really makes life a lot easier and you've got a lot more flexibility But if you really do need to run something on a low-powered device, then there are some special architectures for that So the particular question was about inception That's a particular another architecture which tends to be pretty memory intensive and yet resident So inception tends to be pretty memory intensive, but it's okay. It's also like It's not terribly resilient. One of the things we try to show you is like stuff which just tends to always work Even if you don't quite tune everything perfectly So resident tends to work pretty well across a wide range of different Kind of details around choices that you might make so I think it's pretty good So we've got this train model and so what's actually happened as we'll learn is it's basically Creating a set of weights if you've ever done anything like linear regression or logistic regression, you'll be familiar with coefficients We basically found some coefficients and parameters that work pretty well And it took us a minute and 56 seconds So if we want to start doing some more playing around and come back later, we probably should save those weights So we can save that minute and 56 seconds so you can just go learn dot save and give it a name It's going to put it In a model sub directory in the same place the data came from So if you save different models or different data bunches from different data sets, they'll all be kept separate. So don't worry about it Alright so we talked about how the most important things are how to learn what goes into your model What comes out we've seen one way of seeing what goes in now. Let's see what comes out As this is the other thing you need to get really good at so to see what comes out we can use this class called classification interpretation and We're going to use this factory method from learner. So we pass in a learn object. So remember a learn object knows two things what's your data and What is your model? It's now not just an architecture, but it's actually a trained model inside there and that's all the information We need to interpret that model. So it's this pass in the learner and we now have a classification interpretation object and So one of the things we can do and perhaps the most useful things to do is called plot top losses So we're going to be learning a lot about this idea of loss functions shortly but in short a loss function is something that tells you how good was your prediction and So specifically that means if you predicted one class of cat With great confidence. You said I am very very sure that this is a Berman But actually you were wrong then then that's going to have a high loss because you were very confident about the wrong answer Okay, so that's what it basically means to have a high loss. So by putting the top losses, we're going to find out What were the things that we were the most wrong on or the most confident about what we got wrong? So you can see here It prints out three things German shorthead before things big all seven point oh four point nine two Well, what do they mean? Perhaps we should look at the documentation So if you we've already seen help right and help just prints out a quick little summary but if you want to really see how to do something use doc and doc Tells you the same information as help, but it has this very important thing which is show in docs So when you click on show in docs It pops up the documentation for that method or class or function or whatever It starts out by showing us the same information about what is what are the parameters it takes? Along with the doc string, but then tells you more information So in this case it's other thing that tells me the title of each shows the prediction the actual the loss and the probability That was predicted So for example and you can see there's actually some code you can run so the documentation always has working code and so in this case it was trying things with handwritten digits and So the first one it was predicted to be a seven. It was actually a three the loss is five point 44 and the probability of the actual class was point oh seven. Okay, so I You know, we did not have a high probability associate the actual class I can see why I thought this was a seven and the less it was wrong. So this is the documentation Okay, and so this is your friend when you're trying to figure out how to use these things the other thing I'll mention is if you're a Somewhat experienced Python programmer. You'll find the source code of fast AI really easy to read we try to write everything in just a small number of you know, Much less than half a screen of code generally four or five lines of code if you click source You can jump straight to the source code, right? So here is the plot top losses and this is also a great way to find out How to use the fast AI library because every line of code here nearly every line of code is calling stuff in the fast AI library Okay, so don't be afraid to look at the source code I've got another really cool trick about the documentation that you're going to see a little bit later Okay So that's how we can look at these top losses and these are perhaps the most important image classification Interpretation tool that we have because it lets us see What are we getting wrong and quite often? Like in this case if you're a dog and cat expert you'll realize that the things that's getting wrong Are breeds that are actually very difficult to tell apart and you'd be able to look at these and say oh I can see why? They've got this one wrong So this is a really useful tool Another useful tool kind of is to use them in quarter confusion matrix, which basically shows you for every actual Type of dog or cat how many times was it predicted to be that dog or cat? But unfortunately in this case because it's so accurate this diagonal basically says Oh, it's pretty much right all the time and you can see there's some slightly darker ones like a five here But it's really hard to read exactly what that combination is So what I suggest you use is instead of if you've got lots of classes don't use a classification confusion matrix But this is my favorite named function in fast AI. I'm very proud of this you can call most confused And most confused will simply grab out of the confusion matrix the particular Combinations have predicted an actual that got wrong the most often so in this case the Staffordshire ballteria was what it should have predicted and instead it predicted an American pit bull terrier and so forth it should have predicted a Siamese and actually predicted boom and that happened four times This particular combination happened six times so this is again a very useful thing because you can look and you can say like From with my domain expertise does it make sense that that would be something that was confused about it So these are some of the kinds of tools you can use to look at the output Let's pick our model better So how do we make the bottle better? We can make it better using fine-tuning So far we fitted For a box and it ran pretty quickly and the reason it ran pretty quickly is that there was a little trick we used These deep learning models these compositional networks they have many layers We'll learn a lot about exactly what layers are but for now just know it goes through a computer computation or computation or computation or computation What we did was we added a few extra layers to the end and we only trained those We basically left most of the model exactly as it was so that's really fast And if we try to build a model of something that's similar to the original Pre trained model so in this case similar to the image net data that works pretty well But what we really want to do is actually go back and train the whole model So this is why we pretty much always use this two-stage process. So by default When we call fit will fit one cycle on a confowner It'll just fine-tune these few extra layers added to the end and it'll run very fast. It'll basically never over fit But to really get it good you have to call unfreeze and unfreeze is the thing that says please train the whole model and then I can call fit one cycle again and Uh-oh The error got much worse Okay, why? In order to understand why we're actually going to have to learn more about exactly what's going on behind the scenes So let's start out by trying to get an intuitive understanding of what's going on behind the scenes And again, we're going to do it by looking at pictures We're going to start with this picture these pictures come from a fantastic paper by Matt Zyler who nowadays is CEO of Clarify Which is a very successful computer vision startup and His supervisor of his PhD Rob Fergus And they created a paper showing how you can visualize the layers of a convolutional neural network So a convolutional neural network will learn mathematically about what the layers are shortly But the basic idea is that your red green and blue pixel values that are numbers from naught to 255 go into a simple computation The first layer and something comes out of that and then the result of that goes into a second layer so that goes to a third layer and so forth and There can be up to a thousand layers of a neural network Resnet 34 has 34 layers Resnet 50 has 50 layers But let's look at layer 1. There's this very simple computation. It's a convolution if you know what they are We'll learn more about them shortly What comes out of this first layer? Well, we can actually visualize these specific coefficients the specific parameters by drawing them as a picture There's actually a few dozen of of them in the first layer So we won't draw all of them, but let's just look at nine at random So here are nine examples of the actual coefficients from the first layer and so these operate on groups of pixels that are next to each other and So this first one basically finds groups of pixels that have a little horizontal diagonal line in this direction This one finds diagonal lines in the other direction This line gradients that go from yellow to blue in this direction this one finds gradients that go from pink to green In this direction and so forth. That's a very very simple little filters That's layer one of a image net pre-trained convolutional neural net Layer two Takes the results of those filters and does a second layer of computation and it allows it to create so here are nine examples of A way of visualizing this one of the second layer features and you can see it's basically learned to create something that looks for Corners top left corners and This one is learned to find things that find right hand curves This one is learned to find things that find little circles All right, so you can see how layer two like this is the easiest way to see it in layer one We have things that can find just one line and layer two we can find things that have two lines joined up or one line repeated If you then look over here These nine show you nine examples of actual bits of actual photos that activated this filter a lot that's another words this little bit of Function math function here was good at finding these kind of window corners and stuff like that This little circle E1 was very good at finding bits of photos that have circles Okay, so this is the kind of stuff You've got to get a really good intuitive understanding for us likely the start of my neural nets gonna find simple Very simple gradients lines the second layer can find very simple shapes the third layer can find combinations of those So now we can find repeating patterns of two-dimensional objects or we can find kind of things that joins that join together Or we can find well, what are these things? Well, let's find out. What is this? Let's go and have a look at some bits of picture that activated this one highly. Oh Mainly they're bits of text although sometimes windows so it seems to be able to find kind of like repeated horizontal patterns and this one here says we have to find kind of Edges of fluffy or flowery things This one here is kind of finding geometric patterns. So layer 3 was able to take all the stuff from layer 2 and combine them together layer 4 can take all the stuff from layer 3 and combine them together by layer 4 we put something that can find dog faces and And let's see what else we've got here Yeah, various kinds of oh here we are bird legs So you kind of get the idea and so by layer 5 we've got something that can find the eyeballs of birds and wizards or Faces of particular breeds of dogs and so forth. So you can see how by the time you get to layer 34 You can find specific dog breeds and cat breeds, right? This is kind of how it works. So when we first Trained when we first fine-tuned that pre-trained model We kept all of these layers that you've seen so far and we just trained a few more layers on top of all of those Sophisticated features that are already been created And so now we're fine-tuning we're going back and saying let's change all of these We'll keep that we'll start with them where they are, right? But let's see if we can make them better Now it seems very unlikely that we can make these layer one features Better like it's very unlikely that the kind of the definition of a diagonal line It's going to be different when we look at dog and cat breeds versus the image net data that this is originally trained on So we don't really want to change layer one very much if at all Where else the last layers, you know this thing of like types of dog face Seems very likely that we do want to change that right? So you kind of want this intuition is understanding that the different layers of a neural network represents different levels of kind of semantic complexity So this is why our attempt to fine-tune this model didn't work is because we actually By default it trains all the layers at the same speed, right? Which is to say it'll update those like things representing diagonal lines of gradients Just as much as it tries to update the things that represent the exact specifics of what an eyeball looks like So we have to change that and so To change it. We first of all need to go back to where we were before. Okay, we just broke this model, right? It's much worse than started out So if we just go load this brings back the model that we saved earlier. Remember we saved it as stage one Okay, so let's go ahead and Load that back up. So that's now our models back to where it was before we killed it and Let's run Learning rate finder. We'll learn about what that is next week But for now just know this is the thing that figures out what is the fastest I can train this neural network at? Without making it zip off the rails and get blown apart okay, so we can call learn dot LR find and Then we can go learn dot recorder dot plot and that will plot the result of our LR finder And what this basically shows you is this this key parameter that we're going to learn all about called the learning rate and the learning Rate basically says how quickly am I updating the parameters in my model? and you can see that what happens is as I think this this bottom one here shows me what happens as I increase the learning rate and This one here shows what you know, what's the result? What's the loss and so you can see once the learning rate gets past 10 to the negative 4 my loss gets worse, okay, so It actually so happens. In fact, I can check this if I press shift tab here my learning rate defaults to 0.003 so my default learning rate is about here So you can see where our loss got worse right because we're trying to fine-tune things now We can't use such a high learning rate So based on the learning rate finder, I tried to pick something, you know Well before it started getting worse So I decided to pick one in x6. So I decided I'm going to trade at that rate But there's no point trading all the layers at that rate because we know that the later layers worked Just fine before when we were training much more quickly again of the default which was to remind us 0.003 so what we can actually do is we can pass a range of learning rates to learn dot fit And we do it like this you pass you use this keyword in fact in Python you may have come across before it's called slice and that can take a start value and a stop value and basically what this says is train the very first players at a learning rate of 1e neg 6 and The very last layers at a rate of 1e neg 4 and then kind of distribute all the other layers Across that, you know between those two values equally So we're going to see that in a lot more detail, but basically for now This is kind of a good rule of thumb is to say when you after you unfreeze This is the thing that's going to train the whole thing Pass a max learning rate parameter pass it a slice Make the second part of that slice about 10 times smaller than your first stage So our first stage defaulted to about 1e neg 3 So let's use about 1e neg 4 and then this one should be a value from your learning rate finder Which is well before things started getting worse and you can see things are starting to get worse Maybe about here So I picked something that's at least 10 times smaller than that. So if I do that then I get point oh five seven eight eight so Remember what we got before Yeah, get better right? So we've gone down from the six point one percent to a five point seven percent So that's about a ten percentage point relative improvement with another 58 seconds of training. So I Would perhaps say for most people most of the time these two stages are enough to get Pretty much a world-class model You won't win a Kaggle competition particularly because now a lot of fast AI alumni are competing on Kaggle And this is the first thing that they do But you know in practice you'll get something that's you know about as good in practice as the vast majority of practitioners can do We can improve it by using more layers and we'll do this next week by basically doing a resnet 50 instead of a resnet 34 And you can try running this during the week if you want to you'll see it's exactly the same as before But I'm using resnet 50 instead of resnet 34 What you'll find is it's very likely if you try to do this you will get an error And the error will be your GPU is run out of memory and the reason for that is that resnet 50 is bigger than resnet 34 and Therefore it has more parameters and therefore it uses more of your graphics cards memory Just totally separate to your normal computer RAM. This is GPU RAM If you're using the kind of default salamander AWS And so forth suggestion then you'll be having a 16 gig of GPU memory the pad I use most the time has 11 gig of GPU memory The cheaper ones have 8 gig of GPU memory and that's kind of the main range you tend to get If yours has less than 8 gig of GPU memory, it's going to be frustrating for you Anyway, so you'll be somewhere around there And it's very likely that we try to run this you'll get it out of memory memory error And that's because it's just trying to do too much too many parameter updates for the amount of RAM you have And that's easily fixed This image data bunch constructor has a parameter at the end Batch size BS for batch size and this basically says how many images do you train at one time? If you run out of memory, just make it smaller Okay, so this worked for me on an 11 gig card It probably won't work for you if you've got an 8 gig card if you do just make that 32 It's fine to use a smaller batch size it just it might take a little bit longer that's all okay If you've got a bigger like a 16 gig you might be able to go away with 64. Okay, so that's just one number you'll need to try during the week and again, we feed it for a while and we We get down to a four point four percent area So this is pretty extraordinary. You know, I was pretty surprised because I mean When we first did in the first course just cats versus dogs. We were kind of getting Somewhere around a three percent error for something where you've got a 50% chance of being right and the two things look totally different so the fact that we can get a four point four percent error for such a fine-grain thing it's quite extraordinary In this case, I unfroze it and fit it a little bit more went from four point four to four point three five tiny improvement Basically, resident 50 is already a pretty good model It's interesting because again you can call most confused here and you can see the kinds of things that it's Getting wrong and I actually depending on when you run it you're going to get slightly Different numbers, but you'll get roughly the same kinds of things So quite often I find that ragdoll and burman are things that it gets confused and I actually never heard of either of those things So I actually looked them up on the internet And I Found a page on the cat site Called is this a burman or a ragdoll and there is a long thread of cat experts like arguing intensely About which it is so I feel fine that my computer had problems I found something similar. I think it was this pit rule versus daffodil terrier Apparently the main difference is like the particular kennel club guidelines as to how they are assessed But some people think that one of them might have a slightly reddened nose So this is the kind of stuff where actually if you're not a domain expert It helps you become one right because I now know more about which kinds of pet breeds are hard to identify Than I used to So model interpretation works both ways. So what I want you to do this week is to run This notebook, you know, make sure you can get through it But then what I really want you to do is to get your own image data set and actually I'm Francisco who I mentioned earlier. He started the language to model thread and he's you know Now helping to TA the course he's actually putting together a guide that will show you how to download data From Google images so you can create your own data set to play with but before I do I want to Okay, I'll come back to that moment Before I do I want to show you Because how to create labels in lots of different ways because your data set wherever you get it from won't necessarily Be that kind of red checks based approach. It could be in lots of different formats So just show you how to do this I'm going to use the MNIST sample and this is pictures of hand-drawn numbers I'm just because I want to show you different ways of Creating these data sets The The MNIST sample Basically looks like this so I can go path dot LS Okay, and you can see it's got a training set in the validation set already So basically the people that put together this data set have already decided what they want you to use as a validation set Okay, so if you go path slash train LS You'll see there's a folder called three and a folder called seven All right Now this is really really common way to just to give people labels It's basically to say oh everything that's a three I'll put in a folder called three everything that's a seven I'll put in a folder called seven that this is often called an Image net style data set because this is how image net is distributed So if you have something in this format where the the labels are just whatever the folders called you can say from folder Okay, and that will create an image data bunch for you And as you can see three seven, it's created the labels just by using the folder names Another possibility and as you can see we can train that get 99.55 percent accuracy blah blah blah Another possibility and for this MNIST sample, I've got both it might come with a CSV file That would look something like this for each file name. What's its label now in this case? The labels aren't three or seven There's zero or one which is basically is it a seven or not? That's that's another possibility. So if this is how your labels are you can use from CSV And if it's called labels dot CSV, you don't even have to pass in a file name If it's called anything else, then you can call pass in the CSV labels So on there, okay, so that's how you can use a CSV. Okay, there it is. This is now is it a seven or not? Another possibility and then you can call data dot passes to see what it found another possibility This as we've seen is you've got paths that look like this And so in this case, this is the same thing. These are the folders, right? I could actually grab the The label by using a regular expression and so here's the regular expression So we've already seen that approach and again, you can see data dot classes has found it So what if you it's something that's in the file name of a path, but it's not just a regular expression. It's more complex You can create an arbitrary function that extracts a label from the file name or path and in that case You would say from name and function Another possibility Is that even you did something even more flexible than that? And so you're going to write some code to create an array of labels And so in that case you can just pass in from lists So here's I've created an array of labels. Here are my labels is from lists Okay, and then I just pass in that rate so you can see there's lots of different ways of creating labels So so during the week Try this out now. You might be wondering How would you know to do all these things like where am I going to find? this Kind of information right? How would I how do you possibly know to do all this stuff? So I'll show you something incredibly cool. Let's grab this function and Do you remember to get documentation we type doc? And here is the documentation for the function and I can click show in docs and It pops up the documentation So here's the thing Every single line of code I just showed you I took it this morning, and I copied and pasted it from the documentation So you can see here the exact Code that I just used so the documentation for fast AI doesn't just tell you What to do but step to step how to do it and Here is perhaps the coolest bit if you go to fast AI fast AI Underscore docs and click on doc source It turns out that all of our documentation is actually just Jupiter notebooks. So in this case, I was looking at vision dot data So here is the vision dot data notebook you can download this repo you can get cloned up and If you run it, you can actually run Every single line of the documentation yourself Okay, so so all of our docs is also code and so like this is the kind of the ultimate example to me of of Experimenting right is that you can now Experiment and you'll see in in github It doesn't quite render properly because github doesn't quite know how to render notebooks properly But if you get plumb this and open it up in Jupiter You can see it and so now anything that you read about in the documentation Nearly everything in the documentation has actual working examples in it with actual data sets that are already sitting in there in the repo For you and so you can actually try every single function in your browser try seeing what goes in and try seeing What comes out? There's a question Will the library use multi GPU and parallel by default? The library will use multiple CPUs by default, but just one GPU by default We've probably what we're looking at multi GPU until part two. It's easy to do and you'll find it on the forum, but Most people won't be needing to use that now And the second question is whether the library can use 3d data such as MRI or Yes, it can and there is actually a forum thread about that already Although that's not as developed as 2d yet, but maybe by the time the MOOC is out it will be So before I wrap up I'll just show an example of the kind of interesting stuff that you can do by Doing this kind of exercise Remember earlier I mentioned that one of our alums who works at Splunk which is the Nasdaq listed big successful company Create this new anti-fraud software This is actually how he created it as part of a fast AI part one class project He took the telemetry of the users who had Splunk analytics installed and watched their mouse movements And it created pictures of the mouse movements. He converted speed into color and bright and left clicks into splotches he then took the exact code that we saw with an earlier version of the software and trained a CNN in exactly the way we saw and Use that to train his fraud model. So he basically took something which is not obviously a picture and he turned it into a picture And got these fantastically good results for a piece of fraud analysis software. So it pays to think Creatively, so if you're wanting to study sounds a lot of people that study sounds do it by actually creating a spectrogram image and Then sticking that into a component. So there's a lot of cool stuff you can do with this So during the week, yeah get your get your GPU going try and use your first notebook Make sure that you can use less than one and work through it and then see if you can repeat the process On your own data set get on the forum and tell us any little success you had It's like oh, I spent three days trying to get my GPU running and I finally did any constraints that you hit You know try it for an hour or two, but if you get stuck, please ask And if you're able to successfully build a model with a new data set, let us know and I will see you next week", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 1, "seek": 0, "start": 2.04, "end": 4.04, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 2, "seek": 0, "start": 4.24, "end": 6.16, "text": " Welcome", "tokens": [4027], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 3, "seek": 0, "start": 6.16, "end": 8.96, "text": " Practical deep learning for coders less than one", "tokens": [19170, 804, 2452, 2539, 337, 17656, 433, 1570, 813, 472], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 4, "seek": 0, "start": 9.58, "end": 11.58, "text": " it's kind of lesson two because", "tokens": [309, 311, 733, 295, 6898, 732, 570], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 5, "seek": 0, "start": 11.92, "end": 17.2, "text": " There's a lesson zero and lesson zero is is why do you need a GPU and how do you get it set up?", "tokens": [821, 311, 257, 6898, 4018, 293, 6898, 4018, 307, 307, 983, 360, 291, 643, 257, 18407, 293, 577, 360, 291, 483, 309, 992, 493, 30], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 6, "seek": 0, "start": 17.2, "end": 20.12, "text": " So if you haven't got a GPU running yet", "tokens": [407, 498, 291, 2378, 380, 658, 257, 18407, 2614, 1939], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 7, "seek": 0, "start": 20.84, "end": 25.240000000000002, "text": " then go back and do that make sure that you can access a", "tokens": [550, 352, 646, 293, 360, 300, 652, 988, 300, 291, 393, 2105, 257], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 8, "seek": 0, "start": 26.0, "end": 28.0, "text": " Jupiter notebook and", "tokens": [24567, 21060, 293], "temperature": 0.0, "avg_logprob": -0.22116721855415092, "compression_ratio": 1.55, "no_speech_prob": 0.01639726758003235}, {"id": 9, "seek": 2800, "start": 28.0, "end": 32.28, "text": " And then you're ready to start the real lesson one. So if you're ready", "tokens": [400, 550, 291, 434, 1919, 281, 722, 264, 957, 6898, 472, 13, 407, 498, 291, 434, 1919], "temperature": 0.0, "avg_logprob": -0.20928618593036002, "compression_ratio": 1.7201646090534979, "no_speech_prob": 1.7502410628367215e-05}, {"id": 10, "seek": 2800, "start": 33.0, "end": 35.96, "text": " You will be able to see something like this", "tokens": [509, 486, 312, 1075, 281, 536, 746, 411, 341], "temperature": 0.0, "avg_logprob": -0.20928618593036002, "compression_ratio": 1.7201646090534979, "no_speech_prob": 1.7502410628367215e-05}, {"id": 11, "seek": 2800, "start": 36.76, "end": 38.2, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.20928618593036002, "compression_ratio": 1.7201646090534979, "no_speech_prob": 1.7502410628367215e-05}, {"id": 12, "seek": 2800, "start": 38.2, "end": 42.18, "text": " In particular, hopefully you have gone to notebook tutorial. It's at the top", "tokens": [682, 1729, 11, 4696, 291, 362, 2780, 281, 21060, 7073, 13, 467, 311, 412, 264, 1192], "temperature": 0.0, "avg_logprob": -0.20928618593036002, "compression_ratio": 1.7201646090534979, "no_speech_prob": 1.7502410628367215e-05}, {"id": 13, "seek": 2800, "start": 42.18, "end": 48.04, "text": " That's why we're zero zero here as this grows. You'll see more and more files, but we'll keep notebook tutorial at the top and", "tokens": [663, 311, 983, 321, 434, 4018, 4018, 510, 382, 341, 13156, 13, 509, 603, 536, 544, 293, 544, 7098, 11, 457, 321, 603, 1066, 21060, 7073, 412, 264, 1192, 293], "temperature": 0.0, "avg_logprob": -0.20928618593036002, "compression_ratio": 1.7201646090534979, "no_speech_prob": 1.7502410628367215e-05}, {"id": 14, "seek": 2800, "start": 48.96, "end": 50.96, "text": " You will have used your", "tokens": [509, 486, 362, 1143, 428], "temperature": 0.0, "avg_logprob": -0.20928618593036002, "compression_ratio": 1.7201646090534979, "no_speech_prob": 1.7502410628367215e-05}, {"id": 15, "seek": 5096, "start": 50.96, "end": 57.96, "text": " Jupiter notebook to add one and one together get in the expected result", "tokens": [24567, 21060, 281, 909, 472, 293, 472, 1214, 483, 294, 264, 5176, 1874], "temperature": 0.0, "avg_logprob": -0.30065559974083533, "compression_ratio": 1.5818181818181818, "no_speech_prob": 9.516137652099133e-06}, {"id": 16, "seek": 5096, "start": 60.52, "end": 62.52, "text": " Let's make that a bit bigger", "tokens": [961, 311, 652, 300, 257, 857, 3801], "temperature": 0.0, "avg_logprob": -0.30065559974083533, "compression_ratio": 1.5818181818181818, "no_speech_prob": 9.516137652099133e-06}, {"id": 17, "seek": 5096, "start": 63.56, "end": 66.52, "text": " And hopefully you've learned these four keyboard shortcuts", "tokens": [400, 4696, 291, 600, 3264, 613, 1451, 10186, 34620], "temperature": 0.0, "avg_logprob": -0.30065559974083533, "compression_ratio": 1.5818181818181818, "no_speech_prob": 9.516137652099133e-06}, {"id": 18, "seek": 5096, "start": 67.52, "end": 68.64, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.30065559974083533, "compression_ratio": 1.5818181818181818, "no_speech_prob": 9.516137652099133e-06}, {"id": 19, "seek": 5096, "start": 68.64, "end": 71.84, "text": " The basic idea is that your Jupiter notebook", "tokens": [440, 3875, 1558, 307, 300, 428, 24567, 21060], "temperature": 0.0, "avg_logprob": -0.30065559974083533, "compression_ratio": 1.5818181818181818, "no_speech_prob": 9.516137652099133e-06}, {"id": 20, "seek": 5096, "start": 72.76, "end": 79.28, "text": " has pros in it it can have pictures in it it can have", "tokens": [575, 6267, 294, 309, 309, 393, 362, 5242, 294, 309, 309, 393, 362], "temperature": 0.0, "avg_logprob": -0.30065559974083533, "compression_ratio": 1.5818181818181818, "no_speech_prob": 9.516137652099133e-06}, {"id": 21, "seek": 7928, "start": 79.28, "end": 82.12, "text": " Charts in it", "tokens": [761, 11814, 294, 309], "temperature": 0.0, "avg_logprob": -0.21854305267333984, "compression_ratio": 1.6511627906976745, "no_speech_prob": 2.5215622372343205e-06}, {"id": 22, "seek": 7928, "start": 83.12, "end": 86.38, "text": " And most importantly it can have code in it", "tokens": [400, 881, 8906, 309, 393, 362, 3089, 294, 309], "temperature": 0.0, "avg_logprob": -0.21854305267333984, "compression_ratio": 1.6511627906976745, "no_speech_prob": 2.5215622372343205e-06}, {"id": 23, "seek": 7928, "start": 87.2, "end": 89.56, "text": " So the code is in Python", "tokens": [407, 264, 3089, 307, 294, 15329], "temperature": 0.0, "avg_logprob": -0.21854305267333984, "compression_ratio": 1.6511627906976745, "no_speech_prob": 2.5215622372343205e-06}, {"id": 24, "seek": 7928, "start": 90.64, "end": 95.98, "text": " How many people have used Python before so nearly all of you that's great", "tokens": [1012, 867, 561, 362, 1143, 15329, 949, 370, 6217, 439, 295, 291, 300, 311, 869], "temperature": 0.0, "avg_logprob": -0.21854305267333984, "compression_ratio": 1.6511627906976745, "no_speech_prob": 2.5215622372343205e-06}, {"id": 25, "seek": 7928, "start": 96.56, "end": 100.52000000000001, "text": " If you haven't used Python, that's totally okay. All right", "tokens": [759, 291, 2378, 380, 1143, 15329, 11, 300, 311, 3879, 1392, 13, 1057, 558], "temperature": 0.0, "avg_logprob": -0.21854305267333984, "compression_ratio": 1.6511627906976745, "no_speech_prob": 2.5215622372343205e-06}, {"id": 26, "seek": 7928, "start": 101.36, "end": 105.02000000000001, "text": " It's a pretty easy language to pick up but if you haven't used Python", "tokens": [467, 311, 257, 1238, 1858, 2856, 281, 1888, 493, 457, 498, 291, 2378, 380, 1143, 15329], "temperature": 0.0, "avg_logprob": -0.21854305267333984, "compression_ratio": 1.6511627906976745, "no_speech_prob": 2.5215622372343205e-06}, {"id": 27, "seek": 10502, "start": 105.02, "end": 112.39999999999999, "text": " This will feel a little bit more intimidating because the code that you're seeing will be unfamiliar to you. Yes, Rachel", "tokens": [639, 486, 841, 257, 707, 857, 544, 29714, 570, 264, 3089, 300, 291, 434, 2577, 486, 312, 29415, 281, 291, 13, 1079, 11, 14246], "temperature": 0.0, "avg_logprob": -0.2728966395060221, "compression_ratio": 1.511111111111111, "no_speech_prob": 3.340453304190305e-06}, {"id": 28, "seek": 10502, "start": 118.5, "end": 120.5, "text": " No, cuz I", "tokens": [883, 11, 11910, 286], "temperature": 0.0, "avg_logprob": -0.2728966395060221, "compression_ratio": 1.511111111111111, "no_speech_prob": 3.340453304190305e-06}, {"id": 29, "seek": 10502, "start": 121.74, "end": 127.89999999999999, "text": " Yeah, okay. Well now that we're here I'll edit this bit out. So as I say there are things like this where", "tokens": [865, 11, 1392, 13, 1042, 586, 300, 321, 434, 510, 286, 603, 8129, 341, 857, 484, 13, 407, 382, 286, 584, 456, 366, 721, 411, 341, 689], "temperature": 0.0, "avg_logprob": -0.2728966395060221, "compression_ratio": 1.511111111111111, "no_speech_prob": 3.340453304190305e-06}, {"id": 30, "seek": 10502, "start": 128.46, "end": 133.56, "text": " People in the room in person. This is one of those bits. It's like this is really for the MOOC audience", "tokens": [3432, 294, 264, 1808, 294, 954, 13, 639, 307, 472, 295, 729, 9239, 13, 467, 311, 411, 341, 307, 534, 337, 264, 49197, 34, 4034], "temperature": 0.0, "avg_logprob": -0.2728966395060221, "compression_ratio": 1.511111111111111, "no_speech_prob": 3.340453304190305e-06}, {"id": 31, "seek": 13356, "start": 133.56, "end": 140.72, "text": " Not for you. That's I think this will be the only time like this in the in the lesson where we've assumed", "tokens": [1726, 337, 291, 13, 663, 311, 286, 519, 341, 486, 312, 264, 787, 565, 411, 341, 294, 264, 294, 264, 6898, 689, 321, 600, 15895], "temperature": 0.0, "avg_logprob": -0.30092709189967104, "compression_ratio": 1.588785046728972, "no_speech_prob": 1.0129823749593925e-05}, {"id": 32, "seek": 13356, "start": 141.04, "end": 142.92000000000002, "text": " You've got this set up", "tokens": [509, 600, 658, 341, 992, 493], "temperature": 0.0, "avg_logprob": -0.30092709189967104, "compression_ratio": 1.588785046728972, "no_speech_prob": 1.0129823749593925e-05}, {"id": 33, "seek": 13356, "start": 142.92000000000002, "end": 144.92000000000002, "text": " Thanks, okay", "tokens": [2561, 11, 1392], "temperature": 0.0, "avg_logprob": -0.30092709189967104, "compression_ratio": 1.588785046728972, "no_speech_prob": 1.0129823749593925e-05}, {"id": 34, "seek": 13356, "start": 146.2, "end": 149.78, "text": " All right, so yeah for those of you in the room or on for on fast AI live", "tokens": [1057, 558, 11, 370, 1338, 337, 729, 295, 291, 294, 264, 1808, 420, 322, 337, 322, 2370, 7318, 1621], "temperature": 0.0, "avg_logprob": -0.30092709189967104, "compression_ratio": 1.588785046728972, "no_speech_prob": 1.0129823749593925e-05}, {"id": 35, "seek": 13356, "start": 150.16, "end": 157.56, "text": " You can go back after this and make sure that you can get this running using the information in course v3.fast.ai", "tokens": [509, 393, 352, 646, 934, 341, 293, 652, 988, 300, 291, 393, 483, 341, 2614, 1228, 264, 1589, 294, 1164, 371, 18, 13, 7011, 13, 1301], "temperature": 0.0, "avg_logprob": -0.30092709189967104, "compression_ratio": 1.588785046728972, "no_speech_prob": 1.0129823749593925e-05}, {"id": 36, "seek": 15756, "start": 157.56, "end": 162.48, "text": " Okay, okay", "tokens": [1033, 11, 1392], "temperature": 0.0, "avg_logprob": -0.33577466011047363, "compression_ratio": 1.381679389312977, "no_speech_prob": 1.1478384294605348e-05}, {"id": 37, "seek": 15756, "start": 166.28, "end": 170.28, "text": " Okay, so a Jupiter notebook is a", "tokens": [1033, 11, 370, 257, 24567, 21060, 307, 257], "temperature": 0.0, "avg_logprob": -0.33577466011047363, "compression_ratio": 1.381679389312977, "no_speech_prob": 1.1478384294605348e-05}, {"id": 38, "seek": 15756, "start": 171.52, "end": 173.52, "text": " really interesting", "tokens": [534, 1880], "temperature": 0.0, "avg_logprob": -0.33577466011047363, "compression_ratio": 1.381679389312977, "no_speech_prob": 1.1478384294605348e-05}, {"id": 39, "seek": 15756, "start": 173.76, "end": 177.12, "text": " device for a data scientist because it kind of lets you", "tokens": [4302, 337, 257, 1412, 12662, 570, 309, 733, 295, 6653, 291], "temperature": 0.0, "avg_logprob": -0.33577466011047363, "compression_ratio": 1.381679389312977, "no_speech_prob": 1.1478384294605348e-05}, {"id": 40, "seek": 15756, "start": 177.92000000000002, "end": 183.24, "text": " run interactive experiments and it lets us give you not just a", "tokens": [1190, 15141, 12050, 293, 309, 6653, 505, 976, 291, 406, 445, 257], "temperature": 0.0, "avg_logprob": -0.33577466011047363, "compression_ratio": 1.381679389312977, "no_speech_prob": 1.1478384294605348e-05}, {"id": 41, "seek": 18324, "start": 183.24, "end": 189.12, "text": " Static piece of information, but it let us let's ask if you something that you can actually", "tokens": [745, 2399, 2522, 295, 1589, 11, 457, 309, 718, 505, 718, 311, 1029, 498, 291, 746, 300, 291, 393, 767], "temperature": 0.0, "avg_logprob": -0.21617638437371506, "compression_ratio": 1.6188524590163935, "no_speech_prob": 1.2218820302223321e-05}, {"id": 42, "seek": 18324, "start": 190.68, "end": 192.68, "text": " interactively experiment with", "tokens": [4648, 3413, 5120, 365], "temperature": 0.0, "avg_logprob": -0.21617638437371506, "compression_ratio": 1.6188524590163935, "no_speech_prob": 1.2218820302223321e-05}, {"id": 43, "seek": 18324, "start": 193.4, "end": 194.92000000000002, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.21617638437371506, "compression_ratio": 1.6188524590163935, "no_speech_prob": 1.2218820302223321e-05}, {"id": 44, "seek": 18324, "start": 194.92000000000002, "end": 197.20000000000002, "text": " Let me explain how we", "tokens": [961, 385, 2903, 577, 321], "temperature": 0.0, "avg_logprob": -0.21617638437371506, "compression_ratio": 1.6188524590163935, "no_speech_prob": 1.2218820302223321e-05}, {"id": 45, "seek": 18324, "start": 197.92000000000002, "end": 204.20000000000002, "text": " Think works well to use these notebooks and to use this material and this is based on the kind of last three years of experience", "tokens": [6557, 1985, 731, 281, 764, 613, 43782, 293, 281, 764, 341, 2527, 293, 341, 307, 2361, 322, 264, 733, 295, 1036, 1045, 924, 295, 1752], "temperature": 0.0, "avg_logprob": -0.21617638437371506, "compression_ratio": 1.6188524590163935, "no_speech_prob": 1.2218820302223321e-05}, {"id": 46, "seek": 18324, "start": 204.20000000000002, "end": 207.08, "text": " We've had with the students who have gone through this course", "tokens": [492, 600, 632, 365, 264, 1731, 567, 362, 2780, 807, 341, 1164], "temperature": 0.0, "avg_logprob": -0.21617638437371506, "compression_ratio": 1.6188524590163935, "no_speech_prob": 1.2218820302223321e-05}, {"id": 47, "seek": 20708, "start": 207.08, "end": 214.20000000000002, "text": " First of all, it works pretty well just to watch a lesson end to end", "tokens": [2386, 295, 439, 11, 309, 1985, 1238, 731, 445, 281, 1159, 257, 6898, 917, 281, 917], "temperature": 0.0, "avg_logprob": -0.19815452500145034, "compression_ratio": 1.6779661016949152, "no_speech_prob": 8.530163540854119e-06}, {"id": 48, "seek": 20708, "start": 216.12, "end": 220.92000000000002, "text": " Don't try and follow along because it's not really designed to go at a speed where you can follow along", "tokens": [1468, 380, 853, 293, 1524, 2051, 570, 309, 311, 406, 534, 4761, 281, 352, 412, 257, 3073, 689, 291, 393, 1524, 2051], "temperature": 0.0, "avg_logprob": -0.19815452500145034, "compression_ratio": 1.6779661016949152, "no_speech_prob": 8.530163540854119e-06}, {"id": 49, "seek": 20708, "start": 220.92000000000002, "end": 224.48000000000002, "text": " It's designed to be something where you just take in the information", "tokens": [467, 311, 4761, 281, 312, 746, 689, 291, 445, 747, 294, 264, 1589], "temperature": 0.0, "avg_logprob": -0.19815452500145034, "compression_ratio": 1.6779661016949152, "no_speech_prob": 8.530163540854119e-06}, {"id": 50, "seek": 20708, "start": 224.48000000000002, "end": 226.98000000000002, "text": " You get a general sense of all of the pieces how it all fits together", "tokens": [509, 483, 257, 2674, 2020, 295, 439, 295, 264, 3755, 577, 309, 439, 9001, 1214], "temperature": 0.0, "avg_logprob": -0.19815452500145034, "compression_ratio": 1.6779661016949152, "no_speech_prob": 8.530163540854119e-06}, {"id": 51, "seek": 20708, "start": 227.32000000000002, "end": 229.04000000000002, "text": " right and", "tokens": [558, 293], "temperature": 0.0, "avg_logprob": -0.19815452500145034, "compression_ratio": 1.6779661016949152, "no_speech_prob": 8.530163540854119e-06}, {"id": 52, "seek": 20708, "start": 229.04000000000002, "end": 232.48000000000002, "text": " Then you can go back and go through it more slowly", "tokens": [1396, 291, 393, 352, 646, 293, 352, 807, 309, 544, 5692], "temperature": 0.0, "avg_logprob": -0.19815452500145034, "compression_ratio": 1.6779661016949152, "no_speech_prob": 8.530163540854119e-06}, {"id": 53, "seek": 20708, "start": 233.28, "end": 235.28, "text": " pausing on in the video", "tokens": [2502, 7981, 322, 294, 264, 960], "temperature": 0.0, "avg_logprob": -0.19815452500145034, "compression_ratio": 1.6779661016949152, "no_speech_prob": 8.530163540854119e-06}, {"id": 54, "seek": 23528, "start": 235.28, "end": 239.7, "text": " And trying things out making sure that you can do the things that I'm doing", "tokens": [400, 1382, 721, 484, 1455, 988, 300, 291, 393, 360, 264, 721, 300, 286, 478, 884], "temperature": 0.0, "avg_logprob": -0.1778552505996201, "compression_ratio": 1.815, "no_speech_prob": 1.4970783922763076e-05}, {"id": 55, "seek": 23528, "start": 240.56, "end": 247.68, "text": " And that you can try and extend them to do it things in your own way. Okay, so don't worry if", "tokens": [400, 300, 291, 393, 853, 293, 10101, 552, 281, 360, 309, 721, 294, 428, 1065, 636, 13, 1033, 11, 370, 500, 380, 3292, 498], "temperature": 0.0, "avg_logprob": -0.1778552505996201, "compression_ratio": 1.815, "no_speech_prob": 1.4970783922763076e-05}, {"id": 56, "seek": 23528, "start": 248.24, "end": 250.24, "text": " Things are zipping along", "tokens": [9514, 366, 710, 6297, 2051], "temperature": 0.0, "avg_logprob": -0.1778552505996201, "compression_ratio": 1.815, "no_speech_prob": 1.4970783922763076e-05}, {"id": 57, "seek": 23528, "start": 250.32, "end": 252.7, "text": " Faster than you can do them. That's normal", "tokens": [46665, 813, 291, 393, 360, 552, 13, 663, 311, 2710], "temperature": 0.0, "avg_logprob": -0.1778552505996201, "compression_ratio": 1.815, "no_speech_prob": 1.4970783922763076e-05}, {"id": 58, "seek": 23528, "start": 253.32, "end": 260.04, "text": " Also, don't try and stop and understand everything the first time if you do understand everything the first time good for you", "tokens": [2743, 11, 500, 380, 853, 293, 1590, 293, 1223, 1203, 264, 700, 565, 498, 291, 360, 1223, 1203, 264, 700, 565, 665, 337, 291], "temperature": 0.0, "avg_logprob": -0.1778552505996201, "compression_ratio": 1.815, "no_speech_prob": 1.4970783922763076e-05}, {"id": 59, "seek": 26004, "start": 260.04, "end": 267.32, "text": " But most people don't particularly as the lessons go on they get faster and they get more difficult. Okay", "tokens": [583, 881, 561, 500, 380, 4098, 382, 264, 8820, 352, 322, 436, 483, 4663, 293, 436, 483, 544, 2252, 13, 1033], "temperature": 0.0, "avg_logprob": -0.15011003142909, "compression_ratio": 1.6176470588235294, "no_speech_prob": 8.139512829075102e-06}, {"id": 60, "seek": 26004, "start": 271.08000000000004, "end": 278.32000000000005, "text": " So at this point we've got our notebooks going we're ready to start doing deep learning and so the main thing that hopefully you're", "tokens": [407, 412, 341, 935, 321, 600, 658, 527, 43782, 516, 321, 434, 1919, 281, 722, 884, 2452, 2539, 293, 370, 264, 2135, 551, 300, 4696, 291, 434], "temperature": 0.0, "avg_logprob": -0.15011003142909, "compression_ratio": 1.6176470588235294, "no_speech_prob": 8.139512829075102e-06}, {"id": 61, "seek": 26004, "start": 278.32000000000005, "end": 284.48, "text": " Going to agree at the end of this is that you can do deep learning regardless of who you are", "tokens": [10963, 281, 3986, 412, 264, 917, 295, 341, 307, 300, 291, 393, 360, 2452, 2539, 10060, 295, 567, 291, 366], "temperature": 0.0, "avg_logprob": -0.15011003142909, "compression_ratio": 1.6176470588235294, "no_speech_prob": 8.139512829075102e-06}, {"id": 62, "seek": 28448, "start": 284.48, "end": 291.64000000000004, "text": " And we don't just mean do we mean do at a very high level. I mean world-class practitioner level deep learning", "tokens": [400, 321, 500, 380, 445, 914, 360, 321, 914, 360, 412, 257, 588, 1090, 1496, 13, 286, 914, 1002, 12, 11665, 32125, 1496, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.24943818544086657, "compression_ratio": 1.4157894736842105, "no_speech_prob": 3.3931123653019313e-06}, {"id": 63, "seek": 28448, "start": 293.32, "end": 294.84000000000003, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.24943818544086657, "compression_ratio": 1.4157894736842105, "no_speech_prob": 3.3931123653019313e-06}, {"id": 64, "seek": 28448, "start": 294.84000000000003, "end": 299.76, "text": " Your main place to be looking for things is course v3.fast.ai", "tokens": [2260, 2135, 1081, 281, 312, 1237, 337, 721, 307, 1164, 371, 18, 13, 7011, 13, 1301], "temperature": 0.0, "avg_logprob": -0.24943818544086657, "compression_ratio": 1.4157894736842105, "no_speech_prob": 3.3931123653019313e-06}, {"id": 65, "seek": 28448, "start": 300.6, "end": 303.52000000000004, "text": " Where you can find out how to get a GPU?", "tokens": [2305, 291, 393, 915, 484, 577, 281, 483, 257, 18407, 30], "temperature": 0.0, "avg_logprob": -0.24943818544086657, "compression_ratio": 1.4157894736842105, "no_speech_prob": 3.3931123653019313e-06}, {"id": 66, "seek": 28448, "start": 304.32, "end": 306.32, "text": " other information and", "tokens": [661, 1589, 293], "temperature": 0.0, "avg_logprob": -0.24943818544086657, "compression_ratio": 1.4157894736842105, "no_speech_prob": 3.3931123653019313e-06}, {"id": 67, "seek": 28448, "start": 306.32, "end": 309.3, "text": " You can also access our forums", "tokens": [509, 393, 611, 2105, 527, 26998], "temperature": 0.0, "avg_logprob": -0.24943818544086657, "compression_ratio": 1.4157894736842105, "no_speech_prob": 3.3931123653019313e-06}, {"id": 68, "seek": 30930, "start": 309.3, "end": 316.5, "text": " You can also access our forums and on our forums you'll find things like how do you", "tokens": [509, 393, 611, 2105, 527, 26998, 293, 322, 527, 26998, 291, 603, 915, 721, 411, 577, 360, 291], "temperature": 0.0, "avg_logprob": -0.16162329370325262, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.68416692961182e-06}, {"id": 69, "seek": 30930, "start": 317.62, "end": 319.62, "text": " build a", "tokens": [1322, 257], "temperature": 0.0, "avg_logprob": -0.16162329370325262, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.68416692961182e-06}, {"id": 70, "seek": 30930, "start": 320.74, "end": 326.22, "text": " Deep learning box yourself and that's something that you can do after you know later on once you've kind of got going", "tokens": [14895, 2539, 2424, 1803, 293, 300, 311, 746, 300, 291, 393, 360, 934, 291, 458, 1780, 322, 1564, 291, 600, 733, 295, 658, 516], "temperature": 0.0, "avg_logprob": -0.16162329370325262, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.68416692961182e-06}, {"id": 71, "seek": 30930, "start": 327.66, "end": 329.66, "text": " Who am I?", "tokens": [2102, 669, 286, 30], "temperature": 0.0, "avg_logprob": -0.16162329370325262, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.68416692961182e-06}, {"id": 72, "seek": 30930, "start": 329.82, "end": 331.82, "text": " So why should you listen to me?", "tokens": [407, 983, 820, 291, 2140, 281, 385, 30], "temperature": 0.0, "avg_logprob": -0.16162329370325262, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.68416692961182e-06}, {"id": 73, "seek": 30930, "start": 332.5, "end": 336.34000000000003, "text": " Well, maybe you shouldn't but I'll try and justify why you should listen to me", "tokens": [1042, 11, 1310, 291, 4659, 380, 457, 286, 603, 853, 293, 20833, 983, 291, 820, 2140, 281, 385], "temperature": 0.0, "avg_logprob": -0.16162329370325262, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.68416692961182e-06}, {"id": 74, "seek": 33634, "start": 336.34, "end": 341.5, "text": " I've been doing stuff with machine learning for over 25 years", "tokens": [286, 600, 668, 884, 1507, 365, 3479, 2539, 337, 670, 3552, 924], "temperature": 0.0, "avg_logprob": -0.2502462213689631, "compression_ratio": 1.6317689530685922, "no_speech_prob": 1.4738368918187916e-05}, {"id": 75, "seek": 33634, "start": 342.06, "end": 348.78, "text": " I started out in management consulting where actually initially I was I think McKinsey and companies first analytical", "tokens": [286, 1409, 484, 294, 4592, 23682, 689, 767, 9105, 286, 390, 286, 519, 21765, 259, 7399, 293, 3431, 700, 29579], "temperature": 0.0, "avg_logprob": -0.2502462213689631, "compression_ratio": 1.6317689530685922, "no_speech_prob": 1.4738368918187916e-05}, {"id": 76, "seek": 33634, "start": 349.06, "end": 353.46, "text": " Specialist and went into general consulting ran a number of startups for a long time", "tokens": [11863, 468, 293, 1437, 666, 2674, 23682, 5872, 257, 1230, 295, 28041, 337, 257, 938, 565], "temperature": 0.0, "avg_logprob": -0.2502462213689631, "compression_ratio": 1.6317689530685922, "no_speech_prob": 1.4738368918187916e-05}, {"id": 77, "seek": 33634, "start": 354.29999999999995, "end": 355.73999999999995, "text": " eventually became", "tokens": [4728, 3062], "temperature": 0.0, "avg_logprob": -0.2502462213689631, "compression_ratio": 1.6317689530685922, "no_speech_prob": 1.4738368918187916e-05}, {"id": 78, "seek": 33634, "start": 355.73999999999995, "end": 357.5, "text": " The president of Kaggle", "tokens": [440, 3868, 295, 48751, 22631], "temperature": 0.0, "avg_logprob": -0.2502462213689631, "compression_ratio": 1.6317689530685922, "no_speech_prob": 1.4738368918187916e-05}, {"id": 79, "seek": 33634, "start": 357.5, "end": 363.38, "text": " But actually the thing I'm probably most proud of in my life is that I got to be the number one ranked contestant in", "tokens": [583, 767, 264, 551, 286, 478, 1391, 881, 4570, 295, 294, 452, 993, 307, 300, 286, 658, 281, 312, 264, 1230, 472, 20197, 10287, 394, 294], "temperature": 0.0, "avg_logprob": -0.2502462213689631, "compression_ratio": 1.6317689530685922, "no_speech_prob": 1.4738368918187916e-05}, {"id": 80, "seek": 36338, "start": 363.38, "end": 368.06, "text": " Kaggle competitions globally. So I think that's a good", "tokens": [48751, 22631, 26185, 18958, 13, 407, 286, 519, 300, 311, 257, 665], "temperature": 0.0, "avg_logprob": -0.24761243613369494, "compression_ratio": 1.5203252032520325, "no_speech_prob": 1.260653789358912e-05}, {"id": 81, "seek": 36338, "start": 369.94, "end": 376.02, "text": " Practical like can you actually train a predictive model that predicts things pretty important aspect of data science", "tokens": [19170, 804, 411, 393, 291, 767, 3847, 257, 35521, 2316, 300, 6069, 82, 721, 1238, 1021, 4171, 295, 1412, 3497], "temperature": 0.0, "avg_logprob": -0.24761243613369494, "compression_ratio": 1.5203252032520325, "no_speech_prob": 1.260653789358912e-05}, {"id": 82, "seek": 36338, "start": 376.02, "end": 382.42, "text": " I then founded a company called in litic, which was the first kind of medical deep learning company", "tokens": [286, 550, 13234, 257, 2237, 1219, 294, 7997, 299, 11, 597, 390, 264, 700, 733, 295, 4625, 2452, 2539, 2237], "temperature": 0.0, "avg_logprob": -0.24761243613369494, "compression_ratio": 1.5203252032520325, "no_speech_prob": 1.260653789358912e-05}, {"id": 83, "seek": 36338, "start": 384.21999999999997, "end": 390.5, "text": " Nowadays I'm on the faculty at University of San Francisco and also co-founder with Rachel of fast AI", "tokens": [28908, 286, 478, 322, 264, 6389, 412, 3535, 295, 5271, 12279, 293, 611, 598, 12, 33348, 365, 14246, 295, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.24761243613369494, "compression_ratio": 1.5203252032520325, "no_speech_prob": 1.260653789358912e-05}, {"id": 84, "seek": 39050, "start": 390.5, "end": 393.7, "text": " So I've used", "tokens": [407, 286, 600, 1143], "temperature": 0.0, "avg_logprob": -0.2085580181431126, "compression_ratio": 1.6476683937823835, "no_speech_prob": 9.972660336643457e-06}, {"id": 85, "seek": 39050, "start": 394.7, "end": 400.3, "text": " Machine learning throughout that time and I guess I'm not really although I am at USS at a university", "tokens": [22155, 2539, 3710, 300, 565, 293, 286, 2041, 286, 478, 406, 534, 4878, 286, 669, 412, 30385, 412, 257, 5454], "temperature": 0.0, "avg_logprob": -0.2085580181431126, "compression_ratio": 1.6476683937823835, "no_speech_prob": 9.972660336643457e-06}, {"id": 86, "seek": 39050, "start": 400.3, "end": 406.82, "text": " I'm not really an academic type. I'm much more interested in in using this tool to do useful things", "tokens": [286, 478, 406, 534, 364, 7778, 2010, 13, 286, 478, 709, 544, 3102, 294, 294, 1228, 341, 2290, 281, 360, 4420, 721], "temperature": 0.0, "avg_logprob": -0.2085580181431126, "compression_ratio": 1.6476683937823835, "no_speech_prob": 9.972660336643457e-06}, {"id": 87, "seek": 39050, "start": 408.42, "end": 414.86, "text": " Specifically through fast AI we are trying to help people use deep learning to do useful things through", "tokens": [26058, 807, 2370, 7318, 321, 366, 1382, 281, 854, 561, 764, 2452, 2539, 281, 360, 4420, 721, 807], "temperature": 0.0, "avg_logprob": -0.2085580181431126, "compression_ratio": 1.6476683937823835, "no_speech_prob": 9.972660336643457e-06}, {"id": 88, "seek": 41486, "start": 414.86, "end": 420.22, "text": " I'm creating software to make deep learning easier to use at a very high level", "tokens": [286, 478, 4084, 4722, 281, 652, 2452, 2539, 3571, 281, 764, 412, 257, 588, 1090, 1496], "temperature": 0.0, "avg_logprob": -0.1403742858341762, "compression_ratio": 1.920152091254753, "no_speech_prob": 9.080376003112178e-06}, {"id": 89, "seek": 41486, "start": 420.78000000000003, "end": 423.42, "text": " Through education such as the thing you're watching now", "tokens": [8927, 3309, 1270, 382, 264, 551, 291, 434, 1976, 586], "temperature": 0.0, "avg_logprob": -0.1403742858341762, "compression_ratio": 1.920152091254753, "no_speech_prob": 9.080376003112178e-06}, {"id": 90, "seek": 41486, "start": 423.98, "end": 429.06, "text": " Through research which is where we spend a very large amount of our time which is researching to figure out", "tokens": [8927, 2132, 597, 307, 689, 321, 3496, 257, 588, 2416, 2372, 295, 527, 565, 597, 307, 24176, 281, 2573, 484], "temperature": 0.0, "avg_logprob": -0.1403742858341762, "compression_ratio": 1.920152091254753, "no_speech_prob": 9.080376003112178e-06}, {"id": 91, "seek": 41486, "start": 429.34000000000003, "end": 433.06, "text": " How can you make deep learning easier to use at a very high level?", "tokens": [1012, 393, 291, 652, 2452, 2539, 3571, 281, 764, 412, 257, 588, 1090, 1496, 30], "temperature": 0.0, "avg_logprob": -0.1403742858341762, "compression_ratio": 1.920152091254753, "no_speech_prob": 9.080376003112178e-06}, {"id": 92, "seek": 41486, "start": 433.06, "end": 438.1, "text": " Which ends up in as you'll see in the software and the education and by helping to build a community", "tokens": [3013, 5314, 493, 294, 382, 291, 603, 536, 294, 264, 4722, 293, 264, 3309, 293, 538, 4315, 281, 1322, 257, 1768], "temperature": 0.0, "avg_logprob": -0.1403742858341762, "compression_ratio": 1.920152091254753, "no_speech_prob": 9.080376003112178e-06}, {"id": 93, "seek": 41486, "start": 438.26, "end": 443.34000000000003, "text": " Which is mainly through the forums so that practitioners can find each other and work together", "tokens": [3013, 307, 8704, 807, 264, 26998, 370, 300, 25742, 393, 915, 1184, 661, 293, 589, 1214], "temperature": 0.0, "avg_logprob": -0.1403742858341762, "compression_ratio": 1.920152091254753, "no_speech_prob": 9.080376003112178e-06}, {"id": 94, "seek": 44334, "start": 443.34, "end": 445.34, "text": " So that's what we're doing", "tokens": [407, 300, 311, 437, 321, 434, 884], "temperature": 0.0, "avg_logprob": -0.17108140672956193, "compression_ratio": 1.6431226765799256, "no_speech_prob": 1.723113382468e-05}, {"id": 95, "seek": 44334, "start": 446.5, "end": 451.21999999999997, "text": " So this lesson practical deep learning for coders is kind of the starting point in this journey", "tokens": [407, 341, 6898, 8496, 2452, 2539, 337, 17656, 433, 307, 733, 295, 264, 2891, 935, 294, 341, 4671], "temperature": 0.0, "avg_logprob": -0.17108140672956193, "compression_ratio": 1.6431226765799256, "no_speech_prob": 1.723113382468e-05}, {"id": 96, "seek": 44334, "start": 451.65999999999997, "end": 455.17999999999995, "text": " It contains seven lessons each one's about two hours long", "tokens": [467, 8306, 3407, 8820, 1184, 472, 311, 466, 732, 2496, 938], "temperature": 0.0, "avg_logprob": -0.17108140672956193, "compression_ratio": 1.6431226765799256, "no_speech_prob": 1.723113382468e-05}, {"id": 97, "seek": 44334, "start": 455.62, "end": 459.55999999999995, "text": " We're then expecting you to do about eight to ten hours of homework during the week", "tokens": [492, 434, 550, 9650, 291, 281, 360, 466, 3180, 281, 2064, 2496, 295, 14578, 1830, 264, 1243], "temperature": 0.0, "avg_logprob": -0.17108140672956193, "compression_ratio": 1.6431226765799256, "no_speech_prob": 1.723113382468e-05}, {"id": 98, "seek": 44334, "start": 459.82, "end": 463.88, "text": " So it'll end up being something around 70 or 80 hours of work", "tokens": [407, 309, 603, 917, 493, 885, 746, 926, 5285, 420, 4688, 2496, 295, 589], "temperature": 0.0, "avg_logprob": -0.17108140672956193, "compression_ratio": 1.6431226765799256, "no_speech_prob": 1.723113382468e-05}, {"id": 99, "seek": 44334, "start": 464.34, "end": 468.03999999999996, "text": " I will say it varies a lot as to how much people put into this", "tokens": [286, 486, 584, 309, 21716, 257, 688, 382, 281, 577, 709, 561, 829, 666, 341], "temperature": 0.0, "avg_logprob": -0.17108140672956193, "compression_ratio": 1.6431226765799256, "no_speech_prob": 1.723113382468e-05}, {"id": 100, "seek": 44334, "start": 468.03999999999996, "end": 472.17999999999995, "text": " I know a lot of people who work full-time on fast AI", "tokens": [286, 458, 257, 688, 295, 561, 567, 589, 1577, 12, 3766, 322, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.17108140672956193, "compression_ratio": 1.6431226765799256, "no_speech_prob": 1.723113382468e-05}, {"id": 101, "seek": 47218, "start": 472.18, "end": 473.3, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.17017813595858486, "compression_ratio": 1.6818181818181819, "no_speech_prob": 1.2411333955242299e-05}, {"id": 102, "seek": 47218, "start": 473.3, "end": 478.1, "text": " Some folks who's do the two parts can spend a whole year doing it really intensively", "tokens": [2188, 4024, 567, 311, 360, 264, 732, 3166, 393, 3496, 257, 1379, 1064, 884, 309, 534, 18957, 356], "temperature": 0.0, "avg_logprob": -0.17017813595858486, "compression_ratio": 1.6818181818181819, "no_speech_prob": 1.2411333955242299e-05}, {"id": 103, "seek": 47218, "start": 478.1, "end": 484.5, "text": " I know some folks watch the videos on double speed and never do any homework and come at the end of it with you know", "tokens": [286, 458, 512, 4024, 1159, 264, 2145, 322, 3834, 3073, 293, 1128, 360, 604, 14578, 293, 808, 412, 264, 917, 295, 309, 365, 291, 458], "temperature": 0.0, "avg_logprob": -0.17017813595858486, "compression_ratio": 1.6818181818181819, "no_speech_prob": 1.2411333955242299e-05}, {"id": 104, "seek": 47218, "start": 484.5, "end": 487.62, "text": " A general sense of what's going on. So there's lots of different ways you can do this", "tokens": [316, 2674, 2020, 295, 437, 311, 516, 322, 13, 407, 456, 311, 3195, 295, 819, 2098, 291, 393, 360, 341], "temperature": 0.0, "avg_logprob": -0.17017813595858486, "compression_ratio": 1.6818181818181819, "no_speech_prob": 1.2411333955242299e-05}, {"id": 105, "seek": 47218, "start": 487.62, "end": 489.9, "text": " but if you follow along with this kind of", "tokens": [457, 498, 291, 1524, 2051, 365, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.17017813595858486, "compression_ratio": 1.6818181818181819, "no_speech_prob": 1.2411333955242299e-05}, {"id": 106, "seek": 47218, "start": 490.46000000000004, "end": 496.14, "text": " Ten hours a week or so approach for the seven weeks by the end you will be able to build an image classification", "tokens": [9380, 2496, 257, 1243, 420, 370, 3109, 337, 264, 3407, 3259, 538, 264, 917, 291, 486, 312, 1075, 281, 1322, 364, 3256, 21538], "temperature": 0.0, "avg_logprob": -0.17017813595858486, "compression_ratio": 1.6818181818181819, "no_speech_prob": 1.2411333955242299e-05}, {"id": 107, "seek": 49614, "start": 496.14, "end": 501.65999999999997, "text": " Model on pictures that you choose that will work at a world-class level", "tokens": [17105, 322, 5242, 300, 291, 2826, 300, 486, 589, 412, 257, 1002, 12, 11665, 1496], "temperature": 0.0, "avg_logprob": -0.17031025332073832, "compression_ratio": 1.646551724137931, "no_speech_prob": 7.889119842729997e-06}, {"id": 108, "seek": 49614, "start": 502.18, "end": 508.09999999999997, "text": " You'll be able to classify text again using whatever data sets you're interested in", "tokens": [509, 603, 312, 1075, 281, 33872, 2487, 797, 1228, 2035, 1412, 6352, 291, 434, 3102, 294], "temperature": 0.0, "avg_logprob": -0.17031025332073832, "compression_ratio": 1.646551724137931, "no_speech_prob": 7.889119842729997e-06}, {"id": 109, "seek": 49614, "start": 508.3, "end": 513.38, "text": " You'll be able to make predictions of kind of commercial applications like sales", "tokens": [509, 603, 312, 1075, 281, 652, 21264, 295, 733, 295, 6841, 5821, 411, 5763], "temperature": 0.0, "avg_logprob": -0.17031025332073832, "compression_ratio": 1.646551724137931, "no_speech_prob": 7.889119842729997e-06}, {"id": 110, "seek": 49614, "start": 513.9, "end": 518.04, "text": " You'll be able to build recommendation systems. That's just the one used by Netflix", "tokens": [509, 603, 312, 1075, 281, 1322, 11879, 3652, 13, 663, 311, 445, 264, 472, 1143, 538, 12778], "temperature": 0.0, "avg_logprob": -0.17031025332073832, "compression_ratio": 1.646551724137931, "no_speech_prob": 7.889119842729997e-06}, {"id": 111, "seek": 49614, "start": 518.66, "end": 522.38, "text": " Not toy examples of any of these but actually things that can", "tokens": [1726, 12058, 5110, 295, 604, 295, 613, 457, 767, 721, 300, 393], "temperature": 0.0, "avg_logprob": -0.17031025332073832, "compression_ratio": 1.646551724137931, "no_speech_prob": 7.889119842729997e-06}, {"id": 112, "seek": 52238, "start": 522.38, "end": 527.5, "text": " Come top 10 and Kaggle competitions that come beat everything that's in the academic community", "tokens": [2492, 1192, 1266, 293, 48751, 22631, 26185, 300, 808, 4224, 1203, 300, 311, 294, 264, 7778, 1768], "temperature": 0.0, "avg_logprob": -0.22524066547771077, "compression_ratio": 1.5772357723577235, "no_speech_prob": 8.2677597674774e-06}, {"id": 113, "seek": 52238, "start": 528.3, "end": 534.4, "text": " Very very high-level versions of these things. So that might surprise you that's not you know, the prerequisite here is", "tokens": [4372, 588, 1090, 12, 12418, 9606, 295, 613, 721, 13, 407, 300, 1062, 6365, 291, 300, 311, 406, 291, 458, 11, 264, 38333, 34152, 510, 307], "temperature": 0.0, "avg_logprob": -0.22524066547771077, "compression_ratio": 1.5772357723577235, "no_speech_prob": 8.2677597674774e-06}, {"id": 114, "seek": 52238, "start": 536.26, "end": 543.98, "text": " Literally one year of coding and high school math, but we have thousands of students now who have done this and shown it to be true", "tokens": [23768, 472, 1064, 295, 17720, 293, 1090, 1395, 5221, 11, 457, 321, 362, 5383, 295, 1731, 586, 567, 362, 1096, 341, 293, 4898, 309, 281, 312, 2074], "temperature": 0.0, "avg_logprob": -0.22524066547771077, "compression_ratio": 1.5772357723577235, "no_speech_prob": 8.2677597674774e-06}, {"id": 115, "seek": 52238, "start": 545.98, "end": 549.04, "text": " You will probably hear a lot of naysayers", "tokens": [509, 486, 1391, 1568, 257, 688, 295, 297, 3772, 320, 433], "temperature": 0.0, "avg_logprob": -0.22524066547771077, "compression_ratio": 1.5772357723577235, "no_speech_prob": 8.2677597674774e-06}, {"id": 116, "seek": 54904, "start": 549.04, "end": 554.4599999999999, "text": " Less now than a couple of years ago than we started but a lot of naysayers telling you that you can't do it", "tokens": [18649, 586, 813, 257, 1916, 295, 924, 2057, 813, 321, 1409, 457, 257, 688, 295, 297, 3772, 320, 433, 3585, 291, 300, 291, 393, 380, 360, 309], "temperature": 0.0, "avg_logprob": -0.20139557707543468, "compression_ratio": 1.7316017316017316, "no_speech_prob": 9.818167200137395e-06}, {"id": 117, "seek": 54904, "start": 554.8, "end": 558.78, "text": " Or that you shouldn't be doing it or the deep learnings got all these problems", "tokens": [1610, 300, 291, 4659, 380, 312, 884, 309, 420, 264, 2452, 2539, 82, 658, 439, 613, 2740], "temperature": 0.0, "avg_logprob": -0.20139557707543468, "compression_ratio": 1.7316017316017316, "no_speech_prob": 9.818167200137395e-06}, {"id": 118, "seek": 54904, "start": 559.04, "end": 562.9, "text": " It's not perfect. But these are all things that people claim about", "tokens": [467, 311, 406, 2176, 13, 583, 613, 366, 439, 721, 300, 561, 3932, 466], "temperature": 0.0, "avg_logprob": -0.20139557707543468, "compression_ratio": 1.7316017316017316, "no_speech_prob": 9.818167200137395e-06}, {"id": 119, "seek": 54904, "start": 563.5999999999999, "end": 565.7199999999999, "text": " deep learning which are either", "tokens": [2452, 2539, 597, 366, 2139], "temperature": 0.0, "avg_logprob": -0.20139557707543468, "compression_ratio": 1.7316017316017316, "no_speech_prob": 9.818167200137395e-06}, {"id": 120, "seek": 54904, "start": 566.4, "end": 568.3199999999999, "text": " pointless or untrue", "tokens": [32824, 420, 1701, 41729], "temperature": 0.0, "avg_logprob": -0.20139557707543468, "compression_ratio": 1.7316017316017316, "no_speech_prob": 9.818167200137395e-06}, {"id": 121, "seek": 54904, "start": 568.3199999999999, "end": 574.06, "text": " It's not a black box as you'll see it's really great for interpret interpreting what's going on", "tokens": [467, 311, 406, 257, 2211, 2424, 382, 291, 603, 536, 309, 311, 534, 869, 337, 7302, 37395, 437, 311, 516, 322], "temperature": 0.0, "avg_logprob": -0.20139557707543468, "compression_ratio": 1.7316017316017316, "no_speech_prob": 9.818167200137395e-06}, {"id": 122, "seek": 57406, "start": 574.06, "end": 579.9799999999999, "text": " It does not need much data for most practical applications. You certainly don't need a PhD", "tokens": [467, 775, 406, 643, 709, 1412, 337, 881, 8496, 5821, 13, 509, 3297, 500, 380, 643, 257, 14476], "temperature": 0.0, "avg_logprob": -0.15853759698700487, "compression_ratio": 1.70446735395189, "no_speech_prob": 1.0451347407069989e-05}, {"id": 123, "seek": 57406, "start": 580.7399999999999, "end": 584.4599999999999, "text": " Rachel has one so it doesn't actually stop you from doing deep learning if you have a PhD", "tokens": [14246, 575, 472, 370, 309, 1177, 380, 767, 1590, 291, 490, 884, 2452, 2539, 498, 291, 362, 257, 14476], "temperature": 0.0, "avg_logprob": -0.15853759698700487, "compression_ratio": 1.70446735395189, "no_speech_prob": 1.0451347407069989e-05}, {"id": 124, "seek": 57406, "start": 584.4599999999999, "end": 587.8199999999999, "text": " I certainly don't I have a philosophy degree and nothing else", "tokens": [286, 3297, 500, 380, 286, 362, 257, 10675, 4314, 293, 1825, 1646], "temperature": 0.0, "avg_logprob": -0.15853759698700487, "compression_ratio": 1.70446735395189, "no_speech_prob": 1.0451347407069989e-05}, {"id": 125, "seek": 57406, "start": 589.3, "end": 595.3599999999999, "text": " It can be used very widely for lots of different applications not just for vision, which is where it's most well known", "tokens": [467, 393, 312, 1143, 588, 13371, 337, 3195, 295, 819, 5821, 406, 445, 337, 5201, 11, 597, 307, 689, 309, 311, 881, 731, 2570], "temperature": 0.0, "avg_logprob": -0.15853759698700487, "compression_ratio": 1.70446735395189, "no_speech_prob": 1.0451347407069989e-05}, {"id": 126, "seek": 57406, "start": 595.78, "end": 597.66, "text": " You don't need lots of hardware", "tokens": [509, 500, 380, 643, 3195, 295, 8837], "temperature": 0.0, "avg_logprob": -0.15853759698700487, "compression_ratio": 1.70446735395189, "no_speech_prob": 1.0451347407069989e-05}, {"id": 127, "seek": 59766, "start": 597.66, "end": 604.42, "text": " You know that 36 cent an hour server is more than enough to get world-class results for most problems", "tokens": [509, 458, 300, 8652, 1489, 364, 1773, 7154, 307, 544, 813, 1547, 281, 483, 1002, 12, 11665, 3542, 337, 881, 2740], "temperature": 0.0, "avg_logprob": -0.17396926879882812, "compression_ratio": 1.675, "no_speech_prob": 3.288680318291881e-06}, {"id": 128, "seek": 59766, "start": 605.54, "end": 612.18, "text": " It's true that maybe this is not going to help you to build a sentient brain, but that's not our focus. Okay, so", "tokens": [467, 311, 2074, 300, 1310, 341, 307, 406, 516, 281, 854, 291, 281, 1322, 257, 2279, 1196, 3567, 11, 457, 300, 311, 406, 527, 1879, 13, 1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.17396926879882812, "compression_ratio": 1.675, "no_speech_prob": 3.288680318291881e-06}, {"id": 129, "seek": 59766, "start": 613.1, "end": 616.62, "text": " For all the people who say deep learning is not interesting because it's not really AI", "tokens": [1171, 439, 264, 561, 567, 584, 2452, 2539, 307, 406, 1880, 570, 309, 311, 406, 534, 7318], "temperature": 0.0, "avg_logprob": -0.17396926879882812, "compression_ratio": 1.675, "no_speech_prob": 3.288680318291881e-06}, {"id": 130, "seek": 59766, "start": 617.5799999999999, "end": 621.06, "text": " Not really a conversation that I'm interested in we're focused on solving", "tokens": [1726, 534, 257, 3761, 300, 286, 478, 3102, 294, 321, 434, 5178, 322, 12606], "temperature": 0.0, "avg_logprob": -0.17396926879882812, "compression_ratio": 1.675, "no_speech_prob": 3.288680318291881e-06}, {"id": 131, "seek": 59766, "start": 621.98, "end": 623.98, "text": " interesting real-world problems", "tokens": [1880, 957, 12, 13217, 2740], "temperature": 0.0, "avg_logprob": -0.17396926879882812, "compression_ratio": 1.675, "no_speech_prob": 3.288680318291881e-06}, {"id": 132, "seek": 59766, "start": 624.6999999999999, "end": 626.88, "text": " What are you going to be able to do by the end of lesson one?", "tokens": [708, 366, 291, 516, 281, 312, 1075, 281, 360, 538, 264, 917, 295, 6898, 472, 30], "temperature": 0.0, "avg_logprob": -0.17396926879882812, "compression_ratio": 1.675, "no_speech_prob": 3.288680318291881e-06}, {"id": 133, "seek": 62688, "start": 626.88, "end": 632.48, "text": " Well, this was an example from Nick you're who's actually in the audience now because he was in last year's course as well", "tokens": [1042, 11, 341, 390, 364, 1365, 490, 9449, 291, 434, 567, 311, 767, 294, 264, 4034, 586, 570, 415, 390, 294, 1036, 1064, 311, 1164, 382, 731], "temperature": 0.0, "avg_logprob": -0.23452032885505159, "compression_ratio": 1.7007874015748032, "no_speech_prob": 1.8342507246416062e-05}, {"id": 134, "seek": 62688, "start": 633.92, "end": 641.26, "text": " This is an example of something he did which is he downloaded 30 images of people playing cricket and people playing baseball and", "tokens": [639, 307, 364, 1365, 295, 746, 415, 630, 597, 307, 415, 21748, 2217, 5267, 295, 561, 2433, 31626, 293, 561, 2433, 14323, 293], "temperature": 0.0, "avg_logprob": -0.23452032885505159, "compression_ratio": 1.7007874015748032, "no_speech_prob": 1.8342507246416062e-05}, {"id": 135, "seek": 62688, "start": 641.68, "end": 644.24, "text": " ran the code you'll see today and built a", "tokens": [5872, 264, 3089, 291, 603, 536, 965, 293, 3094, 257], "temperature": 0.0, "avg_logprob": -0.23452032885505159, "compression_ratio": 1.7007874015748032, "no_speech_prob": 1.8342507246416062e-05}, {"id": 136, "seek": 62688, "start": 644.88, "end": 646.88, "text": " nearly perfect classifier of", "tokens": [6217, 2176, 1508, 9902, 295], "temperature": 0.0, "avg_logprob": -0.23452032885505159, "compression_ratio": 1.7007874015748032, "no_speech_prob": 1.8342507246416062e-05}, {"id": 137, "seek": 62688, "start": 646.92, "end": 648.24, "text": " Which is which?", "tokens": [3013, 307, 597, 30], "temperature": 0.0, "avg_logprob": -0.23452032885505159, "compression_ratio": 1.7007874015748032, "no_speech_prob": 1.8342507246416062e-05}, {"id": 138, "seek": 62688, "start": 648.24, "end": 652.8, "text": " So this kind of it's kind of stuff that you can build with some fun hobby examples like this", "tokens": [407, 341, 733, 295, 309, 311, 733, 295, 1507, 300, 291, 393, 1322, 365, 512, 1019, 18240, 5110, 411, 341], "temperature": 0.0, "avg_logprob": -0.23452032885505159, "compression_ratio": 1.7007874015748032, "no_speech_prob": 1.8342507246416062e-05}, {"id": 139, "seek": 65280, "start": 652.8, "end": 657.9599999999999, "text": " Or you can try stuff as we'll see in the workplace that could be of direct commercial value", "tokens": [1610, 291, 393, 853, 1507, 382, 321, 603, 536, 294, 264, 15328, 300, 727, 312, 295, 2047, 6841, 2158], "temperature": 0.0, "avg_logprob": -0.15361282711937313, "compression_ratio": 1.746031746031746, "no_speech_prob": 6.540360573126236e-06}, {"id": 140, "seek": 65280, "start": 658.5999999999999, "end": 661.3599999999999, "text": " So this is the idea of where we're going to get to by the end of lesson one", "tokens": [407, 341, 307, 264, 1558, 295, 689, 321, 434, 516, 281, 483, 281, 538, 264, 917, 295, 6898, 472], "temperature": 0.0, "avg_logprob": -0.15361282711937313, "compression_ratio": 1.746031746031746, "no_speech_prob": 6.540360573126236e-06}, {"id": 141, "seek": 65280, "start": 662.92, "end": 666.38, "text": " We're going to start by looking at code", "tokens": [492, 434, 516, 281, 722, 538, 1237, 412, 3089], "temperature": 0.0, "avg_logprob": -0.15361282711937313, "compression_ratio": 1.746031746031746, "no_speech_prob": 6.540360573126236e-06}, {"id": 142, "seek": 65280, "start": 667.24, "end": 669.24, "text": " which is very different to", "tokens": [597, 307, 588, 819, 281], "temperature": 0.0, "avg_logprob": -0.15361282711937313, "compression_ratio": 1.746031746031746, "no_speech_prob": 6.540360573126236e-06}, {"id": 143, "seek": 65280, "start": 670.0799999999999, "end": 675.8399999999999, "text": " Many of the academic courses so for those of you who have a kind of an engineering or math or computer science background", "tokens": [5126, 295, 264, 7778, 7712, 370, 337, 729, 295, 291, 567, 362, 257, 733, 295, 364, 7043, 420, 5221, 420, 3820, 3497, 3678], "temperature": 0.0, "avg_logprob": -0.15361282711937313, "compression_ratio": 1.746031746031746, "no_speech_prob": 6.540360573126236e-06}, {"id": 144, "seek": 65280, "start": 675.8399999999999, "end": 679.5999999999999, "text": " This is very different to the approach where you start with lots and lots of theory", "tokens": [639, 307, 588, 819, 281, 264, 3109, 689, 291, 722, 365, 3195, 293, 3195, 295, 5261], "temperature": 0.0, "avg_logprob": -0.15361282711937313, "compression_ratio": 1.746031746031746, "no_speech_prob": 6.540360573126236e-06}, {"id": 145, "seek": 67960, "start": 679.6, "end": 684.48, "text": " And then eventually you get to a postgraduate degree and you finally are at the point where you can build something useful", "tokens": [400, 550, 4728, 291, 483, 281, 257, 2183, 47187, 4314, 293, 291, 2721, 366, 412, 264, 935, 689, 291, 393, 1322, 746, 4420], "temperature": 0.0, "avg_logprob": -0.12776823512843397, "compression_ratio": 1.7870036101083033, "no_speech_prob": 3.0894696010363987e-06}, {"id": 146, "seek": 67960, "start": 684.98, "end": 686.98, "text": " We're going to learn to build the useful thing today", "tokens": [492, 434, 516, 281, 1466, 281, 1322, 264, 4420, 551, 965], "temperature": 0.0, "avg_logprob": -0.12776823512843397, "compression_ratio": 1.7870036101083033, "no_speech_prob": 3.0894696010363987e-06}, {"id": 147, "seek": 67960, "start": 687.76, "end": 689.76, "text": " Now that means that at the end of today", "tokens": [823, 300, 1355, 300, 412, 264, 917, 295, 965], "temperature": 0.0, "avg_logprob": -0.12776823512843397, "compression_ratio": 1.7870036101083033, "no_speech_prob": 3.0894696010363987e-06}, {"id": 148, "seek": 67960, "start": 690.08, "end": 691.9200000000001, "text": " You won't know all the theory", "tokens": [509, 1582, 380, 458, 439, 264, 5261], "temperature": 0.0, "avg_logprob": -0.12776823512843397, "compression_ratio": 1.7870036101083033, "no_speech_prob": 3.0894696010363987e-06}, {"id": 149, "seek": 67960, "start": 691.9200000000001, "end": 697.9, "text": " Okay, there will be lots of aspects of what we do that you don't know why or how it works. That's okay", "tokens": [1033, 11, 456, 486, 312, 3195, 295, 7270, 295, 437, 321, 360, 300, 291, 500, 380, 458, 983, 420, 577, 309, 1985, 13, 663, 311, 1392], "temperature": 0.0, "avg_logprob": -0.12776823512843397, "compression_ratio": 1.7870036101083033, "no_speech_prob": 3.0894696010363987e-06}, {"id": 150, "seek": 67960, "start": 698.2, "end": 702.5400000000001, "text": " You will learn why and how it works over the next seven weeks", "tokens": [509, 486, 1466, 983, 293, 577, 309, 1985, 670, 264, 958, 3407, 3259], "temperature": 0.0, "avg_logprob": -0.12776823512843397, "compression_ratio": 1.7870036101083033, "no_speech_prob": 3.0894696010363987e-06}, {"id": 151, "seek": 67960, "start": 703.44, "end": 708.72, "text": " But for now we found that what works really well is to actually get your hands dirty", "tokens": [583, 337, 586, 321, 1352, 300, 437, 1985, 534, 731, 307, 281, 767, 483, 428, 2377, 9360], "temperature": 0.0, "avg_logprob": -0.12776823512843397, "compression_ratio": 1.7870036101083033, "no_speech_prob": 3.0894696010363987e-06}, {"id": 152, "seek": 70872, "start": 708.72, "end": 710.48, "text": " coding", "tokens": [17720], "temperature": 0.0, "avg_logprob": -0.21692657470703125, "compression_ratio": 1.7304347826086957, "no_speech_prob": 1.1125410310341977e-05}, {"id": 153, "seek": 70872, "start": 710.48, "end": 713.0400000000001, "text": " not focusing on theory because", "tokens": [406, 8416, 322, 5261, 570], "temperature": 0.0, "avg_logprob": -0.21692657470703125, "compression_ratio": 1.7304347826086957, "no_speech_prob": 1.1125410310341977e-05}, {"id": 154, "seek": 70872, "start": 713.64, "end": 715.64, "text": " There's still a lot of", "tokens": [821, 311, 920, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.21692657470703125, "compression_ratio": 1.7304347826086957, "no_speech_prob": 1.1125410310341977e-05}, {"id": 155, "seek": 70872, "start": 716.0, "end": 722.12, "text": " Artisanship in deep learning. Unfortunately, it's still a situation where people who are good practitioners", "tokens": [5735, 271, 27140, 294, 2452, 2539, 13, 8590, 11, 309, 311, 920, 257, 2590, 689, 561, 567, 366, 665, 25742], "temperature": 0.0, "avg_logprob": -0.21692657470703125, "compression_ratio": 1.7304347826086957, "no_speech_prob": 1.1125410310341977e-05}, {"id": 156, "seek": 70872, "start": 722.5600000000001, "end": 729.4200000000001, "text": " Have a really good feel for how to work with the code and how to work with the data and you can only get that through", "tokens": [3560, 257, 534, 665, 841, 337, 577, 281, 589, 365, 264, 3089, 293, 577, 281, 589, 365, 264, 1412, 293, 291, 393, 787, 483, 300, 807], "temperature": 0.0, "avg_logprob": -0.21692657470703125, "compression_ratio": 1.7304347826086957, "no_speech_prob": 1.1125410310341977e-05}, {"id": 157, "seek": 70872, "start": 729.4200000000001, "end": 730.64, "text": " experience and", "tokens": [1752, 293], "temperature": 0.0, "avg_logprob": -0.21692657470703125, "compression_ratio": 1.7304347826086957, "no_speech_prob": 1.1125410310341977e-05}, {"id": 158, "seek": 70872, "start": 730.64, "end": 736.44, "text": " So the best way to get that that that feel of how to get good models is to create lots of models", "tokens": [407, 264, 1151, 636, 281, 483, 300, 300, 300, 841, 295, 577, 281, 483, 665, 5245, 307, 281, 1884, 3195, 295, 5245], "temperature": 0.0, "avg_logprob": -0.21692657470703125, "compression_ratio": 1.7304347826086957, "no_speech_prob": 1.1125410310341977e-05}, {"id": 159, "seek": 73644, "start": 736.44, "end": 738.44, "text": " through lots of coding and", "tokens": [807, 3195, 295, 17720, 293], "temperature": 0.0, "avg_logprob": -0.20711334983071128, "compression_ratio": 1.7114427860696517, "no_speech_prob": 5.955084816378076e-06}, {"id": 160, "seek": 73644, "start": 738.8000000000001, "end": 744.48, "text": " Study them carefully and it's a jupyter notebook provides a really great way to study them. So", "tokens": [27039, 552, 7500, 293, 309, 311, 257, 361, 1010, 88, 391, 21060, 6417, 257, 534, 869, 636, 281, 2979, 552, 13, 407], "temperature": 0.0, "avg_logprob": -0.20711334983071128, "compression_ratio": 1.7114427860696517, "no_speech_prob": 5.955084816378076e-06}, {"id": 161, "seek": 73644, "start": 745.8000000000001, "end": 753.12, "text": " Let's try that. Let's try getting started. So to get started you will open your jupyter notebook and", "tokens": [961, 311, 853, 300, 13, 961, 311, 853, 1242, 1409, 13, 407, 281, 483, 1409, 291, 486, 1269, 428, 361, 1010, 88, 391, 21060, 293], "temperature": 0.0, "avg_logprob": -0.20711334983071128, "compression_ratio": 1.7114427860696517, "no_speech_prob": 5.955084816378076e-06}, {"id": 162, "seek": 73644, "start": 754.48, "end": 761.1400000000001, "text": " You'll click on lesson one lesson one pets and it will pop open looking something like this", "tokens": [509, 603, 2052, 322, 6898, 472, 6898, 472, 19897, 293, 309, 486, 1665, 1269, 1237, 746, 411, 341], "temperature": 0.0, "avg_logprob": -0.20711334983071128, "compression_ratio": 1.7114427860696517, "no_speech_prob": 5.955084816378076e-06}, {"id": 163, "seek": 73644, "start": 761.1400000000001, "end": 763.7600000000001, "text": " And so here it is. So you can", "tokens": [400, 370, 510, 309, 307, 13, 407, 291, 393], "temperature": 0.0, "avg_logprob": -0.20711334983071128, "compression_ratio": 1.7114427860696517, "no_speech_prob": 5.955084816378076e-06}, {"id": 164, "seek": 76376, "start": 763.76, "end": 765.26, "text": " run", "tokens": [1190], "temperature": 0.0, "avg_logprob": -0.22900916979863092, "compression_ratio": 1.8917748917748918, "no_speech_prob": 1.723129207675811e-05}, {"id": 165, "seek": 76376, "start": 765.26, "end": 768.72, "text": " a cell in a jupyter notebook by clicking on it and", "tokens": [257, 2815, 294, 257, 361, 1010, 88, 391, 21060, 538, 9697, 322, 309, 293], "temperature": 0.0, "avg_logprob": -0.22900916979863092, "compression_ratio": 1.8917748917748918, "no_speech_prob": 1.723129207675811e-05}, {"id": 166, "seek": 76376, "start": 769.52, "end": 770.96, "text": " pressing run", "tokens": [12417, 1190], "temperature": 0.0, "avg_logprob": -0.22900916979863092, "compression_ratio": 1.8917748917748918, "no_speech_prob": 1.723129207675811e-05}, {"id": 167, "seek": 76376, "start": 770.96, "end": 777.22, "text": " But if you do so everybody will know that you're not a real deep learning practitioner because real deep learning practitioners know the keyboard shortcuts", "tokens": [583, 498, 291, 360, 370, 2201, 486, 458, 300, 291, 434, 406, 257, 957, 2452, 2539, 32125, 570, 957, 2452, 2539, 25742, 458, 264, 10186, 34620], "temperature": 0.0, "avg_logprob": -0.22900916979863092, "compression_ratio": 1.8917748917748918, "no_speech_prob": 1.723129207675811e-05}, {"id": 168, "seek": 76376, "start": 777.22, "end": 782.72, "text": " And the keyboard shortcut is shift enter given how often you have to run a cell", "tokens": [400, 264, 10186, 24822, 307, 5513, 3242, 2212, 577, 2049, 291, 362, 281, 1190, 257, 2815], "temperature": 0.0, "avg_logprob": -0.22900916979863092, "compression_ratio": 1.8917748917748918, "no_speech_prob": 1.723129207675811e-05}, {"id": 169, "seek": 76376, "start": 783.6, "end": 785.0, "text": " Don't be", "tokens": [1468, 380, 312], "temperature": 0.0, "avg_logprob": -0.22900916979863092, "compression_ratio": 1.8917748917748918, "no_speech_prob": 1.723129207675811e-05}, {"id": 170, "seek": 76376, "start": 785.0, "end": 790.22, "text": " Going all the way up here finding it clicking it just shift enter. Okay, so type type type shift enter type type shift enter", "tokens": [10963, 439, 264, 636, 493, 510, 5006, 309, 9697, 309, 445, 5513, 3242, 13, 1033, 11, 370, 2010, 2010, 2010, 5513, 3242, 2010, 2010, 5513, 3242], "temperature": 0.0, "avg_logprob": -0.22900916979863092, "compression_ratio": 1.8917748917748918, "no_speech_prob": 1.723129207675811e-05}, {"id": 171, "seek": 79022, "start": 790.22, "end": 794.94, "text": " Up and down to move around to pick something to run shift enter to run it", "tokens": [5858, 293, 760, 281, 1286, 926, 281, 1888, 746, 281, 1190, 5513, 3242, 281, 1190, 309], "temperature": 0.0, "avg_logprob": -0.12076773733462927, "compression_ratio": 1.749003984063745, "no_speech_prob": 1.051146341524145e-06}, {"id": 172, "seek": 79022, "start": 795.84, "end": 802.64, "text": " So we're going to go through this quickly and then later on we're going to go back over it more carefully", "tokens": [407, 321, 434, 516, 281, 352, 807, 341, 2661, 293, 550, 1780, 322, 321, 434, 516, 281, 352, 646, 670, 309, 544, 7500], "temperature": 0.0, "avg_logprob": -0.12076773733462927, "compression_ratio": 1.749003984063745, "no_speech_prob": 1.051146341524145e-06}, {"id": 173, "seek": 79022, "start": 802.64, "end": 805.08, "text": " So here's the quick version to get a sense of what's going on", "tokens": [407, 510, 311, 264, 1702, 3037, 281, 483, 257, 2020, 295, 437, 311, 516, 322], "temperature": 0.0, "avg_logprob": -0.12076773733462927, "compression_ratio": 1.749003984063745, "no_speech_prob": 1.051146341524145e-06}, {"id": 174, "seek": 79022, "start": 806.2, "end": 812.6800000000001, "text": " So here we are in lesson one and these three lines is what we start every notebook with", "tokens": [407, 510, 321, 366, 294, 6898, 472, 293, 613, 1045, 3876, 307, 437, 321, 722, 633, 21060, 365], "temperature": 0.0, "avg_logprob": -0.12076773733462927, "compression_ratio": 1.749003984063745, "no_speech_prob": 1.051146341524145e-06}, {"id": 175, "seek": 79022, "start": 813.38, "end": 819.0600000000001, "text": " These things starting with percent are special directives to jupyter notebook itself. They're not Python code", "tokens": [1981, 721, 2891, 365, 3043, 366, 2121, 2047, 1539, 281, 361, 1010, 88, 391, 21060, 2564, 13, 814, 434, 406, 15329, 3089], "temperature": 0.0, "avg_logprob": -0.12076773733462927, "compression_ratio": 1.749003984063745, "no_speech_prob": 1.051146341524145e-06}, {"id": 176, "seek": 81906, "start": 819.06, "end": 821.06, "text": " They're called magic's", "tokens": [814, 434, 1219, 5585, 311], "temperature": 0.0, "avg_logprob": -0.19255782146843112, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.029435785923852e-06}, {"id": 177, "seek": 81906, "start": 821.06, "end": 825.04, "text": " Which is kind of a cool name and these three directives the details aren't very important", "tokens": [3013, 307, 733, 295, 257, 1627, 1315, 293, 613, 1045, 2047, 1539, 264, 4365, 3212, 380, 588, 1021], "temperature": 0.0, "avg_logprob": -0.19255782146843112, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.029435785923852e-06}, {"id": 178, "seek": 81906, "start": 825.04, "end": 831.54, "text": " But basically it says hey if somebody changes the underlying library code while I'm running this, please reload it automatically", "tokens": [583, 1936, 309, 1619, 4177, 498, 2618, 2962, 264, 14217, 6405, 3089, 1339, 286, 478, 2614, 341, 11, 1767, 25628, 309, 6772], "temperature": 0.0, "avg_logprob": -0.19255782146843112, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.029435785923852e-06}, {"id": 179, "seek": 81906, "start": 831.78, "end": 836.66, "text": " If somebody asks to plot something then please plot it here in this jupyter notebook", "tokens": [759, 2618, 8962, 281, 7542, 746, 550, 1767, 7542, 309, 510, 294, 341, 361, 1010, 88, 391, 21060], "temperature": 0.0, "avg_logprob": -0.19255782146843112, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.029435785923852e-06}, {"id": 180, "seek": 81906, "start": 836.66, "end": 839.4799999999999, "text": " So just put those three lines at the top of everything", "tokens": [407, 445, 829, 729, 1045, 3876, 412, 264, 1192, 295, 1203], "temperature": 0.0, "avg_logprob": -0.19255782146843112, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.029435785923852e-06}, {"id": 181, "seek": 81906, "start": 840.7399999999999, "end": 845.16, "text": " The next two lines load up the fast AI library", "tokens": [440, 958, 732, 3876, 3677, 493, 264, 2370, 7318, 6405], "temperature": 0.0, "avg_logprob": -0.19255782146843112, "compression_ratio": 1.6589147286821706, "no_speech_prob": 4.029435785923852e-06}, {"id": 182, "seek": 84516, "start": 845.16, "end": 850.56, "text": " What is the fast AI library? So it's a little bit confusing fast AI with no dot", "tokens": [708, 307, 264, 2370, 7318, 6405, 30, 407, 309, 311, 257, 707, 857, 13181, 2370, 7318, 365, 572, 5893], "temperature": 0.0, "avg_logprob": -0.2071162907764165, "compression_ratio": 1.721461187214612, "no_speech_prob": 6.048863724572584e-06}, {"id": 183, "seek": 84516, "start": 850.56, "end": 856.68, "text": " It's the name of our software and then fast dot AI with the dot is the name of our organization", "tokens": [467, 311, 264, 1315, 295, 527, 4722, 293, 550, 2370, 5893, 7318, 365, 264, 5893, 307, 264, 1315, 295, 527, 4475], "temperature": 0.0, "avg_logprob": -0.2071162907764165, "compression_ratio": 1.721461187214612, "no_speech_prob": 6.048863724572584e-06}, {"id": 184, "seek": 84516, "start": 857.36, "end": 859.52, "text": " So if you go to docs dot fast dot AI", "tokens": [407, 498, 291, 352, 281, 45623, 5893, 2370, 5893, 7318], "temperature": 0.0, "avg_logprob": -0.2071162907764165, "compression_ratio": 1.721461187214612, "no_speech_prob": 6.048863724572584e-06}, {"id": 185, "seek": 84516, "start": 860.28, "end": 863.2199999999999, "text": " This is the fast AI library", "tokens": [639, 307, 264, 2370, 7318, 6405], "temperature": 0.0, "avg_logprob": -0.2071162907764165, "compression_ratio": 1.721461187214612, "no_speech_prob": 6.048863724572584e-06}, {"id": 186, "seek": 84516, "start": 863.4, "end": 865.64, "text": " Okay, we'll learn more about it in a moment", "tokens": [1033, 11, 321, 603, 1466, 544, 466, 309, 294, 257, 1623], "temperature": 0.0, "avg_logprob": -0.2071162907764165, "compression_ratio": 1.721461187214612, "no_speech_prob": 6.048863724572584e-06}, {"id": 187, "seek": 84516, "start": 865.64, "end": 870.52, "text": " But for now just realize everything we are going to do is going to be using basically either", "tokens": [583, 337, 586, 445, 4325, 1203, 321, 366, 516, 281, 360, 307, 516, 281, 312, 1228, 1936, 2139], "temperature": 0.0, "avg_logprob": -0.2071162907764165, "compression_ratio": 1.721461187214612, "no_speech_prob": 6.048863724572584e-06}, {"id": 188, "seek": 87052, "start": 870.52, "end": 875.64, "text": " fast AI or the thing that fast AI sits on top of which is", "tokens": [2370, 7318, 420, 264, 551, 300, 2370, 7318, 12696, 322, 1192, 295, 597, 307], "temperature": 0.0, "avg_logprob": -0.2703233512051134, "compression_ratio": 1.625, "no_speech_prob": 1.1125394848932046e-05}, {"id": 189, "seek": 87052, "start": 876.24, "end": 877.68, "text": " pi torch", "tokens": [3895, 27822], "temperature": 0.0, "avg_logprob": -0.2703233512051134, "compression_ratio": 1.625, "no_speech_prob": 1.1125394848932046e-05}, {"id": 190, "seek": 87052, "start": 877.68, "end": 880.1999999999999, "text": " Pi torch is one of the most popular", "tokens": [17741, 27822, 307, 472, 295, 264, 881, 3743], "temperature": 0.0, "avg_logprob": -0.2703233512051134, "compression_ratio": 1.625, "no_speech_prob": 1.1125394848932046e-05}, {"id": 191, "seek": 87052, "start": 880.88, "end": 882.88, "text": " Libraries for deep learning in the world", "tokens": [12006, 4889, 337, 2452, 2539, 294, 264, 1002], "temperature": 0.0, "avg_logprob": -0.2703233512051134, "compression_ratio": 1.625, "no_speech_prob": 1.1125394848932046e-05}, {"id": 192, "seek": 87052, "start": 883.56, "end": 889.8, "text": " It's a bit newer than tensorflow. So in a lot of ways, it's more modern than tensorflow", "tokens": [467, 311, 257, 857, 17628, 813, 40863, 10565, 13, 407, 294, 257, 688, 295, 2098, 11, 309, 311, 544, 4363, 813, 40863, 10565], "temperature": 0.0, "avg_logprob": -0.2703233512051134, "compression_ratio": 1.625, "no_speech_prob": 1.1125394848932046e-05}, {"id": 193, "seek": 87052, "start": 892.0799999999999, "end": 893.72, "text": " It's", "tokens": [467, 311], "temperature": 0.0, "avg_logprob": -0.2703233512051134, "compression_ratio": 1.625, "no_speech_prob": 1.1125394848932046e-05}, {"id": 194, "seek": 87052, "start": 893.72, "end": 896.64, "text": " extremely fast growing extremely popular and we use it because", "tokens": [4664, 2370, 4194, 4664, 3743, 293, 321, 764, 309, 570], "temperature": 0.0, "avg_logprob": -0.2703233512051134, "compression_ratio": 1.625, "no_speech_prob": 1.1125394848932046e-05}, {"id": 195, "seek": 89664, "start": 896.64, "end": 902.84, "text": " Well, we used to use tensorflow a couple of years ago and we found we can just do a lot more a lot more quickly", "tokens": [1042, 11, 321, 1143, 281, 764, 40863, 10565, 257, 1916, 295, 924, 2057, 293, 321, 1352, 321, 393, 445, 360, 257, 688, 544, 257, 688, 544, 2661], "temperature": 0.0, "avg_logprob": -0.1647167385749097, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.939598046708852e-06}, {"id": 196, "seek": 89664, "start": 903.12, "end": 905.12, "text": " with pi torch", "tokens": [365, 3895, 27822], "temperature": 0.0, "avg_logprob": -0.1647167385749097, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.939598046708852e-06}, {"id": 197, "seek": 89664, "start": 905.84, "end": 909.56, "text": " And then we have this software that sits on top of pi torch unless you do", "tokens": [400, 550, 321, 362, 341, 4722, 300, 12696, 322, 1192, 295, 3895, 27822, 5969, 291, 360], "temperature": 0.0, "avg_logprob": -0.1647167385749097, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.939598046708852e-06}, {"id": 198, "seek": 89664, "start": 909.92, "end": 914.24, "text": " Far far far more things far far far more easily than you can with pi torch alone", "tokens": [9067, 1400, 1400, 544, 721, 1400, 1400, 1400, 544, 3612, 813, 291, 393, 365, 3895, 27822, 3312], "temperature": 0.0, "avg_logprob": -0.1647167385749097, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.939598046708852e-06}, {"id": 199, "seek": 89664, "start": 914.24, "end": 921.08, "text": " So it's a good combination. We'll be talking a lot about it. But for now just know that you can use fast AI by doing two things", "tokens": [407, 309, 311, 257, 665, 6562, 13, 492, 603, 312, 1417, 257, 688, 466, 309, 13, 583, 337, 586, 445, 458, 300, 291, 393, 764, 2370, 7318, 538, 884, 732, 721], "temperature": 0.0, "avg_logprob": -0.1647167385749097, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.939598046708852e-06}, {"id": 200, "seek": 92108, "start": 921.08, "end": 927.4200000000001, "text": " importing star from fast AI and then importing star from fast AI dot", "tokens": [43866, 3543, 490, 2370, 7318, 293, 550, 43866, 3543, 490, 2370, 7318, 5893], "temperature": 0.0, "avg_logprob": -0.15322023630142212, "compression_ratio": 1.8170731707317074, "no_speech_prob": 5.338104529073462e-06}, {"id": 201, "seek": 92108, "start": 927.98, "end": 934.4200000000001, "text": " Something where something is the application you want and currently fast AI supports four applications computer vision", "tokens": [6595, 689, 746, 307, 264, 3861, 291, 528, 293, 4362, 2370, 7318, 9346, 1451, 5821, 3820, 5201], "temperature": 0.0, "avg_logprob": -0.15322023630142212, "compression_ratio": 1.8170731707317074, "no_speech_prob": 5.338104529073462e-06}, {"id": 202, "seek": 92108, "start": 935.26, "end": 937.26, "text": " natural language text", "tokens": [3303, 2856, 2487], "temperature": 0.0, "avg_logprob": -0.15322023630142212, "compression_ratio": 1.8170731707317074, "no_speech_prob": 5.338104529073462e-06}, {"id": 203, "seek": 92108, "start": 937.62, "end": 939.38, "text": " tabular data and", "tokens": [4421, 1040, 1412, 293], "temperature": 0.0, "avg_logprob": -0.15322023630142212, "compression_ratio": 1.8170731707317074, "no_speech_prob": 5.338104529073462e-06}, {"id": 204, "seek": 92108, "start": 939.38, "end": 943.74, "text": " Collaborative filtering and we're going to see lots of examples of all of those during the seven weeks", "tokens": [44483, 1166, 30822, 293, 321, 434, 516, 281, 536, 3195, 295, 5110, 295, 439, 295, 729, 1830, 264, 3407, 3259], "temperature": 0.0, "avg_logprob": -0.15322023630142212, "compression_ratio": 1.8170731707317074, "no_speech_prob": 5.338104529073462e-06}, {"id": 205, "seek": 92108, "start": 943.74, "end": 945.74, "text": " So we're going to be doing some computer vision", "tokens": [407, 321, 434, 516, 281, 312, 884, 512, 3820, 5201], "temperature": 0.0, "avg_logprob": -0.15322023630142212, "compression_ratio": 1.8170731707317074, "no_speech_prob": 5.338104529073462e-06}, {"id": 206, "seek": 94574, "start": 945.74, "end": 950.94, "text": " At this point if you are a Python software engineer, you are probably", "tokens": [1711, 341, 935, 498, 291, 366, 257, 15329, 4722, 11403, 11, 291, 366, 1391], "temperature": 0.0, "avg_logprob": -0.1369307752241168, "compression_ratio": 1.7333333333333334, "no_speech_prob": 4.222799361741636e-06}, {"id": 207, "seek": 94574, "start": 951.66, "end": 958.36, "text": " Feeling sick because you've seen me go import star which is something that you've all been told to never ever do", "tokens": [29945, 4998, 570, 291, 600, 1612, 385, 352, 974, 3543, 597, 307, 746, 300, 291, 600, 439, 668, 1907, 281, 1128, 1562, 360], "temperature": 0.0, "avg_logprob": -0.1369307752241168, "compression_ratio": 1.7333333333333334, "no_speech_prob": 4.222799361741636e-06}, {"id": 208, "seek": 94574, "start": 958.74, "end": 965.8, "text": " Okay, and there's very good reasons to not use import star in standard production code with most libraries", "tokens": [1033, 11, 293, 456, 311, 588, 665, 4112, 281, 406, 764, 974, 3543, 294, 3832, 4265, 3089, 365, 881, 15148], "temperature": 0.0, "avg_logprob": -0.1369307752241168, "compression_ratio": 1.7333333333333334, "no_speech_prob": 4.222799361741636e-06}, {"id": 209, "seek": 94574, "start": 966.34, "end": 969.7, "text": " But you might have also seen for those of you that have used something like matlab", "tokens": [583, 291, 1062, 362, 611, 1612, 337, 729, 295, 291, 300, 362, 1143, 746, 411, 3803, 44990], "temperature": 0.0, "avg_logprob": -0.1369307752241168, "compression_ratio": 1.7333333333333334, "no_speech_prob": 4.222799361741636e-06}, {"id": 210, "seek": 94574, "start": 969.74, "end": 974.92, "text": " It's kind of the opposite everything's there for you all the time. You don't even have to import things a lot of the time", "tokens": [467, 311, 733, 295, 264, 6182, 1203, 311, 456, 337, 291, 439, 264, 565, 13, 509, 500, 380, 754, 362, 281, 974, 721, 257, 688, 295, 264, 565], "temperature": 0.0, "avg_logprob": -0.1369307752241168, "compression_ratio": 1.7333333333333334, "no_speech_prob": 4.222799361741636e-06}, {"id": 211, "seek": 97492, "start": 974.92, "end": 979.5999999999999, "text": " It's kind of funny. We've got these two extremes of like how do I code?", "tokens": [467, 311, 733, 295, 4074, 13, 492, 600, 658, 613, 732, 41119, 295, 411, 577, 360, 286, 3089, 30], "temperature": 0.0, "avg_logprob": -0.16719674656533787, "compression_ratio": 1.732899022801303, "no_speech_prob": 5.771880751126446e-06}, {"id": 212, "seek": 97492, "start": 979.5999999999999, "end": 986.28, "text": " You've got a scientific programming community that has one way and then you've got the software engineering community that has the other", "tokens": [509, 600, 658, 257, 8134, 9410, 1768, 300, 575, 472, 636, 293, 550, 291, 600, 658, 264, 4722, 7043, 1768, 300, 575, 264, 661], "temperature": 0.0, "avg_logprob": -0.16719674656533787, "compression_ratio": 1.732899022801303, "no_speech_prob": 5.771880751126446e-06}, {"id": 213, "seek": 97492, "start": 986.92, "end": 992.8, "text": " Both have really good reasons for doing things and with the fast AI library. We actually support both approaches", "tokens": [6767, 362, 534, 665, 4112, 337, 884, 721, 293, 365, 264, 2370, 7318, 6405, 13, 492, 767, 1406, 1293, 11587], "temperature": 0.0, "avg_logprob": -0.16719674656533787, "compression_ratio": 1.732899022801303, "no_speech_prob": 5.771880751126446e-06}, {"id": 214, "seek": 97492, "start": 993.4, "end": 998.24, "text": " Any Jupiter notebook where you want to be able to quickly interactively try stuff out?", "tokens": [2639, 24567, 21060, 689, 291, 528, 281, 312, 1075, 281, 2661, 4648, 3413, 853, 1507, 484, 30], "temperature": 0.0, "avg_logprob": -0.16719674656533787, "compression_ratio": 1.732899022801303, "no_speech_prob": 5.771880751126446e-06}, {"id": 215, "seek": 97492, "start": 998.28, "end": 1003.0799999999999, "text": " You don't want to be constantly going back up to the top and importing more stuff and trying to figure out where things are", "tokens": [509, 500, 380, 528, 281, 312, 6460, 516, 646, 493, 281, 264, 1192, 293, 43866, 544, 1507, 293, 1382, 281, 2573, 484, 689, 721, 366], "temperature": 0.0, "avg_logprob": -0.16719674656533787, "compression_ratio": 1.732899022801303, "no_speech_prob": 5.771880751126446e-06}, {"id": 216, "seek": 100308, "start": 1003.08, "end": 1009.2800000000001, "text": " You want to be able to use lots of tab complete be you know, very experimental. So import star is great", "tokens": [509, 528, 281, 312, 1075, 281, 764, 3195, 295, 4421, 3566, 312, 291, 458, 11, 588, 17069, 13, 407, 974, 3543, 307, 869], "temperature": 0.0, "avg_logprob": -0.18211704922705582, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.422185040515615e-06}, {"id": 217, "seek": 100308, "start": 1009.72, "end": 1017.96, "text": " Then when you're building stuff in production you can do the normal pep 8 style, you know proper software engineering practices", "tokens": [1396, 562, 291, 434, 2390, 1507, 294, 4265, 291, 393, 360, 264, 2710, 520, 79, 1649, 3758, 11, 291, 458, 2296, 4722, 7043, 7525], "temperature": 0.0, "avg_logprob": -0.18211704922705582, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.422185040515615e-06}, {"id": 218, "seek": 100308, "start": 1018.12, "end": 1019.5200000000001, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.18211704922705582, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.422185040515615e-06}, {"id": 219, "seek": 100308, "start": 1019.5200000000001, "end": 1021.24, "text": " So don't worry", "tokens": [407, 500, 380, 3292], "temperature": 0.0, "avg_logprob": -0.18211704922705582, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.422185040515615e-06}, {"id": 220, "seek": 100308, "start": 1021.24, "end": 1028.1200000000001, "text": " When you see me doing stuff which at your workplace is found upon. Okay, it's it's this is a different style of coding", "tokens": [1133, 291, 536, 385, 884, 1507, 597, 412, 428, 15328, 307, 1352, 3564, 13, 1033, 11, 309, 311, 309, 311, 341, 307, 257, 819, 3758, 295, 17720], "temperature": 0.0, "avg_logprob": -0.18211704922705582, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.422185040515615e-06}, {"id": 221, "seek": 100308, "start": 1028.1200000000001, "end": 1029.28, "text": " It's not that", "tokens": [467, 311, 406, 300], "temperature": 0.0, "avg_logprob": -0.18211704922705582, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.422185040515615e-06}, {"id": 222, "seek": 102928, "start": 1029.28, "end": 1035.18, "text": " There are no rules in data science programming is that the rules are different right when you're training models", "tokens": [821, 366, 572, 4474, 294, 1412, 3497, 9410, 307, 300, 264, 4474, 366, 819, 558, 562, 291, 434, 3097, 5245], "temperature": 0.0, "avg_logprob": -0.16740373085285054, "compression_ratio": 1.6700680272108843, "no_speech_prob": 3.90546074413578e-06}, {"id": 223, "seek": 102928, "start": 1035.18, "end": 1042.62, "text": " The most important thing is to be able to interactively experiment quickly. Okay, so you'll see we use a lot of very different", "tokens": [440, 881, 1021, 551, 307, 281, 312, 1075, 281, 4648, 3413, 5120, 2661, 13, 1033, 11, 370, 291, 603, 536, 321, 764, 257, 688, 295, 588, 819], "temperature": 0.0, "avg_logprob": -0.16740373085285054, "compression_ratio": 1.6700680272108843, "no_speech_prob": 3.90546074413578e-06}, {"id": 224, "seek": 102928, "start": 1044.16, "end": 1047.6, "text": " Processes styles and stuff to what you're used to but they're there for a reason", "tokens": [31093, 279, 13273, 293, 1507, 281, 437, 291, 434, 1143, 281, 457, 436, 434, 456, 337, 257, 1778], "temperature": 0.0, "avg_logprob": -0.16740373085285054, "compression_ratio": 1.6700680272108843, "no_speech_prob": 3.90546074413578e-06}, {"id": 225, "seek": 102928, "start": 1048.32, "end": 1050.32, "text": " And you'll learn about them over time", "tokens": [400, 291, 603, 1466, 466, 552, 670, 565], "temperature": 0.0, "avg_logprob": -0.16740373085285054, "compression_ratio": 1.6700680272108843, "no_speech_prob": 3.90546074413578e-06}, {"id": 226, "seek": 102928, "start": 1050.36, "end": 1054.16, "text": " You can choose to use a similar approach or not. It's entirely up to you", "tokens": [509, 393, 2826, 281, 764, 257, 2531, 3109, 420, 406, 13, 467, 311, 7696, 493, 281, 291], "temperature": 0.0, "avg_logprob": -0.16740373085285054, "compression_ratio": 1.6700680272108843, "no_speech_prob": 3.90546074413578e-06}, {"id": 227, "seek": 102928, "start": 1054.72, "end": 1058.12, "text": " The other thing to mention is that the faster AI libraries?", "tokens": [440, 661, 551, 281, 2152, 307, 300, 264, 4663, 7318, 15148, 30], "temperature": 0.0, "avg_logprob": -0.16740373085285054, "compression_ratio": 1.6700680272108843, "no_speech_prob": 3.90546074413578e-06}, {"id": 228, "seek": 105812, "start": 1058.12, "end": 1065.4799999999998, "text": " in a real designed in a very interesting modular way and you'll find over time that when you do use import star there's", "tokens": [294, 257, 957, 4761, 294, 257, 588, 1880, 31111, 636, 293, 291, 603, 915, 670, 565, 300, 562, 291, 360, 764, 974, 3543, 456, 311], "temperature": 0.0, "avg_logprob": -0.2133821861766209, "compression_ratio": 1.6796875, "no_speech_prob": 8.939598956203554e-06}, {"id": 229, "seek": 105812, "start": 1065.56, "end": 1068.08, "text": " Far less plobbering of things than you might expect", "tokens": [9067, 1570, 499, 996, 607, 278, 295, 721, 813, 291, 1062, 2066], "temperature": 0.0, "avg_logprob": -0.2133821861766209, "compression_ratio": 1.6796875, "no_speech_prob": 8.939598956203554e-06}, {"id": 230, "seek": 105812, "start": 1068.08, "end": 1074.36, "text": " It's all explicitly designed to allow you to pull in things and use them quickly without having problems", "tokens": [467, 311, 439, 20803, 4761, 281, 2089, 291, 281, 2235, 294, 721, 293, 764, 552, 2661, 1553, 1419, 2740], "temperature": 0.0, "avg_logprob": -0.2133821861766209, "compression_ratio": 1.6796875, "no_speech_prob": 8.939598956203554e-06}, {"id": 231, "seek": 105812, "start": 1075.36, "end": 1076.56, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.2133821861766209, "compression_ratio": 1.6796875, "no_speech_prob": 8.939598956203554e-06}, {"id": 232, "seek": 105812, "start": 1076.56, "end": 1079.52, "text": " so we're going to look at some data and", "tokens": [370, 321, 434, 516, 281, 574, 412, 512, 1412, 293], "temperature": 0.0, "avg_logprob": -0.2133821861766209, "compression_ratio": 1.6796875, "no_speech_prob": 8.939598956203554e-06}, {"id": 233, "seek": 105812, "start": 1080.1599999999999, "end": 1085.2399999999998, "text": " There's two main places that we'll be tending to get data from for the course one is from", "tokens": [821, 311, 732, 2135, 3190, 300, 321, 603, 312, 256, 2029, 281, 483, 1412, 490, 337, 264, 1164, 472, 307, 490], "temperature": 0.0, "avg_logprob": -0.2133821861766209, "compression_ratio": 1.6796875, "no_speech_prob": 8.939598956203554e-06}, {"id": 234, "seek": 105812, "start": 1085.8799999999999, "end": 1087.8799999999999, "text": " academic data sets", "tokens": [7778, 1412, 6352], "temperature": 0.0, "avg_logprob": -0.2133821861766209, "compression_ratio": 1.6796875, "no_speech_prob": 8.939598956203554e-06}, {"id": 235, "seek": 108788, "start": 1087.88, "end": 1090.72, "text": " Academic data sets are really important. They're really interesting", "tokens": [36139, 1412, 6352, 366, 534, 1021, 13, 814, 434, 534, 1880], "temperature": 0.0, "avg_logprob": -0.18100496322389634, "compression_ratio": 1.8476821192052981, "no_speech_prob": 3.591151107684709e-05}, {"id": 236, "seek": 108788, "start": 1091.0400000000002, "end": 1093.5, "text": " There are things where academics spend a lot of time", "tokens": [821, 366, 721, 689, 25695, 3496, 257, 688, 295, 565], "temperature": 0.0, "avg_logprob": -0.18100496322389634, "compression_ratio": 1.8476821192052981, "no_speech_prob": 3.591151107684709e-05}, {"id": 237, "seek": 108788, "start": 1093.92, "end": 1099.2600000000002, "text": " Curating and gathering a data set so that they can show how well different kinds of approaches work with that data", "tokens": [7907, 990, 293, 13519, 257, 1412, 992, 370, 300, 436, 393, 855, 577, 731, 819, 3685, 295, 11587, 589, 365, 300, 1412], "temperature": 0.0, "avg_logprob": -0.18100496322389634, "compression_ratio": 1.8476821192052981, "no_speech_prob": 3.591151107684709e-05}, {"id": 238, "seek": 108788, "start": 1099.2600000000002, "end": 1102.1000000000001, "text": " And the idea is they try to design data sets that are", "tokens": [400, 264, 1558, 307, 436, 853, 281, 1715, 1412, 6352, 300, 366], "temperature": 0.0, "avg_logprob": -0.18100496322389634, "compression_ratio": 1.8476821192052981, "no_speech_prob": 3.591151107684709e-05}, {"id": 239, "seek": 108788, "start": 1103.0600000000002, "end": 1106.72, "text": " Challenging in some way and require some kind of breakthrough to do them. Well", "tokens": [14398, 1501, 278, 294, 512, 636, 293, 3651, 512, 733, 295, 22397, 281, 360, 552, 13, 1042], "temperature": 0.0, "avg_logprob": -0.18100496322389634, "compression_ratio": 1.8476821192052981, "no_speech_prob": 3.591151107684709e-05}, {"id": 240, "seek": 108788, "start": 1107.5200000000002, "end": 1110.92, "text": " So we're going to be starting with an academic data set called the pet data set", "tokens": [407, 321, 434, 516, 281, 312, 2891, 365, 364, 7778, 1412, 992, 1219, 264, 3817, 1412, 992], "temperature": 0.0, "avg_logprob": -0.18100496322389634, "compression_ratio": 1.8476821192052981, "no_speech_prob": 3.591151107684709e-05}, {"id": 241, "seek": 108788, "start": 1111.16, "end": 1117.1200000000001, "text": " The other kind of data set will be using during the course is data sets from the Kaggle competitions platform", "tokens": [440, 661, 733, 295, 1412, 992, 486, 312, 1228, 1830, 264, 1164, 307, 1412, 6352, 490, 264, 48751, 22631, 26185, 3663], "temperature": 0.0, "avg_logprob": -0.18100496322389634, "compression_ratio": 1.8476821192052981, "no_speech_prob": 3.591151107684709e-05}, {"id": 242, "seek": 111712, "start": 1117.12, "end": 1121.6799999999998, "text": " Both academic data sets and Kaggle data sets are interesting for us", "tokens": [6767, 7778, 1412, 6352, 293, 48751, 22631, 1412, 6352, 366, 1880, 337, 505], "temperature": 0.0, "avg_logprob": -0.23822849168689972, "compression_ratio": 1.7027027027027026, "no_speech_prob": 4.710862413048744e-06}, {"id": 243, "seek": 111712, "start": 1122.0, "end": 1127.6399999999999, "text": " Particularly because they provide strong baselines that is to say you want to know if you're doing a good job", "tokens": [32281, 570, 436, 2893, 2068, 987, 9173, 300, 307, 281, 584, 291, 528, 281, 458, 498, 291, 434, 884, 257, 665, 1691], "temperature": 0.0, "avg_logprob": -0.23822849168689972, "compression_ratio": 1.7027027027027026, "no_speech_prob": 4.710862413048744e-06}, {"id": 244, "seek": 111712, "start": 1128.1599999999999, "end": 1131.4399999999998, "text": " So with kakal data sets that have come from a competition", "tokens": [407, 365, 350, 514, 304, 1412, 6352, 300, 362, 808, 490, 257, 6211], "temperature": 0.0, "avg_logprob": -0.23822849168689972, "compression_ratio": 1.7027027027027026, "no_speech_prob": 4.710862413048744e-06}, {"id": 245, "seek": 111712, "start": 1131.76, "end": 1136.84, "text": " You can actually submit your results to Kaggle and see how well would you have gone in that competition?", "tokens": [509, 393, 767, 10315, 428, 3542, 281, 48751, 22631, 293, 536, 577, 731, 576, 291, 362, 2780, 294, 300, 6211, 30], "temperature": 0.0, "avg_logprob": -0.23822849168689972, "compression_ratio": 1.7027027027027026, "no_speech_prob": 4.710862413048744e-06}, {"id": 246, "seek": 111712, "start": 1136.84, "end": 1140.6, "text": " And if you can get in about the top 10% that I'd say you're doing", "tokens": [400, 498, 291, 393, 483, 294, 466, 264, 1192, 1266, 4, 300, 286, 1116, 584, 291, 434, 884], "temperature": 0.0, "avg_logprob": -0.23822849168689972, "compression_ratio": 1.7027027027027026, "no_speech_prob": 4.710862413048744e-06}, {"id": 247, "seek": 111712, "start": 1141.32, "end": 1142.84, "text": " pretty well", "tokens": [1238, 731], "temperature": 0.0, "avg_logprob": -0.23822849168689972, "compression_ratio": 1.7027027027027026, "no_speech_prob": 4.710862413048744e-06}, {"id": 248, "seek": 111712, "start": 1142.84, "end": 1144.84, "text": " for academic data sets", "tokens": [337, 7778, 1412, 6352], "temperature": 0.0, "avg_logprob": -0.23822849168689972, "compression_ratio": 1.7027027027027026, "no_speech_prob": 4.710862413048744e-06}, {"id": 249, "seek": 114484, "start": 1144.84, "end": 1151.22, "text": " Academics write down in papers what the state of the art is so how well did they go with using models on that data set?", "tokens": [9740, 38014, 2464, 760, 294, 10577, 437, 264, 1785, 295, 264, 1523, 307, 370, 577, 731, 630, 436, 352, 365, 1228, 5245, 322, 300, 1412, 992, 30], "temperature": 0.0, "avg_logprob": -0.21707687011131874, "compression_ratio": 1.615702479338843, "no_speech_prob": 4.860390163230477e-06}, {"id": 250, "seek": 114484, "start": 1151.22, "end": 1155.04, "text": " Okay, so this is this is what we're going to do. We're going to try and create", "tokens": [1033, 11, 370, 341, 307, 341, 307, 437, 321, 434, 516, 281, 360, 13, 492, 434, 516, 281, 853, 293, 1884], "temperature": 0.0, "avg_logprob": -0.21707687011131874, "compression_ratio": 1.615702479338843, "no_speech_prob": 4.860390163230477e-06}, {"id": 251, "seek": 114484, "start": 1155.8799999999999, "end": 1162.1999999999998, "text": " Models that get right up towards the top of Kaggle competitions preferably actually in the top 10 not just the top 10%", "tokens": [6583, 1625, 300, 483, 558, 493, 3030, 264, 1192, 295, 48751, 22631, 26185, 45916, 767, 294, 264, 1192, 1266, 406, 445, 264, 1192, 1266, 4], "temperature": 0.0, "avg_logprob": -0.21707687011131874, "compression_ratio": 1.615702479338843, "no_speech_prob": 4.860390163230477e-06}, {"id": 252, "seek": 114484, "start": 1163.08, "end": 1167.52, "text": " Or that meet or exceed academic state-of-the-art published results", "tokens": [1610, 300, 1677, 420, 14048, 7778, 1785, 12, 2670, 12, 3322, 12, 446, 6572, 3542], "temperature": 0.0, "avg_logprob": -0.21707687011131874, "compression_ratio": 1.615702479338843, "no_speech_prob": 4.860390163230477e-06}, {"id": 253, "seek": 114484, "start": 1168.3999999999999, "end": 1169.72, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.21707687011131874, "compression_ratio": 1.615702479338843, "no_speech_prob": 4.860390163230477e-06}, {"id": 254, "seek": 114484, "start": 1169.72, "end": 1171.72, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.21707687011131874, "compression_ratio": 1.615702479338843, "no_speech_prob": 4.860390163230477e-06}, {"id": 255, "seek": 117172, "start": 1171.72, "end": 1176.28, "text": " When you use an academic data set it's important to cite it", "tokens": [1133, 291, 764, 364, 7778, 1412, 992, 309, 311, 1021, 281, 37771, 309], "temperature": 0.0, "avg_logprob": -0.19421946100828028, "compression_ratio": 1.712280701754386, "no_speech_prob": 1.428520590707194e-05}, {"id": 256, "seek": 117172, "start": 1176.28, "end": 1180.8, "text": " So you'll see here there's a link to the paper that it's from you definitely don't need to read that paper right now", "tokens": [407, 291, 603, 536, 510, 456, 311, 257, 2113, 281, 264, 3035, 300, 309, 311, 490, 291, 2138, 500, 380, 643, 281, 1401, 300, 3035, 558, 586], "temperature": 0.0, "avg_logprob": -0.19421946100828028, "compression_ratio": 1.712280701754386, "no_speech_prob": 1.428520590707194e-05}, {"id": 257, "seek": 117172, "start": 1181.04, "end": 1186.0, "text": " But if you're interested in learning more about it, and why it was created and how it was created all the details", "tokens": [583, 498, 291, 434, 3102, 294, 2539, 544, 466, 309, 11, 293, 983, 309, 390, 2942, 293, 577, 309, 390, 2942, 439, 264, 4365], "temperature": 0.0, "avg_logprob": -0.19421946100828028, "compression_ratio": 1.712280701754386, "no_speech_prob": 1.428520590707194e-05}, {"id": 258, "seek": 117172, "start": 1186.76, "end": 1188.48, "text": " there", "tokens": [456], "temperature": 0.0, "avg_logprob": -0.19421946100828028, "compression_ratio": 1.712280701754386, "no_speech_prob": 1.428520590707194e-05}, {"id": 259, "seek": 117172, "start": 1188.48, "end": 1190.76, "text": " So in this case, this is a pretty difficult challenge", "tokens": [407, 294, 341, 1389, 11, 341, 307, 257, 1238, 2252, 3430], "temperature": 0.0, "avg_logprob": -0.19421946100828028, "compression_ratio": 1.712280701754386, "no_speech_prob": 1.428520590707194e-05}, {"id": 260, "seek": 117172, "start": 1190.96, "end": 1197.88, "text": " The pet data sets going to ask us to distinguish between 37 different categories of dog breed and cat breed", "tokens": [440, 3817, 1412, 6352, 516, 281, 1029, 505, 281, 20206, 1296, 13435, 819, 10479, 295, 3000, 18971, 293, 3857, 18971], "temperature": 0.0, "avg_logprob": -0.19421946100828028, "compression_ratio": 1.712280701754386, "no_speech_prob": 1.428520590707194e-05}, {"id": 261, "seek": 117172, "start": 1198.2, "end": 1200.48, "text": " So that's really hard in fact", "tokens": [407, 300, 311, 534, 1152, 294, 1186], "temperature": 0.0, "avg_logprob": -0.19421946100828028, "compression_ratio": 1.712280701754386, "no_speech_prob": 1.428520590707194e-05}, {"id": 262, "seek": 120048, "start": 1200.48, "end": 1205.58, "text": " The every course until this one we've used a different data set", "tokens": [440, 633, 1164, 1826, 341, 472, 321, 600, 1143, 257, 819, 1412, 992], "temperature": 0.0, "avg_logprob": -0.18567365010579426, "compression_ratio": 1.7394366197183098, "no_speech_prob": 9.080365089175757e-06}, {"id": 263, "seek": 120048, "start": 1205.68, "end": 1209.3600000000001, "text": " Which is one where you just have to decide is something a dog or is it a cat?", "tokens": [3013, 307, 472, 689, 291, 445, 362, 281, 4536, 307, 746, 257, 3000, 420, 307, 309, 257, 3857, 30], "temperature": 0.0, "avg_logprob": -0.18567365010579426, "compression_ratio": 1.7394366197183098, "no_speech_prob": 9.080365089175757e-06}, {"id": 264, "seek": 120048, "start": 1209.72, "end": 1214.24, "text": " So you've got a 50-50 chance right away right and dogs and cats look really different", "tokens": [407, 291, 600, 658, 257, 2625, 12, 2803, 2931, 558, 1314, 558, 293, 7197, 293, 11111, 574, 534, 819], "temperature": 0.0, "avg_logprob": -0.18567365010579426, "compression_ratio": 1.7394366197183098, "no_speech_prob": 9.080365089175757e-06}, {"id": 265, "seek": 120048, "start": 1214.24, "end": 1219.76, "text": " There are lots of dog breeds and cat breeds look pretty much the same so why if we change that data set", "tokens": [821, 366, 3195, 295, 3000, 41609, 293, 3857, 41609, 574, 1238, 709, 264, 912, 370, 983, 498, 321, 1319, 300, 1412, 992], "temperature": 0.0, "avg_logprob": -0.18567365010579426, "compression_ratio": 1.7394366197183098, "no_speech_prob": 9.080365089175757e-06}, {"id": 266, "seek": 120048, "start": 1220.28, "end": 1225.82, "text": " We've got to the point now where deep learning is so fast and so easy that the dog's versus cat's problem", "tokens": [492, 600, 658, 281, 264, 935, 586, 689, 2452, 2539, 307, 370, 2370, 293, 370, 1858, 300, 264, 3000, 311, 5717, 3857, 311, 1154], "temperature": 0.0, "avg_logprob": -0.18567365010579426, "compression_ratio": 1.7394366197183098, "no_speech_prob": 9.080365089175757e-06}, {"id": 267, "seek": 120048, "start": 1225.82, "end": 1229.1, "text": " Which a few years ago was considered extremely difficult", "tokens": [3013, 257, 1326, 924, 2057, 390, 4888, 4664, 2252], "temperature": 0.0, "avg_logprob": -0.18567365010579426, "compression_ratio": 1.7394366197183098, "no_speech_prob": 9.080365089175757e-06}, {"id": 268, "seek": 122910, "start": 1229.1, "end": 1232.86, "text": " Or 80% accuracy was a state-of-the-art. It's now too easy", "tokens": [1610, 4688, 4, 14170, 390, 257, 1785, 12, 2670, 12, 3322, 12, 446, 13, 467, 311, 586, 886, 1858], "temperature": 0.0, "avg_logprob": -0.17767421888268511, "compression_ratio": 1.6266233766233766, "no_speech_prob": 1.3631167348648887e-05}, {"id": 269, "seek": 122910, "start": 1233.6999999999998, "end": 1240.6799999999998, "text": " Our models were basically getting everything right all the time without any tuning and so they want you know really a lot of", "tokens": [2621, 5245, 645, 1936, 1242, 1203, 558, 439, 264, 565, 1553, 604, 15164, 293, 370, 436, 528, 291, 458, 534, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.17767421888268511, "compression_ratio": 1.6266233766233766, "no_speech_prob": 1.3631167348648887e-05}, {"id": 270, "seek": 122910, "start": 1241.2199999999998, "end": 1246.58, "text": " Opportunities for me to show you how to do more sophisticated stuff, so we've picked a harder problem this year", "tokens": [39441, 1088, 337, 385, 281, 855, 291, 577, 281, 360, 544, 16950, 1507, 11, 370, 321, 600, 6183, 257, 6081, 1154, 341, 1064], "temperature": 0.0, "avg_logprob": -0.17767421888268511, "compression_ratio": 1.6266233766233766, "no_speech_prob": 1.3631167348648887e-05}, {"id": 271, "seek": 122910, "start": 1247.02, "end": 1252.6399999999999, "text": " So this is the first class where we're going to be learning how to do this difficult problem and this kind of thing where you", "tokens": [407, 341, 307, 264, 700, 1508, 689, 321, 434, 516, 281, 312, 2539, 577, 281, 360, 341, 2252, 1154, 293, 341, 733, 295, 551, 689, 291], "temperature": 0.0, "avg_logprob": -0.17767421888268511, "compression_ratio": 1.6266233766233766, "no_speech_prob": 1.3631167348648887e-05}, {"id": 272, "seek": 122910, "start": 1252.6599999999999, "end": 1257.9399999999998, "text": " Have to distinguish between similar categories is caught in the academic context", "tokens": [3560, 281, 20206, 1296, 2531, 10479, 307, 5415, 294, 264, 7778, 4319], "temperature": 0.0, "avg_logprob": -0.17767421888268511, "compression_ratio": 1.6266233766233766, "no_speech_prob": 1.3631167348648887e-05}, {"id": 273, "seek": 125794, "start": 1257.94, "end": 1262.4, "text": " It's called fine-grained classification. So we're going to do the fine-grained classification task of", "tokens": [467, 311, 1219, 2489, 12, 20735, 2001, 21538, 13, 407, 321, 434, 516, 281, 360, 264, 2489, 12, 20735, 2001, 21538, 5633, 295], "temperature": 0.0, "avg_logprob": -0.21542375581758516, "compression_ratio": 1.8616600790513833, "no_speech_prob": 2.318695442227181e-05}, {"id": 274, "seek": 125794, "start": 1263.22, "end": 1265.22, "text": " figuring out a particular kind of pet", "tokens": [15213, 484, 257, 1729, 733, 295, 3817], "temperature": 0.0, "avg_logprob": -0.21542375581758516, "compression_ratio": 1.8616600790513833, "no_speech_prob": 2.318695442227181e-05}, {"id": 275, "seek": 125794, "start": 1265.5, "end": 1270.1200000000001, "text": " So the first thing we have to do is download and extract the data that we want", "tokens": [407, 264, 700, 551, 321, 362, 281, 360, 307, 5484, 293, 8947, 264, 1412, 300, 321, 528], "temperature": 0.0, "avg_logprob": -0.21542375581758516, "compression_ratio": 1.8616600790513833, "no_speech_prob": 2.318695442227181e-05}, {"id": 276, "seek": 125794, "start": 1270.5800000000002, "end": 1274.4, "text": " We're going to be using this function called and tar data", "tokens": [492, 434, 516, 281, 312, 1228, 341, 2445, 1219, 293, 3112, 1412], "temperature": 0.0, "avg_logprob": -0.21542375581758516, "compression_ratio": 1.8616600790513833, "no_speech_prob": 2.318695442227181e-05}, {"id": 277, "seek": 125794, "start": 1274.78, "end": 1278.42, "text": " Which will download it automatically and will untie it automatically", "tokens": [3013, 486, 5484, 309, 6772, 293, 486, 1701, 414, 309, 6772], "temperature": 0.0, "avg_logprob": -0.21542375581758516, "compression_ratio": 1.8616600790513833, "no_speech_prob": 2.318695442227181e-05}, {"id": 278, "seek": 125794, "start": 1279.5, "end": 1284.16, "text": " AWS has been kind enough to give us lots of space and bandwidth for these data sets", "tokens": [17650, 575, 668, 733, 1547, 281, 976, 505, 3195, 295, 1901, 293, 23647, 337, 613, 1412, 6352], "temperature": 0.0, "avg_logprob": -0.21542375581758516, "compression_ratio": 1.8616600790513833, "no_speech_prob": 2.318695442227181e-05}, {"id": 279, "seek": 125794, "start": 1284.16, "end": 1286.16, "text": " So they'll download super quickly for you", "tokens": [407, 436, 603, 5484, 1687, 2661, 337, 291], "temperature": 0.0, "avg_logprob": -0.21542375581758516, "compression_ratio": 1.8616600790513833, "no_speech_prob": 2.318695442227181e-05}, {"id": 280, "seek": 128616, "start": 1286.16, "end": 1291.5800000000002, "text": " And so the first question then would be how do I know what untie data?", "tokens": [400, 370, 264, 700, 1168, 550, 576, 312, 577, 360, 286, 458, 437, 1701, 414, 1412, 30], "temperature": 0.0, "avg_logprob": -0.18280949543431863, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.0030117891801638e-06}, {"id": 281, "seek": 128616, "start": 1292.24, "end": 1293.6000000000001, "text": " does", "tokens": [775], "temperature": 0.0, "avg_logprob": -0.18280949543431863, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.0030117891801638e-06}, {"id": 282, "seek": 128616, "start": 1293.6000000000001, "end": 1296.38, "text": " So you can just type help and you will find out", "tokens": [407, 291, 393, 445, 2010, 854, 293, 291, 486, 915, 484], "temperature": 0.0, "avg_logprob": -0.18280949543431863, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.0030117891801638e-06}, {"id": 283, "seek": 128616, "start": 1296.9, "end": 1301.26, "text": " What module did it come from because since we imported star we don't necessarily know that", "tokens": [708, 10088, 630, 309, 808, 490, 570, 1670, 321, 25524, 3543, 321, 500, 380, 4725, 458, 300], "temperature": 0.0, "avg_logprob": -0.18280949543431863, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.0030117891801638e-06}, {"id": 284, "seek": 128616, "start": 1302.3200000000002, "end": 1307.6000000000001, "text": " What does it do and something you might not have seen before even if you're an experienced programmer is", "tokens": [708, 775, 309, 360, 293, 746, 291, 1062, 406, 362, 1612, 949, 754, 498, 291, 434, 364, 6751, 32116, 307], "temperature": 0.0, "avg_logprob": -0.18280949543431863, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.0030117891801638e-06}, {"id": 285, "seek": 128616, "start": 1308.28, "end": 1313.88, "text": " What exactly do you pass to it? You're probably used to seeing the names URL", "tokens": [708, 2293, 360, 291, 1320, 281, 309, 30, 509, 434, 1391, 1143, 281, 2577, 264, 5288, 12905], "temperature": 0.0, "avg_logprob": -0.18280949543431863, "compression_ratio": 1.565217391304348, "no_speech_prob": 1.0030117891801638e-06}, {"id": 286, "seek": 131388, "start": 1313.88, "end": 1315.72, "text": " file name", "tokens": [3991, 1315], "temperature": 0.0, "avg_logprob": -0.20097428957621258, "compression_ratio": 1.7822878228782288, "no_speech_prob": 8.664589586260263e-06}, {"id": 287, "seek": 131388, "start": 1315.72, "end": 1318.1000000000001, "text": " Destination that you might not be used to seeing", "tokens": [16339, 2486, 300, 291, 1062, 406, 312, 1143, 281, 2577], "temperature": 0.0, "avg_logprob": -0.20097428957621258, "compression_ratio": 1.7822878228782288, "no_speech_prob": 8.664589586260263e-06}, {"id": 288, "seek": 131388, "start": 1318.8000000000002, "end": 1324.3400000000001, "text": " These bits these bits of types can if you've used a type programming language, you'll be used to seeing them", "tokens": [1981, 9239, 613, 9239, 295, 3467, 393, 498, 291, 600, 1143, 257, 2010, 9410, 2856, 11, 291, 603, 312, 1143, 281, 2577, 552], "temperature": 0.0, "avg_logprob": -0.20097428957621258, "compression_ratio": 1.7822878228782288, "no_speech_prob": 8.664589586260263e-06}, {"id": 289, "seek": 131388, "start": 1324.88, "end": 1327.0400000000002, "text": " But Python programmers are less used to it", "tokens": [583, 15329, 41504, 366, 1570, 1143, 281, 309], "temperature": 0.0, "avg_logprob": -0.20097428957621258, "compression_ratio": 1.7822878228782288, "no_speech_prob": 8.664589586260263e-06}, {"id": 290, "seek": 131388, "start": 1327.2, "end": 1328.96, "text": " But if you think about it", "tokens": [583, 498, 291, 519, 466, 309], "temperature": 0.0, "avg_logprob": -0.20097428957621258, "compression_ratio": 1.7822878228782288, "no_speech_prob": 8.664589586260263e-06}, {"id": 291, "seek": 131388, "start": 1328.96, "end": 1335.18, "text": " You don't actually know how to use a function unless you know what type each thing is that you're providing it", "tokens": [509, 500, 380, 767, 458, 577, 281, 764, 257, 2445, 5969, 291, 458, 437, 2010, 1184, 551, 307, 300, 291, 434, 6530, 309], "temperature": 0.0, "avg_logprob": -0.20097428957621258, "compression_ratio": 1.7822878228782288, "no_speech_prob": 8.664589586260263e-06}, {"id": 292, "seek": 131388, "start": 1335.2, "end": 1337.64, "text": " So we make sure that we give you that type information", "tokens": [407, 321, 652, 988, 300, 321, 976, 291, 300, 2010, 1589], "temperature": 0.0, "avg_logprob": -0.20097428957621258, "compression_ratio": 1.7822878228782288, "no_speech_prob": 8.664589586260263e-06}, {"id": 293, "seek": 133764, "start": 1337.64, "end": 1344.76, "text": " Directly here in the help. So in this case, the URL is a string and the file name is either", "tokens": [18308, 356, 510, 294, 264, 854, 13, 407, 294, 341, 1389, 11, 264, 12905, 307, 257, 6798, 293, 264, 3991, 1315, 307, 2139], "temperature": 0.0, "avg_logprob": -0.1956467534981522, "compression_ratio": 1.8878504672897196, "no_speech_prob": 1.0451447451487184e-05}, {"id": 294, "seek": 133764, "start": 1344.92, "end": 1352.0800000000002, "text": " Union means either either a path or a string and it defaults to nothing and the", "tokens": [8133, 1355, 2139, 2139, 257, 3100, 420, 257, 6798, 293, 309, 7576, 82, 281, 1825, 293, 264], "temperature": 0.0, "avg_logprob": -0.1956467534981522, "compression_ratio": 1.8878504672897196, "no_speech_prob": 1.0451447451487184e-05}, {"id": 295, "seek": 133764, "start": 1352.24, "end": 1355.8000000000002, "text": " Destination is either a path or a string that defaults to nothing", "tokens": [16339, 2486, 307, 2139, 257, 3100, 420, 257, 6798, 300, 7576, 82, 281, 1825], "temperature": 0.0, "avg_logprob": -0.1956467534981522, "compression_ratio": 1.8878504672897196, "no_speech_prob": 1.0451447451487184e-05}, {"id": 296, "seek": 133764, "start": 1356.2800000000002, "end": 1360.8000000000002, "text": " So we'll learn more shortly about how to get more documentation about the details of this", "tokens": [407, 321, 603, 1466, 544, 13392, 466, 577, 281, 483, 544, 14333, 466, 264, 4365, 295, 341], "temperature": 0.0, "avg_logprob": -0.1956467534981522, "compression_ratio": 1.8878504672897196, "no_speech_prob": 1.0451447451487184e-05}, {"id": 297, "seek": 133764, "start": 1360.92, "end": 1364.6000000000001, "text": " But for now we can see we don't have to pass in a file name or a destination", "tokens": [583, 337, 586, 321, 393, 536, 321, 500, 380, 362, 281, 1320, 294, 257, 3991, 1315, 420, 257, 12236], "temperature": 0.0, "avg_logprob": -0.1956467534981522, "compression_ratio": 1.8878504672897196, "no_speech_prob": 1.0451447451487184e-05}, {"id": 298, "seek": 136460, "start": 1364.6, "end": 1370.62, "text": " It'll figure them out for us from the URL so and for all the data sets will be using in the course", "tokens": [467, 603, 2573, 552, 484, 337, 505, 490, 264, 12905, 370, 293, 337, 439, 264, 1412, 6352, 486, 312, 1228, 294, 264, 1164], "temperature": 0.0, "avg_logprob": -0.19860317230224608, "compression_ratio": 1.605263157894737, "no_speech_prob": 3.7852980767638655e-06}, {"id": 299, "seek": 136460, "start": 1370.9199999999998, "end": 1372.9199999999998, "text": " We already have constants to find", "tokens": [492, 1217, 362, 35870, 281, 915], "temperature": 0.0, "avg_logprob": -0.19860317230224608, "compression_ratio": 1.605263157894737, "no_speech_prob": 3.7852980767638655e-06}, {"id": 300, "seek": 136460, "start": 1373.36, "end": 1377.8, "text": " For all of them, right so in this URLs module class actually", "tokens": [1171, 439, 295, 552, 11, 558, 370, 294, 341, 43267, 10088, 1508, 767], "temperature": 0.0, "avg_logprob": -0.19860317230224608, "compression_ratio": 1.605263157894737, "no_speech_prob": 3.7852980767638655e-06}, {"id": 301, "seek": 136460, "start": 1378.76, "end": 1380.28, "text": " You can see", "tokens": [509, 393, 536], "temperature": 0.0, "avg_logprob": -0.19860317230224608, "compression_ratio": 1.605263157894737, "no_speech_prob": 3.7852980767638655e-06}, {"id": 302, "seek": 136460, "start": 1380.28, "end": 1384.6, "text": " That's where it's going to grab it from. Okay, so it's going to download that to some", "tokens": [663, 311, 689, 309, 311, 516, 281, 4444, 309, 490, 13, 1033, 11, 370, 309, 311, 516, 281, 5484, 300, 281, 512], "temperature": 0.0, "avg_logprob": -0.19860317230224608, "compression_ratio": 1.605263157894737, "no_speech_prob": 3.7852980767638655e-06}, {"id": 303, "seek": 136460, "start": 1385.7199999999998, "end": 1389.28, "text": " Convenient path and untie it for us and will then return", "tokens": [45992, 1196, 3100, 293, 1701, 414, 309, 337, 505, 293, 486, 550, 2736], "temperature": 0.0, "avg_logprob": -0.19860317230224608, "compression_ratio": 1.605263157894737, "no_speech_prob": 3.7852980767638655e-06}, {"id": 304, "seek": 136460, "start": 1390.08, "end": 1392.08, "text": " the value of path", "tokens": [264, 2158, 295, 3100], "temperature": 0.0, "avg_logprob": -0.19860317230224608, "compression_ratio": 1.605263157894737, "no_speech_prob": 3.7852980767638655e-06}, {"id": 305, "seek": 139208, "start": 1392.08, "end": 1396.1, "text": " Okay, and then in Jupyter notebook, it's kind of handy", "tokens": [1033, 11, 293, 550, 294, 22125, 88, 391, 21060, 11, 309, 311, 733, 295, 13239], "temperature": 0.0, "avg_logprob": -0.18383916219075522, "compression_ratio": 1.6134453781512605, "no_speech_prob": 2.6425714167999104e-06}, {"id": 306, "seek": 139208, "start": 1396.1599999999999, "end": 1403.1999999999998, "text": " You can just write a variable on its own and semicolon is just a end of statement marker in Python", "tokens": [509, 393, 445, 2464, 257, 7006, 322, 1080, 1065, 293, 27515, 38780, 307, 445, 257, 917, 295, 5629, 15247, 294, 15329], "temperature": 0.0, "avg_logprob": -0.18383916219075522, "compression_ratio": 1.6134453781512605, "no_speech_prob": 2.6425714167999104e-06}, {"id": 307, "seek": 139208, "start": 1403.1999999999998, "end": 1406.3999999999999, "text": " So it's the same as doing this you can write it on phone and it fits it", "tokens": [407, 309, 311, 264, 912, 382, 884, 341, 291, 393, 2464, 309, 322, 2593, 293, 309, 9001, 309], "temperature": 0.0, "avg_logprob": -0.18383916219075522, "compression_ratio": 1.6134453781512605, "no_speech_prob": 2.6425714167999104e-06}, {"id": 308, "seek": 139208, "start": 1406.52, "end": 1414.6399999999999, "text": " You can also say print right? But again, we're trying to do everything fast and interactively just write it and here is the path", "tokens": [509, 393, 611, 584, 4482, 558, 30, 583, 797, 11, 321, 434, 1382, 281, 360, 1203, 2370, 293, 4648, 3413, 445, 2464, 309, 293, 510, 307, 264, 3100], "temperature": 0.0, "avg_logprob": -0.18383916219075522, "compression_ratio": 1.6134453781512605, "no_speech_prob": 2.6425714167999104e-06}, {"id": 309, "seek": 139208, "start": 1415.24, "end": 1417.24, "text": " Where it's given us our data?", "tokens": [2305, 309, 311, 2212, 505, 527, 1412, 30], "temperature": 0.0, "avg_logprob": -0.18383916219075522, "compression_ratio": 1.6134453781512605, "no_speech_prob": 2.6425714167999104e-06}, {"id": 310, "seek": 141724, "start": 1417.24, "end": 1421.52, "text": " Next time you run this since you've already downloaded it", "tokens": [3087, 565, 291, 1190, 341, 1670, 291, 600, 1217, 21748, 309], "temperature": 0.0, "avg_logprob": -0.1560353682591365, "compression_ratio": 1.7170542635658914, "no_speech_prob": 8.267812518170103e-06}, {"id": 311, "seek": 141724, "start": 1421.52, "end": 1425.02, "text": " It won't download it again since you've already untied it it won't untie it again", "tokens": [467, 1582, 380, 5484, 309, 797, 1670, 291, 600, 1217, 1701, 1091, 309, 309, 1582, 380, 1701, 414, 309, 797], "temperature": 0.0, "avg_logprob": -0.1560353682591365, "compression_ratio": 1.7170542635658914, "no_speech_prob": 8.267812518170103e-06}, {"id": 312, "seek": 141724, "start": 1425.02, "end": 1428.36, "text": " So everything is kind of designed to be pretty automatic pretty easy", "tokens": [407, 1203, 307, 733, 295, 4761, 281, 312, 1238, 12509, 1238, 1858], "temperature": 0.0, "avg_logprob": -0.1560353682591365, "compression_ratio": 1.7170542635658914, "no_speech_prob": 8.267812518170103e-06}, {"id": 313, "seek": 141724, "start": 1430.96, "end": 1432.96, "text": " There are some things in", "tokens": [821, 366, 512, 721, 294], "temperature": 0.0, "avg_logprob": -0.1560353682591365, "compression_ratio": 1.7170542635658914, "no_speech_prob": 8.267812518170103e-06}, {"id": 314, "seek": 141724, "start": 1433.0, "end": 1438.56, "text": " Python that are less convenient for interactive use than they should be for example when you do have a path object", "tokens": [15329, 300, 366, 1570, 10851, 337, 15141, 764, 813, 436, 820, 312, 337, 1365, 562, 291, 360, 362, 257, 3100, 2657], "temperature": 0.0, "avg_logprob": -0.1560353682591365, "compression_ratio": 1.7170542635658914, "no_speech_prob": 8.267812518170103e-06}, {"id": 315, "seek": 141724, "start": 1439.0, "end": 1443.96, "text": " Seeing what's in it actually is takes a lot more typing than I would like. So sometimes we add", "tokens": [19703, 437, 311, 294, 309, 767, 307, 2516, 257, 688, 544, 18444, 813, 286, 576, 411, 13, 407, 2171, 321, 909], "temperature": 0.0, "avg_logprob": -0.1560353682591365, "compression_ratio": 1.7170542635658914, "no_speech_prob": 8.267812518170103e-06}, {"id": 316, "seek": 144396, "start": 1443.96, "end": 1451.68, "text": " Functionality into existing Python stuff. One of the things we do is we add an LS method to paths. So if you go path.ls", "tokens": [11166, 882, 1860, 666, 6741, 15329, 1507, 13, 1485, 295, 264, 721, 321, 360, 307, 321, 909, 364, 36657, 3170, 281, 14518, 13, 407, 498, 291, 352, 3100, 13, 11784], "temperature": 0.0, "avg_logprob": -0.17516935096596772, "compression_ratio": 1.603846153846154, "no_speech_prob": 7.889198968769051e-06}, {"id": 317, "seek": 144396, "start": 1452.44, "end": 1454.44, "text": " Here is what's inside", "tokens": [1692, 307, 437, 311, 1854], "temperature": 0.0, "avg_logprob": -0.17516935096596772, "compression_ratio": 1.603846153846154, "no_speech_prob": 7.889198968769051e-06}, {"id": 318, "seek": 144396, "start": 1454.6000000000001, "end": 1458.16, "text": " This path so that's what we just downloaded. So when you try this yourself", "tokens": [639, 3100, 370, 300, 311, 437, 321, 445, 21748, 13, 407, 562, 291, 853, 341, 1803], "temperature": 0.0, "avg_logprob": -0.17516935096596772, "compression_ratio": 1.603846153846154, "no_speech_prob": 7.889198968769051e-06}, {"id": 319, "seek": 144396, "start": 1459.24, "end": 1461.24, "text": " You wait a couple minutes for it to download", "tokens": [509, 1699, 257, 1916, 2077, 337, 309, 281, 5484], "temperature": 0.0, "avg_logprob": -0.17516935096596772, "compression_ratio": 1.603846153846154, "no_speech_prob": 7.889198968769051e-06}, {"id": 320, "seek": 144396, "start": 1461.8400000000001, "end": 1464.04, "text": " Unzip and then you can see what's in there", "tokens": [1156, 27268, 293, 550, 291, 393, 536, 437, 311, 294, 456], "temperature": 0.0, "avg_logprob": -0.17516935096596772, "compression_ratio": 1.603846153846154, "no_speech_prob": 7.889198968769051e-06}, {"id": 321, "seek": 144396, "start": 1466.44, "end": 1472.3600000000001, "text": " If you're an experienced Python programmer you may not be familiar with this approach of using a slash like this", "tokens": [759, 291, 434, 364, 6751, 15329, 32116, 291, 815, 406, 312, 4963, 365, 341, 3109, 295, 1228, 257, 17330, 411, 341], "temperature": 0.0, "avg_logprob": -0.17516935096596772, "compression_ratio": 1.603846153846154, "no_speech_prob": 7.889198968769051e-06}, {"id": 322, "seek": 147236, "start": 1472.36, "end": 1478.08, "text": " Now this is a really convenient function that's part of Python 3 its functionality from something called pathlib", "tokens": [823, 341, 307, 257, 534, 10851, 2445, 300, 311, 644, 295, 15329, 805, 1080, 14980, 490, 746, 1219, 3100, 38270], "temperature": 0.0, "avg_logprob": -0.18913677126862283, "compression_ratio": 1.5732217573221758, "no_speech_prob": 3.611955889937235e-06}, {"id": 323, "seek": 147236, "start": 1478.12, "end": 1484.52, "text": " These are path objects path objects are much better to use than strings that lets you basically create", "tokens": [1981, 366, 3100, 6565, 3100, 6565, 366, 709, 1101, 281, 764, 813, 13985, 300, 6653, 291, 1936, 1884], "temperature": 0.0, "avg_logprob": -0.18913677126862283, "compression_ratio": 1.5732217573221758, "no_speech_prob": 3.611955889937235e-06}, {"id": 324, "seek": 147236, "start": 1485.1999999999998, "end": 1490.9199999999998, "text": " Subpaths like this doesn't matter if you're on Windows Linux Mac. It's always going to work exactly the same way", "tokens": [8511, 31852, 82, 411, 341, 1177, 380, 1871, 498, 291, 434, 322, 8591, 18734, 5707, 13, 467, 311, 1009, 516, 281, 589, 2293, 264, 912, 636], "temperature": 0.0, "avg_logprob": -0.18913677126862283, "compression_ratio": 1.5732217573221758, "no_speech_prob": 3.611955889937235e-06}, {"id": 325, "seek": 147236, "start": 1491.9599999999998, "end": 1495.4799999999998, "text": " So here's a path to the images in that data set", "tokens": [407, 510, 311, 257, 3100, 281, 264, 5267, 294, 300, 1412, 992], "temperature": 0.0, "avg_logprob": -0.18913677126862283, "compression_ratio": 1.5732217573221758, "no_speech_prob": 3.611955889937235e-06}, {"id": 326, "seek": 149548, "start": 1495.48, "end": 1502.88, "text": " All right, so if you're starting with a brand new data set trying to do some deep learning on it", "tokens": [1057, 558, 11, 370, 498, 291, 434, 2891, 365, 257, 3360, 777, 1412, 992, 1382, 281, 360, 512, 2452, 2539, 322, 309], "temperature": 0.0, "avg_logprob": -0.1456796910503123, "compression_ratio": 1.6266094420600858, "no_speech_prob": 7.527927209594054e-06}, {"id": 327, "seek": 149548, "start": 1503.1200000000001, "end": 1509.32, "text": " What do you do? Well, the first thing you would want to do is probably see what's in there. So we found that these are the", "tokens": [708, 360, 291, 360, 30, 1042, 11, 264, 700, 551, 291, 576, 528, 281, 360, 307, 1391, 536, 437, 311, 294, 456, 13, 407, 321, 1352, 300, 613, 366, 264], "temperature": 0.0, "avg_logprob": -0.1456796910503123, "compression_ratio": 1.6266094420600858, "no_speech_prob": 7.527927209594054e-06}, {"id": 328, "seek": 149548, "start": 1512.16, "end": 1514.52, "text": " Directories that are in there. So what's in this images?", "tokens": [7680, 530, 300, 366, 294, 456, 13, 407, 437, 311, 294, 341, 5267, 30], "temperature": 0.0, "avg_logprob": -0.1456796910503123, "compression_ratio": 1.6266094420600858, "no_speech_prob": 7.527927209594054e-06}, {"id": 329, "seek": 149548, "start": 1515.2, "end": 1518.42, "text": " There's a lot of functions in fast AI for you", "tokens": [821, 311, 257, 688, 295, 6828, 294, 2370, 7318, 337, 291], "temperature": 0.0, "avg_logprob": -0.1456796910503123, "compression_ratio": 1.6266094420600858, "no_speech_prob": 7.527927209594054e-06}, {"id": 330, "seek": 149548, "start": 1518.42, "end": 1521.1200000000001, "text": " there's one called get image files that will just grab a", "tokens": [456, 311, 472, 1219, 483, 3256, 7098, 300, 486, 445, 4444, 257], "temperature": 0.0, "avg_logprob": -0.1456796910503123, "compression_ratio": 1.6266094420600858, "no_speech_prob": 7.527927209594054e-06}, {"id": 331, "seek": 152112, "start": 1521.12, "end": 1525.5, "text": " Array of all of the image files based on extension in a path", "tokens": [1587, 3458, 295, 439, 295, 264, 3256, 7098, 2361, 322, 10320, 294, 257, 3100], "temperature": 0.0, "avg_logprob": -0.21784857865218277, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.933351541083539e-06}, {"id": 332, "seek": 152112, "start": 1526.5, "end": 1528.5, "text": " And so here you can see", "tokens": [400, 370, 510, 291, 393, 536], "temperature": 0.0, "avg_logprob": -0.21784857865218277, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.933351541083539e-06}, {"id": 333, "seek": 152112, "start": 1528.6399999999999, "end": 1533.12, "text": " We've got lots of different files. Okay, so this is a pretty", "tokens": [492, 600, 658, 3195, 295, 819, 7098, 13, 1033, 11, 370, 341, 307, 257, 1238], "temperature": 0.0, "avg_logprob": -0.21784857865218277, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.933351541083539e-06}, {"id": 334, "seek": 152112, "start": 1533.76, "end": 1539.7199999999998, "text": " Common way to for image computer vision data sets to get passed around is that there's just one folder with a whole bunch of", "tokens": [18235, 636, 281, 337, 3256, 3820, 5201, 1412, 6352, 281, 483, 4678, 926, 307, 300, 456, 311, 445, 472, 10820, 365, 257, 1379, 3840, 295], "temperature": 0.0, "avg_logprob": -0.21784857865218277, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.933351541083539e-06}, {"id": 335, "seek": 152112, "start": 1540.2399999999998, "end": 1541.56, "text": " files in", "tokens": [7098, 294], "temperature": 0.0, "avg_logprob": -0.21784857865218277, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.933351541083539e-06}, {"id": 336, "seek": 152112, "start": 1541.56, "end": 1543.8799999999999, "text": " so the interesting bit then is", "tokens": [370, 264, 1880, 857, 550, 307], "temperature": 0.0, "avg_logprob": -0.21784857865218277, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.933351541083539e-06}, {"id": 337, "seek": 152112, "start": 1544.6399999999999, "end": 1546.6399999999999, "text": " How do we get the labels?", "tokens": [1012, 360, 321, 483, 264, 16949, 30], "temperature": 0.0, "avg_logprob": -0.21784857865218277, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.933351541083539e-06}, {"id": 338, "seek": 154664, "start": 1546.64, "end": 1552.96, "text": " So in machine learning the labels refer to the thing we're trying to predict and if we just eyeball this", "tokens": [407, 294, 3479, 2539, 264, 16949, 2864, 281, 264, 551, 321, 434, 1382, 281, 6069, 293, 498, 321, 445, 38868, 341], "temperature": 0.0, "avg_logprob": -0.20151754867198857, "compression_ratio": 1.63013698630137, "no_speech_prob": 1.32877266878495e-06}, {"id": 339, "seek": 154664, "start": 1553.2800000000002, "end": 1556.3600000000001, "text": " We could immediately see that the labels", "tokens": [492, 727, 4258, 536, 300, 264, 16949], "temperature": 0.0, "avg_logprob": -0.20151754867198857, "compression_ratio": 1.63013698630137, "no_speech_prob": 1.32877266878495e-06}, {"id": 340, "seek": 154664, "start": 1557.3200000000002, "end": 1563.6200000000001, "text": " Actually part of the file name you see that right? It's kind of like path slash label", "tokens": [5135, 644, 295, 264, 3991, 1315, 291, 536, 300, 558, 30, 467, 311, 733, 295, 411, 3100, 17330, 7645], "temperature": 0.0, "avg_logprob": -0.20151754867198857, "compression_ratio": 1.63013698630137, "no_speech_prob": 1.32877266878495e-06}, {"id": 341, "seek": 154664, "start": 1564.1200000000001, "end": 1566.1200000000001, "text": " underscore number", "tokens": [37556, 1230], "temperature": 0.0, "avg_logprob": -0.20151754867198857, "compression_ratio": 1.63013698630137, "no_speech_prob": 1.32877266878495e-06}, {"id": 342, "seek": 154664, "start": 1566.1200000000001, "end": 1569.76, "text": " extension so we need to somehow get a list of", "tokens": [10320, 370, 321, 643, 281, 6063, 483, 257, 1329, 295], "temperature": 0.0, "avg_logprob": -0.20151754867198857, "compression_ratio": 1.63013698630137, "no_speech_prob": 1.32877266878495e-06}, {"id": 343, "seek": 154664, "start": 1570.8000000000002, "end": 1573.66, "text": " These bits of each file name and that will give us our labels", "tokens": [1981, 9239, 295, 1184, 3991, 1315, 293, 300, 486, 976, 505, 527, 16949], "temperature": 0.0, "avg_logprob": -0.20151754867198857, "compression_ratio": 1.63013698630137, "no_speech_prob": 1.32877266878495e-06}, {"id": 344, "seek": 157366, "start": 1573.66, "end": 1581.16, "text": " Because that's all you need to build a deep learning model in its in pictures. So files containing the images and you need some labels", "tokens": [1436, 300, 311, 439, 291, 643, 281, 1322, 257, 2452, 2539, 2316, 294, 1080, 294, 5242, 13, 407, 7098, 19273, 264, 5267, 293, 291, 643, 512, 16949], "temperature": 0.0, "avg_logprob": -0.1815159980286943, "compression_ratio": 1.7787610619469028, "no_speech_prob": 1.4063863090996165e-05}, {"id": 345, "seek": 157366, "start": 1582.46, "end": 1584.22, "text": " so in fast AI", "tokens": [370, 294, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.1815159980286943, "compression_ratio": 1.7787610619469028, "no_speech_prob": 1.4063863090996165e-05}, {"id": 346, "seek": 157366, "start": 1584.22, "end": 1586.74, "text": " This is made really easy. There's a", "tokens": [639, 307, 1027, 534, 1858, 13, 821, 311, 257], "temperature": 0.0, "avg_logprob": -0.1815159980286943, "compression_ratio": 1.7787610619469028, "no_speech_prob": 1.4063863090996165e-05}, {"id": 347, "seek": 157366, "start": 1587.74, "end": 1593.6200000000001, "text": " Object called image data bunch and an image data bunch represents all of the data you need to build a model", "tokens": [24753, 1219, 3256, 1412, 3840, 293, 364, 3256, 1412, 3840, 8855, 439, 295, 264, 1412, 291, 643, 281, 1322, 257, 2316], "temperature": 0.0, "avg_logprob": -0.1815159980286943, "compression_ratio": 1.7787610619469028, "no_speech_prob": 1.4063863090996165e-05}, {"id": 348, "seek": 157366, "start": 1593.6200000000001, "end": 1601.0600000000002, "text": " And there's basically some factory methods which try to make it really easy for you to create that data bunch", "tokens": [400, 456, 311, 1936, 512, 9265, 7150, 597, 853, 281, 652, 309, 534, 1858, 337, 291, 281, 1884, 300, 1412, 3840], "temperature": 0.0, "avg_logprob": -0.1815159980286943, "compression_ratio": 1.7787610619469028, "no_speech_prob": 1.4063863090996165e-05}, {"id": 349, "seek": 160106, "start": 1601.06, "end": 1607.36, "text": " Try we'll talk more about this shortly but a training set and a validation set with images and labels for you", "tokens": [6526, 321, 603, 751, 544, 466, 341, 13392, 457, 257, 3097, 992, 293, 257, 24071, 992, 365, 5267, 293, 16949, 337, 291], "temperature": 0.0, "avg_logprob": -0.19268201432138118, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.710886514658341e-06}, {"id": 350, "seek": 160106, "start": 1607.7, "end": 1610.8999999999999, "text": " Now in this case we can see we need to extract the labels", "tokens": [823, 294, 341, 1389, 321, 393, 536, 321, 643, 281, 8947, 264, 16949], "temperature": 0.0, "avg_logprob": -0.19268201432138118, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.710886514658341e-06}, {"id": 351, "seek": 160106, "start": 1611.82, "end": 1613.58, "text": " from the names", "tokens": [490, 264, 5288], "temperature": 0.0, "avg_logprob": -0.19268201432138118, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.710886514658341e-06}, {"id": 352, "seek": 160106, "start": 1613.58, "end": 1616.62, "text": " Okay, so we're going to use from name RE", "tokens": [1033, 11, 370, 321, 434, 516, 281, 764, 490, 1315, 10869], "temperature": 0.0, "avg_logprob": -0.19268201432138118, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.710886514658341e-06}, {"id": 353, "seek": 160106, "start": 1616.62, "end": 1622.22, "text": " So for those of you that use Python your know RE is the module in Python that does regular expressions things", "tokens": [407, 337, 729, 295, 291, 300, 764, 15329, 428, 458, 10869, 307, 264, 10088, 294, 15329, 300, 775, 3890, 15277, 721], "temperature": 0.0, "avg_logprob": -0.19268201432138118, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.710886514658341e-06}, {"id": 354, "seek": 160106, "start": 1622.22, "end": 1624.22, "text": " That's really useful for extracting", "tokens": [663, 311, 534, 4420, 337, 49844], "temperature": 0.0, "avg_logprob": -0.19268201432138118, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.710886514658341e-06}, {"id": 355, "seek": 160106, "start": 1624.3799999999999, "end": 1630.28, "text": " Text I just went ahead and created the regular expression that would extract the", "tokens": [18643, 286, 445, 1437, 2286, 293, 2942, 264, 3890, 6114, 300, 576, 8947, 264], "temperature": 0.0, "avg_logprob": -0.19268201432138118, "compression_ratio": 1.7307692307692308, "no_speech_prob": 4.710886514658341e-06}, {"id": 356, "seek": 163028, "start": 1630.28, "end": 1632.28, "text": " label from this text", "tokens": [7645, 490, 341, 2487], "temperature": 0.0, "avg_logprob": -0.19632257441038725, "compression_ratio": 1.6153846153846154, "no_speech_prob": 6.6433913161745295e-06}, {"id": 357, "seek": 163028, "start": 1633.24, "end": 1635.24, "text": " so those of you who", "tokens": [370, 729, 295, 291, 567], "temperature": 0.0, "avg_logprob": -0.19632257441038725, "compression_ratio": 1.6153846153846154, "no_speech_prob": 6.6433913161745295e-06}, {"id": 358, "seek": 163028, "start": 1635.92, "end": 1639.04, "text": " Not familiar with regular expressions super useful tool", "tokens": [1726, 4963, 365, 3890, 15277, 1687, 4420, 2290], "temperature": 0.0, "avg_logprob": -0.19632257441038725, "compression_ratio": 1.6153846153846154, "no_speech_prob": 6.6433913161745295e-06}, {"id": 359, "seek": 163028, "start": 1639.16, "end": 1647.1, "text": " It'd be very useful to spend some time figuring out how and why that particular regular expression is going to extract the label", "tokens": [467, 1116, 312, 588, 4420, 281, 3496, 512, 565, 15213, 484, 577, 293, 983, 300, 1729, 3890, 6114, 307, 516, 281, 8947, 264, 7645], "temperature": 0.0, "avg_logprob": -0.19632257441038725, "compression_ratio": 1.6153846153846154, "no_speech_prob": 6.6433913161745295e-06}, {"id": 360, "seek": 163028, "start": 1647.6399999999999, "end": 1654.04, "text": " From this text. Okay, so with this factory method we can basically say okay. I've got this path containing images", "tokens": [3358, 341, 2487, 13, 1033, 11, 370, 365, 341, 9265, 3170, 321, 393, 1936, 584, 1392, 13, 286, 600, 658, 341, 3100, 19273, 5267], "temperature": 0.0, "avg_logprob": -0.19632257441038725, "compression_ratio": 1.6153846153846154, "no_speech_prob": 6.6433913161745295e-06}, {"id": 361, "seek": 163028, "start": 1654.92, "end": 1657.52, "text": " This is a list of file names. Remember I got them back here", "tokens": [639, 307, 257, 1329, 295, 3991, 5288, 13, 5459, 286, 658, 552, 646, 510], "temperature": 0.0, "avg_logprob": -0.19632257441038725, "compression_ratio": 1.6153846153846154, "no_speech_prob": 6.6433913161745295e-06}, {"id": 362, "seek": 165752, "start": 1657.52, "end": 1664.6, "text": " This is the regular expression pattern that is going to be used to extract the label from the file name", "tokens": [639, 307, 264, 3890, 6114, 5102, 300, 307, 516, 281, 312, 1143, 281, 8947, 264, 7645, 490, 264, 3991, 1315], "temperature": 0.0, "avg_logprob": -0.15048805359871156, "compression_ratio": 1.7442922374429224, "no_speech_prob": 6.339169885904994e-06}, {"id": 363, "seek": 165752, "start": 1665.6, "end": 1667.6, "text": " We'll talk about transforms later", "tokens": [492, 603, 751, 466, 35592, 1780], "temperature": 0.0, "avg_logprob": -0.15048805359871156, "compression_ratio": 1.7442922374429224, "no_speech_prob": 6.339169885904994e-06}, {"id": 364, "seek": 165752, "start": 1668.48, "end": 1674.08, "text": " And then you also need to say what size images do you want to work with? So that might seem weird", "tokens": [400, 550, 291, 611, 643, 281, 584, 437, 2744, 5267, 360, 291, 528, 281, 589, 365, 30, 407, 300, 1062, 1643, 3657], "temperature": 0.0, "avg_logprob": -0.15048805359871156, "compression_ratio": 1.7442922374429224, "no_speech_prob": 6.339169885904994e-06}, {"id": 365, "seek": 165752, "start": 1674.16, "end": 1676.96, "text": " Why do I need to say what size images I want to work with?", "tokens": [1545, 360, 286, 643, 281, 584, 437, 2744, 5267, 286, 528, 281, 589, 365, 30], "temperature": 0.0, "avg_logprob": -0.15048805359871156, "compression_ratio": 1.7442922374429224, "no_speech_prob": 6.339169885904994e-06}, {"id": 366, "seek": 165752, "start": 1677.4, "end": 1682.56, "text": " Because the images have a size we can see what size the images are and I guess honestly", "tokens": [1436, 264, 5267, 362, 257, 2744, 321, 393, 536, 437, 2744, 264, 5267, 366, 293, 286, 2041, 6095], "temperature": 0.0, "avg_logprob": -0.15048805359871156, "compression_ratio": 1.7442922374429224, "no_speech_prob": 6.339169885904994e-06}, {"id": 367, "seek": 168256, "start": 1682.56, "end": 1688.52, "text": " This is a shortcoming of current deep learning technology, which is that a GPU?", "tokens": [639, 307, 257, 2099, 6590, 295, 2190, 2452, 2539, 2899, 11, 597, 307, 300, 257, 18407, 30], "temperature": 0.0, "avg_logprob": -0.17541182771021005, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.5294083368644351e-06}, {"id": 368, "seek": 168256, "start": 1689.36, "end": 1696.72, "text": " Has to apply the exact same instruction to a whole bunch of things at the same time in order to be fast and", "tokens": [8646, 281, 3079, 264, 1900, 912, 10951, 281, 257, 1379, 3840, 295, 721, 412, 264, 912, 565, 294, 1668, 281, 312, 2370, 293], "temperature": 0.0, "avg_logprob": -0.17541182771021005, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.5294083368644351e-06}, {"id": 369, "seek": 168256, "start": 1697.24, "end": 1701.36, "text": " So if the images are different shapes and sizes, they can't do that", "tokens": [407, 498, 264, 5267, 366, 819, 10854, 293, 11602, 11, 436, 393, 380, 360, 300], "temperature": 0.0, "avg_logprob": -0.17541182771021005, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.5294083368644351e-06}, {"id": 370, "seek": 168256, "start": 1702.0, "end": 1707.06, "text": " Okay, so we actually have to make all of the images the same shape and size", "tokens": [1033, 11, 370, 321, 767, 362, 281, 652, 439, 295, 264, 5267, 264, 912, 3909, 293, 2744], "temperature": 0.0, "avg_logprob": -0.17541182771021005, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.5294083368644351e-06}, {"id": 371, "seek": 168256, "start": 1708.28, "end": 1711.3, "text": " In part one of the course, we're always going to be making", "tokens": [682, 644, 472, 295, 264, 1164, 11, 321, 434, 1009, 516, 281, 312, 1455], "temperature": 0.0, "avg_logprob": -0.17541182771021005, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.5294083368644351e-06}, {"id": 372, "seek": 171130, "start": 1711.3, "end": 1712.78, "text": " images", "tokens": [5267], "temperature": 0.0, "avg_logprob": -0.23699878824168238, "compression_ratio": 1.5659574468085107, "no_speech_prob": 9.666035111877136e-06}, {"id": 373, "seek": 171130, "start": 1712.78, "end": 1719.26, "text": " Square shapes in part two will learn how to use rectangles as well. It turns out to be surprisingly nuanced", "tokens": [16463, 10854, 294, 644, 732, 486, 1466, 577, 281, 764, 24077, 904, 382, 731, 13, 467, 4523, 484, 281, 312, 17600, 45115], "temperature": 0.0, "avg_logprob": -0.23699878824168238, "compression_ratio": 1.5659574468085107, "no_speech_prob": 9.666035111877136e-06}, {"id": 374, "seek": 171130, "start": 1719.26, "end": 1726.68, "text": " That pretty much everybody in pretty much all computer vision modeling nearly all of it uses this approach of square", "tokens": [663, 1238, 709, 2201, 294, 1238, 709, 439, 3820, 5201, 15983, 6217, 439, 295, 309, 4960, 341, 3109, 295, 3732], "temperature": 0.0, "avg_logprob": -0.23699878824168238, "compression_ratio": 1.5659574468085107, "no_speech_prob": 9.666035111877136e-06}, {"id": 375, "seek": 171130, "start": 1727.46, "end": 1734.9199999999998, "text": " And 224 by 224 for reasons we'll learn about is an extremely common size that most models tend to use", "tokens": [400, 5853, 19, 538, 5853, 19, 337, 4112, 321, 603, 1466, 466, 307, 364, 4664, 2689, 2744, 300, 881, 5245, 3928, 281, 764], "temperature": 0.0, "avg_logprob": -0.23699878824168238, "compression_ratio": 1.5659574468085107, "no_speech_prob": 9.666035111877136e-06}, {"id": 376, "seek": 171130, "start": 1734.98, "end": 1737.26, "text": " So if you just use size equals 224", "tokens": [407, 498, 291, 445, 764, 2744, 6915, 5853, 19], "temperature": 0.0, "avg_logprob": -0.23699878824168238, "compression_ratio": 1.5659574468085107, "no_speech_prob": 9.666035111877136e-06}, {"id": 377, "seek": 173726, "start": 1737.26, "end": 1741.98, "text": " You're probably going to get pretty good results most of the time and this is kind of", "tokens": [509, 434, 1391, 516, 281, 483, 1238, 665, 3542, 881, 295, 264, 565, 293, 341, 307, 733, 295], "temperature": 0.0, "avg_logprob": -0.15219949967790358, "compression_ratio": 1.7107438016528926, "no_speech_prob": 2.9480047487595584e-06}, {"id": 378, "seek": 173726, "start": 1742.78, "end": 1748.7, "text": " The little bits of artisan ship that I want to teach you folks, which is like what generally just works", "tokens": [440, 707, 9239, 295, 1523, 14804, 5374, 300, 286, 528, 281, 2924, 291, 4024, 11, 597, 307, 411, 437, 5101, 445, 1985], "temperature": 0.0, "avg_logprob": -0.15219949967790358, "compression_ratio": 1.7107438016528926, "no_speech_prob": 2.9480047487595584e-06}, {"id": 379, "seek": 173726, "start": 1749.02, "end": 1754.6, "text": " Okay, so if you just use size equals 224 that'll generally just work for most things most of the time", "tokens": [1033, 11, 370, 498, 291, 445, 764, 2744, 6915, 5853, 19, 300, 603, 5101, 445, 589, 337, 881, 721, 881, 295, 264, 565], "temperature": 0.0, "avg_logprob": -0.15219949967790358, "compression_ratio": 1.7107438016528926, "no_speech_prob": 2.9480047487595584e-06}, {"id": 380, "seek": 173726, "start": 1756.54, "end": 1758.54, "text": " So this is going to return a", "tokens": [407, 341, 307, 516, 281, 2736, 257], "temperature": 0.0, "avg_logprob": -0.15219949967790358, "compression_ratio": 1.7107438016528926, "no_speech_prob": 2.9480047487595584e-06}, {"id": 381, "seek": 173726, "start": 1759.18, "end": 1764.46, "text": " Data bunch object and in fast AI everything you model with is going to be a data bunch object", "tokens": [11888, 3840, 2657, 293, 294, 2370, 7318, 1203, 291, 2316, 365, 307, 516, 281, 312, 257, 1412, 3840, 2657], "temperature": 0.0, "avg_logprob": -0.15219949967790358, "compression_ratio": 1.7107438016528926, "no_speech_prob": 2.9480047487595584e-06}, {"id": 382, "seek": 176446, "start": 1764.46, "end": 1767.56, "text": " We're going to learn all about them and what's in them and how do we look at them and so forth?", "tokens": [492, 434, 516, 281, 1466, 439, 466, 552, 293, 437, 311, 294, 552, 293, 577, 360, 321, 574, 412, 552, 293, 370, 5220, 30], "temperature": 0.0, "avg_logprob": -0.16379752401578224, "compression_ratio": 1.9835390946502058, "no_speech_prob": 9.666007827036083e-06}, {"id": 383, "seek": 176446, "start": 1767.56, "end": 1769.98, "text": " But basically a data bunch object contains", "tokens": [583, 1936, 257, 1412, 3840, 2657, 8306], "temperature": 0.0, "avg_logprob": -0.16379752401578224, "compression_ratio": 1.9835390946502058, "no_speech_prob": 9.666007827036083e-06}, {"id": 384, "seek": 176446, "start": 1770.58, "end": 1772.58, "text": " two or three", "tokens": [732, 420, 1045], "temperature": 0.0, "avg_logprob": -0.16379752401578224, "compression_ratio": 1.9835390946502058, "no_speech_prob": 9.666007827036083e-06}, {"id": 385, "seek": 176446, "start": 1773.26, "end": 1775.26, "text": " Datasets it contains your training data", "tokens": [9315, 296, 1385, 309, 8306, 428, 3097, 1412], "temperature": 0.0, "avg_logprob": -0.16379752401578224, "compression_ratio": 1.9835390946502058, "no_speech_prob": 9.666007827036083e-06}, {"id": 386, "seek": 176446, "start": 1775.8600000000001, "end": 1781.3, "text": " We'll learn about this shortly. It'll contain your validation data and optionally it contains your test data", "tokens": [492, 603, 1466, 466, 341, 13392, 13, 467, 603, 5304, 428, 24071, 1412, 293, 3614, 379, 309, 8306, 428, 1500, 1412], "temperature": 0.0, "avg_logprob": -0.16379752401578224, "compression_ratio": 1.9835390946502058, "no_speech_prob": 9.666007827036083e-06}, {"id": 387, "seek": 176446, "start": 1781.3, "end": 1783.76, "text": " and for each of those it contains your", "tokens": [293, 337, 1184, 295, 729, 309, 8306, 428], "temperature": 0.0, "avg_logprob": -0.16379752401578224, "compression_ratio": 1.9835390946502058, "no_speech_prob": 9.666007827036083e-06}, {"id": 388, "seek": 176446, "start": 1785.26, "end": 1791.5, "text": " Your images and your labels or your texts and your labels or your tabular data and your labels or so forth", "tokens": [2260, 5267, 293, 428, 16949, 420, 428, 15765, 293, 428, 16949, 420, 428, 4421, 1040, 1412, 293, 428, 16949, 420, 370, 5220], "temperature": 0.0, "avg_logprob": -0.16379752401578224, "compression_ratio": 1.9835390946502058, "no_speech_prob": 9.666007827036083e-06}, {"id": 389, "seek": 179150, "start": 1791.5, "end": 1795.1, "text": " And that all sits there in this one place", "tokens": [400, 300, 439, 12696, 456, 294, 341, 472, 1081], "temperature": 0.0, "avg_logprob": -0.16725758945240693, "compression_ratio": 1.7383177570093458, "no_speech_prob": 1.0615969586069696e-05}, {"id": 390, "seek": 179150, "start": 1796.22, "end": 1798.22, "text": " Something we'll learn more about a little bit is", "tokens": [6595, 321, 603, 1466, 544, 466, 257, 707, 857, 307], "temperature": 0.0, "avg_logprob": -0.16725758945240693, "compression_ratio": 1.7383177570093458, "no_speech_prob": 1.0615969586069696e-05}, {"id": 391, "seek": 179150, "start": 1798.94, "end": 1804.34, "text": " Normalization but generally in all nearly all machine learning tasks you have to make all of your data", "tokens": [21277, 2144, 457, 5101, 294, 439, 6217, 439, 3479, 2539, 9608, 291, 362, 281, 652, 439, 295, 428, 1412], "temperature": 0.0, "avg_logprob": -0.16725758945240693, "compression_ratio": 1.7383177570093458, "no_speech_prob": 1.0615969586069696e-05}, {"id": 392, "seek": 179150, "start": 1804.82, "end": 1809.58, "text": " About the same size specifically about the same mean and about the same standard deviation", "tokens": [7769, 264, 912, 2744, 4682, 466, 264, 912, 914, 293, 466, 264, 912, 3832, 25163], "temperature": 0.0, "avg_logprob": -0.16725758945240693, "compression_ratio": 1.7383177570093458, "no_speech_prob": 1.0615969586069696e-05}, {"id": 393, "seek": 179150, "start": 1810.26, "end": 1816.28, "text": " So there's a normalize function that we can use to normalize our data bunch in that way", "tokens": [407, 456, 311, 257, 2710, 1125, 2445, 300, 321, 393, 764, 281, 2710, 1125, 527, 1412, 3840, 294, 300, 636], "temperature": 0.0, "avg_logprob": -0.16725758945240693, "compression_ratio": 1.7383177570093458, "no_speech_prob": 1.0615969586069696e-05}, {"id": 394, "seek": 181628, "start": 1816.28, "end": 1818.28, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.2240758308997521, "compression_ratio": 1.5238095238095237, "no_speech_prob": 2.4824569209158653e-06}, {"id": 395, "seek": 181628, "start": 1819.72, "end": 1822.08, "text": " Okay, Rachel come and ask the question", "tokens": [1033, 11, 14246, 808, 293, 1029, 264, 1168], "temperature": 0.0, "avg_logprob": -0.2240758308997521, "compression_ratio": 1.5238095238095237, "no_speech_prob": 2.4824569209158653e-06}, {"id": 396, "seek": 181628, "start": 1825.8, "end": 1829.3799999999999, "text": " What is the function do if the image size is not 224", "tokens": [708, 307, 264, 2445, 360, 498, 264, 3256, 2744, 307, 406, 5853, 19], "temperature": 0.0, "avg_logprob": -0.2240758308997521, "compression_ratio": 1.5238095238095237, "no_speech_prob": 2.4824569209158653e-06}, {"id": 397, "seek": 181628, "start": 1830.8, "end": 1832.6, "text": " Great so", "tokens": [3769, 370], "temperature": 0.0, "avg_logprob": -0.2240758308997521, "compression_ratio": 1.5238095238095237, "no_speech_prob": 2.4824569209158653e-06}, {"id": 398, "seek": 181628, "start": 1832.6, "end": 1834.6, "text": " This is what we're going to learn about shortly", "tokens": [639, 307, 437, 321, 434, 516, 281, 1466, 466, 13392], "temperature": 0.0, "avg_logprob": -0.2240758308997521, "compression_ratio": 1.5238095238095237, "no_speech_prob": 2.4824569209158653e-06}, {"id": 399, "seek": 181628, "start": 1834.72, "end": 1840.6399999999999, "text": " Basically this thing called transforms is is used to do a number of things and one of the things it does is to make something", "tokens": [8537, 341, 551, 1219, 35592, 307, 307, 1143, 281, 360, 257, 1230, 295, 721, 293, 472, 295, 264, 721, 309, 775, 307, 281, 652, 746], "temperature": 0.0, "avg_logprob": -0.2240758308997521, "compression_ratio": 1.5238095238095237, "no_speech_prob": 2.4824569209158653e-06}, {"id": 400, "seek": 181628, "start": 1841.16, "end": 1843.16, "text": " size 224", "tokens": [2744, 5853, 19], "temperature": 0.0, "avg_logprob": -0.2240758308997521, "compression_ratio": 1.5238095238095237, "no_speech_prob": 2.4824569209158653e-06}, {"id": 401, "seek": 184316, "start": 1843.16, "end": 1848.8000000000002, "text": " Let's take a look at a few pictures. Here are a few pictures of things from my data from my data bunch", "tokens": [961, 311, 747, 257, 574, 412, 257, 1326, 5242, 13, 1692, 366, 257, 1326, 5242, 295, 721, 490, 452, 1412, 490, 452, 1412, 3840], "temperature": 0.0, "avg_logprob": -0.15586514308534818, "compression_ratio": 1.7976190476190477, "no_speech_prob": 2.9479981549229706e-06}, {"id": 402, "seek": 184316, "start": 1848.8000000000002, "end": 1850.8000000000002, "text": " So you can see data dot show batch", "tokens": [407, 291, 393, 536, 1412, 5893, 855, 15245], "temperature": 0.0, "avg_logprob": -0.15586514308534818, "compression_ratio": 1.7976190476190477, "no_speech_prob": 2.9479981549229706e-06}, {"id": 403, "seek": 184316, "start": 1851.3600000000001, "end": 1856.22, "text": " Can be used to show me the contents of some of the contents of my data bunch", "tokens": [1664, 312, 1143, 281, 855, 385, 264, 15768, 295, 512, 295, 264, 15768, 295, 452, 1412, 3840], "temperature": 0.0, "avg_logprob": -0.15586514308534818, "compression_ratio": 1.7976190476190477, "no_speech_prob": 2.9479981549229706e-06}, {"id": 404, "seek": 184316, "start": 1857.0, "end": 1859.0, "text": " So this is going to be three by three", "tokens": [407, 341, 307, 516, 281, 312, 1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.15586514308534818, "compression_ratio": 1.7976190476190477, "no_speech_prob": 2.9479981549229706e-06}, {"id": 405, "seek": 184316, "start": 1859.68, "end": 1866.5800000000002, "text": " And you can see roughly what's happened is that they all seem to have been kind of zoomed and cropped in a reasonably nice way", "tokens": [400, 291, 393, 536, 9810, 437, 311, 2011, 307, 300, 436, 439, 1643, 281, 362, 668, 733, 295, 8863, 292, 293, 4848, 3320, 294, 257, 23551, 1481, 636], "temperature": 0.0, "avg_logprob": -0.15586514308534818, "compression_ratio": 1.7976190476190477, "no_speech_prob": 2.9479981549229706e-06}, {"id": 406, "seek": 184316, "start": 1866.7, "end": 1870.24, "text": " So basically what it'll do is something called by default", "tokens": [407, 1936, 437, 309, 603, 360, 307, 746, 1219, 538, 7576], "temperature": 0.0, "avg_logprob": -0.15586514308534818, "compression_ratio": 1.7976190476190477, "no_speech_prob": 2.9479981549229706e-06}, {"id": 407, "seek": 184316, "start": 1871.1200000000001, "end": 1872.5600000000002, "text": " center cropping", "tokens": [3056, 4848, 3759], "temperature": 0.0, "avg_logprob": -0.15586514308534818, "compression_ratio": 1.7976190476190477, "no_speech_prob": 2.9479981549229706e-06}, {"id": 408, "seek": 187256, "start": 1872.56, "end": 1877.26, "text": " Which means it'll kind of grab the middle bit and it will also resize it", "tokens": [3013, 1355, 309, 603, 733, 295, 4444, 264, 2808, 857, 293, 309, 486, 611, 50069, 309], "temperature": 0.0, "avg_logprob": -0.1273155128746702, "compression_ratio": 1.7672727272727273, "no_speech_prob": 6.643384494964266e-06}, {"id": 409, "seek": 187256, "start": 1877.56, "end": 1881.24, "text": " So we'll talk more about the detail of this because it turns out to actually be quite important", "tokens": [407, 321, 603, 751, 544, 466, 264, 2607, 295, 341, 570, 309, 4523, 484, 281, 767, 312, 1596, 1021], "temperature": 0.0, "avg_logprob": -0.1273155128746702, "compression_ratio": 1.7672727272727273, "no_speech_prob": 6.643384494964266e-06}, {"id": 410, "seek": 187256, "start": 1881.24, "end": 1885.84, "text": " But basically a combination of cropping and resizing is used", "tokens": [583, 1936, 257, 6562, 295, 4848, 3759, 293, 725, 3319, 307, 1143], "temperature": 0.0, "avg_logprob": -0.1273155128746702, "compression_ratio": 1.7672727272727273, "no_speech_prob": 6.643384494964266e-06}, {"id": 411, "seek": 187256, "start": 1887.04, "end": 1891.12, "text": " Something else we'll learn about is we also use this to do something called data augmentation", "tokens": [6595, 1646, 321, 603, 1466, 466, 307, 321, 611, 764, 341, 281, 360, 746, 1219, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.1273155128746702, "compression_ratio": 1.7672727272727273, "no_speech_prob": 6.643384494964266e-06}, {"id": 412, "seek": 187256, "start": 1891.12, "end": 1895.8799999999999, "text": " So there's actually some randomization in how much and where it crops and stuff like that", "tokens": [407, 456, 311, 767, 512, 4974, 2144, 294, 577, 709, 293, 689, 309, 16829, 293, 1507, 411, 300], "temperature": 0.0, "avg_logprob": -0.1273155128746702, "compression_ratio": 1.7672727272727273, "no_speech_prob": 6.643384494964266e-06}, {"id": 413, "seek": 187256, "start": 1896.0, "end": 1901.72, "text": " Okay, but that's the basic idea is some cropping and some resizing often", "tokens": [1033, 11, 457, 300, 311, 264, 3875, 1558, 307, 512, 4848, 3759, 293, 512, 725, 3319, 2049], "temperature": 0.0, "avg_logprob": -0.1273155128746702, "compression_ratio": 1.7672727272727273, "no_speech_prob": 6.643384494964266e-06}, {"id": 414, "seek": 190172, "start": 1901.72, "end": 1907.52, "text": " We also also do some some padding so there's all kinds of different ways and it depends on data augmentation", "tokens": [492, 611, 611, 360, 512, 512, 39562, 370, 456, 311, 439, 3685, 295, 819, 2098, 293, 309, 5946, 322, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.19757500816794002, "compression_ratio": 1.9363636363636363, "no_speech_prob": 6.854261755506741e-06}, {"id": 415, "seek": 190172, "start": 1908.0, "end": 1910.0, "text": " Which we're going to learn about shortly", "tokens": [3013, 321, 434, 516, 281, 1466, 466, 13392], "temperature": 0.0, "avg_logprob": -0.19757500816794002, "compression_ratio": 1.9363636363636363, "no_speech_prob": 6.854261755506741e-06}, {"id": 416, "seek": 190172, "start": 1911.44, "end": 1914.16, "text": " And what does it mean to normalize the images", "tokens": [400, 437, 775, 309, 914, 281, 2710, 1125, 264, 5267], "temperature": 0.0, "avg_logprob": -0.19757500816794002, "compression_ratio": 1.9363636363636363, "no_speech_prob": 6.854261755506741e-06}, {"id": 417, "seek": 190172, "start": 1916.2, "end": 1920.04, "text": " So normalizing the images we're going to be learning more about later in the course", "tokens": [407, 2710, 3319, 264, 5267, 321, 434, 516, 281, 312, 2539, 544, 466, 1780, 294, 264, 1164], "temperature": 0.0, "avg_logprob": -0.19757500816794002, "compression_ratio": 1.9363636363636363, "no_speech_prob": 6.854261755506741e-06}, {"id": 418, "seek": 190172, "start": 1920.24, "end": 1926.88, "text": " But in short it means that the the pixel values and we're going to be learning more about pixel values the pixel values start out", "tokens": [583, 294, 2099, 309, 1355, 300, 264, 264, 19261, 4190, 293, 321, 434, 516, 281, 312, 2539, 544, 466, 19261, 4190, 264, 19261, 4190, 722, 484], "temperature": 0.0, "avg_logprob": -0.19757500816794002, "compression_ratio": 1.9363636363636363, "no_speech_prob": 6.854261755506741e-06}, {"id": 419, "seek": 190172, "start": 1926.88, "end": 1928.88, "text": " from more to 255", "tokens": [490, 544, 281, 3552, 20], "temperature": 0.0, "avg_logprob": -0.19757500816794002, "compression_ratio": 1.9363636363636363, "no_speech_prob": 6.854261755506741e-06}, {"id": 420, "seek": 192888, "start": 1928.88, "end": 1932.5600000000002, "text": " and some pixel values might tend to be", "tokens": [293, 512, 19261, 4190, 1062, 3928, 281, 312], "temperature": 0.0, "avg_logprob": -0.22723445185908564, "compression_ratio": 1.9399141630901287, "no_speech_prob": 7.76688648329582e-06}, {"id": 421, "seek": 192888, "start": 1934.0800000000002, "end": 1936.0800000000002, "text": " Really I", "tokens": [4083, 286], "temperature": 0.0, "avg_logprob": -0.22723445185908564, "compression_ratio": 1.9399141630901287, "no_speech_prob": 7.76688648329582e-06}, {"id": 422, "seek": 192888, "start": 1936.3200000000002, "end": 1940.5200000000002, "text": " Should say some channels because there's red green and blue so some channels might tend to be", "tokens": [6454, 584, 512, 9235, 570, 456, 311, 2182, 3092, 293, 3344, 370, 512, 9235, 1062, 3928, 281, 312], "temperature": 0.0, "avg_logprob": -0.22723445185908564, "compression_ratio": 1.9399141630901287, "no_speech_prob": 7.76688648329582e-06}, {"id": 423, "seek": 192888, "start": 1940.8400000000001, "end": 1946.24, "text": " Really bright and some might tend to be really not right at all and some might vary a lot and some might not very much", "tokens": [4083, 4730, 293, 512, 1062, 3928, 281, 312, 534, 406, 558, 412, 439, 293, 512, 1062, 10559, 257, 688, 293, 512, 1062, 406, 588, 709], "temperature": 0.0, "avg_logprob": -0.22723445185908564, "compression_ratio": 1.9399141630901287, "no_speech_prob": 7.76688648329582e-06}, {"id": 424, "seek": 192888, "start": 1946.24, "end": 1953.48, "text": " At all it really helps train a deep learning model if each one of those red green and blue channels has a mean of zero", "tokens": [1711, 439, 309, 534, 3665, 3847, 257, 2452, 2539, 2316, 498, 1184, 472, 295, 729, 2182, 3092, 293, 3344, 9235, 575, 257, 914, 295, 4018], "temperature": 0.0, "avg_logprob": -0.22723445185908564, "compression_ratio": 1.9399141630901287, "no_speech_prob": 7.76688648329582e-06}, {"id": 425, "seek": 195348, "start": 1953.48, "end": 1961.34, "text": " In a standard deviation of one. Okay, we'll learn more about that if you haven't studied or don't remember means and standard deviations", "tokens": [682, 257, 3832, 25163, 295, 472, 13, 1033, 11, 321, 603, 1466, 544, 466, 300, 498, 291, 2378, 380, 9454, 420, 500, 380, 1604, 1355, 293, 3832, 31219, 763], "temperature": 0.0, "avg_logprob": -0.15158214088247604, "compression_ratio": 1.8082706766917294, "no_speech_prob": 2.406089379292098e-06}, {"id": 426, "seek": 195348, "start": 1961.34, "end": 1964.3600000000001, "text": " We'll get back to some of that later, but that's the basic idea", "tokens": [492, 603, 483, 646, 281, 512, 295, 300, 1780, 11, 457, 300, 311, 264, 3875, 1558], "temperature": 0.0, "avg_logprob": -0.15158214088247604, "compression_ratio": 1.8082706766917294, "no_speech_prob": 2.406089379292098e-06}, {"id": 427, "seek": 195348, "start": 1964.3600000000001, "end": 1969.4, "text": " That's what normalization does if your data and again, we'll learn much more about the details", "tokens": [663, 311, 437, 2710, 2144, 775, 498, 428, 1412, 293, 797, 11, 321, 603, 1466, 709, 544, 466, 264, 4365], "temperature": 0.0, "avg_logprob": -0.15158214088247604, "compression_ratio": 1.8082706766917294, "no_speech_prob": 2.406089379292098e-06}, {"id": 428, "seek": 195348, "start": 1969.4, "end": 1974.72, "text": " But if your data is not normalized, it can be quite difficult for your model to train", "tokens": [583, 498, 428, 1412, 307, 406, 48704, 11, 309, 393, 312, 1596, 2252, 337, 428, 2316, 281, 3847], "temperature": 0.0, "avg_logprob": -0.15158214088247604, "compression_ratio": 1.8082706766917294, "no_speech_prob": 2.406089379292098e-06}, {"id": 429, "seek": 195348, "start": 1974.72, "end": 1979.04, "text": " Well, so if you do have trouble training a model one thing to check is that you've normalized it", "tokens": [1042, 11, 370, 498, 291, 360, 362, 5253, 3097, 257, 2316, 472, 551, 281, 1520, 307, 300, 291, 600, 48704, 309], "temperature": 0.0, "avg_logprob": -0.15158214088247604, "compression_ratio": 1.8082706766917294, "no_speech_prob": 2.406089379292098e-06}, {"id": 430, "seek": 195348, "start": 1979.92, "end": 1981.48, "text": " as", "tokens": [382], "temperature": 0.0, "avg_logprob": -0.15158214088247604, "compression_ratio": 1.8082706766917294, "no_speech_prob": 2.406089379292098e-06}, {"id": 431, "seek": 198148, "start": 1981.48, "end": 1988.64, "text": " GPU man will be empowered to doesn't size 256 sound more practical considering GPU little utilization", "tokens": [18407, 587, 486, 312, 27898, 281, 1177, 380, 2744, 38882, 1626, 544, 8496, 8079, 18407, 707, 37074], "temperature": 0.0, "avg_logprob": -0.17814499681646173, "compression_ratio": 1.5355648535564854, "no_speech_prob": 1.0289360034221318e-05}, {"id": 432, "seek": 198148, "start": 1990.16, "end": 1994.88, "text": " So we're going to be getting into that shortly, but the brief answer is that the", "tokens": [407, 321, 434, 516, 281, 312, 1242, 666, 300, 13392, 11, 457, 264, 5353, 1867, 307, 300, 264], "temperature": 0.0, "avg_logprob": -0.17814499681646173, "compression_ratio": 1.5355648535564854, "no_speech_prob": 1.0289360034221318e-05}, {"id": 433, "seek": 198148, "start": 1995.48, "end": 1999.68, "text": " Models are designed so that the final layer is of size 7 by 7", "tokens": [6583, 1625, 366, 4761, 370, 300, 264, 2572, 4583, 307, 295, 2744, 1614, 538, 1614], "temperature": 0.0, "avg_logprob": -0.17814499681646173, "compression_ratio": 1.5355648535564854, "no_speech_prob": 1.0289360034221318e-05}, {"id": 434, "seek": 198148, "start": 1999.88, "end": 2006.48, "text": " So we actually want something where if you go 7 times to a bunch of times then you end up with something. It's a good size", "tokens": [407, 321, 767, 528, 746, 689, 498, 291, 352, 1614, 1413, 281, 257, 3840, 295, 1413, 550, 291, 917, 493, 365, 746, 13, 467, 311, 257, 665, 2744], "temperature": 0.0, "avg_logprob": -0.17814499681646173, "compression_ratio": 1.5355648535564854, "no_speech_prob": 1.0289360034221318e-05}, {"id": 435, "seek": 200648, "start": 2006.48, "end": 2012.8, "text": " Yeah, all of these details we are gonna you are going to get to but the key thing is I wanted to get you training", "tokens": [865, 11, 439, 295, 613, 4365, 321, 366, 799, 291, 366, 516, 281, 483, 281, 457, 264, 2141, 551, 307, 286, 1415, 281, 483, 291, 3097], "temperature": 0.0, "avg_logprob": -0.14850403606027796, "compression_ratio": 1.8121019108280254, "no_speech_prob": 6.748001851519803e-06}, {"id": 436, "seek": 200648, "start": 2012.8, "end": 2014.8, "text": " A model as quickly as possible", "tokens": [316, 2316, 382, 2661, 382, 1944], "temperature": 0.0, "avg_logprob": -0.14850403606027796, "compression_ratio": 1.8121019108280254, "no_speech_prob": 6.748001851519803e-06}, {"id": 437, "seek": 200648, "start": 2015.52, "end": 2020.42, "text": " But you know, one of the most important things to be a really good practitioner is to be able to look at your data", "tokens": [583, 291, 458, 11, 472, 295, 264, 881, 1021, 721, 281, 312, 257, 534, 665, 32125, 307, 281, 312, 1075, 281, 574, 412, 428, 1412], "temperature": 0.0, "avg_logprob": -0.14850403606027796, "compression_ratio": 1.8121019108280254, "no_speech_prob": 6.748001851519803e-06}, {"id": 438, "seek": 200648, "start": 2020.68, "end": 2025.44, "text": " Okay, so it's really important to remember to go data dot show batch and take a look", "tokens": [1033, 11, 370, 309, 311, 534, 1021, 281, 1604, 281, 352, 1412, 5893, 855, 15245, 293, 747, 257, 574], "temperature": 0.0, "avg_logprob": -0.14850403606027796, "compression_ratio": 1.8121019108280254, "no_speech_prob": 6.748001851519803e-06}, {"id": 439, "seek": 200648, "start": 2025.44, "end": 2031.56, "text": " It's surprising how often when you actually look at the data set you've been given that you realize it's got weird black borders on", "tokens": [467, 311, 8830, 577, 2049, 562, 291, 767, 574, 412, 264, 1412, 992, 291, 600, 668, 2212, 300, 291, 4325, 309, 311, 658, 3657, 2211, 16287, 322], "temperature": 0.0, "avg_logprob": -0.14850403606027796, "compression_ratio": 1.8121019108280254, "no_speech_prob": 6.748001851519803e-06}, {"id": 440, "seek": 200648, "start": 2031.56, "end": 2035.68, "text": " It or some of the things have text covering up some of it or some of its rotated in odd ways", "tokens": [467, 420, 512, 295, 264, 721, 362, 2487, 10322, 493, 512, 295, 309, 420, 512, 295, 1080, 42146, 294, 7401, 2098], "temperature": 0.0, "avg_logprob": -0.14850403606027796, "compression_ratio": 1.8121019108280254, "no_speech_prob": 6.748001851519803e-06}, {"id": 441, "seek": 203568, "start": 2035.68, "end": 2037.8, "text": " So make sure you take a look. Okay", "tokens": [407, 652, 988, 291, 747, 257, 574, 13, 1033], "temperature": 0.0, "avg_logprob": -0.22018979775785197, "compression_ratio": 1.7844036697247707, "no_speech_prob": 4.425473889568821e-06}, {"id": 442, "seek": 203568, "start": 2040.6000000000001, "end": 2043.68, "text": " And then the other thing we want to look at do is not just look at the pictures", "tokens": [400, 550, 264, 661, 551, 321, 528, 281, 574, 412, 360, 307, 406, 445, 574, 412, 264, 5242], "temperature": 0.0, "avg_logprob": -0.22018979775785197, "compression_ratio": 1.7844036697247707, "no_speech_prob": 4.425473889568821e-06}, {"id": 443, "seek": 203568, "start": 2043.68, "end": 2048.04, "text": " But also look at the labels and so all of the possible", "tokens": [583, 611, 574, 412, 264, 16949, 293, 370, 439, 295, 264, 1944], "temperature": 0.0, "avg_logprob": -0.22018979775785197, "compression_ratio": 1.7844036697247707, "no_speech_prob": 4.425473889568821e-06}, {"id": 444, "seek": 203568, "start": 2048.88, "end": 2050.28, "text": " label names", "tokens": [7645, 5288], "temperature": 0.0, "avg_logprob": -0.22018979775785197, "compression_ratio": 1.7844036697247707, "no_speech_prob": 4.425473889568821e-06}, {"id": 445, "seek": 203568, "start": 2050.28, "end": 2055.62, "text": " Accord your classes that's where the data bunch you can print out your data dot classes", "tokens": [5725, 765, 428, 5359, 300, 311, 689, 264, 1412, 3840, 291, 393, 4482, 484, 428, 1412, 5893, 5359], "temperature": 0.0, "avg_logprob": -0.22018979775785197, "compression_ratio": 1.7844036697247707, "no_speech_prob": 4.425473889568821e-06}, {"id": 446, "seek": 203568, "start": 2055.62, "end": 2057.04, "text": " And so here they are", "tokens": [400, 370, 510, 436, 366], "temperature": 0.0, "avg_logprob": -0.22018979775785197, "compression_ratio": 1.7844036697247707, "no_speech_prob": 4.425473889568821e-06}, {"id": 447, "seek": 203568, "start": 2057.04, "end": 2062.54, "text": " That's all of the possible labels that we found by using that regular expression on the file names", "tokens": [663, 311, 439, 295, 264, 1944, 16949, 300, 321, 1352, 538, 1228, 300, 3890, 6114, 322, 264, 3991, 5288], "temperature": 0.0, "avg_logprob": -0.22018979775785197, "compression_ratio": 1.7844036697247707, "no_speech_prob": 4.425473889568821e-06}, {"id": 448, "seek": 206254, "start": 2062.54, "end": 2067.24, "text": " And we learned earlier on in that prose I wrote at the top that there are 37", "tokens": [400, 321, 3264, 3071, 322, 294, 300, 12505, 286, 4114, 412, 264, 1192, 300, 456, 366, 13435], "temperature": 0.0, "avg_logprob": -0.20080653599330356, "compression_ratio": 1.6113074204946995, "no_speech_prob": 2.026134097832255e-06}, {"id": 449, "seek": 206254, "start": 2067.88, "end": 2072.96, "text": " Possible categories and so just checking length data classes. It is indeed 37 a", "tokens": [430, 5785, 10479, 293, 370, 445, 8568, 4641, 1412, 5359, 13, 467, 307, 6451, 13435, 257], "temperature": 0.0, "avg_logprob": -0.20080653599330356, "compression_ratio": 1.6113074204946995, "no_speech_prob": 2.026134097832255e-06}, {"id": 450, "seek": 206254, "start": 2073.92, "end": 2076.52, "text": " Data bunch will always have a property called C", "tokens": [11888, 3840, 486, 1009, 362, 257, 4707, 1219, 383], "temperature": 0.0, "avg_logprob": -0.20080653599330356, "compression_ratio": 1.6113074204946995, "no_speech_prob": 2.026134097832255e-06}, {"id": 451, "seek": 206254, "start": 2077.08, "end": 2081.94, "text": " And that property called C the technical details will kind of get to later", "tokens": [400, 300, 4707, 1219, 383, 264, 6191, 4365, 486, 733, 295, 483, 281, 1780], "temperature": 0.0, "avg_logprob": -0.20080653599330356, "compression_ratio": 1.6113074204946995, "no_speech_prob": 2.026134097832255e-06}, {"id": 452, "seek": 206254, "start": 2081.94, "end": 2085.16, "text": " But for now you can kind of think of it as being the number of classes", "tokens": [583, 337, 586, 291, 393, 733, 295, 519, 295, 309, 382, 885, 264, 1230, 295, 5359], "temperature": 0.0, "avg_logprob": -0.20080653599330356, "compression_ratio": 1.6113074204946995, "no_speech_prob": 2.026134097832255e-06}, {"id": 453, "seek": 206254, "start": 2086.44, "end": 2091.84, "text": " For things like regression problems and multi-label classification and stuff. That's not exactly accurate", "tokens": [1171, 721, 411, 24590, 2740, 293, 4825, 12, 75, 18657, 21538, 293, 1507, 13, 663, 311, 406, 2293, 8559], "temperature": 0.0, "avg_logprob": -0.20080653599330356, "compression_ratio": 1.6113074204946995, "no_speech_prob": 2.026134097832255e-06}, {"id": 454, "seek": 209184, "start": 2091.84, "end": 2093.84, "text": " But it'll do for now", "tokens": [583, 309, 603, 360, 337, 586], "temperature": 0.0, "avg_logprob": -0.22278990396639195, "compression_ratio": 1.6127450980392157, "no_speech_prob": 8.0134186646319e-06}, {"id": 455, "seek": 209184, "start": 2094.0, "end": 2096.6000000000004, "text": " It's it's important to know that data dot C", "tokens": [467, 311, 309, 311, 1021, 281, 458, 300, 1412, 5893, 383], "temperature": 0.0, "avg_logprob": -0.22278990396639195, "compression_ratio": 1.6127450980392157, "no_speech_prob": 8.0134186646319e-06}, {"id": 456, "seek": 209184, "start": 2097.08, "end": 2103.1600000000003, "text": " Is a really important piece of information that is something like or at least for classification problems", "tokens": [1119, 257, 534, 1021, 2522, 295, 1589, 300, 307, 746, 411, 420, 412, 1935, 337, 21538, 2740], "temperature": 0.0, "avg_logprob": -0.22278990396639195, "compression_ratio": 1.6127450980392157, "no_speech_prob": 8.0134186646319e-06}, {"id": 457, "seek": 209184, "start": 2103.1600000000003, "end": 2105.1600000000003, "text": " It is the number of classes", "tokens": [467, 307, 264, 1230, 295, 5359], "temperature": 0.0, "avg_logprob": -0.22278990396639195, "compression_ratio": 1.6127450980392157, "no_speech_prob": 8.0134186646319e-06}, {"id": 458, "seek": 209184, "start": 2107.04, "end": 2112.04, "text": " Right believe it or not we're now ready to train a model and", "tokens": [1779, 1697, 309, 420, 406, 321, 434, 586, 1919, 281, 3847, 257, 2316, 293], "temperature": 0.0, "avg_logprob": -0.22278990396639195, "compression_ratio": 1.6127450980392157, "no_speech_prob": 8.0134186646319e-06}, {"id": 459, "seek": 209184, "start": 2113.04, "end": 2119.76, "text": " So a model is trained in fast AI using something called a learner and", "tokens": [407, 257, 2316, 307, 8895, 294, 2370, 7318, 1228, 746, 1219, 257, 33347, 293], "temperature": 0.0, "avg_logprob": -0.22278990396639195, "compression_ratio": 1.6127450980392157, "no_speech_prob": 8.0134186646319e-06}, {"id": 460, "seek": 211976, "start": 2119.76, "end": 2124.5800000000004, "text": " Just like a data bunch is a general fast AI concept for your data", "tokens": [1449, 411, 257, 1412, 3840, 307, 257, 2674, 2370, 7318, 3410, 337, 428, 1412], "temperature": 0.0, "avg_logprob": -0.2016478180885315, "compression_ratio": 1.8209606986899562, "no_speech_prob": 1.892483123810962e-05}, {"id": 461, "seek": 211976, "start": 2125.8, "end": 2129.6400000000003, "text": " And from there there are subclasses for particular applications", "tokens": [400, 490, 456, 456, 366, 1422, 11665, 279, 337, 1729, 5821], "temperature": 0.0, "avg_logprob": -0.2016478180885315, "compression_ratio": 1.8209606986899562, "no_speech_prob": 1.892483123810962e-05}, {"id": 462, "seek": 211976, "start": 2130.2400000000002, "end": 2132.2400000000002, "text": " like image data bunch a", "tokens": [411, 3256, 1412, 3840, 257], "temperature": 0.0, "avg_logprob": -0.2016478180885315, "compression_ratio": 1.8209606986899562, "no_speech_prob": 1.892483123810962e-05}, {"id": 463, "seek": 211976, "start": 2132.88, "end": 2136.2400000000002, "text": " Learner is a general concept for things that can learn", "tokens": [17216, 260, 307, 257, 2674, 3410, 337, 721, 300, 393, 1466], "temperature": 0.0, "avg_logprob": -0.2016478180885315, "compression_ratio": 1.8209606986899562, "no_speech_prob": 1.892483123810962e-05}, {"id": 464, "seek": 211976, "start": 2136.6400000000003, "end": 2141.6000000000004, "text": " To fit the model and from that there are various subclasses to make things easier and in particular", "tokens": [1407, 3318, 264, 2316, 293, 490, 300, 456, 366, 3683, 1422, 11665, 279, 281, 652, 721, 3571, 293, 294, 1729], "temperature": 0.0, "avg_logprob": -0.2016478180885315, "compression_ratio": 1.8209606986899562, "no_speech_prob": 1.892483123810962e-05}, {"id": 465, "seek": 211976, "start": 2141.6000000000004, "end": 2147.48, "text": " There's one called comms learner, which is something that will create a convolutional neural network for you", "tokens": [821, 311, 472, 1219, 800, 82, 33347, 11, 597, 307, 746, 300, 486, 1884, 257, 45216, 304, 18161, 3209, 337, 291], "temperature": 0.0, "avg_logprob": -0.2016478180885315, "compression_ratio": 1.8209606986899562, "no_speech_prob": 1.892483123810962e-05}, {"id": 466, "seek": 214748, "start": 2147.48, "end": 2150.52, "text": " We'll be learning a lot about that over the next few lessons", "tokens": [492, 603, 312, 2539, 257, 688, 466, 300, 670, 264, 958, 1326, 8820], "temperature": 0.0, "avg_logprob": -0.15386583237420945, "compression_ratio": 1.7701612903225807, "no_speech_prob": 2.443982566546765e-06}, {"id": 467, "seek": 214748, "start": 2151.68, "end": 2156.62, "text": " But for now just know that to create a learner for a convolutional neural network", "tokens": [583, 337, 586, 445, 458, 300, 281, 1884, 257, 33347, 337, 257, 45216, 304, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.15386583237420945, "compression_ratio": 1.7701612903225807, "no_speech_prob": 2.443982566546765e-06}, {"id": 468, "seek": 214748, "start": 2156.72, "end": 2159.46, "text": " You just have to tell it two things. The first is", "tokens": [509, 445, 362, 281, 980, 309, 732, 721, 13, 440, 700, 307], "temperature": 0.0, "avg_logprob": -0.15386583237420945, "compression_ratio": 1.7701612903225807, "no_speech_prob": 2.443982566546765e-06}, {"id": 469, "seek": 214748, "start": 2160.42, "end": 2166.6, "text": " What's your data and not surprisingly it takes a data bunch and the second thing you need to tell it is", "tokens": [708, 311, 428, 1412, 293, 406, 17600, 309, 2516, 257, 1412, 3840, 293, 264, 1150, 551, 291, 643, 281, 980, 309, 307], "temperature": 0.0, "avg_logprob": -0.15386583237420945, "compression_ratio": 1.7701612903225807, "no_speech_prob": 2.443982566546765e-06}, {"id": 470, "seek": 214748, "start": 2167.0, "end": 2169.0, "text": " What's your model?", "tokens": [708, 311, 428, 2316, 30], "temperature": 0.0, "avg_logprob": -0.15386583237420945, "compression_ratio": 1.7701612903225807, "no_speech_prob": 2.443982566546765e-06}, {"id": 471, "seek": 214748, "start": 2169.08, "end": 2176.2, "text": " What's your architecture? So as we'll learn there are lots of different ways of constructing a convolutional neural network", "tokens": [708, 311, 428, 9482, 30, 407, 382, 321, 603, 1466, 456, 366, 3195, 295, 819, 2098, 295, 39969, 257, 45216, 304, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.15386583237420945, "compression_ratio": 1.7701612903225807, "no_speech_prob": 2.443982566546765e-06}, {"id": 472, "seek": 217620, "start": 2176.2, "end": 2183.4399999999996, "text": " But for now the most important thing for you to know is that there's a particular kind of model called a resnet", "tokens": [583, 337, 586, 264, 881, 1021, 551, 337, 291, 281, 458, 307, 300, 456, 311, 257, 1729, 733, 295, 2316, 1219, 257, 725, 7129], "temperature": 0.0, "avg_logprob": -0.21998538573582968, "compression_ratio": 1.6118143459915613, "no_speech_prob": 4.289313892513746e-06}, {"id": 473, "seek": 217620, "start": 2183.7999999999997, "end": 2186.08, "text": " which works extremely well", "tokens": [597, 1985, 4664, 731], "temperature": 0.0, "avg_logprob": -0.21998538573582968, "compression_ratio": 1.6118143459915613, "no_speech_prob": 4.289313892513746e-06}, {"id": 474, "seek": 217620, "start": 2186.7999999999997, "end": 2188.64, "text": " nearly all the time and", "tokens": [6217, 439, 264, 565, 293], "temperature": 0.0, "avg_logprob": -0.21998538573582968, "compression_ratio": 1.6118143459915613, "no_speech_prob": 4.289313892513746e-06}, {"id": 475, "seek": 217620, "start": 2188.64, "end": 2191.96, "text": " So for a while at least you really only need to be doing", "tokens": [407, 337, 257, 1339, 412, 1935, 291, 534, 787, 643, 281, 312, 884], "temperature": 0.0, "avg_logprob": -0.21998538573582968, "compression_ratio": 1.6118143459915613, "no_speech_prob": 4.289313892513746e-06}, {"id": 476, "seek": 217620, "start": 2192.48, "end": 2196.64, "text": " Choosing between two things which is what size resnet do you want?", "tokens": [12366, 6110, 1296, 732, 721, 597, 307, 437, 2744, 725, 7129, 360, 291, 528, 30], "temperature": 0.0, "avg_logprob": -0.21998538573582968, "compression_ratio": 1.6118143459915613, "no_speech_prob": 4.289313892513746e-06}, {"id": 477, "seek": 217620, "start": 2196.8399999999997, "end": 2201.24, "text": " It's just basically how big is it and we'll learn them all about the details of what that means", "tokens": [467, 311, 445, 1936, 577, 955, 307, 309, 293, 321, 603, 1466, 552, 439, 466, 264, 4365, 295, 437, 300, 1355], "temperature": 0.0, "avg_logprob": -0.21998538573582968, "compression_ratio": 1.6118143459915613, "no_speech_prob": 4.289313892513746e-06}, {"id": 478, "seek": 220124, "start": 2201.24, "end": 2207.52, "text": " But there's that one quarter resnet 34 and there's one quarter resnet 50 and so when we're getting started with something", "tokens": [583, 456, 311, 300, 472, 6555, 725, 7129, 12790, 293, 456, 311, 472, 6555, 725, 7129, 2625, 293, 370, 562, 321, 434, 1242, 1409, 365, 746], "temperature": 0.0, "avg_logprob": -0.17501303631326426, "compression_ratio": 1.8379446640316206, "no_speech_prob": 6.339168521662941e-06}, {"id": 479, "seek": 220124, "start": 2207.52, "end": 2209.8399999999997, "text": " I'll pick a smaller one because it'll train faster", "tokens": [286, 603, 1888, 257, 4356, 472, 570, 309, 603, 3847, 4663], "temperature": 0.0, "avg_logprob": -0.17501303631326426, "compression_ratio": 1.8379446640316206, "no_speech_prob": 6.339168521662941e-06}, {"id": 480, "seek": 220124, "start": 2210.4799999999996, "end": 2211.72, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.17501303631326426, "compression_ratio": 1.8379446640316206, "no_speech_prob": 6.339168521662941e-06}, {"id": 481, "seek": 220124, "start": 2211.72, "end": 2217.1, "text": " That's kind of it. That's as much as you need to know to be a pretty good practitioner about architectures for now", "tokens": [663, 311, 733, 295, 309, 13, 663, 311, 382, 709, 382, 291, 643, 281, 458, 281, 312, 257, 1238, 665, 32125, 466, 6331, 1303, 337, 586], "temperature": 0.0, "avg_logprob": -0.17501303631326426, "compression_ratio": 1.8379446640316206, "no_speech_prob": 6.339168521662941e-06}, {"id": 482, "seek": 220124, "start": 2217.24, "end": 2222.2, "text": " Which is that there's two architectures or two variants of one architecture that work pretty well", "tokens": [3013, 307, 300, 456, 311, 732, 6331, 1303, 420, 732, 21669, 295, 472, 9482, 300, 589, 1238, 731], "temperature": 0.0, "avg_logprob": -0.17501303631326426, "compression_ratio": 1.8379446640316206, "no_speech_prob": 6.339168521662941e-06}, {"id": 483, "seek": 220124, "start": 2222.64, "end": 2226.64, "text": " Resnet 34 and resnet 50 start with a smaller one and see if it's good enough", "tokens": [5015, 7129, 12790, 293, 725, 7129, 2625, 722, 365, 257, 4356, 472, 293, 536, 498, 309, 311, 665, 1547], "temperature": 0.0, "avg_logprob": -0.17501303631326426, "compression_ratio": 1.8379446640316206, "no_speech_prob": 6.339168521662941e-06}, {"id": 484, "seek": 222664, "start": 2226.64, "end": 2232.18, "text": " So that is all the information we need to create a convolutional neural network learner", "tokens": [407, 300, 307, 439, 264, 1589, 321, 643, 281, 1884, 257, 45216, 304, 18161, 3209, 33347], "temperature": 0.0, "avg_logprob": -0.1691992216021101, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.7603368860363844e-06}, {"id": 485, "seek": 222664, "start": 2233.18, "end": 2236.72, "text": " There's one other thing I'm going to give it though, which is a list of metrics", "tokens": [821, 311, 472, 661, 551, 286, 478, 516, 281, 976, 309, 1673, 11, 597, 307, 257, 1329, 295, 16367], "temperature": 0.0, "avg_logprob": -0.1691992216021101, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.7603368860363844e-06}, {"id": 486, "seek": 222664, "start": 2237.14, "end": 2240.16, "text": " Metrics are literally just things that get printed out as it's training", "tokens": [6377, 10716, 366, 3736, 445, 721, 300, 483, 13567, 484, 382, 309, 311, 3097], "temperature": 0.0, "avg_logprob": -0.1691992216021101, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.7603368860363844e-06}, {"id": 487, "seek": 222664, "start": 2240.58, "end": 2244.8199999999997, "text": " So I've saying I would like you to print out the error rate, please", "tokens": [407, 286, 600, 1566, 286, 576, 411, 291, 281, 4482, 484, 264, 6713, 3314, 11, 1767], "temperature": 0.0, "avg_logprob": -0.1691992216021101, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.7603368860363844e-06}, {"id": 488, "seek": 222664, "start": 2245.5, "end": 2249.2599999999998, "text": " Now you can see the first time I ran this on a newly installed box", "tokens": [823, 291, 393, 536, 264, 700, 565, 286, 5872, 341, 322, 257, 15109, 8899, 2424], "temperature": 0.0, "avg_logprob": -0.1691992216021101, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.7603368860363844e-06}, {"id": 489, "seek": 222664, "start": 2250.06, "end": 2252.06, "text": " It downloaded something", "tokens": [467, 21748, 746], "temperature": 0.0, "avg_logprob": -0.1691992216021101, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.7603368860363844e-06}, {"id": 490, "seek": 222664, "start": 2252.3399999999997, "end": 2254.8199999999997, "text": " What's it downloading? It's downloading", "tokens": [708, 311, 309, 32529, 30, 467, 311, 32529], "temperature": 0.0, "avg_logprob": -0.1691992216021101, "compression_ratio": 1.6528301886792454, "no_speech_prob": 1.7603368860363844e-06}, {"id": 491, "seek": 225482, "start": 2254.82, "end": 2256.26, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.20366144180297852, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.844908860628493e-06}, {"id": 492, "seek": 225482, "start": 2256.26, "end": 2258.26, "text": " Resnet 34", "tokens": [5015, 7129, 12790], "temperature": 0.0, "avg_logprob": -0.20366144180297852, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.844908860628493e-06}, {"id": 493, "seek": 225482, "start": 2258.34, "end": 2260.02, "text": " pre-trained weights", "tokens": [659, 12, 17227, 2001, 17443], "temperature": 0.0, "avg_logprob": -0.20366144180297852, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.844908860628493e-06}, {"id": 494, "seek": 225482, "start": 2260.02, "end": 2265.1000000000004, "text": " Now what this means is that this particular model has actually already been trained", "tokens": [823, 437, 341, 1355, 307, 300, 341, 1729, 2316, 575, 767, 1217, 668, 8895], "temperature": 0.0, "avg_logprob": -0.20366144180297852, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.844908860628493e-06}, {"id": 495, "seek": 225482, "start": 2265.7000000000003, "end": 2271.28, "text": " For a particular task and that particular task is that it was trained on looking at about one and a half million", "tokens": [1171, 257, 1729, 5633, 293, 300, 1729, 5633, 307, 300, 309, 390, 8895, 322, 1237, 412, 466, 472, 293, 257, 1922, 2459], "temperature": 0.0, "avg_logprob": -0.20366144180297852, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.844908860628493e-06}, {"id": 496, "seek": 225482, "start": 2271.82, "end": 2275.42, "text": " Pictures of all kinds of different things a thousand different categories of things", "tokens": [45877, 295, 439, 3685, 295, 819, 721, 257, 4714, 819, 10479, 295, 721], "temperature": 0.0, "avg_logprob": -0.20366144180297852, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.844908860628493e-06}, {"id": 497, "seek": 225482, "start": 2276.1000000000004, "end": 2279.1400000000003, "text": " using an image a data set called image net and", "tokens": [1228, 364, 3256, 257, 1412, 992, 1219, 3256, 2533, 293], "temperature": 0.0, "avg_logprob": -0.20366144180297852, "compression_ratio": 1.7355769230769231, "no_speech_prob": 3.844908860628493e-06}, {"id": 498, "seek": 227914, "start": 2279.14, "end": 2285.8799999999997, "text": " So we can download those pre-trained weights so that we start start with a model that knows nothing about anything", "tokens": [407, 321, 393, 5484, 729, 659, 12, 17227, 2001, 17443, 370, 300, 321, 722, 722, 365, 257, 2316, 300, 3255, 1825, 466, 1340], "temperature": 0.0, "avg_logprob": -0.16124780972798666, "compression_ratio": 1.8461538461538463, "no_speech_prob": 5.014703674532939e-06}, {"id": 499, "seek": 227914, "start": 2285.96, "end": 2292.4, "text": " But we actually start with a model that knows how to recognize the a thousand categories of things in image net", "tokens": [583, 321, 767, 722, 365, 257, 2316, 300, 3255, 577, 281, 5521, 264, 257, 4714, 10479, 295, 721, 294, 3256, 2533], "temperature": 0.0, "avg_logprob": -0.16124780972798666, "compression_ratio": 1.8461538461538463, "no_speech_prob": 5.014703674532939e-06}, {"id": 500, "seek": 227914, "start": 2292.8799999999997, "end": 2297.92, "text": " Now I don't think I'm not sure but I don't think all of these 37 categories of pet", "tokens": [823, 286, 500, 380, 519, 286, 478, 406, 988, 457, 286, 500, 380, 519, 439, 295, 613, 13435, 10479, 295, 3817], "temperature": 0.0, "avg_logprob": -0.16124780972798666, "compression_ratio": 1.8461538461538463, "no_speech_prob": 5.014703674532939e-06}, {"id": 501, "seek": 227914, "start": 2298.3199999999997, "end": 2303.4, "text": " Were in image net, but there were certainly some kinds of dog. There's certainly some kinds of cat", "tokens": [12448, 294, 3256, 2533, 11, 457, 456, 645, 3297, 512, 3685, 295, 3000, 13, 821, 311, 3297, 512, 3685, 295, 3857], "temperature": 0.0, "avg_logprob": -0.16124780972798666, "compression_ratio": 1.8461538461538463, "no_speech_prob": 5.014703674532939e-06}, {"id": 502, "seek": 230340, "start": 2303.4, "end": 2309.3, "text": " So this pre-trained model already knows quite a little bit about what pets look like", "tokens": [407, 341, 659, 12, 17227, 2001, 2316, 1217, 3255, 1596, 257, 707, 857, 466, 437, 19897, 574, 411], "temperature": 0.0, "avg_logprob": -0.15194149192320097, "compression_ratio": 1.937759336099585, "no_speech_prob": 2.90230059363239e-06}, {"id": 503, "seek": 230340, "start": 2309.56, "end": 2316.08, "text": " And it certainly knows quite a lot about what animals look like and what photos look like so the idea is that we don't start", "tokens": [400, 309, 3297, 3255, 1596, 257, 688, 466, 437, 4882, 574, 411, 293, 437, 5787, 574, 411, 370, 264, 1558, 307, 300, 321, 500, 380, 722], "temperature": 0.0, "avg_logprob": -0.15194149192320097, "compression_ratio": 1.937759336099585, "no_speech_prob": 2.90230059363239e-06}, {"id": 504, "seek": 230340, "start": 2316.7200000000003, "end": 2318.7200000000003, "text": " With a model that knows nothing at all", "tokens": [2022, 257, 2316, 300, 3255, 1825, 412, 439], "temperature": 0.0, "avg_logprob": -0.15194149192320097, "compression_ratio": 1.937759336099585, "no_speech_prob": 2.90230059363239e-06}, {"id": 505, "seek": 230340, "start": 2319.12, "end": 2321.56, "text": " But we start by downloading a model that knows", "tokens": [583, 321, 722, 538, 32529, 257, 2316, 300, 3255], "temperature": 0.0, "avg_logprob": -0.15194149192320097, "compression_ratio": 1.937759336099585, "no_speech_prob": 2.90230059363239e-06}, {"id": 506, "seek": 230340, "start": 2322.28, "end": 2324.46, "text": " Something about recognizing images already", "tokens": [6595, 466, 18538, 5267, 1217], "temperature": 0.0, "avg_logprob": -0.15194149192320097, "compression_ratio": 1.937759336099585, "no_speech_prob": 2.90230059363239e-06}, {"id": 507, "seek": 230340, "start": 2324.96, "end": 2331.62, "text": " So it downloads for us automatically the first time we use it a pre-trained model and then from now on it won't need to download", "tokens": [407, 309, 36553, 337, 505, 6772, 264, 700, 565, 321, 764, 309, 257, 659, 12, 17227, 2001, 2316, 293, 550, 490, 586, 322, 309, 1582, 380, 643, 281, 5484], "temperature": 0.0, "avg_logprob": -0.15194149192320097, "compression_ratio": 1.937759336099585, "no_speech_prob": 2.90230059363239e-06}, {"id": 508, "seek": 233162, "start": 2331.62, "end": 2333.62, "text": " It again, it'll just use the one we've got", "tokens": [467, 797, 11, 309, 603, 445, 764, 264, 472, 321, 600, 658], "temperature": 0.0, "avg_logprob": -0.1551295458260229, "compression_ratio": 1.7179487179487178, "no_speech_prob": 3.4465604130673455e-06}, {"id": 509, "seek": 233162, "start": 2334.14, "end": 2337.3199999999997, "text": " This is really important. We're learning to learn a lot about this", "tokens": [639, 307, 534, 1021, 13, 492, 434, 2539, 281, 1466, 257, 688, 466, 341], "temperature": 0.0, "avg_logprob": -0.1551295458260229, "compression_ratio": 1.7179487179487178, "no_speech_prob": 3.4465604130673455e-06}, {"id": 510, "seek": 233162, "start": 2337.3199999999997, "end": 2342.3199999999997, "text": " It's kind of the focus of the whole course which is how to do this is called transfer learning", "tokens": [467, 311, 733, 295, 264, 1879, 295, 264, 1379, 1164, 597, 307, 577, 281, 360, 341, 307, 1219, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.1551295458260229, "compression_ratio": 1.7179487179487178, "no_speech_prob": 3.4465604130673455e-06}, {"id": 511, "seek": 233162, "start": 2342.88, "end": 2349.1, "text": " How to take a model that already knows how to do something pretty well and make it so that it can do your thing", "tokens": [1012, 281, 747, 257, 2316, 300, 1217, 3255, 577, 281, 360, 746, 1238, 731, 293, 652, 309, 370, 300, 309, 393, 360, 428, 551], "temperature": 0.0, "avg_logprob": -0.1551295458260229, "compression_ratio": 1.7179487179487178, "no_speech_prob": 3.4465604130673455e-06}, {"id": 512, "seek": 233162, "start": 2349.48, "end": 2354.2, "text": " Really? Well, I take a pre-trained model and then we fit it", "tokens": [4083, 30, 1042, 11, 286, 747, 257, 659, 12, 17227, 2001, 2316, 293, 550, 321, 3318, 309], "temperature": 0.0, "avg_logprob": -0.1551295458260229, "compression_ratio": 1.7179487179487178, "no_speech_prob": 3.4465604130673455e-06}, {"id": 513, "seek": 233162, "start": 2354.44, "end": 2358.8399999999997, "text": " So that instead of predicting the a thousand categories of image net with the image net data", "tokens": [407, 300, 2602, 295, 32884, 264, 257, 4714, 10479, 295, 3256, 2533, 365, 264, 3256, 2533, 1412], "temperature": 0.0, "avg_logprob": -0.1551295458260229, "compression_ratio": 1.7179487179487178, "no_speech_prob": 3.4465604130673455e-06}, {"id": 514, "seek": 235884, "start": 2358.84, "end": 2362.92, "text": " It predicts the 37 categories of pets using your pet data", "tokens": [467, 6069, 82, 264, 13435, 10479, 295, 19897, 1228, 428, 3817, 1412], "temperature": 0.0, "avg_logprob": -0.24841180689194622, "compression_ratio": 1.7004830917874396, "no_speech_prob": 5.862753369001439e-06}, {"id": 515, "seek": 235884, "start": 2363.36, "end": 2367.2000000000003, "text": " And it turns out that by doing this you can train models in", "tokens": [400, 309, 4523, 484, 300, 538, 884, 341, 291, 393, 3847, 5245, 294], "temperature": 0.0, "avg_logprob": -0.24841180689194622, "compression_ratio": 1.7004830917874396, "no_speech_prob": 5.862753369001439e-06}, {"id": 516, "seek": 235884, "start": 2368.56, "end": 2374.08, "text": " 1-100 or less of the time of regular model training with", "tokens": [502, 12, 6879, 420, 1570, 295, 264, 565, 295, 3890, 2316, 3097, 365], "temperature": 0.0, "avg_logprob": -0.24841180689194622, "compression_ratio": 1.7004830917874396, "no_speech_prob": 5.862753369001439e-06}, {"id": 517, "seek": 235884, "start": 2374.6000000000004, "end": 2380.88, "text": " 1-100 or less of the data of regular model training in fact potentially many thousands of times less", "tokens": [502, 12, 6879, 420, 1570, 295, 264, 1412, 295, 3890, 2316, 3097, 294, 1186, 7263, 867, 5383, 295, 1413, 1570], "temperature": 0.0, "avg_logprob": -0.24841180689194622, "compression_ratio": 1.7004830917874396, "no_speech_prob": 5.862753369001439e-06}, {"id": 518, "seek": 235884, "start": 2381.04, "end": 2385.26, "text": " Remember I showed you the slide of Nichols lesson one project from last year", "tokens": [5459, 286, 4712, 291, 264, 4137, 295, 17102, 19385, 6898, 472, 1716, 490, 1036, 1064], "temperature": 0.0, "avg_logprob": -0.24841180689194622, "compression_ratio": 1.7004830917874396, "no_speech_prob": 5.862753369001439e-06}, {"id": 519, "seek": 238526, "start": 2385.26, "end": 2390.88, "text": " He used 30 images and there's not cricket and baseball images in image net", "tokens": [634, 1143, 2217, 5267, 293, 456, 311, 406, 31626, 293, 14323, 5267, 294, 3256, 2533], "temperature": 0.0, "avg_logprob": -0.18352748098827543, "compression_ratio": 1.5482456140350878, "no_speech_prob": 1.5294060631276807e-06}, {"id": 520, "seek": 238526, "start": 2391.2000000000003, "end": 2395.96, "text": " Right, but it just turns out that image nets already so good at recognizing things in the world", "tokens": [1779, 11, 457, 309, 445, 4523, 484, 300, 3256, 36170, 1217, 370, 665, 412, 18538, 721, 294, 264, 1002], "temperature": 0.0, "avg_logprob": -0.18352748098827543, "compression_ratio": 1.5482456140350878, "no_speech_prob": 1.5294060631276807e-06}, {"id": 521, "seek": 238526, "start": 2395.96, "end": 2401.8, "text": " They're just 30 examples of people playing baseball and cricket was enough to build a nearly perfect classifier", "tokens": [814, 434, 445, 2217, 5110, 295, 561, 2433, 14323, 293, 31626, 390, 1547, 281, 1322, 257, 6217, 2176, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.18352748098827543, "compression_ratio": 1.5482456140350878, "no_speech_prob": 1.5294060631276807e-06}, {"id": 522, "seek": 238526, "start": 2402.84, "end": 2404.36, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.18352748098827543, "compression_ratio": 1.5482456140350878, "no_speech_prob": 1.5294060631276807e-06}, {"id": 523, "seek": 238526, "start": 2404.36, "end": 2406.0800000000004, "text": " now", "tokens": [586], "temperature": 0.0, "avg_logprob": -0.18352748098827543, "compression_ratio": 1.5482456140350878, "no_speech_prob": 1.5294060631276807e-06}, {"id": 524, "seek": 238526, "start": 2406.0800000000004, "end": 2408.0800000000004, "text": " You would naturally be", "tokens": [509, 576, 8195, 312], "temperature": 0.0, "avg_logprob": -0.18352748098827543, "compression_ratio": 1.5482456140350878, "no_speech_prob": 1.5294060631276807e-06}, {"id": 525, "seek": 238526, "start": 2408.96, "end": 2411.28, "text": " Potentially saying well, wait a minute", "tokens": [9145, 3137, 1566, 731, 11, 1699, 257, 3456], "temperature": 0.0, "avg_logprob": -0.18352748098827543, "compression_ratio": 1.5482456140350878, "no_speech_prob": 1.5294060631276807e-06}, {"id": 526, "seek": 241128, "start": 2411.28, "end": 2418.8, "text": " How do you know that it was going to actually that it can actually recognize pictures of people playing cricket versus baseball", "tokens": [1012, 360, 291, 458, 300, 309, 390, 516, 281, 767, 300, 309, 393, 767, 5521, 5242, 295, 561, 2433, 31626, 5717, 14323], "temperature": 0.0, "avg_logprob": -0.251300300519491, "compression_ratio": 1.7883817427385893, "no_speech_prob": 5.422175036073895e-06}, {"id": 527, "seek": 241128, "start": 2419.32, "end": 2423.0, "text": " In general, maybe it just learned to recognize those 30", "tokens": [682, 2674, 11, 1310, 309, 445, 3264, 281, 5521, 729, 2217], "temperature": 0.0, "avg_logprob": -0.251300300519491, "compression_ratio": 1.7883817427385893, "no_speech_prob": 5.422175036073895e-06}, {"id": 528, "seek": 241128, "start": 2423.6400000000003, "end": 2426.7200000000003, "text": " Maybe it's just cheating right and that's called overfitting", "tokens": [2704, 309, 311, 445, 18309, 558, 293, 300, 311, 1219, 670, 69, 2414], "temperature": 0.0, "avg_logprob": -0.251300300519491, "compression_ratio": 1.7883817427385893, "no_speech_prob": 5.422175036073895e-06}, {"id": 529, "seek": 241128, "start": 2426.7200000000003, "end": 2429.36, "text": " We'll be going talking a lot about that during this course, right?", "tokens": [492, 603, 312, 516, 1417, 257, 688, 466, 300, 1830, 341, 1164, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.251300300519491, "compression_ratio": 1.7883817427385893, "no_speech_prob": 5.422175036073895e-06}, {"id": 530, "seek": 241128, "start": 2429.36, "end": 2434.6800000000003, "text": " But overfitting is where you don't learn to recognize pictures of say cricket versus baseball", "tokens": [583, 670, 69, 2414, 307, 689, 291, 500, 380, 1466, 281, 5521, 5242, 295, 584, 31626, 5717, 14323], "temperature": 0.0, "avg_logprob": -0.251300300519491, "compression_ratio": 1.7883817427385893, "no_speech_prob": 5.422175036073895e-06}, {"id": 531, "seek": 241128, "start": 2434.6800000000003, "end": 2436.6800000000003, "text": " But just these particular", "tokens": [583, 445, 613, 1729], "temperature": 0.0, "avg_logprob": -0.251300300519491, "compression_ratio": 1.7883817427385893, "no_speech_prob": 5.422175036073895e-06}, {"id": 532, "seek": 243668, "start": 2436.68, "end": 2443.64, "text": " Cricketers in these particular photos and these particular baseball players and these particular photos we have to make sure that we don't know the theater", "tokens": [4779, 618, 6202, 294, 613, 1729, 5787, 293, 613, 1729, 14323, 4150, 293, 613, 1729, 5787, 321, 362, 281, 652, 988, 300, 321, 500, 380, 458, 264, 10612], "temperature": 0.0, "avg_logprob": -0.15729930913336923, "compression_ratio": 1.9437751004016064, "no_speech_prob": 3.3405217436666135e-06}, {"id": 533, "seek": 243668, "start": 2443.64, "end": 2447.52, "text": " and so the way we do that is using something called a validation set a", "tokens": [293, 370, 264, 636, 321, 360, 300, 307, 1228, 746, 1219, 257, 24071, 992, 257], "temperature": 0.0, "avg_logprob": -0.15729930913336923, "compression_ratio": 1.9437751004016064, "no_speech_prob": 3.3405217436666135e-06}, {"id": 534, "seek": 243668, "start": 2448.2, "end": 2454.7999999999997, "text": " Validation set is a set of images that your model does not get to look at and so these metrics", "tokens": [7188, 327, 399, 992, 307, 257, 992, 295, 5267, 300, 428, 2316, 775, 406, 483, 281, 574, 412, 293, 370, 613, 16367], "temperature": 0.0, "avg_logprob": -0.15729930913336923, "compression_ratio": 1.9437751004016064, "no_speech_prob": 3.3405217436666135e-06}, {"id": 535, "seek": 243668, "start": 2455.3999999999996, "end": 2462.8999999999996, "text": " Like in this case error rate get printed out automatically using the validation set a set of images that our model never got to see", "tokens": [1743, 294, 341, 1389, 6713, 3314, 483, 13567, 484, 6772, 1228, 264, 24071, 992, 257, 992, 295, 5267, 300, 527, 2316, 1128, 658, 281, 536], "temperature": 0.0, "avg_logprob": -0.15729930913336923, "compression_ratio": 1.9437751004016064, "no_speech_prob": 3.3405217436666135e-06}, {"id": 536, "seek": 246290, "start": 2462.9, "end": 2469.88, "text": " When we created our data bunch it automatically created a validation set for us", "tokens": [1133, 321, 2942, 527, 1412, 3840, 309, 6772, 2942, 257, 24071, 992, 337, 505], "temperature": 0.0, "avg_logprob": -0.12064812660217285, "compression_ratio": 1.8362068965517242, "no_speech_prob": 7.071813797665527e-06}, {"id": 537, "seek": 246290, "start": 2470.5, "end": 2475.04, "text": " Okay, and we'll learn lots of ways of creating and using validation sets", "tokens": [1033, 11, 293, 321, 603, 1466, 3195, 295, 2098, 295, 4084, 293, 1228, 24071, 6352], "temperature": 0.0, "avg_logprob": -0.12064812660217285, "compression_ratio": 1.8362068965517242, "no_speech_prob": 7.071813797665527e-06}, {"id": 538, "seek": 246290, "start": 2475.3, "end": 2478.6, "text": " But because we try to bake in all of the best practices", "tokens": [583, 570, 321, 853, 281, 16562, 294, 439, 295, 264, 1151, 7525], "temperature": 0.0, "avg_logprob": -0.12064812660217285, "compression_ratio": 1.8362068965517242, "no_speech_prob": 7.071813797665527e-06}, {"id": 539, "seek": 246290, "start": 2479.1, "end": 2485.28, "text": " We actually make it nearly impossible for you not to use a validation set because if you're not using a validation set", "tokens": [492, 767, 652, 309, 6217, 6243, 337, 291, 406, 281, 764, 257, 24071, 992, 570, 498, 291, 434, 406, 1228, 257, 24071, 992], "temperature": 0.0, "avg_logprob": -0.12064812660217285, "compression_ratio": 1.8362068965517242, "no_speech_prob": 7.071813797665527e-06}, {"id": 540, "seek": 246290, "start": 2485.28, "end": 2489.78, "text": " You don't know if you're overfitting. Okay, so we always print out the metrics on a validation set", "tokens": [509, 500, 380, 458, 498, 291, 434, 670, 69, 2414, 13, 1033, 11, 370, 321, 1009, 4482, 484, 264, 16367, 322, 257, 24071, 992], "temperature": 0.0, "avg_logprob": -0.12064812660217285, "compression_ratio": 1.8362068965517242, "no_speech_prob": 7.071813797665527e-06}, {"id": 541, "seek": 248978, "start": 2489.78, "end": 2494.6000000000004, "text": " We always hold it out. We always make sure that the model doesn't touch it. That's all done for you", "tokens": [492, 1009, 1797, 309, 484, 13, 492, 1009, 652, 988, 300, 264, 2316, 1177, 380, 2557, 309, 13, 663, 311, 439, 1096, 337, 291], "temperature": 0.0, "avg_logprob": -0.12350394990709093, "compression_ratio": 1.7008196721311475, "no_speech_prob": 6.6434031396056525e-06}, {"id": 542, "seek": 248978, "start": 2495.1600000000003, "end": 2499.1000000000004, "text": " Okay, and that's all built into this data bunch object", "tokens": [1033, 11, 293, 300, 311, 439, 3094, 666, 341, 1412, 3840, 2657], "temperature": 0.0, "avg_logprob": -0.12350394990709093, "compression_ratio": 1.7008196721311475, "no_speech_prob": 6.6434031396056525e-06}, {"id": 543, "seek": 248978, "start": 2500.38, "end": 2502.38, "text": " So now that we have a conv learner", "tokens": [407, 586, 300, 321, 362, 257, 3754, 33347], "temperature": 0.0, "avg_logprob": -0.12350394990709093, "compression_ratio": 1.7008196721311475, "no_speech_prob": 6.6434031396056525e-06}, {"id": 544, "seek": 248978, "start": 2502.7000000000003, "end": 2504.7000000000003, "text": " We can fit it", "tokens": [492, 393, 3318, 309], "temperature": 0.0, "avg_logprob": -0.12350394990709093, "compression_ratio": 1.7008196721311475, "no_speech_prob": 6.6434031396056525e-06}, {"id": 545, "seek": 248978, "start": 2505.0400000000004, "end": 2507.5800000000004, "text": " You can just use a method called fit", "tokens": [509, 393, 445, 764, 257, 3170, 1219, 3318], "temperature": 0.0, "avg_logprob": -0.12350394990709093, "compression_ratio": 1.7008196721311475, "no_speech_prob": 6.6434031396056525e-06}, {"id": 546, "seek": 248978, "start": 2508.1400000000003, "end": 2512.26, "text": " But in practice, you should nearly always use a method called fit one cycle", "tokens": [583, 294, 3124, 11, 291, 820, 6217, 1009, 764, 257, 3170, 1219, 3318, 472, 6586], "temperature": 0.0, "avg_logprob": -0.12350394990709093, "compression_ratio": 1.7008196721311475, "no_speech_prob": 6.6434031396056525e-06}, {"id": 547, "seek": 248978, "start": 2512.46, "end": 2518.3, "text": " We'll learn more about this during the course, but in short one cycle learning is a paper that was", "tokens": [492, 603, 1466, 544, 466, 341, 1830, 264, 1164, 11, 457, 294, 2099, 472, 6586, 2539, 307, 257, 3035, 300, 390], "temperature": 0.0, "avg_logprob": -0.12350394990709093, "compression_ratio": 1.7008196721311475, "no_speech_prob": 6.6434031396056525e-06}, {"id": 548, "seek": 251830, "start": 2518.3, "end": 2520.2200000000003, "text": " released", "tokens": [4736], "temperature": 0.0, "avg_logprob": -0.16823776908542798, "compression_ratio": 1.5541125541125542, "no_speech_prob": 7.07183562553837e-06}, {"id": 549, "seek": 251830, "start": 2520.2200000000003, "end": 2523.3, "text": " I'm trying to think few months ago less than a year ago", "tokens": [286, 478, 1382, 281, 519, 1326, 2493, 2057, 1570, 813, 257, 1064, 2057], "temperature": 0.0, "avg_logprob": -0.16823776908542798, "compression_ratio": 1.5541125541125542, "no_speech_prob": 7.07183562553837e-06}, {"id": 550, "seek": 251830, "start": 2524.34, "end": 2526.34, "text": " Yeah, so a few months ago", "tokens": [865, 11, 370, 257, 1326, 2493, 2057], "temperature": 0.0, "avg_logprob": -0.16823776908542798, "compression_ratio": 1.5541125541125542, "no_speech_prob": 7.07183562553837e-06}, {"id": 551, "seek": 251830, "start": 2526.54, "end": 2532.0600000000004, "text": " And it turned out to be dramatically better both more accurate and faster than any previous approach", "tokens": [400, 309, 3574, 484, 281, 312, 17548, 1101, 1293, 544, 8559, 293, 4663, 813, 604, 3894, 3109], "temperature": 0.0, "avg_logprob": -0.16823776908542798, "compression_ratio": 1.5541125541125542, "no_speech_prob": 7.07183562553837e-06}, {"id": 552, "seek": 251830, "start": 2532.2200000000003, "end": 2534.7000000000003, "text": " So again, I don't want to teach you how to do", "tokens": [407, 797, 11, 286, 500, 380, 528, 281, 2924, 291, 577, 281, 360], "temperature": 0.0, "avg_logprob": -0.16823776908542798, "compression_ratio": 1.5541125541125542, "no_speech_prob": 7.07183562553837e-06}, {"id": 553, "seek": 251830, "start": 2536.7400000000002, "end": 2543.1000000000004, "text": " 2017 deep learning right in 2018 the best way to fit models is to use something called one cycle", "tokens": [6591, 2452, 2539, 558, 294, 6096, 264, 1151, 636, 281, 3318, 5245, 307, 281, 764, 746, 1219, 472, 6586], "temperature": 0.0, "avg_logprob": -0.16823776908542798, "compression_ratio": 1.5541125541125542, "no_speech_prob": 7.07183562553837e-06}, {"id": 554, "seek": 251830, "start": 2543.1000000000004, "end": 2544.02, "text": " We'll learn all about it", "tokens": [492, 603, 1466, 439, 466, 309], "temperature": 0.0, "avg_logprob": -0.16823776908542798, "compression_ratio": 1.5541125541125542, "no_speech_prob": 7.07183562553837e-06}, {"id": 555, "seek": 254402, "start": 2544.02, "end": 2548.74, "text": " But for now just know you should probably type my own dot fit one cycle. Okay", "tokens": [583, 337, 586, 445, 458, 291, 820, 1391, 2010, 452, 1065, 5893, 3318, 472, 6586, 13, 1033], "temperature": 0.0, "avg_logprob": -0.1891857673381937, "compression_ratio": 1.7251908396946565, "no_speech_prob": 8.139621968439315e-06}, {"id": 556, "seek": 254402, "start": 2549.94, "end": 2554.66, "text": " If you forget how to type it you can start typing a few letters and hit tab", "tokens": [759, 291, 2870, 577, 281, 2010, 309, 291, 393, 722, 18444, 257, 1326, 7825, 293, 2045, 4421], "temperature": 0.0, "avg_logprob": -0.1891857673381937, "compression_ratio": 1.7251908396946565, "no_speech_prob": 8.139621968439315e-06}, {"id": 557, "seek": 254402, "start": 2555.58, "end": 2558.46, "text": " Okay, and you'll get a list of potential options", "tokens": [1033, 11, 293, 291, 603, 483, 257, 1329, 295, 3995, 3956], "temperature": 0.0, "avg_logprob": -0.1891857673381937, "compression_ratio": 1.7251908396946565, "no_speech_prob": 8.139621968439315e-06}, {"id": 558, "seek": 254402, "start": 2559.06, "end": 2563.9, "text": " right, and then if you forget what to pass it you can press shift tab and", "tokens": [558, 11, 293, 550, 498, 291, 2870, 437, 281, 1320, 309, 291, 393, 1886, 5513, 4421, 293], "temperature": 0.0, "avg_logprob": -0.1891857673381937, "compression_ratio": 1.7251908396946565, "no_speech_prob": 8.139621968439315e-06}, {"id": 559, "seek": 254402, "start": 2564.66, "end": 2568.4, "text": " It'll show you exactly what to pass it. So you don't actually have to type help", "tokens": [467, 603, 855, 291, 2293, 437, 281, 1320, 309, 13, 407, 291, 500, 380, 767, 362, 281, 2010, 854], "temperature": 0.0, "avg_logprob": -0.1891857673381937, "compression_ratio": 1.7251908396946565, "no_speech_prob": 8.139621968439315e-06}, {"id": 560, "seek": 254402, "start": 2568.42, "end": 2572.78, "text": " And again, this is kind of nice that we have all the types here because we can see cycle length", "tokens": [400, 797, 11, 341, 307, 733, 295, 1481, 300, 321, 362, 439, 264, 3467, 510, 570, 321, 393, 536, 6586, 4641], "temperature": 0.0, "avg_logprob": -0.1891857673381937, "compression_ratio": 1.7251908396946565, "no_speech_prob": 8.139621968439315e-06}, {"id": 561, "seek": 257278, "start": 2572.78, "end": 2578.82, "text": " I will learn more about what that is shortly is an integer and then max learning rate could either be a float or a collection", "tokens": [286, 486, 1466, 544, 466, 437, 300, 307, 13392, 307, 364, 24922, 293, 550, 11469, 2539, 3314, 727, 2139, 312, 257, 15706, 420, 257, 5765], "temperature": 0.0, "avg_logprob": -0.19173051778552602, "compression_ratio": 1.7183673469387755, "no_speech_prob": 8.664591405249666e-06}, {"id": 562, "seek": 257278, "start": 2578.82, "end": 2583.3, "text": " Or whatever and so forth and you can see that momentums will default to this couple", "tokens": [1610, 2035, 293, 370, 5220, 293, 291, 393, 536, 300, 1623, 8099, 486, 7576, 281, 341, 1916], "temperature": 0.0, "avg_logprob": -0.19173051778552602, "compression_ratio": 1.7183673469387755, "no_speech_prob": 8.664591405249666e-06}, {"id": 563, "seek": 257278, "start": 2585.38, "end": 2587.38, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.19173051778552602, "compression_ratio": 1.7183673469387755, "no_speech_prob": 8.664591405249666e-06}, {"id": 564, "seek": 257278, "start": 2587.6600000000003, "end": 2592.0600000000004, "text": " For now just know that this number four basically decides", "tokens": [1171, 586, 445, 458, 300, 341, 1230, 1451, 1936, 14898], "temperature": 0.0, "avg_logprob": -0.19173051778552602, "compression_ratio": 1.7183673469387755, "no_speech_prob": 8.664591405249666e-06}, {"id": 565, "seek": 257278, "start": 2592.38, "end": 2595.9, "text": " How many times do we go through the entire data set?", "tokens": [1012, 867, 1413, 360, 321, 352, 807, 264, 2302, 1412, 992, 30], "temperature": 0.0, "avg_logprob": -0.19173051778552602, "compression_ratio": 1.7183673469387755, "no_speech_prob": 8.664591405249666e-06}, {"id": 566, "seek": 257278, "start": 2595.9, "end": 2600.4, "text": " How many times do we show the data set to the model so that it can learn from it each time?", "tokens": [1012, 867, 1413, 360, 321, 855, 264, 1412, 992, 281, 264, 2316, 370, 300, 309, 393, 1466, 490, 309, 1184, 565, 30], "temperature": 0.0, "avg_logprob": -0.19173051778552602, "compression_ratio": 1.7183673469387755, "no_speech_prob": 8.664591405249666e-06}, {"id": 567, "seek": 260040, "start": 2600.4, "end": 2602.86, "text": " It sees a picture. It's going to get a little bit better", "tokens": [467, 8194, 257, 3036, 13, 467, 311, 516, 281, 483, 257, 707, 857, 1101], "temperature": 0.0, "avg_logprob": -0.19504459087665266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.8573056169989286e-06}, {"id": 568, "seek": 260040, "start": 2603.3, "end": 2605.3, "text": " But it's going to take time and", "tokens": [583, 309, 311, 516, 281, 747, 565, 293], "temperature": 0.0, "avg_logprob": -0.19504459087665266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.8573056169989286e-06}, {"id": 569, "seek": 260040, "start": 2606.26, "end": 2609.42, "text": " It means it could overfit it sees the same picture too many times", "tokens": [467, 1355, 309, 727, 670, 6845, 309, 8194, 264, 912, 3036, 886, 867, 1413], "temperature": 0.0, "avg_logprob": -0.19504459087665266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.8573056169989286e-06}, {"id": 570, "seek": 260040, "start": 2609.46, "end": 2613.1, "text": " It'll just learn to recognize that picture not pets in general", "tokens": [467, 603, 445, 1466, 281, 5521, 300, 3036, 406, 19897, 294, 2674], "temperature": 0.0, "avg_logprob": -0.19504459087665266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.8573056169989286e-06}, {"id": 571, "seek": 260040, "start": 2614.46, "end": 2617.1800000000003, "text": " so we'll learn all about how to", "tokens": [370, 321, 603, 1466, 439, 466, 577, 281], "temperature": 0.0, "avg_logprob": -0.19504459087665266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.8573056169989286e-06}, {"id": 572, "seek": 260040, "start": 2618.26, "end": 2621.26, "text": " tune this number during the next couple of lessons", "tokens": [10864, 341, 1230, 1830, 264, 958, 1916, 295, 8820], "temperature": 0.0, "avg_logprob": -0.19504459087665266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.8573056169989286e-06}, {"id": 573, "seek": 260040, "start": 2622.06, "end": 2623.26, "text": " but", "tokens": [457], "temperature": 0.0, "avg_logprob": -0.19504459087665266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.8573056169989286e-06}, {"id": 574, "seek": 262326, "start": 2623.26, "end": 2630.98, "text": " Starting out with four is a pretty good start just to see how it goes and you can actually see after four", "tokens": [16217, 484, 365, 1451, 307, 257, 1238, 665, 722, 445, 281, 536, 577, 309, 1709, 293, 291, 393, 767, 536, 934, 1451], "temperature": 0.0, "avg_logprob": -0.1729743538833246, "compression_ratio": 1.5153061224489797, "no_speech_prob": 4.710890607384499e-06}, {"id": 575, "seek": 262326, "start": 2631.26, "end": 2633.26, "text": " epochs or four cycles", "tokens": [30992, 28346, 420, 1451, 17796], "temperature": 0.0, "avg_logprob": -0.1729743538833246, "compression_ratio": 1.5153061224489797, "no_speech_prob": 4.710890607384499e-06}, {"id": 576, "seek": 262326, "start": 2633.26, "end": 2635.26, "text": " we've got an error rate of", "tokens": [321, 600, 658, 364, 6713, 3314, 295], "temperature": 0.0, "avg_logprob": -0.1729743538833246, "compression_ratio": 1.5153061224489797, "no_speech_prob": 4.710890607384499e-06}, {"id": 577, "seek": 262326, "start": 2635.9, "end": 2637.9, "text": " six percent", "tokens": [2309, 3043], "temperature": 0.0, "avg_logprob": -0.1729743538833246, "compression_ratio": 1.5153061224489797, "no_speech_prob": 4.710890607384499e-06}, {"id": 578, "seek": 262326, "start": 2638.5, "end": 2644.2200000000003, "text": " So a natural question is how long did that took that took a minute and 56 seconds", "tokens": [407, 257, 3303, 1168, 307, 577, 938, 630, 300, 1890, 300, 1890, 257, 3456, 293, 19687, 3949], "temperature": 0.0, "avg_logprob": -0.1729743538833246, "compression_ratio": 1.5153061224489797, "no_speech_prob": 4.710890607384499e-06}, {"id": 579, "seek": 262326, "start": 2644.6600000000003, "end": 2647.0200000000004, "text": " Yeah, so we're paying, you know", "tokens": [865, 11, 370, 321, 434, 6229, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.1729743538833246, "compression_ratio": 1.5153061224489797, "no_speech_prob": 4.710890607384499e-06}, {"id": 580, "seek": 262326, "start": 2647.7000000000003, "end": 2649.5400000000004, "text": " 60 cents an hour", "tokens": [4060, 14941, 364, 1773], "temperature": 0.0, "avg_logprob": -0.1729743538833246, "compression_ratio": 1.5153061224489797, "no_speech_prob": 4.710890607384499e-06}, {"id": 581, "seek": 264954, "start": 2649.54, "end": 2654.58, "text": " We just paid for two minutes of time. I mean we actually pay for the whole time that it's on and running", "tokens": [492, 445, 4835, 337, 732, 2077, 295, 565, 13, 286, 914, 321, 767, 1689, 337, 264, 1379, 565, 300, 309, 311, 322, 293, 2614], "temperature": 0.0, "avg_logprob": -0.19249242039050085, "compression_ratio": 1.6724738675958188, "no_speech_prob": 8.6645577539457e-06}, {"id": 582, "seek": 264954, "start": 2654.58, "end": 2659.3, "text": " but we use two minutes of compute time and we got an error rate of six percent, so", "tokens": [457, 321, 764, 732, 2077, 295, 14722, 565, 293, 321, 658, 364, 6713, 3314, 295, 2309, 3043, 11, 370], "temperature": 0.0, "avg_logprob": -0.19249242039050085, "compression_ratio": 1.6724738675958188, "no_speech_prob": 8.6645577539457e-06}, {"id": 583, "seek": 264954, "start": 2660.2599999999998, "end": 2664.06, "text": " 94 percent of the time we correctly picked the exact right one of", "tokens": [30849, 3043, 295, 264, 565, 321, 8944, 6183, 264, 1900, 558, 472, 295], "temperature": 0.0, "avg_logprob": -0.19249242039050085, "compression_ratio": 1.6724738675958188, "no_speech_prob": 8.6645577539457e-06}, {"id": 584, "seek": 264954, "start": 2664.9, "end": 2669.12, "text": " Those 94 dog and cat breeds which feels pretty good to me", "tokens": [3950, 30849, 3000, 293, 3857, 41609, 597, 3417, 1238, 665, 281, 385], "temperature": 0.0, "avg_logprob": -0.19249242039050085, "compression_ratio": 1.6724738675958188, "no_speech_prob": 8.6645577539457e-06}, {"id": 585, "seek": 264954, "start": 2669.62, "end": 2673.22, "text": " But to get a sense of how good it is. Maybe we should go back and look at the paper", "tokens": [583, 281, 483, 257, 2020, 295, 577, 665, 309, 307, 13, 2704, 321, 820, 352, 646, 293, 574, 412, 264, 3035], "temperature": 0.0, "avg_logprob": -0.19249242039050085, "compression_ratio": 1.6724738675958188, "no_speech_prob": 8.6645577539457e-06}, {"id": 586, "seek": 264954, "start": 2674.3, "end": 2678.84, "text": " Just remember I said the nice thing about using academic papers or capital data sets", "tokens": [1449, 1604, 286, 848, 264, 1481, 551, 466, 1228, 7778, 10577, 420, 4238, 1412, 6352], "temperature": 0.0, "avg_logprob": -0.19249242039050085, "compression_ratio": 1.6724738675958188, "no_speech_prob": 8.6645577539457e-06}, {"id": 587, "seek": 267884, "start": 2678.84, "end": 2680.84, "text": " Is we can compare?", "tokens": [1119, 321, 393, 6794, 30], "temperature": 0.0, "avg_logprob": -0.1777039909362793, "compression_ratio": 1.7114624505928853, "no_speech_prob": 1.0129916518053506e-05}, {"id": 588, "seek": 267884, "start": 2681.06, "end": 2685.44, "text": " our solution to whatever the best people in Kaggle did or whatever the", "tokens": [527, 3827, 281, 2035, 264, 1151, 561, 294, 48751, 22631, 630, 420, 2035, 264], "temperature": 0.0, "avg_logprob": -0.1777039909362793, "compression_ratio": 1.7114624505928853, "no_speech_prob": 1.0129916518053506e-05}, {"id": 589, "seek": 267884, "start": 2685.82, "end": 2691.1400000000003, "text": " academics did so this particular data set of pet breeds is from 2012 and", "tokens": [25695, 630, 370, 341, 1729, 1412, 992, 295, 3817, 41609, 307, 490, 9125, 293], "temperature": 0.0, "avg_logprob": -0.1777039909362793, "compression_ratio": 1.7114624505928853, "no_speech_prob": 1.0129916518053506e-05}, {"id": 590, "seek": 267884, "start": 2692.1600000000003, "end": 2696.38, "text": " If I scroll through the paper, you'll generally find in any academic paper", "tokens": [759, 286, 11369, 807, 264, 3035, 11, 291, 603, 5101, 915, 294, 604, 7778, 3035], "temperature": 0.0, "avg_logprob": -0.1777039909362793, "compression_ratio": 1.7114624505928853, "no_speech_prob": 1.0129916518053506e-05}, {"id": 591, "seek": 267884, "start": 2696.38, "end": 2701.94, "text": " There'll be a section called experiments about two-thirds of the way through and if you find the section on experiments", "tokens": [821, 603, 312, 257, 3541, 1219, 12050, 466, 732, 12, 38507, 295, 264, 636, 807, 293, 498, 291, 915, 264, 3541, 322, 12050], "temperature": 0.0, "avg_logprob": -0.1777039909362793, "compression_ratio": 1.7114624505928853, "no_speech_prob": 1.0129916518053506e-05}, {"id": 592, "seek": 267884, "start": 2702.1000000000004, "end": 2706.48, "text": " Then you can find the section on accuracy and they've got lots of different", "tokens": [1396, 291, 393, 915, 264, 3541, 322, 14170, 293, 436, 600, 658, 3195, 295, 819], "temperature": 0.0, "avg_logprob": -0.1777039909362793, "compression_ratio": 1.7114624505928853, "no_speech_prob": 1.0129916518053506e-05}, {"id": 593, "seek": 270648, "start": 2706.48, "end": 2713.4, "text": " Models and their models as you'll read about in the paper are extremely kind of pet specific", "tokens": [6583, 1625, 293, 641, 5245, 382, 291, 603, 1401, 466, 294, 264, 3035, 366, 4664, 733, 295, 3817, 2685], "temperature": 0.0, "avg_logprob": -0.23621481518412746, "compression_ratio": 1.5972850678733033, "no_speech_prob": 3.7266206618369324e-06}, {"id": 594, "seek": 270648, "start": 2713.4, "end": 2719.88, "text": " They learn something about how pet heads look and how pet bodies look and pet images in general look they combine them all together", "tokens": [814, 1466, 746, 466, 577, 3817, 8050, 574, 293, 577, 3817, 7510, 574, 293, 3817, 5267, 294, 2674, 574, 436, 10432, 552, 439, 1214], "temperature": 0.0, "avg_logprob": -0.23621481518412746, "compression_ratio": 1.5972850678733033, "no_speech_prob": 3.7266206618369324e-06}, {"id": 595, "seek": 270648, "start": 2720.2400000000002, "end": 2722.2400000000002, "text": " And once they use all of this", "tokens": [400, 1564, 436, 764, 439, 295, 341], "temperature": 0.0, "avg_logprob": -0.23621481518412746, "compression_ratio": 1.5972850678733033, "no_speech_prob": 3.7266206618369324e-06}, {"id": 596, "seek": 270648, "start": 2722.76, "end": 2726.2, "text": " complex code and math they got an accuracy of", "tokens": [3997, 3089, 293, 5221, 436, 658, 364, 14170, 295], "temperature": 0.0, "avg_logprob": -0.23621481518412746, "compression_ratio": 1.5972850678733033, "no_speech_prob": 3.7266206618369324e-06}, {"id": 597, "seek": 270648, "start": 2727.56, "end": 2729.2, "text": " 59 percent", "tokens": [24624, 3043], "temperature": 0.0, "avg_logprob": -0.23621481518412746, "compression_ratio": 1.5972850678733033, "no_speech_prob": 3.7266206618369324e-06}, {"id": 598, "seek": 270648, "start": 2729.2, "end": 2731.2, "text": " Okay, so in 2012", "tokens": [1033, 11, 370, 294, 9125], "temperature": 0.0, "avg_logprob": -0.23621481518412746, "compression_ratio": 1.5972850678733033, "no_speech_prob": 3.7266206618369324e-06}, {"id": 599, "seek": 270648, "start": 2731.48, "end": 2733.48, "text": " this highly pet specific", "tokens": [341, 5405, 3817, 2685], "temperature": 0.0, "avg_logprob": -0.23621481518412746, "compression_ratio": 1.5972850678733033, "no_speech_prob": 3.7266206618369324e-06}, {"id": 600, "seek": 273348, "start": 2733.48, "end": 2740.88, "text": " Analysis got an accuracy of 59 percent least were the top researchers from Oxford University today in", "tokens": [38172, 658, 364, 14170, 295, 24624, 3043, 1935, 645, 264, 1192, 10309, 490, 24786, 3535, 965, 294], "temperature": 0.0, "avg_logprob": -0.2272613749784582, "compression_ratio": 1.517094017094017, "no_speech_prob": 3.4465599583199946e-06}, {"id": 601, "seek": 273348, "start": 2741.56, "end": 2743.16, "text": " 2018", "tokens": [6096], "temperature": 0.0, "avg_logprob": -0.2272613749784582, "compression_ratio": 1.517094017094017, "no_speech_prob": 3.4465599583199946e-06}, {"id": 602, "seek": 273348, "start": 2743.16, "end": 2744.68, "text": " with", "tokens": [365], "temperature": 0.0, "avg_logprob": -0.2272613749784582, "compression_ratio": 1.517094017094017, "no_speech_prob": 3.4465599583199946e-06}, {"id": 603, "seek": 273348, "start": 2744.68, "end": 2748.16, "text": " Basically if you go back and look at actually how much code we just wrote it's about", "tokens": [8537, 498, 291, 352, 646, 293, 574, 412, 767, 577, 709, 3089, 321, 445, 4114, 309, 311, 466], "temperature": 0.0, "avg_logprob": -0.2272613749784582, "compression_ratio": 1.517094017094017, "no_speech_prob": 3.4465599583199946e-06}, {"id": 604, "seek": 273348, "start": 2748.64, "end": 2753.62, "text": " Three lines of code the other stuff is just printing out things to see what we're doing we got", "tokens": [6244, 3876, 295, 3089, 264, 661, 1507, 307, 445, 14699, 484, 721, 281, 536, 437, 321, 434, 884, 321, 658], "temperature": 0.0, "avg_logprob": -0.2272613749784582, "compression_ratio": 1.517094017094017, "no_speech_prob": 3.4465599583199946e-06}, {"id": 605, "seek": 273348, "start": 2754.8, "end": 2759.36, "text": " 94 percent so 6 percent error so like that gives you a sense of", "tokens": [30849, 3043, 370, 1386, 3043, 6713, 370, 411, 300, 2709, 291, 257, 2020, 295], "temperature": 0.0, "avg_logprob": -0.2272613749784582, "compression_ratio": 1.517094017094017, "no_speech_prob": 3.4465599583199946e-06}, {"id": 606, "seek": 275936, "start": 2759.36, "end": 2766.36, "text": " You know how far we've come with deep learning and particularly with pytorch and fast AI how easy things are", "tokens": [509, 458, 577, 1400, 321, 600, 808, 365, 2452, 2539, 293, 4098, 365, 25878, 284, 339, 293, 2370, 7318, 577, 1858, 721, 366], "temperature": 0.0, "avg_logprob": -0.1801961430332117, "compression_ratio": 1.6487455197132617, "no_speech_prob": 3.219145582988858e-05}, {"id": 607, "seek": 275936, "start": 2767.44, "end": 2769.44, "text": " Yeah, so", "tokens": [865, 11, 370], "temperature": 0.0, "avg_logprob": -0.1801961430332117, "compression_ratio": 1.6487455197132617, "no_speech_prob": 3.219145582988858e-05}, {"id": 608, "seek": 275936, "start": 2769.92, "end": 2772.88, "text": " Before we take a break. I just want to check to see if we've got any", "tokens": [4546, 321, 747, 257, 1821, 13, 286, 445, 528, 281, 1520, 281, 536, 498, 321, 600, 658, 604], "temperature": 0.0, "avg_logprob": -0.1801961430332117, "compression_ratio": 1.6487455197132617, "no_speech_prob": 3.219145582988858e-05}, {"id": 609, "seek": 275936, "start": 2773.96, "end": 2778.52, "text": " And just remember if you're in the audience and you see a question that you want asked", "tokens": [400, 445, 1604, 498, 291, 434, 294, 264, 4034, 293, 291, 536, 257, 1168, 300, 291, 528, 2351], "temperature": 0.0, "avg_logprob": -0.1801961430332117, "compression_ratio": 1.6487455197132617, "no_speech_prob": 3.219145582988858e-05}, {"id": 610, "seek": 275936, "start": 2778.52, "end": 2783.2000000000003, "text": " Please click the love heart next to it so that Rachel knows that you want to hear about it", "tokens": [2555, 2052, 264, 959, 1917, 958, 281, 309, 370, 300, 14246, 3255, 300, 291, 528, 281, 1568, 466, 309], "temperature": 0.0, "avg_logprob": -0.1801961430332117, "compression_ratio": 1.6487455197132617, "no_speech_prob": 3.219145582988858e-05}, {"id": 611, "seek": 278320, "start": 2783.2, "end": 2789.96, "text": " Also, if there is something with six likes and Rachel didn't notice it, which is quite possible just just", "tokens": [2743, 11, 498, 456, 307, 746, 365, 2309, 5902, 293, 14246, 994, 380, 3449, 309, 11, 597, 307, 1596, 1944, 445, 445], "temperature": 0.0, "avg_logprob": -0.19919295704692874, "compression_ratio": 1.5866141732283465, "no_speech_prob": 1.4285335055319592e-05}, {"id": 612, "seek": 278320, "start": 2790.16, "end": 2797.48, "text": " Quote it in a reply and say hey at Rachel. This one's got six likes. Okay, so what we're going to do is", "tokens": [2326, 1370, 309, 294, 257, 16972, 293, 584, 4177, 412, 14246, 13, 639, 472, 311, 658, 2309, 5902, 13, 1033, 11, 370, 437, 321, 434, 516, 281, 360, 307], "temperature": 0.0, "avg_logprob": -0.19919295704692874, "compression_ratio": 1.5866141732283465, "no_speech_prob": 1.4285335055319592e-05}, {"id": 613, "seek": 278320, "start": 2797.48, "end": 2799.48, "text": " we're going to take a", "tokens": [321, 434, 516, 281, 747, 257], "temperature": 0.0, "avg_logprob": -0.19919295704692874, "compression_ratio": 1.5866141732283465, "no_speech_prob": 1.4285335055319592e-05}, {"id": 614, "seek": 278320, "start": 2799.7599999999998, "end": 2802.9199999999996, "text": " Eight-minute break so we'll come back at five past eight", "tokens": [17708, 12, 18256, 1821, 370, 321, 603, 808, 646, 412, 1732, 1791, 3180], "temperature": 0.0, "avg_logprob": -0.19919295704692874, "compression_ratio": 1.5866141732283465, "no_speech_prob": 1.4285335055319592e-05}, {"id": 615, "seek": 278320, "start": 2804.3199999999997, "end": 2808.6, "text": " So where we got to was we just we just trained a model", "tokens": [407, 689, 321, 658, 281, 390, 321, 445, 321, 445, 8895, 257, 2316], "temperature": 0.0, "avg_logprob": -0.19919295704692874, "compression_ratio": 1.5866141732283465, "no_speech_prob": 1.4285335055319592e-05}, {"id": 616, "seek": 278320, "start": 2808.6, "end": 2811.3599999999997, "text": " We don't exactly know what that involved or how it happened", "tokens": [492, 500, 380, 2293, 458, 437, 300, 3288, 420, 577, 309, 2011], "temperature": 0.0, "avg_logprob": -0.19919295704692874, "compression_ratio": 1.5866141732283465, "no_speech_prob": 1.4285335055319592e-05}, {"id": 617, "seek": 281136, "start": 2811.36, "end": 2814.08, "text": " But we do know that with three or four lines of code", "tokens": [583, 321, 360, 458, 300, 365, 1045, 420, 1451, 3876, 295, 3089], "temperature": 0.0, "avg_logprob": -0.23332301245795356, "compression_ratio": 1.5774058577405858, "no_speech_prob": 1.5206619536911603e-05}, {"id": 618, "seek": 281136, "start": 2814.6800000000003, "end": 2816.6800000000003, "text": " We built something which", "tokens": [492, 3094, 746, 597], "temperature": 0.0, "avg_logprob": -0.23332301245795356, "compression_ratio": 1.5774058577405858, "no_speech_prob": 1.5206619536911603e-05}, {"id": 619, "seek": 281136, "start": 2817.36, "end": 2819.8, "text": " smashed the accuracy of the state-of-the-art of", "tokens": [33269, 264, 14170, 295, 264, 1785, 12, 2670, 12, 3322, 12, 446, 295], "temperature": 0.0, "avg_logprob": -0.23332301245795356, "compression_ratio": 1.5774058577405858, "no_speech_prob": 1.5206619536911603e-05}, {"id": 620, "seek": 281136, "start": 2820.2400000000002, "end": 2826.56, "text": " 2012 six percent error certainly sounds like pretty impressive for something that can recognize different dog breeds and cat breeds", "tokens": [9125, 2309, 3043, 6713, 3297, 3263, 411, 1238, 8992, 337, 746, 300, 393, 5521, 819, 3000, 41609, 293, 3857, 41609], "temperature": 0.0, "avg_logprob": -0.23332301245795356, "compression_ratio": 1.5774058577405858, "no_speech_prob": 1.5206619536911603e-05}, {"id": 621, "seek": 281136, "start": 2828.36, "end": 2835.2000000000003, "text": " But we don't really know why it works that we will that's okay that and", "tokens": [583, 321, 500, 380, 534, 458, 983, 309, 1985, 300, 321, 486, 300, 311, 1392, 300, 293], "temperature": 0.0, "avg_logprob": -0.23332301245795356, "compression_ratio": 1.5774058577405858, "no_speech_prob": 1.5206619536911603e-05}, {"id": 622, "seek": 281136, "start": 2837.28, "end": 2839.4, "text": " In terms of getting the most out of this course", "tokens": [682, 2115, 295, 1242, 264, 881, 484, 295, 341, 1164], "temperature": 0.0, "avg_logprob": -0.23332301245795356, "compression_ratio": 1.5774058577405858, "no_speech_prob": 1.5206619536911603e-05}, {"id": 623, "seek": 283940, "start": 2839.4, "end": 2841.4, "text": " We", "tokens": [492], "temperature": 0.0, "avg_logprob": -0.23000897182507463, "compression_ratio": 1.625514403292181, "no_speech_prob": 1.2029453500872478e-05}, {"id": 624, "seek": 283940, "start": 2841.64, "end": 2847.1, "text": " Very very regularly here after the course is finished the same basic feedback", "tokens": [4372, 588, 11672, 510, 934, 264, 1164, 307, 4335, 264, 912, 3875, 5824], "temperature": 0.0, "avg_logprob": -0.23000897182507463, "compression_ratio": 1.625514403292181, "no_speech_prob": 1.2029453500872478e-05}, {"id": 625, "seek": 283940, "start": 2847.88, "end": 2850.52, "text": " Which this is literally copy and pasted for them forum", "tokens": [3013, 341, 307, 3736, 5055, 293, 1791, 292, 337, 552, 17542], "temperature": 0.0, "avg_logprob": -0.23000897182507463, "compression_ratio": 1.625514403292181, "no_speech_prob": 1.2029453500872478e-05}, {"id": 626, "seek": 283940, "start": 2850.52, "end": 2857.6800000000003, "text": " I fell into the habit of watching the lectures too much and googling too much about concepts without running the code", "tokens": [286, 5696, 666, 264, 7164, 295, 1976, 264, 16564, 886, 709, 293, 50061, 1688, 886, 709, 466, 10392, 1553, 2614, 264, 3089], "temperature": 0.0, "avg_logprob": -0.23000897182507463, "compression_ratio": 1.625514403292181, "no_speech_prob": 1.2029453500872478e-05}, {"id": 627, "seek": 283940, "start": 2858.2000000000003, "end": 2861.56, "text": " Now first I thought I should just read it and then research the theory", "tokens": [823, 700, 286, 1194, 286, 820, 445, 1401, 309, 293, 550, 2132, 264, 5261], "temperature": 0.0, "avg_logprob": -0.23000897182507463, "compression_ratio": 1.625514403292181, "no_speech_prob": 1.2029453500872478e-05}, {"id": 628, "seek": 283940, "start": 2862.2000000000003, "end": 2867.62, "text": " And we keep hearing people saying my number one regret is I just spent", "tokens": [400, 321, 1066, 4763, 561, 1566, 452, 1230, 472, 10879, 307, 286, 445, 4418], "temperature": 0.0, "avg_logprob": -0.23000897182507463, "compression_ratio": 1.625514403292181, "no_speech_prob": 1.2029453500872478e-05}, {"id": 629, "seek": 286762, "start": 2867.62, "end": 2869.62, "text": " 70 hours doing that", "tokens": [5285, 2496, 884, 300], "temperature": 0.0, "avg_logprob": -0.2190418783223854, "compression_ratio": 1.777327935222672, "no_speech_prob": 6.240866696316516e-06}, {"id": 630, "seek": 286762, "start": 2870.1, "end": 2874.42, "text": " And at the very end I started running the code and oh it turned out I learned a lot more", "tokens": [400, 412, 264, 588, 917, 286, 1409, 2614, 264, 3089, 293, 1954, 309, 3574, 484, 286, 3264, 257, 688, 544], "temperature": 0.0, "avg_logprob": -0.2190418783223854, "compression_ratio": 1.777327935222672, "no_speech_prob": 6.240866696316516e-06}, {"id": 631, "seek": 286762, "start": 2874.7, "end": 2877.04, "text": " So please run the code", "tokens": [407, 1767, 1190, 264, 3089], "temperature": 0.0, "avg_logprob": -0.2190418783223854, "compression_ratio": 1.777327935222672, "no_speech_prob": 6.240866696316516e-06}, {"id": 632, "seek": 286762, "start": 2877.9, "end": 2879.9, "text": " Really run the code I", "tokens": [4083, 1190, 264, 3089, 286], "temperature": 0.0, "avg_logprob": -0.2190418783223854, "compression_ratio": 1.777327935222672, "no_speech_prob": 6.240866696316516e-06}, {"id": 633, "seek": 286762, "start": 2880.2999999999997, "end": 2886.2599999999998, "text": " should have spent the majority of my time on the actual code in the notebooks running it seeing what goes in and", "tokens": [820, 362, 4418, 264, 6286, 295, 452, 565, 322, 264, 3539, 3089, 294, 264, 43782, 2614, 309, 2577, 437, 1709, 294, 293], "temperature": 0.0, "avg_logprob": -0.2190418783223854, "compression_ratio": 1.777327935222672, "no_speech_prob": 6.240866696316516e-06}, {"id": 634, "seek": 286762, "start": 2887.1, "end": 2893.9, "text": " Seeing what comes out so your most important skills to practice are learning and we're going to show you how to do this in", "tokens": [19703, 437, 1487, 484, 370, 428, 881, 1021, 3942, 281, 3124, 366, 2539, 293, 321, 434, 516, 281, 855, 291, 577, 281, 360, 341, 294], "temperature": 0.0, "avg_logprob": -0.2190418783223854, "compression_ratio": 1.777327935222672, "no_speech_prob": 6.240866696316516e-06}, {"id": 635, "seek": 289390, "start": 2893.9, "end": 2899.14, "text": " A lot more detail, but understanding what goes in and what goes out", "tokens": [316, 688, 544, 2607, 11, 457, 3701, 437, 1709, 294, 293, 437, 1709, 484], "temperature": 0.0, "avg_logprob": -0.18718413873152298, "compression_ratio": 1.7025641025641025, "no_speech_prob": 1.2218934898555744e-05}, {"id": 636, "seek": 289390, "start": 2900.06, "end": 2903.34, "text": " So we've already seen an example of looking at what goes in", "tokens": [407, 321, 600, 1217, 1612, 364, 1365, 295, 1237, 412, 437, 1709, 294], "temperature": 0.0, "avg_logprob": -0.18718413873152298, "compression_ratio": 1.7025641025641025, "no_speech_prob": 1.2218934898555744e-05}, {"id": 637, "seek": 289390, "start": 2904.2200000000003, "end": 2909.14, "text": " which is data dot show batch and that's going to show you examples of labels and", "tokens": [597, 307, 1412, 5893, 855, 15245, 293, 300, 311, 516, 281, 855, 291, 5110, 295, 16949, 293], "temperature": 0.0, "avg_logprob": -0.18718413873152298, "compression_ratio": 1.7025641025641025, "no_speech_prob": 1.2218934898555744e-05}, {"id": 638, "seek": 289390, "start": 2910.1, "end": 2911.62, "text": " images and", "tokens": [5267, 293], "temperature": 0.0, "avg_logprob": -0.18718413873152298, "compression_ratio": 1.7025641025641025, "no_speech_prob": 1.2218934898555744e-05}, {"id": 639, "seek": 289390, "start": 2911.62, "end": 2915.14, "text": " So next we're going to be seeing how to look at what came out", "tokens": [407, 958, 321, 434, 516, 281, 312, 2577, 577, 281, 574, 412, 437, 1361, 484], "temperature": 0.0, "avg_logprob": -0.18718413873152298, "compression_ratio": 1.7025641025641025, "no_speech_prob": 1.2218934898555744e-05}, {"id": 640, "seek": 289390, "start": 2915.86, "end": 2918.06, "text": " That's the most important thing to study", "tokens": [663, 311, 264, 881, 1021, 551, 281, 2979], "temperature": 0.0, "avg_logprob": -0.18718413873152298, "compression_ratio": 1.7025641025641025, "no_speech_prob": 1.2218934898555744e-05}, {"id": 641, "seek": 289390, "start": 2919.26, "end": 2920.78, "text": " as I said", "tokens": [382, 286, 848], "temperature": 0.0, "avg_logprob": -0.18718413873152298, "compression_ratio": 1.7025641025641025, "no_speech_prob": 1.2218934898555744e-05}, {"id": 642, "seek": 292078, "start": 2920.78, "end": 2927.6600000000003, "text": " The reason we've been able to do this so quickly is heavily because of the fast AI library now fast AI library is pretty new", "tokens": [440, 1778, 321, 600, 668, 1075, 281, 360, 341, 370, 2661, 307, 10950, 570, 295, 264, 2370, 7318, 6405, 586, 2370, 7318, 6405, 307, 1238, 777], "temperature": 0.0, "avg_logprob": -0.16989527043608046, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.8342268958804198e-05}, {"id": 643, "seek": 292078, "start": 2928.1000000000004, "end": 2936.32, "text": " But it's already getting an extraordinary amount of traction as you've seen all of the major cloud providers either support it or about to support it", "tokens": [583, 309, 311, 1217, 1242, 364, 10581, 2372, 295, 23558, 382, 291, 600, 1612, 439, 295, 264, 2563, 4588, 11330, 2139, 1406, 309, 420, 466, 281, 1406, 309], "temperature": 0.0, "avg_logprob": -0.16989527043608046, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.8342268958804198e-05}, {"id": 644, "seek": 292078, "start": 2936.78, "end": 2940.3, "text": " a lot of researchers are starting to use it it's it's", "tokens": [257, 688, 295, 10309, 366, 2891, 281, 764, 309, 309, 311, 309, 311], "temperature": 0.0, "avg_logprob": -0.16989527043608046, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.8342268958804198e-05}, {"id": 645, "seek": 292078, "start": 2941.1400000000003, "end": 2948.34, "text": " Doing making a lot of things a lot easier, but it's also making new things possible and so", "tokens": [18496, 1455, 257, 688, 295, 721, 257, 688, 3571, 11, 457, 309, 311, 611, 1455, 777, 721, 1944, 293, 370], "temperature": 0.0, "avg_logprob": -0.16989527043608046, "compression_ratio": 1.7102040816326531, "no_speech_prob": 1.8342268958804198e-05}, {"id": 646, "seek": 294834, "start": 2948.34, "end": 2956.06, "text": " Really understanding the fast AI software is something which is going to take you a long way and the best way to really understand the faster", "tokens": [4083, 3701, 264, 2370, 7318, 4722, 307, 746, 597, 307, 516, 281, 747, 291, 257, 938, 636, 293, 264, 1151, 636, 281, 534, 1223, 264, 4663], "temperature": 0.0, "avg_logprob": -0.21227931032086364, "compression_ratio": 1.8506224066390042, "no_speech_prob": 5.95505116507411e-06}, {"id": 647, "seek": 294834, "start": 2956.06, "end": 2958.46, "text": " You're software. Well is by using the fast AI", "tokens": [509, 434, 4722, 13, 1042, 307, 538, 1228, 264, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.21227931032086364, "compression_ratio": 1.8506224066390042, "no_speech_prob": 5.95505116507411e-06}, {"id": 648, "seek": 294834, "start": 2959.42, "end": 2963.58, "text": " Documentation and we'll be learning more about the fast AI documentation shortly", "tokens": [37684, 399, 293, 321, 603, 312, 2539, 544, 466, 264, 2370, 7318, 14333, 13392], "temperature": 0.0, "avg_logprob": -0.21227931032086364, "compression_ratio": 1.8506224066390042, "no_speech_prob": 5.95505116507411e-06}, {"id": 649, "seek": 294834, "start": 2965.86, "end": 2971.2200000000003, "text": " So, how does it compare I mean there's really only one major other piece of software like fast AI", "tokens": [407, 11, 577, 775, 309, 6794, 286, 914, 456, 311, 534, 787, 472, 2563, 661, 2522, 295, 4722, 411, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.21227931032086364, "compression_ratio": 1.8506224066390042, "no_speech_prob": 5.95505116507411e-06}, {"id": 650, "seek": 294834, "start": 2971.2200000000003, "end": 2976.6200000000003, "text": " That is something that tries to make deep learning easy to use and that's Keras", "tokens": [663, 307, 746, 300, 9898, 281, 652, 2452, 2539, 1858, 281, 764, 293, 300, 311, 591, 6985], "temperature": 0.0, "avg_logprob": -0.21227931032086364, "compression_ratio": 1.8506224066390042, "no_speech_prob": 5.95505116507411e-06}, {"id": 651, "seek": 297662, "start": 2976.62, "end": 2983.58, "text": " Our Keras is a really terrific piece of software. We actually used it for the previous courses until we switched to fast AI", "tokens": [2621, 591, 6985, 307, 257, 534, 20899, 2522, 295, 4722, 13, 492, 767, 1143, 309, 337, 264, 3894, 7712, 1826, 321, 16858, 281, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.18468151297620547, "compression_ratio": 1.569672131147541, "no_speech_prob": 1.1478547094156966e-05}, {"id": 652, "seek": 297662, "start": 2984.9, "end": 2986.9, "text": " It runs on top of tensorflow", "tokens": [467, 6676, 322, 1192, 295, 40863, 10565], "temperature": 0.0, "avg_logprob": -0.18468151297620547, "compression_ratio": 1.569672131147541, "no_speech_prob": 1.1478547094156966e-05}, {"id": 653, "seek": 297662, "start": 2987.02, "end": 2993.18, "text": " It was kind of the gold standard for making deep learning easy to use before but life is much easier with fast AI", "tokens": [467, 390, 733, 295, 264, 3821, 3832, 337, 1455, 2452, 2539, 1858, 281, 764, 949, 457, 993, 307, 709, 3571, 365, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.18468151297620547, "compression_ratio": 1.569672131147541, "no_speech_prob": 1.1478547094156966e-05}, {"id": 654, "seek": 297662, "start": 2993.22, "end": 2996.42, "text": " So if you look for example at the last year's course", "tokens": [407, 498, 291, 574, 337, 1365, 412, 264, 1036, 1064, 311, 1164], "temperature": 0.0, "avg_logprob": -0.18468151297620547, "compression_ratio": 1.569672131147541, "no_speech_prob": 1.1478547094156966e-05}, {"id": 655, "seek": 297662, "start": 2997.06, "end": 2999.3399999999997, "text": " Exercise which is getting dogs versus cats", "tokens": [44307, 597, 307, 1242, 7197, 5717, 11111], "temperature": 0.0, "avg_logprob": -0.18468151297620547, "compression_ratio": 1.569672131147541, "no_speech_prob": 1.1478547094156966e-05}, {"id": 656, "seek": 297662, "start": 3001.7799999999997, "end": 3003.7799999999997, "text": " Fast AI lets you get", "tokens": [15968, 7318, 6653, 291, 483], "temperature": 0.0, "avg_logprob": -0.18468151297620547, "compression_ratio": 1.569672131147541, "no_speech_prob": 1.1478547094156966e-05}, {"id": 657, "seek": 300378, "start": 3003.78, "end": 3008.6000000000004, "text": " More much more accurate less than half the error on a validation set, of course", "tokens": [5048, 709, 544, 8559, 1570, 813, 1922, 264, 6713, 322, 257, 24071, 992, 11, 295, 1164], "temperature": 0.0, "avg_logprob": -0.1618446574491613, "compression_ratio": 1.7832512315270936, "no_speech_prob": 3.6119649848842528e-06}, {"id": 658, "seek": 300378, "start": 3009.9, "end": 3011.7000000000003, "text": " training time is", "tokens": [3097, 565, 307], "temperature": 0.0, "avg_logprob": -0.1618446574491613, "compression_ratio": 1.7832512315270936, "no_speech_prob": 3.6119649848842528e-06}, {"id": 659, "seek": 300378, "start": 3011.7000000000003, "end": 3013.7000000000003, "text": " less than half the time", "tokens": [1570, 813, 1922, 264, 565], "temperature": 0.0, "avg_logprob": -0.1618446574491613, "compression_ratio": 1.7832512315270936, "no_speech_prob": 3.6119649848842528e-06}, {"id": 660, "seek": 300378, "start": 3014.5, "end": 3019.1000000000004, "text": " Lines of code is about a sixth of the lines of code and the lines of code", "tokens": [441, 1652, 295, 3089, 307, 466, 257, 15102, 295, 264, 3876, 295, 3089, 293, 264, 3876, 295, 3089], "temperature": 0.0, "avg_logprob": -0.1618446574491613, "compression_ratio": 1.7832512315270936, "no_speech_prob": 3.6119649848842528e-06}, {"id": 661, "seek": 300378, "start": 3020.1800000000003, "end": 3026.6200000000003, "text": " More important than you might realize because those 31 lines of Keras code involve you making a lot of decisions", "tokens": [5048, 1021, 813, 291, 1062, 4325, 570, 729, 10353, 3876, 295, 591, 6985, 3089, 9494, 291, 1455, 257, 688, 295, 5327], "temperature": 0.0, "avg_logprob": -0.1618446574491613, "compression_ratio": 1.7832512315270936, "no_speech_prob": 3.6119649848842528e-06}, {"id": 662, "seek": 300378, "start": 3027.6200000000003, "end": 3030.1800000000003, "text": " Setting lots of parameters doing lots of configuration", "tokens": [21063, 3195, 295, 9834, 884, 3195, 295, 11694], "temperature": 0.0, "avg_logprob": -0.1618446574491613, "compression_ratio": 1.7832512315270936, "no_speech_prob": 3.6119649848842528e-06}, {"id": 663, "seek": 303018, "start": 3030.18, "end": 3036.12, "text": " So that's all stuff where you have to know how to set those things to get kind of best practice results", "tokens": [407, 300, 311, 439, 1507, 689, 291, 362, 281, 458, 577, 281, 992, 729, 721, 281, 483, 733, 295, 1151, 3124, 3542], "temperature": 0.0, "avg_logprob": -0.1735294148073358, "compression_ratio": 1.6836363636363636, "no_speech_prob": 3.905452103936113e-06}, {"id": 664, "seek": 303018, "start": 3036.3399999999997, "end": 3038.3399999999997, "text": " Where else these five lines of code?", "tokens": [2305, 1646, 613, 1732, 3876, 295, 3089, 30], "temperature": 0.0, "avg_logprob": -0.1735294148073358, "compression_ratio": 1.6836363636363636, "no_speech_prob": 3.905452103936113e-06}, {"id": 665, "seek": 303018, "start": 3039.02, "end": 3043.94, "text": " Anytime we know what to do for you. We do it for you anytime we can pick a good default we pick it for you", "tokens": [39401, 321, 458, 437, 281, 360, 337, 291, 13, 492, 360, 309, 337, 291, 13038, 321, 393, 1888, 257, 665, 7576, 321, 1888, 309, 337, 291], "temperature": 0.0, "avg_logprob": -0.1735294148073358, "compression_ratio": 1.6836363636363636, "no_speech_prob": 3.905452103936113e-06}, {"id": 666, "seek": 303018, "start": 3043.94, "end": 3045.94, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.1735294148073358, "compression_ratio": 1.6836363636363636, "no_speech_prob": 3.905452103936113e-06}, {"id": 667, "seek": 303018, "start": 3045.94, "end": 3052.72, "text": " Hopefully you'll find this a really useful library not just for learning deep learning but for taking it a very long way", "tokens": [10429, 291, 603, 915, 341, 257, 534, 4420, 6405, 406, 445, 337, 2539, 2452, 2539, 457, 337, 1940, 309, 257, 588, 938, 636], "temperature": 0.0, "avg_logprob": -0.1735294148073358, "compression_ratio": 1.6836363636363636, "no_speech_prob": 3.905452103936113e-06}, {"id": 668, "seek": 303018, "start": 3053.16, "end": 3058.5, "text": " How far can you take it? Well as you'll see all of the research that we do at fast AI", "tokens": [1012, 1400, 393, 291, 747, 309, 30, 1042, 382, 291, 603, 536, 439, 295, 264, 2132, 300, 321, 360, 412, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.1735294148073358, "compression_ratio": 1.6836363636363636, "no_speech_prob": 3.905452103936113e-06}, {"id": 669, "seek": 305850, "start": 3058.5, "end": 3060.5, "text": " uses the library and", "tokens": [4960, 264, 6405, 293], "temperature": 0.0, "avg_logprob": -0.23686189854398687, "compression_ratio": 1.6653543307086613, "no_speech_prob": 2.014508208958432e-05}, {"id": 670, "seek": 305850, "start": 3060.86, "end": 3064.76, "text": " An example of the research we did which was recently featured in wired", "tokens": [1107, 1365, 295, 264, 2132, 321, 630, 597, 390, 3938, 13822, 294, 27415], "temperature": 0.0, "avg_logprob": -0.23686189854398687, "compression_ratio": 1.6653543307086613, "no_speech_prob": 2.014508208958432e-05}, {"id": 671, "seek": 305850, "start": 3065.46, "end": 3067.46, "text": " describes a new", "tokens": [15626, 257, 777], "temperature": 0.0, "avg_logprob": -0.23686189854398687, "compression_ratio": 1.6653543307086613, "no_speech_prob": 2.014508208958432e-05}, {"id": 672, "seek": 305850, "start": 3067.58, "end": 3073.0, "text": " breakthrough in a natural language processing processing which people are calling the image net moment", "tokens": [22397, 294, 257, 3303, 2856, 9007, 9007, 597, 561, 366, 5141, 264, 3256, 2533, 1623], "temperature": 0.0, "avg_logprob": -0.23686189854398687, "compression_ratio": 1.6653543307086613, "no_speech_prob": 2.014508208958432e-05}, {"id": 673, "seek": 305850, "start": 3073.0, "end": 3078.06, "text": " Which is basically we broke a new state-of-the-art result in text classification", "tokens": [3013, 307, 1936, 321, 6902, 257, 777, 1785, 12, 2670, 12, 3322, 12, 446, 1874, 294, 2487, 21538], "temperature": 0.0, "avg_logprob": -0.23686189854398687, "compression_ratio": 1.6653543307086613, "no_speech_prob": 2.014508208958432e-05}, {"id": 674, "seek": 305850, "start": 3078.46, "end": 3085.82, "text": " Which open AI then built on top of our paper to do with more compute and more data and some different tasks to take it even further", "tokens": [3013, 1269, 7318, 550, 3094, 322, 1192, 295, 527, 3035, 281, 360, 365, 544, 14722, 293, 544, 1412, 293, 512, 819, 9608, 281, 747, 309, 754, 3052], "temperature": 0.0, "avg_logprob": -0.23686189854398687, "compression_ratio": 1.6653543307086613, "no_speech_prob": 2.014508208958432e-05}, {"id": 675, "seek": 308582, "start": 3085.82, "end": 3087.38, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.20226275126139323, "compression_ratio": 1.7236842105263157, "no_speech_prob": 1.922218143590726e-05}, {"id": 676, "seek": 308582, "start": 3087.38, "end": 3094.1400000000003, "text": " Like this is an example of something that we've done in the last six months in conjunction actually with my colleagues Sebastian Ruda", "tokens": [1743, 341, 307, 364, 1365, 295, 746, 300, 321, 600, 1096, 294, 264, 1036, 2309, 2493, 294, 27482, 767, 365, 452, 7734, 31102, 497, 11152], "temperature": 0.0, "avg_logprob": -0.20226275126139323, "compression_ratio": 1.7236842105263157, "no_speech_prob": 1.922218143590726e-05}, {"id": 677, "seek": 308582, "start": 3096.38, "end": 3102.82, "text": " Example of something that's being built in the fast AI library and you're going to learn how to use this brand new model in", "tokens": [24755, 781, 295, 746, 300, 311, 885, 3094, 294, 264, 2370, 7318, 6405, 293, 291, 434, 516, 281, 1466, 577, 281, 764, 341, 3360, 777, 2316, 294], "temperature": 0.0, "avg_logprob": -0.20226275126139323, "compression_ratio": 1.7236842105263157, "no_speech_prob": 1.922218143590726e-05}, {"id": 678, "seek": 308582, "start": 3103.42, "end": 3109.7200000000003, "text": " Three lessons time and you're actually going to get this exact result from this exact paper yourself", "tokens": [6244, 8820, 565, 293, 291, 434, 767, 516, 281, 483, 341, 1900, 1874, 490, 341, 1900, 3035, 1803], "temperature": 0.0, "avg_logprob": -0.20226275126139323, "compression_ratio": 1.7236842105263157, "no_speech_prob": 1.922218143590726e-05}, {"id": 679, "seek": 308582, "start": 3111.42, "end": 3114.1400000000003, "text": " Another example one of our alums", "tokens": [3996, 1365, 472, 295, 527, 419, 8099], "temperature": 0.0, "avg_logprob": -0.20226275126139323, "compression_ratio": 1.7236842105263157, "no_speech_prob": 1.922218143590726e-05}, {"id": 680, "seek": 311414, "start": 3114.14, "end": 3116.14, "text": " Hamel Hussein", "tokens": [8234, 338, 21282, 33042], "temperature": 0.0, "avg_logprob": -0.15082449714342752, "compression_ratio": 1.5719844357976653, "no_speech_prob": 1.0129721886187326e-05}, {"id": 681, "seek": 311414, "start": 3116.66, "end": 3124.22, "text": " Who you'll come across on the forum plenty because he's a great guy very active built a new system for natural language semantic code search", "tokens": [2102, 291, 603, 808, 2108, 322, 264, 17542, 7140, 570, 415, 311, 257, 869, 2146, 588, 4967, 3094, 257, 777, 1185, 337, 3303, 2856, 47982, 3089, 3164], "temperature": 0.0, "avg_logprob": -0.15082449714342752, "compression_ratio": 1.5719844357976653, "no_speech_prob": 1.0129721886187326e-05}, {"id": 682, "seek": 311414, "start": 3124.22, "end": 3126.22, "text": " You can find it on github", "tokens": [509, 393, 915, 309, 322, 290, 355, 836], "temperature": 0.0, "avg_logprob": -0.15082449714342752, "compression_ratio": 1.5719844357976653, "no_speech_prob": 1.0129721886187326e-05}, {"id": 683, "seek": 311414, "start": 3126.58, "end": 3133.3399999999997, "text": " Where you can actually type in English sentences and find snippets of code that do the thing you ask for and again", "tokens": [2305, 291, 393, 767, 2010, 294, 3669, 16579, 293, 915, 35623, 1385, 295, 3089, 300, 360, 264, 551, 291, 1029, 337, 293, 797], "temperature": 0.0, "avg_logprob": -0.15082449714342752, "compression_ratio": 1.5719844357976653, "no_speech_prob": 1.0129721886187326e-05}, {"id": 684, "seek": 311414, "start": 3133.3399999999997, "end": 3138.18, "text": " That's being built with the fast AI library using the techniques. You'll be learning in the next seven weeks", "tokens": [663, 311, 885, 3094, 365, 264, 2370, 7318, 6405, 1228, 264, 7512, 13, 509, 603, 312, 2539, 294, 264, 958, 3407, 3259], "temperature": 0.0, "avg_logprob": -0.15082449714342752, "compression_ratio": 1.5719844357976653, "no_speech_prob": 1.0129721886187326e-05}, {"id": 685, "seek": 313818, "start": 3138.18, "end": 3144.14, "text": " In production in production. Yeah. Well, it's it's I think at this stage. It's a part of their experiments platform", "tokens": [682, 4265, 294, 4265, 13, 865, 13, 1042, 11, 309, 311, 309, 311, 286, 519, 412, 341, 3233, 13, 467, 311, 257, 644, 295, 641, 12050, 3663], "temperature": 0.0, "avg_logprob": -0.1981123978236936, "compression_ratio": 1.7380952380952381, "no_speech_prob": 8.013267688511405e-06}, {"id": 686, "seek": 313818, "start": 3144.14, "end": 3146.2599999999998, "text": " So it's kind of pre production I guess", "tokens": [407, 309, 311, 733, 295, 659, 4265, 286, 2041], "temperature": 0.0, "avg_logprob": -0.1981123978236936, "compression_ratio": 1.7380952380952381, "no_speech_prob": 8.013267688511405e-06}, {"id": 687, "seek": 313818, "start": 3147.18, "end": 3149.18, "text": " and so the best place to", "tokens": [293, 370, 264, 1151, 1081, 281], "temperature": 0.0, "avg_logprob": -0.1981123978236936, "compression_ratio": 1.7380952380952381, "no_speech_prob": 8.013267688511405e-06}, {"id": 688, "seek": 313818, "start": 3150.06, "end": 3154.2799999999997, "text": " Learn about these things and get involved from these things is on the forums", "tokens": [17216, 466, 613, 721, 293, 483, 3288, 490, 613, 721, 307, 322, 264, 26998], "temperature": 0.0, "avg_logprob": -0.1981123978236936, "compression_ratio": 1.7380952380952381, "no_speech_prob": 8.013267688511405e-06}, {"id": 689, "seek": 313818, "start": 3154.98, "end": 3160.8999999999996, "text": " Where as well as categories for each part of the course, there's also a general category for deep learning where people talk about", "tokens": [2305, 382, 731, 382, 10479, 337, 1184, 644, 295, 264, 1164, 11, 456, 311, 611, 257, 2674, 7719, 337, 2452, 2539, 689, 561, 751, 466], "temperature": 0.0, "avg_logprob": -0.1981123978236936, "compression_ratio": 1.7380952380952381, "no_speech_prob": 8.013267688511405e-06}, {"id": 690, "seek": 313818, "start": 3161.7, "end": 3164.46, "text": " research papers applications so on and so forth", "tokens": [2132, 10577, 5821, 370, 322, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.1981123978236936, "compression_ratio": 1.7380952380952381, "no_speech_prob": 8.013267688511405e-06}, {"id": 691, "seek": 313818, "start": 3165.66, "end": 3167.66, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.1981123978236936, "compression_ratio": 1.7380952380952381, "no_speech_prob": 8.013267688511405e-06}, {"id": 692, "seek": 316766, "start": 3167.66, "end": 3169.66, "text": " Even though today", "tokens": [2754, 1673, 965], "temperature": 0.0, "avg_logprob": -0.17331442399458452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2218510164530016e-05}, {"id": 693, "seek": 316766, "start": 3169.66, "end": 3175.94, "text": " We're kind of going to focus on a small number of lines of code to do a particular thing, which is image classification", "tokens": [492, 434, 733, 295, 516, 281, 1879, 322, 257, 1359, 1230, 295, 3876, 295, 3089, 281, 360, 257, 1729, 551, 11, 597, 307, 3256, 21538], "temperature": 0.0, "avg_logprob": -0.17331442399458452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2218510164530016e-05}, {"id": 694, "seek": 316766, "start": 3176.54, "end": 3183.44, "text": " And we're not learning much math or theory or whatever over these seven weeks and then part two another seven weeks", "tokens": [400, 321, 434, 406, 2539, 709, 5221, 420, 5261, 420, 2035, 670, 613, 3407, 3259, 293, 550, 644, 732, 1071, 3407, 3259], "temperature": 0.0, "avg_logprob": -0.17331442399458452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2218510164530016e-05}, {"id": 695, "seek": 316766, "start": 3183.46, "end": 3187.8599999999997, "text": " We're going to go deeper and deeper and deeper. And so where can that take you? I want to give you some examples", "tokens": [492, 434, 516, 281, 352, 7731, 293, 7731, 293, 7731, 13, 400, 370, 689, 393, 300, 747, 291, 30, 286, 528, 281, 976, 291, 512, 5110], "temperature": 0.0, "avg_logprob": -0.17331442399458452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2218510164530016e-05}, {"id": 696, "seek": 316766, "start": 3188.74, "end": 3193.62, "text": " That there is Sarah Hooker. She did our first course a couple of years ago", "tokens": [663, 456, 307, 9519, 33132, 260, 13, 1240, 630, 527, 700, 1164, 257, 1916, 295, 924, 2057], "temperature": 0.0, "avg_logprob": -0.17331442399458452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2218510164530016e-05}, {"id": 697, "seek": 316766, "start": 3194.8199999999997, "end": 3196.8199999999997, "text": " Her background was", "tokens": [3204, 3678, 390], "temperature": 0.0, "avg_logprob": -0.17331442399458452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.2218510164530016e-05}, {"id": 698, "seek": 319682, "start": 3196.82, "end": 3204.5, "text": " Economics didn't have a background in coding math computer science. I think she started learning to code two years before she took our course", "tokens": [39024, 994, 380, 362, 257, 3678, 294, 17720, 5221, 3820, 3497, 13, 286, 519, 750, 1409, 2539, 281, 3089, 732, 924, 949, 750, 1890, 527, 1164], "temperature": 0.0, "avg_logprob": -0.18522154766580332, "compression_ratio": 1.5296803652968036, "no_speech_prob": 2.0144965674262494e-05}, {"id": 699, "seek": 319682, "start": 3205.6200000000003, "end": 3209.6200000000003, "text": " She helped develop something at she started a nonprofit called", "tokens": [1240, 4254, 1499, 746, 412, 750, 1409, 257, 23348, 1219], "temperature": 0.0, "avg_logprob": -0.18522154766580332, "compression_ratio": 1.5296803652968036, "no_speech_prob": 2.0144965674262494e-05}, {"id": 700, "seek": 319682, "start": 3211.34, "end": 3212.82, "text": " Delta analytics", "tokens": [18183, 15370], "temperature": 0.0, "avg_logprob": -0.18522154766580332, "compression_ratio": 1.5296803652968036, "no_speech_prob": 2.0144965674262494e-05}, {"id": 701, "seek": 319682, "start": 3212.82, "end": 3220.36, "text": " They helped build this amazing system where they attached old mobile phones to trees in the Kenyan rainforests and", "tokens": [814, 4254, 1322, 341, 2243, 1185, 689, 436, 8570, 1331, 6013, 10216, 281, 5852, 294, 264, 8273, 6277, 48531, 82, 293], "temperature": 0.0, "avg_logprob": -0.18522154766580332, "compression_ratio": 1.5296803652968036, "no_speech_prob": 2.0144965674262494e-05}, {"id": 702, "seek": 322036, "start": 3220.36, "end": 3227.7200000000003, "text": " Used it to listen for chainsaw noises and then they used deep learning to figure out when there was a chainsaw being used", "tokens": [43237, 309, 281, 2140, 337, 12626, 1607, 14620, 293, 550, 436, 1143, 2452, 2539, 281, 2573, 484, 562, 456, 390, 257, 12626, 1607, 885, 1143], "temperature": 0.0, "avg_logprob": -0.14579103390375772, "compression_ratio": 1.7079646017699115, "no_speech_prob": 5.862685611646157e-06}, {"id": 703, "seek": 322036, "start": 3227.7200000000003, "end": 3234.6400000000003, "text": " And then they had a system set up to alert ranges to go out and stop a legal deforestation in the rainforests", "tokens": [400, 550, 436, 632, 257, 1185, 992, 493, 281, 9615, 22526, 281, 352, 484, 293, 1590, 257, 5089, 368, 845, 19159, 294, 264, 48531, 82], "temperature": 0.0, "avg_logprob": -0.14579103390375772, "compression_ratio": 1.7079646017699115, "no_speech_prob": 5.862685611646157e-06}, {"id": 704, "seek": 322036, "start": 3235.04, "end": 3240.1200000000003, "text": " So that was something that she was doing while she was in the course as part of her kind of class projects", "tokens": [407, 300, 390, 746, 300, 750, 390, 884, 1339, 750, 390, 294, 264, 1164, 382, 644, 295, 720, 733, 295, 1508, 4455], "temperature": 0.0, "avg_logprob": -0.14579103390375772, "compression_ratio": 1.7079646017699115, "no_speech_prob": 5.862685611646157e-06}, {"id": 705, "seek": 322036, "start": 3241.32, "end": 3243.32, "text": " What's she doing now?", "tokens": [708, 311, 750, 884, 586, 30], "temperature": 0.0, "avg_logprob": -0.14579103390375772, "compression_ratio": 1.7079646017699115, "no_speech_prob": 5.862685611646157e-06}, {"id": 706, "seek": 322036, "start": 3243.4, "end": 3245.4, "text": " She is now a Google brain", "tokens": [1240, 307, 586, 257, 3329, 3567], "temperature": 0.0, "avg_logprob": -0.14579103390375772, "compression_ratio": 1.7079646017699115, "no_speech_prob": 5.862685611646157e-06}, {"id": 707, "seek": 324540, "start": 3245.4, "end": 3251.08, "text": " researcher, which I guess is one of the top if not the top place to do deep learning", "tokens": [21751, 11, 597, 286, 2041, 307, 472, 295, 264, 1192, 498, 406, 264, 1192, 1081, 281, 360, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.17868943441481816, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.4970164556871168e-05}, {"id": 708, "seek": 324540, "start": 3251.96, "end": 3254.28, "text": " She's just been publishing some papers", "tokens": [1240, 311, 445, 668, 17832, 512, 10577], "temperature": 0.0, "avg_logprob": -0.17868943441481816, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.4970164556871168e-05}, {"id": 709, "seek": 324540, "start": 3254.76, "end": 3261.84, "text": " Now she is going to Africa to set up Google brains first deep learning AI research center in Africa", "tokens": [823, 750, 307, 516, 281, 7349, 281, 992, 493, 3329, 15442, 700, 2452, 2539, 7318, 2132, 3056, 294, 7349], "temperature": 0.0, "avg_logprob": -0.17868943441481816, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.4970164556871168e-05}, {"id": 710, "seek": 324540, "start": 3261.88, "end": 3265.5, "text": " Now I'll say like she worked her ass off, you know", "tokens": [823, 286, 603, 584, 411, 750, 2732, 720, 1256, 766, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.17868943441481816, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.4970164556871168e-05}, {"id": 711, "seek": 324540, "start": 3265.5, "end": 3270.4, "text": " She really really invested in this course not just doing all of the assignments", "tokens": [1240, 534, 534, 13104, 294, 341, 1164, 406, 445, 884, 439, 295, 264, 22546], "temperature": 0.0, "avg_logprob": -0.17868943441481816, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.4970164556871168e-05}, {"id": 712, "seek": 327040, "start": 3270.4, "end": 3276.36, "text": " But also going out and reading Ian Goodfellow's book and doing lots of other things, but it really shows", "tokens": [583, 611, 516, 484, 293, 3760, 19595, 2205, 69, 21348, 311, 1446, 293, 884, 3195, 295, 661, 721, 11, 457, 309, 534, 3110], "temperature": 0.0, "avg_logprob": -0.21405820148747143, "compression_ratio": 1.5176991150442478, "no_speech_prob": 1.300633175560506e-05}, {"id": 713, "seek": 327040, "start": 3276.96, "end": 3283.92, "text": " Where somebody who has no computer science or math background at all can be now one of the world's top", "tokens": [2305, 2618, 567, 575, 572, 3820, 3497, 420, 5221, 3678, 412, 439, 393, 312, 586, 472, 295, 264, 1002, 311, 1192], "temperature": 0.0, "avg_logprob": -0.21405820148747143, "compression_ratio": 1.5176991150442478, "no_speech_prob": 1.300633175560506e-05}, {"id": 714, "seek": 327040, "start": 3284.52, "end": 3288.0, "text": " deep-learning researchers and doing very valuable work", "tokens": [2452, 12, 47204, 10309, 293, 884, 588, 8263, 589], "temperature": 0.0, "avg_logprob": -0.21405820148747143, "compression_ratio": 1.5176991150442478, "no_speech_prob": 1.300633175560506e-05}, {"id": 715, "seek": 327040, "start": 3289.56, "end": 3293.7200000000003, "text": " Another example from our most recent course Christine pain", "tokens": [3996, 1365, 490, 527, 881, 5162, 1164, 24038, 1822], "temperature": 0.0, "avg_logprob": -0.21405820148747143, "compression_ratio": 1.5176991150442478, "no_speech_prob": 1.300633175560506e-05}, {"id": 716, "seek": 327040, "start": 3294.88, "end": 3296.8, "text": " she", "tokens": [750], "temperature": 0.0, "avg_logprob": -0.21405820148747143, "compression_ratio": 1.5176991150442478, "no_speech_prob": 1.300633175560506e-05}, {"id": 717, "seek": 327040, "start": 3296.8, "end": 3298.8, "text": " Is now at open AI", "tokens": [1119, 586, 412, 1269, 7318], "temperature": 0.0, "avg_logprob": -0.21405820148747143, "compression_ratio": 1.5176991150442478, "no_speech_prob": 1.300633175560506e-05}, {"id": 718, "seek": 329880, "start": 3298.8, "end": 3299.7200000000003, "text": " AI", "tokens": [7318], "temperature": 0.0, "avg_logprob": -0.2159483167860243, "compression_ratio": 1.6868131868131868, "no_speech_prob": 1.5688867279095575e-05}, {"id": 719, "seek": 329880, "start": 3299.7200000000003, "end": 3307.4, "text": " And you can find her post and actually listen to her music samples of she actually built something to do", "tokens": [400, 291, 393, 915, 720, 2183, 293, 767, 2140, 281, 720, 1318, 10938, 295, 750, 767, 3094, 746, 281, 360], "temperature": 0.0, "avg_logprob": -0.2159483167860243, "compression_ratio": 1.6868131868131868, "no_speech_prob": 1.5688867279095575e-05}, {"id": 720, "seek": 329880, "start": 3309.1600000000003, "end": 3313.1200000000003, "text": " Automatically create chamber music compositions that you can play and you can listen to online", "tokens": [24619, 5030, 1884, 13610, 1318, 43401, 300, 291, 393, 862, 293, 291, 393, 2140, 281, 2950], "temperature": 0.0, "avg_logprob": -0.2159483167860243, "compression_ratio": 1.6868131868131868, "no_speech_prob": 1.5688867279095575e-05}, {"id": 721, "seek": 329880, "start": 3313.88, "end": 3315.88, "text": " And so again, it's her background", "tokens": [400, 370, 797, 11, 309, 311, 720, 3678], "temperature": 0.0, "avg_logprob": -0.2159483167860243, "compression_ratio": 1.6868131868131868, "no_speech_prob": 1.5688867279095575e-05}, {"id": 722, "seek": 329880, "start": 3316.5600000000004, "end": 3318.5600000000004, "text": " math and computer science", "tokens": [5221, 293, 3820, 3497], "temperature": 0.0, "avg_logprob": -0.2159483167860243, "compression_ratio": 1.6868131868131868, "no_speech_prob": 1.5688867279095575e-05}, {"id": 723, "seek": 329880, "start": 3319.6800000000003, "end": 3323.4, "text": " Actually, that's her there classical pianist", "tokens": [5135, 11, 300, 311, 720, 456, 13735, 32198, 468], "temperature": 0.0, "avg_logprob": -0.2159483167860243, "compression_ratio": 1.6868131868131868, "no_speech_prob": 1.5688867279095575e-05}, {"id": 724, "seek": 332340, "start": 3323.4, "end": 3327.6, "text": " Now I will say she's not your average classical pianist", "tokens": [823, 286, 486, 584, 750, 311, 406, 428, 4274, 13735, 32198, 468], "temperature": 0.0, "avg_logprob": -0.230623653956822, "compression_ratio": 1.6898954703832754, "no_speech_prob": 7.527750312874559e-06}, {"id": 725, "seek": 332340, "start": 3327.6, "end": 3332.48, "text": " She's a classical pianist who also has a master's in medical research from Stanford and studied neuroscience", "tokens": [1240, 311, 257, 13735, 32198, 468, 567, 611, 575, 257, 4505, 311, 294, 4625, 2132, 490, 20374, 293, 9454, 42762], "temperature": 0.0, "avg_logprob": -0.230623653956822, "compression_ratio": 1.6898954703832754, "no_speech_prob": 7.527750312874559e-06}, {"id": 726, "seek": 332340, "start": 3332.64, "end": 3337.88, "text": " And was a high-performance computing expert at the shore and was about a Victorian at Princeton", "tokens": [400, 390, 257, 1090, 12, 50242, 15866, 5844, 412, 264, 17805, 293, 390, 466, 257, 37302, 412, 36592], "temperature": 0.0, "avg_logprob": -0.230623653956822, "compression_ratio": 1.6898954703832754, "no_speech_prob": 7.527750312874559e-06}, {"id": 727, "seek": 332340, "start": 3338.04, "end": 3341.48, "text": " Anyway, she you know very annoying person good at everything she does", "tokens": [5684, 11, 750, 291, 458, 588, 11304, 954, 665, 412, 1203, 750, 775], "temperature": 0.0, "avg_logprob": -0.230623653956822, "compression_ratio": 1.6898954703832754, "no_speech_prob": 7.527750312874559e-06}, {"id": 728, "seek": 332340, "start": 3342.56, "end": 3348.64, "text": " But you know, I think it's really cool to see how a kind of a domain expert in this case the domain of playing piano", "tokens": [583, 291, 458, 11, 286, 519, 309, 311, 534, 1627, 281, 536, 577, 257, 733, 295, 257, 9274, 5844, 294, 341, 1389, 264, 9274, 295, 2433, 9211], "temperature": 0.0, "avg_logprob": -0.230623653956822, "compression_ratio": 1.6898954703832754, "no_speech_prob": 7.527750312874559e-06}, {"id": 729, "seek": 332340, "start": 3349.44, "end": 3352.1600000000003, "text": " can go through the fast AI course and", "tokens": [393, 352, 807, 264, 2370, 7318, 1164, 293], "temperature": 0.0, "avg_logprob": -0.230623653956822, "compression_ratio": 1.6898954703832754, "no_speech_prob": 7.527750312874559e-06}, {"id": 730, "seek": 335216, "start": 3352.16, "end": 3355.44, "text": " Come out the other end and I guess open AI would be", "tokens": [2492, 484, 264, 661, 917, 293, 286, 2041, 1269, 7318, 576, 312], "temperature": 0.0, "avg_logprob": -0.22203735911518063, "compression_ratio": 1.75, "no_speech_prob": 4.289276148483623e-06}, {"id": 731, "seek": 335216, "start": 3355.8799999999997, "end": 3361.64, "text": " You know of the three top research institutes Google Blaine or open AI would be two of them probably along with deep learning", "tokens": [509, 458, 295, 264, 1045, 1192, 2132, 4348, 1819, 3329, 2177, 7119, 420, 1269, 7318, 576, 312, 732, 295, 552, 1391, 2051, 365, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.22203735911518063, "compression_ratio": 1.75, "no_speech_prob": 4.289276148483623e-06}, {"id": 732, "seek": 335216, "start": 3363.7999999999997, "end": 3369.3999999999996, "text": " And interestingly actually one of our other students or should say alumni of the course recently interviewed", "tokens": [400, 25873, 767, 472, 295, 527, 661, 1731, 420, 820, 584, 16347, 295, 264, 1164, 3938, 19770], "temperature": 0.0, "avg_logprob": -0.22203735911518063, "compression_ratio": 1.75, "no_speech_prob": 4.289276148483623e-06}, {"id": 733, "seek": 335216, "start": 3369.7599999999998, "end": 3373.96, "text": " Her for a blog post series. He's doing on top AI researchers", "tokens": [3204, 337, 257, 6968, 2183, 2638, 13, 634, 311, 884, 322, 1192, 7318, 10309], "temperature": 0.0, "avg_logprob": -0.22203735911518063, "compression_ratio": 1.75, "no_speech_prob": 4.289276148483623e-06}, {"id": 734, "seek": 335216, "start": 3373.96, "end": 3377.8599999999997, "text": " And she said one of the most important pieces of advice she got was for me", "tokens": [400, 750, 848, 472, 295, 264, 881, 1021, 3755, 295, 5192, 750, 658, 390, 337, 385], "temperature": 0.0, "avg_logprob": -0.22203735911518063, "compression_ratio": 1.75, "no_speech_prob": 4.289276148483623e-06}, {"id": 735, "seek": 335216, "start": 3377.8599999999997, "end": 3381.3199999999997, "text": " And she said the piece of advice was pick one project", "tokens": [400, 750, 848, 264, 2522, 295, 5192, 390, 1888, 472, 1716], "temperature": 0.0, "avg_logprob": -0.22203735911518063, "compression_ratio": 1.75, "no_speech_prob": 4.289276148483623e-06}, {"id": 736, "seek": 338132, "start": 3381.32, "end": 3384.1200000000003, "text": " Do it really well make it fantastic", "tokens": [1144, 309, 534, 731, 652, 309, 5456], "temperature": 0.0, "avg_logprob": -0.1769327057732476, "compression_ratio": 1.669603524229075, "no_speech_prob": 4.4951229938305914e-06}, {"id": 737, "seek": 338132, "start": 3385.28, "end": 3391.88, "text": " Okay, so that was the piece of advice she found the most useful and we're going to be talking a lot about you", "tokens": [1033, 11, 370, 300, 390, 264, 2522, 295, 5192, 750, 1352, 264, 881, 4420, 293, 321, 434, 516, 281, 312, 1417, 257, 688, 466, 291], "temperature": 0.0, "avg_logprob": -0.1769327057732476, "compression_ratio": 1.669603524229075, "no_speech_prob": 4.4951229938305914e-06}, {"id": 738, "seek": 338132, "start": 3392.1200000000003, "end": 3395.6000000000004, "text": " Doing projects and making them fantastic during this course", "tokens": [18496, 4455, 293, 1455, 552, 5456, 1830, 341, 1164], "temperature": 0.0, "avg_logprob": -0.1769327057732476, "compression_ratio": 1.669603524229075, "no_speech_prob": 4.4951229938305914e-06}, {"id": 739, "seek": 338132, "start": 3396.52, "end": 3400.54, "text": " Having said that I don't really want you to go to AI or Google brain", "tokens": [10222, 848, 300, 286, 500, 380, 534, 528, 291, 281, 352, 281, 7318, 420, 3329, 3567], "temperature": 0.0, "avg_logprob": -0.1769327057732476, "compression_ratio": 1.669603524229075, "no_speech_prob": 4.4951229938305914e-06}, {"id": 740, "seek": 338132, "start": 3400.54, "end": 3408.1400000000003, "text": " What I really want you to do is go back to your workplace or your passion project and apply these skills", "tokens": [708, 286, 534, 528, 291, 281, 360, 307, 352, 646, 281, 428, 15328, 420, 428, 5418, 1716, 293, 3079, 613, 3942], "temperature": 0.0, "avg_logprob": -0.1769327057732476, "compression_ratio": 1.669603524229075, "no_speech_prob": 4.4951229938305914e-06}, {"id": 741, "seek": 340814, "start": 3408.14, "end": 3411.04, "text": " There right let me give you an example", "tokens": [821, 558, 718, 385, 976, 291, 364, 1365], "temperature": 0.0, "avg_logprob": -0.300643675667899, "compression_ratio": 1.5133689839572193, "no_speech_prob": 9.516135833109729e-06}, {"id": 742, "seek": 340814, "start": 3412.2999999999997, "end": 3419.98, "text": " MIT released a deep learning course and they highlighted in their announcement for this deep learning course this medical imaging example", "tokens": [13100, 4736, 257, 2452, 2539, 1164, 293, 436, 17173, 294, 641, 12847, 337, 341, 2452, 2539, 1164, 341, 4625, 25036, 1365], "temperature": 0.0, "avg_logprob": -0.300643675667899, "compression_ratio": 1.5133689839572193, "no_speech_prob": 9.516135833109729e-06}, {"id": 743, "seek": 340814, "start": 3420.7, "end": 3422.7, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.300643675667899, "compression_ratio": 1.5133689839572193, "no_speech_prob": 9.516135833109729e-06}, {"id": 744, "seek": 340814, "start": 3423.1, "end": 3425.1, "text": " One of our students", "tokens": [1485, 295, 527, 1731], "temperature": 0.0, "avg_logprob": -0.300643675667899, "compression_ratio": 1.5133689839572193, "no_speech_prob": 9.516135833109729e-06}, {"id": 745, "seek": 340814, "start": 3425.1, "end": 3427.22, "text": " Alex who is a radiologist?", "tokens": [5202, 567, 307, 257, 16335, 9201, 30], "temperature": 0.0, "avg_logprob": -0.300643675667899, "compression_ratio": 1.5133689839572193, "no_speech_prob": 9.516135833109729e-06}, {"id": 746, "seek": 340814, "start": 3428.02, "end": 3429.18, "text": " said", "tokens": [848], "temperature": 0.0, "avg_logprob": -0.300643675667899, "compression_ratio": 1.5133689839572193, "no_speech_prob": 9.516135833109729e-06}, {"id": 747, "seek": 340814, "start": 3429.18, "end": 3433.2799999999997, "text": " You guys just showed model overfitting. I can tell", "tokens": [509, 1074, 445, 4712, 2316, 670, 69, 2414, 13, 286, 393, 980], "temperature": 0.0, "avg_logprob": -0.300643675667899, "compression_ratio": 1.5133689839572193, "no_speech_prob": 9.516135833109729e-06}, {"id": 748, "seek": 343328, "start": 3433.28, "end": 3438.6800000000003, "text": " Because I'm a radiologist and this is not what this would look like", "tokens": [1436, 286, 478, 257, 16335, 9201, 293, 341, 307, 406, 437, 341, 576, 574, 411], "temperature": 0.0, "avg_logprob": -0.1995214045732871, "compression_ratio": 1.7198067632850242, "no_speech_prob": 3.927854095309158e-07}, {"id": 749, "seek": 343328, "start": 3439.44, "end": 3441.44, "text": " on a chest film", "tokens": [322, 257, 7443, 2007], "temperature": 0.0, "avg_logprob": -0.1995214045732871, "compression_ratio": 1.7198067632850242, "no_speech_prob": 3.927854095309158e-07}, {"id": 750, "seek": 343328, "start": 3441.48, "end": 3446.2000000000003, "text": " This is what it should look like and this as a deep learning practitioner. This is how I know", "tokens": [639, 307, 437, 309, 820, 574, 411, 293, 341, 382, 257, 2452, 2539, 32125, 13, 639, 307, 577, 286, 458], "temperature": 0.0, "avg_logprob": -0.1995214045732871, "compression_ratio": 1.7198067632850242, "no_speech_prob": 3.927854095309158e-07}, {"id": 751, "seek": 343328, "start": 3446.7200000000003, "end": 3453.4, "text": " This is what happened in your model. So Alex is combining his knowledge of radiology and his knowledge of deep learning", "tokens": [639, 307, 437, 2011, 294, 428, 2316, 13, 407, 5202, 307, 21928, 702, 3601, 295, 16335, 1793, 293, 702, 3601, 295, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.1995214045732871, "compression_ratio": 1.7198067632850242, "no_speech_prob": 3.927854095309158e-07}, {"id": 752, "seek": 343328, "start": 3454.1600000000003, "end": 3455.92, "text": " to assess", "tokens": [281, 5877], "temperature": 0.0, "avg_logprob": -0.1995214045732871, "compression_ratio": 1.7198067632850242, "no_speech_prob": 3.927854095309158e-07}, {"id": 753, "seek": 343328, "start": 3455.92, "end": 3459.76, "text": " MIT's model from just two images very accurately", "tokens": [13100, 311, 2316, 490, 445, 732, 5267, 588, 20095], "temperature": 0.0, "avg_logprob": -0.1995214045732871, "compression_ratio": 1.7198067632850242, "no_speech_prob": 3.927854095309158e-07}, {"id": 754, "seek": 345976, "start": 3459.76, "end": 3464.6800000000003, "text": " All right, and so this is actually what I want most of you to be doing is to take your domain expertise", "tokens": [1057, 558, 11, 293, 370, 341, 307, 767, 437, 286, 528, 881, 295, 291, 281, 312, 884, 307, 281, 747, 428, 9274, 11769], "temperature": 0.0, "avg_logprob": -0.1757133960723877, "compression_ratio": 1.7009966777408638, "no_speech_prob": 5.338107257557567e-06}, {"id": 755, "seek": 345976, "start": 3465.32, "end": 3467.5600000000004, "text": " And combine it with the deep learning", "tokens": [400, 10432, 309, 365, 264, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.1757133960723877, "compression_ratio": 1.7009966777408638, "no_speech_prob": 5.338107257557567e-06}, {"id": 756, "seek": 345976, "start": 3468.1200000000003, "end": 3472.88, "text": " Practical aspects that you'll learn in this course and bring them together like Alex is doing here", "tokens": [19170, 804, 7270, 300, 291, 603, 1466, 294, 341, 1164, 293, 1565, 552, 1214, 411, 5202, 307, 884, 510], "temperature": 0.0, "avg_logprob": -0.1757133960723877, "compression_ratio": 1.7009966777408638, "no_speech_prob": 5.338107257557567e-06}, {"id": 757, "seek": 345976, "start": 3472.88, "end": 3476.6400000000003, "text": " and so a lot of radiologists have actually gone through this course now and", "tokens": [293, 370, 257, 688, 295, 16335, 12256, 362, 767, 2780, 807, 341, 1164, 586, 293], "temperature": 0.0, "avg_logprob": -0.1757133960723877, "compression_ratio": 1.7009966777408638, "no_speech_prob": 5.338107257557567e-06}, {"id": 758, "seek": 345976, "start": 3477.5200000000004, "end": 3479.84, "text": " have built journal clubs and", "tokens": [362, 3094, 6708, 15428, 293], "temperature": 0.0, "avg_logprob": -0.1757133960723877, "compression_ratio": 1.7009966777408638, "no_speech_prob": 5.338107257557567e-06}, {"id": 759, "seek": 345976, "start": 3480.48, "end": 3482.6800000000003, "text": " American Council of Radiology practice groups", "tokens": [2665, 7076, 295, 37806, 1793, 3124, 3935], "temperature": 0.0, "avg_logprob": -0.1757133960723877, "compression_ratio": 1.7009966777408638, "no_speech_prob": 5.338107257557567e-06}, {"id": 760, "seek": 345976, "start": 3483.32, "end": 3488.92, "text": " There's a data science institute at the ACR now and so forth and Alex is one of the people who's providing kind of a lot", "tokens": [821, 311, 257, 1412, 3497, 26860, 412, 264, 8157, 49, 586, 293, 370, 5220, 293, 5202, 307, 472, 295, 264, 561, 567, 311, 6530, 733, 295, 257, 688], "temperature": 0.0, "avg_logprob": -0.1757133960723877, "compression_ratio": 1.7009966777408638, "no_speech_prob": 5.338107257557567e-06}, {"id": 761, "seek": 348892, "start": 3488.92, "end": 3490.2400000000002, "text": " Of leadership in this area", "tokens": [2720, 5848, 294, 341, 1859], "temperature": 0.0, "avg_logprob": -0.25036023737310054, "compression_ratio": 1.66, "no_speech_prob": 1.1125410310341977e-05}, {"id": 762, "seek": 348892, "start": 3490.2400000000002, "end": 3496.88, "text": " I would love you to do the same kind of thing that Alex is doing which is to really bring deep learning later leadership into your", "tokens": [286, 576, 959, 291, 281, 360, 264, 912, 733, 295, 551, 300, 5202, 307, 884, 597, 307, 281, 534, 1565, 2452, 2539, 1780, 5848, 666, 428], "temperature": 0.0, "avg_logprob": -0.25036023737310054, "compression_ratio": 1.66, "no_speech_prob": 1.1125410310341977e-05}, {"id": 763, "seek": 348892, "start": 3497.44, "end": 3502.0, "text": " Industry and just your social impact project whatever it is that you're trying to do", "tokens": [38178, 293, 445, 428, 2093, 2712, 1716, 2035, 309, 307, 300, 291, 434, 1382, 281, 360], "temperature": 0.0, "avg_logprob": -0.25036023737310054, "compression_ratio": 1.66, "no_speech_prob": 1.1125410310341977e-05}, {"id": 764, "seek": 348892, "start": 3502.76, "end": 3507.94, "text": " So another great example was this was Melissa Fabros who was a English literature PhD", "tokens": [407, 1071, 869, 1365, 390, 341, 390, 22844, 17440, 2635, 567, 390, 257, 3669, 10394, 14476], "temperature": 0.0, "avg_logprob": -0.25036023737310054, "compression_ratio": 1.66, "no_speech_prob": 1.1125410310341977e-05}, {"id": 765, "seek": 348892, "start": 3508.28, "end": 3512.7200000000003, "text": " He just studied like gendered language in English literature or something", "tokens": [634, 445, 9454, 411, 7898, 292, 2856, 294, 3669, 10394, 420, 746], "temperature": 0.0, "avg_logprob": -0.25036023737310054, "compression_ratio": 1.66, "no_speech_prob": 1.1125410310341977e-05}, {"id": 766, "seek": 348892, "start": 3513.44, "end": 3515.44, "text": " and actually", "tokens": [293, 767], "temperature": 0.0, "avg_logprob": -0.25036023737310054, "compression_ratio": 1.66, "no_speech_prob": 1.1125410310341977e-05}, {"id": 767, "seek": 351544, "start": 3515.44, "end": 3522.44, "text": " Rachel in a previous job taught her to code I think and then she came into the fast AI course and she helped", "tokens": [14246, 294, 257, 3894, 1691, 5928, 720, 281, 3089, 286, 519, 293, 550, 750, 1361, 666, 264, 2370, 7318, 1164, 293, 750, 4254], "temperature": 0.0, "avg_logprob": -0.21813739819473096, "compression_ratio": 1.5490196078431373, "no_speech_prob": 3.5008167742489604e-06}, {"id": 768, "seek": 351544, "start": 3522.68, "end": 3528.52, "text": " Kiva a micro lending social impact organization to build a system that can recognize", "tokens": [591, 5931, 257, 4532, 29823, 2093, 2712, 4475, 281, 1322, 257, 1185, 300, 393, 5521], "temperature": 0.0, "avg_logprob": -0.21813739819473096, "compression_ratio": 1.5490196078431373, "no_speech_prob": 3.5008167742489604e-06}, {"id": 769, "seek": 351544, "start": 3529.48, "end": 3534.36, "text": " Faces why is that necessary? Well, we're going to be talking a lot about this but because", "tokens": [479, 2116, 983, 307, 300, 4818, 30, 1042, 11, 321, 434, 516, 281, 312, 1417, 257, 688, 466, 341, 457, 570], "temperature": 0.0, "avg_logprob": -0.21813739819473096, "compression_ratio": 1.5490196078431373, "no_speech_prob": 3.5008167742489604e-06}, {"id": 770, "seek": 351544, "start": 3535.2000000000003, "end": 3538.08, "text": " most AI researchers are white men", "tokens": [881, 7318, 10309, 366, 2418, 1706], "temperature": 0.0, "avg_logprob": -0.21813739819473096, "compression_ratio": 1.5490196078431373, "no_speech_prob": 3.5008167742489604e-06}, {"id": 771, "seek": 351544, "start": 3539.48, "end": 3541.48, "text": " most computer vision software", "tokens": [881, 3820, 5201, 4722], "temperature": 0.0, "avg_logprob": -0.21813739819473096, "compression_ratio": 1.5490196078431373, "no_speech_prob": 3.5008167742489604e-06}, {"id": 772, "seek": 354148, "start": 3541.48, "end": 3546.28, "text": " Can only recognize white male faces effectively in fact", "tokens": [1664, 787, 5521, 2418, 7133, 8475, 8659, 294, 1186], "temperature": 0.0, "avg_logprob": -0.28322672162737167, "compression_ratio": 1.5737704918032787, "no_speech_prob": 5.682334176526638e-06}, {"id": 773, "seek": 354148, "start": 3546.28, "end": 3551.1, "text": " I think of this IBM system is like ninety nine point eight percent accurate on common", "tokens": [286, 519, 295, 341, 23487, 1185, 307, 411, 25063, 4949, 935, 3180, 3043, 8559, 322, 2689], "temperature": 0.0, "avg_logprob": -0.28322672162737167, "compression_ratio": 1.5737704918032787, "no_speech_prob": 5.682334176526638e-06}, {"id": 774, "seek": 354148, "start": 3551.48, "end": 3553.48, "text": " white face men", "tokens": [2418, 1851, 1706], "temperature": 0.0, "avg_logprob": -0.28322672162737167, "compression_ratio": 1.5737704918032787, "no_speech_prob": 5.682334176526638e-06}, {"id": 775, "seek": 354148, "start": 3554.8, "end": 3556.08, "text": " versus", "tokens": [5717], "temperature": 0.0, "avg_logprob": -0.28322672162737167, "compression_ratio": 1.5737704918032787, "no_speech_prob": 5.682334176526638e-06}, {"id": 776, "seek": 354148, "start": 3556.08, "end": 3562.12, "text": " 60 percent accurate 65 percent accurate on dark fate dark skinned women", "tokens": [4060, 3043, 8559, 11624, 3043, 8559, 322, 2877, 12738, 2877, 3178, 9232, 2266], "temperature": 0.0, "avg_logprob": -0.28322672162737167, "compression_ratio": 1.5737704918032787, "no_speech_prob": 5.682334176526638e-06}, {"id": 777, "seek": 354148, "start": 3562.28, "end": 3566.2400000000002, "text": " So it's like what is that like 30 or 40 times worse?", "tokens": [407, 309, 311, 411, 437, 307, 300, 411, 2217, 420, 3356, 1413, 5324, 30], "temperature": 0.0, "avg_logprob": -0.28322672162737167, "compression_ratio": 1.5737704918032787, "no_speech_prob": 5.682334176526638e-06}, {"id": 778, "seek": 356624, "start": 3566.24, "end": 3571.3199999999997, "text": " For black women versus white men and this is really important because for Kiva", "tokens": [1171, 2211, 2266, 5717, 2418, 1706, 293, 341, 307, 534, 1021, 570, 337, 591, 5931], "temperature": 0.0, "avg_logprob": -0.1998240483271611, "compression_ratio": 1.563063063063063, "no_speech_prob": 9.080245945369825e-06}, {"id": 779, "seek": 356624, "start": 3572.68, "end": 3578.4799999999996, "text": " Black women are you know, perhaps the most common user base for their micro lending platform", "tokens": [4076, 2266, 366, 291, 458, 11, 4317, 264, 881, 2689, 4195, 3096, 337, 641, 4532, 29823, 3663], "temperature": 0.0, "avg_logprob": -0.1998240483271611, "compression_ratio": 1.563063063063063, "no_speech_prob": 9.080245945369825e-06}, {"id": 780, "seek": 356624, "start": 3578.9599999999996, "end": 3586.3599999999997, "text": " So Melissa after taking our course and again working her ass off and being super intense in her study and her work", "tokens": [407, 22844, 934, 1940, 527, 1164, 293, 797, 1364, 720, 1256, 766, 293, 885, 1687, 9447, 294, 720, 2979, 293, 720, 589], "temperature": 0.0, "avg_logprob": -0.1998240483271611, "compression_ratio": 1.563063063063063, "no_speech_prob": 9.080245945369825e-06}, {"id": 781, "seek": 356624, "start": 3586.64, "end": 3591.2, "text": " Won this 1 million dollar AI challenge for her work for Kiva", "tokens": [14710, 341, 502, 2459, 7241, 7318, 3430, 337, 720, 589, 337, 591, 5931], "temperature": 0.0, "avg_logprob": -0.1998240483271611, "compression_ratio": 1.563063063063063, "no_speech_prob": 9.080245945369825e-06}, {"id": 782, "seek": 359120, "start": 3591.2, "end": 3593.2, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.15255854310107833, "compression_ratio": 1.7152777777777777, "no_speech_prob": 1.3845699868397787e-05}, {"id": 783, "seek": 359120, "start": 3594.2799999999997, "end": 3598.98, "text": " Think did our course and realized that the thing he wanted to do wasn't at his company", "tokens": [6557, 630, 527, 1164, 293, 5334, 300, 264, 551, 415, 1415, 281, 360, 2067, 380, 412, 702, 2237], "temperature": 0.0, "avg_logprob": -0.15255854310107833, "compression_ratio": 1.7152777777777777, "no_speech_prob": 1.3845699868397787e-05}, {"id": 784, "seek": 359120, "start": 3598.98, "end": 3602.3999999999996, "text": " It was something else which is to help blind people to understand the world around them", "tokens": [467, 390, 746, 1646, 597, 307, 281, 854, 6865, 561, 281, 1223, 264, 1002, 926, 552], "temperature": 0.0, "avg_logprob": -0.15255854310107833, "compression_ratio": 1.7152777777777777, "no_speech_prob": 1.3845699868397787e-05}, {"id": 785, "seek": 359120, "start": 3602.3999999999996, "end": 3605.9199999999996, "text": " So he started a new startup you can find it now. It's called in vision", "tokens": [407, 415, 1409, 257, 777, 18578, 291, 393, 915, 309, 586, 13, 467, 311, 1219, 294, 5201], "temperature": 0.0, "avg_logprob": -0.15255854310107833, "compression_ratio": 1.7152777777777777, "no_speech_prob": 1.3845699868397787e-05}, {"id": 786, "seek": 359120, "start": 3605.9199999999996, "end": 3610.8199999999997, "text": " You can download the app you can point your phone at things and it will tell you what it sees", "tokens": [509, 393, 5484, 264, 724, 291, 393, 935, 428, 2593, 412, 721, 293, 309, 486, 980, 291, 437, 309, 8194], "temperature": 0.0, "avg_logprob": -0.15255854310107833, "compression_ratio": 1.7152777777777777, "no_speech_prob": 1.3845699868397787e-05}, {"id": 787, "seek": 359120, "start": 3611.4399999999996, "end": 3616.8199999999997, "text": " And I actually talked to a blind lady about these kinds of apps the other day and she confirmed to me", "tokens": [400, 286, 767, 2825, 281, 257, 6865, 7262, 466, 613, 3685, 295, 7733, 264, 661, 786, 293, 750, 11341, 281, 385], "temperature": 0.0, "avg_logprob": -0.15255854310107833, "compression_ratio": 1.7152777777777777, "no_speech_prob": 1.3845699868397787e-05}, {"id": 788, "seek": 359120, "start": 3616.8199999999997, "end": 3618.8199999999997, "text": " This is a super useful thing", "tokens": [639, 307, 257, 1687, 4420, 551], "temperature": 0.0, "avg_logprob": -0.15255854310107833, "compression_ratio": 1.7152777777777777, "no_speech_prob": 1.3845699868397787e-05}, {"id": 789, "seek": 361882, "start": 3618.82, "end": 3621.6600000000003, "text": " for visually disabled users", "tokens": [337, 19622, 15191, 5022], "temperature": 0.0, "avg_logprob": -0.23326289026360764, "compression_ratio": 1.5771144278606966, "no_speech_prob": 8.530138075002469e-06}, {"id": 790, "seek": 361882, "start": 3623.86, "end": 3628.5800000000004, "text": " And it's not it's the level that you can get to", "tokens": [400, 309, 311, 406, 309, 311, 264, 1496, 300, 291, 393, 483, 281], "temperature": 0.0, "avg_logprob": -0.23326289026360764, "compression_ratio": 1.5771144278606966, "no_speech_prob": 8.530138075002469e-06}, {"id": 791, "seek": 361882, "start": 3629.02, "end": 3633.54, "text": " With with the content that you're going to get over these seven weeks and with this software", "tokens": [2022, 365, 264, 2701, 300, 291, 434, 516, 281, 483, 670, 613, 3407, 3259, 293, 365, 341, 4722], "temperature": 0.0, "avg_logprob": -0.23326289026360764, "compression_ratio": 1.5771144278606966, "no_speech_prob": 8.530138075002469e-06}, {"id": 792, "seek": 361882, "start": 3634.42, "end": 3638.3, "text": " Can get you right to the cutting edge in areas you might find surprising", "tokens": [1664, 483, 291, 558, 281, 264, 6492, 4691, 294, 3179, 291, 1062, 915, 8830], "temperature": 0.0, "avg_logprob": -0.23326289026360764, "compression_ratio": 1.5771144278606966, "no_speech_prob": 8.530138075002469e-06}, {"id": 793, "seek": 361882, "start": 3638.94, "end": 3645.06, "text": " For example, I helped a team of some of our students and some collaborators", "tokens": [1171, 1365, 11, 286, 4254, 257, 1469, 295, 512, 295, 527, 1731, 293, 512, 39789], "temperature": 0.0, "avg_logprob": -0.23326289026360764, "compression_ratio": 1.5771144278606966, "no_speech_prob": 8.530138075002469e-06}, {"id": 794, "seek": 364506, "start": 3645.06, "end": 3650.34, "text": " on actually breaking the world record for training remember", "tokens": [322, 767, 7697, 264, 1002, 2136, 337, 3097, 1604], "temperature": 0.0, "avg_logprob": -0.18141660150491967, "compression_ratio": 1.6768060836501901, "no_speech_prob": 1.1659245501505211e-05}, {"id": 795, "seek": 364506, "start": 3650.34, "end": 3654.06, "text": " I mentioned the image net data set lots of people want to train on the image net data set", "tokens": [286, 2835, 264, 3256, 2533, 1412, 992, 3195, 295, 561, 528, 281, 3847, 322, 264, 3256, 2533, 1412, 992], "temperature": 0.0, "avg_logprob": -0.18141660150491967, "compression_ratio": 1.6768060836501901, "no_speech_prob": 1.1659245501505211e-05}, {"id": 796, "seek": 364506, "start": 3654.06, "end": 3659.12, "text": " We smashed the world record for how quickly you can train it. We use standard AWS", "tokens": [492, 33269, 264, 1002, 2136, 337, 577, 2661, 291, 393, 3847, 309, 13, 492, 764, 3832, 17650], "temperature": 0.0, "avg_logprob": -0.18141660150491967, "compression_ratio": 1.6768060836501901, "no_speech_prob": 1.1659245501505211e-05}, {"id": 797, "seek": 364506, "start": 3659.74, "end": 3661.74, "text": " cloud infrastructure", "tokens": [4588, 6896], "temperature": 0.0, "avg_logprob": -0.18141660150491967, "compression_ratio": 1.6768060836501901, "no_speech_prob": 1.1659245501505211e-05}, {"id": 798, "seek": 364506, "start": 3661.82, "end": 3664.64, "text": " Cost of $40 of compute to train this model", "tokens": [20863, 295, 1848, 5254, 295, 14722, 281, 3847, 341, 2316], "temperature": 0.0, "avg_logprob": -0.18141660150491967, "compression_ratio": 1.6768060836501901, "no_speech_prob": 1.1659245501505211e-05}, {"id": 799, "seek": 364506, "start": 3665.54, "end": 3668.7, "text": " Using again fast AI library the techniques that we learn in this course", "tokens": [11142, 797, 2370, 7318, 6405, 264, 7512, 300, 321, 1466, 294, 341, 1164], "temperature": 0.0, "avg_logprob": -0.18141660150491967, "compression_ratio": 1.6768060836501901, "no_speech_prob": 1.1659245501505211e-05}, {"id": 800, "seek": 364506, "start": 3669.34, "end": 3673.7599999999998, "text": " So it can really take you a long way. So don't be kind of put off by this", "tokens": [407, 309, 393, 534, 747, 291, 257, 938, 636, 13, 407, 500, 380, 312, 733, 295, 829, 766, 538, 341], "temperature": 0.0, "avg_logprob": -0.18141660150491967, "compression_ratio": 1.6768060836501901, "no_speech_prob": 1.1659245501505211e-05}, {"id": 801, "seek": 367376, "start": 3673.76, "end": 3677.4, "text": " What might seem pretty simple at first we're going to get deeper and deeper", "tokens": [708, 1062, 1643, 1238, 2199, 412, 700, 321, 434, 516, 281, 483, 7731, 293, 7731], "temperature": 0.0, "avg_logprob": -0.2439628152286305, "compression_ratio": 1.549800796812749, "no_speech_prob": 7.766798262309749e-06}, {"id": 802, "seek": 367376, "start": 3677.6800000000003, "end": 3681.32, "text": " You can also use it for other kinds of passion project", "tokens": [509, 393, 611, 764, 309, 337, 661, 3685, 295, 5418, 1716], "temperature": 0.0, "avg_logprob": -0.2439628152286305, "compression_ratio": 1.549800796812749, "no_speech_prob": 7.766798262309749e-06}, {"id": 803, "seek": 367376, "start": 3681.32, "end": 3686.6000000000004, "text": " So Helena sarin actually you should definitely check out her Twitter account like a list", "tokens": [407, 49294, 13782, 259, 767, 291, 820, 2138, 1520, 484, 720, 5794, 2696, 411, 257, 1329], "temperature": 0.0, "avg_logprob": -0.2439628152286305, "compression_ratio": 1.549800796812749, "no_speech_prob": 7.766798262309749e-06}, {"id": 804, "seek": 367376, "start": 3687.2400000000002, "end": 3692.2400000000002, "text": " This art is a basically a new style of art that she's developed", "tokens": [639, 1523, 307, 257, 1936, 257, 777, 3758, 295, 1523, 300, 750, 311, 4743], "temperature": 0.0, "avg_logprob": -0.2439628152286305, "compression_ratio": 1.549800796812749, "no_speech_prob": 7.766798262309749e-06}, {"id": 805, "seek": 367376, "start": 3692.84, "end": 3700.0800000000004, "text": " Which combines her painting and drawing with generative adversarial models to create these extraordinary?", "tokens": [3013, 29520, 720, 5370, 293, 6316, 365, 1337, 1166, 17641, 44745, 5245, 281, 1884, 613, 10581, 30], "temperature": 0.0, "avg_logprob": -0.2439628152286305, "compression_ratio": 1.549800796812749, "no_speech_prob": 7.766798262309749e-06}, {"id": 806, "seek": 370008, "start": 3700.08, "end": 3707.84, "text": " Results and so I think this is super cool. I mean, she's not a professional artist. She is a professional software developer", "tokens": [5015, 33361, 293, 370, 286, 519, 341, 307, 1687, 1627, 13, 286, 914, 11, 750, 311, 406, 257, 4843, 5748, 13, 1240, 307, 257, 4843, 4722, 10754], "temperature": 0.0, "avg_logprob": -0.19937688296603173, "compression_ratio": 1.6653386454183268, "no_speech_prob": 3.1691106414655223e-05}, {"id": 807, "seek": 370008, "start": 3708.44, "end": 3711.56, "text": " but she just keeps on producing these beautiful results and", "tokens": [457, 750, 445, 5965, 322, 10501, 613, 2238, 3542, 293], "temperature": 0.0, "avg_logprob": -0.19937688296603173, "compression_ratio": 1.6653386454183268, "no_speech_prob": 3.1691106414655223e-05}, {"id": 808, "seek": 370008, "start": 3712.44, "end": 3714.3199999999997, "text": " when she started", "tokens": [562, 750, 1409], "temperature": 0.0, "avg_logprob": -0.19937688296603173, "compression_ratio": 1.6653386454183268, "no_speech_prob": 3.1691106414655223e-05}, {"id": 809, "seek": 370008, "start": 3714.3199999999997, "end": 3716.3199999999997, "text": " you know her", "tokens": [291, 458, 720], "temperature": 0.0, "avg_logprob": -0.19937688296603173, "compression_ratio": 1.6653386454183268, "no_speech_prob": 3.1691106414655223e-05}, {"id": 810, "seek": 370008, "start": 3716.68, "end": 3721.44, "text": " Her art had not really been shown anywhere or discussed anywhere now", "tokens": [3204, 1523, 632, 406, 534, 668, 4898, 4992, 420, 7152, 4992, 586], "temperature": 0.0, "avg_logprob": -0.19937688296603173, "compression_ratio": 1.6653386454183268, "no_speech_prob": 3.1691106414655223e-05}, {"id": 811, "seek": 370008, "start": 3721.44, "end": 3727.48, "text": " There's recently been some quite high profile articles describing how she is creating a new form of art again", "tokens": [821, 311, 3938, 668, 512, 1596, 1090, 7964, 11290, 16141, 577, 750, 307, 4084, 257, 777, 1254, 295, 1523, 797], "temperature": 0.0, "avg_logprob": -0.19937688296603173, "compression_ratio": 1.6653386454183268, "no_speech_prob": 3.1691106414655223e-05}, {"id": 812, "seek": 370008, "start": 3727.48, "end": 3729.48, "text": " this has come out of the", "tokens": [341, 575, 808, 484, 295, 264], "temperature": 0.0, "avg_logprob": -0.19937688296603173, "compression_ratio": 1.6653386454183268, "no_speech_prob": 3.1691106414655223e-05}, {"id": 813, "seek": 372948, "start": 3729.48, "end": 3731.48, "text": " fast AI", "tokens": [2370, 7318], "temperature": 0.0, "avg_logprob": -0.21550168047894488, "compression_ratio": 1.6260162601626016, "no_speech_prob": 4.757133137900382e-05}, {"id": 814, "seek": 372948, "start": 3731.52, "end": 3733.52, "text": " course that she developed these skills or", "tokens": [1164, 300, 750, 4743, 613, 3942, 420], "temperature": 0.0, "avg_logprob": -0.21550168047894488, "compression_ratio": 1.6260162601626016, "no_speech_prob": 4.757133137900382e-05}, {"id": 815, "seek": 372948, "start": 3734.12, "end": 3740.8, "text": " Equally important Brad Kensler who figured out how to make a picture of Kanye out of pictures of Patrick Stewart's head", "tokens": [15624, 379, 1021, 11895, 591, 694, 1918, 567, 8932, 484, 577, 281, 652, 257, 3036, 295, 37654, 484, 295, 5242, 295, 13980, 25951, 311, 1378], "temperature": 0.0, "avg_logprob": -0.21550168047894488, "compression_ratio": 1.6260162601626016, "no_speech_prob": 4.757133137900382e-05}, {"id": 816, "seek": 372948, "start": 3741.36, "end": 3743.84, "text": " Also something you will learn to do if you wish to", "tokens": [2743, 746, 291, 486, 1466, 281, 360, 498, 291, 3172, 281], "temperature": 0.0, "avg_logprob": -0.21550168047894488, "compression_ratio": 1.6260162601626016, "no_speech_prob": 4.757133137900382e-05}, {"id": 817, "seek": 372948, "start": 3745.12, "end": 3748.96, "text": " This particular style this particular type of what's called style transfer", "tokens": [639, 1729, 3758, 341, 1729, 2010, 295, 437, 311, 1219, 3758, 5003], "temperature": 0.0, "avg_logprob": -0.21550168047894488, "compression_ratio": 1.6260162601626016, "no_speech_prob": 4.757133137900382e-05}, {"id": 818, "seek": 372948, "start": 3748.96, "end": 3754.08, "text": " was a really interesting tweak that allowed him to do some things that hadn't quite been done before and", "tokens": [390, 257, 534, 1880, 29879, 300, 4350, 796, 281, 360, 512, 721, 300, 8782, 380, 1596, 668, 1096, 949, 293], "temperature": 0.0, "avg_logprob": -0.21550168047894488, "compression_ratio": 1.6260162601626016, "no_speech_prob": 4.757133137900382e-05}, {"id": 819, "seek": 375408, "start": 3754.08, "end": 3760.44, "text": " And this particular picture helped him to get a job as a deep learning specialist at AWS. So", "tokens": [400, 341, 1729, 3036, 4254, 796, 281, 483, 257, 1691, 382, 257, 2452, 2539, 17008, 412, 17650, 13, 407], "temperature": 0.0, "avg_logprob": -0.21061853262094352, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.972701263905037e-06}, {"id": 820, "seek": 375408, "start": 3763.04, "end": 3768.56, "text": " Another interesting example another alumni actually worked at Splunk as a software engineer", "tokens": [3996, 1880, 1365, 1071, 16347, 767, 2732, 412, 19788, 3197, 382, 257, 4722, 11403], "temperature": 0.0, "avg_logprob": -0.21061853262094352, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.972701263905037e-06}, {"id": 821, "seek": 375408, "start": 3769.44, "end": 3770.96, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.21061853262094352, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.972701263905037e-06}, {"id": 822, "seek": 375408, "start": 3770.96, "end": 3773.96, "text": " He'd signed an algorithm after like lesson three", "tokens": [634, 1116, 8175, 364, 9284, 934, 411, 6898, 1045], "temperature": 0.0, "avg_logprob": -0.21061853262094352, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.972701263905037e-06}, {"id": 823, "seek": 375408, "start": 3774.4, "end": 3781.12, "text": " Which basically turned out at Splunk to be fantastically good at identifying fraud and we'll talk more about it shortly", "tokens": [3013, 1936, 3574, 484, 412, 19788, 3197, 281, 312, 4115, 22808, 665, 412, 16696, 14560, 293, 321, 603, 751, 544, 466, 309, 13392], "temperature": 0.0, "avg_logprob": -0.21061853262094352, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.972701263905037e-06}, {"id": 824, "seek": 378112, "start": 3781.12, "end": 3786.2, "text": " If you've seen Silicon Valley the HBO series the hot dog not hot dog app", "tokens": [759, 291, 600, 1612, 25351, 10666, 264, 37409, 2638, 264, 2368, 3000, 406, 2368, 3000, 724], "temperature": 0.0, "avg_logprob": -0.21459711358902303, "compression_ratio": 1.6069868995633187, "no_speech_prob": 5.014594080421375e-06}, {"id": 825, "seek": 378112, "start": 3786.44, "end": 3792.72, "text": " That's actually a real app you can download and it was actually built by Tim on blade as a fast AI student project", "tokens": [663, 311, 767, 257, 957, 724, 291, 393, 5484, 293, 309, 390, 767, 3094, 538, 7172, 322, 10959, 382, 257, 2370, 7318, 3107, 1716], "temperature": 0.0, "avg_logprob": -0.21459711358902303, "compression_ratio": 1.6069868995633187, "no_speech_prob": 5.014594080421375e-06}, {"id": 826, "seek": 378112, "start": 3793.52, "end": 3796.68, "text": " So there's a lot of cool stuff that you can do", "tokens": [407, 456, 311, 257, 688, 295, 1627, 1507, 300, 291, 393, 360], "temperature": 0.0, "avg_logprob": -0.21459711358902303, "compression_ratio": 1.6069868995633187, "no_speech_prob": 5.014594080421375e-06}, {"id": 827, "seek": 378112, "start": 3797.8399999999997, "end": 3804.12, "text": " Yes, it was it any nominated. So I think we only have one any nominated deep fast AI alumni at this stage", "tokens": [1079, 11, 309, 390, 309, 604, 25159, 13, 407, 286, 519, 321, 787, 362, 472, 604, 25159, 2452, 2370, 7318, 16347, 412, 341, 3233], "temperature": 0.0, "avg_logprob": -0.21459711358902303, "compression_ratio": 1.6069868995633187, "no_speech_prob": 5.014594080421375e-06}, {"id": 828, "seek": 378112, "start": 3804.12, "end": 3806.12, "text": " So, please help change that", "tokens": [407, 11, 1767, 854, 1319, 300], "temperature": 0.0, "avg_logprob": -0.21459711358902303, "compression_ratio": 1.6069868995633187, "no_speech_prob": 5.014594080421375e-06}, {"id": 829, "seek": 380612, "start": 3806.12, "end": 3808.12, "text": " All", "tokens": [1057], "temperature": 0.0, "avg_logprob": -0.18760232364430146, "compression_ratio": 1.642570281124498, "no_speech_prob": 1.5206285752356052e-05}, {"id": 830, "seek": 380612, "start": 3809.92, "end": 3811.3599999999997, "text": " Right", "tokens": [1779], "temperature": 0.0, "avg_logprob": -0.18760232364430146, "compression_ratio": 1.642570281124498, "no_speech_prob": 1.5206285752356052e-05}, {"id": 831, "seek": 380612, "start": 3811.3599999999997, "end": 3817.0, "text": " The other thing, you know is is is the forum threads can kind of turn into these really cool things", "tokens": [440, 661, 551, 11, 291, 458, 307, 307, 307, 264, 17542, 19314, 393, 733, 295, 1261, 666, 613, 534, 1627, 721], "temperature": 0.0, "avg_logprob": -0.18760232364430146, "compression_ratio": 1.642570281124498, "no_speech_prob": 1.5206285752356052e-05}, {"id": 832, "seek": 380612, "start": 3817.0, "end": 3819.96, "text": " So Francisco is actually here in the audience. He's a really", "tokens": [407, 12279, 307, 767, 510, 294, 264, 4034, 13, 634, 311, 257, 534], "temperature": 0.0, "avg_logprob": -0.18760232364430146, "compression_ratio": 1.642570281124498, "no_speech_prob": 1.5206285752356052e-05}, {"id": 833, "seek": 380612, "start": 3820.7599999999998, "end": 3826.66, "text": " Boring McKinsey consultant like me right so Francisco and I both have this shameful past that we were McKinsey consultants", "tokens": [363, 3662, 21765, 259, 7399, 24676, 411, 385, 558, 370, 12279, 293, 286, 1293, 362, 341, 49600, 1791, 300, 321, 645, 21765, 259, 7399, 38935], "temperature": 0.0, "avg_logprob": -0.18760232364430146, "compression_ratio": 1.642570281124498, "no_speech_prob": 1.5206285752356052e-05}, {"id": 834, "seek": 380612, "start": 3826.68, "end": 3829.24, "text": " but we left and we're okay now and", "tokens": [457, 321, 1411, 293, 321, 434, 1392, 586, 293], "temperature": 0.0, "avg_logprob": -0.18760232364430146, "compression_ratio": 1.642570281124498, "no_speech_prob": 1.5206285752356052e-05}, {"id": 835, "seek": 380612, "start": 3830.2, "end": 3833.96, "text": " He started this thread saying like oh this stuff. We've just been learning about", "tokens": [634, 1409, 341, 7207, 1566, 411, 1954, 341, 1507, 13, 492, 600, 445, 668, 2539, 466], "temperature": 0.0, "avg_logprob": -0.18760232364430146, "compression_ratio": 1.642570281124498, "no_speech_prob": 1.5206285752356052e-05}, {"id": 836, "seek": 383396, "start": 3833.96, "end": 3835.7200000000003, "text": " building", "tokens": [2390], "temperature": 0.0, "avg_logprob": -0.23625169197718301, "compression_ratio": 1.8127659574468085, "no_speech_prob": 4.610779433278367e-05}, {"id": 837, "seek": 383396, "start": 3835.7200000000003, "end": 3839.14, "text": " NLP and different languages. Let's try and do lots of different languages", "tokens": [426, 45196, 293, 819, 8650, 13, 961, 311, 853, 293, 360, 3195, 295, 819, 8650], "temperature": 0.0, "avg_logprob": -0.23625169197718301, "compression_ratio": 1.8127659574468085, "no_speech_prob": 4.610779433278367e-05}, {"id": 838, "seek": 383396, "start": 3839.16, "end": 3845.64, "text": " We started this thing called the language model zoo and out of that there's now been an academic", "tokens": [492, 1409, 341, 551, 1219, 264, 2856, 2316, 25347, 293, 484, 295, 300, 456, 311, 586, 668, 364, 7778], "temperature": 0.0, "avg_logprob": -0.23625169197718301, "compression_ratio": 1.8127659574468085, "no_speech_prob": 4.610779433278367e-05}, {"id": 839, "seek": 383396, "start": 3847.12, "end": 3850.02, "text": " Competition was one in Polish that led to an academic paper", "tokens": [43634, 390, 472, 294, 18504, 300, 4684, 281, 364, 7778, 3035], "temperature": 0.0, "avg_logprob": -0.23625169197718301, "compression_ratio": 1.8127659574468085, "no_speech_prob": 4.610779433278367e-05}, {"id": 840, "seek": 383396, "start": 3850.76, "end": 3852.76, "text": " Thai state of the art", "tokens": [19254, 1785, 295, 264, 1523], "temperature": 0.0, "avg_logprob": -0.23625169197718301, "compression_ratio": 1.8127659574468085, "no_speech_prob": 4.610779433278367e-05}, {"id": 841, "seek": 383396, "start": 3852.92, "end": 3854.68, "text": " German state of the art", "tokens": [6521, 1785, 295, 264, 1523], "temperature": 0.0, "avg_logprob": -0.23625169197718301, "compression_ratio": 1.8127659574468085, "no_speech_prob": 4.610779433278367e-05}, {"id": 842, "seek": 383396, "start": 3854.68, "end": 3861.68, "text": " Basically as students have been coming up with new study that results across lots of different languages and this all is entirely being done", "tokens": [8537, 382, 1731, 362, 668, 1348, 493, 365, 777, 2979, 300, 3542, 2108, 3195, 295, 819, 8650, 293, 341, 439, 307, 7696, 885, 1096], "temperature": 0.0, "avg_logprob": -0.23625169197718301, "compression_ratio": 1.8127659574468085, "no_speech_prob": 4.610779433278367e-05}, {"id": 843, "seek": 386168, "start": 3861.68, "end": 3867.56, "text": " By students working together through the forum. So please get on the forum", "tokens": [3146, 1731, 1364, 1214, 807, 264, 17542, 13, 407, 1767, 483, 322, 264, 17542], "temperature": 0.0, "avg_logprob": -0.1828084531037704, "compression_ratio": 1.7924528301886793, "no_speech_prob": 3.3404919577151304e-06}, {"id": 844, "seek": 386168, "start": 3868.08, "end": 3869.3599999999997, "text": " but", "tokens": [457], "temperature": 0.0, "avg_logprob": -0.1828084531037704, "compression_ratio": 1.7924528301886793, "no_speech_prob": 3.3404919577151304e-06}, {"id": 845, "seek": 386168, "start": 3869.3599999999997, "end": 3876.2799999999997, "text": " Don't be intimidated because remember a lot of the people everybody you see on the forum the vast majority posting", "tokens": [1468, 380, 312, 40234, 570, 1604, 257, 688, 295, 264, 561, 2201, 291, 536, 322, 264, 17542, 264, 8369, 6286, 15978], "temperature": 0.0, "avg_logprob": -0.1828084531037704, "compression_ratio": 1.7924528301886793, "no_speech_prob": 3.3404919577151304e-06}, {"id": 846, "seek": 386168, "start": 3876.64, "end": 3878.48, "text": " Post all the damn time right?", "tokens": [10223, 439, 264, 8151, 565, 558, 30], "temperature": 0.0, "avg_logprob": -0.1828084531037704, "compression_ratio": 1.7924528301886793, "no_speech_prob": 3.3404919577151304e-06}, {"id": 847, "seek": 386168, "start": 3878.48, "end": 3883.3599999999997, "text": " They've been doing this a lot and they do it a lot of the time and so at first it can feel", "tokens": [814, 600, 668, 884, 341, 257, 688, 293, 436, 360, 309, 257, 688, 295, 264, 565, 293, 370, 412, 700, 309, 393, 841], "temperature": 0.0, "avg_logprob": -0.1828084531037704, "compression_ratio": 1.7924528301886793, "no_speech_prob": 3.3404919577151304e-06}, {"id": 848, "seek": 386168, "start": 3883.56, "end": 3886.2, "text": " Intimidating because it can feel like you're the only new person there", "tokens": [5681, 332, 327, 990, 570, 309, 393, 841, 411, 291, 434, 264, 787, 777, 954, 456], "temperature": 0.0, "avg_logprob": -0.1828084531037704, "compression_ratio": 1.7924528301886793, "no_speech_prob": 3.3404919577151304e-06}, {"id": 849, "seek": 386168, "start": 3886.52, "end": 3891.06, "text": " But you're not right all of you people in the audience everybody who's watching everybody", "tokens": [583, 291, 434, 406, 558, 439, 295, 291, 561, 294, 264, 4034, 2201, 567, 311, 1976, 2201], "temperature": 0.0, "avg_logprob": -0.1828084531037704, "compression_ratio": 1.7924528301886793, "no_speech_prob": 3.3404919577151304e-06}, {"id": 850, "seek": 389106, "start": 3891.06, "end": 3895.94, "text": " He's listening you're all new people that and so when you just get out there and say like", "tokens": [634, 311, 4764, 291, 434, 439, 777, 561, 300, 293, 370, 562, 291, 445, 483, 484, 456, 293, 584, 411], "temperature": 0.0, "avg_logprob": -0.19618954467773436, "compression_ratio": 1.6677966101694914, "no_speech_prob": 1.2411028365022503e-05}, {"id": 851, "seek": 389106, "start": 3896.64, "end": 3900.92, "text": " Okay, all you people getting used out of the art results in German language modeling. I", "tokens": [1033, 11, 439, 291, 561, 1242, 1143, 484, 295, 264, 1523, 3542, 294, 6521, 2856, 15983, 13, 286], "temperature": 0.0, "avg_logprob": -0.19618954467773436, "compression_ratio": 1.6677966101694914, "no_speech_prob": 1.2411028365022503e-05}, {"id": 852, "seek": 389106, "start": 3901.96, "end": 3905.94, "text": " Can't start my server. I try to click the notebook and I get an error", "tokens": [1664, 380, 722, 452, 7154, 13, 286, 853, 281, 2052, 264, 21060, 293, 286, 483, 364, 6713], "temperature": 0.0, "avg_logprob": -0.19618954467773436, "compression_ratio": 1.6677966101694914, "no_speech_prob": 1.2411028365022503e-05}, {"id": 853, "seek": 389106, "start": 3906.6, "end": 3908.82, "text": " What do I do people will help you?", "tokens": [708, 360, 286, 360, 561, 486, 854, 291, 30], "temperature": 0.0, "avg_logprob": -0.19618954467773436, "compression_ratio": 1.6677966101694914, "no_speech_prob": 1.2411028365022503e-05}, {"id": 854, "seek": 389106, "start": 3909.32, "end": 3913.7599999999998, "text": " Okay, just make sure you provide all the information. This is though. You know, I'm using paper space", "tokens": [1033, 11, 445, 652, 988, 291, 2893, 439, 264, 1589, 13, 639, 307, 1673, 13, 509, 458, 11, 286, 478, 1228, 3035, 1901], "temperature": 0.0, "avg_logprob": -0.19618954467773436, "compression_ratio": 1.6677966101694914, "no_speech_prob": 1.2411028365022503e-05}, {"id": 855, "seek": 389106, "start": 3914.16, "end": 3918.06, "text": " This was the particular instance. I tried to use here's a screenshot of my error", "tokens": [639, 390, 264, 1729, 5197, 13, 286, 3031, 281, 764, 510, 311, 257, 27712, 295, 452, 6713], "temperature": 0.0, "avg_logprob": -0.19618954467773436, "compression_ratio": 1.6677966101694914, "no_speech_prob": 1.2411028365022503e-05}, {"id": 856, "seek": 391806, "start": 3918.06, "end": 3923.9, "text": " People will help you. Okay, or if you've got something to add so if people are talking about", "tokens": [3432, 486, 854, 291, 13, 1033, 11, 420, 498, 291, 600, 658, 746, 281, 909, 370, 498, 561, 366, 1417, 466], "temperature": 0.0, "avg_logprob": -0.2018052971881369, "compression_ratio": 1.695167286245353, "no_speech_prob": 1.045132739818655e-05}, {"id": 857, "seek": 391806, "start": 3924.66, "end": 3929.58, "text": " Crop yield analysis and you're a farmer and you think you know, oh, I've got something to add", "tokens": [383, 1513, 11257, 5215, 293, 291, 434, 257, 17891, 293, 291, 519, 291, 458, 11, 1954, 11, 286, 600, 658, 746, 281, 909], "temperature": 0.0, "avg_logprob": -0.2018052971881369, "compression_ratio": 1.695167286245353, "no_speech_prob": 1.045132739818655e-05}, {"id": 858, "seek": 391806, "start": 3930.46, "end": 3931.62, "text": " Please", "tokens": [2555], "temperature": 0.0, "avg_logprob": -0.2018052971881369, "compression_ratio": 1.695167286245353, "no_speech_prob": 1.045132739818655e-05}, {"id": 859, "seek": 391806, "start": 3931.62, "end": 3935.52, "text": " Mention it even even if you're not sure it's exactly relevant. It's fine", "tokens": [376, 1251, 309, 754, 754, 498, 291, 434, 406, 988, 309, 311, 2293, 7340, 13, 467, 311, 2489], "temperature": 0.0, "avg_logprob": -0.2018052971881369, "compression_ratio": 1.695167286245353, "no_speech_prob": 1.045132739818655e-05}, {"id": 860, "seek": 391806, "start": 3935.52, "end": 3939.88, "text": " You know just get involved and because remember everybody else in the forum started out", "tokens": [509, 458, 445, 483, 3288, 293, 570, 1604, 2201, 1646, 294, 264, 17542, 1409, 484], "temperature": 0.0, "avg_logprob": -0.2018052971881369, "compression_ratio": 1.695167286245353, "no_speech_prob": 1.045132739818655e-05}, {"id": 861, "seek": 391806, "start": 3940.62, "end": 3943.58, "text": " Also intimidated. All right, we all start out", "tokens": [2743, 40234, 13, 1057, 558, 11, 321, 439, 722, 484], "temperature": 0.0, "avg_logprob": -0.2018052971881369, "compression_ratio": 1.695167286245353, "no_speech_prob": 1.045132739818655e-05}, {"id": 862, "seek": 394358, "start": 3943.58, "end": 3947.38, "text": " Not knowing things and so just get out there and try it. Okay", "tokens": [1726, 5276, 721, 293, 370, 445, 483, 484, 456, 293, 853, 309, 13, 1033], "temperature": 0.0, "avg_logprob": -0.2676962267967962, "compression_ratio": 1.484076433121019, "no_speech_prob": 1.9525390598573722e-05}, {"id": 863, "seek": 394358, "start": 3950.62, "end": 3952.54, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.2676962267967962, "compression_ratio": 1.484076433121019, "no_speech_prob": 1.9525390598573722e-05}, {"id": 864, "seek": 394358, "start": 3952.54, "end": 3954.54, "text": " Let's get back and do some more coding", "tokens": [961, 311, 483, 646, 293, 360, 512, 544, 17720], "temperature": 0.0, "avg_logprob": -0.2676962267967962, "compression_ratio": 1.484076433121019, "no_speech_prob": 1.9525390598573722e-05}, {"id": 865, "seek": 394358, "start": 3956.62, "end": 3958.62, "text": " Yes, Richard, we have some questions", "tokens": [1079, 11, 9809, 11, 321, 362, 512, 1651], "temperature": 0.0, "avg_logprob": -0.2676962267967962, "compression_ratio": 1.484076433121019, "no_speech_prob": 1.9525390598573722e-05}, {"id": 866, "seek": 394358, "start": 3966.94, "end": 3969.42, "text": " So the question is about this architecture", "tokens": [407, 264, 1168, 307, 466, 341, 9482], "temperature": 0.0, "avg_logprob": -0.2676962267967962, "compression_ratio": 1.484076433121019, "no_speech_prob": 1.9525390598573722e-05}, {"id": 867, "seek": 396942, "start": 3969.42, "end": 3975.62, "text": " So there are lots of architectures to choose from and it would be fair to say there isn't", "tokens": [407, 456, 366, 3195, 295, 6331, 1303, 281, 2826, 490, 293, 309, 576, 312, 3143, 281, 584, 456, 1943, 380], "temperature": 0.0, "avg_logprob": -0.2517727891059771, "compression_ratio": 1.5852272727272727, "no_speech_prob": 2.4681985451024957e-05}, {"id": 868, "seek": 396942, "start": 3977.02, "end": 3979.02, "text": " one best one", "tokens": [472, 1151, 472], "temperature": 0.0, "avg_logprob": -0.2517727891059771, "compression_ratio": 1.5852272727272727, "no_speech_prob": 2.4681985451024957e-05}, {"id": 869, "seek": 396942, "start": 3979.94, "end": 3981.94, "text": " but if you look at", "tokens": [457, 498, 291, 574, 412], "temperature": 0.0, "avg_logprob": -0.2517727891059771, "compression_ratio": 1.5852272727272727, "no_speech_prob": 2.4681985451024957e-05}, {"id": 870, "seek": 396942, "start": 3982.46, "end": 3984.1800000000003, "text": " things like the", "tokens": [721, 411, 264], "temperature": 0.0, "avg_logprob": -0.2517727891059771, "compression_ratio": 1.5852272727272727, "no_speech_prob": 2.4681985451024957e-05}, {"id": 871, "seek": 396942, "start": 3984.1800000000003, "end": 3986.1800000000003, "text": " Stanford dawn bench benchmark", "tokens": [20374, 18192, 10638, 18927], "temperature": 0.0, "avg_logprob": -0.2517727891059771, "compression_ratio": 1.5852272727272727, "no_speech_prob": 2.4681985451024957e-05}, {"id": 872, "seek": 396942, "start": 3986.58, "end": 3988.58, "text": " or image net classification", "tokens": [420, 3256, 2533, 21538], "temperature": 0.0, "avg_logprob": -0.2517727891059771, "compression_ratio": 1.5852272727272727, "no_speech_prob": 2.4681985451024957e-05}, {"id": 873, "seek": 396942, "start": 3988.86, "end": 3993.7000000000003, "text": " You'll see in first place in second place in third place in fourth place is fast AI", "tokens": [509, 603, 536, 294, 700, 1081, 294, 1150, 1081, 294, 2636, 1081, 294, 6409, 1081, 307, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.2517727891059771, "compression_ratio": 1.5852272727272727, "no_speech_prob": 2.4681985451024957e-05}, {"id": 874, "seek": 399370, "start": 3993.7, "end": 3999.54, "text": " Jeremy had and fast AI Jeremy had fast AI here's gloves from the Department of Defense Innovation team", "tokens": [17809, 632, 293, 2370, 7318, 17809, 632, 2370, 7318, 510, 311, 14976, 490, 264, 5982, 295, 17410, 27092, 1469], "temperature": 0.0, "avg_logprob": -0.27577692397097325, "compression_ratio": 1.6652173913043478, "no_speech_prob": 6.339102128549712e-06}, {"id": 875, "seek": 399370, "start": 4000.22, "end": 4001.3799999999997, "text": " Google", "tokens": [3329], "temperature": 0.0, "avg_logprob": -0.27577692397097325, "compression_ratio": 1.6652173913043478, "no_speech_prob": 6.339102128549712e-06}, {"id": 876, "seek": 399370, "start": 4001.3799999999997, "end": 4007.8199999999997, "text": " Resnet resnet resnet resnet resnet. It's good enough. Okay, so it's fun", "tokens": [5015, 7129, 725, 7129, 725, 7129, 725, 7129, 725, 7129, 13, 467, 311, 665, 1547, 13, 1033, 11, 370, 309, 311, 1019], "temperature": 0.0, "avg_logprob": -0.27577692397097325, "compression_ratio": 1.6652173913043478, "no_speech_prob": 6.339102128549712e-06}, {"id": 877, "seek": 399370, "start": 4012.54, "end": 4017.9399999999996, "text": " There are other architectures the main reason you might want a different architecture is if you want to do edge computing", "tokens": [821, 366, 661, 6331, 1303, 264, 2135, 1778, 291, 1062, 528, 257, 819, 9482, 307, 498, 291, 528, 281, 360, 4691, 15866], "temperature": 0.0, "avg_logprob": -0.27577692397097325, "compression_ratio": 1.6652173913043478, "no_speech_prob": 6.339102128549712e-06}, {"id": 878, "seek": 399370, "start": 4017.9399999999996, "end": 4021.18, "text": " So if you want to create a model that's going to sit on somebody's mobile phone", "tokens": [407, 498, 291, 528, 281, 1884, 257, 2316, 300, 311, 516, 281, 1394, 322, 2618, 311, 6013, 2593], "temperature": 0.0, "avg_logprob": -0.27577692397097325, "compression_ratio": 1.6652173913043478, "no_speech_prob": 6.339102128549712e-06}, {"id": 879, "seek": 402118, "start": 4021.18, "end": 4027.3799999999997, "text": " Having said that even there most of the time I reckon the best way to get a model onto somebody's mobile phone is to run", "tokens": [10222, 848, 300, 754, 456, 881, 295, 264, 565, 286, 29548, 264, 1151, 636, 281, 483, 257, 2316, 3911, 2618, 311, 6013, 2593, 307, 281, 1190], "temperature": 0.0, "avg_logprob": -0.14629280358030086, "compression_ratio": 1.7465753424657535, "no_speech_prob": 1.8631419152370654e-05}, {"id": 880, "seek": 402118, "start": 4027.3799999999997, "end": 4031.1, "text": " It on your server and then have your mobile phone app talk to it", "tokens": [467, 322, 428, 7154, 293, 550, 362, 428, 6013, 2593, 724, 751, 281, 309], "temperature": 0.0, "avg_logprob": -0.14629280358030086, "compression_ratio": 1.7465753424657535, "no_speech_prob": 1.8631419152370654e-05}, {"id": 881, "seek": 402118, "start": 4031.1, "end": 4034.14, "text": " It really makes life a lot easier and you've got a lot more flexibility", "tokens": [467, 534, 1669, 993, 257, 688, 3571, 293, 291, 600, 658, 257, 688, 544, 12635], "temperature": 0.0, "avg_logprob": -0.14629280358030086, "compression_ratio": 1.7465753424657535, "no_speech_prob": 1.8631419152370654e-05}, {"id": 882, "seek": 402118, "start": 4034.4199999999996, "end": 4039.62, "text": " But if you really do need to run something on a low-powered device, then there are some special architectures for that", "tokens": [583, 498, 291, 534, 360, 643, 281, 1190, 746, 322, 257, 2295, 12, 27178, 4302, 11, 550, 456, 366, 512, 2121, 6331, 1303, 337, 300], "temperature": 0.0, "avg_logprob": -0.14629280358030086, "compression_ratio": 1.7465753424657535, "no_speech_prob": 1.8631419152370654e-05}, {"id": 883, "seek": 402118, "start": 4042.2999999999997, "end": 4044.2999999999997, "text": " So the particular question was about inception", "tokens": [407, 264, 1729, 1168, 390, 466, 49834], "temperature": 0.0, "avg_logprob": -0.14629280358030086, "compression_ratio": 1.7465753424657535, "no_speech_prob": 1.8631419152370654e-05}, {"id": 884, "seek": 404430, "start": 4044.3, "end": 4052.1000000000004, "text": " That's a particular another architecture which tends to be pretty memory intensive and yet resident", "tokens": [663, 311, 257, 1729, 1071, 9482, 597, 12258, 281, 312, 1238, 4675, 18957, 293, 1939, 10832], "temperature": 0.0, "avg_logprob": -0.1874734629755435, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.9222676201025024e-05}, {"id": 885, "seek": 404430, "start": 4053.2200000000003, "end": 4057.2200000000003, "text": " So inception tends to be pretty memory intensive, but it's okay. It's also like", "tokens": [407, 49834, 12258, 281, 312, 1238, 4675, 18957, 11, 457, 309, 311, 1392, 13, 467, 311, 611, 411], "temperature": 0.0, "avg_logprob": -0.1874734629755435, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.9222676201025024e-05}, {"id": 886, "seek": 404430, "start": 4057.86, "end": 4063.6200000000003, "text": " It's not terribly resilient. One of the things we try to show you is like stuff which just tends to always work", "tokens": [467, 311, 406, 22903, 23699, 13, 1485, 295, 264, 721, 321, 853, 281, 855, 291, 307, 411, 1507, 597, 445, 12258, 281, 1009, 589], "temperature": 0.0, "avg_logprob": -0.1874734629755435, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.9222676201025024e-05}, {"id": 887, "seek": 404430, "start": 4064.3, "end": 4066.54, "text": " Even if you don't quite tune everything perfectly", "tokens": [2754, 498, 291, 500, 380, 1596, 10864, 1203, 6239], "temperature": 0.0, "avg_logprob": -0.1874734629755435, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.9222676201025024e-05}, {"id": 888, "seek": 404430, "start": 4067.34, "end": 4071.1200000000003, "text": " So resident tends to work pretty well across a wide range of different", "tokens": [407, 10832, 12258, 281, 589, 1238, 731, 2108, 257, 4874, 3613, 295, 819], "temperature": 0.0, "avg_logprob": -0.1874734629755435, "compression_ratio": 1.73109243697479, "no_speech_prob": 1.9222676201025024e-05}, {"id": 889, "seek": 407112, "start": 4071.12, "end": 4076.2999999999997, "text": " Kind of details around choices that you might make so I think it's pretty good", "tokens": [9242, 295, 4365, 926, 7994, 300, 291, 1062, 652, 370, 286, 519, 309, 311, 1238, 665], "temperature": 0.0, "avg_logprob": -0.17137626891440533, "compression_ratio": 1.6472868217054264, "no_speech_prob": 2.212524486822076e-05}, {"id": 890, "seek": 407112, "start": 4078.68, "end": 4083.12, "text": " So we've got this train model and so what's actually happened as we'll learn is it's basically", "tokens": [407, 321, 600, 658, 341, 3847, 2316, 293, 370, 437, 311, 767, 2011, 382, 321, 603, 1466, 307, 309, 311, 1936], "temperature": 0.0, "avg_logprob": -0.17137626891440533, "compression_ratio": 1.6472868217054264, "no_speech_prob": 2.212524486822076e-05}, {"id": 891, "seek": 407112, "start": 4084.3599999999997, "end": 4090.8599999999997, "text": " Creating a set of weights if you've ever done anything like linear regression or logistic regression, you'll be familiar with coefficients", "tokens": [40002, 257, 992, 295, 17443, 498, 291, 600, 1562, 1096, 1340, 411, 8213, 24590, 420, 3565, 3142, 24590, 11, 291, 603, 312, 4963, 365, 31994], "temperature": 0.0, "avg_logprob": -0.17137626891440533, "compression_ratio": 1.6472868217054264, "no_speech_prob": 2.212524486822076e-05}, {"id": 892, "seek": 407112, "start": 4090.8599999999997, "end": 4093.74, "text": " We basically found some coefficients and parameters that work pretty well", "tokens": [492, 1936, 1352, 512, 31994, 293, 9834, 300, 589, 1238, 731], "temperature": 0.0, "avg_logprob": -0.17137626891440533, "compression_ratio": 1.6472868217054264, "no_speech_prob": 2.212524486822076e-05}, {"id": 893, "seek": 407112, "start": 4094.52, "end": 4096.72, "text": " And it took us a minute and 56 seconds", "tokens": [400, 309, 1890, 505, 257, 3456, 293, 19687, 3949], "temperature": 0.0, "avg_logprob": -0.17137626891440533, "compression_ratio": 1.6472868217054264, "no_speech_prob": 2.212524486822076e-05}, {"id": 894, "seek": 409672, "start": 4096.72, "end": 4102.320000000001, "text": " So if we want to start doing some more playing around and come back later, we probably should save those weights", "tokens": [407, 498, 321, 528, 281, 722, 884, 512, 544, 2433, 926, 293, 808, 646, 1780, 11, 321, 1391, 820, 3155, 729, 17443], "temperature": 0.0, "avg_logprob": -0.1453351287841797, "compression_ratio": 1.7254901960784315, "no_speech_prob": 4.565943982015597e-06}, {"id": 895, "seek": 409672, "start": 4102.320000000001, "end": 4107.0, "text": " So we can save that minute and 56 seconds so you can just go learn dot save and give it a name", "tokens": [407, 321, 393, 3155, 300, 3456, 293, 19687, 3949, 370, 291, 393, 445, 352, 1466, 5893, 3155, 293, 976, 309, 257, 1315], "temperature": 0.0, "avg_logprob": -0.1453351287841797, "compression_ratio": 1.7254901960784315, "no_speech_prob": 4.565943982015597e-06}, {"id": 896, "seek": 409672, "start": 4107.52, "end": 4109.400000000001, "text": " It's going to put it", "tokens": [467, 311, 516, 281, 829, 309], "temperature": 0.0, "avg_logprob": -0.1453351287841797, "compression_ratio": 1.7254901960784315, "no_speech_prob": 4.565943982015597e-06}, {"id": 897, "seek": 409672, "start": 4109.400000000001, "end": 4112.84, "text": " In a model sub directory in the same place the data came from", "tokens": [682, 257, 2316, 1422, 21120, 294, 264, 912, 1081, 264, 1412, 1361, 490], "temperature": 0.0, "avg_logprob": -0.1453351287841797, "compression_ratio": 1.7254901960784315, "no_speech_prob": 4.565943982015597e-06}, {"id": 898, "seek": 409672, "start": 4112.96, "end": 4120.12, "text": " So if you save different models or different data bunches from different data sets, they'll all be kept separate. So don't worry about it", "tokens": [407, 498, 291, 3155, 819, 5245, 420, 819, 1412, 3840, 279, 490, 819, 1412, 6352, 11, 436, 603, 439, 312, 4305, 4994, 13, 407, 500, 380, 3292, 466, 309], "temperature": 0.0, "avg_logprob": -0.1453351287841797, "compression_ratio": 1.7254901960784315, "no_speech_prob": 4.565943982015597e-06}, {"id": 899, "seek": 409672, "start": 4122.4800000000005, "end": 4126.68, "text": " Alright so we talked about how the most important things are how to learn what goes into your model", "tokens": [2798, 370, 321, 2825, 466, 577, 264, 881, 1021, 721, 366, 577, 281, 1466, 437, 1709, 666, 428, 2316], "temperature": 0.0, "avg_logprob": -0.1453351287841797, "compression_ratio": 1.7254901960784315, "no_speech_prob": 4.565943982015597e-06}, {"id": 900, "seek": 412668, "start": 4126.68, "end": 4131.84, "text": " What comes out we've seen one way of seeing what goes in now. Let's see what comes out", "tokens": [708, 1487, 484, 321, 600, 1612, 472, 636, 295, 2577, 437, 1709, 294, 586, 13, 961, 311, 536, 437, 1487, 484], "temperature": 0.0, "avg_logprob": -0.1774037953080802, "compression_ratio": 1.7655677655677655, "no_speech_prob": 1.3845888133801054e-05}, {"id": 901, "seek": 412668, "start": 4131.96, "end": 4134.200000000001, "text": " As this is the other thing you need to get really good at", "tokens": [1018, 341, 307, 264, 661, 551, 291, 643, 281, 483, 534, 665, 412], "temperature": 0.0, "avg_logprob": -0.1774037953080802, "compression_ratio": 1.7655677655677655, "no_speech_prob": 1.3845888133801054e-05}, {"id": 902, "seek": 412668, "start": 4135.280000000001, "end": 4140.96, "text": " so to see what comes out we can use this class called classification interpretation and", "tokens": [370, 281, 536, 437, 1487, 484, 321, 393, 764, 341, 1508, 1219, 21538, 14174, 293], "temperature": 0.0, "avg_logprob": -0.1774037953080802, "compression_ratio": 1.7655677655677655, "no_speech_prob": 1.3845888133801054e-05}, {"id": 903, "seek": 412668, "start": 4142.200000000001, "end": 4148.76, "text": " We're going to use this factory method from learner. So we pass in a learn object. So remember a learn object knows two things", "tokens": [492, 434, 516, 281, 764, 341, 9265, 3170, 490, 33347, 13, 407, 321, 1320, 294, 257, 1466, 2657, 13, 407, 1604, 257, 1466, 2657, 3255, 732, 721], "temperature": 0.0, "avg_logprob": -0.1774037953080802, "compression_ratio": 1.7655677655677655, "no_speech_prob": 1.3845888133801054e-05}, {"id": 904, "seek": 412668, "start": 4149.320000000001, "end": 4151.320000000001, "text": " what's your data and", "tokens": [437, 311, 428, 1412, 293], "temperature": 0.0, "avg_logprob": -0.1774037953080802, "compression_ratio": 1.7655677655677655, "no_speech_prob": 1.3845888133801054e-05}, {"id": 905, "seek": 415132, "start": 4151.32, "end": 4157.5599999999995, "text": " What is your model? It's now not just an architecture, but it's actually a trained model inside there and that's all the information", "tokens": [708, 307, 428, 2316, 30, 467, 311, 586, 406, 445, 364, 9482, 11, 457, 309, 311, 767, 257, 8895, 2316, 1854, 456, 293, 300, 311, 439, 264, 1589], "temperature": 0.0, "avg_logprob": -0.18195456325417697, "compression_ratio": 1.704724409448819, "no_speech_prob": 1.933351086336188e-06}, {"id": 906, "seek": 415132, "start": 4157.5599999999995, "end": 4164.92, "text": " We need to interpret that model. So it's this pass in the learner and we now have a classification interpretation object", "tokens": [492, 643, 281, 7302, 300, 2316, 13, 407, 309, 311, 341, 1320, 294, 264, 33347, 293, 321, 586, 362, 257, 21538, 14174, 2657], "temperature": 0.0, "avg_logprob": -0.18195456325417697, "compression_ratio": 1.704724409448819, "no_speech_prob": 1.933351086336188e-06}, {"id": 907, "seek": 415132, "start": 4165.92, "end": 4167.099999999999, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.18195456325417697, "compression_ratio": 1.704724409448819, "no_speech_prob": 1.933351086336188e-06}, {"id": 908, "seek": 415132, "start": 4167.099999999999, "end": 4172.599999999999, "text": " So one of the things we can do and perhaps the most useful things to do is called plot top losses", "tokens": [407, 472, 295, 264, 721, 321, 393, 360, 293, 4317, 264, 881, 4420, 721, 281, 360, 307, 1219, 7542, 1192, 15352], "temperature": 0.0, "avg_logprob": -0.18195456325417697, "compression_ratio": 1.704724409448819, "no_speech_prob": 1.933351086336188e-06}, {"id": 909, "seek": 415132, "start": 4173.639999999999, "end": 4178.78, "text": " So we're going to be learning a lot about this idea of loss functions shortly", "tokens": [407, 321, 434, 516, 281, 312, 2539, 257, 688, 466, 341, 1558, 295, 4470, 6828, 13392], "temperature": 0.0, "avg_logprob": -0.18195456325417697, "compression_ratio": 1.704724409448819, "no_speech_prob": 1.933351086336188e-06}, {"id": 910, "seek": 417878, "start": 4178.78, "end": 4184.54, "text": " but in short a loss function is something that tells you how good was your prediction and", "tokens": [457, 294, 2099, 257, 4470, 2445, 307, 746, 300, 5112, 291, 577, 665, 390, 428, 17630, 293], "temperature": 0.0, "avg_logprob": -0.19252703563276544, "compression_ratio": 1.6587677725118484, "no_speech_prob": 2.026130005106097e-06}, {"id": 911, "seek": 417878, "start": 4185.099999999999, "end": 4187.94, "text": " So specifically that means if you predicted", "tokens": [407, 4682, 300, 1355, 498, 291, 19147], "temperature": 0.0, "avg_logprob": -0.19252703563276544, "compression_ratio": 1.6587677725118484, "no_speech_prob": 2.026130005106097e-06}, {"id": 912, "seek": 417878, "start": 4188.74, "end": 4190.74, "text": " one class of cat", "tokens": [472, 1508, 295, 3857], "temperature": 0.0, "avg_logprob": -0.19252703563276544, "compression_ratio": 1.6587677725118484, "no_speech_prob": 2.026130005106097e-06}, {"id": 913, "seek": 417878, "start": 4191.54, "end": 4196.259999999999, "text": " With great confidence. You said I am very very sure that this is a", "tokens": [2022, 869, 6687, 13, 509, 848, 286, 669, 588, 588, 988, 300, 341, 307, 257], "temperature": 0.0, "avg_logprob": -0.19252703563276544, "compression_ratio": 1.6587677725118484, "no_speech_prob": 2.026130005106097e-06}, {"id": 914, "seek": 417878, "start": 4198.219999999999, "end": 4199.74, "text": " Berman", "tokens": [363, 11821], "temperature": 0.0, "avg_logprob": -0.19252703563276544, "compression_ratio": 1.6587677725118484, "no_speech_prob": 2.026130005106097e-06}, {"id": 915, "seek": 417878, "start": 4199.74, "end": 4206.759999999999, "text": " But actually you were wrong then then that's going to have a high loss because you were very confident about the wrong answer", "tokens": [583, 767, 291, 645, 2085, 550, 550, 300, 311, 516, 281, 362, 257, 1090, 4470, 570, 291, 645, 588, 6679, 466, 264, 2085, 1867], "temperature": 0.0, "avg_logprob": -0.19252703563276544, "compression_ratio": 1.6587677725118484, "no_speech_prob": 2.026130005106097e-06}, {"id": 916, "seek": 420676, "start": 4206.76, "end": 4212.4800000000005, "text": " Okay, so that's what it basically means to have a high loss. So by putting the top losses, we're going to find out", "tokens": [1033, 11, 370, 300, 311, 437, 309, 1936, 1355, 281, 362, 257, 1090, 4470, 13, 407, 538, 3372, 264, 1192, 15352, 11, 321, 434, 516, 281, 915, 484], "temperature": 0.0, "avg_logprob": -0.19942803984706842, "compression_ratio": 1.6584362139917694, "no_speech_prob": 1.9033778926313971e-06}, {"id": 917, "seek": 420676, "start": 4212.92, "end": 4218.04, "text": " What were the things that we were the most wrong on or the most confident about what we got wrong?", "tokens": [708, 645, 264, 721, 300, 321, 645, 264, 881, 2085, 322, 420, 264, 881, 6679, 466, 437, 321, 658, 2085, 30], "temperature": 0.0, "avg_logprob": -0.19942803984706842, "compression_ratio": 1.6584362139917694, "no_speech_prob": 1.9033778926313971e-06}, {"id": 918, "seek": 420676, "start": 4218.84, "end": 4220.84, "text": " So you can see here", "tokens": [407, 291, 393, 536, 510], "temperature": 0.0, "avg_logprob": -0.19942803984706842, "compression_ratio": 1.6584362139917694, "no_speech_prob": 1.9033778926313971e-06}, {"id": 919, "seek": 420676, "start": 4220.88, "end": 4222.88, "text": " It prints out three things", "tokens": [467, 22305, 484, 1045, 721], "temperature": 0.0, "avg_logprob": -0.19942803984706842, "compression_ratio": 1.6584362139917694, "no_speech_prob": 1.9033778926313971e-06}, {"id": 920, "seek": 420676, "start": 4223.4400000000005, "end": 4228.9800000000005, "text": " German shorthead before things big all seven point oh four point nine two", "tokens": [6521, 402, 2652, 2056, 949, 721, 955, 439, 3407, 935, 1954, 1451, 935, 4949, 732], "temperature": 0.0, "avg_logprob": -0.19942803984706842, "compression_ratio": 1.6584362139917694, "no_speech_prob": 1.9033778926313971e-06}, {"id": 921, "seek": 420676, "start": 4230.12, "end": 4232.12, "text": " Well, what do they mean?", "tokens": [1042, 11, 437, 360, 436, 914, 30], "temperature": 0.0, "avg_logprob": -0.19942803984706842, "compression_ratio": 1.6584362139917694, "no_speech_prob": 1.9033778926313971e-06}, {"id": 922, "seek": 423212, "start": 4232.12, "end": 4235.92, "text": " Perhaps we should look at the documentation", "tokens": [10517, 321, 820, 574, 412, 264, 14333], "temperature": 0.0, "avg_logprob": -0.2270780226763557, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.9669694160693325e-06}, {"id": 923, "seek": 423212, "start": 4237.2, "end": 4242.0, "text": " So if you we've already seen help right and help just prints out a quick little summary", "tokens": [407, 498, 291, 321, 600, 1217, 1612, 854, 558, 293, 854, 445, 22305, 484, 257, 1702, 707, 12691], "temperature": 0.0, "avg_logprob": -0.2270780226763557, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.9669694160693325e-06}, {"id": 924, "seek": 423212, "start": 4242.0, "end": 4244.92, "text": " but if you want to really see how to do something use doc and", "tokens": [457, 498, 291, 528, 281, 534, 536, 577, 281, 360, 746, 764, 3211, 293], "temperature": 0.0, "avg_logprob": -0.2270780226763557, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.9669694160693325e-06}, {"id": 925, "seek": 423212, "start": 4245.88, "end": 4247.16, "text": " doc", "tokens": [3211], "temperature": 0.0, "avg_logprob": -0.2270780226763557, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.9669694160693325e-06}, {"id": 926, "seek": 423212, "start": 4247.16, "end": 4250.96, "text": " Tells you the same information as help, but it has this very important thing which is", "tokens": [5115, 82, 291, 264, 912, 1589, 382, 854, 11, 457, 309, 575, 341, 588, 1021, 551, 597, 307], "temperature": 0.0, "avg_logprob": -0.2270780226763557, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.9669694160693325e-06}, {"id": 927, "seek": 423212, "start": 4251.64, "end": 4253.64, "text": " show in docs", "tokens": [855, 294, 45623], "temperature": 0.0, "avg_logprob": -0.2270780226763557, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.9669694160693325e-06}, {"id": 928, "seek": 423212, "start": 4253.64, "end": 4255.76, "text": " So when you click on show in docs", "tokens": [407, 562, 291, 2052, 322, 855, 294, 45623], "temperature": 0.0, "avg_logprob": -0.2270780226763557, "compression_ratio": 1.625615763546798, "no_speech_prob": 3.9669694160693325e-06}, {"id": 929, "seek": 425576, "start": 4255.76, "end": 4262.4400000000005, "text": " It pops up the documentation for that method or class or function or whatever", "tokens": [467, 16795, 493, 264, 14333, 337, 300, 3170, 420, 1508, 420, 2445, 420, 2035], "temperature": 0.0, "avg_logprob": -0.22763933454241073, "compression_ratio": 1.7130044843049328, "no_speech_prob": 1.4823539231656468e-06}, {"id": 930, "seek": 425576, "start": 4263.08, "end": 4267.4400000000005, "text": " It starts out by showing us the same information about what is what are the parameters it takes?", "tokens": [467, 3719, 484, 538, 4099, 505, 264, 912, 1589, 466, 437, 307, 437, 366, 264, 9834, 309, 2516, 30], "temperature": 0.0, "avg_logprob": -0.22763933454241073, "compression_ratio": 1.7130044843049328, "no_speech_prob": 1.4823539231656468e-06}, {"id": 931, "seek": 425576, "start": 4268.2, "end": 4272.84, "text": " Along with the doc string, but then tells you more information", "tokens": [17457, 365, 264, 3211, 6798, 11, 457, 550, 5112, 291, 544, 1589], "temperature": 0.0, "avg_logprob": -0.22763933454241073, "compression_ratio": 1.7130044843049328, "no_speech_prob": 1.4823539231656468e-06}, {"id": 932, "seek": 425576, "start": 4272.84, "end": 4276.12, "text": " So in this case it's other thing that tells me the title of each shows", "tokens": [407, 294, 341, 1389, 309, 311, 661, 551, 300, 5112, 385, 264, 4876, 295, 1184, 3110], "temperature": 0.0, "avg_logprob": -0.22763933454241073, "compression_ratio": 1.7130044843049328, "no_speech_prob": 1.4823539231656468e-06}, {"id": 933, "seek": 425576, "start": 4276.92, "end": 4279.360000000001, "text": " the prediction the actual", "tokens": [264, 17630, 264, 3539], "temperature": 0.0, "avg_logprob": -0.22763933454241073, "compression_ratio": 1.7130044843049328, "no_speech_prob": 1.4823539231656468e-06}, {"id": 934, "seek": 425576, "start": 4280.04, "end": 4281.92, "text": " the loss and", "tokens": [264, 4470, 293], "temperature": 0.0, "avg_logprob": -0.22763933454241073, "compression_ratio": 1.7130044843049328, "no_speech_prob": 1.4823539231656468e-06}, {"id": 935, "seek": 425576, "start": 4281.92, "end": 4283.4400000000005, "text": " the probability", "tokens": [264, 8482], "temperature": 0.0, "avg_logprob": -0.22763933454241073, "compression_ratio": 1.7130044843049328, "no_speech_prob": 1.4823539231656468e-06}, {"id": 936, "seek": 425576, "start": 4283.4400000000005, "end": 4285.24, "text": " That was predicted", "tokens": [663, 390, 19147], "temperature": 0.0, "avg_logprob": -0.22763933454241073, "compression_ratio": 1.7130044843049328, "no_speech_prob": 1.4823539231656468e-06}, {"id": 937, "seek": 428524, "start": 4285.24, "end": 4288.5199999999995, "text": " So for example and you can see there's actually some code you can run", "tokens": [407, 337, 1365, 293, 291, 393, 536, 456, 311, 767, 512, 3089, 291, 393, 1190], "temperature": 0.0, "avg_logprob": -0.1914539522337682, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.530250852345489e-06}, {"id": 938, "seek": 428524, "start": 4288.84, "end": 4294.639999999999, "text": " so the documentation always has working code and so in this case it was trying things with handwritten digits and", "tokens": [370, 264, 14333, 1009, 575, 1364, 3089, 293, 370, 294, 341, 1389, 309, 390, 1382, 721, 365, 1011, 26859, 27011, 293], "temperature": 0.0, "avg_logprob": -0.1914539522337682, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.530250852345489e-06}, {"id": 939, "seek": 428524, "start": 4295.28, "end": 4299.48, "text": " So the first one it was predicted to be a seven. It was actually a three", "tokens": [407, 264, 700, 472, 309, 390, 19147, 281, 312, 257, 3407, 13, 467, 390, 767, 257, 1045], "temperature": 0.0, "avg_logprob": -0.1914539522337682, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.530250852345489e-06}, {"id": 940, "seek": 428524, "start": 4300.04, "end": 4302.04, "text": " the loss is five point", "tokens": [264, 4470, 307, 1732, 935], "temperature": 0.0, "avg_logprob": -0.1914539522337682, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.530250852345489e-06}, {"id": 941, "seek": 428524, "start": 4302.44, "end": 4308.5199999999995, "text": " 44 and the probability of the actual class was point oh seven. Okay, so I", "tokens": [16408, 293, 264, 8482, 295, 264, 3539, 1508, 390, 935, 1954, 3407, 13, 1033, 11, 370, 286], "temperature": 0.0, "avg_logprob": -0.1914539522337682, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.530250852345489e-06}, {"id": 942, "seek": 428524, "start": 4309.36, "end": 4312.86, "text": " You know, we did not have a high probability associate the actual class", "tokens": [509, 458, 11, 321, 630, 406, 362, 257, 1090, 8482, 14644, 264, 3539, 1508], "temperature": 0.0, "avg_logprob": -0.1914539522337682, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.530250852345489e-06}, {"id": 943, "seek": 431286, "start": 4312.86, "end": 4318.16, "text": " I can see why I thought this was a seven and the less it was wrong. So this is the documentation", "tokens": [286, 393, 536, 983, 286, 1194, 341, 390, 257, 3407, 293, 264, 1570, 309, 390, 2085, 13, 407, 341, 307, 264, 14333], "temperature": 0.0, "avg_logprob": -0.2119567454362116, "compression_ratio": 1.6816608996539792, "no_speech_prob": 6.1441442085197195e-06}, {"id": 944, "seek": 431286, "start": 4318.28, "end": 4322.44, "text": " Okay, and so this is your friend when you're trying to figure out how to use these things", "tokens": [1033, 11, 293, 370, 341, 307, 428, 1277, 562, 291, 434, 1382, 281, 2573, 484, 577, 281, 764, 613, 721], "temperature": 0.0, "avg_logprob": -0.2119567454362116, "compression_ratio": 1.6816608996539792, "no_speech_prob": 6.1441442085197195e-06}, {"id": 945, "seek": 431286, "start": 4322.5199999999995, "end": 4324.759999999999, "text": " the other thing I'll mention is if you're a", "tokens": [264, 661, 551, 286, 603, 2152, 307, 498, 291, 434, 257], "temperature": 0.0, "avg_logprob": -0.2119567454362116, "compression_ratio": 1.6816608996539792, "no_speech_prob": 6.1441442085197195e-06}, {"id": 946, "seek": 431286, "start": 4326.08, "end": 4331.0599999999995, "text": " Somewhat experienced Python programmer. You'll find the source code of fast AI really easy to read", "tokens": [2188, 5479, 6751, 15329, 32116, 13, 509, 603, 915, 264, 4009, 3089, 295, 2370, 7318, 534, 1858, 281, 1401], "temperature": 0.0, "avg_logprob": -0.2119567454362116, "compression_ratio": 1.6816608996539792, "no_speech_prob": 6.1441442085197195e-06}, {"id": 947, "seek": 431286, "start": 4331.2, "end": 4334.82, "text": " we try to write everything in just a small number of you know,", "tokens": [321, 853, 281, 2464, 1203, 294, 445, 257, 1359, 1230, 295, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.2119567454362116, "compression_ratio": 1.6816608996539792, "no_speech_prob": 6.1441442085197195e-06}, {"id": 948, "seek": 431286, "start": 4335.0199999999995, "end": 4339.28, "text": " Much less than half a screen of code generally four or five lines of code if you click source", "tokens": [12313, 1570, 813, 1922, 257, 2568, 295, 3089, 5101, 1451, 420, 1732, 3876, 295, 3089, 498, 291, 2052, 4009], "temperature": 0.0, "avg_logprob": -0.2119567454362116, "compression_ratio": 1.6816608996539792, "no_speech_prob": 6.1441442085197195e-06}, {"id": 949, "seek": 433928, "start": 4339.28, "end": 4342.92, "text": " You can jump straight to the source code, right?", "tokens": [509, 393, 3012, 2997, 281, 264, 4009, 3089, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.12361121900153882, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.459373038414924e-06}, {"id": 950, "seek": 433928, "start": 4342.92, "end": 4347.759999999999, "text": " So here is the plot top losses and this is also a great way to find out", "tokens": [407, 510, 307, 264, 7542, 1192, 15352, 293, 341, 307, 611, 257, 869, 636, 281, 915, 484], "temperature": 0.0, "avg_logprob": -0.12361121900153882, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.459373038414924e-06}, {"id": 951, "seek": 433928, "start": 4349.48, "end": 4356.08, "text": " How to use the fast AI library because every line of code here nearly every line of code is calling stuff in the fast AI library", "tokens": [1012, 281, 764, 264, 2370, 7318, 6405, 570, 633, 1622, 295, 3089, 510, 6217, 633, 1622, 295, 3089, 307, 5141, 1507, 294, 264, 2370, 7318, 6405], "temperature": 0.0, "avg_logprob": -0.12361121900153882, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.459373038414924e-06}, {"id": 952, "seek": 433928, "start": 4356.8, "end": 4360.16, "text": " Okay, so don't be afraid to look at the source code", "tokens": [1033, 11, 370, 500, 380, 312, 4638, 281, 574, 412, 264, 4009, 3089], "temperature": 0.0, "avg_logprob": -0.12361121900153882, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.459373038414924e-06}, {"id": 953, "seek": 433928, "start": 4362.32, "end": 4366.08, "text": " I've got another really cool trick about the documentation that you're going to see a little bit later", "tokens": [286, 600, 658, 1071, 534, 1627, 4282, 466, 264, 14333, 300, 291, 434, 516, 281, 536, 257, 707, 857, 1780], "temperature": 0.0, "avg_logprob": -0.12361121900153882, "compression_ratio": 1.7046413502109705, "no_speech_prob": 1.459373038414924e-06}, {"id": 954, "seek": 436608, "start": 4366.08, "end": 4368.44, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.18543311924610323, "compression_ratio": 1.6771653543307086, "no_speech_prob": 6.438968739530537e-06}, {"id": 955, "seek": 436608, "start": 4368.44, "end": 4374.92, "text": " So that's how we can look at these top losses and these are perhaps the most important image classification", "tokens": [407, 300, 311, 577, 321, 393, 574, 412, 613, 1192, 15352, 293, 613, 366, 4317, 264, 881, 1021, 3256, 21538], "temperature": 0.0, "avg_logprob": -0.18543311924610323, "compression_ratio": 1.6771653543307086, "no_speech_prob": 6.438968739530537e-06}, {"id": 956, "seek": 436608, "start": 4375.5599999999995, "end": 4379.0199999999995, "text": " Interpretation tool that we have because it lets us see", "tokens": [5751, 6629, 399, 2290, 300, 321, 362, 570, 309, 6653, 505, 536], "temperature": 0.0, "avg_logprob": -0.18543311924610323, "compression_ratio": 1.6771653543307086, "no_speech_prob": 6.438968739530537e-06}, {"id": 957, "seek": 436608, "start": 4379.68, "end": 4381.96, "text": " What are we getting wrong and quite often?", "tokens": [708, 366, 321, 1242, 2085, 293, 1596, 2049, 30], "temperature": 0.0, "avg_logprob": -0.18543311924610323, "compression_ratio": 1.6771653543307086, "no_speech_prob": 6.438968739530537e-06}, {"id": 958, "seek": 436608, "start": 4382.5599999999995, "end": 4388.72, "text": " Like in this case if you're a dog and cat expert you'll realize that the things that's getting wrong", "tokens": [1743, 294, 341, 1389, 498, 291, 434, 257, 3000, 293, 3857, 5844, 291, 603, 4325, 300, 264, 721, 300, 311, 1242, 2085], "temperature": 0.0, "avg_logprob": -0.18543311924610323, "compression_ratio": 1.6771653543307086, "no_speech_prob": 6.438968739530537e-06}, {"id": 959, "seek": 438872, "start": 4388.72, "end": 4395.6, "text": " Are breeds that are actually very difficult to tell apart and you'd be able to look at these and say oh I can see why?", "tokens": [2014, 41609, 300, 366, 767, 588, 2252, 281, 980, 4936, 293, 291, 1116, 312, 1075, 281, 574, 412, 613, 293, 584, 1954, 286, 393, 536, 983, 30], "temperature": 0.0, "avg_logprob": -0.17064290518289085, "compression_ratio": 1.5775862068965518, "no_speech_prob": 2.3687928205617936e-06}, {"id": 960, "seek": 438872, "start": 4395.740000000001, "end": 4397.740000000001, "text": " They've got this one wrong", "tokens": [814, 600, 658, 341, 472, 2085], "temperature": 0.0, "avg_logprob": -0.17064290518289085, "compression_ratio": 1.5775862068965518, "no_speech_prob": 2.3687928205617936e-06}, {"id": 961, "seek": 438872, "start": 4399.12, "end": 4401.12, "text": " So this is a really useful tool", "tokens": [407, 341, 307, 257, 534, 4420, 2290], "temperature": 0.0, "avg_logprob": -0.17064290518289085, "compression_ratio": 1.5775862068965518, "no_speech_prob": 2.3687928205617936e-06}, {"id": 962, "seek": 438872, "start": 4401.4800000000005, "end": 4408.54, "text": " Another useful tool kind of is to use them in quarter confusion matrix, which basically shows you for every actual", "tokens": [3996, 4420, 2290, 733, 295, 307, 281, 764, 552, 294, 6555, 15075, 8141, 11, 597, 1936, 3110, 291, 337, 633, 3539], "temperature": 0.0, "avg_logprob": -0.17064290518289085, "compression_ratio": 1.5775862068965518, "no_speech_prob": 2.3687928205617936e-06}, {"id": 963, "seek": 438872, "start": 4409.16, "end": 4414.0, "text": " Type of dog or cat how many times was it predicted to be that dog or cat?", "tokens": [15576, 295, 3000, 420, 3857, 577, 867, 1413, 390, 309, 19147, 281, 312, 300, 3000, 420, 3857, 30], "temperature": 0.0, "avg_logprob": -0.17064290518289085, "compression_ratio": 1.5775862068965518, "no_speech_prob": 2.3687928205617936e-06}, {"id": 964, "seek": 441400, "start": 4414.0, "end": 4418.7, "text": " But unfortunately in this case because it's so accurate this diagonal basically says", "tokens": [583, 7015, 294, 341, 1389, 570, 309, 311, 370, 8559, 341, 21539, 1936, 1619], "temperature": 0.0, "avg_logprob": -0.1636023298602238, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.594309186562896e-06}, {"id": 965, "seek": 441400, "start": 4418.7, "end": 4423.44, "text": " Oh, it's pretty much right all the time and you can see there's some slightly darker ones like a five here", "tokens": [876, 11, 309, 311, 1238, 709, 558, 439, 264, 565, 293, 291, 393, 536, 456, 311, 512, 4748, 12741, 2306, 411, 257, 1732, 510], "temperature": 0.0, "avg_logprob": -0.1636023298602238, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.594309186562896e-06}, {"id": 966, "seek": 441400, "start": 4423.44, "end": 4426.28, "text": " But it's really hard to read exactly what that combination is", "tokens": [583, 309, 311, 534, 1152, 281, 1401, 2293, 437, 300, 6562, 307], "temperature": 0.0, "avg_logprob": -0.1636023298602238, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.594309186562896e-06}, {"id": 967, "seek": 441400, "start": 4426.44, "end": 4432.52, "text": " So what I suggest you use is instead of if you've got lots of classes don't use a classification confusion matrix", "tokens": [407, 437, 286, 3402, 291, 764, 307, 2602, 295, 498, 291, 600, 658, 3195, 295, 5359, 500, 380, 764, 257, 21538, 15075, 8141], "temperature": 0.0, "avg_logprob": -0.1636023298602238, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.594309186562896e-06}, {"id": 968, "seek": 441400, "start": 4432.76, "end": 4439.08, "text": " But this is my favorite named function in fast AI. I'm very proud of this you can call most confused", "tokens": [583, 341, 307, 452, 2954, 4926, 2445, 294, 2370, 7318, 13, 286, 478, 588, 4570, 295, 341, 291, 393, 818, 881, 9019], "temperature": 0.0, "avg_logprob": -0.1636023298602238, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.594309186562896e-06}, {"id": 969, "seek": 443908, "start": 4439.08, "end": 4444.96, "text": " And most confused will simply grab out of the confusion matrix the particular", "tokens": [400, 881, 9019, 486, 2935, 4444, 484, 295, 264, 15075, 8141, 264, 1729], "temperature": 0.0, "avg_logprob": -0.2188436350691209, "compression_ratio": 1.8884758364312269, "no_speech_prob": 5.422168214863632e-06}, {"id": 970, "seek": 443908, "start": 4445.64, "end": 4449.48, "text": " Combinations have predicted an actual that got wrong the most often", "tokens": [25939, 10325, 362, 19147, 364, 3539, 300, 658, 2085, 264, 881, 2049], "temperature": 0.0, "avg_logprob": -0.2188436350691209, "compression_ratio": 1.8884758364312269, "no_speech_prob": 5.422168214863632e-06}, {"id": 971, "seek": 443908, "start": 4450.12, "end": 4456.08, "text": " so in this case the Staffordshire ballteria was what it should have predicted and instead it predicted an", "tokens": [370, 294, 341, 1389, 264, 16440, 765, 22294, 2594, 391, 654, 390, 437, 309, 820, 362, 19147, 293, 2602, 309, 19147, 364], "temperature": 0.0, "avg_logprob": -0.2188436350691209, "compression_ratio": 1.8884758364312269, "no_speech_prob": 5.422168214863632e-06}, {"id": 972, "seek": 443908, "start": 4456.48, "end": 4461.84, "text": " American pit bull terrier and so forth it should have predicted a Siamese and actually predicted boom and that happened four times", "tokens": [2665, 10147, 4693, 1796, 7326, 293, 370, 5220, 309, 820, 362, 19147, 257, 318, 2918, 1130, 293, 767, 19147, 9351, 293, 300, 2011, 1451, 1413], "temperature": 0.0, "avg_logprob": -0.2188436350691209, "compression_ratio": 1.8884758364312269, "no_speech_prob": 5.422168214863632e-06}, {"id": 973, "seek": 443908, "start": 4462.04, "end": 4464.08, "text": " This particular combination happened six times", "tokens": [639, 1729, 6562, 2011, 2309, 1413], "temperature": 0.0, "avg_logprob": -0.2188436350691209, "compression_ratio": 1.8884758364312269, "no_speech_prob": 5.422168214863632e-06}, {"id": 974, "seek": 443908, "start": 4464.08, "end": 4467.26, "text": " so this is again a very useful thing because you can look and you can say like", "tokens": [370, 341, 307, 797, 257, 588, 4420, 551, 570, 291, 393, 574, 293, 291, 393, 584, 411], "temperature": 0.0, "avg_logprob": -0.2188436350691209, "compression_ratio": 1.8884758364312269, "no_speech_prob": 5.422168214863632e-06}, {"id": 975, "seek": 446726, "start": 4467.26, "end": 4473.400000000001, "text": " From with my domain expertise does it make sense that that would be something that was confused about it", "tokens": [3358, 365, 452, 9274, 11769, 775, 309, 652, 2020, 300, 300, 576, 312, 746, 300, 390, 9019, 466, 309], "temperature": 0.0, "avg_logprob": -0.21184215730833775, "compression_ratio": 1.7322175732217573, "no_speech_prob": 8.664585038786754e-06}, {"id": 976, "seek": 446726, "start": 4473.400000000001, "end": 4476.820000000001, "text": " So these are some of the kinds of tools you can use to look at the output", "tokens": [407, 613, 366, 512, 295, 264, 3685, 295, 3873, 291, 393, 764, 281, 574, 412, 264, 5598], "temperature": 0.0, "avg_logprob": -0.21184215730833775, "compression_ratio": 1.7322175732217573, "no_speech_prob": 8.664585038786754e-06}, {"id": 977, "seek": 446726, "start": 4478.34, "end": 4480.34, "text": " Let's pick our model better", "tokens": [961, 311, 1888, 527, 2316, 1101], "temperature": 0.0, "avg_logprob": -0.21184215730833775, "compression_ratio": 1.7322175732217573, "no_speech_prob": 8.664585038786754e-06}, {"id": 978, "seek": 446726, "start": 4480.46, "end": 4485.1, "text": " So how do we make the bottle better? We can make it better using fine-tuning", "tokens": [407, 577, 360, 321, 652, 264, 7817, 1101, 30, 492, 393, 652, 309, 1101, 1228, 2489, 12, 83, 37726], "temperature": 0.0, "avg_logprob": -0.21184215730833775, "compression_ratio": 1.7322175732217573, "no_speech_prob": 8.664585038786754e-06}, {"id": 979, "seek": 446726, "start": 4486.02, "end": 4487.900000000001, "text": " So far we fitted", "tokens": [407, 1400, 321, 26321], "temperature": 0.0, "avg_logprob": -0.21184215730833775, "compression_ratio": 1.7322175732217573, "no_speech_prob": 8.664585038786754e-06}, {"id": 980, "seek": 446726, "start": 4487.900000000001, "end": 4494.38, "text": " For a box and it ran pretty quickly and the reason it ran pretty quickly is that there was a little trick we used", "tokens": [1171, 257, 2424, 293, 309, 5872, 1238, 2661, 293, 264, 1778, 309, 5872, 1238, 2661, 307, 300, 456, 390, 257, 707, 4282, 321, 1143], "temperature": 0.0, "avg_logprob": -0.21184215730833775, "compression_ratio": 1.7322175732217573, "no_speech_prob": 8.664585038786754e-06}, {"id": 981, "seek": 449438, "start": 4494.38, "end": 4498.4800000000005, "text": " These deep learning models these compositional networks they have many layers", "tokens": [1981, 2452, 2539, 5245, 613, 10199, 2628, 9590, 436, 362, 867, 7914], "temperature": 0.0, "avg_logprob": -0.2481509273492017, "compression_ratio": 1.852, "no_speech_prob": 6.240840320970165e-06}, {"id": 982, "seek": 449438, "start": 4498.66, "end": 4502.62, "text": " We'll learn a lot about exactly what layers are but for now just know it goes through a computer", "tokens": [492, 603, 1466, 257, 688, 466, 2293, 437, 7914, 366, 457, 337, 586, 445, 458, 309, 1709, 807, 257, 3820], "temperature": 0.0, "avg_logprob": -0.2481509273492017, "compression_ratio": 1.852, "no_speech_prob": 6.240840320970165e-06}, {"id": 983, "seek": 449438, "start": 4503.26, "end": 4505.26, "text": " computation or computation or computation or computation", "tokens": [24903, 420, 24903, 420, 24903, 420, 24903], "temperature": 0.0, "avg_logprob": -0.2481509273492017, "compression_ratio": 1.852, "no_speech_prob": 6.240840320970165e-06}, {"id": 984, "seek": 449438, "start": 4506.86, "end": 4512.02, "text": " What we did was we added a few extra layers to the end and we only trained those", "tokens": [708, 321, 630, 390, 321, 3869, 257, 1326, 2857, 7914, 281, 264, 917, 293, 321, 787, 8895, 729], "temperature": 0.0, "avg_logprob": -0.2481509273492017, "compression_ratio": 1.852, "no_speech_prob": 6.240840320970165e-06}, {"id": 985, "seek": 449438, "start": 4512.1, "end": 4516.22, "text": " We basically left most of the model exactly as it was so that's really fast", "tokens": [492, 1936, 1411, 881, 295, 264, 2316, 2293, 382, 309, 390, 370, 300, 311, 534, 2370], "temperature": 0.0, "avg_logprob": -0.2481509273492017, "compression_ratio": 1.852, "no_speech_prob": 6.240840320970165e-06}, {"id": 986, "seek": 449438, "start": 4516.86, "end": 4521.1, "text": " And if we try to build a model of something that's similar to the original", "tokens": [400, 498, 321, 853, 281, 1322, 257, 2316, 295, 746, 300, 311, 2531, 281, 264, 3380], "temperature": 0.0, "avg_logprob": -0.2481509273492017, "compression_ratio": 1.852, "no_speech_prob": 6.240840320970165e-06}, {"id": 987, "seek": 452110, "start": 4521.1, "end": 4525.9400000000005, "text": " Pre trained model so in this case similar to the image net data that works pretty well", "tokens": [6001, 8895, 2316, 370, 294, 341, 1389, 2531, 281, 264, 3256, 2533, 1412, 300, 1985, 1238, 731], "temperature": 0.0, "avg_logprob": -0.20605076169504702, "compression_ratio": 1.6294820717131475, "no_speech_prob": 4.2892975216091145e-06}, {"id": 988, "seek": 452110, "start": 4526.820000000001, "end": 4531.26, "text": " But what we really want to do is actually go back and train the whole model", "tokens": [583, 437, 321, 534, 528, 281, 360, 307, 767, 352, 646, 293, 3847, 264, 1379, 2316], "temperature": 0.0, "avg_logprob": -0.20605076169504702, "compression_ratio": 1.6294820717131475, "no_speech_prob": 4.2892975216091145e-06}, {"id": 989, "seek": 452110, "start": 4531.34, "end": 4536.54, "text": " So this is why we pretty much always use this two-stage process. So by default", "tokens": [407, 341, 307, 983, 321, 1238, 709, 1009, 764, 341, 732, 12, 17882, 1399, 13, 407, 538, 7576], "temperature": 0.0, "avg_logprob": -0.20605076169504702, "compression_ratio": 1.6294820717131475, "no_speech_prob": 4.2892975216091145e-06}, {"id": 990, "seek": 452110, "start": 4538.34, "end": 4542.46, "text": " When we call fit will fit one cycle on a confowner", "tokens": [1133, 321, 818, 3318, 486, 3318, 472, 6586, 322, 257, 1497, 34679], "temperature": 0.0, "avg_logprob": -0.20605076169504702, "compression_ratio": 1.6294820717131475, "no_speech_prob": 4.2892975216091145e-06}, {"id": 991, "seek": 452110, "start": 4542.46, "end": 4549.22, "text": " It'll just fine-tune these few extra layers added to the end and it'll run very fast. It'll basically never over fit", "tokens": [467, 603, 445, 2489, 12, 83, 2613, 613, 1326, 2857, 7914, 3869, 281, 264, 917, 293, 309, 603, 1190, 588, 2370, 13, 467, 603, 1936, 1128, 670, 3318], "temperature": 0.0, "avg_logprob": -0.20605076169504702, "compression_ratio": 1.6294820717131475, "no_speech_prob": 4.2892975216091145e-06}, {"id": 992, "seek": 454922, "start": 4549.22, "end": 4556.5, "text": " But to really get it good you have to call unfreeze and unfreeze is the thing that says please train", "tokens": [583, 281, 534, 483, 309, 665, 291, 362, 281, 818, 3971, 701, 1381, 293, 3971, 701, 1381, 307, 264, 551, 300, 1619, 1767, 3847], "temperature": 0.0, "avg_logprob": -0.18872794238003818, "compression_ratio": 1.5458937198067633, "no_speech_prob": 3.905464836861938e-06}, {"id": 993, "seek": 454922, "start": 4557.1, "end": 4559.1, "text": " the whole model and", "tokens": [264, 1379, 2316, 293], "temperature": 0.0, "avg_logprob": -0.18872794238003818, "compression_ratio": 1.5458937198067633, "no_speech_prob": 3.905464836861938e-06}, {"id": 994, "seek": 454922, "start": 4559.780000000001, "end": 4561.9400000000005, "text": " then I can call fit one cycle again and", "tokens": [550, 286, 393, 818, 3318, 472, 6586, 797, 293], "temperature": 0.0, "avg_logprob": -0.18872794238003818, "compression_ratio": 1.5458937198067633, "no_speech_prob": 3.905464836861938e-06}, {"id": 995, "seek": 454922, "start": 4563.3, "end": 4564.42, "text": " Uh-oh", "tokens": [4019, 12, 1445], "temperature": 0.0, "avg_logprob": -0.18872794238003818, "compression_ratio": 1.5458937198067633, "no_speech_prob": 3.905464836861938e-06}, {"id": 996, "seek": 454922, "start": 4564.42, "end": 4567.22, "text": " The error got much worse", "tokens": [440, 6713, 658, 709, 5324], "temperature": 0.0, "avg_logprob": -0.18872794238003818, "compression_ratio": 1.5458937198067633, "no_speech_prob": 3.905464836861938e-06}, {"id": 997, "seek": 454922, "start": 4568.42, "end": 4570.22, "text": " Okay, why?", "tokens": [1033, 11, 983, 30], "temperature": 0.0, "avg_logprob": -0.18872794238003818, "compression_ratio": 1.5458937198067633, "no_speech_prob": 3.905464836861938e-06}, {"id": 998, "seek": 454922, "start": 4570.22, "end": 4577.72, "text": " In order to understand why we're actually going to have to learn more about exactly what's going on behind the scenes", "tokens": [682, 1668, 281, 1223, 983, 321, 434, 767, 516, 281, 362, 281, 1466, 544, 466, 2293, 437, 311, 516, 322, 2261, 264, 8026], "temperature": 0.0, "avg_logprob": -0.18872794238003818, "compression_ratio": 1.5458937198067633, "no_speech_prob": 3.905464836861938e-06}, {"id": 999, "seek": 457772, "start": 4577.72, "end": 4583.92, "text": " So let's start out by trying to get an intuitive understanding of what's going on behind the scenes", "tokens": [407, 718, 311, 722, 484, 538, 1382, 281, 483, 364, 21769, 3701, 295, 437, 311, 516, 322, 2261, 264, 8026], "temperature": 0.0, "avg_logprob": -0.2516758388943142, "compression_ratio": 1.5672268907563025, "no_speech_prob": 1.2218893061799463e-05}, {"id": 1000, "seek": 457772, "start": 4583.92, "end": 4586.08, "text": " And again, we're going to do it by looking at pictures", "tokens": [400, 797, 11, 321, 434, 516, 281, 360, 309, 538, 1237, 412, 5242], "temperature": 0.0, "avg_logprob": -0.2516758388943142, "compression_ratio": 1.5672268907563025, "no_speech_prob": 1.2218893061799463e-05}, {"id": 1001, "seek": 457772, "start": 4588.12, "end": 4595.2, "text": " We're going to start with this picture these pictures come from a fantastic paper by Matt Zyler who nowadays is CEO of Clarify", "tokens": [492, 434, 516, 281, 722, 365, 341, 3036, 613, 5242, 808, 490, 257, 5456, 3035, 538, 7397, 1176, 88, 1918, 567, 13434, 307, 9282, 295, 28410, 2505], "temperature": 0.0, "avg_logprob": -0.2516758388943142, "compression_ratio": 1.5672268907563025, "no_speech_prob": 1.2218893061799463e-05}, {"id": 1002, "seek": 457772, "start": 4595.2, "end": 4597.2, "text": " Which is a very successful", "tokens": [3013, 307, 257, 588, 4406], "temperature": 0.0, "avg_logprob": -0.2516758388943142, "compression_ratio": 1.5672268907563025, "no_speech_prob": 1.2218893061799463e-05}, {"id": 1003, "seek": 457772, "start": 4597.2, "end": 4599.2, "text": " computer vision startup and", "tokens": [3820, 5201, 18578, 293], "temperature": 0.0, "avg_logprob": -0.2516758388943142, "compression_ratio": 1.5672268907563025, "no_speech_prob": 1.2218893061799463e-05}, {"id": 1004, "seek": 457772, "start": 4599.72, "end": 4602.16, "text": " His supervisor of his PhD Rob Fergus", "tokens": [2812, 24610, 295, 702, 14476, 5424, 36790], "temperature": 0.0, "avg_logprob": -0.2516758388943142, "compression_ratio": 1.5672268907563025, "no_speech_prob": 1.2218893061799463e-05}, {"id": 1005, "seek": 460216, "start": 4602.16, "end": 4608.24, "text": " And they created a paper showing how you can visualize the layers of a convolutional neural network", "tokens": [400, 436, 2942, 257, 3035, 4099, 577, 291, 393, 23273, 264, 7914, 295, 257, 45216, 304, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.2072471917844286, "compression_ratio": 1.8359375, "no_speech_prob": 7.527874913648702e-06}, {"id": 1006, "seek": 460216, "start": 4608.68, "end": 4613.139999999999, "text": " So a convolutional neural network will learn mathematically about what the layers are shortly", "tokens": [407, 257, 45216, 304, 18161, 3209, 486, 1466, 44003, 466, 437, 264, 7914, 366, 13392], "temperature": 0.0, "avg_logprob": -0.2072471917844286, "compression_ratio": 1.8359375, "no_speech_prob": 7.527874913648702e-06}, {"id": 1007, "seek": 460216, "start": 4613.139999999999, "end": 4620.28, "text": " But the basic idea is that your red green and blue pixel values that are numbers from naught to 255 go into a simple computation", "tokens": [583, 264, 3875, 1558, 307, 300, 428, 2182, 3092, 293, 3344, 19261, 4190, 300, 366, 3547, 490, 13138, 281, 3552, 20, 352, 666, 257, 2199, 24903], "temperature": 0.0, "avg_logprob": -0.2072471917844286, "compression_ratio": 1.8359375, "no_speech_prob": 7.527874913648702e-06}, {"id": 1008, "seek": 460216, "start": 4621.36, "end": 4625.96, "text": " The first layer and something comes out of that and then the result of that goes into a second layer", "tokens": [440, 700, 4583, 293, 746, 1487, 484, 295, 300, 293, 550, 264, 1874, 295, 300, 1709, 666, 257, 1150, 4583], "temperature": 0.0, "avg_logprob": -0.2072471917844286, "compression_ratio": 1.8359375, "no_speech_prob": 7.527874913648702e-06}, {"id": 1009, "seek": 460216, "start": 4625.96, "end": 4628.5599999999995, "text": " so that goes to a third layer and so forth and", "tokens": [370, 300, 1709, 281, 257, 2636, 4583, 293, 370, 5220, 293], "temperature": 0.0, "avg_logprob": -0.2072471917844286, "compression_ratio": 1.8359375, "no_speech_prob": 7.527874913648702e-06}, {"id": 1010, "seek": 462856, "start": 4628.56, "end": 4634.84, "text": " There can be up to a thousand layers of a neural network", "tokens": [821, 393, 312, 493, 281, 257, 4714, 7914, 295, 257, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.19126888116200766, "compression_ratio": 1.596, "no_speech_prob": 4.1573343878553715e-06}, {"id": 1011, "seek": 462856, "start": 4635.84, "end": 4640.0, "text": " Resnet 34 has 34 layers Resnet 50 has 50 layers", "tokens": [5015, 7129, 12790, 575, 12790, 7914, 5015, 7129, 2625, 575, 2625, 7914], "temperature": 0.0, "avg_logprob": -0.19126888116200766, "compression_ratio": 1.596, "no_speech_prob": 4.1573343878553715e-06}, {"id": 1012, "seek": 462856, "start": 4640.84, "end": 4647.22, "text": " But let's look at layer 1. There's this very simple computation. It's a convolution if you know what they are", "tokens": [583, 718, 311, 574, 412, 4583, 502, 13, 821, 311, 341, 588, 2199, 24903, 13, 467, 311, 257, 45216, 498, 291, 458, 437, 436, 366], "temperature": 0.0, "avg_logprob": -0.19126888116200766, "compression_ratio": 1.596, "no_speech_prob": 4.1573343878553715e-06}, {"id": 1013, "seek": 462856, "start": 4647.22, "end": 4649.22, "text": " We'll learn more about them shortly", "tokens": [492, 603, 1466, 544, 466, 552, 13392], "temperature": 0.0, "avg_logprob": -0.19126888116200766, "compression_ratio": 1.596, "no_speech_prob": 4.1573343878553715e-06}, {"id": 1014, "seek": 462856, "start": 4649.8, "end": 4651.8, "text": " What comes out of this first layer?", "tokens": [708, 1487, 484, 295, 341, 700, 4583, 30], "temperature": 0.0, "avg_logprob": -0.19126888116200766, "compression_ratio": 1.596, "no_speech_prob": 4.1573343878553715e-06}, {"id": 1015, "seek": 462856, "start": 4651.84, "end": 4657.400000000001, "text": " Well, we can actually visualize these specific coefficients the specific parameters by drawing them as a picture", "tokens": [1042, 11, 321, 393, 767, 23273, 613, 2685, 31994, 264, 2685, 9834, 538, 6316, 552, 382, 257, 3036], "temperature": 0.0, "avg_logprob": -0.19126888116200766, "compression_ratio": 1.596, "no_speech_prob": 4.1573343878553715e-06}, {"id": 1016, "seek": 465740, "start": 4657.4, "end": 4661.5599999999995, "text": " There's actually a few dozen of of them in the first layer", "tokens": [821, 311, 767, 257, 1326, 16654, 295, 295, 552, 294, 264, 700, 4583], "temperature": 0.0, "avg_logprob": -0.19328563048107789, "compression_ratio": 1.8445378151260505, "no_speech_prob": 6.240891707420815e-06}, {"id": 1017, "seek": 465740, "start": 4661.5599999999995, "end": 4664.32, "text": " So we won't draw all of them, but let's just look at nine at random", "tokens": [407, 321, 1582, 380, 2642, 439, 295, 552, 11, 457, 718, 311, 445, 574, 412, 4949, 412, 4974], "temperature": 0.0, "avg_logprob": -0.19328563048107789, "compression_ratio": 1.8445378151260505, "no_speech_prob": 6.240891707420815e-06}, {"id": 1018, "seek": 465740, "start": 4664.639999999999, "end": 4671.339999999999, "text": " So here are nine examples of the actual coefficients from the first layer and so these operate on", "tokens": [407, 510, 366, 4949, 5110, 295, 264, 3539, 31994, 490, 264, 700, 4583, 293, 370, 613, 9651, 322], "temperature": 0.0, "avg_logprob": -0.19328563048107789, "compression_ratio": 1.8445378151260505, "no_speech_prob": 6.240891707420815e-06}, {"id": 1019, "seek": 465740, "start": 4671.879999999999, "end": 4674.2, "text": " groups of pixels that are next to each other and", "tokens": [3935, 295, 18668, 300, 366, 958, 281, 1184, 661, 293], "temperature": 0.0, "avg_logprob": -0.19328563048107789, "compression_ratio": 1.8445378151260505, "no_speech_prob": 6.240891707420815e-06}, {"id": 1020, "seek": 465740, "start": 4674.839999999999, "end": 4680.0, "text": " So this first one basically finds groups of pixels that have a little horizontal diagonal line in this direction", "tokens": [407, 341, 700, 472, 1936, 10704, 3935, 295, 18668, 300, 362, 257, 707, 12750, 21539, 1622, 294, 341, 3513], "temperature": 0.0, "avg_logprob": -0.19328563048107789, "compression_ratio": 1.8445378151260505, "no_speech_prob": 6.240891707420815e-06}, {"id": 1021, "seek": 465740, "start": 4680.04, "end": 4682.08, "text": " This one finds diagonal lines in the other direction", "tokens": [639, 472, 10704, 21539, 3876, 294, 264, 661, 3513], "temperature": 0.0, "avg_logprob": -0.19328563048107789, "compression_ratio": 1.8445378151260505, "no_speech_prob": 6.240891707420815e-06}, {"id": 1022, "seek": 468208, "start": 4682.08, "end": 4688.4, "text": " This line gradients that go from yellow to blue in this direction this one finds gradients that go from pink to green", "tokens": [639, 1622, 2771, 2448, 300, 352, 490, 5566, 281, 3344, 294, 341, 3513, 341, 472, 10704, 2771, 2448, 300, 352, 490, 7022, 281, 3092], "temperature": 0.0, "avg_logprob": -0.2318668758746275, "compression_ratio": 1.7733333333333334, "no_speech_prob": 4.42546843260061e-06}, {"id": 1023, "seek": 468208, "start": 4688.5599999999995, "end": 4692.12, "text": " In this direction and so forth. That's a very very simple", "tokens": [682, 341, 3513, 293, 370, 5220, 13, 663, 311, 257, 588, 588, 2199], "temperature": 0.0, "avg_logprob": -0.2318668758746275, "compression_ratio": 1.7733333333333334, "no_speech_prob": 4.42546843260061e-06}, {"id": 1024, "seek": 468208, "start": 4692.92, "end": 4694.16, "text": " little", "tokens": [707], "temperature": 0.0, "avg_logprob": -0.2318668758746275, "compression_ratio": 1.7733333333333334, "no_speech_prob": 4.42546843260061e-06}, {"id": 1025, "seek": 468208, "start": 4694.16, "end": 4695.5199999999995, "text": " filters", "tokens": [15995], "temperature": 0.0, "avg_logprob": -0.2318668758746275, "compression_ratio": 1.7733333333333334, "no_speech_prob": 4.42546843260061e-06}, {"id": 1026, "seek": 468208, "start": 4695.5199999999995, "end": 4699.5599999999995, "text": " That's layer one of a image net pre-trained convolutional neural net", "tokens": [663, 311, 4583, 472, 295, 257, 3256, 2533, 659, 12, 17227, 2001, 45216, 304, 18161, 2533], "temperature": 0.0, "avg_logprob": -0.2318668758746275, "compression_ratio": 1.7733333333333334, "no_speech_prob": 4.42546843260061e-06}, {"id": 1027, "seek": 468208, "start": 4701.44, "end": 4703.0, "text": " Layer two", "tokens": [35166, 732], "temperature": 0.0, "avg_logprob": -0.2318668758746275, "compression_ratio": 1.7733333333333334, "no_speech_prob": 4.42546843260061e-06}, {"id": 1028, "seek": 470300, "start": 4703.0, "end": 4712.2, "text": " Takes the results of those filters and does a second layer of computation and it allows it to create so here are nine examples of", "tokens": [44347, 264, 3542, 295, 729, 15995, 293, 775, 257, 1150, 4583, 295, 24903, 293, 309, 4045, 309, 281, 1884, 370, 510, 366, 4949, 5110, 295], "temperature": 0.0, "avg_logprob": -0.18380362054576044, "compression_ratio": 1.8818181818181818, "no_speech_prob": 7.766914677631576e-06}, {"id": 1029, "seek": 470300, "start": 4712.2, "end": 4719.52, "text": " A way of visualizing this one of the second layer features and you can see it's basically learned to create something that looks for", "tokens": [316, 636, 295, 5056, 3319, 341, 472, 295, 264, 1150, 4583, 4122, 293, 291, 393, 536, 309, 311, 1936, 3264, 281, 1884, 746, 300, 1542, 337], "temperature": 0.0, "avg_logprob": -0.18380362054576044, "compression_ratio": 1.8818181818181818, "no_speech_prob": 7.766914677631576e-06}, {"id": 1030, "seek": 470300, "start": 4720.92, "end": 4722.92, "text": " Corners top left corners and", "tokens": [21590, 433, 1192, 1411, 12413, 293], "temperature": 0.0, "avg_logprob": -0.18380362054576044, "compression_ratio": 1.8818181818181818, "no_speech_prob": 7.766914677631576e-06}, {"id": 1031, "seek": 470300, "start": 4723.56, "end": 4726.88, "text": " This one is learned to find things that find right hand curves", "tokens": [639, 472, 307, 3264, 281, 915, 721, 300, 915, 558, 1011, 19490], "temperature": 0.0, "avg_logprob": -0.18380362054576044, "compression_ratio": 1.8818181818181818, "no_speech_prob": 7.766914677631576e-06}, {"id": 1032, "seek": 470300, "start": 4727.16, "end": 4729.9, "text": " This one is learned to find things that find little circles", "tokens": [639, 472, 307, 3264, 281, 915, 721, 300, 915, 707, 13040], "temperature": 0.0, "avg_logprob": -0.18380362054576044, "compression_ratio": 1.8818181818181818, "no_speech_prob": 7.766914677631576e-06}, {"id": 1033, "seek": 472990, "start": 4729.9, "end": 4734.9, "text": " All right, so you can see how layer two like this is the easiest way to see it in layer one", "tokens": [1057, 558, 11, 370, 291, 393, 536, 577, 4583, 732, 411, 341, 307, 264, 12889, 636, 281, 536, 309, 294, 4583, 472], "temperature": 0.0, "avg_logprob": -0.15921086336659118, "compression_ratio": 1.8150943396226416, "no_speech_prob": 2.8130098144174553e-06}, {"id": 1034, "seek": 472990, "start": 4734.9, "end": 4740.74, "text": " We have things that can find just one line and layer two we can find things that have two lines joined up or one line", "tokens": [492, 362, 721, 300, 393, 915, 445, 472, 1622, 293, 4583, 732, 321, 393, 915, 721, 300, 362, 732, 3876, 6869, 493, 420, 472, 1622], "temperature": 0.0, "avg_logprob": -0.15921086336659118, "compression_ratio": 1.8150943396226416, "no_speech_prob": 2.8130098144174553e-06}, {"id": 1035, "seek": 472990, "start": 4740.74, "end": 4742.0599999999995, "text": " repeated", "tokens": [10477], "temperature": 0.0, "avg_logprob": -0.15921086336659118, "compression_ratio": 1.8150943396226416, "no_speech_prob": 2.8130098144174553e-06}, {"id": 1036, "seek": 472990, "start": 4742.0599999999995, "end": 4744.0599999999995, "text": " If you then look over here", "tokens": [759, 291, 550, 574, 670, 510], "temperature": 0.0, "avg_logprob": -0.15921086336659118, "compression_ratio": 1.8150943396226416, "no_speech_prob": 2.8130098144174553e-06}, {"id": 1037, "seek": 472990, "start": 4744.099999999999, "end": 4750.5599999999995, "text": " These nine show you nine examples of actual bits of actual photos that activated this filter a lot", "tokens": [1981, 4949, 855, 291, 4949, 5110, 295, 3539, 9239, 295, 3539, 5787, 300, 18157, 341, 6608, 257, 688], "temperature": 0.0, "avg_logprob": -0.15921086336659118, "compression_ratio": 1.8150943396226416, "no_speech_prob": 2.8130098144174553e-06}, {"id": 1038, "seek": 472990, "start": 4750.7, "end": 4752.7, "text": " that's another words this little bit of", "tokens": [300, 311, 1071, 2283, 341, 707, 857, 295], "temperature": 0.0, "avg_logprob": -0.15921086336659118, "compression_ratio": 1.8150943396226416, "no_speech_prob": 2.8130098144174553e-06}, {"id": 1039, "seek": 475270, "start": 4752.7, "end": 4759.26, "text": " Function math function here was good at finding these kind of window corners and stuff like that", "tokens": [11166, 882, 5221, 2445, 510, 390, 665, 412, 5006, 613, 733, 295, 4910, 12413, 293, 1507, 411, 300], "temperature": 0.0, "avg_logprob": -0.20546815833266902, "compression_ratio": 1.788, "no_speech_prob": 1.7061769312931574e-06}, {"id": 1040, "seek": 475270, "start": 4760.099999999999, "end": 4764.26, "text": " This little circle E1 was very good at finding bits of photos that have circles", "tokens": [639, 707, 6329, 462, 16, 390, 588, 665, 412, 5006, 9239, 295, 5787, 300, 362, 13040], "temperature": 0.0, "avg_logprob": -0.20546815833266902, "compression_ratio": 1.788, "no_speech_prob": 1.7061769312931574e-06}, {"id": 1041, "seek": 475270, "start": 4764.62, "end": 4766.62, "text": " Okay, so this is the kind of stuff", "tokens": [1033, 11, 370, 341, 307, 264, 733, 295, 1507], "temperature": 0.0, "avg_logprob": -0.20546815833266902, "compression_ratio": 1.788, "no_speech_prob": 1.7061769312931574e-06}, {"id": 1042, "seek": 475270, "start": 4766.62, "end": 4772.099999999999, "text": " You've got to get a really good intuitive understanding for us likely the start of my neural nets gonna find simple", "tokens": [509, 600, 658, 281, 483, 257, 534, 665, 21769, 3701, 337, 505, 3700, 264, 722, 295, 452, 18161, 36170, 799, 915, 2199], "temperature": 0.0, "avg_logprob": -0.20546815833266902, "compression_ratio": 1.788, "no_speech_prob": 1.7061769312931574e-06}, {"id": 1043, "seek": 475270, "start": 4772.42, "end": 4778.84, "text": " Very simple gradients lines the second layer can find very simple shapes the third layer can find combinations of those", "tokens": [4372, 2199, 2771, 2448, 3876, 264, 1150, 4583, 393, 915, 588, 2199, 10854, 264, 2636, 4583, 393, 915, 21267, 295, 729], "temperature": 0.0, "avg_logprob": -0.20546815833266902, "compression_ratio": 1.788, "no_speech_prob": 1.7061769312931574e-06}, {"id": 1044, "seek": 477884, "start": 4778.84, "end": 4787.8, "text": " So now we can find repeating patterns of two-dimensional objects or we can find kind of things that joins that join together", "tokens": [407, 586, 321, 393, 915, 18617, 8294, 295, 732, 12, 18759, 6565, 420, 321, 393, 915, 733, 295, 721, 300, 24397, 300, 3917, 1214], "temperature": 0.0, "avg_logprob": -0.20853328704833984, "compression_ratio": 1.7217391304347827, "no_speech_prob": 3.6119636206422e-06}, {"id": 1045, "seek": 477884, "start": 4789.400000000001, "end": 4793.64, "text": " Or we can find well, what are these things? Well, let's find out. What is this?", "tokens": [1610, 321, 393, 915, 731, 11, 437, 366, 613, 721, 30, 1042, 11, 718, 311, 915, 484, 13, 708, 307, 341, 30], "temperature": 0.0, "avg_logprob": -0.20853328704833984, "compression_ratio": 1.7217391304347827, "no_speech_prob": 3.6119636206422e-06}, {"id": 1046, "seek": 477884, "start": 4793.64, "end": 4797.52, "text": " Let's go and have a look at some bits of picture that activated this one highly. Oh", "tokens": [961, 311, 352, 293, 362, 257, 574, 412, 512, 9239, 295, 3036, 300, 18157, 341, 472, 5405, 13, 876], "temperature": 0.0, "avg_logprob": -0.20853328704833984, "compression_ratio": 1.7217391304347827, "no_speech_prob": 3.6119636206422e-06}, {"id": 1047, "seek": 477884, "start": 4799.16, "end": 4805.32, "text": " Mainly they're bits of text although sometimes windows so it seems to be able to find kind of like repeated", "tokens": [47468, 436, 434, 9239, 295, 2487, 4878, 2171, 9309, 370, 309, 2544, 281, 312, 1075, 281, 915, 733, 295, 411, 10477], "temperature": 0.0, "avg_logprob": -0.20853328704833984, "compression_ratio": 1.7217391304347827, "no_speech_prob": 3.6119636206422e-06}, {"id": 1048, "seek": 480532, "start": 4805.32, "end": 4809.719999999999, "text": " horizontal patterns and this one here says we have to find kind of", "tokens": [12750, 8294, 293, 341, 472, 510, 1619, 321, 362, 281, 915, 733, 295], "temperature": 0.0, "avg_logprob": -0.20892384711732256, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.425460701895645e-06}, {"id": 1049, "seek": 480532, "start": 4810.5199999999995, "end": 4813.24, "text": " Edges of fluffy or flowery things", "tokens": [3977, 2880, 295, 22778, 420, 8617, 88, 721], "temperature": 0.0, "avg_logprob": -0.20892384711732256, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.425460701895645e-06}, {"id": 1050, "seek": 480532, "start": 4813.84, "end": 4821.16, "text": " This one here is kind of finding geometric patterns. So layer 3 was able to take all the stuff from layer 2 and combine them together", "tokens": [639, 472, 510, 307, 733, 295, 5006, 33246, 8294, 13, 407, 4583, 805, 390, 1075, 281, 747, 439, 264, 1507, 490, 4583, 568, 293, 10432, 552, 1214], "temperature": 0.0, "avg_logprob": -0.20892384711732256, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.425460701895645e-06}, {"id": 1051, "seek": 480532, "start": 4822.32, "end": 4829.88, "text": " layer 4 can take all the stuff from layer 3 and combine them together by layer 4 we put something that can find dog faces and", "tokens": [4583, 1017, 393, 747, 439, 264, 1507, 490, 4583, 805, 293, 10432, 552, 1214, 538, 4583, 1017, 321, 829, 746, 300, 393, 915, 3000, 8475, 293], "temperature": 0.0, "avg_logprob": -0.20892384711732256, "compression_ratio": 1.8372093023255813, "no_speech_prob": 4.425460701895645e-06}, {"id": 1052, "seek": 482988, "start": 4829.88, "end": 4833.6, "text": " And let's see what else we've got here", "tokens": [400, 718, 311, 536, 437, 1646, 321, 600, 658, 510], "temperature": 0.0, "avg_logprob": -0.18607082586178833, "compression_ratio": 1.595959595959596, "no_speech_prob": 3.8449156818387564e-06}, {"id": 1053, "seek": 482988, "start": 4836.2, "end": 4838.5, "text": " Yeah, various kinds of oh here we are bird legs", "tokens": [865, 11, 3683, 3685, 295, 1954, 510, 321, 366, 5255, 5668], "temperature": 0.0, "avg_logprob": -0.18607082586178833, "compression_ratio": 1.595959595959596, "no_speech_prob": 3.8449156818387564e-06}, {"id": 1054, "seek": 482988, "start": 4840.0, "end": 4846.0, "text": " So you kind of get the idea and so by layer 5 we've got something that can find the eyeballs of birds and wizards or", "tokens": [407, 291, 733, 295, 483, 264, 1558, 293, 370, 538, 4583, 1025, 321, 600, 658, 746, 300, 393, 915, 264, 43758, 295, 9009, 293, 40808, 2287, 420], "temperature": 0.0, "avg_logprob": -0.18607082586178833, "compression_ratio": 1.595959595959596, "no_speech_prob": 3.8449156818387564e-06}, {"id": 1055, "seek": 482988, "start": 4847.400000000001, "end": 4853.12, "text": " Faces of particular breeds of dogs and so forth. So you can see how by the time you get to layer 34", "tokens": [479, 2116, 295, 1729, 41609, 295, 7197, 293, 370, 5220, 13, 407, 291, 393, 536, 577, 538, 264, 565, 291, 483, 281, 4583, 12790], "temperature": 0.0, "avg_logprob": -0.18607082586178833, "compression_ratio": 1.595959595959596, "no_speech_prob": 3.8449156818387564e-06}, {"id": 1056, "seek": 482988, "start": 4854.72, "end": 4856.72, "text": " You can find", "tokens": [509, 393, 915], "temperature": 0.0, "avg_logprob": -0.18607082586178833, "compression_ratio": 1.595959595959596, "no_speech_prob": 3.8449156818387564e-06}, {"id": 1057, "seek": 485672, "start": 4856.72, "end": 4860.280000000001, "text": " specific dog breeds and cat breeds, right? This is kind of how it works. So", "tokens": [2685, 3000, 41609, 293, 3857, 41609, 11, 558, 30, 639, 307, 733, 295, 577, 309, 1985, 13, 407], "temperature": 0.0, "avg_logprob": -0.1957322601088904, "compression_ratio": 1.7841726618705036, "no_speech_prob": 3.668840918180649e-06}, {"id": 1058, "seek": 485672, "start": 4861.320000000001, "end": 4863.320000000001, "text": " when we first", "tokens": [562, 321, 700], "temperature": 0.0, "avg_logprob": -0.1957322601088904, "compression_ratio": 1.7841726618705036, "no_speech_prob": 3.668840918180649e-06}, {"id": 1059, "seek": 485672, "start": 4863.4400000000005, "end": 4866.68, "text": " Trained when we first fine-tuned that pre-trained model", "tokens": [5403, 2001, 562, 321, 700, 2489, 12, 83, 43703, 300, 659, 12, 17227, 2001, 2316], "temperature": 0.0, "avg_logprob": -0.1957322601088904, "compression_ratio": 1.7841726618705036, "no_speech_prob": 3.668840918180649e-06}, {"id": 1060, "seek": 485672, "start": 4866.76, "end": 4873.18, "text": " We kept all of these layers that you've seen so far and we just trained a few more layers on top of all of those", "tokens": [492, 4305, 439, 295, 613, 7914, 300, 291, 600, 1612, 370, 1400, 293, 321, 445, 8895, 257, 1326, 544, 7914, 322, 1192, 295, 439, 295, 729], "temperature": 0.0, "avg_logprob": -0.1957322601088904, "compression_ratio": 1.7841726618705036, "no_speech_prob": 3.668840918180649e-06}, {"id": 1061, "seek": 485672, "start": 4873.4400000000005, "end": 4875.4400000000005, "text": " Sophisticated features that are already been created", "tokens": [18921, 3142, 770, 4122, 300, 366, 1217, 668, 2942], "temperature": 0.0, "avg_logprob": -0.1957322601088904, "compression_ratio": 1.7841726618705036, "no_speech_prob": 3.668840918180649e-06}, {"id": 1062, "seek": 485672, "start": 4875.56, "end": 4880.84, "text": " And so now we're fine-tuning we're going back and saying let's change all of these", "tokens": [400, 370, 586, 321, 434, 2489, 12, 83, 37726, 321, 434, 516, 646, 293, 1566, 718, 311, 1319, 439, 295, 613], "temperature": 0.0, "avg_logprob": -0.1957322601088904, "compression_ratio": 1.7841726618705036, "no_speech_prob": 3.668840918180649e-06}, {"id": 1063, "seek": 485672, "start": 4881.2, "end": 4885.6, "text": " We'll keep that we'll start with them where they are, right? But let's see if we can make them better", "tokens": [492, 603, 1066, 300, 321, 603, 722, 365, 552, 689, 436, 366, 11, 558, 30, 583, 718, 311, 536, 498, 321, 393, 652, 552, 1101], "temperature": 0.0, "avg_logprob": -0.1957322601088904, "compression_ratio": 1.7841726618705036, "no_speech_prob": 3.668840918180649e-06}, {"id": 1064, "seek": 488560, "start": 4885.6, "end": 4892.160000000001, "text": " Now it seems very unlikely that we can make these layer one features", "tokens": [823, 309, 2544, 588, 17518, 300, 321, 393, 652, 613, 4583, 472, 4122], "temperature": 0.0, "avg_logprob": -0.15155981205127858, "compression_ratio": 1.776061776061776, "no_speech_prob": 3.3405206067982363e-06}, {"id": 1065, "seek": 488560, "start": 4892.72, "end": 4896.6, "text": " Better like it's very unlikely that the kind of the definition of a diagonal line", "tokens": [15753, 411, 309, 311, 588, 17518, 300, 264, 733, 295, 264, 7123, 295, 257, 21539, 1622], "temperature": 0.0, "avg_logprob": -0.15155981205127858, "compression_ratio": 1.776061776061776, "no_speech_prob": 3.3405206067982363e-06}, {"id": 1066, "seek": 488560, "start": 4896.6, "end": 4902.8, "text": " It's going to be different when we look at dog and cat breeds versus the image net data that this is originally trained on", "tokens": [467, 311, 516, 281, 312, 819, 562, 321, 574, 412, 3000, 293, 3857, 41609, 5717, 264, 3256, 2533, 1412, 300, 341, 307, 7993, 8895, 322], "temperature": 0.0, "avg_logprob": -0.15155981205127858, "compression_ratio": 1.776061776061776, "no_speech_prob": 3.3405206067982363e-06}, {"id": 1067, "seek": 488560, "start": 4903.08, "end": 4906.8, "text": " So we don't really want to change layer one very much if at all", "tokens": [407, 321, 500, 380, 534, 528, 281, 1319, 4583, 472, 588, 709, 498, 412, 439], "temperature": 0.0, "avg_logprob": -0.15155981205127858, "compression_ratio": 1.776061776061776, "no_speech_prob": 3.3405206067982363e-06}, {"id": 1068, "seek": 488560, "start": 4907.4400000000005, "end": 4912.320000000001, "text": " Where else the last layers, you know this thing of like types of dog face", "tokens": [2305, 1646, 264, 1036, 7914, 11, 291, 458, 341, 551, 295, 411, 3467, 295, 3000, 1851], "temperature": 0.0, "avg_logprob": -0.15155981205127858, "compression_ratio": 1.776061776061776, "no_speech_prob": 3.3405206067982363e-06}, {"id": 1069, "seek": 491232, "start": 4912.32, "end": 4915.96, "text": " Seems very likely that we do want to change that right?", "tokens": [22524, 588, 3700, 300, 321, 360, 528, 281, 1319, 300, 558, 30], "temperature": 0.0, "avg_logprob": -0.1977136499741498, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.816216240513313e-06}, {"id": 1070, "seek": 491232, "start": 4915.96, "end": 4920.799999999999, "text": " So you kind of want this intuition is understanding that the different layers of a neural network", "tokens": [407, 291, 733, 295, 528, 341, 24002, 307, 3701, 300, 264, 819, 7914, 295, 257, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.1977136499741498, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.816216240513313e-06}, {"id": 1071, "seek": 491232, "start": 4921.32, "end": 4925.08, "text": " represents different levels of kind of semantic complexity", "tokens": [8855, 819, 4358, 295, 733, 295, 47982, 14024], "temperature": 0.0, "avg_logprob": -0.1977136499741498, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.816216240513313e-06}, {"id": 1072, "seek": 491232, "start": 4926.88, "end": 4928.88, "text": " So this is why", "tokens": [407, 341, 307, 983], "temperature": 0.0, "avg_logprob": -0.1977136499741498, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.816216240513313e-06}, {"id": 1073, "seek": 491232, "start": 4928.92, "end": 4933.28, "text": " our attempt to fine-tune this model didn't work is because we actually", "tokens": [527, 5217, 281, 2489, 12, 83, 2613, 341, 2316, 994, 380, 589, 307, 570, 321, 767], "temperature": 0.0, "avg_logprob": -0.1977136499741498, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.816216240513313e-06}, {"id": 1074, "seek": 491232, "start": 4934.28, "end": 4939.12, "text": " By default it trains all the layers at the same speed, right?", "tokens": [3146, 7576, 309, 16329, 439, 264, 7914, 412, 264, 912, 3073, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1977136499741498, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.816216240513313e-06}, {"id": 1075, "seek": 493912, "start": 4939.12, "end": 4943.08, "text": " Which is to say it'll update those like things representing diagonal lines of gradients", "tokens": [3013, 307, 281, 584, 309, 603, 5623, 729, 411, 721, 13460, 21539, 3876, 295, 2771, 2448], "temperature": 0.0, "avg_logprob": -0.13542977054562189, "compression_ratio": 1.7232472324723247, "no_speech_prob": 5.25536324857967e-06}, {"id": 1076, "seek": 493912, "start": 4943.36, "end": 4948.599999999999, "text": " Just as much as it tries to update the things that represent the exact specifics of what an eyeball looks like", "tokens": [1449, 382, 709, 382, 309, 9898, 281, 5623, 264, 721, 300, 2906, 264, 1900, 28454, 295, 437, 364, 38868, 1542, 411], "temperature": 0.0, "avg_logprob": -0.13542977054562189, "compression_ratio": 1.7232472324723247, "no_speech_prob": 5.25536324857967e-06}, {"id": 1077, "seek": 493912, "start": 4948.84, "end": 4951.62, "text": " So we have to change that and so", "tokens": [407, 321, 362, 281, 1319, 300, 293, 370], "temperature": 0.0, "avg_logprob": -0.13542977054562189, "compression_ratio": 1.7232472324723247, "no_speech_prob": 5.25536324857967e-06}, {"id": 1078, "seek": 493912, "start": 4952.5599999999995, "end": 4958.24, "text": " To change it. We first of all need to go back to where we were before. Okay, we just broke this model, right?", "tokens": [1407, 1319, 309, 13, 492, 700, 295, 439, 643, 281, 352, 646, 281, 689, 321, 645, 949, 13, 1033, 11, 321, 445, 6902, 341, 2316, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.13542977054562189, "compression_ratio": 1.7232472324723247, "no_speech_prob": 5.25536324857967e-06}, {"id": 1079, "seek": 493912, "start": 4958.24, "end": 4960.24, "text": " It's much worse than started out", "tokens": [467, 311, 709, 5324, 813, 1409, 484], "temperature": 0.0, "avg_logprob": -0.13542977054562189, "compression_ratio": 1.7232472324723247, "no_speech_prob": 5.25536324857967e-06}, {"id": 1080, "seek": 496024, "start": 4960.24, "end": 4969.639999999999, "text": " So if we just go load this brings back the model that we saved earlier. Remember we saved it as stage one", "tokens": [407, 498, 321, 445, 352, 3677, 341, 5607, 646, 264, 2316, 300, 321, 6624, 3071, 13, 5459, 321, 6624, 309, 382, 3233, 472], "temperature": 0.0, "avg_logprob": -0.18572267804827008, "compression_ratio": 1.6612244897959183, "no_speech_prob": 1.2482685178838437e-06}, {"id": 1081, "seek": 496024, "start": 4970.16, "end": 4972.48, "text": " Okay, so let's go ahead and", "tokens": [1033, 11, 370, 718, 311, 352, 2286, 293], "temperature": 0.0, "avg_logprob": -0.18572267804827008, "compression_ratio": 1.6612244897959183, "no_speech_prob": 1.2482685178838437e-06}, {"id": 1082, "seek": 496024, "start": 4973.28, "end": 4977.28, "text": " Load that back up. So that's now our models back to where it was before we killed it and", "tokens": [48408, 300, 646, 493, 13, 407, 300, 311, 586, 527, 5245, 646, 281, 689, 309, 390, 949, 321, 4652, 309, 293], "temperature": 0.0, "avg_logprob": -0.18572267804827008, "compression_ratio": 1.6612244897959183, "no_speech_prob": 1.2482685178838437e-06}, {"id": 1083, "seek": 496024, "start": 4978.8, "end": 4980.16, "text": " Let's run", "tokens": [961, 311, 1190], "temperature": 0.0, "avg_logprob": -0.18572267804827008, "compression_ratio": 1.6612244897959183, "no_speech_prob": 1.2482685178838437e-06}, {"id": 1084, "seek": 496024, "start": 4980.16, "end": 4983.0, "text": " Learning rate finder. We'll learn about what that is next week", "tokens": [15205, 3314, 915, 260, 13, 492, 603, 1466, 466, 437, 300, 307, 958, 1243], "temperature": 0.0, "avg_logprob": -0.18572267804827008, "compression_ratio": 1.6612244897959183, "no_speech_prob": 1.2482685178838437e-06}, {"id": 1085, "seek": 498300, "start": 4983.0, "end": 4989.8, "text": " But for now just know this is the thing that figures out what is the fastest I can train this neural network at?", "tokens": [583, 337, 586, 445, 458, 341, 307, 264, 551, 300, 9624, 484, 437, 307, 264, 14573, 286, 393, 3847, 341, 18161, 3209, 412, 30], "temperature": 0.0, "avg_logprob": -0.21580374015952056, "compression_ratio": 1.76, "no_speech_prob": 4.2228211896144785e-06}, {"id": 1086, "seek": 498300, "start": 4990.64, "end": 4994.4, "text": " Without making it zip off the rails and get blown apart", "tokens": [9129, 1455, 309, 20730, 766, 264, 27649, 293, 483, 16479, 4936], "temperature": 0.0, "avg_logprob": -0.21580374015952056, "compression_ratio": 1.76, "no_speech_prob": 4.2228211896144785e-06}, {"id": 1087, "seek": 498300, "start": 4994.76, "end": 4997.04, "text": " okay, so we can call learn dot LR find and", "tokens": [1392, 11, 370, 321, 393, 818, 1466, 5893, 441, 49, 915, 293], "temperature": 0.0, "avg_logprob": -0.21580374015952056, "compression_ratio": 1.76, "no_speech_prob": 4.2228211896144785e-06}, {"id": 1088, "seek": 498300, "start": 4997.6, "end": 5003.16, "text": " Then we can go learn dot recorder dot plot and that will plot the result of our LR finder", "tokens": [1396, 321, 393, 352, 1466, 5893, 37744, 5893, 7542, 293, 300, 486, 7542, 264, 1874, 295, 527, 441, 49, 915, 260], "temperature": 0.0, "avg_logprob": -0.21580374015952056, "compression_ratio": 1.76, "no_speech_prob": 4.2228211896144785e-06}, {"id": 1089, "seek": 498300, "start": 5003.16, "end": 5009.6, "text": " And what this basically shows you is this this key parameter that we're going to learn all about called the learning rate and the learning", "tokens": [400, 437, 341, 1936, 3110, 291, 307, 341, 341, 2141, 13075, 300, 321, 434, 516, 281, 1466, 439, 466, 1219, 264, 2539, 3314, 293, 264, 2539], "temperature": 0.0, "avg_logprob": -0.21580374015952056, "compression_ratio": 1.76, "no_speech_prob": 4.2228211896144785e-06}, {"id": 1090, "seek": 500960, "start": 5009.6, "end": 5014.320000000001, "text": " Rate basically says how quickly am I updating the parameters in my model?", "tokens": [49583, 1936, 1619, 577, 2661, 669, 286, 25113, 264, 9834, 294, 452, 2316, 30], "temperature": 0.0, "avg_logprob": -0.18375025404260514, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.710887878900394e-06}, {"id": 1091, "seek": 500960, "start": 5015.360000000001, "end": 5022.280000000001, "text": " and you can see that what happens is as I think this this bottom one here shows me what happens as I increase the learning rate and", "tokens": [293, 291, 393, 536, 300, 437, 2314, 307, 382, 286, 519, 341, 341, 2767, 472, 510, 3110, 385, 437, 2314, 382, 286, 3488, 264, 2539, 3314, 293], "temperature": 0.0, "avg_logprob": -0.18375025404260514, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.710887878900394e-06}, {"id": 1092, "seek": 500960, "start": 5023.240000000001, "end": 5026.120000000001, "text": " This one here shows what you know, what's the result?", "tokens": [639, 472, 510, 3110, 437, 291, 458, 11, 437, 311, 264, 1874, 30], "temperature": 0.0, "avg_logprob": -0.18375025404260514, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.710887878900394e-06}, {"id": 1093, "seek": 500960, "start": 5026.120000000001, "end": 5032.08, "text": " What's the loss and so you can see once the learning rate gets past 10 to the negative 4 my loss gets", "tokens": [708, 311, 264, 4470, 293, 370, 291, 393, 536, 1564, 264, 2539, 3314, 2170, 1791, 1266, 281, 264, 3671, 1017, 452, 4470, 2170], "temperature": 0.0, "avg_logprob": -0.18375025404260514, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.710887878900394e-06}, {"id": 1094, "seek": 500960, "start": 5032.72, "end": 5034.72, "text": " worse, okay, so", "tokens": [5324, 11, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.18375025404260514, "compression_ratio": 1.7453703703703705, "no_speech_prob": 4.710887878900394e-06}, {"id": 1095, "seek": 503472, "start": 5034.72, "end": 5042.16, "text": " It actually so happens. In fact, I can check this if I press shift tab here my learning rate defaults to", "tokens": [467, 767, 370, 2314, 13, 682, 1186, 11, 286, 393, 1520, 341, 498, 286, 1886, 5513, 4421, 510, 452, 2539, 3314, 7576, 82, 281], "temperature": 0.0, "avg_logprob": -0.1733821942968276, "compression_ratio": 1.6866952789699572, "no_speech_prob": 4.860418812313583e-06}, {"id": 1096, "seek": 503472, "start": 5043.52, "end": 5046.780000000001, "text": " 0.003 so my default learning rate is about here", "tokens": [1958, 13, 628, 18, 370, 452, 7576, 2539, 3314, 307, 466, 510], "temperature": 0.0, "avg_logprob": -0.1733821942968276, "compression_ratio": 1.6866952789699572, "no_speech_prob": 4.860418812313583e-06}, {"id": 1097, "seek": 503472, "start": 5047.08, "end": 5051.08, "text": " So you can see where our loss got worse right because we're trying to fine-tune things now", "tokens": [407, 291, 393, 536, 689, 527, 4470, 658, 5324, 558, 570, 321, 434, 1382, 281, 2489, 12, 83, 2613, 721, 586], "temperature": 0.0, "avg_logprob": -0.1733821942968276, "compression_ratio": 1.6866952789699572, "no_speech_prob": 4.860418812313583e-06}, {"id": 1098, "seek": 503472, "start": 5051.4400000000005, "end": 5053.4400000000005, "text": " We can't use such a high learning rate", "tokens": [492, 393, 380, 764, 1270, 257, 1090, 2539, 3314], "temperature": 0.0, "avg_logprob": -0.1733821942968276, "compression_ratio": 1.6866952789699572, "no_speech_prob": 4.860418812313583e-06}, {"id": 1099, "seek": 503472, "start": 5054.280000000001, "end": 5058.820000000001, "text": " So based on the learning rate finder, I tried to pick something, you know", "tokens": [407, 2361, 322, 264, 2539, 3314, 915, 260, 11, 286, 3031, 281, 1888, 746, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.1733821942968276, "compression_ratio": 1.6866952789699572, "no_speech_prob": 4.860418812313583e-06}, {"id": 1100, "seek": 503472, "start": 5059.4400000000005, "end": 5061.740000000001, "text": " Well before it started getting worse", "tokens": [1042, 949, 309, 1409, 1242, 5324], "temperature": 0.0, "avg_logprob": -0.1733821942968276, "compression_ratio": 1.6866952789699572, "no_speech_prob": 4.860418812313583e-06}, {"id": 1101, "seek": 506174, "start": 5061.74, "end": 5068.0599999999995, "text": " So I decided to pick one in x6. So I decided I'm going to trade at that rate", "tokens": [407, 286, 3047, 281, 1888, 472, 294, 2031, 21, 13, 407, 286, 3047, 286, 478, 516, 281, 4923, 412, 300, 3314], "temperature": 0.0, "avg_logprob": -0.21735321745580558, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.936951881973073e-06}, {"id": 1102, "seek": 506174, "start": 5069.139999999999, "end": 5074.3, "text": " But there's no point trading all the layers at that rate because we know that the later layers worked", "tokens": [583, 456, 311, 572, 935, 9529, 439, 264, 7914, 412, 300, 3314, 570, 321, 458, 300, 264, 1780, 7914, 2732], "temperature": 0.0, "avg_logprob": -0.21735321745580558, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.936951881973073e-06}, {"id": 1103, "seek": 506174, "start": 5074.46, "end": 5081.5, "text": " Just fine before when we were training much more quickly again of the default which was to remind us", "tokens": [1449, 2489, 949, 562, 321, 645, 3097, 709, 544, 2661, 797, 295, 264, 7576, 597, 390, 281, 4160, 505], "temperature": 0.0, "avg_logprob": -0.21735321745580558, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.936951881973073e-06}, {"id": 1104, "seek": 508150, "start": 5081.5, "end": 5090.26, "text": " 0.003 so what we can actually do is we can pass a range of learning rates to learn dot fit", "tokens": [1958, 13, 628, 18, 370, 437, 321, 393, 767, 360, 307, 321, 393, 1320, 257, 3613, 295, 2539, 6846, 281, 1466, 5893, 3318], "temperature": 0.0, "avg_logprob": -0.21990331013997397, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.4738751815457363e-05}, {"id": 1105, "seek": 508150, "start": 5090.34, "end": 5094.72, "text": " And we do it like this you pass you use this keyword in fact in Python", "tokens": [400, 321, 360, 309, 411, 341, 291, 1320, 291, 764, 341, 20428, 294, 1186, 294, 15329], "temperature": 0.0, "avg_logprob": -0.21990331013997397, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.4738751815457363e-05}, {"id": 1106, "seek": 508150, "start": 5094.72, "end": 5098.68, "text": " you may have come across before it's called slice and that can take a", "tokens": [291, 815, 362, 808, 2108, 949, 309, 311, 1219, 13153, 293, 300, 393, 747, 257], "temperature": 0.0, "avg_logprob": -0.21990331013997397, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.4738751815457363e-05}, {"id": 1107, "seek": 508150, "start": 5099.18, "end": 5105.02, "text": " start value and a stop value and basically what this says is train the very first players at a", "tokens": [722, 2158, 293, 257, 1590, 2158, 293, 1936, 437, 341, 1619, 307, 3847, 264, 588, 700, 4150, 412, 257], "temperature": 0.0, "avg_logprob": -0.21990331013997397, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.4738751815457363e-05}, {"id": 1108, "seek": 508150, "start": 5105.9, "end": 5107.9, "text": " learning rate of 1e neg 6 and", "tokens": [2539, 3314, 295, 502, 68, 2485, 1386, 293], "temperature": 0.0, "avg_logprob": -0.21990331013997397, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.4738751815457363e-05}, {"id": 1109, "seek": 510790, "start": 5107.9, "end": 5114.54, "text": " The very last layers at a rate of 1e neg 4 and then kind of distribute all the other layers", "tokens": [440, 588, 1036, 7914, 412, 257, 3314, 295, 502, 68, 2485, 1017, 293, 550, 733, 295, 20594, 439, 264, 661, 7914], "temperature": 0.0, "avg_logprob": -0.18082130596201906, "compression_ratio": 1.6111111111111112, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1110, "seek": 510790, "start": 5115.299999999999, "end": 5118.0599999999995, "text": " Across that, you know between those two values", "tokens": [34527, 300, 11, 291, 458, 1296, 729, 732, 4190], "temperature": 0.0, "avg_logprob": -0.18082130596201906, "compression_ratio": 1.6111111111111112, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1111, "seek": 510790, "start": 5118.78, "end": 5120.0599999999995, "text": " equally", "tokens": [12309], "temperature": 0.0, "avg_logprob": -0.18082130596201906, "compression_ratio": 1.6111111111111112, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1112, "seek": 510790, "start": 5120.0599999999995, "end": 5123.5199999999995, "text": " So we're going to see that in a lot more detail, but basically for now", "tokens": [407, 321, 434, 516, 281, 536, 300, 294, 257, 688, 544, 2607, 11, 457, 1936, 337, 586], "temperature": 0.0, "avg_logprob": -0.18082130596201906, "compression_ratio": 1.6111111111111112, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1113, "seek": 510790, "start": 5125.139999999999, "end": 5130.7, "text": " This is kind of a good rule of thumb is to say when you after you unfreeze", "tokens": [639, 307, 733, 295, 257, 665, 4978, 295, 9298, 307, 281, 584, 562, 291, 934, 291, 3971, 701, 1381], "temperature": 0.0, "avg_logprob": -0.18082130596201906, "compression_ratio": 1.6111111111111112, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1114, "seek": 510790, "start": 5130.7, "end": 5132.78, "text": " This is the thing that's going to train the whole thing", "tokens": [639, 307, 264, 551, 300, 311, 516, 281, 3847, 264, 1379, 551], "temperature": 0.0, "avg_logprob": -0.18082130596201906, "compression_ratio": 1.6111111111111112, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1115, "seek": 513278, "start": 5132.78, "end": 5138.179999999999, "text": " Pass a max learning rate parameter pass it a slice", "tokens": [10319, 257, 11469, 2539, 3314, 13075, 1320, 309, 257, 13153], "temperature": 0.0, "avg_logprob": -0.17248139632375617, "compression_ratio": 1.7399103139013452, "no_speech_prob": 6.339165338431485e-06}, {"id": 1116, "seek": 513278, "start": 5138.98, "end": 5144.66, "text": " Make the second part of that slice about 10 times smaller than your first stage", "tokens": [4387, 264, 1150, 644, 295, 300, 13153, 466, 1266, 1413, 4356, 813, 428, 700, 3233], "temperature": 0.0, "avg_logprob": -0.17248139632375617, "compression_ratio": 1.7399103139013452, "no_speech_prob": 6.339165338431485e-06}, {"id": 1117, "seek": 513278, "start": 5144.78, "end": 5147.36, "text": " So our first stage defaulted to about 1e neg 3", "tokens": [407, 527, 700, 3233, 7576, 292, 281, 466, 502, 68, 2485, 805], "temperature": 0.0, "avg_logprob": -0.17248139632375617, "compression_ratio": 1.7399103139013452, "no_speech_prob": 6.339165338431485e-06}, {"id": 1118, "seek": 513278, "start": 5147.36, "end": 5153.58, "text": " So let's use about 1e neg 4 and then this one should be a value from your learning rate finder", "tokens": [407, 718, 311, 764, 466, 502, 68, 2485, 1017, 293, 550, 341, 472, 820, 312, 257, 2158, 490, 428, 2539, 3314, 915, 260], "temperature": 0.0, "avg_logprob": -0.17248139632375617, "compression_ratio": 1.7399103139013452, "no_speech_prob": 6.339165338431485e-06}, {"id": 1119, "seek": 513278, "start": 5153.62, "end": 5158.0599999999995, "text": " Which is well before things started getting worse and you can see things are starting to get worse", "tokens": [3013, 307, 731, 949, 721, 1409, 1242, 5324, 293, 291, 393, 536, 721, 366, 2891, 281, 483, 5324], "temperature": 0.0, "avg_logprob": -0.17248139632375617, "compression_ratio": 1.7399103139013452, "no_speech_prob": 6.339165338431485e-06}, {"id": 1120, "seek": 513278, "start": 5158.9, "end": 5160.66, "text": " Maybe about here", "tokens": [2704, 466, 510], "temperature": 0.0, "avg_logprob": -0.17248139632375617, "compression_ratio": 1.7399103139013452, "no_speech_prob": 6.339165338431485e-06}, {"id": 1121, "seek": 516066, "start": 5160.66, "end": 5167.099999999999, "text": " So I picked something that's at least 10 times smaller than that. So if I do that then I get point oh", "tokens": [407, 286, 6183, 746, 300, 311, 412, 1935, 1266, 1413, 4356, 813, 300, 13, 407, 498, 286, 360, 300, 550, 286, 483, 935, 1954], "temperature": 0.0, "avg_logprob": -0.26012227800157334, "compression_ratio": 1.6334841628959276, "no_speech_prob": 4.785060809808783e-06}, {"id": 1122, "seek": 516066, "start": 5167.62, "end": 5169.62, "text": " five seven eight eight", "tokens": [1732, 3407, 3180, 3180], "temperature": 0.0, "avg_logprob": -0.26012227800157334, "compression_ratio": 1.6334841628959276, "no_speech_prob": 4.785060809808783e-06}, {"id": 1123, "seek": 516066, "start": 5170.38, "end": 5171.82, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.26012227800157334, "compression_ratio": 1.6334841628959276, "no_speech_prob": 4.785060809808783e-06}, {"id": 1124, "seek": 516066, "start": 5171.82, "end": 5173.82, "text": " Remember what we got before", "tokens": [5459, 437, 321, 658, 949], "temperature": 0.0, "avg_logprob": -0.26012227800157334, "compression_ratio": 1.6334841628959276, "no_speech_prob": 4.785060809808783e-06}, {"id": 1125, "seek": 516066, "start": 5173.9, "end": 5179.42, "text": " Yeah, get better right? So we've gone down from the six point one percent to a five point seven percent", "tokens": [865, 11, 483, 1101, 558, 30, 407, 321, 600, 2780, 760, 490, 264, 2309, 935, 472, 3043, 281, 257, 1732, 935, 3407, 3043], "temperature": 0.0, "avg_logprob": -0.26012227800157334, "compression_ratio": 1.6334841628959276, "no_speech_prob": 4.785060809808783e-06}, {"id": 1126, "seek": 516066, "start": 5179.42, "end": 5186.26, "text": " So that's about a ten percentage point relative improvement with another 58 seconds of training. So I", "tokens": [407, 300, 311, 466, 257, 2064, 9668, 935, 4972, 10444, 365, 1071, 21786, 3949, 295, 3097, 13, 407, 286], "temperature": 0.0, "avg_logprob": -0.26012227800157334, "compression_ratio": 1.6334841628959276, "no_speech_prob": 4.785060809808783e-06}, {"id": 1127, "seek": 518626, "start": 5186.26, "end": 5193.34, "text": " Would perhaps say for most people most of the time these two stages are enough to get", "tokens": [6068, 4317, 584, 337, 881, 561, 881, 295, 264, 565, 613, 732, 10232, 366, 1547, 281, 483], "temperature": 0.0, "avg_logprob": -0.1293084725089695, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.225270691269543e-06}, {"id": 1128, "seek": 518626, "start": 5194.06, "end": 5196.06, "text": " Pretty much a world-class model", "tokens": [10693, 709, 257, 1002, 12, 11665, 2316], "temperature": 0.0, "avg_logprob": -0.1293084725089695, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.225270691269543e-06}, {"id": 1129, "seek": 518626, "start": 5196.62, "end": 5202.66, "text": " You won't win a Kaggle competition particularly because now a lot of fast AI alumni are competing on Kaggle", "tokens": [509, 1582, 380, 1942, 257, 48751, 22631, 6211, 4098, 570, 586, 257, 688, 295, 2370, 7318, 16347, 366, 15439, 322, 48751, 22631], "temperature": 0.0, "avg_logprob": -0.1293084725089695, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.225270691269543e-06}, {"id": 1130, "seek": 518626, "start": 5202.66, "end": 5204.66, "text": " And this is the first thing that they do", "tokens": [400, 341, 307, 264, 700, 551, 300, 436, 360], "temperature": 0.0, "avg_logprob": -0.1293084725089695, "compression_ratio": 1.6285714285714286, "no_speech_prob": 2.225270691269543e-06}, {"id": 1131, "seek": 520466, "start": 5204.66, "end": 5215.3, "text": " But you know in practice you'll get something that's you know about as good in practice as the vast majority of practitioners can do", "tokens": [583, 291, 458, 294, 3124, 291, 603, 483, 746, 300, 311, 291, 458, 466, 382, 665, 294, 3124, 382, 264, 8369, 6286, 295, 25742, 393, 360], "temperature": 0.0, "avg_logprob": -0.15940217297486584, "compression_ratio": 1.728448275862069, "no_speech_prob": 6.4389678300358355e-06}, {"id": 1132, "seek": 520466, "start": 5216.0199999999995, "end": 5223.08, "text": " We can improve it by using more layers and we'll do this next week by basically doing a resnet 50 instead of a resnet 34", "tokens": [492, 393, 3470, 309, 538, 1228, 544, 7914, 293, 321, 603, 360, 341, 958, 1243, 538, 1936, 884, 257, 725, 7129, 2625, 2602, 295, 257, 725, 7129, 12790], "temperature": 0.0, "avg_logprob": -0.15940217297486584, "compression_ratio": 1.728448275862069, "no_speech_prob": 6.4389678300358355e-06}, {"id": 1133, "seek": 520466, "start": 5224.3, "end": 5229.22, "text": " And you can try running this during the week if you want to you'll see it's exactly the same as before", "tokens": [400, 291, 393, 853, 2614, 341, 1830, 264, 1243, 498, 291, 528, 281, 291, 603, 536, 309, 311, 2293, 264, 912, 382, 949], "temperature": 0.0, "avg_logprob": -0.15940217297486584, "compression_ratio": 1.728448275862069, "no_speech_prob": 6.4389678300358355e-06}, {"id": 1134, "seek": 520466, "start": 5229.22, "end": 5231.94, "text": " But I'm using resnet 50 instead of resnet 34", "tokens": [583, 286, 478, 1228, 725, 7129, 2625, 2602, 295, 725, 7129, 12790], "temperature": 0.0, "avg_logprob": -0.15940217297486584, "compression_ratio": 1.728448275862069, "no_speech_prob": 6.4389678300358355e-06}, {"id": 1135, "seek": 523194, "start": 5231.94, "end": 5237.66, "text": " What you'll find is it's very likely if you try to do this you will get an error", "tokens": [708, 291, 603, 915, 307, 309, 311, 588, 3700, 498, 291, 853, 281, 360, 341, 291, 486, 483, 364, 6713], "temperature": 0.0, "avg_logprob": -0.19797921648212508, "compression_ratio": 1.6374501992031874, "no_speech_prob": 8.013410479179583e-06}, {"id": 1136, "seek": 523194, "start": 5237.66, "end": 5241.259999999999, "text": " And the error will be your GPU is run out of memory", "tokens": [400, 264, 6713, 486, 312, 428, 18407, 307, 1190, 484, 295, 4675], "temperature": 0.0, "avg_logprob": -0.19797921648212508, "compression_ratio": 1.6374501992031874, "no_speech_prob": 8.013410479179583e-06}, {"id": 1137, "seek": 523194, "start": 5241.259999999999, "end": 5246.099999999999, "text": " and the reason for that is that resnet 50 is bigger than resnet 34 and", "tokens": [293, 264, 1778, 337, 300, 307, 300, 725, 7129, 2625, 307, 3801, 813, 725, 7129, 12790, 293], "temperature": 0.0, "avg_logprob": -0.19797921648212508, "compression_ratio": 1.6374501992031874, "no_speech_prob": 8.013410479179583e-06}, {"id": 1138, "seek": 523194, "start": 5246.62, "end": 5250.62, "text": " Therefore it has more parameters and therefore it uses more of your graphics cards memory", "tokens": [7504, 309, 575, 544, 9834, 293, 4412, 309, 4960, 544, 295, 428, 11837, 5632, 4675], "temperature": 0.0, "avg_logprob": -0.19797921648212508, "compression_ratio": 1.6374501992031874, "no_speech_prob": 8.013410479179583e-06}, {"id": 1139, "seek": 523194, "start": 5250.9, "end": 5254.7, "text": " Just totally separate to your normal computer RAM. This is GPU RAM", "tokens": [1449, 3879, 4994, 281, 428, 2710, 3820, 14561, 13, 639, 307, 18407, 14561], "temperature": 0.0, "avg_logprob": -0.19797921648212508, "compression_ratio": 1.6374501992031874, "no_speech_prob": 8.013410479179583e-06}, {"id": 1140, "seek": 525470, "start": 5254.7, "end": 5260.42, "text": " If you're using the kind of default salamander AWS", "tokens": [759, 291, 434, 1228, 264, 733, 295, 7576, 1845, 335, 4483, 17650], "temperature": 0.0, "avg_logprob": -0.23467068050218665, "compression_ratio": 1.7079207920792079, "no_speech_prob": 3.37357196258381e-05}, {"id": 1141, "seek": 525470, "start": 5261.9, "end": 5266.179999999999, "text": " And so forth suggestion then you'll be having a 16 gig of", "tokens": [400, 370, 5220, 16541, 550, 291, 603, 312, 1419, 257, 3165, 8741, 295], "temperature": 0.0, "avg_logprob": -0.23467068050218665, "compression_ratio": 1.7079207920792079, "no_speech_prob": 3.37357196258381e-05}, {"id": 1142, "seek": 525470, "start": 5267.42, "end": 5272.78, "text": " GPU memory the pad I use most the time has 11 gig of GPU memory", "tokens": [18407, 4675, 264, 6887, 286, 764, 881, 264, 565, 575, 2975, 8741, 295, 18407, 4675], "temperature": 0.0, "avg_logprob": -0.23467068050218665, "compression_ratio": 1.7079207920792079, "no_speech_prob": 3.37357196258381e-05}, {"id": 1143, "seek": 525470, "start": 5272.78, "end": 5277.74, "text": " The cheaper ones have 8 gig of GPU memory and that's kind of the main range you tend to get", "tokens": [440, 12284, 2306, 362, 1649, 8741, 295, 18407, 4675, 293, 300, 311, 733, 295, 264, 2135, 3613, 291, 3928, 281, 483], "temperature": 0.0, "avg_logprob": -0.23467068050218665, "compression_ratio": 1.7079207920792079, "no_speech_prob": 3.37357196258381e-05}, {"id": 1144, "seek": 525470, "start": 5278.0599999999995, "end": 5282.26, "text": " If yours has less than 8 gig of GPU memory, it's going to be frustrating for you", "tokens": [759, 6342, 575, 1570, 813, 1649, 8741, 295, 18407, 4675, 11, 309, 311, 516, 281, 312, 16522, 337, 291], "temperature": 0.0, "avg_logprob": -0.23467068050218665, "compression_ratio": 1.7079207920792079, "no_speech_prob": 3.37357196258381e-05}, {"id": 1145, "seek": 528226, "start": 5282.26, "end": 5284.56, "text": " Anyway, so you'll be somewhere around there", "tokens": [5684, 11, 370, 291, 603, 312, 4079, 926, 456], "temperature": 0.0, "avg_logprob": -0.1792828767195992, "compression_ratio": 1.7158671586715868, "no_speech_prob": 4.9369332373316865e-06}, {"id": 1146, "seek": 528226, "start": 5285.1, "end": 5289.22, "text": " And it's very likely that we try to run this you'll get it out of memory memory error", "tokens": [400, 309, 311, 588, 3700, 300, 321, 853, 281, 1190, 341, 291, 603, 483, 309, 484, 295, 4675, 4675, 6713], "temperature": 0.0, "avg_logprob": -0.1792828767195992, "compression_ratio": 1.7158671586715868, "no_speech_prob": 4.9369332373316865e-06}, {"id": 1147, "seek": 528226, "start": 5289.22, "end": 5295.22, "text": " And that's because it's just trying to do too much too many parameter updates for the amount of RAM you have", "tokens": [400, 300, 311, 570, 309, 311, 445, 1382, 281, 360, 886, 709, 886, 867, 13075, 9205, 337, 264, 2372, 295, 14561, 291, 362], "temperature": 0.0, "avg_logprob": -0.1792828767195992, "compression_ratio": 1.7158671586715868, "no_speech_prob": 4.9369332373316865e-06}, {"id": 1148, "seek": 528226, "start": 5295.820000000001, "end": 5297.820000000001, "text": " And that's easily fixed", "tokens": [400, 300, 311, 3612, 6806], "temperature": 0.0, "avg_logprob": -0.1792828767195992, "compression_ratio": 1.7158671586715868, "no_speech_prob": 4.9369332373316865e-06}, {"id": 1149, "seek": 528226, "start": 5297.860000000001, "end": 5302.06, "text": " This image data bunch constructor has a parameter at the end", "tokens": [639, 3256, 1412, 3840, 47479, 575, 257, 13075, 412, 264, 917], "temperature": 0.0, "avg_logprob": -0.1792828767195992, "compression_ratio": 1.7158671586715868, "no_speech_prob": 4.9369332373316865e-06}, {"id": 1150, "seek": 528226, "start": 5302.820000000001, "end": 5308.62, "text": " Batch size BS for batch size and this basically says how many images do you train at one time?", "tokens": [363, 852, 2744, 27253, 337, 15245, 2744, 293, 341, 1936, 1619, 577, 867, 5267, 360, 291, 3847, 412, 472, 565, 30], "temperature": 0.0, "avg_logprob": -0.1792828767195992, "compression_ratio": 1.7158671586715868, "no_speech_prob": 4.9369332373316865e-06}, {"id": 1151, "seek": 530862, "start": 5308.62, "end": 5311.58, "text": " If you run out of memory, just make it smaller", "tokens": [759, 291, 1190, 484, 295, 4675, 11, 445, 652, 309, 4356], "temperature": 0.0, "avg_logprob": -0.2003521438716918, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.3320574200624833e-06}, {"id": 1152, "seek": 530862, "start": 5312.0199999999995, "end": 5314.98, "text": " Okay, so this worked for me on an 11 gig card", "tokens": [1033, 11, 370, 341, 2732, 337, 385, 322, 364, 2975, 8741, 2920], "temperature": 0.0, "avg_logprob": -0.2003521438716918, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.3320574200624833e-06}, {"id": 1153, "seek": 530862, "start": 5314.98, "end": 5319.66, "text": " It probably won't work for you if you've got an 8 gig card if you do just make that 32", "tokens": [467, 1391, 1582, 380, 589, 337, 291, 498, 291, 600, 658, 364, 1649, 8741, 2920, 498, 291, 360, 445, 652, 300, 8858], "temperature": 0.0, "avg_logprob": -0.2003521438716918, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.3320574200624833e-06}, {"id": 1154, "seek": 530862, "start": 5322.18, "end": 5327.36, "text": " It's fine to use a smaller batch size it just it might take a little bit longer that's all okay", "tokens": [467, 311, 2489, 281, 764, 257, 4356, 15245, 2744, 309, 445, 309, 1062, 747, 257, 707, 857, 2854, 300, 311, 439, 1392], "temperature": 0.0, "avg_logprob": -0.2003521438716918, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.3320574200624833e-06}, {"id": 1155, "seek": 530862, "start": 5327.36, "end": 5332.78, "text": " If you've got a bigger like a 16 gig you might be able to go away with 64. Okay, so that's just one number", "tokens": [759, 291, 600, 658, 257, 3801, 411, 257, 3165, 8741, 291, 1062, 312, 1075, 281, 352, 1314, 365, 12145, 13, 1033, 11, 370, 300, 311, 445, 472, 1230], "temperature": 0.0, "avg_logprob": -0.2003521438716918, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.3320574200624833e-06}, {"id": 1156, "seek": 530862, "start": 5332.78, "end": 5334.78, "text": " you'll need to try during the week and", "tokens": [291, 603, 643, 281, 853, 1830, 264, 1243, 293], "temperature": 0.0, "avg_logprob": -0.2003521438716918, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.3320574200624833e-06}, {"id": 1157, "seek": 530862, "start": 5335.22, "end": 5337.22, "text": " again, we feed it for a while and", "tokens": [797, 11, 321, 3154, 309, 337, 257, 1339, 293], "temperature": 0.0, "avg_logprob": -0.2003521438716918, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.3320574200624833e-06}, {"id": 1158, "seek": 533722, "start": 5337.22, "end": 5338.62, "text": " we", "tokens": [321], "temperature": 0.0, "avg_logprob": -0.22708009021116957, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.0616050531098153e-05}, {"id": 1159, "seek": 533722, "start": 5338.62, "end": 5342.02, "text": " We get down to a four point four percent area", "tokens": [492, 483, 760, 281, 257, 1451, 935, 1451, 3043, 1859], "temperature": 0.0, "avg_logprob": -0.22708009021116957, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.0616050531098153e-05}, {"id": 1160, "seek": 533722, "start": 5342.58, "end": 5347.46, "text": " So this is pretty extraordinary. You know, I was pretty surprised because I mean", "tokens": [407, 341, 307, 1238, 10581, 13, 509, 458, 11, 286, 390, 1238, 6100, 570, 286, 914], "temperature": 0.0, "avg_logprob": -0.22708009021116957, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.0616050531098153e-05}, {"id": 1161, "seek": 533722, "start": 5348.780000000001, "end": 5353.820000000001, "text": " When we first did in the first course just cats versus dogs. We were kind of getting", "tokens": [1133, 321, 700, 630, 294, 264, 700, 1164, 445, 11111, 5717, 7197, 13, 492, 645, 733, 295, 1242], "temperature": 0.0, "avg_logprob": -0.22708009021116957, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.0616050531098153e-05}, {"id": 1162, "seek": 533722, "start": 5355.34, "end": 5361.06, "text": " Somewhere around a three percent error for something where you've got a 50% chance of being right and the two things look totally different", "tokens": [34500, 926, 257, 1045, 3043, 6713, 337, 746, 689, 291, 600, 658, 257, 2625, 4, 2931, 295, 885, 558, 293, 264, 732, 721, 574, 3879, 819], "temperature": 0.0, "avg_logprob": -0.22708009021116957, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.0616050531098153e-05}, {"id": 1163, "seek": 533722, "start": 5361.780000000001, "end": 5365.26, "text": " so the fact that we can get a four point four percent error for such a", "tokens": [370, 264, 1186, 300, 321, 393, 483, 257, 1451, 935, 1451, 3043, 6713, 337, 1270, 257], "temperature": 0.0, "avg_logprob": -0.22708009021116957, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.0616050531098153e-05}, {"id": 1164, "seek": 536526, "start": 5365.26, "end": 5368.1, "text": " fine-grain thing it's quite extraordinary", "tokens": [2489, 12, 70, 7146, 551, 309, 311, 1596, 10581], "temperature": 0.0, "avg_logprob": -0.25602699279785157, "compression_ratio": 1.6085271317829457, "no_speech_prob": 1.7231375750270672e-05}, {"id": 1165, "seek": 536526, "start": 5369.42, "end": 5374.900000000001, "text": " In this case, I unfroze it and fit it a little bit more went from four point four to four point three five", "tokens": [682, 341, 1389, 11, 286, 3971, 340, 1381, 309, 293, 3318, 309, 257, 707, 857, 544, 1437, 490, 1451, 935, 1451, 281, 1451, 935, 1045, 1732], "temperature": 0.0, "avg_logprob": -0.25602699279785157, "compression_ratio": 1.6085271317829457, "no_speech_prob": 1.7231375750270672e-05}, {"id": 1166, "seek": 536526, "start": 5375.46, "end": 5377.46, "text": " tiny improvement", "tokens": [5870, 10444], "temperature": 0.0, "avg_logprob": -0.25602699279785157, "compression_ratio": 1.6085271317829457, "no_speech_prob": 1.7231375750270672e-05}, {"id": 1167, "seek": 536526, "start": 5377.46, "end": 5379.58, "text": " Basically, resident 50 is already a pretty good model", "tokens": [8537, 11, 10832, 2625, 307, 1217, 257, 1238, 665, 2316], "temperature": 0.0, "avg_logprob": -0.25602699279785157, "compression_ratio": 1.6085271317829457, "no_speech_prob": 1.7231375750270672e-05}, {"id": 1168, "seek": 536526, "start": 5382.34, "end": 5389.26, "text": " It's interesting because again you can call most confused here and you can see the kinds of things that it's", "tokens": [467, 311, 1880, 570, 797, 291, 393, 818, 881, 9019, 510, 293, 291, 393, 536, 264, 3685, 295, 721, 300, 309, 311], "temperature": 0.0, "avg_logprob": -0.25602699279785157, "compression_ratio": 1.6085271317829457, "no_speech_prob": 1.7231375750270672e-05}, {"id": 1169, "seek": 536526, "start": 5389.9400000000005, "end": 5394.06, "text": " Getting wrong and I actually depending on when you run it you're going to get slightly", "tokens": [13674, 2085, 293, 286, 767, 5413, 322, 562, 291, 1190, 309, 291, 434, 516, 281, 483, 4748], "temperature": 0.0, "avg_logprob": -0.25602699279785157, "compression_ratio": 1.6085271317829457, "no_speech_prob": 1.7231375750270672e-05}, {"id": 1170, "seek": 539406, "start": 5394.06, "end": 5397.18, "text": " Different numbers, but you'll get roughly the same kinds of things", "tokens": [20825, 3547, 11, 457, 291, 603, 483, 9810, 264, 912, 3685, 295, 721], "temperature": 0.0, "avg_logprob": -0.22425402427206234, "compression_ratio": 1.6964285714285714, "no_speech_prob": 6.854122148070019e-06}, {"id": 1171, "seek": 539406, "start": 5398.38, "end": 5404.38, "text": " So quite often I find that ragdoll and burman are things that it gets confused and I actually never heard of either of those things", "tokens": [407, 1596, 2049, 286, 915, 300, 17539, 67, 1833, 293, 2779, 1601, 366, 721, 300, 309, 2170, 9019, 293, 286, 767, 1128, 2198, 295, 2139, 295, 729, 721], "temperature": 0.0, "avg_logprob": -0.22425402427206234, "compression_ratio": 1.6964285714285714, "no_speech_prob": 6.854122148070019e-06}, {"id": 1172, "seek": 539406, "start": 5404.580000000001, "end": 5406.580000000001, "text": " So I actually looked them up on the internet", "tokens": [407, 286, 767, 2956, 552, 493, 322, 264, 4705], "temperature": 0.0, "avg_logprob": -0.22425402427206234, "compression_ratio": 1.6964285714285714, "no_speech_prob": 6.854122148070019e-06}, {"id": 1173, "seek": 539406, "start": 5408.780000000001, "end": 5410.620000000001, "text": " And I", "tokens": [400, 286], "temperature": 0.0, "avg_logprob": -0.22425402427206234, "compression_ratio": 1.6964285714285714, "no_speech_prob": 6.854122148070019e-06}, {"id": 1174, "seek": 539406, "start": 5410.620000000001, "end": 5413.1, "text": " Found a page on the cat site", "tokens": [8207, 257, 3028, 322, 264, 3857, 3621], "temperature": 0.0, "avg_logprob": -0.22425402427206234, "compression_ratio": 1.6964285714285714, "no_speech_prob": 6.854122148070019e-06}, {"id": 1175, "seek": 539406, "start": 5413.46, "end": 5419.76, "text": " Called is this a burman or a ragdoll and there is a long thread of cat experts like", "tokens": [45001, 307, 341, 257, 2779, 1601, 420, 257, 17539, 67, 1833, 293, 456, 307, 257, 938, 7207, 295, 3857, 8572, 411], "temperature": 0.0, "avg_logprob": -0.22425402427206234, "compression_ratio": 1.6964285714285714, "no_speech_prob": 6.854122148070019e-06}, {"id": 1176, "seek": 539406, "start": 5420.42, "end": 5422.1, "text": " arguing intensely", "tokens": [19697, 43235], "temperature": 0.0, "avg_logprob": -0.22425402427206234, "compression_ratio": 1.6964285714285714, "no_speech_prob": 6.854122148070019e-06}, {"id": 1177, "seek": 542210, "start": 5422.1, "end": 5426.72, "text": " About which it is so I feel fine that my computer had problems", "tokens": [7769, 597, 309, 307, 370, 286, 841, 2489, 300, 452, 3820, 632, 2740], "temperature": 0.0, "avg_logprob": -0.32301821607224485, "compression_ratio": 1.584, "no_speech_prob": 8.939523468143307e-06}, {"id": 1178, "seek": 542210, "start": 5429.14, "end": 5432.660000000001, "text": " I found something similar. I think it was this pit rule versus daffodil terrier", "tokens": [286, 1352, 746, 2531, 13, 286, 519, 309, 390, 341, 10147, 4978, 5717, 1120, 602, 378, 388, 1796, 7326], "temperature": 0.0, "avg_logprob": -0.32301821607224485, "compression_ratio": 1.584, "no_speech_prob": 8.939523468143307e-06}, {"id": 1179, "seek": 542210, "start": 5432.900000000001, "end": 5439.04, "text": " Apparently the main difference is like the particular kennel club guidelines as to how they are assessed", "tokens": [16755, 264, 2135, 2649, 307, 411, 264, 1729, 36272, 338, 6482, 12470, 382, 281, 577, 436, 366, 36051], "temperature": 0.0, "avg_logprob": -0.32301821607224485, "compression_ratio": 1.584, "no_speech_prob": 8.939523468143307e-06}, {"id": 1180, "seek": 542210, "start": 5439.08, "end": 5442.08, "text": " But some people think that one of them might have a slightly reddened nose", "tokens": [583, 512, 561, 519, 300, 472, 295, 552, 1062, 362, 257, 4748, 2182, 1556, 292, 6690], "temperature": 0.0, "avg_logprob": -0.32301821607224485, "compression_ratio": 1.584, "no_speech_prob": 8.939523468143307e-06}, {"id": 1181, "seek": 542210, "start": 5442.92, "end": 5447.240000000001, "text": " So this is the kind of stuff where actually if you're not a domain expert", "tokens": [407, 341, 307, 264, 733, 295, 1507, 689, 767, 498, 291, 434, 406, 257, 9274, 5844], "temperature": 0.0, "avg_logprob": -0.32301821607224485, "compression_ratio": 1.584, "no_speech_prob": 8.939523468143307e-06}, {"id": 1182, "seek": 544724, "start": 5447.24, "end": 5453.38, "text": " It helps you become one right because I now know more about which kinds of pet breeds are hard to identify", "tokens": [467, 3665, 291, 1813, 472, 558, 570, 286, 586, 458, 544, 466, 597, 3685, 295, 3817, 41609, 366, 1152, 281, 5876], "temperature": 0.0, "avg_logprob": -0.14487666433507745, "compression_ratio": 1.6129032258064515, "no_speech_prob": 4.222798452246934e-06}, {"id": 1183, "seek": 544724, "start": 5453.82, "end": 5455.82, "text": " Than I used to", "tokens": [18289, 286, 1143, 281], "temperature": 0.0, "avg_logprob": -0.14487666433507745, "compression_ratio": 1.6129032258064515, "no_speech_prob": 4.222798452246934e-06}, {"id": 1184, "seek": 544724, "start": 5456.179999999999, "end": 5462.139999999999, "text": " So model interpretation works both ways. So what I want you to do this week is to run", "tokens": [407, 2316, 14174, 1985, 1293, 2098, 13, 407, 437, 286, 528, 291, 281, 360, 341, 1243, 307, 281, 1190], "temperature": 0.0, "avg_logprob": -0.14487666433507745, "compression_ratio": 1.6129032258064515, "no_speech_prob": 4.222798452246934e-06}, {"id": 1185, "seek": 544724, "start": 5463.7, "end": 5466.3, "text": " This notebook, you know, make sure you can get through it", "tokens": [639, 21060, 11, 291, 458, 11, 652, 988, 291, 393, 483, 807, 309], "temperature": 0.0, "avg_logprob": -0.14487666433507745, "compression_ratio": 1.6129032258064515, "no_speech_prob": 4.222798452246934e-06}, {"id": 1186, "seek": 544724, "start": 5466.3, "end": 5473.099999999999, "text": " But then what I really want you to do is to get your own image data set and actually", "tokens": [583, 550, 437, 286, 534, 528, 291, 281, 360, 307, 281, 483, 428, 1065, 3256, 1412, 992, 293, 767], "temperature": 0.0, "avg_logprob": -0.14487666433507745, "compression_ratio": 1.6129032258064515, "no_speech_prob": 4.222798452246934e-06}, {"id": 1187, "seek": 547310, "start": 5473.1, "end": 5478.620000000001, "text": " I'm Francisco who I mentioned earlier. He started the language to model thread and he's you know", "tokens": [286, 478, 12279, 567, 286, 2835, 3071, 13, 634, 1409, 264, 2856, 281, 2316, 7207, 293, 415, 311, 291, 458], "temperature": 0.0, "avg_logprob": -0.2159939441052112, "compression_ratio": 1.6008771929824561, "no_speech_prob": 1.2805179721908644e-05}, {"id": 1188, "seek": 547310, "start": 5478.780000000001, "end": 5485.26, "text": " Now helping to TA the course he's actually putting together a guide that will show you how to download data", "tokens": [823, 4315, 281, 20094, 264, 1164, 415, 311, 767, 3372, 1214, 257, 5934, 300, 486, 855, 291, 577, 281, 5484, 1412], "temperature": 0.0, "avg_logprob": -0.2159939441052112, "compression_ratio": 1.6008771929824561, "no_speech_prob": 1.2805179721908644e-05}, {"id": 1189, "seek": 547310, "start": 5485.740000000001, "end": 5491.740000000001, "text": " From Google images so you can create your own data set to play with but before I do I want to", "tokens": [3358, 3329, 5267, 370, 291, 393, 1884, 428, 1065, 1412, 992, 281, 862, 365, 457, 949, 286, 360, 286, 528, 281], "temperature": 0.0, "avg_logprob": -0.2159939441052112, "compression_ratio": 1.6008771929824561, "no_speech_prob": 1.2805179721908644e-05}, {"id": 1190, "seek": 547310, "start": 5493.42, "end": 5495.42, "text": " Okay, I'll come back to that moment", "tokens": [1033, 11, 286, 603, 808, 646, 281, 300, 1623], "temperature": 0.0, "avg_logprob": -0.2159939441052112, "compression_ratio": 1.6008771929824561, "no_speech_prob": 1.2805179721908644e-05}, {"id": 1191, "seek": 547310, "start": 5496.06, "end": 5498.06, "text": " Before I do I want to show you", "tokens": [4546, 286, 360, 286, 528, 281, 855, 291], "temperature": 0.0, "avg_logprob": -0.2159939441052112, "compression_ratio": 1.6008771929824561, "no_speech_prob": 1.2805179721908644e-05}, {"id": 1192, "seek": 549806, "start": 5498.06, "end": 5504.700000000001, "text": " Because how to create labels in lots of different ways because your data set wherever you get it from won't necessarily", "tokens": [1436, 577, 281, 1884, 16949, 294, 3195, 295, 819, 2098, 570, 428, 1412, 992, 8660, 291, 483, 309, 490, 1582, 380, 4725], "temperature": 0.0, "avg_logprob": -0.17746506523840205, "compression_ratio": 1.670940170940171, "no_speech_prob": 1.1478536180220544e-05}, {"id": 1193, "seek": 549806, "start": 5505.620000000001, "end": 5510.080000000001, "text": " Be that kind of red checks based approach. It could be in lots of different formats", "tokens": [879, 300, 733, 295, 2182, 13834, 2361, 3109, 13, 467, 727, 312, 294, 3195, 295, 819, 25879], "temperature": 0.0, "avg_logprob": -0.17746506523840205, "compression_ratio": 1.670940170940171, "no_speech_prob": 1.1478536180220544e-05}, {"id": 1194, "seek": 549806, "start": 5510.620000000001, "end": 5512.34, "text": " So just show you how to do this", "tokens": [407, 445, 855, 291, 577, 281, 360, 341], "temperature": 0.0, "avg_logprob": -0.17746506523840205, "compression_ratio": 1.670940170940171, "no_speech_prob": 1.1478536180220544e-05}, {"id": 1195, "seek": 549806, "start": 5512.34, "end": 5517.26, "text": " I'm going to use the MNIST sample and this is pictures of hand-drawn numbers", "tokens": [286, 478, 516, 281, 764, 264, 376, 45, 19756, 6889, 293, 341, 307, 5242, 295, 1011, 12, 67, 29603, 3547], "temperature": 0.0, "avg_logprob": -0.17746506523840205, "compression_ratio": 1.670940170940171, "no_speech_prob": 1.1478536180220544e-05}, {"id": 1196, "seek": 549806, "start": 5517.26, "end": 5519.9800000000005, "text": " I'm just because I want to show you different ways of", "tokens": [286, 478, 445, 570, 286, 528, 281, 855, 291, 819, 2098, 295], "temperature": 0.0, "avg_logprob": -0.17746506523840205, "compression_ratio": 1.670940170940171, "no_speech_prob": 1.1478536180220544e-05}, {"id": 1197, "seek": 549806, "start": 5522.38, "end": 5524.38, "text": " Creating these data sets", "tokens": [40002, 613, 1412, 6352], "temperature": 0.0, "avg_logprob": -0.17746506523840205, "compression_ratio": 1.670940170940171, "no_speech_prob": 1.1478536180220544e-05}, {"id": 1198, "seek": 552438, "start": 5524.38, "end": 5526.38, "text": " The", "tokens": [440], "temperature": 0.0, "avg_logprob": -0.2625366348818124, "compression_ratio": 1.5958549222797926, "no_speech_prob": 8.939585313783027e-06}, {"id": 1199, "seek": 552438, "start": 5528.22, "end": 5530.22, "text": " The MNIST sample", "tokens": [440, 376, 45, 19756, 6889], "temperature": 0.0, "avg_logprob": -0.2625366348818124, "compression_ratio": 1.5958549222797926, "no_speech_prob": 8.939585313783027e-06}, {"id": 1200, "seek": 552438, "start": 5532.18, "end": 5535.5, "text": " Basically looks like this so I can go path dot LS", "tokens": [8537, 1542, 411, 341, 370, 286, 393, 352, 3100, 5893, 36657], "temperature": 0.0, "avg_logprob": -0.2625366348818124, "compression_ratio": 1.5958549222797926, "no_speech_prob": 8.939585313783027e-06}, {"id": 1201, "seek": 552438, "start": 5536.3, "end": 5540.08, "text": " Okay, and you can see it's got a training set in the validation set already", "tokens": [1033, 11, 293, 291, 393, 536, 309, 311, 658, 257, 3097, 992, 294, 264, 24071, 992, 1217], "temperature": 0.0, "avg_logprob": -0.2625366348818124, "compression_ratio": 1.5958549222797926, "no_speech_prob": 8.939585313783027e-06}, {"id": 1202, "seek": 552438, "start": 5540.08, "end": 5546.08, "text": " So basically the people that put together this data set have already decided what they want you to use as a validation set", "tokens": [407, 1936, 264, 561, 300, 829, 1214, 341, 1412, 992, 362, 1217, 3047, 437, 436, 528, 291, 281, 764, 382, 257, 24071, 992], "temperature": 0.0, "avg_logprob": -0.2625366348818124, "compression_ratio": 1.5958549222797926, "no_speech_prob": 8.939585313783027e-06}, {"id": 1203, "seek": 552438, "start": 5546.42, "end": 5549.58, "text": " Okay, so if you go path slash train", "tokens": [1033, 11, 370, 498, 291, 352, 3100, 17330, 3847], "temperature": 0.0, "avg_logprob": -0.2625366348818124, "compression_ratio": 1.5958549222797926, "no_speech_prob": 8.939585313783027e-06}, {"id": 1204, "seek": 552438, "start": 5550.74, "end": 5552.1, "text": " LS", "tokens": [36657], "temperature": 0.0, "avg_logprob": -0.2625366348818124, "compression_ratio": 1.5958549222797926, "no_speech_prob": 8.939585313783027e-06}, {"id": 1205, "seek": 555210, "start": 5552.1, "end": 5555.620000000001, "text": " You'll see there's a folder called three and a folder called seven", "tokens": [509, 603, 536, 456, 311, 257, 10820, 1219, 1045, 293, 257, 10820, 1219, 3407], "temperature": 0.0, "avg_logprob": -0.18371809021500515, "compression_ratio": 2.0118577075098814, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1206, "seek": 555210, "start": 5555.860000000001, "end": 5556.38, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.18371809021500515, "compression_ratio": 2.0118577075098814, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1207, "seek": 555210, "start": 5556.38, "end": 5559.9800000000005, "text": " Now this is really really common way to just to give people labels", "tokens": [823, 341, 307, 534, 534, 2689, 636, 281, 445, 281, 976, 561, 16949], "temperature": 0.0, "avg_logprob": -0.18371809021500515, "compression_ratio": 2.0118577075098814, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1208, "seek": 555210, "start": 5559.9800000000005, "end": 5564.660000000001, "text": " It's basically to say oh everything that's a three I'll put in a folder called three everything that's a seven", "tokens": [467, 311, 1936, 281, 584, 1954, 1203, 300, 311, 257, 1045, 286, 603, 829, 294, 257, 10820, 1219, 1045, 1203, 300, 311, 257, 3407], "temperature": 0.0, "avg_logprob": -0.18371809021500515, "compression_ratio": 2.0118577075098814, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1209, "seek": 555210, "start": 5564.660000000001, "end": 5566.660000000001, "text": " I'll put in a folder called seven that this is", "tokens": [286, 603, 829, 294, 257, 10820, 1219, 3407, 300, 341, 307], "temperature": 0.0, "avg_logprob": -0.18371809021500515, "compression_ratio": 2.0118577075098814, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1210, "seek": 555210, "start": 5567.34, "end": 5568.820000000001, "text": " often called an", "tokens": [2049, 1219, 364], "temperature": 0.0, "avg_logprob": -0.18371809021500515, "compression_ratio": 2.0118577075098814, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1211, "seek": 555210, "start": 5568.820000000001, "end": 5572.280000000001, "text": " Image net style data set because this is how image net is distributed", "tokens": [29903, 2533, 3758, 1412, 992, 570, 341, 307, 577, 3256, 2533, 307, 12631], "temperature": 0.0, "avg_logprob": -0.18371809021500515, "compression_ratio": 2.0118577075098814, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1212, "seek": 555210, "start": 5572.900000000001, "end": 5580.200000000001, "text": " So if you have something in this format where the the labels are just whatever the folders called you can say from folder", "tokens": [407, 498, 291, 362, 746, 294, 341, 7877, 689, 264, 264, 16949, 366, 445, 2035, 264, 31082, 1219, 291, 393, 584, 490, 10820], "temperature": 0.0, "avg_logprob": -0.18371809021500515, "compression_ratio": 2.0118577075098814, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1213, "seek": 558020, "start": 5580.2, "end": 5583.32, "text": " Okay, and that will create an image data bunch for you", "tokens": [1033, 11, 293, 300, 486, 1884, 364, 3256, 1412, 3840, 337, 291], "temperature": 0.0, "avg_logprob": -0.1638030830873262, "compression_ratio": 1.687732342007435, "no_speech_prob": 4.785057626577327e-06}, {"id": 1214, "seek": 558020, "start": 5583.32, "end": 5589.8, "text": " And as you can see three seven, it's created the labels just by using the folder names", "tokens": [400, 382, 291, 393, 536, 1045, 3407, 11, 309, 311, 2942, 264, 16949, 445, 538, 1228, 264, 10820, 5288], "temperature": 0.0, "avg_logprob": -0.1638030830873262, "compression_ratio": 1.687732342007435, "no_speech_prob": 4.785057626577327e-06}, {"id": 1215, "seek": 558020, "start": 5592.08, "end": 5597.0, "text": " Another possibility and as you can see we can train that get 99.55 percent accuracy blah blah blah", "tokens": [3996, 7959, 293, 382, 291, 393, 536, 321, 393, 3847, 300, 483, 11803, 13, 13622, 3043, 14170, 12288, 12288, 12288], "temperature": 0.0, "avg_logprob": -0.1638030830873262, "compression_ratio": 1.687732342007435, "no_speech_prob": 4.785057626577327e-06}, {"id": 1216, "seek": 558020, "start": 5597.599999999999, "end": 5602.5599999999995, "text": " Another possibility and for this MNIST sample, I've got both it might come with a CSV file", "tokens": [3996, 7959, 293, 337, 341, 376, 45, 19756, 6889, 11, 286, 600, 658, 1293, 309, 1062, 808, 365, 257, 48814, 3991], "temperature": 0.0, "avg_logprob": -0.1638030830873262, "compression_ratio": 1.687732342007435, "no_speech_prob": 4.785057626577327e-06}, {"id": 1217, "seek": 560256, "start": 5602.56, "end": 5609.6, "text": " That would look something like this for each file name. What's its label now in this case? The labels aren't three or seven", "tokens": [663, 576, 574, 746, 411, 341, 337, 1184, 3991, 1315, 13, 708, 311, 1080, 7645, 586, 294, 341, 1389, 30, 440, 16949, 3212, 380, 1045, 420, 3407], "temperature": 0.0, "avg_logprob": -0.20269142497669568, "compression_ratio": 1.7336065573770492, "no_speech_prob": 2.0145340386079624e-05}, {"id": 1218, "seek": 560256, "start": 5609.84, "end": 5613.120000000001, "text": " There's zero or one which is basically is it a seven or not?", "tokens": [821, 311, 4018, 420, 472, 597, 307, 1936, 307, 309, 257, 3407, 420, 406, 30], "temperature": 0.0, "avg_logprob": -0.20269142497669568, "compression_ratio": 1.7336065573770492, "no_speech_prob": 2.0145340386079624e-05}, {"id": 1219, "seek": 560256, "start": 5613.120000000001, "end": 5618.8, "text": " That's that's another possibility. So if this is how your labels are you can use from CSV", "tokens": [663, 311, 300, 311, 1071, 7959, 13, 407, 498, 341, 307, 577, 428, 16949, 366, 291, 393, 764, 490, 48814], "temperature": 0.0, "avg_logprob": -0.20269142497669568, "compression_ratio": 1.7336065573770492, "no_speech_prob": 2.0145340386079624e-05}, {"id": 1220, "seek": 560256, "start": 5619.400000000001, "end": 5623.0, "text": " And if it's called labels dot CSV, you don't even have to pass in a file name", "tokens": [400, 498, 309, 311, 1219, 16949, 5893, 48814, 11, 291, 500, 380, 754, 362, 281, 1320, 294, 257, 3991, 1315], "temperature": 0.0, "avg_logprob": -0.20269142497669568, "compression_ratio": 1.7336065573770492, "no_speech_prob": 2.0145340386079624e-05}, {"id": 1221, "seek": 560256, "start": 5623.0, "end": 5627.4800000000005, "text": " If it's called anything else, then you can call pass in the CSV labels", "tokens": [759, 309, 311, 1219, 1340, 1646, 11, 550, 291, 393, 818, 1320, 294, 264, 48814, 16949], "temperature": 0.0, "avg_logprob": -0.20269142497669568, "compression_ratio": 1.7336065573770492, "no_speech_prob": 2.0145340386079624e-05}, {"id": 1222, "seek": 562748, "start": 5627.48, "end": 5633.679999999999, "text": " So on there, okay, so that's how you can use a CSV. Okay, there it is. This is now is it a seven or not?", "tokens": [407, 322, 456, 11, 1392, 11, 370, 300, 311, 577, 291, 393, 764, 257, 48814, 13, 1033, 11, 456, 309, 307, 13, 639, 307, 586, 307, 309, 257, 3407, 420, 406, 30], "temperature": 0.0, "avg_logprob": -0.24103048206430622, "compression_ratio": 1.7120622568093384, "no_speech_prob": 4.565939434542088e-06}, {"id": 1223, "seek": 562748, "start": 5636.5599999999995, "end": 5641.0, "text": " Another possibility and then you can call data dot passes to see what it found another possibility", "tokens": [3996, 7959, 293, 550, 291, 393, 818, 1412, 5893, 11335, 281, 536, 437, 309, 1352, 1071, 7959], "temperature": 0.0, "avg_logprob": -0.24103048206430622, "compression_ratio": 1.7120622568093384, "no_speech_prob": 4.565939434542088e-06}, {"id": 1224, "seek": 562748, "start": 5641.0, "end": 5644.36, "text": " This as we've seen is you've got paths that look like this", "tokens": [639, 382, 321, 600, 1612, 307, 291, 600, 658, 14518, 300, 574, 411, 341], "temperature": 0.0, "avg_logprob": -0.24103048206430622, "compression_ratio": 1.7120622568093384, "no_speech_prob": 4.565939434542088e-06}, {"id": 1225, "seek": 562748, "start": 5645.28, "end": 5650.299999999999, "text": " And so in this case, this is the same thing. These are the folders, right? I could actually grab the", "tokens": [400, 370, 294, 341, 1389, 11, 341, 307, 264, 912, 551, 13, 1981, 366, 264, 31082, 11, 558, 30, 286, 727, 767, 4444, 264], "temperature": 0.0, "avg_logprob": -0.24103048206430622, "compression_ratio": 1.7120622568093384, "no_speech_prob": 4.565939434542088e-06}, {"id": 1226, "seek": 562748, "start": 5651.4, "end": 5655.879999999999, "text": " The label by using a regular expression and so here's the regular expression", "tokens": [440, 7645, 538, 1228, 257, 3890, 6114, 293, 370, 510, 311, 264, 3890, 6114], "temperature": 0.0, "avg_logprob": -0.24103048206430622, "compression_ratio": 1.7120622568093384, "no_speech_prob": 4.565939434542088e-06}, {"id": 1227, "seek": 565588, "start": 5655.88, "end": 5660.32, "text": " So we've already seen that approach and again, you can see data dot classes has found it", "tokens": [407, 321, 600, 1217, 1612, 300, 3109, 293, 797, 11, 291, 393, 536, 1412, 5893, 5359, 575, 1352, 309], "temperature": 0.0, "avg_logprob": -0.15296880491487272, "compression_ratio": 1.6343612334801763, "no_speech_prob": 2.948007022496313e-06}, {"id": 1228, "seek": 565588, "start": 5661.4400000000005, "end": 5667.4800000000005, "text": " So what if you it's something that's in the file name of a path, but it's not just a regular expression. It's more complex", "tokens": [407, 437, 498, 291, 309, 311, 746, 300, 311, 294, 264, 3991, 1315, 295, 257, 3100, 11, 457, 309, 311, 406, 445, 257, 3890, 6114, 13, 467, 311, 544, 3997], "temperature": 0.0, "avg_logprob": -0.15296880491487272, "compression_ratio": 1.6343612334801763, "no_speech_prob": 2.948007022496313e-06}, {"id": 1229, "seek": 565588, "start": 5668.2, "end": 5674.88, "text": " You can create an arbitrary function that extracts a label from the file name or path and in that case", "tokens": [509, 393, 1884, 364, 23211, 2445, 300, 8947, 82, 257, 7645, 490, 264, 3991, 1315, 420, 3100, 293, 294, 300, 1389], "temperature": 0.0, "avg_logprob": -0.15296880491487272, "compression_ratio": 1.6343612334801763, "no_speech_prob": 2.948007022496313e-06}, {"id": 1230, "seek": 565588, "start": 5674.88, "end": 5676.88, "text": " You would say from name and function", "tokens": [509, 576, 584, 490, 1315, 293, 2445], "temperature": 0.0, "avg_logprob": -0.15296880491487272, "compression_ratio": 1.6343612334801763, "no_speech_prob": 2.948007022496313e-06}, {"id": 1231, "seek": 565588, "start": 5680.7, "end": 5682.7, "text": " Another possibility", "tokens": [3996, 7959], "temperature": 0.0, "avg_logprob": -0.15296880491487272, "compression_ratio": 1.6343612334801763, "no_speech_prob": 2.948007022496313e-06}, {"id": 1232, "seek": 568270, "start": 5682.7, "end": 5686.5199999999995, "text": " Is that even you did something even more flexible than that?", "tokens": [1119, 300, 754, 291, 630, 746, 754, 544, 11358, 813, 300, 30], "temperature": 0.0, "avg_logprob": -0.16591443202292272, "compression_ratio": 1.7942238267148014, "no_speech_prob": 6.04889237365569e-06}, {"id": 1233, "seek": 568270, "start": 5686.5199999999995, "end": 5690.12, "text": " And so you're going to write some code to create an array of labels", "tokens": [400, 370, 291, 434, 516, 281, 2464, 512, 3089, 281, 1884, 364, 10225, 295, 16949], "temperature": 0.0, "avg_logprob": -0.16591443202292272, "compression_ratio": 1.7942238267148014, "no_speech_prob": 6.04889237365569e-06}, {"id": 1234, "seek": 568270, "start": 5690.12, "end": 5693.76, "text": " And so in that case you can just pass in from lists", "tokens": [400, 370, 294, 300, 1389, 291, 393, 445, 1320, 294, 490, 14511], "temperature": 0.0, "avg_logprob": -0.16591443202292272, "compression_ratio": 1.7942238267148014, "no_speech_prob": 6.04889237365569e-06}, {"id": 1235, "seek": 568270, "start": 5693.76, "end": 5698.32, "text": " So here's I've created an array of labels. Here are my labels is from lists", "tokens": [407, 510, 311, 286, 600, 2942, 364, 10225, 295, 16949, 13, 1692, 366, 452, 16949, 307, 490, 14511], "temperature": 0.0, "avg_logprob": -0.16591443202292272, "compression_ratio": 1.7942238267148014, "no_speech_prob": 6.04889237365569e-06}, {"id": 1236, "seek": 568270, "start": 5698.679999999999, "end": 5703.12, "text": " Okay, and then I just pass in that rate so you can see there's lots of different ways of creating labels", "tokens": [1033, 11, 293, 550, 286, 445, 1320, 294, 300, 3314, 370, 291, 393, 536, 456, 311, 3195, 295, 819, 2098, 295, 4084, 16949], "temperature": 0.0, "avg_logprob": -0.16591443202292272, "compression_ratio": 1.7942238267148014, "no_speech_prob": 6.04889237365569e-06}, {"id": 1237, "seek": 568270, "start": 5703.12, "end": 5705.12, "text": " So so during the week", "tokens": [407, 370, 1830, 264, 1243], "temperature": 0.0, "avg_logprob": -0.16591443202292272, "compression_ratio": 1.7942238267148014, "no_speech_prob": 6.04889237365569e-06}, {"id": 1238, "seek": 568270, "start": 5705.28, "end": 5707.28, "text": " Try this out now. You might be wondering", "tokens": [6526, 341, 484, 586, 13, 509, 1062, 312, 6359], "temperature": 0.0, "avg_logprob": -0.16591443202292272, "compression_ratio": 1.7942238267148014, "no_speech_prob": 6.04889237365569e-06}, {"id": 1239, "seek": 568270, "start": 5707.92, "end": 5711.16, "text": " How would you know to do all these things like where am I going to find?", "tokens": [1012, 576, 291, 458, 281, 360, 439, 613, 721, 411, 689, 669, 286, 516, 281, 915, 30], "temperature": 0.0, "avg_logprob": -0.16591443202292272, "compression_ratio": 1.7942238267148014, "no_speech_prob": 6.04889237365569e-06}, {"id": 1240, "seek": 571116, "start": 5711.16, "end": 5712.12, "text": " this", "tokens": [341], "temperature": 0.0, "avg_logprob": -0.24540955992950791, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.080425115826074e-06}, {"id": 1241, "seek": 571116, "start": 5712.12, "end": 5716.96, "text": " Kind of information right? How would I how do you possibly know to do all this stuff?", "tokens": [9242, 295, 1589, 558, 30, 1012, 576, 286, 577, 360, 291, 6264, 458, 281, 360, 439, 341, 1507, 30], "temperature": 0.0, "avg_logprob": -0.24540955992950791, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.080425115826074e-06}, {"id": 1242, "seek": 571116, "start": 5717.36, "end": 5721.88, "text": " So I'll show you something incredibly cool. Let's grab this function and", "tokens": [407, 286, 603, 855, 291, 746, 6252, 1627, 13, 961, 311, 4444, 341, 2445, 293], "temperature": 0.0, "avg_logprob": -0.24540955992950791, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.080425115826074e-06}, {"id": 1243, "seek": 571116, "start": 5722.84, "end": 5726.0, "text": " Do you remember to get documentation we type doc?", "tokens": [1144, 291, 1604, 281, 483, 14333, 321, 2010, 3211, 30], "temperature": 0.0, "avg_logprob": -0.24540955992950791, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.080425115826074e-06}, {"id": 1244, "seek": 571116, "start": 5728.32, "end": 5733.639999999999, "text": " And here is the documentation for the function and I can click show in docs and", "tokens": [400, 510, 307, 264, 14333, 337, 264, 2445, 293, 286, 393, 2052, 855, 294, 45623, 293], "temperature": 0.0, "avg_logprob": -0.24540955992950791, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.080425115826074e-06}, {"id": 1245, "seek": 571116, "start": 5735.12, "end": 5737.12, "text": " It pops up the documentation", "tokens": [467, 16795, 493, 264, 14333], "temperature": 0.0, "avg_logprob": -0.24540955992950791, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.080425115826074e-06}, {"id": 1246, "seek": 571116, "start": 5737.639999999999, "end": 5739.639999999999, "text": " So here's the thing", "tokens": [407, 510, 311, 264, 551], "temperature": 0.0, "avg_logprob": -0.24540955992950791, "compression_ratio": 1.6764705882352942, "no_speech_prob": 9.080425115826074e-06}, {"id": 1247, "seek": 573964, "start": 5739.64, "end": 5746.58, "text": " Every single line of code I just showed you I took it this morning, and I copied and pasted it from the documentation", "tokens": [2048, 2167, 1622, 295, 3089, 286, 445, 4712, 291, 286, 1890, 309, 341, 2446, 11, 293, 286, 25365, 293, 1791, 292, 309, 490, 264, 14333], "temperature": 0.0, "avg_logprob": -0.18248225981930652, "compression_ratio": 1.6262626262626263, "no_speech_prob": 1.505696900494513e-06}, {"id": 1248, "seek": 573964, "start": 5748.160000000001, "end": 5751.08, "text": " So you can see here the exact", "tokens": [407, 291, 393, 536, 510, 264, 1900], "temperature": 0.0, "avg_logprob": -0.18248225981930652, "compression_ratio": 1.6262626262626263, "no_speech_prob": 1.505696900494513e-06}, {"id": 1249, "seek": 573964, "start": 5752.4400000000005, "end": 5756.68, "text": " Code that I just used so the documentation for fast AI doesn't just tell you", "tokens": [15549, 300, 286, 445, 1143, 370, 264, 14333, 337, 2370, 7318, 1177, 380, 445, 980, 291], "temperature": 0.0, "avg_logprob": -0.18248225981930652, "compression_ratio": 1.6262626262626263, "no_speech_prob": 1.505696900494513e-06}, {"id": 1250, "seek": 573964, "start": 5757.64, "end": 5761.400000000001, "text": " What to do but step to step how to do it and", "tokens": [708, 281, 360, 457, 1823, 281, 1823, 577, 281, 360, 309, 293], "temperature": 0.0, "avg_logprob": -0.18248225981930652, "compression_ratio": 1.6262626262626263, "no_speech_prob": 1.505696900494513e-06}, {"id": 1251, "seek": 576140, "start": 5761.4, "end": 5769.759999999999, "text": " Here is perhaps the coolest bit if you go to fast AI fast AI", "tokens": [1692, 307, 4317, 264, 22013, 857, 498, 291, 352, 281, 2370, 7318, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.2728698462770696, "compression_ratio": 1.4135802469135803, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1252, "seek": 576140, "start": 5771.2, "end": 5775.799999999999, "text": " Underscore docs and click on doc source", "tokens": [2719, 433, 12352, 45623, 293, 2052, 322, 3211, 4009], "temperature": 0.0, "avg_logprob": -0.2728698462770696, "compression_ratio": 1.4135802469135803, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1253, "seek": 576140, "start": 5777.5599999999995, "end": 5785.2, "text": " It turns out that all of our documentation is actually just Jupiter notebooks. So in this case, I was looking at vision dot data", "tokens": [467, 4523, 484, 300, 439, 295, 527, 14333, 307, 767, 445, 24567, 43782, 13, 407, 294, 341, 1389, 11, 286, 390, 1237, 412, 5201, 5893, 1412], "temperature": 0.0, "avg_logprob": -0.2728698462770696, "compression_ratio": 1.4135802469135803, "no_speech_prob": 2.6016034553322243e-06}, {"id": 1254, "seek": 578520, "start": 5785.2, "end": 5794.16, "text": " So here is the vision dot data notebook you can download this repo you can get cloned up and", "tokens": [407, 510, 307, 264, 5201, 5893, 1412, 21060, 291, 393, 5484, 341, 49040, 291, 393, 483, 596, 19009, 493, 293], "temperature": 0.0, "avg_logprob": -0.2456704876090907, "compression_ratio": 1.597938144329897, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1255, "seek": 578520, "start": 5794.599999999999, "end": 5797.08, "text": " If you run it, you can actually run", "tokens": [759, 291, 1190, 309, 11, 291, 393, 767, 1190], "temperature": 0.0, "avg_logprob": -0.2456704876090907, "compression_ratio": 1.597938144329897, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1256, "seek": 578520, "start": 5797.72, "end": 5800.2, "text": " Every single line of the documentation yourself", "tokens": [2048, 2167, 1622, 295, 264, 14333, 1803], "temperature": 0.0, "avg_logprob": -0.2456704876090907, "compression_ratio": 1.597938144329897, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1257, "seek": 578520, "start": 5801.5199999999995, "end": 5809.84, "text": " Okay, so so all of our docs is also code and so like this is the kind of the ultimate example to me of", "tokens": [1033, 11, 370, 370, 439, 295, 527, 45623, 307, 611, 3089, 293, 370, 411, 341, 307, 264, 733, 295, 264, 9705, 1365, 281, 385, 295], "temperature": 0.0, "avg_logprob": -0.2456704876090907, "compression_ratio": 1.597938144329897, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1258, "seek": 578520, "start": 5811.12, "end": 5812.44, "text": " of", "tokens": [295], "temperature": 0.0, "avg_logprob": -0.2456704876090907, "compression_ratio": 1.597938144329897, "no_speech_prob": 2.2252736471273238e-06}, {"id": 1259, "seek": 581244, "start": 5812.44, "end": 5816.12, "text": " Experimenting right is that you can now", "tokens": [37933, 278, 558, 307, 300, 291, 393, 586], "temperature": 0.0, "avg_logprob": -0.1907017583432405, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.72313903021859e-05}, {"id": 1260, "seek": 581244, "start": 5816.96, "end": 5819.679999999999, "text": " Experiment and you'll see in in github", "tokens": [37933, 293, 291, 603, 536, 294, 294, 290, 355, 836], "temperature": 0.0, "avg_logprob": -0.1907017583432405, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.72313903021859e-05}, {"id": 1261, "seek": 581244, "start": 5819.679999999999, "end": 5824.2, "text": " It doesn't quite render properly because github doesn't quite know how to render notebooks properly", "tokens": [467, 1177, 380, 1596, 15529, 6108, 570, 290, 355, 836, 1177, 380, 1596, 458, 577, 281, 15529, 43782, 6108], "temperature": 0.0, "avg_logprob": -0.1907017583432405, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.72313903021859e-05}, {"id": 1262, "seek": 581244, "start": 5824.2, "end": 5826.799999999999, "text": " But if you get plumb this and open it up in Jupiter", "tokens": [583, 498, 291, 483, 499, 2860, 341, 293, 1269, 309, 493, 294, 24567], "temperature": 0.0, "avg_logprob": -0.1907017583432405, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.72313903021859e-05}, {"id": 1263, "seek": 581244, "start": 5827.28, "end": 5831.12, "text": " You can see it and so now anything that you read about in the documentation", "tokens": [509, 393, 536, 309, 293, 370, 586, 1340, 300, 291, 1401, 466, 294, 264, 14333], "temperature": 0.0, "avg_logprob": -0.1907017583432405, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.72313903021859e-05}, {"id": 1264, "seek": 581244, "start": 5831.639999999999, "end": 5837.96, "text": " Nearly everything in the documentation has actual working examples in it with actual data sets that are already sitting in there in the repo", "tokens": [38000, 1203, 294, 264, 14333, 575, 3539, 1364, 5110, 294, 309, 365, 3539, 1412, 6352, 300, 366, 1217, 3798, 294, 456, 294, 264, 49040], "temperature": 0.0, "avg_logprob": -0.1907017583432405, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.72313903021859e-05}, {"id": 1265, "seek": 583796, "start": 5837.96, "end": 5845.8, "text": " For you and so you can actually try every single function in your browser try seeing what goes in and try seeing", "tokens": [1171, 291, 293, 370, 291, 393, 767, 853, 633, 2167, 2445, 294, 428, 11185, 853, 2577, 437, 1709, 294, 293, 853, 2577], "temperature": 0.0, "avg_logprob": -0.20034189224243165, "compression_ratio": 1.6624472573839661, "no_speech_prob": 1.0451408343215007e-05}, {"id": 1266, "seek": 583796, "start": 5845.96, "end": 5847.96, "text": " What comes out?", "tokens": [708, 1487, 484, 30], "temperature": 0.0, "avg_logprob": -0.20034189224243165, "compression_ratio": 1.6624472573839661, "no_speech_prob": 1.0451408343215007e-05}, {"id": 1267, "seek": 583796, "start": 5848.28, "end": 5850.28, "text": " There's a question", "tokens": [821, 311, 257, 1168], "temperature": 0.0, "avg_logprob": -0.20034189224243165, "compression_ratio": 1.6624472573839661, "no_speech_prob": 1.0451408343215007e-05}, {"id": 1268, "seek": 583796, "start": 5850.28, "end": 5853.92, "text": " Will the library use multi GPU and parallel by default?", "tokens": [3099, 264, 6405, 764, 4825, 18407, 293, 8952, 538, 7576, 30], "temperature": 0.0, "avg_logprob": -0.20034189224243165, "compression_ratio": 1.6624472573839661, "no_speech_prob": 1.0451408343215007e-05}, {"id": 1269, "seek": 583796, "start": 5855.64, "end": 5860.2, "text": " The library will use multiple CPUs by default, but just one GPU by default", "tokens": [440, 6405, 486, 764, 3866, 13199, 82, 538, 7576, 11, 457, 445, 472, 18407, 538, 7576], "temperature": 0.0, "avg_logprob": -0.20034189224243165, "compression_ratio": 1.6624472573839661, "no_speech_prob": 1.0451408343215007e-05}, {"id": 1270, "seek": 583796, "start": 5860.44, "end": 5866.76, "text": " We've probably what we're looking at multi GPU until part two. It's easy to do and you'll find it on the forum, but", "tokens": [492, 600, 1391, 437, 321, 434, 1237, 412, 4825, 18407, 1826, 644, 732, 13, 467, 311, 1858, 281, 360, 293, 291, 603, 915, 309, 322, 264, 17542, 11, 457], "temperature": 0.0, "avg_logprob": -0.20034189224243165, "compression_ratio": 1.6624472573839661, "no_speech_prob": 1.0451408343215007e-05}, {"id": 1271, "seek": 586676, "start": 5866.76, "end": 5869.76, "text": " Most people won't be needing to use that now", "tokens": [4534, 561, 1582, 380, 312, 18006, 281, 764, 300, 586], "temperature": 0.0, "avg_logprob": -0.21846807845915206, "compression_ratio": 1.5241935483870968, "no_speech_prob": 1.98327634279849e-05}, {"id": 1272, "seek": 586676, "start": 5870.4800000000005, "end": 5873.88, "text": " And the second question is whether the library can use", "tokens": [400, 264, 1150, 1168, 307, 1968, 264, 6405, 393, 764], "temperature": 0.0, "avg_logprob": -0.21846807845915206, "compression_ratio": 1.5241935483870968, "no_speech_prob": 1.98327634279849e-05}, {"id": 1273, "seek": 586676, "start": 5874.88, "end": 5876.88, "text": " 3d data such as MRI or", "tokens": [805, 67, 1412, 1270, 382, 32812, 420], "temperature": 0.0, "avg_logprob": -0.21846807845915206, "compression_ratio": 1.5241935483870968, "no_speech_prob": 1.98327634279849e-05}, {"id": 1274, "seek": 586676, "start": 5879.400000000001, "end": 5883.96, "text": " Yes, it can and there is actually a forum thread about that already", "tokens": [1079, 11, 309, 393, 293, 456, 307, 767, 257, 17542, 7207, 466, 300, 1217], "temperature": 0.0, "avg_logprob": -0.21846807845915206, "compression_ratio": 1.5241935483870968, "no_speech_prob": 1.98327634279849e-05}, {"id": 1275, "seek": 586676, "start": 5884.88, "end": 5889.0, "text": " Although that's not as developed as 2d yet, but maybe by the time the MOOC is out it will be", "tokens": [5780, 300, 311, 406, 382, 4743, 382, 568, 67, 1939, 11, 457, 1310, 538, 264, 565, 264, 49197, 34, 307, 484, 309, 486, 312], "temperature": 0.0, "avg_logprob": -0.21846807845915206, "compression_ratio": 1.5241935483870968, "no_speech_prob": 1.98327634279849e-05}, {"id": 1276, "seek": 588900, "start": 5889.0, "end": 5897.28, "text": " So before I wrap up I'll just show an example of the kind of interesting stuff that you can do by", "tokens": [407, 949, 286, 7019, 493, 286, 603, 445, 855, 364, 1365, 295, 264, 733, 295, 1880, 1507, 300, 291, 393, 360, 538], "temperature": 0.0, "avg_logprob": -0.26016515234242316, "compression_ratio": 1.5168067226890756, "no_speech_prob": 3.3211297704838216e-05}, {"id": 1277, "seek": 588900, "start": 5898.24, "end": 5900.24, "text": " Doing this kind of exercise", "tokens": [18496, 341, 733, 295, 5380], "temperature": 0.0, "avg_logprob": -0.26016515234242316, "compression_ratio": 1.5168067226890756, "no_speech_prob": 3.3211297704838216e-05}, {"id": 1278, "seek": 588900, "start": 5900.24, "end": 5905.64, "text": " Remember earlier I mentioned that one of our alums who works at Splunk which is the", "tokens": [5459, 3071, 286, 2835, 300, 472, 295, 527, 419, 8099, 567, 1985, 412, 19788, 3197, 597, 307, 264], "temperature": 0.0, "avg_logprob": -0.26016515234242316, "compression_ratio": 1.5168067226890756, "no_speech_prob": 3.3211297704838216e-05}, {"id": 1279, "seek": 588900, "start": 5906.64, "end": 5908.88, "text": " Nasdaq listed big successful company", "tokens": [16151, 2675, 80, 10052, 955, 4406, 2237], "temperature": 0.0, "avg_logprob": -0.26016515234242316, "compression_ratio": 1.5168067226890756, "no_speech_prob": 3.3211297704838216e-05}, {"id": 1280, "seek": 588900, "start": 5909.84, "end": 5911.84, "text": " Create this new anti-fraud software", "tokens": [20248, 341, 777, 6061, 12, 69, 424, 532, 4722], "temperature": 0.0, "avg_logprob": -0.26016515234242316, "compression_ratio": 1.5168067226890756, "no_speech_prob": 3.3211297704838216e-05}, {"id": 1281, "seek": 588900, "start": 5912.28, "end": 5918.16, "text": " This is actually how he created it as part of a fast AI part one class project", "tokens": [639, 307, 767, 577, 415, 2942, 309, 382, 644, 295, 257, 2370, 7318, 644, 472, 1508, 1716], "temperature": 0.0, "avg_logprob": -0.26016515234242316, "compression_ratio": 1.5168067226890756, "no_speech_prob": 3.3211297704838216e-05}, {"id": 1282, "seek": 591816, "start": 5918.16, "end": 5925.86, "text": " He took the telemetry of the users who had Splunk analytics installed and watched their mouse movements", "tokens": [634, 1890, 264, 4304, 5537, 627, 295, 264, 5022, 567, 632, 19788, 3197, 15370, 8899, 293, 6337, 641, 9719, 9981], "temperature": 0.0, "avg_logprob": -0.2681684028811571, "compression_ratio": 1.6635071090047393, "no_speech_prob": 7.527848083555e-06}, {"id": 1283, "seek": 591816, "start": 5925.96, "end": 5929.84, "text": " And it created pictures of the mouse movements. He converted speed into", "tokens": [400, 309, 2942, 5242, 295, 264, 9719, 9981, 13, 634, 16424, 3073, 666], "temperature": 0.0, "avg_logprob": -0.2681684028811571, "compression_ratio": 1.6635071090047393, "no_speech_prob": 7.527848083555e-06}, {"id": 1284, "seek": 591816, "start": 5930.5599999999995, "end": 5934.5599999999995, "text": " color and bright and left clicks into splotches", "tokens": [2017, 293, 4730, 293, 1411, 18521, 666, 4732, 310, 3781], "temperature": 0.0, "avg_logprob": -0.2681684028811571, "compression_ratio": 1.6635071090047393, "no_speech_prob": 7.527848083555e-06}, {"id": 1285, "seek": 591816, "start": 5935.0, "end": 5940.04, "text": " he then took the exact code that we saw with an earlier version of the software and", "tokens": [415, 550, 1890, 264, 1900, 3089, 300, 321, 1866, 365, 364, 3071, 3037, 295, 264, 4722, 293], "temperature": 0.0, "avg_logprob": -0.2681684028811571, "compression_ratio": 1.6635071090047393, "no_speech_prob": 7.527848083555e-06}, {"id": 1286, "seek": 591816, "start": 5940.44, "end": 5943.2, "text": " trained a CNN in exactly the way we saw and", "tokens": [8895, 257, 24859, 294, 2293, 264, 636, 321, 1866, 293], "temperature": 0.0, "avg_logprob": -0.2681684028811571, "compression_ratio": 1.6635071090047393, "no_speech_prob": 7.527848083555e-06}, {"id": 1287, "seek": 594320, "start": 5943.2, "end": 5951.16, "text": " Use that to train his fraud model. So he basically took something which is not obviously a picture and he turned it into a picture", "tokens": [8278, 300, 281, 3847, 702, 14560, 2316, 13, 407, 415, 1936, 1890, 746, 597, 307, 406, 2745, 257, 3036, 293, 415, 3574, 309, 666, 257, 3036], "temperature": 0.0, "avg_logprob": -0.165430177961077, "compression_ratio": 1.700374531835206, "no_speech_prob": 3.1875331387709593e-06}, {"id": 1288, "seek": 594320, "start": 5952.24, "end": 5959.12, "text": " And got these fantastically good results for a piece of fraud analysis software. So it pays to think", "tokens": [400, 658, 613, 4115, 22808, 665, 3542, 337, 257, 2522, 295, 14560, 5215, 4722, 13, 407, 309, 10604, 281, 519], "temperature": 0.0, "avg_logprob": -0.165430177961077, "compression_ratio": 1.700374531835206, "no_speech_prob": 3.1875331387709593e-06}, {"id": 1289, "seek": 594320, "start": 5960.16, "end": 5967.32, "text": " Creatively, so if you're wanting to study sounds a lot of people that study sounds do it by actually creating a spectrogram image and", "tokens": [11972, 3413, 11, 370, 498, 291, 434, 7935, 281, 2979, 3263, 257, 688, 295, 561, 300, 2979, 3263, 360, 309, 538, 767, 4084, 257, 6177, 340, 1342, 3256, 293], "temperature": 0.0, "avg_logprob": -0.165430177961077, "compression_ratio": 1.700374531835206, "no_speech_prob": 3.1875331387709593e-06}, {"id": 1290, "seek": 594320, "start": 5967.5599999999995, "end": 5971.28, "text": " Then sticking that into a component. So there's a lot of cool stuff you can do with this", "tokens": [1396, 13465, 300, 666, 257, 6542, 13, 407, 456, 311, 257, 688, 295, 1627, 1507, 291, 393, 360, 365, 341], "temperature": 0.0, "avg_logprob": -0.165430177961077, "compression_ratio": 1.700374531835206, "no_speech_prob": 3.1875331387709593e-06}, {"id": 1291, "seek": 597128, "start": 5971.28, "end": 5976.5599999999995, "text": " So during the week, yeah get your get your GPU going try and use your first notebook", "tokens": [407, 1830, 264, 1243, 11, 1338, 483, 428, 483, 428, 18407, 516, 853, 293, 764, 428, 700, 21060], "temperature": 0.0, "avg_logprob": -0.20335947119671366, "compression_ratio": 1.7038461538461538, "no_speech_prob": 9.818093531066552e-06}, {"id": 1292, "seek": 597128, "start": 5976.719999999999, "end": 5982.28, "text": " Make sure that you can use less than one and work through it and then see if you can repeat the process", "tokens": [4387, 988, 300, 291, 393, 764, 1570, 813, 472, 293, 589, 807, 309, 293, 550, 536, 498, 291, 393, 7149, 264, 1399], "temperature": 0.0, "avg_logprob": -0.20335947119671366, "compression_ratio": 1.7038461538461538, "no_speech_prob": 9.818093531066552e-06}, {"id": 1293, "seek": 597128, "start": 5982.599999999999, "end": 5988.0199999999995, "text": " On your own data set get on the forum and tell us any little success you had", "tokens": [1282, 428, 1065, 1412, 992, 483, 322, 264, 17542, 293, 980, 505, 604, 707, 2245, 291, 632], "temperature": 0.0, "avg_logprob": -0.20335947119671366, "compression_ratio": 1.7038461538461538, "no_speech_prob": 9.818093531066552e-06}, {"id": 1294, "seek": 597128, "start": 5988.0199999999995, "end": 5991.7, "text": " It's like oh, I spent three days trying to get my GPU running and I finally did", "tokens": [467, 311, 411, 1954, 11, 286, 4418, 1045, 1708, 1382, 281, 483, 452, 18407, 2614, 293, 286, 2721, 630], "temperature": 0.0, "avg_logprob": -0.20335947119671366, "compression_ratio": 1.7038461538461538, "no_speech_prob": 9.818093531066552e-06}, {"id": 1295, "seek": 597128, "start": 5992.44, "end": 5994.0, "text": " any", "tokens": [604], "temperature": 0.0, "avg_logprob": -0.20335947119671366, "compression_ratio": 1.7038461538461538, "no_speech_prob": 9.818093531066552e-06}, {"id": 1296, "seek": 597128, "start": 5994.0, "end": 5995.719999999999, "text": " constraints that you hit", "tokens": [18491, 300, 291, 2045], "temperature": 0.0, "avg_logprob": -0.20335947119671366, "compression_ratio": 1.7038461538461538, "no_speech_prob": 9.818093531066552e-06}, {"id": 1297, "seek": 597128, "start": 5995.719999999999, "end": 5999.4, "text": " You know try it for an hour or two, but if you get stuck, please ask", "tokens": [509, 458, 853, 309, 337, 364, 1773, 420, 732, 11, 457, 498, 291, 483, 5541, 11, 1767, 1029], "temperature": 0.0, "avg_logprob": -0.20335947119671366, "compression_ratio": 1.7038461538461538, "no_speech_prob": 9.818093531066552e-06}, {"id": 1298, "seek": 599940, "start": 5999.4, "end": 6006.639999999999, "text": " And if you're able to successfully build a model with a new data set, let us know and I will see you next week", "tokens": [50364, 400, 498, 291, 434, 1075, 281, 10727, 1322, 257, 2316, 365, 257, 777, 1412, 992, 11, 718, 505, 458, 293, 286, 486, 536, 291, 958, 1243, 50726], "temperature": 0.0, "avg_logprob": -0.09526350580412767, "compression_ratio": 1.1458333333333333, "no_speech_prob": 3.53476352756843e-05}], "language": "en"}