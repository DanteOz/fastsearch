{"text": " But instead of telling you all this now, I'd love to introduce Jeremy Howard, who will show you how Mojo works in practice. Thanks Chris. You know, I realized it's been 30 years since I first trained a neural network. And to be honest, I haven't been that satisfied with any of the languages that I've been able to use throughout that time. In fact, I complained to Chris about this when I first met him years ago. And Chris has been telling me ever since, don't worry, Jeremy, one day we are going to fix this. The thing that I really want to fix is to see a language where I can write performant, flexible, hardcore code, but it should also be concise, readable, understandable code. And I think that actually Chris and his team here have done it with this new language called Mojo. Mojo is actually a superset of Python. So I can use my Python code. Here, check this out. I'll show you what I mean. So here is a notebook, right? But this notebook is no normal notebook. This is a Mojo notebook. And by way of demonstration, because this is the most fundamental foundational algorithm in deep learning, we're going to look at matrix multiplication. Now, of course, Mojo has got its own, we don't need to write our own, but we're just showing here we can actually write our own high performance matrix multiplication. Let's start by comparing to Python. That's very easy to do because we can just type %python in a Mojo notebook, and then it actually is going to run it on the CPython interpreter. So here's our basic matrix multiplication, go across the rows and the columns, multiply together, add it up. Let's write a little matrix and a little benchmark and try it out. And oh, dear, 0.005 gigaflops. That's not great. How do we speed it up? Well, actually, believe it or not, we just take that code, we copy and paste it into a new cell without the %python. And because Mojo is a superset of Python, this runs too. But this time it runs in Mojo, not in Python. And immediately, we get an 8.5 times speed up. Now, there's a lot of performance left on the table here. And to go faster, we're going to want a nice, fast, compact matrix type. Of course, we can use the one that Mojo provides for us. But just to show you that we can, here we've implemented it from scratch. So we're actually creating a struct here. This is nice, compact in memory. And it's got the normal things we're used to, like done to get item and done to set item and stuff you don't expect to see in Python, like alloc and like SIMD. And as you can see, the whole thing fits in about a page of code, a screen of code. So that's our matrix. And so to use it, we take copy and paste the code again, but this time just add a type annotation. And now, it's a 300 times speed up. Suddenly, things are looking pretty amazing. But there's a lot more we can do. We can look at doing, if our CPU supports it, say, 8 elements at a time using SIMD instructions. It's a bit of a mess to do that manually. There's quite a bit of code. But we can do it manually. And we get a 570 times speed up. But better still, we can just call vectorize. So just write a dot product operation, call vectorize, and it will automatically handle it on SIMD for us with the same performance speed up. So that's going to be happening in the innermost loop. We're going to be using SIMD. And in the outermost loop, what if we just call paralyze? This is something we can do. And now, suddenly, the rows are going to be done on separate cores for a 2,000 times speed up. So we've only got four cores going on here. So it's not huge. If you've got more cores, it'll be much bigger. This is something you absolutely can't do with Python. You can do some very, very basic parallel processing with Python. But it's literally creating separate processes and having to move memory around. And it's pretty nasty. And there's all kinds of complexities around the global interpreter lock and so forth as well. This is how easy it is in Mojo. And so suddenly, we've got a 2,000 times faster matrix multiplication written from scratch. We can also make sure that we're using the cache really effectively by doing tiling. So doing a few bits of memory that's close to each other at a time and reusing them. Tiling is as easy as creating this little tiling function and then calling it to tile our function. So now, we've got something that is paralyzed, tiled, and vectorized for a 2,170 times speed up over Python. We can also add unrolling for a 2,200 times speed up. So vectorize unroll is already built into Mojo. So we don't even have to write that. Now, there's a lot of complexity here, though. Like what tile size do we use? How many processes? What SIMD size? All this mess to worry about. And each different person you deploy to is going to have different versions of these. They'll have different memory. They're going to have different CPUs and so forth. No worries. Look at what you can do. We can create an auto-tuned version by simply calling auto-tune. So if we want an auto-tuned tile size, we just say, hey, Mojo, try these different tile sizes for us. Figure out which one's the fastest. Compile the fastest version for us. Cache it for this individual computer and then use that paralyzed, tiled, unrolled, vectorized for a 4,164 times speed up. So this is pretty remarkable, right? Now, it's not just linear algebra stuff. We can do really iterative stuff like calculating Mandelbrot. So we can create our own complex number type and it's going to be a struct. So again, it's going to be compact in memory. It looks like absolutely standard Python, as you can see, multiplying, subtracting, using the operations. And to create the Mandelbrot kernel, we just take the classic Mandelbrot set equation, iterative equation, and pop it in Python here. And then we can call it a bunch of times in a loop, returning at the appropriate time to compute the Mandelbrot set. That's all very well and good. Did it work? Well, it'd be nice to look at it. So how would you look at it? Well, it'd be nice to use matplotlib. Oh, no worries. Every single Python library works in Mojo. And you can import it. Check this out. Plot is import the Python module, matplotlib. mp is import the module, numpy, and the rest of it. This is actually Mojo code, but it's also Python code. And it works. And I don't know if you remember, but Chris actually said the Mandelbrot set is 35,000 times faster than Python. And that's because we can also do an even faster version where we're handling it with SIMD. And we can actually create the kind of iterative algorithm that you just can't do in Python, even with the help of stuff like numpy. This is something which is really unique to Mojo. So we now have something here which is incredibly flexible, incredibly fast, can utilize the hardware you have no matter what it is, and is really understandable to Python programmers like you and me. I think finally we're at a point where we are going to have something where I actually enjoy writing neural networks. Wow! How awesome was that?", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.48, "text": " But instead of telling you all this now, I'd love to introduce Jeremy Howard, who will", "tokens": [50364, 583, 2602, 295, 3585, 291, 439, 341, 586, 11, 286, 1116, 959, 281, 5366, 17809, 17626, 11, 567, 486, 50588], "temperature": 0.0, "avg_logprob": -0.24521841696642954, "compression_ratio": 1.5622641509433963, "no_speech_prob": 0.5519089102745056}, {"id": 1, "seek": 0, "start": 4.48, "end": 10.44, "text": " show you how Mojo works in practice.", "tokens": [50588, 855, 291, 577, 3335, 5134, 1985, 294, 3124, 13, 50886], "temperature": 0.0, "avg_logprob": -0.24521841696642954, "compression_ratio": 1.5622641509433963, "no_speech_prob": 0.5519089102745056}, {"id": 2, "seek": 0, "start": 10.44, "end": 11.44, "text": " Thanks Chris.", "tokens": [50886, 2561, 6688, 13, 50936], "temperature": 0.0, "avg_logprob": -0.24521841696642954, "compression_ratio": 1.5622641509433963, "no_speech_prob": 0.5519089102745056}, {"id": 3, "seek": 0, "start": 11.44, "end": 16.76, "text": " You know, I realized it's been 30 years since I first trained a neural network.", "tokens": [50936, 509, 458, 11, 286, 5334, 309, 311, 668, 2217, 924, 1670, 286, 700, 8895, 257, 18161, 3209, 13, 51202], "temperature": 0.0, "avg_logprob": -0.24521841696642954, "compression_ratio": 1.5622641509433963, "no_speech_prob": 0.5519089102745056}, {"id": 4, "seek": 0, "start": 16.76, "end": 21.36, "text": " And to be honest, I haven't been that satisfied with any of the languages that I've been able", "tokens": [51202, 400, 281, 312, 3245, 11, 286, 2378, 380, 668, 300, 11239, 365, 604, 295, 264, 8650, 300, 286, 600, 668, 1075, 51432], "temperature": 0.0, "avg_logprob": -0.24521841696642954, "compression_ratio": 1.5622641509433963, "no_speech_prob": 0.5519089102745056}, {"id": 5, "seek": 0, "start": 21.36, "end": 23.48, "text": " to use throughout that time.", "tokens": [51432, 281, 764, 3710, 300, 565, 13, 51538], "temperature": 0.0, "avg_logprob": -0.24521841696642954, "compression_ratio": 1.5622641509433963, "no_speech_prob": 0.5519089102745056}, {"id": 6, "seek": 0, "start": 23.48, "end": 28.54, "text": " In fact, I complained to Chris about this when I first met him years ago.", "tokens": [51538, 682, 1186, 11, 286, 33951, 281, 6688, 466, 341, 562, 286, 700, 1131, 796, 924, 2057, 13, 51791], "temperature": 0.0, "avg_logprob": -0.24521841696642954, "compression_ratio": 1.5622641509433963, "no_speech_prob": 0.5519089102745056}, {"id": 7, "seek": 2854, "start": 28.54, "end": 33.26, "text": " And Chris has been telling me ever since, don't worry, Jeremy, one day we are going", "tokens": [50364, 400, 6688, 575, 668, 3585, 385, 1562, 1670, 11, 500, 380, 3292, 11, 17809, 11, 472, 786, 321, 366, 516, 50600], "temperature": 0.0, "avg_logprob": -0.2662985324859619, "compression_ratio": 1.5635593220338984, "no_speech_prob": 0.017170321196317673}, {"id": 8, "seek": 2854, "start": 33.26, "end": 34.26, "text": " to fix this.", "tokens": [50600, 281, 3191, 341, 13, 50650], "temperature": 0.0, "avg_logprob": -0.2662985324859619, "compression_ratio": 1.5635593220338984, "no_speech_prob": 0.017170321196317673}, {"id": 9, "seek": 2854, "start": 34.26, "end": 41.34, "text": " The thing that I really want to fix is to see a language where I can write performant,", "tokens": [50650, 440, 551, 300, 286, 534, 528, 281, 3191, 307, 281, 536, 257, 2856, 689, 286, 393, 2464, 2042, 394, 11, 51004], "temperature": 0.0, "avg_logprob": -0.2662985324859619, "compression_ratio": 1.5635593220338984, "no_speech_prob": 0.017170321196317673}, {"id": 10, "seek": 2854, "start": 41.34, "end": 48.980000000000004, "text": " flexible, hardcore code, but it should also be concise, readable, understandable code.", "tokens": [51004, 11358, 11, 28196, 3089, 11, 457, 309, 820, 611, 312, 44882, 11, 49857, 11, 25648, 3089, 13, 51386], "temperature": 0.0, "avg_logprob": -0.2662985324859619, "compression_ratio": 1.5635593220338984, "no_speech_prob": 0.017170321196317673}, {"id": 11, "seek": 2854, "start": 48.980000000000004, "end": 55.14, "text": " And I think that actually Chris and his team here have done it with this new language called", "tokens": [51386, 400, 286, 519, 300, 767, 6688, 293, 702, 1469, 510, 362, 1096, 309, 365, 341, 777, 2856, 1219, 51694], "temperature": 0.0, "avg_logprob": -0.2662985324859619, "compression_ratio": 1.5635593220338984, "no_speech_prob": 0.017170321196317673}, {"id": 12, "seek": 2854, "start": 55.14, "end": 56.14, "text": " Mojo.", "tokens": [51694, 3335, 5134, 13, 51744], "temperature": 0.0, "avg_logprob": -0.2662985324859619, "compression_ratio": 1.5635593220338984, "no_speech_prob": 0.017170321196317673}, {"id": 13, "seek": 5614, "start": 56.14, "end": 58.86, "text": " Mojo is actually a superset of Python.", "tokens": [50364, 3335, 5134, 307, 767, 257, 37906, 302, 295, 15329, 13, 50500], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 14, "seek": 5614, "start": 58.86, "end": 61.02, "text": " So I can use my Python code.", "tokens": [50500, 407, 286, 393, 764, 452, 15329, 3089, 13, 50608], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 15, "seek": 5614, "start": 61.02, "end": 62.42, "text": " Here, check this out.", "tokens": [50608, 1692, 11, 1520, 341, 484, 13, 50678], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 16, "seek": 5614, "start": 62.42, "end": 63.76, "text": " I'll show you what I mean.", "tokens": [50678, 286, 603, 855, 291, 437, 286, 914, 13, 50745], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 17, "seek": 5614, "start": 63.76, "end": 65.96000000000001, "text": " So here is a notebook, right?", "tokens": [50745, 407, 510, 307, 257, 21060, 11, 558, 30, 50855], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 18, "seek": 5614, "start": 65.96000000000001, "end": 67.72, "text": " But this notebook is no normal notebook.", "tokens": [50855, 583, 341, 21060, 307, 572, 2710, 21060, 13, 50943], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 19, "seek": 5614, "start": 67.72, "end": 69.84, "text": " This is a Mojo notebook.", "tokens": [50943, 639, 307, 257, 3335, 5134, 21060, 13, 51049], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 20, "seek": 5614, "start": 69.84, "end": 75.66, "text": " And by way of demonstration, because this is the most fundamental foundational algorithm", "tokens": [51049, 400, 538, 636, 295, 16520, 11, 570, 341, 307, 264, 881, 8088, 32195, 9284, 51340], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 21, "seek": 5614, "start": 75.66, "end": 77.82, "text": " in deep learning, we're going to look at matrix multiplication.", "tokens": [51340, 294, 2452, 2539, 11, 321, 434, 516, 281, 574, 412, 8141, 27290, 13, 51448], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 22, "seek": 5614, "start": 77.82, "end": 81.5, "text": " Now, of course, Mojo has got its own, we don't need to write our own, but we're just showing", "tokens": [51448, 823, 11, 295, 1164, 11, 3335, 5134, 575, 658, 1080, 1065, 11, 321, 500, 380, 643, 281, 2464, 527, 1065, 11, 457, 321, 434, 445, 4099, 51632], "temperature": 0.0, "avg_logprob": -0.2800811767578125, "compression_ratio": 1.6183745583038869, "no_speech_prob": 0.0020186270121484995}, {"id": 23, "seek": 8150, "start": 81.5, "end": 86.38, "text": " here we can actually write our own high performance matrix multiplication.", "tokens": [50364, 510, 321, 393, 767, 2464, 527, 1065, 1090, 3389, 8141, 27290, 13, 50608], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 24, "seek": 8150, "start": 86.38, "end": 87.94, "text": " Let's start by comparing to Python.", "tokens": [50608, 961, 311, 722, 538, 15763, 281, 15329, 13, 50686], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 25, "seek": 8150, "start": 87.94, "end": 91.86, "text": " That's very easy to do because we can just type %python in a Mojo notebook, and then", "tokens": [50686, 663, 311, 588, 1858, 281, 360, 570, 321, 393, 445, 2010, 14189, 8200, 11943, 294, 257, 3335, 5134, 21060, 11, 293, 550, 50882], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 26, "seek": 8150, "start": 91.86, "end": 94.9, "text": " it actually is going to run it on the CPython interpreter.", "tokens": [50882, 309, 767, 307, 516, 281, 1190, 309, 322, 264, 22431, 88, 11943, 34132, 13, 51034], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 27, "seek": 8150, "start": 94.9, "end": 99.06, "text": " So here's our basic matrix multiplication, go across the rows and the columns, multiply", "tokens": [51034, 407, 510, 311, 527, 3875, 8141, 27290, 11, 352, 2108, 264, 13241, 293, 264, 13766, 11, 12972, 51242], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 28, "seek": 8150, "start": 99.06, "end": 101.22, "text": " together, add it up.", "tokens": [51242, 1214, 11, 909, 309, 493, 13, 51350], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 29, "seek": 8150, "start": 101.22, "end": 105.28, "text": " Let's write a little matrix and a little benchmark and try it out.", "tokens": [51350, 961, 311, 2464, 257, 707, 8141, 293, 257, 707, 18927, 293, 853, 309, 484, 13, 51553], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 30, "seek": 8150, "start": 105.28, "end": 108.62, "text": " And oh, dear, 0.005 gigaflops.", "tokens": [51553, 400, 1954, 11, 6875, 11, 1958, 13, 628, 20, 8741, 2792, 75, 3370, 13, 51720], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 31, "seek": 8150, "start": 108.62, "end": 109.62, "text": " That's not great.", "tokens": [51720, 663, 311, 406, 869, 13, 51770], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 32, "seek": 8150, "start": 109.62, "end": 110.78, "text": " How do we speed it up?", "tokens": [51770, 1012, 360, 321, 3073, 309, 493, 30, 51828], "temperature": 0.0, "avg_logprob": -0.29185434798119775, "compression_ratio": 1.7016949152542373, "no_speech_prob": 0.3239324390888214}, {"id": 33, "seek": 11078, "start": 111.06, "end": 114.58, "text": " Well, actually, believe it or not, we just take that code, we copy and paste it into", "tokens": [50378, 1042, 11, 767, 11, 1697, 309, 420, 406, 11, 321, 445, 747, 300, 3089, 11, 321, 5055, 293, 9163, 309, 666, 50554], "temperature": 0.0, "avg_logprob": -0.2696353594462077, "compression_ratio": 1.5943775100401607, "no_speech_prob": 0.0006165732629597187}, {"id": 34, "seek": 11078, "start": 114.58, "end": 117.7, "text": " a new cell without the %python.", "tokens": [50554, 257, 777, 2815, 1553, 264, 14189, 8200, 11943, 13, 50710], "temperature": 0.0, "avg_logprob": -0.2696353594462077, "compression_ratio": 1.5943775100401607, "no_speech_prob": 0.0006165732629597187}, {"id": 35, "seek": 11078, "start": 117.7, "end": 121.34, "text": " And because Mojo is a superset of Python, this runs too.", "tokens": [50710, 400, 570, 3335, 5134, 307, 257, 37906, 302, 295, 15329, 11, 341, 6676, 886, 13, 50892], "temperature": 0.0, "avg_logprob": -0.2696353594462077, "compression_ratio": 1.5943775100401607, "no_speech_prob": 0.0006165732629597187}, {"id": 36, "seek": 11078, "start": 121.34, "end": 125.18, "text": " But this time it runs in Mojo, not in Python.", "tokens": [50892, 583, 341, 565, 309, 6676, 294, 3335, 5134, 11, 406, 294, 15329, 13, 51084], "temperature": 0.0, "avg_logprob": -0.2696353594462077, "compression_ratio": 1.5943775100401607, "no_speech_prob": 0.0006165732629597187}, {"id": 37, "seek": 11078, "start": 125.18, "end": 129.22, "text": " And immediately, we get an 8.5 times speed up.", "tokens": [51084, 400, 4258, 11, 321, 483, 364, 1649, 13, 20, 1413, 3073, 493, 13, 51286], "temperature": 0.0, "avg_logprob": -0.2696353594462077, "compression_ratio": 1.5943775100401607, "no_speech_prob": 0.0006165732629597187}, {"id": 38, "seek": 11078, "start": 129.22, "end": 133.54, "text": " Now, there's a lot of performance left on the table here.", "tokens": [51286, 823, 11, 456, 311, 257, 688, 295, 3389, 1411, 322, 264, 3199, 510, 13, 51502], "temperature": 0.0, "avg_logprob": -0.2696353594462077, "compression_ratio": 1.5943775100401607, "no_speech_prob": 0.0006165732629597187}, {"id": 39, "seek": 11078, "start": 133.54, "end": 138.78, "text": " And to go faster, we're going to want a nice, fast, compact matrix type.", "tokens": [51502, 400, 281, 352, 4663, 11, 321, 434, 516, 281, 528, 257, 1481, 11, 2370, 11, 14679, 8141, 2010, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2696353594462077, "compression_ratio": 1.5943775100401607, "no_speech_prob": 0.0006165732629597187}, {"id": 40, "seek": 13878, "start": 138.78, "end": 141.42, "text": " Of course, we can use the one that Mojo provides for us.", "tokens": [50364, 2720, 1164, 11, 321, 393, 764, 264, 472, 300, 3335, 5134, 6417, 337, 505, 13, 50496], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 41, "seek": 13878, "start": 141.42, "end": 145.18, "text": " But just to show you that we can, here we've implemented it from scratch.", "tokens": [50496, 583, 445, 281, 855, 291, 300, 321, 393, 11, 510, 321, 600, 12270, 309, 490, 8459, 13, 50684], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 42, "seek": 13878, "start": 145.18, "end": 146.78, "text": " So we're actually creating a struct here.", "tokens": [50684, 407, 321, 434, 767, 4084, 257, 6594, 510, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 43, "seek": 13878, "start": 146.78, "end": 149.02, "text": " This is nice, compact in memory.", "tokens": [50764, 639, 307, 1481, 11, 14679, 294, 4675, 13, 50876], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 44, "seek": 13878, "start": 149.02, "end": 152.02, "text": " And it's got the normal things we're used to, like done to get item and done to set", "tokens": [50876, 400, 309, 311, 658, 264, 2710, 721, 321, 434, 1143, 281, 11, 411, 1096, 281, 483, 3174, 293, 1096, 281, 992, 51026], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 45, "seek": 13878, "start": 152.02, "end": 157.4, "text": " item and stuff you don't expect to see in Python, like alloc and like SIMD.", "tokens": [51026, 3174, 293, 1507, 291, 500, 380, 2066, 281, 536, 294, 15329, 11, 411, 12660, 293, 411, 24738, 35, 13, 51295], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 46, "seek": 13878, "start": 157.4, "end": 161.58, "text": " And as you can see, the whole thing fits in about a page of code, a screen of code.", "tokens": [51295, 400, 382, 291, 393, 536, 11, 264, 1379, 551, 9001, 294, 466, 257, 3028, 295, 3089, 11, 257, 2568, 295, 3089, 13, 51504], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 47, "seek": 13878, "start": 161.58, "end": 163.44, "text": " So that's our matrix.", "tokens": [51504, 407, 300, 311, 527, 8141, 13, 51597], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 48, "seek": 13878, "start": 163.44, "end": 167.46, "text": " And so to use it, we take copy and paste the code again, but this time just add a type", "tokens": [51597, 400, 370, 281, 764, 309, 11, 321, 747, 5055, 293, 9163, 264, 3089, 797, 11, 457, 341, 565, 445, 909, 257, 2010, 51798], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 49, "seek": 13878, "start": 167.46, "end": 168.46, "text": " annotation.", "tokens": [51798, 48654, 13, 51848], "temperature": 0.0, "avg_logprob": -0.25604641218126917, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.037319183349609375}, {"id": 50, "seek": 16846, "start": 169.14000000000001, "end": 172.26000000000002, "text": " And now, it's a 300 times speed up.", "tokens": [50398, 400, 586, 11, 309, 311, 257, 6641, 1413, 3073, 493, 13, 50554], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 51, "seek": 16846, "start": 172.26000000000002, "end": 174.06, "text": " Suddenly, things are looking pretty amazing.", "tokens": [50554, 21194, 11, 721, 366, 1237, 1238, 2243, 13, 50644], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 52, "seek": 16846, "start": 174.06, "end": 176.9, "text": " But there's a lot more we can do.", "tokens": [50644, 583, 456, 311, 257, 688, 544, 321, 393, 360, 13, 50786], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 53, "seek": 16846, "start": 176.9, "end": 185.3, "text": " We can look at doing, if our CPU supports it, say, 8 elements at a time using SIMD instructions.", "tokens": [50786, 492, 393, 574, 412, 884, 11, 498, 527, 13199, 9346, 309, 11, 584, 11, 1649, 4959, 412, 257, 565, 1228, 24738, 35, 9415, 13, 51206], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 54, "seek": 16846, "start": 185.3, "end": 186.9, "text": " It's a bit of a mess to do that manually.", "tokens": [51206, 467, 311, 257, 857, 295, 257, 2082, 281, 360, 300, 16945, 13, 51286], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 55, "seek": 16846, "start": 186.9, "end": 187.9, "text": " There's quite a bit of code.", "tokens": [51286, 821, 311, 1596, 257, 857, 295, 3089, 13, 51336], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 56, "seek": 16846, "start": 187.9, "end": 190.14000000000001, "text": " But we can do it manually.", "tokens": [51336, 583, 321, 393, 360, 309, 16945, 13, 51448], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 57, "seek": 16846, "start": 190.14000000000001, "end": 192.66, "text": " And we get a 570 times speed up.", "tokens": [51448, 400, 321, 483, 257, 1025, 5867, 1413, 3073, 493, 13, 51574], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 58, "seek": 16846, "start": 192.66, "end": 195.46, "text": " But better still, we can just call vectorize.", "tokens": [51574, 583, 1101, 920, 11, 321, 393, 445, 818, 8062, 1125, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2835002615432109, "compression_ratio": 1.5772357723577235, "no_speech_prob": 0.32061609625816345}, {"id": 59, "seek": 19546, "start": 195.46, "end": 199.98000000000002, "text": " So just write a dot product operation, call vectorize, and it will automatically handle", "tokens": [50364, 407, 445, 2464, 257, 5893, 1674, 6916, 11, 818, 8062, 1125, 11, 293, 309, 486, 6772, 4813, 50590], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 60, "seek": 19546, "start": 199.98000000000002, "end": 203.9, "text": " it on SIMD for us with the same performance speed up.", "tokens": [50590, 309, 322, 24738, 35, 337, 505, 365, 264, 912, 3389, 3073, 493, 13, 50786], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 61, "seek": 19546, "start": 203.9, "end": 205.70000000000002, "text": " So that's going to be happening in the innermost loop.", "tokens": [50786, 407, 300, 311, 516, 281, 312, 2737, 294, 264, 7714, 966, 555, 6367, 13, 50876], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 62, "seek": 19546, "start": 205.70000000000002, "end": 207.42000000000002, "text": " We're going to be using SIMD.", "tokens": [50876, 492, 434, 516, 281, 312, 1228, 24738, 35, 13, 50962], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 63, "seek": 19546, "start": 207.42000000000002, "end": 211.42000000000002, "text": " And in the outermost loop, what if we just call paralyze?", "tokens": [50962, 400, 294, 264, 484, 966, 555, 6367, 11, 437, 498, 321, 445, 818, 32645, 1381, 30, 51162], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 64, "seek": 19546, "start": 211.42000000000002, "end": 212.42000000000002, "text": " This is something we can do.", "tokens": [51162, 639, 307, 746, 321, 393, 360, 13, 51212], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 65, "seek": 19546, "start": 212.42000000000002, "end": 217.14000000000001, "text": " And now, suddenly, the rows are going to be done on separate cores for a 2,000 times speed", "tokens": [51212, 400, 586, 11, 5800, 11, 264, 13241, 366, 516, 281, 312, 1096, 322, 4994, 24826, 337, 257, 568, 11, 1360, 1413, 3073, 51448], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 66, "seek": 19546, "start": 217.14000000000001, "end": 218.14000000000001, "text": " up.", "tokens": [51448, 493, 13, 51498], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 67, "seek": 19546, "start": 218.14000000000001, "end": 219.26000000000002, "text": " So we've only got four cores going on here.", "tokens": [51498, 407, 321, 600, 787, 658, 1451, 24826, 516, 322, 510, 13, 51554], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 68, "seek": 19546, "start": 219.26000000000002, "end": 220.26000000000002, "text": " So it's not huge.", "tokens": [51554, 407, 309, 311, 406, 2603, 13, 51604], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 69, "seek": 19546, "start": 220.26000000000002, "end": 222.46, "text": " If you've got more cores, it'll be much bigger.", "tokens": [51604, 759, 291, 600, 658, 544, 24826, 11, 309, 603, 312, 709, 3801, 13, 51714], "temperature": 0.0, "avg_logprob": -0.22108429747742492, "compression_ratio": 1.6872964169381108, "no_speech_prob": 0.009411465376615524}, {"id": 70, "seek": 22246, "start": 222.46, "end": 225.5, "text": " This is something you absolutely can't do with Python.", "tokens": [50364, 639, 307, 746, 291, 3122, 393, 380, 360, 365, 15329, 13, 50516], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 71, "seek": 22246, "start": 225.5, "end": 229.10000000000002, "text": " You can do some very, very basic parallel processing with Python.", "tokens": [50516, 509, 393, 360, 512, 588, 11, 588, 3875, 8952, 9007, 365, 15329, 13, 50696], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 72, "seek": 22246, "start": 229.10000000000002, "end": 233.70000000000002, "text": " But it's literally creating separate processes and having to move memory around.", "tokens": [50696, 583, 309, 311, 3736, 4084, 4994, 7555, 293, 1419, 281, 1286, 4675, 926, 13, 50926], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 73, "seek": 22246, "start": 233.70000000000002, "end": 234.70000000000002, "text": " And it's pretty nasty.", "tokens": [50926, 400, 309, 311, 1238, 17923, 13, 50976], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 74, "seek": 22246, "start": 234.70000000000002, "end": 238.62, "text": " And there's all kinds of complexities around the global interpreter lock and so forth as", "tokens": [50976, 400, 456, 311, 439, 3685, 295, 48705, 926, 264, 4338, 34132, 4017, 293, 370, 5220, 382, 51172], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 75, "seek": 22246, "start": 238.62, "end": 239.62, "text": " well.", "tokens": [51172, 731, 13, 51222], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 76, "seek": 22246, "start": 239.62, "end": 241.26000000000002, "text": " This is how easy it is in Mojo.", "tokens": [51222, 639, 307, 577, 1858, 309, 307, 294, 3335, 5134, 13, 51304], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 77, "seek": 22246, "start": 241.26000000000002, "end": 246.34, "text": " And so suddenly, we've got a 2,000 times faster matrix multiplication written from scratch.", "tokens": [51304, 400, 370, 5800, 11, 321, 600, 658, 257, 568, 11, 1360, 1413, 4663, 8141, 27290, 3720, 490, 8459, 13, 51558], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 78, "seek": 22246, "start": 246.34, "end": 251.06, "text": " We can also make sure that we're using the cache really effectively by doing tiling.", "tokens": [51558, 492, 393, 611, 652, 988, 300, 321, 434, 1228, 264, 19459, 534, 8659, 538, 884, 256, 4883, 13, 51794], "temperature": 0.0, "avg_logprob": -0.24001726254012234, "compression_ratio": 1.6196319018404908, "no_speech_prob": 0.5034816861152649}, {"id": 79, "seek": 25106, "start": 251.06, "end": 256.18, "text": " So doing a few bits of memory that's close to each other at a time and reusing them.", "tokens": [50364, 407, 884, 257, 1326, 9239, 295, 4675, 300, 311, 1998, 281, 1184, 661, 412, 257, 565, 293, 319, 7981, 552, 13, 50620], "temperature": 0.0, "avg_logprob": -0.254800562272992, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.048836883157491684}, {"id": 80, "seek": 25106, "start": 256.18, "end": 262.1, "text": " Tiling is as easy as creating this little tiling function and then calling it to tile", "tokens": [50620, 314, 4883, 307, 382, 1858, 382, 4084, 341, 707, 256, 4883, 2445, 293, 550, 5141, 309, 281, 20590, 50916], "temperature": 0.0, "avg_logprob": -0.254800562272992, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.048836883157491684}, {"id": 81, "seek": 25106, "start": 262.1, "end": 263.1, "text": " our function.", "tokens": [50916, 527, 2445, 13, 50966], "temperature": 0.0, "avg_logprob": -0.254800562272992, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.048836883157491684}, {"id": 82, "seek": 25106, "start": 263.1, "end": 269.86, "text": " So now, we've got something that is paralyzed, tiled, and vectorized for a 2,170 times speed", "tokens": [50966, 407, 586, 11, 321, 600, 658, 746, 300, 307, 41919, 11, 256, 7292, 11, 293, 8062, 1602, 337, 257, 568, 11, 16, 5867, 1413, 3073, 51304], "temperature": 0.0, "avg_logprob": -0.254800562272992, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.048836883157491684}, {"id": 83, "seek": 25106, "start": 269.86, "end": 271.34000000000003, "text": " up over Python.", "tokens": [51304, 493, 670, 15329, 13, 51378], "temperature": 0.0, "avg_logprob": -0.254800562272992, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.048836883157491684}, {"id": 84, "seek": 25106, "start": 271.34000000000003, "end": 276.18, "text": " We can also add unrolling for a 2,200 times speed up.", "tokens": [51378, 492, 393, 611, 909, 517, 18688, 337, 257, 568, 11, 7629, 1413, 3073, 493, 13, 51620], "temperature": 0.0, "avg_logprob": -0.254800562272992, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.048836883157491684}, {"id": 85, "seek": 25106, "start": 276.18, "end": 279.0, "text": " So vectorize unroll is already built into Mojo.", "tokens": [51620, 407, 8062, 1125, 517, 3970, 307, 1217, 3094, 666, 3335, 5134, 13, 51761], "temperature": 0.0, "avg_logprob": -0.254800562272992, "compression_ratio": 1.6322314049586777, "no_speech_prob": 0.048836883157491684}, {"id": 86, "seek": 27900, "start": 279.04, "end": 280.84, "text": " So we don't even have to write that.", "tokens": [50366, 407, 321, 500, 380, 754, 362, 281, 2464, 300, 13, 50456], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 87, "seek": 27900, "start": 280.84, "end": 283.84, "text": " Now, there's a lot of complexity here, though.", "tokens": [50456, 823, 11, 456, 311, 257, 688, 295, 14024, 510, 11, 1673, 13, 50606], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 88, "seek": 27900, "start": 283.84, "end": 285.64, "text": " Like what tile size do we use?", "tokens": [50606, 1743, 437, 20590, 2744, 360, 321, 764, 30, 50696], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 89, "seek": 27900, "start": 285.64, "end": 287.44, "text": " How many processes?", "tokens": [50696, 1012, 867, 7555, 30, 50786], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 90, "seek": 27900, "start": 287.44, "end": 288.8, "text": " What SIMD size?", "tokens": [50786, 708, 24738, 35, 2744, 30, 50854], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 91, "seek": 27900, "start": 288.8, "end": 291.2, "text": " All this mess to worry about.", "tokens": [50854, 1057, 341, 2082, 281, 3292, 466, 13, 50974], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 92, "seek": 27900, "start": 291.2, "end": 294.56, "text": " And each different person you deploy to is going to have different versions of these.", "tokens": [50974, 400, 1184, 819, 954, 291, 7274, 281, 307, 516, 281, 362, 819, 9606, 295, 613, 13, 51142], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 93, "seek": 27900, "start": 294.56, "end": 295.56, "text": " They'll have different memory.", "tokens": [51142, 814, 603, 362, 819, 4675, 13, 51192], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 94, "seek": 27900, "start": 295.56, "end": 299.0, "text": " They're going to have different CPUs and so forth.", "tokens": [51192, 814, 434, 516, 281, 362, 819, 13199, 82, 293, 370, 5220, 13, 51364], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 95, "seek": 27900, "start": 299.0, "end": 300.72, "text": " No worries.", "tokens": [51364, 883, 16340, 13, 51450], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 96, "seek": 27900, "start": 300.72, "end": 301.88, "text": " Look at what you can do.", "tokens": [51450, 2053, 412, 437, 291, 393, 360, 13, 51508], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 97, "seek": 27900, "start": 301.88, "end": 305.92, "text": " We can create an auto-tuned version by simply calling auto-tune.", "tokens": [51508, 492, 393, 1884, 364, 8399, 12, 83, 43703, 3037, 538, 2935, 5141, 8399, 12, 83, 2613, 13, 51710], "temperature": 0.0, "avg_logprob": -0.29225207450694607, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.15194976329803467}, {"id": 98, "seek": 30592, "start": 305.92, "end": 310.0, "text": " So if we want an auto-tuned tile size, we just say, hey, Mojo, try these different tile", "tokens": [50364, 407, 498, 321, 528, 364, 8399, 12, 83, 43703, 20590, 2744, 11, 321, 445, 584, 11, 4177, 11, 3335, 5134, 11, 853, 613, 819, 20590, 50568], "temperature": 0.0, "avg_logprob": -0.27676001616886686, "compression_ratio": 1.5080645161290323, "no_speech_prob": 0.020328188315033913}, {"id": 99, "seek": 30592, "start": 310.0, "end": 311.40000000000003, "text": " sizes for us.", "tokens": [50568, 11602, 337, 505, 13, 50638], "temperature": 0.0, "avg_logprob": -0.27676001616886686, "compression_ratio": 1.5080645161290323, "no_speech_prob": 0.020328188315033913}, {"id": 100, "seek": 30592, "start": 311.40000000000003, "end": 313.68, "text": " Figure out which one's the fastest.", "tokens": [50638, 43225, 484, 597, 472, 311, 264, 14573, 13, 50752], "temperature": 0.0, "avg_logprob": -0.27676001616886686, "compression_ratio": 1.5080645161290323, "no_speech_prob": 0.020328188315033913}, {"id": 101, "seek": 30592, "start": 313.68, "end": 315.68, "text": " Compile the fastest version for us.", "tokens": [50752, 6620, 794, 264, 14573, 3037, 337, 505, 13, 50852], "temperature": 0.0, "avg_logprob": -0.27676001616886686, "compression_ratio": 1.5080645161290323, "no_speech_prob": 0.020328188315033913}, {"id": 102, "seek": 30592, "start": 315.68, "end": 322.48, "text": " Cache it for this individual computer and then use that paralyzed, tiled, unrolled,", "tokens": [50852, 383, 6000, 309, 337, 341, 2609, 3820, 293, 550, 764, 300, 41919, 11, 256, 7292, 11, 517, 28850, 11, 51192], "temperature": 0.0, "avg_logprob": -0.27676001616886686, "compression_ratio": 1.5080645161290323, "no_speech_prob": 0.020328188315033913}, {"id": 103, "seek": 30592, "start": 322.48, "end": 327.28000000000003, "text": " vectorized for a 4,164 times speed up.", "tokens": [51192, 8062, 1602, 337, 257, 1017, 11, 6866, 19, 1413, 3073, 493, 13, 51432], "temperature": 0.0, "avg_logprob": -0.27676001616886686, "compression_ratio": 1.5080645161290323, "no_speech_prob": 0.020328188315033913}, {"id": 104, "seek": 30592, "start": 327.28000000000003, "end": 329.44, "text": " So this is pretty remarkable, right?", "tokens": [51432, 407, 341, 307, 1238, 12802, 11, 558, 30, 51540], "temperature": 0.0, "avg_logprob": -0.27676001616886686, "compression_ratio": 1.5080645161290323, "no_speech_prob": 0.020328188315033913}, {"id": 105, "seek": 30592, "start": 329.44, "end": 332.40000000000003, "text": " Now, it's not just linear algebra stuff.", "tokens": [51540, 823, 11, 309, 311, 406, 445, 8213, 21989, 1507, 13, 51688], "temperature": 0.0, "avg_logprob": -0.27676001616886686, "compression_ratio": 1.5080645161290323, "no_speech_prob": 0.020328188315033913}, {"id": 106, "seek": 33240, "start": 332.4, "end": 336.59999999999997, "text": " We can do really iterative stuff like calculating Mandelbrot.", "tokens": [50364, 492, 393, 360, 534, 17138, 1166, 1507, 411, 28258, 15458, 338, 1443, 310, 13, 50574], "temperature": 0.0, "avg_logprob": -0.24178513309411837, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.08748328685760498}, {"id": 107, "seek": 33240, "start": 336.59999999999997, "end": 339.84, "text": " So we can create our own complex number type and it's going to be a struct.", "tokens": [50574, 407, 321, 393, 1884, 527, 1065, 3997, 1230, 2010, 293, 309, 311, 516, 281, 312, 257, 6594, 13, 50736], "temperature": 0.0, "avg_logprob": -0.24178513309411837, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.08748328685760498}, {"id": 108, "seek": 33240, "start": 339.84, "end": 341.88, "text": " So again, it's going to be compact in memory.", "tokens": [50736, 407, 797, 11, 309, 311, 516, 281, 312, 14679, 294, 4675, 13, 50838], "temperature": 0.0, "avg_logprob": -0.24178513309411837, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.08748328685760498}, {"id": 109, "seek": 33240, "start": 341.88, "end": 347.15999999999997, "text": " It looks like absolutely standard Python, as you can see, multiplying, subtracting,", "tokens": [50838, 467, 1542, 411, 3122, 3832, 15329, 11, 382, 291, 393, 536, 11, 30955, 11, 16390, 278, 11, 51102], "temperature": 0.0, "avg_logprob": -0.24178513309411837, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.08748328685760498}, {"id": 110, "seek": 33240, "start": 347.15999999999997, "end": 349.44, "text": " using the operations.", "tokens": [51102, 1228, 264, 7705, 13, 51216], "temperature": 0.0, "avg_logprob": -0.24178513309411837, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.08748328685760498}, {"id": 111, "seek": 33240, "start": 349.44, "end": 354.79999999999995, "text": " And to create the Mandelbrot kernel, we just take the classic Mandelbrot set equation,", "tokens": [51216, 400, 281, 1884, 264, 15458, 338, 1443, 310, 28256, 11, 321, 445, 747, 264, 7230, 15458, 338, 1443, 310, 992, 5367, 11, 51484], "temperature": 0.0, "avg_logprob": -0.24178513309411837, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.08748328685760498}, {"id": 112, "seek": 33240, "start": 354.79999999999995, "end": 359.12, "text": " iterative equation, and pop it in Python here.", "tokens": [51484, 17138, 1166, 5367, 11, 293, 1665, 309, 294, 15329, 510, 13, 51700], "temperature": 0.0, "avg_logprob": -0.24178513309411837, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.08748328685760498}, {"id": 113, "seek": 35912, "start": 359.12, "end": 364.64, "text": " And then we can call it a bunch of times in a loop, returning at the appropriate time", "tokens": [50364, 400, 550, 321, 393, 818, 309, 257, 3840, 295, 1413, 294, 257, 6367, 11, 12678, 412, 264, 6854, 565, 50640], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 114, "seek": 35912, "start": 364.64, "end": 366.96, "text": " to compute the Mandelbrot set.", "tokens": [50640, 281, 14722, 264, 15458, 338, 1443, 310, 992, 13, 50756], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 115, "seek": 35912, "start": 366.96, "end": 368.32, "text": " That's all very well and good.", "tokens": [50756, 663, 311, 439, 588, 731, 293, 665, 13, 50824], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 116, "seek": 35912, "start": 368.32, "end": 369.32, "text": " Did it work?", "tokens": [50824, 2589, 309, 589, 30, 50874], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 117, "seek": 35912, "start": 369.32, "end": 370.84000000000003, "text": " Well, it'd be nice to look at it.", "tokens": [50874, 1042, 11, 309, 1116, 312, 1481, 281, 574, 412, 309, 13, 50950], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 118, "seek": 35912, "start": 370.84000000000003, "end": 371.84000000000003, "text": " So how would you look at it?", "tokens": [50950, 407, 577, 576, 291, 574, 412, 309, 30, 51000], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 119, "seek": 35912, "start": 371.84000000000003, "end": 373.56, "text": " Well, it'd be nice to use matplotlib.", "tokens": [51000, 1042, 11, 309, 1116, 312, 1481, 281, 764, 3803, 564, 310, 38270, 13, 51086], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 120, "seek": 35912, "start": 373.56, "end": 375.52, "text": " Oh, no worries.", "tokens": [51086, 876, 11, 572, 16340, 13, 51184], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 121, "seek": 35912, "start": 375.52, "end": 379.56, "text": " Every single Python library works in Mojo.", "tokens": [51184, 2048, 2167, 15329, 6405, 1985, 294, 3335, 5134, 13, 51386], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 122, "seek": 35912, "start": 379.56, "end": 380.56, "text": " And you can import it.", "tokens": [51386, 400, 291, 393, 974, 309, 13, 51436], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 123, "seek": 35912, "start": 380.56, "end": 381.56, "text": " Check this out.", "tokens": [51436, 6881, 341, 484, 13, 51486], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 124, "seek": 35912, "start": 381.56, "end": 384.44, "text": " Plot is import the Python module, matplotlib.", "tokens": [51486, 2149, 310, 307, 974, 264, 15329, 10088, 11, 3803, 564, 310, 38270, 13, 51630], "temperature": 0.0, "avg_logprob": -0.23584309330692999, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.227985680103302}, {"id": 125, "seek": 38444, "start": 384.76, "end": 389.12, "text": " mp is import the module, numpy, and the rest of it.", "tokens": [50380, 275, 79, 307, 974, 264, 10088, 11, 1031, 8200, 11, 293, 264, 1472, 295, 309, 13, 50598], "temperature": 0.0, "avg_logprob": -0.2688041560906024, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.15606164932250977}, {"id": 126, "seek": 38444, "start": 389.12, "end": 393.8, "text": " This is actually Mojo code, but it's also Python code.", "tokens": [50598, 639, 307, 767, 3335, 5134, 3089, 11, 457, 309, 311, 611, 15329, 3089, 13, 50832], "temperature": 0.0, "avg_logprob": -0.2688041560906024, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.15606164932250977}, {"id": 127, "seek": 38444, "start": 393.8, "end": 396.4, "text": " And it works.", "tokens": [50832, 400, 309, 1985, 13, 50962], "temperature": 0.0, "avg_logprob": -0.2688041560906024, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.15606164932250977}, {"id": 128, "seek": 38444, "start": 396.4, "end": 400.56, "text": " And I don't know if you remember, but Chris actually said the Mandelbrot set is 35,000", "tokens": [50962, 400, 286, 500, 380, 458, 498, 291, 1604, 11, 457, 6688, 767, 848, 264, 15458, 338, 1443, 310, 992, 307, 6976, 11, 1360, 51170], "temperature": 0.0, "avg_logprob": -0.2688041560906024, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.15606164932250977}, {"id": 129, "seek": 38444, "start": 400.56, "end": 402.32, "text": " times faster than Python.", "tokens": [51170, 1413, 4663, 813, 15329, 13, 51258], "temperature": 0.0, "avg_logprob": -0.2688041560906024, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.15606164932250977}, {"id": 130, "seek": 38444, "start": 402.32, "end": 406.28, "text": " And that's because we can also do an even faster version where we're handling it with", "tokens": [51258, 400, 300, 311, 570, 321, 393, 611, 360, 364, 754, 4663, 3037, 689, 321, 434, 13175, 309, 365, 51456], "temperature": 0.0, "avg_logprob": -0.2688041560906024, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.15606164932250977}, {"id": 131, "seek": 38444, "start": 406.28, "end": 407.36, "text": " SIMD.", "tokens": [51456, 24738, 35, 13, 51510], "temperature": 0.0, "avg_logprob": -0.2688041560906024, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.15606164932250977}, {"id": 132, "seek": 38444, "start": 407.36, "end": 414.2, "text": " And we can actually create the kind of iterative algorithm that you just can't do in Python,", "tokens": [51510, 400, 321, 393, 767, 1884, 264, 733, 295, 17138, 1166, 9284, 300, 291, 445, 393, 380, 360, 294, 15329, 11, 51852], "temperature": 0.0, "avg_logprob": -0.2688041560906024, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.15606164932250977}, {"id": 133, "seek": 41420, "start": 414.24, "end": 417.36, "text": " even with the help of stuff like numpy.", "tokens": [50366, 754, 365, 264, 854, 295, 1507, 411, 1031, 8200, 13, 50522], "temperature": 0.0, "avg_logprob": -0.26126560722429726, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.0020823192317038774}, {"id": 134, "seek": 41420, "start": 417.36, "end": 421.28, "text": " This is something which is really unique to Mojo.", "tokens": [50522, 639, 307, 746, 597, 307, 534, 3845, 281, 3335, 5134, 13, 50718], "temperature": 0.0, "avg_logprob": -0.26126560722429726, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.0020823192317038774}, {"id": 135, "seek": 41420, "start": 421.28, "end": 427.2, "text": " So we now have something here which is incredibly flexible, incredibly fast, can utilize the", "tokens": [50718, 407, 321, 586, 362, 746, 510, 597, 307, 6252, 11358, 11, 6252, 2370, 11, 393, 16117, 264, 51014], "temperature": 0.0, "avg_logprob": -0.26126560722429726, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.0020823192317038774}, {"id": 136, "seek": 41420, "start": 427.2, "end": 433.36, "text": " hardware you have no matter what it is, and is really understandable to Python programmers", "tokens": [51014, 8837, 291, 362, 572, 1871, 437, 309, 307, 11, 293, 307, 534, 25648, 281, 15329, 41504, 51322], "temperature": 0.0, "avg_logprob": -0.26126560722429726, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.0020823192317038774}, {"id": 137, "seek": 41420, "start": 433.36, "end": 434.59999999999997, "text": " like you and me.", "tokens": [51322, 411, 291, 293, 385, 13, 51384], "temperature": 0.0, "avg_logprob": -0.26126560722429726, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.0020823192317038774}, {"id": 138, "seek": 41420, "start": 434.59999999999997, "end": 439.0, "text": " I think finally we're at a point where we are going to have something where I actually", "tokens": [51384, 286, 519, 2721, 321, 434, 412, 257, 935, 689, 321, 366, 516, 281, 362, 746, 689, 286, 767, 51604], "temperature": 0.0, "avg_logprob": -0.26126560722429726, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.0020823192317038774}, {"id": 139, "seek": 41420, "start": 439.0, "end": 441.59999999999997, "text": " enjoy writing neural networks.", "tokens": [51604, 2103, 3579, 18161, 9590, 13, 51734], "temperature": 0.0, "avg_logprob": -0.26126560722429726, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.0020823192317038774}, {"id": 140, "seek": 44420, "start": 444.59999999999997, "end": 445.59999999999997, "text": " Wow!", "tokens": [50384, 3153, 0, 50434], "temperature": 0.0, "avg_logprob": -0.5561510721842448, "compression_ratio": 0.7647058823529411, "no_speech_prob": 0.471642404794693}, {"id": 141, "seek": 44420, "start": 445.59999999999997, "end": 447.03999999999996, "text": " How awesome was that?", "tokens": [50434, 1012, 3476, 390, 300, 30, 50506], "temperature": 0.0, "avg_logprob": -0.5561510721842448, "compression_ratio": 0.7647058823529411, "no_speech_prob": 0.471642404794693}], "language": "en"}