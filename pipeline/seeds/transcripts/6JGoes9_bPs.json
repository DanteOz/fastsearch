{"text": " So you've got a new patty submission. Let's take a look. Kaggle. Competition. By the way, it's really beautiful to see over the last week or two, all these fast AI people just pop up at the top of that leaderboard. It's so cool. Okay, fast AI, fast AI, fast AI, fast AI, fast AI. Who's this person? Is this fast AI? At least the top five. Yeah, like most of the top five or top 10 are following you in these walkthroughs. You've all got the same score though. Somebody's got to like, you know, Kurian's got something. Secret source there. Well, I've got a few ideas I can show you guys today if you want to try and take it a bit further, which I bet you do. Anybody have any comments or questions in the meantime? All right. So, chair screen. And that's the right screen. And I'll move you guys onto the other screen. And now I can see. Yeah, all right. So, addy leaderboard. There we are. Where's Radek? Not here. Serada, I see. Okay. One thing that I guess it would be nice if it wasn't so sort of, I don't know, a little bit of a mess because I set this up in paper space and then started running it. And then I went to bed because it was taking so long. And I just have a fear that if my browser sleeps or goes to sleep, that it'll just basically stop the session even though there's more hours and the process in the workstation is running. I wasn't sure. So, I mean, it shouldn't, but what happens is it queues up for when your browser comes back. But the problem is there is some limit to how much it'll queue. So, although it'll have run, if you've hit that limit, you won't see all the outputs, which is nearly just as bad. So, there's a few things you can do. The most obvious one would be to use nvdev to export the notebook to a script and then run the script in Tmux. Because then you can close it down, come back, reattach Tmux and there it is. Okay, that'd be interesting. Now, something that I've noticed is something, yeah, so maybe we'll look at that sometime. Now, something I don't, well, does paperspace gradient let you have, does it let you SSH in with a suitable IP? I'm not sure. If you've got your own GPU at home, or on AWS or GCP or whatever, then what I do is I run xRDP on it, which is a remote desktop server. And then I can connect to it like so, and run Firefox. And so this is my, yeah, this is my server's screen, remote desktopping in. So if I now go in and run something. Patty, I remember from last time. Okay, so I can set this running. So I can set this running. So I can set this running. Okay, so I can set this running, and then I can close it down, go to sleep, come back the next day, reconnect to that screen, and it's still been running. So like that's the preferred way to do it. But I, yeah, as I say, I don't know if it's possible on paper space gradient. You could do it, sorry, go on. Machines seem to have a limit of six hours that I've seen so far. If you subscribe to their pro or whatever, you can bump it up or get rid of it all together. It's this tab here, machine tab, you can change the auto shutdown. Okay, it looks like a week's the maximum. Oh no, there's a limit there as well. There's a limit there as well. When you're paying. No, that's fine. When you're paying, but I mean, I think it's like eight bucks a month. Yeah, eight bucks a month. You may as well. Yeah, I've got the pro, but I don't have on the, when you pick a free machine. Oh, yeah. Right. Free P5000. Maximum of six hours, yep. So Jeremy, sorry to interrupt. Paper space in their support channels, they talk about you can assign a public IP to a machine and then SSH to it. So you could SSH and then T-MACS. Is that for gradient machine though? Well, good question. I don't know about that. Look, I'm not sure that it would be. So advanced options. No, it's not. And so they also have this thing called core, right? Which are like more like AWS or Google servers, which absolutely lets you do a static IP. And you don't even need, I don't even know if you need a static IP necessarily, but you could use a dynamic IP. We've worked just as well. Bit cheaper. The thing is though, I reckon they're pretty expensive. Yeah. They're a pretty expensive product. So these are very basic GPUs. So that's not bad. 45 cents an hour. I guess they're not too terrible. If you want to TX. Oh no, I guess they're the same price really, 56 cents. All right, I take that back. I guess the thing I found expensive was their CPU pricing for running it all the time. Yeah. So Jeremy, with this RDP solution that you showed, how does that work? Do you have an... Oh, just a moment, Radit. Yeah. Okay. I didn't get what computer you're RDPing into. I'm RDPing to my own GPU machine, but it could just as well be a AWS machine or GCP machine. This is basically the same as VNC, if you've come across VNC before. RDP is the kind of Microsoft version of that. I like it generally quite a lot better. And much to my surprise, the Mac client for RDP is better than the Windows client for RDP. It even shows you a little mini screenshot, you know, of the screen. So yeah, this is now finished training. No, not nearly finished. It's halfway through training, whatever. Was this tricky to set up because you're running a Linux server? Not even slightly tricky to set up. So yeah, you just... It's called XRDP, since it's RDP for X Windows. And you just go app install. Yeah, I mean, I hate installing this kind of thing. It drives me crazy. But this is it. You just sudo app install, sudo add user, sudo systemctl restart. And then you might also want to run sudo systemctl enable, which will cause it to automatically start when you start your computer. And I don't think I... Oh, you know, if you've got a firewall, you have to let it in. So it's port 3389. Basically this line of code. And I think I did have a firewall. So I also ran this. Yeah, that was it. It just used my username and password that I had on the machine. Amazing. Yeah. Very surprisingly not annoying. And then I think I just installed Microsoft Remote Desktop from the Mac app store or on Windows. I think it comes with Windows. So that was easy. Yeah, nobody seems to talk about it. I'm going to talk about BNC, which is also fine, but I find it a bit slower and a little bit more awkward. All right. I mean, one weird thing, I guess, is I guess my machine, and this is pretty common. I haven't set up really to be a graphical workstation. I always use it from the console. So I actually don't really have much of a window manager here. I can't even like... Oh no, I can do a little bit. I don't know what the hell window manager is even using. But often you'll find like there is no window manager or whatever running. But you know, a bit of Googling will show you how to install, you know, whatever, KDE or stuff. Okay. Since we're on the installation topic, could I ask a question? So I think I kind of brought it up a little bit, but I can't launch FastAI, a machine that runs FastAI, and PyTorch. A PyTorch one would work. So what suggestions would you have about... So that means that your prerun.sh file has got a problem. So maybe comment it out from my PyTorch. Just start it up. Open up your PyTorch. Open up a PyTorch machine. Move prerun.sh to prerun.back or something. Or just open it and see, like it might be obvious what's wrong with it. Yeah, I couldn't see anything. When you say it's not working, what's like, what's not working? Well, it just says error when I try to start it up. It just says error and I tried to reach out to the paper spread space support a couple of times. Maybe it's a too abstract of a question. I'll try that. I'm sure people are putting stuff in the text chat. Please try to say things, verbal chat, if you can, because it's way nicer for me, and I don't have to check multiple windows. I know it's not possible for everybody. Okay, so sorry, Jeremy. There is a way to SSH into a gradient machine, but you have to trigger the virtual machine to be built from the command line. So you have to initiate the job, and there's paper space, have a GitHub repo. And is there any reason to do that? Like that sounds complicated. It's way more effort than it's worth. Just run a call, just run a paper space core machine if you want to, I guess. Yeah, exactly. So you can do it. It's just, why would you? So yeah, I mean so for paper space the issue around the notebook closing, I would like start running something, close the notebook, and then reopen it, just to see what happens. You know, and, you know, let's try it here, right? Now what was that thing we learned the other day? It was Shifty. Let's see the other one. Oh, that was my one. Okay, I gotta learn how to. Hey Jeremy. Yeah. Um, can you, are you using iterm2 because you can do tmux minus CC and you'll get native windows in tmux instead of the little sort of terminal ones. That sounds interesting. Let me try that. Yeah, I'm addicted to that. It's awesome. So, minus capital capital, minus capital CC. Unknown option C. Before the A. Yeah, so it'll be tmux minus capital capital. Yeah, here you go. Okay. And what are the benefits of this? You can have windows so you can click and drag them and move them around pop them out. Yeah, all that stuff. Click and drag tmux windows as well. Okay, so it's all the same as, like, you've got to have mouse mode on for them to work. So you can click the shortcut keys like command shift D will split panes, you don't have to go into I think is a colon or something and command something. It's just like less dimy. You just use control B. And maybe it's exactly the same. Yeah. I mean you have the same control B doesn't work anymore so my tmux shortcuts are not going to work anymore. How do I do that now. They're different escape, I think, or. If you go back to the original window that launched it. Okay. Okay. Yeah, I'm not convinced it's going to help my workflow but I think yeah for people who are more familiar with tmux shortcuts that could be cool. Thanks for the tip. What's going on down here. The, the trick to get mouse support working so for example my scroll wheel as you can see works nicely in this normal tmux window is to have a dot tmux dot conf file that contains set option minus g mouse on. And then you can also increase your history limit. And yeah, that's how come I can scroll. I think the thing like, you know, or a thing I like about tmux is that it's integrated with my kind of the normal way of doing things in in unix, you know, so for example, if I want to search through my previous session. I could just hit question mark to search up, and I could search for make file. For example, and you know, hit n, just like I would in vim. Hit slash to look forwards. You know it's like my terminal works the same way as vim or whatever which I, yeah, which I really like. And I think, yeah, that way I don't have to know like, oh the items that are shortcuts and some other set of shortcuts it's just this kind of kind of like general unixy way of doing things, I guess. And of course they'll also all work on the paper space terminal as well. Yeah, so let's try this. So if we start running this. Okay, close that. Leave it for a few seconds. And you can see here it says in my console, starting buffering. So it's remembering things that were sent to me so if I click now back here. It's, let's see. Hmm. That didn't seem to work, did it? That's interesting. Okay, so let's try something different. So I don't think you can just close it and reopen it. Alright, let's try something else. What if we fake a network disconnection by closing SSH. Okay, so now, alright, connections failed. So I'll leave that window open. And then we reconnect. And Okay, so that worked. So there's some of our answer. But yeah, I think there's something now if you leave it long enough. It says I've stopped listening for events because there's been too many and tells you there's some configuration option you can change to make it bigger. Should probably be a useful thing to know about. Let me just go and turn this alarm off. Hang on. Okay. Yeah. Sorry about that. My daughter likes to be permanently entertained. So any gaps in her homeschooling schedule. She wants to be amused. She doesn't like the fact that I'm doing this and Rachel's a CrossFit. Okay. So we had a look the other day at progressive resizing right. And so this is where I got to I think like progressive resizing one interesting thing you can do is like you can go crazy like you can go extra large. And, you know, we start out with some teeny tiny images and train for a while. And then combine that with gradient accumulation. To then go up to big images. But don't have to train so long. And so I think this is a good trick for probably particularly for code competitions on Kaggle where you've got serious resource constraints, you know, or just wanting to do more with less time. And yeah, on Kaggle you would have needed accumulation level of four rather than two to make this fit because they've got 16 gig cards. We also got 24 gig card. So then something else that then we started talking about was weighted models. That's weird. What happened to my weighted model? Did I move it to course 22? Oh well, that's fine. So the question I think we had yesterday was about unbalanced datasets and would it be a good idea to balance our dataset? So let's start with a nice small model. If he uses a base case, something we've done before. Conv next. Okay, let's use this one. So actually there's no point copying progressive I guess. Let's copy small models. Okay. Rename. And so this is going to be for weighted. As we'll do the resizing. Okay, so that's going to be our base case. So for weighting we can df.label.valueCounts So there's our level of unbalancedness. So it's not too bad. There's a lot of normals, a lot of blasts. Not many of these are bacterial thingies. Nick, I don't know if you're around. I mean, I can see you are around. I don't know if you're able to talk. But if you are, you could tell us about what you found because I know you've been looking at these, which of these are hard to kind of visually see the difference between. Yeah, yeah, for sure. I'm sorry I dropped out earlier because we had a power cut here, but I'm back now. Are you intentionally video lists? I am not intentionally video lists, but that's the break at the moment. Sorry about that. No worries. But yeah, like one thing that I did just to, I guess, get a better handle on the data set was going through them and having a look at the different types. I found it really hard to pick even what the difference was between a normal image and say like downy mildew or whatever. It can be quite hard to pick out. And so one thing I thought it would be fun to do was to almost like segment or mask the images playing with the color channel to see if they would come out a bit better. And then when I did that, I was able to take kind of, I guess, the yellow dead bits or disease parts and I could see them better when they were like in bright red. And the thing is, is that so many of these, like when I found like when I've trained them, I find that there is a handful of a handful of images really like like 20 to 25 images that are very difficult to classify. And it tends to be these actually from these imbalance classes, where it tends to categorize them as blast when it's not. And I think material ones tend to get. Yeah. In fact, let me just pull up in one of my notebooks, maybe share your screen. Yeah, let me see if I like when you look at this. Are you able to see. To make these bigger, are you able to see the disease in these because I don't know what I'm looking for. How do we make this bigger? Probably there's like a bigger size in that plot lives there, that plot live. So like fixed size, fixed size. Yes. Big signs equals. I don't know. By the way, around 9.15 we can't hear you by the way Nick I don't know if you lost you. I also tried to look into the image using the confusion matrix and then the most laws to put it out, but it's just too hard is beyond my domain. I was planning to do that today actually so that's yeah. I don't know what happened to Nick maybe he's having some internet problems again. I wonder if it's just like spread spots or something. So yeah, I mean it's in anyway it's interesting that Nick said he found these ones difficult so yeah there's basically two reasons to to wait different rows differently one is that some of them are harder. And that you want them to be shown more often to give the computer more of a chance to learn them. And the other is some are less common. And same thing. So, you know one possible waiting for these would be to take their reciprocal. And so then, you know, normal is going to be shown less often if we wait all the normal ones by this amount, and all the bacterial panicle blight ones this amount, you're going to get more of these. So that's like one approach we could use. So I feel like that might be overkill. So I'd be inclined to kind of like, not do it quite that much so like another approach would be to like take the square root, maybe one over the square root, kind of like that. So then, these are going to be shown about twice as often as these, you know. So maybe like let's start with trying this as our set of weightings. Jeremy, if I could ask a question at this point. So the waiting and when you talk about waiting such that images are shown more or less often. This is where it's it's very imbalanced, whether that could lead to some classes being overfitted to because the model learns about the images themselves I came across in looking at classification. And whether there was a way to, I read about how to deal with imbalances, and I've seen some recommendations to try to wait when calculating the losses, rather than resampling the inputs so I just wondered whether it was possible. It's different right like so. In the end you want it to be able to recognize the features of the images you care about. And there's no substitute for like having them see the images enough times to recognize them. However, when it does that, it is then going to because it sees the rare cases more often, it's going to recognize rare cases are more probable than they actually are. So you have to reverse that. Then, when you make predictions. So that's yeah that's something to be to be careful of so I mean, I mean, I think probably just help to try to try to take a look at it to see what that looks like. So yeah so here's our weights right. So this line to probably. Can we merge things directly, let's take a look so if I go. Df dot merge, which is kind of like a way of doing a join in pandas. And the right hand side yeah the right hand side can be a series. Cool. So merge on weights. What does that look like. And then, okay. Left. I see so left. Okay so on left left on left on equals label. And right, I think that's called the index. I'm not a pandas expert. I don't know if anybody is. There we go. Okay. So that's added these weights here. Give them a slightly weird name but that's okay. So if we call that weighted Df. And so then, we could get take a little, a little function and move them over here. And I think what we want to do is use data blocks at this point. That's kind of a good idea. And we have a data blocks version. Certainly make one otherwise. Okay, here's a data block. So let's create a data block. Got an image block and a category block. Get y is parent label. Okay. Item transforms is this. Jeremy I think you're in the wrong. Book should be in weighted. Thank you. Thank you. Yes, I had these here but. Thank you. Okay, and that transforms. We should just use the same ones we had here. To make it fair. Okay. So there's our data block. Oh, we actually use this resizing. So, yes. Okay, Jeremy. Yeah, sorry. Sorry to interrupt there. So this approach is we're going to use the data block to even the numbers of what's being sampled so that we can more augmentations of the same images. So, we're going to use the data block to even the numbers of the same images for the lower represented samples or kind of. So, it's nothing to do with the data block. We're going to use things called weighted data loaders. And the way to data loader is going to use these numbers here. To as as basically like probabilities of how likely it is to pick that row. And to each of these divided by the sum so they'll add to one. The reason I did data blocks is because the weighted data loaders method is a method of data block. It's not something we get in the, you know, quick and dirty image data loaders thing that doesn't have as much flexibility. So now that we've got a data block we can type the block dot. Oh, and we'll have to import it import fast. I call back dot. What was it in again. I don't remember fast. I waited. Oh, okay. So that's it's a it's actually a method of data sets. So we can get a data sets object from a data block. Like so. And we pass in source. So that would be our list of image files. So we can files equals get image files. In our training set. You pass those in and there's our training set and there's a validation set. So their data sets. So these are the things that remember we can index into and get a single X, Y pair. And so weighted data loaders is then something we can pass data sets to and give it weights and a batch size. Okay. And the weights for the training set. Okay, we're going to have to be careful about this. So we should be to go DSS dot weighted data loaders. And so the source code. I guess it calls. Which is here. Okay. All right. I'm not 100 percent sure how this is going to work, but let's try it. So our weighted data frame. So this is the weight for each row. And then we've got our files. Yeah, we're going to be a bit careful here, right? Because they're in they're in different orders. So we actually need. We actually need a way to get a list of weights where the two orders are going to match each other. Can you do it by key lookup? Can you put a key? Yeah, we could do it by key lookup. I'm actually thinking of something a little lazier, which is just to sort them both. Okay, so. Although this seems to only have a what's going on here? Doesn't have them all. Are they not contiguous? Sort values by image ID. They are contiguous. So where is image 100001? The sorting must be by folder first though. Yes, of course. That's exactly what it is. Thank you. Okay. So we could use a key. That looks hopeful. It says here if the key is a string, use attribute getter. So I think I can just pass in the key name. Ah, that is magic. That is the magic of fast core right there. There we go. So that's sorting by name. And we can do the same thing for this one. Like so. And so now they're sorted by the same thing. So that's a good step. So the weights are basically WDF dot label Y. Now that's a pandas series, which yes, to numpy would turn it into an array. I'm just not quite sure whether this has to be just for the training set or is for both. We'll find out in a moment. If I run that, it doesn't like it. That's interesting. Of course. So the batch transforms actually didn't end up getting applied because we used dot data sets, which doesn't apply batch transforms. So we would need to now apply them here. So that's quite confusing. So presumably, I don't see it here, but I would expect to be able to go batch transforms at this point. Oh, DL quarks. This is all quite awkward, isn't it? So data loader keyword arguments equals batch. So if we are creating a data loader, a weighted data loader, you know what would be a good idea would probably be to look at the data block dot data loaders source code to see how that does it. Data sets dot data loaders. Here we go. After underscore batch is what it is. After underscore batch. OK, that's not it. Let's see. OK, it's calling dot data loaders, passing in the keyword arguments and OK, dot data loaders does not call it after batch. Dot data loaders. Well. Data sets. Yeah, so OK, so data sets dot data loaders is this thing here and that doesn't call it after underscore batch. So. Oh, and I think I know why. I think that's because when we looked the other day at data block, we noticed that it like adds. Oh, yes, yes, yes. The image block. That adds into float tensor as a batch transform. So we might need to add that as well. OK. So it's getting PIL images. So the fact is getting PIL images means it's never being converted to a tensor. So data block. I really think there's something that calls to tensor or something at some point. Oh, there is here. Item transforms. So why isn't that getting called? Because. Oh, item transforms, I think are also done at the data loader stage. Item transforms. Let's see. Item transforms. Yes, that's also done. OK, so basically using data sets instead of data loaders is quite awkward. I think we need to fix this in fast AI because. Yes, it's not being done for us, but you know what we could do actually is what we could do. Is the same thing that. Data block does, which is just to use these self dot item transforms and self dot batch transforms. So if we have a look at our data block. Oops, Daisy. OK, I think this is all going to become clear in a moment. Hopefully it's got these item transforms in it. And it's got these batch transforms in it. And so what we actually want to do when we create our data loaders is say that after batch is. The data block says the batch transforms are and after item. Is whatever the data block. Says the item transforms are. OK, that's ugly. So that's something I think we should try to make easier. So hopefully by the time people see this video, this will all be easier. So there's some data loaders. OK. So my guess is that here. Is we've given the wrong number of weights. I'm guessing this needs to be weights just for the training set. So the way I would check this is I would type percent debug and that puts us into the. Python debugger and the Python debugger is a very, very cool thing. It's called PDB. And definitely want to know how to use it. H gives you the help. And. W shows you where in the stack you are so you can see this is the line of code I'm about to run. And so I can print out with P self dot N. And I can print out with P. Self dot weights. And I can you don't actually normally need to even say P. It just assumes that so I can just say self dot weights dot shape. And so there's the problem. So it's expecting 8,326 weights, not 10,407 weights. And so that's because and you know, to be fair, the documentation warned us about this. It's expecting weights just for the training set. Not for both training and validation sets. Okay, no problem. Did you predetermine your split by adding another column in you in the same data set that you put the weights in? Yeah, I could do that. But actually, and somebody actually asked about this the other day. This is our training set. And items tells you the file names actually. So we just need to look at each of these up. In the data frame. So what we could do is we could say weights equals. And so we could go through each of those. So that's going to be all of our files. And then we need to. Look up the image ID. And, you know, I think something you could possibly do here is set the index to image ID. Right, which is this kind of pandas idea. WTF equals. And then we say. location of one, one dot JPEG. Oh, there it is. For label why. There it is. So if we copy that over to here and replace that with O. Oh, dot name. Look at that. So. OK, so we don't want to sort values. We want to set index. I should probably take more use, make more use of indices in pandas. I guess I still don't have a great sense in my head of quite how they work. So I tend to underuse them. OK, so weights should now be the right length. The training set. OK, so now. Now weights here. It's just weights. Cool. And then what I'd be inclined to do is to do a few more. And what I find encouraging here is that we've got a lot of bacterials. Ground spot. Yeah, you know, this seems like a good mix, right? So then. We should just be able to. Pass those to our learner. Find June for five. Epochs. All right, sorry, that was a bit more awkward than I would have liked and definitely used a whole bunch of concepts which we haven't. Covered before. So don't worry if you're feeling lost about the implementation here. Basically, Jeremy. Yeah, just about the have the sampling works. Yeah, we've got weights and that's creating. How is that actually sampled from the training set? Is it do we have an X number of rows or number of images that we're trying to create a sample? Yes, what happens is it creates it creates batches. So each batch will have 64 things in. And so it's going to grab at random 64 images. But it's a weighted random sample. Each row is weighted by this. This weight. And so, and it parks not exactly an epoch anymore. In that it won't necessarily see every image once at a box and a box just equal to the total number of rows in the data set is how many rows I've seen. But, you know, we'll see a lot of the less common ones multiple times. And so there's a definite danger of overfitting. The weighted sampling is not done for the validation set. So we should be able to compare these. Let's take a look. So 5.6. This is 4.6. Now, you know, this is expected. But where this might be interesting would be like, through all of our training, and then maybe at the very end, do a few epochs with weighted training, you know, at the point that it's already really good, just to show it a few more examples of the less common ones. Or just train it for longer with more data augmentation. But yeah, I mean, you know, you would expect the error rate at this point to be worse, I think, because the most common types, which it's particularly ought to care about because they're the ones that's going to have mainly in the training set, it hasn't seen very much. So the overall error has gone down. But yeah, I think it might, there may well be ways to use this. Jeremy, is it possible you could quickly explain where the deficiency was in this random weighted API, how you would prefer that to look like you said you fixed it up later, but I mean, I think the way this ought to look would be that I can say DLs equals D block.weighted data loader. Like that. In fact, you know, we could we could fix it up now. Reusing the existing after batch and after items already and then we can fix it up now if you're interested. Yeah, I'd love to see how to change. So, you know, the first thing I'd do before I change the fast AI library is make sure I've got the latest version of it by doing a get pull. Because nobody likes conflicts. All right, it's up to date. So then I would go into the notebooks and it was in the data callbacks. Callback.data. And so here's weighted data loaders. It's just a bit of a silly question, but is it a callback or is it just kind of like a transform within the actual data block? Should it be if you send weights to a data block, then it just does it. Is it a callback? No, it's not a callback. So it's in a strange place. It's not a callback. What it is, it's a data loader, actually. And a patch to data sets. So there's a, you know, something I like very much in Fastcore called patch, which allows us to add a method with this name to this class. And I want to add something to the data block class. Like so. But yeah, I think that the doc string is correct. And I would then be inclined to just grab this here. Copy and paste it in here. Paste. Okay. And so this would be calling. Yeah, so we're calling the data blocks. So I guess we're going to do the two steps kind of manually, aren't we? So we're first going to go create the data sets. And so that means we need to be passed in the items called source. And I'd be inclined to like grab all that. Okay, so this thing in data block is going to need a source. It's going to need the weights. It's going to need a batch size. Apparently there's something called verbose. I don't know what that means, but that's fine. So the data sets is self.dataSets passing in the source. And verbose equals verbose. And then we called dss.dataloaders. And when we did that. Okay, so now we're going to be passing doing dss.weighted.dataloaders. And that's basically. Oops. What happened there? And then we pass in the weights. Weights. So weighted data loaders, yeah, gets the weights. And then the batch size and then the things we added. Any additional keyword arguments. And this will delegate down to dataSets.weighted.dataloaders is where the keyword arguments get passed to. Okay, so as far as I can tell, these same tests should all work. We don't need these labels anymore. It is valid. We've already got a data block. So previously we called data set and item transforms and weights manually. So that is our source. So we could get rid of all this. And we're now going to go data block.weighted.dataloaders. And we've got to pass in our source. Okay, and we've got to pass in our weights, which were called weights. Oh, I already had that. Never mind. And we don't need that anymore. Okay. Why did I get zero? That's slightly surprising to me. Oh, no, zero. Yeah, that's fine. Yeah, I could get zero or one. Yeah, because it depends how it... Why is that slightly random? I'm not sure. Something's slightly random. But anyway, it's working. So then, okay, then again, for this one, we shouldn't need to do dataSets. We should be able to go data block.weighted.dataloaders. And we should be able to pass in our items and our weights. And... Okay, what did I do wrong there? Data blocked.weighted.dataloaders. Oh, it's got a... Okay, let's see. Our source, our weights. Why doesn't it like that? Source equals... So let's see how it's different to what this one said. dataSets. Okay, this doesn't use a data block. So, okay, I can't replicate that. That's fine. Okay, so that's our test. There we go. So what I would then do is I would export it. And if... So that...I don't have to rebuild or reinstall or anything like that my fastai library. That's because I have it installed using something called an editable install. So if you haven't seen that before, basically, or maybe you have and you've wondered why, when you go pip install minus E dot in a Git repo, basically that creates like a SIM link from your Python library to this folder. And so fastai, when I import fastai, it's actually going to import it from this folder. And so now, back over here in my weighted thingy, if I do all this, data block, we should find that there's now a dblock dot weighted data loaders, which I can pass source and weights. And my source is files and my weights is... weights. Oh, and my weights. Okay, so that's interesting. My weights. Yes, we don't have data sets yet. So that's a very interesting point. So how do we know what our weights are? We don't, because they haven't been split. So the... Could you not send them through as one of the blocks and as a column Git from, and then use that because then it would be linked quite intimately with the actual row? Well, we don't need to. I think what we need to do is pass in weights. I think we should pass in all the weights. And then this thing here should then be responsible for grabbing the subset for the training set. And that would actually be much more convenient, which is after all is what we want. So, yes. So we should determine the weights based on the distribution across the classes rather than... We should split the weights based on the splitter in a training and test set. So then we don't need any of this. So then weights actually will simply be... That's our weighted data frame. So basically what I would do here is this... well, actually, we'll go back to saying this is sort values. And then our weights will be WDF.labelY. That's actually our weights as a NumPy. Silly question. Could you not just send a function for weights to the standard data block? And if it doesn't get one, then it does nothing. Potentially, we could. I kind of like this, though, because like, yeah, I don't know. It's like... If weights were all one as a default, then we could use the one solution for... Yeah, yeah, you could. I find it's a little bit too coupled for me. I don't love it, but it would be doable. Unnecessary multiplication, I suppose. You know, I like how nicely decoupled this is. So I think this is what I want it to look like. So... So I would look at how the splitters work. So the splitter... OK, so the splits gets created here in datasets. Cool. And then... I wonder if datasets remembers what those splits are. Oh, I don't have tags here. What do you mean no tags file? OK, there we go. Datasets. So that's Ctrl-right-square-bracket to remind you to jump to a symbol in Vim. I see. And that's actually mainly happening in this inheritance. The superclass is where... This is split stuff. Splits. I see. There is a splits. So dss.splits. OK. dss.splits. Yeah, so there's the indices of the training and test sets. And so that's the indices of the training set. So the actual weights we want are those ones. So over here... We can say training weights are... So we'll change this to dataset from training set. And so this will be the weights at those indices. And that's what we'd use. Like so. self.splits. Thank you so much. dss.splits. self is a data block and it's actually the dss that has the splits. The data block has a function that knows how to split, but the split doesn't happen until you create it. That way you can get different random splits each time if you want them. Thank you for checking though. OK, so I'll export that. And probably be good to have auto load going, but we don't, so be it. OK. Now that we did miss a self, but it's not the one you thought of. This one here. Yeah. OK. I guess actually if I just comment this out, then we can just run all above without worrying. Aha! OK, things are happening. So dls equals that. OK, that looks pretty good. OK, so I think we've created our feature. So then the next thing I would do is to, it would be very, very weird if any tests broke, but I would go ahead and run the tests. I would then create an issue for my feature, and so I've got a bunch of tiny little aliases and functions, one's called enhancement, which creates an issue with the enhancement label. So I'll go enhancement, add data block dot weighted data loaders. So that creates the issue. As 3706. So if you were interested, you could take a look at that issue. Not the world's most interesting issue, but there it is. All right, looks like the tests are basically, oh, no, we've got an issue. There we go. So we've got a test that's failed. Range index must be integers or slices. Yes. Right. So I'm glad we checked. OK, so the problem here is that I sliced into my weights on the assumption that this is something I can slice into, which would only be true if it was a tensor or an array. But in this case, actually, my weights are not either of those things. So. What would I do to fix that? There's a question here. Yeah. When you split, you only get you back the index of the training and validation data set. And how can you know this is the weights because you haven't actually do the calculation and do the inverse of one square root kind of thing. The weights are being passed in as a parameter. And so we calculated the weights up here. Yep. And then we passed them in. Yeah. What's the incorrect type that's coming through in the test? It's not that it's an incorrect type. It's that see how here I'm indexing into the weights using my splits. This here is a list or an array. You can't index into a Python list with a list. You can only do that with tensors or non-py arrays. Yeah, I mean, what we actually want to do is check whether it's an array type. Is there an is a listy or something that function? There is, but that's not quite I think what the opposite, which is, is this the kind of thing that one could expect to be able to do non-py style indexing on? And I believe the correct way to do that might be to look for this thing. Yeah. So I would be inclined to say. And there may, there may well already be something in fast AI that knows how to check for this, to be honest. Oh, WG. Okay. So this what's this thing? Oh, that's something that's commented out. All right. So I guess I don't have anything which checks for that. So we'll just do it manually. So if weights has the Dunder array attribute. Because I'm pretty sure that tensors have that as well. Yeah, it does. So if it has that attribute, then I think we're good to go. Otherwise, we can use a list comprehension. Oh, you know what we could do? Yeah. Okay. What we'll do is we'll just say if it doesn't have that. I don't know if this is too, too rude to change their weights. But I think this is fine. It's making an array. Not a NumPy type array. It's probably going to benefit from being converted to one anyway, right? Yeah, I mean, I don't see a downside. Passes our test. Okay, so. And that was our only test that failed, which is now passing. So I would now say we've fixed issue 3706. So I've got to fix this little function that does that 3706. Okay. And so now if we look at that issue, you'll see that it's been resolved using this commit. Yeah. But what do you commit from the notebook? Do you sort of have it like reset with empty cells or do you run the cells? I commit them basically however they are, but with unnecessary metadata removed. So there's a hook that automatically runs this function, which is the thing that removes stuff like the execution count, unnecessary notebook metadata, stuff like that. So the idea is that the notebooks want to have all the outputs in place because they get turned into documentation. And we wouldn't want to run them all in continuous integration to create the documentation because they can involve spending 10 hours training an NLP model, for example. So we don't remove the outputs for that reason. And also because I want people to be able to look at the notebooks in GitHub and see, you know, all the pictures and stuff. All right. I better stop there. Oh, that's interesting. Did I? Okay. I guess I don't have my hook installed. So I'm glad I ran that manually. So you can see exactly what it does, right? Empties out the execution counts and removes the metadata. Sorry for another question. I'm just trying to find it. Is that GitHub available in the repo or do you do? Yeah. So it's if you go MB dev install GitHub, it installs the hook. And specifically, it's going to see. Is that under NBS folder? No, this is part of NB dev. Oh, OK. Right. So once that package is installed, it's a built in command in there. And so that then installs a filter here. I'll read more about it. Thanks. And it also installs a get hook to trust the notebooks, which calls NB dev trust NBs. Anyway, yeah, that's all in the NB dev docs. And then what's going to happen now on the fast AI on the GitHub side is it's now busily running all the tests again. Like so. And one of the things that checks is to make sure that the notebooks are clean and that the exports been run. Then it checks all the notebooks somewhat in parallel. All right. I better go. See you all. Thanks. Bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.88, "text": " So you've got a new patty submission.", "tokens": [407, 291, 600, 658, 257, 777, 1947, 874, 23689, 13], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 1, "seek": 0, "start": 3.88, "end": 4.92, "text": " Let's take a look.", "tokens": [961, 311, 747, 257, 574, 13], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 2, "seek": 0, "start": 4.92, "end": 5.76, "text": " Kaggle.", "tokens": [48751, 22631, 13], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 3, "seek": 0, "start": 7.76, "end": 8.6, "text": " Competition.", "tokens": [43634, 13], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 4, "seek": 0, "start": 8.6, "end": 10.28, "text": " By the way, it's really beautiful to see", "tokens": [3146, 264, 636, 11, 309, 311, 534, 2238, 281, 536], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 5, "seek": 0, "start": 10.28, "end": 12.68, "text": " over the last week or two,", "tokens": [670, 264, 1036, 1243, 420, 732, 11], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 6, "seek": 0, "start": 12.68, "end": 14.72, "text": " all these fast AI people just pop up", "tokens": [439, 613, 2370, 7318, 561, 445, 1665, 493], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 7, "seek": 0, "start": 14.72, "end": 16.240000000000002, "text": " at the top of that leaderboard.", "tokens": [412, 264, 1192, 295, 300, 5263, 3787, 13], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 8, "seek": 0, "start": 16.240000000000002, "end": 17.080000000000002, "text": " It's so cool.", "tokens": [467, 311, 370, 1627, 13], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 9, "seek": 0, "start": 17.080000000000002, "end": 22.080000000000002, "text": " Okay, fast AI, fast AI, fast AI, fast AI, fast AI.", "tokens": [1033, 11, 2370, 7318, 11, 2370, 7318, 11, 2370, 7318, 11, 2370, 7318, 11, 2370, 7318, 13], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 10, "seek": 0, "start": 22.84, "end": 23.68, "text": " Who's this person?", "tokens": [2102, 311, 341, 954, 30], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 11, "seek": 0, "start": 23.68, "end": 24.7, "text": " Is this fast AI?", "tokens": [1119, 341, 2370, 7318, 30], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 12, "seek": 0, "start": 27.0, "end": 29.0, "text": " At least the top five.", "tokens": [1711, 1935, 264, 1192, 1732, 13], "temperature": 0.0, "avg_logprob": -0.23537670771280925, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.1774483472108841}, {"id": 13, "seek": 2900, "start": 29.0, "end": 31.64, "text": " Yeah, like most of the top five or top 10", "tokens": [865, 11, 411, 881, 295, 264, 1192, 1732, 420, 1192, 1266], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 14, "seek": 2900, "start": 31.64, "end": 35.24, "text": " are following you in these walkthroughs.", "tokens": [366, 3480, 291, 294, 613, 1792, 11529, 82, 13], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 15, "seek": 2900, "start": 37.16, "end": 38.36, "text": " You've all got the same score though.", "tokens": [509, 600, 439, 658, 264, 912, 6175, 1673, 13], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 16, "seek": 2900, "start": 38.36, "end": 39.86, "text": " Somebody's got to like, you know,", "tokens": [13463, 311, 658, 281, 411, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 17, "seek": 2900, "start": 39.86, "end": 41.18, "text": " Kurian's got something.", "tokens": [16481, 952, 311, 658, 746, 13], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 18, "seek": 2900, "start": 42.44, "end": 44.08, "text": " Secret source there.", "tokens": [7400, 4009, 456, 13], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 19, "seek": 2900, "start": 46.94, "end": 49.24, "text": " Well, I've got a few ideas I can show you guys today", "tokens": [1042, 11, 286, 600, 658, 257, 1326, 3487, 286, 393, 855, 291, 1074, 965], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 20, "seek": 2900, "start": 49.24, "end": 51.480000000000004, "text": " if you want to try and take it a bit further,", "tokens": [498, 291, 528, 281, 853, 293, 747, 309, 257, 857, 3052, 11], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 21, "seek": 2900, "start": 54.16, "end": 55.519999999999996, "text": " which I bet you do.", "tokens": [597, 286, 778, 291, 360, 13], "temperature": 0.0, "avg_logprob": -0.289256591796875, "compression_ratio": 1.5071090047393365, "no_speech_prob": 8.476599032292143e-05}, {"id": 22, "seek": 5552, "start": 55.52, "end": 60.52, "text": " Anybody have any comments or questions in the meantime?", "tokens": [19082, 362, 604, 3053, 420, 1651, 294, 264, 14991, 30], "temperature": 0.0, "avg_logprob": -0.35994695580523944, "compression_ratio": 1.0526315789473684, "no_speech_prob": 3.5306820791447535e-05}, {"id": 23, "seek": 5552, "start": 76.0, "end": 76.84, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.35994695580523944, "compression_ratio": 1.0526315789473684, "no_speech_prob": 3.5306820791447535e-05}, {"id": 24, "seek": 7684, "start": 76.84, "end": 81.84, "text": " So, chair screen.", "tokens": [407, 11, 6090, 2568, 13], "temperature": 0.0, "avg_logprob": -0.3655587322307083, "compression_ratio": 1.3603603603603605, "no_speech_prob": 2.045914516202174e-05}, {"id": 25, "seek": 7684, "start": 86.96000000000001, "end": 88.56, "text": " And that's the right screen.", "tokens": [400, 300, 311, 264, 558, 2568, 13], "temperature": 0.0, "avg_logprob": -0.3655587322307083, "compression_ratio": 1.3603603603603605, "no_speech_prob": 2.045914516202174e-05}, {"id": 26, "seek": 7684, "start": 89.88000000000001, "end": 92.16, "text": " And I'll move you guys onto the other screen.", "tokens": [400, 286, 603, 1286, 291, 1074, 3911, 264, 661, 2568, 13], "temperature": 0.0, "avg_logprob": -0.3655587322307083, "compression_ratio": 1.3603603603603605, "no_speech_prob": 2.045914516202174e-05}, {"id": 27, "seek": 7684, "start": 92.16, "end": 93.44, "text": " And now I can see.", "tokens": [400, 586, 286, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.3655587322307083, "compression_ratio": 1.3603603603603605, "no_speech_prob": 2.045914516202174e-05}, {"id": 28, "seek": 7684, "start": 95.56, "end": 97.04, "text": " Yeah, all right.", "tokens": [865, 11, 439, 558, 13], "temperature": 0.0, "avg_logprob": -0.3655587322307083, "compression_ratio": 1.3603603603603605, "no_speech_prob": 2.045914516202174e-05}, {"id": 29, "seek": 9704, "start": 97.04, "end": 105.56, "text": " So, addy leaderboard.", "tokens": [407, 11, 909, 88, 5263, 3787, 13], "temperature": 0.0, "avg_logprob": -0.566562853361431, "compression_ratio": 0.974025974025974, "no_speech_prob": 1.862709177657962e-05}, {"id": 30, "seek": 9704, "start": 107.68, "end": 108.52000000000001, "text": " There we are.", "tokens": [821, 321, 366, 13], "temperature": 0.0, "avg_logprob": -0.566562853361431, "compression_ratio": 0.974025974025974, "no_speech_prob": 1.862709177657962e-05}, {"id": 31, "seek": 9704, "start": 117.96000000000001, "end": 119.56, "text": " Where's Radek?", "tokens": [2305, 311, 497, 762, 74, 30], "temperature": 0.0, "avg_logprob": -0.566562853361431, "compression_ratio": 0.974025974025974, "no_speech_prob": 1.862709177657962e-05}, {"id": 32, "seek": 9704, "start": 119.56, "end": 120.72, "text": " Not here.", "tokens": [1726, 510, 13], "temperature": 0.0, "avg_logprob": -0.566562853361431, "compression_ratio": 0.974025974025974, "no_speech_prob": 1.862709177657962e-05}, {"id": 33, "seek": 9704, "start": 120.72, "end": 122.56, "text": " Serada, I see.", "tokens": [4210, 1538, 11, 286, 536, 13], "temperature": 0.0, "avg_logprob": -0.566562853361431, "compression_ratio": 0.974025974025974, "no_speech_prob": 1.862709177657962e-05}, {"id": 34, "seek": 12256, "start": 122.56, "end": 123.4, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.3096968552161907, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00015289198199752718}, {"id": 35, "seek": 12256, "start": 126.88, "end": 129.84, "text": " One thing that I guess it would be nice", "tokens": [1485, 551, 300, 286, 2041, 309, 576, 312, 1481], "temperature": 0.0, "avg_logprob": -0.3096968552161907, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00015289198199752718}, {"id": 36, "seek": 12256, "start": 129.84, "end": 132.76, "text": " if it wasn't so sort of, I don't know,", "tokens": [498, 309, 2067, 380, 370, 1333, 295, 11, 286, 500, 380, 458, 11], "temperature": 0.0, "avg_logprob": -0.3096968552161907, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00015289198199752718}, {"id": 37, "seek": 12256, "start": 132.76, "end": 137.76, "text": " a little bit of a mess because I set this up in paper space", "tokens": [257, 707, 857, 295, 257, 2082, 570, 286, 992, 341, 493, 294, 3035, 1901], "temperature": 0.0, "avg_logprob": -0.3096968552161907, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00015289198199752718}, {"id": 38, "seek": 12256, "start": 138.44, "end": 140.4, "text": " and then started running it.", "tokens": [293, 550, 1409, 2614, 309, 13], "temperature": 0.0, "avg_logprob": -0.3096968552161907, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00015289198199752718}, {"id": 39, "seek": 12256, "start": 140.4, "end": 143.84, "text": " And then I went to bed because it was taking so long.", "tokens": [400, 550, 286, 1437, 281, 2901, 570, 309, 390, 1940, 370, 938, 13], "temperature": 0.0, "avg_logprob": -0.3096968552161907, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.00015289198199752718}, {"id": 40, "seek": 14384, "start": 143.84, "end": 148.84, "text": " And I just have a fear that if my browser sleeps", "tokens": [400, 286, 445, 362, 257, 4240, 300, 498, 452, 11185, 37991], "temperature": 0.0, "avg_logprob": -0.2575308014364803, "compression_ratio": 1.4339622641509433, "no_speech_prob": 3.265365012339316e-05}, {"id": 41, "seek": 14384, "start": 155.28, "end": 160.28, "text": " or goes to sleep, that it'll just basically stop the session", "tokens": [420, 1709, 281, 2817, 11, 300, 309, 603, 445, 1936, 1590, 264, 5481], "temperature": 0.0, "avg_logprob": -0.2575308014364803, "compression_ratio": 1.4339622641509433, "no_speech_prob": 3.265365012339316e-05}, {"id": 42, "seek": 14384, "start": 161.36, "end": 164.76, "text": " even though there's more hours and the process", "tokens": [754, 1673, 456, 311, 544, 2496, 293, 264, 1399], "temperature": 0.0, "avg_logprob": -0.2575308014364803, "compression_ratio": 1.4339622641509433, "no_speech_prob": 3.265365012339316e-05}, {"id": 43, "seek": 14384, "start": 164.76, "end": 167.48000000000002, "text": " in the workstation is running.", "tokens": [294, 264, 589, 19159, 307, 2614, 13], "temperature": 0.0, "avg_logprob": -0.2575308014364803, "compression_ratio": 1.4339622641509433, "no_speech_prob": 3.265365012339316e-05}, {"id": 44, "seek": 14384, "start": 167.48000000000002, "end": 168.68, "text": " I wasn't sure.", "tokens": [286, 2067, 380, 988, 13], "temperature": 0.0, "avg_logprob": -0.2575308014364803, "compression_ratio": 1.4339622641509433, "no_speech_prob": 3.265365012339316e-05}, {"id": 45, "seek": 14384, "start": 168.68, "end": 172.0, "text": " So, I mean, it shouldn't,", "tokens": [407, 11, 286, 914, 11, 309, 4659, 380, 11], "temperature": 0.0, "avg_logprob": -0.2575308014364803, "compression_ratio": 1.4339622641509433, "no_speech_prob": 3.265365012339316e-05}, {"id": 46, "seek": 17200, "start": 172.0, "end": 177.0, "text": " but what happens is it queues up for when your browser", "tokens": [457, 437, 2314, 307, 309, 631, 1247, 493, 337, 562, 428, 11185], "temperature": 0.0, "avg_logprob": -0.15745690735903653, "compression_ratio": 1.5080213903743316, "no_speech_prob": 2.013628909480758e-05}, {"id": 47, "seek": 17200, "start": 179.32, "end": 180.44, "text": " comes back.", "tokens": [1487, 646, 13], "temperature": 0.0, "avg_logprob": -0.15745690735903653, "compression_ratio": 1.5080213903743316, "no_speech_prob": 2.013628909480758e-05}, {"id": 48, "seek": 17200, "start": 180.44, "end": 183.2, "text": " But the problem is there is some limit", "tokens": [583, 264, 1154, 307, 456, 307, 512, 4948], "temperature": 0.0, "avg_logprob": -0.15745690735903653, "compression_ratio": 1.5080213903743316, "no_speech_prob": 2.013628909480758e-05}, {"id": 49, "seek": 17200, "start": 183.2, "end": 184.48, "text": " to how much it'll queue.", "tokens": [281, 577, 709, 309, 603, 18639, 13], "temperature": 0.0, "avg_logprob": -0.15745690735903653, "compression_ratio": 1.5080213903743316, "no_speech_prob": 2.013628909480758e-05}, {"id": 50, "seek": 17200, "start": 185.48, "end": 190.4, "text": " So, although it'll have run, if you've hit that limit,", "tokens": [407, 11, 4878, 309, 603, 362, 1190, 11, 498, 291, 600, 2045, 300, 4948, 11], "temperature": 0.0, "avg_logprob": -0.15745690735903653, "compression_ratio": 1.5080213903743316, "no_speech_prob": 2.013628909480758e-05}, {"id": 51, "seek": 17200, "start": 190.4, "end": 192.2, "text": " you won't see all the outputs,", "tokens": [291, 1582, 380, 536, 439, 264, 23930, 11], "temperature": 0.0, "avg_logprob": -0.15745690735903653, "compression_ratio": 1.5080213903743316, "no_speech_prob": 2.013628909480758e-05}, {"id": 52, "seek": 17200, "start": 193.64, "end": 195.16, "text": " which is nearly just as bad.", "tokens": [597, 307, 6217, 445, 382, 1578, 13], "temperature": 0.0, "avg_logprob": -0.15745690735903653, "compression_ratio": 1.5080213903743316, "no_speech_prob": 2.013628909480758e-05}, {"id": 53, "seek": 19516, "start": 195.16, "end": 200.16, "text": " So, there's a few things you can do.", "tokens": [407, 11, 456, 311, 257, 1326, 721, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.41433416387086275, "compression_ratio": 1.5185185185185186, "no_speech_prob": 8.662914297019597e-06}, {"id": 54, "seek": 19516, "start": 203.76, "end": 207.2, "text": " The most obvious one would be to use nvdev", "tokens": [440, 881, 6322, 472, 576, 312, 281, 764, 297, 85, 40343], "temperature": 0.0, "avg_logprob": -0.41433416387086275, "compression_ratio": 1.5185185185185186, "no_speech_prob": 8.662914297019597e-06}, {"id": 55, "seek": 19516, "start": 207.2, "end": 211.0, "text": " to export the notebook to a script", "tokens": [281, 10725, 264, 21060, 281, 257, 5755], "temperature": 0.0, "avg_logprob": -0.41433416387086275, "compression_ratio": 1.5185185185185186, "no_speech_prob": 8.662914297019597e-06}, {"id": 56, "seek": 19516, "start": 211.0, "end": 213.84, "text": " and then run the script in Tmux.", "tokens": [293, 550, 1190, 264, 5755, 294, 314, 76, 2449, 13], "temperature": 0.0, "avg_logprob": -0.41433416387086275, "compression_ratio": 1.5185185185185186, "no_speech_prob": 8.662914297019597e-06}, {"id": 57, "seek": 19516, "start": 213.84, "end": 215.44, "text": " Because then you can close it down,", "tokens": [1436, 550, 291, 393, 1998, 309, 760, 11], "temperature": 0.0, "avg_logprob": -0.41433416387086275, "compression_ratio": 1.5185185185185186, "no_speech_prob": 8.662914297019597e-06}, {"id": 58, "seek": 19516, "start": 215.44, "end": 220.44, "text": " come back, reattach Tmux and there it is.", "tokens": [808, 646, 11, 319, 1591, 608, 314, 76, 2449, 293, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.41433416387086275, "compression_ratio": 1.5185185185185186, "no_speech_prob": 8.662914297019597e-06}, {"id": 59, "seek": 19516, "start": 220.44, "end": 221.96, "text": " Okay, that'd be interesting.", "tokens": [1033, 11, 300, 1116, 312, 1880, 13], "temperature": 0.0, "avg_logprob": -0.41433416387086275, "compression_ratio": 1.5185185185185186, "no_speech_prob": 8.662914297019597e-06}, {"id": 60, "seek": 19516, "start": 221.96, "end": 224.51999999999998, "text": " Now, something that I've noticed", "tokens": [823, 11, 746, 300, 286, 600, 5694], "temperature": 0.0, "avg_logprob": -0.41433416387086275, "compression_ratio": 1.5185185185185186, "no_speech_prob": 8.662914297019597e-06}, {"id": 61, "seek": 22452, "start": 224.52, "end": 228.8, "text": " is something, yeah, so maybe we'll look at that sometime.", "tokens": [307, 746, 11, 1338, 11, 370, 1310, 321, 603, 574, 412, 300, 15053, 13], "temperature": 0.0, "avg_logprob": -0.2137664886842291, "compression_ratio": 1.398876404494382, "no_speech_prob": 2.4679733542143367e-05}, {"id": 62, "seek": 22452, "start": 230.4, "end": 233.52, "text": " Now, something I don't, well,", "tokens": [823, 11, 746, 286, 500, 380, 11, 731, 11], "temperature": 0.0, "avg_logprob": -0.2137664886842291, "compression_ratio": 1.398876404494382, "no_speech_prob": 2.4679733542143367e-05}, {"id": 63, "seek": 22452, "start": 235.04000000000002, "end": 237.68, "text": " does paperspace gradient let you have,", "tokens": [775, 10577, 17940, 16235, 718, 291, 362, 11], "temperature": 0.0, "avg_logprob": -0.2137664886842291, "compression_ratio": 1.398876404494382, "no_speech_prob": 2.4679733542143367e-05}, {"id": 64, "seek": 22452, "start": 239.24, "end": 242.56, "text": " does it let you SSH in with a suitable IP?", "tokens": [775, 309, 718, 291, 12238, 39, 294, 365, 257, 12873, 8671, 30], "temperature": 0.0, "avg_logprob": -0.2137664886842291, "compression_ratio": 1.398876404494382, "no_speech_prob": 2.4679733542143367e-05}, {"id": 65, "seek": 22452, "start": 242.56, "end": 244.36, "text": " I'm not sure.", "tokens": [286, 478, 406, 988, 13], "temperature": 0.0, "avg_logprob": -0.2137664886842291, "compression_ratio": 1.398876404494382, "no_speech_prob": 2.4679733542143367e-05}, {"id": 66, "seek": 22452, "start": 244.36, "end": 247.72, "text": " If you've got your own GPU at home,", "tokens": [759, 291, 600, 658, 428, 1065, 18407, 412, 1280, 11], "temperature": 0.0, "avg_logprob": -0.2137664886842291, "compression_ratio": 1.398876404494382, "no_speech_prob": 2.4679733542143367e-05}, {"id": 67, "seek": 22452, "start": 247.72, "end": 251.04000000000002, "text": " or on AWS or GCP or whatever,", "tokens": [420, 322, 17650, 420, 460, 20049, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.2137664886842291, "compression_ratio": 1.398876404494382, "no_speech_prob": 2.4679733542143367e-05}, {"id": 68, "seek": 25104, "start": 251.04, "end": 256.03999999999996, "text": " then what I do is I run xRDP on it,", "tokens": [550, 437, 286, 360, 307, 286, 1190, 2031, 49, 11373, 322, 309, 11], "temperature": 0.0, "avg_logprob": -0.16208043645639889, "compression_ratio": 1.330827067669173, "no_speech_prob": 3.392940470803296e-06}, {"id": 69, "seek": 25104, "start": 257.76, "end": 260.12, "text": " which is a remote desktop server.", "tokens": [597, 307, 257, 8607, 14502, 7154, 13], "temperature": 0.0, "avg_logprob": -0.16208043645639889, "compression_ratio": 1.330827067669173, "no_speech_prob": 3.392940470803296e-06}, {"id": 70, "seek": 25104, "start": 260.12, "end": 265.12, "text": " And then I can connect to it like so,", "tokens": [400, 550, 286, 393, 1745, 281, 309, 411, 370, 11], "temperature": 0.0, "avg_logprob": -0.16208043645639889, "compression_ratio": 1.330827067669173, "no_speech_prob": 3.392940470803296e-06}, {"id": 71, "seek": 25104, "start": 266.8, "end": 270.44, "text": " and run Firefox.", "tokens": [293, 1190, 46613, 13], "temperature": 0.0, "avg_logprob": -0.16208043645639889, "compression_ratio": 1.330827067669173, "no_speech_prob": 3.392940470803296e-06}, {"id": 72, "seek": 25104, "start": 273.08, "end": 278.08, "text": " And so this is my, yeah, this is my server's screen,", "tokens": [400, 370, 341, 307, 452, 11, 1338, 11, 341, 307, 452, 7154, 311, 2568, 11], "temperature": 0.0, "avg_logprob": -0.16208043645639889, "compression_ratio": 1.330827067669173, "no_speech_prob": 3.392940470803296e-06}, {"id": 73, "seek": 27808, "start": 278.08, "end": 279.24, "text": " remote desktopping in.", "tokens": [8607, 14502, 3381, 294, 13], "temperature": 0.0, "avg_logprob": -0.47177906036376954, "compression_ratio": 1.0813953488372092, "no_speech_prob": 5.826514461659826e-05}, {"id": 74, "seek": 27808, "start": 279.24, "end": 282.28, "text": " So if I now go in and run something.", "tokens": [407, 498, 286, 586, 352, 294, 293, 1190, 746, 13], "temperature": 0.0, "avg_logprob": -0.47177906036376954, "compression_ratio": 1.0813953488372092, "no_speech_prob": 5.826514461659826e-05}, {"id": 75, "seek": 28228, "start": 282.28, "end": 301.28, "text": " Patty, I remember from last time.", "tokens": [44116, 11, 286, 1604, 490, 1036, 565, 13], "temperature": 0.0, "avg_logprob": -0.8112549200290586, "compression_ratio": 1.6, "no_speech_prob": 3.1186689739115536e-05}, {"id": 76, "seek": 28228, "start": 302.96, "end": 304.96, "text": " Okay, so I can set this running.", "tokens": [1033, 11, 370, 286, 393, 992, 341, 2614, 13], "temperature": 0.0, "avg_logprob": -0.8112549200290586, "compression_ratio": 1.6, "no_speech_prob": 3.1186689739115536e-05}, {"id": 77, "seek": 28228, "start": 304.96, "end": 306.96, "text": " So I can set this running.", "tokens": [407, 286, 393, 992, 341, 2614, 13], "temperature": 0.0, "avg_logprob": -0.8112549200290586, "compression_ratio": 1.6, "no_speech_prob": 3.1186689739115536e-05}, {"id": 78, "seek": 28228, "start": 306.96, "end": 308.96, "text": " So I can set this running.", "tokens": [407, 286, 393, 992, 341, 2614, 13], "temperature": 0.0, "avg_logprob": -0.8112549200290586, "compression_ratio": 1.6, "no_speech_prob": 3.1186689739115536e-05}, {"id": 79, "seek": 30896, "start": 308.96, "end": 312.59999999999997, "text": " Okay, so I can set this running,", "tokens": [1033, 11, 370, 286, 393, 992, 341, 2614, 11], "temperature": 0.0, "avg_logprob": -0.22956089491254827, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.184228494821582e-05}, {"id": 80, "seek": 30896, "start": 312.59999999999997, "end": 315.08, "text": " and then I can close it down,", "tokens": [293, 550, 286, 393, 1998, 309, 760, 11], "temperature": 0.0, "avg_logprob": -0.22956089491254827, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.184228494821582e-05}, {"id": 81, "seek": 30896, "start": 317.2, "end": 320.15999999999997, "text": " go to sleep, come back the next day,", "tokens": [352, 281, 2817, 11, 808, 646, 264, 958, 786, 11], "temperature": 0.0, "avg_logprob": -0.22956089491254827, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.184228494821582e-05}, {"id": 82, "seek": 30896, "start": 320.15999999999997, "end": 321.64, "text": " reconnect to that screen,", "tokens": [30095, 281, 300, 2568, 11], "temperature": 0.0, "avg_logprob": -0.22956089491254827, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.184228494821582e-05}, {"id": 83, "seek": 30896, "start": 324.47999999999996, "end": 326.52, "text": " and it's still been running.", "tokens": [293, 309, 311, 920, 668, 2614, 13], "temperature": 0.0, "avg_logprob": -0.22956089491254827, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.184228494821582e-05}, {"id": 84, "seek": 30896, "start": 326.52, "end": 330.08, "text": " So like that's the preferred way to do it.", "tokens": [407, 411, 300, 311, 264, 16494, 636, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.22956089491254827, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.184228494821582e-05}, {"id": 85, "seek": 30896, "start": 331.47999999999996, "end": 332.91999999999996, "text": " But I, yeah, as I say,", "tokens": [583, 286, 11, 1338, 11, 382, 286, 584, 11], "temperature": 0.0, "avg_logprob": -0.22956089491254827, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.184228494821582e-05}, {"id": 86, "seek": 33292, "start": 332.92, "end": 337.92, "text": " I don't know if it's possible on paper space gradient.", "tokens": [286, 500, 380, 458, 498, 309, 311, 1944, 322, 3035, 1901, 16235, 13], "temperature": 0.0, "avg_logprob": -0.3079029532039867, "compression_ratio": 1.375796178343949, "no_speech_prob": 7.720777648501098e-05}, {"id": 87, "seek": 33292, "start": 343.16, "end": 345.20000000000005, "text": " You could do it, sorry, go on.", "tokens": [509, 727, 360, 309, 11, 2597, 11, 352, 322, 13], "temperature": 0.0, "avg_logprob": -0.3079029532039867, "compression_ratio": 1.375796178343949, "no_speech_prob": 7.720777648501098e-05}, {"id": 88, "seek": 33292, "start": 345.20000000000005, "end": 348.84000000000003, "text": " Machines seem to have a limit of six hours", "tokens": [12089, 1652, 1643, 281, 362, 257, 4948, 295, 2309, 2496], "temperature": 0.0, "avg_logprob": -0.3079029532039867, "compression_ratio": 1.375796178343949, "no_speech_prob": 7.720777648501098e-05}, {"id": 89, "seek": 33292, "start": 348.84000000000003, "end": 351.84000000000003, "text": " that I've seen so far.", "tokens": [300, 286, 600, 1612, 370, 1400, 13], "temperature": 0.0, "avg_logprob": -0.3079029532039867, "compression_ratio": 1.375796178343949, "no_speech_prob": 7.720777648501098e-05}, {"id": 90, "seek": 33292, "start": 351.84000000000003, "end": 356.84000000000003, "text": " If you subscribe to their pro or whatever,", "tokens": [759, 291, 3022, 281, 641, 447, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.3079029532039867, "compression_ratio": 1.375796178343949, "no_speech_prob": 7.720777648501098e-05}, {"id": 91, "seek": 35684, "start": 356.84, "end": 361.84, "text": " you can bump it up or get rid of it all together.", "tokens": [291, 393, 9961, 309, 493, 420, 483, 3973, 295, 309, 439, 1214, 13], "temperature": 0.0, "avg_logprob": -0.44269016810825895, "compression_ratio": 1.3900709219858156, "no_speech_prob": 3.534407005645335e-05}, {"id": 92, "seek": 35684, "start": 374.88, "end": 377.71999999999997, "text": " It's this tab here, machine tab,", "tokens": [467, 311, 341, 4421, 510, 11, 3479, 4421, 11], "temperature": 0.0, "avg_logprob": -0.44269016810825895, "compression_ratio": 1.3900709219858156, "no_speech_prob": 3.534407005645335e-05}, {"id": 93, "seek": 35684, "start": 377.71999999999997, "end": 380.03999999999996, "text": " you can change the auto shutdown.", "tokens": [291, 393, 1319, 264, 8399, 34927, 13], "temperature": 0.0, "avg_logprob": -0.44269016810825895, "compression_ratio": 1.3900709219858156, "no_speech_prob": 3.534407005645335e-05}, {"id": 94, "seek": 35684, "start": 380.03999999999996, "end": 382.67999999999995, "text": " Okay, it looks like a week's the maximum.", "tokens": [1033, 11, 309, 1542, 411, 257, 1243, 311, 264, 6674, 13], "temperature": 0.0, "avg_logprob": -0.44269016810825895, "compression_ratio": 1.3900709219858156, "no_speech_prob": 3.534407005645335e-05}, {"id": 95, "seek": 35684, "start": 382.67999999999995, "end": 384.47999999999996, "text": " Oh no, there's a limit there as well.", "tokens": [876, 572, 11, 456, 311, 257, 4948, 456, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.44269016810825895, "compression_ratio": 1.3900709219858156, "no_speech_prob": 3.534407005645335e-05}, {"id": 96, "seek": 38448, "start": 384.48, "end": 385.64000000000004, "text": " There's a limit there as well.", "tokens": [821, 311, 257, 4948, 456, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 97, "seek": 38448, "start": 392.72, "end": 393.56, "text": " When you're paying.", "tokens": [1133, 291, 434, 6229, 13], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 98, "seek": 38448, "start": 393.56, "end": 394.40000000000003, "text": " No, that's fine.", "tokens": [883, 11, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 99, "seek": 38448, "start": 394.40000000000003, "end": 395.92, "text": " When you're paying, but I mean,", "tokens": [1133, 291, 434, 6229, 11, 457, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 100, "seek": 38448, "start": 399.76, "end": 401.16, "text": " I think it's like eight bucks a month.", "tokens": [286, 519, 309, 311, 411, 3180, 11829, 257, 1618, 13], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 101, "seek": 38448, "start": 401.16, "end": 402.84000000000003, "text": " Yeah, eight bucks a month.", "tokens": [865, 11, 3180, 11829, 257, 1618, 13], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 102, "seek": 38448, "start": 402.84000000000003, "end": 403.76, "text": " You may as well.", "tokens": [509, 815, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 103, "seek": 38448, "start": 404.96000000000004, "end": 406.20000000000005, "text": " Yeah, I've got the pro,", "tokens": [865, 11, 286, 600, 658, 264, 447, 11], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 104, "seek": 38448, "start": 406.20000000000005, "end": 408.16, "text": " but I don't have on the,", "tokens": [457, 286, 500, 380, 362, 322, 264, 11], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 105, "seek": 38448, "start": 408.16, "end": 410.36, "text": " when you pick a free machine.", "tokens": [562, 291, 1888, 257, 1737, 3479, 13], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 106, "seek": 38448, "start": 410.36, "end": 411.68, "text": " Oh, yeah.", "tokens": [876, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.28718005693875825, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.645386459538713e-05}, {"id": 107, "seek": 41168, "start": 411.68, "end": 413.84000000000003, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.3911351804380064, "compression_ratio": 1.2302158273381294, "no_speech_prob": 1.0613529411784839e-05}, {"id": 108, "seek": 41168, "start": 415.96, "end": 417.44, "text": " Free P5000.", "tokens": [11551, 430, 44557, 13], "temperature": 0.0, "avg_logprob": -0.3911351804380064, "compression_ratio": 1.2302158273381294, "no_speech_prob": 1.0613529411784839e-05}, {"id": 109, "seek": 41168, "start": 427.44, "end": 428.92, "text": " Maximum of six hours, yep.", "tokens": [29076, 449, 295, 2309, 2496, 11, 18633, 13], "temperature": 0.0, "avg_logprob": -0.3911351804380064, "compression_ratio": 1.2302158273381294, "no_speech_prob": 1.0613529411784839e-05}, {"id": 110, "seek": 41168, "start": 431.0, "end": 433.88, "text": " So Jeremy, sorry to interrupt.", "tokens": [407, 17809, 11, 2597, 281, 12729, 13], "temperature": 0.0, "avg_logprob": -0.3911351804380064, "compression_ratio": 1.2302158273381294, "no_speech_prob": 1.0613529411784839e-05}, {"id": 111, "seek": 41168, "start": 433.88, "end": 438.52, "text": " Paper space in their support channels,", "tokens": [24990, 1901, 294, 641, 1406, 9235, 11], "temperature": 0.0, "avg_logprob": -0.3911351804380064, "compression_ratio": 1.2302158273381294, "no_speech_prob": 1.0613529411784839e-05}, {"id": 112, "seek": 41168, "start": 438.52, "end": 441.24, "text": " they talk about you can assign a public IP to a machine", "tokens": [436, 751, 466, 291, 393, 6269, 257, 1908, 8671, 281, 257, 3479], "temperature": 0.0, "avg_logprob": -0.3911351804380064, "compression_ratio": 1.2302158273381294, "no_speech_prob": 1.0613529411784839e-05}, {"id": 113, "seek": 44124, "start": 441.24, "end": 443.24, "text": " and then SSH to it.", "tokens": [293, 550, 12238, 39, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 114, "seek": 44124, "start": 443.24, "end": 445.88, "text": " So you could SSH and then T-MACS.", "tokens": [407, 291, 727, 12238, 39, 293, 550, 314, 12, 44, 4378, 50, 13], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 115, "seek": 44124, "start": 445.88, "end": 448.40000000000003, "text": " Is that for gradient machine though?", "tokens": [1119, 300, 337, 16235, 3479, 1673, 30], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 116, "seek": 44124, "start": 448.40000000000003, "end": 450.08, "text": " Well, good question.", "tokens": [1042, 11, 665, 1168, 13], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 117, "seek": 44124, "start": 450.08, "end": 450.92, "text": " I don't know about that.", "tokens": [286, 500, 380, 458, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 118, "seek": 44124, "start": 450.92, "end": 452.76, "text": " Look, I'm not sure that it would be.", "tokens": [2053, 11, 286, 478, 406, 988, 300, 309, 576, 312, 13], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 119, "seek": 44124, "start": 454.96000000000004, "end": 458.0, "text": " So advanced options.", "tokens": [407, 7339, 3956, 13], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 120, "seek": 44124, "start": 461.92, "end": 463.24, "text": " No, it's not.", "tokens": [883, 11, 309, 311, 406, 13], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 121, "seek": 44124, "start": 464.96000000000004, "end": 469.16, "text": " And so they also have this thing called core, right?", "tokens": [400, 370, 436, 611, 362, 341, 551, 1219, 4965, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.26469549925430963, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.7497279259259813e-05}, {"id": 122, "seek": 46916, "start": 469.16, "end": 474.16, "text": " Which are like more like AWS or Google servers,", "tokens": [3013, 366, 411, 544, 411, 17650, 420, 3329, 15909, 11], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 123, "seek": 46916, "start": 474.16, "end": 479.16, "text": " which absolutely lets you do a static IP.", "tokens": [597, 3122, 6653, 291, 360, 257, 13437, 8671, 13], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 124, "seek": 46916, "start": 479.52000000000004, "end": 480.52000000000004, "text": " And you don't even need,", "tokens": [400, 291, 500, 380, 754, 643, 11], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 125, "seek": 46916, "start": 480.52000000000004, "end": 483.20000000000005, "text": " I don't even know if you need a static IP necessarily,", "tokens": [286, 500, 380, 754, 458, 498, 291, 643, 257, 13437, 8671, 4725, 11], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 126, "seek": 46916, "start": 483.20000000000005, "end": 486.72, "text": " but you could use a dynamic IP.", "tokens": [457, 291, 727, 764, 257, 8546, 8671, 13], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 127, "seek": 46916, "start": 486.72, "end": 487.96000000000004, "text": " We've worked just as well.", "tokens": [492, 600, 2732, 445, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 128, "seek": 46916, "start": 488.88, "end": 489.76000000000005, "text": " Bit cheaper.", "tokens": [9101, 12284, 13], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 129, "seek": 46916, "start": 489.76000000000005, "end": 490.84000000000003, "text": " The thing is though,", "tokens": [440, 551, 307, 1673, 11], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 130, "seek": 46916, "start": 491.72, "end": 493.48, "text": " I reckon they're pretty expensive.", "tokens": [286, 29548, 436, 434, 1238, 5124, 13], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 131, "seek": 46916, "start": 494.72, "end": 495.56, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.23094655066421352, "compression_ratio": 1.5023696682464456, "no_speech_prob": 1.0269905942550395e-05}, {"id": 132, "seek": 49556, "start": 495.56, "end": 500.56, "text": " They're a pretty expensive product.", "tokens": [814, 434, 257, 1238, 5124, 1674, 13], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 133, "seek": 49556, "start": 501.68, "end": 504.6, "text": " So these are very basic GPUs.", "tokens": [407, 613, 366, 588, 3875, 18407, 82, 13], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 134, "seek": 49556, "start": 504.6, "end": 505.72, "text": " So that's not bad.", "tokens": [407, 300, 311, 406, 1578, 13], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 135, "seek": 49556, "start": 505.72, "end": 507.04, "text": " 45 cents an hour.", "tokens": [6905, 14941, 364, 1773, 13], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 136, "seek": 49556, "start": 509.24, "end": 510.92, "text": " I guess they're not too terrible.", "tokens": [286, 2041, 436, 434, 406, 886, 6237, 13], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 137, "seek": 49556, "start": 512.4, "end": 514.56, "text": " If you want to TX.", "tokens": [759, 291, 528, 281, 314, 55, 13], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 138, "seek": 49556, "start": 514.56, "end": 516.92, "text": " Oh no, I guess they're the same price really, 56 cents.", "tokens": [876, 572, 11, 286, 2041, 436, 434, 264, 912, 3218, 534, 11, 19687, 14941, 13], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 139, "seek": 49556, "start": 516.92, "end": 518.6, "text": " All right, I take that back.", "tokens": [1057, 558, 11, 286, 747, 300, 646, 13], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 140, "seek": 49556, "start": 518.6, "end": 520.12, "text": " I guess the thing I found expensive", "tokens": [286, 2041, 264, 551, 286, 1352, 5124], "temperature": 0.0, "avg_logprob": -0.2973964468946735, "compression_ratio": 1.5476190476190477, "no_speech_prob": 1.83417050720891e-05}, {"id": 141, "seek": 52012, "start": 520.12, "end": 526.12, "text": " was their CPU pricing for running it all the time.", "tokens": [390, 641, 13199, 17621, 337, 2614, 309, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.2961119374921245, "compression_ratio": 1.2620689655172415, "no_speech_prob": 8.861090464051813e-05}, {"id": 142, "seek": 52012, "start": 526.12, "end": 526.96, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.2961119374921245, "compression_ratio": 1.2620689655172415, "no_speech_prob": 8.861090464051813e-05}, {"id": 143, "seek": 52012, "start": 529.08, "end": 534.08, "text": " So Jeremy, with this RDP solution that you showed,", "tokens": [407, 17809, 11, 365, 341, 497, 11373, 3827, 300, 291, 4712, 11], "temperature": 0.0, "avg_logprob": -0.2961119374921245, "compression_ratio": 1.2620689655172415, "no_speech_prob": 8.861090464051813e-05}, {"id": 144, "seek": 52012, "start": 534.64, "end": 536.08, "text": " how does that work?", "tokens": [577, 775, 300, 589, 30], "temperature": 0.0, "avg_logprob": -0.2961119374921245, "compression_ratio": 1.2620689655172415, "no_speech_prob": 8.861090464051813e-05}, {"id": 145, "seek": 52012, "start": 536.08, "end": 538.0, "text": " Do you have an...", "tokens": [1144, 291, 362, 364, 485], "temperature": 0.0, "avg_logprob": -0.2961119374921245, "compression_ratio": 1.2620689655172415, "no_speech_prob": 8.861090464051813e-05}, {"id": 146, "seek": 52012, "start": 538.0, "end": 539.0, "text": " Oh, just a moment, Radit.", "tokens": [876, 11, 445, 257, 1623, 11, 9654, 270, 13], "temperature": 0.0, "avg_logprob": -0.2961119374921245, "compression_ratio": 1.2620689655172415, "no_speech_prob": 8.861090464051813e-05}, {"id": 147, "seek": 53900, "start": 539.0, "end": 554.0, "text": " Yeah.", "tokens": [50364, 865, 13, 51114], "temperature": 0.0, "avg_logprob": -0.790226411819458, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.0012122991029173136}, {"id": 148, "seek": 56900, "start": 569.56, "end": 594.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 1.0, "avg_logprob": -1.4888647715250651, "compression_ratio": 0.85, "no_speech_prob": 0.0036809700541198254}, {"id": 149, "seek": 59408, "start": 594.08, "end": 599.08, "text": " I didn't get what computer you're RDPing into.", "tokens": [286, 994, 380, 483, 437, 3820, 291, 434, 497, 11373, 278, 666, 13], "temperature": 0.0, "avg_logprob": -0.1839881854110889, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.04198237881064415}, {"id": 150, "seek": 59408, "start": 599.08, "end": 607.08, "text": " I'm RDPing to my own GPU machine, but it could just as well be a AWS machine or GCP machine.", "tokens": [286, 478, 497, 11373, 278, 281, 452, 1065, 18407, 3479, 11, 457, 309, 727, 445, 382, 731, 312, 257, 17650, 3479, 420, 460, 20049, 3479, 13], "temperature": 0.0, "avg_logprob": -0.1839881854110889, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.04198237881064415}, {"id": 151, "seek": 59408, "start": 607.08, "end": 612.08, "text": " This is basically the same as VNC, if you've come across VNC before.", "tokens": [639, 307, 1936, 264, 912, 382, 691, 45, 34, 11, 498, 291, 600, 808, 2108, 691, 45, 34, 949, 13], "temperature": 0.0, "avg_logprob": -0.1839881854110889, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.04198237881064415}, {"id": 152, "seek": 59408, "start": 612.08, "end": 620.08, "text": " RDP is the kind of Microsoft version of that. I like it generally quite a lot better.", "tokens": [497, 11373, 307, 264, 733, 295, 8116, 3037, 295, 300, 13, 286, 411, 309, 5101, 1596, 257, 688, 1101, 13], "temperature": 0.0, "avg_logprob": -0.1839881854110889, "compression_ratio": 1.4271844660194175, "no_speech_prob": 0.04198237881064415}, {"id": 153, "seek": 62008, "start": 620.08, "end": 628.08, "text": " And much to my surprise, the Mac client for RDP is better than the Windows client for RDP.", "tokens": [400, 709, 281, 452, 6365, 11, 264, 5707, 6423, 337, 497, 11373, 307, 1101, 813, 264, 8591, 6423, 337, 497, 11373, 13], "temperature": 0.0, "avg_logprob": -0.2131838181439568, "compression_ratio": 1.5068493150684932, "no_speech_prob": 7.839685713406652e-05}, {"id": 154, "seek": 62008, "start": 628.08, "end": 634.08, "text": " It even shows you a little mini screenshot, you know, of the screen.", "tokens": [467, 754, 3110, 291, 257, 707, 8382, 27712, 11, 291, 458, 11, 295, 264, 2568, 13], "temperature": 0.0, "avg_logprob": -0.2131838181439568, "compression_ratio": 1.5068493150684932, "no_speech_prob": 7.839685713406652e-05}, {"id": 155, "seek": 62008, "start": 634.08, "end": 641.08, "text": " So yeah, this is now finished training. No, not nearly finished. It's halfway through training, whatever.", "tokens": [407, 1338, 11, 341, 307, 586, 4335, 3097, 13, 883, 11, 406, 6217, 4335, 13, 467, 311, 15461, 807, 3097, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2131838181439568, "compression_ratio": 1.5068493150684932, "no_speech_prob": 7.839685713406652e-05}, {"id": 156, "seek": 62008, "start": 641.08, "end": 646.08, "text": " Was this tricky to set up because you're running a Linux server?", "tokens": [3027, 341, 12414, 281, 992, 493, 570, 291, 434, 2614, 257, 18734, 7154, 30], "temperature": 0.0, "avg_logprob": -0.2131838181439568, "compression_ratio": 1.5068493150684932, "no_speech_prob": 7.839685713406652e-05}, {"id": 157, "seek": 64608, "start": 646.08, "end": 657.08, "text": " Not even slightly tricky to set up. So yeah, you just...", "tokens": [1726, 754, 4748, 12414, 281, 992, 493, 13, 407, 1338, 11, 291, 445, 485], "temperature": 0.0, "avg_logprob": -0.17130031305200913, "compression_ratio": 1.3558282208588956, "no_speech_prob": 1.280463948205579e-05}, {"id": 158, "seek": 64608, "start": 657.08, "end": 663.08, "text": " It's called XRDP, since it's RDP for X Windows. And you just go app install.", "tokens": [467, 311, 1219, 1783, 49, 11373, 11, 1670, 309, 311, 497, 11373, 337, 1783, 8591, 13, 400, 291, 445, 352, 724, 3625, 13], "temperature": 0.0, "avg_logprob": -0.17130031305200913, "compression_ratio": 1.3558282208588956, "no_speech_prob": 1.280463948205579e-05}, {"id": 159, "seek": 64608, "start": 663.08, "end": 667.08, "text": " Yeah, I mean, I hate installing this kind of thing. It drives me crazy. But this is it.", "tokens": [865, 11, 286, 914, 11, 286, 4700, 20762, 341, 733, 295, 551, 13, 467, 11754, 385, 3219, 13, 583, 341, 307, 309, 13], "temperature": 0.0, "avg_logprob": -0.17130031305200913, "compression_ratio": 1.3558282208588956, "no_speech_prob": 1.280463948205579e-05}, {"id": 160, "seek": 66708, "start": 667.08, "end": 677.08, "text": " You just sudo app install, sudo add user, sudo systemctl restart.", "tokens": [509, 445, 459, 2595, 724, 3625, 11, 459, 2595, 909, 4195, 11, 459, 2595, 1185, 349, 75, 21022, 13], "temperature": 0.0, "avg_logprob": -0.08313024268960054, "compression_ratio": 1.4924242424242424, "no_speech_prob": 1.0288415069226176e-05}, {"id": 161, "seek": 66708, "start": 677.08, "end": 688.08, "text": " And then you might also want to run sudo systemctl enable, which will cause it to automatically start when you start your computer.", "tokens": [400, 550, 291, 1062, 611, 528, 281, 1190, 459, 2595, 1185, 349, 75, 9528, 11, 597, 486, 3082, 309, 281, 6772, 722, 562, 291, 722, 428, 3820, 13], "temperature": 0.0, "avg_logprob": -0.08313024268960054, "compression_ratio": 1.4924242424242424, "no_speech_prob": 1.0288415069226176e-05}, {"id": 162, "seek": 68808, "start": 688.08, "end": 698.08, "text": " And I don't think I... Oh, you know, if you've got a firewall, you have to let it in. So it's port 3389.", "tokens": [400, 286, 500, 380, 519, 286, 485, 876, 11, 291, 458, 11, 498, 291, 600, 658, 257, 36109, 11, 291, 362, 281, 718, 309, 294, 13, 407, 309, 311, 2436, 11816, 21115, 13], "temperature": 0.0, "avg_logprob": -0.09531940483465427, "compression_ratio": 1.446808510638298, "no_speech_prob": 1.0614333405101206e-05}, {"id": 163, "seek": 68808, "start": 698.08, "end": 704.08, "text": " Basically this line of code. And I think I did have a firewall. So I also ran this.", "tokens": [8537, 341, 1622, 295, 3089, 13, 400, 286, 519, 286, 630, 362, 257, 36109, 13, 407, 286, 611, 5872, 341, 13], "temperature": 0.0, "avg_logprob": -0.09531940483465427, "compression_ratio": 1.446808510638298, "no_speech_prob": 1.0614333405101206e-05}, {"id": 164, "seek": 68808, "start": 704.08, "end": 714.08, "text": " Yeah, that was it. It just used my username and password that I had on the machine.", "tokens": [865, 11, 300, 390, 309, 13, 467, 445, 1143, 452, 30351, 293, 11524, 300, 286, 632, 322, 264, 3479, 13], "temperature": 0.0, "avg_logprob": -0.09531940483465427, "compression_ratio": 1.446808510638298, "no_speech_prob": 1.0614333405101206e-05}, {"id": 165, "seek": 71408, "start": 714.08, "end": 723.08, "text": " Amazing. Yeah. Very surprisingly not annoying.", "tokens": [14165, 13, 865, 13, 4372, 17600, 406, 11304, 13], "temperature": 0.0, "avg_logprob": -0.2516829095235685, "compression_ratio": 1.2985074626865671, "no_speech_prob": 2.0142708308412693e-05}, {"id": 166, "seek": 71408, "start": 723.08, "end": 734.08, "text": " And then I think I just installed Microsoft Remote Desktop from the Mac app store or on Windows. I think it comes with Windows.", "tokens": [400, 550, 286, 519, 286, 445, 8899, 8116, 44858, 49044, 490, 264, 5707, 724, 3531, 420, 322, 8591, 13, 286, 519, 309, 1487, 365, 8591, 13], "temperature": 0.0, "avg_logprob": -0.2516829095235685, "compression_ratio": 1.2985074626865671, "no_speech_prob": 2.0142708308412693e-05}, {"id": 167, "seek": 73408, "start": 734.08, "end": 746.08, "text": " So that was easy. Yeah, nobody seems to talk about it. I'm going to talk about BNC, which is also fine, but I find it a bit slower and a little bit more awkward.", "tokens": [407, 300, 390, 1858, 13, 865, 11, 5079, 2544, 281, 751, 466, 309, 13, 286, 478, 516, 281, 751, 466, 363, 45, 34, 11, 597, 307, 611, 2489, 11, 457, 286, 915, 309, 257, 857, 14009, 293, 257, 707, 857, 544, 11411, 13], "temperature": 0.0, "avg_logprob": -0.19342302631687475, "compression_ratio": 1.4628571428571429, "no_speech_prob": 1.084448285837425e-06}, {"id": 168, "seek": 73408, "start": 746.08, "end": 760.08, "text": " All right. I mean, one weird thing, I guess, is I guess my machine, and this is pretty common.", "tokens": [1057, 558, 13, 286, 914, 11, 472, 3657, 551, 11, 286, 2041, 11, 307, 286, 2041, 452, 3479, 11, 293, 341, 307, 1238, 2689, 13], "temperature": 0.0, "avg_logprob": -0.19342302631687475, "compression_ratio": 1.4628571428571429, "no_speech_prob": 1.084448285837425e-06}, {"id": 169, "seek": 76008, "start": 760.08, "end": 774.08, "text": " I haven't set up really to be a graphical workstation. I always use it from the console. So I actually don't really have much of a window manager here. I can't even like...", "tokens": [286, 2378, 380, 992, 493, 534, 281, 312, 257, 35942, 589, 19159, 13, 286, 1009, 764, 309, 490, 264, 11076, 13, 407, 286, 767, 500, 380, 534, 362, 709, 295, 257, 4910, 6598, 510, 13, 286, 393, 380, 754, 411, 485], "temperature": 0.0, "avg_logprob": -0.11865476880754744, "compression_ratio": 1.5508982035928143, "no_speech_prob": 1.184212578664301e-05}, {"id": 170, "seek": 76008, "start": 774.08, "end": 781.08, "text": " Oh no, I can do a little bit. I don't know what the hell window manager is even using.", "tokens": [876, 572, 11, 286, 393, 360, 257, 707, 857, 13, 286, 500, 380, 458, 437, 264, 4921, 4910, 6598, 307, 754, 1228, 13], "temperature": 0.0, "avg_logprob": -0.11865476880754744, "compression_ratio": 1.5508982035928143, "no_speech_prob": 1.184212578664301e-05}, {"id": 171, "seek": 78108, "start": 781.08, "end": 803.08, "text": " But often you'll find like there is no window manager or whatever running. But you know, a bit of Googling will show you how to install, you know, whatever, KDE or stuff.", "tokens": [583, 2049, 291, 603, 915, 411, 456, 307, 572, 4910, 6598, 420, 2035, 2614, 13, 583, 291, 458, 11, 257, 857, 295, 45005, 1688, 486, 855, 291, 577, 281, 3625, 11, 291, 458, 11, 2035, 11, 591, 22296, 420, 1507, 13], "temperature": 0.0, "avg_logprob": -0.17705752357604013, "compression_ratio": 1.4058823529411764, "no_speech_prob": 8.66302889335202e-06}, {"id": 172, "seek": 78108, "start": 803.08, "end": 809.08, "text": " Okay. Since we're on the installation topic, could I ask a question?", "tokens": [1033, 13, 4162, 321, 434, 322, 264, 13260, 4829, 11, 727, 286, 1029, 257, 1168, 30], "temperature": 0.0, "avg_logprob": -0.17705752357604013, "compression_ratio": 1.4058823529411764, "no_speech_prob": 8.66302889335202e-06}, {"id": 173, "seek": 80908, "start": 809.08, "end": 822.08, "text": " So I think I kind of brought it up a little bit, but I can't launch FastAI, a machine that runs FastAI, and PyTorch. A PyTorch one would work.", "tokens": [407, 286, 519, 286, 733, 295, 3038, 309, 493, 257, 707, 857, 11, 457, 286, 393, 380, 4025, 15968, 48698, 11, 257, 3479, 300, 6676, 15968, 48698, 11, 293, 9953, 51, 284, 339, 13, 316, 9953, 51, 284, 339, 472, 576, 589, 13], "temperature": 0.0, "avg_logprob": -0.15408826854130994, "compression_ratio": 1.4186046511627908, "no_speech_prob": 1.5204896953946445e-05}, {"id": 174, "seek": 80908, "start": 822.08, "end": 829.08, "text": " So what suggestions would you have about... So that means that your prerun.sh file has got a problem.", "tokens": [407, 437, 13396, 576, 291, 362, 466, 485, 407, 300, 1355, 300, 428, 582, 260, 409, 13, 2716, 3991, 575, 658, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.15408826854130994, "compression_ratio": 1.4186046511627908, "no_speech_prob": 1.5204896953946445e-05}, {"id": 175, "seek": 82908, "start": 829.08, "end": 842.08, "text": " So maybe comment it out from my PyTorch. Just start it up. Open up your PyTorch. Open up a PyTorch machine. Move prerun.sh to prerun.back or something.", "tokens": [407, 1310, 2871, 309, 484, 490, 452, 9953, 51, 284, 339, 13, 1449, 722, 309, 493, 13, 7238, 493, 428, 9953, 51, 284, 339, 13, 7238, 493, 257, 9953, 51, 284, 339, 3479, 13, 10475, 582, 260, 409, 13, 2716, 281, 582, 260, 409, 13, 3207, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.14683253506580032, "compression_ratio": 1.4682080924855492, "no_speech_prob": 1.0952270713460166e-05}, {"id": 176, "seek": 82908, "start": 842.08, "end": 846.08, "text": " Or just open it and see, like it might be obvious what's wrong with it.", "tokens": [1610, 445, 1269, 309, 293, 536, 11, 411, 309, 1062, 312, 6322, 437, 311, 2085, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.14683253506580032, "compression_ratio": 1.4682080924855492, "no_speech_prob": 1.0952270713460166e-05}, {"id": 177, "seek": 82908, "start": 846.08, "end": 851.08, "text": " Yeah, I couldn't see anything.", "tokens": [865, 11, 286, 2809, 380, 536, 1340, 13], "temperature": 0.0, "avg_logprob": -0.14683253506580032, "compression_ratio": 1.4682080924855492, "no_speech_prob": 1.0952270713460166e-05}, {"id": 178, "seek": 85108, "start": 851.08, "end": 864.08, "text": " When you say it's not working, what's like, what's not working? Well, it just says error when I try to start it up. It just says error and I tried to reach out to the paper spread space support a couple of times.", "tokens": [1133, 291, 584, 309, 311, 406, 1364, 11, 437, 311, 411, 11, 437, 311, 406, 1364, 30, 1042, 11, 309, 445, 1619, 6713, 562, 286, 853, 281, 722, 309, 493, 13, 467, 445, 1619, 6713, 293, 286, 3031, 281, 2524, 484, 281, 264, 3035, 3974, 1901, 1406, 257, 1916, 295, 1413, 13], "temperature": 0.0, "avg_logprob": -0.28546229044596355, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.0951575859508011e-05}, {"id": 179, "seek": 85108, "start": 864.08, "end": 868.08, "text": " Maybe it's a too abstract of a question.", "tokens": [2704, 309, 311, 257, 886, 12649, 295, 257, 1168, 13], "temperature": 0.0, "avg_logprob": -0.28546229044596355, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.0951575859508011e-05}, {"id": 180, "seek": 85108, "start": 868.08, "end": 877.08, "text": " I'll try that.", "tokens": [286, 603, 853, 300, 13], "temperature": 0.0, "avg_logprob": -0.28546229044596355, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.0951575859508011e-05}, {"id": 181, "seek": 87708, "start": 877.08, "end": 890.08, "text": " I'm sure people are putting stuff in the text chat. Please try to say things, verbal chat, if you can, because it's way nicer for me, and I don't have to check multiple windows.", "tokens": [286, 478, 988, 561, 366, 3372, 1507, 294, 264, 2487, 5081, 13, 2555, 853, 281, 584, 721, 11, 24781, 5081, 11, 498, 291, 393, 11, 570, 309, 311, 636, 22842, 337, 385, 11, 293, 286, 500, 380, 362, 281, 1520, 3866, 9309, 13], "temperature": 0.0, "avg_logprob": -0.1688007321851007, "compression_ratio": 1.3734177215189873, "no_speech_prob": 2.7521349693415686e-05}, {"id": 182, "seek": 87708, "start": 890.08, "end": 899.08, "text": " I know it's not possible for everybody.", "tokens": [286, 458, 309, 311, 406, 1944, 337, 2201, 13], "temperature": 0.0, "avg_logprob": -0.1688007321851007, "compression_ratio": 1.3734177215189873, "no_speech_prob": 2.7521349693415686e-05}, {"id": 183, "seek": 89908, "start": 899.08, "end": 909.08, "text": " Okay, so sorry, Jeremy. There is a way to SSH into a gradient machine, but you have to trigger the virtual machine to be built from the command line.", "tokens": [1033, 11, 370, 2597, 11, 17809, 13, 821, 307, 257, 636, 281, 12238, 39, 666, 257, 16235, 3479, 11, 457, 291, 362, 281, 7875, 264, 6374, 3479, 281, 312, 3094, 490, 264, 5622, 1622, 13], "temperature": 0.0, "avg_logprob": -0.16600848111239347, "compression_ratio": 1.59765625, "no_speech_prob": 6.853114882687805e-06}, {"id": 184, "seek": 89908, "start": 909.08, "end": 914.08, "text": " So you have to initiate the job, and there's paper space, have a GitHub repo.", "tokens": [407, 291, 362, 281, 31574, 264, 1691, 11, 293, 456, 311, 3035, 1901, 11, 362, 257, 23331, 49040, 13], "temperature": 0.0, "avg_logprob": -0.16600848111239347, "compression_ratio": 1.59765625, "no_speech_prob": 6.853114882687805e-06}, {"id": 185, "seek": 89908, "start": 914.08, "end": 918.08, "text": " And is there any reason to do that? Like that sounds complicated.", "tokens": [400, 307, 456, 604, 1778, 281, 360, 300, 30, 1743, 300, 3263, 6179, 13], "temperature": 0.0, "avg_logprob": -0.16600848111239347, "compression_ratio": 1.59765625, "no_speech_prob": 6.853114882687805e-06}, {"id": 186, "seek": 89908, "start": 918.08, "end": 921.08, "text": " It's way more effort than it's worth.", "tokens": [467, 311, 636, 544, 4630, 813, 309, 311, 3163, 13], "temperature": 0.0, "avg_logprob": -0.16600848111239347, "compression_ratio": 1.59765625, "no_speech_prob": 6.853114882687805e-06}, {"id": 187, "seek": 89908, "start": 921.08, "end": 925.08, "text": " Just run a call, just run a paper space core machine if you want to, I guess.", "tokens": [1449, 1190, 257, 818, 11, 445, 1190, 257, 3035, 1901, 4965, 3479, 498, 291, 528, 281, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.16600848111239347, "compression_ratio": 1.59765625, "no_speech_prob": 6.853114882687805e-06}, {"id": 188, "seek": 92508, "start": 925.08, "end": 930.08, "text": " Yeah, exactly. So you can do it. It's just, why would you?", "tokens": [865, 11, 2293, 13, 407, 291, 393, 360, 309, 13, 467, 311, 445, 11, 983, 576, 291, 30], "temperature": 0.0, "avg_logprob": -0.15876636197490077, "compression_ratio": 1.4842767295597483, "no_speech_prob": 3.667920054795104e-06}, {"id": 189, "seek": 92508, "start": 930.08, "end": 944.08, "text": " So yeah, I mean so for paper space the issue around the notebook closing, I would like start running something, close the notebook, and then reopen it, just to see what happens.", "tokens": [407, 1338, 11, 286, 914, 370, 337, 3035, 1901, 264, 2734, 926, 264, 21060, 10377, 11, 286, 576, 411, 722, 2614, 746, 11, 1998, 264, 21060, 11, 293, 550, 33861, 309, 11, 445, 281, 536, 437, 2314, 13], "temperature": 0.0, "avg_logprob": -0.15876636197490077, "compression_ratio": 1.4842767295597483, "no_speech_prob": 3.667920054795104e-06}, {"id": 190, "seek": 94408, "start": 944.08, "end": 964.08, "text": " You know, and, you know, let's try it here, right?", "tokens": [509, 458, 11, 293, 11, 291, 458, 11, 718, 311, 853, 309, 510, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19046816072965922, "compression_ratio": 1.1734693877551021, "no_speech_prob": 2.5446897780057043e-05}, {"id": 191, "seek": 94408, "start": 964.08, "end": 969.08, "text": " Now what was that thing we learned the other day? It was Shifty.", "tokens": [823, 437, 390, 300, 551, 321, 3264, 264, 661, 786, 30, 467, 390, 1160, 37177, 13], "temperature": 0.0, "avg_logprob": -0.19046816072965922, "compression_ratio": 1.1734693877551021, "no_speech_prob": 2.5446897780057043e-05}, {"id": 192, "seek": 96908, "start": 969.08, "end": 974.08, "text": " Let's see the other one.", "tokens": [961, 311, 536, 264, 661, 472, 13], "temperature": 0.0, "avg_logprob": -0.23802335334546637, "compression_ratio": 1.4908256880733946, "no_speech_prob": 1.3210858924139757e-05}, {"id": 193, "seek": 96908, "start": 974.08, "end": 978.08, "text": " Oh, that was my one. Okay, I gotta learn how to.", "tokens": [876, 11, 300, 390, 452, 472, 13, 1033, 11, 286, 3428, 1466, 577, 281, 13], "temperature": 0.0, "avg_logprob": -0.23802335334546637, "compression_ratio": 1.4908256880733946, "no_speech_prob": 1.3210858924139757e-05}, {"id": 194, "seek": 96908, "start": 978.08, "end": 980.08, "text": " Hey Jeremy. Yeah.", "tokens": [1911, 17809, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.23802335334546637, "compression_ratio": 1.4908256880733946, "no_speech_prob": 1.3210858924139757e-05}, {"id": 195, "seek": 96908, "start": 980.08, "end": 990.08, "text": " Um, can you, are you using iterm2 because you can do tmux minus CC and you'll get native windows in tmux instead of the little sort of terminal ones.", "tokens": [3301, 11, 393, 291, 11, 366, 291, 1228, 309, 966, 17, 570, 291, 393, 360, 256, 76, 2449, 3175, 12630, 293, 291, 603, 483, 8470, 9309, 294, 256, 76, 2449, 2602, 295, 264, 707, 1333, 295, 14709, 2306, 13], "temperature": 0.0, "avg_logprob": -0.23802335334546637, "compression_ratio": 1.4908256880733946, "no_speech_prob": 1.3210858924139757e-05}, {"id": 196, "seek": 96908, "start": 990.08, "end": 996.08, "text": " That sounds interesting. Let me try that. Yeah, I'm addicted to that. It's awesome.", "tokens": [663, 3263, 1880, 13, 961, 385, 853, 300, 13, 865, 11, 286, 478, 24629, 281, 300, 13, 467, 311, 3476, 13], "temperature": 0.0, "avg_logprob": -0.23802335334546637, "compression_ratio": 1.4908256880733946, "no_speech_prob": 1.3210858924139757e-05}, {"id": 197, "seek": 99608, "start": 996.08, "end": 1003.08, "text": " So, minus capital capital, minus capital CC.", "tokens": [407, 11, 3175, 4238, 4238, 11, 3175, 4238, 12630, 13], "temperature": 0.0, "avg_logprob": -0.3648405883271815, "compression_ratio": 1.456, "no_speech_prob": 2.2826872736914083e-05}, {"id": 198, "seek": 99608, "start": 1003.08, "end": 1006.08, "text": " Unknown option C.", "tokens": [32766, 3614, 383, 13], "temperature": 0.0, "avg_logprob": -0.3648405883271815, "compression_ratio": 1.456, "no_speech_prob": 2.2826872736914083e-05}, {"id": 199, "seek": 99608, "start": 1006.08, "end": 1012.08, "text": " Before the A. Yeah, so it'll be tmux minus capital capital. Yeah, here you go.", "tokens": [4546, 264, 316, 13, 865, 11, 370, 309, 603, 312, 256, 76, 2449, 3175, 4238, 4238, 13, 865, 11, 510, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.3648405883271815, "compression_ratio": 1.456, "no_speech_prob": 2.2826872736914083e-05}, {"id": 200, "seek": 99608, "start": 1012.08, "end": 1014.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.3648405883271815, "compression_ratio": 1.456, "no_speech_prob": 2.2826872736914083e-05}, {"id": 201, "seek": 99608, "start": 1014.08, "end": 1018.08, "text": " And what are the benefits of this?", "tokens": [400, 437, 366, 264, 5311, 295, 341, 30], "temperature": 0.0, "avg_logprob": -0.3648405883271815, "compression_ratio": 1.456, "no_speech_prob": 2.2826872736914083e-05}, {"id": 202, "seek": 101808, "start": 1018.08, "end": 1036.08, "text": " You can have windows so you can click and drag them and move them around pop them out. Yeah, all that stuff. Click and drag tmux windows as well.", "tokens": [509, 393, 362, 9309, 370, 291, 393, 2052, 293, 5286, 552, 293, 1286, 552, 926, 1665, 552, 484, 13, 865, 11, 439, 300, 1507, 13, 8230, 293, 5286, 256, 76, 2449, 9309, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2111210823059082, "compression_ratio": 1.5328947368421053, "no_speech_prob": 2.6841471481020562e-06}, {"id": 203, "seek": 101808, "start": 1036.08, "end": 1045.08, "text": " Okay, so it's all the same as, like, you've got to have mouse mode on for them to work.", "tokens": [1033, 11, 370, 309, 311, 439, 264, 912, 382, 11, 411, 11, 291, 600, 658, 281, 362, 9719, 4391, 322, 337, 552, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.2111210823059082, "compression_ratio": 1.5328947368421053, "no_speech_prob": 2.6841471481020562e-06}, {"id": 204, "seek": 104508, "start": 1045.08, "end": 1054.08, "text": " So you can click the shortcut keys like command shift D will split panes, you don't have to go into I think is a colon or something and command something. It's just like less dimy.", "tokens": [407, 291, 393, 2052, 264, 24822, 9317, 411, 5622, 5513, 413, 486, 7472, 2462, 279, 11, 291, 500, 380, 362, 281, 352, 666, 286, 519, 307, 257, 8255, 420, 746, 293, 5622, 746, 13, 467, 311, 445, 411, 1570, 274, 13189, 13], "temperature": 0.0, "avg_logprob": -0.3140267489249246, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.6186919310712256e-05}, {"id": 205, "seek": 104508, "start": 1054.08, "end": 1056.08, "text": " You just use control B.", "tokens": [509, 445, 764, 1969, 363, 13], "temperature": 0.0, "avg_logprob": -0.3140267489249246, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.6186919310712256e-05}, {"id": 206, "seek": 104508, "start": 1056.08, "end": 1059.08, "text": " And maybe it's exactly the same.", "tokens": [400, 1310, 309, 311, 2293, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.3140267489249246, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.6186919310712256e-05}, {"id": 207, "seek": 104508, "start": 1059.08, "end": 1061.08, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3140267489249246, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.6186919310712256e-05}, {"id": 208, "seek": 104508, "start": 1061.08, "end": 1066.08, "text": " I mean you have the same control B doesn't work anymore so my tmux shortcuts are not going to work anymore.", "tokens": [286, 914, 291, 362, 264, 912, 1969, 363, 1177, 380, 589, 3602, 370, 452, 256, 76, 2449, 34620, 366, 406, 516, 281, 589, 3602, 13], "temperature": 0.0, "avg_logprob": -0.3140267489249246, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.6186919310712256e-05}, {"id": 209, "seek": 104508, "start": 1066.08, "end": 1072.08, "text": " How do I do that now. They're different escape, I think, or.", "tokens": [1012, 360, 286, 360, 300, 586, 13, 814, 434, 819, 7615, 11, 286, 519, 11, 420, 13], "temperature": 0.0, "avg_logprob": -0.3140267489249246, "compression_ratio": 1.6349206349206349, "no_speech_prob": 1.6186919310712256e-05}, {"id": 210, "seek": 107208, "start": 1072.08, "end": 1084.08, "text": " If you go back to the original window that launched it.", "tokens": [759, 291, 352, 646, 281, 264, 3380, 4910, 300, 8730, 309, 13], "temperature": 0.0, "avg_logprob": -0.1465514600276947, "compression_ratio": 0.9852941176470589, "no_speech_prob": 1.6177864381461404e-05}, {"id": 211, "seek": 107208, "start": 1084.08, "end": 1086.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.1465514600276947, "compression_ratio": 0.9852941176470589, "no_speech_prob": 1.6177864381461404e-05}, {"id": 212, "seek": 107208, "start": 1086.08, "end": 1088.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.1465514600276947, "compression_ratio": 0.9852941176470589, "no_speech_prob": 1.6177864381461404e-05}, {"id": 213, "seek": 108808, "start": 1088.08, "end": 1102.08, "text": " Yeah, I'm not convinced it's going to help my workflow but I think yeah for people who are more familiar with tmux shortcuts that could be cool.", "tokens": [865, 11, 286, 478, 406, 12561, 309, 311, 516, 281, 854, 452, 20993, 457, 286, 519, 1338, 337, 561, 567, 366, 544, 4963, 365, 256, 76, 2449, 34620, 300, 727, 312, 1627, 13], "temperature": 0.0, "avg_logprob": -0.09723932338210772, "compression_ratio": 1.3082191780821917, "no_speech_prob": 2.5043827918125317e-05}, {"id": 214, "seek": 108808, "start": 1102.08, "end": 1105.08, "text": " Thanks for the tip.", "tokens": [2561, 337, 264, 4125, 13], "temperature": 0.0, "avg_logprob": -0.09723932338210772, "compression_ratio": 1.3082191780821917, "no_speech_prob": 2.5043827918125317e-05}, {"id": 215, "seek": 108808, "start": 1105.08, "end": 1112.08, "text": " What's going on down here.", "tokens": [708, 311, 516, 322, 760, 510, 13], "temperature": 0.0, "avg_logprob": -0.09723932338210772, "compression_ratio": 1.3082191780821917, "no_speech_prob": 2.5043827918125317e-05}, {"id": 216, "seek": 111208, "start": 1112.08, "end": 1118.08, "text": " The,", "tokens": [440, 11], "temperature": 0.0, "avg_logprob": -0.1472355524698893, "compression_ratio": 1.2616822429906542, "no_speech_prob": 2.368705736444099e-06}, {"id": 217, "seek": 111208, "start": 1118.08, "end": 1132.08, "text": " the trick to get mouse support working so for example my scroll wheel as you can see works nicely in this normal tmux window is to", "tokens": [264, 4282, 281, 483, 9719, 1406, 1364, 370, 337, 1365, 452, 11369, 5589, 382, 291, 393, 536, 1985, 9594, 294, 341, 2710, 256, 76, 2449, 4910, 307, 281], "temperature": 0.0, "avg_logprob": -0.1472355524698893, "compression_ratio": 1.2616822429906542, "no_speech_prob": 2.368705736444099e-06}, {"id": 218, "seek": 113208, "start": 1132.08, "end": 1142.08, "text": " have a dot tmux dot conf file that contains set option minus g mouse on.", "tokens": [362, 257, 5893, 256, 76, 2449, 5893, 1497, 3991, 300, 8306, 992, 3614, 3175, 290, 9719, 322, 13], "temperature": 0.0, "avg_logprob": -0.13268134088227243, "compression_ratio": 1.4967320261437909, "no_speech_prob": 8.714056320968666e-07}, {"id": 219, "seek": 113208, "start": 1142.08, "end": 1145.08, "text": " And then you can also increase your history limit.", "tokens": [400, 550, 291, 393, 611, 3488, 428, 2503, 4948, 13], "temperature": 0.0, "avg_logprob": -0.13268134088227243, "compression_ratio": 1.4967320261437909, "no_speech_prob": 8.714056320968666e-07}, {"id": 220, "seek": 113208, "start": 1145.08, "end": 1157.08, "text": " And yeah, that's how come I can scroll. I think the thing like, you know, or a thing I like about tmux is", "tokens": [400, 1338, 11, 300, 311, 577, 808, 286, 393, 11369, 13, 286, 519, 264, 551, 411, 11, 291, 458, 11, 420, 257, 551, 286, 411, 466, 256, 76, 2449, 307], "temperature": 0.0, "avg_logprob": -0.13268134088227243, "compression_ratio": 1.4967320261437909, "no_speech_prob": 8.714056320968666e-07}, {"id": 221, "seek": 115708, "start": 1157.08, "end": 1170.08, "text": " that it's integrated with my kind of the normal way of doing things in in unix, you know, so for example, if I want to search through my previous session.", "tokens": [300, 309, 311, 10919, 365, 452, 733, 295, 264, 2710, 636, 295, 884, 721, 294, 294, 517, 970, 11, 291, 458, 11, 370, 337, 1365, 11, 498, 286, 528, 281, 3164, 807, 452, 3894, 5481, 13], "temperature": 0.0, "avg_logprob": -0.1943860650062561, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.8571676011779346e-06}, {"id": 222, "seek": 115708, "start": 1170.08, "end": 1175.08, "text": " I could just hit question mark to search up, and I could search for make file.", "tokens": [286, 727, 445, 2045, 1168, 1491, 281, 3164, 493, 11, 293, 286, 727, 3164, 337, 652, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1943860650062561, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.8571676011779346e-06}, {"id": 223, "seek": 115708, "start": 1175.08, "end": 1180.08, "text": " For example, and you know, hit n, just like I would in vim.", "tokens": [1171, 1365, 11, 293, 291, 458, 11, 2045, 297, 11, 445, 411, 286, 576, 294, 371, 332, 13], "temperature": 0.0, "avg_logprob": -0.1943860650062561, "compression_ratio": 1.5837837837837838, "no_speech_prob": 2.8571676011779346e-06}, {"id": 224, "seek": 118008, "start": 1180.08, "end": 1194.08, "text": " Hit slash to look forwards. You know it's like my terminal works the same way as vim or whatever which I, yeah, which I really like.", "tokens": [9217, 17330, 281, 574, 30126, 13, 509, 458, 309, 311, 411, 452, 14709, 1985, 264, 912, 636, 382, 371, 332, 420, 2035, 597, 286, 11, 1338, 11, 597, 286, 534, 411, 13], "temperature": 0.0, "avg_logprob": -0.17170697793193246, "compression_ratio": 1.5990338164251208, "no_speech_prob": 3.5549830954551e-06}, {"id": 225, "seek": 118008, "start": 1194.08, "end": 1206.08, "text": " And I think, yeah, that way I don't have to know like, oh the items that are shortcuts and some other set of shortcuts it's just this kind of kind of like general unixy way of doing things, I guess.", "tokens": [400, 286, 519, 11, 1338, 11, 300, 636, 286, 500, 380, 362, 281, 458, 411, 11, 1954, 264, 4754, 300, 366, 34620, 293, 512, 661, 992, 295, 34620, 309, 311, 445, 341, 733, 295, 733, 295, 411, 2674, 517, 970, 88, 636, 295, 884, 721, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.17170697793193246, "compression_ratio": 1.5990338164251208, "no_speech_prob": 3.5549830954551e-06}, {"id": 226, "seek": 120608, "start": 1206.08, "end": 1216.08, "text": " And of course they'll also all work on the paper space terminal as well.", "tokens": [400, 295, 1164, 436, 603, 611, 439, 589, 322, 264, 3035, 1901, 14709, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1017754933772943, "compression_ratio": 1.2, "no_speech_prob": 6.961888175283093e-06}, {"id": 227, "seek": 120608, "start": 1216.08, "end": 1223.08, "text": " Yeah, so let's try this.", "tokens": [865, 11, 370, 718, 311, 853, 341, 13], "temperature": 0.0, "avg_logprob": -0.1017754933772943, "compression_ratio": 1.2, "no_speech_prob": 6.961888175283093e-06}, {"id": 228, "seek": 120608, "start": 1223.08, "end": 1231.08, "text": " So if we start running this.", "tokens": [407, 498, 321, 722, 2614, 341, 13], "temperature": 0.0, "avg_logprob": -0.1017754933772943, "compression_ratio": 1.2, "no_speech_prob": 6.961888175283093e-06}, {"id": 229, "seek": 123108, "start": 1231.08, "end": 1238.08, "text": " Okay, close that.", "tokens": [1033, 11, 1998, 300, 13], "temperature": 0.0, "avg_logprob": -0.13356482355218185, "compression_ratio": 1.3285714285714285, "no_speech_prob": 2.6685785996960476e-05}, {"id": 230, "seek": 123108, "start": 1238.08, "end": 1242.08, "text": " Leave it for a few seconds.", "tokens": [9825, 309, 337, 257, 1326, 3949, 13], "temperature": 0.0, "avg_logprob": -0.13356482355218185, "compression_ratio": 1.3285714285714285, "no_speech_prob": 2.6685785996960476e-05}, {"id": 231, "seek": 123108, "start": 1242.08, "end": 1245.08, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.13356482355218185, "compression_ratio": 1.3285714285714285, "no_speech_prob": 2.6685785996960476e-05}, {"id": 232, "seek": 123108, "start": 1245.08, "end": 1252.08, "text": " you can see here it says in my console, starting buffering.", "tokens": [291, 393, 536, 510, 309, 1619, 294, 452, 11076, 11, 2891, 9204, 1794, 13], "temperature": 0.0, "avg_logprob": -0.13356482355218185, "compression_ratio": 1.3285714285714285, "no_speech_prob": 2.6685785996960476e-05}, {"id": 233, "seek": 123108, "start": 1252.08, "end": 1258.08, "text": " So it's remembering things that were sent to me so if I click now back here.", "tokens": [407, 309, 311, 20719, 721, 300, 645, 2279, 281, 385, 370, 498, 286, 2052, 586, 646, 510, 13], "temperature": 0.0, "avg_logprob": -0.13356482355218185, "compression_ratio": 1.3285714285714285, "no_speech_prob": 2.6685785996960476e-05}, {"id": 234, "seek": 125808, "start": 1258.08, "end": 1268.08, "text": " It's, let's see.", "tokens": [467, 311, 11, 718, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.13643357583454677, "compression_ratio": 1.310077519379845, "no_speech_prob": 1.8630666090757586e-05}, {"id": 235, "seek": 125808, "start": 1268.08, "end": 1272.08, "text": " Hmm.", "tokens": [8239, 13], "temperature": 0.0, "avg_logprob": -0.13643357583454677, "compression_ratio": 1.310077519379845, "no_speech_prob": 1.8630666090757586e-05}, {"id": 236, "seek": 125808, "start": 1272.08, "end": 1275.08, "text": " That didn't seem to work, did it? That's interesting.", "tokens": [663, 994, 380, 1643, 281, 589, 11, 630, 309, 30, 663, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.13643357583454677, "compression_ratio": 1.310077519379845, "no_speech_prob": 1.8630666090757586e-05}, {"id": 237, "seek": 125808, "start": 1275.08, "end": 1282.08, "text": " Okay, so let's try something different. So I don't think you can just close it and reopen it.", "tokens": [1033, 11, 370, 718, 311, 853, 746, 819, 13, 407, 286, 500, 380, 519, 291, 393, 445, 1998, 309, 293, 33861, 309, 13], "temperature": 0.0, "avg_logprob": -0.13643357583454677, "compression_ratio": 1.310077519379845, "no_speech_prob": 1.8630666090757586e-05}, {"id": 238, "seek": 128208, "start": 1282.08, "end": 1291.08, "text": " Alright, let's try something else.", "tokens": [2798, 11, 718, 311, 853, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.1422084260869909, "compression_ratio": 1.3333333333333333, "no_speech_prob": 8.530138984497171e-06}, {"id": 239, "seek": 128208, "start": 1291.08, "end": 1298.08, "text": " What if we fake a network disconnection by closing SSH.", "tokens": [708, 498, 321, 7592, 257, 3209, 14299, 313, 538, 10377, 12238, 39, 13], "temperature": 0.0, "avg_logprob": -0.1422084260869909, "compression_ratio": 1.3333333333333333, "no_speech_prob": 8.530138984497171e-06}, {"id": 240, "seek": 128208, "start": 1298.08, "end": 1304.08, "text": " Okay, so now, alright, connections failed. So I'll leave that window open.", "tokens": [1033, 11, 370, 586, 11, 5845, 11, 9271, 7612, 13, 407, 286, 603, 1856, 300, 4910, 1269, 13], "temperature": 0.0, "avg_logprob": -0.1422084260869909, "compression_ratio": 1.3333333333333333, "no_speech_prob": 8.530138984497171e-06}, {"id": 241, "seek": 128208, "start": 1304.08, "end": 1309.08, "text": " And then we reconnect.", "tokens": [400, 550, 321, 30095, 13], "temperature": 0.0, "avg_logprob": -0.1422084260869909, "compression_ratio": 1.3333333333333333, "no_speech_prob": 8.530138984497171e-06}, {"id": 242, "seek": 130908, "start": 1309.08, "end": 1314.08, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.10463923718555863, "compression_ratio": 1.5545023696682465, "no_speech_prob": 1.0615239261824172e-05}, {"id": 243, "seek": 130908, "start": 1314.08, "end": 1317.08, "text": " Okay, so that worked.", "tokens": [1033, 11, 370, 300, 2732, 13], "temperature": 0.0, "avg_logprob": -0.10463923718555863, "compression_ratio": 1.5545023696682465, "no_speech_prob": 1.0615239261824172e-05}, {"id": 244, "seek": 130908, "start": 1317.08, "end": 1322.08, "text": " So there's some of our answer. But yeah, I think there's something now if you leave it long enough.", "tokens": [407, 456, 311, 512, 295, 527, 1867, 13, 583, 1338, 11, 286, 519, 456, 311, 746, 586, 498, 291, 1856, 309, 938, 1547, 13], "temperature": 0.0, "avg_logprob": -0.10463923718555863, "compression_ratio": 1.5545023696682465, "no_speech_prob": 1.0615239261824172e-05}, {"id": 245, "seek": 130908, "start": 1322.08, "end": 1330.08, "text": " It says I've stopped listening for events because there's been too many and tells you there's some configuration option you can change to make it bigger.", "tokens": [467, 1619, 286, 600, 5936, 4764, 337, 3931, 570, 456, 311, 668, 886, 867, 293, 5112, 291, 456, 311, 512, 11694, 3614, 291, 393, 1319, 281, 652, 309, 3801, 13], "temperature": 0.0, "avg_logprob": -0.10463923718555863, "compression_ratio": 1.5545023696682465, "no_speech_prob": 1.0615239261824172e-05}, {"id": 246, "seek": 130908, "start": 1330.08, "end": 1337.08, "text": " Should probably be a useful thing to know about.", "tokens": [6454, 1391, 312, 257, 4420, 551, 281, 458, 466, 13], "temperature": 0.0, "avg_logprob": -0.10463923718555863, "compression_ratio": 1.5545023696682465, "no_speech_prob": 1.0615239261824172e-05}, {"id": 247, "seek": 133708, "start": 1337.08, "end": 1341.08, "text": " Let me just go and turn this alarm off. Hang on.", "tokens": [50364, 961, 385, 445, 352, 293, 1261, 341, 14183, 766, 13, 14070, 322, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2319316416978836, "compression_ratio": 0.8727272727272727, "no_speech_prob": 0.00031376085826195776}, {"id": 248, "seek": 136708, "start": 1367.08, "end": 1389.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.6179021994272867, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.6148372888565063}, {"id": 249, "seek": 138908, "start": 1389.08, "end": 1399.08, "text": " Yeah.", "tokens": [50364, 865, 13, 50864], "temperature": 0.0, "avg_logprob": -0.6128666400909424, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.0007772760582156479}, {"id": 250, "seek": 141908, "start": 1419.08, "end": 1438.08, "text": " Sorry about that.", "tokens": [4919, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.4014228582382202, "compression_ratio": 0.68, "no_speech_prob": 0.1002986952662468}, {"id": 251, "seek": 143808, "start": 1438.08, "end": 1457.08, "text": " My daughter likes to be permanently entertained. So any gaps in her homeschooling schedule.", "tokens": [1222, 4653, 5902, 281, 312, 24042, 44783, 13, 407, 604, 15031, 294, 720, 7388, 21856, 278, 7567, 13], "temperature": 0.0, "avg_logprob": -0.18819659406488592, "compression_ratio": 1.0833333333333333, "no_speech_prob": 2.352606679778546e-05}, {"id": 252, "seek": 145708, "start": 1457.08, "end": 1470.08, "text": " She wants to be amused. She doesn't like the fact that I'm doing this and Rachel's a CrossFit.", "tokens": [1240, 2738, 281, 312, 669, 4717, 13, 1240, 1177, 380, 411, 264, 1186, 300, 286, 478, 884, 341, 293, 14246, 311, 257, 11623, 49901, 13], "temperature": 0.0, "avg_logprob": -0.11393224949739417, "compression_ratio": 1.265625, "no_speech_prob": 1.5533273654000368e-06}, {"id": 253, "seek": 145708, "start": 1470.08, "end": 1474.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.11393224949739417, "compression_ratio": 1.265625, "no_speech_prob": 1.5533273654000368e-06}, {"id": 254, "seek": 145708, "start": 1474.08, "end": 1483.08, "text": " So we had a look the other day at progressive resizing right.", "tokens": [407, 321, 632, 257, 574, 264, 661, 786, 412, 16131, 725, 3319, 558, 13], "temperature": 0.0, "avg_logprob": -0.11393224949739417, "compression_ratio": 1.265625, "no_speech_prob": 1.5533273654000368e-06}, {"id": 255, "seek": 148308, "start": 1483.08, "end": 1496.08, "text": " And so this is where I got to I think like progressive resizing one interesting thing you can do is like you can go crazy like you can go extra large.", "tokens": [400, 370, 341, 307, 689, 286, 658, 281, 286, 519, 411, 16131, 725, 3319, 472, 1880, 551, 291, 393, 360, 307, 411, 291, 393, 352, 3219, 411, 291, 393, 352, 2857, 2416, 13], "temperature": 0.0, "avg_logprob": -0.10941146159994192, "compression_ratio": 1.506578947368421, "no_speech_prob": 3.2884015581657877e-06}, {"id": 256, "seek": 148308, "start": 1496.08, "end": 1511.08, "text": " And, you know, we start out with some teeny tiny images and train for a while.", "tokens": [400, 11, 291, 458, 11, 321, 722, 484, 365, 512, 48232, 5870, 5267, 293, 3847, 337, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.10941146159994192, "compression_ratio": 1.506578947368421, "no_speech_prob": 3.2884015581657877e-06}, {"id": 257, "seek": 151108, "start": 1511.08, "end": 1524.08, "text": " And then combine that with gradient accumulation.", "tokens": [400, 550, 10432, 300, 365, 16235, 35647, 13], "temperature": 0.0, "avg_logprob": -0.17927591728441644, "compression_ratio": 1.1443298969072164, "no_speech_prob": 8.139089004544076e-06}, {"id": 258, "seek": 151108, "start": 1524.08, "end": 1528.08, "text": " To then go up to big images.", "tokens": [1407, 550, 352, 493, 281, 955, 5267, 13], "temperature": 0.0, "avg_logprob": -0.17927591728441644, "compression_ratio": 1.1443298969072164, "no_speech_prob": 8.139089004544076e-06}, {"id": 259, "seek": 151108, "start": 1528.08, "end": 1532.08, "text": " But don't have to train so long.", "tokens": [583, 500, 380, 362, 281, 3847, 370, 938, 13], "temperature": 0.0, "avg_logprob": -0.17927591728441644, "compression_ratio": 1.1443298969072164, "no_speech_prob": 8.139089004544076e-06}, {"id": 260, "seek": 153208, "start": 1532.08, "end": 1551.08, "text": " And so I think this is a good trick for probably particularly for code competitions on Kaggle where you've got serious resource constraints, you know, or just wanting to do more with less time.", "tokens": [400, 370, 286, 519, 341, 307, 257, 665, 4282, 337, 1391, 4098, 337, 3089, 26185, 322, 48751, 22631, 689, 291, 600, 658, 3156, 7684, 18491, 11, 291, 458, 11, 420, 445, 7935, 281, 360, 544, 365, 1570, 565, 13], "temperature": 0.0, "avg_logprob": -0.12205340141473814, "compression_ratio": 1.3402777777777777, "no_speech_prob": 7.888676009315532e-06}, {"id": 261, "seek": 155108, "start": 1551.08, "end": 1565.08, "text": " And yeah, on Kaggle you would have needed accumulation level of four rather than two to make this fit because they've got 16 gig cards. We also got 24 gig card.", "tokens": [400, 1338, 11, 322, 48751, 22631, 291, 576, 362, 2978, 35647, 1496, 295, 1451, 2831, 813, 732, 281, 652, 341, 3318, 570, 436, 600, 658, 3165, 8741, 5632, 13, 492, 611, 658, 4022, 8741, 2920, 13], "temperature": 0.0, "avg_logprob": -0.18674113832671066, "compression_ratio": 1.4142011834319526, "no_speech_prob": 3.041487843802315e-06}, {"id": 262, "seek": 155108, "start": 1565.08, "end": 1570.08, "text": " So then something else that", "tokens": [407, 550, 746, 1646, 300], "temperature": 0.0, "avg_logprob": -0.18674113832671066, "compression_ratio": 1.4142011834319526, "no_speech_prob": 3.041487843802315e-06}, {"id": 263, "seek": 155108, "start": 1570.08, "end": 1580.08, "text": " then we started talking about was weighted models.", "tokens": [550, 321, 1409, 1417, 466, 390, 32807, 5245, 13], "temperature": 0.0, "avg_logprob": -0.18674113832671066, "compression_ratio": 1.4142011834319526, "no_speech_prob": 3.041487843802315e-06}, {"id": 264, "seek": 158008, "start": 1580.08, "end": 1589.08, "text": " That's weird. What happened to my weighted model?", "tokens": [663, 311, 3657, 13, 708, 2011, 281, 452, 32807, 2316, 30], "temperature": 0.0, "avg_logprob": -0.2323602367849911, "compression_ratio": 1.053191489361702, "no_speech_prob": 7.888555046520196e-06}, {"id": 265, "seek": 158008, "start": 1589.08, "end": 1595.08, "text": " Did I move it to course 22?", "tokens": [2589, 286, 1286, 309, 281, 1164, 5853, 30], "temperature": 0.0, "avg_logprob": -0.2323602367849911, "compression_ratio": 1.053191489361702, "no_speech_prob": 7.888555046520196e-06}, {"id": 266, "seek": 158008, "start": 1595.08, "end": 1602.08, "text": " Oh well, that's fine.", "tokens": [876, 731, 11, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.2323602367849911, "compression_ratio": 1.053191489361702, "no_speech_prob": 7.888555046520196e-06}, {"id": 267, "seek": 160208, "start": 1602.08, "end": 1618.08, "text": " So the question I think we had yesterday was about unbalanced datasets and would it be a good idea to balance our dataset?", "tokens": [407, 264, 1168, 286, 519, 321, 632, 5186, 390, 466, 517, 40251, 42856, 293, 576, 309, 312, 257, 665, 1558, 281, 4772, 527, 28872, 30], "temperature": 0.0, "avg_logprob": -0.1753906011581421, "compression_ratio": 1.288659793814433, "no_speech_prob": 8.937546226661652e-06}, {"id": 268, "seek": 160208, "start": 1618.08, "end": 1626.08, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.1753906011581421, "compression_ratio": 1.288659793814433, "no_speech_prob": 8.937546226661652e-06}, {"id": 269, "seek": 162608, "start": 1626.08, "end": 1639.08, "text": " let's start with a nice small model.", "tokens": [718, 311, 722, 365, 257, 1481, 1359, 2316, 13], "temperature": 0.0, "avg_logprob": -0.22664540154593332, "compression_ratio": 1.0987654320987654, "no_speech_prob": 1.9221926777390763e-05}, {"id": 270, "seek": 162608, "start": 1639.08, "end": 1646.08, "text": " If he uses a base case, something we've done before.", "tokens": [759, 415, 4960, 257, 3096, 1389, 11, 746, 321, 600, 1096, 949, 13], "temperature": 0.0, "avg_logprob": -0.22664540154593332, "compression_ratio": 1.0987654320987654, "no_speech_prob": 1.9221926777390763e-05}, {"id": 271, "seek": 164608, "start": 1646.08, "end": 1657.08, "text": " Conv next. Okay, let's use this one.", "tokens": [2656, 85, 958, 13, 1033, 11, 718, 311, 764, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.2536025643348694, "compression_ratio": 0.8181818181818182, "no_speech_prob": 8.800572686595842e-06}, {"id": 272, "seek": 165708, "start": 1657.08, "end": 1679.08, "text": " So actually there's no point copying progressive I guess. Let's copy small models.", "tokens": [407, 767, 456, 311, 572, 935, 27976, 16131, 286, 2041, 13, 961, 311, 5055, 1359, 5245, 13], "temperature": 0.0, "avg_logprob": -0.19797286987304688, "compression_ratio": 1.0232558139534884, "no_speech_prob": 5.862525540578645e-06}, {"id": 273, "seek": 165708, "start": 1679.08, "end": 1683.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.19797286987304688, "compression_ratio": 1.0232558139534884, "no_speech_prob": 5.862525540578645e-06}, {"id": 274, "seek": 168308, "start": 1683.08, "end": 1702.08, "text": " Rename. And so this is going to be for weighted.", "tokens": [12883, 529, 13, 400, 370, 341, 307, 516, 281, 312, 337, 32807, 13], "temperature": 0.0, "avg_logprob": -0.18079381830552044, "compression_ratio": 0.8888888888888888, "no_speech_prob": 2.014332130784169e-05}, {"id": 275, "seek": 170208, "start": 1702.08, "end": 1716.08, "text": " As we'll do the resizing.", "tokens": [1018, 321, 603, 360, 264, 725, 3319, 13], "temperature": 0.0, "avg_logprob": -0.6260656515757242, "compression_ratio": 0.7575757575757576, "no_speech_prob": 2.1441794160637073e-05}, {"id": 276, "seek": 171608, "start": 1716.08, "end": 1733.08, "text": " Okay, so that's going to be our base case.", "tokens": [1033, 11, 370, 300, 311, 516, 281, 312, 527, 3096, 1389, 13], "temperature": 0.0, "avg_logprob": -0.17777602239088577, "compression_ratio": 0.921875, "no_speech_prob": 5.420218258223031e-06}, {"id": 277, "seek": 171608, "start": 1733.08, "end": 1744.08, "text": " So for weighting", "tokens": [407, 337, 3364, 278], "temperature": 0.0, "avg_logprob": -0.17777602239088577, "compression_ratio": 0.921875, "no_speech_prob": 5.420218258223031e-06}, {"id": 278, "seek": 174408, "start": 1744.08, "end": 1748.08, "text": " we can", "tokens": [321, 393], "temperature": 0.0, "avg_logprob": -0.14291498737950478, "compression_ratio": 1.3410852713178294, "no_speech_prob": 1.7777570974431e-05}, {"id": 279, "seek": 174408, "start": 1748.08, "end": 1754.08, "text": " df.label.valueCounts", "tokens": [274, 69, 13, 75, 18657, 13, 29155, 34, 792, 82], "temperature": 0.0, "avg_logprob": -0.14291498737950478, "compression_ratio": 1.3410852713178294, "no_speech_prob": 1.7777570974431e-05}, {"id": 280, "seek": 174408, "start": 1754.08, "end": 1759.08, "text": " So there's our", "tokens": [407, 456, 311, 527], "temperature": 0.0, "avg_logprob": -0.14291498737950478, "compression_ratio": 1.3410852713178294, "no_speech_prob": 1.7777570974431e-05}, {"id": 281, "seek": 174408, "start": 1759.08, "end": 1773.08, "text": " level of unbalancedness. So it's not too bad. There's a lot of normals, a lot of blasts. Not many of these are bacterial thingies.", "tokens": [1496, 295, 517, 40251, 1287, 13, 407, 309, 311, 406, 886, 1578, 13, 821, 311, 257, 688, 295, 2026, 1124, 11, 257, 688, 295, 12035, 82, 13, 1726, 867, 295, 613, 366, 35632, 551, 530, 13], "temperature": 0.0, "avg_logprob": -0.14291498737950478, "compression_ratio": 1.3410852713178294, "no_speech_prob": 1.7777570974431e-05}, {"id": 282, "seek": 177308, "start": 1773.08, "end": 1785.08, "text": " Nick, I don't know if you're around. I mean, I can see you are around. I don't know if you're able to talk. But if you are, you could tell us about what you found because I know you've been looking at these, which of these are hard to kind of visually see the difference between.", "tokens": [9449, 11, 286, 500, 380, 458, 498, 291, 434, 926, 13, 286, 914, 11, 286, 393, 536, 291, 366, 926, 13, 286, 500, 380, 458, 498, 291, 434, 1075, 281, 751, 13, 583, 498, 291, 366, 11, 291, 727, 980, 505, 466, 437, 291, 1352, 570, 286, 458, 291, 600, 668, 1237, 412, 613, 11, 597, 295, 613, 366, 1152, 281, 733, 295, 19622, 536, 264, 2649, 1296, 13], "temperature": 0.0, "avg_logprob": -0.19876115841973097, "compression_ratio": 1.7985865724381624, "no_speech_prob": 0.000269314885372296}, {"id": 283, "seek": 177308, "start": 1785.08, "end": 1790.08, "text": " Yeah, yeah, for sure. I'm sorry I dropped out earlier because we had a power cut here, but I'm back now.", "tokens": [865, 11, 1338, 11, 337, 988, 13, 286, 478, 2597, 286, 8119, 484, 3071, 570, 321, 632, 257, 1347, 1723, 510, 11, 457, 286, 478, 646, 586, 13], "temperature": 0.0, "avg_logprob": -0.19876115841973097, "compression_ratio": 1.7985865724381624, "no_speech_prob": 0.000269314885372296}, {"id": 284, "seek": 177308, "start": 1790.08, "end": 1793.08, "text": " Are you intentionally video lists?", "tokens": [2014, 291, 22062, 960, 14511, 30], "temperature": 0.0, "avg_logprob": -0.19876115841973097, "compression_ratio": 1.7985865724381624, "no_speech_prob": 0.000269314885372296}, {"id": 285, "seek": 177308, "start": 1793.08, "end": 1797.08, "text": " I am not intentionally video lists, but that's the break at the moment. Sorry about that.", "tokens": [286, 669, 406, 22062, 960, 14511, 11, 457, 300, 311, 264, 1821, 412, 264, 1623, 13, 4919, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.19876115841973097, "compression_ratio": 1.7985865724381624, "no_speech_prob": 0.000269314885372296}, {"id": 286, "seek": 179708, "start": 1797.08, "end": 1816.08, "text": " No worries. But yeah, like one thing that I did just to, I guess, get a better handle on the data set was going through them and having a look at the different types. I found it really hard to pick even what the difference was between a normal image and say like downy mildew or whatever.", "tokens": [883, 16340, 13, 583, 1338, 11, 411, 472, 551, 300, 286, 630, 445, 281, 11, 286, 2041, 11, 483, 257, 1101, 4813, 322, 264, 1412, 992, 390, 516, 807, 552, 293, 1419, 257, 574, 412, 264, 819, 3467, 13, 286, 1352, 309, 534, 1152, 281, 1888, 754, 437, 264, 2649, 390, 1296, 257, 2710, 3256, 293, 584, 411, 760, 88, 15154, 1023, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.15758790831634964, "compression_ratio": 1.5483870967741935, "no_speech_prob": 1.6700367268640548e-05}, {"id": 287, "seek": 181608, "start": 1816.08, "end": 1835.08, "text": " It can be quite hard to pick out. And so one thing I thought it would be fun to do was to almost like segment or mask the images playing with the color channel to see if they would come out a bit better. And then when I did that, I was able to take kind of, I guess, the yellow dead bits or disease parts and I could see them better when they were like in bright red.", "tokens": [467, 393, 312, 1596, 1152, 281, 1888, 484, 13, 400, 370, 472, 551, 286, 1194, 309, 576, 312, 1019, 281, 360, 390, 281, 1920, 411, 9469, 420, 6094, 264, 5267, 2433, 365, 264, 2017, 2269, 281, 536, 498, 436, 576, 808, 484, 257, 857, 1101, 13, 400, 550, 562, 286, 630, 300, 11, 286, 390, 1075, 281, 747, 733, 295, 11, 286, 2041, 11, 264, 5566, 3116, 9239, 420, 4752, 3166, 293, 286, 727, 536, 552, 1101, 562, 436, 645, 411, 294, 4730, 2182, 13], "temperature": 0.0, "avg_logprob": -0.11345016822386324, "compression_ratio": 1.6383928571428572, "no_speech_prob": 1.6963735106401145e-05}, {"id": 288, "seek": 183508, "start": 1835.08, "end": 1852.08, "text": " And the thing is, is that so many of these, like when I found like when I've trained them, I find that there is a handful of a handful of images really like like 20 to 25 images that are very difficult to classify.", "tokens": [400, 264, 551, 307, 11, 307, 300, 370, 867, 295, 613, 11, 411, 562, 286, 1352, 411, 562, 286, 600, 8895, 552, 11, 286, 915, 300, 456, 307, 257, 16458, 295, 257, 16458, 295, 5267, 534, 411, 411, 945, 281, 3552, 5267, 300, 366, 588, 2252, 281, 33872, 13], "temperature": 0.0, "avg_logprob": -0.11772052152657214, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.46819563471945e-05}, {"id": 289, "seek": 183508, "start": 1852.08, "end": 1862.08, "text": " And it tends to be these actually from these imbalance classes, where it tends to categorize them as blast when it's not.", "tokens": [400, 309, 12258, 281, 312, 613, 767, 490, 613, 43007, 5359, 11, 689, 309, 12258, 281, 19250, 1125, 552, 382, 12035, 562, 309, 311, 406, 13], "temperature": 0.0, "avg_logprob": -0.11772052152657214, "compression_ratio": 1.671641791044776, "no_speech_prob": 2.46819563471945e-05}, {"id": 290, "seek": 186208, "start": 1862.08, "end": 1871.08, "text": " And I think material ones tend to get. Yeah. In fact, let me just pull up in one of my notebooks, maybe share your screen.", "tokens": [400, 286, 519, 2527, 2306, 3928, 281, 483, 13, 865, 13, 682, 1186, 11, 718, 385, 445, 2235, 493, 294, 472, 295, 452, 43782, 11, 1310, 2073, 428, 2568, 13], "temperature": 0.0, "avg_logprob": -0.24799258368355886, "compression_ratio": 1.3884892086330936, "no_speech_prob": 3.763115091715008e-05}, {"id": 291, "seek": 186208, "start": 1871.08, "end": 1878.08, "text": " Yeah, let me see if I like when you look at this. Are you able to see.", "tokens": [865, 11, 718, 385, 536, 498, 286, 411, 562, 291, 574, 412, 341, 13, 2014, 291, 1075, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.24799258368355886, "compression_ratio": 1.3884892086330936, "no_speech_prob": 3.763115091715008e-05}, {"id": 292, "seek": 187808, "start": 1878.08, "end": 1893.08, "text": " To make these bigger, are you able to see the disease in these because I don't know what I'm looking for.", "tokens": [50364, 1407, 652, 613, 3801, 11, 366, 291, 1075, 281, 536, 264, 4752, 294, 613, 570, 286, 500, 380, 458, 437, 286, 478, 1237, 337, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2284742764064244, "compression_ratio": 1.141304347826087, "no_speech_prob": 0.0001463747030356899}, {"id": 293, "seek": 190808, "start": 1908.08, "end": 1913.08, "text": " How do we make this bigger?", "tokens": [1012, 360, 321, 652, 341, 3801, 30], "temperature": 0.0, "avg_logprob": -0.3875221633911133, "compression_ratio": 1.3675213675213675, "no_speech_prob": 0.06557638198137283}, {"id": 294, "seek": 190808, "start": 1913.08, "end": 1919.08, "text": " Probably there's like a bigger size in that plot lives there, that plot live.", "tokens": [9210, 456, 311, 411, 257, 3801, 2744, 294, 300, 7542, 2909, 456, 11, 300, 7542, 1621, 13], "temperature": 0.0, "avg_logprob": -0.3875221633911133, "compression_ratio": 1.3675213675213675, "no_speech_prob": 0.06557638198137283}, {"id": 295, "seek": 190808, "start": 1919.08, "end": 1924.08, "text": " So like fixed size, fixed size.", "tokens": [407, 411, 6806, 2744, 11, 6806, 2744, 13], "temperature": 0.0, "avg_logprob": -0.3875221633911133, "compression_ratio": 1.3675213675213675, "no_speech_prob": 0.06557638198137283}, {"id": 296, "seek": 190808, "start": 1924.08, "end": 1926.08, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3875221633911133, "compression_ratio": 1.3675213675213675, "no_speech_prob": 0.06557638198137283}, {"id": 297, "seek": 190808, "start": 1926.08, "end": 1932.08, "text": " Big signs equals.", "tokens": [5429, 7880, 6915, 13], "temperature": 0.0, "avg_logprob": -0.3875221633911133, "compression_ratio": 1.3675213675213675, "no_speech_prob": 0.06557638198137283}, {"id": 298, "seek": 193208, "start": 1932.08, "end": 1938.08, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.32816837929390574, "compression_ratio": 1.1744186046511629, "no_speech_prob": 0.00014643653412349522}, {"id": 299, "seek": 193208, "start": 1938.08, "end": 1960.08, "text": " By the way, around 9.15 we can't hear you by the way Nick I don't know if you lost you.", "tokens": [3146, 264, 636, 11, 926, 1722, 13, 5211, 321, 393, 380, 1568, 291, 538, 264, 636, 9449, 286, 500, 380, 458, 498, 291, 2731, 291, 13], "temperature": 0.0, "avg_logprob": -0.32816837929390574, "compression_ratio": 1.1744186046511629, "no_speech_prob": 0.00014643653412349522}, {"id": 300, "seek": 196008, "start": 1960.08, "end": 1973.08, "text": " I also tried to look into the image using the confusion matrix and then the most laws to put it out, but it's just too hard is beyond my domain.", "tokens": [286, 611, 3031, 281, 574, 666, 264, 3256, 1228, 264, 15075, 8141, 293, 550, 264, 881, 6064, 281, 829, 309, 484, 11, 457, 309, 311, 445, 886, 1152, 307, 4399, 452, 9274, 13], "temperature": 0.0, "avg_logprob": -0.20803177524620378, "compression_ratio": 1.518716577540107, "no_speech_prob": 3.762740743695758e-05}, {"id": 301, "seek": 196008, "start": 1973.08, "end": 1978.08, "text": " I was planning to do that today actually so that's yeah.", "tokens": [286, 390, 5038, 281, 360, 300, 965, 767, 370, 300, 311, 1338, 13], "temperature": 0.0, "avg_logprob": -0.20803177524620378, "compression_ratio": 1.518716577540107, "no_speech_prob": 3.762740743695758e-05}, {"id": 302, "seek": 196008, "start": 1978.08, "end": 1982.08, "text": " I don't know what happened to Nick maybe he's having some internet problems again.", "tokens": [286, 500, 380, 458, 437, 2011, 281, 9449, 1310, 415, 311, 1419, 512, 4705, 2740, 797, 13], "temperature": 0.0, "avg_logprob": -0.20803177524620378, "compression_ratio": 1.518716577540107, "no_speech_prob": 3.762740743695758e-05}, {"id": 303, "seek": 198208, "start": 1982.08, "end": 1990.08, "text": " I wonder if it's just like spread spots or something.", "tokens": [286, 2441, 498, 309, 311, 445, 411, 3974, 10681, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.1367486317952474, "compression_ratio": 1.5235294117647058, "no_speech_prob": 4.467978578759357e-05}, {"id": 304, "seek": 198208, "start": 1990.08, "end": 2004.08, "text": " So yeah, I mean it's in anyway it's interesting that Nick said he found these ones difficult so yeah there's basically two reasons to to wait different rows differently one is that some of them are harder.", "tokens": [407, 1338, 11, 286, 914, 309, 311, 294, 4033, 309, 311, 1880, 300, 9449, 848, 415, 1352, 613, 2306, 2252, 370, 1338, 456, 311, 1936, 732, 4112, 281, 281, 1699, 819, 13241, 7614, 472, 307, 300, 512, 295, 552, 366, 6081, 13], "temperature": 0.0, "avg_logprob": -0.1367486317952474, "compression_ratio": 1.5235294117647058, "no_speech_prob": 4.467978578759357e-05}, {"id": 305, "seek": 200408, "start": 2004.08, "end": 2014.08, "text": " And that you want them to be shown more often to give the computer more of a chance to learn them. And the other is some are less common. And same thing.", "tokens": [400, 300, 291, 528, 552, 281, 312, 4898, 544, 2049, 281, 976, 264, 3820, 544, 295, 257, 2931, 281, 1466, 552, 13, 400, 264, 661, 307, 512, 366, 1570, 2689, 13, 400, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.09166204097659089, "compression_ratio": 1.353448275862069, "no_speech_prob": 8.011462341528386e-06}, {"id": 306, "seek": 200408, "start": 2014.08, "end": 2018.08, "text": " So,", "tokens": [407, 11], "temperature": 0.0, "avg_logprob": -0.09166204097659089, "compression_ratio": 1.353448275862069, "no_speech_prob": 8.011462341528386e-06}, {"id": 307, "seek": 201808, "start": 2018.08, "end": 2037.08, "text": " you know one possible waiting for these would be to take their reciprocal. And so then, you know, normal is going to be shown less often if we wait all the normal ones by this amount, and all the bacterial panicle blight ones this amount, you're going to get more of these.", "tokens": [291, 458, 472, 1944, 3806, 337, 613, 576, 312, 281, 747, 641, 46948, 13, 400, 370, 550, 11, 291, 458, 11, 2710, 307, 516, 281, 312, 4898, 1570, 2049, 498, 321, 1699, 439, 264, 2710, 2306, 538, 341, 2372, 11, 293, 439, 264, 35632, 2462, 3520, 888, 397, 2306, 341, 2372, 11, 291, 434, 516, 281, 483, 544, 295, 613, 13], "temperature": 0.0, "avg_logprob": -0.14601774339552048, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.710658686235547e-06}, {"id": 308, "seek": 201808, "start": 2037.08, "end": 2040.08, "text": " So that's like one approach we could use.", "tokens": [407, 300, 311, 411, 472, 3109, 321, 727, 764, 13], "temperature": 0.0, "avg_logprob": -0.14601774339552048, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.710658686235547e-06}, {"id": 309, "seek": 204008, "start": 2040.08, "end": 2056.08, "text": " So I feel like that might be overkill. So I'd be inclined to kind of like, not do it quite that much so like another approach would be to like take the square root, maybe one over the square root, kind of like that.", "tokens": [407, 286, 841, 411, 300, 1062, 312, 670, 34213, 13, 407, 286, 1116, 312, 28173, 281, 733, 295, 411, 11, 406, 360, 309, 1596, 300, 709, 370, 411, 1071, 3109, 576, 312, 281, 411, 747, 264, 3732, 5593, 11, 1310, 472, 670, 264, 3732, 5593, 11, 733, 295, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.14012031806142708, "compression_ratio": 1.646067415730337, "no_speech_prob": 1.933269459186704e-06}, {"id": 310, "seek": 204008, "start": 2056.08, "end": 2063.08, "text": " So then, these are going to be shown about twice as often as these, you know.", "tokens": [407, 550, 11, 613, 366, 516, 281, 312, 4898, 466, 6091, 382, 2049, 382, 613, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.14012031806142708, "compression_ratio": 1.646067415730337, "no_speech_prob": 1.933269459186704e-06}, {"id": 311, "seek": 206308, "start": 2063.08, "end": 2070.08, "text": " So maybe like let's start with trying this as our set of weightings.", "tokens": [407, 1310, 411, 718, 311, 722, 365, 1382, 341, 382, 527, 992, 295, 3364, 1109, 13], "temperature": 0.0, "avg_logprob": -0.19390655864368786, "compression_ratio": 1.388157894736842, "no_speech_prob": 7.478727638954297e-05}, {"id": 312, "seek": 206308, "start": 2070.08, "end": 2076.08, "text": " Jeremy, if I could ask a question at this point.", "tokens": [17809, 11, 498, 286, 727, 1029, 257, 1168, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.19390655864368786, "compression_ratio": 1.388157894736842, "no_speech_prob": 7.478727638954297e-05}, {"id": 313, "seek": 206308, "start": 2076.08, "end": 2086.08, "text": " So the waiting and when you talk about waiting such that images are shown more or less often.", "tokens": [407, 264, 3806, 293, 562, 291, 751, 466, 3806, 1270, 300, 5267, 366, 4898, 544, 420, 1570, 2049, 13], "temperature": 0.0, "avg_logprob": -0.19390655864368786, "compression_ratio": 1.388157894736842, "no_speech_prob": 7.478727638954297e-05}, {"id": 314, "seek": 208608, "start": 2086.08, "end": 2104.08, "text": " This is where it's it's very imbalanced, whether that could lead to some classes being overfitted to because the model learns about the images themselves I came across in looking at classification.", "tokens": [639, 307, 689, 309, 311, 309, 311, 588, 566, 40251, 11, 1968, 300, 727, 1477, 281, 512, 5359, 885, 670, 69, 3944, 281, 570, 264, 2316, 27152, 466, 264, 5267, 2969, 286, 1361, 2108, 294, 1237, 412, 21538, 13], "temperature": 0.0, "avg_logprob": -0.22895169812579488, "compression_ratio": 1.3873239436619718, "no_speech_prob": 4.599312160280533e-05}, {"id": 315, "seek": 210408, "start": 2104.08, "end": 2126.08, "text": " And whether there was a way to, I read about how to deal with imbalances, and I've seen some recommendations to try to wait when calculating the losses, rather than resampling the inputs so I just wondered whether it was possible.", "tokens": [400, 1968, 456, 390, 257, 636, 281, 11, 286, 1401, 466, 577, 281, 2028, 365, 566, 2645, 2676, 11, 293, 286, 600, 1612, 512, 10434, 281, 853, 281, 1699, 562, 28258, 264, 15352, 11, 2831, 813, 725, 335, 11970, 264, 15743, 370, 286, 445, 17055, 1968, 309, 390, 1944, 13], "temperature": 0.0, "avg_logprob": -0.22744501961602104, "compression_ratio": 1.4743589743589745, "no_speech_prob": 1.240183428308228e-05}, {"id": 316, "seek": 212608, "start": 2126.08, "end": 2142.08, "text": " It's different right like so. In the end you want it to be able to recognize the features of the images you care about. And there's no substitute for like having them see the images enough times to recognize them.", "tokens": [467, 311, 819, 558, 411, 370, 13, 682, 264, 917, 291, 528, 309, 281, 312, 1075, 281, 5521, 264, 4122, 295, 264, 5267, 291, 1127, 466, 13, 400, 456, 311, 572, 15802, 337, 411, 1419, 552, 536, 264, 5267, 1547, 1413, 281, 5521, 552, 13], "temperature": 0.0, "avg_logprob": -0.1302952766418457, "compression_ratio": 1.65625, "no_speech_prob": 5.861972113052616e-06}, {"id": 317, "seek": 212608, "start": 2142.08, "end": 2151.08, "text": " However, when it does that, it is then going to because it sees the rare cases more often, it's going to", "tokens": [2908, 11, 562, 309, 775, 300, 11, 309, 307, 550, 516, 281, 570, 309, 8194, 264, 5892, 3331, 544, 2049, 11, 309, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.1302952766418457, "compression_ratio": 1.65625, "no_speech_prob": 5.861972113052616e-06}, {"id": 318, "seek": 215108, "start": 2151.08, "end": 2156.08, "text": " recognize rare cases are more probable than they actually are.", "tokens": [5521, 5892, 3331, 366, 544, 21759, 813, 436, 767, 366, 13], "temperature": 0.0, "avg_logprob": -0.09861285036260431, "compression_ratio": 1.6717948717948719, "no_speech_prob": 9.222349035553634e-06}, {"id": 319, "seek": 215108, "start": 2156.08, "end": 2158.08, "text": " So you have to reverse that.", "tokens": [407, 291, 362, 281, 9943, 300, 13], "temperature": 0.0, "avg_logprob": -0.09861285036260431, "compression_ratio": 1.6717948717948719, "no_speech_prob": 9.222349035553634e-06}, {"id": 320, "seek": 215108, "start": 2158.08, "end": 2163.08, "text": " Then, when you make predictions.", "tokens": [1396, 11, 562, 291, 652, 21264, 13], "temperature": 0.0, "avg_logprob": -0.09861285036260431, "compression_ratio": 1.6717948717948719, "no_speech_prob": 9.222349035553634e-06}, {"id": 321, "seek": 215108, "start": 2163.08, "end": 2174.08, "text": " So that's yeah that's something to be to be careful of so I mean, I mean, I think probably just help to try to try to take a look at it to see what that looks like.", "tokens": [407, 300, 311, 1338, 300, 311, 746, 281, 312, 281, 312, 5026, 295, 370, 286, 914, 11, 286, 914, 11, 286, 519, 1391, 445, 854, 281, 853, 281, 853, 281, 747, 257, 574, 412, 309, 281, 536, 437, 300, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.09861285036260431, "compression_ratio": 1.6717948717948719, "no_speech_prob": 9.222349035553634e-06}, {"id": 322, "seek": 215108, "start": 2174.08, "end": 2179.08, "text": " So yeah so here's our weights right.", "tokens": [407, 1338, 370, 510, 311, 527, 17443, 558, 13], "temperature": 0.0, "avg_logprob": -0.09861285036260431, "compression_ratio": 1.6717948717948719, "no_speech_prob": 9.222349035553634e-06}, {"id": 323, "seek": 217908, "start": 2179.08, "end": 2182.08, "text": " So this line to probably.", "tokens": [407, 341, 1622, 281, 1391, 13], "temperature": 0.0, "avg_logprob": -0.18960029738289969, "compression_ratio": 1.5337078651685394, "no_speech_prob": 4.0061495383270085e-05}, {"id": 324, "seek": 217908, "start": 2182.08, "end": 2187.08, "text": " Can we merge things directly, let's take a look so if I go.", "tokens": [1664, 321, 22183, 721, 3838, 11, 718, 311, 747, 257, 574, 370, 498, 286, 352, 13], "temperature": 0.0, "avg_logprob": -0.18960029738289969, "compression_ratio": 1.5337078651685394, "no_speech_prob": 4.0061495383270085e-05}, {"id": 325, "seek": 217908, "start": 2187.08, "end": 2195.08, "text": " Df dot merge, which is kind of like a way of doing a join in pandas.", "tokens": [413, 69, 5893, 22183, 11, 597, 307, 733, 295, 411, 257, 636, 295, 884, 257, 3917, 294, 4565, 296, 13], "temperature": 0.0, "avg_logprob": -0.18960029738289969, "compression_ratio": 1.5337078651685394, "no_speech_prob": 4.0061495383270085e-05}, {"id": 326, "seek": 217908, "start": 2195.08, "end": 2199.08, "text": " And the right hand side yeah the right hand side can be a series. Cool.", "tokens": [400, 264, 558, 1011, 1252, 1338, 264, 558, 1011, 1252, 393, 312, 257, 2638, 13, 8561, 13], "temperature": 0.0, "avg_logprob": -0.18960029738289969, "compression_ratio": 1.5337078651685394, "no_speech_prob": 4.0061495383270085e-05}, {"id": 327, "seek": 217908, "start": 2199.08, "end": 2203.08, "text": " So merge on weights.", "tokens": [407, 22183, 322, 17443, 13], "temperature": 0.0, "avg_logprob": -0.18960029738289969, "compression_ratio": 1.5337078651685394, "no_speech_prob": 4.0061495383270085e-05}, {"id": 328, "seek": 217908, "start": 2203.08, "end": 2206.08, "text": " What does that look like.", "tokens": [708, 775, 300, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.18960029738289969, "compression_ratio": 1.5337078651685394, "no_speech_prob": 4.0061495383270085e-05}, {"id": 329, "seek": 220608, "start": 2206.08, "end": 2215.08, "text": " And then, okay.", "tokens": [400, 550, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.3342105484008789, "compression_ratio": 1.2796610169491525, "no_speech_prob": 1.9525234165485017e-05}, {"id": 330, "seek": 220608, "start": 2215.08, "end": 2227.08, "text": " Left. I see so left. Okay so on left left on left on equals label.", "tokens": [16405, 13, 286, 536, 370, 1411, 13, 1033, 370, 322, 1411, 1411, 322, 1411, 322, 6915, 7645, 13], "temperature": 0.0, "avg_logprob": -0.3342105484008789, "compression_ratio": 1.2796610169491525, "no_speech_prob": 1.9525234165485017e-05}, {"id": 331, "seek": 220608, "start": 2227.08, "end": 2233.08, "text": " And right, I think that's called the index. I'm not a pandas expert.", "tokens": [400, 558, 11, 286, 519, 300, 311, 1219, 264, 8186, 13, 286, 478, 406, 257, 4565, 296, 5844, 13], "temperature": 0.0, "avg_logprob": -0.3342105484008789, "compression_ratio": 1.2796610169491525, "no_speech_prob": 1.9525234165485017e-05}, {"id": 332, "seek": 223308, "start": 2233.08, "end": 2238.08, "text": " I don't know if anybody is.", "tokens": [286, 500, 380, 458, 498, 4472, 307, 13], "temperature": 0.0, "avg_logprob": -0.1671867881502424, "compression_ratio": 1.3360655737704918, "no_speech_prob": 1.544580482004676e-05}, {"id": 333, "seek": 223308, "start": 2238.08, "end": 2239.08, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.1671867881502424, "compression_ratio": 1.3360655737704918, "no_speech_prob": 1.544580482004676e-05}, {"id": 334, "seek": 223308, "start": 2239.08, "end": 2241.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.1671867881502424, "compression_ratio": 1.3360655737704918, "no_speech_prob": 1.544580482004676e-05}, {"id": 335, "seek": 223308, "start": 2241.08, "end": 2250.08, "text": " So that's added these weights here.", "tokens": [407, 300, 311, 3869, 613, 17443, 510, 13], "temperature": 0.0, "avg_logprob": -0.1671867881502424, "compression_ratio": 1.3360655737704918, "no_speech_prob": 1.544580482004676e-05}, {"id": 336, "seek": 223308, "start": 2250.08, "end": 2256.08, "text": " Give them a slightly weird name but that's okay.", "tokens": [5303, 552, 257, 4748, 3657, 1315, 457, 300, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.1671867881502424, "compression_ratio": 1.3360655737704918, "no_speech_prob": 1.544580482004676e-05}, {"id": 337, "seek": 223308, "start": 2256.08, "end": 2262.08, "text": " So if we call that weighted Df.", "tokens": [407, 498, 321, 818, 300, 32807, 413, 69, 13], "temperature": 0.0, "avg_logprob": -0.1671867881502424, "compression_ratio": 1.3360655737704918, "no_speech_prob": 1.544580482004676e-05}, {"id": 338, "seek": 226208, "start": 2262.08, "end": 2272.08, "text": " And so then,", "tokens": [400, 370, 550, 11], "temperature": 0.0, "avg_logprob": -0.1967045393857089, "compression_ratio": 1.3097345132743363, "no_speech_prob": 1.8923137758974917e-05}, {"id": 339, "seek": 226208, "start": 2272.08, "end": 2280.08, "text": " we could get take a little, a little function and move them over here.", "tokens": [321, 727, 483, 747, 257, 707, 11, 257, 707, 2445, 293, 1286, 552, 670, 510, 13], "temperature": 0.0, "avg_logprob": -0.1967045393857089, "compression_ratio": 1.3097345132743363, "no_speech_prob": 1.8923137758974917e-05}, {"id": 340, "seek": 226208, "start": 2280.08, "end": 2289.08, "text": " And I think what we want to do is use data blocks at this point.", "tokens": [400, 286, 519, 437, 321, 528, 281, 360, 307, 764, 1412, 8474, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.1967045393857089, "compression_ratio": 1.3097345132743363, "no_speech_prob": 1.8923137758974917e-05}, {"id": 341, "seek": 228908, "start": 2289.08, "end": 2298.08, "text": " That's kind of a good idea.", "tokens": [663, 311, 733, 295, 257, 665, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1515352909381573, "compression_ratio": 1.1553398058252426, "no_speech_prob": 3.763357744901441e-05}, {"id": 342, "seek": 228908, "start": 2298.08, "end": 2303.08, "text": " And we have a data blocks version.", "tokens": [400, 321, 362, 257, 1412, 8474, 3037, 13], "temperature": 0.0, "avg_logprob": -0.1515352909381573, "compression_ratio": 1.1553398058252426, "no_speech_prob": 3.763357744901441e-05}, {"id": 343, "seek": 228908, "start": 2303.08, "end": 2309.08, "text": " Certainly make one otherwise.", "tokens": [16628, 652, 472, 5911, 13], "temperature": 0.0, "avg_logprob": -0.1515352909381573, "compression_ratio": 1.1553398058252426, "no_speech_prob": 3.763357744901441e-05}, {"id": 344, "seek": 228908, "start": 2309.08, "end": 2316.08, "text": " Okay, here's a data block.", "tokens": [1033, 11, 510, 311, 257, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.1515352909381573, "compression_ratio": 1.1553398058252426, "no_speech_prob": 3.763357744901441e-05}, {"id": 345, "seek": 231608, "start": 2316.08, "end": 2321.08, "text": " So let's create a data block.", "tokens": [407, 718, 311, 1884, 257, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.20613173515565933, "compression_ratio": 1.1481481481481481, "no_speech_prob": 8.530181730748154e-06}, {"id": 346, "seek": 231608, "start": 2321.08, "end": 2331.08, "text": " Got an image block and a category block.", "tokens": [5803, 364, 3256, 3461, 293, 257, 7719, 3461, 13], "temperature": 0.0, "avg_logprob": -0.20613173515565933, "compression_ratio": 1.1481481481481481, "no_speech_prob": 8.530181730748154e-06}, {"id": 347, "seek": 231608, "start": 2331.08, "end": 2337.08, "text": " Get y is parent label.", "tokens": [3240, 288, 307, 2596, 7645, 13], "temperature": 0.0, "avg_logprob": -0.20613173515565933, "compression_ratio": 1.1481481481481481, "no_speech_prob": 8.530181730748154e-06}, {"id": 348, "seek": 233708, "start": 2337.08, "end": 2346.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2939600027524508, "compression_ratio": 1.2327586206896552, "no_speech_prob": 0.00011561907740542665}, {"id": 349, "seek": 233708, "start": 2346.08, "end": 2348.08, "text": " Item transforms is this.", "tokens": [31066, 35592, 307, 341, 13], "temperature": 0.0, "avg_logprob": -0.2939600027524508, "compression_ratio": 1.2327586206896552, "no_speech_prob": 0.00011561907740542665}, {"id": 350, "seek": 233708, "start": 2348.08, "end": 2350.08, "text": " Jeremy I think you're in the wrong.", "tokens": [17809, 286, 519, 291, 434, 294, 264, 2085, 13], "temperature": 0.0, "avg_logprob": -0.2939600027524508, "compression_ratio": 1.2327586206896552, "no_speech_prob": 0.00011561907740542665}, {"id": 351, "seek": 233708, "start": 2350.08, "end": 2352.08, "text": " Book should be in weighted.", "tokens": [9476, 820, 312, 294, 32807, 13], "temperature": 0.0, "avg_logprob": -0.2939600027524508, "compression_ratio": 1.2327586206896552, "no_speech_prob": 0.00011561907740542665}, {"id": 352, "seek": 233708, "start": 2352.08, "end": 2355.08, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2939600027524508, "compression_ratio": 1.2327586206896552, "no_speech_prob": 0.00011561907740542665}, {"id": 353, "seek": 233708, "start": 2355.08, "end": 2357.08, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2939600027524508, "compression_ratio": 1.2327586206896552, "no_speech_prob": 0.00011561907740542665}, {"id": 354, "seek": 233708, "start": 2357.08, "end": 2360.08, "text": " Yes, I had these here but.", "tokens": [1079, 11, 286, 632, 613, 510, 457, 13], "temperature": 0.0, "avg_logprob": -0.2939600027524508, "compression_ratio": 1.2327586206896552, "no_speech_prob": 0.00011561907740542665}, {"id": 355, "seek": 236008, "start": 2360.08, "end": 2374.08, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.18484912774501702, "compression_ratio": 1.1397849462365592, "no_speech_prob": 7.410991202050354e-06}, {"id": 356, "seek": 236008, "start": 2374.08, "end": 2379.08, "text": " Okay, and that transforms.", "tokens": [1033, 11, 293, 300, 35592, 13], "temperature": 0.0, "avg_logprob": -0.18484912774501702, "compression_ratio": 1.1397849462365592, "no_speech_prob": 7.410991202050354e-06}, {"id": 357, "seek": 236008, "start": 2379.08, "end": 2382.08, "text": " We should just use the same ones we had here.", "tokens": [492, 820, 445, 764, 264, 912, 2306, 321, 632, 510, 13], "temperature": 0.0, "avg_logprob": -0.18484912774501702, "compression_ratio": 1.1397849462365592, "no_speech_prob": 7.410991202050354e-06}, {"id": 358, "seek": 236008, "start": 2382.08, "end": 2386.08, "text": " To make it fair.", "tokens": [1407, 652, 309, 3143, 13], "temperature": 0.0, "avg_logprob": -0.18484912774501702, "compression_ratio": 1.1397849462365592, "no_speech_prob": 7.410991202050354e-06}, {"id": 359, "seek": 236008, "start": 2386.08, "end": 2388.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.18484912774501702, "compression_ratio": 1.1397849462365592, "no_speech_prob": 7.410991202050354e-06}, {"id": 360, "seek": 238808, "start": 2388.08, "end": 2394.08, "text": " So there's our data block.", "tokens": [407, 456, 311, 527, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.23211424034762096, "compression_ratio": 1.478494623655914, "no_speech_prob": 3.426007242524065e-05}, {"id": 361, "seek": 238808, "start": 2394.08, "end": 2400.08, "text": " Oh, we actually use this resizing.", "tokens": [876, 11, 321, 767, 764, 341, 725, 3319, 13], "temperature": 0.0, "avg_logprob": -0.23211424034762096, "compression_ratio": 1.478494623655914, "no_speech_prob": 3.426007242524065e-05}, {"id": 362, "seek": 238808, "start": 2400.08, "end": 2402.08, "text": " So, yes.", "tokens": [407, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.23211424034762096, "compression_ratio": 1.478494623655914, "no_speech_prob": 3.426007242524065e-05}, {"id": 363, "seek": 238808, "start": 2402.08, "end": 2403.08, "text": " Okay, Jeremy.", "tokens": [1033, 11, 17809, 13], "temperature": 0.0, "avg_logprob": -0.23211424034762096, "compression_ratio": 1.478494623655914, "no_speech_prob": 3.426007242524065e-05}, {"id": 364, "seek": 238808, "start": 2403.08, "end": 2404.08, "text": " Yeah, sorry.", "tokens": [865, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.23211424034762096, "compression_ratio": 1.478494623655914, "no_speech_prob": 3.426007242524065e-05}, {"id": 365, "seek": 238808, "start": 2404.08, "end": 2405.08, "text": " Sorry to interrupt there.", "tokens": [4919, 281, 12729, 456, 13], "temperature": 0.0, "avg_logprob": -0.23211424034762096, "compression_ratio": 1.478494623655914, "no_speech_prob": 3.426007242524065e-05}, {"id": 366, "seek": 238808, "start": 2405.08, "end": 2417.08, "text": " So this approach is we're going to use the data block to even the numbers of what's being sampled so that we can more augmentations of the same images.", "tokens": [407, 341, 3109, 307, 321, 434, 516, 281, 764, 264, 1412, 3461, 281, 754, 264, 3547, 295, 437, 311, 885, 3247, 15551, 370, 300, 321, 393, 544, 29919, 763, 295, 264, 912, 5267, 13], "temperature": 0.0, "avg_logprob": -0.23211424034762096, "compression_ratio": 1.478494623655914, "no_speech_prob": 3.426007242524065e-05}, {"id": 367, "seek": 241708, "start": 2417.08, "end": 2427.08, "text": " So, we're going to use the data block to even the numbers of the same images for the lower represented samples or kind of.", "tokens": [407, 11, 321, 434, 516, 281, 764, 264, 1412, 3461, 281, 754, 264, 3547, 295, 264, 912, 5267, 337, 264, 3126, 10379, 10938, 420, 733, 295, 13], "temperature": 0.0, "avg_logprob": -0.3383090039517017, "compression_ratio": 1.7524271844660195, "no_speech_prob": 2.045671863015741e-05}, {"id": 368, "seek": 241708, "start": 2427.08, "end": 2429.08, "text": " So, it's nothing to do with the data block.", "tokens": [407, 11, 309, 311, 1825, 281, 360, 365, 264, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.3383090039517017, "compression_ratio": 1.7524271844660195, "no_speech_prob": 2.045671863015741e-05}, {"id": 369, "seek": 241708, "start": 2429.08, "end": 2432.08, "text": " We're going to use things called weighted data loaders.", "tokens": [492, 434, 516, 281, 764, 721, 1219, 32807, 1412, 3677, 433, 13], "temperature": 0.0, "avg_logprob": -0.3383090039517017, "compression_ratio": 1.7524271844660195, "no_speech_prob": 2.045671863015741e-05}, {"id": 370, "seek": 241708, "start": 2432.08, "end": 2437.08, "text": " And the way to data loader is going to use these numbers here.", "tokens": [400, 264, 636, 281, 1412, 3677, 260, 307, 516, 281, 764, 613, 3547, 510, 13], "temperature": 0.0, "avg_logprob": -0.3383090039517017, "compression_ratio": 1.7524271844660195, "no_speech_prob": 2.045671863015741e-05}, {"id": 371, "seek": 241708, "start": 2437.08, "end": 2445.08, "text": " To as as basically like probabilities of how likely it is to pick that row.", "tokens": [1407, 382, 382, 1936, 411, 33783, 295, 577, 3700, 309, 307, 281, 1888, 300, 5386, 13], "temperature": 0.0, "avg_logprob": -0.3383090039517017, "compression_ratio": 1.7524271844660195, "no_speech_prob": 2.045671863015741e-05}, {"id": 372, "seek": 244508, "start": 2445.08, "end": 2449.08, "text": " And to each of these divided by the sum so they'll add to one.", "tokens": [400, 281, 1184, 295, 613, 6666, 538, 264, 2408, 370, 436, 603, 909, 281, 472, 13], "temperature": 0.0, "avg_logprob": -0.1098648489338078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 2.2470328985946253e-05}, {"id": 373, "seek": 244508, "start": 2449.08, "end": 2458.08, "text": " The reason I did data blocks is because the weighted data loaders method is a method of data block.", "tokens": [440, 1778, 286, 630, 1412, 8474, 307, 570, 264, 32807, 1412, 3677, 433, 3170, 307, 257, 3170, 295, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.1098648489338078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 2.2470328985946253e-05}, {"id": 374, "seek": 244508, "start": 2458.08, "end": 2466.08, "text": " It's not something we get in the, you know, quick and dirty image data loaders thing that doesn't have as much flexibility.", "tokens": [467, 311, 406, 746, 321, 483, 294, 264, 11, 291, 458, 11, 1702, 293, 9360, 3256, 1412, 3677, 433, 551, 300, 1177, 380, 362, 382, 709, 12635, 13], "temperature": 0.0, "avg_logprob": -0.1098648489338078, "compression_ratio": 1.5294117647058822, "no_speech_prob": 2.2470328985946253e-05}, {"id": 375, "seek": 246608, "start": 2466.08, "end": 2475.08, "text": " So now that we've got a data block we can type the block dot. Oh, and we'll have to import it import fast.", "tokens": [407, 586, 300, 321, 600, 658, 257, 1412, 3461, 321, 393, 2010, 264, 3461, 5893, 13, 876, 11, 293, 321, 603, 362, 281, 974, 309, 974, 2370, 13], "temperature": 0.0, "avg_logprob": -0.3510627746582031, "compression_ratio": 1.4126984126984128, "no_speech_prob": 3.6686703879240667e-06}, {"id": 376, "seek": 246608, "start": 2475.08, "end": 2481.08, "text": " I call back dot.", "tokens": [286, 818, 646, 5893, 13], "temperature": 0.0, "avg_logprob": -0.3510627746582031, "compression_ratio": 1.4126984126984128, "no_speech_prob": 3.6686703879240667e-06}, {"id": 377, "seek": 246608, "start": 2481.08, "end": 2483.08, "text": " What was it in again.", "tokens": [708, 390, 309, 294, 797, 13], "temperature": 0.0, "avg_logprob": -0.3510627746582031, "compression_ratio": 1.4126984126984128, "no_speech_prob": 3.6686703879240667e-06}, {"id": 378, "seek": 246608, "start": 2483.08, "end": 2485.08, "text": " I don't remember fast.", "tokens": [286, 500, 380, 1604, 2370, 13], "temperature": 0.0, "avg_logprob": -0.3510627746582031, "compression_ratio": 1.4126984126984128, "no_speech_prob": 3.6686703879240667e-06}, {"id": 379, "seek": 246608, "start": 2485.08, "end": 2490.08, "text": " I waited.", "tokens": [286, 15240, 13], "temperature": 0.0, "avg_logprob": -0.3510627746582031, "compression_ratio": 1.4126984126984128, "no_speech_prob": 3.6686703879240667e-06}, {"id": 380, "seek": 249008, "start": 2490.08, "end": 2505.08, "text": " Oh, okay.", "tokens": [876, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.20234878063201905, "compression_ratio": 1.25, "no_speech_prob": 6.143851351225749e-06}, {"id": 381, "seek": 249008, "start": 2505.08, "end": 2511.08, "text": " So that's it's a it's actually a method of data sets.", "tokens": [407, 300, 311, 309, 311, 257, 309, 311, 767, 257, 3170, 295, 1412, 6352, 13], "temperature": 0.0, "avg_logprob": -0.20234878063201905, "compression_ratio": 1.25, "no_speech_prob": 6.143851351225749e-06}, {"id": 382, "seek": 249008, "start": 2511.08, "end": 2516.08, "text": " So we can get a data sets object from a data block.", "tokens": [407, 321, 393, 483, 257, 1412, 6352, 2657, 490, 257, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.20234878063201905, "compression_ratio": 1.25, "no_speech_prob": 6.143851351225749e-06}, {"id": 383, "seek": 251608, "start": 2516.08, "end": 2520.08, "text": " Like so.", "tokens": [1743, 370, 13], "temperature": 0.0, "avg_logprob": -0.1427938249376085, "compression_ratio": 1.2884615384615385, "no_speech_prob": 1.0289250894857105e-05}, {"id": 384, "seek": 251608, "start": 2520.08, "end": 2523.08, "text": " And we pass in source.", "tokens": [400, 321, 1320, 294, 4009, 13], "temperature": 0.0, "avg_logprob": -0.1427938249376085, "compression_ratio": 1.2884615384615385, "no_speech_prob": 1.0289250894857105e-05}, {"id": 385, "seek": 251608, "start": 2523.08, "end": 2531.08, "text": " So that would be our list of image files.", "tokens": [407, 300, 576, 312, 527, 1329, 295, 3256, 7098, 13], "temperature": 0.0, "avg_logprob": -0.1427938249376085, "compression_ratio": 1.2884615384615385, "no_speech_prob": 1.0289250894857105e-05}, {"id": 386, "seek": 251608, "start": 2531.08, "end": 2539.08, "text": " So we can files equals get image files.", "tokens": [407, 321, 393, 7098, 6915, 483, 3256, 7098, 13], "temperature": 0.0, "avg_logprob": -0.1427938249376085, "compression_ratio": 1.2884615384615385, "no_speech_prob": 1.0289250894857105e-05}, {"id": 387, "seek": 251608, "start": 2539.08, "end": 2542.08, "text": " In our training set.", "tokens": [682, 527, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.1427938249376085, "compression_ratio": 1.2884615384615385, "no_speech_prob": 1.0289250894857105e-05}, {"id": 388, "seek": 254208, "start": 2542.08, "end": 2551.08, "text": " You pass those in and there's our training set and there's a validation set.", "tokens": [509, 1320, 729, 294, 293, 456, 311, 527, 3097, 992, 293, 456, 311, 257, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.1284551362733583, "compression_ratio": 1.6571428571428573, "no_speech_prob": 5.771819360234076e-06}, {"id": 389, "seek": 254208, "start": 2551.08, "end": 2557.08, "text": " So their data sets. So these are the things that remember we can index into and get a single X, Y pair.", "tokens": [407, 641, 1412, 6352, 13, 407, 613, 366, 264, 721, 300, 1604, 321, 393, 8186, 666, 293, 483, 257, 2167, 1783, 11, 398, 6119, 13], "temperature": 0.0, "avg_logprob": -0.1284551362733583, "compression_ratio": 1.6571428571428573, "no_speech_prob": 5.771819360234076e-06}, {"id": 390, "seek": 254208, "start": 2557.08, "end": 2569.08, "text": " And so weighted data loaders is then something we can pass data sets to and give it weights and a batch size.", "tokens": [400, 370, 32807, 1412, 3677, 433, 307, 550, 746, 321, 393, 1320, 1412, 6352, 281, 293, 976, 309, 17443, 293, 257, 15245, 2744, 13], "temperature": 0.0, "avg_logprob": -0.1284551362733583, "compression_ratio": 1.6571428571428573, "no_speech_prob": 5.771819360234076e-06}, {"id": 391, "seek": 256908, "start": 2569.08, "end": 2575.08, "text": " Okay. And the weights for the training set.", "tokens": [1033, 13, 400, 264, 17443, 337, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.16771276941839255, "compression_ratio": 1.3129770992366412, "no_speech_prob": 8.800931937003043e-06}, {"id": 392, "seek": 256908, "start": 2575.08, "end": 2583.08, "text": " Okay, we're going to have to be careful about this.", "tokens": [1033, 11, 321, 434, 516, 281, 362, 281, 312, 5026, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.16771276941839255, "compression_ratio": 1.3129770992366412, "no_speech_prob": 8.800931937003043e-06}, {"id": 393, "seek": 256908, "start": 2583.08, "end": 2588.08, "text": " So we should be to go DSS dot weighted data loaders.", "tokens": [407, 321, 820, 312, 281, 352, 15816, 50, 5893, 32807, 1412, 3677, 433, 13], "temperature": 0.0, "avg_logprob": -0.16771276941839255, "compression_ratio": 1.3129770992366412, "no_speech_prob": 8.800931937003043e-06}, {"id": 394, "seek": 256908, "start": 2588.08, "end": 2592.08, "text": " And so the source code.", "tokens": [400, 370, 264, 4009, 3089, 13], "temperature": 0.0, "avg_logprob": -0.16771276941839255, "compression_ratio": 1.3129770992366412, "no_speech_prob": 8.800931937003043e-06}, {"id": 395, "seek": 259208, "start": 2592.08, "end": 2599.08, "text": " I guess it calls.", "tokens": [286, 2041, 309, 5498, 13], "temperature": 0.0, "avg_logprob": -0.41674702962239585, "compression_ratio": 0.8, "no_speech_prob": 4.3984156945953146e-05}, {"id": 396, "seek": 259208, "start": 2599.08, "end": 2611.08, "text": " Which is here.", "tokens": [3013, 307, 510, 13], "temperature": 0.0, "avg_logprob": -0.41674702962239585, "compression_ratio": 0.8, "no_speech_prob": 4.3984156945953146e-05}, {"id": 397, "seek": 261108, "start": 2611.08, "end": 2623.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.16815317471822103, "compression_ratio": 1.0238095238095237, "no_speech_prob": 2.684144874365302e-06}, {"id": 398, "seek": 261108, "start": 2623.08, "end": 2635.08, "text": " All right. I'm not 100 percent sure how this is going to work, but let's try it.", "tokens": [1057, 558, 13, 286, 478, 406, 2319, 3043, 988, 577, 341, 307, 516, 281, 589, 11, 457, 718, 311, 853, 309, 13], "temperature": 0.0, "avg_logprob": -0.16815317471822103, "compression_ratio": 1.0238095238095237, "no_speech_prob": 2.684144874365302e-06}, {"id": 399, "seek": 263508, "start": 2635.08, "end": 2642.08, "text": " So our weighted data frame.", "tokens": [407, 527, 32807, 1412, 3920, 13], "temperature": 0.0, "avg_logprob": -0.1439305736172584, "compression_ratio": 1.1204819277108433, "no_speech_prob": 5.453211429085059e-07}, {"id": 400, "seek": 263508, "start": 2642.08, "end": 2653.08, "text": " So this is the weight for each row.", "tokens": [407, 341, 307, 264, 3364, 337, 1184, 5386, 13], "temperature": 0.0, "avg_logprob": -0.1439305736172584, "compression_ratio": 1.1204819277108433, "no_speech_prob": 5.453211429085059e-07}, {"id": 401, "seek": 263508, "start": 2653.08, "end": 2656.08, "text": " And then we've got our files.", "tokens": [400, 550, 321, 600, 658, 527, 7098, 13], "temperature": 0.0, "avg_logprob": -0.1439305736172584, "compression_ratio": 1.1204819277108433, "no_speech_prob": 5.453211429085059e-07}, {"id": 402, "seek": 265608, "start": 2656.08, "end": 2669.08, "text": " Yeah, we're going to be a bit careful here, right? Because they're in they're in different orders.", "tokens": [865, 11, 321, 434, 516, 281, 312, 257, 857, 5026, 510, 11, 558, 30, 1436, 436, 434, 294, 436, 434, 294, 819, 9470, 13], "temperature": 0.0, "avg_logprob": -0.12683546745170982, "compression_ratio": 1.5, "no_speech_prob": 1.1658419680316001e-05}, {"id": 403, "seek": 265608, "start": 2669.08, "end": 2675.08, "text": " So we actually need.", "tokens": [407, 321, 767, 643, 13], "temperature": 0.0, "avg_logprob": -0.12683546745170982, "compression_ratio": 1.5, "no_speech_prob": 1.1658419680316001e-05}, {"id": 404, "seek": 265608, "start": 2675.08, "end": 2685.08, "text": " We actually need a way to get a list of weights where the two orders are going to match each other.", "tokens": [492, 767, 643, 257, 636, 281, 483, 257, 1329, 295, 17443, 689, 264, 732, 9470, 366, 516, 281, 2995, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.12683546745170982, "compression_ratio": 1.5, "no_speech_prob": 1.1658419680316001e-05}, {"id": 405, "seek": 268508, "start": 2685.08, "end": 2688.08, "text": " Can you do it by key lookup? Can you put a key? Yeah, we could do it by key lookup.", "tokens": [1664, 291, 360, 309, 538, 2141, 574, 1010, 30, 1664, 291, 829, 257, 2141, 30, 865, 11, 321, 727, 360, 309, 538, 2141, 574, 1010, 13], "temperature": 0.0, "avg_logprob": -0.22382814089457195, "compression_ratio": 1.355072463768116, "no_speech_prob": 1.2605917618202511e-05}, {"id": 406, "seek": 268508, "start": 2688.08, "end": 2698.08, "text": " I'm actually thinking of something a little lazier, which is just to sort them both.", "tokens": [286, 478, 767, 1953, 295, 746, 257, 707, 19320, 811, 11, 597, 307, 445, 281, 1333, 552, 1293, 13], "temperature": 0.0, "avg_logprob": -0.22382814089457195, "compression_ratio": 1.355072463768116, "no_speech_prob": 1.2605917618202511e-05}, {"id": 407, "seek": 268508, "start": 2698.08, "end": 2704.08, "text": " Okay, so.", "tokens": [1033, 11, 370, 13], "temperature": 0.0, "avg_logprob": -0.22382814089457195, "compression_ratio": 1.355072463768116, "no_speech_prob": 1.2605917618202511e-05}, {"id": 408, "seek": 268508, "start": 2704.08, "end": 2709.08, "text": " Although", "tokens": [5780], "temperature": 0.0, "avg_logprob": -0.22382814089457195, "compression_ratio": 1.355072463768116, "no_speech_prob": 1.2605917618202511e-05}, {"id": 409, "seek": 270908, "start": 2709.08, "end": 2717.08, "text": " this seems to only have a what's going on here?", "tokens": [341, 2544, 281, 787, 362, 257, 437, 311, 516, 322, 510, 30], "temperature": 0.0, "avg_logprob": -0.13869833946228027, "compression_ratio": 1.1176470588235294, "no_speech_prob": 8.530142622475978e-06}, {"id": 410, "seek": 270908, "start": 2717.08, "end": 2726.08, "text": " Doesn't have them all.", "tokens": [12955, 380, 362, 552, 439, 13], "temperature": 0.0, "avg_logprob": -0.13869833946228027, "compression_ratio": 1.1176470588235294, "no_speech_prob": 8.530142622475978e-06}, {"id": 411, "seek": 270908, "start": 2726.08, "end": 2734.08, "text": " Are they not contiguous?", "tokens": [2014, 436, 406, 660, 30525, 30], "temperature": 0.0, "avg_logprob": -0.13869833946228027, "compression_ratio": 1.1176470588235294, "no_speech_prob": 8.530142622475978e-06}, {"id": 412, "seek": 273408, "start": 2734.08, "end": 2740.08, "text": " Sort values by image ID.", "tokens": [26149, 4190, 538, 3256, 7348, 13], "temperature": 0.0, "avg_logprob": -0.19391366055137232, "compression_ratio": 1.25, "no_speech_prob": 1.4281761650636327e-05}, {"id": 413, "seek": 273408, "start": 2740.08, "end": 2748.08, "text": " They are contiguous. So where is image 100001?", "tokens": [814, 366, 660, 30525, 13, 407, 689, 307, 3256, 2319, 628, 16, 30], "temperature": 0.0, "avg_logprob": -0.19391366055137232, "compression_ratio": 1.25, "no_speech_prob": 1.4281761650636327e-05}, {"id": 414, "seek": 273408, "start": 2748.08, "end": 2752.08, "text": " The sorting must be by folder first though.", "tokens": [440, 32411, 1633, 312, 538, 10820, 700, 1673, 13], "temperature": 0.0, "avg_logprob": -0.19391366055137232, "compression_ratio": 1.25, "no_speech_prob": 1.4281761650636327e-05}, {"id": 415, "seek": 273408, "start": 2752.08, "end": 2758.08, "text": " Yes, of course. That's exactly what it is. Thank you.", "tokens": [1079, 11, 295, 1164, 13, 663, 311, 2293, 437, 309, 307, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.19391366055137232, "compression_ratio": 1.25, "no_speech_prob": 1.4281761650636327e-05}, {"id": 416, "seek": 273408, "start": 2758.08, "end": 2762.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.19391366055137232, "compression_ratio": 1.25, "no_speech_prob": 1.4281761650636327e-05}, {"id": 417, "seek": 276208, "start": 2762.08, "end": 2768.08, "text": " So we could use a key.", "tokens": [407, 321, 727, 764, 257, 2141, 13], "temperature": 0.0, "avg_logprob": -0.10296075375049145, "compression_ratio": 1.4850299401197604, "no_speech_prob": 5.173801582714077e-06}, {"id": 418, "seek": 276208, "start": 2768.08, "end": 2776.08, "text": " That looks hopeful. It says here if the key is a string, use attribute getter. So I think I can just pass in the key name.", "tokens": [663, 1542, 20531, 13, 467, 1619, 510, 498, 264, 2141, 307, 257, 6798, 11, 764, 19667, 483, 391, 13, 407, 286, 519, 286, 393, 445, 1320, 294, 264, 2141, 1315, 13], "temperature": 0.0, "avg_logprob": -0.10296075375049145, "compression_ratio": 1.4850299401197604, "no_speech_prob": 5.173801582714077e-06}, {"id": 419, "seek": 276208, "start": 2776.08, "end": 2780.08, "text": " Ah, that is magic.", "tokens": [2438, 11, 300, 307, 5585, 13], "temperature": 0.0, "avg_logprob": -0.10296075375049145, "compression_ratio": 1.4850299401197604, "no_speech_prob": 5.173801582714077e-06}, {"id": 420, "seek": 276208, "start": 2780.08, "end": 2786.08, "text": " That is the magic of fast core right there.", "tokens": [663, 307, 264, 5585, 295, 2370, 4965, 558, 456, 13], "temperature": 0.0, "avg_logprob": -0.10296075375049145, "compression_ratio": 1.4850299401197604, "no_speech_prob": 5.173801582714077e-06}, {"id": 421, "seek": 276208, "start": 2786.08, "end": 2790.08, "text": " There we go. So that's sorting by name.", "tokens": [821, 321, 352, 13, 407, 300, 311, 32411, 538, 1315, 13], "temperature": 0.0, "avg_logprob": -0.10296075375049145, "compression_ratio": 1.4850299401197604, "no_speech_prob": 5.173801582714077e-06}, {"id": 422, "seek": 279008, "start": 2790.08, "end": 2798.08, "text": " And we can do the same thing for this one.", "tokens": [400, 321, 393, 360, 264, 912, 551, 337, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.06505994200706482, "compression_ratio": 1.2659574468085106, "no_speech_prob": 1.3845013199897949e-05}, {"id": 423, "seek": 279008, "start": 2798.08, "end": 2801.08, "text": " Like so.", "tokens": [1743, 370, 13], "temperature": 0.0, "avg_logprob": -0.06505994200706482, "compression_ratio": 1.2659574468085106, "no_speech_prob": 1.3845013199897949e-05}, {"id": 424, "seek": 279008, "start": 2801.08, "end": 2814.08, "text": " And so now they're sorted by the same thing. So that's a good step.", "tokens": [400, 370, 586, 436, 434, 25462, 538, 264, 912, 551, 13, 407, 300, 311, 257, 665, 1823, 13], "temperature": 0.0, "avg_logprob": -0.06505994200706482, "compression_ratio": 1.2659574468085106, "no_speech_prob": 1.3845013199897949e-05}, {"id": 425, "seek": 281408, "start": 2814.08, "end": 2826.08, "text": " So the weights are basically WDF dot label Y.", "tokens": [407, 264, 17443, 366, 1936, 343, 35, 37, 5893, 7645, 398, 13], "temperature": 0.0, "avg_logprob": -0.23596170213487414, "compression_ratio": 0.9753086419753086, "no_speech_prob": 9.971829058486037e-06}, {"id": 426, "seek": 281408, "start": 2826.08, "end": 2838.08, "text": " Now that's a pandas series, which", "tokens": [823, 300, 311, 257, 4565, 296, 2638, 11, 597], "temperature": 0.0, "avg_logprob": -0.23596170213487414, "compression_ratio": 0.9753086419753086, "no_speech_prob": 9.971829058486037e-06}, {"id": 427, "seek": 283808, "start": 2838.08, "end": 2845.08, "text": " yes, to numpy would turn it into an array.", "tokens": [2086, 11, 281, 1031, 8200, 576, 1261, 309, 666, 364, 10225, 13], "temperature": 0.0, "avg_logprob": -0.15043700536092122, "compression_ratio": 1.3661971830985915, "no_speech_prob": 1.112508380174404e-05}, {"id": 428, "seek": 283808, "start": 2845.08, "end": 2851.08, "text": " I'm just not quite sure whether this has to be just for the training set or is for both. We'll find out in a moment.", "tokens": [286, 478, 445, 406, 1596, 988, 1968, 341, 575, 281, 312, 445, 337, 264, 3097, 992, 420, 307, 337, 1293, 13, 492, 603, 915, 484, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.15043700536092122, "compression_ratio": 1.3661971830985915, "no_speech_prob": 1.112508380174404e-05}, {"id": 429, "seek": 283808, "start": 2851.08, "end": 2859.08, "text": " If I run that, it doesn't like it.", "tokens": [759, 286, 1190, 300, 11, 309, 1177, 380, 411, 309, 13], "temperature": 0.0, "avg_logprob": -0.15043700536092122, "compression_ratio": 1.3661971830985915, "no_speech_prob": 1.112508380174404e-05}, {"id": 430, "seek": 285908, "start": 2859.08, "end": 2868.08, "text": " That's interesting.", "tokens": [663, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.13830397605895997, "compression_ratio": 1.0978260869565217, "no_speech_prob": 4.565611106954748e-06}, {"id": 431, "seek": 285908, "start": 2868.08, "end": 2878.08, "text": " Of course. So the batch transforms actually didn't end up getting applied because", "tokens": [2720, 1164, 13, 407, 264, 15245, 35592, 767, 994, 380, 917, 493, 1242, 6456, 570], "temperature": 0.0, "avg_logprob": -0.13830397605895997, "compression_ratio": 1.0978260869565217, "no_speech_prob": 4.565611106954748e-06}, {"id": 432, "seek": 287808, "start": 2878.08, "end": 2890.08, "text": " we used dot data sets, which doesn't apply batch transforms. So we would need to now apply them here. So that's quite confusing.", "tokens": [321, 1143, 5893, 1412, 6352, 11, 597, 1177, 380, 3079, 15245, 35592, 13, 407, 321, 576, 643, 281, 586, 3079, 552, 510, 13, 407, 300, 311, 1596, 13181, 13], "temperature": 0.0, "avg_logprob": -0.1605243682861328, "compression_ratio": 1.5064935064935066, "no_speech_prob": 6.240711172722513e-06}, {"id": 433, "seek": 287808, "start": 2890.08, "end": 2900.08, "text": " So presumably, I don't see it here, but I would expect to be able to go batch transforms at this point.", "tokens": [407, 26742, 11, 286, 500, 380, 536, 309, 510, 11, 457, 286, 576, 2066, 281, 312, 1075, 281, 352, 15245, 35592, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.1605243682861328, "compression_ratio": 1.5064935064935066, "no_speech_prob": 6.240711172722513e-06}, {"id": 434, "seek": 290008, "start": 2900.08, "end": 2908.08, "text": " Oh, DL quarks. This is all quite awkward, isn't it?", "tokens": [876, 11, 413, 43, 421, 20851, 13, 639, 307, 439, 1596, 11411, 11, 1943, 380, 309, 30], "temperature": 0.0, "avg_logprob": -0.16346466064453125, "compression_ratio": 1.3032786885245902, "no_speech_prob": 5.86271789870807e-06}, {"id": 435, "seek": 290008, "start": 2908.08, "end": 2919.08, "text": " So data loader keyword arguments equals", "tokens": [407, 1412, 3677, 260, 20428, 12869, 6915], "temperature": 0.0, "avg_logprob": -0.16346466064453125, "compression_ratio": 1.3032786885245902, "no_speech_prob": 5.86271789870807e-06}, {"id": 436, "seek": 290008, "start": 2919.08, "end": 2929.08, "text": " batch. So if we are creating a data loader, a weighted data loader,", "tokens": [15245, 13, 407, 498, 321, 366, 4084, 257, 1412, 3677, 260, 11, 257, 32807, 1412, 3677, 260, 11], "temperature": 0.0, "avg_logprob": -0.16346466064453125, "compression_ratio": 1.3032786885245902, "no_speech_prob": 5.86271789870807e-06}, {"id": 437, "seek": 292908, "start": 2929.08, "end": 2940.08, "text": " you know what would be a good idea would probably be to look at the data block dot data loaders source code to see how that does it.", "tokens": [291, 458, 437, 576, 312, 257, 665, 1558, 576, 1391, 312, 281, 574, 412, 264, 1412, 3461, 5893, 1412, 3677, 433, 4009, 3089, 281, 536, 577, 300, 775, 309, 13], "temperature": 0.0, "avg_logprob": -0.1265876509926536, "compression_ratio": 1.5107913669064748, "no_speech_prob": 1.8923752577393316e-05}, {"id": 438, "seek": 292908, "start": 2940.08, "end": 2951.08, "text": " Data sets dot data loaders. Here we go. After underscore batch is what it is.", "tokens": [11888, 6352, 5893, 1412, 3677, 433, 13, 1692, 321, 352, 13, 2381, 37556, 15245, 307, 437, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1265876509926536, "compression_ratio": 1.5107913669064748, "no_speech_prob": 1.8923752577393316e-05}, {"id": 439, "seek": 295108, "start": 2951.08, "end": 2968.08, "text": " After underscore batch.", "tokens": [2381, 37556, 15245, 13], "temperature": 0.0, "avg_logprob": -0.23399007320404053, "compression_ratio": 0.7419354838709677, "no_speech_prob": 3.94268827221822e-05}, {"id": 440, "seek": 296808, "start": 2968.08, "end": 2990.08, "text": " OK, that's not it. Let's see.", "tokens": [2264, 11, 300, 311, 406, 309, 13, 961, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.11702781518300374, "compression_ratio": 0.8529411764705882, "no_speech_prob": 5.422015419753734e-06}, {"id": 441, "seek": 299008, "start": 2990.08, "end": 2999.08, "text": " OK, it's calling dot data loaders, passing in the keyword arguments and", "tokens": [2264, 11, 309, 311, 5141, 5893, 1412, 3677, 433, 11, 8437, 294, 264, 20428, 12869, 293], "temperature": 0.0, "avg_logprob": -0.13060929434640067, "compression_ratio": 1.2448979591836735, "no_speech_prob": 8.5292822404881e-06}, {"id": 442, "seek": 299008, "start": 2999.08, "end": 3005.08, "text": " OK, dot data loaders does not call it after batch.", "tokens": [2264, 11, 5893, 1412, 3677, 433, 775, 406, 818, 309, 934, 15245, 13], "temperature": 0.0, "avg_logprob": -0.13060929434640067, "compression_ratio": 1.2448979591836735, "no_speech_prob": 8.5292822404881e-06}, {"id": 443, "seek": 300508, "start": 3005.08, "end": 3021.08, "text": " Dot data loaders.", "tokens": [38753, 1412, 3677, 433, 13], "temperature": 0.0, "avg_logprob": -0.2950107786390517, "compression_ratio": 0.68, "no_speech_prob": 0.0002958355180453509}, {"id": 444, "seek": 302108, "start": 3021.08, "end": 3035.08, "text": " Well.", "tokens": [1042, 13], "temperature": 0.0, "avg_logprob": -0.5962514877319336, "compression_ratio": 0.38461538461538464, "no_speech_prob": 1.2804734069504775e-05}, {"id": 445, "seek": 303508, "start": 3035.08, "end": 3052.08, "text": " Data sets. Yeah, so OK, so data sets dot data loaders is this thing here and that doesn't call it after underscore batch. So.", "tokens": [11888, 6352, 13, 865, 11, 370, 2264, 11, 370, 1412, 6352, 5893, 1412, 3677, 433, 307, 341, 551, 510, 293, 300, 1177, 380, 818, 309, 934, 37556, 15245, 13, 407, 13], "temperature": 0.0, "avg_logprob": -0.2707078661237444, "compression_ratio": 1.2376237623762376, "no_speech_prob": 1.844763801273075e-06}, {"id": 446, "seek": 305208, "start": 3052.08, "end": 3065.08, "text": " Oh, and I think I know why. I think that's because when we looked the other day at data block,", "tokens": [876, 11, 293, 286, 519, 286, 458, 983, 13, 286, 519, 300, 311, 570, 562, 321, 2956, 264, 661, 786, 412, 1412, 3461, 11], "temperature": 0.0, "avg_logprob": -0.17061835644291898, "compression_ratio": 1.3445378151260505, "no_speech_prob": 3.6687067677121377e-06}, {"id": 447, "seek": 305208, "start": 3065.08, "end": 3071.08, "text": " we noticed that it like adds.", "tokens": [321, 5694, 300, 309, 411, 10860, 13], "temperature": 0.0, "avg_logprob": -0.17061835644291898, "compression_ratio": 1.3445378151260505, "no_speech_prob": 3.6687067677121377e-06}, {"id": 448, "seek": 305208, "start": 3071.08, "end": 3080.08, "text": " Oh, yes, yes, yes. The image block.", "tokens": [876, 11, 2086, 11, 2086, 11, 2086, 13, 440, 3256, 3461, 13], "temperature": 0.0, "avg_logprob": -0.17061835644291898, "compression_ratio": 1.3445378151260505, "no_speech_prob": 3.6687067677121377e-06}, {"id": 449, "seek": 308008, "start": 3080.08, "end": 3089.08, "text": " That adds into float tensor as a batch transform.", "tokens": [663, 10860, 666, 15706, 40863, 382, 257, 15245, 4088, 13], "temperature": 0.0, "avg_logprob": -0.14106797255002534, "compression_ratio": 1.1153846153846154, "no_speech_prob": 8.579195309721399e-07}, {"id": 450, "seek": 308008, "start": 3089.08, "end": 3103.08, "text": " So we might need to add that as well.", "tokens": [407, 321, 1062, 643, 281, 909, 300, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.14106797255002534, "compression_ratio": 1.1153846153846154, "no_speech_prob": 8.579195309721399e-07}, {"id": 451, "seek": 310308, "start": 3103.08, "end": 3112.08, "text": " OK. So it's getting PIL images.", "tokens": [2264, 13, 407, 309, 311, 1242, 430, 4620, 5267, 13], "temperature": 0.0, "avg_logprob": -0.25306871959141325, "compression_ratio": 0.7948717948717948, "no_speech_prob": 3.6118894968240056e-06}, {"id": 452, "seek": 311208, "start": 3112.08, "end": 3133.08, "text": " So the fact is getting PIL images means it's never being converted to a tensor.", "tokens": [407, 264, 1186, 307, 1242, 430, 4620, 5267, 1355, 309, 311, 1128, 885, 16424, 281, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.0894326079975475, "compression_ratio": 1.025974025974026, "no_speech_prob": 5.368697770791186e-07}, {"id": 453, "seek": 313308, "start": 3133.08, "end": 3142.08, "text": " So data block. I really think there's something that calls to tensor or something at some point.", "tokens": [407, 1412, 3461, 13, 286, 534, 519, 456, 311, 746, 300, 5498, 281, 40863, 420, 746, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.09510549969143338, "compression_ratio": 1.328, "no_speech_prob": 1.7603024389245547e-06}, {"id": 454, "seek": 313308, "start": 3142.08, "end": 3146.08, "text": " Oh, there is here. Item transforms.", "tokens": [876, 11, 456, 307, 510, 13, 31066, 35592, 13], "temperature": 0.0, "avg_logprob": -0.09510549969143338, "compression_ratio": 1.328, "no_speech_prob": 1.7603024389245547e-06}, {"id": 455, "seek": 313308, "start": 3146.08, "end": 3150.08, "text": " So why isn't that getting called?", "tokens": [407, 983, 1943, 380, 300, 1242, 1219, 30], "temperature": 0.0, "avg_logprob": -0.09510549969143338, "compression_ratio": 1.328, "no_speech_prob": 1.7603024389245547e-06}, {"id": 456, "seek": 315008, "start": 3150.08, "end": 3163.08, "text": " Because. Oh, item transforms, I think are also done at the data loader stage.", "tokens": [1436, 13, 876, 11, 3174, 35592, 11, 286, 519, 366, 611, 1096, 412, 264, 1412, 3677, 260, 3233, 13], "temperature": 0.0, "avg_logprob": -0.2056940697334908, "compression_ratio": 1.3406593406593406, "no_speech_prob": 3.3930800782400183e-06}, {"id": 457, "seek": 315008, "start": 3163.08, "end": 3167.08, "text": " Item transforms. Let's see.", "tokens": [31066, 35592, 13, 961, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.2056940697334908, "compression_ratio": 1.3406593406593406, "no_speech_prob": 3.3930800782400183e-06}, {"id": 458, "seek": 315008, "start": 3167.08, "end": 3174.08, "text": " Item transforms.", "tokens": [31066, 35592, 13], "temperature": 0.0, "avg_logprob": -0.2056940697334908, "compression_ratio": 1.3406593406593406, "no_speech_prob": 3.3930800782400183e-06}, {"id": 459, "seek": 317408, "start": 3174.08, "end": 3186.08, "text": " Yes, that's also done. OK, so basically using data sets instead of data loaders is quite awkward.", "tokens": [1079, 11, 300, 311, 611, 1096, 13, 2264, 11, 370, 1936, 1228, 1412, 6352, 2602, 295, 1412, 3677, 433, 307, 1596, 11411, 13], "temperature": 0.0, "avg_logprob": -0.13556400697622725, "compression_ratio": 1.4782608695652173, "no_speech_prob": 4.936841833114158e-06}, {"id": 460, "seek": 317408, "start": 3186.08, "end": 3192.08, "text": " I think we need to fix this in fast AI because.", "tokens": [286, 519, 321, 643, 281, 3191, 341, 294, 2370, 7318, 570, 13], "temperature": 0.0, "avg_logprob": -0.13556400697622725, "compression_ratio": 1.4782608695652173, "no_speech_prob": 4.936841833114158e-06}, {"id": 461, "seek": 317408, "start": 3192.08, "end": 3202.08, "text": " Yes, it's not being done for us, but you know what we could do actually is what we could do.", "tokens": [1079, 11, 309, 311, 406, 885, 1096, 337, 505, 11, 457, 291, 458, 437, 321, 727, 360, 767, 307, 437, 321, 727, 360, 13], "temperature": 0.0, "avg_logprob": -0.13556400697622725, "compression_ratio": 1.4782608695652173, "no_speech_prob": 4.936841833114158e-06}, {"id": 462, "seek": 320208, "start": 3202.08, "end": 3209.08, "text": " Is the same thing that.", "tokens": [1119, 264, 912, 551, 300, 13], "temperature": 0.0, "avg_logprob": -0.15294474495781793, "compression_ratio": 1.393162393162393, "no_speech_prob": 1.5445351891685277e-05}, {"id": 463, "seek": 320208, "start": 3209.08, "end": 3216.08, "text": " Data block does, which is just to use these self dot item transforms and self dot batch transforms.", "tokens": [11888, 3461, 775, 11, 597, 307, 445, 281, 764, 613, 2698, 5893, 3174, 35592, 293, 2698, 5893, 15245, 35592, 13], "temperature": 0.0, "avg_logprob": -0.15294474495781793, "compression_ratio": 1.393162393162393, "no_speech_prob": 1.5445351891685277e-05}, {"id": 464, "seek": 320208, "start": 3216.08, "end": 3223.08, "text": " So if we have a look at our data block.", "tokens": [407, 498, 321, 362, 257, 574, 412, 527, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.15294474495781793, "compression_ratio": 1.393162393162393, "no_speech_prob": 1.5445351891685277e-05}, {"id": 465, "seek": 322308, "start": 3223.08, "end": 3232.08, "text": " Oops, Daisy. OK, I think this is all going to become clear in a moment.", "tokens": [21726, 11, 37472, 13, 2264, 11, 286, 519, 341, 307, 439, 516, 281, 1813, 1850, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.1543836190666951, "compression_ratio": 1.5575757575757576, "no_speech_prob": 4.222760708216811e-06}, {"id": 466, "seek": 322308, "start": 3232.08, "end": 3237.08, "text": " Hopefully it's got these item transforms in it.", "tokens": [10429, 309, 311, 658, 613, 3174, 35592, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.1543836190666951, "compression_ratio": 1.5575757575757576, "no_speech_prob": 4.222760708216811e-06}, {"id": 467, "seek": 322308, "start": 3237.08, "end": 3242.08, "text": " And it's got these batch transforms in it.", "tokens": [400, 309, 311, 658, 613, 15245, 35592, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.1543836190666951, "compression_ratio": 1.5575757575757576, "no_speech_prob": 4.222760708216811e-06}, {"id": 468, "seek": 322308, "start": 3242.08, "end": 3250.08, "text": " And so what we actually want to do when we create our data loaders is say that after batch is.", "tokens": [400, 370, 437, 321, 767, 528, 281, 360, 562, 321, 1884, 527, 1412, 3677, 433, 307, 584, 300, 934, 15245, 307, 13], "temperature": 0.0, "avg_logprob": -0.1543836190666951, "compression_ratio": 1.5575757575757576, "no_speech_prob": 4.222760708216811e-06}, {"id": 469, "seek": 325008, "start": 3250.08, "end": 3258.08, "text": " The data block says the batch transforms are and after item.", "tokens": [440, 1412, 3461, 1619, 264, 15245, 35592, 366, 293, 934, 3174, 13], "temperature": 0.0, "avg_logprob": -0.08085371696785705, "compression_ratio": 1.5739644970414202, "no_speech_prob": 1.54458248289302e-05}, {"id": 470, "seek": 325008, "start": 3258.08, "end": 3262.08, "text": " Is whatever the data block.", "tokens": [1119, 2035, 264, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.08085371696785705, "compression_ratio": 1.5739644970414202, "no_speech_prob": 1.54458248289302e-05}, {"id": 471, "seek": 325008, "start": 3262.08, "end": 3266.08, "text": " Says the item transforms are.", "tokens": [36780, 264, 3174, 35592, 366, 13], "temperature": 0.0, "avg_logprob": -0.08085371696785705, "compression_ratio": 1.5739644970414202, "no_speech_prob": 1.54458248289302e-05}, {"id": 472, "seek": 325008, "start": 3266.08, "end": 3268.08, "text": " OK, that's ugly.", "tokens": [2264, 11, 300, 311, 12246, 13], "temperature": 0.0, "avg_logprob": -0.08085371696785705, "compression_ratio": 1.5739644970414202, "no_speech_prob": 1.54458248289302e-05}, {"id": 473, "seek": 325008, "start": 3268.08, "end": 3271.08, "text": " So that's something I think we should try to make easier.", "tokens": [407, 300, 311, 746, 286, 519, 321, 820, 853, 281, 652, 3571, 13], "temperature": 0.0, "avg_logprob": -0.08085371696785705, "compression_ratio": 1.5739644970414202, "no_speech_prob": 1.54458248289302e-05}, {"id": 474, "seek": 325008, "start": 3271.08, "end": 3279.08, "text": " So hopefully by the time people see this video, this will all be easier.", "tokens": [407, 4696, 538, 264, 565, 561, 536, 341, 960, 11, 341, 486, 439, 312, 3571, 13], "temperature": 0.0, "avg_logprob": -0.08085371696785705, "compression_ratio": 1.5739644970414202, "no_speech_prob": 1.54458248289302e-05}, {"id": 475, "seek": 327908, "start": 3279.08, "end": 3290.08, "text": " So there's some data loaders.", "tokens": [407, 456, 311, 512, 1412, 3677, 433, 13], "temperature": 0.0, "avg_logprob": -0.1322005271911621, "compression_ratio": 0.921875, "no_speech_prob": 1.8921915398095734e-05}, {"id": 476, "seek": 327908, "start": 3290.08, "end": 3297.08, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1322005271911621, "compression_ratio": 0.921875, "no_speech_prob": 1.8921915398095734e-05}, {"id": 477, "seek": 327908, "start": 3297.08, "end": 3301.08, "text": " So my guess is that here.", "tokens": [407, 452, 2041, 307, 300, 510, 13], "temperature": 0.0, "avg_logprob": -0.1322005271911621, "compression_ratio": 0.921875, "no_speech_prob": 1.8921915398095734e-05}, {"id": 478, "seek": 330108, "start": 3301.08, "end": 3312.08, "text": " Is we've given the wrong number of weights. I'm guessing this needs to be weights just for the training set. So the way I would check this is I would type percent debug and that puts us into the.", "tokens": [1119, 321, 600, 2212, 264, 2085, 1230, 295, 17443, 13, 286, 478, 17939, 341, 2203, 281, 312, 17443, 445, 337, 264, 3097, 992, 13, 407, 264, 636, 286, 576, 1520, 341, 307, 286, 576, 2010, 3043, 24083, 293, 300, 8137, 505, 666, 264, 13], "temperature": 0.0, "avg_logprob": -0.09601802411286728, "compression_ratio": 1.5681818181818181, "no_speech_prob": 1.2606185009644832e-05}, {"id": 479, "seek": 330108, "start": 3312.08, "end": 3317.08, "text": " Python debugger and the Python debugger is a very, very cool thing.", "tokens": [15329, 24083, 1321, 293, 264, 15329, 24083, 1321, 307, 257, 588, 11, 588, 1627, 551, 13], "temperature": 0.0, "avg_logprob": -0.09601802411286728, "compression_ratio": 1.5681818181818181, "no_speech_prob": 1.2606185009644832e-05}, {"id": 480, "seek": 330108, "start": 3317.08, "end": 3320.08, "text": " It's called PDB.", "tokens": [467, 311, 1219, 10464, 33, 13], "temperature": 0.0, "avg_logprob": -0.09601802411286728, "compression_ratio": 1.5681818181818181, "no_speech_prob": 1.2606185009644832e-05}, {"id": 481, "seek": 330108, "start": 3320.08, "end": 3327.08, "text": " And definitely want to know how to use it. H gives you the help.", "tokens": [400, 2138, 528, 281, 458, 577, 281, 764, 309, 13, 389, 2709, 291, 264, 854, 13], "temperature": 0.0, "avg_logprob": -0.09601802411286728, "compression_ratio": 1.5681818181818181, "no_speech_prob": 1.2606185009644832e-05}, {"id": 482, "seek": 332708, "start": 3327.08, "end": 3334.08, "text": " And.", "tokens": [400, 13], "temperature": 0.0, "avg_logprob": -0.1274326415289016, "compression_ratio": 1.4538461538461538, "no_speech_prob": 1.568871630297508e-05}, {"id": 483, "seek": 332708, "start": 3334.08, "end": 3340.08, "text": " W shows you where in the stack you are so you can see this is the line of code I'm about to run.", "tokens": [343, 3110, 291, 689, 294, 264, 8630, 291, 366, 370, 291, 393, 536, 341, 307, 264, 1622, 295, 3089, 286, 478, 466, 281, 1190, 13], "temperature": 0.0, "avg_logprob": -0.1274326415289016, "compression_ratio": 1.4538461538461538, "no_speech_prob": 1.568871630297508e-05}, {"id": 484, "seek": 332708, "start": 3340.08, "end": 3345.08, "text": " And so I can print out with P self dot N.", "tokens": [400, 370, 286, 393, 4482, 484, 365, 430, 2698, 5893, 426, 13], "temperature": 0.0, "avg_logprob": -0.1274326415289016, "compression_ratio": 1.4538461538461538, "no_speech_prob": 1.568871630297508e-05}, {"id": 485, "seek": 332708, "start": 3345.08, "end": 3348.08, "text": " And I can print out with P.", "tokens": [400, 286, 393, 4482, 484, 365, 430, 13], "temperature": 0.0, "avg_logprob": -0.1274326415289016, "compression_ratio": 1.4538461538461538, "no_speech_prob": 1.568871630297508e-05}, {"id": 486, "seek": 332708, "start": 3348.08, "end": 3351.08, "text": " Self dot weights.", "tokens": [16348, 5893, 17443, 13], "temperature": 0.0, "avg_logprob": -0.1274326415289016, "compression_ratio": 1.4538461538461538, "no_speech_prob": 1.568871630297508e-05}, {"id": 487, "seek": 335108, "start": 3351.08, "end": 3358.08, "text": " And I can you don't actually normally need to even say P. It just assumes that so I can just say self dot weights dot shape.", "tokens": [400, 286, 393, 291, 500, 380, 767, 5646, 643, 281, 754, 584, 430, 13, 467, 445, 37808, 300, 370, 286, 393, 445, 584, 2698, 5893, 17443, 5893, 3909, 13], "temperature": 0.0, "avg_logprob": -0.1528504381897629, "compression_ratio": 1.5662100456621004, "no_speech_prob": 8.26727682579076e-06}, {"id": 488, "seek": 335108, "start": 3358.08, "end": 3368.08, "text": " And so there's the problem. So it's expecting 8,326 weights, not 10,407 weights.", "tokens": [400, 370, 456, 311, 264, 1154, 13, 407, 309, 311, 9650, 1649, 11, 18, 10880, 17443, 11, 406, 1266, 11, 5254, 22, 17443, 13], "temperature": 0.0, "avg_logprob": -0.1528504381897629, "compression_ratio": 1.5662100456621004, "no_speech_prob": 8.26727682579076e-06}, {"id": 489, "seek": 335108, "start": 3368.08, "end": 3375.08, "text": " And so that's because and you know, to be fair, the documentation warned us about this.", "tokens": [400, 370, 300, 311, 570, 293, 291, 458, 11, 281, 312, 3143, 11, 264, 14333, 21284, 505, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.1528504381897629, "compression_ratio": 1.5662100456621004, "no_speech_prob": 8.26727682579076e-06}, {"id": 490, "seek": 335108, "start": 3375.08, "end": 3379.08, "text": " It's expecting weights just for the training set.", "tokens": [467, 311, 9650, 17443, 445, 337, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.1528504381897629, "compression_ratio": 1.5662100456621004, "no_speech_prob": 8.26727682579076e-06}, {"id": 491, "seek": 337908, "start": 3379.08, "end": 3387.08, "text": " Not for both training and validation sets.", "tokens": [1726, 337, 1293, 3097, 293, 24071, 6352, 13], "temperature": 0.0, "avg_logprob": -0.18825586982395337, "compression_ratio": 1.3384615384615384, "no_speech_prob": 2.282556852151174e-05}, {"id": 492, "seek": 337908, "start": 3387.08, "end": 3397.08, "text": " Okay, no problem.", "tokens": [1033, 11, 572, 1154, 13], "temperature": 0.0, "avg_logprob": -0.18825586982395337, "compression_ratio": 1.3384615384615384, "no_speech_prob": 2.282556852151174e-05}, {"id": 493, "seek": 337908, "start": 3397.08, "end": 3405.08, "text": " Did you predetermine your split by adding another column in you in the same data set that you put the weights in?", "tokens": [2589, 291, 3852, 35344, 533, 428, 7472, 538, 5127, 1071, 7738, 294, 291, 294, 264, 912, 1412, 992, 300, 291, 829, 264, 17443, 294, 30], "temperature": 0.0, "avg_logprob": -0.18825586982395337, "compression_ratio": 1.3384615384615384, "no_speech_prob": 2.282556852151174e-05}, {"id": 494, "seek": 340508, "start": 3405.08, "end": 3412.08, "text": " Yeah, I could do that. But actually, and somebody actually asked about this the other day.", "tokens": [865, 11, 286, 727, 360, 300, 13, 583, 767, 11, 293, 2618, 767, 2351, 466, 341, 264, 661, 786, 13], "temperature": 0.0, "avg_logprob": -0.11478325358608313, "compression_ratio": 1.3918918918918919, "no_speech_prob": 4.029279807582498e-06}, {"id": 495, "seek": 340508, "start": 3412.08, "end": 3415.08, "text": " This is our training set.", "tokens": [639, 307, 527, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.11478325358608313, "compression_ratio": 1.3918918918918919, "no_speech_prob": 4.029279807582498e-06}, {"id": 496, "seek": 340508, "start": 3415.08, "end": 3421.08, "text": " And items tells you the file names actually.", "tokens": [400, 4754, 5112, 291, 264, 3991, 5288, 767, 13], "temperature": 0.0, "avg_logprob": -0.11478325358608313, "compression_ratio": 1.3918918918918919, "no_speech_prob": 4.029279807582498e-06}, {"id": 497, "seek": 340508, "start": 3421.08, "end": 3430.08, "text": " So we just need to look at each of these up.", "tokens": [407, 321, 445, 643, 281, 574, 412, 1184, 295, 613, 493, 13], "temperature": 0.0, "avg_logprob": -0.11478325358608313, "compression_ratio": 1.3918918918918919, "no_speech_prob": 4.029279807582498e-06}, {"id": 498, "seek": 343008, "start": 3430.08, "end": 3435.08, "text": " In the data frame.", "tokens": [682, 264, 1412, 3920, 13], "temperature": 0.0, "avg_logprob": -0.08629879643840174, "compression_ratio": 1.4233576642335766, "no_speech_prob": 6.048828254279215e-06}, {"id": 499, "seek": 343008, "start": 3435.08, "end": 3444.08, "text": " So what we could do is we could say weights equals.", "tokens": [407, 437, 321, 727, 360, 307, 321, 727, 584, 17443, 6915, 13], "temperature": 0.0, "avg_logprob": -0.08629879643840174, "compression_ratio": 1.4233576642335766, "no_speech_prob": 6.048828254279215e-06}, {"id": 500, "seek": 343008, "start": 3444.08, "end": 3449.08, "text": " And so we could go through each of those. So that's going to be all of our files.", "tokens": [400, 370, 321, 727, 352, 807, 1184, 295, 729, 13, 407, 300, 311, 516, 281, 312, 439, 295, 527, 7098, 13], "temperature": 0.0, "avg_logprob": -0.08629879643840174, "compression_ratio": 1.4233576642335766, "no_speech_prob": 6.048828254279215e-06}, {"id": 501, "seek": 343008, "start": 3449.08, "end": 3454.08, "text": " And then we need to.", "tokens": [400, 550, 321, 643, 281, 13], "temperature": 0.0, "avg_logprob": -0.08629879643840174, "compression_ratio": 1.4233576642335766, "no_speech_prob": 6.048828254279215e-06}, {"id": 502, "seek": 343008, "start": 3454.08, "end": 3457.08, "text": " Look up the image ID.", "tokens": [2053, 493, 264, 3256, 7348, 13], "temperature": 0.0, "avg_logprob": -0.08629879643840174, "compression_ratio": 1.4233576642335766, "no_speech_prob": 6.048828254279215e-06}, {"id": 503, "seek": 345708, "start": 3457.08, "end": 3466.08, "text": " And, you know, I think something you could possibly do here is", "tokens": [400, 11, 291, 458, 11, 286, 519, 746, 291, 727, 6264, 360, 510, 307], "temperature": 0.0, "avg_logprob": -0.19335126876831055, "compression_ratio": 1.1818181818181819, "no_speech_prob": 7.071755590004614e-06}, {"id": 504, "seek": 345708, "start": 3466.08, "end": 3470.08, "text": " set the index", "tokens": [992, 264, 8186], "temperature": 0.0, "avg_logprob": -0.19335126876831055, "compression_ratio": 1.1818181818181819, "no_speech_prob": 7.071755590004614e-06}, {"id": 505, "seek": 345708, "start": 3470.08, "end": 3476.08, "text": " to image ID.", "tokens": [281, 3256, 7348, 13], "temperature": 0.0, "avg_logprob": -0.19335126876831055, "compression_ratio": 1.1818181818181819, "no_speech_prob": 7.071755590004614e-06}, {"id": 506, "seek": 345708, "start": 3476.08, "end": 3479.08, "text": " Right, which is this kind of pandas idea.", "tokens": [1779, 11, 597, 307, 341, 733, 295, 4565, 296, 1558, 13], "temperature": 0.0, "avg_logprob": -0.19335126876831055, "compression_ratio": 1.1818181818181819, "no_speech_prob": 7.071755590004614e-06}, {"id": 507, "seek": 345708, "start": 3479.08, "end": 3482.08, "text": " WTF equals.", "tokens": [343, 20527, 6915, 13], "temperature": 0.0, "avg_logprob": -0.19335126876831055, "compression_ratio": 1.1818181818181819, "no_speech_prob": 7.071755590004614e-06}, {"id": 508, "seek": 348208, "start": 3482.08, "end": 3490.08, "text": " And then we say.", "tokens": [400, 550, 321, 584, 13], "temperature": 0.4, "avg_logprob": -0.3684043066842215, "compression_ratio": 0.9753086419753086, "no_speech_prob": 6.8539588937710505e-06}, {"id": 509, "seek": 348208, "start": 3490.08, "end": 3497.08, "text": " location of one, one dot JPEG.", "tokens": [4914, 295, 472, 11, 472, 5893, 508, 5208, 38, 13], "temperature": 0.4, "avg_logprob": -0.3684043066842215, "compression_ratio": 0.9753086419753086, "no_speech_prob": 6.8539588937710505e-06}, {"id": 510, "seek": 348208, "start": 3497.08, "end": 3501.08, "text": " Oh, there it is.", "tokens": [876, 11, 456, 309, 307, 13], "temperature": 0.4, "avg_logprob": -0.3684043066842215, "compression_ratio": 0.9753086419753086, "no_speech_prob": 6.8539588937710505e-06}, {"id": 511, "seek": 348208, "start": 3501.08, "end": 3507.08, "text": " For label why.", "tokens": [1171, 7645, 983, 13], "temperature": 0.4, "avg_logprob": -0.3684043066842215, "compression_ratio": 0.9753086419753086, "no_speech_prob": 6.8539588937710505e-06}, {"id": 512, "seek": 350708, "start": 3507.08, "end": 3513.08, "text": " There it is. So", "tokens": [821, 309, 307, 13, 407], "temperature": 0.0, "avg_logprob": -0.1951147470718775, "compression_ratio": 1.1411764705882352, "no_speech_prob": 6.540268259414006e-06}, {"id": 513, "seek": 350708, "start": 3513.08, "end": 3518.08, "text": " if we copy that over to here", "tokens": [498, 321, 5055, 300, 670, 281, 510], "temperature": 0.0, "avg_logprob": -0.1951147470718775, "compression_ratio": 1.1411764705882352, "no_speech_prob": 6.540268259414006e-06}, {"id": 514, "seek": 350708, "start": 3518.08, "end": 3527.08, "text": " and replace that with O.", "tokens": [293, 7406, 300, 365, 422, 13], "temperature": 0.0, "avg_logprob": -0.1951147470718775, "compression_ratio": 1.1411764705882352, "no_speech_prob": 6.540268259414006e-06}, {"id": 515, "seek": 350708, "start": 3527.08, "end": 3531.08, "text": " Oh, dot name.", "tokens": [876, 11, 5893, 1315, 13], "temperature": 0.0, "avg_logprob": -0.1951147470718775, "compression_ratio": 1.1411764705882352, "no_speech_prob": 6.540268259414006e-06}, {"id": 516, "seek": 350708, "start": 3531.08, "end": 3534.08, "text": " Look at that.", "tokens": [2053, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.1951147470718775, "compression_ratio": 1.1411764705882352, "no_speech_prob": 6.540268259414006e-06}, {"id": 517, "seek": 353408, "start": 3534.08, "end": 3542.08, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.13269005026868594, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.9832037651212886e-05}, {"id": 518, "seek": 353408, "start": 3542.08, "end": 3545.08, "text": " OK, so we don't want to sort values. We want to set index.", "tokens": [2264, 11, 370, 321, 500, 380, 528, 281, 1333, 4190, 13, 492, 528, 281, 992, 8186, 13], "temperature": 0.0, "avg_logprob": -0.13269005026868594, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.9832037651212886e-05}, {"id": 519, "seek": 353408, "start": 3545.08, "end": 3550.08, "text": " I should probably take more use, make more use of indices in pandas.", "tokens": [286, 820, 1391, 747, 544, 764, 11, 652, 544, 764, 295, 43840, 294, 4565, 296, 13], "temperature": 0.0, "avg_logprob": -0.13269005026868594, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.9832037651212886e-05}, {"id": 520, "seek": 353408, "start": 3550.08, "end": 3554.08, "text": " I guess I still don't have a great sense in my head of quite how they work.", "tokens": [286, 2041, 286, 920, 500, 380, 362, 257, 869, 2020, 294, 452, 1378, 295, 1596, 577, 436, 589, 13], "temperature": 0.0, "avg_logprob": -0.13269005026868594, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.9832037651212886e-05}, {"id": 521, "seek": 353408, "start": 3554.08, "end": 3556.08, "text": " So I tend to underuse them.", "tokens": [407, 286, 3928, 281, 833, 438, 552, 13], "temperature": 0.0, "avg_logprob": -0.13269005026868594, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.9832037651212886e-05}, {"id": 522, "seek": 353408, "start": 3556.08, "end": 3560.08, "text": " OK, so weights should now be the right length.", "tokens": [2264, 11, 370, 17443, 820, 586, 312, 264, 558, 4641, 13], "temperature": 0.0, "avg_logprob": -0.13269005026868594, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.9832037651212886e-05}, {"id": 523, "seek": 353408, "start": 3560.08, "end": 3562.08, "text": " The training set.", "tokens": [440, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.13269005026868594, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.9832037651212886e-05}, {"id": 524, "seek": 356208, "start": 3562.08, "end": 3570.08, "text": " OK, so now.", "tokens": [2264, 11, 370, 586, 13], "temperature": 0.0, "avg_logprob": -0.24260054935108533, "compression_ratio": 0.96, "no_speech_prob": 8.13923452369636e-06}, {"id": 525, "seek": 356208, "start": 3570.08, "end": 3573.08, "text": " Now weights here.", "tokens": [823, 17443, 510, 13], "temperature": 0.0, "avg_logprob": -0.24260054935108533, "compression_ratio": 0.96, "no_speech_prob": 8.13923452369636e-06}, {"id": 526, "seek": 356208, "start": 3573.08, "end": 3584.08, "text": " It's just weights.", "tokens": [467, 311, 445, 17443, 13], "temperature": 0.0, "avg_logprob": -0.24260054935108533, "compression_ratio": 0.96, "no_speech_prob": 8.13923452369636e-06}, {"id": 527, "seek": 358408, "start": 3584.08, "end": 3594.08, "text": " Cool. And then what I'd be inclined to do is to do a few more.", "tokens": [8561, 13, 400, 550, 437, 286, 1116, 312, 28173, 281, 360, 307, 281, 360, 257, 1326, 544, 13], "temperature": 0.0, "avg_logprob": -0.07586358814704709, "compression_ratio": 1.276190476190476, "no_speech_prob": 5.093439085612772e-06}, {"id": 528, "seek": 358408, "start": 3594.08, "end": 3607.08, "text": " And what I find encouraging here is that we've got a lot of bacterials.", "tokens": [400, 437, 286, 915, 14580, 510, 307, 300, 321, 600, 658, 257, 688, 295, 9755, 12356, 13], "temperature": 0.0, "avg_logprob": -0.07586358814704709, "compression_ratio": 1.276190476190476, "no_speech_prob": 5.093439085612772e-06}, {"id": 529, "seek": 360708, "start": 3607.08, "end": 3620.08, "text": " Ground spot. Yeah, you know, this seems like a good mix, right?", "tokens": [28371, 4008, 13, 865, 11, 291, 458, 11, 341, 2544, 411, 257, 665, 2890, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.16971852438790458, "compression_ratio": 1.076086956521739, "no_speech_prob": 7.1828753789304756e-06}, {"id": 530, "seek": 360708, "start": 3620.08, "end": 3622.08, "text": " So then.", "tokens": [407, 550, 13], "temperature": 0.0, "avg_logprob": -0.16971852438790458, "compression_ratio": 1.076086956521739, "no_speech_prob": 7.1828753789304756e-06}, {"id": 531, "seek": 360708, "start": 3622.08, "end": 3632.08, "text": " We should just be able to.", "tokens": [492, 820, 445, 312, 1075, 281, 13], "temperature": 0.0, "avg_logprob": -0.16971852438790458, "compression_ratio": 1.076086956521739, "no_speech_prob": 7.1828753789304756e-06}, {"id": 532, "seek": 363208, "start": 3632.08, "end": 3637.08, "text": " Pass those to our learner.", "tokens": [10319, 729, 281, 527, 33347, 13], "temperature": 0.0, "avg_logprob": -0.1277926518366887, "compression_ratio": 1.385786802030457, "no_speech_prob": 2.212216168118175e-05}, {"id": 533, "seek": 363208, "start": 3637.08, "end": 3641.08, "text": " Find June for five.", "tokens": [11809, 6928, 337, 1732, 13], "temperature": 0.0, "avg_logprob": -0.1277926518366887, "compression_ratio": 1.385786802030457, "no_speech_prob": 2.212216168118175e-05}, {"id": 534, "seek": 363208, "start": 3641.08, "end": 3644.08, "text": " Epochs.", "tokens": [462, 2259, 28346, 13], "temperature": 0.0, "avg_logprob": -0.1277926518366887, "compression_ratio": 1.385786802030457, "no_speech_prob": 2.212216168118175e-05}, {"id": 535, "seek": 363208, "start": 3644.08, "end": 3647.08, "text": " All right, sorry, that was a bit more awkward than I would have liked", "tokens": [1057, 558, 11, 2597, 11, 300, 390, 257, 857, 544, 11411, 813, 286, 576, 362, 4501], "temperature": 0.0, "avg_logprob": -0.1277926518366887, "compression_ratio": 1.385786802030457, "no_speech_prob": 2.212216168118175e-05}, {"id": 536, "seek": 363208, "start": 3647.08, "end": 3652.08, "text": " and definitely used a whole bunch of concepts which we haven't.", "tokens": [293, 2138, 1143, 257, 1379, 3840, 295, 10392, 597, 321, 2378, 380, 13], "temperature": 0.0, "avg_logprob": -0.1277926518366887, "compression_ratio": 1.385786802030457, "no_speech_prob": 2.212216168118175e-05}, {"id": 537, "seek": 363208, "start": 3652.08, "end": 3655.08, "text": " Covered before.", "tokens": [19106, 292, 949, 13], "temperature": 0.0, "avg_logprob": -0.1277926518366887, "compression_ratio": 1.385786802030457, "no_speech_prob": 2.212216168118175e-05}, {"id": 538, "seek": 363208, "start": 3655.08, "end": 3660.08, "text": " So don't worry if you're feeling lost about the implementation here.", "tokens": [407, 500, 380, 3292, 498, 291, 434, 2633, 2731, 466, 264, 11420, 510, 13], "temperature": 0.0, "avg_logprob": -0.1277926518366887, "compression_ratio": 1.385786802030457, "no_speech_prob": 2.212216168118175e-05}, {"id": 539, "seek": 366008, "start": 3660.08, "end": 3666.08, "text": " Basically, Jeremy. Yeah, just about the have the sampling works.", "tokens": [8537, 11, 17809, 13, 865, 11, 445, 466, 264, 362, 264, 21179, 1985, 13], "temperature": 0.0, "avg_logprob": -0.23843602931245844, "compression_ratio": 1.6093023255813954, "no_speech_prob": 2.045815381279681e-05}, {"id": 540, "seek": 366008, "start": 3666.08, "end": 3671.08, "text": " Yeah, we've got weights and that's creating.", "tokens": [865, 11, 321, 600, 658, 17443, 293, 300, 311, 4084, 13], "temperature": 0.0, "avg_logprob": -0.23843602931245844, "compression_ratio": 1.6093023255813954, "no_speech_prob": 2.045815381279681e-05}, {"id": 541, "seek": 366008, "start": 3671.08, "end": 3674.08, "text": " How is that actually sampled from the training set?", "tokens": [1012, 307, 300, 767, 3247, 15551, 490, 264, 3097, 992, 30], "temperature": 0.0, "avg_logprob": -0.23843602931245844, "compression_ratio": 1.6093023255813954, "no_speech_prob": 2.045815381279681e-05}, {"id": 542, "seek": 366008, "start": 3674.08, "end": 3682.08, "text": " Is it do we have an X number of rows or number of images that we're trying to create a sample?", "tokens": [1119, 309, 360, 321, 362, 364, 1783, 1230, 295, 13241, 420, 1230, 295, 5267, 300, 321, 434, 1382, 281, 1884, 257, 6889, 30], "temperature": 0.0, "avg_logprob": -0.23843602931245844, "compression_ratio": 1.6093023255813954, "no_speech_prob": 2.045815381279681e-05}, {"id": 543, "seek": 366008, "start": 3682.08, "end": 3685.08, "text": " Yes, what happens is it creates it creates batches.", "tokens": [1079, 11, 437, 2314, 307, 309, 7829, 309, 7829, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.23843602931245844, "compression_ratio": 1.6093023255813954, "no_speech_prob": 2.045815381279681e-05}, {"id": 544, "seek": 366008, "start": 3685.08, "end": 3688.08, "text": " So each batch will have 64 things in.", "tokens": [407, 1184, 15245, 486, 362, 12145, 721, 294, 13], "temperature": 0.0, "avg_logprob": -0.23843602931245844, "compression_ratio": 1.6093023255813954, "no_speech_prob": 2.045815381279681e-05}, {"id": 545, "seek": 368808, "start": 3688.08, "end": 3693.08, "text": " And so it's going to grab at random 64 images.", "tokens": [400, 370, 309, 311, 516, 281, 4444, 412, 4974, 12145, 5267, 13], "temperature": 0.0, "avg_logprob": -0.1983799267840642, "compression_ratio": 1.5424528301886793, "no_speech_prob": 7.888754225859884e-06}, {"id": 546, "seek": 368808, "start": 3693.08, "end": 3697.08, "text": " But it's a weighted random sample.", "tokens": [583, 309, 311, 257, 32807, 4974, 6889, 13], "temperature": 0.0, "avg_logprob": -0.1983799267840642, "compression_ratio": 1.5424528301886793, "no_speech_prob": 7.888754225859884e-06}, {"id": 547, "seek": 368808, "start": 3697.08, "end": 3700.08, "text": " Each row is weighted by this.", "tokens": [6947, 5386, 307, 32807, 538, 341, 13], "temperature": 0.0, "avg_logprob": -0.1983799267840642, "compression_ratio": 1.5424528301886793, "no_speech_prob": 7.888754225859884e-06}, {"id": 548, "seek": 368808, "start": 3700.08, "end": 3703.08, "text": " This weight.", "tokens": [639, 3364, 13], "temperature": 0.0, "avg_logprob": -0.1983799267840642, "compression_ratio": 1.5424528301886793, "no_speech_prob": 7.888754225859884e-06}, {"id": 549, "seek": 368808, "start": 3703.08, "end": 3707.08, "text": " And so, and it parks not exactly an epoch anymore.", "tokens": [400, 370, 11, 293, 309, 16213, 406, 2293, 364, 30992, 339, 3602, 13], "temperature": 0.0, "avg_logprob": -0.1983799267840642, "compression_ratio": 1.5424528301886793, "no_speech_prob": 7.888754225859884e-06}, {"id": 550, "seek": 368808, "start": 3707.08, "end": 3717.08, "text": " In that it won't necessarily see every image once at a box and a box just equal to the total number of rows in the data set is how many rows I've seen.", "tokens": [682, 300, 309, 1582, 380, 4725, 536, 633, 3256, 1564, 412, 257, 2424, 293, 257, 2424, 445, 2681, 281, 264, 3217, 1230, 295, 13241, 294, 264, 1412, 992, 307, 577, 867, 13241, 286, 600, 1612, 13], "temperature": 0.0, "avg_logprob": -0.1983799267840642, "compression_ratio": 1.5424528301886793, "no_speech_prob": 7.888754225859884e-06}, {"id": 551, "seek": 371708, "start": 3717.08, "end": 3724.08, "text": " But, you know, we'll see a lot of the less common ones multiple times.", "tokens": [583, 11, 291, 458, 11, 321, 603, 536, 257, 688, 295, 264, 1570, 2689, 2306, 3866, 1413, 13], "temperature": 0.0, "avg_logprob": -0.09883836197526488, "compression_ratio": 1.3885714285714286, "no_speech_prob": 5.421954938356066e-06}, {"id": 552, "seek": 371708, "start": 3724.08, "end": 3730.08, "text": " And so there's a definite danger of overfitting.", "tokens": [400, 370, 456, 311, 257, 25131, 4330, 295, 670, 69, 2414, 13], "temperature": 0.0, "avg_logprob": -0.09883836197526488, "compression_ratio": 1.3885714285714286, "no_speech_prob": 5.421954938356066e-06}, {"id": 553, "seek": 371708, "start": 3730.08, "end": 3735.08, "text": " The weighted sampling is not done for the validation set.", "tokens": [440, 32807, 21179, 307, 406, 1096, 337, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.09883836197526488, "compression_ratio": 1.3885714285714286, "no_speech_prob": 5.421954938356066e-06}, {"id": 554, "seek": 371708, "start": 3735.08, "end": 3738.08, "text": " So we should be able to compare these.", "tokens": [407, 321, 820, 312, 1075, 281, 6794, 613, 13], "temperature": 0.0, "avg_logprob": -0.09883836197526488, "compression_ratio": 1.3885714285714286, "no_speech_prob": 5.421954938356066e-06}, {"id": 555, "seek": 371708, "start": 3738.08, "end": 3742.08, "text": " Let's take a look. So 5.6.", "tokens": [961, 311, 747, 257, 574, 13, 407, 1025, 13, 21, 13], "temperature": 0.0, "avg_logprob": -0.09883836197526488, "compression_ratio": 1.3885714285714286, "no_speech_prob": 5.421954938356066e-06}, {"id": 556, "seek": 374208, "start": 3742.08, "end": 3747.08, "text": " This is 4.6. Now, you know, this is expected.", "tokens": [639, 307, 1017, 13, 21, 13, 823, 11, 291, 458, 11, 341, 307, 5176, 13], "temperature": 0.0, "avg_logprob": -0.14705570445341223, "compression_ratio": 1.5369458128078817, "no_speech_prob": 4.565525614452781e-06}, {"id": 557, "seek": 374208, "start": 3747.08, "end": 3752.08, "text": " But where this might be interesting would be like,", "tokens": [583, 689, 341, 1062, 312, 1880, 576, 312, 411, 11], "temperature": 0.0, "avg_logprob": -0.14705570445341223, "compression_ratio": 1.5369458128078817, "no_speech_prob": 4.565525614452781e-06}, {"id": 558, "seek": 374208, "start": 3752.08, "end": 3758.08, "text": " through all of our training, and then maybe at the very end,", "tokens": [807, 439, 295, 527, 3097, 11, 293, 550, 1310, 412, 264, 588, 917, 11], "temperature": 0.0, "avg_logprob": -0.14705570445341223, "compression_ratio": 1.5369458128078817, "no_speech_prob": 4.565525614452781e-06}, {"id": 559, "seek": 374208, "start": 3758.08, "end": 3768.08, "text": " do a few epochs with weighted training, you know, at the point that it's already really good, just to show it a few more examples of the less common ones.", "tokens": [360, 257, 1326, 30992, 28346, 365, 32807, 3097, 11, 291, 458, 11, 412, 264, 935, 300, 309, 311, 1217, 534, 665, 11, 445, 281, 855, 309, 257, 1326, 544, 5110, 295, 264, 1570, 2689, 2306, 13], "temperature": 0.0, "avg_logprob": -0.14705570445341223, "compression_ratio": 1.5369458128078817, "no_speech_prob": 4.565525614452781e-06}, {"id": 560, "seek": 376808, "start": 3768.08, "end": 3773.08, "text": " Or just train it for longer with more data augmentation.", "tokens": [1610, 445, 3847, 309, 337, 2854, 365, 544, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.08154667460400125, "compression_ratio": 1.5646551724137931, "no_speech_prob": 1.4059765817364678e-05}, {"id": 561, "seek": 376808, "start": 3773.08, "end": 3787.08, "text": " But yeah, I mean, you know, you would expect the error rate at this point to be worse, I think, because the most common types, which it's", "tokens": [583, 1338, 11, 286, 914, 11, 291, 458, 11, 291, 576, 2066, 264, 6713, 3314, 412, 341, 935, 281, 312, 5324, 11, 286, 519, 11, 570, 264, 881, 2689, 3467, 11, 597, 309, 311], "temperature": 0.0, "avg_logprob": -0.08154667460400125, "compression_ratio": 1.5646551724137931, "no_speech_prob": 1.4059765817364678e-05}, {"id": 562, "seek": 376808, "start": 3787.08, "end": 3792.08, "text": " particularly ought to care about because they're the ones that's going to have mainly in the training set, it hasn't seen very much.", "tokens": [4098, 13416, 281, 1127, 466, 570, 436, 434, 264, 2306, 300, 311, 516, 281, 362, 8704, 294, 264, 3097, 992, 11, 309, 6132, 380, 1612, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.08154667460400125, "compression_ratio": 1.5646551724137931, "no_speech_prob": 1.4059765817364678e-05}, {"id": 563, "seek": 376808, "start": 3792.08, "end": 3795.08, "text": " So the overall error has gone down.", "tokens": [407, 264, 4787, 6713, 575, 2780, 760, 13], "temperature": 0.0, "avg_logprob": -0.08154667460400125, "compression_ratio": 1.5646551724137931, "no_speech_prob": 1.4059765817364678e-05}, {"id": 564, "seek": 379508, "start": 3795.08, "end": 3803.08, "text": " But yeah, I think it might, there may well be ways to use this.", "tokens": [583, 1338, 11, 286, 519, 309, 1062, 11, 456, 815, 731, 312, 2098, 281, 764, 341, 13], "temperature": 0.0, "avg_logprob": -0.21148673949703092, "compression_ratio": 1.4228571428571428, "no_speech_prob": 1.112445261242101e-05}, {"id": 565, "seek": 379508, "start": 3803.08, "end": 3818.08, "text": " Jeremy, is it possible you could quickly explain where the deficiency was in this random weighted API, how you would prefer that to look like you said you fixed it up later, but I mean,", "tokens": [17809, 11, 307, 309, 1944, 291, 727, 2661, 2903, 689, 264, 37500, 390, 294, 341, 4974, 32807, 9362, 11, 577, 291, 576, 4382, 300, 281, 574, 411, 291, 848, 291, 6806, 309, 493, 1780, 11, 457, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.21148673949703092, "compression_ratio": 1.4228571428571428, "no_speech_prob": 1.112445261242101e-05}, {"id": 566, "seek": 381808, "start": 3818.08, "end": 3831.08, "text": " I think the way this ought to look would be that I can say DLs equals D block.weighted data loader.", "tokens": [286, 519, 264, 636, 341, 13416, 281, 574, 576, 312, 300, 286, 393, 584, 413, 43, 82, 6915, 413, 3461, 13, 12329, 292, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.22444898654253054, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.6536480416107224e-06}, {"id": 567, "seek": 381808, "start": 3831.08, "end": 3834.08, "text": " Like that.", "tokens": [1743, 300, 13], "temperature": 0.0, "avg_logprob": -0.22444898654253054, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.6536480416107224e-06}, {"id": 568, "seek": 381808, "start": 3834.08, "end": 3837.08, "text": " In fact, you know, we could we could fix it up now.", "tokens": [682, 1186, 11, 291, 458, 11, 321, 727, 321, 727, 3191, 309, 493, 586, 13], "temperature": 0.0, "avg_logprob": -0.22444898654253054, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.6536480416107224e-06}, {"id": 569, "seek": 381808, "start": 3837.08, "end": 3844.08, "text": " Reusing the existing after batch and after items already and then we can fix it up now if you're interested.", "tokens": [1300, 7981, 264, 6741, 934, 15245, 293, 934, 4754, 1217, 293, 550, 321, 393, 3191, 309, 493, 586, 498, 291, 434, 3102, 13], "temperature": 0.0, "avg_logprob": -0.22444898654253054, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.6536480416107224e-06}, {"id": 570, "seek": 384408, "start": 3844.08, "end": 3850.08, "text": " Yeah, I'd love to see how to change.", "tokens": [865, 11, 286, 1116, 959, 281, 536, 577, 281, 1319, 13], "temperature": 0.0, "avg_logprob": -0.18116068158830914, "compression_ratio": 1.4023668639053255, "no_speech_prob": 1.54440804180922e-05}, {"id": 571, "seek": 384408, "start": 3850.08, "end": 3858.08, "text": " So, you know, the first thing I'd do before I change the fast AI library is make sure I've got the latest version of it by doing a get pull.", "tokens": [407, 11, 291, 458, 11, 264, 700, 551, 286, 1116, 360, 949, 286, 1319, 264, 2370, 7318, 6405, 307, 652, 988, 286, 600, 658, 264, 6792, 3037, 295, 309, 538, 884, 257, 483, 2235, 13], "temperature": 0.0, "avg_logprob": -0.18116068158830914, "compression_ratio": 1.4023668639053255, "no_speech_prob": 1.54440804180922e-05}, {"id": 572, "seek": 384408, "start": 3858.08, "end": 3861.08, "text": " Because nobody likes conflicts.", "tokens": [1436, 5079, 5902, 19807, 13], "temperature": 0.0, "avg_logprob": -0.18116068158830914, "compression_ratio": 1.4023668639053255, "no_speech_prob": 1.54440804180922e-05}, {"id": 573, "seek": 384408, "start": 3861.08, "end": 3864.08, "text": " All right, it's up to date.", "tokens": [1057, 558, 11, 309, 311, 493, 281, 4002, 13], "temperature": 0.0, "avg_logprob": -0.18116068158830914, "compression_ratio": 1.4023668639053255, "no_speech_prob": 1.54440804180922e-05}, {"id": 574, "seek": 386408, "start": 3864.08, "end": 3874.08, "text": " So then I would go into the notebooks and it was in the data callbacks.", "tokens": [407, 550, 286, 576, 352, 666, 264, 43782, 293, 309, 390, 294, 264, 1412, 818, 17758, 13], "temperature": 0.0, "avg_logprob": -0.18780261278152466, "compression_ratio": 1.2424242424242424, "no_speech_prob": 8.310338307637721e-05}, {"id": 575, "seek": 386408, "start": 3874.08, "end": 3878.08, "text": " Callback.data.", "tokens": [7807, 3207, 13, 67, 3274, 13], "temperature": 0.0, "avg_logprob": -0.18780261278152466, "compression_ratio": 1.2424242424242424, "no_speech_prob": 8.310338307637721e-05}, {"id": 576, "seek": 386408, "start": 3878.08, "end": 3887.08, "text": " And so here's weighted data loaders.", "tokens": [400, 370, 510, 311, 32807, 1412, 3677, 433, 13], "temperature": 0.0, "avg_logprob": -0.18780261278152466, "compression_ratio": 1.2424242424242424, "no_speech_prob": 8.310338307637721e-05}, {"id": 577, "seek": 388708, "start": 3887.08, "end": 3895.08, "text": " It's just a bit of a silly question, but is it a callback or is it just kind of like a transform within the actual data block?", "tokens": [467, 311, 445, 257, 857, 295, 257, 11774, 1168, 11, 457, 307, 309, 257, 818, 3207, 420, 307, 309, 445, 733, 295, 411, 257, 4088, 1951, 264, 3539, 1412, 3461, 30], "temperature": 0.0, "avg_logprob": -0.1256994170111579, "compression_ratio": 1.535031847133758, "no_speech_prob": 8.024837006814778e-05}, {"id": 578, "seek": 388708, "start": 3895.08, "end": 3901.08, "text": " Should it be if you send weights to a data block, then it just does it.", "tokens": [6454, 309, 312, 498, 291, 2845, 17443, 281, 257, 1412, 3461, 11, 550, 309, 445, 775, 309, 13], "temperature": 0.0, "avg_logprob": -0.1256994170111579, "compression_ratio": 1.535031847133758, "no_speech_prob": 8.024837006814778e-05}, {"id": 579, "seek": 388708, "start": 3901.08, "end": 3909.08, "text": " Is it a callback?", "tokens": [1119, 309, 257, 818, 3207, 30], "temperature": 0.0, "avg_logprob": -0.1256994170111579, "compression_ratio": 1.535031847133758, "no_speech_prob": 8.024837006814778e-05}, {"id": 580, "seek": 388708, "start": 3909.08, "end": 3913.08, "text": " No, it's not a callback.", "tokens": [883, 11, 309, 311, 406, 257, 818, 3207, 13], "temperature": 0.0, "avg_logprob": -0.1256994170111579, "compression_ratio": 1.535031847133758, "no_speech_prob": 8.024837006814778e-05}, {"id": 581, "seek": 391308, "start": 3913.08, "end": 3918.08, "text": " So it's in a strange place.", "tokens": [407, 309, 311, 294, 257, 5861, 1081, 13], "temperature": 0.0, "avg_logprob": -0.14196160634358723, "compression_ratio": 1.183673469387755, "no_speech_prob": 1.963713884833851e-06}, {"id": 582, "seek": 391308, "start": 3918.08, "end": 3921.08, "text": " It's not a callback.", "tokens": [467, 311, 406, 257, 818, 3207, 13], "temperature": 0.0, "avg_logprob": -0.14196160634358723, "compression_ratio": 1.183673469387755, "no_speech_prob": 1.963713884833851e-06}, {"id": 583, "seek": 391308, "start": 3921.08, "end": 3925.08, "text": " What it is, it's a data loader, actually.", "tokens": [708, 309, 307, 11, 309, 311, 257, 1412, 3677, 260, 11, 767, 13], "temperature": 0.0, "avg_logprob": -0.14196160634358723, "compression_ratio": 1.183673469387755, "no_speech_prob": 1.963713884833851e-06}, {"id": 584, "seek": 391308, "start": 3925.08, "end": 3932.08, "text": " And a patch to data sets.", "tokens": [400, 257, 9972, 281, 1412, 6352, 13], "temperature": 0.0, "avg_logprob": -0.14196160634358723, "compression_ratio": 1.183673469387755, "no_speech_prob": 1.963713884833851e-06}, {"id": 585, "seek": 393208, "start": 3932.08, "end": 3947.08, "text": " So there's a, you know, something I like very much in Fastcore called patch, which allows us to add a method with this name to this class.", "tokens": [407, 456, 311, 257, 11, 291, 458, 11, 746, 286, 411, 588, 709, 294, 15968, 12352, 1219, 9972, 11, 597, 4045, 505, 281, 909, 257, 3170, 365, 341, 1315, 281, 341, 1508, 13], "temperature": 0.0, "avg_logprob": -0.17657902661491842, "compression_ratio": 1.4148148148148147, "no_speech_prob": 4.222536063025473e-06}, {"id": 586, "seek": 393208, "start": 3947.08, "end": 3961.08, "text": " And I want to add something to the data block class.", "tokens": [400, 286, 528, 281, 909, 746, 281, 264, 1412, 3461, 1508, 13], "temperature": 0.0, "avg_logprob": -0.17657902661491842, "compression_ratio": 1.4148148148148147, "no_speech_prob": 4.222536063025473e-06}, {"id": 587, "seek": 396108, "start": 3961.08, "end": 3972.08, "text": " Like so.", "tokens": [1743, 370, 13], "temperature": 0.0, "avg_logprob": -0.23349969046456473, "compression_ratio": 1.15625, "no_speech_prob": 1.77755700860871e-05}, {"id": 588, "seek": 396108, "start": 3972.08, "end": 3978.08, "text": " But yeah, I think that the doc string is correct.", "tokens": [583, 1338, 11, 286, 519, 300, 264, 3211, 6798, 307, 3006, 13], "temperature": 0.0, "avg_logprob": -0.23349969046456473, "compression_ratio": 1.15625, "no_speech_prob": 1.77755700860871e-05}, {"id": 589, "seek": 396108, "start": 3978.08, "end": 3986.08, "text": " And I would then be inclined to just grab this here.", "tokens": [400, 286, 576, 550, 312, 28173, 281, 445, 4444, 341, 510, 13], "temperature": 0.0, "avg_logprob": -0.23349969046456473, "compression_ratio": 1.15625, "no_speech_prob": 1.77755700860871e-05}, {"id": 590, "seek": 398608, "start": 3986.08, "end": 3995.08, "text": " Copy and paste it in here.", "tokens": [25653, 293, 9163, 309, 294, 510, 13], "temperature": 0.0, "avg_logprob": -0.1329005517457661, "compression_ratio": 1.1473684210526316, "no_speech_prob": 4.637823622033466e-06}, {"id": 591, "seek": 398608, "start": 3995.08, "end": 3998.08, "text": " Paste.", "tokens": [43827, 13], "temperature": 0.0, "avg_logprob": -0.1329005517457661, "compression_ratio": 1.1473684210526316, "no_speech_prob": 4.637823622033466e-06}, {"id": 592, "seek": 398608, "start": 3998.08, "end": 4003.08, "text": " Okay. And so this would be calling.", "tokens": [1033, 13, 400, 370, 341, 576, 312, 5141, 13], "temperature": 0.0, "avg_logprob": -0.1329005517457661, "compression_ratio": 1.1473684210526316, "no_speech_prob": 4.637823622033466e-06}, {"id": 593, "seek": 398608, "start": 4003.08, "end": 4014.08, "text": " Yeah, so we're calling the data blocks.", "tokens": [865, 11, 370, 321, 434, 5141, 264, 1412, 8474, 13], "temperature": 0.0, "avg_logprob": -0.1329005517457661, "compression_ratio": 1.1473684210526316, "no_speech_prob": 4.637823622033466e-06}, {"id": 594, "seek": 401408, "start": 4014.08, "end": 4019.08, "text": " So I guess we're going to do the two steps kind of manually, aren't we?", "tokens": [407, 286, 2041, 321, 434, 516, 281, 360, 264, 732, 4439, 733, 295, 16945, 11, 3212, 380, 321, 30], "temperature": 0.0, "avg_logprob": -0.1466106466344885, "compression_ratio": 1.2121212121212122, "no_speech_prob": 7.646058293175884e-06}, {"id": 595, "seek": 401408, "start": 4019.08, "end": 4035.08, "text": " So we're first going to go create the data sets.", "tokens": [407, 321, 434, 700, 516, 281, 352, 1884, 264, 1412, 6352, 13], "temperature": 0.0, "avg_logprob": -0.1466106466344885, "compression_ratio": 1.2121212121212122, "no_speech_prob": 7.646058293175884e-06}, {"id": 596, "seek": 403508, "start": 4035.08, "end": 4047.08, "text": " And so that means we need to be passed in", "tokens": [400, 370, 300, 1355, 321, 643, 281, 312, 4678, 294], "temperature": 0.0, "avg_logprob": -0.15339103937149048, "compression_ratio": 1.23, "no_speech_prob": 2.994309170389897e-06}, {"id": 597, "seek": 403508, "start": 4047.08, "end": 4052.08, "text": " the items called source.", "tokens": [264, 4754, 1219, 4009, 13], "temperature": 0.0, "avg_logprob": -0.15339103937149048, "compression_ratio": 1.23, "no_speech_prob": 2.994309170389897e-06}, {"id": 598, "seek": 403508, "start": 4052.08, "end": 4057.08, "text": " And I'd be inclined to like grab all that.", "tokens": [400, 286, 1116, 312, 28173, 281, 411, 4444, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.15339103937149048, "compression_ratio": 1.23, "no_speech_prob": 2.994309170389897e-06}, {"id": 599, "seek": 403508, "start": 4057.08, "end": 4064.08, "text": " Okay, so this", "tokens": [1033, 11, 370, 341], "temperature": 0.0, "avg_logprob": -0.15339103937149048, "compression_ratio": 1.23, "no_speech_prob": 2.994309170389897e-06}, {"id": 600, "seek": 406408, "start": 4064.08, "end": 4070.08, "text": " thing in data block", "tokens": [551, 294, 1412, 3461], "temperature": 0.0, "avg_logprob": -0.09323405437782163, "compression_ratio": 1.5037037037037038, "no_speech_prob": 1.2804929610865656e-05}, {"id": 601, "seek": 406408, "start": 4070.08, "end": 4077.08, "text": " is going to need a source.", "tokens": [307, 516, 281, 643, 257, 4009, 13], "temperature": 0.0, "avg_logprob": -0.09323405437782163, "compression_ratio": 1.5037037037037038, "no_speech_prob": 1.2804929610865656e-05}, {"id": 602, "seek": 406408, "start": 4077.08, "end": 4080.08, "text": " It's going to need the weights.", "tokens": [467, 311, 516, 281, 643, 264, 17443, 13], "temperature": 0.0, "avg_logprob": -0.09323405437782163, "compression_ratio": 1.5037037037037038, "no_speech_prob": 1.2804929610865656e-05}, {"id": 603, "seek": 406408, "start": 4080.08, "end": 4083.08, "text": " It's going to need a batch size.", "tokens": [467, 311, 516, 281, 643, 257, 15245, 2744, 13], "temperature": 0.0, "avg_logprob": -0.09323405437782163, "compression_ratio": 1.5037037037037038, "no_speech_prob": 1.2804929610865656e-05}, {"id": 604, "seek": 406408, "start": 4083.08, "end": 4090.08, "text": " Apparently there's something called verbose. I don't know what that means, but that's fine.", "tokens": [16755, 456, 311, 746, 1219, 9595, 541, 13, 286, 500, 380, 458, 437, 300, 1355, 11, 457, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.09323405437782163, "compression_ratio": 1.5037037037037038, "no_speech_prob": 1.2804929610865656e-05}, {"id": 605, "seek": 409008, "start": 4090.08, "end": 4097.08, "text": " So the data sets is self.dataSets passing in the source.", "tokens": [407, 264, 1412, 6352, 307, 2698, 13, 67, 3274, 50, 1385, 8437, 294, 264, 4009, 13], "temperature": 0.0, "avg_logprob": -0.17767317001133748, "compression_ratio": 1.5323741007194245, "no_speech_prob": 5.337771199265262e-06}, {"id": 606, "seek": 409008, "start": 4097.08, "end": 4101.08, "text": " And verbose equals verbose.", "tokens": [400, 9595, 541, 6915, 9595, 541, 13], "temperature": 0.0, "avg_logprob": -0.17767317001133748, "compression_ratio": 1.5323741007194245, "no_speech_prob": 5.337771199265262e-06}, {"id": 607, "seek": 409008, "start": 4101.08, "end": 4108.08, "text": " And then we called dss.dataloaders.", "tokens": [400, 550, 321, 1219, 274, 3810, 13, 20367, 10334, 15221, 13], "temperature": 0.0, "avg_logprob": -0.17767317001133748, "compression_ratio": 1.5323741007194245, "no_speech_prob": 5.337771199265262e-06}, {"id": 608, "seek": 409008, "start": 4108.08, "end": 4111.08, "text": " And when we did that.", "tokens": [400, 562, 321, 630, 300, 13], "temperature": 0.0, "avg_logprob": -0.17767317001133748, "compression_ratio": 1.5323741007194245, "no_speech_prob": 5.337771199265262e-06}, {"id": 609, "seek": 409008, "start": 4111.08, "end": 4118.08, "text": " Okay, so now we're going to be passing doing dss.weighted.dataloaders.", "tokens": [1033, 11, 370, 586, 321, 434, 516, 281, 312, 8437, 884, 274, 3810, 13, 12329, 292, 13, 20367, 10334, 15221, 13], "temperature": 0.0, "avg_logprob": -0.17767317001133748, "compression_ratio": 1.5323741007194245, "no_speech_prob": 5.337771199265262e-06}, {"id": 610, "seek": 411808, "start": 4118.08, "end": 4134.08, "text": " And that's basically.", "tokens": [400, 300, 311, 1936, 13], "temperature": 0.0, "avg_logprob": -0.45211581622853, "compression_ratio": 0.9056603773584906, "no_speech_prob": 4.331635864218697e-05}, {"id": 611, "seek": 411808, "start": 4134.08, "end": 4143.08, "text": " Oops. What happened there?", "tokens": [21726, 13, 708, 2011, 456, 30], "temperature": 0.0, "avg_logprob": -0.45211581622853, "compression_ratio": 0.9056603773584906, "no_speech_prob": 4.331635864218697e-05}, {"id": 612, "seek": 414308, "start": 4143.08, "end": 4150.08, "text": " And then we pass in the weights.", "tokens": [400, 550, 321, 1320, 294, 264, 17443, 13], "temperature": 0.0, "avg_logprob": -0.18268216573275053, "compression_ratio": 1.504201680672269, "no_speech_prob": 6.240727998374496e-06}, {"id": 613, "seek": 414308, "start": 4150.08, "end": 4152.08, "text": " Weights.", "tokens": [492, 5761, 13], "temperature": 0.0, "avg_logprob": -0.18268216573275053, "compression_ratio": 1.504201680672269, "no_speech_prob": 6.240727998374496e-06}, {"id": 614, "seek": 414308, "start": 4152.08, "end": 4156.08, "text": " So weighted data loaders, yeah, gets the weights.", "tokens": [407, 32807, 1412, 3677, 433, 11, 1338, 11, 2170, 264, 17443, 13], "temperature": 0.0, "avg_logprob": -0.18268216573275053, "compression_ratio": 1.504201680672269, "no_speech_prob": 6.240727998374496e-06}, {"id": 615, "seek": 414308, "start": 4156.08, "end": 4160.08, "text": " And then the batch size and then the things we added.", "tokens": [400, 550, 264, 15245, 2744, 293, 550, 264, 721, 321, 3869, 13], "temperature": 0.0, "avg_logprob": -0.18268216573275053, "compression_ratio": 1.504201680672269, "no_speech_prob": 6.240727998374496e-06}, {"id": 616, "seek": 414308, "start": 4160.08, "end": 4166.08, "text": " Any additional keyword arguments.", "tokens": [2639, 4497, 20428, 12869, 13], "temperature": 0.0, "avg_logprob": -0.18268216573275053, "compression_ratio": 1.504201680672269, "no_speech_prob": 6.240727998374496e-06}, {"id": 617, "seek": 416608, "start": 4166.08, "end": 4176.08, "text": " And this will delegate down to", "tokens": [400, 341, 486, 40999, 760, 281], "temperature": 0.0, "avg_logprob": -0.10278017624564793, "compression_ratio": 1.2622950819672132, "no_speech_prob": 3.7853026242373744e-06}, {"id": 618, "seek": 416608, "start": 4176.08, "end": 4183.08, "text": " dataSets.weighted.dataloaders is where the keyword arguments get passed to.", "tokens": [1412, 50, 1385, 13, 12329, 292, 13, 20367, 10334, 15221, 307, 689, 264, 20428, 12869, 483, 4678, 281, 13], "temperature": 0.0, "avg_logprob": -0.10278017624564793, "compression_ratio": 1.2622950819672132, "no_speech_prob": 3.7853026242373744e-06}, {"id": 619, "seek": 416608, "start": 4183.08, "end": 4192.08, "text": " Okay, so as far as I can tell, these same tests", "tokens": [1033, 11, 370, 382, 1400, 382, 286, 393, 980, 11, 613, 912, 6921], "temperature": 0.0, "avg_logprob": -0.10278017624564793, "compression_ratio": 1.2622950819672132, "no_speech_prob": 3.7853026242373744e-06}, {"id": 620, "seek": 419208, "start": 4192.08, "end": 4197.08, "text": " should all work. We don't need these labels anymore. It is valid.", "tokens": [820, 439, 589, 13, 492, 500, 380, 643, 613, 16949, 3602, 13, 467, 307, 7363, 13], "temperature": 0.0, "avg_logprob": -0.08416440337896347, "compression_ratio": 1.4430379746835442, "no_speech_prob": 8.013379556359723e-06}, {"id": 621, "seek": 419208, "start": 4197.08, "end": 4199.08, "text": " We've already got a data block.", "tokens": [492, 600, 1217, 658, 257, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.08416440337896347, "compression_ratio": 1.4430379746835442, "no_speech_prob": 8.013379556359723e-06}, {"id": 622, "seek": 419208, "start": 4199.08, "end": 4206.08, "text": " So previously we called data set and item transforms and weights manually.", "tokens": [407, 8046, 321, 1219, 1412, 992, 293, 3174, 35592, 293, 17443, 16945, 13], "temperature": 0.0, "avg_logprob": -0.08416440337896347, "compression_ratio": 1.4430379746835442, "no_speech_prob": 8.013379556359723e-06}, {"id": 623, "seek": 419208, "start": 4206.08, "end": 4212.08, "text": " So that is our source.", "tokens": [407, 300, 307, 527, 4009, 13], "temperature": 0.0, "avg_logprob": -0.08416440337896347, "compression_ratio": 1.4430379746835442, "no_speech_prob": 8.013379556359723e-06}, {"id": 624, "seek": 419208, "start": 4212.08, "end": 4216.08, "text": " So we could get rid of all this.", "tokens": [407, 321, 727, 483, 3973, 295, 439, 341, 13], "temperature": 0.0, "avg_logprob": -0.08416440337896347, "compression_ratio": 1.4430379746835442, "no_speech_prob": 8.013379556359723e-06}, {"id": 625, "seek": 421608, "start": 4216.08, "end": 4222.08, "text": " And we're now going to go data block.weighted.dataloaders.", "tokens": [400, 321, 434, 586, 516, 281, 352, 1412, 3461, 13, 12329, 292, 13, 20367, 10334, 15221, 13], "temperature": 0.0, "avg_logprob": -0.14372466504573822, "compression_ratio": 1.4852941176470589, "no_speech_prob": 1.473849351896206e-05}, {"id": 626, "seek": 421608, "start": 4222.08, "end": 4226.08, "text": " And we've got to pass in our source.", "tokens": [400, 321, 600, 658, 281, 1320, 294, 527, 4009, 13], "temperature": 0.0, "avg_logprob": -0.14372466504573822, "compression_ratio": 1.4852941176470589, "no_speech_prob": 1.473849351896206e-05}, {"id": 627, "seek": 421608, "start": 4226.08, "end": 4234.08, "text": " Okay, and we've got to pass in our weights, which were called weights.", "tokens": [1033, 11, 293, 321, 600, 658, 281, 1320, 294, 527, 17443, 11, 597, 645, 1219, 17443, 13], "temperature": 0.0, "avg_logprob": -0.14372466504573822, "compression_ratio": 1.4852941176470589, "no_speech_prob": 1.473849351896206e-05}, {"id": 628, "seek": 421608, "start": 4234.08, "end": 4239.08, "text": " Oh, I already had that. Never mind.", "tokens": [876, 11, 286, 1217, 632, 300, 13, 7344, 1575, 13], "temperature": 0.0, "avg_logprob": -0.14372466504573822, "compression_ratio": 1.4852941176470589, "no_speech_prob": 1.473849351896206e-05}, {"id": 629, "seek": 423908, "start": 4239.08, "end": 4248.08, "text": " And we don't need that anymore.", "tokens": [400, 321, 500, 380, 643, 300, 3602, 13], "temperature": 0.0, "avg_logprob": -0.18915720188871343, "compression_ratio": 1.1272727272727272, "no_speech_prob": 1.0129732800123747e-05}, {"id": 630, "seek": 423908, "start": 4248.08, "end": 4250.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.18915720188871343, "compression_ratio": 1.1272727272727272, "no_speech_prob": 1.0129732800123747e-05}, {"id": 631, "seek": 423908, "start": 4250.08, "end": 4252.08, "text": " Why did I get zero?", "tokens": [1545, 630, 286, 483, 4018, 30], "temperature": 0.0, "avg_logprob": -0.18915720188871343, "compression_ratio": 1.1272727272727272, "no_speech_prob": 1.0129732800123747e-05}, {"id": 632, "seek": 423908, "start": 4252.08, "end": 4257.08, "text": " That's slightly surprising to me.", "tokens": [663, 311, 4748, 8830, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.18915720188871343, "compression_ratio": 1.1272727272727272, "no_speech_prob": 1.0129732800123747e-05}, {"id": 633, "seek": 423908, "start": 4257.08, "end": 4268.08, "text": " Oh, no, zero. Yeah, that's fine.", "tokens": [876, 11, 572, 11, 4018, 13, 865, 11, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.18915720188871343, "compression_ratio": 1.1272727272727272, "no_speech_prob": 1.0129732800123747e-05}, {"id": 634, "seek": 426808, "start": 4268.08, "end": 4273.08, "text": " Yeah, I could get zero or one.", "tokens": [865, 11, 286, 727, 483, 4018, 420, 472, 13], "temperature": 0.0, "avg_logprob": -0.20629211374231288, "compression_ratio": 1.4082840236686391, "no_speech_prob": 8.013335900614038e-06}, {"id": 635, "seek": 426808, "start": 4273.08, "end": 4282.08, "text": " Yeah, because it depends how it...", "tokens": [865, 11, 570, 309, 5946, 577, 309, 485], "temperature": 0.0, "avg_logprob": -0.20629211374231288, "compression_ratio": 1.4082840236686391, "no_speech_prob": 8.013335900614038e-06}, {"id": 636, "seek": 426808, "start": 4282.08, "end": 4284.08, "text": " Why is that slightly random?", "tokens": [1545, 307, 300, 4748, 4974, 30], "temperature": 0.0, "avg_logprob": -0.20629211374231288, "compression_ratio": 1.4082840236686391, "no_speech_prob": 8.013335900614038e-06}, {"id": 637, "seek": 426808, "start": 4284.08, "end": 4288.08, "text": " I'm not sure. Something's slightly random. But anyway, it's working.", "tokens": [286, 478, 406, 988, 13, 6595, 311, 4748, 4974, 13, 583, 4033, 11, 309, 311, 1364, 13], "temperature": 0.0, "avg_logprob": -0.20629211374231288, "compression_ratio": 1.4082840236686391, "no_speech_prob": 8.013335900614038e-06}, {"id": 638, "seek": 426808, "start": 4288.08, "end": 4295.08, "text": " So then, okay, then again, for this one, we shouldn't need to do dataSets.", "tokens": [407, 550, 11, 1392, 11, 550, 797, 11, 337, 341, 472, 11, 321, 4659, 380, 643, 281, 360, 1412, 50, 1385, 13], "temperature": 0.0, "avg_logprob": -0.20629211374231288, "compression_ratio": 1.4082840236686391, "no_speech_prob": 8.013335900614038e-06}, {"id": 639, "seek": 429508, "start": 4295.08, "end": 4300.08, "text": " We should be able to go data block.weighted.dataloaders.", "tokens": [492, 820, 312, 1075, 281, 352, 1412, 3461, 13, 12329, 292, 13, 20367, 10334, 15221, 13], "temperature": 0.0, "avg_logprob": -0.10580099953545465, "compression_ratio": 1.3181818181818181, "no_speech_prob": 4.356778390501859e-06}, {"id": 640, "seek": 429508, "start": 4300.08, "end": 4310.08, "text": " And we should be able to pass in our items and our weights.", "tokens": [400, 321, 820, 312, 1075, 281, 1320, 294, 527, 4754, 293, 527, 17443, 13], "temperature": 0.0, "avg_logprob": -0.10580099953545465, "compression_ratio": 1.3181818181818181, "no_speech_prob": 4.356778390501859e-06}, {"id": 641, "seek": 431008, "start": 4310.08, "end": 4330.08, "text": " And...", "tokens": [400, 485], "temperature": 0.0, "avg_logprob": -0.19117573897043863, "compression_ratio": 1.0222222222222221, "no_speech_prob": 2.2473450371762738e-05}, {"id": 642, "seek": 431008, "start": 4330.08, "end": 4332.08, "text": " Okay, what did I do wrong there?", "tokens": [1033, 11, 437, 630, 286, 360, 2085, 456, 30], "temperature": 0.0, "avg_logprob": -0.19117573897043863, "compression_ratio": 1.0222222222222221, "no_speech_prob": 2.2473450371762738e-05}, {"id": 643, "seek": 431008, "start": 4332.08, "end": 4338.08, "text": " Data blocked.weighted.dataloaders. Oh, it's got a...", "tokens": [11888, 15470, 13, 12329, 292, 13, 20367, 10334, 15221, 13, 876, 11, 309, 311, 658, 257, 485], "temperature": 0.0, "avg_logprob": -0.19117573897043863, "compression_ratio": 1.0222222222222221, "no_speech_prob": 2.2473450371762738e-05}, {"id": 644, "seek": 433808, "start": 4338.08, "end": 4346.08, "text": " Okay, let's see.", "tokens": [1033, 11, 718, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.21104583033808955, "compression_ratio": 0.9178082191780822, "no_speech_prob": 7.141631067497656e-05}, {"id": 645, "seek": 433808, "start": 4346.08, "end": 4356.08, "text": " Our source, our weights.", "tokens": [2621, 4009, 11, 527, 17443, 13], "temperature": 0.0, "avg_logprob": -0.21104583033808955, "compression_ratio": 0.9178082191780822, "no_speech_prob": 7.141631067497656e-05}, {"id": 646, "seek": 433808, "start": 4356.08, "end": 4365.08, "text": " Why doesn't it like that?", "tokens": [1545, 1177, 380, 309, 411, 300, 30], "temperature": 0.0, "avg_logprob": -0.21104583033808955, "compression_ratio": 0.9178082191780822, "no_speech_prob": 7.141631067497656e-05}, {"id": 647, "seek": 436508, "start": 4365.08, "end": 4369.08, "text": " Source equals...", "tokens": [29629, 6915, 485], "temperature": 0.0, "avg_logprob": -0.14478752069305956, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.2218699339427985e-05}, {"id": 648, "seek": 436508, "start": 4369.08, "end": 4373.08, "text": " So let's see how it's different to what this one said.", "tokens": [407, 718, 311, 536, 577, 309, 311, 819, 281, 437, 341, 472, 848, 13], "temperature": 0.0, "avg_logprob": -0.14478752069305956, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.2218699339427985e-05}, {"id": 649, "seek": 436508, "start": 4373.08, "end": 4381.08, "text": " dataSets.", "tokens": [1412, 50, 1385, 13], "temperature": 0.0, "avg_logprob": -0.14478752069305956, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.2218699339427985e-05}, {"id": 650, "seek": 436508, "start": 4381.08, "end": 4385.08, "text": " Okay, this doesn't use a data block. So, okay, I can't replicate that.", "tokens": [1033, 11, 341, 1177, 380, 764, 257, 1412, 3461, 13, 407, 11, 1392, 11, 286, 393, 380, 25356, 300, 13], "temperature": 0.0, "avg_logprob": -0.14478752069305956, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.2218699339427985e-05}, {"id": 651, "seek": 436508, "start": 4385.08, "end": 4387.08, "text": " That's fine.", "tokens": [663, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.14478752069305956, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.2218699339427985e-05}, {"id": 652, "seek": 438708, "start": 4387.08, "end": 4399.08, "text": " Okay, so that's our test.", "tokens": [1033, 11, 370, 300, 311, 527, 1500, 13], "temperature": 0.0, "avg_logprob": -0.14475841522216798, "compression_ratio": 1.0681818181818181, "no_speech_prob": 8.397706551477313e-06}, {"id": 653, "seek": 438708, "start": 4399.08, "end": 4405.08, "text": " There we go. So what I would then do is I would export it.", "tokens": [821, 321, 352, 13, 407, 437, 286, 576, 550, 360, 307, 286, 576, 10725, 309, 13], "temperature": 0.0, "avg_logprob": -0.14475841522216798, "compression_ratio": 1.0681818181818181, "no_speech_prob": 8.397706551477313e-06}, {"id": 654, "seek": 438708, "start": 4405.08, "end": 4410.08, "text": " And if...", "tokens": [400, 498, 485], "temperature": 0.0, "avg_logprob": -0.14475841522216798, "compression_ratio": 1.0681818181818181, "no_speech_prob": 8.397706551477313e-06}, {"id": 655, "seek": 441008, "start": 4410.08, "end": 4417.08, "text": " So that...I don't have to rebuild or reinstall or anything like that my fastai library.", "tokens": [407, 300, 485, 40, 500, 380, 362, 281, 16877, 420, 35056, 336, 420, 1340, 411, 300, 452, 2370, 1301, 6405, 13], "temperature": 0.0, "avg_logprob": -0.17300861583036534, "compression_ratio": 1.6280193236714975, "no_speech_prob": 7.182874469435774e-06}, {"id": 656, "seek": 441008, "start": 4417.08, "end": 4421.08, "text": " That's because I have it installed using something called an editable install.", "tokens": [663, 311, 570, 286, 362, 309, 8899, 1228, 746, 1219, 364, 8129, 712, 3625, 13], "temperature": 0.0, "avg_logprob": -0.17300861583036534, "compression_ratio": 1.6280193236714975, "no_speech_prob": 7.182874469435774e-06}, {"id": 657, "seek": 441008, "start": 4421.08, "end": 4425.08, "text": " So if you haven't seen that before, basically, or maybe you have and you've wondered why,", "tokens": [407, 498, 291, 2378, 380, 1612, 300, 949, 11, 1936, 11, 420, 1310, 291, 362, 293, 291, 600, 17055, 983, 11], "temperature": 0.0, "avg_logprob": -0.17300861583036534, "compression_ratio": 1.6280193236714975, "no_speech_prob": 7.182874469435774e-06}, {"id": 658, "seek": 441008, "start": 4425.08, "end": 4432.08, "text": " when you go pip install minus E dot in a Git repo, basically that creates like a", "tokens": [562, 291, 352, 8489, 3625, 3175, 462, 5893, 294, 257, 16939, 49040, 11, 1936, 300, 7829, 411, 257], "temperature": 0.0, "avg_logprob": -0.17300861583036534, "compression_ratio": 1.6280193236714975, "no_speech_prob": 7.182874469435774e-06}, {"id": 659, "seek": 443208, "start": 4432.08, "end": 4441.08, "text": " SIM link from your Python library to this folder. And so fastai, when I import fastai,", "tokens": [24738, 2113, 490, 428, 15329, 6405, 281, 341, 10820, 13, 400, 370, 2370, 1301, 11, 562, 286, 974, 2370, 1301, 11], "temperature": 0.0, "avg_logprob": -0.14414535378510096, "compression_ratio": 1.3955223880597014, "no_speech_prob": 5.955002961854916e-06}, {"id": 660, "seek": 443208, "start": 4441.08, "end": 4445.08, "text": " it's actually going to import it from this folder.", "tokens": [309, 311, 767, 516, 281, 974, 309, 490, 341, 10820, 13], "temperature": 0.0, "avg_logprob": -0.14414535378510096, "compression_ratio": 1.3955223880597014, "no_speech_prob": 5.955002961854916e-06}, {"id": 661, "seek": 443208, "start": 4445.08, "end": 4452.08, "text": " And so now, back over here in my weighted thingy,", "tokens": [400, 370, 586, 11, 646, 670, 510, 294, 452, 32807, 551, 88, 11], "temperature": 0.0, "avg_logprob": -0.14414535378510096, "compression_ratio": 1.3955223880597014, "no_speech_prob": 5.955002961854916e-06}, {"id": 662, "seek": 445208, "start": 4452.08, "end": 4468.08, "text": " if I do all this, data block,", "tokens": [498, 286, 360, 439, 341, 11, 1412, 3461, 11], "temperature": 0.0, "avg_logprob": -0.21369204982634513, "compression_ratio": 1.1547619047619047, "no_speech_prob": 1.0952829143207055e-05}, {"id": 663, "seek": 445208, "start": 4468.08, "end": 4474.08, "text": " we should find that there's now a dblock dot weighted data loaders,", "tokens": [321, 820, 915, 300, 456, 311, 586, 257, 274, 28830, 5893, 32807, 1412, 3677, 433, 11], "temperature": 0.0, "avg_logprob": -0.21369204982634513, "compression_ratio": 1.1547619047619047, "no_speech_prob": 1.0952829143207055e-05}, {"id": 664, "seek": 447408, "start": 4474.08, "end": 4487.08, "text": " which I can pass source and weights. And my source is files and my weights is...", "tokens": [597, 286, 393, 1320, 4009, 293, 17443, 13, 400, 452, 4009, 307, 7098, 293, 452, 17443, 307, 485], "temperature": 0.0, "avg_logprob": -0.18252654191924306, "compression_ratio": 1.3529411764705883, "no_speech_prob": 1.1478558917588089e-05}, {"id": 665, "seek": 447408, "start": 4487.08, "end": 4490.08, "text": " weights.", "tokens": [17443, 13], "temperature": 0.0, "avg_logprob": -0.18252654191924306, "compression_ratio": 1.3529411764705883, "no_speech_prob": 1.1478558917588089e-05}, {"id": 666, "seek": 447408, "start": 4490.08, "end": 4500.08, "text": " Oh, and my weights. Okay, so that's interesting.", "tokens": [876, 11, 293, 452, 17443, 13, 1033, 11, 370, 300, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.18252654191924306, "compression_ratio": 1.3529411764705883, "no_speech_prob": 1.1478558917588089e-05}, {"id": 667, "seek": 450008, "start": 4500.08, "end": 4509.08, "text": " My weights. Yes, we don't have data sets yet.", "tokens": [1222, 17443, 13, 1079, 11, 321, 500, 380, 362, 1412, 6352, 1939, 13], "temperature": 0.0, "avg_logprob": -0.09585483724420721, "compression_ratio": 1.359375, "no_speech_prob": 2.5460769393248484e-05}, {"id": 668, "seek": 450008, "start": 4509.08, "end": 4517.08, "text": " So that's a very interesting point.", "tokens": [407, 300, 311, 257, 588, 1880, 935, 13], "temperature": 0.0, "avg_logprob": -0.09585483724420721, "compression_ratio": 1.359375, "no_speech_prob": 2.5460769393248484e-05}, {"id": 669, "seek": 450008, "start": 4517.08, "end": 4521.08, "text": " So how do we know what our weights are? We don't, because they haven't been split.", "tokens": [407, 577, 360, 321, 458, 437, 527, 17443, 366, 30, 492, 500, 380, 11, 570, 436, 2378, 380, 668, 7472, 13], "temperature": 0.0, "avg_logprob": -0.09585483724420721, "compression_ratio": 1.359375, "no_speech_prob": 2.5460769393248484e-05}, {"id": 670, "seek": 450008, "start": 4521.08, "end": 4527.08, "text": " So the...", "tokens": [407, 264, 485], "temperature": 0.0, "avg_logprob": -0.09585483724420721, "compression_ratio": 1.359375, "no_speech_prob": 2.5460769393248484e-05}, {"id": 671, "seek": 452708, "start": 4527.08, "end": 4531.08, "text": " Could you not send them through as one of the blocks and as a column Git from,", "tokens": [7497, 291, 406, 2845, 552, 807, 382, 472, 295, 264, 8474, 293, 382, 257, 7738, 16939, 490, 11], "temperature": 0.0, "avg_logprob": -0.12328699656895228, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0002935771772172302}, {"id": 672, "seek": 452708, "start": 4531.08, "end": 4537.08, "text": " and then use that because then it would be linked quite intimately with the actual row?", "tokens": [293, 550, 764, 300, 570, 550, 309, 576, 312, 9408, 1596, 560, 5401, 365, 264, 3539, 5386, 30], "temperature": 0.0, "avg_logprob": -0.12328699656895228, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0002935771772172302}, {"id": 673, "seek": 452708, "start": 4537.08, "end": 4543.08, "text": " Well, we don't need to. I think what we need to do is pass in weights.", "tokens": [1042, 11, 321, 500, 380, 643, 281, 13, 286, 519, 437, 321, 643, 281, 360, 307, 1320, 294, 17443, 13], "temperature": 0.0, "avg_logprob": -0.12328699656895228, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0002935771772172302}, {"id": 674, "seek": 452708, "start": 4543.08, "end": 4552.08, "text": " I think we should pass in all the weights. And then this thing here should then be", "tokens": [286, 519, 321, 820, 1320, 294, 439, 264, 17443, 13, 400, 550, 341, 551, 510, 820, 550, 312], "temperature": 0.0, "avg_logprob": -0.12328699656895228, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.0002935771772172302}, {"id": 675, "seek": 455208, "start": 4552.08, "end": 4558.08, "text": " responsible for grabbing the subset for the training set.", "tokens": [6250, 337, 23771, 264, 25993, 337, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.181974002293178, "compression_ratio": 1.7052631578947368, "no_speech_prob": 1.147829243564047e-05}, {"id": 676, "seek": 455208, "start": 4558.08, "end": 4563.08, "text": " And that would actually be much more convenient, which is after all is what we want.", "tokens": [400, 300, 576, 767, 312, 709, 544, 10851, 11, 597, 307, 934, 439, 307, 437, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.181974002293178, "compression_ratio": 1.7052631578947368, "no_speech_prob": 1.147829243564047e-05}, {"id": 677, "seek": 455208, "start": 4563.08, "end": 4564.08, "text": " So, yes.", "tokens": [407, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.181974002293178, "compression_ratio": 1.7052631578947368, "no_speech_prob": 1.147829243564047e-05}, {"id": 678, "seek": 455208, "start": 4564.08, "end": 4571.08, "text": " So we should determine the weights based on the distribution across the classes rather than...", "tokens": [407, 321, 820, 6997, 264, 17443, 2361, 322, 264, 7316, 2108, 264, 5359, 2831, 813, 485], "temperature": 0.0, "avg_logprob": -0.181974002293178, "compression_ratio": 1.7052631578947368, "no_speech_prob": 1.147829243564047e-05}, {"id": 679, "seek": 455208, "start": 4571.08, "end": 4577.08, "text": " We should split the weights based on the splitter in a training and test set.", "tokens": [492, 820, 7472, 264, 17443, 2361, 322, 264, 4732, 3904, 294, 257, 3097, 293, 1500, 992, 13], "temperature": 0.0, "avg_logprob": -0.181974002293178, "compression_ratio": 1.7052631578947368, "no_speech_prob": 1.147829243564047e-05}, {"id": 680, "seek": 457708, "start": 4577.08, "end": 4594.08, "text": " So then we don't need any of this. So then weights actually will simply be...", "tokens": [407, 550, 321, 500, 380, 643, 604, 295, 341, 13, 407, 550, 17443, 767, 486, 2935, 312, 485], "temperature": 0.0, "avg_logprob": -0.15898697951744342, "compression_ratio": 1.4726027397260273, "no_speech_prob": 5.338084065442672e-06}, {"id": 681, "seek": 457708, "start": 4594.08, "end": 4597.08, "text": " That's our weighted data frame.", "tokens": [663, 311, 527, 32807, 1412, 3920, 13], "temperature": 0.0, "avg_logprob": -0.15898697951744342, "compression_ratio": 1.4726027397260273, "no_speech_prob": 5.338084065442672e-06}, {"id": 682, "seek": 457708, "start": 4597.08, "end": 4605.08, "text": " So basically what I would do here is this... well, actually, we'll go back to saying this is sort values.", "tokens": [407, 1936, 437, 286, 576, 360, 510, 307, 341, 485, 731, 11, 767, 11, 321, 603, 352, 646, 281, 1566, 341, 307, 1333, 4190, 13], "temperature": 0.0, "avg_logprob": -0.15898697951744342, "compression_ratio": 1.4726027397260273, "no_speech_prob": 5.338084065442672e-06}, {"id": 683, "seek": 460508, "start": 4605.08, "end": 4617.08, "text": " And then our weights will be WDF.labelY.", "tokens": [400, 550, 527, 17443, 486, 312, 343, 35, 37, 13, 75, 18657, 56, 13], "temperature": 0.0, "avg_logprob": -0.14797403262211725, "compression_ratio": 1.2857142857142858, "no_speech_prob": 7.465018279617652e-05}, {"id": 684, "seek": 460508, "start": 4617.08, "end": 4623.08, "text": " That's actually our weights as a NumPy.", "tokens": [663, 311, 767, 527, 17443, 382, 257, 22592, 47, 88, 13], "temperature": 0.0, "avg_logprob": -0.14797403262211725, "compression_ratio": 1.2857142857142858, "no_speech_prob": 7.465018279617652e-05}, {"id": 685, "seek": 460508, "start": 4623.08, "end": 4628.08, "text": " Silly question. Could you not just send a function for weights to the standard data block?", "tokens": [318, 6917, 1168, 13, 7497, 291, 406, 445, 2845, 257, 2445, 337, 17443, 281, 264, 3832, 1412, 3461, 30], "temperature": 0.0, "avg_logprob": -0.14797403262211725, "compression_ratio": 1.2857142857142858, "no_speech_prob": 7.465018279617652e-05}, {"id": 686, "seek": 462808, "start": 4628.08, "end": 4635.08, "text": " And if it doesn't get one, then it does nothing.", "tokens": [400, 498, 309, 1177, 380, 483, 472, 11, 550, 309, 775, 1825, 13], "temperature": 0.0, "avg_logprob": -0.1376586155015595, "compression_ratio": 1.2782608695652173, "no_speech_prob": 5.049107130616903e-05}, {"id": 687, "seek": 462808, "start": 4635.08, "end": 4647.08, "text": " Potentially, we could.", "tokens": [9145, 3137, 11, 321, 727, 13], "temperature": 0.0, "avg_logprob": -0.1376586155015595, "compression_ratio": 1.2782608695652173, "no_speech_prob": 5.049107130616903e-05}, {"id": 688, "seek": 462808, "start": 4647.08, "end": 4653.08, "text": " I kind of like this, though, because like, yeah, I don't know. It's like...", "tokens": [286, 733, 295, 411, 341, 11, 1673, 11, 570, 411, 11, 1338, 11, 286, 500, 380, 458, 13, 467, 311, 411, 485], "temperature": 0.0, "avg_logprob": -0.1376586155015595, "compression_ratio": 1.2782608695652173, "no_speech_prob": 5.049107130616903e-05}, {"id": 689, "seek": 465308, "start": 4653.08, "end": 4659.08, "text": " If weights were all one as a default, then we could use the one solution for...", "tokens": [759, 17443, 645, 439, 472, 382, 257, 7576, 11, 550, 321, 727, 764, 264, 472, 3827, 337, 485], "temperature": 0.0, "avg_logprob": -0.1289225342453167, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.9219609384890646e-05}, {"id": 690, "seek": 465308, "start": 4659.08, "end": 4666.08, "text": " Yeah, yeah, you could. I find it's a little bit too coupled for me. I don't love it, but it would be doable.", "tokens": [865, 11, 1338, 11, 291, 727, 13, 286, 915, 309, 311, 257, 707, 857, 886, 29482, 337, 385, 13, 286, 500, 380, 959, 309, 11, 457, 309, 576, 312, 41183, 13], "temperature": 0.0, "avg_logprob": -0.1289225342453167, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.9219609384890646e-05}, {"id": 691, "seek": 465308, "start": 4666.08, "end": 4670.08, "text": " Unnecessary multiplication, I suppose.", "tokens": [1156, 15975, 822, 27290, 11, 286, 7297, 13], "temperature": 0.0, "avg_logprob": -0.1289225342453167, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.9219609384890646e-05}, {"id": 692, "seek": 465308, "start": 4670.08, "end": 4679.08, "text": " You know, I like how nicely decoupled this is. So I think this is what I want it to look like.", "tokens": [509, 458, 11, 286, 411, 577, 9594, 979, 263, 15551, 341, 307, 13, 407, 286, 519, 341, 307, 437, 286, 528, 309, 281, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.1289225342453167, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.9219609384890646e-05}, {"id": 693, "seek": 467908, "start": 4679.08, "end": 4690.08, "text": " So...", "tokens": [407, 485], "temperature": 0.0, "avg_logprob": -0.11680955153245193, "compression_ratio": 1.1166666666666667, "no_speech_prob": 9.515911187918391e-06}, {"id": 694, "seek": 467908, "start": 4690.08, "end": 4695.08, "text": " So I would look at how the splitters work.", "tokens": [407, 286, 576, 574, 412, 577, 264, 7472, 1559, 589, 13], "temperature": 0.0, "avg_logprob": -0.11680955153245193, "compression_ratio": 1.1166666666666667, "no_speech_prob": 9.515911187918391e-06}, {"id": 695, "seek": 467908, "start": 4695.08, "end": 4699.08, "text": " So the splitter...", "tokens": [407, 264, 4732, 3904, 485], "temperature": 0.0, "avg_logprob": -0.11680955153245193, "compression_ratio": 1.1166666666666667, "no_speech_prob": 9.515911187918391e-06}, {"id": 696, "seek": 469908, "start": 4699.08, "end": 4709.08, "text": " OK, so the splits gets created here in datasets.", "tokens": [2264, 11, 370, 264, 37741, 2170, 2942, 510, 294, 42856, 13], "temperature": 0.0, "avg_logprob": -0.15410360168008244, "compression_ratio": 1.2121212121212122, "no_speech_prob": 1.4509861102851573e-05}, {"id": 697, "seek": 469908, "start": 4709.08, "end": 4716.08, "text": " Cool. And then...", "tokens": [8561, 13, 400, 550, 485], "temperature": 0.0, "avg_logprob": -0.15410360168008244, "compression_ratio": 1.2121212121212122, "no_speech_prob": 1.4509861102851573e-05}, {"id": 698, "seek": 469908, "start": 4716.08, "end": 4724.08, "text": " I wonder if datasets remembers what those splits are.", "tokens": [286, 2441, 498, 42856, 26228, 437, 729, 37741, 366, 13], "temperature": 0.0, "avg_logprob": -0.15410360168008244, "compression_ratio": 1.2121212121212122, "no_speech_prob": 1.4509861102851573e-05}, {"id": 699, "seek": 472408, "start": 4724.08, "end": 4734.08, "text": " Oh, I don't have tags here.", "tokens": [876, 11, 286, 500, 380, 362, 18632, 510, 13], "temperature": 0.0, "avg_logprob": -0.07471846617185153, "compression_ratio": 0.7714285714285715, "no_speech_prob": 5.061961564933881e-05}, {"id": 700, "seek": 473408, "start": 4734.08, "end": 4756.08, "text": " What do you mean no tags file?", "tokens": [50364, 708, 360, 291, 914, 572, 18632, 3991, 30, 51464], "temperature": 0.0, "avg_logprob": -0.3280500065196644, "compression_ratio": 0.7894736842105263, "no_speech_prob": 7.249289774335921e-05}, {"id": 701, "seek": 476408, "start": 4764.08, "end": 4768.08, "text": " OK, there we go. Datasets.", "tokens": [2264, 11, 456, 321, 352, 13, 9315, 296, 1385, 13], "temperature": 0.0, "avg_logprob": -0.21993550658226013, "compression_ratio": 1.2894736842105263, "no_speech_prob": 0.04738861322402954}, {"id": 702, "seek": 476408, "start": 4768.08, "end": 4778.08, "text": " So that's Ctrl-right-square-bracket to remind you to jump to a symbol in Vim.", "tokens": [407, 300, 311, 35233, 12, 1938, 12, 33292, 543, 12, 1443, 501, 302, 281, 4160, 291, 281, 3012, 281, 257, 5986, 294, 691, 332, 13], "temperature": 0.0, "avg_logprob": -0.21993550658226013, "compression_ratio": 1.2894736842105263, "no_speech_prob": 0.04738861322402954}, {"id": 703, "seek": 476408, "start": 4778.08, "end": 4783.08, "text": " I see. And that's actually mainly happening in this inheritance.", "tokens": [286, 536, 13, 400, 300, 311, 767, 8704, 2737, 294, 341, 32122, 13], "temperature": 0.0, "avg_logprob": -0.21993550658226013, "compression_ratio": 1.2894736842105263, "no_speech_prob": 0.04738861322402954}, {"id": 704, "seek": 476408, "start": 4783.08, "end": 4787.08, "text": " The superclass is where...", "tokens": [440, 1687, 11665, 307, 689, 485], "temperature": 0.0, "avg_logprob": -0.21993550658226013, "compression_ratio": 1.2894736842105263, "no_speech_prob": 0.04738861322402954}, {"id": 705, "seek": 478708, "start": 4787.08, "end": 4795.08, "text": " This is split stuff. Splits. I see. There is a splits.", "tokens": [639, 307, 7472, 1507, 13, 19788, 1208, 13, 286, 536, 13, 821, 307, 257, 37741, 13], "temperature": 0.0, "avg_logprob": -0.26464152917629336, "compression_ratio": 1.3076923076923077, "no_speech_prob": 3.1690029572928324e-05}, {"id": 706, "seek": 478708, "start": 4795.08, "end": 4800.08, "text": " So dss.splits.", "tokens": [407, 274, 3810, 13, 46535, 1208, 13], "temperature": 0.0, "avg_logprob": -0.26464152917629336, "compression_ratio": 1.3076923076923077, "no_speech_prob": 3.1690029572928324e-05}, {"id": 707, "seek": 478708, "start": 4800.08, "end": 4805.08, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.26464152917629336, "compression_ratio": 1.3076923076923077, "no_speech_prob": 3.1690029572928324e-05}, {"id": 708, "seek": 478708, "start": 4805.08, "end": 4810.08, "text": " dss.splits.", "tokens": [274, 3810, 13, 46535, 1208, 13], "temperature": 0.0, "avg_logprob": -0.26464152917629336, "compression_ratio": 1.3076923076923077, "no_speech_prob": 3.1690029572928324e-05}, {"id": 709, "seek": 481008, "start": 4810.08, "end": 4818.08, "text": " Yeah, so there's the indices of the training and test sets. And so that's the indices of the training set.", "tokens": [865, 11, 370, 456, 311, 264, 43840, 295, 264, 3097, 293, 1500, 6352, 13, 400, 370, 300, 311, 264, 43840, 295, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.12249050749109146, "compression_ratio": 1.5272727272727273, "no_speech_prob": 5.5073746807465795e-06}, {"id": 710, "seek": 481008, "start": 4818.08, "end": 4825.08, "text": " So the actual weights we want are those ones.", "tokens": [407, 264, 3539, 17443, 321, 528, 366, 729, 2306, 13], "temperature": 0.0, "avg_logprob": -0.12249050749109146, "compression_ratio": 1.5272727272727273, "no_speech_prob": 5.5073746807465795e-06}, {"id": 711, "seek": 481008, "start": 4825.08, "end": 4831.08, "text": " So over here...", "tokens": [407, 670, 510, 485], "temperature": 0.0, "avg_logprob": -0.12249050749109146, "compression_ratio": 1.5272727272727273, "no_speech_prob": 5.5073746807465795e-06}, {"id": 712, "seek": 483108, "start": 4831.08, "end": 4840.08, "text": " We can say training weights are...", "tokens": [492, 393, 584, 3097, 17443, 366, 485], "temperature": 0.0, "avg_logprob": -0.16712445923776337, "compression_ratio": 1.4225352112676057, "no_speech_prob": 1.2804506695829332e-05}, {"id": 713, "seek": 483108, "start": 4840.08, "end": 4844.08, "text": " So we'll change this to dataset from training set.", "tokens": [407, 321, 603, 1319, 341, 281, 28872, 490, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.16712445923776337, "compression_ratio": 1.4225352112676057, "no_speech_prob": 1.2804506695829332e-05}, {"id": 714, "seek": 483108, "start": 4844.08, "end": 4849.08, "text": " And so this will be the weights at those indices.", "tokens": [400, 370, 341, 486, 312, 264, 17443, 412, 729, 43840, 13], "temperature": 0.0, "avg_logprob": -0.16712445923776337, "compression_ratio": 1.4225352112676057, "no_speech_prob": 1.2804506695829332e-05}, {"id": 715, "seek": 483108, "start": 4849.08, "end": 4854.08, "text": " And that's what we'd use.", "tokens": [400, 300, 311, 437, 321, 1116, 764, 13], "temperature": 0.0, "avg_logprob": -0.16712445923776337, "compression_ratio": 1.4225352112676057, "no_speech_prob": 1.2804506695829332e-05}, {"id": 716, "seek": 483108, "start": 4854.08, "end": 4855.08, "text": " Like so.", "tokens": [1743, 370, 13], "temperature": 0.0, "avg_logprob": -0.16712445923776337, "compression_ratio": 1.4225352112676057, "no_speech_prob": 1.2804506695829332e-05}, {"id": 717, "seek": 483108, "start": 4855.08, "end": 4857.08, "text": " self.splits.", "tokens": [2698, 13, 46535, 1208, 13], "temperature": 0.0, "avg_logprob": -0.16712445923776337, "compression_ratio": 1.4225352112676057, "no_speech_prob": 1.2804506695829332e-05}, {"id": 718, "seek": 483108, "start": 4857.08, "end": 4860.08, "text": " Thank you so much.", "tokens": [1044, 291, 370, 709, 13], "temperature": 0.0, "avg_logprob": -0.16712445923776337, "compression_ratio": 1.4225352112676057, "no_speech_prob": 1.2804506695829332e-05}, {"id": 719, "seek": 486008, "start": 4860.08, "end": 4862.08, "text": " dss.splits.", "tokens": [274, 3810, 13, 46535, 1208, 13], "temperature": 0.0, "avg_logprob": -0.1000639990474401, "compression_ratio": 1.596938775510204, "no_speech_prob": 1.9832166799460538e-05}, {"id": 720, "seek": 486008, "start": 4862.08, "end": 4866.08, "text": " self is a data block and it's actually the dss that has the splits.", "tokens": [2698, 307, 257, 1412, 3461, 293, 309, 311, 767, 264, 274, 3810, 300, 575, 264, 37741, 13], "temperature": 0.0, "avg_logprob": -0.1000639990474401, "compression_ratio": 1.596938775510204, "no_speech_prob": 1.9832166799460538e-05}, {"id": 721, "seek": 486008, "start": 4866.08, "end": 4872.08, "text": " The data block has a function that knows how to split, but the split doesn't happen until you create it.", "tokens": [440, 1412, 3461, 575, 257, 2445, 300, 3255, 577, 281, 7472, 11, 457, 264, 7472, 1177, 380, 1051, 1826, 291, 1884, 309, 13], "temperature": 0.0, "avg_logprob": -0.1000639990474401, "compression_ratio": 1.596938775510204, "no_speech_prob": 1.9832166799460538e-05}, {"id": 722, "seek": 486008, "start": 4872.08, "end": 4877.08, "text": " That way you can get different random splits each time if you want them.", "tokens": [663, 636, 291, 393, 483, 819, 4974, 37741, 1184, 565, 498, 291, 528, 552, 13], "temperature": 0.0, "avg_logprob": -0.1000639990474401, "compression_ratio": 1.596938775510204, "no_speech_prob": 1.9832166799460538e-05}, {"id": 723, "seek": 486008, "start": 4877.08, "end": 4879.08, "text": " Thank you for checking though.", "tokens": [1044, 291, 337, 8568, 1673, 13], "temperature": 0.0, "avg_logprob": -0.1000639990474401, "compression_ratio": 1.596938775510204, "no_speech_prob": 1.9832166799460538e-05}, {"id": 724, "seek": 486008, "start": 4879.08, "end": 4882.08, "text": " OK, so I'll export that.", "tokens": [2264, 11, 370, 286, 603, 10725, 300, 13], "temperature": 0.0, "avg_logprob": -0.1000639990474401, "compression_ratio": 1.596938775510204, "no_speech_prob": 1.9832166799460538e-05}, {"id": 725, "seek": 488208, "start": 4882.08, "end": 4894.08, "text": " And probably be good to have auto load going, but we don't, so be it.", "tokens": [400, 1391, 312, 665, 281, 362, 8399, 3677, 516, 11, 457, 321, 500, 380, 11, 370, 312, 309, 13], "temperature": 0.0, "avg_logprob": -0.16262193962379737, "compression_ratio": 0.9605263157894737, "no_speech_prob": 3.31969240505714e-05}, {"id": 726, "seek": 488208, "start": 4894.08, "end": 4904.08, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.16262193962379737, "compression_ratio": 0.9605263157894737, "no_speech_prob": 3.31969240505714e-05}, {"id": 727, "seek": 490408, "start": 4904.08, "end": 4919.08, "text": " Now that we did miss a self, but it's not the one you thought of.", "tokens": [823, 300, 321, 630, 1713, 257, 2698, 11, 457, 309, 311, 406, 264, 472, 291, 1194, 295, 13], "temperature": 0.0, "avg_logprob": -0.1758286782673427, "compression_ratio": 1.0126582278481013, "no_speech_prob": 7.836077566025779e-05}, {"id": 728, "seek": 490408, "start": 4919.08, "end": 4931.08, "text": " This one here.", "tokens": [639, 472, 510, 13], "temperature": 0.0, "avg_logprob": -0.1758286782673427, "compression_ratio": 1.0126582278481013, "no_speech_prob": 7.836077566025779e-05}, {"id": 729, "seek": 493108, "start": 4931.08, "end": 4934.08, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.21361513137817384, "compression_ratio": 0.5294117647058824, "no_speech_prob": 3.1685151043348014e-05}, {"id": 730, "seek": 493108, "start": 4934.08, "end": 4956.08, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.21361513137817384, "compression_ratio": 0.5294117647058824, "no_speech_prob": 3.1685151043348014e-05}, {"id": 731, "seek": 495608, "start": 4956.08, "end": 4974.08, "text": " I guess actually if I just comment this out, then we can just run all above without worrying.", "tokens": [286, 2041, 767, 498, 286, 445, 2871, 341, 484, 11, 550, 321, 393, 445, 1190, 439, 3673, 1553, 18788, 13], "temperature": 0.0, "avg_logprob": -0.14797509417814367, "compression_ratio": 1.158878504672897, "no_speech_prob": 4.356552381068468e-06}, {"id": 732, "seek": 495608, "start": 4974.08, "end": 4977.08, "text": " Aha! OK, things are happening.", "tokens": [27448, 0, 2264, 11, 721, 366, 2737, 13], "temperature": 0.0, "avg_logprob": -0.14797509417814367, "compression_ratio": 1.158878504672897, "no_speech_prob": 4.356552381068468e-06}, {"id": 733, "seek": 497708, "start": 4977.08, "end": 4994.08, "text": " So dls equals that.", "tokens": [407, 37873, 82, 6915, 300, 13], "temperature": 0.0, "avg_logprob": -0.15215252339839935, "compression_ratio": 1.0470588235294118, "no_speech_prob": 4.494134827837115e-06}, {"id": 734, "seek": 497708, "start": 4994.08, "end": 4997.08, "text": " OK, that looks pretty good.", "tokens": [2264, 11, 300, 1542, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.15215252339839935, "compression_ratio": 1.0470588235294118, "no_speech_prob": 4.494134827837115e-06}, {"id": 735, "seek": 497708, "start": 4997.08, "end": 5004.08, "text": " OK, so I think we've created our feature.", "tokens": [2264, 11, 370, 286, 519, 321, 600, 2942, 527, 4111, 13], "temperature": 0.0, "avg_logprob": -0.15215252339839935, "compression_ratio": 1.0470588235294118, "no_speech_prob": 4.494134827837115e-06}, {"id": 736, "seek": 500408, "start": 5004.08, "end": 5017.08, "text": " So then the next thing I would do is to, it would be very, very weird if any tests broke, but I would go ahead and run the tests.", "tokens": [407, 550, 264, 958, 551, 286, 576, 360, 307, 281, 11, 309, 576, 312, 588, 11, 588, 3657, 498, 604, 6921, 6902, 11, 457, 286, 576, 352, 2286, 293, 1190, 264, 6921, 13], "temperature": 0.0, "avg_logprob": -0.09984160758353569, "compression_ratio": 1.2772277227722773, "no_speech_prob": 4.7547935537295416e-05}, {"id": 737, "seek": 501708, "start": 5017.08, "end": 5035.08, "text": " I would then create an issue for my feature, and so I've got a bunch of tiny little aliases and functions, one's called enhancement, which creates an issue with the enhancement label.", "tokens": [286, 576, 550, 1884, 364, 2734, 337, 452, 4111, 11, 293, 370, 286, 600, 658, 257, 3840, 295, 5870, 707, 10198, 1957, 293, 6828, 11, 472, 311, 1219, 40776, 11, 597, 7829, 364, 2734, 365, 264, 40776, 7645, 13], "temperature": 0.0, "avg_logprob": -0.08985250495200933, "compression_ratio": 1.4296875, "no_speech_prob": 8.800338036962785e-06}, {"id": 738, "seek": 503508, "start": 5035.08, "end": 5049.08, "text": " So I'll go enhancement, add data block dot weighted data loaders.", "tokens": [407, 286, 603, 352, 40776, 11, 909, 1412, 3461, 5893, 32807, 1412, 3677, 433, 13], "temperature": 0.0, "avg_logprob": -0.1671458412619198, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.4062415175430942e-05}, {"id": 739, "seek": 503508, "start": 5049.08, "end": 5053.08, "text": " So that creates the issue.", "tokens": [407, 300, 7829, 264, 2734, 13], "temperature": 0.0, "avg_logprob": -0.1671458412619198, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.4062415175430942e-05}, {"id": 740, "seek": 503508, "start": 5053.08, "end": 5056.08, "text": " As 3706.", "tokens": [1018, 805, 5867, 21, 13], "temperature": 0.0, "avg_logprob": -0.1671458412619198, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.4062415175430942e-05}, {"id": 741, "seek": 503508, "start": 5056.08, "end": 5062.08, "text": " So if you were interested, you could take a look at that issue.", "tokens": [407, 498, 291, 645, 3102, 11, 291, 727, 747, 257, 574, 412, 300, 2734, 13], "temperature": 0.0, "avg_logprob": -0.1671458412619198, "compression_ratio": 1.2992125984251968, "no_speech_prob": 1.4062415175430942e-05}, {"id": 742, "seek": 506208, "start": 5062.08, "end": 5069.08, "text": " Not the world's most interesting issue, but there it is.", "tokens": [1726, 264, 1002, 311, 881, 1880, 2734, 11, 457, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.19036828226117947, "compression_ratio": 1.4267515923566878, "no_speech_prob": 1.3005995242565405e-05}, {"id": 743, "seek": 506208, "start": 5069.08, "end": 5078.08, "text": " All right, looks like the tests are basically, oh, no, we've got an issue. There we go. So we've got a test that's failed.", "tokens": [1057, 558, 11, 1542, 411, 264, 6921, 366, 1936, 11, 1954, 11, 572, 11, 321, 600, 658, 364, 2734, 13, 821, 321, 352, 13, 407, 321, 600, 658, 257, 1500, 300, 311, 7612, 13], "temperature": 0.0, "avg_logprob": -0.19036828226117947, "compression_ratio": 1.4267515923566878, "no_speech_prob": 1.3005995242565405e-05}, {"id": 744, "seek": 506208, "start": 5078.08, "end": 5083.08, "text": " Range index must be integers or slices.", "tokens": [33778, 8186, 1633, 312, 41674, 420, 19793, 13], "temperature": 0.0, "avg_logprob": -0.19036828226117947, "compression_ratio": 1.4267515923566878, "no_speech_prob": 1.3005995242565405e-05}, {"id": 745, "seek": 506208, "start": 5083.08, "end": 5085.08, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.19036828226117947, "compression_ratio": 1.4267515923566878, "no_speech_prob": 1.3005995242565405e-05}, {"id": 746, "seek": 508508, "start": 5085.08, "end": 5096.08, "text": " Right. So I'm glad we checked.", "tokens": [1779, 13, 407, 286, 478, 5404, 321, 10033, 13], "temperature": 0.0, "avg_logprob": -0.1482989237858699, "compression_ratio": 0.7894736842105263, "no_speech_prob": 3.138044803563389e-06}, {"id": 747, "seek": 509608, "start": 5096.08, "end": 5116.08, "text": " OK, so the problem here is that I sliced into my weights on the assumption that this is something I can slice into, which would only be true if it was a tensor or an array.", "tokens": [2264, 11, 370, 264, 1154, 510, 307, 300, 286, 27098, 666, 452, 17443, 322, 264, 15302, 300, 341, 307, 746, 286, 393, 13153, 666, 11, 597, 576, 787, 312, 2074, 498, 309, 390, 257, 40863, 420, 364, 10225, 13], "temperature": 0.0, "avg_logprob": -0.08277901665109103, "compression_ratio": 1.49079754601227, "no_speech_prob": 1.577904868099722e-06}, {"id": 748, "seek": 509608, "start": 5116.08, "end": 5125.08, "text": " But in this case, actually, my weights are not either of those things.", "tokens": [583, 294, 341, 1389, 11, 767, 11, 452, 17443, 366, 406, 2139, 295, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.08277901665109103, "compression_ratio": 1.49079754601227, "no_speech_prob": 1.577904868099722e-06}, {"id": 749, "seek": 512508, "start": 5125.08, "end": 5128.08, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.21644135010548127, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.9221915863454342e-05}, {"id": 750, "seek": 512508, "start": 5128.08, "end": 5131.08, "text": " What would I do to fix that?", "tokens": [708, 576, 286, 360, 281, 3191, 300, 30], "temperature": 0.0, "avg_logprob": -0.21644135010548127, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.9221915863454342e-05}, {"id": 751, "seek": 512508, "start": 5131.08, "end": 5134.08, "text": " There's a question here. Yeah.", "tokens": [821, 311, 257, 1168, 510, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.21644135010548127, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.9221915863454342e-05}, {"id": 752, "seek": 512508, "start": 5134.08, "end": 5140.08, "text": " When you split, you only get you back the index of the training and validation data set.", "tokens": [1133, 291, 7472, 11, 291, 787, 483, 291, 646, 264, 8186, 295, 264, 3097, 293, 24071, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.21644135010548127, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.9221915863454342e-05}, {"id": 753, "seek": 512508, "start": 5140.08, "end": 5148.08, "text": " And how can you know this is the weights because you haven't actually do the calculation and do the inverse of one square root kind of thing.", "tokens": [400, 577, 393, 291, 458, 341, 307, 264, 17443, 570, 291, 2378, 380, 767, 360, 264, 17108, 293, 360, 264, 17340, 295, 472, 3732, 5593, 733, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.21644135010548127, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.9221915863454342e-05}, {"id": 754, "seek": 514808, "start": 5148.08, "end": 5157.08, "text": " The weights are being passed in as a parameter. And so we calculated the weights up here.", "tokens": [440, 17443, 366, 885, 4678, 294, 382, 257, 13075, 13, 400, 370, 321, 15598, 264, 17443, 493, 510, 13], "temperature": 0.0, "avg_logprob": -0.10210102796554565, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.494610493566142e-06}, {"id": 755, "seek": 514808, "start": 5157.08, "end": 5164.08, "text": " Yep. And then we passed them in. Yeah.", "tokens": [7010, 13, 400, 550, 321, 4678, 552, 294, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.10210102796554565, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.494610493566142e-06}, {"id": 756, "seek": 514808, "start": 5164.08, "end": 5167.08, "text": " What's the incorrect type that's coming through in the test?", "tokens": [708, 311, 264, 18424, 2010, 300, 311, 1348, 807, 294, 264, 1500, 30], "temperature": 0.0, "avg_logprob": -0.10210102796554565, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.494610493566142e-06}, {"id": 757, "seek": 514808, "start": 5167.08, "end": 5177.08, "text": " It's not that it's an incorrect type. It's that see how here I'm indexing into the weights using my splits.", "tokens": [467, 311, 406, 300, 309, 311, 364, 18424, 2010, 13, 467, 311, 300, 536, 577, 510, 286, 478, 8186, 278, 666, 264, 17443, 1228, 452, 37741, 13], "temperature": 0.0, "avg_logprob": -0.10210102796554565, "compression_ratio": 1.6779661016949152, "no_speech_prob": 4.494610493566142e-06}, {"id": 758, "seek": 517708, "start": 5177.08, "end": 5184.08, "text": " This here is a list or an array. You can't index into a Python list with a list.", "tokens": [639, 510, 307, 257, 1329, 420, 364, 10225, 13, 509, 393, 380, 8186, 666, 257, 15329, 1329, 365, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.17215046325287262, "compression_ratio": 1.5595238095238095, "no_speech_prob": 3.340434204801568e-06}, {"id": 759, "seek": 517708, "start": 5184.08, "end": 5191.08, "text": " You can only do that with tensors or non-py arrays.", "tokens": [509, 393, 787, 360, 300, 365, 10688, 830, 420, 2107, 12, 8200, 41011, 13], "temperature": 0.0, "avg_logprob": -0.17215046325287262, "compression_ratio": 1.5595238095238095, "no_speech_prob": 3.340434204801568e-06}, {"id": 760, "seek": 517708, "start": 5191.08, "end": 5201.08, "text": " Yeah, I mean, what we actually want to do is check whether it's an array type.", "tokens": [865, 11, 286, 914, 11, 437, 321, 767, 528, 281, 360, 307, 1520, 1968, 309, 311, 364, 10225, 2010, 13], "temperature": 0.0, "avg_logprob": -0.17215046325287262, "compression_ratio": 1.5595238095238095, "no_speech_prob": 3.340434204801568e-06}, {"id": 761, "seek": 517708, "start": 5201.08, "end": 5205.08, "text": " Is there an is a listy or something that function?", "tokens": [1119, 456, 364, 307, 257, 1329, 88, 420, 746, 300, 2445, 30], "temperature": 0.0, "avg_logprob": -0.17215046325287262, "compression_ratio": 1.5595238095238095, "no_speech_prob": 3.340434204801568e-06}, {"id": 762, "seek": 520508, "start": 5205.08, "end": 5216.08, "text": " There is, but that's not quite I think what the opposite, which is, is this the kind of thing that one could expect to be able to do non-py style indexing on?", "tokens": [821, 307, 11, 457, 300, 311, 406, 1596, 286, 519, 437, 264, 6182, 11, 597, 307, 11, 307, 341, 264, 733, 295, 551, 300, 472, 727, 2066, 281, 312, 1075, 281, 360, 2107, 12, 8200, 3758, 8186, 278, 322, 30], "temperature": 0.0, "avg_logprob": -0.10936556922064887, "compression_ratio": 1.4777070063694266, "no_speech_prob": 3.4462991607142612e-06}, {"id": 763, "seek": 520508, "start": 5216.08, "end": 5230.08, "text": " And I believe the correct way to do that might be to look for this thing.", "tokens": [400, 286, 1697, 264, 3006, 636, 281, 360, 300, 1062, 312, 281, 574, 337, 341, 551, 13], "temperature": 0.0, "avg_logprob": -0.10936556922064887, "compression_ratio": 1.4777070063694266, "no_speech_prob": 3.4462991607142612e-06}, {"id": 764, "seek": 523008, "start": 5230.08, "end": 5242.08, "text": " Yeah. So I would be inclined to say.", "tokens": [865, 13, 407, 286, 576, 312, 28173, 281, 584, 13], "temperature": 0.0, "avg_logprob": -0.2010232413687357, "compression_ratio": 1.2586206896551724, "no_speech_prob": 8.267607881862205e-06}, {"id": 765, "seek": 523008, "start": 5242.08, "end": 5253.08, "text": " And there may, there may well already be something in fast AI that knows how to check for this, to be honest.", "tokens": [400, 456, 815, 11, 456, 815, 731, 1217, 312, 746, 294, 2370, 7318, 300, 3255, 577, 281, 1520, 337, 341, 11, 281, 312, 3245, 13], "temperature": 0.0, "avg_logprob": -0.2010232413687357, "compression_ratio": 1.2586206896551724, "no_speech_prob": 8.267607881862205e-06}, {"id": 766, "seek": 525308, "start": 5253.08, "end": 5262.08, "text": " Oh, WG.", "tokens": [876, 11, 343, 38, 13], "temperature": 0.0, "avg_logprob": -0.3744516372680664, "compression_ratio": 0.9523809523809523, "no_speech_prob": 3.4465053886378882e-06}, {"id": 767, "seek": 525308, "start": 5262.08, "end": 5272.08, "text": " Okay. So this what's this thing?", "tokens": [1033, 13, 407, 341, 437, 311, 341, 551, 30], "temperature": 0.0, "avg_logprob": -0.3744516372680664, "compression_ratio": 0.9523809523809523, "no_speech_prob": 3.4465053886378882e-06}, {"id": 768, "seek": 527208, "start": 5272.08, "end": 5286.08, "text": " Oh, that's something that's commented out. All right. So I guess I don't have anything which checks for that. So we'll just do it manually. So if weights has the Dunder array attribute.", "tokens": [876, 11, 300, 311, 746, 300, 311, 26940, 484, 13, 1057, 558, 13, 407, 286, 2041, 286, 500, 380, 362, 1340, 597, 13834, 337, 300, 13, 407, 321, 603, 445, 360, 309, 16945, 13, 407, 498, 17443, 575, 264, 413, 6617, 10225, 19667, 13], "temperature": 0.0, "avg_logprob": -0.0788203006566957, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.6687101783172693e-06}, {"id": 769, "seek": 527208, "start": 5286.08, "end": 5292.08, "text": " Because I'm pretty sure that tensors have that as well.", "tokens": [1436, 286, 478, 1238, 988, 300, 10688, 830, 362, 300, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.0788203006566957, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.6687101783172693e-06}, {"id": 770, "seek": 527208, "start": 5292.08, "end": 5301.08, "text": " Yeah, it does. So if it has that attribute, then I think we're good to go.", "tokens": [865, 11, 309, 775, 13, 407, 498, 309, 575, 300, 19667, 11, 550, 286, 519, 321, 434, 665, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.0788203006566957, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.6687101783172693e-06}, {"id": 771, "seek": 530108, "start": 5301.08, "end": 5307.08, "text": " Otherwise, we can use a list comprehension.", "tokens": [10328, 11, 321, 393, 764, 257, 1329, 44991, 13], "temperature": 0.0, "avg_logprob": -0.12102239173755311, "compression_ratio": 1.303030303030303, "no_speech_prob": 9.972607585950755e-06}, {"id": 772, "seek": 530108, "start": 5307.08, "end": 5311.08, "text": " Oh, you know what we could do?", "tokens": [876, 11, 291, 458, 437, 321, 727, 360, 30], "temperature": 0.0, "avg_logprob": -0.12102239173755311, "compression_ratio": 1.303030303030303, "no_speech_prob": 9.972607585950755e-06}, {"id": 773, "seek": 530108, "start": 5311.08, "end": 5320.08, "text": " Yeah. Okay. What we'll do is we'll just say if it doesn't have that.", "tokens": [865, 13, 1033, 13, 708, 321, 603, 360, 307, 321, 603, 445, 584, 498, 309, 1177, 380, 362, 300, 13], "temperature": 0.0, "avg_logprob": -0.12102239173755311, "compression_ratio": 1.303030303030303, "no_speech_prob": 9.972607585950755e-06}, {"id": 774, "seek": 530108, "start": 5320.08, "end": 5324.08, "text": " I don't know if this is too,", "tokens": [286, 500, 380, 458, 498, 341, 307, 886, 11], "temperature": 0.0, "avg_logprob": -0.12102239173755311, "compression_ratio": 1.303030303030303, "no_speech_prob": 9.972607585950755e-06}, {"id": 775, "seek": 532408, "start": 5324.08, "end": 5332.08, "text": " too rude to change their weights.", "tokens": [886, 18895, 281, 1319, 641, 17443, 13], "temperature": 0.0, "avg_logprob": -0.23681724605275623, "compression_ratio": 1.3647798742138364, "no_speech_prob": 1.3006424524064641e-05}, {"id": 776, "seek": 532408, "start": 5332.08, "end": 5335.08, "text": " But I think this is fine.", "tokens": [583, 286, 519, 341, 307, 2489, 13], "temperature": 0.0, "avg_logprob": -0.23681724605275623, "compression_ratio": 1.3647798742138364, "no_speech_prob": 1.3006424524064641e-05}, {"id": 777, "seek": 532408, "start": 5335.08, "end": 5337.08, "text": " It's making an array.", "tokens": [467, 311, 1455, 364, 10225, 13], "temperature": 0.0, "avg_logprob": -0.23681724605275623, "compression_ratio": 1.3647798742138364, "no_speech_prob": 1.3006424524064641e-05}, {"id": 778, "seek": 532408, "start": 5337.08, "end": 5342.08, "text": " Not a NumPy type array. It's probably going to benefit from being converted to one anyway, right?", "tokens": [1726, 257, 22592, 47, 88, 2010, 10225, 13, 467, 311, 1391, 516, 281, 5121, 490, 885, 16424, 281, 472, 4033, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23681724605275623, "compression_ratio": 1.3647798742138364, "no_speech_prob": 1.3006424524064641e-05}, {"id": 779, "seek": 532408, "start": 5342.08, "end": 5347.08, "text": " Yeah, I mean, I don't see a downside.", "tokens": [865, 11, 286, 914, 11, 286, 500, 380, 536, 257, 25060, 13], "temperature": 0.0, "avg_logprob": -0.23681724605275623, "compression_ratio": 1.3647798742138364, "no_speech_prob": 1.3006424524064641e-05}, {"id": 780, "seek": 534708, "start": 5347.08, "end": 5355.08, "text": " Passes our test.", "tokens": [10319, 279, 527, 1500, 13], "temperature": 0.0, "avg_logprob": -0.18153086952541186, "compression_ratio": 1.1592920353982301, "no_speech_prob": 1.0129409929504618e-05}, {"id": 781, "seek": 534708, "start": 5355.08, "end": 5358.08, "text": " Okay, so.", "tokens": [1033, 11, 370, 13], "temperature": 0.0, "avg_logprob": -0.18153086952541186, "compression_ratio": 1.1592920353982301, "no_speech_prob": 1.0129409929504618e-05}, {"id": 782, "seek": 534708, "start": 5358.08, "end": 5367.08, "text": " And that was our only test that failed, which is now passing.", "tokens": [400, 300, 390, 527, 787, 1500, 300, 7612, 11, 597, 307, 586, 8437, 13], "temperature": 0.0, "avg_logprob": -0.18153086952541186, "compression_ratio": 1.1592920353982301, "no_speech_prob": 1.0129409929504618e-05}, {"id": 783, "seek": 534708, "start": 5367.08, "end": 5374.08, "text": " So I would now say we've fixed issue 3706.", "tokens": [407, 286, 576, 586, 584, 321, 600, 6806, 2734, 805, 5867, 21, 13], "temperature": 0.0, "avg_logprob": -0.18153086952541186, "compression_ratio": 1.1592920353982301, "no_speech_prob": 1.0129409929504618e-05}, {"id": 784, "seek": 537408, "start": 5374.08, "end": 5383.08, "text": " So I've got to fix this little function that does that 3706.", "tokens": [407, 286, 600, 658, 281, 3191, 341, 707, 2445, 300, 775, 300, 805, 5867, 21, 13], "temperature": 0.0, "avg_logprob": -0.1768498841454001, "compression_ratio": 1.0842105263157895, "no_speech_prob": 2.01439434022177e-05}, {"id": 785, "seek": 537408, "start": 5383.08, "end": 5391.08, "text": " Okay. And so now if we look at that issue,", "tokens": [1033, 13, 400, 370, 586, 498, 321, 574, 412, 300, 2734, 11], "temperature": 0.0, "avg_logprob": -0.1768498841454001, "compression_ratio": 1.0842105263157895, "no_speech_prob": 2.01439434022177e-05}, {"id": 786, "seek": 539108, "start": 5391.08, "end": 5406.08, "text": " you'll see that it's been resolved using this commit.", "tokens": [291, 603, 536, 300, 309, 311, 668, 20772, 1228, 341, 5599, 13], "temperature": 0.0, "avg_logprob": -0.14641428928749234, "compression_ratio": 1.3615384615384616, "no_speech_prob": 1.4736663615622092e-05}, {"id": 787, "seek": 539108, "start": 5406.08, "end": 5407.08, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.14641428928749234, "compression_ratio": 1.3615384615384616, "no_speech_prob": 1.4736663615622092e-05}, {"id": 788, "seek": 539108, "start": 5407.08, "end": 5409.08, "text": " But what do you commit from the notebook?", "tokens": [583, 437, 360, 291, 5599, 490, 264, 21060, 30], "temperature": 0.0, "avg_logprob": -0.14641428928749234, "compression_ratio": 1.3615384615384616, "no_speech_prob": 1.4736663615622092e-05}, {"id": 789, "seek": 539108, "start": 5409.08, "end": 5415.08, "text": " Do you sort of have it like reset with empty cells or do you run the cells?", "tokens": [1144, 291, 1333, 295, 362, 309, 411, 14322, 365, 6707, 5438, 420, 360, 291, 1190, 264, 5438, 30], "temperature": 0.0, "avg_logprob": -0.14641428928749234, "compression_ratio": 1.3615384615384616, "no_speech_prob": 1.4736663615622092e-05}, {"id": 790, "seek": 541508, "start": 5415.08, "end": 5424.08, "text": " I commit them basically however they are, but with unnecessary metadata removed.", "tokens": [286, 5599, 552, 1936, 4461, 436, 366, 11, 457, 365, 19350, 26603, 7261, 13], "temperature": 0.0, "avg_logprob": -0.07375943443991921, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.045039425662253e-05}, {"id": 791, "seek": 541508, "start": 5424.08, "end": 5432.08, "text": " So there's a hook that automatically runs this function,", "tokens": [407, 456, 311, 257, 6328, 300, 6772, 6676, 341, 2445, 11], "temperature": 0.0, "avg_logprob": -0.07375943443991921, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.045039425662253e-05}, {"id": 792, "seek": 541508, "start": 5432.08, "end": 5439.08, "text": " which is the thing that removes stuff like the execution count,", "tokens": [597, 307, 264, 551, 300, 30445, 1507, 411, 264, 15058, 1207, 11], "temperature": 0.0, "avg_logprob": -0.07375943443991921, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.045039425662253e-05}, {"id": 793, "seek": 541508, "start": 5439.08, "end": 5443.08, "text": " unnecessary notebook metadata, stuff like that.", "tokens": [19350, 21060, 26603, 11, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.07375943443991921, "compression_ratio": 1.5660377358490567, "no_speech_prob": 1.045039425662253e-05}, {"id": 794, "seek": 544308, "start": 5443.08, "end": 5449.08, "text": " So the idea is that the notebooks want to have all the outputs in place", "tokens": [407, 264, 1558, 307, 300, 264, 43782, 528, 281, 362, 439, 264, 23930, 294, 1081], "temperature": 0.0, "avg_logprob": -0.09154774306656478, "compression_ratio": 1.6323529411764706, "no_speech_prob": 7.645769983355422e-06}, {"id": 795, "seek": 544308, "start": 5449.08, "end": 5452.08, "text": " because they get turned into documentation.", "tokens": [570, 436, 483, 3574, 666, 14333, 13], "temperature": 0.0, "avg_logprob": -0.09154774306656478, "compression_ratio": 1.6323529411764706, "no_speech_prob": 7.645769983355422e-06}, {"id": 796, "seek": 544308, "start": 5452.08, "end": 5458.08, "text": " And we wouldn't want to run them all in continuous integration to create the documentation", "tokens": [400, 321, 2759, 380, 528, 281, 1190, 552, 439, 294, 10957, 10980, 281, 1884, 264, 14333], "temperature": 0.0, "avg_logprob": -0.09154774306656478, "compression_ratio": 1.6323529411764706, "no_speech_prob": 7.645769983355422e-06}, {"id": 797, "seek": 544308, "start": 5458.08, "end": 5464.08, "text": " because they can involve spending 10 hours training an NLP model, for example.", "tokens": [570, 436, 393, 9494, 6434, 1266, 2496, 3097, 364, 426, 45196, 2316, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.09154774306656478, "compression_ratio": 1.6323529411764706, "no_speech_prob": 7.645769983355422e-06}, {"id": 798, "seek": 544308, "start": 5464.08, "end": 5467.08, "text": " So we don't remove the outputs for that reason.", "tokens": [407, 321, 500, 380, 4159, 264, 23930, 337, 300, 1778, 13], "temperature": 0.0, "avg_logprob": -0.09154774306656478, "compression_ratio": 1.6323529411764706, "no_speech_prob": 7.645769983355422e-06}, {"id": 799, "seek": 546708, "start": 5467.08, "end": 5478.08, "text": " And also because I want people to be able to look at the notebooks in GitHub and see, you know, all the pictures and stuff.", "tokens": [400, 611, 570, 286, 528, 561, 281, 312, 1075, 281, 574, 412, 264, 43782, 294, 23331, 293, 536, 11, 291, 458, 11, 439, 264, 5242, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.11172039207370801, "compression_ratio": 1.4644549763033174, "no_speech_prob": 9.36859487410402e-06}, {"id": 800, "seek": 546708, "start": 5478.08, "end": 5485.08, "text": " All right. I better stop there. Oh, that's interesting. Did I?", "tokens": [1057, 558, 13, 286, 1101, 1590, 456, 13, 876, 11, 300, 311, 1880, 13, 2589, 286, 30], "temperature": 0.0, "avg_logprob": -0.11172039207370801, "compression_ratio": 1.4644549763033174, "no_speech_prob": 9.36859487410402e-06}, {"id": 801, "seek": 546708, "start": 5485.08, "end": 5489.08, "text": " Okay. I guess I don't have my hook installed. So I'm glad I ran that manually.", "tokens": [1033, 13, 286, 2041, 286, 500, 380, 362, 452, 6328, 8899, 13, 407, 286, 478, 5404, 286, 5872, 300, 16945, 13], "temperature": 0.0, "avg_logprob": -0.11172039207370801, "compression_ratio": 1.4644549763033174, "no_speech_prob": 9.36859487410402e-06}, {"id": 802, "seek": 546708, "start": 5489.08, "end": 5491.08, "text": " So you can see exactly what it does, right?", "tokens": [407, 291, 393, 536, 2293, 437, 309, 775, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.11172039207370801, "compression_ratio": 1.4644549763033174, "no_speech_prob": 9.36859487410402e-06}, {"id": 803, "seek": 549108, "start": 5491.08, "end": 5500.08, "text": " Empties out the execution counts and removes the metadata.", "tokens": [3968, 662, 530, 484, 264, 15058, 14893, 293, 30445, 264, 26603, 13], "temperature": 0.0, "avg_logprob": -0.23582863807678223, "compression_ratio": 1.3928571428571428, "no_speech_prob": 3.0240082196542062e-05}, {"id": 804, "seek": 549108, "start": 5500.08, "end": 5506.08, "text": " Sorry for another question. I'm just trying to find it. Is that GitHub available in the repo or do you do?", "tokens": [4919, 337, 1071, 1168, 13, 286, 478, 445, 1382, 281, 915, 309, 13, 1119, 300, 23331, 2435, 294, 264, 49040, 420, 360, 291, 360, 30], "temperature": 0.0, "avg_logprob": -0.23582863807678223, "compression_ratio": 1.3928571428571428, "no_speech_prob": 3.0240082196542062e-05}, {"id": 805, "seek": 549108, "start": 5506.08, "end": 5515.08, "text": " Yeah. So it's if you go MB dev install GitHub, it installs the hook.", "tokens": [865, 13, 407, 309, 311, 498, 291, 352, 28866, 1905, 3625, 23331, 11, 309, 3625, 82, 264, 6328, 13], "temperature": 0.0, "avg_logprob": -0.23582863807678223, "compression_ratio": 1.3928571428571428, "no_speech_prob": 3.0240082196542062e-05}, {"id": 806, "seek": 551508, "start": 5515.08, "end": 5526.08, "text": " And specifically, it's going to see. Is that under NBS folder? No, this is part of NB dev.", "tokens": [400, 4682, 11, 309, 311, 516, 281, 536, 13, 1119, 300, 833, 426, 8176, 10820, 30, 883, 11, 341, 307, 644, 295, 426, 33, 1905, 13], "temperature": 0.0, "avg_logprob": -0.2297742970784505, "compression_ratio": 1.3932584269662922, "no_speech_prob": 8.397209057875443e-06}, {"id": 807, "seek": 551508, "start": 5526.08, "end": 5530.08, "text": " Oh, OK. Right. So once that package is installed, it's a built in command in there.", "tokens": [876, 11, 2264, 13, 1779, 13, 407, 1564, 300, 7372, 307, 8899, 11, 309, 311, 257, 3094, 294, 5622, 294, 456, 13], "temperature": 0.0, "avg_logprob": -0.2297742970784505, "compression_ratio": 1.3932584269662922, "no_speech_prob": 8.397209057875443e-06}, {"id": 808, "seek": 551508, "start": 5530.08, "end": 5536.08, "text": " And so that then installs a filter here. I'll read more about it. Thanks.", "tokens": [400, 370, 300, 550, 3625, 82, 257, 6608, 510, 13, 286, 603, 1401, 544, 466, 309, 13, 2561, 13], "temperature": 0.0, "avg_logprob": -0.2297742970784505, "compression_ratio": 1.3932584269662922, "no_speech_prob": 8.397209057875443e-06}, {"id": 809, "seek": 553608, "start": 5536.08, "end": 5549.08, "text": " And it also installs a get hook to trust the notebooks, which calls NB dev trust NBs.", "tokens": [400, 309, 611, 3625, 82, 257, 483, 6328, 281, 3361, 264, 43782, 11, 597, 5498, 426, 33, 1905, 3361, 426, 33, 82, 13], "temperature": 0.0, "avg_logprob": -0.26892772940702214, "compression_ratio": 1.25, "no_speech_prob": 4.356499175628414e-06}, {"id": 810, "seek": 553608, "start": 5549.08, "end": 5556.08, "text": " Anyway, yeah, that's all in the NB dev docs.", "tokens": [5684, 11, 1338, 11, 300, 311, 439, 294, 264, 426, 33, 1905, 45623, 13], "temperature": 0.0, "avg_logprob": -0.26892772940702214, "compression_ratio": 1.25, "no_speech_prob": 4.356499175628414e-06}, {"id": 811, "seek": 555608, "start": 5556.08, "end": 5580.08, "text": " And then what's going to happen now on the fast AI on the GitHub side is it's now busily running all the tests again.", "tokens": [400, 550, 437, 311, 516, 281, 1051, 586, 322, 264, 2370, 7318, 322, 264, 23331, 1252, 307, 309, 311, 586, 1255, 953, 2614, 439, 264, 6921, 797, 13], "temperature": 0.0, "avg_logprob": -0.1574993133544922, "compression_ratio": 1.21875, "no_speech_prob": 7.410904800053686e-06}, {"id": 812, "seek": 558008, "start": 5580.08, "end": 5587.08, "text": " Like so. And one of the things that checks is to make sure that the notebooks are clean and that the exports been run.", "tokens": [1743, 370, 13, 400, 472, 295, 264, 721, 300, 13834, 307, 281, 652, 988, 300, 264, 43782, 366, 2541, 293, 300, 264, 31428, 668, 1190, 13], "temperature": 0.0, "avg_logprob": -0.21715823535261483, "compression_ratio": 1.4966442953020134, "no_speech_prob": 1.0608610864437651e-05}, {"id": 813, "seek": 558008, "start": 5587.08, "end": 5591.08, "text": " Then it checks all the notebooks somewhat in parallel.", "tokens": [1396, 309, 13834, 439, 264, 43782, 8344, 294, 8952, 13], "temperature": 0.0, "avg_logprob": -0.21715823535261483, "compression_ratio": 1.4966442953020134, "no_speech_prob": 1.0608610864437651e-05}, {"id": 814, "seek": 559108, "start": 5591.08, "end": 5611.08, "text": " All right. I better go. See you all. Thanks. Bye.", "tokens": [50364, 1057, 558, 13, 286, 1101, 352, 13, 3008, 291, 439, 13, 2561, 13, 4621, 13, 51364], "temperature": 0.0, "avg_logprob": -0.30778982904222274, "compression_ratio": 0.8596491228070176, "no_speech_prob": 2.7411435439717025e-05}], "language": "en"}