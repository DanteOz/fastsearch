{"text": " Welcome to lesson 13, where we're going to be talking about image enhancement. Image enhancement would cover things like this painting that you might be familiar with. However, you might not have noticed before that this painting actually has a picture of an eagle in it. The reason you may not have noticed that before is this painting actually didn't used to have an eagle in it. By the same token actually on that first page, this painting did not used to have Captain America's shield on it either. And this painting did not used to have a clock in it either. This is a cool new paper actually that just came out a couple of days ago called Deep Painterly Harmonization. And it uses almost exactly the technique we're going to learn in this lesson with some minor tweaks. But you can see the basic idea is take one picture, paste it on top of another picture, and then use some kind of approach to combine the two. And the basic approach is something called a style transfer. Before we talk about that though, I wanted to mention this really cool contribution by William Horton, who added this stochastic weight averaging technique to the FastAI library. That is now all merged and ready to go, and he's written a whole post about that, which I strongly recommend you check out, not just because stochastic weight averaging actually lets you get higher performance from your existing neural networks with basically no extra work. It's as simple as adding these two parameters to your fit function. But also he's described his process of building this and how he tested it and how he contributed to the library. So I think it's interesting, you know, if you're interested in doing something like this, I think William had not built this kind of library before, so he describes how he did it. Another very cool contribution to the FastAI library is a new train phase API. And I'm going to do something I've never done before, which I'm actually going to present somebody else's notebook. And the reason I haven't done it before is because I haven't liked any notebooks enough to think they're worth presenting, but Silvan's done a fantastic job here of not just creating this new API, but also creating a beautiful notebook describing what it is and how it works and so forth. And the background here is, as you guys know, we've been trying to train networks faster, partly as part of this Dawnbench competition, and also for a reason that you'll learn about next week. And I mentioned on the forums last week it would be really handy for our experiments if we had an easier way to try out different learning rate schedules and stuff. And I basically laid out an API that I had in mind. I said it would be really cool if somebody could write this because I'm going to bed now and I kind of need it by tomorrow. And Silvan replied on the forum, well that sounds like a good challenge. And by 24 hours later, it was done. And it's been super cool. I want to take you through it because it's going to allow you to do research into things that nobody's tried before. So it's called the train phase API. And the easiest way to show it is to show an example of what it does, which is here. Here is an iteration against a learning rate chart, as you're familiar with seeing. And this is one where we train for a while at a learning rate of.01, and then we train for a while at a learning rate of.001. I actually wanted to create something very much like that learning rate chart because most people that train ImageNet use this stepwise approach. And it's actually not something that's built into fast AI because it's not generally something we recommend. But in order to replicate existing papers, I wanted to do it the same way. And so rather than writing a number of fit fit fit calls with different learning rates, it would be nice to be able to basically say train for n epochs at this learning rate and then m epochs at that learning rate. And so here's how you do that. You can say phases. So a phase is a period of training with particular optimizer parameters. And it consists of a number of training phase objects. And a training phase object says how many epochs to train for, what optimization function to use, and what learning rate, amongst other things that we'll see. And so here you'll see the two training phases that you just saw on that graph. So now rather than calling learn.fit, you say learn.fit with an optimizer scheduler with these phases. And then from there, most of the things you pass in can just get sent across to the fit function as per usual. So most of the usual parameters will work fine. But in this case, generally speaking, actually, we can just use these training phases and you'll see it fits in the usual way. And then when you say plot LR, there it is. And not only does it plot the learning rate, it also plots momentum. And for each phase, it tells you what optimizer it used. You can turn off the printing of the optimizers, you can turn off the printing of momentums, and you can do other little things like a training phase could have an LR decay parameter. So here's a fixed learning rate and then a linear decay learning rate and then a fixed learning rate, which gives us that picture. And this might be quite a good way to train actually, because we know at high learning rates you get to kind of explore better and at low learning rates you get to fine-tune better and it's probably better to gradually slide between the two. So this actually isn't a bad approach, I suspect. You can use other decay types, not just linear, so cosine. This probably makes even more sense as a genuinely potentially useful learning rate annealing shape. Exponential which is a super popular approach. Polynomial which isn't terribly popular but actually in the literature works better than just about anything else but seems to have been largely ignored. So polynomial is good to be aware of. And what Sylvain has done is he's given us the formula for each of these curves. And so with a polynomial you get to pick what polynomial to use. So here it is with a different size. And I believe a p of.9 is the one that I've seen really good results for, FYI. If you don't give a tuple of learning rates when there's an LR decay, then it will decay all the way down to 0. And as you can see, you can happily start the next cycle at a different point. So the cool thing is now we can replicate all of our existing schedules using nothing but these training phases. So here's a function called phases.sgdr which does sgdr using the new training phase API. And so you can see if he runs this schedule, then here's what it looks like. That is even done the little trick I have where you train at a really low learning rate just for a little bit and then pop up and do a few cycles and the cycles are increasing in length. And that's all done in a single function. So the new one cycle we can now implement with, again, a single little function. And so if we fit with that, we get this triangle followed by a little flatter bit and the momentum is a cool thing, the momentum has a momentum decay. And then here we've got a fixed momentum at the end. So it's doing the momentum and the learning rate at the same time. So something that I haven't tried yet that I think would be really interesting is to use, he's calling it differential learning rates, we've changed the name now to discriminative learning rates. So a combination of discriminative learning rates and one cycle, no one's tried yet. So that would be really interesting. There's actually a, the only paper I've come across which has discriminative learning rates is called, uses something called LARS, L-A-R-S, and it was used to train ImageNet with very very large batch sizes by basically looking at the ratio between the gradient and the mean at each layer and using that to change the learning rate of each layer automatically and they found that they could use much larger batch sizes. That's the only other place I've seen this kind of approach used, but there's lots of interesting things you could try with combining discriminative learning rates and different interesting schedules. So you can now write your own LRFinder of different types, specifically because there's now this stop-div parameter, which basically means that it'll use whatever schedule you asked for, but when the loss gets too bad, it'll stop training. So here's one with learning rate versus loss, and you can see it stops itself automatically. One useful thing that's been added is the linear parameter to the plot function. If you use linear schedule rather than an exponential schedule in your learning rate finder, which is a good idea if you've kind of fine-tuned in to roughly the right area, then you can use linear to find exactly the right area, and then you probably want to plot it with a linear scale. So that's why you can also pass linear to plot now as well. You can change the optimizer HVACES, and that's more important than you might imagine because actually the current state of the art for training on really large batch sizes really quickly for ImageNet actually starts with RMSProp for the first bit, and then they switch to SGD for the second bit. And so that could be something interesting to experiment more with, because at least one paper has now shown that that can work well. And again, it's something that isn't well appreciated as yet. And then the bit I find most interesting is you can change your data. Why would you want to change your data? Because you remember from lessons 1 and 2 you could use smaller images at the start and bigger images later. And the theory is that you could use that to train the first bit more quickly with smaller images. And remember, if you have half the height and half the width, then you've got a quarter of the activations of basically every layer, so it can be a lot faster. And it might even generalize better. So you can now create a couple of different, for example, this case has got 28 and then 32 sized images. This is just sci-fi 10, so there's only so much you can do. And then if you pass in an array of data in this data list parameter, when you call fit opshed, it'll use a different data set for each phase. So that's really cool because we can use that now, like we could use that in our dorm bench entries and see what happens when we actually increase the size with very little code. So what happens when we do that? Well, the answer is here in Dawnbench, training on ImageNet, and you can see here that Google has won this with half an hour on a cluster of TPUs. The best non-cluster of TPU result is fastai plus students under 3 hours beating out Intel on 128 computers, or else we ran on a single computer. We also beat Google running on a TPU. So using this approach, we've shown the fastest GPU result, the fastest single machine result, the fastest publicly available infrastructure result, these TPU pods you can't use unless you're Google. And the cost is tiny, like this Intel one cost them $1,200 worth of compute, they haven't even written it here. That's 128 computers in parallel, each one with 36 cores, each one with 140GB compared to our single AWS instance. So this is a kind of a breakthrough in what we can do, like the idea that we can train ImageNet on a single publicly available machine. And this $72, by the way, it was actually $25 because we used a spot instance. So one of our students, Andrew Shaw, built this whole system to allow us to throw a whole bunch of spot instance experiments up and run them simultaneously and pretty much automatically. But DawnBench doesn't quote the actual number we used, so it's actually $25, not $72. So this data list idea is super important and helpful. And so our SciFi 10 results are also now up there officially. And you might remember the previous best was a bit over an hour. And the trick here was using one cycle, basically. So all this stuff that's in Silvance training phase API is really all the stuff that we've used to get these top results. And really cool, another fast AI student who goes by the name here, BKJ, has taken that and done his own version. He took ResNet 18 and added the concat pooling that you might remember that we learned about on top and used Leslie Smith's one cycle. And so he's got on the leaderboard all the top three fast AI students, which is wonderful. And same for cost, the top three. And you can see, Paperspace, so Brett ran this on Paperspace and got the cheapest result, just ahead of BKJ. So I think you can see a lot of the interesting opportunities at the moment for training stuff more quickly and cheaply are all about the learning rate annealing and size annealing and training with different parameters at different times. And I still think we're only scratching the surface. I think we can go a lot faster and a lot cheaper. And that's really helpful for people in resource constrained environments, which is basically everybody except Google, maybe Facebook. Architecture is interesting as well, though. And one of the things we looked at last week was just creating a simpler architecture, which is basically state of the art, like the really basic kind of dark net architecture. But there's a piece of architecture we haven't talked about, which is necessary to understand the inception network. And the inception network is actually pretty interesting, because they use some tricks to actually make things more efficient. And we're not currently using these tricks, and I kind of feel like maybe we should try it. And so the most interesting, most successful inception network is their Inception ResNet-2 network. And most of the blocks in that look something like this. And it looks a lot like a standard ResNet block in that there's an identity connection here and then there's a conv-conv path here and then we add them up together. But it's not quite that. The first is that this path is a one-by-one conv, not just any old conv, but a one-by-one conv. And so it's worth thinking about what a one-by-one conv actually is. So a one-by-one conv is simply saying for each grid cell in your input, you've got a, basically it's a vector, a one-by-one-by-number-of-filters tensor is basically a vector. So for each grid cell in your input, you're just doing a dot product with that tensor. And then of course there's going to be one of those vectors for each of the 192 activations we're creating. So you basically do 192 dot products with grid cell 1,1, and then 192 with grid cell 1,2, and 1,3, and so forth. And so you'll end up with something which has got the same grid size as the input and 192 channels in the output. So that's a really good way to either reduce the dimensionality or increase the dimensionality of an input without changing the grid size. That's normally what we use one-by-one convs for. So here we've got a one-by-one conv and then we've got another one-by-one conv and then they're added together. And then there's a third path, and this third path is not added. This third path is not actually explicitly mentioned, but it's concatenated. And so actually there is a form of resnet which is basically identical to resnet, but we don't do plus, we do concat. And that's called a dense net. So it's just a resnet where we do concat instead of plus. And that's an interesting approach because then the identity path is literally being copied. So you kind of get that flow all the way through. And so as we'll see next week, that tends to be good for segmentation and stuff like that where you really want to keep the original pixels and the first layer of pixels and the second layer of pixels untouched. So concatenating rather than adding branches is a very useful thing to do. And so here we're concatenating this branch. And this branch is doing something interesting, which is it's doing first of all the one-by-one conv and then a one-by-seven and then a seven-by-one. So what's going on there? So what's going on there is basically what we really want to do is do a seven-by-seven conv. And the reason we want to do a seven-by-seven conv is that if you've got multiple paths, each of which has different kernel sizes, then it's able to look at different amounts of the image. And so like the original inception network had like a one-by-one, a three-by-three, a five-by-five, a seven-by-seven, kind of getting concatenated in together, something like that. And so if we can have a seven-by-seven filter, then we get to kind of look at a lot of the image at once and create a really rich representation. And so actually the stem of the inception network, that is the first few layers of the inception network, actually also use this kind of seven-by-seven conv, because you start out with this 224x224x3, and you want to turn it into something that's like 112x112x64. And so by using a seven-by-seven conv, you can get a lot of information in each one of those outputs to get those 64 filters. But the problem is that seven-by-seven conv is a lot of work. You've got 49 kernel values to multiply by 49 inputs for every input pixel across every channel. So the compute is crazy. You can kind of get away with it maybe for the very first layer, and in fact the very first layer, the very first conv of ResNet is a seven-by-seven conv. But not so for inception. For inception they don't do a seven-by-seven conv. Instead they do a one-by-seven followed by a seven-by-one. And so to explain, the basic idea of the inception networks, all the different versions of it, that you have a number of separate paths which have different convolution widths. In this case, conceptually the idea is this is a one-by-one convolution width, and this is going to be a seven convolution width. And so they're looking at different amounts of data and then we combine them together. But we don't want to have a seven-by-seven conv throughout the network because it's just too computationally expensive. But if you think about it, if we've got some input coming in, and we have some big filter that we want and it's too big to deal with, what could we do? So let's say, let's just make it a little bit less boring, let's do 5x5. What we can do is to create two filters, one which is 1x5, one which is 5x1, or 7, or whatever, or 9. So we take our activations to the previous layer and we put it through the 1x5, we take the activations out of that and put it through the 5x1, and something comes out the other end. Now what comes out the other end? Well rather than thinking of it as first of all we take the activations, then we put it through the 5x1, then we put it through the 1x5, then the 5x1. What if instead we think of these two operations together and say, what does a 5x1.product and a 1x5.product do together? And effectively, you could take a 1x5 and a 5x1 and the outer product of that is going to give you a 5x5. Now you can't create any possible 5x5 matrix by taking that product, but there's a lot of 5x5 matrices that you can create. And so the basic idea here is when you think about the order of operations, and I'm not going to go into the detail of this, if you're interested in more of the theory here, you should check out Rachel's numerical linear algebra course, which is basically a whole course about this stuff. But conceptually the idea is that very often the computation you want to do is actually more simple than an entire 5x5 convolution. Very often the term we use in linear algebra is that there's some lower rank approximation. In other words, the 1x5 and the 5x1 combined together, that 5x5 matrix is nearly as good as the 5x5 matrix you really ideally would have computed if you were able to. And so this is very often the case in practice, just because the nature of the real world is that the real world tends to have more structure than randomness. So the cool thing is, if we replace our 7x7 conv with a 1x7 and a 7x1, then this has basically for each cell it's got 14 by input channel by output channel dot products to do, whereas this one has 49 to do. So it's just going to be a lot faster, and we have to hope that it's going to be nearly as good. It's certainly capturing as much width of information by definition. So if you're interested in learning more about this specifically in the deep learning area, you can Google for factored convolutions. The idea was come up with 3 or 4 years ago now. It's probably been around for longer, but that was when I first saw it. And yeah, it turned out to work really well, and the inception network uses it quite widely. They actually use it in their stem. It's interesting actually, we've talked before about how we tend to kind of add on, we tend to say there's this main backbone, like when we have ResNet 34 for example, we kind of say there's this main backbone which is all of the convolutions, and then we've talked about how we can add on to it a custom head. And that tends to be like a max pooling layer and a fully connected layer or something like that. You know, it's actually kind of better to talk about the backbone as containing two pieces. One is the stem, and then the other is kind of the main backbone. And the reason is that the thing that's coming in, remember it's only got 3 channels, and so we want some sequence of operations, it's going to expand that out into something richer, generally something like 64 channels. And so in ResNet, the stem is just super simple. It's a 7x7 conv, stride2 conv, followed by stride2 max pool. I think that's it, if memory serves correctly. In inception, they have a much more complex stem with multiple paths getting combined, concatenated, including factored cons of 1x7 and 7x1. And I'm kind of interested in what would happen if you stuck a standard ResNet on top of an inception stem, for instance. I think that would be a really interesting thing to try. An inception stem is quite a carefully engineered thing, and this thing of how do you take your 3-channel input and turn it into something richer seems really important. And all of that work seems to have got thrown away for ResNet. We like ResNet, it works really well. But what if we put the dense net backbone on top of an inception stem? Or what if we replaced the 7x7 conv with a 1x7, 7x1 factored conv in a standard ResNet? I don't know, there's lots of things we could try, and I think it would be really interesting. So there's some more thoughts about potential research directions. So that was kind of my little bunch of random stuff section. Moving a little bit closer to the actual main topic of this, which is image enhancement. I'm going to talk about a new paper briefly because it really connects what I just discussed with what we're going to discuss next. The new paper is a paper on progressive GANs which came from NVIDIA. And the progressive GANs paper is really neat. Question, 1x1 conv is usually called a network within a network in the literature. What is the intuition of such a name? No, network in network is more than just a 1x1 conv. It's part of an IN. I don't think there's any particular reason to look at that. So the progressive GAN basically takes this idea of gradually increasing the image size. It's the only other direction I'm aware of where people have actually gradually increased the image size. It kind of surprises me because this paper is actually very popular and very well-known and very well-liked, and yet people haven't taken the basic idea of gradually increasing the image size and used it anywhere else, which shows you the general level of creativity you can expect to find in the deep learning research community perhaps. So they start with a 4x4 GAN, like literally, they're trying to replicate 4x4 pixels, and then 8x8 pixels. So here's the 8x8 pixels. This is the Celeb A data set, so we're trying to recreate pictures of celebrities. And then they go 16x16, and then 32, and then 64, and then 128, and then 256. And one of the really nifty things they do is that as they increase size, they also add more layers to the network, which kind of makes sense, because if you're doing more of a ResNet-y type thing, then you're spitting out something which hopefully makes sense at each grid cell size, and so you should be able to layer stuff on top. And they do another nifty thing where they add a skip connection when they do that, and they gradually change a linear interpolation parameter that moves it more and more away from the old 4x4 network and towards the new 8x8 network. And then once they've totally moved it across, they throw away that extra connection. So the details don't matter too much, but it uses the basic ideas we've talked about gradually increasing the image size, kind of skip connections and stuff. But it's a great paper to study because A, it's like one of these rare things where they've like good engineers actually built something that just works in a really sensible way. And it's not surprising, this actually comes from NVIDIA themselves. So NVIDIA don't do a lot of papers, but it's interesting that when they do, they build something that's so thoroughly practical and sensible. And so I think it's a great paper to study if you want to kind of put together lots of the different things we've learnt. And there aren't many re-implementations of this, so like it's an interesting thing to project and maybe you could build on and find something else. So here's what happens next. We eventually go up to 1024x1024, and you'll see that the images are not only getting higher resolution but they're getting better. And so 1024x1024, I'm going to see if you can guess which one of the next page is fake. They're all fake. That's the next stage. You go up, up, up, up, up, up, and then boom. So like GANs and stuff are getting crazy, and some of you may have seen this during the week. So this video just came out and it's a speech by Barack Obama, and let's check it out. So as you can see, they've used this kind of technology to literally move Obama's face in the way that Jordan Peele's face was moving. You basically have all the techniques you need now to do that. So is that a good idea? So this is the bit where we talk about what's most important, which is like, now that we can do all this stuff, what should we be doing, and how do we think about that? And the TLDR version is, I actually don't know. Maybe a lot of you saw the founders of the Spacey Prodigy folks, founders of Explosion AI, did a talk, and Matthew and Ines. I went to dinner with them afterwards and we basically spent the entire evening talking, debating, arguing about what does it mean that companies like ours are building tools that are democratizing access to tools that can be used in harmful ways. And they're incredibly thoughtful people. I wouldn't say we didn't agree, we just couldn't come to a conclusion ourselves. So I'm just going to lay out some of the questions and point to some of the research. And when I say research, most of the actual literature review and putting this together was done by Rachel. Let me start by saying the models we build are often pretty shitty in ways which are not immediately apparent. And you won't know how shitty they are unless the people that are building them with you are a range of people, and the people that are using them with you are a range of people. So for example, a couple of wonderful researchers, Joy and Timnit did this really interesting research where they looked at some basically off-the-shelf face recognizers, one from Face Plus Plus, which is a huge Chinese company, IBMs and Microsofts, and they looked for a range of different face types. And generally speaking, the Microsoft one in particular was incredibly accurate, unless the face type happened to be dark skinned when suddenly it went 25 times worse, got it wrong nearly half the time. And for a big company like this to release a product that for a very very large percentage of the world basically doesn't work is more than a technical failure. It's a really deep failure of understanding what kind of team needs to be used to create such a technology and to test such a technology, or even an understanding of who your customers are. Yes, some of your customers have dark skin. Yes, Rachel. I was also going to add that the classifiers all did worse on women than on men. Shocking. Yeah, it's funny, actually Rachel tweeted about something like this the other day, and some guy was like, what's this all about? What are you saying? Don't you know about people made cars for a long time? Are you saying you might need women to make cars too? And Rachel pointed out, well actually yes, for most of the history of car safety, women in cars have been far far more at risk of death than men in cars, because the men created male looking feeling sized crash test dummies. And so car safety was literally not tested on women sized bodies. So the fact, shitty product management with a total failure of diversity and understanding is not new to our field. I was just going to say that was comparing impacts of similar strength, men and women. Yeah, I don't know why. Whenever you say something like this on Twitter, Rachel has to say this, because anytime you say something like this on Twitter, there's like 10 people who will be like, oh you have to compare all these other things. We didn't know that. I mean, other things our very best, most famous systems do like Microsoft's face recognizer or Google's language translator, you turn she is a doctor, he is a nurse into Turkish and quite correctly both the pronouns become oh, because there's no gender pronouns in Turkish. So go the other direction, I'll be a doctor, I don't know how to say that, the equivalent for Turkish nurse. And what does it get turned into? He is a doctor, she is a nurse. So like we've got these kind of like biases built into tools that we're all using every day. And again, people are like, oh, it's just showing us what's in the world. And well, okay, there's lots of problems with that basic assertion. But as you know, machine learning algorithms love to generalize. And so because they love to generalize, this is one of the cool things about you guys knowing the technical details now, because they love to generalize, when you see something like 60% of people cooking are women in the pictures they use to build this model, and then you actually run the model on a separate set of pictures, then 84% of the people they choose as cooking women rather than the correct 67%. Which is like a really understandable thing for an algorithm to do, is it took a biased input and created a more biased output, because for this particular loss function, that's kind of where it ended up. And this is a really common kind of model amplification. So this stuff matters. It matters in ways more than just awkward translations or black people's photos not being classified correctly. Maybe there's some wins too as well, like horrifying surveillance everywhere, maybe won't work on black people. Or it'll be even worse because it's horrifying surveillance and it's flat out racist and wrong. I agree with that too. But let's go deeper. For all we say about human failings, humans are generally, there's a long history of civilization and societies creating layers of human judgment which avoid hopefully the most horrible things happening. And sometimes companies which love technology think, let's throw away the humans and replace them with technology like Facebook did. So 2 or 3 years ago, Facebook literally got rid of their human editors, like this was in the news at the time, and they were replaced with algorithms. And so now there's algorithms that put all the stuff on your news feed and human editors are out of the loop. What happened next? Many things happened next. One of which was a massive horrifying genocide in Myanmar. Babies getting torn out of their mother's arms and thrown into fires. Mass rape, murder, and an entire people exiled from their homeland. I'm not going to say that was because Facebook did this, but what I will say is that when the leaders of this horrifying project are interviewed, they regularly talk about how everything they learnt about the disgusting animal behaviors of Rohingyas that need to be thrown off the earth, they learnt from Facebook. Because the algorithms just want to feed you more stuff that gets you clicking. And so if you get told these people that don't look like you and you don't know are bad people and here's lots of stories about the bad people, and then you start clicking on them, and then they feed you more of those things, and next thing you know you have this extraordinary cycle. And people have been studying this. So for example, we've been told a few times people click on our Fast AI videos, and then the next thing recommended to them is like conspiracy theory videos from Alex Jones, and then that continues there. Because you know, humans click on things that shock us and surprise us and horrify us. And so at so many levels, this decision has had extraordinary consequences which we're only beginning to understand. And again, this is not to say this particular consequence is because of this one thing, but to say it's entirely unrelated would be clearly ignoring all of the evidence and information that we have. So this is really kind of the key takeaway is to think like, what are you building and how could it be used? So lots and lots of effort now being put into face detection, including in our course. We've been spending a lot of time thinking about how to recognize stuff and where it is, and there's lots of good reasons to want to be good at that. For improving crop yields in agriculture, for improving diagnostic and treatment planning and medicine, for improving your Lego sorting robot system, whatever. But it's also being widely used in surveillance and propaganda and disinformation. And again, the question is what do I do about that? I don't exactly know. But it's definitely at least important to be thinking about it, talking about it, and sometimes you can do really good things. For example, Meetup.com did something which I would put in the category of really good thing, which is they recognized early a potential problem, which is that more men were tending to go to their meetups. And that was causing their collaborative filtering systems, which you're all familiar with building now, to recommend more technical content to men. And that was causing more men to go to more technical content, which was causing the recommendation systems to suggest more technical content to men. And this kind of runaway feedback loop is extremely common when we interface the algorithm and the human together. So what did Meetup do? They intentionally made the decision to recommend more technical content to women. Not because of some highfalutin idea about how the world should be, but just because that makes sense. The runaway feedback loop was a bug. There are women that want to go to tech meetups, but when you turn up to a tech meetup and it's all men, and you don't go, and it recommends more to men, and so on and so forth. So Meetup made a really strong product management decision here, which was to not do what the algorithm said to do. Unfortunately this is rare. Most of these runaway feedback loops, for example in predictive policing, where algorithms tell policemen where to go, which very often is more black neighborhoods, which end up crawling with more policemen, which leads to more arrests, which has the systems tell more policemen to go to more black neighborhoods, and so forth. So this problem of algorithmic bias is now very widespread, and as algorithms become more and more widely used for specific policy decisions, judicial decisions, day to day decisions about who to give what offer to, this just keeps becoming a bigger problem. And some of them are really things that the people involved in the product management decision should have seen at the very start didn't make sense and were unreasonable under any definition of the term. For example, this stuff that I've gone pointed out, these were questions that were used to decide, Rachel was this sentencing guidelines? This software is used for both pre-trial, so who was required to post bail, so these are people that haven't even been convicted, as well as for sentencing and for who gets parole, and this was upheld by the Wisconsin Supreme Court last year despite all the flaws that were pointed out. So whether you have to stay in jail because you can't pay the bail, and how long your sentence is for, and how long you stay in jail for, depends on what your father did, whether your parents stayed married, who your friends are, and where you live. Now it turns out these algorithms are actually terribly, terribly bad, so some recent analysis showed that they're basically worse than chance, but even if the companies building them were competent and these were statistically accurate correlations, does anybody imagine there's a world where it makes sense to decide what happens to you based on what your dad did? So a lot of this stuff at the basic level is obviously unreasonable, and a lot of it just fails in these ways, but you can see empirically that these runaway feedback loops must have happened, and these overgeneralizations must have happened. For example, these are the kind of cross-tabs that anybody working in these fields, in any field that's using algorithms, should be preparing. So prediction of likelihood of reoffending for black vs. white defendants, we can just calculate this very simply. Of the people that were labeled high risk but didn't reoffend, there were 23.5% white but about twice that African-American. Whereas those that were labeled lower risk but did reoffend was like half the white people and only 20% of the African-American. So this is the kind of stuff where at least if you're taking the technologies we've been talking about and putting the production in any way, or building an API for other people, or providing training for people, or whatever, then at least make sure that what you're doing can be tracked in a way that people know what's going on. So at least they're informed. I think it's a mistake in my opinion to assume that people are evil and trying to break society. I prefer to start with an assumption of if people are doing dumb stuff, it's because they don't know better. So at least make sure that they have this information. I find very few ML practitioners thinking about what is the information they should be presenting in their interface. And often I'll talk to data scientists who will say, the stuff I'm working on doesn't have a societal impact. It's like, really? Like a number of people who think that what they're doing is entirely pointless? Come on! Otherwise people are paying you to do it for a reason. It's going to impact people in some way. So think about what that is. The other thing I know is a lot of people involved here are hiring people. And so if you're hiring people, I guess you're all very familiar with the Fast AI philosophy now, which is the basic premise. And I think it comes back to this idea that I don't think people on the whole are evil. I think they need to be informed and have tools. So we're trying to give as many people the tools as possible that they need. And particularly we're trying to put those tools in the hands of a more diverse range of people. So if you're involved in hiring decisions, perhaps you can keep this kind of philosophy in mind as well. If you're not just hiring a wider range of people, but also promoting a wider range of people and providing really appropriate career management for a wider range of people. Well, apart from anything else, your company will do better. It actually turns out that more diverse teams are more creative and tend to solve problems more quickly and better and less diverse teams. But also you might avoid these kind of awful screw-ups which at one level are bad for the world, and at another level if you ever get found out, they can also destroy your company. Also they can destroy you, or at least make you look pretty bad in history. A couple of examples. One is going right back to the Second World War, IBM basically provided all of the infrastructure necessary to track the Holocaust. So they had different code for Jews were 8 and gypsies were 12, death in the gas chambers was 6, and they all went on these punch cards. You can go and look at these punch cards in museums now. And this has actually been reviewed by a Swiss judge who said that IBM's technical assistance facilitated the task of the Nazis and the commission of the crimes against humanity. And it's interesting to read back the history from these times to see what was going through the minds of people at IBM at that time. And what was clearly going through the minds was the opportunity to show technical superiority, the opportunity to test out their new systems, and of course the extraordinary amount of money that they were making. When you do something which at some point down the line turns out to be a problem, even if you are told to do it, that can turn out to be a problem for you personally. For example, you'll remember the diesel emissions scandal in VW. Who was the one guy that went to jail? It was the engineer. Who's doing his job? So if all of this stuff about actually not fucking up the world isn't enough to convince you, it can fuck up your life too. So if you do something that turns out to cause problems, even though somebody told you to do it, you can absolutely be held criminally responsible. And you'll certainly look at Kogan. I think a lot of people now know the name Alexander Kogan, he was the guy that handed over the Cambridge Analytica data. He's a Cambridge academic, now a very famous Cambridge academic the world over for doing his part to destroy the foundations of democracy. So this is probably not how we want to go down in history. So let's have a break before we do. Question on a different topic. In one of your tweets you said Dropout is patented. I think this is about WaveNet patent from Google. What does it mean? Can you please share more insight on this subject? Does it mean that we'll have to pay to use Dropout in the future? Good question. Let's talk about that after the break. So let's come back at 7.40. The question before the break was about patents. What does it mean? So I guess the reason it's coming up was because I wrote a tweet this week, which I think was like 3 words, and said Dropout is patented. One of the patent holders is Jeffrey Hinton. So what? Isn't that great, invention is all about patents. My answer is no. Patents have gone wildly crazy. The amount of things that are patentable that we talk about every week would be dozens. Like it's so easy to come up with a little tweak. If you turn that into a patent, you stop everybody from using that little tweak for the next 14 years, and you end up with a situation we have now where everything is patented in 50 different ways. So then you get these patent trolls who have made a very, very good business out of basically buying lots of shitty little patents and then suing anybody who accidentally turned out did that thing, like putting rounded corners on buttons. What does it mean for us that a lot of stuff is patented in deep learning? I don't know. One theory, like a lot of the main people doing this is Google, and people from Google who reply to this patent tend to assume that Google is doing it because they wanted to have it defensively. So if somebody sues them, they'll be like don't sue us, we'll sue you back because we have all these patents. The problem is that as far as I know, they haven't signed what's called a defensive patent pledge. Basically you can sign a legally binding document that says our patent portfolio will only be used in defense and not offense. And even if you believe all the management of Google would never turn into a patent troll, you've got to remember that management changes. And to give a specific example, I know the somewhat recent CFO of Google has a much more aggressive stance towards the P&L. And I don't know, maybe she might decide that they should start monetizing their patents. Or maybe the group that made that patent might get spun off and then sold to another company that might end up in private equity hands and decide to monetize the patents. So I think it's a problem. There has been a big shift legally recently away from software patents actually having any legal standing. So it's possible that these will all end up thrown out of court. But the reality is that anything but a big company is unlikely to have the financial ability to defend themselves against one of these huge patent trolls. So I think it's a problem. You can't avoid using patented stuff if you write code. I wouldn't be surprised if most lines of code you write have patents on them. So actually funnily enough, the best thing to do is not to study the patents. Because if you do and you infringe knowingly, then the penalties are worse. So the best thing to do is to put your hands in your ears, sing a song, and get back to work. So that thing about Dropout's patented, forget I said that, you don't know that. This is super fun, artistic style. We're going to go a bit retro here because this is actually the original artistic style paper and there's been a lot of updates to it, a lot of different approaches. And I actually think in many ways the original is the best. We're going to look at some of the newer approaches as well, but I actually think the original is a terrific way to do it, even with everything that's gone since. Let's just jump to the code. So this is the style transfer notebook. So the idea here is that we want to take a photo of this bird and we want to create a painting that looks like Van Gogh painted the picture of the bird. Quite a bit of the stuff that I'm doing by the way uses ImageNet. You don't have to download the whole of ImageNet for any of the things I'm doing. There's an ImageNet sample on files.fast.ai. Which has a couple of gigs. It should be plenty good enough for everything we're doing. If you want to get really great results, you can grab ImageNet. You can download it from Kaggle. On Kaggle, the localization competition actually contains all of the classification data as well. So if you've got room, it's good to have a copy of ImageNet because it comes in handy all the time. So I just grabbed a bird out of my ImageNet folder and there is my bird. And so what I'm going to do is I'm going to start with this picture and I'm going to try and make it more and more like a picture of this bird painted by Van Gogh. And the way I do that is actually very simple. You're all familiar with it. We will create a loss function, which we'll call f. And the loss function is going to take as input a picture and spit out as output a value. And the value will be lower if the image looks more like the bird photo painted by Van Gogh. Having written that loss function, we will then use the PyTorch gradient and optimizers times the learning rate. And we're not going to update any weights. We're going to update the pixels of the input image to make it a little bit more like a picture which would be a bird painted by Van Gogh. And we'll stick it through the loss function again to get more gradients and do it again and again. And that's it. So it's like identical to how we solve every problem. You know I'm a one-trick pony, right? This is my only trick. Create a loss function, use it to get some gradients, multiply it by learning rates to update something. Always before, we've updated weights in a model. But today we're not going to do that. We're going to update the pixels in the input. But it's no different at all. We're just taking the gradient with respect to the input rather than with respect to the weights. That's it. So we're nearly done. Let's do a couple more things. Let's mention here that there's going to be two more inputs to our loss function. One is the picture of the bird. Birds look like this. And the second is an artwork by Van Gogh. They look like this. And of course, there we go. And by having those as inputs as well, that means we'll be able to rerun the function later to make it look like a bird painted by Monet or a jumbo jet painted by Van Gogh or whatever. So those are going to be the three inputs. And so initially, as we discussed, our input here, this is going to be the first time I've ever found the rainbow pen useful. So we start with some random noise, use the loss function, get the gradients, make it a little bit more like a bird painted by Van Gogh, and so forth. So the only outstanding question, which I guess we can talk about briefly, is how we calculate how much our image looks like this bird painted by Van Gogh. So let's split it into two parts. Let's split it into a part called the content loss. And that's going to return a value that's lower if it looks more like the bird. Not just any bird, the specific bird that we had coming in. And then let's also create something called the style loss. And that's going to be a lower number if the image is more like Van Gogh's style. So there's one way to do the content loss, which is very simple. We could look at the pixels of the output, compare them to the pixels of the bird, and do a mean squared error, add them up. So if we did that, I ran this for a while, eventually our image would turn into an image of the bird. You should try it. You should try this as an exercise. Try to use the optimizer in PyTorch to start with a random image and turn it into another image by using mean squared error pixel loss. Not terribly exciting, but that would be step one. The problem is, even if we already had our style loss function working beautifully, and then presumably what we're going to do is we're going to add these two together, and then one of them we'll multiply by some lambda to adjust some number we'll pick to adjust how much style versus how much content. So assuming we had a style loss, we picked some sensible lambda, if we used a pixel-wise content loss, then anything that makes it look more like Van Gogh and less like the exact photo, the exact background, the exact contrast, lighting, everything, will decrease the content loss, which is not what we want. We want it to look like the bird, but not in the same way. It's still going to have the same two eyes in the same place and be the same kind of shape and so forth, but not the same representation. So what we're going to do is, this is going to shock you, we're going to use a neural network. I totally meant that to be black and it came out green. It's always a black box. And we're going to use the VGG neural network because that's what I used last year and I didn't have time to see if other things worked, so you can try that yourself during the week. And the VGG network is something which takes in an input and sticks it through a number of layers. And I'm just going to treat these as just the convolutional layers, there's obviously ReLU there, and if it's a VGG with batch norm, which most are today, then it's also got batch norm. And there's some max pooling and so forth, but that's fine. What we could do is we could take one of these convolutional activations and then rather than comparing the pixels of this bird, we could instead compare the VGG layer 5 activations of this to the VGG layer 5 activations of our original bird, or layer 6 or layer 7 or whatever. So why might that be more interesting? Well for one thing, it wouldn't be the same bird, it wouldn't be exactly the same, because we're not checking the pixels, we're checking some later set of activations. And so what do those later sets of activations contain? Well assuming it's after some max pooling, they contain a smaller grid, so it's less specific about where things are. And rather than containing pixel color values, they're more like semantic things, like is this kind of like an eyeball, or is this kind of furry, or is this kind of bright, or is this kind of reflective, or is this laying flat, whatever. So we would hope that there's some level of semantic features through those layers where if we get something, a picture that matches those activations, then any picture that matches those activations looks like the bird, but it's not the same representation of the bird. So that's what we're going to do. That's what our content loss is going to be. And people generally call this a perceptual loss. It's really important in deep learning that you always create a new name for every obvious thing you do. So if you compare two activations together, you're doing a perceptual loss. So that's it. Our content loss is going to be a perceptual loss. And then we'll do the style loss later. So let's start by trying to create a bird that initially is random noise, and we're going to use perceptual loss to create something that is bird-like, but is not this bird. So let's start by saying we're going to do 288x288. Because we're only going to do one bird, there's going to be no GPU memory problems. So I was actually disappointed that I realized that I picked a rather small input image. It would be fun to try this with something much bigger to create a really grand-scale piece. The other thing to remember is if you were productionizing this, you could do a whole batch at a time. So people sometimes complain about this approach. Gaddis is the lead author. The Gaddis style transfer approach is being slow. I don't agree it's slow. It takes a few seconds and you can do a whole batch in a few seconds. So we're going to stick it through some transforms as per usual, transforms for VGG16 model. And so remember, the transform class has a dunder call method, so we can treat it as if it's a function. So if you pass an image into that, then we get the transformed image. So try not to treat the fast AI and PyTorch infrastructure as a black box, because it's all designed to be really easy to use in a decoupled way. So this idea that transforms are just callables, i.e. things that you can do with parentheses, comes from PyTorch. And we totally plagiarized the idea. So with TorchVision or with fast AI, your transforms are just callables. And the whole pipeline of transforms is just a callable. So now we have something of 3x288x288, because PyTorch likes the channel to be first, and as you can see, it's been turned into a square for us, it's been normalized to 0,1, all that normal stuff. Now we'll create a random image. And here's something I discovered. Trying to turn this into a picture of anything is actually really hard. I found it very difficult to actually get an optimizer to get reasonable gradients that went anywhere. And just as I thought I was going to run out of time for this class and really embarrass myself, I realized the key issue is that pictures don't look like this, they have more smoothness. So I turned this into this by just kind of blurring it a little bit. I used a median filter, basically it's like a median pooling effectively. And as soon as I changed it from this to this, it immediately started training really well. So it's like, the number of little tweaks you have to do to get these things to work is kind of insane. So we start with a random image which is at least somewhat smooth. I found that my bird image had a standard deviation of pixels that was about half of this mean, so I divided it by 2, just trying to make it a little bit easier for it to match. I don't know if it matters. Turn that into a variable, because this image, remember, we're going to be modifying those pixels with an optimization algorithm. So anything that's involved in the loss function needs to be a variable, and specifically it requires a gradient because we're actually updating the image. So we now have a mini-batch of 1, 3 channels, 288x288 random noise. We're going to use for no particular reason the 37th layer of VGG. If you print out the VGG network, you can just type in m-underscore-vgg and it prints it out, you'll see that this is a mid to late stage layer. So we can just grab the first 37 layers and turn it into a sequential model, and so now we've got a subset of VGG that will spit out some mid-layer activations, and so that's what the model's going to be. So we can take our actual bird image, and we want to create a mini-batch of 1. So remember, if you slice in NumPy with None, also known as np.newAxis, it introduces a new unit axis in that point. So here I want to create an axis of size 1 to say this is a mini-batch of size 1. So slicing with None, just like I did here, I sliced with None to get this 1 unit axis at the front. So then we turn that into a variable, and this one doesn't need to be updated, so we use bv to say you don't need gradients for this guy. And so that's going to give us our target activations. So we've basically taken our bird image, turned it into a variable, stuck it through our model to grab the 37th layer activations, and that's our target, is that we want our content loss to be this set of activations here. So now we're going to create an optimizer, we'll go back to the details of this in a moment, but we're going to create an optimizer, and we're going to step a bunch of times, going zero the gradients, call some loss function, loss.backward, blah blah blah. So that's the high-level version, and I'm going to come back to the details in a moment, but the key thing is that the loss function we're passing in that randomly generated image, the optimization image, or actually the variable of it. So we pass that to our loss function, and so it's going to update this using the loss function, and the loss function is the mean squared error loss, comparing our current optimization image, pass through our VGG to get the intermediate activations, and comparing it to our target activations, just like we discussed. And we'll run that a bunch of times, and we'll print it out, and we have our bird, but not the representation of the bird. So there it is. So a couple of new details here, one is a weird optimizer, LBFTS. Anybody who's done, I don't know exactly what courses they're in, but certain parts of math and computer science courses, comes into deep learning, discovers we use all this stuff like Adam and SGD, and always assume that nobody in the field knows the first thing about computer science, and immediately says, oh have any of you guys tried using VFTS? There's basically a long history of a totally different kind of algorithm for optimization that we don't use to train neural networks. And of course the answer is actually the people who have spent decades studying neural networks do know a thing or two about computer science, and it turns out these techniques on the whole don't work very well. But it's actually going to work well for this, and it's a good opportunity to talk about an interesting algorithm for those of you that haven't studied this type of optimization algorithm at school. So BFTS is initials of 4 different people, the L stands for limited memory, so it's really just called BFTS, limited memory BFTS. And it's an optimizer, so as an optimizer, it means that there's some loss function, and it's going to use some gradients to, not all optimizers use gradients, but all the ones we use do, use gradients to find a direction to go and try to make the loss function go lower and lower by adjusting some parameters. It's just an optimizer. But it's an interesting kind of optimizer because it does a bit more work than the ones we're used to on each step. And so specifically, so the way it works is it starts the same way that we're used to, which is we just kind of pick somewhere to get started, and in this case we pick like a random image, as you saw. And as per usual, we calculate the gradient. But we then don't just take a step, but what we actually do is as well as finding the gradient, we also try to find the second derivative. So the second derivative says how fast does the gradient change. So the gradient is how fast does the function change, the second derivative is how fast does the gradient change. In other words, how curvy is it? And the basic idea is that if you know that it's not very curvy, then you can probably jump further. But if it is very curvy, then you probably don't want to jump as far. And so in higher dimensions, the gradient is called the Jacobian and the second derivative is called the Hessian. You'll see those words all the time, but that's all they mean. Again, mathematicians have to invent new words for everything as well. They're just like deep learning researchers, except maybe a bit more snooty. So with BFGS, we're going to try and calculate the second derivative, and then we're going to use that to figure out what direction to go and how far to go. So it's less of a wild jump into the undone. Now the problem is that actually calculating the Hessian, the second derivative, is almost certainly not a good idea. Because in each possible direction that you can head, for each direction that you're measuring the gradient in, you also have to calculate the Hessian in every direction. It gets ridiculously big. So rather than actually calculating it, we take a few steps and we basically look at how much the gradient's changing as we do each step, and we approximate the Hessian using that little function. And this seems like a really obvious thing to do, but nobody thought of it until surprisingly a long time later. Keeping track of every single step you take takes a lot of memory. So don't keep track of every step you take, just keep the last 10 or 20. And the second bit there, that's the L, to the L BFGS. So a limited memory BFGS means keep the last 10 or 20 gradients, use that to approximate the amount of curvature, and then use the curvature and gradient to estimate what direction to travel and how far. And so that's normally not a good idea in deep learning for a number of reasons. It's obviously more work to do than an atom or an SGD update. It's obviously more memory. Memory is much more of a big issue when you've got a GPU to store it on and hundreds of millions of weights. But more importantly, the mini-batches are super bumpy, so figuring out curvature to decide exactly how far to travel is kind of polishing turds, as we say. Is that an American expression or an Australian thing? I bet English says it too. Polishing turds, you get the idea. And also interestingly, actually using the second derivative information, it turns out it's like a magnet for saddle points, so there's some interesting theoretical results that basically say it actually sends you towards nasty flat areas of the function if you use second derivative information. So normally not a good idea. But in this case, we're not optimizing weights, we're optimizing pixels, so all the rules change and actually it turns out LBFTS does make sense. And because it does more work each time, it's a different kind of optimizer, the API is a little bit different in PyTorch. As you can see here, when you say optimizer.step, you actually pass in the loss function. So my loss function is to call step with a particular loss function, which is my activation loss. And as you can see, you don't inside the loop, you don't say step, step, step, but rather it looks like this. So it's a little bit different. And you're welcome to try and rewrite this to use SGD, it'll still work, it'll just take a bit longer. I haven't tried it with SGD, I'd be interested to know how much longer it takes. So you can see the loss function going down, the mean squared error between the activations at layer 37 of our VGG model for our optimized image versus the target activations, and remember the target activations were the VGG applied to our BERT. Does that make sense? So we've now got a content loss. Now one thing I'll say about this content loss is we don't know which layer is going to work best, so it would be nice if we were able to experiment a little bit more, and the way it is here is annoying. Maybe we even want to use multiple layers. So rather than lopping off all of the layers after the one we want, wouldn't it be nice if we could somehow grab the activations of a few layers as it calculates? Now we already know one way to do that. Back when we did SSD, we actually wrote our own network which had a number of outputs. Remember, like the different convolutional layers, we spat out a different Oconv thing. But I don't really want to go and add that to the TorchVision ResNet model, especially not if later on I want to try the TorchVision VGG model and then I want to try the NestNetA model. I don't want to go into all of them and change their outputs, besides which I'd like to easily be able to turn certain activations on and off at demand. So we've briefly touched before on this idea that PyTorch has these fantastic things called hooks. You can have forward hooks that let you plug anything you like into the forward path of a calculation, or a backward hook that lets you plug anything you like into the backward path. So we're going to create the world's simplest forward hook. And this is one of these things that almost nobody knows about. So like almost any code you find on the Internet that implements style transfer, we'll have all kinds of horrible hacks rather than using forward hooks. But with forward hooks, it's really easy. So to create a forward hook, you just create a class, and the class has to have something called hook function. And your hook function is going to receive the module that you've hooked. It's going to receive the input for the forward pass, and it's going to receive the target, and then you do whatever the hell you like. So what I'm going to do is I'm just going to store the output of this module in some attribute. That's it. So this can actually be called anything you like, but hook function seems to be the standard. You can see what happens here in the constructor is I store inside some attribute the result of, this is going to be the layer that I'm going to hook, you go module.registerForwardHook and pass in the function that you want to be called when this module, when its forward method is called. So when its forward method is called, it will call self.hook function, which will store the output in an attribute called features. So now what we can do is we can create our VGG as before, and let's set it to not trainable so we don't waste time and memory calculating gradients for it. And let's go through and find out, let's find all of the max pool layers. So let's go through all of the children of this module, and if it's a max pool layer, let's spit out index-1. So that's going to give me the layer before the max pool. And so in general, the layer before a max pool or the layer before a stride2 conv is a very interesting layer, because it's like it's the most complete representation we have at that grid cell size. Because the very next layer is changing the grid. So that seems to me like a good place to grab the content loss from, is the best, most semantic, most interesting content we have at that grid size. So that's why I'm going to pick those indexes. So here they are. Those are the indexes of the last layer before each max pool in VGG. So I'm going to grab this one here, 22, just for no particular reason, just to try something else. So I'm going to say block ends 3, so that's going to be 32. So children VGG index to block ends 3 will give me the 32nd layer of VGG as a module. And then if I call the save features constructor, it's going to go self.hook equals 32nd layer of VGG.registerForwardHook hook function. So now every time I do a forward pass on this VGG model, it's going to store the 32nd layer's output inside sf.features. So we can now say, see here I'm calling my VGG network, but I'm not storing it anywhere. I'm not saying activations equals VGG of my image. I'm calling it, throwing away the answer, and then grabbing the features that we stored in our sf, in our save features object. So that way, this is now going to contain, this is a forward pass. Now that's how you do a forward pass in PyTorch. You don't say.forward, you just use it as a callable. And using it as a callable on an nn.module automatically calls forward. That's how PyTorch modules work. So we call it as a callable. That ends up calling our forward hook. That forward hook stores the activations in sf.features. And so now we have our target variable, just like before, but in a much more flexible way. These are the same 4 lines of code we had earlier. I've just stuck them into a function. And so it's just giving me my random image to optimize and an optimizer to optimize that image. This is exactly the same code as before. So that gives me this. And so now I can go ahead and do exactly the same thing, but now I'm going to use a different loss function, activation loss number 2, which doesn't say out equals mvgg. Again, it calls mvgg to do a forward pass, throws away the results, and grabs sf.features. And so that's now my 30-second layer activations, which I can then do my MSC loss on. You might have noticed the last loss function and this one are both multiplied by 1000. Why are they multiplied by 1000? Again, this was like all the things that were trying to get this lesson to not work correctly. I didn't used to have the 1000. It wasn't training. Lunchtime today, nothing was working after days of trying to get this thing to work. And finally, just randomly noticed, the last functions, the numbers are really low, like 10e and x7. And I just thought, what if they weren't so low? So I multiplied them by 1000 and it started working. So why did it not work? Because we're doing single precision floating point, and single precision floating point ain't that precise. And particularly once you're getting gradients that are kind of small and then you're multiplying by the learning rate, it can be kind of small, and you end up with a small number. And if it's so small, it could get rounded to 0, and that's what was happening and my model wasn't training. So I'm sure there are better ways to multiply by 1000, but whatever, it works fine. It doesn't matter what you multiply a loss function by, because all you care about is its direction and its relative size. And interestingly, this is actually something similar we do for when we were training ImageNet. We were using half precision floating point, because the Volta tensor cores require that. And it's actually a standard practice if you want to get the half precision floating point to train, you actually have to multiply the loss function by a scaling factor. And we were using 1024 or 512. And I think FastAI is now the first library that has all of the tricks necessary to train in half precision floating point built in. So if you have a lucky enough to have a Volta, or you can pay for a P3, if you've got a learner object, you can just say learn.half, and it will now just magically train correctly half precision floating point. Built into the model data objects as well, it's all automatic, and pretty sure no other library does that. So this is just doing the same thing on a slightly earlier layer. And you can see that the bird looks, the later layer doesn't look very bird-like at all, but you can kind of tell it's a bird. Slightly earlier layer, more bird-like. And hopefully that makes sense to you that earlier layers are getting closer to the pixels. It's a smaller grid size, more grid cells, each cell is smaller, smaller receptive field, less complex semantic features. So the earlier we get, the more it's going to look like a bird. And in fact, the paper has a nice picture of that showing various different layers and kind of zooming into this house. They're trying to make this house look like this picture. And you can see that later on, it's pretty messy, and earlier on, it looks like this. So this is just doing what we just did. And I will say, one of the things I've noticed in our study group is anytime I say to answer a question, anytime I say, read the paper, there's a thing in the paper that tells you the answer to that question, there's always this shocked look. Read the paper? Me? The paper? But seriously, the papers have, they've done these experiments and drawn the pictures. Like there's all this stuff in the papers. It doesn't mean you have to read every part of the paper, but at least look at the pictures. So check out the Gaddy's paper, it's got nice pictures. So they've done the experiment for us. They basically did this experiment. But it looks like they didn't go as deep, they just got some earlier ones. The next thing we need to do is to create style loss. So we've already got the loss, which is how much like the bird is it. Now we need how much like this painting's style is it. And we're going to do nearly the same thing. We're going to grab the activations of some layer. Now the problem is that the activations of some layer, let's say it was a 5x5 layer. There are no 5x5 layers at 224x224, but we'll pretend. 5x5x19. Totally unrealistic sizes, but never mind. So here's some activations, and we can get these activations both for the image we're optimizing and for our Van Gogh painting. I downloaded this from Wikipedia, and I was wondering why it was taking so long to load. It turns out that the Wikipedia version I downloaded was 30,000x30,000 pixels. It's pretty cool, they've got this serious gallery-quality archive stuff there. I didn't know it existed, so don't try and run a neural net on that. Totally killed my Jupyter Notebook. So we can do that for our Van Gogh image, and we can do that for our optimizer image. And then we can compare the two, and we would end up creating an image that looks content like the painting, but it's not the painting. That's not what we want. We want something with the same style, but it's not the painting, it doesn't have the content. So we actually want to throw away all of the spatial information. We're not trying to create something that has a moon here and stars here and a church here and whatever. We don't want any of that. So how do we throw away all the spatial information? What we do is, let's grab, so in this case there are like 19 faces on this, like 19 slices. So let's grab this top slice. Let's grab that top slice. So that's going to be a 5x5 matrix. And now let's flatten it. So now we've got a 25 long vector. Now in one stroke, we've thrown away the bulk of the spatial information by flattening it. Now let's grab a second slice, so another channel, and do the same thing. So here's channel 1 flattened, here's channel 2 flattened, and they've both got 25 elements. And now let's take the dot product, which we can do with at. And so the dot product is going to give us one number. What's that number? What is it telling us? Well assuming this is somewhere around the middle activation, the activations are somewhere around the middle layer of the VGG network, we might expect some of these activations to be like how textured is the brush stroke, and some of them to be like how bright is this area, and some of them to be like is this part of a house or part of a circular thing, or other parts to be how dark is this part of the painting. And so a dot product, remember, is basically a correlation. If this element and this element are both highly positive or both highly negative, it gives us a big result, or else if they're the opposite, it gives us more result. If they're both close to 0, it gives no result. So it's basically a dot product as a measure of how similar these two things are. And so if the activations of channel 1 and channel 2 are similar, then it basically says, let's give an example, let's say this first one was like how textured are the brush strokes, and this one here, let's say, was like how kind of diagonally oriented are the brush strokes. And if both of these were high together and both of these were high together, then it's basically saying anywhere that there's more textured brush strokes, they tend to be diagonal. Another interesting one is what would be the dot product of C1 with C1? So that would be basically the 2-norm, the sum of the squares of that channel. Which in other words is basically just, on average, how, sorry, let's go back, I screwed this up. Channel 1 might be texture and channel 2 might be diagonal. And this one here would be cell 1,1. And this cell here would be like cell say 4,2. And so, sorry, what I should have been saying is if these are both high at the same time and these are both high at the same time, then it's saying grid cells that have texture tend to also have diagonal. So this number is going to be high when grid cells that have texture also have diagonal and when they don't, they don't. So that's C1.product C2. Whereas C1.product C1 is basically, as we said, the 2-norm effectively, or the sum of the squares of C1. Sum over i of C1 squared. And this is basically saying how in how many grid cells is the textured channel active and how active is it. So in other words, C1.product C1 tells us how much textured painting is going on. And C2.product C2 tells us how much diagonal paint strokes is going on. And maybe C3 is bright colors. So C3.product C3 would be how often do we have bright colored cells. So what we could do then is we could create a 25 by 25 matrix containing every one, channel 1, channel 2, channel 3, channel 1, channel 2, channel 3, sorry not channel, man it's been a long day. 19, there are 19 channels. 19 by 19. Channel 1, channel 2, channel 3, channel 19, channel 1, channel 2, channel 3, channel 19, okay. And so this would be the dot product of channel 1 with channel 1, this would be the dot product of channel 2 with channel 2, and so forth, after flattening. And like we've discussed, mathematicians have to give everything a name. So this particular matrix where you flatten something out and then do all the dot products is called a Gram matrix. And I'll tell you a secret, most deep learning practitioners either don't know or don't remember all these things like what is a Gram matrix, if they ever did study at university they probably forgot it because they had a big night afterwards. And the way it works in practice is like you realize, oh I could create a kind of non-spatial representation of how the channels correlate with each other, and then when I write up the paper I have to go and ask around and say like, does this thing have a name? And somebody would be like, isn't that the Gram matrix? And you go and look it up, and it is. So don't think like you have to go and study all of math first, use your intuition and common sense and then you worry about what the math is called later, normally. Sometimes it works the other way, not with me because I can't do math. So this is called the Gram matrix, and of course if you're a real mathematician it's very important that you say this as if you always knew it was a Gram matrix and you kind of just go, oh yes we just calculated the Gram matrix. That's really important. So the Gram matrix then is this kind of map of the diagonal is perhaps the most interesting. The diagonal is like which channels are the most active, and then the off diagonal is like which channels tend to appear together. And overall, if two pictures have the same style, then we're expecting that some layer of activations, they will have similar Gram matrices, because if we found the level of activations that capture a lot of stuff about like paint strokes and colors and stuff, then the diagonal alone might even be enough. And like that's another interesting homework assignment if somebody wants to take it, is try doing Gattie style transfer not using the Gram matrix, but just using the diagonal of the Gram matrix. And that would be like a single line of code to change, but I haven't seen it tried. I don't know if it would work at all, but it might work fine. Christine, you've tried it. I was going to say I have tried that, and it works most of the time except when you have funny pictures where you need two styles to appear in the same spot. So if you have like grass in one half and like a crowd in one half, and you need the two styles. Cool. You still got to do your homework. But okay, Christine says she'll do it for you. Okay, so let's do that. So here's our painting. I've tried to resize the painting so it's the same size as my bird picture. So that's all this is just doing. So there it is. It doesn't matter too much which bit I use as long as it's got lots of the nice style in it. I grab my optimizer and my random image just like before, and this time I call saveFeatures for all of my block ends, and that's going to give me an array of saveFeatures objects, one for each module that appears the layer before a maxPull. Because this time I want to play around with different activation layer styles, or more specifically I want to let you play around with it. So now I've got a whole array of them. So now I call my VGG module on my image again. Style image is my Van Gogh painting. So I take my style image, put it through my transformations to create my transform style image, I turn that into a variable, put it through the forward pass of my VGG module, and now I can go through all of my saveFeatures objects and grab each set of features. Notice I call clone, because later on if I call my VGG object again, it's going to replace those contents. I haven't quite thought about whether this is necessary, if you take it away, it's fine, but I was just being careful. So here's now an array of the activations at every block end layer. So here you can see all of those shapes. And you can see being able to whip up a list comprehension really quickly, it's really important in your Jupyter fiddling around, because you really want to be able to immediately see, here's my channel, 64, 138, 255, 12, and you can see here the grid size halving, as we would expect, because all of these appeared just before a maxpull. So to do a gram MSC loss, it's going to be the MSC loss on the gram matrix of the input versus the gram matrix of the target. And the gram matrix is just the matrix multiply of X with X transpose, where X is simply equal to my input, where I flattened the batch and channel axes all down together. And I've only got one image, so you can kind of ignore the batch part, it's basically channel, and then everything else, which in this case is the height and width, is the other dimension. So it's now going to be channel by height and width, and then as we discussed, we can then just do the matrix multiply of that by its transpose. And just to normalize it, we'll divide that by the number of elements. It would actually be more elegant if I had said divided by input.num elements. That would be the same thing. And then again, this kind of gives me tiny numbers, so I multiply it by a big number to make it something more sensible. So that's basically my loss. So now my style loss is to take my image to optimize, throw it through VGG forward pass, grab an array of the features in all of the, say, features objects, and then call my gram msc loss on every one of those layers. And that's going to give me an array. And then I just add them up. Now you could add them up with different weightings, you could add up a subset, whatever. In this case, I'm just grabbing all of them. Pass that into my optimizer as before, and here we have a random image in the style of Van Gogh, which I think is kind of cool. And again, Gaddy's has done it for us. Here is different layers of random image in the style of Van Gogh. And so the first one, as you can see, the activations are simple geometric things, not very interesting at all. The later layers are much more interesting. So we kind of have a suspicion that we probably want to use later layers largely for our style loss if we want it to look good. I added this save features.close which just calls, remember I stored the hook here, and so hook.remove gets rid of it. And it's a good idea to get rid of it because otherwise you can potentially just keep using memory. So at the end, I go through each of my save features object and close it. So style transfer is adding the two together with some weight. So there's not much to show. Grab my optimizer, grab my image, and now my combined loss is the MSC loss at one particular layer, my style loss at all of my layers, sum up the style losses, add them to the content loss, the content loss I'm scaling. Actually the style loss I scaled already by 1.6 and this one is 1, 2, 3, 4, 5, 6. So actually they're both scaled exactly the same. Add them together, and again you could try weighting the different style losses or you could maybe remove some of them, whatever. So this is the simplest possible version. Train that, and like holy shit, it actually looks good. So I think that's pretty awesome. Again the main takeaway here is if you want to solve something with a neural network, all you've got to do is set up a loss function and then optimize something. The loss function is something which a lower number is something that you're happier with. Because then when you optimize it, it's going to make that number as low as you can and it will do what you wanted it to do. So here Gaddy's came up with a loss function that does a good job of being a smaller number when it looks like the thing we want it to look like and it looks like the style of the thing we want it to be in the style of. That's all we had to do. When it actually comes to it, apart from implementing gramm-mse loss, which was like 6 lines of code, that's our loss function, pass it to our optimizer, wait about 5 seconds and we're done. And remember we could do a batch of these at a time, so we could wait 5 seconds and 64 of these would be done. So I think that's really interesting and since this paper came out, it's really inspired a lot of interesting work. To me though, most of the interesting work hasn't happened yet. To me, the interesting work is the work where you combine human creativity with these kinds of tools. I haven't seen much in the way of tools that you can download or use where the artist is in control and can kind of do things interactively. It's interesting talking to the guys at the Google Magenta project, which is kind of their creative AI project, all of the stuff they're doing with music is specifically about this. It's building tools that musicians can use to perform in real time. And so you'll see much more of that on the music space thanks to Magenta. If you go to their website, there's all kinds of things where you can press the buttons to actually change the drum beats or melodies or keys or whatever. And you can definitely see Adobe and Nvidia starting to release little prototypes that are starting to do this. This kind of creative AI explosion hasn't happened yet. I think we have pretty much all the technology we need, but no one's put it together into a thing and said, look at the thing I built and look at the stuff that people built with my thing. So that's just a huge area of opportunity. So the paper that I mentioned at the start of class in passing, the one where we can add Captain America's shield to arbitrary paintings, basically used this technique. The trick was, though, some minor tweaks to make the pasted Captain America shield blend in nicely. That paper's only a couple of days old, so that would be a really interesting project to try. You can use all this code, it really does leverage this approach. And then you could start by making the content image be like the painting with the shield, and then the style image could be the painting without the shield. And that would be a good start, and then you could kind of see what specific problems they tried to solve in this paper to make it better. But you could have a start on it right now. So let's make a quick start on the next bit, which is, yes, Rachel. Question from the audience. Earlier there were a number of people that expressed interest in your thoughts on Pyro and probabilistic programming. So TensorFlow's now got this, what do they call it, TensorFlow probability or something. There's a bunch of probabilistic programming frameworks out there. I think they're intriguing, but as yet unproven in the sense that I haven't seen anything done with any probabilistic programming system which hasn't been done better without them. The basic premise is that it allows you to create more of a model of how you think the world works and then plug in the parameters. So back when I used to work in management consulting 20 years ago, we used to do a lot of stuff where we would use a spreadsheet and then we would have these Monte Carlo simulation plugins. There's one called At Risk and one called Crystal Ball. I don't know if they still exist decades later. But basically they would let you change a spreadsheet cell to say this is not a specific value but it actually represents a distribution of values with this mean and standard deviation or it's got this distribution. And then you would hit a button and the spreadsheet would recalculate a thousand times pulling random numbers from the distributions and show you the distribution of your outcome that might be some profit or market share or whatever. And we used them all the time back then. I partly feel that a spreadsheet is a more obvious place to do that kind of work because you can kind of see it all much more naturally. But I don't know, we'll see. At this stage, I hope it turns out to be useful because I find it very appealing and it kind of appeals to, as I say, the kind of work I used to do a lot of. There's actually whole practices around this stuff they used to call systems dynamics which really was built on top of this kind of stuff. But I don't know, it's not quite gone anywhere. Question about pre-training for generic style transfer. Yes, I don't think you can pre-train for a generic style, but you can pre-train for a generic photo for a particular style, which is where we're going to get to. Although it may end up being homework, I haven't decided. But I'm going to do all the pieces. One more question is, please ask him to talk about multi-GPU. Before we do, just another interesting picture from the Gaddy's paper. They've got a few more, just didn't fit in my slide here. Different convolutional layers for the style, different style to content ratios. Obviously this isn't Van Gogh anymore, this is a different combination. So you can see if you just do all style, you don't see any image. If you do lots of content, but you use a low enough convolutional layer, it looks okay, but the background is kind of dumb. So you kind of want somewhere around here or here, I guess. So you can play around with the experiment, but also use the paper to help guide you. Actually I think I might work on the math now, and we'll talk about multi-GPU and super resolution next week. I think this is from the paper, and one of the things I really do want you to do after we talk about a paper is to read the paper and then ask questions on the forum, anything that's not clear. But there's kind of like a key part of this paper which I wanted to talk about and discuss how to interpret it. So the paper says we're going to be given an input image X, and this little thing means it's a vector, but this one's a matrix. So normally small letter bold means vector, or small letter with doobie on top means vector, and normally big letter means matrix, or small letter with two doobies on top means matrix. In this case our image is a matrix. We are going to basically treat it as a vector, so maybe we're just getting ahead of ourselves. So we've got an input image X, and it can be encoded in a particular layer of the CNN by the filter responses, so the activations. Filter responses are activations. So hopefully that's something you all understand. That's basically what a CNN does, it produces layers of activations. A layer has a bunch of filters which produce a number of channels. And so this here says that layer number L has capital NL filters. And again this capital does not mean matrix. So I don't know, math notation is so inconsistent. So capital NL distinct filters at layer L, which means it has also that many feature maps. So make sure you can see that this letter is the same as this letter. So you've got to be very careful to read the letters and recognize it's like snap, that's the same letter as that. So obviously NL feature maps or NL filters create NL feature maps or channels. H1 is of size M, so I can see this is where the unrolling is happening. Hbap is of size M little l. So this is like M square bracket L in NumPy notation, it's the Lth layer. So M for the Lth layer. And the size is height times width. So we flattened it out. So the responses at that layer L can be stored in a matrix F, and now the L goes at the top for some reason. So this is not F to the power of L, this is just another indexing, we're just moving it around for fun. And this thing here where we say it's an element of R, this is a special R meaning the real numbers, N times M, this is saying that the dimensions of this is N by M. So this is really important, it's just like with PyTorch, making sure you understand the rank and size of your dimensions first. Same with math, these are the bits where you stop and think, why is it N by M? So N is the number of filters, M is height by width. So do you remember that thing where we did view batch times channel, minus 1? Here that is. So try to map the code to the math. So F is X. If I was nicer to you, I would have used the same letters as the paper, but I was too busy getting this damn thing working to do that carefully. So you can go back and rename it as capital F. This is why we moved the L to the top, because we're now going to have some more indexing. So like where else in NumPy or PyTorch we index things by square brackets and lots of things with commas between, the approach in math is to surround your letter by little letters all around it. Just throw them up there everywhere. So here FL is the Lth layer of F, and then ij is the activation of the i-th filter at position j of layer L. So position j is up to size M, which is up to size height by width. This is the kind of thing that would be easy to get confused. Like often you'd see an ij and assume that's indexing into a position of an image, like height by width, but it's totally not, is it? It's indexing into channel by flattened image. And it even tells you, it's the i-th filter, the i-th channel in the j-th position in the flattened out image in layer L. So you're not going to be able to get any further in the paper unless you know, unless you understand what F is. So that's why these are the bits where you stop and make sure you're comfortable. So now, the content loss, I'm not going to spend much time on, but basically we're going to just check out the values of the activations versus the predictions squared. So there's our content loss. And the style loss will be much the same thing, but using the Gram matrix G. And I really wanted to show you this one, because I think it's super, sometimes I really like things you can do in math notation, and there are things you can also generally do in J and APL, which is there's kind of this implicit loop going on here. What this is saying is there's a whole bunch of values of i and a whole bunch of values of j, and I've got to define g for all of them. And there's a whole bunch of values of L as well. I'm going to define g for all of those as well. And so for all of my g at every L, every i, every j, it's going to be equal to something. And you can see the something has an i and a j and an L, so matching these. And it also has a k, and that's part of the sum. So what's going on here? Well, it's saying that my Gram matrix in layer L for the ith channel, well these aren't channels anymore, in the ith position in one axis and the jth position in another axis, is equal to my F matrix, so my flattened out matrix, for the ith channel in that layer versus the jth channel in the same layer. And then I'm going to sum over, so you see this k and this k, they're the same letter. So we're going to take the kth position and multiply them together and then add them all up. So that's exactly what we just did before when we calculated our Gram matrix. So like this, there's a lot going on because of some, to me, very neat notation. There are 3 implicit loops all going on at the same time, plus 1 explicit loop in the sum, and then they all work together to create this Gram matrix for every layer. So let's go back and see if you can match this. So all that's kind of happening all at once, which I think is pretty great. So that's it. So next week we're going to be looking at a very similar approach, basically doing style transfer all over again, but in a way where we're actually going to train a neural network to do it for us, rather than having to do the optimization. We'll also see that you can do the same thing to do super resolution. And we're also going to go back and revisit some of that SSD stuff, as well as doing some segmentation. So if you've forgotten SSD, it might be worth doing a little bit of revision this week. Thanks everybody, see you next week.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.4, "text": " Welcome to lesson 13, where we're going to be talking about image enhancement.", "tokens": [4027, 281, 6898, 3705, 11, 689, 321, 434, 516, 281, 312, 1417, 466, 3256, 40776, 13], "temperature": 0.0, "avg_logprob": -0.16681947600975466, "compression_ratio": 1.8229665071770336, "no_speech_prob": 0.007343268487602472}, {"id": 1, "seek": 0, "start": 11.4, "end": 15.76, "text": " Image enhancement would cover things like this painting that you might be familiar with.", "tokens": [29903, 40776, 576, 2060, 721, 411, 341, 5370, 300, 291, 1062, 312, 4963, 365, 13], "temperature": 0.0, "avg_logprob": -0.16681947600975466, "compression_ratio": 1.8229665071770336, "no_speech_prob": 0.007343268487602472}, {"id": 2, "seek": 0, "start": 15.76, "end": 20.94, "text": " However, you might not have noticed before that this painting actually has a picture", "tokens": [2908, 11, 291, 1062, 406, 362, 5694, 949, 300, 341, 5370, 767, 575, 257, 3036], "temperature": 0.0, "avg_logprob": -0.16681947600975466, "compression_ratio": 1.8229665071770336, "no_speech_prob": 0.007343268487602472}, {"id": 3, "seek": 0, "start": 20.94, "end": 22.76, "text": " of an eagle in it.", "tokens": [295, 364, 30745, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.16681947600975466, "compression_ratio": 1.8229665071770336, "no_speech_prob": 0.007343268487602472}, {"id": 4, "seek": 0, "start": 22.76, "end": 25.96, "text": " The reason you may not have noticed that before is this painting actually didn't used to have", "tokens": [440, 1778, 291, 815, 406, 362, 5694, 300, 949, 307, 341, 5370, 767, 994, 380, 1143, 281, 362], "temperature": 0.0, "avg_logprob": -0.16681947600975466, "compression_ratio": 1.8229665071770336, "no_speech_prob": 0.007343268487602472}, {"id": 5, "seek": 0, "start": 25.96, "end": 28.28, "text": " an eagle in it.", "tokens": [364, 30745, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.16681947600975466, "compression_ratio": 1.8229665071770336, "no_speech_prob": 0.007343268487602472}, {"id": 6, "seek": 2828, "start": 28.28, "end": 31.76, "text": " By the same token actually on that first page, this painting did not used to have Captain", "tokens": [3146, 264, 912, 14862, 767, 322, 300, 700, 3028, 11, 341, 5370, 630, 406, 1143, 281, 362, 10873], "temperature": 0.0, "avg_logprob": -0.16705402658005392, "compression_ratio": 1.7117437722419928, "no_speech_prob": 2.97712285828311e-05}, {"id": 7, "seek": 2828, "start": 31.76, "end": 34.52, "text": " America's shield on it either.", "tokens": [3374, 311, 10257, 322, 309, 2139, 13], "temperature": 0.0, "avg_logprob": -0.16705402658005392, "compression_ratio": 1.7117437722419928, "no_speech_prob": 2.97712285828311e-05}, {"id": 8, "seek": 2828, "start": 34.52, "end": 37.96, "text": " And this painting did not used to have a clock in it either.", "tokens": [400, 341, 5370, 630, 406, 1143, 281, 362, 257, 7830, 294, 309, 2139, 13], "temperature": 0.0, "avg_logprob": -0.16705402658005392, "compression_ratio": 1.7117437722419928, "no_speech_prob": 2.97712285828311e-05}, {"id": 9, "seek": 2828, "start": 37.96, "end": 42.72, "text": " This is a cool new paper actually that just came out a couple of days ago called Deep", "tokens": [639, 307, 257, 1627, 777, 3035, 767, 300, 445, 1361, 484, 257, 1916, 295, 1708, 2057, 1219, 14895], "temperature": 0.0, "avg_logprob": -0.16705402658005392, "compression_ratio": 1.7117437722419928, "no_speech_prob": 2.97712285828311e-05}, {"id": 10, "seek": 2828, "start": 42.72, "end": 44.160000000000004, "text": " Painterly Harmonization.", "tokens": [24943, 391, 356, 40599, 2144, 13], "temperature": 0.0, "avg_logprob": -0.16705402658005392, "compression_ratio": 1.7117437722419928, "no_speech_prob": 2.97712285828311e-05}, {"id": 11, "seek": 2828, "start": 44.160000000000004, "end": 50.24, "text": " And it uses almost exactly the technique we're going to learn in this lesson with some minor", "tokens": [400, 309, 4960, 1920, 2293, 264, 6532, 321, 434, 516, 281, 1466, 294, 341, 6898, 365, 512, 6696], "temperature": 0.0, "avg_logprob": -0.16705402658005392, "compression_ratio": 1.7117437722419928, "no_speech_prob": 2.97712285828311e-05}, {"id": 12, "seek": 2828, "start": 50.24, "end": 51.24, "text": " tweaks.", "tokens": [46664, 13], "temperature": 0.0, "avg_logprob": -0.16705402658005392, "compression_ratio": 1.7117437722419928, "no_speech_prob": 2.97712285828311e-05}, {"id": 13, "seek": 2828, "start": 51.24, "end": 57.040000000000006, "text": " But you can see the basic idea is take one picture, paste it on top of another picture,", "tokens": [583, 291, 393, 536, 264, 3875, 1558, 307, 747, 472, 3036, 11, 9163, 309, 322, 1192, 295, 1071, 3036, 11], "temperature": 0.0, "avg_logprob": -0.16705402658005392, "compression_ratio": 1.7117437722419928, "no_speech_prob": 2.97712285828311e-05}, {"id": 14, "seek": 5704, "start": 57.04, "end": 61.32, "text": " and then use some kind of approach to combine the two.", "tokens": [293, 550, 764, 512, 733, 295, 3109, 281, 10432, 264, 732, 13], "temperature": 0.0, "avg_logprob": -0.1599107155433068, "compression_ratio": 1.5528455284552845, "no_speech_prob": 1.450976742489729e-05}, {"id": 15, "seek": 5704, "start": 61.32, "end": 67.96, "text": " And the basic approach is something called a style transfer.", "tokens": [400, 264, 3875, 3109, 307, 746, 1219, 257, 3758, 5003, 13], "temperature": 0.0, "avg_logprob": -0.1599107155433068, "compression_ratio": 1.5528455284552845, "no_speech_prob": 1.450976742489729e-05}, {"id": 16, "seek": 5704, "start": 67.96, "end": 74.16, "text": " Before we talk about that though, I wanted to mention this really cool contribution by", "tokens": [4546, 321, 751, 466, 300, 1673, 11, 286, 1415, 281, 2152, 341, 534, 1627, 13150, 538], "temperature": 0.0, "avg_logprob": -0.1599107155433068, "compression_ratio": 1.5528455284552845, "no_speech_prob": 1.450976742489729e-05}, {"id": 17, "seek": 5704, "start": 74.16, "end": 80.46000000000001, "text": " William Horton, who added this stochastic weight averaging technique to the FastAI library.", "tokens": [6740, 389, 36184, 11, 567, 3869, 341, 342, 8997, 2750, 3364, 47308, 6532, 281, 264, 15968, 48698, 6405, 13], "temperature": 0.0, "avg_logprob": -0.1599107155433068, "compression_ratio": 1.5528455284552845, "no_speech_prob": 1.450976742489729e-05}, {"id": 18, "seek": 5704, "start": 80.46000000000001, "end": 85.75999999999999, "text": " That is now all merged and ready to go, and he's written a whole post about that, which", "tokens": [663, 307, 586, 439, 36427, 293, 1919, 281, 352, 11, 293, 415, 311, 3720, 257, 1379, 2183, 466, 300, 11, 597], "temperature": 0.0, "avg_logprob": -0.1599107155433068, "compression_ratio": 1.5528455284552845, "no_speech_prob": 1.450976742489729e-05}, {"id": 19, "seek": 8576, "start": 85.76, "end": 91.2, "text": " I strongly recommend you check out, not just because stochastic weight averaging actually", "tokens": [286, 10613, 2748, 291, 1520, 484, 11, 406, 445, 570, 342, 8997, 2750, 3364, 47308, 767], "temperature": 0.0, "avg_logprob": -0.13956714370875684, "compression_ratio": 1.6223021582733812, "no_speech_prob": 1.922267438203562e-05}, {"id": 20, "seek": 8576, "start": 91.2, "end": 96.08000000000001, "text": " lets you get higher performance from your existing neural networks with basically no", "tokens": [6653, 291, 483, 2946, 3389, 490, 428, 6741, 18161, 9590, 365, 1936, 572], "temperature": 0.0, "avg_logprob": -0.13956714370875684, "compression_ratio": 1.6223021582733812, "no_speech_prob": 1.922267438203562e-05}, {"id": 21, "seek": 8576, "start": 96.08000000000001, "end": 97.52000000000001, "text": " extra work.", "tokens": [2857, 589, 13], "temperature": 0.0, "avg_logprob": -0.13956714370875684, "compression_ratio": 1.6223021582733812, "no_speech_prob": 1.922267438203562e-05}, {"id": 22, "seek": 8576, "start": 97.52000000000001, "end": 101.56, "text": " It's as simple as adding these two parameters to your fit function.", "tokens": [467, 311, 382, 2199, 382, 5127, 613, 732, 9834, 281, 428, 3318, 2445, 13], "temperature": 0.0, "avg_logprob": -0.13956714370875684, "compression_ratio": 1.6223021582733812, "no_speech_prob": 1.922267438203562e-05}, {"id": 23, "seek": 8576, "start": 101.56, "end": 107.0, "text": " But also he's described his process of building this and how he tested it and how he contributed", "tokens": [583, 611, 415, 311, 7619, 702, 1399, 295, 2390, 341, 293, 577, 415, 8246, 309, 293, 577, 415, 18434], "temperature": 0.0, "avg_logprob": -0.13956714370875684, "compression_ratio": 1.6223021582733812, "no_speech_prob": 1.922267438203562e-05}, {"id": 24, "seek": 8576, "start": 107.0, "end": 108.0, "text": " to the library.", "tokens": [281, 264, 6405, 13], "temperature": 0.0, "avg_logprob": -0.13956714370875684, "compression_ratio": 1.6223021582733812, "no_speech_prob": 1.922267438203562e-05}, {"id": 25, "seek": 8576, "start": 108.0, "end": 112.0, "text": " So I think it's interesting, you know, if you're interested in doing something like", "tokens": [407, 286, 519, 309, 311, 1880, 11, 291, 458, 11, 498, 291, 434, 3102, 294, 884, 746, 411], "temperature": 0.0, "avg_logprob": -0.13956714370875684, "compression_ratio": 1.6223021582733812, "no_speech_prob": 1.922267438203562e-05}, {"id": 26, "seek": 11200, "start": 112.0, "end": 119.2, "text": " this, I think William had not built this kind of library before, so he describes how he", "tokens": [341, 11, 286, 519, 6740, 632, 406, 3094, 341, 733, 295, 6405, 949, 11, 370, 415, 15626, 577, 415], "temperature": 0.0, "avg_logprob": -0.09828641791092722, "compression_ratio": 1.6223175965665235, "no_speech_prob": 3.187548827554565e-06}, {"id": 27, "seek": 11200, "start": 119.2, "end": 122.16, "text": " did it.", "tokens": [630, 309, 13], "temperature": 0.0, "avg_logprob": -0.09828641791092722, "compression_ratio": 1.6223175965665235, "no_speech_prob": 3.187548827554565e-06}, {"id": 28, "seek": 11200, "start": 122.16, "end": 130.32, "text": " Another very cool contribution to the FastAI library is a new train phase API.", "tokens": [3996, 588, 1627, 13150, 281, 264, 15968, 48698, 6405, 307, 257, 777, 3847, 5574, 9362, 13], "temperature": 0.0, "avg_logprob": -0.09828641791092722, "compression_ratio": 1.6223175965665235, "no_speech_prob": 3.187548827554565e-06}, {"id": 29, "seek": 11200, "start": 130.32, "end": 134.56, "text": " And I'm going to do something I've never done before, which I'm actually going to present", "tokens": [400, 286, 478, 516, 281, 360, 746, 286, 600, 1128, 1096, 949, 11, 597, 286, 478, 767, 516, 281, 1974], "temperature": 0.0, "avg_logprob": -0.09828641791092722, "compression_ratio": 1.6223175965665235, "no_speech_prob": 3.187548827554565e-06}, {"id": 30, "seek": 11200, "start": 134.56, "end": 136.4, "text": " somebody else's notebook.", "tokens": [2618, 1646, 311, 21060, 13], "temperature": 0.0, "avg_logprob": -0.09828641791092722, "compression_ratio": 1.6223175965665235, "no_speech_prob": 3.187548827554565e-06}, {"id": 31, "seek": 11200, "start": 136.4, "end": 141.28, "text": " And the reason I haven't done it before is because I haven't liked any notebooks enough", "tokens": [400, 264, 1778, 286, 2378, 380, 1096, 309, 949, 307, 570, 286, 2378, 380, 4501, 604, 43782, 1547], "temperature": 0.0, "avg_logprob": -0.09828641791092722, "compression_ratio": 1.6223175965665235, "no_speech_prob": 3.187548827554565e-06}, {"id": 32, "seek": 14128, "start": 141.28, "end": 147.16, "text": " to think they're worth presenting, but Silvan's done a fantastic job here of not just creating", "tokens": [281, 519, 436, 434, 3163, 15578, 11, 457, 6943, 9768, 311, 1096, 257, 5456, 1691, 510, 295, 406, 445, 4084], "temperature": 0.0, "avg_logprob": -0.15859099796840123, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.3419593415164854e-05}, {"id": 33, "seek": 14128, "start": 147.16, "end": 151.8, "text": " this new API, but also creating a beautiful notebook describing what it is and how it", "tokens": [341, 777, 9362, 11, 457, 611, 4084, 257, 2238, 21060, 16141, 437, 309, 307, 293, 577, 309], "temperature": 0.0, "avg_logprob": -0.15859099796840123, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.3419593415164854e-05}, {"id": 34, "seek": 14128, "start": 151.8, "end": 153.44, "text": " works and so forth.", "tokens": [1985, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.15859099796840123, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.3419593415164854e-05}, {"id": 35, "seek": 14128, "start": 153.44, "end": 162.12, "text": " And the background here is, as you guys know, we've been trying to train networks faster,", "tokens": [400, 264, 3678, 510, 307, 11, 382, 291, 1074, 458, 11, 321, 600, 668, 1382, 281, 3847, 9590, 4663, 11], "temperature": 0.0, "avg_logprob": -0.15859099796840123, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.3419593415164854e-05}, {"id": 36, "seek": 14128, "start": 162.12, "end": 166.8, "text": " partly as part of this Dawnbench competition, and also for a reason that you'll learn about", "tokens": [17031, 382, 644, 295, 341, 26001, 47244, 6211, 11, 293, 611, 337, 257, 1778, 300, 291, 603, 1466, 466], "temperature": 0.0, "avg_logprob": -0.15859099796840123, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.3419593415164854e-05}, {"id": 37, "seek": 14128, "start": 166.8, "end": 170.04, "text": " next week.", "tokens": [958, 1243, 13], "temperature": 0.0, "avg_logprob": -0.15859099796840123, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.3419593415164854e-05}, {"id": 38, "seek": 17004, "start": 170.04, "end": 176.2, "text": " And I mentioned on the forums last week it would be really handy for our experiments", "tokens": [400, 286, 2835, 322, 264, 26998, 1036, 1243, 309, 576, 312, 534, 13239, 337, 527, 12050], "temperature": 0.0, "avg_logprob": -0.14128113718866145, "compression_ratio": 1.6388888888888888, "no_speech_prob": 1.0615699466143269e-05}, {"id": 39, "seek": 17004, "start": 176.2, "end": 180.76, "text": " if we had an easier way to try out different learning rate schedules and stuff.", "tokens": [498, 321, 632, 364, 3571, 636, 281, 853, 484, 819, 2539, 3314, 28078, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.14128113718866145, "compression_ratio": 1.6388888888888888, "no_speech_prob": 1.0615699466143269e-05}, {"id": 40, "seek": 17004, "start": 180.76, "end": 184.28, "text": " And I basically laid out an API that I had in mind.", "tokens": [400, 286, 1936, 9897, 484, 364, 9362, 300, 286, 632, 294, 1575, 13], "temperature": 0.0, "avg_logprob": -0.14128113718866145, "compression_ratio": 1.6388888888888888, "no_speech_prob": 1.0615699466143269e-05}, {"id": 41, "seek": 17004, "start": 184.28, "end": 189.16, "text": " I said it would be really cool if somebody could write this because I'm going to bed", "tokens": [286, 848, 309, 576, 312, 534, 1627, 498, 2618, 727, 2464, 341, 570, 286, 478, 516, 281, 2901], "temperature": 0.0, "avg_logprob": -0.14128113718866145, "compression_ratio": 1.6388888888888888, "no_speech_prob": 1.0615699466143269e-05}, {"id": 42, "seek": 17004, "start": 189.16, "end": 192.68, "text": " now and I kind of need it by tomorrow.", "tokens": [586, 293, 286, 733, 295, 643, 309, 538, 4153, 13], "temperature": 0.0, "avg_logprob": -0.14128113718866145, "compression_ratio": 1.6388888888888888, "no_speech_prob": 1.0615699466143269e-05}, {"id": 43, "seek": 17004, "start": 192.68, "end": 197.84, "text": " And Silvan replied on the forum, well that sounds like a good challenge.", "tokens": [400, 6943, 9768, 20345, 322, 264, 17542, 11, 731, 300, 3263, 411, 257, 665, 3430, 13], "temperature": 0.0, "avg_logprob": -0.14128113718866145, "compression_ratio": 1.6388888888888888, "no_speech_prob": 1.0615699466143269e-05}, {"id": 44, "seek": 19784, "start": 197.84, "end": 201.72, "text": " And by 24 hours later, it was done.", "tokens": [400, 538, 4022, 2496, 1780, 11, 309, 390, 1096, 13], "temperature": 0.0, "avg_logprob": -0.1372853212578352, "compression_ratio": 1.5025125628140703, "no_speech_prob": 4.860398803430144e-06}, {"id": 45, "seek": 19784, "start": 201.72, "end": 203.48, "text": " And it's been super cool.", "tokens": [400, 309, 311, 668, 1687, 1627, 13], "temperature": 0.0, "avg_logprob": -0.1372853212578352, "compression_ratio": 1.5025125628140703, "no_speech_prob": 4.860398803430144e-06}, {"id": 46, "seek": 19784, "start": 203.48, "end": 210.52, "text": " I want to take you through it because it's going to allow you to do research into things", "tokens": [286, 528, 281, 747, 291, 807, 309, 570, 309, 311, 516, 281, 2089, 291, 281, 360, 2132, 666, 721], "temperature": 0.0, "avg_logprob": -0.1372853212578352, "compression_ratio": 1.5025125628140703, "no_speech_prob": 4.860398803430144e-06}, {"id": 47, "seek": 19784, "start": 210.52, "end": 213.2, "text": " that nobody's tried before.", "tokens": [300, 5079, 311, 3031, 949, 13], "temperature": 0.0, "avg_logprob": -0.1372853212578352, "compression_ratio": 1.5025125628140703, "no_speech_prob": 4.860398803430144e-06}, {"id": 48, "seek": 19784, "start": 213.2, "end": 215.16, "text": " So it's called the train phase API.", "tokens": [407, 309, 311, 1219, 264, 3847, 5574, 9362, 13], "temperature": 0.0, "avg_logprob": -0.1372853212578352, "compression_ratio": 1.5025125628140703, "no_speech_prob": 4.860398803430144e-06}, {"id": 49, "seek": 19784, "start": 215.16, "end": 221.88, "text": " And the easiest way to show it is to show an example of what it does, which is here.", "tokens": [400, 264, 12889, 636, 281, 855, 309, 307, 281, 855, 364, 1365, 295, 437, 309, 775, 11, 597, 307, 510, 13], "temperature": 0.0, "avg_logprob": -0.1372853212578352, "compression_ratio": 1.5025125628140703, "no_speech_prob": 4.860398803430144e-06}, {"id": 50, "seek": 22188, "start": 221.88, "end": 228.56, "text": " Here is an iteration against a learning rate chart, as you're familiar with seeing.", "tokens": [1692, 307, 364, 24784, 1970, 257, 2539, 3314, 6927, 11, 382, 291, 434, 4963, 365, 2577, 13], "temperature": 0.0, "avg_logprob": -0.13901917318279824, "compression_ratio": 1.7661691542288558, "no_speech_prob": 6.4389519138785545e-06}, {"id": 51, "seek": 22188, "start": 228.56, "end": 233.32, "text": " And this is one where we train for a while at a learning rate of.01, and then we train", "tokens": [400, 341, 307, 472, 689, 321, 3847, 337, 257, 1339, 412, 257, 2539, 3314, 295, 2411, 10607, 11, 293, 550, 321, 3847], "temperature": 0.0, "avg_logprob": -0.13901917318279824, "compression_ratio": 1.7661691542288558, "no_speech_prob": 6.4389519138785545e-06}, {"id": 52, "seek": 22188, "start": 233.32, "end": 238.28, "text": " for a while at a learning rate of.001.", "tokens": [337, 257, 1339, 412, 257, 2539, 3314, 295, 2411, 628, 16, 13], "temperature": 0.0, "avg_logprob": -0.13901917318279824, "compression_ratio": 1.7661691542288558, "no_speech_prob": 6.4389519138785545e-06}, {"id": 53, "seek": 22188, "start": 238.28, "end": 242.12, "text": " I actually wanted to create something very much like that learning rate chart because", "tokens": [286, 767, 1415, 281, 1884, 746, 588, 709, 411, 300, 2539, 3314, 6927, 570], "temperature": 0.0, "avg_logprob": -0.13901917318279824, "compression_ratio": 1.7661691542288558, "no_speech_prob": 6.4389519138785545e-06}, {"id": 54, "seek": 22188, "start": 242.12, "end": 247.04, "text": " most people that train ImageNet use this stepwise approach.", "tokens": [881, 561, 300, 3847, 29903, 31890, 764, 341, 1823, 3711, 3109, 13], "temperature": 0.0, "avg_logprob": -0.13901917318279824, "compression_ratio": 1.7661691542288558, "no_speech_prob": 6.4389519138785545e-06}, {"id": 55, "seek": 24704, "start": 247.04, "end": 253.0, "text": " And it's actually not something that's built into fast AI because it's not generally something", "tokens": [400, 309, 311, 767, 406, 746, 300, 311, 3094, 666, 2370, 7318, 570, 309, 311, 406, 5101, 746], "temperature": 0.0, "avg_logprob": -0.15460070248307853, "compression_ratio": 1.7470817120622568, "no_speech_prob": 2.7693872652889695e-06}, {"id": 56, "seek": 24704, "start": 253.0, "end": 254.0, "text": " we recommend.", "tokens": [321, 2748, 13], "temperature": 0.0, "avg_logprob": -0.15460070248307853, "compression_ratio": 1.7470817120622568, "no_speech_prob": 2.7693872652889695e-06}, {"id": 57, "seek": 24704, "start": 254.0, "end": 258.4, "text": " But in order to replicate existing papers, I wanted to do it the same way.", "tokens": [583, 294, 1668, 281, 25356, 6741, 10577, 11, 286, 1415, 281, 360, 309, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.15460070248307853, "compression_ratio": 1.7470817120622568, "no_speech_prob": 2.7693872652889695e-06}, {"id": 58, "seek": 24704, "start": 258.4, "end": 263.03999999999996, "text": " And so rather than writing a number of fit fit fit calls with different learning rates,", "tokens": [400, 370, 2831, 813, 3579, 257, 1230, 295, 3318, 3318, 3318, 5498, 365, 819, 2539, 6846, 11], "temperature": 0.0, "avg_logprob": -0.15460070248307853, "compression_ratio": 1.7470817120622568, "no_speech_prob": 2.7693872652889695e-06}, {"id": 59, "seek": 24704, "start": 263.03999999999996, "end": 268.14, "text": " it would be nice to be able to basically say train for n epochs at this learning rate and", "tokens": [309, 576, 312, 1481, 281, 312, 1075, 281, 1936, 584, 3847, 337, 297, 30992, 28346, 412, 341, 2539, 3314, 293], "temperature": 0.0, "avg_logprob": -0.15460070248307853, "compression_ratio": 1.7470817120622568, "no_speech_prob": 2.7693872652889695e-06}, {"id": 60, "seek": 24704, "start": 268.14, "end": 270.7, "text": " then m epochs at that learning rate.", "tokens": [550, 275, 30992, 28346, 412, 300, 2539, 3314, 13], "temperature": 0.0, "avg_logprob": -0.15460070248307853, "compression_ratio": 1.7470817120622568, "no_speech_prob": 2.7693872652889695e-06}, {"id": 61, "seek": 24704, "start": 270.7, "end": 272.44, "text": " And so here's how you do that.", "tokens": [400, 370, 510, 311, 577, 291, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.15460070248307853, "compression_ratio": 1.7470817120622568, "no_speech_prob": 2.7693872652889695e-06}, {"id": 62, "seek": 24704, "start": 272.44, "end": 273.68, "text": " You can say phases.", "tokens": [509, 393, 584, 18764, 13], "temperature": 0.0, "avg_logprob": -0.15460070248307853, "compression_ratio": 1.7470817120622568, "no_speech_prob": 2.7693872652889695e-06}, {"id": 63, "seek": 27368, "start": 273.68, "end": 279.88, "text": " So a phase is a period of training with particular optimizer parameters.", "tokens": [407, 257, 5574, 307, 257, 2896, 295, 3097, 365, 1729, 5028, 6545, 9834, 13], "temperature": 0.0, "avg_logprob": -0.1291991580616344, "compression_ratio": 1.7766990291262137, "no_speech_prob": 1.5779565956108854e-06}, {"id": 64, "seek": 27368, "start": 279.88, "end": 282.24, "text": " And it consists of a number of training phase objects.", "tokens": [400, 309, 14689, 295, 257, 1230, 295, 3097, 5574, 6565, 13], "temperature": 0.0, "avg_logprob": -0.1291991580616344, "compression_ratio": 1.7766990291262137, "no_speech_prob": 1.5779565956108854e-06}, {"id": 65, "seek": 27368, "start": 282.24, "end": 289.24, "text": " And a training phase object says how many epochs to train for, what optimization function", "tokens": [400, 257, 3097, 5574, 2657, 1619, 577, 867, 30992, 28346, 281, 3847, 337, 11, 437, 19618, 2445], "temperature": 0.0, "avg_logprob": -0.1291991580616344, "compression_ratio": 1.7766990291262137, "no_speech_prob": 1.5779565956108854e-06}, {"id": 66, "seek": 27368, "start": 289.24, "end": 294.12, "text": " to use, and what learning rate, amongst other things that we'll see.", "tokens": [281, 764, 11, 293, 437, 2539, 3314, 11, 12918, 661, 721, 300, 321, 603, 536, 13], "temperature": 0.0, "avg_logprob": -0.1291991580616344, "compression_ratio": 1.7766990291262137, "no_speech_prob": 1.5779565956108854e-06}, {"id": 67, "seek": 27368, "start": 294.12, "end": 300.24, "text": " And so here you'll see the two training phases that you just saw on that graph.", "tokens": [400, 370, 510, 291, 603, 536, 264, 732, 3097, 18764, 300, 291, 445, 1866, 322, 300, 4295, 13], "temperature": 0.0, "avg_logprob": -0.1291991580616344, "compression_ratio": 1.7766990291262137, "no_speech_prob": 1.5779565956108854e-06}, {"id": 68, "seek": 30024, "start": 300.24, "end": 308.6, "text": " So now rather than calling learn.fit, you say learn.fit with an optimizer scheduler with", "tokens": [407, 586, 2831, 813, 5141, 1466, 13, 6845, 11, 291, 584, 1466, 13, 6845, 365, 364, 5028, 6545, 12000, 260, 365], "temperature": 0.0, "avg_logprob": -0.1583086402670851, "compression_ratio": 1.6581196581196582, "no_speech_prob": 1.9637966488517122e-06}, {"id": 69, "seek": 30024, "start": 308.6, "end": 312.52, "text": " these phases.", "tokens": [613, 18764, 13], "temperature": 0.0, "avg_logprob": -0.1583086402670851, "compression_ratio": 1.6581196581196582, "no_speech_prob": 1.9637966488517122e-06}, {"id": 70, "seek": 30024, "start": 312.52, "end": 317.0, "text": " And then from there, most of the things you pass in can just get sent across to the fit", "tokens": [400, 550, 490, 456, 11, 881, 295, 264, 721, 291, 1320, 294, 393, 445, 483, 2279, 2108, 281, 264, 3318], "temperature": 0.0, "avg_logprob": -0.1583086402670851, "compression_ratio": 1.6581196581196582, "no_speech_prob": 1.9637966488517122e-06}, {"id": 71, "seek": 30024, "start": 317.0, "end": 318.24, "text": " function as per usual.", "tokens": [2445, 382, 680, 7713, 13], "temperature": 0.0, "avg_logprob": -0.1583086402670851, "compression_ratio": 1.6581196581196582, "no_speech_prob": 1.9637966488517122e-06}, {"id": 72, "seek": 30024, "start": 318.24, "end": 322.56, "text": " So most of the usual parameters will work fine.", "tokens": [407, 881, 295, 264, 7713, 9834, 486, 589, 2489, 13], "temperature": 0.0, "avg_logprob": -0.1583086402670851, "compression_ratio": 1.6581196581196582, "no_speech_prob": 1.9637966488517122e-06}, {"id": 73, "seek": 30024, "start": 322.56, "end": 327.32, "text": " But in this case, generally speaking, actually, we can just use these training phases and", "tokens": [583, 294, 341, 1389, 11, 5101, 4124, 11, 767, 11, 321, 393, 445, 764, 613, 3097, 18764, 293], "temperature": 0.0, "avg_logprob": -0.1583086402670851, "compression_ratio": 1.6581196581196582, "no_speech_prob": 1.9637966488517122e-06}, {"id": 74, "seek": 30024, "start": 327.32, "end": 329.6, "text": " you'll see it fits in the usual way.", "tokens": [291, 603, 536, 309, 9001, 294, 264, 7713, 636, 13], "temperature": 0.0, "avg_logprob": -0.1583086402670851, "compression_ratio": 1.6581196581196582, "no_speech_prob": 1.9637966488517122e-06}, {"id": 75, "seek": 32960, "start": 329.6, "end": 333.56, "text": " And then when you say plot LR, there it is.", "tokens": [400, 550, 562, 291, 584, 7542, 441, 49, 11, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.10861852712798536, "compression_ratio": 1.888412017167382, "no_speech_prob": 7.453755870301393e-07}, {"id": 76, "seek": 32960, "start": 333.56, "end": 338.24, "text": " And not only does it plot the learning rate, it also plots momentum.", "tokens": [400, 406, 787, 775, 309, 7542, 264, 2539, 3314, 11, 309, 611, 28609, 11244, 13], "temperature": 0.0, "avg_logprob": -0.10861852712798536, "compression_ratio": 1.888412017167382, "no_speech_prob": 7.453755870301393e-07}, {"id": 77, "seek": 32960, "start": 338.24, "end": 342.92, "text": " And for each phase, it tells you what optimizer it used.", "tokens": [400, 337, 1184, 5574, 11, 309, 5112, 291, 437, 5028, 6545, 309, 1143, 13], "temperature": 0.0, "avg_logprob": -0.10861852712798536, "compression_ratio": 1.888412017167382, "no_speech_prob": 7.453755870301393e-07}, {"id": 78, "seek": 32960, "start": 342.92, "end": 349.04, "text": " You can turn off the printing of the optimizers, you can turn off the printing of momentums,", "tokens": [509, 393, 1261, 766, 264, 14699, 295, 264, 5028, 22525, 11, 291, 393, 1261, 766, 264, 14699, 295, 1623, 8099, 11], "temperature": 0.0, "avg_logprob": -0.10861852712798536, "compression_ratio": 1.888412017167382, "no_speech_prob": 7.453755870301393e-07}, {"id": 79, "seek": 32960, "start": 349.04, "end": 354.88, "text": " and you can do other little things like a training phase could have an LR decay parameter.", "tokens": [293, 291, 393, 360, 661, 707, 721, 411, 257, 3097, 5574, 727, 362, 364, 441, 49, 21039, 13075, 13], "temperature": 0.0, "avg_logprob": -0.10861852712798536, "compression_ratio": 1.888412017167382, "no_speech_prob": 7.453755870301393e-07}, {"id": 80, "seek": 32960, "start": 354.88, "end": 359.32000000000005, "text": " So here's a fixed learning rate and then a linear decay learning rate and then a fixed", "tokens": [407, 510, 311, 257, 6806, 2539, 3314, 293, 550, 257, 8213, 21039, 2539, 3314, 293, 550, 257, 6806], "temperature": 0.0, "avg_logprob": -0.10861852712798536, "compression_ratio": 1.888412017167382, "no_speech_prob": 7.453755870301393e-07}, {"id": 81, "seek": 35932, "start": 359.32, "end": 364.04, "text": " learning rate, which gives us that picture.", "tokens": [2539, 3314, 11, 597, 2709, 505, 300, 3036, 13], "temperature": 0.0, "avg_logprob": -0.15807955605643137, "compression_ratio": 1.6584158415841583, "no_speech_prob": 6.5404065026086755e-06}, {"id": 82, "seek": 35932, "start": 364.04, "end": 369.68, "text": " And this might be quite a good way to train actually, because we know at high learning", "tokens": [400, 341, 1062, 312, 1596, 257, 665, 636, 281, 3847, 767, 11, 570, 321, 458, 412, 1090, 2539], "temperature": 0.0, "avg_logprob": -0.15807955605643137, "compression_ratio": 1.6584158415841583, "no_speech_prob": 6.5404065026086755e-06}, {"id": 83, "seek": 35932, "start": 369.68, "end": 375.6, "text": " rates you get to kind of explore better and at low learning rates you get to fine-tune", "tokens": [6846, 291, 483, 281, 733, 295, 6839, 1101, 293, 412, 2295, 2539, 6846, 291, 483, 281, 2489, 12, 83, 2613], "temperature": 0.0, "avg_logprob": -0.15807955605643137, "compression_ratio": 1.6584158415841583, "no_speech_prob": 6.5404065026086755e-06}, {"id": 84, "seek": 35932, "start": 375.6, "end": 380.08, "text": " better and it's probably better to gradually slide between the two.", "tokens": [1101, 293, 309, 311, 1391, 1101, 281, 13145, 4137, 1296, 264, 732, 13], "temperature": 0.0, "avg_logprob": -0.15807955605643137, "compression_ratio": 1.6584158415841583, "no_speech_prob": 6.5404065026086755e-06}, {"id": 85, "seek": 35932, "start": 380.08, "end": 386.3, "text": " So this actually isn't a bad approach, I suspect.", "tokens": [407, 341, 767, 1943, 380, 257, 1578, 3109, 11, 286, 9091, 13], "temperature": 0.0, "avg_logprob": -0.15807955605643137, "compression_ratio": 1.6584158415841583, "no_speech_prob": 6.5404065026086755e-06}, {"id": 86, "seek": 38630, "start": 386.3, "end": 390.12, "text": " You can use other decay types, not just linear, so cosine.", "tokens": [509, 393, 764, 661, 21039, 3467, 11, 406, 445, 8213, 11, 370, 23565, 13], "temperature": 0.0, "avg_logprob": -0.18322650422441197, "compression_ratio": 1.5793650793650793, "no_speech_prob": 1.0451397429278586e-05}, {"id": 87, "seek": 38630, "start": 390.12, "end": 396.24, "text": " This probably makes even more sense as a genuinely potentially useful learning rate annealing", "tokens": [639, 1391, 1669, 754, 544, 2020, 382, 257, 17839, 7263, 4420, 2539, 3314, 22256, 4270], "temperature": 0.0, "avg_logprob": -0.18322650422441197, "compression_ratio": 1.5793650793650793, "no_speech_prob": 1.0451397429278586e-05}, {"id": 88, "seek": 38630, "start": 396.24, "end": 398.44, "text": " shape.", "tokens": [3909, 13], "temperature": 0.0, "avg_logprob": -0.18322650422441197, "compression_ratio": 1.5793650793650793, "no_speech_prob": 1.0451397429278586e-05}, {"id": 89, "seek": 38630, "start": 398.44, "end": 403.24, "text": " Exponential which is a super popular approach.", "tokens": [21391, 266, 2549, 597, 307, 257, 1687, 3743, 3109, 13], "temperature": 0.0, "avg_logprob": -0.18322650422441197, "compression_ratio": 1.5793650793650793, "no_speech_prob": 1.0451397429278586e-05}, {"id": 90, "seek": 38630, "start": 403.24, "end": 408.6, "text": " Polynomial which isn't terribly popular but actually in the literature works better than", "tokens": [6165, 9896, 47429, 597, 1943, 380, 22903, 3743, 457, 767, 294, 264, 10394, 1985, 1101, 813], "temperature": 0.0, "avg_logprob": -0.18322650422441197, "compression_ratio": 1.5793650793650793, "no_speech_prob": 1.0451397429278586e-05}, {"id": 91, "seek": 38630, "start": 408.6, "end": 412.32, "text": " just about anything else but seems to have been largely ignored.", "tokens": [445, 466, 1340, 1646, 457, 2544, 281, 362, 668, 11611, 19735, 13], "temperature": 0.0, "avg_logprob": -0.18322650422441197, "compression_ratio": 1.5793650793650793, "no_speech_prob": 1.0451397429278586e-05}, {"id": 92, "seek": 38630, "start": 412.32, "end": 414.28000000000003, "text": " So polynomial is good to be aware of.", "tokens": [407, 26110, 307, 665, 281, 312, 3650, 295, 13], "temperature": 0.0, "avg_logprob": -0.18322650422441197, "compression_ratio": 1.5793650793650793, "no_speech_prob": 1.0451397429278586e-05}, {"id": 93, "seek": 41428, "start": 414.28, "end": 419.55999999999995, "text": " And what Sylvain has done is he's given us the formula for each of these curves.", "tokens": [400, 437, 3902, 14574, 491, 575, 1096, 307, 415, 311, 2212, 505, 264, 8513, 337, 1184, 295, 613, 19490, 13], "temperature": 0.0, "avg_logprob": -0.13401221294029086, "compression_ratio": 1.368421052631579, "no_speech_prob": 4.565946255752351e-06}, {"id": 94, "seek": 41428, "start": 419.55999999999995, "end": 430.71999999999997, "text": " And so with a polynomial you get to pick what polynomial to use.", "tokens": [400, 370, 365, 257, 26110, 291, 483, 281, 1888, 437, 26110, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.13401221294029086, "compression_ratio": 1.368421052631579, "no_speech_prob": 4.565946255752351e-06}, {"id": 95, "seek": 41428, "start": 430.71999999999997, "end": 435.67999999999995, "text": " So here it is with a different size.", "tokens": [407, 510, 309, 307, 365, 257, 819, 2744, 13], "temperature": 0.0, "avg_logprob": -0.13401221294029086, "compression_ratio": 1.368421052631579, "no_speech_prob": 4.565946255752351e-06}, {"id": 96, "seek": 43568, "start": 435.68, "end": 447.16, "text": " And I believe a p of.9 is the one that I've seen really good results for, FYI.", "tokens": [400, 286, 1697, 257, 280, 295, 2411, 24, 307, 264, 472, 300, 286, 600, 1612, 534, 665, 3542, 337, 11, 42730, 40, 13], "temperature": 0.0, "avg_logprob": -0.10390211034704137, "compression_ratio": 1.4157894736842105, "no_speech_prob": 1.5534930071225972e-06}, {"id": 97, "seek": 43568, "start": 447.16, "end": 451.92, "text": " If you don't give a tuple of learning rates when there's an LR decay, then it will decay", "tokens": [759, 291, 500, 380, 976, 257, 2604, 781, 295, 2539, 6846, 562, 456, 311, 364, 441, 49, 21039, 11, 550, 309, 486, 21039], "temperature": 0.0, "avg_logprob": -0.10390211034704137, "compression_ratio": 1.4157894736842105, "no_speech_prob": 1.5534930071225972e-06}, {"id": 98, "seek": 43568, "start": 451.92, "end": 454.36, "text": " all the way down to 0.", "tokens": [439, 264, 636, 760, 281, 1958, 13], "temperature": 0.0, "avg_logprob": -0.10390211034704137, "compression_ratio": 1.4157894736842105, "no_speech_prob": 1.5534930071225972e-06}, {"id": 99, "seek": 43568, "start": 454.36, "end": 464.28000000000003, "text": " And as you can see, you can happily start the next cycle at a different point.", "tokens": [400, 382, 291, 393, 536, 11, 291, 393, 19909, 722, 264, 958, 6586, 412, 257, 819, 935, 13], "temperature": 0.0, "avg_logprob": -0.10390211034704137, "compression_ratio": 1.4157894736842105, "no_speech_prob": 1.5534930071225972e-06}, {"id": 100, "seek": 46428, "start": 464.28, "end": 469.94, "text": " So the cool thing is now we can replicate all of our existing schedules using nothing", "tokens": [407, 264, 1627, 551, 307, 586, 321, 393, 25356, 439, 295, 527, 6741, 28078, 1228, 1825], "temperature": 0.0, "avg_logprob": -0.14867013242064403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 4.710864686785499e-06}, {"id": 101, "seek": 46428, "start": 469.94, "end": 472.15999999999997, "text": " but these training phases.", "tokens": [457, 613, 3097, 18764, 13], "temperature": 0.0, "avg_logprob": -0.14867013242064403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 4.710864686785499e-06}, {"id": 102, "seek": 46428, "start": 472.15999999999997, "end": 480.11999999999995, "text": " So here's a function called phases.sgdr which does sgdr using the new training phase API.", "tokens": [407, 510, 311, 257, 2445, 1219, 18764, 13, 82, 70, 16753, 597, 775, 262, 70, 16753, 1228, 264, 777, 3097, 5574, 9362, 13], "temperature": 0.0, "avg_logprob": -0.14867013242064403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 4.710864686785499e-06}, {"id": 103, "seek": 46428, "start": 480.11999999999995, "end": 485.59999999999997, "text": " And so you can see if he runs this schedule, then here's what it looks like.", "tokens": [400, 370, 291, 393, 536, 498, 415, 6676, 341, 7567, 11, 550, 510, 311, 437, 309, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.14867013242064403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 4.710864686785499e-06}, {"id": 104, "seek": 46428, "start": 485.59999999999997, "end": 488.91999999999996, "text": " That is even done the little trick I have where you train at a really low learning rate", "tokens": [663, 307, 754, 1096, 264, 707, 4282, 286, 362, 689, 291, 3847, 412, 257, 534, 2295, 2539, 3314], "temperature": 0.0, "avg_logprob": -0.14867013242064403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 4.710864686785499e-06}, {"id": 105, "seek": 46428, "start": 488.91999999999996, "end": 492.44, "text": " just for a little bit and then pop up and do a few cycles and the cycles are increasing", "tokens": [445, 337, 257, 707, 857, 293, 550, 1665, 493, 293, 360, 257, 1326, 17796, 293, 264, 17796, 366, 5662], "temperature": 0.0, "avg_logprob": -0.14867013242064403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 4.710864686785499e-06}, {"id": 106, "seek": 46428, "start": 492.44, "end": 493.44, "text": " in length.", "tokens": [294, 4641, 13], "temperature": 0.0, "avg_logprob": -0.14867013242064403, "compression_ratio": 1.7388059701492538, "no_speech_prob": 4.710864686785499e-06}, {"id": 107, "seek": 49344, "start": 493.44, "end": 500.71999999999997, "text": " And that's all done in a single function.", "tokens": [400, 300, 311, 439, 1096, 294, 257, 2167, 2445, 13], "temperature": 0.0, "avg_logprob": -0.15235654931319387, "compression_ratio": 1.5136986301369864, "no_speech_prob": 2.6425750547787175e-06}, {"id": 108, "seek": 49344, "start": 500.71999999999997, "end": 508.92, "text": " So the new one cycle we can now implement with, again, a single little function.", "tokens": [407, 264, 777, 472, 6586, 321, 393, 586, 4445, 365, 11, 797, 11, 257, 2167, 707, 2445, 13], "temperature": 0.0, "avg_logprob": -0.15235654931319387, "compression_ratio": 1.5136986301369864, "no_speech_prob": 2.6425750547787175e-06}, {"id": 109, "seek": 49344, "start": 508.92, "end": 516.72, "text": " And so if we fit with that, we get this triangle followed by a little flatter bit and the momentum", "tokens": [400, 370, 498, 321, 3318, 365, 300, 11, 321, 483, 341, 13369, 6263, 538, 257, 707, 41247, 857, 293, 264, 11244], "temperature": 0.0, "avg_logprob": -0.15235654931319387, "compression_ratio": 1.5136986301369864, "no_speech_prob": 2.6425750547787175e-06}, {"id": 110, "seek": 51672, "start": 516.72, "end": 525.4, "text": " is a cool thing, the momentum has a momentum decay.", "tokens": [307, 257, 1627, 551, 11, 264, 11244, 575, 257, 11244, 21039, 13], "temperature": 0.0, "avg_logprob": -0.13915289532054553, "compression_ratio": 1.7205882352941178, "no_speech_prob": 5.1738902584475e-06}, {"id": 111, "seek": 51672, "start": 525.4, "end": 528.84, "text": " And then here we've got a fixed momentum at the end.", "tokens": [400, 550, 510, 321, 600, 658, 257, 6806, 11244, 412, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.13915289532054553, "compression_ratio": 1.7205882352941178, "no_speech_prob": 5.1738902584475e-06}, {"id": 112, "seek": 51672, "start": 528.84, "end": 534.38, "text": " So it's doing the momentum and the learning rate at the same time.", "tokens": [407, 309, 311, 884, 264, 11244, 293, 264, 2539, 3314, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.13915289532054553, "compression_ratio": 1.7205882352941178, "no_speech_prob": 5.1738902584475e-06}, {"id": 113, "seek": 51672, "start": 534.38, "end": 538.74, "text": " So something that I haven't tried yet that I think would be really interesting is to", "tokens": [407, 746, 300, 286, 2378, 380, 3031, 1939, 300, 286, 519, 576, 312, 534, 1880, 307, 281], "temperature": 0.0, "avg_logprob": -0.13915289532054553, "compression_ratio": 1.7205882352941178, "no_speech_prob": 5.1738902584475e-06}, {"id": 114, "seek": 51672, "start": 538.74, "end": 544.5600000000001, "text": " use, he's calling it differential learning rates, we've changed the name now to discriminative", "tokens": [764, 11, 415, 311, 5141, 309, 15756, 2539, 6846, 11, 321, 600, 3105, 264, 1315, 586, 281, 20828, 1166], "temperature": 0.0, "avg_logprob": -0.13915289532054553, "compression_ratio": 1.7205882352941178, "no_speech_prob": 5.1738902584475e-06}, {"id": 115, "seek": 54456, "start": 544.56, "end": 555.7199999999999, "text": " learning rates.", "tokens": [2539, 6846, 13], "temperature": 0.0, "avg_logprob": -0.19166454247065953, "compression_ratio": 1.5793103448275863, "no_speech_prob": 6.854229923192179e-06}, {"id": 116, "seek": 54456, "start": 555.7199999999999, "end": 561.0, "text": " So a combination of discriminative learning rates and one cycle, no one's tried yet.", "tokens": [407, 257, 6562, 295, 20828, 1166, 2539, 6846, 293, 472, 6586, 11, 572, 472, 311, 3031, 1939, 13], "temperature": 0.0, "avg_logprob": -0.19166454247065953, "compression_ratio": 1.5793103448275863, "no_speech_prob": 6.854229923192179e-06}, {"id": 117, "seek": 54456, "start": 561.0, "end": 563.4799999999999, "text": " So that would be really interesting.", "tokens": [407, 300, 576, 312, 534, 1880, 13], "temperature": 0.0, "avg_logprob": -0.19166454247065953, "compression_ratio": 1.5793103448275863, "no_speech_prob": 6.854229923192179e-06}, {"id": 118, "seek": 54456, "start": 563.4799999999999, "end": 568.3599999999999, "text": " There's actually a, the only paper I've come across which has discriminative learning rates", "tokens": [821, 311, 767, 257, 11, 264, 787, 3035, 286, 600, 808, 2108, 597, 575, 20828, 1166, 2539, 6846], "temperature": 0.0, "avg_logprob": -0.19166454247065953, "compression_ratio": 1.5793103448275863, "no_speech_prob": 6.854229923192179e-06}, {"id": 119, "seek": 56836, "start": 568.36, "end": 576.52, "text": " is called, uses something called LARS, L-A-R-S, and it was used to train ImageNet with very", "tokens": [307, 1219, 11, 4960, 746, 1219, 441, 31343, 11, 441, 12, 32, 12, 49, 12, 50, 11, 293, 309, 390, 1143, 281, 3847, 29903, 31890, 365, 588], "temperature": 0.0, "avg_logprob": -0.10799911022186279, "compression_ratio": 1.618811881188119, "no_speech_prob": 6.85422037349781e-06}, {"id": 120, "seek": 56836, "start": 576.52, "end": 582.44, "text": " very large batch sizes by basically looking at the ratio between the gradient and the", "tokens": [588, 2416, 15245, 11602, 538, 1936, 1237, 412, 264, 8509, 1296, 264, 16235, 293, 264], "temperature": 0.0, "avg_logprob": -0.10799911022186279, "compression_ratio": 1.618811881188119, "no_speech_prob": 6.85422037349781e-06}, {"id": 121, "seek": 56836, "start": 582.44, "end": 591.96, "text": " mean at each layer and using that to change the learning rate of each layer automatically", "tokens": [914, 412, 1184, 4583, 293, 1228, 300, 281, 1319, 264, 2539, 3314, 295, 1184, 4583, 6772], "temperature": 0.0, "avg_logprob": -0.10799911022186279, "compression_ratio": 1.618811881188119, "no_speech_prob": 6.85422037349781e-06}, {"id": 122, "seek": 56836, "start": 591.96, "end": 595.9200000000001, "text": " and they found that they could use much larger batch sizes.", "tokens": [293, 436, 1352, 300, 436, 727, 764, 709, 4833, 15245, 11602, 13], "temperature": 0.0, "avg_logprob": -0.10799911022186279, "compression_ratio": 1.618811881188119, "no_speech_prob": 6.85422037349781e-06}, {"id": 123, "seek": 59592, "start": 595.92, "end": 599.3199999999999, "text": " That's the only other place I've seen this kind of approach used, but there's lots of", "tokens": [663, 311, 264, 787, 661, 1081, 286, 600, 1612, 341, 733, 295, 3109, 1143, 11, 457, 456, 311, 3195, 295], "temperature": 0.0, "avg_logprob": -0.12679574096087112, "compression_ratio": 1.6356877323420074, "no_speech_prob": 1.184289521916071e-05}, {"id": 124, "seek": 59592, "start": 599.3199999999999, "end": 604.12, "text": " interesting things you could try with combining discriminative learning rates and different", "tokens": [1880, 721, 291, 727, 853, 365, 21928, 20828, 1166, 2539, 6846, 293, 819], "temperature": 0.0, "avg_logprob": -0.12679574096087112, "compression_ratio": 1.6356877323420074, "no_speech_prob": 1.184289521916071e-05}, {"id": 125, "seek": 59592, "start": 604.12, "end": 606.7199999999999, "text": " interesting schedules.", "tokens": [1880, 28078, 13], "temperature": 0.0, "avg_logprob": -0.12679574096087112, "compression_ratio": 1.6356877323420074, "no_speech_prob": 1.184289521916071e-05}, {"id": 126, "seek": 59592, "start": 606.7199999999999, "end": 611.4799999999999, "text": " So you can now write your own LRFinder of different types, specifically because there's", "tokens": [407, 291, 393, 586, 2464, 428, 1065, 441, 49, 37, 5669, 295, 819, 3467, 11, 4682, 570, 456, 311], "temperature": 0.0, "avg_logprob": -0.12679574096087112, "compression_ratio": 1.6356877323420074, "no_speech_prob": 1.184289521916071e-05}, {"id": 127, "seek": 59592, "start": 611.4799999999999, "end": 617.5999999999999, "text": " now this stop-div parameter, which basically means that it'll use whatever schedule you", "tokens": [586, 341, 1590, 12, 67, 592, 13075, 11, 597, 1936, 1355, 300, 309, 603, 764, 2035, 7567, 291], "temperature": 0.0, "avg_logprob": -0.12679574096087112, "compression_ratio": 1.6356877323420074, "no_speech_prob": 1.184289521916071e-05}, {"id": 128, "seek": 59592, "start": 617.5999999999999, "end": 622.7199999999999, "text": " asked for, but when the loss gets too bad, it'll stop training.", "tokens": [2351, 337, 11, 457, 562, 264, 4470, 2170, 886, 1578, 11, 309, 603, 1590, 3097, 13], "temperature": 0.0, "avg_logprob": -0.12679574096087112, "compression_ratio": 1.6356877323420074, "no_speech_prob": 1.184289521916071e-05}, {"id": 129, "seek": 62272, "start": 622.72, "end": 637.74, "text": " So here's one with learning rate versus loss, and you can see it stops itself automatically.", "tokens": [407, 510, 311, 472, 365, 2539, 3314, 5717, 4470, 11, 293, 291, 393, 536, 309, 10094, 2564, 6772, 13], "temperature": 0.0, "avg_logprob": -0.13601710503561454, "compression_ratio": 1.5176470588235293, "no_speech_prob": 2.482471700204769e-06}, {"id": 130, "seek": 62272, "start": 637.74, "end": 644.52, "text": " One useful thing that's been added is the linear parameter to the plot function.", "tokens": [1485, 4420, 551, 300, 311, 668, 3869, 307, 264, 8213, 13075, 281, 264, 7542, 2445, 13], "temperature": 0.0, "avg_logprob": -0.13601710503561454, "compression_ratio": 1.5176470588235293, "no_speech_prob": 2.482471700204769e-06}, {"id": 131, "seek": 62272, "start": 644.52, "end": 650.32, "text": " If you use linear schedule rather than an exponential schedule in your learning rate", "tokens": [759, 291, 764, 8213, 7567, 2831, 813, 364, 21510, 7567, 294, 428, 2539, 3314], "temperature": 0.0, "avg_logprob": -0.13601710503561454, "compression_ratio": 1.5176470588235293, "no_speech_prob": 2.482471700204769e-06}, {"id": 132, "seek": 65032, "start": 650.32, "end": 656.32, "text": " finder, which is a good idea if you've kind of fine-tuned in to roughly the right area,", "tokens": [915, 260, 11, 597, 307, 257, 665, 1558, 498, 291, 600, 733, 295, 2489, 12, 83, 43703, 294, 281, 9810, 264, 558, 1859, 11], "temperature": 0.0, "avg_logprob": -0.16032846195181621, "compression_ratio": 1.640552995391705, "no_speech_prob": 3.6119631658948492e-06}, {"id": 133, "seek": 65032, "start": 656.32, "end": 659.9200000000001, "text": " then you can use linear to find exactly the right area, and then you probably want to", "tokens": [550, 291, 393, 764, 8213, 281, 915, 2293, 264, 558, 1859, 11, 293, 550, 291, 1391, 528, 281], "temperature": 0.0, "avg_logprob": -0.16032846195181621, "compression_ratio": 1.640552995391705, "no_speech_prob": 3.6119631658948492e-06}, {"id": 134, "seek": 65032, "start": 659.9200000000001, "end": 661.9200000000001, "text": " plot it with a linear scale.", "tokens": [7542, 309, 365, 257, 8213, 4373, 13], "temperature": 0.0, "avg_logprob": -0.16032846195181621, "compression_ratio": 1.640552995391705, "no_speech_prob": 3.6119631658948492e-06}, {"id": 135, "seek": 65032, "start": 661.9200000000001, "end": 667.48, "text": " So that's why you can also pass linear to plot now as well.", "tokens": [407, 300, 311, 983, 291, 393, 611, 1320, 8213, 281, 7542, 586, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16032846195181621, "compression_ratio": 1.640552995391705, "no_speech_prob": 3.6119631658948492e-06}, {"id": 136, "seek": 65032, "start": 667.48, "end": 675.58, "text": " You can change the optimizer HVACES, and that's more important than you might imagine because", "tokens": [509, 393, 1319, 264, 5028, 6545, 389, 53, 4378, 2358, 11, 293, 300, 311, 544, 1021, 813, 291, 1062, 3811, 570], "temperature": 0.0, "avg_logprob": -0.16032846195181621, "compression_ratio": 1.640552995391705, "no_speech_prob": 3.6119631658948492e-06}, {"id": 137, "seek": 67558, "start": 675.58, "end": 682.24, "text": " actually the current state of the art for training on really large batch sizes really", "tokens": [767, 264, 2190, 1785, 295, 264, 1523, 337, 3097, 322, 534, 2416, 15245, 11602, 534], "temperature": 0.0, "avg_logprob": -0.11524576022301192, "compression_ratio": 1.5483870967741935, "no_speech_prob": 1.1300724509055726e-05}, {"id": 138, "seek": 67558, "start": 682.24, "end": 687.4000000000001, "text": " quickly for ImageNet actually starts with RMSProp for the first bit, and then they switch", "tokens": [2661, 337, 29903, 31890, 767, 3719, 365, 497, 10288, 47, 1513, 337, 264, 700, 857, 11, 293, 550, 436, 3679], "temperature": 0.0, "avg_logprob": -0.11524576022301192, "compression_ratio": 1.5483870967741935, "no_speech_prob": 1.1300724509055726e-05}, {"id": 139, "seek": 67558, "start": 687.4000000000001, "end": 691.74, "text": " to SGD for the second bit.", "tokens": [281, 34520, 35, 337, 264, 1150, 857, 13], "temperature": 0.0, "avg_logprob": -0.11524576022301192, "compression_ratio": 1.5483870967741935, "no_speech_prob": 1.1300724509055726e-05}, {"id": 140, "seek": 67558, "start": 691.74, "end": 697.6600000000001, "text": " And so that could be something interesting to experiment more with, because at least", "tokens": [400, 370, 300, 727, 312, 746, 1880, 281, 5120, 544, 365, 11, 570, 412, 1935], "temperature": 0.0, "avg_logprob": -0.11524576022301192, "compression_ratio": 1.5483870967741935, "no_speech_prob": 1.1300724509055726e-05}, {"id": 141, "seek": 67558, "start": 697.6600000000001, "end": 701.76, "text": " one paper has now shown that that can work well.", "tokens": [472, 3035, 575, 586, 4898, 300, 300, 393, 589, 731, 13], "temperature": 0.0, "avg_logprob": -0.11524576022301192, "compression_ratio": 1.5483870967741935, "no_speech_prob": 1.1300724509055726e-05}, {"id": 142, "seek": 70176, "start": 701.76, "end": 710.12, "text": " And again, it's something that isn't well appreciated as yet.", "tokens": [400, 797, 11, 309, 311, 746, 300, 1943, 380, 731, 17169, 382, 1939, 13], "temperature": 0.0, "avg_logprob": -0.16475261097222987, "compression_ratio": 1.5135135135135136, "no_speech_prob": 3.2887317047425313e-06}, {"id": 143, "seek": 70176, "start": 710.12, "end": 714.16, "text": " And then the bit I find most interesting is you can change your data.", "tokens": [400, 550, 264, 857, 286, 915, 881, 1880, 307, 291, 393, 1319, 428, 1412, 13], "temperature": 0.0, "avg_logprob": -0.16475261097222987, "compression_ratio": 1.5135135135135136, "no_speech_prob": 3.2887317047425313e-06}, {"id": 144, "seek": 70176, "start": 714.16, "end": 716.12, "text": " Why would you want to change your data?", "tokens": [1545, 576, 291, 528, 281, 1319, 428, 1412, 30], "temperature": 0.0, "avg_logprob": -0.16475261097222987, "compression_ratio": 1.5135135135135136, "no_speech_prob": 3.2887317047425313e-06}, {"id": 145, "seek": 70176, "start": 716.12, "end": 720.0, "text": " Because you remember from lessons 1 and 2 you could use smaller images at the start", "tokens": [1436, 291, 1604, 490, 8820, 502, 293, 568, 291, 727, 764, 4356, 5267, 412, 264, 722], "temperature": 0.0, "avg_logprob": -0.16475261097222987, "compression_ratio": 1.5135135135135136, "no_speech_prob": 3.2887317047425313e-06}, {"id": 146, "seek": 70176, "start": 720.0, "end": 722.76, "text": " and bigger images later.", "tokens": [293, 3801, 5267, 1780, 13], "temperature": 0.0, "avg_logprob": -0.16475261097222987, "compression_ratio": 1.5135135135135136, "no_speech_prob": 3.2887317047425313e-06}, {"id": 147, "seek": 72276, "start": 722.76, "end": 734.3199999999999, "text": " And the theory is that you could use that to train the first bit more quickly with smaller", "tokens": [400, 264, 5261, 307, 300, 291, 727, 764, 300, 281, 3847, 264, 700, 857, 544, 2661, 365, 4356], "temperature": 0.0, "avg_logprob": -0.12172067320192015, "compression_ratio": 1.5526315789473684, "no_speech_prob": 8.990934361463587e-07}, {"id": 148, "seek": 72276, "start": 734.3199999999999, "end": 735.3199999999999, "text": " images.", "tokens": [5267, 13], "temperature": 0.0, "avg_logprob": -0.12172067320192015, "compression_ratio": 1.5526315789473684, "no_speech_prob": 8.990934361463587e-07}, {"id": 149, "seek": 72276, "start": 735.3199999999999, "end": 738.96, "text": " And remember, if you have half the height and half the width, then you've got a quarter", "tokens": [400, 1604, 11, 498, 291, 362, 1922, 264, 6681, 293, 1922, 264, 11402, 11, 550, 291, 600, 658, 257, 6555], "temperature": 0.0, "avg_logprob": -0.12172067320192015, "compression_ratio": 1.5526315789473684, "no_speech_prob": 8.990934361463587e-07}, {"id": 150, "seek": 72276, "start": 738.96, "end": 744.76, "text": " of the activations of basically every layer, so it can be a lot faster.", "tokens": [295, 264, 2430, 763, 295, 1936, 633, 4583, 11, 370, 309, 393, 312, 257, 688, 4663, 13], "temperature": 0.0, "avg_logprob": -0.12172067320192015, "compression_ratio": 1.5526315789473684, "no_speech_prob": 8.990934361463587e-07}, {"id": 151, "seek": 72276, "start": 744.76, "end": 748.4, "text": " And it might even generalize better.", "tokens": [400, 309, 1062, 754, 2674, 1125, 1101, 13], "temperature": 0.0, "avg_logprob": -0.12172067320192015, "compression_ratio": 1.5526315789473684, "no_speech_prob": 8.990934361463587e-07}, {"id": 152, "seek": 74840, "start": 748.4, "end": 753.16, "text": " So you can now create a couple of different, for example, this case has got 28 and then", "tokens": [407, 291, 393, 586, 1884, 257, 1916, 295, 819, 11, 337, 1365, 11, 341, 1389, 575, 658, 7562, 293, 550], "temperature": 0.0, "avg_logprob": -0.21323238100324357, "compression_ratio": 1.6219512195121952, "no_speech_prob": 2.813001401591464e-06}, {"id": 153, "seek": 74840, "start": 753.16, "end": 754.48, "text": " 32 sized images.", "tokens": [8858, 20004, 5267, 13], "temperature": 0.0, "avg_logprob": -0.21323238100324357, "compression_ratio": 1.6219512195121952, "no_speech_prob": 2.813001401591464e-06}, {"id": 154, "seek": 74840, "start": 754.48, "end": 757.48, "text": " This is just sci-fi 10, so there's only so much you can do.", "tokens": [639, 307, 445, 2180, 12, 13325, 1266, 11, 370, 456, 311, 787, 370, 709, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.21323238100324357, "compression_ratio": 1.6219512195121952, "no_speech_prob": 2.813001401591464e-06}, {"id": 155, "seek": 74840, "start": 757.48, "end": 762.6, "text": " And then if you pass in an array of data in this data list parameter, when you call fit", "tokens": [400, 550, 498, 291, 1320, 294, 364, 10225, 295, 1412, 294, 341, 1412, 1329, 13075, 11, 562, 291, 818, 3318], "temperature": 0.0, "avg_logprob": -0.21323238100324357, "compression_ratio": 1.6219512195121952, "no_speech_prob": 2.813001401591464e-06}, {"id": 156, "seek": 74840, "start": 762.6, "end": 769.04, "text": " opshed, it'll use a different data set for each phase.", "tokens": [999, 2716, 292, 11, 309, 603, 764, 257, 819, 1412, 992, 337, 1184, 5574, 13], "temperature": 0.0, "avg_logprob": -0.21323238100324357, "compression_ratio": 1.6219512195121952, "no_speech_prob": 2.813001401591464e-06}, {"id": 157, "seek": 74840, "start": 769.04, "end": 773.12, "text": " So that's really cool because we can use that now, like we could use that in our dorm bench", "tokens": [407, 300, 311, 534, 1627, 570, 321, 393, 764, 300, 586, 11, 411, 321, 727, 764, 300, 294, 527, 12521, 10638], "temperature": 0.0, "avg_logprob": -0.21323238100324357, "compression_ratio": 1.6219512195121952, "no_speech_prob": 2.813001401591464e-06}, {"id": 158, "seek": 77312, "start": 773.12, "end": 783.6, "text": " entries and see what happens when we actually increase the size with very little code.", "tokens": [23041, 293, 536, 437, 2314, 562, 321, 767, 3488, 264, 2744, 365, 588, 707, 3089, 13], "temperature": 0.0, "avg_logprob": -0.16457446416219076, "compression_ratio": 1.4489795918367347, "no_speech_prob": 3.138129386570654e-06}, {"id": 159, "seek": 77312, "start": 783.6, "end": 786.04, "text": " So what happens when we do that?", "tokens": [407, 437, 2314, 562, 321, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.16457446416219076, "compression_ratio": 1.4489795918367347, "no_speech_prob": 3.138129386570654e-06}, {"id": 160, "seek": 77312, "start": 786.04, "end": 795.92, "text": " Well, the answer is here in Dawnbench, training on ImageNet, and you can see here that Google", "tokens": [1042, 11, 264, 1867, 307, 510, 294, 26001, 47244, 11, 3097, 322, 29903, 31890, 11, 293, 291, 393, 536, 510, 300, 3329], "temperature": 0.0, "avg_logprob": -0.16457446416219076, "compression_ratio": 1.4489795918367347, "no_speech_prob": 3.138129386570654e-06}, {"id": 161, "seek": 79592, "start": 795.92, "end": 803.36, "text": " has won this with half an hour on a cluster of TPUs.", "tokens": [575, 1582, 341, 365, 1922, 364, 1773, 322, 257, 13630, 295, 314, 8115, 82, 13], "temperature": 0.0, "avg_logprob": -0.15609075312028853, "compression_ratio": 1.4042553191489362, "no_speech_prob": 8.139602869050577e-06}, {"id": 162, "seek": 79592, "start": 803.36, "end": 814.4799999999999, "text": " The best non-cluster of TPU result is fastai plus students under 3 hours beating out Intel", "tokens": [440, 1151, 2107, 12, 3474, 8393, 295, 314, 8115, 1874, 307, 2370, 1301, 1804, 1731, 833, 805, 2496, 13497, 484, 19762], "temperature": 0.0, "avg_logprob": -0.15609075312028853, "compression_ratio": 1.4042553191489362, "no_speech_prob": 8.139602869050577e-06}, {"id": 163, "seek": 79592, "start": 814.4799999999999, "end": 821.3399999999999, "text": " on 128 computers, or else we ran on a single computer.", "tokens": [322, 29810, 10807, 11, 420, 1646, 321, 5872, 322, 257, 2167, 3820, 13], "temperature": 0.0, "avg_logprob": -0.15609075312028853, "compression_ratio": 1.4042553191489362, "no_speech_prob": 8.139602869050577e-06}, {"id": 164, "seek": 82134, "start": 821.34, "end": 827.64, "text": " We also beat Google running on a TPU.", "tokens": [492, 611, 4224, 3329, 2614, 322, 257, 314, 8115, 13], "temperature": 0.0, "avg_logprob": -0.10545895213172549, "compression_ratio": 1.5571428571428572, "no_speech_prob": 6.43893417873187e-06}, {"id": 165, "seek": 82134, "start": 827.64, "end": 835.9200000000001, "text": " So using this approach, we've shown the fastest GPU result, the fastest single machine result,", "tokens": [407, 1228, 341, 3109, 11, 321, 600, 4898, 264, 14573, 18407, 1874, 11, 264, 14573, 2167, 3479, 1874, 11], "temperature": 0.0, "avg_logprob": -0.10545895213172549, "compression_ratio": 1.5571428571428572, "no_speech_prob": 6.43893417873187e-06}, {"id": 166, "seek": 82134, "start": 835.9200000000001, "end": 841.84, "text": " the fastest publicly available infrastructure result, these TPU pods you can't use unless", "tokens": [264, 14573, 14843, 2435, 6896, 1874, 11, 613, 314, 8115, 31925, 291, 393, 380, 764, 5969], "temperature": 0.0, "avg_logprob": -0.10545895213172549, "compression_ratio": 1.5571428571428572, "no_speech_prob": 6.43893417873187e-06}, {"id": 167, "seek": 82134, "start": 841.84, "end": 844.4, "text": " you're Google.", "tokens": [291, 434, 3329, 13], "temperature": 0.0, "avg_logprob": -0.10545895213172549, "compression_ratio": 1.5571428571428572, "no_speech_prob": 6.43893417873187e-06}, {"id": 168, "seek": 82134, "start": 844.4, "end": 850.36, "text": " And the cost is tiny, like this Intel one cost them $1,200 worth of compute, they haven't", "tokens": [400, 264, 2063, 307, 5870, 11, 411, 341, 19762, 472, 2063, 552, 1848, 16, 11, 7629, 3163, 295, 14722, 11, 436, 2378, 380], "temperature": 0.0, "avg_logprob": -0.10545895213172549, "compression_ratio": 1.5571428571428572, "no_speech_prob": 6.43893417873187e-06}, {"id": 169, "seek": 85036, "start": 850.36, "end": 852.24, "text": " even written it here.", "tokens": [754, 3720, 309, 510, 13], "temperature": 0.0, "avg_logprob": -0.18734681606292725, "compression_ratio": 1.4093264248704662, "no_speech_prob": 3.9669612306170166e-06}, {"id": 170, "seek": 85036, "start": 852.24, "end": 861.4, "text": " That's 128 computers in parallel, each one with 36 cores, each one with 140GB compared", "tokens": [663, 311, 29810, 10807, 294, 8952, 11, 1184, 472, 365, 8652, 24826, 11, 1184, 472, 365, 21548, 8769, 5347], "temperature": 0.0, "avg_logprob": -0.18734681606292725, "compression_ratio": 1.4093264248704662, "no_speech_prob": 3.9669612306170166e-06}, {"id": 171, "seek": 85036, "start": 861.4, "end": 866.1, "text": " to our single AWS instance.", "tokens": [281, 527, 2167, 17650, 5197, 13], "temperature": 0.0, "avg_logprob": -0.18734681606292725, "compression_ratio": 1.4093264248704662, "no_speech_prob": 3.9669612306170166e-06}, {"id": 172, "seek": 85036, "start": 866.1, "end": 876.08, "text": " So this is a kind of a breakthrough in what we can do, like the idea that we can train", "tokens": [407, 341, 307, 257, 733, 295, 257, 22397, 294, 437, 321, 393, 360, 11, 411, 264, 1558, 300, 321, 393, 3847], "temperature": 0.0, "avg_logprob": -0.18734681606292725, "compression_ratio": 1.4093264248704662, "no_speech_prob": 3.9669612306170166e-06}, {"id": 173, "seek": 85036, "start": 876.08, "end": 879.0600000000001, "text": " ImageNet on a single publicly available machine.", "tokens": [29903, 31890, 322, 257, 2167, 14843, 2435, 3479, 13], "temperature": 0.0, "avg_logprob": -0.18734681606292725, "compression_ratio": 1.4093264248704662, "no_speech_prob": 3.9669612306170166e-06}, {"id": 174, "seek": 87906, "start": 879.06, "end": 884.9599999999999, "text": " And this $72, by the way, it was actually $25 because we used a spot instance.", "tokens": [400, 341, 1848, 28890, 11, 538, 264, 636, 11, 309, 390, 767, 1848, 6074, 570, 321, 1143, 257, 4008, 5197, 13], "temperature": 0.0, "avg_logprob": -0.12478330400254992, "compression_ratio": 1.5530973451327434, "no_speech_prob": 1.0129819202120416e-05}, {"id": 175, "seek": 87906, "start": 884.9599999999999, "end": 889.3199999999999, "text": " So one of our students, Andrew Shaw, built this whole system to allow us to throw a whole", "tokens": [407, 472, 295, 527, 1731, 11, 10110, 27132, 11, 3094, 341, 1379, 1185, 281, 2089, 505, 281, 3507, 257, 1379], "temperature": 0.0, "avg_logprob": -0.12478330400254992, "compression_ratio": 1.5530973451327434, "no_speech_prob": 1.0129819202120416e-05}, {"id": 176, "seek": 87906, "start": 889.3199999999999, "end": 895.4799999999999, "text": " bunch of spot instance experiments up and run them simultaneously and pretty much automatically.", "tokens": [3840, 295, 4008, 5197, 12050, 493, 293, 1190, 552, 16561, 293, 1238, 709, 6772, 13], "temperature": 0.0, "avg_logprob": -0.12478330400254992, "compression_ratio": 1.5530973451327434, "no_speech_prob": 1.0129819202120416e-05}, {"id": 177, "seek": 87906, "start": 895.4799999999999, "end": 903.1999999999999, "text": " But DawnBench doesn't quote the actual number we used, so it's actually $25, not $72.", "tokens": [583, 26001, 21736, 339, 1177, 380, 6513, 264, 3539, 1230, 321, 1143, 11, 370, 309, 311, 767, 1848, 6074, 11, 406, 1848, 28890, 13], "temperature": 0.0, "avg_logprob": -0.12478330400254992, "compression_ratio": 1.5530973451327434, "no_speech_prob": 1.0129819202120416e-05}, {"id": 178, "seek": 90320, "start": 903.2, "end": 916.0400000000001, "text": " So this data list idea is super important and helpful.", "tokens": [407, 341, 1412, 1329, 1558, 307, 1687, 1021, 293, 4961, 13], "temperature": 0.0, "avg_logprob": -0.17692562739054363, "compression_ratio": 1.4146341463414633, "no_speech_prob": 2.4439689241262386e-06}, {"id": 179, "seek": 90320, "start": 916.0400000000001, "end": 920.88, "text": " And so our SciFi 10 results are also now up there officially.", "tokens": [400, 370, 527, 16942, 13229, 1266, 3542, 366, 611, 586, 493, 456, 12053, 13], "temperature": 0.0, "avg_logprob": -0.17692562739054363, "compression_ratio": 1.4146341463414633, "no_speech_prob": 2.4439689241262386e-06}, {"id": 180, "seek": 90320, "start": 920.88, "end": 925.4200000000001, "text": " And you might remember the previous best was a bit over an hour.", "tokens": [400, 291, 1062, 1604, 264, 3894, 1151, 390, 257, 857, 670, 364, 1773, 13], "temperature": 0.0, "avg_logprob": -0.17692562739054363, "compression_ratio": 1.4146341463414633, "no_speech_prob": 2.4439689241262386e-06}, {"id": 181, "seek": 90320, "start": 925.4200000000001, "end": 928.48, "text": " And the trick here was using one cycle, basically.", "tokens": [400, 264, 4282, 510, 390, 1228, 472, 6586, 11, 1936, 13], "temperature": 0.0, "avg_logprob": -0.17692562739054363, "compression_ratio": 1.4146341463414633, "no_speech_prob": 2.4439689241262386e-06}, {"id": 182, "seek": 92848, "start": 928.48, "end": 933.36, "text": " So all this stuff that's in Silvance training phase API is really all the stuff that we've", "tokens": [407, 439, 341, 1507, 300, 311, 294, 6943, 85, 719, 3097, 5574, 9362, 307, 534, 439, 264, 1507, 300, 321, 600], "temperature": 0.0, "avg_logprob": -0.20803707122802734, "compression_ratio": 1.5352697095435686, "no_speech_prob": 2.190752638853155e-06}, {"id": 183, "seek": 92848, "start": 933.36, "end": 935.44, "text": " used to get these top results.", "tokens": [1143, 281, 483, 613, 1192, 3542, 13], "temperature": 0.0, "avg_logprob": -0.20803707122802734, "compression_ratio": 1.5352697095435686, "no_speech_prob": 2.190752638853155e-06}, {"id": 184, "seek": 92848, "start": 935.44, "end": 943.88, "text": " And really cool, another fast AI student who goes by the name here, BKJ, has taken that", "tokens": [400, 534, 1627, 11, 1071, 2370, 7318, 3107, 567, 1709, 538, 264, 1315, 510, 11, 363, 42, 41, 11, 575, 2726, 300], "temperature": 0.0, "avg_logprob": -0.20803707122802734, "compression_ratio": 1.5352697095435686, "no_speech_prob": 2.190752638853155e-06}, {"id": 185, "seek": 92848, "start": 943.88, "end": 947.4, "text": " and done his own version.", "tokens": [293, 1096, 702, 1065, 3037, 13], "temperature": 0.0, "avg_logprob": -0.20803707122802734, "compression_ratio": 1.5352697095435686, "no_speech_prob": 2.190752638853155e-06}, {"id": 186, "seek": 92848, "start": 947.4, "end": 951.88, "text": " He took ResNet 18 and added the concat pooling that you might remember that we learned about", "tokens": [634, 1890, 5015, 31890, 2443, 293, 3869, 264, 1588, 267, 7005, 278, 300, 291, 1062, 1604, 300, 321, 3264, 466], "temperature": 0.0, "avg_logprob": -0.20803707122802734, "compression_ratio": 1.5352697095435686, "no_speech_prob": 2.190752638853155e-06}, {"id": 187, "seek": 92848, "start": 951.88, "end": 958.0600000000001, "text": " on top and used Leslie Smith's one cycle.", "tokens": [322, 1192, 293, 1143, 28140, 8538, 311, 472, 6586, 13], "temperature": 0.0, "avg_logprob": -0.20803707122802734, "compression_ratio": 1.5352697095435686, "no_speech_prob": 2.190752638853155e-06}, {"id": 188, "seek": 95806, "start": 958.06, "end": 965.14, "text": " And so he's got on the leaderboard all the top three fast AI students, which is wonderful.", "tokens": [400, 370, 415, 311, 658, 322, 264, 5263, 3787, 439, 264, 1192, 1045, 2370, 7318, 1731, 11, 597, 307, 3715, 13], "temperature": 0.0, "avg_logprob": -0.2463733400617327, "compression_ratio": 1.4654088050314464, "no_speech_prob": 1.3211743862484582e-05}, {"id": 189, "seek": 95806, "start": 965.14, "end": 967.8, "text": " And same for cost, the top three.", "tokens": [400, 912, 337, 2063, 11, 264, 1192, 1045, 13], "temperature": 0.0, "avg_logprob": -0.2463733400617327, "compression_ratio": 1.4654088050314464, "no_speech_prob": 1.3211743862484582e-05}, {"id": 190, "seek": 95806, "start": 967.8, "end": 978.14, "text": " And you can see, Paperspace, so Brett ran this on Paperspace and got the cheapest result,", "tokens": [400, 291, 393, 536, 11, 15919, 433, 17940, 11, 370, 29447, 5872, 341, 322, 15919, 433, 17940, 293, 658, 264, 29167, 1874, 11], "temperature": 0.0, "avg_logprob": -0.2463733400617327, "compression_ratio": 1.4654088050314464, "no_speech_prob": 1.3211743862484582e-05}, {"id": 191, "seek": 95806, "start": 978.14, "end": 980.16, "text": " just ahead of BKJ.", "tokens": [445, 2286, 295, 363, 42, 41, 13], "temperature": 0.0, "avg_logprob": -0.2463733400617327, "compression_ratio": 1.4654088050314464, "no_speech_prob": 1.3211743862484582e-05}, {"id": 192, "seek": 98016, "start": 980.16, "end": 994.52, "text": " So I think you can see a lot of the interesting opportunities at the moment for training stuff", "tokens": [407, 286, 519, 291, 393, 536, 257, 688, 295, 264, 1880, 4786, 412, 264, 1623, 337, 3097, 1507], "temperature": 0.0, "avg_logprob": -0.17180508375167847, "compression_ratio": 1.6764705882352942, "no_speech_prob": 1.4367432186190854e-06}, {"id": 193, "seek": 98016, "start": 994.52, "end": 999.3199999999999, "text": " more quickly and cheaply are all about the learning rate annealing and size annealing", "tokens": [544, 2661, 293, 7084, 356, 366, 439, 466, 264, 2539, 3314, 22256, 4270, 293, 2744, 22256, 4270], "temperature": 0.0, "avg_logprob": -0.17180508375167847, "compression_ratio": 1.6764705882352942, "no_speech_prob": 1.4367432186190854e-06}, {"id": 194, "seek": 98016, "start": 999.3199999999999, "end": 1002.92, "text": " and training with different parameters at different times.", "tokens": [293, 3097, 365, 819, 9834, 412, 819, 1413, 13], "temperature": 0.0, "avg_logprob": -0.17180508375167847, "compression_ratio": 1.6764705882352942, "no_speech_prob": 1.4367432186190854e-06}, {"id": 195, "seek": 98016, "start": 1002.92, "end": 1004.74, "text": " And I still think we're only scratching the surface.", "tokens": [400, 286, 920, 519, 321, 434, 787, 29699, 264, 3753, 13], "temperature": 0.0, "avg_logprob": -0.17180508375167847, "compression_ratio": 1.6764705882352942, "no_speech_prob": 1.4367432186190854e-06}, {"id": 196, "seek": 98016, "start": 1004.74, "end": 1008.56, "text": " I think we can go a lot faster and a lot cheaper.", "tokens": [286, 519, 321, 393, 352, 257, 688, 4663, 293, 257, 688, 12284, 13], "temperature": 0.0, "avg_logprob": -0.17180508375167847, "compression_ratio": 1.6764705882352942, "no_speech_prob": 1.4367432186190854e-06}, {"id": 197, "seek": 100856, "start": 1008.56, "end": 1013.56, "text": " And that's really helpful for people in resource constrained environments, which is basically", "tokens": [400, 300, 311, 534, 4961, 337, 561, 294, 7684, 38901, 12388, 11, 597, 307, 1936], "temperature": 0.0, "avg_logprob": -0.20535204008028105, "compression_ratio": 1.6330275229357798, "no_speech_prob": 1.2606586096808314e-05}, {"id": 198, "seek": 100856, "start": 1013.56, "end": 1022.5999999999999, "text": " everybody except Google, maybe Facebook.", "tokens": [2201, 3993, 3329, 11, 1310, 4384, 13], "temperature": 0.0, "avg_logprob": -0.20535204008028105, "compression_ratio": 1.6330275229357798, "no_speech_prob": 1.2606586096808314e-05}, {"id": 199, "seek": 100856, "start": 1022.5999999999999, "end": 1024.04, "text": " Architecture is interesting as well, though.", "tokens": [43049, 307, 1880, 382, 731, 11, 1673, 13], "temperature": 0.0, "avg_logprob": -0.20535204008028105, "compression_ratio": 1.6330275229357798, "no_speech_prob": 1.2606586096808314e-05}, {"id": 200, "seek": 100856, "start": 1024.04, "end": 1028.1599999999999, "text": " And one of the things we looked at last week was just creating a simpler architecture,", "tokens": [400, 472, 295, 264, 721, 321, 2956, 412, 1036, 1243, 390, 445, 4084, 257, 18587, 9482, 11], "temperature": 0.0, "avg_logprob": -0.20535204008028105, "compression_ratio": 1.6330275229357798, "no_speech_prob": 1.2606586096808314e-05}, {"id": 201, "seek": 100856, "start": 1028.1599999999999, "end": 1035.72, "text": " which is basically state of the art, like the really basic kind of dark net architecture.", "tokens": [597, 307, 1936, 1785, 295, 264, 1523, 11, 411, 264, 534, 3875, 733, 295, 2877, 2533, 9482, 13], "temperature": 0.0, "avg_logprob": -0.20535204008028105, "compression_ratio": 1.6330275229357798, "no_speech_prob": 1.2606586096808314e-05}, {"id": 202, "seek": 103572, "start": 1035.72, "end": 1041.8, "text": " But there's a piece of architecture we haven't talked about, which is necessary to understand", "tokens": [583, 456, 311, 257, 2522, 295, 9482, 321, 2378, 380, 2825, 466, 11, 597, 307, 4818, 281, 1223], "temperature": 0.0, "avg_logprob": -0.1875141929177677, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.6700694686733186e-05}, {"id": 203, "seek": 103572, "start": 1041.8, "end": 1043.4, "text": " the inception network.", "tokens": [264, 49834, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1875141929177677, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.6700694686733186e-05}, {"id": 204, "seek": 103572, "start": 1043.4, "end": 1048.6000000000001, "text": " And the inception network is actually pretty interesting, because they use some tricks", "tokens": [400, 264, 49834, 3209, 307, 767, 1238, 1880, 11, 570, 436, 764, 512, 11733], "temperature": 0.0, "avg_logprob": -0.1875141929177677, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.6700694686733186e-05}, {"id": 205, "seek": 103572, "start": 1048.6000000000001, "end": 1053.04, "text": " to actually make things more efficient.", "tokens": [281, 767, 652, 721, 544, 7148, 13], "temperature": 0.0, "avg_logprob": -0.1875141929177677, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.6700694686733186e-05}, {"id": 206, "seek": 103572, "start": 1053.04, "end": 1056.3600000000001, "text": " And we're not currently using these tricks, and I kind of feel like maybe we should try", "tokens": [400, 321, 434, 406, 4362, 1228, 613, 11733, 11, 293, 286, 733, 295, 841, 411, 1310, 321, 820, 853], "temperature": 0.0, "avg_logprob": -0.1875141929177677, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.6700694686733186e-05}, {"id": 207, "seek": 103572, "start": 1056.3600000000001, "end": 1058.08, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.1875141929177677, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.6700694686733186e-05}, {"id": 208, "seek": 103572, "start": 1058.08, "end": 1064.0, "text": " And so the most interesting, most successful inception network is their Inception ResNet-2", "tokens": [400, 370, 264, 881, 1880, 11, 881, 4406, 49834, 3209, 307, 641, 682, 7311, 5015, 31890, 12, 17], "temperature": 0.0, "avg_logprob": -0.1875141929177677, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.6700694686733186e-05}, {"id": 209, "seek": 103572, "start": 1064.0, "end": 1065.0, "text": " network.", "tokens": [3209, 13], "temperature": 0.0, "avg_logprob": -0.1875141929177677, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.6700694686733186e-05}, {"id": 210, "seek": 106500, "start": 1065.0, "end": 1068.32, "text": " And most of the blocks in that look something like this.", "tokens": [400, 881, 295, 264, 8474, 294, 300, 574, 746, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.16547361060754576, "compression_ratio": 1.5668789808917198, "no_speech_prob": 6.1441323850885965e-06}, {"id": 211, "seek": 106500, "start": 1068.32, "end": 1072.08, "text": " And it looks a lot like a standard ResNet block in that there's an identity connection", "tokens": [400, 309, 1542, 257, 688, 411, 257, 3832, 5015, 31890, 3461, 294, 300, 456, 311, 364, 6575, 4984], "temperature": 0.0, "avg_logprob": -0.16547361060754576, "compression_ratio": 1.5668789808917198, "no_speech_prob": 6.1441323850885965e-06}, {"id": 212, "seek": 106500, "start": 1072.08, "end": 1080.2, "text": " here and then there's a conv-conv path here and then we add them up together.", "tokens": [510, 293, 550, 456, 311, 257, 3754, 12, 1671, 85, 3100, 510, 293, 550, 321, 909, 552, 493, 1214, 13], "temperature": 0.0, "avg_logprob": -0.16547361060754576, "compression_ratio": 1.5668789808917198, "no_speech_prob": 6.1441323850885965e-06}, {"id": 213, "seek": 106500, "start": 1080.2, "end": 1086.12, "text": " But it's not quite that.", "tokens": [583, 309, 311, 406, 1596, 300, 13], "temperature": 0.0, "avg_logprob": -0.16547361060754576, "compression_ratio": 1.5668789808917198, "no_speech_prob": 6.1441323850885965e-06}, {"id": 214, "seek": 108612, "start": 1086.12, "end": 1096.12, "text": " The first is that this path is a one-by-one conv, not just any old conv, but a one-by-one", "tokens": [440, 700, 307, 300, 341, 3100, 307, 257, 472, 12, 2322, 12, 546, 3754, 11, 406, 445, 604, 1331, 3754, 11, 457, 257, 472, 12, 2322, 12, 546], "temperature": 0.0, "avg_logprob": -0.130990878645196, "compression_ratio": 1.6352201257861636, "no_speech_prob": 8.990945161713171e-07}, {"id": 215, "seek": 108612, "start": 1096.12, "end": 1098.12, "text": " conv.", "tokens": [3754, 13], "temperature": 0.0, "avg_logprob": -0.130990878645196, "compression_ratio": 1.6352201257861636, "no_speech_prob": 8.990945161713171e-07}, {"id": 216, "seek": 108612, "start": 1098.12, "end": 1104.06, "text": " And so it's worth thinking about what a one-by-one conv actually is.", "tokens": [400, 370, 309, 311, 3163, 1953, 466, 437, 257, 472, 12, 2322, 12, 546, 3754, 767, 307, 13], "temperature": 0.0, "avg_logprob": -0.130990878645196, "compression_ratio": 1.6352201257861636, "no_speech_prob": 8.990945161713171e-07}, {"id": 217, "seek": 108612, "start": 1104.06, "end": 1112.0, "text": " So a one-by-one conv is simply saying for each grid cell in your input, you've got a, basically", "tokens": [407, 257, 472, 12, 2322, 12, 546, 3754, 307, 2935, 1566, 337, 1184, 10748, 2815, 294, 428, 4846, 11, 291, 600, 658, 257, 11, 1936], "temperature": 0.0, "avg_logprob": -0.130990878645196, "compression_ratio": 1.6352201257861636, "no_speech_prob": 8.990945161713171e-07}, {"id": 218, "seek": 111200, "start": 1112.0, "end": 1118.16, "text": " it's a vector, a one-by-one-by-number-of-filters tensor is basically a vector.", "tokens": [309, 311, 257, 8062, 11, 257, 472, 12, 2322, 12, 546, 12, 2322, 12, 41261, 12, 2670, 12, 19776, 1559, 40863, 307, 1936, 257, 8062, 13], "temperature": 0.0, "avg_logprob": -0.13049423694610596, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.9944278594484786e-06}, {"id": 219, "seek": 111200, "start": 1118.16, "end": 1125.56, "text": " So for each grid cell in your input, you're just doing a dot product with that tensor.", "tokens": [407, 337, 1184, 10748, 2815, 294, 428, 4846, 11, 291, 434, 445, 884, 257, 5893, 1674, 365, 300, 40863, 13], "temperature": 0.0, "avg_logprob": -0.13049423694610596, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.9944278594484786e-06}, {"id": 220, "seek": 111200, "start": 1125.56, "end": 1131.2, "text": " And then of course there's going to be one of those vectors for each of the 192 activations", "tokens": [400, 550, 295, 1164, 456, 311, 516, 281, 312, 472, 295, 729, 18875, 337, 1184, 295, 264, 1294, 17, 2430, 763], "temperature": 0.0, "avg_logprob": -0.13049423694610596, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.9944278594484786e-06}, {"id": 221, "seek": 111200, "start": 1131.2, "end": 1132.2, "text": " we're creating.", "tokens": [321, 434, 4084, 13], "temperature": 0.0, "avg_logprob": -0.13049423694610596, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.9944278594484786e-06}, {"id": 222, "seek": 111200, "start": 1132.2, "end": 1137.96, "text": " So you basically do 192 dot products with grid cell 1,1, and then 192 with grid cell", "tokens": [407, 291, 1936, 360, 1294, 17, 5893, 3383, 365, 10748, 2815, 502, 11, 16, 11, 293, 550, 1294, 17, 365, 10748, 2815], "temperature": 0.0, "avg_logprob": -0.13049423694610596, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.9944278594484786e-06}, {"id": 223, "seek": 111200, "start": 1137.96, "end": 1140.28, "text": " 1,2, and 1,3, and so forth.", "tokens": [502, 11, 17, 11, 293, 502, 11, 18, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.13049423694610596, "compression_ratio": 1.7309417040358743, "no_speech_prob": 2.9944278594484786e-06}, {"id": 224, "seek": 114028, "start": 1140.28, "end": 1145.96, "text": " And so you'll end up with something which has got the same grid size as the input and", "tokens": [400, 370, 291, 603, 917, 493, 365, 746, 597, 575, 658, 264, 912, 10748, 2744, 382, 264, 4846, 293], "temperature": 0.0, "avg_logprob": -0.09806531446951407, "compression_ratio": 1.7889908256880733, "no_speech_prob": 1.505698151049728e-06}, {"id": 225, "seek": 114028, "start": 1145.96, "end": 1149.2, "text": " 192 channels in the output.", "tokens": [1294, 17, 9235, 294, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.09806531446951407, "compression_ratio": 1.7889908256880733, "no_speech_prob": 1.505698151049728e-06}, {"id": 226, "seek": 114028, "start": 1149.2, "end": 1156.26, "text": " So that's a really good way to either reduce the dimensionality or increase the dimensionality", "tokens": [407, 300, 311, 257, 534, 665, 636, 281, 2139, 5407, 264, 10139, 1860, 420, 3488, 264, 10139, 1860], "temperature": 0.0, "avg_logprob": -0.09806531446951407, "compression_ratio": 1.7889908256880733, "no_speech_prob": 1.505698151049728e-06}, {"id": 227, "seek": 114028, "start": 1156.26, "end": 1160.3, "text": " of an input without changing the grid size.", "tokens": [295, 364, 4846, 1553, 4473, 264, 10748, 2744, 13], "temperature": 0.0, "avg_logprob": -0.09806531446951407, "compression_ratio": 1.7889908256880733, "no_speech_prob": 1.505698151049728e-06}, {"id": 228, "seek": 114028, "start": 1160.3, "end": 1165.04, "text": " That's normally what we use one-by-one convs for.", "tokens": [663, 311, 5646, 437, 321, 764, 472, 12, 2322, 12, 546, 3754, 82, 337, 13], "temperature": 0.0, "avg_logprob": -0.09806531446951407, "compression_ratio": 1.7889908256880733, "no_speech_prob": 1.505698151049728e-06}, {"id": 229, "seek": 114028, "start": 1165.04, "end": 1168.76, "text": " So here we've got a one-by-one conv and then we've got another one-by-one conv and then", "tokens": [407, 510, 321, 600, 658, 257, 472, 12, 2322, 12, 546, 3754, 293, 550, 321, 600, 658, 1071, 472, 12, 2322, 12, 546, 3754, 293, 550], "temperature": 0.0, "avg_logprob": -0.09806531446951407, "compression_ratio": 1.7889908256880733, "no_speech_prob": 1.505698151049728e-06}, {"id": 230, "seek": 116876, "start": 1168.76, "end": 1170.8, "text": " they're added together.", "tokens": [436, 434, 3869, 1214, 13], "temperature": 0.0, "avg_logprob": -0.13811387748361748, "compression_ratio": 1.832512315270936, "no_speech_prob": 4.222821644361829e-06}, {"id": 231, "seek": 116876, "start": 1170.8, "end": 1175.96, "text": " And then there's a third path, and this third path is not added.", "tokens": [400, 550, 456, 311, 257, 2636, 3100, 11, 293, 341, 2636, 3100, 307, 406, 3869, 13], "temperature": 0.0, "avg_logprob": -0.13811387748361748, "compression_ratio": 1.832512315270936, "no_speech_prob": 4.222821644361829e-06}, {"id": 232, "seek": 116876, "start": 1175.96, "end": 1181.28, "text": " This third path is not actually explicitly mentioned, but it's concatenated.", "tokens": [639, 2636, 3100, 307, 406, 767, 20803, 2835, 11, 457, 309, 311, 1588, 7186, 770, 13], "temperature": 0.0, "avg_logprob": -0.13811387748361748, "compression_ratio": 1.832512315270936, "no_speech_prob": 4.222821644361829e-06}, {"id": 233, "seek": 116876, "start": 1181.28, "end": 1186.6, "text": " And so actually there is a form of resnet which is basically identical to resnet, but", "tokens": [400, 370, 767, 456, 307, 257, 1254, 295, 725, 7129, 597, 307, 1936, 14800, 281, 725, 7129, 11, 457], "temperature": 0.0, "avg_logprob": -0.13811387748361748, "compression_ratio": 1.832512315270936, "no_speech_prob": 4.222821644361829e-06}, {"id": 234, "seek": 116876, "start": 1186.6, "end": 1189.94, "text": " we don't do plus, we do concat.", "tokens": [321, 500, 380, 360, 1804, 11, 321, 360, 1588, 267, 13], "temperature": 0.0, "avg_logprob": -0.13811387748361748, "compression_ratio": 1.832512315270936, "no_speech_prob": 4.222821644361829e-06}, {"id": 235, "seek": 116876, "start": 1189.94, "end": 1191.96, "text": " And that's called a dense net.", "tokens": [400, 300, 311, 1219, 257, 18011, 2533, 13], "temperature": 0.0, "avg_logprob": -0.13811387748361748, "compression_ratio": 1.832512315270936, "no_speech_prob": 4.222821644361829e-06}, {"id": 236, "seek": 116876, "start": 1191.96, "end": 1196.32, "text": " So it's just a resnet where we do concat instead of plus.", "tokens": [407, 309, 311, 445, 257, 725, 7129, 689, 321, 360, 1588, 267, 2602, 295, 1804, 13], "temperature": 0.0, "avg_logprob": -0.13811387748361748, "compression_ratio": 1.832512315270936, "no_speech_prob": 4.222821644361829e-06}, {"id": 237, "seek": 119632, "start": 1196.32, "end": 1204.52, "text": " And that's an interesting approach because then the identity path is literally being", "tokens": [400, 300, 311, 364, 1880, 3109, 570, 550, 264, 6575, 3100, 307, 3736, 885], "temperature": 0.0, "avg_logprob": -0.16033950893358254, "compression_ratio": 1.6542056074766356, "no_speech_prob": 1.2098635124857537e-06}, {"id": 238, "seek": 119632, "start": 1204.52, "end": 1205.52, "text": " copied.", "tokens": [25365, 13], "temperature": 0.0, "avg_logprob": -0.16033950893358254, "compression_ratio": 1.6542056074766356, "no_speech_prob": 1.2098635124857537e-06}, {"id": 239, "seek": 119632, "start": 1205.52, "end": 1209.76, "text": " So you kind of get that flow all the way through.", "tokens": [407, 291, 733, 295, 483, 300, 3095, 439, 264, 636, 807, 13], "temperature": 0.0, "avg_logprob": -0.16033950893358254, "compression_ratio": 1.6542056074766356, "no_speech_prob": 1.2098635124857537e-06}, {"id": 240, "seek": 119632, "start": 1209.76, "end": 1215.2, "text": " And so as we'll see next week, that tends to be good for segmentation and stuff like", "tokens": [400, 370, 382, 321, 603, 536, 958, 1243, 11, 300, 12258, 281, 312, 665, 337, 9469, 399, 293, 1507, 411], "temperature": 0.0, "avg_logprob": -0.16033950893358254, "compression_ratio": 1.6542056074766356, "no_speech_prob": 1.2098635124857537e-06}, {"id": 241, "seek": 119632, "start": 1215.2, "end": 1219.36, "text": " that where you really want to keep the original pixels and the first layer of pixels and the", "tokens": [300, 689, 291, 534, 528, 281, 1066, 264, 3380, 18668, 293, 264, 700, 4583, 295, 18668, 293, 264], "temperature": 0.0, "avg_logprob": -0.16033950893358254, "compression_ratio": 1.6542056074766356, "no_speech_prob": 1.2098635124857537e-06}, {"id": 242, "seek": 119632, "start": 1219.36, "end": 1223.34, "text": " second layer of pixels untouched.", "tokens": [1150, 4583, 295, 18668, 1701, 36740, 13], "temperature": 0.0, "avg_logprob": -0.16033950893358254, "compression_ratio": 1.6542056074766356, "no_speech_prob": 1.2098635124857537e-06}, {"id": 243, "seek": 122334, "start": 1223.34, "end": 1231.32, "text": " So concatenating rather than adding branches is a very useful thing to do.", "tokens": [407, 1588, 7186, 990, 2831, 813, 5127, 14770, 307, 257, 588, 4420, 551, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.09789342658464299, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.495164375839522e-06}, {"id": 244, "seek": 122334, "start": 1231.32, "end": 1233.8799999999999, "text": " And so here we're concatenating this branch.", "tokens": [400, 370, 510, 321, 434, 1588, 7186, 990, 341, 9819, 13], "temperature": 0.0, "avg_logprob": -0.09789342658464299, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.495164375839522e-06}, {"id": 245, "seek": 122334, "start": 1233.8799999999999, "end": 1237.8799999999999, "text": " And this branch is doing something interesting, which is it's doing first of all the one-by-one", "tokens": [400, 341, 9819, 307, 884, 746, 1880, 11, 597, 307, 309, 311, 884, 700, 295, 439, 264, 472, 12, 2322, 12, 546], "temperature": 0.0, "avg_logprob": -0.09789342658464299, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.495164375839522e-06}, {"id": 246, "seek": 122334, "start": 1237.8799999999999, "end": 1243.26, "text": " conv and then a one-by-seven and then a seven-by-one.", "tokens": [3754, 293, 550, 257, 472, 12, 2322, 12, 44476, 293, 550, 257, 3407, 12, 2322, 12, 546, 13], "temperature": 0.0, "avg_logprob": -0.09789342658464299, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.495164375839522e-06}, {"id": 247, "seek": 122334, "start": 1243.26, "end": 1246.48, "text": " So what's going on there?", "tokens": [407, 437, 311, 516, 322, 456, 30], "temperature": 0.0, "avg_logprob": -0.09789342658464299, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.495164375839522e-06}, {"id": 248, "seek": 124648, "start": 1246.48, "end": 1253.16, "text": " So what's going on there is basically what we really want to do is do a seven-by-seven", "tokens": [407, 437, 311, 516, 322, 456, 307, 1936, 437, 321, 534, 528, 281, 360, 307, 360, 257, 3407, 12, 2322, 12, 44476], "temperature": 0.0, "avg_logprob": -0.1346270633193682, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.406091425655177e-06}, {"id": 249, "seek": 124648, "start": 1253.16, "end": 1254.16, "text": " conv.", "tokens": [3754, 13], "temperature": 0.0, "avg_logprob": -0.1346270633193682, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.406091425655177e-06}, {"id": 250, "seek": 124648, "start": 1254.16, "end": 1259.0, "text": " And the reason we want to do a seven-by-seven conv is that if you've got multiple paths,", "tokens": [400, 264, 1778, 321, 528, 281, 360, 257, 3407, 12, 2322, 12, 44476, 3754, 307, 300, 498, 291, 600, 658, 3866, 14518, 11], "temperature": 0.0, "avg_logprob": -0.1346270633193682, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.406091425655177e-06}, {"id": 251, "seek": 124648, "start": 1259.0, "end": 1265.84, "text": " each of which has different kernel sizes, then it's able to look at different amounts", "tokens": [1184, 295, 597, 575, 819, 28256, 11602, 11, 550, 309, 311, 1075, 281, 574, 412, 819, 11663], "temperature": 0.0, "avg_logprob": -0.1346270633193682, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.406091425655177e-06}, {"id": 252, "seek": 124648, "start": 1265.84, "end": 1267.04, "text": " of the image.", "tokens": [295, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1346270633193682, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.406091425655177e-06}, {"id": 253, "seek": 124648, "start": 1267.04, "end": 1271.24, "text": " And so like the original inception network had like a one-by-one, a three-by-three, a", "tokens": [400, 370, 411, 264, 3380, 49834, 3209, 632, 411, 257, 472, 12, 2322, 12, 546, 11, 257, 1045, 12, 2322, 12, 27583, 11, 257], "temperature": 0.0, "avg_logprob": -0.1346270633193682, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.406091425655177e-06}, {"id": 254, "seek": 127124, "start": 1271.24, "end": 1277.4, "text": " five-by-five, a seven-by-seven, kind of getting concatenated in together, something like that.", "tokens": [1732, 12, 2322, 12, 18621, 11, 257, 3407, 12, 2322, 12, 44476, 11, 733, 295, 1242, 1588, 7186, 770, 294, 1214, 11, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.11321261981586078, "compression_ratio": 1.8738738738738738, "no_speech_prob": 1.4367467429110548e-06}, {"id": 255, "seek": 127124, "start": 1277.4, "end": 1282.16, "text": " And so if we can have a seven-by-seven filter, then we get to kind of look at a lot of the", "tokens": [400, 370, 498, 321, 393, 362, 257, 3407, 12, 2322, 12, 44476, 6608, 11, 550, 321, 483, 281, 733, 295, 574, 412, 257, 688, 295, 264], "temperature": 0.0, "avg_logprob": -0.11321261981586078, "compression_ratio": 1.8738738738738738, "no_speech_prob": 1.4367467429110548e-06}, {"id": 256, "seek": 127124, "start": 1282.16, "end": 1285.92, "text": " image at once and create a really rich representation.", "tokens": [3256, 412, 1564, 293, 1884, 257, 534, 4593, 10290, 13], "temperature": 0.0, "avg_logprob": -0.11321261981586078, "compression_ratio": 1.8738738738738738, "no_speech_prob": 1.4367467429110548e-06}, {"id": 257, "seek": 127124, "start": 1285.92, "end": 1293.16, "text": " And so actually the stem of the inception network, that is the first few layers of the", "tokens": [400, 370, 767, 264, 12312, 295, 264, 49834, 3209, 11, 300, 307, 264, 700, 1326, 7914, 295, 264], "temperature": 0.0, "avg_logprob": -0.11321261981586078, "compression_ratio": 1.8738738738738738, "no_speech_prob": 1.4367467429110548e-06}, {"id": 258, "seek": 127124, "start": 1293.16, "end": 1300.08, "text": " inception network, actually also use this kind of seven-by-seven conv, because you start", "tokens": [49834, 3209, 11, 767, 611, 764, 341, 733, 295, 3407, 12, 2322, 12, 44476, 3754, 11, 570, 291, 722], "temperature": 0.0, "avg_logprob": -0.11321261981586078, "compression_ratio": 1.8738738738738738, "no_speech_prob": 1.4367467429110548e-06}, {"id": 259, "seek": 130008, "start": 1300.08, "end": 1308.8799999999999, "text": " out with this 224x224x3, and you want to turn it into something that's like 112x112x64.", "tokens": [484, 365, 341, 5853, 19, 87, 7490, 19, 87, 18, 11, 293, 291, 528, 281, 1261, 309, 666, 746, 300, 311, 411, 45835, 87, 16, 4762, 87, 19395, 13], "temperature": 0.0, "avg_logprob": -0.1338911166136292, "compression_ratio": 1.5277777777777777, "no_speech_prob": 1.6280473573715426e-06}, {"id": 260, "seek": 130008, "start": 1308.8799999999999, "end": 1314.1599999999999, "text": " And so by using a seven-by-seven conv, you can get a lot of information in each one of", "tokens": [400, 370, 538, 1228, 257, 3407, 12, 2322, 12, 44476, 3754, 11, 291, 393, 483, 257, 688, 295, 1589, 294, 1184, 472, 295], "temperature": 0.0, "avg_logprob": -0.1338911166136292, "compression_ratio": 1.5277777777777777, "no_speech_prob": 1.6280473573715426e-06}, {"id": 261, "seek": 130008, "start": 1314.1599999999999, "end": 1317.6, "text": " those outputs to get those 64 filters.", "tokens": [729, 23930, 281, 483, 729, 12145, 15995, 13], "temperature": 0.0, "avg_logprob": -0.1338911166136292, "compression_ratio": 1.5277777777777777, "no_speech_prob": 1.6280473573715426e-06}, {"id": 262, "seek": 130008, "start": 1317.6, "end": 1325.0, "text": " But the problem is that seven-by-seven conv is a lot of work.", "tokens": [583, 264, 1154, 307, 300, 3407, 12, 2322, 12, 44476, 3754, 307, 257, 688, 295, 589, 13], "temperature": 0.0, "avg_logprob": -0.1338911166136292, "compression_ratio": 1.5277777777777777, "no_speech_prob": 1.6280473573715426e-06}, {"id": 263, "seek": 132500, "start": 1325.0, "end": 1333.88, "text": " You've got 49 kernel values to multiply by 49 inputs for every input pixel across every", "tokens": [509, 600, 658, 16513, 28256, 4190, 281, 12972, 538, 16513, 15743, 337, 633, 4846, 19261, 2108, 633], "temperature": 0.0, "avg_logprob": -0.13656808081127347, "compression_ratio": 1.556701030927835, "no_speech_prob": 1.3081736369713326e-06}, {"id": 264, "seek": 132500, "start": 1333.88, "end": 1336.2, "text": " channel.", "tokens": [2269, 13], "temperature": 0.0, "avg_logprob": -0.13656808081127347, "compression_ratio": 1.556701030927835, "no_speech_prob": 1.3081736369713326e-06}, {"id": 265, "seek": 132500, "start": 1336.2, "end": 1339.52, "text": " So the compute is crazy.", "tokens": [407, 264, 14722, 307, 3219, 13], "temperature": 0.0, "avg_logprob": -0.13656808081127347, "compression_ratio": 1.556701030927835, "no_speech_prob": 1.3081736369713326e-06}, {"id": 266, "seek": 132500, "start": 1339.52, "end": 1343.92, "text": " You can kind of get away with it maybe for the very first layer, and in fact the very", "tokens": [509, 393, 733, 295, 483, 1314, 365, 309, 1310, 337, 264, 588, 700, 4583, 11, 293, 294, 1186, 264, 588], "temperature": 0.0, "avg_logprob": -0.13656808081127347, "compression_ratio": 1.556701030927835, "no_speech_prob": 1.3081736369713326e-06}, {"id": 267, "seek": 132500, "start": 1343.92, "end": 1351.42, "text": " first layer, the very first conv of ResNet is a seven-by-seven conv.", "tokens": [700, 4583, 11, 264, 588, 700, 3754, 295, 5015, 31890, 307, 257, 3407, 12, 2322, 12, 44476, 3754, 13], "temperature": 0.0, "avg_logprob": -0.13656808081127347, "compression_ratio": 1.556701030927835, "no_speech_prob": 1.3081736369713326e-06}, {"id": 268, "seek": 132500, "start": 1351.42, "end": 1353.36, "text": " But not so for inception.", "tokens": [583, 406, 370, 337, 49834, 13], "temperature": 0.0, "avg_logprob": -0.13656808081127347, "compression_ratio": 1.556701030927835, "no_speech_prob": 1.3081736369713326e-06}, {"id": 269, "seek": 135336, "start": 1353.36, "end": 1357.0, "text": " For inception they don't do a seven-by-seven conv.", "tokens": [1171, 49834, 436, 500, 380, 360, 257, 3407, 12, 2322, 12, 44476, 3754, 13], "temperature": 0.0, "avg_logprob": -0.1569863898413522, "compression_ratio": 1.8407079646017699, "no_speech_prob": 6.854265848232899e-06}, {"id": 270, "seek": 135336, "start": 1357.0, "end": 1362.52, "text": " Instead they do a one-by-seven followed by a seven-by-one.", "tokens": [7156, 436, 360, 257, 472, 12, 2322, 12, 44476, 6263, 538, 257, 3407, 12, 2322, 12, 546, 13], "temperature": 0.0, "avg_logprob": -0.1569863898413522, "compression_ratio": 1.8407079646017699, "no_speech_prob": 6.854265848232899e-06}, {"id": 271, "seek": 135336, "start": 1362.52, "end": 1369.52, "text": " And so to explain, the basic idea of the inception networks, all the different versions of it,", "tokens": [400, 370, 281, 2903, 11, 264, 3875, 1558, 295, 264, 49834, 9590, 11, 439, 264, 819, 9606, 295, 309, 11], "temperature": 0.0, "avg_logprob": -0.1569863898413522, "compression_ratio": 1.8407079646017699, "no_speech_prob": 6.854265848232899e-06}, {"id": 272, "seek": 135336, "start": 1369.52, "end": 1375.24, "text": " that you have a number of separate paths which have different convolution widths.", "tokens": [300, 291, 362, 257, 1230, 295, 4994, 14518, 597, 362, 819, 45216, 11402, 82, 13], "temperature": 0.0, "avg_logprob": -0.1569863898413522, "compression_ratio": 1.8407079646017699, "no_speech_prob": 6.854265848232899e-06}, {"id": 273, "seek": 135336, "start": 1375.24, "end": 1379.56, "text": " In this case, conceptually the idea is this is a one-by-one convolution width, and this", "tokens": [682, 341, 1389, 11, 3410, 671, 264, 1558, 307, 341, 307, 257, 472, 12, 2322, 12, 546, 45216, 11402, 11, 293, 341], "temperature": 0.0, "avg_logprob": -0.1569863898413522, "compression_ratio": 1.8407079646017699, "no_speech_prob": 6.854265848232899e-06}, {"id": 274, "seek": 135336, "start": 1379.56, "end": 1382.3999999999999, "text": " is going to be a seven convolution width.", "tokens": [307, 516, 281, 312, 257, 3407, 45216, 11402, 13], "temperature": 0.0, "avg_logprob": -0.1569863898413522, "compression_ratio": 1.8407079646017699, "no_speech_prob": 6.854265848232899e-06}, {"id": 275, "seek": 138240, "start": 1382.4, "end": 1389.8400000000001, "text": " And so they're looking at different amounts of data and then we combine them together.", "tokens": [400, 370, 436, 434, 1237, 412, 819, 11663, 295, 1412, 293, 550, 321, 10432, 552, 1214, 13], "temperature": 0.0, "avg_logprob": -0.09117942174275716, "compression_ratio": 1.5179487179487179, "no_speech_prob": 5.255350515653845e-06}, {"id": 276, "seek": 138240, "start": 1389.8400000000001, "end": 1396.0800000000002, "text": " But we don't want to have a seven-by-seven conv throughout the network because it's just", "tokens": [583, 321, 500, 380, 528, 281, 362, 257, 3407, 12, 2322, 12, 44476, 3754, 3710, 264, 3209, 570, 309, 311, 445], "temperature": 0.0, "avg_logprob": -0.09117942174275716, "compression_ratio": 1.5179487179487179, "no_speech_prob": 5.255350515653845e-06}, {"id": 277, "seek": 138240, "start": 1396.0800000000002, "end": 1399.48, "text": " too computationally expensive.", "tokens": [886, 24903, 379, 5124, 13], "temperature": 0.0, "avg_logprob": -0.09117942174275716, "compression_ratio": 1.5179487179487179, "no_speech_prob": 5.255350515653845e-06}, {"id": 278, "seek": 138240, "start": 1399.48, "end": 1408.96, "text": " But if you think about it, if we've got some input coming in, and we have some big filter", "tokens": [583, 498, 291, 519, 466, 309, 11, 498, 321, 600, 658, 512, 4846, 1348, 294, 11, 293, 321, 362, 512, 955, 6608], "temperature": 0.0, "avg_logprob": -0.09117942174275716, "compression_ratio": 1.5179487179487179, "no_speech_prob": 5.255350515653845e-06}, {"id": 279, "seek": 140896, "start": 1408.96, "end": 1413.64, "text": " that we want and it's too big to deal with, what could we do?", "tokens": [300, 321, 528, 293, 309, 311, 886, 955, 281, 2028, 365, 11, 437, 727, 321, 360, 30], "temperature": 0.0, "avg_logprob": -0.23256851104368648, "compression_ratio": 1.4658385093167703, "no_speech_prob": 9.368654900754336e-06}, {"id": 280, "seek": 140896, "start": 1413.64, "end": 1418.48, "text": " So let's say, let's just make it a little bit less boring, let's do 5x5.", "tokens": [407, 718, 311, 584, 11, 718, 311, 445, 652, 309, 257, 707, 857, 1570, 9989, 11, 718, 311, 360, 1025, 87, 20, 13], "temperature": 0.0, "avg_logprob": -0.23256851104368648, "compression_ratio": 1.4658385093167703, "no_speech_prob": 9.368654900754336e-06}, {"id": 281, "seek": 140896, "start": 1418.48, "end": 1433.4, "text": " What we can do is to create two filters, one which is 1x5, one which is 5x1, or 7, or whatever,", "tokens": [708, 321, 393, 360, 307, 281, 1884, 732, 15995, 11, 472, 597, 307, 502, 87, 20, 11, 472, 597, 307, 1025, 87, 16, 11, 420, 1614, 11, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.23256851104368648, "compression_ratio": 1.4658385093167703, "no_speech_prob": 9.368654900754336e-06}, {"id": 282, "seek": 140896, "start": 1433.4, "end": 1435.04, "text": " or 9.", "tokens": [420, 1722, 13], "temperature": 0.0, "avg_logprob": -0.23256851104368648, "compression_ratio": 1.4658385093167703, "no_speech_prob": 9.368654900754336e-06}, {"id": 283, "seek": 143504, "start": 1435.04, "end": 1443.24, "text": " So we take our activations to the previous layer and we put it through the 1x5, we take", "tokens": [407, 321, 747, 527, 2430, 763, 281, 264, 3894, 4583, 293, 321, 829, 309, 807, 264, 502, 87, 20, 11, 321, 747], "temperature": 0.0, "avg_logprob": -0.15593271816478055, "compression_ratio": 1.8424242424242425, "no_speech_prob": 3.041584704988054e-06}, {"id": 284, "seek": 143504, "start": 1443.24, "end": 1449.6, "text": " the activations out of that and put it through the 5x1, and something comes out the other", "tokens": [264, 2430, 763, 484, 295, 300, 293, 829, 309, 807, 264, 1025, 87, 16, 11, 293, 746, 1487, 484, 264, 661], "temperature": 0.0, "avg_logprob": -0.15593271816478055, "compression_ratio": 1.8424242424242425, "no_speech_prob": 3.041584704988054e-06}, {"id": 285, "seek": 143504, "start": 1449.6, "end": 1450.6, "text": " end.", "tokens": [917, 13], "temperature": 0.0, "avg_logprob": -0.15593271816478055, "compression_ratio": 1.8424242424242425, "no_speech_prob": 3.041584704988054e-06}, {"id": 286, "seek": 143504, "start": 1450.6, "end": 1452.52, "text": " Now what comes out the other end?", "tokens": [823, 437, 1487, 484, 264, 661, 917, 30], "temperature": 0.0, "avg_logprob": -0.15593271816478055, "compression_ratio": 1.8424242424242425, "no_speech_prob": 3.041584704988054e-06}, {"id": 287, "seek": 143504, "start": 1452.52, "end": 1458.7, "text": " Well rather than thinking of it as first of all we take the activations, then we put it", "tokens": [1042, 2831, 813, 1953, 295, 309, 382, 700, 295, 439, 321, 747, 264, 2430, 763, 11, 550, 321, 829, 309], "temperature": 0.0, "avg_logprob": -0.15593271816478055, "compression_ratio": 1.8424242424242425, "no_speech_prob": 3.041584704988054e-06}, {"id": 288, "seek": 145870, "start": 1458.7, "end": 1465.26, "text": " through the 5x1, then we put it through the 1x5, then the 5x1.", "tokens": [807, 264, 1025, 87, 16, 11, 550, 321, 829, 309, 807, 264, 502, 87, 20, 11, 550, 264, 1025, 87, 16, 13], "temperature": 0.0, "avg_logprob": -0.15112311341041743, "compression_ratio": 1.622754491017964, "no_speech_prob": 1.73304738382285e-06}, {"id": 289, "seek": 145870, "start": 1465.26, "end": 1475.8, "text": " What if instead we think of these two operations together and say, what does a 5x1.product", "tokens": [708, 498, 2602, 321, 519, 295, 613, 732, 7705, 1214, 293, 584, 11, 437, 775, 257, 1025, 87, 16, 13, 33244], "temperature": 0.0, "avg_logprob": -0.15112311341041743, "compression_ratio": 1.622754491017964, "no_speech_prob": 1.73304738382285e-06}, {"id": 290, "seek": 145870, "start": 1475.8, "end": 1480.8400000000001, "text": " and a 1x5.product do together?", "tokens": [293, 257, 502, 87, 20, 13, 33244, 360, 1214, 30], "temperature": 0.0, "avg_logprob": -0.15112311341041743, "compression_ratio": 1.622754491017964, "no_speech_prob": 1.73304738382285e-06}, {"id": 291, "seek": 145870, "start": 1480.8400000000001, "end": 1487.88, "text": " And effectively, you could take a 1x5 and a 5x1 and the outer product of that is going", "tokens": [400, 8659, 11, 291, 727, 747, 257, 502, 87, 20, 293, 257, 1025, 87, 16, 293, 264, 10847, 1674, 295, 300, 307, 516], "temperature": 0.0, "avg_logprob": -0.15112311341041743, "compression_ratio": 1.622754491017964, "no_speech_prob": 1.73304738382285e-06}, {"id": 292, "seek": 148788, "start": 1487.88, "end": 1496.44, "text": " to give you a 5x5.", "tokens": [281, 976, 291, 257, 1025, 87, 20, 13], "temperature": 0.0, "avg_logprob": -0.13881866828255032, "compression_ratio": 1.5763546798029557, "no_speech_prob": 2.058041445707204e-06}, {"id": 293, "seek": 148788, "start": 1496.44, "end": 1504.18, "text": " Now you can't create any possible 5x5 matrix by taking that product, but there's a lot", "tokens": [823, 291, 393, 380, 1884, 604, 1944, 1025, 87, 20, 8141, 538, 1940, 300, 1674, 11, 457, 456, 311, 257, 688], "temperature": 0.0, "avg_logprob": -0.13881866828255032, "compression_ratio": 1.5763546798029557, "no_speech_prob": 2.058041445707204e-06}, {"id": 294, "seek": 148788, "start": 1504.18, "end": 1507.64, "text": " of 5x5 matrices that you can create.", "tokens": [295, 1025, 87, 20, 32284, 300, 291, 393, 1884, 13], "temperature": 0.0, "avg_logprob": -0.13881866828255032, "compression_ratio": 1.5763546798029557, "no_speech_prob": 2.058041445707204e-06}, {"id": 295, "seek": 148788, "start": 1507.64, "end": 1512.2800000000002, "text": " And so the basic idea here is when you think about the order of operations, and I'm not", "tokens": [400, 370, 264, 3875, 1558, 510, 307, 562, 291, 519, 466, 264, 1668, 295, 7705, 11, 293, 286, 478, 406], "temperature": 0.0, "avg_logprob": -0.13881866828255032, "compression_ratio": 1.5763546798029557, "no_speech_prob": 2.058041445707204e-06}, {"id": 296, "seek": 148788, "start": 1512.2800000000002, "end": 1516.68, "text": " going to go into the detail of this, if you're interested in more of the theory here, you", "tokens": [516, 281, 352, 666, 264, 2607, 295, 341, 11, 498, 291, 434, 3102, 294, 544, 295, 264, 5261, 510, 11, 291], "temperature": 0.0, "avg_logprob": -0.13881866828255032, "compression_ratio": 1.5763546798029557, "no_speech_prob": 2.058041445707204e-06}, {"id": 297, "seek": 151668, "start": 1516.68, "end": 1521.64, "text": " should check out Rachel's numerical linear algebra course, which is basically a whole", "tokens": [820, 1520, 484, 14246, 311, 29054, 8213, 21989, 1164, 11, 597, 307, 1936, 257, 1379], "temperature": 0.0, "avg_logprob": -0.10636979883367365, "compression_ratio": 1.5829383886255923, "no_speech_prob": 7.411180376948323e-06}, {"id": 298, "seek": 151668, "start": 1521.64, "end": 1525.04, "text": " course about this stuff.", "tokens": [1164, 466, 341, 1507, 13], "temperature": 0.0, "avg_logprob": -0.10636979883367365, "compression_ratio": 1.5829383886255923, "no_speech_prob": 7.411180376948323e-06}, {"id": 299, "seek": 151668, "start": 1525.04, "end": 1533.16, "text": " But conceptually the idea is that very often the computation you want to do is actually", "tokens": [583, 3410, 671, 264, 1558, 307, 300, 588, 2049, 264, 24903, 291, 528, 281, 360, 307, 767], "temperature": 0.0, "avg_logprob": -0.10636979883367365, "compression_ratio": 1.5829383886255923, "no_speech_prob": 7.411180376948323e-06}, {"id": 300, "seek": 151668, "start": 1533.16, "end": 1539.3600000000001, "text": " more simple than an entire 5x5 convolution.", "tokens": [544, 2199, 813, 364, 2302, 1025, 87, 20, 45216, 13], "temperature": 0.0, "avg_logprob": -0.10636979883367365, "compression_ratio": 1.5829383886255923, "no_speech_prob": 7.411180376948323e-06}, {"id": 301, "seek": 151668, "start": 1539.3600000000001, "end": 1546.2, "text": " Very often the term we use in linear algebra is that there's some lower rank approximation.", "tokens": [4372, 2049, 264, 1433, 321, 764, 294, 8213, 21989, 307, 300, 456, 311, 512, 3126, 6181, 28023, 13], "temperature": 0.0, "avg_logprob": -0.10636979883367365, "compression_ratio": 1.5829383886255923, "no_speech_prob": 7.411180376948323e-06}, {"id": 302, "seek": 154620, "start": 1546.2, "end": 1553.4, "text": " In other words, the 1x5 and the 5x1 combined together, that 5x5 matrix is nearly as good", "tokens": [682, 661, 2283, 11, 264, 502, 87, 20, 293, 264, 1025, 87, 16, 9354, 1214, 11, 300, 1025, 87, 20, 8141, 307, 6217, 382, 665], "temperature": 0.0, "avg_logprob": -0.10093152863638742, "compression_ratio": 1.4883720930232558, "no_speech_prob": 7.183185061876429e-06}, {"id": 303, "seek": 154620, "start": 1553.4, "end": 1560.1200000000001, "text": " as the 5x5 matrix you really ideally would have computed if you were able to.", "tokens": [382, 264, 1025, 87, 20, 8141, 291, 534, 22915, 576, 362, 40610, 498, 291, 645, 1075, 281, 13], "temperature": 0.0, "avg_logprob": -0.10093152863638742, "compression_ratio": 1.4883720930232558, "no_speech_prob": 7.183185061876429e-06}, {"id": 304, "seek": 154620, "start": 1560.1200000000001, "end": 1567.8, "text": " And so this is very often the case in practice, just because the nature of the real world", "tokens": [400, 370, 341, 307, 588, 2049, 264, 1389, 294, 3124, 11, 445, 570, 264, 3687, 295, 264, 957, 1002], "temperature": 0.0, "avg_logprob": -0.10093152863638742, "compression_ratio": 1.4883720930232558, "no_speech_prob": 7.183185061876429e-06}, {"id": 305, "seek": 156780, "start": 1567.8, "end": 1577.44, "text": " is that the real world tends to have more structure than randomness.", "tokens": [307, 300, 264, 957, 1002, 12258, 281, 362, 544, 3877, 813, 4974, 1287, 13], "temperature": 0.0, "avg_logprob": -0.09801639829363142, "compression_ratio": 1.2936507936507937, "no_speech_prob": 3.138133024549461e-06}, {"id": 306, "seek": 156780, "start": 1577.44, "end": 1596.68, "text": " So the cool thing is, if we replace our 7x7 conv with a 1x7 and a 7x1, then this has basically", "tokens": [407, 264, 1627, 551, 307, 11, 498, 321, 7406, 527, 1614, 87, 22, 3754, 365, 257, 502, 87, 22, 293, 257, 1614, 87, 16, 11, 550, 341, 575, 1936], "temperature": 0.0, "avg_logprob": -0.09801639829363142, "compression_ratio": 1.2936507936507937, "no_speech_prob": 3.138133024549461e-06}, {"id": 307, "seek": 159668, "start": 1596.68, "end": 1605.04, "text": " for each cell it's got 14 by input channel by output channel dot products to do, whereas", "tokens": [337, 1184, 2815, 309, 311, 658, 3499, 538, 4846, 2269, 538, 5598, 2269, 5893, 3383, 281, 360, 11, 9735], "temperature": 0.0, "avg_logprob": -0.12223747654965049, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.952553793671541e-05}, {"id": 308, "seek": 159668, "start": 1605.04, "end": 1609.52, "text": " this one has 49 to do.", "tokens": [341, 472, 575, 16513, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.12223747654965049, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.952553793671541e-05}, {"id": 309, "seek": 159668, "start": 1609.52, "end": 1614.28, "text": " So it's just going to be a lot faster, and we have to hope that it's going to be nearly", "tokens": [407, 309, 311, 445, 516, 281, 312, 257, 688, 4663, 11, 293, 321, 362, 281, 1454, 300, 309, 311, 516, 281, 312, 6217], "temperature": 0.0, "avg_logprob": -0.12223747654965049, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.952553793671541e-05}, {"id": 310, "seek": 159668, "start": 1614.28, "end": 1615.28, "text": " as good.", "tokens": [382, 665, 13], "temperature": 0.0, "avg_logprob": -0.12223747654965049, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.952553793671541e-05}, {"id": 311, "seek": 159668, "start": 1615.28, "end": 1621.0800000000002, "text": " It's certainly capturing as much width of information by definition.", "tokens": [467, 311, 3297, 23384, 382, 709, 11402, 295, 1589, 538, 7123, 13], "temperature": 0.0, "avg_logprob": -0.12223747654965049, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.952553793671541e-05}, {"id": 312, "seek": 159668, "start": 1621.0800000000002, "end": 1624.1000000000001, "text": " So if you're interested in learning more about this specifically in the deep learning area,", "tokens": [407, 498, 291, 434, 3102, 294, 2539, 544, 466, 341, 4682, 294, 264, 2452, 2539, 1859, 11], "temperature": 0.0, "avg_logprob": -0.12223747654965049, "compression_ratio": 1.6327433628318584, "no_speech_prob": 1.952553793671541e-05}, {"id": 313, "seek": 162410, "start": 1624.1, "end": 1627.7199999999998, "text": " you can Google for factored convolutions.", "tokens": [291, 393, 3329, 337, 1186, 2769, 3754, 15892, 13], "temperature": 0.0, "avg_logprob": -0.17169791576909085, "compression_ratio": 1.5655737704918034, "no_speech_prob": 1.4970767551858444e-05}, {"id": 314, "seek": 162410, "start": 1627.7199999999998, "end": 1631.32, "text": " The idea was come up with 3 or 4 years ago now.", "tokens": [440, 1558, 390, 808, 493, 365, 805, 420, 1017, 924, 2057, 586, 13], "temperature": 0.0, "avg_logprob": -0.17169791576909085, "compression_ratio": 1.5655737704918034, "no_speech_prob": 1.4970767551858444e-05}, {"id": 315, "seek": 162410, "start": 1631.32, "end": 1635.1999999999998, "text": " It's probably been around for longer, but that was when I first saw it.", "tokens": [467, 311, 1391, 668, 926, 337, 2854, 11, 457, 300, 390, 562, 286, 700, 1866, 309, 13], "temperature": 0.0, "avg_logprob": -0.17169791576909085, "compression_ratio": 1.5655737704918034, "no_speech_prob": 1.4970767551858444e-05}, {"id": 316, "seek": 162410, "start": 1635.1999999999998, "end": 1642.7199999999998, "text": " And yeah, it turned out to work really well, and the inception network uses it quite widely.", "tokens": [400, 1338, 11, 309, 3574, 484, 281, 589, 534, 731, 11, 293, 264, 49834, 3209, 4960, 309, 1596, 13371, 13], "temperature": 0.0, "avg_logprob": -0.17169791576909085, "compression_ratio": 1.5655737704918034, "no_speech_prob": 1.4970767551858444e-05}, {"id": 317, "seek": 162410, "start": 1642.7199999999998, "end": 1647.1, "text": " They actually use it in their stem.", "tokens": [814, 767, 764, 309, 294, 641, 12312, 13], "temperature": 0.0, "avg_logprob": -0.17169791576909085, "compression_ratio": 1.5655737704918034, "no_speech_prob": 1.4970767551858444e-05}, {"id": 318, "seek": 162410, "start": 1647.1, "end": 1653.8999999999999, "text": " It's interesting actually, we've talked before about how we tend to kind of add on, we tend", "tokens": [467, 311, 1880, 767, 11, 321, 600, 2825, 949, 466, 577, 321, 3928, 281, 733, 295, 909, 322, 11, 321, 3928], "temperature": 0.0, "avg_logprob": -0.17169791576909085, "compression_ratio": 1.5655737704918034, "no_speech_prob": 1.4970767551858444e-05}, {"id": 319, "seek": 165390, "start": 1653.9, "end": 1659.44, "text": " to say there's this main backbone, like when we have ResNet 34 for example, we kind of", "tokens": [281, 584, 456, 311, 341, 2135, 34889, 11, 411, 562, 321, 362, 5015, 31890, 12790, 337, 1365, 11, 321, 733, 295], "temperature": 0.0, "avg_logprob": -0.23362099682843243, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.267798875749577e-06}, {"id": 320, "seek": 165390, "start": 1659.44, "end": 1663.96, "text": " say there's this main backbone which is all of the convolutions, and then we've talked", "tokens": [584, 456, 311, 341, 2135, 34889, 597, 307, 439, 295, 264, 3754, 15892, 11, 293, 550, 321, 600, 2825], "temperature": 0.0, "avg_logprob": -0.23362099682843243, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.267798875749577e-06}, {"id": 321, "seek": 165390, "start": 1663.96, "end": 1667.88, "text": " about how we can add on to it a custom head.", "tokens": [466, 577, 321, 393, 909, 322, 281, 309, 257, 2375, 1378, 13], "temperature": 0.0, "avg_logprob": -0.23362099682843243, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.267798875749577e-06}, {"id": 322, "seek": 165390, "start": 1667.88, "end": 1674.1200000000001, "text": " And that tends to be like a max pooling layer and a fully connected layer or something like", "tokens": [400, 300, 12258, 281, 312, 411, 257, 11469, 7005, 278, 4583, 293, 257, 4498, 4582, 4583, 420, 746, 411], "temperature": 0.0, "avg_logprob": -0.23362099682843243, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.267798875749577e-06}, {"id": 323, "seek": 165390, "start": 1674.1200000000001, "end": 1675.1200000000001, "text": " that.", "tokens": [300, 13], "temperature": 0.0, "avg_logprob": -0.23362099682843243, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.267798875749577e-06}, {"id": 324, "seek": 165390, "start": 1675.1200000000001, "end": 1680.64, "text": " You know, it's actually kind of better to talk about the backbone as containing two", "tokens": [509, 458, 11, 309, 311, 767, 733, 295, 1101, 281, 751, 466, 264, 34889, 382, 19273, 732], "temperature": 0.0, "avg_logprob": -0.23362099682843243, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.267798875749577e-06}, {"id": 325, "seek": 165390, "start": 1680.64, "end": 1681.64, "text": " pieces.", "tokens": [3755, 13], "temperature": 0.0, "avg_logprob": -0.23362099682843243, "compression_ratio": 1.6859504132231404, "no_speech_prob": 8.267798875749577e-06}, {"id": 326, "seek": 168164, "start": 1681.64, "end": 1691.1200000000001, "text": " One is the stem, and then the other is kind of the main backbone.", "tokens": [1485, 307, 264, 12312, 11, 293, 550, 264, 661, 307, 733, 295, 264, 2135, 34889, 13], "temperature": 0.0, "avg_logprob": -0.12534914345576845, "compression_ratio": 1.6183574879227054, "no_speech_prob": 2.9479995191650232e-06}, {"id": 327, "seek": 168164, "start": 1691.1200000000001, "end": 1697.3200000000002, "text": " And the reason is that the thing that's coming in, remember it's only got 3 channels, and", "tokens": [400, 264, 1778, 307, 300, 264, 551, 300, 311, 1348, 294, 11, 1604, 309, 311, 787, 658, 805, 9235, 11, 293], "temperature": 0.0, "avg_logprob": -0.12534914345576845, "compression_ratio": 1.6183574879227054, "no_speech_prob": 2.9479995191650232e-06}, {"id": 328, "seek": 168164, "start": 1697.3200000000002, "end": 1702.8400000000001, "text": " so we want some sequence of operations, it's going to expand that out into something richer,", "tokens": [370, 321, 528, 512, 8310, 295, 7705, 11, 309, 311, 516, 281, 5268, 300, 484, 666, 746, 29021, 11], "temperature": 0.0, "avg_logprob": -0.12534914345576845, "compression_ratio": 1.6183574879227054, "no_speech_prob": 2.9479995191650232e-06}, {"id": 329, "seek": 168164, "start": 1702.8400000000001, "end": 1704.96, "text": " generally something like 64 channels.", "tokens": [5101, 746, 411, 12145, 9235, 13], "temperature": 0.0, "avg_logprob": -0.12534914345576845, "compression_ratio": 1.6183574879227054, "no_speech_prob": 2.9479995191650232e-06}, {"id": 330, "seek": 168164, "start": 1704.96, "end": 1709.5200000000002, "text": " And so in ResNet, the stem is just super simple.", "tokens": [400, 370, 294, 5015, 31890, 11, 264, 12312, 307, 445, 1687, 2199, 13], "temperature": 0.0, "avg_logprob": -0.12534914345576845, "compression_ratio": 1.6183574879227054, "no_speech_prob": 2.9479995191650232e-06}, {"id": 331, "seek": 170952, "start": 1709.52, "end": 1716.96, "text": " It's a 7x7 conv, stride2 conv, followed by stride2 max pool.", "tokens": [467, 311, 257, 1614, 87, 22, 3754, 11, 1056, 482, 17, 3754, 11, 6263, 538, 1056, 482, 17, 11469, 7005, 13], "temperature": 0.0, "avg_logprob": -0.26536707560221356, "compression_ratio": 1.4011299435028248, "no_speech_prob": 3.0894741485099075e-06}, {"id": 332, "seek": 170952, "start": 1716.96, "end": 1720.04, "text": " I think that's it, if memory serves correctly.", "tokens": [286, 519, 300, 311, 309, 11, 498, 4675, 13451, 8944, 13], "temperature": 0.0, "avg_logprob": -0.26536707560221356, "compression_ratio": 1.4011299435028248, "no_speech_prob": 3.0894741485099075e-06}, {"id": 333, "seek": 170952, "start": 1720.04, "end": 1725.52, "text": " In inception, they have a much more complex stem with multiple paths getting combined,", "tokens": [682, 49834, 11, 436, 362, 257, 709, 544, 3997, 12312, 365, 3866, 14518, 1242, 9354, 11], "temperature": 0.0, "avg_logprob": -0.26536707560221356, "compression_ratio": 1.4011299435028248, "no_speech_prob": 3.0894741485099075e-06}, {"id": 334, "seek": 170952, "start": 1725.52, "end": 1731.32, "text": " concatenated, including factored cons of 1x7 and 7x1.", "tokens": [1588, 7186, 770, 11, 3009, 1186, 2769, 1014, 295, 502, 87, 22, 293, 1614, 87, 16, 13], "temperature": 0.0, "avg_logprob": -0.26536707560221356, "compression_ratio": 1.4011299435028248, "no_speech_prob": 3.0894741485099075e-06}, {"id": 335, "seek": 173132, "start": 1731.32, "end": 1740.9199999999998, "text": " And I'm kind of interested in what would happen if you stuck a standard ResNet on top of an", "tokens": [400, 286, 478, 733, 295, 3102, 294, 437, 576, 1051, 498, 291, 5541, 257, 3832, 5015, 31890, 322, 1192, 295, 364], "temperature": 0.0, "avg_logprob": -0.18106027490952437, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.7693922675098293e-06}, {"id": 336, "seek": 173132, "start": 1740.9199999999998, "end": 1743.9199999999998, "text": " inception stem, for instance.", "tokens": [49834, 12312, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.18106027490952437, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.7693922675098293e-06}, {"id": 337, "seek": 173132, "start": 1743.9199999999998, "end": 1748.56, "text": " I think that would be a really interesting thing to try.", "tokens": [286, 519, 300, 576, 312, 257, 534, 1880, 551, 281, 853, 13], "temperature": 0.0, "avg_logprob": -0.18106027490952437, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.7693922675098293e-06}, {"id": 338, "seek": 173132, "start": 1748.56, "end": 1753.3999999999999, "text": " An inception stem is quite a carefully engineered thing, and this thing of how do you take your", "tokens": [1107, 49834, 12312, 307, 1596, 257, 7500, 38648, 551, 11, 293, 341, 551, 295, 577, 360, 291, 747, 428], "temperature": 0.0, "avg_logprob": -0.18106027490952437, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.7693922675098293e-06}, {"id": 339, "seek": 173132, "start": 1753.3999999999999, "end": 1757.8799999999999, "text": " 3-channel input and turn it into something richer seems really important.", "tokens": [805, 12, 339, 11444, 4846, 293, 1261, 309, 666, 746, 29021, 2544, 534, 1021, 13], "temperature": 0.0, "avg_logprob": -0.18106027490952437, "compression_ratio": 1.6261682242990654, "no_speech_prob": 2.7693922675098293e-06}, {"id": 340, "seek": 175788, "start": 1757.88, "end": 1762.46, "text": " And all of that work seems to have got thrown away for ResNet.", "tokens": [400, 439, 295, 300, 589, 2544, 281, 362, 658, 11732, 1314, 337, 5015, 31890, 13], "temperature": 0.0, "avg_logprob": -0.18834777978750375, "compression_ratio": 1.5324675324675325, "no_speech_prob": 3.4465583667042665e-06}, {"id": 341, "seek": 175788, "start": 1762.46, "end": 1764.4, "text": " We like ResNet, it works really well.", "tokens": [492, 411, 5015, 31890, 11, 309, 1985, 534, 731, 13], "temperature": 0.0, "avg_logprob": -0.18834777978750375, "compression_ratio": 1.5324675324675325, "no_speech_prob": 3.4465583667042665e-06}, {"id": 342, "seek": 175788, "start": 1764.4, "end": 1771.3600000000001, "text": " But what if we put the dense net backbone on top of an inception stem?", "tokens": [583, 437, 498, 321, 829, 264, 18011, 2533, 34889, 322, 1192, 295, 364, 49834, 12312, 30], "temperature": 0.0, "avg_logprob": -0.18834777978750375, "compression_ratio": 1.5324675324675325, "no_speech_prob": 3.4465583667042665e-06}, {"id": 343, "seek": 175788, "start": 1771.3600000000001, "end": 1779.48, "text": " Or what if we replaced the 7x7 conv with a 1x7, 7x1 factored conv in a standard ResNet?", "tokens": [1610, 437, 498, 321, 10772, 264, 1614, 87, 22, 3754, 365, 257, 502, 87, 22, 11, 1614, 87, 16, 1186, 2769, 3754, 294, 257, 3832, 5015, 31890, 30], "temperature": 0.0, "avg_logprob": -0.18834777978750375, "compression_ratio": 1.5324675324675325, "no_speech_prob": 3.4465583667042665e-06}, {"id": 344, "seek": 175788, "start": 1779.48, "end": 1784.1200000000001, "text": " I don't know, there's lots of things we could try, and I think it would be really interesting.", "tokens": [286, 500, 380, 458, 11, 456, 311, 3195, 295, 721, 321, 727, 853, 11, 293, 286, 519, 309, 576, 312, 534, 1880, 13], "temperature": 0.0, "avg_logprob": -0.18834777978750375, "compression_ratio": 1.5324675324675325, "no_speech_prob": 3.4465583667042665e-06}, {"id": 345, "seek": 178412, "start": 1784.12, "end": 1793.1999999999998, "text": " So there's some more thoughts about potential research directions.", "tokens": [407, 456, 311, 512, 544, 4598, 466, 3995, 2132, 11095, 13], "temperature": 0.0, "avg_logprob": -0.20556974411010742, "compression_ratio": 1.411764705882353, "no_speech_prob": 7.183207344496623e-06}, {"id": 346, "seek": 178412, "start": 1793.1999999999998, "end": 1800.6399999999999, "text": " So that was kind of my little bunch of random stuff section.", "tokens": [407, 300, 390, 733, 295, 452, 707, 3840, 295, 4974, 1507, 3541, 13], "temperature": 0.0, "avg_logprob": -0.20556974411010742, "compression_ratio": 1.411764705882353, "no_speech_prob": 7.183207344496623e-06}, {"id": 347, "seek": 178412, "start": 1800.6399999999999, "end": 1811.9199999999998, "text": " Moving a little bit closer to the actual main topic of this, which is image enhancement.", "tokens": [14242, 257, 707, 857, 4966, 281, 264, 3539, 2135, 4829, 295, 341, 11, 597, 307, 3256, 40776, 13], "temperature": 0.0, "avg_logprob": -0.20556974411010742, "compression_ratio": 1.411764705882353, "no_speech_prob": 7.183207344496623e-06}, {"id": 348, "seek": 181192, "start": 1811.92, "end": 1817.96, "text": " I'm going to talk about a new paper briefly because it really connects what I just discussed", "tokens": [286, 478, 516, 281, 751, 466, 257, 777, 3035, 10515, 570, 309, 534, 16967, 437, 286, 445, 7152], "temperature": 0.0, "avg_logprob": -0.22071925076571378, "compression_ratio": 1.5246913580246915, "no_speech_prob": 2.885623871407006e-05}, {"id": 349, "seek": 181192, "start": 1817.96, "end": 1820.88, "text": " with what we're going to discuss next.", "tokens": [365, 437, 321, 434, 516, 281, 2248, 958, 13], "temperature": 0.0, "avg_logprob": -0.22071925076571378, "compression_ratio": 1.5246913580246915, "no_speech_prob": 2.885623871407006e-05}, {"id": 350, "seek": 181192, "start": 1820.88, "end": 1832.96, "text": " The new paper is a paper on progressive GANs which came from NVIDIA.", "tokens": [440, 777, 3035, 307, 257, 3035, 322, 16131, 460, 1770, 82, 597, 1361, 490, 426, 3958, 6914, 13], "temperature": 0.0, "avg_logprob": -0.22071925076571378, "compression_ratio": 1.5246913580246915, "no_speech_prob": 2.885623871407006e-05}, {"id": 351, "seek": 181192, "start": 1832.96, "end": 1837.48, "text": " And the progressive GANs paper is really neat.", "tokens": [400, 264, 16131, 460, 1770, 82, 3035, 307, 534, 10654, 13], "temperature": 0.0, "avg_logprob": -0.22071925076571378, "compression_ratio": 1.5246913580246915, "no_speech_prob": 2.885623871407006e-05}, {"id": 352, "seek": 183748, "start": 1837.48, "end": 1846.48, "text": " Question, 1x1 conv is usually called a network within a network in the literature.", "tokens": [14464, 11, 502, 87, 16, 3754, 307, 2673, 1219, 257, 3209, 1951, 257, 3209, 294, 264, 10394, 13], "temperature": 0.0, "avg_logprob": -0.2693100460505081, "compression_ratio": 1.4191176470588236, "no_speech_prob": 6.604675581911579e-05}, {"id": 353, "seek": 183748, "start": 1846.48, "end": 1848.6, "text": " What is the intuition of such a name?", "tokens": [708, 307, 264, 24002, 295, 1270, 257, 1315, 30], "temperature": 0.0, "avg_logprob": -0.2693100460505081, "compression_ratio": 1.4191176470588236, "no_speech_prob": 6.604675581911579e-05}, {"id": 354, "seek": 183748, "start": 1848.6, "end": 1855.4, "text": " No, network in network is more than just a 1x1 conv.", "tokens": [883, 11, 3209, 294, 3209, 307, 544, 813, 445, 257, 502, 87, 16, 3754, 13], "temperature": 0.0, "avg_logprob": -0.2693100460505081, "compression_ratio": 1.4191176470588236, "no_speech_prob": 6.604675581911579e-05}, {"id": 355, "seek": 183748, "start": 1855.4, "end": 1856.72, "text": " It's part of an IN.", "tokens": [467, 311, 644, 295, 364, 6892, 13], "temperature": 0.0, "avg_logprob": -0.2693100460505081, "compression_ratio": 1.4191176470588236, "no_speech_prob": 6.604675581911579e-05}, {"id": 356, "seek": 185672, "start": 1856.72, "end": 1872.16, "text": " I don't think there's any particular reason to look at that.", "tokens": [286, 500, 380, 519, 456, 311, 604, 1729, 1778, 281, 574, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.1620153718524509, "compression_ratio": 1.2416666666666667, "no_speech_prob": 2.9479724616976455e-06}, {"id": 357, "seek": 185672, "start": 1872.16, "end": 1881.3600000000001, "text": " So the progressive GAN basically takes this idea of gradually increasing the image size.", "tokens": [407, 264, 16131, 460, 1770, 1936, 2516, 341, 1558, 295, 13145, 5662, 264, 3256, 2744, 13], "temperature": 0.0, "avg_logprob": -0.1620153718524509, "compression_ratio": 1.2416666666666667, "no_speech_prob": 2.9479724616976455e-06}, {"id": 358, "seek": 188136, "start": 1881.36, "end": 1887.4799999999998, "text": " It's the only other direction I'm aware of where people have actually gradually increased", "tokens": [467, 311, 264, 787, 661, 3513, 286, 478, 3650, 295, 689, 561, 362, 767, 13145, 6505], "temperature": 0.0, "avg_logprob": -0.12862611770629884, "compression_ratio": 1.7619047619047619, "no_speech_prob": 6.144002782093594e-06}, {"id": 359, "seek": 188136, "start": 1887.4799999999998, "end": 1888.4799999999998, "text": " the image size.", "tokens": [264, 3256, 2744, 13], "temperature": 0.0, "avg_logprob": -0.12862611770629884, "compression_ratio": 1.7619047619047619, "no_speech_prob": 6.144002782093594e-06}, {"id": 360, "seek": 188136, "start": 1888.4799999999998, "end": 1893.12, "text": " It kind of surprises me because this paper is actually very popular and very well-known", "tokens": [467, 733, 295, 22655, 385, 570, 341, 3035, 307, 767, 588, 3743, 293, 588, 731, 12, 6861], "temperature": 0.0, "avg_logprob": -0.12862611770629884, "compression_ratio": 1.7619047619047619, "no_speech_prob": 6.144002782093594e-06}, {"id": 361, "seek": 188136, "start": 1893.12, "end": 1897.1599999999999, "text": " and very well-liked, and yet people haven't taken the basic idea of gradually increasing", "tokens": [293, 588, 731, 12, 13462, 292, 11, 293, 1939, 561, 2378, 380, 2726, 264, 3875, 1558, 295, 13145, 5662], "temperature": 0.0, "avg_logprob": -0.12862611770629884, "compression_ratio": 1.7619047619047619, "no_speech_prob": 6.144002782093594e-06}, {"id": 362, "seek": 188136, "start": 1897.1599999999999, "end": 1902.34, "text": " the image size and used it anywhere else, which shows you the general level of creativity", "tokens": [264, 3256, 2744, 293, 1143, 309, 4992, 1646, 11, 597, 3110, 291, 264, 2674, 1496, 295, 12915], "temperature": 0.0, "avg_logprob": -0.12862611770629884, "compression_ratio": 1.7619047619047619, "no_speech_prob": 6.144002782093594e-06}, {"id": 363, "seek": 188136, "start": 1902.34, "end": 1908.2199999999998, "text": " you can expect to find in the deep learning research community perhaps.", "tokens": [291, 393, 2066, 281, 915, 294, 264, 2452, 2539, 2132, 1768, 4317, 13], "temperature": 0.0, "avg_logprob": -0.12862611770629884, "compression_ratio": 1.7619047619047619, "no_speech_prob": 6.144002782093594e-06}, {"id": 364, "seek": 190822, "start": 1908.22, "end": 1917.96, "text": " So they start with a 4x4 GAN, like literally, they're trying to replicate 4x4 pixels, and", "tokens": [407, 436, 722, 365, 257, 1017, 87, 19, 460, 1770, 11, 411, 3736, 11, 436, 434, 1382, 281, 25356, 1017, 87, 19, 18668, 11, 293], "temperature": 0.0, "avg_logprob": -0.23410503989771791, "compression_ratio": 1.655367231638418, "no_speech_prob": 3.2698742870707065e-05}, {"id": 365, "seek": 190822, "start": 1917.96, "end": 1918.96, "text": " then 8x8 pixels.", "tokens": [550, 1649, 87, 23, 18668, 13], "temperature": 0.0, "avg_logprob": -0.23410503989771791, "compression_ratio": 1.655367231638418, "no_speech_prob": 3.2698742870707065e-05}, {"id": 366, "seek": 190822, "start": 1918.96, "end": 1921.1200000000001, "text": " So here's the 8x8 pixels.", "tokens": [407, 510, 311, 264, 1649, 87, 23, 18668, 13], "temperature": 0.0, "avg_logprob": -0.23410503989771791, "compression_ratio": 1.655367231638418, "no_speech_prob": 3.2698742870707065e-05}, {"id": 367, "seek": 190822, "start": 1921.1200000000001, "end": 1925.24, "text": " This is the Celeb A data set, so we're trying to recreate pictures of celebrities.", "tokens": [639, 307, 264, 8257, 28512, 316, 1412, 992, 11, 370, 321, 434, 1382, 281, 25833, 5242, 295, 23200, 13], "temperature": 0.0, "avg_logprob": -0.23410503989771791, "compression_ratio": 1.655367231638418, "no_speech_prob": 3.2698742870707065e-05}, {"id": 368, "seek": 190822, "start": 1925.24, "end": 1933.0, "text": " And then they go 16x16, and then 32, and then 64, and then 128, and then 256.", "tokens": [400, 550, 436, 352, 3165, 87, 6866, 11, 293, 550, 8858, 11, 293, 550, 12145, 11, 293, 550, 29810, 11, 293, 550, 38882, 13], "temperature": 0.0, "avg_logprob": -0.23410503989771791, "compression_ratio": 1.655367231638418, "no_speech_prob": 3.2698742870707065e-05}, {"id": 369, "seek": 193300, "start": 1933.0, "end": 1939.06, "text": " And one of the really nifty things they do is that as they increase size, they also add", "tokens": [400, 472, 295, 264, 534, 297, 37177, 721, 436, 360, 307, 300, 382, 436, 3488, 2744, 11, 436, 611, 909], "temperature": 0.0, "avg_logprob": -0.12183568187963183, "compression_ratio": 1.7396694214876034, "no_speech_prob": 6.540375125041464e-06}, {"id": 370, "seek": 193300, "start": 1939.06, "end": 1944.24, "text": " more layers to the network, which kind of makes sense, because if you're doing more", "tokens": [544, 7914, 281, 264, 3209, 11, 597, 733, 295, 1669, 2020, 11, 570, 498, 291, 434, 884, 544], "temperature": 0.0, "avg_logprob": -0.12183568187963183, "compression_ratio": 1.7396694214876034, "no_speech_prob": 6.540375125041464e-06}, {"id": 371, "seek": 193300, "start": 1944.24, "end": 1949.64, "text": " of a ResNet-y type thing, then you're spitting out something which hopefully makes sense", "tokens": [295, 257, 5015, 31890, 12, 88, 2010, 551, 11, 550, 291, 434, 637, 2414, 484, 746, 597, 4696, 1669, 2020], "temperature": 0.0, "avg_logprob": -0.12183568187963183, "compression_ratio": 1.7396694214876034, "no_speech_prob": 6.540375125041464e-06}, {"id": 372, "seek": 193300, "start": 1949.64, "end": 1954.6, "text": " at each grid cell size, and so you should be able to layer stuff on top.", "tokens": [412, 1184, 10748, 2815, 2744, 11, 293, 370, 291, 820, 312, 1075, 281, 4583, 1507, 322, 1192, 13], "temperature": 0.0, "avg_logprob": -0.12183568187963183, "compression_ratio": 1.7396694214876034, "no_speech_prob": 6.540375125041464e-06}, {"id": 373, "seek": 193300, "start": 1954.6, "end": 1961.04, "text": " And they do another nifty thing where they add a skip connection when they do that, and", "tokens": [400, 436, 360, 1071, 297, 37177, 551, 689, 436, 909, 257, 10023, 4984, 562, 436, 360, 300, 11, 293], "temperature": 0.0, "avg_logprob": -0.12183568187963183, "compression_ratio": 1.7396694214876034, "no_speech_prob": 6.540375125041464e-06}, {"id": 374, "seek": 196104, "start": 1961.04, "end": 1965.7, "text": " they gradually change a linear interpolation parameter that moves it more and more away", "tokens": [436, 13145, 1319, 257, 8213, 44902, 399, 13075, 300, 6067, 309, 544, 293, 544, 1314], "temperature": 0.0, "avg_logprob": -0.15643575273711105, "compression_ratio": 1.6818181818181819, "no_speech_prob": 2.190770146626164e-06}, {"id": 375, "seek": 196104, "start": 1965.7, "end": 1971.36, "text": " from the old 4x4 network and towards the new 8x8 network.", "tokens": [490, 264, 1331, 1017, 87, 19, 3209, 293, 3030, 264, 777, 1649, 87, 23, 3209, 13], "temperature": 0.0, "avg_logprob": -0.15643575273711105, "compression_ratio": 1.6818181818181819, "no_speech_prob": 2.190770146626164e-06}, {"id": 376, "seek": 196104, "start": 1971.36, "end": 1976.1599999999999, "text": " And then once they've totally moved it across, they throw away that extra connection.", "tokens": [400, 550, 1564, 436, 600, 3879, 4259, 309, 2108, 11, 436, 3507, 1314, 300, 2857, 4984, 13], "temperature": 0.0, "avg_logprob": -0.15643575273711105, "compression_ratio": 1.6818181818181819, "no_speech_prob": 2.190770146626164e-06}, {"id": 377, "seek": 196104, "start": 1976.1599999999999, "end": 1980.8799999999999, "text": " So the details don't matter too much, but it uses the basic ideas we've talked about", "tokens": [407, 264, 4365, 500, 380, 1871, 886, 709, 11, 457, 309, 4960, 264, 3875, 3487, 321, 600, 2825, 466], "temperature": 0.0, "avg_logprob": -0.15643575273711105, "compression_ratio": 1.6818181818181819, "no_speech_prob": 2.190770146626164e-06}, {"id": 378, "seek": 196104, "start": 1980.8799999999999, "end": 1985.1599999999999, "text": " gradually increasing the image size, kind of skip connections and stuff.", "tokens": [13145, 5662, 264, 3256, 2744, 11, 733, 295, 10023, 9271, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.15643575273711105, "compression_ratio": 1.6818181818181819, "no_speech_prob": 2.190770146626164e-06}, {"id": 379, "seek": 196104, "start": 1985.1599999999999, "end": 1990.84, "text": " But it's a great paper to study because A, it's like one of these rare things where they've", "tokens": [583, 309, 311, 257, 869, 3035, 281, 2979, 570, 316, 11, 309, 311, 411, 472, 295, 613, 5892, 721, 689, 436, 600], "temperature": 0.0, "avg_logprob": -0.15643575273711105, "compression_ratio": 1.6818181818181819, "no_speech_prob": 2.190770146626164e-06}, {"id": 380, "seek": 199084, "start": 1990.84, "end": 1995.32, "text": " like good engineers actually built something that just works in a really sensible way.", "tokens": [411, 665, 11955, 767, 3094, 746, 300, 445, 1985, 294, 257, 534, 25380, 636, 13], "temperature": 0.0, "avg_logprob": -0.1660759082207313, "compression_ratio": 1.6431372549019607, "no_speech_prob": 3.120154360658489e-05}, {"id": 381, "seek": 199084, "start": 1995.32, "end": 1998.72, "text": " And it's not surprising, this actually comes from NVIDIA themselves.", "tokens": [400, 309, 311, 406, 8830, 11, 341, 767, 1487, 490, 426, 3958, 6914, 2969, 13], "temperature": 0.0, "avg_logprob": -0.1660759082207313, "compression_ratio": 1.6431372549019607, "no_speech_prob": 3.120154360658489e-05}, {"id": 382, "seek": 199084, "start": 1998.72, "end": 2002.4399999999998, "text": " So NVIDIA don't do a lot of papers, but it's interesting that when they do, they build", "tokens": [407, 426, 3958, 6914, 500, 380, 360, 257, 688, 295, 10577, 11, 457, 309, 311, 1880, 300, 562, 436, 360, 11, 436, 1322], "temperature": 0.0, "avg_logprob": -0.1660759082207313, "compression_ratio": 1.6431372549019607, "no_speech_prob": 3.120154360658489e-05}, {"id": 383, "seek": 199084, "start": 2002.4399999999998, "end": 2006.1599999999999, "text": " something that's so thoroughly practical and sensible.", "tokens": [746, 300, 311, 370, 17987, 8496, 293, 25380, 13], "temperature": 0.0, "avg_logprob": -0.1660759082207313, "compression_ratio": 1.6431372549019607, "no_speech_prob": 3.120154360658489e-05}, {"id": 384, "seek": 199084, "start": 2006.1599999999999, "end": 2012.8799999999999, "text": " And so I think it's a great paper to study if you want to kind of put together lots of", "tokens": [400, 370, 286, 519, 309, 311, 257, 869, 3035, 281, 2979, 498, 291, 528, 281, 733, 295, 829, 1214, 3195, 295], "temperature": 0.0, "avg_logprob": -0.1660759082207313, "compression_ratio": 1.6431372549019607, "no_speech_prob": 3.120154360658489e-05}, {"id": 385, "seek": 199084, "start": 2012.8799999999999, "end": 2016.28, "text": " the different things we've learnt.", "tokens": [264, 819, 721, 321, 600, 18991, 13], "temperature": 0.0, "avg_logprob": -0.1660759082207313, "compression_ratio": 1.6431372549019607, "no_speech_prob": 3.120154360658489e-05}, {"id": 386, "seek": 201628, "start": 2016.28, "end": 2022.24, "text": " And there aren't many re-implementations of this, so like it's an interesting thing to", "tokens": [400, 456, 3212, 380, 867, 319, 12, 332, 43704, 763, 295, 341, 11, 370, 411, 309, 311, 364, 1880, 551, 281], "temperature": 0.0, "avg_logprob": -0.15889681035822087, "compression_ratio": 1.5943775100401607, "no_speech_prob": 1.1300448932161089e-05}, {"id": 387, "seek": 201628, "start": 2022.24, "end": 2026.04, "text": " project and maybe you could build on and find something else.", "tokens": [1716, 293, 1310, 291, 727, 1322, 322, 293, 915, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.15889681035822087, "compression_ratio": 1.5943775100401607, "no_speech_prob": 1.1300448932161089e-05}, {"id": 388, "seek": 201628, "start": 2026.04, "end": 2027.8799999999999, "text": " So here's what happens next.", "tokens": [407, 510, 311, 437, 2314, 958, 13], "temperature": 0.0, "avg_logprob": -0.15889681035822087, "compression_ratio": 1.5943775100401607, "no_speech_prob": 1.1300448932161089e-05}, {"id": 389, "seek": 201628, "start": 2027.8799999999999, "end": 2032.68, "text": " We eventually go up to 1024x1024, and you'll see that the images are not only getting higher", "tokens": [492, 4728, 352, 493, 281, 1266, 7911, 87, 3279, 7911, 11, 293, 291, 603, 536, 300, 264, 5267, 366, 406, 787, 1242, 2946], "temperature": 0.0, "avg_logprob": -0.15889681035822087, "compression_ratio": 1.5943775100401607, "no_speech_prob": 1.1300448932161089e-05}, {"id": 390, "seek": 201628, "start": 2032.68, "end": 2034.48, "text": " resolution but they're getting better.", "tokens": [8669, 457, 436, 434, 1242, 1101, 13], "temperature": 0.0, "avg_logprob": -0.15889681035822087, "compression_ratio": 1.5943775100401607, "no_speech_prob": 1.1300448932161089e-05}, {"id": 391, "seek": 201628, "start": 2034.48, "end": 2044.28, "text": " And so 1024x1024, I'm going to see if you can guess which one of the next page is fake.", "tokens": [400, 370, 1266, 7911, 87, 3279, 7911, 11, 286, 478, 516, 281, 536, 498, 291, 393, 2041, 597, 472, 295, 264, 958, 3028, 307, 7592, 13], "temperature": 0.0, "avg_logprob": -0.15889681035822087, "compression_ratio": 1.5943775100401607, "no_speech_prob": 1.1300448932161089e-05}, {"id": 392, "seek": 204428, "start": 2044.28, "end": 2048.96, "text": " They're all fake.", "tokens": [814, 434, 439, 7592, 13], "temperature": 0.0, "avg_logprob": -0.18396307528018951, "compression_ratio": 1.3432835820895523, "no_speech_prob": 7.183182788139675e-06}, {"id": 393, "seek": 204428, "start": 2048.96, "end": 2049.96, "text": " That's the next stage.", "tokens": [663, 311, 264, 958, 3233, 13], "temperature": 0.0, "avg_logprob": -0.18396307528018951, "compression_ratio": 1.3432835820895523, "no_speech_prob": 7.183182788139675e-06}, {"id": 394, "seek": 204428, "start": 2049.96, "end": 2056.64, "text": " You go up, up, up, up, up, up, and then boom.", "tokens": [509, 352, 493, 11, 493, 11, 493, 11, 493, 11, 493, 11, 493, 11, 293, 550, 9351, 13], "temperature": 0.0, "avg_logprob": -0.18396307528018951, "compression_ratio": 1.3432835820895523, "no_speech_prob": 7.183182788139675e-06}, {"id": 395, "seek": 204428, "start": 2056.64, "end": 2065.24, "text": " So like GANs and stuff are getting crazy, and some of you may have seen this during", "tokens": [407, 411, 460, 1770, 82, 293, 1507, 366, 1242, 3219, 11, 293, 512, 295, 291, 815, 362, 1612, 341, 1830], "temperature": 0.0, "avg_logprob": -0.18396307528018951, "compression_ratio": 1.3432835820895523, "no_speech_prob": 7.183182788139675e-06}, {"id": 396, "seek": 204428, "start": 2065.24, "end": 2072.84, "text": " the week.", "tokens": [264, 1243, 13], "temperature": 0.0, "avg_logprob": -0.18396307528018951, "compression_ratio": 1.3432835820895523, "no_speech_prob": 7.183182788139675e-06}, {"id": 397, "seek": 207284, "start": 2072.84, "end": 2102.8, "text": " So this video just came out and it's a speech by Barack Obama, and let's check it out.", "tokens": [407, 341, 960, 445, 1361, 484, 293, 309, 311, 257, 6218, 538, 31705, 9560, 11, 293, 718, 311, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.15002857721768892, "compression_ratio": 1.036144578313253, "no_speech_prob": 0.00010389270028099418}, {"id": 398, "seek": 210280, "start": 2102.8, "end": 2113.2400000000002, "text": " So as you can see, they've used this kind of technology to literally move Obama's face", "tokens": [407, 382, 291, 393, 536, 11, 436, 600, 1143, 341, 733, 295, 2899, 281, 3736, 1286, 9560, 311, 1851], "temperature": 0.0, "avg_logprob": -0.09458098873015373, "compression_ratio": 1.4076433121019107, "no_speech_prob": 3.5559216939873295e-06}, {"id": 399, "seek": 210280, "start": 2113.2400000000002, "end": 2117.86, "text": " in the way that Jordan Peele's face was moving.", "tokens": [294, 264, 636, 300, 10979, 430, 1653, 306, 311, 1851, 390, 2684, 13], "temperature": 0.0, "avg_logprob": -0.09458098873015373, "compression_ratio": 1.4076433121019107, "no_speech_prob": 3.5559216939873295e-06}, {"id": 400, "seek": 210280, "start": 2117.86, "end": 2124.5600000000004, "text": " You basically have all the techniques you need now to do that.", "tokens": [509, 1936, 362, 439, 264, 7512, 291, 643, 586, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.09458098873015373, "compression_ratio": 1.4076433121019107, "no_speech_prob": 3.5559216939873295e-06}, {"id": 401, "seek": 210280, "start": 2124.5600000000004, "end": 2131.8, "text": " So is that a good idea?", "tokens": [407, 307, 300, 257, 665, 1558, 30], "temperature": 0.0, "avg_logprob": -0.09458098873015373, "compression_ratio": 1.4076433121019107, "no_speech_prob": 3.5559216939873295e-06}, {"id": 402, "seek": 213180, "start": 2131.8, "end": 2137.2400000000002, "text": " So this is the bit where we talk about what's most important, which is like, now that we", "tokens": [407, 341, 307, 264, 857, 689, 321, 751, 466, 437, 311, 881, 1021, 11, 597, 307, 411, 11, 586, 300, 321], "temperature": 0.0, "avg_logprob": -0.1648554801940918, "compression_ratio": 1.3670886075949367, "no_speech_prob": 1.1842958883789834e-05}, {"id": 403, "seek": 213180, "start": 2137.2400000000002, "end": 2149.48, "text": " can do all this stuff, what should we be doing, and how do we think about that?", "tokens": [393, 360, 439, 341, 1507, 11, 437, 820, 321, 312, 884, 11, 293, 577, 360, 321, 519, 466, 300, 30], "temperature": 0.0, "avg_logprob": -0.1648554801940918, "compression_ratio": 1.3670886075949367, "no_speech_prob": 1.1842958883789834e-05}, {"id": 404, "seek": 213180, "start": 2149.48, "end": 2155.7200000000003, "text": " And the TLDR version is, I actually don't know.", "tokens": [400, 264, 40277, 9301, 3037, 307, 11, 286, 767, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.1648554801940918, "compression_ratio": 1.3670886075949367, "no_speech_prob": 1.1842958883789834e-05}, {"id": 405, "seek": 215572, "start": 2155.72, "end": 2162.3399999999997, "text": " Maybe a lot of you saw the founders of the Spacey Prodigy folks, founders of Explosion", "tokens": [2704, 257, 688, 295, 291, 1866, 264, 25608, 295, 264, 8705, 88, 1705, 25259, 88, 4024, 11, 25608, 295, 12514, 19996], "temperature": 0.0, "avg_logprob": -0.28260125340642156, "compression_ratio": 1.495, "no_speech_prob": 5.771822543465532e-06}, {"id": 406, "seek": 215572, "start": 2162.3399999999997, "end": 2165.08, "text": " AI, did a talk, and Matthew and Ines.", "tokens": [7318, 11, 630, 257, 751, 11, 293, 12434, 293, 682, 279, 13], "temperature": 0.0, "avg_logprob": -0.28260125340642156, "compression_ratio": 1.495, "no_speech_prob": 5.771822543465532e-06}, {"id": 407, "seek": 215572, "start": 2165.08, "end": 2170.6, "text": " I went to dinner with them afterwards and we basically spent the entire evening talking,", "tokens": [286, 1437, 281, 6148, 365, 552, 10543, 293, 321, 1936, 4418, 264, 2302, 5634, 1417, 11], "temperature": 0.0, "avg_logprob": -0.28260125340642156, "compression_ratio": 1.495, "no_speech_prob": 5.771822543465532e-06}, {"id": 408, "seek": 215572, "start": 2170.6, "end": 2178.8799999999997, "text": " debating, arguing about what does it mean that companies like ours are building tools", "tokens": [40647, 11, 19697, 466, 437, 775, 309, 914, 300, 3431, 411, 11896, 366, 2390, 3873], "temperature": 0.0, "avg_logprob": -0.28260125340642156, "compression_ratio": 1.495, "no_speech_prob": 5.771822543465532e-06}, {"id": 409, "seek": 217888, "start": 2178.88, "end": 2186.52, "text": " that are democratizing access to tools that can be used in harmful ways.", "tokens": [300, 366, 37221, 3319, 2105, 281, 3873, 300, 393, 312, 1143, 294, 19727, 2098, 13], "temperature": 0.0, "avg_logprob": -0.14701074964544747, "compression_ratio": 1.6043478260869566, "no_speech_prob": 9.368613063998055e-06}, {"id": 410, "seek": 217888, "start": 2186.52, "end": 2190.8, "text": " And they're incredibly thoughtful people.", "tokens": [400, 436, 434, 6252, 21566, 561, 13], "temperature": 0.0, "avg_logprob": -0.14701074964544747, "compression_ratio": 1.6043478260869566, "no_speech_prob": 9.368613063998055e-06}, {"id": 411, "seek": 217888, "start": 2190.8, "end": 2195.6800000000003, "text": " I wouldn't say we didn't agree, we just couldn't come to a conclusion ourselves.", "tokens": [286, 2759, 380, 584, 321, 994, 380, 3986, 11, 321, 445, 2809, 380, 808, 281, 257, 10063, 4175, 13], "temperature": 0.0, "avg_logprob": -0.14701074964544747, "compression_ratio": 1.6043478260869566, "no_speech_prob": 9.368613063998055e-06}, {"id": 412, "seek": 217888, "start": 2195.6800000000003, "end": 2202.6, "text": " So I'm just going to lay out some of the questions and point to some of the research.", "tokens": [407, 286, 478, 445, 516, 281, 2360, 484, 512, 295, 264, 1651, 293, 935, 281, 512, 295, 264, 2132, 13], "temperature": 0.0, "avg_logprob": -0.14701074964544747, "compression_ratio": 1.6043478260869566, "no_speech_prob": 9.368613063998055e-06}, {"id": 413, "seek": 217888, "start": 2202.6, "end": 2207.32, "text": " And when I say research, most of the actual literature review and putting this together", "tokens": [400, 562, 286, 584, 2132, 11, 881, 295, 264, 3539, 10394, 3131, 293, 3372, 341, 1214], "temperature": 0.0, "avg_logprob": -0.14701074964544747, "compression_ratio": 1.6043478260869566, "no_speech_prob": 9.368613063998055e-06}, {"id": 414, "seek": 220732, "start": 2207.32, "end": 2213.0, "text": " was done by Rachel.", "tokens": [390, 1096, 538, 14246, 13], "temperature": 0.0, "avg_logprob": -0.1271297529146269, "compression_ratio": 1.7965116279069768, "no_speech_prob": 5.093644631415373e-06}, {"id": 415, "seek": 220732, "start": 2213.0, "end": 2221.6000000000004, "text": " Let me start by saying the models we build are often pretty shitty in ways which are", "tokens": [961, 385, 722, 538, 1566, 264, 5245, 321, 1322, 366, 2049, 1238, 30748, 294, 2098, 597, 366], "temperature": 0.0, "avg_logprob": -0.1271297529146269, "compression_ratio": 1.7965116279069768, "no_speech_prob": 5.093644631415373e-06}, {"id": 416, "seek": 220732, "start": 2221.6000000000004, "end": 2224.32, "text": " not immediately apparent.", "tokens": [406, 4258, 18335, 13], "temperature": 0.0, "avg_logprob": -0.1271297529146269, "compression_ratio": 1.7965116279069768, "no_speech_prob": 5.093644631415373e-06}, {"id": 417, "seek": 220732, "start": 2224.32, "end": 2229.28, "text": " And you won't know how shitty they are unless the people that are building them with you", "tokens": [400, 291, 1582, 380, 458, 577, 30748, 436, 366, 5969, 264, 561, 300, 366, 2390, 552, 365, 291], "temperature": 0.0, "avg_logprob": -0.1271297529146269, "compression_ratio": 1.7965116279069768, "no_speech_prob": 5.093644631415373e-06}, {"id": 418, "seek": 220732, "start": 2229.28, "end": 2234.1400000000003, "text": " are a range of people, and the people that are using them with you are a range of people.", "tokens": [366, 257, 3613, 295, 561, 11, 293, 264, 561, 300, 366, 1228, 552, 365, 291, 366, 257, 3613, 295, 561, 13], "temperature": 0.0, "avg_logprob": -0.1271297529146269, "compression_ratio": 1.7965116279069768, "no_speech_prob": 5.093644631415373e-06}, {"id": 419, "seek": 223414, "start": 2234.14, "end": 2253.9, "text": " So for example, a couple of wonderful researchers, Joy and Timnit did this really interesting", "tokens": [407, 337, 1365, 11, 257, 1916, 295, 3715, 10309, 11, 15571, 293, 7172, 77, 270, 630, 341, 534, 1880], "temperature": 0.0, "avg_logprob": -0.22515674070878464, "compression_ratio": 1.3430656934306568, "no_speech_prob": 1.1300615369691513e-05}, {"id": 420, "seek": 223414, "start": 2253.9, "end": 2259.2799999999997, "text": " research where they looked at some basically off-the-shelf face recognizers, one from Face", "tokens": [2132, 689, 436, 2956, 412, 512, 1936, 766, 12, 3322, 12, 46626, 1851, 3068, 22525, 11, 472, 490, 4047], "temperature": 0.0, "avg_logprob": -0.22515674070878464, "compression_ratio": 1.3430656934306568, "no_speech_prob": 1.1300615369691513e-05}, {"id": 421, "seek": 225928, "start": 2259.28, "end": 2265.44, "text": " Plus Plus, which is a huge Chinese company, IBMs and Microsofts, and they looked for a", "tokens": [7721, 7721, 11, 597, 307, 257, 2603, 4649, 2237, 11, 23487, 82, 293, 8116, 82, 11, 293, 436, 2956, 337, 257], "temperature": 0.0, "avg_logprob": -0.1887370256277231, "compression_ratio": 1.4814814814814814, "no_speech_prob": 9.516139471088536e-06}, {"id": 422, "seek": 225928, "start": 2265.44, "end": 2268.96, "text": " range of different face types.", "tokens": [3613, 295, 819, 1851, 3467, 13], "temperature": 0.0, "avg_logprob": -0.1887370256277231, "compression_ratio": 1.4814814814814814, "no_speech_prob": 9.516139471088536e-06}, {"id": 423, "seek": 225928, "start": 2268.96, "end": 2273.6800000000003, "text": " And generally speaking, the Microsoft one in particular was incredibly accurate, unless", "tokens": [400, 5101, 4124, 11, 264, 8116, 472, 294, 1729, 390, 6252, 8559, 11, 5969], "temperature": 0.0, "avg_logprob": -0.1887370256277231, "compression_ratio": 1.4814814814814814, "no_speech_prob": 9.516139471088536e-06}, {"id": 424, "seek": 225928, "start": 2273.6800000000003, "end": 2282.6000000000004, "text": " the face type happened to be dark skinned when suddenly it went 25 times worse, got", "tokens": [264, 1851, 2010, 2011, 281, 312, 2877, 3178, 9232, 562, 5800, 309, 1437, 3552, 1413, 5324, 11, 658], "temperature": 0.0, "avg_logprob": -0.1887370256277231, "compression_ratio": 1.4814814814814814, "no_speech_prob": 9.516139471088536e-06}, {"id": 425, "seek": 225928, "start": 2282.6000000000004, "end": 2285.8, "text": " it wrong nearly half the time.", "tokens": [309, 2085, 6217, 1922, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.1887370256277231, "compression_ratio": 1.4814814814814814, "no_speech_prob": 9.516139471088536e-06}, {"id": 426, "seek": 228580, "start": 2285.8, "end": 2296.1200000000003, "text": " And for a big company like this to release a product that for a very very large percentage", "tokens": [400, 337, 257, 955, 2237, 411, 341, 281, 4374, 257, 1674, 300, 337, 257, 588, 588, 2416, 9668], "temperature": 0.0, "avg_logprob": -0.13297815811939728, "compression_ratio": 1.674757281553398, "no_speech_prob": 1.4510274013446178e-05}, {"id": 427, "seek": 228580, "start": 2296.1200000000003, "end": 2302.5600000000004, "text": " of the world basically doesn't work is more than a technical failure.", "tokens": [295, 264, 1002, 1936, 1177, 380, 589, 307, 544, 813, 257, 6191, 7763, 13], "temperature": 0.0, "avg_logprob": -0.13297815811939728, "compression_ratio": 1.674757281553398, "no_speech_prob": 1.4510274013446178e-05}, {"id": 428, "seek": 228580, "start": 2302.5600000000004, "end": 2309.1800000000003, "text": " It's a really deep failure of understanding what kind of team needs to be used to create", "tokens": [467, 311, 257, 534, 2452, 7763, 295, 3701, 437, 733, 295, 1469, 2203, 281, 312, 1143, 281, 1884], "temperature": 0.0, "avg_logprob": -0.13297815811939728, "compression_ratio": 1.674757281553398, "no_speech_prob": 1.4510274013446178e-05}, {"id": 429, "seek": 228580, "start": 2309.1800000000003, "end": 2314.7200000000003, "text": " such a technology and to test such a technology, or even an understanding of who your customers", "tokens": [1270, 257, 2899, 293, 281, 1500, 1270, 257, 2899, 11, 420, 754, 364, 3701, 295, 567, 428, 4581], "temperature": 0.0, "avg_logprob": -0.13297815811939728, "compression_ratio": 1.674757281553398, "no_speech_prob": 1.4510274013446178e-05}, {"id": 430, "seek": 231472, "start": 2314.72, "end": 2315.72, "text": " are.", "tokens": [366, 13], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 431, "seek": 231472, "start": 2315.72, "end": 2318.16, "text": " Yes, some of your customers have dark skin.", "tokens": [1079, 11, 512, 295, 428, 4581, 362, 2877, 3178, 13], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 432, "seek": 231472, "start": 2318.16, "end": 2319.16, "text": " Yes, Rachel.", "tokens": [1079, 11, 14246, 13], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 433, "seek": 231472, "start": 2319.16, "end": 2325.9599999999996, "text": " I was also going to add that the classifiers all did worse on women than on men.", "tokens": [286, 390, 611, 516, 281, 909, 300, 264, 1508, 23463, 439, 630, 5324, 322, 2266, 813, 322, 1706, 13], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 434, "seek": 231472, "start": 2325.9599999999996, "end": 2326.9599999999996, "text": " Shocking.", "tokens": [1160, 31730, 13], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 435, "seek": 231472, "start": 2326.9599999999996, "end": 2334.48, "text": " Yeah, it's funny, actually Rachel tweeted about something like this the other day, and", "tokens": [865, 11, 309, 311, 4074, 11, 767, 14246, 25646, 466, 746, 411, 341, 264, 661, 786, 11, 293], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 436, "seek": 231472, "start": 2334.48, "end": 2337.48, "text": " some guy was like, what's this all about?", "tokens": [512, 2146, 390, 411, 11, 437, 311, 341, 439, 466, 30], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 437, "seek": 231472, "start": 2337.48, "end": 2339.04, "text": " What are you saying?", "tokens": [708, 366, 291, 1566, 30], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 438, "seek": 231472, "start": 2339.04, "end": 2343.68, "text": " Don't you know about people made cars for a long time?", "tokens": [1468, 380, 291, 458, 466, 561, 1027, 5163, 337, 257, 938, 565, 30], "temperature": 0.0, "avg_logprob": -0.331828853062221, "compression_ratio": 1.5521739130434782, "no_speech_prob": 2.1444633603096008e-05}, {"id": 439, "seek": 234368, "start": 2343.68, "end": 2345.7999999999997, "text": " Are you saying you might need women to make cars too?", "tokens": [2014, 291, 1566, 291, 1062, 643, 2266, 281, 652, 5163, 886, 30], "temperature": 0.0, "avg_logprob": -0.20294808780445772, "compression_ratio": 1.645933014354067, "no_speech_prob": 1.8631233615451492e-05}, {"id": 440, "seek": 234368, "start": 2345.7999999999997, "end": 2352.96, "text": " And Rachel pointed out, well actually yes, for most of the history of car safety, women", "tokens": [400, 14246, 10932, 484, 11, 731, 767, 2086, 11, 337, 881, 295, 264, 2503, 295, 1032, 4514, 11, 2266], "temperature": 0.0, "avg_logprob": -0.20294808780445772, "compression_ratio": 1.645933014354067, "no_speech_prob": 1.8631233615451492e-05}, {"id": 441, "seek": 234368, "start": 2352.96, "end": 2359.96, "text": " in cars have been far far more at risk of death than men in cars, because the men created", "tokens": [294, 5163, 362, 668, 1400, 1400, 544, 412, 3148, 295, 2966, 813, 1706, 294, 5163, 11, 570, 264, 1706, 2942], "temperature": 0.0, "avg_logprob": -0.20294808780445772, "compression_ratio": 1.645933014354067, "no_speech_prob": 1.8631233615451492e-05}, {"id": 442, "seek": 234368, "start": 2359.96, "end": 2364.16, "text": " male looking feeling sized crash test dummies.", "tokens": [7133, 1237, 2633, 20004, 8252, 1500, 16784, 38374, 13], "temperature": 0.0, "avg_logprob": -0.20294808780445772, "compression_ratio": 1.645933014354067, "no_speech_prob": 1.8631233615451492e-05}, {"id": 443, "seek": 234368, "start": 2364.16, "end": 2368.58, "text": " And so car safety was literally not tested on women sized bodies.", "tokens": [400, 370, 1032, 4514, 390, 3736, 406, 8246, 322, 2266, 20004, 7510, 13], "temperature": 0.0, "avg_logprob": -0.20294808780445772, "compression_ratio": 1.645933014354067, "no_speech_prob": 1.8631233615451492e-05}, {"id": 444, "seek": 236858, "start": 2368.58, "end": 2374.3199999999997, "text": " So the fact, shitty product management with a total failure of diversity and understanding", "tokens": [407, 264, 1186, 11, 30748, 1674, 4592, 365, 257, 3217, 7763, 295, 8811, 293, 3701], "temperature": 0.0, "avg_logprob": -0.26852831709275554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.5206555872282479e-05}, {"id": 445, "seek": 236858, "start": 2374.3199999999997, "end": 2376.6, "text": " is not new to our field.", "tokens": [307, 406, 777, 281, 527, 2519, 13], "temperature": 0.0, "avg_logprob": -0.26852831709275554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.5206555872282479e-05}, {"id": 446, "seek": 236858, "start": 2376.6, "end": 2383.72, "text": " I was just going to say that was comparing impacts of similar strength, men and women.", "tokens": [286, 390, 445, 516, 281, 584, 300, 390, 15763, 11606, 295, 2531, 3800, 11, 1706, 293, 2266, 13], "temperature": 0.0, "avg_logprob": -0.26852831709275554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.5206555872282479e-05}, {"id": 447, "seek": 236858, "start": 2383.72, "end": 2385.44, "text": " Yeah, I don't know why.", "tokens": [865, 11, 286, 500, 380, 458, 983, 13], "temperature": 0.0, "avg_logprob": -0.26852831709275554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.5206555872282479e-05}, {"id": 448, "seek": 236858, "start": 2385.44, "end": 2389.0, "text": " Whenever you say something like this on Twitter, Rachel has to say this, because anytime you", "tokens": [14159, 291, 584, 746, 411, 341, 322, 5794, 11, 14246, 575, 281, 584, 341, 11, 570, 13038, 291], "temperature": 0.0, "avg_logprob": -0.26852831709275554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.5206555872282479e-05}, {"id": 449, "seek": 236858, "start": 2389.0, "end": 2392.08, "text": " say something like this on Twitter, there's like 10 people who will be like, oh you have", "tokens": [584, 746, 411, 341, 322, 5794, 11, 456, 311, 411, 1266, 561, 567, 486, 312, 411, 11, 1954, 291, 362], "temperature": 0.0, "avg_logprob": -0.26852831709275554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.5206555872282479e-05}, {"id": 450, "seek": 236858, "start": 2392.08, "end": 2393.84, "text": " to compare all these other things.", "tokens": [281, 6794, 439, 613, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.26852831709275554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 1.5206555872282479e-05}, {"id": 451, "seek": 239384, "start": 2393.84, "end": 2398.84, "text": " We didn't know that.", "tokens": [492, 994, 380, 458, 300, 13], "temperature": 0.0, "avg_logprob": -0.28097853789458405, "compression_ratio": 1.4848484848484849, "no_speech_prob": 2.0462066459003836e-05}, {"id": 452, "seek": 239384, "start": 2398.84, "end": 2407.56, "text": " I mean, other things our very best, most famous systems do like Microsoft's face recognizer", "tokens": [286, 914, 11, 661, 721, 527, 588, 1151, 11, 881, 4618, 3652, 360, 411, 8116, 311, 1851, 3068, 6545], "temperature": 0.0, "avg_logprob": -0.28097853789458405, "compression_ratio": 1.4848484848484849, "no_speech_prob": 2.0462066459003836e-05}, {"id": 453, "seek": 239384, "start": 2407.56, "end": 2413.94, "text": " or Google's language translator, you turn she is a doctor, he is a nurse into Turkish", "tokens": [420, 3329, 311, 2856, 35223, 11, 291, 1261, 750, 307, 257, 4631, 11, 415, 307, 257, 14012, 666, 18565], "temperature": 0.0, "avg_logprob": -0.28097853789458405, "compression_ratio": 1.4848484848484849, "no_speech_prob": 2.0462066459003836e-05}, {"id": 454, "seek": 239384, "start": 2413.94, "end": 2419.08, "text": " and quite correctly both the pronouns become oh, because there's no gender pronouns in", "tokens": [293, 1596, 8944, 1293, 264, 35883, 1813, 1954, 11, 570, 456, 311, 572, 7898, 35883, 294], "temperature": 0.0, "avg_logprob": -0.28097853789458405, "compression_ratio": 1.4848484848484849, "no_speech_prob": 2.0462066459003836e-05}, {"id": 455, "seek": 239384, "start": 2419.08, "end": 2420.36, "text": " Turkish.", "tokens": [18565, 13], "temperature": 0.0, "avg_logprob": -0.28097853789458405, "compression_ratio": 1.4848484848484849, "no_speech_prob": 2.0462066459003836e-05}, {"id": 456, "seek": 242036, "start": 2420.36, "end": 2425.04, "text": " So go the other direction, I'll be a doctor, I don't know how to say that, the equivalent", "tokens": [407, 352, 264, 661, 3513, 11, 286, 603, 312, 257, 4631, 11, 286, 500, 380, 458, 577, 281, 584, 300, 11, 264, 10344], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 457, "seek": 242036, "start": 2425.04, "end": 2428.1200000000003, "text": " for Turkish nurse.", "tokens": [337, 18565, 14012, 13], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 458, "seek": 242036, "start": 2428.1200000000003, "end": 2429.6800000000003, "text": " And what does it get turned into?", "tokens": [400, 437, 775, 309, 483, 3574, 666, 30], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 459, "seek": 242036, "start": 2429.6800000000003, "end": 2432.2000000000003, "text": " He is a doctor, she is a nurse.", "tokens": [634, 307, 257, 4631, 11, 750, 307, 257, 14012, 13], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 460, "seek": 242036, "start": 2432.2000000000003, "end": 2437.1200000000003, "text": " So like we've got these kind of like biases built into tools that we're all using every", "tokens": [407, 411, 321, 600, 658, 613, 733, 295, 411, 32152, 3094, 666, 3873, 300, 321, 434, 439, 1228, 633], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 461, "seek": 242036, "start": 2437.1200000000003, "end": 2438.1200000000003, "text": " day.", "tokens": [786, 13], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 462, "seek": 242036, "start": 2438.1200000000003, "end": 2441.88, "text": " And again, people are like, oh, it's just showing us what's in the world.", "tokens": [400, 797, 11, 561, 366, 411, 11, 1954, 11, 309, 311, 445, 4099, 505, 437, 311, 294, 264, 1002, 13], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 463, "seek": 242036, "start": 2441.88, "end": 2445.32, "text": " And well, okay, there's lots of problems with that basic assertion.", "tokens": [400, 731, 11, 1392, 11, 456, 311, 3195, 295, 2740, 365, 300, 3875, 19810, 313, 13], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 464, "seek": 242036, "start": 2445.32, "end": 2450.1600000000003, "text": " But as you know, machine learning algorithms love to generalize.", "tokens": [583, 382, 291, 458, 11, 3479, 2539, 14642, 959, 281, 2674, 1125, 13], "temperature": 0.0, "avg_logprob": -0.1932842113353588, "compression_ratio": 1.6177474402730376, "no_speech_prob": 3.9053275031619705e-06}, {"id": 465, "seek": 245016, "start": 2450.16, "end": 2454.48, "text": " And so because they love to generalize, this is one of the cool things about you guys knowing", "tokens": [400, 370, 570, 436, 959, 281, 2674, 1125, 11, 341, 307, 472, 295, 264, 1627, 721, 466, 291, 1074, 5276], "temperature": 0.0, "avg_logprob": -0.11227602811203789, "compression_ratio": 1.7929515418502202, "no_speech_prob": 7.411120350298006e-06}, {"id": 466, "seek": 245016, "start": 2454.48, "end": 2459.72, "text": " the technical details now, because they love to generalize, when you see something like", "tokens": [264, 6191, 4365, 586, 11, 570, 436, 959, 281, 2674, 1125, 11, 562, 291, 536, 746, 411], "temperature": 0.0, "avg_logprob": -0.11227602811203789, "compression_ratio": 1.7929515418502202, "no_speech_prob": 7.411120350298006e-06}, {"id": 467, "seek": 245016, "start": 2459.72, "end": 2464.64, "text": " 60% of people cooking are women in the pictures they use to build this model, and then you", "tokens": [4060, 4, 295, 561, 6361, 366, 2266, 294, 264, 5242, 436, 764, 281, 1322, 341, 2316, 11, 293, 550, 291], "temperature": 0.0, "avg_logprob": -0.11227602811203789, "compression_ratio": 1.7929515418502202, "no_speech_prob": 7.411120350298006e-06}, {"id": 468, "seek": 245016, "start": 2464.64, "end": 2470.8799999999997, "text": " actually run the model on a separate set of pictures, then 84% of the people they choose", "tokens": [767, 1190, 264, 2316, 322, 257, 4994, 992, 295, 5242, 11, 550, 29018, 4, 295, 264, 561, 436, 2826], "temperature": 0.0, "avg_logprob": -0.11227602811203789, "compression_ratio": 1.7929515418502202, "no_speech_prob": 7.411120350298006e-06}, {"id": 469, "seek": 245016, "start": 2470.8799999999997, "end": 2475.96, "text": " as cooking women rather than the correct 67%.", "tokens": [382, 6361, 2266, 2831, 813, 264, 3006, 23879, 6856], "temperature": 0.0, "avg_logprob": -0.11227602811203789, "compression_ratio": 1.7929515418502202, "no_speech_prob": 7.411120350298006e-06}, {"id": 470, "seek": 247596, "start": 2475.96, "end": 2482.2, "text": " Which is like a really understandable thing for an algorithm to do, is it took a biased", "tokens": [3013, 307, 411, 257, 534, 25648, 551, 337, 364, 9284, 281, 360, 11, 307, 309, 1890, 257, 28035], "temperature": 0.0, "avg_logprob": -0.11040574731961103, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.2805195183318574e-05}, {"id": 471, "seek": 247596, "start": 2482.2, "end": 2489.64, "text": " input and created a more biased output, because for this particular loss function, that's", "tokens": [4846, 293, 2942, 257, 544, 28035, 5598, 11, 570, 337, 341, 1729, 4470, 2445, 11, 300, 311], "temperature": 0.0, "avg_logprob": -0.11040574731961103, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.2805195183318574e-05}, {"id": 472, "seek": 247596, "start": 2489.64, "end": 2491.32, "text": " kind of where it ended up.", "tokens": [733, 295, 689, 309, 4590, 493, 13], "temperature": 0.0, "avg_logprob": -0.11040574731961103, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.2805195183318574e-05}, {"id": 473, "seek": 247596, "start": 2491.32, "end": 2500.28, "text": " And this is a really common kind of model amplification.", "tokens": [400, 341, 307, 257, 534, 2689, 733, 295, 2316, 9731, 3774, 13], "temperature": 0.0, "avg_logprob": -0.11040574731961103, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.2805195183318574e-05}, {"id": 474, "seek": 247596, "start": 2500.28, "end": 2505.0, "text": " So this stuff matters.", "tokens": [407, 341, 1507, 7001, 13], "temperature": 0.0, "avg_logprob": -0.11040574731961103, "compression_ratio": 1.5106382978723405, "no_speech_prob": 1.2805195183318574e-05}, {"id": 475, "seek": 250500, "start": 2505.0, "end": 2515.28, "text": " It matters in ways more than just awkward translations or black people's photos not", "tokens": [467, 7001, 294, 2098, 544, 813, 445, 11411, 37578, 420, 2211, 561, 311, 5787, 406], "temperature": 0.0, "avg_logprob": -0.252720947265625, "compression_ratio": 1.5870646766169154, "no_speech_prob": 1.1478548003651667e-05}, {"id": 476, "seek": 250500, "start": 2515.28, "end": 2518.36, "text": " being classified correctly.", "tokens": [885, 20627, 8944, 13], "temperature": 0.0, "avg_logprob": -0.252720947265625, "compression_ratio": 1.5870646766169154, "no_speech_prob": 1.1478548003651667e-05}, {"id": 477, "seek": 250500, "start": 2518.36, "end": 2523.04, "text": " Maybe there's some wins too as well, like horrifying surveillance everywhere, maybe", "tokens": [2704, 456, 311, 512, 10641, 886, 382, 731, 11, 411, 40227, 18475, 5315, 11, 1310], "temperature": 0.0, "avg_logprob": -0.252720947265625, "compression_ratio": 1.5870646766169154, "no_speech_prob": 1.1478548003651667e-05}, {"id": 478, "seek": 250500, "start": 2523.04, "end": 2524.84, "text": " won't work on black people.", "tokens": [1582, 380, 589, 322, 2211, 561, 13], "temperature": 0.0, "avg_logprob": -0.252720947265625, "compression_ratio": 1.5870646766169154, "no_speech_prob": 1.1478548003651667e-05}, {"id": 479, "seek": 250500, "start": 2524.84, "end": 2531.92, "text": " Or it'll be even worse because it's horrifying surveillance and it's flat out racist and", "tokens": [1610, 309, 603, 312, 754, 5324, 570, 309, 311, 40227, 18475, 293, 309, 311, 4962, 484, 16419, 293], "temperature": 0.0, "avg_logprob": -0.252720947265625, "compression_ratio": 1.5870646766169154, "no_speech_prob": 1.1478548003651667e-05}, {"id": 480, "seek": 250500, "start": 2531.92, "end": 2532.92, "text": " wrong.", "tokens": [2085, 13], "temperature": 0.0, "avg_logprob": -0.252720947265625, "compression_ratio": 1.5870646766169154, "no_speech_prob": 1.1478548003651667e-05}, {"id": 481, "seek": 253292, "start": 2532.92, "end": 2535.12, "text": " I agree with that too.", "tokens": [286, 3986, 365, 300, 886, 13], "temperature": 0.0, "avg_logprob": -0.2451327641805013, "compression_ratio": 1.4114285714285715, "no_speech_prob": 1.9832956240861677e-05}, {"id": 482, "seek": 253292, "start": 2535.12, "end": 2540.92, "text": " But let's go deeper.", "tokens": [583, 718, 311, 352, 7731, 13], "temperature": 0.0, "avg_logprob": -0.2451327641805013, "compression_ratio": 1.4114285714285715, "no_speech_prob": 1.9832956240861677e-05}, {"id": 483, "seek": 253292, "start": 2540.92, "end": 2550.0, "text": " For all we say about human failings, humans are generally, there's a long history of civilization", "tokens": [1171, 439, 321, 584, 466, 1952, 3061, 1109, 11, 6255, 366, 5101, 11, 456, 311, 257, 938, 2503, 295, 18036], "temperature": 0.0, "avg_logprob": -0.2451327641805013, "compression_ratio": 1.4114285714285715, "no_speech_prob": 1.9832956240861677e-05}, {"id": 484, "seek": 253292, "start": 2550.0, "end": 2556.92, "text": " and societies creating layers of human judgment which avoid hopefully the most horrible things", "tokens": [293, 19329, 4084, 7914, 295, 1952, 12216, 597, 5042, 4696, 264, 881, 9263, 721], "temperature": 0.0, "avg_logprob": -0.2451327641805013, "compression_ratio": 1.4114285714285715, "no_speech_prob": 1.9832956240861677e-05}, {"id": 485, "seek": 253292, "start": 2556.92, "end": 2558.1, "text": " happening.", "tokens": [2737, 13], "temperature": 0.0, "avg_logprob": -0.2451327641805013, "compression_ratio": 1.4114285714285715, "no_speech_prob": 1.9832956240861677e-05}, {"id": 486, "seek": 255810, "start": 2558.1, "end": 2564.36, "text": " And sometimes companies which love technology think, let's throw away the humans and replace", "tokens": [400, 2171, 3431, 597, 959, 2899, 519, 11, 718, 311, 3507, 1314, 264, 6255, 293, 7406], "temperature": 0.0, "avg_logprob": -0.16449366774514457, "compression_ratio": 1.71875, "no_speech_prob": 1.4367449239216512e-06}, {"id": 487, "seek": 255810, "start": 2564.36, "end": 2567.12, "text": " them with technology like Facebook did.", "tokens": [552, 365, 2899, 411, 4384, 630, 13], "temperature": 0.0, "avg_logprob": -0.16449366774514457, "compression_ratio": 1.71875, "no_speech_prob": 1.4367449239216512e-06}, {"id": 488, "seek": 255810, "start": 2567.12, "end": 2572.92, "text": " So 2 or 3 years ago, Facebook literally got rid of their human editors, like this was", "tokens": [407, 568, 420, 805, 924, 2057, 11, 4384, 3736, 658, 3973, 295, 641, 1952, 31446, 11, 411, 341, 390], "temperature": 0.0, "avg_logprob": -0.16449366774514457, "compression_ratio": 1.71875, "no_speech_prob": 1.4367449239216512e-06}, {"id": 489, "seek": 255810, "start": 2572.92, "end": 2576.7599999999998, "text": " in the news at the time, and they were replaced with algorithms.", "tokens": [294, 264, 2583, 412, 264, 565, 11, 293, 436, 645, 10772, 365, 14642, 13], "temperature": 0.0, "avg_logprob": -0.16449366774514457, "compression_ratio": 1.71875, "no_speech_prob": 1.4367449239216512e-06}, {"id": 490, "seek": 255810, "start": 2576.7599999999998, "end": 2581.7999999999997, "text": " And so now there's algorithms that put all the stuff on your news feed and human editors", "tokens": [400, 370, 586, 456, 311, 14642, 300, 829, 439, 264, 1507, 322, 428, 2583, 3154, 293, 1952, 31446], "temperature": 0.0, "avg_logprob": -0.16449366774514457, "compression_ratio": 1.71875, "no_speech_prob": 1.4367449239216512e-06}, {"id": 491, "seek": 255810, "start": 2581.7999999999997, "end": 2583.24, "text": " are out of the loop.", "tokens": [366, 484, 295, 264, 6367, 13], "temperature": 0.0, "avg_logprob": -0.16449366774514457, "compression_ratio": 1.71875, "no_speech_prob": 1.4367449239216512e-06}, {"id": 492, "seek": 255810, "start": 2583.24, "end": 2584.96, "text": " What happened next?", "tokens": [708, 2011, 958, 30], "temperature": 0.0, "avg_logprob": -0.16449366774514457, "compression_ratio": 1.71875, "no_speech_prob": 1.4367449239216512e-06}, {"id": 493, "seek": 255810, "start": 2584.96, "end": 2586.48, "text": " Many things happened next.", "tokens": [5126, 721, 2011, 958, 13], "temperature": 0.0, "avg_logprob": -0.16449366774514457, "compression_ratio": 1.71875, "no_speech_prob": 1.4367449239216512e-06}, {"id": 494, "seek": 258648, "start": 2586.48, "end": 2593.2400000000002, "text": " One of which was a massive horrifying genocide in Myanmar.", "tokens": [1485, 295, 597, 390, 257, 5994, 40227, 31867, 294, 42725, 13], "temperature": 0.0, "avg_logprob": -0.1894961330625746, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.356836143415421e-06}, {"id": 495, "seek": 258648, "start": 2593.2400000000002, "end": 2597.2, "text": " Babies getting torn out of their mother's arms and thrown into fires.", "tokens": [15820, 530, 1242, 10885, 484, 295, 641, 2895, 311, 5812, 293, 11732, 666, 15044, 13], "temperature": 0.0, "avg_logprob": -0.1894961330625746, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.356836143415421e-06}, {"id": 496, "seek": 258648, "start": 2597.2, "end": 2606.32, "text": " Mass rape, murder, and an entire people exiled from their homeland.", "tokens": [10482, 22846, 11, 6568, 11, 293, 364, 2302, 561, 454, 7292, 490, 641, 32494, 13], "temperature": 0.0, "avg_logprob": -0.1894961330625746, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.356836143415421e-06}, {"id": 497, "seek": 258648, "start": 2606.32, "end": 2613.4, "text": " I'm not going to say that was because Facebook did this, but what I will say is that when", "tokens": [286, 478, 406, 516, 281, 584, 300, 390, 570, 4384, 630, 341, 11, 457, 437, 286, 486, 584, 307, 300, 562], "temperature": 0.0, "avg_logprob": -0.1894961330625746, "compression_ratio": 1.4591836734693877, "no_speech_prob": 4.356836143415421e-06}, {"id": 498, "seek": 261340, "start": 2613.4, "end": 2621.4, "text": " the leaders of this horrifying project are interviewed, they regularly talk about how", "tokens": [264, 3523, 295, 341, 40227, 1716, 366, 19770, 11, 436, 11672, 751, 466, 577], "temperature": 0.0, "avg_logprob": -0.10366827718327555, "compression_ratio": 1.6419753086419753, "no_speech_prob": 2.9944185371277854e-06}, {"id": 499, "seek": 261340, "start": 2621.4, "end": 2626.92, "text": " everything they learnt about the disgusting animal behaviors of Rohingyas that need to", "tokens": [1203, 436, 18991, 466, 264, 17552, 5496, 15501, 295, 3101, 571, 39472, 300, 643, 281], "temperature": 0.0, "avg_logprob": -0.10366827718327555, "compression_ratio": 1.6419753086419753, "no_speech_prob": 2.9944185371277854e-06}, {"id": 500, "seek": 261340, "start": 2626.92, "end": 2630.8, "text": " be thrown off the earth, they learnt from Facebook.", "tokens": [312, 11732, 766, 264, 4120, 11, 436, 18991, 490, 4384, 13], "temperature": 0.0, "avg_logprob": -0.10366827718327555, "compression_ratio": 1.6419753086419753, "no_speech_prob": 2.9944185371277854e-06}, {"id": 501, "seek": 261340, "start": 2630.8, "end": 2636.0, "text": " Because the algorithms just want to feed you more stuff that gets you clicking.", "tokens": [1436, 264, 14642, 445, 528, 281, 3154, 291, 544, 1507, 300, 2170, 291, 9697, 13], "temperature": 0.0, "avg_logprob": -0.10366827718327555, "compression_ratio": 1.6419753086419753, "no_speech_prob": 2.9944185371277854e-06}, {"id": 502, "seek": 261340, "start": 2636.0, "end": 2641.08, "text": " And so if you get told these people that don't look like you and you don't know are bad people", "tokens": [400, 370, 498, 291, 483, 1907, 613, 561, 300, 500, 380, 574, 411, 291, 293, 291, 500, 380, 458, 366, 1578, 561], "temperature": 0.0, "avg_logprob": -0.10366827718327555, "compression_ratio": 1.6419753086419753, "no_speech_prob": 2.9944185371277854e-06}, {"id": 503, "seek": 264108, "start": 2641.08, "end": 2644.7999999999997, "text": " and here's lots of stories about the bad people, and then you start clicking on them, and then", "tokens": [293, 510, 311, 3195, 295, 3676, 466, 264, 1578, 561, 11, 293, 550, 291, 722, 9697, 322, 552, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.18624498276483445, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.5206552234303672e-05}, {"id": 504, "seek": 264108, "start": 2644.7999999999997, "end": 2649.08, "text": " they feed you more of those things, and next thing you know you have this extraordinary", "tokens": [436, 3154, 291, 544, 295, 729, 721, 11, 293, 958, 551, 291, 458, 291, 362, 341, 10581], "temperature": 0.0, "avg_logprob": -0.18624498276483445, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.5206552234303672e-05}, {"id": 505, "seek": 264108, "start": 2649.08, "end": 2650.08, "text": " cycle.", "tokens": [6586, 13], "temperature": 0.0, "avg_logprob": -0.18624498276483445, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.5206552234303672e-05}, {"id": 506, "seek": 264108, "start": 2650.08, "end": 2652.56, "text": " And people have been studying this.", "tokens": [400, 561, 362, 668, 7601, 341, 13], "temperature": 0.0, "avg_logprob": -0.18624498276483445, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.5206552234303672e-05}, {"id": 507, "seek": 264108, "start": 2652.56, "end": 2658.88, "text": " So for example, we've been told a few times people click on our Fast AI videos, and then", "tokens": [407, 337, 1365, 11, 321, 600, 668, 1907, 257, 1326, 1413, 561, 2052, 322, 527, 15968, 7318, 2145, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.18624498276483445, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.5206552234303672e-05}, {"id": 508, "seek": 264108, "start": 2658.88, "end": 2664.12, "text": " the next thing recommended to them is like conspiracy theory videos from Alex Jones,", "tokens": [264, 958, 551, 9628, 281, 552, 307, 411, 20439, 5261, 2145, 490, 5202, 10512, 11], "temperature": 0.0, "avg_logprob": -0.18624498276483445, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.5206552234303672e-05}, {"id": 509, "seek": 264108, "start": 2664.12, "end": 2666.72, "text": " and then that continues there.", "tokens": [293, 550, 300, 6515, 456, 13], "temperature": 0.0, "avg_logprob": -0.18624498276483445, "compression_ratio": 1.7479674796747968, "no_speech_prob": 1.5206552234303672e-05}, {"id": 510, "seek": 266672, "start": 2666.72, "end": 2674.2799999999997, "text": " Because you know, humans click on things that shock us and surprise us and horrify us.", "tokens": [1436, 291, 458, 11, 6255, 2052, 322, 721, 300, 5588, 505, 293, 6365, 505, 293, 17582, 2505, 505, 13], "temperature": 0.0, "avg_logprob": -0.1382300713483025, "compression_ratio": 1.5815217391304348, "no_speech_prob": 4.157330749876564e-06}, {"id": 511, "seek": 266672, "start": 2674.2799999999997, "end": 2684.3599999999997, "text": " And so at so many levels, this decision has had extraordinary consequences which we're", "tokens": [400, 370, 412, 370, 867, 4358, 11, 341, 3537, 575, 632, 10581, 10098, 597, 321, 434], "temperature": 0.0, "avg_logprob": -0.1382300713483025, "compression_ratio": 1.5815217391304348, "no_speech_prob": 4.157330749876564e-06}, {"id": 512, "seek": 266672, "start": 2684.3599999999997, "end": 2686.48, "text": " only beginning to understand.", "tokens": [787, 2863, 281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.1382300713483025, "compression_ratio": 1.5815217391304348, "no_speech_prob": 4.157330749876564e-06}, {"id": 513, "seek": 266672, "start": 2686.48, "end": 2691.8799999999997, "text": " And again, this is not to say this particular consequence is because of this one thing,", "tokens": [400, 797, 11, 341, 307, 406, 281, 584, 341, 1729, 18326, 307, 570, 295, 341, 472, 551, 11], "temperature": 0.0, "avg_logprob": -0.1382300713483025, "compression_ratio": 1.5815217391304348, "no_speech_prob": 4.157330749876564e-06}, {"id": 514, "seek": 269188, "start": 2691.88, "end": 2699.8, "text": " but to say it's entirely unrelated would be clearly ignoring all of the evidence and information", "tokens": [457, 281, 584, 309, 311, 7696, 38967, 576, 312, 4448, 26258, 439, 295, 264, 4467, 293, 1589], "temperature": 0.0, "avg_logprob": -0.1314301575933184, "compression_ratio": 1.4129032258064516, "no_speech_prob": 4.157343028055038e-06}, {"id": 515, "seek": 269188, "start": 2699.8, "end": 2701.92, "text": " that we have.", "tokens": [300, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.1314301575933184, "compression_ratio": 1.4129032258064516, "no_speech_prob": 4.157343028055038e-06}, {"id": 516, "seek": 269188, "start": 2701.92, "end": 2711.8, "text": " So this is really kind of the key takeaway is to think like, what are you building and", "tokens": [407, 341, 307, 534, 733, 295, 264, 2141, 30681, 307, 281, 519, 411, 11, 437, 366, 291, 2390, 293], "temperature": 0.0, "avg_logprob": -0.1314301575933184, "compression_ratio": 1.4129032258064516, "no_speech_prob": 4.157343028055038e-06}, {"id": 517, "seek": 269188, "start": 2711.8, "end": 2714.0, "text": " how could it be used?", "tokens": [577, 727, 309, 312, 1143, 30], "temperature": 0.0, "avg_logprob": -0.1314301575933184, "compression_ratio": 1.4129032258064516, "no_speech_prob": 4.157343028055038e-06}, {"id": 518, "seek": 271400, "start": 2714.0, "end": 2724.0, "text": " So lots and lots of effort now being put into face detection, including in our course.", "tokens": [407, 3195, 293, 3195, 295, 4630, 586, 885, 829, 666, 1851, 17784, 11, 3009, 294, 527, 1164, 13], "temperature": 0.0, "avg_logprob": -0.16192670186360678, "compression_ratio": 1.5825242718446602, "no_speech_prob": 2.8130048121965956e-06}, {"id": 519, "seek": 271400, "start": 2724.0, "end": 2727.92, "text": " We've been spending a lot of time thinking about how to recognize stuff and where it", "tokens": [492, 600, 668, 6434, 257, 688, 295, 565, 1953, 466, 577, 281, 5521, 1507, 293, 689, 309], "temperature": 0.0, "avg_logprob": -0.16192670186360678, "compression_ratio": 1.5825242718446602, "no_speech_prob": 2.8130048121965956e-06}, {"id": 520, "seek": 271400, "start": 2727.92, "end": 2732.56, "text": " is, and there's lots of good reasons to want to be good at that.", "tokens": [307, 11, 293, 456, 311, 3195, 295, 665, 4112, 281, 528, 281, 312, 665, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.16192670186360678, "compression_ratio": 1.5825242718446602, "no_speech_prob": 2.8130048121965956e-06}, {"id": 521, "seek": 271400, "start": 2732.56, "end": 2737.92, "text": " For improving crop yields in agriculture, for improving diagnostic and treatment planning", "tokens": [1171, 11470, 9086, 32168, 294, 14837, 11, 337, 11470, 27897, 293, 5032, 5038], "temperature": 0.0, "avg_logprob": -0.16192670186360678, "compression_ratio": 1.5825242718446602, "no_speech_prob": 2.8130048121965956e-06}, {"id": 522, "seek": 273792, "start": 2737.92, "end": 2747.8, "text": " and medicine, for improving your Lego sorting robot system, whatever.", "tokens": [293, 7195, 11, 337, 11470, 428, 28761, 32411, 7881, 1185, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2278860326398883, "compression_ratio": 1.3865030674846626, "no_speech_prob": 9.721496780912275e-07}, {"id": 523, "seek": 273792, "start": 2747.8, "end": 2755.8, "text": " But it's also being widely used in surveillance and propaganda and disinformation.", "tokens": [583, 309, 311, 611, 885, 13371, 1143, 294, 18475, 293, 22968, 293, 717, 20941, 13], "temperature": 0.0, "avg_logprob": -0.2278860326398883, "compression_ratio": 1.3865030674846626, "no_speech_prob": 9.721496780912275e-07}, {"id": 524, "seek": 273792, "start": 2755.8, "end": 2762.6800000000003, "text": " And again, the question is what do I do about that?", "tokens": [400, 797, 11, 264, 1168, 307, 437, 360, 286, 360, 466, 300, 30], "temperature": 0.0, "avg_logprob": -0.2278860326398883, "compression_ratio": 1.3865030674846626, "no_speech_prob": 9.721496780912275e-07}, {"id": 525, "seek": 273792, "start": 2762.6800000000003, "end": 2763.92, "text": " I don't exactly know.", "tokens": [286, 500, 380, 2293, 458, 13], "temperature": 0.0, "avg_logprob": -0.2278860326398883, "compression_ratio": 1.3865030674846626, "no_speech_prob": 9.721496780912275e-07}, {"id": 526, "seek": 276392, "start": 2763.92, "end": 2771.8, "text": " But it's definitely at least important to be thinking about it, talking about it, and", "tokens": [583, 309, 311, 2138, 412, 1935, 1021, 281, 312, 1953, 466, 309, 11, 1417, 466, 309, 11, 293], "temperature": 0.0, "avg_logprob": -0.12469052693930018, "compression_ratio": 1.6274509803921569, "no_speech_prob": 4.029417141282465e-06}, {"id": 527, "seek": 276392, "start": 2771.8, "end": 2774.52, "text": " sometimes you can do really good things.", "tokens": [2171, 291, 393, 360, 534, 665, 721, 13], "temperature": 0.0, "avg_logprob": -0.12469052693930018, "compression_ratio": 1.6274509803921569, "no_speech_prob": 4.029417141282465e-06}, {"id": 528, "seek": 276392, "start": 2774.52, "end": 2780.3, "text": " For example, Meetup.com did something which I would put in the category of really good", "tokens": [1171, 1365, 11, 22963, 1010, 13, 1112, 630, 746, 597, 286, 576, 829, 294, 264, 7719, 295, 534, 665], "temperature": 0.0, "avg_logprob": -0.12469052693930018, "compression_ratio": 1.6274509803921569, "no_speech_prob": 4.029417141282465e-06}, {"id": 529, "seek": 276392, "start": 2780.3, "end": 2789.32, "text": " thing, which is they recognized early a potential problem, which is that more men were tending", "tokens": [551, 11, 597, 307, 436, 9823, 2440, 257, 3995, 1154, 11, 597, 307, 300, 544, 1706, 645, 256, 2029], "temperature": 0.0, "avg_logprob": -0.12469052693930018, "compression_ratio": 1.6274509803921569, "no_speech_prob": 4.029417141282465e-06}, {"id": 530, "seek": 276392, "start": 2789.32, "end": 2792.2000000000003, "text": " to go to their meetups.", "tokens": [281, 352, 281, 641, 1677, 7528, 13], "temperature": 0.0, "avg_logprob": -0.12469052693930018, "compression_ratio": 1.6274509803921569, "no_speech_prob": 4.029417141282465e-06}, {"id": 531, "seek": 279220, "start": 2792.2, "end": 2798.16, "text": " And that was causing their collaborative filtering systems, which you're all familiar with building", "tokens": [400, 300, 390, 9853, 641, 16555, 30822, 3652, 11, 597, 291, 434, 439, 4963, 365, 2390], "temperature": 0.0, "avg_logprob": -0.1096539909456983, "compression_ratio": 1.916256157635468, "no_speech_prob": 2.769379307210329e-06}, {"id": 532, "seek": 279220, "start": 2798.16, "end": 2804.7999999999997, "text": " now, to recommend more technical content to men.", "tokens": [586, 11, 281, 2748, 544, 6191, 2701, 281, 1706, 13], "temperature": 0.0, "avg_logprob": -0.1096539909456983, "compression_ratio": 1.916256157635468, "no_speech_prob": 2.769379307210329e-06}, {"id": 533, "seek": 279220, "start": 2804.7999999999997, "end": 2809.3399999999997, "text": " And that was causing more men to go to more technical content, which was causing the recommendation", "tokens": [400, 300, 390, 9853, 544, 1706, 281, 352, 281, 544, 6191, 2701, 11, 597, 390, 9853, 264, 11879], "temperature": 0.0, "avg_logprob": -0.1096539909456983, "compression_ratio": 1.916256157635468, "no_speech_prob": 2.769379307210329e-06}, {"id": 534, "seek": 279220, "start": 2809.3399999999997, "end": 2814.0, "text": " systems to suggest more technical content to men.", "tokens": [3652, 281, 3402, 544, 6191, 2701, 281, 1706, 13], "temperature": 0.0, "avg_logprob": -0.1096539909456983, "compression_ratio": 1.916256157635468, "no_speech_prob": 2.769379307210329e-06}, {"id": 535, "seek": 279220, "start": 2814.0, "end": 2820.7999999999997, "text": " And this kind of runaway feedback loop is extremely common when we interface the algorithm", "tokens": [400, 341, 733, 295, 1190, 10318, 5824, 6367, 307, 4664, 2689, 562, 321, 9226, 264, 9284], "temperature": 0.0, "avg_logprob": -0.1096539909456983, "compression_ratio": 1.916256157635468, "no_speech_prob": 2.769379307210329e-06}, {"id": 536, "seek": 282080, "start": 2820.8, "end": 2823.44, "text": " and the human together.", "tokens": [293, 264, 1952, 1214, 13], "temperature": 0.0, "avg_logprob": -0.10831514994303386, "compression_ratio": 1.6071428571428572, "no_speech_prob": 2.6841878479899606e-06}, {"id": 537, "seek": 282080, "start": 2823.44, "end": 2825.52, "text": " So what did Meetup do?", "tokens": [407, 437, 630, 22963, 1010, 360, 30], "temperature": 0.0, "avg_logprob": -0.10831514994303386, "compression_ratio": 1.6071428571428572, "no_speech_prob": 2.6841878479899606e-06}, {"id": 538, "seek": 282080, "start": 2825.52, "end": 2832.92, "text": " They intentionally made the decision to recommend more technical content to women.", "tokens": [814, 22062, 1027, 264, 3537, 281, 2748, 544, 6191, 2701, 281, 2266, 13], "temperature": 0.0, "avg_logprob": -0.10831514994303386, "compression_ratio": 1.6071428571428572, "no_speech_prob": 2.6841878479899606e-06}, {"id": 539, "seek": 282080, "start": 2832.92, "end": 2840.52, "text": " Not because of some highfalutin idea about how the world should be, but just because", "tokens": [1726, 570, 295, 512, 1090, 36474, 325, 259, 1558, 466, 577, 264, 1002, 820, 312, 11, 457, 445, 570], "temperature": 0.0, "avg_logprob": -0.10831514994303386, "compression_ratio": 1.6071428571428572, "no_speech_prob": 2.6841878479899606e-06}, {"id": 540, "seek": 282080, "start": 2840.52, "end": 2842.6800000000003, "text": " that makes sense.", "tokens": [300, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.10831514994303386, "compression_ratio": 1.6071428571428572, "no_speech_prob": 2.6841878479899606e-06}, {"id": 541, "seek": 282080, "start": 2842.6800000000003, "end": 2846.8, "text": " The runaway feedback loop was a bug.", "tokens": [440, 1190, 10318, 5824, 6367, 390, 257, 7426, 13], "temperature": 0.0, "avg_logprob": -0.10831514994303386, "compression_ratio": 1.6071428571428572, "no_speech_prob": 2.6841878479899606e-06}, {"id": 542, "seek": 282080, "start": 2846.8, "end": 2850.2000000000003, "text": " There are women that want to go to tech meetups, but when you turn up to a tech meetup and", "tokens": [821, 366, 2266, 300, 528, 281, 352, 281, 7553, 1677, 7528, 11, 457, 562, 291, 1261, 493, 281, 257, 7553, 1677, 1010, 293], "temperature": 0.0, "avg_logprob": -0.10831514994303386, "compression_ratio": 1.6071428571428572, "no_speech_prob": 2.6841878479899606e-06}, {"id": 543, "seek": 285020, "start": 2850.2, "end": 2856.56, "text": " it's all men, and you don't go, and it recommends more to men, and so on and so forth.", "tokens": [309, 311, 439, 1706, 11, 293, 291, 500, 380, 352, 11, 293, 309, 34556, 544, 281, 1706, 11, 293, 370, 322, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.13371846255134134, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.2603144316235557e-06}, {"id": 544, "seek": 285020, "start": 2856.56, "end": 2862.72, "text": " So Meetup made a really strong product management decision here, which was to not do what the", "tokens": [407, 22963, 1010, 1027, 257, 534, 2068, 1674, 4592, 3537, 510, 11, 597, 390, 281, 406, 360, 437, 264], "temperature": 0.0, "avg_logprob": -0.13371846255134134, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.2603144316235557e-06}, {"id": 545, "seek": 285020, "start": 2862.72, "end": 2866.3999999999996, "text": " algorithm said to do.", "tokens": [9284, 848, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.13371846255134134, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.2603144316235557e-06}, {"id": 546, "seek": 285020, "start": 2866.3999999999996, "end": 2868.3599999999997, "text": " Unfortunately this is rare.", "tokens": [8590, 341, 307, 5892, 13], "temperature": 0.0, "avg_logprob": -0.13371846255134134, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.2603144316235557e-06}, {"id": 547, "seek": 285020, "start": 2868.3599999999997, "end": 2873.72, "text": " Most of these runaway feedback loops, for example in predictive policing, where algorithms", "tokens": [4534, 295, 613, 1190, 10318, 5824, 16121, 11, 337, 1365, 294, 35521, 28799, 11, 689, 14642], "temperature": 0.0, "avg_logprob": -0.13371846255134134, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.2603144316235557e-06}, {"id": 548, "seek": 285020, "start": 2873.72, "end": 2878.64, "text": " tell policemen where to go, which very often is more black neighborhoods, which end up", "tokens": [980, 6285, 14071, 689, 281, 352, 11, 597, 588, 2049, 307, 544, 2211, 20052, 11, 597, 917, 493], "temperature": 0.0, "avg_logprob": -0.13371846255134134, "compression_ratio": 1.6451612903225807, "no_speech_prob": 2.2603144316235557e-06}, {"id": 549, "seek": 287864, "start": 2878.64, "end": 2882.6, "text": " crawling with more policemen, which leads to more arrests, which has the systems tell", "tokens": [32979, 365, 544, 6285, 14071, 11, 597, 6689, 281, 544, 48813, 11, 597, 575, 264, 3652, 980], "temperature": 0.0, "avg_logprob": -0.10218524065884677, "compression_ratio": 1.570469798657718, "no_speech_prob": 1.0676980082280352e-06}, {"id": 550, "seek": 287864, "start": 2882.6, "end": 2889.6, "text": " more policemen to go to more black neighborhoods, and so forth.", "tokens": [544, 6285, 14071, 281, 352, 281, 544, 2211, 20052, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.10218524065884677, "compression_ratio": 1.570469798657718, "no_speech_prob": 1.0676980082280352e-06}, {"id": 551, "seek": 287864, "start": 2889.6, "end": 2901.0, "text": " So this problem of algorithmic bias is now very widespread, and as algorithms become", "tokens": [407, 341, 1154, 295, 9284, 299, 12577, 307, 586, 588, 22679, 11, 293, 382, 14642, 1813], "temperature": 0.0, "avg_logprob": -0.10218524065884677, "compression_ratio": 1.570469798657718, "no_speech_prob": 1.0676980082280352e-06}, {"id": 552, "seek": 290100, "start": 2901.0, "end": 2909.48, "text": " more and more widely used for specific policy decisions, judicial decisions, day to day", "tokens": [544, 293, 544, 13371, 1143, 337, 2685, 3897, 5327, 11, 26581, 5327, 11, 786, 281, 786], "temperature": 0.0, "avg_logprob": -0.09797521148409162, "compression_ratio": 1.5146198830409356, "no_speech_prob": 2.769399770841119e-06}, {"id": 553, "seek": 290100, "start": 2909.48, "end": 2921.0, "text": " decisions about who to give what offer to, this just keeps becoming a bigger problem.", "tokens": [5327, 466, 567, 281, 976, 437, 2626, 281, 11, 341, 445, 5965, 5617, 257, 3801, 1154, 13], "temperature": 0.0, "avg_logprob": -0.09797521148409162, "compression_ratio": 1.5146198830409356, "no_speech_prob": 2.769399770841119e-06}, {"id": 554, "seek": 290100, "start": 2921.0, "end": 2927.56, "text": " And some of them are really things that the people involved in the product management", "tokens": [400, 512, 295, 552, 366, 534, 721, 300, 264, 561, 3288, 294, 264, 1674, 4592], "temperature": 0.0, "avg_logprob": -0.09797521148409162, "compression_ratio": 1.5146198830409356, "no_speech_prob": 2.769399770841119e-06}, {"id": 555, "seek": 292756, "start": 2927.56, "end": 2933.88, "text": " decision should have seen at the very start didn't make sense and were unreasonable under", "tokens": [3537, 820, 362, 1612, 412, 264, 588, 722, 994, 380, 652, 2020, 293, 645, 41730, 833], "temperature": 0.0, "avg_logprob": -0.20774087561182228, "compression_ratio": 1.5596330275229358, "no_speech_prob": 9.368640348839108e-06}, {"id": 556, "seek": 292756, "start": 2933.88, "end": 2935.48, "text": " any definition of the term.", "tokens": [604, 7123, 295, 264, 1433, 13], "temperature": 0.0, "avg_logprob": -0.20774087561182228, "compression_ratio": 1.5596330275229358, "no_speech_prob": 9.368640348839108e-06}, {"id": 557, "seek": 292756, "start": 2935.48, "end": 2942.64, "text": " For example, this stuff that I've gone pointed out, these were questions that were used to", "tokens": [1171, 1365, 11, 341, 1507, 300, 286, 600, 2780, 10932, 484, 11, 613, 645, 1651, 300, 645, 1143, 281], "temperature": 0.0, "avg_logprob": -0.20774087561182228, "compression_ratio": 1.5596330275229358, "no_speech_prob": 9.368640348839108e-06}, {"id": 558, "seek": 292756, "start": 2942.64, "end": 2948.36, "text": " decide, Rachel was this sentencing guidelines?", "tokens": [4536, 11, 14246, 390, 341, 2279, 13644, 12470, 30], "temperature": 0.0, "avg_logprob": -0.20774087561182228, "compression_ratio": 1.5596330275229358, "no_speech_prob": 9.368640348839108e-06}, {"id": 559, "seek": 292756, "start": 2948.36, "end": 2953.7999999999997, "text": " This software is used for both pre-trial, so who was required to post bail, so these", "tokens": [639, 4722, 307, 1143, 337, 1293, 659, 12, 83, 7111, 11, 370, 567, 390, 4739, 281, 2183, 19313, 11, 370, 613], "temperature": 0.0, "avg_logprob": -0.20774087561182228, "compression_ratio": 1.5596330275229358, "no_speech_prob": 9.368640348839108e-06}, {"id": 560, "seek": 295380, "start": 2953.8, "end": 2958.2400000000002, "text": " are people that haven't even been convicted, as well as for sentencing and for who gets", "tokens": [366, 561, 300, 2378, 380, 754, 668, 26942, 11, 382, 731, 382, 337, 2279, 13644, 293, 337, 567, 2170], "temperature": 0.0, "avg_logprob": -0.18321008885160406, "compression_ratio": 1.690909090909091, "no_speech_prob": 8.664566848892719e-06}, {"id": 561, "seek": 295380, "start": 2958.2400000000002, "end": 2963.8, "text": " parole, and this was upheld by the Wisconsin Supreme Court last year despite all the flaws", "tokens": [26783, 11, 293, 341, 390, 493, 23504, 538, 264, 17977, 11032, 7873, 1036, 1064, 7228, 439, 264, 27108], "temperature": 0.0, "avg_logprob": -0.18321008885160406, "compression_ratio": 1.690909090909091, "no_speech_prob": 8.664566848892719e-06}, {"id": 562, "seek": 295380, "start": 2963.8, "end": 2965.52, "text": " that were pointed out.", "tokens": [300, 645, 10932, 484, 13], "temperature": 0.0, "avg_logprob": -0.18321008885160406, "compression_ratio": 1.690909090909091, "no_speech_prob": 8.664566848892719e-06}, {"id": 563, "seek": 295380, "start": 2965.52, "end": 2971.5600000000004, "text": " So whether you have to stay in jail because you can't pay the bail, and how long your", "tokens": [407, 1968, 291, 362, 281, 1754, 294, 10511, 570, 291, 393, 380, 1689, 264, 19313, 11, 293, 577, 938, 428], "temperature": 0.0, "avg_logprob": -0.18321008885160406, "compression_ratio": 1.690909090909091, "no_speech_prob": 8.664566848892719e-06}, {"id": 564, "seek": 295380, "start": 2971.5600000000004, "end": 2977.36, "text": " sentence is for, and how long you stay in jail for, depends on what your father did,", "tokens": [8174, 307, 337, 11, 293, 577, 938, 291, 1754, 294, 10511, 337, 11, 5946, 322, 437, 428, 3086, 630, 11], "temperature": 0.0, "avg_logprob": -0.18321008885160406, "compression_ratio": 1.690909090909091, "no_speech_prob": 8.664566848892719e-06}, {"id": 565, "seek": 297736, "start": 2977.36, "end": 2983.96, "text": " whether your parents stayed married, who your friends are, and where you live.", "tokens": [1968, 428, 3152, 9181, 5259, 11, 567, 428, 1855, 366, 11, 293, 689, 291, 1621, 13], "temperature": 0.0, "avg_logprob": -0.11965738760458457, "compression_ratio": 1.6126126126126126, "no_speech_prob": 2.2252759208640782e-06}, {"id": 566, "seek": 297736, "start": 2983.96, "end": 2991.76, "text": " Now it turns out these algorithms are actually terribly, terribly bad, so some recent analysis", "tokens": [823, 309, 4523, 484, 613, 14642, 366, 767, 22903, 11, 22903, 1578, 11, 370, 512, 5162, 5215], "temperature": 0.0, "avg_logprob": -0.11965738760458457, "compression_ratio": 1.6126126126126126, "no_speech_prob": 2.2252759208640782e-06}, {"id": 567, "seek": 297736, "start": 2991.76, "end": 2996.48, "text": " showed that they're basically worse than chance, but even if the companies building them were", "tokens": [4712, 300, 436, 434, 1936, 5324, 813, 2931, 11, 457, 754, 498, 264, 3431, 2390, 552, 645], "temperature": 0.0, "avg_logprob": -0.11965738760458457, "compression_ratio": 1.6126126126126126, "no_speech_prob": 2.2252759208640782e-06}, {"id": 568, "seek": 297736, "start": 2996.48, "end": 3003.44, "text": " competent and these were statistically accurate correlations, does anybody imagine there's", "tokens": [29998, 293, 613, 645, 36478, 8559, 13983, 763, 11, 775, 4472, 3811, 456, 311], "temperature": 0.0, "avg_logprob": -0.11965738760458457, "compression_ratio": 1.6126126126126126, "no_speech_prob": 2.2252759208640782e-06}, {"id": 569, "seek": 300344, "start": 3003.44, "end": 3014.52, "text": " a world where it makes sense to decide what happens to you based on what your dad did?", "tokens": [257, 1002, 689, 309, 1669, 2020, 281, 4536, 437, 2314, 281, 291, 2361, 322, 437, 428, 3546, 630, 30], "temperature": 0.0, "avg_logprob": -0.14181631803512573, "compression_ratio": 1.6287128712871286, "no_speech_prob": 1.6028081972763175e-06}, {"id": 570, "seek": 300344, "start": 3014.52, "end": 3023.84, "text": " So a lot of this stuff at the basic level is obviously unreasonable, and a lot of it", "tokens": [407, 257, 688, 295, 341, 1507, 412, 264, 3875, 1496, 307, 2745, 41730, 11, 293, 257, 688, 295, 309], "temperature": 0.0, "avg_logprob": -0.14181631803512573, "compression_ratio": 1.6287128712871286, "no_speech_prob": 1.6028081972763175e-06}, {"id": 571, "seek": 300344, "start": 3023.84, "end": 3028.8, "text": " just fails in these ways, but you can see empirically that these runaway feedback loops", "tokens": [445, 18199, 294, 613, 2098, 11, 457, 291, 393, 536, 25790, 984, 300, 613, 1190, 10318, 5824, 16121], "temperature": 0.0, "avg_logprob": -0.14181631803512573, "compression_ratio": 1.6287128712871286, "no_speech_prob": 1.6028081972763175e-06}, {"id": 572, "seek": 300344, "start": 3028.8, "end": 3031.96, "text": " must have happened, and these overgeneralizations must have happened.", "tokens": [1633, 362, 2011, 11, 293, 613, 670, 1766, 2790, 14455, 1633, 362, 2011, 13], "temperature": 0.0, "avg_logprob": -0.14181631803512573, "compression_ratio": 1.6287128712871286, "no_speech_prob": 1.6028081972763175e-06}, {"id": 573, "seek": 303196, "start": 3031.96, "end": 3037.8, "text": " For example, these are the kind of cross-tabs that anybody working in these fields, in any", "tokens": [1171, 1365, 11, 613, 366, 264, 733, 295, 3278, 12, 83, 17243, 300, 4472, 1364, 294, 613, 7909, 11, 294, 604], "temperature": 0.0, "avg_logprob": -0.1469352282010592, "compression_ratio": 1.4519774011299436, "no_speech_prob": 1.4593740615964634e-06}, {"id": 574, "seek": 303196, "start": 3037.8, "end": 3041.2, "text": " field that's using algorithms, should be preparing.", "tokens": [2519, 300, 311, 1228, 14642, 11, 820, 312, 10075, 13], "temperature": 0.0, "avg_logprob": -0.1469352282010592, "compression_ratio": 1.4519774011299436, "no_speech_prob": 1.4593740615964634e-06}, {"id": 575, "seek": 303196, "start": 3041.2, "end": 3052.36, "text": " So prediction of likelihood of reoffending for black vs. white defendants, we can just", "tokens": [407, 17630, 295, 22119, 295, 319, 4506, 2029, 337, 2211, 12041, 13, 2418, 8602, 1719, 11, 321, 393, 445], "temperature": 0.0, "avg_logprob": -0.1469352282010592, "compression_ratio": 1.4519774011299436, "no_speech_prob": 1.4593740615964634e-06}, {"id": 576, "seek": 303196, "start": 3052.36, "end": 3054.52, "text": " calculate this very simply.", "tokens": [8873, 341, 588, 2935, 13], "temperature": 0.0, "avg_logprob": -0.1469352282010592, "compression_ratio": 1.4519774011299436, "no_speech_prob": 1.4593740615964634e-06}, {"id": 577, "seek": 305452, "start": 3054.52, "end": 3064.68, "text": " Of the people that were labeled high risk but didn't reoffend, there were 23.5% white", "tokens": [2720, 264, 561, 300, 645, 21335, 1090, 3148, 457, 994, 380, 319, 4506, 521, 11, 456, 645, 6673, 13, 20, 4, 2418], "temperature": 0.0, "avg_logprob": -0.1657858175389907, "compression_ratio": 1.632258064516129, "no_speech_prob": 5.862791113031562e-06}, {"id": 578, "seek": 305452, "start": 3064.68, "end": 3068.96, "text": " but about twice that African-American.", "tokens": [457, 466, 6091, 300, 7312, 12, 14604, 13], "temperature": 0.0, "avg_logprob": -0.1657858175389907, "compression_ratio": 1.632258064516129, "no_speech_prob": 5.862791113031562e-06}, {"id": 579, "seek": 305452, "start": 3068.96, "end": 3076.56, "text": " Whereas those that were labeled lower risk but did reoffend was like half the white people", "tokens": [13813, 729, 300, 645, 21335, 3126, 3148, 457, 630, 319, 4506, 521, 390, 411, 1922, 264, 2418, 561], "temperature": 0.0, "avg_logprob": -0.1657858175389907, "compression_ratio": 1.632258064516129, "no_speech_prob": 5.862791113031562e-06}, {"id": 580, "seek": 305452, "start": 3076.56, "end": 3079.64, "text": " and only 20% of the African-American.", "tokens": [293, 787, 945, 4, 295, 264, 7312, 12, 14604, 13], "temperature": 0.0, "avg_logprob": -0.1657858175389907, "compression_ratio": 1.632258064516129, "no_speech_prob": 5.862791113031562e-06}, {"id": 581, "seek": 307964, "start": 3079.64, "end": 3085.2799999999997, "text": " So this is the kind of stuff where at least if you're taking the technologies we've been", "tokens": [407, 341, 307, 264, 733, 295, 1507, 689, 412, 1935, 498, 291, 434, 1940, 264, 7943, 321, 600, 668], "temperature": 0.0, "avg_logprob": -0.12492616176605224, "compression_ratio": 1.6417910447761195, "no_speech_prob": 8.139636520354543e-06}, {"id": 582, "seek": 307964, "start": 3085.2799999999997, "end": 3093.2799999999997, "text": " talking about and putting the production in any way, or building an API for other people,", "tokens": [1417, 466, 293, 3372, 264, 4265, 294, 604, 636, 11, 420, 2390, 364, 9362, 337, 661, 561, 11], "temperature": 0.0, "avg_logprob": -0.12492616176605224, "compression_ratio": 1.6417910447761195, "no_speech_prob": 8.139636520354543e-06}, {"id": 583, "seek": 307964, "start": 3093.2799999999997, "end": 3102.3599999999997, "text": " or providing training for people, or whatever, then at least make sure that what you're doing", "tokens": [420, 6530, 3097, 337, 561, 11, 420, 2035, 11, 550, 412, 1935, 652, 988, 300, 437, 291, 434, 884], "temperature": 0.0, "avg_logprob": -0.12492616176605224, "compression_ratio": 1.6417910447761195, "no_speech_prob": 8.139636520354543e-06}, {"id": 584, "seek": 307964, "start": 3102.3599999999997, "end": 3108.12, "text": " can be tracked in a way that people know what's going on.", "tokens": [393, 312, 31703, 294, 257, 636, 300, 561, 458, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.12492616176605224, "compression_ratio": 1.6417910447761195, "no_speech_prob": 8.139636520354543e-06}, {"id": 585, "seek": 310812, "start": 3108.12, "end": 3110.04, "text": " So at least they're informed.", "tokens": [407, 412, 1935, 436, 434, 11740, 13], "temperature": 0.0, "avg_logprob": -0.18903966267903646, "compression_ratio": 1.5846994535519126, "no_speech_prob": 1.6187323126359843e-05}, {"id": 586, "seek": 310812, "start": 3110.04, "end": 3122.64, "text": " I think it's a mistake in my opinion to assume that people are evil and trying to break society.", "tokens": [286, 519, 309, 311, 257, 6146, 294, 452, 4800, 281, 6552, 300, 561, 366, 6724, 293, 1382, 281, 1821, 4086, 13], "temperature": 0.0, "avg_logprob": -0.18903966267903646, "compression_ratio": 1.5846994535519126, "no_speech_prob": 1.6187323126359843e-05}, {"id": 587, "seek": 310812, "start": 3122.64, "end": 3127.48, "text": " I prefer to start with an assumption of if people are doing dumb stuff, it's because", "tokens": [286, 4382, 281, 722, 365, 364, 15302, 295, 498, 561, 366, 884, 10316, 1507, 11, 309, 311, 570], "temperature": 0.0, "avg_logprob": -0.18903966267903646, "compression_ratio": 1.5846994535519126, "no_speech_prob": 1.6187323126359843e-05}, {"id": 588, "seek": 310812, "start": 3127.48, "end": 3129.3199999999997, "text": " they don't know better.", "tokens": [436, 500, 380, 458, 1101, 13], "temperature": 0.0, "avg_logprob": -0.18903966267903646, "compression_ratio": 1.5846994535519126, "no_speech_prob": 1.6187323126359843e-05}, {"id": 589, "seek": 310812, "start": 3129.3199999999997, "end": 3132.2799999999997, "text": " So at least make sure that they have this information.", "tokens": [407, 412, 1935, 652, 988, 300, 436, 362, 341, 1589, 13], "temperature": 0.0, "avg_logprob": -0.18903966267903646, "compression_ratio": 1.5846994535519126, "no_speech_prob": 1.6187323126359843e-05}, {"id": 590, "seek": 313228, "start": 3132.28, "end": 3139.1200000000003, "text": " I find very few ML practitioners thinking about what is the information they should", "tokens": [286, 915, 588, 1326, 21601, 25742, 1953, 466, 437, 307, 264, 1589, 436, 820], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 591, "seek": 313228, "start": 3139.1200000000003, "end": 3141.6400000000003, "text": " be presenting in their interface.", "tokens": [312, 15578, 294, 641, 9226, 13], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 592, "seek": 313228, "start": 3141.6400000000003, "end": 3145.6400000000003, "text": " And often I'll talk to data scientists who will say, the stuff I'm working on doesn't", "tokens": [400, 2049, 286, 603, 751, 281, 1412, 7708, 567, 486, 584, 11, 264, 1507, 286, 478, 1364, 322, 1177, 380], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 593, "seek": 313228, "start": 3145.6400000000003, "end": 3147.5600000000004, "text": " have a societal impact.", "tokens": [362, 257, 33472, 2712, 13], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 594, "seek": 313228, "start": 3147.5600000000004, "end": 3150.7200000000003, "text": " It's like, really?", "tokens": [467, 311, 411, 11, 534, 30], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 595, "seek": 313228, "start": 3150.7200000000003, "end": 3154.76, "text": " Like a number of people who think that what they're doing is entirely pointless?", "tokens": [1743, 257, 1230, 295, 561, 567, 519, 300, 437, 436, 434, 884, 307, 7696, 32824, 30], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 596, "seek": 313228, "start": 3154.76, "end": 3155.76, "text": " Come on!", "tokens": [2492, 322, 0], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 597, "seek": 313228, "start": 3155.76, "end": 3159.32, "text": " Otherwise people are paying you to do it for a reason.", "tokens": [10328, 561, 366, 6229, 291, 281, 360, 309, 337, 257, 1778, 13], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 598, "seek": 313228, "start": 3159.32, "end": 3161.8, "text": " It's going to impact people in some way.", "tokens": [467, 311, 516, 281, 2712, 561, 294, 512, 636, 13], "temperature": 0.0, "avg_logprob": -0.2200347355433873, "compression_ratio": 1.6240601503759398, "no_speech_prob": 3.446566324782907e-06}, {"id": 599, "seek": 316180, "start": 3161.8, "end": 3166.36, "text": " So think about what that is.", "tokens": [407, 519, 466, 437, 300, 307, 13], "temperature": 0.0, "avg_logprob": -0.1349647659616372, "compression_ratio": 1.6266666666666667, "no_speech_prob": 2.9944246762170224e-06}, {"id": 600, "seek": 316180, "start": 3166.36, "end": 3170.48, "text": " The other thing I know is a lot of people involved here are hiring people.", "tokens": [440, 661, 551, 286, 458, 307, 257, 688, 295, 561, 3288, 510, 366, 15335, 561, 13], "temperature": 0.0, "avg_logprob": -0.1349647659616372, "compression_ratio": 1.6266666666666667, "no_speech_prob": 2.9944246762170224e-06}, {"id": 601, "seek": 316180, "start": 3170.48, "end": 3175.28, "text": " And so if you're hiring people, I guess you're all very familiar with the Fast AI philosophy", "tokens": [400, 370, 498, 291, 434, 15335, 561, 11, 286, 2041, 291, 434, 439, 588, 4963, 365, 264, 15968, 7318, 10675], "temperature": 0.0, "avg_logprob": -0.1349647659616372, "compression_ratio": 1.6266666666666667, "no_speech_prob": 2.9944246762170224e-06}, {"id": 602, "seek": 316180, "start": 3175.28, "end": 3177.6400000000003, "text": " now, which is the basic premise.", "tokens": [586, 11, 597, 307, 264, 3875, 22045, 13], "temperature": 0.0, "avg_logprob": -0.1349647659616372, "compression_ratio": 1.6266666666666667, "no_speech_prob": 2.9944246762170224e-06}, {"id": 603, "seek": 316180, "start": 3177.6400000000003, "end": 3182.84, "text": " And I think it comes back to this idea that I don't think people on the whole are evil.", "tokens": [400, 286, 519, 309, 1487, 646, 281, 341, 1558, 300, 286, 500, 380, 519, 561, 322, 264, 1379, 366, 6724, 13], "temperature": 0.0, "avg_logprob": -0.1349647659616372, "compression_ratio": 1.6266666666666667, "no_speech_prob": 2.9944246762170224e-06}, {"id": 604, "seek": 316180, "start": 3182.84, "end": 3187.48, "text": " I think they need to be informed and have tools.", "tokens": [286, 519, 436, 643, 281, 312, 11740, 293, 362, 3873, 13], "temperature": 0.0, "avg_logprob": -0.1349647659616372, "compression_ratio": 1.6266666666666667, "no_speech_prob": 2.9944246762170224e-06}, {"id": 605, "seek": 318748, "start": 3187.48, "end": 3192.48, "text": " So we're trying to give as many people the tools as possible that they need.", "tokens": [407, 321, 434, 1382, 281, 976, 382, 867, 561, 264, 3873, 382, 1944, 300, 436, 643, 13], "temperature": 0.0, "avg_logprob": -0.09625093833259914, "compression_ratio": 1.7298578199052133, "no_speech_prob": 6.962186944292625e-06}, {"id": 606, "seek": 318748, "start": 3192.48, "end": 3197.52, "text": " And particularly we're trying to put those tools in the hands of a more diverse range", "tokens": [400, 4098, 321, 434, 1382, 281, 829, 729, 3873, 294, 264, 2377, 295, 257, 544, 9521, 3613], "temperature": 0.0, "avg_logprob": -0.09625093833259914, "compression_ratio": 1.7298578199052133, "no_speech_prob": 6.962186944292625e-06}, {"id": 607, "seek": 318748, "start": 3197.52, "end": 3198.52, "text": " of people.", "tokens": [295, 561, 13], "temperature": 0.0, "avg_logprob": -0.09625093833259914, "compression_ratio": 1.7298578199052133, "no_speech_prob": 6.962186944292625e-06}, {"id": 608, "seek": 318748, "start": 3198.52, "end": 3203.16, "text": " So if you're involved in hiring decisions, perhaps you can keep this kind of philosophy", "tokens": [407, 498, 291, 434, 3288, 294, 15335, 5327, 11, 4317, 291, 393, 1066, 341, 733, 295, 10675], "temperature": 0.0, "avg_logprob": -0.09625093833259914, "compression_ratio": 1.7298578199052133, "no_speech_prob": 6.962186944292625e-06}, {"id": 609, "seek": 318748, "start": 3203.16, "end": 3205.32, "text": " in mind as well.", "tokens": [294, 1575, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.09625093833259914, "compression_ratio": 1.7298578199052133, "no_speech_prob": 6.962186944292625e-06}, {"id": 610, "seek": 318748, "start": 3205.32, "end": 3213.36, "text": " If you're not just hiring a wider range of people, but also promoting a wider range of", "tokens": [759, 291, 434, 406, 445, 15335, 257, 11842, 3613, 295, 561, 11, 457, 611, 16383, 257, 11842, 3613, 295], "temperature": 0.0, "avg_logprob": -0.09625093833259914, "compression_ratio": 1.7298578199052133, "no_speech_prob": 6.962186944292625e-06}, {"id": 611, "seek": 321336, "start": 3213.36, "end": 3218.6400000000003, "text": " people and providing really appropriate career management for a wider range of people.", "tokens": [561, 293, 6530, 534, 6854, 3988, 4592, 337, 257, 11842, 3613, 295, 561, 13], "temperature": 0.0, "avg_logprob": -0.18924083028520858, "compression_ratio": 1.6, "no_speech_prob": 1.6280417867164942e-06}, {"id": 612, "seek": 321336, "start": 3218.6400000000003, "end": 3224.84, "text": " Well, apart from anything else, your company will do better.", "tokens": [1042, 11, 4936, 490, 1340, 1646, 11, 428, 2237, 486, 360, 1101, 13], "temperature": 0.0, "avg_logprob": -0.18924083028520858, "compression_ratio": 1.6, "no_speech_prob": 1.6280417867164942e-06}, {"id": 613, "seek": 321336, "start": 3224.84, "end": 3230.2000000000003, "text": " It actually turns out that more diverse teams are more creative and tend to solve problems", "tokens": [467, 767, 4523, 484, 300, 544, 9521, 5491, 366, 544, 5880, 293, 3928, 281, 5039, 2740], "temperature": 0.0, "avg_logprob": -0.18924083028520858, "compression_ratio": 1.6, "no_speech_prob": 1.6280417867164942e-06}, {"id": 614, "seek": 321336, "start": 3230.2000000000003, "end": 3233.52, "text": " more quickly and better and less diverse teams.", "tokens": [544, 2661, 293, 1101, 293, 1570, 9521, 5491, 13], "temperature": 0.0, "avg_logprob": -0.18924083028520858, "compression_ratio": 1.6, "no_speech_prob": 1.6280417867164942e-06}, {"id": 615, "seek": 321336, "start": 3233.52, "end": 3242.36, "text": " But also you might avoid these kind of awful screw-ups which at one level are bad for the", "tokens": [583, 611, 291, 1062, 5042, 613, 733, 295, 11232, 5630, 12, 7528, 597, 412, 472, 1496, 366, 1578, 337, 264], "temperature": 0.0, "avg_logprob": -0.18924083028520858, "compression_ratio": 1.6, "no_speech_prob": 1.6280417867164942e-06}, {"id": 616, "seek": 324236, "start": 3242.36, "end": 3249.2000000000003, "text": " world, and at another level if you ever get found out, they can also destroy your company.", "tokens": [1002, 11, 293, 412, 1071, 1496, 498, 291, 1562, 483, 1352, 484, 11, 436, 393, 611, 5293, 428, 2237, 13], "temperature": 0.0, "avg_logprob": -0.15445387704031807, "compression_ratio": 1.4742268041237114, "no_speech_prob": 2.601590040285373e-06}, {"id": 617, "seek": 324236, "start": 3249.2000000000003, "end": 3256.32, "text": " Also they can destroy you, or at least make you look pretty bad in history.", "tokens": [2743, 436, 393, 5293, 291, 11, 420, 412, 1935, 652, 291, 574, 1238, 1578, 294, 2503, 13], "temperature": 0.0, "avg_logprob": -0.15445387704031807, "compression_ratio": 1.4742268041237114, "no_speech_prob": 2.601590040285373e-06}, {"id": 618, "seek": 324236, "start": 3256.32, "end": 3258.6800000000003, "text": " A couple of examples.", "tokens": [316, 1916, 295, 5110, 13], "temperature": 0.0, "avg_logprob": -0.15445387704031807, "compression_ratio": 1.4742268041237114, "no_speech_prob": 2.601590040285373e-06}, {"id": 619, "seek": 324236, "start": 3258.6800000000003, "end": 3267.04, "text": " One is going right back to the Second World War, IBM basically provided all of the infrastructure", "tokens": [1485, 307, 516, 558, 646, 281, 264, 5736, 3937, 3630, 11, 23487, 1936, 5649, 439, 295, 264, 6896], "temperature": 0.0, "avg_logprob": -0.15445387704031807, "compression_ratio": 1.4742268041237114, "no_speech_prob": 2.601590040285373e-06}, {"id": 620, "seek": 326704, "start": 3267.04, "end": 3272.8, "text": " necessary to track the Holocaust.", "tokens": [4818, 281, 2837, 264, 28399, 13], "temperature": 0.0, "avg_logprob": -0.19745810237931616, "compression_ratio": 1.5, "no_speech_prob": 8.267766133940313e-06}, {"id": 621, "seek": 326704, "start": 3272.8, "end": 3282.72, "text": " So they had different code for Jews were 8 and gypsies were 12, death in the gas chambers", "tokens": [407, 436, 632, 819, 3089, 337, 11041, 645, 1649, 293, 15823, 1878, 530, 645, 2272, 11, 2966, 294, 264, 4211, 34513], "temperature": 0.0, "avg_logprob": -0.19745810237931616, "compression_ratio": 1.5, "no_speech_prob": 8.267766133940313e-06}, {"id": 622, "seek": 326704, "start": 3282.72, "end": 3284.92, "text": " was 6, and they all went on these punch cards.", "tokens": [390, 1386, 11, 293, 436, 439, 1437, 322, 613, 8135, 5632, 13], "temperature": 0.0, "avg_logprob": -0.19745810237931616, "compression_ratio": 1.5, "no_speech_prob": 8.267766133940313e-06}, {"id": 623, "seek": 326704, "start": 3284.92, "end": 3289.2799999999997, "text": " You can go and look at these punch cards in museums now.", "tokens": [509, 393, 352, 293, 574, 412, 613, 8135, 5632, 294, 23248, 586, 13], "temperature": 0.0, "avg_logprob": -0.19745810237931616, "compression_ratio": 1.5, "no_speech_prob": 8.267766133940313e-06}, {"id": 624, "seek": 326704, "start": 3289.2799999999997, "end": 3295.96, "text": " And this has actually been reviewed by a Swiss judge who said that IBM's technical assistance", "tokens": [400, 341, 575, 767, 668, 18429, 538, 257, 21965, 6995, 567, 848, 300, 23487, 311, 6191, 9683], "temperature": 0.0, "avg_logprob": -0.19745810237931616, "compression_ratio": 1.5, "no_speech_prob": 8.267766133940313e-06}, {"id": 625, "seek": 329596, "start": 3295.96, "end": 3302.36, "text": " facilitated the task of the Nazis and the commission of the crimes against humanity.", "tokens": [10217, 18266, 264, 5633, 295, 264, 29812, 293, 264, 9221, 295, 264, 13916, 1970, 10243, 13], "temperature": 0.0, "avg_logprob": -0.13676363771611993, "compression_ratio": 1.7445887445887447, "no_speech_prob": 1.644185795157682e-05}, {"id": 626, "seek": 329596, "start": 3302.36, "end": 3310.44, "text": " And it's interesting to read back the history from these times to see what was going through", "tokens": [400, 309, 311, 1880, 281, 1401, 646, 264, 2503, 490, 613, 1413, 281, 536, 437, 390, 516, 807], "temperature": 0.0, "avg_logprob": -0.13676363771611993, "compression_ratio": 1.7445887445887447, "no_speech_prob": 1.644185795157682e-05}, {"id": 627, "seek": 329596, "start": 3310.44, "end": 3313.4, "text": " the minds of people at IBM at that time.", "tokens": [264, 9634, 295, 561, 412, 23487, 412, 300, 565, 13], "temperature": 0.0, "avg_logprob": -0.13676363771611993, "compression_ratio": 1.7445887445887447, "no_speech_prob": 1.644185795157682e-05}, {"id": 628, "seek": 329596, "start": 3313.4, "end": 3318.76, "text": " And what was clearly going through the minds was the opportunity to show technical superiority,", "tokens": [400, 437, 390, 4448, 516, 807, 264, 9634, 390, 264, 2650, 281, 855, 6191, 48668, 11], "temperature": 0.0, "avg_logprob": -0.13676363771611993, "compression_ratio": 1.7445887445887447, "no_speech_prob": 1.644185795157682e-05}, {"id": 629, "seek": 329596, "start": 3318.76, "end": 3325.88, "text": " the opportunity to test out their new systems, and of course the extraordinary amount of", "tokens": [264, 2650, 281, 1500, 484, 641, 777, 3652, 11, 293, 295, 1164, 264, 10581, 2372, 295], "temperature": 0.0, "avg_logprob": -0.13676363771611993, "compression_ratio": 1.7445887445887447, "no_speech_prob": 1.644185795157682e-05}, {"id": 630, "seek": 332588, "start": 3325.88, "end": 3332.6800000000003, "text": " money that they were making.", "tokens": [1460, 300, 436, 645, 1455, 13], "temperature": 0.0, "avg_logprob": -0.20999256047335538, "compression_ratio": 1.5658536585365854, "no_speech_prob": 1.4970891243137885e-05}, {"id": 631, "seek": 332588, "start": 3332.6800000000003, "end": 3339.2400000000002, "text": " When you do something which at some point down the line turns out to be a problem, even", "tokens": [1133, 291, 360, 746, 597, 412, 512, 935, 760, 264, 1622, 4523, 484, 281, 312, 257, 1154, 11, 754], "temperature": 0.0, "avg_logprob": -0.20999256047335538, "compression_ratio": 1.5658536585365854, "no_speech_prob": 1.4970891243137885e-05}, {"id": 632, "seek": 332588, "start": 3339.2400000000002, "end": 3344.28, "text": " if you are told to do it, that can turn out to be a problem for you personally.", "tokens": [498, 291, 366, 1907, 281, 360, 309, 11, 300, 393, 1261, 484, 281, 312, 257, 1154, 337, 291, 5665, 13], "temperature": 0.0, "avg_logprob": -0.20999256047335538, "compression_ratio": 1.5658536585365854, "no_speech_prob": 1.4970891243137885e-05}, {"id": 633, "seek": 332588, "start": 3344.28, "end": 3349.12, "text": " For example, you'll remember the diesel emissions scandal in VW.", "tokens": [1171, 1365, 11, 291, 603, 1604, 264, 21258, 14607, 27922, 294, 691, 54, 13], "temperature": 0.0, "avg_logprob": -0.20999256047335538, "compression_ratio": 1.5658536585365854, "no_speech_prob": 1.4970891243137885e-05}, {"id": 634, "seek": 332588, "start": 3349.12, "end": 3351.6400000000003, "text": " Who was the one guy that went to jail?", "tokens": [2102, 390, 264, 472, 2146, 300, 1437, 281, 10511, 30], "temperature": 0.0, "avg_logprob": -0.20999256047335538, "compression_ratio": 1.5658536585365854, "no_speech_prob": 1.4970891243137885e-05}, {"id": 635, "seek": 332588, "start": 3351.6400000000003, "end": 3354.2400000000002, "text": " It was the engineer.", "tokens": [467, 390, 264, 11403, 13], "temperature": 0.0, "avg_logprob": -0.20999256047335538, "compression_ratio": 1.5658536585365854, "no_speech_prob": 1.4970891243137885e-05}, {"id": 636, "seek": 335424, "start": 3354.24, "end": 3356.52, "text": " Who's doing his job?", "tokens": [2102, 311, 884, 702, 1691, 30], "temperature": 0.0, "avg_logprob": -0.185003609492861, "compression_ratio": 1.5255813953488373, "no_speech_prob": 4.565946710499702e-06}, {"id": 637, "seek": 335424, "start": 3356.52, "end": 3362.72, "text": " So if all of this stuff about actually not fucking up the world isn't enough to convince", "tokens": [407, 498, 439, 295, 341, 1507, 466, 767, 406, 5546, 493, 264, 1002, 1943, 380, 1547, 281, 13447], "temperature": 0.0, "avg_logprob": -0.185003609492861, "compression_ratio": 1.5255813953488373, "no_speech_prob": 4.565946710499702e-06}, {"id": 638, "seek": 335424, "start": 3362.72, "end": 3365.9599999999996, "text": " you, it can fuck up your life too.", "tokens": [291, 11, 309, 393, 3275, 493, 428, 993, 886, 13], "temperature": 0.0, "avg_logprob": -0.185003609492861, "compression_ratio": 1.5255813953488373, "no_speech_prob": 4.565946710499702e-06}, {"id": 639, "seek": 335424, "start": 3365.9599999999996, "end": 3371.8799999999997, "text": " So if you do something that turns out to cause problems, even though somebody told you to", "tokens": [407, 498, 291, 360, 746, 300, 4523, 484, 281, 3082, 2740, 11, 754, 1673, 2618, 1907, 291, 281], "temperature": 0.0, "avg_logprob": -0.185003609492861, "compression_ratio": 1.5255813953488373, "no_speech_prob": 4.565946710499702e-06}, {"id": 640, "seek": 335424, "start": 3371.8799999999997, "end": 3377.68, "text": " do it, you can absolutely be held criminally responsible.", "tokens": [360, 309, 11, 291, 393, 3122, 312, 5167, 19044, 379, 6250, 13], "temperature": 0.0, "avg_logprob": -0.185003609492861, "compression_ratio": 1.5255813953488373, "no_speech_prob": 4.565946710499702e-06}, {"id": 641, "seek": 335424, "start": 3377.68, "end": 3381.7999999999997, "text": " And you'll certainly look at Kogan.", "tokens": [400, 291, 603, 3297, 574, 412, 591, 21576, 13], "temperature": 0.0, "avg_logprob": -0.185003609492861, "compression_ratio": 1.5255813953488373, "no_speech_prob": 4.565946710499702e-06}, {"id": 642, "seek": 338180, "start": 3381.8, "end": 3385.6400000000003, "text": " I think a lot of people now know the name Alexander Kogan, he was the guy that handed", "tokens": [286, 519, 257, 688, 295, 561, 586, 458, 264, 1315, 14845, 591, 21576, 11, 415, 390, 264, 2146, 300, 16013], "temperature": 0.0, "avg_logprob": -0.17563449943458642, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.6187330402317457e-05}, {"id": 643, "seek": 338180, "start": 3385.6400000000003, "end": 3389.1200000000003, "text": " over the Cambridge Analytica data.", "tokens": [670, 264, 24876, 23688, 2262, 1412, 13], "temperature": 0.0, "avg_logprob": -0.17563449943458642, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.6187330402317457e-05}, {"id": 644, "seek": 338180, "start": 3389.1200000000003, "end": 3396.7200000000003, "text": " He's a Cambridge academic, now a very famous Cambridge academic the world over for doing", "tokens": [634, 311, 257, 24876, 7778, 11, 586, 257, 588, 4618, 24876, 7778, 264, 1002, 670, 337, 884], "temperature": 0.0, "avg_logprob": -0.17563449943458642, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.6187330402317457e-05}, {"id": 645, "seek": 338180, "start": 3396.7200000000003, "end": 3400.0, "text": " his part to destroy the foundations of democracy.", "tokens": [702, 644, 281, 5293, 264, 22467, 295, 10528, 13], "temperature": 0.0, "avg_logprob": -0.17563449943458642, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.6187330402317457e-05}, {"id": 646, "seek": 338180, "start": 3400.0, "end": 3406.6000000000004, "text": " So this is probably not how we want to go down in history.", "tokens": [407, 341, 307, 1391, 406, 577, 321, 528, 281, 352, 760, 294, 2503, 13], "temperature": 0.0, "avg_logprob": -0.17563449943458642, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.6187330402317457e-05}, {"id": 647, "seek": 338180, "start": 3406.6000000000004, "end": 3409.6000000000004, "text": " So let's have a break before we do.", "tokens": [407, 718, 311, 362, 257, 1821, 949, 321, 360, 13], "temperature": 0.0, "avg_logprob": -0.17563449943458642, "compression_ratio": 1.5945945945945945, "no_speech_prob": 1.6187330402317457e-05}, {"id": 648, "seek": 340960, "start": 3409.6, "end": 3414.44, "text": " Question on a different topic.", "tokens": [14464, 322, 257, 819, 4829, 13], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 649, "seek": 340960, "start": 3414.44, "end": 3417.16, "text": " In one of your tweets you said Dropout is patented.", "tokens": [682, 472, 295, 428, 25671, 291, 848, 17675, 346, 307, 1947, 6003, 13], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 650, "seek": 340960, "start": 3417.16, "end": 3420.58, "text": " I think this is about WaveNet patent from Google.", "tokens": [286, 519, 341, 307, 466, 28530, 31890, 20495, 490, 3329, 13], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 651, "seek": 340960, "start": 3420.58, "end": 3421.58, "text": " What does it mean?", "tokens": [708, 775, 309, 914, 30], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 652, "seek": 340960, "start": 3421.58, "end": 3423.92, "text": " Can you please share more insight on this subject?", "tokens": [1664, 291, 1767, 2073, 544, 11269, 322, 341, 3983, 30], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 653, "seek": 340960, "start": 3423.92, "end": 3427.12, "text": " Does it mean that we'll have to pay to use Dropout in the future?", "tokens": [4402, 309, 914, 300, 321, 603, 362, 281, 1689, 281, 764, 17675, 346, 294, 264, 2027, 30], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 654, "seek": 340960, "start": 3427.12, "end": 3428.6, "text": " Good question.", "tokens": [2205, 1168, 13], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 655, "seek": 340960, "start": 3428.6, "end": 3431.52, "text": " Let's talk about that after the break.", "tokens": [961, 311, 751, 466, 300, 934, 264, 1821, 13], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 656, "seek": 340960, "start": 3431.52, "end": 3435.94, "text": " So let's come back at 7.40.", "tokens": [407, 718, 311, 808, 646, 412, 1614, 13, 5254, 13], "temperature": 0.0, "avg_logprob": -0.20267745164724496, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.00013764416507910937}, {"id": 657, "seek": 343594, "start": 3435.94, "end": 3439.92, "text": " The question before the break was about patents.", "tokens": [440, 1168, 949, 264, 1821, 390, 466, 38142, 13], "temperature": 0.0, "avg_logprob": -0.16332865397135415, "compression_ratio": 1.4, "no_speech_prob": 1.7778111214283854e-05}, {"id": 658, "seek": 343594, "start": 3439.92, "end": 3446.76, "text": " What does it mean?", "tokens": [708, 775, 309, 914, 30], "temperature": 0.0, "avg_logprob": -0.16332865397135415, "compression_ratio": 1.4, "no_speech_prob": 1.7778111214283854e-05}, {"id": 659, "seek": 343594, "start": 3446.76, "end": 3453.16, "text": " So I guess the reason it's coming up was because I wrote a tweet this week, which I think was", "tokens": [407, 286, 2041, 264, 1778, 309, 311, 1348, 493, 390, 570, 286, 4114, 257, 15258, 341, 1243, 11, 597, 286, 519, 390], "temperature": 0.0, "avg_logprob": -0.16332865397135415, "compression_ratio": 1.4, "no_speech_prob": 1.7778111214283854e-05}, {"id": 660, "seek": 343594, "start": 3453.16, "end": 3458.16, "text": " like 3 words, and said Dropout is patented.", "tokens": [411, 805, 2283, 11, 293, 848, 17675, 346, 307, 1947, 6003, 13], "temperature": 0.0, "avg_logprob": -0.16332865397135415, "compression_ratio": 1.4, "no_speech_prob": 1.7778111214283854e-05}, {"id": 661, "seek": 343594, "start": 3458.16, "end": 3463.4, "text": " One of the patent holders is Jeffrey Hinton.", "tokens": [1485, 295, 264, 20495, 29274, 307, 28721, 389, 12442, 13], "temperature": 0.0, "avg_logprob": -0.16332865397135415, "compression_ratio": 1.4, "no_speech_prob": 1.7778111214283854e-05}, {"id": 662, "seek": 343594, "start": 3463.4, "end": 3464.4, "text": " So what?", "tokens": [407, 437, 30], "temperature": 0.0, "avg_logprob": -0.16332865397135415, "compression_ratio": 1.4, "no_speech_prob": 1.7778111214283854e-05}, {"id": 663, "seek": 346440, "start": 3464.4, "end": 3469.6800000000003, "text": " Isn't that great, invention is all about patents.", "tokens": [6998, 380, 300, 869, 11, 22265, 307, 439, 466, 38142, 13], "temperature": 0.0, "avg_logprob": -0.2118602840379737, "compression_ratio": 1.5741626794258374, "no_speech_prob": 3.1201216188492253e-05}, {"id": 664, "seek": 346440, "start": 3469.6800000000003, "end": 3471.8, "text": " My answer is no.", "tokens": [1222, 1867, 307, 572, 13], "temperature": 0.0, "avg_logprob": -0.2118602840379737, "compression_ratio": 1.5741626794258374, "no_speech_prob": 3.1201216188492253e-05}, {"id": 665, "seek": 346440, "start": 3471.8, "end": 3475.36, "text": " Patents have gone wildly crazy.", "tokens": [4379, 791, 362, 2780, 34731, 3219, 13], "temperature": 0.0, "avg_logprob": -0.2118602840379737, "compression_ratio": 1.5741626794258374, "no_speech_prob": 3.1201216188492253e-05}, {"id": 666, "seek": 346440, "start": 3475.36, "end": 3481.48, "text": " The amount of things that are patentable that we talk about every week would be dozens.", "tokens": [440, 2372, 295, 721, 300, 366, 20495, 712, 300, 321, 751, 466, 633, 1243, 576, 312, 18431, 13], "temperature": 0.0, "avg_logprob": -0.2118602840379737, "compression_ratio": 1.5741626794258374, "no_speech_prob": 3.1201216188492253e-05}, {"id": 667, "seek": 346440, "start": 3481.48, "end": 3487.8, "text": " Like it's so easy to come up with a little tweak.", "tokens": [1743, 309, 311, 370, 1858, 281, 808, 493, 365, 257, 707, 29879, 13], "temperature": 0.0, "avg_logprob": -0.2118602840379737, "compression_ratio": 1.5741626794258374, "no_speech_prob": 3.1201216188492253e-05}, {"id": 668, "seek": 346440, "start": 3487.8, "end": 3491.44, "text": " If you turn that into a patent, you stop everybody from using that little tweak for the next", "tokens": [759, 291, 1261, 300, 666, 257, 20495, 11, 291, 1590, 2201, 490, 1228, 300, 707, 29879, 337, 264, 958], "temperature": 0.0, "avg_logprob": -0.2118602840379737, "compression_ratio": 1.5741626794258374, "no_speech_prob": 3.1201216188492253e-05}, {"id": 669, "seek": 349144, "start": 3491.44, "end": 3497.12, "text": " 14 years, and you end up with a situation we have now where everything is patented in", "tokens": [3499, 924, 11, 293, 291, 917, 493, 365, 257, 2590, 321, 362, 586, 689, 1203, 307, 1947, 6003, 294], "temperature": 0.0, "avg_logprob": -0.22039886019123134, "compression_ratio": 1.5376344086021505, "no_speech_prob": 1.2805309779650997e-05}, {"id": 670, "seek": 349144, "start": 3497.12, "end": 3498.12, "text": " 50 different ways.", "tokens": [2625, 819, 2098, 13], "temperature": 0.0, "avg_logprob": -0.22039886019123134, "compression_ratio": 1.5376344086021505, "no_speech_prob": 1.2805309779650997e-05}, {"id": 671, "seek": 349144, "start": 3498.12, "end": 3504.48, "text": " So then you get these patent trolls who have made a very, very good business out of basically", "tokens": [407, 550, 291, 483, 613, 20495, 47749, 567, 362, 1027, 257, 588, 11, 588, 665, 1606, 484, 295, 1936], "temperature": 0.0, "avg_logprob": -0.22039886019123134, "compression_ratio": 1.5376344086021505, "no_speech_prob": 1.2805309779650997e-05}, {"id": 672, "seek": 349144, "start": 3504.48, "end": 3510.56, "text": " buying lots of shitty little patents and then suing anybody who accidentally turned out", "tokens": [6382, 3195, 295, 30748, 707, 38142, 293, 550, 459, 278, 4472, 567, 15715, 3574, 484], "temperature": 0.0, "avg_logprob": -0.22039886019123134, "compression_ratio": 1.5376344086021505, "no_speech_prob": 1.2805309779650997e-05}, {"id": 673, "seek": 351056, "start": 3510.56, "end": 3527.7599999999998, "text": " did that thing, like putting rounded corners on buttons.", "tokens": [630, 300, 551, 11, 411, 3372, 23382, 12413, 322, 9905, 13], "temperature": 0.0, "avg_logprob": -0.2297994749886649, "compression_ratio": 1.2608695652173914, "no_speech_prob": 5.594297363131773e-06}, {"id": 674, "seek": 351056, "start": 3527.7599999999998, "end": 3532.32, "text": " What does it mean for us that a lot of stuff is patented in deep learning?", "tokens": [708, 775, 309, 914, 337, 505, 300, 257, 688, 295, 1507, 307, 1947, 6003, 294, 2452, 2539, 30], "temperature": 0.0, "avg_logprob": -0.2297994749886649, "compression_ratio": 1.2608695652173914, "no_speech_prob": 5.594297363131773e-06}, {"id": 675, "seek": 351056, "start": 3532.32, "end": 3536.72, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.2297994749886649, "compression_ratio": 1.2608695652173914, "no_speech_prob": 5.594297363131773e-06}, {"id": 676, "seek": 353672, "start": 3536.72, "end": 3544.3199999999997, "text": " One theory, like a lot of the main people doing this is Google, and people from Google", "tokens": [1485, 5261, 11, 411, 257, 688, 295, 264, 2135, 561, 884, 341, 307, 3329, 11, 293, 561, 490, 3329], "temperature": 0.0, "avg_logprob": -0.1771307615476234, "compression_ratio": 1.7076271186440677, "no_speech_prob": 1.095302195608383e-05}, {"id": 677, "seek": 353672, "start": 3544.3199999999997, "end": 3550.0, "text": " who reply to this patent tend to assume that Google is doing it because they wanted to", "tokens": [567, 16972, 281, 341, 20495, 3928, 281, 6552, 300, 3329, 307, 884, 309, 570, 436, 1415, 281], "temperature": 0.0, "avg_logprob": -0.1771307615476234, "compression_ratio": 1.7076271186440677, "no_speech_prob": 1.095302195608383e-05}, {"id": 678, "seek": 353672, "start": 3550.0, "end": 3551.0, "text": " have it defensively.", "tokens": [362, 309, 16468, 356, 13], "temperature": 0.0, "avg_logprob": -0.1771307615476234, "compression_ratio": 1.7076271186440677, "no_speech_prob": 1.095302195608383e-05}, {"id": 679, "seek": 353672, "start": 3551.0, "end": 3555.04, "text": " So if somebody sues them, they'll be like don't sue us, we'll sue you back because we", "tokens": [407, 498, 2618, 459, 279, 552, 11, 436, 603, 312, 411, 500, 380, 20416, 505, 11, 321, 603, 20416, 291, 646, 570, 321], "temperature": 0.0, "avg_logprob": -0.1771307615476234, "compression_ratio": 1.7076271186440677, "no_speech_prob": 1.095302195608383e-05}, {"id": 680, "seek": 353672, "start": 3555.04, "end": 3557.6, "text": " have all these patents.", "tokens": [362, 439, 613, 38142, 13], "temperature": 0.0, "avg_logprob": -0.1771307615476234, "compression_ratio": 1.7076271186440677, "no_speech_prob": 1.095302195608383e-05}, {"id": 681, "seek": 353672, "start": 3557.6, "end": 3562.3199999999997, "text": " The problem is that as far as I know, they haven't signed what's called a defensive patent", "tokens": [440, 1154, 307, 300, 382, 1400, 382, 286, 458, 11, 436, 2378, 380, 8175, 437, 311, 1219, 257, 16468, 20495], "temperature": 0.0, "avg_logprob": -0.1771307615476234, "compression_ratio": 1.7076271186440677, "no_speech_prob": 1.095302195608383e-05}, {"id": 682, "seek": 353672, "start": 3562.3199999999997, "end": 3563.3199999999997, "text": " pledge.", "tokens": [26819, 13], "temperature": 0.0, "avg_logprob": -0.1771307615476234, "compression_ratio": 1.7076271186440677, "no_speech_prob": 1.095302195608383e-05}, {"id": 683, "seek": 356332, "start": 3563.32, "end": 3568.48, "text": " Basically you can sign a legally binding document that says our patent portfolio will only be", "tokens": [8537, 291, 393, 1465, 257, 21106, 17359, 4166, 300, 1619, 527, 20495, 12583, 486, 787, 312], "temperature": 0.0, "avg_logprob": -0.175769971764606, "compression_ratio": 1.5942622950819672, "no_speech_prob": 5.422185040515615e-06}, {"id": 684, "seek": 356332, "start": 3568.48, "end": 3571.6800000000003, "text": " used in defense and not offense.", "tokens": [1143, 294, 7654, 293, 406, 17834, 13], "temperature": 0.0, "avg_logprob": -0.175769971764606, "compression_ratio": 1.5942622950819672, "no_speech_prob": 5.422185040515615e-06}, {"id": 685, "seek": 356332, "start": 3571.6800000000003, "end": 3576.7200000000003, "text": " And even if you believe all the management of Google would never turn into a patent troll,", "tokens": [400, 754, 498, 291, 1697, 439, 264, 4592, 295, 3329, 576, 1128, 1261, 666, 257, 20495, 20680, 11], "temperature": 0.0, "avg_logprob": -0.175769971764606, "compression_ratio": 1.5942622950819672, "no_speech_prob": 5.422185040515615e-06}, {"id": 686, "seek": 356332, "start": 3576.7200000000003, "end": 3581.04, "text": " you've got to remember that management changes.", "tokens": [291, 600, 658, 281, 1604, 300, 4592, 2962, 13], "temperature": 0.0, "avg_logprob": -0.175769971764606, "compression_ratio": 1.5942622950819672, "no_speech_prob": 5.422185040515615e-06}, {"id": 687, "seek": 356332, "start": 3581.04, "end": 3589.96, "text": " And to give a specific example, I know the somewhat recent CFO of Google has a much more", "tokens": [400, 281, 976, 257, 2685, 1365, 11, 286, 458, 264, 8344, 5162, 383, 18067, 295, 3329, 575, 257, 709, 544], "temperature": 0.0, "avg_logprob": -0.175769971764606, "compression_ratio": 1.5942622950819672, "no_speech_prob": 5.422185040515615e-06}, {"id": 688, "seek": 356332, "start": 3589.96, "end": 3592.28, "text": " aggressive stance towards the P&L.", "tokens": [10762, 21033, 3030, 264, 430, 5, 43, 13], "temperature": 0.0, "avg_logprob": -0.175769971764606, "compression_ratio": 1.5942622950819672, "no_speech_prob": 5.422185040515615e-06}, {"id": 689, "seek": 359228, "start": 3592.28, "end": 3597.88, "text": " And I don't know, maybe she might decide that they should start monetizing their patents.", "tokens": [400, 286, 500, 380, 458, 11, 1310, 750, 1062, 4536, 300, 436, 820, 722, 15556, 3319, 641, 38142, 13], "temperature": 0.0, "avg_logprob": -0.14815984746461275, "compression_ratio": 1.6485355648535565, "no_speech_prob": 2.5071343770832755e-05}, {"id": 690, "seek": 359228, "start": 3597.88, "end": 3604.0800000000004, "text": " Or maybe the group that made that patent might get spun off and then sold to another company", "tokens": [1610, 1310, 264, 1594, 300, 1027, 300, 20495, 1062, 483, 37038, 766, 293, 550, 3718, 281, 1071, 2237], "temperature": 0.0, "avg_logprob": -0.14815984746461275, "compression_ratio": 1.6485355648535565, "no_speech_prob": 2.5071343770832755e-05}, {"id": 691, "seek": 359228, "start": 3604.0800000000004, "end": 3608.5600000000004, "text": " that might end up in private equity hands and decide to monetize the patents.", "tokens": [300, 1062, 917, 493, 294, 4551, 10769, 2377, 293, 4536, 281, 15556, 1125, 264, 38142, 13], "temperature": 0.0, "avg_logprob": -0.14815984746461275, "compression_ratio": 1.6485355648535565, "no_speech_prob": 2.5071343770832755e-05}, {"id": 692, "seek": 359228, "start": 3608.5600000000004, "end": 3612.8, "text": " So I think it's a problem.", "tokens": [407, 286, 519, 309, 311, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.14815984746461275, "compression_ratio": 1.6485355648535565, "no_speech_prob": 2.5071343770832755e-05}, {"id": 693, "seek": 359228, "start": 3612.8, "end": 3619.92, "text": " There has been a big shift legally recently away from software patents actually having", "tokens": [821, 575, 668, 257, 955, 5513, 21106, 3938, 1314, 490, 4722, 38142, 767, 1419], "temperature": 0.0, "avg_logprob": -0.14815984746461275, "compression_ratio": 1.6485355648535565, "no_speech_prob": 2.5071343770832755e-05}, {"id": 694, "seek": 359228, "start": 3619.92, "end": 3622.2000000000003, "text": " any legal standing.", "tokens": [604, 5089, 4877, 13], "temperature": 0.0, "avg_logprob": -0.14815984746461275, "compression_ratio": 1.6485355648535565, "no_speech_prob": 2.5071343770832755e-05}, {"id": 695, "seek": 362220, "start": 3622.2, "end": 3624.48, "text": " So it's possible that these will all end up thrown out of court.", "tokens": [407, 309, 311, 1944, 300, 613, 486, 439, 917, 493, 11732, 484, 295, 4753, 13], "temperature": 0.0, "avg_logprob": -0.1543308559216951, "compression_ratio": 1.5175879396984924, "no_speech_prob": 3.966962594859069e-06}, {"id": 696, "seek": 362220, "start": 3624.48, "end": 3630.6, "text": " But the reality is that anything but a big company is unlikely to have the financial", "tokens": [583, 264, 4103, 307, 300, 1340, 457, 257, 955, 2237, 307, 17518, 281, 362, 264, 4669], "temperature": 0.0, "avg_logprob": -0.1543308559216951, "compression_ratio": 1.5175879396984924, "no_speech_prob": 3.966962594859069e-06}, {"id": 697, "seek": 362220, "start": 3630.6, "end": 3637.7799999999997, "text": " ability to defend themselves against one of these huge patent trolls.", "tokens": [3485, 281, 8602, 2969, 1970, 472, 295, 613, 2603, 20495, 47749, 13], "temperature": 0.0, "avg_logprob": -0.1543308559216951, "compression_ratio": 1.5175879396984924, "no_speech_prob": 3.966962594859069e-06}, {"id": 698, "seek": 362220, "start": 3637.7799999999997, "end": 3642.72, "text": " So I think it's a problem.", "tokens": [407, 286, 519, 309, 311, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.1543308559216951, "compression_ratio": 1.5175879396984924, "no_speech_prob": 3.966962594859069e-06}, {"id": 699, "seek": 362220, "start": 3642.72, "end": 3648.8799999999997, "text": " You can't avoid using patented stuff if you write code.", "tokens": [509, 393, 380, 5042, 1228, 1947, 6003, 1507, 498, 291, 2464, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1543308559216951, "compression_ratio": 1.5175879396984924, "no_speech_prob": 3.966962594859069e-06}, {"id": 700, "seek": 364888, "start": 3648.88, "end": 3654.36, "text": " I wouldn't be surprised if most lines of code you write have patents on them.", "tokens": [286, 2759, 380, 312, 6100, 498, 881, 3876, 295, 3089, 291, 2464, 362, 38142, 322, 552, 13], "temperature": 0.0, "avg_logprob": -0.15542867448594835, "compression_ratio": 1.6169154228855722, "no_speech_prob": 9.818129001359921e-06}, {"id": 701, "seek": 364888, "start": 3654.36, "end": 3660.48, "text": " So actually funnily enough, the best thing to do is not to study the patents.", "tokens": [407, 767, 1019, 77, 953, 1547, 11, 264, 1151, 551, 281, 360, 307, 406, 281, 2979, 264, 38142, 13], "temperature": 0.0, "avg_logprob": -0.15542867448594835, "compression_ratio": 1.6169154228855722, "no_speech_prob": 9.818129001359921e-06}, {"id": 702, "seek": 364888, "start": 3660.48, "end": 3667.96, "text": " Because if you do and you infringe knowingly, then the penalties are worse.", "tokens": [1436, 498, 291, 360, 293, 291, 1536, 38895, 5276, 356, 11, 550, 264, 35389, 366, 5324, 13], "temperature": 0.0, "avg_logprob": -0.15542867448594835, "compression_ratio": 1.6169154228855722, "no_speech_prob": 9.818129001359921e-06}, {"id": 703, "seek": 364888, "start": 3667.96, "end": 3675.1600000000003, "text": " So the best thing to do is to put your hands in your ears, sing a song, and get back to", "tokens": [407, 264, 1151, 551, 281, 360, 307, 281, 829, 428, 2377, 294, 428, 8798, 11, 1522, 257, 2153, 11, 293, 483, 646, 281], "temperature": 0.0, "avg_logprob": -0.15542867448594835, "compression_ratio": 1.6169154228855722, "no_speech_prob": 9.818129001359921e-06}, {"id": 704, "seek": 364888, "start": 3675.1600000000003, "end": 3677.1600000000003, "text": " work.", "tokens": [589, 13], "temperature": 0.0, "avg_logprob": -0.15542867448594835, "compression_ratio": 1.6169154228855722, "no_speech_prob": 9.818129001359921e-06}, {"id": 705, "seek": 367716, "start": 3677.16, "end": 3690.2999999999997, "text": " So that thing about Dropout's patented, forget I said that, you don't know that.", "tokens": [407, 300, 551, 466, 17675, 346, 311, 1947, 6003, 11, 2870, 286, 848, 300, 11, 291, 500, 380, 458, 300, 13], "temperature": 0.0, "avg_logprob": -0.26889478838121567, "compression_ratio": 1.5026737967914439, "no_speech_prob": 8.267562407127116e-06}, {"id": 706, "seek": 367716, "start": 3690.2999999999997, "end": 3693.7599999999998, "text": " This is super fun, artistic style.", "tokens": [639, 307, 1687, 1019, 11, 17090, 3758, 13], "temperature": 0.0, "avg_logprob": -0.26889478838121567, "compression_ratio": 1.5026737967914439, "no_speech_prob": 8.267562407127116e-06}, {"id": 707, "seek": 367716, "start": 3693.7599999999998, "end": 3698.52, "text": " We're going to go a bit retro here because this is actually the original artistic style", "tokens": [492, 434, 516, 281, 352, 257, 857, 18820, 510, 570, 341, 307, 767, 264, 3380, 17090, 3758], "temperature": 0.0, "avg_logprob": -0.26889478838121567, "compression_ratio": 1.5026737967914439, "no_speech_prob": 8.267562407127116e-06}, {"id": 708, "seek": 367716, "start": 3698.52, "end": 3705.72, "text": " paper and there's been a lot of updates to it, a lot of different approaches.", "tokens": [3035, 293, 456, 311, 668, 257, 688, 295, 9205, 281, 309, 11, 257, 688, 295, 819, 11587, 13], "temperature": 0.0, "avg_logprob": -0.26889478838121567, "compression_ratio": 1.5026737967914439, "no_speech_prob": 8.267562407127116e-06}, {"id": 709, "seek": 370572, "start": 3705.72, "end": 3710.56, "text": " And I actually think in many ways the original is the best.", "tokens": [400, 286, 767, 519, 294, 867, 2098, 264, 3380, 307, 264, 1151, 13], "temperature": 0.0, "avg_logprob": -0.13914255662397904, "compression_ratio": 1.547872340425532, "no_speech_prob": 2.857288791346946e-06}, {"id": 710, "seek": 370572, "start": 3710.56, "end": 3716.2799999999997, "text": " We're going to look at some of the newer approaches as well, but I actually think the original", "tokens": [492, 434, 516, 281, 574, 412, 512, 295, 264, 17628, 11587, 382, 731, 11, 457, 286, 767, 519, 264, 3380], "temperature": 0.0, "avg_logprob": -0.13914255662397904, "compression_ratio": 1.547872340425532, "no_speech_prob": 2.857288791346946e-06}, {"id": 711, "seek": 370572, "start": 3716.2799999999997, "end": 3725.9199999999996, "text": " is a terrific way to do it, even with everything that's gone since.", "tokens": [307, 257, 20899, 636, 281, 360, 309, 11, 754, 365, 1203, 300, 311, 2780, 1670, 13], "temperature": 0.0, "avg_logprob": -0.13914255662397904, "compression_ratio": 1.547872340425532, "no_speech_prob": 2.857288791346946e-06}, {"id": 712, "seek": 370572, "start": 3725.9199999999996, "end": 3727.9199999999996, "text": " Let's just jump to the code.", "tokens": [961, 311, 445, 3012, 281, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.13914255662397904, "compression_ratio": 1.547872340425532, "no_speech_prob": 2.857288791346946e-06}, {"id": 713, "seek": 370572, "start": 3727.9199999999996, "end": 3733.72, "text": " So this is the style transfer notebook.", "tokens": [407, 341, 307, 264, 3758, 5003, 21060, 13], "temperature": 0.0, "avg_logprob": -0.13914255662397904, "compression_ratio": 1.547872340425532, "no_speech_prob": 2.857288791346946e-06}, {"id": 714, "seek": 373372, "start": 3733.72, "end": 3745.04, "text": " So the idea here is that we want to take a photo of this bird and we want to create a", "tokens": [407, 264, 1558, 510, 307, 300, 321, 528, 281, 747, 257, 5052, 295, 341, 5255, 293, 321, 528, 281, 1884, 257], "temperature": 0.0, "avg_logprob": -0.1326109250386556, "compression_ratio": 1.5034482758620689, "no_speech_prob": 3.905412086169235e-06}, {"id": 715, "seek": 373372, "start": 3745.04, "end": 3757.72, "text": " painting that looks like Van Gogh painted the picture of the bird.", "tokens": [5370, 300, 1542, 411, 8979, 39690, 71, 11797, 264, 3036, 295, 264, 5255, 13], "temperature": 0.0, "avg_logprob": -0.1326109250386556, "compression_ratio": 1.5034482758620689, "no_speech_prob": 3.905412086169235e-06}, {"id": 716, "seek": 373372, "start": 3757.72, "end": 3761.24, "text": " Quite a bit of the stuff that I'm doing by the way uses ImageNet.", "tokens": [20464, 257, 857, 295, 264, 1507, 300, 286, 478, 884, 538, 264, 636, 4960, 29903, 31890, 13], "temperature": 0.0, "avg_logprob": -0.1326109250386556, "compression_ratio": 1.5034482758620689, "no_speech_prob": 3.905412086169235e-06}, {"id": 717, "seek": 376124, "start": 3761.24, "end": 3764.4399999999996, "text": " You don't have to download the whole of ImageNet for any of the things I'm doing.", "tokens": [509, 500, 380, 362, 281, 5484, 264, 1379, 295, 29903, 31890, 337, 604, 295, 264, 721, 286, 478, 884, 13], "temperature": 0.0, "avg_logprob": -0.19554184578560493, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.5688932762714103e-05}, {"id": 718, "seek": 376124, "start": 3764.4399999999996, "end": 3769.04, "text": " There's an ImageNet sample on files.fast.ai.", "tokens": [821, 311, 364, 29903, 31890, 6889, 322, 7098, 13, 7011, 13, 1301, 13], "temperature": 0.0, "avg_logprob": -0.19554184578560493, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.5688932762714103e-05}, {"id": 719, "seek": 376124, "start": 3769.04, "end": 3772.0, "text": " Which has a couple of gigs.", "tokens": [3013, 575, 257, 1916, 295, 34586, 13], "temperature": 0.0, "avg_logprob": -0.19554184578560493, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.5688932762714103e-05}, {"id": 720, "seek": 376124, "start": 3772.0, "end": 3774.72, "text": " It should be plenty good enough for everything we're doing.", "tokens": [467, 820, 312, 7140, 665, 1547, 337, 1203, 321, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.19554184578560493, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.5688932762714103e-05}, {"id": 721, "seek": 376124, "start": 3774.72, "end": 3777.6, "text": " If you want to get really great results, you can grab ImageNet.", "tokens": [759, 291, 528, 281, 483, 534, 869, 3542, 11, 291, 393, 4444, 29903, 31890, 13], "temperature": 0.0, "avg_logprob": -0.19554184578560493, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.5688932762714103e-05}, {"id": 722, "seek": 376124, "start": 3777.6, "end": 3780.2, "text": " You can download it from Kaggle.", "tokens": [509, 393, 5484, 309, 490, 48751, 22631, 13], "temperature": 0.0, "avg_logprob": -0.19554184578560493, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.5688932762714103e-05}, {"id": 723, "seek": 376124, "start": 3780.2, "end": 3787.0, "text": " On Kaggle, the localization competition actually contains all of the classification data as", "tokens": [1282, 48751, 22631, 11, 264, 2654, 2144, 6211, 767, 8306, 439, 295, 264, 21538, 1412, 382], "temperature": 0.0, "avg_logprob": -0.19554184578560493, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.5688932762714103e-05}, {"id": 724, "seek": 376124, "start": 3787.0, "end": 3791.12, "text": " well.", "tokens": [731, 13], "temperature": 0.0, "avg_logprob": -0.19554184578560493, "compression_ratio": 1.623015873015873, "no_speech_prob": 1.5688932762714103e-05}, {"id": 725, "seek": 379112, "start": 3791.12, "end": 3796.56, "text": " So if you've got room, it's good to have a copy of ImageNet because it comes in handy", "tokens": [407, 498, 291, 600, 658, 1808, 11, 309, 311, 665, 281, 362, 257, 5055, 295, 29903, 31890, 570, 309, 1487, 294, 13239], "temperature": 0.0, "avg_logprob": -0.10193718873061143, "compression_ratio": 1.5535714285714286, "no_speech_prob": 1.0129897418664768e-05}, {"id": 726, "seek": 379112, "start": 3796.56, "end": 3798.68, "text": " all the time.", "tokens": [439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.10193718873061143, "compression_ratio": 1.5535714285714286, "no_speech_prob": 1.0129897418664768e-05}, {"id": 727, "seek": 379112, "start": 3798.68, "end": 3806.48, "text": " So I just grabbed a bird out of my ImageNet folder and there is my bird.", "tokens": [407, 286, 445, 18607, 257, 5255, 484, 295, 452, 29903, 31890, 10820, 293, 456, 307, 452, 5255, 13], "temperature": 0.0, "avg_logprob": -0.10193718873061143, "compression_ratio": 1.5535714285714286, "no_speech_prob": 1.0129897418664768e-05}, {"id": 728, "seek": 379112, "start": 3806.48, "end": 3814.96, "text": " And so what I'm going to do is I'm going to start with this picture and I'm going to try", "tokens": [400, 370, 437, 286, 478, 516, 281, 360, 307, 286, 478, 516, 281, 722, 365, 341, 3036, 293, 286, 478, 516, 281, 853], "temperature": 0.0, "avg_logprob": -0.10193718873061143, "compression_ratio": 1.5535714285714286, "no_speech_prob": 1.0129897418664768e-05}, {"id": 729, "seek": 381496, "start": 3814.96, "end": 3825.2400000000002, "text": " and make it more and more like a picture of this bird painted by Van Gogh.", "tokens": [293, 652, 309, 544, 293, 544, 411, 257, 3036, 295, 341, 5255, 11797, 538, 8979, 39690, 71, 13], "temperature": 0.0, "avg_logprob": -0.10916010808136503, "compression_ratio": 1.3289473684210527, "no_speech_prob": 1.6797263242551708e-06}, {"id": 730, "seek": 381496, "start": 3825.2400000000002, "end": 3830.16, "text": " And the way I do that is actually very simple.", "tokens": [400, 264, 636, 286, 360, 300, 307, 767, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.10916010808136503, "compression_ratio": 1.3289473684210527, "no_speech_prob": 1.6797263242551708e-06}, {"id": 731, "seek": 381496, "start": 3830.16, "end": 3833.2, "text": " You're all familiar with it.", "tokens": [509, 434, 439, 4963, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.10916010808136503, "compression_ratio": 1.3289473684210527, "no_speech_prob": 1.6797263242551708e-06}, {"id": 732, "seek": 381496, "start": 3833.2, "end": 3843.32, "text": " We will create a loss function, which we'll call f.", "tokens": [492, 486, 1884, 257, 4470, 2445, 11, 597, 321, 603, 818, 283, 13], "temperature": 0.0, "avg_logprob": -0.10916010808136503, "compression_ratio": 1.3289473684210527, "no_speech_prob": 1.6797263242551708e-06}, {"id": 733, "seek": 384332, "start": 3843.32, "end": 3855.2200000000003, "text": " And the loss function is going to take as input a picture and spit out as output a value.", "tokens": [400, 264, 4470, 2445, 307, 516, 281, 747, 382, 4846, 257, 3036, 293, 22127, 484, 382, 5598, 257, 2158, 13], "temperature": 0.0, "avg_logprob": -0.08292879449560288, "compression_ratio": 1.3893129770992367, "no_speech_prob": 5.714997541872435e-07}, {"id": 734, "seek": 384332, "start": 3855.2200000000003, "end": 3870.36, "text": " And the value will be lower if the image looks more like the bird photo painted by Van Gogh.", "tokens": [400, 264, 2158, 486, 312, 3126, 498, 264, 3256, 1542, 544, 411, 264, 5255, 5052, 11797, 538, 8979, 39690, 71, 13], "temperature": 0.0, "avg_logprob": -0.08292879449560288, "compression_ratio": 1.3893129770992367, "no_speech_prob": 5.714997541872435e-07}, {"id": 735, "seek": 387036, "start": 3870.36, "end": 3883.92, "text": " Having written that loss function, we will then use the PyTorch gradient and optimizers", "tokens": [10222, 3720, 300, 4470, 2445, 11, 321, 486, 550, 764, 264, 9953, 51, 284, 339, 16235, 293, 5028, 22525], "temperature": 0.0, "avg_logprob": -0.12787269055843353, "compression_ratio": 1.4727272727272727, "no_speech_prob": 1.9033801663681515e-06}, {"id": 736, "seek": 387036, "start": 3883.92, "end": 3886.6, "text": " times the learning rate.", "tokens": [1413, 264, 2539, 3314, 13], "temperature": 0.0, "avg_logprob": -0.12787269055843353, "compression_ratio": 1.4727272727272727, "no_speech_prob": 1.9033801663681515e-06}, {"id": 737, "seek": 387036, "start": 3886.6, "end": 3889.88, "text": " And we're not going to update any weights.", "tokens": [400, 321, 434, 406, 516, 281, 5623, 604, 17443, 13], "temperature": 0.0, "avg_logprob": -0.12787269055843353, "compression_ratio": 1.4727272727272727, "no_speech_prob": 1.9033801663681515e-06}, {"id": 738, "seek": 387036, "start": 3889.88, "end": 3898.2000000000003, "text": " We're going to update the pixels of the input image to make it a little bit more like a", "tokens": [492, 434, 516, 281, 5623, 264, 18668, 295, 264, 4846, 3256, 281, 652, 309, 257, 707, 857, 544, 411, 257], "temperature": 0.0, "avg_logprob": -0.12787269055843353, "compression_ratio": 1.4727272727272727, "no_speech_prob": 1.9033801663681515e-06}, {"id": 739, "seek": 389820, "start": 3898.2, "end": 3901.7999999999997, "text": " picture which would be a bird painted by Van Gogh.", "tokens": [3036, 597, 576, 312, 257, 5255, 11797, 538, 8979, 39690, 71, 13], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 740, "seek": 389820, "start": 3901.7999999999997, "end": 3907.08, "text": " And we'll stick it through the loss function again to get more gradients and do it again", "tokens": [400, 321, 603, 2897, 309, 807, 264, 4470, 2445, 797, 281, 483, 544, 2771, 2448, 293, 360, 309, 797], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 741, "seek": 389820, "start": 3907.08, "end": 3909.04, "text": " and again.", "tokens": [293, 797, 13], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 742, "seek": 389820, "start": 3909.04, "end": 3910.04, "text": " And that's it.", "tokens": [400, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 743, "seek": 389820, "start": 3910.04, "end": 3914.8399999999997, "text": " So it's like identical to how we solve every problem.", "tokens": [407, 309, 311, 411, 14800, 281, 577, 321, 5039, 633, 1154, 13], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 744, "seek": 389820, "start": 3914.8399999999997, "end": 3916.24, "text": " You know I'm a one-trick pony, right?", "tokens": [509, 458, 286, 478, 257, 472, 12, 6903, 618, 27342, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 745, "seek": 389820, "start": 3916.24, "end": 3919.56, "text": " This is my only trick.", "tokens": [639, 307, 452, 787, 4282, 13], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 746, "seek": 389820, "start": 3919.56, "end": 3923.2799999999997, "text": " Create a loss function, use it to get some gradients, multiply it by learning rates to", "tokens": [20248, 257, 4470, 2445, 11, 764, 309, 281, 483, 512, 2771, 2448, 11, 12972, 309, 538, 2539, 6846, 281], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 747, "seek": 389820, "start": 3923.2799999999997, "end": 3925.0, "text": " update something.", "tokens": [5623, 746, 13], "temperature": 0.0, "avg_logprob": -0.1624347312109811, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.530289051122963e-06}, {"id": 748, "seek": 392500, "start": 3925.0, "end": 3929.44, "text": " Always before, we've updated weights in a model.", "tokens": [11270, 949, 11, 321, 600, 10588, 17443, 294, 257, 2316, 13], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 749, "seek": 392500, "start": 3929.44, "end": 3931.16, "text": " But today we're not going to do that.", "tokens": [583, 965, 321, 434, 406, 516, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 750, "seek": 392500, "start": 3931.16, "end": 3935.68, "text": " We're going to update the pixels in the input.", "tokens": [492, 434, 516, 281, 5623, 264, 18668, 294, 264, 4846, 13], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 751, "seek": 392500, "start": 3935.68, "end": 3938.72, "text": " But it's no different at all.", "tokens": [583, 309, 311, 572, 819, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 752, "seek": 392500, "start": 3938.72, "end": 3942.4, "text": " We're just taking the gradient with respect to the input rather than with respect to the", "tokens": [492, 434, 445, 1940, 264, 16235, 365, 3104, 281, 264, 4846, 2831, 813, 365, 3104, 281, 264], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 753, "seek": 392500, "start": 3942.4, "end": 3943.4, "text": " weights.", "tokens": [17443, 13], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 754, "seek": 392500, "start": 3943.4, "end": 3947.32, "text": " That's it.", "tokens": [663, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 755, "seek": 392500, "start": 3947.32, "end": 3949.64, "text": " So we're nearly done.", "tokens": [407, 321, 434, 6217, 1096, 13], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 756, "seek": 392500, "start": 3949.64, "end": 3951.82, "text": " Let's do a couple more things.", "tokens": [961, 311, 360, 257, 1916, 544, 721, 13], "temperature": 0.0, "avg_logprob": -0.2107130424263551, "compression_ratio": 1.6331658291457287, "no_speech_prob": 2.3320694708672818e-06}, {"id": 757, "seek": 395182, "start": 3951.82, "end": 3958.86, "text": " Let's mention here that there's going to be two more inputs to our loss function.", "tokens": [961, 311, 2152, 510, 300, 456, 311, 516, 281, 312, 732, 544, 15743, 281, 527, 4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1944411487902625, "compression_ratio": 1.4142857142857144, "no_speech_prob": 5.173846147954464e-06}, {"id": 758, "seek": 395182, "start": 3958.86, "end": 3961.48, "text": " One is the picture of the bird.", "tokens": [1485, 307, 264, 3036, 295, 264, 5255, 13], "temperature": 0.0, "avg_logprob": -0.1944411487902625, "compression_ratio": 1.4142857142857144, "no_speech_prob": 5.173846147954464e-06}, {"id": 759, "seek": 395182, "start": 3961.48, "end": 3967.44, "text": " Birds look like this.", "tokens": [41456, 574, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1944411487902625, "compression_ratio": 1.4142857142857144, "no_speech_prob": 5.173846147954464e-06}, {"id": 760, "seek": 395182, "start": 3967.44, "end": 3973.7000000000003, "text": " And the second is an artwork by Van Gogh.", "tokens": [400, 264, 1150, 307, 364, 15829, 538, 8979, 39690, 71, 13], "temperature": 0.0, "avg_logprob": -0.1944411487902625, "compression_ratio": 1.4142857142857144, "no_speech_prob": 5.173846147954464e-06}, {"id": 761, "seek": 395182, "start": 3973.7000000000003, "end": 3976.28, "text": " They look like this.", "tokens": [814, 574, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1944411487902625, "compression_ratio": 1.4142857142857144, "no_speech_prob": 5.173846147954464e-06}, {"id": 762, "seek": 397628, "start": 3976.28, "end": 3986.4, "text": " And of course, there we go.", "tokens": [400, 295, 1164, 11, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.15913021242296374, "compression_ratio": 1.4739884393063585, "no_speech_prob": 1.3709519635085599e-06}, {"id": 763, "seek": 397628, "start": 3986.4, "end": 3990.88, "text": " And by having those as inputs as well, that means we'll be able to rerun the function", "tokens": [400, 538, 1419, 729, 382, 15743, 382, 731, 11, 300, 1355, 321, 603, 312, 1075, 281, 43819, 409, 264, 2445], "temperature": 0.0, "avg_logprob": -0.15913021242296374, "compression_ratio": 1.4739884393063585, "no_speech_prob": 1.3709519635085599e-06}, {"id": 764, "seek": 397628, "start": 3990.88, "end": 4000.92, "text": " later to make it look like a bird painted by Monet or a jumbo jet painted by Van Gogh", "tokens": [1780, 281, 652, 309, 574, 411, 257, 5255, 11797, 538, 47871, 420, 257, 29067, 1763, 14452, 11797, 538, 8979, 39690, 71], "temperature": 0.0, "avg_logprob": -0.15913021242296374, "compression_ratio": 1.4739884393063585, "no_speech_prob": 1.3709519635085599e-06}, {"id": 765, "seek": 397628, "start": 4000.92, "end": 4002.3, "text": " or whatever.", "tokens": [420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.15913021242296374, "compression_ratio": 1.4739884393063585, "no_speech_prob": 1.3709519635085599e-06}, {"id": 766, "seek": 397628, "start": 4002.3, "end": 4005.32, "text": " So those are going to be the three inputs.", "tokens": [407, 729, 366, 516, 281, 312, 264, 1045, 15743, 13], "temperature": 0.0, "avg_logprob": -0.15913021242296374, "compression_ratio": 1.4739884393063585, "no_speech_prob": 1.3709519635085599e-06}, {"id": 767, "seek": 400532, "start": 4005.32, "end": 4010.6000000000004, "text": " And so initially, as we discussed, our input here, this is going to be the first time I've", "tokens": [400, 370, 9105, 11, 382, 321, 7152, 11, 527, 4846, 510, 11, 341, 307, 516, 281, 312, 264, 700, 565, 286, 600], "temperature": 0.0, "avg_logprob": -0.16698365462453743, "compression_ratio": 1.4375, "no_speech_prob": 9.516054888081271e-06}, {"id": 768, "seek": 400532, "start": 4010.6000000000004, "end": 4021.6000000000004, "text": " ever found the rainbow pen useful.", "tokens": [1562, 1352, 264, 18526, 3435, 4420, 13], "temperature": 0.0, "avg_logprob": -0.16698365462453743, "compression_ratio": 1.4375, "no_speech_prob": 9.516054888081271e-06}, {"id": 769, "seek": 400532, "start": 4021.6000000000004, "end": 4025.36, "text": " So we start with some random noise, use the loss function, get the gradients, make it", "tokens": [407, 321, 722, 365, 512, 4974, 5658, 11, 764, 264, 4470, 2445, 11, 483, 264, 2771, 2448, 11, 652, 309], "temperature": 0.0, "avg_logprob": -0.16698365462453743, "compression_ratio": 1.4375, "no_speech_prob": 9.516054888081271e-06}, {"id": 770, "seek": 400532, "start": 4025.36, "end": 4029.6800000000003, "text": " a little bit more like a bird painted by Van Gogh, and so forth.", "tokens": [257, 707, 857, 544, 411, 257, 5255, 11797, 538, 8979, 39690, 71, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.16698365462453743, "compression_ratio": 1.4375, "no_speech_prob": 9.516054888081271e-06}, {"id": 771, "seek": 402968, "start": 4029.68, "end": 4036.64, "text": " So the only outstanding question, which I guess we can talk about briefly, is how we", "tokens": [407, 264, 787, 14485, 1168, 11, 597, 286, 2041, 321, 393, 751, 466, 10515, 11, 307, 577, 321], "temperature": 0.0, "avg_logprob": -0.1404007077217102, "compression_ratio": 1.478527607361963, "no_speech_prob": 3.5763554251388996e-07}, {"id": 772, "seek": 402968, "start": 4036.64, "end": 4045.5, "text": " calculate how much our image looks like this bird painted by Van Gogh.", "tokens": [8873, 577, 709, 527, 3256, 1542, 411, 341, 5255, 11797, 538, 8979, 39690, 71, 13], "temperature": 0.0, "avg_logprob": -0.1404007077217102, "compression_ratio": 1.478527607361963, "no_speech_prob": 3.5763554251388996e-07}, {"id": 773, "seek": 402968, "start": 4045.5, "end": 4048.8799999999997, "text": " So let's split it into two parts.", "tokens": [407, 718, 311, 7472, 309, 666, 732, 3166, 13], "temperature": 0.0, "avg_logprob": -0.1404007077217102, "compression_ratio": 1.478527607361963, "no_speech_prob": 3.5763554251388996e-07}, {"id": 774, "seek": 402968, "start": 4048.8799999999997, "end": 4056.4199999999996, "text": " Let's split it into a part called the content loss.", "tokens": [961, 311, 7472, 309, 666, 257, 644, 1219, 264, 2701, 4470, 13], "temperature": 0.0, "avg_logprob": -0.1404007077217102, "compression_ratio": 1.478527607361963, "no_speech_prob": 3.5763554251388996e-07}, {"id": 775, "seek": 405642, "start": 4056.42, "end": 4067.56, "text": " And that's going to return a value that's lower if it looks more like the bird.", "tokens": [400, 300, 311, 516, 281, 2736, 257, 2158, 300, 311, 3126, 498, 309, 1542, 544, 411, 264, 5255, 13], "temperature": 0.0, "avg_logprob": -0.10996496452475493, "compression_ratio": 1.4420289855072463, "no_speech_prob": 2.2603107936447486e-06}, {"id": 776, "seek": 405642, "start": 4067.56, "end": 4076.16, "text": " Not just any bird, the specific bird that we had coming in.", "tokens": [1726, 445, 604, 5255, 11, 264, 2685, 5255, 300, 321, 632, 1348, 294, 13], "temperature": 0.0, "avg_logprob": -0.10996496452475493, "compression_ratio": 1.4420289855072463, "no_speech_prob": 2.2603107936447486e-06}, {"id": 777, "seek": 405642, "start": 4076.16, "end": 4081.28, "text": " And then let's also create something called the style loss.", "tokens": [400, 550, 718, 311, 611, 1884, 746, 1219, 264, 3758, 4470, 13], "temperature": 0.0, "avg_logprob": -0.10996496452475493, "compression_ratio": 1.4420289855072463, "no_speech_prob": 2.2603107936447486e-06}, {"id": 778, "seek": 408128, "start": 4081.28, "end": 4102.320000000001, "text": " And that's going to be a lower number if the image is more like Van Gogh's style.", "tokens": [400, 300, 311, 516, 281, 312, 257, 3126, 1230, 498, 264, 3256, 307, 544, 411, 8979, 39690, 71, 311, 3758, 13], "temperature": 0.0, "avg_logprob": -0.06272547744041265, "compression_ratio": 1.226890756302521, "no_speech_prob": 1.0030123576143524e-06}, {"id": 779, "seek": 408128, "start": 4102.320000000001, "end": 4107.360000000001, "text": " So there's one way to do the content loss, which is very simple.", "tokens": [407, 456, 311, 472, 636, 281, 360, 264, 2701, 4470, 11, 597, 307, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.06272547744041265, "compression_ratio": 1.226890756302521, "no_speech_prob": 1.0030123576143524e-06}, {"id": 780, "seek": 410736, "start": 4107.36, "end": 4112.839999999999, "text": " We could look at the pixels of the output, compare them to the pixels of the bird, and", "tokens": [492, 727, 574, 412, 264, 18668, 295, 264, 5598, 11, 6794, 552, 281, 264, 18668, 295, 264, 5255, 11, 293], "temperature": 0.0, "avg_logprob": -0.11099876547759434, "compression_ratio": 1.701834862385321, "no_speech_prob": 6.85426130075939e-06}, {"id": 781, "seek": 410736, "start": 4112.839999999999, "end": 4116.96, "text": " do a mean squared error, add them up.", "tokens": [360, 257, 914, 8889, 6713, 11, 909, 552, 493, 13], "temperature": 0.0, "avg_logprob": -0.11099876547759434, "compression_ratio": 1.701834862385321, "no_speech_prob": 6.85426130075939e-06}, {"id": 782, "seek": 410736, "start": 4116.96, "end": 4124.2, "text": " So if we did that, I ran this for a while, eventually our image would turn into an image", "tokens": [407, 498, 321, 630, 300, 11, 286, 5872, 341, 337, 257, 1339, 11, 4728, 527, 3256, 576, 1261, 666, 364, 3256], "temperature": 0.0, "avg_logprob": -0.11099876547759434, "compression_ratio": 1.701834862385321, "no_speech_prob": 6.85426130075939e-06}, {"id": 783, "seek": 410736, "start": 4124.2, "end": 4126.28, "text": " of the bird.", "tokens": [295, 264, 5255, 13], "temperature": 0.0, "avg_logprob": -0.11099876547759434, "compression_ratio": 1.701834862385321, "no_speech_prob": 6.85426130075939e-06}, {"id": 784, "seek": 410736, "start": 4126.28, "end": 4127.28, "text": " You should try it.", "tokens": [509, 820, 853, 309, 13], "temperature": 0.0, "avg_logprob": -0.11099876547759434, "compression_ratio": 1.701834862385321, "no_speech_prob": 6.85426130075939e-06}, {"id": 785, "seek": 410736, "start": 4127.28, "end": 4130.28, "text": " You should try this as an exercise.", "tokens": [509, 820, 853, 341, 382, 364, 5380, 13], "temperature": 0.0, "avg_logprob": -0.11099876547759434, "compression_ratio": 1.701834862385321, "no_speech_prob": 6.85426130075939e-06}, {"id": 786, "seek": 410736, "start": 4130.28, "end": 4135.88, "text": " Try to use the optimizer in PyTorch to start with a random image and turn it into another", "tokens": [6526, 281, 764, 264, 5028, 6545, 294, 9953, 51, 284, 339, 281, 722, 365, 257, 4974, 3256, 293, 1261, 309, 666, 1071], "temperature": 0.0, "avg_logprob": -0.11099876547759434, "compression_ratio": 1.701834862385321, "no_speech_prob": 6.85426130075939e-06}, {"id": 787, "seek": 413588, "start": 4135.88, "end": 4140.4400000000005, "text": " image by using mean squared error pixel loss.", "tokens": [3256, 538, 1228, 914, 8889, 6713, 19261, 4470, 13], "temperature": 0.0, "avg_logprob": -0.15815950162482983, "compression_ratio": 1.5112359550561798, "no_speech_prob": 4.289320258976659e-06}, {"id": 788, "seek": 413588, "start": 4140.4400000000005, "end": 4146.24, "text": " Not terribly exciting, but that would be step one.", "tokens": [1726, 22903, 4670, 11, 457, 300, 576, 312, 1823, 472, 13], "temperature": 0.0, "avg_logprob": -0.15815950162482983, "compression_ratio": 1.5112359550561798, "no_speech_prob": 4.289320258976659e-06}, {"id": 789, "seek": 413588, "start": 4146.24, "end": 4152.88, "text": " The problem is, even if we already had our style loss function working beautifully, and", "tokens": [440, 1154, 307, 11, 754, 498, 321, 1217, 632, 527, 3758, 4470, 2445, 1364, 16525, 11, 293], "temperature": 0.0, "avg_logprob": -0.15815950162482983, "compression_ratio": 1.5112359550561798, "no_speech_prob": 4.289320258976659e-06}, {"id": 790, "seek": 413588, "start": 4152.88, "end": 4160.08, "text": " then presumably what we're going to do is we're going to add these two together, and", "tokens": [550, 26742, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 909, 613, 732, 1214, 11, 293], "temperature": 0.0, "avg_logprob": -0.15815950162482983, "compression_ratio": 1.5112359550561798, "no_speech_prob": 4.289320258976659e-06}, {"id": 791, "seek": 416008, "start": 4160.08, "end": 4168.48, "text": " then one of them we'll multiply by some lambda to adjust some number we'll pick to adjust", "tokens": [550, 472, 295, 552, 321, 603, 12972, 538, 512, 13607, 281, 4369, 512, 1230, 321, 603, 1888, 281, 4369], "temperature": 0.0, "avg_logprob": -0.16351802223607115, "compression_ratio": 1.7161572052401746, "no_speech_prob": 2.8573065264936304e-06}, {"id": 792, "seek": 416008, "start": 4168.48, "end": 4171.88, "text": " how much style versus how much content.", "tokens": [577, 709, 3758, 5717, 577, 709, 2701, 13], "temperature": 0.0, "avg_logprob": -0.16351802223607115, "compression_ratio": 1.7161572052401746, "no_speech_prob": 2.8573065264936304e-06}, {"id": 793, "seek": 416008, "start": 4171.88, "end": 4176.2, "text": " So assuming we had a style loss, we picked some sensible lambda, if we used a pixel-wise", "tokens": [407, 11926, 321, 632, 257, 3758, 4470, 11, 321, 6183, 512, 25380, 13607, 11, 498, 321, 1143, 257, 19261, 12, 3711], "temperature": 0.0, "avg_logprob": -0.16351802223607115, "compression_ratio": 1.7161572052401746, "no_speech_prob": 2.8573065264936304e-06}, {"id": 794, "seek": 416008, "start": 4176.2, "end": 4182.24, "text": " content loss, then anything that makes it look more like Van Gogh and less like the", "tokens": [2701, 4470, 11, 550, 1340, 300, 1669, 309, 574, 544, 411, 8979, 39690, 71, 293, 1570, 411, 264], "temperature": 0.0, "avg_logprob": -0.16351802223607115, "compression_ratio": 1.7161572052401746, "no_speech_prob": 2.8573065264936304e-06}, {"id": 795, "seek": 416008, "start": 4182.24, "end": 4189.5199999999995, "text": " exact photo, the exact background, the exact contrast, lighting, everything, will decrease", "tokens": [1900, 5052, 11, 264, 1900, 3678, 11, 264, 1900, 8712, 11, 9577, 11, 1203, 11, 486, 11514], "temperature": 0.0, "avg_logprob": -0.16351802223607115, "compression_ratio": 1.7161572052401746, "no_speech_prob": 2.8573065264936304e-06}, {"id": 796, "seek": 418952, "start": 4189.52, "end": 4193.040000000001, "text": " the content loss, which is not what we want.", "tokens": [264, 2701, 4470, 11, 597, 307, 406, 437, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.12626920287142096, "compression_ratio": 1.7591623036649215, "no_speech_prob": 2.9480124794645235e-06}, {"id": 797, "seek": 418952, "start": 4193.040000000001, "end": 4200.320000000001, "text": " We want it to look like the bird, but not in the same way.", "tokens": [492, 528, 309, 281, 574, 411, 264, 5255, 11, 457, 406, 294, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.12626920287142096, "compression_ratio": 1.7591623036649215, "no_speech_prob": 2.9480124794645235e-06}, {"id": 798, "seek": 418952, "start": 4200.320000000001, "end": 4204.0, "text": " It's still going to have the same two eyes in the same place and be the same kind of", "tokens": [467, 311, 920, 516, 281, 362, 264, 912, 732, 2575, 294, 264, 912, 1081, 293, 312, 264, 912, 733, 295], "temperature": 0.0, "avg_logprob": -0.12626920287142096, "compression_ratio": 1.7591623036649215, "no_speech_prob": 2.9480124794645235e-06}, {"id": 799, "seek": 418952, "start": 4204.0, "end": 4209.52, "text": " shape and so forth, but not the same representation.", "tokens": [3909, 293, 370, 5220, 11, 457, 406, 264, 912, 10290, 13], "temperature": 0.0, "avg_logprob": -0.12626920287142096, "compression_ratio": 1.7591623036649215, "no_speech_prob": 2.9480124794645235e-06}, {"id": 800, "seek": 418952, "start": 4209.52, "end": 4214.96, "text": " So what we're going to do is, this is going to shock you, we're going to use a neural", "tokens": [407, 437, 321, 434, 516, 281, 360, 307, 11, 341, 307, 516, 281, 5588, 291, 11, 321, 434, 516, 281, 764, 257, 18161], "temperature": 0.0, "avg_logprob": -0.12626920287142096, "compression_ratio": 1.7591623036649215, "no_speech_prob": 2.9480124794645235e-06}, {"id": 801, "seek": 418952, "start": 4214.96, "end": 4215.96, "text": " network.", "tokens": [3209, 13], "temperature": 0.0, "avg_logprob": -0.12626920287142096, "compression_ratio": 1.7591623036649215, "no_speech_prob": 2.9480124794645235e-06}, {"id": 802, "seek": 421596, "start": 4215.96, "end": 4222.92, "text": " I totally meant that to be black and it came out green.", "tokens": [286, 3879, 4140, 300, 281, 312, 2211, 293, 309, 1361, 484, 3092, 13], "temperature": 0.0, "avg_logprob": -0.17871775892045763, "compression_ratio": 1.4692737430167597, "no_speech_prob": 7.527899924753001e-06}, {"id": 803, "seek": 421596, "start": 4222.92, "end": 4228.36, "text": " It's always a black box.", "tokens": [467, 311, 1009, 257, 2211, 2424, 13], "temperature": 0.0, "avg_logprob": -0.17871775892045763, "compression_ratio": 1.4692737430167597, "no_speech_prob": 7.527899924753001e-06}, {"id": 804, "seek": 421596, "start": 4228.36, "end": 4233.4800000000005, "text": " And we're going to use the VGG neural network because that's what I used last year and I", "tokens": [400, 321, 434, 516, 281, 764, 264, 691, 27561, 18161, 3209, 570, 300, 311, 437, 286, 1143, 1036, 1064, 293, 286], "temperature": 0.0, "avg_logprob": -0.17871775892045763, "compression_ratio": 1.4692737430167597, "no_speech_prob": 7.527899924753001e-06}, {"id": 805, "seek": 421596, "start": 4233.4800000000005, "end": 4240.08, "text": " didn't have time to see if other things worked, so you can try that yourself during the week.", "tokens": [994, 380, 362, 565, 281, 536, 498, 661, 721, 2732, 11, 370, 291, 393, 853, 300, 1803, 1830, 264, 1243, 13], "temperature": 0.0, "avg_logprob": -0.17871775892045763, "compression_ratio": 1.4692737430167597, "no_speech_prob": 7.527899924753001e-06}, {"id": 806, "seek": 424008, "start": 4240.08, "end": 4249.32, "text": " And the VGG network is something which takes in an input and sticks it through a number", "tokens": [400, 264, 691, 27561, 3209, 307, 746, 597, 2516, 294, 364, 4846, 293, 12518, 309, 807, 257, 1230], "temperature": 0.0, "avg_logprob": -0.16315284067270708, "compression_ratio": 1.5495495495495495, "no_speech_prob": 3.2377431580243865e-06}, {"id": 807, "seek": 424008, "start": 4249.32, "end": 4252.84, "text": " of layers.", "tokens": [295, 7914, 13], "temperature": 0.0, "avg_logprob": -0.16315284067270708, "compression_ratio": 1.5495495495495495, "no_speech_prob": 3.2377431580243865e-06}, {"id": 808, "seek": 424008, "start": 4252.84, "end": 4256.0, "text": " And I'm just going to treat these as just the convolutional layers, there's obviously", "tokens": [400, 286, 478, 445, 516, 281, 2387, 613, 382, 445, 264, 45216, 304, 7914, 11, 456, 311, 2745], "temperature": 0.0, "avg_logprob": -0.16315284067270708, "compression_ratio": 1.5495495495495495, "no_speech_prob": 3.2377431580243865e-06}, {"id": 809, "seek": 424008, "start": 4256.0, "end": 4263.8, "text": " ReLU there, and if it's a VGG with batch norm, which most are today, then it's also got batch", "tokens": [1300, 43, 52, 456, 11, 293, 498, 309, 311, 257, 691, 27561, 365, 15245, 2026, 11, 597, 881, 366, 965, 11, 550, 309, 311, 611, 658, 15245], "temperature": 0.0, "avg_logprob": -0.16315284067270708, "compression_ratio": 1.5495495495495495, "no_speech_prob": 3.2377431580243865e-06}, {"id": 810, "seek": 424008, "start": 4263.8, "end": 4264.8, "text": " norm.", "tokens": [2026, 13], "temperature": 0.0, "avg_logprob": -0.16315284067270708, "compression_ratio": 1.5495495495495495, "no_speech_prob": 3.2377431580243865e-06}, {"id": 811, "seek": 424008, "start": 4264.8, "end": 4269.38, "text": " And there's some max pooling and so forth, but that's fine.", "tokens": [400, 456, 311, 512, 11469, 7005, 278, 293, 370, 5220, 11, 457, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.16315284067270708, "compression_ratio": 1.5495495495495495, "no_speech_prob": 3.2377431580243865e-06}, {"id": 812, "seek": 426938, "start": 4269.38, "end": 4280.32, "text": " What we could do is we could take one of these convolutional activations and then rather", "tokens": [708, 321, 727, 360, 307, 321, 727, 747, 472, 295, 613, 45216, 304, 2430, 763, 293, 550, 2831], "temperature": 0.0, "avg_logprob": -0.09747599446496298, "compression_ratio": 1.4836065573770492, "no_speech_prob": 3.785299441005918e-06}, {"id": 813, "seek": 426938, "start": 4280.32, "end": 4292.8, "text": " than comparing the pixels of this bird, we could instead compare the VGG layer 5 activations", "tokens": [813, 15763, 264, 18668, 295, 341, 5255, 11, 321, 727, 2602, 6794, 264, 691, 27561, 4583, 1025, 2430, 763], "temperature": 0.0, "avg_logprob": -0.09747599446496298, "compression_ratio": 1.4836065573770492, "no_speech_prob": 3.785299441005918e-06}, {"id": 814, "seek": 429280, "start": 4292.8, "end": 4300.52, "text": " of this to the VGG layer 5 activations of our original bird, or layer 6 or layer 7 or", "tokens": [295, 341, 281, 264, 691, 27561, 4583, 1025, 2430, 763, 295, 527, 3380, 5255, 11, 420, 4583, 1386, 420, 4583, 1614, 420], "temperature": 0.0, "avg_logprob": -0.16732833311729825, "compression_ratio": 1.6966824644549763, "no_speech_prob": 2.36878850046196e-06}, {"id": 815, "seek": 429280, "start": 4300.52, "end": 4301.64, "text": " whatever.", "tokens": [2035, 13], "temperature": 0.0, "avg_logprob": -0.16732833311729825, "compression_ratio": 1.6966824644549763, "no_speech_prob": 2.36878850046196e-06}, {"id": 816, "seek": 429280, "start": 4301.64, "end": 4304.16, "text": " So why might that be more interesting?", "tokens": [407, 983, 1062, 300, 312, 544, 1880, 30], "temperature": 0.0, "avg_logprob": -0.16732833311729825, "compression_ratio": 1.6966824644549763, "no_speech_prob": 2.36878850046196e-06}, {"id": 817, "seek": 429280, "start": 4304.16, "end": 4309.88, "text": " Well for one thing, it wouldn't be the same bird, it wouldn't be exactly the same, because", "tokens": [1042, 337, 472, 551, 11, 309, 2759, 380, 312, 264, 912, 5255, 11, 309, 2759, 380, 312, 2293, 264, 912, 11, 570], "temperature": 0.0, "avg_logprob": -0.16732833311729825, "compression_ratio": 1.6966824644549763, "no_speech_prob": 2.36878850046196e-06}, {"id": 818, "seek": 429280, "start": 4309.88, "end": 4313.52, "text": " we're not checking the pixels, we're checking some later set of activations.", "tokens": [321, 434, 406, 8568, 264, 18668, 11, 321, 434, 8568, 512, 1780, 992, 295, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.16732833311729825, "compression_ratio": 1.6966824644549763, "no_speech_prob": 2.36878850046196e-06}, {"id": 819, "seek": 429280, "start": 4313.52, "end": 4317.320000000001, "text": " And so what do those later sets of activations contain?", "tokens": [400, 370, 437, 360, 729, 1780, 6352, 295, 2430, 763, 5304, 30], "temperature": 0.0, "avg_logprob": -0.16732833311729825, "compression_ratio": 1.6966824644549763, "no_speech_prob": 2.36878850046196e-06}, {"id": 820, "seek": 431732, "start": 4317.32, "end": 4323.24, "text": " Well assuming it's after some max pooling, they contain a smaller grid, so it's less", "tokens": [1042, 11926, 309, 311, 934, 512, 11469, 7005, 278, 11, 436, 5304, 257, 4356, 10748, 11, 370, 309, 311, 1570], "temperature": 0.0, "avg_logprob": -0.12133391872867123, "compression_ratio": 1.792929292929293, "no_speech_prob": 2.190770601373515e-06}, {"id": 821, "seek": 431732, "start": 4323.24, "end": 4325.799999999999, "text": " specific about where things are.", "tokens": [2685, 466, 689, 721, 366, 13], "temperature": 0.0, "avg_logprob": -0.12133391872867123, "compression_ratio": 1.792929292929293, "no_speech_prob": 2.190770601373515e-06}, {"id": 822, "seek": 431732, "start": 4325.799999999999, "end": 4331.08, "text": " And rather than containing pixel color values, they're more like semantic things, like is", "tokens": [400, 2831, 813, 19273, 19261, 2017, 4190, 11, 436, 434, 544, 411, 47982, 721, 11, 411, 307], "temperature": 0.0, "avg_logprob": -0.12133391872867123, "compression_ratio": 1.792929292929293, "no_speech_prob": 2.190770601373515e-06}, {"id": 823, "seek": 431732, "start": 4331.08, "end": 4336.12, "text": " this kind of like an eyeball, or is this kind of furry, or is this kind of bright, or is", "tokens": [341, 733, 295, 411, 364, 38868, 11, 420, 307, 341, 733, 295, 47073, 11, 420, 307, 341, 733, 295, 4730, 11, 420, 307], "temperature": 0.0, "avg_logprob": -0.12133391872867123, "compression_ratio": 1.792929292929293, "no_speech_prob": 2.190770601373515e-06}, {"id": 824, "seek": 431732, "start": 4336.12, "end": 4342.0199999999995, "text": " this kind of reflective, or is this laying flat, whatever.", "tokens": [341, 733, 295, 28931, 11, 420, 307, 341, 14903, 4962, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.12133391872867123, "compression_ratio": 1.792929292929293, "no_speech_prob": 2.190770601373515e-06}, {"id": 825, "seek": 434202, "start": 4342.02, "end": 4349.64, "text": " So we would hope that there's some level of semantic features through those layers where", "tokens": [407, 321, 576, 1454, 300, 456, 311, 512, 1496, 295, 47982, 4122, 807, 729, 7914, 689], "temperature": 0.0, "avg_logprob": -0.09722659754198651, "compression_ratio": 1.7715736040609138, "no_speech_prob": 2.406095063633984e-06}, {"id": 826, "seek": 434202, "start": 4349.64, "end": 4356.240000000001, "text": " if we get something, a picture that matches those activations, then any picture that matches", "tokens": [498, 321, 483, 746, 11, 257, 3036, 300, 10676, 729, 2430, 763, 11, 550, 604, 3036, 300, 10676], "temperature": 0.0, "avg_logprob": -0.09722659754198651, "compression_ratio": 1.7715736040609138, "no_speech_prob": 2.406095063633984e-06}, {"id": 827, "seek": 434202, "start": 4356.240000000001, "end": 4364.76, "text": " those activations looks like the bird, but it's not the same representation of the bird.", "tokens": [729, 2430, 763, 1542, 411, 264, 5255, 11, 457, 309, 311, 406, 264, 912, 10290, 295, 264, 5255, 13], "temperature": 0.0, "avg_logprob": -0.09722659754198651, "compression_ratio": 1.7715736040609138, "no_speech_prob": 2.406095063633984e-06}, {"id": 828, "seek": 434202, "start": 4364.76, "end": 4366.0, "text": " So that's what we're going to do.", "tokens": [407, 300, 311, 437, 321, 434, 516, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.09722659754198651, "compression_ratio": 1.7715736040609138, "no_speech_prob": 2.406095063633984e-06}, {"id": 829, "seek": 434202, "start": 4366.0, "end": 4368.72, "text": " That's what our content loss is going to be.", "tokens": [663, 311, 437, 527, 2701, 4470, 307, 516, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.09722659754198651, "compression_ratio": 1.7715736040609138, "no_speech_prob": 2.406095063633984e-06}, {"id": 830, "seek": 436872, "start": 4368.72, "end": 4374.64, "text": " And people generally call this a perceptual loss.", "tokens": [400, 561, 5101, 818, 341, 257, 43276, 901, 4470, 13], "temperature": 0.0, "avg_logprob": -0.09014230246072287, "compression_ratio": 1.6262135922330097, "no_speech_prob": 9.972878615371883e-06}, {"id": 831, "seek": 436872, "start": 4374.64, "end": 4379.2, "text": " It's really important in deep learning that you always create a new name for every obvious", "tokens": [467, 311, 534, 1021, 294, 2452, 2539, 300, 291, 1009, 1884, 257, 777, 1315, 337, 633, 6322], "temperature": 0.0, "avg_logprob": -0.09014230246072287, "compression_ratio": 1.6262135922330097, "no_speech_prob": 9.972878615371883e-06}, {"id": 832, "seek": 436872, "start": 4379.2, "end": 4380.280000000001, "text": " thing you do.", "tokens": [551, 291, 360, 13], "temperature": 0.0, "avg_logprob": -0.09014230246072287, "compression_ratio": 1.6262135922330097, "no_speech_prob": 9.972878615371883e-06}, {"id": 833, "seek": 436872, "start": 4380.280000000001, "end": 4388.76, "text": " So if you compare two activations together, you're doing a perceptual loss.", "tokens": [407, 498, 291, 6794, 732, 2430, 763, 1214, 11, 291, 434, 884, 257, 43276, 901, 4470, 13], "temperature": 0.0, "avg_logprob": -0.09014230246072287, "compression_ratio": 1.6262135922330097, "no_speech_prob": 9.972878615371883e-06}, {"id": 834, "seek": 436872, "start": 4388.76, "end": 4389.76, "text": " So that's it.", "tokens": [407, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.09014230246072287, "compression_ratio": 1.6262135922330097, "no_speech_prob": 9.972878615371883e-06}, {"id": 835, "seek": 436872, "start": 4389.76, "end": 4391.64, "text": " Our content loss is going to be a perceptual loss.", "tokens": [2621, 2701, 4470, 307, 516, 281, 312, 257, 43276, 901, 4470, 13], "temperature": 0.0, "avg_logprob": -0.09014230246072287, "compression_ratio": 1.6262135922330097, "no_speech_prob": 9.972878615371883e-06}, {"id": 836, "seek": 436872, "start": 4391.64, "end": 4393.2, "text": " And then we'll do the style loss later.", "tokens": [400, 550, 321, 603, 360, 264, 3758, 4470, 1780, 13], "temperature": 0.0, "avg_logprob": -0.09014230246072287, "compression_ratio": 1.6262135922330097, "no_speech_prob": 9.972878615371883e-06}, {"id": 837, "seek": 439320, "start": 4393.2, "end": 4402.08, "text": " So let's start by trying to create a bird that initially is random noise, and we're", "tokens": [407, 718, 311, 722, 538, 1382, 281, 1884, 257, 5255, 300, 9105, 307, 4974, 5658, 11, 293, 321, 434], "temperature": 0.0, "avg_logprob": -0.08713327605148842, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.684188530110987e-06}, {"id": 838, "seek": 439320, "start": 4402.08, "end": 4411.4, "text": " going to use perceptual loss to create something that is bird-like, but is not this bird.", "tokens": [516, 281, 764, 43276, 901, 4470, 281, 1884, 746, 300, 307, 5255, 12, 4092, 11, 457, 307, 406, 341, 5255, 13], "temperature": 0.0, "avg_logprob": -0.08713327605148842, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.684188530110987e-06}, {"id": 839, "seek": 439320, "start": 4411.4, "end": 4416.88, "text": " So let's start by saying we're going to do 288x288.", "tokens": [407, 718, 311, 722, 538, 1566, 321, 434, 516, 281, 360, 7562, 23, 87, 11205, 23, 13], "temperature": 0.0, "avg_logprob": -0.08713327605148842, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.684188530110987e-06}, {"id": 840, "seek": 439320, "start": 4416.88, "end": 4422.12, "text": " Because we're only going to do one bird, there's going to be no GPU memory problems.", "tokens": [1436, 321, 434, 787, 516, 281, 360, 472, 5255, 11, 456, 311, 516, 281, 312, 572, 18407, 4675, 2740, 13], "temperature": 0.0, "avg_logprob": -0.08713327605148842, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.684188530110987e-06}, {"id": 841, "seek": 442212, "start": 4422.12, "end": 4425.96, "text": " So I was actually disappointed that I realized that I picked a rather small input image.", "tokens": [407, 286, 390, 767, 13856, 300, 286, 5334, 300, 286, 6183, 257, 2831, 1359, 4846, 3256, 13], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 842, "seek": 442212, "start": 4425.96, "end": 4430.44, "text": " It would be fun to try this with something much bigger to create a really grand-scale", "tokens": [467, 576, 312, 1019, 281, 853, 341, 365, 746, 709, 3801, 281, 1884, 257, 534, 2697, 12, 20033], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 843, "seek": 442212, "start": 4430.44, "end": 4431.44, "text": " piece.", "tokens": [2522, 13], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 844, "seek": 442212, "start": 4431.44, "end": 4435.64, "text": " The other thing to remember is if you were productionizing this, you could do a whole", "tokens": [440, 661, 551, 281, 1604, 307, 498, 291, 645, 4265, 3319, 341, 11, 291, 727, 360, 257, 1379], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 845, "seek": 442212, "start": 4435.64, "end": 4439.04, "text": " batch at a time.", "tokens": [15245, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 846, "seek": 442212, "start": 4439.04, "end": 4441.8, "text": " So people sometimes complain about this approach.", "tokens": [407, 561, 2171, 11024, 466, 341, 3109, 13], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 847, "seek": 442212, "start": 4441.8, "end": 4443.48, "text": " Gaddis is the lead author.", "tokens": [37171, 13731, 307, 264, 1477, 3793, 13], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 848, "seek": 442212, "start": 4443.48, "end": 4446.5199999999995, "text": " The Gaddis style transfer approach is being slow.", "tokens": [440, 37171, 13731, 3758, 5003, 3109, 307, 885, 2964, 13], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 849, "seek": 442212, "start": 4446.5199999999995, "end": 4447.66, "text": " I don't agree it's slow.", "tokens": [286, 500, 380, 3986, 309, 311, 2964, 13], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 850, "seek": 442212, "start": 4447.66, "end": 4451.36, "text": " It takes a few seconds and you can do a whole batch in a few seconds.", "tokens": [467, 2516, 257, 1326, 3949, 293, 291, 393, 360, 257, 1379, 15245, 294, 257, 1326, 3949, 13], "temperature": 0.0, "avg_logprob": -0.21970972870335434, "compression_ratio": 1.726962457337884, "no_speech_prob": 1.98327124962816e-05}, {"id": 851, "seek": 445136, "start": 4451.36, "end": 4458.839999999999, "text": " So we're going to stick it through some transforms as per usual, transforms for VGG16 model.", "tokens": [407, 321, 434, 516, 281, 2897, 309, 807, 512, 35592, 382, 680, 7713, 11, 35592, 337, 691, 27561, 6866, 2316, 13], "temperature": 0.0, "avg_logprob": -0.1813721411006967, "compression_ratio": 1.5638766519823788, "no_speech_prob": 5.093683284940198e-06}, {"id": 852, "seek": 445136, "start": 4458.839999999999, "end": 4467.839999999999, "text": " And so remember, the transform class has a dunder call method, so we can treat it as", "tokens": [400, 370, 1604, 11, 264, 4088, 1508, 575, 257, 274, 6617, 818, 3170, 11, 370, 321, 393, 2387, 309, 382], "temperature": 0.0, "avg_logprob": -0.1813721411006967, "compression_ratio": 1.5638766519823788, "no_speech_prob": 5.093683284940198e-06}, {"id": 853, "seek": 445136, "start": 4467.839999999999, "end": 4469.679999999999, "text": " if it's a function.", "tokens": [498, 309, 311, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1813721411006967, "compression_ratio": 1.5638766519823788, "no_speech_prob": 5.093683284940198e-06}, {"id": 854, "seek": 445136, "start": 4469.679999999999, "end": 4474.5199999999995, "text": " So if you pass an image into that, then we get the transformed image.", "tokens": [407, 498, 291, 1320, 364, 3256, 666, 300, 11, 550, 321, 483, 264, 16894, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1813721411006967, "compression_ratio": 1.5638766519823788, "no_speech_prob": 5.093683284940198e-06}, {"id": 855, "seek": 445136, "start": 4474.5199999999995, "end": 4481.24, "text": " So try not to treat the fast AI and PyTorch infrastructure as a black box, because it's", "tokens": [407, 853, 406, 281, 2387, 264, 2370, 7318, 293, 9953, 51, 284, 339, 6896, 382, 257, 2211, 2424, 11, 570, 309, 311], "temperature": 0.0, "avg_logprob": -0.1813721411006967, "compression_ratio": 1.5638766519823788, "no_speech_prob": 5.093683284940198e-06}, {"id": 856, "seek": 448124, "start": 4481.24, "end": 4485.8, "text": " all designed to be really easy to use in a decoupled way.", "tokens": [439, 4761, 281, 312, 534, 1858, 281, 764, 294, 257, 979, 263, 15551, 636, 13], "temperature": 0.0, "avg_logprob": -0.14788628607681117, "compression_ratio": 1.6782178217821782, "no_speech_prob": 2.429980486340355e-05}, {"id": 857, "seek": 448124, "start": 4485.8, "end": 4492.5599999999995, "text": " So this idea that transforms are just callables, i.e. things that you can do with parentheses,", "tokens": [407, 341, 1558, 300, 35592, 366, 445, 818, 2965, 11, 741, 13, 68, 13, 721, 300, 291, 393, 360, 365, 34153, 11], "temperature": 0.0, "avg_logprob": -0.14788628607681117, "compression_ratio": 1.6782178217821782, "no_speech_prob": 2.429980486340355e-05}, {"id": 858, "seek": 448124, "start": 4492.5599999999995, "end": 4493.5599999999995, "text": " comes from PyTorch.", "tokens": [1487, 490, 9953, 51, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.14788628607681117, "compression_ratio": 1.6782178217821782, "no_speech_prob": 2.429980486340355e-05}, {"id": 859, "seek": 448124, "start": 4493.5599999999995, "end": 4496.36, "text": " And we totally plagiarized the idea.", "tokens": [400, 321, 3879, 33756, 9448, 1602, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.14788628607681117, "compression_ratio": 1.6782178217821782, "no_speech_prob": 2.429980486340355e-05}, {"id": 860, "seek": 448124, "start": 4496.36, "end": 4502.9, "text": " So with TorchVision or with fast AI, your transforms are just callables.", "tokens": [407, 365, 7160, 339, 53, 1991, 420, 365, 2370, 7318, 11, 428, 35592, 366, 445, 818, 2965, 13], "temperature": 0.0, "avg_logprob": -0.14788628607681117, "compression_ratio": 1.6782178217821782, "no_speech_prob": 2.429980486340355e-05}, {"id": 861, "seek": 448124, "start": 4502.9, "end": 4506.0199999999995, "text": " And the whole pipeline of transforms is just a callable.", "tokens": [400, 264, 1379, 15517, 295, 35592, 307, 445, 257, 818, 712, 13], "temperature": 0.0, "avg_logprob": -0.14788628607681117, "compression_ratio": 1.6782178217821782, "no_speech_prob": 2.429980486340355e-05}, {"id": 862, "seek": 450602, "start": 4506.02, "end": 4512.4400000000005, "text": " So now we have something of 3x288x288, because PyTorch likes the channel to be first, and", "tokens": [407, 586, 321, 362, 746, 295, 805, 87, 11205, 23, 87, 11205, 23, 11, 570, 9953, 51, 284, 339, 5902, 264, 2269, 281, 312, 700, 11, 293], "temperature": 0.0, "avg_logprob": -0.15583856178052496, "compression_ratio": 1.5, "no_speech_prob": 7.88918259786442e-06}, {"id": 863, "seek": 450602, "start": 4512.4400000000005, "end": 4517.4800000000005, "text": " as you can see, it's been turned into a square for us, it's been normalized to 0,1, all that", "tokens": [382, 291, 393, 536, 11, 309, 311, 668, 3574, 666, 257, 3732, 337, 505, 11, 309, 311, 668, 48704, 281, 1958, 11, 16, 11, 439, 300], "temperature": 0.0, "avg_logprob": -0.15583856178052496, "compression_ratio": 1.5, "no_speech_prob": 7.88918259786442e-06}, {"id": 864, "seek": 450602, "start": 4517.4800000000005, "end": 4520.96, "text": " normal stuff.", "tokens": [2710, 1507, 13], "temperature": 0.0, "avg_logprob": -0.15583856178052496, "compression_ratio": 1.5, "no_speech_prob": 7.88918259786442e-06}, {"id": 865, "seek": 450602, "start": 4520.96, "end": 4525.42, "text": " Now we'll create a random image.", "tokens": [823, 321, 603, 1884, 257, 4974, 3256, 13], "temperature": 0.0, "avg_logprob": -0.15583856178052496, "compression_ratio": 1.5, "no_speech_prob": 7.88918259786442e-06}, {"id": 866, "seek": 450602, "start": 4525.42, "end": 4528.46, "text": " And here's something I discovered.", "tokens": [400, 510, 311, 746, 286, 6941, 13], "temperature": 0.0, "avg_logprob": -0.15583856178052496, "compression_ratio": 1.5, "no_speech_prob": 7.88918259786442e-06}, {"id": 867, "seek": 450602, "start": 4528.46, "end": 4533.18, "text": " Trying to turn this into a picture of anything is actually really hard.", "tokens": [20180, 281, 1261, 341, 666, 257, 3036, 295, 1340, 307, 767, 534, 1152, 13], "temperature": 0.0, "avg_logprob": -0.15583856178052496, "compression_ratio": 1.5, "no_speech_prob": 7.88918259786442e-06}, {"id": 868, "seek": 453318, "start": 4533.18, "end": 4538.38, "text": " I found it very difficult to actually get an optimizer to get reasonable gradients that", "tokens": [286, 1352, 309, 588, 2252, 281, 767, 483, 364, 5028, 6545, 281, 483, 10585, 2771, 2448, 300], "temperature": 0.0, "avg_logprob": -0.09341711468166775, "compression_ratio": 1.5276595744680852, "no_speech_prob": 2.318722545169294e-05}, {"id": 869, "seek": 453318, "start": 4538.38, "end": 4540.6, "text": " went anywhere.", "tokens": [1437, 4992, 13], "temperature": 0.0, "avg_logprob": -0.09341711468166775, "compression_ratio": 1.5276595744680852, "no_speech_prob": 2.318722545169294e-05}, {"id": 870, "seek": 453318, "start": 4540.6, "end": 4544.400000000001, "text": " And just as I thought I was going to run out of time for this class and really embarrass", "tokens": [400, 445, 382, 286, 1194, 286, 390, 516, 281, 1190, 484, 295, 565, 337, 341, 1508, 293, 534, 9187], "temperature": 0.0, "avg_logprob": -0.09341711468166775, "compression_ratio": 1.5276595744680852, "no_speech_prob": 2.318722545169294e-05}, {"id": 871, "seek": 453318, "start": 4544.400000000001, "end": 4554.62, "text": " myself, I realized the key issue is that pictures don't look like this, they have more smoothness.", "tokens": [2059, 11, 286, 5334, 264, 2141, 2734, 307, 300, 5242, 500, 380, 574, 411, 341, 11, 436, 362, 544, 5508, 1287, 13], "temperature": 0.0, "avg_logprob": -0.09341711468166775, "compression_ratio": 1.5276595744680852, "no_speech_prob": 2.318722545169294e-05}, {"id": 872, "seek": 453318, "start": 4554.62, "end": 4559.52, "text": " So I turned this into this by just kind of blurring it a little bit.", "tokens": [407, 286, 3574, 341, 666, 341, 538, 445, 733, 295, 14257, 2937, 309, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.09341711468166775, "compression_ratio": 1.5276595744680852, "no_speech_prob": 2.318722545169294e-05}, {"id": 873, "seek": 455952, "start": 4559.52, "end": 4568.240000000001, "text": " I used a median filter, basically it's like a median pooling effectively.", "tokens": [286, 1143, 257, 26779, 6608, 11, 1936, 309, 311, 411, 257, 26779, 7005, 278, 8659, 13], "temperature": 0.0, "avg_logprob": -0.15727341515677315, "compression_ratio": 1.5197740112994351, "no_speech_prob": 5.77187756789499e-06}, {"id": 874, "seek": 455952, "start": 4568.240000000001, "end": 4572.72, "text": " And as soon as I changed it from this to this, it immediately started training really well.", "tokens": [400, 382, 2321, 382, 286, 3105, 309, 490, 341, 281, 341, 11, 309, 4258, 1409, 3097, 534, 731, 13], "temperature": 0.0, "avg_logprob": -0.15727341515677315, "compression_ratio": 1.5197740112994351, "no_speech_prob": 5.77187756789499e-06}, {"id": 875, "seek": 455952, "start": 4572.72, "end": 4576.76, "text": " So it's like, the number of little tweaks you have to do to get these things to work is", "tokens": [407, 309, 311, 411, 11, 264, 1230, 295, 707, 46664, 291, 362, 281, 360, 281, 483, 613, 721, 281, 589, 307], "temperature": 0.0, "avg_logprob": -0.15727341515677315, "compression_ratio": 1.5197740112994351, "no_speech_prob": 5.77187756789499e-06}, {"id": 876, "seek": 455952, "start": 4576.76, "end": 4581.280000000001, "text": " kind of insane.", "tokens": [733, 295, 10838, 13], "temperature": 0.0, "avg_logprob": -0.15727341515677315, "compression_ratio": 1.5197740112994351, "no_speech_prob": 5.77187756789499e-06}, {"id": 877, "seek": 458128, "start": 4581.28, "end": 4592.84, "text": " So we start with a random image which is at least somewhat smooth.", "tokens": [407, 321, 722, 365, 257, 4974, 3256, 597, 307, 412, 1935, 8344, 5508, 13], "temperature": 0.0, "avg_logprob": -0.18168356647230174, "compression_ratio": 1.4782608695652173, "no_speech_prob": 2.090443558699917e-06}, {"id": 878, "seek": 458128, "start": 4592.84, "end": 4598.16, "text": " I found that my bird image had a standard deviation of pixels that was about half of", "tokens": [286, 1352, 300, 452, 5255, 3256, 632, 257, 3832, 25163, 295, 18668, 300, 390, 466, 1922, 295], "temperature": 0.0, "avg_logprob": -0.18168356647230174, "compression_ratio": 1.4782608695652173, "no_speech_prob": 2.090443558699917e-06}, {"id": 879, "seek": 458128, "start": 4598.16, "end": 4604.759999999999, "text": " this mean, so I divided it by 2, just trying to make it a little bit easier for it to match.", "tokens": [341, 914, 11, 370, 286, 6666, 309, 538, 568, 11, 445, 1382, 281, 652, 309, 257, 707, 857, 3571, 337, 309, 281, 2995, 13], "temperature": 0.0, "avg_logprob": -0.18168356647230174, "compression_ratio": 1.4782608695652173, "no_speech_prob": 2.090443558699917e-06}, {"id": 880, "seek": 458128, "start": 4604.759999999999, "end": 4606.84, "text": " I don't know if it matters.", "tokens": [286, 500, 380, 458, 498, 309, 7001, 13], "temperature": 0.0, "avg_logprob": -0.18168356647230174, "compression_ratio": 1.4782608695652173, "no_speech_prob": 2.090443558699917e-06}, {"id": 881, "seek": 460684, "start": 4606.84, "end": 4611.92, "text": " Turn that into a variable, because this image, remember, we're going to be modifying those", "tokens": [7956, 300, 666, 257, 7006, 11, 570, 341, 3256, 11, 1604, 11, 321, 434, 516, 281, 312, 42626, 729], "temperature": 0.0, "avg_logprob": -0.14529746770858765, "compression_ratio": 1.548913043478261, "no_speech_prob": 5.2553523346432485e-06}, {"id": 882, "seek": 460684, "start": 4611.92, "end": 4615.24, "text": " pixels with an optimization algorithm.", "tokens": [18668, 365, 364, 19618, 9284, 13], "temperature": 0.0, "avg_logprob": -0.14529746770858765, "compression_ratio": 1.548913043478261, "no_speech_prob": 5.2553523346432485e-06}, {"id": 883, "seek": 460684, "start": 4615.24, "end": 4620.12, "text": " So anything that's involved in the loss function needs to be a variable, and specifically it", "tokens": [407, 1340, 300, 311, 3288, 294, 264, 4470, 2445, 2203, 281, 312, 257, 7006, 11, 293, 4682, 309], "temperature": 0.0, "avg_logprob": -0.14529746770858765, "compression_ratio": 1.548913043478261, "no_speech_prob": 5.2553523346432485e-06}, {"id": 884, "seek": 460684, "start": 4620.12, "end": 4627.82, "text": " requires a gradient because we're actually updating the image.", "tokens": [7029, 257, 16235, 570, 321, 434, 767, 25113, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.14529746770858765, "compression_ratio": 1.548913043478261, "no_speech_prob": 5.2553523346432485e-06}, {"id": 885, "seek": 462782, "start": 4627.82, "end": 4637.12, "text": " So we now have a mini-batch of 1, 3 channels, 288x288 random noise.", "tokens": [407, 321, 586, 362, 257, 8382, 12, 65, 852, 295, 502, 11, 805, 9235, 11, 7562, 23, 87, 11205, 23, 4974, 5658, 13], "temperature": 0.0, "avg_logprob": -0.19216114086109204, "compression_ratio": 1.4020100502512562, "no_speech_prob": 2.6016000447270926e-06}, {"id": 886, "seek": 462782, "start": 4637.12, "end": 4642.48, "text": " We're going to use for no particular reason the 37th layer of VGG.", "tokens": [492, 434, 516, 281, 764, 337, 572, 1729, 1778, 264, 13435, 392, 4583, 295, 691, 27561, 13], "temperature": 0.0, "avg_logprob": -0.19216114086109204, "compression_ratio": 1.4020100502512562, "no_speech_prob": 2.6016000447270926e-06}, {"id": 887, "seek": 462782, "start": 4642.48, "end": 4646.5599999999995, "text": " If you print out the VGG network, you can just type in m-underscore-vgg and it prints", "tokens": [759, 291, 4482, 484, 264, 691, 27561, 3209, 11, 291, 393, 445, 2010, 294, 275, 12, 997, 433, 12352, 12, 85, 1615, 293, 309, 22305], "temperature": 0.0, "avg_logprob": -0.19216114086109204, "compression_ratio": 1.4020100502512562, "no_speech_prob": 2.6016000447270926e-06}, {"id": 888, "seek": 462782, "start": 4646.5599999999995, "end": 4652.92, "text": " it out, you'll see that this is a mid to late stage layer.", "tokens": [309, 484, 11, 291, 603, 536, 300, 341, 307, 257, 2062, 281, 3469, 3233, 4583, 13], "temperature": 0.0, "avg_logprob": -0.19216114086109204, "compression_ratio": 1.4020100502512562, "no_speech_prob": 2.6016000447270926e-06}, {"id": 889, "seek": 465292, "start": 4652.92, "end": 4659.32, "text": " So we can just grab the first 37 layers and turn it into a sequential model, and so now", "tokens": [407, 321, 393, 445, 4444, 264, 700, 13435, 7914, 293, 1261, 309, 666, 257, 42881, 2316, 11, 293, 370, 586], "temperature": 0.0, "avg_logprob": -0.11773928006490071, "compression_ratio": 1.4739583333333333, "no_speech_prob": 3.089482106588548e-06}, {"id": 890, "seek": 465292, "start": 4659.32, "end": 4666.4, "text": " we've got a subset of VGG that will spit out some mid-layer activations, and so that's", "tokens": [321, 600, 658, 257, 25993, 295, 691, 27561, 300, 486, 22127, 484, 512, 2062, 12, 8376, 260, 2430, 763, 11, 293, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.11773928006490071, "compression_ratio": 1.4739583333333333, "no_speech_prob": 3.089482106588548e-06}, {"id": 891, "seek": 465292, "start": 4666.4, "end": 4668.9, "text": " what the model's going to be.", "tokens": [437, 264, 2316, 311, 516, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.11773928006490071, "compression_ratio": 1.4739583333333333, "no_speech_prob": 3.089482106588548e-06}, {"id": 892, "seek": 465292, "start": 4668.9, "end": 4676.42, "text": " So we can take our actual bird image, and we want to create a mini-batch of 1.", "tokens": [407, 321, 393, 747, 527, 3539, 5255, 3256, 11, 293, 321, 528, 281, 1884, 257, 8382, 12, 65, 852, 295, 502, 13], "temperature": 0.0, "avg_logprob": -0.11773928006490071, "compression_ratio": 1.4739583333333333, "no_speech_prob": 3.089482106588548e-06}, {"id": 893, "seek": 467642, "start": 4676.42, "end": 4685.36, "text": " So remember, if you slice in NumPy with None, also known as np.newAxis, it introduces a", "tokens": [407, 1604, 11, 498, 291, 13153, 294, 22592, 47, 88, 365, 14492, 11, 611, 2570, 382, 33808, 13, 7686, 32, 39637, 11, 309, 31472, 257], "temperature": 0.0, "avg_logprob": -0.15589320275091356, "compression_ratio": 1.6162162162162161, "no_speech_prob": 2.769387492662645e-06}, {"id": 894, "seek": 467642, "start": 4685.36, "end": 4690.12, "text": " new unit axis in that point.", "tokens": [777, 4985, 10298, 294, 300, 935, 13], "temperature": 0.0, "avg_logprob": -0.15589320275091356, "compression_ratio": 1.6162162162162161, "no_speech_prob": 2.769387492662645e-06}, {"id": 895, "seek": 467642, "start": 4690.12, "end": 4695.92, "text": " So here I want to create an axis of size 1 to say this is a mini-batch of size 1.", "tokens": [407, 510, 286, 528, 281, 1884, 364, 10298, 295, 2744, 502, 281, 584, 341, 307, 257, 8382, 12, 65, 852, 295, 2744, 502, 13], "temperature": 0.0, "avg_logprob": -0.15589320275091356, "compression_ratio": 1.6162162162162161, "no_speech_prob": 2.769387492662645e-06}, {"id": 896, "seek": 467642, "start": 4695.92, "end": 4702.24, "text": " So slicing with None, just like I did here, I sliced with None to get this 1 unit axis", "tokens": [407, 46586, 365, 14492, 11, 445, 411, 286, 630, 510, 11, 286, 27098, 365, 14492, 281, 483, 341, 502, 4985, 10298], "temperature": 0.0, "avg_logprob": -0.15589320275091356, "compression_ratio": 1.6162162162162161, "no_speech_prob": 2.769387492662645e-06}, {"id": 897, "seek": 467642, "start": 4702.24, "end": 4704.46, "text": " at the front.", "tokens": [412, 264, 1868, 13], "temperature": 0.0, "avg_logprob": -0.15589320275091356, "compression_ratio": 1.6162162162162161, "no_speech_prob": 2.769387492662645e-06}, {"id": 898, "seek": 470446, "start": 4704.46, "end": 4710.76, "text": " So then we turn that into a variable, and this one doesn't need to be updated, so we", "tokens": [407, 550, 321, 1261, 300, 666, 257, 7006, 11, 293, 341, 472, 1177, 380, 643, 281, 312, 10588, 11, 370, 321], "temperature": 0.0, "avg_logprob": -0.12740762927864172, "compression_ratio": 1.5769230769230769, "no_speech_prob": 2.5215590540028643e-06}, {"id": 899, "seek": 470446, "start": 4710.76, "end": 4717.44, "text": " use bv to say you don't need gradients for this guy.", "tokens": [764, 272, 85, 281, 584, 291, 500, 380, 643, 2771, 2448, 337, 341, 2146, 13], "temperature": 0.0, "avg_logprob": -0.12740762927864172, "compression_ratio": 1.5769230769230769, "no_speech_prob": 2.5215590540028643e-06}, {"id": 900, "seek": 470446, "start": 4717.44, "end": 4722.64, "text": " And so that's going to give us our target activations.", "tokens": [400, 370, 300, 311, 516, 281, 976, 505, 527, 3779, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.12740762927864172, "compression_ratio": 1.5769230769230769, "no_speech_prob": 2.5215590540028643e-06}, {"id": 901, "seek": 470446, "start": 4722.64, "end": 4729.34, "text": " So we've basically taken our bird image, turned it into a variable, stuck it through our model", "tokens": [407, 321, 600, 1936, 2726, 527, 5255, 3256, 11, 3574, 309, 666, 257, 7006, 11, 5541, 309, 807, 527, 2316], "temperature": 0.0, "avg_logprob": -0.12740762927864172, "compression_ratio": 1.5769230769230769, "no_speech_prob": 2.5215590540028643e-06}, {"id": 902, "seek": 472934, "start": 4729.34, "end": 4736.32, "text": " to grab the 37th layer activations, and that's our target, is that we want our content loss", "tokens": [281, 4444, 264, 13435, 392, 4583, 2430, 763, 11, 293, 300, 311, 527, 3779, 11, 307, 300, 321, 528, 527, 2701, 4470], "temperature": 0.0, "avg_logprob": -0.15261768740276957, "compression_ratio": 1.735632183908046, "no_speech_prob": 1.3925423445471097e-06}, {"id": 903, "seek": 472934, "start": 4736.32, "end": 4741.52, "text": " to be this set of activations here.", "tokens": [281, 312, 341, 992, 295, 2430, 763, 510, 13], "temperature": 0.0, "avg_logprob": -0.15261768740276957, "compression_ratio": 1.735632183908046, "no_speech_prob": 1.3925423445471097e-06}, {"id": 904, "seek": 472934, "start": 4741.52, "end": 4744.84, "text": " So now we're going to create an optimizer, we'll go back to the details of this in a", "tokens": [407, 586, 321, 434, 516, 281, 1884, 364, 5028, 6545, 11, 321, 603, 352, 646, 281, 264, 4365, 295, 341, 294, 257], "temperature": 0.0, "avg_logprob": -0.15261768740276957, "compression_ratio": 1.735632183908046, "no_speech_prob": 1.3925423445471097e-06}, {"id": 905, "seek": 472934, "start": 4744.84, "end": 4751.92, "text": " moment, but we're going to create an optimizer, and we're going to step a bunch of times,", "tokens": [1623, 11, 457, 321, 434, 516, 281, 1884, 364, 5028, 6545, 11, 293, 321, 434, 516, 281, 1823, 257, 3840, 295, 1413, 11], "temperature": 0.0, "avg_logprob": -0.15261768740276957, "compression_ratio": 1.735632183908046, "no_speech_prob": 1.3925423445471097e-06}, {"id": 906, "seek": 475192, "start": 4751.92, "end": 4760.72, "text": " going zero the gradients, call some loss function, loss.backward, blah blah blah.", "tokens": [516, 4018, 264, 2771, 2448, 11, 818, 512, 4470, 2445, 11, 4470, 13, 3207, 1007, 11, 12288, 12288, 12288, 13], "temperature": 0.0, "avg_logprob": -0.1720137479828625, "compression_ratio": 1.614213197969543, "no_speech_prob": 1.3709517361348844e-06}, {"id": 907, "seek": 475192, "start": 4760.72, "end": 4769.4, "text": " So that's the high-level version, and I'm going to come back to the details in a moment,", "tokens": [407, 300, 311, 264, 1090, 12, 12418, 3037, 11, 293, 286, 478, 516, 281, 808, 646, 281, 264, 4365, 294, 257, 1623, 11], "temperature": 0.0, "avg_logprob": -0.1720137479828625, "compression_ratio": 1.614213197969543, "no_speech_prob": 1.3709517361348844e-06}, {"id": 908, "seek": 475192, "start": 4769.4, "end": 4775.62, "text": " but the key thing is that the loss function we're passing in that randomly generated image,", "tokens": [457, 264, 2141, 551, 307, 300, 264, 4470, 2445, 321, 434, 8437, 294, 300, 16979, 10833, 3256, 11], "temperature": 0.0, "avg_logprob": -0.1720137479828625, "compression_ratio": 1.614213197969543, "no_speech_prob": 1.3709517361348844e-06}, {"id": 909, "seek": 475192, "start": 4775.62, "end": 4779.56, "text": " the optimization image, or actually the variable of it.", "tokens": [264, 19618, 3256, 11, 420, 767, 264, 7006, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.1720137479828625, "compression_ratio": 1.614213197969543, "no_speech_prob": 1.3709517361348844e-06}, {"id": 910, "seek": 477956, "start": 4779.56, "end": 4786.160000000001, "text": " So we pass that to our loss function, and so it's going to update this using the loss", "tokens": [407, 321, 1320, 300, 281, 527, 4470, 2445, 11, 293, 370, 309, 311, 516, 281, 5623, 341, 1228, 264, 4470], "temperature": 0.0, "avg_logprob": -0.12388046264648438, "compression_ratio": 1.7808988764044944, "no_speech_prob": 2.601600272100768e-06}, {"id": 911, "seek": 477956, "start": 4786.160000000001, "end": 4792.96, "text": " function, and the loss function is the mean squared error loss, comparing our current", "tokens": [2445, 11, 293, 264, 4470, 2445, 307, 264, 914, 8889, 6713, 4470, 11, 15763, 527, 2190], "temperature": 0.0, "avg_logprob": -0.12388046264648438, "compression_ratio": 1.7808988764044944, "no_speech_prob": 2.601600272100768e-06}, {"id": 912, "seek": 477956, "start": 4792.96, "end": 4798.72, "text": " optimization image, pass through our VGG to get the intermediate activations, and comparing", "tokens": [19618, 3256, 11, 1320, 807, 527, 691, 27561, 281, 483, 264, 19376, 2430, 763, 11, 293, 15763], "temperature": 0.0, "avg_logprob": -0.12388046264648438, "compression_ratio": 1.7808988764044944, "no_speech_prob": 2.601600272100768e-06}, {"id": 913, "seek": 477956, "start": 4798.72, "end": 4804.14, "text": " it to our target activations, just like we discussed.", "tokens": [309, 281, 527, 3779, 2430, 763, 11, 445, 411, 321, 7152, 13], "temperature": 0.0, "avg_logprob": -0.12388046264648438, "compression_ratio": 1.7808988764044944, "no_speech_prob": 2.601600272100768e-06}, {"id": 914, "seek": 480414, "start": 4804.14, "end": 4812.200000000001, "text": " And we'll run that a bunch of times, and we'll print it out, and we have our bird, but not", "tokens": [400, 321, 603, 1190, 300, 257, 3840, 295, 1413, 11, 293, 321, 603, 4482, 309, 484, 11, 293, 321, 362, 527, 5255, 11, 457, 406], "temperature": 0.0, "avg_logprob": -0.14660856940529562, "compression_ratio": 1.4166666666666667, "no_speech_prob": 1.6280478121188935e-06}, {"id": 915, "seek": 480414, "start": 4812.200000000001, "end": 4814.56, "text": " the representation of the bird.", "tokens": [264, 10290, 295, 264, 5255, 13], "temperature": 0.0, "avg_logprob": -0.14660856940529562, "compression_ratio": 1.4166666666666667, "no_speech_prob": 1.6280478121188935e-06}, {"id": 916, "seek": 480414, "start": 4814.56, "end": 4818.88, "text": " So there it is.", "tokens": [407, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.14660856940529562, "compression_ratio": 1.4166666666666667, "no_speech_prob": 1.6280478121188935e-06}, {"id": 917, "seek": 480414, "start": 4818.88, "end": 4827.68, "text": " So a couple of new details here, one is a weird optimizer, LBFTS.", "tokens": [407, 257, 1916, 295, 777, 4365, 510, 11, 472, 307, 257, 3657, 5028, 6545, 11, 441, 33, 37, 7327, 13], "temperature": 0.0, "avg_logprob": -0.14660856940529562, "compression_ratio": 1.4166666666666667, "no_speech_prob": 1.6280478121188935e-06}, {"id": 918, "seek": 482768, "start": 4827.68, "end": 4834.320000000001, "text": " Anybody who's done, I don't know exactly what courses they're in, but certain parts of math", "tokens": [19082, 567, 311, 1096, 11, 286, 500, 380, 458, 2293, 437, 7712, 436, 434, 294, 11, 457, 1629, 3166, 295, 5221], "temperature": 0.0, "avg_logprob": -0.15511212068445543, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.2029545359837357e-05}, {"id": 919, "seek": 482768, "start": 4834.320000000001, "end": 4841.12, "text": " and computer science courses, comes into deep learning, discovers we use all this stuff", "tokens": [293, 3820, 3497, 7712, 11, 1487, 666, 2452, 2539, 11, 44522, 321, 764, 439, 341, 1507], "temperature": 0.0, "avg_logprob": -0.15511212068445543, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.2029545359837357e-05}, {"id": 920, "seek": 482768, "start": 4841.12, "end": 4848.04, "text": " like Adam and SGD, and always assume that nobody in the field knows the first thing", "tokens": [411, 7938, 293, 34520, 35, 11, 293, 1009, 6552, 300, 5079, 294, 264, 2519, 3255, 264, 700, 551], "temperature": 0.0, "avg_logprob": -0.15511212068445543, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.2029545359837357e-05}, {"id": 921, "seek": 482768, "start": 4848.04, "end": 4855.360000000001, "text": " about computer science, and immediately says, oh have any of you guys tried using VFTS?", "tokens": [466, 3820, 3497, 11, 293, 4258, 1619, 11, 1954, 362, 604, 295, 291, 1074, 3031, 1228, 691, 37, 7327, 30], "temperature": 0.0, "avg_logprob": -0.15511212068445543, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.2029545359837357e-05}, {"id": 922, "seek": 485536, "start": 4855.36, "end": 4860.599999999999, "text": " There's basically a long history of a totally different kind of algorithm for optimization", "tokens": [821, 311, 1936, 257, 938, 2503, 295, 257, 3879, 819, 733, 295, 9284, 337, 19618], "temperature": 0.0, "avg_logprob": -0.12357806344317575, "compression_ratio": 1.782312925170068, "no_speech_prob": 5.093636445963057e-06}, {"id": 923, "seek": 485536, "start": 4860.599999999999, "end": 4863.48, "text": " that we don't use to train neural networks.", "tokens": [300, 321, 500, 380, 764, 281, 3847, 18161, 9590, 13], "temperature": 0.0, "avg_logprob": -0.12357806344317575, "compression_ratio": 1.782312925170068, "no_speech_prob": 5.093636445963057e-06}, {"id": 924, "seek": 485536, "start": 4863.48, "end": 4867.5599999999995, "text": " And of course the answer is actually the people who have spent decades studying neural networks", "tokens": [400, 295, 1164, 264, 1867, 307, 767, 264, 561, 567, 362, 4418, 7878, 7601, 18161, 9590], "temperature": 0.0, "avg_logprob": -0.12357806344317575, "compression_ratio": 1.782312925170068, "no_speech_prob": 5.093636445963057e-06}, {"id": 925, "seek": 485536, "start": 4867.5599999999995, "end": 4871.679999999999, "text": " do know a thing or two about computer science, and it turns out these techniques on the whole", "tokens": [360, 458, 257, 551, 420, 732, 466, 3820, 3497, 11, 293, 309, 4523, 484, 613, 7512, 322, 264, 1379], "temperature": 0.0, "avg_logprob": -0.12357806344317575, "compression_ratio": 1.782312925170068, "no_speech_prob": 5.093636445963057e-06}, {"id": 926, "seek": 485536, "start": 4871.679999999999, "end": 4873.299999999999, "text": " don't work very well.", "tokens": [500, 380, 589, 588, 731, 13], "temperature": 0.0, "avg_logprob": -0.12357806344317575, "compression_ratio": 1.782312925170068, "no_speech_prob": 5.093636445963057e-06}, {"id": 927, "seek": 485536, "start": 4873.299999999999, "end": 4876.799999999999, "text": " But it's actually going to work well for this, and it's a good opportunity to talk about", "tokens": [583, 309, 311, 767, 516, 281, 589, 731, 337, 341, 11, 293, 309, 311, 257, 665, 2650, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.12357806344317575, "compression_ratio": 1.782312925170068, "no_speech_prob": 5.093636445963057e-06}, {"id": 928, "seek": 485536, "start": 4876.799999999999, "end": 4882.7, "text": " an interesting algorithm for those of you that haven't studied this type of optimization", "tokens": [364, 1880, 9284, 337, 729, 295, 291, 300, 2378, 380, 9454, 341, 2010, 295, 19618], "temperature": 0.0, "avg_logprob": -0.12357806344317575, "compression_ratio": 1.782312925170068, "no_speech_prob": 5.093636445963057e-06}, {"id": 929, "seek": 488270, "start": 4882.7, "end": 4886.92, "text": " algorithm at school.", "tokens": [9284, 412, 1395, 13], "temperature": 0.0, "avg_logprob": -0.22215446955721144, "compression_ratio": 1.4779874213836477, "no_speech_prob": 1.644217445573304e-05}, {"id": 930, "seek": 488270, "start": 4886.92, "end": 4899.4, "text": " So BFTS is initials of 4 different people, the L stands for limited memory, so it's really", "tokens": [407, 363, 37, 7327, 307, 5883, 82, 295, 1017, 819, 561, 11, 264, 441, 7382, 337, 5567, 4675, 11, 370, 309, 311, 534], "temperature": 0.0, "avg_logprob": -0.22215446955721144, "compression_ratio": 1.4779874213836477, "no_speech_prob": 1.644217445573304e-05}, {"id": 931, "seek": 488270, "start": 4899.4, "end": 4903.54, "text": " just called BFTS, limited memory BFTS.", "tokens": [445, 1219, 363, 37, 7327, 11, 5567, 4675, 363, 37, 7327, 13], "temperature": 0.0, "avg_logprob": -0.22215446955721144, "compression_ratio": 1.4779874213836477, "no_speech_prob": 1.644217445573304e-05}, {"id": 932, "seek": 488270, "start": 4903.54, "end": 4908.98, "text": " And it's an optimizer, so as an optimizer, it means that there's some loss function,", "tokens": [400, 309, 311, 364, 5028, 6545, 11, 370, 382, 364, 5028, 6545, 11, 309, 1355, 300, 456, 311, 512, 4470, 2445, 11], "temperature": 0.0, "avg_logprob": -0.22215446955721144, "compression_ratio": 1.4779874213836477, "no_speech_prob": 1.644217445573304e-05}, {"id": 933, "seek": 490898, "start": 4908.98, "end": 4913.44, "text": " and it's going to use some gradients to, not all optimizers use gradients, but all the", "tokens": [293, 309, 311, 516, 281, 764, 512, 2771, 2448, 281, 11, 406, 439, 5028, 22525, 764, 2771, 2448, 11, 457, 439, 264], "temperature": 0.0, "avg_logprob": -0.14840368270874024, "compression_ratio": 1.7548076923076923, "no_speech_prob": 4.356832505436614e-06}, {"id": 934, "seek": 490898, "start": 4913.44, "end": 4919.459999999999, "text": " ones we use do, use gradients to find a direction to go and try to make the loss function go", "tokens": [2306, 321, 764, 360, 11, 764, 2771, 2448, 281, 915, 257, 3513, 281, 352, 293, 853, 281, 652, 264, 4470, 2445, 352], "temperature": 0.0, "avg_logprob": -0.14840368270874024, "compression_ratio": 1.7548076923076923, "no_speech_prob": 4.356832505436614e-06}, {"id": 935, "seek": 490898, "start": 4919.459999999999, "end": 4922.36, "text": " lower and lower by adjusting some parameters.", "tokens": [3126, 293, 3126, 538, 23559, 512, 9834, 13], "temperature": 0.0, "avg_logprob": -0.14840368270874024, "compression_ratio": 1.7548076923076923, "no_speech_prob": 4.356832505436614e-06}, {"id": 936, "seek": 490898, "start": 4922.36, "end": 4925.839999999999, "text": " It's just an optimizer.", "tokens": [467, 311, 445, 364, 5028, 6545, 13], "temperature": 0.0, "avg_logprob": -0.14840368270874024, "compression_ratio": 1.7548076923076923, "no_speech_prob": 4.356832505436614e-06}, {"id": 937, "seek": 490898, "start": 4925.839999999999, "end": 4930.58, "text": " But it's an interesting kind of optimizer because it does a bit more work than the ones we're", "tokens": [583, 309, 311, 364, 1880, 733, 295, 5028, 6545, 570, 309, 775, 257, 857, 544, 589, 813, 264, 2306, 321, 434], "temperature": 0.0, "avg_logprob": -0.14840368270874024, "compression_ratio": 1.7548076923076923, "no_speech_prob": 4.356832505436614e-06}, {"id": 938, "seek": 490898, "start": 4930.58, "end": 4933.16, "text": " used to on each step.", "tokens": [1143, 281, 322, 1184, 1823, 13], "temperature": 0.0, "avg_logprob": -0.14840368270874024, "compression_ratio": 1.7548076923076923, "no_speech_prob": 4.356832505436614e-06}, {"id": 939, "seek": 493316, "start": 4933.16, "end": 4960.36, "text": " And so specifically, so the way it works is it starts the same way that we're used to,", "tokens": [400, 370, 4682, 11, 370, 264, 636, 309, 1985, 307, 309, 3719, 264, 912, 636, 300, 321, 434, 1143, 281, 11], "temperature": 0.0, "avg_logprob": -0.21749160766601563, "compression_ratio": 1.1168831168831168, "no_speech_prob": 1.0451315574755426e-05}, {"id": 940, "seek": 496036, "start": 4960.36, "end": 4965.32, "text": " which is we just kind of pick somewhere to get started, and in this case we pick like", "tokens": [597, 307, 321, 445, 733, 295, 1888, 4079, 281, 483, 1409, 11, 293, 294, 341, 1389, 321, 1888, 411], "temperature": 0.0, "avg_logprob": -0.16044498961648823, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.66452683112584e-06}, {"id": 941, "seek": 496036, "start": 4965.32, "end": 4969.2, "text": " a random image, as you saw.", "tokens": [257, 4974, 3256, 11, 382, 291, 1866, 13], "temperature": 0.0, "avg_logprob": -0.16044498961648823, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.66452683112584e-06}, {"id": 942, "seek": 496036, "start": 4969.2, "end": 4979.799999999999, "text": " And as per usual, we calculate the gradient.", "tokens": [400, 382, 680, 7713, 11, 321, 8873, 264, 16235, 13], "temperature": 0.0, "avg_logprob": -0.16044498961648823, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.66452683112584e-06}, {"id": 943, "seek": 496036, "start": 4979.799999999999, "end": 4985.98, "text": " But we then don't just take a step, but what we actually do is as well as finding the gradient,", "tokens": [583, 321, 550, 500, 380, 445, 747, 257, 1823, 11, 457, 437, 321, 767, 360, 307, 382, 731, 382, 5006, 264, 16235, 11], "temperature": 0.0, "avg_logprob": -0.16044498961648823, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.66452683112584e-06}, {"id": 944, "seek": 496036, "start": 4985.98, "end": 4988.679999999999, "text": " we also try to find the second derivative.", "tokens": [321, 611, 853, 281, 915, 264, 1150, 13760, 13], "temperature": 0.0, "avg_logprob": -0.16044498961648823, "compression_ratio": 1.5714285714285714, "no_speech_prob": 8.66452683112584e-06}, {"id": 945, "seek": 498868, "start": 4988.68, "end": 4993.0, "text": " So the second derivative says how fast does the gradient change.", "tokens": [407, 264, 1150, 13760, 1619, 577, 2370, 775, 264, 16235, 1319, 13], "temperature": 0.0, "avg_logprob": -0.1481987943927061, "compression_ratio": 1.9792746113989637, "no_speech_prob": 2.5215524601662764e-06}, {"id": 946, "seek": 498868, "start": 4993.0, "end": 4996.08, "text": " So the gradient is how fast does the function change, the second derivative is how fast", "tokens": [407, 264, 16235, 307, 577, 2370, 775, 264, 2445, 1319, 11, 264, 1150, 13760, 307, 577, 2370], "temperature": 0.0, "avg_logprob": -0.1481987943927061, "compression_ratio": 1.9792746113989637, "no_speech_prob": 2.5215524601662764e-06}, {"id": 947, "seek": 498868, "start": 4996.08, "end": 4997.08, "text": " does the gradient change.", "tokens": [775, 264, 16235, 1319, 13], "temperature": 0.0, "avg_logprob": -0.1481987943927061, "compression_ratio": 1.9792746113989637, "no_speech_prob": 2.5215524601662764e-06}, {"id": 948, "seek": 498868, "start": 4997.08, "end": 4999.16, "text": " In other words, how curvy is it?", "tokens": [682, 661, 2283, 11, 577, 1262, 11869, 307, 309, 30], "temperature": 0.0, "avg_logprob": -0.1481987943927061, "compression_ratio": 1.9792746113989637, "no_speech_prob": 2.5215524601662764e-06}, {"id": 949, "seek": 498868, "start": 4999.16, "end": 5008.200000000001, "text": " And the basic idea is that if you know that it's not very curvy, then you can probably", "tokens": [400, 264, 3875, 1558, 307, 300, 498, 291, 458, 300, 309, 311, 406, 588, 1262, 11869, 11, 550, 291, 393, 1391], "temperature": 0.0, "avg_logprob": -0.1481987943927061, "compression_ratio": 1.9792746113989637, "no_speech_prob": 2.5215524601662764e-06}, {"id": 950, "seek": 498868, "start": 5008.200000000001, "end": 5011.84, "text": " jump further.", "tokens": [3012, 3052, 13], "temperature": 0.0, "avg_logprob": -0.1481987943927061, "compression_ratio": 1.9792746113989637, "no_speech_prob": 2.5215524601662764e-06}, {"id": 951, "seek": 498868, "start": 5011.84, "end": 5016.6, "text": " But if it is very curvy, then you probably don't want to jump as far.", "tokens": [583, 498, 309, 307, 588, 1262, 11869, 11, 550, 291, 1391, 500, 380, 528, 281, 3012, 382, 1400, 13], "temperature": 0.0, "avg_logprob": -0.1481987943927061, "compression_ratio": 1.9792746113989637, "no_speech_prob": 2.5215524601662764e-06}, {"id": 952, "seek": 501660, "start": 5016.6, "end": 5020.84, "text": " And so in higher dimensions, the gradient is called the Jacobian and the second derivative", "tokens": [400, 370, 294, 2946, 12819, 11, 264, 16235, 307, 1219, 264, 14117, 952, 293, 264, 1150, 13760], "temperature": 0.0, "avg_logprob": -0.16662003653390067, "compression_ratio": 1.66, "no_speech_prob": 6.643354026891757e-06}, {"id": 953, "seek": 501660, "start": 5020.84, "end": 5021.84, "text": " is called the Hessian.", "tokens": [307, 1219, 264, 35960, 952, 13], "temperature": 0.0, "avg_logprob": -0.16662003653390067, "compression_ratio": 1.66, "no_speech_prob": 6.643354026891757e-06}, {"id": 954, "seek": 501660, "start": 5021.84, "end": 5025.6, "text": " You'll see those words all the time, but that's all they mean.", "tokens": [509, 603, 536, 729, 2283, 439, 264, 565, 11, 457, 300, 311, 439, 436, 914, 13], "temperature": 0.0, "avg_logprob": -0.16662003653390067, "compression_ratio": 1.66, "no_speech_prob": 6.643354026891757e-06}, {"id": 955, "seek": 501660, "start": 5025.6, "end": 5028.88, "text": " Again, mathematicians have to invent new words for everything as well.", "tokens": [3764, 11, 32811, 2567, 362, 281, 7962, 777, 2283, 337, 1203, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16662003653390067, "compression_ratio": 1.66, "no_speech_prob": 6.643354026891757e-06}, {"id": 956, "seek": 501660, "start": 5028.88, "end": 5036.240000000001, "text": " They're just like deep learning researchers, except maybe a bit more snooty.", "tokens": [814, 434, 445, 411, 2452, 2539, 10309, 11, 3993, 1310, 257, 857, 544, 43287, 6737, 13], "temperature": 0.0, "avg_logprob": -0.16662003653390067, "compression_ratio": 1.66, "no_speech_prob": 6.643354026891757e-06}, {"id": 957, "seek": 501660, "start": 5036.240000000001, "end": 5043.96, "text": " So with BFGS, we're going to try and calculate the second derivative, and then we're going", "tokens": [407, 365, 363, 37, 24446, 11, 321, 434, 516, 281, 853, 293, 8873, 264, 1150, 13760, 11, 293, 550, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.16662003653390067, "compression_ratio": 1.66, "no_speech_prob": 6.643354026891757e-06}, {"id": 958, "seek": 504396, "start": 5043.96, "end": 5051.24, "text": " to use that to figure out what direction to go and how far to go.", "tokens": [281, 764, 300, 281, 2573, 484, 437, 3513, 281, 352, 293, 577, 1400, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.11977302880934727, "compression_ratio": 1.5833333333333333, "no_speech_prob": 8.801052899798378e-06}, {"id": 959, "seek": 504396, "start": 5051.24, "end": 5056.32, "text": " So it's less of a wild jump into the undone.", "tokens": [407, 309, 311, 1570, 295, 257, 4868, 3012, 666, 264, 674, 546, 13], "temperature": 0.0, "avg_logprob": -0.11977302880934727, "compression_ratio": 1.5833333333333333, "no_speech_prob": 8.801052899798378e-06}, {"id": 960, "seek": 504396, "start": 5056.32, "end": 5062.28, "text": " Now the problem is that actually calculating the Hessian, the second derivative, is almost", "tokens": [823, 264, 1154, 307, 300, 767, 28258, 264, 35960, 952, 11, 264, 1150, 13760, 11, 307, 1920], "temperature": 0.0, "avg_logprob": -0.11977302880934727, "compression_ratio": 1.5833333333333333, "no_speech_prob": 8.801052899798378e-06}, {"id": 961, "seek": 504396, "start": 5062.28, "end": 5064.6, "text": " certainly not a good idea.", "tokens": [3297, 406, 257, 665, 1558, 13], "temperature": 0.0, "avg_logprob": -0.11977302880934727, "compression_ratio": 1.5833333333333333, "no_speech_prob": 8.801052899798378e-06}, {"id": 962, "seek": 504396, "start": 5064.6, "end": 5069.44, "text": " Because in each possible direction that you can head, for each direction that you're measuring", "tokens": [1436, 294, 1184, 1944, 3513, 300, 291, 393, 1378, 11, 337, 1184, 3513, 300, 291, 434, 13389], "temperature": 0.0, "avg_logprob": -0.11977302880934727, "compression_ratio": 1.5833333333333333, "no_speech_prob": 8.801052899798378e-06}, {"id": 963, "seek": 506944, "start": 5069.44, "end": 5074.759999999999, "text": " the gradient in, you also have to calculate the Hessian in every direction.", "tokens": [264, 16235, 294, 11, 291, 611, 362, 281, 8873, 264, 35960, 952, 294, 633, 3513, 13], "temperature": 0.0, "avg_logprob": -0.10771025043644317, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.7880588529806118e-06}, {"id": 964, "seek": 506944, "start": 5074.759999999999, "end": 5078.679999999999, "text": " It gets ridiculously big.", "tokens": [467, 2170, 41358, 955, 13], "temperature": 0.0, "avg_logprob": -0.10771025043644317, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.7880588529806118e-06}, {"id": 965, "seek": 506944, "start": 5078.679999999999, "end": 5084.839999999999, "text": " So rather than actually calculating it, we take a few steps and we basically look at", "tokens": [407, 2831, 813, 767, 28258, 309, 11, 321, 747, 257, 1326, 4439, 293, 321, 1936, 574, 412], "temperature": 0.0, "avg_logprob": -0.10771025043644317, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.7880588529806118e-06}, {"id": 966, "seek": 506944, "start": 5084.839999999999, "end": 5092.2, "text": " how much the gradient's changing as we do each step, and we approximate the Hessian", "tokens": [577, 709, 264, 16235, 311, 4473, 382, 321, 360, 1184, 1823, 11, 293, 321, 30874, 264, 35960, 952], "temperature": 0.0, "avg_logprob": -0.10771025043644317, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.7880588529806118e-06}, {"id": 967, "seek": 506944, "start": 5092.2, "end": 5094.96, "text": " using that little function.", "tokens": [1228, 300, 707, 2445, 13], "temperature": 0.0, "avg_logprob": -0.10771025043644317, "compression_ratio": 1.5851063829787233, "no_speech_prob": 1.7880588529806118e-06}, {"id": 968, "seek": 509496, "start": 5094.96, "end": 5102.4800000000005, "text": " And this seems like a really obvious thing to do, but nobody thought of it until surprisingly", "tokens": [400, 341, 2544, 411, 257, 534, 6322, 551, 281, 360, 11, 457, 5079, 1194, 295, 309, 1826, 17600], "temperature": 0.0, "avg_logprob": -0.1528706994167594, "compression_ratio": 1.535, "no_speech_prob": 3.2887312499951804e-06}, {"id": 969, "seek": 509496, "start": 5102.4800000000005, "end": 5104.96, "text": " a long time later.", "tokens": [257, 938, 565, 1780, 13], "temperature": 0.0, "avg_logprob": -0.1528706994167594, "compression_ratio": 1.535, "no_speech_prob": 3.2887312499951804e-06}, {"id": 970, "seek": 509496, "start": 5104.96, "end": 5110.0, "text": " Keeping track of every single step you take takes a lot of memory.", "tokens": [30187, 2837, 295, 633, 2167, 1823, 291, 747, 2516, 257, 688, 295, 4675, 13], "temperature": 0.0, "avg_logprob": -0.1528706994167594, "compression_ratio": 1.535, "no_speech_prob": 3.2887312499951804e-06}, {"id": 971, "seek": 509496, "start": 5110.0, "end": 5116.04, "text": " So don't keep track of every step you take, just keep the last 10 or 20.", "tokens": [407, 500, 380, 1066, 2837, 295, 633, 1823, 291, 747, 11, 445, 1066, 264, 1036, 1266, 420, 945, 13], "temperature": 0.0, "avg_logprob": -0.1528706994167594, "compression_ratio": 1.535, "no_speech_prob": 3.2887312499951804e-06}, {"id": 972, "seek": 509496, "start": 5116.04, "end": 5120.24, "text": " And the second bit there, that's the L, to the L BFGS.", "tokens": [400, 264, 1150, 857, 456, 11, 300, 311, 264, 441, 11, 281, 264, 441, 363, 37, 24446, 13], "temperature": 0.0, "avg_logprob": -0.1528706994167594, "compression_ratio": 1.535, "no_speech_prob": 3.2887312499951804e-06}, {"id": 973, "seek": 512024, "start": 5120.24, "end": 5127.96, "text": " So a limited memory BFGS means keep the last 10 or 20 gradients, use that to approximate", "tokens": [407, 257, 5567, 4675, 363, 37, 24446, 1355, 1066, 264, 1036, 1266, 420, 945, 2771, 2448, 11, 764, 300, 281, 30874], "temperature": 0.0, "avg_logprob": -0.14193366618638628, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.0188063015448279e-06}, {"id": 974, "seek": 512024, "start": 5127.96, "end": 5132.76, "text": " the amount of curvature, and then use the curvature and gradient to estimate what direction", "tokens": [264, 2372, 295, 37638, 11, 293, 550, 764, 264, 37638, 293, 16235, 281, 12539, 437, 3513], "temperature": 0.0, "avg_logprob": -0.14193366618638628, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.0188063015448279e-06}, {"id": 975, "seek": 512024, "start": 5132.76, "end": 5138.5599999999995, "text": " to travel and how far.", "tokens": [281, 3147, 293, 577, 1400, 13], "temperature": 0.0, "avg_logprob": -0.14193366618638628, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.0188063015448279e-06}, {"id": 976, "seek": 512024, "start": 5138.5599999999995, "end": 5143.16, "text": " And so that's normally not a good idea in deep learning for a number of reasons.", "tokens": [400, 370, 300, 311, 5646, 406, 257, 665, 1558, 294, 2452, 2539, 337, 257, 1230, 295, 4112, 13], "temperature": 0.0, "avg_logprob": -0.14193366618638628, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.0188063015448279e-06}, {"id": 977, "seek": 512024, "start": 5143.16, "end": 5149.0, "text": " It's obviously more work to do than an atom or an SGD update.", "tokens": [467, 311, 2745, 544, 589, 281, 360, 813, 364, 12018, 420, 364, 34520, 35, 5623, 13], "temperature": 0.0, "avg_logprob": -0.14193366618638628, "compression_ratio": 1.5309734513274336, "no_speech_prob": 1.0188063015448279e-06}, {"id": 978, "seek": 514900, "start": 5149.0, "end": 5151.04, "text": " It's obviously more memory.", "tokens": [467, 311, 2745, 544, 4675, 13], "temperature": 0.0, "avg_logprob": -0.2276500129699707, "compression_ratio": 1.4880952380952381, "no_speech_prob": 2.4299539290950634e-05}, {"id": 979, "seek": 514900, "start": 5151.04, "end": 5155.48, "text": " Memory is much more of a big issue when you've got a GPU to store it on and hundreds of millions", "tokens": [38203, 307, 709, 544, 295, 257, 955, 2734, 562, 291, 600, 658, 257, 18407, 281, 3531, 309, 322, 293, 6779, 295, 6803], "temperature": 0.0, "avg_logprob": -0.2276500129699707, "compression_ratio": 1.4880952380952381, "no_speech_prob": 2.4299539290950634e-05}, {"id": 980, "seek": 514900, "start": 5155.48, "end": 5156.48, "text": " of weights.", "tokens": [295, 17443, 13], "temperature": 0.0, "avg_logprob": -0.2276500129699707, "compression_ratio": 1.4880952380952381, "no_speech_prob": 2.4299539290950634e-05}, {"id": 981, "seek": 514900, "start": 5156.48, "end": 5162.32, "text": " But more importantly, the mini-batches are super bumpy, so figuring out curvature to", "tokens": [583, 544, 8906, 11, 264, 8382, 12, 65, 852, 279, 366, 1687, 49400, 11, 370, 15213, 484, 37638, 281], "temperature": 0.0, "avg_logprob": -0.2276500129699707, "compression_ratio": 1.4880952380952381, "no_speech_prob": 2.4299539290950634e-05}, {"id": 982, "seek": 514900, "start": 5162.32, "end": 5167.4, "text": " decide exactly how far to travel is kind of polishing turds, as we say.", "tokens": [4536, 2293, 577, 1400, 281, 3147, 307, 733, 295, 47258, 3243, 16063, 11, 382, 321, 584, 13], "temperature": 0.0, "avg_logprob": -0.2276500129699707, "compression_ratio": 1.4880952380952381, "no_speech_prob": 2.4299539290950634e-05}, {"id": 983, "seek": 514900, "start": 5167.4, "end": 5171.96, "text": " Is that an American expression or an Australian thing?", "tokens": [1119, 300, 364, 2665, 6114, 420, 364, 13337, 551, 30], "temperature": 0.0, "avg_logprob": -0.2276500129699707, "compression_ratio": 1.4880952380952381, "no_speech_prob": 2.4299539290950634e-05}, {"id": 984, "seek": 514900, "start": 5171.96, "end": 5176.76, "text": " I bet English says it too.", "tokens": [286, 778, 3669, 1619, 309, 886, 13], "temperature": 0.0, "avg_logprob": -0.2276500129699707, "compression_ratio": 1.4880952380952381, "no_speech_prob": 2.4299539290950634e-05}, {"id": 985, "seek": 517676, "start": 5176.76, "end": 5180.360000000001, "text": " Polishing turds, you get the idea.", "tokens": [3635, 3807, 3243, 16063, 11, 291, 483, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.16251039505004883, "compression_ratio": 1.7647058823529411, "no_speech_prob": 5.507560217665741e-06}, {"id": 986, "seek": 517676, "start": 5180.360000000001, "end": 5186.56, "text": " And also interestingly, actually using the second derivative information, it turns out", "tokens": [400, 611, 25873, 11, 767, 1228, 264, 1150, 13760, 1589, 11, 309, 4523, 484], "temperature": 0.0, "avg_logprob": -0.16251039505004883, "compression_ratio": 1.7647058823529411, "no_speech_prob": 5.507560217665741e-06}, {"id": 987, "seek": 517676, "start": 5186.56, "end": 5190.92, "text": " it's like a magnet for saddle points, so there's some interesting theoretical results that", "tokens": [309, 311, 411, 257, 15211, 337, 30459, 2793, 11, 370, 456, 311, 512, 1880, 20864, 3542, 300], "temperature": 0.0, "avg_logprob": -0.16251039505004883, "compression_ratio": 1.7647058823529411, "no_speech_prob": 5.507560217665741e-06}, {"id": 988, "seek": 517676, "start": 5190.92, "end": 5197.860000000001, "text": " basically say it actually sends you towards nasty flat areas of the function if you use", "tokens": [1936, 584, 309, 767, 14790, 291, 3030, 17923, 4962, 3179, 295, 264, 2445, 498, 291, 764], "temperature": 0.0, "avg_logprob": -0.16251039505004883, "compression_ratio": 1.7647058823529411, "no_speech_prob": 5.507560217665741e-06}, {"id": 989, "seek": 517676, "start": 5197.860000000001, "end": 5199.360000000001, "text": " second derivative information.", "tokens": [1150, 13760, 1589, 13], "temperature": 0.0, "avg_logprob": -0.16251039505004883, "compression_ratio": 1.7647058823529411, "no_speech_prob": 5.507560217665741e-06}, {"id": 990, "seek": 517676, "start": 5199.360000000001, "end": 5200.68, "text": " So normally not a good idea.", "tokens": [407, 5646, 406, 257, 665, 1558, 13], "temperature": 0.0, "avg_logprob": -0.16251039505004883, "compression_ratio": 1.7647058823529411, "no_speech_prob": 5.507560217665741e-06}, {"id": 991, "seek": 517676, "start": 5200.68, "end": 5205.24, "text": " But in this case, we're not optimizing weights, we're optimizing pixels, so all the rules", "tokens": [583, 294, 341, 1389, 11, 321, 434, 406, 40425, 17443, 11, 321, 434, 40425, 18668, 11, 370, 439, 264, 4474], "temperature": 0.0, "avg_logprob": -0.16251039505004883, "compression_ratio": 1.7647058823529411, "no_speech_prob": 5.507560217665741e-06}, {"id": 992, "seek": 520524, "start": 5205.24, "end": 5211.24, "text": " change and actually it turns out LBFTS does make sense.", "tokens": [1319, 293, 767, 309, 4523, 484, 441, 33, 37, 7327, 775, 652, 2020, 13], "temperature": 0.0, "avg_logprob": -0.16323859970290938, "compression_ratio": 1.4408602150537635, "no_speech_prob": 5.862735179107403e-06}, {"id": 993, "seek": 520524, "start": 5211.24, "end": 5216.16, "text": " And because it does more work each time, it's a different kind of optimizer, the API is", "tokens": [400, 570, 309, 775, 544, 589, 1184, 565, 11, 309, 311, 257, 819, 733, 295, 5028, 6545, 11, 264, 9362, 307], "temperature": 0.0, "avg_logprob": -0.16323859970290938, "compression_ratio": 1.4408602150537635, "no_speech_prob": 5.862735179107403e-06}, {"id": 994, "seek": 520524, "start": 5216.16, "end": 5218.4, "text": " a little bit different in PyTorch.", "tokens": [257, 707, 857, 819, 294, 9953, 51, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.16323859970290938, "compression_ratio": 1.4408602150537635, "no_speech_prob": 5.862735179107403e-06}, {"id": 995, "seek": 520524, "start": 5218.4, "end": 5228.46, "text": " As you can see here, when you say optimizer.step, you actually pass in the loss function.", "tokens": [1018, 291, 393, 536, 510, 11, 562, 291, 584, 5028, 6545, 13, 16792, 11, 291, 767, 1320, 294, 264, 4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.16323859970290938, "compression_ratio": 1.4408602150537635, "no_speech_prob": 5.862735179107403e-06}, {"id": 996, "seek": 522846, "start": 5228.46, "end": 5235.68, "text": " So my loss function is to call step with a particular loss function, which is my activation", "tokens": [407, 452, 4470, 2445, 307, 281, 818, 1823, 365, 257, 1729, 4470, 2445, 11, 597, 307, 452, 24433], "temperature": 0.0, "avg_logprob": -0.18556604290952777, "compression_ratio": 1.6363636363636365, "no_speech_prob": 5.255285032035317e-06}, {"id": 997, "seek": 522846, "start": 5235.68, "end": 5236.68, "text": " loss.", "tokens": [4470, 13], "temperature": 0.0, "avg_logprob": -0.18556604290952777, "compression_ratio": 1.6363636363636365, "no_speech_prob": 5.255285032035317e-06}, {"id": 998, "seek": 522846, "start": 5236.68, "end": 5242.0, "text": " And as you can see, you don't inside the loop, you don't say step, step, step, but rather", "tokens": [400, 382, 291, 393, 536, 11, 291, 500, 380, 1854, 264, 6367, 11, 291, 500, 380, 584, 1823, 11, 1823, 11, 1823, 11, 457, 2831], "temperature": 0.0, "avg_logprob": -0.18556604290952777, "compression_ratio": 1.6363636363636365, "no_speech_prob": 5.255285032035317e-06}, {"id": 999, "seek": 522846, "start": 5242.0, "end": 5243.0, "text": " it looks like this.", "tokens": [309, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.18556604290952777, "compression_ratio": 1.6363636363636365, "no_speech_prob": 5.255285032035317e-06}, {"id": 1000, "seek": 522846, "start": 5243.0, "end": 5245.82, "text": " So it's a little bit different.", "tokens": [407, 309, 311, 257, 707, 857, 819, 13], "temperature": 0.0, "avg_logprob": -0.18556604290952777, "compression_ratio": 1.6363636363636365, "no_speech_prob": 5.255285032035317e-06}, {"id": 1001, "seek": 522846, "start": 5245.82, "end": 5250.8, "text": " And you're welcome to try and rewrite this to use SGD, it'll still work, it'll just take", "tokens": [400, 291, 434, 2928, 281, 853, 293, 28132, 341, 281, 764, 34520, 35, 11, 309, 603, 920, 589, 11, 309, 603, 445, 747], "temperature": 0.0, "avg_logprob": -0.18556604290952777, "compression_ratio": 1.6363636363636365, "no_speech_prob": 5.255285032035317e-06}, {"id": 1002, "seek": 522846, "start": 5250.8, "end": 5251.8, "text": " a bit longer.", "tokens": [257, 857, 2854, 13], "temperature": 0.0, "avg_logprob": -0.18556604290952777, "compression_ratio": 1.6363636363636365, "no_speech_prob": 5.255285032035317e-06}, {"id": 1003, "seek": 525180, "start": 5251.8, "end": 5259.56, "text": " I haven't tried it with SGD, I'd be interested to know how much longer it takes.", "tokens": [286, 2378, 380, 3031, 309, 365, 34520, 35, 11, 286, 1116, 312, 3102, 281, 458, 577, 709, 2854, 309, 2516, 13], "temperature": 0.0, "avg_logprob": -0.15788030049887047, "compression_ratio": 1.5233644859813085, "no_speech_prob": 7.296291641978314e-06}, {"id": 1004, "seek": 525180, "start": 5259.56, "end": 5266.6, "text": " So you can see the loss function going down, the mean squared error between the activations", "tokens": [407, 291, 393, 536, 264, 4470, 2445, 516, 760, 11, 264, 914, 8889, 6713, 1296, 264, 2430, 763], "temperature": 0.0, "avg_logprob": -0.15788030049887047, "compression_ratio": 1.5233644859813085, "no_speech_prob": 7.296291641978314e-06}, {"id": 1005, "seek": 525180, "start": 5266.6, "end": 5275.96, "text": " at layer 37 of our VGG model for our optimized image versus the target activations, and remember", "tokens": [412, 4583, 13435, 295, 527, 691, 27561, 2316, 337, 527, 26941, 3256, 5717, 264, 3779, 2430, 763, 11, 293, 1604], "temperature": 0.0, "avg_logprob": -0.15788030049887047, "compression_ratio": 1.5233644859813085, "no_speech_prob": 7.296291641978314e-06}, {"id": 1006, "seek": 525180, "start": 5275.96, "end": 5280.64, "text": " the target activations were the VGG applied to our BERT.", "tokens": [264, 3779, 2430, 763, 645, 264, 691, 27561, 6456, 281, 527, 363, 31479, 13], "temperature": 0.0, "avg_logprob": -0.15788030049887047, "compression_ratio": 1.5233644859813085, "no_speech_prob": 7.296291641978314e-06}, {"id": 1007, "seek": 528064, "start": 5280.64, "end": 5288.96, "text": " Does that make sense?", "tokens": [4402, 300, 652, 2020, 30], "temperature": 0.0, "avg_logprob": -0.1249607759363511, "compression_ratio": 1.505, "no_speech_prob": 7.071854270179756e-06}, {"id": 1008, "seek": 528064, "start": 5288.96, "end": 5293.400000000001, "text": " So we've now got a content loss.", "tokens": [407, 321, 600, 586, 658, 257, 2701, 4470, 13], "temperature": 0.0, "avg_logprob": -0.1249607759363511, "compression_ratio": 1.505, "no_speech_prob": 7.071854270179756e-06}, {"id": 1009, "seek": 528064, "start": 5293.400000000001, "end": 5300.360000000001, "text": " Now one thing I'll say about this content loss is we don't know which layer is going", "tokens": [823, 472, 551, 286, 603, 584, 466, 341, 2701, 4470, 307, 321, 500, 380, 458, 597, 4583, 307, 516], "temperature": 0.0, "avg_logprob": -0.1249607759363511, "compression_ratio": 1.505, "no_speech_prob": 7.071854270179756e-06}, {"id": 1010, "seek": 528064, "start": 5300.360000000001, "end": 5304.4400000000005, "text": " to work best, so it would be nice if we were able to experiment a little bit more, and", "tokens": [281, 589, 1151, 11, 370, 309, 576, 312, 1481, 498, 321, 645, 1075, 281, 5120, 257, 707, 857, 544, 11, 293], "temperature": 0.0, "avg_logprob": -0.1249607759363511, "compression_ratio": 1.505, "no_speech_prob": 7.071854270179756e-06}, {"id": 1011, "seek": 528064, "start": 5304.4400000000005, "end": 5306.96, "text": " the way it is here is annoying.", "tokens": [264, 636, 309, 307, 510, 307, 11304, 13], "temperature": 0.0, "avg_logprob": -0.1249607759363511, "compression_ratio": 1.505, "no_speech_prob": 7.071854270179756e-06}, {"id": 1012, "seek": 528064, "start": 5306.96, "end": 5310.52, "text": " Maybe we even want to use multiple layers.", "tokens": [2704, 321, 754, 528, 281, 764, 3866, 7914, 13], "temperature": 0.0, "avg_logprob": -0.1249607759363511, "compression_ratio": 1.505, "no_speech_prob": 7.071854270179756e-06}, {"id": 1013, "seek": 531052, "start": 5310.52, "end": 5317.820000000001, "text": " So rather than lopping off all of the layers after the one we want, wouldn't it be nice", "tokens": [407, 2831, 813, 287, 32799, 766, 439, 295, 264, 7914, 934, 264, 472, 321, 528, 11, 2759, 380, 309, 312, 1481], "temperature": 0.0, "avg_logprob": -0.13284342629568918, "compression_ratio": 1.467005076142132, "no_speech_prob": 8.267808880191296e-06}, {"id": 1014, "seek": 531052, "start": 5317.820000000001, "end": 5325.4800000000005, "text": " if we could somehow grab the activations of a few layers as it calculates?", "tokens": [498, 321, 727, 6063, 4444, 264, 2430, 763, 295, 257, 1326, 7914, 382, 309, 4322, 1024, 30], "temperature": 0.0, "avg_logprob": -0.13284342629568918, "compression_ratio": 1.467005076142132, "no_speech_prob": 8.267808880191296e-06}, {"id": 1015, "seek": 531052, "start": 5325.4800000000005, "end": 5327.6, "text": " Now we already know one way to do that.", "tokens": [823, 321, 1217, 458, 472, 636, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.13284342629568918, "compression_ratio": 1.467005076142132, "no_speech_prob": 8.267808880191296e-06}, {"id": 1016, "seek": 531052, "start": 5327.6, "end": 5335.320000000001, "text": " Back when we did SSD, we actually wrote our own network which had a number of outputs.", "tokens": [5833, 562, 321, 630, 30262, 11, 321, 767, 4114, 527, 1065, 3209, 597, 632, 257, 1230, 295, 23930, 13], "temperature": 0.0, "avg_logprob": -0.13284342629568918, "compression_ratio": 1.467005076142132, "no_speech_prob": 8.267808880191296e-06}, {"id": 1017, "seek": 533532, "start": 5335.32, "end": 5342.44, "text": " Remember, like the different convolutional layers, we spat out a different Oconv thing.", "tokens": [5459, 11, 411, 264, 819, 45216, 304, 7914, 11, 321, 15000, 484, 257, 819, 422, 1671, 85, 551, 13], "temperature": 0.0, "avg_logprob": -0.19877257589566505, "compression_ratio": 1.697211155378486, "no_speech_prob": 9.516173122392502e-06}, {"id": 1018, "seek": 533532, "start": 5342.44, "end": 5348.28, "text": " But I don't really want to go and add that to the TorchVision ResNet model, especially", "tokens": [583, 286, 500, 380, 534, 528, 281, 352, 293, 909, 300, 281, 264, 7160, 339, 53, 1991, 5015, 31890, 2316, 11, 2318], "temperature": 0.0, "avg_logprob": -0.19877257589566505, "compression_ratio": 1.697211155378486, "no_speech_prob": 9.516173122392502e-06}, {"id": 1019, "seek": 533532, "start": 5348.28, "end": 5353.84, "text": " not if later on I want to try the TorchVision VGG model and then I want to try the NestNetA", "tokens": [406, 498, 1780, 322, 286, 528, 281, 853, 264, 7160, 339, 53, 1991, 691, 27561, 2316, 293, 550, 286, 528, 281, 853, 264, 31581, 31890, 32], "temperature": 0.0, "avg_logprob": -0.19877257589566505, "compression_ratio": 1.697211155378486, "no_speech_prob": 9.516173122392502e-06}, {"id": 1020, "seek": 533532, "start": 5353.84, "end": 5354.84, "text": " model.", "tokens": [2316, 13], "temperature": 0.0, "avg_logprob": -0.19877257589566505, "compression_ratio": 1.697211155378486, "no_speech_prob": 9.516173122392502e-06}, {"id": 1021, "seek": 533532, "start": 5354.84, "end": 5360.219999999999, "text": " I don't want to go into all of them and change their outputs, besides which I'd like to easily", "tokens": [286, 500, 380, 528, 281, 352, 666, 439, 295, 552, 293, 1319, 641, 23930, 11, 11868, 597, 286, 1116, 411, 281, 3612], "temperature": 0.0, "avg_logprob": -0.19877257589566505, "compression_ratio": 1.697211155378486, "no_speech_prob": 9.516173122392502e-06}, {"id": 1022, "seek": 533532, "start": 5360.219999999999, "end": 5364.36, "text": " be able to turn certain activations on and off at demand.", "tokens": [312, 1075, 281, 1261, 1629, 2430, 763, 322, 293, 766, 412, 4733, 13], "temperature": 0.0, "avg_logprob": -0.19877257589566505, "compression_ratio": 1.697211155378486, "no_speech_prob": 9.516173122392502e-06}, {"id": 1023, "seek": 536436, "start": 5364.36, "end": 5369.5599999999995, "text": " So we've briefly touched before on this idea that PyTorch has these fantastic things called", "tokens": [407, 321, 600, 10515, 9828, 949, 322, 341, 1558, 300, 9953, 51, 284, 339, 575, 613, 5456, 721, 1219], "temperature": 0.0, "avg_logprob": -0.11841259580669981, "compression_ratio": 1.8, "no_speech_prob": 8.139633791870438e-06}, {"id": 1024, "seek": 536436, "start": 5369.5599999999995, "end": 5370.5599999999995, "text": " hooks.", "tokens": [26485, 13], "temperature": 0.0, "avg_logprob": -0.11841259580669981, "compression_ratio": 1.8, "no_speech_prob": 8.139633791870438e-06}, {"id": 1025, "seek": 536436, "start": 5370.5599999999995, "end": 5377.5599999999995, "text": " You can have forward hooks that let you plug anything you like into the forward path of", "tokens": [509, 393, 362, 2128, 26485, 300, 718, 291, 5452, 1340, 291, 411, 666, 264, 2128, 3100, 295], "temperature": 0.0, "avg_logprob": -0.11841259580669981, "compression_ratio": 1.8, "no_speech_prob": 8.139633791870438e-06}, {"id": 1026, "seek": 536436, "start": 5377.5599999999995, "end": 5382.04, "text": " a calculation, or a backward hook that lets you plug anything you like into the backward", "tokens": [257, 17108, 11, 420, 257, 23897, 6328, 300, 6653, 291, 5452, 1340, 291, 411, 666, 264, 23897], "temperature": 0.0, "avg_logprob": -0.11841259580669981, "compression_ratio": 1.8, "no_speech_prob": 8.139633791870438e-06}, {"id": 1027, "seek": 536436, "start": 5382.04, "end": 5383.12, "text": " path.", "tokens": [3100, 13], "temperature": 0.0, "avg_logprob": -0.11841259580669981, "compression_ratio": 1.8, "no_speech_prob": 8.139633791870438e-06}, {"id": 1028, "seek": 536436, "start": 5383.12, "end": 5387.639999999999, "text": " So we're going to create the world's simplest forward hook.", "tokens": [407, 321, 434, 516, 281, 1884, 264, 1002, 311, 22811, 2128, 6328, 13], "temperature": 0.0, "avg_logprob": -0.11841259580669981, "compression_ratio": 1.8, "no_speech_prob": 8.139633791870438e-06}, {"id": 1029, "seek": 536436, "start": 5387.639999999999, "end": 5391.2, "text": " And this is one of these things that almost nobody knows about.", "tokens": [400, 341, 307, 472, 295, 613, 721, 300, 1920, 5079, 3255, 466, 13], "temperature": 0.0, "avg_logprob": -0.11841259580669981, "compression_ratio": 1.8, "no_speech_prob": 8.139633791870438e-06}, {"id": 1030, "seek": 539120, "start": 5391.2, "end": 5400.12, "text": " So like almost any code you find on the Internet that implements style transfer, we'll have", "tokens": [407, 411, 1920, 604, 3089, 291, 915, 322, 264, 7703, 300, 704, 17988, 3758, 5003, 11, 321, 603, 362], "temperature": 0.0, "avg_logprob": -0.1527525378811744, "compression_ratio": 1.6740088105726871, "no_speech_prob": 2.9023040042375214e-06}, {"id": 1031, "seek": 539120, "start": 5400.12, "end": 5402.96, "text": " all kinds of horrible hacks rather than using forward hooks.", "tokens": [439, 3685, 295, 9263, 33617, 2831, 813, 1228, 2128, 26485, 13], "temperature": 0.0, "avg_logprob": -0.1527525378811744, "compression_ratio": 1.6740088105726871, "no_speech_prob": 2.9023040042375214e-06}, {"id": 1032, "seek": 539120, "start": 5402.96, "end": 5405.46, "text": " But with forward hooks, it's really easy.", "tokens": [583, 365, 2128, 26485, 11, 309, 311, 534, 1858, 13], "temperature": 0.0, "avg_logprob": -0.1527525378811744, "compression_ratio": 1.6740088105726871, "no_speech_prob": 2.9023040042375214e-06}, {"id": 1033, "seek": 539120, "start": 5405.46, "end": 5412.08, "text": " So to create a forward hook, you just create a class, and the class has to have something", "tokens": [407, 281, 1884, 257, 2128, 6328, 11, 291, 445, 1884, 257, 1508, 11, 293, 264, 1508, 575, 281, 362, 746], "temperature": 0.0, "avg_logprob": -0.1527525378811744, "compression_ratio": 1.6740088105726871, "no_speech_prob": 2.9023040042375214e-06}, {"id": 1034, "seek": 539120, "start": 5412.08, "end": 5415.36, "text": " called hook function.", "tokens": [1219, 6328, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1527525378811744, "compression_ratio": 1.6740088105726871, "no_speech_prob": 2.9023040042375214e-06}, {"id": 1035, "seek": 539120, "start": 5415.36, "end": 5420.92, "text": " And your hook function is going to receive the module that you've hooked.", "tokens": [400, 428, 6328, 2445, 307, 516, 281, 4774, 264, 10088, 300, 291, 600, 20410, 13], "temperature": 0.0, "avg_logprob": -0.1527525378811744, "compression_ratio": 1.6740088105726871, "no_speech_prob": 2.9023040042375214e-06}, {"id": 1036, "seek": 542092, "start": 5420.92, "end": 5425.64, "text": " It's going to receive the input for the forward pass, and it's going to receive the target,", "tokens": [467, 311, 516, 281, 4774, 264, 4846, 337, 264, 2128, 1320, 11, 293, 309, 311, 516, 281, 4774, 264, 3779, 11], "temperature": 0.0, "avg_logprob": -0.13510850759652945, "compression_ratio": 1.7055837563451777, "no_speech_prob": 3.726629074662924e-06}, {"id": 1037, "seek": 542092, "start": 5425.64, "end": 5428.08, "text": " and then you do whatever the hell you like.", "tokens": [293, 550, 291, 360, 2035, 264, 4921, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.13510850759652945, "compression_ratio": 1.7055837563451777, "no_speech_prob": 3.726629074662924e-06}, {"id": 1038, "seek": 542092, "start": 5428.08, "end": 5436.8, "text": " So what I'm going to do is I'm just going to store the output of this module in some", "tokens": [407, 437, 286, 478, 516, 281, 360, 307, 286, 478, 445, 516, 281, 3531, 264, 5598, 295, 341, 10088, 294, 512], "temperature": 0.0, "avg_logprob": -0.13510850759652945, "compression_ratio": 1.7055837563451777, "no_speech_prob": 3.726629074662924e-06}, {"id": 1039, "seek": 542092, "start": 5436.8, "end": 5439.04, "text": " attribute.", "tokens": [19667, 13], "temperature": 0.0, "avg_logprob": -0.13510850759652945, "compression_ratio": 1.7055837563451777, "no_speech_prob": 3.726629074662924e-06}, {"id": 1040, "seek": 542092, "start": 5439.04, "end": 5442.72, "text": " That's it.", "tokens": [663, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.13510850759652945, "compression_ratio": 1.7055837563451777, "no_speech_prob": 3.726629074662924e-06}, {"id": 1041, "seek": 542092, "start": 5442.72, "end": 5446.32, "text": " So this can actually be called anything you like, but hook function seems to be the standard.", "tokens": [407, 341, 393, 767, 312, 1219, 1340, 291, 411, 11, 457, 6328, 2445, 2544, 281, 312, 264, 3832, 13], "temperature": 0.0, "avg_logprob": -0.13510850759652945, "compression_ratio": 1.7055837563451777, "no_speech_prob": 3.726629074662924e-06}, {"id": 1042, "seek": 544632, "start": 5446.32, "end": 5452.32, "text": " You can see what happens here in the constructor is I store inside some attribute the result", "tokens": [509, 393, 536, 437, 2314, 510, 294, 264, 47479, 307, 286, 3531, 1854, 512, 19667, 264, 1874], "temperature": 0.0, "avg_logprob": -0.14707347044010752, "compression_ratio": 1.778301886792453, "no_speech_prob": 7.4112508627877105e-06}, {"id": 1043, "seek": 544632, "start": 5452.32, "end": 5459.36, "text": " of, this is going to be the layer that I'm going to hook, you go module.registerForwardHook", "tokens": [295, 11, 341, 307, 516, 281, 312, 264, 4583, 300, 286, 478, 516, 281, 6328, 11, 291, 352, 10088, 13, 3375, 1964, 12587, 1007, 39, 1212], "temperature": 0.0, "avg_logprob": -0.14707347044010752, "compression_ratio": 1.778301886792453, "no_speech_prob": 7.4112508627877105e-06}, {"id": 1044, "seek": 544632, "start": 5459.36, "end": 5467.04, "text": " and pass in the function that you want to be called when this module, when its forward", "tokens": [293, 1320, 294, 264, 2445, 300, 291, 528, 281, 312, 1219, 562, 341, 10088, 11, 562, 1080, 2128], "temperature": 0.0, "avg_logprob": -0.14707347044010752, "compression_ratio": 1.778301886792453, "no_speech_prob": 7.4112508627877105e-06}, {"id": 1045, "seek": 544632, "start": 5467.04, "end": 5468.08, "text": " method is called.", "tokens": [3170, 307, 1219, 13], "temperature": 0.0, "avg_logprob": -0.14707347044010752, "compression_ratio": 1.778301886792453, "no_speech_prob": 7.4112508627877105e-06}, {"id": 1046, "seek": 544632, "start": 5468.08, "end": 5474.679999999999, "text": " So when its forward method is called, it will call self.hook function, which will store", "tokens": [407, 562, 1080, 2128, 3170, 307, 1219, 11, 309, 486, 818, 2698, 13, 71, 1212, 2445, 11, 597, 486, 3531], "temperature": 0.0, "avg_logprob": -0.14707347044010752, "compression_ratio": 1.778301886792453, "no_speech_prob": 7.4112508627877105e-06}, {"id": 1047, "seek": 547468, "start": 5474.68, "end": 5482.280000000001, "text": " the output in an attribute called features.", "tokens": [264, 5598, 294, 364, 19667, 1219, 4122, 13], "temperature": 0.0, "avg_logprob": -0.1452782154083252, "compression_ratio": 1.5, "no_speech_prob": 9.422434459338547e-07}, {"id": 1048, "seek": 547468, "start": 5482.280000000001, "end": 5491.820000000001, "text": " So now what we can do is we can create our VGG as before, and let's set it to not trainable", "tokens": [407, 586, 437, 321, 393, 360, 307, 321, 393, 1884, 527, 691, 27561, 382, 949, 11, 293, 718, 311, 992, 309, 281, 406, 3847, 712], "temperature": 0.0, "avg_logprob": -0.1452782154083252, "compression_ratio": 1.5, "no_speech_prob": 9.422434459338547e-07}, {"id": 1049, "seek": 547468, "start": 5491.820000000001, "end": 5496.6, "text": " so we don't waste time and memory calculating gradients for it.", "tokens": [370, 321, 500, 380, 5964, 565, 293, 4675, 28258, 2771, 2448, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.1452782154083252, "compression_ratio": 1.5, "no_speech_prob": 9.422434459338547e-07}, {"id": 1050, "seek": 547468, "start": 5496.6, "end": 5501.860000000001, "text": " And let's go through and find out, let's find all of the max pool layers.", "tokens": [400, 718, 311, 352, 807, 293, 915, 484, 11, 718, 311, 915, 439, 295, 264, 11469, 7005, 7914, 13], "temperature": 0.0, "avg_logprob": -0.1452782154083252, "compression_ratio": 1.5, "no_speech_prob": 9.422434459338547e-07}, {"id": 1051, "seek": 550186, "start": 5501.86, "end": 5508.12, "text": " So let's go through all of the children of this module, and if it's a max pool layer,", "tokens": [407, 718, 311, 352, 807, 439, 295, 264, 2227, 295, 341, 10088, 11, 293, 498, 309, 311, 257, 11469, 7005, 4583, 11], "temperature": 0.0, "avg_logprob": -0.16532819411333868, "compression_ratio": 1.7183098591549295, "no_speech_prob": 2.1568134798144456e-06}, {"id": 1052, "seek": 550186, "start": 5508.12, "end": 5511.2, "text": " let's spit out index-1.", "tokens": [718, 311, 22127, 484, 8186, 12, 16, 13], "temperature": 0.0, "avg_logprob": -0.16532819411333868, "compression_ratio": 1.7183098591549295, "no_speech_prob": 2.1568134798144456e-06}, {"id": 1053, "seek": 550186, "start": 5511.2, "end": 5514.24, "text": " So that's going to give me the layer before the max pool.", "tokens": [407, 300, 311, 516, 281, 976, 385, 264, 4583, 949, 264, 11469, 7005, 13], "temperature": 0.0, "avg_logprob": -0.16532819411333868, "compression_ratio": 1.7183098591549295, "no_speech_prob": 2.1568134798144456e-06}, {"id": 1054, "seek": 550186, "start": 5514.24, "end": 5519.28, "text": " And so in general, the layer before a max pool or the layer before a stride2 conv is", "tokens": [400, 370, 294, 2674, 11, 264, 4583, 949, 257, 11469, 7005, 420, 264, 4583, 949, 257, 1056, 482, 17, 3754, 307], "temperature": 0.0, "avg_logprob": -0.16532819411333868, "compression_ratio": 1.7183098591549295, "no_speech_prob": 2.1568134798144456e-06}, {"id": 1055, "seek": 550186, "start": 5519.28, "end": 5528.08, "text": " a very interesting layer, because it's like it's the most complete representation we have", "tokens": [257, 588, 1880, 4583, 11, 570, 309, 311, 411, 309, 311, 264, 881, 3566, 10290, 321, 362], "temperature": 0.0, "avg_logprob": -0.16532819411333868, "compression_ratio": 1.7183098591549295, "no_speech_prob": 2.1568134798144456e-06}, {"id": 1056, "seek": 550186, "start": 5528.08, "end": 5530.719999999999, "text": " at that grid cell size.", "tokens": [412, 300, 10748, 2815, 2744, 13], "temperature": 0.0, "avg_logprob": -0.16532819411333868, "compression_ratio": 1.7183098591549295, "no_speech_prob": 2.1568134798144456e-06}, {"id": 1057, "seek": 553072, "start": 5530.72, "end": 5534.08, "text": " Because the very next layer is changing the grid.", "tokens": [1436, 264, 588, 958, 4583, 307, 4473, 264, 10748, 13], "temperature": 0.0, "avg_logprob": -0.11940957152325174, "compression_ratio": 1.603864734299517, "no_speech_prob": 7.527926300099352e-06}, {"id": 1058, "seek": 553072, "start": 5534.08, "end": 5542.52, "text": " So that seems to me like a good place to grab the content loss from, is the best, most semantic,", "tokens": [407, 300, 2544, 281, 385, 411, 257, 665, 1081, 281, 4444, 264, 2701, 4470, 490, 11, 307, 264, 1151, 11, 881, 47982, 11], "temperature": 0.0, "avg_logprob": -0.11940957152325174, "compression_ratio": 1.603864734299517, "no_speech_prob": 7.527926300099352e-06}, {"id": 1059, "seek": 553072, "start": 5542.52, "end": 5546.04, "text": " most interesting content we have at that grid size.", "tokens": [881, 1880, 2701, 321, 362, 412, 300, 10748, 2744, 13], "temperature": 0.0, "avg_logprob": -0.11940957152325174, "compression_ratio": 1.603864734299517, "no_speech_prob": 7.527926300099352e-06}, {"id": 1060, "seek": 553072, "start": 5546.04, "end": 5548.8, "text": " So that's why I'm going to pick those indexes.", "tokens": [407, 300, 311, 983, 286, 478, 516, 281, 1888, 729, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.11940957152325174, "compression_ratio": 1.603864734299517, "no_speech_prob": 7.527926300099352e-06}, {"id": 1061, "seek": 553072, "start": 5548.8, "end": 5550.72, "text": " So here they are.", "tokens": [407, 510, 436, 366, 13], "temperature": 0.0, "avg_logprob": -0.11940957152325174, "compression_ratio": 1.603864734299517, "no_speech_prob": 7.527926300099352e-06}, {"id": 1062, "seek": 553072, "start": 5550.72, "end": 5557.860000000001, "text": " Those are the indexes of the last layer before each max pool in VGG.", "tokens": [3950, 366, 264, 8186, 279, 295, 264, 1036, 4583, 949, 1184, 11469, 7005, 294, 691, 27561, 13], "temperature": 0.0, "avg_logprob": -0.11940957152325174, "compression_ratio": 1.603864734299517, "no_speech_prob": 7.527926300099352e-06}, {"id": 1063, "seek": 555786, "start": 5557.86, "end": 5563.44, "text": " So I'm going to grab this one here, 22, just for no particular reason, just to try something", "tokens": [407, 286, 478, 516, 281, 4444, 341, 472, 510, 11, 5853, 11, 445, 337, 572, 1729, 1778, 11, 445, 281, 853, 746], "temperature": 0.0, "avg_logprob": -0.1909936777750651, "compression_ratio": 1.5061728395061729, "no_speech_prob": 3.785303533732076e-06}, {"id": 1064, "seek": 555786, "start": 5563.44, "end": 5564.9, "text": " else.", "tokens": [1646, 13], "temperature": 0.0, "avg_logprob": -0.1909936777750651, "compression_ratio": 1.5061728395061729, "no_speech_prob": 3.785303533732076e-06}, {"id": 1065, "seek": 555786, "start": 5564.9, "end": 5570.98, "text": " So I'm going to say block ends 3, so that's going to be 32.", "tokens": [407, 286, 478, 516, 281, 584, 3461, 5314, 805, 11, 370, 300, 311, 516, 281, 312, 8858, 13], "temperature": 0.0, "avg_logprob": -0.1909936777750651, "compression_ratio": 1.5061728395061729, "no_speech_prob": 3.785303533732076e-06}, {"id": 1066, "seek": 555786, "start": 5570.98, "end": 5582.74, "text": " So children VGG index to block ends 3 will give me the 32nd layer of VGG as a module.", "tokens": [407, 2227, 691, 27561, 8186, 281, 3461, 5314, 805, 486, 976, 385, 264, 8858, 273, 4583, 295, 691, 27561, 382, 257, 10088, 13], "temperature": 0.0, "avg_logprob": -0.1909936777750651, "compression_ratio": 1.5061728395061729, "no_speech_prob": 3.785303533732076e-06}, {"id": 1067, "seek": 558274, "start": 5582.74, "end": 5589.84, "text": " And then if I call the save features constructor, it's going to go self.hook equals 32nd layer", "tokens": [400, 550, 498, 286, 818, 264, 3155, 4122, 47479, 11, 309, 311, 516, 281, 352, 2698, 13, 71, 1212, 6915, 8858, 273, 4583], "temperature": 0.0, "avg_logprob": -0.1361554585970365, "compression_ratio": 1.4602272727272727, "no_speech_prob": 2.3687928205617936e-06}, {"id": 1068, "seek": 558274, "start": 5589.84, "end": 5594.5199999999995, "text": " of VGG.registerForwardHook hook function.", "tokens": [295, 691, 27561, 13, 3375, 1964, 12587, 1007, 39, 1212, 6328, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1361554585970365, "compression_ratio": 1.4602272727272727, "no_speech_prob": 2.3687928205617936e-06}, {"id": 1069, "seek": 558274, "start": 5594.5199999999995, "end": 5602.44, "text": " So now every time I do a forward pass on this VGG model, it's going to store the 32nd layer's", "tokens": [407, 586, 633, 565, 286, 360, 257, 2128, 1320, 322, 341, 691, 27561, 2316, 11, 309, 311, 516, 281, 3531, 264, 8858, 273, 4583, 311], "temperature": 0.0, "avg_logprob": -0.1361554585970365, "compression_ratio": 1.4602272727272727, "no_speech_prob": 2.3687928205617936e-06}, {"id": 1070, "seek": 558274, "start": 5602.44, "end": 5609.8, "text": " output inside sf.features.", "tokens": [5598, 1854, 47095, 13, 2106, 3377, 13], "temperature": 0.0, "avg_logprob": -0.1361554585970365, "compression_ratio": 1.4602272727272727, "no_speech_prob": 2.3687928205617936e-06}, {"id": 1071, "seek": 560980, "start": 5609.8, "end": 5618.16, "text": " So we can now say, see here I'm calling my VGG network, but I'm not storing it anywhere.", "tokens": [407, 321, 393, 586, 584, 11, 536, 510, 286, 478, 5141, 452, 691, 27561, 3209, 11, 457, 286, 478, 406, 26085, 309, 4992, 13], "temperature": 0.0, "avg_logprob": -0.12260732014973959, "compression_ratio": 1.5705882352941176, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1072, "seek": 560980, "start": 5618.16, "end": 5623.38, "text": " I'm not saying activations equals VGG of my image.", "tokens": [286, 478, 406, 1566, 2430, 763, 6915, 691, 27561, 295, 452, 3256, 13], "temperature": 0.0, "avg_logprob": -0.12260732014973959, "compression_ratio": 1.5705882352941176, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1073, "seek": 560980, "start": 5623.38, "end": 5631.64, "text": " I'm calling it, throwing away the answer, and then grabbing the features that we stored", "tokens": [286, 478, 5141, 309, 11, 10238, 1314, 264, 1867, 11, 293, 550, 23771, 264, 4122, 300, 321, 12187], "temperature": 0.0, "avg_logprob": -0.12260732014973959, "compression_ratio": 1.5705882352941176, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1074, "seek": 560980, "start": 5631.64, "end": 5636.66, "text": " in our sf, in our save features object.", "tokens": [294, 527, 47095, 11, 294, 527, 3155, 4122, 2657, 13], "temperature": 0.0, "avg_logprob": -0.12260732014973959, "compression_ratio": 1.5705882352941176, "no_speech_prob": 2.1907749214733485e-06}, {"id": 1075, "seek": 563666, "start": 5636.66, "end": 5641.54, "text": " So that way, this is now going to contain, this is a forward pass.", "tokens": [407, 300, 636, 11, 341, 307, 586, 516, 281, 5304, 11, 341, 307, 257, 2128, 1320, 13], "temperature": 0.0, "avg_logprob": -0.1489008011356477, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.966966232837876e-06}, {"id": 1076, "seek": 563666, "start": 5641.54, "end": 5644.34, "text": " Now that's how you do a forward pass in PyTorch.", "tokens": [823, 300, 311, 577, 291, 360, 257, 2128, 1320, 294, 9953, 51, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.1489008011356477, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.966966232837876e-06}, {"id": 1077, "seek": 563666, "start": 5644.34, "end": 5647.639999999999, "text": " You don't say.forward, you just use it as a callable.", "tokens": [509, 500, 380, 584, 2411, 13305, 11, 291, 445, 764, 309, 382, 257, 818, 712, 13], "temperature": 0.0, "avg_logprob": -0.1489008011356477, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.966966232837876e-06}, {"id": 1078, "seek": 563666, "start": 5647.639999999999, "end": 5652.46, "text": " And using it as a callable on an nn.module automatically calls forward.", "tokens": [400, 1228, 309, 382, 257, 818, 712, 322, 364, 297, 77, 13, 8014, 2271, 6772, 5498, 2128, 13], "temperature": 0.0, "avg_logprob": -0.1489008011356477, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.966966232837876e-06}, {"id": 1079, "seek": 563666, "start": 5652.46, "end": 5656.099999999999, "text": " That's how PyTorch modules work.", "tokens": [663, 311, 577, 9953, 51, 284, 339, 16679, 589, 13], "temperature": 0.0, "avg_logprob": -0.1489008011356477, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.966966232837876e-06}, {"id": 1080, "seek": 563666, "start": 5656.099999999999, "end": 5658.08, "text": " So we call it as a callable.", "tokens": [407, 321, 818, 309, 382, 257, 818, 712, 13], "temperature": 0.0, "avg_logprob": -0.1489008011356477, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.966966232837876e-06}, {"id": 1081, "seek": 563666, "start": 5658.08, "end": 5660.0, "text": " That ends up calling our forward hook.", "tokens": [663, 5314, 493, 5141, 527, 2128, 6328, 13], "temperature": 0.0, "avg_logprob": -0.1489008011356477, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.966966232837876e-06}, {"id": 1082, "seek": 563666, "start": 5660.0, "end": 5664.68, "text": " That forward hook stores the activations in sf.features.", "tokens": [663, 2128, 6328, 9512, 264, 2430, 763, 294, 47095, 13, 2106, 3377, 13], "temperature": 0.0, "avg_logprob": -0.1489008011356477, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.966966232837876e-06}, {"id": 1083, "seek": 566468, "start": 5664.68, "end": 5675.12, "text": " And so now we have our target variable, just like before, but in a much more flexible way.", "tokens": [400, 370, 586, 321, 362, 527, 3779, 7006, 11, 445, 411, 949, 11, 457, 294, 257, 709, 544, 11358, 636, 13], "temperature": 0.0, "avg_logprob": -0.17955004915278008, "compression_ratio": 1.5767441860465117, "no_speech_prob": 1.1544569815669092e-06}, {"id": 1084, "seek": 566468, "start": 5675.12, "end": 5676.88, "text": " These are the same 4 lines of code we had earlier.", "tokens": [1981, 366, 264, 912, 1017, 3876, 295, 3089, 321, 632, 3071, 13], "temperature": 0.0, "avg_logprob": -0.17955004915278008, "compression_ratio": 1.5767441860465117, "no_speech_prob": 1.1544569815669092e-06}, {"id": 1085, "seek": 566468, "start": 5676.88, "end": 5679.280000000001, "text": " I've just stuck them into a function.", "tokens": [286, 600, 445, 5541, 552, 666, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.17955004915278008, "compression_ratio": 1.5767441860465117, "no_speech_prob": 1.1544569815669092e-06}, {"id": 1086, "seek": 566468, "start": 5679.280000000001, "end": 5686.320000000001, "text": " And so it's just giving me my random image to optimize and an optimizer to optimize that", "tokens": [400, 370, 309, 311, 445, 2902, 385, 452, 4974, 3256, 281, 19719, 293, 364, 5028, 6545, 281, 19719, 300], "temperature": 0.0, "avg_logprob": -0.17955004915278008, "compression_ratio": 1.5767441860465117, "no_speech_prob": 1.1544569815669092e-06}, {"id": 1087, "seek": 566468, "start": 5686.320000000001, "end": 5687.320000000001, "text": " image.", "tokens": [3256, 13], "temperature": 0.0, "avg_logprob": -0.17955004915278008, "compression_ratio": 1.5767441860465117, "no_speech_prob": 1.1544569815669092e-06}, {"id": 1088, "seek": 566468, "start": 5687.320000000001, "end": 5688.4400000000005, "text": " This is exactly the same code as before.", "tokens": [639, 307, 2293, 264, 912, 3089, 382, 949, 13], "temperature": 0.0, "avg_logprob": -0.17955004915278008, "compression_ratio": 1.5767441860465117, "no_speech_prob": 1.1544569815669092e-06}, {"id": 1089, "seek": 566468, "start": 5688.4400000000005, "end": 5690.4800000000005, "text": " So that gives me this.", "tokens": [407, 300, 2709, 385, 341, 13], "temperature": 0.0, "avg_logprob": -0.17955004915278008, "compression_ratio": 1.5767441860465117, "no_speech_prob": 1.1544569815669092e-06}, {"id": 1090, "seek": 569048, "start": 5690.48, "end": 5695.48, "text": " And so now I can go ahead and do exactly the same thing, but now I'm going to use a different", "tokens": [400, 370, 586, 286, 393, 352, 2286, 293, 360, 2293, 264, 912, 551, 11, 457, 586, 286, 478, 516, 281, 764, 257, 819], "temperature": 0.0, "avg_logprob": -0.13303332328796386, "compression_ratio": 1.5377777777777777, "no_speech_prob": 4.936971436109161e-06}, {"id": 1091, "seek": 569048, "start": 5695.48, "end": 5702.28, "text": " loss function, activation loss number 2, which doesn't say out equals mvgg.", "tokens": [4470, 2445, 11, 24433, 4470, 1230, 568, 11, 597, 1177, 380, 584, 484, 6915, 275, 85, 1615, 13], "temperature": 0.0, "avg_logprob": -0.13303332328796386, "compression_ratio": 1.5377777777777777, "no_speech_prob": 4.936971436109161e-06}, {"id": 1092, "seek": 569048, "start": 5702.28, "end": 5711.599999999999, "text": " Again, it calls mvgg to do a forward pass, throws away the results, and grabs sf.features.", "tokens": [3764, 11, 309, 5498, 275, 85, 1615, 281, 360, 257, 2128, 1320, 11, 19251, 1314, 264, 3542, 11, 293, 30028, 47095, 13, 2106, 3377, 13], "temperature": 0.0, "avg_logprob": -0.13303332328796386, "compression_ratio": 1.5377777777777777, "no_speech_prob": 4.936971436109161e-06}, {"id": 1093, "seek": 569048, "start": 5711.599999999999, "end": 5719.48, "text": " And so that's now my 30-second layer activations, which I can then do my MSC loss on.", "tokens": [400, 370, 300, 311, 586, 452, 2217, 12, 27375, 4583, 2430, 763, 11, 597, 286, 393, 550, 360, 452, 7395, 34, 4470, 322, 13], "temperature": 0.0, "avg_logprob": -0.13303332328796386, "compression_ratio": 1.5377777777777777, "no_speech_prob": 4.936971436109161e-06}, {"id": 1094, "seek": 571948, "start": 5719.48, "end": 5724.879999999999, "text": " You might have noticed the last loss function and this one are both multiplied by 1000.", "tokens": [509, 1062, 362, 5694, 264, 1036, 4470, 2445, 293, 341, 472, 366, 1293, 17207, 538, 9714, 13], "temperature": 0.0, "avg_logprob": -0.19517476823594834, "compression_ratio": 1.6525821596244132, "no_speech_prob": 4.7108933358686045e-06}, {"id": 1095, "seek": 571948, "start": 5724.879999999999, "end": 5726.44, "text": " Why are they multiplied by 1000?", "tokens": [1545, 366, 436, 17207, 538, 9714, 30], "temperature": 0.0, "avg_logprob": -0.19517476823594834, "compression_ratio": 1.6525821596244132, "no_speech_prob": 4.7108933358686045e-06}, {"id": 1096, "seek": 571948, "start": 5726.44, "end": 5731.719999999999, "text": " Again, this was like all the things that were trying to get this lesson to not work correctly.", "tokens": [3764, 11, 341, 390, 411, 439, 264, 721, 300, 645, 1382, 281, 483, 341, 6898, 281, 406, 589, 8944, 13], "temperature": 0.0, "avg_logprob": -0.19517476823594834, "compression_ratio": 1.6525821596244132, "no_speech_prob": 4.7108933358686045e-06}, {"id": 1097, "seek": 571948, "start": 5731.719999999999, "end": 5733.32, "text": " I didn't used to have the 1000.", "tokens": [286, 994, 380, 1143, 281, 362, 264, 9714, 13], "temperature": 0.0, "avg_logprob": -0.19517476823594834, "compression_ratio": 1.6525821596244132, "no_speech_prob": 4.7108933358686045e-06}, {"id": 1098, "seek": 571948, "start": 5733.32, "end": 5735.919999999999, "text": " It wasn't training.", "tokens": [467, 2067, 380, 3097, 13], "temperature": 0.0, "avg_logprob": -0.19517476823594834, "compression_ratio": 1.6525821596244132, "no_speech_prob": 4.7108933358686045e-06}, {"id": 1099, "seek": 571948, "start": 5735.919999999999, "end": 5743.4, "text": " Lunchtime today, nothing was working after days of trying to get this thing to work.", "tokens": [44958, 3766, 965, 11, 1825, 390, 1364, 934, 1708, 295, 1382, 281, 483, 341, 551, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.19517476823594834, "compression_ratio": 1.6525821596244132, "no_speech_prob": 4.7108933358686045e-06}, {"id": 1100, "seek": 574340, "start": 5743.4, "end": 5751.44, "text": " And finally, just randomly noticed, the last functions, the numbers are really low, like", "tokens": [400, 2721, 11, 445, 16979, 5694, 11, 264, 1036, 6828, 11, 264, 3547, 366, 534, 2295, 11, 411], "temperature": 0.0, "avg_logprob": -0.19336523576216263, "compression_ratio": 1.6980392156862745, "no_speech_prob": 2.2959122816246236e-06}, {"id": 1101, "seek": 574340, "start": 5751.44, "end": 5753.839999999999, "text": " 10e and x7.", "tokens": [1266, 68, 293, 2031, 22, 13], "temperature": 0.0, "avg_logprob": -0.19336523576216263, "compression_ratio": 1.6980392156862745, "no_speech_prob": 2.2959122816246236e-06}, {"id": 1102, "seek": 574340, "start": 5753.839999999999, "end": 5756.28, "text": " And I just thought, what if they weren't so low?", "tokens": [400, 286, 445, 1194, 11, 437, 498, 436, 4999, 380, 370, 2295, 30], "temperature": 0.0, "avg_logprob": -0.19336523576216263, "compression_ratio": 1.6980392156862745, "no_speech_prob": 2.2959122816246236e-06}, {"id": 1103, "seek": 574340, "start": 5756.28, "end": 5759.259999999999, "text": " So I multiplied them by 1000 and it started working.", "tokens": [407, 286, 17207, 552, 538, 9714, 293, 309, 1409, 1364, 13], "temperature": 0.0, "avg_logprob": -0.19336523576216263, "compression_ratio": 1.6980392156862745, "no_speech_prob": 2.2959122816246236e-06}, {"id": 1104, "seek": 574340, "start": 5759.259999999999, "end": 5761.44, "text": " So why did it not work?", "tokens": [407, 983, 630, 309, 406, 589, 30], "temperature": 0.0, "avg_logprob": -0.19336523576216263, "compression_ratio": 1.6980392156862745, "no_speech_prob": 2.2959122816246236e-06}, {"id": 1105, "seek": 574340, "start": 5761.44, "end": 5765.799999999999, "text": " Because we're doing single precision floating point, and single precision floating point", "tokens": [1436, 321, 434, 884, 2167, 18356, 12607, 935, 11, 293, 2167, 18356, 12607, 935], "temperature": 0.0, "avg_logprob": -0.19336523576216263, "compression_ratio": 1.6980392156862745, "no_speech_prob": 2.2959122816246236e-06}, {"id": 1106, "seek": 574340, "start": 5765.799999999999, "end": 5767.42, "text": " ain't that precise.", "tokens": [7862, 380, 300, 13600, 13], "temperature": 0.0, "avg_logprob": -0.19336523576216263, "compression_ratio": 1.6980392156862745, "no_speech_prob": 2.2959122816246236e-06}, {"id": 1107, "seek": 574340, "start": 5767.42, "end": 5770.879999999999, "text": " And particularly once you're getting gradients that are kind of small and then you're multiplying", "tokens": [400, 4098, 1564, 291, 434, 1242, 2771, 2448, 300, 366, 733, 295, 1359, 293, 550, 291, 434, 30955], "temperature": 0.0, "avg_logprob": -0.19336523576216263, "compression_ratio": 1.6980392156862745, "no_speech_prob": 2.2959122816246236e-06}, {"id": 1108, "seek": 577088, "start": 5770.88, "end": 5774.8, "text": " by the learning rate, it can be kind of small, and you end up with a small number.", "tokens": [538, 264, 2539, 3314, 11, 309, 393, 312, 733, 295, 1359, 11, 293, 291, 917, 493, 365, 257, 1359, 1230, 13], "temperature": 0.0, "avg_logprob": -0.20341514872613353, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.936964160151547e-06}, {"id": 1109, "seek": 577088, "start": 5774.8, "end": 5779.52, "text": " And if it's so small, it could get rounded to 0, and that's what was happening and my", "tokens": [400, 498, 309, 311, 370, 1359, 11, 309, 727, 483, 23382, 281, 1958, 11, 293, 300, 311, 437, 390, 2737, 293, 452], "temperature": 0.0, "avg_logprob": -0.20341514872613353, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.936964160151547e-06}, {"id": 1110, "seek": 577088, "start": 5779.52, "end": 5782.76, "text": " model wasn't training.", "tokens": [2316, 2067, 380, 3097, 13], "temperature": 0.0, "avg_logprob": -0.20341514872613353, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.936964160151547e-06}, {"id": 1111, "seek": 577088, "start": 5782.76, "end": 5788.0, "text": " So I'm sure there are better ways to multiply by 1000, but whatever, it works fine.", "tokens": [407, 286, 478, 988, 456, 366, 1101, 2098, 281, 12972, 538, 9714, 11, 457, 2035, 11, 309, 1985, 2489, 13], "temperature": 0.0, "avg_logprob": -0.20341514872613353, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.936964160151547e-06}, {"id": 1112, "seek": 577088, "start": 5788.0, "end": 5791.92, "text": " It doesn't matter what you multiply a loss function by, because all you care about is", "tokens": [467, 1177, 380, 1871, 437, 291, 12972, 257, 4470, 2445, 538, 11, 570, 439, 291, 1127, 466, 307], "temperature": 0.0, "avg_logprob": -0.20341514872613353, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.936964160151547e-06}, {"id": 1113, "seek": 577088, "start": 5791.92, "end": 5797.6, "text": " its direction and its relative size.", "tokens": [1080, 3513, 293, 1080, 4972, 2744, 13], "temperature": 0.0, "avg_logprob": -0.20341514872613353, "compression_ratio": 1.6048387096774193, "no_speech_prob": 4.936964160151547e-06}, {"id": 1114, "seek": 579760, "start": 5797.6, "end": 5801.84, "text": " And interestingly, this is actually something similar we do for when we were training ImageNet.", "tokens": [400, 25873, 11, 341, 307, 767, 746, 2531, 321, 360, 337, 562, 321, 645, 3097, 29903, 31890, 13], "temperature": 0.0, "avg_logprob": -0.16870378918117948, "compression_ratio": 1.6566523605150214, "no_speech_prob": 9.223392225976568e-06}, {"id": 1115, "seek": 579760, "start": 5801.84, "end": 5807.8, "text": " We were using half precision floating point, because the Volta tensor cores require that.", "tokens": [492, 645, 1228, 1922, 18356, 12607, 935, 11, 570, 264, 8911, 1328, 40863, 24826, 3651, 300, 13], "temperature": 0.0, "avg_logprob": -0.16870378918117948, "compression_ratio": 1.6566523605150214, "no_speech_prob": 9.223392225976568e-06}, {"id": 1116, "seek": 579760, "start": 5807.8, "end": 5814.0, "text": " And it's actually a standard practice if you want to get the half precision floating point", "tokens": [400, 309, 311, 767, 257, 3832, 3124, 498, 291, 528, 281, 483, 264, 1922, 18356, 12607, 935], "temperature": 0.0, "avg_logprob": -0.16870378918117948, "compression_ratio": 1.6566523605150214, "no_speech_prob": 9.223392225976568e-06}, {"id": 1117, "seek": 579760, "start": 5814.0, "end": 5818.64, "text": " to train, you actually have to multiply the loss function by a scaling factor.", "tokens": [281, 3847, 11, 291, 767, 362, 281, 12972, 264, 4470, 2445, 538, 257, 21589, 5952, 13], "temperature": 0.0, "avg_logprob": -0.16870378918117948, "compression_ratio": 1.6566523605150214, "no_speech_prob": 9.223392225976568e-06}, {"id": 1118, "seek": 579760, "start": 5818.64, "end": 5823.08, "text": " And we were using 1024 or 512.", "tokens": [400, 321, 645, 1228, 1266, 7911, 420, 1025, 4762, 13], "temperature": 0.0, "avg_logprob": -0.16870378918117948, "compression_ratio": 1.6566523605150214, "no_speech_prob": 9.223392225976568e-06}, {"id": 1119, "seek": 582308, "start": 5823.08, "end": 5829.0, "text": " And I think FastAI is now the first library that has all of the tricks necessary to train", "tokens": [400, 286, 519, 15968, 48698, 307, 586, 264, 700, 6405, 300, 575, 439, 295, 264, 11733, 4818, 281, 3847], "temperature": 0.0, "avg_logprob": -0.20702008084133938, "compression_ratio": 1.68359375, "no_speech_prob": 4.565949893731158e-06}, {"id": 1120, "seek": 582308, "start": 5829.0, "end": 5831.24, "text": " in half precision floating point built in.", "tokens": [294, 1922, 18356, 12607, 935, 3094, 294, 13], "temperature": 0.0, "avg_logprob": -0.20702008084133938, "compression_ratio": 1.68359375, "no_speech_prob": 4.565949893731158e-06}, {"id": 1121, "seek": 582308, "start": 5831.24, "end": 5838.16, "text": " So if you have a lucky enough to have a Volta, or you can pay for a P3, if you've got a learner", "tokens": [407, 498, 291, 362, 257, 6356, 1547, 281, 362, 257, 8911, 1328, 11, 420, 291, 393, 1689, 337, 257, 430, 18, 11, 498, 291, 600, 658, 257, 33347], "temperature": 0.0, "avg_logprob": -0.20702008084133938, "compression_ratio": 1.68359375, "no_speech_prob": 4.565949893731158e-06}, {"id": 1122, "seek": 582308, "start": 5838.16, "end": 5845.24, "text": " object, you can just say learn.half, and it will now just magically train correctly half", "tokens": [2657, 11, 291, 393, 445, 584, 1466, 13, 25461, 11, 293, 309, 486, 586, 445, 39763, 3847, 8944, 1922], "temperature": 0.0, "avg_logprob": -0.20702008084133938, "compression_ratio": 1.68359375, "no_speech_prob": 4.565949893731158e-06}, {"id": 1123, "seek": 582308, "start": 5845.24, "end": 5847.76, "text": " precision floating point.", "tokens": [18356, 12607, 935, 13], "temperature": 0.0, "avg_logprob": -0.20702008084133938, "compression_ratio": 1.68359375, "no_speech_prob": 4.565949893731158e-06}, {"id": 1124, "seek": 582308, "start": 5847.76, "end": 5852.16, "text": " Built into the model data objects as well, it's all automatic, and pretty sure no other", "tokens": [49822, 666, 264, 2316, 1412, 6565, 382, 731, 11, 309, 311, 439, 12509, 11, 293, 1238, 988, 572, 661], "temperature": 0.0, "avg_logprob": -0.20702008084133938, "compression_ratio": 1.68359375, "no_speech_prob": 4.565949893731158e-06}, {"id": 1125, "seek": 585216, "start": 5852.16, "end": 5857.04, "text": " library does that.", "tokens": [6405, 775, 300, 13], "temperature": 0.0, "avg_logprob": -0.16929663782534393, "compression_ratio": 1.7064676616915422, "no_speech_prob": 1.7231377569260076e-05}, {"id": 1126, "seek": 585216, "start": 5857.04, "end": 5860.68, "text": " So this is just doing the same thing on a slightly earlier layer.", "tokens": [407, 341, 307, 445, 884, 264, 912, 551, 322, 257, 4748, 3071, 4583, 13], "temperature": 0.0, "avg_logprob": -0.16929663782534393, "compression_ratio": 1.7064676616915422, "no_speech_prob": 1.7231377569260076e-05}, {"id": 1127, "seek": 585216, "start": 5860.68, "end": 5867.44, "text": " And you can see that the bird looks, the later layer doesn't look very bird-like at all,", "tokens": [400, 291, 393, 536, 300, 264, 5255, 1542, 11, 264, 1780, 4583, 1177, 380, 574, 588, 5255, 12, 4092, 412, 439, 11], "temperature": 0.0, "avg_logprob": -0.16929663782534393, "compression_ratio": 1.7064676616915422, "no_speech_prob": 1.7231377569260076e-05}, {"id": 1128, "seek": 585216, "start": 5867.44, "end": 5869.12, "text": " but you can kind of tell it's a bird.", "tokens": [457, 291, 393, 733, 295, 980, 309, 311, 257, 5255, 13], "temperature": 0.0, "avg_logprob": -0.16929663782534393, "compression_ratio": 1.7064676616915422, "no_speech_prob": 1.7231377569260076e-05}, {"id": 1129, "seek": 585216, "start": 5869.12, "end": 5871.8, "text": " Slightly earlier layer, more bird-like.", "tokens": [318, 44872, 3071, 4583, 11, 544, 5255, 12, 4092, 13], "temperature": 0.0, "avg_logprob": -0.16929663782534393, "compression_ratio": 1.7064676616915422, "no_speech_prob": 1.7231377569260076e-05}, {"id": 1130, "seek": 585216, "start": 5871.8, "end": 5881.84, "text": " And hopefully that makes sense to you that earlier layers are getting closer to the pixels.", "tokens": [400, 4696, 300, 1669, 2020, 281, 291, 300, 3071, 7914, 366, 1242, 4966, 281, 264, 18668, 13], "temperature": 0.0, "avg_logprob": -0.16929663782534393, "compression_ratio": 1.7064676616915422, "no_speech_prob": 1.7231377569260076e-05}, {"id": 1131, "seek": 588184, "start": 5881.84, "end": 5891.360000000001, "text": " It's a smaller grid size, more grid cells, each cell is smaller, smaller receptive field,", "tokens": [467, 311, 257, 4356, 10748, 2744, 11, 544, 10748, 5438, 11, 1184, 2815, 307, 4356, 11, 4356, 45838, 2519, 11], "temperature": 0.0, "avg_logprob": -0.16259031710417374, "compression_ratio": 1.6278026905829597, "no_speech_prob": 7.183201432781061e-06}, {"id": 1132, "seek": 588184, "start": 5891.360000000001, "end": 5894.32, "text": " less complex semantic features.", "tokens": [1570, 3997, 47982, 4122, 13], "temperature": 0.0, "avg_logprob": -0.16259031710417374, "compression_ratio": 1.6278026905829597, "no_speech_prob": 7.183201432781061e-06}, {"id": 1133, "seek": 588184, "start": 5894.32, "end": 5898.88, "text": " So the earlier we get, the more it's going to look like a bird.", "tokens": [407, 264, 3071, 321, 483, 11, 264, 544, 309, 311, 516, 281, 574, 411, 257, 5255, 13], "temperature": 0.0, "avg_logprob": -0.16259031710417374, "compression_ratio": 1.6278026905829597, "no_speech_prob": 7.183201432781061e-06}, {"id": 1134, "seek": 588184, "start": 5898.88, "end": 5906.24, "text": " And in fact, the paper has a nice picture of that showing various different layers and", "tokens": [400, 294, 1186, 11, 264, 3035, 575, 257, 1481, 3036, 295, 300, 4099, 3683, 819, 7914, 293], "temperature": 0.0, "avg_logprob": -0.16259031710417374, "compression_ratio": 1.6278026905829597, "no_speech_prob": 7.183201432781061e-06}, {"id": 1135, "seek": 588184, "start": 5906.24, "end": 5907.6, "text": " kind of zooming into this house.", "tokens": [733, 295, 48226, 666, 341, 1782, 13], "temperature": 0.0, "avg_logprob": -0.16259031710417374, "compression_ratio": 1.6278026905829597, "no_speech_prob": 7.183201432781061e-06}, {"id": 1136, "seek": 588184, "start": 5907.6, "end": 5910.400000000001, "text": " They're trying to make this house look like this picture.", "tokens": [814, 434, 1382, 281, 652, 341, 1782, 574, 411, 341, 3036, 13], "temperature": 0.0, "avg_logprob": -0.16259031710417374, "compression_ratio": 1.6278026905829597, "no_speech_prob": 7.183201432781061e-06}, {"id": 1137, "seek": 591040, "start": 5910.4, "end": 5917.24, "text": " And you can see that later on, it's pretty messy, and earlier on, it looks like this.", "tokens": [400, 291, 393, 536, 300, 1780, 322, 11, 309, 311, 1238, 16191, 11, 293, 3071, 322, 11, 309, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.15717116646144702, "compression_ratio": 1.7347826086956522, "no_speech_prob": 6.439004209823906e-06}, {"id": 1138, "seek": 591040, "start": 5917.24, "end": 5920.12, "text": " So this is just doing what we just did.", "tokens": [407, 341, 307, 445, 884, 437, 321, 445, 630, 13], "temperature": 0.0, "avg_logprob": -0.15717116646144702, "compression_ratio": 1.7347826086956522, "no_speech_prob": 6.439004209823906e-06}, {"id": 1139, "seek": 591040, "start": 5920.12, "end": 5926.4, "text": " And I will say, one of the things I've noticed in our study group is anytime I say to answer", "tokens": [400, 286, 486, 584, 11, 472, 295, 264, 721, 286, 600, 5694, 294, 527, 2979, 1594, 307, 13038, 286, 584, 281, 1867], "temperature": 0.0, "avg_logprob": -0.15717116646144702, "compression_ratio": 1.7347826086956522, "no_speech_prob": 6.439004209823906e-06}, {"id": 1140, "seek": 591040, "start": 5926.4, "end": 5932.08, "text": " a question, anytime I say, read the paper, there's a thing in the paper that tells you", "tokens": [257, 1168, 11, 13038, 286, 584, 11, 1401, 264, 3035, 11, 456, 311, 257, 551, 294, 264, 3035, 300, 5112, 291], "temperature": 0.0, "avg_logprob": -0.15717116646144702, "compression_ratio": 1.7347826086956522, "no_speech_prob": 6.439004209823906e-06}, {"id": 1141, "seek": 591040, "start": 5932.08, "end": 5936.2, "text": " the answer to that question, there's always this shocked look.", "tokens": [264, 1867, 281, 300, 1168, 11, 456, 311, 1009, 341, 12763, 574, 13], "temperature": 0.0, "avg_logprob": -0.15717116646144702, "compression_ratio": 1.7347826086956522, "no_speech_prob": 6.439004209823906e-06}, {"id": 1142, "seek": 591040, "start": 5936.2, "end": 5937.2, "text": " Read the paper?", "tokens": [17604, 264, 3035, 30], "temperature": 0.0, "avg_logprob": -0.15717116646144702, "compression_ratio": 1.7347826086956522, "no_speech_prob": 6.439004209823906e-06}, {"id": 1143, "seek": 591040, "start": 5937.2, "end": 5938.2, "text": " Me?", "tokens": [1923, 30], "temperature": 0.0, "avg_logprob": -0.15717116646144702, "compression_ratio": 1.7347826086956522, "no_speech_prob": 6.439004209823906e-06}, {"id": 1144, "seek": 591040, "start": 5938.2, "end": 5939.2, "text": " The paper?", "tokens": [440, 3035, 30], "temperature": 0.0, "avg_logprob": -0.15717116646144702, "compression_ratio": 1.7347826086956522, "no_speech_prob": 6.439004209823906e-06}, {"id": 1145, "seek": 593920, "start": 5939.2, "end": 5945.76, "text": " But seriously, the papers have, they've done these experiments and drawn the pictures.", "tokens": [583, 6638, 11, 264, 10577, 362, 11, 436, 600, 1096, 613, 12050, 293, 10117, 264, 5242, 13], "temperature": 0.0, "avg_logprob": -0.1728495115874916, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.6964120732154697e-05}, {"id": 1146, "seek": 593920, "start": 5945.76, "end": 5948.84, "text": " Like there's all this stuff in the papers.", "tokens": [1743, 456, 311, 439, 341, 1507, 294, 264, 10577, 13], "temperature": 0.0, "avg_logprob": -0.1728495115874916, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.6964120732154697e-05}, {"id": 1147, "seek": 593920, "start": 5948.84, "end": 5954.36, "text": " It doesn't mean you have to read every part of the paper, but at least look at the pictures.", "tokens": [467, 1177, 380, 914, 291, 362, 281, 1401, 633, 644, 295, 264, 3035, 11, 457, 412, 1935, 574, 412, 264, 5242, 13], "temperature": 0.0, "avg_logprob": -0.1728495115874916, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.6964120732154697e-05}, {"id": 1148, "seek": 593920, "start": 5954.36, "end": 5960.36, "text": " So check out the Gaddy's paper, it's got nice pictures.", "tokens": [407, 1520, 484, 264, 37171, 3173, 311, 3035, 11, 309, 311, 658, 1481, 5242, 13], "temperature": 0.0, "avg_logprob": -0.1728495115874916, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.6964120732154697e-05}, {"id": 1149, "seek": 593920, "start": 5960.36, "end": 5962.28, "text": " So they've done the experiment for us.", "tokens": [407, 436, 600, 1096, 264, 5120, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.1728495115874916, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.6964120732154697e-05}, {"id": 1150, "seek": 593920, "start": 5962.28, "end": 5963.88, "text": " They basically did this experiment.", "tokens": [814, 1936, 630, 341, 5120, 13], "temperature": 0.0, "avg_logprob": -0.1728495115874916, "compression_ratio": 1.7475247524752475, "no_speech_prob": 1.6964120732154697e-05}, {"id": 1151, "seek": 596388, "start": 5963.88, "end": 5970.12, "text": " But it looks like they didn't go as deep, they just got some earlier ones.", "tokens": [583, 309, 1542, 411, 436, 994, 380, 352, 382, 2452, 11, 436, 445, 658, 512, 3071, 2306, 13], "temperature": 0.0, "avg_logprob": -0.13838895161946616, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.240874881768832e-06}, {"id": 1152, "seek": 596388, "start": 5970.12, "end": 5973.96, "text": " The next thing we need to do is to create style loss.", "tokens": [440, 958, 551, 321, 643, 281, 360, 307, 281, 1884, 3758, 4470, 13], "temperature": 0.0, "avg_logprob": -0.13838895161946616, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.240874881768832e-06}, {"id": 1153, "seek": 596388, "start": 5973.96, "end": 5979.56, "text": " So we've already got the loss, which is how much like the bird is it.", "tokens": [407, 321, 600, 1217, 658, 264, 4470, 11, 597, 307, 577, 709, 411, 264, 5255, 307, 309, 13], "temperature": 0.0, "avg_logprob": -0.13838895161946616, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.240874881768832e-06}, {"id": 1154, "seek": 596388, "start": 5979.56, "end": 5985.52, "text": " Now we need how much like this painting's style is it.", "tokens": [823, 321, 643, 577, 709, 411, 341, 5370, 311, 3758, 307, 309, 13], "temperature": 0.0, "avg_logprob": -0.13838895161946616, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.240874881768832e-06}, {"id": 1155, "seek": 596388, "start": 5985.52, "end": 5987.52, "text": " And we're going to do nearly the same thing.", "tokens": [400, 321, 434, 516, 281, 360, 6217, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.13838895161946616, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.240874881768832e-06}, {"id": 1156, "seek": 596388, "start": 5987.52, "end": 5991.08, "text": " We're going to grab the activations of some layer.", "tokens": [492, 434, 516, 281, 4444, 264, 2430, 763, 295, 512, 4583, 13], "temperature": 0.0, "avg_logprob": -0.13838895161946616, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.240874881768832e-06}, {"id": 1157, "seek": 599108, "start": 5991.08, "end": 6003.5199999999995, "text": " Now the problem is that the activations of some layer, let's say it was a 5x5 layer.", "tokens": [823, 264, 1154, 307, 300, 264, 2430, 763, 295, 512, 4583, 11, 718, 311, 584, 309, 390, 257, 1025, 87, 20, 4583, 13], "temperature": 0.0, "avg_logprob": -0.30093643882057886, "compression_ratio": 1.3475177304964538, "no_speech_prob": 2.2827673092251644e-05}, {"id": 1158, "seek": 599108, "start": 6003.5199999999995, "end": 6008.32, "text": " There are no 5x5 layers at 224x224, but we'll pretend.", "tokens": [821, 366, 572, 1025, 87, 20, 7914, 412, 5853, 19, 87, 7490, 19, 11, 457, 321, 603, 11865, 13], "temperature": 0.0, "avg_logprob": -0.30093643882057886, "compression_ratio": 1.3475177304964538, "no_speech_prob": 2.2827673092251644e-05}, {"id": 1159, "seek": 599108, "start": 6008.32, "end": 6012.04, "text": " 5x5x19.", "tokens": [1025, 87, 20, 87, 3405, 13], "temperature": 0.0, "avg_logprob": -0.30093643882057886, "compression_ratio": 1.3475177304964538, "no_speech_prob": 2.2827673092251644e-05}, {"id": 1160, "seek": 599108, "start": 6012.04, "end": 6021.0, "text": " Totally unrealistic sizes, but never mind.", "tokens": [22837, 42867, 11602, 11, 457, 1128, 1575, 13], "temperature": 0.0, "avg_logprob": -0.30093643882057886, "compression_ratio": 1.3475177304964538, "no_speech_prob": 2.2827673092251644e-05}, {"id": 1161, "seek": 602100, "start": 6021.0, "end": 6026.52, "text": " So here's some activations, and we can get these activations both for the image we're", "tokens": [407, 510, 311, 512, 2430, 763, 11, 293, 321, 393, 483, 613, 2430, 763, 1293, 337, 264, 3256, 321, 434], "temperature": 0.0, "avg_logprob": -0.2036033853307947, "compression_ratio": 1.5526315789473684, "no_speech_prob": 7.183169600466499e-06}, {"id": 1162, "seek": 602100, "start": 6026.52, "end": 6039.56, "text": " optimizing and for our Van Gogh painting.", "tokens": [40425, 293, 337, 527, 8979, 39690, 71, 5370, 13], "temperature": 0.0, "avg_logprob": -0.2036033853307947, "compression_ratio": 1.5526315789473684, "no_speech_prob": 7.183169600466499e-06}, {"id": 1163, "seek": 602100, "start": 6039.56, "end": 6044.28, "text": " I downloaded this from Wikipedia, and I was wondering why it was taking so long to load.", "tokens": [286, 21748, 341, 490, 28999, 11, 293, 286, 390, 6359, 983, 309, 390, 1940, 370, 938, 281, 3677, 13], "temperature": 0.0, "avg_logprob": -0.2036033853307947, "compression_ratio": 1.5526315789473684, "no_speech_prob": 7.183169600466499e-06}, {"id": 1164, "seek": 602100, "start": 6044.28, "end": 6049.6, "text": " It turns out that the Wikipedia version I downloaded was 30,000x30,000 pixels.", "tokens": [467, 4523, 484, 300, 264, 28999, 3037, 286, 21748, 390, 2217, 11, 1360, 87, 3446, 11, 1360, 18668, 13], "temperature": 0.0, "avg_logprob": -0.2036033853307947, "compression_ratio": 1.5526315789473684, "no_speech_prob": 7.183169600466499e-06}, {"id": 1165, "seek": 604960, "start": 6049.6, "end": 6055.8, "text": " It's pretty cool, they've got this serious gallery-quality archive stuff there.", "tokens": [467, 311, 1238, 1627, 11, 436, 600, 658, 341, 3156, 18378, 12, 11286, 23507, 1507, 456, 13], "temperature": 0.0, "avg_logprob": -0.18973742998563325, "compression_ratio": 1.4673913043478262, "no_speech_prob": 7.766893759253435e-06}, {"id": 1166, "seek": 604960, "start": 6055.8, "end": 6061.92, "text": " I didn't know it existed, so don't try and run a neural net on that.", "tokens": [286, 994, 380, 458, 309, 13135, 11, 370, 500, 380, 853, 293, 1190, 257, 18161, 2533, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.18973742998563325, "compression_ratio": 1.4673913043478262, "no_speech_prob": 7.766893759253435e-06}, {"id": 1167, "seek": 604960, "start": 6061.92, "end": 6068.200000000001, "text": " Totally killed my Jupyter Notebook.", "tokens": [22837, 4652, 452, 22125, 88, 391, 11633, 2939, 13], "temperature": 0.0, "avg_logprob": -0.18973742998563325, "compression_ratio": 1.4673913043478262, "no_speech_prob": 7.766893759253435e-06}, {"id": 1168, "seek": 604960, "start": 6068.200000000001, "end": 6074.900000000001, "text": " So we can do that for our Van Gogh image, and we can do that for our optimizer image.", "tokens": [407, 321, 393, 360, 300, 337, 527, 8979, 39690, 71, 3256, 11, 293, 321, 393, 360, 300, 337, 527, 5028, 6545, 3256, 13], "temperature": 0.0, "avg_logprob": -0.18973742998563325, "compression_ratio": 1.4673913043478262, "no_speech_prob": 7.766893759253435e-06}, {"id": 1169, "seek": 607490, "start": 6074.9, "end": 6080.5199999999995, "text": " And then we can compare the two, and we would end up creating an image that looks content", "tokens": [400, 550, 321, 393, 6794, 264, 732, 11, 293, 321, 576, 917, 493, 4084, 364, 3256, 300, 1542, 2701], "temperature": 0.0, "avg_logprob": -0.15188096250806535, "compression_ratio": 1.8205128205128205, "no_speech_prob": 6.339171704894397e-06}, {"id": 1170, "seek": 607490, "start": 6080.5199999999995, "end": 6082.48, "text": " like the painting, but it's not the painting.", "tokens": [411, 264, 5370, 11, 457, 309, 311, 406, 264, 5370, 13], "temperature": 0.0, "avg_logprob": -0.15188096250806535, "compression_ratio": 1.8205128205128205, "no_speech_prob": 6.339171704894397e-06}, {"id": 1171, "seek": 607490, "start": 6082.48, "end": 6083.48, "text": " That's not what we want.", "tokens": [663, 311, 406, 437, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.15188096250806535, "compression_ratio": 1.8205128205128205, "no_speech_prob": 6.339171704894397e-06}, {"id": 1172, "seek": 607490, "start": 6083.48, "end": 6086.96, "text": " We want something with the same style, but it's not the painting, it doesn't have the", "tokens": [492, 528, 746, 365, 264, 912, 3758, 11, 457, 309, 311, 406, 264, 5370, 11, 309, 1177, 380, 362, 264], "temperature": 0.0, "avg_logprob": -0.15188096250806535, "compression_ratio": 1.8205128205128205, "no_speech_prob": 6.339171704894397e-06}, {"id": 1173, "seek": 607490, "start": 6086.96, "end": 6087.96, "text": " content.", "tokens": [2701, 13], "temperature": 0.0, "avg_logprob": -0.15188096250806535, "compression_ratio": 1.8205128205128205, "no_speech_prob": 6.339171704894397e-06}, {"id": 1174, "seek": 607490, "start": 6087.96, "end": 6093.2, "text": " So we actually want to throw away all of the spatial information.", "tokens": [407, 321, 767, 528, 281, 3507, 1314, 439, 295, 264, 23598, 1589, 13], "temperature": 0.0, "avg_logprob": -0.15188096250806535, "compression_ratio": 1.8205128205128205, "no_speech_prob": 6.339171704894397e-06}, {"id": 1175, "seek": 607490, "start": 6093.2, "end": 6100.92, "text": " We're not trying to create something that has a moon here and stars here and a church", "tokens": [492, 434, 406, 1382, 281, 1884, 746, 300, 575, 257, 7135, 510, 293, 6105, 510, 293, 257, 4128], "temperature": 0.0, "avg_logprob": -0.15188096250806535, "compression_ratio": 1.8205128205128205, "no_speech_prob": 6.339171704894397e-06}, {"id": 1176, "seek": 607490, "start": 6100.92, "end": 6103.24, "text": " here and whatever.", "tokens": [510, 293, 2035, 13], "temperature": 0.0, "avg_logprob": -0.15188096250806535, "compression_ratio": 1.8205128205128205, "no_speech_prob": 6.339171704894397e-06}, {"id": 1177, "seek": 610324, "start": 6103.24, "end": 6104.96, "text": " We don't want any of that.", "tokens": [492, 500, 380, 528, 604, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.16560921198885206, "compression_ratio": 1.5616438356164384, "no_speech_prob": 4.785075361724012e-06}, {"id": 1178, "seek": 610324, "start": 6104.96, "end": 6108.76, "text": " So how do we throw away all the spatial information?", "tokens": [407, 577, 360, 321, 3507, 1314, 439, 264, 23598, 1589, 30], "temperature": 0.0, "avg_logprob": -0.16560921198885206, "compression_ratio": 1.5616438356164384, "no_speech_prob": 4.785075361724012e-06}, {"id": 1179, "seek": 610324, "start": 6108.76, "end": 6118.76, "text": " What we do is, let's grab, so in this case there are like 19 faces on this, like 19 slices.", "tokens": [708, 321, 360, 307, 11, 718, 311, 4444, 11, 370, 294, 341, 1389, 456, 366, 411, 1294, 8475, 322, 341, 11, 411, 1294, 19793, 13], "temperature": 0.0, "avg_logprob": -0.16560921198885206, "compression_ratio": 1.5616438356164384, "no_speech_prob": 4.785075361724012e-06}, {"id": 1180, "seek": 610324, "start": 6118.76, "end": 6125.8, "text": " So let's grab this top slice.", "tokens": [407, 718, 311, 4444, 341, 1192, 13153, 13], "temperature": 0.0, "avg_logprob": -0.16560921198885206, "compression_ratio": 1.5616438356164384, "no_speech_prob": 4.785075361724012e-06}, {"id": 1181, "seek": 610324, "start": 6125.8, "end": 6127.0599999999995, "text": " Let's grab that top slice.", "tokens": [961, 311, 4444, 300, 1192, 13153, 13], "temperature": 0.0, "avg_logprob": -0.16560921198885206, "compression_ratio": 1.5616438356164384, "no_speech_prob": 4.785075361724012e-06}, {"id": 1182, "seek": 612706, "start": 6127.06, "end": 6134.160000000001, "text": " So that's going to be a 5x5 matrix.", "tokens": [407, 300, 311, 516, 281, 312, 257, 1025, 87, 20, 8141, 13], "temperature": 0.0, "avg_logprob": -0.16230900004758672, "compression_ratio": 1.3169014084507042, "no_speech_prob": 3.138130523439031e-06}, {"id": 1183, "seek": 612706, "start": 6134.160000000001, "end": 6141.38, "text": " And now let's flatten it.", "tokens": [400, 586, 718, 311, 24183, 309, 13], "temperature": 0.0, "avg_logprob": -0.16230900004758672, "compression_ratio": 1.3169014084507042, "no_speech_prob": 3.138130523439031e-06}, {"id": 1184, "seek": 612706, "start": 6141.38, "end": 6147.92, "text": " So now we've got a 25 long vector.", "tokens": [407, 586, 321, 600, 658, 257, 3552, 938, 8062, 13], "temperature": 0.0, "avg_logprob": -0.16230900004758672, "compression_ratio": 1.3169014084507042, "no_speech_prob": 3.138130523439031e-06}, {"id": 1185, "seek": 612706, "start": 6147.92, "end": 6156.72, "text": " Now in one stroke, we've thrown away the bulk of the spatial information by flattening it.", "tokens": [823, 294, 472, 12403, 11, 321, 600, 11732, 1314, 264, 16139, 295, 264, 23598, 1589, 538, 24183, 278, 309, 13], "temperature": 0.0, "avg_logprob": -0.16230900004758672, "compression_ratio": 1.3169014084507042, "no_speech_prob": 3.138130523439031e-06}, {"id": 1186, "seek": 615672, "start": 6156.72, "end": 6175.8, "text": " Now let's grab a second slice, so another channel, and do the same thing.", "tokens": [823, 718, 311, 4444, 257, 1150, 13153, 11, 370, 1071, 2269, 11, 293, 360, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.1773582417914208, "compression_ratio": 1.3833333333333333, "no_speech_prob": 8.939650797401555e-06}, {"id": 1187, "seek": 615672, "start": 6175.8, "end": 6184.08, "text": " So here's channel 1 flattened, here's channel 2 flattened, and they've both got 25 elements.", "tokens": [407, 510, 311, 2269, 502, 24183, 292, 11, 510, 311, 2269, 568, 24183, 292, 11, 293, 436, 600, 1293, 658, 3552, 4959, 13], "temperature": 0.0, "avg_logprob": -0.1773582417914208, "compression_ratio": 1.3833333333333333, "no_speech_prob": 8.939650797401555e-06}, {"id": 1188, "seek": 618408, "start": 6184.08, "end": 6191.24, "text": " And now let's take the dot product, which we can do with at.", "tokens": [400, 586, 718, 311, 747, 264, 5893, 1674, 11, 597, 321, 393, 360, 365, 412, 13], "temperature": 0.0, "avg_logprob": -0.20940598674204158, "compression_ratio": 1.731958762886598, "no_speech_prob": 4.785078090208117e-06}, {"id": 1189, "seek": 618408, "start": 6191.24, "end": 6197.76, "text": " And so the dot product is going to give us one number.", "tokens": [400, 370, 264, 5893, 1674, 307, 516, 281, 976, 505, 472, 1230, 13], "temperature": 0.0, "avg_logprob": -0.20940598674204158, "compression_ratio": 1.731958762886598, "no_speech_prob": 4.785078090208117e-06}, {"id": 1190, "seek": 618408, "start": 6197.76, "end": 6199.72, "text": " What's that number?", "tokens": [708, 311, 300, 1230, 30], "temperature": 0.0, "avg_logprob": -0.20940598674204158, "compression_ratio": 1.731958762886598, "no_speech_prob": 4.785078090208117e-06}, {"id": 1191, "seek": 618408, "start": 6199.72, "end": 6202.12, "text": " What is it telling us?", "tokens": [708, 307, 309, 3585, 505, 30], "temperature": 0.0, "avg_logprob": -0.20940598674204158, "compression_ratio": 1.731958762886598, "no_speech_prob": 4.785078090208117e-06}, {"id": 1192, "seek": 618408, "start": 6202.12, "end": 6209.04, "text": " Well assuming this is somewhere around the middle activation, the activations are somewhere", "tokens": [1042, 11926, 341, 307, 4079, 926, 264, 2808, 24433, 11, 264, 2430, 763, 366, 4079], "temperature": 0.0, "avg_logprob": -0.20940598674204158, "compression_ratio": 1.731958762886598, "no_speech_prob": 4.785078090208117e-06}, {"id": 1193, "seek": 618408, "start": 6209.04, "end": 6213.24, "text": " around the middle layer of the VGG network, we might expect some of these activations", "tokens": [926, 264, 2808, 4583, 295, 264, 691, 27561, 3209, 11, 321, 1062, 2066, 512, 295, 613, 2430, 763], "temperature": 0.0, "avg_logprob": -0.20940598674204158, "compression_ratio": 1.731958762886598, "no_speech_prob": 4.785078090208117e-06}, {"id": 1194, "seek": 621324, "start": 6213.24, "end": 6218.36, "text": " to be like how textured is the brush stroke, and some of them to be like how bright is", "tokens": [281, 312, 411, 577, 48656, 307, 264, 5287, 12403, 11, 293, 512, 295, 552, 281, 312, 411, 577, 4730, 307], "temperature": 0.0, "avg_logprob": -0.1797014594078064, "compression_ratio": 1.8282208588957056, "no_speech_prob": 6.643372216785792e-06}, {"id": 1195, "seek": 621324, "start": 6218.36, "end": 6226.24, "text": " this area, and some of them to be like is this part of a house or part of a circular", "tokens": [341, 1859, 11, 293, 512, 295, 552, 281, 312, 411, 307, 341, 644, 295, 257, 1782, 420, 644, 295, 257, 16476], "temperature": 0.0, "avg_logprob": -0.1797014594078064, "compression_ratio": 1.8282208588957056, "no_speech_prob": 6.643372216785792e-06}, {"id": 1196, "seek": 621324, "start": 6226.24, "end": 6231.599999999999, "text": " thing, or other parts to be how dark is this part of the painting.", "tokens": [551, 11, 420, 661, 3166, 281, 312, 577, 2877, 307, 341, 644, 295, 264, 5370, 13], "temperature": 0.0, "avg_logprob": -0.1797014594078064, "compression_ratio": 1.8282208588957056, "no_speech_prob": 6.643372216785792e-06}, {"id": 1197, "seek": 621324, "start": 6231.599999999999, "end": 6239.0, "text": " And so a dot product, remember, is basically a correlation.", "tokens": [400, 370, 257, 5893, 1674, 11, 1604, 11, 307, 1936, 257, 20009, 13], "temperature": 0.0, "avg_logprob": -0.1797014594078064, "compression_ratio": 1.8282208588957056, "no_speech_prob": 6.643372216785792e-06}, {"id": 1198, "seek": 623900, "start": 6239.0, "end": 6246.04, "text": " If this element and this element are both highly positive or both highly negative, it", "tokens": [759, 341, 4478, 293, 341, 4478, 366, 1293, 5405, 3353, 420, 1293, 5405, 3671, 11, 309], "temperature": 0.0, "avg_logprob": -0.14787699959494852, "compression_ratio": 1.787037037037037, "no_speech_prob": 4.936966433888301e-06}, {"id": 1199, "seek": 623900, "start": 6246.04, "end": 6251.2, "text": " gives us a big result, or else if they're the opposite, it gives us more result.", "tokens": [2709, 505, 257, 955, 1874, 11, 420, 1646, 498, 436, 434, 264, 6182, 11, 309, 2709, 505, 544, 1874, 13], "temperature": 0.0, "avg_logprob": -0.14787699959494852, "compression_ratio": 1.787037037037037, "no_speech_prob": 4.936966433888301e-06}, {"id": 1200, "seek": 623900, "start": 6251.2, "end": 6253.7, "text": " If they're both close to 0, it gives no result.", "tokens": [759, 436, 434, 1293, 1998, 281, 1958, 11, 309, 2709, 572, 1874, 13], "temperature": 0.0, "avg_logprob": -0.14787699959494852, "compression_ratio": 1.787037037037037, "no_speech_prob": 4.936966433888301e-06}, {"id": 1201, "seek": 623900, "start": 6253.7, "end": 6259.32, "text": " So it's basically a dot product as a measure of how similar these two things are.", "tokens": [407, 309, 311, 1936, 257, 5893, 1674, 382, 257, 3481, 295, 577, 2531, 613, 732, 721, 366, 13], "temperature": 0.0, "avg_logprob": -0.14787699959494852, "compression_ratio": 1.787037037037037, "no_speech_prob": 4.936966433888301e-06}, {"id": 1202, "seek": 623900, "start": 6259.32, "end": 6268.8, "text": " And so if the activations of channel 1 and channel 2 are similar, then it basically says,", "tokens": [400, 370, 498, 264, 2430, 763, 295, 2269, 502, 293, 2269, 568, 366, 2531, 11, 550, 309, 1936, 1619, 11], "temperature": 0.0, "avg_logprob": -0.14787699959494852, "compression_ratio": 1.787037037037037, "no_speech_prob": 4.936966433888301e-06}, {"id": 1203, "seek": 626880, "start": 6268.8, "end": 6275.320000000001, "text": " let's give an example, let's say this first one was like how textured are the brush strokes,", "tokens": [718, 311, 976, 364, 1365, 11, 718, 311, 584, 341, 700, 472, 390, 411, 577, 48656, 366, 264, 5287, 24493, 11], "temperature": 0.0, "avg_logprob": -0.1861557384113689, "compression_ratio": 1.9267015706806283, "no_speech_prob": 7.889227163104806e-06}, {"id": 1204, "seek": 626880, "start": 6275.320000000001, "end": 6281.0, "text": " and this one here, let's say, was like how kind of diagonally oriented are the brush", "tokens": [293, 341, 472, 510, 11, 718, 311, 584, 11, 390, 411, 577, 733, 295, 17405, 379, 21841, 366, 264, 5287], "temperature": 0.0, "avg_logprob": -0.1861557384113689, "compression_ratio": 1.9267015706806283, "no_speech_prob": 7.889227163104806e-06}, {"id": 1205, "seek": 626880, "start": 6281.0, "end": 6283.400000000001, "text": " strokes.", "tokens": [24493, 13], "temperature": 0.0, "avg_logprob": -0.1861557384113689, "compression_ratio": 1.9267015706806283, "no_speech_prob": 7.889227163104806e-06}, {"id": 1206, "seek": 626880, "start": 6283.400000000001, "end": 6287.88, "text": " And if both of these were high together and both of these were high together, then it's", "tokens": [400, 498, 1293, 295, 613, 645, 1090, 1214, 293, 1293, 295, 613, 645, 1090, 1214, 11, 550, 309, 311], "temperature": 0.0, "avg_logprob": -0.1861557384113689, "compression_ratio": 1.9267015706806283, "no_speech_prob": 7.889227163104806e-06}, {"id": 1207, "seek": 626880, "start": 6287.88, "end": 6295.24, "text": " basically saying anywhere that there's more textured brush strokes, they tend to be diagonal.", "tokens": [1936, 1566, 4992, 300, 456, 311, 544, 48656, 5287, 24493, 11, 436, 3928, 281, 312, 21539, 13], "temperature": 0.0, "avg_logprob": -0.1861557384113689, "compression_ratio": 1.9267015706806283, "no_speech_prob": 7.889227163104806e-06}, {"id": 1208, "seek": 629524, "start": 6295.24, "end": 6303.5199999999995, "text": " Another interesting one is what would be the dot product of C1 with C1?", "tokens": [3996, 1880, 472, 307, 437, 576, 312, 264, 5893, 1674, 295, 383, 16, 365, 383, 16, 30], "temperature": 0.0, "avg_logprob": -0.1581173883357518, "compression_ratio": 1.4252873563218391, "no_speech_prob": 3.50083973899018e-06}, {"id": 1209, "seek": 629524, "start": 6303.5199999999995, "end": 6311.719999999999, "text": " So that would be basically the 2-norm, the sum of the squares of that channel.", "tokens": [407, 300, 576, 312, 1936, 264, 568, 12, 13403, 11, 264, 2408, 295, 264, 19368, 295, 300, 2269, 13], "temperature": 0.0, "avg_logprob": -0.1581173883357518, "compression_ratio": 1.4252873563218391, "no_speech_prob": 3.50083973899018e-06}, {"id": 1210, "seek": 629524, "start": 6311.719999999999, "end": 6319.92, "text": " Which in other words is basically just, on average, how, sorry, let's go back, I screwed", "tokens": [3013, 294, 661, 2283, 307, 1936, 445, 11, 322, 4274, 11, 577, 11, 2597, 11, 718, 311, 352, 646, 11, 286, 20331], "temperature": 0.0, "avg_logprob": -0.1581173883357518, "compression_ratio": 1.4252873563218391, "no_speech_prob": 3.50083973899018e-06}, {"id": 1211, "seek": 629524, "start": 6319.92, "end": 6324.32, "text": " this up.", "tokens": [341, 493, 13], "temperature": 0.0, "avg_logprob": -0.1581173883357518, "compression_ratio": 1.4252873563218391, "no_speech_prob": 3.50083973899018e-06}, {"id": 1212, "seek": 632432, "start": 6324.32, "end": 6331.679999999999, "text": " Channel 1 might be texture and channel 2 might be diagonal.", "tokens": [13553, 502, 1062, 312, 8091, 293, 2269, 568, 1062, 312, 21539, 13], "temperature": 0.0, "avg_logprob": -0.14667911963029343, "compression_ratio": 1.807909604519774, "no_speech_prob": 5.014702765038237e-06}, {"id": 1213, "seek": 632432, "start": 6331.679999999999, "end": 6336.0, "text": " And this one here would be cell 1,1.", "tokens": [400, 341, 472, 510, 576, 312, 2815, 502, 11, 16, 13], "temperature": 0.0, "avg_logprob": -0.14667911963029343, "compression_ratio": 1.807909604519774, "no_speech_prob": 5.014702765038237e-06}, {"id": 1214, "seek": 632432, "start": 6336.0, "end": 6340.58, "text": " And this cell here would be like cell say 4,2.", "tokens": [400, 341, 2815, 510, 576, 312, 411, 2815, 584, 1017, 11, 17, 13], "temperature": 0.0, "avg_logprob": -0.14667911963029343, "compression_ratio": 1.807909604519774, "no_speech_prob": 5.014702765038237e-06}, {"id": 1215, "seek": 632432, "start": 6340.58, "end": 6346.16, "text": " And so, sorry, what I should have been saying is if these are both high at the same time", "tokens": [400, 370, 11, 2597, 11, 437, 286, 820, 362, 668, 1566, 307, 498, 613, 366, 1293, 1090, 412, 264, 912, 565], "temperature": 0.0, "avg_logprob": -0.14667911963029343, "compression_ratio": 1.807909604519774, "no_speech_prob": 5.014702765038237e-06}, {"id": 1216, "seek": 632432, "start": 6346.16, "end": 6352.4, "text": " and these are both high at the same time, then it's saying grid cells that have texture", "tokens": [293, 613, 366, 1293, 1090, 412, 264, 912, 565, 11, 550, 309, 311, 1566, 10748, 5438, 300, 362, 8091], "temperature": 0.0, "avg_logprob": -0.14667911963029343, "compression_ratio": 1.807909604519774, "no_speech_prob": 5.014702765038237e-06}, {"id": 1217, "seek": 635240, "start": 6352.4, "end": 6361.44, "text": " tend to also have diagonal.", "tokens": [3928, 281, 611, 362, 21539, 13], "temperature": 0.0, "avg_logprob": -0.1977268434920401, "compression_ratio": 1.3951612903225807, "no_speech_prob": 4.860433818976162e-06}, {"id": 1218, "seek": 635240, "start": 6361.44, "end": 6367.48, "text": " So this number is going to be high when grid cells that have texture also have diagonal", "tokens": [407, 341, 1230, 307, 516, 281, 312, 1090, 562, 10748, 5438, 300, 362, 8091, 611, 362, 21539], "temperature": 0.0, "avg_logprob": -0.1977268434920401, "compression_ratio": 1.3951612903225807, "no_speech_prob": 4.860433818976162e-06}, {"id": 1219, "seek": 635240, "start": 6367.48, "end": 6372.04, "text": " and when they don't, they don't.", "tokens": [293, 562, 436, 500, 380, 11, 436, 500, 380, 13], "temperature": 0.0, "avg_logprob": -0.1977268434920401, "compression_ratio": 1.3951612903225807, "no_speech_prob": 4.860433818976162e-06}, {"id": 1220, "seek": 635240, "start": 6372.04, "end": 6377.28, "text": " So that's C1.product C2.", "tokens": [407, 300, 311, 383, 16, 13, 33244, 383, 17, 13], "temperature": 0.0, "avg_logprob": -0.1977268434920401, "compression_ratio": 1.3951612903225807, "no_speech_prob": 4.860433818976162e-06}, {"id": 1221, "seek": 637728, "start": 6377.28, "end": 6388.0, "text": " Whereas C1.product C1 is basically, as we said, the 2-norm effectively, or the sum of", "tokens": [13813, 383, 16, 13, 33244, 383, 16, 307, 1936, 11, 382, 321, 848, 11, 264, 568, 12, 13403, 8659, 11, 420, 264, 2408, 295], "temperature": 0.0, "avg_logprob": -0.20287623612777048, "compression_ratio": 1.2264150943396226, "no_speech_prob": 6.540421054523904e-06}, {"id": 1222, "seek": 637728, "start": 6388.0, "end": 6391.12, "text": " the squares of C1.", "tokens": [264, 19368, 295, 383, 16, 13], "temperature": 0.0, "avg_logprob": -0.20287623612777048, "compression_ratio": 1.2264150943396226, "no_speech_prob": 6.540421054523904e-06}, {"id": 1223, "seek": 637728, "start": 6391.12, "end": 6398.719999999999, "text": " Sum over i of C1 squared.", "tokens": [8626, 670, 741, 295, 383, 16, 8889, 13], "temperature": 0.0, "avg_logprob": -0.20287623612777048, "compression_ratio": 1.2264150943396226, "no_speech_prob": 6.540421054523904e-06}, {"id": 1224, "seek": 639872, "start": 6398.72, "end": 6409.72, "text": " And this is basically saying how in how many grid cells is the textured channel active", "tokens": [400, 341, 307, 1936, 1566, 577, 294, 577, 867, 10748, 5438, 307, 264, 48656, 2269, 4967], "temperature": 0.0, "avg_logprob": -0.14272006128875303, "compression_ratio": 1.6375, "no_speech_prob": 6.083580501581309e-07}, {"id": 1225, "seek": 639872, "start": 6409.72, "end": 6411.400000000001, "text": " and how active is it.", "tokens": [293, 577, 4967, 307, 309, 13], "temperature": 0.0, "avg_logprob": -0.14272006128875303, "compression_ratio": 1.6375, "no_speech_prob": 6.083580501581309e-07}, {"id": 1226, "seek": 639872, "start": 6411.400000000001, "end": 6419.6, "text": " So in other words, C1.product C1 tells us how much textured painting is going on.", "tokens": [407, 294, 661, 2283, 11, 383, 16, 13, 33244, 383, 16, 5112, 505, 577, 709, 48656, 5370, 307, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.14272006128875303, "compression_ratio": 1.6375, "no_speech_prob": 6.083580501581309e-07}, {"id": 1227, "seek": 639872, "start": 6419.6, "end": 6426.4800000000005, "text": " And C2.product C2 tells us how much diagonal paint strokes is going on.", "tokens": [400, 383, 17, 13, 33244, 383, 17, 5112, 505, 577, 709, 21539, 4225, 24493, 307, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.14272006128875303, "compression_ratio": 1.6375, "no_speech_prob": 6.083580501581309e-07}, {"id": 1228, "seek": 642648, "start": 6426.48, "end": 6430.839999999999, "text": " And maybe C3 is bright colors.", "tokens": [400, 1310, 383, 18, 307, 4730, 4577, 13], "temperature": 0.0, "avg_logprob": -0.200575175108733, "compression_ratio": 1.3741007194244603, "no_speech_prob": 1.084514792637492e-06}, {"id": 1229, "seek": 642648, "start": 6430.839999999999, "end": 6438.04, "text": " So C3.product C3 would be how often do we have bright colored cells.", "tokens": [407, 383, 18, 13, 33244, 383, 18, 576, 312, 577, 2049, 360, 321, 362, 4730, 14332, 5438, 13], "temperature": 0.0, "avg_logprob": -0.200575175108733, "compression_ratio": 1.3741007194244603, "no_speech_prob": 1.084514792637492e-06}, {"id": 1230, "seek": 642648, "start": 6438.04, "end": 6448.28, "text": " So what we could do then is we could create a 25 by 25 matrix containing every one, channel", "tokens": [407, 437, 321, 727, 360, 550, 307, 321, 727, 1884, 257, 3552, 538, 3552, 8141, 19273, 633, 472, 11, 2269], "temperature": 0.0, "avg_logprob": -0.200575175108733, "compression_ratio": 1.3741007194244603, "no_speech_prob": 1.084514792637492e-06}, {"id": 1231, "seek": 644828, "start": 6448.28, "end": 6458.88, "text": " 1, channel 2, channel 3, channel 1, channel 2, channel 3, sorry not channel, man it's", "tokens": [502, 11, 2269, 568, 11, 2269, 805, 11, 2269, 502, 11, 2269, 568, 11, 2269, 805, 11, 2597, 406, 2269, 11, 587, 309, 311], "temperature": 0.0, "avg_logprob": -0.36103233538175883, "compression_ratio": 2.201923076923077, "no_speech_prob": 7.967030978761613e-05}, {"id": 1232, "seek": 644828, "start": 6458.88, "end": 6461.88, "text": " been a long day.", "tokens": [668, 257, 938, 786, 13], "temperature": 0.0, "avg_logprob": -0.36103233538175883, "compression_ratio": 2.201923076923077, "no_speech_prob": 7.967030978761613e-05}, {"id": 1233, "seek": 644828, "start": 6461.88, "end": 6465.5599999999995, "text": " 19, there are 19 channels.", "tokens": [1294, 11, 456, 366, 1294, 9235, 13], "temperature": 0.0, "avg_logprob": -0.36103233538175883, "compression_ratio": 2.201923076923077, "no_speech_prob": 7.967030978761613e-05}, {"id": 1234, "seek": 644828, "start": 6465.5599999999995, "end": 6468.8, "text": " 19 by 19.", "tokens": [1294, 538, 1294, 13], "temperature": 0.0, "avg_logprob": -0.36103233538175883, "compression_ratio": 2.201923076923077, "no_speech_prob": 7.967030978761613e-05}, {"id": 1235, "seek": 644828, "start": 6468.8, "end": 6478.04, "text": " Channel 1, channel 2, channel 3, channel 19, channel 1, channel 2, channel 3, channel 19,", "tokens": [13553, 502, 11, 2269, 568, 11, 2269, 805, 11, 2269, 1294, 11, 2269, 502, 11, 2269, 568, 11, 2269, 805, 11, 2269, 1294, 11], "temperature": 0.0, "avg_logprob": -0.36103233538175883, "compression_ratio": 2.201923076923077, "no_speech_prob": 7.967030978761613e-05}, {"id": 1236, "seek": 647804, "start": 6478.04, "end": 6479.32, "text": " okay.", "tokens": [1392, 13], "temperature": 0.0, "avg_logprob": -0.19320370238504292, "compression_ratio": 1.7717391304347827, "no_speech_prob": 8.664625966048334e-06}, {"id": 1237, "seek": 647804, "start": 6479.32, "end": 6484.44, "text": " And so this would be the dot product of channel 1 with channel 1, this would be the dot product", "tokens": [400, 370, 341, 576, 312, 264, 5893, 1674, 295, 2269, 502, 365, 2269, 502, 11, 341, 576, 312, 264, 5893, 1674], "temperature": 0.0, "avg_logprob": -0.19320370238504292, "compression_ratio": 1.7717391304347827, "no_speech_prob": 8.664625966048334e-06}, {"id": 1238, "seek": 647804, "start": 6484.44, "end": 6492.0, "text": " of channel 2 with channel 2, and so forth, after flattening.", "tokens": [295, 2269, 568, 365, 2269, 568, 11, 293, 370, 5220, 11, 934, 24183, 278, 13], "temperature": 0.0, "avg_logprob": -0.19320370238504292, "compression_ratio": 1.7717391304347827, "no_speech_prob": 8.664625966048334e-06}, {"id": 1239, "seek": 647804, "start": 6492.0, "end": 6497.1, "text": " And like we've discussed, mathematicians have to give everything a name.", "tokens": [400, 411, 321, 600, 7152, 11, 32811, 2567, 362, 281, 976, 1203, 257, 1315, 13], "temperature": 0.0, "avg_logprob": -0.19320370238504292, "compression_ratio": 1.7717391304347827, "no_speech_prob": 8.664625966048334e-06}, {"id": 1240, "seek": 647804, "start": 6497.1, "end": 6504.0, "text": " So this particular matrix where you flatten something out and then do all the dot products", "tokens": [407, 341, 1729, 8141, 689, 291, 24183, 746, 484, 293, 550, 360, 439, 264, 5893, 3383], "temperature": 0.0, "avg_logprob": -0.19320370238504292, "compression_ratio": 1.7717391304347827, "no_speech_prob": 8.664625966048334e-06}, {"id": 1241, "seek": 650400, "start": 6504.0, "end": 6509.96, "text": " is called a Gram matrix.", "tokens": [307, 1219, 257, 22130, 8141, 13], "temperature": 0.0, "avg_logprob": -0.14552608951107487, "compression_ratio": 1.5603448275862069, "no_speech_prob": 5.594321009994019e-06}, {"id": 1242, "seek": 650400, "start": 6509.96, "end": 6517.46, "text": " And I'll tell you a secret, most deep learning practitioners either don't know or don't remember", "tokens": [400, 286, 603, 980, 291, 257, 4054, 11, 881, 2452, 2539, 25742, 2139, 500, 380, 458, 420, 500, 380, 1604], "temperature": 0.0, "avg_logprob": -0.14552608951107487, "compression_ratio": 1.5603448275862069, "no_speech_prob": 5.594321009994019e-06}, {"id": 1243, "seek": 650400, "start": 6517.46, "end": 6521.96, "text": " all these things like what is a Gram matrix, if they ever did study at university they", "tokens": [439, 613, 721, 411, 437, 307, 257, 22130, 8141, 11, 498, 436, 1562, 630, 2979, 412, 5454, 436], "temperature": 0.0, "avg_logprob": -0.14552608951107487, "compression_ratio": 1.5603448275862069, "no_speech_prob": 5.594321009994019e-06}, {"id": 1244, "seek": 650400, "start": 6521.96, "end": 6524.96, "text": " probably forgot it because they had a big night afterwards.", "tokens": [1391, 5298, 309, 570, 436, 632, 257, 955, 1818, 10543, 13], "temperature": 0.0, "avg_logprob": -0.14552608951107487, "compression_ratio": 1.5603448275862069, "no_speech_prob": 5.594321009994019e-06}, {"id": 1245, "seek": 650400, "start": 6524.96, "end": 6531.2, "text": " And the way it works in practice is like you realize, oh I could create a kind of non-spatial", "tokens": [400, 264, 636, 309, 1985, 294, 3124, 307, 411, 291, 4325, 11, 1954, 286, 727, 1884, 257, 733, 295, 2107, 12, 4952, 267, 831], "temperature": 0.0, "avg_logprob": -0.14552608951107487, "compression_ratio": 1.5603448275862069, "no_speech_prob": 5.594321009994019e-06}, {"id": 1246, "seek": 653120, "start": 6531.2, "end": 6537.12, "text": " representation of how the channels correlate with each other, and then when I write up", "tokens": [10290, 295, 577, 264, 9235, 48742, 365, 1184, 661, 11, 293, 550, 562, 286, 2464, 493], "temperature": 0.0, "avg_logprob": -0.20877320916803033, "compression_ratio": 1.701195219123506, "no_speech_prob": 1.544599399494473e-05}, {"id": 1247, "seek": 653120, "start": 6537.12, "end": 6541.5599999999995, "text": " the paper I have to go and ask around and say like, does this thing have a name?", "tokens": [264, 3035, 286, 362, 281, 352, 293, 1029, 926, 293, 584, 411, 11, 775, 341, 551, 362, 257, 1315, 30], "temperature": 0.0, "avg_logprob": -0.20877320916803033, "compression_ratio": 1.701195219123506, "no_speech_prob": 1.544599399494473e-05}, {"id": 1248, "seek": 653120, "start": 6541.5599999999995, "end": 6544.5199999999995, "text": " And somebody would be like, isn't that the Gram matrix?", "tokens": [400, 2618, 576, 312, 411, 11, 1943, 380, 300, 264, 22130, 8141, 30], "temperature": 0.0, "avg_logprob": -0.20877320916803033, "compression_ratio": 1.701195219123506, "no_speech_prob": 1.544599399494473e-05}, {"id": 1249, "seek": 653120, "start": 6544.5199999999995, "end": 6546.28, "text": " And you go and look it up, and it is.", "tokens": [400, 291, 352, 293, 574, 309, 493, 11, 293, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.20877320916803033, "compression_ratio": 1.701195219123506, "no_speech_prob": 1.544599399494473e-05}, {"id": 1250, "seek": 653120, "start": 6546.28, "end": 6551.2, "text": " So don't think like you have to go and study all of math first, use your intuition and", "tokens": [407, 500, 380, 519, 411, 291, 362, 281, 352, 293, 2979, 439, 295, 5221, 700, 11, 764, 428, 24002, 293], "temperature": 0.0, "avg_logprob": -0.20877320916803033, "compression_ratio": 1.701195219123506, "no_speech_prob": 1.544599399494473e-05}, {"id": 1251, "seek": 653120, "start": 6551.2, "end": 6557.76, "text": " common sense and then you worry about what the math is called later, normally.", "tokens": [2689, 2020, 293, 550, 291, 3292, 466, 437, 264, 5221, 307, 1219, 1780, 11, 5646, 13], "temperature": 0.0, "avg_logprob": -0.20877320916803033, "compression_ratio": 1.701195219123506, "no_speech_prob": 1.544599399494473e-05}, {"id": 1252, "seek": 655776, "start": 6557.76, "end": 6563.4400000000005, "text": " Sometimes it works the other way, not with me because I can't do math.", "tokens": [4803, 309, 1985, 264, 661, 636, 11, 406, 365, 385, 570, 286, 393, 380, 360, 5221, 13], "temperature": 0.0, "avg_logprob": -0.1630891575532801, "compression_ratio": 1.6363636363636365, "no_speech_prob": 6.922049942659214e-05}, {"id": 1253, "seek": 655776, "start": 6563.4400000000005, "end": 6566.4800000000005, "text": " So this is called the Gram matrix, and of course if you're a real mathematician it's", "tokens": [407, 341, 307, 1219, 264, 22130, 8141, 11, 293, 295, 1164, 498, 291, 434, 257, 957, 48281, 309, 311], "temperature": 0.0, "avg_logprob": -0.1630891575532801, "compression_ratio": 1.6363636363636365, "no_speech_prob": 6.922049942659214e-05}, {"id": 1254, "seek": 655776, "start": 6566.4800000000005, "end": 6572.22, "text": " very important that you say this as if you always knew it was a Gram matrix and you kind", "tokens": [588, 1021, 300, 291, 584, 341, 382, 498, 291, 1009, 2586, 309, 390, 257, 22130, 8141, 293, 291, 733], "temperature": 0.0, "avg_logprob": -0.1630891575532801, "compression_ratio": 1.6363636363636365, "no_speech_prob": 6.922049942659214e-05}, {"id": 1255, "seek": 655776, "start": 6572.22, "end": 6575.4400000000005, "text": " of just go, oh yes we just calculated the Gram matrix.", "tokens": [295, 445, 352, 11, 1954, 2086, 321, 445, 15598, 264, 22130, 8141, 13], "temperature": 0.0, "avg_logprob": -0.1630891575532801, "compression_ratio": 1.6363636363636365, "no_speech_prob": 6.922049942659214e-05}, {"id": 1256, "seek": 655776, "start": 6575.4400000000005, "end": 6578.92, "text": " That's really important.", "tokens": [663, 311, 534, 1021, 13], "temperature": 0.0, "avg_logprob": -0.1630891575532801, "compression_ratio": 1.6363636363636365, "no_speech_prob": 6.922049942659214e-05}, {"id": 1257, "seek": 657892, "start": 6578.92, "end": 6591.76, "text": " So the Gram matrix then is this kind of map of the diagonal is perhaps the most interesting.", "tokens": [407, 264, 22130, 8141, 550, 307, 341, 733, 295, 4471, 295, 264, 21539, 307, 4317, 264, 881, 1880, 13], "temperature": 0.0, "avg_logprob": -0.1226122654401339, "compression_ratio": 1.6893939393939394, "no_speech_prob": 1.6028070604079403e-06}, {"id": 1258, "seek": 657892, "start": 6591.76, "end": 6598.08, "text": " The diagonal is like which channels are the most active, and then the off diagonal is", "tokens": [440, 21539, 307, 411, 597, 9235, 366, 264, 881, 4967, 11, 293, 550, 264, 766, 21539, 307], "temperature": 0.0, "avg_logprob": -0.1226122654401339, "compression_ratio": 1.6893939393939394, "no_speech_prob": 1.6028070604079403e-06}, {"id": 1259, "seek": 657892, "start": 6598.08, "end": 6601.64, "text": " like which channels tend to appear together.", "tokens": [411, 597, 9235, 3928, 281, 4204, 1214, 13], "temperature": 0.0, "avg_logprob": -0.1226122654401339, "compression_ratio": 1.6893939393939394, "no_speech_prob": 1.6028070604079403e-06}, {"id": 1260, "seek": 660164, "start": 6601.64, "end": 6609.88, "text": " And overall, if two pictures have the same style, then we're expecting that some layer", "tokens": [400, 4787, 11, 498, 732, 5242, 362, 264, 912, 3758, 11, 550, 321, 434, 9650, 300, 512, 4583], "temperature": 0.0, "avg_logprob": -0.15461932288275826, "compression_ratio": 1.6322314049586777, "no_speech_prob": 5.896410470995761e-07}, {"id": 1261, "seek": 660164, "start": 6609.88, "end": 6615.68, "text": " of activations, they will have similar Gram matrices, because if we found the level of", "tokens": [295, 2430, 763, 11, 436, 486, 362, 2531, 22130, 32284, 11, 570, 498, 321, 1352, 264, 1496, 295], "temperature": 0.0, "avg_logprob": -0.15461932288275826, "compression_ratio": 1.6322314049586777, "no_speech_prob": 5.896410470995761e-07}, {"id": 1262, "seek": 660164, "start": 6615.68, "end": 6621.56, "text": " activations that capture a lot of stuff about like paint strokes and colors and stuff, then", "tokens": [2430, 763, 300, 7983, 257, 688, 295, 1507, 466, 411, 4225, 24493, 293, 4577, 293, 1507, 11, 550], "temperature": 0.0, "avg_logprob": -0.15461932288275826, "compression_ratio": 1.6322314049586777, "no_speech_prob": 5.896410470995761e-07}, {"id": 1263, "seek": 660164, "start": 6621.56, "end": 6626.02, "text": " the diagonal alone might even be enough.", "tokens": [264, 21539, 3312, 1062, 754, 312, 1547, 13], "temperature": 0.0, "avg_logprob": -0.15461932288275826, "compression_ratio": 1.6322314049586777, "no_speech_prob": 5.896410470995761e-07}, {"id": 1264, "seek": 660164, "start": 6626.02, "end": 6630.68, "text": " And like that's another interesting homework assignment if somebody wants to take it, is", "tokens": [400, 411, 300, 311, 1071, 1880, 14578, 15187, 498, 2618, 2738, 281, 747, 309, 11, 307], "temperature": 0.0, "avg_logprob": -0.15461932288275826, "compression_ratio": 1.6322314049586777, "no_speech_prob": 5.896410470995761e-07}, {"id": 1265, "seek": 663068, "start": 6630.68, "end": 6636.16, "text": " try doing Gattie style transfer not using the Gram matrix, but just using the diagonal", "tokens": [853, 884, 460, 1591, 414, 3758, 5003, 406, 1228, 264, 22130, 8141, 11, 457, 445, 1228, 264, 21539], "temperature": 0.0, "avg_logprob": -0.25669359693340227, "compression_ratio": 1.6590909090909092, "no_speech_prob": 1.593653178133536e-05}, {"id": 1266, "seek": 663068, "start": 6636.16, "end": 6638.200000000001, "text": " of the Gram matrix.", "tokens": [295, 264, 22130, 8141, 13], "temperature": 0.0, "avg_logprob": -0.25669359693340227, "compression_ratio": 1.6590909090909092, "no_speech_prob": 1.593653178133536e-05}, {"id": 1267, "seek": 663068, "start": 6638.200000000001, "end": 6643.12, "text": " And that would be like a single line of code to change, but I haven't seen it tried.", "tokens": [400, 300, 576, 312, 411, 257, 2167, 1622, 295, 3089, 281, 1319, 11, 457, 286, 2378, 380, 1612, 309, 3031, 13], "temperature": 0.0, "avg_logprob": -0.25669359693340227, "compression_ratio": 1.6590909090909092, "no_speech_prob": 1.593653178133536e-05}, {"id": 1268, "seek": 663068, "start": 6643.12, "end": 6648.280000000001, "text": " I don't know if it would work at all, but it might work fine.", "tokens": [286, 500, 380, 458, 498, 309, 576, 589, 412, 439, 11, 457, 309, 1062, 589, 2489, 13], "temperature": 0.0, "avg_logprob": -0.25669359693340227, "compression_ratio": 1.6590909090909092, "no_speech_prob": 1.593653178133536e-05}, {"id": 1269, "seek": 663068, "start": 6648.280000000001, "end": 6653.320000000001, "text": " Christine, you've tried it.", "tokens": [24038, 11, 291, 600, 3031, 309, 13], "temperature": 0.0, "avg_logprob": -0.25669359693340227, "compression_ratio": 1.6590909090909092, "no_speech_prob": 1.593653178133536e-05}, {"id": 1270, "seek": 663068, "start": 6653.320000000001, "end": 6656.84, "text": " I was going to say I have tried that, and it works most of the time except when you", "tokens": [286, 390, 516, 281, 584, 286, 362, 3031, 300, 11, 293, 309, 1985, 881, 295, 264, 565, 3993, 562, 291], "temperature": 0.0, "avg_logprob": -0.25669359693340227, "compression_ratio": 1.6590909090909092, "no_speech_prob": 1.593653178133536e-05}, {"id": 1271, "seek": 665684, "start": 6656.84, "end": 6660.96, "text": " have funny pictures where you need two styles to appear in the same spot.", "tokens": [362, 4074, 5242, 689, 291, 643, 732, 13273, 281, 4204, 294, 264, 912, 4008, 13], "temperature": 0.0, "avg_logprob": -0.28173087624942555, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.280409014725592e-05}, {"id": 1272, "seek": 665684, "start": 6660.96, "end": 6664.68, "text": " So if you have like grass in one half and like a crowd in one half, and you need the", "tokens": [407, 498, 291, 362, 411, 8054, 294, 472, 1922, 293, 411, 257, 6919, 294, 472, 1922, 11, 293, 291, 643, 264], "temperature": 0.0, "avg_logprob": -0.28173087624942555, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.280409014725592e-05}, {"id": 1273, "seek": 665684, "start": 6664.68, "end": 6665.68, "text": " two styles.", "tokens": [732, 13273, 13], "temperature": 0.0, "avg_logprob": -0.28173087624942555, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.280409014725592e-05}, {"id": 1274, "seek": 665684, "start": 6665.68, "end": 6666.68, "text": " Cool.", "tokens": [8561, 13], "temperature": 0.0, "avg_logprob": -0.28173087624942555, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.280409014725592e-05}, {"id": 1275, "seek": 665684, "start": 6666.68, "end": 6669.0, "text": " You still got to do your homework.", "tokens": [509, 920, 658, 281, 360, 428, 14578, 13], "temperature": 0.0, "avg_logprob": -0.28173087624942555, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.280409014725592e-05}, {"id": 1276, "seek": 665684, "start": 6669.0, "end": 6675.96, "text": " But okay, Christine says she'll do it for you.", "tokens": [583, 1392, 11, 24038, 1619, 750, 603, 360, 309, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.28173087624942555, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.280409014725592e-05}, {"id": 1277, "seek": 665684, "start": 6675.96, "end": 6682.4800000000005, "text": " Okay, so let's do that.", "tokens": [1033, 11, 370, 718, 311, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.28173087624942555, "compression_ratio": 1.558011049723757, "no_speech_prob": 1.280409014725592e-05}, {"id": 1278, "seek": 668248, "start": 6682.48, "end": 6687.32, "text": " So here's our painting.", "tokens": [407, 510, 311, 527, 5370, 13], "temperature": 0.0, "avg_logprob": -0.2084756901389674, "compression_ratio": 1.4938271604938271, "no_speech_prob": 1.260671251657186e-05}, {"id": 1279, "seek": 668248, "start": 6687.32, "end": 6692.799999999999, "text": " I've tried to resize the painting so it's the same size as my bird picture.", "tokens": [286, 600, 3031, 281, 50069, 264, 5370, 370, 309, 311, 264, 912, 2744, 382, 452, 5255, 3036, 13], "temperature": 0.0, "avg_logprob": -0.2084756901389674, "compression_ratio": 1.4938271604938271, "no_speech_prob": 1.260671251657186e-05}, {"id": 1280, "seek": 668248, "start": 6692.799999999999, "end": 6698.12, "text": " So that's all this is just doing.", "tokens": [407, 300, 311, 439, 341, 307, 445, 884, 13], "temperature": 0.0, "avg_logprob": -0.2084756901389674, "compression_ratio": 1.4938271604938271, "no_speech_prob": 1.260671251657186e-05}, {"id": 1281, "seek": 668248, "start": 6698.12, "end": 6702.12, "text": " So there it is.", "tokens": [407, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.2084756901389674, "compression_ratio": 1.4938271604938271, "no_speech_prob": 1.260671251657186e-05}, {"id": 1282, "seek": 668248, "start": 6702.12, "end": 6706.799999999999, "text": " It doesn't matter too much which bit I use as long as it's got lots of the nice style", "tokens": [467, 1177, 380, 1871, 886, 709, 597, 857, 286, 764, 382, 938, 382, 309, 311, 658, 3195, 295, 264, 1481, 3758], "temperature": 0.0, "avg_logprob": -0.2084756901389674, "compression_ratio": 1.4938271604938271, "no_speech_prob": 1.260671251657186e-05}, {"id": 1283, "seek": 668248, "start": 6706.799999999999, "end": 6708.679999999999, "text": " in it.", "tokens": [294, 309, 13], "temperature": 0.0, "avg_logprob": -0.2084756901389674, "compression_ratio": 1.4938271604938271, "no_speech_prob": 1.260671251657186e-05}, {"id": 1284, "seek": 670868, "start": 6708.68, "end": 6717.240000000001, "text": " I grab my optimizer and my random image just like before, and this time I call saveFeatures", "tokens": [286, 4444, 452, 5028, 6545, 293, 452, 4974, 3256, 445, 411, 949, 11, 293, 341, 565, 286, 818, 3155, 29341, 3377], "temperature": 0.0, "avg_logprob": -0.18069324723209243, "compression_ratio": 1.569377990430622, "no_speech_prob": 9.516126738162711e-06}, {"id": 1285, "seek": 670868, "start": 6717.240000000001, "end": 6723.400000000001, "text": " for all of my block ends, and that's going to give me an array of saveFeatures objects,", "tokens": [337, 439, 295, 452, 3461, 5314, 11, 293, 300, 311, 516, 281, 976, 385, 364, 10225, 295, 3155, 29341, 3377, 6565, 11], "temperature": 0.0, "avg_logprob": -0.18069324723209243, "compression_ratio": 1.569377990430622, "no_speech_prob": 9.516126738162711e-06}, {"id": 1286, "seek": 670868, "start": 6723.400000000001, "end": 6729.52, "text": " one for each module that appears the layer before a maxPull.", "tokens": [472, 337, 1184, 10088, 300, 7038, 264, 4583, 949, 257, 11469, 47, 858, 13], "temperature": 0.0, "avg_logprob": -0.18069324723209243, "compression_ratio": 1.569377990430622, "no_speech_prob": 9.516126738162711e-06}, {"id": 1287, "seek": 670868, "start": 6729.52, "end": 6737.200000000001, "text": " Because this time I want to play around with different activation layer styles, or more", "tokens": [1436, 341, 565, 286, 528, 281, 862, 926, 365, 819, 24433, 4583, 13273, 11, 420, 544], "temperature": 0.0, "avg_logprob": -0.18069324723209243, "compression_ratio": 1.569377990430622, "no_speech_prob": 9.516126738162711e-06}, {"id": 1288, "seek": 673720, "start": 6737.2, "end": 6741.32, "text": " specifically I want to let you play around with it.", "tokens": [4682, 286, 528, 281, 718, 291, 862, 926, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.15220488442314994, "compression_ratio": 1.359375, "no_speech_prob": 1.6028045592975104e-06}, {"id": 1289, "seek": 673720, "start": 6741.32, "end": 6744.179999999999, "text": " So now I've got a whole array of them.", "tokens": [407, 586, 286, 600, 658, 257, 1379, 10225, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.15220488442314994, "compression_ratio": 1.359375, "no_speech_prob": 1.6028045592975104e-06}, {"id": 1290, "seek": 673720, "start": 6744.179999999999, "end": 6762.36, "text": " So now I call my VGG module on my image again.", "tokens": [407, 586, 286, 818, 452, 691, 27561, 10088, 322, 452, 3256, 797, 13], "temperature": 0.0, "avg_logprob": -0.15220488442314994, "compression_ratio": 1.359375, "no_speech_prob": 1.6028045592975104e-06}, {"id": 1291, "seek": 673720, "start": 6762.36, "end": 6764.5599999999995, "text": " Style image is my Van Gogh painting.", "tokens": [27004, 3256, 307, 452, 8979, 39690, 71, 5370, 13], "temperature": 0.0, "avg_logprob": -0.15220488442314994, "compression_ratio": 1.359375, "no_speech_prob": 1.6028045592975104e-06}, {"id": 1292, "seek": 676456, "start": 6764.56, "end": 6768.280000000001, "text": " So I take my style image, put it through my transformations to create my transform style", "tokens": [407, 286, 747, 452, 3758, 3256, 11, 829, 309, 807, 452, 34852, 281, 1884, 452, 4088, 3758], "temperature": 0.0, "avg_logprob": -0.14000151784796463, "compression_ratio": 1.695852534562212, "no_speech_prob": 1.130069085775176e-05}, {"id": 1293, "seek": 676456, "start": 6768.280000000001, "end": 6775.14, "text": " image, I turn that into a variable, put it through the forward pass of my VGG module,", "tokens": [3256, 11, 286, 1261, 300, 666, 257, 7006, 11, 829, 309, 807, 264, 2128, 1320, 295, 452, 691, 27561, 10088, 11], "temperature": 0.0, "avg_logprob": -0.14000151784796463, "compression_ratio": 1.695852534562212, "no_speech_prob": 1.130069085775176e-05}, {"id": 1294, "seek": 676456, "start": 6775.14, "end": 6782.280000000001, "text": " and now I can go through all of my saveFeatures objects and grab each set of features.", "tokens": [293, 586, 286, 393, 352, 807, 439, 295, 452, 3155, 29341, 3377, 6565, 293, 4444, 1184, 992, 295, 4122, 13], "temperature": 0.0, "avg_logprob": -0.14000151784796463, "compression_ratio": 1.695852534562212, "no_speech_prob": 1.130069085775176e-05}, {"id": 1295, "seek": 676456, "start": 6782.280000000001, "end": 6789.1, "text": " Notice I call clone, because later on if I call my VGG object again, it's going to replace", "tokens": [13428, 286, 818, 26506, 11, 570, 1780, 322, 498, 286, 818, 452, 691, 27561, 2657, 797, 11, 309, 311, 516, 281, 7406], "temperature": 0.0, "avg_logprob": -0.14000151784796463, "compression_ratio": 1.695852534562212, "no_speech_prob": 1.130069085775176e-05}, {"id": 1296, "seek": 676456, "start": 6789.1, "end": 6791.200000000001, "text": " those contents.", "tokens": [729, 15768, 13], "temperature": 0.0, "avg_logprob": -0.14000151784796463, "compression_ratio": 1.695852534562212, "no_speech_prob": 1.130069085775176e-05}, {"id": 1297, "seek": 679120, "start": 6791.2, "end": 6795.04, "text": " I haven't quite thought about whether this is necessary, if you take it away, it's fine,", "tokens": [286, 2378, 380, 1596, 1194, 466, 1968, 341, 307, 4818, 11, 498, 291, 747, 309, 1314, 11, 309, 311, 2489, 11], "temperature": 0.0, "avg_logprob": -0.1553289845304669, "compression_ratio": 1.6345381526104417, "no_speech_prob": 1.0289464626112022e-05}, {"id": 1298, "seek": 679120, "start": 6795.04, "end": 6798.0, "text": " but I was just being careful.", "tokens": [457, 286, 390, 445, 885, 5026, 13], "temperature": 0.0, "avg_logprob": -0.1553289845304669, "compression_ratio": 1.6345381526104417, "no_speech_prob": 1.0289464626112022e-05}, {"id": 1299, "seek": 679120, "start": 6798.0, "end": 6808.2, "text": " So here's now an array of the activations at every block end layer.", "tokens": [407, 510, 311, 586, 364, 10225, 295, 264, 2430, 763, 412, 633, 3461, 917, 4583, 13], "temperature": 0.0, "avg_logprob": -0.1553289845304669, "compression_ratio": 1.6345381526104417, "no_speech_prob": 1.0289464626112022e-05}, {"id": 1300, "seek": 679120, "start": 6808.2, "end": 6810.84, "text": " So here you can see all of those shapes.", "tokens": [407, 510, 291, 393, 536, 439, 295, 729, 10854, 13], "temperature": 0.0, "avg_logprob": -0.1553289845304669, "compression_ratio": 1.6345381526104417, "no_speech_prob": 1.0289464626112022e-05}, {"id": 1301, "seek": 679120, "start": 6810.84, "end": 6815.2, "text": " And you can see being able to whip up a list comprehension really quickly, it's really", "tokens": [400, 291, 393, 536, 885, 1075, 281, 22377, 493, 257, 1329, 44991, 534, 2661, 11, 309, 311, 534], "temperature": 0.0, "avg_logprob": -0.1553289845304669, "compression_ratio": 1.6345381526104417, "no_speech_prob": 1.0289464626112022e-05}, {"id": 1302, "seek": 679120, "start": 6815.2, "end": 6819.84, "text": " important in your Jupyter fiddling around, because you really want to be able to immediately", "tokens": [1021, 294, 428, 22125, 88, 391, 283, 14273, 1688, 926, 11, 570, 291, 534, 528, 281, 312, 1075, 281, 4258], "temperature": 0.0, "avg_logprob": -0.1553289845304669, "compression_ratio": 1.6345381526104417, "no_speech_prob": 1.0289464626112022e-05}, {"id": 1303, "seek": 681984, "start": 6819.84, "end": 6826.52, "text": " see, here's my channel, 64, 138, 255, 12, and you can see here the grid size halving,", "tokens": [536, 11, 510, 311, 452, 2269, 11, 12145, 11, 3705, 23, 11, 3552, 20, 11, 2272, 11, 293, 291, 393, 536, 510, 264, 10748, 2744, 7523, 798, 11], "temperature": 0.0, "avg_logprob": -0.29395159808072174, "compression_ratio": 1.4947368421052631, "no_speech_prob": 8.013441401999444e-06}, {"id": 1304, "seek": 681984, "start": 6826.52, "end": 6833.4800000000005, "text": " as we would expect, because all of these appeared just before a maxpull.", "tokens": [382, 321, 576, 2066, 11, 570, 439, 295, 613, 8516, 445, 949, 257, 11469, 79, 858, 13], "temperature": 0.0, "avg_logprob": -0.29395159808072174, "compression_ratio": 1.4947368421052631, "no_speech_prob": 8.013441401999444e-06}, {"id": 1305, "seek": 681984, "start": 6833.4800000000005, "end": 6841.64, "text": " So to do a gram MSC loss, it's going to be the MSC loss on the gram matrix of the input", "tokens": [407, 281, 360, 257, 21353, 7395, 34, 4470, 11, 309, 311, 516, 281, 312, 264, 7395, 34, 4470, 322, 264, 21353, 8141, 295, 264, 4846], "temperature": 0.0, "avg_logprob": -0.29395159808072174, "compression_ratio": 1.4947368421052631, "no_speech_prob": 8.013441401999444e-06}, {"id": 1306, "seek": 681984, "start": 6841.64, "end": 6845.12, "text": " versus the gram matrix of the target.", "tokens": [5717, 264, 21353, 8141, 295, 264, 3779, 13], "temperature": 0.0, "avg_logprob": -0.29395159808072174, "compression_ratio": 1.4947368421052631, "no_speech_prob": 8.013441401999444e-06}, {"id": 1307, "seek": 684512, "start": 6845.12, "end": 6855.16, "text": " And the gram matrix is just the matrix multiply of X with X transpose, where X is simply equal", "tokens": [400, 264, 21353, 8141, 307, 445, 264, 8141, 12972, 295, 1783, 365, 1783, 25167, 11, 689, 1783, 307, 2935, 2681], "temperature": 0.0, "avg_logprob": -0.15397556093004014, "compression_ratio": 1.592920353982301, "no_speech_prob": 2.4824728370731464e-06}, {"id": 1308, "seek": 684512, "start": 6855.16, "end": 6863.68, "text": " to my input, where I flattened the batch and channel axes all down together.", "tokens": [281, 452, 4846, 11, 689, 286, 24183, 292, 264, 15245, 293, 2269, 35387, 439, 760, 1214, 13], "temperature": 0.0, "avg_logprob": -0.15397556093004014, "compression_ratio": 1.592920353982301, "no_speech_prob": 2.4824728370731464e-06}, {"id": 1309, "seek": 684512, "start": 6863.68, "end": 6869.44, "text": " And I've only got one image, so you can kind of ignore the batch part, it's basically channel,", "tokens": [400, 286, 600, 787, 658, 472, 3256, 11, 370, 291, 393, 733, 295, 11200, 264, 15245, 644, 11, 309, 311, 1936, 2269, 11], "temperature": 0.0, "avg_logprob": -0.15397556093004014, "compression_ratio": 1.592920353982301, "no_speech_prob": 2.4824728370731464e-06}, {"id": 1310, "seek": 684512, "start": 6869.44, "end": 6873.68, "text": " and then everything else, which in this case is the height and width, is the other dimension.", "tokens": [293, 550, 1203, 1646, 11, 597, 294, 341, 1389, 307, 264, 6681, 293, 11402, 11, 307, 264, 661, 10139, 13], "temperature": 0.0, "avg_logprob": -0.15397556093004014, "compression_ratio": 1.592920353982301, "no_speech_prob": 2.4824728370731464e-06}, {"id": 1311, "seek": 687368, "start": 6873.68, "end": 6879.4400000000005, "text": " So it's now going to be channel by height and width, and then as we discussed, we can", "tokens": [407, 309, 311, 586, 516, 281, 312, 2269, 538, 6681, 293, 11402, 11, 293, 550, 382, 321, 7152, 11, 321, 393], "temperature": 0.0, "avg_logprob": -0.21054174961187902, "compression_ratio": 1.5233160621761659, "no_speech_prob": 6.048878731235163e-06}, {"id": 1312, "seek": 687368, "start": 6879.4400000000005, "end": 6884.4400000000005, "text": " then just do the matrix multiply of that by its transpose.", "tokens": [550, 445, 360, 264, 8141, 12972, 295, 300, 538, 1080, 25167, 13], "temperature": 0.0, "avg_logprob": -0.21054174961187902, "compression_ratio": 1.5233160621761659, "no_speech_prob": 6.048878731235163e-06}, {"id": 1313, "seek": 687368, "start": 6884.4400000000005, "end": 6889.72, "text": " And just to normalize it, we'll divide that by the number of elements.", "tokens": [400, 445, 281, 2710, 1125, 309, 11, 321, 603, 9845, 300, 538, 264, 1230, 295, 4959, 13], "temperature": 0.0, "avg_logprob": -0.21054174961187902, "compression_ratio": 1.5233160621761659, "no_speech_prob": 6.048878731235163e-06}, {"id": 1314, "seek": 687368, "start": 6889.72, "end": 6898.56, "text": " It would actually be more elegant if I had said divided by input.num elements.", "tokens": [467, 576, 767, 312, 544, 21117, 498, 286, 632, 848, 6666, 538, 4846, 13, 77, 449, 4959, 13], "temperature": 0.0, "avg_logprob": -0.21054174961187902, "compression_ratio": 1.5233160621761659, "no_speech_prob": 6.048878731235163e-06}, {"id": 1315, "seek": 689856, "start": 6898.56, "end": 6904.92, "text": " That would be the same thing.", "tokens": [663, 576, 312, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.1768518231578709, "compression_ratio": 1.584070796460177, "no_speech_prob": 9.818245416681748e-06}, {"id": 1316, "seek": 689856, "start": 6904.92, "end": 6908.52, "text": " And then again, this kind of gives me tiny numbers, so I multiply it by a big number", "tokens": [400, 550, 797, 11, 341, 733, 295, 2709, 385, 5870, 3547, 11, 370, 286, 12972, 309, 538, 257, 955, 1230], "temperature": 0.0, "avg_logprob": -0.1768518231578709, "compression_ratio": 1.584070796460177, "no_speech_prob": 9.818245416681748e-06}, {"id": 1317, "seek": 689856, "start": 6908.52, "end": 6912.52, "text": " to make it something more sensible.", "tokens": [281, 652, 309, 746, 544, 25380, 13], "temperature": 0.0, "avg_logprob": -0.1768518231578709, "compression_ratio": 1.584070796460177, "no_speech_prob": 9.818245416681748e-06}, {"id": 1318, "seek": 689856, "start": 6912.52, "end": 6914.06, "text": " So that's basically my loss.", "tokens": [407, 300, 311, 1936, 452, 4470, 13], "temperature": 0.0, "avg_logprob": -0.1768518231578709, "compression_ratio": 1.584070796460177, "no_speech_prob": 9.818245416681748e-06}, {"id": 1319, "seek": 689856, "start": 6914.06, "end": 6921.080000000001, "text": " So now my style loss is to take my image to optimize, throw it through VGG forward pass,", "tokens": [407, 586, 452, 3758, 4470, 307, 281, 747, 452, 3256, 281, 19719, 11, 3507, 309, 807, 691, 27561, 2128, 1320, 11], "temperature": 0.0, "avg_logprob": -0.1768518231578709, "compression_ratio": 1.584070796460177, "no_speech_prob": 9.818245416681748e-06}, {"id": 1320, "seek": 689856, "start": 6921.080000000001, "end": 6926.64, "text": " grab an array of the features in all of the, say, features objects, and then call my gram", "tokens": [4444, 364, 10225, 295, 264, 4122, 294, 439, 295, 264, 11, 584, 11, 4122, 6565, 11, 293, 550, 818, 452, 21353], "temperature": 0.0, "avg_logprob": -0.1768518231578709, "compression_ratio": 1.584070796460177, "no_speech_prob": 9.818245416681748e-06}, {"id": 1321, "seek": 692664, "start": 6926.64, "end": 6934.72, "text": " msc loss on every one of those layers.", "tokens": [275, 4417, 4470, 322, 633, 472, 295, 729, 7914, 13], "temperature": 0.0, "avg_logprob": -0.1884614494111803, "compression_ratio": 1.4906832298136645, "no_speech_prob": 4.356865247245878e-06}, {"id": 1322, "seek": 692664, "start": 6934.72, "end": 6936.400000000001, "text": " And that's going to give me an array.", "tokens": [400, 300, 311, 516, 281, 976, 385, 364, 10225, 13], "temperature": 0.0, "avg_logprob": -0.1884614494111803, "compression_ratio": 1.4906832298136645, "no_speech_prob": 4.356865247245878e-06}, {"id": 1323, "seek": 692664, "start": 6936.400000000001, "end": 6937.76, "text": " And then I just add them up.", "tokens": [400, 550, 286, 445, 909, 552, 493, 13], "temperature": 0.0, "avg_logprob": -0.1884614494111803, "compression_ratio": 1.4906832298136645, "no_speech_prob": 4.356865247245878e-06}, {"id": 1324, "seek": 692664, "start": 6937.76, "end": 6945.08, "text": " Now you could add them up with different weightings, you could add up a subset, whatever.", "tokens": [823, 291, 727, 909, 552, 493, 365, 819, 3364, 1109, 11, 291, 727, 909, 493, 257, 25993, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1884614494111803, "compression_ratio": 1.4906832298136645, "no_speech_prob": 4.356865247245878e-06}, {"id": 1325, "seek": 692664, "start": 6945.08, "end": 6951.96, "text": " In this case, I'm just grabbing all of them.", "tokens": [682, 341, 1389, 11, 286, 478, 445, 23771, 439, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.1884614494111803, "compression_ratio": 1.4906832298136645, "no_speech_prob": 4.356865247245878e-06}, {"id": 1326, "seek": 695196, "start": 6951.96, "end": 6959.12, "text": " Pass that into my optimizer as before, and here we have a random image in the style of", "tokens": [10319, 300, 666, 452, 5028, 6545, 382, 949, 11, 293, 510, 321, 362, 257, 4974, 3256, 294, 264, 3758, 295], "temperature": 0.0, "avg_logprob": -0.11107684154899752, "compression_ratio": 1.6121495327102804, "no_speech_prob": 5.59431646252051e-06}, {"id": 1327, "seek": 695196, "start": 6959.12, "end": 6963.6, "text": " Van Gogh, which I think is kind of cool.", "tokens": [8979, 39690, 71, 11, 597, 286, 519, 307, 733, 295, 1627, 13], "temperature": 0.0, "avg_logprob": -0.11107684154899752, "compression_ratio": 1.6121495327102804, "no_speech_prob": 5.59431646252051e-06}, {"id": 1328, "seek": 695196, "start": 6963.6, "end": 6966.92, "text": " And again, Gaddy's has done it for us.", "tokens": [400, 797, 11, 37171, 3173, 311, 575, 1096, 309, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.11107684154899752, "compression_ratio": 1.6121495327102804, "no_speech_prob": 5.59431646252051e-06}, {"id": 1329, "seek": 695196, "start": 6966.92, "end": 6973.4, "text": " Here is different layers of random image in the style of Van Gogh.", "tokens": [1692, 307, 819, 7914, 295, 4974, 3256, 294, 264, 3758, 295, 8979, 39690, 71, 13], "temperature": 0.0, "avg_logprob": -0.11107684154899752, "compression_ratio": 1.6121495327102804, "no_speech_prob": 5.59431646252051e-06}, {"id": 1330, "seek": 695196, "start": 6973.4, "end": 6979.2, "text": " And so the first one, as you can see, the activations are simple geometric things, not", "tokens": [400, 370, 264, 700, 472, 11, 382, 291, 393, 536, 11, 264, 2430, 763, 366, 2199, 33246, 721, 11, 406], "temperature": 0.0, "avg_logprob": -0.11107684154899752, "compression_ratio": 1.6121495327102804, "no_speech_prob": 5.59431646252051e-06}, {"id": 1331, "seek": 695196, "start": 6979.2, "end": 6981.12, "text": " very interesting at all.", "tokens": [588, 1880, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.11107684154899752, "compression_ratio": 1.6121495327102804, "no_speech_prob": 5.59431646252051e-06}, {"id": 1332, "seek": 698112, "start": 6981.12, "end": 6983.36, "text": " The later layers are much more interesting.", "tokens": [440, 1780, 7914, 366, 709, 544, 1880, 13], "temperature": 0.0, "avg_logprob": -0.19071435928344727, "compression_ratio": 1.4885057471264367, "no_speech_prob": 4.565951257973211e-06}, {"id": 1333, "seek": 698112, "start": 6983.36, "end": 6991.28, "text": " So we kind of have a suspicion that we probably want to use later layers largely for our style", "tokens": [407, 321, 733, 295, 362, 257, 32020, 300, 321, 1391, 528, 281, 764, 1780, 7914, 11611, 337, 527, 3758], "temperature": 0.0, "avg_logprob": -0.19071435928344727, "compression_ratio": 1.4885057471264367, "no_speech_prob": 4.565951257973211e-06}, {"id": 1334, "seek": 698112, "start": 6991.28, "end": 6998.32, "text": " loss if we want it to look good.", "tokens": [4470, 498, 321, 528, 309, 281, 574, 665, 13], "temperature": 0.0, "avg_logprob": -0.19071435928344727, "compression_ratio": 1.4885057471264367, "no_speech_prob": 4.565951257973211e-06}, {"id": 1335, "seek": 698112, "start": 6998.32, "end": 7010.88, "text": " I added this save features.close which just calls, remember I stored the hook here, and", "tokens": [286, 3869, 341, 3155, 4122, 13, 3474, 541, 597, 445, 5498, 11, 1604, 286, 12187, 264, 6328, 510, 11, 293], "temperature": 0.0, "avg_logprob": -0.19071435928344727, "compression_ratio": 1.4885057471264367, "no_speech_prob": 4.565951257973211e-06}, {"id": 1336, "seek": 701088, "start": 7010.88, "end": 7013.52, "text": " so hook.remove gets rid of it.", "tokens": [370, 6328, 13, 2579, 1682, 2170, 3973, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.14814777896828848, "compression_ratio": 1.459016393442623, "no_speech_prob": 1.933354724314995e-06}, {"id": 1337, "seek": 701088, "start": 7013.52, "end": 7019.16, "text": " And it's a good idea to get rid of it because otherwise you can potentially just keep using", "tokens": [400, 309, 311, 257, 665, 1558, 281, 483, 3973, 295, 309, 570, 5911, 291, 393, 7263, 445, 1066, 1228], "temperature": 0.0, "avg_logprob": -0.14814777896828848, "compression_ratio": 1.459016393442623, "no_speech_prob": 1.933354724314995e-06}, {"id": 1338, "seek": 701088, "start": 7019.16, "end": 7021.6, "text": " memory.", "tokens": [4675, 13], "temperature": 0.0, "avg_logprob": -0.14814777896828848, "compression_ratio": 1.459016393442623, "no_speech_prob": 1.933354724314995e-06}, {"id": 1339, "seek": 701088, "start": 7021.6, "end": 7028.8, "text": " So at the end, I go through each of my save features object and close it.", "tokens": [407, 412, 264, 917, 11, 286, 352, 807, 1184, 295, 452, 3155, 4122, 2657, 293, 1998, 309, 13], "temperature": 0.0, "avg_logprob": -0.14814777896828848, "compression_ratio": 1.459016393442623, "no_speech_prob": 1.933354724314995e-06}, {"id": 1340, "seek": 701088, "start": 7028.8, "end": 7039.72, "text": " So style transfer is adding the two together with some weight.", "tokens": [407, 3758, 5003, 307, 5127, 264, 732, 1214, 365, 512, 3364, 13], "temperature": 0.0, "avg_logprob": -0.14814777896828848, "compression_ratio": 1.459016393442623, "no_speech_prob": 1.933354724314995e-06}, {"id": 1341, "seek": 703972, "start": 7039.72, "end": 7041.16, "text": " So there's not much to show.", "tokens": [407, 456, 311, 406, 709, 281, 855, 13], "temperature": 0.0, "avg_logprob": -0.15586885452270507, "compression_ratio": 1.5865384615384615, "no_speech_prob": 6.962186944292625e-06}, {"id": 1342, "seek": 703972, "start": 7041.16, "end": 7048.360000000001, "text": " Grab my optimizer, grab my image, and now my combined loss is the MSC loss at one particular", "tokens": [20357, 452, 5028, 6545, 11, 4444, 452, 3256, 11, 293, 586, 452, 9354, 4470, 307, 264, 7395, 34, 4470, 412, 472, 1729], "temperature": 0.0, "avg_logprob": -0.15586885452270507, "compression_ratio": 1.5865384615384615, "no_speech_prob": 6.962186944292625e-06}, {"id": 1343, "seek": 703972, "start": 7048.360000000001, "end": 7054.8, "text": " layer, my style loss at all of my layers, sum up the style losses, add them to the content", "tokens": [4583, 11, 452, 3758, 4470, 412, 439, 295, 452, 7914, 11, 2408, 493, 264, 3758, 15352, 11, 909, 552, 281, 264, 2701], "temperature": 0.0, "avg_logprob": -0.15586885452270507, "compression_ratio": 1.5865384615384615, "no_speech_prob": 6.962186944292625e-06}, {"id": 1344, "seek": 703972, "start": 7054.8, "end": 7059.04, "text": " loss, the content loss I'm scaling.", "tokens": [4470, 11, 264, 2701, 4470, 286, 478, 21589, 13], "temperature": 0.0, "avg_logprob": -0.15586885452270507, "compression_ratio": 1.5865384615384615, "no_speech_prob": 6.962186944292625e-06}, {"id": 1345, "seek": 703972, "start": 7059.04, "end": 7067.54, "text": " Actually the style loss I scaled already by 1.6 and this one is 1, 2, 3, 4, 5, 6.", "tokens": [5135, 264, 3758, 4470, 286, 36039, 1217, 538, 502, 13, 21, 293, 341, 472, 307, 502, 11, 568, 11, 805, 11, 1017, 11, 1025, 11, 1386, 13], "temperature": 0.0, "avg_logprob": -0.15586885452270507, "compression_ratio": 1.5865384615384615, "no_speech_prob": 6.962186944292625e-06}, {"id": 1346, "seek": 706754, "start": 7067.54, "end": 7071.5199999999995, "text": " So actually they're both scaled exactly the same.", "tokens": [407, 767, 436, 434, 1293, 36039, 2293, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.24057302613189255, "compression_ratio": 1.5054347826086956, "no_speech_prob": 1.6280465615636786e-06}, {"id": 1347, "seek": 706754, "start": 7071.5199999999995, "end": 7075.48, "text": " Add them together, and again you could try weighting the different style losses or you", "tokens": [5349, 552, 1214, 11, 293, 797, 291, 727, 853, 3364, 278, 264, 819, 3758, 15352, 420, 291], "temperature": 0.0, "avg_logprob": -0.24057302613189255, "compression_ratio": 1.5054347826086956, "no_speech_prob": 1.6280465615636786e-06}, {"id": 1348, "seek": 706754, "start": 7075.48, "end": 7078.44, "text": " could maybe remove some of them, whatever.", "tokens": [727, 1310, 4159, 512, 295, 552, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.24057302613189255, "compression_ratio": 1.5054347826086956, "no_speech_prob": 1.6280465615636786e-06}, {"id": 1349, "seek": 706754, "start": 7078.44, "end": 7082.2, "text": " So this is the simplest possible version.", "tokens": [407, 341, 307, 264, 22811, 1944, 3037, 13], "temperature": 0.0, "avg_logprob": -0.24057302613189255, "compression_ratio": 1.5054347826086956, "no_speech_prob": 1.6280465615636786e-06}, {"id": 1350, "seek": 706754, "start": 7082.2, "end": 7089.84, "text": " Train that, and like holy shit, it actually looks good.", "tokens": [28029, 300, 11, 293, 411, 10622, 4611, 11, 309, 767, 1542, 665, 13], "temperature": 0.0, "avg_logprob": -0.24057302613189255, "compression_ratio": 1.5054347826086956, "no_speech_prob": 1.6280465615636786e-06}, {"id": 1351, "seek": 708984, "start": 7089.84, "end": 7098.400000000001, "text": " So I think that's pretty awesome.", "tokens": [407, 286, 519, 300, 311, 1238, 3476, 13], "temperature": 0.0, "avg_logprob": -0.1761157989501953, "compression_ratio": 1.3732394366197183, "no_speech_prob": 2.2603182969760383e-06}, {"id": 1352, "seek": 708984, "start": 7098.400000000001, "end": 7111.04, "text": " Again the main takeaway here is if you want to solve something with a neural network,", "tokens": [3764, 264, 2135, 30681, 510, 307, 498, 291, 528, 281, 5039, 746, 365, 257, 18161, 3209, 11], "temperature": 0.0, "avg_logprob": -0.1761157989501953, "compression_ratio": 1.3732394366197183, "no_speech_prob": 2.2603182969760383e-06}, {"id": 1353, "seek": 708984, "start": 7111.04, "end": 7119.08, "text": " all you've got to do is set up a loss function and then optimize something.", "tokens": [439, 291, 600, 658, 281, 360, 307, 992, 493, 257, 4470, 2445, 293, 550, 19719, 746, 13], "temperature": 0.0, "avg_logprob": -0.1761157989501953, "compression_ratio": 1.3732394366197183, "no_speech_prob": 2.2603182969760383e-06}, {"id": 1354, "seek": 711908, "start": 7119.08, "end": 7124.92, "text": " The loss function is something which a lower number is something that you're happier with.", "tokens": [440, 4470, 2445, 307, 746, 597, 257, 3126, 1230, 307, 746, 300, 291, 434, 20423, 365, 13], "temperature": 0.0, "avg_logprob": -0.16827833125021605, "compression_ratio": 1.8669527896995708, "no_speech_prob": 7.296329840755789e-06}, {"id": 1355, "seek": 711908, "start": 7124.92, "end": 7128.12, "text": " Because then when you optimize it, it's going to make that number as low as you can and", "tokens": [1436, 550, 562, 291, 19719, 309, 11, 309, 311, 516, 281, 652, 300, 1230, 382, 2295, 382, 291, 393, 293], "temperature": 0.0, "avg_logprob": -0.16827833125021605, "compression_ratio": 1.8669527896995708, "no_speech_prob": 7.296329840755789e-06}, {"id": 1356, "seek": 711908, "start": 7128.12, "end": 7131.88, "text": " it will do what you wanted it to do.", "tokens": [309, 486, 360, 437, 291, 1415, 309, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.16827833125021605, "compression_ratio": 1.8669527896995708, "no_speech_prob": 7.296329840755789e-06}, {"id": 1357, "seek": 711908, "start": 7131.88, "end": 7142.68, "text": " So here Gaddy's came up with a loss function that does a good job of being a smaller number", "tokens": [407, 510, 37171, 3173, 311, 1361, 493, 365, 257, 4470, 2445, 300, 775, 257, 665, 1691, 295, 885, 257, 4356, 1230], "temperature": 0.0, "avg_logprob": -0.16827833125021605, "compression_ratio": 1.8669527896995708, "no_speech_prob": 7.296329840755789e-06}, {"id": 1358, "seek": 711908, "start": 7142.68, "end": 7146.04, "text": " when it looks like the thing we want it to look like and it looks like the style of the", "tokens": [562, 309, 1542, 411, 264, 551, 321, 528, 309, 281, 574, 411, 293, 309, 1542, 411, 264, 3758, 295, 264], "temperature": 0.0, "avg_logprob": -0.16827833125021605, "compression_ratio": 1.8669527896995708, "no_speech_prob": 7.296329840755789e-06}, {"id": 1359, "seek": 711908, "start": 7146.04, "end": 7148.0, "text": " thing we want it to be in the style of.", "tokens": [551, 321, 528, 309, 281, 312, 294, 264, 3758, 295, 13], "temperature": 0.0, "avg_logprob": -0.16827833125021605, "compression_ratio": 1.8669527896995708, "no_speech_prob": 7.296329840755789e-06}, {"id": 1360, "seek": 714800, "start": 7148.0, "end": 7150.76, "text": " That's all we had to do.", "tokens": [663, 311, 439, 321, 632, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.23501928647359213, "compression_ratio": 1.5598086124401913, "no_speech_prob": 2.156810069209314e-06}, {"id": 1361, "seek": 714800, "start": 7150.76, "end": 7157.12, "text": " When it actually comes to it, apart from implementing gramm-mse loss, which was like 6 lines of", "tokens": [1133, 309, 767, 1487, 281, 309, 11, 4936, 490, 18114, 21353, 76, 12, 76, 405, 4470, 11, 597, 390, 411, 1386, 3876, 295], "temperature": 0.0, "avg_logprob": -0.23501928647359213, "compression_ratio": 1.5598086124401913, "no_speech_prob": 2.156810069209314e-06}, {"id": 1362, "seek": 714800, "start": 7157.12, "end": 7166.48, "text": " code, that's our loss function, pass it to our optimizer, wait about 5 seconds and we're", "tokens": [3089, 11, 300, 311, 527, 4470, 2445, 11, 1320, 309, 281, 527, 5028, 6545, 11, 1699, 466, 1025, 3949, 293, 321, 434], "temperature": 0.0, "avg_logprob": -0.23501928647359213, "compression_ratio": 1.5598086124401913, "no_speech_prob": 2.156810069209314e-06}, {"id": 1363, "seek": 714800, "start": 7166.48, "end": 7167.48, "text": " done.", "tokens": [1096, 13], "temperature": 0.0, "avg_logprob": -0.23501928647359213, "compression_ratio": 1.5598086124401913, "no_speech_prob": 2.156810069209314e-06}, {"id": 1364, "seek": 714800, "start": 7167.48, "end": 7170.96, "text": " And remember we could do a batch of these at a time, so we could wait 5 seconds and", "tokens": [400, 1604, 321, 727, 360, 257, 15245, 295, 613, 412, 257, 565, 11, 370, 321, 727, 1699, 1025, 3949, 293], "temperature": 0.0, "avg_logprob": -0.23501928647359213, "compression_ratio": 1.5598086124401913, "no_speech_prob": 2.156810069209314e-06}, {"id": 1365, "seek": 714800, "start": 7170.96, "end": 7176.44, "text": " 64 of these would be done.", "tokens": [12145, 295, 613, 576, 312, 1096, 13], "temperature": 0.0, "avg_logprob": -0.23501928647359213, "compression_ratio": 1.5598086124401913, "no_speech_prob": 2.156810069209314e-06}, {"id": 1366, "seek": 717644, "start": 7176.44, "end": 7184.2, "text": " So I think that's really interesting and since this paper came out, it's really inspired", "tokens": [407, 286, 519, 300, 311, 534, 1880, 293, 1670, 341, 3035, 1361, 484, 11, 309, 311, 534, 7547], "temperature": 0.0, "avg_logprob": -0.1696720940726144, "compression_ratio": 1.7030303030303031, "no_speech_prob": 7.07182562109665e-06}, {"id": 1367, "seek": 717644, "start": 7184.2, "end": 7187.44, "text": " a lot of interesting work.", "tokens": [257, 688, 295, 1880, 589, 13], "temperature": 0.0, "avg_logprob": -0.1696720940726144, "compression_ratio": 1.7030303030303031, "no_speech_prob": 7.07182562109665e-06}, {"id": 1368, "seek": 717644, "start": 7187.44, "end": 7190.679999999999, "text": " To me though, most of the interesting work hasn't happened yet.", "tokens": [1407, 385, 1673, 11, 881, 295, 264, 1880, 589, 6132, 380, 2011, 1939, 13], "temperature": 0.0, "avg_logprob": -0.1696720940726144, "compression_ratio": 1.7030303030303031, "no_speech_prob": 7.07182562109665e-06}, {"id": 1369, "seek": 717644, "start": 7190.679999999999, "end": 7198.2, "text": " To me, the interesting work is the work where you combine human creativity with these kinds", "tokens": [1407, 385, 11, 264, 1880, 589, 307, 264, 589, 689, 291, 10432, 1952, 12915, 365, 613, 3685], "temperature": 0.0, "avg_logprob": -0.1696720940726144, "compression_ratio": 1.7030303030303031, "no_speech_prob": 7.07182562109665e-06}, {"id": 1370, "seek": 717644, "start": 7198.2, "end": 7199.2, "text": " of tools.", "tokens": [295, 3873, 13], "temperature": 0.0, "avg_logprob": -0.1696720940726144, "compression_ratio": 1.7030303030303031, "no_speech_prob": 7.07182562109665e-06}, {"id": 1371, "seek": 719920, "start": 7199.2, "end": 7207.5599999999995, "text": " I haven't seen much in the way of tools that you can download or use where the artist is", "tokens": [286, 2378, 380, 1612, 709, 294, 264, 636, 295, 3873, 300, 291, 393, 5484, 420, 764, 689, 264, 5748, 307], "temperature": 0.0, "avg_logprob": -0.14704455720617415, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.9832657926599495e-05}, {"id": 1372, "seek": 719920, "start": 7207.5599999999995, "end": 7212.12, "text": " in control and can kind of do things interactively.", "tokens": [294, 1969, 293, 393, 733, 295, 360, 721, 4648, 3413, 13], "temperature": 0.0, "avg_logprob": -0.14704455720617415, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.9832657926599495e-05}, {"id": 1373, "seek": 719920, "start": 7212.12, "end": 7216.76, "text": " It's interesting talking to the guys at the Google Magenta project, which is kind of their", "tokens": [467, 311, 1880, 1417, 281, 264, 1074, 412, 264, 3329, 6395, 8938, 1716, 11, 597, 307, 733, 295, 641], "temperature": 0.0, "avg_logprob": -0.14704455720617415, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.9832657926599495e-05}, {"id": 1374, "seek": 719920, "start": 7216.76, "end": 7222.72, "text": " creative AI project, all of the stuff they're doing with music is specifically about this.", "tokens": [5880, 7318, 1716, 11, 439, 295, 264, 1507, 436, 434, 884, 365, 1318, 307, 4682, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.14704455720617415, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.9832657926599495e-05}, {"id": 1375, "seek": 719920, "start": 7222.72, "end": 7227.32, "text": " It's building tools that musicians can use to perform in real time.", "tokens": [467, 311, 2390, 3873, 300, 16916, 393, 764, 281, 2042, 294, 957, 565, 13], "temperature": 0.0, "avg_logprob": -0.14704455720617415, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.9832657926599495e-05}, {"id": 1376, "seek": 722732, "start": 7227.32, "end": 7230.599999999999, "text": " And so you'll see much more of that on the music space thanks to Magenta.", "tokens": [400, 370, 291, 603, 536, 709, 544, 295, 300, 322, 264, 1318, 1901, 3231, 281, 6395, 8938, 13], "temperature": 0.0, "avg_logprob": -0.2011707305908203, "compression_ratio": 1.6032388663967612, "no_speech_prob": 2.144340760423802e-05}, {"id": 1377, "seek": 722732, "start": 7230.599999999999, "end": 7234.5199999999995, "text": " If you go to their website, there's all kinds of things where you can press the buttons", "tokens": [759, 291, 352, 281, 641, 3144, 11, 456, 311, 439, 3685, 295, 721, 689, 291, 393, 1886, 264, 9905], "temperature": 0.0, "avg_logprob": -0.2011707305908203, "compression_ratio": 1.6032388663967612, "no_speech_prob": 2.144340760423802e-05}, {"id": 1378, "seek": 722732, "start": 7234.5199999999995, "end": 7240.04, "text": " to actually change the drum beats or melodies or keys or whatever.", "tokens": [281, 767, 1319, 264, 10206, 16447, 420, 47085, 420, 9317, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2011707305908203, "compression_ratio": 1.6032388663967612, "no_speech_prob": 2.144340760423802e-05}, {"id": 1379, "seek": 722732, "start": 7240.04, "end": 7246.5599999999995, "text": " And you can definitely see Adobe and Nvidia starting to release little prototypes that", "tokens": [400, 291, 393, 2138, 536, 24862, 293, 46284, 2891, 281, 4374, 707, 42197, 300], "temperature": 0.0, "avg_logprob": -0.2011707305908203, "compression_ratio": 1.6032388663967612, "no_speech_prob": 2.144340760423802e-05}, {"id": 1380, "seek": 722732, "start": 7246.5599999999995, "end": 7249.08, "text": " are starting to do this.", "tokens": [366, 2891, 281, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.2011707305908203, "compression_ratio": 1.6032388663967612, "no_speech_prob": 2.144340760423802e-05}, {"id": 1381, "seek": 722732, "start": 7249.08, "end": 7255.219999999999, "text": " This kind of creative AI explosion hasn't happened yet.", "tokens": [639, 733, 295, 5880, 7318, 15673, 6132, 380, 2011, 1939, 13], "temperature": 0.0, "avg_logprob": -0.2011707305908203, "compression_ratio": 1.6032388663967612, "no_speech_prob": 2.144340760423802e-05}, {"id": 1382, "seek": 725522, "start": 7255.22, "end": 7259.820000000001, "text": " I think we have pretty much all the technology we need, but no one's put it together into", "tokens": [286, 519, 321, 362, 1238, 709, 439, 264, 2899, 321, 643, 11, 457, 572, 472, 311, 829, 309, 1214, 666], "temperature": 0.0, "avg_logprob": -0.11357818331037249, "compression_ratio": 1.6288659793814433, "no_speech_prob": 3.071704850299284e-05}, {"id": 1383, "seek": 725522, "start": 7259.820000000001, "end": 7264.88, "text": " a thing and said, look at the thing I built and look at the stuff that people built with", "tokens": [257, 551, 293, 848, 11, 574, 412, 264, 551, 286, 3094, 293, 574, 412, 264, 1507, 300, 561, 3094, 365], "temperature": 0.0, "avg_logprob": -0.11357818331037249, "compression_ratio": 1.6288659793814433, "no_speech_prob": 3.071704850299284e-05}, {"id": 1384, "seek": 725522, "start": 7264.88, "end": 7267.04, "text": " my thing.", "tokens": [452, 551, 13], "temperature": 0.0, "avg_logprob": -0.11357818331037249, "compression_ratio": 1.6288659793814433, "no_speech_prob": 3.071704850299284e-05}, {"id": 1385, "seek": 725522, "start": 7267.04, "end": 7276.6, "text": " So that's just a huge area of opportunity.", "tokens": [407, 300, 311, 445, 257, 2603, 1859, 295, 2650, 13], "temperature": 0.0, "avg_logprob": -0.11357818331037249, "compression_ratio": 1.6288659793814433, "no_speech_prob": 3.071704850299284e-05}, {"id": 1386, "seek": 725522, "start": 7276.6, "end": 7282.6, "text": " So the paper that I mentioned at the start of class in passing, the one where we can", "tokens": [407, 264, 3035, 300, 286, 2835, 412, 264, 722, 295, 1508, 294, 8437, 11, 264, 472, 689, 321, 393], "temperature": 0.0, "avg_logprob": -0.11357818331037249, "compression_ratio": 1.6288659793814433, "no_speech_prob": 3.071704850299284e-05}, {"id": 1387, "seek": 728260, "start": 7282.6, "end": 7291.8, "text": " add Captain America's shield to arbitrary paintings, basically used this technique.", "tokens": [909, 10873, 3374, 311, 10257, 281, 23211, 14880, 11, 1936, 1143, 341, 6532, 13], "temperature": 0.0, "avg_logprob": -0.16312750648049748, "compression_ratio": 1.5054347826086956, "no_speech_prob": 6.854090315755457e-06}, {"id": 1388, "seek": 728260, "start": 7291.8, "end": 7300.360000000001, "text": " The trick was, though, some minor tweaks to make the pasted Captain America shield blend", "tokens": [440, 4282, 390, 11, 1673, 11, 512, 6696, 46664, 281, 652, 264, 1791, 292, 10873, 3374, 10257, 10628], "temperature": 0.0, "avg_logprob": -0.16312750648049748, "compression_ratio": 1.5054347826086956, "no_speech_prob": 6.854090315755457e-06}, {"id": 1389, "seek": 728260, "start": 7300.360000000001, "end": 7301.360000000001, "text": " in nicely.", "tokens": [294, 9594, 13], "temperature": 0.0, "avg_logprob": -0.16312750648049748, "compression_ratio": 1.5054347826086956, "no_speech_prob": 6.854090315755457e-06}, {"id": 1390, "seek": 728260, "start": 7301.360000000001, "end": 7307.56, "text": " That paper's only a couple of days old, so that would be a really interesting project", "tokens": [663, 3035, 311, 787, 257, 1916, 295, 1708, 1331, 11, 370, 300, 576, 312, 257, 534, 1880, 1716], "temperature": 0.0, "avg_logprob": -0.16312750648049748, "compression_ratio": 1.5054347826086956, "no_speech_prob": 6.854090315755457e-06}, {"id": 1391, "seek": 728260, "start": 7307.56, "end": 7309.08, "text": " to try.", "tokens": [281, 853, 13], "temperature": 0.0, "avg_logprob": -0.16312750648049748, "compression_ratio": 1.5054347826086956, "no_speech_prob": 6.854090315755457e-06}, {"id": 1392, "seek": 730908, "start": 7309.08, "end": 7314.44, "text": " You can use all this code, it really does leverage this approach.", "tokens": [509, 393, 764, 439, 341, 3089, 11, 309, 534, 775, 13982, 341, 3109, 13], "temperature": 0.0, "avg_logprob": -0.16643232586740078, "compression_ratio": 1.800995024875622, "no_speech_prob": 4.495124358072644e-06}, {"id": 1393, "seek": 730908, "start": 7314.44, "end": 7324.68, "text": " And then you could start by making the content image be like the painting with the shield,", "tokens": [400, 550, 291, 727, 722, 538, 1455, 264, 2701, 3256, 312, 411, 264, 5370, 365, 264, 10257, 11], "temperature": 0.0, "avg_logprob": -0.16643232586740078, "compression_ratio": 1.800995024875622, "no_speech_prob": 4.495124358072644e-06}, {"id": 1394, "seek": 730908, "start": 7324.68, "end": 7328.5599999999995, "text": " and then the style image could be the painting without the shield.", "tokens": [293, 550, 264, 3758, 3256, 727, 312, 264, 5370, 1553, 264, 10257, 13], "temperature": 0.0, "avg_logprob": -0.16643232586740078, "compression_ratio": 1.800995024875622, "no_speech_prob": 4.495124358072644e-06}, {"id": 1395, "seek": 730908, "start": 7328.5599999999995, "end": 7332.16, "text": " And that would be a good start, and then you could kind of see what specific problems they", "tokens": [400, 300, 576, 312, 257, 665, 722, 11, 293, 550, 291, 727, 733, 295, 536, 437, 2685, 2740, 436], "temperature": 0.0, "avg_logprob": -0.16643232586740078, "compression_ratio": 1.800995024875622, "no_speech_prob": 4.495124358072644e-06}, {"id": 1396, "seek": 730908, "start": 7332.16, "end": 7336.92, "text": " tried to solve in this paper to make it better.", "tokens": [3031, 281, 5039, 294, 341, 3035, 281, 652, 309, 1101, 13], "temperature": 0.0, "avg_logprob": -0.16643232586740078, "compression_ratio": 1.800995024875622, "no_speech_prob": 4.495124358072644e-06}, {"id": 1397, "seek": 733692, "start": 7336.92, "end": 7343.92, "text": " But you could have a start on it right now.", "tokens": [583, 291, 727, 362, 257, 722, 322, 309, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.34738021600441854, "compression_ratio": 1.3865030674846626, "no_speech_prob": 2.3551689082523808e-05}, {"id": 1398, "seek": 733692, "start": 7343.92, "end": 7354.04, "text": " So let's make a quick start on the next bit, which is, yes, Rachel.", "tokens": [407, 718, 311, 652, 257, 1702, 722, 322, 264, 958, 857, 11, 597, 307, 11, 2086, 11, 14246, 13], "temperature": 0.0, "avg_logprob": -0.34738021600441854, "compression_ratio": 1.3865030674846626, "no_speech_prob": 2.3551689082523808e-05}, {"id": 1399, "seek": 733692, "start": 7354.04, "end": 7357.04, "text": " Question from the audience.", "tokens": [14464, 490, 264, 4034, 13], "temperature": 0.0, "avg_logprob": -0.34738021600441854, "compression_ratio": 1.3865030674846626, "no_speech_prob": 2.3551689082523808e-05}, {"id": 1400, "seek": 733692, "start": 7357.04, "end": 7361.04, "text": " Earlier there were a number of people that expressed interest in your thoughts on Pyro", "tokens": [24552, 456, 645, 257, 1230, 295, 561, 300, 12675, 1179, 294, 428, 4598, 322, 9953, 340], "temperature": 0.0, "avg_logprob": -0.34738021600441854, "compression_ratio": 1.3865030674846626, "no_speech_prob": 2.3551689082523808e-05}, {"id": 1401, "seek": 736104, "start": 7361.04, "end": 7369.08, "text": " and probabilistic programming.", "tokens": [293, 31959, 3142, 9410, 13], "temperature": 0.0, "avg_logprob": -0.45590378517328306, "compression_ratio": 1.488, "no_speech_prob": 1.1125403943879064e-05}, {"id": 1402, "seek": 736104, "start": 7369.08, "end": 7374.16, "text": " So TensorFlow's now got this, what do they call it, TensorFlow probability or something.", "tokens": [407, 37624, 311, 586, 658, 341, 11, 437, 360, 436, 818, 309, 11, 37624, 8482, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.45590378517328306, "compression_ratio": 1.488, "no_speech_prob": 1.1125403943879064e-05}, {"id": 1403, "seek": 736104, "start": 7374.16, "end": 7381.76, "text": " There's a bunch of probabilistic programming frameworks out there.", "tokens": [821, 311, 257, 3840, 295, 31959, 3142, 9410, 29834, 484, 456, 13], "temperature": 0.0, "avg_logprob": -0.45590378517328306, "compression_ratio": 1.488, "no_speech_prob": 1.1125403943879064e-05}, {"id": 1404, "seek": 738176, "start": 7381.76, "end": 7395.52, "text": " I think they're intriguing, but as yet unproven in the sense that I haven't seen anything", "tokens": [286, 519, 436, 434, 32503, 11, 457, 382, 1939, 517, 4318, 553, 294, 264, 2020, 300, 286, 2378, 380, 1612, 1340], "temperature": 0.0, "avg_logprob": -0.09146957619245662, "compression_ratio": 1.3846153846153846, "no_speech_prob": 2.3687875909672584e-06}, {"id": 1405, "seek": 738176, "start": 7395.52, "end": 7402.72, "text": " done with any probabilistic programming system which hasn't been done better without them.", "tokens": [1096, 365, 604, 31959, 3142, 9410, 1185, 597, 6132, 380, 668, 1096, 1101, 1553, 552, 13], "temperature": 0.0, "avg_logprob": -0.09146957619245662, "compression_ratio": 1.3846153846153846, "no_speech_prob": 2.3687875909672584e-06}, {"id": 1406, "seek": 740272, "start": 7402.72, "end": 7412.08, "text": " The basic premise is that it allows you to create more of a model of how you think the", "tokens": [440, 3875, 22045, 307, 300, 309, 4045, 291, 281, 1884, 544, 295, 257, 2316, 295, 577, 291, 519, 264], "temperature": 0.0, "avg_logprob": -0.1730974125412275, "compression_ratio": 1.5977443609022557, "no_speech_prob": 1.696400977380108e-05}, {"id": 1407, "seek": 740272, "start": 7412.08, "end": 7414.64, "text": " world works and then plug in the parameters.", "tokens": [1002, 1985, 293, 550, 5452, 294, 264, 9834, 13], "temperature": 0.0, "avg_logprob": -0.1730974125412275, "compression_ratio": 1.5977443609022557, "no_speech_prob": 1.696400977380108e-05}, {"id": 1408, "seek": 740272, "start": 7414.64, "end": 7418.4800000000005, "text": " So back when I used to work in management consulting 20 years ago, we used to do a lot", "tokens": [407, 646, 562, 286, 1143, 281, 589, 294, 4592, 23682, 945, 924, 2057, 11, 321, 1143, 281, 360, 257, 688], "temperature": 0.0, "avg_logprob": -0.1730974125412275, "compression_ratio": 1.5977443609022557, "no_speech_prob": 1.696400977380108e-05}, {"id": 1409, "seek": 740272, "start": 7418.4800000000005, "end": 7424.64, "text": " of stuff where we would use a spreadsheet and then we would have these Monte Carlo simulation", "tokens": [295, 1507, 689, 321, 576, 764, 257, 27733, 293, 550, 321, 576, 362, 613, 38105, 45112, 16575], "temperature": 0.0, "avg_logprob": -0.1730974125412275, "compression_ratio": 1.5977443609022557, "no_speech_prob": 1.696400977380108e-05}, {"id": 1410, "seek": 740272, "start": 7424.64, "end": 7425.64, "text": " plugins.", "tokens": [33759, 13], "temperature": 0.0, "avg_logprob": -0.1730974125412275, "compression_ratio": 1.5977443609022557, "no_speech_prob": 1.696400977380108e-05}, {"id": 1411, "seek": 740272, "start": 7425.64, "end": 7427.68, "text": " There's one called At Risk and one called Crystal Ball.", "tokens": [821, 311, 472, 1219, 1711, 45892, 293, 472, 1219, 23489, 10744, 13], "temperature": 0.0, "avg_logprob": -0.1730974125412275, "compression_ratio": 1.5977443609022557, "no_speech_prob": 1.696400977380108e-05}, {"id": 1412, "seek": 740272, "start": 7427.68, "end": 7429.64, "text": " I don't know if they still exist decades later.", "tokens": [286, 500, 380, 458, 498, 436, 920, 2514, 7878, 1780, 13], "temperature": 0.0, "avg_logprob": -0.1730974125412275, "compression_ratio": 1.5977443609022557, "no_speech_prob": 1.696400977380108e-05}, {"id": 1413, "seek": 742964, "start": 7429.64, "end": 7435.88, "text": " But basically they would let you change a spreadsheet cell to say this is not a specific", "tokens": [583, 1936, 436, 576, 718, 291, 1319, 257, 27733, 2815, 281, 584, 341, 307, 406, 257, 2685], "temperature": 0.0, "avg_logprob": -0.16415639718373617, "compression_ratio": 1.796, "no_speech_prob": 1.1300436199235264e-05}, {"id": 1414, "seek": 742964, "start": 7435.88, "end": 7440.360000000001, "text": " value but it actually represents a distribution of values with this mean and standard deviation", "tokens": [2158, 457, 309, 767, 8855, 257, 7316, 295, 4190, 365, 341, 914, 293, 3832, 25163], "temperature": 0.0, "avg_logprob": -0.16415639718373617, "compression_ratio": 1.796, "no_speech_prob": 1.1300436199235264e-05}, {"id": 1415, "seek": 742964, "start": 7440.360000000001, "end": 7442.4800000000005, "text": " or it's got this distribution.", "tokens": [420, 309, 311, 658, 341, 7316, 13], "temperature": 0.0, "avg_logprob": -0.16415639718373617, "compression_ratio": 1.796, "no_speech_prob": 1.1300436199235264e-05}, {"id": 1416, "seek": 742964, "start": 7442.4800000000005, "end": 7447.56, "text": " And then you would hit a button and the spreadsheet would recalculate a thousand times pulling", "tokens": [400, 550, 291, 576, 2045, 257, 2960, 293, 264, 27733, 576, 850, 304, 2444, 473, 257, 4714, 1413, 8407], "temperature": 0.0, "avg_logprob": -0.16415639718373617, "compression_ratio": 1.796, "no_speech_prob": 1.1300436199235264e-05}, {"id": 1417, "seek": 742964, "start": 7447.56, "end": 7451.360000000001, "text": " random numbers from the distributions and show you the distribution of your outcome", "tokens": [4974, 3547, 490, 264, 37870, 293, 855, 291, 264, 7316, 295, 428, 9700], "temperature": 0.0, "avg_logprob": -0.16415639718373617, "compression_ratio": 1.796, "no_speech_prob": 1.1300436199235264e-05}, {"id": 1418, "seek": 742964, "start": 7451.360000000001, "end": 7456.360000000001, "text": " that might be some profit or market share or whatever.", "tokens": [300, 1062, 312, 512, 7475, 420, 2142, 2073, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.16415639718373617, "compression_ratio": 1.796, "no_speech_prob": 1.1300436199235264e-05}, {"id": 1419, "seek": 745636, "start": 7456.36, "end": 7459.799999999999, "text": " And we used them all the time back then.", "tokens": [400, 321, 1143, 552, 439, 264, 565, 646, 550, 13], "temperature": 0.0, "avg_logprob": -0.2091617351625024, "compression_ratio": 1.5572916666666667, "no_speech_prob": 3.7852971672691638e-06}, {"id": 1420, "seek": 745636, "start": 7459.799999999999, "end": 7466.24, "text": " I partly feel that a spreadsheet is a more obvious place to do that kind of work because", "tokens": [286, 17031, 841, 300, 257, 27733, 307, 257, 544, 6322, 1081, 281, 360, 300, 733, 295, 589, 570], "temperature": 0.0, "avg_logprob": -0.2091617351625024, "compression_ratio": 1.5572916666666667, "no_speech_prob": 3.7852971672691638e-06}, {"id": 1421, "seek": 745636, "start": 7466.24, "end": 7469.719999999999, "text": " you can kind of see it all much more naturally.", "tokens": [291, 393, 733, 295, 536, 309, 439, 709, 544, 8195, 13], "temperature": 0.0, "avg_logprob": -0.2091617351625024, "compression_ratio": 1.5572916666666667, "no_speech_prob": 3.7852971672691638e-06}, {"id": 1422, "seek": 745636, "start": 7469.719999999999, "end": 7475.32, "text": " But I don't know, we'll see.", "tokens": [583, 286, 500, 380, 458, 11, 321, 603, 536, 13], "temperature": 0.0, "avg_logprob": -0.2091617351625024, "compression_ratio": 1.5572916666666667, "no_speech_prob": 3.7852971672691638e-06}, {"id": 1423, "seek": 745636, "start": 7475.32, "end": 7481.48, "text": " At this stage, I hope it turns out to be useful because I find it very appealing and it kind", "tokens": [1711, 341, 3233, 11, 286, 1454, 309, 4523, 484, 281, 312, 4420, 570, 286, 915, 309, 588, 23842, 293, 309, 733], "temperature": 0.0, "avg_logprob": -0.2091617351625024, "compression_ratio": 1.5572916666666667, "no_speech_prob": 3.7852971672691638e-06}, {"id": 1424, "seek": 748148, "start": 7481.48, "end": 7486.44, "text": " of appeals to, as I say, the kind of work I used to do a lot of.", "tokens": [295, 32603, 281, 11, 382, 286, 584, 11, 264, 733, 295, 589, 286, 1143, 281, 360, 257, 688, 295, 13], "temperature": 0.0, "avg_logprob": -0.23354183755269864, "compression_ratio": 1.4902912621359223, "no_speech_prob": 6.643339929723879e-06}, {"id": 1425, "seek": 748148, "start": 7486.44, "end": 7491.16, "text": " There's actually whole practices around this stuff they used to call systems dynamics which", "tokens": [821, 311, 767, 1379, 7525, 926, 341, 1507, 436, 1143, 281, 818, 3652, 15679, 597], "temperature": 0.0, "avg_logprob": -0.23354183755269864, "compression_ratio": 1.4902912621359223, "no_speech_prob": 6.643339929723879e-06}, {"id": 1426, "seek": 748148, "start": 7491.16, "end": 7494.04, "text": " really was built on top of this kind of stuff.", "tokens": [534, 390, 3094, 322, 1192, 295, 341, 733, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.23354183755269864, "compression_ratio": 1.4902912621359223, "no_speech_prob": 6.643339929723879e-06}, {"id": 1427, "seek": 748148, "start": 7494.04, "end": 7496.919999999999, "text": " But I don't know, it's not quite gone anywhere.", "tokens": [583, 286, 500, 380, 458, 11, 309, 311, 406, 1596, 2780, 4992, 13], "temperature": 0.0, "avg_logprob": -0.23354183755269864, "compression_ratio": 1.4902912621359223, "no_speech_prob": 6.643339929723879e-06}, {"id": 1428, "seek": 748148, "start": 7496.919999999999, "end": 7505.799999999999, "text": " Question about pre-training for generic style transfer.", "tokens": [14464, 466, 659, 12, 17227, 1760, 337, 19577, 3758, 5003, 13], "temperature": 0.0, "avg_logprob": -0.23354183755269864, "compression_ratio": 1.4902912621359223, "no_speech_prob": 6.643339929723879e-06}, {"id": 1429, "seek": 750580, "start": 7505.8, "end": 7516.4400000000005, "text": " Yes, I don't think you can pre-train for a generic style, but you can pre-train for a", "tokens": [1079, 11, 286, 500, 380, 519, 291, 393, 659, 12, 83, 7146, 337, 257, 19577, 3758, 11, 457, 291, 393, 659, 12, 83, 7146, 337, 257], "temperature": 0.0, "avg_logprob": -0.1725563124606484, "compression_ratio": 1.536144578313253, "no_speech_prob": 1.0348481964683742e-06}, {"id": 1430, "seek": 750580, "start": 7516.4400000000005, "end": 7524.400000000001, "text": " generic photo for a particular style, which is where we're going to get to.", "tokens": [19577, 5052, 337, 257, 1729, 3758, 11, 597, 307, 689, 321, 434, 516, 281, 483, 281, 13], "temperature": 0.0, "avg_logprob": -0.1725563124606484, "compression_ratio": 1.536144578313253, "no_speech_prob": 1.0348481964683742e-06}, {"id": 1431, "seek": 750580, "start": 7524.400000000001, "end": 7528.76, "text": " Although it may end up being homework, I haven't decided.", "tokens": [5780, 309, 815, 917, 493, 885, 14578, 11, 286, 2378, 380, 3047, 13], "temperature": 0.0, "avg_logprob": -0.1725563124606484, "compression_ratio": 1.536144578313253, "no_speech_prob": 1.0348481964683742e-06}, {"id": 1432, "seek": 750580, "start": 7528.76, "end": 7532.08, "text": " But I'm going to do all the pieces.", "tokens": [583, 286, 478, 516, 281, 360, 439, 264, 3755, 13], "temperature": 0.0, "avg_logprob": -0.1725563124606484, "compression_ratio": 1.536144578313253, "no_speech_prob": 1.0348481964683742e-06}, {"id": 1433, "seek": 753208, "start": 7532.08, "end": 7549.6, "text": " One more question is, please ask him to talk about multi-GPU.", "tokens": [1485, 544, 1168, 307, 11, 1767, 1029, 796, 281, 751, 466, 4825, 12, 38, 8115, 13], "temperature": 0.0, "avg_logprob": -0.3024403658780185, "compression_ratio": 1.2925170068027212, "no_speech_prob": 8.800808245723601e-06}, {"id": 1434, "seek": 753208, "start": 7549.6, "end": 7553.5199999999995, "text": " Before we do, just another interesting picture from the Gaddy's paper.", "tokens": [4546, 321, 360, 11, 445, 1071, 1880, 3036, 490, 264, 37171, 3173, 311, 3035, 13], "temperature": 0.0, "avg_logprob": -0.3024403658780185, "compression_ratio": 1.2925170068027212, "no_speech_prob": 8.800808245723601e-06}, {"id": 1435, "seek": 753208, "start": 7553.5199999999995, "end": 7557.5599999999995, "text": " They've got a few more, just didn't fit in my slide here.", "tokens": [814, 600, 658, 257, 1326, 544, 11, 445, 994, 380, 3318, 294, 452, 4137, 510, 13], "temperature": 0.0, "avg_logprob": -0.3024403658780185, "compression_ratio": 1.2925170068027212, "no_speech_prob": 8.800808245723601e-06}, {"id": 1436, "seek": 755756, "start": 7557.56, "end": 7566.240000000001, "text": " Different convolutional layers for the style, different style to content ratios.", "tokens": [20825, 45216, 304, 7914, 337, 264, 3758, 11, 819, 3758, 281, 2701, 32435, 13], "temperature": 0.0, "avg_logprob": -0.2455085190859708, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.6476412788033485e-05}, {"id": 1437, "seek": 755756, "start": 7566.240000000001, "end": 7570.120000000001, "text": " Obviously this isn't Van Gogh anymore, this is a different combination.", "tokens": [7580, 341, 1943, 380, 8979, 39690, 71, 3602, 11, 341, 307, 257, 819, 6562, 13], "temperature": 0.0, "avg_logprob": -0.2455085190859708, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.6476412788033485e-05}, {"id": 1438, "seek": 755756, "start": 7570.120000000001, "end": 7574.5, "text": " So you can see if you just do all style, you don't see any image.", "tokens": [407, 291, 393, 536, 498, 291, 445, 360, 439, 3758, 11, 291, 500, 380, 536, 604, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2455085190859708, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.6476412788033485e-05}, {"id": 1439, "seek": 755756, "start": 7574.5, "end": 7581.240000000001, "text": " If you do lots of content, but you use a low enough convolutional layer, it looks okay,", "tokens": [759, 291, 360, 3195, 295, 2701, 11, 457, 291, 764, 257, 2295, 1547, 45216, 304, 4583, 11, 309, 1542, 1392, 11], "temperature": 0.0, "avg_logprob": -0.2455085190859708, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.6476412788033485e-05}, {"id": 1440, "seek": 755756, "start": 7581.240000000001, "end": 7583.76, "text": " but the background is kind of dumb.", "tokens": [457, 264, 3678, 307, 733, 295, 10316, 13], "temperature": 0.0, "avg_logprob": -0.2455085190859708, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.6476412788033485e-05}, {"id": 1441, "seek": 758376, "start": 7583.76, "end": 7587.780000000001, "text": " So you kind of want somewhere around here or here, I guess.", "tokens": [407, 291, 733, 295, 528, 4079, 926, 510, 420, 510, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.15962518816408905, "compression_ratio": 1.5688073394495412, "no_speech_prob": 1.8631439161254093e-05}, {"id": 1442, "seek": 758376, "start": 7587.780000000001, "end": 7594.2, "text": " So you can play around with the experiment, but also use the paper to help guide you.", "tokens": [407, 291, 393, 862, 926, 365, 264, 5120, 11, 457, 611, 764, 264, 3035, 281, 854, 5934, 291, 13], "temperature": 0.0, "avg_logprob": -0.15962518816408905, "compression_ratio": 1.5688073394495412, "no_speech_prob": 1.8631439161254093e-05}, {"id": 1443, "seek": 758376, "start": 7594.2, "end": 7602.04, "text": " Actually I think I might work on the math now, and we'll talk about multi-GPU and super", "tokens": [5135, 286, 519, 286, 1062, 589, 322, 264, 5221, 586, 11, 293, 321, 603, 751, 466, 4825, 12, 38, 8115, 293, 1687], "temperature": 0.0, "avg_logprob": -0.15962518816408905, "compression_ratio": 1.5688073394495412, "no_speech_prob": 1.8631439161254093e-05}, {"id": 1444, "seek": 758376, "start": 7602.04, "end": 7604.04, "text": " resolution next week.", "tokens": [8669, 958, 1243, 13], "temperature": 0.0, "avg_logprob": -0.15962518816408905, "compression_ratio": 1.5688073394495412, "no_speech_prob": 1.8631439161254093e-05}, {"id": 1445, "seek": 758376, "start": 7604.04, "end": 7609.3, "text": " I think this is from the paper, and one of the things I really do want you to do after", "tokens": [286, 519, 341, 307, 490, 264, 3035, 11, 293, 472, 295, 264, 721, 286, 534, 360, 528, 291, 281, 360, 934], "temperature": 0.0, "avg_logprob": -0.15962518816408905, "compression_ratio": 1.5688073394495412, "no_speech_prob": 1.8631439161254093e-05}, {"id": 1446, "seek": 760930, "start": 7609.3, "end": 7614.4800000000005, "text": " we talk about a paper is to read the paper and then ask questions on the forum, anything", "tokens": [321, 751, 466, 257, 3035, 307, 281, 1401, 264, 3035, 293, 550, 1029, 1651, 322, 264, 17542, 11, 1340], "temperature": 0.0, "avg_logprob": -0.15375857883029515, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.0451398338773288e-05}, {"id": 1447, "seek": 760930, "start": 7614.4800000000005, "end": 7615.4800000000005, "text": " that's not clear.", "tokens": [300, 311, 406, 1850, 13], "temperature": 0.0, "avg_logprob": -0.15375857883029515, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.0451398338773288e-05}, {"id": 1448, "seek": 760930, "start": 7615.4800000000005, "end": 7622.400000000001, "text": " But there's kind of like a key part of this paper which I wanted to talk about and discuss", "tokens": [583, 456, 311, 733, 295, 411, 257, 2141, 644, 295, 341, 3035, 597, 286, 1415, 281, 751, 466, 293, 2248], "temperature": 0.0, "avg_logprob": -0.15375857883029515, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.0451398338773288e-05}, {"id": 1449, "seek": 760930, "start": 7622.400000000001, "end": 7623.72, "text": " how to interpret it.", "tokens": [577, 281, 7302, 309, 13], "temperature": 0.0, "avg_logprob": -0.15375857883029515, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.0451398338773288e-05}, {"id": 1450, "seek": 760930, "start": 7623.72, "end": 7631.28, "text": " So the paper says we're going to be given an input image X, and this little thing means", "tokens": [407, 264, 3035, 1619, 321, 434, 516, 281, 312, 2212, 364, 4846, 3256, 1783, 11, 293, 341, 707, 551, 1355], "temperature": 0.0, "avg_logprob": -0.15375857883029515, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.0451398338773288e-05}, {"id": 1451, "seek": 763128, "start": 7631.28, "end": 7648.8, "text": " it's a vector, but this one's a matrix.", "tokens": [309, 311, 257, 8062, 11, 457, 341, 472, 311, 257, 8141, 13], "temperature": 0.0, "avg_logprob": -0.26548463419864055, "compression_ratio": 1.3894736842105264, "no_speech_prob": 1.2218782103445847e-05}, {"id": 1452, "seek": 763128, "start": 7648.8, "end": 7658.08, "text": " So normally small letter bold means vector, or small letter with doobie on top means vector,", "tokens": [407, 5646, 1359, 5063, 11928, 1355, 8062, 11, 420, 1359, 5063, 365, 360, 996, 414, 322, 1192, 1355, 8062, 11], "temperature": 0.0, "avg_logprob": -0.26548463419864055, "compression_ratio": 1.3894736842105264, "no_speech_prob": 1.2218782103445847e-05}, {"id": 1453, "seek": 765808, "start": 7658.08, "end": 7663.8, "text": " and normally big letter means matrix, or small letter with two doobies on top means matrix.", "tokens": [293, 5646, 955, 5063, 1355, 8141, 11, 420, 1359, 5063, 365, 732, 360, 996, 530, 322, 1192, 1355, 8141, 13], "temperature": 0.0, "avg_logprob": -0.15300956658557452, "compression_ratio": 1.6781609195402298, "no_speech_prob": 4.860408353124512e-06}, {"id": 1454, "seek": 765808, "start": 7663.8, "end": 7666.76, "text": " In this case our image is a matrix.", "tokens": [682, 341, 1389, 527, 3256, 307, 257, 8141, 13], "temperature": 0.0, "avg_logprob": -0.15300956658557452, "compression_ratio": 1.6781609195402298, "no_speech_prob": 4.860408353124512e-06}, {"id": 1455, "seek": 765808, "start": 7666.76, "end": 7672.04, "text": " We are going to basically treat it as a vector, so maybe we're just getting ahead of ourselves.", "tokens": [492, 366, 516, 281, 1936, 2387, 309, 382, 257, 8062, 11, 370, 1310, 321, 434, 445, 1242, 2286, 295, 4175, 13], "temperature": 0.0, "avg_logprob": -0.15300956658557452, "compression_ratio": 1.6781609195402298, "no_speech_prob": 4.860408353124512e-06}, {"id": 1456, "seek": 765808, "start": 7672.04, "end": 7678.32, "text": " So we've got an input image X, and it can be encoded in a particular layer of the CNN", "tokens": [407, 321, 600, 658, 364, 4846, 3256, 1783, 11, 293, 309, 393, 312, 2058, 12340, 294, 257, 1729, 4583, 295, 264, 24859], "temperature": 0.0, "avg_logprob": -0.15300956658557452, "compression_ratio": 1.6781609195402298, "no_speech_prob": 4.860408353124512e-06}, {"id": 1457, "seek": 765808, "start": 7678.32, "end": 7681.4, "text": " by the filter responses, so the activations.", "tokens": [538, 264, 6608, 13019, 11, 370, 264, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.15300956658557452, "compression_ratio": 1.6781609195402298, "no_speech_prob": 4.860408353124512e-06}, {"id": 1458, "seek": 765808, "start": 7681.4, "end": 7683.74, "text": " Filter responses are activations.", "tokens": [39592, 13019, 366, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.15300956658557452, "compression_ratio": 1.6781609195402298, "no_speech_prob": 4.860408353124512e-06}, {"id": 1459, "seek": 765808, "start": 7683.74, "end": 7686.32, "text": " So hopefully that's something you all understand.", "tokens": [407, 4696, 300, 311, 746, 291, 439, 1223, 13], "temperature": 0.0, "avg_logprob": -0.15300956658557452, "compression_ratio": 1.6781609195402298, "no_speech_prob": 4.860408353124512e-06}, {"id": 1460, "seek": 768632, "start": 7686.32, "end": 7691.5199999999995, "text": " That's basically what a CNN does, it produces layers of activations.", "tokens": [663, 311, 1936, 437, 257, 24859, 775, 11, 309, 14725, 7914, 295, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.18767229303137048, "compression_ratio": 1.5549738219895288, "no_speech_prob": 1.2218977644806728e-05}, {"id": 1461, "seek": 768632, "start": 7691.5199999999995, "end": 7696.679999999999, "text": " A layer has a bunch of filters which produce a number of channels.", "tokens": [316, 4583, 575, 257, 3840, 295, 15995, 597, 5258, 257, 1230, 295, 9235, 13], "temperature": 0.0, "avg_logprob": -0.18767229303137048, "compression_ratio": 1.5549738219895288, "no_speech_prob": 1.2218977644806728e-05}, {"id": 1462, "seek": 768632, "start": 7696.679999999999, "end": 7703.28, "text": " And so this here says that layer number L has capital NL filters.", "tokens": [400, 370, 341, 510, 1619, 300, 4583, 1230, 441, 575, 4238, 426, 43, 15995, 13], "temperature": 0.0, "avg_logprob": -0.18767229303137048, "compression_ratio": 1.5549738219895288, "no_speech_prob": 1.2218977644806728e-05}, {"id": 1463, "seek": 768632, "start": 7703.28, "end": 7706.74, "text": " And again this capital does not mean matrix.", "tokens": [400, 797, 341, 4238, 775, 406, 914, 8141, 13], "temperature": 0.0, "avg_logprob": -0.18767229303137048, "compression_ratio": 1.5549738219895288, "no_speech_prob": 1.2218977644806728e-05}, {"id": 1464, "seek": 768632, "start": 7706.74, "end": 7710.599999999999, "text": " So I don't know, math notation is so inconsistent.", "tokens": [407, 286, 500, 380, 458, 11, 5221, 24657, 307, 370, 36891, 13], "temperature": 0.0, "avg_logprob": -0.18767229303137048, "compression_ratio": 1.5549738219895288, "no_speech_prob": 1.2218977644806728e-05}, {"id": 1465, "seek": 771060, "start": 7710.6, "end": 7718.660000000001, "text": " So capital NL distinct filters at layer L, which means it has also that many feature", "tokens": [407, 4238, 426, 43, 10644, 15995, 412, 4583, 441, 11, 597, 1355, 309, 575, 611, 300, 867, 4111], "temperature": 0.0, "avg_logprob": -0.1798413728412829, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.157316652708687e-06}, {"id": 1466, "seek": 771060, "start": 7718.660000000001, "end": 7719.660000000001, "text": " maps.", "tokens": [11317, 13], "temperature": 0.0, "avg_logprob": -0.1798413728412829, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.157316652708687e-06}, {"id": 1467, "seek": 771060, "start": 7719.660000000001, "end": 7722.4400000000005, "text": " So make sure you can see that this letter is the same as this letter.", "tokens": [407, 652, 988, 291, 393, 536, 300, 341, 5063, 307, 264, 912, 382, 341, 5063, 13], "temperature": 0.0, "avg_logprob": -0.1798413728412829, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.157316652708687e-06}, {"id": 1468, "seek": 771060, "start": 7722.4400000000005, "end": 7727.52, "text": " So you've got to be very careful to read the letters and recognize it's like snap, that's", "tokens": [407, 291, 600, 658, 281, 312, 588, 5026, 281, 1401, 264, 7825, 293, 5521, 309, 311, 411, 13650, 11, 300, 311], "temperature": 0.0, "avg_logprob": -0.1798413728412829, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.157316652708687e-06}, {"id": 1469, "seek": 771060, "start": 7727.52, "end": 7729.6, "text": " the same letter as that.", "tokens": [264, 912, 5063, 382, 300, 13], "temperature": 0.0, "avg_logprob": -0.1798413728412829, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.157316652708687e-06}, {"id": 1470, "seek": 771060, "start": 7729.6, "end": 7736.88, "text": " So obviously NL feature maps or NL filters create NL feature maps or channels.", "tokens": [407, 2745, 426, 43, 4111, 11317, 420, 426, 43, 15995, 1884, 426, 43, 4111, 11317, 420, 9235, 13], "temperature": 0.0, "avg_logprob": -0.1798413728412829, "compression_ratio": 1.7352941176470589, "no_speech_prob": 4.157316652708687e-06}, {"id": 1471, "seek": 773688, "start": 7736.88, "end": 7743.68, "text": " H1 is of size M, so I can see this is where the unrolling is happening.", "tokens": [389, 16, 307, 295, 2744, 376, 11, 370, 286, 393, 536, 341, 307, 689, 264, 517, 18688, 307, 2737, 13], "temperature": 0.0, "avg_logprob": -0.24043943665244363, "compression_ratio": 1.5029239766081872, "no_speech_prob": 2.1568107513303403e-06}, {"id": 1472, "seek": 773688, "start": 7743.68, "end": 7746.92, "text": " Hbap is of size M little l.", "tokens": [389, 65, 569, 307, 295, 2744, 376, 707, 287, 13], "temperature": 0.0, "avg_logprob": -0.24043943665244363, "compression_ratio": 1.5029239766081872, "no_speech_prob": 2.1568107513303403e-06}, {"id": 1473, "seek": 773688, "start": 7746.92, "end": 7753.8, "text": " So this is like M square bracket L in NumPy notation, it's the Lth layer.", "tokens": [407, 341, 307, 411, 376, 3732, 16904, 441, 294, 22592, 47, 88, 24657, 11, 309, 311, 264, 441, 392, 4583, 13], "temperature": 0.0, "avg_logprob": -0.24043943665244363, "compression_ratio": 1.5029239766081872, "no_speech_prob": 2.1568107513303403e-06}, {"id": 1474, "seek": 773688, "start": 7753.8, "end": 7756.04, "text": " So M for the Lth layer.", "tokens": [407, 376, 337, 264, 441, 392, 4583, 13], "temperature": 0.0, "avg_logprob": -0.24043943665244363, "compression_ratio": 1.5029239766081872, "no_speech_prob": 2.1568107513303403e-06}, {"id": 1475, "seek": 773688, "start": 7756.04, "end": 7760.68, "text": " And the size is height times width.", "tokens": [400, 264, 2744, 307, 6681, 1413, 11402, 13], "temperature": 0.0, "avg_logprob": -0.24043943665244363, "compression_ratio": 1.5029239766081872, "no_speech_prob": 2.1568107513303403e-06}, {"id": 1476, "seek": 773688, "start": 7760.68, "end": 7762.92, "text": " So we flattened it out.", "tokens": [407, 321, 24183, 292, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.24043943665244363, "compression_ratio": 1.5029239766081872, "no_speech_prob": 2.1568107513303403e-06}, {"id": 1477, "seek": 776292, "start": 7762.92, "end": 7770.76, "text": " So the responses at that layer L can be stored in a matrix F, and now the L goes at the top", "tokens": [407, 264, 13019, 412, 300, 4583, 441, 393, 312, 12187, 294, 257, 8141, 479, 11, 293, 586, 264, 441, 1709, 412, 264, 1192], "temperature": 0.0, "avg_logprob": -0.1382208920400077, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.769398861346417e-06}, {"id": 1478, "seek": 776292, "start": 7770.76, "end": 7771.76, "text": " for some reason.", "tokens": [337, 512, 1778, 13], "temperature": 0.0, "avg_logprob": -0.1382208920400077, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.769398861346417e-06}, {"id": 1479, "seek": 776292, "start": 7771.76, "end": 7775.72, "text": " So this is not F to the power of L, this is just another indexing, we're just moving it", "tokens": [407, 341, 307, 406, 479, 281, 264, 1347, 295, 441, 11, 341, 307, 445, 1071, 8186, 278, 11, 321, 434, 445, 2684, 309], "temperature": 0.0, "avg_logprob": -0.1382208920400077, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.769398861346417e-06}, {"id": 1480, "seek": 776292, "start": 7775.72, "end": 7778.76, "text": " around for fun.", "tokens": [926, 337, 1019, 13], "temperature": 0.0, "avg_logprob": -0.1382208920400077, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.769398861346417e-06}, {"id": 1481, "seek": 776292, "start": 7778.76, "end": 7782.72, "text": " And this thing here where we say it's an element of R, this is a special R meaning the real", "tokens": [400, 341, 551, 510, 689, 321, 584, 309, 311, 364, 4478, 295, 497, 11, 341, 307, 257, 2121, 497, 3620, 264, 957], "temperature": 0.0, "avg_logprob": -0.1382208920400077, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.769398861346417e-06}, {"id": 1482, "seek": 776292, "start": 7782.72, "end": 7789.04, "text": " numbers, N times M, this is saying that the dimensions of this is N by M.", "tokens": [3547, 11, 426, 1413, 376, 11, 341, 307, 1566, 300, 264, 12819, 295, 341, 307, 426, 538, 376, 13], "temperature": 0.0, "avg_logprob": -0.1382208920400077, "compression_ratio": 1.6506550218340612, "no_speech_prob": 2.769398861346417e-06}, {"id": 1483, "seek": 778904, "start": 7789.04, "end": 7794.0, "text": " So this is really important, it's just like with PyTorch, making sure you understand the", "tokens": [407, 341, 307, 534, 1021, 11, 309, 311, 445, 411, 365, 9953, 51, 284, 339, 11, 1455, 988, 291, 1223, 264], "temperature": 0.0, "avg_logprob": -0.15944796860820115, "compression_ratio": 1.5107296137339057, "no_speech_prob": 7.296346666407771e-06}, {"id": 1484, "seek": 778904, "start": 7794.0, "end": 7797.24, "text": " rank and size of your dimensions first.", "tokens": [6181, 293, 2744, 295, 428, 12819, 700, 13], "temperature": 0.0, "avg_logprob": -0.15944796860820115, "compression_ratio": 1.5107296137339057, "no_speech_prob": 7.296346666407771e-06}, {"id": 1485, "seek": 778904, "start": 7797.24, "end": 7803.68, "text": " Same with math, these are the bits where you stop and think, why is it N by M?", "tokens": [10635, 365, 5221, 11, 613, 366, 264, 9239, 689, 291, 1590, 293, 519, 11, 983, 307, 309, 426, 538, 376, 30], "temperature": 0.0, "avg_logprob": -0.15944796860820115, "compression_ratio": 1.5107296137339057, "no_speech_prob": 7.296346666407771e-06}, {"id": 1486, "seek": 778904, "start": 7803.68, "end": 7808.28, "text": " So N is the number of filters, M is height by width.", "tokens": [407, 426, 307, 264, 1230, 295, 15995, 11, 376, 307, 6681, 538, 11402, 13], "temperature": 0.0, "avg_logprob": -0.15944796860820115, "compression_ratio": 1.5107296137339057, "no_speech_prob": 7.296346666407771e-06}, {"id": 1487, "seek": 778904, "start": 7808.28, "end": 7815.24, "text": " So do you remember that thing where we did view batch times channel, minus 1?", "tokens": [407, 360, 291, 1604, 300, 551, 689, 321, 630, 1910, 15245, 1413, 2269, 11, 3175, 502, 30], "temperature": 0.0, "avg_logprob": -0.15944796860820115, "compression_ratio": 1.5107296137339057, "no_speech_prob": 7.296346666407771e-06}, {"id": 1488, "seek": 778904, "start": 7815.24, "end": 7816.24, "text": " Here that is.", "tokens": [1692, 300, 307, 13], "temperature": 0.0, "avg_logprob": -0.15944796860820115, "compression_ratio": 1.5107296137339057, "no_speech_prob": 7.296346666407771e-06}, {"id": 1489, "seek": 781624, "start": 7816.24, "end": 7819.4, "text": " So try to map the code to the math.", "tokens": [407, 853, 281, 4471, 264, 3089, 281, 264, 5221, 13], "temperature": 0.0, "avg_logprob": -0.1373234060075548, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.1659482879622374e-05}, {"id": 1490, "seek": 781624, "start": 7819.4, "end": 7831.679999999999, "text": " So F is X.", "tokens": [407, 479, 307, 1783, 13], "temperature": 0.0, "avg_logprob": -0.1373234060075548, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.1659482879622374e-05}, {"id": 1491, "seek": 781624, "start": 7831.679999999999, "end": 7836.48, "text": " If I was nicer to you, I would have used the same letters as the paper, but I was too busy", "tokens": [759, 286, 390, 22842, 281, 291, 11, 286, 576, 362, 1143, 264, 912, 7825, 382, 264, 3035, 11, 457, 286, 390, 886, 5856], "temperature": 0.0, "avg_logprob": -0.1373234060075548, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.1659482879622374e-05}, {"id": 1492, "seek": 781624, "start": 7836.48, "end": 7839.94, "text": " getting this damn thing working to do that carefully.", "tokens": [1242, 341, 8151, 551, 1364, 281, 360, 300, 7500, 13], "temperature": 0.0, "avg_logprob": -0.1373234060075548, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.1659482879622374e-05}, {"id": 1493, "seek": 781624, "start": 7839.94, "end": 7844.2, "text": " So you can go back and rename it as capital F.", "tokens": [407, 291, 393, 352, 646, 293, 36741, 309, 382, 4238, 479, 13], "temperature": 0.0, "avg_logprob": -0.1373234060075548, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.1659482879622374e-05}, {"id": 1494, "seek": 784420, "start": 7844.2, "end": 7848.599999999999, "text": " This is why we moved the L to the top, because we're now going to have some more indexing.", "tokens": [639, 307, 983, 321, 4259, 264, 441, 281, 264, 1192, 11, 570, 321, 434, 586, 516, 281, 362, 512, 544, 8186, 278, 13], "temperature": 0.0, "avg_logprob": -0.18098993216995643, "compression_ratio": 1.59375, "no_speech_prob": 4.6378440856642555e-06}, {"id": 1495, "seek": 784420, "start": 7848.599999999999, "end": 7853.36, "text": " So like where else in NumPy or PyTorch we index things by square brackets and lots of", "tokens": [407, 411, 689, 1646, 294, 22592, 47, 88, 420, 9953, 51, 284, 339, 321, 8186, 721, 538, 3732, 26179, 293, 3195, 295], "temperature": 0.0, "avg_logprob": -0.18098993216995643, "compression_ratio": 1.59375, "no_speech_prob": 4.6378440856642555e-06}, {"id": 1496, "seek": 784420, "start": 7853.36, "end": 7859.4, "text": " things with commas between, the approach in math is to surround your letter by little", "tokens": [721, 365, 800, 296, 1296, 11, 264, 3109, 294, 5221, 307, 281, 6262, 428, 5063, 538, 707], "temperature": 0.0, "avg_logprob": -0.18098993216995643, "compression_ratio": 1.59375, "no_speech_prob": 4.6378440856642555e-06}, {"id": 1497, "seek": 784420, "start": 7859.4, "end": 7861.92, "text": " letters all around it.", "tokens": [7825, 439, 926, 309, 13], "temperature": 0.0, "avg_logprob": -0.18098993216995643, "compression_ratio": 1.59375, "no_speech_prob": 4.6378440856642555e-06}, {"id": 1498, "seek": 784420, "start": 7861.92, "end": 7863.5199999999995, "text": " Just throw them up there everywhere.", "tokens": [1449, 3507, 552, 493, 456, 5315, 13], "temperature": 0.0, "avg_logprob": -0.18098993216995643, "compression_ratio": 1.59375, "no_speech_prob": 4.6378440856642555e-06}, {"id": 1499, "seek": 784420, "start": 7863.5199999999995, "end": 7871.679999999999, "text": " So here FL is the Lth layer of F, and then ij is the activation of the i-th filter at", "tokens": [407, 510, 24720, 307, 264, 441, 392, 4583, 295, 479, 11, 293, 550, 741, 73, 307, 264, 24433, 295, 264, 741, 12, 392, 6608, 412], "temperature": 0.0, "avg_logprob": -0.18098993216995643, "compression_ratio": 1.59375, "no_speech_prob": 4.6378440856642555e-06}, {"id": 1500, "seek": 787168, "start": 7871.68, "end": 7880.16, "text": " position j of layer L. So position j is up to size M, which is up to size height by width.", "tokens": [2535, 361, 295, 4583, 441, 13, 407, 2535, 361, 307, 493, 281, 2744, 376, 11, 597, 307, 493, 281, 2744, 6681, 538, 11402, 13], "temperature": 0.0, "avg_logprob": -0.2012446721394857, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.570811698722537e-07}, {"id": 1501, "seek": 787168, "start": 7880.16, "end": 7882.68, "text": " This is the kind of thing that would be easy to get confused.", "tokens": [639, 307, 264, 733, 295, 551, 300, 576, 312, 1858, 281, 483, 9019, 13], "temperature": 0.0, "avg_logprob": -0.2012446721394857, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.570811698722537e-07}, {"id": 1502, "seek": 787168, "start": 7882.68, "end": 7887.8, "text": " Like often you'd see an ij and assume that's indexing into a position of an image, like", "tokens": [1743, 2049, 291, 1116, 536, 364, 741, 73, 293, 6552, 300, 311, 8186, 278, 666, 257, 2535, 295, 364, 3256, 11, 411], "temperature": 0.0, "avg_logprob": -0.2012446721394857, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.570811698722537e-07}, {"id": 1503, "seek": 787168, "start": 7887.8, "end": 7891.4400000000005, "text": " height by width, but it's totally not, is it?", "tokens": [6681, 538, 11402, 11, 457, 309, 311, 3879, 406, 11, 307, 309, 30], "temperature": 0.0, "avg_logprob": -0.2012446721394857, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.570811698722537e-07}, {"id": 1504, "seek": 787168, "start": 7891.4400000000005, "end": 7898.04, "text": " It's indexing into channel by flattened image.", "tokens": [467, 311, 8186, 278, 666, 2269, 538, 24183, 292, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2012446721394857, "compression_ratio": 1.6485148514851484, "no_speech_prob": 9.570811698722537e-07}, {"id": 1505, "seek": 789804, "start": 7898.04, "end": 7904.48, "text": " And it even tells you, it's the i-th filter, the i-th channel in the j-th position in the", "tokens": [400, 309, 754, 5112, 291, 11, 309, 311, 264, 741, 12, 392, 6608, 11, 264, 741, 12, 392, 2269, 294, 264, 361, 12, 392, 2535, 294, 264], "temperature": 0.0, "avg_logprob": -0.10742177856102418, "compression_ratio": 1.595959595959596, "no_speech_prob": 2.4439877961413004e-06}, {"id": 1506, "seek": 789804, "start": 7904.48, "end": 7910.56, "text": " flattened out image in layer L. So you're not going to be able to get any further in", "tokens": [24183, 292, 484, 3256, 294, 4583, 441, 13, 407, 291, 434, 406, 516, 281, 312, 1075, 281, 483, 604, 3052, 294], "temperature": 0.0, "avg_logprob": -0.10742177856102418, "compression_ratio": 1.595959595959596, "no_speech_prob": 2.4439877961413004e-06}, {"id": 1507, "seek": 789804, "start": 7910.56, "end": 7916.44, "text": " the paper unless you know, unless you understand what F is.", "tokens": [264, 3035, 5969, 291, 458, 11, 5969, 291, 1223, 437, 479, 307, 13], "temperature": 0.0, "avg_logprob": -0.10742177856102418, "compression_ratio": 1.595959595959596, "no_speech_prob": 2.4439877961413004e-06}, {"id": 1508, "seek": 789804, "start": 7916.44, "end": 7924.0199999999995, "text": " So that's why these are the bits where you stop and make sure you're comfortable.", "tokens": [407, 300, 311, 983, 613, 366, 264, 9239, 689, 291, 1590, 293, 652, 988, 291, 434, 4619, 13], "temperature": 0.0, "avg_logprob": -0.10742177856102418, "compression_ratio": 1.595959595959596, "no_speech_prob": 2.4439877961413004e-06}, {"id": 1509, "seek": 792402, "start": 7924.02, "end": 7930.88, "text": " So now, the content loss, I'm not going to spend much time on, but basically we're going", "tokens": [407, 586, 11, 264, 2701, 4470, 11, 286, 478, 406, 516, 281, 3496, 709, 565, 322, 11, 457, 1936, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.17770884899382897, "compression_ratio": 1.6278026905829597, "no_speech_prob": 1.1726393722710782e-06}, {"id": 1510, "seek": 792402, "start": 7930.88, "end": 7941.4400000000005, "text": " to just check out the values of the activations versus the predictions squared.", "tokens": [281, 445, 1520, 484, 264, 4190, 295, 264, 2430, 763, 5717, 264, 21264, 8889, 13], "temperature": 0.0, "avg_logprob": -0.17770884899382897, "compression_ratio": 1.6278026905829597, "no_speech_prob": 1.1726393722710782e-06}, {"id": 1511, "seek": 792402, "start": 7941.4400000000005, "end": 7944.120000000001, "text": " So there's our content loss.", "tokens": [407, 456, 311, 527, 2701, 4470, 13], "temperature": 0.0, "avg_logprob": -0.17770884899382897, "compression_ratio": 1.6278026905829597, "no_speech_prob": 1.1726393722710782e-06}, {"id": 1512, "seek": 792402, "start": 7944.120000000001, "end": 7949.280000000001, "text": " And the style loss will be much the same thing, but using the Gram matrix G.", "tokens": [400, 264, 3758, 4470, 486, 312, 709, 264, 912, 551, 11, 457, 1228, 264, 22130, 8141, 460, 13], "temperature": 0.0, "avg_logprob": -0.17770884899382897, "compression_ratio": 1.6278026905829597, "no_speech_prob": 1.1726393722710782e-06}, {"id": 1513, "seek": 792402, "start": 7949.280000000001, "end": 7952.580000000001, "text": " And I really wanted to show you this one, because I think it's super, sometimes I really", "tokens": [400, 286, 534, 1415, 281, 855, 291, 341, 472, 11, 570, 286, 519, 309, 311, 1687, 11, 2171, 286, 534], "temperature": 0.0, "avg_logprob": -0.17770884899382897, "compression_ratio": 1.6278026905829597, "no_speech_prob": 1.1726393722710782e-06}, {"id": 1514, "seek": 795258, "start": 7952.58, "end": 7956.96, "text": " like things you can do in math notation, and there are things you can also generally do", "tokens": [411, 721, 291, 393, 360, 294, 5221, 24657, 11, 293, 456, 366, 721, 291, 393, 611, 5101, 360], "temperature": 0.0, "avg_logprob": -0.17057459694998606, "compression_ratio": 1.979899497487437, "no_speech_prob": 2.090451744152233e-06}, {"id": 1515, "seek": 795258, "start": 7956.96, "end": 7963.4, "text": " in J and APL, which is there's kind of this implicit loop going on here.", "tokens": [294, 508, 293, 5372, 43, 11, 597, 307, 456, 311, 733, 295, 341, 26947, 6367, 516, 322, 510, 13], "temperature": 0.0, "avg_logprob": -0.17057459694998606, "compression_ratio": 1.979899497487437, "no_speech_prob": 2.090451744152233e-06}, {"id": 1516, "seek": 795258, "start": 7963.4, "end": 7968.04, "text": " What this is saying is there's a whole bunch of values of i and a whole bunch of values", "tokens": [708, 341, 307, 1566, 307, 456, 311, 257, 1379, 3840, 295, 4190, 295, 741, 293, 257, 1379, 3840, 295, 4190], "temperature": 0.0, "avg_logprob": -0.17057459694998606, "compression_ratio": 1.979899497487437, "no_speech_prob": 2.090451744152233e-06}, {"id": 1517, "seek": 795258, "start": 7968.04, "end": 7972.32, "text": " of j, and I've got to define g for all of them.", "tokens": [295, 361, 11, 293, 286, 600, 658, 281, 6964, 290, 337, 439, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.17057459694998606, "compression_ratio": 1.979899497487437, "no_speech_prob": 2.090451744152233e-06}, {"id": 1518, "seek": 795258, "start": 7972.32, "end": 7973.92, "text": " And there's a whole bunch of values of L as well.", "tokens": [400, 456, 311, 257, 1379, 3840, 295, 4190, 295, 441, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17057459694998606, "compression_ratio": 1.979899497487437, "no_speech_prob": 2.090451744152233e-06}, {"id": 1519, "seek": 795258, "start": 7973.92, "end": 7976.88, "text": " I'm going to define g for all of those as well.", "tokens": [286, 478, 516, 281, 6964, 290, 337, 439, 295, 729, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17057459694998606, "compression_ratio": 1.979899497487437, "no_speech_prob": 2.090451744152233e-06}, {"id": 1520, "seek": 797688, "start": 7976.88, "end": 7983.24, "text": " And so for all of my g at every L, every i, every j, it's going to be equal to something.", "tokens": [400, 370, 337, 439, 295, 452, 290, 412, 633, 441, 11, 633, 741, 11, 633, 361, 11, 309, 311, 516, 281, 312, 2681, 281, 746, 13], "temperature": 0.0, "avg_logprob": -0.18801972472551956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 1.349700141872745e-06}, {"id": 1521, "seek": 797688, "start": 7983.24, "end": 7990.8, "text": " And you can see the something has an i and a j and an L, so matching these.", "tokens": [400, 291, 393, 536, 264, 746, 575, 364, 741, 293, 257, 361, 293, 364, 441, 11, 370, 14324, 613, 13], "temperature": 0.0, "avg_logprob": -0.18801972472551956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 1.349700141872745e-06}, {"id": 1522, "seek": 797688, "start": 7990.8, "end": 7994.88, "text": " And it also has a k, and that's part of the sum.", "tokens": [400, 309, 611, 575, 257, 350, 11, 293, 300, 311, 644, 295, 264, 2408, 13], "temperature": 0.0, "avg_logprob": -0.18801972472551956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 1.349700141872745e-06}, {"id": 1523, "seek": 797688, "start": 7994.88, "end": 7996.28, "text": " So what's going on here?", "tokens": [407, 437, 311, 516, 322, 510, 30], "temperature": 0.0, "avg_logprob": -0.18801972472551956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 1.349700141872745e-06}, {"id": 1524, "seek": 797688, "start": 7996.28, "end": 8006.64, "text": " Well, it's saying that my Gram matrix in layer L for the ith channel, well these aren't channels", "tokens": [1042, 11, 309, 311, 1566, 300, 452, 22130, 8141, 294, 4583, 441, 337, 264, 309, 71, 2269, 11, 731, 613, 3212, 380, 9235], "temperature": 0.0, "avg_logprob": -0.18801972472551956, "compression_ratio": 1.6551724137931034, "no_speech_prob": 1.349700141872745e-06}, {"id": 1525, "seek": 800664, "start": 8006.64, "end": 8013.1, "text": " anymore, in the ith position in one axis and the jth position in another axis, is equal", "tokens": [3602, 11, 294, 264, 309, 71, 2535, 294, 472, 10298, 293, 264, 361, 392, 2535, 294, 1071, 10298, 11, 307, 2681], "temperature": 0.0, "avg_logprob": -0.1685099433450138, "compression_ratio": 1.7294117647058824, "no_speech_prob": 3.785303988479427e-06}, {"id": 1526, "seek": 800664, "start": 8013.1, "end": 8025.52, "text": " to my F matrix, so my flattened out matrix, for the ith channel in that layer versus the", "tokens": [281, 452, 479, 8141, 11, 370, 452, 24183, 292, 484, 8141, 11, 337, 264, 309, 71, 2269, 294, 300, 4583, 5717, 264], "temperature": 0.0, "avg_logprob": -0.1685099433450138, "compression_ratio": 1.7294117647058824, "no_speech_prob": 3.785303988479427e-06}, {"id": 1527, "seek": 800664, "start": 8025.52, "end": 8029.9400000000005, "text": " jth channel in the same layer.", "tokens": [361, 392, 2269, 294, 264, 912, 4583, 13], "temperature": 0.0, "avg_logprob": -0.1685099433450138, "compression_ratio": 1.7294117647058824, "no_speech_prob": 3.785303988479427e-06}, {"id": 1528, "seek": 800664, "start": 8029.9400000000005, "end": 8035.76, "text": " And then I'm going to sum over, so you see this k and this k, they're the same letter.", "tokens": [400, 550, 286, 478, 516, 281, 2408, 670, 11, 370, 291, 536, 341, 350, 293, 341, 350, 11, 436, 434, 264, 912, 5063, 13], "temperature": 0.0, "avg_logprob": -0.1685099433450138, "compression_ratio": 1.7294117647058824, "no_speech_prob": 3.785303988479427e-06}, {"id": 1529, "seek": 803576, "start": 8035.76, "end": 8040.84, "text": " So we're going to take the kth position and multiply them together and then add them all", "tokens": [407, 321, 434, 516, 281, 747, 264, 350, 392, 2535, 293, 12972, 552, 1214, 293, 550, 909, 552, 439], "temperature": 0.0, "avg_logprob": -0.1899961621573802, "compression_ratio": 1.5529953917050692, "no_speech_prob": 1.6028047866711859e-06}, {"id": 1530, "seek": 803576, "start": 8040.84, "end": 8041.84, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.1899961621573802, "compression_ratio": 1.5529953917050692, "no_speech_prob": 1.6028047866711859e-06}, {"id": 1531, "seek": 803576, "start": 8041.84, "end": 8046.4400000000005, "text": " So that's exactly what we just did before when we calculated our Gram matrix.", "tokens": [407, 300, 311, 2293, 437, 321, 445, 630, 949, 562, 321, 15598, 527, 22130, 8141, 13], "temperature": 0.0, "avg_logprob": -0.1899961621573802, "compression_ratio": 1.5529953917050692, "no_speech_prob": 1.6028047866711859e-06}, {"id": 1532, "seek": 803576, "start": 8046.4400000000005, "end": 8054.92, "text": " So like this, there's a lot going on because of some, to me, very neat notation.", "tokens": [407, 411, 341, 11, 456, 311, 257, 688, 516, 322, 570, 295, 512, 11, 281, 385, 11, 588, 10654, 24657, 13], "temperature": 0.0, "avg_logprob": -0.1899961621573802, "compression_ratio": 1.5529953917050692, "no_speech_prob": 1.6028047866711859e-06}, {"id": 1533, "seek": 803576, "start": 8054.92, "end": 8060.72, "text": " There are 3 implicit loops all going on at the same time, plus 1 explicit loop in the", "tokens": [821, 366, 805, 26947, 16121, 439, 516, 322, 412, 264, 912, 565, 11, 1804, 502, 13691, 6367, 294, 264], "temperature": 0.0, "avg_logprob": -0.1899961621573802, "compression_ratio": 1.5529953917050692, "no_speech_prob": 1.6028047866711859e-06}, {"id": 1534, "seek": 806072, "start": 8060.72, "end": 8067.04, "text": " sum, and then they all work together to create this Gram matrix for every layer.", "tokens": [2408, 11, 293, 550, 436, 439, 589, 1214, 281, 1884, 341, 22130, 8141, 337, 633, 4583, 13], "temperature": 0.0, "avg_logprob": -0.1419220424833752, "compression_ratio": 1.4342105263157894, "no_speech_prob": 7.889212611189578e-06}, {"id": 1535, "seek": 806072, "start": 8067.04, "end": 8078.08, "text": " So let's go back and see if you can match this.", "tokens": [407, 718, 311, 352, 646, 293, 536, 498, 291, 393, 2995, 341, 13], "temperature": 0.0, "avg_logprob": -0.1419220424833752, "compression_ratio": 1.4342105263157894, "no_speech_prob": 7.889212611189578e-06}, {"id": 1536, "seek": 806072, "start": 8078.08, "end": 8085.360000000001, "text": " So all that's kind of happening all at once, which I think is pretty great.", "tokens": [407, 439, 300, 311, 733, 295, 2737, 439, 412, 1564, 11, 597, 286, 519, 307, 1238, 869, 13], "temperature": 0.0, "avg_logprob": -0.1419220424833752, "compression_ratio": 1.4342105263157894, "no_speech_prob": 7.889212611189578e-06}, {"id": 1537, "seek": 806072, "start": 8085.360000000001, "end": 8087.1, "text": " So that's it.", "tokens": [407, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.1419220424833752, "compression_ratio": 1.4342105263157894, "no_speech_prob": 7.889212611189578e-06}, {"id": 1538, "seek": 808710, "start": 8087.1, "end": 8092.280000000001, "text": " So next week we're going to be looking at a very similar approach, basically doing style", "tokens": [407, 958, 1243, 321, 434, 516, 281, 312, 1237, 412, 257, 588, 2531, 3109, 11, 1936, 884, 3758], "temperature": 0.0, "avg_logprob": -0.12798640841529482, "compression_ratio": 1.6720647773279351, "no_speech_prob": 1.520644855190767e-05}, {"id": 1539, "seek": 808710, "start": 8092.280000000001, "end": 8097.08, "text": " transfer all over again, but in a way where we're actually going to train a neural network", "tokens": [5003, 439, 670, 797, 11, 457, 294, 257, 636, 689, 321, 434, 767, 516, 281, 3847, 257, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.12798640841529482, "compression_ratio": 1.6720647773279351, "no_speech_prob": 1.520644855190767e-05}, {"id": 1540, "seek": 808710, "start": 8097.08, "end": 8100.52, "text": " to do it for us, rather than having to do the optimization.", "tokens": [281, 360, 309, 337, 505, 11, 2831, 813, 1419, 281, 360, 264, 19618, 13], "temperature": 0.0, "avg_logprob": -0.12798640841529482, "compression_ratio": 1.6720647773279351, "no_speech_prob": 1.520644855190767e-05}, {"id": 1541, "seek": 808710, "start": 8100.52, "end": 8105.04, "text": " We'll also see that you can do the same thing to do super resolution.", "tokens": [492, 603, 611, 536, 300, 291, 393, 360, 264, 912, 551, 281, 360, 1687, 8669, 13], "temperature": 0.0, "avg_logprob": -0.12798640841529482, "compression_ratio": 1.6720647773279351, "no_speech_prob": 1.520644855190767e-05}, {"id": 1542, "seek": 808710, "start": 8105.04, "end": 8113.200000000001, "text": " And we're also going to go back and revisit some of that SSD stuff, as well as doing some", "tokens": [400, 321, 434, 611, 516, 281, 352, 646, 293, 32676, 512, 295, 300, 30262, 1507, 11, 382, 731, 382, 884, 512], "temperature": 0.0, "avg_logprob": -0.12798640841529482, "compression_ratio": 1.6720647773279351, "no_speech_prob": 1.520644855190767e-05}, {"id": 1543, "seek": 808710, "start": 8113.200000000001, "end": 8115.360000000001, "text": " segmentation.", "tokens": [9469, 399, 13], "temperature": 0.0, "avg_logprob": -0.12798640841529482, "compression_ratio": 1.6720647773279351, "no_speech_prob": 1.520644855190767e-05}, {"id": 1544, "seek": 811536, "start": 8115.36, "end": 8122.24, "text": " So if you've forgotten SSD, it might be worth doing a little bit of revision this week.", "tokens": [407, 498, 291, 600, 11832, 30262, 11, 309, 1062, 312, 3163, 884, 257, 707, 857, 295, 34218, 341, 1243, 13], "temperature": 0.0, "avg_logprob": -0.2248829205830892, "compression_ratio": 1.180952380952381, "no_speech_prob": 2.3550839614472352e-05}, {"id": 1545, "seek": 812224, "start": 8122.24, "end": 8149.28, "text": " Thanks everybody, see you next week.", "tokens": [50364, 2561, 2201, 11, 536, 291, 958, 1243, 13, 51716], "temperature": 0.0, "avg_logprob": -0.5349862792275168, "compression_ratio": 0.8181818181818182, "no_speech_prob": 0.00013769023644272238}], "language": "en"}