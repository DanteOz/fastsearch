{"text": " Hi everybody. Today we are covering lesson 23 and we're here with Jono and Tanishq. How are you guys both doing? Doing well. Excited for another lecture, another lesson. Yeah, likewise. Great. I shamefully have to start with admitting to a bug, which actually is rather, well, I don't know, it kind of messed up things in a sense, but I kind of, I think it's really interesting actually what happened. The bug, it was in notebook 23, the Keras notebook, and it's about the measure, measuring the FID. So to recall, FID measures how similar a bunch of samples are from a model to a bunch of samples of real images. And that similarity is defined in this kind of like, some kind of distance between the distributions of the features in a classifier or some kind of model. So that means that to get FID, we have to load a model and we have to pass it some data loaders so that it can calculate what the samples look like from real images. Now the problem is that the data loaders I was passing actually had images that the pixels were between negative 0.5 and positive 0.5. But you might recall this model that I trained has pixels between negative 1 and 1. So what this image eval class would have seen, and specifically this C model which we are getting the features from, is it would have seen a whole bunch of unusually low contrast images. So they wouldn't really have looked like many things in the data set, because in fact in the data set I think, particularly for fashion MNIST, things are pretty consistently, you know, normalized in terms of going all the way from 0 to 1 or negative 1 to 1, I guess 0 to 2.5 in the original. And so as a result, I think what would have happened is that the features that came out of this would have been kind of weird. And they might not have necessarily consistently said, oh, these are T-shirt features and these are shoe features, but they would have said, oh, this is a weird low contrast image feature. And so then the shame continues in that I added another bug on top of this bug, which is when I then did the sampling, I didn't, I didn't multiply by 2, and the data that I trained it on was actually the same data loaders, or specifically the same transform, the same Noisify transform. Well where did that come from? It's the same, yeah, the same transform I, not Noisify, the same transform I, which, yeah, previously was from negative 0.5 to 0.5. So I trained the model using this restricted input space as well. And therefore it was spitting out things that were between negative 0.5 and 0.5. And so the FID then said, wow, these are so similar. The samples are consistently spitting out features of low contrast things, and all of the real samples are low contrast things. So those are really similar. And that's how we got really low numbers. So those low numbers were wrong. So I was a bit surprised, I guess, that the Keras model was doing so much better. And it certainly, it made me a big believer in the Keras model. But actually it's not doing so much better. So once we fix that, the FIDs are actually around 5, 6, 5, and the reals are 2.5. So to compare, we were getting some pretty good results in cosine. So cosine, yeah, we were getting 3 to 4, depending on how many steps we were doing DDIM. So the result of this is that this, this somewhat odd situation where the cosine model, where we scaled it accidentally to be negative 0.5 to 0.5, and then post-sampling multiplied by 2, so we're not cheating, like the Keras one used to be, is working better than Keras, which, yeah, is a surprise to me. Because I was thinking Keras was kind of like, in theory, optimally scaling things. But I guess the truth is, it was scaling things to unit variance, but there's nothing particularly to say that's optimally scaling things. And so empirically, we've found kind of accidentally a better way to scale things. And also our dependent variable is different. You know, our dependent variable is not that Keras, you know, C mix combination, but our dependent variable is just the noise, the 0, 1 noise, you know, the noise before it's multiplied by alpha bar. Okay, so that's, that's the bug. Anyway, I promised last time we would stop looking at fashion MNIST for a while. So let's move on to tiny image net. So, and the reason we're going to do this is because we want to, I want to show an example of, we're going to try and create units today. And I wanted to show an example of a nice unit we can create that combines a lot of the ideas we've been looking at. It's going to be a super resolution unit. And doing super resolution on fashion MNIST isn't going to be very interesting because the maximum training size we have is 28 by 28. So, so I thought we'd go a little bit bigger than that to tiny image net, which is 64 by 64. I found it quite difficult actually to find tiny image net data, but eventually I discovered that it's still on the Stanford servers where it was originally created. It's just not linked to anywhere. So we'll try to, if this disappears, we will, we will keep our forum and website up to date with other places to find it. Anyway, so for now we can grab the URL from there and unpack it. So shutil is a very handy little library inside the Python standard library. And one of the things it has is a very handy unpack archive, so it can handle zip files and it's going to put it in our data directory. So I, yeah, just, you know, there's a few different ways we could process this. And I thought we might experiment with some things, but I thought, yeah, it wouldn't be a bad idea to try doing things the reasonably kind of manual way, just to see, you know, what that looks like. Often this is the easiest way to do things because, you know, that's a very well-defined set of steps, right? So step one is to create a dataset. So a dataset is just literally something that has a length and that you can index into it. So it has to have these two things defined. You don't have to inherit from anything. You just have to define these two things. Broadly speaking in Python, you generally don't have to inherit from things. You just have to provide the methods that are expected. So our dataset is in a directory called tiny-image-net-200. And then there's a train directory and a val directory for the training and the validation set. And then the train directory, this is pretty classic, normal thing. Each category, so this is a category, has images in a separate folder and specifically they're in images subfolder. So what I wanted to do was to just grab, start with, grab all of the files in path slash train, all the image files. So the Python standard library has a glob function, which searches recursively if asked to, for everything that matches this, well, this specification. So this specification is path slash star dot jpeg. And then this star star here, I don't know why we need to do it twice. It's a bit weird. You also need that to be recursive. So to be recursive, you both have to say recursive true here and also put star star before the slash here. So that's going to give us a list of all files inside path train. And so then if we index into that training dataset with zero, that will call get item, passing an i of zero. And so we will then return a tuple. One is the thing in self.files.i, which is this file, and then the label for it. And the label is that. So it's the parents, parents, name, parents, parents, name. And so that's the name. Okay. So there's a data set that returns two strings when you index into it, a tuple of two strings. The first is the name of the image file, so the path of the image file. And the second is the name of the category it's in. These weird names are called WordNet categories. They're like codes that indicate concepts, basically, in English. So one of the reasons I actually used this particular dataset is because it's going to force us to do some more data processing, which I think is good practice. And that's because weirdly, in the validation set, although it's in tiny image net 200 slash val, which is the not weird part, the weird part is that they are not then in subdirectories organized by label. Instead, there is a separate val annotations.txt file, which looks like this. So it says to each file name, what category is it? It's also got the bounding box of whereabouts that is, but we're not going to be using that today. So I decided to create a dictionary that would tell us for each file, what category is it in? So that means that I want to create a, in this case here, I'm doing something exactly like a list comprehension, but because it's not in square brackets, it's a generator comprehension. So it'll generate, it'll kind of stream out the results. And we're going to go through each line in this file. And we're going to split on tab. So that's going to give us this, and then this, and then this, and then we're going to grab the first two. And if you basically pass a list of lists or list of tuples or whatever to dict, it will create a dictionary using these pairs as key values. So if we have a look, there it is. So that's quite a nice, neat way to do it. And if you're not sure, you can just click type dict, type open brackets, and then hit shift tab a couple of times, and it'll show you the various options. And you can see here, I'm doing dict iterable because my generator is iterable. And it says, oh, that's exactly as if you created a dictionary and then gone for kv in iterable dk equals v. So there's a nice little trick. Okay, now we need a data set that works just like tiny data set, but the get items are going to label things differently. So I just inherited from tiny data set. So that means we don't need to do init or len again. And then get item again, it's going to turn the ith file. This time, the label will not be the parent, parent name, but we will look up in the annotations dictionary, the name of the file. And so that works. We can check the length works. So then a fairly generally useful thing that I thought we'll then create is something that lets us transform any data set. So here's a class that you can pass it a data set, and you can pass it a transformation for the x or the independent variable, and you can pass it a transformation for the y. And both of them default to no op, that is no operation, so it just doesn't change it at all. So a transform data set, the length of it is just the length of the original data set. So it's just a transform data set. But when we call get item, it'll grab the tuple from the data set we passed in, and it will return that tuple, but with transform x and transform y applied to it. Does that make sense so far? Great. Okay. So I don't like working with these n030 things, but the data set luckily has a WordNet IDs file in it. So if I just open it up, oh sorry, this one actually is not quite going to help us. This is just a list of all of the WordNet IDs that they have images for. We could have actually got this by simply grabbing, by listing this directory, it would have told us all the IDs, but they've got, they've also got just a, the text file containing all of them. So we can see that there are 200 categories. Okay. And that's useful because we're going to want to change n030 etc into an int. And the way we can change it into an int is by simply saying, oh, we'll call, we'll call this one zero and this one one and so forth. Right. So the kind of the int to string or ID to string version of this is literally this list. So zero will be that, that, but the string to int version, we do this all the time, is basically enumerate. So that gives us the index and the value for everything in the list. So those are going to be our keys and values, but actually we're going to invert it to become value colon key. And that's what str2id will be. So note here that we have a dictionary comprehension. You can tell because it's got curly brackets and a colon. And so here's our dictionary comprehension. So we could have used that for this as well. We could have done a dictionary comprehension instead, but yeah. So there's lots of ways of doing things. None of them is any better or worse than any other. Okay. So that's something that... Is the, those wordnet tags or whatever, do we have the names for them or is that something external that we have to get? Yes. The names I'm going to get to. Yes, shortly. There's a word.text. So, yeah. All right. I grabbed one batch of data and grabbed its mean and standard deviation. And so then I've just copied and pasted them in here for normalizing. So my, my transform X is going to be, I'm going to read the image. If you read it as RGB, that's going to force it to be three channels, because actually some of them are only one channel. Divide it by 255. So it'd be between zero and one. And then we will normalize. And then for our Ys, we will go through strd id to get the ID and just use that as our tensor. So it's, you know, doing it manually is actually pretty straightforward, right? Because now we just pass those to our TwfmDS, our transformed data set. And we can check that, you know, you can see YI is a tensor, but we can look it up to get its value. And Xi is an image tensor with three channels. So channel by height by width has its normal for PyTorch. So for showing images, it's nice to denormalize them. So that's just denormalizing. And so if we show the image that we just grabbed, it's a water jug, I guess. All right, so now we can create a data loader for our training set. So that's going to contain our transformed training data set, and pass in a batch size. This one has to be shuffled. Not sure where I put numWorkers equals zero there. Generally eight's pretty good, if you've got at least eight cores. Yeah, so we can now grab an X batch and a Y batch, and take a look at a denormalized image from there. So there we've got a nice little kitty cat. So I think this is already looking better than Fashion MNIST. Yeah, so there's this thing, words.text, that they've also provided. And this is actually a list of the entire WordNet hierarchy. So the top of the hierarchy is entity, and one of the entity types is a physical entity, or an abstract entity. Entities can be things, and so forth. So this is how WordNet is, yeah, handled. So this is quite a big file actually. So if we go through each item of that file, and again split on tabs, because split on tabs, that's what backslash t means, is going to give us the WordNet ID, and then the name of it. So now we can go through all of those. They call them sinsets. And if the key is in our list of the 200 that we want, we'll keep it. And we don't really want like causal agent, comma, cause, comma, causal agency. The first one generally seems to be the most normal. So I just split on comma, split on comma, and grab the first one. All right, so that's, so we could then go through our y-batch, and just turn each of those numbers into strings, and then look at each of those up in our sinsets, and join them up, and then use those as titles to see our Egyptian cat, and our cliff, and our guacamole, it's a monarch butterfly, and so forth. And you can see that this is going to be quite tricky, because like a cliff versus a cliff dwelling, for instance, could be quite, you know, complicated. I have a feeling for this, they intentionally, like a hundred of the categories might have come from the normal ImageNet, and I think they might have then picked a hundred that are designed to be particularly difficult, or something, if memory serves correctly. All right, so then we could define a transform batch function, with the same basic idea. And that's just gonna, yeah, transform the x and the y in a batch. Oh yes, we're about to use that, I should move that down a bit, because we're not quite there yet. Okay, so before that, we can create our data loaders. We created a getDls back in an earlier lesson, which simply turns that into a data loader, and that into a data loader, and this one gets shuffled, and that one doesn't, and so forth. Oh, I see, this is where we do our numWorkers. Cool. All right, so then, oh yeah, so then we want to add our data augmentation. So I noticed that training a tiny ImageNet model, I mean, it's a much harder thing to do than fashion MNIST, and overfitting was actually a real challenge. And I guess it's because 64 by 64 isn't that many pixels. So yeah, so I found I really needed data augmentation to make much progress at all. Now, very common data augmentation is called random resize crop, which is basically to pick one area inside, and zoom into it, and make that your image. But for such low resolution images, that tends to work really poorly, because it's going to introduce a lot of blurring artifacts. So instead, for small images, I think it's better to add a bit of padding around them, and then randomly pick a 64 by 64 area from that padded area. So it's just going to be a 64 by 64 area from that padded area. So it's just going to shift them slightly. It's not a lot of augmentation, but it's something. And then we do our random horizontal flips, and then we'll use that random erase thing that we created earlier. This is just something I was experimenting with. So yeah, so now we can use that batch transform callback, using transform batch, passing in those transforms. So with torch vision transforms, so this capital T is torch vision transforms. Yeah, because these are all nn.modules, you can pass them to nn.sequential, to just have each of them called one at a time, in a row. There's nothing magic about this, it's just doing function composition. We could easily create our own. In fact, there's also the transforms.compose, that does the same thing. Yeah, I was going to say, so we've got a fast, fastcore.compose, which as you can see, basically it just says for f in funcs, x equals f of x. Yeah, I don't know, is there, is there's a, yeah torch, torch vision compose, I think might be kind of the old way to do it. Is that right? I'm not sure. I have a feeling maybe this is considered the better way now, because it's kind of scriptable. I'm not promising that though. But yeah, it does basically the same thing. Okay, so yeah, we can now create a model as usual. Okay, so basically I copied the get model with dropout, get drop model from our earlier tiny, sorry, our earlier fashion MNIST stuff. And I, yeah, started with kernel size five convolution, and then yeah, a bunch of res blocks. Yeah, so this is all what we're used to seeing before. And so we can take a look in this case, as it's quite often seems to be the case, we accidentally end up with no random erasing. Let's just run it again. Really doesn't want to do random erasing. Here we go. So we can see it. So yeah, there's this very small border you can hardly see sometimes, and a bit of random erasing. And it's been done, you know, all of the batch is being transformed, or augmented in the same way, which is kind of okay. It's certainly faster. It can be a bit of a problem if you have like one batch that has lots and lots and lots of augmentation being done to it. And it could be like really hard to recognize. And that could cause the loss to be a lot in that batch. And if you're like been training for ages, that could kind of jump you out of the, you know, the smooth part of the loss surface. That's the one downside of this. So I'm not going to say it's always a good idea to do augmentation at batch level, but it can certainly speed things up a lot if you don't have heaps of CPUs. All right, so you can use that summary thing we created. There's our model. And yeah, because we're increasing the, doubling the number of channels as we're decreasing the grid size, our number of megaflops per layer is constant. So that's a pretty good sign that we're using compute throughout. So yeah, then we can train it with AdamW, mixed precision, and our augmentations. So I then did the learning rate finder, and trained it for 25 epochs, and got a nearly 60 percent, 59 percent. And yeah, this took quite a while actually to get close to 60%, I've got to admit. And you can see that the training sets are already up to 91, so we're kind of on the verge of overfitting. Overfitting. Okay, so then I thought, all right, how do we do better? And I wanted to have a sense of like, how much better could we get? And I kind of tend to like to look at papers with code, which is a site that shows papers with their code. And also like, how good a results did they get? So this is the image classification on TinyImageNet. And at first I was like, pretty disheartened to see all these like, 90 percent plus things. But as I looked at the papers, I realized something. Well, the first thing is I noticed that these ticks here represent extra training data. So these are actually pre-trained models that are only fine-tuned on TinyImageNet. So that's a total cheater. And then I looked more closely at this one, and actually these are also using pre-trained data, so papers with code is actually incorrect. And so the first ones I could see which I could clearly kind of replicate and make sense of was this one. So the highest one that I'm confident of is this 72 percent. And so then I kind of wanted to get a sense of, all right, how, you know, how much work is there to get from like 60 percent to 70 percent, and how good is this? So I opened up the paper. And so here's TinyImageNet. And they've got like, basically this paper turns out to be about a new type of mix-up data augmentation. This is the normal kind of mix-up, and this is their special kind of mix-up. And on a ResNet-18, yeah, I see they're getting like 63, 64, 65 with various different types of mix-up, and kind of 64 or 65 for their special one. And then if they use much bigger models than we're using, they can get up to 66-ish. So that kind of made me think, okay, this classifier is not bad, but there's clearly room to improve it. And I can't help myself, I always have to try to do better. So this is a good opportunity to learn about a trick that is used in real ResNets, which is in a real ResNet, we don't just say how many filters or channels or activations per layer, and then just go through and do a, you know, stride to conv each time. But instead, you can also say the number of ResBlocks per kind of downsampling layer. So this would say do three ResBlocks, and you know, then downsample, or downsample, and then do three ResBlocks, or something like that, or do three ResBlocks, the first of which, or the last of which is a downsample, and then two ResBlocks with a downsample, and then two ResBlocks with a downsample. So this has got a total of one, two, three, four, five downsamples, but it's got, rather than having one, two, three, four, five ResBlocks, it's going to have three, four, five, six, seven, eight, nine ResBlocks. So it's nearly twice as deep. And so the way we do that is we just replace the places it was saying ResBlock with Res underscore blocks. And that's just a sequential, which goes through the number of blocks and creates a ResBlock. And you can do it a couple of ways. In this case, I said if it's the last one, then make it stride two, otherwise stride one. So it's going to be downsampling at the end of each set of ResBlocks. So that's the only thing I changed. I changed ResBlock to ResBlocks and passed in the number of blocks, which is this. Okay, so the number of megaflops is now 710-ish, which is more than double, right? So should have more opportunity to learn stuff, which also could be more opportunity to overfit. So again, we do our LRFind. And yeah, so I just did 25 epochs, and I didn't actually add more augmentation. Okay, and that got up to nearly 62. So that was a good improvement. And you know, interestingly, it's not overfitting more. It's actually, if anything, less, which, you know, there's something about its ability to actually learn this, which is slowing it down or something. So I thought, yeah, it'd be nice to train it for longer. So I decided to add more augmentation. And to do that, I decided to use something called trivial augment, which is not a very well-known approach, but it deserves to be. And it comes from Frank Hutter's lab. Frank Hutter is somebody who consistently creates extremely practical, useful improvements, with much less of the nonsense that we often see from some of the huge, well-funded labs. And so this one's kind of a bit of a reaction to some previous approaches, such as one called auto-augmentation, which is a very, very simple approach. One called rand-augment. They might have both come from Google Brain. I'm not quite sure. Where they kind of used lots of, like, you know, many, many thousands of TPU hours to, like, optimize how every image is, you know, or how each set of images is augmented. And yeah, what these guys did is they said, well, what if we don't do that, but we just randomly pick a different augmentation for each image. And that's what they did. They just said, algorithm one, here's the procedure. Pick an augmentation. Pick an amount. Do it. I feel like they're almost kind of, like, trying to make a point about writing this algorithm here. Yeah. And they basically find this is at least as good or often better, actually, than the incredibly resource-intensive ones. The incredibly resource-intensive ones also kind of require a different version for every data set, which is why they describe this as tuning-free. So rather nicely, and surprisingly for me, it's actually built into PyTorch. So if we go to PyTorch's website and go to trivial augment wide, yeah, they show you some examples of trivial augment wide. We can create our own as well. Now, the thing is, I found that doing this at a batch level worked poorly. And I think the reason is what I described earlier. I think sometimes it will pick a really challenging augmentation to see, you know, and it all totally, like, mess up the loss function. And if every single image in the batch is like that, then it'll shoot it off into the distant parts of the weight area. Which is a good excuse for me to show how to do augmentations on a per item level. Now, these actually require, or some of them require, having a PIL image, the Python imaging library image, not a tensor. So I had to change things around. So we have to import image from PIL. And we have to change our tiffmx now. And we're going to do the augmentations in there instead for the training set. So for the training set, we're going to, in fact, for both. So we're going to pass in something, it's just, do you want to do augmentations? So for the training set, we're going to pass aug equals true. And for the validation set, we won't. So, yeah, so image.open is how you create a PIL image object. And then if we wanted augmentations, then do these augmentations. And then convert it into a tensor. So torch vision has a dot to tensor we can then call. And then we can normalize it. And actually, I decided just to use torch visions normalize. I mean, either is fine, or this one works well. And then again, if you want augmentation, then do your round arrays. And if you remember, our round arrays was designed to kind of use 0, 1 distributed Gaussian noise. So you want that to happen after normalization. So that's why I do it in this order. So yeah, so now we don't need to use the batch triffim thing. We're just doing it all directly in the data set. So you can see, you know, you can do data augmentation in very simple ways without almost any framework help here. In fact, we're really not, we're not doing any, nothing's coming from a framework really. It's just, yeah, it's just this little triffim DS we made. And so now, yeah, we just pass that into our data loaders, getDLs. And we don't need any augmentation callback. All right. So now we can keep improving things by doing something called pre-activation ResNets. So if we go back to our original ResNet, you might recall that the way we did it, we have this conv block, which consists two convolutions in a row. The second one has no activation. And to remind you what conv is, is that we first of all do a conv, and then optionally we do a normalization, and then optionally we do our activation function. So we end up, and then the second of those has act equals none. So basically what this is saying is go convolution, norm activation, convolution norm. That's what self.cons is. And then this is the identity path. So this does nothing at all, if there's no downsampling or no change of channels. And then we apply the activation function, the final activation function, to the whole thing. So that was how the original ResBlock was designed, which is kind of a bit of an accident, because I, to be honest, when I wrote that I didn't bother looking at the paper. I just did whatever seemed reasonable in my head. But yeah, then looking into it further, I looked at this slightly later paper by the same author as of the ResNet paper, Kaiming He. And Kaiming He drew, you know, this version here on the left. As you can see, it's conv norm relu, conv norm add relu. And yeah, he basically pointed out, yeah, you know what, maybe that's not great, because the relu is being applied to the addition. So there isn't actually really an identity path at all. So wouldn't it be nice if we could have a pure identity path? And so to do that, he proposed reordering things to go norm relu conv, norm relu conv add. And so this is called a preact, or preactivation ResBlock. So that means I had to redefine conv to do norm, then act, and then conv. So my sequential now has the activation in both places. And so yeah, other than that, oh, and then of course, there's no activation happening in the ResBlock, because it's all happening in the cons. Does that make sense? Yeah, it makes sense. Yeah. Cool. So this is now the same, this is exactly the same, except we now need to have an activation and a batch norm after all those blocks, because previously it finished with a norm and an activation. Now it starts with them. So we have to put these at the end. It also means we can't start with a ResBlock anymore, because if we started with a ResBlock, then it would have an activation function at the start, which would throw away half of our data, which would be a bad idea. So you've got to be a bit careful with some of the details. But yeah, so now you can see that each image is getting its own augmentation. And so this one's been sheared, looks like it's a door or something, because it's very hard to tell what the hell it is. It's been sheared. This one's been moved. It looks like this one's also been sheared. And you can also see they've got different amounts of rand arrays on them. So yeah, so I thought I'd try training that for 50 epochs. And that got us to 65%, which is, you know, as good as, nearly as good as the, you know, normal mix-up things that we're getting even on a ResNet-50s. This is looking really good. So I won't spend time on this, but I'll just mention I was kind of curious, like, I mean, one of the things I should mention also is they trained all these for 400 epochs. So I was kind of curious what would happen if we trained it a bit longer. I wasn't patient enough to train it for 400 epochs, but I thought I could do 200 epochs. So I just duplicated that last one, but made it 200 epochs. And that got us to 67.5, which, yeah, is better than any of their non-special mix-ups. So I think it just goes to show you can get, you know, genuinely state-of-the-art results. So if we use their special mix-up, that would be interesting to try as well, see if we can match their results there. But, you know, we've built all this from scratch. We didn't do the data augmentation from scratch because it's not very interesting. But yeah, other than that, so I think that's really cool. So I know that you did some other experiments with the pre-activation. Oh, right. Yeah. Right. When I saw the pre-activation success, I was quite enthusiastic about it. So I actually thought like, oh, maybe I should go back and actually use it everywhere. But weirdly enough, I think it's weird, like it was worse for fashion MNIST and worse for like less data augmentation. I mean, maybe it's not that weird, but because the idea of when He et al introduced it, they said this is to train deeper models. You know, there's a more pure identity path. And so with that more pure identity path, that should kind of let the gradients flow through it more easily. And so there should be a smoother surface, weight surface, loss surface. So yeah, I guess it makes sense that you don't really see the benefits on less deep models. The bit I'm surprised- Could you elaborate? Because like, it seems like that should be, that sort of justification should be true for smaller models, right? Or- Well, yeah, it does, but smaller models are going to have a less bumpy surface anyway. They've just got less dimensions to be bumpy on, and there's less, more importantly, they're less deep. So there's less room for gradients to explode exponentially. So they're not as sensitive. But yeah, I mean, I can see why they don't necessarily help as much, but I don't have any idea why they were worse. And they were quite consistent, worse. And they were quite consistently worse. Yeah. Yeah. I find it quite interesting too. Yeah. Yeah. Yeah. It's quite curious. And it's interesting that when we do these like experiments on things that nowadays are considered pretty fundamental and foundational, where you kind of all the time discover things that nobody seems to have noticed or written about, or there's plenty of room to, as a kind of a more experimental researcher to do experiments and then go like, oh, that's interesting. And then try and figure out what's going on. Yeah. I think a lot of researchers go in the opposite direction and they try to start with like theoretical assumptions and then test them. When I think about it, I feel like maybe a lot of the more successful folks in terms of people who build stuff that actually get used are more experimental first, maybe. Okay. So, shall we have a five minute break since we're kind of on the hour? Sure. All right. So let's now look at notebook 25, super res. I've just copied a few things from the previous notebook, some transforms and our data sets and our denorm and our Triffim batch and our Triffim X. I'm not sure we're using Triffim batch here. We're not even using Triffim batch. Let's get rid of that because that's just confusing. Okay. So it looks like we're doing the per, let's figure this out. So what are we doing here? So we've got, what are our two data sets? All right. So the goal of this is we're going to do super resolution, not classification. So let's talk about what that means. What we're going to do is the independent variable will be scaled down to a 32 by 32 pixel image and the dependent variable will be the original image. And so to do random crop within a padded image and random flips, both the independent and the dependent variable needs to have had exactly the same random cropping and exactly the same flipping. Otherwise, it can't say, oh, this is how you do super res to go from the 32 by 32 to the 64 by 64. Because it might be like, oh, it has to be flipped around and moved around. So yes, so for this kind of image reconstruction task, it's important to make sure that your augmentation is done the same way on the independent and the dependent variable. So that's why we've put it into our data set. And so this is something people often get confused about and they don't know how to do it. But it's actually pretty straightforward if we do it this way. We just put it straight in the data set. And it doesn't require any framework fanciness. Now, then what I did do is I then added random erasing just to the training set. And the reason for that is I wanted to make the super resolution task a bit more difficult. Which means sometimes it doesn't just do super resolution, but it also has to like replace some of the deleted pixels with proper pixels. And so it gives it a little bit more to do, you know, which can be quite helpful. It's kind of, it's a data augmentation technique and also something to give it like more of an opportunity to learn what the pictures really look like. Okay, so with that in case that, so these are going to do the padding, random cropping, and flipping. The training set will also add random erasing. And then we create data loaders from those. Would it make sense to use the trivial augment here? The trivial augment, did you say? Yeah. Maybe. Yeah, I don't particularly see a reason not to. If, well, only if you found that overfitting was a problem. And if you did do it, you would do it to both independent and dependent variables. So yeah, here you can see an example of the independent variables. Some of the, in this case, all of them actually have some random arrays. The dependent doesn't. So it has to figure out how to replace that with that. And you can also see that this is very blocky. And this is less blocky. That's because this has been gone down to 32 by 32 pixels. And this one's still at the 64 by 64. So in fact, once you go down that far, the cat's lost its eyes entirely. So it's going to be quite challenging. It's lost its lines entirely. So super resolution is quite a good task to try to get a model to learn what pictures look like. Because it has to, yeah, figure out like how to draw an eye, and how to draw cat's whiskers, and things like that. Were you going to say something, Jono? Sorry. JONO GRANTHAM Oh, I was just going to point out that the datasets are also simpler because you don't have to load the labels. So there's no difference between the train and the validation. Now it's just finding all the images. SIMON RIGGEDALL Good point. Yeah. Because the label, you know, is actually a dependent variable, is just the picture. And so, okay, so because TwfmDS has a TwfmX, which is only applied to the independent variable, the independent variable has applied to it this pair of resize to 32 by 32, and then interpolate. And what that actually does is it ends up still with a 64 by 64 image, but the pixels in that image are all like doubled up. And so that means that it's still doing super resolution, but it's not actually going from 32 by 32 to 64 by 64. But it's just going from the 64 by 64, where all of the pixels are like two by two pixels. And it's just a little bit easier, because that way, we could certainly create a unit that goes from 32 to 64. But if you have the input and output image the same size, it can make code a little bit simpler. I originally started doing it by not doing this interpolate thing. And then I decided I was just getting a little bit confusing. And there's no reason not to do it this way, frankly. Okay, so that's our task. And the idea is that then, if it does a good job of this, you know, you could pass 64 by 64 images into it, and hopefully it might turn them into 128 by 128 images. Particularly if you trained it on a few different resolutions, you'd expect it to get pretty good at, you know, resizing things to a bunch of different resolutions. You could even call it multiple times. But anyway, for this, I was just kind of doing it to demonstrate. But we have in previous courses trained, you know, bigger ones for longer with larger images. And they actually do one of the interesting things is they tend to not only do super resolution, but they often make the images look better. Because the kind of the pixels it fills in, it kind of fills in with like, what that image looks like on average, which tends to kind of like average out imperfections. So often these super resolution models actually improve image quality as well, funnily enough. Okay, so let's consider the dumb way to do things. We've seen a kind of a dumb way to do things before, which is an autoencoder. So go in with low expectations here, because we've done an autoencoder before. And it was so bad, it actually inspired us to create the learner, if you remember. So that was back in notebook 8. And so basically, what we're going to do is we're going to have a model which looks a lot like previous models. It starts with a res block kernel size 5. And then it's got a bunch of res blocks of stride 2. But then we're going to have an equal number of up blocks. And what an up block is going to do, is it's going to sequentially, first of all, it's going to do an up sampling nearest 2d, which is actually identical to this. Right, so it's going to just double all the pixels. And then we're going to pass that through a res block. So it's basically a res block with like a stride of a half, if you like. You know, it's undoing a stride 2. It's up sampling rather than down sampling. Okay, so and then we'll have an extra res block at the end to get it down to three channels, which is what we need. Okay, so we can do our learning rate finder on that. And I just train it pretty briefly for five epochs. So this model is basically trying to take the image that we start up, then kind of really squeeze it into, I guess, a small representation. And then try to bring that small representation back up to then the full super resolution image. Is that correct? Exactly right, Tanishka. And we could have done it without any of the stride 2. You know, I guess we could have just had a whole bunch of stride 1 layers. There's a few reasons not to do it that way though. One is obviously just the computation requirements are very high, because the convolution has to scan over the image. And so when you keep it at 64 by 64, that's a lot of scanning. Another is that you're never kind of forcing it to learn higher level abstractions by recognizing how to kind of like, you know, use more channels on a smaller grid size to represent it. So yeah, it's like the same reason that we, in classifiers, we don't leave it at stride 1 the whole time. You know, you end up with something that's inefficient and generally not as good. Exactly, yep. Thanks for clarifying, Tanishka. Okay, so the loss goes down. And the loss function I'm using is just mse here, right? So it's how similar is each pixel to the pixel it's meant to be. And so then I can call capture preds to get the predictions and the targets and the inputs, or probabilities, targets and inputs. I can't quite remember now. So here's our input images. So they're pretty low resolution. And oh dear, here's our predicted images. So pretty terrible. So why is that? Well, basically, it's kind of like the problem we had with our earlier auto encoder. It's really difficult to go from like a 2 by 2 or 4 by 4 or whatever image into a 64 by 64 image, you know. We're asking it to do something that's just really challenging. And so that would require a much bigger model trained for a much longer amount of time. I'm sure it's possible. And in fact, you know, latent diffusion, as we've talked about, has a model that kind of does exactly that. But in our case, there's no need to make it so complicated. We can actually do something dramatically easier, which is we can create a a UNet. So UNets were originally developed in 2015. And they were originally developed for medical imaging. But they've been used very, very widely since. And I was involved in medical imaging at the time they came out. And certainly they quite quickly got recognized in medical imaging. They took a little bit longer to get recognized elsewhere. But nowadays, they're pretty universal. And they are used in stable diffusion. And basically, some of the details don't matter here. This is like the original paper. So let's focus on the kind of the broad idea. This thing here is called the, we're going to call it the downsampling path. So in this case, they started with 572 by 572 images. And it looks like they started with one channel images. And then they, you know, as we've seen, then they took them down to 284 by 284 by 128. And then down to 140 by 140 by 256. And then down to 68 by 68 by 512. 32 by 32 by 1024. So here's this downsampling path. And then the upsampling path is exactly what we've seen before. Right. So we upsample and have some, I mean, in the original thing, they didn't use resnets or resblocks. They just use convs. So the idea is the same. But the trick is these extra things across here, these arrows, which is copy and crop. What we can do is we can take, so during the upsampling, we've got a 512 by 512 here. Sorry, a 512 channel thing here. We can upsample to a 512 channel thing. We can then put it through a conv to make it into a 256 channel thing. And then what we can do is we can copy across the activations from here. Now they actually do things in a slightly weird way. They had 136 pixels by 136. And over here they have 104 by 104. That's because of the slightly weird way they basically weren't padding things. Nowadays we don't have to worry about that cropping. So we copy over these activations. And we then either concatenate or add. And you can see in this case they're concatenating. See how there's the white bit and the blue bit? So they have concatenated the two lots together. So actually I think what they did here is they went from a 52 by 52 by 512 to a 104 by 104 by 256. And I think that's what this little blue rectangle here is. And then they had another copy copied out the 104 by 104 by 256 and then put the two together to get a 104 by 104 by 512. And so this these activations half are from the upsampling and half are from the downsampling from earlier in this whole process. And it might be easiest to understand why that's interesting when we get all the way back up to the top where we've got this 392 by 392 thing. The thing we're copying across now is just two convolutions away from the original image. So like for super resolution for example, we want it to look a lot like the original image. So in this case we're actually going to have an entire copy of almost something very much like the original image that we can include in these final convolutions. And so ditto here we have you know something that's kind of like the somewhat downsampled version we can use here and the more downsampled version we can use here. So yeah that's that's how the unit works. Do either of you guys have anything to add like things that you found this helpful to understand or anything surprising? I mean I guess it's shaping and alternating thing these days a lot of people tend to just add. So you've got the you know the outputs from the down layer are the same shape as the inputs for the corresponding like up block and then they just kind of add the. Yeah particularly for super resolution adding might make more sense than concatenating because you're like literally saying like oh this little two by two bit is basically the right pixel but it just have to be slightly modified on the edges. Yeah it also makes me think of like a boosting sort of thing where if you think about like the fact that a lot of information from the original image is being passed all the way across at that highest skip connection then the rest of the network can be effectively producing an update to that rather than having to recreate the whole image. Or to put it another way it's like a resnet but there's a skip connections right but the skip connections are like jumping from the start to the end and a bit after the start to a bit before the end and I guess a resnet's a bit like boosting too. Yeah. Yeah I mean it was kind of a good thing so yeah basically I think compared to like the noising on encoder where like we saw like the results were like even worse than I guess the original image here I guess the worst it can be is basically the original image so you know I guess it's just like a similar sort of kind of intuition behind the the the resnet and how that works. So yeah I mean it could be worse if these comms at the end are incapable of undoing what these comms did which is like one argument for maybe why there should also be a connection from here over to here and maybe a few more comms after that which is something I'm kind of interested in and not enough people do in my opinion. Another thing to consider is that they've only got two comms down here but at this point you have the benefit of only being a 28 by 28 you know why not do more computation at this point you know so there's a couple of things that sometimes people consider but maybe not enough. So let me try to remember what I did. So in my unit here so we've got the downsampling path which is a list of res blocks. Now a module list is just like a sequential except it doesn't actually do anything so then in the forward we have to go through the down path and x equals lx each time so it's basically yeah it's sequential that doesn't actually do anything and so the up path is exactly the same as we saw before it's a bunch of up blocks and then like we saw before the final one's going to have to go to three channel but now for our forward what we're going to do is we're going to keep track of since we're going to be copying this over here and copying this over here we have to save it during the downsampling path so we're going to save it in a something called layers. So I actually decided to do the little trick I mentioned which is to save the very first input. So I save the very first input I then put it through the very first res block and then we go through each in the downward path there's actually no need at all for there to be an il here it doesn't have to be enumerated because we don't use i. Okay so we go through the downward path so for this l for layer so for each layer in the downward path append the activations so that again as we go through each one we're going to be able to copy them over by saving them for later and then call the layer. Okay so how many layers have we got there's n layers that we've stored away so now we're going to go through the upsampling path and again we're going to call call each one but before we do we're going to actually do the thing that Jono mentioned which is rather than concatenating unless we're back at unless this is the very first layer because the very first upsampling layer there's nothing to copy. Right so unless it's the very first upsampling layer let's just add the saved activations and then call the layer and then right at the very end we'll add back the very first layer and then pass it through the very fine last res block. All right maybe that last one should be concatenated I'm not sure. Anywho this is what I did. Now the next thing that I wondered about was like how to initialize this and basically what I wanted to do is I wanted to initialize this so that when it's when it's untrained it would the output of the model would be identical to the input because like a reasonable starting point for like what does this look like so yeah what does this look like following super resolution would be this you know that's a reasonable starting point. So I just created this little zero weights thing which zeros out the weights and biases of a layer right so I created the model and then I said okay let's look at the very end of the upsampling path and we'll call that the last resnet and so let's zero out the very last convolutions and also the id connection and so that means that whatever it does for all this at the very end at the very end it's going to have nothing in there this will be zero so that means that this will be equal to layer zero and then that means we also want to make sure that this doesn't change anything so then we can just zero out the weights there that's probably not quite right is it I guess I should have actually set those to like an identity matrix maybe I'll try to do that later but at least it's something that would be very easy for it to I have a question Jeremy yeah this this zero weights I see a lot of people do a thing where they instead like multiply by one e minus three or one e minus four to make the weights really small but not completely zero and I don't have a good intuition whether it's like you know in some sense having everything set to zero fires off some warnings that maybe this is going to be like perfectly balanced on some saddle point or it's not going to have any signal to work with yeah it's very small but not quite zero random weights might be better yeah do you have an intuition for that I think so or not too much intuition but more empirical like or both I don't I don't think it's an issue and I think it comes from like a lot of people's PhD supervisors and stuff you know come from back in an era when they were doing like linear regression with one layer or whatever and in those cases yeah if all the weights are the same then no learning can happen because every weight update is identical but in this case all the previous weights are different so there's they all have different gradients and there's definitely yeah nothing to worry about I mean multiplying it by a small number would work too like it's not a problem but um yeah setting it to zeros I honestly I have to stop myself from I mean not that's a problem but I just I always have this natural inclination to not want to set them to zeros because of years of being told not to but there's no reason that should be a problem um all right so I just would I was just like again like that unit code is very concise and it's very very interesting to see if the basic idea is you know very simple and oh yeah to see that I guess yeah yeah it's helpful I think to just get it into a little bit of code isn't it yeah thanks um that's very simple code too um okay so we do our lrfind and then we train and you can see previously our loss even after five epochs was 207 and in this case our loss after one epoch is 086 so it's obviously much easier and we end up at 073 okay so we can take a look here's our inputs and there's our outputs so it's actually better rather than dramatically worse now so that's good um yeah some of it's actually not bad at all I would say um this car definitely looks like I think it's like a little over smoothed you know I think you could say so if we look at the other guy's eyes kids eyes still aren't great like in the original he's actually got proper pupils um so yeah it's definitely not recreated the original but you know given limited compute and limited data like the basic idea is not bad um I do worry that the poor koala like it it didn't have eyes here but like it ought to have known there should be eyes in a sense and it didn't create any and maybe it should have done a better job on the eyes so um my feeling is um and this is a pretty common way of thinking about this is that when you use mean squared error MSC as your loss function on these kinds of models you tend to get rather blurry results because if the model's not sure what to do it's just going to predict kind of the average you know um so one good way to fix that is to use perceptual loss and um I think it was Jono who taught us about perceptual loss wasn't it when we did like the style transfer stuff um um so perceptual loss is this idea that we could look it's kind of similar as well to the the FID idea we could look at the some intermediate layer of a pre-trained model and try to make sure that um our output images have the same features as the real images and in this case it ought to be saying like the real image you know if we went to kind of midway through a resnet it should be saying like there should be an eye here you know and in this case this would not represent an eye very well so that would should give it some useful feedback to improve how it draws an eye here um so that's the basic idea um so to do perceptual loss we need to classify a model so I just used the little I don't know why I used the 25 epoch one I guess maybe that's all I had trained when at that time um so it's used a little 25 epoch model um so then um yeah just grab a batch validation set and then we can just try it out by calling the classifier model um and here I'm doing it in FP16 just keeping my memory use down um I don't think this dot half would be necessary since I got auto cast anyway never mind um okay this is the same code we had before for the sin sets um so here is our images um so what we've got here huh just looking at some of them they're a bit weird aren't they I mean koalas are fine you know I wouldn't have picked this as a parking meter I wouldn't have picked this as a bow tie um so yeah so basically what this is doing here is it's um showing us the predictions so the predictions are not amazing um trolley bus that looks right um this is weird it's called this one a neck brace and this one a basketball that looks more like a neck brace the labrador retriever it's got right the tractor it's got right centipedes right mushrooms right those probably aren't mush punching bags okay so you know you can see our classifier it's okay but it's not amazing I think this was one with like a 60% accuracy um but the important thing is it's like it's got enough features to be able to like do an okay job I have no idea what this is so I'm pretty sure it's not a goose um okay so the model um the model is a very simple just a bunch of res blocks um three four five and then at the end we've got our pooling flatten dropout linear batch not um so we don't need yeah so what we're going to do is just to keep things simple we're just going to grab um I think the end of the three res block and so a simple way to do that is we'll just go from range four to the end of the model and delete those layers so if we do that and then look at the model again you can now see I've got zero one two three and that's it so this model um is going to yeah return kind of the activations after the fourth res block um so for perceptual loss as I think we talked about you could like pick a couple of different places like there's various ways to do it this is just the simplest I didn't even have to use hooks or anything we can just call c model and in fact if we do it um so just to take a look at this looks like and again we're going to use uh mixed precision here um we can grab our y batch as before put it through our classifier model um and so now that we've done this this is now going to give us those intermediate level features um so the features what's the shape of them it's batch size one or two four by the number of channels of that layer by the height and width of that layer so these are eight by eight by 256 features we're going to be using for the perceptual loss um and so when I was doing this I kind of wanted to like check whether things were vaguely looking reasonable um so I would expect that these features um from the actual y should be similar to if I um use our model um so something that I did I thought okay if we if we took that model that we trained then we would hope that the features were at least of the same sign um from you know from the um result of the model then they are in the real images um so this is just me comparing that and it's like oh yeah they are generally the same sign so this is just a little check to see if they're the real images um so this is just me comparing that and it's like oh yeah they are generally the same sign so this is just little checks that I was doing along the way and then I also thought I'd kind of look at the MSC loss along the way um yeah so there's no need to keep all those in there it was just stuff I was kind of doing to like debug as I went well not even debug to like identify ahead of time as if any problems um so now we can calculate create our loss function so our loss function is going to be the um the MSC loss just like before between the input and the target which is just all that's being passed in here plus the MSC loss between the features we get out of cmodel and the features we get from the actual and the features we get from the actual target image and so the features um we can calculate for the target image now the target image we're not going to be modifying that at all so we do that bit with no gradient um but we do want to be able to modify the thing that's generating our input that's the model we're trying to actually optimize so we do have gradient for that so in each case we're calling the classifier model one on the target and one on the input and so those are giving us our features now then we add them together but they're not particularly similar numerically like they're very different scales and we wouldn't want it to focus entirely on one or the other so i just ran it for an epoch or two checked what the losses would look like and i noticed that the feature loss was about 10 times bigger so my very hacky way was just to divide it by 10 but honestly like that detail doesn't tend to matter very much in my opinion which there's nothing wrong with doing it a rather hacky way um there are papers which suggest more elegant ways to handle it which isn't a bad idea to save you a bit of time if you're doing a lot of messing around with this. Jeremy, I don't know if you know it but the the new VAE decoder from Stability AI for the stable diffusion auto encoder they trained some with just mean squared error and some with mean squared error combined with the perceptual loss and they had a scaling factor of you know times 0.1 so exactly the same dividing the percentage so the answer is 0.1 that's that's the official and Andrej Kapathy says that the correct learning rate to use is always 4e neg 3 so we're getting all this sorted out now that's good all right so for my unit we're going to do the same stuff as before in terms of initializing it do our lr find train it for 20 epochs and obviously the loss is not comparable because this is lost now incorporates the perceptual loss as well and so this is one of the challenges with these things is like is it better or worse well we're just going to have to take a look and compare I guess and maybe I should copy over our previous models images so we can compare okay there's our inputs there's our outputs and yeah look he's got pupils now which he didn't used to have koala still doesn't quite have eyeballs but like it's definitely less you know out of focus looking um so yeah it's sort of flipping that's going on yeah so there's there's some of them are going to be flipped because this is copied from earlier so yeah there's clipping and cropping going on so they won't be identical yeah you can also see like the background like was all just blurred before where else now it's got texture which if we look at the real the real has texture you know so yeah clearly the perceptual loss has improved matters quite significantly there's an interesting thing here which is that there's not really any metric we can use now right because if we did mean squared error the one that's trained early on means good error would probably do better but visually it looks worse yeah and if we use like an fid well that's based on the features of the pre-trained network so that would probably be biased by the one that's trained using those features the perceptual loss and so you get back to this very old school thing of like well actually how are we choosing is just looking and evaluating right um and when you speak to someone like Jason Antic who's made a whole career out of you know image restoration and super resolution and colorization that is like a big part of his process even now is still like looking at a bunch of images to decide whether something is better rather than relying on these yeah some PhD student yelled at me on twitter a few weeks ago for like saying like look at this cool thing our student made look how don't they look better and he was like don't you know there's rigorous ways to measure these things this is not a rigorous approach at all it's like uh PhD students man they got all the answers can't have a human looking at a picture and deciding if they like it or not that's insane well i'm a PhD student i agree though that we should be looking at it so yeah okay some PhD students are better than others that's that's fair enough what's this oh right okay so talking of cheating let's do that um um so we're going to do something which is kind of fast ai's favorite trick and has been since we first launched which is uh gradually unfreezing pre-trained networks um so so in a sense it seems a bit funny to initialize all of this down path randomly because we already have a model that's perfectly capable of doing something useful on tiny image net images which is this so yeah what if we um took our unit right and for the model dot start which to remind you is the res block right at the front why don't we use the actual weights of the pre-trained model and then for each of the bits in the down sampling path why don't we use the actual weights that we used for that as well and so this is a useful way to understand how we can um copy over weights which is that any part of a module an nn.module is itself an nn.module an nn.module has a state dict which is a thing you can then call load state dict to put it somewhere else so this is going to fill in the whole res block called model.start with the whole res block which is p model zero so here's how we can copy across yeah that starting one and then all the down blocks are going to have the rest of it so this is basically going to copy into our model rather than having random weights we're going to have all the weights from our pre-trained model um and then since they're they're good at doing something they're not good at doing super resolution but they're good at doing something why don't we assume that they're good at doing super resolution so turn off requires grad and so what that means if we now train it's not going to update any of the parameters in the down block i guess i should have actually done model.start requires grad as false too now i think about it and so this is uh the the classic uh fine-tune approach from fast.ai the library we're going to do one epoch of just the upsampling path and that gets us to a loss of 255 now our loss function hasn't changed so that's totally comparable so previously our one epoch was 385 and in fact after one epoch with frozen weights for the down path we've beaten this now this is in a sense totally cheating but in a sense it's totally not it's totally cheating because the thing we're trying to do is to generate for the perceptual loss intermediate layer activations which are the same as this and so we're literally using that to create intermediate layer activations so obviously that's going to work but why is it okay to be cheating well because that's actually what we want like to be able to do super resolution we need something that can like have it recognize there's an eye here so we already have something that knows that there's an eye there and in fact interestingly this thing trained a lot more quickly than this thing and it turns out it's better at super resolution than that thing even though it wasn't trained to do super resolution and i think that's because the signal which is just like what is this is a really simple signal to use so yeah so we do that and then we can basically go through and set requires grad equals true again and so the basic idea being here that yeah when you've got a bunch of random weights which is the whole upsampling path and a bunch of pre-trained weights the downsampling path don't start then fine-tuning the whole thing because at the start it's going to be crap you know so and so just train the random weights for at least an epoch and then set everything to unfrozen and then we'll do our 20 epochs on the whole thing and so we go from 255 to 249 207 198 so it's improved a lot so to clarify uh with the um with using these weights and comparing that to the perceptual loss the perceptual loss is looking at the up sample data or the uh super resolution image as well as incorporating the weights that's for the downsampling path and so that's looking at i guess the original uh downgraded version of the image although we are just adding them so if you have zeros in the upsampling path that it's going to be the same so it is very easy for it to get the correct activations in the upsampling path um and then yeah i mean then it's kind of a bit weird because it goes all the way back to the top creates the image and then goes into the class of c model the classifier again um but i think it's going to create basically the same activations it's a bit confusing and weird um so yeah i mean it's not totally cheating but it's um it's certainly a much easier problem to solve yeah um okay so let's get our results again so there's our inputs yeah so that's looking pretty impressive so the kid has a yeah definitely looks pretty reasonable now um car looks pretty reasonable we still don't have eyes for the koala such as life but definitely the background textures look way better um the candy store looks less much better than it did um medicine looks a lot better than it did so yeah it's really i think it looks great okay so then we can get better still this is not part of the original unit but you know making better models is often about like where can we squeeze in more computation give it opportunities to do things and like there's nothing particularly that says that this downsampling thing is exactly the right thing you need here right it's being used for two things one is this conv and one is this conv but those are two different things and so it's kind of having to like learn to squeeze both purposes into one thing so i had this idea probably i'm sure lots of people had this idea but um whatever i had this idea which is why don't we put some res blocks in here which i called cross connections or cross cons so i decided that a cross conv is going to be just a res block followed by a conv um and so the unit i just copied and pasted but now as well as the downs i've also got crosses and so the crosses are cross cons um so now um rather than just adding the layer i add the cross conv applied to the layer um yeah i really should have added a cross con for this one as well now i think about it this is probably the one that wants it the most oh well never mind another time um okay so now yeah again we can definitely compare loss functions this is 198 so everything else was the same so i did the same thing of because you know the downsampling is the same so we can still copy in the state dict requires grad and it's better 189 quite a lot better really because you know this is these are hard to get improvements uh let's see if we can notice anything hey look it's got an eye just yeah so how about that um at this point it's almost quite difficult to see whether it's an improvement or not but the fact there's a bit of an eye on the koala i think is encouraging yeah so that's our super res uh oh man the bad news is we're out of time okay we didn't promise to do diffusion unit this lesson so we built a unit we built a unit yes we did and it's and we did super resolution with it and it looks pretty good so um i gotta admit i haven't thought about like exercises for people to do what would be useful things for people to try with like maybe they could create a unit they could try and learn about segmentation create a unit for segmentation or oh you know you can create there are a couple points where you well i was just gonna say there were a couple points we said oh i should have tried this you should have tried that i think that's obviously you know yeah basically yeah i think that's a obviously a good next step i was gonna say um style transfer is a good idea to do i think with a unit so style transfer you can actually um set up a loss function so that you can create a unit that learns to create images that look like van gogh you know for example um it's a totally different approach it's a it's a tricky one um i think i think when i was playing with that it almost hoped to not have the skip connections at the highest resolutions otherwise it just really wants to copy the input and modify it slightly interesting um maybe doing um where it's what you want would be better there too oh yes that's a good point yeah cool well we'll put some stuff up on the website about yeah you know ideas and i'm sure some students hopefully by the time you watch this we'll have some ideas on the forum of things i've tried too all right yeah the colorization is nice because it's um colorization right the transform is just to gray scale and back oh yes and then that's yeah that's a really actually okay so there's all kinds of decryptification you could do isn't there so if you want to keep it a bit more simple yes rather than doing these two lines of code you could um um yeah just turn it into black and white that's a great point um or um you could delete the center every time you know to create like a something that learns how to uh fill in or maybe delete the left hand side and that way that would lay then something that you can give it a photo in it'll invent a little bit more to the left yeah and then you could keep running it to generate a panorama another one you could do would be to like um in memory or something save it as a really uh highly compressed jpeg and so then you would you would learn to remove jpeg artifacts which then for your like old photos that you saved with crappy jpeg compression you could bring them back to life you could probably do like yeah you could do like i guess drawing to painting or something like this by taking some paintings and then like passing it through some sort of edge detection and using that as your starting point sounds interesting yeah i think that's a good idea yeah i think that's a starting point sounds interesting oh what about watermark removal you could um you know use pil or whatever to draw watermarks text whatever over the top which is quite useful for like you know radiology images and stuff sometimes have personally identifiable information written on them and you can just like learn to delete it yeah okay so lots of things people can do that's awesome thanks for your ideas basically any image to image task super all right um or just make the super res better um try it on full image net if you like if you've got lots of hard drive space thanks jono thanks tanishq see you next time we'll see you in the next one", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.28, "text": " Hi everybody. Today we are covering lesson 23 and we're here with Jono and Tanishq. How", "tokens": [50364, 2421, 2201, 13, 2692, 321, 366, 10322, 6898, 6673, 293, 321, 434, 510, 365, 7745, 78, 293, 314, 7524, 80, 13, 1012, 50728], "temperature": 0.0, "avg_logprob": -0.4464623092056869, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.007206195034086704}, {"id": 1, "seek": 0, "start": 7.28, "end": 8.84, "text": " are you guys both doing?", "tokens": [50728, 366, 291, 1074, 1293, 884, 30, 50806], "temperature": 0.0, "avg_logprob": -0.4464623092056869, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.007206195034086704}, {"id": 2, "seek": 0, "start": 8.84, "end": 14.56, "text": " Doing well. Excited for another lecture, another lesson.", "tokens": [50806, 18496, 731, 13, 9368, 1226, 337, 1071, 7991, 11, 1071, 6898, 13, 51092], "temperature": 0.0, "avg_logprob": -0.4464623092056869, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.007206195034086704}, {"id": 3, "seek": 0, "start": 14.56, "end": 16.96, "text": " Yeah, likewise.", "tokens": [51092, 865, 11, 32407, 13, 51212], "temperature": 0.0, "avg_logprob": -0.4464623092056869, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.007206195034086704}, {"id": 4, "seek": 0, "start": 16.96, "end": 28.0, "text": " Great. I shamefully have to start with admitting to a bug, which actually is rather, well,", "tokens": [51212, 3769, 13, 286, 10069, 2277, 362, 281, 722, 365, 44056, 281, 257, 7426, 11, 597, 767, 307, 2831, 11, 731, 11, 51764], "temperature": 0.0, "avg_logprob": -0.4464623092056869, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.007206195034086704}, {"id": 5, "seek": 2800, "start": 28.0, "end": 31.52, "text": " I don't know, it kind of messed up things in a sense, but I kind of, I think it's really", "tokens": [50364, 286, 500, 380, 458, 11, 309, 733, 295, 16507, 493, 721, 294, 257, 2020, 11, 457, 286, 733, 295, 11, 286, 519, 309, 311, 534, 50540], "temperature": 0.0, "avg_logprob": -0.2812460024062901, "compression_ratio": 1.497142857142857, "no_speech_prob": 2.7966481866315007e-05}, {"id": 6, "seek": 2800, "start": 31.52, "end": 39.84, "text": " interesting actually what happened. The bug, it was in notebook 23, the Keras notebook,", "tokens": [50540, 1880, 767, 437, 2011, 13, 440, 7426, 11, 309, 390, 294, 21060, 6673, 11, 264, 591, 6985, 21060, 11, 50956], "temperature": 0.0, "avg_logprob": -0.2812460024062901, "compression_ratio": 1.497142857142857, "no_speech_prob": 2.7966481866315007e-05}, {"id": 7, "seek": 2800, "start": 39.84, "end": 49.879999999999995, "text": " and it's about the measure, measuring the FID. So to recall, FID measures how similar", "tokens": [50956, 293, 309, 311, 466, 264, 3481, 11, 13389, 264, 479, 2777, 13, 407, 281, 9901, 11, 479, 2777, 8000, 577, 2531, 51458], "temperature": 0.0, "avg_logprob": -0.2812460024062901, "compression_ratio": 1.497142857142857, "no_speech_prob": 2.7966481866315007e-05}, {"id": 8, "seek": 4988, "start": 49.88, "end": 58.32, "text": " a bunch of samples are from a model to a bunch of samples of real images. And that similarity", "tokens": [50364, 257, 3840, 295, 10938, 366, 490, 257, 2316, 281, 257, 3840, 295, 10938, 295, 957, 5267, 13, 400, 300, 32194, 50786], "temperature": 0.0, "avg_logprob": -0.25656865624820485, "compression_ratio": 1.5847953216374269, "no_speech_prob": 0.0010812575928866863}, {"id": 9, "seek": 4988, "start": 58.32, "end": 64.68, "text": " is defined in this kind of like, some kind of distance between the distributions of the", "tokens": [50786, 307, 7642, 294, 341, 733, 295, 411, 11, 512, 733, 295, 4560, 1296, 264, 37870, 295, 264, 51104], "temperature": 0.0, "avg_logprob": -0.25656865624820485, "compression_ratio": 1.5847953216374269, "no_speech_prob": 0.0010812575928866863}, {"id": 10, "seek": 4988, "start": 64.68, "end": 73.84, "text": " features in a classifier or some kind of model. So that means that to get FID, we have to", "tokens": [51104, 4122, 294, 257, 1508, 9902, 420, 512, 733, 295, 2316, 13, 407, 300, 1355, 300, 281, 483, 479, 2777, 11, 321, 362, 281, 51562], "temperature": 0.0, "avg_logprob": -0.25656865624820485, "compression_ratio": 1.5847953216374269, "no_speech_prob": 0.0010812575928866863}, {"id": 11, "seek": 7384, "start": 73.84, "end": 82.24000000000001, "text": " load a model and we have to pass it some data loaders so that it can calculate what", "tokens": [50364, 3677, 257, 2316, 293, 321, 362, 281, 1320, 309, 512, 1412, 3677, 433, 370, 300, 309, 393, 8873, 437, 50784], "temperature": 0.0, "avg_logprob": -0.25882078317495494, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.7231470337719657e-05}, {"id": 12, "seek": 7384, "start": 82.24000000000001, "end": 87.64, "text": " the samples look like from real images. Now the problem is that the data loaders I was", "tokens": [50784, 264, 10938, 574, 411, 490, 957, 5267, 13, 823, 264, 1154, 307, 300, 264, 1412, 3677, 433, 286, 390, 51054], "temperature": 0.0, "avg_logprob": -0.25882078317495494, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.7231470337719657e-05}, {"id": 13, "seek": 7384, "start": 87.64, "end": 97.96000000000001, "text": " passing actually had images that the pixels were between negative 0.5 and positive 0.5.", "tokens": [51054, 8437, 767, 632, 5267, 300, 264, 18668, 645, 1296, 3671, 1958, 13, 20, 293, 3353, 1958, 13, 20, 13, 51570], "temperature": 0.0, "avg_logprob": -0.25882078317495494, "compression_ratio": 1.5357142857142858, "no_speech_prob": 1.7231470337719657e-05}, {"id": 14, "seek": 9796, "start": 98.0, "end": 105.96, "text": " But you might recall this model that I trained has pixels between negative 1 and 1. So what", "tokens": [50366, 583, 291, 1062, 9901, 341, 2316, 300, 286, 8895, 575, 18668, 1296, 3671, 502, 293, 502, 13, 407, 437, 50764], "temperature": 0.0, "avg_logprob": -0.28940420711741727, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.000362578866770491}, {"id": 15, "seek": 9796, "start": 105.96, "end": 112.63999999999999, "text": " this image eval class would have seen, and specifically this C model which we are getting", "tokens": [50764, 341, 3256, 1073, 304, 1508, 576, 362, 1612, 11, 293, 4682, 341, 383, 2316, 597, 321, 366, 1242, 51098], "temperature": 0.0, "avg_logprob": -0.28940420711741727, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.000362578866770491}, {"id": 16, "seek": 9796, "start": 112.63999999999999, "end": 120.5, "text": " the features from, is it would have seen a whole bunch of unusually low contrast images.", "tokens": [51098, 264, 4122, 490, 11, 307, 309, 576, 362, 1612, 257, 1379, 3840, 295, 10054, 671, 2295, 8712, 5267, 13, 51491], "temperature": 0.0, "avg_logprob": -0.28940420711741727, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.000362578866770491}, {"id": 17, "seek": 9796, "start": 120.5, "end": 125.03999999999999, "text": " So they wouldn't really have looked like many things in the data set, because in fact in", "tokens": [51491, 407, 436, 2759, 380, 534, 362, 2956, 411, 867, 721, 294, 264, 1412, 992, 11, 570, 294, 1186, 294, 51718], "temperature": 0.0, "avg_logprob": -0.28940420711741727, "compression_ratio": 1.609865470852018, "no_speech_prob": 0.000362578866770491}, {"id": 18, "seek": 12504, "start": 125.04, "end": 130.72, "text": " the data set I think, particularly for fashion MNIST, things are pretty consistently, you", "tokens": [50364, 264, 1412, 992, 286, 519, 11, 4098, 337, 6700, 376, 45, 19756, 11, 721, 366, 1238, 14961, 11, 291, 50648], "temperature": 0.0, "avg_logprob": -0.31324813186481437, "compression_ratio": 1.521551724137931, "no_speech_prob": 0.0004511893494054675}, {"id": 19, "seek": 12504, "start": 130.72, "end": 136.76000000000002, "text": " know, normalized in terms of going all the way from 0 to 1 or negative 1 to 1, I guess", "tokens": [50648, 458, 11, 48704, 294, 2115, 295, 516, 439, 264, 636, 490, 1958, 281, 502, 420, 3671, 502, 281, 502, 11, 286, 2041, 50950], "temperature": 0.0, "avg_logprob": -0.31324813186481437, "compression_ratio": 1.521551724137931, "no_speech_prob": 0.0004511893494054675}, {"id": 20, "seek": 12504, "start": 136.76000000000002, "end": 144.48000000000002, "text": " 0 to 2.5 in the original. And so as a result, I think what would have happened is that the", "tokens": [50950, 1958, 281, 568, 13, 20, 294, 264, 3380, 13, 400, 370, 382, 257, 1874, 11, 286, 519, 437, 576, 362, 2011, 307, 300, 264, 51336], "temperature": 0.0, "avg_logprob": -0.31324813186481437, "compression_ratio": 1.521551724137931, "no_speech_prob": 0.0004511893494054675}, {"id": 21, "seek": 12504, "start": 144.48000000000002, "end": 150.24, "text": " features that came out of this would have been kind of weird. And they might not have", "tokens": [51336, 4122, 300, 1361, 484, 295, 341, 576, 362, 668, 733, 295, 3657, 13, 400, 436, 1062, 406, 362, 51624], "temperature": 0.0, "avg_logprob": -0.31324813186481437, "compression_ratio": 1.521551724137931, "no_speech_prob": 0.0004511893494054675}, {"id": 22, "seek": 15024, "start": 150.24, "end": 155.68, "text": " necessarily consistently said, oh, these are T-shirt features and these are shoe features,", "tokens": [50364, 4725, 14961, 848, 11, 1954, 11, 613, 366, 314, 12, 15313, 4122, 293, 613, 366, 12796, 4122, 11, 50636], "temperature": 0.0, "avg_logprob": -0.2840855726555212, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.03408728539943695}, {"id": 23, "seek": 15024, "start": 155.68, "end": 164.8, "text": " but they would have said, oh, this is a weird low contrast image feature. And so then the", "tokens": [50636, 457, 436, 576, 362, 848, 11, 1954, 11, 341, 307, 257, 3657, 2295, 8712, 3256, 4111, 13, 400, 370, 550, 264, 51092], "temperature": 0.0, "avg_logprob": -0.2840855726555212, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.03408728539943695}, {"id": 24, "seek": 15024, "start": 164.8, "end": 170.12, "text": " shame continues in that I added another bug on top of this bug, which is when I then did", "tokens": [51092, 10069, 6515, 294, 300, 286, 3869, 1071, 7426, 322, 1192, 295, 341, 7426, 11, 597, 307, 562, 286, 550, 630, 51358], "temperature": 0.0, "avg_logprob": -0.2840855726555212, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.03408728539943695}, {"id": 25, "seek": 17012, "start": 170.12, "end": 183.28, "text": " the sampling, I didn't, I didn't multiply by 2, and the data that I trained it on was", "tokens": [50364, 264, 21179, 11, 286, 994, 380, 11, 286, 994, 380, 12972, 538, 568, 11, 293, 264, 1412, 300, 286, 8895, 309, 322, 390, 51022], "temperature": 0.0, "avg_logprob": -0.3223203106930381, "compression_ratio": 1.68944099378882, "no_speech_prob": 0.007231427356600761}, {"id": 26, "seek": 17012, "start": 183.28, "end": 193.12, "text": " actually the same data loaders, or specifically the same transform, the same Noisify transform.", "tokens": [51022, 767, 264, 912, 1412, 3677, 433, 11, 420, 4682, 264, 912, 4088, 11, 264, 912, 883, 271, 2505, 4088, 13, 51514], "temperature": 0.0, "avg_logprob": -0.3223203106930381, "compression_ratio": 1.68944099378882, "no_speech_prob": 0.007231427356600761}, {"id": 27, "seek": 17012, "start": 193.12, "end": 198.28, "text": " Well where did that come from? It's the same, yeah, the same transform I, not Noisify, the", "tokens": [51514, 1042, 689, 630, 300, 808, 490, 30, 467, 311, 264, 912, 11, 1338, 11, 264, 912, 4088, 286, 11, 406, 883, 271, 2505, 11, 264, 51772], "temperature": 0.0, "avg_logprob": -0.3223203106930381, "compression_ratio": 1.68944099378882, "no_speech_prob": 0.007231427356600761}, {"id": 28, "seek": 19828, "start": 198.44, "end": 204.76, "text": " same transform I, which, yeah, previously was from negative 0.5 to 0.5. So I trained the model", "tokens": [50372, 912, 4088, 286, 11, 597, 11, 1338, 11, 8046, 390, 490, 3671, 1958, 13, 20, 281, 1958, 13, 20, 13, 407, 286, 8895, 264, 2316, 50688], "temperature": 0.0, "avg_logprob": -0.2283683353000217, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.00019716823589988053}, {"id": 29, "seek": 19828, "start": 204.76, "end": 211.24, "text": " using this restricted input space as well. And therefore it was spitting out things that were", "tokens": [50688, 1228, 341, 20608, 4846, 1901, 382, 731, 13, 400, 4412, 309, 390, 637, 2414, 484, 721, 300, 645, 51012], "temperature": 0.0, "avg_logprob": -0.2283683353000217, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.00019716823589988053}, {"id": 30, "seek": 19828, "start": 211.24, "end": 220.92000000000002, "text": " between negative 0.5 and 0.5. And so the FID then said, wow, these are so similar. The samples are", "tokens": [51012, 1296, 3671, 1958, 13, 20, 293, 1958, 13, 20, 13, 400, 370, 264, 479, 2777, 550, 848, 11, 6076, 11, 613, 366, 370, 2531, 13, 440, 10938, 366, 51496], "temperature": 0.0, "avg_logprob": -0.2283683353000217, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.00019716823589988053}, {"id": 31, "seek": 19828, "start": 220.92000000000002, "end": 225.56, "text": " consistently spitting out features of low contrast things, and all of the real samples are low", "tokens": [51496, 14961, 637, 2414, 484, 4122, 295, 2295, 8712, 721, 11, 293, 439, 295, 264, 957, 10938, 366, 2295, 51728], "temperature": 0.0, "avg_logprob": -0.2283683353000217, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.00019716823589988053}, {"id": 32, "seek": 22556, "start": 225.56, "end": 231.32, "text": " contrast things. So those are really similar. And that's how we got really low numbers. So those", "tokens": [50364, 8712, 721, 13, 407, 729, 366, 534, 2531, 13, 400, 300, 311, 577, 321, 658, 534, 2295, 3547, 13, 407, 729, 50652], "temperature": 0.0, "avg_logprob": -0.19385596941102226, "compression_ratio": 1.7252252252252251, "no_speech_prob": 1.9223149138269946e-05}, {"id": 33, "seek": 22556, "start": 231.32, "end": 236.76, "text": " low numbers were wrong. So I was a bit surprised, I guess, that the Keras model was doing so much", "tokens": [50652, 2295, 3547, 645, 2085, 13, 407, 286, 390, 257, 857, 6100, 11, 286, 2041, 11, 300, 264, 591, 6985, 2316, 390, 884, 370, 709, 50924], "temperature": 0.0, "avg_logprob": -0.19385596941102226, "compression_ratio": 1.7252252252252251, "no_speech_prob": 1.9223149138269946e-05}, {"id": 34, "seek": 22556, "start": 236.76, "end": 242.2, "text": " better. And it certainly, it made me a big believer in the Keras model. But actually it's", "tokens": [50924, 1101, 13, 400, 309, 3297, 11, 309, 1027, 385, 257, 955, 23892, 294, 264, 591, 6985, 2316, 13, 583, 767, 309, 311, 51196], "temperature": 0.0, "avg_logprob": -0.19385596941102226, "compression_ratio": 1.7252252252252251, "no_speech_prob": 1.9223149138269946e-05}, {"id": 35, "seek": 22556, "start": 242.2, "end": 254.6, "text": " not doing so much better. So once we fix that, the FIDs are actually around 5, 6, 5, and the reals", "tokens": [51196, 406, 884, 370, 709, 1101, 13, 407, 1564, 321, 3191, 300, 11, 264, 479, 2777, 82, 366, 767, 926, 1025, 11, 1386, 11, 1025, 11, 293, 264, 957, 82, 51816], "temperature": 0.0, "avg_logprob": -0.19385596941102226, "compression_ratio": 1.7252252252252251, "no_speech_prob": 1.9223149138269946e-05}, {"id": 36, "seek": 25460, "start": 255.32, "end": 259.56, "text": " are 2.5. So to compare,", "tokens": [50400, 366, 568, 13, 20, 13, 407, 281, 6794, 11, 50612], "temperature": 0.0, "avg_logprob": -0.2685601552327474, "compression_ratio": 1.4598540145985401, "no_speech_prob": 1.8058199202641845e-05}, {"id": 37, "seek": 25460, "start": 263.96, "end": 268.52, "text": " we were getting some pretty good results in cosine. So cosine, yeah, we were getting 3", "tokens": [50832, 321, 645, 1242, 512, 1238, 665, 3542, 294, 23565, 13, 407, 23565, 11, 1338, 11, 321, 645, 1242, 805, 51060], "temperature": 0.0, "avg_logprob": -0.2685601552327474, "compression_ratio": 1.4598540145985401, "no_speech_prob": 1.8058199202641845e-05}, {"id": 38, "seek": 25460, "start": 269.88, "end": 277.88, "text": " to 4, depending on how many steps we were doing DDIM. So the result of this is that this,", "tokens": [51128, 281, 1017, 11, 5413, 322, 577, 867, 4439, 321, 645, 884, 413, 3085, 44, 13, 407, 264, 1874, 295, 341, 307, 300, 341, 11, 51528], "temperature": 0.0, "avg_logprob": -0.2685601552327474, "compression_ratio": 1.4598540145985401, "no_speech_prob": 1.8058199202641845e-05}, {"id": 39, "seek": 27788, "start": 278.52, "end": 285.32, "text": " this somewhat odd situation where the cosine model, where we", "tokens": [50396, 341, 8344, 7401, 2590, 689, 264, 23565, 2316, 11, 689, 321, 50736], "temperature": 0.0, "avg_logprob": -0.20342493768948228, "compression_ratio": 1.4176470588235295, "no_speech_prob": 1.1659405572572723e-05}, {"id": 40, "seek": 27788, "start": 288.76, "end": 297.96, "text": " scaled it accidentally to be negative 0.5 to 0.5, and then post-sampling multiplied by 2,", "tokens": [50908, 36039, 309, 15715, 281, 312, 3671, 1958, 13, 20, 281, 1958, 13, 20, 11, 293, 550, 2183, 12, 19988, 11970, 17207, 538, 568, 11, 51368], "temperature": 0.0, "avg_logprob": -0.20342493768948228, "compression_ratio": 1.4176470588235295, "no_speech_prob": 1.1659405572572723e-05}, {"id": 41, "seek": 27788, "start": 297.96, "end": 303.48, "text": " so we're not cheating, like the Keras one used to be, is working better than Keras, which,", "tokens": [51368, 370, 321, 434, 406, 18309, 11, 411, 264, 591, 6985, 472, 1143, 281, 312, 11, 307, 1364, 1101, 813, 591, 6985, 11, 597, 11, 51644], "temperature": 0.0, "avg_logprob": -0.20342493768948228, "compression_ratio": 1.4176470588235295, "no_speech_prob": 1.1659405572572723e-05}, {"id": 42, "seek": 30348, "start": 303.48, "end": 309.72, "text": " yeah, is a surprise to me. Because I was thinking Keras was kind of like, in theory,", "tokens": [50364, 1338, 11, 307, 257, 6365, 281, 385, 13, 1436, 286, 390, 1953, 591, 6985, 390, 733, 295, 411, 11, 294, 5261, 11, 50676], "temperature": 0.0, "avg_logprob": -0.22306173112657335, "compression_ratio": 1.7311320754716981, "no_speech_prob": 3.7852498735446716e-06}, {"id": 43, "seek": 30348, "start": 310.84000000000003, "end": 316.68, "text": " optimally scaling things. But I guess the truth is, it was scaling things to unit variance, but", "tokens": [50732, 5028, 379, 21589, 721, 13, 583, 286, 2041, 264, 3494, 307, 11, 309, 390, 21589, 721, 281, 4985, 21977, 11, 457, 51024], "temperature": 0.0, "avg_logprob": -0.22306173112657335, "compression_ratio": 1.7311320754716981, "no_speech_prob": 3.7852498735446716e-06}, {"id": 44, "seek": 30348, "start": 316.68, "end": 320.92, "text": " there's nothing particularly to say that's optimally scaling things. And so empirically,", "tokens": [51024, 456, 311, 1825, 4098, 281, 584, 300, 311, 5028, 379, 21589, 721, 13, 400, 370, 25790, 984, 11, 51236], "temperature": 0.0, "avg_logprob": -0.22306173112657335, "compression_ratio": 1.7311320754716981, "no_speech_prob": 3.7852498735446716e-06}, {"id": 45, "seek": 30348, "start": 320.92, "end": 331.08000000000004, "text": " we've found kind of accidentally a better way to scale things. And also our dependent variable is", "tokens": [51236, 321, 600, 1352, 733, 295, 15715, 257, 1101, 636, 281, 4373, 721, 13, 400, 611, 527, 12334, 7006, 307, 51744], "temperature": 0.0, "avg_logprob": -0.22306173112657335, "compression_ratio": 1.7311320754716981, "no_speech_prob": 3.7852498735446716e-06}, {"id": 46, "seek": 33108, "start": 331.08, "end": 336.2, "text": " different. You know, our dependent variable is not that Keras, you know, C mix combination,", "tokens": [50364, 819, 13, 509, 458, 11, 527, 12334, 7006, 307, 406, 300, 591, 6985, 11, 291, 458, 11, 383, 2890, 6562, 11, 50620], "temperature": 0.0, "avg_logprob": -0.24909724687275134, "compression_ratio": 1.5875706214689265, "no_speech_prob": 7.527742127422243e-06}, {"id": 47, "seek": 33108, "start": 337.0, "end": 345.0, "text": " but our dependent variable is just the noise, the 0, 1 noise, you know, the noise before it's", "tokens": [50660, 457, 527, 12334, 7006, 307, 445, 264, 5658, 11, 264, 1958, 11, 502, 5658, 11, 291, 458, 11, 264, 5658, 949, 309, 311, 51060], "temperature": 0.0, "avg_logprob": -0.24909724687275134, "compression_ratio": 1.5875706214689265, "no_speech_prob": 7.527742127422243e-06}, {"id": 48, "seek": 33108, "start": 345.0, "end": 354.44, "text": " multiplied by alpha bar. Okay, so that's, that's the bug. Anyway, I promised last time we would", "tokens": [51060, 17207, 538, 8961, 2159, 13, 1033, 11, 370, 300, 311, 11, 300, 311, 264, 7426, 13, 5684, 11, 286, 10768, 1036, 565, 321, 576, 51532], "temperature": 0.0, "avg_logprob": -0.24909724687275134, "compression_ratio": 1.5875706214689265, "no_speech_prob": 7.527742127422243e-06}, {"id": 49, "seek": 35444, "start": 354.44, "end": 363.48, "text": " stop looking at fashion MNIST for a while. So let's move on to tiny image net. So, and the", "tokens": [50364, 1590, 1237, 412, 6700, 376, 45, 19756, 337, 257, 1339, 13, 407, 718, 311, 1286, 322, 281, 5870, 3256, 2533, 13, 407, 11, 293, 264, 50816], "temperature": 0.0, "avg_logprob": -0.17888104336933025, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.00020662540919147432}, {"id": 50, "seek": 35444, "start": 363.48, "end": 369.4, "text": " reason we're going to do this is because we want to, I want to show an example of, we're going to", "tokens": [50816, 1778, 321, 434, 516, 281, 360, 341, 307, 570, 321, 528, 281, 11, 286, 528, 281, 855, 364, 1365, 295, 11, 321, 434, 516, 281, 51112], "temperature": 0.0, "avg_logprob": -0.17888104336933025, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.00020662540919147432}, {"id": 51, "seek": 35444, "start": 369.4, "end": 375.24, "text": " try and create units today. And I wanted to show an example of a nice unit we can create that", "tokens": [51112, 853, 293, 1884, 6815, 965, 13, 400, 286, 1415, 281, 855, 364, 1365, 295, 257, 1481, 4985, 321, 393, 1884, 300, 51404], "temperature": 0.0, "avg_logprob": -0.17888104336933025, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.00020662540919147432}, {"id": 52, "seek": 35444, "start": 375.24, "end": 380.84, "text": " combines a lot of the ideas we've been looking at. It's going to be a super resolution unit.", "tokens": [51404, 29520, 257, 688, 295, 264, 3487, 321, 600, 668, 1237, 412, 13, 467, 311, 516, 281, 312, 257, 1687, 8669, 4985, 13, 51684], "temperature": 0.0, "avg_logprob": -0.17888104336933025, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.00020662540919147432}, {"id": 53, "seek": 38084, "start": 380.84, "end": 384.76, "text": " And doing super resolution on fashion MNIST isn't going to be very interesting because the", "tokens": [50364, 400, 884, 1687, 8669, 322, 6700, 376, 45, 19756, 1943, 380, 516, 281, 312, 588, 1880, 570, 264, 50560], "temperature": 0.0, "avg_logprob": -0.1767219875169837, "compression_ratio": 1.5138339920948616, "no_speech_prob": 1.994711965380702e-06}, {"id": 54, "seek": 38084, "start": 384.76, "end": 392.67999999999995, "text": " maximum training size we have is 28 by 28. So, so I thought we'd go a little bit bigger than that", "tokens": [50560, 6674, 3097, 2744, 321, 362, 307, 7562, 538, 7562, 13, 407, 11, 370, 286, 1194, 321, 1116, 352, 257, 707, 857, 3801, 813, 300, 50956], "temperature": 0.0, "avg_logprob": -0.1767219875169837, "compression_ratio": 1.5138339920948616, "no_speech_prob": 1.994711965380702e-06}, {"id": 55, "seek": 38084, "start": 392.67999999999995, "end": 402.44, "text": " to tiny image net, which is 64 by 64. I found it quite difficult actually to find tiny image net", "tokens": [50956, 281, 5870, 3256, 2533, 11, 597, 307, 12145, 538, 12145, 13, 286, 1352, 309, 1596, 2252, 767, 281, 915, 5870, 3256, 2533, 51444], "temperature": 0.0, "avg_logprob": -0.1767219875169837, "compression_ratio": 1.5138339920948616, "no_speech_prob": 1.994711965380702e-06}, {"id": 56, "seek": 38084, "start": 402.44, "end": 407.55999999999995, "text": " data, but eventually I discovered that it's still on the Stanford servers where it was originally", "tokens": [51444, 1412, 11, 457, 4728, 286, 6941, 300, 309, 311, 920, 322, 264, 20374, 15909, 689, 309, 390, 7993, 51700], "temperature": 0.0, "avg_logprob": -0.1767219875169837, "compression_ratio": 1.5138339920948616, "no_speech_prob": 1.994711965380702e-06}, {"id": 57, "seek": 40756, "start": 407.56, "end": 413.72, "text": " created. It's just not linked to anywhere. So we'll try to, if this disappears, we will, we will", "tokens": [50364, 2942, 13, 467, 311, 445, 406, 9408, 281, 4992, 13, 407, 321, 603, 853, 281, 11, 498, 341, 25527, 11, 321, 486, 11, 321, 486, 50672], "temperature": 0.0, "avg_logprob": -0.2100251448781867, "compression_ratio": 1.5617021276595744, "no_speech_prob": 7.254086813190952e-05}, {"id": 58, "seek": 40756, "start": 413.72, "end": 422.76, "text": " keep our forum and website up to date with other places to find it. Anyway, so for now we can", "tokens": [50672, 1066, 527, 17542, 293, 3144, 493, 281, 4002, 365, 661, 3190, 281, 915, 309, 13, 5684, 11, 370, 337, 586, 321, 393, 51124], "temperature": 0.0, "avg_logprob": -0.2100251448781867, "compression_ratio": 1.5617021276595744, "no_speech_prob": 7.254086813190952e-05}, {"id": 59, "seek": 40756, "start": 424.04, "end": 431.64, "text": " grab the URL from there and unpack it. So shutil is a very handy little library inside", "tokens": [51188, 4444, 264, 12905, 490, 456, 293, 26699, 309, 13, 407, 402, 20835, 307, 257, 588, 13239, 707, 6405, 1854, 51568], "temperature": 0.0, "avg_logprob": -0.2100251448781867, "compression_ratio": 1.5617021276595744, "no_speech_prob": 7.254086813190952e-05}, {"id": 60, "seek": 40756, "start": 431.64, "end": 435.4, "text": " the Python standard library. And one of the things it has is a very handy unpack archive,", "tokens": [51568, 264, 15329, 3832, 6405, 13, 400, 472, 295, 264, 721, 309, 575, 307, 257, 588, 13239, 26699, 23507, 11, 51756], "temperature": 0.0, "avg_logprob": -0.2100251448781867, "compression_ratio": 1.5617021276595744, "no_speech_prob": 7.254086813190952e-05}, {"id": 61, "seek": 43540, "start": 435.4, "end": 439.47999999999996, "text": " so it can handle zip files and it's going to put it in our data directory.", "tokens": [50364, 370, 309, 393, 4813, 20730, 7098, 293, 309, 311, 516, 281, 829, 309, 294, 527, 1412, 21120, 13, 50568], "temperature": 0.0, "avg_logprob": -0.24200575979132402, "compression_ratio": 1.5758928571428572, "no_speech_prob": 4.029400770377833e-06}, {"id": 62, "seek": 43540, "start": 442.84, "end": 447.15999999999997, "text": " So I, yeah, just, you know, there's a few different ways we could process this.", "tokens": [50736, 407, 286, 11, 1338, 11, 445, 11, 291, 458, 11, 456, 311, 257, 1326, 819, 2098, 321, 727, 1399, 341, 13, 50952], "temperature": 0.0, "avg_logprob": -0.24200575979132402, "compression_ratio": 1.5758928571428572, "no_speech_prob": 4.029400770377833e-06}, {"id": 63, "seek": 43540, "start": 447.79999999999995, "end": 452.2, "text": " And I thought we might experiment with some things, but I thought, yeah, it wouldn't be a bad idea to", "tokens": [50984, 400, 286, 1194, 321, 1062, 5120, 365, 512, 721, 11, 457, 286, 1194, 11, 1338, 11, 309, 2759, 380, 312, 257, 1578, 1558, 281, 51204], "temperature": 0.0, "avg_logprob": -0.24200575979132402, "compression_ratio": 1.5758928571428572, "no_speech_prob": 4.029400770377833e-06}, {"id": 64, "seek": 43540, "start": 453.56, "end": 459.71999999999997, "text": " try doing things the reasonably kind of manual way, just to see, you know, what that looks like.", "tokens": [51272, 853, 884, 721, 264, 23551, 733, 295, 9688, 636, 11, 445, 281, 536, 11, 291, 458, 11, 437, 300, 1542, 411, 13, 51580], "temperature": 0.0, "avg_logprob": -0.24200575979132402, "compression_ratio": 1.5758928571428572, "no_speech_prob": 4.029400770377833e-06}, {"id": 65, "seek": 45972, "start": 459.8, "end": 465.16, "text": " Often this is the easiest way to do things because, you know, that's a very well-defined", "tokens": [50368, 20043, 341, 307, 264, 12889, 636, 281, 360, 721, 570, 11, 291, 458, 11, 300, 311, 257, 588, 731, 12, 37716, 50636], "temperature": 0.0, "avg_logprob": -0.20876297708285058, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005112343351356685}, {"id": 66, "seek": 45972, "start": 465.16, "end": 471.24, "text": " set of steps, right? So step one is to create a dataset. So a dataset is just literally something", "tokens": [50636, 992, 295, 4439, 11, 558, 30, 407, 1823, 472, 307, 281, 1884, 257, 28872, 13, 407, 257, 28872, 307, 445, 3736, 746, 50940], "temperature": 0.0, "avg_logprob": -0.20876297708285058, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005112343351356685}, {"id": 67, "seek": 45972, "start": 471.24, "end": 476.84000000000003, "text": " that has a length and that you can index into it. So it has to have these two things defined.", "tokens": [50940, 300, 575, 257, 4641, 293, 300, 291, 393, 8186, 666, 309, 13, 407, 309, 575, 281, 362, 613, 732, 721, 7642, 13, 51220], "temperature": 0.0, "avg_logprob": -0.20876297708285058, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005112343351356685}, {"id": 68, "seek": 45972, "start": 478.20000000000005, "end": 484.28000000000003, "text": " You don't have to inherit from anything. You just have to define these two things. Broadly speaking", "tokens": [51288, 509, 500, 380, 362, 281, 21389, 490, 1340, 13, 509, 445, 362, 281, 6964, 613, 732, 721, 13, 14074, 356, 4124, 51592], "temperature": 0.0, "avg_logprob": -0.20876297708285058, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005112343351356685}, {"id": 69, "seek": 45972, "start": 484.28000000000003, "end": 489.24, "text": " in Python, you generally don't have to inherit from things. You just have to provide the methods", "tokens": [51592, 294, 15329, 11, 291, 5101, 500, 380, 362, 281, 21389, 490, 721, 13, 509, 445, 362, 281, 2893, 264, 7150, 51840], "temperature": 0.0, "avg_logprob": -0.20876297708285058, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0005112343351356685}, {"id": 70, "seek": 48924, "start": 489.32, "end": 500.84000000000003, "text": " that are expected. So our dataset is in a directory called tiny-image-net-200. And then", "tokens": [50368, 300, 366, 5176, 13, 407, 527, 28872, 307, 294, 257, 21120, 1219, 5870, 12, 26624, 12, 7129, 12, 7629, 13, 400, 550, 50944], "temperature": 0.0, "avg_logprob": -0.23298920222691127, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.22343951970106e-06}, {"id": 71, "seek": 48924, "start": 500.84000000000003, "end": 505.40000000000003, "text": " there's a train directory and a val directory for the training and the validation set. And then", "tokens": [50944, 456, 311, 257, 3847, 21120, 293, 257, 1323, 21120, 337, 264, 3097, 293, 264, 24071, 992, 13, 400, 550, 51172], "temperature": 0.0, "avg_logprob": -0.23298920222691127, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.22343951970106e-06}, {"id": 72, "seek": 48924, "start": 505.40000000000003, "end": 511.64, "text": " the train directory, this is pretty classic, normal thing. Each category, so this is a category,", "tokens": [51172, 264, 3847, 21120, 11, 341, 307, 1238, 7230, 11, 2710, 551, 13, 6947, 7719, 11, 370, 341, 307, 257, 7719, 11, 51484], "temperature": 0.0, "avg_logprob": -0.23298920222691127, "compression_ratio": 1.6666666666666667, "no_speech_prob": 9.22343951970106e-06}, {"id": 73, "seek": 51164, "start": 512.28, "end": 520.6, "text": " has images in a separate folder and specifically they're in images subfolder. So what I wanted to", "tokens": [50396, 575, 5267, 294, 257, 4994, 10820, 293, 4682, 436, 434, 294, 5267, 1422, 18353, 260, 13, 407, 437, 286, 1415, 281, 50812], "temperature": 0.0, "avg_logprob": -0.3431002657178422, "compression_ratio": 1.5212765957446808, "no_speech_prob": 4.985949635738507e-05}, {"id": 74, "seek": 51164, "start": 520.6, "end": 527.88, "text": " do was to just grab, start with, grab all of the files in path slash train, all the image files.", "tokens": [50812, 360, 390, 281, 445, 4444, 11, 722, 365, 11, 4444, 439, 295, 264, 7098, 294, 3100, 17330, 3847, 11, 439, 264, 3256, 7098, 13, 51176], "temperature": 0.0, "avg_logprob": -0.3431002657178422, "compression_ratio": 1.5212765957446808, "no_speech_prob": 4.985949635738507e-05}, {"id": 75, "seek": 51164, "start": 528.52, "end": 536.6, "text": " So the Python standard library has a glob function, which searches recursively if asked to,", "tokens": [51208, 407, 264, 15329, 3832, 6405, 575, 257, 16125, 2445, 11, 597, 26701, 20560, 3413, 498, 2351, 281, 11, 51612], "temperature": 0.0, "avg_logprob": -0.3431002657178422, "compression_ratio": 1.5212765957446808, "no_speech_prob": 4.985949635738507e-05}, {"id": 76, "seek": 53660, "start": 537.08, "end": 547.16, "text": " for everything that matches this, well, this specification. So this specification is path", "tokens": [50388, 337, 1203, 300, 10676, 341, 11, 731, 11, 341, 31256, 13, 407, 341, 31256, 307, 3100, 50892], "temperature": 0.0, "avg_logprob": -0.23546041099770557, "compression_ratio": 1.7330316742081449, "no_speech_prob": 1.6701369531801902e-05}, {"id": 77, "seek": 53660, "start": 547.16, "end": 553.0, "text": " slash star dot jpeg. And then this star star here, I don't know why we need to do it twice. It's a", "tokens": [50892, 17330, 3543, 5893, 361, 494, 70, 13, 400, 550, 341, 3543, 3543, 510, 11, 286, 500, 380, 458, 983, 321, 643, 281, 360, 309, 6091, 13, 467, 311, 257, 51184], "temperature": 0.0, "avg_logprob": -0.23546041099770557, "compression_ratio": 1.7330316742081449, "no_speech_prob": 1.6701369531801902e-05}, {"id": 78, "seek": 53660, "start": 553.0, "end": 558.52, "text": " bit weird. You also need that to be recursive. So to be recursive, you both have to say recursive", "tokens": [51184, 857, 3657, 13, 509, 611, 643, 300, 281, 312, 20560, 488, 13, 407, 281, 312, 20560, 488, 11, 291, 1293, 362, 281, 584, 20560, 488, 51460], "temperature": 0.0, "avg_logprob": -0.23546041099770557, "compression_ratio": 1.7330316742081449, "no_speech_prob": 1.6701369531801902e-05}, {"id": 79, "seek": 53660, "start": 558.52, "end": 565.4, "text": " true here and also put star star before the slash here. So that's going to give us a list of all", "tokens": [51460, 2074, 510, 293, 611, 829, 3543, 3543, 949, 264, 17330, 510, 13, 407, 300, 311, 516, 281, 976, 505, 257, 1329, 295, 439, 51804], "temperature": 0.0, "avg_logprob": -0.23546041099770557, "compression_ratio": 1.7330316742081449, "no_speech_prob": 1.6701369531801902e-05}, {"id": 80, "seek": 56540, "start": 565.48, "end": 575.88, "text": " files inside path train. And so then if we index into that training dataset with zero, that will", "tokens": [50368, 7098, 1854, 3100, 3847, 13, 400, 370, 550, 498, 321, 8186, 666, 300, 3097, 28872, 365, 4018, 11, 300, 486, 50888], "temperature": 0.0, "avg_logprob": -0.23841839301876905, "compression_ratio": 1.6379310344827587, "no_speech_prob": 2.295908416272141e-06}, {"id": 81, "seek": 56540, "start": 575.88, "end": 583.88, "text": " call get item, passing an i of zero. And so we will then return a tuple. One is the thing in", "tokens": [50888, 818, 483, 3174, 11, 8437, 364, 741, 295, 4018, 13, 400, 370, 321, 486, 550, 2736, 257, 2604, 781, 13, 1485, 307, 264, 551, 294, 51288], "temperature": 0.0, "avg_logprob": -0.23841839301876905, "compression_ratio": 1.6379310344827587, "no_speech_prob": 2.295908416272141e-06}, {"id": 82, "seek": 56540, "start": 583.88, "end": 595.0, "text": " self.files.i, which is this file, and then the label for it. And the label is that. So it's the", "tokens": [51288, 2698, 13, 69, 4680, 13, 72, 11, 597, 307, 341, 3991, 11, 293, 550, 264, 7645, 337, 309, 13, 400, 264, 7645, 307, 300, 13, 407, 309, 311, 264, 51844], "temperature": 0.0, "avg_logprob": -0.23841839301876905, "compression_ratio": 1.6379310344827587, "no_speech_prob": 2.295908416272141e-06}, {"id": 83, "seek": 59500, "start": 595.0, "end": 604.36, "text": " parents, parents, name, parents, parents, name. And so that's the name. Okay. So there's a data", "tokens": [50364, 3152, 11, 3152, 11, 1315, 11, 3152, 11, 3152, 11, 1315, 13, 400, 370, 300, 311, 264, 1315, 13, 1033, 13, 407, 456, 311, 257, 1412, 50832], "temperature": 0.0, "avg_logprob": -0.2467839813232422, "compression_ratio": 1.8173076923076923, "no_speech_prob": 3.4663219139474677e-07}, {"id": 84, "seek": 59500, "start": 604.36, "end": 609.4, "text": " set that returns two strings when you index into it, a tuple of two strings. The first is the name", "tokens": [50832, 992, 300, 11247, 732, 13985, 562, 291, 8186, 666, 309, 11, 257, 2604, 781, 295, 732, 13985, 13, 440, 700, 307, 264, 1315, 51084], "temperature": 0.0, "avg_logprob": -0.2467839813232422, "compression_ratio": 1.8173076923076923, "no_speech_prob": 3.4663219139474677e-07}, {"id": 85, "seek": 59500, "start": 609.4, "end": 617.16, "text": " of the image file, so the path of the image file. And the second is the name of the category it's", "tokens": [51084, 295, 264, 3256, 3991, 11, 370, 264, 3100, 295, 264, 3256, 3991, 13, 400, 264, 1150, 307, 264, 1315, 295, 264, 7719, 309, 311, 51472], "temperature": 0.0, "avg_logprob": -0.2467839813232422, "compression_ratio": 1.8173076923076923, "no_speech_prob": 3.4663219139474677e-07}, {"id": 86, "seek": 59500, "start": 617.16, "end": 622.44, "text": " in. These weird names are called WordNet categories. They're like codes that indicate", "tokens": [51472, 294, 13, 1981, 3657, 5288, 366, 1219, 8725, 31890, 10479, 13, 814, 434, 411, 14211, 300, 13330, 51736], "temperature": 0.0, "avg_logprob": -0.2467839813232422, "compression_ratio": 1.8173076923076923, "no_speech_prob": 3.4663219139474677e-07}, {"id": 87, "seek": 62244, "start": 622.84, "end": 632.6800000000001, "text": " concepts, basically, in English. So one of the reasons I actually used this particular dataset", "tokens": [50384, 10392, 11, 1936, 11, 294, 3669, 13, 407, 472, 295, 264, 4112, 286, 767, 1143, 341, 1729, 28872, 50876], "temperature": 0.0, "avg_logprob": -0.3312366758074079, "compression_ratio": 1.4771573604060915, "no_speech_prob": 8.714223440620117e-07}, {"id": 88, "seek": 62244, "start": 632.6800000000001, "end": 638.6800000000001, "text": " is because it's going to force us to do some more data processing, which I think is good practice.", "tokens": [50876, 307, 570, 309, 311, 516, 281, 3464, 505, 281, 360, 512, 544, 1412, 9007, 11, 597, 286, 519, 307, 665, 3124, 13, 51176], "temperature": 0.0, "avg_logprob": -0.3312366758074079, "compression_ratio": 1.4771573604060915, "no_speech_prob": 8.714223440620117e-07}, {"id": 89, "seek": 62244, "start": 639.72, "end": 645.8000000000001, "text": " And that's because weirdly, in the validation set, although it's in tiny image net 200 slash val,", "tokens": [51228, 400, 300, 311, 570, 48931, 11, 294, 264, 24071, 992, 11, 4878, 309, 311, 294, 5870, 3256, 2533, 2331, 17330, 1323, 11, 51532], "temperature": 0.0, "avg_logprob": -0.3312366758074079, "compression_ratio": 1.4771573604060915, "no_speech_prob": 8.714223440620117e-07}, {"id": 90, "seek": 64580, "start": 646.76, "end": 653.16, "text": " which is the not weird part, the weird part is that they are not then in subdirectories", "tokens": [50412, 597, 307, 264, 406, 3657, 644, 11, 264, 3657, 644, 307, 300, 436, 366, 406, 550, 294, 1422, 18267, 1672, 530, 50732], "temperature": 0.0, "avg_logprob": -0.26607915438138524, "compression_ratio": 1.4936708860759493, "no_speech_prob": 1.2029537174385041e-05}, {"id": 91, "seek": 64580, "start": 653.8, "end": 664.12, "text": " organized by label. Instead, there is a separate val annotations.txt file,", "tokens": [50764, 9983, 538, 7645, 13, 7156, 11, 456, 307, 257, 4994, 1323, 25339, 763, 13, 83, 734, 3991, 11, 51280], "temperature": 0.0, "avg_logprob": -0.26607915438138524, "compression_ratio": 1.4936708860759493, "no_speech_prob": 1.2029537174385041e-05}, {"id": 92, "seek": 64580, "start": 668.28, "end": 673.64, "text": " which looks like this. So it says to each file name, what category is it?", "tokens": [51488, 597, 1542, 411, 341, 13, 407, 309, 1619, 281, 1184, 3991, 1315, 11, 437, 7719, 307, 309, 30, 51756], "temperature": 0.0, "avg_logprob": -0.26607915438138524, "compression_ratio": 1.4936708860759493, "no_speech_prob": 1.2029537174385041e-05}, {"id": 93, "seek": 67364, "start": 674.6, "end": 679.96, "text": " It's also got the bounding box of whereabouts that is, but we're not going to be using that today.", "tokens": [50412, 467, 311, 611, 658, 264, 5472, 278, 2424, 295, 689, 41620, 300, 307, 11, 457, 321, 434, 406, 516, 281, 312, 1228, 300, 965, 13, 50680], "temperature": 0.0, "avg_logprob": -0.19302510667121273, "compression_ratio": 1.5666666666666667, "no_speech_prob": 5.507584774022689e-06}, {"id": 94, "seek": 67364, "start": 682.1999999999999, "end": 688.04, "text": " So I decided to create a dictionary that would tell us for each", "tokens": [50792, 407, 286, 3047, 281, 1884, 257, 25890, 300, 576, 980, 505, 337, 1184, 51084], "temperature": 0.0, "avg_logprob": -0.19302510667121273, "compression_ratio": 1.5666666666666667, "no_speech_prob": 5.507584774022689e-06}, {"id": 95, "seek": 67364, "start": 689.88, "end": 697.08, "text": " file, what category is it in? So that means that I want to create a, in this case here,", "tokens": [51176, 3991, 11, 437, 7719, 307, 309, 294, 30, 407, 300, 1355, 300, 286, 528, 281, 1884, 257, 11, 294, 341, 1389, 510, 11, 51536], "temperature": 0.0, "avg_logprob": -0.19302510667121273, "compression_ratio": 1.5666666666666667, "no_speech_prob": 5.507584774022689e-06}, {"id": 96, "seek": 67364, "start": 697.08, "end": 700.12, "text": " I'm doing something exactly like a list comprehension, but because it's not in", "tokens": [51536, 286, 478, 884, 746, 2293, 411, 257, 1329, 44991, 11, 457, 570, 309, 311, 406, 294, 51688], "temperature": 0.0, "avg_logprob": -0.19302510667121273, "compression_ratio": 1.5666666666666667, "no_speech_prob": 5.507584774022689e-06}, {"id": 97, "seek": 70012, "start": 700.12, "end": 703.32, "text": " square brackets, it's a generator comprehension. So it'll generate,", "tokens": [50364, 3732, 26179, 11, 309, 311, 257, 19265, 44991, 13, 407, 309, 603, 8460, 11, 50524], "temperature": 0.0, "avg_logprob": -0.21984825134277344, "compression_ratio": 1.6666666666666667, "no_speech_prob": 8.059424203565868e-07}, {"id": 98, "seek": 70012, "start": 704.28, "end": 712.36, "text": " it'll kind of stream out the results. And we're going to go through each line in this file.", "tokens": [50572, 309, 603, 733, 295, 4309, 484, 264, 3542, 13, 400, 321, 434, 516, 281, 352, 807, 1184, 1622, 294, 341, 3991, 13, 50976], "temperature": 0.0, "avg_logprob": -0.21984825134277344, "compression_ratio": 1.6666666666666667, "no_speech_prob": 8.059424203565868e-07}, {"id": 99, "seek": 70012, "start": 713.72, "end": 722.52, "text": " And we're going to split on tab. So that's going to give us this, and then this, and then this,", "tokens": [51044, 400, 321, 434, 516, 281, 7472, 322, 4421, 13, 407, 300, 311, 516, 281, 976, 505, 341, 11, 293, 550, 341, 11, 293, 550, 341, 11, 51484], "temperature": 0.0, "avg_logprob": -0.21984825134277344, "compression_ratio": 1.6666666666666667, "no_speech_prob": 8.059424203565868e-07}, {"id": 100, "seek": 72252, "start": 722.6, "end": 730.6, "text": " and then we're going to grab the first two. And if you basically pass a list of lists or", "tokens": [50368, 293, 550, 321, 434, 516, 281, 4444, 264, 700, 732, 13, 400, 498, 291, 1936, 1320, 257, 1329, 295, 14511, 420, 50768], "temperature": 0.0, "avg_logprob": -0.22227578549771695, "compression_ratio": 1.5114942528735633, "no_speech_prob": 8.092412463156506e-05}, {"id": 101, "seek": 72252, "start": 730.6, "end": 739.4, "text": " list of tuples or whatever to dict, it will create a dictionary using these pairs as key values.", "tokens": [50768, 1329, 295, 2604, 2622, 420, 2035, 281, 12569, 11, 309, 486, 1884, 257, 25890, 1228, 613, 15494, 382, 2141, 4190, 13, 51208], "temperature": 0.0, "avg_logprob": -0.22227578549771695, "compression_ratio": 1.5114942528735633, "no_speech_prob": 8.092412463156506e-05}, {"id": 102, "seek": 72252, "start": 740.1999999999999, "end": 748.92, "text": " So if we have a look, there it is. So that's quite a nice, neat way to do it.", "tokens": [51248, 407, 498, 321, 362, 257, 574, 11, 456, 309, 307, 13, 407, 300, 311, 1596, 257, 1481, 11, 10654, 636, 281, 360, 309, 13, 51684], "temperature": 0.0, "avg_logprob": -0.22227578549771695, "compression_ratio": 1.5114942528735633, "no_speech_prob": 8.092412463156506e-05}, {"id": 103, "seek": 74892, "start": 749.88, "end": 755.4799999999999, "text": " And if you're not sure, you can just click type dict, type open brackets, and then hit", "tokens": [50412, 400, 498, 291, 434, 406, 988, 11, 291, 393, 445, 2052, 2010, 12569, 11, 2010, 1269, 26179, 11, 293, 550, 2045, 50692], "temperature": 0.0, "avg_logprob": -0.246912303723787, "compression_ratio": 1.6074766355140186, "no_speech_prob": 2.9943960271339165e-06}, {"id": 104, "seek": 74892, "start": 755.4799999999999, "end": 758.52, "text": " shift tab a couple of times, and it'll show you the various options.", "tokens": [50692, 5513, 4421, 257, 1916, 295, 1413, 11, 293, 309, 603, 855, 291, 264, 3683, 3956, 13, 50844], "temperature": 0.0, "avg_logprob": -0.246912303723787, "compression_ratio": 1.6074766355140186, "no_speech_prob": 2.9943960271339165e-06}, {"id": 105, "seek": 74892, "start": 759.7199999999999, "end": 764.8399999999999, "text": " And you can see here, I'm doing dict iterable because my generator is iterable. And it says,", "tokens": [50904, 400, 291, 393, 536, 510, 11, 286, 478, 884, 12569, 17138, 712, 570, 452, 19265, 307, 17138, 712, 13, 400, 309, 1619, 11, 51160], "temperature": 0.0, "avg_logprob": -0.246912303723787, "compression_ratio": 1.6074766355140186, "no_speech_prob": 2.9943960271339165e-06}, {"id": 106, "seek": 74892, "start": 764.8399999999999, "end": 770.04, "text": " oh, that's exactly as if you created a dictionary and then gone for kv in iterable dk equals v.", "tokens": [51160, 1954, 11, 300, 311, 2293, 382, 498, 291, 2942, 257, 25890, 293, 550, 2780, 337, 350, 85, 294, 17138, 712, 274, 74, 6915, 371, 13, 51420], "temperature": 0.0, "avg_logprob": -0.246912303723787, "compression_ratio": 1.6074766355140186, "no_speech_prob": 2.9943960271339165e-06}, {"id": 107, "seek": 77004, "start": 770.4399999999999, "end": 775.8, "text": " So there's a nice little trick. Okay, now", "tokens": [50384, 407, 456, 311, 257, 1481, 707, 4282, 13, 1033, 11, 586, 50652], "temperature": 0.0, "avg_logprob": -0.3478116535005115, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0002453619090374559}, {"id": 108, "seek": 77004, "start": 779.3199999999999, "end": 786.12, "text": " we need a data set that works just like tiny data set, but the get items are going to label", "tokens": [50828, 321, 643, 257, 1412, 992, 300, 1985, 445, 411, 5870, 1412, 992, 11, 457, 264, 483, 4754, 366, 516, 281, 7645, 51168], "temperature": 0.0, "avg_logprob": -0.3478116535005115, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0002453619090374559}, {"id": 109, "seek": 77004, "start": 786.12, "end": 790.8399999999999, "text": " things differently. So I just inherited from tiny data set. So that means we don't need to", "tokens": [51168, 721, 7614, 13, 407, 286, 445, 27091, 490, 5870, 1412, 992, 13, 407, 300, 1355, 321, 500, 380, 643, 281, 51404], "temperature": 0.0, "avg_logprob": -0.3478116535005115, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0002453619090374559}, {"id": 110, "seek": 77004, "start": 790.8399999999999, "end": 795.24, "text": " do init or len again. And then get item again, it's going to turn the ith file.", "tokens": [51404, 360, 3157, 420, 40116, 797, 13, 400, 550, 483, 3174, 797, 11, 309, 311, 516, 281, 1261, 264, 309, 71, 3991, 13, 51624], "temperature": 0.0, "avg_logprob": -0.3478116535005115, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0002453619090374559}, {"id": 111, "seek": 79524, "start": 795.8, "end": 798.44, "text": " This time, the label will not be the parent, parent name, but", "tokens": [50392, 639, 565, 11, 264, 7645, 486, 406, 312, 264, 2596, 11, 2596, 1315, 11, 457, 50524], "temperature": 0.0, "avg_logprob": -0.44116165268589075, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0003150292322970927}, {"id": 112, "seek": 79524, "start": 799.64, "end": 804.2, "text": " we will look up in the annotations dictionary, the name of the file.", "tokens": [50584, 321, 486, 574, 493, 294, 264, 25339, 763, 25890, 11, 264, 1315, 295, 264, 3991, 13, 50812], "temperature": 0.0, "avg_logprob": -0.44116165268589075, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0003150292322970927}, {"id": 113, "seek": 79524, "start": 808.6, "end": 811.64, "text": " And so that works. We can check the length works.", "tokens": [51032, 400, 370, 300, 1985, 13, 492, 393, 1520, 264, 4641, 1985, 13, 51184], "temperature": 0.0, "avg_logprob": -0.44116165268589075, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0003150292322970927}, {"id": 114, "seek": 79524, "start": 813.5600000000001, "end": 819.96, "text": " So then a fairly generally useful thing that I thought we'll then create is something that lets", "tokens": [51280, 407, 550, 257, 6457, 5101, 4420, 551, 300, 286, 1194, 321, 603, 550, 1884, 307, 746, 300, 6653, 51600], "temperature": 0.0, "avg_logprob": -0.44116165268589075, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0003150292322970927}, {"id": 115, "seek": 81996, "start": 820.0400000000001, "end": 826.9200000000001, "text": " us transform any data set. So here's a class that you can pass it a data set,", "tokens": [50368, 505, 4088, 604, 1412, 992, 13, 407, 510, 311, 257, 1508, 300, 291, 393, 1320, 309, 257, 1412, 992, 11, 50712], "temperature": 0.0, "avg_logprob": -0.38356943483705874, "compression_ratio": 2.076530612244898, "no_speech_prob": 3.480794475763105e-05}, {"id": 116, "seek": 81996, "start": 827.88, "end": 832.6800000000001, "text": " and you can pass it a transformation for the x or the independent variable,", "tokens": [50760, 293, 291, 393, 1320, 309, 257, 9887, 337, 264, 2031, 420, 264, 6695, 7006, 11, 51000], "temperature": 0.0, "avg_logprob": -0.38356943483705874, "compression_ratio": 2.076530612244898, "no_speech_prob": 3.480794475763105e-05}, {"id": 117, "seek": 81996, "start": 832.6800000000001, "end": 837.08, "text": " and you can pass it a transformation for the y. And both of them default to no op,", "tokens": [51000, 293, 291, 393, 1320, 309, 257, 9887, 337, 264, 288, 13, 400, 1293, 295, 552, 7576, 281, 572, 999, 11, 51220], "temperature": 0.0, "avg_logprob": -0.38356943483705874, "compression_ratio": 2.076530612244898, "no_speech_prob": 3.480794475763105e-05}, {"id": 118, "seek": 81996, "start": 837.08, "end": 843.8000000000001, "text": " that is no operation, so it just doesn't change it at all. So a transform data set,", "tokens": [51220, 300, 307, 572, 6916, 11, 370, 309, 445, 1177, 380, 1319, 309, 412, 439, 13, 407, 257, 4088, 1412, 992, 11, 51556], "temperature": 0.0, "avg_logprob": -0.38356943483705874, "compression_ratio": 2.076530612244898, "no_speech_prob": 3.480794475763105e-05}, {"id": 119, "seek": 81996, "start": 843.8000000000001, "end": 849.72, "text": " the length of it is just the length of the original data set. So it's just a transform", "tokens": [51556, 264, 4641, 295, 309, 307, 445, 264, 4641, 295, 264, 3380, 1412, 992, 13, 407, 309, 311, 445, 257, 4088, 51852], "temperature": 0.0, "avg_logprob": -0.38356943483705874, "compression_ratio": 2.076530612244898, "no_speech_prob": 3.480794475763105e-05}, {"id": 120, "seek": 84972, "start": 850.12, "end": 857.1600000000001, "text": " data set. But when we call get item, it'll grab the tuple from the data set we passed in,", "tokens": [50384, 1412, 992, 13, 583, 562, 321, 818, 483, 3174, 11, 309, 603, 4444, 264, 2604, 781, 490, 264, 1412, 992, 321, 4678, 294, 11, 50736], "temperature": 0.0, "avg_logprob": -0.25911088891931483, "compression_ratio": 1.4636871508379887, "no_speech_prob": 1.863153011072427e-05}, {"id": 121, "seek": 84972, "start": 857.8000000000001, "end": 864.12, "text": " and it will return that tuple, but with transform x and transform y applied to it.", "tokens": [50768, 293, 309, 486, 2736, 300, 2604, 781, 11, 457, 365, 4088, 2031, 293, 4088, 288, 6456, 281, 309, 13, 51084], "temperature": 0.0, "avg_logprob": -0.25911088891931483, "compression_ratio": 1.4636871508379887, "no_speech_prob": 1.863153011072427e-05}, {"id": 122, "seek": 84972, "start": 865.0, "end": 879.24, "text": " Does that make sense so far? Great. Okay. So I don't like working with these n030 things,", "tokens": [51128, 4402, 300, 652, 2020, 370, 1400, 30, 3769, 13, 1033, 13, 407, 286, 500, 380, 411, 1364, 365, 613, 297, 15, 3446, 721, 11, 51840], "temperature": 0.0, "avg_logprob": -0.25911088891931483, "compression_ratio": 1.4636871508379887, "no_speech_prob": 1.863153011072427e-05}, {"id": 123, "seek": 87972, "start": 879.88, "end": 884.44, "text": " but the data set luckily has a WordNet IDs file in it.", "tokens": [50372, 457, 264, 1412, 992, 22880, 575, 257, 8725, 31890, 48212, 3991, 294, 309, 13, 50600], "temperature": 0.0, "avg_logprob": -0.1921162749781753, "compression_ratio": 1.453416149068323, "no_speech_prob": 1.172634142676543e-06}, {"id": 124, "seek": 87972, "start": 891.48, "end": 896.28, "text": " So if I just open it up, oh sorry, this one actually is not quite going to help us. This", "tokens": [50952, 407, 498, 286, 445, 1269, 309, 493, 11, 1954, 2597, 11, 341, 472, 767, 307, 406, 1596, 516, 281, 854, 505, 13, 639, 51192], "temperature": 0.0, "avg_logprob": -0.1921162749781753, "compression_ratio": 1.453416149068323, "no_speech_prob": 1.172634142676543e-06}, {"id": 125, "seek": 87972, "start": 896.28, "end": 903.0, "text": " is just a list of all of the WordNet IDs that they have images for. We could have actually", "tokens": [51192, 307, 445, 257, 1329, 295, 439, 295, 264, 8725, 31890, 48212, 300, 436, 362, 5267, 337, 13, 492, 727, 362, 767, 51528], "temperature": 0.0, "avg_logprob": -0.1921162749781753, "compression_ratio": 1.453416149068323, "no_speech_prob": 1.172634142676543e-06}, {"id": 126, "seek": 90300, "start": 903.0, "end": 909.88, "text": " got this by simply grabbing, by listing this directory, it would have told us all the IDs,", "tokens": [50364, 658, 341, 538, 2935, 23771, 11, 538, 22161, 341, 21120, 11, 309, 576, 362, 1907, 505, 439, 264, 48212, 11, 50708], "temperature": 0.0, "avg_logprob": -0.21155053690860146, "compression_ratio": 1.4517766497461928, "no_speech_prob": 0.0009547170484438539}, {"id": 127, "seek": 90300, "start": 909.88, "end": 915.56, "text": " but they've got, they've also got just a, the text file containing all of them. So we can see that", "tokens": [50708, 457, 436, 600, 658, 11, 436, 600, 611, 658, 445, 257, 11, 264, 2487, 3991, 19273, 439, 295, 552, 13, 407, 321, 393, 536, 300, 50992], "temperature": 0.0, "avg_logprob": -0.21155053690860146, "compression_ratio": 1.4517766497461928, "no_speech_prob": 0.0009547170484438539}, {"id": 128, "seek": 90300, "start": 915.56, "end": 932.36, "text": " there are 200 categories. Okay. And that's useful because we're going to want to change n030 etc", "tokens": [50992, 456, 366, 2331, 10479, 13, 1033, 13, 400, 300, 311, 4420, 570, 321, 434, 516, 281, 528, 281, 1319, 297, 15, 3446, 5183, 51832], "temperature": 0.0, "avg_logprob": -0.21155053690860146, "compression_ratio": 1.4517766497461928, "no_speech_prob": 0.0009547170484438539}, {"id": 129, "seek": 93236, "start": 932.36, "end": 938.6, "text": " into an int. And the way we can change it into an int is by simply saying, oh, we'll call,", "tokens": [50364, 666, 364, 560, 13, 400, 264, 636, 321, 393, 1319, 309, 666, 364, 560, 307, 538, 2935, 1566, 11, 1954, 11, 321, 603, 818, 11, 50676], "temperature": 0.0, "avg_logprob": -0.2453617132627047, "compression_ratio": 1.7417840375586855, "no_speech_prob": 3.138141664749128e-06}, {"id": 130, "seek": 93236, "start": 938.6, "end": 946.6, "text": " we'll call this one zero and this one one and so forth. Right. So the kind of the int to string", "tokens": [50676, 321, 603, 818, 341, 472, 4018, 293, 341, 472, 472, 293, 370, 5220, 13, 1779, 13, 407, 264, 733, 295, 264, 560, 281, 6798, 51076], "temperature": 0.0, "avg_logprob": -0.2453617132627047, "compression_ratio": 1.7417840375586855, "no_speech_prob": 3.138141664749128e-06}, {"id": 131, "seek": 93236, "start": 946.6, "end": 953.16, "text": " or ID to string version of this is literally this list. So zero will be that, that, but the string", "tokens": [51076, 420, 7348, 281, 6798, 3037, 295, 341, 307, 3736, 341, 1329, 13, 407, 4018, 486, 312, 300, 11, 300, 11, 457, 264, 6798, 51404], "temperature": 0.0, "avg_logprob": -0.2453617132627047, "compression_ratio": 1.7417840375586855, "no_speech_prob": 3.138141664749128e-06}, {"id": 132, "seek": 93236, "start": 953.16, "end": 958.76, "text": " to int version, we do this all the time, is basically enumerate. So that gives us the", "tokens": [51404, 281, 560, 3037, 11, 321, 360, 341, 439, 264, 565, 11, 307, 1936, 465, 15583, 473, 13, 407, 300, 2709, 505, 264, 51684], "temperature": 0.0, "avg_logprob": -0.2453617132627047, "compression_ratio": 1.7417840375586855, "no_speech_prob": 3.138141664749128e-06}, {"id": 133, "seek": 95876, "start": 959.64, "end": 961.96, "text": " index and the value for everything in the list.", "tokens": [50408, 8186, 293, 264, 2158, 337, 1203, 294, 264, 1329, 13, 50524], "temperature": 0.0, "avg_logprob": -0.20862031537433004, "compression_ratio": 1.6796116504854368, "no_speech_prob": 2.7108764697914012e-05}, {"id": 134, "seek": 95876, "start": 963.48, "end": 967.08, "text": " So those are going to be our keys and values, but actually we're going to invert it to become", "tokens": [50600, 407, 729, 366, 516, 281, 312, 527, 9317, 293, 4190, 11, 457, 767, 321, 434, 516, 281, 33966, 309, 281, 1813, 50780], "temperature": 0.0, "avg_logprob": -0.20862031537433004, "compression_ratio": 1.6796116504854368, "no_speech_prob": 2.7108764697914012e-05}, {"id": 135, "seek": 95876, "start": 967.08, "end": 976.68, "text": " value colon key. And that's what str2id will be. So note here that we have a dictionary comprehension.", "tokens": [50780, 2158, 8255, 2141, 13, 400, 300, 311, 437, 1056, 17, 327, 486, 312, 13, 407, 3637, 510, 300, 321, 362, 257, 25890, 44991, 13, 51260], "temperature": 0.0, "avg_logprob": -0.20862031537433004, "compression_ratio": 1.6796116504854368, "no_speech_prob": 2.7108764697914012e-05}, {"id": 136, "seek": 95876, "start": 976.68, "end": 983.3199999999999, "text": " You can tell because it's got curly brackets and a colon. And so here's our dictionary comprehension.", "tokens": [51260, 509, 393, 980, 570, 309, 311, 658, 32066, 26179, 293, 257, 8255, 13, 400, 370, 510, 311, 527, 25890, 44991, 13, 51592], "temperature": 0.0, "avg_logprob": -0.20862031537433004, "compression_ratio": 1.6796116504854368, "no_speech_prob": 2.7108764697914012e-05}, {"id": 137, "seek": 98332, "start": 983.32, "end": 989.72, "text": " So we could have used that for this as well. We could have done a dictionary comprehension", "tokens": [50364, 407, 321, 727, 362, 1143, 300, 337, 341, 382, 731, 13, 492, 727, 362, 1096, 257, 25890, 44991, 50684], "temperature": 0.0, "avg_logprob": -0.3364693998086332, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0002002715482376516}, {"id": 138, "seek": 98332, "start": 991.08, "end": 996.2, "text": " instead, but yeah. So there's lots of ways of doing things. None of them is any better or worse", "tokens": [50752, 2602, 11, 457, 1338, 13, 407, 456, 311, 3195, 295, 2098, 295, 884, 721, 13, 14492, 295, 552, 307, 604, 1101, 420, 5324, 51008], "temperature": 0.0, "avg_logprob": -0.3364693998086332, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0002002715482376516}, {"id": 139, "seek": 98332, "start": 996.2, "end": 1004.6, "text": " than any other. Okay. So that's something that... Is the, those wordnet tags or whatever, do we have", "tokens": [51008, 813, 604, 661, 13, 1033, 13, 407, 300, 311, 746, 300, 485, 1119, 264, 11, 729, 1349, 7129, 18632, 420, 2035, 11, 360, 321, 362, 51428], "temperature": 0.0, "avg_logprob": -0.3364693998086332, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0002002715482376516}, {"id": 140, "seek": 98332, "start": 1004.6, "end": 1009.48, "text": " the names for them or is that something external that we have to get? Yes. The names I'm going to", "tokens": [51428, 264, 5288, 337, 552, 420, 307, 300, 746, 8320, 300, 321, 362, 281, 483, 30, 1079, 13, 440, 5288, 286, 478, 516, 281, 51672], "temperature": 0.0, "avg_logprob": -0.3364693998086332, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0002002715482376516}, {"id": 141, "seek": 100948, "start": 1009.48, "end": 1017.88, "text": " get to. Yes, shortly. There's a word.text. So, yeah. All right. I grabbed one batch of data", "tokens": [50364, 483, 281, 13, 1079, 11, 13392, 13, 821, 311, 257, 1349, 13, 25111, 13, 407, 11, 1338, 13, 1057, 558, 13, 286, 18607, 472, 15245, 295, 1412, 50784], "temperature": 0.0, "avg_logprob": -0.23914672333059958, "compression_ratio": 1.5397489539748954, "no_speech_prob": 5.064237484475598e-05}, {"id": 142, "seek": 100948, "start": 1017.88, "end": 1022.52, "text": " and grabbed its mean and standard deviation. And so then I've just copied and pasted them in here", "tokens": [50784, 293, 18607, 1080, 914, 293, 3832, 25163, 13, 400, 370, 550, 286, 600, 445, 25365, 293, 1791, 292, 552, 294, 510, 51016], "temperature": 0.0, "avg_logprob": -0.23914672333059958, "compression_ratio": 1.5397489539748954, "no_speech_prob": 5.064237484475598e-05}, {"id": 143, "seek": 100948, "start": 1023.24, "end": 1029.8, "text": " for normalizing. So my, my transform X is going to be, I'm going to read the image.", "tokens": [51052, 337, 2710, 3319, 13, 407, 452, 11, 452, 4088, 1783, 307, 516, 281, 312, 11, 286, 478, 516, 281, 1401, 264, 3256, 13, 51380], "temperature": 0.0, "avg_logprob": -0.23914672333059958, "compression_ratio": 1.5397489539748954, "no_speech_prob": 5.064237484475598e-05}, {"id": 144, "seek": 100948, "start": 1032.68, "end": 1037.56, "text": " If you read it as RGB, that's going to force it to be three channels, because actually some of", "tokens": [51524, 759, 291, 1401, 309, 382, 31231, 11, 300, 311, 516, 281, 3464, 309, 281, 312, 1045, 9235, 11, 570, 767, 512, 295, 51768], "temperature": 0.0, "avg_logprob": -0.23914672333059958, "compression_ratio": 1.5397489539748954, "no_speech_prob": 5.064237484475598e-05}, {"id": 145, "seek": 103756, "start": 1037.56, "end": 1044.04, "text": " them are only one channel. Divide it by 255. So it'd be between zero and one. And then we will", "tokens": [50364, 552, 366, 787, 472, 2269, 13, 9886, 482, 309, 538, 3552, 20, 13, 407, 309, 1116, 312, 1296, 4018, 293, 472, 13, 400, 550, 321, 486, 50688], "temperature": 0.0, "avg_logprob": -0.24138370561011044, "compression_ratio": 1.469387755102041, "no_speech_prob": 1.370956397295231e-06}, {"id": 146, "seek": 103756, "start": 1044.04, "end": 1054.28, "text": " normalize. And then for our Ys, we will go through strd id to get the ID and just use that as our", "tokens": [50688, 2710, 1125, 13, 400, 550, 337, 527, 398, 82, 11, 321, 486, 352, 807, 1056, 67, 4496, 281, 483, 264, 7348, 293, 445, 764, 300, 382, 527, 51200], "temperature": 0.0, "avg_logprob": -0.24138370561011044, "compression_ratio": 1.469387755102041, "no_speech_prob": 1.370956397295231e-06}, {"id": 147, "seek": 103756, "start": 1054.28, "end": 1061.08, "text": " tensor. So it's, you know, doing it manually is actually pretty straightforward, right? Because", "tokens": [51200, 40863, 13, 407, 309, 311, 11, 291, 458, 11, 884, 309, 16945, 307, 767, 1238, 15325, 11, 558, 30, 1436, 51540], "temperature": 0.0, "avg_logprob": -0.24138370561011044, "compression_ratio": 1.469387755102041, "no_speech_prob": 1.370956397295231e-06}, {"id": 148, "seek": 106108, "start": 1061.08, "end": 1069.24, "text": " now we just pass those to our TwfmDS, our transformed data set. And we can check that,", "tokens": [50364, 586, 321, 445, 1320, 729, 281, 527, 2574, 69, 76, 11844, 11, 527, 16894, 1412, 992, 13, 400, 321, 393, 1520, 300, 11, 50772], "temperature": 0.0, "avg_logprob": -0.26949424743652345, "compression_ratio": 1.3768115942028984, "no_speech_prob": 1.77784932020586e-05}, {"id": 149, "seek": 106108, "start": 1070.1999999999998, "end": 1074.28, "text": " you know, you can see YI", "tokens": [50820, 291, 458, 11, 291, 393, 536, 398, 40, 51024], "temperature": 0.0, "avg_logprob": -0.26949424743652345, "compression_ratio": 1.3768115942028984, "no_speech_prob": 1.77784932020586e-05}, {"id": 150, "seek": 106108, "start": 1077.24, "end": 1086.1999999999998, "text": " is a tensor, but we can look it up to get its value. And Xi is an image tensor", "tokens": [51172, 307, 257, 40863, 11, 457, 321, 393, 574, 309, 493, 281, 483, 1080, 2158, 13, 400, 15712, 307, 364, 3256, 40863, 51620], "temperature": 0.0, "avg_logprob": -0.26949424743652345, "compression_ratio": 1.3768115942028984, "no_speech_prob": 1.77784932020586e-05}, {"id": 151, "seek": 108620, "start": 1086.8400000000001, "end": 1096.04, "text": " with three channels. So channel by height by width has its normal for PyTorch.", "tokens": [50396, 365, 1045, 9235, 13, 407, 2269, 538, 6681, 538, 11402, 575, 1080, 2710, 337, 9953, 51, 284, 339, 13, 50856], "temperature": 0.0, "avg_logprob": -0.25223980779233185, "compression_ratio": 1.5222929936305734, "no_speech_prob": 5.7719139476830605e-06}, {"id": 152, "seek": 108620, "start": 1097.88, "end": 1102.3600000000001, "text": " So for showing images, it's nice to denormalize them. So that's just denormalizing.", "tokens": [50948, 407, 337, 4099, 5267, 11, 309, 311, 1481, 281, 1441, 24440, 1125, 552, 13, 407, 300, 311, 445, 1441, 24440, 3319, 13, 51172], "temperature": 0.0, "avg_logprob": -0.25223980779233185, "compression_ratio": 1.5222929936305734, "no_speech_prob": 5.7719139476830605e-06}, {"id": 153, "seek": 108620, "start": 1103.96, "end": 1111.16, "text": " And so if we show the image that we just grabbed, it's a water jug, I guess.", "tokens": [51252, 400, 370, 498, 321, 855, 264, 3256, 300, 321, 445, 18607, 11, 309, 311, 257, 1281, 9568, 11, 286, 2041, 13, 51612], "temperature": 0.0, "avg_logprob": -0.25223980779233185, "compression_ratio": 1.5222929936305734, "no_speech_prob": 5.7719139476830605e-06}, {"id": 154, "seek": 111620, "start": 1116.2, "end": 1121.0800000000002, "text": " All right, so now we can create a data loader for our training set. So that's going to contain our", "tokens": [50364, 1057, 558, 11, 370, 586, 321, 393, 1884, 257, 1412, 3677, 260, 337, 527, 3097, 992, 13, 407, 300, 311, 516, 281, 5304, 527, 50608], "temperature": 0.0, "avg_logprob": -0.22759880254298082, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.927844716145046e-07}, {"id": 155, "seek": 111620, "start": 1121.8, "end": 1127.96, "text": " transformed training data set, and pass in a batch size. This one has to be shuffled.", "tokens": [50644, 16894, 3097, 1412, 992, 11, 293, 1320, 294, 257, 15245, 2744, 13, 639, 472, 575, 281, 312, 402, 33974, 13, 50952], "temperature": 0.0, "avg_logprob": -0.22759880254298082, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.927844716145046e-07}, {"id": 156, "seek": 111620, "start": 1131.0800000000002, "end": 1133.48, "text": " Not sure where I put numWorkers equals zero there.", "tokens": [51108, 1726, 988, 689, 286, 829, 1031, 28846, 433, 6915, 4018, 456, 13, 51228], "temperature": 0.0, "avg_logprob": -0.22759880254298082, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.927844716145046e-07}, {"id": 157, "seek": 111620, "start": 1135.96, "end": 1138.2, "text": " Generally eight's pretty good, if you've got at least eight cores.", "tokens": [51352, 21082, 3180, 311, 1238, 665, 11, 498, 291, 600, 658, 412, 1935, 3180, 24826, 13, 51464], "temperature": 0.0, "avg_logprob": -0.22759880254298082, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.927844716145046e-07}, {"id": 158, "seek": 113820, "start": 1138.68, "end": 1141.96, "text": " Yeah, so we can now grab an X batch and a Y batch,", "tokens": [50388, 865, 11, 370, 321, 393, 586, 4444, 364, 1783, 15245, 293, 257, 398, 15245, 11, 50552], "temperature": 0.0, "avg_logprob": -0.3355727528416833, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.77781857928494e-05}, {"id": 159, "seek": 113820, "start": 1143.64, "end": 1147.96, "text": " and take a look at a denormalized image from there. So there we've got a nice little kitty cat.", "tokens": [50636, 293, 747, 257, 574, 412, 257, 1441, 24440, 1602, 3256, 490, 456, 13, 407, 456, 321, 600, 658, 257, 1481, 707, 33026, 3857, 13, 50852], "temperature": 0.0, "avg_logprob": -0.3355727528416833, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.77781857928494e-05}, {"id": 160, "seek": 113820, "start": 1150.52, "end": 1153.56, "text": " So I think this is already looking better than Fashion MNIST.", "tokens": [50980, 407, 286, 519, 341, 307, 1217, 1237, 1101, 813, 32782, 376, 45, 19756, 13, 51132], "temperature": 0.0, "avg_logprob": -0.3355727528416833, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.77781857928494e-05}, {"id": 161, "seek": 113820, "start": 1156.28, "end": 1163.64, "text": " Yeah, so there's this thing, words.text, that they've also provided. And this is actually a", "tokens": [51268, 865, 11, 370, 456, 311, 341, 551, 11, 2283, 13, 25111, 11, 300, 436, 600, 611, 5649, 13, 400, 341, 307, 767, 257, 51636], "temperature": 0.0, "avg_logprob": -0.3355727528416833, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.77781857928494e-05}, {"id": 162, "seek": 116364, "start": 1164.0400000000002, "end": 1174.2, "text": " list of the entire WordNet hierarchy. So the top of the hierarchy is entity,", "tokens": [50384, 1329, 295, 264, 2302, 8725, 31890, 22333, 13, 407, 264, 1192, 295, 264, 22333, 307, 13977, 11, 50892], "temperature": 0.0, "avg_logprob": -0.2305200764390289, "compression_ratio": 1.6058394160583942, "no_speech_prob": 6.85427676216932e-06}, {"id": 163, "seek": 116364, "start": 1174.2, "end": 1177.48, "text": " and one of the entity types is a physical entity, or an abstract entity.", "tokens": [50892, 293, 472, 295, 264, 13977, 3467, 307, 257, 4001, 13977, 11, 420, 364, 12649, 13977, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2305200764390289, "compression_ratio": 1.6058394160583942, "no_speech_prob": 6.85427676216932e-06}, {"id": 164, "seek": 116364, "start": 1178.6000000000001, "end": 1185.8000000000002, "text": " Entities can be things, and so forth. So this is how WordNet is, yeah,", "tokens": [51112, 3951, 1088, 393, 312, 721, 11, 293, 370, 5220, 13, 407, 341, 307, 577, 8725, 31890, 307, 11, 1338, 11, 51472], "temperature": 0.0, "avg_logprob": -0.2305200764390289, "compression_ratio": 1.6058394160583942, "no_speech_prob": 6.85427676216932e-06}, {"id": 165, "seek": 118580, "start": 1186.52, "end": 1196.12, "text": " handled. So this is quite a big file actually. So if we go through each item of that file,", "tokens": [50400, 18033, 13, 407, 341, 307, 1596, 257, 955, 3991, 767, 13, 407, 498, 321, 352, 807, 1184, 3174, 295, 300, 3991, 11, 50880], "temperature": 0.0, "avg_logprob": -0.21996500720716503, "compression_ratio": 1.526946107784431, "no_speech_prob": 1.4593413197871996e-06}, {"id": 166, "seek": 118580, "start": 1196.12, "end": 1205.3999999999999, "text": " and again split on tabs, because split on tabs, that's what backslash t means,", "tokens": [50880, 293, 797, 7472, 322, 20743, 11, 570, 7472, 322, 20743, 11, 300, 311, 437, 646, 10418, 1299, 256, 1355, 11, 51344], "temperature": 0.0, "avg_logprob": -0.21996500720716503, "compression_ratio": 1.526946107784431, "no_speech_prob": 1.4593413197871996e-06}, {"id": 167, "seek": 118580, "start": 1205.3999999999999, "end": 1211.96, "text": " is going to give us the WordNet ID, and then the name of it. So now we can go through", "tokens": [51344, 307, 516, 281, 976, 505, 264, 8725, 31890, 7348, 11, 293, 550, 264, 1315, 295, 309, 13, 407, 586, 321, 393, 352, 807, 51672], "temperature": 0.0, "avg_logprob": -0.21996500720716503, "compression_ratio": 1.526946107784431, "no_speech_prob": 1.4593413197871996e-06}, {"id": 168, "seek": 121196, "start": 1212.6000000000001, "end": 1219.96, "text": " all of those. They call them sinsets. And if the key is in our list of the 200 that we want,", "tokens": [50396, 439, 295, 729, 13, 814, 818, 552, 13815, 1385, 13, 400, 498, 264, 2141, 307, 294, 527, 1329, 295, 264, 2331, 300, 321, 528, 11, 50764], "temperature": 0.0, "avg_logprob": -0.3233657582600911, "compression_ratio": 1.5465116279069768, "no_speech_prob": 4.468952101888135e-05}, {"id": 169, "seek": 121196, "start": 1219.96, "end": 1230.04, "text": " we'll keep it. And we don't really want like causal agent, comma, cause, comma, causal agency.", "tokens": [50764, 321, 603, 1066, 309, 13, 400, 321, 500, 380, 534, 528, 411, 38755, 9461, 11, 22117, 11, 3082, 11, 22117, 11, 38755, 7934, 13, 51268], "temperature": 0.0, "avg_logprob": -0.3233657582600911, "compression_ratio": 1.5465116279069768, "no_speech_prob": 4.468952101888135e-05}, {"id": 170, "seek": 121196, "start": 1230.04, "end": 1235.72, "text": " The first one generally seems to be the most normal. So I just split on comma,", "tokens": [51268, 440, 700, 472, 5101, 2544, 281, 312, 264, 881, 2710, 13, 407, 286, 445, 7472, 322, 22117, 11, 51552], "temperature": 0.0, "avg_logprob": -0.3233657582600911, "compression_ratio": 1.5465116279069768, "no_speech_prob": 4.468952101888135e-05}, {"id": 171, "seek": 123572, "start": 1235.8, "end": 1239.48, "text": " split on comma, and grab the first one.", "tokens": [50368, 7472, 322, 22117, 11, 293, 4444, 264, 700, 472, 13, 50552], "temperature": 0.0, "avg_logprob": -0.26884735331815834, "compression_ratio": 1.5743243243243243, "no_speech_prob": 4.637822712538764e-06}, {"id": 172, "seek": 123572, "start": 1244.44, "end": 1251.64, "text": " All right, so that's, so we could then go through our y-batch, and just turn each of those numbers", "tokens": [50800, 1057, 558, 11, 370, 300, 311, 11, 370, 321, 727, 550, 352, 807, 527, 288, 12, 65, 852, 11, 293, 445, 1261, 1184, 295, 729, 3547, 51160], "temperature": 0.0, "avg_logprob": -0.26884735331815834, "compression_ratio": 1.5743243243243243, "no_speech_prob": 4.637822712538764e-06}, {"id": 173, "seek": 123572, "start": 1251.64, "end": 1257.56, "text": " into strings, and then look at each of those up in our sinsets, and join them up, and then use", "tokens": [51160, 666, 13985, 11, 293, 550, 574, 412, 1184, 295, 729, 493, 294, 527, 13815, 1385, 11, 293, 3917, 552, 493, 11, 293, 550, 764, 51456], "temperature": 0.0, "avg_logprob": -0.26884735331815834, "compression_ratio": 1.5743243243243243, "no_speech_prob": 4.637822712538764e-06}, {"id": 174, "seek": 125756, "start": 1257.56, "end": 1265.72, "text": " those as titles to see our Egyptian cat, and our cliff, and our guacamole, it's a monarch butterfly,", "tokens": [50364, 729, 382, 12992, 281, 536, 527, 24257, 3857, 11, 293, 527, 22316, 11, 293, 527, 695, 47190, 4812, 11, 309, 311, 257, 33658, 22140, 11, 50772], "temperature": 0.0, "avg_logprob": -0.21915123841472875, "compression_ratio": 1.6719367588932805, "no_speech_prob": 0.0009253395837731659}, {"id": 175, "seek": 125756, "start": 1266.9199999999998, "end": 1271.56, "text": " and so forth. And you can see that this is going to be quite tricky, because like a cliff", "tokens": [50832, 293, 370, 5220, 13, 400, 291, 393, 536, 300, 341, 307, 516, 281, 312, 1596, 12414, 11, 570, 411, 257, 22316, 51064], "temperature": 0.0, "avg_logprob": -0.21915123841472875, "compression_ratio": 1.6719367588932805, "no_speech_prob": 0.0009253395837731659}, {"id": 176, "seek": 125756, "start": 1271.56, "end": 1276.28, "text": " versus a cliff dwelling, for instance, could be quite, you know, complicated.", "tokens": [51064, 5717, 257, 22316, 41750, 11, 337, 5197, 11, 727, 312, 1596, 11, 291, 458, 11, 6179, 13, 51300], "temperature": 0.0, "avg_logprob": -0.21915123841472875, "compression_ratio": 1.6719367588932805, "no_speech_prob": 0.0009253395837731659}, {"id": 177, "seek": 125756, "start": 1278.44, "end": 1281.56, "text": " I have a feeling for this, they intentionally, like a hundred of the", "tokens": [51408, 286, 362, 257, 2633, 337, 341, 11, 436, 22062, 11, 411, 257, 3262, 295, 264, 51564], "temperature": 0.0, "avg_logprob": -0.21915123841472875, "compression_ratio": 1.6719367588932805, "no_speech_prob": 0.0009253395837731659}, {"id": 178, "seek": 125756, "start": 1283.6399999999999, "end": 1286.52, "text": " categories might have come from the normal ImageNet, and I think they might have then", "tokens": [51668, 10479, 1062, 362, 808, 490, 264, 2710, 29903, 31890, 11, 293, 286, 519, 436, 1062, 362, 550, 51812], "temperature": 0.0, "avg_logprob": -0.21915123841472875, "compression_ratio": 1.6719367588932805, "no_speech_prob": 0.0009253395837731659}, {"id": 179, "seek": 128652, "start": 1286.52, "end": 1292.2, "text": " picked a hundred that are designed to be particularly difficult, or something, if memory serves correctly.", "tokens": [50364, 6183, 257, 3262, 300, 366, 4761, 281, 312, 4098, 2252, 11, 420, 746, 11, 498, 4675, 13451, 8944, 13, 50648], "temperature": 0.0, "avg_logprob": -0.25765126943588257, "compression_ratio": 1.4802259887005649, "no_speech_prob": 2.1233686311461497e-06}, {"id": 180, "seek": 128652, "start": 1294.76, "end": 1300.92, "text": " All right, so then we could define a transform batch function, with the same basic idea.", "tokens": [50776, 1057, 558, 11, 370, 550, 321, 727, 6964, 257, 4088, 15245, 2445, 11, 365, 264, 912, 3875, 1558, 13, 51084], "temperature": 0.0, "avg_logprob": -0.25765126943588257, "compression_ratio": 1.4802259887005649, "no_speech_prob": 2.1233686311461497e-06}, {"id": 181, "seek": 128652, "start": 1302.76, "end": 1307.48, "text": " And that's just gonna, yeah, transform the x and the y in a batch.", "tokens": [51176, 400, 300, 311, 445, 799, 11, 1338, 11, 4088, 264, 2031, 293, 264, 288, 294, 257, 15245, 13, 51412], "temperature": 0.0, "avg_logprob": -0.25765126943588257, "compression_ratio": 1.4802259887005649, "no_speech_prob": 2.1233686311461497e-06}, {"id": 182, "seek": 130748, "start": 1308.44, "end": 1316.76, "text": " Oh yes, we're about to use that, I should move that down a bit, because we're not quite there yet.", "tokens": [50412, 876, 2086, 11, 321, 434, 466, 281, 764, 300, 11, 286, 820, 1286, 300, 760, 257, 857, 11, 570, 321, 434, 406, 1596, 456, 1939, 13, 50828], "temperature": 0.0, "avg_logprob": -0.2060506552980657, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.00013134749315213412}, {"id": 183, "seek": 130748, "start": 1317.32, "end": 1323.96, "text": " Okay, so before that, we can create our data loaders. We created a getDls back in an earlier lesson,", "tokens": [50856, 1033, 11, 370, 949, 300, 11, 321, 393, 1884, 527, 1412, 3677, 433, 13, 492, 2942, 257, 483, 35, 11784, 646, 294, 364, 3071, 6898, 11, 51188], "temperature": 0.0, "avg_logprob": -0.2060506552980657, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.00013134749315213412}, {"id": 184, "seek": 130748, "start": 1323.96, "end": 1328.52, "text": " which simply turns that into a data loader, and that into a data loader, and this one gets", "tokens": [51188, 597, 2935, 4523, 300, 666, 257, 1412, 3677, 260, 11, 293, 300, 666, 257, 1412, 3677, 260, 11, 293, 341, 472, 2170, 51416], "temperature": 0.0, "avg_logprob": -0.2060506552980657, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.00013134749315213412}, {"id": 185, "seek": 130748, "start": 1328.52, "end": 1334.28, "text": " shuffled, and that one doesn't, and so forth. Oh, I see, this is where we do our numWorkers. Cool.", "tokens": [51416, 402, 33974, 11, 293, 300, 472, 1177, 380, 11, 293, 370, 5220, 13, 876, 11, 286, 536, 11, 341, 307, 689, 321, 360, 527, 1031, 28846, 433, 13, 8561, 13, 51704], "temperature": 0.0, "avg_logprob": -0.2060506552980657, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.00013134749315213412}, {"id": 186, "seek": 133428, "start": 1334.36, "end": 1346.92, "text": " All right, so then, oh yeah, so then we want to add our data augmentation. So I noticed that", "tokens": [50368, 1057, 558, 11, 370, 550, 11, 1954, 1338, 11, 370, 550, 321, 528, 281, 909, 527, 1412, 14501, 19631, 13, 407, 286, 5694, 300, 50996], "temperature": 0.0, "avg_logprob": -0.33080217573377824, "compression_ratio": 1.326086956521739, "no_speech_prob": 4.356811587058473e-06}, {"id": 187, "seek": 133428, "start": 1348.2, "end": 1355.96, "text": " training a tiny ImageNet model, I mean, it's a much harder thing to do than fashion MNIST,", "tokens": [51060, 3097, 257, 5870, 29903, 31890, 2316, 11, 286, 914, 11, 309, 311, 257, 709, 6081, 551, 281, 360, 813, 6700, 376, 45, 19756, 11, 51448], "temperature": 0.0, "avg_logprob": -0.33080217573377824, "compression_ratio": 1.326086956521739, "no_speech_prob": 4.356811587058473e-06}, {"id": 188, "seek": 135596, "start": 1356.28, "end": 1364.76, "text": " and overfitting was actually a real challenge. And I guess it's because 64 by 64 isn't that many", "tokens": [50380, 293, 670, 69, 2414, 390, 767, 257, 957, 3430, 13, 400, 286, 2041, 309, 311, 570, 12145, 538, 12145, 1943, 380, 300, 867, 50804], "temperature": 0.0, "avg_logprob": -0.34535139885501587, "compression_ratio": 1.4473684210526316, "no_speech_prob": 2.6274665287928656e-05}, {"id": 189, "seek": 135596, "start": 1364.76, "end": 1373.56, "text": " pixels. So yeah, so I found I really needed data augmentation to make much progress at all.", "tokens": [50804, 18668, 13, 407, 1338, 11, 370, 286, 1352, 286, 534, 2978, 1412, 14501, 19631, 281, 652, 709, 4205, 412, 439, 13, 51244], "temperature": 0.0, "avg_logprob": -0.34535139885501587, "compression_ratio": 1.4473684210526316, "no_speech_prob": 2.6274665287928656e-05}, {"id": 190, "seek": 135596, "start": 1374.52, "end": 1381.96, "text": " Now, very common data augmentation is called random resize crop, which is basically to", "tokens": [51292, 823, 11, 588, 2689, 1412, 14501, 19631, 307, 1219, 4974, 50069, 9086, 11, 597, 307, 1936, 281, 51664], "temperature": 0.0, "avg_logprob": -0.34535139885501587, "compression_ratio": 1.4473684210526316, "no_speech_prob": 2.6274665287928656e-05}, {"id": 191, "seek": 138196, "start": 1382.04, "end": 1388.52, "text": " pick one area inside, and zoom into it, and make that your image. But for such low resolution", "tokens": [50368, 1888, 472, 1859, 1854, 11, 293, 8863, 666, 309, 11, 293, 652, 300, 428, 3256, 13, 583, 337, 1270, 2295, 8669, 50692], "temperature": 0.0, "avg_logprob": -0.37056835492451984, "compression_ratio": 1.6157205240174672, "no_speech_prob": 2.3552498532808386e-05}, {"id": 192, "seek": 138196, "start": 1388.52, "end": 1395.16, "text": " images, that tends to work really poorly, because it's going to introduce a lot of blurring artifacts.", "tokens": [50692, 5267, 11, 300, 12258, 281, 589, 534, 22271, 11, 570, 309, 311, 516, 281, 5366, 257, 688, 295, 14257, 2937, 24617, 13, 51024], "temperature": 0.0, "avg_logprob": -0.37056835492451984, "compression_ratio": 1.6157205240174672, "no_speech_prob": 2.3552498532808386e-05}, {"id": 193, "seek": 138196, "start": 1396.2, "end": 1400.92, "text": " So instead, for small images, I think it's better to add a bit of padding around them,", "tokens": [51076, 407, 2602, 11, 337, 1359, 5267, 11, 286, 519, 309, 311, 1101, 281, 909, 257, 857, 295, 39562, 926, 552, 11, 51312], "temperature": 0.0, "avg_logprob": -0.37056835492451984, "compression_ratio": 1.6157205240174672, "no_speech_prob": 2.3552498532808386e-05}, {"id": 194, "seek": 138196, "start": 1402.2, "end": 1407.96, "text": " and then randomly pick a 64 by 64 area from that padded area. So it's just going to be", "tokens": [51376, 293, 550, 16979, 1888, 257, 12145, 538, 12145, 1859, 490, 300, 6887, 9207, 1859, 13, 407, 309, 311, 445, 516, 281, 312, 51664], "temperature": 0.0, "avg_logprob": -0.37056835492451984, "compression_ratio": 1.6157205240174672, "no_speech_prob": 2.3552498532808386e-05}, {"id": 195, "seek": 140796, "start": 1408.76, "end": 1414.44, "text": " a 64 by 64 area from that padded area. So it's just going to shift them slightly. It's not a lot", "tokens": [50404, 257, 12145, 538, 12145, 1859, 490, 300, 6887, 9207, 1859, 13, 407, 309, 311, 445, 516, 281, 5513, 552, 4748, 13, 467, 311, 406, 257, 688, 50688], "temperature": 0.0, "avg_logprob": -0.21065306412546259, "compression_ratio": 1.644736842105263, "no_speech_prob": 2.2827976863482036e-05}, {"id": 196, "seek": 140796, "start": 1414.44, "end": 1419.56, "text": " of augmentation, but it's something. And then we do our random horizontal flips, and then we'll", "tokens": [50688, 295, 14501, 19631, 11, 457, 309, 311, 746, 13, 400, 550, 321, 360, 527, 4974, 12750, 40249, 11, 293, 550, 321, 603, 50944], "temperature": 0.0, "avg_logprob": -0.21065306412546259, "compression_ratio": 1.644736842105263, "no_speech_prob": 2.2827976863482036e-05}, {"id": 197, "seek": 140796, "start": 1419.56, "end": 1426.28, "text": " use that random erase thing that we created earlier. This is just something I was experimenting", "tokens": [50944, 764, 300, 4974, 23525, 551, 300, 321, 2942, 3071, 13, 639, 307, 445, 746, 286, 390, 29070, 51280], "temperature": 0.0, "avg_logprob": -0.21065306412546259, "compression_ratio": 1.644736842105263, "no_speech_prob": 2.2827976863482036e-05}, {"id": 198, "seek": 140796, "start": 1426.28, "end": 1433.96, "text": " with. So yeah, so now we can use that batch transform callback, using transform batch,", "tokens": [51280, 365, 13, 407, 1338, 11, 370, 586, 321, 393, 764, 300, 15245, 4088, 818, 3207, 11, 1228, 4088, 15245, 11, 51664], "temperature": 0.0, "avg_logprob": -0.21065306412546259, "compression_ratio": 1.644736842105263, "no_speech_prob": 2.2827976863482036e-05}, {"id": 199, "seek": 143396, "start": 1433.96, "end": 1442.68, "text": " passing in those transforms. So with torch vision transforms, so this capital T is torch", "tokens": [50364, 8437, 294, 729, 35592, 13, 407, 365, 27822, 5201, 35592, 11, 370, 341, 4238, 314, 307, 27822, 50800], "temperature": 0.0, "avg_logprob": -0.2130142289239007, "compression_ratio": 1.5536723163841808, "no_speech_prob": 5.7719062169780955e-06}, {"id": 200, "seek": 143396, "start": 1442.68, "end": 1451.8, "text": " vision transforms. Yeah, because these are all nn.modules, you can pass them to nn.sequential,", "tokens": [50800, 5201, 35592, 13, 865, 11, 570, 613, 366, 439, 297, 77, 13, 8014, 3473, 11, 291, 393, 1320, 552, 281, 297, 77, 13, 11834, 2549, 11, 51256], "temperature": 0.0, "avg_logprob": -0.2130142289239007, "compression_ratio": 1.5536723163841808, "no_speech_prob": 5.7719062169780955e-06}, {"id": 201, "seek": 143396, "start": 1451.8, "end": 1458.2, "text": " to just have each of them called one at a time, in a row. There's nothing magic about this,", "tokens": [51256, 281, 445, 362, 1184, 295, 552, 1219, 472, 412, 257, 565, 11, 294, 257, 5386, 13, 821, 311, 1825, 5585, 466, 341, 11, 51576], "temperature": 0.0, "avg_logprob": -0.2130142289239007, "compression_ratio": 1.5536723163841808, "no_speech_prob": 5.7719062169780955e-06}, {"id": 202, "seek": 145820, "start": 1458.2, "end": 1462.68, "text": " it's just doing function composition. We could easily create our own.", "tokens": [50364, 309, 311, 445, 884, 2445, 12686, 13, 492, 727, 3612, 1884, 527, 1065, 13, 50588], "temperature": 0.0, "avg_logprob": -0.29651114228483916, "compression_ratio": 1.5, "no_speech_prob": 0.000579158659093082}, {"id": 203, "seek": 145820, "start": 1466.92, "end": 1472.68, "text": " In fact, there's also the transforms.compose, that does the same thing. Yeah, I was going to say,", "tokens": [50800, 682, 1186, 11, 456, 311, 611, 264, 35592, 13, 21541, 541, 11, 300, 775, 264, 912, 551, 13, 865, 11, 286, 390, 516, 281, 584, 11, 51088], "temperature": 0.0, "avg_logprob": -0.29651114228483916, "compression_ratio": 1.5, "no_speech_prob": 0.000579158659093082}, {"id": 204, "seek": 145820, "start": 1472.68, "end": 1483.64, "text": " so we've got a fast, fastcore.compose, which as you can see, basically it just says for f in funcs,", "tokens": [51088, 370, 321, 600, 658, 257, 2370, 11, 2370, 12352, 13, 21541, 541, 11, 597, 382, 291, 393, 536, 11, 1936, 309, 445, 1619, 337, 283, 294, 1019, 14368, 11, 51636], "temperature": 0.0, "avg_logprob": -0.29651114228483916, "compression_ratio": 1.5, "no_speech_prob": 0.000579158659093082}, {"id": 205, "seek": 148364, "start": 1483.64, "end": 1492.76, "text": " x equals f of x. Yeah, I don't know, is there, is there's a, yeah torch, torch vision compose,", "tokens": [50364, 2031, 6915, 283, 295, 2031, 13, 865, 11, 286, 500, 380, 458, 11, 307, 456, 11, 307, 456, 311, 257, 11, 1338, 27822, 11, 27822, 5201, 35925, 11, 50820], "temperature": 0.0, "avg_logprob": -0.20247420486138792, "compression_ratio": 1.5454545454545454, "no_speech_prob": 7.88919351180084e-06}, {"id": 206, "seek": 148364, "start": 1493.4, "end": 1498.2800000000002, "text": " I think might be kind of the old way to do it. Is that right? I'm not sure. I have a feeling", "tokens": [50852, 286, 519, 1062, 312, 733, 295, 264, 1331, 636, 281, 360, 309, 13, 1119, 300, 558, 30, 286, 478, 406, 988, 13, 286, 362, 257, 2633, 51096], "temperature": 0.0, "avg_logprob": -0.20247420486138792, "compression_ratio": 1.5454545454545454, "no_speech_prob": 7.88919351180084e-06}, {"id": 207, "seek": 148364, "start": 1498.2800000000002, "end": 1501.24, "text": " maybe this is considered the better way now, because it's kind of scriptable.", "tokens": [51096, 1310, 341, 307, 4888, 264, 1101, 636, 586, 11, 570, 309, 311, 733, 295, 5755, 712, 13, 51244], "temperature": 0.0, "avg_logprob": -0.20247420486138792, "compression_ratio": 1.5454545454545454, "no_speech_prob": 7.88919351180084e-06}, {"id": 208, "seek": 148364, "start": 1502.0400000000002, "end": 1507.4, "text": " I'm not promising that though. But yeah, it does basically the same thing.", "tokens": [51284, 286, 478, 406, 20257, 300, 1673, 13, 583, 1338, 11, 309, 775, 1936, 264, 912, 551, 13, 51552], "temperature": 0.0, "avg_logprob": -0.20247420486138792, "compression_ratio": 1.5454545454545454, "no_speech_prob": 7.88919351180084e-06}, {"id": 209, "seek": 150740, "start": 1508.1200000000001, "end": 1512.76, "text": " Okay, so yeah, we can now create a model as usual.", "tokens": [50400, 1033, 11, 370, 1338, 11, 321, 393, 586, 1884, 257, 2316, 382, 7713, 13, 50632], "temperature": 0.0, "avg_logprob": -0.4585492203875286, "compression_ratio": 1.3333333333333333, "no_speech_prob": 2.840928573277779e-05}, {"id": 210, "seek": 150740, "start": 1517.8000000000002, "end": 1526.6000000000001, "text": " Okay, so basically I copied the get model with dropout, get drop model from our earlier tiny,", "tokens": [50884, 1033, 11, 370, 1936, 286, 25365, 264, 483, 2316, 365, 3270, 346, 11, 483, 3270, 2316, 490, 527, 3071, 5870, 11, 51324], "temperature": 0.0, "avg_logprob": -0.4585492203875286, "compression_ratio": 1.3333333333333333, "no_speech_prob": 2.840928573277779e-05}, {"id": 211, "seek": 152660, "start": 1526.9199999999998, "end": 1531.56, "text": " sorry, our earlier fashion MNIST stuff.", "tokens": [50380, 2597, 11, 527, 3071, 6700, 376, 45, 19756, 1507, 13, 50612], "temperature": 0.0, "avg_logprob": -0.37398298163163035, "compression_ratio": 1.1565217391304348, "no_speech_prob": 9.313776536146179e-05}, {"id": 212, "seek": 152660, "start": 1534.9199999999998, "end": 1543.1599999999999, "text": " And I, yeah, started with kernel size five convolution, and then yeah, a bunch of res blocks.", "tokens": [50780, 400, 286, 11, 1338, 11, 1409, 365, 28256, 2744, 1732, 45216, 11, 293, 550, 1338, 11, 257, 3840, 295, 725, 8474, 13, 51192], "temperature": 0.0, "avg_logprob": -0.37398298163163035, "compression_ratio": 1.1565217391304348, "no_speech_prob": 9.313776536146179e-05}, {"id": 213, "seek": 154316, "start": 1543.16, "end": 1558.92, "text": " Yeah, so this is all what we're used to seeing before. And so we can take a look in this case,", "tokens": [50364, 865, 11, 370, 341, 307, 439, 437, 321, 434, 1143, 281, 2577, 949, 13, 400, 370, 321, 393, 747, 257, 574, 294, 341, 1389, 11, 51152], "temperature": 0.0, "avg_logprob": -0.26637845357259116, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.00016603682888671756}, {"id": 214, "seek": 154316, "start": 1558.92, "end": 1563.72, "text": " as it's quite often seems to be the case, we accidentally end up with no random erasing.", "tokens": [51152, 382, 309, 311, 1596, 2049, 2544, 281, 312, 264, 1389, 11, 321, 15715, 917, 493, 365, 572, 4974, 1189, 3349, 13, 51392], "temperature": 0.0, "avg_logprob": -0.26637845357259116, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.00016603682888671756}, {"id": 215, "seek": 154316, "start": 1563.72, "end": 1570.2, "text": " Let's just run it again. Really doesn't want to do random erasing. Here we go.", "tokens": [51392, 961, 311, 445, 1190, 309, 797, 13, 4083, 1177, 380, 528, 281, 360, 4974, 1189, 3349, 13, 1692, 321, 352, 13, 51716], "temperature": 0.0, "avg_logprob": -0.26637845357259116, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.00016603682888671756}, {"id": 216, "seek": 157020, "start": 1570.2, "end": 1575.72, "text": " So we can see it. So yeah, there's this very small border you can hardly see sometimes,", "tokens": [50364, 407, 321, 393, 536, 309, 13, 407, 1338, 11, 456, 311, 341, 588, 1359, 7838, 291, 393, 13572, 536, 2171, 11, 50640], "temperature": 0.0, "avg_logprob": -0.22937050606440573, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.2805127880710643e-05}, {"id": 217, "seek": 157020, "start": 1575.72, "end": 1582.28, "text": " and a bit of random erasing. And it's been done, you know, all of the batch is being transformed,", "tokens": [50640, 293, 257, 857, 295, 4974, 1189, 3349, 13, 400, 309, 311, 668, 1096, 11, 291, 458, 11, 439, 295, 264, 15245, 307, 885, 16894, 11, 50968], "temperature": 0.0, "avg_logprob": -0.22937050606440573, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.2805127880710643e-05}, {"id": 218, "seek": 157020, "start": 1582.28, "end": 1591.8, "text": " or augmented in the same way, which is kind of okay. It's certainly faster. It can be a bit of", "tokens": [50968, 420, 36155, 294, 264, 912, 636, 11, 597, 307, 733, 295, 1392, 13, 467, 311, 3297, 4663, 13, 467, 393, 312, 257, 857, 295, 51444], "temperature": 0.0, "avg_logprob": -0.22937050606440573, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.2805127880710643e-05}, {"id": 219, "seek": 157020, "start": 1591.8, "end": 1597.96, "text": " a problem if you have like one batch that has lots and lots and lots of augmentation being done to it.", "tokens": [51444, 257, 1154, 498, 291, 362, 411, 472, 15245, 300, 575, 3195, 293, 3195, 293, 3195, 295, 14501, 19631, 885, 1096, 281, 309, 13, 51752], "temperature": 0.0, "avg_logprob": -0.22937050606440573, "compression_ratio": 1.6437768240343347, "no_speech_prob": 1.2805127880710643e-05}, {"id": 220, "seek": 159796, "start": 1597.96, "end": 1604.6000000000001, "text": " And it could be like really hard to recognize. And that could cause the loss to be a lot in that", "tokens": [50364, 400, 309, 727, 312, 411, 534, 1152, 281, 5521, 13, 400, 300, 727, 3082, 264, 4470, 281, 312, 257, 688, 294, 300, 50696], "temperature": 0.0, "avg_logprob": -0.18874970662225152, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.863125362433493e-05}, {"id": 221, "seek": 159796, "start": 1604.6000000000001, "end": 1610.76, "text": " batch. And if you're like been training for ages, that could kind of jump you out of the,", "tokens": [50696, 15245, 13, 400, 498, 291, 434, 411, 668, 3097, 337, 12357, 11, 300, 727, 733, 295, 3012, 291, 484, 295, 264, 11, 51004], "temperature": 0.0, "avg_logprob": -0.18874970662225152, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.863125362433493e-05}, {"id": 222, "seek": 159796, "start": 1613.88, "end": 1619.48, "text": " you know, the smooth part of the loss surface. That's the one downside of this. So I'm not", "tokens": [51160, 291, 458, 11, 264, 5508, 644, 295, 264, 4470, 3753, 13, 663, 311, 264, 472, 25060, 295, 341, 13, 407, 286, 478, 406, 51440], "temperature": 0.0, "avg_logprob": -0.18874970662225152, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.863125362433493e-05}, {"id": 223, "seek": 159796, "start": 1619.48, "end": 1622.92, "text": " going to say it's always a good idea to do augmentation at batch level, but it can", "tokens": [51440, 516, 281, 584, 309, 311, 1009, 257, 665, 1558, 281, 360, 14501, 19631, 412, 15245, 1496, 11, 457, 309, 393, 51612], "temperature": 0.0, "avg_logprob": -0.18874970662225152, "compression_ratio": 1.6216216216216217, "no_speech_prob": 1.863125362433493e-05}, {"id": 224, "seek": 162292, "start": 1622.92, "end": 1627.5600000000002, "text": " certainly speed things up a lot if you don't have heaps of CPUs.", "tokens": [50364, 3297, 3073, 721, 493, 257, 688, 498, 291, 500, 380, 362, 415, 2382, 295, 13199, 82, 13, 50596], "temperature": 0.0, "avg_logprob": -0.1948310552018412, "compression_ratio": 1.5534883720930233, "no_speech_prob": 3.64783700206317e-05}, {"id": 225, "seek": 162292, "start": 1630.68, "end": 1635.16, "text": " All right, so you can use that summary thing we created. There's our model.", "tokens": [50752, 1057, 558, 11, 370, 291, 393, 764, 300, 12691, 551, 321, 2942, 13, 821, 311, 527, 2316, 13, 50976], "temperature": 0.0, "avg_logprob": -0.1948310552018412, "compression_ratio": 1.5534883720930233, "no_speech_prob": 3.64783700206317e-05}, {"id": 226, "seek": 162292, "start": 1638.2, "end": 1644.76, "text": " And yeah, because we're increasing the, doubling the number of channels as we're decreasing the", "tokens": [51128, 400, 1338, 11, 570, 321, 434, 5662, 264, 11, 33651, 264, 1230, 295, 9235, 382, 321, 434, 23223, 264, 51456], "temperature": 0.0, "avg_logprob": -0.1948310552018412, "compression_ratio": 1.5534883720930233, "no_speech_prob": 3.64783700206317e-05}, {"id": 227, "seek": 162292, "start": 1644.76, "end": 1648.8400000000001, "text": " grid size, our number of megaflops per layer is constant. So that's a pretty good sign that we're", "tokens": [51456, 10748, 2744, 11, 527, 1230, 295, 10816, 2792, 75, 3370, 680, 4583, 307, 5754, 13, 407, 300, 311, 257, 1238, 665, 1465, 300, 321, 434, 51660], "temperature": 0.0, "avg_logprob": -0.1948310552018412, "compression_ratio": 1.5534883720930233, "no_speech_prob": 3.64783700206317e-05}, {"id": 228, "seek": 164884, "start": 1648.84, "end": 1656.04, "text": " using compute throughout. So yeah, then we can train it with AdamW, mixed precision,", "tokens": [50364, 1228, 14722, 3710, 13, 407, 1338, 11, 550, 321, 393, 3847, 309, 365, 7938, 54, 11, 7467, 18356, 11, 50724], "temperature": 0.0, "avg_logprob": -0.27587263107299803, "compression_ratio": 1.330935251798561, "no_speech_prob": 1.4510384971799795e-05}, {"id": 229, "seek": 164884, "start": 1658.4399999999998, "end": 1671.32, "text": " and our augmentations. So I then did the learning rate finder, and trained it for 25 epochs, and got", "tokens": [50844, 293, 527, 29919, 763, 13, 407, 286, 550, 630, 264, 2539, 3314, 915, 260, 11, 293, 8895, 309, 337, 3552, 30992, 28346, 11, 293, 658, 51488], "temperature": 0.0, "avg_logprob": -0.27587263107299803, "compression_ratio": 1.330935251798561, "no_speech_prob": 1.4510384971799795e-05}, {"id": 230, "seek": 167132, "start": 1672.28, "end": 1680.6799999999998, "text": " a nearly 60 percent, 59 percent. And yeah, this took quite a while actually to get close to 60%,", "tokens": [50412, 257, 6217, 4060, 3043, 11, 24624, 3043, 13, 400, 1338, 11, 341, 1890, 1596, 257, 1339, 767, 281, 483, 1998, 281, 4060, 8923, 50832], "temperature": 0.0, "avg_logprob": -0.3846547603607178, "compression_ratio": 1.3962264150943395, "no_speech_prob": 4.069339411216788e-05}, {"id": 231, "seek": 167132, "start": 1680.6799999999998, "end": 1687.8, "text": " I've got to admit. And you can see that the training sets are already up to 91,", "tokens": [50832, 286, 600, 658, 281, 9796, 13, 400, 291, 393, 536, 300, 264, 3097, 6352, 366, 1217, 493, 281, 31064, 11, 51188], "temperature": 0.0, "avg_logprob": -0.3846547603607178, "compression_ratio": 1.3962264150943395, "no_speech_prob": 4.069339411216788e-05}, {"id": 232, "seek": 167132, "start": 1687.8, "end": 1690.52, "text": " so we're kind of on the verge of overfitting.", "tokens": [51188, 370, 321, 434, 733, 295, 322, 264, 37164, 295, 670, 69, 2414, 13, 51324], "temperature": 0.0, "avg_logprob": -0.3846547603607178, "compression_ratio": 1.3962264150943395, "no_speech_prob": 4.069339411216788e-05}, {"id": 233, "seek": 169052, "start": 1690.76, "end": 1691.48, "text": " Overfitting.", "tokens": [50376, 4886, 69, 2414, 13, 50412], "temperature": 0.0, "avg_logprob": -0.22493548142282585, "compression_ratio": 1.5602409638554218, "no_speech_prob": 1.9525701645761728e-05}, {"id": 234, "seek": 169052, "start": 1696.44, "end": 1702.2, "text": " Okay, so then I thought, all right, how do we do better?", "tokens": [50660, 1033, 11, 370, 550, 286, 1194, 11, 439, 558, 11, 577, 360, 321, 360, 1101, 30, 50948], "temperature": 0.0, "avg_logprob": -0.22493548142282585, "compression_ratio": 1.5602409638554218, "no_speech_prob": 1.9525701645761728e-05}, {"id": 235, "seek": 169052, "start": 1706.6, "end": 1712.2, "text": " And I wanted to have a sense of like, how much better could we get? And I kind of tend to like", "tokens": [51168, 400, 286, 1415, 281, 362, 257, 2020, 295, 411, 11, 577, 709, 1101, 727, 321, 483, 30, 400, 286, 733, 295, 3928, 281, 411, 51448], "temperature": 0.0, "avg_logprob": -0.22493548142282585, "compression_ratio": 1.5602409638554218, "no_speech_prob": 1.9525701645761728e-05}, {"id": 236, "seek": 169052, "start": 1712.2, "end": 1718.68, "text": " to look at papers with code, which is a site that shows papers with their code. And also like,", "tokens": [51448, 281, 574, 412, 10577, 365, 3089, 11, 597, 307, 257, 3621, 300, 3110, 10577, 365, 641, 3089, 13, 400, 611, 411, 11, 51772], "temperature": 0.0, "avg_logprob": -0.22493548142282585, "compression_ratio": 1.5602409638554218, "no_speech_prob": 1.9525701645761728e-05}, {"id": 237, "seek": 171868, "start": 1718.68, "end": 1723.24, "text": " how good a results did they get? So this is the image classification on TinyImageNet.", "tokens": [50364, 577, 665, 257, 3542, 630, 436, 483, 30, 407, 341, 307, 264, 3256, 21538, 322, 39992, 31128, 609, 31890, 13, 50592], "temperature": 0.0, "avg_logprob": -0.23800993773896814, "compression_ratio": 1.6580882352941178, "no_speech_prob": 3.426799230510369e-05}, {"id": 238, "seek": 171868, "start": 1724.1200000000001, "end": 1729.8, "text": " And at first I was like, pretty disheartened to see all these like, 90 percent plus things.", "tokens": [50636, 400, 412, 700, 286, 390, 411, 11, 1238, 717, 12864, 5320, 281, 536, 439, 613, 411, 11, 4289, 3043, 1804, 721, 13, 50920], "temperature": 0.0, "avg_logprob": -0.23800993773896814, "compression_ratio": 1.6580882352941178, "no_speech_prob": 3.426799230510369e-05}, {"id": 239, "seek": 171868, "start": 1730.68, "end": 1736.52, "text": " But as I looked at the papers, I realized something. Well, the first thing is I noticed", "tokens": [50964, 583, 382, 286, 2956, 412, 264, 10577, 11, 286, 5334, 746, 13, 1042, 11, 264, 700, 551, 307, 286, 5694, 51256], "temperature": 0.0, "avg_logprob": -0.23800993773896814, "compression_ratio": 1.6580882352941178, "no_speech_prob": 3.426799230510369e-05}, {"id": 240, "seek": 171868, "start": 1736.52, "end": 1743.96, "text": " that these ticks here represent extra training data. So these are actually pre-trained models", "tokens": [51256, 300, 613, 42475, 510, 2906, 2857, 3097, 1412, 13, 407, 613, 366, 767, 659, 12, 17227, 2001, 5245, 51628], "temperature": 0.0, "avg_logprob": -0.23800993773896814, "compression_ratio": 1.6580882352941178, "no_speech_prob": 3.426799230510369e-05}, {"id": 241, "seek": 171868, "start": 1743.96, "end": 1748.44, "text": " that are only fine-tuned on TinyImageNet. So that's a total cheater. And then I looked more", "tokens": [51628, 300, 366, 787, 2489, 12, 83, 43703, 322, 39992, 31128, 609, 31890, 13, 407, 300, 311, 257, 3217, 947, 771, 13, 400, 550, 286, 2956, 544, 51852], "temperature": 0.0, "avg_logprob": -0.23800993773896814, "compression_ratio": 1.6580882352941178, "no_speech_prob": 3.426799230510369e-05}, {"id": 242, "seek": 174844, "start": 1748.44, "end": 1752.52, "text": " closely at this one, and actually these are also using pre-trained data, so papers with code is", "tokens": [50364, 8185, 412, 341, 472, 11, 293, 767, 613, 366, 611, 1228, 659, 12, 17227, 2001, 1412, 11, 370, 10577, 365, 3089, 307, 50568], "temperature": 0.0, "avg_logprob": -0.20606244405110677, "compression_ratio": 1.6398104265402844, "no_speech_prob": 7.766888302285224e-06}, {"id": 243, "seek": 174844, "start": 1752.52, "end": 1760.2, "text": " actually incorrect. And so the first ones I could see which I could clearly kind of replicate and", "tokens": [50568, 767, 18424, 13, 400, 370, 264, 700, 2306, 286, 727, 536, 597, 286, 727, 4448, 733, 295, 25356, 293, 50952], "temperature": 0.0, "avg_logprob": -0.20606244405110677, "compression_ratio": 1.6398104265402844, "no_speech_prob": 7.766888302285224e-06}, {"id": 244, "seek": 174844, "start": 1760.2, "end": 1766.76, "text": " make sense of was this one. So the highest one that I'm confident of is this 72 percent.", "tokens": [50952, 652, 2020, 295, 390, 341, 472, 13, 407, 264, 6343, 472, 300, 286, 478, 6679, 295, 307, 341, 18731, 3043, 13, 51280], "temperature": 0.0, "avg_logprob": -0.20606244405110677, "compression_ratio": 1.6398104265402844, "no_speech_prob": 7.766888302285224e-06}, {"id": 245, "seek": 174844, "start": 1769.8, "end": 1773.56, "text": " And so then I kind of wanted to get a sense of, all right, how,", "tokens": [51432, 400, 370, 550, 286, 733, 295, 1415, 281, 483, 257, 2020, 295, 11, 439, 558, 11, 577, 11, 51620], "temperature": 0.0, "avg_logprob": -0.20606244405110677, "compression_ratio": 1.6398104265402844, "no_speech_prob": 7.766888302285224e-06}, {"id": 246, "seek": 177356, "start": 1774.52, "end": 1782.52, "text": " you know, how much work is there to get from like 60 percent to 70 percent, and how good is this?", "tokens": [50412, 291, 458, 11, 577, 709, 589, 307, 456, 281, 483, 490, 411, 4060, 3043, 281, 5285, 3043, 11, 293, 577, 665, 307, 341, 30, 50812], "temperature": 0.0, "avg_logprob": -0.3392059598650251, "compression_ratio": 1.4152046783625731, "no_speech_prob": 6.854284947621636e-06}, {"id": 247, "seek": 177356, "start": 1788.76, "end": 1793.08, "text": " So I opened up the paper. And so here's TinyImageNet.", "tokens": [51124, 407, 286, 5625, 493, 264, 3035, 13, 400, 370, 510, 311, 39992, 31128, 609, 31890, 13, 51340], "temperature": 0.0, "avg_logprob": -0.3392059598650251, "compression_ratio": 1.4152046783625731, "no_speech_prob": 6.854284947621636e-06}, {"id": 248, "seek": 177356, "start": 1795.48, "end": 1800.12, "text": " And they've got like, basically this paper turns out to be about a new type of mix-up data", "tokens": [51460, 400, 436, 600, 658, 411, 11, 1936, 341, 3035, 4523, 484, 281, 312, 466, 257, 777, 2010, 295, 2890, 12, 1010, 1412, 51692], "temperature": 0.0, "avg_logprob": -0.3392059598650251, "compression_ratio": 1.4152046783625731, "no_speech_prob": 6.854284947621636e-06}, {"id": 249, "seek": 180012, "start": 1800.4399999999998, "end": 1805.7199999999998, "text": " augmentation. This is the normal kind of mix-up, and this is their special kind of mix-up.", "tokens": [50380, 14501, 19631, 13, 639, 307, 264, 2710, 733, 295, 2890, 12, 1010, 11, 293, 341, 307, 641, 2121, 733, 295, 2890, 12, 1010, 13, 50644], "temperature": 0.0, "avg_logprob": -0.19113880879170186, "compression_ratio": 1.6266094420600858, "no_speech_prob": 9.368696737510618e-06}, {"id": 250, "seek": 180012, "start": 1805.7199999999998, "end": 1812.4399999999998, "text": " And on a ResNet-18, yeah, I see they're getting like 63, 64, 65 with various different types of", "tokens": [50644, 400, 322, 257, 5015, 31890, 12, 6494, 11, 1338, 11, 286, 536, 436, 434, 1242, 411, 25082, 11, 12145, 11, 11624, 365, 3683, 819, 3467, 295, 50980], "temperature": 0.0, "avg_logprob": -0.19113880879170186, "compression_ratio": 1.6266094420600858, "no_speech_prob": 9.368696737510618e-06}, {"id": 251, "seek": 180012, "start": 1812.4399999999998, "end": 1818.84, "text": " mix-up, and kind of 64 or 65 for their special one. And then if they use much bigger models than", "tokens": [50980, 2890, 12, 1010, 11, 293, 733, 295, 12145, 420, 11624, 337, 641, 2121, 472, 13, 400, 550, 498, 436, 764, 709, 3801, 5245, 813, 51300], "temperature": 0.0, "avg_logprob": -0.19113880879170186, "compression_ratio": 1.6266094420600858, "no_speech_prob": 9.368696737510618e-06}, {"id": 252, "seek": 180012, "start": 1818.84, "end": 1825.1599999999999, "text": " we're using, they can get up to 66-ish. So that kind of made me think, okay, this classifier is", "tokens": [51300, 321, 434, 1228, 11, 436, 393, 483, 493, 281, 21126, 12, 742, 13, 407, 300, 733, 295, 1027, 385, 519, 11, 1392, 11, 341, 1508, 9902, 307, 51616], "temperature": 0.0, "avg_logprob": -0.19113880879170186, "compression_ratio": 1.6266094420600858, "no_speech_prob": 9.368696737510618e-06}, {"id": 253, "seek": 182516, "start": 1826.1200000000001, "end": 1833.88, "text": " not bad, but there's clearly room to improve it. And I can't help myself, I always have to try to", "tokens": [50412, 406, 1578, 11, 457, 456, 311, 4448, 1808, 281, 3470, 309, 13, 400, 286, 393, 380, 854, 2059, 11, 286, 1009, 362, 281, 853, 281, 50800], "temperature": 0.0, "avg_logprob": -0.16392029195592023, "compression_ratio": 1.4131736526946108, "no_speech_prob": 3.3931371490325546e-06}, {"id": 254, "seek": 182516, "start": 1834.92, "end": 1840.52, "text": " do better. So this is a good opportunity to learn about a trick that is used in", "tokens": [50852, 360, 1101, 13, 407, 341, 307, 257, 665, 2650, 281, 1466, 466, 257, 4282, 300, 307, 1143, 294, 51132], "temperature": 0.0, "avg_logprob": -0.16392029195592023, "compression_ratio": 1.4131736526946108, "no_speech_prob": 3.3931371490325546e-06}, {"id": 255, "seek": 182516, "start": 1841.8000000000002, "end": 1846.8400000000001, "text": " real ResNets, which is in a real ResNet, we don't just say", "tokens": [51196, 957, 5015, 45, 1385, 11, 597, 307, 294, 257, 957, 5015, 31890, 11, 321, 500, 380, 445, 584, 51448], "temperature": 0.0, "avg_logprob": -0.16392029195592023, "compression_ratio": 1.4131736526946108, "no_speech_prob": 3.3931371490325546e-06}, {"id": 256, "seek": 184684, "start": 1846.84, "end": 1858.4399999999998, "text": " how many filters or channels or activations per layer, and then just go through and do a,", "tokens": [50364, 577, 867, 15995, 420, 9235, 420, 2430, 763, 680, 4583, 11, 293, 550, 445, 352, 807, 293, 360, 257, 11, 50944], "temperature": 0.0, "avg_logprob": -0.3344795849858498, "compression_ratio": 1.335820895522388, "no_speech_prob": 6.048902378097409e-06}, {"id": 257, "seek": 184684, "start": 1859.56, "end": 1871.8, "text": " you know, stride to conv each time. But instead, you can also say the number of ResBlocks", "tokens": [51000, 291, 458, 11, 1056, 482, 281, 3754, 1184, 565, 13, 583, 2602, 11, 291, 393, 611, 584, 264, 1230, 295, 5015, 33, 34896, 51612], "temperature": 0.0, "avg_logprob": -0.3344795849858498, "compression_ratio": 1.335820895522388, "no_speech_prob": 6.048902378097409e-06}, {"id": 258, "seek": 187180, "start": 1872.76, "end": 1877.96, "text": " per kind of downsampling layer. So this would say do three ResBlocks,", "tokens": [50412, 680, 733, 295, 760, 19988, 11970, 4583, 13, 407, 341, 576, 584, 360, 1045, 5015, 33, 34896, 11, 50672], "temperature": 0.0, "avg_logprob": -0.22885557982298704, "compression_ratio": 2.225609756097561, "no_speech_prob": 3.0415935725613963e-06}, {"id": 259, "seek": 187180, "start": 1879.32, "end": 1883.8, "text": " and you know, then downsample, or downsample, and then do three ResBlocks, or something like that,", "tokens": [50740, 293, 291, 458, 11, 550, 760, 19988, 781, 11, 420, 760, 19988, 781, 11, 293, 550, 360, 1045, 5015, 33, 34896, 11, 420, 746, 411, 300, 11, 50964], "temperature": 0.0, "avg_logprob": -0.22885557982298704, "compression_ratio": 2.225609756097561, "no_speech_prob": 3.0415935725613963e-06}, {"id": 260, "seek": 187180, "start": 1883.8, "end": 1888.36, "text": " or do three ResBlocks, the first of which, or the last of which is a downsample, and then two ResBlocks", "tokens": [50964, 420, 360, 1045, 5015, 33, 34896, 11, 264, 700, 295, 597, 11, 420, 264, 1036, 295, 597, 307, 257, 760, 19988, 781, 11, 293, 550, 732, 5015, 33, 34896, 51192], "temperature": 0.0, "avg_logprob": -0.22885557982298704, "compression_ratio": 2.225609756097561, "no_speech_prob": 3.0415935725613963e-06}, {"id": 261, "seek": 187180, "start": 1889.8, "end": 1893.3999999999999, "text": " with a downsample, and then two ResBlocks with a downsample. So this has got a total of one,", "tokens": [51264, 365, 257, 760, 19988, 781, 11, 293, 550, 732, 5015, 33, 34896, 365, 257, 760, 19988, 781, 13, 407, 341, 575, 658, 257, 3217, 295, 472, 11, 51444], "temperature": 0.0, "avg_logprob": -0.22885557982298704, "compression_ratio": 2.225609756097561, "no_speech_prob": 3.0415935725613963e-06}, {"id": 262, "seek": 189340, "start": 1893.4, "end": 1900.8400000000001, "text": " two, three, four, five downsamples, but it's got, rather than having one, two, three, four, five", "tokens": [50364, 732, 11, 1045, 11, 1451, 11, 1732, 760, 19988, 2622, 11, 457, 309, 311, 658, 11, 2831, 813, 1419, 472, 11, 732, 11, 1045, 11, 1451, 11, 1732, 50736], "temperature": 0.0, "avg_logprob": -0.19200018786509102, "compression_ratio": 1.704035874439462, "no_speech_prob": 1.544628139527049e-05}, {"id": 263, "seek": 189340, "start": 1901.5600000000002, "end": 1907.48, "text": " ResBlocks, it's going to have three, four, five, six, seven, eight, nine ResBlocks. So it's nearly", "tokens": [50772, 5015, 33, 34896, 11, 309, 311, 516, 281, 362, 1045, 11, 1451, 11, 1732, 11, 2309, 11, 3407, 11, 3180, 11, 4949, 5015, 33, 34896, 13, 407, 309, 311, 6217, 51068], "temperature": 0.0, "avg_logprob": -0.19200018786509102, "compression_ratio": 1.704035874439462, "no_speech_prob": 1.544628139527049e-05}, {"id": 264, "seek": 189340, "start": 1907.48, "end": 1913.5600000000002, "text": " twice as deep. And so the way we do that is we just replace the places it was saying ResBlock", "tokens": [51068, 6091, 382, 2452, 13, 400, 370, 264, 636, 321, 360, 300, 307, 321, 445, 7406, 264, 3190, 309, 390, 1566, 5015, 33, 4102, 51372], "temperature": 0.0, "avg_logprob": -0.19200018786509102, "compression_ratio": 1.704035874439462, "no_speech_prob": 1.544628139527049e-05}, {"id": 265, "seek": 189340, "start": 1913.5600000000002, "end": 1921.0800000000002, "text": " with Res underscore blocks. And that's just a sequential, which goes through the number of", "tokens": [51372, 365, 5015, 37556, 8474, 13, 400, 300, 311, 445, 257, 42881, 11, 597, 1709, 807, 264, 1230, 295, 51748], "temperature": 0.0, "avg_logprob": -0.19200018786509102, "compression_ratio": 1.704035874439462, "no_speech_prob": 1.544628139527049e-05}, {"id": 266, "seek": 192108, "start": 1921.8, "end": 1927.8, "text": " blocks and creates a ResBlock. And you can do it a couple of ways. In this case,", "tokens": [50400, 8474, 293, 7829, 257, 5015, 33, 4102, 13, 400, 291, 393, 360, 309, 257, 1916, 295, 2098, 13, 682, 341, 1389, 11, 50700], "temperature": 0.0, "avg_logprob": -0.18194343985580816, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.715955164627303e-07}, {"id": 267, "seek": 192108, "start": 1929.32, "end": 1937.8, "text": " I said if it's the last one, then make it stride two, otherwise stride one. So it's going to be", "tokens": [50776, 286, 848, 498, 309, 311, 264, 1036, 472, 11, 550, 652, 309, 1056, 482, 732, 11, 5911, 1056, 482, 472, 13, 407, 309, 311, 516, 281, 312, 51200], "temperature": 0.0, "avg_logprob": -0.18194343985580816, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.715955164627303e-07}, {"id": 268, "seek": 192108, "start": 1938.76, "end": 1945.24, "text": " downsampling at the end of each set of ResBlocks. So that's the only thing I changed. I changed", "tokens": [51248, 760, 19988, 11970, 412, 264, 917, 295, 1184, 992, 295, 5015, 33, 34896, 13, 407, 300, 311, 264, 787, 551, 286, 3105, 13, 286, 3105, 51572], "temperature": 0.0, "avg_logprob": -0.18194343985580816, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.715955164627303e-07}, {"id": 269, "seek": 194524, "start": 1945.24, "end": 1953.96, "text": " ResBlock to ResBlocks and passed in the number of blocks, which is this. Okay, so", "tokens": [50364, 5015, 33, 4102, 281, 5015, 33, 34896, 293, 4678, 294, 264, 1230, 295, 8474, 11, 597, 307, 341, 13, 1033, 11, 370, 50800], "temperature": 0.0, "avg_logprob": -0.24455460024551606, "compression_ratio": 1.5555555555555556, "no_speech_prob": 2.0261400095478166e-06}, {"id": 270, "seek": 194524, "start": 1957.56, "end": 1965.16, "text": " the number of megaflops is now 710-ish, which is more than double, right? So", "tokens": [50980, 264, 1230, 295, 10816, 2792, 75, 3370, 307, 586, 1614, 3279, 12, 742, 11, 597, 307, 544, 813, 3834, 11, 558, 30, 407, 51360], "temperature": 0.0, "avg_logprob": -0.24455460024551606, "compression_ratio": 1.5555555555555556, "no_speech_prob": 2.0261400095478166e-06}, {"id": 271, "seek": 194524, "start": 1966.36, "end": 1970.92, "text": " should have more opportunity to learn stuff, which also could be more opportunity to overfit.", "tokens": [51420, 820, 362, 544, 2650, 281, 1466, 1507, 11, 597, 611, 727, 312, 544, 2650, 281, 670, 6845, 13, 51648], "temperature": 0.0, "avg_logprob": -0.24455460024551606, "compression_ratio": 1.5555555555555556, "no_speech_prob": 2.0261400095478166e-06}, {"id": 272, "seek": 197092, "start": 1970.92, "end": 1982.28, "text": " So again, we do our LRFind. And yeah, so I just did 25 epochs, and I didn't actually add more", "tokens": [50364, 407, 797, 11, 321, 360, 527, 441, 49, 37, 471, 13, 400, 1338, 11, 370, 286, 445, 630, 3552, 30992, 28346, 11, 293, 286, 994, 380, 767, 909, 544, 50932], "temperature": 0.0, "avg_logprob": -0.25089874267578127, "compression_ratio": 1.4314720812182742, "no_speech_prob": 5.77189848627313e-06}, {"id": 273, "seek": 197092, "start": 1982.28, "end": 1993.96, "text": " augmentation. Okay, and that got up to nearly 62. So that was a good improvement. And you know,", "tokens": [50932, 14501, 19631, 13, 1033, 11, 293, 300, 658, 493, 281, 6217, 24536, 13, 407, 300, 390, 257, 665, 10444, 13, 400, 291, 458, 11, 51516], "temperature": 0.0, "avg_logprob": -0.25089874267578127, "compression_ratio": 1.4314720812182742, "no_speech_prob": 5.77189848627313e-06}, {"id": 274, "seek": 197092, "start": 1993.96, "end": 2000.28, "text": " interestingly, it's not overfitting more. It's actually, if anything, less, which, you know,", "tokens": [51516, 25873, 11, 309, 311, 406, 670, 69, 2414, 544, 13, 467, 311, 767, 11, 498, 1340, 11, 1570, 11, 597, 11, 291, 458, 11, 51832], "temperature": 0.0, "avg_logprob": -0.25089874267578127, "compression_ratio": 1.4314720812182742, "no_speech_prob": 5.77189848627313e-06}, {"id": 275, "seek": 200028, "start": 2000.28, "end": 2007.96, "text": " there's something about its ability to actually learn this, which is slowing it down or something.", "tokens": [50364, 456, 311, 746, 466, 1080, 3485, 281, 767, 1466, 341, 11, 597, 307, 26958, 309, 760, 420, 746, 13, 50748], "temperature": 0.0, "avg_logprob": -0.1564502301423446, "compression_ratio": 1.3565891472868217, "no_speech_prob": 1.459373038414924e-06}, {"id": 276, "seek": 200028, "start": 2011.3999999999999, "end": 2017.48, "text": " So I thought, yeah, it'd be nice to train it for longer. So I decided to add", "tokens": [50920, 407, 286, 1194, 11, 1338, 11, 309, 1116, 312, 1481, 281, 3847, 309, 337, 2854, 13, 407, 286, 3047, 281, 909, 51224], "temperature": 0.0, "avg_logprob": -0.1564502301423446, "compression_ratio": 1.3565891472868217, "no_speech_prob": 1.459373038414924e-06}, {"id": 277, "seek": 201748, "start": 2017.88, "end": 2031.16, "text": " more augmentation. And to do that, I decided to use something called trivial augment,", "tokens": [50384, 544, 14501, 19631, 13, 400, 281, 360, 300, 11, 286, 3047, 281, 764, 746, 1219, 26703, 29919, 11, 51048], "temperature": 0.0, "avg_logprob": -0.2228235721588135, "compression_ratio": 1.2735042735042734, "no_speech_prob": 0.0002780271170195192}, {"id": 278, "seek": 201748, "start": 2031.96, "end": 2037.16, "text": " which is not a very well-known approach, but it deserves to be.", "tokens": [51088, 597, 307, 406, 257, 588, 731, 12, 6861, 3109, 11, 457, 309, 17037, 281, 312, 13, 51348], "temperature": 0.0, "avg_logprob": -0.2228235721588135, "compression_ratio": 1.2735042735042734, "no_speech_prob": 0.0002780271170195192}, {"id": 279, "seek": 203716, "start": 2037.8000000000002, "end": 2043.24, "text": " And it comes from Frank Hutter's lab. Frank Hutter is somebody who consistently creates", "tokens": [50396, 400, 309, 1487, 490, 6823, 389, 9947, 311, 2715, 13, 6823, 389, 9947, 307, 2618, 567, 14961, 7829, 50668], "temperature": 0.0, "avg_logprob": -0.5212871975368923, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0020827387925237417}, {"id": 280, "seek": 203716, "start": 2043.8000000000002, "end": 2052.52, "text": " extremely practical, useful improvements, with much less of the nonsense that we often see from", "tokens": [50696, 4664, 8496, 11, 4420, 13797, 11, 365, 709, 1570, 295, 264, 14925, 300, 321, 2049, 536, 490, 51132], "temperature": 0.0, "avg_logprob": -0.5212871975368923, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0020827387925237417}, {"id": 281, "seek": 203716, "start": 2053.7200000000003, "end": 2060.04, "text": " some of the huge, well-funded labs. And so this one's kind of a bit of a reaction to some previous", "tokens": [51192, 512, 295, 264, 2603, 11, 731, 12, 43589, 20339, 13, 400, 370, 341, 472, 311, 733, 295, 257, 857, 295, 257, 5480, 281, 512, 3894, 51508], "temperature": 0.0, "avg_logprob": -0.5212871975368923, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0020827387925237417}, {"id": 282, "seek": 203716, "start": 2060.04, "end": 2066.2000000000003, "text": " approaches, such as one called auto-augmentation, which is a very, very simple approach.", "tokens": [51508, 11587, 11, 1270, 382, 472, 1219, 8399, 12, 64, 697, 19631, 11, 597, 307, 257, 588, 11, 588, 2199, 3109, 13, 51816], "temperature": 0.0, "avg_logprob": -0.5212871975368923, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0020827387925237417}, {"id": 283, "seek": 206716, "start": 2068.12, "end": 2074.52, "text": " One called rand-augment. They might have both come from Google Brain. I'm not quite sure.", "tokens": [50412, 1485, 1219, 367, 474, 12, 20056, 518, 13, 814, 1062, 362, 1293, 808, 490, 3329, 29783, 13, 286, 478, 406, 1596, 988, 13, 50732], "temperature": 0.0, "avg_logprob": -0.2377790825389256, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.0694139897823334e-05}, {"id": 284, "seek": 206716, "start": 2075.16, "end": 2083.0, "text": " Where they kind of used lots of, like, you know, many, many thousands of TPU hours to, like, optimize", "tokens": [50764, 2305, 436, 733, 295, 1143, 3195, 295, 11, 411, 11, 291, 458, 11, 867, 11, 867, 5383, 295, 314, 8115, 2496, 281, 11, 411, 11, 19719, 51156], "temperature": 0.0, "avg_logprob": -0.2377790825389256, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.0694139897823334e-05}, {"id": 285, "seek": 206716, "start": 2083.96, "end": 2090.44, "text": " how every image is, you know, or how each set of images is augmented. And yeah, what these guys did", "tokens": [51204, 577, 633, 3256, 307, 11, 291, 458, 11, 420, 577, 1184, 992, 295, 5267, 307, 36155, 13, 400, 1338, 11, 437, 613, 1074, 630, 51528], "temperature": 0.0, "avg_logprob": -0.2377790825389256, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.0694139897823334e-05}, {"id": 286, "seek": 206716, "start": 2090.44, "end": 2095.3199999999997, "text": " is they said, well, what if we don't do that, but we just randomly pick a different augmentation for", "tokens": [51528, 307, 436, 848, 11, 731, 11, 437, 498, 321, 500, 380, 360, 300, 11, 457, 321, 445, 16979, 1888, 257, 819, 14501, 19631, 337, 51772], "temperature": 0.0, "avg_logprob": -0.2377790825389256, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.0694139897823334e-05}, {"id": 287, "seek": 209532, "start": 2095.32, "end": 2106.6000000000004, "text": " each image. And that's what they did. They just said, algorithm one, here's the procedure. Pick an", "tokens": [50364, 1184, 3256, 13, 400, 300, 311, 437, 436, 630, 13, 814, 445, 848, 11, 9284, 472, 11, 510, 311, 264, 10747, 13, 14129, 364, 50928], "temperature": 0.0, "avg_logprob": -0.24550467652159852, "compression_ratio": 1.5025641025641026, "no_speech_prob": 1.920807517308276e-05}, {"id": 288, "seek": 209532, "start": 2106.6000000000004, "end": 2116.04, "text": " augmentation. Pick an amount. Do it. I feel like they're almost kind of, like, trying to make a", "tokens": [50928, 14501, 19631, 13, 14129, 364, 2372, 13, 1144, 309, 13, 286, 841, 411, 436, 434, 1920, 733, 295, 11, 411, 11, 1382, 281, 652, 257, 51400], "temperature": 0.0, "avg_logprob": -0.24550467652159852, "compression_ratio": 1.5025641025641026, "no_speech_prob": 1.920807517308276e-05}, {"id": 289, "seek": 209532, "start": 2116.04, "end": 2125.0800000000004, "text": " point about writing this algorithm here. Yeah. And they basically find this is at least as good or", "tokens": [51400, 935, 466, 3579, 341, 9284, 510, 13, 865, 13, 400, 436, 1936, 915, 341, 307, 412, 1935, 382, 665, 420, 51852], "temperature": 0.0, "avg_logprob": -0.24550467652159852, "compression_ratio": 1.5025641025641026, "no_speech_prob": 1.920807517308276e-05}, {"id": 290, "seek": 212508, "start": 2125.08, "end": 2130.44, "text": " often better, actually, than the incredibly resource-intensive ones. The incredibly", "tokens": [50364, 2049, 1101, 11, 767, 11, 813, 264, 6252, 7684, 12, 686, 2953, 2306, 13, 440, 6252, 50632], "temperature": 0.0, "avg_logprob": -0.2210207814755647, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.721542255647364e-07}, {"id": 291, "seek": 212508, "start": 2130.44, "end": 2134.2, "text": " resource-intensive ones also kind of require a different version for every data set,", "tokens": [50632, 7684, 12, 686, 2953, 2306, 611, 733, 295, 3651, 257, 819, 3037, 337, 633, 1412, 992, 11, 50820], "temperature": 0.0, "avg_logprob": -0.2210207814755647, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.721542255647364e-07}, {"id": 292, "seek": 212508, "start": 2135.3199999999997, "end": 2138.44, "text": " which is why they describe this as tuning-free.", "tokens": [50876, 597, 307, 983, 436, 6786, 341, 382, 15164, 12, 10792, 13, 51032], "temperature": 0.0, "avg_logprob": -0.2210207814755647, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.721542255647364e-07}, {"id": 293, "seek": 212508, "start": 2140.2, "end": 2144.12, "text": " So rather nicely, and surprisingly for me, it's actually built into PyTorch.", "tokens": [51120, 407, 2831, 9594, 11, 293, 17600, 337, 385, 11, 309, 311, 767, 3094, 666, 9953, 51, 284, 339, 13, 51316], "temperature": 0.0, "avg_logprob": -0.2210207814755647, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.721542255647364e-07}, {"id": 294, "seek": 212508, "start": 2147.7999999999997, "end": 2152.68, "text": " So if we go to PyTorch's website and go to trivial augment wide,", "tokens": [51500, 407, 498, 321, 352, 281, 9953, 51, 284, 339, 311, 3144, 293, 352, 281, 26703, 29919, 4874, 11, 51744], "temperature": 0.0, "avg_logprob": -0.2210207814755647, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.721542255647364e-07}, {"id": 295, "seek": 215508, "start": 2155.56, "end": 2159.3199999999997, "text": " yeah, they show you some examples of trivial augment wide.", "tokens": [50388, 1338, 11, 436, 855, 291, 512, 5110, 295, 26703, 29919, 4874, 13, 50576], "temperature": 0.0, "avg_logprob": -0.2250866725527007, "compression_ratio": 1.5405405405405406, "no_speech_prob": 4.495057510212064e-06}, {"id": 296, "seek": 215508, "start": 2163.56, "end": 2171.16, "text": " We can create our own as well. Now, the thing is, I found that doing this at a batch level", "tokens": [50788, 492, 393, 1884, 527, 1065, 382, 731, 13, 823, 11, 264, 551, 307, 11, 286, 1352, 300, 884, 341, 412, 257, 15245, 1496, 51168], "temperature": 0.0, "avg_logprob": -0.2250866725527007, "compression_ratio": 1.5405405405405406, "no_speech_prob": 4.495057510212064e-06}, {"id": 297, "seek": 215508, "start": 2171.16, "end": 2177.08, "text": " worked poorly. And I think the reason is what I described earlier. I think sometimes it will pick", "tokens": [51168, 2732, 22271, 13, 400, 286, 519, 264, 1778, 307, 437, 286, 7619, 3071, 13, 286, 519, 2171, 309, 486, 1888, 51464], "temperature": 0.0, "avg_logprob": -0.2250866725527007, "compression_ratio": 1.5405405405405406, "no_speech_prob": 4.495057510212064e-06}, {"id": 298, "seek": 215508, "start": 2178.44, "end": 2184.44, "text": " a really challenging augmentation to see, you know, and it all totally, like, mess up the loss", "tokens": [51532, 257, 534, 7595, 14501, 19631, 281, 536, 11, 291, 458, 11, 293, 309, 439, 3879, 11, 411, 11, 2082, 493, 264, 4470, 51832], "temperature": 0.0, "avg_logprob": -0.2250866725527007, "compression_ratio": 1.5405405405405406, "no_speech_prob": 4.495057510212064e-06}, {"id": 299, "seek": 218444, "start": 2184.44, "end": 2189.8, "text": " function. And if every single image in the batch is like that, then it'll shoot it off into the", "tokens": [50364, 2445, 13, 400, 498, 633, 2167, 3256, 294, 264, 15245, 307, 411, 300, 11, 550, 309, 603, 3076, 309, 766, 666, 264, 50632], "temperature": 0.0, "avg_logprob": -0.2191235817084878, "compression_ratio": 1.4090909090909092, "no_speech_prob": 4.133406400796957e-05}, {"id": 300, "seek": 218444, "start": 2191.16, "end": 2199.8, "text": " distant parts of the weight area. Which is a good excuse for me to show", "tokens": [50700, 17275, 3166, 295, 264, 3364, 1859, 13, 3013, 307, 257, 665, 8960, 337, 385, 281, 855, 51132], "temperature": 0.0, "avg_logprob": -0.2191235817084878, "compression_ratio": 1.4090909090909092, "no_speech_prob": 4.133406400796957e-05}, {"id": 301, "seek": 218444, "start": 2200.36, "end": 2207.08, "text": " how to do augmentations on a per item level. Now,", "tokens": [51160, 577, 281, 360, 29919, 763, 322, 257, 680, 3174, 1496, 13, 823, 11, 51496], "temperature": 0.0, "avg_logprob": -0.2191235817084878, "compression_ratio": 1.4090909090909092, "no_speech_prob": 4.133406400796957e-05}, {"id": 302, "seek": 220708, "start": 2208.04, "end": 2220.44, "text": " these actually require, or some of them require, having a PIL image, the Python imaging library", "tokens": [50412, 613, 767, 3651, 11, 420, 512, 295, 552, 3651, 11, 1419, 257, 430, 4620, 3256, 11, 264, 15329, 25036, 6405, 51032], "temperature": 0.0, "avg_logprob": -0.28582101821899414, "compression_ratio": 1.406015037593985, "no_speech_prob": 3.426736293477006e-05}, {"id": 303, "seek": 220708, "start": 2220.44, "end": 2230.36, "text": " image, not a tensor. So I had to change things around. So we have to import image from PIL.", "tokens": [51032, 3256, 11, 406, 257, 40863, 13, 407, 286, 632, 281, 1319, 721, 926, 13, 407, 321, 362, 281, 974, 3256, 490, 430, 4620, 13, 51528], "temperature": 0.0, "avg_logprob": -0.28582101821899414, "compression_ratio": 1.406015037593985, "no_speech_prob": 3.426736293477006e-05}, {"id": 304, "seek": 223036, "start": 2230.92, "end": 2239.32, "text": " And we have to change our tiffmx now. And we're going to do the augmentations in there", "tokens": [50392, 400, 321, 362, 281, 1319, 527, 256, 351, 69, 76, 87, 586, 13, 400, 321, 434, 516, 281, 360, 264, 29919, 763, 294, 456, 50812], "temperature": 0.0, "avg_logprob": -0.398491248655855, "compression_ratio": 1.9483870967741936, "no_speech_prob": 2.014490200963337e-05}, {"id": 305, "seek": 223036, "start": 2239.88, "end": 2245.7200000000003, "text": " instead for the training set. So for the training set,", "tokens": [50840, 2602, 337, 264, 3097, 992, 13, 407, 337, 264, 3097, 992, 11, 51132], "temperature": 0.0, "avg_logprob": -0.398491248655855, "compression_ratio": 1.9483870967741936, "no_speech_prob": 2.014490200963337e-05}, {"id": 306, "seek": 223036, "start": 2248.44, "end": 2251.08, "text": " we're going to, in fact, for both. So we're going to pass in something,", "tokens": [51268, 321, 434, 516, 281, 11, 294, 1186, 11, 337, 1293, 13, 407, 321, 434, 516, 281, 1320, 294, 746, 11, 51400], "temperature": 0.0, "avg_logprob": -0.398491248655855, "compression_ratio": 1.9483870967741936, "no_speech_prob": 2.014490200963337e-05}, {"id": 307, "seek": 223036, "start": 2251.08, "end": 2257.2400000000002, "text": " it's just, do you want to do augmentations? So for the training set, we're going to pass", "tokens": [51400, 309, 311, 445, 11, 360, 291, 528, 281, 360, 29919, 763, 30, 407, 337, 264, 3097, 992, 11, 321, 434, 516, 281, 1320, 51708], "temperature": 0.0, "avg_logprob": -0.398491248655855, "compression_ratio": 1.9483870967741936, "no_speech_prob": 2.014490200963337e-05}, {"id": 308, "seek": 225724, "start": 2258.2, "end": 2266.6, "text": " aug equals true. And for the validation set, we won't. So, yeah, so image.open is how you create", "tokens": [50412, 14501, 6915, 2074, 13, 400, 337, 264, 24071, 992, 11, 321, 1582, 380, 13, 407, 11, 1338, 11, 370, 3256, 13, 15752, 307, 577, 291, 1884, 50832], "temperature": 0.0, "avg_logprob": -0.2594060516357422, "compression_ratio": 1.5485714285714285, "no_speech_prob": 3.1381380267703207e-06}, {"id": 309, "seek": 225724, "start": 2266.6, "end": 2274.9199999999996, "text": " a PIL image object. And then if we wanted augmentations, then do these augmentations.", "tokens": [50832, 257, 430, 4620, 3256, 2657, 13, 400, 550, 498, 321, 1415, 29919, 763, 11, 550, 360, 613, 29919, 763, 13, 51248], "temperature": 0.0, "avg_logprob": -0.2594060516357422, "compression_ratio": 1.5485714285714285, "no_speech_prob": 3.1381380267703207e-06}, {"id": 310, "seek": 225724, "start": 2275.9599999999996, "end": 2283.3999999999996, "text": " And then convert it into a tensor. So torch vision has a dot to tensor we can then call.", "tokens": [51300, 400, 550, 7620, 309, 666, 257, 40863, 13, 407, 27822, 5201, 575, 257, 5893, 281, 40863, 321, 393, 550, 818, 13, 51672], "temperature": 0.0, "avg_logprob": -0.2594060516357422, "compression_ratio": 1.5485714285714285, "no_speech_prob": 3.1381380267703207e-06}, {"id": 311, "seek": 228340, "start": 2284.36, "end": 2289.48, "text": " And then we can normalize it. And actually, I decided just to use torch visions normalize.", "tokens": [50412, 400, 550, 321, 393, 2710, 1125, 309, 13, 400, 767, 11, 286, 3047, 445, 281, 764, 27822, 30746, 2710, 1125, 13, 50668], "temperature": 0.0, "avg_logprob": -0.3228837107564067, "compression_ratio": 1.6164383561643836, "no_speech_prob": 5.771895303041674e-06}, {"id": 312, "seek": 228340, "start": 2290.84, "end": 2295.48, "text": " I mean, either is fine, or this one works well. And then again, if you want augmentation,", "tokens": [50736, 286, 914, 11, 2139, 307, 2489, 11, 420, 341, 472, 1985, 731, 13, 400, 550, 797, 11, 498, 291, 528, 14501, 19631, 11, 50968], "temperature": 0.0, "avg_logprob": -0.3228837107564067, "compression_ratio": 1.6164383561643836, "no_speech_prob": 5.771895303041674e-06}, {"id": 313, "seek": 228340, "start": 2295.48, "end": 2301.32, "text": " then do your round arrays. And if you remember, our round arrays was designed to kind of use", "tokens": [50968, 550, 360, 428, 3098, 41011, 13, 400, 498, 291, 1604, 11, 527, 3098, 41011, 390, 4761, 281, 733, 295, 764, 51260], "temperature": 0.0, "avg_logprob": -0.3228837107564067, "compression_ratio": 1.6164383561643836, "no_speech_prob": 5.771895303041674e-06}, {"id": 314, "seek": 228340, "start": 2303.88, "end": 2309.88, "text": " 0, 1 distributed Gaussian noise. So you want that to happen after normalization.", "tokens": [51388, 1958, 11, 502, 12631, 39148, 5658, 13, 407, 291, 528, 300, 281, 1051, 934, 2710, 2144, 13, 51688], "temperature": 0.0, "avg_logprob": -0.3228837107564067, "compression_ratio": 1.6164383561643836, "no_speech_prob": 5.771895303041674e-06}, {"id": 315, "seek": 230988, "start": 2309.96, "end": 2315.4, "text": " So that's why I do it in this order. So yeah, so now we don't need to use the", "tokens": [50368, 407, 300, 311, 983, 286, 360, 309, 294, 341, 1668, 13, 407, 1338, 11, 370, 586, 321, 500, 380, 643, 281, 764, 264, 50640], "temperature": 0.0, "avg_logprob": -0.34652966869120694, "compression_ratio": 1.6118721461187215, "no_speech_prob": 8.801013791526202e-06}, {"id": 316, "seek": 230988, "start": 2317.4, "end": 2323.32, "text": " batch triffim thing. We're just doing it all directly in the data set. So you can see,", "tokens": [50740, 15245, 504, 3661, 332, 551, 13, 492, 434, 445, 884, 309, 439, 3838, 294, 264, 1412, 992, 13, 407, 291, 393, 536, 11, 51036], "temperature": 0.0, "avg_logprob": -0.34652966869120694, "compression_ratio": 1.6118721461187215, "no_speech_prob": 8.801013791526202e-06}, {"id": 317, "seek": 230988, "start": 2323.32, "end": 2332.92, "text": " you know, you can do data augmentation in very simple ways without almost any framework help", "tokens": [51036, 291, 458, 11, 291, 393, 360, 1412, 14501, 19631, 294, 588, 2199, 2098, 1553, 1920, 604, 8388, 854, 51516], "temperature": 0.0, "avg_logprob": -0.34652966869120694, "compression_ratio": 1.6118721461187215, "no_speech_prob": 8.801013791526202e-06}, {"id": 318, "seek": 230988, "start": 2332.92, "end": 2337.4, "text": " here. In fact, we're really not, we're not doing any, nothing's coming from a framework really.", "tokens": [51516, 510, 13, 682, 1186, 11, 321, 434, 534, 406, 11, 321, 434, 406, 884, 604, 11, 1825, 311, 1348, 490, 257, 8388, 534, 13, 51740], "temperature": 0.0, "avg_logprob": -0.34652966869120694, "compression_ratio": 1.6118721461187215, "no_speech_prob": 8.801013791526202e-06}, {"id": 319, "seek": 233740, "start": 2337.7200000000003, "end": 2343.88, "text": " It's just, yeah, it's just this little triffim DS we made. And so now, yeah, we just pass that", "tokens": [50380, 467, 311, 445, 11, 1338, 11, 309, 311, 445, 341, 707, 504, 3661, 332, 15816, 321, 1027, 13, 400, 370, 586, 11, 1338, 11, 321, 445, 1320, 300, 50688], "temperature": 0.0, "avg_logprob": -0.4155524253845215, "compression_ratio": 1.4432432432432432, "no_speech_prob": 1.9832823454635218e-05}, {"id": 320, "seek": 233740, "start": 2343.88, "end": 2350.84, "text": " into our data loaders, getDLs. And we don't need any augmentation callback.", "tokens": [50688, 666, 527, 1412, 3677, 433, 11, 483, 35, 43, 82, 13, 400, 321, 500, 380, 643, 604, 14501, 19631, 818, 3207, 13, 51036], "temperature": 0.0, "avg_logprob": -0.4155524253845215, "compression_ratio": 1.4432432432432432, "no_speech_prob": 1.9832823454635218e-05}, {"id": 321, "seek": 233740, "start": 2353.88, "end": 2364.04, "text": " All right. So now we can keep improving things by doing something called pre-activation ResNets.", "tokens": [51188, 1057, 558, 13, 407, 586, 321, 393, 1066, 11470, 721, 538, 884, 746, 1219, 659, 12, 23397, 399, 5015, 45, 1385, 13, 51696], "temperature": 0.0, "avg_logprob": -0.4155524253845215, "compression_ratio": 1.4432432432432432, "no_speech_prob": 1.9832823454635218e-05}, {"id": 322, "seek": 236404, "start": 2364.12, "end": 2367.08, "text": " So if we go back to our original ResNet,", "tokens": [50368, 407, 498, 321, 352, 646, 281, 527, 3380, 5015, 31890, 11, 50516], "temperature": 0.0, "avg_logprob": -0.436767578125, "compression_ratio": 1.328125, "no_speech_prob": 2.7535636036191136e-05}, {"id": 323, "seek": 236404, "start": 2370.92, "end": 2375.24, "text": " you might recall that the way we did it,", "tokens": [50708, 291, 1062, 9901, 300, 264, 636, 321, 630, 309, 11, 50924], "temperature": 0.0, "avg_logprob": -0.436767578125, "compression_ratio": 1.328125, "no_speech_prob": 2.7535636036191136e-05}, {"id": 324, "seek": 236404, "start": 2378.68, "end": 2388.2, "text": " we have this conv block, which consists two convolutions in a row. The second one has no", "tokens": [51096, 321, 362, 341, 3754, 3461, 11, 597, 14689, 732, 3754, 15892, 294, 257, 5386, 13, 440, 1150, 472, 575, 572, 51572], "temperature": 0.0, "avg_logprob": -0.436767578125, "compression_ratio": 1.328125, "no_speech_prob": 2.7535636036191136e-05}, {"id": 325, "seek": 238820, "start": 2388.3599999999997, "end": 2394.4399999999996, "text": " activation. And to remind you what conv is,", "tokens": [50372, 24433, 13, 400, 281, 4160, 291, 437, 3754, 307, 11, 50676], "temperature": 0.0, "avg_logprob": -0.23181931177775064, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.2473474018624984e-05}, {"id": 326, "seek": 238820, "start": 2399.64, "end": 2407.3999999999996, "text": " is that we first of all do a conv, and then optionally we do a normalization,", "tokens": [50936, 307, 300, 321, 700, 295, 439, 360, 257, 3754, 11, 293, 550, 3614, 379, 321, 360, 257, 2710, 2144, 11, 51324], "temperature": 0.0, "avg_logprob": -0.23181931177775064, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.2473474018624984e-05}, {"id": 327, "seek": 238820, "start": 2407.3999999999996, "end": 2417.0, "text": " and then optionally we do our activation function. So we end up, and then the second of those has", "tokens": [51324, 293, 550, 3614, 379, 321, 360, 527, 24433, 2445, 13, 407, 321, 917, 493, 11, 293, 550, 264, 1150, 295, 729, 575, 51804], "temperature": 0.0, "avg_logprob": -0.23181931177775064, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.2473474018624984e-05}, {"id": 328, "seek": 241700, "start": 2417.0, "end": 2424.28, "text": " act equals none. So basically what this is saying is go convolution, norm activation, convolution", "tokens": [50364, 605, 6915, 6022, 13, 407, 1936, 437, 341, 307, 1566, 307, 352, 45216, 11, 2026, 24433, 11, 45216, 50728], "temperature": 0.0, "avg_logprob": -0.21417854854038784, "compression_ratio": 1.627906976744186, "no_speech_prob": 1.1300789992674254e-05}, {"id": 329, "seek": 241700, "start": 2424.28, "end": 2432.28, "text": " norm. That's what self.cons is. And then this is the identity path. So this does nothing at all,", "tokens": [50728, 2026, 13, 663, 311, 437, 2698, 13, 21190, 307, 13, 400, 550, 341, 307, 264, 6575, 3100, 13, 407, 341, 775, 1825, 412, 439, 11, 51128], "temperature": 0.0, "avg_logprob": -0.21417854854038784, "compression_ratio": 1.627906976744186, "no_speech_prob": 1.1300789992674254e-05}, {"id": 330, "seek": 241700, "start": 2432.28, "end": 2437.48, "text": " if there's no downsampling or no change of channels. And then we apply the activation", "tokens": [51128, 498, 456, 311, 572, 760, 19988, 11970, 420, 572, 1319, 295, 9235, 13, 400, 550, 321, 3079, 264, 24433, 51388], "temperature": 0.0, "avg_logprob": -0.21417854854038784, "compression_ratio": 1.627906976744186, "no_speech_prob": 1.1300789992674254e-05}, {"id": 331, "seek": 243748, "start": 2437.48, "end": 2440.52, "text": " function, the final activation function, to the whole thing.", "tokens": [50364, 2445, 11, 264, 2572, 24433, 2445, 11, 281, 264, 1379, 551, 13, 50516], "temperature": 0.0, "avg_logprob": -0.2177437557263321, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.0031233944464474916}, {"id": 332, "seek": 243748, "start": 2445.48, "end": 2452.04, "text": " So that was how the original ResBlock was designed, which is kind of a bit of an accident, because I,", "tokens": [50764, 407, 300, 390, 577, 264, 3380, 5015, 33, 4102, 390, 4761, 11, 597, 307, 733, 295, 257, 857, 295, 364, 6398, 11, 570, 286, 11, 51092], "temperature": 0.0, "avg_logprob": -0.2177437557263321, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.0031233944464474916}, {"id": 333, "seek": 243748, "start": 2452.68, "end": 2456.52, "text": " to be honest, when I wrote that I didn't bother looking at the paper. I just did whatever seemed", "tokens": [51124, 281, 312, 3245, 11, 562, 286, 4114, 300, 286, 994, 380, 8677, 1237, 412, 264, 3035, 13, 286, 445, 630, 2035, 6576, 51316], "temperature": 0.0, "avg_logprob": -0.2177437557263321, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.0031233944464474916}, {"id": 334, "seek": 243748, "start": 2456.52, "end": 2463.48, "text": " reasonable in my head. But yeah, then looking into it further, I looked at this slightly later", "tokens": [51316, 10585, 294, 452, 1378, 13, 583, 1338, 11, 550, 1237, 666, 309, 3052, 11, 286, 2956, 412, 341, 4748, 1780, 51664], "temperature": 0.0, "avg_logprob": -0.2177437557263321, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.0031233944464474916}, {"id": 335, "seek": 246348, "start": 2463.48, "end": 2476.84, "text": " paper by the same author as of the ResNet paper, Kaiming He. And Kaiming He drew, you know, this", "tokens": [50364, 3035, 538, 264, 912, 3793, 382, 295, 264, 5015, 31890, 3035, 11, 10988, 332, 278, 634, 13, 400, 10988, 332, 278, 634, 12804, 11, 291, 458, 11, 341, 51032], "temperature": 0.0, "avg_logprob": -0.2546073814918255, "compression_ratio": 1.376923076923077, "no_speech_prob": 0.0005191946984268725}, {"id": 336, "seek": 246348, "start": 2479.4, "end": 2488.28, "text": " version here on the left. As you can see, it's conv norm relu, conv norm add relu.", "tokens": [51160, 3037, 510, 322, 264, 1411, 13, 1018, 291, 393, 536, 11, 309, 311, 3754, 2026, 1039, 84, 11, 3754, 2026, 909, 1039, 84, 13, 51604], "temperature": 0.0, "avg_logprob": -0.2546073814918255, "compression_ratio": 1.376923076923077, "no_speech_prob": 0.0005191946984268725}, {"id": 337, "seek": 248828, "start": 2489.2400000000002, "end": 2495.6400000000003, "text": " And yeah, he basically pointed out, yeah, you know what, maybe that's not great, because the", "tokens": [50412, 400, 1338, 11, 415, 1936, 10932, 484, 11, 1338, 11, 291, 458, 437, 11, 1310, 300, 311, 406, 869, 11, 570, 264, 50732], "temperature": 0.0, "avg_logprob": -0.21132317711325252, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.5355256841285154e-05}, {"id": 338, "seek": 248828, "start": 2495.6400000000003, "end": 2500.52, "text": " relu is being applied to the addition. So there isn't actually really an identity path at all.", "tokens": [50732, 1039, 84, 307, 885, 6456, 281, 264, 4500, 13, 407, 456, 1943, 380, 767, 534, 364, 6575, 3100, 412, 439, 13, 50976], "temperature": 0.0, "avg_logprob": -0.21132317711325252, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.5355256841285154e-05}, {"id": 339, "seek": 248828, "start": 2501.1600000000003, "end": 2507.0800000000004, "text": " So wouldn't it be nice if we could have a pure identity path? And so to do that, he proposed", "tokens": [51008, 407, 2759, 380, 309, 312, 1481, 498, 321, 727, 362, 257, 6075, 6575, 3100, 30, 400, 370, 281, 360, 300, 11, 415, 10348, 51304], "temperature": 0.0, "avg_logprob": -0.21132317711325252, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.5355256841285154e-05}, {"id": 340, "seek": 248828, "start": 2507.0800000000004, "end": 2515.96, "text": " reordering things to go norm relu conv, norm relu conv add. And so this is called a preact,", "tokens": [51304, 319, 765, 1794, 721, 281, 352, 2026, 1039, 84, 3754, 11, 2026, 1039, 84, 3754, 909, 13, 400, 370, 341, 307, 1219, 257, 659, 578, 11, 51748], "temperature": 0.0, "avg_logprob": -0.21132317711325252, "compression_ratio": 1.6533333333333333, "no_speech_prob": 3.5355256841285154e-05}, {"id": 341, "seek": 251596, "start": 2515.96, "end": 2528.52, "text": " or preactivation ResBlock. So that means I had to redefine conv to do norm, then act, and then", "tokens": [50364, 420, 659, 23397, 399, 5015, 33, 4102, 13, 407, 300, 1355, 286, 632, 281, 38818, 533, 3754, 281, 360, 2026, 11, 550, 605, 11, 293, 550, 50992], "temperature": 0.0, "avg_logprob": -0.21354027514187796, "compression_ratio": 1.3777777777777778, "no_speech_prob": 2.6841728413273813e-06}, {"id": 342, "seek": 251596, "start": 2528.52, "end": 2541.8, "text": " conv. So my sequential now has the activation in both places. And so yeah, other than that,", "tokens": [50992, 3754, 13, 407, 452, 42881, 586, 575, 264, 24433, 294, 1293, 3190, 13, 400, 370, 1338, 11, 661, 813, 300, 11, 51656], "temperature": 0.0, "avg_logprob": -0.21354027514187796, "compression_ratio": 1.3777777777777778, "no_speech_prob": 2.6841728413273813e-06}, {"id": 343, "seek": 254180, "start": 2542.28, "end": 2547.1600000000003, "text": " oh, and then of course, there's no activation happening in the ResBlock,", "tokens": [50388, 1954, 11, 293, 550, 295, 1164, 11, 456, 311, 572, 24433, 2737, 294, 264, 5015, 33, 4102, 11, 50632], "temperature": 0.0, "avg_logprob": -0.28336077025442413, "compression_ratio": 1.522875816993464, "no_speech_prob": 0.0004581351240631193}, {"id": 344, "seek": 254180, "start": 2547.1600000000003, "end": 2551.88, "text": " because it's all happening in the cons. Does that make sense?", "tokens": [50632, 570, 309, 311, 439, 2737, 294, 264, 1014, 13, 4402, 300, 652, 2020, 30, 50868], "temperature": 0.0, "avg_logprob": -0.28336077025442413, "compression_ratio": 1.522875816993464, "no_speech_prob": 0.0004581351240631193}, {"id": 345, "seek": 254180, "start": 2557.5600000000004, "end": 2565.7200000000003, "text": " Yeah, it makes sense. Yeah. Cool. So this is now the same, this is exactly the same, except we now", "tokens": [51152, 865, 11, 309, 1669, 2020, 13, 865, 13, 8561, 13, 407, 341, 307, 586, 264, 912, 11, 341, 307, 2293, 264, 912, 11, 3993, 321, 586, 51560], "temperature": 0.0, "avg_logprob": -0.28336077025442413, "compression_ratio": 1.522875816993464, "no_speech_prob": 0.0004581351240631193}, {"id": 346, "seek": 256572, "start": 2565.72, "end": 2572.52, "text": " need to have an activation and a batch norm after all those blocks, because previously it finished", "tokens": [50364, 643, 281, 362, 364, 24433, 293, 257, 15245, 2026, 934, 439, 729, 8474, 11, 570, 8046, 309, 4335, 50704], "temperature": 0.0, "avg_logprob": -0.18070644285620713, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.00026947553851641715}, {"id": 347, "seek": 256572, "start": 2572.52, "end": 2579.16, "text": " with a norm and an activation. Now it starts with them. So we have to put these at the end. It also", "tokens": [50704, 365, 257, 2026, 293, 364, 24433, 13, 823, 309, 3719, 365, 552, 13, 407, 321, 362, 281, 829, 613, 412, 264, 917, 13, 467, 611, 51036], "temperature": 0.0, "avg_logprob": -0.18070644285620713, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.00026947553851641715}, {"id": 348, "seek": 256572, "start": 2579.16, "end": 2582.52, "text": " means we can't start with a ResBlock anymore, because if we started with a ResBlock, then it", "tokens": [51036, 1355, 321, 393, 380, 722, 365, 257, 5015, 33, 4102, 3602, 11, 570, 498, 321, 1409, 365, 257, 5015, 33, 4102, 11, 550, 309, 51204], "temperature": 0.0, "avg_logprob": -0.18070644285620713, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.00026947553851641715}, {"id": 349, "seek": 256572, "start": 2582.52, "end": 2586.3599999999997, "text": " would have an activation function at the start, which would throw away half of our data, which", "tokens": [51204, 576, 362, 364, 24433, 2445, 412, 264, 722, 11, 597, 576, 3507, 1314, 1922, 295, 527, 1412, 11, 597, 51396], "temperature": 0.0, "avg_logprob": -0.18070644285620713, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.00026947553851641715}, {"id": 350, "seek": 256572, "start": 2586.3599999999997, "end": 2595.16, "text": " would be a bad idea. So you've got to be a bit careful with some of the details. But yeah, so", "tokens": [51396, 576, 312, 257, 1578, 1558, 13, 407, 291, 600, 658, 281, 312, 257, 857, 5026, 365, 512, 295, 264, 4365, 13, 583, 1338, 11, 370, 51836], "temperature": 0.0, "avg_logprob": -0.18070644285620713, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.00026947553851641715}, {"id": 351, "seek": 259516, "start": 2595.16, "end": 2602.3599999999997, "text": " now you can see that each image is getting its own augmentation. And so this one's been sheared,", "tokens": [50364, 586, 291, 393, 536, 300, 1184, 3256, 307, 1242, 1080, 1065, 14501, 19631, 13, 400, 370, 341, 472, 311, 668, 750, 1642, 11, 50724], "temperature": 0.0, "avg_logprob": -0.21577241285791937, "compression_ratio": 1.7256637168141593, "no_speech_prob": 2.7693945412465837e-06}, {"id": 352, "seek": 259516, "start": 2602.3599999999997, "end": 2605.72, "text": " looks like it's a door or something, because it's very hard to tell what the hell it is. It's been", "tokens": [50724, 1542, 411, 309, 311, 257, 2853, 420, 746, 11, 570, 309, 311, 588, 1152, 281, 980, 437, 264, 4921, 309, 307, 13, 467, 311, 668, 50892], "temperature": 0.0, "avg_logprob": -0.21577241285791937, "compression_ratio": 1.7256637168141593, "no_speech_prob": 2.7693945412465837e-06}, {"id": 353, "seek": 259516, "start": 2605.72, "end": 2614.04, "text": " sheared. This one's been moved. It looks like this one's also been sheared. And you can also see", "tokens": [50892, 750, 1642, 13, 639, 472, 311, 668, 4259, 13, 467, 1542, 411, 341, 472, 311, 611, 668, 750, 1642, 13, 400, 291, 393, 611, 536, 51308], "temperature": 0.0, "avg_logprob": -0.21577241285791937, "compression_ratio": 1.7256637168141593, "no_speech_prob": 2.7693945412465837e-06}, {"id": 354, "seek": 259516, "start": 2614.04, "end": 2620.12, "text": " they've got different amounts of rand arrays on them. So yeah, so I thought I'd try training that", "tokens": [51308, 436, 600, 658, 819, 11663, 295, 367, 474, 41011, 322, 552, 13, 407, 1338, 11, 370, 286, 1194, 286, 1116, 853, 3097, 300, 51612], "temperature": 0.0, "avg_logprob": -0.21577241285791937, "compression_ratio": 1.7256637168141593, "no_speech_prob": 2.7693945412465837e-06}, {"id": 355, "seek": 262012, "start": 2620.12, "end": 2640.8399999999997, "text": " for 50 epochs. And that got us to 65%, which is, you know, as good as, nearly as good as the,", "tokens": [50364, 337, 2625, 30992, 28346, 13, 400, 300, 658, 505, 281, 11624, 8923, 597, 307, 11, 291, 458, 11, 382, 665, 382, 11, 6217, 382, 665, 382, 264, 11, 51400], "temperature": 0.0, "avg_logprob": -0.252269188563029, "compression_ratio": 1.3287671232876712, "no_speech_prob": 0.0012445885222405195}, {"id": 356, "seek": 262012, "start": 2641.96, "end": 2646.3599999999997, "text": " you know, normal mix-up things that we're getting even on a ResNet-50s. This is looking really good.", "tokens": [51456, 291, 458, 11, 2710, 2890, 12, 1010, 721, 300, 321, 434, 1242, 754, 322, 257, 5015, 31890, 12, 2803, 82, 13, 639, 307, 1237, 534, 665, 13, 51676], "temperature": 0.0, "avg_logprob": -0.252269188563029, "compression_ratio": 1.3287671232876712, "no_speech_prob": 0.0012445885222405195}, {"id": 357, "seek": 265012, "start": 2650.3599999999997, "end": 2654.3599999999997, "text": " So I won't spend time on this, but I'll just mention I was kind of curious, like, I mean,", "tokens": [50376, 407, 286, 1582, 380, 3496, 565, 322, 341, 11, 457, 286, 603, 445, 2152, 286, 390, 733, 295, 6369, 11, 411, 11, 286, 914, 11, 50576], "temperature": 0.0, "avg_logprob": -0.1612919757240697, "compression_ratio": 1.7828054298642535, "no_speech_prob": 1.6027388483053073e-06}, {"id": 358, "seek": 265012, "start": 2654.3599999999997, "end": 2657.7999999999997, "text": " one of the things I should mention also is they trained all these for 400 epochs.", "tokens": [50576, 472, 295, 264, 721, 286, 820, 2152, 611, 307, 436, 8895, 439, 613, 337, 8423, 30992, 28346, 13, 50748], "temperature": 0.0, "avg_logprob": -0.1612919757240697, "compression_ratio": 1.7828054298642535, "no_speech_prob": 1.6027388483053073e-06}, {"id": 359, "seek": 265012, "start": 2658.68, "end": 2661.56, "text": " So I was kind of curious what would happen if we trained it a bit longer. I wasn't", "tokens": [50792, 407, 286, 390, 733, 295, 6369, 437, 576, 1051, 498, 321, 8895, 309, 257, 857, 2854, 13, 286, 2067, 380, 50936], "temperature": 0.0, "avg_logprob": -0.1612919757240697, "compression_ratio": 1.7828054298642535, "no_speech_prob": 1.6027388483053073e-06}, {"id": 360, "seek": 265012, "start": 2662.2, "end": 2665.96, "text": " patient enough to train it for 400 epochs, but I thought I could do", "tokens": [50968, 4537, 1547, 281, 3847, 309, 337, 8423, 30992, 28346, 11, 457, 286, 1194, 286, 727, 360, 51156], "temperature": 0.0, "avg_logprob": -0.1612919757240697, "compression_ratio": 1.7828054298642535, "no_speech_prob": 1.6027388483053073e-06}, {"id": 361, "seek": 265012, "start": 2668.04, "end": 2671.48, "text": " 200 epochs. So I just duplicated that last one,", "tokens": [51260, 2331, 30992, 28346, 13, 407, 286, 445, 1581, 564, 3587, 300, 1036, 472, 11, 51432], "temperature": 0.0, "avg_logprob": -0.1612919757240697, "compression_ratio": 1.7828054298642535, "no_speech_prob": 1.6027388483053073e-06}, {"id": 362, "seek": 265012, "start": 2674.7599999999998, "end": 2676.12, "text": " but made it 200 epochs.", "tokens": [51596, 457, 1027, 309, 2331, 30992, 28346, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1612919757240697, "compression_ratio": 1.7828054298642535, "no_speech_prob": 1.6027388483053073e-06}, {"id": 363, "seek": 267612, "start": 2676.8399999999997, "end": 2679.88, "text": " And that got us to 67.5,", "tokens": [50400, 400, 300, 658, 505, 281, 23879, 13, 20, 11, 50552], "temperature": 0.0, "avg_logprob": -0.24990210372410462, "compression_ratio": 1.544502617801047, "no_speech_prob": 6.709185981890187e-05}, {"id": 364, "seek": 267612, "start": 2686.04, "end": 2696.52, "text": " which, yeah, is better than any of their non-special mix-ups. So I think it just goes", "tokens": [50860, 597, 11, 1338, 11, 307, 1101, 813, 604, 295, 641, 2107, 12, 7053, 1013, 2890, 12, 7528, 13, 407, 286, 519, 309, 445, 1709, 51384], "temperature": 0.0, "avg_logprob": -0.24990210372410462, "compression_ratio": 1.544502617801047, "no_speech_prob": 6.709185981890187e-05}, {"id": 365, "seek": 267612, "start": 2696.52, "end": 2701.24, "text": " to show you can get, you know, genuinely state-of-the-art results. So if we use their", "tokens": [51384, 281, 855, 291, 393, 483, 11, 291, 458, 11, 17839, 1785, 12, 2670, 12, 3322, 12, 446, 3542, 13, 407, 498, 321, 764, 641, 51620], "temperature": 0.0, "avg_logprob": -0.24990210372410462, "compression_ratio": 1.544502617801047, "no_speech_prob": 6.709185981890187e-05}, {"id": 366, "seek": 267612, "start": 2701.24, "end": 2705.7999999999997, "text": " special mix-up, that would be interesting to try as well, see if we can match their results there.", "tokens": [51620, 2121, 2890, 12, 1010, 11, 300, 576, 312, 1880, 281, 853, 382, 731, 11, 536, 498, 321, 393, 2995, 641, 3542, 456, 13, 51848], "temperature": 0.0, "avg_logprob": -0.24990210372410462, "compression_ratio": 1.544502617801047, "no_speech_prob": 6.709185981890187e-05}, {"id": 367, "seek": 270612, "start": 2706.44, "end": 2712.44, "text": " But, you know, we've built all this from scratch. We didn't do the data augmentation from scratch", "tokens": [50380, 583, 11, 291, 458, 11, 321, 600, 3094, 439, 341, 490, 8459, 13, 492, 994, 380, 360, 264, 1412, 14501, 19631, 490, 8459, 50680], "temperature": 0.0, "avg_logprob": -0.23382612587749094, "compression_ratio": 1.4662921348314606, "no_speech_prob": 4.0061495383270085e-05}, {"id": 368, "seek": 270612, "start": 2712.44, "end": 2719.48, "text": " because it's not very interesting. But yeah, other than that, so I think that's really cool.", "tokens": [50680, 570, 309, 311, 406, 588, 1880, 13, 583, 1338, 11, 661, 813, 300, 11, 370, 286, 519, 300, 311, 534, 1627, 13, 51032], "temperature": 0.0, "avg_logprob": -0.23382612587749094, "compression_ratio": 1.4662921348314606, "no_speech_prob": 4.0061495383270085e-05}, {"id": 369, "seek": 270612, "start": 2720.52, "end": 2724.7599999999998, "text": " So I know that you did some other experiments with the pre-activation.", "tokens": [51084, 407, 286, 458, 300, 291, 630, 512, 661, 12050, 365, 264, 659, 12, 23397, 399, 13, 51296], "temperature": 0.0, "avg_logprob": -0.23382612587749094, "compression_ratio": 1.4662921348314606, "no_speech_prob": 4.0061495383270085e-05}, {"id": 370, "seek": 272476, "start": 2725.4, "end": 2736.1200000000003, "text": " Oh, right. Yeah. Right. When I saw the pre-activation success, I was quite enthusiastic", "tokens": [50396, 876, 11, 558, 13, 865, 13, 1779, 13, 1133, 286, 1866, 264, 659, 12, 23397, 399, 2245, 11, 286, 390, 1596, 28574, 50932], "temperature": 0.0, "avg_logprob": -0.22319371541341146, "compression_ratio": 1.453125, "no_speech_prob": 0.013825093396008015}, {"id": 371, "seek": 272476, "start": 2736.1200000000003, "end": 2739.88, "text": " about it. So I actually thought like, oh, maybe I should go back and actually use it everywhere.", "tokens": [50932, 466, 309, 13, 407, 286, 767, 1194, 411, 11, 1954, 11, 1310, 286, 820, 352, 646, 293, 767, 764, 309, 5315, 13, 51120], "temperature": 0.0, "avg_logprob": -0.22319371541341146, "compression_ratio": 1.453125, "no_speech_prob": 0.013825093396008015}, {"id": 372, "seek": 272476, "start": 2741.96, "end": 2748.1200000000003, "text": " But weirdly enough, I think it's weird, like it was worse for fashion MNIST and worse for like", "tokens": [51224, 583, 48931, 1547, 11, 286, 519, 309, 311, 3657, 11, 411, 309, 390, 5324, 337, 6700, 376, 45, 19756, 293, 5324, 337, 411, 51532], "temperature": 0.0, "avg_logprob": -0.22319371541341146, "compression_ratio": 1.453125, "no_speech_prob": 0.013825093396008015}, {"id": 373, "seek": 274812, "start": 2748.8399999999997, "end": 2756.68, "text": " less data augmentation. I mean, maybe it's not that weird, but because the idea of when", "tokens": [50400, 1570, 1412, 14501, 19631, 13, 286, 914, 11, 1310, 309, 311, 406, 300, 3657, 11, 457, 570, 264, 1558, 295, 562, 50792], "temperature": 0.0, "avg_logprob": -0.20723116916158926, "compression_ratio": 1.6561085972850678, "no_speech_prob": 4.469028499443084e-05}, {"id": 374, "seek": 274812, "start": 2756.68, "end": 2762.6, "text": " He et al introduced it, they said this is to train deeper models. You know, there's a more pure", "tokens": [50792, 634, 1030, 419, 7268, 309, 11, 436, 848, 341, 307, 281, 3847, 7731, 5245, 13, 509, 458, 11, 456, 311, 257, 544, 6075, 51088], "temperature": 0.0, "avg_logprob": -0.20723116916158926, "compression_ratio": 1.6561085972850678, "no_speech_prob": 4.469028499443084e-05}, {"id": 375, "seek": 274812, "start": 2762.6, "end": 2769.88, "text": " identity path. And so with that more pure identity path, that should kind of let the", "tokens": [51088, 6575, 3100, 13, 400, 370, 365, 300, 544, 6075, 6575, 3100, 11, 300, 820, 733, 295, 718, 264, 51452], "temperature": 0.0, "avg_logprob": -0.20723116916158926, "compression_ratio": 1.6561085972850678, "no_speech_prob": 4.469028499443084e-05}, {"id": 376, "seek": 274812, "start": 2769.88, "end": 2775.88, "text": " gradients flow through it more easily. And so there should be a smoother surface, weight surface,", "tokens": [51452, 2771, 2448, 3095, 807, 309, 544, 3612, 13, 400, 370, 456, 820, 312, 257, 28640, 3753, 11, 3364, 3753, 11, 51752], "temperature": 0.0, "avg_logprob": -0.20723116916158926, "compression_ratio": 1.6561085972850678, "no_speech_prob": 4.469028499443084e-05}, {"id": 377, "seek": 277588, "start": 2775.88, "end": 2783.4, "text": " loss surface. So yeah, I guess it makes sense that you don't really see the benefits on", "tokens": [50364, 4470, 3753, 13, 407, 1338, 11, 286, 2041, 309, 1669, 2020, 300, 291, 500, 380, 534, 536, 264, 5311, 322, 50740], "temperature": 0.0, "avg_logprob": -0.29102397870413865, "compression_ratio": 1.5376884422110553, "no_speech_prob": 6.921608292032033e-05}, {"id": 378, "seek": 277588, "start": 2783.4, "end": 2788.28, "text": " less deep models. The bit I'm surprised- Could you elaborate? Because like,", "tokens": [50740, 1570, 2452, 5245, 13, 440, 857, 286, 478, 6100, 12, 7497, 291, 20945, 30, 1436, 411, 11, 50984], "temperature": 0.0, "avg_logprob": -0.29102397870413865, "compression_ratio": 1.5376884422110553, "no_speech_prob": 6.921608292032033e-05}, {"id": 379, "seek": 277588, "start": 2788.28, "end": 2792.44, "text": " it seems like that should be, that sort of justification should be true for", "tokens": [50984, 309, 2544, 411, 300, 820, 312, 11, 300, 1333, 295, 31591, 820, 312, 2074, 337, 51192], "temperature": 0.0, "avg_logprob": -0.29102397870413865, "compression_ratio": 1.5376884422110553, "no_speech_prob": 6.921608292032033e-05}, {"id": 380, "seek": 277588, "start": 2793.7200000000003, "end": 2797.88, "text": " smaller models, right? Or- Well, yeah, it does, but smaller models", "tokens": [51256, 4356, 5245, 11, 558, 30, 1610, 12, 1042, 11, 1338, 11, 309, 775, 11, 457, 4356, 5245, 51464], "temperature": 0.0, "avg_logprob": -0.29102397870413865, "compression_ratio": 1.5376884422110553, "no_speech_prob": 6.921608292032033e-05}, {"id": 381, "seek": 279788, "start": 2798.84, "end": 2805.08, "text": " are going to have a less bumpy surface anyway. They've just got less dimensions to be bumpy on,", "tokens": [50412, 366, 516, 281, 362, 257, 1570, 49400, 3753, 4033, 13, 814, 600, 445, 658, 1570, 12819, 281, 312, 49400, 322, 11, 50724], "temperature": 0.0, "avg_logprob": -0.29354900783962673, "compression_ratio": 1.6371308016877637, "no_speech_prob": 3.2190651836572215e-05}, {"id": 382, "seek": 279788, "start": 2805.08, "end": 2812.36, "text": " and there's less, more importantly, they're less deep. So there's less room for gradients to explode", "tokens": [50724, 293, 456, 311, 1570, 11, 544, 8906, 11, 436, 434, 1570, 2452, 13, 407, 456, 311, 1570, 1808, 337, 2771, 2448, 281, 21411, 51088], "temperature": 0.0, "avg_logprob": -0.29354900783962673, "compression_ratio": 1.6371308016877637, "no_speech_prob": 3.2190651836572215e-05}, {"id": 383, "seek": 279788, "start": 2812.92, "end": 2822.2000000000003, "text": " exponentially. So they're not as sensitive. But yeah, I mean, I can see why they don't necessarily", "tokens": [51116, 37330, 13, 407, 436, 434, 406, 382, 9477, 13, 583, 1338, 11, 286, 914, 11, 286, 393, 536, 983, 436, 500, 380, 4725, 51580], "temperature": 0.0, "avg_logprob": -0.29354900783962673, "compression_ratio": 1.6371308016877637, "no_speech_prob": 3.2190651836572215e-05}, {"id": 384, "seek": 279788, "start": 2822.2000000000003, "end": 2826.44, "text": " help as much, but I don't have any idea why they were worse. And they were quite consistent,", "tokens": [51580, 854, 382, 709, 11, 457, 286, 500, 380, 362, 604, 1558, 983, 436, 645, 5324, 13, 400, 436, 645, 1596, 8398, 11, 51792], "temperature": 0.0, "avg_logprob": -0.29354900783962673, "compression_ratio": 1.6371308016877637, "no_speech_prob": 3.2190651836572215e-05}, {"id": 385, "seek": 282644, "start": 2826.52, "end": 2832.68, "text": " worse. And they were quite consistently worse. Yeah. Yeah. I find it quite interesting too.", "tokens": [50368, 5324, 13, 400, 436, 645, 1596, 14961, 5324, 13, 865, 13, 865, 13, 286, 915, 309, 1596, 1880, 886, 13, 50676], "temperature": 0.0, "avg_logprob": -0.24072788982856563, "compression_ratio": 1.7333333333333334, "no_speech_prob": 3.534999996190891e-05}, {"id": 386, "seek": 282644, "start": 2832.68, "end": 2839.4, "text": " Yeah. Yeah. Yeah. It's quite curious. And it's interesting that when we do these like", "tokens": [50676, 865, 13, 865, 13, 865, 13, 467, 311, 1596, 6369, 13, 400, 309, 311, 1880, 300, 562, 321, 360, 613, 411, 51012], "temperature": 0.0, "avg_logprob": -0.24072788982856563, "compression_ratio": 1.7333333333333334, "no_speech_prob": 3.534999996190891e-05}, {"id": 387, "seek": 282644, "start": 2840.76, "end": 2845.4, "text": " experiments on things that nowadays are considered pretty fundamental and foundational,", "tokens": [51080, 12050, 322, 721, 300, 13434, 366, 4888, 1238, 8088, 293, 32195, 11, 51312], "temperature": 0.0, "avg_logprob": -0.24072788982856563, "compression_ratio": 1.7333333333333334, "no_speech_prob": 3.534999996190891e-05}, {"id": 388, "seek": 282644, "start": 2845.4, "end": 2851.08, "text": " where you kind of all the time discover things that nobody seems to have noticed or written about,", "tokens": [51312, 689, 291, 733, 295, 439, 264, 565, 4411, 721, 300, 5079, 2544, 281, 362, 5694, 420, 3720, 466, 11, 51596], "temperature": 0.0, "avg_logprob": -0.24072788982856563, "compression_ratio": 1.7333333333333334, "no_speech_prob": 3.534999996190891e-05}, {"id": 389, "seek": 285108, "start": 2851.08, "end": 2858.2799999999997, "text": " or there's plenty of room to, as a kind of a more experimental researcher to do experiments and then", "tokens": [50364, 420, 456, 311, 7140, 295, 1808, 281, 11, 382, 257, 733, 295, 257, 544, 17069, 21751, 281, 360, 12050, 293, 550, 50724], "temperature": 0.0, "avg_logprob": -0.2126122190241228, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0008825964760035276}, {"id": 390, "seek": 285108, "start": 2858.2799999999997, "end": 2864.6, "text": " go like, oh, that's interesting. And then try and figure out what's going on. Yeah. I think a lot of", "tokens": [50724, 352, 411, 11, 1954, 11, 300, 311, 1880, 13, 400, 550, 853, 293, 2573, 484, 437, 311, 516, 322, 13, 865, 13, 286, 519, 257, 688, 295, 51040], "temperature": 0.0, "avg_logprob": -0.2126122190241228, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0008825964760035276}, {"id": 391, "seek": 285108, "start": 2864.6, "end": 2869.24, "text": " researchers go in the opposite direction and they try to start with like theoretical assumptions and", "tokens": [51040, 10309, 352, 294, 264, 6182, 3513, 293, 436, 853, 281, 722, 365, 411, 20864, 17695, 293, 51272], "temperature": 0.0, "avg_logprob": -0.2126122190241228, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0008825964760035276}, {"id": 392, "seek": 285108, "start": 2869.24, "end": 2876.2799999999997, "text": " then test them. When I think about it, I feel like maybe a lot of the more successful folks", "tokens": [51272, 550, 1500, 552, 13, 1133, 286, 519, 466, 309, 11, 286, 841, 411, 1310, 257, 688, 295, 264, 544, 4406, 4024, 51624], "temperature": 0.0, "avg_logprob": -0.2126122190241228, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0008825964760035276}, {"id": 393, "seek": 285108, "start": 2876.2799999999997, "end": 2880.84, "text": " in terms of people who build stuff that actually get used are more experimental first, maybe.", "tokens": [51624, 294, 2115, 295, 561, 567, 1322, 1507, 300, 767, 483, 1143, 366, 544, 17069, 700, 11, 1310, 13, 51852], "temperature": 0.0, "avg_logprob": -0.2126122190241228, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0008825964760035276}, {"id": 394, "seek": 288108, "start": 2881.48, "end": 2885.56, "text": " Okay. So,", "tokens": [50384, 1033, 13, 407, 11, 50588], "temperature": 0.0, "avg_logprob": -0.30003056159386265, "compression_ratio": 1.2173913043478262, "no_speech_prob": 2.8386315534589812e-05}, {"id": 395, "seek": 288108, "start": 2890.68, "end": 2894.84, "text": " shall we have a five minute break since we're kind of on the hour?", "tokens": [50844, 4393, 321, 362, 257, 1732, 3456, 1821, 1670, 321, 434, 733, 295, 322, 264, 1773, 30, 51052], "temperature": 0.0, "avg_logprob": -0.30003056159386265, "compression_ratio": 1.2173913043478262, "no_speech_prob": 2.8386315534589812e-05}, {"id": 396, "seek": 288108, "start": 2896.2799999999997, "end": 2906.6, "text": " Sure. All right. So let's now look at notebook 25, super res. I've just copied a few things", "tokens": [51124, 4894, 13, 1057, 558, 13, 407, 718, 311, 586, 574, 412, 21060, 3552, 11, 1687, 725, 13, 286, 600, 445, 25365, 257, 1326, 721, 51640], "temperature": 0.0, "avg_logprob": -0.30003056159386265, "compression_ratio": 1.2173913043478262, "no_speech_prob": 2.8386315534589812e-05}, {"id": 397, "seek": 290660, "start": 2906.6, "end": 2914.8399999999997, "text": " from the previous notebook, some transforms and our data sets and our denorm and our Triffim batch", "tokens": [50364, 490, 264, 3894, 21060, 11, 512, 35592, 293, 527, 1412, 6352, 293, 527, 1441, 687, 293, 527, 1765, 3661, 332, 15245, 50776], "temperature": 0.0, "avg_logprob": -0.26237065864331793, "compression_ratio": 1.7058823529411764, "no_speech_prob": 8.217760478146374e-05}, {"id": 398, "seek": 290660, "start": 2917.64, "end": 2921.56, "text": " and our Triffim X. I'm not sure we're using Triffim batch here.", "tokens": [50916, 293, 527, 1765, 3661, 332, 1783, 13, 286, 478, 406, 988, 321, 434, 1228, 1765, 3661, 332, 15245, 510, 13, 51112], "temperature": 0.0, "avg_logprob": -0.26237065864331793, "compression_ratio": 1.7058823529411764, "no_speech_prob": 8.217760478146374e-05}, {"id": 399, "seek": 290660, "start": 2923.56, "end": 2926.8399999999997, "text": " We're not even using Triffim batch. Let's get rid of that because that's just confusing.", "tokens": [51212, 492, 434, 406, 754, 1228, 1765, 3661, 332, 15245, 13, 961, 311, 483, 3973, 295, 300, 570, 300, 311, 445, 13181, 13, 51376], "temperature": 0.0, "avg_logprob": -0.26237065864331793, "compression_ratio": 1.7058823529411764, "no_speech_prob": 8.217760478146374e-05}, {"id": 400, "seek": 290660, "start": 2927.72, "end": 2934.04, "text": " Okay. So it looks like we're doing the per, let's figure this out. So what are we doing here? So", "tokens": [51420, 1033, 13, 407, 309, 1542, 411, 321, 434, 884, 264, 680, 11, 718, 311, 2573, 341, 484, 13, 407, 437, 366, 321, 884, 510, 30, 407, 51736], "temperature": 0.0, "avg_logprob": -0.26237065864331793, "compression_ratio": 1.7058823529411764, "no_speech_prob": 8.217760478146374e-05}, {"id": 401, "seek": 293404, "start": 2934.04, "end": 2940.84, "text": " we've got, what are our two data sets? All right. So the goal of this is we're going to do super", "tokens": [50364, 321, 600, 658, 11, 437, 366, 527, 732, 1412, 6352, 30, 1057, 558, 13, 407, 264, 3387, 295, 341, 307, 321, 434, 516, 281, 360, 1687, 50704], "temperature": 0.0, "avg_logprob": -0.228423810005188, "compression_ratio": 1.6424870466321244, "no_speech_prob": 7.112398634490091e-07}, {"id": 402, "seek": 293404, "start": 2940.84, "end": 2947.4, "text": " resolution, not classification. So let's talk about what that means. What we're going to do", "tokens": [50704, 8669, 11, 406, 21538, 13, 407, 718, 311, 751, 466, 437, 300, 1355, 13, 708, 321, 434, 516, 281, 360, 51032], "temperature": 0.0, "avg_logprob": -0.228423810005188, "compression_ratio": 1.6424870466321244, "no_speech_prob": 7.112398634490091e-07}, {"id": 403, "seek": 293404, "start": 2948.2799999999997, "end": 2956.6, "text": " is the independent variable will be scaled down to a 32 by 32 pixel", "tokens": [51076, 307, 264, 6695, 7006, 486, 312, 36039, 760, 281, 257, 8858, 538, 8858, 19261, 51492], "temperature": 0.0, "avg_logprob": -0.228423810005188, "compression_ratio": 1.6424870466321244, "no_speech_prob": 7.112398634490091e-07}, {"id": 404, "seek": 293404, "start": 2958.44, "end": 2961.8, "text": " image and the dependent variable will be the original image.", "tokens": [51584, 3256, 293, 264, 12334, 7006, 486, 312, 264, 3380, 3256, 13, 51752], "temperature": 0.0, "avg_logprob": -0.228423810005188, "compression_ratio": 1.6424870466321244, "no_speech_prob": 7.112398634490091e-07}, {"id": 405, "seek": 296404, "start": 2964.2, "end": 2974.92, "text": " And so to do random crop within a padded image and random flips, both the independent and the", "tokens": [50372, 400, 370, 281, 360, 4974, 9086, 1951, 257, 6887, 9207, 3256, 293, 4974, 40249, 11, 1293, 264, 6695, 293, 264, 50908], "temperature": 0.0, "avg_logprob": -0.2646973553825827, "compression_ratio": 1.6624472573839661, "no_speech_prob": 2.2125568648334593e-05}, {"id": 406, "seek": 296404, "start": 2974.92, "end": 2978.92, "text": " dependent variable needs to have had exactly the same random cropping and exactly the same flipping.", "tokens": [50908, 12334, 7006, 2203, 281, 362, 632, 2293, 264, 912, 4974, 4848, 3759, 293, 2293, 264, 912, 26886, 13, 51108], "temperature": 0.0, "avg_logprob": -0.2646973553825827, "compression_ratio": 1.6624472573839661, "no_speech_prob": 2.2125568648334593e-05}, {"id": 407, "seek": 296404, "start": 2979.48, "end": 2986.2799999999997, "text": " Otherwise, it can't say, oh, this is how you do super res to go from the 32 by 32 to the 64 by 64.", "tokens": [51136, 10328, 11, 309, 393, 380, 584, 11, 1954, 11, 341, 307, 577, 291, 360, 1687, 725, 281, 352, 490, 264, 8858, 538, 8858, 281, 264, 12145, 538, 12145, 13, 51476], "temperature": 0.0, "avg_logprob": -0.2646973553825827, "compression_ratio": 1.6624472573839661, "no_speech_prob": 2.2125568648334593e-05}, {"id": 408, "seek": 296404, "start": 2986.2799999999997, "end": 2990.52, "text": " Because it might be like, oh, it has to be flipped around and moved around. So yes, so for this kind", "tokens": [51476, 1436, 309, 1062, 312, 411, 11, 1954, 11, 309, 575, 281, 312, 26273, 926, 293, 4259, 926, 13, 407, 2086, 11, 370, 337, 341, 733, 51688], "temperature": 0.0, "avg_logprob": -0.2646973553825827, "compression_ratio": 1.6624472573839661, "no_speech_prob": 2.2125568648334593e-05}, {"id": 409, "seek": 299052, "start": 2990.6, "end": 3000.12, "text": " of image reconstruction task, it's important to make sure that your augmentation is done", "tokens": [50368, 295, 3256, 31565, 5633, 11, 309, 311, 1021, 281, 652, 988, 300, 428, 14501, 19631, 307, 1096, 50844], "temperature": 0.0, "avg_logprob": -0.2071764180948446, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00011412175808800384}, {"id": 410, "seek": 299052, "start": 3000.12, "end": 3006.7599999999998, "text": " the same way on the independent and the dependent variable. So that's why we've put it into our", "tokens": [50844, 264, 912, 636, 322, 264, 6695, 293, 264, 12334, 7006, 13, 407, 300, 311, 983, 321, 600, 829, 309, 666, 527, 51176], "temperature": 0.0, "avg_logprob": -0.2071764180948446, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00011412175808800384}, {"id": 411, "seek": 299052, "start": 3006.7599999999998, "end": 3011.24, "text": " data set. And so this is something people often get confused about and they don't know how to do", "tokens": [51176, 1412, 992, 13, 400, 370, 341, 307, 746, 561, 2049, 483, 9019, 466, 293, 436, 500, 380, 458, 577, 281, 360, 51400], "temperature": 0.0, "avg_logprob": -0.2071764180948446, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00011412175808800384}, {"id": 412, "seek": 299052, "start": 3011.24, "end": 3014.28, "text": " it. But it's actually pretty straightforward if we do it this way. We just put it straight in the", "tokens": [51400, 309, 13, 583, 309, 311, 767, 1238, 15325, 498, 321, 360, 309, 341, 636, 13, 492, 445, 829, 309, 2997, 294, 264, 51552], "temperature": 0.0, "avg_logprob": -0.2071764180948446, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00011412175808800384}, {"id": 413, "seek": 301428, "start": 3014.28, "end": 3025.0, "text": " data set. And it doesn't require any framework fanciness. Now, then what I did do is I then", "tokens": [50364, 1412, 992, 13, 400, 309, 1177, 380, 3651, 604, 8388, 3429, 66, 1324, 13, 823, 11, 550, 437, 286, 630, 360, 307, 286, 550, 50900], "temperature": 0.0, "avg_logprob": -0.18704817635672433, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.001754544209688902}, {"id": 414, "seek": 301428, "start": 3025.8, "end": 3035.4, "text": " added random erasing just to the training set. And the reason for that is I wanted to make the", "tokens": [50940, 3869, 4974, 1189, 3349, 445, 281, 264, 3097, 992, 13, 400, 264, 1778, 337, 300, 307, 286, 1415, 281, 652, 264, 51420], "temperature": 0.0, "avg_logprob": -0.18704817635672433, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.001754544209688902}, {"id": 415, "seek": 301428, "start": 3036.28, "end": 3041.0800000000004, "text": " super resolution task a bit more difficult. Which means sometimes it doesn't just do super", "tokens": [51464, 1687, 8669, 5633, 257, 857, 544, 2252, 13, 3013, 1355, 2171, 309, 1177, 380, 445, 360, 1687, 51704], "temperature": 0.0, "avg_logprob": -0.18704817635672433, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.001754544209688902}, {"id": 416, "seek": 304108, "start": 3041.08, "end": 3046.04, "text": " resolution, but it also has to like replace some of the deleted pixels with proper pixels.", "tokens": [50364, 8669, 11, 457, 309, 611, 575, 281, 411, 7406, 512, 295, 264, 22981, 18668, 365, 2296, 18668, 13, 50612], "temperature": 0.0, "avg_logprob": -0.2193238031296503, "compression_ratio": 1.6284584980237153, "no_speech_prob": 7.84366056905128e-05}, {"id": 417, "seek": 304108, "start": 3046.04, "end": 3051.72, "text": " And so it gives it a little bit more to do, you know, which can be quite helpful. It's kind of,", "tokens": [50612, 400, 370, 309, 2709, 309, 257, 707, 857, 544, 281, 360, 11, 291, 458, 11, 597, 393, 312, 1596, 4961, 13, 467, 311, 733, 295, 11, 50896], "temperature": 0.0, "avg_logprob": -0.2193238031296503, "compression_ratio": 1.6284584980237153, "no_speech_prob": 7.84366056905128e-05}, {"id": 418, "seek": 304108, "start": 3051.72, "end": 3055.72, "text": " it's a data augmentation technique and also something to give it like", "tokens": [50896, 309, 311, 257, 1412, 14501, 19631, 6532, 293, 611, 746, 281, 976, 309, 411, 51096], "temperature": 0.0, "avg_logprob": -0.2193238031296503, "compression_ratio": 1.6284584980237153, "no_speech_prob": 7.84366056905128e-05}, {"id": 419, "seek": 304108, "start": 3057.16, "end": 3059.88, "text": " more of an opportunity to learn what the pictures really look like.", "tokens": [51168, 544, 295, 364, 2650, 281, 1466, 437, 264, 5242, 534, 574, 411, 13, 51304], "temperature": 0.0, "avg_logprob": -0.2193238031296503, "compression_ratio": 1.6284584980237153, "no_speech_prob": 7.84366056905128e-05}, {"id": 420, "seek": 304108, "start": 3062.52, "end": 3067.72, "text": " Okay, so with that in case that, so these are going to do the padding, random cropping,", "tokens": [51436, 1033, 11, 370, 365, 300, 294, 1389, 300, 11, 370, 613, 366, 516, 281, 360, 264, 39562, 11, 4974, 4848, 3759, 11, 51696], "temperature": 0.0, "avg_logprob": -0.2193238031296503, "compression_ratio": 1.6284584980237153, "no_speech_prob": 7.84366056905128e-05}, {"id": 421, "seek": 306772, "start": 3067.72, "end": 3072.9199999999996, "text": " and flipping. The training set will also add random erasing. And then we create data loaders", "tokens": [50364, 293, 26886, 13, 440, 3097, 992, 486, 611, 909, 4974, 1189, 3349, 13, 400, 550, 321, 1884, 1412, 3677, 433, 50624], "temperature": 0.0, "avg_logprob": -0.2456687978796057, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0005274360883049667}, {"id": 422, "seek": 306772, "start": 3072.9199999999996, "end": 3083.64, "text": " from those. Would it make sense to use the trivial augment here? The trivial augment, did you say?", "tokens": [50624, 490, 729, 13, 6068, 309, 652, 2020, 281, 764, 264, 26703, 29919, 510, 30, 440, 26703, 29919, 11, 630, 291, 584, 30, 51160], "temperature": 0.0, "avg_logprob": -0.2456687978796057, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0005274360883049667}, {"id": 423, "seek": 306772, "start": 3084.2799999999997, "end": 3096.8399999999997, "text": " Yeah. Maybe. Yeah, I don't particularly see a reason not to. If, well, only if you found that", "tokens": [51192, 865, 13, 2704, 13, 865, 11, 286, 500, 380, 4098, 536, 257, 1778, 406, 281, 13, 759, 11, 731, 11, 787, 498, 291, 1352, 300, 51820], "temperature": 0.0, "avg_logprob": -0.2456687978796057, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.0005274360883049667}, {"id": 424, "seek": 309772, "start": 3098.68, "end": 3105.16, "text": " overfitting was a problem. And if you did do it, you would do it to both independent and", "tokens": [50412, 670, 69, 2414, 390, 257, 1154, 13, 400, 498, 291, 630, 360, 309, 11, 291, 576, 360, 309, 281, 1293, 6695, 293, 50736], "temperature": 0.0, "avg_logprob": -0.21741939009281627, "compression_ratio": 1.7926829268292683, "no_speech_prob": 3.120156179647893e-05}, {"id": 425, "seek": 309772, "start": 3105.16, "end": 3111.0, "text": " dependent variables. So yeah, here you can see an example of the independent variables. Some of the,", "tokens": [50736, 12334, 9102, 13, 407, 1338, 11, 510, 291, 393, 536, 364, 1365, 295, 264, 6695, 9102, 13, 2188, 295, 264, 11, 51028], "temperature": 0.0, "avg_logprob": -0.21741939009281627, "compression_ratio": 1.7926829268292683, "no_speech_prob": 3.120156179647893e-05}, {"id": 426, "seek": 309772, "start": 3111.0, "end": 3114.68, "text": " in this case, all of them actually have some random arrays. The dependent doesn't.", "tokens": [51028, 294, 341, 1389, 11, 439, 295, 552, 767, 362, 512, 4974, 41011, 13, 440, 12334, 1177, 380, 13, 51212], "temperature": 0.0, "avg_logprob": -0.21741939009281627, "compression_ratio": 1.7926829268292683, "no_speech_prob": 3.120156179647893e-05}, {"id": 427, "seek": 309772, "start": 3114.68, "end": 3119.56, "text": " So it has to figure out how to replace that with that. And you can also see", "tokens": [51212, 407, 309, 575, 281, 2573, 484, 577, 281, 7406, 300, 365, 300, 13, 400, 291, 393, 611, 536, 51456], "temperature": 0.0, "avg_logprob": -0.21741939009281627, "compression_ratio": 1.7926829268292683, "no_speech_prob": 3.120156179647893e-05}, {"id": 428, "seek": 309772, "start": 3121.8799999999997, "end": 3127.64, "text": " that this is very blocky. And this is less blocky. That's because this has been gone down to", "tokens": [51572, 300, 341, 307, 588, 3461, 88, 13, 400, 341, 307, 1570, 3461, 88, 13, 663, 311, 570, 341, 575, 668, 2780, 760, 281, 51860], "temperature": 0.0, "avg_logprob": -0.21741939009281627, "compression_ratio": 1.7926829268292683, "no_speech_prob": 3.120156179647893e-05}, {"id": 429, "seek": 312764, "start": 3128.2, "end": 3133.96, "text": " 32 by 32 pixels. And this one's still at the 64 by 64. So in fact, once you go down that far,", "tokens": [50392, 8858, 538, 8858, 18668, 13, 400, 341, 472, 311, 920, 412, 264, 12145, 538, 12145, 13, 407, 294, 1186, 11, 1564, 291, 352, 760, 300, 1400, 11, 50680], "temperature": 0.0, "avg_logprob": -0.20163647491152925, "compression_ratio": 1.5869565217391304, "no_speech_prob": 4.264725066605024e-05}, {"id": 430, "seek": 312764, "start": 3133.96, "end": 3137.8799999999997, "text": " the cat's lost its eyes entirely. So it's going to be quite challenging. It's lost its", "tokens": [50680, 264, 3857, 311, 2731, 1080, 2575, 7696, 13, 407, 309, 311, 516, 281, 312, 1596, 7595, 13, 467, 311, 2731, 1080, 50876], "temperature": 0.0, "avg_logprob": -0.20163647491152925, "compression_ratio": 1.5869565217391304, "no_speech_prob": 4.264725066605024e-05}, {"id": 431, "seek": 312764, "start": 3138.44, "end": 3144.92, "text": " lines entirely. So super resolution is quite a good task to try to get a model to learn what", "tokens": [50904, 3876, 7696, 13, 407, 1687, 8669, 307, 1596, 257, 665, 5633, 281, 853, 281, 483, 257, 2316, 281, 1466, 437, 51228], "temperature": 0.0, "avg_logprob": -0.20163647491152925, "compression_ratio": 1.5869565217391304, "no_speech_prob": 4.264725066605024e-05}, {"id": 432, "seek": 312764, "start": 3144.92, "end": 3150.3599999999997, "text": " pictures look like. Because it has to, yeah, figure out like how to draw an eye, and how to", "tokens": [51228, 5242, 574, 411, 13, 1436, 309, 575, 281, 11, 1338, 11, 2573, 484, 411, 577, 281, 2642, 364, 3313, 11, 293, 577, 281, 51500], "temperature": 0.0, "avg_logprob": -0.20163647491152925, "compression_ratio": 1.5869565217391304, "no_speech_prob": 4.264725066605024e-05}, {"id": 433, "seek": 315036, "start": 3150.36, "end": 3156.6800000000003, "text": " draw cat's whiskers, and things like that. Were you going to say something, Jono? Sorry.", "tokens": [50364, 2642, 3857, 311, 24485, 433, 11, 293, 721, 411, 300, 13, 12448, 291, 516, 281, 584, 746, 11, 7745, 78, 30, 4919, 13, 50680], "temperature": 0.0, "avg_logprob": -0.3959042257513882, "compression_ratio": 1.5192982456140351, "no_speech_prob": 0.01665155217051506}, {"id": 434, "seek": 315036, "start": 3156.6800000000003, "end": 3157.56, "text": " JONO GRANTHAM", "tokens": [50680, 27838, 46, 30204, 39, 2865, 50724], "temperature": 0.0, "avg_logprob": -0.3959042257513882, "compression_ratio": 1.5192982456140351, "no_speech_prob": 0.01665155217051506}, {"id": 435, "seek": 315036, "start": 3158.6, "end": 3162.1200000000003, "text": " Oh, I was just going to point out that the datasets are also simpler because you don't", "tokens": [50776, 876, 11, 286, 390, 445, 516, 281, 935, 484, 300, 264, 42856, 366, 611, 18587, 570, 291, 500, 380, 50952], "temperature": 0.0, "avg_logprob": -0.3959042257513882, "compression_ratio": 1.5192982456140351, "no_speech_prob": 0.01665155217051506}, {"id": 436, "seek": 315036, "start": 3162.1200000000003, "end": 3166.6, "text": " have to load the labels. So there's no difference between the train and the validation. Now it's", "tokens": [50952, 362, 281, 3677, 264, 16949, 13, 407, 456, 311, 572, 2649, 1296, 264, 3847, 293, 264, 24071, 13, 823, 309, 311, 51176], "temperature": 0.0, "avg_logprob": -0.3959042257513882, "compression_ratio": 1.5192982456140351, "no_speech_prob": 0.01665155217051506}, {"id": 437, "seek": 315036, "start": 3166.6, "end": 3167.6400000000003, "text": " just finding all the images.", "tokens": [51176, 445, 5006, 439, 264, 5267, 13, 51228], "temperature": 0.0, "avg_logprob": -0.3959042257513882, "compression_ratio": 1.5192982456140351, "no_speech_prob": 0.01665155217051506}, {"id": 438, "seek": 315036, "start": 3167.6400000000003, "end": 3167.7200000000003, "text": " SIMON RIGGEDALL", "tokens": [51228, 24738, 1928, 497, 10489, 38, 4731, 32, 24010, 51232], "temperature": 0.0, "avg_logprob": -0.3959042257513882, "compression_ratio": 1.5192982456140351, "no_speech_prob": 0.01665155217051506}, {"id": 439, "seek": 315036, "start": 3167.7200000000003, "end": 3173.4, "text": " Good point. Yeah. Because the label, you know, is actually a dependent variable, is just the picture.", "tokens": [51232, 2205, 935, 13, 865, 13, 1436, 264, 7645, 11, 291, 458, 11, 307, 767, 257, 12334, 7006, 11, 307, 445, 264, 3036, 13, 51516], "temperature": 0.0, "avg_logprob": -0.3959042257513882, "compression_ratio": 1.5192982456140351, "no_speech_prob": 0.01665155217051506}, {"id": 440, "seek": 317340, "start": 3174.36, "end": 3188.2000000000003, "text": " And so, okay, so because TwfmDS has a TwfmX, which is only applied to the independent variable,", "tokens": [50412, 400, 370, 11, 1392, 11, 370, 570, 2574, 69, 76, 11844, 575, 257, 2574, 69, 76, 55, 11, 597, 307, 787, 6456, 281, 264, 6695, 7006, 11, 51104], "temperature": 0.0, "avg_logprob": -0.3077144269590025, "compression_ratio": 1.4296296296296296, "no_speech_prob": 0.0006770493346266448}, {"id": 441, "seek": 317340, "start": 3189.64, "end": 3197.88, "text": " the independent variable has applied to it this pair of resize to 32 by 32, and then interpolate.", "tokens": [51176, 264, 6695, 7006, 575, 6456, 281, 309, 341, 6119, 295, 50069, 281, 8858, 538, 8858, 11, 293, 550, 44902, 473, 13, 51588], "temperature": 0.0, "avg_logprob": -0.3077144269590025, "compression_ratio": 1.4296296296296296, "no_speech_prob": 0.0006770493346266448}, {"id": 442, "seek": 319788, "start": 3198.76, "end": 3205.6400000000003, "text": " And what that actually does is it ends up still with a 64 by 64 image, but the pixels in that", "tokens": [50408, 400, 437, 300, 767, 775, 307, 309, 5314, 493, 920, 365, 257, 12145, 538, 12145, 3256, 11, 457, 264, 18668, 294, 300, 50752], "temperature": 0.0, "avg_logprob": -0.19737756018545113, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0003459750732872635}, {"id": 443, "seek": 319788, "start": 3205.6400000000003, "end": 3212.36, "text": " image are all like doubled up. And so that means that it's still doing super resolution, but it's", "tokens": [50752, 3256, 366, 439, 411, 24405, 493, 13, 400, 370, 300, 1355, 300, 309, 311, 920, 884, 1687, 8669, 11, 457, 309, 311, 51088], "temperature": 0.0, "avg_logprob": -0.19737756018545113, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0003459750732872635}, {"id": 444, "seek": 319788, "start": 3212.36, "end": 3218.28, "text": " not actually going from 32 by 32 to 64 by 64. But it's just going from the 64 by 64, where all of", "tokens": [51088, 406, 767, 516, 490, 8858, 538, 8858, 281, 12145, 538, 12145, 13, 583, 309, 311, 445, 516, 490, 264, 12145, 538, 12145, 11, 689, 439, 295, 51384], "temperature": 0.0, "avg_logprob": -0.19737756018545113, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0003459750732872635}, {"id": 445, "seek": 319788, "start": 3218.28, "end": 3222.6800000000003, "text": " the pixels are like two by two pixels. And it's just a little bit easier, because that way,", "tokens": [51384, 264, 18668, 366, 411, 732, 538, 732, 18668, 13, 400, 309, 311, 445, 257, 707, 857, 3571, 11, 570, 300, 636, 11, 51604], "temperature": 0.0, "avg_logprob": -0.19737756018545113, "compression_ratio": 1.8056872037914693, "no_speech_prob": 0.0003459750732872635}, {"id": 446, "seek": 322268, "start": 3223.64, "end": 3230.8399999999997, "text": " we could certainly create a unit that goes from 32 to 64. But if you have the input and output", "tokens": [50412, 321, 727, 3297, 1884, 257, 4985, 300, 1709, 490, 8858, 281, 12145, 13, 583, 498, 291, 362, 264, 4846, 293, 5598, 50772], "temperature": 0.0, "avg_logprob": -0.21115262648638558, "compression_ratio": 1.5248868778280542, "no_speech_prob": 7.030829874565825e-05}, {"id": 447, "seek": 322268, "start": 3230.8399999999997, "end": 3235.7999999999997, "text": " image the same size, it can make code a little bit simpler. I originally started doing it by", "tokens": [50772, 3256, 264, 912, 2744, 11, 309, 393, 652, 3089, 257, 707, 857, 18587, 13, 286, 7993, 1409, 884, 309, 538, 51020], "temperature": 0.0, "avg_logprob": -0.21115262648638558, "compression_ratio": 1.5248868778280542, "no_speech_prob": 7.030829874565825e-05}, {"id": 448, "seek": 322268, "start": 3236.7599999999998, "end": 3240.3599999999997, "text": " not doing this interpolate thing. And then I decided I was just getting a little bit", "tokens": [51068, 406, 884, 341, 44902, 473, 551, 13, 400, 550, 286, 3047, 286, 390, 445, 1242, 257, 707, 857, 51248], "temperature": 0.0, "avg_logprob": -0.21115262648638558, "compression_ratio": 1.5248868778280542, "no_speech_prob": 7.030829874565825e-05}, {"id": 449, "seek": 322268, "start": 3240.3599999999997, "end": 3243.56, "text": " confusing. And there's no reason not to do it this way, frankly.", "tokens": [51248, 13181, 13, 400, 456, 311, 572, 1778, 406, 281, 360, 309, 341, 636, 11, 11939, 13, 51408], "temperature": 0.0, "avg_logprob": -0.21115262648638558, "compression_ratio": 1.5248868778280542, "no_speech_prob": 7.030829874565825e-05}, {"id": 450, "seek": 324356, "start": 3244.36, "end": 3253.24, "text": " Okay, so that's our task. And the idea is that then, if it does a good job of this, you know,", "tokens": [50404, 1033, 11, 370, 300, 311, 527, 5633, 13, 400, 264, 1558, 307, 300, 550, 11, 498, 309, 775, 257, 665, 1691, 295, 341, 11, 291, 458, 11, 50848], "temperature": 0.0, "avg_logprob": -0.22031654914220175, "compression_ratio": 1.6017316017316017, "no_speech_prob": 0.002672872506082058}, {"id": 451, "seek": 324356, "start": 3253.24, "end": 3258.84, "text": " you could pass 64 by 64 images into it, and hopefully it might turn them into 128 by 128", "tokens": [50848, 291, 727, 1320, 12145, 538, 12145, 5267, 666, 309, 11, 293, 4696, 309, 1062, 1261, 552, 666, 29810, 538, 29810, 51128], "temperature": 0.0, "avg_logprob": -0.22031654914220175, "compression_ratio": 1.6017316017316017, "no_speech_prob": 0.002672872506082058}, {"id": 452, "seek": 324356, "start": 3258.84, "end": 3263.7999999999997, "text": " images. Particularly if you trained it on a few different resolutions, you'd expect it to get", "tokens": [51128, 5267, 13, 32281, 498, 291, 8895, 309, 322, 257, 1326, 819, 32179, 11, 291, 1116, 2066, 309, 281, 483, 51376], "temperature": 0.0, "avg_logprob": -0.22031654914220175, "compression_ratio": 1.6017316017316017, "no_speech_prob": 0.002672872506082058}, {"id": 453, "seek": 324356, "start": 3263.7999999999997, "end": 3268.68, "text": " pretty good at, you know, resizing things to a bunch of different resolutions. You could even", "tokens": [51376, 1238, 665, 412, 11, 291, 458, 11, 725, 3319, 721, 281, 257, 3840, 295, 819, 32179, 13, 509, 727, 754, 51620], "temperature": 0.0, "avg_logprob": -0.22031654914220175, "compression_ratio": 1.6017316017316017, "no_speech_prob": 0.002672872506082058}, {"id": 454, "seek": 326868, "start": 3268.68, "end": 3276.68, "text": " call it multiple times. But anyway, for this, I was just kind of doing it to demonstrate. But we", "tokens": [50364, 818, 309, 3866, 1413, 13, 583, 4033, 11, 337, 341, 11, 286, 390, 445, 733, 295, 884, 309, 281, 11698, 13, 583, 321, 50764], "temperature": 0.0, "avg_logprob": -0.22342250658118207, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.0002823986578732729}, {"id": 455, "seek": 326868, "start": 3276.68, "end": 3282.3599999999997, "text": " have in previous courses trained, you know, bigger ones for longer with larger images. And they", "tokens": [50764, 362, 294, 3894, 7712, 8895, 11, 291, 458, 11, 3801, 2306, 337, 2854, 365, 4833, 5267, 13, 400, 436, 51048], "temperature": 0.0, "avg_logprob": -0.22342250658118207, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.0002823986578732729}, {"id": 456, "seek": 326868, "start": 3282.3599999999997, "end": 3287.72, "text": " actually do one of the interesting things is they tend to not only do super resolution, but they", "tokens": [51048, 767, 360, 472, 295, 264, 1880, 721, 307, 436, 3928, 281, 406, 787, 360, 1687, 8669, 11, 457, 436, 51316], "temperature": 0.0, "avg_logprob": -0.22342250658118207, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.0002823986578732729}, {"id": 457, "seek": 326868, "start": 3287.72, "end": 3294.04, "text": " often make the images look better. Because the kind of the pixels it fills in, it kind of fills", "tokens": [51316, 2049, 652, 264, 5267, 574, 1101, 13, 1436, 264, 733, 295, 264, 18668, 309, 22498, 294, 11, 309, 733, 295, 22498, 51632], "temperature": 0.0, "avg_logprob": -0.22342250658118207, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.0002823986578732729}, {"id": 458, "seek": 329404, "start": 3294.12, "end": 3302.04, "text": " in with like, what that image looks like on average, which tends to kind of like average out", "tokens": [50368, 294, 365, 411, 11, 437, 300, 3256, 1542, 411, 322, 4274, 11, 597, 12258, 281, 733, 295, 411, 4274, 484, 50764], "temperature": 0.0, "avg_logprob": -0.21479949951171876, "compression_ratio": 1.75, "no_speech_prob": 4.133516995352693e-05}, {"id": 459, "seek": 329404, "start": 3302.7599999999998, "end": 3307.4, "text": " imperfections. So often these super resolution models actually improve image quality as well,", "tokens": [50800, 26714, 626, 13, 407, 2049, 613, 1687, 8669, 5245, 767, 3470, 3256, 3125, 382, 731, 11, 51032], "temperature": 0.0, "avg_logprob": -0.21479949951171876, "compression_ratio": 1.75, "no_speech_prob": 4.133516995352693e-05}, {"id": 460, "seek": 329404, "start": 3307.4, "end": 3314.12, "text": " funnily enough. Okay, so let's consider the dumb way to do things. We've seen a kind of a dumb way", "tokens": [51032, 1019, 77, 953, 1547, 13, 1033, 11, 370, 718, 311, 1949, 264, 10316, 636, 281, 360, 721, 13, 492, 600, 1612, 257, 733, 295, 257, 10316, 636, 51368], "temperature": 0.0, "avg_logprob": -0.21479949951171876, "compression_ratio": 1.75, "no_speech_prob": 4.133516995352693e-05}, {"id": 461, "seek": 329404, "start": 3314.12, "end": 3319.0, "text": " to do things before, which is an autoencoder. So go in with low expectations here, because we've", "tokens": [51368, 281, 360, 721, 949, 11, 597, 307, 364, 8399, 22660, 19866, 13, 407, 352, 294, 365, 2295, 9843, 510, 11, 570, 321, 600, 51612], "temperature": 0.0, "avg_logprob": -0.21479949951171876, "compression_ratio": 1.75, "no_speech_prob": 4.133516995352693e-05}, {"id": 462, "seek": 329404, "start": 3319.0, "end": 3322.92, "text": " done an autoencoder before. And it was so bad, it actually inspired us to create the learner,", "tokens": [51612, 1096, 364, 8399, 22660, 19866, 949, 13, 400, 309, 390, 370, 1578, 11, 309, 767, 7547, 505, 281, 1884, 264, 33347, 11, 51808], "temperature": 0.0, "avg_logprob": -0.21479949951171876, "compression_ratio": 1.75, "no_speech_prob": 4.133516995352693e-05}, {"id": 463, "seek": 332292, "start": 3322.92, "end": 3328.92, "text": " if you remember. So that was back in notebook 8. And so basically, what we're going to do", "tokens": [50364, 498, 291, 1604, 13, 407, 300, 390, 646, 294, 21060, 1649, 13, 400, 370, 1936, 11, 437, 321, 434, 516, 281, 360, 50664], "temperature": 0.0, "avg_logprob": -0.21206105219853388, "compression_ratio": 1.55, "no_speech_prob": 7.001757467151037e-07}, {"id": 464, "seek": 332292, "start": 3329.8, "end": 3335.2400000000002, "text": " is we're going to have a model which looks a lot like previous models. It starts with a res", "tokens": [50708, 307, 321, 434, 516, 281, 362, 257, 2316, 597, 1542, 257, 688, 411, 3894, 5245, 13, 467, 3719, 365, 257, 725, 50980], "temperature": 0.0, "avg_logprob": -0.21206105219853388, "compression_ratio": 1.55, "no_speech_prob": 7.001757467151037e-07}, {"id": 465, "seek": 332292, "start": 3335.2400000000002, "end": 3345.08, "text": " block kernel size 5. And then it's got a bunch of res blocks of stride 2. But then we're going to", "tokens": [50980, 3461, 28256, 2744, 1025, 13, 400, 550, 309, 311, 658, 257, 3840, 295, 725, 8474, 295, 1056, 482, 568, 13, 583, 550, 321, 434, 516, 281, 51472], "temperature": 0.0, "avg_logprob": -0.21206105219853388, "compression_ratio": 1.55, "no_speech_prob": 7.001757467151037e-07}, {"id": 466, "seek": 334508, "start": 3345.08, "end": 3352.7599999999998, "text": " have an equal number of up blocks. And what an up block is going to do, is it's going to", "tokens": [50364, 362, 364, 2681, 1230, 295, 493, 8474, 13, 400, 437, 364, 493, 3461, 307, 516, 281, 360, 11, 307, 309, 311, 516, 281, 50748], "temperature": 0.0, "avg_logprob": -0.1931303816956359, "compression_ratio": 1.6449704142011834, "no_speech_prob": 0.0001072085797204636}, {"id": 467, "seek": 334508, "start": 3352.7599999999998, "end": 3357.7999999999997, "text": " sequentially, first of all, it's going to do an up sampling nearest 2d, which is actually identical", "tokens": [50748, 5123, 3137, 11, 700, 295, 439, 11, 309, 311, 516, 281, 360, 364, 493, 21179, 23831, 568, 67, 11, 597, 307, 767, 14800, 51000], "temperature": 0.0, "avg_logprob": -0.1931303816956359, "compression_ratio": 1.6449704142011834, "no_speech_prob": 0.0001072085797204636}, {"id": 468, "seek": 334508, "start": 3359.72, "end": 3367.3199999999997, "text": " to this. Right, so it's going to just double all the pixels. And then we're going to pass", "tokens": [51096, 281, 341, 13, 1779, 11, 370, 309, 311, 516, 281, 445, 3834, 439, 264, 18668, 13, 400, 550, 321, 434, 516, 281, 1320, 51476], "temperature": 0.0, "avg_logprob": -0.1931303816956359, "compression_ratio": 1.6449704142011834, "no_speech_prob": 0.0001072085797204636}, {"id": 469, "seek": 336732, "start": 3367.32, "end": 3376.1200000000003, "text": " that through a res block. So it's basically a res block with like a stride of a half, if you like.", "tokens": [50364, 300, 807, 257, 725, 3461, 13, 407, 309, 311, 1936, 257, 725, 3461, 365, 411, 257, 1056, 482, 295, 257, 1922, 11, 498, 291, 411, 13, 50804], "temperature": 0.0, "avg_logprob": -0.1907809885536752, "compression_ratio": 1.559782608695652, "no_speech_prob": 2.5466380975558423e-05}, {"id": 470, "seek": 336732, "start": 3376.1200000000003, "end": 3384.6800000000003, "text": " You know, it's undoing a stride 2. It's up sampling rather than down sampling. Okay, so", "tokens": [50804, 509, 458, 11, 309, 311, 23779, 278, 257, 1056, 482, 568, 13, 467, 311, 493, 21179, 2831, 813, 760, 21179, 13, 1033, 11, 370, 51232], "temperature": 0.0, "avg_logprob": -0.1907809885536752, "compression_ratio": 1.559782608695652, "no_speech_prob": 2.5466380975558423e-05}, {"id": 471, "seek": 336732, "start": 3385.7200000000003, "end": 3389.96, "text": " and then we'll have an extra res block at the end to get it down to three channels, which is what we", "tokens": [51284, 293, 550, 321, 603, 362, 364, 2857, 725, 3461, 412, 264, 917, 281, 483, 309, 760, 281, 1045, 9235, 11, 597, 307, 437, 321, 51496], "temperature": 0.0, "avg_logprob": -0.1907809885536752, "compression_ratio": 1.559782608695652, "no_speech_prob": 2.5466380975558423e-05}, {"id": 472, "seek": 338996, "start": 3389.96, "end": 3403.16, "text": " need. Okay, so we can do our learning rate finder on that. And I just train it pretty briefly for", "tokens": [50364, 643, 13, 1033, 11, 370, 321, 393, 360, 527, 2539, 3314, 915, 260, 322, 300, 13, 400, 286, 445, 3847, 309, 1238, 10515, 337, 51024], "temperature": 0.0, "avg_logprob": -0.2218345668580797, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.00028684744029305875}, {"id": 473, "seek": 338996, "start": 3403.16, "end": 3410.6, "text": " five epochs. So this model is basically trying to take the image that we start up, then kind of", "tokens": [51024, 1732, 30992, 28346, 13, 407, 341, 2316, 307, 1936, 1382, 281, 747, 264, 3256, 300, 321, 722, 493, 11, 550, 733, 295, 51396], "temperature": 0.0, "avg_logprob": -0.2218345668580797, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.00028684744029305875}, {"id": 474, "seek": 338996, "start": 3410.6, "end": 3414.84, "text": " really squeeze it into, I guess, a small representation. And then try to bring that", "tokens": [51396, 534, 13578, 309, 666, 11, 286, 2041, 11, 257, 1359, 10290, 13, 400, 550, 853, 281, 1565, 300, 51608], "temperature": 0.0, "avg_logprob": -0.2218345668580797, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.00028684744029305875}, {"id": 475, "seek": 341484, "start": 3414.84, "end": 3419.2400000000002, "text": " small representation back up to then the full super resolution image. Is that correct?", "tokens": [50364, 1359, 10290, 646, 493, 281, 550, 264, 1577, 1687, 8669, 3256, 13, 1119, 300, 3006, 30, 50584], "temperature": 0.0, "avg_logprob": -0.20712143580118816, "compression_ratio": 1.595959595959596, "no_speech_prob": 8.34913516882807e-05}, {"id": 476, "seek": 341484, "start": 3419.2400000000002, "end": 3425.32, "text": " Exactly right, Tanishka. And we could have done it without any of the stride 2. You know, I guess we", "tokens": [50584, 7587, 558, 11, 314, 7524, 2330, 13, 400, 321, 727, 362, 1096, 309, 1553, 604, 295, 264, 1056, 482, 568, 13, 509, 458, 11, 286, 2041, 321, 50888], "temperature": 0.0, "avg_logprob": -0.20712143580118816, "compression_ratio": 1.595959595959596, "no_speech_prob": 8.34913516882807e-05}, {"id": 477, "seek": 341484, "start": 3425.32, "end": 3430.52, "text": " could have just had a whole bunch of stride 1 layers. There's a few reasons not to do it that", "tokens": [50888, 727, 362, 445, 632, 257, 1379, 3840, 295, 1056, 482, 502, 7914, 13, 821, 311, 257, 1326, 4112, 406, 281, 360, 309, 300, 51148], "temperature": 0.0, "avg_logprob": -0.20712143580118816, "compression_ratio": 1.595959595959596, "no_speech_prob": 8.34913516882807e-05}, {"id": 478, "seek": 341484, "start": 3430.52, "end": 3435.08, "text": " way though. One is obviously just the computation requirements are very high, because the convolution", "tokens": [51148, 636, 1673, 13, 1485, 307, 2745, 445, 264, 24903, 7728, 366, 588, 1090, 11, 570, 264, 45216, 51376], "temperature": 0.0, "avg_logprob": -0.20712143580118816, "compression_ratio": 1.595959595959596, "no_speech_prob": 8.34913516882807e-05}, {"id": 479, "seek": 341484, "start": 3435.08, "end": 3441.88, "text": " has to scan over the image. And so when you keep it at 64 by 64, that's a lot of scanning.", "tokens": [51376, 575, 281, 11049, 670, 264, 3256, 13, 400, 370, 562, 291, 1066, 309, 412, 12145, 538, 12145, 11, 300, 311, 257, 688, 295, 27019, 13, 51716], "temperature": 0.0, "avg_logprob": -0.20712143580118816, "compression_ratio": 1.595959595959596, "no_speech_prob": 8.34913516882807e-05}, {"id": 480, "seek": 344188, "start": 3442.6800000000003, "end": 3450.84, "text": " Another is that you're never kind of forcing it to learn higher level abstractions by recognizing", "tokens": [50404, 3996, 307, 300, 291, 434, 1128, 733, 295, 19030, 309, 281, 1466, 2946, 1496, 12649, 626, 538, 18538, 50812], "temperature": 0.0, "avg_logprob": -0.18543082789370888, "compression_ratio": 1.5583333333333333, "no_speech_prob": 2.2602957869821694e-06}, {"id": 481, "seek": 344188, "start": 3450.84, "end": 3456.2000000000003, "text": " how to kind of like, you know, use more channels on a smaller grid size to represent it.", "tokens": [50812, 577, 281, 733, 295, 411, 11, 291, 458, 11, 764, 544, 9235, 322, 257, 4356, 10748, 2744, 281, 2906, 309, 13, 51080], "temperature": 0.0, "avg_logprob": -0.18543082789370888, "compression_ratio": 1.5583333333333333, "no_speech_prob": 2.2602957869821694e-06}, {"id": 482, "seek": 344188, "start": 3458.12, "end": 3465.32, "text": " So yeah, it's like the same reason that we, in classifiers, we don't leave it at stride 1 the", "tokens": [51176, 407, 1338, 11, 309, 311, 411, 264, 912, 1778, 300, 321, 11, 294, 1508, 23463, 11, 321, 500, 380, 1856, 309, 412, 1056, 482, 502, 264, 51536], "temperature": 0.0, "avg_logprob": -0.18543082789370888, "compression_ratio": 1.5583333333333333, "no_speech_prob": 2.2602957869821694e-06}, {"id": 483, "seek": 344188, "start": 3465.32, "end": 3469.1600000000003, "text": " whole time. You know, you end up with something that's inefficient and generally not as good.", "tokens": [51536, 1379, 565, 13, 509, 458, 11, 291, 917, 493, 365, 746, 300, 311, 43495, 293, 5101, 406, 382, 665, 13, 51728], "temperature": 0.0, "avg_logprob": -0.18543082789370888, "compression_ratio": 1.5583333333333333, "no_speech_prob": 2.2602957869821694e-06}, {"id": 484, "seek": 346916, "start": 3470.12, "end": 3477.3999999999996, "text": " Exactly, yep. Thanks for clarifying, Tanishka. Okay, so the loss goes down. And the loss function", "tokens": [50412, 7587, 11, 18633, 13, 2561, 337, 6093, 5489, 11, 314, 7524, 2330, 13, 1033, 11, 370, 264, 4470, 1709, 760, 13, 400, 264, 4470, 2445, 50776], "temperature": 0.0, "avg_logprob": -0.2612661157996909, "compression_ratio": 1.6092436974789917, "no_speech_prob": 1.7778091205400415e-05}, {"id": 485, "seek": 346916, "start": 3477.3999999999996, "end": 3482.52, "text": " I'm using is just mse here, right? So it's how similar is each pixel to the pixel it's meant to be.", "tokens": [50776, 286, 478, 1228, 307, 445, 275, 405, 510, 11, 558, 30, 407, 309, 311, 577, 2531, 307, 1184, 19261, 281, 264, 19261, 309, 311, 4140, 281, 312, 13, 51032], "temperature": 0.0, "avg_logprob": -0.2612661157996909, "compression_ratio": 1.6092436974789917, "no_speech_prob": 1.7778091205400415e-05}, {"id": 486, "seek": 346916, "start": 3485.0, "end": 3491.16, "text": " And so then I can call capture preds to get the predictions and the targets and the inputs,", "tokens": [51156, 400, 370, 550, 286, 393, 818, 7983, 3852, 82, 281, 483, 264, 21264, 293, 264, 12911, 293, 264, 15743, 11, 51464], "temperature": 0.0, "avg_logprob": -0.2612661157996909, "compression_ratio": 1.6092436974789917, "no_speech_prob": 1.7778091205400415e-05}, {"id": 487, "seek": 346916, "start": 3491.16, "end": 3496.8399999999997, "text": " or probabilities, targets and inputs. I can't quite remember now. So here's our input images.", "tokens": [51464, 420, 33783, 11, 12911, 293, 15743, 13, 286, 393, 380, 1596, 1604, 586, 13, 407, 510, 311, 527, 4846, 5267, 13, 51748], "temperature": 0.0, "avg_logprob": -0.2612661157996909, "compression_ratio": 1.6092436974789917, "no_speech_prob": 1.7778091205400415e-05}, {"id": 488, "seek": 349916, "start": 3499.16, "end": 3508.68, "text": " So they're pretty low resolution. And oh dear, here's our predicted images. So pretty terrible.", "tokens": [50364, 407, 436, 434, 1238, 2295, 8669, 13, 400, 1954, 6875, 11, 510, 311, 527, 19147, 5267, 13, 407, 1238, 6237, 13, 50840], "temperature": 0.0, "avg_logprob": -0.20326218539721344, "compression_ratio": 1.433862433862434, "no_speech_prob": 3.2058105148280447e-07}, {"id": 489, "seek": 349916, "start": 3511.3199999999997, "end": 3518.52, "text": " So why is that? Well, basically, it's kind of like the problem we had with our earlier auto", "tokens": [50972, 407, 983, 307, 300, 30, 1042, 11, 1936, 11, 309, 311, 733, 295, 411, 264, 1154, 321, 632, 365, 527, 3071, 8399, 51332], "temperature": 0.0, "avg_logprob": -0.20326218539721344, "compression_ratio": 1.433862433862434, "no_speech_prob": 3.2058105148280447e-07}, {"id": 490, "seek": 349916, "start": 3518.52, "end": 3525.7999999999997, "text": " encoder. It's really difficult to go from like a 2 by 2 or 4 by 4 or whatever image", "tokens": [51332, 2058, 19866, 13, 467, 311, 534, 2252, 281, 352, 490, 411, 257, 568, 538, 568, 420, 1017, 538, 1017, 420, 2035, 3256, 51696], "temperature": 0.0, "avg_logprob": -0.20326218539721344, "compression_ratio": 1.433862433862434, "no_speech_prob": 3.2058105148280447e-07}, {"id": 491, "seek": 352580, "start": 3526.2000000000003, "end": 3531.96, "text": " into a 64 by 64 image, you know. We're asking it to do something that's just really challenging.", "tokens": [50384, 666, 257, 12145, 538, 12145, 3256, 11, 291, 458, 13, 492, 434, 3365, 309, 281, 360, 746, 300, 311, 445, 534, 7595, 13, 50672], "temperature": 0.0, "avg_logprob": -0.2621919314066569, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.241145764652174e-05}, {"id": 492, "seek": 352580, "start": 3531.96, "end": 3538.1200000000003, "text": " And so that would require a much bigger model trained for a much longer amount of time. I'm", "tokens": [50672, 400, 370, 300, 576, 3651, 257, 709, 3801, 2316, 8895, 337, 257, 709, 2854, 2372, 295, 565, 13, 286, 478, 50980], "temperature": 0.0, "avg_logprob": -0.2621919314066569, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.241145764652174e-05}, {"id": 493, "seek": 352580, "start": 3538.1200000000003, "end": 3545.96, "text": " sure it's possible. And in fact, you know, latent diffusion, as we've talked about,", "tokens": [50980, 988, 309, 311, 1944, 13, 400, 294, 1186, 11, 291, 458, 11, 48994, 25242, 11, 382, 321, 600, 2825, 466, 11, 51372], "temperature": 0.0, "avg_logprob": -0.2621919314066569, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.241145764652174e-05}, {"id": 494, "seek": 352580, "start": 3546.6000000000004, "end": 3553.4, "text": " has a model that kind of does exactly that. But in our case, there's no need to make it", "tokens": [51404, 575, 257, 2316, 300, 733, 295, 775, 2293, 300, 13, 583, 294, 527, 1389, 11, 456, 311, 572, 643, 281, 652, 309, 51744], "temperature": 0.0, "avg_logprob": -0.2621919314066569, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.241145764652174e-05}, {"id": 495, "seek": 355340, "start": 3553.56, "end": 3564.6800000000003, "text": " so complicated. We can actually do something dramatically easier, which is we can create a", "tokens": [50372, 370, 6179, 13, 492, 393, 767, 360, 746, 17548, 3571, 11, 597, 307, 321, 393, 1884, 257, 50928], "temperature": 0.0, "avg_logprob": -0.4074875967843192, "compression_ratio": 1.4031007751937985, "no_speech_prob": 3.7853017147426726e-06}, {"id": 496, "seek": 355340, "start": 3565.64, "end": 3575.2400000000002, "text": " a UNet. So UNets were originally developed in 2015. And they were originally developed for", "tokens": [50976, 257, 8229, 302, 13, 407, 8229, 1385, 645, 7993, 4743, 294, 7546, 13, 400, 436, 645, 7993, 4743, 337, 51456], "temperature": 0.0, "avg_logprob": -0.4074875967843192, "compression_ratio": 1.4031007751937985, "no_speech_prob": 3.7853017147426726e-06}, {"id": 497, "seek": 357524, "start": 3576.2, "end": 3585.24, "text": " medical imaging. But they've been used very, very widely since. And I was involved in medical", "tokens": [50412, 4625, 25036, 13, 583, 436, 600, 668, 1143, 588, 11, 588, 13371, 1670, 13, 400, 286, 390, 3288, 294, 4625, 50864], "temperature": 0.0, "avg_logprob": -0.21102538289903086, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.00013135017070453614}, {"id": 498, "seek": 357524, "start": 3585.24, "end": 3589.24, "text": " imaging at the time they came out. And certainly they quite quickly got recognized in medical", "tokens": [50864, 25036, 412, 264, 565, 436, 1361, 484, 13, 400, 3297, 436, 1596, 2661, 658, 9823, 294, 4625, 51064], "temperature": 0.0, "avg_logprob": -0.21102538289903086, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.00013135017070453614}, {"id": 499, "seek": 357524, "start": 3589.24, "end": 3592.9199999999996, "text": " imaging. They took a little bit longer to get recognized elsewhere. But nowadays,", "tokens": [51064, 25036, 13, 814, 1890, 257, 707, 857, 2854, 281, 483, 9823, 14517, 13, 583, 13434, 11, 51248], "temperature": 0.0, "avg_logprob": -0.21102538289903086, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.00013135017070453614}, {"id": 500, "seek": 357524, "start": 3592.9199999999996, "end": 3598.2799999999997, "text": " they're pretty universal. And they are used in stable diffusion. And basically,", "tokens": [51248, 436, 434, 1238, 11455, 13, 400, 436, 366, 1143, 294, 8351, 25242, 13, 400, 1936, 11, 51516], "temperature": 0.0, "avg_logprob": -0.21102538289903086, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.00013135017070453614}, {"id": 501, "seek": 359828, "start": 3599.0800000000004, "end": 3605.48, "text": " some of the details don't matter here. This is like the original paper. So let's focus on the", "tokens": [50404, 512, 295, 264, 4365, 500, 380, 1871, 510, 13, 639, 307, 411, 264, 3380, 3035, 13, 407, 718, 311, 1879, 322, 264, 50724], "temperature": 0.0, "avg_logprob": -0.21214085358839768, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.141831156332046e-05}, {"id": 502, "seek": 359828, "start": 3605.48, "end": 3610.76, "text": " kind of the broad idea. This thing here is called the, we're going to call it the downsampling path.", "tokens": [50724, 733, 295, 264, 4152, 1558, 13, 639, 551, 510, 307, 1219, 264, 11, 321, 434, 516, 281, 818, 309, 264, 760, 19988, 11970, 3100, 13, 50988], "temperature": 0.0, "avg_logprob": -0.21214085358839768, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.141831156332046e-05}, {"id": 503, "seek": 359828, "start": 3610.76, "end": 3617.5600000000004, "text": " So in this case, they started with 572 by 572 images. And it looks like they started with", "tokens": [50988, 407, 294, 341, 1389, 11, 436, 1409, 365, 21423, 17, 538, 21423, 17, 5267, 13, 400, 309, 1542, 411, 436, 1409, 365, 51328], "temperature": 0.0, "avg_logprob": -0.21214085358839768, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.141831156332046e-05}, {"id": 504, "seek": 359828, "start": 3617.5600000000004, "end": 3623.48, "text": " one channel images. And then they, you know, as we've seen, then they took them down to 284 by", "tokens": [51328, 472, 2269, 5267, 13, 400, 550, 436, 11, 291, 458, 11, 382, 321, 600, 1612, 11, 550, 436, 1890, 552, 760, 281, 7562, 19, 538, 51624], "temperature": 0.0, "avg_logprob": -0.21214085358839768, "compression_ratio": 1.676991150442478, "no_speech_prob": 7.141831156332046e-05}, {"id": 505, "seek": 362348, "start": 3623.48, "end": 3633.8, "text": " 284 by 128. And then down to 140 by 140 by 256. And then down to 68 by 68 by 512. 32 by 32 by 1024.", "tokens": [50364, 7562, 19, 538, 29810, 13, 400, 550, 760, 281, 21548, 538, 21548, 538, 38882, 13, 400, 550, 760, 281, 23317, 538, 23317, 538, 1025, 4762, 13, 8858, 538, 8858, 538, 1266, 7911, 13, 50880], "temperature": 0.0, "avg_logprob": -0.21935959700699692, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.00030534627148881555}, {"id": 506, "seek": 362348, "start": 3633.8, "end": 3639.2400000000002, "text": " So here's this downsampling path. And then the upsampling path is exactly what we've seen before.", "tokens": [50880, 407, 510, 311, 341, 760, 19988, 11970, 3100, 13, 400, 550, 264, 15497, 335, 11970, 3100, 307, 2293, 437, 321, 600, 1612, 949, 13, 51152], "temperature": 0.0, "avg_logprob": -0.21935959700699692, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.00030534627148881555}, {"id": 507, "seek": 362348, "start": 3639.2400000000002, "end": 3645.64, "text": " Right. So we upsample and have some, I mean, in the original thing, they didn't use resnets", "tokens": [51152, 1779, 13, 407, 321, 15497, 335, 781, 293, 362, 512, 11, 286, 914, 11, 294, 264, 3380, 551, 11, 436, 994, 380, 764, 725, 77, 1385, 51472], "temperature": 0.0, "avg_logprob": -0.21935959700699692, "compression_ratio": 1.5966850828729282, "no_speech_prob": 0.00030534627148881555}, {"id": 508, "seek": 364564, "start": 3645.64, "end": 3651.24, "text": " or resblocks. They just use convs. So the idea is the same.", "tokens": [50364, 420, 725, 15962, 2761, 13, 814, 445, 764, 3754, 82, 13, 407, 264, 1558, 307, 264, 912, 13, 50644], "temperature": 0.0, "avg_logprob": -0.23560134569803873, "compression_ratio": 1.4320987654320987, "no_speech_prob": 4.092893050255952e-06}, {"id": 509, "seek": 364564, "start": 3653.72, "end": 3662.12, "text": " But the trick is these extra things across here, these arrows, which is copy and crop.", "tokens": [50768, 583, 264, 4282, 307, 613, 2857, 721, 2108, 510, 11, 613, 19669, 11, 597, 307, 5055, 293, 9086, 13, 51188], "temperature": 0.0, "avg_logprob": -0.23560134569803873, "compression_ratio": 1.4320987654320987, "no_speech_prob": 4.092893050255952e-06}, {"id": 510, "seek": 364564, "start": 3662.12, "end": 3672.12, "text": " What we can do is we can take, so during the upsampling, we've got a 512 by 512 here.", "tokens": [51188, 708, 321, 393, 360, 307, 321, 393, 747, 11, 370, 1830, 264, 15497, 335, 11970, 11, 321, 600, 658, 257, 1025, 4762, 538, 1025, 4762, 510, 13, 51688], "temperature": 0.0, "avg_logprob": -0.23560134569803873, "compression_ratio": 1.4320987654320987, "no_speech_prob": 4.092893050255952e-06}, {"id": 511, "seek": 367212, "start": 3672.12, "end": 3677.72, "text": " Sorry, a 512 channel thing here. We can upsample to a 512 channel thing.", "tokens": [50364, 4919, 11, 257, 1025, 4762, 2269, 551, 510, 13, 492, 393, 15497, 335, 781, 281, 257, 1025, 4762, 2269, 551, 13, 50644], "temperature": 0.0, "avg_logprob": -0.20170318719112512, "compression_ratio": 1.570469798657718, "no_speech_prob": 1.863141187641304e-05}, {"id": 512, "seek": 367212, "start": 3680.7599999999998, "end": 3688.12, "text": " We can then put it through a conv to make it into a 256 channel thing.", "tokens": [50796, 492, 393, 550, 829, 309, 807, 257, 3754, 281, 652, 309, 666, 257, 38882, 2269, 551, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20170318719112512, "compression_ratio": 1.570469798657718, "no_speech_prob": 1.863141187641304e-05}, {"id": 513, "seek": 367212, "start": 3689.56, "end": 3697.7999999999997, "text": " And then what we can do is we can copy across the activations from here. Now they actually", "tokens": [51236, 400, 550, 437, 321, 393, 360, 307, 321, 393, 5055, 2108, 264, 2430, 763, 490, 510, 13, 823, 436, 767, 51648], "temperature": 0.0, "avg_logprob": -0.20170318719112512, "compression_ratio": 1.570469798657718, "no_speech_prob": 1.863141187641304e-05}, {"id": 514, "seek": 369780, "start": 3697.88, "end": 3706.04, "text": " do things in a slightly weird way. They had 136 pixels by 136. And over here they have 104 by 104.", "tokens": [50368, 360, 721, 294, 257, 4748, 3657, 636, 13, 814, 632, 3705, 21, 18668, 538, 3705, 21, 13, 400, 670, 510, 436, 362, 47757, 538, 47757, 13, 50776], "temperature": 0.0, "avg_logprob": -0.3695721833602242, "compression_ratio": 1.52, "no_speech_prob": 0.00022341216390486807}, {"id": 515, "seek": 369780, "start": 3708.6000000000004, "end": 3714.04, "text": " That's because of the slightly weird way they basically weren't padding things.", "tokens": [50904, 663, 311, 570, 295, 264, 4748, 3657, 636, 436, 1936, 4999, 380, 39562, 721, 13, 51176], "temperature": 0.0, "avg_logprob": -0.3695721833602242, "compression_ratio": 1.52, "no_speech_prob": 0.00022341216390486807}, {"id": 516, "seek": 369780, "start": 3714.76, "end": 3723.0800000000004, "text": " Nowadays we don't have to worry about that cropping. So we copy over these activations.", "tokens": [51212, 28908, 321, 500, 380, 362, 281, 3292, 466, 300, 4848, 3759, 13, 407, 321, 5055, 670, 613, 2430, 763, 13, 51628], "temperature": 0.0, "avg_logprob": -0.3695721833602242, "compression_ratio": 1.52, "no_speech_prob": 0.00022341216390486807}, {"id": 517, "seek": 372308, "start": 3723.72, "end": 3728.36, "text": " And we then either concatenate or add. And you can see in this case they're concatenating. See", "tokens": [50396, 400, 321, 550, 2139, 1588, 7186, 473, 420, 909, 13, 400, 291, 393, 536, 294, 341, 1389, 436, 434, 1588, 7186, 990, 13, 3008, 50628], "temperature": 0.0, "avg_logprob": -0.21481648057994276, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.00021318296785466373}, {"id": 518, "seek": 372308, "start": 3728.36, "end": 3734.12, "text": " how there's the white bit and the blue bit? So they have concatenated the two lots together.", "tokens": [50628, 577, 456, 311, 264, 2418, 857, 293, 264, 3344, 857, 30, 407, 436, 362, 1588, 7186, 770, 264, 732, 3195, 1214, 13, 50916], "temperature": 0.0, "avg_logprob": -0.21481648057994276, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.00021318296785466373}, {"id": 519, "seek": 372308, "start": 3734.12, "end": 3743.7999999999997, "text": " So actually I think what they did here is they went from a 52 by 52 by 512 to a 104 by 104 by 256.", "tokens": [50916, 407, 767, 286, 519, 437, 436, 630, 510, 307, 436, 1437, 490, 257, 18079, 538, 18079, 538, 1025, 4762, 281, 257, 47757, 538, 47757, 538, 38882, 13, 51400], "temperature": 0.0, "avg_logprob": -0.21481648057994276, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.00021318296785466373}, {"id": 520, "seek": 372308, "start": 3744.36, "end": 3748.2, "text": " And I think that's what this little blue rectangle here is. And then they had another", "tokens": [51428, 400, 286, 519, 300, 311, 437, 341, 707, 3344, 21930, 510, 307, 13, 400, 550, 436, 632, 1071, 51620], "temperature": 0.0, "avg_logprob": -0.21481648057994276, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.00021318296785466373}, {"id": 521, "seek": 374820, "start": 3749.0, "end": 3757.0, "text": " copy copied out the 104 by 104 by 256 and then put the two together to get a 104 by 104 by 512.", "tokens": [50404, 5055, 25365, 484, 264, 47757, 538, 47757, 538, 38882, 293, 550, 829, 264, 732, 1214, 281, 483, 257, 47757, 538, 47757, 538, 1025, 4762, 13, 50804], "temperature": 0.0, "avg_logprob": -0.41404507710383487, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.7231301171705127e-05}, {"id": 522, "seek": 374820, "start": 3759.0, "end": 3770.2799999999997, "text": " And so this these activations half are from the upsampling and half are from the downsampling", "tokens": [50904, 400, 370, 341, 613, 2430, 763, 1922, 366, 490, 264, 15497, 335, 11970, 293, 1922, 366, 490, 264, 760, 19988, 11970, 51468], "temperature": 0.0, "avg_logprob": -0.41404507710383487, "compression_ratio": 1.5491803278688525, "no_speech_prob": 1.7231301171705127e-05}, {"id": 523, "seek": 377028, "start": 3770.6800000000003, "end": 3779.0, "text": " from earlier in this whole process. And it might be easiest to understand why that's interesting", "tokens": [50384, 490, 3071, 294, 341, 1379, 1399, 13, 400, 309, 1062, 312, 12889, 281, 1223, 983, 300, 311, 1880, 50800], "temperature": 0.0, "avg_logprob": -0.20989376390484019, "compression_ratio": 1.4666666666666666, "no_speech_prob": 2.212557774328161e-05}, {"id": 524, "seek": 377028, "start": 3779.0, "end": 3787.96, "text": " when we get all the way back up to the top where we've got this 392 by 392 thing. The thing we're", "tokens": [50800, 562, 321, 483, 439, 264, 636, 646, 493, 281, 264, 1192, 689, 321, 600, 658, 341, 15238, 17, 538, 15238, 17, 551, 13, 440, 551, 321, 434, 51248], "temperature": 0.0, "avg_logprob": -0.20989376390484019, "compression_ratio": 1.4666666666666666, "no_speech_prob": 2.212557774328161e-05}, {"id": 525, "seek": 377028, "start": 3787.96, "end": 3796.6800000000003, "text": " copying across now is just two convolutions away from the original image. So like for super", "tokens": [51248, 27976, 2108, 586, 307, 445, 732, 3754, 15892, 1314, 490, 264, 3380, 3256, 13, 407, 411, 337, 1687, 51684], "temperature": 0.0, "avg_logprob": -0.20989376390484019, "compression_ratio": 1.4666666666666666, "no_speech_prob": 2.212557774328161e-05}, {"id": 526, "seek": 379668, "start": 3796.68, "end": 3803.64, "text": " resolution for example, we want it to look a lot like the original image. So in this case we're", "tokens": [50364, 8669, 337, 1365, 11, 321, 528, 309, 281, 574, 257, 688, 411, 264, 3380, 3256, 13, 407, 294, 341, 1389, 321, 434, 50712], "temperature": 0.0, "avg_logprob": -0.1816422108853801, "compression_ratio": 1.728110599078341, "no_speech_prob": 8.092702046269551e-05}, {"id": 527, "seek": 379668, "start": 3803.64, "end": 3807.3999999999996, "text": " actually going to have an entire copy of almost something very much like the original image", "tokens": [50712, 767, 516, 281, 362, 364, 2302, 5055, 295, 1920, 746, 588, 709, 411, 264, 3380, 3256, 50900], "temperature": 0.0, "avg_logprob": -0.1816422108853801, "compression_ratio": 1.728110599078341, "no_speech_prob": 8.092702046269551e-05}, {"id": 528, "seek": 379668, "start": 3808.2799999999997, "end": 3815.8799999999997, "text": " that we can include in these final convolutions. And so ditto here we have you know something", "tokens": [50944, 300, 321, 393, 4090, 294, 613, 2572, 3754, 15892, 13, 400, 370, 274, 34924, 510, 321, 362, 291, 458, 746, 51324], "temperature": 0.0, "avg_logprob": -0.1816422108853801, "compression_ratio": 1.728110599078341, "no_speech_prob": 8.092702046269551e-05}, {"id": 529, "seek": 379668, "start": 3815.8799999999997, "end": 3819.72, "text": " that's kind of like the somewhat downsampled version we can use here and the more downsampled", "tokens": [51324, 300, 311, 733, 295, 411, 264, 8344, 760, 19988, 15551, 3037, 321, 393, 764, 510, 293, 264, 544, 760, 19988, 15551, 51516], "temperature": 0.0, "avg_logprob": -0.1816422108853801, "compression_ratio": 1.728110599078341, "no_speech_prob": 8.092702046269551e-05}, {"id": 530, "seek": 381972, "start": 3819.72, "end": 3826.8399999999997, "text": " version we can use here. So yeah that's that's how the unit works. Do either of you guys have", "tokens": [50364, 3037, 321, 393, 764, 510, 13, 407, 1338, 300, 311, 300, 311, 577, 264, 4985, 1985, 13, 1144, 2139, 295, 291, 1074, 362, 50720], "temperature": 0.0, "avg_logprob": -0.2680657876504434, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.012820390984416008}, {"id": 531, "seek": 381972, "start": 3826.8399999999997, "end": 3832.2799999999997, "text": " anything to add like things that you found this helpful to understand or anything surprising?", "tokens": [50720, 1340, 281, 909, 411, 721, 300, 291, 1352, 341, 4961, 281, 1223, 420, 1340, 8830, 30, 50992], "temperature": 0.0, "avg_logprob": -0.2680657876504434, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.012820390984416008}, {"id": 532, "seek": 381972, "start": 3833.3199999999997, "end": 3838.04, "text": " I mean I guess it's shaping and alternating thing these days a lot of people tend to just add.", "tokens": [51044, 286, 914, 286, 2041, 309, 311, 25945, 293, 40062, 551, 613, 1708, 257, 688, 295, 561, 3928, 281, 445, 909, 13, 51280], "temperature": 0.0, "avg_logprob": -0.2680657876504434, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.012820390984416008}, {"id": 533, "seek": 381972, "start": 3838.04, "end": 3843.3199999999997, "text": " So you've got the you know the outputs from the down layer are the same shape as the inputs for", "tokens": [51280, 407, 291, 600, 658, 264, 291, 458, 264, 23930, 490, 264, 760, 4583, 366, 264, 912, 3909, 382, 264, 15743, 337, 51544], "temperature": 0.0, "avg_logprob": -0.2680657876504434, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.012820390984416008}, {"id": 534, "seek": 381972, "start": 3843.3199999999997, "end": 3848.2, "text": " the corresponding like up block and then they just kind of add the. Yeah particularly for super", "tokens": [51544, 264, 11760, 411, 493, 3461, 293, 550, 436, 445, 733, 295, 909, 264, 13, 865, 4098, 337, 1687, 51788], "temperature": 0.0, "avg_logprob": -0.2680657876504434, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.012820390984416008}, {"id": 535, "seek": 384820, "start": 3848.2, "end": 3853.24, "text": " resolution adding might make more sense than concatenating because you're like literally saying", "tokens": [50364, 8669, 5127, 1062, 652, 544, 2020, 813, 1588, 7186, 990, 570, 291, 434, 411, 3736, 1566, 50616], "temperature": 0.0, "avg_logprob": -0.19768264918651396, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00020342027710285038}, {"id": 536, "seek": 384820, "start": 3853.24, "end": 3858.2, "text": " like oh this little two by two bit is basically the right pixel but it just have to be slightly", "tokens": [50616, 411, 1954, 341, 707, 732, 538, 732, 857, 307, 1936, 264, 558, 19261, 457, 309, 445, 362, 281, 312, 4748, 50864], "temperature": 0.0, "avg_logprob": -0.19768264918651396, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00020342027710285038}, {"id": 537, "seek": 384820, "start": 3858.2, "end": 3864.9199999999996, "text": " modified on the edges. Yeah it also makes me think of like a boosting sort of thing where", "tokens": [50864, 15873, 322, 264, 8819, 13, 865, 309, 611, 1669, 385, 519, 295, 411, 257, 43117, 1333, 295, 551, 689, 51200], "temperature": 0.0, "avg_logprob": -0.19768264918651396, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00020342027710285038}, {"id": 538, "seek": 384820, "start": 3865.96, "end": 3870.2799999999997, "text": " if you think about like the fact that a lot of information from the original image is being", "tokens": [51252, 498, 291, 519, 466, 411, 264, 1186, 300, 257, 688, 295, 1589, 490, 264, 3380, 3256, 307, 885, 51468], "temperature": 0.0, "avg_logprob": -0.19768264918651396, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00020342027710285038}, {"id": 539, "seek": 384820, "start": 3870.2799999999997, "end": 3875.08, "text": " passed all the way across at that highest skip connection then the rest of the network can be", "tokens": [51468, 4678, 439, 264, 636, 2108, 412, 300, 6343, 10023, 4984, 550, 264, 1472, 295, 264, 3209, 393, 312, 51708], "temperature": 0.0, "avg_logprob": -0.19768264918651396, "compression_ratio": 1.742537313432836, "no_speech_prob": 0.00020342027710285038}, {"id": 540, "seek": 387508, "start": 3875.96, "end": 3880.7599999999998, "text": " effectively producing an update to that rather than having to recreate the whole image.", "tokens": [50408, 8659, 10501, 364, 5623, 281, 300, 2831, 813, 1419, 281, 25833, 264, 1379, 3256, 13, 50648], "temperature": 0.0, "avg_logprob": -0.27173789342244464, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.0003199235361535102}, {"id": 541, "seek": 387508, "start": 3880.7599999999998, "end": 3887.48, "text": " Or to put it another way it's like a resnet but there's a skip connections right but the skip", "tokens": [50648, 1610, 281, 829, 309, 1071, 636, 309, 311, 411, 257, 725, 7129, 457, 456, 311, 257, 10023, 9271, 558, 457, 264, 10023, 50984], "temperature": 0.0, "avg_logprob": -0.27173789342244464, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.0003199235361535102}, {"id": 542, "seek": 387508, "start": 3887.48, "end": 3893.0, "text": " connections are like jumping from the start to the end and a bit after the start to a bit before the", "tokens": [50984, 9271, 366, 411, 11233, 490, 264, 722, 281, 264, 917, 293, 257, 857, 934, 264, 722, 281, 257, 857, 949, 264, 51260], "temperature": 0.0, "avg_logprob": -0.27173789342244464, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.0003199235361535102}, {"id": 543, "seek": 387508, "start": 3893.0, "end": 3898.52, "text": " end and I guess a resnet's a bit like boosting too. Yeah.", "tokens": [51260, 917, 293, 286, 2041, 257, 725, 7129, 311, 257, 857, 411, 43117, 886, 13, 865, 13, 51536], "temperature": 0.0, "avg_logprob": -0.27173789342244464, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.0003199235361535102}, {"id": 544, "seek": 389852, "start": 3898.52, "end": 3907.64, "text": " Yeah I mean it was kind of a good thing so yeah basically I think compared to like the", "tokens": [50364, 865, 286, 914, 309, 390, 733, 295, 257, 665, 551, 370, 1338, 1936, 286, 519, 5347, 281, 411, 264, 50820], "temperature": 0.0, "avg_logprob": -0.43267996414848, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.010322023183107376}, {"id": 545, "seek": 389852, "start": 3907.64, "end": 3912.2, "text": " noising on encoder where like we saw like the results were like even worse than I guess the", "tokens": [50820, 572, 271, 278, 322, 2058, 19866, 689, 411, 321, 1866, 411, 264, 3542, 645, 411, 754, 5324, 813, 286, 2041, 264, 51048], "temperature": 0.0, "avg_logprob": -0.43267996414848, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.010322023183107376}, {"id": 546, "seek": 389852, "start": 3912.2, "end": 3918.28, "text": " original image here I guess the worst it can be is basically the original image so you know I guess", "tokens": [51048, 3380, 3256, 510, 286, 2041, 264, 5855, 309, 393, 312, 307, 1936, 264, 3380, 3256, 370, 291, 458, 286, 2041, 51352], "temperature": 0.0, "avg_logprob": -0.43267996414848, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.010322023183107376}, {"id": 547, "seek": 389852, "start": 3918.28, "end": 3926.36, "text": " it's just like a similar sort of kind of intuition behind the the the resnet and how that works.", "tokens": [51352, 309, 311, 445, 411, 257, 2531, 1333, 295, 733, 295, 24002, 2261, 264, 264, 264, 725, 7129, 293, 577, 300, 1985, 13, 51756], "temperature": 0.0, "avg_logprob": -0.43267996414848, "compression_ratio": 1.8028846153846154, "no_speech_prob": 0.010322023183107376}, {"id": 548, "seek": 392636, "start": 3926.36, "end": 3933.08, "text": " So yeah I mean it could be worse if these comms at the end are incapable of undoing what these", "tokens": [50364, 407, 1338, 286, 914, 309, 727, 312, 5324, 498, 613, 800, 82, 412, 264, 917, 366, 44174, 295, 23779, 278, 437, 613, 50700], "temperature": 0.0, "avg_logprob": -0.17490903190944507, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.00016859946481417865}, {"id": 549, "seek": 392636, "start": 3933.08, "end": 3939.4, "text": " comms did which is like one argument for maybe why there should also be a connection from here", "tokens": [50700, 800, 82, 630, 597, 307, 411, 472, 6770, 337, 1310, 983, 456, 820, 611, 312, 257, 4984, 490, 510, 51016], "temperature": 0.0, "avg_logprob": -0.17490903190944507, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.00016859946481417865}, {"id": 550, "seek": 392636, "start": 3939.4, "end": 3944.1200000000003, "text": " over to here and maybe a few more comms after that which is something I'm kind of interested in", "tokens": [51016, 670, 281, 510, 293, 1310, 257, 1326, 544, 800, 82, 934, 300, 597, 307, 746, 286, 478, 733, 295, 3102, 294, 51252], "temperature": 0.0, "avg_logprob": -0.17490903190944507, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.00016859946481417865}, {"id": 551, "seek": 392636, "start": 3944.1200000000003, "end": 3951.6400000000003, "text": " and not enough people do in my opinion. Another thing to consider is that they've only got two", "tokens": [51252, 293, 406, 1547, 561, 360, 294, 452, 4800, 13, 3996, 551, 281, 1949, 307, 300, 436, 600, 787, 658, 732, 51628], "temperature": 0.0, "avg_logprob": -0.17490903190944507, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.00016859946481417865}, {"id": 552, "seek": 395164, "start": 3951.64, "end": 3959.7999999999997, "text": " comms down here but at this point you have the benefit of only being a 28 by 28 you know why not", "tokens": [50364, 800, 82, 760, 510, 457, 412, 341, 935, 291, 362, 264, 5121, 295, 787, 885, 257, 7562, 538, 7562, 291, 458, 983, 406, 50772], "temperature": 0.0, "avg_logprob": -0.21176586151123047, "compression_ratio": 1.558659217877095, "no_speech_prob": 3.591075073927641e-05}, {"id": 553, "seek": 395164, "start": 3959.7999999999997, "end": 3967.72, "text": " do more computation at this point you know so there's a couple of things that sometimes people", "tokens": [50772, 360, 544, 24903, 412, 341, 935, 291, 458, 370, 456, 311, 257, 1916, 295, 721, 300, 2171, 561, 51168], "temperature": 0.0, "avg_logprob": -0.21176586151123047, "compression_ratio": 1.558659217877095, "no_speech_prob": 3.591075073927641e-05}, {"id": 554, "seek": 395164, "start": 3967.72, "end": 3978.3599999999997, "text": " consider but maybe not enough. So let me try to remember what I did. So in my unit here", "tokens": [51168, 1949, 457, 1310, 406, 1547, 13, 407, 718, 385, 853, 281, 1604, 437, 286, 630, 13, 407, 294, 452, 4985, 510, 51700], "temperature": 0.0, "avg_logprob": -0.21176586151123047, "compression_ratio": 1.558659217877095, "no_speech_prob": 3.591075073927641e-05}, {"id": 555, "seek": 397836, "start": 3978.44, "end": 3991.4, "text": " so we've got the downsampling path which is a list of res blocks. Now a module list is just", "tokens": [50368, 370, 321, 600, 658, 264, 760, 19988, 11970, 3100, 597, 307, 257, 1329, 295, 725, 8474, 13, 823, 257, 10088, 1329, 307, 445, 51016], "temperature": 0.0, "avg_logprob": -0.2504020796881782, "compression_ratio": 1.574585635359116, "no_speech_prob": 4.8604356379655655e-06}, {"id": 556, "seek": 397836, "start": 3991.4, "end": 3997.32, "text": " like a sequential except it doesn't actually do anything so then in the forward we have to go", "tokens": [51016, 411, 257, 42881, 3993, 309, 1177, 380, 767, 360, 1340, 370, 550, 294, 264, 2128, 321, 362, 281, 352, 51312], "temperature": 0.0, "avg_logprob": -0.2504020796881782, "compression_ratio": 1.574585635359116, "no_speech_prob": 4.8604356379655655e-06}, {"id": 557, "seek": 397836, "start": 3997.32, "end": 4006.28, "text": " through the down path and x equals lx each time so it's basically yeah it's sequential that doesn't", "tokens": [51312, 807, 264, 760, 3100, 293, 2031, 6915, 287, 87, 1184, 565, 370, 309, 311, 1936, 1338, 309, 311, 42881, 300, 1177, 380, 51760], "temperature": 0.0, "avg_logprob": -0.2504020796881782, "compression_ratio": 1.574585635359116, "no_speech_prob": 4.8604356379655655e-06}, {"id": 558, "seek": 400628, "start": 4006.28, "end": 4012.0400000000004, "text": " actually do anything and so the up path is exactly the same as we saw before it's a bunch of up blocks", "tokens": [50364, 767, 360, 1340, 293, 370, 264, 493, 3100, 307, 2293, 264, 912, 382, 321, 1866, 949, 309, 311, 257, 3840, 295, 493, 8474, 50652], "temperature": 0.0, "avg_logprob": -0.20455409155951607, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.095307834475534e-05}, {"id": 559, "seek": 400628, "start": 4014.28, "end": 4021.32, "text": " and then like we saw before the final one's going to have to go to three channel but now for our", "tokens": [50764, 293, 550, 411, 321, 1866, 949, 264, 2572, 472, 311, 516, 281, 362, 281, 352, 281, 1045, 2269, 457, 586, 337, 527, 51116], "temperature": 0.0, "avg_logprob": -0.20455409155951607, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.095307834475534e-05}, {"id": 560, "seek": 400628, "start": 4021.32, "end": 4026.44, "text": " forward what we're going to do is we're going to keep track of", "tokens": [51116, 2128, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 1066, 2837, 295, 51372], "temperature": 0.0, "avg_logprob": -0.20455409155951607, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.095307834475534e-05}, {"id": 561, "seek": 400628, "start": 4030.6800000000003, "end": 4034.92, "text": " since we're going to be copying this over here and copying this over here we have to save it", "tokens": [51584, 1670, 321, 434, 516, 281, 312, 27976, 341, 670, 510, 293, 27976, 341, 670, 510, 321, 362, 281, 3155, 309, 51796], "temperature": 0.0, "avg_logprob": -0.20455409155951607, "compression_ratio": 1.868421052631579, "no_speech_prob": 1.095307834475534e-05}, {"id": 562, "seek": 403492, "start": 4035.7200000000003, "end": 4045.64, "text": " during the downsampling path so we're going to save it in a something called layers. So I actually", "tokens": [50404, 1830, 264, 760, 19988, 11970, 3100, 370, 321, 434, 516, 281, 3155, 309, 294, 257, 746, 1219, 7914, 13, 407, 286, 767, 50900], "temperature": 0.0, "avg_logprob": -0.2527145743370056, "compression_ratio": 1.6538461538461537, "no_speech_prob": 5.626255301649508e-07}, {"id": 563, "seek": 403492, "start": 4045.64, "end": 4050.04, "text": " decided to do the little trick I mentioned which is to save the very first input.", "tokens": [50900, 3047, 281, 360, 264, 707, 4282, 286, 2835, 597, 307, 281, 3155, 264, 588, 700, 4846, 13, 51120], "temperature": 0.0, "avg_logprob": -0.2527145743370056, "compression_ratio": 1.6538461538461537, "no_speech_prob": 5.626255301649508e-07}, {"id": 564, "seek": 403492, "start": 4052.12, "end": 4056.84, "text": " So I save the very first input I then put it through the very first res block", "tokens": [51224, 407, 286, 3155, 264, 588, 700, 4846, 286, 550, 829, 309, 807, 264, 588, 700, 725, 3461, 51460], "temperature": 0.0, "avg_logprob": -0.2527145743370056, "compression_ratio": 1.6538461538461537, "no_speech_prob": 5.626255301649508e-07}, {"id": 565, "seek": 405684, "start": 4057.2400000000002, "end": 4061.4, "text": " and then we go through each in the downward path", "tokens": [50384, 293, 550, 321, 352, 807, 1184, 294, 264, 24805, 3100, 50592], "temperature": 0.0, "avg_logprob": -0.3472768783569336, "compression_ratio": 1.9441340782122905, "no_speech_prob": 1.4970721167628653e-05}, {"id": 566, "seek": 405684, "start": 4065.0, "end": 4070.44, "text": " there's actually no need at all for there to be an il here it doesn't have to be enumerated because", "tokens": [50772, 456, 311, 767, 572, 643, 412, 439, 337, 456, 281, 312, 364, 1930, 510, 309, 1177, 380, 362, 281, 312, 465, 15583, 770, 570, 51044], "temperature": 0.0, "avg_logprob": -0.3472768783569336, "compression_ratio": 1.9441340782122905, "no_speech_prob": 1.4970721167628653e-05}, {"id": 567, "seek": 405684, "start": 4070.44, "end": 4077.1600000000003, "text": " we don't use i. Okay so we go through the downward path so for this l for layer so for each layer in", "tokens": [51044, 321, 500, 380, 764, 741, 13, 1033, 370, 321, 352, 807, 264, 24805, 3100, 370, 337, 341, 287, 337, 4583, 370, 337, 1184, 4583, 294, 51380], "temperature": 0.0, "avg_logprob": -0.3472768783569336, "compression_ratio": 1.9441340782122905, "no_speech_prob": 1.4970721167628653e-05}, {"id": 568, "seek": 405684, "start": 4077.1600000000003, "end": 4083.8, "text": " the downward path append the activations so that again as we go through each one we're going to be", "tokens": [51380, 264, 24805, 3100, 34116, 264, 2430, 763, 370, 300, 797, 382, 321, 352, 807, 1184, 472, 321, 434, 516, 281, 312, 51712], "temperature": 0.0, "avg_logprob": -0.3472768783569336, "compression_ratio": 1.9441340782122905, "no_speech_prob": 1.4970721167628653e-05}, {"id": 569, "seek": 408380, "start": 4084.1200000000003, "end": 4093.32, "text": " able to copy them over by saving them for later and then call the layer. Okay so how many layers", "tokens": [50380, 1075, 281, 5055, 552, 670, 538, 6816, 552, 337, 1780, 293, 550, 818, 264, 4583, 13, 1033, 370, 577, 867, 7914, 50840], "temperature": 0.0, "avg_logprob": -0.22536398967107138, "compression_ratio": 1.7834101382488479, "no_speech_prob": 8.750135020818561e-05}, {"id": 570, "seek": 408380, "start": 4093.32, "end": 4099.08, "text": " have we got there's n layers that we've stored away so now we're going to go through the upsampling", "tokens": [50840, 362, 321, 658, 456, 311, 297, 7914, 300, 321, 600, 12187, 1314, 370, 586, 321, 434, 516, 281, 352, 807, 264, 493, 19988, 11970, 51128], "temperature": 0.0, "avg_logprob": -0.22536398967107138, "compression_ratio": 1.7834101382488479, "no_speech_prob": 8.750135020818561e-05}, {"id": 571, "seek": 408380, "start": 4099.08, "end": 4104.04, "text": " path and again we're going to call call each one but before we do we're going to actually do the", "tokens": [51128, 3100, 293, 797, 321, 434, 516, 281, 818, 818, 1184, 472, 457, 949, 321, 360, 321, 434, 516, 281, 767, 360, 264, 51376], "temperature": 0.0, "avg_logprob": -0.22536398967107138, "compression_ratio": 1.7834101382488479, "no_speech_prob": 8.750135020818561e-05}, {"id": 572, "seek": 408380, "start": 4104.04, "end": 4109.72, "text": " thing that Jono mentioned which is rather than concatenating unless we're back at unless this", "tokens": [51376, 551, 300, 7745, 78, 2835, 597, 307, 2831, 813, 1588, 7186, 990, 5969, 321, 434, 646, 412, 5969, 341, 51660], "temperature": 0.0, "avg_logprob": -0.22536398967107138, "compression_ratio": 1.7834101382488479, "no_speech_prob": 8.750135020818561e-05}, {"id": 573, "seek": 410972, "start": 4109.72, "end": 4114.2, "text": " is the very first layer because the very first upsampling layer there's nothing to copy.", "tokens": [50364, 307, 264, 588, 700, 4583, 570, 264, 588, 700, 15497, 335, 11970, 4583, 456, 311, 1825, 281, 5055, 13, 50588], "temperature": 0.0, "avg_logprob": -0.23944521662014634, "compression_ratio": 1.8943661971830985, "no_speech_prob": 6.8542954068107065e-06}, {"id": 574, "seek": 410972, "start": 4115.08, "end": 4122.68, "text": " Right so unless it's the very first upsampling layer let's just add the saved activations", "tokens": [50632, 1779, 370, 5969, 309, 311, 264, 588, 700, 15497, 335, 11970, 4583, 718, 311, 445, 909, 264, 6624, 2430, 763, 51012], "temperature": 0.0, "avg_logprob": -0.23944521662014634, "compression_ratio": 1.8943661971830985, "no_speech_prob": 6.8542954068107065e-06}, {"id": 575, "seek": 410972, "start": 4123.4800000000005, "end": 4131.8, "text": " and then call the layer and then right at the very end we'll add back the very first layer", "tokens": [51052, 293, 550, 818, 264, 4583, 293, 550, 558, 412, 264, 588, 917, 321, 603, 909, 646, 264, 588, 700, 4583, 51468], "temperature": 0.0, "avg_logprob": -0.23944521662014634, "compression_ratio": 1.8943661971830985, "no_speech_prob": 6.8542954068107065e-06}, {"id": 576, "seek": 413180, "start": 4132.76, "end": 4137.72, "text": " and then pass it through the very fine last res block.", "tokens": [50412, 293, 550, 1320, 309, 807, 264, 588, 2489, 1036, 725, 3461, 13, 50660], "temperature": 0.0, "avg_logprob": -0.3225962093898228, "compression_ratio": 1.385135135135135, "no_speech_prob": 4.1334362322231755e-05}, {"id": 577, "seek": 413180, "start": 4144.28, "end": 4149.64, "text": " All right maybe that last one should be concatenated I'm not sure. Anywho this is what I did.", "tokens": [50988, 1057, 558, 1310, 300, 1036, 472, 820, 312, 1588, 7186, 770, 286, 478, 406, 988, 13, 2639, 13506, 341, 307, 437, 286, 630, 13, 51256], "temperature": 0.0, "avg_logprob": -0.3225962093898228, "compression_ratio": 1.385135135135135, "no_speech_prob": 4.1334362322231755e-05}, {"id": 578, "seek": 413180, "start": 4153.0, "end": 4157.64, "text": " Now the next thing that I wondered about was like how to", "tokens": [51424, 823, 264, 958, 551, 300, 286, 17055, 466, 390, 411, 577, 281, 51656], "temperature": 0.0, "avg_logprob": -0.3225962093898228, "compression_ratio": 1.385135135135135, "no_speech_prob": 4.1334362322231755e-05}, {"id": 579, "seek": 415764, "start": 4158.52, "end": 4163.96, "text": " initialize this and basically what I wanted to do is I wanted to initialize this so that when it's", "tokens": [50408, 5883, 1125, 341, 293, 1936, 437, 286, 1415, 281, 360, 307, 286, 1415, 281, 5883, 1125, 341, 370, 300, 562, 309, 311, 50680], "temperature": 0.0, "avg_logprob": -0.2950534596162684, "compression_ratio": 1.943298969072165, "no_speech_prob": 1.4063625712879002e-05}, {"id": 580, "seek": 415764, "start": 4163.96, "end": 4170.84, "text": " when it's untrained it would the output of the model would be identical to the input", "tokens": [50680, 562, 309, 311, 1701, 31774, 309, 576, 264, 5598, 295, 264, 2316, 576, 312, 14800, 281, 264, 4846, 51024], "temperature": 0.0, "avg_logprob": -0.2950534596162684, "compression_ratio": 1.943298969072165, "no_speech_prob": 1.4063625712879002e-05}, {"id": 581, "seek": 415764, "start": 4171.400000000001, "end": 4175.64, "text": " because like a reasonable starting point for like what does this look like so yeah what does this", "tokens": [51052, 570, 411, 257, 10585, 2891, 935, 337, 411, 437, 775, 341, 574, 411, 370, 1338, 437, 775, 341, 51264], "temperature": 0.0, "avg_logprob": -0.2950534596162684, "compression_ratio": 1.943298969072165, "no_speech_prob": 1.4063625712879002e-05}, {"id": 582, "seek": 415764, "start": 4175.64, "end": 4181.96, "text": " look like following super resolution would be this you know that's a reasonable starting point.", "tokens": [51264, 574, 411, 3480, 1687, 8669, 576, 312, 341, 291, 458, 300, 311, 257, 10585, 2891, 935, 13, 51580], "temperature": 0.0, "avg_logprob": -0.2950534596162684, "compression_ratio": 1.943298969072165, "no_speech_prob": 1.4063625712879002e-05}, {"id": 583, "seek": 418196, "start": 4182.2, "end": 4190.44, "text": " So I just created this little zero weights thing which zeros out the weights and biases of a layer", "tokens": [50376, 407, 286, 445, 2942, 341, 707, 4018, 17443, 551, 597, 35193, 484, 264, 17443, 293, 32152, 295, 257, 4583, 50788], "temperature": 0.0, "avg_logprob": -0.2638488497052874, "compression_ratio": 1.4776119402985075, "no_speech_prob": 6.854248113086214e-06}, {"id": 584, "seek": 418196, "start": 4191.16, "end": 4200.04, "text": " right so I created the model and then I said okay let's look at the very end of the upsampling path", "tokens": [50824, 558, 370, 286, 2942, 264, 2316, 293, 550, 286, 848, 1392, 718, 311, 574, 412, 264, 588, 917, 295, 264, 15497, 335, 11970, 3100, 51268], "temperature": 0.0, "avg_logprob": -0.2638488497052874, "compression_ratio": 1.4776119402985075, "no_speech_prob": 6.854248113086214e-06}, {"id": 585, "seek": 420004, "start": 4200.6, "end": 4210.6, "text": " and we'll call that the last resnet and so let's zero out the very last convolutions", "tokens": [50392, 293, 321, 603, 818, 300, 264, 1036, 725, 7129, 293, 370, 718, 311, 4018, 484, 264, 588, 1036, 3754, 15892, 50892], "temperature": 0.0, "avg_logprob": -0.40163575048032013, "compression_ratio": 1.565217391304348, "no_speech_prob": 6.438868240365991e-06}, {"id": 586, "seek": 420004, "start": 4213.4, "end": 4221.8, "text": " and also the id connection and so that means that whatever it does for all this at the very end", "tokens": [51032, 293, 611, 264, 4496, 4984, 293, 370, 300, 1355, 300, 2035, 309, 775, 337, 439, 341, 412, 264, 588, 917, 51452], "temperature": 0.0, "avg_logprob": -0.40163575048032013, "compression_ratio": 1.565217391304348, "no_speech_prob": 6.438868240365991e-06}, {"id": 587, "seek": 422180, "start": 4222.04, "end": 4225.24, "text": " at the very end it's going to have", "tokens": [50376, 412, 264, 588, 917, 309, 311, 516, 281, 362, 50536], "temperature": 0.0, "avg_logprob": -0.22667874081034056, "compression_ratio": 1.7125748502994012, "no_speech_prob": 1.2878913366876077e-06}, {"id": 588, "seek": 422180, "start": 4228.2, "end": 4233.4800000000005, "text": " nothing in there this will be zero so that means that this will be equal to layer zero", "tokens": [50684, 1825, 294, 456, 341, 486, 312, 4018, 370, 300, 1355, 300, 341, 486, 312, 2681, 281, 4583, 4018, 50948], "temperature": 0.0, "avg_logprob": -0.22667874081034056, "compression_ratio": 1.7125748502994012, "no_speech_prob": 1.2878913366876077e-06}, {"id": 589, "seek": 422180, "start": 4235.72, "end": 4238.92, "text": " and then that means we also want to make sure that this doesn't change anything", "tokens": [51060, 293, 550, 300, 1355, 321, 611, 528, 281, 652, 988, 300, 341, 1177, 380, 1319, 1340, 51220], "temperature": 0.0, "avg_logprob": -0.22667874081034056, "compression_ratio": 1.7125748502994012, "no_speech_prob": 1.2878913366876077e-06}, {"id": 590, "seek": 422180, "start": 4240.28, "end": 4247.8, "text": " so then we can just zero out the weights there that's probably not quite right is it", "tokens": [51288, 370, 550, 321, 393, 445, 4018, 484, 264, 17443, 456, 300, 311, 1391, 406, 1596, 558, 307, 309, 51664], "temperature": 0.0, "avg_logprob": -0.22667874081034056, "compression_ratio": 1.7125748502994012, "no_speech_prob": 1.2878913366876077e-06}, {"id": 591, "seek": 424780, "start": 4248.68, "end": 4255.08, "text": " I guess I should have actually set those to like an identity matrix maybe I'll try to do that later", "tokens": [50408, 286, 2041, 286, 820, 362, 767, 992, 729, 281, 411, 364, 6575, 8141, 1310, 286, 603, 853, 281, 360, 300, 1780, 50728], "temperature": 0.0, "avg_logprob": -0.20034848863833418, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.0004655068914871663}, {"id": 592, "seek": 424780, "start": 4255.8, "end": 4257.88, "text": " but at least it's something that would be very easy for it to", "tokens": [50764, 457, 412, 1935, 309, 311, 746, 300, 576, 312, 588, 1858, 337, 309, 281, 50868], "temperature": 0.0, "avg_logprob": -0.20034848863833418, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.0004655068914871663}, {"id": 593, "seek": 424780, "start": 4259.96, "end": 4265.16, "text": " I have a question Jeremy yeah this this zero weights I see a lot of people do a thing where", "tokens": [50972, 286, 362, 257, 1168, 17809, 1338, 341, 341, 4018, 17443, 286, 536, 257, 688, 295, 561, 360, 257, 551, 689, 51232], "temperature": 0.0, "avg_logprob": -0.20034848863833418, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.0004655068914871663}, {"id": 594, "seek": 424780, "start": 4265.16, "end": 4271.0, "text": " they instead like multiply by one e minus three or one e minus four to make the weights really", "tokens": [51232, 436, 2602, 411, 12972, 538, 472, 308, 3175, 1045, 420, 472, 308, 3175, 1451, 281, 652, 264, 17443, 534, 51524], "temperature": 0.0, "avg_logprob": -0.20034848863833418, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.0004655068914871663}, {"id": 595, "seek": 424780, "start": 4271.0, "end": 4277.320000000001, "text": " small but not completely zero and I don't have a good intuition whether it's like you know in some", "tokens": [51524, 1359, 457, 406, 2584, 4018, 293, 286, 500, 380, 362, 257, 665, 24002, 1968, 309, 311, 411, 291, 458, 294, 512, 51840], "temperature": 0.0, "avg_logprob": -0.20034848863833418, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.0004655068914871663}, {"id": 596, "seek": 427732, "start": 4277.32, "end": 4282.36, "text": " sense having everything set to zero fires off some warnings that maybe this is going to be like", "tokens": [50364, 2020, 1419, 1203, 992, 281, 4018, 15044, 766, 512, 30009, 300, 1310, 341, 307, 516, 281, 312, 411, 50616], "temperature": 0.0, "avg_logprob": -0.1840674417060718, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.00044417032040655613}, {"id": 597, "seek": 427732, "start": 4282.36, "end": 4286.92, "text": " perfectly balanced on some saddle point or it's not going to have any signal to work with yeah it's", "tokens": [50616, 6239, 13902, 322, 512, 30459, 935, 420, 309, 311, 406, 516, 281, 362, 604, 6358, 281, 589, 365, 1338, 309, 311, 50844], "temperature": 0.0, "avg_logprob": -0.1840674417060718, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.00044417032040655613}, {"id": 598, "seek": 427732, "start": 4286.92, "end": 4291.5599999999995, "text": " very small but not quite zero random weights might be better yeah do you have an intuition for that", "tokens": [50844, 588, 1359, 457, 406, 1596, 4018, 4974, 17443, 1062, 312, 1101, 1338, 360, 291, 362, 364, 24002, 337, 300, 51076], "temperature": 0.0, "avg_logprob": -0.1840674417060718, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.00044417032040655613}, {"id": 599, "seek": 427732, "start": 4291.5599999999995, "end": 4298.679999999999, "text": " I think so or not too much intuition but more empirical like or both I don't I don't think it's", "tokens": [51076, 286, 519, 370, 420, 406, 886, 709, 24002, 457, 544, 31886, 411, 420, 1293, 286, 500, 380, 286, 500, 380, 519, 309, 311, 51432], "temperature": 0.0, "avg_logprob": -0.1840674417060718, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.00044417032040655613}, {"id": 600, "seek": 427732, "start": 4298.679999999999, "end": 4303.719999999999, "text": " an issue and I think it comes from like a lot of people's PhD supervisors and stuff you know come", "tokens": [51432, 364, 2734, 293, 286, 519, 309, 1487, 490, 411, 257, 688, 295, 561, 311, 14476, 42218, 293, 1507, 291, 458, 808, 51684], "temperature": 0.0, "avg_logprob": -0.1840674417060718, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.00044417032040655613}, {"id": 601, "seek": 430372, "start": 4303.72, "end": 4308.12, "text": " from back in an era when they were doing like linear regression with one layer or whatever and", "tokens": [50364, 490, 646, 294, 364, 4249, 562, 436, 645, 884, 411, 8213, 24590, 365, 472, 4583, 420, 2035, 293, 50584], "temperature": 0.0, "avg_logprob": -0.19698021628639914, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00013341382145881653}, {"id": 602, "seek": 430372, "start": 4308.76, "end": 4314.4400000000005, "text": " in those cases yeah if all the weights are the same then no learning can happen because every", "tokens": [50616, 294, 729, 3331, 1338, 498, 439, 264, 17443, 366, 264, 912, 550, 572, 2539, 393, 1051, 570, 633, 50900], "temperature": 0.0, "avg_logprob": -0.19698021628639914, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00013341382145881653}, {"id": 603, "seek": 430372, "start": 4314.4400000000005, "end": 4319.56, "text": " weight update is identical but in this case all the previous weights are different so there's", "tokens": [50900, 3364, 5623, 307, 14800, 457, 294, 341, 1389, 439, 264, 3894, 17443, 366, 819, 370, 456, 311, 51156], "temperature": 0.0, "avg_logprob": -0.19698021628639914, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00013341382145881653}, {"id": 604, "seek": 430372, "start": 4321.0, "end": 4324.2, "text": " they all have different gradients and there's definitely yeah nothing to worry about", "tokens": [51228, 436, 439, 362, 819, 2771, 2448, 293, 456, 311, 2138, 1338, 1825, 281, 3292, 466, 51388], "temperature": 0.0, "avg_logprob": -0.19698021628639914, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00013341382145881653}, {"id": 605, "seek": 430372, "start": 4326.68, "end": 4331.4800000000005, "text": " I mean multiplying it by a small number would work too like it's not a problem but um", "tokens": [51512, 286, 914, 30955, 309, 538, 257, 1359, 1230, 576, 589, 886, 411, 309, 311, 406, 257, 1154, 457, 1105, 51752], "temperature": 0.0, "avg_logprob": -0.19698021628639914, "compression_ratio": 1.749034749034749, "no_speech_prob": 0.00013341382145881653}, {"id": 606, "seek": 433148, "start": 4332.2, "end": 4340.28, "text": " yeah setting it to zeros I honestly I have to stop myself from I mean not that's a problem but I just", "tokens": [50400, 1338, 3287, 309, 281, 35193, 286, 6095, 286, 362, 281, 1590, 2059, 490, 286, 914, 406, 300, 311, 257, 1154, 457, 286, 445, 50804], "temperature": 0.0, "avg_logprob": -0.23853130638599396, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.024111720151268e-05}, {"id": 607, "seek": 433148, "start": 4341.879999999999, "end": 4345.719999999999, "text": " I always have this natural inclination to not want to set them to zeros because", "tokens": [50884, 286, 1009, 362, 341, 3303, 37070, 2486, 281, 406, 528, 281, 992, 552, 281, 35193, 570, 51076], "temperature": 0.0, "avg_logprob": -0.23853130638599396, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.024111720151268e-05}, {"id": 608, "seek": 433148, "start": 4345.719999999999, "end": 4351.4, "text": " of years of being told not to but there's no reason that should be a problem", "tokens": [51076, 295, 924, 295, 885, 1907, 406, 281, 457, 456, 311, 572, 1778, 300, 820, 312, 257, 1154, 51360], "temperature": 0.0, "avg_logprob": -0.23853130638599396, "compression_ratio": 1.5925925925925926, "no_speech_prob": 3.024111720151268e-05}, {"id": 609, "seek": 435140, "start": 4352.12, "end": 4361.879999999999, "text": " um all right so I just would I was just like again like that unit code is very concise and it's very", "tokens": [50400, 1105, 439, 558, 370, 286, 445, 576, 286, 390, 445, 411, 797, 411, 300, 4985, 3089, 307, 588, 44882, 293, 309, 311, 588, 50888], "temperature": 0.0, "avg_logprob": -0.25947268803914386, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0001177404192276299}, {"id": 610, "seek": 435140, "start": 4362.759999999999, "end": 4369.879999999999, "text": " very interesting to see if the basic idea is you know very simple and oh yeah to see that I guess", "tokens": [50932, 588, 1880, 281, 536, 498, 264, 3875, 1558, 307, 291, 458, 588, 2199, 293, 1954, 1338, 281, 536, 300, 286, 2041, 51288], "temperature": 0.0, "avg_logprob": -0.25947268803914386, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0001177404192276299}, {"id": 611, "seek": 435140, "start": 4370.599999999999, "end": 4375.16, "text": " yeah yeah it's helpful I think to just get it into a little bit of code isn't it", "tokens": [51324, 1338, 1338, 309, 311, 4961, 286, 519, 281, 445, 483, 309, 666, 257, 707, 857, 295, 3089, 1943, 380, 309, 51552], "temperature": 0.0, "avg_logprob": -0.25947268803914386, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0001177404192276299}, {"id": 612, "seek": 437516, "start": 4375.16, "end": 4386.599999999999, "text": " yeah thanks um that's very simple code too um okay so we do our lrfind and then we train", "tokens": [50364, 1338, 3231, 1105, 300, 311, 588, 2199, 3089, 886, 1105, 1392, 370, 321, 360, 527, 287, 81, 35072, 293, 550, 321, 3847, 50936], "temperature": 0.0, "avg_logprob": -0.27418806114975286, "compression_ratio": 1.4031007751937985, "no_speech_prob": 3.089273832301842e-06}, {"id": 613, "seek": 437516, "start": 4388.28, "end": 4396.76, "text": " and you can see previously our loss even after five epochs was 207 and in this case our loss", "tokens": [51020, 293, 291, 393, 536, 8046, 527, 4470, 754, 934, 1732, 30992, 28346, 390, 945, 22, 293, 294, 341, 1389, 527, 4470, 51444], "temperature": 0.0, "avg_logprob": -0.27418806114975286, "compression_ratio": 1.4031007751937985, "no_speech_prob": 3.089273832301842e-06}, {"id": 614, "seek": 439676, "start": 4396.76, "end": 4410.12, "text": " after one epoch is 086 so it's obviously much easier and we end up at 073 okay so we can take", "tokens": [50364, 934, 472, 30992, 339, 307, 1958, 22193, 370, 309, 311, 2745, 709, 3571, 293, 321, 917, 493, 412, 1958, 33396, 1392, 370, 321, 393, 747, 51032], "temperature": 0.0, "avg_logprob": -0.19889881241489465, "compression_ratio": 1.5689655172413792, "no_speech_prob": 1.6693824363755994e-05}, {"id": 615, "seek": 439676, "start": 4410.12, "end": 4418.2, "text": " a look here's our inputs and there's our outputs so it's actually better rather than dramatically", "tokens": [51032, 257, 574, 510, 311, 527, 15743, 293, 456, 311, 527, 23930, 370, 309, 311, 767, 1101, 2831, 813, 17548, 51436], "temperature": 0.0, "avg_logprob": -0.19889881241489465, "compression_ratio": 1.5689655172413792, "no_speech_prob": 1.6693824363755994e-05}, {"id": 616, "seek": 439676, "start": 4418.2, "end": 4425.72, "text": " worse now so that's good um yeah some of it's actually not bad at all I would say", "tokens": [51436, 5324, 586, 370, 300, 311, 665, 1105, 1338, 512, 295, 309, 311, 767, 406, 1578, 412, 439, 286, 576, 584, 51812], "temperature": 0.0, "avg_logprob": -0.19889881241489465, "compression_ratio": 1.5689655172413792, "no_speech_prob": 1.6693824363755994e-05}, {"id": 617, "seek": 442676, "start": 4426.84, "end": 4436.12, "text": " um this car definitely looks like I think it's like a little over smoothed you know I think you", "tokens": [50368, 1105, 341, 1032, 2138, 1542, 411, 286, 519, 309, 311, 411, 257, 707, 670, 5508, 292, 291, 458, 286, 519, 291, 50832], "temperature": 0.0, "avg_logprob": -0.19486951136934585, "compression_ratio": 1.6453488372093024, "no_speech_prob": 8.397953934036195e-06}, {"id": 618, "seek": 442676, "start": 4436.12, "end": 4442.04, "text": " could say so if we look at the other guy's eyes kids eyes still aren't great like in the original", "tokens": [50832, 727, 584, 370, 498, 321, 574, 412, 264, 661, 2146, 311, 2575, 2301, 2575, 920, 3212, 380, 869, 411, 294, 264, 3380, 51128], "temperature": 0.0, "avg_logprob": -0.19486951136934585, "compression_ratio": 1.6453488372093024, "no_speech_prob": 8.397953934036195e-06}, {"id": 619, "seek": 442676, "start": 4442.04, "end": 4449.56, "text": " he's actually got proper pupils um so yeah it's definitely not recreated the original but", "tokens": [51128, 415, 311, 767, 658, 2296, 38404, 1105, 370, 1338, 309, 311, 2138, 406, 850, 26559, 264, 3380, 457, 51504], "temperature": 0.0, "avg_logprob": -0.19486951136934585, "compression_ratio": 1.6453488372093024, "no_speech_prob": 8.397953934036195e-06}, {"id": 620, "seek": 444956, "start": 4449.88, "end": 4460.68, "text": " you know given limited compute and limited data like the basic idea is not bad um I do worry that", "tokens": [50380, 291, 458, 2212, 5567, 14722, 293, 5567, 1412, 411, 264, 3875, 1558, 307, 406, 1578, 1105, 286, 360, 3292, 300, 50920], "temperature": 0.0, "avg_logprob": -0.2358449648504388, "compression_ratio": 1.727810650887574, "no_speech_prob": 1.5446181350853294e-05}, {"id": 621, "seek": 444956, "start": 4460.68, "end": 4466.76, "text": " the poor koala like it it didn't have eyes here but like it ought to have known there should be", "tokens": [50920, 264, 4716, 8384, 5159, 411, 309, 309, 994, 380, 362, 2575, 510, 457, 411, 309, 13416, 281, 362, 2570, 456, 820, 312, 51224], "temperature": 0.0, "avg_logprob": -0.2358449648504388, "compression_ratio": 1.727810650887574, "no_speech_prob": 1.5446181350853294e-05}, {"id": 622, "seek": 444956, "start": 4466.76, "end": 4471.72, "text": " eyes in a sense and it didn't create any and maybe it should have done a better job on the eyes so", "tokens": [51224, 2575, 294, 257, 2020, 293, 309, 994, 380, 1884, 604, 293, 1310, 309, 820, 362, 1096, 257, 1101, 1691, 322, 264, 2575, 370, 51472], "temperature": 0.0, "avg_logprob": -0.2358449648504388, "compression_ratio": 1.727810650887574, "no_speech_prob": 1.5446181350853294e-05}, {"id": 623, "seek": 447172, "start": 4472.280000000001, "end": 4479.56, "text": " um my feeling is um and this is a pretty common way of thinking about this is that when you use", "tokens": [50392, 1105, 452, 2633, 307, 1105, 293, 341, 307, 257, 1238, 2689, 636, 295, 1953, 466, 341, 307, 300, 562, 291, 764, 50756], "temperature": 0.0, "avg_logprob": -0.20415703455607095, "compression_ratio": 1.6355932203389831, "no_speech_prob": 2.4682465664227493e-05}, {"id": 624, "seek": 447172, "start": 4479.56, "end": 4485.88, "text": " mean squared error MSC as your loss function on these kinds of models you tend to get rather blurry", "tokens": [50756, 914, 8889, 6713, 7395, 34, 382, 428, 4470, 2445, 322, 613, 3685, 295, 5245, 291, 3928, 281, 483, 2831, 37644, 51072], "temperature": 0.0, "avg_logprob": -0.20415703455607095, "compression_ratio": 1.6355932203389831, "no_speech_prob": 2.4682465664227493e-05}, {"id": 625, "seek": 447172, "start": 4485.88, "end": 4490.52, "text": " results because if the model's not sure what to do it's just going to predict kind of the average", "tokens": [51072, 3542, 570, 498, 264, 2316, 311, 406, 988, 437, 281, 360, 309, 311, 445, 516, 281, 6069, 733, 295, 264, 4274, 51304], "temperature": 0.0, "avg_logprob": -0.20415703455607095, "compression_ratio": 1.6355932203389831, "no_speech_prob": 2.4682465664227493e-05}, {"id": 626, "seek": 447172, "start": 4491.16, "end": 4500.92, "text": " you know um so one good way to fix that is to use perceptual loss and um I think it was Jono", "tokens": [51336, 291, 458, 1105, 370, 472, 665, 636, 281, 3191, 300, 307, 281, 764, 43276, 901, 4470, 293, 1105, 286, 519, 309, 390, 7745, 78, 51824], "temperature": 0.0, "avg_logprob": -0.20415703455607095, "compression_ratio": 1.6355932203389831, "no_speech_prob": 2.4682465664227493e-05}, {"id": 627, "seek": 450092, "start": 4500.92, "end": 4507.4, "text": " who taught us about perceptual loss wasn't it when we did like the style transfer stuff um um", "tokens": [50364, 567, 5928, 505, 466, 43276, 901, 4470, 2067, 380, 309, 562, 321, 630, 411, 264, 3758, 5003, 1507, 1105, 1105, 50688], "temperature": 0.0, "avg_logprob": -0.21347802305874758, "compression_ratio": 1.6033519553072626, "no_speech_prob": 9.074613444681745e-06}, {"id": 628, "seek": 450092, "start": 4507.4, "end": 4512.76, "text": " so perceptual loss is this idea that we could look it's kind of similar as well to the the FID idea", "tokens": [50688, 370, 43276, 901, 4470, 307, 341, 1558, 300, 321, 727, 574, 309, 311, 733, 295, 2531, 382, 731, 281, 264, 264, 479, 2777, 1558, 50956], "temperature": 0.0, "avg_logprob": -0.21347802305874758, "compression_ratio": 1.6033519553072626, "no_speech_prob": 9.074613444681745e-06}, {"id": 629, "seek": 450092, "start": 4513.72, "end": 4521.4, "text": " we could look at the some intermediate layer of a pre-trained model and try to make sure that", "tokens": [51004, 321, 727, 574, 412, 264, 512, 19376, 4583, 295, 257, 659, 12, 17227, 2001, 2316, 293, 853, 281, 652, 988, 300, 51388], "temperature": 0.0, "avg_logprob": -0.21347802305874758, "compression_ratio": 1.6033519553072626, "no_speech_prob": 9.074613444681745e-06}, {"id": 630, "seek": 452140, "start": 4522.04, "end": 4532.44, "text": " um our output images have the same features as the real images and in this case it ought to be", "tokens": [50396, 1105, 527, 5598, 5267, 362, 264, 912, 4122, 382, 264, 957, 5267, 293, 294, 341, 1389, 309, 13416, 281, 312, 50916], "temperature": 0.0, "avg_logprob": -0.19603385925292968, "compression_ratio": 1.9441624365482233, "no_speech_prob": 6.108699017204344e-05}, {"id": 631, "seek": 452140, "start": 4532.44, "end": 4537.799999999999, "text": " saying like the real image you know if we went to kind of midway through a resnet it should be", "tokens": [50916, 1566, 411, 264, 957, 3256, 291, 458, 498, 321, 1437, 281, 733, 295, 2062, 676, 807, 257, 725, 7129, 309, 820, 312, 51184], "temperature": 0.0, "avg_logprob": -0.19603385925292968, "compression_ratio": 1.9441624365482233, "no_speech_prob": 6.108699017204344e-05}, {"id": 632, "seek": 452140, "start": 4537.799999999999, "end": 4543.799999999999, "text": " saying like there should be an eye here you know and in this case this would not represent an eye", "tokens": [51184, 1566, 411, 456, 820, 312, 364, 3313, 510, 291, 458, 293, 294, 341, 1389, 341, 576, 406, 2906, 364, 3313, 51484], "temperature": 0.0, "avg_logprob": -0.19603385925292968, "compression_ratio": 1.9441624365482233, "no_speech_prob": 6.108699017204344e-05}, {"id": 633, "seek": 452140, "start": 4543.799999999999, "end": 4550.5199999999995, "text": " very well so that would should give it some useful feedback to improve how it draws an eye here", "tokens": [51484, 588, 731, 370, 300, 576, 820, 976, 309, 512, 4420, 5824, 281, 3470, 577, 309, 20045, 364, 3313, 510, 51820], "temperature": 0.0, "avg_logprob": -0.19603385925292968, "compression_ratio": 1.9441624365482233, "no_speech_prob": 6.108699017204344e-05}, {"id": 634, "seek": 455140, "start": 4551.48, "end": 4557.639999999999, "text": " um so that's the basic idea um so to do perceptual loss we need to classify a model", "tokens": [50368, 1105, 370, 300, 311, 264, 3875, 1558, 1105, 370, 281, 360, 43276, 901, 4470, 321, 643, 281, 33872, 257, 2316, 50676], "temperature": 0.0, "avg_logprob": -0.25971601297567176, "compression_ratio": 1.6954314720812182, "no_speech_prob": 8.397906640311703e-06}, {"id": 635, "seek": 455140, "start": 4558.92, "end": 4563.16, "text": " so I just used the little I don't know why I used the 25 epoch one I guess maybe that's", "tokens": [50740, 370, 286, 445, 1143, 264, 707, 286, 500, 380, 458, 983, 286, 1143, 264, 3552, 30992, 339, 472, 286, 2041, 1310, 300, 311, 50952], "temperature": 0.0, "avg_logprob": -0.25971601297567176, "compression_ratio": 1.6954314720812182, "no_speech_prob": 8.397906640311703e-06}, {"id": 636, "seek": 455140, "start": 4563.16, "end": 4568.92, "text": " all I had trained when at that time um so it's used a little 25 epoch model um", "tokens": [50952, 439, 286, 632, 8895, 562, 412, 300, 565, 1105, 370, 309, 311, 1143, 257, 707, 3552, 30992, 339, 2316, 1105, 51240], "temperature": 0.0, "avg_logprob": -0.25971601297567176, "compression_ratio": 1.6954314720812182, "no_speech_prob": 8.397906640311703e-06}, {"id": 637, "seek": 455140, "start": 4573.5599999999995, "end": 4580.36, "text": " so then um yeah just grab a batch validation set and then we can just try it out by", "tokens": [51472, 370, 550, 1105, 1338, 445, 4444, 257, 15245, 24071, 992, 293, 550, 321, 393, 445, 853, 309, 484, 538, 51812], "temperature": 0.0, "avg_logprob": -0.25971601297567176, "compression_ratio": 1.6954314720812182, "no_speech_prob": 8.397906640311703e-06}, {"id": 638, "seek": 458140, "start": 4582.04, "end": 4593.4, "text": " calling the classifier model um and here I'm doing it in FP16 just keeping my memory use down", "tokens": [50396, 5141, 264, 1508, 9902, 2316, 1105, 293, 510, 286, 478, 884, 309, 294, 36655, 6866, 445, 5145, 452, 4675, 764, 760, 50964], "temperature": 0.0, "avg_logprob": -0.28435107200376447, "compression_ratio": 1.4269005847953216, "no_speech_prob": 3.0415751552936854e-06}, {"id": 639, "seek": 458140, "start": 4596.5199999999995, "end": 4601.4, "text": " um I don't think this dot half would be necessary since I got auto cast", "tokens": [51120, 1105, 286, 500, 380, 519, 341, 5893, 1922, 576, 312, 4818, 1670, 286, 658, 8399, 4193, 51364], "temperature": 0.0, "avg_logprob": -0.28435107200376447, "compression_ratio": 1.4269005847953216, "no_speech_prob": 3.0415751552936854e-06}, {"id": 640, "seek": 458140, "start": 4601.4, "end": 4606.92, "text": " anyway never mind um okay this is the same code we had before for the sin sets", "tokens": [51364, 4033, 1128, 1575, 1105, 1392, 341, 307, 264, 912, 3089, 321, 632, 949, 337, 264, 3343, 6352, 51640], "temperature": 0.0, "avg_logprob": -0.28435107200376447, "compression_ratio": 1.4269005847953216, "no_speech_prob": 3.0415751552936854e-06}, {"id": 641, "seek": 460692, "start": 4607.8, "end": 4613.24, "text": " um so here is our images", "tokens": [50408, 1105, 370, 510, 307, 527, 5267, 50680], "temperature": 0.0, "avg_logprob": -0.2770383101243239, "compression_ratio": 1.644927536231884, "no_speech_prob": 1.371145208395319e-05}, {"id": 642, "seek": 460692, "start": 4616.52, "end": 4621.56, "text": " um so what we've got here", "tokens": [50844, 1105, 370, 437, 321, 600, 658, 510, 51096], "temperature": 0.0, "avg_logprob": -0.2770383101243239, "compression_ratio": 1.644927536231884, "no_speech_prob": 1.371145208395319e-05}, {"id": 643, "seek": 460692, "start": 4627.16, "end": 4631.32, "text": " huh just looking at some of them they're a bit weird aren't they I mean koalas are", "tokens": [51376, 7020, 445, 1237, 412, 512, 295, 552, 436, 434, 257, 857, 3657, 3212, 380, 436, 286, 914, 8384, 304, 296, 366, 51584], "temperature": 0.0, "avg_logprob": -0.2770383101243239, "compression_ratio": 1.644927536231884, "no_speech_prob": 1.371145208395319e-05}, {"id": 644, "seek": 460692, "start": 4631.32, "end": 4635.32, "text": " fine you know I wouldn't have picked this as a parking meter I wouldn't have picked this as a", "tokens": [51584, 2489, 291, 458, 286, 2759, 380, 362, 6183, 341, 382, 257, 9893, 9255, 286, 2759, 380, 362, 6183, 341, 382, 257, 51784], "temperature": 0.0, "avg_logprob": -0.2770383101243239, "compression_ratio": 1.644927536231884, "no_speech_prob": 1.371145208395319e-05}, {"id": 645, "seek": 463532, "start": 4635.32, "end": 4641.0, "text": " bow tie um so yeah so basically what this is doing here is it's um", "tokens": [50364, 4503, 7582, 1105, 370, 1338, 370, 1936, 437, 341, 307, 884, 510, 307, 309, 311, 1105, 50648], "temperature": 0.0, "avg_logprob": -0.21139701015977974, "compression_ratio": 1.92, "no_speech_prob": 5.173851604922675e-06}, {"id": 646, "seek": 463532, "start": 4647.08, "end": 4654.2, "text": " showing us the predictions so the predictions are not amazing um trolley bus that looks right", "tokens": [50952, 4099, 505, 264, 21264, 370, 264, 21264, 366, 406, 2243, 1105, 20680, 2030, 1255, 300, 1542, 558, 51308], "temperature": 0.0, "avg_logprob": -0.21139701015977974, "compression_ratio": 1.92, "no_speech_prob": 5.173851604922675e-06}, {"id": 647, "seek": 463532, "start": 4655.719999999999, "end": 4660.92, "text": " um this is weird it's called this one a neck brace and this one a basketball that looks more", "tokens": [51384, 1105, 341, 307, 3657, 309, 311, 1219, 341, 472, 257, 6189, 38458, 293, 341, 472, 257, 11767, 300, 1542, 544, 51644], "temperature": 0.0, "avg_logprob": -0.21139701015977974, "compression_ratio": 1.92, "no_speech_prob": 5.173851604922675e-06}, {"id": 648, "seek": 463532, "start": 4660.92, "end": 4664.28, "text": " like a neck brace the labrador retriever it's got right the tractor it's got right", "tokens": [51644, 411, 257, 6189, 38458, 264, 2715, 81, 5409, 19817, 331, 309, 311, 658, 558, 264, 31857, 309, 311, 658, 558, 51812], "temperature": 0.0, "avg_logprob": -0.21139701015977974, "compression_ratio": 1.92, "no_speech_prob": 5.173851604922675e-06}, {"id": 649, "seek": 466428, "start": 4664.28, "end": 4669.32, "text": " centipedes right mushrooms right those probably aren't mush punching bags okay so you know you", "tokens": [50364, 1489, 647, 48490, 558, 17973, 558, 729, 1391, 3212, 380, 275, 1498, 34866, 10405, 1392, 370, 291, 458, 291, 50616], "temperature": 0.0, "avg_logprob": -0.19591135025024414, "compression_ratio": 1.6351931330472103, "no_speech_prob": 3.3931180496438174e-06}, {"id": 650, "seek": 466428, "start": 4669.32, "end": 4672.759999999999, "text": " can see our classifier it's okay but it's not amazing I think this was one with like a 60%", "tokens": [50616, 393, 536, 527, 1508, 9902, 309, 311, 1392, 457, 309, 311, 406, 2243, 286, 519, 341, 390, 472, 365, 411, 257, 4060, 4, 50788], "temperature": 0.0, "avg_logprob": -0.19591135025024414, "compression_ratio": 1.6351931330472103, "no_speech_prob": 3.3931180496438174e-06}, {"id": 651, "seek": 466428, "start": 4673.719999999999, "end": 4680.679999999999, "text": " accuracy um but the important thing is it's like it's got enough features to be able to like", "tokens": [50836, 14170, 1105, 457, 264, 1021, 551, 307, 309, 311, 411, 309, 311, 658, 1547, 4122, 281, 312, 1075, 281, 411, 51184], "temperature": 0.0, "avg_logprob": -0.19591135025024414, "compression_ratio": 1.6351931330472103, "no_speech_prob": 3.3931180496438174e-06}, {"id": 652, "seek": 466428, "start": 4680.679999999999, "end": 4685.639999999999, "text": " do an okay job I have no idea what this is so I'm pretty sure it's not a goose", "tokens": [51184, 360, 364, 1392, 1691, 286, 362, 572, 1558, 437, 341, 307, 370, 286, 478, 1238, 988, 309, 311, 406, 257, 24717, 51432], "temperature": 0.0, "avg_logprob": -0.19591135025024414, "compression_ratio": 1.6351931330472103, "no_speech_prob": 3.3931180496438174e-06}, {"id": 653, "seek": 466428, "start": 4688.04, "end": 4690.84, "text": " um okay so the model um", "tokens": [51552, 1105, 1392, 370, 264, 2316, 1105, 51692], "temperature": 0.0, "avg_logprob": -0.19591135025024414, "compression_ratio": 1.6351931330472103, "no_speech_prob": 3.3931180496438174e-06}, {"id": 654, "seek": 469428, "start": 4694.599999999999, "end": 4706.12, "text": " the model is a very simple just a bunch of res blocks um three four five and then at the end", "tokens": [50380, 264, 2316, 307, 257, 588, 2199, 445, 257, 3840, 295, 725, 8474, 1105, 1045, 1451, 1732, 293, 550, 412, 264, 917, 50956], "temperature": 0.0, "avg_logprob": -0.24140796376698054, "compression_ratio": 1.58125, "no_speech_prob": 8.05894558197906e-07}, {"id": 655, "seek": 469428, "start": 4706.12, "end": 4715.48, "text": " we've got our pooling flatten dropout linear batch not um so we don't need", "tokens": [50956, 321, 600, 658, 527, 7005, 278, 24183, 3270, 346, 8213, 15245, 406, 1105, 370, 321, 500, 380, 643, 51424], "temperature": 0.0, "avg_logprob": -0.24140796376698054, "compression_ratio": 1.58125, "no_speech_prob": 8.05894558197906e-07}, {"id": 656, "seek": 469428, "start": 4717.32, "end": 4721.639999999999, "text": " yeah so what we're going to do is just to keep things simple we're just going to grab", "tokens": [51516, 1338, 370, 437, 321, 434, 516, 281, 360, 307, 445, 281, 1066, 721, 2199, 321, 434, 445, 516, 281, 4444, 51732], "temperature": 0.0, "avg_logprob": -0.24140796376698054, "compression_ratio": 1.58125, "no_speech_prob": 8.05894558197906e-07}, {"id": 657, "seek": 472164, "start": 4722.360000000001, "end": 4733.240000000001, "text": " um I think the end of the three res block and so a simple way to do that is we'll just go from", "tokens": [50400, 1105, 286, 519, 264, 917, 295, 264, 1045, 725, 3461, 293, 370, 257, 2199, 636, 281, 360, 300, 307, 321, 603, 445, 352, 490, 50944], "temperature": 0.0, "avg_logprob": -0.1786699441763071, "compression_ratio": 1.5695364238410596, "no_speech_prob": 5.122888637743017e-07}, {"id": 658, "seek": 472164, "start": 4733.240000000001, "end": 4739.56, "text": " range four to the end of the model and delete those layers so if we do that", "tokens": [50944, 3613, 1451, 281, 264, 917, 295, 264, 2316, 293, 12097, 729, 7914, 370, 498, 321, 360, 300, 51260], "temperature": 0.0, "avg_logprob": -0.1786699441763071, "compression_ratio": 1.5695364238410596, "no_speech_prob": 5.122888637743017e-07}, {"id": 659, "seek": 472164, "start": 4740.84, "end": 4744.76, "text": " and then look at the model again you can now see I've got zero one", "tokens": [51324, 293, 550, 574, 412, 264, 2316, 797, 291, 393, 586, 536, 286, 600, 658, 4018, 472, 51520], "temperature": 0.0, "avg_logprob": -0.1786699441763071, "compression_ratio": 1.5695364238410596, "no_speech_prob": 5.122888637743017e-07}, {"id": 660, "seek": 474476, "start": 4744.92, "end": 4755.320000000001, "text": " two three and that's it so this model um is going to yeah return", "tokens": [50372, 732, 1045, 293, 300, 311, 309, 370, 341, 2316, 1105, 307, 516, 281, 1338, 2736, 50892], "temperature": 0.0, "avg_logprob": -0.21555307706197102, "compression_ratio": 1.490909090909091, "no_speech_prob": 3.138120746370987e-06}, {"id": 661, "seek": 474476, "start": 4756.280000000001, "end": 4765.0, "text": " kind of the activations after the fourth res block um so for perceptual loss as I think we", "tokens": [50940, 733, 295, 264, 2430, 763, 934, 264, 6409, 725, 3461, 1105, 370, 337, 43276, 901, 4470, 382, 286, 519, 321, 51376], "temperature": 0.0, "avg_logprob": -0.21555307706197102, "compression_ratio": 1.490909090909091, "no_speech_prob": 3.138120746370987e-06}, {"id": 662, "seek": 474476, "start": 4765.0, "end": 4769.400000000001, "text": " talked about you could like pick a couple of different places like there's various ways to", "tokens": [51376, 2825, 466, 291, 727, 411, 1888, 257, 1916, 295, 819, 3190, 411, 456, 311, 3683, 2098, 281, 51596], "temperature": 0.0, "avg_logprob": -0.21555307706197102, "compression_ratio": 1.490909090909091, "no_speech_prob": 3.138120746370987e-06}, {"id": 663, "seek": 476940, "start": 4769.4, "end": 4775.32, "text": " do it this is just the simplest I didn't even have to use hooks or anything we can just call", "tokens": [50364, 360, 309, 341, 307, 445, 264, 22811, 286, 994, 380, 754, 362, 281, 764, 26485, 420, 1340, 321, 393, 445, 818, 50660], "temperature": 0.0, "avg_logprob": -0.20097467773839048, "compression_ratio": 1.6120218579234973, "no_speech_prob": 2.144444988516625e-05}, {"id": 664, "seek": 476940, "start": 4775.32, "end": 4784.5199999999995, "text": " c model and in fact if we do it um so just to take a look at this looks like and again we're going to", "tokens": [50660, 269, 2316, 293, 294, 1186, 498, 321, 360, 309, 1105, 370, 445, 281, 747, 257, 574, 412, 341, 1542, 411, 293, 797, 321, 434, 516, 281, 51120], "temperature": 0.0, "avg_logprob": -0.20097467773839048, "compression_ratio": 1.6120218579234973, "no_speech_prob": 2.144444988516625e-05}, {"id": 665, "seek": 476940, "start": 4784.5199999999995, "end": 4794.04, "text": " use uh mixed precision here um we can grab our y batch as before put it through our classifier model", "tokens": [51120, 764, 2232, 7467, 18356, 510, 1105, 321, 393, 4444, 527, 288, 15245, 382, 949, 829, 309, 807, 527, 1508, 9902, 2316, 51596], "temperature": 0.0, "avg_logprob": -0.20097467773839048, "compression_ratio": 1.6120218579234973, "no_speech_prob": 2.144444988516625e-05}, {"id": 666, "seek": 479404, "start": 4794.28, "end": 4802.28, "text": " um and so now that we've done this this is now going to give us those intermediate level features", "tokens": [50376, 1105, 293, 370, 586, 300, 321, 600, 1096, 341, 341, 307, 586, 516, 281, 976, 505, 729, 19376, 1496, 4122, 50776], "temperature": 0.0, "avg_logprob": -0.22594906733586237, "compression_ratio": 1.7619047619047619, "no_speech_prob": 2.1907753762206994e-06}, {"id": 667, "seek": 479404, "start": 4803.56, "end": 4807.64, "text": " um so the features what's the shape of them it's batch size one or two four", "tokens": [50840, 1105, 370, 264, 4122, 437, 311, 264, 3909, 295, 552, 309, 311, 15245, 2744, 472, 420, 732, 1451, 51044], "temperature": 0.0, "avg_logprob": -0.22594906733586237, "compression_ratio": 1.7619047619047619, "no_speech_prob": 2.1907753762206994e-06}, {"id": 668, "seek": 479404, "start": 4808.44, "end": 4813.08, "text": " by the number of channels of that layer by the height and width of that layer so these are eight", "tokens": [51084, 538, 264, 1230, 295, 9235, 295, 300, 4583, 538, 264, 6681, 293, 11402, 295, 300, 4583, 370, 613, 366, 3180, 51316], "temperature": 0.0, "avg_logprob": -0.22594906733586237, "compression_ratio": 1.7619047619047619, "no_speech_prob": 2.1907753762206994e-06}, {"id": 669, "seek": 479404, "start": 4813.08, "end": 4821.8, "text": " by eight by 256 features we're going to be using for the perceptual loss um and so when I was doing", "tokens": [51316, 538, 3180, 538, 38882, 4122, 321, 434, 516, 281, 312, 1228, 337, 264, 43276, 901, 4470, 1105, 293, 370, 562, 286, 390, 884, 51752], "temperature": 0.0, "avg_logprob": -0.22594906733586237, "compression_ratio": 1.7619047619047619, "no_speech_prob": 2.1907753762206994e-06}, {"id": 670, "seek": 482180, "start": 4821.8, "end": 4826.84, "text": " this I kind of wanted to like check whether things were vaguely looking reasonable um so I", "tokens": [50364, 341, 286, 733, 295, 1415, 281, 411, 1520, 1968, 721, 645, 13501, 48863, 1237, 10585, 1105, 370, 286, 50616], "temperature": 0.0, "avg_logprob": -0.2480163790962913, "compression_ratio": 1.406015037593985, "no_speech_prob": 2.1232078779576113e-06}, {"id": 671, "seek": 482180, "start": 4826.84, "end": 4842.68, "text": " would expect that these features um from the actual y should be similar to if I um use our model", "tokens": [50616, 576, 2066, 300, 613, 4122, 1105, 490, 264, 3539, 288, 820, 312, 2531, 281, 498, 286, 1105, 764, 527, 2316, 51408], "temperature": 0.0, "avg_logprob": -0.2480163790962913, "compression_ratio": 1.406015037593985, "no_speech_prob": 2.1232078779576113e-06}, {"id": 672, "seek": 484268, "start": 4843.320000000001, "end": 4848.92, "text": " um so something that I did I thought okay if we if we took that model that we trained then", "tokens": [50396, 1105, 370, 746, 300, 286, 630, 286, 1194, 1392, 498, 321, 498, 321, 1890, 300, 2316, 300, 321, 8895, 550, 50676], "temperature": 0.0, "avg_logprob": -0.42299635692309306, "compression_ratio": 1.8341463414634147, "no_speech_prob": 1.1658358744170982e-05}, {"id": 673, "seek": 484268, "start": 4848.92, "end": 4856.92, "text": " we would hope that the features were at least of the same sign um from you know from the um result", "tokens": [50676, 321, 576, 1454, 300, 264, 4122, 645, 412, 1935, 295, 264, 912, 1465, 1105, 490, 291, 458, 490, 264, 1105, 1874, 51076], "temperature": 0.0, "avg_logprob": -0.42299635692309306, "compression_ratio": 1.8341463414634147, "no_speech_prob": 1.1658358744170982e-05}, {"id": 674, "seek": 484268, "start": 4856.92, "end": 4863.0, "text": " of the model then they are in the real images um so this is just me comparing that and it's like", "tokens": [51076, 295, 264, 2316, 550, 436, 366, 294, 264, 957, 5267, 1105, 370, 341, 307, 445, 385, 15763, 300, 293, 309, 311, 411, 51380], "temperature": 0.0, "avg_logprob": -0.42299635692309306, "compression_ratio": 1.8341463414634147, "no_speech_prob": 1.1658358744170982e-05}, {"id": 675, "seek": 484268, "start": 4863.0, "end": 4866.360000000001, "text": " oh yeah they are generally the same sign so this is just a little check to see if they're", "tokens": [51380, 1954, 1338, 436, 366, 5101, 264, 912, 1465, 370, 341, 307, 445, 257, 707, 1520, 281, 536, 498, 436, 434, 51548], "temperature": 0.0, "avg_logprob": -0.42299635692309306, "compression_ratio": 1.8341463414634147, "no_speech_prob": 1.1658358744170982e-05}, {"id": 676, "seek": 486636, "start": 4866.5199999999995, "end": 4871.0, "text": " the real images um so this is just me comparing that and it's like oh yeah they are generally", "tokens": [50372, 264, 957, 5267, 1105, 370, 341, 307, 445, 385, 15763, 300, 293, 309, 311, 411, 1954, 1338, 436, 366, 5101, 50596], "temperature": 0.0, "avg_logprob": -0.19875395500053794, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.0011126033496111631}, {"id": 677, "seek": 486636, "start": 4871.0, "end": 4875.48, "text": " the same sign so this is just little checks that I was doing along the way and then I also thought", "tokens": [50596, 264, 912, 1465, 370, 341, 307, 445, 707, 13834, 300, 286, 390, 884, 2051, 264, 636, 293, 550, 286, 611, 1194, 50820], "temperature": 0.0, "avg_logprob": -0.19875395500053794, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.0011126033496111631}, {"id": 678, "seek": 486636, "start": 4875.48, "end": 4883.5599999999995, "text": " I'd kind of look at the MSC loss along the way um yeah so there's no need to keep all those in there", "tokens": [50820, 286, 1116, 733, 295, 574, 412, 264, 7395, 34, 4470, 2051, 264, 636, 1105, 1338, 370, 456, 311, 572, 643, 281, 1066, 439, 729, 294, 456, 51224], "temperature": 0.0, "avg_logprob": -0.19875395500053794, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.0011126033496111631}, {"id": 679, "seek": 486636, "start": 4883.5599999999995, "end": 4888.759999999999, "text": " it was just stuff I was kind of doing to like debug as I went well not even debug to like", "tokens": [51224, 309, 390, 445, 1507, 286, 390, 733, 295, 884, 281, 411, 24083, 382, 286, 1437, 731, 406, 754, 24083, 281, 411, 51484], "temperature": 0.0, "avg_logprob": -0.19875395500053794, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.0011126033496111631}, {"id": 680, "seek": 486636, "start": 4888.759999999999, "end": 4894.28, "text": " identify ahead of time as if any problems um so now we can calculate create our loss function", "tokens": [51484, 5876, 2286, 295, 565, 382, 498, 604, 2740, 1105, 370, 586, 321, 393, 8873, 1884, 527, 4470, 2445, 51760], "temperature": 0.0, "avg_logprob": -0.19875395500053794, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.0011126033496111631}, {"id": 681, "seek": 489428, "start": 4895.0, "end": 4902.5199999999995, "text": " so our loss function is going to be the um the MSC loss just like before between the input and", "tokens": [50400, 370, 527, 4470, 2445, 307, 516, 281, 312, 264, 1105, 264, 7395, 34, 4470, 445, 411, 949, 1296, 264, 4846, 293, 50776], "temperature": 0.0, "avg_logprob": -0.22207704186439514, "compression_ratio": 1.6733333333333333, "no_speech_prob": 8.530239028914366e-06}, {"id": 682, "seek": 489428, "start": 4902.5199999999995, "end": 4909.48, "text": " the target which is just all that's being passed in here plus the MSC loss between the", "tokens": [50776, 264, 3779, 597, 307, 445, 439, 300, 311, 885, 4678, 294, 510, 1804, 264, 7395, 34, 4470, 1296, 264, 51124], "temperature": 0.0, "avg_logprob": -0.22207704186439514, "compression_ratio": 1.6733333333333333, "no_speech_prob": 8.530239028914366e-06}, {"id": 683, "seek": 489428, "start": 4910.28, "end": 4914.92, "text": " features we get out of cmodel and the features we get from the actual", "tokens": [51164, 4122, 321, 483, 484, 295, 269, 8014, 338, 293, 264, 4122, 321, 483, 490, 264, 3539, 51396], "temperature": 0.0, "avg_logprob": -0.22207704186439514, "compression_ratio": 1.6733333333333333, "no_speech_prob": 8.530239028914366e-06}, {"id": 684, "seek": 491492, "start": 4915.88, "end": 4926.52, "text": " and the features we get from the actual target image and so the features um we can calculate", "tokens": [50412, 293, 264, 4122, 321, 483, 490, 264, 3539, 3779, 3256, 293, 370, 264, 4122, 1105, 321, 393, 8873, 50944], "temperature": 0.0, "avg_logprob": -0.251578562187426, "compression_ratio": 1.8299319727891157, "no_speech_prob": 0.0005357661284506321}, {"id": 685, "seek": 491492, "start": 4927.88, "end": 4934.84, "text": " for the target image now the target image we're not going to be modifying that at all", "tokens": [51012, 337, 264, 3779, 3256, 586, 264, 3779, 3256, 321, 434, 406, 516, 281, 312, 42626, 300, 412, 439, 51360], "temperature": 0.0, "avg_logprob": -0.251578562187426, "compression_ratio": 1.8299319727891157, "no_speech_prob": 0.0005357661284506321}, {"id": 686, "seek": 491492, "start": 4934.84, "end": 4941.4, "text": " so we do that bit with no gradient um but we do want to be able to modify the thing that's", "tokens": [51360, 370, 321, 360, 300, 857, 365, 572, 16235, 1105, 457, 321, 360, 528, 281, 312, 1075, 281, 16927, 264, 551, 300, 311, 51688], "temperature": 0.0, "avg_logprob": -0.251578562187426, "compression_ratio": 1.8299319727891157, "no_speech_prob": 0.0005357661284506321}, {"id": 687, "seek": 494140, "start": 4941.4, "end": 4945.32, "text": " generating our input that's the model we're trying to actually optimize so we do have gradient", "tokens": [50364, 17746, 527, 4846, 300, 311, 264, 2316, 321, 434, 1382, 281, 767, 19719, 370, 321, 360, 362, 16235, 50560], "temperature": 0.0, "avg_logprob": -0.18105055865119485, "compression_ratio": 1.7, "no_speech_prob": 9.223448614648078e-06}, {"id": 688, "seek": 494140, "start": 4945.32, "end": 4950.92, "text": " for that so in each case we're calling the classifier model one on the target and one on", "tokens": [50560, 337, 300, 370, 294, 1184, 1389, 321, 434, 5141, 264, 1508, 9902, 2316, 472, 322, 264, 3779, 293, 472, 322, 50840], "temperature": 0.0, "avg_logprob": -0.18105055865119485, "compression_ratio": 1.7, "no_speech_prob": 9.223448614648078e-06}, {"id": 689, "seek": 494140, "start": 4950.92, "end": 4959.96, "text": " the input and so those are giving us our features now then we add them together but they're not", "tokens": [50840, 264, 4846, 293, 370, 729, 366, 2902, 505, 527, 4122, 586, 550, 321, 909, 552, 1214, 457, 436, 434, 406, 51292], "temperature": 0.0, "avg_logprob": -0.18105055865119485, "compression_ratio": 1.7, "no_speech_prob": 9.223448614648078e-06}, {"id": 690, "seek": 494140, "start": 4959.96, "end": 4965.879999999999, "text": " particularly similar numerically like they're very different scales and we wouldn't want it to", "tokens": [51292, 4098, 2531, 7866, 984, 411, 436, 434, 588, 819, 17408, 293, 321, 2759, 380, 528, 309, 281, 51588], "temperature": 0.0, "avg_logprob": -0.18105055865119485, "compression_ratio": 1.7, "no_speech_prob": 9.223448614648078e-06}, {"id": 691, "seek": 496588, "start": 4965.88, "end": 4972.6, "text": " focus entirely on one or the other so i just ran it for an epoch or two checked what the losses", "tokens": [50364, 1879, 7696, 322, 472, 420, 264, 661, 370, 741, 445, 5872, 309, 337, 364, 30992, 339, 420, 732, 10033, 437, 264, 15352, 50700], "temperature": 0.0, "avg_logprob": -0.1984437716904507, "compression_ratio": 1.685589519650655, "no_speech_prob": 1.5446192264789715e-05}, {"id": 692, "seek": 496588, "start": 4972.6, "end": 4977.16, "text": " would look like and i noticed that the feature loss was about 10 times bigger so my very hacky", "tokens": [50700, 576, 574, 411, 293, 741, 5694, 300, 264, 4111, 4470, 390, 466, 1266, 1413, 3801, 370, 452, 588, 10339, 88, 50928], "temperature": 0.0, "avg_logprob": -0.1984437716904507, "compression_ratio": 1.685589519650655, "no_speech_prob": 1.5446192264789715e-05}, {"id": 693, "seek": 496588, "start": 4977.16, "end": 4983.8, "text": " way was just to divide it by 10 but honestly like that detail doesn't tend to matter very much in", "tokens": [50928, 636, 390, 445, 281, 9845, 309, 538, 1266, 457, 6095, 411, 300, 2607, 1177, 380, 3928, 281, 1871, 588, 709, 294, 51260], "temperature": 0.0, "avg_logprob": -0.1984437716904507, "compression_ratio": 1.685589519650655, "no_speech_prob": 1.5446192264789715e-05}, {"id": 694, "seek": 496588, "start": 4983.8, "end": 4992.28, "text": " my opinion which there's nothing wrong with doing it a rather hacky way um there are papers which", "tokens": [51260, 452, 4800, 597, 456, 311, 1825, 2085, 365, 884, 309, 257, 2831, 10339, 88, 636, 1105, 456, 366, 10577, 597, 51684], "temperature": 0.0, "avg_logprob": -0.1984437716904507, "compression_ratio": 1.685589519650655, "no_speech_prob": 1.5446192264789715e-05}, {"id": 695, "seek": 499228, "start": 4992.28, "end": 4998.28, "text": " suggest more elegant ways to handle it which isn't a bad idea to save you a bit of time if", "tokens": [50364, 3402, 544, 21117, 2098, 281, 4813, 309, 597, 1943, 380, 257, 1578, 1558, 281, 3155, 291, 257, 857, 295, 565, 498, 50664], "temperature": 0.0, "avg_logprob": -0.2468102561102973, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.00028683588607236743}, {"id": 696, "seek": 499228, "start": 4998.28, "end": 5004.12, "text": " you're doing a lot of messing around with this. Jeremy, I don't know if you know it but the", "tokens": [50664, 291, 434, 884, 257, 688, 295, 23258, 926, 365, 341, 13, 17809, 11, 286, 500, 380, 458, 498, 291, 458, 309, 457, 264, 50956], "temperature": 0.0, "avg_logprob": -0.2468102561102973, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.00028683588607236743}, {"id": 697, "seek": 499228, "start": 5004.92, "end": 5013.5599999999995, "text": " the new VAE decoder from Stability AI for the stable diffusion auto encoder they trained", "tokens": [50996, 264, 777, 18527, 36, 979, 19866, 490, 745, 2310, 7318, 337, 264, 8351, 25242, 8399, 2058, 19866, 436, 8895, 51428], "temperature": 0.0, "avg_logprob": -0.2468102561102973, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.00028683588607236743}, {"id": 698, "seek": 499228, "start": 5013.5599999999995, "end": 5017.48, "text": " some with just mean squared error and some with mean squared error combined with the perceptual", "tokens": [51428, 512, 365, 445, 914, 8889, 6713, 293, 512, 365, 914, 8889, 6713, 9354, 365, 264, 43276, 901, 51624], "temperature": 0.0, "avg_logprob": -0.2468102561102973, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.00028683588607236743}, {"id": 699, "seek": 501748, "start": 5017.48, "end": 5023.16, "text": " loss and they had a scaling factor of you know times 0.1 so exactly the same dividing the", "tokens": [50364, 4470, 293, 436, 632, 257, 21589, 5952, 295, 291, 458, 1413, 1958, 13, 16, 370, 2293, 264, 912, 26764, 264, 50648], "temperature": 0.0, "avg_logprob": -0.27229926983515423, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0005702360649593174}, {"id": 700, "seek": 501748, "start": 5023.16, "end": 5029.48, "text": " percentage so the answer is 0.1 that's that's the official and Andrej Kapathy says that the", "tokens": [50648, 3043, 559, 68, 370, 264, 1867, 307, 1958, 13, 16, 300, 311, 300, 311, 264, 4783, 293, 20667, 73, 21216, 9527, 1619, 300, 264, 50964], "temperature": 0.0, "avg_logprob": -0.27229926983515423, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0005702360649593174}, {"id": 701, "seek": 501748, "start": 5029.48, "end": 5033.639999999999, "text": " correct learning rate to use is always 4e neg 3 so we're getting all this sorted out now that's good", "tokens": [50964, 3006, 2539, 3314, 281, 764, 307, 1009, 1017, 68, 2485, 805, 370, 321, 434, 1242, 439, 341, 25462, 484, 586, 300, 311, 665, 51172], "temperature": 0.0, "avg_logprob": -0.27229926983515423, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0005702360649593174}, {"id": 702, "seek": 501748, "start": 5035.639999999999, "end": 5039.5599999999995, "text": " all right so for my unit we're going to do the same stuff as before in terms of", "tokens": [51272, 439, 558, 370, 337, 452, 4985, 321, 434, 516, 281, 360, 264, 912, 1507, 382, 949, 294, 2115, 295, 51468], "temperature": 0.0, "avg_logprob": -0.27229926983515423, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0005702360649593174}, {"id": 703, "seek": 503956, "start": 5040.52, "end": 5049.080000000001, "text": " initializing it do our lr find train it for 20 epochs and obviously the loss is not comparable", "tokens": [50412, 5883, 3319, 309, 360, 527, 287, 81, 915, 3847, 309, 337, 945, 30992, 28346, 293, 2745, 264, 4470, 307, 406, 25323, 50840], "temperature": 0.0, "avg_logprob": -0.21205884356831395, "compression_ratio": 1.6339285714285714, "no_speech_prob": 1.2805442565877456e-05}, {"id": 704, "seek": 503956, "start": 5049.080000000001, "end": 5053.56, "text": " because this is lost now incorporates the perceptual loss as well and so this is one of", "tokens": [50840, 570, 341, 307, 2731, 586, 50193, 264, 43276, 901, 4470, 382, 731, 293, 370, 341, 307, 472, 295, 51064], "temperature": 0.0, "avg_logprob": -0.21205884356831395, "compression_ratio": 1.6339285714285714, "no_speech_prob": 1.2805442565877456e-05}, {"id": 705, "seek": 503956, "start": 5053.56, "end": 5057.56, "text": " the challenges with these things is like is it better or worse well we're just going to have to", "tokens": [51064, 264, 4759, 365, 613, 721, 307, 411, 307, 309, 1101, 420, 5324, 731, 321, 434, 445, 516, 281, 362, 281, 51264], "temperature": 0.0, "avg_logprob": -0.21205884356831395, "compression_ratio": 1.6339285714285714, "no_speech_prob": 1.2805442565877456e-05}, {"id": 706, "seek": 503956, "start": 5057.56, "end": 5062.92, "text": " take a look and compare I guess and maybe I should copy over our previous models images", "tokens": [51264, 747, 257, 574, 293, 6794, 286, 2041, 293, 1310, 286, 820, 5055, 670, 527, 3894, 5245, 5267, 51532], "temperature": 0.0, "avg_logprob": -0.21205884356831395, "compression_ratio": 1.6339285714285714, "no_speech_prob": 1.2805442565877456e-05}, {"id": 707, "seek": 506292, "start": 5063.88, "end": 5072.76, "text": " so we can compare okay there's our inputs there's our outputs and yeah look he's got pupils now", "tokens": [50412, 370, 321, 393, 6794, 1392, 456, 311, 527, 15743, 456, 311, 527, 23930, 293, 1338, 574, 415, 311, 658, 38404, 586, 50856], "temperature": 0.0, "avg_logprob": -0.2458629047169405, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.7571142204105854e-05}, {"id": 708, "seek": 506292, "start": 5072.76, "end": 5080.52, "text": " which he didn't used to have koala still doesn't quite have eyeballs but like it's definitely less", "tokens": [50856, 597, 415, 994, 380, 1143, 281, 362, 8384, 5159, 920, 1177, 380, 1596, 362, 43758, 457, 411, 309, 311, 2138, 1570, 51244], "temperature": 0.0, "avg_logprob": -0.2458629047169405, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.7571142204105854e-05}, {"id": 709, "seek": 506292, "start": 5082.2, "end": 5090.2, "text": " you know out of focus looking um so yeah it's sort of flipping that's going on", "tokens": [51328, 291, 458, 484, 295, 1879, 1237, 1105, 370, 1338, 309, 311, 1333, 295, 26886, 300, 311, 516, 322, 51728], "temperature": 0.0, "avg_logprob": -0.2458629047169405, "compression_ratio": 1.6153846153846154, "no_speech_prob": 4.7571142204105854e-05}, {"id": 710, "seek": 509020, "start": 5090.76, "end": 5094.5199999999995, "text": " yeah so there's there's some of them are going to be flipped because this is copied from earlier", "tokens": [50392, 1338, 370, 456, 311, 456, 311, 512, 295, 552, 366, 516, 281, 312, 26273, 570, 341, 307, 25365, 490, 3071, 50580], "temperature": 0.0, "avg_logprob": -0.21485610235305058, "compression_ratio": 1.6158536585365855, "no_speech_prob": 1.9832006728393026e-05}, {"id": 711, "seek": 509020, "start": 5095.639999999999, "end": 5099.0, "text": " so yeah there's clipping and cropping going on so they won't be identical", "tokens": [50636, 370, 1338, 456, 311, 49320, 293, 4848, 3759, 516, 322, 370, 436, 1582, 380, 312, 14800, 50804], "temperature": 0.0, "avg_logprob": -0.21485610235305058, "compression_ratio": 1.6158536585365855, "no_speech_prob": 1.9832006728393026e-05}, {"id": 712, "seek": 509020, "start": 5105.5599999999995, "end": 5111.24, "text": " yeah you can also see like the background like was all just blurred before where else now it's", "tokens": [51132, 1338, 291, 393, 611, 536, 411, 264, 3678, 411, 390, 439, 445, 43525, 949, 689, 1646, 586, 309, 311, 51416], "temperature": 0.0, "avg_logprob": -0.21485610235305058, "compression_ratio": 1.6158536585365855, "no_speech_prob": 1.9832006728393026e-05}, {"id": 713, "seek": 511124, "start": 5111.24, "end": 5120.36, "text": " got texture which if we look at the real the real has texture you know so yeah clearly the", "tokens": [50364, 658, 8091, 597, 498, 321, 574, 412, 264, 957, 264, 957, 575, 8091, 291, 458, 370, 1338, 4448, 264, 50820], "temperature": 0.0, "avg_logprob": -0.1922629882242078, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.004609242081642151}, {"id": 714, "seek": 511124, "start": 5120.36, "end": 5127.719999999999, "text": " perceptual loss has improved matters quite significantly there's an interesting thing", "tokens": [50820, 43276, 901, 4470, 575, 9689, 7001, 1596, 10591, 456, 311, 364, 1880, 551, 51188], "temperature": 0.0, "avg_logprob": -0.1922629882242078, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.004609242081642151}, {"id": 715, "seek": 511124, "start": 5127.719999999999, "end": 5131.08, "text": " here which is that there's not really any metric we can use now right because if we did mean squared", "tokens": [51188, 510, 597, 307, 300, 456, 311, 406, 534, 604, 20678, 321, 393, 764, 586, 558, 570, 498, 321, 630, 914, 8889, 51356], "temperature": 0.0, "avg_logprob": -0.1922629882242078, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.004609242081642151}, {"id": 716, "seek": 511124, "start": 5131.08, "end": 5135.16, "text": " error the one that's trained early on means good error would probably do better but visually it", "tokens": [51356, 6713, 264, 472, 300, 311, 8895, 2440, 322, 1355, 665, 6713, 576, 1391, 360, 1101, 457, 19622, 309, 51560], "temperature": 0.0, "avg_logprob": -0.1922629882242078, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.004609242081642151}, {"id": 717, "seek": 511124, "start": 5135.16, "end": 5139.5599999999995, "text": " looks worse yeah and if we use like an fid well that's based on the features of the pre-trained", "tokens": [51560, 1542, 5324, 1338, 293, 498, 321, 764, 411, 364, 283, 327, 731, 300, 311, 2361, 322, 264, 4122, 295, 264, 659, 12, 17227, 2001, 51780], "temperature": 0.0, "avg_logprob": -0.1922629882242078, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.004609242081642151}, {"id": 718, "seek": 513956, "start": 5139.56, "end": 5143.4800000000005, "text": " network so that would probably be biased by the one that's trained using those features the", "tokens": [50364, 3209, 370, 300, 576, 1391, 312, 28035, 538, 264, 472, 300, 311, 8895, 1228, 729, 4122, 264, 50560], "temperature": 0.0, "avg_logprob": -0.1846812919334129, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.0005525812739506364}, {"id": 719, "seek": 513956, "start": 5143.4800000000005, "end": 5147.56, "text": " perceptual loss and so you get back to this very old school thing of like well actually how are", "tokens": [50560, 43276, 901, 4470, 293, 370, 291, 483, 646, 281, 341, 588, 1331, 1395, 551, 295, 411, 731, 767, 577, 366, 50764], "temperature": 0.0, "avg_logprob": -0.1846812919334129, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.0005525812739506364}, {"id": 720, "seek": 513956, "start": 5147.56, "end": 5152.4400000000005, "text": " we choosing is just looking and evaluating right um and when you speak to someone like Jason Antic", "tokens": [50764, 321, 10875, 307, 445, 1237, 293, 27479, 558, 1105, 293, 562, 291, 1710, 281, 1580, 411, 11181, 5130, 299, 51008], "temperature": 0.0, "avg_logprob": -0.1846812919334129, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.0005525812739506364}, {"id": 721, "seek": 513956, "start": 5152.4400000000005, "end": 5157.56, "text": " who's made a whole career out of you know image restoration and super resolution and colorization", "tokens": [51008, 567, 311, 1027, 257, 1379, 3988, 484, 295, 291, 458, 3256, 23722, 293, 1687, 8669, 293, 2017, 2144, 51264], "temperature": 0.0, "avg_logprob": -0.1846812919334129, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.0005525812739506364}, {"id": 722, "seek": 513956, "start": 5157.56, "end": 5164.52, "text": " that is like a big part of his process even now is still like looking at a bunch of images to decide", "tokens": [51264, 300, 307, 411, 257, 955, 644, 295, 702, 1399, 754, 586, 307, 920, 411, 1237, 412, 257, 3840, 295, 5267, 281, 4536, 51612], "temperature": 0.0, "avg_logprob": -0.1846812919334129, "compression_ratio": 1.7572463768115942, "no_speech_prob": 0.0005525812739506364}, {"id": 723, "seek": 516452, "start": 5164.52, "end": 5170.120000000001, "text": " whether something is better rather than relying on these yeah some PhD student yelled at me on", "tokens": [50364, 1968, 746, 307, 1101, 2831, 813, 24140, 322, 613, 1338, 512, 14476, 3107, 38023, 412, 385, 322, 50644], "temperature": 0.0, "avg_logprob": -0.21251164007624354, "compression_ratio": 1.84765625, "no_speech_prob": 0.007805071771144867}, {"id": 724, "seek": 516452, "start": 5170.120000000001, "end": 5174.360000000001, "text": " twitter a few weeks ago for like saying like look at this cool thing our student made look how don't", "tokens": [50644, 21439, 257, 1326, 3259, 2057, 337, 411, 1566, 411, 574, 412, 341, 1627, 551, 527, 3107, 1027, 574, 577, 500, 380, 50856], "temperature": 0.0, "avg_logprob": -0.21251164007624354, "compression_ratio": 1.84765625, "no_speech_prob": 0.007805071771144867}, {"id": 725, "seek": 516452, "start": 5174.360000000001, "end": 5178.6, "text": " they look better and he was like don't you know there's rigorous ways to measure these things", "tokens": [50856, 436, 574, 1101, 293, 415, 390, 411, 500, 380, 291, 458, 456, 311, 29882, 2098, 281, 3481, 613, 721, 51068], "temperature": 0.0, "avg_logprob": -0.21251164007624354, "compression_ratio": 1.84765625, "no_speech_prob": 0.007805071771144867}, {"id": 726, "seek": 516452, "start": 5178.6, "end": 5185.080000000001, "text": " this is not a rigorous approach at all it's like uh PhD students man they got all the answers", "tokens": [51068, 341, 307, 406, 257, 29882, 3109, 412, 439, 309, 311, 411, 2232, 14476, 1731, 587, 436, 658, 439, 264, 6338, 51392], "temperature": 0.0, "avg_logprob": -0.21251164007624354, "compression_ratio": 1.84765625, "no_speech_prob": 0.007805071771144867}, {"id": 727, "seek": 516452, "start": 5186.4400000000005, "end": 5190.040000000001, "text": " can't have a human looking at a picture and deciding if they like it or not that's insane", "tokens": [51460, 393, 380, 362, 257, 1952, 1237, 412, 257, 3036, 293, 17990, 498, 436, 411, 309, 420, 406, 300, 311, 10838, 51640], "temperature": 0.0, "avg_logprob": -0.21251164007624354, "compression_ratio": 1.84765625, "no_speech_prob": 0.007805071771144867}, {"id": 728, "seek": 519004, "start": 5190.6, "end": 5193.8, "text": " well i'm a PhD student i agree though that we should be looking at it so", "tokens": [50392, 731, 741, 478, 257, 14476, 3107, 741, 3986, 1673, 300, 321, 820, 312, 1237, 412, 309, 370, 50552], "temperature": 0.0, "avg_logprob": -0.45611471878854853, "compression_ratio": 1.5693430656934306, "no_speech_prob": 0.00028677465161308646}, {"id": 729, "seek": 519004, "start": 5193.8, "end": 5197.4, "text": " yeah okay some PhD students are better than others that's that's fair enough", "tokens": [50552, 1338, 1392, 512, 14476, 1731, 366, 1101, 813, 2357, 300, 311, 300, 311, 3143, 1547, 50732], "temperature": 0.0, "avg_logprob": -0.45611471878854853, "compression_ratio": 1.5693430656934306, "no_speech_prob": 0.00028677465161308646}, {"id": 730, "seek": 519004, "start": 5203.08, "end": 5203.64, "text": " what's this", "tokens": [51016, 437, 311, 341, 51044], "temperature": 0.0, "avg_logprob": -0.45611471878854853, "compression_ratio": 1.5693430656934306, "no_speech_prob": 0.00028677465161308646}, {"id": 731, "seek": 519004, "start": 5206.2, "end": 5213.64, "text": " oh right okay so talking of cheating let's do that um", "tokens": [51172, 1954, 558, 1392, 370, 1417, 295, 18309, 718, 311, 360, 300, 1105, 51544], "temperature": 0.0, "avg_logprob": -0.45611471878854853, "compression_ratio": 1.5693430656934306, "no_speech_prob": 0.00028677465161308646}, {"id": 732, "seek": 521364, "start": 5214.360000000001, "end": 5214.860000000001, "text": " um", "tokens": [50400, 1105, 50425], "temperature": 0.0, "avg_logprob": -0.23459971469381583, "compression_ratio": 1.3650793650793651, "no_speech_prob": 1.4063914022699464e-05}, {"id": 733, "seek": 521364, "start": 5219.08, "end": 5227.96, "text": " so we're going to do something which is kind of fast ai's favorite trick and has been since we", "tokens": [50636, 370, 321, 434, 516, 281, 360, 746, 597, 307, 733, 295, 2370, 9783, 311, 2954, 4282, 293, 575, 668, 1670, 321, 51080], "temperature": 0.0, "avg_logprob": -0.23459971469381583, "compression_ratio": 1.3650793650793651, "no_speech_prob": 1.4063914022699464e-05}, {"id": 734, "seek": 521364, "start": 5227.96, "end": 5233.88, "text": " first launched which is uh gradually unfreezing pre-trained networks um so", "tokens": [51080, 700, 8730, 597, 307, 2232, 13145, 3971, 701, 8781, 659, 12, 17227, 2001, 9590, 1105, 370, 51376], "temperature": 0.0, "avg_logprob": -0.23459971469381583, "compression_ratio": 1.3650793650793651, "no_speech_prob": 1.4063914022699464e-05}, {"id": 735, "seek": 523388, "start": 5234.04, "end": 5246.2, "text": " so in a sense it seems a bit funny to initialize all of this down path randomly because we already", "tokens": [50372, 370, 294, 257, 2020, 309, 2544, 257, 857, 4074, 281, 5883, 1125, 439, 295, 341, 760, 3100, 16979, 570, 321, 1217, 50980], "temperature": 0.0, "avg_logprob": -0.23892659919206485, "compression_ratio": 1.4274809160305344, "no_speech_prob": 4.450839981018362e-07}, {"id": 736, "seek": 523388, "start": 5246.2, "end": 5251.72, "text": " have a model that's perfectly capable of doing something useful on tiny image net images", "tokens": [50980, 362, 257, 2316, 300, 311, 6239, 8189, 295, 884, 746, 4420, 322, 5870, 3256, 2533, 5267, 51256], "temperature": 0.0, "avg_logprob": -0.23892659919206485, "compression_ratio": 1.4274809160305344, "no_speech_prob": 4.450839981018362e-07}, {"id": 737, "seek": 525172, "start": 5252.68, "end": 5253.320000000001, "text": " which is this", "tokens": [50412, 597, 307, 341, 50444], "temperature": 0.0, "avg_logprob": -0.2518014704927485, "compression_ratio": 1.4273504273504274, "no_speech_prob": 8.936495760281105e-06}, {"id": 738, "seek": 525172, "start": 5256.12, "end": 5264.76, "text": " so yeah what if we um took our unit right and", "tokens": [50584, 370, 1338, 437, 498, 321, 1105, 1890, 527, 4985, 558, 293, 51016], "temperature": 0.0, "avg_logprob": -0.2518014704927485, "compression_ratio": 1.4273504273504274, "no_speech_prob": 8.936495760281105e-06}, {"id": 739, "seek": 525172, "start": 5267.56, "end": 5271.400000000001, "text": " for the model dot start which to remind you", "tokens": [51156, 337, 264, 2316, 5893, 722, 597, 281, 4160, 291, 51348], "temperature": 0.0, "avg_logprob": -0.2518014704927485, "compression_ratio": 1.4273504273504274, "no_speech_prob": 8.936495760281105e-06}, {"id": 740, "seek": 525172, "start": 5275.0, "end": 5280.04, "text": " is the res block right at the front why don't we use the actual", "tokens": [51528, 307, 264, 725, 3461, 558, 412, 264, 1868, 983, 500, 380, 321, 764, 264, 3539, 51780], "temperature": 0.0, "avg_logprob": -0.2518014704927485, "compression_ratio": 1.4273504273504274, "no_speech_prob": 8.936495760281105e-06}, {"id": 741, "seek": 528172, "start": 5282.360000000001, "end": 5289.320000000001, "text": " weights of the pre-trained model and then for each of the bits in the down sampling path", "tokens": [50396, 17443, 295, 264, 659, 12, 17227, 2001, 2316, 293, 550, 337, 1184, 295, 264, 9239, 294, 264, 760, 21179, 3100, 50744], "temperature": 0.0, "avg_logprob": -0.2145379384358724, "compression_ratio": 1.6627906976744187, "no_speech_prob": 1.3925446182838641e-06}, {"id": 742, "seek": 528172, "start": 5290.04, "end": 5296.360000000001, "text": " why don't we use the actual weights that we used for that as well and so this is a useful way to", "tokens": [50780, 983, 500, 380, 321, 764, 264, 3539, 17443, 300, 321, 1143, 337, 300, 382, 731, 293, 370, 341, 307, 257, 4420, 636, 281, 51096], "temperature": 0.0, "avg_logprob": -0.2145379384358724, "compression_ratio": 1.6627906976744187, "no_speech_prob": 1.3925446182838641e-06}, {"id": 743, "seek": 528172, "start": 5296.360000000001, "end": 5309.8, "text": " understand how we can um copy over weights which is that any part of a module an nn.module is itself", "tokens": [51096, 1223, 577, 321, 393, 1105, 5055, 670, 17443, 597, 307, 300, 604, 644, 295, 257, 10088, 364, 297, 77, 13, 8014, 2271, 307, 2564, 51768], "temperature": 0.0, "avg_logprob": -0.2145379384358724, "compression_ratio": 1.6627906976744187, "no_speech_prob": 1.3925446182838641e-06}, {"id": 744, "seek": 530980, "start": 5309.8, "end": 5317.400000000001, "text": " an nn.module an nn.module has a state dict which is a thing you can then call load state dict", "tokens": [50364, 364, 297, 77, 13, 8014, 2271, 364, 297, 77, 13, 8014, 2271, 575, 257, 1785, 12569, 597, 307, 257, 551, 291, 393, 550, 818, 3677, 1785, 12569, 50744], "temperature": 0.0, "avg_logprob": -0.1889662061418806, "compression_ratio": 1.8663366336633664, "no_speech_prob": 6.854308594483882e-06}, {"id": 745, "seek": 530980, "start": 5317.96, "end": 5322.92, "text": " to put it somewhere else so this is going to fill in the whole res block called model.start", "tokens": [50772, 281, 829, 309, 4079, 1646, 370, 341, 307, 516, 281, 2836, 294, 264, 1379, 725, 3461, 1219, 2316, 13, 24419, 51020], "temperature": 0.0, "avg_logprob": -0.1889662061418806, "compression_ratio": 1.8663366336633664, "no_speech_prob": 6.854308594483882e-06}, {"id": 746, "seek": 530980, "start": 5323.72, "end": 5330.28, "text": " with the whole res block which is p model zero so here's how we can copy across yeah that starting", "tokens": [51060, 365, 264, 1379, 725, 3461, 597, 307, 280, 2316, 4018, 370, 510, 311, 577, 321, 393, 5055, 2108, 1338, 300, 2891, 51388], "temperature": 0.0, "avg_logprob": -0.1889662061418806, "compression_ratio": 1.8663366336633664, "no_speech_prob": 6.854308594483882e-06}, {"id": 747, "seek": 530980, "start": 5330.28, "end": 5334.68, "text": " one and then all the down blocks are going to have the rest of it so this is basically going", "tokens": [51388, 472, 293, 550, 439, 264, 760, 8474, 366, 516, 281, 362, 264, 1472, 295, 309, 370, 341, 307, 1936, 516, 51608], "temperature": 0.0, "avg_logprob": -0.1889662061418806, "compression_ratio": 1.8663366336633664, "no_speech_prob": 6.854308594483882e-06}, {"id": 748, "seek": 533468, "start": 5334.68, "end": 5339.72, "text": " to copy into our model rather than having random weights we're going to have all the weights from", "tokens": [50364, 281, 5055, 666, 527, 2316, 2831, 813, 1419, 4974, 17443, 321, 434, 516, 281, 362, 439, 264, 17443, 490, 50616], "temperature": 0.0, "avg_logprob": -0.19881104887201545, "compression_ratio": 2.0157068062827226, "no_speech_prob": 2.796904846036341e-05}, {"id": 749, "seek": 533468, "start": 5340.84, "end": 5350.52, "text": " our pre-trained model um and then since they're they're good at doing something they're not good", "tokens": [50672, 527, 659, 12, 17227, 2001, 2316, 1105, 293, 550, 1670, 436, 434, 436, 434, 665, 412, 884, 746, 436, 434, 406, 665, 51156], "temperature": 0.0, "avg_logprob": -0.19881104887201545, "compression_ratio": 2.0157068062827226, "no_speech_prob": 2.796904846036341e-05}, {"id": 750, "seek": 533468, "start": 5350.52, "end": 5355.96, "text": " at doing super resolution but they're good at doing something why don't we assume that they're", "tokens": [51156, 412, 884, 1687, 8669, 457, 436, 434, 665, 412, 884, 746, 983, 500, 380, 321, 6552, 300, 436, 434, 51428], "temperature": 0.0, "avg_logprob": -0.19881104887201545, "compression_ratio": 2.0157068062827226, "no_speech_prob": 2.796904846036341e-05}, {"id": 751, "seek": 533468, "start": 5355.96, "end": 5362.12, "text": " good at doing super resolution so turn off requires grad and so what that means if we now train", "tokens": [51428, 665, 412, 884, 1687, 8669, 370, 1261, 766, 7029, 2771, 293, 370, 437, 300, 1355, 498, 321, 586, 3847, 51736], "temperature": 0.0, "avg_logprob": -0.19881104887201545, "compression_ratio": 2.0157068062827226, "no_speech_prob": 2.796904846036341e-05}, {"id": 752, "seek": 536212, "start": 5362.76, "end": 5366.2, "text": " it's not going to update any of the parameters in the down block", "tokens": [50396, 309, 311, 406, 516, 281, 5623, 604, 295, 264, 9834, 294, 264, 760, 3461, 50568], "temperature": 0.0, "avg_logprob": -0.25072641083688446, "compression_ratio": 1.4883720930232558, "no_speech_prob": 1.0953060154861305e-05}, {"id": 753, "seek": 536212, "start": 5366.92, "end": 5371.4, "text": " i guess i should have actually done model.start requires grad as false too now i think about it", "tokens": [50604, 741, 2041, 741, 820, 362, 767, 1096, 2316, 13, 24419, 7029, 2771, 382, 7908, 886, 586, 741, 519, 466, 309, 50828], "temperature": 0.0, "avg_logprob": -0.25072641083688446, "compression_ratio": 1.4883720930232558, "no_speech_prob": 1.0953060154861305e-05}, {"id": 754, "seek": 536212, "start": 5373.24, "end": 5380.84, "text": " and so this is uh the the classic uh fine-tune approach from fast.ai the library we're going to", "tokens": [50920, 293, 370, 341, 307, 2232, 264, 264, 7230, 2232, 2489, 12, 83, 2613, 3109, 490, 2370, 13, 1301, 264, 6405, 321, 434, 516, 281, 51300], "temperature": 0.0, "avg_logprob": -0.25072641083688446, "compression_ratio": 1.4883720930232558, "no_speech_prob": 1.0953060154861305e-05}, {"id": 755, "seek": 538084, "start": 5380.84, "end": 5391.8, "text": " do one epoch of just the upsampling path and that gets us to a loss of 255 now our", "tokens": [50364, 360, 472, 30992, 339, 295, 445, 264, 15497, 335, 11970, 3100, 293, 300, 2170, 505, 281, 257, 4470, 295, 3552, 20, 586, 527, 50912], "temperature": 0.0, "avg_logprob": -0.20249299860712308, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.0004442146164365113}, {"id": 756, "seek": 538084, "start": 5393.0, "end": 5399.64, "text": " loss function hasn't changed so that's totally comparable so previously our one epoch was 385", "tokens": [50972, 4470, 2445, 6132, 380, 3105, 370, 300, 311, 3879, 25323, 370, 8046, 527, 472, 30992, 339, 390, 12843, 20, 51304], "temperature": 0.0, "avg_logprob": -0.20249299860712308, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.0004442146164365113}, {"id": 757, "seek": 538084, "start": 5400.52, "end": 5405.88, "text": " and in fact after one epoch with frozen weights for the down path we've beaten", "tokens": [51348, 293, 294, 1186, 934, 472, 30992, 339, 365, 12496, 17443, 337, 264, 760, 3100, 321, 600, 17909, 51616], "temperature": 0.0, "avg_logprob": -0.20249299860712308, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.0004442146164365113}, {"id": 758, "seek": 540588, "start": 5406.52, "end": 5415.08, "text": " this now this is in a sense totally cheating but in a sense it's totally not it's totally", "tokens": [50396, 341, 586, 341, 307, 294, 257, 2020, 3879, 18309, 457, 294, 257, 2020, 309, 311, 3879, 406, 309, 311, 3879, 50824], "temperature": 0.0, "avg_logprob": -0.20713461599042338, "compression_ratio": 1.7615894039735098, "no_speech_prob": 5.862787475052755e-06}, {"id": 759, "seek": 540588, "start": 5415.08, "end": 5422.92, "text": " cheating because the thing we're trying to do is to generate for the perceptual loss", "tokens": [50824, 18309, 570, 264, 551, 321, 434, 1382, 281, 360, 307, 281, 8460, 337, 264, 43276, 901, 4470, 51216], "temperature": 0.0, "avg_logprob": -0.20713461599042338, "compression_ratio": 1.7615894039735098, "no_speech_prob": 5.862787475052755e-06}, {"id": 760, "seek": 540588, "start": 5422.92, "end": 5432.76, "text": " intermediate layer activations which are the same as this and so we're literally using that", "tokens": [51216, 19376, 4583, 2430, 763, 597, 366, 264, 912, 382, 341, 293, 370, 321, 434, 3736, 1228, 300, 51708], "temperature": 0.0, "avg_logprob": -0.20713461599042338, "compression_ratio": 1.7615894039735098, "no_speech_prob": 5.862787475052755e-06}, {"id": 761, "seek": 543276, "start": 5432.76, "end": 5440.76, "text": " to create intermediate layer activations so obviously that's going to work but why is it", "tokens": [50364, 281, 1884, 19376, 4583, 2430, 763, 370, 2745, 300, 311, 516, 281, 589, 457, 983, 307, 309, 50764], "temperature": 0.0, "avg_logprob": -0.19584236145019532, "compression_ratio": 1.7844036697247707, "no_speech_prob": 1.4285486940934788e-05}, {"id": 762, "seek": 543276, "start": 5440.76, "end": 5447.08, "text": " okay to be cheating well because that's actually what we want like to be able to do super resolution", "tokens": [50764, 1392, 281, 312, 18309, 731, 570, 300, 311, 767, 437, 321, 528, 411, 281, 312, 1075, 281, 360, 1687, 8669, 51080], "temperature": 0.0, "avg_logprob": -0.19584236145019532, "compression_ratio": 1.7844036697247707, "no_speech_prob": 1.4285486940934788e-05}, {"id": 763, "seek": 543276, "start": 5447.08, "end": 5453.24, "text": " we need something that can like have it recognize there's an eye here so we already have something", "tokens": [51080, 321, 643, 746, 300, 393, 411, 362, 309, 5521, 456, 311, 364, 3313, 510, 370, 321, 1217, 362, 746, 51388], "temperature": 0.0, "avg_logprob": -0.19584236145019532, "compression_ratio": 1.7844036697247707, "no_speech_prob": 1.4285486940934788e-05}, {"id": 764, "seek": 543276, "start": 5453.24, "end": 5458.2, "text": " that knows that there's an eye there and in fact interestingly this thing trained a lot more quickly", "tokens": [51388, 300, 3255, 300, 456, 311, 364, 3313, 456, 293, 294, 1186, 25873, 341, 551, 8895, 257, 688, 544, 2661, 51636], "temperature": 0.0, "avg_logprob": -0.19584236145019532, "compression_ratio": 1.7844036697247707, "no_speech_prob": 1.4285486940934788e-05}, {"id": 765, "seek": 545820, "start": 5458.28, "end": 5466.84, "text": " than this thing and it turns out it's better at super resolution than that thing even though it", "tokens": [50368, 813, 341, 551, 293, 309, 4523, 484, 309, 311, 1101, 412, 1687, 8669, 813, 300, 551, 754, 1673, 309, 50796], "temperature": 0.0, "avg_logprob": -0.22032584863550522, "compression_ratio": 1.7393939393939395, "no_speech_prob": 4.785086275660433e-06}, {"id": 766, "seek": 545820, "start": 5466.84, "end": 5471.88, "text": " wasn't trained to do super resolution and i think that's because the signal which is just like", "tokens": [50796, 2067, 380, 8895, 281, 360, 1687, 8669, 293, 741, 519, 300, 311, 570, 264, 6358, 597, 307, 445, 411, 51048], "temperature": 0.0, "avg_logprob": -0.22032584863550522, "compression_ratio": 1.7393939393939395, "no_speech_prob": 4.785086275660433e-06}, {"id": 767, "seek": 545820, "start": 5472.84, "end": 5482.36, "text": " what is this is a really simple signal to use so yeah so we do that and then we can basically go", "tokens": [51096, 437, 307, 341, 307, 257, 534, 2199, 6358, 281, 764, 370, 1338, 370, 321, 360, 300, 293, 550, 321, 393, 1936, 352, 51572], "temperature": 0.0, "avg_logprob": -0.22032584863550522, "compression_ratio": 1.7393939393939395, "no_speech_prob": 4.785086275660433e-06}, {"id": 768, "seek": 548236, "start": 5482.36, "end": 5487.0, "text": " through and set requires grad equals true again and so the basic idea being here that", "tokens": [50364, 807, 293, 992, 7029, 2771, 6915, 2074, 797, 293, 370, 264, 3875, 1558, 885, 510, 300, 50596], "temperature": 0.0, "avg_logprob": -0.1897361423658288, "compression_ratio": 1.823293172690763, "no_speech_prob": 7.484481466235593e-05}, {"id": 769, "seek": 548236, "start": 5488.5199999999995, "end": 5494.2, "text": " yeah when you've got a bunch of random weights which is the whole upsampling path and a bunch", "tokens": [50672, 1338, 562, 291, 600, 658, 257, 3840, 295, 4974, 17443, 597, 307, 264, 1379, 15497, 335, 11970, 3100, 293, 257, 3840, 50956], "temperature": 0.0, "avg_logprob": -0.1897361423658288, "compression_ratio": 1.823293172690763, "no_speech_prob": 7.484481466235593e-05}, {"id": 770, "seek": 548236, "start": 5494.2, "end": 5499.32, "text": " of pre-trained weights the downsampling path don't start then fine-tuning the whole thing", "tokens": [50956, 295, 659, 12, 17227, 2001, 17443, 264, 760, 19988, 11970, 3100, 500, 380, 722, 550, 2489, 12, 83, 37726, 264, 1379, 551, 51212], "temperature": 0.0, "avg_logprob": -0.1897361423658288, "compression_ratio": 1.823293172690763, "no_speech_prob": 7.484481466235593e-05}, {"id": 771, "seek": 548236, "start": 5500.2, "end": 5505.0, "text": " because at the start it's going to be crap you know so and so just train the random weights", "tokens": [51256, 570, 412, 264, 722, 309, 311, 516, 281, 312, 12426, 291, 458, 370, 293, 370, 445, 3847, 264, 4974, 17443, 51496], "temperature": 0.0, "avg_logprob": -0.1897361423658288, "compression_ratio": 1.823293172690763, "no_speech_prob": 7.484481466235593e-05}, {"id": 772, "seek": 548236, "start": 5505.719999999999, "end": 5512.04, "text": " for at least an epoch and then set everything to unfrozen and then we'll do our 20 epochs on", "tokens": [51532, 337, 412, 1935, 364, 30992, 339, 293, 550, 992, 1203, 281, 3971, 340, 2904, 293, 550, 321, 603, 360, 527, 945, 30992, 28346, 322, 51848], "temperature": 0.0, "avg_logprob": -0.1897361423658288, "compression_ratio": 1.823293172690763, "no_speech_prob": 7.484481466235593e-05}, {"id": 773, "seek": 551204, "start": 5512.04, "end": 5523.4, "text": " the whole thing and so we go from 255 to 249 207 198 so it's improved a lot", "tokens": [50364, 264, 1379, 551, 293, 370, 321, 352, 490, 3552, 20, 281, 4022, 24, 945, 22, 6375, 370, 309, 311, 9689, 257, 688, 50932], "temperature": 0.0, "avg_logprob": -0.2695835500523664, "compression_ratio": 1.5857988165680474, "no_speech_prob": 5.3910320275463164e-05}, {"id": 774, "seek": 551204, "start": 5526.6, "end": 5534.44, "text": " so to clarify uh with the um with using these weights and comparing that to the perceptual loss", "tokens": [51092, 370, 281, 17594, 2232, 365, 264, 1105, 365, 1228, 613, 17443, 293, 15763, 300, 281, 264, 43276, 901, 4470, 51484], "temperature": 0.0, "avg_logprob": -0.2695835500523664, "compression_ratio": 1.5857988165680474, "no_speech_prob": 5.3910320275463164e-05}, {"id": 775, "seek": 551204, "start": 5534.44, "end": 5540.36, "text": " the perceptual loss is looking at the up sample data or the uh super resolution image as well as", "tokens": [51484, 264, 43276, 901, 4470, 307, 1237, 412, 264, 493, 6889, 1412, 420, 264, 2232, 1687, 8669, 3256, 382, 731, 382, 51780], "temperature": 0.0, "avg_logprob": -0.2695835500523664, "compression_ratio": 1.5857988165680474, "no_speech_prob": 5.3910320275463164e-05}, {"id": 776, "seek": 554036, "start": 5541.0, "end": 5545.24, "text": " incorporating the weights that's for the downsampling path and so that's looking at", "tokens": [50396, 33613, 264, 17443, 300, 311, 337, 264, 760, 19988, 11970, 3100, 293, 370, 300, 311, 1237, 412, 50608], "temperature": 0.0, "avg_logprob": -0.18607987079423727, "compression_ratio": 1.7971698113207548, "no_speech_prob": 8.349410200025886e-05}, {"id": 777, "seek": 554036, "start": 5545.24, "end": 5551.5599999999995, "text": " i guess the original uh downgraded version of the image although we are just adding them so if you", "tokens": [50608, 741, 2041, 264, 3380, 2232, 760, 7165, 292, 3037, 295, 264, 3256, 4878, 321, 366, 445, 5127, 552, 370, 498, 291, 50924], "temperature": 0.0, "avg_logprob": -0.18607987079423727, "compression_ratio": 1.7971698113207548, "no_speech_prob": 8.349410200025886e-05}, {"id": 778, "seek": 554036, "start": 5551.5599999999995, "end": 5558.5199999999995, "text": " have zeros in the upsampling path that it's going to be the same so it is very easy for it to get", "tokens": [50924, 362, 35193, 294, 264, 15497, 335, 11970, 3100, 300, 309, 311, 516, 281, 312, 264, 912, 370, 309, 307, 588, 1858, 337, 309, 281, 483, 51272], "temperature": 0.0, "avg_logprob": -0.18607987079423727, "compression_ratio": 1.7971698113207548, "no_speech_prob": 8.349410200025886e-05}, {"id": 779, "seek": 554036, "start": 5558.5199999999995, "end": 5568.28, "text": " the correct activations in the upsampling path um and then yeah i mean then it's kind of a bit weird", "tokens": [51272, 264, 3006, 2430, 763, 294, 264, 15497, 335, 11970, 3100, 1105, 293, 550, 1338, 741, 914, 550, 309, 311, 733, 295, 257, 857, 3657, 51760], "temperature": 0.0, "avg_logprob": -0.18607987079423727, "compression_ratio": 1.7971698113207548, "no_speech_prob": 8.349410200025886e-05}, {"id": 780, "seek": 556828, "start": 5568.28, "end": 5571.639999999999, "text": " because it goes all the way back to the top creates the image and then goes into the class", "tokens": [50364, 570, 309, 1709, 439, 264, 636, 646, 281, 264, 1192, 7829, 264, 3256, 293, 550, 1709, 666, 264, 1508, 50532], "temperature": 0.0, "avg_logprob": -0.1774190306663513, "compression_ratio": 1.694736842105263, "no_speech_prob": 1.3210868928581476e-05}, {"id": 781, "seek": 556828, "start": 5571.639999999999, "end": 5579.5599999999995, "text": " of c model the classifier again um but i think it's going to create basically the same activations", "tokens": [50532, 295, 269, 2316, 264, 1508, 9902, 797, 1105, 457, 741, 519, 309, 311, 516, 281, 1884, 1936, 264, 912, 2430, 763, 50928], "temperature": 0.0, "avg_logprob": -0.1774190306663513, "compression_ratio": 1.694736842105263, "no_speech_prob": 1.3210868928581476e-05}, {"id": 782, "seek": 556828, "start": 5580.92, "end": 5585.5599999999995, "text": " it's a bit confusing and weird um so yeah i mean it's not totally cheating but it's um", "tokens": [50996, 309, 311, 257, 857, 13181, 293, 3657, 1105, 370, 1338, 741, 914, 309, 311, 406, 3879, 18309, 457, 309, 311, 1105, 51228], "temperature": 0.0, "avg_logprob": -0.1774190306663513, "compression_ratio": 1.694736842105263, "no_speech_prob": 1.3210868928581476e-05}, {"id": 783, "seek": 556828, "start": 5587.48, "end": 5589.48, "text": " it's certainly a much easier problem to solve", "tokens": [51324, 309, 311, 3297, 257, 709, 3571, 1154, 281, 5039, 51424], "temperature": 0.0, "avg_logprob": -0.1774190306663513, "compression_ratio": 1.694736842105263, "no_speech_prob": 1.3210868928581476e-05}, {"id": 784, "seek": 558948, "start": 5589.5599999999995, "end": 5598.599999999999, "text": " yeah um okay so let's get our results again so there's our inputs", "tokens": [50368, 1338, 1105, 1392, 370, 718, 311, 483, 527, 3542, 797, 370, 456, 311, 527, 15743, 50820], "temperature": 0.0, "avg_logprob": -0.3079807032709536, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.0005354608874768019}, {"id": 785, "seek": 558948, "start": 5601.5599999999995, "end": 5609.08, "text": " yeah so that's looking pretty impressive so the kid has a yeah definitely looks", "tokens": [50968, 1338, 370, 300, 311, 1237, 1238, 8992, 370, 264, 1636, 575, 257, 1338, 2138, 1542, 51344], "temperature": 0.0, "avg_logprob": -0.3079807032709536, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.0005354608874768019}, {"id": 786, "seek": 558948, "start": 5610.36, "end": 5616.28, "text": " pretty reasonable now um car looks pretty reasonable", "tokens": [51408, 1238, 10585, 586, 1105, 1032, 1542, 1238, 10585, 51704], "temperature": 0.0, "avg_logprob": -0.3079807032709536, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.0005354608874768019}, {"id": 787, "seek": 561628, "start": 5616.679999999999, "end": 5621.4, "text": " we still don't have eyes for the koala such as life but definitely the background textures look", "tokens": [50384, 321, 920, 500, 380, 362, 2575, 337, 264, 8384, 5159, 1270, 382, 993, 457, 2138, 264, 3678, 24501, 574, 50620], "temperature": 0.0, "avg_logprob": -0.35082523639385516, "compression_ratio": 1.7015706806282722, "no_speech_prob": 6.6432312451070175e-06}, {"id": 788, "seek": 561628, "start": 5621.4, "end": 5630.599999999999, "text": " way better um the candy store looks less much better than it did um medicine looks a lot", "tokens": [50620, 636, 1101, 1105, 264, 11237, 3531, 1542, 1570, 709, 1101, 813, 309, 630, 1105, 7195, 1542, 257, 688, 51080], "temperature": 0.0, "avg_logprob": -0.35082523639385516, "compression_ratio": 1.7015706806282722, "no_speech_prob": 6.6432312451070175e-06}, {"id": 789, "seek": 561628, "start": 5630.599999999999, "end": 5635.08, "text": " better than it did so yeah it's really i think it looks great", "tokens": [51080, 1101, 813, 309, 630, 370, 1338, 309, 311, 534, 741, 519, 309, 1542, 869, 51304], "temperature": 0.0, "avg_logprob": -0.35082523639385516, "compression_ratio": 1.7015706806282722, "no_speech_prob": 6.6432312451070175e-06}, {"id": 790, "seek": 561628, "start": 5638.28, "end": 5643.88, "text": " okay so then we can get better still this is not part of the original unit but", "tokens": [51464, 1392, 370, 550, 321, 393, 483, 1101, 920, 341, 307, 406, 644, 295, 264, 3380, 4985, 457, 51744], "temperature": 0.0, "avg_logprob": -0.35082523639385516, "compression_ratio": 1.7015706806282722, "no_speech_prob": 6.6432312451070175e-06}, {"id": 791, "seek": 564388, "start": 5644.68, "end": 5652.68, "text": " you know making better models is often about like where can we squeeze in more computation", "tokens": [50404, 291, 458, 1455, 1101, 5245, 307, 2049, 466, 411, 689, 393, 321, 13578, 294, 544, 24903, 50804], "temperature": 0.0, "avg_logprob": -0.24306594757806688, "compression_ratio": 1.7757009345794392, "no_speech_prob": 2.0145556845818646e-05}, {"id": 792, "seek": 564388, "start": 5653.32, "end": 5657.8, "text": " give it opportunities to do things and like there's nothing particularly that says that this", "tokens": [50836, 976, 309, 4786, 281, 360, 721, 293, 411, 456, 311, 1825, 4098, 300, 1619, 300, 341, 51060], "temperature": 0.0, "avg_logprob": -0.24306594757806688, "compression_ratio": 1.7757009345794392, "no_speech_prob": 2.0145556845818646e-05}, {"id": 793, "seek": 564388, "start": 5657.8, "end": 5663.24, "text": " downsampling thing is exactly the right thing you need here right it's being used for two things one", "tokens": [51060, 760, 19988, 11970, 551, 307, 2293, 264, 558, 551, 291, 643, 510, 558, 309, 311, 885, 1143, 337, 732, 721, 472, 51332], "temperature": 0.0, "avg_logprob": -0.24306594757806688, "compression_ratio": 1.7757009345794392, "no_speech_prob": 2.0145556845818646e-05}, {"id": 794, "seek": 564388, "start": 5663.24, "end": 5669.24, "text": " is this conv and one is this conv but those are two different things and so it's kind of having", "tokens": [51332, 307, 341, 3754, 293, 472, 307, 341, 3754, 457, 729, 366, 732, 819, 721, 293, 370, 309, 311, 733, 295, 1419, 51632], "temperature": 0.0, "avg_logprob": -0.24306594757806688, "compression_ratio": 1.7757009345794392, "no_speech_prob": 2.0145556845818646e-05}, {"id": 795, "seek": 566924, "start": 5669.24, "end": 5675.5599999999995, "text": " to like learn to squeeze both purposes into one thing so i had this idea probably i'm sure lots of", "tokens": [50364, 281, 411, 1466, 281, 13578, 1293, 9932, 666, 472, 551, 370, 741, 632, 341, 1558, 1391, 741, 478, 988, 3195, 295, 50680], "temperature": 0.0, "avg_logprob": -0.2076074558755626, "compression_ratio": 1.7641509433962264, "no_speech_prob": 7.031165296211839e-05}, {"id": 796, "seek": 566924, "start": 5675.5599999999995, "end": 5680.5199999999995, "text": " people had this idea but um whatever i had this idea which is why don't we put some res blocks", "tokens": [50680, 561, 632, 341, 1558, 457, 1105, 2035, 741, 632, 341, 1558, 597, 307, 983, 500, 380, 321, 829, 512, 725, 8474, 50928], "temperature": 0.0, "avg_logprob": -0.2076074558755626, "compression_ratio": 1.7641509433962264, "no_speech_prob": 7.031165296211839e-05}, {"id": 797, "seek": 566924, "start": 5681.24, "end": 5689.0, "text": " in here which i called cross connections or cross cons so i decided that a cross conv", "tokens": [50964, 294, 510, 597, 741, 1219, 3278, 9271, 420, 3278, 1014, 370, 741, 3047, 300, 257, 3278, 3754, 51352], "temperature": 0.0, "avg_logprob": -0.2076074558755626, "compression_ratio": 1.7641509433962264, "no_speech_prob": 7.031165296211839e-05}, {"id": 798, "seek": 566924, "start": 5689.0, "end": 5698.84, "text": " is going to be just a res block followed by a conv um and so the unit i just copied and pasted", "tokens": [51352, 307, 516, 281, 312, 445, 257, 725, 3461, 6263, 538, 257, 3754, 1105, 293, 370, 264, 4985, 741, 445, 25365, 293, 1791, 292, 51844], "temperature": 0.0, "avg_logprob": -0.2076074558755626, "compression_ratio": 1.7641509433962264, "no_speech_prob": 7.031165296211839e-05}, {"id": 799, "seek": 569884, "start": 5698.84, "end": 5704.360000000001, "text": " but now as well as the downs i've also got crosses and so the crosses are cross cons", "tokens": [50364, 457, 586, 382, 731, 382, 264, 21554, 741, 600, 611, 658, 28467, 293, 370, 264, 28467, 366, 3278, 1014, 50640], "temperature": 0.0, "avg_logprob": -0.2444936247432933, "compression_ratio": 1.7450980392156863, "no_speech_prob": 4.222812549414812e-06}, {"id": 800, "seek": 569884, "start": 5705.64, "end": 5714.68, "text": " um so now um rather than just adding the layer i add the cross conv applied to the layer", "tokens": [50704, 1105, 370, 586, 1105, 2831, 813, 445, 5127, 264, 4583, 741, 909, 264, 3278, 416, 85, 6456, 281, 264, 4583, 51156], "temperature": 0.0, "avg_logprob": -0.2444936247432933, "compression_ratio": 1.7450980392156863, "no_speech_prob": 4.222812549414812e-06}, {"id": 801, "seek": 569884, "start": 5716.28, "end": 5722.360000000001, "text": " um yeah i really should have added a cross con for this one as well now i think about it this", "tokens": [51236, 1105, 1338, 741, 534, 820, 362, 3869, 257, 3278, 416, 337, 341, 472, 382, 731, 586, 741, 519, 466, 309, 341, 51540], "temperature": 0.0, "avg_logprob": -0.2444936247432933, "compression_ratio": 1.7450980392156863, "no_speech_prob": 4.222812549414812e-06}, {"id": 802, "seek": 572236, "start": 5722.36, "end": 5730.04, "text": " is probably the one that wants it the most oh well never mind another time um okay so now yeah", "tokens": [50364, 307, 1391, 264, 472, 300, 2738, 309, 264, 881, 1954, 731, 1128, 1575, 1071, 565, 1105, 1392, 370, 586, 1338, 50748], "temperature": 0.0, "avg_logprob": -0.22218108543982873, "compression_ratio": 1.611764705882353, "no_speech_prob": 3.319782263133675e-05}, {"id": 803, "seek": 572236, "start": 5730.04, "end": 5737.48, "text": " again we can definitely compare loss functions this is 198 so everything else was the same", "tokens": [50748, 797, 321, 393, 2138, 6794, 4470, 6828, 341, 307, 6375, 370, 1203, 1646, 390, 264, 912, 51120], "temperature": 0.0, "avg_logprob": -0.22218108543982873, "compression_ratio": 1.611764705882353, "no_speech_prob": 3.319782263133675e-05}, {"id": 804, "seek": 572236, "start": 5738.44, "end": 5742.2, "text": " so i did the same thing of because you know the downsampling is the same so we can still", "tokens": [51168, 370, 741, 630, 264, 912, 551, 295, 570, 291, 458, 264, 760, 19988, 11970, 307, 264, 912, 370, 321, 393, 920, 51356], "temperature": 0.0, "avg_logprob": -0.22218108543982873, "compression_ratio": 1.611764705882353, "no_speech_prob": 3.319782263133675e-05}, {"id": 805, "seek": 574220, "start": 5743.0, "end": 5745.96, "text": " copy in the state dict requires grad", "tokens": [50404, 5055, 294, 264, 1785, 12569, 7029, 2771, 50552], "temperature": 0.0, "avg_logprob": -0.2057781219482422, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.00018809759058058262}, {"id": 806, "seek": 574220, "start": 5748.5199999999995, "end": 5755.08, "text": " and it's better 189 quite a lot better really because you know this is these are hard to get", "tokens": [50680, 293, 309, 311, 1101, 2443, 24, 1596, 257, 688, 1101, 534, 570, 291, 458, 341, 307, 613, 366, 1152, 281, 483, 51008], "temperature": 0.0, "avg_logprob": -0.2057781219482422, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.00018809759058058262}, {"id": 807, "seek": 574220, "start": 5755.08, "end": 5762.84, "text": " improvements uh let's see if we can notice anything hey look it's got an eye just", "tokens": [51008, 13797, 2232, 718, 311, 536, 498, 321, 393, 3449, 1340, 4177, 574, 309, 311, 658, 364, 3313, 445, 51396], "temperature": 0.0, "avg_logprob": -0.2057781219482422, "compression_ratio": 1.4256756756756757, "no_speech_prob": 0.00018809759058058262}, {"id": 808, "seek": 576284, "start": 5763.08, "end": 5772.2, "text": " yeah so how about that um at this point it's almost quite difficult to see whether it's", "tokens": [50376, 1338, 370, 577, 466, 300, 1105, 412, 341, 935, 309, 311, 1920, 1596, 2252, 281, 536, 1968, 309, 311, 50832], "temperature": 0.0, "avg_logprob": -0.2944201741899763, "compression_ratio": 1.5179856115107915, "no_speech_prob": 0.0004044666711706668}, {"id": 809, "seek": 576284, "start": 5772.2, "end": 5776.68, "text": " an improvement or not but the fact there's a bit of an eye on the koala i think is encouraging", "tokens": [50832, 364, 10444, 420, 406, 457, 264, 1186, 456, 311, 257, 857, 295, 364, 3313, 322, 264, 8384, 5159, 741, 519, 307, 14580, 51056], "temperature": 0.0, "avg_logprob": -0.2944201741899763, "compression_ratio": 1.5179856115107915, "no_speech_prob": 0.0004044666711706668}, {"id": 810, "seek": 576284, "start": 5780.76, "end": 5786.76, "text": " yeah so that's our super res", "tokens": [51260, 1338, 370, 300, 311, 527, 1687, 725, 51560], "temperature": 0.0, "avg_logprob": -0.2944201741899763, "compression_ratio": 1.5179856115107915, "no_speech_prob": 0.0004044666711706668}, {"id": 811, "seek": 578676, "start": 5787.08, "end": 5790.92, "text": " uh oh man", "tokens": [50380, 2232, 1954, 587, 50572], "temperature": 0.0, "avg_logprob": -0.23436551174875034, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.0016742461593821645}, {"id": 812, "seek": 578676, "start": 5793.16, "end": 5794.68, "text": " the bad news is we're out of time", "tokens": [50684, 264, 1578, 2583, 307, 321, 434, 484, 295, 565, 50760], "temperature": 0.0, "avg_logprob": -0.23436551174875034, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.0016742461593821645}, {"id": 813, "seek": 578676, "start": 5797.08, "end": 5797.58, "text": " okay", "tokens": [50880, 1392, 50905], "temperature": 0.0, "avg_logprob": -0.23436551174875034, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.0016742461593821645}, {"id": 814, "seek": 578676, "start": 5800.280000000001, "end": 5803.0, "text": " we didn't promise to do diffusion unit this lesson so", "tokens": [51040, 321, 994, 380, 6228, 281, 360, 25242, 4985, 341, 6898, 370, 51176], "temperature": 0.0, "avg_logprob": -0.23436551174875034, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.0016742461593821645}, {"id": 815, "seek": 578676, "start": 5806.2, "end": 5813.08, "text": " we built a unit we built a unit yes we did and it's and we did super resolution with it and it", "tokens": [51336, 321, 3094, 257, 4985, 321, 3094, 257, 4985, 2086, 321, 630, 293, 309, 311, 293, 321, 630, 1687, 8669, 365, 309, 293, 309, 51680], "temperature": 0.0, "avg_logprob": -0.23436551174875034, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.0016742461593821645}, {"id": 816, "seek": 581308, "start": 5813.08, "end": 5821.0, "text": " looks pretty good so um i gotta admit i haven't thought about like exercises for people to do what", "tokens": [50364, 1542, 1238, 665, 370, 1105, 741, 3428, 9796, 741, 2378, 380, 1194, 466, 411, 11900, 337, 561, 281, 360, 437, 50760], "temperature": 0.0, "avg_logprob": -0.24278524552268543, "compression_ratio": 1.8634146341463416, "no_speech_prob": 0.005906933918595314}, {"id": 817, "seek": 581308, "start": 5821.0, "end": 5827.4, "text": " would be useful things for people to try with like maybe they could create a unit they could try and", "tokens": [50760, 576, 312, 4420, 721, 337, 561, 281, 853, 365, 411, 1310, 436, 727, 1884, 257, 4985, 436, 727, 853, 293, 51080], "temperature": 0.0, "avg_logprob": -0.24278524552268543, "compression_ratio": 1.8634146341463416, "no_speech_prob": 0.005906933918595314}, {"id": 818, "seek": 581308, "start": 5827.4, "end": 5833.16, "text": " learn about segmentation create a unit for segmentation or oh you know you can create", "tokens": [51080, 1466, 466, 9469, 399, 1884, 257, 4985, 337, 9469, 399, 420, 1954, 291, 458, 291, 393, 1884, 51368], "temperature": 0.0, "avg_logprob": -0.24278524552268543, "compression_ratio": 1.8634146341463416, "no_speech_prob": 0.005906933918595314}, {"id": 819, "seek": 581308, "start": 5833.16, "end": 5838.36, "text": " there are a couple points where you well i was just gonna say there were a couple points we said", "tokens": [51368, 456, 366, 257, 1916, 2793, 689, 291, 731, 741, 390, 445, 799, 584, 456, 645, 257, 1916, 2793, 321, 848, 51628], "temperature": 0.0, "avg_logprob": -0.24278524552268543, "compression_ratio": 1.8634146341463416, "no_speech_prob": 0.005906933918595314}, {"id": 820, "seek": 583836, "start": 5838.36, "end": 5842.5199999999995, "text": " oh i should have tried this you should have tried that i think that's obviously you know", "tokens": [50364, 1954, 741, 820, 362, 3031, 341, 291, 820, 362, 3031, 300, 741, 519, 300, 311, 2745, 291, 458, 50572], "temperature": 0.0, "avg_logprob": -0.22250799699263138, "compression_ratio": 1.982532751091703, "no_speech_prob": 0.003647597972303629}, {"id": 821, "seek": 583836, "start": 5843.4, "end": 5848.599999999999, "text": " yeah basically yeah i think that's a obviously a good next step i was gonna say um style transfer", "tokens": [50616, 1338, 1936, 1338, 741, 519, 300, 311, 257, 2745, 257, 665, 958, 1823, 741, 390, 799, 584, 1105, 3758, 5003, 50876], "temperature": 0.0, "avg_logprob": -0.22250799699263138, "compression_ratio": 1.982532751091703, "no_speech_prob": 0.003647597972303629}, {"id": 822, "seek": 583836, "start": 5849.24, "end": 5853.08, "text": " is a good idea to do i think with a unit so style transfer you can actually", "tokens": [50908, 307, 257, 665, 1558, 281, 360, 741, 519, 365, 257, 4985, 370, 3758, 5003, 291, 393, 767, 51100], "temperature": 0.0, "avg_logprob": -0.22250799699263138, "compression_ratio": 1.982532751091703, "no_speech_prob": 0.003647597972303629}, {"id": 823, "seek": 583836, "start": 5853.88, "end": 5859.88, "text": " um set up a loss function so that you can create a unit that learns to create images that look like", "tokens": [51140, 1105, 992, 493, 257, 4470, 2445, 370, 300, 291, 393, 1884, 257, 4985, 300, 27152, 281, 1884, 5267, 300, 574, 411, 51440], "temperature": 0.0, "avg_logprob": -0.22250799699263138, "compression_ratio": 1.982532751091703, "no_speech_prob": 0.003647597972303629}, {"id": 824, "seek": 583836, "start": 5859.88, "end": 5866.36, "text": " van gogh you know for example um it's a totally different approach it's a it's a tricky one", "tokens": [51440, 3161, 352, 9030, 291, 458, 337, 1365, 1105, 309, 311, 257, 3879, 819, 3109, 309, 311, 257, 309, 311, 257, 12414, 472, 51764], "temperature": 0.0, "avg_logprob": -0.22250799699263138, "compression_ratio": 1.982532751091703, "no_speech_prob": 0.003647597972303629}, {"id": 825, "seek": 586636, "start": 5866.36, "end": 5874.839999999999, "text": " um i think i think when i was playing with that it almost hoped to not have the skip connections", "tokens": [50364, 1105, 741, 519, 741, 519, 562, 741, 390, 2433, 365, 300, 309, 1920, 19737, 281, 406, 362, 264, 10023, 9271, 50788], "temperature": 0.0, "avg_logprob": -0.2652294803673113, "compression_ratio": 1.6470588235294117, "no_speech_prob": 9.91487322608009e-05}, {"id": 826, "seek": 586636, "start": 5874.839999999999, "end": 5879.5599999999995, "text": " at the highest resolutions otherwise it just really wants to copy the input and modify it", "tokens": [50788, 412, 264, 6343, 32179, 5911, 309, 445, 534, 2738, 281, 5055, 264, 4846, 293, 16927, 309, 51024], "temperature": 0.0, "avg_logprob": -0.2652294803673113, "compression_ratio": 1.6470588235294117, "no_speech_prob": 9.91487322608009e-05}, {"id": 827, "seek": 586636, "start": 5879.5599999999995, "end": 5886.12, "text": " slightly interesting um maybe doing um where it's what you want would be better there too", "tokens": [51024, 4748, 1880, 1105, 1310, 884, 1105, 689, 309, 311, 437, 291, 528, 576, 312, 1101, 456, 886, 51352], "temperature": 0.0, "avg_logprob": -0.2652294803673113, "compression_ratio": 1.6470588235294117, "no_speech_prob": 9.91487322608009e-05}, {"id": 828, "seek": 586636, "start": 5888.679999999999, "end": 5890.44, "text": " oh yes that's a good point yeah", "tokens": [51480, 1954, 2086, 300, 311, 257, 665, 935, 1338, 51568], "temperature": 0.0, "avg_logprob": -0.2652294803673113, "compression_ratio": 1.6470588235294117, "no_speech_prob": 9.91487322608009e-05}, {"id": 829, "seek": 589044, "start": 5891.24, "end": 5895.32, "text": " cool well we'll put some stuff up on the website about yeah you know ideas and i'm sure some", "tokens": [50404, 1627, 731, 321, 603, 829, 512, 1507, 493, 322, 264, 3144, 466, 1338, 291, 458, 3487, 293, 741, 478, 988, 512, 50608], "temperature": 0.0, "avg_logprob": -0.35596209439364346, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.00026527163572609425}, {"id": 830, "seek": 589044, "start": 5895.32, "end": 5899.639999999999, "text": " students hopefully by the time you watch this we'll have some ideas on the forum of things", "tokens": [50608, 1731, 4696, 538, 264, 565, 291, 1159, 341, 321, 603, 362, 512, 3487, 322, 264, 17542, 295, 721, 50824], "temperature": 0.0, "avg_logprob": -0.35596209439364346, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.00026527163572609425}, {"id": 831, "seek": 589044, "start": 5899.639999999999, "end": 5906.5199999999995, "text": " i've tried too all right yeah the colorization is nice because it's um", "tokens": [50824, 741, 600, 3031, 886, 439, 558, 1338, 264, 2017, 2144, 307, 1481, 570, 309, 311, 1105, 51168], "temperature": 0.0, "avg_logprob": -0.35596209439364346, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.00026527163572609425}, {"id": 832, "seek": 589044, "start": 5906.5199999999995, "end": 5913.32, "text": " colorization right the transform is just to gray scale and back oh yes and then that's yeah that's", "tokens": [51168, 2017, 2144, 558, 264, 4088, 307, 445, 281, 10855, 4373, 293, 646, 1954, 2086, 293, 550, 300, 311, 1338, 300, 311, 51508], "temperature": 0.0, "avg_logprob": -0.35596209439364346, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.00026527163572609425}, {"id": 833, "seek": 589044, "start": 5913.32, "end": 5917.32, "text": " a really actually okay so there's all kinds of decryptification you could do isn't there so if", "tokens": [51508, 257, 534, 767, 1392, 370, 456, 311, 439, 3685, 295, 979, 627, 662, 3774, 291, 727, 360, 1943, 380, 456, 370, 498, 51708], "temperature": 0.0, "avg_logprob": -0.35596209439364346, "compression_ratio": 1.7991967871485943, "no_speech_prob": 0.00026527163572609425}, {"id": 834, "seek": 591732, "start": 5917.799999999999, "end": 5925.719999999999, "text": " you want to keep it a bit more simple yes rather than doing these two lines of code you could um", "tokens": [50388, 291, 528, 281, 1066, 309, 257, 857, 544, 2199, 2086, 2831, 813, 884, 613, 732, 3876, 295, 3089, 291, 727, 1105, 50784], "temperature": 0.0, "avg_logprob": -0.4819984729473408, "compression_ratio": 1.5680473372781065, "no_speech_prob": 7.60234470362775e-05}, {"id": 835, "seek": 591732, "start": 5925.719999999999, "end": 5939.4, "text": " um yeah just turn it into black and white that's a great point um or um you could delete the center", "tokens": [50784, 1105, 1338, 445, 1261, 309, 666, 2211, 293, 2418, 300, 311, 257, 869, 935, 1105, 420, 1105, 291, 727, 12097, 264, 3056, 51468], "temperature": 0.0, "avg_logprob": -0.4819984729473408, "compression_ratio": 1.5680473372781065, "no_speech_prob": 7.60234470362775e-05}, {"id": 836, "seek": 591732, "start": 5940.04, "end": 5944.12, "text": " every time you know to create like a something that learns how to uh", "tokens": [51500, 633, 565, 291, 458, 281, 1884, 411, 257, 746, 300, 27152, 577, 281, 2232, 51704], "temperature": 0.0, "avg_logprob": -0.4819984729473408, "compression_ratio": 1.5680473372781065, "no_speech_prob": 7.60234470362775e-05}, {"id": 837, "seek": 594412, "start": 5944.2, "end": 5948.599999999999, "text": " fill in or maybe delete the left hand side and that way that would lay then something that you", "tokens": [50368, 2836, 294, 420, 1310, 12097, 264, 1411, 1011, 1252, 293, 300, 636, 300, 576, 2360, 550, 746, 300, 291, 50588], "temperature": 0.0, "avg_logprob": -0.3797190376881803, "compression_ratio": 1.8059701492537314, "no_speech_prob": 3.169302362948656e-05}, {"id": 838, "seek": 594412, "start": 5948.599999999999, "end": 5953.16, "text": " can give it a photo in it'll invent a little bit more to the left yeah and then you could", "tokens": [50588, 393, 976, 309, 257, 5052, 294, 309, 603, 7962, 257, 707, 857, 544, 281, 264, 1411, 1338, 293, 550, 291, 727, 50816], "temperature": 0.0, "avg_logprob": -0.3797190376881803, "compression_ratio": 1.8059701492537314, "no_speech_prob": 3.169302362948656e-05}, {"id": 839, "seek": 594412, "start": 5953.16, "end": 5964.12, "text": " keep running it to generate a panorama another one you could do would be to like um in memory", "tokens": [50816, 1066, 2614, 309, 281, 8460, 257, 2462, 32988, 1071, 472, 291, 727, 360, 576, 312, 281, 411, 1105, 294, 4675, 51364], "temperature": 0.0, "avg_logprob": -0.3797190376881803, "compression_ratio": 1.8059701492537314, "no_speech_prob": 3.169302362948656e-05}, {"id": 840, "seek": 594412, "start": 5964.12, "end": 5970.12, "text": " or something save it as a really uh highly compressed jpeg and so then you would you", "tokens": [51364, 420, 746, 3155, 309, 382, 257, 534, 2232, 5405, 30353, 361, 494, 70, 293, 370, 550, 291, 576, 291, 51664], "temperature": 0.0, "avg_logprob": -0.3797190376881803, "compression_ratio": 1.8059701492537314, "no_speech_prob": 3.169302362948656e-05}, {"id": 841, "seek": 597012, "start": 5970.12, "end": 5975.88, "text": " would learn to remove jpeg artifacts which then for your like old photos that you", "tokens": [50364, 576, 1466, 281, 4159, 361, 494, 70, 24617, 597, 550, 337, 428, 411, 1331, 5787, 300, 291, 50652], "temperature": 0.0, "avg_logprob": -0.5451083374023438, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.011867471970617771}, {"id": 842, "seek": 597012, "start": 5975.88, "end": 5981.0, "text": " saved with crappy jpeg compression you could bring them back to life", "tokens": [50652, 6624, 365, 36531, 361, 494, 70, 19355, 291, 727, 1565, 552, 646, 281, 993, 50908], "temperature": 0.0, "avg_logprob": -0.5451083374023438, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.011867471970617771}, {"id": 843, "seek": 597012, "start": 5983.48, "end": 5988.28, "text": " you could probably do like yeah you could do like i guess drawing to painting or something like this", "tokens": [51032, 291, 727, 1391, 360, 411, 1338, 291, 727, 360, 411, 741, 2041, 6316, 281, 5370, 420, 746, 411, 341, 51272], "temperature": 0.0, "avg_logprob": -0.5451083374023438, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.011867471970617771}, {"id": 844, "seek": 597012, "start": 5988.28, "end": 5992.44, "text": " by taking some paintings and then like passing it through some sort of edge detection and using that", "tokens": [51272, 538, 1940, 512, 14880, 293, 550, 411, 8437, 309, 807, 512, 1333, 295, 4691, 17784, 293, 1228, 300, 51480], "temperature": 0.0, "avg_logprob": -0.5451083374023438, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.011867471970617771}, {"id": 845, "seek": 597012, "start": 5992.44, "end": 5997.96, "text": " as your starting point sounds interesting yeah i think that's a good idea yeah i think that's a", "tokens": [51480, 382, 428, 2891, 935, 3263, 1880, 1338, 741, 519, 300, 311, 257, 665, 1558, 1338, 741, 519, 300, 311, 257, 51756], "temperature": 0.0, "avg_logprob": -0.5451083374023438, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.011867471970617771}, {"id": 846, "seek": 599796, "start": 5998.04, "end": 6005.72, "text": " starting point sounds interesting oh what about watermark removal you could um you know use pil or", "tokens": [50368, 2891, 935, 3263, 1880, 1954, 437, 466, 1281, 5638, 17933, 291, 727, 1105, 291, 458, 764, 6429, 420, 50752], "temperature": 0.0, "avg_logprob": -0.18575039888039613, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.0008425912237726152}, {"id": 847, "seek": 599796, "start": 6005.72, "end": 6011.72, "text": " whatever to draw watermarks text whatever over the top which is quite useful for like", "tokens": [50752, 2035, 281, 2642, 1281, 37307, 2487, 2035, 670, 264, 1192, 597, 307, 1596, 4420, 337, 411, 51052], "temperature": 0.0, "avg_logprob": -0.18575039888039613, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.0008425912237726152}, {"id": 848, "seek": 599796, "start": 6012.84, "end": 6017.32, "text": " you know radiology images and stuff sometimes have personally identifiable information written", "tokens": [51108, 291, 458, 16335, 1793, 5267, 293, 1507, 2171, 362, 5665, 2473, 30876, 1589, 3720, 51332], "temperature": 0.0, "avg_logprob": -0.18575039888039613, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.0008425912237726152}, {"id": 849, "seek": 599796, "start": 6017.32, "end": 6024.28, "text": " on them and you can just like learn to delete it yeah okay so lots of things people can do", "tokens": [51332, 322, 552, 293, 291, 393, 445, 411, 1466, 281, 12097, 309, 1338, 1392, 370, 3195, 295, 721, 561, 393, 360, 51680], "temperature": 0.0, "avg_logprob": -0.18575039888039613, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.0008425912237726152}, {"id": 850, "seek": 602428, "start": 6025.0, "end": 6028.44, "text": " that's awesome thanks for your ideas basically any image to image task", "tokens": [50400, 300, 311, 3476, 3231, 337, 428, 3487, 1936, 604, 3256, 281, 3256, 5633, 50572], "temperature": 0.0, "avg_logprob": -0.29502628589498586, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.002251286758109927}, {"id": 851, "seek": 602428, "start": 6031.24, "end": 6039.88, "text": " super all right um or just make the super res better um try it on full image net if you like", "tokens": [50712, 1687, 439, 558, 1105, 420, 445, 652, 264, 1687, 725, 1101, 1105, 853, 309, 322, 1577, 3256, 2533, 498, 291, 411, 51144], "temperature": 0.0, "avg_logprob": -0.29502628589498586, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.002251286758109927}, {"id": 852, "seek": 602428, "start": 6042.44, "end": 6047.719999999999, "text": " if you've got lots of hard drive space thanks jono thanks tanishq", "tokens": [51272, 498, 291, 600, 658, 3195, 295, 1152, 3332, 1901, 3231, 361, 8957, 3231, 256, 7524, 80, 51536], "temperature": 0.0, "avg_logprob": -0.29502628589498586, "compression_ratio": 1.5793103448275863, "no_speech_prob": 0.002251286758109927}, {"id": 853, "seek": 604772, "start": 6047.72, "end": 6050.76, "text": " see you next time we'll see you in the next one", "tokens": [50412, 536, 291, 958, 565, 321, 603, 536, 291, 294, 264, 958, 472, 50516], "temperature": 0.0, "avg_logprob": -0.6739865620930989, "compression_ratio": 1.0444444444444445, "no_speech_prob": 0.020039018243551254}], "language": "en"}