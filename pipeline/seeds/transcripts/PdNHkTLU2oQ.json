{"text": " Hi and welcome to lesson 20. In the last lesson we were about to learn about implementing mixed precision training. Let's dive into it. So to, and I'm going to fiddle with other things just because I want to really experiment. I just love fiddling around. So one thing I wanted to do is I wanted to get rid of the ddpmcb entirely. We made it pretty small here, but I wanted to remove it. So much as Janice said, isn't it great the callbacks make everything so cool? I wanted to show we can actually make things so cool without callbacks at all. And so to do that I realized what we could do is we could put noisify inside a collation function. So the collation function, if you remember back to our datasets notebook, which was going back to notebook 5, and you've probably forgotten that by now. So go and reread that to remind yourself. It's the function that runs to take all of the, you know, you've basically each kind of row of data, you know, will be a separate tuple. Then it hits the collation function and the collation function turns that into tensors, you know, one tensor representing the independent variable, one tensor representing the dependent variable, something like that. And the default collation function is called, not surprisingly, default collate. So if our collation function calls that on our batch, and then grabs the X part, which is, it's always been the same for the last few things, that's the image because we use, because datasets uses dictionaries. So we're going to grab the image. Then we can call noisify on that collated batch. Then that's exactly the same thing as Tanishq's before batch did. Right? Because before batch is operating on the thing that came out of the default collate function. So we could just do it in a collate function. So if we do it here, and then we create a ddpm data loader function, which just creates a data loader from some dataset that we pass in with some batch size, with that collation function, then we can create our DLs, not using data loaders dot from, what's it called? Data loaders dot from dd. But instead of that, the original, you know, the plain init that we created for data loaders, and again you should go back and remind yourself of this, you just pass in the data loaders for training and test. So there's our two data loaders. So with that we don't need a ddpm callback anymore. All right, so now that we've, you know, and again this isn't, this is not required for mixed precision, this is just because I wanted to experiment and flex our muscles a little bit of trying things out. So here's our mixed precision callback, and this is a training callback, and basically if you Google for PyTorch mixed precision, you'll see that the docs show the typical mixed precision basically says with auto cast device equals CUDA type equals float 16, get your predictions and call your loss. So again, remind yourself if you've forgotten that this is called a context manager, and context managers when they start call something called done to enter, and when they finish they call something called done to exit. So we could therefore put the torch dot auto cast into an attribute and call done to enter before the batch begins, and then after we've calculated the loss we want to finish that context manager. So after loss we call auto cast done to exit, and so I had to add this. So you'll find now in the 09 learner that there's a section called updated version since the lesson, where I've added an after predict, and after loss, and after backward, and an after step, and that means that a callback can now insert code at any point of the training loop, and so we haven't used all of those different things here, but we certainly do want, yeah, after loss we need to be able to do that, and then yeah this is just code that has to be run according to it to the PyTorch docs, so instead of calling loss dot backwards, you have to call scalar dot scale loss dot backward. So we replace our backward in the train callback with something called scalar dot scale loss dot backward, and then it says that finally when you do the step you don't call optimizer dot step, you call scalar dot step optimizer, scalar dot update. So we've replaced step with scalar dot step, scalar dot update. So that does all of the things in here, and the nice thing is now that this exists, we don't have to think about any of that, we can add mixed precision to anything, which is really nice, and so we now, as you'll see, CB's no longer has a DDPM CB, but we do have the mixed precision, and that's a train callback, so we just need a normal learner, not a train learner, and we initialize our DDPM. Now to get benefit from mixed precision, you need to do quite a bit at a time, you know, your GPU needs to be busy, and on something as small as fashion MNIST, it's not easy to keep a GPU busy, so that's why I've increased the batch size by four times. Now that means that each epoch, it's going to have four times less batches, because they're bigger, and that means it's got four times less opportunities to update, and that's going to be a problem, because if I want to have as good a result as Tanishk had, and as I've had here, in less time, that's the whole purpose of this, is to do it in less time, then I'm going to need to, you know, increase the learning rate, and maybe also increase the epoch. So increase the epochs up to eight from five, and I increase the learning rate up to 1 enig 2, and yeah, I found I could train it fine with that, once I used the proper initialization, and most importantly used the optimization function that has epsilon of 1 enig 5, and so this trains, even though it's doing more epochs, this trains about twice as fast, and gets the same result. Does that make sense so far? Yeah, it was great. Cool. Now the good news is actually, we don't even need to write all this, because there's a nice library from Hugging Face, originally created by Sylva, who used to work with me at Fast.ai, and went to Hugging Face, and kept on doing awesome work, and he started this project called Accelerator, which he now works on with another Fast.ai alum, named Zach Riehler, and accelerates a library that provides this thing called Accelerator, that does things to accelerate your training loops, and one of the things it does is mixed precision training, and it basically handles these things for you. It also lets you train on multiple GPUs, it also lets you train on TPUs, so by adding a train CB subclass that will allow us to use accelerate, that means we can now hopefully use TPUs, and multi GPU training, and all that kind of thing. So the accelerate docs show that what you have to do to use accelerate, is to create an accelerator, tell it what kind of mixed precision you want to use, so we're going to use 16-bit floating-point FP16, and then you have to basically call accelerate, accelerator.prepare, and you pass in your model, your optimizer, and your training and validation data loaders, and it returns you back a model, an optimizer, and training and validation data loaders, but they've been wrapped up in accelerate, and accelerate is going to now do all the things we saw you have to do automatically, and that's why that's almost all the code we need. The only other thing we need is it didn't, we didn't like tell it how to like change our loss function to use accelerate, so we actually have to change backward, that's why we inherit from train CB, we have to change backward to not call loss.backward, but self.accelerate.backward and pass in loss. Okay, and then I had another idea of something I wanted to do, which is I like the idea that noisify, I've copied noisify here, but rather than returning a tuple of tuples, I just return a tuple with three things. I think this is neater to me, I would like to just have three things in the tuple, I don't want to have to modify my model, I don't want to have to modify my training callback, I don't want to do anything tricky, I don't even want to have a custom collation function, sorry I want to have a custom collation function, but I don't want to have a modified model. So I'm going to go back to using a unet2d model. So how can we use a unet2d model when we've now got three things? And what I did in my modified learner, just underneath it, sorry actually what I did was I modified trainCB to add one parameter, which is number of inputs, and so this tells you how many inputs are there to the model. Normally you would expect one input, but our model has two inputs. So here we say, okay so accelerateCB is a trainCB, so when we call it we say we're going to have two inputs, and so what that's going to do is it's just going to remember how many you asked for, and so when you call predict it's not going to pass learn.batch zero, it's going to call star learn.batch colon self.numInputs, and ditto when you call the loss function it's going to be the rest. So it's star learn.batch self.numInputs. So this way you can have one, two, three, four, five inputs, one, two, three, four, five outputs, whatever you like, and it's just up to you then to make sure that your model and your loss function take the number of parameters. So the loss function is going to first of all take your threads, and then yeah however many non inputs you have. So that way yeah we now don't need to replace anything except that we did need to do the thing to make sure that we get the dot sample out. So I just had a little, this is the whole DDPMCB callback now, DDPMCB2, so after the predictions are done, replace them with the dot sample. Right so that's nice and easy, you know. So we end up with quite a bit of pieces, but they're all very decoupled, you know. So with mini AI, you know, with and with accelerate CB, whatever, I guess we should export these actually, so into a nice module. Well if you had all those, then yeah you wouldn't have accelerate CB, the only thing you would need would be the would be the noisify and the collation function, and this tiny callback, and then yeah use our learner and fit, and we get the same result as usual. And this takes basically an identical amount of time, because at this point I'm not using multi GPU or TPU or whatever, I'm just using mixed precision. So this is just a shortcut for this. It's not a huge shortcut, the main purpose of it really is to allow us to use other types of accelerators, or multiple accelerators, or whatever. So we'll look at those later. Does that make sense so far? Yeah, oh yeah, it's sorry it's really powerful and pretty amazing. Yeah, it is, and I know like a lot of, yeah, like I know Kat Carlson uses it in all her K diffusion code, for example. Yeah, it's used a lot out there in the real world. Yeah. I've got one more thing I just want to mention briefly, just a sneaky trick. I haven't even bothered training anything with it, because it's just a sneaky trick. But sometimes thinking about speed, loading the data is the slow bit. And so particularly if you use Kaggle, for example, on Kaggle you get two GPUs, which is amazing, but trying to get to CPUs, which is crazy. So it's really hard to like take advantage of them, because the amount of time it takes to like open a PNG or a JPEG, you know, your GPU is sitting around waiting for you. So there's a, if your, you know, if your data loading and transformation process is slow, and it's difficult to keep your GPUs busy, there's a trick you can do, which is you could create a new data loader class, which wraps your existing data loader, and it replaces dunder-idder. Now dunder-idder is the thing that gets called when you use a for loop, right? Or when you use next-idder, it calls this. And when you call this, you just go through the data loader as per usual, that's what dunder-idder would normally do. But then you also go through i from 0 to by default 2, and then you spit out the batch. And what this is going to do is it's going to go through the data loader and spit out the batch twice. Why is that interesting? Because it means every epoch is going to be twice as long, but it's going to only load and augment the data as often as one epoch, but it's going to give you two epochs worth of updates. And basically there's no reason to have a whole new batch every time, you know, looking at the same batch two or three or four times at a row is totally fine. And what happens in practice is you look at that batch, you do an update, get to any part of the wait space, look at exactly the same batch, and find out now where to go in the wait space. It's still, yeah, basically equally useful. So I just wanted to add this little sneaky trick here, particularly because if we start doing more stuff on Kaggle, we'll probably want to surprise all the Kagglers with how fast our mini AI solutions are. And they'll be like, how is that possible? We'll be like, oh, we're using our, you know, two GPUs, thanks to accelerate. Asking him, how do we use the two GPUs? And like, oh, and we're, you know, using, you know, getting our loading flying through using multdl. I think that'd be pretty sweet. So that's that. Nice. Yeah, it's great to see the various different ways that we can use mini AI to do the same thing, I guess, or, you know, however you feel like doing it or whatever works best for you. I'll be curious to see if other people find other ways to, you know, I'm sure there's so many different ways to handle this problem. I think it's an interesting problem to solve. And I think for the homework, it'd be useful for people to run some of their own experiments, maybe either use these techniques on other data sets, or see if you can come up with other variants of these approaches, or come up with some different noise schedules to try. It would all be useful. Any other thoughts of exercises people could try? Yeah, I mean, getting away with less than a thousand steps. Yeah, less than a thousand steps. It's happening in the final 200. So why not just train with only 200 steps? Yeah, less steps would be good. Yeah, because the sampling is actually pretty slow. So that's a good point. Yeah, yeah, yeah, I was gonna say something similar in terms of like, yeah, many, I guess, work with less number of steps. You know, you would have to adjust the noise schedule appropriately. And you have to, I guess there's maybe a little bit more thought into some of these things. Or, you know, another aspect is like, when you're selecting the time step during training, right now we select it randomly, kind of uniformly. Each time step has equal probability of being selected. Maybe different probabilities are better, and some papers do analyze that more carefully. So that's another thing to play around with as well. That's almost kind of like, if, I guess there are almost two ways of doing the same thing, in a sense, right? If you change that mapping from T to beta, then you could reduce T and have different betas, would kind of give you a similar result as changing the probabilities of the Ts, I think. Yeah, I think there's definitely, they're kind of similar, but potentially something complementary happening there as well. And I think those could be some interesting experiments to study that. And also, the sort of noise levels that you do choose affect the sort of behavior of the sampling process, and of course, what features you focus on. And so maybe as people play around with that, maybe they'll start to notice how using, yeah, different noise levels, or, you know, different noise levels affect maybe some of the features that you see in the final image. And that could be something very interesting to study as well. Great. Well, let me also say it's been really fun doing something a bit different, which is doing a lesson with you guys, rather than all on my lonesome. I hope we can do this again, because I've really enjoyed it. Yeah, it was great. So of course, now, you know, strictly speaking, in the recording, we'll next up see Jono, who's actually already recorded his, thanks to the Zoom mess up, but stick around. So I've already seen it. Jono's thing is amazing. So you definitely don't want to miss that. Hello, everyone. So today, depending on the order that this ends up happening, you've probably seen Tanishq's DBPM implementation, where we're taking the default training callback and doing some more interesting things with preparing the data for the learner or interpreting the results. So in these two notebooks that I'm going to show, we're going to be doing something similar, just exploring like, what else can we do besides just the classic kind of classification model where we have some inputs and a label? And what else can we do with this mini AI setup that we have? And so in the first one, we're going to approach a kind of classic AI art approach called style transfer. And so the idea here is that we're going to want to somehow create an artistic combination of two images where we have the structure and layout of one image and the style of another. So we'll look at how we do that. And then we'll also talk along the way in terms of like, why is this actually useful beyond just making pretty pictures? So to start with, I've got a couple of URLs for images. You're welcome to go and slip in your own as well. I definitely recommend trying this notebook with some different ones just to see what effects you can get. And we're going to download the image and load it up as a tensor. So we have here a three channel image, 256 by 256 pixels. And so this is the kind of base image that we're going to start working with. So before we talk about styles or anything, let's just think what is our goal here? We'd like to do some sort of training or optimization. We'd like to get to a point where we can match some aspect of this image. And so maybe a good place to start is to just try and do, well, can we start from a random image and optimize it until it matches pixel for pixel exactly? And that's going to help us get this. Yeah. Something that might be helpful is if you type style transfer deep learning into Google images, you could maybe show some examples so that people will see what their goal is. Yeah, that's a very good point. So let's see. This is a good one here. We've got the Mona Lisa as our base, but we've managed to apply somehow some different artistic styles to that same base structure. So we have the great wave by Misaki. We have starry night by Vincent Van Gogh. This is some sort of Kandinsky or something. Yeah. So this is our end goal to be able to take the overall structure and layout of one image and the style from some different reference image. And in fact, this was the first ever, I think, fast.ai generative modeling lesson looked at style transfer. It's been around for a few years. It's kind of a classic technique. And it's really, I think a lot of the students, when we first did it, found it extremely useful, a way of better understanding, like, you know, flexing their deep learning muscles, understanding what's going on, and also created some really interesting new approaches. So hopefully we'll see the same thing again. Maybe some students will be able to show some really interesting results from this. Yeah. And I mean, today we're going to focus on kind of the classic approach. But I know one of the previous students from fast.ai did a whole different way of doing that style loss that we'll maybe post in the forums or, you know, I've got some comparisons that we can look at. So yeah, definitely a fruitful field still. And I think after the initial hype of like, everyone was excited about style transfer apps and things, I don't know, five years ago, I feel like there's still some things to explore there. I agree. Very creative and fun little diversion in the deep learning world. Okay. So our first step in getting to that point is being able to optimize an image. And so up until now, we've been optimizing like the weights of a neural network. But now we want to go to something a bit more simple. And we just want to optimize the raw pixels of an image. Do you mind if we scroll up a bit to the previous code, just so we can have a look at it. So there's a couple of interesting points about this code here is, you know, we're not, we're not cheating. Well, not really. So we're, so yeah, we, we, we've seen how to download things in the network before. So we're using fast codes URL read, because we're allowed to. And then I think we decided we weren't going to write our own JPEG parser. So Torchvision actually has a pretty good one, which a lot of people don't realize exists. And a lot of people tend to use PIL, but actually Torchvision has a more performant option. And it's actually quite difficult to find any examples of how to use it like this. But here's some code you can borrow. Yeah. And actually Google load image from a URL in PyTorch. All of the examples are going to use PIL. And that's what I've done historically, is use the requests library to download the URL and then feed that into PIL's image.open function. So yeah, that was fun when I was working with Jeremy on this notebook, like that's how I was doing it. It's way through breaking the rules. Let's see if we can do this directly into a tensor without this intermediate step of loading it with, with pillow. Cool. Okay. So how are we going to do this image optimization? Well, first thing is we don't really have a data set of lots of training examples. We just have a single target and a single thing we're optimizing. And so we built this linked data set here, which is just going to follow the PyTorch like data set standard. We're going to tell it how to get a particular item and what our length is. But in this case, we're just always going to return zero, zero. We're not actually going to care about the results from this data set. We just want something that we can pass to the learner to do some number of training iterations. So we create like a fake dummy data set with a hundred items. And then we create our data loaders from that. And that's going to give us a way to train for some number of steps without really caring about what this data is. So does that make sense? Yeah. So just to clarify the reason we're doing this. So basically the idea is we're going to start with that photo you downloaded. And I guess you're going to be downloading another photo. So that photo is going to be like the content. We're going to try to make it continue to look like that lady. And then we're going to try to change the style so that the style looks like the style of some other picture. And the way we're going to be doing that is by doing an optimization loop with like SGD or whatever. But so the idea is that each step of that we're going to be moving the style somehow of the image closer and closer to one of those images you downloaded. So it's not that we're going to be looping through lots of different images, but we're just going to be looping through, through steps of a optimization loop. Is that the idea? Exactly. And so, yeah, we can, we can create this fake data loader. And then in terms of the actual like model that we're optimizing and passing to the learner, we've created this tensor model class, which just has whatever tensor we pass in as its parameter. So there's no actual neural network necessarily. We're just going to pass in a random image or some image shaped thing, a set of numbers that we can then optimize. So just in case people have forgotten that, so to remind people, when you put something in an end parameter, it doesn't change it in any way. It's just a normal tensor, but it's stored inside the module as being something, as being a tensor to optimize. So what you're doing here, Jono, I guess is to say, I'm not actually optimizing a model at all. I'm optimizing an image, the pixels of an image directly. Exactly. And because it's in a parameter, if we look at our, our model, we can see that for example, model.t, it does require grad, right? Because that's already set up because this nn.module is going to look for any parameters. And if our optimizer is looking at, let's look at the shape of the parameters. So this is the shape of the parameters that we're optimizing. This is just that tensor that we passed in, the same shape as our image. And this is what's going to be optimized if we pass this into any sort of learner fit method. Okay, so this model does have a thing being passed to forward, which is x, which we're ignoring. And I guess that's just because our learner passes something in. So we're making life a bit easier for ourselves by making the model look the way our learner expects. Yeah. And we could do that using like trainCB or something if we wanted to, but this seems like a nice, nice easy way to do it. Yeah. So I mean, this is the way I've done it. If you do want to use trainCB, you can set it up with a custom predict method that is just going to call the model forward method with no parameters. And if you want, likewise, just calling the loss function on just the predictions. But if you want to skip this, because we take this argument x equals zero and never use it, that should also work without this callback. So either way is fine. This is a nice approach if you have something that you're using an existing model, which expects some number of parameters or something. Yeah, you can just modify that training callback, but we almost don't need to in this case. Okay, so let's see. Let's put this in a learner. Let's optimize it with some loss function. Oh, just to clarify, I get it. So the get loss you had to change because normally we pass a target to the loss function. Yeah. So it's learner.preds and then learner.batch. And again, we could avoid, we could remove that as well if we wanted to by having our loss function take a target that we then ignore. Yeah, yeah, exactly. So both are the approaches. I like this because we're going to kind of be building on this idea of modifying the training callback in the DDPM example and the other examples. But in this case, it's just these like two lines change. This is how we get our model predictions. We just call the forward method, which returns this image that we're optimizing. And we're going to evaluate this according to some loss function that just takes in an image. And so for our first loss function, we are just going to use the mean squared error between the image that we are generating, like this output of our model and that content image that's our target. Right? So we're going to set up our model, start it out with a random image like this above. We're going to create a learner with a dummy data loader for 100 steps. Our loss function is going to be this mean squared error loss function, set a learning rate and an optimizer function. The defaults would probably also work. And if we run this, something's going to happen. Our loss is going to go from a non-zero number to close to zero. And we can look at the final result. Like if we call learn.model and show that as an image versus the actual image, we'll see that they look pretty much identical. Yeah. So just to clarify, this is like a pointless example. But what we did, we started with that noisy image you showed above. And then we used SGD to make those pixels get closer and closer to the lady in the sunglasses. Not, you know, not for any particular purpose, but just to show that we can turn noisy pixels into something else by having it follow a loss function. And this loss function was just like, make the pixels look as much as possible like that lady in the sunglasses. Exactly. And so in this case, it's a very simple loss. There's like a one direction that you update. So it's almost trivial to solve, but it still helps us get like the framework in place. But just seeing this final result is not very instructive because you almost think, well, did I get a bug in my code? Did I just duplicated the image? How do I know this is actually doing what we expect? And so before we even move on to any more complicated loss functions, I thought it was important to have some sort of more obvious way of doing progress. So I've created a little logging callback here that is just after every batch, it's going to store the output as an image. And I guess after every 10 batches here by default. Oh, yes. Yeah. So sorry. So we can set how often it's going to update and then every 10 iterations or 50 iterations, whatever we set the log every argument to, it's going to store that in a list. And then after the training is done, after that, we're just going to show those images. And so everything else the same as before, but passing in this extra logging callback, it's going to give us the kind of progress. And so now you can see, OK, there is actually something happening. We're starting from this noise after a few iterations, already most of it is gone. And by the end of this process, it looks exactly like the content image. So I really like this because what you've basically done here is you've now already got all the tooling and infrastructure in place you need to basically create a really wide variety of interesting outputs that could either be artistic or, like, you know, they could be more like image reconstruction, super resolution, colorization, whatever. And you just have to modify the loss function and you, you know, and I really like the way you've created the absolute easiest possible first and fully checked it. And before you start doing the fancy stuff and now you kind of, I guess you're really comfortable doing the fancy stuff because, you know, that's all in place. Yeah, exactly. And we know that we're going to see some tracking, so hopefully it'll be like visually obvious if things are going wrong and we know exactly what we need to modify. If we can now express some desired property that's more interesting than just like mean squared error to a target image, then we quickly have everything in place to optimize. And so this is now really fun to like, OK, let's think about what other loss functions we could do. Maybe we wanted to match an image, but also have a particular overall color. Maybe we want some, some more complicated thing. And so towards that, like towards starting to get a more richer, like measure of what this output image looks like. We're going to talk about extracting features from a pre-trained network. And this is kind of like the core idea of this notebook is that we have these big convolutional neural networks. This one is a much older architecture. And so relatively simple compared to some of the big, you know, dense nets and so on used today. It's actually a lot like our pre-resnet fashion MNIST model. It's basically almost the same as VGG 16. Yeah, yeah, exactly. And so we're feeding in an image and then we have these like convolutional layers, downsampling, convolution, you know, downsampling with max pooling up until some final prediction. Oh, but the question... Can I just point something out? There's one big difference here, which is that 7 by 7 by 512, if you can point at that. Normally nowadays and in our models, we tried, you know, using an adaptive or global pooling to get down to a 1 by 1 by 512. VGG 16 does something which is very unusual by today's standards, which is it just flattens that out into a 1 by 1 by 4096, which actually might be a really interesting feature of VGG. And I've always felt like people might want to consider training, you know, resnets and stuff without the global pooling and instead do the flattening. The reason we don't do the flattening nowadays is that that very last linear layer that goes from 1 by 1 by 4096 to 1 by 1 by 1000, because this is an image net model, is going to need an awfully big weight matrix. You've got a 4096 by 1000 weight matrix, as a result of which this is actually horrifically memory intensive for a reasonably poor performing model by modern standards. But yeah, I think that doing that actually also has some benefits potentially as well. Yeah, and in this case, we are not even really interested in the classification side. We're more excited about the capacity of this to extract different features. And so the idea here, and maybe I should pull up this classic article looking at like, what do neural networks learn and trying to visualize some of these features. This is something we've mentioned before with these big pre-trained networks, is that the early layers tend to pick up on very simple features, edges and shapes and textures. And those get mixed together into more complicated textures. And by the way, this is just trying to visualize like what kind of input maximally activates a particular output on each of these layers. And so it's a great way to see like what kinds of things that's learning. And so you can see as we move deeper and deeper into the network, we're getting more and more complicated, like hierarchical features. Now, we should mention, so we've looked at the Zeiler and Fergus paper before, which is an earlier version doing something like this to see what kind of features were available. So we're linked to this distilled paper from the forum and the course lesson page, because it's actually a more modern and fancy version kind of of the same thing. Yeah. Also note the names here. All of these people are worth following. Chris does amazing work on interpretability. And Alexander Mordvintsev we'll see in the second notebook that I look at today, doing all sorts of other cool stuff as well. Anyway, so we want to think about like, let's extract the outputs of these layers in the hope that they give us a representation of our image that's richer than just the raw pixels. So we can list... The idea being there that if we had another, if we were able to change our image to have the same features at those of those various like types that you were just showing us, that then it would like have similar textures or similar kind of higher level concepts or whatever. Exactly. So if you think of this like 14 by 14 feature map over here, maybe it's capturing that there's, you know, an eye in the top left and some hair on the top right, these kind of abstract things. And if you change the, like if you change the brightness of the image, it's unlikely that it's going to change what features are stored there because the network's learned to be somewhat invariant to these like rough transformations, a bit of noise, a bit of changing texture early on is not going to affect the fact that it still thinks this looks like a dog. And a few layers before that, that it still thinks that part looks like a nose and that part looks like an ear. And maybe the more interesting bits then for what you're doing are those earlier layers where it's going to be like, there's a whole bunch of kind of diagonal lines here, or there's a kind of a loopy bit here. Because then, yeah, if you replicate those, you're going to get similar textures without changing the semantics. Exactly. Yeah. So, I mean, I guess let's load the model and look at what the layers are. And then in the next section, we can try and like see what kinds of images work when we optimize towards different layers in there. And so this is the network we have, um, revolutions, values, max pooling. So all of this we should be familiar with by now. Um, and it's all just in one big NN.sequential. Um, this doesn't have the head. So we said, uh, dot features. If you did this without you'd have then the, this is like the features, um, sub sub sub network. That's everything up until some point. And then you have the flattening and the classification, which we are kind of just throwing away. So this is the body of the network. And we're going to try and tag into various layers here and extract the outputs. Um, but before we do that, there's one more bit of admin we need to handle. Um, this was trained on a normalized version of ImageNet, right? Where you took the dataset mean and the dataset standard deviation, and you use that to normalize your images. So if we want to match what the data looked like during training, we need to match that normalization step. And we've done this on grayscale images where we just subtract the mean divided by the standard deviation. Um, but with three channel images, these RGB images, um, we can't get away with just saying, uh, let's subtract our mean from our image and divide by the standard deviation. You're going to get an error. It's going to pop up. And this is because we now need to think about broadcasting and these shapes a little bit more carefully than we can with just a scalar value. Um, so if we look at the mean here, we just have three values, right? One for each channel, the red, green, and blue channels. Um, whereas our content image has three channels and then 256 by 256 for the, you know, spatial dimensions. So if we try and say content image, you know, divided by the mean or minus the mean, um, it's going to go from right to left and find the first non-unit, um, axis. So would anything with a, with a size greater than one, and it's going to try and line those up. And in this case, the three and the 256, those aren't going to match. And so we're going to get an error. Um, well, perniciously, if the shape did happen to match, um, that might still not be what you intended. So what we'd like is to have these three channels mapped to the three channels of our image, and then somehow expand those values out across the two other dimensions. And the way we do that is we just add two additional dimensions on the right for our image net dot mean. And you could also do dot unsqueeze minus one dot unsqueeze minus one. Um, but this is the kind of syntax that we're using in this course. And now our shapes are going to match because we're going to go from right to left. If it's a unit dimension size one, we're going to expand it out to match the other tensors. Um, and if it's a non-unit dimension, then the shapes have to match. And that looks like it's the case. And so now with this, um, reshaping operation, we can write a little normalize function, which we can then apply to our content image. And I'm just checking the min and the max to make sure that this roughly makes sense. Um, we could check the mean, uh, as well to make sure that the mean is somewhat close to zero. Um, okay. In this case, less maybe because it's a darker image than average. Um, but at least we are doing the operation. It seems like the math is correct. And now the shader in the channel wise mean would be interesting. Uh, Oh yes. Um, so that would be the mean over the dimensions. Um, one and two, I think. Uh, I think you have to tap all one comma two. This wasn't sure which way it was. Yeah. I always forget to. Um, okay. So our blue channel is brighter than the others. And if we go back and look at our image, um, maybe believe that the magenta is going to be blue and red and the face is going to be just blue. Um, yeah. Okay. So that seems to be working. We can double check because now that we've implemented ourselves, torch vision dot transforms has a normalized function that you can pass the mean and standard deviation to, and it's going to handle making sure that the devices match that the shapes match, et cetera. And you can see if we check the min and max, it's exactly the same, just a little bit of reassurance that our function is doing the same thing as this normalized transform. I appreciate you not cheating by implementing that. Jono, thank you. You're welcome. Gotta follow the rules. Gotta follow the rules. Okay. So with that bit of admin out the way, we can finally say, how do we extract the features from this network? Uh, now if you remember the previous lesson on hooks, that might be something that springs to mind. I'm going to leave that as an exercise for the reader. And what we're going to do is we're just going to normalize our inputs. And then we're going to run through the layers one by one in this sequential stack. Um, we're going to pass our X through that layer. And then if we're in one of the target layers, which we can specify, we're going to store the outputs of that layer. And I can't remember if I've used the term features before or not. So apologies if I have, but just to clarify here, when we say features, we just mean. The activations of, of a layer. In this case, Jono's picked out two particular layers, 18 and 25. Um, yeah, I just want to, I mean, I'm not sure it matters in this particular case, but there's a bit of a gotcha you've got here, Jono, which is you should change that. Um, default 18 comma 25 from a list to a tuple. And the reason for that is that when, uh, you use a mutable type, like a list in a Python, um, default parameter, it does this really weird thing where it actually keeps it around. And if you change it at all later than it actually kind of modifies your function. So I would suggest, yeah, never using a list as a default parameter, because at some point it will create the weirdest bug you've ever had. I speak, I say this from experience. Yeah. Yeah. That sounds like, um, something that, that was hard one. All right. I'll, I'll change that. And by the time you see this notebook, that change should be there. Um, all right. So this is one way to do it. Just manually running through the layers one by one up until whatever the latest layer we're interested in is. Um, but you could do this just as easily by adding hooks to the specific layers and then just feeding your data through the whole network at once and relying on the hooks to store those intermediates. Yeah. So let's make that a homework, actually, not just an exercise you can do, but yeah, I want, let's make sure everybody does that. You can use the, one of the hooks, um, callbacks we had or the hooks context managers we had, or you can use the register forward hook PyTorch directly. Yeah. Um, and so what we get out here, um, we feeding in an image that's 256 by 256. And the first layer that we're looking at is this one here. Um, and so it's getting half to 128, then to 64. These ones are just different because it's a different starting size. Um, and then to 32 by 32 by 512. And so those are the features that we're talking about for that layer 18. It's this thing of shape 512 by 32 by 32 for every kind of spatial location in that 32 by 32 grid, we have the output from 512 different filters. And so those are going to be the features that we're talking about. So there's being the, the, uh, the channels in a, in a, in a single convolution. Yeah. Um, okay. So what's the point of this? Well, like I said, we hoping that we can capture different things at different layers. Um, and so to kind of first get a feel for this, this, like, what if we just compared these feature maps, um, we can institute what, what I'm calling a content loss, or you might see it as a perceptual loss. Um, and we're going to focus on a couple of later layers. Again, make sure that this is. The people as I've learned, um, and what we're going to do is we're going to pass in a target image in this case, our content image. Um, and we're going to calculate those features in those target layers. Um, and then in the, um, in the forward method, when we comparing to our inputs, we're going to calculate the features of our inputs, and we're going to do the mean squared error between those and our target features. Um, so maybe there's a bad way of explaining it, but the, so the. So I can maybe read it back to you to make sure you understand. Yeah. Would that help? Yeah. So, okay. So this is a loss function you've created. It has a done to call method, which means you can pretend that it's a function. It's a callable in, in Python language. Um, your, your forward. So yeah, in, in an NM module would call it forward, but in normal Python, we just use done to call. It's taking, uh, one input, um, which is the way you set up your, your image training callback earlier. It's just going to pass in the input, which is, this is the image as it's been optimized to so far. So initially it's going to be that random noise. And then the, uh, loss you're calculating is the mean squared error of how far away is this, um, input image from the, um, target image, um, the mean squared error for each of the layers, eight, by default, 18 and 25. Um, and so you're literally actually, it's a bit weird. You're actually calling a different neural network. Calc features actually call the neural network, but not because that's the model we're optimizing, but because it's actually the loss function is how far away are we? Yeah. So that's the last option. And so if we, so if you, so if we with SGD optimize that loss function, you're not going to get the same pixels. You're going to get, I don't even know what this is going to look like. You're going to get some pixels, which have the same activations of those features. Yeah. And so if we run that, we see, you can see the sort of shape of our person there, but it definitely doesn't match on like a color and style basis. So 18 and 25 remind us how deep they are in the scheme of things. So these are fairly close towards the end. Okay. So I guess color often doesn't have much of a semantic kind of property. So that's probably why it doesn't care much about color because it's still going to be an eyeball, whether it's green or blue or, or brown. Yeah. There's something else I should mention, which is we aren't constraining our tensor that we're optimizing to be in the same bounds as a normal image. And so some of these will also be less than zero or greater than one as kind of like almost hacking the neural network to get the same features that those deep layers by passing in some by passing in something that it's never seen during training. And so for display, we're clipping it to the same bounds as an image, but you might want to have either some sort of sigmoid function or some other way that you clamp your, your tensor model and to have outputs that are, that are like within the allowed range for. Oh, good point. Also, it's interesting to note the background hasn't changed much. And I guess the reason for that would be that the VGG model you were using in the loss function was trained on ImageNet. And ImageNet is specifically about recognizing generally as a single big object, like a dog or a boat or whatever. So it's not going to care about the background and the background probably isn't going to have much in the way of features at all, which is why it hasn't really changed the background. Yeah, exactly. And so, I mean, this is kind of interesting to see how little it looks like the image while at same time still being like, if you squint, you can recognize it. But we can also try passing in earlier layers, right? And comparing, comparing on those earlier layers and see that we get a completely different result because now we're optimizing to some image that is a lot closer to the original. It still doesn't look exactly the same. And so there's a few things that I thought were worth noting, just potentially of interest. One is that we're looking into these early layers, which might mean, for example, that if you're looking at the very early layers, you're missing out on some kinds of features. That was one of my guesses as to why this didn't have as dark a dark as the input image. And then also we still have this thing where we might be going out of bounds to get the same kinds of features. So, yeah, you can see how by looking at really deep layers, we really don't care about the color or texture at all. We're just getting like sunglasses bits and nosy bits there. By looking at the earlier layers, we have much more rigid adherence to the sort of lower level features as well. And so this is nice. It gives you a very tunable way to compare two images. You can say, do I care that they match exactly on pixels? Then I could use mean squared error. But do I care quite a lot about the exact match? Then I can use maybe some early layers. But do I only care about like the overall semantics? In that case, I can go to some deeper layers. And you can experiment with. If I remember correctly, this is also something like the kind of technique that Zyler and Fergus and the distilled up pub papers used to like just identify like what do filters look at, which is like you can optimize an image to try and maximize a particular filter. For example, that would be a similar loss function to the one you've built here. And that would show you what they're looking at. Yeah. And that would be a really fun little project, actually. So do it where you calculate these feature maps and then just pick one of those 512 features and optimize the image to maximize that activation. By default, you might get quite a noisy, weird result, like almost an adversarial input. And so what these feature visualization people do is they add things like augmentations so that you're optimizing an image that even under some augmentations still activates that feature. But yeah, that might be a good one to play with. Cool. OK, so we have a lot of our infrastructure in place. We know how to optimize an image. We know how to extract features from this neural network. And we're saying this is great for comparing at these different kind of types of feature how similar two images are. The final piece that we need for our full style transfer artistic application is to say I'd like to keep the structure of this image, but I'd like to have the style come from a different image. And you might think, oh, well, that's easy. We just look at the early layers like you've shown us. But there's a problem, which is that these feature maps by default, we feed in our image and we get these feature maps. They have a spatial component, right? We said we had a 32 by 32 by 512 feature map out. And each of those locations in that 32 by 32 grid are going to correspond to some part of the input image. And so if we just said, let's do mean squared error. For the activations from some early layers, what we'd be saying is I want the same types of feature, like the same style, the same textures. And I want them in the same location. Right. And so we can't just get like Van Gogh brush strokes. We're going to try and have the same colors in the same place and the same textures in the same place. And so we're going to get something that just matches our image. What we'd like is something that has the same colors and textures, but doesn't. But there might be in different parts of the image. So we want to get rid of this spatial aspect. Just to clarify, when we're saying to it, for example, give it to us in the style of Van Gogh's Starry Night, we're not saying in this part of the image there should be something with this texture. But we're saying that the kinds of textures that are used anywhere in that image should also appear in our version, but not necessarily in the same place. Exactly. And so the solution that Zylor and Thurgisson proposed is this thing called a Grammatrix. So what we want is some measure of what kinds of styles are present without worrying about where they are. And so there's always a trouble trying to represent more than two dimensional things on a 2D grid. But what I've done here is I've made our feature map, right, where we have our height and our width that might be 32 by 32 and some number of features. But instead of having those be like a third dimension, I've just represented those features as these little colored dots. And so what we're going to do with the Grammatrix is we're going to flatten out our spatial dimension. So we're going to reshape this so that we have the width times the height. So that like the spatial location on one axis and the feature dimension on the other. And so each of these rows is like this is the location here. There's no yellow dot. So we get a zero. There's no green. So we get a zero. There is a red and a blue. So we get ones. So we've kind of flattened out this feature map into a 2D thing. And then instead of caring about the spatial dimension at all, all we care about is which features do we have in general, which types of features and do they occur with each other. And so we're going to get effectively the dot products of this row with itself. And then this row with the next row and this row with the next row. We're saying like for these feature vectors, how correlated are they with each other? Right. And so we'll see this in code just now. I think you might have said, I might have misheard you, but I just want to make sure I got the citation here. Right. So this idea came from, I don't know if it was first invented in the Gattis et al. paper. Yes. Sorry. Neural algorithm of artistic style. Yeah. Yeah. I meant Gattis, that's the style transfer one. Cider and Ferguson is the feature visualization one. Yeah. Sorry, I got that switched. Thanks. Thanks, Jeremy. Okay. So we are ending up with this kind of like this Gram matrix, this correlation of features. And the way you can read this in this example is to say, okay, there are seven reds, right? Red with red. There's seven in total. And if you go and count them, there's seven there. And then if I look at any other one in this row, like here, there's only one red that occurs alongside a green, right? This is the only location where there's one red cell and one green cell. There's three reds that occur with a yellow. They're there and there. And so this Gram matrix here has no spatial component at all. It's just the feature dimension by the feature dimension. But it has a measure of how common these features are. Like what's an uncommon one here? Yeah. Maybe there's only three greens in total, right? And all of them occur with alongside a yellow. One of them occurs alongside a red, one of them occurs alongside a blue. Yeah. So this is exactly what we want. This is some measure of what features are present, where if they occur together with other features often, that's a useful thing. But it doesn't have the spatial component. We've gotten rid of that. And this is the first. Clear explanation I've ever seen of how a Gram matrix works. This is such a cool picture. I also want to, maybe you can open up the original paper, because I'd also like to encourage people to look at the original paper, because this is something we're trying to practice at this point is reading papers. And so hopefully you can take Jono's fantastic explanation and, yeah, and bring it back to understanding the paper. As well. That's crazy that it's put it so far down. Oh, yeah. It's a different search engine that I'm trying out that has some AI magic, but they use Bing for their actual searching, which. Right. That's smart one. The best, yeah. And yeah, so we can quickly check the paper. I don't know if I've actually read this paper, as horrific as that sounds. Not horrific at all. It was a while ago. But I think it's got some nice pictures and I'm going to zoom in a bit. Oh, good idea. Okay. They're the examples. It's great examples. Yeah. Not for Kandinsky. Sorry about the doorbell. Okay. Yeah. The Gram matrix, inner product between the vectorized feature map. So those kinds of wordings kind of put me off for a while. The way I explained Gram matrices when I had to deal with them at all was to say, it's magic that measures with, you know, what features are there without worrying about where they are and left it at that. And it is worth, yeah, trying to decode this back. They talk about which layers they're looking into. I think in TensorFlow they have names. We're just using the index. Okay. Yeah. So it doesn't really explain how the Gram matrix works, but it's something that people use historically in some other contexts as well. And for the same kind of measure. Nowadays, actually PyTorch has named parameters and I don't know if they've updated VGG yet, but you can name layers of a sequential model as well. Yeah. Okay. So just quickly, I wanted to implement this diagram in code. I should mention these are like zero or one for simplicity, but you could have like obviously different size activations and things. The correlation idea is still going to be there, just not as easy to represent visually. And so we're going to do it with an Einstein because it makes it easy to add later the bash dimension and so on. But I wanted to also highlight that this is just this matrix multiplied with its own transpose. And you're going to get the same result. So, yeah, that's our Gram matrix calculation. There's no magic involved there as much as it might seem like it. And so we can now use this, like, can we create this measure and then can we do optimization? When you look later at things like Word2Vec, I think it's got some similarities, this idea of kind of co-occurrence of features. And it also reminds me of the clip loss, similar idea of like basically a dot product, but in this case with itself. I mean, we've seen how co-variance is basically that as well. So this idea of kind of like multiplying with your own transpose is a really common mathematical technique we've come across three or four times in this course. Yeah. And it comes up all over the place. Even, yeah, you'll see that in protein folding stuff as well. They have a big co-variance matrix for like. So the difference in each case is like, yeah, the difference in each case is the matrix that we're multiplying by its own transpose. So for co-variance, the matrix is the matrix of differences to the mean, for example. And yeah, in this case, the matrix is this flattened feature thing. Cool. So I have here the calculate grams function that's going to do exactly that operation we did above, but we're going to add some scaling. And the reason we're adding the scaling is that we have this feature map and we might pass in images of different sizes. And so what this gives us is the absolute, like you can see there's a relation to the number of spatial locations here. And so by scaling by this width times height, we're going to get like a relative measure as opposed to like an absolute measure. It just means that the comparisons are going to be valid even for images of different sizes. And so that's the only extra complexity here. But we have a channels by height by width image in and we're going to pass in, oh sorry, this is like channels being the number of features. We're going to pass in two versions of that, right? Because it's the same image in both times. But we're going to map this down to just the features by features, but you can't repeat variables in Einstein. So that's why it's C and D. And if we run this on our style image, you can see I'm targeting five different layers. And for each one, the first layer has 64 features. And so we get a 64 by 64 gram matrix. The second one has 128 features. We can get 120 by 128 gram matrix. So this is doing, it seems like what we want. And because this is a list, we can use this at or got method, which I will actually. It's a fast call capital L, not a list. Sorry. Yeah. Magic list. That's what I like to think about. Yeah. So either works. Okay. So let's use this as a loss. Just like with the content loss before, we're going to take in a target image, which is going to be our style. We're going to calculate these gram matrices for that. And then when we get in an input to our loss function, we're going to calculate the gram matrices for that and do the mean squared error between the gram matrices. So these are the no spatial components, just what features are there, comparing the two to make sure that they're ideally have the same kinds of features and the same kinds of. Correlations between features. So we can set that up. We can evaluate it on my image. So our content image at the moment has quite a high loss when we compare it to our style image. And that means that our content image doesn't look anything like a spider web in terms of its textures and whatever. Exactly. So we're going to set up an optimization thing here. One difference is that at the moment I'm starting from the content image itself rather than optimizing from random noise. You can choose either way. For style transfer, it's quite nice to use the content image as a starting point. And so you can see at the beginning, it just looks like our content image. But as we do more and more steps, we maintain the structure because we're still using the content loss as one component of our loss function. But now we also have more and more of the style because of the early layers we're evaluating that style loss. And you can see this doesn't have the same layout as our spider web, but it has the same kinds of textures and the same types of structure there. And so we can check out the final result and you can see it's done ostensibly what our goal is. It's taken one image and it's done it in the style of another. And to me, this is quite satisfying. And it's actually done it in a particularly clever way because look at her arm. You know, her arm has the spider web nicely laid out on it. And she's almost like picking it out with her fingers. And her face, you know, which is kind of quite an important or very important in terms of like object recognition. The model didn't want to mess with the face much at all. So it's kept the spider webs away from that. Like I think it's the more you look at it, the more impressive it is in how it's managed to find a way to add spider webs without messing up. The overall kind of semantics of the image. Yeah. Yeah. So this is really fun to play with. If you've been running the notebook with the demo images, please like right now go and find your own pictures. Make sure you're not stealing someone's licensed work. But there's lots of creative commons images out there and try bash them together. Do it at a larger size, you know, get some higher resolution style loss going. And then there's so much that you can experiment with. So, for example, you can change the content loss to focus on maybe an earlier layer as well. You can start from a random image instead of the content image, or you can start from the style image and optimize towards the content image. You can change how you scale these two components of the loss function. You can change how long you train for, what your learning rate is. All of this is up for grabs in terms of what you can optimize and what you can explore. And you get different results with different scalings and different focus layers. So there's a whole lot of fun experimentation to be done in terms of finding a set of parameters that gives you like a pleasing result for a given style content pair and for a given effect that you want on the output. Yeah. On that note, I wanted to like, one of the really interesting things about this is just, you know, how well Ouija works as a network, even though it's a very old network. But I think it's also worth playing around with other networks as well. I think there's definitely some special properties of VGG that allow for it to do well for style transfer. And there are a few papers on that. And there are also some papers that explore how we can use maybe other networks for style transfer that maintains maybe some of these nice properties of VGG. So I think that could be interesting to explore some of these papers. And of course, we have this very nice framework that allows us to easily plug and play, you know, different networks and try that aspect out as well. Yeah. And in particular, I think taking a ConvNext or a ResNet or something and replacing its head with a VGG head would be an interesting thing to try. Yeah. And then on the experimentation version, one of the things that when we were developing this, I said to Jeremy was like, ah, we're doing all this work, setting up these callbacks and things, you know, isn't it nicer to just have like, here's my image that I'm optimizing, set up an optimizer, set up my loss function and do this optimization loop? And the answer is that it is theoretically easier when you just want to do this once. Like, and that's why you see in a tutorial or something, you keep this as minimal as possible. You just want to show what style loss is. But as soon as you say, OK, I'd like to try this again, but adding a different layer. So maybe let me do another cell and then copying and pasting over a bunch, you know, and then you say, oh, let me add some progress stuff. So images, you know, it gets messy really quickly. As soon as you want to save images for a video and you want to mess with the loss function and you want to do some sort of annealing on your learning rate, each of these things is going to grow this loop into something messier and messier. Yeah. And so I thought it was fun. Like, I was very quickly a convert to being able to experiment with a completely new version with minimal lines of code, minimal changes and having everything in its own piece, like the image logging or if you wanted to make a little movie showing the progress, that goes in a separate callback. You want to tweak the model, you're just tweaking one thing, but maybe all the other infrastructure can stay the same. Yeah. So that was pretty cool. I mean, there's not like one answer, right? Like it's, yeah. Use the right layer of abstraction for what you're doing at the right time. Like something I actually think people do too much of when they use the fast AI library is jumping straight into data blocks, for example, even though they might be working on a slightly more custom thing where data blocks, there isn't a data block already written for them. And so then step one is like, oh, write a data block. That's not at all easy. And you actually want to be focusing on building your model. So I kind of say to people, oh, well, like, you know, go, go down a layer of abstraction. Now I will say I don't very often start at the very lowest level of abstraction. So something like the very last thing that you showed, Jono, just because in my experience, I'm not good enough to do that. Right. And so like most of the time I, yeah, I'll forget zero grad or I'll just mess up something, especially if I want to like have it run reasonably quickly by using like, you know, FB16, mixed precision or, you know, or I'll be like, oh, now I've got to like think about how to put a metrics in so that I can see it's training properly. And I always mess that up. So I don't often go to that level, but I do like quite often start at a reasonably low level. And I think with mini AI now we all have this tool where we fully understand all the layers and there aren't that many. And yeah, you could like write your own train CB or whatever. And at least you've got something that makes sure, for example, that, oh, okay. You remember to use torch.no grad here and you remember to put it in, you know, put it in a vowel mode there. But, you know, those things will be done correctly. And you'll be able to easily run a learning rate finder and easily have it run on Cuda and, you know, or whatever device you're on. So I think, you know, hopefully this is a good place for people now to have a framework that they can call their own. You know, and use as much as there's no good as big sense. The other nice thing is of course, like there are multiple ways of doing the same thing and it's like whatever way maybe works better for you. You can implement that. Like, for example, Jonathan showed with the image opt callback, you know, you could implement that in different ways and whichever one I guess is easier for you to understand or easier for you to work with. It's, you can implement it that way. And yeah, MiniAI is flexible in multiple ways. So that's the especially one thing I really enjoy about it. Yeah. And there's one extreme of like weirdness, I think, which is like Jono's like using MiniAI for something that we never really considered making it for, which is like, it's not even looping through data. It's just looping through loops. So, you know, this is about as weird as it's going to get, I guess. Yeah. Well, the next notebook is about as weird as it's going to get, I think. Oh, great. Yeah. Okay. So before we move on to what we're going to do next is use this kind of style loss in an even funkier way to train a different kind of thing. But before we do that, I did want to just call out like using these pre-trained networks as very smart feature extractors is pretty powerful. And unlike the kind of fun, crazy example that we're going to look at just now, they also have very valid uses. So if you're doing like a super resolution or even something like diffusion, adding in a perceptual loss or even a style loss to your target image, it can improve things. We've played around with using perceptual loss for diffusion or even during, like, say you want to generate an image that matches a face in some kind of image to image thing with stable diffusion. Maybe you have an extra guidance function that makes sure that structurally it matches, but maybe a text really doesn't. Maybe you want to pass in a style image and have that guide to the diffusion process to be a particular style without having to say, you know, in the style of Vincent van Gogh's Starry Night. Yeah. And for all sorts of like image to image tasks, this perceptual, this idea of like using the features from a network like VGG, it does actually have lots of practical uses apart from just this artistic and kind of fiddling. Okay. So speaking of artistic fiddling, we're going to look at something a little bit more niche now called neural cellular automata. And so try and spend about half an hour on this before we move on to the next section. And so this is off the beaten track. It's a really fun domain of, yeah, like combining a lot of different fields, all of which I'm quite excited about. And so you may be familiar with like kind of classic cellular automata. So if we look at Conway's Game of Life, Oops, I misspelled it, but you've probably seen this kind of classic Conway's Game of Life. I almost came up with that game of life when I was a kid. Yeah. So the idea here is that you have all of these independent cells and each cell can only see its neighbors. And you have some sort of update rule, right? That says if a cell has three neighbors, it's going to remain the same state for the next one. If it has only one neighbor, it's going to die in the next iteration. And so this is a really cool example of like a distributed system or self-organizing system where there's no like global communication or anything. Each cell can only look at its immediate neighbors. And typically the rules are really small and simple. And so we can use these to model these complex systems. It's very much inspired by biology where we actually do have huge, you know, arrangements of cells, each of which is only seeing its neighborhood, like sensing chemicals in the bloodstream next to it and so on. And yet somehow they're able to coordinate together. I watched a really cool video the other day about ants. And I didn't know this before, maybe everybody else does, but ants, like huge ant colonies, are organized by like having little chemical signals that the ants around can smell. And yeah, it can like organize the entire massive ant colony just using that. I thought it was crazy, but it sounds really similar. Yeah, yeah. And you could do. So let me do my tangent. You could do very similar things where you have, yeah, like the trails, the chemical trails being left are just like pixel values in some grid and your ants are just little tiny agents that have some rules. And so I should probably link this here, but this is exactly that kind of system, right? Each little tiny dot, which are almost too small to see, is leaving behind these different trails. And then that determines the behavior. The difference between this and what we're going to do today is that. Just to clarify, I think you've told me before that like actual slime molds kind of do this, right? They're another example. Yes. Yeah, yeah, exactly. There's some limited signaling. Each one is like, oh, I'm by food. And then after that, that signal is going to propagate and anything that's moving is going to follow. And so, yeah, if you play with this kind of simulation, you often get patterns that look exactly like emergent patterns in nature, like ants moving to food or, you know, corals coordinating and that sort of thing. So it's a very biologic field. The difference with our cellular automata is that they're going to be, there's nothing moving. Each, like, grid cell has its own little agent. And so there's no like wandering around. It's just each individual cell looking at its neighbors and then updating. And just to clarify, when you say agent, that can be really simple. Like, I don't really remember, but I vaguely remember that Conway's gain of life. It's kind of like a single kind of if statement. It's like if there's, I don't know, what is it, two cells around, you get another one or something. Yeah. Yeah. If there's two or three nearby, you stay alive in the next one. If you're overcrowded with four or five or there's no one near you with zero or one neighbors, then you're going to die. So it's a very, very simple rule. But what we're going to do today is replace that hard-coded if statement with a neural network and in particular, a very small neural network. So I should start with the paper that inspired me to like even begin looking at this. So this is by Alexander Mordvintsev and a team with him at Google Brain, and they built these neural cellular automata. So this is a pixel grid. Every pixel is a cellular automata that's looking at its neighbors and they can't see the global structure at all. And it starts out with a single black pixel in the middle. And if you run the simulation, you can see it builds this little lizard structure, this little emoji. So that's wild to me that a bunch of pixels that only know about their neighbor can actually create such a large and sophisticated image. Yeah, they can self-assemble into this. And what's more, the way that they train them, they are robust. They're able to repair damage. And so there's no, it's not perfect, but there's no global signaling. No little agent here knows what the full picture looks like. It doesn't know where in the picture it is. All it knows that its neighbors have certain values. And so it's going to update itself to match those values. And so you can see... I mean, this does seem like something that ought to have a lot of use in the real world with like, I don't know, like having a bunch of drones working together when they can't contact, you know, some kind of central base. I'm thinking about like work that some Australian folks have been involved in where they were doing like automated subterranean rescue operations. And they've like, you literally can't communicate through thousands of meters of rock, stuff like that. Yeah. Yeah. So this idea of like self-organizing systems, there's a lot of promise for like nanotechnology and things like that that can do pretty amazing things. This is the blog post that's linked. Yeah. The future of artificial intelligence is self-organizing and self-assembling. Oh, cool. And definitely, yeah. That's a pattern that's worked really well in nature, right? Like lots of loosely coordinated cells coming together and talking about deep learning is quite a miracle. And so I think, yeah, that's an interesting pattern to explore. Okay. So how do we train something like this? How on earth do you set up your structure so that you can get something that not only builds out an image or builds out something like a texture, but then is robust and able to maintain that and keep it going? So the sort of base is that we're going to set up a neural network with some learnable weights that's going to apply our little update rule. Right. And this is just going to be a little dense MLP. And we can get our inputs, which is just the neighborhood of the cell. And they sometimes have like additional channels that aren't shown, but the agents can use this communication with their neighbors. So we can set this up in code. We'll be able to get our neighbors using maybe convolution or some other method, flatten those out and feed them through a little MLP and take our outputs and use that as our updates. Just to clarify something that I missed originally is this is not a simplified picture of it. This is it like that, that three by, like it's literally three by three. You're only allowed to see the things right next to you or they can be in a different channel. Exactly. And this paper has this additional step of like cells being alive or dead. But we're going to do one that doesn't even have that. So it's, it's even simpler than this diagram. Okay. So to train this, what we could do is we could start from our initial state, apply our network over some number of steps, look at the final output and compare it to our targets and calculate our loss. And you might think, okay, well, that's pretty cool. We can maybe do that. And if you run this, you do indeed get something that after some number of steps can learn to grow into something that looks like your target image. But there's this problem, which is that you're applying some number of steps and then you're applying your loss after that. But that doesn't guarantee that it's going to be stable. I hope so. There goes my phone. Stable longer term. And so we need some additional way to say, okay, I don't just want to grow into this image. I'd like to then maintain that shape once I have it. And the solution that this paper proposes is to have a pool of training examples. Right. And we'll see this in code just now. So the idea here is that sometimes we'll start from a random state. And we'll apply some number of updates. We'll apply our loss function and update our network. And then most of the time we'll take that final output and we'll put it back into the pool to be used again as a starting point for another round of training. And so this means that the network might see the initial state and have to produce the lizard. Or it might see a lizard that's already been produced. And after some number of steps, it still needs to look like that lizard. And so this is adding like an additional constraint that says even after much more steps, we'd still like you to look like this final output. And so, yeah, it's also nice because like I mentioned here, initially the model ends up in various incorrect states that don't look like a lizard, but also don't look like the starting point. And it then has to learn to correct those as well. So we get this nice additional robustness from this in addition. And you can see here now they have a thing that is able to grow into the lizard and then maintain that structure kind of indefinitely. And in this paper, they do this final step where they sometimes chop off half of the image as additional like augmentation. So you could have like a bunch of drones or something that like can only see the ones nearby and they don't have GPS or something. And a gust of wind could come along and set them off path and they still reconfigure themselves. Yeah, yeah, exactly. Half of them go offline and run out of battery. That's fine. So very, very cool paper. But you can see this kind of training is a little bit more complicated than, oh, we just have a network and some target outputs and we optimize it. So we're not going to follow that paper exactly, although it should be fairly easy to tweak what we have to match that. We're instead going to go for a slightly different one by the same authors where they train even smaller networks to match textures. And so you can imagine our style loss is going to come in useful here. We'd like to produce a texture without necessarily worrying about the overall structure. We just want the style. And so the same sort of idea, the same sort of training. We're going to start from random and then after some number of steps, we'd like it to look like our target style image. And in fact, there actually is a spider web, which I hadn't noticed until now. And that's the one thing that makes a texture a texture in this case, is it's something you can tile nicely. Is that? Yes. Yeah. And so that tiling is going to come almost for free. So we're going to have our input. We're going to look at our neighbors. We're going to feed that through a network and produce an output. And every cell is going to do the same rule, which will work fine by default if we set this up without thinking about tiling at all. Except that at the edges, when we do like say a convolution to get our neighbors, we need to think about what happens for the neighbors of the cells on the edge. Which ones should those be? And by default, those will just be padding of zero. And so those cells in the edge, A, they'll know they're on the edge. And B, they won't necessarily have any communication with the other side. If we want this to tile, what we're going to do is we're going to set our padding mode to circular. In other words, the neighbors of this top right cell are going to be these cells next to it here and these cells down in the bottom corner. And then for free, we're going to get tiling. Okay. So enough waffle. Let's get into code. We're going to download our style image. Oops. Need to do my imports. This is going to be our target style image. And again, feel free to experiment with your own, please. We're going to set up a style loss, just like we did in lesson 17a. The difference being that we're going to have a batch dimension to our inputs to this calculate grams function, which I didn't do in the style transfer example, because you're always dealing with a single image. Everything else is going to be pretty much the same. So we can set up our style loss with the target image, and then we can feed in a new image or in this case, a batch of images, and we're going to get back a loss. So we're, we're setting up our, our evaluation. We would like after some number of steps, our output to look like a spiderweb. Okay. Let's define our model. And here I'm making a very small model with only four channels and our hidden number of hidden neurons in the brain is just going to be eight. You can increase these. Something I would be inclined to do. People might want to play with in style loss to target is you're giving all the layers the same weight. You know, a nice addition would be to have a vector of weights. You could pass in an experiment with that. Definitely. All right. So the, the world in which these cellular automata are going to live is going to be a grid. We're going to have some number of them. If we call this function number of channels and the size, you could make it non-square if you cared about that. For our perception in this little diagram here, we're going to use some hard coded filters. And you could have these be learned, right? There'd be additional weights in the neural network. The reason they're hard coded is because the people who are working behind this paper, they wanted to keep the parameter counts really low. Literally like a few hundred parameters total. And also they were kind of inspired by- A few hundred? That's crazy. Like, cause we've been, even now that old fashioned MNIST models have had quite a few million parameters. Yeah. So this is, this is a totally- So I should have mentioned that's one of the coolest things about these systems is they really can do a lot with very little parameters. And so these filters that we just going to hard code are going to be the identity, right? Just looking at itself. And then a couple that looking at gradients. Again, inspired by biology where even simple cells can sense gradients of chemical concentration. So we're going to have these filters. We're going to have a way to apply these filters individually. Just to help people understand that that first one, for example, that's a three by three. It's been kind of like visually flattened out. But if you were to kind of lay it out, you could see it's a identity matrix. Yeah. Anyway, so you can see these filters. This one is going to sense a horizontal gradient. This one is going to sense a vertical gradient. And the final one is called a Sobel filter. And yeah, so we've got some hard coded filters. We're going to apply them individually to each channel of the input. And rather than having a kernel that has separate weights for each channel on the input. And so we can make a grid. We can apply our evolution. I didn't know circular was a padding mode before. So that just does the thing you said where it's basically going to circle around and kind of copy in the thing from the other side when you reach the edge. Yeah. Yeah. And this is very useful for avoiding issues on the edges with. So as you'll see, a lot of a little bit of limitations just deal with the fact that they have slightly weird pixels around the edge and they don't really look into it. And this is one way to deal with that. Yeah. Okay. So we can make a grid. We can apply our filters to get our model inputs. And this is going to be 16 inputs, right? Because we have four channels and four filters. 16 inputs. That's going to be the input to our little brain. And we have this for every location in the grid. So now how do we implement that little neural network that we saw? The way it's shown in the diagram is it's a dense linear network and we can set that up. We have a linear layer with number of channels by four, which is the number of filters as its number of inputs, some hidden number of neurons. We have a ReLU and then we have a second linear layer that's outputting one output per channel as the update. And so if we wanted to use this as our brain, what we'd have to do is we'd have to deal with this, these extra dimensions. So we take our batch by channel by height and width. We're going to map the batch and the height and the width all to one dimension and the channels to the second dimension. So now we have like a big grid of 16 inputs and lots of examples. I don't think we've seen inops.rearrange before. So let's like put a bit of a bookmark to come back to teach people about that in maybe in the next video. Very, very useful function. But it is a little complicated because we have to rearrange our inputs into something that has just 16 features, feed that through the linear layer and then rearrange the outputs back to match the shape of our grid. So you can totally do that and you can see what parameters we have on our brain. We have an 8 by 16 inputs and 8 biases for the first layer. And then we just have a 4 by 8 weight matrix for the second linear layer. And I've said bias equals false because we're having these networks propose an update. And if we want them to be stable, the update is usually going to be zero or close to it. And so there's no need for the bias. And we want to keep the number of parameters as low as possible. That's kind of the name of the game. And so that's why we're setting bias equals false. OK, so this is one way to implement this. It's not particularly fast. We have to do this reshaping and then we're feeding these examples through the linear layer. We can cheat by using convolution. So this might seem like, wait, that isn't a linear layer. We're going to apply this linear network on top of each set of inputs. But we can do that by having a filter size of one, a kernel size of one in our convolutional layer. So I have 16 input channels in my model input here. And I'm going to have eight output channels from this first convolutional layer. And my kernel size is going to be one by one. And then I have ReLU and then I have another one by one convolutional layer. And so we can see this gives me the right shape output. And if I look at the parameters, my first convolutional layer has eight by 16 by one by one parameters in its filters. And so maybe spend a little bit of time convincing yourself that these two are doing the same operation. Yeah, this stuff is using shading. I mean, this is quite elegant. And in languages like APL, actually, there's an operation called stenciling, which is basically the same idea. It's this idea of like applying some computation over a grid. Yeah. And I should mention that convolutions are very efficient. All of our GPUs and things are set up for this kind of operation. And what makes neural cellular automata quite exciting is that because we're doing this convolution, you have an operation for every pixel that we're applying. Right. And this is looking at the neighborhood of reducing an output. There's no global thing that we need to handle. And so this is actually exactly what GPUs were designed for. They're designed for running some operation for every pixel on your screen to render graphics or show you your video game or make your website scroll nice and slick. And so we can take advantage of that kind of built in bias of the hardware from doing lots of little operations in parallel to make these go really, really fast. And we'll show I'll show you just now we can run these real time in the browser, which is quite satisfying. OK, so now that we have all that infrastructure in place, I'm just going to put it into a class. My simple CA is my cellular automata. We have our little brain, two convolutional layers and a value. Optionally, we can set the weights of the second layer to zero again, because you want to start by being very conservative in terms of what updates we we produce. Not necessarily necessary, but it does help the training. And then in our forward pass. I would be inclined. I don't know if it matters, but I'd be inclined to put that. I would be inclined to do. You know, and in it. Constant zero or put that in a no grad, like often initializing things without no grad can cause problems. OK, I'll look into that. In the forward method, we're going to apply our filters to get our model inputs and then we've got data zero. OK, so that's that's fine. Yeah, I think this is the built in the built in method. All right. Oh, it's the dot data, which is the thing that makes it. Yeah. You don't need torch dot no grad because you've got dot data. So. Yeah, it's all good. And cool. OK. And so the forward is applying the filters. It's feeding it through the first convolutional layer, then the ready, then the second layer. And then it's doing this final step, which again goes back to the original paper. Somewhere in here, they mentioned that they are inspired by biology. And one thing that you don't have in a biological system is some sort of global clock where everything updates at exactly the same second. It's much more random and organic. Each one is almost independent. And so to mirror that, what we do here is we create a random update mask. And if you go in, let's just actually write this out. Let's just make a cell and check that this is what we're doing. So I'm going to just go mvhw1 just to visualize. Update rate. There we go. Yeah. So this is creating this random mask, some zeros and some ones according to what our update rate is. And this is going to determine whether we apply this update to our original input or not. It's a lot like dropout. This is my what? Yeah, it's like dropout. Exactly. And why this is nice, if you imagine we start from a perfectly uniform grid and then every cell is running the exact same rule, after one update, we will still have a perfectly uniform grid. There's no way for there to be any randomness. And so we can never break out of that. Whereas once we add this random updates, only a subset of cells are going to be updated. And now there's some differences. They have different neighborhoods and things. And so then we get this added randomness in. And this is very much like in a biological system, no cell is going to be identical. So that's a little bit of additional complexity, but again, inspired by nature and inspired by paper. With all of this in place, we can do our training. We're going to use the same dummy dataset idea as before. We are going to have a progress callback, which is a lot of code, but it's all just basically sitting around for doing some plotting. So I'm not going to spend too much time on that. And then the fun stuff is going to happen in our training callback. And so now we are actually getting deep into the weeds. We're modifying our prediction function. This is much more complicated than just feeding a batch of data through our model. We are setting up a pool of grids, 256 examples. And these are all going to start out as just uniform zeros. But every time we call predict, we're going to pick some random samples from that pool. We are occasionally going to reset those samples to the initial state. And then we can apply the model a number of times. And it's worth thinking here, if we are applying this model 50 steps, this is like a 50 layer deep model all of a sudden. And so we start to get some of the same issues. Is that learn.model rather than self.learn.model? Oh, yes, because I already have learn. Nice. And yeah, so we've got to just be aware that by applying this a large number of times, we could get something like gradient exploding and things like that, which we'll deal with a little bit later. And but we apply the model a large number of steps. Then we put those final outputs back in the pool for the next round of training and we store our predictions. These are the outputs after we've applied a number of steps. And in the loss, we're going to use a style loss saying, does this match the style of my target image? And we're going to add an overflow loss that penalizes it if the values are out of bounds. Just to try and change self.learn here too. Yes. I think I read this before we changed the note. Because I've got the callback there. Okay, my bad. One more self.learn.preds.clamp in the overflow loss one. Yes, thank you. There we go. And yeah, so get loss is doing a style loss plus this overflow loss just to keep things from growing exponentially out of bounds. Again, something that's quite likely to happen when you're applying a large number of steps. And so we really want to penalize that. And the final thing is in learn.backward, I've added a technique that is probably going to be quite useful in some other places as well called gradient normalization. And so we're just running through the parameters of our model, and we are normalizing them. And this means that even if they're really, really tiny, really, really large at the end of that multiple number of update steps, this is kind of a hack to bring this back into control. And Jeremy, I think you have more. So let's put a bookmark to come back to that as well in more detail. Might come back to that. And I guess that before fit, maybe we don't need anymore. Oh, right, because this is now default. Okay. Oh, so I should have set this running before we started talking. It is going to take a little while. But you can see my progress callback here is scatterplotting the loss. And the reason I'm, you'll see in the callback here, I'm setting the Y limits to the minimum of the initial set of losses. It's just because the overflow loss is sometimes so much larger than the rest of the loss ones that you get this really like bad scaling. So using a log scaling and clipping the bounds tends to help just like visualize what's actually important, like the overall trend. I guess the last bit does not run. We can, then we can see it without you running it. Oh, right. Yeah. Yeah. So you can see the outputs here. And so what I'm visualizing is the examples that we've drawn from the pool. Every time we're drawing, in this case, I've got a fixed batch size that should probably be an argument. But you can take a look at them and kind of compare them to the style loss and see initially that I really look too similar. After some training, we get some definite like webby tendencies. And we can take this model and then apply it to like a random grid and log the images, you know, every hundred steps or whatever. And you can see that starting from this random position, it quite quickly, you know, builds this pattern. It doesn't look perfectly spider webby. But in its defense, this model has 168 parameters. And a tiles. That to me is like the magic of these models is that even with very few parameters, they're able to do something pretty impressive. And if you would like, go back up to where we define number of channels and number of layers. If you give it more channels to work with, 8 or 16, and more hidden neurons, 32 or 64, you still have a tiny model. But it's able to capture some much nicer. So I would say, please, on the forums, try some larger sizes. I'll also maybe post some results. And just to give you a little preview of what's possible. So I did a project before using MiniAI. So the code's a little messy and hacky. But what I did was I logged the cellular automata. Well, maybe I should show this. We, this is way outside the bounds for this course, but you can write something called a fragment shader in WebGL. So this is designed to run in the browser. It's a little program that runs once for every pixel. And so you can see here, I have the weights of my neural network. I have sampling the neighborhood of each cell. We have our filters. We have our activation function. This is in a language called GLSL. We're running through the layers of our network and proposing our updates. And this one here, I just had more, I think, more hidden neurons, more channels. And optimized with a slightly different loss function. So it was a style loss plus clip to the prompt, I think, dragon scales or glowing dragon scales. And you can see this is running in real time or near real time because I'm recording. And it's interactive. You can click to kind of like zero out the grid and then see it like rebuild within that. And so in a similar way, in this weights and biases report, I'm logging these kind of interactive HTML previews. We've got some videos and just logging the grids from the different things. And so you can see these are still pretty small as far as these networks go. I think they only have four channels because I'm working with RGBA shaders. But quite fun to see what you can do with these. And if you pick the right style images and train for a bit longer and use a few more channels, you can do some really fun stuff. And you can get really creative applying them at different scales. Or I did some messing around with video, which again is just like messing with the inputs to different cells to try and get some cool patterns. So, yeah, to me, this is a really exciting, fun... Amazing. ...niche. Yeah, I don't know if there's too many practical applications at this stage, but I'm already thinking of denoising cellular automata and stylizing or image restoration cellular automata. And you can really have a lot of fun with this structure. And I also thought it was just a good demo of like how far can we push what you can do with a training callback to have this like pool training and the, you know, like gradient normalization and all these extra things added in. Very, very different from here's a batch of images and a batch of labels. So I hope you found that interesting. And I'll stop sharing my screen. And then, Jeremy, if you have any questions or follow ups. No, that's amazing. Thank you so much. I actually have to go. But that's just one of the coolest things I've seen.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.24, "text": " Hi and welcome to lesson 20. In the last lesson we were about to learn about implementing", "tokens": [50364, 2421, 293, 2928, 281, 6898, 945, 13, 682, 264, 1036, 6898, 321, 645, 466, 281, 1466, 466, 18114, 50676], "temperature": 0.0, "avg_logprob": -0.249159038066864, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0021820170804858208}, {"id": 1, "seek": 0, "start": 6.24, "end": 14.08, "text": " mixed precision training. Let's dive into it. So to, and I'm going to fiddle with other", "tokens": [50676, 7467, 18356, 3097, 13, 961, 311, 9192, 666, 309, 13, 407, 281, 11, 293, 286, 478, 516, 281, 24553, 2285, 365, 661, 51068], "temperature": 0.0, "avg_logprob": -0.249159038066864, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0021820170804858208}, {"id": 2, "seek": 0, "start": 14.08, "end": 18.56, "text": " things just because I want to really experiment. I just love fiddling around. So one thing", "tokens": [51068, 721, 445, 570, 286, 528, 281, 534, 5120, 13, 286, 445, 959, 283, 14273, 1688, 926, 13, 407, 472, 551, 51292], "temperature": 0.0, "avg_logprob": -0.249159038066864, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0021820170804858208}, {"id": 3, "seek": 0, "start": 18.56, "end": 28.54, "text": " I wanted to do is I wanted to get rid of the ddpmcb entirely. We made it pretty small here,", "tokens": [51292, 286, 1415, 281, 360, 307, 286, 1415, 281, 483, 3973, 295, 264, 274, 67, 14395, 66, 65, 7696, 13, 492, 1027, 309, 1238, 1359, 510, 11, 51791], "temperature": 0.0, "avg_logprob": -0.249159038066864, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0021820170804858208}, {"id": 4, "seek": 2854, "start": 28.54, "end": 33.54, "text": " but I wanted to remove it. So much as Janice said, isn't it great the callbacks make everything", "tokens": [50364, 457, 286, 1415, 281, 4159, 309, 13, 407, 709, 382, 4956, 573, 848, 11, 1943, 380, 309, 869, 264, 818, 17758, 652, 1203, 50614], "temperature": 0.0, "avg_logprob": -0.26087775281680525, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.0031725801527500153}, {"id": 5, "seek": 2854, "start": 33.54, "end": 39.0, "text": " so cool? I wanted to show we can actually make things so cool without callbacks at all.", "tokens": [50614, 370, 1627, 30, 286, 1415, 281, 855, 321, 393, 767, 652, 721, 370, 1627, 1553, 818, 17758, 412, 439, 13, 50887], "temperature": 0.0, "avg_logprob": -0.26087775281680525, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.0031725801527500153}, {"id": 6, "seek": 2854, "start": 39.0, "end": 45.480000000000004, "text": " And so to do that I realized what we could do is we could put noisify inside a collation", "tokens": [50887, 400, 370, 281, 360, 300, 286, 5334, 437, 321, 727, 360, 307, 321, 727, 829, 572, 271, 2505, 1854, 257, 1263, 399, 51211], "temperature": 0.0, "avg_logprob": -0.26087775281680525, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.0031725801527500153}, {"id": 7, "seek": 2854, "start": 45.480000000000004, "end": 52.86, "text": " function. So the collation function, if you remember back to our datasets notebook, which", "tokens": [51211, 2445, 13, 407, 264, 1263, 399, 2445, 11, 498, 291, 1604, 646, 281, 527, 42856, 21060, 11, 597, 51580], "temperature": 0.0, "avg_logprob": -0.26087775281680525, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.0031725801527500153}, {"id": 8, "seek": 5286, "start": 52.86, "end": 58.66, "text": " was going back to notebook 5, and you've probably forgotten that by now. So go and", "tokens": [50364, 390, 516, 646, 281, 21060, 1025, 11, 293, 291, 600, 1391, 11832, 300, 538, 586, 13, 407, 352, 293, 50654], "temperature": 0.0, "avg_logprob": -0.3146953229550962, "compression_ratio": 1.902127659574468, "no_speech_prob": 4.264730523573235e-05}, {"id": 9, "seek": 5286, "start": 58.66, "end": 67.02, "text": " reread that to remind yourself. It's the function that runs to take all of the, you know, you've", "tokens": [50654, 46453, 345, 300, 281, 4160, 1803, 13, 467, 311, 264, 2445, 300, 6676, 281, 747, 439, 295, 264, 11, 291, 458, 11, 291, 600, 51072], "temperature": 0.0, "avg_logprob": -0.3146953229550962, "compression_ratio": 1.902127659574468, "no_speech_prob": 4.264730523573235e-05}, {"id": 10, "seek": 5286, "start": 67.02, "end": 73.03999999999999, "text": " basically each kind of row of data, you know, will be a separate tuple. Then it hits the", "tokens": [51072, 1936, 1184, 733, 295, 5386, 295, 1412, 11, 291, 458, 11, 486, 312, 257, 4994, 2604, 781, 13, 1396, 309, 8664, 264, 51373], "temperature": 0.0, "avg_logprob": -0.3146953229550962, "compression_ratio": 1.902127659574468, "no_speech_prob": 4.264730523573235e-05}, {"id": 11, "seek": 5286, "start": 73.03999999999999, "end": 78.12, "text": " collation function and the collation function turns that into tensors, you know, one tensor", "tokens": [51373, 1263, 399, 2445, 293, 264, 1263, 399, 2445, 4523, 300, 666, 10688, 830, 11, 291, 458, 11, 472, 40863, 51627], "temperature": 0.0, "avg_logprob": -0.3146953229550962, "compression_ratio": 1.902127659574468, "no_speech_prob": 4.264730523573235e-05}, {"id": 12, "seek": 5286, "start": 78.12, "end": 81.58, "text": " representing the independent variable, one tensor representing the dependent variable,", "tokens": [51627, 13460, 264, 6695, 7006, 11, 472, 40863, 13460, 264, 12334, 7006, 11, 51800], "temperature": 0.0, "avg_logprob": -0.3146953229550962, "compression_ratio": 1.902127659574468, "no_speech_prob": 4.264730523573235e-05}, {"id": 13, "seek": 8158, "start": 81.89999999999999, "end": 87.74, "text": " something like that. And the default collation function is called, not surprisingly, default", "tokens": [50380, 746, 411, 300, 13, 400, 264, 7576, 1263, 399, 2445, 307, 1219, 11, 406, 17600, 11, 7576, 50672], "temperature": 0.0, "avg_logprob": -0.29286260283395144, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.00019110417633783072}, {"id": 14, "seek": 8158, "start": 87.74, "end": 96.06, "text": " collate. So if our collation function calls that on our batch, and then grabs the X part,", "tokens": [50672, 1263, 473, 13, 407, 498, 527, 1263, 399, 2445, 5498, 300, 322, 527, 15245, 11, 293, 550, 30028, 264, 1783, 644, 11, 51088], "temperature": 0.0, "avg_logprob": -0.29286260283395144, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.00019110417633783072}, {"id": 15, "seek": 8158, "start": 96.06, "end": 100.3, "text": " which is, it's always been the same for the last few things, that's the image because", "tokens": [51088, 597, 307, 11, 309, 311, 1009, 668, 264, 912, 337, 264, 1036, 1326, 721, 11, 300, 311, 264, 3256, 570, 51300], "temperature": 0.0, "avg_logprob": -0.29286260283395144, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.00019110417633783072}, {"id": 16, "seek": 8158, "start": 100.3, "end": 107.86, "text": " we use, because datasets uses dictionaries. So we're going to grab the image. Then we", "tokens": [51300, 321, 764, 11, 570, 42856, 4960, 22352, 4889, 13, 407, 321, 434, 516, 281, 4444, 264, 3256, 13, 1396, 321, 51678], "temperature": 0.0, "avg_logprob": -0.29286260283395144, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.00019110417633783072}, {"id": 17, "seek": 10786, "start": 107.86, "end": 116.1, "text": " can call noisify on that collated batch. Then that's exactly the same thing as Tanishq's", "tokens": [50364, 393, 818, 572, 271, 2505, 322, 300, 1263, 770, 15245, 13, 1396, 300, 311, 2293, 264, 912, 551, 382, 314, 7524, 80, 311, 50776], "temperature": 0.0, "avg_logprob": -0.27624749122781955, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.04207834601402283}, {"id": 18, "seek": 10786, "start": 116.1, "end": 120.26, "text": " before batch did. Right? Because before batch is operating on the thing that came out of", "tokens": [50776, 949, 15245, 630, 13, 1779, 30, 1436, 949, 15245, 307, 7447, 322, 264, 551, 300, 1361, 484, 295, 50984], "temperature": 0.0, "avg_logprob": -0.27624749122781955, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.04207834601402283}, {"id": 19, "seek": 10786, "start": 120.26, "end": 123.94, "text": " the default collate function. So we could just do it in a collate function. So if we", "tokens": [50984, 264, 7576, 1263, 473, 2445, 13, 407, 321, 727, 445, 360, 309, 294, 257, 1263, 473, 2445, 13, 407, 498, 321, 51168], "temperature": 0.0, "avg_logprob": -0.27624749122781955, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.04207834601402283}, {"id": 20, "seek": 10786, "start": 123.94, "end": 131.22, "text": " do it here, and then we create a ddpm data loader function, which just creates a data", "tokens": [51168, 360, 309, 510, 11, 293, 550, 321, 1884, 257, 274, 67, 14395, 1412, 3677, 260, 2445, 11, 597, 445, 7829, 257, 1412, 51532], "temperature": 0.0, "avg_logprob": -0.27624749122781955, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.04207834601402283}, {"id": 21, "seek": 13122, "start": 131.22, "end": 136.5, "text": " loader from some dataset that we pass in with some batch size, with that collation", "tokens": [50364, 3677, 260, 490, 512, 28872, 300, 321, 1320, 294, 365, 512, 15245, 2744, 11, 365, 300, 1263, 399, 50628], "temperature": 0.0, "avg_logprob": -0.295165183696341, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.22250214219093323}, {"id": 22, "seek": 13122, "start": 136.5, "end": 144.98, "text": " function, then we can create our DLs, not using data loaders dot from, what's it called?", "tokens": [50628, 2445, 11, 550, 321, 393, 1884, 527, 413, 43, 82, 11, 406, 1228, 1412, 3677, 433, 5893, 490, 11, 437, 311, 309, 1219, 30, 51052], "temperature": 0.0, "avg_logprob": -0.295165183696341, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.22250214219093323}, {"id": 23, "seek": 13122, "start": 144.98, "end": 154.38, "text": " Data loaders dot from dd. But instead of that, the original, you know, the plain init that", "tokens": [51052, 11888, 3677, 433, 5893, 490, 274, 67, 13, 583, 2602, 295, 300, 11, 264, 3380, 11, 291, 458, 11, 264, 11121, 3157, 300, 51522], "temperature": 0.0, "avg_logprob": -0.295165183696341, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.22250214219093323}, {"id": 24, "seek": 13122, "start": 154.38, "end": 157.62, "text": " we created for data loaders, and again you should go back and remind yourself of this,", "tokens": [51522, 321, 2942, 337, 1412, 3677, 433, 11, 293, 797, 291, 820, 352, 646, 293, 4160, 1803, 295, 341, 11, 51684], "temperature": 0.0, "avg_logprob": -0.295165183696341, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.22250214219093323}, {"id": 25, "seek": 15762, "start": 157.62, "end": 163.86, "text": " you just pass in the data loaders for training and test. So there's our two data loaders.", "tokens": [50364, 291, 445, 1320, 294, 264, 1412, 3677, 433, 337, 3097, 293, 1500, 13, 407, 456, 311, 527, 732, 1412, 3677, 433, 13, 50676], "temperature": 0.0, "avg_logprob": -0.25044110725665913, "compression_ratio": 1.7991803278688525, "no_speech_prob": 0.10519319772720337}, {"id": 26, "seek": 15762, "start": 163.86, "end": 169.70000000000002, "text": " So with that we don't need a ddpm callback anymore. All right, so now that we've, you", "tokens": [50676, 407, 365, 300, 321, 500, 380, 643, 257, 274, 67, 14395, 818, 3207, 3602, 13, 1057, 558, 11, 370, 586, 300, 321, 600, 11, 291, 50968], "temperature": 0.0, "avg_logprob": -0.25044110725665913, "compression_ratio": 1.7991803278688525, "no_speech_prob": 0.10519319772720337}, {"id": 27, "seek": 15762, "start": 169.70000000000002, "end": 173.3, "text": " know, and again this isn't, this is not required for mixed precision, this is just because", "tokens": [50968, 458, 11, 293, 797, 341, 1943, 380, 11, 341, 307, 406, 4739, 337, 7467, 18356, 11, 341, 307, 445, 570, 51148], "temperature": 0.0, "avg_logprob": -0.25044110725665913, "compression_ratio": 1.7991803278688525, "no_speech_prob": 0.10519319772720337}, {"id": 28, "seek": 15762, "start": 173.3, "end": 179.18, "text": " I wanted to experiment and flex our muscles a little bit of trying things out. So here's", "tokens": [51148, 286, 1415, 281, 5120, 293, 5896, 527, 9530, 257, 707, 857, 295, 1382, 721, 484, 13, 407, 510, 311, 51442], "temperature": 0.0, "avg_logprob": -0.25044110725665913, "compression_ratio": 1.7991803278688525, "no_speech_prob": 0.10519319772720337}, {"id": 29, "seek": 15762, "start": 179.18, "end": 186.14000000000001, "text": " our mixed precision callback, and this is a training callback, and basically if you", "tokens": [51442, 527, 7467, 18356, 818, 3207, 11, 293, 341, 307, 257, 3097, 818, 3207, 11, 293, 1936, 498, 291, 51790], "temperature": 0.0, "avg_logprob": -0.25044110725665913, "compression_ratio": 1.7991803278688525, "no_speech_prob": 0.10519319772720337}, {"id": 30, "seek": 18614, "start": 186.14, "end": 198.61999999999998, "text": " Google for PyTorch mixed precision, you'll see that the docs show the typical mixed", "tokens": [50364, 3329, 337, 9953, 51, 284, 339, 7467, 18356, 11, 291, 603, 536, 300, 264, 45623, 855, 264, 7476, 7467, 50988], "temperature": 0.0, "avg_logprob": -0.35858388806952807, "compression_ratio": 1.45, "no_speech_prob": 0.009859432466328144}, {"id": 31, "seek": 18614, "start": 198.61999999999998, "end": 207.14, "text": " precision basically says with auto cast device equals CUDA type equals float 16, get your", "tokens": [50988, 18356, 1936, 1619, 365, 8399, 4193, 4302, 6915, 29777, 7509, 2010, 6915, 15706, 3165, 11, 483, 428, 51414], "temperature": 0.0, "avg_logprob": -0.35858388806952807, "compression_ratio": 1.45, "no_speech_prob": 0.009859432466328144}, {"id": 32, "seek": 18614, "start": 207.14, "end": 215.29999999999998, "text": " predictions and call your loss. So again, remind yourself if you've forgotten that this", "tokens": [51414, 21264, 293, 818, 428, 4470, 13, 407, 797, 11, 4160, 1803, 498, 291, 600, 11832, 300, 341, 51822], "temperature": 0.0, "avg_logprob": -0.35858388806952807, "compression_ratio": 1.45, "no_speech_prob": 0.009859432466328144}, {"id": 33, "seek": 21530, "start": 215.3, "end": 219.5, "text": " is called a context manager, and context managers when they start call something called", "tokens": [50364, 307, 1219, 257, 4319, 6598, 11, 293, 4319, 14084, 562, 436, 722, 818, 746, 1219, 50574], "temperature": 0.0, "avg_logprob": -0.28614201545715334, "compression_ratio": 1.9408602150537635, "no_speech_prob": 0.011507969349622726}, {"id": 34, "seek": 21530, "start": 219.5, "end": 224.82000000000002, "text": " done to enter, and when they finish they call something called done to exit. So we could", "tokens": [50574, 1096, 281, 3242, 11, 293, 562, 436, 2413, 436, 818, 746, 1219, 1096, 281, 11043, 13, 407, 321, 727, 50840], "temperature": 0.0, "avg_logprob": -0.28614201545715334, "compression_ratio": 1.9408602150537635, "no_speech_prob": 0.011507969349622726}, {"id": 35, "seek": 21530, "start": 224.82000000000002, "end": 233.34, "text": " therefore put the torch dot auto cast into an attribute and call done to enter before", "tokens": [50840, 4412, 829, 264, 27822, 5893, 8399, 4193, 666, 364, 19667, 293, 818, 1096, 281, 3242, 949, 51266], "temperature": 0.0, "avg_logprob": -0.28614201545715334, "compression_ratio": 1.9408602150537635, "no_speech_prob": 0.011507969349622726}, {"id": 36, "seek": 21530, "start": 233.34, "end": 243.42000000000002, "text": " the batch begins, and then after we've calculated the loss we want to finish that context manager.", "tokens": [51266, 264, 15245, 7338, 11, 293, 550, 934, 321, 600, 15598, 264, 4470, 321, 528, 281, 2413, 300, 4319, 6598, 13, 51770], "temperature": 0.0, "avg_logprob": -0.28614201545715334, "compression_ratio": 1.9408602150537635, "no_speech_prob": 0.011507969349622726}, {"id": 37, "seek": 24342, "start": 243.42, "end": 253.42, "text": " So after loss we call auto cast done to exit, and so I had to add this. So you'll find now", "tokens": [50364, 407, 934, 4470, 321, 818, 8399, 4193, 1096, 281, 11043, 11, 293, 370, 286, 632, 281, 909, 341, 13, 407, 291, 603, 915, 586, 50864], "temperature": 0.0, "avg_logprob": -0.3025564274317782, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0023231350351125}, {"id": 38, "seek": 24342, "start": 253.42, "end": 265.46, "text": " in the 09 learner that there's a section called updated version since the lesson, where I've", "tokens": [50864, 294, 264, 48729, 33347, 300, 456, 311, 257, 3541, 1219, 10588, 3037, 1670, 264, 6898, 11, 689, 286, 600, 51466], "temperature": 0.0, "avg_logprob": -0.3025564274317782, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0023231350351125}, {"id": 39, "seek": 24342, "start": 265.46, "end": 272.86, "text": " added an after predict, and after loss, and after backward, and an after step, and that", "tokens": [51466, 3869, 364, 934, 6069, 11, 293, 934, 4470, 11, 293, 934, 23897, 11, 293, 364, 934, 1823, 11, 293, 300, 51836], "temperature": 0.0, "avg_logprob": -0.3025564274317782, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0023231350351125}, {"id": 40, "seek": 27286, "start": 272.86, "end": 279.94, "text": " means that a callback can now insert code at any point of the training loop, and so", "tokens": [50364, 1355, 300, 257, 818, 3207, 393, 586, 8969, 3089, 412, 604, 935, 295, 264, 3097, 6367, 11, 293, 370, 50718], "temperature": 0.0, "avg_logprob": -0.28588132960821994, "compression_ratio": 1.625, "no_speech_prob": 0.00013765391486231238}, {"id": 41, "seek": 27286, "start": 279.94, "end": 287.3, "text": " we haven't used all of those different things here, but we certainly do want, yeah, after", "tokens": [50718, 321, 2378, 380, 1143, 439, 295, 729, 819, 721, 510, 11, 457, 321, 3297, 360, 528, 11, 1338, 11, 934, 51086], "temperature": 0.0, "avg_logprob": -0.28588132960821994, "compression_ratio": 1.625, "no_speech_prob": 0.00013765391486231238}, {"id": 42, "seek": 27286, "start": 287.3, "end": 297.06, "text": " loss we need to be able to do that, and then yeah this is just code that has to be run", "tokens": [51086, 4470, 321, 643, 281, 312, 1075, 281, 360, 300, 11, 293, 550, 1338, 341, 307, 445, 3089, 300, 575, 281, 312, 1190, 51574], "temperature": 0.0, "avg_logprob": -0.28588132960821994, "compression_ratio": 1.625, "no_speech_prob": 0.00013765391486231238}, {"id": 43, "seek": 27286, "start": 297.06, "end": 301.7, "text": " according to it to the PyTorch docs, so instead of calling loss dot backwards, you have to", "tokens": [51574, 4650, 281, 309, 281, 264, 9953, 51, 284, 339, 45623, 11, 370, 2602, 295, 5141, 4470, 5893, 12204, 11, 291, 362, 281, 51806], "temperature": 0.0, "avg_logprob": -0.28588132960821994, "compression_ratio": 1.625, "no_speech_prob": 0.00013765391486231238}, {"id": 44, "seek": 30170, "start": 301.7, "end": 308.7, "text": " call scalar dot scale loss dot backward. So we replace our backward in the train callback", "tokens": [50364, 818, 39684, 5893, 4373, 4470, 5893, 23897, 13, 407, 321, 7406, 527, 23897, 294, 264, 3847, 818, 3207, 50714], "temperature": 0.0, "avg_logprob": -0.2796314912683823, "compression_ratio": 2.125748502994012, "no_speech_prob": 0.007345536258071661}, {"id": 45, "seek": 30170, "start": 308.7, "end": 313.7, "text": " with something called scalar dot scale loss dot backward, and then it says that finally", "tokens": [50714, 365, 746, 1219, 39684, 5893, 4373, 4470, 5893, 23897, 11, 293, 550, 309, 1619, 300, 2721, 50964], "temperature": 0.0, "avg_logprob": -0.2796314912683823, "compression_ratio": 2.125748502994012, "no_speech_prob": 0.007345536258071661}, {"id": 46, "seek": 30170, "start": 313.7, "end": 319.06, "text": " when you do the step you don't call optimizer dot step, you call scalar dot step optimizer,", "tokens": [50964, 562, 291, 360, 264, 1823, 291, 500, 380, 818, 5028, 6545, 5893, 1823, 11, 291, 818, 39684, 5893, 1823, 5028, 6545, 11, 51232], "temperature": 0.0, "avg_logprob": -0.2796314912683823, "compression_ratio": 2.125748502994012, "no_speech_prob": 0.007345536258071661}, {"id": 47, "seek": 30170, "start": 319.06, "end": 326.5, "text": " scalar dot update. So we've replaced step with scalar dot step, scalar dot update. So", "tokens": [51232, 39684, 5893, 5623, 13, 407, 321, 600, 10772, 1823, 365, 39684, 5893, 1823, 11, 39684, 5893, 5623, 13, 407, 51604], "temperature": 0.0, "avg_logprob": -0.2796314912683823, "compression_ratio": 2.125748502994012, "no_speech_prob": 0.007345536258071661}, {"id": 48, "seek": 32650, "start": 326.5, "end": 332.34, "text": " that does all of the things in here, and the nice thing is now that this exists, we", "tokens": [50364, 300, 775, 439, 295, 264, 721, 294, 510, 11, 293, 264, 1481, 551, 307, 586, 300, 341, 8198, 11, 321, 50656], "temperature": 0.0, "avg_logprob": -0.25325252041958346, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.09666333347558975}, {"id": 49, "seek": 32650, "start": 332.34, "end": 338.3, "text": " don't have to think about any of that, we can add mixed precision to anything, which", "tokens": [50656, 500, 380, 362, 281, 519, 466, 604, 295, 300, 11, 321, 393, 909, 7467, 18356, 281, 1340, 11, 597, 50954], "temperature": 0.0, "avg_logprob": -0.25325252041958346, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.09666333347558975}, {"id": 50, "seek": 32650, "start": 338.3, "end": 349.5, "text": " is really nice, and so we now, as you'll see, CB's no longer has a DDPM CB, but we do have", "tokens": [50954, 307, 534, 1481, 11, 293, 370, 321, 586, 11, 382, 291, 603, 536, 11, 18745, 311, 572, 2854, 575, 257, 413, 11373, 44, 18745, 11, 457, 321, 360, 362, 51514], "temperature": 0.0, "avg_logprob": -0.25325252041958346, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.09666333347558975}, {"id": 51, "seek": 32650, "start": 349.5, "end": 354.5, "text": " the mixed precision, and that's a train callback, so we just need a normal learner, not a train", "tokens": [51514, 264, 7467, 18356, 11, 293, 300, 311, 257, 3847, 818, 3207, 11, 370, 321, 445, 643, 257, 2710, 33347, 11, 406, 257, 3847, 51764], "temperature": 0.0, "avg_logprob": -0.25325252041958346, "compression_ratio": 1.658878504672897, "no_speech_prob": 0.09666333347558975}, {"id": 52, "seek": 35450, "start": 354.5, "end": 362.06, "text": " learner, and we initialize our DDPM. Now to get benefit from mixed precision, you need", "tokens": [50364, 33347, 11, 293, 321, 5883, 1125, 527, 413, 11373, 44, 13, 823, 281, 483, 5121, 490, 7467, 18356, 11, 291, 643, 50742], "temperature": 0.0, "avg_logprob": -0.19407312393188478, "compression_ratio": 1.5530973451327434, "no_speech_prob": 7.368586375378072e-05}, {"id": 53, "seek": 35450, "start": 362.06, "end": 367.9, "text": " to do quite a bit at a time, you know, your GPU needs to be busy, and on something as", "tokens": [50742, 281, 360, 1596, 257, 857, 412, 257, 565, 11, 291, 458, 11, 428, 18407, 2203, 281, 312, 5856, 11, 293, 322, 746, 382, 51034], "temperature": 0.0, "avg_logprob": -0.19407312393188478, "compression_ratio": 1.5530973451327434, "no_speech_prob": 7.368586375378072e-05}, {"id": 54, "seek": 35450, "start": 367.9, "end": 373.5, "text": " small as fashion MNIST, it's not easy to keep a GPU busy, so that's why I've increased the", "tokens": [51034, 1359, 382, 6700, 376, 45, 19756, 11, 309, 311, 406, 1858, 281, 1066, 257, 18407, 5856, 11, 370, 300, 311, 983, 286, 600, 6505, 264, 51314], "temperature": 0.0, "avg_logprob": -0.19407312393188478, "compression_ratio": 1.5530973451327434, "no_speech_prob": 7.368586375378072e-05}, {"id": 55, "seek": 35450, "start": 373.5, "end": 381.62, "text": " batch size by four times. Now that means that each epoch, it's going to have four times", "tokens": [51314, 15245, 2744, 538, 1451, 1413, 13, 823, 300, 1355, 300, 1184, 30992, 339, 11, 309, 311, 516, 281, 362, 1451, 1413, 51720], "temperature": 0.0, "avg_logprob": -0.19407312393188478, "compression_ratio": 1.5530973451327434, "no_speech_prob": 7.368586375378072e-05}, {"id": 56, "seek": 38162, "start": 381.62, "end": 385.94, "text": " less batches, because they're bigger, and that means it's got four times less opportunities", "tokens": [50364, 1570, 15245, 279, 11, 570, 436, 434, 3801, 11, 293, 300, 1355, 309, 311, 658, 1451, 1413, 1570, 4786, 50580], "temperature": 0.0, "avg_logprob": -0.2475742063214702, "compression_ratio": 1.8677685950413223, "no_speech_prob": 0.01615205593407154}, {"id": 57, "seek": 38162, "start": 385.94, "end": 390.26, "text": " to update, and that's going to be a problem, because if I want to have as good a result", "tokens": [50580, 281, 5623, 11, 293, 300, 311, 516, 281, 312, 257, 1154, 11, 570, 498, 286, 528, 281, 362, 382, 665, 257, 1874, 50796], "temperature": 0.0, "avg_logprob": -0.2475742063214702, "compression_ratio": 1.8677685950413223, "no_speech_prob": 0.01615205593407154}, {"id": 58, "seek": 38162, "start": 390.26, "end": 396.86, "text": " as Tanishk had, and as I've had here, in less time, that's the whole purpose of this, is", "tokens": [50796, 382, 314, 7524, 74, 632, 11, 293, 382, 286, 600, 632, 510, 11, 294, 1570, 565, 11, 300, 311, 264, 1379, 4334, 295, 341, 11, 307, 51126], "temperature": 0.0, "avg_logprob": -0.2475742063214702, "compression_ratio": 1.8677685950413223, "no_speech_prob": 0.01615205593407154}, {"id": 59, "seek": 38162, "start": 396.86, "end": 405.58, "text": " to do it in less time, then I'm going to need to, you know, increase the learning rate,", "tokens": [51126, 281, 360, 309, 294, 1570, 565, 11, 550, 286, 478, 516, 281, 643, 281, 11, 291, 458, 11, 3488, 264, 2539, 3314, 11, 51562], "temperature": 0.0, "avg_logprob": -0.2475742063214702, "compression_ratio": 1.8677685950413223, "no_speech_prob": 0.01615205593407154}, {"id": 60, "seek": 38162, "start": 405.58, "end": 409.62, "text": " and maybe also increase the epoch. So increase the epochs up to eight from five, and I increase", "tokens": [51562, 293, 1310, 611, 3488, 264, 30992, 339, 13, 407, 3488, 264, 30992, 28346, 493, 281, 3180, 490, 1732, 11, 293, 286, 3488, 51764], "temperature": 0.0, "avg_logprob": -0.2475742063214702, "compression_ratio": 1.8677685950413223, "no_speech_prob": 0.01615205593407154}, {"id": 61, "seek": 40962, "start": 409.62, "end": 419.94, "text": " the learning rate up to 1 enig 2, and yeah, I found I could train it fine with that, once", "tokens": [50364, 264, 2539, 3314, 493, 281, 502, 465, 328, 568, 11, 293, 1338, 11, 286, 1352, 286, 727, 3847, 309, 2489, 365, 300, 11, 1564, 50880], "temperature": 0.0, "avg_logprob": -0.2630793530008067, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0004044778470415622}, {"id": 62, "seek": 40962, "start": 419.94, "end": 424.3, "text": " I used the proper initialization, and most importantly used the optimization function", "tokens": [50880, 286, 1143, 264, 2296, 5883, 2144, 11, 293, 881, 8906, 1143, 264, 19618, 2445, 51098], "temperature": 0.0, "avg_logprob": -0.2630793530008067, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0004044778470415622}, {"id": 63, "seek": 40962, "start": 424.3, "end": 431.98, "text": " that has epsilon of 1 enig 5, and so this trains, even though it's doing more epochs,", "tokens": [51098, 300, 575, 17889, 295, 502, 465, 328, 1025, 11, 293, 370, 341, 16329, 11, 754, 1673, 309, 311, 884, 544, 30992, 28346, 11, 51482], "temperature": 0.0, "avg_logprob": -0.2630793530008067, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0004044778470415622}, {"id": 64, "seek": 43198, "start": 431.98, "end": 444.14000000000004, "text": " this trains about twice as fast, and gets the same result. Does that make sense so far?", "tokens": [50364, 341, 16329, 466, 6091, 382, 2370, 11, 293, 2170, 264, 912, 1874, 13, 4402, 300, 652, 2020, 370, 1400, 30, 50972], "temperature": 0.0, "avg_logprob": -0.3683956146240234, "compression_ratio": 1.380952380952381, "no_speech_prob": 0.07261858135461807}, {"id": 65, "seek": 43198, "start": 444.14000000000004, "end": 450.78000000000003, "text": " Yeah, it was great. Cool. Now the good news is actually, we don't even need to write all", "tokens": [50972, 865, 11, 309, 390, 869, 13, 8561, 13, 823, 264, 665, 2583, 307, 767, 11, 321, 500, 380, 754, 643, 281, 2464, 439, 51304], "temperature": 0.0, "avg_logprob": -0.3683956146240234, "compression_ratio": 1.380952380952381, "no_speech_prob": 0.07261858135461807}, {"id": 66, "seek": 43198, "start": 450.78000000000003, "end": 459.5, "text": " this, because there's a nice library from Hugging Face, originally created by Sylva,", "tokens": [51304, 341, 11, 570, 456, 311, 257, 1481, 6405, 490, 46892, 3249, 4047, 11, 7993, 2942, 538, 33349, 2757, 11, 51740], "temperature": 0.0, "avg_logprob": -0.3683956146240234, "compression_ratio": 1.380952380952381, "no_speech_prob": 0.07261858135461807}, {"id": 67, "seek": 45950, "start": 459.5, "end": 464.14, "text": " who used to work with me at Fast.ai, and went to Hugging Face, and kept on doing awesome", "tokens": [50364, 567, 1143, 281, 589, 365, 385, 412, 15968, 13, 1301, 11, 293, 1437, 281, 46892, 3249, 4047, 11, 293, 4305, 322, 884, 3476, 50596], "temperature": 0.0, "avg_logprob": -0.33350155804608317, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.01016878429800272}, {"id": 68, "seek": 45950, "start": 464.14, "end": 469.46, "text": " work, and he started this project called Accelerator, which he now works on with another Fast.ai", "tokens": [50596, 589, 11, 293, 415, 1409, 341, 1716, 1219, 5725, 6185, 1639, 11, 597, 415, 586, 1985, 322, 365, 1071, 15968, 13, 1301, 50862], "temperature": 0.0, "avg_logprob": -0.33350155804608317, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.01016878429800272}, {"id": 69, "seek": 45950, "start": 469.46, "end": 474.34, "text": " alum, named Zach Riehler, and accelerates a library that provides this thing called", "tokens": [50862, 12064, 11, 4926, 21028, 497, 414, 71, 1918, 11, 293, 10172, 1024, 257, 6405, 300, 6417, 341, 551, 1219, 51106], "temperature": 0.0, "avg_logprob": -0.33350155804608317, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.01016878429800272}, {"id": 70, "seek": 45950, "start": 474.34, "end": 478.54, "text": " Accelerator, that does things to accelerate your training loops, and one of the things", "tokens": [51106, 5725, 6185, 1639, 11, 300, 775, 721, 281, 21341, 428, 3097, 16121, 11, 293, 472, 295, 264, 721, 51316], "temperature": 0.0, "avg_logprob": -0.33350155804608317, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.01016878429800272}, {"id": 71, "seek": 45950, "start": 478.54, "end": 486.34, "text": " it does is mixed precision training, and it basically handles these things for you. It", "tokens": [51316, 309, 775, 307, 7467, 18356, 3097, 11, 293, 309, 1936, 18722, 613, 721, 337, 291, 13, 467, 51706], "temperature": 0.0, "avg_logprob": -0.33350155804608317, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.01016878429800272}, {"id": 72, "seek": 48634, "start": 486.34, "end": 492.9, "text": " also lets you train on multiple GPUs, it also lets you train on TPUs, so by adding", "tokens": [50364, 611, 6653, 291, 3847, 322, 3866, 18407, 82, 11, 309, 611, 6653, 291, 3847, 322, 314, 8115, 82, 11, 370, 538, 5127, 50692], "temperature": 0.0, "avg_logprob": -0.2393403675245202, "compression_ratio": 1.8219895287958114, "no_speech_prob": 0.033584047108888626}, {"id": 73, "seek": 48634, "start": 492.9, "end": 499.17999999999995, "text": " a train CB subclass that will allow us to use accelerate, that means we can now hopefully", "tokens": [50692, 257, 3847, 18745, 1422, 11665, 300, 486, 2089, 505, 281, 764, 21341, 11, 300, 1355, 321, 393, 586, 4696, 51006], "temperature": 0.0, "avg_logprob": -0.2393403675245202, "compression_ratio": 1.8219895287958114, "no_speech_prob": 0.033584047108888626}, {"id": 74, "seek": 48634, "start": 499.17999999999995, "end": 508.26, "text": " use TPUs, and multi GPU training, and all that kind of thing. So the accelerate docs", "tokens": [51006, 764, 314, 8115, 82, 11, 293, 4825, 18407, 3097, 11, 293, 439, 300, 733, 295, 551, 13, 407, 264, 21341, 45623, 51460], "temperature": 0.0, "avg_logprob": -0.2393403675245202, "compression_ratio": 1.8219895287958114, "no_speech_prob": 0.033584047108888626}, {"id": 75, "seek": 48634, "start": 508.26, "end": 515.5799999999999, "text": " show that what you have to do to use accelerate, is to create an accelerator, tell it what", "tokens": [51460, 855, 300, 437, 291, 362, 281, 360, 281, 764, 21341, 11, 307, 281, 1884, 364, 39889, 11, 980, 309, 437, 51826], "temperature": 0.0, "avg_logprob": -0.2393403675245202, "compression_ratio": 1.8219895287958114, "no_speech_prob": 0.033584047108888626}, {"id": 76, "seek": 51558, "start": 515.58, "end": 519.86, "text": " kind of mixed precision you want to use, so we're going to use 16-bit floating-point", "tokens": [50364, 733, 295, 7467, 18356, 291, 528, 281, 764, 11, 370, 321, 434, 516, 281, 764, 3165, 12, 5260, 12607, 12, 6053, 50578], "temperature": 0.0, "avg_logprob": -0.2629180621075374, "compression_ratio": 1.7536945812807883, "no_speech_prob": 0.000398212083382532}, {"id": 77, "seek": 51558, "start": 519.86, "end": 530.38, "text": " FP16, and then you have to basically call accelerate, accelerator.prepare, and you pass", "tokens": [50578, 36655, 6866, 11, 293, 550, 291, 362, 281, 1936, 818, 21341, 11, 39889, 13, 3712, 79, 543, 11, 293, 291, 1320, 51104], "temperature": 0.0, "avg_logprob": -0.2629180621075374, "compression_ratio": 1.7536945812807883, "no_speech_prob": 0.000398212083382532}, {"id": 78, "seek": 51558, "start": 530.38, "end": 537.34, "text": " in your model, your optimizer, and your training and validation data loaders, and it returns", "tokens": [51104, 294, 428, 2316, 11, 428, 5028, 6545, 11, 293, 428, 3097, 293, 24071, 1412, 3677, 433, 11, 293, 309, 11247, 51452], "temperature": 0.0, "avg_logprob": -0.2629180621075374, "compression_ratio": 1.7536945812807883, "no_speech_prob": 0.000398212083382532}, {"id": 79, "seek": 51558, "start": 537.34, "end": 542.22, "text": " you back a model, an optimizer, and training and validation data loaders, but they've been", "tokens": [51452, 291, 646, 257, 2316, 11, 364, 5028, 6545, 11, 293, 3097, 293, 24071, 1412, 3677, 433, 11, 457, 436, 600, 668, 51696], "temperature": 0.0, "avg_logprob": -0.2629180621075374, "compression_ratio": 1.7536945812807883, "no_speech_prob": 0.000398212083382532}, {"id": 80, "seek": 54222, "start": 542.22, "end": 547.9, "text": " wrapped up in accelerate, and accelerate is going to now do all the things we saw you", "tokens": [50364, 14226, 493, 294, 21341, 11, 293, 21341, 307, 516, 281, 586, 360, 439, 264, 721, 321, 1866, 291, 50648], "temperature": 0.0, "avg_logprob": -0.23864108118517646, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.014279761351644993}, {"id": 81, "seek": 54222, "start": 547.9, "end": 555.34, "text": " have to do automatically, and that's why that's almost all the code we need. The only other", "tokens": [50648, 362, 281, 360, 6772, 11, 293, 300, 311, 983, 300, 311, 1920, 439, 264, 3089, 321, 643, 13, 440, 787, 661, 51020], "temperature": 0.0, "avg_logprob": -0.23864108118517646, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.014279761351644993}, {"id": 82, "seek": 54222, "start": 555.34, "end": 560.6600000000001, "text": " thing we need is it didn't, we didn't like tell it how to like change our loss function", "tokens": [51020, 551, 321, 643, 307, 309, 994, 380, 11, 321, 994, 380, 411, 980, 309, 577, 281, 411, 1319, 527, 4470, 2445, 51286], "temperature": 0.0, "avg_logprob": -0.23864108118517646, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.014279761351644993}, {"id": 83, "seek": 54222, "start": 560.6600000000001, "end": 564.58, "text": " to use accelerate, so we actually have to change backward, that's why we inherit from", "tokens": [51286, 281, 764, 21341, 11, 370, 321, 767, 362, 281, 1319, 23897, 11, 300, 311, 983, 321, 21389, 490, 51482], "temperature": 0.0, "avg_logprob": -0.23864108118517646, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.014279761351644993}, {"id": 84, "seek": 54222, "start": 564.58, "end": 570.9, "text": " train CB, we have to change backward to not call loss.backward, but self.accelerate.backward", "tokens": [51482, 3847, 18745, 11, 321, 362, 281, 1319, 23897, 281, 406, 818, 4470, 13, 3207, 1007, 11, 457, 2698, 13, 326, 4933, 260, 473, 13, 3207, 1007, 51798], "temperature": 0.0, "avg_logprob": -0.23864108118517646, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.014279761351644993}, {"id": 85, "seek": 57090, "start": 570.9, "end": 579.9399999999999, "text": " and pass in loss. Okay, and then I had another idea of something I wanted to do, which is", "tokens": [50364, 293, 1320, 294, 4470, 13, 1033, 11, 293, 550, 286, 632, 1071, 1558, 295, 746, 286, 1415, 281, 360, 11, 597, 307, 50816], "temperature": 0.0, "avg_logprob": -0.20379463195800782, "compression_ratio": 1.6995073891625616, "no_speech_prob": 9.461215086048469e-05}, {"id": 86, "seek": 57090, "start": 579.9399999999999, "end": 584.5799999999999, "text": " I like the idea that noisify, I've copied noisify here, but rather than returning a", "tokens": [50816, 286, 411, 264, 1558, 300, 572, 271, 2505, 11, 286, 600, 25365, 572, 271, 2505, 510, 11, 457, 2831, 813, 12678, 257, 51048], "temperature": 0.0, "avg_logprob": -0.20379463195800782, "compression_ratio": 1.6995073891625616, "no_speech_prob": 9.461215086048469e-05}, {"id": 87, "seek": 57090, "start": 584.5799999999999, "end": 591.4399999999999, "text": " tuple of tuples, I just return a tuple with three things. I think this is neater to me,", "tokens": [51048, 2604, 781, 295, 2604, 2622, 11, 286, 445, 2736, 257, 2604, 781, 365, 1045, 721, 13, 286, 519, 341, 307, 408, 771, 281, 385, 11, 51391], "temperature": 0.0, "avg_logprob": -0.20379463195800782, "compression_ratio": 1.6995073891625616, "no_speech_prob": 9.461215086048469e-05}, {"id": 88, "seek": 57090, "start": 591.4399999999999, "end": 595.68, "text": " I would like to just have three things in the tuple, I don't want to have to modify", "tokens": [51391, 286, 576, 411, 281, 445, 362, 1045, 721, 294, 264, 2604, 781, 11, 286, 500, 380, 528, 281, 362, 281, 16927, 51603], "temperature": 0.0, "avg_logprob": -0.20379463195800782, "compression_ratio": 1.6995073891625616, "no_speech_prob": 9.461215086048469e-05}, {"id": 89, "seek": 59568, "start": 595.68, "end": 602.1999999999999, "text": " my model, I don't want to have to modify my training callback, I don't want to do anything", "tokens": [50364, 452, 2316, 11, 286, 500, 380, 528, 281, 362, 281, 16927, 452, 3097, 818, 3207, 11, 286, 500, 380, 528, 281, 360, 1340, 50690], "temperature": 0.0, "avg_logprob": -0.2405823272408791, "compression_ratio": 2.0171428571428573, "no_speech_prob": 0.10371462255716324}, {"id": 90, "seek": 59568, "start": 602.1999999999999, "end": 612.8399999999999, "text": " tricky, I don't even want to have a custom collation function, sorry I want to have a", "tokens": [50690, 12414, 11, 286, 500, 380, 754, 528, 281, 362, 257, 2375, 1263, 399, 2445, 11, 2597, 286, 528, 281, 362, 257, 51222], "temperature": 0.0, "avg_logprob": -0.2405823272408791, "compression_ratio": 2.0171428571428573, "no_speech_prob": 0.10371462255716324}, {"id": 91, "seek": 59568, "start": 612.8399999999999, "end": 617.2399999999999, "text": " custom collation function, but I don't want to have a modified model. So I'm going to", "tokens": [51222, 2375, 1263, 399, 2445, 11, 457, 286, 500, 380, 528, 281, 362, 257, 15873, 2316, 13, 407, 286, 478, 516, 281, 51442], "temperature": 0.0, "avg_logprob": -0.2405823272408791, "compression_ratio": 2.0171428571428573, "no_speech_prob": 0.10371462255716324}, {"id": 92, "seek": 59568, "start": 617.2399999999999, "end": 623.76, "text": " go back to using a unet2d model. So how can we use a unet2d model when we've now got three", "tokens": [51442, 352, 646, 281, 1228, 257, 517, 302, 17, 67, 2316, 13, 407, 577, 393, 321, 764, 257, 517, 302, 17, 67, 2316, 562, 321, 600, 586, 658, 1045, 51768], "temperature": 0.0, "avg_logprob": -0.2405823272408791, "compression_ratio": 2.0171428571428573, "no_speech_prob": 0.10371462255716324}, {"id": 93, "seek": 62376, "start": 623.76, "end": 634.88, "text": " things? And what I did in my modified learner, just underneath it, sorry actually what I", "tokens": [50364, 721, 30, 400, 437, 286, 630, 294, 452, 15873, 33347, 11, 445, 7223, 309, 11, 2597, 767, 437, 286, 50920], "temperature": 0.0, "avg_logprob": -0.33781384407205783, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.0022871973924338818}, {"id": 94, "seek": 62376, "start": 634.88, "end": 644.4, "text": " did was I modified trainCB to add one parameter, which is number of inputs, and so this tells", "tokens": [50920, 630, 390, 286, 15873, 3847, 34, 33, 281, 909, 472, 13075, 11, 597, 307, 1230, 295, 15743, 11, 293, 370, 341, 5112, 51396], "temperature": 0.0, "avg_logprob": -0.33781384407205783, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.0022871973924338818}, {"id": 95, "seek": 64440, "start": 644.4, "end": 655.16, "text": " you how many inputs are there to the model. Normally you would expect one input, but our", "tokens": [50364, 291, 577, 867, 15743, 366, 456, 281, 264, 2316, 13, 17424, 291, 576, 2066, 472, 4846, 11, 457, 527, 50902], "temperature": 0.0, "avg_logprob": -0.30364015579223635, "compression_ratio": 1.3511450381679388, "no_speech_prob": 0.037312258034944534}, {"id": 96, "seek": 64440, "start": 655.16, "end": 670.4399999999999, "text": " model has two inputs. So here we say, okay so accelerateCB is a trainCB, so when we call", "tokens": [50902, 2316, 575, 732, 15743, 13, 407, 510, 321, 584, 11, 1392, 370, 21341, 34, 33, 307, 257, 3847, 34, 33, 11, 370, 562, 321, 818, 51666], "temperature": 0.0, "avg_logprob": -0.30364015579223635, "compression_ratio": 1.3511450381679388, "no_speech_prob": 0.037312258034944534}, {"id": 97, "seek": 67044, "start": 670.44, "end": 676.48, "text": " it we say we're going to have two inputs, and so what that's going to do is it's just", "tokens": [50364, 309, 321, 584, 321, 434, 516, 281, 362, 732, 15743, 11, 293, 370, 437, 300, 311, 516, 281, 360, 307, 309, 311, 445, 50666], "temperature": 0.0, "avg_logprob": -0.2453141212463379, "compression_ratio": 1.8864864864864865, "no_speech_prob": 0.3106105327606201}, {"id": 98, "seek": 67044, "start": 676.48, "end": 681.08, "text": " going to remember how many you asked for, and so when you call predict it's not going", "tokens": [50666, 516, 281, 1604, 577, 867, 291, 2351, 337, 11, 293, 370, 562, 291, 818, 6069, 309, 311, 406, 516, 50896], "temperature": 0.0, "avg_logprob": -0.2453141212463379, "compression_ratio": 1.8864864864864865, "no_speech_prob": 0.3106105327606201}, {"id": 99, "seek": 67044, "start": 681.08, "end": 690.36, "text": " to pass learn.batch zero, it's going to call star learn.batch colon self.numInputs, and", "tokens": [50896, 281, 1320, 1466, 13, 65, 852, 4018, 11, 309, 311, 516, 281, 818, 3543, 1466, 13, 65, 852, 8255, 2698, 13, 77, 449, 4575, 2582, 82, 11, 293, 51360], "temperature": 0.0, "avg_logprob": -0.2453141212463379, "compression_ratio": 1.8864864864864865, "no_speech_prob": 0.3106105327606201}, {"id": 100, "seek": 67044, "start": 690.36, "end": 694.7600000000001, "text": " ditto when you call the loss function it's going to be the rest. So it's star learn.batch", "tokens": [51360, 274, 34924, 562, 291, 818, 264, 4470, 2445, 309, 311, 516, 281, 312, 264, 1472, 13, 407, 309, 311, 3543, 1466, 13, 65, 852, 51580], "temperature": 0.0, "avg_logprob": -0.2453141212463379, "compression_ratio": 1.8864864864864865, "no_speech_prob": 0.3106105327606201}, {"id": 101, "seek": 69476, "start": 694.76, "end": 700.84, "text": " self.numInputs. So this way you can have one, two, three, four, five inputs, one, two,", "tokens": [50364, 2698, 13, 77, 449, 4575, 2582, 82, 13, 407, 341, 636, 291, 393, 362, 472, 11, 732, 11, 1045, 11, 1451, 11, 1732, 15743, 11, 472, 11, 732, 11, 50668], "temperature": 0.0, "avg_logprob": -0.27561473846435547, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.08269038051366806}, {"id": 102, "seek": 69476, "start": 700.84, "end": 705.52, "text": " three, four, five outputs, whatever you like, and it's just up to you then to make sure", "tokens": [50668, 1045, 11, 1451, 11, 1732, 23930, 11, 2035, 291, 411, 11, 293, 309, 311, 445, 493, 281, 291, 550, 281, 652, 988, 50902], "temperature": 0.0, "avg_logprob": -0.27561473846435547, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.08269038051366806}, {"id": 103, "seek": 69476, "start": 705.52, "end": 711.04, "text": " that your model and your loss function take the number of parameters. So the loss function", "tokens": [50902, 300, 428, 2316, 293, 428, 4470, 2445, 747, 264, 1230, 295, 9834, 13, 407, 264, 4470, 2445, 51178], "temperature": 0.0, "avg_logprob": -0.27561473846435547, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.08269038051366806}, {"id": 104, "seek": 69476, "start": 711.04, "end": 718.88, "text": " is going to first of all take your threads, and then yeah however many non inputs you", "tokens": [51178, 307, 516, 281, 700, 295, 439, 747, 428, 19314, 11, 293, 550, 1338, 4461, 867, 2107, 15743, 291, 51570], "temperature": 0.0, "avg_logprob": -0.27561473846435547, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.08269038051366806}, {"id": 105, "seek": 71888, "start": 718.88, "end": 730.8, "text": " have. So that way yeah we now don't need to replace anything except that we did need", "tokens": [50364, 362, 13, 407, 300, 636, 1338, 321, 586, 500, 380, 643, 281, 7406, 1340, 3993, 300, 321, 630, 643, 50960], "temperature": 0.0, "avg_logprob": -0.2828736114501953, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.2538173794746399}, {"id": 106, "seek": 71888, "start": 730.8, "end": 736.6, "text": " to do the thing to make sure that we get the dot sample out. So I just had a little, this", "tokens": [50960, 281, 360, 264, 551, 281, 652, 988, 300, 321, 483, 264, 5893, 6889, 484, 13, 407, 286, 445, 632, 257, 707, 11, 341, 51250], "temperature": 0.0, "avg_logprob": -0.2828736114501953, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.2538173794746399}, {"id": 107, "seek": 71888, "start": 736.6, "end": 743.96, "text": " is the whole DDPMCB callback now, DDPMCB2, so after the predictions are done, replace", "tokens": [51250, 307, 264, 1379, 413, 11373, 39261, 33, 818, 3207, 586, 11, 413, 11373, 39261, 33, 17, 11, 370, 934, 264, 21264, 366, 1096, 11, 7406, 51618], "temperature": 0.0, "avg_logprob": -0.2828736114501953, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.2538173794746399}, {"id": 108, "seek": 74396, "start": 743.96, "end": 752.4000000000001, "text": " them with the dot sample. Right so that's nice and easy, you know. So we end up with", "tokens": [50364, 552, 365, 264, 5893, 6889, 13, 1779, 370, 300, 311, 1481, 293, 1858, 11, 291, 458, 13, 407, 321, 917, 493, 365, 50786], "temperature": 0.0, "avg_logprob": -0.36231152216593426, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.1800576150417328}, {"id": 109, "seek": 74396, "start": 752.4000000000001, "end": 759.84, "text": " quite a bit of pieces, but they're all very decoupled, you know. So with mini AI, you", "tokens": [50786, 1596, 257, 857, 295, 3755, 11, 457, 436, 434, 439, 588, 979, 263, 15551, 11, 291, 458, 13, 407, 365, 8382, 7318, 11, 291, 51158], "temperature": 0.0, "avg_logprob": -0.36231152216593426, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.1800576150417328}, {"id": 110, "seek": 74396, "start": 759.84, "end": 764.72, "text": " know, with and with accelerate CB, whatever, I guess we should export these actually, so", "tokens": [51158, 458, 11, 365, 293, 365, 21341, 18745, 11, 2035, 11, 286, 2041, 321, 820, 10725, 613, 767, 11, 370, 51402], "temperature": 0.0, "avg_logprob": -0.36231152216593426, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.1800576150417328}, {"id": 111, "seek": 74396, "start": 764.72, "end": 772.52, "text": " into a nice module. Well if you had all those, then yeah you wouldn't have accelerate CB,", "tokens": [51402, 666, 257, 1481, 10088, 13, 1042, 498, 291, 632, 439, 729, 11, 550, 1338, 291, 2759, 380, 362, 21341, 18745, 11, 51792], "temperature": 0.0, "avg_logprob": -0.36231152216593426, "compression_ratio": 1.6308411214953271, "no_speech_prob": 0.1800576150417328}, {"id": 112, "seek": 77252, "start": 772.52, "end": 780.04, "text": " the only thing you would need would be the would be the noisify and the collation function,", "tokens": [50364, 264, 787, 551, 291, 576, 643, 576, 312, 264, 576, 312, 264, 572, 271, 2505, 293, 264, 1263, 399, 2445, 11, 50740], "temperature": 0.0, "avg_logprob": -0.27899393828018854, "compression_ratio": 1.6130952380952381, "no_speech_prob": 0.0011160090798512101}, {"id": 113, "seek": 77252, "start": 780.04, "end": 788.0799999999999, "text": " and this tiny callback, and then yeah use our learner and fit, and we get the same result", "tokens": [50740, 293, 341, 5870, 818, 3207, 11, 293, 550, 1338, 764, 527, 33347, 293, 3318, 11, 293, 321, 483, 264, 912, 1874, 51142], "temperature": 0.0, "avg_logprob": -0.27899393828018854, "compression_ratio": 1.6130952380952381, "no_speech_prob": 0.0011160090798512101}, {"id": 114, "seek": 77252, "start": 788.0799999999999, "end": 794.48, "text": " as usual. And this takes basically an identical amount of time, because at this point I'm", "tokens": [51142, 382, 7713, 13, 400, 341, 2516, 1936, 364, 14800, 2372, 295, 565, 11, 570, 412, 341, 935, 286, 478, 51462], "temperature": 0.0, "avg_logprob": -0.27899393828018854, "compression_ratio": 1.6130952380952381, "no_speech_prob": 0.0011160090798512101}, {"id": 115, "seek": 79448, "start": 794.48, "end": 800.24, "text": " not using multi GPU or TPU or whatever, I'm just using mixed precision. So this is just", "tokens": [50364, 406, 1228, 4825, 18407, 420, 314, 8115, 420, 2035, 11, 286, 478, 445, 1228, 7467, 18356, 13, 407, 341, 307, 445, 50652], "temperature": 0.0, "avg_logprob": -0.30457793787906046, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.06464255601167679}, {"id": 116, "seek": 79448, "start": 800.24, "end": 807.32, "text": " a shortcut for this. It's not a huge shortcut, the main purpose of it really is to allow", "tokens": [50652, 257, 24822, 337, 341, 13, 467, 311, 406, 257, 2603, 24822, 11, 264, 2135, 4334, 295, 309, 534, 307, 281, 2089, 51006], "temperature": 0.0, "avg_logprob": -0.30457793787906046, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.06464255601167679}, {"id": 117, "seek": 79448, "start": 807.32, "end": 812.52, "text": " us to use other types of accelerators, or multiple accelerators, or whatever. So we'll", "tokens": [51006, 505, 281, 764, 661, 3467, 295, 10172, 3391, 11, 420, 3866, 10172, 3391, 11, 420, 2035, 13, 407, 321, 603, 51266], "temperature": 0.0, "avg_logprob": -0.30457793787906046, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.06464255601167679}, {"id": 118, "seek": 79448, "start": 812.52, "end": 820.64, "text": " look at those later. Does that make sense so far? Yeah, oh yeah, it's sorry it's really", "tokens": [51266, 574, 412, 729, 1780, 13, 4402, 300, 652, 2020, 370, 1400, 30, 865, 11, 1954, 1338, 11, 309, 311, 2597, 309, 311, 534, 51672], "temperature": 0.0, "avg_logprob": -0.30457793787906046, "compression_ratio": 1.6175115207373272, "no_speech_prob": 0.06464255601167679}, {"id": 119, "seek": 82064, "start": 820.64, "end": 827.96, "text": " powerful and pretty amazing. Yeah, it is, and I know like a lot of, yeah, like I know", "tokens": [50364, 4005, 293, 1238, 2243, 13, 865, 11, 309, 307, 11, 293, 286, 458, 411, 257, 688, 295, 11, 1338, 11, 411, 286, 458, 50730], "temperature": 0.0, "avg_logprob": -0.2970593571662903, "compression_ratio": 1.5765765765765767, "no_speech_prob": 0.1258864402770996}, {"id": 120, "seek": 82064, "start": 827.96, "end": 834.04, "text": " Kat Carlson uses it in all her K diffusion code, for example. Yeah, it's used a lot out", "tokens": [50730, 8365, 14256, 3015, 4960, 309, 294, 439, 720, 591, 25242, 3089, 11, 337, 1365, 13, 865, 11, 309, 311, 1143, 257, 688, 484, 51034], "temperature": 0.0, "avg_logprob": -0.2970593571662903, "compression_ratio": 1.5765765765765767, "no_speech_prob": 0.1258864402770996}, {"id": 121, "seek": 82064, "start": 834.04, "end": 841.4, "text": " there in the real world. Yeah. I've got one more thing I just want to mention briefly,", "tokens": [51034, 456, 294, 264, 957, 1002, 13, 865, 13, 286, 600, 658, 472, 544, 551, 286, 445, 528, 281, 2152, 10515, 11, 51402], "temperature": 0.0, "avg_logprob": -0.2970593571662903, "compression_ratio": 1.5765765765765767, "no_speech_prob": 0.1258864402770996}, {"id": 122, "seek": 82064, "start": 841.4, "end": 844.96, "text": " just a sneaky trick. I haven't even bothered training anything with it, because it's just", "tokens": [51402, 445, 257, 39518, 4282, 13, 286, 2378, 380, 754, 22996, 3097, 1340, 365, 309, 11, 570, 309, 311, 445, 51580], "temperature": 0.0, "avg_logprob": -0.2970593571662903, "compression_ratio": 1.5765765765765767, "no_speech_prob": 0.1258864402770996}, {"id": 123, "seek": 84496, "start": 844.96, "end": 858.2, "text": " a sneaky trick. But sometimes thinking about speed, loading the data is the slow bit. And", "tokens": [50364, 257, 39518, 4282, 13, 583, 2171, 1953, 466, 3073, 11, 15114, 264, 1412, 307, 264, 2964, 857, 13, 400, 51026], "temperature": 0.0, "avg_logprob": -0.29696332931518554, "compression_ratio": 1.5276595744680852, "no_speech_prob": 0.03513699397444725}, {"id": 124, "seek": 84496, "start": 858.2, "end": 863.0, "text": " so particularly if you use Kaggle, for example, on Kaggle you get two GPUs, which is amazing,", "tokens": [51026, 370, 4098, 498, 291, 764, 48751, 22631, 11, 337, 1365, 11, 322, 48751, 22631, 291, 483, 732, 18407, 82, 11, 597, 307, 2243, 11, 51266], "temperature": 0.0, "avg_logprob": -0.29696332931518554, "compression_ratio": 1.5276595744680852, "no_speech_prob": 0.03513699397444725}, {"id": 125, "seek": 84496, "start": 863.0, "end": 868.32, "text": " but trying to get to CPUs, which is crazy. So it's really hard to like take advantage", "tokens": [51266, 457, 1382, 281, 483, 281, 13199, 82, 11, 597, 307, 3219, 13, 407, 309, 311, 534, 1152, 281, 411, 747, 5002, 51532], "temperature": 0.0, "avg_logprob": -0.29696332931518554, "compression_ratio": 1.5276595744680852, "no_speech_prob": 0.03513699397444725}, {"id": 126, "seek": 84496, "start": 868.32, "end": 874.5600000000001, "text": " of them, because the amount of time it takes to like open a PNG or a JPEG, you know, your", "tokens": [51532, 295, 552, 11, 570, 264, 2372, 295, 565, 309, 2516, 281, 411, 1269, 257, 430, 30237, 420, 257, 508, 5208, 38, 11, 291, 458, 11, 428, 51844], "temperature": 0.0, "avg_logprob": -0.29696332931518554, "compression_ratio": 1.5276595744680852, "no_speech_prob": 0.03513699397444725}, {"id": 127, "seek": 87456, "start": 874.56, "end": 882.3199999999999, "text": " GPU is sitting around waiting for you. So there's a, if your, you know, if your data", "tokens": [50364, 18407, 307, 3798, 926, 3806, 337, 291, 13, 407, 456, 311, 257, 11, 498, 428, 11, 291, 458, 11, 498, 428, 1412, 50752], "temperature": 0.0, "avg_logprob": -0.27579349279403687, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0005112503422424197}, {"id": 128, "seek": 87456, "start": 882.3199999999999, "end": 888.3599999999999, "text": " loading and transformation process is slow, and it's difficult to keep your GPUs busy,", "tokens": [50752, 15114, 293, 9887, 1399, 307, 2964, 11, 293, 309, 311, 2252, 281, 1066, 428, 18407, 82, 5856, 11, 51054], "temperature": 0.0, "avg_logprob": -0.27579349279403687, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0005112503422424197}, {"id": 129, "seek": 87456, "start": 888.3599999999999, "end": 897.3, "text": " there's a trick you can do, which is you could create a new data loader class, which wraps", "tokens": [51054, 456, 311, 257, 4282, 291, 393, 360, 11, 597, 307, 291, 727, 1884, 257, 777, 1412, 3677, 260, 1508, 11, 597, 25831, 51501], "temperature": 0.0, "avg_logprob": -0.27579349279403687, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0005112503422424197}, {"id": 130, "seek": 87456, "start": 897.3, "end": 901.8399999999999, "text": " your existing data loader, and it replaces dunder-idder. Now dunder-idder is the thing", "tokens": [51501, 428, 6741, 1412, 3677, 260, 11, 293, 309, 46734, 274, 6617, 12, 327, 1068, 13, 823, 274, 6617, 12, 327, 1068, 307, 264, 551, 51728], "temperature": 0.0, "avg_logprob": -0.27579349279403687, "compression_ratio": 1.6778846153846154, "no_speech_prob": 0.0005112503422424197}, {"id": 131, "seek": 90184, "start": 901.9200000000001, "end": 906.32, "text": " that gets called when you use a for loop, right? Or when you use next-idder, it calls", "tokens": [50368, 300, 2170, 1219, 562, 291, 764, 257, 337, 6367, 11, 558, 30, 1610, 562, 291, 764, 958, 12, 327, 1068, 11, 309, 5498, 50588], "temperature": 0.0, "avg_logprob": -0.27991655557462486, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.003945257980376482}, {"id": 132, "seek": 90184, "start": 906.32, "end": 912.88, "text": " this. And when you call this, you just go through the data loader as per usual, that's", "tokens": [50588, 341, 13, 400, 562, 291, 818, 341, 11, 291, 445, 352, 807, 264, 1412, 3677, 260, 382, 680, 7713, 11, 300, 311, 50916], "temperature": 0.0, "avg_logprob": -0.27991655557462486, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.003945257980376482}, {"id": 133, "seek": 90184, "start": 912.88, "end": 920.0400000000001, "text": " what dunder-idder would normally do. But then you also go through i from 0 to by default", "tokens": [50916, 437, 274, 6617, 12, 327, 1068, 576, 5646, 360, 13, 583, 550, 291, 611, 352, 807, 741, 490, 1958, 281, 538, 7576, 51274], "temperature": 0.0, "avg_logprob": -0.27991655557462486, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.003945257980376482}, {"id": 134, "seek": 90184, "start": 920.0400000000001, "end": 928.84, "text": " 2, and then you spit out the batch. And what this is going to do is it's going to go through", "tokens": [51274, 568, 11, 293, 550, 291, 22127, 484, 264, 15245, 13, 400, 437, 341, 307, 516, 281, 360, 307, 309, 311, 516, 281, 352, 807, 51714], "temperature": 0.0, "avg_logprob": -0.27991655557462486, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.003945257980376482}, {"id": 135, "seek": 92884, "start": 928.84, "end": 935.32, "text": " the data loader and spit out the batch twice. Why is that interesting? Because it means", "tokens": [50364, 264, 1412, 3677, 260, 293, 22127, 484, 264, 15245, 6091, 13, 1545, 307, 300, 1880, 30, 1436, 309, 1355, 50688], "temperature": 0.0, "avg_logprob": -0.2152360833209494, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.06559529900550842}, {"id": 136, "seek": 92884, "start": 935.32, "end": 941.88, "text": " every epoch is going to be twice as long, but it's going to only load and augment the", "tokens": [50688, 633, 30992, 339, 307, 516, 281, 312, 6091, 382, 938, 11, 457, 309, 311, 516, 281, 787, 3677, 293, 29919, 264, 51016], "temperature": 0.0, "avg_logprob": -0.2152360833209494, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.06559529900550842}, {"id": 137, "seek": 92884, "start": 941.88, "end": 949.76, "text": " data as often as one epoch, but it's going to give you two epochs worth of updates. And", "tokens": [51016, 1412, 382, 2049, 382, 472, 30992, 339, 11, 457, 309, 311, 516, 281, 976, 291, 732, 30992, 28346, 3163, 295, 9205, 13, 400, 51410], "temperature": 0.0, "avg_logprob": -0.2152360833209494, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.06559529900550842}, {"id": 138, "seek": 92884, "start": 949.76, "end": 955.72, "text": " basically there's no reason to have a whole new batch every time, you know, looking at", "tokens": [51410, 1936, 456, 311, 572, 1778, 281, 362, 257, 1379, 777, 15245, 633, 565, 11, 291, 458, 11, 1237, 412, 51708], "temperature": 0.0, "avg_logprob": -0.2152360833209494, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.06559529900550842}, {"id": 139, "seek": 95572, "start": 955.72, "end": 960.84, "text": " the same batch two or three or four times at a row is totally fine. And what happens", "tokens": [50364, 264, 912, 15245, 732, 420, 1045, 420, 1451, 1413, 412, 257, 5386, 307, 3879, 2489, 13, 400, 437, 2314, 50620], "temperature": 0.0, "avg_logprob": -0.23372960524125533, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.11121625453233719}, {"id": 140, "seek": 95572, "start": 960.84, "end": 965.8000000000001, "text": " in practice is you look at that batch, you do an update, get to any part of the wait", "tokens": [50620, 294, 3124, 307, 291, 574, 412, 300, 15245, 11, 291, 360, 364, 5623, 11, 483, 281, 604, 644, 295, 264, 1699, 50868], "temperature": 0.0, "avg_logprob": -0.23372960524125533, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.11121625453233719}, {"id": 141, "seek": 95572, "start": 965.8000000000001, "end": 972.1600000000001, "text": " space, look at exactly the same batch, and find out now where to go in the wait space.", "tokens": [50868, 1901, 11, 574, 412, 2293, 264, 912, 15245, 11, 293, 915, 484, 586, 689, 281, 352, 294, 264, 1699, 1901, 13, 51186], "temperature": 0.0, "avg_logprob": -0.23372960524125533, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.11121625453233719}, {"id": 142, "seek": 95572, "start": 972.1600000000001, "end": 979.32, "text": " It's still, yeah, basically equally useful. So I just wanted to add this little sneaky", "tokens": [51186, 467, 311, 920, 11, 1338, 11, 1936, 12309, 4420, 13, 407, 286, 445, 1415, 281, 909, 341, 707, 39518, 51544], "temperature": 0.0, "avg_logprob": -0.23372960524125533, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.11121625453233719}, {"id": 143, "seek": 95572, "start": 979.32, "end": 984.52, "text": " trick here, particularly because if we start doing more stuff on Kaggle, we'll probably", "tokens": [51544, 4282, 510, 11, 4098, 570, 498, 321, 722, 884, 544, 1507, 322, 48751, 22631, 11, 321, 603, 1391, 51804], "temperature": 0.0, "avg_logprob": -0.23372960524125533, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.11121625453233719}, {"id": 144, "seek": 98452, "start": 984.52, "end": 991.52, "text": " want to surprise all the Kagglers with how fast our mini AI solutions are. And they'll", "tokens": [50364, 528, 281, 6365, 439, 264, 48751, 7191, 433, 365, 577, 2370, 527, 8382, 7318, 6547, 366, 13, 400, 436, 603, 50714], "temperature": 0.0, "avg_logprob": -0.38562696225175236, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.00619282154366374}, {"id": 145, "seek": 98452, "start": 991.52, "end": 996.12, "text": " be like, how is that possible? We'll be like, oh, we're using our, you know, two GPUs, thanks", "tokens": [50714, 312, 411, 11, 577, 307, 300, 1944, 30, 492, 603, 312, 411, 11, 1954, 11, 321, 434, 1228, 527, 11, 291, 458, 11, 732, 18407, 82, 11, 3231, 50944], "temperature": 0.0, "avg_logprob": -0.38562696225175236, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.00619282154366374}, {"id": 146, "seek": 98452, "start": 996.12, "end": 1001.24, "text": " to accelerate. Asking him, how do we use the two GPUs? And like, oh, and we're, you know,", "tokens": [50944, 281, 21341, 13, 1018, 5092, 796, 11, 577, 360, 321, 764, 264, 732, 18407, 82, 30, 400, 411, 11, 1954, 11, 293, 321, 434, 11, 291, 458, 11, 51200], "temperature": 0.0, "avg_logprob": -0.38562696225175236, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.00619282154366374}, {"id": 147, "seek": 98452, "start": 1001.24, "end": 1007.12, "text": " using, you know, getting our loading flying through using multdl. I think that'd be pretty", "tokens": [51200, 1228, 11, 291, 458, 11, 1242, 527, 15114, 7137, 807, 1228, 2120, 67, 75, 13, 286, 519, 300, 1116, 312, 1238, 51494], "temperature": 0.0, "avg_logprob": -0.38562696225175236, "compression_ratio": 1.6484018264840183, "no_speech_prob": 0.00619282154366374}, {"id": 148, "seek": 100712, "start": 1007.12, "end": 1019.96, "text": " sweet. So that's that. Nice. Yeah, it's great to see the various different ways that we", "tokens": [50364, 3844, 13, 407, 300, 311, 300, 13, 5490, 13, 865, 11, 309, 311, 869, 281, 536, 264, 3683, 819, 2098, 300, 321, 51006], "temperature": 0.0, "avg_logprob": -0.28261640336778426, "compression_ratio": 1.4914285714285713, "no_speech_prob": 0.3665013611316681}, {"id": 149, "seek": 100712, "start": 1019.96, "end": 1027.0, "text": " can use mini AI to do the same thing, I guess, or, you know, however you feel like doing", "tokens": [51006, 393, 764, 8382, 7318, 281, 360, 264, 912, 551, 11, 286, 2041, 11, 420, 11, 291, 458, 11, 4461, 291, 841, 411, 884, 51358], "temperature": 0.0, "avg_logprob": -0.28261640336778426, "compression_ratio": 1.4914285714285713, "no_speech_prob": 0.3665013611316681}, {"id": 150, "seek": 100712, "start": 1027.0, "end": 1031.84, "text": " it or whatever works best for you. I'll be curious to see if other people find other", "tokens": [51358, 309, 420, 2035, 1985, 1151, 337, 291, 13, 286, 603, 312, 6369, 281, 536, 498, 661, 561, 915, 661, 51600], "temperature": 0.0, "avg_logprob": -0.28261640336778426, "compression_ratio": 1.4914285714285713, "no_speech_prob": 0.3665013611316681}, {"id": 151, "seek": 103184, "start": 1031.84, "end": 1037.24, "text": " ways to, you know, I'm sure there's so many different ways to handle this problem. I think", "tokens": [50364, 2098, 281, 11, 291, 458, 11, 286, 478, 988, 456, 311, 370, 867, 819, 2098, 281, 4813, 341, 1154, 13, 286, 519, 50634], "temperature": 0.0, "avg_logprob": -0.28264729730014143, "compression_ratio": 1.625, "no_speech_prob": 0.22802166640758514}, {"id": 152, "seek": 103184, "start": 1037.24, "end": 1043.9199999999998, "text": " it's an interesting problem to solve. And I think for the homework, it'd be useful for", "tokens": [50634, 309, 311, 364, 1880, 1154, 281, 5039, 13, 400, 286, 519, 337, 264, 14578, 11, 309, 1116, 312, 4420, 337, 50968], "temperature": 0.0, "avg_logprob": -0.28264729730014143, "compression_ratio": 1.625, "no_speech_prob": 0.22802166640758514}, {"id": 153, "seek": 103184, "start": 1043.9199999999998, "end": 1049.36, "text": " people to run some of their own experiments, maybe either use these techniques on other", "tokens": [50968, 561, 281, 1190, 512, 295, 641, 1065, 12050, 11, 1310, 2139, 764, 613, 7512, 322, 661, 51240], "temperature": 0.0, "avg_logprob": -0.28264729730014143, "compression_ratio": 1.625, "no_speech_prob": 0.22802166640758514}, {"id": 154, "seek": 103184, "start": 1049.36, "end": 1057.56, "text": " data sets, or see if you can come up with other variants of these approaches, or come", "tokens": [51240, 1412, 6352, 11, 420, 536, 498, 291, 393, 808, 493, 365, 661, 21669, 295, 613, 11587, 11, 420, 808, 51650], "temperature": 0.0, "avg_logprob": -0.28264729730014143, "compression_ratio": 1.625, "no_speech_prob": 0.22802166640758514}, {"id": 155, "seek": 105756, "start": 1057.56, "end": 1065.56, "text": " up with some different noise schedules to try. It would all be useful. Any other thoughts", "tokens": [50364, 493, 365, 512, 819, 5658, 28078, 281, 853, 13, 467, 576, 439, 312, 4420, 13, 2639, 661, 4598, 50764], "temperature": 0.0, "avg_logprob": -0.30377900198604285, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.13652350008487701}, {"id": 156, "seek": 105756, "start": 1065.56, "end": 1074.56, "text": " of exercises people could try? Yeah, I mean, getting away with less than a thousand steps.", "tokens": [50764, 295, 11900, 561, 727, 853, 30, 865, 11, 286, 914, 11, 1242, 1314, 365, 1570, 813, 257, 4714, 4439, 13, 51214], "temperature": 0.0, "avg_logprob": -0.30377900198604285, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.13652350008487701}, {"id": 157, "seek": 105756, "start": 1074.56, "end": 1079.32, "text": " Yeah, less than a thousand steps. It's happening in the final 200. So why not just train with", "tokens": [51214, 865, 11, 1570, 813, 257, 4714, 4439, 13, 467, 311, 2737, 294, 264, 2572, 2331, 13, 407, 983, 406, 445, 3847, 365, 51452], "temperature": 0.0, "avg_logprob": -0.30377900198604285, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.13652350008487701}, {"id": 158, "seek": 105756, "start": 1079.32, "end": 1085.2, "text": " only 200 steps? Yeah, less steps would be good. Yeah, because the sampling is actually", "tokens": [51452, 787, 2331, 4439, 30, 865, 11, 1570, 4439, 576, 312, 665, 13, 865, 11, 570, 264, 21179, 307, 767, 51746], "temperature": 0.0, "avg_logprob": -0.30377900198604285, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.13652350008487701}, {"id": 159, "seek": 108520, "start": 1085.2, "end": 1093.48, "text": " pretty slow. So that's a good point. Yeah, yeah, yeah, I was gonna say something similar", "tokens": [50364, 1238, 2964, 13, 407, 300, 311, 257, 665, 935, 13, 865, 11, 1338, 11, 1338, 11, 286, 390, 799, 584, 746, 2531, 50778], "temperature": 0.0, "avg_logprob": -0.2932012875874837, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.3344961702823639}, {"id": 160, "seek": 108520, "start": 1093.48, "end": 1098.3600000000001, "text": " in terms of like, yeah, many, I guess, work with less number of steps. You know, you would", "tokens": [50778, 294, 2115, 295, 411, 11, 1338, 11, 867, 11, 286, 2041, 11, 589, 365, 1570, 1230, 295, 4439, 13, 509, 458, 11, 291, 576, 51022], "temperature": 0.0, "avg_logprob": -0.2932012875874837, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.3344961702823639}, {"id": 161, "seek": 108520, "start": 1098.3600000000001, "end": 1103.72, "text": " have to adjust the noise schedule appropriately. And you have to, I guess there's maybe a little", "tokens": [51022, 362, 281, 4369, 264, 5658, 7567, 23505, 13, 400, 291, 362, 281, 11, 286, 2041, 456, 311, 1310, 257, 707, 51290], "temperature": 0.0, "avg_logprob": -0.2932012875874837, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.3344961702823639}, {"id": 162, "seek": 108520, "start": 1103.72, "end": 1111.68, "text": " bit more thought into some of these things. Or, you know, another aspect is like, when", "tokens": [51290, 857, 544, 1194, 666, 512, 295, 613, 721, 13, 1610, 11, 291, 458, 11, 1071, 4171, 307, 411, 11, 562, 51688], "temperature": 0.0, "avg_logprob": -0.2932012875874837, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.3344961702823639}, {"id": 163, "seek": 111168, "start": 1111.68, "end": 1118.4, "text": " you're selecting the time step during training, right now we select it randomly, kind of uniformly.", "tokens": [50364, 291, 434, 18182, 264, 565, 1823, 1830, 3097, 11, 558, 586, 321, 3048, 309, 16979, 11, 733, 295, 48806, 13, 50700], "temperature": 0.0, "avg_logprob": -0.29106340063623637, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.09533686190843582}, {"id": 164, "seek": 111168, "start": 1118.4, "end": 1123.44, "text": " Each time step has equal probability of being selected. Maybe different probabilities are", "tokens": [50700, 6947, 565, 1823, 575, 2681, 8482, 295, 885, 8209, 13, 2704, 819, 33783, 366, 50952], "temperature": 0.0, "avg_logprob": -0.29106340063623637, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.09533686190843582}, {"id": 165, "seek": 111168, "start": 1123.44, "end": 1127.88, "text": " better, and some papers do analyze that more carefully. So that's another thing to play", "tokens": [50952, 1101, 11, 293, 512, 10577, 360, 12477, 300, 544, 7500, 13, 407, 300, 311, 1071, 551, 281, 862, 51174], "temperature": 0.0, "avg_logprob": -0.29106340063623637, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.09533686190843582}, {"id": 166, "seek": 111168, "start": 1127.88, "end": 1136.0800000000002, "text": " around with as well. That's almost kind of like, if, I guess there are almost two ways", "tokens": [51174, 926, 365, 382, 731, 13, 663, 311, 1920, 733, 295, 411, 11, 498, 11, 286, 2041, 456, 366, 1920, 732, 2098, 51584], "temperature": 0.0, "avg_logprob": -0.29106340063623637, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.09533686190843582}, {"id": 167, "seek": 113608, "start": 1136.08, "end": 1143.3999999999999, "text": " of doing the same thing, in a sense, right? If you change that mapping from T to beta,", "tokens": [50364, 295, 884, 264, 912, 551, 11, 294, 257, 2020, 11, 558, 30, 759, 291, 1319, 300, 18350, 490, 314, 281, 9861, 11, 50730], "temperature": 0.0, "avg_logprob": -0.3084867832272552, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.32412227988243103}, {"id": 168, "seek": 113608, "start": 1143.3999999999999, "end": 1150.96, "text": " then you could reduce T and have different betas, would kind of give you a similar result", "tokens": [50730, 550, 291, 727, 5407, 314, 293, 362, 819, 778, 296, 11, 576, 733, 295, 976, 291, 257, 2531, 1874, 51108], "temperature": 0.0, "avg_logprob": -0.3084867832272552, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.32412227988243103}, {"id": 169, "seek": 113608, "start": 1150.96, "end": 1159.28, "text": " as changing the probabilities of the Ts, I think. Yeah, I think there's definitely, they're", "tokens": [51108, 382, 4473, 264, 33783, 295, 264, 16518, 11, 286, 519, 13, 865, 11, 286, 519, 456, 311, 2138, 11, 436, 434, 51524], "temperature": 0.0, "avg_logprob": -0.3084867832272552, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.32412227988243103}, {"id": 170, "seek": 113608, "start": 1159.28, "end": 1164.72, "text": " kind of similar, but potentially something complementary happening there as well. And", "tokens": [51524, 733, 295, 2531, 11, 457, 7263, 746, 40705, 2737, 456, 382, 731, 13, 400, 51796], "temperature": 0.0, "avg_logprob": -0.3084867832272552, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.32412227988243103}, {"id": 171, "seek": 116472, "start": 1164.72, "end": 1174.6000000000001, "text": " I think those could be some interesting experiments to study that. And also, the sort of noise", "tokens": [50364, 286, 519, 729, 727, 312, 512, 1880, 12050, 281, 2979, 300, 13, 400, 611, 11, 264, 1333, 295, 5658, 50858], "temperature": 0.0, "avg_logprob": -0.31632250408793605, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.005468395072966814}, {"id": 172, "seek": 116472, "start": 1174.6000000000001, "end": 1181.1200000000001, "text": " levels that you do choose affect the sort of behavior of the sampling process, and of", "tokens": [50858, 4358, 300, 291, 360, 2826, 3345, 264, 1333, 295, 5223, 295, 264, 21179, 1399, 11, 293, 295, 51184], "temperature": 0.0, "avg_logprob": -0.31632250408793605, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.005468395072966814}, {"id": 173, "seek": 116472, "start": 1181.1200000000001, "end": 1187.08, "text": " course, what features you focus on. And so maybe as people play around with that, maybe", "tokens": [51184, 1164, 11, 437, 4122, 291, 1879, 322, 13, 400, 370, 1310, 382, 561, 862, 926, 365, 300, 11, 1310, 51482], "temperature": 0.0, "avg_logprob": -0.31632250408793605, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.005468395072966814}, {"id": 174, "seek": 116472, "start": 1187.08, "end": 1192.64, "text": " they'll start to notice how using, yeah, different noise levels, or, you know, different noise", "tokens": [51482, 436, 603, 722, 281, 3449, 577, 1228, 11, 1338, 11, 819, 5658, 4358, 11, 420, 11, 291, 458, 11, 819, 5658, 51760], "temperature": 0.0, "avg_logprob": -0.31632250408793605, "compression_ratio": 1.6575342465753424, "no_speech_prob": 0.005468395072966814}, {"id": 175, "seek": 119264, "start": 1192.64, "end": 1199.16, "text": " levels affect maybe some of the features that you see in the final image. And that", "tokens": [50364, 4358, 3345, 1310, 512, 295, 264, 4122, 300, 291, 536, 294, 264, 2572, 3256, 13, 400, 300, 50690], "temperature": 0.0, "avg_logprob": -0.30961979641003556, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.061873164027929306}, {"id": 176, "seek": 119264, "start": 1199.16, "end": 1206.2800000000002, "text": " could be something very interesting to study as well. Great. Well, let me also say it's", "tokens": [50690, 727, 312, 746, 588, 1880, 281, 2979, 382, 731, 13, 3769, 13, 1042, 11, 718, 385, 611, 584, 309, 311, 51046], "temperature": 0.0, "avg_logprob": -0.30961979641003556, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.061873164027929306}, {"id": 177, "seek": 119264, "start": 1206.2800000000002, "end": 1210.96, "text": " been really fun doing something a bit different, which is doing a lesson with you guys, rather", "tokens": [51046, 668, 534, 1019, 884, 746, 257, 857, 819, 11, 597, 307, 884, 257, 6898, 365, 291, 1074, 11, 2831, 51280], "temperature": 0.0, "avg_logprob": -0.30961979641003556, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.061873164027929306}, {"id": 178, "seek": 119264, "start": 1210.96, "end": 1215.96, "text": " than all on my lonesome. I hope we can do this again, because I've really enjoyed it.", "tokens": [51280, 813, 439, 322, 452, 287, 2213, 423, 13, 286, 1454, 321, 393, 360, 341, 797, 11, 570, 286, 600, 534, 4626, 309, 13, 51530], "temperature": 0.0, "avg_logprob": -0.30961979641003556, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.061873164027929306}, {"id": 179, "seek": 121596, "start": 1215.96, "end": 1222.2, "text": " Yeah, it was great. So of course, now, you know, strictly speaking, in the recording,", "tokens": [50364, 865, 11, 309, 390, 869, 13, 407, 295, 1164, 11, 586, 11, 291, 458, 11, 20792, 4124, 11, 294, 264, 6613, 11, 50676], "temperature": 0.0, "avg_logprob": -0.34159884832601634, "compression_ratio": 1.5580524344569289, "no_speech_prob": 0.25968363881111145}, {"id": 180, "seek": 121596, "start": 1222.2, "end": 1227.76, "text": " we'll next up see Jono, who's actually already recorded his, thanks to the Zoom mess up,", "tokens": [50676, 321, 603, 958, 493, 536, 7745, 78, 11, 567, 311, 767, 1217, 8287, 702, 11, 3231, 281, 264, 13453, 2082, 493, 11, 50954], "temperature": 0.0, "avg_logprob": -0.34159884832601634, "compression_ratio": 1.5580524344569289, "no_speech_prob": 0.25968363881111145}, {"id": 181, "seek": 121596, "start": 1227.76, "end": 1232.64, "text": " but stick around. So I've already seen it. Jono's thing is amazing. So you definitely", "tokens": [50954, 457, 2897, 926, 13, 407, 286, 600, 1217, 1612, 309, 13, 7745, 78, 311, 551, 307, 2243, 13, 407, 291, 2138, 51198], "temperature": 0.0, "avg_logprob": -0.34159884832601634, "compression_ratio": 1.5580524344569289, "no_speech_prob": 0.25968363881111145}, {"id": 182, "seek": 121596, "start": 1232.64, "end": 1237.0, "text": " don't want to miss that. Hello, everyone. So today, depending on the", "tokens": [51198, 500, 380, 528, 281, 1713, 300, 13, 2425, 11, 1518, 13, 407, 965, 11, 5413, 322, 264, 51416], "temperature": 0.0, "avg_logprob": -0.34159884832601634, "compression_ratio": 1.5580524344569289, "no_speech_prob": 0.25968363881111145}, {"id": 183, "seek": 121596, "start": 1237.0, "end": 1242.16, "text": " order that this ends up happening, you've probably seen Tanishq's DBPM implementation,", "tokens": [51416, 1668, 300, 341, 5314, 493, 2737, 11, 291, 600, 1391, 1612, 314, 7524, 80, 311, 26754, 18819, 11420, 11, 51674], "temperature": 0.0, "avg_logprob": -0.34159884832601634, "compression_ratio": 1.5580524344569289, "no_speech_prob": 0.25968363881111145}, {"id": 184, "seek": 124216, "start": 1242.16, "end": 1245.96, "text": " where we're taking the default training callback and doing some more interesting things with", "tokens": [50364, 689, 321, 434, 1940, 264, 7576, 3097, 818, 3207, 293, 884, 512, 544, 1880, 721, 365, 50554], "temperature": 0.0, "avg_logprob": -0.26869311987185013, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.6073727607727051}, {"id": 185, "seek": 124216, "start": 1245.96, "end": 1251.3600000000001, "text": " preparing the data for the learner or interpreting the results. So in these two notebooks that", "tokens": [50554, 10075, 264, 1412, 337, 264, 33347, 420, 37395, 264, 3542, 13, 407, 294, 613, 732, 43782, 300, 50824], "temperature": 0.0, "avg_logprob": -0.26869311987185013, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.6073727607727051}, {"id": 186, "seek": 124216, "start": 1251.3600000000001, "end": 1255.0, "text": " I'm going to show, we're going to be doing something similar, just exploring like, what", "tokens": [50824, 286, 478, 516, 281, 855, 11, 321, 434, 516, 281, 312, 884, 746, 2531, 11, 445, 12736, 411, 11, 437, 51006], "temperature": 0.0, "avg_logprob": -0.26869311987185013, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.6073727607727051}, {"id": 187, "seek": 124216, "start": 1255.0, "end": 1259.8400000000001, "text": " else can we do besides just the classic kind of classification model where we have some", "tokens": [51006, 1646, 393, 321, 360, 11868, 445, 264, 7230, 733, 295, 21538, 2316, 689, 321, 362, 512, 51248], "temperature": 0.0, "avg_logprob": -0.26869311987185013, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.6073727607727051}, {"id": 188, "seek": 124216, "start": 1259.8400000000001, "end": 1266.44, "text": " inputs and a label? And what else can we do with this mini AI setup that we have? And", "tokens": [51248, 15743, 293, 257, 7645, 30, 400, 437, 1646, 393, 321, 360, 365, 341, 8382, 7318, 8657, 300, 321, 362, 30, 400, 51578], "temperature": 0.0, "avg_logprob": -0.26869311987185013, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.6073727607727051}, {"id": 189, "seek": 126644, "start": 1266.44, "end": 1274.6000000000001, "text": " so in the first one, we're going to approach a kind of classic AI art approach called", "tokens": [50364, 370, 294, 264, 700, 472, 11, 321, 434, 516, 281, 3109, 257, 733, 295, 7230, 7318, 1523, 3109, 1219, 50772], "temperature": 0.0, "avg_logprob": -0.21901501349683078, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.20175258815288544}, {"id": 190, "seek": 126644, "start": 1274.6000000000001, "end": 1279.56, "text": " style transfer. And so the idea here is that we're going to want to somehow create an artistic", "tokens": [50772, 3758, 5003, 13, 400, 370, 264, 1558, 510, 307, 300, 321, 434, 516, 281, 528, 281, 6063, 1884, 364, 17090, 51020], "temperature": 0.0, "avg_logprob": -0.21901501349683078, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.20175258815288544}, {"id": 191, "seek": 126644, "start": 1279.56, "end": 1285.6000000000001, "text": " combination of two images where we have the structure and layout of one image and the", "tokens": [51020, 6562, 295, 732, 5267, 689, 321, 362, 264, 3877, 293, 13333, 295, 472, 3256, 293, 264, 51322], "temperature": 0.0, "avg_logprob": -0.21901501349683078, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.20175258815288544}, {"id": 192, "seek": 126644, "start": 1285.6000000000001, "end": 1288.6000000000001, "text": " style of another. So we'll look at how we do that. And then we'll also talk along the", "tokens": [51322, 3758, 295, 1071, 13, 407, 321, 603, 574, 412, 577, 321, 360, 300, 13, 400, 550, 321, 603, 611, 751, 2051, 264, 51472], "temperature": 0.0, "avg_logprob": -0.21901501349683078, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.20175258815288544}, {"id": 193, "seek": 126644, "start": 1288.6000000000001, "end": 1294.64, "text": " way in terms of like, why is this actually useful beyond just making pretty pictures?", "tokens": [51472, 636, 294, 2115, 295, 411, 11, 983, 307, 341, 767, 4420, 4399, 445, 1455, 1238, 5242, 30, 51774], "temperature": 0.0, "avg_logprob": -0.21901501349683078, "compression_ratio": 1.6846153846153846, "no_speech_prob": 0.20175258815288544}, {"id": 194, "seek": 129464, "start": 1294.64, "end": 1298.5200000000002, "text": " So to start with, I've got a couple of URLs for images. You're welcome to go and slip", "tokens": [50364, 407, 281, 722, 365, 11, 286, 600, 658, 257, 1916, 295, 43267, 337, 5267, 13, 509, 434, 2928, 281, 352, 293, 11140, 50558], "temperature": 0.0, "avg_logprob": -0.2092101914542062, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.18706423044204712}, {"id": 195, "seek": 129464, "start": 1298.5200000000002, "end": 1302.2800000000002, "text": " in your own as well. I definitely recommend trying this notebook with some different ones", "tokens": [50558, 294, 428, 1065, 382, 731, 13, 286, 2138, 2748, 1382, 341, 21060, 365, 512, 819, 2306, 50746], "temperature": 0.0, "avg_logprob": -0.2092101914542062, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.18706423044204712}, {"id": 196, "seek": 129464, "start": 1302.2800000000002, "end": 1308.3200000000002, "text": " just to see what effects you can get. And we're going to download the image and load", "tokens": [50746, 445, 281, 536, 437, 5065, 291, 393, 483, 13, 400, 321, 434, 516, 281, 5484, 264, 3256, 293, 3677, 51048], "temperature": 0.0, "avg_logprob": -0.2092101914542062, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.18706423044204712}, {"id": 197, "seek": 129464, "start": 1308.3200000000002, "end": 1314.72, "text": " it up as a tensor. So we have here a three channel image, 256 by 256 pixels. And so this", "tokens": [51048, 309, 493, 382, 257, 40863, 13, 407, 321, 362, 510, 257, 1045, 2269, 3256, 11, 38882, 538, 38882, 18668, 13, 400, 370, 341, 51368], "temperature": 0.0, "avg_logprob": -0.2092101914542062, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.18706423044204712}, {"id": 198, "seek": 129464, "start": 1314.72, "end": 1318.72, "text": " is the kind of base image that we're going to start working with. So before we talk about", "tokens": [51368, 307, 264, 733, 295, 3096, 3256, 300, 321, 434, 516, 281, 722, 1364, 365, 13, 407, 949, 321, 751, 466, 51568], "temperature": 0.0, "avg_logprob": -0.2092101914542062, "compression_ratio": 1.6139705882352942, "no_speech_prob": 0.18706423044204712}, {"id": 199, "seek": 131872, "start": 1318.72, "end": 1325.08, "text": " styles or anything, let's just think what is our goal here? We'd like to do some sort", "tokens": [50364, 13273, 420, 1340, 11, 718, 311, 445, 519, 437, 307, 527, 3387, 510, 30, 492, 1116, 411, 281, 360, 512, 1333, 50682], "temperature": 0.0, "avg_logprob": -0.24765609191344665, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.5542393922805786}, {"id": 200, "seek": 131872, "start": 1325.08, "end": 1329.52, "text": " of training or optimization. We'd like to get to a point where we can match some aspect", "tokens": [50682, 295, 3097, 420, 19618, 13, 492, 1116, 411, 281, 483, 281, 257, 935, 689, 321, 393, 2995, 512, 4171, 50904], "temperature": 0.0, "avg_logprob": -0.24765609191344665, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.5542393922805786}, {"id": 201, "seek": 131872, "start": 1329.52, "end": 1336.16, "text": " of this image. And so maybe a good place to start is to just try and do, well, can we", "tokens": [50904, 295, 341, 3256, 13, 400, 370, 1310, 257, 665, 1081, 281, 722, 307, 281, 445, 853, 293, 360, 11, 731, 11, 393, 321, 51236], "temperature": 0.0, "avg_logprob": -0.24765609191344665, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.5542393922805786}, {"id": 202, "seek": 131872, "start": 1336.16, "end": 1341.3600000000001, "text": " start from a random image and optimize it until it matches pixel for pixel exactly?", "tokens": [51236, 722, 490, 257, 4974, 3256, 293, 19719, 309, 1826, 309, 10676, 19261, 337, 19261, 2293, 30, 51496], "temperature": 0.0, "avg_logprob": -0.24765609191344665, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.5542393922805786}, {"id": 203, "seek": 131872, "start": 1341.3600000000001, "end": 1345.2, "text": " And that's going to help us get this. Yeah. Something that might be helpful is if you", "tokens": [51496, 400, 300, 311, 516, 281, 854, 505, 483, 341, 13, 865, 13, 6595, 300, 1062, 312, 4961, 307, 498, 291, 51688], "temperature": 0.0, "avg_logprob": -0.24765609191344665, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.5542393922805786}, {"id": 204, "seek": 134520, "start": 1345.2, "end": 1351.0800000000002, "text": " type style transfer deep learning into Google images, you could maybe show some examples", "tokens": [50364, 2010, 3758, 5003, 2452, 2539, 666, 3329, 5267, 11, 291, 727, 1310, 855, 512, 5110, 50658], "temperature": 0.0, "avg_logprob": -0.315249117937955, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.4300270974636078}, {"id": 205, "seek": 134520, "start": 1351.0800000000002, "end": 1360.2, "text": " so that people will see what their goal is. Yeah, that's a very good point. So let's see.", "tokens": [50658, 370, 300, 561, 486, 536, 437, 641, 3387, 307, 13, 865, 11, 300, 311, 257, 588, 665, 935, 13, 407, 718, 311, 536, 13, 51114], "temperature": 0.0, "avg_logprob": -0.315249117937955, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.4300270974636078}, {"id": 206, "seek": 134520, "start": 1360.2, "end": 1365.28, "text": " This is a good one here. We've got the Mona Lisa as our base, but we've managed to apply", "tokens": [51114, 639, 307, 257, 665, 472, 510, 13, 492, 600, 658, 264, 43731, 12252, 382, 527, 3096, 11, 457, 321, 600, 6453, 281, 3079, 51368], "temperature": 0.0, "avg_logprob": -0.315249117937955, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.4300270974636078}, {"id": 207, "seek": 134520, "start": 1365.28, "end": 1370.76, "text": " somehow some different artistic styles to that same base structure. So we have the great", "tokens": [51368, 6063, 512, 819, 17090, 13273, 281, 300, 912, 3096, 3877, 13, 407, 321, 362, 264, 869, 51642], "temperature": 0.0, "avg_logprob": -0.315249117937955, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.4300270974636078}, {"id": 208, "seek": 137076, "start": 1370.76, "end": 1376.8, "text": " wave by Misaki. We have starry night by Vincent Van Gogh. This is some sort of Kandinsky or", "tokens": [50364, 5772, 538, 23240, 7421, 13, 492, 362, 3543, 627, 1818, 538, 28003, 8979, 39690, 71, 13, 639, 307, 512, 1333, 295, 591, 474, 44153, 420, 50666], "temperature": 0.0, "avg_logprob": -0.33246459131655487, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.403449684381485}, {"id": 209, "seek": 137076, "start": 1376.8, "end": 1380.76, "text": " something. Yeah. So this is our end goal to be able to take the overall structure and", "tokens": [50666, 746, 13, 865, 13, 407, 341, 307, 527, 917, 3387, 281, 312, 1075, 281, 747, 264, 4787, 3877, 293, 50864], "temperature": 0.0, "avg_logprob": -0.33246459131655487, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.403449684381485}, {"id": 210, "seek": 137076, "start": 1380.76, "end": 1385.96, "text": " layout of one image and the style from some different reference image. And in fact, this", "tokens": [50864, 13333, 295, 472, 3256, 293, 264, 3758, 490, 512, 819, 6408, 3256, 13, 400, 294, 1186, 11, 341, 51124], "temperature": 0.0, "avg_logprob": -0.33246459131655487, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.403449684381485}, {"id": 211, "seek": 137076, "start": 1385.96, "end": 1395.76, "text": " was the first ever, I think, fast.ai generative modeling lesson looked at style transfer.", "tokens": [51124, 390, 264, 700, 1562, 11, 286, 519, 11, 2370, 13, 1301, 1337, 1166, 15983, 6898, 2956, 412, 3758, 5003, 13, 51614], "temperature": 0.0, "avg_logprob": -0.33246459131655487, "compression_ratio": 1.5411255411255411, "no_speech_prob": 0.403449684381485}, {"id": 212, "seek": 139576, "start": 1395.76, "end": 1400.96, "text": " It's been around for a few years. It's kind of a classic technique. And it's really, I", "tokens": [50364, 467, 311, 668, 926, 337, 257, 1326, 924, 13, 467, 311, 733, 295, 257, 7230, 6532, 13, 400, 309, 311, 534, 11, 286, 50624], "temperature": 0.0, "avg_logprob": -0.2749155169335481, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0926520824432373}, {"id": 213, "seek": 139576, "start": 1400.96, "end": 1406.44, "text": " think a lot of the students, when we first did it, found it extremely useful, a way of", "tokens": [50624, 519, 257, 688, 295, 264, 1731, 11, 562, 321, 700, 630, 309, 11, 1352, 309, 4664, 4420, 11, 257, 636, 295, 50898], "temperature": 0.0, "avg_logprob": -0.2749155169335481, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0926520824432373}, {"id": 214, "seek": 139576, "start": 1406.44, "end": 1413.36, "text": " better understanding, like, you know, flexing their deep learning muscles, understanding", "tokens": [50898, 1101, 3701, 11, 411, 11, 291, 458, 11, 5896, 278, 641, 2452, 2539, 9530, 11, 3701, 51244], "temperature": 0.0, "avg_logprob": -0.2749155169335481, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0926520824432373}, {"id": 215, "seek": 139576, "start": 1413.36, "end": 1419.64, "text": " what's going on, and also created some really interesting new approaches. So hopefully we'll", "tokens": [51244, 437, 311, 516, 322, 11, 293, 611, 2942, 512, 534, 1880, 777, 11587, 13, 407, 4696, 321, 603, 51558], "temperature": 0.0, "avg_logprob": -0.2749155169335481, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0926520824432373}, {"id": 216, "seek": 139576, "start": 1419.64, "end": 1425.36, "text": " see the same thing again. Maybe some students will be able to show some really interesting", "tokens": [51558, 536, 264, 912, 551, 797, 13, 2704, 512, 1731, 486, 312, 1075, 281, 855, 512, 534, 1880, 51844], "temperature": 0.0, "avg_logprob": -0.2749155169335481, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0926520824432373}, {"id": 217, "seek": 142536, "start": 1425.36, "end": 1429.12, "text": " results from this. Yeah. And I mean, today we're going to focus", "tokens": [50364, 3542, 490, 341, 13, 865, 13, 400, 286, 914, 11, 965, 321, 434, 516, 281, 1879, 50552], "temperature": 0.0, "avg_logprob": -0.24908818304538727, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.8126504421234131}, {"id": 218, "seek": 142536, "start": 1429.12, "end": 1434.1999999999998, "text": " on kind of the classic approach. But I know one of the previous students from fast.ai", "tokens": [50552, 322, 733, 295, 264, 7230, 3109, 13, 583, 286, 458, 472, 295, 264, 3894, 1731, 490, 2370, 13, 1301, 50806], "temperature": 0.0, "avg_logprob": -0.24908818304538727, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.8126504421234131}, {"id": 219, "seek": 142536, "start": 1434.1999999999998, "end": 1439.3999999999999, "text": " did a whole different way of doing that style loss that we'll maybe post in the forums or,", "tokens": [50806, 630, 257, 1379, 819, 636, 295, 884, 300, 3758, 4470, 300, 321, 603, 1310, 2183, 294, 264, 26998, 420, 11, 51066], "temperature": 0.0, "avg_logprob": -0.24908818304538727, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.8126504421234131}, {"id": 220, "seek": 142536, "start": 1439.3999999999999, "end": 1443.08, "text": " you know, I've got some comparisons that we can look at. So yeah, definitely a fruitful", "tokens": [51066, 291, 458, 11, 286, 600, 658, 512, 33157, 300, 321, 393, 574, 412, 13, 407, 1338, 11, 2138, 257, 49795, 51250], "temperature": 0.0, "avg_logprob": -0.24908818304538727, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.8126504421234131}, {"id": 221, "seek": 142536, "start": 1443.08, "end": 1447.3999999999999, "text": " field still. And I think after the initial hype of like, everyone was excited about style", "tokens": [51250, 2519, 920, 13, 400, 286, 519, 934, 264, 5883, 24144, 295, 411, 11, 1518, 390, 2919, 466, 3758, 51466], "temperature": 0.0, "avg_logprob": -0.24908818304538727, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.8126504421234131}, {"id": 222, "seek": 142536, "start": 1447.3999999999999, "end": 1451.9599999999998, "text": " transfer apps and things, I don't know, five years ago, I feel like there's still some", "tokens": [51466, 5003, 7733, 293, 721, 11, 286, 500, 380, 458, 11, 1732, 924, 2057, 11, 286, 841, 411, 456, 311, 920, 512, 51694], "temperature": 0.0, "avg_logprob": -0.24908818304538727, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.8126504421234131}, {"id": 223, "seek": 145196, "start": 1451.96, "end": 1455.52, "text": " things to explore there. I agree.", "tokens": [50364, 721, 281, 6839, 456, 13, 286, 3986, 13, 50542], "temperature": 0.0, "avg_logprob": -0.2796613036609087, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.5810192823410034}, {"id": 224, "seek": 145196, "start": 1455.52, "end": 1461.44, "text": " Very creative and fun little diversion in the deep learning world. Okay. So our first", "tokens": [50542, 4372, 5880, 293, 1019, 707, 49422, 294, 264, 2452, 2539, 1002, 13, 1033, 13, 407, 527, 700, 50838], "temperature": 0.0, "avg_logprob": -0.2796613036609087, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.5810192823410034}, {"id": 225, "seek": 145196, "start": 1461.44, "end": 1466.28, "text": " step in getting to that point is being able to optimize an image. And so up until now,", "tokens": [50838, 1823, 294, 1242, 281, 300, 935, 307, 885, 1075, 281, 19719, 364, 3256, 13, 400, 370, 493, 1826, 586, 11, 51080], "temperature": 0.0, "avg_logprob": -0.2796613036609087, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.5810192823410034}, {"id": 226, "seek": 145196, "start": 1466.28, "end": 1469.96, "text": " we've been optimizing like the weights of a neural network. But now we want to go to", "tokens": [51080, 321, 600, 668, 40425, 411, 264, 17443, 295, 257, 18161, 3209, 13, 583, 586, 321, 528, 281, 352, 281, 51264], "temperature": 0.0, "avg_logprob": -0.2796613036609087, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.5810192823410034}, {"id": 227, "seek": 145196, "start": 1469.96, "end": 1473.28, "text": " something a bit more simple. And we just want to optimize the raw pixels of an image.", "tokens": [51264, 746, 257, 857, 544, 2199, 13, 400, 321, 445, 528, 281, 19719, 264, 8936, 18668, 295, 364, 3256, 13, 51430], "temperature": 0.0, "avg_logprob": -0.2796613036609087, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.5810192823410034}, {"id": 228, "seek": 145196, "start": 1473.28, "end": 1477.44, "text": " Do you mind if we scroll up a bit to the previous code, just so we can have a look at it. So", "tokens": [51430, 1144, 291, 1575, 498, 321, 11369, 493, 257, 857, 281, 264, 3894, 3089, 11, 445, 370, 321, 393, 362, 257, 574, 412, 309, 13, 407, 51638], "temperature": 0.0, "avg_logprob": -0.2796613036609087, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.5810192823410034}, {"id": 229, "seek": 147744, "start": 1477.52, "end": 1481.48, "text": " there's a couple of interesting points about this code here is, you know, we're not, we're", "tokens": [50368, 456, 311, 257, 1916, 295, 1880, 2793, 466, 341, 3089, 510, 307, 11, 291, 458, 11, 321, 434, 406, 11, 321, 434, 50566], "temperature": 0.0, "avg_logprob": -0.25550105494837605, "compression_ratio": 1.5971223021582734, "no_speech_prob": 0.46856164932250977}, {"id": 230, "seek": 147744, "start": 1481.48, "end": 1488.8, "text": " not cheating. Well, not really. So we're, so yeah, we, we, we've seen how to download", "tokens": [50566, 406, 18309, 13, 1042, 11, 406, 534, 13, 407, 321, 434, 11, 370, 1338, 11, 321, 11, 321, 11, 321, 600, 1612, 577, 281, 5484, 50932], "temperature": 0.0, "avg_logprob": -0.25550105494837605, "compression_ratio": 1.5971223021582734, "no_speech_prob": 0.46856164932250977}, {"id": 231, "seek": 147744, "start": 1488.8, "end": 1492.52, "text": " things in the network before. So we're using fast codes URL read, because we're allowed", "tokens": [50932, 721, 294, 264, 3209, 949, 13, 407, 321, 434, 1228, 2370, 14211, 12905, 1401, 11, 570, 321, 434, 4350, 51118], "temperature": 0.0, "avg_logprob": -0.25550105494837605, "compression_ratio": 1.5971223021582734, "no_speech_prob": 0.46856164932250977}, {"id": 232, "seek": 147744, "start": 1492.52, "end": 1498.64, "text": " to. And then I think we decided we weren't going to write our own JPEG parser. So Torchvision", "tokens": [51118, 281, 13, 400, 550, 286, 519, 321, 3047, 321, 4999, 380, 516, 281, 2464, 527, 1065, 508, 5208, 38, 21156, 260, 13, 407, 7160, 339, 6763, 51424], "temperature": 0.0, "avg_logprob": -0.25550105494837605, "compression_ratio": 1.5971223021582734, "no_speech_prob": 0.46856164932250977}, {"id": 233, "seek": 147744, "start": 1498.64, "end": 1503.2, "text": " actually has a pretty good one, which a lot of people don't realize exists. And a lot", "tokens": [51424, 767, 575, 257, 1238, 665, 472, 11, 597, 257, 688, 295, 561, 500, 380, 4325, 8198, 13, 400, 257, 688, 51652], "temperature": 0.0, "avg_logprob": -0.25550105494837605, "compression_ratio": 1.5971223021582734, "no_speech_prob": 0.46856164932250977}, {"id": 234, "seek": 150320, "start": 1503.2, "end": 1512.0800000000002, "text": " of people tend to use PIL, but actually Torchvision has a more performant option. And it's actually", "tokens": [50364, 295, 561, 3928, 281, 764, 430, 4620, 11, 457, 767, 7160, 339, 6763, 575, 257, 544, 2042, 394, 3614, 13, 400, 309, 311, 767, 50808], "temperature": 0.0, "avg_logprob": -0.2524288020183131, "compression_ratio": 1.5446808510638297, "no_speech_prob": 0.5349812507629395}, {"id": 235, "seek": 150320, "start": 1512.0800000000002, "end": 1520.28, "text": " quite difficult to find any examples of how to use it like this. But here's some code", "tokens": [50808, 1596, 2252, 281, 915, 604, 5110, 295, 577, 281, 764, 309, 411, 341, 13, 583, 510, 311, 512, 3089, 51218], "temperature": 0.0, "avg_logprob": -0.2524288020183131, "compression_ratio": 1.5446808510638297, "no_speech_prob": 0.5349812507629395}, {"id": 236, "seek": 150320, "start": 1520.28, "end": 1525.92, "text": " you can borrow. Yeah. And actually Google load image from a URL in PyTorch. All of the", "tokens": [51218, 291, 393, 11172, 13, 865, 13, 400, 767, 3329, 3677, 3256, 490, 257, 12905, 294, 9953, 51, 284, 339, 13, 1057, 295, 264, 51500], "temperature": 0.0, "avg_logprob": -0.2524288020183131, "compression_ratio": 1.5446808510638297, "no_speech_prob": 0.5349812507629395}, {"id": 237, "seek": 150320, "start": 1525.92, "end": 1530.8400000000001, "text": " examples are going to use PIL. And that's what I've done historically, is use the requests", "tokens": [51500, 5110, 366, 516, 281, 764, 430, 4620, 13, 400, 300, 311, 437, 286, 600, 1096, 16180, 11, 307, 764, 264, 12475, 51746], "temperature": 0.0, "avg_logprob": -0.2524288020183131, "compression_ratio": 1.5446808510638297, "no_speech_prob": 0.5349812507629395}, {"id": 238, "seek": 153084, "start": 1530.84, "end": 1538.3999999999999, "text": " library to download the URL and then feed that into PIL's image.open function. So yeah,", "tokens": [50364, 6405, 281, 5484, 264, 12905, 293, 550, 3154, 300, 666, 430, 4620, 311, 3256, 13, 15752, 2445, 13, 407, 1338, 11, 50742], "temperature": 0.0, "avg_logprob": -0.30103680125454013, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.5963772535324097}, {"id": 239, "seek": 153084, "start": 1538.3999999999999, "end": 1541.1999999999998, "text": " that was fun when I was working with Jeremy on this notebook, like that's how I was doing", "tokens": [50742, 300, 390, 1019, 562, 286, 390, 1364, 365, 17809, 322, 341, 21060, 11, 411, 300, 311, 577, 286, 390, 884, 50882], "temperature": 0.0, "avg_logprob": -0.30103680125454013, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.5963772535324097}, {"id": 240, "seek": 153084, "start": 1541.1999999999998, "end": 1545.1999999999998, "text": " it. It's way through breaking the rules. Let's see if we can do this directly into a tensor", "tokens": [50882, 309, 13, 467, 311, 636, 807, 7697, 264, 4474, 13, 961, 311, 536, 498, 321, 393, 360, 341, 3838, 666, 257, 40863, 51082], "temperature": 0.0, "avg_logprob": -0.30103680125454013, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.5963772535324097}, {"id": 241, "seek": 153084, "start": 1545.1999999999998, "end": 1554.04, "text": " without this intermediate step of loading it with, with pillow. Cool. Okay. So how are", "tokens": [51082, 1553, 341, 19376, 1823, 295, 15114, 309, 365, 11, 365, 18581, 13, 8561, 13, 1033, 13, 407, 577, 366, 51524], "temperature": 0.0, "avg_logprob": -0.30103680125454013, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.5963772535324097}, {"id": 242, "seek": 153084, "start": 1554.04, "end": 1558.56, "text": " we going to do this image optimization? Well, first thing is we don't really have a data", "tokens": [51524, 321, 516, 281, 360, 341, 3256, 19618, 30, 1042, 11, 700, 551, 307, 321, 500, 380, 534, 362, 257, 1412, 51750], "temperature": 0.0, "avg_logprob": -0.30103680125454013, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.5963772535324097}, {"id": 243, "seek": 155856, "start": 1558.56, "end": 1562.76, "text": " set of lots of training examples. We just have a single target and a single thing we're", "tokens": [50364, 992, 295, 3195, 295, 3097, 5110, 13, 492, 445, 362, 257, 2167, 3779, 293, 257, 2167, 551, 321, 434, 50574], "temperature": 0.0, "avg_logprob": -0.24039898496685605, "compression_ratio": 1.7932203389830508, "no_speech_prob": 0.8518043756484985}, {"id": 244, "seek": 155856, "start": 1562.76, "end": 1567.9199999999998, "text": " optimizing. And so we built this linked data set here, which is just going to follow the", "tokens": [50574, 40425, 13, 400, 370, 321, 3094, 341, 9408, 1412, 992, 510, 11, 597, 307, 445, 516, 281, 1524, 264, 50832], "temperature": 0.0, "avg_logprob": -0.24039898496685605, "compression_ratio": 1.7932203389830508, "no_speech_prob": 0.8518043756484985}, {"id": 245, "seek": 155856, "start": 1567.9199999999998, "end": 1572.8799999999999, "text": " PyTorch like data set standard. We're going to tell it how to get a particular item and", "tokens": [50832, 9953, 51, 284, 339, 411, 1412, 992, 3832, 13, 492, 434, 516, 281, 980, 309, 577, 281, 483, 257, 1729, 3174, 293, 51080], "temperature": 0.0, "avg_logprob": -0.24039898496685605, "compression_ratio": 1.7932203389830508, "no_speech_prob": 0.8518043756484985}, {"id": 246, "seek": 155856, "start": 1572.8799999999999, "end": 1578.72, "text": " what our length is. But in this case, we're just always going to return zero, zero. We're", "tokens": [51080, 437, 527, 4641, 307, 13, 583, 294, 341, 1389, 11, 321, 434, 445, 1009, 516, 281, 2736, 4018, 11, 4018, 13, 492, 434, 51372], "temperature": 0.0, "avg_logprob": -0.24039898496685605, "compression_ratio": 1.7932203389830508, "no_speech_prob": 0.8518043756484985}, {"id": 247, "seek": 155856, "start": 1578.72, "end": 1581.96, "text": " not actually going to care about the results from this data set. We just want something", "tokens": [51372, 406, 767, 516, 281, 1127, 466, 264, 3542, 490, 341, 1412, 992, 13, 492, 445, 528, 746, 51534], "temperature": 0.0, "avg_logprob": -0.24039898496685605, "compression_ratio": 1.7932203389830508, "no_speech_prob": 0.8518043756484985}, {"id": 248, "seek": 155856, "start": 1581.96, "end": 1586.2, "text": " that we can pass to the learner to do some number of training iterations. So we create", "tokens": [51534, 300, 321, 393, 1320, 281, 264, 33347, 281, 360, 512, 1230, 295, 3097, 36540, 13, 407, 321, 1884, 51746], "temperature": 0.0, "avg_logprob": -0.24039898496685605, "compression_ratio": 1.7932203389830508, "no_speech_prob": 0.8518043756484985}, {"id": 249, "seek": 158620, "start": 1586.2, "end": 1591.64, "text": " like a fake dummy data set with a hundred items. And then we create our data loaders", "tokens": [50364, 411, 257, 7592, 35064, 1412, 992, 365, 257, 3262, 4754, 13, 400, 550, 321, 1884, 527, 1412, 3677, 433, 50636], "temperature": 0.0, "avg_logprob": -0.2111936796695814, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.47932836413383484}, {"id": 250, "seek": 158620, "start": 1591.64, "end": 1596.44, "text": " from that. And that's going to give us a way to train for some number of steps without", "tokens": [50636, 490, 300, 13, 400, 300, 311, 516, 281, 976, 505, 257, 636, 281, 3847, 337, 512, 1230, 295, 4439, 1553, 50876], "temperature": 0.0, "avg_logprob": -0.2111936796695814, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.47932836413383484}, {"id": 251, "seek": 158620, "start": 1596.44, "end": 1602.8600000000001, "text": " really caring about what this data is. So does that make sense? Yeah. So just to clarify", "tokens": [50876, 534, 15365, 466, 437, 341, 1412, 307, 13, 407, 775, 300, 652, 2020, 30, 865, 13, 407, 445, 281, 17594, 51197], "temperature": 0.0, "avg_logprob": -0.2111936796695814, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.47932836413383484}, {"id": 252, "seek": 158620, "start": 1602.8600000000001, "end": 1607.8400000000001, "text": " the reason we're doing this. So basically the idea is we're going to start with that", "tokens": [51197, 264, 1778, 321, 434, 884, 341, 13, 407, 1936, 264, 1558, 307, 321, 434, 516, 281, 722, 365, 300, 51446], "temperature": 0.0, "avg_logprob": -0.2111936796695814, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.47932836413383484}, {"id": 253, "seek": 158620, "start": 1607.8400000000001, "end": 1615.04, "text": " photo you downloaded. And I guess you're going to be downloading another photo. So that photo", "tokens": [51446, 5052, 291, 21748, 13, 400, 286, 2041, 291, 434, 516, 281, 312, 32529, 1071, 5052, 13, 407, 300, 5052, 51806], "temperature": 0.0, "avg_logprob": -0.2111936796695814, "compression_ratio": 1.7701612903225807, "no_speech_prob": 0.47932836413383484}, {"id": 254, "seek": 161504, "start": 1615.04, "end": 1618.12, "text": " is going to be like the content. We're going to try to make it continue to look like that", "tokens": [50364, 307, 516, 281, 312, 411, 264, 2701, 13, 492, 434, 516, 281, 853, 281, 652, 309, 2354, 281, 574, 411, 300, 50518], "temperature": 0.0, "avg_logprob": -0.22361740179821454, "compression_ratio": 1.969298245614035, "no_speech_prob": 0.03903194144368172}, {"id": 255, "seek": 161504, "start": 1618.12, "end": 1622.3999999999999, "text": " lady. And then we're going to try to change the style so that the style looks like the", "tokens": [50518, 7262, 13, 400, 550, 321, 434, 516, 281, 853, 281, 1319, 264, 3758, 370, 300, 264, 3758, 1542, 411, 264, 50732], "temperature": 0.0, "avg_logprob": -0.22361740179821454, "compression_ratio": 1.969298245614035, "no_speech_prob": 0.03903194144368172}, {"id": 256, "seek": 161504, "start": 1622.3999999999999, "end": 1627.8, "text": " style of some other picture. And the way we're going to be doing that is by doing an optimization", "tokens": [50732, 3758, 295, 512, 661, 3036, 13, 400, 264, 636, 321, 434, 516, 281, 312, 884, 300, 307, 538, 884, 364, 19618, 51002], "temperature": 0.0, "avg_logprob": -0.22361740179821454, "compression_ratio": 1.969298245614035, "no_speech_prob": 0.03903194144368172}, {"id": 257, "seek": 161504, "start": 1627.8, "end": 1636.04, "text": " loop with like SGD or whatever. But so the idea is that each step of that we're going", "tokens": [51002, 6367, 365, 411, 34520, 35, 420, 2035, 13, 583, 370, 264, 1558, 307, 300, 1184, 1823, 295, 300, 321, 434, 516, 51414], "temperature": 0.0, "avg_logprob": -0.22361740179821454, "compression_ratio": 1.969298245614035, "no_speech_prob": 0.03903194144368172}, {"id": 258, "seek": 161504, "start": 1636.04, "end": 1641.44, "text": " to be moving the style somehow of the image closer and closer to one of those images you", "tokens": [51414, 281, 312, 2684, 264, 3758, 6063, 295, 264, 3256, 4966, 293, 4966, 281, 472, 295, 729, 5267, 291, 51684], "temperature": 0.0, "avg_logprob": -0.22361740179821454, "compression_ratio": 1.969298245614035, "no_speech_prob": 0.03903194144368172}, {"id": 259, "seek": 164144, "start": 1641.44, "end": 1645.52, "text": " downloaded. So it's not that we're going to be looping through lots of different images,", "tokens": [50364, 21748, 13, 407, 309, 311, 406, 300, 321, 434, 516, 281, 312, 6367, 278, 807, 3195, 295, 819, 5267, 11, 50568], "temperature": 0.0, "avg_logprob": -0.2836914737667658, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.42622804641723633}, {"id": 260, "seek": 164144, "start": 1645.52, "end": 1653.04, "text": " but we're just going to be looping through, through steps of a optimization loop. Is that", "tokens": [50568, 457, 321, 434, 445, 516, 281, 312, 6367, 278, 807, 11, 807, 4439, 295, 257, 19618, 6367, 13, 1119, 300, 50944], "temperature": 0.0, "avg_logprob": -0.2836914737667658, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.42622804641723633}, {"id": 261, "seek": 164144, "start": 1653.04, "end": 1659.96, "text": " the idea? Exactly. And so, yeah, we can, we can create this fake data loader. And then", "tokens": [50944, 264, 1558, 30, 7587, 13, 400, 370, 11, 1338, 11, 321, 393, 11, 321, 393, 1884, 341, 7592, 1412, 3677, 260, 13, 400, 550, 51290], "temperature": 0.0, "avg_logprob": -0.2836914737667658, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.42622804641723633}, {"id": 262, "seek": 164144, "start": 1659.96, "end": 1664.16, "text": " in terms of the actual like model that we're optimizing and passing to the learner, we've", "tokens": [51290, 294, 2115, 295, 264, 3539, 411, 2316, 300, 321, 434, 40425, 293, 8437, 281, 264, 33347, 11, 321, 600, 51500], "temperature": 0.0, "avg_logprob": -0.2836914737667658, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.42622804641723633}, {"id": 263, "seek": 164144, "start": 1664.16, "end": 1670.3600000000001, "text": " created this tensor model class, which just has whatever tensor we pass in as its parameter.", "tokens": [51500, 2942, 341, 40863, 2316, 1508, 11, 597, 445, 575, 2035, 40863, 321, 1320, 294, 382, 1080, 13075, 13, 51810], "temperature": 0.0, "avg_logprob": -0.2836914737667658, "compression_ratio": 1.7848605577689243, "no_speech_prob": 0.42622804641723633}, {"id": 264, "seek": 167036, "start": 1670.36, "end": 1674.9199999999998, "text": " So there's no actual neural network necessarily. We're just going to pass in a random image", "tokens": [50364, 407, 456, 311, 572, 3539, 18161, 3209, 4725, 13, 492, 434, 445, 516, 281, 1320, 294, 257, 4974, 3256, 50592], "temperature": 0.0, "avg_logprob": -0.2841838702820895, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.09946839511394501}, {"id": 265, "seek": 167036, "start": 1674.9199999999998, "end": 1680.6, "text": " or some image shaped thing, a set of numbers that we can then optimize. So just in case", "tokens": [50592, 420, 512, 3256, 13475, 551, 11, 257, 992, 295, 3547, 300, 321, 393, 550, 19719, 13, 407, 445, 294, 1389, 50876], "temperature": 0.0, "avg_logprob": -0.2841838702820895, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.09946839511394501}, {"id": 266, "seek": 167036, "start": 1680.6, "end": 1684.9199999999998, "text": " people have forgotten that, so to remind people, when you put something in an end parameter,", "tokens": [50876, 561, 362, 11832, 300, 11, 370, 281, 4160, 561, 11, 562, 291, 829, 746, 294, 364, 917, 13075, 11, 51092], "temperature": 0.0, "avg_logprob": -0.2841838702820895, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.09946839511394501}, {"id": 267, "seek": 167036, "start": 1684.9199999999998, "end": 1690.0, "text": " it doesn't change it in any way. It's just a normal tensor, but it's stored inside the", "tokens": [51092, 309, 1177, 380, 1319, 309, 294, 604, 636, 13, 467, 311, 445, 257, 2710, 40863, 11, 457, 309, 311, 12187, 1854, 264, 51346], "temperature": 0.0, "avg_logprob": -0.2841838702820895, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.09946839511394501}, {"id": 268, "seek": 167036, "start": 1690.0, "end": 1696.04, "text": " module as being something, as being a tensor to optimize. So what you're doing here, Jono,", "tokens": [51346, 10088, 382, 885, 746, 11, 382, 885, 257, 40863, 281, 19719, 13, 407, 437, 291, 434, 884, 510, 11, 7745, 78, 11, 51648], "temperature": 0.0, "avg_logprob": -0.2841838702820895, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.09946839511394501}, {"id": 269, "seek": 169604, "start": 1696.04, "end": 1703.96, "text": " I guess is to say, I'm not actually optimizing a model at all. I'm optimizing an image, the", "tokens": [50364, 286, 2041, 307, 281, 584, 11, 286, 478, 406, 767, 40425, 257, 2316, 412, 439, 13, 286, 478, 40425, 364, 3256, 11, 264, 50760], "temperature": 0.0, "avg_logprob": -0.2552454014017124, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.7215740084648132}, {"id": 270, "seek": 169604, "start": 1703.96, "end": 1710.68, "text": " pixels of an image directly. Exactly. And because it's in a parameter, if we look at", "tokens": [50760, 18668, 295, 364, 3256, 3838, 13, 7587, 13, 400, 570, 309, 311, 294, 257, 13075, 11, 498, 321, 574, 412, 51096], "temperature": 0.0, "avg_logprob": -0.2552454014017124, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.7215740084648132}, {"id": 271, "seek": 169604, "start": 1710.68, "end": 1720.56, "text": " our, our model, we can see that for example, model.t, it does require grad, right? Because", "tokens": [51096, 527, 11, 527, 2316, 11, 321, 393, 536, 300, 337, 1365, 11, 2316, 13, 83, 11, 309, 775, 3651, 2771, 11, 558, 30, 1436, 51590], "temperature": 0.0, "avg_logprob": -0.2552454014017124, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.7215740084648132}, {"id": 272, "seek": 169604, "start": 1720.56, "end": 1724.96, "text": " that's already set up because this nn.module is going to look for any parameters. And if", "tokens": [51590, 300, 311, 1217, 992, 493, 570, 341, 297, 77, 13, 8014, 2271, 307, 516, 281, 574, 337, 604, 9834, 13, 400, 498, 51810], "temperature": 0.0, "avg_logprob": -0.2552454014017124, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.7215740084648132}, {"id": 273, "seek": 172496, "start": 1724.96, "end": 1735.68, "text": " our optimizer is looking at, let's look at the shape of the parameters. So this is the", "tokens": [50364, 527, 5028, 6545, 307, 1237, 412, 11, 718, 311, 574, 412, 264, 3909, 295, 264, 9834, 13, 407, 341, 307, 264, 50900], "temperature": 0.0, "avg_logprob": -0.21086242742705763, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.014728483743965626}, {"id": 274, "seek": 172496, "start": 1735.68, "end": 1740.08, "text": " shape of the parameters that we're optimizing. This is just that tensor that we passed in,", "tokens": [50900, 3909, 295, 264, 9834, 300, 321, 434, 40425, 13, 639, 307, 445, 300, 40863, 300, 321, 4678, 294, 11, 51120], "temperature": 0.0, "avg_logprob": -0.21086242742705763, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.014728483743965626}, {"id": 275, "seek": 172496, "start": 1740.08, "end": 1743.8400000000001, "text": " the same shape as our image. And this is what's going to be optimized if we pass this into", "tokens": [51120, 264, 912, 3909, 382, 527, 3256, 13, 400, 341, 307, 437, 311, 516, 281, 312, 26941, 498, 321, 1320, 341, 666, 51308], "temperature": 0.0, "avg_logprob": -0.21086242742705763, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.014728483743965626}, {"id": 276, "seek": 172496, "start": 1743.8400000000001, "end": 1750.4, "text": " any sort of learner fit method. Okay, so this model does have a thing being passed to forward,", "tokens": [51308, 604, 1333, 295, 33347, 3318, 3170, 13, 1033, 11, 370, 341, 2316, 775, 362, 257, 551, 885, 4678, 281, 2128, 11, 51636], "temperature": 0.0, "avg_logprob": -0.21086242742705763, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.014728483743965626}, {"id": 277, "seek": 172496, "start": 1750.4, "end": 1754.44, "text": " which is x, which we're ignoring. And I guess that's just because our learner passes something", "tokens": [51636, 597, 307, 2031, 11, 597, 321, 434, 26258, 13, 400, 286, 2041, 300, 311, 445, 570, 527, 33347, 11335, 746, 51838], "temperature": 0.0, "avg_logprob": -0.21086242742705763, "compression_ratio": 1.854251012145749, "no_speech_prob": 0.014728483743965626}, {"id": 278, "seek": 175444, "start": 1754.44, "end": 1759.0800000000002, "text": " in. So we're making life a bit easier for ourselves by making the model look the way", "tokens": [50364, 294, 13, 407, 321, 434, 1455, 993, 257, 857, 3571, 337, 4175, 538, 1455, 264, 2316, 574, 264, 636, 50596], "temperature": 0.0, "avg_logprob": -0.24638533391872375, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.004609296098351479}, {"id": 279, "seek": 175444, "start": 1759.0800000000002, "end": 1764.8400000000001, "text": " our learner expects. Yeah. And we could do that using like trainCB or something if we", "tokens": [50596, 527, 33347, 33280, 13, 865, 13, 400, 321, 727, 360, 300, 1228, 411, 3847, 34, 33, 420, 746, 498, 321, 50884], "temperature": 0.0, "avg_logprob": -0.24638533391872375, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.004609296098351479}, {"id": 280, "seek": 175444, "start": 1764.8400000000001, "end": 1771.8, "text": " wanted to, but this seems like a nice, nice easy way to do it. Yeah. So I mean, this is", "tokens": [50884, 1415, 281, 11, 457, 341, 2544, 411, 257, 1481, 11, 1481, 1858, 636, 281, 360, 309, 13, 865, 13, 407, 286, 914, 11, 341, 307, 51232], "temperature": 0.0, "avg_logprob": -0.24638533391872375, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.004609296098351479}, {"id": 281, "seek": 175444, "start": 1771.8, "end": 1777.68, "text": " the way I've done it. If you do want to use trainCB, you can set it up with a custom predict", "tokens": [51232, 264, 636, 286, 600, 1096, 309, 13, 759, 291, 360, 528, 281, 764, 3847, 34, 33, 11, 291, 393, 992, 309, 493, 365, 257, 2375, 6069, 51526], "temperature": 0.0, "avg_logprob": -0.24638533391872375, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.004609296098351479}, {"id": 282, "seek": 175444, "start": 1777.68, "end": 1783.44, "text": " method that is just going to call the model forward method with no parameters. And if", "tokens": [51526, 3170, 300, 307, 445, 516, 281, 818, 264, 2316, 2128, 3170, 365, 572, 9834, 13, 400, 498, 51814], "temperature": 0.0, "avg_logprob": -0.24638533391872375, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.004609296098351479}, {"id": 283, "seek": 178344, "start": 1783.44, "end": 1789.0, "text": " you want, likewise, just calling the loss function on just the predictions. But if you", "tokens": [50364, 291, 528, 11, 32407, 11, 445, 5141, 264, 4470, 2445, 322, 445, 264, 21264, 13, 583, 498, 291, 50642], "temperature": 0.0, "avg_logprob": -0.22507043709432273, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.020963674411177635}, {"id": 284, "seek": 178344, "start": 1789.0, "end": 1794.1200000000001, "text": " want to skip this, because we take this argument x equals zero and never use it, that should", "tokens": [50642, 528, 281, 10023, 341, 11, 570, 321, 747, 341, 6770, 2031, 6915, 4018, 293, 1128, 764, 309, 11, 300, 820, 50898], "temperature": 0.0, "avg_logprob": -0.22507043709432273, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.020963674411177635}, {"id": 285, "seek": 178344, "start": 1794.1200000000001, "end": 1798.8400000000001, "text": " also work without this callback. So either way is fine. This is a nice approach if you", "tokens": [50898, 611, 589, 1553, 341, 818, 3207, 13, 407, 2139, 636, 307, 2489, 13, 639, 307, 257, 1481, 3109, 498, 291, 51134], "temperature": 0.0, "avg_logprob": -0.22507043709432273, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.020963674411177635}, {"id": 286, "seek": 178344, "start": 1798.8400000000001, "end": 1802.3600000000001, "text": " have something that you're using an existing model, which expects some number of parameters", "tokens": [51134, 362, 746, 300, 291, 434, 1228, 364, 6741, 2316, 11, 597, 33280, 512, 1230, 295, 9834, 51310], "temperature": 0.0, "avg_logprob": -0.22507043709432273, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.020963674411177635}, {"id": 287, "seek": 178344, "start": 1802.3600000000001, "end": 1807.3200000000002, "text": " or something. Yeah, you can just modify that training callback, but we almost don't need", "tokens": [51310, 420, 746, 13, 865, 11, 291, 393, 445, 16927, 300, 3097, 818, 3207, 11, 457, 321, 1920, 500, 380, 643, 51558], "temperature": 0.0, "avg_logprob": -0.22507043709432273, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.020963674411177635}, {"id": 288, "seek": 178344, "start": 1807.3200000000002, "end": 1813.4, "text": " to in this case. Okay, so let's see. Let's put this in a learner. Let's optimize it with", "tokens": [51558, 281, 294, 341, 1389, 13, 1033, 11, 370, 718, 311, 536, 13, 961, 311, 829, 341, 294, 257, 33347, 13, 961, 311, 19719, 309, 365, 51862], "temperature": 0.0, "avg_logprob": -0.22507043709432273, "compression_ratio": 1.6962025316455696, "no_speech_prob": 0.020963674411177635}, {"id": 289, "seek": 181340, "start": 1813.4, "end": 1817.48, "text": " some loss function. Oh, just to clarify, I get it. So the get loss you had to change", "tokens": [50364, 512, 4470, 2445, 13, 876, 11, 445, 281, 17594, 11, 286, 483, 309, 13, 407, 264, 483, 4470, 291, 632, 281, 1319, 50568], "temperature": 0.0, "avg_logprob": -0.329156681642694, "compression_ratio": 1.7283464566929134, "no_speech_prob": 0.006388119421899319}, {"id": 290, "seek": 181340, "start": 1817.48, "end": 1822.3200000000002, "text": " because normally we pass a target to the loss function. Yeah. So it's learner.preds and", "tokens": [50568, 570, 5646, 321, 1320, 257, 3779, 281, 264, 4470, 2445, 13, 865, 13, 407, 309, 311, 33347, 13, 79, 986, 82, 293, 50810], "temperature": 0.0, "avg_logprob": -0.329156681642694, "compression_ratio": 1.7283464566929134, "no_speech_prob": 0.006388119421899319}, {"id": 291, "seek": 181340, "start": 1822.3200000000002, "end": 1829.76, "text": " then learner.batch. And again, we could avoid, we could remove that as well if we wanted", "tokens": [50810, 550, 33347, 13, 65, 852, 13, 400, 797, 11, 321, 727, 5042, 11, 321, 727, 4159, 300, 382, 731, 498, 321, 1415, 51182], "temperature": 0.0, "avg_logprob": -0.329156681642694, "compression_ratio": 1.7283464566929134, "no_speech_prob": 0.006388119421899319}, {"id": 292, "seek": 181340, "start": 1829.76, "end": 1836.96, "text": " to by having our loss function take a target that we then ignore. Yeah, yeah, exactly.", "tokens": [51182, 281, 538, 1419, 527, 4470, 2445, 747, 257, 3779, 300, 321, 550, 11200, 13, 865, 11, 1338, 11, 2293, 13, 51542], "temperature": 0.0, "avg_logprob": -0.329156681642694, "compression_ratio": 1.7283464566929134, "no_speech_prob": 0.006388119421899319}, {"id": 293, "seek": 181340, "start": 1836.96, "end": 1840.96, "text": " So both are the approaches. I like this because we're going to kind of be building on this", "tokens": [51542, 407, 1293, 366, 264, 11587, 13, 286, 411, 341, 570, 321, 434, 516, 281, 733, 295, 312, 2390, 322, 341, 51742], "temperature": 0.0, "avg_logprob": -0.329156681642694, "compression_ratio": 1.7283464566929134, "no_speech_prob": 0.006388119421899319}, {"id": 294, "seek": 184096, "start": 1840.96, "end": 1846.56, "text": " idea of modifying the training callback in the DDPM example and the other examples. But", "tokens": [50364, 1558, 295, 42626, 264, 3097, 818, 3207, 294, 264, 413, 11373, 44, 1365, 293, 264, 661, 5110, 13, 583, 50644], "temperature": 0.0, "avg_logprob": -0.24843589843265593, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.3811759650707245}, {"id": 295, "seek": 184096, "start": 1846.56, "end": 1849.88, "text": " in this case, it's just these like two lines change. This is how we get our model predictions.", "tokens": [50644, 294, 341, 1389, 11, 309, 311, 445, 613, 411, 732, 3876, 1319, 13, 639, 307, 577, 321, 483, 527, 2316, 21264, 13, 50810], "temperature": 0.0, "avg_logprob": -0.24843589843265593, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.3811759650707245}, {"id": 296, "seek": 184096, "start": 1849.88, "end": 1854.64, "text": " We just call the forward method, which returns this image that we're optimizing. And we're", "tokens": [50810, 492, 445, 818, 264, 2128, 3170, 11, 597, 11247, 341, 3256, 300, 321, 434, 40425, 13, 400, 321, 434, 51048], "temperature": 0.0, "avg_logprob": -0.24843589843265593, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.3811759650707245}, {"id": 297, "seek": 184096, "start": 1854.64, "end": 1860.32, "text": " going to evaluate this according to some loss function that just takes in an image. And", "tokens": [51048, 516, 281, 13059, 341, 4650, 281, 512, 4470, 2445, 300, 445, 2516, 294, 364, 3256, 13, 400, 51332], "temperature": 0.0, "avg_logprob": -0.24843589843265593, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.3811759650707245}, {"id": 298, "seek": 184096, "start": 1860.32, "end": 1865.16, "text": " so for our first loss function, we are just going to use the mean squared error between", "tokens": [51332, 370, 337, 527, 700, 4470, 2445, 11, 321, 366, 445, 516, 281, 764, 264, 914, 8889, 6713, 1296, 51574], "temperature": 0.0, "avg_logprob": -0.24843589843265593, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.3811759650707245}, {"id": 299, "seek": 184096, "start": 1865.16, "end": 1870.46, "text": " the image that we are generating, like this output of our model and that content image", "tokens": [51574, 264, 3256, 300, 321, 366, 17746, 11, 411, 341, 5598, 295, 527, 2316, 293, 300, 2701, 3256, 51839], "temperature": 0.0, "avg_logprob": -0.24843589843265593, "compression_ratio": 1.7748344370860927, "no_speech_prob": 0.3811759650707245}, {"id": 300, "seek": 187046, "start": 1870.46, "end": 1875.26, "text": " that's our target. Right? So we're going to set up our model, start it out with a random", "tokens": [50364, 300, 311, 527, 3779, 13, 1779, 30, 407, 321, 434, 516, 281, 992, 493, 527, 2316, 11, 722, 309, 484, 365, 257, 4974, 50604], "temperature": 0.0, "avg_logprob": -0.27340711173364673, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.7744792103767395}, {"id": 301, "seek": 187046, "start": 1875.26, "end": 1882.02, "text": " image like this above. We're going to create a learner with a dummy data loader for 100", "tokens": [50604, 3256, 411, 341, 3673, 13, 492, 434, 516, 281, 1884, 257, 33347, 365, 257, 35064, 1412, 3677, 260, 337, 2319, 50942], "temperature": 0.0, "avg_logprob": -0.27340711173364673, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.7744792103767395}, {"id": 302, "seek": 187046, "start": 1882.02, "end": 1886.6200000000001, "text": " steps. Our loss function is going to be this mean squared error loss function, set a learning", "tokens": [50942, 4439, 13, 2621, 4470, 2445, 307, 516, 281, 312, 341, 914, 8889, 6713, 4470, 2445, 11, 992, 257, 2539, 51172], "temperature": 0.0, "avg_logprob": -0.27340711173364673, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.7744792103767395}, {"id": 303, "seek": 187046, "start": 1886.6200000000001, "end": 1893.66, "text": " rate and an optimizer function. The defaults would probably also work. And if we run this,", "tokens": [51172, 3314, 293, 364, 5028, 6545, 2445, 13, 440, 7576, 82, 576, 1391, 611, 589, 13, 400, 498, 321, 1190, 341, 11, 51524], "temperature": 0.0, "avg_logprob": -0.27340711173364673, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.7744792103767395}, {"id": 304, "seek": 187046, "start": 1893.66, "end": 1899.3400000000001, "text": " something's going to happen. Our loss is going to go from a non-zero number to close to zero.", "tokens": [51524, 746, 311, 516, 281, 1051, 13, 2621, 4470, 307, 516, 281, 352, 490, 257, 2107, 12, 32226, 1230, 281, 1998, 281, 4018, 13, 51808], "temperature": 0.0, "avg_logprob": -0.27340711173364673, "compression_ratio": 1.7041198501872659, "no_speech_prob": 0.7744792103767395}, {"id": 305, "seek": 189934, "start": 1899.34, "end": 1903.3799999999999, "text": " And we can look at the final result. Like if we call learn.model and show that as an", "tokens": [50364, 400, 321, 393, 574, 412, 264, 2572, 1874, 13, 1743, 498, 321, 818, 1466, 13, 8014, 338, 293, 855, 300, 382, 364, 50566], "temperature": 0.0, "avg_logprob": -0.27859553775271856, "compression_ratio": 1.5919117647058822, "no_speech_prob": 0.31061026453971863}, {"id": 306, "seek": 189934, "start": 1903.3799999999999, "end": 1907.26, "text": " image versus the actual image, we'll see that they look pretty much identical.", "tokens": [50566, 3256, 5717, 264, 3539, 3256, 11, 321, 603, 536, 300, 436, 574, 1238, 709, 14800, 13, 50760], "temperature": 0.0, "avg_logprob": -0.27859553775271856, "compression_ratio": 1.5919117647058822, "no_speech_prob": 0.31061026453971863}, {"id": 307, "seek": 189934, "start": 1907.26, "end": 1912.62, "text": " Yeah. So just to clarify, this is like a pointless example. But what we did, we started with", "tokens": [50760, 865, 13, 407, 445, 281, 17594, 11, 341, 307, 411, 257, 32824, 1365, 13, 583, 437, 321, 630, 11, 321, 1409, 365, 51028], "temperature": 0.0, "avg_logprob": -0.27859553775271856, "compression_ratio": 1.5919117647058822, "no_speech_prob": 0.31061026453971863}, {"id": 308, "seek": 189934, "start": 1912.62, "end": 1918.5, "text": " that noisy image you showed above. And then we used SGD to make those pixels get closer", "tokens": [51028, 300, 24518, 3256, 291, 4712, 3673, 13, 400, 550, 321, 1143, 34520, 35, 281, 652, 729, 18668, 483, 4966, 51322], "temperature": 0.0, "avg_logprob": -0.27859553775271856, "compression_ratio": 1.5919117647058822, "no_speech_prob": 0.31061026453971863}, {"id": 309, "seek": 189934, "start": 1918.5, "end": 1924.98, "text": " and closer to the lady in the sunglasses. Not, you know, not for any particular purpose,", "tokens": [51322, 293, 4966, 281, 264, 7262, 294, 264, 28675, 13, 1726, 11, 291, 458, 11, 406, 337, 604, 1729, 4334, 11, 51646], "temperature": 0.0, "avg_logprob": -0.27859553775271856, "compression_ratio": 1.5919117647058822, "no_speech_prob": 0.31061026453971863}, {"id": 310, "seek": 192498, "start": 1924.98, "end": 1930.9, "text": " but just to show that we can turn noisy pixels into something else by having it follow a", "tokens": [50364, 457, 445, 281, 855, 300, 321, 393, 1261, 24518, 18668, 666, 746, 1646, 538, 1419, 309, 1524, 257, 50660], "temperature": 0.0, "avg_logprob": -0.24497628547775913, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.12414703518152237}, {"id": 311, "seek": 192498, "start": 1930.9, "end": 1934.42, "text": " loss function. And this loss function was just like, make the pixels look as much as", "tokens": [50660, 4470, 2445, 13, 400, 341, 4470, 2445, 390, 445, 411, 11, 652, 264, 18668, 574, 382, 709, 382, 50836], "temperature": 0.0, "avg_logprob": -0.24497628547775913, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.12414703518152237}, {"id": 312, "seek": 192498, "start": 1934.42, "end": 1937.3, "text": " possible like that lady in the sunglasses.", "tokens": [50836, 1944, 411, 300, 7262, 294, 264, 28675, 13, 50980], "temperature": 0.0, "avg_logprob": -0.24497628547775913, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.12414703518152237}, {"id": 313, "seek": 192498, "start": 1937.3, "end": 1941.26, "text": " Exactly. And so in this case, it's a very simple loss. There's like a one direction", "tokens": [50980, 7587, 13, 400, 370, 294, 341, 1389, 11, 309, 311, 257, 588, 2199, 4470, 13, 821, 311, 411, 257, 472, 3513, 51178], "temperature": 0.0, "avg_logprob": -0.24497628547775913, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.12414703518152237}, {"id": 314, "seek": 192498, "start": 1941.26, "end": 1945.5, "text": " that you update. So it's almost trivial to solve, but it still helps us get like the", "tokens": [51178, 300, 291, 5623, 13, 407, 309, 311, 1920, 26703, 281, 5039, 11, 457, 309, 920, 3665, 505, 483, 411, 264, 51390], "temperature": 0.0, "avg_logprob": -0.24497628547775913, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.12414703518152237}, {"id": 315, "seek": 192498, "start": 1945.5, "end": 1950.7, "text": " framework in place. But just seeing this final result is not very instructive because you", "tokens": [51390, 8388, 294, 1081, 13, 583, 445, 2577, 341, 2572, 1874, 307, 406, 588, 7232, 488, 570, 291, 51650], "temperature": 0.0, "avg_logprob": -0.24497628547775913, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.12414703518152237}, {"id": 316, "seek": 192498, "start": 1950.7, "end": 1953.82, "text": " almost think, well, did I get a bug in my code? Did I just duplicated the image? How", "tokens": [51650, 1920, 519, 11, 731, 11, 630, 286, 483, 257, 7426, 294, 452, 3089, 30, 2589, 286, 445, 1581, 564, 3587, 264, 3256, 30, 1012, 51806], "temperature": 0.0, "avg_logprob": -0.24497628547775913, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.12414703518152237}, {"id": 317, "seek": 195382, "start": 1953.82, "end": 1958.1, "text": " do I know this is actually doing what we expect? And so before we even move on to any", "tokens": [50364, 360, 286, 458, 341, 307, 767, 884, 437, 321, 2066, 30, 400, 370, 949, 321, 754, 1286, 322, 281, 604, 50578], "temperature": 0.0, "avg_logprob": -0.26308364056526345, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.294149249792099}, {"id": 318, "seek": 195382, "start": 1958.1, "end": 1962.9399999999998, "text": " more complicated loss functions, I thought it was important to have some sort of more", "tokens": [50578, 544, 6179, 4470, 6828, 11, 286, 1194, 309, 390, 1021, 281, 362, 512, 1333, 295, 544, 50820], "temperature": 0.0, "avg_logprob": -0.26308364056526345, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.294149249792099}, {"id": 319, "seek": 195382, "start": 1962.9399999999998, "end": 1969.86, "text": " obvious way of doing progress. So I've created a little logging callback here that is just", "tokens": [50820, 6322, 636, 295, 884, 4205, 13, 407, 286, 600, 2942, 257, 707, 27991, 818, 3207, 510, 300, 307, 445, 51166], "temperature": 0.0, "avg_logprob": -0.26308364056526345, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.294149249792099}, {"id": 320, "seek": 195382, "start": 1969.86, "end": 1976.8999999999999, "text": " after every batch, it's going to store the output as an image.", "tokens": [51166, 934, 633, 15245, 11, 309, 311, 516, 281, 3531, 264, 5598, 382, 364, 3256, 13, 51518], "temperature": 0.0, "avg_logprob": -0.26308364056526345, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.294149249792099}, {"id": 321, "seek": 195382, "start": 1976.8999999999999, "end": 1979.3799999999999, "text": " And I guess after every 10 batches here by default.", "tokens": [51518, 400, 286, 2041, 934, 633, 1266, 15245, 279, 510, 538, 7576, 13, 51642], "temperature": 0.0, "avg_logprob": -0.26308364056526345, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.294149249792099}, {"id": 322, "seek": 197938, "start": 1979.38, "end": 1984.2600000000002, "text": " Oh, yes. Yeah. So sorry. So we can set how often it's going to update and then every", "tokens": [50364, 876, 11, 2086, 13, 865, 13, 407, 2597, 13, 407, 321, 393, 992, 577, 2049, 309, 311, 516, 281, 5623, 293, 550, 633, 50608], "temperature": 0.0, "avg_logprob": -0.26485253793221936, "compression_ratio": 1.782312925170068, "no_speech_prob": 0.19924944639205933}, {"id": 323, "seek": 197938, "start": 1984.2600000000002, "end": 1989.3000000000002, "text": " 10 iterations or 50 iterations, whatever we set the log every argument to, it's going", "tokens": [50608, 1266, 36540, 420, 2625, 36540, 11, 2035, 321, 992, 264, 3565, 633, 6770, 281, 11, 309, 311, 516, 50860], "temperature": 0.0, "avg_logprob": -0.26485253793221936, "compression_ratio": 1.782312925170068, "no_speech_prob": 0.19924944639205933}, {"id": 324, "seek": 197938, "start": 1989.3000000000002, "end": 1993.94, "text": " to store that in a list. And then after the training is done, after that, we're just going", "tokens": [50860, 281, 3531, 300, 294, 257, 1329, 13, 400, 550, 934, 264, 3097, 307, 1096, 11, 934, 300, 11, 321, 434, 445, 516, 51092], "temperature": 0.0, "avg_logprob": -0.26485253793221936, "compression_ratio": 1.782312925170068, "no_speech_prob": 0.19924944639205933}, {"id": 325, "seek": 197938, "start": 1993.94, "end": 1999.42, "text": " to show those images. And so everything else the same as before, but passing in this extra", "tokens": [51092, 281, 855, 729, 5267, 13, 400, 370, 1203, 1646, 264, 912, 382, 949, 11, 457, 8437, 294, 341, 2857, 51366], "temperature": 0.0, "avg_logprob": -0.26485253793221936, "compression_ratio": 1.782312925170068, "no_speech_prob": 0.19924944639205933}, {"id": 326, "seek": 197938, "start": 1999.42, "end": 2004.94, "text": " logging callback, it's going to give us the kind of progress. And so now you can see,", "tokens": [51366, 27991, 818, 3207, 11, 309, 311, 516, 281, 976, 505, 264, 733, 295, 4205, 13, 400, 370, 586, 291, 393, 536, 11, 51642], "temperature": 0.0, "avg_logprob": -0.26485253793221936, "compression_ratio": 1.782312925170068, "no_speech_prob": 0.19924944639205933}, {"id": 327, "seek": 197938, "start": 2004.94, "end": 2008.5400000000002, "text": " OK, there is actually something happening. We're starting from this noise after a few", "tokens": [51642, 2264, 11, 456, 307, 767, 746, 2737, 13, 492, 434, 2891, 490, 341, 5658, 934, 257, 1326, 51822], "temperature": 0.0, "avg_logprob": -0.26485253793221936, "compression_ratio": 1.782312925170068, "no_speech_prob": 0.19924944639205933}, {"id": 328, "seek": 200854, "start": 2008.7, "end": 2013.6599999999999, "text": " iterations, already most of it is gone. And by the end of this process, it looks exactly", "tokens": [50372, 36540, 11, 1217, 881, 295, 309, 307, 2780, 13, 400, 538, 264, 917, 295, 341, 1399, 11, 309, 1542, 2293, 50620], "temperature": 0.0, "avg_logprob": -0.27868036680583713, "compression_ratio": 1.6073059360730593, "no_speech_prob": 0.5388559699058533}, {"id": 329, "seek": 200854, "start": 2013.6599999999999, "end": 2018.98, "text": " like the content image. So I really like this because what you've basically done here is", "tokens": [50620, 411, 264, 2701, 3256, 13, 407, 286, 534, 411, 341, 570, 437, 291, 600, 1936, 1096, 510, 307, 50886], "temperature": 0.0, "avg_logprob": -0.27868036680583713, "compression_ratio": 1.6073059360730593, "no_speech_prob": 0.5388559699058533}, {"id": 330, "seek": 200854, "start": 2018.98, "end": 2027.1, "text": " you've now already got all the tooling and infrastructure in place you need to basically", "tokens": [50886, 291, 600, 586, 1217, 658, 439, 264, 46593, 293, 6896, 294, 1081, 291, 643, 281, 1936, 51292], "temperature": 0.0, "avg_logprob": -0.27868036680583713, "compression_ratio": 1.6073059360730593, "no_speech_prob": 0.5388559699058533}, {"id": 331, "seek": 200854, "start": 2027.1, "end": 2037.02, "text": " create a really wide variety of interesting outputs that could either be artistic or,", "tokens": [51292, 1884, 257, 534, 4874, 5673, 295, 1880, 23930, 300, 727, 2139, 312, 17090, 420, 11, 51788], "temperature": 0.0, "avg_logprob": -0.27868036680583713, "compression_ratio": 1.6073059360730593, "no_speech_prob": 0.5388559699058533}, {"id": 332, "seek": 203702, "start": 2038.02, "end": 2044.86, "text": " like, you know, they could be more like image reconstruction, super resolution, colorization,", "tokens": [50414, 411, 11, 291, 458, 11, 436, 727, 312, 544, 411, 3256, 31565, 11, 1687, 8669, 11, 2017, 2144, 11, 50756], "temperature": 0.0, "avg_logprob": -0.3047959047205308, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.001810110523365438}, {"id": 333, "seek": 203702, "start": 2044.86, "end": 2051.94, "text": " whatever. And you just have to modify the loss function and you, you know, and I really", "tokens": [50756, 2035, 13, 400, 291, 445, 362, 281, 16927, 264, 4470, 2445, 293, 291, 11, 291, 458, 11, 293, 286, 534, 51110], "temperature": 0.0, "avg_logprob": -0.3047959047205308, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.001810110523365438}, {"id": 334, "seek": 203702, "start": 2051.94, "end": 2059.3, "text": " like the way you've created the absolute easiest possible first and fully checked it. And before", "tokens": [51110, 411, 264, 636, 291, 600, 2942, 264, 8236, 12889, 1944, 700, 293, 4498, 10033, 309, 13, 400, 949, 51478], "temperature": 0.0, "avg_logprob": -0.3047959047205308, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.001810110523365438}, {"id": 335, "seek": 203702, "start": 2059.3, "end": 2064.54, "text": " you start doing the fancy stuff and now you kind of, I guess you're really comfortable", "tokens": [51478, 291, 722, 884, 264, 10247, 1507, 293, 586, 291, 733, 295, 11, 286, 2041, 291, 434, 534, 4619, 51740], "temperature": 0.0, "avg_logprob": -0.3047959047205308, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.001810110523365438}, {"id": 336, "seek": 206454, "start": 2064.58, "end": 2067.7799999999997, "text": " doing the fancy stuff because, you know, that's all in place.", "tokens": [50366, 884, 264, 10247, 1507, 570, 11, 291, 458, 11, 300, 311, 439, 294, 1081, 13, 50526], "temperature": 0.0, "avg_logprob": -0.22633228302001954, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.38476642966270447}, {"id": 337, "seek": 206454, "start": 2069.1, "end": 2072.62, "text": " Yeah, exactly. And we know that we're going to see some tracking, so hopefully it'll be", "tokens": [50592, 865, 11, 2293, 13, 400, 321, 458, 300, 321, 434, 516, 281, 536, 512, 11603, 11, 370, 4696, 309, 603, 312, 50768], "temperature": 0.0, "avg_logprob": -0.22633228302001954, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.38476642966270447}, {"id": 338, "seek": 206454, "start": 2072.62, "end": 2075.86, "text": " like visually obvious if things are going wrong and we know exactly what we need to", "tokens": [50768, 411, 19622, 6322, 498, 721, 366, 516, 2085, 293, 321, 458, 2293, 437, 321, 643, 281, 50930], "temperature": 0.0, "avg_logprob": -0.22633228302001954, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.38476642966270447}, {"id": 339, "seek": 206454, "start": 2075.86, "end": 2080.46, "text": " modify. If we can now express some desired property that's more interesting than just", "tokens": [50930, 16927, 13, 759, 321, 393, 586, 5109, 512, 14721, 4707, 300, 311, 544, 1880, 813, 445, 51160], "temperature": 0.0, "avg_logprob": -0.22633228302001954, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.38476642966270447}, {"id": 340, "seek": 206454, "start": 2080.46, "end": 2084.94, "text": " like mean squared error to a target image, then we quickly have everything in place to", "tokens": [51160, 411, 914, 8889, 6713, 281, 257, 3779, 3256, 11, 550, 321, 2661, 362, 1203, 294, 1081, 281, 51384], "temperature": 0.0, "avg_logprob": -0.22633228302001954, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.38476642966270447}, {"id": 341, "seek": 206454, "start": 2084.94, "end": 2089.38, "text": " optimize. And so this is now really fun to like, OK, let's think about what other loss", "tokens": [51384, 19719, 13, 400, 370, 341, 307, 586, 534, 1019, 281, 411, 11, 2264, 11, 718, 311, 519, 466, 437, 661, 4470, 51606], "temperature": 0.0, "avg_logprob": -0.22633228302001954, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.38476642966270447}, {"id": 342, "seek": 206454, "start": 2089.38, "end": 2092.74, "text": " functions we could do. Maybe we wanted to match an image, but also have a particular", "tokens": [51606, 6828, 321, 727, 360, 13, 2704, 321, 1415, 281, 2995, 364, 3256, 11, 457, 611, 362, 257, 1729, 51774], "temperature": 0.0, "avg_logprob": -0.22633228302001954, "compression_ratio": 1.7202380952380953, "no_speech_prob": 0.38476642966270447}, {"id": 343, "seek": 209274, "start": 2092.74, "end": 2098.3399999999997, "text": " overall color. Maybe we want some, some more complicated thing. And so towards that, like", "tokens": [50364, 4787, 2017, 13, 2704, 321, 528, 512, 11, 512, 544, 6179, 551, 13, 400, 370, 3030, 300, 11, 411, 50644], "temperature": 0.0, "avg_logprob": -0.262141482035319, "compression_ratio": 1.713310580204778, "no_speech_prob": 0.008711092174053192}, {"id": 344, "seek": 209274, "start": 2098.3399999999997, "end": 2103.2599999999998, "text": " towards starting to get a more richer, like measure of what this output image looks like.", "tokens": [50644, 3030, 2891, 281, 483, 257, 544, 29021, 11, 411, 3481, 295, 437, 341, 5598, 3256, 1542, 411, 13, 50890], "temperature": 0.0, "avg_logprob": -0.262141482035319, "compression_ratio": 1.713310580204778, "no_speech_prob": 0.008711092174053192}, {"id": 345, "seek": 209274, "start": 2104.06, "end": 2108.14, "text": " We're going to talk about extracting features from a pre-trained network. And this is kind", "tokens": [50930, 492, 434, 516, 281, 751, 466, 49844, 4122, 490, 257, 659, 12, 17227, 2001, 3209, 13, 400, 341, 307, 733, 51134], "temperature": 0.0, "avg_logprob": -0.262141482035319, "compression_ratio": 1.713310580204778, "no_speech_prob": 0.008711092174053192}, {"id": 346, "seek": 209274, "start": 2108.14, "end": 2113.58, "text": " of like the core idea of this notebook is that we have these big convolutional neural", "tokens": [51134, 295, 411, 264, 4965, 1558, 295, 341, 21060, 307, 300, 321, 362, 613, 955, 45216, 304, 18161, 51406], "temperature": 0.0, "avg_logprob": -0.262141482035319, "compression_ratio": 1.713310580204778, "no_speech_prob": 0.008711092174053192}, {"id": 347, "seek": 209274, "start": 2113.58, "end": 2119.1, "text": " networks. This one is a much older architecture. And so relatively simple compared to some", "tokens": [51406, 9590, 13, 639, 472, 307, 257, 709, 4906, 9482, 13, 400, 370, 7226, 2199, 5347, 281, 512, 51682], "temperature": 0.0, "avg_logprob": -0.262141482035319, "compression_ratio": 1.713310580204778, "no_speech_prob": 0.008711092174053192}, {"id": 348, "seek": 209274, "start": 2119.1, "end": 2121.2599999999998, "text": " of the big, you know, dense nets and so on used today.", "tokens": [51682, 295, 264, 955, 11, 291, 458, 11, 18011, 36170, 293, 370, 322, 1143, 965, 13, 51790], "temperature": 0.0, "avg_logprob": -0.262141482035319, "compression_ratio": 1.713310580204778, "no_speech_prob": 0.008711092174053192}, {"id": 349, "seek": 212126, "start": 2121.26, "end": 2129.5800000000004, "text": " It's actually a lot like our pre-resnet fashion MNIST model. It's basically almost the same", "tokens": [50364, 467, 311, 767, 257, 688, 411, 527, 659, 12, 495, 7129, 6700, 376, 45, 19756, 2316, 13, 467, 311, 1936, 1920, 264, 912, 50780], "temperature": 0.0, "avg_logprob": -0.3470403737035291, "compression_ratio": 1.5036231884057971, "no_speech_prob": 0.002359599806368351}, {"id": 350, "seek": 212126, "start": 2129.5800000000004, "end": 2130.7400000000002, "text": " as VGG 16.", "tokens": [50780, 382, 691, 27561, 3165, 13, 50838], "temperature": 0.0, "avg_logprob": -0.3470403737035291, "compression_ratio": 1.5036231884057971, "no_speech_prob": 0.002359599806368351}, {"id": 351, "seek": 212126, "start": 2131.5400000000004, "end": 2136.5400000000004, "text": " Yeah, yeah, exactly. And so we're feeding in an image and then we have these like", "tokens": [50878, 865, 11, 1338, 11, 2293, 13, 400, 370, 321, 434, 12919, 294, 364, 3256, 293, 550, 321, 362, 613, 411, 51128], "temperature": 0.0, "avg_logprob": -0.3470403737035291, "compression_ratio": 1.5036231884057971, "no_speech_prob": 0.002359599806368351}, {"id": 352, "seek": 212126, "start": 2136.5400000000004, "end": 2141.46, "text": " convolutional layers, downsampling, convolution, you know, downsampling with max pooling up", "tokens": [51128, 45216, 304, 7914, 11, 760, 19988, 11970, 11, 45216, 11, 291, 458, 11, 760, 19988, 11970, 365, 11469, 7005, 278, 493, 51374], "temperature": 0.0, "avg_logprob": -0.3470403737035291, "compression_ratio": 1.5036231884057971, "no_speech_prob": 0.002359599806368351}, {"id": 353, "seek": 212126, "start": 2141.46, "end": 2142.6600000000003, "text": " until some final prediction.", "tokens": [51374, 1826, 512, 2572, 17630, 13, 51434], "temperature": 0.0, "avg_logprob": -0.3470403737035291, "compression_ratio": 1.5036231884057971, "no_speech_prob": 0.002359599806368351}, {"id": 354, "seek": 212126, "start": 2143.26, "end": 2143.78, "text": " Oh, but the question...", "tokens": [51464, 876, 11, 457, 264, 1168, 485, 51490], "temperature": 0.0, "avg_logprob": -0.3470403737035291, "compression_ratio": 1.5036231884057971, "no_speech_prob": 0.002359599806368351}, {"id": 355, "seek": 212126, "start": 2143.78, "end": 2148.6600000000003, "text": " Can I just point something out? There's one big difference here, which is that 7 by 7", "tokens": [51490, 1664, 286, 445, 935, 746, 484, 30, 821, 311, 472, 955, 2649, 510, 11, 597, 307, 300, 1614, 538, 1614, 51734], "temperature": 0.0, "avg_logprob": -0.3470403737035291, "compression_ratio": 1.5036231884057971, "no_speech_prob": 0.002359599806368351}, {"id": 356, "seek": 214866, "start": 2148.66, "end": 2154.7, "text": " by 512, if you can point at that. Normally nowadays and in our models, we tried, you", "tokens": [50364, 538, 1025, 4762, 11, 498, 291, 393, 935, 412, 300, 13, 17424, 13434, 293, 294, 527, 5245, 11, 321, 3031, 11, 291, 50666], "temperature": 0.0, "avg_logprob": -0.23373483874134182, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.026756877079606056}, {"id": 357, "seek": 214866, "start": 2154.7, "end": 2162.42, "text": " know, using an adaptive or global pooling to get down to a 1 by 1 by 512. VGG 16 does", "tokens": [50666, 458, 11, 1228, 364, 27912, 420, 4338, 7005, 278, 281, 483, 760, 281, 257, 502, 538, 502, 538, 1025, 4762, 13, 691, 27561, 3165, 775, 51052], "temperature": 0.0, "avg_logprob": -0.23373483874134182, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.026756877079606056}, {"id": 358, "seek": 214866, "start": 2162.42, "end": 2166.3799999999997, "text": " something which is very unusual by today's standards, which is it just flattens that", "tokens": [51052, 746, 597, 307, 588, 10901, 538, 965, 311, 7787, 11, 597, 307, 309, 445, 932, 1591, 694, 300, 51250], "temperature": 0.0, "avg_logprob": -0.23373483874134182, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.026756877079606056}, {"id": 359, "seek": 214866, "start": 2166.3799999999997, "end": 2176.18, "text": " out into a 1 by 1 by 4096, which actually might be a really interesting feature of VGG.", "tokens": [51250, 484, 666, 257, 502, 538, 502, 538, 3356, 22962, 11, 597, 767, 1062, 312, 257, 534, 1880, 4111, 295, 691, 27561, 13, 51740], "temperature": 0.0, "avg_logprob": -0.23373483874134182, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.026756877079606056}, {"id": 360, "seek": 217618, "start": 2176.18, "end": 2181.54, "text": " And I've always felt like people might want to consider training, you know, resnets and", "tokens": [50364, 400, 286, 600, 1009, 2762, 411, 561, 1062, 528, 281, 1949, 3097, 11, 291, 458, 11, 725, 77, 1385, 293, 50632], "temperature": 0.0, "avg_logprob": -0.2533252239227295, "compression_ratio": 1.5574468085106383, "no_speech_prob": 4.6838562411721796e-05}, {"id": 361, "seek": 217618, "start": 2181.54, "end": 2184.8599999999997, "text": " stuff without the global pooling and instead do the flattening.", "tokens": [50632, 1507, 1553, 264, 4338, 7005, 278, 293, 2602, 360, 264, 24183, 278, 13, 50798], "temperature": 0.0, "avg_logprob": -0.2533252239227295, "compression_ratio": 1.5574468085106383, "no_speech_prob": 4.6838562411721796e-05}, {"id": 362, "seek": 217618, "start": 2185.4199999999996, "end": 2190.22, "text": " The reason we don't do the flattening nowadays is that that very last linear layer that goes", "tokens": [50826, 440, 1778, 321, 500, 380, 360, 264, 24183, 278, 13434, 307, 300, 300, 588, 1036, 8213, 4583, 300, 1709, 51066], "temperature": 0.0, "avg_logprob": -0.2533252239227295, "compression_ratio": 1.5574468085106383, "no_speech_prob": 4.6838562411721796e-05}, {"id": 363, "seek": 217618, "start": 2190.22, "end": 2196.8599999999997, "text": " from 1 by 1 by 4096 to 1 by 1 by 1000, because this is an image net model, is going to need", "tokens": [51066, 490, 502, 538, 502, 538, 3356, 22962, 281, 502, 538, 502, 538, 9714, 11, 570, 341, 307, 364, 3256, 2533, 2316, 11, 307, 516, 281, 643, 51398], "temperature": 0.0, "avg_logprob": -0.2533252239227295, "compression_ratio": 1.5574468085106383, "no_speech_prob": 4.6838562411721796e-05}, {"id": 364, "seek": 217618, "start": 2197.66, "end": 2200.06, "text": " an awfully big weight matrix.", "tokens": [51438, 364, 47976, 955, 3364, 8141, 13, 51558], "temperature": 0.0, "avg_logprob": -0.2533252239227295, "compression_ratio": 1.5574468085106383, "no_speech_prob": 4.6838562411721796e-05}, {"id": 365, "seek": 220006, "start": 2200.1, "end": 2206.34, "text": " You've got a 4096 by 1000 weight matrix, as a result of which this is actually horrifically", "tokens": [50366, 509, 600, 658, 257, 3356, 22962, 538, 9714, 3364, 8141, 11, 382, 257, 1874, 295, 597, 341, 307, 767, 17582, 4278, 50678], "temperature": 0.0, "avg_logprob": -0.27529603691511256, "compression_ratio": 1.5655430711610487, "no_speech_prob": 0.0200215931981802}, {"id": 366, "seek": 220006, "start": 2206.34, "end": 2211.38, "text": " memory intensive for a reasonably poor performing model by modern standards.", "tokens": [50678, 4675, 18957, 337, 257, 23551, 4716, 10205, 2316, 538, 4363, 7787, 13, 50930], "temperature": 0.0, "avg_logprob": -0.27529603691511256, "compression_ratio": 1.5655430711610487, "no_speech_prob": 0.0200215931981802}, {"id": 367, "seek": 220006, "start": 2211.38, "end": 2217.06, "text": " But yeah, I think that doing that actually also has some benefits potentially as well.", "tokens": [50930, 583, 1338, 11, 286, 519, 300, 884, 300, 767, 611, 575, 512, 5311, 7263, 382, 731, 13, 51214], "temperature": 0.0, "avg_logprob": -0.27529603691511256, "compression_ratio": 1.5655430711610487, "no_speech_prob": 0.0200215931981802}, {"id": 368, "seek": 220006, "start": 2218.9, "end": 2224.46, "text": " Yeah, and in this case, we are not even really interested in the classification side.", "tokens": [51306, 865, 11, 293, 294, 341, 1389, 11, 321, 366, 406, 754, 534, 3102, 294, 264, 21538, 1252, 13, 51584], "temperature": 0.0, "avg_logprob": -0.27529603691511256, "compression_ratio": 1.5655430711610487, "no_speech_prob": 0.0200215931981802}, {"id": 369, "seek": 220006, "start": 2224.7799999999997, "end": 2229.06, "text": " We're more excited about the capacity of this to extract different features.", "tokens": [51600, 492, 434, 544, 2919, 466, 264, 6042, 295, 341, 281, 8947, 819, 4122, 13, 51814], "temperature": 0.0, "avg_logprob": -0.27529603691511256, "compression_ratio": 1.5655430711610487, "no_speech_prob": 0.0200215931981802}, {"id": 370, "seek": 223006, "start": 2230.2999999999997, "end": 2240.2599999999998, "text": " And so the idea here, and maybe I should pull up this classic article looking at like, what", "tokens": [50376, 400, 370, 264, 1558, 510, 11, 293, 1310, 286, 820, 2235, 493, 341, 7230, 7222, 1237, 412, 411, 11, 437, 50874], "temperature": 0.0, "avg_logprob": -0.28401661967183206, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0014549429761245847}, {"id": 371, "seek": 223006, "start": 2240.2599999999998, "end": 2244.46, "text": " do neural networks learn and trying to visualize some of these features.", "tokens": [50874, 360, 18161, 9590, 1466, 293, 1382, 281, 23273, 512, 295, 613, 4122, 13, 51084], "temperature": 0.0, "avg_logprob": -0.28401661967183206, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0014549429761245847}, {"id": 372, "seek": 223006, "start": 2245.2599999999998, "end": 2249.06, "text": " This is something we've mentioned before with these big pre-trained networks, is that the", "tokens": [51124, 639, 307, 746, 321, 600, 2835, 949, 365, 613, 955, 659, 12, 17227, 2001, 9590, 11, 307, 300, 264, 51314], "temperature": 0.0, "avg_logprob": -0.28401661967183206, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0014549429761245847}, {"id": 373, "seek": 223006, "start": 2249.06, "end": 2253.1, "text": " early layers tend to pick up on very simple features, edges and shapes and textures.", "tokens": [51314, 2440, 7914, 3928, 281, 1888, 493, 322, 588, 2199, 4122, 11, 8819, 293, 10854, 293, 24501, 13, 51516], "temperature": 0.0, "avg_logprob": -0.28401661967183206, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0014549429761245847}, {"id": 374, "seek": 223006, "start": 2253.62, "end": 2256.46, "text": " And those get mixed together into more complicated textures.", "tokens": [51542, 400, 729, 483, 7467, 1214, 666, 544, 6179, 24501, 13, 51684], "temperature": 0.0, "avg_logprob": -0.28401661967183206, "compression_ratio": 1.6194331983805668, "no_speech_prob": 0.0014549429761245847}, {"id": 375, "seek": 225646, "start": 2257.46, "end": 2261.7, "text": " And by the way, this is just trying to visualize like what kind of input maximally", "tokens": [50414, 400, 538, 264, 636, 11, 341, 307, 445, 1382, 281, 23273, 411, 437, 733, 295, 4846, 5138, 379, 50626], "temperature": 0.0, "avg_logprob": -0.26890488872377893, "compression_ratio": 1.7124183006535947, "no_speech_prob": 0.007815389893949032}, {"id": 376, "seek": 225646, "start": 2261.7, "end": 2264.62, "text": " activates a particular output on each of these layers.", "tokens": [50626, 43869, 257, 1729, 5598, 322, 1184, 295, 613, 7914, 13, 50772], "temperature": 0.0, "avg_logprob": -0.26890488872377893, "compression_ratio": 1.7124183006535947, "no_speech_prob": 0.007815389893949032}, {"id": 377, "seek": 225646, "start": 2265.02, "end": 2267.9, "text": " And so it's a great way to see like what kinds of things that's learning.", "tokens": [50792, 400, 370, 309, 311, 257, 869, 636, 281, 536, 411, 437, 3685, 295, 721, 300, 311, 2539, 13, 50936], "temperature": 0.0, "avg_logprob": -0.26890488872377893, "compression_ratio": 1.7124183006535947, "no_speech_prob": 0.007815389893949032}, {"id": 378, "seek": 225646, "start": 2268.66, "end": 2272.7400000000002, "text": " And so you can see as we move deeper and deeper into the network, we're getting more and", "tokens": [50974, 400, 370, 291, 393, 536, 382, 321, 1286, 7731, 293, 7731, 666, 264, 3209, 11, 321, 434, 1242, 544, 293, 51178], "temperature": 0.0, "avg_logprob": -0.26890488872377893, "compression_ratio": 1.7124183006535947, "no_speech_prob": 0.007815389893949032}, {"id": 379, "seek": 225646, "start": 2272.7400000000002, "end": 2275.46, "text": " more complicated, like hierarchical features.", "tokens": [51178, 544, 6179, 11, 411, 35250, 804, 4122, 13, 51314], "temperature": 0.0, "avg_logprob": -0.26890488872377893, "compression_ratio": 1.7124183006535947, "no_speech_prob": 0.007815389893949032}, {"id": 380, "seek": 225646, "start": 2275.78, "end": 2279.94, "text": " Now, we should mention, so we've looked at the Zeiler and Fergus paper before, which is", "tokens": [51330, 823, 11, 321, 820, 2152, 11, 370, 321, 600, 2956, 412, 264, 4853, 5441, 293, 36790, 3035, 949, 11, 597, 307, 51538], "temperature": 0.0, "avg_logprob": -0.26890488872377893, "compression_ratio": 1.7124183006535947, "no_speech_prob": 0.007815389893949032}, {"id": 381, "seek": 225646, "start": 2279.94, "end": 2285.26, "text": " an earlier version doing something like this to see what kind of features were available.", "tokens": [51538, 364, 3071, 3037, 884, 746, 411, 341, 281, 536, 437, 733, 295, 4122, 645, 2435, 13, 51804], "temperature": 0.0, "avg_logprob": -0.26890488872377893, "compression_ratio": 1.7124183006535947, "no_speech_prob": 0.007815389893949032}, {"id": 382, "seek": 228526, "start": 2285.26, "end": 2293.38, "text": " So we're linked to this distilled paper from the forum and the course lesson page,", "tokens": [50364, 407, 321, 434, 9408, 281, 341, 1483, 6261, 3035, 490, 264, 17542, 293, 264, 1164, 6898, 3028, 11, 50770], "temperature": 0.0, "avg_logprob": -0.32058931280065467, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00045116848195903003}, {"id": 383, "seek": 228526, "start": 2293.6600000000003, "end": 2298.26, "text": " because it's actually a more modern and fancy version kind of of the same thing.", "tokens": [50784, 570, 309, 311, 767, 257, 544, 4363, 293, 10247, 3037, 733, 295, 295, 264, 912, 551, 13, 51014], "temperature": 0.0, "avg_logprob": -0.32058931280065467, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00045116848195903003}, {"id": 384, "seek": 228526, "start": 2298.98, "end": 2299.38, "text": " Yeah.", "tokens": [51050, 865, 13, 51070], "temperature": 0.0, "avg_logprob": -0.32058931280065467, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00045116848195903003}, {"id": 385, "seek": 228526, "start": 2300.0200000000004, "end": 2301.42, "text": " Also note the names here.", "tokens": [51102, 2743, 3637, 264, 5288, 510, 13, 51172], "temperature": 0.0, "avg_logprob": -0.32058931280065467, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00045116848195903003}, {"id": 386, "seek": 228526, "start": 2301.9, "end": 2303.42, "text": " All of these people are worth following.", "tokens": [51196, 1057, 295, 613, 561, 366, 3163, 3480, 13, 51272], "temperature": 0.0, "avg_logprob": -0.32058931280065467, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00045116848195903003}, {"id": 387, "seek": 228526, "start": 2303.42, "end": 2305.38, "text": " Chris does amazing work on interpretability.", "tokens": [51272, 6688, 775, 2243, 589, 322, 7302, 2310, 13, 51370], "temperature": 0.0, "avg_logprob": -0.32058931280065467, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00045116848195903003}, {"id": 388, "seek": 228526, "start": 2305.6600000000003, "end": 2310.0600000000004, "text": " And Alexander Mordvintsev we'll see in the second notebook that I look at today, doing", "tokens": [51384, 400, 14845, 376, 765, 85, 686, 405, 85, 321, 603, 536, 294, 264, 1150, 21060, 300, 286, 574, 412, 965, 11, 884, 51604], "temperature": 0.0, "avg_logprob": -0.32058931280065467, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00045116848195903003}, {"id": 389, "seek": 228526, "start": 2310.0600000000004, "end": 2311.42, "text": " all sorts of other cool stuff as well.", "tokens": [51604, 439, 7527, 295, 661, 1627, 1507, 382, 731, 13, 51672], "temperature": 0.0, "avg_logprob": -0.32058931280065467, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00045116848195903003}, {"id": 390, "seek": 231142, "start": 2312.1800000000003, "end": 2317.42, "text": " Anyway, so we want to think about like, let's extract the outputs of these layers in the", "tokens": [50402, 5684, 11, 370, 321, 528, 281, 519, 466, 411, 11, 718, 311, 8947, 264, 23930, 295, 613, 7914, 294, 264, 50664], "temperature": 0.0, "avg_logprob": -0.3130890494898746, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.002323101507499814}, {"id": 391, "seek": 231142, "start": 2317.42, "end": 2321.7400000000002, "text": " hope that they give us a representation of our image that's richer than just the raw", "tokens": [50664, 1454, 300, 436, 976, 505, 257, 10290, 295, 527, 3256, 300, 311, 29021, 813, 445, 264, 8936, 50880], "temperature": 0.0, "avg_logprob": -0.3130890494898746, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.002323101507499814}, {"id": 392, "seek": 231142, "start": 2321.7400000000002, "end": 2322.3, "text": " pixels.", "tokens": [50880, 18668, 13, 50908], "temperature": 0.0, "avg_logprob": -0.3130890494898746, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.002323101507499814}, {"id": 393, "seek": 231142, "start": 2323.02, "end": 2323.7000000000003, "text": " So we can list...", "tokens": [50944, 407, 321, 393, 1329, 485, 50978], "temperature": 0.0, "avg_logprob": -0.3130890494898746, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.002323101507499814}, {"id": 394, "seek": 231142, "start": 2323.7000000000003, "end": 2329.06, "text": " The idea being there that if we had another, if we were able to change our image to have", "tokens": [50978, 440, 1558, 885, 456, 300, 498, 321, 632, 1071, 11, 498, 321, 645, 1075, 281, 1319, 527, 3256, 281, 362, 51246], "temperature": 0.0, "avg_logprob": -0.3130890494898746, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.002323101507499814}, {"id": 395, "seek": 231142, "start": 2329.06, "end": 2334.9, "text": " the same features at those of those various like types that you were just showing us,", "tokens": [51246, 264, 912, 4122, 412, 729, 295, 729, 3683, 411, 3467, 300, 291, 645, 445, 4099, 505, 11, 51538], "temperature": 0.0, "avg_logprob": -0.3130890494898746, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.002323101507499814}, {"id": 396, "seek": 233490, "start": 2335.38, "end": 2344.86, "text": " that then it would like have similar textures or similar kind of higher level concepts or", "tokens": [50388, 300, 550, 309, 576, 411, 362, 2531, 24501, 420, 2531, 733, 295, 2946, 1496, 10392, 420, 50862], "temperature": 0.0, "avg_logprob": -0.27763559010403216, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.018832173198461533}, {"id": 397, "seek": 233490, "start": 2344.98, "end": 2345.38, "text": " whatever.", "tokens": [50868, 2035, 13, 50888], "temperature": 0.0, "avg_logprob": -0.27763559010403216, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.018832173198461533}, {"id": 398, "seek": 233490, "start": 2345.6600000000003, "end": 2346.14, "text": " Exactly.", "tokens": [50902, 7587, 13, 50926], "temperature": 0.0, "avg_logprob": -0.27763559010403216, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.018832173198461533}, {"id": 399, "seek": 233490, "start": 2346.14, "end": 2350.38, "text": " So if you think of this like 14 by 14 feature map over here, maybe it's capturing that", "tokens": [50926, 407, 498, 291, 519, 295, 341, 411, 3499, 538, 3499, 4111, 4471, 670, 510, 11, 1310, 309, 311, 23384, 300, 51138], "temperature": 0.0, "avg_logprob": -0.27763559010403216, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.018832173198461533}, {"id": 400, "seek": 233490, "start": 2350.38, "end": 2355.14, "text": " there's, you know, an eye in the top left and some hair on the top right, these kind of", "tokens": [51138, 456, 311, 11, 291, 458, 11, 364, 3313, 294, 264, 1192, 1411, 293, 512, 2578, 322, 264, 1192, 558, 11, 613, 733, 295, 51376], "temperature": 0.0, "avg_logprob": -0.27763559010403216, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.018832173198461533}, {"id": 401, "seek": 233490, "start": 2355.34, "end": 2356.14, "text": " abstract things.", "tokens": [51386, 12649, 721, 13, 51426], "temperature": 0.0, "avg_logprob": -0.27763559010403216, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.018832173198461533}, {"id": 402, "seek": 233490, "start": 2356.14, "end": 2360.2200000000003, "text": " And if you change the, like if you change the brightness of the image, it's unlikely that", "tokens": [51426, 400, 498, 291, 1319, 264, 11, 411, 498, 291, 1319, 264, 21367, 295, 264, 3256, 11, 309, 311, 17518, 300, 51630], "temperature": 0.0, "avg_logprob": -0.27763559010403216, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.018832173198461533}, {"id": 403, "seek": 233490, "start": 2360.2200000000003, "end": 2364.26, "text": " it's going to change what features are stored there because the network's learned to be", "tokens": [51630, 309, 311, 516, 281, 1319, 437, 4122, 366, 12187, 456, 570, 264, 3209, 311, 3264, 281, 312, 51832], "temperature": 0.0, "avg_logprob": -0.27763559010403216, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.018832173198461533}, {"id": 404, "seek": 236426, "start": 2364.46, "end": 2367.98, "text": " somewhat invariant to these like rough transformations, a bit of noise, a bit of", "tokens": [50374, 8344, 33270, 394, 281, 613, 411, 5903, 34852, 11, 257, 857, 295, 5658, 11, 257, 857, 295, 50550], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 405, "seek": 236426, "start": 2367.98, "end": 2371.7000000000003, "text": " changing texture early on is not going to affect the fact that it still thinks this", "tokens": [50550, 4473, 8091, 2440, 322, 307, 406, 516, 281, 3345, 264, 1186, 300, 309, 920, 7309, 341, 50736], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 406, "seek": 236426, "start": 2371.7000000000003, "end": 2372.5, "text": " looks like a dog.", "tokens": [50736, 1542, 411, 257, 3000, 13, 50776], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 407, "seek": 236426, "start": 2372.9, "end": 2375.98, "text": " And a few layers before that, that it still thinks that part looks like a nose and that", "tokens": [50796, 400, 257, 1326, 7914, 949, 300, 11, 300, 309, 920, 7309, 300, 644, 1542, 411, 257, 6690, 293, 300, 50950], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 408, "seek": 236426, "start": 2375.98, "end": 2376.82, "text": " part looks like an ear.", "tokens": [50950, 644, 1542, 411, 364, 1273, 13, 50992], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 409, "seek": 236426, "start": 2376.82, "end": 2380.34, "text": " And maybe the more interesting bits then for what you're doing are those earlier layers", "tokens": [50992, 400, 1310, 264, 544, 1880, 9239, 550, 337, 437, 291, 434, 884, 366, 729, 3071, 7914, 51168], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 410, "seek": 236426, "start": 2380.38, "end": 2384.82, "text": " where it's going to be like, there's a whole bunch of kind of diagonal lines here, or", "tokens": [51170, 689, 309, 311, 516, 281, 312, 411, 11, 456, 311, 257, 1379, 3840, 295, 733, 295, 21539, 3876, 510, 11, 420, 51392], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 411, "seek": 236426, "start": 2384.82, "end": 2386.42, "text": " there's a kind of a loopy bit here.", "tokens": [51392, 456, 311, 257, 733, 295, 257, 6367, 88, 857, 510, 13, 51472], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 412, "seek": 236426, "start": 2387.46, "end": 2392.3, "text": " Because then, yeah, if you replicate those, you're going to get similar textures without", "tokens": [51524, 1436, 550, 11, 1338, 11, 498, 291, 25356, 729, 11, 291, 434, 516, 281, 483, 2531, 24501, 1553, 51766], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 413, "seek": 236426, "start": 2392.3, "end": 2393.9, "text": " changing the semantics.", "tokens": [51766, 4473, 264, 4361, 45298, 13, 51846], "temperature": 0.0, "avg_logprob": -0.24647160191689768, "compression_ratio": 1.9525316455696202, "no_speech_prob": 0.002082910155877471}, {"id": 414, "seek": 239426, "start": 2395.0200000000004, "end": 2395.7000000000003, "text": " Exactly.", "tokens": [50402, 7587, 13, 50436], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 415, "seek": 239426, "start": 2395.7400000000002, "end": 2396.1400000000003, "text": " Yeah.", "tokens": [50438, 865, 13, 50458], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 416, "seek": 239426, "start": 2396.1400000000003, "end": 2400.0200000000004, "text": " So, I mean, I guess let's load the model and look at what the layers are.", "tokens": [50458, 407, 11, 286, 914, 11, 286, 2041, 718, 311, 3677, 264, 2316, 293, 574, 412, 437, 264, 7914, 366, 13, 50652], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 417, "seek": 239426, "start": 2400.0200000000004, "end": 2404.1400000000003, "text": " And then in the next section, we can try and like see what kinds of images work when we", "tokens": [50652, 400, 550, 294, 264, 958, 3541, 11, 321, 393, 853, 293, 411, 536, 437, 3685, 295, 5267, 589, 562, 321, 50858], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 418, "seek": 239426, "start": 2404.1400000000003, "end": 2406.7000000000003, "text": " optimize towards different layers in there.", "tokens": [50858, 19719, 3030, 819, 7914, 294, 456, 13, 50986], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 419, "seek": 239426, "start": 2407.26, "end": 2412.26, "text": " And so this is the network we have, um, revolutions, values, max pooling.", "tokens": [51014, 400, 370, 341, 307, 264, 3209, 321, 362, 11, 1105, 11, 3698, 15892, 11, 4190, 11, 11469, 7005, 278, 13, 51264], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 420, "seek": 239426, "start": 2412.6200000000003, "end": 2414.6200000000003, "text": " So all of this we should be familiar with by now.", "tokens": [51282, 407, 439, 295, 341, 321, 820, 312, 4963, 365, 538, 586, 13, 51382], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 421, "seek": 239426, "start": 2415.2200000000003, "end": 2418.3, "text": " Um, and it's all just in one big NN.sequential.", "tokens": [51412, 3301, 11, 293, 309, 311, 439, 445, 294, 472, 955, 426, 45, 13, 11834, 2549, 13, 51566], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 422, "seek": 239426, "start": 2418.6200000000003, "end": 2419.86, "text": " Um, this doesn't have the head.", "tokens": [51582, 3301, 11, 341, 1177, 380, 362, 264, 1378, 13, 51644], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 423, "seek": 239426, "start": 2419.86, "end": 2421.5400000000004, "text": " So we said, uh, dot features.", "tokens": [51644, 407, 321, 848, 11, 2232, 11, 5893, 4122, 13, 51728], "temperature": 0.0, "avg_logprob": -0.31918609399589704, "compression_ratio": 1.6156583629893237, "no_speech_prob": 0.0011513415956869721}, {"id": 424, "seek": 242154, "start": 2421.9, "end": 2427.02, "text": " If you did this without you'd have then the, this is like the features, um, sub sub sub", "tokens": [50382, 759, 291, 630, 341, 1553, 291, 1116, 362, 550, 264, 11, 341, 307, 411, 264, 4122, 11, 1105, 11, 1422, 1422, 1422, 50638], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 425, "seek": 242154, "start": 2427.02, "end": 2427.38, "text": " network.", "tokens": [50638, 3209, 13, 50656], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 426, "seek": 242154, "start": 2427.38, "end": 2429.02, "text": " That's everything up until some point.", "tokens": [50656, 663, 311, 1203, 493, 1826, 512, 935, 13, 50738], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 427, "seek": 242154, "start": 2429.02, "end": 2432.9, "text": " And then you have the flattening and the classification, which we are kind of just", "tokens": [50738, 400, 550, 291, 362, 264, 24183, 278, 293, 264, 21538, 11, 597, 321, 366, 733, 295, 445, 50932], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 428, "seek": 242154, "start": 2432.9, "end": 2433.46, "text": " throwing away.", "tokens": [50932, 10238, 1314, 13, 50960], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 429, "seek": 242154, "start": 2433.5, "end": 2435.34, "text": " So this is the body of the network.", "tokens": [50962, 407, 341, 307, 264, 1772, 295, 264, 3209, 13, 51054], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 430, "seek": 242154, "start": 2435.74, "end": 2439.3, "text": " And we're going to try and tag into various layers here and extract the outputs.", "tokens": [51074, 400, 321, 434, 516, 281, 853, 293, 6162, 666, 3683, 7914, 510, 293, 8947, 264, 23930, 13, 51252], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 431, "seek": 242154, "start": 2439.98, "end": 2442.98, "text": " Um, but before we do that, there's one more bit of admin we need to handle.", "tokens": [51286, 3301, 11, 457, 949, 321, 360, 300, 11, 456, 311, 472, 544, 857, 295, 24236, 321, 643, 281, 4813, 13, 51436], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 432, "seek": 242154, "start": 2443.38, "end": 2446.9, "text": " Um, this was trained on a normalized version of ImageNet, right?", "tokens": [51456, 3301, 11, 341, 390, 8895, 322, 257, 48704, 3037, 295, 29903, 31890, 11, 558, 30, 51632], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 433, "seek": 242154, "start": 2446.9, "end": 2450.22, "text": " Where you took the dataset mean and the dataset standard deviation, and you use that to", "tokens": [51632, 2305, 291, 1890, 264, 28872, 914, 293, 264, 28872, 3832, 25163, 11, 293, 291, 764, 300, 281, 51798], "temperature": 0.0, "avg_logprob": -0.254212781002647, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0009110412793233991}, {"id": 434, "seek": 245022, "start": 2450.2599999999998, "end": 2451.4199999999996, "text": " normalize your images.", "tokens": [50366, 2710, 1125, 428, 5267, 13, 50424], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 435, "seek": 245022, "start": 2451.8999999999996, "end": 2455.18, "text": " So if we want to match what the data looked like during training, we need to match that", "tokens": [50448, 407, 498, 321, 528, 281, 2995, 437, 264, 1412, 2956, 411, 1830, 3097, 11, 321, 643, 281, 2995, 300, 50612], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 436, "seek": 245022, "start": 2455.18, "end": 2456.18, "text": " normalization step.", "tokens": [50612, 2710, 2144, 1823, 13, 50662], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 437, "seek": 245022, "start": 2456.7799999999997, "end": 2460.5, "text": " And we've done this on grayscale images where we just subtract the mean divided by the", "tokens": [50692, 400, 321, 600, 1096, 341, 322, 677, 3772, 37088, 5267, 689, 321, 445, 16390, 264, 914, 6666, 538, 264, 50878], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 438, "seek": 245022, "start": 2460.5, "end": 2461.3399999999997, "text": " standard deviation.", "tokens": [50878, 3832, 25163, 13, 50920], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 439, "seek": 245022, "start": 2461.8199999999997, "end": 2466.3399999999997, "text": " Um, but with three channel images, these RGB images, um, we can't get away with just", "tokens": [50944, 3301, 11, 457, 365, 1045, 2269, 5267, 11, 613, 31231, 5267, 11, 1105, 11, 321, 393, 380, 483, 1314, 365, 445, 51170], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 440, "seek": 245022, "start": 2466.3399999999997, "end": 2471.06, "text": " saying, uh, let's subtract our mean from our image and divide by the standard deviation.", "tokens": [51170, 1566, 11, 2232, 11, 718, 311, 16390, 527, 914, 490, 527, 3256, 293, 9845, 538, 264, 3832, 25163, 13, 51406], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 441, "seek": 245022, "start": 2471.06, "end": 2472.1, "text": " You're going to get an error.", "tokens": [51406, 509, 434, 516, 281, 483, 364, 6713, 13, 51458], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 442, "seek": 245022, "start": 2473.1, "end": 2473.8199999999997, "text": " It's going to pop up.", "tokens": [51508, 467, 311, 516, 281, 1665, 493, 13, 51544], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 443, "seek": 245022, "start": 2473.8199999999997, "end": 2478.02, "text": " And this is because we now need to think about broadcasting and these shapes a little bit", "tokens": [51544, 400, 341, 307, 570, 321, 586, 643, 281, 519, 466, 30024, 293, 613, 10854, 257, 707, 857, 51754], "temperature": 0.0, "avg_logprob": -0.2078202035692003, "compression_ratio": 1.8131147540983608, "no_speech_prob": 0.0069036283530294895}, {"id": 444, "seek": 247802, "start": 2478.02, "end": 2480.2599999999998, "text": " more carefully than we can with just a scalar value.", "tokens": [50364, 544, 7500, 813, 321, 393, 365, 445, 257, 39684, 2158, 13, 50476], "temperature": 0.0, "avg_logprob": -0.205752629500169, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.043364543467760086}, {"id": 445, "seek": 247802, "start": 2481.1, "end": 2484.22, "text": " Um, so if we look at the mean here, we just have three values, right?", "tokens": [50518, 3301, 11, 370, 498, 321, 574, 412, 264, 914, 510, 11, 321, 445, 362, 1045, 4190, 11, 558, 30, 50674], "temperature": 0.0, "avg_logprob": -0.205752629500169, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.043364543467760086}, {"id": 446, "seek": 247802, "start": 2484.22, "end": 2487.34, "text": " One for each channel, the red, green, and blue channels.", "tokens": [50674, 1485, 337, 1184, 2269, 11, 264, 2182, 11, 3092, 11, 293, 3344, 9235, 13, 50830], "temperature": 0.0, "avg_logprob": -0.205752629500169, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.043364543467760086}, {"id": 447, "seek": 247802, "start": 2487.46, "end": 2493.62, "text": " Um, whereas our content image has three channels and then 256 by 256 for the, you know,", "tokens": [50836, 3301, 11, 9735, 527, 2701, 3256, 575, 1045, 9235, 293, 550, 38882, 538, 38882, 337, 264, 11, 291, 458, 11, 51144], "temperature": 0.0, "avg_logprob": -0.205752629500169, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.043364543467760086}, {"id": 448, "seek": 247802, "start": 2493.62, "end": 2494.62, "text": " spatial dimensions.", "tokens": [51144, 23598, 12819, 13, 51194], "temperature": 0.0, "avg_logprob": -0.205752629500169, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.043364543467760086}, {"id": 449, "seek": 247802, "start": 2495.38, "end": 2502.14, "text": " So if we try and say content image, you know, divided by the mean or minus the mean, um,", "tokens": [51232, 407, 498, 321, 853, 293, 584, 2701, 3256, 11, 291, 458, 11, 6666, 538, 264, 914, 420, 3175, 264, 914, 11, 1105, 11, 51570], "temperature": 0.0, "avg_logprob": -0.205752629500169, "compression_ratio": 1.6936936936936937, "no_speech_prob": 0.043364543467760086}, {"id": 450, "seek": 250214, "start": 2502.14, "end": 2508.3399999999997, "text": " it's going to go from right to left and find the first non-unit, um, axis.", "tokens": [50364, 309, 311, 516, 281, 352, 490, 558, 281, 1411, 293, 915, 264, 700, 2107, 12, 409, 270, 11, 1105, 11, 10298, 13, 50674], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 451, "seek": 250214, "start": 2508.3399999999997, "end": 2512.18, "text": " So would anything with a, with a size greater than one, and it's going to try and line", "tokens": [50674, 407, 576, 1340, 365, 257, 11, 365, 257, 2744, 5044, 813, 472, 11, 293, 309, 311, 516, 281, 853, 293, 1622, 50866], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 452, "seek": 250214, "start": 2512.18, "end": 2512.54, "text": " those up.", "tokens": [50866, 729, 493, 13, 50884], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 453, "seek": 250214, "start": 2512.54, "end": 2515.2599999999998, "text": " And in this case, the three and the 256, those aren't going to match.", "tokens": [50884, 400, 294, 341, 1389, 11, 264, 1045, 293, 264, 38882, 11, 729, 3212, 380, 516, 281, 2995, 13, 51020], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 454, "seek": 250214, "start": 2515.58, "end": 2516.8199999999997, "text": " And so we're going to get an error.", "tokens": [51036, 400, 370, 321, 434, 516, 281, 483, 364, 6713, 13, 51098], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 455, "seek": 250214, "start": 2517.3399999999997, "end": 2521.42, "text": " Um, well, perniciously, if the shape did happen to match, um, that might still not be what", "tokens": [51124, 3301, 11, 731, 11, 680, 77, 3784, 356, 11, 498, 264, 3909, 630, 1051, 281, 2995, 11, 1105, 11, 300, 1062, 920, 406, 312, 437, 51328], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 456, "seek": 250214, "start": 2521.42, "end": 2522.02, "text": " you intended.", "tokens": [51328, 291, 10226, 13, 51358], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 457, "seek": 250214, "start": 2522.46, "end": 2526.42, "text": " So what we'd like is to have these three channels mapped to the three channels of our", "tokens": [51380, 407, 437, 321, 1116, 411, 307, 281, 362, 613, 1045, 9235, 33318, 281, 264, 1045, 9235, 295, 527, 51578], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 458, "seek": 250214, "start": 2526.42, "end": 2531.8599999999997, "text": " image, and then somehow expand those values out across the two other dimensions.", "tokens": [51578, 3256, 11, 293, 550, 6063, 5268, 729, 4190, 484, 2108, 264, 732, 661, 12819, 13, 51850], "temperature": 0.0, "avg_logprob": -0.2197979022930195, "compression_ratio": 1.7766990291262137, "no_speech_prob": 0.09136977791786194}, {"id": 459, "seek": 253214, "start": 2532.3399999999997, "end": 2537.14, "text": " And the way we do that is we just add two additional dimensions on the right for our", "tokens": [50374, 400, 264, 636, 321, 360, 300, 307, 321, 445, 909, 732, 4497, 12819, 322, 264, 558, 337, 527, 50614], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 460, "seek": 253214, "start": 2537.14, "end": 2537.94, "text": " image net dot mean.", "tokens": [50614, 3256, 2533, 5893, 914, 13, 50654], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 461, "seek": 253214, "start": 2537.94, "end": 2541.58, "text": " And you could also do dot unsqueeze minus one dot unsqueeze minus one.", "tokens": [50654, 400, 291, 727, 611, 360, 5893, 2693, 1077, 10670, 3175, 472, 5893, 2693, 1077, 10670, 3175, 472, 13, 50836], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 462, "seek": 253214, "start": 2542.1, "end": 2545.74, "text": " Um, but this is the kind of syntax that we're using in this course.", "tokens": [50862, 3301, 11, 457, 341, 307, 264, 733, 295, 28431, 300, 321, 434, 1228, 294, 341, 1164, 13, 51044], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 463, "seek": 253214, "start": 2546.14, "end": 2549.46, "text": " And now our shapes are going to match because we're going to go from right to left.", "tokens": [51064, 400, 586, 527, 10854, 366, 516, 281, 2995, 570, 321, 434, 516, 281, 352, 490, 558, 281, 1411, 13, 51230], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 464, "seek": 253214, "start": 2549.8199999999997, "end": 2554.42, "text": " If it's a unit dimension size one, we're going to expand it out to match the other", "tokens": [51248, 759, 309, 311, 257, 4985, 10139, 2744, 472, 11, 321, 434, 516, 281, 5268, 309, 484, 281, 2995, 264, 661, 51478], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 465, "seek": 253214, "start": 2554.54, "end": 2555.06, "text": " tensors.", "tokens": [51484, 10688, 830, 13, 51510], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 466, "seek": 253214, "start": 2555.98, "end": 2558.5, "text": " Um, and if it's a non-unit dimension, then the shapes have to match.", "tokens": [51556, 3301, 11, 293, 498, 309, 311, 257, 2107, 12, 409, 270, 10139, 11, 550, 264, 10854, 362, 281, 2995, 13, 51682], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 467, "seek": 253214, "start": 2558.58, "end": 2559.94, "text": " And that looks like it's the case.", "tokens": [51686, 400, 300, 1542, 411, 309, 311, 264, 1389, 13, 51754], "temperature": 0.0, "avg_logprob": -0.23649868549116507, "compression_ratio": 1.888086642599278, "no_speech_prob": 0.0009697223431430757}, {"id": 468, "seek": 255994, "start": 2560.3, "end": 2566.46, "text": " And so now with this, um, reshaping operation, we can write a little normalize function,", "tokens": [50382, 400, 370, 586, 365, 341, 11, 1105, 11, 725, 71, 569, 278, 6916, 11, 321, 393, 2464, 257, 707, 2710, 1125, 2445, 11, 50690], "temperature": 0.0, "avg_logprob": -0.23070161573348508, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.012053235433995724}, {"id": 469, "seek": 255994, "start": 2566.82, "end": 2568.78, "text": " which we can then apply to our content image.", "tokens": [50708, 597, 321, 393, 550, 3079, 281, 527, 2701, 3256, 13, 50806], "temperature": 0.0, "avg_logprob": -0.23070161573348508, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.012053235433995724}, {"id": 470, "seek": 255994, "start": 2568.78, "end": 2572.2200000000003, "text": " And I'm just checking the min and the max to make sure that this roughly makes sense.", "tokens": [50806, 400, 286, 478, 445, 8568, 264, 923, 293, 264, 11469, 281, 652, 988, 300, 341, 9810, 1669, 2020, 13, 50978], "temperature": 0.0, "avg_logprob": -0.23070161573348508, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.012053235433995724}, {"id": 471, "seek": 255994, "start": 2572.62, "end": 2578.02, "text": " Um, we could check the mean, uh, as well to make sure that the mean is somewhat close", "tokens": [50998, 3301, 11, 321, 727, 1520, 264, 914, 11, 2232, 11, 382, 731, 281, 652, 988, 300, 264, 914, 307, 8344, 1998, 51268], "temperature": 0.0, "avg_logprob": -0.23070161573348508, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.012053235433995724}, {"id": 472, "seek": 255994, "start": 2578.02, "end": 2578.54, "text": " to zero.", "tokens": [51268, 281, 4018, 13, 51294], "temperature": 0.0, "avg_logprob": -0.23070161573348508, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.012053235433995724}, {"id": 473, "seek": 255994, "start": 2582.42, "end": 2582.9, "text": " Um, okay.", "tokens": [51488, 3301, 11, 1392, 13, 51512], "temperature": 0.0, "avg_logprob": -0.23070161573348508, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.012053235433995724}, {"id": 474, "seek": 255994, "start": 2582.9, "end": 2585.78, "text": " In this case, less maybe because it's a darker image than average.", "tokens": [51512, 682, 341, 1389, 11, 1570, 1310, 570, 309, 311, 257, 12741, 3256, 813, 4274, 13, 51656], "temperature": 0.0, "avg_logprob": -0.23070161573348508, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.012053235433995724}, {"id": 475, "seek": 255994, "start": 2586.14, "end": 2588.58, "text": " Um, but at least we are doing the operation.", "tokens": [51674, 3301, 11, 457, 412, 1935, 321, 366, 884, 264, 6916, 13, 51796], "temperature": 0.0, "avg_logprob": -0.23070161573348508, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.012053235433995724}, {"id": 476, "seek": 258858, "start": 2588.58, "end": 2589.9, "text": " It seems like the math is correct.", "tokens": [50364, 467, 2544, 411, 264, 5221, 307, 3006, 13, 50430], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 477, "seek": 258858, "start": 2589.9, "end": 2592.42, "text": " And now the shader in the channel wise mean would be interesting.", "tokens": [50430, 400, 586, 264, 5744, 260, 294, 264, 2269, 10829, 914, 576, 312, 1880, 13, 50556], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 478, "seek": 258858, "start": 2593.8199999999997, "end": 2595.1, "text": " Uh, Oh yes.", "tokens": [50626, 4019, 11, 876, 2086, 13, 50690], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 479, "seek": 258858, "start": 2595.18, "end": 2598.06, "text": " Um, so that would be the mean over the dimensions.", "tokens": [50694, 3301, 11, 370, 300, 576, 312, 264, 914, 670, 264, 12819, 13, 50838], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 480, "seek": 258858, "start": 2598.1, "end": 2601.9, "text": " Um, one and two, I think.", "tokens": [50840, 3301, 11, 472, 293, 732, 11, 286, 519, 13, 51030], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 481, "seek": 258858, "start": 2604.8199999999997, "end": 2607.7, "text": " Uh, I think you have to tap all one comma two.", "tokens": [51176, 4019, 11, 286, 519, 291, 362, 281, 5119, 439, 472, 22117, 732, 13, 51320], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 482, "seek": 258858, "start": 2608.5, "end": 2610.7799999999997, "text": " This wasn't sure which way it was.", "tokens": [51360, 639, 2067, 380, 988, 597, 636, 309, 390, 13, 51474], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 483, "seek": 258858, "start": 2610.8199999999997, "end": 2611.14, "text": " Yeah.", "tokens": [51476, 865, 13, 51492], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 484, "seek": 258858, "start": 2611.14, "end": 2612.22, "text": " I always forget to.", "tokens": [51492, 286, 1009, 2870, 281, 13, 51546], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 485, "seek": 258858, "start": 2615.38, "end": 2615.98, "text": " Um, okay.", "tokens": [51704, 3301, 11, 1392, 13, 51734], "temperature": 0.0, "avg_logprob": -0.41707781449104975, "compression_ratio": 1.535, "no_speech_prob": 0.028005197644233704}, {"id": 486, "seek": 261598, "start": 2615.98, "end": 2618.66, "text": " So our blue channel is brighter than the others.", "tokens": [50364, 407, 527, 3344, 2269, 307, 19764, 813, 264, 2357, 13, 50498], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 487, "seek": 261598, "start": 2618.66, "end": 2624.78, "text": " And if we go back and look at our image, um, maybe believe that the magenta is going to", "tokens": [50498, 400, 498, 321, 352, 646, 293, 574, 412, 527, 3256, 11, 1105, 11, 1310, 1697, 300, 264, 2258, 8938, 307, 516, 281, 50804], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 488, "seek": 261598, "start": 2624.78, "end": 2628.42, "text": " be blue and red and the face is going to be just blue.", "tokens": [50804, 312, 3344, 293, 2182, 293, 264, 1851, 307, 516, 281, 312, 445, 3344, 13, 50986], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 489, "seek": 261598, "start": 2629.18, "end": 2629.98, "text": " Um, yeah.", "tokens": [51024, 3301, 11, 1338, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 490, "seek": 261598, "start": 2630.02, "end": 2630.34, "text": " Okay.", "tokens": [51066, 1033, 13, 51082], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 491, "seek": 261598, "start": 2630.42, "end": 2631.66, "text": " So that seems to be working.", "tokens": [51086, 407, 300, 2544, 281, 312, 1364, 13, 51148], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 492, "seek": 261598, "start": 2631.94, "end": 2635.46, "text": " We can double check because now that we've implemented ourselves, torch vision dot", "tokens": [51162, 492, 393, 3834, 1520, 570, 586, 300, 321, 600, 12270, 4175, 11, 27822, 5201, 5893, 51338], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 493, "seek": 261598, "start": 2635.46, "end": 2638.94, "text": " transforms has a normalized function that you can pass the mean and standard deviation", "tokens": [51338, 35592, 575, 257, 48704, 2445, 300, 291, 393, 1320, 264, 914, 293, 3832, 25163, 51512], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 494, "seek": 261598, "start": 2638.94, "end": 2643.46, "text": " to, and it's going to handle making sure that the devices match that the shapes match,", "tokens": [51512, 281, 11, 293, 309, 311, 516, 281, 4813, 1455, 988, 300, 264, 5759, 2995, 300, 264, 10854, 2995, 11, 51738], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 495, "seek": 261598, "start": 2643.46, "end": 2643.98, "text": " et cetera.", "tokens": [51738, 1030, 11458, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23777560031775272, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.010817963629961014}, {"id": 496, "seek": 264398, "start": 2644.46, "end": 2648.06, "text": " And you can see if we check the min and max, it's exactly the same, just a little bit of", "tokens": [50388, 400, 291, 393, 536, 498, 321, 1520, 264, 923, 293, 11469, 11, 309, 311, 2293, 264, 912, 11, 445, 257, 707, 857, 295, 50568], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 497, "seek": 264398, "start": 2648.06, "end": 2652.26, "text": " reassurance that our function is doing the same thing as this normalized transform.", "tokens": [50568, 19486, 5683, 300, 527, 2445, 307, 884, 264, 912, 551, 382, 341, 48704, 4088, 13, 50778], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 498, "seek": 264398, "start": 2653.9, "end": 2656.42, "text": " I appreciate you not cheating by implementing that.", "tokens": [50860, 286, 4449, 291, 406, 18309, 538, 18114, 300, 13, 50986], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 499, "seek": 264398, "start": 2656.5, "end": 2657.38, "text": " Jono, thank you.", "tokens": [50990, 7745, 78, 11, 1309, 291, 13, 51034], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 500, "seek": 264398, "start": 2658.62, "end": 2659.06, "text": " You're welcome.", "tokens": [51096, 509, 434, 2928, 13, 51118], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 501, "seek": 264398, "start": 2659.06, "end": 2660.02, "text": " Gotta follow the rules.", "tokens": [51118, 21527, 1524, 264, 4474, 13, 51166], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 502, "seek": 264398, "start": 2660.22, "end": 2660.7400000000002, "text": " Gotta follow the rules.", "tokens": [51176, 21527, 1524, 264, 4474, 13, 51202], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 503, "seek": 264398, "start": 2660.82, "end": 2661.02, "text": " Okay.", "tokens": [51206, 1033, 13, 51216], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 504, "seek": 264398, "start": 2661.06, "end": 2665.34, "text": " So with that bit of admin out the way, we can finally say, how do we extract the", "tokens": [51218, 407, 365, 300, 857, 295, 24236, 484, 264, 636, 11, 321, 393, 2721, 584, 11, 577, 360, 321, 8947, 264, 51432], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 505, "seek": 264398, "start": 2665.34, "end": 2666.94, "text": " features from this network?", "tokens": [51432, 4122, 490, 341, 3209, 30, 51512], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 506, "seek": 264398, "start": 2667.5, "end": 2672.26, "text": " Uh, now if you remember the previous lesson on hooks, that might be something that", "tokens": [51540, 4019, 11, 586, 498, 291, 1604, 264, 3894, 6898, 322, 26485, 11, 300, 1062, 312, 746, 300, 51778], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 507, "seek": 264398, "start": 2672.26, "end": 2673.02, "text": " springs to mind.", "tokens": [51778, 24647, 281, 1575, 13, 51816], "temperature": 0.0, "avg_logprob": -0.3211181586515819, "compression_ratio": 1.6720257234726688, "no_speech_prob": 0.01081816665828228}, {"id": 508, "seek": 267302, "start": 2673.38, "end": 2675.7, "text": " I'm going to leave that as an exercise for the reader.", "tokens": [50382, 286, 478, 516, 281, 1856, 300, 382, 364, 5380, 337, 264, 15149, 13, 50498], "temperature": 0.0, "avg_logprob": -0.2239903344048394, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0003859636199194938}, {"id": 509, "seek": 267302, "start": 2676.14, "end": 2679.58, "text": " And what we're going to do is we're just going to normalize our inputs.", "tokens": [50520, 400, 437, 321, 434, 516, 281, 360, 307, 321, 434, 445, 516, 281, 2710, 1125, 527, 15743, 13, 50692], "temperature": 0.0, "avg_logprob": -0.2239903344048394, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0003859636199194938}, {"id": 510, "seek": 267302, "start": 2680.22, "end": 2685.18, "text": " And then we're going to run through the layers one by one in this sequential stack.", "tokens": [50724, 400, 550, 321, 434, 516, 281, 1190, 807, 264, 7914, 472, 538, 472, 294, 341, 42881, 8630, 13, 50972], "temperature": 0.0, "avg_logprob": -0.2239903344048394, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0003859636199194938}, {"id": 511, "seek": 267302, "start": 2685.74, "end": 2688.14, "text": " Um, we're going to pass our X through that layer.", "tokens": [51000, 3301, 11, 321, 434, 516, 281, 1320, 527, 1783, 807, 300, 4583, 13, 51120], "temperature": 0.0, "avg_logprob": -0.2239903344048394, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0003859636199194938}, {"id": 512, "seek": 267302, "start": 2688.58, "end": 2692.54, "text": " And then if we're in one of the target layers, which we can specify, we're going to", "tokens": [51142, 400, 550, 498, 321, 434, 294, 472, 295, 264, 3779, 7914, 11, 597, 321, 393, 16500, 11, 321, 434, 516, 281, 51340], "temperature": 0.0, "avg_logprob": -0.2239903344048394, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0003859636199194938}, {"id": 513, "seek": 267302, "start": 2692.54, "end": 2694.46, "text": " store the outputs of that layer.", "tokens": [51340, 3531, 264, 23930, 295, 300, 4583, 13, 51436], "temperature": 0.0, "avg_logprob": -0.2239903344048394, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0003859636199194938}, {"id": 514, "seek": 267302, "start": 2694.9, "end": 2698.54, "text": " And I can't remember if I've used the term features before or not.", "tokens": [51458, 400, 286, 393, 380, 1604, 498, 286, 600, 1143, 264, 1433, 4122, 949, 420, 406, 13, 51640], "temperature": 0.0, "avg_logprob": -0.2239903344048394, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0003859636199194938}, {"id": 515, "seek": 267302, "start": 2698.54, "end": 2702.38, "text": " So apologies if I have, but just to clarify here, when we say features, we just mean.", "tokens": [51640, 407, 34929, 498, 286, 362, 11, 457, 445, 281, 17594, 510, 11, 562, 321, 584, 4122, 11, 321, 445, 914, 13, 51832], "temperature": 0.0, "avg_logprob": -0.2239903344048394, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0003859636199194938}, {"id": 516, "seek": 270302, "start": 2703.14, "end": 2706.38, "text": " The activations of, of a layer.", "tokens": [50370, 440, 2430, 763, 295, 11, 295, 257, 4583, 13, 50532], "temperature": 0.0, "avg_logprob": -0.21646871874409337, "compression_ratio": 1.562992125984252, "no_speech_prob": 0.00032503309193998575}, {"id": 517, "seek": 270302, "start": 2706.46, "end": 2710.94, "text": " In this case, Jono's picked out two particular layers, 18 and 25.", "tokens": [50536, 682, 341, 1389, 11, 7745, 78, 311, 6183, 484, 732, 1729, 7914, 11, 2443, 293, 3552, 13, 50760], "temperature": 0.0, "avg_logprob": -0.21646871874409337, "compression_ratio": 1.562992125984252, "no_speech_prob": 0.00032503309193998575}, {"id": 518, "seek": 270302, "start": 2711.82, "end": 2715.42, "text": " Um, yeah, I just want to, I mean, I'm not sure it matters in this particular case,", "tokens": [50804, 3301, 11, 1338, 11, 286, 445, 528, 281, 11, 286, 914, 11, 286, 478, 406, 988, 309, 7001, 294, 341, 1729, 1389, 11, 50984], "temperature": 0.0, "avg_logprob": -0.21646871874409337, "compression_ratio": 1.562992125984252, "no_speech_prob": 0.00032503309193998575}, {"id": 519, "seek": 270302, "start": 2715.42, "end": 2718.98, "text": " but there's a bit of a gotcha you've got here, Jono, which is you should change that.", "tokens": [50984, 457, 456, 311, 257, 857, 295, 257, 658, 4413, 291, 600, 658, 510, 11, 7745, 78, 11, 597, 307, 291, 820, 1319, 300, 13, 51162], "temperature": 0.0, "avg_logprob": -0.21646871874409337, "compression_ratio": 1.562992125984252, "no_speech_prob": 0.00032503309193998575}, {"id": 520, "seek": 270302, "start": 2719.62, "end": 2724.06, "text": " Um, default 18 comma 25 from a list to a tuple.", "tokens": [51194, 3301, 11, 7576, 2443, 22117, 3552, 490, 257, 1329, 281, 257, 2604, 781, 13, 51416], "temperature": 0.0, "avg_logprob": -0.21646871874409337, "compression_ratio": 1.562992125984252, "no_speech_prob": 0.00032503309193998575}, {"id": 521, "seek": 270302, "start": 2724.62, "end": 2731.62, "text": " And the reason for that is that when, uh, you use a mutable type, like a list in a", "tokens": [51444, 400, 264, 1778, 337, 300, 307, 300, 562, 11, 2232, 11, 291, 764, 257, 5839, 712, 2010, 11, 411, 257, 1329, 294, 257, 51794], "temperature": 0.0, "avg_logprob": -0.21646871874409337, "compression_ratio": 1.562992125984252, "no_speech_prob": 0.00032503309193998575}, {"id": 522, "seek": 273162, "start": 2731.62, "end": 2736.9, "text": " Python, um, default parameter, it does this really weird thing where it actually", "tokens": [50364, 15329, 11, 1105, 11, 7576, 13075, 11, 309, 775, 341, 534, 3657, 551, 689, 309, 767, 50628], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 523, "seek": 273162, "start": 2736.9, "end": 2738.02, "text": " keeps it around.", "tokens": [50628, 5965, 309, 926, 13, 50684], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 524, "seek": 273162, "start": 2738.02, "end": 2741.8599999999997, "text": " And if you change it at all later than it actually kind of modifies your function.", "tokens": [50684, 400, 498, 291, 1319, 309, 412, 439, 1780, 813, 309, 767, 733, 295, 1072, 11221, 428, 2445, 13, 50876], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 525, "seek": 273162, "start": 2742.3399999999997, "end": 2746.7, "text": " So I would suggest, yeah, never using a list as a default parameter, because at some", "tokens": [50900, 407, 286, 576, 3402, 11, 1338, 11, 1128, 1228, 257, 1329, 382, 257, 7576, 13075, 11, 570, 412, 512, 51118], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 526, "seek": 273162, "start": 2746.7, "end": 2750.3399999999997, "text": " point it will create the weirdest bug you've ever had.", "tokens": [51118, 935, 309, 486, 1884, 264, 44807, 7426, 291, 600, 1562, 632, 13, 51300], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 527, "seek": 273162, "start": 2750.7799999999997, "end": 2752.3399999999997, "text": " I speak, I say this from experience.", "tokens": [51322, 286, 1710, 11, 286, 584, 341, 490, 1752, 13, 51400], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 528, "seek": 273162, "start": 2753.1, "end": 2753.46, "text": " Yeah.", "tokens": [51438, 865, 13, 51456], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 529, "seek": 273162, "start": 2753.46, "end": 2753.74, "text": " Yeah.", "tokens": [51456, 865, 13, 51470], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 530, "seek": 273162, "start": 2753.74, "end": 2756.38, "text": " That sounds like, um, something that, that was hard one.", "tokens": [51470, 663, 3263, 411, 11, 1105, 11, 746, 300, 11, 300, 390, 1152, 472, 13, 51602], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 531, "seek": 273162, "start": 2756.7799999999997, "end": 2757.06, "text": " All right.", "tokens": [51622, 1057, 558, 13, 51636], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 532, "seek": 273162, "start": 2757.1, "end": 2758.1, "text": " I'll, I'll change that.", "tokens": [51638, 286, 603, 11, 286, 603, 1319, 300, 13, 51688], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 533, "seek": 273162, "start": 2758.1, "end": 2760.46, "text": " And by the time you see this notebook, that change should be there.", "tokens": [51688, 400, 538, 264, 565, 291, 536, 341, 21060, 11, 300, 1319, 820, 312, 456, 13, 51806], "temperature": 0.0, "avg_logprob": -0.24673456759066195, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0001488356210757047}, {"id": 534, "seek": 276046, "start": 2761.1, "end": 2761.62, "text": " Um, all right.", "tokens": [50396, 3301, 11, 439, 558, 13, 50422], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 535, "seek": 276046, "start": 2761.62, "end": 2762.98, "text": " So this is one way to do it.", "tokens": [50422, 407, 341, 307, 472, 636, 281, 360, 309, 13, 50490], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 536, "seek": 276046, "start": 2762.98, "end": 2767.2200000000003, "text": " Just manually running through the layers one by one up until whatever the latest layer", "tokens": [50490, 1449, 16945, 2614, 807, 264, 7914, 472, 538, 472, 493, 1826, 2035, 264, 6792, 4583, 50702], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 537, "seek": 276046, "start": 2767.2200000000003, "end": 2768.38, "text": " we're interested in is.", "tokens": [50702, 321, 434, 3102, 294, 307, 13, 50760], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 538, "seek": 276046, "start": 2768.82, "end": 2772.62, "text": " Um, but you could do this just as easily by adding hooks to the specific layers and then", "tokens": [50782, 3301, 11, 457, 291, 727, 360, 341, 445, 382, 3612, 538, 5127, 26485, 281, 264, 2685, 7914, 293, 550, 50972], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 539, "seek": 276046, "start": 2772.62, "end": 2775.9, "text": " just feeding your data through the whole network at once and relying on the hooks to", "tokens": [50972, 445, 12919, 428, 1412, 807, 264, 1379, 3209, 412, 1564, 293, 24140, 322, 264, 26485, 281, 51136], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 540, "seek": 276046, "start": 2776.34, "end": 2777.82, "text": " store those intermediates.", "tokens": [51158, 3531, 729, 15184, 1024, 13, 51232], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 541, "seek": 276046, "start": 2777.82, "end": 2777.86, "text": " Yeah.", "tokens": [51232, 865, 13, 51234], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 542, "seek": 276046, "start": 2777.86, "end": 2781.94, "text": " So let's make that a homework, actually, not just an exercise you can do, but yeah, I", "tokens": [51234, 407, 718, 311, 652, 300, 257, 14578, 11, 767, 11, 406, 445, 364, 5380, 291, 393, 360, 11, 457, 1338, 11, 286, 51438], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 543, "seek": 276046, "start": 2781.94, "end": 2784.1, "text": " want, let's make sure everybody does that.", "tokens": [51438, 528, 11, 718, 311, 652, 988, 2201, 775, 300, 13, 51546], "temperature": 0.0, "avg_logprob": -0.2524914049920235, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.0003740866668522358}, {"id": 544, "seek": 278410, "start": 2784.14, "end": 2790.5, "text": " You can use the, one of the hooks, um, callbacks we had or the hooks context managers", "tokens": [50366, 509, 393, 764, 264, 11, 472, 295, 264, 26485, 11, 1105, 11, 818, 17758, 321, 632, 420, 264, 26485, 4319, 14084, 50684], "temperature": 0.0, "avg_logprob": -0.24591701286883394, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.005641601979732513}, {"id": 545, "seek": 278410, "start": 2790.5, "end": 2795.18, "text": " we had, or you can use the register forward hook PyTorch directly.", "tokens": [50684, 321, 632, 11, 420, 291, 393, 764, 264, 7280, 2128, 6328, 9953, 51, 284, 339, 3838, 13, 50918], "temperature": 0.0, "avg_logprob": -0.24591701286883394, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.005641601979732513}, {"id": 546, "seek": 278410, "start": 2796.46, "end": 2796.7, "text": " Yeah.", "tokens": [50982, 865, 13, 50994], "temperature": 0.0, "avg_logprob": -0.24591701286883394, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.005641601979732513}, {"id": 547, "seek": 278410, "start": 2797.46, "end": 2802.18, "text": " Um, and so what we get out here, um, we feeding in an image that's 256 by 256.", "tokens": [51032, 3301, 11, 293, 370, 437, 321, 483, 484, 510, 11, 1105, 11, 321, 12919, 294, 364, 3256, 300, 311, 38882, 538, 38882, 13, 51268], "temperature": 0.0, "avg_logprob": -0.24591701286883394, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.005641601979732513}, {"id": 548, "seek": 278410, "start": 2802.58, "end": 2805.06, "text": " And the first layer that we're looking at is this one here.", "tokens": [51288, 400, 264, 700, 4583, 300, 321, 434, 1237, 412, 307, 341, 472, 510, 13, 51412], "temperature": 0.0, "avg_logprob": -0.24591701286883394, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.005641601979732513}, {"id": 549, "seek": 278410, "start": 2805.54, "end": 2810.2599999999998, "text": " Um, and so it's getting half to 128, then to 64.", "tokens": [51436, 3301, 11, 293, 370, 309, 311, 1242, 1922, 281, 29810, 11, 550, 281, 12145, 13, 51672], "temperature": 0.0, "avg_logprob": -0.24591701286883394, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.005641601979732513}, {"id": 550, "seek": 278410, "start": 2810.2599999999998, "end": 2813.18, "text": " These ones are just different because it's a different starting size.", "tokens": [51672, 1981, 2306, 366, 445, 819, 570, 309, 311, 257, 819, 2891, 2744, 13, 51818], "temperature": 0.0, "avg_logprob": -0.24591701286883394, "compression_ratio": 1.6313725490196078, "no_speech_prob": 0.005641601979732513}, {"id": 551, "seek": 281318, "start": 2813.66, "end": 2816.7, "text": " Um, and then to 32 by 32 by 512.", "tokens": [50388, 3301, 11, 293, 550, 281, 8858, 538, 8858, 538, 1025, 4762, 13, 50540], "temperature": 0.0, "avg_logprob": -0.2543445394820526, "compression_ratio": 1.808888888888889, "no_speech_prob": 0.0014103342546150088}, {"id": 552, "seek": 281318, "start": 2817.06, "end": 2820.14, "text": " And so those are the features that we're talking about for that layer 18.", "tokens": [50558, 400, 370, 729, 366, 264, 4122, 300, 321, 434, 1417, 466, 337, 300, 4583, 2443, 13, 50712], "temperature": 0.0, "avg_logprob": -0.2543445394820526, "compression_ratio": 1.808888888888889, "no_speech_prob": 0.0014103342546150088}, {"id": 553, "seek": 281318, "start": 2820.4199999999996, "end": 2826.5, "text": " It's this thing of shape 512 by 32 by 32 for every kind of spatial location in that 32", "tokens": [50726, 467, 311, 341, 551, 295, 3909, 1025, 4762, 538, 8858, 538, 8858, 337, 633, 733, 295, 23598, 4914, 294, 300, 8858, 51030], "temperature": 0.0, "avg_logprob": -0.2543445394820526, "compression_ratio": 1.808888888888889, "no_speech_prob": 0.0014103342546150088}, {"id": 554, "seek": 281318, "start": 2826.5, "end": 2830.66, "text": " by 32 grid, we have the output from 512 different filters.", "tokens": [51030, 538, 8858, 10748, 11, 321, 362, 264, 5598, 490, 1025, 4762, 819, 15995, 13, 51238], "temperature": 0.0, "avg_logprob": -0.2543445394820526, "compression_ratio": 1.808888888888889, "no_speech_prob": 0.0014103342546150088}, {"id": 555, "seek": 281318, "start": 2831.22, "end": 2833.8599999999997, "text": " And so those are going to be the features that we're talking about.", "tokens": [51266, 400, 370, 729, 366, 516, 281, 312, 264, 4122, 300, 321, 434, 1417, 466, 13, 51398], "temperature": 0.0, "avg_logprob": -0.2543445394820526, "compression_ratio": 1.808888888888889, "no_speech_prob": 0.0014103342546150088}, {"id": 556, "seek": 281318, "start": 2834.4199999999996, "end": 2839.8599999999997, "text": " So there's being the, the, uh, the channels in a, in a, in a single convolution.", "tokens": [51426, 407, 456, 311, 885, 264, 11, 264, 11, 2232, 11, 264, 9235, 294, 257, 11, 294, 257, 11, 294, 257, 2167, 45216, 13, 51698], "temperature": 0.0, "avg_logprob": -0.2543445394820526, "compression_ratio": 1.808888888888889, "no_speech_prob": 0.0014103342546150088}, {"id": 557, "seek": 281318, "start": 2840.66, "end": 2840.98, "text": " Yeah.", "tokens": [51738, 865, 13, 51754], "temperature": 0.0, "avg_logprob": -0.2543445394820526, "compression_ratio": 1.808888888888889, "no_speech_prob": 0.0014103342546150088}, {"id": 558, "seek": 284098, "start": 2841.66, "end": 2843.06, "text": " Um, okay.", "tokens": [50398, 3301, 11, 1392, 13, 50468], "temperature": 0.0, "avg_logprob": -0.24608399791102256, "compression_ratio": 1.6484375, "no_speech_prob": 0.006797206122428179}, {"id": 559, "seek": 284098, "start": 2843.1, "end": 2844.5, "text": " So what's the point of this?", "tokens": [50470, 407, 437, 311, 264, 935, 295, 341, 30, 50540], "temperature": 0.0, "avg_logprob": -0.24608399791102256, "compression_ratio": 1.6484375, "no_speech_prob": 0.006797206122428179}, {"id": 560, "seek": 284098, "start": 2844.5, "end": 2849.58, "text": " Well, like I said, we hoping that we can capture different things at different layers.", "tokens": [50540, 1042, 11, 411, 286, 848, 11, 321, 7159, 300, 321, 393, 7983, 819, 721, 412, 819, 7914, 13, 50794], "temperature": 0.0, "avg_logprob": -0.24608399791102256, "compression_ratio": 1.6484375, "no_speech_prob": 0.006797206122428179}, {"id": 561, "seek": 284098, "start": 2850.02, "end": 2854.26, "text": " Um, and so to kind of first get a feel for this, this, like, what if we just compared", "tokens": [50816, 3301, 11, 293, 370, 281, 733, 295, 700, 483, 257, 841, 337, 341, 11, 341, 11, 411, 11, 437, 498, 321, 445, 5347, 51028], "temperature": 0.0, "avg_logprob": -0.24608399791102256, "compression_ratio": 1.6484375, "no_speech_prob": 0.006797206122428179}, {"id": 562, "seek": 284098, "start": 2854.26, "end": 2858.58, "text": " these feature maps, um, we can institute what, what I'm calling a content loss, or", "tokens": [51028, 613, 4111, 11317, 11, 1105, 11, 321, 393, 26860, 437, 11, 437, 286, 478, 5141, 257, 2701, 4470, 11, 420, 51244], "temperature": 0.0, "avg_logprob": -0.24608399791102256, "compression_ratio": 1.6484375, "no_speech_prob": 0.006797206122428179}, {"id": 563, "seek": 284098, "start": 2858.58, "end": 2860.54, "text": " you might see it as a perceptual loss.", "tokens": [51244, 291, 1062, 536, 309, 382, 257, 43276, 901, 4470, 13, 51342], "temperature": 0.0, "avg_logprob": -0.24608399791102256, "compression_ratio": 1.6484375, "no_speech_prob": 0.006797206122428179}, {"id": 564, "seek": 284098, "start": 2861.02, "end": 2864.3, "text": " Um, and we're going to focus on a couple of later layers.", "tokens": [51366, 3301, 11, 293, 321, 434, 516, 281, 1879, 322, 257, 1916, 295, 1780, 7914, 13, 51530], "temperature": 0.0, "avg_logprob": -0.24608399791102256, "compression_ratio": 1.6484375, "no_speech_prob": 0.006797206122428179}, {"id": 565, "seek": 284098, "start": 2864.82, "end": 2866.18, "text": " Again, make sure that this is.", "tokens": [51556, 3764, 11, 652, 988, 300, 341, 307, 13, 51624], "temperature": 0.0, "avg_logprob": -0.24608399791102256, "compression_ratio": 1.6484375, "no_speech_prob": 0.006797206122428179}, {"id": 566, "seek": 286618, "start": 2866.8999999999996, "end": 2871.22, "text": " The people as I've learned, um, and what we're going to do is we're going to pass", "tokens": [50400, 440, 561, 382, 286, 600, 3264, 11, 1105, 11, 293, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 1320, 50616], "temperature": 0.0, "avg_logprob": -0.2636185073852539, "compression_ratio": 1.989071038251366, "no_speech_prob": 0.005301790311932564}, {"id": 567, "seek": 286618, "start": 2871.22, "end": 2873.74, "text": " in a target image in this case, our content image.", "tokens": [50616, 294, 257, 3779, 3256, 294, 341, 1389, 11, 527, 2701, 3256, 13, 50742], "temperature": 0.0, "avg_logprob": -0.2636185073852539, "compression_ratio": 1.989071038251366, "no_speech_prob": 0.005301790311932564}, {"id": 568, "seek": 286618, "start": 2874.2599999999998, "end": 2878.74, "text": " Um, and we're going to calculate those features in those target layers.", "tokens": [50768, 3301, 11, 293, 321, 434, 516, 281, 8873, 729, 4122, 294, 729, 3779, 7914, 13, 50992], "temperature": 0.0, "avg_logprob": -0.2636185073852539, "compression_ratio": 1.989071038251366, "no_speech_prob": 0.005301790311932564}, {"id": 569, "seek": 286618, "start": 2879.5, "end": 2890.3799999999997, "text": " Um, and then in the, um, in the forward method, when we comparing to our inputs,", "tokens": [51030, 3301, 11, 293, 550, 294, 264, 11, 1105, 11, 294, 264, 2128, 3170, 11, 562, 321, 15763, 281, 527, 15743, 11, 51574], "temperature": 0.0, "avg_logprob": -0.2636185073852539, "compression_ratio": 1.989071038251366, "no_speech_prob": 0.005301790311932564}, {"id": 570, "seek": 286618, "start": 2890.62, "end": 2894.8999999999996, "text": " we're going to calculate the features of our inputs, and we're going to do the", "tokens": [51586, 321, 434, 516, 281, 8873, 264, 4122, 295, 527, 15743, 11, 293, 321, 434, 516, 281, 360, 264, 51800], "temperature": 0.0, "avg_logprob": -0.2636185073852539, "compression_ratio": 1.989071038251366, "no_speech_prob": 0.005301790311932564}, {"id": 571, "seek": 289490, "start": 2894.9, "end": 2897.7000000000003, "text": " mean squared error between those and our target features.", "tokens": [50364, 914, 8889, 6713, 1296, 729, 293, 527, 3779, 4122, 13, 50504], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 572, "seek": 289490, "start": 2898.34, "end": 2901.3, "text": " Um, so maybe there's a bad way of explaining it, but the, so the.", "tokens": [50536, 3301, 11, 370, 1310, 456, 311, 257, 1578, 636, 295, 13468, 309, 11, 457, 264, 11, 370, 264, 13, 50684], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 573, "seek": 289490, "start": 2901.3, "end": 2904.62, "text": " So I can maybe read it back to you to make sure you understand.", "tokens": [50684, 407, 286, 393, 1310, 1401, 309, 646, 281, 291, 281, 652, 988, 291, 1223, 13, 50850], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 574, "seek": 289490, "start": 2904.62, "end": 2904.9, "text": " Yeah.", "tokens": [50850, 865, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 575, "seek": 289490, "start": 2904.98, "end": 2905.5, "text": " Would that help?", "tokens": [50868, 6068, 300, 854, 30, 50894], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 576, "seek": 289490, "start": 2905.5, "end": 2905.7000000000003, "text": " Yeah.", "tokens": [50894, 865, 13, 50904], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 577, "seek": 289490, "start": 2905.7000000000003, "end": 2906.78, "text": " So, okay.", "tokens": [50904, 407, 11, 1392, 13, 50958], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 578, "seek": 289490, "start": 2906.78, "end": 2909.46, "text": " So this is a loss function you've created.", "tokens": [50958, 407, 341, 307, 257, 4470, 2445, 291, 600, 2942, 13, 51092], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 579, "seek": 289490, "start": 2910.02, "end": 2913.38, "text": " It has a done to call method, which means you can pretend that it's a function.", "tokens": [51120, 467, 575, 257, 1096, 281, 818, 3170, 11, 597, 1355, 291, 393, 11865, 300, 309, 311, 257, 2445, 13, 51288], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 580, "seek": 289490, "start": 2913.54, "end": 2916.42, "text": " It's a callable in, in Python language.", "tokens": [51296, 467, 311, 257, 818, 712, 294, 11, 294, 15329, 2856, 13, 51440], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 581, "seek": 289490, "start": 2916.82, "end": 2920.1, "text": " Um, your, your forward.", "tokens": [51460, 3301, 11, 428, 11, 428, 2128, 13, 51624], "temperature": 0.0, "avg_logprob": -0.3658558402474471, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0008968963520601392}, {"id": 582, "seek": 292010, "start": 2921.1, "end": 2924.8199999999997, "text": " So yeah, in, in an NM module would call it forward, but in normal", "tokens": [50414, 407, 1338, 11, 294, 11, 294, 364, 426, 44, 10088, 576, 818, 309, 2128, 11, 457, 294, 2710, 50600], "temperature": 0.0, "avg_logprob": -0.280566808745617, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.001410344848409295}, {"id": 583, "seek": 292010, "start": 2924.8199999999997, "end": 2926.3399999999997, "text": " Python, we just use done to call.", "tokens": [50600, 15329, 11, 321, 445, 764, 1096, 281, 818, 13, 50676], "temperature": 0.0, "avg_logprob": -0.280566808745617, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.001410344848409295}, {"id": 584, "seek": 292010, "start": 2926.7799999999997, "end": 2932.7799999999997, "text": " It's taking, uh, one input, um, which is the way you set up your, your", "tokens": [50698, 467, 311, 1940, 11, 2232, 11, 472, 4846, 11, 1105, 11, 597, 307, 264, 636, 291, 992, 493, 428, 11, 428, 50998], "temperature": 0.0, "avg_logprob": -0.280566808745617, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.001410344848409295}, {"id": 585, "seek": 292010, "start": 2932.7799999999997, "end": 2935.02, "text": " image training callback earlier.", "tokens": [50998, 3256, 3097, 818, 3207, 3071, 13, 51110], "temperature": 0.0, "avg_logprob": -0.280566808745617, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.001410344848409295}, {"id": 586, "seek": 292010, "start": 2935.02, "end": 2939.14, "text": " It's just going to pass in the input, which is, this is the image as", "tokens": [51110, 467, 311, 445, 516, 281, 1320, 294, 264, 4846, 11, 597, 307, 11, 341, 307, 264, 3256, 382, 51316], "temperature": 0.0, "avg_logprob": -0.280566808745617, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.001410344848409295}, {"id": 587, "seek": 292010, "start": 2939.14, "end": 2940.7, "text": " it's been optimized to so far.", "tokens": [51316, 309, 311, 668, 26941, 281, 370, 1400, 13, 51394], "temperature": 0.0, "avg_logprob": -0.280566808745617, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.001410344848409295}, {"id": 588, "seek": 292010, "start": 2940.7, "end": 2942.5, "text": " So initially it's going to be that random noise.", "tokens": [51394, 407, 9105, 309, 311, 516, 281, 312, 300, 4974, 5658, 13, 51484], "temperature": 0.0, "avg_logprob": -0.280566808745617, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.001410344848409295}, {"id": 589, "seek": 292010, "start": 2943.22, "end": 2948.62, "text": " And then the, uh, loss you're calculating is the mean squared error of how far", "tokens": [51520, 400, 550, 264, 11, 2232, 11, 4470, 291, 434, 28258, 307, 264, 914, 8889, 6713, 295, 577, 1400, 51790], "temperature": 0.0, "avg_logprob": -0.280566808745617, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.001410344848409295}, {"id": 590, "seek": 294862, "start": 2948.62, "end": 2958.3399999999997, "text": " away is this, um, input image from the, um, target image, um, the mean squared", "tokens": [50364, 1314, 307, 341, 11, 1105, 11, 4846, 3256, 490, 264, 11, 1105, 11, 3779, 3256, 11, 1105, 11, 264, 914, 8889, 50850], "temperature": 0.0, "avg_logprob": -0.27548104189754874, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.00045831166789866984}, {"id": 591, "seek": 294862, "start": 2958.3399999999997, "end": 2964.42, "text": " error for each of the layers, eight, by default, 18 and 25.", "tokens": [50850, 6713, 337, 1184, 295, 264, 7914, 11, 3180, 11, 538, 7576, 11, 2443, 293, 3552, 13, 51154], "temperature": 0.0, "avg_logprob": -0.27548104189754874, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.00045831166789866984}, {"id": 592, "seek": 294862, "start": 2965.2999999999997, "end": 2969.2599999999998, "text": " Um, and so you're literally actually, it's a bit weird.", "tokens": [51198, 3301, 11, 293, 370, 291, 434, 3736, 767, 11, 309, 311, 257, 857, 3657, 13, 51396], "temperature": 0.0, "avg_logprob": -0.27548104189754874, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.00045831166789866984}, {"id": 593, "seek": 294862, "start": 2969.46, "end": 2972.02, "text": " You're actually calling a different neural network.", "tokens": [51406, 509, 434, 767, 5141, 257, 819, 18161, 3209, 13, 51534], "temperature": 0.0, "avg_logprob": -0.27548104189754874, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.00045831166789866984}, {"id": 594, "seek": 294862, "start": 2973.1, "end": 2977.42, "text": " Calc features actually call the neural network, but not because that's the model", "tokens": [51588, 3511, 66, 4122, 767, 818, 264, 18161, 3209, 11, 457, 406, 570, 300, 311, 264, 2316, 51804], "temperature": 0.0, "avg_logprob": -0.27548104189754874, "compression_ratio": 1.587378640776699, "no_speech_prob": 0.00045831166789866984}, {"id": 595, "seek": 297742, "start": 2977.42, "end": 2985.06, "text": " we're optimizing, but because it's actually the loss function is how far away are we?", "tokens": [50364, 321, 434, 40425, 11, 457, 570, 309, 311, 767, 264, 4470, 2445, 307, 577, 1400, 1314, 366, 321, 30, 50746], "temperature": 0.0, "avg_logprob": -0.24354883142419764, "compression_ratio": 1.7048458149779735, "no_speech_prob": 9.761530964169651e-05}, {"id": 596, "seek": 297742, "start": 2986.38, "end": 2986.7000000000003, "text": " Yeah.", "tokens": [50812, 865, 13, 50828], "temperature": 0.0, "avg_logprob": -0.24354883142419764, "compression_ratio": 1.7048458149779735, "no_speech_prob": 9.761530964169651e-05}, {"id": 597, "seek": 297742, "start": 2986.98, "end": 2988.1, "text": " So that's the last option.", "tokens": [50842, 407, 300, 311, 264, 1036, 3614, 13, 50898], "temperature": 0.0, "avg_logprob": -0.24354883142419764, "compression_ratio": 1.7048458149779735, "no_speech_prob": 9.761530964169651e-05}, {"id": 598, "seek": 297742, "start": 2988.46, "end": 2993.94, "text": " And so if we, so if you, so if we with SGD optimize that loss function, you're", "tokens": [50916, 400, 370, 498, 321, 11, 370, 498, 291, 11, 370, 498, 321, 365, 34520, 35, 19719, 300, 4470, 2445, 11, 291, 434, 51190], "temperature": 0.0, "avg_logprob": -0.24354883142419764, "compression_ratio": 1.7048458149779735, "no_speech_prob": 9.761530964169651e-05}, {"id": 599, "seek": 297742, "start": 2993.94, "end": 2996.06, "text": " not going to get the same pixels.", "tokens": [51190, 406, 516, 281, 483, 264, 912, 18668, 13, 51296], "temperature": 0.0, "avg_logprob": -0.24354883142419764, "compression_ratio": 1.7048458149779735, "no_speech_prob": 9.761530964169651e-05}, {"id": 600, "seek": 297742, "start": 2996.46, "end": 2999.3, "text": " You're going to get, I don't even know what this is going to look like.", "tokens": [51316, 509, 434, 516, 281, 483, 11, 286, 500, 380, 754, 458, 437, 341, 307, 516, 281, 574, 411, 13, 51458], "temperature": 0.0, "avg_logprob": -0.24354883142419764, "compression_ratio": 1.7048458149779735, "no_speech_prob": 9.761530964169651e-05}, {"id": 601, "seek": 297742, "start": 2999.3, "end": 3005.7400000000002, "text": " You're going to get some pixels, which have the same activations of those features.", "tokens": [51458, 509, 434, 516, 281, 483, 512, 18668, 11, 597, 362, 264, 912, 2430, 763, 295, 729, 4122, 13, 51780], "temperature": 0.0, "avg_logprob": -0.24354883142419764, "compression_ratio": 1.7048458149779735, "no_speech_prob": 9.761530964169651e-05}, {"id": 602, "seek": 300574, "start": 3006.2599999999998, "end": 3006.66, "text": " Yeah.", "tokens": [50390, 865, 13, 50410], "temperature": 0.0, "avg_logprob": -0.41336433174683873, "compression_ratio": 1.5178571428571428, "no_speech_prob": 4.908650225843303e-05}, {"id": 603, "seek": 300574, "start": 3006.74, "end": 3013.3399999999997, "text": " And so if we run that, we see, you can see the sort of shape of our person there, but", "tokens": [50414, 400, 370, 498, 321, 1190, 300, 11, 321, 536, 11, 291, 393, 536, 264, 1333, 295, 3909, 295, 527, 954, 456, 11, 457, 50744], "temperature": 0.0, "avg_logprob": -0.41336433174683873, "compression_ratio": 1.5178571428571428, "no_speech_prob": 4.908650225843303e-05}, {"id": 604, "seek": 300574, "start": 3013.7799999999997, "end": 3018.66, "text": " it definitely doesn't match on like a color and style basis.", "tokens": [50766, 309, 2138, 1177, 380, 2995, 322, 411, 257, 2017, 293, 3758, 5143, 13, 51010], "temperature": 0.0, "avg_logprob": -0.41336433174683873, "compression_ratio": 1.5178571428571428, "no_speech_prob": 4.908650225843303e-05}, {"id": 605, "seek": 300574, "start": 3019.1, "end": 3024.2999999999997, "text": " So 18 and 25 remind us how deep they are in the scheme of things.", "tokens": [51032, 407, 2443, 293, 3552, 4160, 505, 577, 2452, 436, 366, 294, 264, 12232, 295, 721, 13, 51292], "temperature": 0.0, "avg_logprob": -0.41336433174683873, "compression_ratio": 1.5178571428571428, "no_speech_prob": 4.908650225843303e-05}, {"id": 606, "seek": 300574, "start": 3025.02, "end": 3027.2599999999998, "text": " So these are fairly close towards the end.", "tokens": [51328, 407, 613, 366, 6457, 1998, 3030, 264, 917, 13, 51440], "temperature": 0.0, "avg_logprob": -0.41336433174683873, "compression_ratio": 1.5178571428571428, "no_speech_prob": 4.908650225843303e-05}, {"id": 607, "seek": 300574, "start": 3027.7, "end": 3028.1, "text": " Okay.", "tokens": [51462, 1033, 13, 51482], "temperature": 0.0, "avg_logprob": -0.41336433174683873, "compression_ratio": 1.5178571428571428, "no_speech_prob": 4.908650225843303e-05}, {"id": 608, "seek": 300574, "start": 3029.1, "end": 3034.06, "text": " So I guess color often doesn't have much of a semantic kind of property.", "tokens": [51532, 407, 286, 2041, 2017, 2049, 1177, 380, 362, 709, 295, 257, 47982, 733, 295, 4707, 13, 51780], "temperature": 0.0, "avg_logprob": -0.41336433174683873, "compression_ratio": 1.5178571428571428, "no_speech_prob": 4.908650225843303e-05}, {"id": 609, "seek": 303406, "start": 3034.06, "end": 3037.74, "text": " So that's probably why it doesn't care much about color because it's still going to be an", "tokens": [50364, 407, 300, 311, 1391, 983, 309, 1177, 380, 1127, 709, 466, 2017, 570, 309, 311, 920, 516, 281, 312, 364, 50548], "temperature": 0.0, "avg_logprob": -0.35202690760294597, "compression_ratio": 1.6586206896551725, "no_speech_prob": 0.000319996994221583}, {"id": 610, "seek": 303406, "start": 3037.74, "end": 3041.02, "text": " eyeball, whether it's green or blue or, or brown.", "tokens": [50548, 38868, 11, 1968, 309, 311, 3092, 420, 3344, 420, 11, 420, 6292, 13, 50712], "temperature": 0.0, "avg_logprob": -0.35202690760294597, "compression_ratio": 1.6586206896551725, "no_speech_prob": 0.000319996994221583}, {"id": 611, "seek": 303406, "start": 3041.94, "end": 3042.42, "text": " Yeah.", "tokens": [50758, 865, 13, 50782], "temperature": 0.0, "avg_logprob": -0.35202690760294597, "compression_ratio": 1.6586206896551725, "no_speech_prob": 0.000319996994221583}, {"id": 612, "seek": 303406, "start": 3042.9, "end": 3049.5, "text": " There's something else I should mention, which is we aren't constraining our tensor that we're", "tokens": [50806, 821, 311, 746, 1646, 286, 820, 2152, 11, 597, 307, 321, 3212, 380, 11525, 1760, 527, 40863, 300, 321, 434, 51136], "temperature": 0.0, "avg_logprob": -0.35202690760294597, "compression_ratio": 1.6586206896551725, "no_speech_prob": 0.000319996994221583}, {"id": 613, "seek": 303406, "start": 3049.5, "end": 3052.14, "text": " optimizing to be in the same bounds as a normal image.", "tokens": [51136, 40425, 281, 312, 294, 264, 912, 29905, 382, 257, 2710, 3256, 13, 51268], "temperature": 0.0, "avg_logprob": -0.35202690760294597, "compression_ratio": 1.6586206896551725, "no_speech_prob": 0.000319996994221583}, {"id": 614, "seek": 303406, "start": 3052.9, "end": 3058.2599999999998, "text": " And so some of these will also be less than zero or greater than one as kind of like almost", "tokens": [51306, 400, 370, 512, 295, 613, 486, 611, 312, 1570, 813, 4018, 420, 5044, 813, 472, 382, 733, 295, 411, 1920, 51574], "temperature": 0.0, "avg_logprob": -0.35202690760294597, "compression_ratio": 1.6586206896551725, "no_speech_prob": 0.000319996994221583}, {"id": 615, "seek": 303406, "start": 3058.2599999999998, "end": 3063.06, "text": " hacking the neural network to get the same features that those deep layers by passing in some", "tokens": [51574, 31422, 264, 18161, 3209, 281, 483, 264, 912, 4122, 300, 729, 2452, 7914, 538, 8437, 294, 512, 51814], "temperature": 0.0, "avg_logprob": -0.35202690760294597, "compression_ratio": 1.6586206896551725, "no_speech_prob": 0.000319996994221583}, {"id": 616, "seek": 306306, "start": 3063.06, "end": 3065.58, "text": " by passing in something that it's never seen during training.", "tokens": [50364, 538, 8437, 294, 746, 300, 309, 311, 1128, 1612, 1830, 3097, 13, 50490], "temperature": 0.0, "avg_logprob": -0.2661892361111111, "compression_ratio": 1.715210355987055, "no_speech_prob": 0.00030061291181482375}, {"id": 617, "seek": 306306, "start": 3066.14, "end": 3069.9, "text": " And so for display, we're clipping it to the same bounds as an image, but you might want to", "tokens": [50518, 400, 370, 337, 4674, 11, 321, 434, 49320, 309, 281, 264, 912, 29905, 382, 364, 3256, 11, 457, 291, 1062, 528, 281, 50706], "temperature": 0.0, "avg_logprob": -0.2661892361111111, "compression_ratio": 1.715210355987055, "no_speech_prob": 0.00030061291181482375}, {"id": 618, "seek": 306306, "start": 3069.9, "end": 3075.7, "text": " have either some sort of sigmoid function or some other way that you clamp your, your tensor", "tokens": [50706, 362, 2139, 512, 1333, 295, 4556, 3280, 327, 2445, 420, 512, 661, 636, 300, 291, 17690, 428, 11, 428, 40863, 50996], "temperature": 0.0, "avg_logprob": -0.2661892361111111, "compression_ratio": 1.715210355987055, "no_speech_prob": 0.00030061291181482375}, {"id": 619, "seek": 306306, "start": 3075.7, "end": 3080.2599999999998, "text": " model and to have outputs that are, that are like within the allowed range for.", "tokens": [50996, 2316, 293, 281, 362, 23930, 300, 366, 11, 300, 366, 411, 1951, 264, 4350, 3613, 337, 13, 51224], "temperature": 0.0, "avg_logprob": -0.2661892361111111, "compression_ratio": 1.715210355987055, "no_speech_prob": 0.00030061291181482375}, {"id": 620, "seek": 306306, "start": 3080.2599999999998, "end": 3080.9, "text": " Oh, good point.", "tokens": [51224, 876, 11, 665, 935, 13, 51256], "temperature": 0.0, "avg_logprob": -0.2661892361111111, "compression_ratio": 1.715210355987055, "no_speech_prob": 0.00030061291181482375}, {"id": 621, "seek": 306306, "start": 3081.38, "end": 3085.46, "text": " Also, it's interesting to note the background hasn't changed much.", "tokens": [51280, 2743, 11, 309, 311, 1880, 281, 3637, 264, 3678, 6132, 380, 3105, 709, 13, 51484], "temperature": 0.0, "avg_logprob": -0.2661892361111111, "compression_ratio": 1.715210355987055, "no_speech_prob": 0.00030061291181482375}, {"id": 622, "seek": 306306, "start": 3085.46, "end": 3089.34, "text": " And I guess the reason for that would be that the VGG model you were using in the loss", "tokens": [51484, 400, 286, 2041, 264, 1778, 337, 300, 576, 312, 300, 264, 691, 27561, 2316, 291, 645, 1228, 294, 264, 4470, 51678], "temperature": 0.0, "avg_logprob": -0.2661892361111111, "compression_ratio": 1.715210355987055, "no_speech_prob": 0.00030061291181482375}, {"id": 623, "seek": 306306, "start": 3089.34, "end": 3091.22, "text": " function was trained on ImageNet.", "tokens": [51678, 2445, 390, 8895, 322, 29903, 31890, 13, 51772], "temperature": 0.0, "avg_logprob": -0.2661892361111111, "compression_ratio": 1.715210355987055, "no_speech_prob": 0.00030061291181482375}, {"id": 624, "seek": 309122, "start": 3091.62, "end": 3098.7799999999997, "text": " And ImageNet is specifically about recognizing generally as a single big object, like a dog or", "tokens": [50384, 400, 29903, 31890, 307, 4682, 466, 18538, 5101, 382, 257, 2167, 955, 2657, 11, 411, 257, 3000, 420, 50742], "temperature": 0.0, "avg_logprob": -0.22773553810867608, "compression_ratio": 1.636, "no_speech_prob": 5.5621512728976086e-05}, {"id": 625, "seek": 309122, "start": 3098.7799999999997, "end": 3100.1, "text": " a boat or whatever.", "tokens": [50742, 257, 6582, 420, 2035, 13, 50808], "temperature": 0.0, "avg_logprob": -0.22773553810867608, "compression_ratio": 1.636, "no_speech_prob": 5.5621512728976086e-05}, {"id": 626, "seek": 309122, "start": 3100.14, "end": 3105.62, "text": " So it's not going to care about the background and the background probably isn't going to have", "tokens": [50810, 407, 309, 311, 406, 516, 281, 1127, 466, 264, 3678, 293, 264, 3678, 1391, 1943, 380, 516, 281, 362, 51084], "temperature": 0.0, "avg_logprob": -0.22773553810867608, "compression_ratio": 1.636, "no_speech_prob": 5.5621512728976086e-05}, {"id": 627, "seek": 309122, "start": 3105.62, "end": 3110.5, "text": " much in the way of features at all, which is why it hasn't really changed the background.", "tokens": [51084, 709, 294, 264, 636, 295, 4122, 412, 439, 11, 597, 307, 983, 309, 6132, 380, 534, 3105, 264, 3678, 13, 51328], "temperature": 0.0, "avg_logprob": -0.22773553810867608, "compression_ratio": 1.636, "no_speech_prob": 5.5621512728976086e-05}, {"id": 628, "seek": 309122, "start": 3112.22, "end": 3114.02, "text": " Yeah, exactly.", "tokens": [51414, 865, 11, 2293, 13, 51504], "temperature": 0.0, "avg_logprob": -0.22773553810867608, "compression_ratio": 1.636, "no_speech_prob": 5.5621512728976086e-05}, {"id": 629, "seek": 309122, "start": 3114.02, "end": 3118.14, "text": " And so, I mean, this is kind of interesting to see how little it looks like the image while at", "tokens": [51504, 400, 370, 11, 286, 914, 11, 341, 307, 733, 295, 1880, 281, 536, 577, 707, 309, 1542, 411, 264, 3256, 1339, 412, 51710], "temperature": 0.0, "avg_logprob": -0.22773553810867608, "compression_ratio": 1.636, "no_speech_prob": 5.5621512728976086e-05}, {"id": 630, "seek": 311814, "start": 3118.14, "end": 3120.9, "text": " same time still being like, if you squint, you can recognize it.", "tokens": [50364, 912, 565, 920, 885, 411, 11, 498, 291, 2339, 686, 11, 291, 393, 5521, 309, 13, 50502], "temperature": 0.0, "avg_logprob": -0.26197017156160796, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.010817967355251312}, {"id": 631, "seek": 311814, "start": 3121.58, "end": 3126.46, "text": " But we can also try passing in earlier layers, right?", "tokens": [50536, 583, 321, 393, 611, 853, 8437, 294, 3071, 7914, 11, 558, 30, 50780], "temperature": 0.0, "avg_logprob": -0.26197017156160796, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.010817967355251312}, {"id": 632, "seek": 311814, "start": 3126.46, "end": 3130.18, "text": " And comparing, comparing on those earlier layers and see that we get a completely different", "tokens": [50780, 400, 15763, 11, 15763, 322, 729, 3071, 7914, 293, 536, 300, 321, 483, 257, 2584, 819, 50966], "temperature": 0.0, "avg_logprob": -0.26197017156160796, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.010817967355251312}, {"id": 633, "seek": 311814, "start": 3130.18, "end": 3136.9, "text": " result because now we're optimizing to some image that is a lot closer to the original.", "tokens": [50966, 1874, 570, 586, 321, 434, 40425, 281, 512, 3256, 300, 307, 257, 688, 4966, 281, 264, 3380, 13, 51302], "temperature": 0.0, "avg_logprob": -0.26197017156160796, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.010817967355251312}, {"id": 634, "seek": 311814, "start": 3137.3799999999997, "end": 3139.02, "text": " It still doesn't look exactly the same.", "tokens": [51326, 467, 920, 1177, 380, 574, 2293, 264, 912, 13, 51408], "temperature": 0.0, "avg_logprob": -0.26197017156160796, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.010817967355251312}, {"id": 635, "seek": 311814, "start": 3139.42, "end": 3143.2599999999998, "text": " And so there's a few things that I thought were worth noting, just potentially of interest.", "tokens": [51428, 400, 370, 456, 311, 257, 1326, 721, 300, 286, 1194, 645, 3163, 26801, 11, 445, 7263, 295, 1179, 13, 51620], "temperature": 0.0, "avg_logprob": -0.26197017156160796, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.010817967355251312}, {"id": 636, "seek": 314326, "start": 3143.6600000000003, "end": 3150.1400000000003, "text": " One is that we're looking into these early layers, which might mean, for example, that if", "tokens": [50384, 1485, 307, 300, 321, 434, 1237, 666, 613, 2440, 7914, 11, 597, 1062, 914, 11, 337, 1365, 11, 300, 498, 50708], "temperature": 0.0, "avg_logprob": -0.22009615935096444, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0022517195902764797}, {"id": 637, "seek": 314326, "start": 3150.1400000000003, "end": 3153.3, "text": " you're looking at the very early layers, you're missing out on some kinds of features.", "tokens": [50708, 291, 434, 1237, 412, 264, 588, 2440, 7914, 11, 291, 434, 5361, 484, 322, 512, 3685, 295, 4122, 13, 50866], "temperature": 0.0, "avg_logprob": -0.22009615935096444, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0022517195902764797}, {"id": 638, "seek": 314326, "start": 3153.3, "end": 3159.5400000000004, "text": " That was one of my guesses as to why this didn't have as dark a dark as the input image.", "tokens": [50866, 663, 390, 472, 295, 452, 42703, 382, 281, 983, 341, 994, 380, 362, 382, 2877, 257, 2877, 382, 264, 4846, 3256, 13, 51178], "temperature": 0.0, "avg_logprob": -0.22009615935096444, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0022517195902764797}, {"id": 639, "seek": 314326, "start": 3160.2200000000003, "end": 3164.0600000000004, "text": " And then also we still have this thing where we might be going out of bounds to get the same", "tokens": [51212, 400, 550, 611, 321, 920, 362, 341, 551, 689, 321, 1062, 312, 516, 484, 295, 29905, 281, 483, 264, 912, 51404], "temperature": 0.0, "avg_logprob": -0.22009615935096444, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0022517195902764797}, {"id": 640, "seek": 314326, "start": 3164.0600000000004, "end": 3164.78, "text": " kinds of features.", "tokens": [51404, 3685, 295, 4122, 13, 51440], "temperature": 0.0, "avg_logprob": -0.22009615935096444, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0022517195902764797}, {"id": 641, "seek": 314326, "start": 3164.78, "end": 3169.46, "text": " So, yeah, you can see how by looking at really deep layers, we really don't care about the", "tokens": [51440, 407, 11, 1338, 11, 291, 393, 536, 577, 538, 1237, 412, 534, 2452, 7914, 11, 321, 534, 500, 380, 1127, 466, 264, 51674], "temperature": 0.0, "avg_logprob": -0.22009615935096444, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0022517195902764797}, {"id": 642, "seek": 314326, "start": 3169.46, "end": 3170.82, "text": " color or texture at all.", "tokens": [51674, 2017, 420, 8091, 412, 439, 13, 51742], "temperature": 0.0, "avg_logprob": -0.22009615935096444, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0022517195902764797}, {"id": 643, "seek": 317082, "start": 3170.82, "end": 3174.26, "text": " We're just getting like sunglasses bits and nosy bits there.", "tokens": [50364, 492, 434, 445, 1242, 411, 28675, 9239, 293, 3269, 88, 9239, 456, 13, 50536], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 644, "seek": 317082, "start": 3174.98, "end": 3180.1400000000003, "text": " By looking at the earlier layers, we have much more rigid adherence to the sort of lower", "tokens": [50572, 3146, 1237, 412, 264, 3071, 7914, 11, 321, 362, 709, 544, 22195, 30106, 655, 281, 264, 1333, 295, 3126, 50830], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 645, "seek": 317082, "start": 3180.1400000000003, "end": 3181.26, "text": " level features as well.", "tokens": [50830, 1496, 4122, 382, 731, 13, 50886], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 646, "seek": 317082, "start": 3182.1000000000004, "end": 3182.86, "text": " And so this is nice.", "tokens": [50928, 400, 370, 341, 307, 1481, 13, 50966], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 647, "seek": 317082, "start": 3182.86, "end": 3185.3, "text": " It gives you a very tunable way to compare two images.", "tokens": [50966, 467, 2709, 291, 257, 588, 4267, 712, 636, 281, 6794, 732, 5267, 13, 51088], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 648, "seek": 317082, "start": 3185.3, "end": 3187.94, "text": " You can say, do I care that they match exactly on pixels?", "tokens": [51088, 509, 393, 584, 11, 360, 286, 1127, 300, 436, 2995, 2293, 322, 18668, 30, 51220], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 649, "seek": 317082, "start": 3187.98, "end": 3189.26, "text": " Then I could use mean squared error.", "tokens": [51222, 1396, 286, 727, 764, 914, 8889, 6713, 13, 51286], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 650, "seek": 317082, "start": 3190.06, "end": 3192.94, "text": " But do I care quite a lot about the exact match?", "tokens": [51326, 583, 360, 286, 1127, 1596, 257, 688, 466, 264, 1900, 2995, 30, 51470], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 651, "seek": 317082, "start": 3192.94, "end": 3194.7000000000003, "text": " Then I can use maybe some early layers.", "tokens": [51470, 1396, 286, 393, 764, 1310, 512, 2440, 7914, 13, 51558], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 652, "seek": 317082, "start": 3195.38, "end": 3197.7400000000002, "text": " But do I only care about like the overall semantics?", "tokens": [51592, 583, 360, 286, 787, 1127, 466, 411, 264, 4787, 4361, 45298, 30, 51710], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 653, "seek": 317082, "start": 3198.06, "end": 3199.98, "text": " In that case, I can go to some deeper layers.", "tokens": [51726, 682, 300, 1389, 11, 286, 393, 352, 281, 512, 7731, 7914, 13, 51822], "temperature": 0.0, "avg_logprob": -0.2387804822856877, "compression_ratio": 1.7106109324758842, "no_speech_prob": 0.015423968434333801}, {"id": 654, "seek": 319998, "start": 3200.02, "end": 3201.14, "text": " And you can experiment with.", "tokens": [50366, 400, 291, 393, 5120, 365, 13, 50422], "temperature": 0.0, "avg_logprob": -0.2912012631775903, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0011878780787810683}, {"id": 655, "seek": 319998, "start": 3201.7400000000002, "end": 3206.1, "text": " If I remember correctly, this is also something like the kind of technique that Zyler and", "tokens": [50452, 759, 286, 1604, 8944, 11, 341, 307, 611, 746, 411, 264, 733, 295, 6532, 300, 1176, 88, 1918, 293, 50670], "temperature": 0.0, "avg_logprob": -0.2912012631775903, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0011878780787810683}, {"id": 656, "seek": 319998, "start": 3206.1, "end": 3212.3, "text": " Fergus and the distilled up pub papers used to like just identify like what do filters look", "tokens": [50670, 36790, 293, 264, 1483, 6261, 493, 1535, 10577, 1143, 281, 411, 445, 5876, 411, 437, 360, 15995, 574, 50980], "temperature": 0.0, "avg_logprob": -0.2912012631775903, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0011878780787810683}, {"id": 657, "seek": 319998, "start": 3212.3, "end": 3217.7, "text": " at, which is like you can optimize an image to try and maximize a particular filter.", "tokens": [50980, 412, 11, 597, 307, 411, 291, 393, 19719, 364, 3256, 281, 853, 293, 19874, 257, 1729, 6608, 13, 51250], "temperature": 0.0, "avg_logprob": -0.2912012631775903, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0011878780787810683}, {"id": 658, "seek": 319998, "start": 3217.7400000000002, "end": 3220.82, "text": " For example, that would be a similar loss function to the one you've built here.", "tokens": [51252, 1171, 1365, 11, 300, 576, 312, 257, 2531, 4470, 2445, 281, 264, 472, 291, 600, 3094, 510, 13, 51406], "temperature": 0.0, "avg_logprob": -0.2912012631775903, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0011878780787810683}, {"id": 659, "seek": 319998, "start": 3220.82, "end": 3224.18, "text": " And that would show you what they're looking at.", "tokens": [51406, 400, 300, 576, 855, 291, 437, 436, 434, 1237, 412, 13, 51574], "temperature": 0.0, "avg_logprob": -0.2912012631775903, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0011878780787810683}, {"id": 660, "seek": 319998, "start": 3225.34, "end": 3225.62, "text": " Yeah.", "tokens": [51632, 865, 13, 51646], "temperature": 0.0, "avg_logprob": -0.2912012631775903, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0011878780787810683}, {"id": 661, "seek": 319998, "start": 3225.62, "end": 3227.58, "text": " And that would be a really fun little project, actually.", "tokens": [51646, 400, 300, 576, 312, 257, 534, 1019, 707, 1716, 11, 767, 13, 51744], "temperature": 0.0, "avg_logprob": -0.2912012631775903, "compression_ratio": 1.6712328767123288, "no_speech_prob": 0.0011878780787810683}, {"id": 662, "seek": 322758, "start": 3227.58, "end": 3232.74, "text": " So do it where you calculate these feature maps and then just pick one of those 512", "tokens": [50364, 407, 360, 309, 689, 291, 8873, 613, 4111, 11317, 293, 550, 445, 1888, 472, 295, 729, 1025, 4762, 50622], "temperature": 0.0, "avg_logprob": -0.26382075299273483, "compression_ratio": 1.6954732510288066, "no_speech_prob": 0.011507207527756691}, {"id": 663, "seek": 322758, "start": 3233.62, "end": 3239.22, "text": " features and optimize the image to maximize that activation.", "tokens": [50666, 4122, 293, 19719, 264, 3256, 281, 19874, 300, 24433, 13, 50946], "temperature": 0.0, "avg_logprob": -0.26382075299273483, "compression_ratio": 1.6954732510288066, "no_speech_prob": 0.011507207527756691}, {"id": 664, "seek": 322758, "start": 3240.42, "end": 3244.62, "text": " By default, you might get quite a noisy, weird result, like almost an adversarial input.", "tokens": [51006, 3146, 7576, 11, 291, 1062, 483, 1596, 257, 24518, 11, 3657, 1874, 11, 411, 1920, 364, 17641, 44745, 4846, 13, 51216], "temperature": 0.0, "avg_logprob": -0.26382075299273483, "compression_ratio": 1.6954732510288066, "no_speech_prob": 0.011507207527756691}, {"id": 665, "seek": 322758, "start": 3244.98, "end": 3250.2999999999997, "text": " And so what these feature visualization people do is they add things like augmentations so", "tokens": [51234, 400, 370, 437, 613, 4111, 25801, 561, 360, 307, 436, 909, 721, 411, 29919, 763, 370, 51500], "temperature": 0.0, "avg_logprob": -0.26382075299273483, "compression_ratio": 1.6954732510288066, "no_speech_prob": 0.011507207527756691}, {"id": 666, "seek": 322758, "start": 3250.2999999999997, "end": 3254.86, "text": " that you're optimizing an image that even under some augmentations still activates that", "tokens": [51500, 300, 291, 434, 40425, 364, 3256, 300, 754, 833, 512, 29919, 763, 920, 43869, 300, 51728], "temperature": 0.0, "avg_logprob": -0.26382075299273483, "compression_ratio": 1.6954732510288066, "no_speech_prob": 0.011507207527756691}, {"id": 667, "seek": 325486, "start": 3255.46, "end": 3258.26, "text": " feature. But yeah, that might be a good one to play with.", "tokens": [50394, 4111, 13, 583, 1338, 11, 300, 1062, 312, 257, 665, 472, 281, 862, 365, 13, 50534], "temperature": 0.0, "avg_logprob": -0.22352252900600433, "compression_ratio": 1.6789297658862876, "no_speech_prob": 0.001284276251681149}, {"id": 668, "seek": 325486, "start": 3259.9, "end": 3262.3, "text": " Cool. OK, so we have a lot of our infrastructure in place.", "tokens": [50616, 8561, 13, 2264, 11, 370, 321, 362, 257, 688, 295, 527, 6896, 294, 1081, 13, 50736], "temperature": 0.0, "avg_logprob": -0.22352252900600433, "compression_ratio": 1.6789297658862876, "no_speech_prob": 0.001284276251681149}, {"id": 669, "seek": 325486, "start": 3262.3, "end": 3264.1, "text": " We know how to optimize an image.", "tokens": [50736, 492, 458, 577, 281, 19719, 364, 3256, 13, 50826], "temperature": 0.0, "avg_logprob": -0.22352252900600433, "compression_ratio": 1.6789297658862876, "no_speech_prob": 0.001284276251681149}, {"id": 670, "seek": 325486, "start": 3264.46, "end": 3266.6200000000003, "text": " We know how to extract features from this neural network.", "tokens": [50844, 492, 458, 577, 281, 8947, 4122, 490, 341, 18161, 3209, 13, 50952], "temperature": 0.0, "avg_logprob": -0.22352252900600433, "compression_ratio": 1.6789297658862876, "no_speech_prob": 0.001284276251681149}, {"id": 671, "seek": 325486, "start": 3266.6200000000003, "end": 3271.34, "text": " And we're saying this is great for comparing at these different kind of types of feature", "tokens": [50952, 400, 321, 434, 1566, 341, 307, 869, 337, 15763, 412, 613, 819, 733, 295, 3467, 295, 4111, 51188], "temperature": 0.0, "avg_logprob": -0.22352252900600433, "compression_ratio": 1.6789297658862876, "no_speech_prob": 0.001284276251681149}, {"id": 672, "seek": 325486, "start": 3271.6200000000003, "end": 3273.06, "text": " how similar two images are.", "tokens": [51202, 577, 2531, 732, 5267, 366, 13, 51274], "temperature": 0.0, "avg_logprob": -0.22352252900600433, "compression_ratio": 1.6789297658862876, "no_speech_prob": 0.001284276251681149}, {"id": 673, "seek": 325486, "start": 3273.7000000000003, "end": 3279.34, "text": " The final piece that we need for our full style transfer artistic application is to say", "tokens": [51306, 440, 2572, 2522, 300, 321, 643, 337, 527, 1577, 3758, 5003, 17090, 3861, 307, 281, 584, 51588], "temperature": 0.0, "avg_logprob": -0.22352252900600433, "compression_ratio": 1.6789297658862876, "no_speech_prob": 0.001284276251681149}, {"id": 674, "seek": 325486, "start": 3279.34, "end": 3283.46, "text": " I'd like to keep the structure of this image, but I'd like to have the style come from a", "tokens": [51588, 286, 1116, 411, 281, 1066, 264, 3877, 295, 341, 3256, 11, 457, 286, 1116, 411, 281, 362, 264, 3758, 808, 490, 257, 51794], "temperature": 0.0, "avg_logprob": -0.22352252900600433, "compression_ratio": 1.6789297658862876, "no_speech_prob": 0.001284276251681149}, {"id": 675, "seek": 328346, "start": 3283.46, "end": 3286.3, "text": " different image. And you might think, oh, well, that's easy.", "tokens": [50364, 819, 3256, 13, 400, 291, 1062, 519, 11, 1954, 11, 731, 11, 300, 311, 1858, 13, 50506], "temperature": 0.0, "avg_logprob": -0.2086709961855322, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.025175919756293297}, {"id": 676, "seek": 328346, "start": 3286.3, "end": 3288.7, "text": " We just look at the early layers like you've shown us.", "tokens": [50506, 492, 445, 574, 412, 264, 2440, 7914, 411, 291, 600, 4898, 505, 13, 50626], "temperature": 0.0, "avg_logprob": -0.2086709961855322, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.025175919756293297}, {"id": 677, "seek": 328346, "start": 3289.42, "end": 3293.62, "text": " But there's a problem, which is that these feature maps by default, we feed in our image", "tokens": [50662, 583, 456, 311, 257, 1154, 11, 597, 307, 300, 613, 4111, 11317, 538, 7576, 11, 321, 3154, 294, 527, 3256, 50872], "temperature": 0.0, "avg_logprob": -0.2086709961855322, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.025175919756293297}, {"id": 678, "seek": 328346, "start": 3293.62, "end": 3295.06, "text": " and we get these feature maps.", "tokens": [50872, 293, 321, 483, 613, 4111, 11317, 13, 50944], "temperature": 0.0, "avg_logprob": -0.2086709961855322, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.025175919756293297}, {"id": 679, "seek": 328346, "start": 3296.42, "end": 3298.5, "text": " They have a spatial component, right?", "tokens": [51012, 814, 362, 257, 23598, 6542, 11, 558, 30, 51116], "temperature": 0.0, "avg_logprob": -0.2086709961855322, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.025175919756293297}, {"id": 680, "seek": 328346, "start": 3298.5, "end": 3303.54, "text": " We said we had a 32 by 32 by 512 feature map out.", "tokens": [51116, 492, 848, 321, 632, 257, 8858, 538, 8858, 538, 1025, 4762, 4111, 4471, 484, 13, 51368], "temperature": 0.0, "avg_logprob": -0.2086709961855322, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.025175919756293297}, {"id": 681, "seek": 328346, "start": 3303.54, "end": 3309.26, "text": " And each of those locations in that 32 by 32 grid are going to correspond to some part of", "tokens": [51368, 400, 1184, 295, 729, 9253, 294, 300, 8858, 538, 8858, 10748, 366, 516, 281, 6805, 281, 512, 644, 295, 51654], "temperature": 0.0, "avg_logprob": -0.2086709961855322, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.025175919756293297}, {"id": 682, "seek": 328346, "start": 3309.26, "end": 3313.18, "text": " the input image. And so if we just said, let's do mean squared error.", "tokens": [51654, 264, 4846, 3256, 13, 400, 370, 498, 321, 445, 848, 11, 718, 311, 360, 914, 8889, 6713, 13, 51850], "temperature": 0.0, "avg_logprob": -0.2086709961855322, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.025175919756293297}, {"id": 683, "seek": 331346, "start": 3313.5, "end": 3317.86, "text": " For the activations from some early layers, what we'd be saying is I want the same types of", "tokens": [50366, 1171, 264, 2430, 763, 490, 512, 2440, 7914, 11, 437, 321, 1116, 312, 1566, 307, 286, 528, 264, 912, 3467, 295, 50584], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 684, "seek": 331346, "start": 3317.86, "end": 3320.2200000000003, "text": " feature, like the same style, the same textures.", "tokens": [50584, 4111, 11, 411, 264, 912, 3758, 11, 264, 912, 24501, 13, 50702], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 685, "seek": 331346, "start": 3321.02, "end": 3322.58, "text": " And I want them in the same location.", "tokens": [50742, 400, 286, 528, 552, 294, 264, 912, 4914, 13, 50820], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 686, "seek": 331346, "start": 3323.42, "end": 3326.58, "text": " Right. And so we can't just get like Van Gogh brush strokes.", "tokens": [50862, 1779, 13, 400, 370, 321, 393, 380, 445, 483, 411, 8979, 39690, 71, 5287, 24493, 13, 51020], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 687, "seek": 331346, "start": 3326.86, "end": 3330.02, "text": " We're going to try and have the same colors in the same place and the same textures in the", "tokens": [51034, 492, 434, 516, 281, 853, 293, 362, 264, 912, 4577, 294, 264, 912, 1081, 293, 264, 912, 24501, 294, 264, 51192], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 688, "seek": 331346, "start": 3330.02, "end": 3333.62, "text": " same place. And so we're going to get something that just matches our image.", "tokens": [51192, 912, 1081, 13, 400, 370, 321, 434, 516, 281, 483, 746, 300, 445, 10676, 527, 3256, 13, 51372], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 689, "seek": 331346, "start": 3334.02, "end": 3337.1, "text": " What we'd like is something that has the same colors and textures, but doesn't.", "tokens": [51392, 708, 321, 1116, 411, 307, 746, 300, 575, 264, 912, 4577, 293, 24501, 11, 457, 1177, 380, 13, 51546], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 690, "seek": 331346, "start": 3337.34, "end": 3338.7400000000002, "text": " But there might be in different parts of the image.", "tokens": [51558, 583, 456, 1062, 312, 294, 819, 3166, 295, 264, 3256, 13, 51628], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 691, "seek": 331346, "start": 3339.02, "end": 3341.78, "text": " So we want to get rid of this spatial aspect.", "tokens": [51642, 407, 321, 528, 281, 483, 3973, 295, 341, 23598, 4171, 13, 51780], "temperature": 0.0, "avg_logprob": -0.2822863343474153, "compression_ratio": 1.9965870307167235, "no_speech_prob": 0.018832307308912277}, {"id": 692, "seek": 334178, "start": 3342.6600000000003, "end": 3348.5400000000004, "text": " Just to clarify, when we're saying to it, for example, give it to us in the style of Van Gogh's", "tokens": [50408, 1449, 281, 17594, 11, 562, 321, 434, 1566, 281, 309, 11, 337, 1365, 11, 976, 309, 281, 505, 294, 264, 3758, 295, 8979, 39690, 71, 311, 50702], "temperature": 0.0, "avg_logprob": -0.2812509000971076, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.0004878347972407937}, {"id": 693, "seek": 334178, "start": 3348.5400000000004, "end": 3355.1000000000004, "text": " Starry Night, we're not saying in this part of the image there should be something with this", "tokens": [50702, 5705, 627, 10190, 11, 321, 434, 406, 1566, 294, 341, 644, 295, 264, 3256, 456, 820, 312, 746, 365, 341, 51030], "temperature": 0.0, "avg_logprob": -0.2812509000971076, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.0004878347972407937}, {"id": 694, "seek": 334178, "start": 3355.1000000000004, "end": 3359.5400000000004, "text": " texture. But we're saying that the kinds of textures that are used anywhere in that image should", "tokens": [51030, 8091, 13, 583, 321, 434, 1566, 300, 264, 3685, 295, 24501, 300, 366, 1143, 4992, 294, 300, 3256, 820, 51252], "temperature": 0.0, "avg_logprob": -0.2812509000971076, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.0004878347972407937}, {"id": 695, "seek": 334178, "start": 3359.5400000000004, "end": 3364.34, "text": " also appear in our version, but not necessarily in the same place.", "tokens": [51252, 611, 4204, 294, 527, 3037, 11, 457, 406, 4725, 294, 264, 912, 1081, 13, 51492], "temperature": 0.0, "avg_logprob": -0.2812509000971076, "compression_ratio": 1.614678899082569, "no_speech_prob": 0.0004878347972407937}, {"id": 696, "seek": 336434, "start": 3365.34, "end": 3371.82, "text": " Exactly. And so the solution that Zylor and Thurgisson proposed is this thing called a", "tokens": [50414, 7587, 13, 400, 370, 264, 3827, 300, 1176, 88, 752, 81, 293, 334, 374, 70, 271, 3015, 10348, 307, 341, 551, 1219, 257, 50738], "temperature": 0.0, "avg_logprob": -0.324903875831666, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.041455257683992386}, {"id": 697, "seek": 336434, "start": 3371.82, "end": 3372.82, "text": " Grammatrix.", "tokens": [50738, 22130, 15677, 6579, 13, 50788], "temperature": 0.0, "avg_logprob": -0.324903875831666, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.041455257683992386}, {"id": 698, "seek": 336434, "start": 3373.1800000000003, "end": 3377.38, "text": " So what we want is some measure of what kinds of styles are present without worrying about", "tokens": [50806, 407, 437, 321, 528, 307, 512, 3481, 295, 437, 3685, 295, 13273, 366, 1974, 1553, 18788, 466, 51016], "temperature": 0.0, "avg_logprob": -0.324903875831666, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.041455257683992386}, {"id": 699, "seek": 336434, "start": 3377.38, "end": 3378.38, "text": " where they are.", "tokens": [51016, 689, 436, 366, 13, 51066], "temperature": 0.0, "avg_logprob": -0.324903875831666, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.041455257683992386}, {"id": 700, "seek": 336434, "start": 3379.1400000000003, "end": 3383.3, "text": " And so there's always a trouble trying to represent more than two dimensional things on a", "tokens": [51104, 400, 370, 456, 311, 1009, 257, 5253, 1382, 281, 2906, 544, 813, 732, 18795, 721, 322, 257, 51312], "temperature": 0.0, "avg_logprob": -0.324903875831666, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.041455257683992386}, {"id": 701, "seek": 336434, "start": 3383.3, "end": 3384.3, "text": " 2D grid.", "tokens": [51312, 568, 35, 10748, 13, 51362], "temperature": 0.0, "avg_logprob": -0.324903875831666, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.041455257683992386}, {"id": 702, "seek": 336434, "start": 3384.7000000000003, "end": 3388.6600000000003, "text": " But what I've done here is I've made our feature map, right, where we have our height and our", "tokens": [51382, 583, 437, 286, 600, 1096, 510, 307, 286, 600, 1027, 527, 4111, 4471, 11, 558, 11, 689, 321, 362, 527, 6681, 293, 527, 51580], "temperature": 0.0, "avg_logprob": -0.324903875831666, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.041455257683992386}, {"id": 703, "seek": 336434, "start": 3388.6600000000003, "end": 3392.06, "text": " width that might be 32 by 32 and some number of features.", "tokens": [51580, 11402, 300, 1062, 312, 8858, 538, 8858, 293, 512, 1230, 295, 4122, 13, 51750], "temperature": 0.0, "avg_logprob": -0.324903875831666, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.041455257683992386}, {"id": 704, "seek": 339206, "start": 3392.46, "end": 3396.86, "text": " But instead of having those be like a third dimension, I've just represented those features as", "tokens": [50384, 583, 2602, 295, 1419, 729, 312, 411, 257, 2636, 10139, 11, 286, 600, 445, 10379, 729, 4122, 382, 50604], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 705, "seek": 339206, "start": 3396.86, "end": 3397.98, "text": " these little colored dots.", "tokens": [50604, 613, 707, 14332, 15026, 13, 50660], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 706, "seek": 339206, "start": 3399.02, "end": 3403.58, "text": " And so what we're going to do with the Grammatrix is we're going to flatten out our spatial", "tokens": [50712, 400, 370, 437, 321, 434, 516, 281, 360, 365, 264, 22130, 15677, 6579, 307, 321, 434, 516, 281, 24183, 484, 527, 23598, 50940], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 707, "seek": 339206, "start": 3403.58, "end": 3409.22, "text": " dimension. So we're going to reshape this so that we have the width times the height.", "tokens": [50940, 10139, 13, 407, 321, 434, 516, 281, 725, 42406, 341, 370, 300, 321, 362, 264, 11402, 1413, 264, 6681, 13, 51222], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 708, "seek": 339206, "start": 3409.22, "end": 3413.34, "text": " So that like the spatial location on one axis and the feature dimension on the other.", "tokens": [51222, 407, 300, 411, 264, 23598, 4914, 322, 472, 10298, 293, 264, 4111, 10139, 322, 264, 661, 13, 51428], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 709, "seek": 339206, "start": 3413.98, "end": 3417.06, "text": " And so each of these rows is like this is the location here.", "tokens": [51460, 400, 370, 1184, 295, 613, 13241, 307, 411, 341, 307, 264, 4914, 510, 13, 51614], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 710, "seek": 339206, "start": 3417.38, "end": 3418.62, "text": " There's no yellow dot.", "tokens": [51630, 821, 311, 572, 5566, 5893, 13, 51692], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 711, "seek": 339206, "start": 3418.66, "end": 3419.66, "text": " So we get a zero.", "tokens": [51694, 407, 321, 483, 257, 4018, 13, 51744], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 712, "seek": 339206, "start": 3419.86, "end": 3420.86, "text": " There's no green.", "tokens": [51754, 821, 311, 572, 3092, 13, 51804], "temperature": 0.0, "avg_logprob": -0.25516943106973977, "compression_ratio": 1.8566176470588236, "no_speech_prob": 0.019417906180024147}, {"id": 713, "seek": 342086, "start": 3421.7400000000002, "end": 3424.34, "text": " So we get a zero. There is a red and a blue.", "tokens": [50408, 407, 321, 483, 257, 4018, 13, 821, 307, 257, 2182, 293, 257, 3344, 13, 50538], "temperature": 0.0, "avg_logprob": -0.26441259384155275, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.0005192930111661553}, {"id": 714, "seek": 342086, "start": 3424.34, "end": 3428.9, "text": " So we get ones. So we've kind of flattened out this feature map into a 2D thing.", "tokens": [50538, 407, 321, 483, 2306, 13, 407, 321, 600, 733, 295, 24183, 292, 484, 341, 4111, 4471, 666, 257, 568, 35, 551, 13, 50766], "temperature": 0.0, "avg_logprob": -0.26441259384155275, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.0005192930111661553}, {"id": 715, "seek": 342086, "start": 3429.46, "end": 3434.6600000000003, "text": " And then instead of caring about the spatial dimension at all, all we care about is which", "tokens": [50794, 400, 550, 2602, 295, 15365, 466, 264, 23598, 10139, 412, 439, 11, 439, 321, 1127, 466, 307, 597, 51054], "temperature": 0.0, "avg_logprob": -0.26441259384155275, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.0005192930111661553}, {"id": 716, "seek": 342086, "start": 3434.6600000000003, "end": 3439.34, "text": " features do we have in general, which types of features and do they occur with each other.", "tokens": [51054, 4122, 360, 321, 362, 294, 2674, 11, 597, 3467, 295, 4122, 293, 360, 436, 5160, 365, 1184, 661, 13, 51288], "temperature": 0.0, "avg_logprob": -0.26441259384155275, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.0005192930111661553}, {"id": 717, "seek": 342086, "start": 3440.2200000000003, "end": 3446.34, "text": " And so we're going to get effectively the dot products of this row with itself.", "tokens": [51332, 400, 370, 321, 434, 516, 281, 483, 8659, 264, 5893, 3383, 295, 341, 5386, 365, 2564, 13, 51638], "temperature": 0.0, "avg_logprob": -0.26441259384155275, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.0005192930111661553}, {"id": 718, "seek": 342086, "start": 3447.6600000000003, "end": 3449.7000000000003, "text": " And then this row with the next row and this row with the next row.", "tokens": [51704, 400, 550, 341, 5386, 365, 264, 958, 5386, 293, 341, 5386, 365, 264, 958, 5386, 13, 51806], "temperature": 0.0, "avg_logprob": -0.26441259384155275, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.0005192930111661553}, {"id": 719, "seek": 344970, "start": 3450.2599999999998, "end": 3456.02, "text": " We're saying like for these feature vectors, how correlated are they with each other?", "tokens": [50392, 492, 434, 1566, 411, 337, 613, 4111, 18875, 11, 577, 38574, 366, 436, 365, 1184, 661, 30, 50680], "temperature": 0.0, "avg_logprob": -0.450833740234375, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.0002959516423288733}, {"id": 720, "seek": 344970, "start": 3456.8599999999997, "end": 3458.58, "text": " Right. And so we'll see this in code just now.", "tokens": [50722, 1779, 13, 400, 370, 321, 603, 536, 341, 294, 3089, 445, 586, 13, 50808], "temperature": 0.0, "avg_logprob": -0.450833740234375, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.0002959516423288733}, {"id": 721, "seek": 344970, "start": 3461.3399999999997, "end": 3468.66, "text": " I think you might have said, I might have misheard you, but I just want to make sure I got the citation here.", "tokens": [50946, 286, 519, 291, 1062, 362, 848, 11, 286, 1062, 362, 3346, 42915, 291, 11, 457, 286, 445, 528, 281, 652, 988, 286, 658, 264, 45590, 510, 13, 51312], "temperature": 0.0, "avg_logprob": -0.450833740234375, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.0002959516423288733}, {"id": 722, "seek": 344970, "start": 3468.66, "end": 3474.3399999999997, "text": " Right. So this idea came from, I don't know if it was first invented in the Gattis et al.", "tokens": [51312, 1779, 13, 407, 341, 1558, 1361, 490, 11, 286, 500, 380, 458, 498, 309, 390, 700, 14479, 294, 264, 460, 1591, 271, 1030, 419, 13, 51596], "temperature": 0.0, "avg_logprob": -0.450833740234375, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.0002959516423288733}, {"id": 723, "seek": 344970, "start": 3475.02, "end": 3475.5, "text": " paper.", "tokens": [51630, 3035, 13, 51654], "temperature": 0.0, "avg_logprob": -0.450833740234375, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.0002959516423288733}, {"id": 724, "seek": 344970, "start": 3475.7799999999997, "end": 3476.1, "text": " Yes.", "tokens": [51668, 1079, 13, 51684], "temperature": 0.0, "avg_logprob": -0.450833740234375, "compression_ratio": 1.5221238938053097, "no_speech_prob": 0.0002959516423288733}, {"id": 725, "seek": 347610, "start": 3476.7, "end": 3476.98, "text": " Sorry.", "tokens": [50394, 4919, 13, 50408], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 726, "seek": 347610, "start": 3476.98, "end": 3478.98, "text": " Neural algorithm of artistic style.", "tokens": [50408, 1734, 1807, 9284, 295, 17090, 3758, 13, 50508], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 727, "seek": 347610, "start": 3480.2599999999998, "end": 3480.5, "text": " Yeah.", "tokens": [50572, 865, 13, 50584], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 728, "seek": 347610, "start": 3481.3399999999997, "end": 3481.58, "text": " Yeah.", "tokens": [50626, 865, 13, 50638], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 729, "seek": 347610, "start": 3481.8199999999997, "end": 3484.18, "text": " I meant Gattis, that's the style transfer one.", "tokens": [50650, 286, 4140, 460, 1591, 271, 11, 300, 311, 264, 3758, 5003, 472, 13, 50768], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 730, "seek": 347610, "start": 3484.2999999999997, "end": 3486.14, "text": " Cider and Ferguson is the feature visualization one.", "tokens": [50774, 383, 1438, 293, 40823, 307, 264, 4111, 25801, 472, 13, 50866], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 731, "seek": 347610, "start": 3486.62, "end": 3486.7799999999997, "text": " Yeah.", "tokens": [50890, 865, 13, 50898], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 732, "seek": 347610, "start": 3486.7799999999997, "end": 3487.62, "text": " Sorry, I got that switched.", "tokens": [50898, 4919, 11, 286, 658, 300, 16858, 13, 50940], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 733, "seek": 347610, "start": 3487.66, "end": 3487.98, "text": " Thanks.", "tokens": [50942, 2561, 13, 50958], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 734, "seek": 347610, "start": 3487.98, "end": 3488.46, "text": " Thanks, Jeremy.", "tokens": [50958, 2561, 11, 17809, 13, 50982], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 735, "seek": 347610, "start": 3489.38, "end": 3489.62, "text": " Okay.", "tokens": [51028, 1033, 13, 51040], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 736, "seek": 347610, "start": 3489.7, "end": 3494.66, "text": " So we are ending up with this kind of like this Gram matrix, this correlation of features.", "tokens": [51044, 407, 321, 366, 8121, 493, 365, 341, 733, 295, 411, 341, 22130, 8141, 11, 341, 20009, 295, 4122, 13, 51292], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 737, "seek": 347610, "start": 3495.14, "end": 3501.58, "text": " And the way you can read this in this example is to say, okay, there are seven reds, right?", "tokens": [51316, 400, 264, 636, 291, 393, 1401, 341, 294, 341, 1365, 307, 281, 584, 11, 1392, 11, 456, 366, 3407, 2182, 82, 11, 558, 30, 51638], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 738, "seek": 347610, "start": 3501.58, "end": 3502.94, "text": " Red with red.", "tokens": [51638, 4477, 365, 2182, 13, 51706], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 739, "seek": 347610, "start": 3502.98, "end": 3504.1, "text": " There's seven in total.", "tokens": [51708, 821, 311, 3407, 294, 3217, 13, 51764], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 740, "seek": 347610, "start": 3504.22, "end": 3505.8199999999997, "text": " And if you go and count them, there's seven there.", "tokens": [51770, 400, 498, 291, 352, 293, 1207, 552, 11, 456, 311, 3407, 456, 13, 51850], "temperature": 0.0, "avg_logprob": -0.39890281777632863, "compression_ratio": 1.6955017301038062, "no_speech_prob": 0.007120808120816946}, {"id": 741, "seek": 350610, "start": 3506.42, "end": 3513.54, "text": " And then if I look at any other one in this row, like here, there's only one red that occurs alongside a green, right?", "tokens": [50380, 400, 550, 498, 286, 574, 412, 604, 661, 472, 294, 341, 5386, 11, 411, 510, 11, 456, 311, 787, 472, 2182, 300, 11843, 12385, 257, 3092, 11, 558, 30, 50736], "temperature": 0.0, "avg_logprob": -0.24625032316378462, "compression_ratio": 1.7735849056603774, "no_speech_prob": 9.461028821533546e-05}, {"id": 742, "seek": 350610, "start": 3513.58, "end": 3517.5, "text": " This is the only location where there's one red cell and one green cell.", "tokens": [50738, 639, 307, 264, 787, 4914, 689, 456, 311, 472, 2182, 2815, 293, 472, 3092, 2815, 13, 50934], "temperature": 0.0, "avg_logprob": -0.24625032316378462, "compression_ratio": 1.7735849056603774, "no_speech_prob": 9.461028821533546e-05}, {"id": 743, "seek": 350610, "start": 3518.02, "end": 3519.86, "text": " There's three reds that occur with a yellow.", "tokens": [50960, 821, 311, 1045, 2182, 82, 300, 5160, 365, 257, 5566, 13, 51052], "temperature": 0.0, "avg_logprob": -0.24625032316378462, "compression_ratio": 1.7735849056603774, "no_speech_prob": 9.461028821533546e-05}, {"id": 744, "seek": 350610, "start": 3520.18, "end": 3521.1, "text": " They're there and there.", "tokens": [51068, 814, 434, 456, 293, 456, 13, 51114], "temperature": 0.0, "avg_logprob": -0.24625032316378462, "compression_ratio": 1.7735849056603774, "no_speech_prob": 9.461028821533546e-05}, {"id": 745, "seek": 350610, "start": 3521.7, "end": 3525.18, "text": " And so this Gram matrix here has no spatial component at all.", "tokens": [51144, 400, 370, 341, 22130, 8141, 510, 575, 572, 23598, 6542, 412, 439, 13, 51318], "temperature": 0.0, "avg_logprob": -0.24625032316378462, "compression_ratio": 1.7735849056603774, "no_speech_prob": 9.461028821533546e-05}, {"id": 746, "seek": 350610, "start": 3525.38, "end": 3527.66, "text": " It's just the feature dimension by the feature dimension.", "tokens": [51328, 467, 311, 445, 264, 4111, 10139, 538, 264, 4111, 10139, 13, 51442], "temperature": 0.0, "avg_logprob": -0.24625032316378462, "compression_ratio": 1.7735849056603774, "no_speech_prob": 9.461028821533546e-05}, {"id": 747, "seek": 350610, "start": 3528.2599999999998, "end": 3532.58, "text": " But it has a measure of how common these features are.", "tokens": [51472, 583, 309, 575, 257, 3481, 295, 577, 2689, 613, 4122, 366, 13, 51688], "temperature": 0.0, "avg_logprob": -0.24625032316378462, "compression_ratio": 1.7735849056603774, "no_speech_prob": 9.461028821533546e-05}, {"id": 748, "seek": 350610, "start": 3532.62, "end": 3536.02, "text": " Like what's an uncommon one here?", "tokens": [51690, 1743, 437, 311, 364, 29289, 472, 510, 30, 51860], "temperature": 0.0, "avg_logprob": -0.24625032316378462, "compression_ratio": 1.7735849056603774, "no_speech_prob": 9.461028821533546e-05}, {"id": 749, "seek": 353610, "start": 3536.86, "end": 3538.5, "text": " Yeah.", "tokens": [50402, 865, 13, 50484], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 750, "seek": 353610, "start": 3538.5, "end": 3542.02, "text": " Maybe there's only three greens in total, right?", "tokens": [50484, 2704, 456, 311, 787, 1045, 22897, 294, 3217, 11, 558, 30, 50660], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 751, "seek": 353610, "start": 3542.1, "end": 3545.94, "text": " And all of them occur with alongside a yellow.", "tokens": [50664, 400, 439, 295, 552, 5160, 365, 12385, 257, 5566, 13, 50856], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 752, "seek": 353610, "start": 3546.42, "end": 3548.94, "text": " One of them occurs alongside a red, one of them occurs alongside a blue.", "tokens": [50880, 1485, 295, 552, 11843, 12385, 257, 2182, 11, 472, 295, 552, 11843, 12385, 257, 3344, 13, 51006], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 753, "seek": 353610, "start": 3549.22, "end": 3549.42, "text": " Yeah.", "tokens": [51020, 865, 13, 51030], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 754, "seek": 353610, "start": 3549.42, "end": 3550.66, "text": " So this is exactly what we want.", "tokens": [51030, 407, 341, 307, 2293, 437, 321, 528, 13, 51092], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 755, "seek": 353610, "start": 3550.7, "end": 3557.94, "text": " This is some measure of what features are present, where if they occur together with other features often, that's a useful thing.", "tokens": [51094, 639, 307, 512, 3481, 295, 437, 4122, 366, 1974, 11, 689, 498, 436, 5160, 1214, 365, 661, 4122, 2049, 11, 300, 311, 257, 4420, 551, 13, 51456], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 756, "seek": 353610, "start": 3558.22, "end": 3559.7, "text": " But it doesn't have the spatial component.", "tokens": [51470, 583, 309, 1177, 380, 362, 264, 23598, 6542, 13, 51544], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 757, "seek": 353610, "start": 3559.7, "end": 3560.58, "text": " We've gotten rid of that.", "tokens": [51544, 492, 600, 5768, 3973, 295, 300, 13, 51588], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 758, "seek": 353610, "start": 3561.02, "end": 3563.98, "text": " And this is the first.", "tokens": [51610, 400, 341, 307, 264, 700, 13, 51758], "temperature": 0.0, "avg_logprob": -0.3363468266334854, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.00013765445328317583}, {"id": 759, "seek": 356398, "start": 3564.98, "end": 3568.42, "text": " Clear explanation I've ever seen of how a Gram matrix works.", "tokens": [50414, 14993, 10835, 286, 600, 1562, 1612, 295, 577, 257, 22130, 8141, 1985, 13, 50586], "temperature": 0.0, "avg_logprob": -0.315373673730967, "compression_ratio": 1.6600790513833992, "no_speech_prob": 0.00342920352704823}, {"id": 760, "seek": 356398, "start": 3568.46, "end": 3569.9, "text": " This is such a cool picture.", "tokens": [50588, 639, 307, 1270, 257, 1627, 3036, 13, 50660], "temperature": 0.0, "avg_logprob": -0.315373673730967, "compression_ratio": 1.6600790513833992, "no_speech_prob": 0.00342920352704823}, {"id": 761, "seek": 356398, "start": 3571.3, "end": 3581.82, "text": " I also want to, maybe you can open up the original paper, because I'd also like to encourage people to look at the original paper, because this is something we're trying to practice at this point is reading papers.", "tokens": [50730, 286, 611, 528, 281, 11, 1310, 291, 393, 1269, 493, 264, 3380, 3035, 11, 570, 286, 1116, 611, 411, 281, 5373, 561, 281, 574, 412, 264, 3380, 3035, 11, 570, 341, 307, 746, 321, 434, 1382, 281, 3124, 412, 341, 935, 307, 3760, 10577, 13, 51256], "temperature": 0.0, "avg_logprob": -0.315373673730967, "compression_ratio": 1.6600790513833992, "no_speech_prob": 0.00342920352704823}, {"id": 762, "seek": 356398, "start": 3582.14, "end": 3593.26, "text": " And so hopefully you can take Jono's fantastic explanation and, yeah, and bring it back to understanding the paper.", "tokens": [51272, 400, 370, 4696, 291, 393, 747, 7745, 78, 311, 5456, 10835, 293, 11, 1338, 11, 293, 1565, 309, 646, 281, 3701, 264, 3035, 13, 51828], "temperature": 0.0, "avg_logprob": -0.315373673730967, "compression_ratio": 1.6600790513833992, "no_speech_prob": 0.00342920352704823}, {"id": 763, "seek": 359398, "start": 3594.02, "end": 3594.54, "text": " As well.", "tokens": [50366, 1018, 731, 13, 50392], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 764, "seek": 359398, "start": 3598.22, "end": 3599.9, "text": " That's crazy that it's put it so far down.", "tokens": [50576, 663, 311, 3219, 300, 309, 311, 829, 309, 370, 1400, 760, 13, 50660], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 765, "seek": 359398, "start": 3601.5, "end": 3601.86, "text": " Oh, yeah.", "tokens": [50740, 876, 11, 1338, 13, 50758], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 766, "seek": 359398, "start": 3601.86, "end": 3607.14, "text": " It's a different search engine that I'm trying out that has some AI magic, but they use Bing for their actual searching, which.", "tokens": [50758, 467, 311, 257, 819, 3164, 2848, 300, 286, 478, 1382, 484, 300, 575, 512, 7318, 5585, 11, 457, 436, 764, 30755, 337, 641, 3539, 10808, 11, 597, 13, 51022], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 767, "seek": 359398, "start": 3607.66, "end": 3607.9, "text": " Right.", "tokens": [51048, 1779, 13, 51060], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 768, "seek": 359398, "start": 3607.94, "end": 3608.62, "text": " That's smart one.", "tokens": [51062, 663, 311, 4069, 472, 13, 51096], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 769, "seek": 359398, "start": 3609.7, "end": 3610.34, "text": " The best, yeah.", "tokens": [51150, 440, 1151, 11, 1338, 13, 51182], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 770, "seek": 359398, "start": 3612.06, "end": 3614.66, "text": " And yeah, so we can quickly check the paper.", "tokens": [51268, 400, 1338, 11, 370, 321, 393, 2661, 1520, 264, 3035, 13, 51398], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 771, "seek": 359398, "start": 3614.66, "end": 3617.34, "text": " I don't know if I've actually read this paper, as horrific as that sounds.", "tokens": [51398, 286, 500, 380, 458, 498, 286, 600, 767, 1401, 341, 3035, 11, 382, 29248, 382, 300, 3263, 13, 51532], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 772, "seek": 359398, "start": 3618.18, "end": 3619.06, "text": " Not horrific at all.", "tokens": [51574, 1726, 29248, 412, 439, 13, 51618], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 773, "seek": 359398, "start": 3619.06, "end": 3620.66, "text": " It was a while ago.", "tokens": [51618, 467, 390, 257, 1339, 2057, 13, 51698], "temperature": 0.0, "avg_logprob": -0.3824239591272866, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010326230898499489}, {"id": 774, "seek": 362066, "start": 3621.66, "end": 3626.5, "text": " But I think it's got some nice pictures and I'm going to zoom in a bit.", "tokens": [50414, 583, 286, 519, 309, 311, 658, 512, 1481, 5242, 293, 286, 478, 516, 281, 8863, 294, 257, 857, 13, 50656], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 775, "seek": 362066, "start": 3627.8599999999997, "end": 3628.42, "text": " Oh, good idea.", "tokens": [50724, 876, 11, 665, 1558, 13, 50752], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 776, "seek": 362066, "start": 3631.22, "end": 3631.54, "text": " Okay.", "tokens": [50892, 1033, 13, 50908], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 777, "seek": 362066, "start": 3631.66, "end": 3632.5, "text": " They're the examples.", "tokens": [50914, 814, 434, 264, 5110, 13, 50956], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 778, "seek": 362066, "start": 3632.5, "end": 3633.58, "text": " It's great examples.", "tokens": [50956, 467, 311, 869, 5110, 13, 51010], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 779, "seek": 362066, "start": 3634.42, "end": 3634.8199999999997, "text": " Yeah.", "tokens": [51052, 865, 13, 51072], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 780, "seek": 362066, "start": 3635.2999999999997, "end": 3636.22, "text": " Not for Kandinsky.", "tokens": [51096, 1726, 337, 591, 474, 44153, 13, 51142], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 781, "seek": 362066, "start": 3639.2599999999998, "end": 3640.42, "text": " Sorry about the doorbell.", "tokens": [51294, 4919, 466, 264, 2853, 7100, 13, 51352], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 782, "seek": 362066, "start": 3641.3799999999997, "end": 3641.8599999999997, "text": " Okay.", "tokens": [51400, 1033, 13, 51424], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 783, "seek": 362066, "start": 3644.3799999999997, "end": 3644.62, "text": " Yeah.", "tokens": [51550, 865, 13, 51562], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 784, "seek": 362066, "start": 3644.66, "end": 3647.8199999999997, "text": " The Gram matrix, inner product between the vectorized feature map.", "tokens": [51564, 440, 22130, 8141, 11, 7284, 1674, 1296, 264, 8062, 1602, 4111, 4471, 13, 51722], "temperature": 0.0, "avg_logprob": -0.4589394370278159, "compression_ratio": 1.394736842105263, "no_speech_prob": 0.06096334010362625}, {"id": 785, "seek": 364782, "start": 3648.82, "end": 3652.02, "text": " So those kinds of wordings kind of put me off for a while.", "tokens": [50414, 407, 729, 3685, 295, 1349, 1109, 733, 295, 829, 385, 766, 337, 257, 1339, 13, 50574], "temperature": 0.0, "avg_logprob": -0.33006463169066375, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.004609344992786646}, {"id": 786, "seek": 364782, "start": 3652.02, "end": 3660.6200000000003, "text": " The way I explained Gram matrices when I had to deal with them at all was to say, it's magic that measures with, you know, what features are there without worrying about where they are and left it at that.", "tokens": [50574, 440, 636, 286, 8825, 22130, 32284, 562, 286, 632, 281, 2028, 365, 552, 412, 439, 390, 281, 584, 11, 309, 311, 5585, 300, 8000, 365, 11, 291, 458, 11, 437, 4122, 366, 456, 1553, 18788, 466, 689, 436, 366, 293, 1411, 309, 412, 300, 13, 51004], "temperature": 0.0, "avg_logprob": -0.33006463169066375, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.004609344992786646}, {"id": 787, "seek": 364782, "start": 3660.82, "end": 3665.1400000000003, "text": " And it is worth, yeah, trying to decode this back.", "tokens": [51014, 400, 309, 307, 3163, 11, 1338, 11, 1382, 281, 979, 1429, 341, 646, 13, 51230], "temperature": 0.0, "avg_logprob": -0.33006463169066375, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.004609344992786646}, {"id": 788, "seek": 364782, "start": 3665.46, "end": 3667.26, "text": " They talk about which layers they're looking into.", "tokens": [51246, 814, 751, 466, 597, 7914, 436, 434, 1237, 666, 13, 51336], "temperature": 0.0, "avg_logprob": -0.33006463169066375, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.004609344992786646}, {"id": 789, "seek": 364782, "start": 3667.7000000000003, "end": 3669.5800000000004, "text": " I think in TensorFlow they have names.", "tokens": [51358, 286, 519, 294, 37624, 436, 362, 5288, 13, 51452], "temperature": 0.0, "avg_logprob": -0.33006463169066375, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.004609344992786646}, {"id": 790, "seek": 364782, "start": 3669.5800000000004, "end": 3671.02, "text": " We're just using the index.", "tokens": [51452, 492, 434, 445, 1228, 264, 8186, 13, 51524], "temperature": 0.0, "avg_logprob": -0.33006463169066375, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.004609344992786646}, {"id": 791, "seek": 364782, "start": 3671.86, "end": 3672.94, "text": " Okay.", "tokens": [51566, 1033, 13, 51620], "temperature": 0.0, "avg_logprob": -0.33006463169066375, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.004609344992786646}, {"id": 792, "seek": 364782, "start": 3672.98, "end": 3673.1800000000003, "text": " Yeah.", "tokens": [51622, 865, 13, 51632], "temperature": 0.0, "avg_logprob": -0.33006463169066375, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.004609344992786646}, {"id": 793, "seek": 367318, "start": 3673.18, "end": 3679.8999999999996, "text": " So it doesn't really explain how the Gram matrix works, but it's something that people use historically in some other contexts as well.", "tokens": [50364, 407, 309, 1177, 380, 534, 2903, 577, 264, 22130, 8141, 1985, 11, 457, 309, 311, 746, 300, 561, 764, 16180, 294, 512, 661, 30628, 382, 731, 13, 50700], "temperature": 0.0, "avg_logprob": -0.2407757598574799, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.006903599947690964}, {"id": 794, "seek": 367318, "start": 3680.06, "end": 3681.58, "text": " And for the same kind of measure.", "tokens": [50708, 400, 337, 264, 912, 733, 295, 3481, 13, 50784], "temperature": 0.0, "avg_logprob": -0.2407757598574799, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.006903599947690964}, {"id": 795, "seek": 367318, "start": 3682.22, "end": 3694.54, "text": " Nowadays, actually PyTorch has named parameters and I don't know if they've updated VGG yet, but you can name layers of a sequential model as well.", "tokens": [50816, 28908, 11, 767, 9953, 51, 284, 339, 575, 4926, 9834, 293, 286, 500, 380, 458, 498, 436, 600, 10588, 691, 27561, 1939, 11, 457, 291, 393, 1315, 7914, 295, 257, 42881, 2316, 382, 731, 13, 51432], "temperature": 0.0, "avg_logprob": -0.2407757598574799, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.006903599947690964}, {"id": 796, "seek": 367318, "start": 3695.7799999999997, "end": 3696.06, "text": " Yeah.", "tokens": [51494, 865, 13, 51508], "temperature": 0.0, "avg_logprob": -0.2407757598574799, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.006903599947690964}, {"id": 797, "seek": 367318, "start": 3697.46, "end": 3698.14, "text": " Okay.", "tokens": [51578, 1033, 13, 51612], "temperature": 0.0, "avg_logprob": -0.2407757598574799, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.006903599947690964}, {"id": 798, "seek": 367318, "start": 3698.18, "end": 3701.02, "text": " So just quickly, I wanted to implement this diagram in code.", "tokens": [51614, 407, 445, 2661, 11, 286, 1415, 281, 4445, 341, 10686, 294, 3089, 13, 51756], "temperature": 0.0, "avg_logprob": -0.2407757598574799, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.006903599947690964}, {"id": 799, "seek": 370102, "start": 3701.74, "end": 3707.5, "text": " I should mention these are like zero or one for simplicity, but you could have like obviously different size activations and things.", "tokens": [50400, 286, 820, 2152, 613, 366, 411, 4018, 420, 472, 337, 25632, 11, 457, 291, 727, 362, 411, 2745, 819, 2744, 2430, 763, 293, 721, 13, 50688], "temperature": 0.0, "avg_logprob": -0.26616441049883444, "compression_ratio": 1.667741935483871, "no_speech_prob": 0.0028448125813156366}, {"id": 800, "seek": 370102, "start": 3707.5, "end": 3711.7, "text": " The correlation idea is still going to be there, just not as easy to represent visually.", "tokens": [50688, 440, 1181, 4419, 399, 1558, 307, 920, 516, 281, 312, 456, 11, 445, 406, 382, 1858, 281, 2906, 19622, 13, 50898], "temperature": 0.0, "avg_logprob": -0.26616441049883444, "compression_ratio": 1.667741935483871, "no_speech_prob": 0.0028448125813156366}, {"id": 801, "seek": 370102, "start": 3712.74, "end": 3718.7, "text": " And so we're going to do it with an Einstein because it makes it easy to add later the bash dimension and so on.", "tokens": [50950, 400, 370, 321, 434, 516, 281, 360, 309, 365, 364, 23486, 570, 309, 1669, 309, 1858, 281, 909, 1780, 264, 46183, 10139, 293, 370, 322, 13, 51248], "temperature": 0.0, "avg_logprob": -0.26616441049883444, "compression_ratio": 1.667741935483871, "no_speech_prob": 0.0028448125813156366}, {"id": 802, "seek": 370102, "start": 3719.66, "end": 3724.58, "text": " But I wanted to also highlight that this is just this matrix multiplied with its own transpose.", "tokens": [51296, 583, 286, 1415, 281, 611, 5078, 300, 341, 307, 445, 341, 8141, 17207, 365, 1080, 1065, 25167, 13, 51542], "temperature": 0.0, "avg_logprob": -0.26616441049883444, "compression_ratio": 1.667741935483871, "no_speech_prob": 0.0028448125813156366}, {"id": 803, "seek": 370102, "start": 3725.9, "end": 3727.1, "text": " And you're going to get the same result.", "tokens": [51608, 400, 291, 434, 516, 281, 483, 264, 912, 1874, 13, 51668], "temperature": 0.0, "avg_logprob": -0.26616441049883444, "compression_ratio": 1.667741935483871, "no_speech_prob": 0.0028448125813156366}, {"id": 804, "seek": 370102, "start": 3727.22, "end": 3730.82, "text": " So, yeah, that's our Gram matrix calculation.", "tokens": [51674, 407, 11, 1338, 11, 300, 311, 527, 22130, 8141, 17108, 13, 51854], "temperature": 0.0, "avg_logprob": -0.26616441049883444, "compression_ratio": 1.667741935483871, "no_speech_prob": 0.0028448125813156366}, {"id": 805, "seek": 373082, "start": 3730.82, "end": 3734.02, "text": " There's no magic involved there as much as it might seem like it.", "tokens": [50364, 821, 311, 572, 5585, 3288, 456, 382, 709, 382, 309, 1062, 1643, 411, 309, 13, 50524], "temperature": 0.0, "avg_logprob": -0.29636419677734377, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.000179524184204638}, {"id": 806, "seek": 373082, "start": 3734.6200000000003, "end": 3738.78, "text": " And so we can now use this, like, can we create this measure and then can we do optimization?", "tokens": [50554, 400, 370, 321, 393, 586, 764, 341, 11, 411, 11, 393, 321, 1884, 341, 3481, 293, 550, 393, 321, 360, 19618, 30, 50762], "temperature": 0.0, "avg_logprob": -0.29636419677734377, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.000179524184204638}, {"id": 807, "seek": 373082, "start": 3738.78, "end": 3745.1400000000003, "text": " When you look later at things like Word2Vec, I think it's got some similarities, this idea of kind of co-occurrence of features.", "tokens": [50762, 1133, 291, 574, 1780, 412, 721, 411, 8725, 17, 53, 3045, 11, 286, 519, 309, 311, 658, 512, 24197, 11, 341, 1558, 295, 733, 295, 598, 12, 905, 14112, 10760, 295, 4122, 13, 51080], "temperature": 0.0, "avg_logprob": -0.29636419677734377, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.000179524184204638}, {"id": 808, "seek": 373082, "start": 3745.1400000000003, "end": 3754.9, "text": " And it also reminds me of the clip loss, similar idea of like basically a dot product, but in this case with itself.", "tokens": [51080, 400, 309, 611, 12025, 385, 295, 264, 7353, 4470, 11, 2531, 1558, 295, 411, 1936, 257, 5893, 1674, 11, 457, 294, 341, 1389, 365, 2564, 13, 51568], "temperature": 0.0, "avg_logprob": -0.29636419677734377, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.000179524184204638}, {"id": 809, "seek": 373082, "start": 3754.94, "end": 3760.1400000000003, "text": " I mean, we've seen how co-variance is basically that as well.", "tokens": [51570, 286, 914, 11, 321, 600, 1612, 577, 598, 12, 34033, 719, 307, 1936, 300, 382, 731, 13, 51830], "temperature": 0.0, "avg_logprob": -0.29636419677734377, "compression_ratio": 1.632867132867133, "no_speech_prob": 0.000179524184204638}, {"id": 810, "seek": 376014, "start": 3760.14, "end": 3770.06, "text": " So this idea of kind of like multiplying with your own transpose is a really common mathematical technique we've come across three or four times in this course.", "tokens": [50364, 407, 341, 1558, 295, 733, 295, 411, 30955, 365, 428, 1065, 25167, 307, 257, 534, 2689, 18894, 6532, 321, 600, 808, 2108, 1045, 420, 1451, 1413, 294, 341, 1164, 13, 50860], "temperature": 0.0, "avg_logprob": -0.31511185385964136, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.0003799737023655325}, {"id": 811, "seek": 376014, "start": 3771.06, "end": 3771.3399999999997, "text": " Yeah.", "tokens": [50910, 865, 13, 50924], "temperature": 0.0, "avg_logprob": -0.31511185385964136, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.0003799737023655325}, {"id": 812, "seek": 376014, "start": 3771.74, "end": 3772.9, "text": " And it comes up all over the place.", "tokens": [50944, 400, 309, 1487, 493, 439, 670, 264, 1081, 13, 51002], "temperature": 0.0, "avg_logprob": -0.31511185385964136, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.0003799737023655325}, {"id": 813, "seek": 376014, "start": 3772.94, "end": 3779.42, "text": " Even, yeah, you'll see that in protein folding stuff as well.", "tokens": [51004, 2754, 11, 1338, 11, 291, 603, 536, 300, 294, 7944, 25335, 1507, 382, 731, 13, 51328], "temperature": 0.0, "avg_logprob": -0.31511185385964136, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.0003799737023655325}, {"id": 814, "seek": 376014, "start": 3779.42, "end": 3782.8599999999997, "text": " They have a big co-variance matrix for like.", "tokens": [51328, 814, 362, 257, 955, 598, 12, 34033, 719, 8141, 337, 411, 13, 51500], "temperature": 0.0, "avg_logprob": -0.31511185385964136, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.0003799737023655325}, {"id": 815, "seek": 376014, "start": 3783.1, "end": 3788.8199999999997, "text": " So the difference in each case is like, yeah, the difference in each case is the matrix that we're multiplying by its own transpose.", "tokens": [51512, 407, 264, 2649, 294, 1184, 1389, 307, 411, 11, 1338, 11, 264, 2649, 294, 1184, 1389, 307, 264, 8141, 300, 321, 434, 30955, 538, 1080, 1065, 25167, 13, 51798], "temperature": 0.0, "avg_logprob": -0.31511185385964136, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.0003799737023655325}, {"id": 816, "seek": 378882, "start": 3788.82, "end": 3795.1400000000003, "text": " So for co-variance, the matrix is the matrix of differences to the mean, for example.", "tokens": [50364, 407, 337, 598, 12, 34033, 719, 11, 264, 8141, 307, 264, 8141, 295, 7300, 281, 264, 914, 11, 337, 1365, 13, 50680], "temperature": 0.0, "avg_logprob": -0.26379414512997584, "compression_ratio": 1.7375, "no_speech_prob": 0.0003150303673464805}, {"id": 817, "seek": 378882, "start": 3795.6600000000003, "end": 3800.7000000000003, "text": " And yeah, in this case, the matrix is this flattened feature thing.", "tokens": [50706, 400, 1338, 11, 294, 341, 1389, 11, 264, 8141, 307, 341, 24183, 292, 4111, 551, 13, 50958], "temperature": 0.0, "avg_logprob": -0.26379414512997584, "compression_ratio": 1.7375, "no_speech_prob": 0.0003150303673464805}, {"id": 818, "seek": 378882, "start": 3802.9, "end": 3803.1800000000003, "text": " Cool.", "tokens": [51068, 8561, 13, 51082], "temperature": 0.0, "avg_logprob": -0.26379414512997584, "compression_ratio": 1.7375, "no_speech_prob": 0.0003150303673464805}, {"id": 819, "seek": 378882, "start": 3803.1800000000003, "end": 3811.34, "text": " So I have here the calculate grams function that's going to do exactly that operation we did above, but we're going to add some scaling.", "tokens": [51082, 407, 286, 362, 510, 264, 8873, 11899, 2445, 300, 311, 516, 281, 360, 2293, 300, 6916, 321, 630, 3673, 11, 457, 321, 434, 516, 281, 909, 512, 21589, 13, 51490], "temperature": 0.0, "avg_logprob": -0.26379414512997584, "compression_ratio": 1.7375, "no_speech_prob": 0.0003150303673464805}, {"id": 820, "seek": 378882, "start": 3811.6600000000003, "end": 3817.02, "text": " And the reason we're adding the scaling is that we have this feature map and we might pass in images of different sizes.", "tokens": [51506, 400, 264, 1778, 321, 434, 5127, 264, 21589, 307, 300, 321, 362, 341, 4111, 4471, 293, 321, 1062, 1320, 294, 5267, 295, 819, 11602, 13, 51774], "temperature": 0.0, "avg_logprob": -0.26379414512997584, "compression_ratio": 1.7375, "no_speech_prob": 0.0003150303673464805}, {"id": 821, "seek": 381702, "start": 3817.54, "end": 3823.9, "text": " And so what this gives us is the absolute, like you can see there's a relation to the number of spatial locations here.", "tokens": [50390, 400, 370, 437, 341, 2709, 505, 307, 264, 8236, 11, 411, 291, 393, 536, 456, 311, 257, 9721, 281, 264, 1230, 295, 23598, 9253, 510, 13, 50708], "temperature": 0.0, "avg_logprob": -0.23966910812880968, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.0041987053118646145}, {"id": 822, "seek": 381702, "start": 3824.38, "end": 3831.66, "text": " And so by scaling by this width times height, we're going to get like a relative measure as opposed to like an absolute measure.", "tokens": [50732, 400, 370, 538, 21589, 538, 341, 11402, 1413, 6681, 11, 321, 434, 516, 281, 483, 411, 257, 4972, 3481, 382, 8851, 281, 411, 364, 8236, 3481, 13, 51096], "temperature": 0.0, "avg_logprob": -0.23966910812880968, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.0041987053118646145}, {"id": 823, "seek": 381702, "start": 3831.7, "end": 3835.42, "text": " It just means that the comparisons are going to be valid even for images of different sizes.", "tokens": [51098, 467, 445, 1355, 300, 264, 33157, 366, 516, 281, 312, 7363, 754, 337, 5267, 295, 819, 11602, 13, 51284], "temperature": 0.0, "avg_logprob": -0.23966910812880968, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.0041987053118646145}, {"id": 824, "seek": 381702, "start": 3835.98, "end": 3839.5, "text": " And so that's the only extra complexity here.", "tokens": [51312, 400, 370, 300, 311, 264, 787, 2857, 14024, 510, 13, 51488], "temperature": 0.0, "avg_logprob": -0.23966910812880968, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.0041987053118646145}, {"id": 825, "seek": 383950, "start": 3839.5, "end": 3848.7, "text": " But we have a channels by height by width image in and we're going to pass in, oh sorry, this is like channels being the number of features.", "tokens": [50364, 583, 321, 362, 257, 9235, 538, 6681, 538, 11402, 3256, 294, 293, 321, 434, 516, 281, 1320, 294, 11, 1954, 2597, 11, 341, 307, 411, 9235, 885, 264, 1230, 295, 4122, 13, 50824], "temperature": 0.0, "avg_logprob": -0.3555007028107596, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.5426455140113831}, {"id": 826, "seek": 383950, "start": 3849.26, "end": 3855.7, "text": " We're going to pass in two versions of that, right?", "tokens": [50852, 492, 434, 516, 281, 1320, 294, 732, 9606, 295, 300, 11, 558, 30, 51174], "temperature": 0.0, "avg_logprob": -0.3555007028107596, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.5426455140113831}, {"id": 827, "seek": 383950, "start": 3855.74, "end": 3857.86, "text": " Because it's the same image in both times.", "tokens": [51176, 1436, 309, 311, 264, 912, 3256, 294, 1293, 1413, 13, 51282], "temperature": 0.0, "avg_logprob": -0.3555007028107596, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.5426455140113831}, {"id": 828, "seek": 383950, "start": 3858.7, "end": 3865.38, "text": " But we're going to map this down to just the features by features, but you can't repeat variables in Einstein.", "tokens": [51324, 583, 321, 434, 516, 281, 4471, 341, 760, 281, 445, 264, 4122, 538, 4122, 11, 457, 291, 393, 380, 7149, 9102, 294, 23486, 13, 51658], "temperature": 0.0, "avg_logprob": -0.3555007028107596, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.5426455140113831}, {"id": 829, "seek": 383950, "start": 3865.38, "end": 3866.62, "text": " So that's why it's C and D.", "tokens": [51658, 407, 300, 311, 983, 309, 311, 383, 293, 413, 13, 51720], "temperature": 0.0, "avg_logprob": -0.3555007028107596, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.5426455140113831}, {"id": 830, "seek": 386662, "start": 3867.22, "end": 3875.62, "text": " And if we run this on our style image, you can see I'm targeting five different layers.", "tokens": [50394, 400, 498, 321, 1190, 341, 322, 527, 3758, 3256, 11, 291, 393, 536, 286, 478, 17918, 1732, 819, 7914, 13, 50814], "temperature": 0.0, "avg_logprob": -0.32618051416733684, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.04336358234286308}, {"id": 831, "seek": 386662, "start": 3876.14, "end": 3880.3399999999997, "text": " And for each one, the first layer has 64 features.", "tokens": [50840, 400, 337, 1184, 472, 11, 264, 700, 4583, 575, 12145, 4122, 13, 51050], "temperature": 0.0, "avg_logprob": -0.32618051416733684, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.04336358234286308}, {"id": 832, "seek": 386662, "start": 3880.3399999999997, "end": 3883.14, "text": " And so we get a 64 by 64 gram matrix.", "tokens": [51050, 400, 370, 321, 483, 257, 12145, 538, 12145, 21353, 8141, 13, 51190], "temperature": 0.0, "avg_logprob": -0.32618051416733684, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.04336358234286308}, {"id": 833, "seek": 386662, "start": 3883.46, "end": 3885.22, "text": " The second one has 128 features.", "tokens": [51206, 440, 1150, 472, 575, 29810, 4122, 13, 51294], "temperature": 0.0, "avg_logprob": -0.32618051416733684, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.04336358234286308}, {"id": 834, "seek": 386662, "start": 3885.22, "end": 3887.2599999999998, "text": " We can get 120 by 128 gram matrix.", "tokens": [51294, 492, 393, 483, 10411, 538, 29810, 21353, 8141, 13, 51396], "temperature": 0.0, "avg_logprob": -0.32618051416733684, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.04336358234286308}, {"id": 835, "seek": 386662, "start": 3887.2599999999998, "end": 3889.58, "text": " So this is doing, it seems like what we want.", "tokens": [51396, 407, 341, 307, 884, 11, 309, 2544, 411, 437, 321, 528, 13, 51512], "temperature": 0.0, "avg_logprob": -0.32618051416733684, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.04336358234286308}, {"id": 836, "seek": 388958, "start": 3890.14, "end": 3898.14, "text": " And because this is a list, we can use this at or got method, which I will actually.", "tokens": [50392, 400, 570, 341, 307, 257, 1329, 11, 321, 393, 764, 341, 412, 420, 658, 3170, 11, 597, 286, 486, 767, 13, 50792], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 837, "seek": 388958, "start": 3898.14, "end": 3901.2999999999997, "text": " It's a fast call capital L, not a list.", "tokens": [50792, 467, 311, 257, 2370, 818, 4238, 441, 11, 406, 257, 1329, 13, 50950], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 838, "seek": 388958, "start": 3901.2999999999997, "end": 3902.58, "text": " Sorry.", "tokens": [50950, 4919, 13, 51014], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 839, "seek": 388958, "start": 3902.58, "end": 3902.9, "text": " Yeah.", "tokens": [51014, 865, 13, 51030], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 840, "seek": 388958, "start": 3904.14, "end": 3904.8199999999997, "text": " Magic list.", "tokens": [51092, 16154, 1329, 13, 51126], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 841, "seek": 388958, "start": 3905.2999999999997, "end": 3906.06, "text": " That's what I like to think about.", "tokens": [51150, 663, 311, 437, 286, 411, 281, 519, 466, 13, 51188], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 842, "seek": 388958, "start": 3908.06, "end": 3908.2999999999997, "text": " Yeah.", "tokens": [51288, 865, 13, 51300], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 843, "seek": 388958, "start": 3908.34, "end": 3909.7, "text": " So either works.", "tokens": [51302, 407, 2139, 1985, 13, 51370], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 844, "seek": 388958, "start": 3910.2599999999998, "end": 3910.46, "text": " Okay.", "tokens": [51398, 1033, 13, 51408], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 845, "seek": 388958, "start": 3910.5, "end": 3912.62, "text": " So let's use this as a loss.", "tokens": [51410, 407, 718, 311, 764, 341, 382, 257, 4470, 13, 51516], "temperature": 0.0, "avg_logprob": -0.6236771236766468, "compression_ratio": 1.4491017964071857, "no_speech_prob": 0.19188223779201508}, {"id": 846, "seek": 391262, "start": 3912.98, "end": 3919.5, "text": " Just like with the content loss before, we're going to take in a target image, which is going to be our style.", "tokens": [50382, 1449, 411, 365, 264, 2701, 4470, 949, 11, 321, 434, 516, 281, 747, 294, 257, 3779, 3256, 11, 597, 307, 516, 281, 312, 527, 3758, 13, 50708], "temperature": 0.0, "avg_logprob": -0.2767106746805125, "compression_ratio": 1.9239543726235742, "no_speech_prob": 0.4881323277950287}, {"id": 847, "seek": 391262, "start": 3919.8199999999997, "end": 3921.9, "text": " We're going to calculate these gram matrices for that.", "tokens": [50724, 492, 434, 516, 281, 8873, 613, 21353, 32284, 337, 300, 13, 50828], "temperature": 0.0, "avg_logprob": -0.2767106746805125, "compression_ratio": 1.9239543726235742, "no_speech_prob": 0.4881323277950287}, {"id": 848, "seek": 391262, "start": 3922.42, "end": 3933.02, "text": " And then when we get in an input to our loss function, we're going to calculate the gram matrices for that and do the mean squared error between the gram matrices.", "tokens": [50854, 400, 550, 562, 321, 483, 294, 364, 4846, 281, 527, 4470, 2445, 11, 321, 434, 516, 281, 8873, 264, 21353, 32284, 337, 300, 293, 360, 264, 914, 8889, 6713, 1296, 264, 21353, 32284, 13, 51384], "temperature": 0.0, "avg_logprob": -0.2767106746805125, "compression_ratio": 1.9239543726235742, "no_speech_prob": 0.4881323277950287}, {"id": 849, "seek": 391262, "start": 3933.1, "end": 3942.54, "text": " So these are the no spatial components, just what features are there, comparing the two to make sure that they're ideally have the same kinds of features and the same kinds of.", "tokens": [51388, 407, 613, 366, 264, 572, 23598, 6677, 11, 445, 437, 4122, 366, 456, 11, 15763, 264, 732, 281, 652, 988, 300, 436, 434, 22915, 362, 264, 912, 3685, 295, 4122, 293, 264, 912, 3685, 295, 13, 51860], "temperature": 0.0, "avg_logprob": -0.2767106746805125, "compression_ratio": 1.9239543726235742, "no_speech_prob": 0.4881323277950287}, {"id": 850, "seek": 394262, "start": 3942.94, "end": 3944.2999999999997, "text": " Correlations between features.", "tokens": [50380, 3925, 4419, 763, 1296, 4122, 13, 50448], "temperature": 0.0, "avg_logprob": -0.2755371863100709, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.0008040678803808987}, {"id": 851, "seek": 394262, "start": 3945.06, "end": 3946.94, "text": " So we can set that up.", "tokens": [50486, 407, 321, 393, 992, 300, 493, 13, 50580], "temperature": 0.0, "avg_logprob": -0.2755371863100709, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.0008040678803808987}, {"id": 852, "seek": 394262, "start": 3946.98, "end": 3948.7799999999997, "text": " We can evaluate it on my image.", "tokens": [50582, 492, 393, 13059, 309, 322, 452, 3256, 13, 50672], "temperature": 0.0, "avg_logprob": -0.2755371863100709, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.0008040678803808987}, {"id": 853, "seek": 394262, "start": 3949.2599999999998, "end": 3953.66, "text": " So our content image at the moment has quite a high loss when we compare it to our style image.", "tokens": [50696, 407, 527, 2701, 3256, 412, 264, 1623, 575, 1596, 257, 1090, 4470, 562, 321, 6794, 309, 281, 527, 3758, 3256, 13, 50916], "temperature": 0.0, "avg_logprob": -0.2755371863100709, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.0008040678803808987}, {"id": 854, "seek": 394262, "start": 3954.22, "end": 3959.14, "text": " And that means that our content image doesn't look anything like a spider web in terms of its textures and whatever.", "tokens": [50944, 400, 300, 1355, 300, 527, 2701, 3256, 1177, 380, 574, 1340, 411, 257, 17614, 3670, 294, 2115, 295, 1080, 24501, 293, 2035, 13, 51190], "temperature": 0.0, "avg_logprob": -0.2755371863100709, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.0008040678803808987}, {"id": 855, "seek": 394262, "start": 3960.22, "end": 3960.74, "text": " Exactly.", "tokens": [51244, 7587, 13, 51270], "temperature": 0.0, "avg_logprob": -0.2755371863100709, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.0008040678803808987}, {"id": 856, "seek": 394262, "start": 3961.42, "end": 3963.8599999999997, "text": " So we're going to set up an optimization thing here.", "tokens": [51304, 407, 321, 434, 516, 281, 992, 493, 364, 19618, 551, 510, 13, 51426], "temperature": 0.0, "avg_logprob": -0.2755371863100709, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.0008040678803808987}, {"id": 857, "seek": 394262, "start": 3964.2999999999997, "end": 3971.02, "text": " One difference is that at the moment I'm starting from the content image itself rather than optimizing from random noise.", "tokens": [51448, 1485, 2649, 307, 300, 412, 264, 1623, 286, 478, 2891, 490, 264, 2701, 3256, 2564, 2831, 813, 40425, 490, 4974, 5658, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2755371863100709, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.0008040678803808987}, {"id": 858, "seek": 397102, "start": 3971.54, "end": 3973.46, "text": " You can choose either way.", "tokens": [50390, 509, 393, 2826, 2139, 636, 13, 50486], "temperature": 0.0, "avg_logprob": -0.2739552270798456, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.03461660444736481}, {"id": 859, "seek": 397102, "start": 3973.54, "end": 3977.5, "text": " For style transfer, it's quite nice to use the content image as a starting point.", "tokens": [50490, 1171, 3758, 5003, 11, 309, 311, 1596, 1481, 281, 764, 264, 2701, 3256, 382, 257, 2891, 935, 13, 50688], "temperature": 0.0, "avg_logprob": -0.2739552270798456, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.03461660444736481}, {"id": 860, "seek": 397102, "start": 3978.1, "end": 3980.62, "text": " And so you can see at the beginning, it just looks like our content image.", "tokens": [50718, 400, 370, 291, 393, 536, 412, 264, 2863, 11, 309, 445, 1542, 411, 527, 2701, 3256, 13, 50844], "temperature": 0.0, "avg_logprob": -0.2739552270798456, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.03461660444736481}, {"id": 861, "seek": 397102, "start": 3981.54, "end": 3990.14, "text": " But as we do more and more steps, we maintain the structure because we're still using the content loss as one component of our loss function.", "tokens": [50890, 583, 382, 321, 360, 544, 293, 544, 4439, 11, 321, 6909, 264, 3877, 570, 321, 434, 920, 1228, 264, 2701, 4470, 382, 472, 6542, 295, 527, 4470, 2445, 13, 51320], "temperature": 0.0, "avg_logprob": -0.2739552270798456, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.03461660444736481}, {"id": 862, "seek": 397102, "start": 3990.86, "end": 3998.38, "text": " But now we also have more and more of the style because of the early layers we're evaluating that style loss.", "tokens": [51356, 583, 586, 321, 611, 362, 544, 293, 544, 295, 264, 3758, 570, 295, 264, 2440, 7914, 321, 434, 27479, 300, 3758, 4470, 13, 51732], "temperature": 0.0, "avg_logprob": -0.2739552270798456, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.03461660444736481}, {"id": 863, "seek": 399838, "start": 3998.38, "end": 4008.6600000000003, "text": " And you can see this doesn't have the same layout as our spider web, but it has the same kinds of textures and the same types of structure there.", "tokens": [50364, 400, 291, 393, 536, 341, 1177, 380, 362, 264, 912, 13333, 382, 527, 17614, 3670, 11, 457, 309, 575, 264, 912, 3685, 295, 24501, 293, 264, 912, 3467, 295, 3877, 456, 13, 50878], "temperature": 0.0, "avg_logprob": -0.24305711581012396, "compression_ratio": 1.788104089219331, "no_speech_prob": 0.0015487109776586294}, {"id": 864, "seek": 399838, "start": 4008.7400000000002, "end": 4013.62, "text": " And so we can check out the final result and you can see it's done ostensibly what our goal is.", "tokens": [50882, 400, 370, 321, 393, 1520, 484, 264, 2572, 1874, 293, 291, 393, 536, 309, 311, 1096, 32946, 694, 3545, 437, 527, 3387, 307, 13, 51126], "temperature": 0.0, "avg_logprob": -0.24305711581012396, "compression_ratio": 1.788104089219331, "no_speech_prob": 0.0015487109776586294}, {"id": 865, "seek": 399838, "start": 4013.6600000000003, "end": 4016.54, "text": " It's taken one image and it's done it in the style of another.", "tokens": [51128, 467, 311, 2726, 472, 3256, 293, 309, 311, 1096, 309, 294, 264, 3758, 295, 1071, 13, 51272], "temperature": 0.0, "avg_logprob": -0.24305711581012396, "compression_ratio": 1.788104089219331, "no_speech_prob": 0.0015487109776586294}, {"id": 866, "seek": 399838, "start": 4017.6600000000003, "end": 4018.82, "text": " And to me, this is quite satisfying.", "tokens": [51328, 400, 281, 385, 11, 341, 307, 1596, 18348, 13, 51386], "temperature": 0.0, "avg_logprob": -0.24305711581012396, "compression_ratio": 1.788104089219331, "no_speech_prob": 0.0015487109776586294}, {"id": 867, "seek": 399838, "start": 4019.54, "end": 4023.7000000000003, "text": " And it's actually done it in a particularly clever way because look at her arm.", "tokens": [51422, 400, 309, 311, 767, 1096, 309, 294, 257, 4098, 13494, 636, 570, 574, 412, 720, 3726, 13, 51630], "temperature": 0.0, "avg_logprob": -0.24305711581012396, "compression_ratio": 1.788104089219331, "no_speech_prob": 0.0015487109776586294}, {"id": 868, "seek": 399838, "start": 4023.9, "end": 4027.42, "text": " You know, her arm has the spider web nicely laid out on it.", "tokens": [51640, 509, 458, 11, 720, 3726, 575, 264, 17614, 3670, 9594, 9897, 484, 322, 309, 13, 51816], "temperature": 0.0, "avg_logprob": -0.24305711581012396, "compression_ratio": 1.788104089219331, "no_speech_prob": 0.0015487109776586294}, {"id": 869, "seek": 402742, "start": 4027.94, "end": 4031.94, "text": " And she's almost like picking it out with her fingers.", "tokens": [50390, 400, 750, 311, 1920, 411, 8867, 309, 484, 365, 720, 7350, 13, 50590], "temperature": 0.0, "avg_logprob": -0.2515097466584678, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00020026178390253335}, {"id": 870, "seek": 402742, "start": 4033.7000000000003, "end": 4040.3, "text": " And her face, you know, which is kind of quite an important or very important in terms of like object recognition.", "tokens": [50678, 400, 720, 1851, 11, 291, 458, 11, 597, 307, 733, 295, 1596, 364, 1021, 420, 588, 1021, 294, 2115, 295, 411, 2657, 11150, 13, 51008], "temperature": 0.0, "avg_logprob": -0.2515097466584678, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00020026178390253335}, {"id": 871, "seek": 402742, "start": 4040.86, "end": 4044.7400000000002, "text": " The model didn't want to mess with the face much at all.", "tokens": [51036, 440, 2316, 994, 380, 528, 281, 2082, 365, 264, 1851, 709, 412, 439, 13, 51230], "temperature": 0.0, "avg_logprob": -0.2515097466584678, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00020026178390253335}, {"id": 872, "seek": 402742, "start": 4044.78, "end": 4047.58, "text": " So it's kept the spider webs away from that.", "tokens": [51232, 407, 309, 311, 4305, 264, 17614, 2859, 1314, 490, 300, 13, 51372], "temperature": 0.0, "avg_logprob": -0.2515097466584678, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00020026178390253335}, {"id": 873, "seek": 402742, "start": 4047.66, "end": 4056.78, "text": " Like I think it's the more you look at it, the more impressive it is in how it's managed to find a way to add spider webs without messing up.", "tokens": [51376, 1743, 286, 519, 309, 311, 264, 544, 291, 574, 412, 309, 11, 264, 544, 8992, 309, 307, 294, 577, 309, 311, 6453, 281, 915, 257, 636, 281, 909, 17614, 2859, 1553, 23258, 493, 13, 51832], "temperature": 0.0, "avg_logprob": -0.2515097466584678, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00020026178390253335}, {"id": 874, "seek": 405678, "start": 4057.02, "end": 4061.6600000000003, "text": " The overall kind of semantics of the image.", "tokens": [50376, 440, 4787, 733, 295, 4361, 45298, 295, 264, 3256, 13, 50608], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 875, "seek": 405678, "start": 4062.9, "end": 4063.26, "text": " Yeah.", "tokens": [50670, 865, 13, 50688], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 876, "seek": 405678, "start": 4063.9, "end": 4064.1000000000004, "text": " Yeah.", "tokens": [50720, 865, 13, 50730], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 877, "seek": 405678, "start": 4064.1400000000003, "end": 4066.26, "text": " So this is really fun to play with.", "tokens": [50732, 407, 341, 307, 534, 1019, 281, 862, 365, 13, 50838], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 878, "seek": 405678, "start": 4066.6200000000003, "end": 4071.38, "text": " If you've been running the notebook with the demo images, please like right now go and find your own pictures.", "tokens": [50856, 759, 291, 600, 668, 2614, 264, 21060, 365, 264, 10723, 5267, 11, 1767, 411, 558, 586, 352, 293, 915, 428, 1065, 5242, 13, 51094], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 879, "seek": 405678, "start": 4071.42, "end": 4073.82, "text": " Make sure you're not stealing someone's licensed work.", "tokens": [51096, 4387, 988, 291, 434, 406, 19757, 1580, 311, 25225, 589, 13, 51216], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 880, "seek": 405678, "start": 4073.82, "end": 4077.6200000000003, "text": " But there's lots of creative commons images out there and try bash them together.", "tokens": [51216, 583, 456, 311, 3195, 295, 5880, 800, 892, 5267, 484, 456, 293, 853, 46183, 552, 1214, 13, 51406], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 881, "seek": 405678, "start": 4077.6200000000003, "end": 4082.9, "text": " Do it at a larger size, you know, get some higher resolution style loss going.", "tokens": [51406, 1144, 309, 412, 257, 4833, 2744, 11, 291, 458, 11, 483, 512, 2946, 8669, 3758, 4470, 516, 13, 51670], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 882, "seek": 405678, "start": 4083.26, "end": 4085.1000000000004, "text": " And then there's so much that you can experiment with.", "tokens": [51688, 400, 550, 456, 311, 370, 709, 300, 291, 393, 5120, 365, 13, 51780], "temperature": 0.0, "avg_logprob": -0.32195008185602003, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0013884672662243247}, {"id": 883, "seek": 408510, "start": 4085.1, "end": 4093.2999999999997, "text": " So, for example, you can change the content loss to focus on maybe an earlier layer as well.", "tokens": [50364, 407, 11, 337, 1365, 11, 291, 393, 1319, 264, 2701, 4470, 281, 1879, 322, 1310, 364, 3071, 4583, 382, 731, 13, 50774], "temperature": 0.0, "avg_logprob": -0.23805655033216563, "compression_ratio": 1.9128630705394192, "no_speech_prob": 0.004681318067014217}, {"id": 884, "seek": 408510, "start": 4093.94, "end": 4100.38, "text": " You can start from a random image instead of the content image, or you can start from the style image and optimize towards the content image.", "tokens": [50806, 509, 393, 722, 490, 257, 4974, 3256, 2602, 295, 264, 2701, 3256, 11, 420, 291, 393, 722, 490, 264, 3758, 3256, 293, 19719, 3030, 264, 2701, 3256, 13, 51128], "temperature": 0.0, "avg_logprob": -0.23805655033216563, "compression_ratio": 1.9128630705394192, "no_speech_prob": 0.004681318067014217}, {"id": 885, "seek": 408510, "start": 4100.78, "end": 4104.5, "text": " You can change how you scale these two components of the loss function.", "tokens": [51148, 509, 393, 1319, 577, 291, 4373, 613, 732, 6677, 295, 264, 4470, 2445, 13, 51334], "temperature": 0.0, "avg_logprob": -0.23805655033216563, "compression_ratio": 1.9128630705394192, "no_speech_prob": 0.004681318067014217}, {"id": 886, "seek": 408510, "start": 4104.94, "end": 4107.5, "text": " You can change how long you train for, what your learning rate is.", "tokens": [51356, 509, 393, 1319, 577, 938, 291, 3847, 337, 11, 437, 428, 2539, 3314, 307, 13, 51484], "temperature": 0.0, "avg_logprob": -0.23805655033216563, "compression_ratio": 1.9128630705394192, "no_speech_prob": 0.004681318067014217}, {"id": 887, "seek": 408510, "start": 4108.66, "end": 4113.74, "text": " All of this is up for grabs in terms of what you can optimize and what you can explore.", "tokens": [51542, 1057, 295, 341, 307, 493, 337, 30028, 294, 2115, 295, 437, 291, 393, 19719, 293, 437, 291, 393, 6839, 13, 51796], "temperature": 0.0, "avg_logprob": -0.23805655033216563, "compression_ratio": 1.9128630705394192, "no_speech_prob": 0.004681318067014217}, {"id": 888, "seek": 411510, "start": 4115.26, "end": 4119.34, "text": " And you get different results with different scalings and different focus layers.", "tokens": [50372, 400, 291, 483, 819, 3542, 365, 819, 15664, 1109, 293, 819, 1879, 7914, 13, 50576], "temperature": 0.0, "avg_logprob": -0.30069211551121305, "compression_ratio": 1.7, "no_speech_prob": 0.0009398935362696648}, {"id": 889, "seek": 411510, "start": 4119.780000000001, "end": 4130.9800000000005, "text": " So there's a whole lot of fun experimentation to be done in terms of finding a set of parameters that gives you like a pleasing result for a given style content pair and for a given effect that you want on the output.", "tokens": [50598, 407, 456, 311, 257, 1379, 688, 295, 1019, 37142, 281, 312, 1096, 294, 2115, 295, 5006, 257, 992, 295, 9834, 300, 2709, 291, 411, 257, 32798, 1874, 337, 257, 2212, 3758, 2701, 6119, 293, 337, 257, 2212, 1802, 300, 291, 528, 322, 264, 5598, 13, 51158], "temperature": 0.0, "avg_logprob": -0.30069211551121305, "compression_ratio": 1.7, "no_speech_prob": 0.0009398935362696648}, {"id": 890, "seek": 411510, "start": 4131.740000000001, "end": 4133.34, "text": " Yeah.", "tokens": [51196, 865, 13, 51276], "temperature": 0.0, "avg_logprob": -0.30069211551121305, "compression_ratio": 1.7, "no_speech_prob": 0.0009398935362696648}, {"id": 891, "seek": 411510, "start": 4133.42, "end": 4142.58, "text": " On that note, I wanted to like, one of the really interesting things about this is just, you know, how well Ouija works as a network, even though it's a very old network.", "tokens": [51280, 1282, 300, 3637, 11, 286, 1415, 281, 411, 11, 472, 295, 264, 534, 1880, 721, 466, 341, 307, 445, 11, 291, 458, 11, 577, 731, 11710, 20642, 1985, 382, 257, 3209, 11, 754, 1673, 309, 311, 257, 588, 1331, 3209, 13, 51738], "temperature": 0.0, "avg_logprob": -0.30069211551121305, "compression_ratio": 1.7, "no_speech_prob": 0.0009398935362696648}, {"id": 892, "seek": 414258, "start": 4142.78, "end": 4146.7, "text": " But I think it's also worth playing around with other networks as well.", "tokens": [50374, 583, 286, 519, 309, 311, 611, 3163, 2433, 926, 365, 661, 9590, 382, 731, 13, 50570], "temperature": 0.0, "avg_logprob": -0.21796391057033165, "compression_ratio": 1.9051724137931034, "no_speech_prob": 0.030655639246106148}, {"id": 893, "seek": 414258, "start": 4146.98, "end": 4154.54, "text": " I think there's definitely some special properties of VGG that allow for it to do well for style transfer.", "tokens": [50584, 286, 519, 456, 311, 2138, 512, 2121, 7221, 295, 691, 27561, 300, 2089, 337, 309, 281, 360, 731, 337, 3758, 5003, 13, 50962], "temperature": 0.0, "avg_logprob": -0.21796391057033165, "compression_ratio": 1.9051724137931034, "no_speech_prob": 0.030655639246106148}, {"id": 894, "seek": 414258, "start": 4154.58, "end": 4155.94, "text": " And there are a few papers on that.", "tokens": [50964, 400, 456, 366, 257, 1326, 10577, 322, 300, 13, 51032], "temperature": 0.0, "avg_logprob": -0.21796391057033165, "compression_ratio": 1.9051724137931034, "no_speech_prob": 0.030655639246106148}, {"id": 895, "seek": 414258, "start": 4156.22, "end": 4164.22, "text": " And there are also some papers that explore how we can use maybe other networks for style transfer that maintains maybe some of these nice properties of VGG.", "tokens": [51046, 400, 456, 366, 611, 512, 10577, 300, 6839, 577, 321, 393, 764, 1310, 661, 9590, 337, 3758, 5003, 300, 33385, 1310, 512, 295, 613, 1481, 7221, 295, 691, 27561, 13, 51446], "temperature": 0.0, "avg_logprob": -0.21796391057033165, "compression_ratio": 1.9051724137931034, "no_speech_prob": 0.030655639246106148}, {"id": 896, "seek": 414258, "start": 4164.46, "end": 4168.98, "text": " So I think that could be interesting to explore some of these papers.", "tokens": [51458, 407, 286, 519, 300, 727, 312, 1880, 281, 6839, 512, 295, 613, 10577, 13, 51684], "temperature": 0.0, "avg_logprob": -0.21796391057033165, "compression_ratio": 1.9051724137931034, "no_speech_prob": 0.030655639246106148}, {"id": 897, "seek": 416898, "start": 4169.0199999999995, "end": 4176.58, "text": " And of course, we have this very nice framework that allows us to easily plug and play, you know, different networks and try that aspect out as well.", "tokens": [50366, 400, 295, 1164, 11, 321, 362, 341, 588, 1481, 8388, 300, 4045, 505, 281, 3612, 5452, 293, 862, 11, 291, 458, 11, 819, 9590, 293, 853, 300, 4171, 484, 382, 731, 13, 50744], "temperature": 0.0, "avg_logprob": -0.2924561849454554, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.04023391753435135}, {"id": 898, "seek": 416898, "start": 4177.419999999999, "end": 4177.62, "text": " Yeah.", "tokens": [50786, 865, 13, 50796], "temperature": 0.0, "avg_logprob": -0.2924561849454554, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.04023391753435135}, {"id": 899, "seek": 416898, "start": 4177.62, "end": 4188.62, "text": " And in particular, I think taking a ConvNext or a ResNet or something and replacing its head with a VGG head would be an interesting thing to try.", "tokens": [50796, 400, 294, 1729, 11, 286, 519, 1940, 257, 2656, 85, 45, 3121, 83, 420, 257, 5015, 31890, 420, 746, 293, 19139, 1080, 1378, 365, 257, 691, 27561, 1378, 576, 312, 364, 1880, 551, 281, 853, 13, 51346], "temperature": 0.0, "avg_logprob": -0.2924561849454554, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.04023391753435135}, {"id": 900, "seek": 416898, "start": 4190.339999999999, "end": 4190.62, "text": " Yeah.", "tokens": [51432, 865, 13, 51446], "temperature": 0.0, "avg_logprob": -0.2924561849454554, "compression_ratio": 1.4807692307692308, "no_speech_prob": 0.04023391753435135}, {"id": 901, "seek": 419062, "start": 4191.5, "end": 4207.18, "text": " And then on the experimentation version, one of the things that when we were developing this, I said to Jeremy was like, ah, we're doing all this work, setting up these callbacks and things, you know, isn't it nicer to just have like, here's my image that I'm optimizing, set up an optimizer, set up my loss function and do this optimization loop?", "tokens": [50408, 400, 550, 322, 264, 37142, 3037, 11, 472, 295, 264, 721, 300, 562, 321, 645, 6416, 341, 11, 286, 848, 281, 17809, 390, 411, 11, 3716, 11, 321, 434, 884, 439, 341, 589, 11, 3287, 493, 613, 818, 17758, 293, 721, 11, 291, 458, 11, 1943, 380, 309, 22842, 281, 445, 362, 411, 11, 510, 311, 452, 3256, 300, 286, 478, 40425, 11, 992, 493, 364, 5028, 6545, 11, 992, 493, 452, 4470, 2445, 293, 360, 341, 19618, 6367, 30, 51192], "temperature": 0.0, "avg_logprob": -0.273762948172433, "compression_ratio": 1.786833855799373, "no_speech_prob": 0.6036404371261597}, {"id": 902, "seek": 419062, "start": 4207.7, "end": 4213.66, "text": " And the answer is that it is theoretically easier when you just want to do this once.", "tokens": [51218, 400, 264, 1867, 307, 300, 309, 307, 29400, 3571, 562, 291, 445, 528, 281, 360, 341, 1564, 13, 51516], "temperature": 0.0, "avg_logprob": -0.273762948172433, "compression_ratio": 1.786833855799373, "no_speech_prob": 0.6036404371261597}, {"id": 903, "seek": 419062, "start": 4213.7, "end": 4218.099999999999, "text": " Like, and that's why you see in a tutorial or something, you keep this as minimal as possible.", "tokens": [51518, 1743, 11, 293, 300, 311, 983, 291, 536, 294, 257, 7073, 420, 746, 11, 291, 1066, 341, 382, 13206, 382, 1944, 13, 51738], "temperature": 0.0, "avg_logprob": -0.273762948172433, "compression_ratio": 1.786833855799373, "no_speech_prob": 0.6036404371261597}, {"id": 904, "seek": 419062, "start": 4218.099999999999, "end": 4219.62, "text": " You just want to show what style loss is.", "tokens": [51738, 509, 445, 528, 281, 855, 437, 3758, 4470, 307, 13, 51814], "temperature": 0.0, "avg_logprob": -0.273762948172433, "compression_ratio": 1.786833855799373, "no_speech_prob": 0.6036404371261597}, {"id": 905, "seek": 421962, "start": 4220.38, "end": 4225.66, "text": " But as soon as you say, OK, I'd like to try this again, but adding a different layer.", "tokens": [50402, 583, 382, 2321, 382, 291, 584, 11, 2264, 11, 286, 1116, 411, 281, 853, 341, 797, 11, 457, 5127, 257, 819, 4583, 13, 50666], "temperature": 0.0, "avg_logprob": -0.21174023249377943, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.006589401513338089}, {"id": 906, "seek": 421962, "start": 4225.66, "end": 4232.0599999999995, "text": " So maybe let me do another cell and then copying and pasting over a bunch, you know, and then you say, oh, let me add some progress stuff.", "tokens": [50666, 407, 1310, 718, 385, 360, 1071, 2815, 293, 550, 27976, 293, 1791, 278, 670, 257, 3840, 11, 291, 458, 11, 293, 550, 291, 584, 11, 1954, 11, 718, 385, 909, 512, 4205, 1507, 13, 50986], "temperature": 0.0, "avg_logprob": -0.21174023249377943, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.006589401513338089}, {"id": 907, "seek": 421962, "start": 4232.0599999999995, "end": 4235.3, "text": " So images, you know, it gets messy really quickly.", "tokens": [50986, 407, 5267, 11, 291, 458, 11, 309, 2170, 16191, 534, 2661, 13, 51148], "temperature": 0.0, "avg_logprob": -0.21174023249377943, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.006589401513338089}, {"id": 908, "seek": 421962, "start": 4235.9, "end": 4247.26, "text": " As soon as you want to save images for a video and you want to mess with the loss function and you want to do some sort of annealing on your learning rate, each of these things is going to grow this loop into something messier and messier.", "tokens": [51178, 1018, 2321, 382, 291, 528, 281, 3155, 5267, 337, 257, 960, 293, 291, 528, 281, 2082, 365, 264, 4470, 2445, 293, 291, 528, 281, 360, 512, 1333, 295, 22256, 4270, 322, 428, 2539, 3314, 11, 1184, 295, 613, 721, 307, 516, 281, 1852, 341, 6367, 666, 746, 2082, 811, 293, 2082, 811, 13, 51746], "temperature": 0.0, "avg_logprob": -0.21174023249377943, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.006589401513338089}, {"id": 909, "seek": 421962, "start": 4248.099999999999, "end": 4248.34, "text": " Yeah.", "tokens": [51788, 865, 13, 51800], "temperature": 0.0, "avg_logprob": -0.21174023249377943, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.006589401513338089}, {"id": 910, "seek": 421962, "start": 4248.34, "end": 4249.22, "text": " And so I thought it was fun.", "tokens": [51800, 400, 370, 286, 1194, 309, 390, 1019, 13, 51844], "temperature": 0.0, "avg_logprob": -0.21174023249377943, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.006589401513338089}, {"id": 911, "seek": 424922, "start": 4249.22, "end": 4267.9400000000005, "text": " Like, I was very quickly a convert to being able to experiment with a completely new version with minimal lines of code, minimal changes and having everything in its own piece, like the image logging or if you wanted to make a little movie showing the progress, that goes in a separate callback.", "tokens": [50364, 1743, 11, 286, 390, 588, 2661, 257, 7620, 281, 885, 1075, 281, 5120, 365, 257, 2584, 777, 3037, 365, 13206, 3876, 295, 3089, 11, 13206, 2962, 293, 1419, 1203, 294, 1080, 1065, 2522, 11, 411, 264, 3256, 27991, 420, 498, 291, 1415, 281, 652, 257, 707, 3169, 4099, 264, 4205, 11, 300, 1709, 294, 257, 4994, 818, 3207, 13, 51300], "temperature": 0.0, "avg_logprob": -0.2777904608310797, "compression_ratio": 1.63, "no_speech_prob": 0.0018101574387401342}, {"id": 912, "seek": 424922, "start": 4268.22, "end": 4273.34, "text": " You want to tweak the model, you're just tweaking one thing, but maybe all the other infrastructure can stay the same.", "tokens": [51314, 509, 528, 281, 29879, 264, 2316, 11, 291, 434, 445, 6986, 2456, 472, 551, 11, 457, 1310, 439, 264, 661, 6896, 393, 1754, 264, 912, 13, 51570], "temperature": 0.0, "avg_logprob": -0.2777904608310797, "compression_ratio": 1.63, "no_speech_prob": 0.0018101574387401342}, {"id": 913, "seek": 424922, "start": 4274.22, "end": 4274.42, "text": " Yeah.", "tokens": [51614, 865, 13, 51624], "temperature": 0.0, "avg_logprob": -0.2777904608310797, "compression_ratio": 1.63, "no_speech_prob": 0.0018101574387401342}, {"id": 914, "seek": 424922, "start": 4274.46, "end": 4275.38, "text": " So that was pretty cool.", "tokens": [51626, 407, 300, 390, 1238, 1627, 13, 51672], "temperature": 0.0, "avg_logprob": -0.2777904608310797, "compression_ratio": 1.63, "no_speech_prob": 0.0018101574387401342}, {"id": 915, "seek": 424922, "start": 4275.46, "end": 4277.900000000001, "text": " I mean, there's not like one answer, right?", "tokens": [51676, 286, 914, 11, 456, 311, 406, 411, 472, 1867, 11, 558, 30, 51798], "temperature": 0.0, "avg_logprob": -0.2777904608310797, "compression_ratio": 1.63, "no_speech_prob": 0.0018101574387401342}, {"id": 916, "seek": 427790, "start": 4277.9, "end": 4279.0599999999995, "text": " Like it's, yeah.", "tokens": [50364, 1743, 309, 311, 11, 1338, 13, 50422], "temperature": 0.0, "avg_logprob": -0.35157012939453125, "compression_ratio": 1.6161137440758293, "no_speech_prob": 0.0012842481955885887}, {"id": 917, "seek": 427790, "start": 4279.46, "end": 4284.86, "text": " Use the right layer of abstraction for what you're doing at the right time.", "tokens": [50442, 8278, 264, 558, 4583, 295, 37765, 337, 437, 291, 434, 884, 412, 264, 558, 565, 13, 50712], "temperature": 0.0, "avg_logprob": -0.35157012939453125, "compression_ratio": 1.6161137440758293, "no_speech_prob": 0.0012842481955885887}, {"id": 918, "seek": 427790, "start": 4284.86, "end": 4307.42, "text": " Like something I actually think people do too much of when they use the fast AI library is jumping straight into data blocks, for example, even though they might be working on a slightly more custom thing where data blocks, there isn't a data block", "tokens": [50712, 1743, 746, 286, 767, 519, 561, 360, 886, 709, 295, 562, 436, 764, 264, 2370, 7318, 6405, 307, 11233, 2997, 666, 1412, 8474, 11, 337, 1365, 11, 754, 1673, 436, 1062, 312, 1364, 322, 257, 4748, 544, 2375, 551, 689, 1412, 8474, 11, 456, 1943, 380, 257, 1412, 3461, 51840], "temperature": 0.0, "avg_logprob": -0.35157012939453125, "compression_ratio": 1.6161137440758293, "no_speech_prob": 0.0012842481955885887}, {"id": 919, "seek": 430742, "start": 4307.46, "end": 4308.62, "text": " already written for them.", "tokens": [50366, 1217, 3720, 337, 552, 13, 50424], "temperature": 0.0, "avg_logprob": -0.27526291933926667, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.0010817066067829728}, {"id": 920, "seek": 430742, "start": 4308.9800000000005, "end": 4311.54, "text": " And so then step one is like, oh, write a data block.", "tokens": [50442, 400, 370, 550, 1823, 472, 307, 411, 11, 1954, 11, 2464, 257, 1412, 3461, 13, 50570], "temperature": 0.0, "avg_logprob": -0.27526291933926667, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.0010817066067829728}, {"id": 921, "seek": 430742, "start": 4311.9400000000005, "end": 4313.06, "text": " That's not at all easy.", "tokens": [50590, 663, 311, 406, 412, 439, 1858, 13, 50646], "temperature": 0.0, "avg_logprob": -0.27526291933926667, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.0010817066067829728}, {"id": 922, "seek": 430742, "start": 4313.34, "end": 4316.3, "text": " And you actually want to be focusing on building your model.", "tokens": [50660, 400, 291, 767, 528, 281, 312, 8416, 322, 2390, 428, 2316, 13, 50808], "temperature": 0.0, "avg_logprob": -0.27526291933926667, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.0010817066067829728}, {"id": 923, "seek": 430742, "start": 4316.86, "end": 4321.18, "text": " So I kind of say to people, oh, well, like, you know, go, go down a layer of abstraction.", "tokens": [50836, 407, 286, 733, 295, 584, 281, 561, 11, 1954, 11, 731, 11, 411, 11, 291, 458, 11, 352, 11, 352, 760, 257, 4583, 295, 37765, 13, 51052], "temperature": 0.0, "avg_logprob": -0.27526291933926667, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.0010817066067829728}, {"id": 924, "seek": 430742, "start": 4321.78, "end": 4328.86, "text": " Now I will say I don't very often start at the very lowest level of abstraction.", "tokens": [51082, 823, 286, 486, 584, 286, 500, 380, 588, 2049, 722, 412, 264, 588, 12437, 1496, 295, 37765, 13, 51436], "temperature": 0.0, "avg_logprob": -0.27526291933926667, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.0010817066067829728}, {"id": 925, "seek": 430742, "start": 4328.86, "end": 4335.9800000000005, "text": " So something like the very last thing that you showed, Jono, just because in my experience, I'm not good enough to do that.", "tokens": [51436, 407, 746, 411, 264, 588, 1036, 551, 300, 291, 4712, 11, 7745, 78, 11, 445, 570, 294, 452, 1752, 11, 286, 478, 406, 665, 1547, 281, 360, 300, 13, 51792], "temperature": 0.0, "avg_logprob": -0.27526291933926667, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.0010817066067829728}, {"id": 926, "seek": 430742, "start": 4336.34, "end": 4336.82, "text": " Right.", "tokens": [51810, 1779, 13, 51834], "temperature": 0.0, "avg_logprob": -0.27526291933926667, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.0010817066067829728}, {"id": 927, "seek": 433682, "start": 4336.94, "end": 4358.5, "text": " And so like most of the time I, yeah, I'll forget zero grad or I'll just mess up something, especially if I want to like have it run reasonably quickly by using like, you know, FB16, mixed precision or, you know, or I'll be like, oh, now I've got to like think about how to put a metrics in so that I can see it's training properly.", "tokens": [50370, 400, 370, 411, 881, 295, 264, 565, 286, 11, 1338, 11, 286, 603, 2870, 4018, 2771, 420, 286, 603, 445, 2082, 493, 746, 11, 2318, 498, 286, 528, 281, 411, 362, 309, 1190, 23551, 2661, 538, 1228, 411, 11, 291, 458, 11, 479, 33, 6866, 11, 7467, 18356, 420, 11, 291, 458, 11, 420, 286, 603, 312, 411, 11, 1954, 11, 586, 286, 600, 658, 281, 411, 519, 466, 577, 281, 829, 257, 16367, 294, 370, 300, 286, 393, 536, 309, 311, 3097, 6108, 13, 51448], "temperature": 0.0, "avg_logprob": -0.2865208606330716, "compression_ratio": 1.5407725321888412, "no_speech_prob": 0.0002780228678602725}, {"id": 928, "seek": 433682, "start": 4358.5, "end": 4360.219999999999, "text": " And I always mess that up.", "tokens": [51448, 400, 286, 1009, 2082, 300, 493, 13, 51534], "temperature": 0.0, "avg_logprob": -0.2865208606330716, "compression_ratio": 1.5407725321888412, "no_speech_prob": 0.0002780228678602725}, {"id": 929, "seek": 436022, "start": 4360.62, "end": 4368.02, "text": " So I don't often go to that level, but I do like quite often start at a reasonably low level.", "tokens": [50384, 407, 286, 500, 380, 2049, 352, 281, 300, 1496, 11, 457, 286, 360, 411, 1596, 2049, 722, 412, 257, 23551, 2295, 1496, 13, 50754], "temperature": 0.0, "avg_logprob": -0.2957637679408973, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.2226392924785614}, {"id": 930, "seek": 436022, "start": 4368.02, "end": 4376.9400000000005, "text": " And I think with mini AI now we all have this tool where we fully understand all the layers and there aren't that many.", "tokens": [50754, 400, 286, 519, 365, 8382, 7318, 586, 321, 439, 362, 341, 2290, 689, 321, 4498, 1223, 439, 264, 7914, 293, 456, 3212, 380, 300, 867, 13, 51200], "temperature": 0.0, "avg_logprob": -0.2957637679408973, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.2226392924785614}, {"id": 931, "seek": 436022, "start": 4378.14, "end": 4383.22, "text": " And yeah, you could like write your own train CB or whatever.", "tokens": [51260, 400, 1338, 11, 291, 727, 411, 2464, 428, 1065, 3847, 18745, 420, 2035, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2957637679408973, "compression_ratio": 1.5193370165745856, "no_speech_prob": 0.2226392924785614}, {"id": 932, "seek": 438322, "start": 4383.22, "end": 4386.02, "text": " And at least you've got something that makes sure, for example, that, oh, okay.", "tokens": [50364, 400, 412, 1935, 291, 600, 658, 746, 300, 1669, 988, 11, 337, 1365, 11, 300, 11, 1954, 11, 1392, 13, 50504], "temperature": 0.0, "avg_logprob": -0.2940322124596798, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.07156623154878616}, {"id": 933, "seek": 438322, "start": 4386.02, "end": 4391.58, "text": " You remember to use torch.no grad here and you remember to put it in, you know, put it in a vowel mode there.", "tokens": [50504, 509, 1604, 281, 764, 27822, 13, 1771, 2771, 510, 293, 291, 1604, 281, 829, 309, 294, 11, 291, 458, 11, 829, 309, 294, 257, 29410, 4391, 456, 13, 50782], "temperature": 0.0, "avg_logprob": -0.2940322124596798, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.07156623154878616}, {"id": 934, "seek": 438322, "start": 4392.34, "end": 4395.46, "text": " But, you know, those things will be done correctly.", "tokens": [50820, 583, 11, 291, 458, 11, 729, 721, 486, 312, 1096, 8944, 13, 50976], "temperature": 0.0, "avg_logprob": -0.2940322124596798, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.07156623154878616}, {"id": 935, "seek": 438322, "start": 4395.820000000001, "end": 4403.14, "text": " And you'll be able to easily run a learning rate finder and easily have it run on Cuda and, you know, or whatever device you're on.", "tokens": [50994, 400, 291, 603, 312, 1075, 281, 3612, 1190, 257, 2539, 3314, 915, 260, 293, 3612, 362, 309, 1190, 322, 383, 11152, 293, 11, 291, 458, 11, 420, 2035, 4302, 291, 434, 322, 13, 51360], "temperature": 0.0, "avg_logprob": -0.2940322124596798, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.07156623154878616}, {"id": 936, "seek": 438322, "start": 4403.14, "end": 4412.5, "text": " So I think, you know, hopefully this is a good place for people now to have a framework that they can call their own.", "tokens": [51360, 407, 286, 519, 11, 291, 458, 11, 4696, 341, 307, 257, 665, 1081, 337, 561, 586, 281, 362, 257, 8388, 300, 436, 393, 818, 641, 1065, 13, 51828], "temperature": 0.0, "avg_logprob": -0.2940322124596798, "compression_ratio": 1.7167832167832169, "no_speech_prob": 0.07156623154878616}, {"id": 937, "seek": 441250, "start": 4412.78, "end": 4415.82, "text": " You know, and use as much as there's no good as big sense.", "tokens": [50378, 509, 458, 11, 293, 764, 382, 709, 382, 264, 265, 311, 572, 665, 382, 955, 2020, 13, 50530], "temperature": 0.0, "avg_logprob": -0.3544235555534689, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0005111782229505479}, {"id": 938, "seek": 441250, "start": 4417.14, "end": 4423.9, "text": " The other nice thing is of course, like there are multiple ways of doing the same thing and it's like whatever way maybe works better for you.", "tokens": [50596, 440, 661, 1481, 551, 307, 295, 1164, 11, 411, 456, 366, 3866, 2098, 295, 884, 264, 912, 551, 293, 309, 311, 411, 2035, 636, 1310, 1985, 1101, 337, 291, 13, 50934], "temperature": 0.0, "avg_logprob": -0.3544235555534689, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0005111782229505479}, {"id": 939, "seek": 441250, "start": 4423.9, "end": 4425.14, "text": " You can implement that.", "tokens": [50934, 509, 393, 4445, 300, 13, 50996], "temperature": 0.0, "avg_logprob": -0.3544235555534689, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0005111782229505479}, {"id": 940, "seek": 441250, "start": 4425.14, "end": 4436.22, "text": " Like, for example, Jonathan showed with the image opt callback, you know, you could implement that in different ways and whichever one I guess is easier for you to understand or easier for you to work with.", "tokens": [50996, 1743, 11, 337, 1365, 11, 15471, 4712, 365, 264, 3256, 2427, 818, 3207, 11, 291, 458, 11, 291, 727, 4445, 300, 294, 819, 2098, 293, 24123, 472, 286, 2041, 307, 3571, 337, 291, 281, 1223, 420, 3571, 337, 291, 281, 589, 365, 13, 51550], "temperature": 0.0, "avg_logprob": -0.3544235555534689, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0005111782229505479}, {"id": 941, "seek": 441250, "start": 4436.3, "end": 4438.46, "text": " It's, you can implement it that way.", "tokens": [51554, 467, 311, 11, 291, 393, 4445, 309, 300, 636, 13, 51662], "temperature": 0.0, "avg_logprob": -0.3544235555534689, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0005111782229505479}, {"id": 942, "seek": 443846, "start": 4438.46, "end": 4442.7, "text": " And yeah, MiniAI is flexible in multiple ways.", "tokens": [50364, 400, 1338, 11, 18239, 48698, 307, 11358, 294, 3866, 2098, 13, 50576], "temperature": 0.0, "avg_logprob": -0.3048604115718553, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.01205336581915617}, {"id": 943, "seek": 443846, "start": 4442.7, "end": 4446.58, "text": " So that's the especially one thing I really enjoy about it.", "tokens": [50576, 407, 300, 311, 264, 2318, 472, 551, 286, 534, 2103, 466, 309, 13, 50770], "temperature": 0.0, "avg_logprob": -0.3048604115718553, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.01205336581915617}, {"id": 944, "seek": 443846, "start": 4447.02, "end": 4447.34, "text": " Yeah.", "tokens": [50792, 865, 13, 50808], "temperature": 0.0, "avg_logprob": -0.3048604115718553, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.01205336581915617}, {"id": 945, "seek": 443846, "start": 4447.42, "end": 4460.34, "text": " And there's one extreme of like weirdness, I think, which is like Jono's like using MiniAI for something that we never really considered making it for, which is like, it's not even looping through data.", "tokens": [50812, 400, 456, 311, 472, 8084, 295, 411, 3657, 1287, 11, 286, 519, 11, 597, 307, 411, 7745, 78, 311, 411, 1228, 18239, 48698, 337, 746, 300, 321, 1128, 534, 4888, 1455, 309, 337, 11, 597, 307, 411, 11, 309, 311, 406, 754, 6367, 278, 807, 1412, 13, 51458], "temperature": 0.0, "avg_logprob": -0.3048604115718553, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.01205336581915617}, {"id": 946, "seek": 443846, "start": 4460.66, "end": 4463.18, "text": " It's just looping through loops.", "tokens": [51474, 467, 311, 445, 6367, 278, 807, 16121, 13, 51600], "temperature": 0.0, "avg_logprob": -0.3048604115718553, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.01205336581915617}, {"id": 947, "seek": 443846, "start": 4463.46, "end": 4466.22, "text": " So, you know, this is about as weird as it's going to get, I guess.", "tokens": [51614, 407, 11, 291, 458, 11, 341, 307, 466, 382, 3657, 382, 309, 311, 516, 281, 483, 11, 286, 2041, 13, 51752], "temperature": 0.0, "avg_logprob": -0.3048604115718553, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.01205336581915617}, {"id": 948, "seek": 443846, "start": 4466.78, "end": 4467.14, "text": " Yeah.", "tokens": [51780, 865, 13, 51798], "temperature": 0.0, "avg_logprob": -0.3048604115718553, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.01205336581915617}, {"id": 949, "seek": 446714, "start": 4467.3, "end": 4469.700000000001, "text": " Well, the next notebook is about as weird as it's going to get, I think.", "tokens": [50372, 1042, 11, 264, 958, 21060, 307, 466, 382, 3657, 382, 309, 311, 516, 281, 483, 11, 286, 519, 13, 50492], "temperature": 0.0, "avg_logprob": -0.26033794346140393, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.00844503939151764}, {"id": 950, "seek": 446714, "start": 4469.9800000000005, "end": 4470.9400000000005, "text": " Oh, great.", "tokens": [50506, 876, 11, 869, 13, 50554], "temperature": 0.0, "avg_logprob": -0.26033794346140393, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.00844503939151764}, {"id": 951, "seek": 446714, "start": 4471.780000000001, "end": 4472.1, "text": " Yeah.", "tokens": [50596, 865, 13, 50612], "temperature": 0.0, "avg_logprob": -0.26033794346140393, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.00844503939151764}, {"id": 952, "seek": 446714, "start": 4473.1, "end": 4473.34, "text": " Okay.", "tokens": [50662, 1033, 13, 50674], "temperature": 0.0, "avg_logprob": -0.26033794346140393, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.00844503939151764}, {"id": 953, "seek": 446714, "start": 4473.34, "end": 4480.700000000001, "text": " So before we move on to what we're going to do next is use this kind of style loss in an even funkier way to train a different kind of thing.", "tokens": [50674, 407, 949, 321, 1286, 322, 281, 437, 321, 434, 516, 281, 360, 958, 307, 764, 341, 733, 295, 3758, 4470, 294, 364, 754, 26476, 811, 636, 281, 3847, 257, 819, 733, 295, 551, 13, 51042], "temperature": 0.0, "avg_logprob": -0.26033794346140393, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.00844503939151764}, {"id": 954, "seek": 446714, "start": 4481.38, "end": 4488.18, "text": " But before we do that, I did want to just call out like using these pre-trained networks as very smart feature extractors is pretty powerful.", "tokens": [51076, 583, 949, 321, 360, 300, 11, 286, 630, 528, 281, 445, 818, 484, 411, 1228, 613, 659, 12, 17227, 2001, 9590, 382, 588, 4069, 4111, 8947, 830, 307, 1238, 4005, 13, 51416], "temperature": 0.0, "avg_logprob": -0.26033794346140393, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.00844503939151764}, {"id": 955, "seek": 446714, "start": 4488.660000000001, "end": 4493.900000000001, "text": " And unlike the kind of fun, crazy example that we're going to look at just now, they also have very valid uses.", "tokens": [51440, 400, 8343, 264, 733, 295, 1019, 11, 3219, 1365, 300, 321, 434, 516, 281, 574, 412, 445, 586, 11, 436, 611, 362, 588, 7363, 4960, 13, 51702], "temperature": 0.0, "avg_logprob": -0.26033794346140393, "compression_ratio": 1.6476510067114094, "no_speech_prob": 0.00844503939151764}, {"id": 956, "seek": 449390, "start": 4493.9, "end": 4504.179999999999, "text": " So if you're doing like a super resolution or even something like diffusion, adding in a perceptual loss or even a style loss to your target image, it can improve things.", "tokens": [50364, 407, 498, 291, 434, 884, 411, 257, 1687, 8669, 420, 754, 746, 411, 25242, 11, 5127, 294, 257, 43276, 901, 4470, 420, 754, 257, 3758, 4470, 281, 428, 3779, 3256, 11, 309, 393, 3470, 721, 13, 50878], "temperature": 0.0, "avg_logprob": -0.24777400052105938, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.023327957838773727}, {"id": 957, "seek": 449390, "start": 4504.299999999999, "end": 4513.9, "text": " We've played around with using perceptual loss for diffusion or even during, like, say you want to generate an image that matches a face in some kind of image to image thing with stable diffusion.", "tokens": [50884, 492, 600, 3737, 926, 365, 1228, 43276, 901, 4470, 337, 25242, 420, 754, 1830, 11, 411, 11, 584, 291, 528, 281, 8460, 364, 3256, 300, 10676, 257, 1851, 294, 512, 733, 295, 3256, 281, 3256, 551, 365, 8351, 25242, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24777400052105938, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.023327957838773727}, {"id": 958, "seek": 449390, "start": 4514.219999999999, "end": 4519.86, "text": " Maybe you have an extra guidance function that makes sure that structurally it matches, but maybe a text really doesn't.", "tokens": [51380, 2704, 291, 362, 364, 2857, 10056, 2445, 300, 1669, 988, 300, 6594, 6512, 309, 10676, 11, 457, 1310, 257, 2487, 534, 1177, 380, 13, 51662], "temperature": 0.0, "avg_logprob": -0.24777400052105938, "compression_ratio": 1.8007380073800738, "no_speech_prob": 0.023327957838773727}, {"id": 959, "seek": 451986, "start": 4520.259999999999, "end": 4528.78, "text": " Maybe you want to pass in a style image and have that guide to the diffusion process to be a particular style without having to say, you know, in the style of Vincent van Gogh's Starry Night.", "tokens": [50384, 2704, 291, 528, 281, 1320, 294, 257, 3758, 3256, 293, 362, 300, 5934, 281, 264, 25242, 1399, 281, 312, 257, 1729, 3758, 1553, 1419, 281, 584, 11, 291, 458, 11, 294, 264, 3758, 295, 28003, 3161, 39690, 71, 311, 5705, 627, 10190, 13, 50810], "temperature": 0.0, "avg_logprob": -0.25219641991381375, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.019717365503311157}, {"id": 960, "seek": 451986, "start": 4529.94, "end": 4530.219999999999, "text": " Yeah.", "tokens": [50868, 865, 13, 50882], "temperature": 0.0, "avg_logprob": -0.25219641991381375, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.019717365503311157}, {"id": 961, "seek": 451986, "start": 4530.219999999999, "end": 4542.82, "text": " And for all sorts of like image to image tasks, this perceptual, this idea of like using the features from a network like VGG, it does actually have lots of practical uses apart from just this artistic and kind of fiddling.", "tokens": [50882, 400, 337, 439, 7527, 295, 411, 3256, 281, 3256, 9608, 11, 341, 43276, 901, 11, 341, 1558, 295, 411, 1228, 264, 4122, 490, 257, 3209, 411, 691, 27561, 11, 309, 775, 767, 362, 3195, 295, 8496, 4960, 4936, 490, 445, 341, 17090, 293, 733, 295, 283, 14273, 1688, 13, 51512], "temperature": 0.0, "avg_logprob": -0.25219641991381375, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.019717365503311157}, {"id": 962, "seek": 451986, "start": 4544.339999999999, "end": 4544.62, "text": " Okay.", "tokens": [51588, 1033, 13, 51602], "temperature": 0.0, "avg_logprob": -0.25219641991381375, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.019717365503311157}, {"id": 963, "seek": 454462, "start": 4544.74, "end": 4551.0599999999995, "text": " So speaking of artistic fiddling, we're going to look at something a little bit more niche now called neural cellular automata.", "tokens": [50370, 407, 4124, 295, 17090, 283, 14273, 1688, 11, 321, 434, 516, 281, 574, 412, 746, 257, 707, 857, 544, 19956, 586, 1219, 18161, 29267, 3553, 3274, 13, 50686], "temperature": 0.0, "avg_logprob": -0.2266944018277255, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.007010431960225105}, {"id": 964, "seek": 454462, "start": 4551.58, "end": 4554.9, "text": " And so try and spend about half an hour on this before we move on to the next section.", "tokens": [50712, 400, 370, 853, 293, 3496, 466, 1922, 364, 1773, 322, 341, 949, 321, 1286, 322, 281, 264, 958, 3541, 13, 50878], "temperature": 0.0, "avg_logprob": -0.2266944018277255, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.007010431960225105}, {"id": 965, "seek": 454462, "start": 4555.38, "end": 4557.7, "text": " And so this is off the beaten track.", "tokens": [50902, 400, 370, 341, 307, 766, 264, 17909, 2837, 13, 51018], "temperature": 0.0, "avg_logprob": -0.2266944018277255, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.007010431960225105}, {"id": 966, "seek": 454462, "start": 4557.9, "end": 4566.82, "text": " It's a really fun domain of, yeah, like combining a lot of different fields, all of which I'm quite excited about.", "tokens": [51028, 467, 311, 257, 534, 1019, 9274, 295, 11, 1338, 11, 411, 21928, 257, 688, 295, 819, 7909, 11, 439, 295, 597, 286, 478, 1596, 2919, 466, 13, 51474], "temperature": 0.0, "avg_logprob": -0.2266944018277255, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.007010431960225105}, {"id": 967, "seek": 454462, "start": 4566.82, "end": 4570.62, "text": " And so you may be familiar with like kind of classic cellular automata.", "tokens": [51474, 400, 370, 291, 815, 312, 4963, 365, 411, 733, 295, 7230, 29267, 3553, 3274, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2266944018277255, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.007010431960225105}, {"id": 968, "seek": 457062, "start": 4571.14, "end": 4573.94, "text": " So if we look at Conway's Game of Life,", "tokens": [50390, 407, 498, 321, 574, 412, 2656, 676, 311, 7522, 295, 7720, 11, 50530], "temperature": 0.0, "avg_logprob": -0.44274250296659245, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.009267210960388184}, {"id": 969, "seek": 457062, "start": 4576.9, "end": 4585.14, "text": " Oops, I misspelled it, but you've probably seen this kind of classic Conway's Game of Life.", "tokens": [50678, 21726, 11, 286, 1713, 33000, 309, 11, 457, 291, 600, 1391, 1612, 341, 733, 295, 7230, 2656, 676, 311, 7522, 295, 7720, 13, 51090], "temperature": 0.0, "avg_logprob": -0.44274250296659245, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.009267210960388184}, {"id": 970, "seek": 457062, "start": 4585.14, "end": 4588.22, "text": " I almost came up with that game of life when I was a kid.", "tokens": [51090, 286, 1920, 1361, 493, 365, 300, 1216, 295, 993, 562, 286, 390, 257, 1636, 13, 51244], "temperature": 0.0, "avg_logprob": -0.44274250296659245, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.009267210960388184}, {"id": 971, "seek": 457062, "start": 4589.0599999999995, "end": 4589.54, "text": " Yeah.", "tokens": [51286, 865, 13, 51310], "temperature": 0.0, "avg_logprob": -0.44274250296659245, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.009267210960388184}, {"id": 972, "seek": 457062, "start": 4590.0199999999995, "end": 4595.42, "text": " So the idea here is that you have all of these independent cells and each cell can only see its neighbors.", "tokens": [51334, 407, 264, 1558, 510, 307, 300, 291, 362, 439, 295, 613, 6695, 5438, 293, 1184, 2815, 393, 787, 536, 1080, 12512, 13, 51604], "temperature": 0.0, "avg_logprob": -0.44274250296659245, "compression_ratio": 1.5024875621890548, "no_speech_prob": 0.009267210960388184}, {"id": 973, "seek": 459542, "start": 4595.82, "end": 4598.18, "text": " And you have some sort of update rule, right?", "tokens": [50384, 400, 291, 362, 512, 1333, 295, 5623, 4978, 11, 558, 30, 50502], "temperature": 0.0, "avg_logprob": -0.21652863088962251, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.07920211553573608}, {"id": 974, "seek": 459542, "start": 4598.18, "end": 4602.78, "text": " That says if a cell has three neighbors, it's going to remain the same state for the next one.", "tokens": [50502, 663, 1619, 498, 257, 2815, 575, 1045, 12512, 11, 309, 311, 516, 281, 6222, 264, 912, 1785, 337, 264, 958, 472, 13, 50732], "temperature": 0.0, "avg_logprob": -0.21652863088962251, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.07920211553573608}, {"id": 975, "seek": 459542, "start": 4602.78, "end": 4606.74, "text": " If it has only one neighbor, it's going to die in the next iteration.", "tokens": [50732, 759, 309, 575, 787, 472, 5987, 11, 309, 311, 516, 281, 978, 294, 264, 958, 24784, 13, 50930], "temperature": 0.0, "avg_logprob": -0.21652863088962251, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.07920211553573608}, {"id": 976, "seek": 459542, "start": 4607.26, "end": 4618.02, "text": " And so this is a really cool example of like a distributed system or self-organizing system where there's no like global communication or anything.", "tokens": [50956, 400, 370, 341, 307, 257, 534, 1627, 1365, 295, 411, 257, 12631, 1185, 420, 2698, 12, 12372, 3319, 1185, 689, 456, 311, 572, 411, 4338, 6101, 420, 1340, 13, 51494], "temperature": 0.0, "avg_logprob": -0.21652863088962251, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.07920211553573608}, {"id": 977, "seek": 459542, "start": 4618.02, "end": 4619.9, "text": " Each cell can only look at its immediate neighbors.", "tokens": [51494, 6947, 2815, 393, 787, 574, 412, 1080, 11629, 12512, 13, 51588], "temperature": 0.0, "avg_logprob": -0.21652863088962251, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.07920211553573608}, {"id": 978, "seek": 459542, "start": 4620.14, "end": 4622.46, "text": " And typically the rules are really small and simple.", "tokens": [51600, 400, 5850, 264, 4474, 366, 534, 1359, 293, 2199, 13, 51716], "temperature": 0.0, "avg_logprob": -0.21652863088962251, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.07920211553573608}, {"id": 979, "seek": 462246, "start": 4623.06, "end": 4626.42, "text": " And so we can use these to model these complex systems.", "tokens": [50394, 400, 370, 321, 393, 764, 613, 281, 2316, 613, 3997, 3652, 13, 50562], "temperature": 0.0, "avg_logprob": -0.2988968112251975, "compression_ratio": 1.5625, "no_speech_prob": 0.0013669825857505202}, {"id": 980, "seek": 462246, "start": 4626.54, "end": 4636.78, "text": " It's very much inspired by biology where we actually do have huge, you know, arrangements of cells, each of which is only seeing its neighborhood, like sensing chemicals in the bloodstream next to it and so on.", "tokens": [50568, 467, 311, 588, 709, 7547, 538, 14956, 689, 321, 767, 360, 362, 2603, 11, 291, 458, 11, 22435, 295, 5438, 11, 1184, 295, 597, 307, 787, 2577, 1080, 7630, 11, 411, 30654, 16152, 294, 264, 3390, 9291, 958, 281, 309, 293, 370, 322, 13, 51080], "temperature": 0.0, "avg_logprob": -0.2988968112251975, "compression_ratio": 1.5625, "no_speech_prob": 0.0013669825857505202}, {"id": 981, "seek": 462246, "start": 4637.14, "end": 4639.14, "text": " And yet somehow they're able to coordinate together.", "tokens": [51098, 400, 1939, 6063, 436, 434, 1075, 281, 15670, 1214, 13, 51198], "temperature": 0.0, "avg_logprob": -0.2988968112251975, "compression_ratio": 1.5625, "no_speech_prob": 0.0013669825857505202}, {"id": 982, "seek": 462246, "start": 4639.78, "end": 4644.82, "text": " I watched a really cool video the other day about ants.", "tokens": [51230, 286, 6337, 257, 534, 1627, 960, 264, 661, 786, 466, 23355, 13, 51482], "temperature": 0.0, "avg_logprob": -0.2988968112251975, "compression_ratio": 1.5625, "no_speech_prob": 0.0013669825857505202}, {"id": 983, "seek": 464482, "start": 4644.82, "end": 4655.34, "text": " And I didn't know this before, maybe everybody else does, but ants, like huge ant colonies, are organized by like having little chemical signals that the ants around can smell.", "tokens": [50364, 400, 286, 994, 380, 458, 341, 949, 11, 1310, 2201, 1646, 775, 11, 457, 23355, 11, 411, 2603, 2511, 27981, 11, 366, 9983, 538, 411, 1419, 707, 7313, 12354, 300, 264, 23355, 926, 393, 4316, 13, 50890], "temperature": 0.0, "avg_logprob": -0.36325046314912685, "compression_ratio": 1.5648148148148149, "no_speech_prob": 0.06557466834783554}, {"id": 984, "seek": 464482, "start": 4655.7, "end": 4662.0599999999995, "text": " And yeah, it can like organize the entire massive ant colony just using that.", "tokens": [50908, 400, 1338, 11, 309, 393, 411, 13859, 264, 2302, 5994, 2511, 23028, 445, 1228, 300, 13, 51226], "temperature": 0.0, "avg_logprob": -0.36325046314912685, "compression_ratio": 1.5648148148148149, "no_speech_prob": 0.06557466834783554}, {"id": 985, "seek": 464482, "start": 4662.0599999999995, "end": 4664.0199999999995, "text": " I thought it was crazy, but it sounds really similar.", "tokens": [51226, 286, 1194, 309, 390, 3219, 11, 457, 309, 3263, 534, 2531, 13, 51324], "temperature": 0.0, "avg_logprob": -0.36325046314912685, "compression_ratio": 1.5648148148148149, "no_speech_prob": 0.06557466834783554}, {"id": 986, "seek": 464482, "start": 4665.38, "end": 4666.46, "text": " Yeah, yeah.", "tokens": [51392, 865, 11, 1338, 13, 51446], "temperature": 0.0, "avg_logprob": -0.36325046314912685, "compression_ratio": 1.5648148148148149, "no_speech_prob": 0.06557466834783554}, {"id": 987, "seek": 464482, "start": 4667.259999999999, "end": 4668.259999999999, "text": " And you could do.", "tokens": [51486, 400, 291, 727, 360, 13, 51536], "temperature": 0.0, "avg_logprob": -0.36325046314912685, "compression_ratio": 1.5648148148148149, "no_speech_prob": 0.06557466834783554}, {"id": 988, "seek": 466826, "start": 4668.860000000001, "end": 4671.1, "text": " So let me do my tangent.", "tokens": [50394, 407, 718, 385, 360, 452, 27747, 13, 50506], "temperature": 0.0, "avg_logprob": -0.32788796997070313, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.03409693390130997}, {"id": 989, "seek": 466826, "start": 4673.38, "end": 4683.58, "text": " You could do very similar things where you have, yeah, like the trails, the chemical trails being left are just like pixel values in some grid and your ants are just little tiny agents that have some rules.", "tokens": [50620, 509, 727, 360, 588, 2531, 721, 689, 291, 362, 11, 1338, 11, 411, 264, 23024, 11, 264, 7313, 23024, 885, 1411, 366, 445, 411, 19261, 4190, 294, 512, 10748, 293, 428, 23355, 366, 445, 707, 5870, 12554, 300, 362, 512, 4474, 13, 51130], "temperature": 0.0, "avg_logprob": -0.32788796997070313, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.03409693390130997}, {"id": 990, "seek": 466826, "start": 4684.06, "end": 4687.58, "text": " And so I should probably link this here, but this is exactly that kind of system, right?", "tokens": [51154, 400, 370, 286, 820, 1391, 2113, 341, 510, 11, 457, 341, 307, 2293, 300, 733, 295, 1185, 11, 558, 30, 51330], "temperature": 0.0, "avg_logprob": -0.32788796997070313, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.03409693390130997}, {"id": 991, "seek": 466826, "start": 4687.58, "end": 4692.26, "text": " Each little tiny dot, which are almost too small to see, is leaving behind these different trails.", "tokens": [51330, 6947, 707, 5870, 5893, 11, 597, 366, 1920, 886, 1359, 281, 536, 11, 307, 5012, 2261, 613, 819, 23024, 13, 51564], "temperature": 0.0, "avg_logprob": -0.32788796997070313, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.03409693390130997}, {"id": 992, "seek": 466826, "start": 4692.26, "end": 4693.780000000001, "text": " And then that determines the behavior.", "tokens": [51564, 400, 550, 300, 24799, 264, 5223, 13, 51640], "temperature": 0.0, "avg_logprob": -0.32788796997070313, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.03409693390130997}, {"id": 993, "seek": 466826, "start": 4694.26, "end": 4697.7, "text": " The difference between this and what we're going to do today is that.", "tokens": [51664, 440, 2649, 1296, 341, 293, 437, 321, 434, 516, 281, 360, 965, 307, 300, 13, 51836], "temperature": 0.0, "avg_logprob": -0.32788796997070313, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.03409693390130997}, {"id": 994, "seek": 469770, "start": 4697.82, "end": 4702.58, "text": " Just to clarify, I think you've told me before that like actual slime molds kind of do this, right?", "tokens": [50370, 1449, 281, 17594, 11, 286, 519, 291, 600, 1907, 385, 949, 300, 411, 3539, 20650, 48257, 733, 295, 360, 341, 11, 558, 30, 50608], "temperature": 0.0, "avg_logprob": -0.2554670606340681, "compression_ratio": 1.7193548387096773, "no_speech_prob": 0.004198634997010231}, {"id": 995, "seek": 469770, "start": 4702.58, "end": 4703.66, "text": " They're another example.", "tokens": [50608, 814, 434, 1071, 1365, 13, 50662], "temperature": 0.0, "avg_logprob": -0.2554670606340681, "compression_ratio": 1.7193548387096773, "no_speech_prob": 0.004198634997010231}, {"id": 996, "seek": 469770, "start": 4703.66, "end": 4704.179999999999, "text": " Yes.", "tokens": [50662, 1079, 13, 50688], "temperature": 0.0, "avg_logprob": -0.2554670606340681, "compression_ratio": 1.7193548387096773, "no_speech_prob": 0.004198634997010231}, {"id": 997, "seek": 469770, "start": 4704.9, "end": 4705.94, "text": " Yeah, yeah, exactly.", "tokens": [50724, 865, 11, 1338, 11, 2293, 13, 50776], "temperature": 0.0, "avg_logprob": -0.2554670606340681, "compression_ratio": 1.7193548387096773, "no_speech_prob": 0.004198634997010231}, {"id": 998, "seek": 469770, "start": 4705.94, "end": 4707.58, "text": " There's some limited signaling.", "tokens": [50776, 821, 311, 512, 5567, 38639, 13, 50858], "temperature": 0.0, "avg_logprob": -0.2554670606340681, "compression_ratio": 1.7193548387096773, "no_speech_prob": 0.004198634997010231}, {"id": 999, "seek": 469770, "start": 4707.58, "end": 4709.26, "text": " Each one is like, oh, I'm by food.", "tokens": [50858, 6947, 472, 307, 411, 11, 1954, 11, 286, 478, 538, 1755, 13, 50942], "temperature": 0.0, "avg_logprob": -0.2554670606340681, "compression_ratio": 1.7193548387096773, "no_speech_prob": 0.004198634997010231}, {"id": 1000, "seek": 469770, "start": 4709.26, "end": 4713.38, "text": " And then after that, that signal is going to propagate and anything that's moving is going to follow.", "tokens": [50942, 400, 550, 934, 300, 11, 300, 6358, 307, 516, 281, 48256, 293, 1340, 300, 311, 2684, 307, 516, 281, 1524, 13, 51148], "temperature": 0.0, "avg_logprob": -0.2554670606340681, "compression_ratio": 1.7193548387096773, "no_speech_prob": 0.004198634997010231}, {"id": 1001, "seek": 469770, "start": 4714.26, "end": 4726.099999999999, "text": " And so, yeah, if you play with this kind of simulation, you often get patterns that look exactly like emergent patterns in nature, like ants moving to food or, you know, corals coordinating and that sort of thing.", "tokens": [51192, 400, 370, 11, 1338, 11, 498, 291, 862, 365, 341, 733, 295, 16575, 11, 291, 2049, 483, 8294, 300, 574, 2293, 411, 4345, 6930, 8294, 294, 3687, 11, 411, 23355, 2684, 281, 1755, 420, 11, 291, 458, 11, 1181, 1124, 37824, 293, 300, 1333, 295, 551, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2554670606340681, "compression_ratio": 1.7193548387096773, "no_speech_prob": 0.004198634997010231}, {"id": 1002, "seek": 472610, "start": 4726.9800000000005, "end": 4729.14, "text": " So it's a very biologic field.", "tokens": [50408, 407, 309, 311, 257, 588, 3228, 36661, 2519, 13, 50516], "temperature": 0.0, "avg_logprob": -0.3090630547475007, "compression_ratio": 1.602189781021898, "no_speech_prob": 0.012240747921168804}, {"id": 1003, "seek": 472610, "start": 4730.54, "end": 4735.14, "text": " The difference with our cellular automata is that they're going to be, there's nothing moving.", "tokens": [50586, 440, 2649, 365, 527, 29267, 3553, 3274, 307, 300, 436, 434, 516, 281, 312, 11, 456, 311, 1825, 2684, 13, 50816], "temperature": 0.0, "avg_logprob": -0.3090630547475007, "compression_ratio": 1.602189781021898, "no_speech_prob": 0.012240747921168804}, {"id": 1004, "seek": 472610, "start": 4735.14, "end": 4738.38, "text": " Each, like, grid cell has its own little agent.", "tokens": [50816, 6947, 11, 411, 11, 290, 8558, 2815, 575, 1080, 1065, 707, 9461, 13, 50978], "temperature": 0.0, "avg_logprob": -0.3090630547475007, "compression_ratio": 1.602189781021898, "no_speech_prob": 0.012240747921168804}, {"id": 1005, "seek": 472610, "start": 4738.820000000001, "end": 4742.14, "text": " And so there's no like wandering around.", "tokens": [51000, 400, 370, 456, 311, 572, 411, 26396, 926, 13, 51166], "temperature": 0.0, "avg_logprob": -0.3090630547475007, "compression_ratio": 1.602189781021898, "no_speech_prob": 0.012240747921168804}, {"id": 1006, "seek": 472610, "start": 4742.14, "end": 4745.06, "text": " It's just each individual cell looking at its neighbors and then updating.", "tokens": [51166, 467, 311, 445, 1184, 2609, 2815, 1237, 412, 1080, 12512, 293, 550, 25113, 13, 51312], "temperature": 0.0, "avg_logprob": -0.3090630547475007, "compression_ratio": 1.602189781021898, "no_speech_prob": 0.012240747921168804}, {"id": 1007, "seek": 472610, "start": 4745.46, "end": 4748.02, "text": " And just to clarify, when you say agent, that can be really simple.", "tokens": [51332, 400, 445, 281, 17594, 11, 562, 291, 584, 9461, 11, 300, 393, 312, 534, 2199, 13, 51460], "temperature": 0.0, "avg_logprob": -0.3090630547475007, "compression_ratio": 1.602189781021898, "no_speech_prob": 0.012240747921168804}, {"id": 1008, "seek": 472610, "start": 4748.02, "end": 4751.1, "text": " Like, I don't really remember, but I vaguely remember that Conway's gain of life.", "tokens": [51460, 1743, 11, 286, 500, 380, 534, 1604, 11, 457, 286, 13501, 48863, 1604, 300, 2656, 676, 311, 6052, 295, 993, 13, 51614], "temperature": 0.0, "avg_logprob": -0.3090630547475007, "compression_ratio": 1.602189781021898, "no_speech_prob": 0.012240747921168804}, {"id": 1009, "seek": 475110, "start": 4751.1, "end": 4754.22, "text": " It's kind of like a single kind of if statement.", "tokens": [50364, 467, 311, 733, 295, 411, 257, 2167, 733, 295, 498, 5629, 13, 50520], "temperature": 0.0, "avg_logprob": -0.26485200830408046, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.09400086104869843}, {"id": 1010, "seek": 475110, "start": 4754.22, "end": 4759.38, "text": " It's like if there's, I don't know, what is it, two cells around, you get another one or something.", "tokens": [50520, 467, 311, 411, 498, 456, 311, 11, 286, 500, 380, 458, 11, 437, 307, 309, 11, 732, 5438, 926, 11, 291, 483, 1071, 472, 420, 746, 13, 50778], "temperature": 0.0, "avg_logprob": -0.26485200830408046, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.09400086104869843}, {"id": 1011, "seek": 475110, "start": 4759.54, "end": 4760.02, "text": " Yeah.", "tokens": [50786, 865, 13, 50810], "temperature": 0.0, "avg_logprob": -0.26485200830408046, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.09400086104869843}, {"id": 1012, "seek": 475110, "start": 4760.06, "end": 4760.3, "text": " Yeah.", "tokens": [50812, 865, 13, 50824], "temperature": 0.0, "avg_logprob": -0.26485200830408046, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.09400086104869843}, {"id": 1013, "seek": 475110, "start": 4760.3, "end": 4762.9400000000005, "text": " If there's two or three nearby, you stay alive in the next one.", "tokens": [50824, 759, 456, 311, 732, 420, 1045, 11184, 11, 291, 1754, 5465, 294, 264, 958, 472, 13, 50956], "temperature": 0.0, "avg_logprob": -0.26485200830408046, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.09400086104869843}, {"id": 1014, "seek": 475110, "start": 4762.9400000000005, "end": 4767.780000000001, "text": " If you're overcrowded with four or five or there's no one near you with zero or one neighbors, then you're going to die.", "tokens": [50956, 759, 291, 434, 40027, 1892, 9207, 365, 1451, 420, 1732, 420, 456, 311, 572, 472, 2651, 291, 365, 4018, 420, 472, 12512, 11, 550, 291, 434, 516, 281, 978, 13, 51198], "temperature": 0.0, "avg_logprob": -0.26485200830408046, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.09400086104869843}, {"id": 1015, "seek": 475110, "start": 4768.1, "end": 4769.38, "text": " So it's a very, very simple rule.", "tokens": [51214, 407, 309, 311, 257, 588, 11, 588, 2199, 4978, 13, 51278], "temperature": 0.0, "avg_logprob": -0.26485200830408046, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.09400086104869843}, {"id": 1016, "seek": 475110, "start": 4769.860000000001, "end": 4778.34, "text": " But what we're going to do today is replace that hard-coded if statement with a neural network and in particular, a very small neural network.", "tokens": [51302, 583, 437, 321, 434, 516, 281, 360, 965, 307, 7406, 300, 1152, 12, 66, 12340, 498, 5629, 365, 257, 18161, 3209, 293, 294, 1729, 11, 257, 588, 1359, 18161, 3209, 13, 51726], "temperature": 0.0, "avg_logprob": -0.26485200830408046, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.09400086104869843}, {"id": 1017, "seek": 477834, "start": 4779.3, "end": 4783.860000000001, "text": " So I should start with the paper that inspired me to like even begin looking at this.", "tokens": [50412, 407, 286, 820, 722, 365, 264, 3035, 300, 7547, 385, 281, 411, 754, 1841, 1237, 412, 341, 13, 50640], "temperature": 0.0, "avg_logprob": -0.249309900238758, "compression_ratio": 1.7630662020905923, "no_speech_prob": 0.03461562842130661}, {"id": 1018, "seek": 477834, "start": 4784.7, "end": 4790.9400000000005, "text": " So this is by Alexander Mordvintsev and a team with him at Google Brain, and they built these neural cellular automata.", "tokens": [50682, 407, 341, 307, 538, 14845, 376, 765, 85, 686, 405, 85, 293, 257, 1469, 365, 796, 412, 3329, 29783, 11, 293, 436, 3094, 613, 18161, 29267, 1476, 298, 3274, 13, 50994], "temperature": 0.0, "avg_logprob": -0.249309900238758, "compression_ratio": 1.7630662020905923, "no_speech_prob": 0.03461562842130661}, {"id": 1019, "seek": 477834, "start": 4790.9400000000005, "end": 4792.7, "text": " So this is a pixel grid.", "tokens": [50994, 407, 341, 307, 257, 19261, 10748, 13, 51082], "temperature": 0.0, "avg_logprob": -0.249309900238758, "compression_ratio": 1.7630662020905923, "no_speech_prob": 0.03461562842130661}, {"id": 1020, "seek": 477834, "start": 4793.14, "end": 4799.02, "text": " Every pixel is a cellular automata that's looking at its neighbors and they can't see the global structure at all.", "tokens": [51104, 2048, 19261, 307, 257, 29267, 3553, 3274, 300, 311, 1237, 412, 1080, 12512, 293, 436, 393, 380, 536, 264, 4338, 3877, 412, 439, 13, 51398], "temperature": 0.0, "avg_logprob": -0.249309900238758, "compression_ratio": 1.7630662020905923, "no_speech_prob": 0.03461562842130661}, {"id": 1021, "seek": 477834, "start": 4799.02, "end": 4801.18, "text": " And it starts out with a single black pixel in the middle.", "tokens": [51398, 400, 309, 3719, 484, 365, 257, 2167, 2211, 19261, 294, 264, 2808, 13, 51506], "temperature": 0.0, "avg_logprob": -0.249309900238758, "compression_ratio": 1.7630662020905923, "no_speech_prob": 0.03461562842130661}, {"id": 1022, "seek": 477834, "start": 4801.82, "end": 4807.46, "text": " And if you run the simulation, you can see it builds this little lizard structure, this little emoji.", "tokens": [51538, 400, 498, 291, 1190, 264, 16575, 11, 291, 393, 536, 309, 15182, 341, 707, 39215, 3877, 11, 341, 707, 31595, 13, 51820], "temperature": 0.0, "avg_logprob": -0.249309900238758, "compression_ratio": 1.7630662020905923, "no_speech_prob": 0.03461562842130661}, {"id": 1023, "seek": 480746, "start": 4807.86, "end": 4819.66, "text": " So that's wild to me that a bunch of pixels that only know about their neighbor can actually create such a large and sophisticated image.", "tokens": [50384, 407, 300, 311, 4868, 281, 385, 300, 257, 3840, 295, 18668, 300, 787, 458, 466, 641, 5987, 393, 767, 1884, 1270, 257, 2416, 293, 16950, 3256, 13, 50974], "temperature": 0.0, "avg_logprob": -0.25954353398290175, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0001376533618895337}, {"id": 1024, "seek": 480746, "start": 4820.34, "end": 4822.42, "text": " Yeah, they can self-assemble into this.", "tokens": [51008, 865, 11, 436, 393, 2698, 12, 37319, 666, 341, 13, 51112], "temperature": 0.0, "avg_logprob": -0.25954353398290175, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0001376533618895337}, {"id": 1025, "seek": 480746, "start": 4822.46, "end": 4826.62, "text": " And what's more, the way that they train them, they are robust.", "tokens": [51114, 400, 437, 311, 544, 11, 264, 636, 300, 436, 3847, 552, 11, 436, 366, 13956, 13, 51322], "temperature": 0.0, "avg_logprob": -0.25954353398290175, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0001376533618895337}, {"id": 1026, "seek": 480746, "start": 4826.66, "end": 4828.06, "text": " They're able to repair damage.", "tokens": [51324, 814, 434, 1075, 281, 10535, 4344, 13, 51394], "temperature": 0.0, "avg_logprob": -0.25954353398290175, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0001376533618895337}, {"id": 1027, "seek": 480746, "start": 4828.58, "end": 4832.22, "text": " And so there's no, it's not perfect, but there's no global signaling.", "tokens": [51420, 400, 370, 456, 311, 572, 11, 309, 311, 406, 2176, 11, 457, 456, 311, 572, 4338, 38639, 13, 51602], "temperature": 0.0, "avg_logprob": -0.25954353398290175, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0001376533618895337}, {"id": 1028, "seek": 480746, "start": 4832.22, "end": 4835.14, "text": " No little agent here knows what the full picture looks like.", "tokens": [51602, 883, 707, 9461, 510, 3255, 437, 264, 1577, 3036, 1542, 411, 13, 51748], "temperature": 0.0, "avg_logprob": -0.25954353398290175, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0001376533618895337}, {"id": 1029, "seek": 480746, "start": 4835.54, "end": 4837.1, "text": " It doesn't know where in the picture it is.", "tokens": [51768, 467, 1177, 380, 458, 689, 294, 264, 3036, 309, 307, 13, 51846], "temperature": 0.0, "avg_logprob": -0.25954353398290175, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0001376533618895337}, {"id": 1030, "seek": 483746, "start": 4837.5, "end": 4840.42, "text": " All it knows that its neighbors have certain values.", "tokens": [50366, 1057, 309, 3255, 300, 1080, 12512, 362, 1629, 4190, 13, 50512], "temperature": 0.0, "avg_logprob": -0.32399012247721354, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00018813973292708397}, {"id": 1031, "seek": 483746, "start": 4840.42, "end": 4843.14, "text": " And so it's going to update itself to match those values.", "tokens": [50512, 400, 370, 309, 311, 516, 281, 5623, 2564, 281, 2995, 729, 4190, 13, 50648], "temperature": 0.0, "avg_logprob": -0.32399012247721354, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00018813973292708397}, {"id": 1032, "seek": 483746, "start": 4843.74, "end": 4844.9800000000005, "text": " And so you can see...", "tokens": [50678, 400, 370, 291, 393, 536, 485, 50740], "temperature": 0.0, "avg_logprob": -0.32399012247721354, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00018813973292708397}, {"id": 1033, "seek": 483746, "start": 4844.9800000000005, "end": 4860.38, "text": " I mean, this does seem like something that ought to have a lot of use in the real world with like, I don't know, like having a bunch of drones working together when they can't contact, you know, some kind of central base.", "tokens": [50740, 286, 914, 11, 341, 775, 1643, 411, 746, 300, 13416, 281, 362, 257, 688, 295, 764, 294, 264, 957, 1002, 365, 411, 11, 286, 500, 380, 458, 11, 411, 1419, 257, 3840, 295, 23823, 1364, 1214, 562, 436, 393, 380, 3385, 11, 291, 458, 11, 512, 733, 295, 5777, 3096, 13, 51510], "temperature": 0.0, "avg_logprob": -0.32399012247721354, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.00018813973292708397}, {"id": 1034, "seek": 486038, "start": 4860.42, "end": 4869.78, "text": " I'm thinking about like work that some Australian folks have been involved in where they were doing like automated subterranean rescue operations.", "tokens": [50366, 286, 478, 1953, 466, 411, 589, 300, 512, 13337, 4024, 362, 668, 3288, 294, 689, 436, 645, 884, 411, 18473, 1422, 391, 24584, 13283, 7705, 13, 50834], "temperature": 0.0, "avg_logprob": -0.2976622671451209, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.014726984314620495}, {"id": 1035, "seek": 486038, "start": 4869.78, "end": 4874.62, "text": " And they've like, you literally can't communicate through thousands of meters of rock, stuff like that.", "tokens": [50834, 400, 436, 600, 411, 11, 291, 3736, 393, 380, 7890, 807, 5383, 295, 8146, 295, 3727, 11, 1507, 411, 300, 13, 51076], "temperature": 0.0, "avg_logprob": -0.2976622671451209, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.014726984314620495}, {"id": 1036, "seek": 486038, "start": 4875.74, "end": 4876.14, "text": " Yeah.", "tokens": [51132, 865, 13, 51152], "temperature": 0.0, "avg_logprob": -0.2976622671451209, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.014726984314620495}, {"id": 1037, "seek": 486038, "start": 4876.82, "end": 4877.06, "text": " Yeah.", "tokens": [51186, 865, 13, 51198], "temperature": 0.0, "avg_logprob": -0.2976622671451209, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.014726984314620495}, {"id": 1038, "seek": 486038, "start": 4877.06, "end": 4886.34, "text": " So this idea of like self-organizing systems, there's a lot of promise for like nanotechnology and things like that that can do pretty amazing things.", "tokens": [51198, 407, 341, 1558, 295, 411, 2698, 12, 12372, 3319, 3652, 11, 456, 311, 257, 688, 295, 6228, 337, 411, 14067, 43594, 293, 721, 411, 300, 300, 393, 360, 1238, 2243, 721, 13, 51662], "temperature": 0.0, "avg_logprob": -0.2976622671451209, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.014726984314620495}, {"id": 1039, "seek": 486038, "start": 4886.5, "end": 4887.9800000000005, "text": " This is the blog post that's linked.", "tokens": [51670, 639, 307, 264, 6968, 2183, 300, 311, 9408, 13, 51744], "temperature": 0.0, "avg_logprob": -0.2976622671451209, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.014726984314620495}, {"id": 1040, "seek": 488798, "start": 4888.099999999999, "end": 4888.379999999999, "text": " Yeah.", "tokens": [50370, 865, 13, 50384], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1041, "seek": 488798, "start": 4888.379999999999, "end": 4891.58, "text": " The future of artificial intelligence is self-organizing and self-assembling.", "tokens": [50384, 440, 2027, 295, 11677, 7599, 307, 2698, 12, 12372, 3319, 293, 2698, 12, 29386, 1688, 13, 50544], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1042, "seek": 488798, "start": 4891.62, "end": 4892.099999999999, "text": " Oh, cool.", "tokens": [50546, 876, 11, 1627, 13, 50570], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1043, "seek": 488798, "start": 4892.219999999999, "end": 4893.339999999999, "text": " And definitely, yeah.", "tokens": [50576, 400, 2138, 11, 1338, 13, 50632], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1044, "seek": 488798, "start": 4894.74, "end": 4896.86, "text": " That's a pattern that's worked really well in nature, right?", "tokens": [50702, 663, 311, 257, 5102, 300, 311, 2732, 534, 731, 294, 3687, 11, 558, 30, 50808], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1045, "seek": 488798, "start": 4896.86, "end": 4902.459999999999, "text": " Like lots of loosely coordinated cells coming together and talking about deep learning is quite a miracle.", "tokens": [50808, 1743, 3195, 295, 37966, 29591, 5438, 1348, 1214, 293, 1417, 466, 2452, 2539, 307, 1596, 257, 14660, 13, 51088], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1046, "seek": 488798, "start": 4903.66, "end": 4907.62, "text": " And so I think, yeah, that's an interesting pattern to explore.", "tokens": [51148, 400, 370, 286, 519, 11, 1338, 11, 300, 311, 364, 1880, 5102, 281, 6839, 13, 51346], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1047, "seek": 488798, "start": 4908.9, "end": 4909.179999999999, "text": " Okay.", "tokens": [51410, 1033, 13, 51424], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1048, "seek": 488798, "start": 4909.219999999999, "end": 4911.259999999999, "text": " So how do we train something like this?", "tokens": [51426, 407, 577, 360, 321, 3847, 746, 411, 341, 30, 51528], "temperature": 0.0, "avg_logprob": -0.29785655793689547, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.014502746053040028}, {"id": 1049, "seek": 491126, "start": 4911.46, "end": 4922.62, "text": " How on earth do you set up your structure so that you can get something that not only builds out an image or builds out something like a texture, but then is robust and able to maintain that and keep it going?", "tokens": [50374, 1012, 322, 4120, 360, 291, 992, 493, 428, 3877, 370, 300, 291, 393, 483, 746, 300, 406, 787, 15182, 484, 364, 3256, 420, 15182, 484, 746, 411, 257, 8091, 11, 457, 550, 307, 13956, 293, 1075, 281, 6909, 300, 293, 1066, 309, 516, 30, 50932], "temperature": 0.0, "avg_logprob": -0.2634638786315918, "compression_ratio": 1.6639344262295082, "no_speech_prob": 0.34857285022735596}, {"id": 1050, "seek": 491126, "start": 4923.9800000000005, "end": 4933.5, "text": " So the sort of base is that we're going to set up a neural network with some learnable weights that's going to apply our little update rule.", "tokens": [51000, 407, 264, 1333, 295, 3096, 307, 300, 321, 434, 516, 281, 992, 493, 257, 18161, 3209, 365, 512, 1466, 712, 17443, 300, 311, 516, 281, 3079, 527, 707, 5623, 4978, 13, 51476], "temperature": 0.0, "avg_logprob": -0.2634638786315918, "compression_ratio": 1.6639344262295082, "no_speech_prob": 0.34857285022735596}, {"id": 1051, "seek": 491126, "start": 4934.5, "end": 4934.7, "text": " Right.", "tokens": [51526, 1779, 13, 51536], "temperature": 0.0, "avg_logprob": -0.2634638786315918, "compression_ratio": 1.6639344262295082, "no_speech_prob": 0.34857285022735596}, {"id": 1052, "seek": 491126, "start": 4934.7, "end": 4938.26, "text": " And this is just going to be a little dense MLP.", "tokens": [51536, 400, 341, 307, 445, 516, 281, 312, 257, 707, 18011, 21601, 47, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2634638786315918, "compression_ratio": 1.6639344262295082, "no_speech_prob": 0.34857285022735596}, {"id": 1053, "seek": 493826, "start": 4939.06, "end": 4943.06, "text": " And we can get our inputs, which is just the neighborhood of the cell.", "tokens": [50404, 400, 321, 393, 483, 527, 15743, 11, 597, 307, 445, 264, 7630, 295, 264, 2815, 13, 50604], "temperature": 0.0, "avg_logprob": -0.25846795241038006, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.04145970568060875}, {"id": 1054, "seek": 493826, "start": 4943.7, "end": 4951.62, "text": " And they sometimes have like additional channels that aren't shown, but the agents can use this communication with their neighbors.", "tokens": [50636, 400, 436, 2171, 362, 411, 4497, 9235, 300, 3212, 380, 4898, 11, 457, 264, 12554, 393, 764, 341, 6101, 365, 641, 12512, 13, 51032], "temperature": 0.0, "avg_logprob": -0.25846795241038006, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.04145970568060875}, {"id": 1055, "seek": 493826, "start": 4952.22, "end": 4954.860000000001, "text": " So we can set this up in code.", "tokens": [51062, 407, 321, 393, 992, 341, 493, 294, 3089, 13, 51194], "temperature": 0.0, "avg_logprob": -0.25846795241038006, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.04145970568060875}, {"id": 1056, "seek": 493826, "start": 4954.900000000001, "end": 4964.820000000001, "text": " We'll be able to get our neighbors using maybe convolution or some other method, flatten those out and feed them through a little MLP and take our outputs and use that as our updates.", "tokens": [51196, 492, 603, 312, 1075, 281, 483, 527, 12512, 1228, 1310, 45216, 420, 512, 661, 3170, 11, 24183, 729, 484, 293, 3154, 552, 807, 257, 707, 21601, 47, 293, 747, 527, 23930, 293, 764, 300, 382, 527, 9205, 13, 51692], "temperature": 0.0, "avg_logprob": -0.25846795241038006, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.04145970568060875}, {"id": 1057, "seek": 496482, "start": 4965.259999999999, "end": 4970.46, "text": " Just to clarify something that I missed originally is this is not a simplified picture of it.", "tokens": [50386, 1449, 281, 17594, 746, 300, 286, 6721, 7993, 307, 341, 307, 406, 257, 26335, 3036, 295, 309, 13, 50646], "temperature": 0.0, "avg_logprob": -0.2843769391377767, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.0052199698984622955}, {"id": 1058, "seek": 496482, "start": 4970.46, "end": 4973.74, "text": " This is it like that, that three by, like it's literally three by three.", "tokens": [50646, 639, 307, 309, 411, 300, 11, 300, 1045, 538, 11, 411, 309, 311, 3736, 1045, 538, 1045, 13, 50810], "temperature": 0.0, "avg_logprob": -0.2843769391377767, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.0052199698984622955}, {"id": 1059, "seek": 496482, "start": 4974.0199999999995, "end": 4979.58, "text": " You're only allowed to see the things right next to you or they can be in a different channel.", "tokens": [50824, 509, 434, 787, 4350, 281, 536, 264, 721, 558, 958, 281, 291, 420, 436, 393, 312, 294, 257, 819, 2269, 13, 51102], "temperature": 0.0, "avg_logprob": -0.2843769391377767, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.0052199698984622955}, {"id": 1060, "seek": 496482, "start": 4980.74, "end": 4981.219999999999, "text": " Exactly.", "tokens": [51160, 7587, 13, 51184], "temperature": 0.0, "avg_logprob": -0.2843769391377767, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.0052199698984622955}, {"id": 1061, "seek": 496482, "start": 4981.259999999999, "end": 4984.66, "text": " And this paper has this additional step of like cells being alive or dead.", "tokens": [51186, 400, 341, 3035, 575, 341, 4497, 1823, 295, 411, 5438, 885, 5465, 420, 3116, 13, 51356], "temperature": 0.0, "avg_logprob": -0.2843769391377767, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.0052199698984622955}, {"id": 1062, "seek": 496482, "start": 4985.139999999999, "end": 4987.299999999999, "text": " But we're going to do one that doesn't even have that.", "tokens": [51380, 583, 321, 434, 516, 281, 360, 472, 300, 1177, 380, 754, 362, 300, 13, 51488], "temperature": 0.0, "avg_logprob": -0.2843769391377767, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.0052199698984622955}, {"id": 1063, "seek": 496482, "start": 4987.34, "end": 4989.259999999999, "text": " So it's, it's even simpler than this diagram.", "tokens": [51490, 407, 309, 311, 11, 309, 311, 754, 18587, 813, 341, 10686, 13, 51586], "temperature": 0.0, "avg_logprob": -0.2843769391377767, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.0052199698984622955}, {"id": 1064, "seek": 496482, "start": 4990.099999999999, "end": 4990.7, "text": " Okay.", "tokens": [51628, 1033, 13, 51658], "temperature": 0.0, "avg_logprob": -0.2843769391377767, "compression_ratio": 1.6496350364963503, "no_speech_prob": 0.0052199698984622955}, {"id": 1065, "seek": 499070, "start": 4990.7, "end": 5000.74, "text": " So to train this, what we could do is we could start from our initial state, apply our network over some number of steps, look at the final output and compare it to our targets and calculate our loss.", "tokens": [50364, 407, 281, 3847, 341, 11, 437, 321, 727, 360, 307, 321, 727, 722, 490, 527, 5883, 1785, 11, 3079, 527, 3209, 670, 512, 1230, 295, 4439, 11, 574, 412, 264, 2572, 5598, 293, 6794, 309, 281, 527, 12911, 293, 8873, 527, 4470, 13, 50866], "temperature": 0.0, "avg_logprob": -0.23547942893019, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.11277775466442108}, {"id": 1066, "seek": 499070, "start": 5001.0199999999995, "end": 5002.54, "text": " And you might think, okay, well, that's pretty cool.", "tokens": [50880, 400, 291, 1062, 519, 11, 1392, 11, 731, 11, 300, 311, 1238, 1627, 13, 50956], "temperature": 0.0, "avg_logprob": -0.23547942893019, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.11277775466442108}, {"id": 1067, "seek": 499070, "start": 5002.98, "end": 5003.86, "text": " We can maybe do that.", "tokens": [50978, 492, 393, 1310, 360, 300, 13, 51022], "temperature": 0.0, "avg_logprob": -0.23547942893019, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.11277775466442108}, {"id": 1068, "seek": 499070, "start": 5004.38, "end": 5012.94, "text": " And if you run this, you do indeed get something that after some number of steps can learn to grow into something that looks like your target image.", "tokens": [51048, 400, 498, 291, 1190, 341, 11, 291, 360, 6451, 483, 746, 300, 934, 512, 1230, 295, 4439, 393, 1466, 281, 1852, 666, 746, 300, 1542, 411, 428, 3779, 3256, 13, 51476], "temperature": 0.0, "avg_logprob": -0.23547942893019, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.11277775466442108}, {"id": 1069, "seek": 501294, "start": 5013.46, "end": 5020.0199999999995, "text": " But there's this problem, which is that you're applying some number of steps and then you're applying your loss after that.", "tokens": [50390, 583, 456, 311, 341, 1154, 11, 597, 307, 300, 291, 434, 9275, 512, 1230, 295, 4439, 293, 550, 291, 434, 9275, 428, 4470, 934, 300, 13, 50718], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1070, "seek": 501294, "start": 5020.5, "end": 5023.339999999999, "text": " But that doesn't guarantee that it's going to be stable.", "tokens": [50742, 583, 300, 1177, 380, 10815, 300, 309, 311, 516, 281, 312, 8351, 13, 50884], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1071, "seek": 501294, "start": 5023.86, "end": 5024.379999999999, "text": " I hope so.", "tokens": [50910, 286, 1454, 370, 13, 50936], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1072, "seek": 501294, "start": 5024.94, "end": 5025.58, "text": " There goes my phone.", "tokens": [50964, 821, 1709, 452, 2593, 13, 50996], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1073, "seek": 501294, "start": 5025.78, "end": 5026.82, "text": " Stable longer term.", "tokens": [51006, 745, 712, 2854, 1433, 13, 51058], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1074, "seek": 501294, "start": 5027.099999999999, "end": 5031.139999999999, "text": " And so we need some additional way to say, okay, I don't just want to grow into this image.", "tokens": [51072, 400, 370, 321, 643, 512, 4497, 636, 281, 584, 11, 1392, 11, 286, 500, 380, 445, 528, 281, 1852, 666, 341, 3256, 13, 51274], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1075, "seek": 501294, "start": 5031.5, "end": 5033.66, "text": " I'd like to then maintain that shape once I have it.", "tokens": [51292, 286, 1116, 411, 281, 550, 6909, 300, 3909, 1564, 286, 362, 309, 13, 51400], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1076, "seek": 501294, "start": 5034.58, "end": 5041.82, "text": " And the solution that this paper proposes is to have a pool of training examples.", "tokens": [51446, 400, 264, 3827, 300, 341, 3035, 2365, 4201, 307, 281, 362, 257, 7005, 295, 3097, 5110, 13, 51808], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1077, "seek": 501294, "start": 5042.299999999999, "end": 5042.62, "text": " Right.", "tokens": [51832, 1779, 13, 51848], "temperature": 0.0, "avg_logprob": -0.3183259665966034, "compression_ratio": 1.6702508960573477, "no_speech_prob": 0.06370909512042999}, {"id": 1078, "seek": 504262, "start": 5042.62, "end": 5044.0599999999995, "text": " And we'll see this in code just now.", "tokens": [50364, 400, 321, 603, 536, 341, 294, 3089, 445, 586, 13, 50436], "temperature": 0.0, "avg_logprob": -0.24156837993197972, "compression_ratio": 1.858974358974359, "no_speech_prob": 0.01912158541381359}, {"id": 1079, "seek": 504262, "start": 5044.58, "end": 5047.34, "text": " So the idea here is that sometimes we'll start from a random state.", "tokens": [50462, 407, 264, 1558, 510, 307, 300, 2171, 321, 603, 722, 490, 257, 4974, 1785, 13, 50600], "temperature": 0.0, "avg_logprob": -0.24156837993197972, "compression_ratio": 1.858974358974359, "no_speech_prob": 0.01912158541381359}, {"id": 1080, "seek": 504262, "start": 5048.5, "end": 5050.18, "text": " And we'll apply some number of updates.", "tokens": [50658, 400, 321, 603, 3079, 512, 1230, 295, 9205, 13, 50742], "temperature": 0.0, "avg_logprob": -0.24156837993197972, "compression_ratio": 1.858974358974359, "no_speech_prob": 0.01912158541381359}, {"id": 1081, "seek": 504262, "start": 5050.46, "end": 5052.74, "text": " We'll apply our loss function and update our network.", "tokens": [50756, 492, 603, 3079, 527, 4470, 2445, 293, 5623, 527, 3209, 13, 50870], "temperature": 0.0, "avg_logprob": -0.24156837993197972, "compression_ratio": 1.858974358974359, "no_speech_prob": 0.01912158541381359}, {"id": 1082, "seek": 504262, "start": 5053.34, "end": 5060.86, "text": " And then most of the time we'll take that final output and we'll put it back into the pool to be used again as a starting point for another round of training.", "tokens": [50900, 400, 550, 881, 295, 264, 565, 321, 603, 747, 300, 2572, 5598, 293, 321, 603, 829, 309, 646, 666, 264, 7005, 281, 312, 1143, 797, 382, 257, 2891, 935, 337, 1071, 3098, 295, 3097, 13, 51276], "temperature": 0.0, "avg_logprob": -0.24156837993197972, "compression_ratio": 1.858974358974359, "no_speech_prob": 0.01912158541381359}, {"id": 1083, "seek": 504262, "start": 5061.66, "end": 5066.58, "text": " And so this means that the network might see the initial state and have to produce the lizard.", "tokens": [51316, 400, 370, 341, 1355, 300, 264, 3209, 1062, 536, 264, 5883, 1785, 293, 362, 281, 5258, 264, 39215, 13, 51562], "temperature": 0.0, "avg_logprob": -0.24156837993197972, "compression_ratio": 1.858974358974359, "no_speech_prob": 0.01912158541381359}, {"id": 1084, "seek": 504262, "start": 5067.26, "end": 5069.42, "text": " Or it might see a lizard that's already been produced.", "tokens": [51596, 1610, 309, 1062, 536, 257, 39215, 300, 311, 1217, 668, 7126, 13, 51704], "temperature": 0.0, "avg_logprob": -0.24156837993197972, "compression_ratio": 1.858974358974359, "no_speech_prob": 0.01912158541381359}, {"id": 1085, "seek": 504262, "start": 5069.86, "end": 5072.34, "text": " And after some number of steps, it still needs to look like that lizard.", "tokens": [51726, 400, 934, 512, 1230, 295, 4439, 11, 309, 920, 2203, 281, 574, 411, 300, 39215, 13, 51850], "temperature": 0.0, "avg_logprob": -0.24156837993197972, "compression_ratio": 1.858974358974359, "no_speech_prob": 0.01912158541381359}, {"id": 1086, "seek": 507262, "start": 5073.0199999999995, "end": 5080.22, "text": " And so this is adding like an additional constraint that says even after much more steps, we'd still like you to look like this final output.", "tokens": [50384, 400, 370, 341, 307, 5127, 411, 364, 4497, 25534, 300, 1619, 754, 934, 709, 544, 4439, 11, 321, 1116, 920, 411, 291, 281, 574, 411, 341, 2572, 5598, 13, 50744], "temperature": 0.0, "avg_logprob": -0.25624980566636574, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.002672809176146984}, {"id": 1087, "seek": 507262, "start": 5082.18, "end": 5091.0199999999995, "text": " And so, yeah, it's also nice because like I mentioned here, initially the model ends up in various incorrect states that don't look like a lizard, but also don't look like the starting point.", "tokens": [50842, 400, 370, 11, 1338, 11, 309, 311, 611, 1481, 570, 411, 286, 2835, 510, 11, 9105, 264, 2316, 5314, 493, 294, 3683, 18424, 4368, 300, 500, 380, 574, 411, 257, 39215, 11, 457, 611, 500, 380, 574, 411, 264, 2891, 935, 13, 51284], "temperature": 0.0, "avg_logprob": -0.25624980566636574, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.002672809176146984}, {"id": 1088, "seek": 507262, "start": 5091.5, "end": 5093.62, "text": " And it then has to learn to correct those as well.", "tokens": [51308, 400, 309, 550, 575, 281, 1466, 281, 3006, 729, 382, 731, 13, 51414], "temperature": 0.0, "avg_logprob": -0.25624980566636574, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.002672809176146984}, {"id": 1089, "seek": 507262, "start": 5093.74, "end": 5097.34, "text": " So we get this nice additional robustness from this in addition.", "tokens": [51420, 407, 321, 483, 341, 1481, 4497, 13956, 1287, 490, 341, 294, 4500, 13, 51600], "temperature": 0.0, "avg_logprob": -0.25624980566636574, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.002672809176146984}, {"id": 1090, "seek": 509734, "start": 5098.14, "end": 5105.82, "text": " And you can see here now they have a thing that is able to grow into the lizard and then maintain that structure kind of indefinitely.", "tokens": [50404, 400, 291, 393, 536, 510, 586, 436, 362, 257, 551, 300, 307, 1075, 281, 1852, 666, 264, 39215, 293, 550, 6909, 300, 3877, 733, 295, 24162, 10925, 13, 50788], "temperature": 0.0, "avg_logprob": -0.27248065391283355, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.060964856296777725}, {"id": 1091, "seek": 509734, "start": 5106.78, "end": 5113.62, "text": " And in this paper, they do this final step where they sometimes chop off half of the image as additional like augmentation.", "tokens": [50836, 400, 294, 341, 3035, 11, 436, 360, 341, 2572, 1823, 689, 436, 2171, 7931, 766, 1922, 295, 264, 3256, 382, 4497, 411, 14501, 19631, 13, 51178], "temperature": 0.0, "avg_logprob": -0.27248065391283355, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.060964856296777725}, {"id": 1092, "seek": 509734, "start": 5114.1, "end": 5122.18, "text": " So you could have like a bunch of drones or something that like can only see the ones nearby and they don't have GPS or something.", "tokens": [51202, 407, 291, 727, 362, 411, 257, 3840, 295, 23823, 420, 746, 300, 411, 393, 787, 536, 264, 2306, 11184, 293, 436, 500, 380, 362, 19462, 420, 746, 13, 51606], "temperature": 0.0, "avg_logprob": -0.27248065391283355, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.060964856296777725}, {"id": 1093, "seek": 512218, "start": 5122.18, "end": 5128.5, "text": " And a gust of wind could come along and set them off path and they still reconfigure themselves.", "tokens": [50364, 400, 257, 9679, 295, 2468, 727, 808, 2051, 293, 992, 552, 766, 3100, 293, 436, 920, 9993, 20646, 540, 2969, 13, 50680], "temperature": 0.0, "avg_logprob": -0.2363248065235169, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.037319812923669815}, {"id": 1094, "seek": 512218, "start": 5129.58, "end": 5130.42, "text": " Yeah, yeah, exactly.", "tokens": [50734, 865, 11, 1338, 11, 2293, 13, 50776], "temperature": 0.0, "avg_logprob": -0.2363248065235169, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.037319812923669815}, {"id": 1095, "seek": 512218, "start": 5130.42, "end": 5132.06, "text": " Half of them go offline and run out of battery.", "tokens": [50776, 15917, 295, 552, 352, 21857, 293, 1190, 484, 295, 5809, 13, 50858], "temperature": 0.0, "avg_logprob": -0.2363248065235169, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.037319812923669815}, {"id": 1096, "seek": 512218, "start": 5132.1, "end": 5132.740000000001, "text": " That's fine.", "tokens": [50860, 663, 311, 2489, 13, 50892], "temperature": 0.0, "avg_logprob": -0.2363248065235169, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.037319812923669815}, {"id": 1097, "seek": 512218, "start": 5134.06, "end": 5135.26, "text": " So very, very cool paper.", "tokens": [50958, 407, 588, 11, 588, 1627, 3035, 13, 51018], "temperature": 0.0, "avg_logprob": -0.2363248065235169, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.037319812923669815}, {"id": 1098, "seek": 512218, "start": 5135.9800000000005, "end": 5142.780000000001, "text": " But you can see this kind of training is a little bit more complicated than, oh, we just have a network and some target outputs and we optimize it.", "tokens": [51054, 583, 291, 393, 536, 341, 733, 295, 3097, 307, 257, 707, 857, 544, 6179, 813, 11, 1954, 11, 321, 445, 362, 257, 3209, 293, 512, 3779, 23930, 293, 321, 19719, 309, 13, 51394], "temperature": 0.0, "avg_logprob": -0.2363248065235169, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.037319812923669815}, {"id": 1099, "seek": 512218, "start": 5143.900000000001, "end": 5149.34, "text": " So we're not going to follow that paper exactly, although it should be fairly easy to tweak what we have to match that.", "tokens": [51450, 407, 321, 434, 406, 516, 281, 1524, 300, 3035, 2293, 11, 4878, 309, 820, 312, 6457, 1858, 281, 29879, 437, 321, 362, 281, 2995, 300, 13, 51722], "temperature": 0.0, "avg_logprob": -0.2363248065235169, "compression_ratio": 1.6332179930795847, "no_speech_prob": 0.037319812923669815}, {"id": 1100, "seek": 514934, "start": 5149.82, "end": 5158.42, "text": " We're instead going to go for a slightly different one by the same authors where they train even smaller networks to match textures.", "tokens": [50388, 492, 434, 2602, 516, 281, 352, 337, 257, 4748, 819, 472, 538, 264, 912, 16552, 689, 436, 3847, 754, 4356, 9590, 281, 2995, 24501, 13, 50818], "temperature": 0.0, "avg_logprob": -0.23469320117917836, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.04401521012187004}, {"id": 1101, "seek": 514934, "start": 5158.5, "end": 5161.26, "text": " And so you can imagine our style loss is going to come in useful here.", "tokens": [50822, 400, 370, 291, 393, 3811, 527, 3758, 4470, 307, 516, 281, 808, 294, 4420, 510, 13, 50960], "temperature": 0.0, "avg_logprob": -0.23469320117917836, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.04401521012187004}, {"id": 1102, "seek": 514934, "start": 5161.74, "end": 5166.14, "text": " We'd like to produce a texture without necessarily worrying about the overall structure.", "tokens": [50984, 492, 1116, 411, 281, 5258, 257, 8091, 1553, 4725, 18788, 466, 264, 4787, 3877, 13, 51204], "temperature": 0.0, "avg_logprob": -0.23469320117917836, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.04401521012187004}, {"id": 1103, "seek": 514934, "start": 5166.14, "end": 5167.18, "text": " We just want the style.", "tokens": [51204, 492, 445, 528, 264, 3758, 13, 51256], "temperature": 0.0, "avg_logprob": -0.23469320117917836, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.04401521012187004}, {"id": 1104, "seek": 514934, "start": 5168.66, "end": 5170.7, "text": " And so the same sort of idea, the same sort of training.", "tokens": [51330, 400, 370, 264, 912, 1333, 295, 1558, 11, 264, 912, 1333, 295, 3097, 13, 51432], "temperature": 0.0, "avg_logprob": -0.23469320117917836, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.04401521012187004}, {"id": 1105, "seek": 514934, "start": 5171.74, "end": 5177.3, "text": " We're going to start from random and then after some number of steps, we'd like it to look like our target style image.", "tokens": [51484, 492, 434, 516, 281, 722, 490, 4974, 293, 550, 934, 512, 1230, 295, 4439, 11, 321, 1116, 411, 309, 281, 574, 411, 527, 3779, 3758, 3256, 13, 51762], "temperature": 0.0, "avg_logprob": -0.23469320117917836, "compression_ratio": 1.7544483985765125, "no_speech_prob": 0.04401521012187004}, {"id": 1106, "seek": 517730, "start": 5177.38, "end": 5180.02, "text": " And in fact, there actually is a spider web, which I hadn't noticed until now.", "tokens": [50368, 400, 294, 1186, 11, 456, 767, 307, 257, 17614, 3670, 11, 597, 286, 8782, 380, 5694, 1826, 586, 13, 50500], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1107, "seek": 517730, "start": 5180.9800000000005, "end": 5186.26, "text": " And that's the one thing that makes a texture a texture in this case, is it's something you can tile nicely.", "tokens": [50548, 400, 300, 311, 264, 472, 551, 300, 1669, 257, 8091, 257, 8091, 294, 341, 1389, 11, 307, 309, 311, 746, 291, 393, 20590, 9594, 13, 50812], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1108, "seek": 517730, "start": 5186.34, "end": 5186.66, "text": " Is that?", "tokens": [50816, 1119, 300, 30, 50832], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1109, "seek": 517730, "start": 5187.22, "end": 5187.860000000001, "text": " Yes.", "tokens": [50860, 1079, 13, 50892], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1110, "seek": 517730, "start": 5187.900000000001, "end": 5188.3, "text": " Yeah.", "tokens": [50894, 865, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1111, "seek": 517730, "start": 5188.820000000001, "end": 5190.74, "text": " And so that tiling is going to come almost for free.", "tokens": [50940, 400, 370, 300, 256, 4883, 307, 516, 281, 808, 1920, 337, 1737, 13, 51036], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1112, "seek": 517730, "start": 5190.78, "end": 5191.78, "text": " So we're going to have our input.", "tokens": [51038, 407, 321, 434, 516, 281, 362, 527, 4846, 13, 51088], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1113, "seek": 517730, "start": 5191.820000000001, "end": 5192.9400000000005, "text": " We're going to look at our neighbors.", "tokens": [51090, 492, 434, 516, 281, 574, 412, 527, 12512, 13, 51146], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1114, "seek": 517730, "start": 5193.26, "end": 5195.3, "text": " We're going to feed that through a network and produce an output.", "tokens": [51162, 492, 434, 516, 281, 3154, 300, 807, 257, 3209, 293, 5258, 364, 5598, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1115, "seek": 517730, "start": 5195.78, "end": 5203.58, "text": " And every cell is going to do the same rule, which will work fine by default if we set this up without thinking about tiling at all.", "tokens": [51288, 400, 633, 2815, 307, 516, 281, 360, 264, 912, 4978, 11, 597, 486, 589, 2489, 538, 7576, 498, 321, 992, 341, 493, 1553, 1953, 466, 256, 4883, 412, 439, 13, 51678], "temperature": 0.0, "avg_logprob": -0.2860067728403452, "compression_ratio": 1.7524752475247525, "no_speech_prob": 0.0018675141036510468}, {"id": 1116, "seek": 520358, "start": 5204.0599999999995, "end": 5212.14, "text": " Except that at the edges, when we do like say a convolution to get our neighbors, we need to think about what happens for the neighbors of the cells on the edge.", "tokens": [50388, 16192, 300, 412, 264, 8819, 11, 562, 321, 360, 411, 584, 257, 45216, 281, 483, 527, 12512, 11, 321, 643, 281, 519, 466, 437, 2314, 337, 264, 12512, 295, 264, 5438, 322, 264, 4691, 13, 50792], "temperature": 0.0, "avg_logprob": -0.23508987729511563, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.12083975225687027}, {"id": 1117, "seek": 520358, "start": 5212.3, "end": 5213.26, "text": " Which ones should those be?", "tokens": [50800, 3013, 2306, 820, 729, 312, 30, 50848], "temperature": 0.0, "avg_logprob": -0.23508987729511563, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.12083975225687027}, {"id": 1118, "seek": 520358, "start": 5213.7, "end": 5215.86, "text": " And by default, those will just be padding of zero.", "tokens": [50870, 400, 538, 7576, 11, 729, 486, 445, 312, 39562, 295, 4018, 13, 50978], "temperature": 0.0, "avg_logprob": -0.23508987729511563, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.12083975225687027}, {"id": 1119, "seek": 520358, "start": 5215.9, "end": 5218.78, "text": " And so those cells in the edge, A, they'll know they're on the edge.", "tokens": [50980, 400, 370, 729, 5438, 294, 264, 4691, 11, 316, 11, 436, 603, 458, 436, 434, 322, 264, 4691, 13, 51124], "temperature": 0.0, "avg_logprob": -0.23508987729511563, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.12083975225687027}, {"id": 1120, "seek": 520358, "start": 5219.3, "end": 5222.86, "text": " And B, they won't necessarily have any communication with the other side.", "tokens": [51150, 400, 363, 11, 436, 1582, 380, 4725, 362, 604, 6101, 365, 264, 661, 1252, 13, 51328], "temperature": 0.0, "avg_logprob": -0.23508987729511563, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.12083975225687027}, {"id": 1121, "seek": 520358, "start": 5223.42, "end": 5227.9, "text": " If we want this to tile, what we're going to do is we're going to set our padding mode to circular.", "tokens": [51356, 759, 321, 528, 341, 281, 20590, 11, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 992, 527, 39562, 4391, 281, 16476, 13, 51580], "temperature": 0.0, "avg_logprob": -0.23508987729511563, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.12083975225687027}, {"id": 1122, "seek": 522790, "start": 5228.299999999999, "end": 5234.219999999999, "text": " In other words, the neighbors of this top right cell are going to be these cells next to it here and these cells down in the bottom corner.", "tokens": [50384, 682, 661, 2283, 11, 264, 12512, 295, 341, 1192, 558, 2815, 366, 516, 281, 312, 613, 5438, 958, 281, 309, 510, 293, 613, 5438, 760, 294, 264, 2767, 4538, 13, 50680], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1123, "seek": 522790, "start": 5234.9, "end": 5237.5, "text": " And then for free, we're going to get tiling.", "tokens": [50714, 400, 550, 337, 1737, 11, 321, 434, 516, 281, 483, 256, 4883, 13, 50844], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1124, "seek": 522790, "start": 5238.74, "end": 5238.98, "text": " Okay.", "tokens": [50906, 1033, 13, 50918], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1125, "seek": 522790, "start": 5239.0199999999995, "end": 5240.299999999999, "text": " So enough waffle.", "tokens": [50920, 407, 1547, 44328, 13, 50984], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1126, "seek": 522790, "start": 5240.339999999999, "end": 5241.299999999999, "text": " Let's get into code.", "tokens": [50986, 961, 311, 483, 666, 3089, 13, 51034], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1127, "seek": 522790, "start": 5242.259999999999, "end": 5244.219999999999, "text": " We're going to download our style image.", "tokens": [51082, 492, 434, 516, 281, 5484, 527, 3758, 3256, 13, 51180], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1128, "seek": 522790, "start": 5244.259999999999, "end": 5244.5, "text": " Oops.", "tokens": [51182, 21726, 13, 51194], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1129, "seek": 522790, "start": 5244.94, "end": 5245.82, "text": " Need to do my imports.", "tokens": [51216, 16984, 281, 360, 452, 41596, 13, 51260], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1130, "seek": 522790, "start": 5248.82, "end": 5250.299999999999, "text": " This is going to be our target style image.", "tokens": [51410, 639, 307, 516, 281, 312, 527, 3779, 3758, 3256, 13, 51484], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1131, "seek": 522790, "start": 5250.339999999999, "end": 5252.58, "text": " And again, feel free to experiment with your own, please.", "tokens": [51486, 400, 797, 11, 841, 1737, 281, 5120, 365, 428, 1065, 11, 1767, 13, 51598], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1132, "seek": 522790, "start": 5253.5, "end": 5256.46, "text": " We're going to set up a style loss, just like we did in lesson 17a.", "tokens": [51644, 492, 434, 516, 281, 992, 493, 257, 3758, 4470, 11, 445, 411, 321, 630, 294, 6898, 3282, 64, 13, 51792], "temperature": 0.0, "avg_logprob": -0.2970533232758011, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.2253773957490921}, {"id": 1133, "seek": 525646, "start": 5257.38, "end": 5267.82, "text": " The difference being that we're going to have a batch dimension to our inputs to this calculate grams function, which I didn't do in the style transfer example, because you're always dealing with a single image.", "tokens": [50410, 440, 2649, 885, 300, 321, 434, 516, 281, 362, 257, 15245, 10139, 281, 527, 15743, 281, 341, 8873, 11899, 2445, 11, 597, 286, 994, 380, 360, 294, 264, 3758, 5003, 1365, 11, 570, 291, 434, 1009, 6260, 365, 257, 2167, 3256, 13, 50932], "temperature": 0.0, "avg_logprob": -0.259934582756561, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.0015247436240315437}, {"id": 1134, "seek": 525646, "start": 5268.54, "end": 5270.22, "text": " Everything else is going to be pretty much the same.", "tokens": [50968, 5471, 1646, 307, 516, 281, 312, 1238, 709, 264, 912, 13, 51052], "temperature": 0.0, "avg_logprob": -0.259934582756561, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.0015247436240315437}, {"id": 1135, "seek": 525646, "start": 5271.02, "end": 5279.1, "text": " So we can set up our style loss with the target image, and then we can feed in a new image or in this case, a batch of images, and we're going to get back a loss.", "tokens": [51092, 407, 321, 393, 992, 493, 527, 3758, 4470, 365, 264, 3779, 3256, 11, 293, 550, 321, 393, 3154, 294, 257, 777, 3256, 420, 294, 341, 1389, 11, 257, 15245, 295, 5267, 11, 293, 321, 434, 516, 281, 483, 646, 257, 4470, 13, 51496], "temperature": 0.0, "avg_logprob": -0.259934582756561, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.0015247436240315437}, {"id": 1136, "seek": 527910, "start": 5280.06, "end": 5283.58, "text": " So we're, we're setting up our, our evaluation.", "tokens": [50412, 407, 321, 434, 11, 321, 434, 3287, 493, 527, 11, 527, 13344, 13, 50588], "temperature": 0.0, "avg_logprob": -0.2908234945157679, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.06853366643190384}, {"id": 1137, "seek": 527910, "start": 5283.58, "end": 5288.1, "text": " We would like after some number of steps, our output to look like a spiderweb.", "tokens": [50588, 492, 576, 411, 934, 512, 1230, 295, 4439, 11, 527, 5598, 281, 574, 411, 257, 17614, 826, 65, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2908234945157679, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.06853366643190384}, {"id": 1138, "seek": 527910, "start": 5289.02, "end": 5289.58, "text": " Okay.", "tokens": [50860, 1033, 13, 50888], "temperature": 0.0, "avg_logprob": -0.2908234945157679, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.06853366643190384}, {"id": 1139, "seek": 527910, "start": 5289.660000000001, "end": 5290.620000000001, "text": " Let's define our model.", "tokens": [50892, 961, 311, 6964, 527, 2316, 13, 50940], "temperature": 0.0, "avg_logprob": -0.2908234945157679, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.06853366643190384}, {"id": 1140, "seek": 527910, "start": 5290.660000000001, "end": 5297.740000000001, "text": " And here I'm making a very small model with only four channels and our hidden number of hidden neurons in the brain is just going to be eight.", "tokens": [50942, 400, 510, 286, 478, 1455, 257, 588, 1359, 2316, 365, 787, 1451, 9235, 293, 527, 7633, 1230, 295, 7633, 22027, 294, 264, 3567, 307, 445, 516, 281, 312, 3180, 13, 51296], "temperature": 0.0, "avg_logprob": -0.2908234945157679, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.06853366643190384}, {"id": 1141, "seek": 527910, "start": 5298.34, "end": 5299.620000000001, "text": " You can increase these.", "tokens": [51326, 509, 393, 3488, 613, 13, 51390], "temperature": 0.0, "avg_logprob": -0.2908234945157679, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.06853366643190384}, {"id": 1142, "seek": 527910, "start": 5299.9800000000005, "end": 5301.9400000000005, "text": " Something I would be inclined to do.", "tokens": [51408, 6595, 286, 576, 312, 28173, 281, 360, 13, 51506], "temperature": 0.0, "avg_logprob": -0.2908234945157679, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.06853366643190384}, {"id": 1143, "seek": 527910, "start": 5301.9800000000005, "end": 5307.58, "text": " People might want to play with in style loss to target is you're giving all the layers the same weight.", "tokens": [51508, 3432, 1062, 528, 281, 862, 365, 294, 3758, 4470, 281, 3779, 307, 291, 434, 2902, 439, 264, 7914, 264, 912, 3364, 13, 51788], "temperature": 0.0, "avg_logprob": -0.2908234945157679, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.06853366643190384}, {"id": 1144, "seek": 530758, "start": 5308.0199999999995, "end": 5313.74, "text": " You know, a nice addition would be to have a vector of weights.", "tokens": [50386, 509, 458, 11, 257, 1481, 4500, 576, 312, 281, 362, 257, 8062, 295, 17443, 13, 50672], "temperature": 0.0, "avg_logprob": -0.3243307095129513, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0008558698464185}, {"id": 1145, "seek": 530758, "start": 5313.74, "end": 5315.58, "text": " You could pass in an experiment with that.", "tokens": [50672, 509, 727, 1320, 294, 364, 5120, 365, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3243307095129513, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0008558698464185}, {"id": 1146, "seek": 530758, "start": 5317.38, "end": 5317.94, "text": " Definitely.", "tokens": [50854, 12151, 13, 50882], "temperature": 0.0, "avg_logprob": -0.3243307095129513, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0008558698464185}, {"id": 1147, "seek": 530758, "start": 5318.62, "end": 5319.1, "text": " All right.", "tokens": [50916, 1057, 558, 13, 50940], "temperature": 0.0, "avg_logprob": -0.3243307095129513, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0008558698464185}, {"id": 1148, "seek": 530758, "start": 5319.1, "end": 5322.9, "text": " So the, the world in which these cellular automata are going to live is going to be a grid.", "tokens": [50940, 407, 264, 11, 264, 1002, 294, 597, 613, 29267, 3553, 3274, 366, 516, 281, 1621, 307, 516, 281, 312, 257, 10748, 13, 51130], "temperature": 0.0, "avg_logprob": -0.3243307095129513, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0008558698464185}, {"id": 1149, "seek": 530758, "start": 5323.26, "end": 5324.82, "text": " We're going to have some number of them.", "tokens": [51148, 492, 434, 516, 281, 362, 512, 1230, 295, 552, 13, 51226], "temperature": 0.0, "avg_logprob": -0.3243307095129513, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0008558698464185}, {"id": 1150, "seek": 530758, "start": 5324.82, "end": 5330.66, "text": " If we call this function number of channels and the size, you could make it non-square if you cared about that.", "tokens": [51226, 759, 321, 818, 341, 2445, 1230, 295, 9235, 293, 264, 2744, 11, 291, 727, 652, 309, 2107, 12, 33292, 543, 498, 291, 19779, 466, 300, 13, 51518], "temperature": 0.0, "avg_logprob": -0.3243307095129513, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0008558698464185}, {"id": 1151, "seek": 533066, "start": 5331.42, "end": 5337.22, "text": " For our perception in this little diagram here, we're going to use some hard coded filters.", "tokens": [50402, 1171, 527, 12860, 294, 341, 707, 10686, 510, 11, 321, 434, 516, 281, 764, 512, 1152, 34874, 15995, 13, 50692], "temperature": 0.0, "avg_logprob": -0.3660822527124247, "compression_ratio": 1.6505576208178439, "no_speech_prob": 0.0446777306497097}, {"id": 1152, "seek": 533066, "start": 5337.86, "end": 5339.86, "text": " And you could have these be learned, right?", "tokens": [50724, 400, 291, 727, 362, 613, 312, 3264, 11, 558, 30, 50824], "temperature": 0.0, "avg_logprob": -0.3660822527124247, "compression_ratio": 1.6505576208178439, "no_speech_prob": 0.0446777306497097}, {"id": 1153, "seek": 533066, "start": 5339.86, "end": 5341.74, "text": " There'd be additional weights in the neural network.", "tokens": [50824, 821, 1116, 312, 4497, 17443, 294, 264, 18161, 3209, 13, 50918], "temperature": 0.0, "avg_logprob": -0.3660822527124247, "compression_ratio": 1.6505576208178439, "no_speech_prob": 0.0446777306497097}, {"id": 1154, "seek": 533066, "start": 5342.26, "end": 5349.5, "text": " The reason they're hard coded is because the people who are working behind this paper, they wanted to keep the parameter counts really low.", "tokens": [50944, 440, 1778, 436, 434, 1152, 34874, 307, 570, 264, 561, 567, 366, 1364, 2261, 341, 3035, 11, 436, 1415, 281, 1066, 264, 13075, 14893, 534, 2295, 13, 51306], "temperature": 0.0, "avg_logprob": -0.3660822527124247, "compression_ratio": 1.6505576208178439, "no_speech_prob": 0.0446777306497097}, {"id": 1155, "seek": 533066, "start": 5350.0199999999995, "end": 5352.66, "text": " Literally like a few hundred parameters total.", "tokens": [51332, 23768, 411, 257, 1326, 3262, 9834, 3217, 13, 51464], "temperature": 0.0, "avg_logprob": -0.3660822527124247, "compression_ratio": 1.6505576208178439, "no_speech_prob": 0.0446777306497097}, {"id": 1156, "seek": 533066, "start": 5353.099999999999, "end": 5354.82, "text": " And also they were kind of inspired by-", "tokens": [51486, 400, 611, 436, 645, 733, 295, 7547, 538, 12, 51572], "temperature": 0.0, "avg_logprob": -0.3660822527124247, "compression_ratio": 1.6505576208178439, "no_speech_prob": 0.0446777306497097}, {"id": 1157, "seek": 533066, "start": 5354.82, "end": 5355.5, "text": " A few hundred?", "tokens": [51572, 316, 1326, 3262, 30, 51606], "temperature": 0.0, "avg_logprob": -0.3660822527124247, "compression_ratio": 1.6505576208178439, "no_speech_prob": 0.0446777306497097}, {"id": 1158, "seek": 533066, "start": 5355.7, "end": 5356.34, "text": " That's crazy.", "tokens": [51616, 663, 311, 3219, 13, 51648], "temperature": 0.0, "avg_logprob": -0.3660822527124247, "compression_ratio": 1.6505576208178439, "no_speech_prob": 0.0446777306497097}, {"id": 1159, "seek": 535634, "start": 5356.34, "end": 5362.18, "text": " Like, cause we've been, even now that old fashioned MNIST models have had quite a few million parameters.", "tokens": [50364, 1743, 11, 3082, 321, 600, 668, 11, 754, 586, 300, 1331, 40646, 376, 45, 19756, 5245, 362, 632, 1596, 257, 1326, 2459, 9834, 13, 50656], "temperature": 0.0, "avg_logprob": -0.3197454105723988, "compression_ratio": 1.6697819314641744, "no_speech_prob": 0.010986573994159698}, {"id": 1160, "seek": 535634, "start": 5362.22, "end": 5362.42, "text": " Yeah.", "tokens": [50658, 865, 13, 50668], "temperature": 0.0, "avg_logprob": -0.3197454105723988, "compression_ratio": 1.6697819314641744, "no_speech_prob": 0.010986573994159698}, {"id": 1161, "seek": 535634, "start": 5362.46, "end": 5364.46, "text": " So this is, this is a totally-", "tokens": [50670, 407, 341, 307, 11, 341, 307, 257, 3879, 12, 50770], "temperature": 0.0, "avg_logprob": -0.3197454105723988, "compression_ratio": 1.6697819314641744, "no_speech_prob": 0.010986573994159698}, {"id": 1162, "seek": 535634, "start": 5364.46, "end": 5369.860000000001, "text": " So I should have mentioned that's one of the coolest things about these systems is they really can do a lot with very little parameters.", "tokens": [50770, 407, 286, 820, 362, 2835, 300, 311, 472, 295, 264, 22013, 721, 466, 613, 3652, 307, 436, 534, 393, 360, 257, 688, 365, 588, 707, 9834, 13, 51040], "temperature": 0.0, "avg_logprob": -0.3197454105723988, "compression_ratio": 1.6697819314641744, "no_speech_prob": 0.010986573994159698}, {"id": 1163, "seek": 535634, "start": 5370.54, "end": 5374.9800000000005, "text": " And so these filters that we just going to hard code are going to be the identity, right?", "tokens": [51074, 400, 370, 613, 15995, 300, 321, 445, 516, 281, 1152, 3089, 366, 516, 281, 312, 264, 6575, 11, 558, 30, 51296], "temperature": 0.0, "avg_logprob": -0.3197454105723988, "compression_ratio": 1.6697819314641744, "no_speech_prob": 0.010986573994159698}, {"id": 1164, "seek": 535634, "start": 5374.9800000000005, "end": 5376.14, "text": " Just looking at itself.", "tokens": [51296, 1449, 1237, 412, 2564, 13, 51354], "temperature": 0.0, "avg_logprob": -0.3197454105723988, "compression_ratio": 1.6697819314641744, "no_speech_prob": 0.010986573994159698}, {"id": 1165, "seek": 535634, "start": 5376.66, "end": 5379.78, "text": " And then a couple that looking at gradients.", "tokens": [51380, 400, 550, 257, 1916, 300, 1237, 412, 2771, 2448, 13, 51536], "temperature": 0.0, "avg_logprob": -0.3197454105723988, "compression_ratio": 1.6697819314641744, "no_speech_prob": 0.010986573994159698}, {"id": 1166, "seek": 535634, "start": 5380.1, "end": 5384.860000000001, "text": " Again, inspired by biology where even simple cells can sense gradients of chemical concentration.", "tokens": [51552, 3764, 11, 7547, 538, 14956, 689, 754, 2199, 5438, 393, 2020, 2771, 2448, 295, 7313, 9856, 13, 51790], "temperature": 0.0, "avg_logprob": -0.3197454105723988, "compression_ratio": 1.6697819314641744, "no_speech_prob": 0.010986573994159698}, {"id": 1167, "seek": 538486, "start": 5385.66, "end": 5387.219999999999, "text": " So we're going to have these filters.", "tokens": [50404, 407, 321, 434, 516, 281, 362, 613, 15995, 13, 50482], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1168, "seek": 538486, "start": 5387.219999999999, "end": 5390.7, "text": " We're going to have a way to apply these filters individually.", "tokens": [50482, 492, 434, 516, 281, 362, 257, 636, 281, 3079, 613, 15995, 16652, 13, 50656], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1169, "seek": 538486, "start": 5390.7, "end": 5395.139999999999, "text": " Just to help people understand that that first one, for example, that's a three by three.", "tokens": [50656, 1449, 281, 854, 561, 1223, 300, 300, 700, 472, 11, 337, 1365, 11, 300, 311, 257, 1045, 538, 1045, 13, 50878], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1170, "seek": 538486, "start": 5395.54, "end": 5397.78, "text": " It's been kind of like visually flattened out.", "tokens": [50898, 467, 311, 668, 733, 295, 411, 19622, 24183, 292, 484, 13, 51010], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1171, "seek": 538486, "start": 5397.82, "end": 5401.78, "text": " But if you were to kind of lay it out, you could see it's a identity matrix.", "tokens": [51012, 583, 498, 291, 645, 281, 733, 295, 2360, 309, 484, 11, 291, 727, 536, 309, 311, 257, 6575, 8141, 13, 51210], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1172, "seek": 538486, "start": 5405.219999999999, "end": 5405.42, "text": " Yeah.", "tokens": [51382, 865, 13, 51392], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1173, "seek": 538486, "start": 5405.42, "end": 5406.66, "text": " Anyway, so you can see these filters.", "tokens": [51392, 5684, 11, 370, 291, 393, 536, 613, 15995, 13, 51454], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1174, "seek": 538486, "start": 5406.66, "end": 5408.98, "text": " This one is going to sense a horizontal gradient.", "tokens": [51454, 639, 472, 307, 516, 281, 2020, 257, 12750, 16235, 13, 51570], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1175, "seek": 538486, "start": 5409.82, "end": 5411.66, "text": " This one is going to sense a vertical gradient.", "tokens": [51612, 639, 472, 307, 516, 281, 2020, 257, 9429, 16235, 13, 51704], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1176, "seek": 538486, "start": 5412.219999999999, "end": 5414.259999999999, "text": " And the final one is called a Sobel filter.", "tokens": [51732, 400, 264, 2572, 472, 307, 1219, 257, 407, 5390, 6608, 13, 51834], "temperature": 0.0, "avg_logprob": -0.278876868477703, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.0006263256655074656}, {"id": 1177, "seek": 541426, "start": 5414.780000000001, "end": 5417.820000000001, "text": " And yeah, so we've got some hard coded filters.", "tokens": [50390, 400, 1338, 11, 370, 321, 600, 658, 512, 1152, 34874, 15995, 13, 50542], "temperature": 0.0, "avg_logprob": -0.29807428213266224, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.00013134974869899452}, {"id": 1178, "seek": 541426, "start": 5417.860000000001, "end": 5420.9800000000005, "text": " We're going to apply them individually to each channel of the input.", "tokens": [50544, 492, 434, 516, 281, 3079, 552, 16652, 281, 1184, 2269, 295, 264, 4846, 13, 50700], "temperature": 0.0, "avg_logprob": -0.29807428213266224, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.00013134974869899452}, {"id": 1179, "seek": 541426, "start": 5421.3, "end": 5427.7, "text": " And rather than having a kernel that has separate weights for each channel on the input.", "tokens": [50716, 400, 2831, 813, 1419, 257, 28256, 300, 575, 4994, 17443, 337, 1184, 2269, 322, 264, 4846, 13, 51036], "temperature": 0.0, "avg_logprob": -0.29807428213266224, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.00013134974869899452}, {"id": 1180, "seek": 541426, "start": 5428.38, "end": 5429.58, "text": " And so we can make a grid.", "tokens": [51070, 400, 370, 321, 393, 652, 257, 10748, 13, 51130], "temperature": 0.0, "avg_logprob": -0.29807428213266224, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.00013134974869899452}, {"id": 1181, "seek": 541426, "start": 5430.3, "end": 5432.54, "text": " We can apply our evolution.", "tokens": [51166, 492, 393, 3079, 527, 9303, 13, 51278], "temperature": 0.0, "avg_logprob": -0.29807428213266224, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.00013134974869899452}, {"id": 1182, "seek": 541426, "start": 5432.58, "end": 5434.74, "text": " I didn't know circular was a padding mode before.", "tokens": [51280, 286, 994, 380, 458, 16476, 390, 257, 39562, 4391, 949, 13, 51388], "temperature": 0.0, "avg_logprob": -0.29807428213266224, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.00013134974869899452}, {"id": 1183, "seek": 541426, "start": 5434.74, "end": 5443.38, "text": " So that just does the thing you said where it's basically going to circle around and kind of copy in the thing from the other side when you reach the edge.", "tokens": [51388, 407, 300, 445, 775, 264, 551, 291, 848, 689, 309, 311, 1936, 516, 281, 6329, 926, 293, 733, 295, 5055, 294, 264, 551, 490, 264, 661, 1252, 562, 291, 2524, 264, 4691, 13, 51820], "temperature": 0.0, "avg_logprob": -0.29807428213266224, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.00013134974869899452}, {"id": 1184, "seek": 544338, "start": 5443.38, "end": 5443.900000000001, "text": " Yeah.", "tokens": [50364, 865, 13, 50390], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1185, "seek": 544338, "start": 5444.46, "end": 5444.66, "text": " Yeah.", "tokens": [50418, 865, 13, 50428], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1186, "seek": 544338, "start": 5444.66, "end": 5448.18, "text": " And this is very useful for avoiding issues on the edges with.", "tokens": [50428, 400, 341, 307, 588, 4420, 337, 20220, 2663, 322, 264, 8819, 365, 13, 50604], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1187, "seek": 544338, "start": 5448.18, "end": 5454.7, "text": " So as you'll see, a lot of a little bit of limitations just deal with the fact that they have slightly weird pixels around the edge and they don't really look into it.", "tokens": [50604, 407, 382, 291, 603, 536, 11, 257, 688, 295, 257, 707, 857, 295, 15705, 445, 2028, 365, 264, 1186, 300, 436, 362, 4748, 3657, 18668, 926, 264, 4691, 293, 436, 500, 380, 534, 574, 666, 309, 13, 50930], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1188, "seek": 544338, "start": 5454.74, "end": 5456.5, "text": " And this is one way to deal with that.", "tokens": [50932, 400, 341, 307, 472, 636, 281, 2028, 365, 300, 13, 51020], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1189, "seek": 544338, "start": 5457.26, "end": 5458.1, "text": " Yeah.", "tokens": [51058, 865, 13, 51100], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1190, "seek": 544338, "start": 5458.14, "end": 5458.38, "text": " Okay.", "tokens": [51102, 1033, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1191, "seek": 544338, "start": 5458.38, "end": 5459.38, "text": " So we can make a grid.", "tokens": [51114, 407, 321, 393, 652, 257, 10748, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1192, "seek": 544338, "start": 5459.46, "end": 5462.34, "text": " We can apply our filters to get our model inputs.", "tokens": [51168, 492, 393, 3079, 527, 15995, 281, 483, 527, 2316, 15743, 13, 51312], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1193, "seek": 544338, "start": 5462.78, "end": 5465.26, "text": " And this is going to be 16 inputs, right?", "tokens": [51334, 400, 341, 307, 516, 281, 312, 3165, 15743, 11, 558, 30, 51458], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1194, "seek": 544338, "start": 5465.26, "end": 5467.26, "text": " Because we have four channels and four filters.", "tokens": [51458, 1436, 321, 362, 1451, 9235, 293, 1451, 15995, 13, 51558], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1195, "seek": 544338, "start": 5467.78, "end": 5468.5, "text": " 16 inputs.", "tokens": [51584, 3165, 15743, 13, 51620], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1196, "seek": 544338, "start": 5468.5, "end": 5470.1, "text": " That's going to be the input to our little brain.", "tokens": [51620, 663, 311, 516, 281, 312, 264, 4846, 281, 527, 707, 3567, 13, 51700], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1197, "seek": 544338, "start": 5470.58, "end": 5472.5, "text": " And we have this for every location in the grid.", "tokens": [51724, 400, 321, 362, 341, 337, 633, 4914, 294, 264, 10748, 13, 51820], "temperature": 0.0, "avg_logprob": -0.2704116394801169, "compression_ratio": 1.831715210355987, "no_speech_prob": 0.0013884869404137135}, {"id": 1198, "seek": 547338, "start": 5473.66, "end": 5477.78, "text": " So now how do we implement that little neural network that we saw?", "tokens": [50378, 407, 586, 577, 360, 321, 4445, 300, 707, 18161, 3209, 300, 321, 1866, 30, 50584], "temperature": 0.0, "avg_logprob": -0.2740907669067383, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0058195581659674644}, {"id": 1199, "seek": 547338, "start": 5478.7, "end": 5483.7, "text": " The way it's shown in the diagram is it's a dense linear network and we can set that up.", "tokens": [50630, 440, 636, 309, 311, 4898, 294, 264, 10686, 307, 309, 311, 257, 18011, 8213, 3209, 293, 321, 393, 992, 300, 493, 13, 50880], "temperature": 0.0, "avg_logprob": -0.2740907669067383, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0058195581659674644}, {"id": 1200, "seek": 547338, "start": 5483.7, "end": 5491.7, "text": " We have a linear layer with number of channels by four, which is the number of filters as its number of inputs, some hidden number of neurons.", "tokens": [50880, 492, 362, 257, 8213, 4583, 365, 1230, 295, 9235, 538, 1451, 11, 597, 307, 264, 1230, 295, 15995, 382, 1080, 1230, 295, 15743, 11, 512, 7633, 1230, 295, 22027, 13, 51280], "temperature": 0.0, "avg_logprob": -0.2740907669067383, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0058195581659674644}, {"id": 1201, "seek": 547338, "start": 5491.7, "end": 5497.78, "text": " We have a ReLU and then we have a second linear layer that's outputting one output per channel as the update.", "tokens": [51280, 492, 362, 257, 1300, 43, 52, 293, 550, 321, 362, 257, 1150, 8213, 4583, 300, 311, 5598, 783, 472, 5598, 680, 2269, 382, 264, 5623, 13, 51584], "temperature": 0.0, "avg_logprob": -0.2740907669067383, "compression_ratio": 1.7510729613733906, "no_speech_prob": 0.0058195581659674644}, {"id": 1202, "seek": 549778, "start": 5498.5, "end": 5504.94, "text": " And so if we wanted to use this as our brain, what we'd have to do is we'd have to deal with this, these extra dimensions.", "tokens": [50400, 400, 370, 498, 321, 1415, 281, 764, 341, 382, 527, 3567, 11, 437, 321, 1116, 362, 281, 360, 307, 321, 1116, 362, 281, 2028, 365, 341, 11, 613, 2857, 12819, 13, 50722], "temperature": 0.0, "avg_logprob": -0.2989437269127887, "compression_ratio": 1.7525423728813558, "no_speech_prob": 0.07476649433374405}, {"id": 1203, "seek": 549778, "start": 5505.38, "end": 5508.34, "text": " So we take our batch by channel by height and width.", "tokens": [50744, 407, 321, 747, 527, 15245, 538, 2269, 538, 6681, 293, 11402, 13, 50892], "temperature": 0.0, "avg_logprob": -0.2989437269127887, "compression_ratio": 1.7525423728813558, "no_speech_prob": 0.07476649433374405}, {"id": 1204, "seek": 549778, "start": 5508.82, "end": 5513.74, "text": " We're going to map the batch and the height and the width all to one dimension and the channels to the second dimension.", "tokens": [50916, 492, 434, 516, 281, 4471, 264, 15245, 293, 264, 6681, 293, 264, 11402, 439, 281, 472, 10139, 293, 264, 9235, 281, 264, 1150, 10139, 13, 51162], "temperature": 0.0, "avg_logprob": -0.2989437269127887, "compression_ratio": 1.7525423728813558, "no_speech_prob": 0.07476649433374405}, {"id": 1205, "seek": 549778, "start": 5514.219999999999, "end": 5518.3, "text": " So now we have like a big grid of 16 inputs and lots of examples.", "tokens": [51186, 407, 586, 321, 362, 411, 257, 955, 10748, 295, 3165, 15743, 293, 3195, 295, 5110, 13, 51390], "temperature": 0.0, "avg_logprob": -0.2989437269127887, "compression_ratio": 1.7525423728813558, "no_speech_prob": 0.07476649433374405}, {"id": 1206, "seek": 549778, "start": 5518.3, "end": 5521.42, "text": " I don't think we've seen inops.rearrange before.", "tokens": [51390, 286, 500, 380, 519, 321, 600, 1612, 294, 3370, 13, 265, 2284, 933, 949, 13, 51546], "temperature": 0.0, "avg_logprob": -0.2989437269127887, "compression_ratio": 1.7525423728813558, "no_speech_prob": 0.07476649433374405}, {"id": 1207, "seek": 549778, "start": 5521.42, "end": 5527.34, "text": " So let's like put a bit of a bookmark to come back to teach people about that in maybe in the next video.", "tokens": [51546, 407, 718, 311, 411, 829, 257, 857, 295, 257, 1446, 5638, 281, 808, 646, 281, 2924, 561, 466, 300, 294, 1310, 294, 264, 958, 960, 13, 51842], "temperature": 0.0, "avg_logprob": -0.2989437269127887, "compression_ratio": 1.7525423728813558, "no_speech_prob": 0.07476649433374405}, {"id": 1208, "seek": 552778, "start": 5528.099999999999, "end": 5529.259999999999, "text": " Very, very useful function.", "tokens": [50380, 4372, 11, 588, 4420, 2445, 13, 50438], "temperature": 0.0, "avg_logprob": -0.28588703945950344, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.0024724346585571766}, {"id": 1209, "seek": 552778, "start": 5530.099999999999, "end": 5536.34, "text": " But it is a little complicated because we have to rearrange our inputs into something that has just 16 features,", "tokens": [50480, 583, 309, 307, 257, 707, 6179, 570, 321, 362, 281, 39568, 527, 15743, 666, 746, 300, 575, 445, 3165, 4122, 11, 50792], "temperature": 0.0, "avg_logprob": -0.28588703945950344, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.0024724346585571766}, {"id": 1210, "seek": 552778, "start": 5536.62, "end": 5541.34, "text": " feed that through the linear layer and then rearrange the outputs back to match the shape of our grid.", "tokens": [50806, 3154, 300, 807, 264, 8213, 4583, 293, 550, 39568, 264, 23930, 646, 281, 2995, 264, 3909, 295, 527, 10748, 13, 51042], "temperature": 0.0, "avg_logprob": -0.28588703945950344, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.0024724346585571766}, {"id": 1211, "seek": 552778, "start": 5542.74, "end": 5546.78, "text": " So you can totally do that and you can see what parameters we have on our brain.", "tokens": [51112, 407, 291, 393, 3879, 360, 300, 293, 291, 393, 536, 437, 9834, 321, 362, 322, 527, 3567, 13, 51314], "temperature": 0.0, "avg_logprob": -0.28588703945950344, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.0024724346585571766}, {"id": 1212, "seek": 552778, "start": 5546.78, "end": 5551.139999999999, "text": " We have an 8 by 16 inputs and 8 biases for the first layer.", "tokens": [51314, 492, 362, 364, 1649, 538, 3165, 15743, 293, 1649, 32152, 337, 264, 700, 4583, 13, 51532], "temperature": 0.0, "avg_logprob": -0.28588703945950344, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.0024724346585571766}, {"id": 1213, "seek": 552778, "start": 5551.62, "end": 5556.139999999999, "text": " And then we just have a 4 by 8 weight matrix for the second linear layer.", "tokens": [51556, 400, 550, 321, 445, 362, 257, 1017, 538, 1649, 3364, 8141, 337, 264, 1150, 8213, 4583, 13, 51782], "temperature": 0.0, "avg_logprob": -0.28588703945950344, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.0024724346585571766}, {"id": 1214, "seek": 555614, "start": 5556.14, "end": 5561.740000000001, "text": " And I've said bias equals false because we're having these networks propose an update.", "tokens": [50364, 400, 286, 600, 848, 12577, 6915, 7908, 570, 321, 434, 1419, 613, 9590, 17421, 364, 5623, 13, 50644], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1215, "seek": 555614, "start": 5562.26, "end": 5566.3, "text": " And if we want them to be stable, the update is usually going to be zero or close to it.", "tokens": [50670, 400, 498, 321, 528, 552, 281, 312, 8351, 11, 264, 5623, 307, 2673, 516, 281, 312, 4018, 420, 1998, 281, 309, 13, 50872], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1216, "seek": 555614, "start": 5566.740000000001, "end": 5568.740000000001, "text": " And so there's no need for the bias.", "tokens": [50894, 400, 370, 456, 311, 572, 643, 337, 264, 12577, 13, 50994], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1217, "seek": 555614, "start": 5568.740000000001, "end": 5571.38, "text": " And we want to keep the number of parameters as low as possible.", "tokens": [50994, 400, 321, 528, 281, 1066, 264, 1230, 295, 9834, 382, 2295, 382, 1944, 13, 51126], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1218, "seek": 555614, "start": 5571.38, "end": 5572.62, "text": " That's kind of the name of the game.", "tokens": [51126, 663, 311, 733, 295, 264, 1315, 295, 264, 1216, 13, 51188], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1219, "seek": 555614, "start": 5573.58, "end": 5575.3, "text": " And so that's why we're setting bias equals false.", "tokens": [51236, 400, 370, 300, 311, 983, 321, 434, 3287, 12577, 6915, 7908, 13, 51322], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1220, "seek": 555614, "start": 5576.26, "end": 5578.02, "text": " OK, so this is one way to implement this.", "tokens": [51370, 2264, 11, 370, 341, 307, 472, 636, 281, 4445, 341, 13, 51458], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1221, "seek": 555614, "start": 5578.700000000001, "end": 5579.740000000001, "text": " It's not particularly fast.", "tokens": [51492, 467, 311, 406, 4098, 2370, 13, 51544], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1222, "seek": 555614, "start": 5579.740000000001, "end": 5582.820000000001, "text": " We have to do this reshaping and then we're feeding these examples through the linear layer.", "tokens": [51544, 492, 362, 281, 360, 341, 725, 71, 569, 278, 293, 550, 321, 434, 12919, 613, 5110, 807, 264, 8213, 4583, 13, 51698], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1223, "seek": 555614, "start": 5583.62, "end": 5585.54, "text": " We can cheat by using convolution.", "tokens": [51738, 492, 393, 17470, 538, 1228, 45216, 13, 51834], "temperature": 0.0, "avg_logprob": -0.23155131561077194, "compression_ratio": 1.7538940809968848, "no_speech_prob": 0.006289652548730373}, {"id": 1224, "seek": 558614, "start": 5586.9400000000005, "end": 5590.700000000001, "text": " So this might seem like, wait, that isn't a linear layer.", "tokens": [50404, 407, 341, 1062, 1643, 411, 11, 1699, 11, 300, 1943, 380, 257, 8213, 4583, 13, 50592], "temperature": 0.0, "avg_logprob": -0.24669731541683798, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0008693448617123067}, {"id": 1225, "seek": 558614, "start": 5591.18, "end": 5599.14, "text": " We're going to apply this linear network on top of each set of inputs.", "tokens": [50616, 492, 434, 516, 281, 3079, 341, 8213, 3209, 322, 1192, 295, 1184, 992, 295, 15743, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24669731541683798, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0008693448617123067}, {"id": 1226, "seek": 558614, "start": 5599.46, "end": 5605.06, "text": " But we can do that by having a filter size of one, a kernel size of one in our convolutional layer.", "tokens": [51030, 583, 321, 393, 360, 300, 538, 1419, 257, 6608, 2744, 295, 472, 11, 257, 28256, 2744, 295, 472, 294, 527, 45216, 304, 4583, 13, 51310], "temperature": 0.0, "avg_logprob": -0.24669731541683798, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0008693448617123067}, {"id": 1227, "seek": 558614, "start": 5605.62, "end": 5610.780000000001, "text": " So I have 16 input channels in my model input here.", "tokens": [51338, 407, 286, 362, 3165, 4846, 9235, 294, 452, 2316, 4846, 510, 13, 51596], "temperature": 0.0, "avg_logprob": -0.24669731541683798, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0008693448617123067}, {"id": 1228, "seek": 558614, "start": 5611.54, "end": 5615.18, "text": " And I'm going to have eight output channels from this first convolutional layer.", "tokens": [51634, 400, 286, 478, 516, 281, 362, 3180, 5598, 9235, 490, 341, 700, 45216, 304, 4583, 13, 51816], "temperature": 0.0, "avg_logprob": -0.24669731541683798, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0008693448617123067}, {"id": 1229, "seek": 561518, "start": 5615.700000000001, "end": 5617.5, "text": " And my kernel size is going to be one by one.", "tokens": [50390, 400, 452, 28256, 2744, 307, 516, 281, 312, 472, 538, 472, 13, 50480], "temperature": 0.0, "avg_logprob": -0.2511043235903881, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0005192983080632985}, {"id": 1230, "seek": 561518, "start": 5618.42, "end": 5622.58, "text": " And then I have ReLU and then I have another one by one convolutional layer.", "tokens": [50526, 400, 550, 286, 362, 1300, 43, 52, 293, 550, 286, 362, 1071, 472, 538, 472, 45216, 304, 4583, 13, 50734], "temperature": 0.0, "avg_logprob": -0.2511043235903881, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0005192983080632985}, {"id": 1231, "seek": 561518, "start": 5623.58, "end": 5625.9800000000005, "text": " And so we can see this gives me the right shape output.", "tokens": [50784, 400, 370, 321, 393, 536, 341, 2709, 385, 264, 558, 3909, 5598, 13, 50904], "temperature": 0.0, "avg_logprob": -0.2511043235903881, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0005192983080632985}, {"id": 1232, "seek": 561518, "start": 5625.9800000000005, "end": 5634.06, "text": " And if I look at the parameters, my first convolutional layer has eight by 16 by one by one parameters in its filters.", "tokens": [50904, 400, 498, 286, 574, 412, 264, 9834, 11, 452, 700, 45216, 304, 4583, 575, 3180, 538, 3165, 538, 472, 538, 472, 9834, 294, 1080, 15995, 13, 51308], "temperature": 0.0, "avg_logprob": -0.2511043235903881, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0005192983080632985}, {"id": 1233, "seek": 561518, "start": 5634.58, "end": 5640.58, "text": " And so maybe spend a little bit of time convincing yourself that these two are doing the same operation.", "tokens": [51334, 400, 370, 1310, 3496, 257, 707, 857, 295, 565, 24823, 1803, 300, 613, 732, 366, 884, 264, 912, 6916, 13, 51634], "temperature": 0.0, "avg_logprob": -0.2511043235903881, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0005192983080632985}, {"id": 1234, "seek": 561518, "start": 5641.02, "end": 5642.38, "text": " Yeah, this stuff is using shading.", "tokens": [51656, 865, 11, 341, 1507, 307, 1228, 30556, 13, 51724], "temperature": 0.0, "avg_logprob": -0.2511043235903881, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0005192983080632985}, {"id": 1235, "seek": 561518, "start": 5642.38, "end": 5643.700000000001, "text": " I mean, this is quite elegant.", "tokens": [51724, 286, 914, 11, 341, 307, 1596, 21117, 13, 51790], "temperature": 0.0, "avg_logprob": -0.2511043235903881, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0005192983080632985}, {"id": 1236, "seek": 564370, "start": 5644.46, "end": 5651.26, "text": " And in languages like APL, actually, there's an operation called stenciling, which is basically the same idea.", "tokens": [50402, 400, 294, 8650, 411, 5372, 43, 11, 767, 11, 456, 311, 364, 6916, 1219, 38670, 278, 11, 597, 307, 1936, 264, 912, 1558, 13, 50742], "temperature": 0.0, "avg_logprob": -0.25389326943291557, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.0010986990528181195}, {"id": 1237, "seek": 564370, "start": 5651.26, "end": 5654.74, "text": " It's this idea of like applying some computation over a grid.", "tokens": [50742, 467, 311, 341, 1558, 295, 411, 9275, 512, 24903, 670, 257, 10748, 13, 50916], "temperature": 0.0, "avg_logprob": -0.25389326943291557, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.0010986990528181195}, {"id": 1238, "seek": 564370, "start": 5655.66, "end": 5659.46, "text": " Yeah. And I should mention that convolutions are very efficient.", "tokens": [50962, 865, 13, 400, 286, 820, 2152, 300, 3754, 15892, 366, 588, 7148, 13, 51152], "temperature": 0.0, "avg_logprob": -0.25389326943291557, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.0010986990528181195}, {"id": 1239, "seek": 564370, "start": 5659.74, "end": 5662.74, "text": " All of our GPUs and things are set up for this kind of operation.", "tokens": [51166, 1057, 295, 527, 18407, 82, 293, 721, 366, 992, 493, 337, 341, 733, 295, 6916, 13, 51316], "temperature": 0.0, "avg_logprob": -0.25389326943291557, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.0010986990528181195}, {"id": 1240, "seek": 564370, "start": 5663.7, "end": 5672.5, "text": " And what makes neural cellular automata quite exciting is that because we're doing this convolution, you have an operation for every pixel that we're applying.", "tokens": [51364, 400, 437, 1669, 18161, 29267, 3553, 3274, 1596, 4670, 307, 300, 570, 321, 434, 884, 341, 45216, 11, 291, 362, 364, 6916, 337, 633, 19261, 300, 321, 434, 9275, 13, 51804], "temperature": 0.0, "avg_logprob": -0.25389326943291557, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.0010986990528181195}, {"id": 1241, "seek": 567250, "start": 5672.5, "end": 5675.42, "text": " Right. And this is looking at the neighborhood of reducing an output.", "tokens": [50364, 1779, 13, 400, 341, 307, 1237, 412, 264, 7630, 295, 12245, 364, 5598, 13, 50510], "temperature": 0.0, "avg_logprob": -0.23746038164411273, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.014727612026035786}, {"id": 1242, "seek": 567250, "start": 5675.42, "end": 5677.78, "text": " There's no global thing that we need to handle.", "tokens": [50510, 821, 311, 572, 4338, 551, 300, 321, 643, 281, 4813, 13, 50628], "temperature": 0.0, "avg_logprob": -0.23746038164411273, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.014727612026035786}, {"id": 1243, "seek": 567250, "start": 5678.58, "end": 5681.74, "text": " And so this is actually exactly what GPUs were designed for.", "tokens": [50668, 400, 370, 341, 307, 767, 2293, 437, 18407, 82, 645, 4761, 337, 13, 50826], "temperature": 0.0, "avg_logprob": -0.23746038164411273, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.014727612026035786}, {"id": 1244, "seek": 567250, "start": 5681.9, "end": 5689.3, "text": " They're designed for running some operation for every pixel on your screen to render graphics or show you your video game or make your website scroll nice and slick.", "tokens": [50834, 814, 434, 4761, 337, 2614, 512, 6916, 337, 633, 19261, 322, 428, 2568, 281, 15529, 11837, 420, 855, 291, 428, 960, 1216, 420, 652, 428, 3144, 11369, 1481, 293, 37406, 13, 51204], "temperature": 0.0, "avg_logprob": -0.23746038164411273, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.014727612026035786}, {"id": 1245, "seek": 567250, "start": 5690.1, "end": 5697.54, "text": " And so we can take advantage of that kind of built in bias of the hardware from doing lots of little operations in parallel to make these go really, really fast.", "tokens": [51244, 400, 370, 321, 393, 747, 5002, 295, 300, 733, 295, 3094, 294, 12577, 295, 264, 8837, 490, 884, 3195, 295, 707, 7705, 294, 8952, 281, 652, 613, 352, 534, 11, 534, 2370, 13, 51616], "temperature": 0.0, "avg_logprob": -0.23746038164411273, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.014727612026035786}, {"id": 1246, "seek": 567250, "start": 5697.94, "end": 5702.38, "text": " And we'll show I'll show you just now we can run these real time in the browser, which is quite satisfying.", "tokens": [51636, 400, 321, 603, 855, 286, 603, 855, 291, 445, 586, 321, 393, 1190, 613, 957, 565, 294, 264, 11185, 11, 597, 307, 1596, 18348, 13, 51858], "temperature": 0.0, "avg_logprob": -0.23746038164411273, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.014727612026035786}, {"id": 1247, "seek": 570250, "start": 5703.5, "end": 5707.34, "text": " OK, so now that we have all that infrastructure in place, I'm just going to put it into a class.", "tokens": [50414, 2264, 11, 370, 586, 300, 321, 362, 439, 300, 6896, 294, 1081, 11, 286, 478, 445, 516, 281, 829, 309, 666, 257, 1508, 13, 50606], "temperature": 0.0, "avg_logprob": -0.2823782447430727, "compression_ratio": 1.633846153846154, "no_speech_prob": 0.005640860181301832}, {"id": 1248, "seek": 570250, "start": 5707.34, "end": 5709.74, "text": " My simple CA is my cellular automata.", "tokens": [50606, 1222, 2199, 22852, 307, 452, 29267, 3553, 3274, 13, 50726], "temperature": 0.0, "avg_logprob": -0.2823782447430727, "compression_ratio": 1.633846153846154, "no_speech_prob": 0.005640860181301832}, {"id": 1249, "seek": 570250, "start": 5710.02, "end": 5713.14, "text": " We have our little brain, two convolutional layers and a value.", "tokens": [50740, 492, 362, 527, 707, 3567, 11, 732, 45216, 304, 7914, 293, 257, 2158, 13, 50896], "temperature": 0.0, "avg_logprob": -0.2823782447430727, "compression_ratio": 1.633846153846154, "no_speech_prob": 0.005640860181301832}, {"id": 1250, "seek": 570250, "start": 5714.06, "end": 5721.74, "text": " Optionally, we can set the weights of the second layer to zero again, because you want to start by being very conservative in terms of what updates we we produce.", "tokens": [50942, 29284, 379, 11, 321, 393, 992, 264, 17443, 295, 264, 1150, 4583, 281, 4018, 797, 11, 570, 291, 528, 281, 722, 538, 885, 588, 13780, 294, 2115, 295, 437, 9205, 321, 321, 5258, 13, 51326], "temperature": 0.0, "avg_logprob": -0.2823782447430727, "compression_ratio": 1.633846153846154, "no_speech_prob": 0.005640860181301832}, {"id": 1251, "seek": 570250, "start": 5722.54, "end": 5725.1, "text": " Not necessarily necessary, but it does help the training.", "tokens": [51366, 1726, 4725, 4818, 11, 457, 309, 775, 854, 264, 3097, 13, 51494], "temperature": 0.0, "avg_logprob": -0.2823782447430727, "compression_ratio": 1.633846153846154, "no_speech_prob": 0.005640860181301832}, {"id": 1252, "seek": 570250, "start": 5725.62, "end": 5726.9, "text": " And then in our forward pass.", "tokens": [51520, 400, 550, 294, 527, 2128, 1320, 13, 51584], "temperature": 0.0, "avg_logprob": -0.2823782447430727, "compression_ratio": 1.633846153846154, "no_speech_prob": 0.005640860181301832}, {"id": 1253, "seek": 570250, "start": 5726.9, "end": 5728.06, "text": " I would be inclined.", "tokens": [51584, 286, 576, 312, 28173, 13, 51642], "temperature": 0.0, "avg_logprob": -0.2823782447430727, "compression_ratio": 1.633846153846154, "no_speech_prob": 0.005640860181301832}, {"id": 1254, "seek": 570250, "start": 5728.06, "end": 5730.22, "text": " I don't know if it matters, but I'd be inclined to put that.", "tokens": [51642, 286, 500, 380, 458, 498, 309, 7001, 11, 457, 286, 1116, 312, 28173, 281, 829, 300, 13, 51750], "temperature": 0.0, "avg_logprob": -0.2823782447430727, "compression_ratio": 1.633846153846154, "no_speech_prob": 0.005640860181301832}, {"id": 1255, "seek": 573022, "start": 5730.5, "end": 5731.54, "text": " I would be inclined to do.", "tokens": [50378, 286, 576, 312, 28173, 281, 360, 13, 50430], "temperature": 0.0, "avg_logprob": -0.3621434812192564, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022869384847581387}, {"id": 1256, "seek": 573022, "start": 5733.46, "end": 5735.1, "text": " You know, and in it.", "tokens": [50526, 509, 458, 11, 293, 294, 309, 13, 50608], "temperature": 0.0, "avg_logprob": -0.3621434812192564, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022869384847581387}, {"id": 1257, "seek": 573022, "start": 5736.34, "end": 5744.26, "text": " Constant zero or put that in a no grad, like often initializing things without no grad can cause problems.", "tokens": [50670, 37413, 4018, 420, 829, 300, 294, 257, 572, 2771, 11, 411, 2049, 5883, 3319, 721, 1553, 572, 2771, 393, 3082, 2740, 13, 51066], "temperature": 0.0, "avg_logprob": -0.3621434812192564, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022869384847581387}, {"id": 1258, "seek": 573022, "start": 5745.06, "end": 5746.900000000001, "text": " OK, I'll look into that.", "tokens": [51106, 2264, 11, 286, 603, 574, 666, 300, 13, 51198], "temperature": 0.0, "avg_logprob": -0.3621434812192564, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022869384847581387}, {"id": 1259, "seek": 573022, "start": 5748.900000000001, "end": 5754.3, "text": " In the forward method, we're going to apply our filters to get our model inputs and then we've got data zero.", "tokens": [51298, 682, 264, 2128, 3170, 11, 321, 434, 516, 281, 3079, 527, 15995, 281, 483, 527, 2316, 15743, 293, 550, 321, 600, 658, 1412, 4018, 13, 51568], "temperature": 0.0, "avg_logprob": -0.3621434812192564, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022869384847581387}, {"id": 1260, "seek": 573022, "start": 5754.34, "end": 5755.900000000001, "text": " OK, so that's that's fine.", "tokens": [51570, 2264, 11, 370, 300, 311, 300, 311, 2489, 13, 51648], "temperature": 0.0, "avg_logprob": -0.3621434812192564, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022869384847581387}, {"id": 1261, "seek": 573022, "start": 5756.5, "end": 5758.62, "text": " Yeah, I think this is the built in the built in method.", "tokens": [51678, 865, 11, 286, 519, 341, 307, 264, 3094, 294, 264, 3094, 294, 3170, 13, 51784], "temperature": 0.0, "avg_logprob": -0.3621434812192564, "compression_ratio": 1.5965665236051503, "no_speech_prob": 0.0022869384847581387}, {"id": 1262, "seek": 575862, "start": 5758.66, "end": 5759.18, "text": " All right.", "tokens": [50366, 1057, 558, 13, 50392], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1263, "seek": 575862, "start": 5759.26, "end": 5761.5, "text": " Oh, it's the dot data, which is the thing that makes it.", "tokens": [50396, 876, 11, 309, 311, 264, 5893, 1412, 11, 597, 307, 264, 551, 300, 1669, 309, 13, 50508], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1264, "seek": 575862, "start": 5761.58, "end": 5761.98, "text": " Yeah.", "tokens": [50512, 865, 13, 50532], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1265, "seek": 575862, "start": 5761.98, "end": 5764.42, "text": " You don't need torch dot no grad because you've got dot data.", "tokens": [50532, 509, 500, 380, 643, 27822, 5893, 572, 2771, 570, 291, 600, 658, 5893, 1412, 13, 50654], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1266, "seek": 575862, "start": 5764.58, "end": 5765.08, "text": " So.", "tokens": [50662, 407, 13, 50687], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1267, "seek": 575862, "start": 5765.94, "end": 5766.58, "text": " Yeah, it's all good.", "tokens": [50730, 865, 11, 309, 311, 439, 665, 13, 50762], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1268, "seek": 575862, "start": 5767.38, "end": 5768.34, "text": " And cool.", "tokens": [50802, 400, 1627, 13, 50850], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1269, "seek": 575862, "start": 5768.58, "end": 5771.18, "text": " OK. And so the forward is applying the filters.", "tokens": [50862, 2264, 13, 400, 370, 264, 2128, 307, 9275, 264, 15995, 13, 50992], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1270, "seek": 575862, "start": 5771.54, "end": 5775.42, "text": " It's feeding it through the first convolutional layer, then the ready, then the second layer.", "tokens": [51010, 467, 311, 12919, 309, 807, 264, 700, 45216, 304, 4583, 11, 550, 264, 1919, 11, 550, 264, 1150, 4583, 13, 51204], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1271, "seek": 575862, "start": 5776.66, "end": 5780.54, "text": " And then it's doing this final step, which again goes back to the original paper.", "tokens": [51266, 400, 550, 309, 311, 884, 341, 2572, 1823, 11, 597, 797, 1709, 646, 281, 264, 3380, 3035, 13, 51460], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1272, "seek": 575862, "start": 5781.66, "end": 5786.22, "text": " Somewhere in here, they mentioned that they are inspired by biology.", "tokens": [51516, 34500, 294, 510, 11, 436, 2835, 300, 436, 366, 7547, 538, 14956, 13, 51744], "temperature": 0.0, "avg_logprob": -0.36803436279296875, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0006166065577417612}, {"id": 1273, "seek": 578622, "start": 5786.54, "end": 5791.9800000000005, "text": " And one thing that you don't have in a biological system is some sort of global clock where everything updates at exactly the same second.", "tokens": [50380, 400, 472, 551, 300, 291, 500, 380, 362, 294, 257, 13910, 1185, 307, 512, 1333, 295, 4338, 7830, 689, 1203, 9205, 412, 2293, 264, 912, 1150, 13, 50652], "temperature": 0.0, "avg_logprob": -0.2609901983761093, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.08034379035234451}, {"id": 1274, "seek": 578622, "start": 5792.9800000000005, "end": 5794.26, "text": " It's much more random and organic.", "tokens": [50702, 467, 311, 709, 544, 4974, 293, 10220, 13, 50766], "temperature": 0.0, "avg_logprob": -0.2609901983761093, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.08034379035234451}, {"id": 1275, "seek": 578622, "start": 5794.26, "end": 5795.66, "text": " Each one is almost independent.", "tokens": [50766, 6947, 472, 307, 1920, 6695, 13, 50836], "temperature": 0.0, "avg_logprob": -0.2609901983761093, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.08034379035234451}, {"id": 1276, "seek": 578622, "start": 5796.1, "end": 5800.38, "text": " And so to mirror that, what we do here is we create a random update mask.", "tokens": [50858, 400, 370, 281, 8013, 300, 11, 437, 321, 360, 510, 307, 321, 1884, 257, 4974, 5623, 6094, 13, 51072], "temperature": 0.0, "avg_logprob": -0.2609901983761093, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.08034379035234451}, {"id": 1277, "seek": 578622, "start": 5801.26, "end": 5803.42, "text": " And if you go in, let's just actually write this out.", "tokens": [51116, 400, 498, 291, 352, 294, 11, 718, 311, 445, 767, 2464, 341, 484, 13, 51224], "temperature": 0.0, "avg_logprob": -0.2609901983761093, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.08034379035234451}, {"id": 1278, "seek": 578622, "start": 5806.5, "end": 5810.22, "text": " Let's just make a cell and check that this is what we're doing.", "tokens": [51378, 961, 311, 445, 652, 257, 2815, 293, 1520, 300, 341, 307, 437, 321, 434, 884, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2609901983761093, "compression_ratio": 1.6008064516129032, "no_speech_prob": 0.08034379035234451}, {"id": 1279, "seek": 581022, "start": 5810.22, "end": 5817.02, "text": " So I'm going to just go mvhw1 just to visualize.", "tokens": [50364, 407, 286, 478, 516, 281, 445, 352, 275, 85, 71, 86, 16, 445, 281, 23273, 13, 50704], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1280, "seek": 581022, "start": 5819.54, "end": 5820.1, "text": " Update rate.", "tokens": [50830, 28923, 3314, 13, 50858], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1281, "seek": 581022, "start": 5823.06, "end": 5823.42, "text": " There we go.", "tokens": [51006, 821, 321, 352, 13, 51024], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1282, "seek": 581022, "start": 5823.58, "end": 5823.780000000001, "text": " Yeah.", "tokens": [51032, 865, 13, 51042], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1283, "seek": 581022, "start": 5823.820000000001, "end": 5828.9800000000005, "text": " So this is creating this random mask, some zeros and some ones according to what our update rate is.", "tokens": [51044, 407, 341, 307, 4084, 341, 4974, 6094, 11, 512, 35193, 293, 512, 2306, 4650, 281, 437, 527, 5623, 3314, 307, 13, 51302], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1284, "seek": 581022, "start": 5830.1, "end": 5835.42, "text": " And this is going to determine whether we apply this update to our original input or not.", "tokens": [51358, 400, 341, 307, 516, 281, 6997, 1968, 321, 3079, 341, 5623, 281, 527, 3380, 4846, 420, 406, 13, 51624], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1285, "seek": 581022, "start": 5835.9400000000005, "end": 5836.7, "text": " It's a lot like dropout.", "tokens": [51650, 467, 311, 257, 688, 411, 3270, 346, 13, 51688], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1286, "seek": 581022, "start": 5836.7, "end": 5837.42, "text": " This is my what?", "tokens": [51688, 639, 307, 452, 437, 30, 51724], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1287, "seek": 581022, "start": 5838.18, "end": 5838.9400000000005, "text": " Yeah, it's like dropout.", "tokens": [51762, 865, 11, 309, 311, 411, 3270, 346, 13, 51800], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1288, "seek": 581022, "start": 5838.9800000000005, "end": 5839.5, "text": " Exactly.", "tokens": [51802, 7587, 13, 51828], "temperature": 0.0, "avg_logprob": -0.44326033415617766, "compression_ratio": 1.5844748858447488, "no_speech_prob": 0.09137528389692307}, {"id": 1289, "seek": 584022, "start": 5840.54, "end": 5849.18, "text": " And why this is nice, if you imagine we start from a perfectly uniform grid and then every cell is running the exact same rule, after one update, we will still have a perfectly uniform grid.", "tokens": [50380, 400, 983, 341, 307, 1481, 11, 498, 291, 3811, 321, 722, 490, 257, 6239, 9452, 10748, 293, 550, 633, 2815, 307, 2614, 264, 1900, 912, 4978, 11, 934, 472, 5623, 11, 321, 486, 920, 362, 257, 6239, 9452, 10748, 13, 50812], "temperature": 0.0, "avg_logprob": -0.24674635667067307, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.005819818004965782}, {"id": 1290, "seek": 584022, "start": 5849.780000000001, "end": 5851.62, "text": " There's no way for there to be any randomness.", "tokens": [50842, 821, 311, 572, 636, 337, 456, 281, 312, 604, 4974, 1287, 13, 50934], "temperature": 0.0, "avg_logprob": -0.24674635667067307, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.005819818004965782}, {"id": 1291, "seek": 584022, "start": 5851.780000000001, "end": 5853.820000000001, "text": " And so we can never break out of that.", "tokens": [50942, 400, 370, 321, 393, 1128, 1821, 484, 295, 300, 13, 51044], "temperature": 0.0, "avg_logprob": -0.24674635667067307, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.005819818004965782}, {"id": 1292, "seek": 584022, "start": 5854.7, "end": 5858.62, "text": " Whereas once we add this random updates, only a subset of cells are going to be updated.", "tokens": [51088, 13813, 1564, 321, 909, 341, 4974, 9205, 11, 787, 257, 25993, 295, 5438, 366, 516, 281, 312, 10588, 13, 51284], "temperature": 0.0, "avg_logprob": -0.24674635667067307, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.005819818004965782}, {"id": 1293, "seek": 584022, "start": 5858.7, "end": 5859.740000000001, "text": " And now there's some differences.", "tokens": [51288, 400, 586, 456, 311, 512, 7300, 13, 51340], "temperature": 0.0, "avg_logprob": -0.24674635667067307, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.005819818004965782}, {"id": 1294, "seek": 584022, "start": 5859.740000000001, "end": 5861.9400000000005, "text": " They have different neighborhoods and things.", "tokens": [51340, 814, 362, 819, 20052, 293, 721, 13, 51450], "temperature": 0.0, "avg_logprob": -0.24674635667067307, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.005819818004965782}, {"id": 1295, "seek": 584022, "start": 5861.9400000000005, "end": 5864.26, "text": " And so then we get this added randomness in.", "tokens": [51450, 400, 370, 550, 321, 483, 341, 3869, 4974, 1287, 294, 13, 51566], "temperature": 0.0, "avg_logprob": -0.24674635667067307, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.005819818004965782}, {"id": 1296, "seek": 584022, "start": 5864.7, "end": 5868.06, "text": " And this is very much like in a biological system, no cell is going to be identical.", "tokens": [51588, 400, 341, 307, 588, 709, 411, 294, 257, 13910, 1185, 11, 572, 2815, 307, 516, 281, 312, 14800, 13, 51756], "temperature": 0.0, "avg_logprob": -0.24674635667067307, "compression_ratio": 1.8312101910828025, "no_speech_prob": 0.005819818004965782}, {"id": 1297, "seek": 586806, "start": 5868.580000000001, "end": 5874.38, "text": " So that's a little bit of additional complexity, but again, inspired by nature and inspired by paper.", "tokens": [50390, 407, 300, 311, 257, 707, 857, 295, 4497, 14024, 11, 457, 797, 11, 7547, 538, 3687, 293, 7547, 538, 3035, 13, 50680], "temperature": 0.0, "avg_logprob": -0.24149822587726497, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.010817386209964752}, {"id": 1298, "seek": 586806, "start": 5875.18, "end": 5878.02, "text": " With all of this in place, we can do our training.", "tokens": [50720, 2022, 439, 295, 341, 294, 1081, 11, 321, 393, 360, 527, 3097, 13, 50862], "temperature": 0.0, "avg_logprob": -0.24149822587726497, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.010817386209964752}, {"id": 1299, "seek": 586806, "start": 5878.22, "end": 5881.5, "text": " We're going to use the same dummy dataset idea as before.", "tokens": [50872, 492, 434, 516, 281, 764, 264, 912, 35064, 28872, 1558, 382, 949, 13, 51036], "temperature": 0.0, "avg_logprob": -0.24149822587726497, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.010817386209964752}, {"id": 1300, "seek": 586806, "start": 5882.1, "end": 5890.54, "text": " We are going to have a progress callback, which is a lot of code, but it's all just basically sitting around for doing some plotting.", "tokens": [51066, 492, 366, 516, 281, 362, 257, 4205, 818, 3207, 11, 597, 307, 257, 688, 295, 3089, 11, 457, 309, 311, 439, 445, 1936, 3798, 926, 337, 884, 512, 41178, 13, 51488], "temperature": 0.0, "avg_logprob": -0.24149822587726497, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.010817386209964752}, {"id": 1301, "seek": 586806, "start": 5890.9800000000005, "end": 5892.820000000001, "text": " So I'm not going to spend too much time on that.", "tokens": [51510, 407, 286, 478, 406, 516, 281, 3496, 886, 709, 565, 322, 300, 13, 51602], "temperature": 0.0, "avg_logprob": -0.24149822587726497, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.010817386209964752}, {"id": 1302, "seek": 586806, "start": 5893.42, "end": 5896.34, "text": " And then the fun stuff is going to happen in our training callback.", "tokens": [51632, 400, 550, 264, 1019, 1507, 307, 516, 281, 1051, 294, 527, 3097, 818, 3207, 13, 51778], "temperature": 0.0, "avg_logprob": -0.24149822587726497, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.010817386209964752}, {"id": 1303, "seek": 589634, "start": 5896.66, "end": 5898.9400000000005, "text": " And so now we are actually getting deep into the weeds.", "tokens": [50380, 400, 370, 586, 321, 366, 767, 1242, 2452, 666, 264, 26370, 13, 50494], "temperature": 0.0, "avg_logprob": -0.25868942119457106, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.0036499144043773413}, {"id": 1304, "seek": 589634, "start": 5898.9400000000005, "end": 5901.5, "text": " We're modifying our prediction function.", "tokens": [50494, 492, 434, 42626, 527, 17630, 2445, 13, 50622], "temperature": 0.0, "avg_logprob": -0.25868942119457106, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.0036499144043773413}, {"id": 1305, "seek": 589634, "start": 5901.860000000001, "end": 5904.66, "text": " This is much more complicated than just feeding a batch of data through our model.", "tokens": [50640, 639, 307, 709, 544, 6179, 813, 445, 12919, 257, 15245, 295, 1412, 807, 527, 2316, 13, 50780], "temperature": 0.0, "avg_logprob": -0.25868942119457106, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.0036499144043773413}, {"id": 1306, "seek": 589634, "start": 5905.46, "end": 5911.5, "text": " We are setting up a pool of grids, 256 examples.", "tokens": [50820, 492, 366, 3287, 493, 257, 7005, 295, 677, 3742, 11, 38882, 5110, 13, 51122], "temperature": 0.0, "avg_logprob": -0.25868942119457106, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.0036499144043773413}, {"id": 1307, "seek": 589634, "start": 5911.66, "end": 5914.62, "text": " And these are all going to start out as just uniform zeros.", "tokens": [51130, 400, 613, 366, 439, 516, 281, 722, 484, 382, 445, 9452, 35193, 13, 51278], "temperature": 0.0, "avg_logprob": -0.25868942119457106, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.0036499144043773413}, {"id": 1308, "seek": 589634, "start": 5915.62, "end": 5919.900000000001, "text": " But every time we call predict, we're going to pick some random samples from that pool.", "tokens": [51328, 583, 633, 565, 321, 818, 6069, 11, 321, 434, 516, 281, 1888, 512, 4974, 10938, 490, 300, 7005, 13, 51542], "temperature": 0.0, "avg_logprob": -0.25868942119457106, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.0036499144043773413}, {"id": 1309, "seek": 589634, "start": 5921.9400000000005, "end": 5924.9400000000005, "text": " We are occasionally going to reset those samples to the initial state.", "tokens": [51644, 492, 366, 16895, 516, 281, 14322, 729, 10938, 281, 264, 5883, 1785, 13, 51794], "temperature": 0.0, "avg_logprob": -0.25868942119457106, "compression_ratio": 1.6804511278195489, "no_speech_prob": 0.0036499144043773413}, {"id": 1310, "seek": 592634, "start": 5926.66, "end": 5928.82, "text": " And then we can apply the model a number of times.", "tokens": [50380, 400, 550, 321, 393, 3079, 264, 2316, 257, 1230, 295, 1413, 13, 50488], "temperature": 0.0, "avg_logprob": -0.40603882639031663, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0007321704179048538}, {"id": 1311, "seek": 592634, "start": 5929.18, "end": 5939.22, "text": " And it's worth thinking here, if we are applying this model 50 steps, this is like a 50 layer deep model all of a sudden.", "tokens": [50506, 400, 309, 311, 3163, 1953, 510, 11, 498, 321, 366, 9275, 341, 2316, 2625, 4439, 11, 341, 307, 411, 257, 2625, 4583, 2452, 2316, 439, 295, 257, 3990, 13, 51008], "temperature": 0.0, "avg_logprob": -0.40603882639031663, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0007321704179048538}, {"id": 1312, "seek": 592634, "start": 5939.82, "end": 5940.9400000000005, "text": " And so we start to get some of the same issues.", "tokens": [51038, 400, 370, 321, 722, 281, 483, 512, 295, 264, 912, 2663, 13, 51094], "temperature": 0.0, "avg_logprob": -0.40603882639031663, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0007321704179048538}, {"id": 1313, "seek": 592634, "start": 5940.9400000000005, "end": 5943.46, "text": " Is that learn.model rather than self.learn.model?", "tokens": [51094, 1119, 300, 1466, 13, 8014, 338, 2831, 813, 2698, 13, 306, 1083, 13, 8014, 338, 30, 51220], "temperature": 0.0, "avg_logprob": -0.40603882639031663, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0007321704179048538}, {"id": 1314, "seek": 592634, "start": 5945.34, "end": 5946.46, "text": " Oh, yes, because I already have learn.", "tokens": [51314, 876, 11, 2086, 11, 570, 286, 1217, 362, 1466, 13, 51370], "temperature": 0.0, "avg_logprob": -0.40603882639031663, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0007321704179048538}, {"id": 1315, "seek": 592634, "start": 5948.06, "end": 5948.38, "text": " Nice.", "tokens": [51450, 5490, 13, 51466], "temperature": 0.0, "avg_logprob": -0.40603882639031663, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0007321704179048538}, {"id": 1316, "seek": 594838, "start": 5949.1, "end": 5959.82, "text": " And yeah, so we've got to just be aware that by applying this a large number of times, we could get something like gradient exploding and things like that, which we'll deal with a little bit later.", "tokens": [50400, 400, 1338, 11, 370, 321, 600, 658, 281, 445, 312, 3650, 300, 538, 9275, 341, 257, 2416, 1230, 295, 1413, 11, 321, 727, 483, 746, 411, 16235, 35175, 293, 721, 411, 300, 11, 597, 321, 603, 2028, 365, 257, 707, 857, 1780, 13, 50936], "temperature": 0.0, "avg_logprob": -0.24670965709383524, "compression_ratio": 1.7789115646258504, "no_speech_prob": 0.33799993991851807}, {"id": 1317, "seek": 594838, "start": 5960.26, "end": 5962.46, "text": " And but we apply the model a large number of steps.", "tokens": [50958, 400, 457, 321, 3079, 264, 2316, 257, 2416, 1230, 295, 4439, 13, 51068], "temperature": 0.0, "avg_logprob": -0.24670965709383524, "compression_ratio": 1.7789115646258504, "no_speech_prob": 0.33799993991851807}, {"id": 1318, "seek": 594838, "start": 5963.3, "end": 5968.900000000001, "text": " Then we put those final outputs back in the pool for the next round of training and we store our predictions.", "tokens": [51110, 1396, 321, 829, 729, 2572, 23930, 646, 294, 264, 7005, 337, 264, 958, 3098, 295, 3097, 293, 321, 3531, 527, 21264, 13, 51390], "temperature": 0.0, "avg_logprob": -0.24670965709383524, "compression_ratio": 1.7789115646258504, "no_speech_prob": 0.33799993991851807}, {"id": 1319, "seek": 594838, "start": 5968.9400000000005, "end": 5971.62, "text": " These are the outputs after we've applied a number of steps.", "tokens": [51392, 1981, 366, 264, 23930, 934, 321, 600, 6456, 257, 1230, 295, 4439, 13, 51526], "temperature": 0.0, "avg_logprob": -0.24670965709383524, "compression_ratio": 1.7789115646258504, "no_speech_prob": 0.33799993991851807}, {"id": 1320, "seek": 594838, "start": 5972.7, "end": 5977.9800000000005, "text": " And in the loss, we're going to use a style loss saying, does this match the style of my target image?", "tokens": [51580, 400, 294, 264, 4470, 11, 321, 434, 516, 281, 764, 257, 3758, 4470, 1566, 11, 775, 341, 2995, 264, 3758, 295, 452, 3779, 3256, 30, 51844], "temperature": 0.0, "avg_logprob": -0.24670965709383524, "compression_ratio": 1.7789115646258504, "no_speech_prob": 0.33799993991851807}, {"id": 1321, "seek": 597838, "start": 5978.9400000000005, "end": 5983.02, "text": " And we're going to add an overflow loss that penalizes it if the values are out of bounds.", "tokens": [50392, 400, 321, 434, 516, 281, 909, 364, 37772, 4470, 300, 13661, 5660, 309, 498, 264, 4190, 366, 484, 295, 29905, 13, 50596], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1322, "seek": 597838, "start": 5983.34, "end": 5985.18, "text": " Just to try and change self.learn here too.", "tokens": [50612, 1449, 281, 853, 293, 1319, 2698, 13, 306, 1083, 510, 886, 13, 50704], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1323, "seek": 597838, "start": 5986.900000000001, "end": 5987.18, "text": " Yes.", "tokens": [50790, 1079, 13, 50804], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1324, "seek": 597838, "start": 5988.54, "end": 5990.9800000000005, "text": " I think I read this before we changed the note.", "tokens": [50872, 286, 519, 286, 1401, 341, 949, 321, 3105, 264, 3637, 13, 50994], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1325, "seek": 597838, "start": 5991.02, "end": 5992.5, "text": " Because I've got the callback there.", "tokens": [50996, 1436, 286, 600, 658, 264, 818, 3207, 456, 13, 51070], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1326, "seek": 597838, "start": 5992.5, "end": 5993.18, "text": " Okay, my bad.", "tokens": [51070, 1033, 11, 452, 1578, 13, 51104], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1327, "seek": 597838, "start": 5994.14, "end": 5998.5, "text": " One more self.learn.preds.clamp in the overflow loss one.", "tokens": [51152, 1485, 544, 2698, 13, 306, 1083, 13, 3712, 16063, 13, 3474, 1215, 294, 264, 37772, 4470, 472, 13, 51370], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1328, "seek": 597838, "start": 5998.54, "end": 5999.54, "text": " Yes, thank you.", "tokens": [51372, 1079, 11, 1309, 291, 13, 51422], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1329, "seek": 597838, "start": 6000.34, "end": 6000.86, "text": " There we go.", "tokens": [51462, 821, 321, 352, 13, 51488], "temperature": 0.0, "avg_logprob": -0.43177028905565495, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.0008166779880411923}, {"id": 1330, "seek": 600086, "start": 6001.46, "end": 6009.66, "text": " And yeah, so get loss is doing a style loss plus this overflow loss just to keep things from growing exponentially out of bounds.", "tokens": [50394, 400, 1338, 11, 370, 483, 4470, 307, 884, 257, 3758, 4470, 1804, 341, 37772, 4470, 445, 281, 1066, 721, 490, 4194, 37330, 484, 295, 29905, 13, 50804], "temperature": 0.0, "avg_logprob": -0.24785150527954103, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.16449525952339172}, {"id": 1331, "seek": 600086, "start": 6009.7, "end": 6013.78, "text": " Again, something that's quite likely to happen when you're applying a large number of steps.", "tokens": [50806, 3764, 11, 746, 300, 311, 1596, 3700, 281, 1051, 562, 291, 434, 9275, 257, 2416, 1230, 295, 4439, 13, 51010], "temperature": 0.0, "avg_logprob": -0.24785150527954103, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.16449525952339172}, {"id": 1332, "seek": 600086, "start": 6014.139999999999, "end": 6015.62, "text": " And so we really want to penalize that.", "tokens": [51028, 400, 370, 321, 534, 528, 281, 13661, 1125, 300, 13, 51102], "temperature": 0.0, "avg_logprob": -0.24785150527954103, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.16449525952339172}, {"id": 1333, "seek": 600086, "start": 6017.66, "end": 6027.0199999999995, "text": " And the final thing is in learn.backward, I've added a technique that is probably going to be quite useful in some other places as well called gradient normalization.", "tokens": [51204, 400, 264, 2572, 551, 307, 294, 1466, 13, 3207, 1007, 11, 286, 600, 3869, 257, 6532, 300, 307, 1391, 516, 281, 312, 1596, 4420, 294, 512, 661, 3190, 382, 731, 1219, 16235, 2710, 2144, 13, 51672], "temperature": 0.0, "avg_logprob": -0.24785150527954103, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.16449525952339172}, {"id": 1334, "seek": 602702, "start": 6027.740000000001, "end": 6032.900000000001, "text": " And so we're just running through the parameters of our model, and we are normalizing them.", "tokens": [50400, 400, 370, 321, 434, 445, 2614, 807, 264, 9834, 295, 527, 2316, 11, 293, 321, 366, 2710, 3319, 552, 13, 50658], "temperature": 0.0, "avg_logprob": -0.380544220191845, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.005060236435383558}, {"id": 1335, "seek": 602702, "start": 6033.580000000001, "end": 6043.1, "text": " And this means that even if they're really, really tiny, really, really large at the end of that multiple number of update steps, this is kind of a hack to bring this back into control.", "tokens": [50692, 400, 341, 1355, 300, 754, 498, 436, 434, 534, 11, 534, 5870, 11, 534, 11, 534, 2416, 412, 264, 917, 295, 300, 3866, 1230, 295, 5623, 4439, 11, 341, 307, 733, 295, 257, 10339, 281, 1565, 341, 646, 666, 1969, 13, 51168], "temperature": 0.0, "avg_logprob": -0.380544220191845, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.005060236435383558}, {"id": 1336, "seek": 602702, "start": 6043.740000000001, "end": 6044.46, "text": " And Jeremy, I think you have more.", "tokens": [51200, 400, 17809, 11, 286, 519, 291, 362, 544, 13, 51236], "temperature": 0.0, "avg_logprob": -0.380544220191845, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.005060236435383558}, {"id": 1337, "seek": 602702, "start": 6044.46, "end": 6048.46, "text": " So let's put a bookmark to come back to that as well in more detail.", "tokens": [51236, 407, 718, 311, 829, 257, 1446, 5638, 281, 808, 646, 281, 300, 382, 731, 294, 544, 2607, 13, 51436], "temperature": 0.0, "avg_logprob": -0.380544220191845, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.005060236435383558}, {"id": 1338, "seek": 602702, "start": 6048.46, "end": 6049.22, "text": " Might come back to that.", "tokens": [51436, 23964, 808, 646, 281, 300, 13, 51474], "temperature": 0.0, "avg_logprob": -0.380544220191845, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.005060236435383558}, {"id": 1339, "seek": 602702, "start": 6049.3, "end": 6051.540000000001, "text": " And I guess that before fit, maybe we don't need anymore.", "tokens": [51478, 400, 286, 2041, 300, 949, 3318, 11, 1310, 321, 500, 380, 643, 3602, 13, 51590], "temperature": 0.0, "avg_logprob": -0.380544220191845, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.005060236435383558}, {"id": 1340, "seek": 602702, "start": 6052.900000000001, "end": 6054.820000000001, "text": " Oh, right, because this is now default.", "tokens": [51658, 876, 11, 558, 11, 570, 341, 307, 586, 7576, 13, 51754], "temperature": 0.0, "avg_logprob": -0.380544220191845, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.005060236435383558}, {"id": 1341, "seek": 602702, "start": 6055.26, "end": 6055.540000000001, "text": " Okay.", "tokens": [51776, 1033, 13, 51790], "temperature": 0.0, "avg_logprob": -0.380544220191845, "compression_ratio": 1.7171717171717171, "no_speech_prob": 0.005060236435383558}, {"id": 1342, "seek": 605554, "start": 6056.54, "end": 6058.78, "text": " Oh, so I should have set this running before we started talking.", "tokens": [50414, 876, 11, 370, 286, 820, 362, 992, 341, 2614, 949, 321, 1409, 1417, 13, 50526], "temperature": 0.0, "avg_logprob": -0.24997631120093075, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.01495523750782013}, {"id": 1343, "seek": 605554, "start": 6059.14, "end": 6060.3, "text": " It is going to take a little while.", "tokens": [50544, 467, 307, 516, 281, 747, 257, 707, 1339, 13, 50602], "temperature": 0.0, "avg_logprob": -0.24997631120093075, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.01495523750782013}, {"id": 1344, "seek": 605554, "start": 6061.42, "end": 6064.98, "text": " But you can see my progress callback here is scatterplotting the loss.", "tokens": [50658, 583, 291, 393, 536, 452, 4205, 818, 3207, 510, 307, 34951, 564, 310, 783, 264, 4470, 13, 50836], "temperature": 0.0, "avg_logprob": -0.24997631120093075, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.01495523750782013}, {"id": 1345, "seek": 605554, "start": 6065.94, "end": 6077.86, "text": " And the reason I'm, you'll see in the callback here, I'm setting the Y limits to the minimum of the initial set of losses.", "tokens": [50884, 400, 264, 1778, 286, 478, 11, 291, 603, 536, 294, 264, 818, 3207, 510, 11, 286, 478, 3287, 264, 398, 10406, 281, 264, 7285, 295, 264, 5883, 992, 295, 15352, 13, 51480], "temperature": 0.0, "avg_logprob": -0.24997631120093075, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.01495523750782013}, {"id": 1346, "seek": 607786, "start": 6078.259999999999, "end": 6085.98, "text": " It's just because the overflow loss is sometimes so much larger than the rest of the loss ones that you get this really like bad scaling.", "tokens": [50384, 467, 311, 445, 570, 264, 37772, 4470, 307, 2171, 370, 709, 4833, 813, 264, 1472, 295, 264, 4470, 2306, 300, 291, 483, 341, 534, 411, 1578, 21589, 13, 50770], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1347, "seek": 607786, "start": 6085.98, "end": 6091.94, "text": " So using a log scaling and clipping the bounds tends to help just like visualize what's actually important, like the overall trend.", "tokens": [50770, 407, 1228, 257, 3565, 21589, 293, 49320, 264, 29905, 12258, 281, 854, 445, 411, 23273, 437, 311, 767, 1021, 11, 411, 264, 4787, 6028, 13, 51068], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1348, "seek": 607786, "start": 6092.299999999999, "end": 6093.98, "text": " I guess the last bit does not run.", "tokens": [51086, 286, 2041, 264, 1036, 857, 775, 406, 1190, 13, 51170], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1349, "seek": 607786, "start": 6094.0199999999995, "end": 6096.179999999999, "text": " We can, then we can see it without you running it.", "tokens": [51172, 492, 393, 11, 550, 321, 393, 536, 309, 1553, 291, 2614, 309, 13, 51280], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1350, "seek": 607786, "start": 6096.179999999999, "end": 6096.9, "text": " Oh, right.", "tokens": [51280, 876, 11, 558, 13, 51316], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1351, "seek": 607786, "start": 6096.94, "end": 6097.219999999999, "text": " Yeah.", "tokens": [51318, 865, 13, 51332], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1352, "seek": 607786, "start": 6097.259999999999, "end": 6097.46, "text": " Yeah.", "tokens": [51334, 865, 13, 51344], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1353, "seek": 607786, "start": 6097.46, "end": 6098.46, "text": " So you can see the outputs here.", "tokens": [51344, 407, 291, 393, 536, 264, 23930, 510, 13, 51394], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1354, "seek": 607786, "start": 6098.98, "end": 6102.179999999999, "text": " And so what I'm visualizing is the examples that we've drawn from the pool.", "tokens": [51420, 400, 370, 437, 286, 478, 5056, 3319, 307, 264, 5110, 300, 321, 600, 10117, 490, 264, 7005, 13, 51580], "temperature": 0.0, "avg_logprob": -0.2885821438574976, "compression_ratio": 1.7087719298245614, "no_speech_prob": 0.29741454124450684}, {"id": 1355, "seek": 610218, "start": 6102.58, "end": 6107.860000000001, "text": " Every time we're drawing, in this case, I've got a fixed batch size that should probably be an argument.", "tokens": [50384, 2048, 565, 321, 434, 6316, 11, 294, 341, 1389, 11, 286, 600, 658, 257, 6806, 15245, 2744, 300, 820, 1391, 312, 364, 6770, 13, 50648], "temperature": 0.0, "avg_logprob": -0.311858279033772, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.4531272053718567}, {"id": 1356, "seek": 610218, "start": 6108.5, "end": 6113.62, "text": " But you can take a look at them and kind of compare them to the style loss and see initially that I really look too similar.", "tokens": [50680, 583, 291, 393, 747, 257, 574, 412, 552, 293, 733, 295, 6794, 552, 281, 264, 3758, 4470, 293, 536, 9105, 300, 286, 534, 574, 886, 2531, 13, 50936], "temperature": 0.0, "avg_logprob": -0.311858279033772, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.4531272053718567}, {"id": 1357, "seek": 610218, "start": 6114.9400000000005, "end": 6118.700000000001, "text": " After some training, we get some definite like webby tendencies.", "tokens": [51002, 2381, 512, 3097, 11, 321, 483, 512, 25131, 411, 3670, 2322, 45488, 13, 51190], "temperature": 0.0, "avg_logprob": -0.311858279033772, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.4531272053718567}, {"id": 1358, "seek": 610218, "start": 6119.62, "end": 6128.14, "text": " And we can take this model and then apply it to like a random grid and log the images, you know, every hundred steps or whatever.", "tokens": [51236, 400, 321, 393, 747, 341, 2316, 293, 550, 3079, 309, 281, 411, 257, 4974, 10748, 293, 3565, 264, 5267, 11, 291, 458, 11, 633, 3262, 4439, 420, 2035, 13, 51662], "temperature": 0.0, "avg_logprob": -0.311858279033772, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.4531272053718567}, {"id": 1359, "seek": 612814, "start": 6128.700000000001, "end": 6133.14, "text": " And you can see that starting from this random position, it quite quickly, you know, builds this pattern.", "tokens": [50392, 400, 291, 393, 536, 300, 2891, 490, 341, 4974, 2535, 11, 309, 1596, 2661, 11, 291, 458, 11, 15182, 341, 5102, 13, 50614], "temperature": 0.0, "avg_logprob": -0.26990801260012004, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.02595633827149868}, {"id": 1360, "seek": 612814, "start": 6133.660000000001, "end": 6135.1, "text": " It doesn't look perfectly spider webby.", "tokens": [50640, 467, 1177, 380, 574, 6239, 17614, 3670, 2322, 13, 50712], "temperature": 0.0, "avg_logprob": -0.26990801260012004, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.02595633827149868}, {"id": 1361, "seek": 612814, "start": 6136.3, "end": 6140.06, "text": " But in its defense, this model has 168 parameters.", "tokens": [50772, 583, 294, 1080, 7654, 11, 341, 2316, 575, 3165, 23, 9834, 13, 50960], "temperature": 0.0, "avg_logprob": -0.26990801260012004, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.02595633827149868}, {"id": 1362, "seek": 612814, "start": 6141.34, "end": 6142.26, "text": " And a tiles.", "tokens": [51024, 400, 257, 21982, 13, 51070], "temperature": 0.0, "avg_logprob": -0.26990801260012004, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.02595633827149868}, {"id": 1363, "seek": 612814, "start": 6142.3, "end": 6148.54, "text": " That to me is like the magic of these models is that even with very few parameters, they're able to do something pretty impressive.", "tokens": [51072, 663, 281, 385, 307, 411, 264, 5585, 295, 613, 5245, 307, 300, 754, 365, 588, 1326, 9834, 11, 436, 434, 1075, 281, 360, 746, 1238, 8992, 13, 51384], "temperature": 0.0, "avg_logprob": -0.26990801260012004, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.02595633827149868}, {"id": 1364, "seek": 612814, "start": 6149.9400000000005, "end": 6155.22, "text": " And if you would like, go back up to where we define number of channels and number of layers.", "tokens": [51454, 400, 498, 291, 576, 411, 11, 352, 646, 493, 281, 689, 321, 6964, 1230, 295, 9235, 293, 1230, 295, 7914, 13, 51718], "temperature": 0.0, "avg_logprob": -0.26990801260012004, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.02595633827149868}, {"id": 1365, "seek": 615522, "start": 6155.22, "end": 6163.22, "text": " If you give it more channels to work with, 8 or 16, and more hidden neurons, 32 or 64, you still have a tiny model.", "tokens": [50364, 759, 291, 976, 309, 544, 9235, 281, 589, 365, 11, 1649, 420, 3165, 11, 293, 544, 7633, 22027, 11, 8858, 420, 12145, 11, 291, 920, 362, 257, 5870, 2316, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2825277716712614, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05919869244098663}, {"id": 1366, "seek": 615522, "start": 6164.22, "end": 6167.26, "text": " But it's able to capture some much nicer.", "tokens": [50814, 583, 309, 311, 1075, 281, 7983, 512, 709, 22842, 13, 50966], "temperature": 0.0, "avg_logprob": -0.2825277716712614, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05919869244098663}, {"id": 1367, "seek": 615522, "start": 6168.06, "end": 6171.46, "text": " So I would say, please, on the forums, try some larger sizes.", "tokens": [51006, 407, 286, 576, 584, 11, 1767, 11, 322, 264, 26998, 11, 853, 512, 4833, 11602, 13, 51176], "temperature": 0.0, "avg_logprob": -0.2825277716712614, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05919869244098663}, {"id": 1368, "seek": 615522, "start": 6171.46, "end": 6172.9800000000005, "text": " I'll also maybe post some results.", "tokens": [51176, 286, 603, 611, 1310, 2183, 512, 3542, 13, 51252], "temperature": 0.0, "avg_logprob": -0.2825277716712614, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05919869244098663}, {"id": 1369, "seek": 615522, "start": 6174.02, "end": 6176.5, "text": " And just to give you a little preview of what's possible.", "tokens": [51304, 400, 445, 281, 976, 291, 257, 707, 14281, 295, 437, 311, 1944, 13, 51428], "temperature": 0.0, "avg_logprob": -0.2825277716712614, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05919869244098663}, {"id": 1370, "seek": 615522, "start": 6177.38, "end": 6181.58, "text": " So I did a project before using MiniAI.", "tokens": [51472, 407, 286, 630, 257, 1716, 949, 1228, 18239, 48698, 13, 51682], "temperature": 0.0, "avg_logprob": -0.2825277716712614, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05919869244098663}, {"id": 1371, "seek": 615522, "start": 6181.66, "end": 6184.58, "text": " So the code's a little messy and hacky.", "tokens": [51686, 407, 264, 3089, 311, 257, 707, 16191, 293, 10339, 88, 13, 51832], "temperature": 0.0, "avg_logprob": -0.2825277716712614, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05919869244098663}, {"id": 1372, "seek": 618522, "start": 6185.58, "end": 6189.18, "text": " But what I did was I logged the cellular automata.", "tokens": [50382, 583, 437, 286, 630, 390, 286, 27231, 264, 29267, 3553, 3274, 13, 50562], "temperature": 0.0, "avg_logprob": -0.2513837485477842, "compression_ratio": 1.5910780669144982, "no_speech_prob": 0.0021825297735631466}, {"id": 1373, "seek": 618522, "start": 6190.02, "end": 6191.34, "text": " Well, maybe I should show this.", "tokens": [50604, 1042, 11, 1310, 286, 820, 855, 341, 13, 50670], "temperature": 0.0, "avg_logprob": -0.2513837485477842, "compression_ratio": 1.5910780669144982, "no_speech_prob": 0.0021825297735631466}, {"id": 1374, "seek": 618522, "start": 6193.9800000000005, "end": 6200.62, "text": " We, this is way outside the bounds for this course, but you can write something called a fragment shader in WebGL.", "tokens": [50802, 492, 11, 341, 307, 636, 2380, 264, 29905, 337, 341, 1164, 11, 457, 291, 393, 2464, 746, 1219, 257, 26424, 5744, 260, 294, 9573, 19440, 13, 51134], "temperature": 0.0, "avg_logprob": -0.2513837485477842, "compression_ratio": 1.5910780669144982, "no_speech_prob": 0.0021825297735631466}, {"id": 1375, "seek": 618522, "start": 6200.780000000001, "end": 6202.58, "text": " So this is designed to run in the browser.", "tokens": [51142, 407, 341, 307, 4761, 281, 1190, 294, 264, 11185, 13, 51232], "temperature": 0.0, "avg_logprob": -0.2513837485477842, "compression_ratio": 1.5910780669144982, "no_speech_prob": 0.0021825297735631466}, {"id": 1376, "seek": 618522, "start": 6202.9800000000005, "end": 6205.62, "text": " It's a little program that runs once for every pixel.", "tokens": [51252, 467, 311, 257, 707, 1461, 300, 6676, 1564, 337, 633, 19261, 13, 51384], "temperature": 0.0, "avg_logprob": -0.2513837485477842, "compression_ratio": 1.5910780669144982, "no_speech_prob": 0.0021825297735631466}, {"id": 1377, "seek": 618522, "start": 6206.58, "end": 6209.18, "text": " And so you can see here, I have the weights of my neural network.", "tokens": [51432, 400, 370, 291, 393, 536, 510, 11, 286, 362, 264, 17443, 295, 452, 18161, 3209, 13, 51562], "temperature": 0.0, "avg_logprob": -0.2513837485477842, "compression_ratio": 1.5910780669144982, "no_speech_prob": 0.0021825297735631466}, {"id": 1378, "seek": 618522, "start": 6209.780000000001, "end": 6213.14, "text": " I have sampling the neighborhood of each cell.", "tokens": [51592, 286, 362, 21179, 264, 7630, 295, 1184, 2815, 13, 51760], "temperature": 0.0, "avg_logprob": -0.2513837485477842, "compression_ratio": 1.5910780669144982, "no_speech_prob": 0.0021825297735631466}, {"id": 1379, "seek": 618522, "start": 6213.62, "end": 6214.740000000001, "text": " We have our filters.", "tokens": [51784, 492, 362, 527, 15995, 13, 51840], "temperature": 0.0, "avg_logprob": -0.2513837485477842, "compression_ratio": 1.5910780669144982, "no_speech_prob": 0.0021825297735631466}, {"id": 1380, "seek": 621474, "start": 6215.0199999999995, "end": 6216.34, "text": " We have our activation function.", "tokens": [50378, 492, 362, 527, 24433, 2445, 13, 50444], "temperature": 0.0, "avg_logprob": -0.23511316050653872, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.0018968008225783706}, {"id": 1381, "seek": 621474, "start": 6216.94, "end": 6218.74, "text": " This is in a language called GLSL.", "tokens": [50474, 639, 307, 294, 257, 2856, 1219, 16225, 47012, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23511316050653872, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.0018968008225783706}, {"id": 1382, "seek": 621474, "start": 6219.54, "end": 6222.5, "text": " We're running through the layers of our network and proposing our updates.", "tokens": [50604, 492, 434, 2614, 807, 264, 7914, 295, 527, 3209, 293, 29939, 527, 9205, 13, 50752], "temperature": 0.0, "avg_logprob": -0.23511316050653872, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.0018968008225783706}, {"id": 1383, "seek": 621474, "start": 6224.0199999999995, "end": 6228.98, "text": " And this one here, I just had more, I think, more hidden neurons, more channels.", "tokens": [50828, 400, 341, 472, 510, 11, 286, 445, 632, 544, 11, 286, 519, 11, 544, 7633, 22027, 11, 544, 9235, 13, 51076], "temperature": 0.0, "avg_logprob": -0.23511316050653872, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.0018968008225783706}, {"id": 1384, "seek": 621474, "start": 6230.179999999999, "end": 6231.98, "text": " And optimized with a slightly different loss function.", "tokens": [51136, 400, 26941, 365, 257, 4748, 819, 4470, 2445, 13, 51226], "temperature": 0.0, "avg_logprob": -0.23511316050653872, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.0018968008225783706}, {"id": 1385, "seek": 621474, "start": 6231.98, "end": 6236.78, "text": " So it was a style loss plus clip to the prompt, I think, dragon scales or glowing dragon scales.", "tokens": [51226, 407, 309, 390, 257, 3758, 4470, 1804, 7353, 281, 264, 12391, 11, 286, 519, 11, 12165, 17408, 420, 27064, 12165, 17408, 13, 51466], "temperature": 0.0, "avg_logprob": -0.23511316050653872, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.0018968008225783706}, {"id": 1386, "seek": 621474, "start": 6237.9, "end": 6241.42, "text": " And you can see this is running in real time or near real time because I'm recording.", "tokens": [51522, 400, 291, 393, 536, 341, 307, 2614, 294, 957, 565, 420, 2651, 957, 565, 570, 286, 478, 6613, 13, 51698], "temperature": 0.0, "avg_logprob": -0.23511316050653872, "compression_ratio": 1.6642599277978338, "no_speech_prob": 0.0018968008225783706}, {"id": 1387, "seek": 624142, "start": 6241.9400000000005, "end": 6243.66, "text": " And it's interactive.", "tokens": [50390, 400, 309, 311, 15141, 13, 50476], "temperature": 0.0, "avg_logprob": -0.26788995977033647, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0027575157582759857}, {"id": 1388, "seek": 624142, "start": 6243.66, "end": 6247.78, "text": " You can click to kind of like zero out the grid and then see it like rebuild within that.", "tokens": [50476, 509, 393, 2052, 281, 733, 295, 411, 4018, 484, 264, 10748, 293, 550, 536, 309, 411, 16877, 1951, 300, 13, 50682], "temperature": 0.0, "avg_logprob": -0.26788995977033647, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0027575157582759857}, {"id": 1389, "seek": 624142, "start": 6248.5, "end": 6253.74, "text": " And so in a similar way, in this weights and biases report, I'm logging these kind of interactive HTML previews.", "tokens": [50718, 400, 370, 294, 257, 2531, 636, 11, 294, 341, 17443, 293, 32152, 2275, 11, 286, 478, 27991, 613, 733, 295, 15141, 17995, 14281, 82, 13, 50980], "temperature": 0.0, "avg_logprob": -0.26788995977033647, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0027575157582759857}, {"id": 1390, "seek": 624142, "start": 6254.06, "end": 6261.26, "text": " We've got some videos and just logging the grids from the different things.", "tokens": [50996, 492, 600, 658, 512, 2145, 293, 445, 27991, 264, 677, 3742, 490, 264, 819, 721, 13, 51356], "temperature": 0.0, "avg_logprob": -0.26788995977033647, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0027575157582759857}, {"id": 1391, "seek": 624142, "start": 6261.26, "end": 6264.9400000000005, "text": " And so you can see these are still pretty small as far as these networks go.", "tokens": [51356, 400, 370, 291, 393, 536, 613, 366, 920, 1238, 1359, 382, 1400, 382, 613, 9590, 352, 13, 51540], "temperature": 0.0, "avg_logprob": -0.26788995977033647, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0027575157582759857}, {"id": 1392, "seek": 624142, "start": 6265.22, "end": 6269.74, "text": " I think they only have four channels because I'm working with RGBA shaders.", "tokens": [51554, 286, 519, 436, 787, 362, 1451, 9235, 570, 286, 478, 1364, 365, 31231, 32, 5744, 433, 13, 51780], "temperature": 0.0, "avg_logprob": -0.26788995977033647, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0027575157582759857}, {"id": 1393, "seek": 626974, "start": 6270.34, "end": 6273.099999999999, "text": " But quite fun to see what you can do with these.", "tokens": [50394, 583, 1596, 1019, 281, 536, 437, 291, 393, 360, 365, 613, 13, 50532], "temperature": 0.0, "avg_logprob": -0.3458924814432609, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.007119865156710148}, {"id": 1394, "seek": 626974, "start": 6273.5, "end": 6279.5, "text": " And if you pick the right style images and train for a bit longer and use a few more channels, you can do some really fun stuff.", "tokens": [50552, 400, 498, 291, 1888, 264, 558, 3758, 5267, 293, 3847, 337, 257, 857, 2854, 293, 764, 257, 1326, 544, 9235, 11, 291, 393, 360, 512, 534, 1019, 1507, 13, 50852], "temperature": 0.0, "avg_logprob": -0.3458924814432609, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.007119865156710148}, {"id": 1395, "seek": 626974, "start": 6279.5, "end": 6282.099999999999, "text": " And you can get really creative applying them at different scales.", "tokens": [50852, 400, 291, 393, 483, 534, 5880, 9275, 552, 412, 819, 17408, 13, 50982], "temperature": 0.0, "avg_logprob": -0.3458924814432609, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.007119865156710148}, {"id": 1396, "seek": 626974, "start": 6282.099999999999, "end": 6292.0199999999995, "text": " Or I did some messing around with video, which again is just like messing with the inputs to different cells to try and get some cool patterns.", "tokens": [50982, 1610, 286, 630, 512, 23258, 926, 365, 960, 11, 597, 797, 307, 445, 411, 23258, 365, 264, 15743, 281, 819, 5438, 281, 853, 293, 483, 512, 1627, 8294, 13, 51478], "temperature": 0.0, "avg_logprob": -0.3458924814432609, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.007119865156710148}, {"id": 1397, "seek": 626974, "start": 6292.0199999999995, "end": 6295.38, "text": " So, yeah, to me, this is a really exciting, fun...", "tokens": [51478, 407, 11, 1338, 11, 281, 385, 11, 341, 307, 257, 534, 4670, 11, 1019, 485, 51646], "temperature": 0.0, "avg_logprob": -0.3458924814432609, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.007119865156710148}, {"id": 1398, "seek": 626974, "start": 6295.7, "end": 6296.219999999999, "text": " Amazing.", "tokens": [51662, 14165, 13, 51688], "temperature": 0.0, "avg_logprob": -0.3458924814432609, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.007119865156710148}, {"id": 1399, "seek": 626974, "start": 6296.219999999999, "end": 6296.74, "text": " ...niche.", "tokens": [51688, 1097, 77, 9304, 13, 51714], "temperature": 0.0, "avg_logprob": -0.3458924814432609, "compression_ratio": 1.6962962962962962, "no_speech_prob": 0.007119865156710148}, {"id": 1400, "seek": 629674, "start": 6297.0599999999995, "end": 6307.66, "text": " Yeah, I don't know if there's too many practical applications at this stage, but I'm already thinking of denoising cellular automata and stylizing or image restoration cellular automata.", "tokens": [50380, 865, 11, 286, 500, 380, 458, 498, 456, 311, 886, 867, 8496, 5821, 412, 341, 3233, 11, 457, 286, 478, 1217, 1953, 295, 1441, 78, 3436, 29267, 3553, 3274, 293, 23736, 3319, 420, 3256, 23722, 29267, 3553, 3274, 13, 50910], "temperature": 0.0, "avg_logprob": -0.2901616529984908, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.05499350279569626}, {"id": 1401, "seek": 629674, "start": 6307.66, "end": 6310.54, "text": " And you can really have a lot of fun with this structure.", "tokens": [50910, 400, 291, 393, 534, 362, 257, 688, 295, 1019, 365, 341, 3877, 13, 51054], "temperature": 0.0, "avg_logprob": -0.2901616529984908, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.05499350279569626}, {"id": 1402, "seek": 629674, "start": 6310.9, "end": 6323.26, "text": " And I also thought it was just a good demo of like how far can we push what you can do with a training callback to have this like pool training and the, you know, like gradient normalization and all these extra things added in.", "tokens": [51072, 400, 286, 611, 1194, 309, 390, 445, 257, 665, 10723, 295, 411, 577, 1400, 393, 321, 2944, 437, 291, 393, 360, 365, 257, 3097, 818, 3207, 281, 362, 341, 411, 7005, 3097, 293, 264, 11, 291, 458, 11, 411, 16235, 2710, 2144, 293, 439, 613, 2857, 721, 3869, 294, 13, 51690], "temperature": 0.0, "avg_logprob": -0.2901616529984908, "compression_ratio": 1.6978417266187051, "no_speech_prob": 0.05499350279569626}, {"id": 1403, "seek": 632326, "start": 6324.14, "end": 6327.34, "text": " Very, very different from here's a batch of images and a batch of labels.", "tokens": [50408, 4372, 11, 588, 819, 490, 510, 311, 257, 15245, 295, 5267, 293, 257, 15245, 295, 16949, 13, 50568], "temperature": 0.0, "avg_logprob": -0.29097828966505984, "compression_ratio": 1.4929577464788732, "no_speech_prob": 0.16222989559173584}, {"id": 1404, "seek": 632326, "start": 6327.7, "end": 6328.900000000001, "text": " So I hope you found that interesting.", "tokens": [50586, 407, 286, 1454, 291, 1352, 300, 1880, 13, 50646], "temperature": 0.0, "avg_logprob": -0.29097828966505984, "compression_ratio": 1.4929577464788732, "no_speech_prob": 0.16222989559173584}, {"id": 1405, "seek": 632326, "start": 6329.1, "end": 6330.38, "text": " And I'll stop sharing my screen.", "tokens": [50656, 400, 286, 603, 1590, 5414, 452, 2568, 13, 50720], "temperature": 0.0, "avg_logprob": -0.29097828966505984, "compression_ratio": 1.4929577464788732, "no_speech_prob": 0.16222989559173584}, {"id": 1406, "seek": 632326, "start": 6330.38, "end": 6333.18, "text": " And then, Jeremy, if you have any questions or follow ups.", "tokens": [50720, 400, 550, 11, 17809, 11, 498, 291, 362, 604, 1651, 420, 1524, 15497, 13, 50860], "temperature": 0.0, "avg_logprob": -0.29097828966505984, "compression_ratio": 1.4929577464788732, "no_speech_prob": 0.16222989559173584}, {"id": 1407, "seek": 632326, "start": 6333.58, "end": 6334.820000000001, "text": " No, that's amazing.", "tokens": [50880, 883, 11, 300, 311, 2243, 13, 50942], "temperature": 0.0, "avg_logprob": -0.29097828966505984, "compression_ratio": 1.4929577464788732, "no_speech_prob": 0.16222989559173584}, {"id": 1408, "seek": 632326, "start": 6335.1, "end": 6335.9400000000005, "text": " Thank you so much.", "tokens": [50956, 1044, 291, 370, 709, 13, 50998], "temperature": 0.0, "avg_logprob": -0.29097828966505984, "compression_ratio": 1.4929577464788732, "no_speech_prob": 0.16222989559173584}, {"id": 1409, "seek": 632326, "start": 6335.9400000000005, "end": 6336.9400000000005, "text": " I actually have to go.", "tokens": [50998, 286, 767, 362, 281, 352, 13, 51048], "temperature": 0.0, "avg_logprob": -0.29097828966505984, "compression_ratio": 1.4929577464788732, "no_speech_prob": 0.16222989559173584}, {"id": 1410, "seek": 632326, "start": 6337.06, "end": 6340.860000000001, "text": " But that's just one of the coolest things I've seen.", "tokens": [51054, 583, 300, 311, 445, 472, 295, 264, 22013, 721, 286, 600, 1612, 13, 51244], "temperature": 0.0, "avg_logprob": -0.29097828966505984, "compression_ratio": 1.4929577464788732, "no_speech_prob": 0.16222989559173584}], "language": "en"}