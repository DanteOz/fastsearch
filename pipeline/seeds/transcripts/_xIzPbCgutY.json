{"text": " Hi everybody, welcome back to lesson 12 of practical deep learning for coders. So got a lot of stuff to cover today, so let's dive straight in. And I actually thought I would start by sharing something which I've seen been getting a lot of attention recently, which is the Clip Interrogator. So the Clip Interrogator is a Hugging Face Spaces, I guess, Gradio app, where I uploaded my image here, and its output, let's just zoom in a bit, its output a text prompt for creating a clip embedding from, I guess. So I've seen a lot of folks on Twitter and elsewhere on the internet saying that this is producing the clip prompt that would generate this image. And generally speaking, the clip, the prompts it creates are rather rude. My one's less rude than some, although, you know, extremely long forehead, maybe not, thanks very much, but your personal data avatar, funny professional photo, I don't know what tectonics is meant to mean here, without eyebrows. So this doesn't actually return the clip prompt that would generate this photo at all. And the fact that some people are saying that makes me realize that some people have no idea what's going on with stable diffusion. So I thought we might take this as an opportunity to explain why we can't do that, and what we can try and do instead. So let's imagine that my friend took a photo of himself, and he wanted to send me his photo, and he thought he would compress it a whole lot. So what he did was he put it through the clip image encoder. Okay, so that's going to take this big image, and it's going to turn it into an embedding. And the embedding is much, much smaller than the image, it's just a vector of a few floats. So then my friend hopes that they could send me this embedding, and so they send that over in an email, and they say, there you go Jeremy, there's the clip embedding of the photo I wanted to send you, so now you just have to decode it to turn it back into a picture. So now I've got the embedding, and I have to decode it. How would you do that? Well, you can't. Okay, we have a function here, or let's call it f, which is the clip image encoder, which takes as input an image, which I'll call x, and returns an embedding. Does that mean that there is some other function, and inverse functions we normally write with the minus one, an inverse function with which I can take that embedding, let's say we call that y, we pass it y, and it would give us back our photo. And so y, remember, is f of x, so to put it another way, this is f inverse of f of f of y. So an inverse function is something that undoes a function, and so that gives you back y. Is there an inverse function for the clip image encoder? Well not everything has an inverse function. For example, consider the function, like let's say in Python, which takes def f, oopsie-daisy, def f of x, return 0. Can you invert that function? If you get back, you pass in 3, you get back 0, is there a function, oopsie, 0, is there a function that's going to take the output and give you back the input? No, of course not, because you just threw the whole thing away. So not all functions can be inverted, and indeed in this case we've started with a function which is whatever, 512 by 512 by 3, say, and we've turned it into something much, much smaller. I can't remember exactly how big a clip image encoding is, embedding is, but it's much smaller. So clearly we're losing something. But what I could do is I could put it through a diffusion process. And so remember a diffusion process is something where we have learnt, we have taught, or we shouldn't say, I don't know, taught, an algorithm has learned to take some noise, so we could start with some noise, and we could start with an image embedding. We haven't done this before, but we could do that, we could train something that takes noise in an image embedding and removes a bit of the noise. And we could run that a bunch of times. But it wouldn't give us back the original picture, but hopefully it would give us something back if it's a conditional, so remember using the conditional diffusion approach, we'd get back something that might be something like our original image. So that's what diffusion is, right? Diffusion is something that takes an embedding and inverts an encoder to give you back something that hopefully might generate that embedding. Now of course remember, we don't actually get image embeddings when we do prompts in stable diffusion. Instead we have text embeddings. But if you remember, that actually doesn't matter. Because do you remember how we actually, or we, OpenAI, trained Clip so that they had various pictures along with their captions, and they trained an algorithm that was explicitly designed to make it so that each image returned a embedding for the image that was similar to the embedding that the text encoder created for the caption. And remember all of the stuff that didn't match, it was trained to be different. And so that means that a text embedding, which describes this picture, and the actual image embedding of this picture, should be very similar, if they're clip embeddings. That's the definition of clip embeddings. So you see, this idea that you could take a text or image embedding and turn it back into an image perfectly, makes most sense. This is the very definition of the thing we're trying to do when we do clip. And because what we're basically trying to do is invert the embedding function, these kinds of problems are generally referred to as inverse problems. So stable diffusion is something that attempts to approximate the solution to an inverse problem. So why does that mean that ClipInterrogator is not actually inverting the picture to give us back the text? Well it's just as nonsensical. If we've got an image embedding, right, trying to undo that to get back to the picture, and trying to undo that to get back to a suitable prompt, is equally infeasible. Both of them require inverting an encoder. And that just doesn't exist. The best we can do is, or at least the best we know how to do at the moment, is to approximate that using a diffusion process. Okay, so that's why these texts that it spits back are fun and interesting, but they are not the thing that you can put back into stable diffusion and have it generate the same photo. And the nice thing is that actually the code for this is available, and you can take a look at it. Here's the app. And you'll see what it does is it has a big list of, let's have a look at some examples. So it has a big, this has big lists of examples, for example, a big list of artists. And it has a big list of mediums, and a big list of movements, and so forth. It's got all this hard-coded pieces of text. And so what it does is it basically mixes and matches those various things together to see which one works well. And it combines it with the output of something called the Blip language model, which is not designed to give you an exactly accurate description of an image, but it has been specifically trained to give an okay-ish caption for an image. And it actually works reasonably well. But again, it's not the inverse of the Clip encoder. So okay, so that's how that all works. So where we had got to was that we had done matrix multiplication with broadcasting, where we had broadcast the entire column from the right-hand matrix all at once. And that allowed us to get it down to a point where we only have one for loop written in Python. And generally speaking, we do not want to be looping through too many things in Python, because that's a slow bit. So the two inner loops we originally had, which just to remind us, originally were here. These two inner loops, looping through 10 and then to 784 respectively, have been replaced with a single line of code. So that was pretty great. And our times now is increased, is improved by 5000 times. So we're 5000 times faster than we started out. So another trick that we can use, which I'm a big fan of, is something called Einstein summation. And Einstein summation is a compact representation for representing products and sums. And this is an example of an Einstein summation. And what we're going to do now is we're going to replicate our matrix product with an Einstein summation. And believe it or not, the entire thing can be pushed down to just these characters, which is pretty amazing. So let me explain what's happening here. The arrow is separating the left-hand side from the right-hand side. The left-hand side is the inputs. The right-hand side is the output. The comma is between each input. So there are two inputs. The letters are just names that you're giving to the number of rows and the number of columns. So the first matrix we're multiplying by has i rows and k columns. The second has k rows and j columns. It's going to go through a process which creates a new matrix. That actually this is not even doing, this is not yet doing the matrix multiplication. This is without the sum. This one's going to create a new matrix that contains i rows and k, well how do we say it, i faces and k rows and j columns. So a rank 3 tensor. So the number of letters is going to be the rank. And the rules of how this works is that if you repeat letters between input arrays, so here's my inputs, ik and kj, we've got a repeated letter. It means that values along those axes will be multiplied together. So it means that each item in each row of, sorry, in each, yeah, across a row will be multiplied by each item down each column to create this i by k by j output tensor. So to remind you, our first matrix is 5 by 784. That's M1. Our second matrix is 7084 by 10. That's M2. So i is 5, k is 784, and j is 10. So if I do this torch.einsum, then I will end up with a i by k by j. It'll be 5 by 784 by 10. If you have a look, I've run it here on these two tensors, M1 and M2, and the shape of the result is 5 by 784 by 10. And what it contains is the original five rows of M1, the original 10 columns of M2, and then for the other 784, that dimension, they're all multiplied together because it's been copied between the two arguments to the einsum. And so if we now sum up that over this dimension, we get back. So what we get back, if we go back to the original matrix multiply we do, we had 10.94, negative, negative .68, etc. And so now with this Einstein summation version, we've got back exactly the same thing. Because what it's done is it's taken each of these columns by rows, multiplied them together to get this 5 by 784 by 10, and then added up that 784 for each one, which is exactly what matrix multiplication does. But we're going to use one of the two things from Einstein summation. The second one says if we omit a letter from the output, so the bit on the right of the arrow, it means those values will be summed. So if we remove this k, which gives us ik and kj goes to ij, so we've removed the k entirely, that means that sum happens automatically. So if we run this, as you see, we get back again matrix multiplication. So Einstein summation notation is, you know, it takes some practice getting used to, but it's very convenient. And once you get used to it, it's actually a really nice way of thinking about what's going on. And as we'll see in lots of examples, often you can really simplify your code by using just a tiny little Einstein summation. And it doesn't even have to be a sum, right? You don't have to omit any letters if you're just doing products. So maybe it's a bit misnamed. So we can now define our matmul as simply this torch.unsum. So if we now check it, test close that the original result is equal to this new matmul, and yes it is. And let's see how the speed looks. 15 milliseconds. Okay and that was for the whole thing. So compared to 600 milliseconds. So as you can see, this is much faster than even the very fast broadcasting approach we used. So this is a pretty good trick, is torch.unsum. Okay but of course we don't have to do any of those things because PyTorch already knows how to do matmul. So there's two ways we can run matmul directly in PyTorch. You can use this special at operator. So xtrain at weights is the same as matmul train, weights as you see, test close. Or you can say torch.matmul. And interestingly as you can see here, the speed is about the same as the unsum. So there's no particular harm, no particular reason not to do an unsum. So when I say unsum, that stands for Einstein summation notation. All right let's go faster still. Currently we're just using my CPU. But I have a GPU. It would be nice to use it. So how does a GPU work? An NVIDIA GPU, and indeed pretty much all GPUs, the way they work is that they do lots and lots of things in parallel. And you have to actually tell the GPU what are all the things you want to do in parallel, one at a time. And so what we're going to do is we're going to write in pure Python something that works like a GPU, except it won't actually be in parallel so it won't be fast at all. But the first thing we have to do if we're going to get something working in parallel is we have to create a function that can calculate just one thing, even if a thousand other things are happening at the same time, it won't interact with anything else. And there's actually a very easy way to think about matrix multiplication in this way, which is what if we try to create something which just as we've done here, fills in a single item of the result. So how do we create something that just fills in row zero, column zero? Well what we could do is we could create a new matmul where we're going to pass in the coordinates of the place that we want to fill in. So we're going to start by passing it 0,0. We'll pass it the matrix matrices we want to multiply. And we'll pass in a tensor that we've pre-filled in with zeros to put the result into. So we're going to say okay the result is torch.zeros, rows by columns, call matmul for location 0,0, passing in those two matrices and the bunch of zeros matrix ready to put the result in. And if we call that we get the answer in cell 0,0. So here's an implementation of that. So the implementation is first of all we've been passed the 0,0 coordinates. So let's destructure them. So hopefully you've been experimenting with destructuring because it's so important. You see it all the time. Enter i and j, that's the row and the column. Make sure that that is inside the bounds of our output matrix. And we're going to start by start at 0 and loop through all of the rows of A and all of the columns of B for i and j. Sorry all of the columns of A and all of the rows of B for i and j. Just like the very innermost loop of our very first Python attempt. And then at the end pop that into the output. So here's something that fills in one piece of the grid successfully. So we could call this row by columns times, each time passing in a different grid. And we could do that in parallel because none of those different locations interact with any other location. So something which can calculate a little piece of an output on a GPU is called a kernel. So we'd call this a kernel. And so now we can create something called launch kernel. We pass it the kernel, so that's the function. So here's an example, launch kernel passing in the function. And how many rows and how many columns are there in the output grid. And then give me any arguments that you need to calculate it. So in Python, star args just says any additional arguments that you pass are going to be put into an array called args. If you use something like C, you might have seen like variadic arguments, parameters, it's the same basic idea. So we're going to be calling launch kernel, we're going to be saying launch the kernel matmul using all the rows of A, all the columns of B. And then the args, which are going to be in star args, are going to be m1, the first matrix, m2, the second matrix, and res, another torch.0 as we just created. So launch kernel is going to loop through the rows of A, and then for each row of A it will loop through the columns of B, and call the kernel, which is matmul, on that grid location, passing in m1, m2, and res. So star args here is going to unpack that and pass them as three separate arguments. And if I run that, run all of that, you'll see it's done it. It's filled in the exact same matrix. OK, so that's actually not fast at all. It's not doing anything in parallel, but it's the basic idea. So now to actually do it in parallel, we have to use something called CUDA. So CUDA is a programming model for NVIDIA GPUs. And to program in CUDA from Python, the easiest way currently to do that is with something called Numba. And Numba is a compiler, well you've seen it actually already, for non-GPU. It's a compiler that takes Python code and spits out, you know, compiled fast machine code. If you use its CUDA module, it'll actually spit out GPU accelerated CUDA code. So rather than using at ngit like before, we now say at cuda.git. And it behaves a little bit differently, but you'll see that this matmul, let me copy the other one over so you can compare, compare it to our Python one. Our Python matmul and this cuda.git matmul look, I think, identical, except for one thing. Instead of passing in the grid, there's a special magic thing called cuda.grid. When you say, how many dimensions does my grid have? And you unpack it. So that's, you don't have to, it's just a little convenience that Numba does for you. You don't have to pass over the grid, it passes it over for you. So it doesn't need this grid. Other than that, these two are identical. But the decorator is going to compile that into GPU code. So now we need to create our output tensor, just like before. And we need to do something else, which is we have to take our input matrices and our output, so our input tensors, the matrices in this case, and the output tensor, and we have to move them to the GPU, or I should say copy them to the GPU. So cuda.device copies a tensor to the GPU. And so we've got three things getting copied to the GPU here, and therefore we store the three things over here. Another way I could have written this is I could have said map, which I kind of quite like doing, a function which is cuda.device to each of these arguments. And this would be the same thing. So this is going to call cuda.device on X train and put it in here, on weights and put it in here, and on R and put it in here. That's a slightly more convenient way to do it. Okay, so we've got our 50,000 by 10 output. That's just all zeros, of course. That's just how we created it. And now we're going to try and fill it in. There is a particular detail that you don't have to worry about too much, which is in cuda they don't just have a grid, but there's also a concept of blocks. And there's something we call here tpb, which is threads per block. This is just a detail of the cuda programming model you don't have to worry about too much. You can just basically copy this. And what it's going to do is it's going to call each grid item in parallel, and with a number of different processes basically. This is just the code which turns the grid into blocks. You don't have to worry too much about the details of that, you just always run it. Okay, and so now how do you call the equivalent of launch kernel? Well it's a slightly weird way to do it, but it works fine. You call matmul, but because matmul has cuda.jit, it's got a special thing, which is you have to put something in square brackets afterwards. Which is you have to tell it how many blocks per grid, that's just the result from the previous cell, and how many threads per block in each of the two dimensions. So again you can just copy and paste this from my version, but then you pass in the three arguments to the function. This will be a, b, and c. And this is how you launch a kernel. So this will launch the kernel matmul on the GPU. At the end of it, rg is going to get filled in. It's on the GPU, which is not much good to us, so we now have to copy it back to the CPU, which is called the host, copy to host. So we run that, and it's done. And test-close shows us that our result is similar to our original result, so it seems to be working. So that's great. So I see Siva on the YouTube chat is finding that it's not working on his Mac. That's right, so this will only work on an NVIDIA GPU, as basically all of the GPU, nearly all the GPU stuff we look at, only works on NVIDIA GPUs. Mac GPUs are gradually starting to get a little bit of support from machine learning libraries, but it's taking quite a while. It's got quite a way to go, as I say this, at least towards the end of 2022. If this works for you later on, that's great. Okay so let's time how fast that is. Okay so that was 3.61 milliseconds, and so if we compare that to the PyTorch matmul on CPU, that was 15 milliseconds. So that's great. So it's faster still. So how much faster, oh by the way, we can actually go faster than that, which is we can use the exact same code we had from the PyTorch op, but here's a trick. If you just take your tensor and write .cuda after it, it copies it over to the GPU. If it's on a NVIDIA GPU, do the same for weights.cuda. So these are our two cuda versions, and now I can do the whole thing, and this will actually run on the GPU. And then to copy it back to the host, you just say .cpu. So if we look to see how fast that is, 458 microseconds. So oh, that is, somebody just pointed out that I wrote the wrong thing here, 1e neg 3. Okay, so how much faster is that? Well 458 microseconds, our original, on the whole data set, was 663 microseconds. So compared to our broadcast version, we are another thousand times faster. So overall, this version here, compared to our original version, which was here, the difference in performance is 5 million x. So when you see people say, yeah, Python can be pretty slow, it can be better to run stuff on the GPU, if possible, we're not talking about a 20% change, we're talking about a 5 million x change. So that's a big deal, and so that's why you need to be running stuff on the GPU. All right, some folks on YouTube are wondering how on earth I'm running CUDA when I'm on a Mac, and given it says localhost here, that's because I'm using something called SSH tunneling, which we might get to sometime. I suspect my live coding from the previous course might have covered that already, but this is basically, you can use a Jupyter notebook that's running anywhere in the world from your own machine, using something called SSH tunneling, which is a good thing to look up. One person asks if Einstein summation borrows anything from APL. Yes, it does actually. So it's kind of the other way around actually, APL borrows it from Einstein notation. So I don't know if you remember I mentioned that Ken Iverson, when he developed APL, was heavily influenced by tensor analysis, and so this Einstein notation is very heavily used there. If you'll notice, a key thing that happens in Einstein notation is there's no loop, you know, there isn't this kind of sigma, you know, i from here to here, and then you put the i inside the function that you're summing up. Everything's implicit, and APL takes that a very long way, and J takes it even further, which is what Ken Iverson developed after APL, and this kind of general idea of removing the index is very important in APL, and it's become very important in NumPy, PyTorch, TensorFlow, and so forth. So finally we know how to multiply matrices. Congratulations! So let's practice that. Let's practice what we've learned. So we're going to go to 0 to mean shift to practice this, and so we're going to try to exercise our kind of tensor manipulation operation muscles in this section, and the key actually endpoint for this is the homework, and so what you need to be doing is getting yourself to a point that you can implement something like this, but for a different algorithm. Why do we care about this? Because this is like learning your times table, your times tables if you're doing, you know, mathematics. It's this kind of like thing that's going to come up all the time, and if you're not good at your times tables, everything else, a lot of other things, particularly at primary school and high school, you know, they get difficult. You get slower, and it's frustrating, and you spend time thinking about these mechanical operations rather than getting your work done. It is, it's important that when you have an idea about something you want to try, or debug, or profile, or whatever, that you can quickly translate that into working code, and the way that code is written for GPUs, or even for fast running on CPUs, is using broadcasting, Einstein notation, matrix modifications, and so forth. So you've got to, you've got to, got to, got to practice. Super important. So we're going to practice it by running, by developing a clustering algorithm, and the clustering algorithm we're going to work on is something called mean shift clustering, which hopefully you've never heard of before, and I say that because I just think it's a really fun algorithm that not many people have come across. I think you'll find it really useful. So what is cluster analysis? Cluster analysis is very different to anything that we've worked on in this course so far, in that there isn't a dependent variable that we're trying to match, but instead we're just trying to find, are there groups of similar things in this data, those groups we call clusters. And as you can see from the wiki page, there's all kinds of applications of cluster analysis across many different areas. I will say that sometimes cluster analysis can be overused or misused. It's really best for when your, your various columns are the same kind of thing and have the same kind of scale. For example, pixels are all the same kind of thing. They're all pixels. So one of the examples they use is market research. So I wouldn't use cluster analysis for socio-demographic inputs because they're all different kinds of things. But the example they give here makes a lot of sense, which is looking at data from surveys, if you've got a whole bunch of like from one to five answers on surveys. All right, so let's take a look at this. And the way I like to build my algorithms is to create some, often to create some synthetic data that I know how I want it to behave. And so we're going to create six clusters and each cluster is going to have 750 samples in it. So first of all, I'm going to randomly create six centroids. And so the centroid is going to be like the middle of where my clusters are. So I'm going to randomly create them. I need to end clusters by two, because I need an X and a Y coordinate for each one. And so now I'm going to randomly generate data around those six centroids. Okay, so to do that, I'm going to call a little function I made here called sample. And I'm going to run it on each of those six centroids. And so I'll show you what that looks like. So here's what that data looks like. So the X's are the six centroids and the colored dots is the data. So if you were given this data without the X's, the idea would be to come back with figuring out where the X's would have been. Like where are the, where are these clustering around? And so if you can get clusters, that's the goal here is to find out that there's a few discreetly distinctly different types of data in your data set. So for example, for images, I've used this before to discover that there are some images that look completely different to all the other ones. For example, they were taken at nighttime or they're of a different object or something like that. So how does sample work? We're passing in the centroid. And so what we want is we're going to get back. So each of those centroids contains an X and a Y. So multivariate normal is just like normal. It's going to give you back normally distributed data, but more than one item. That's why it's multivariate. And so we passed in two means, a mean for X and a mean for our Y. And so that's the mean that we're going to get. And our standard deviation is going to be 5. Why do we use torch.diag 5,5? That's because we're saying that's because for multivariate normal distributions, there's not just one standard deviation for each column that you get back. There could also be a connection between columns. So columns might not be independent. So you actually need what's called a covariance matrix, not just a variance. We discuss that a little bit more in lesson 9b, if you're interested in learning more about that. Okay, so this is something that's going to give us back random columns of data with this mean and this standard deviation. And this is the number of samples that we want. And this is coming from PyTorch. So PyTorch has a whole bunch of different distributions that you can use, which can be very handy. So there's our data. Okay, so remember for clustering, we don't know the different colors. And we don't know where the Xs are. That's kind of our job is to figure that out. We might just briefly also look at how to plot. So in this case, we want to plot the Xs. And we want to plot the data. So it looks like this. So all I do is I loop through each centroid. And I grab that centroid samples, and they're just all done in order. So I grab it from i times n samples up to i plus 1 times n samples. And then I create a scatterplot with the samples on them. And what I've done is I've created an axis here. You'll see why later that we can also pass one in, but I'm not passing one in. So we create a plot and an axis. And so in matplotlib, you can keep plotting things on the same axis. So then I plot on the centroid a big X, which is black, and then a smaller X, which is, what is that, magenta. And so that's how I get these Xs. So that's how plot data works. Okay, so how do we create something now that starts with all the dots and returns where the Xs are? We're going to use a particular algorithm, particular clustering algorithm called mean shift. And mean shift is a nice clustering approach, because you don't have to say how many clusters there are. So it's not that often that you actually got to know how many clusters there are. So we don't have to say. Quite a few things, like the very popular k-means, require you to say how many. Instead we just have to pass them in called a bandwidth, which we'll learn about, which can actually be chosen automatically. And it can also handle clusters of any shape. So they don't have to be ball-shaped like they are here. They can be kind of like L-shaped or ellipse-shaped or whatever. And so here's what's going to happen. We're going to pick some point. So let's say we pick that point just there. And so what we now do is we go through each data point. So we pick the first one. And so we then find the distance between that point and every other point. So we're going to have to say what is the distance between that point and that point, and that point and that point, and that point and that point, and also the ones further away. That point and that point. And you do it for every single point compared to the one that we're currently looking at. Okay. So we get all of those as a big list. And now what we're going to do is we're going to take a weighted average of all of those points. Now that's not interesting without the weighting. If we just take an average of all of the points and how far away they are, we're going to end up somewhere here, right? This is the average of all the points. But the key is that we're going to take an average. Let me just find the right spot. The key is we need to find an average that is weighted by how far away things are. So for example, this one over here is a very long way away from our point of interest. And so it should have a very low weight in the weighted average. Whereas this point here, which is very close, should have a very high weight in our weighted average. So what we do is we create weights for every point compared to the one that we're currently interested in, using a what's called a Gaussian kernel that we'll look at. But the key thing to know is that points that are further away from our point of interest, which is this one, are going to have lower weights. That's what we mean there. They're penalized. The rate at which weights fall to zero is determined by this thing that we set at the start called the bandwidth. And that's going to be the standard deviation of our Gaussian. So we take an average of all the points in the data set, a weighted average weighted by how far away they are. So for our point of interest, right, this point's going to get a big weight. This point's going to get a big weight. This point's going to get a big weight. That point's going to get a tiny weight. That point's going to get an even tinier weight. So it's mainly going to be a weighted average of these points that are nearby. And the weighted average of those points, I would guess, is going to be somewhere around about here. And we'd have a similar thing for the weighted average of the points near this one. That's going to probably be somewhere around about here, right, or maybe over here. And so it's going to move all of these points in closer. It's almost like a gravity, right? They're kind of going to be moved like closer and closer in towards this kind of gravitational center. And then these ones will go towards their own gravitational center, and so forth. Okay, so let's take a look at it. All right, so what's the Gaussian kernel? This is the Gaussian kernel, which was a sign in the original March for Science, back in the days when the idea of not following scientists was considered socially unacceptable. We used to have March for these things, if you remember. So this is not normal. So this is the definition of the Gaussian kernel, which is also known as the normal distribution. This is the shape of it. Sure you've seen it before. And here is that formula copied directly off the Science March sign. Okay, here we are. See the square root, 2 pi, etc. Okay, and this here is the standard deviation. Now what does that look like? It's very helpful to have something that we can very quickly plot any function. That doesn't come with Matplotlib, but it's very easy to write one. As x, let's use all the numbers from 0 to 10, 100 of them spaced evenly. That's what linz-based does. Linearly spaced 100 numbers in this range. That's going to be our x's. So plot those x's and plot f of x's, the y's. So here's a very nice little plot funk we want. And here it is. And as you can see here, we've now got something where if you are this, like very close to the point of interest, you're going to get a very high weight. And if you're a long way away from the point of interest, you'll get a very low weight. So that's the key thing that we wanted, remember, is something that penalizes further away points more. Now you'll notice here I managed to plot this function for a bandwidth of 2.5. And the way I did that was using this special thing from FuncTools called partial. Now the first thing to point out here is that very often, it drives me crazy, I see people trying to find out what something is in Jupyter. And the way they do it is they'll scroll up to the top of the notebook and search through the imports and try to find it. That is the dumb way to do it. The smart way to do it is just to type it. And press shift-enter and it'll tell you where it comes from. And you can get its help with question mark, and you can get its source code with two question marks. OK, so just type it to find out where it comes from. OK, so this is, as Siva's mentioned in the chat, also known as currying or partial function application. This creates a new function. So let's just grab it. And we create a new function. And this function f is the function Gaussian, but it's going to automatically pass bw equals 2.5. So this is a partially applied function. So I could type f of 4, for example. That's going to be a tensor. There we go. And you can see that's exactly what this is. Go up to 4, go across, yep, about 0.44. So we use partial function application all the time. It's a very, very, very important tool. Without it, for example, plotting this function would have been more complicated. With it, it was trivially easy. I guess the alternative, like one alternative, which would be fine but slightly more clunky, would be we could create a little function in line. So we could have said, oh, plot a function that I'm going to define right now, which is called lambda, which is lambda x, which is Gaussian of x with a bandwidth of 0.25. You could do that too. You know, it's fine. But, yeah, partials, I think, are a bit neater, a bit less to think about. They often produce some neater and clearer code. Okay. Why did we decide to make the bandwidth 2.5? As a rule of thumb, choose a bandwidth which covers about a third of the data. So if we kind of found ourselves somewhere over here, right, a bandwidth which covers about a third of the data would be enough to cover two clusters-ish. So you'd want to be kind of like this big. So somewhere in the middle there. So that's the basic idea. Yeah. But you can play around with bandwidths and get different amounts of clusters. I should mention, like often when you see something that's kind of on the complicated side, like a Gaussian, you can often simplify things. I think most implementations and write-ups I've seen talk about using Gaussians. But if you look at the shape of it, it looks a lot like this shape. So this is a triangular weighting, which is just using clamp min. So it's just using a linear with clamp min. And yeah, it occurred to me that we could probably use this just as well. So I decided to define this triangular weighting, and then we can try both. Anyway, so we'll start with, we're going to use the Gaussian version. All right, so we're going to be literally moving all the points towards their kind of center of gravity. So we don't want to mess up our original data, so we clone it. That's a PyTorch thing, it's .clone, it's very handy. And so big X is our matrix of data. I mean, it's actually a, that's right, matrix of data, yeah. And then little x will be our first point. And it's pretty common to use capital letters for matrices. So this is our data, this is the first point. Okay, so there it is. We're going to start at 26.2, 26.3. So 26.2, 26.3, so somewhere up here. So little x, its shape is just, it's a rank 1 tensor of shape 2. Big X is a rank 2 tensor of 1500 data points by 2, the x and y. And if we call x none, that would add a unit axis to that. And the reason I'm going to show you that is because we want to find the distance from little x to everything in big X. And the way we do a distance is with minus. But you wouldn't be able to go, you wouldn't be able to go x minus big X and get the right, actually do you get the right answer? Let's think about that. x.shape, we've got that already. No, actually that is going to work, isn't it? So, yes, all right, so you can see why we've got these two versions here. If we do x none, we've got something of shape 1, 2. Now we can subtract that from something of shape 1500, 2. Because the 2s match up, because they're the same. And the 1500 and the 1 matches up, because you remember our NumPy rules, everything matches up to a unit axis. So it's going to copy this matrix across every row of this matrix. And it works. But do you remember, there's a special trick, which is if you've got two shapes of different lengths, we can use the shorter length and it's gonna add unit axes to the front to make it as long as necessary. So we actually don't need the x none, we can just use little x. And it works because it's gonna say, is this compatible with this? Well, the last axis, remember we go right to left, the last axis matches. The second last axis, it doesn't exist, so we pretend that there's a unit axis. And so it's gonna do exactly the same thing as this. So, if you have not studied the broadcasting from last week carefully, that might not have made a lot of sense to you. And so definitely at this point, you might wanna pause the video and go back and reread the NumPy broadcasting rules from last time and practice them, because that's what we just did. We used NumPy broadcasting rules, and we're gonna be doing this dozens more times throughout the rest of the course, and many more times, in fact, in this lesson. Okay, so now I think it's a pretty good place to have a pause. So I'll see you back here in nine minutes. Hi everybody, welcome back. So we had got to the point where we had managed to get the distance between our first point, x, and all of the other points in the data. And so we're just looking at the first eight of them here. So the very first distance is of course, 0 on the x-axis and 0 on the y-axis, because it is the first point. The other thing is that because the way we created the clusters is they're all kind of next to each other in the list, so these are all in the first cluster, so none of them are too far away from each other. So now that we've got all the distances, it's easy enough to, well, not the distances on x and y, it's easy enough to get the distance, the kind of Euclidean distance. So we can just square that difference and sum and square root. And actually, maybe this is a good time to talk about norms and to talk about what we just did there. We've got all these data points. So here's one of our data points, and here's the other one of our data points. And there's some distance across the x-axis, and there's some distance along the y-axis. So we could call that change in x and change in y. And one way to think about this distance then is it's this distance here. So to calculate that, we can use Pythagoras. So a squared plus b squared equals c squared. Or in our case, so this would be c, a, and b, say. So in our case, it would be the square root of the change in x squared plus the change in y squared. And rather than saying square root, we could say, To the power of a half, another way of saying the same thing. But there's a different way we could find the distance. We could first go along here, and then go up here. And so that one would be change in x, if you like, to the 1 plus change in y to the 1 to the power of 1 1th. I'm writing it a slightly odd way for reasons you'll see in a moment. It's just this, otherwise. In general, if we've got a whole list of numbers, we can add them up. Let's say there are some list v. We can add them up. We can do each one to the power of some number alpha. And take that sum to the 1 over alpha. And this thing here is called a norm. So you might have remembered we came across that last week. And we've come across it again this week. They basically come up, I don't know, they might end up coming up every week. They come up all the time. Particularly because the two norm, which we could write like this. Or we could write like this. Or we could write like this. They're all the two norm. This is just saying it's this equation for alpha equals 2. And Stefano's pointing out we should actually have an absolute value. I'm not gonna worry about that. We're just doing real numbers here. So we'll keep things simple. Well, I guess for higher than 1, no, you're probably right. For something like 3, yeah, I guess we do need an absolute value there. That's a good point because, okay, we could have this one. And so the distance actually has to be the absolute value. So the change in x is the absolute value of that distance. Yes, thank you, Stefano. Okay, so we'll have the absolute value. Okay, so the two norm is what happens when alpha equals 2. And we would call this, in this case, we would call this the Euclidean distance. But actually, where it comes up more often is when you're doing like a loss function. So the mean squared error is just, well, the root mean squared error, I should say, is just the two norm. Or else the mean absolute error is the one norm. And these are also known as L2 and L1 loss. And remember what we saw in that paper last week. We saw it in this form. There's a 2 up here, which is where they got rid of the square root again. So that would have just been change in x squared plus change in y squared. And now we don't even need the parentheses. Oopsie daisy. Okay, so all of this is to say that for, this comes up all the time because we're very, very often interested in distances and errors and things like that. I'm trying to think, I don't feel like I've ever seen anything other than one or two. So although it is a general concept, I don't think we're gonna see probably things other than one or two in this course. I'd be excited if we do, that would be kind of cool. So here we're taking the Euclidean distance, which is the 2-norm. So this has got eight things in it, because we've summed it over dimension 1. So here's your first homework, is to rewrite using torch.einsum. You won't be able to get rid of the x minus x, you'll still need to have that in there. But when you've got a multiply followed by a sum, you won't be able to get rid of the square root either. You should be able to get rid of the multiply and the sum by doing it in a single torch.einsum. So we're summing up over the first dimension, which is this dimension. So in other words, we're summing up the x and the y-axes. Okay, so now we can get the weights by passing those distances into our Gaussian. And so as we would expect, the biggest weights, it gets up to 0.16. So the closest one is itself, it's gonna be at a big weight. These other ones get reasonable weights. And the ones that are in totally different clusters have weights small enough that at three significant figures they appear to be 0. Okay, so we've got our weights. So the weights are 1500 long vector. And of course, our original data is 1500 by 2, the x and the y for each one. So we now want a weighted average. We want this data, we want its average weighted by this. So normally, an average is the sum of your data divided by the count. That's a normal average. A weighted average, each item in your data, let's put some i's around here just to be more clear. Each item in your data is gonna have a different weight. And so you multiply each one by the weights. And so rather than dividing by n, which is just the sum of ones, we would divide by the sum of weights. So this is an important concept to be familiar with, weighted averages. So we need to multiply every one of these x's by this. Okay, so can we say weight times x? No. All right, why didn't that work? So remember, we go right to left. So first of all, it's gonna say, let's look at the 2 and multiply that by the 15. Are they compatible? Things are compatible if they're equal, or if at least one of them is 1. These are not equal, and they're not 1, so they're not compatible. That's why it says the size of a tensor A must match. Now when it says match, it doesn't mean they have to be the same. One of them can be 1. Okay, that's what it means to match. They're either equal or one of them's 1. So that doesn't work. On the other hand, what if this was 1500, 1? If it was 1500, 1, then they would match, because the 1 and the 2 match, because one of them's a unit axis. And the 1500 and the 1500 match, because they're the same. So that's what we're gonna do. Because that would then copy this to every one of these, which is what we want. We want weights for each of these x, y tuples. So to add the trailing unit axis, we say every row and a trailing unit axis. So that's what that shape looks like. So we can now multiply that by x. And as you can see, it's now weighting each of them. And so each of these x's and y's down the bottom, they're all 0. So we can sum that up and then divide by the sum of weights. So let's now write a function that puts all this together. So you can see this really important way of, to me, the only way that makes sense to do particularly scientific numerical programming, I actually do all my programming this way, particularly scientific and numerical programming, is write it all out step by step, check every piece, have it all there documented for you and for others. And then copy the cells, merge them together, and indent them to indent its control right square bracket, and put a function header on top. So here's all those things we just did. And now rather than just grabbing the first x, we enumerate through all of them. So that's the distance we had before. That's the weight we had before. There's the product we had before. And then finally, sum across the rows, divide by the sum of the weights. So that's gonna calculate for the ith, it's gonna move, so it's actually changing capital X. So it's changing the ith thing in capital X, so that it's now the weighted sum. Actually, sorry, the weighted average of all of the other data, weighted by how far it is away. So that's gonna do a single step. So the mean shift update is extremely straightforward, which is clone the data, iterate a few times, and do the update. So if we run it, take 600 milliseconds. And what I've done is I've plotted the centroids moved by two pixels, or two, well not two pixels, two units, so that you can see them. And so you can see the dots is where our data is, and they're dots now, because every single data point is on top of each other on a cluster. And so you can see they are now in the correct spots. So it has successfully clustered our data. So that's great news. And so we could test out our hypothesis. Could we use triangular just as well as we could have used Gaussian? So Ctrl slash comments and uncomments. Yep, we got exactly the same results. So that's good. It's really important to know these keyboard shortcuts. Hit H to get a list of them. Some things that are really important don't have keyboard shortcuts. So if you click Help, Edit Keyboard Shortcuts, there's a list of all the things Jupyter can do. And you can add keyboard shortcuts to things that don't have them. So for example, I always add keyboard shortcuts to run all cells above and run all cells below. As you can see, I type Q and then A for above and Q and then B for below. All right, now that was kind of boring in a way because it did five steps. But we just saw the result. What did it look like one step at a time? This isn't just fun. It's really important to be able to see things happening one step at a time. Cuz there are so many algorithms we do which are like updating weights or updating data. So for stable diffusion, for example, you're very likely to want to show your incrementally denoising and so forth. So in my opinion, it's important to know how to do animations. And I found the documentation for this unnecessarily complicated. Because a lot of it's about how to make them performant. But most of the time, we probably don't care too much about that. So I wanna show you a little trick, a simple way to create animations without any trouble. So matplotlib.animation has something called funcanimation. That's what we're gonna use. To create an animation, you have to create a function. And the function, you're gonna be calling funcanimation, passing in the name of that function, and saying how many times to run it. And that's what this frames argument. This says run this function this many times. And then create an animation that basically contains the result of that with a 500 millisecond interval between each one. So what's this do one gonna do? To create one frame of animation, we will call our one update. Here it is, one update, right? We're gonna call this. That's gonna update our x's. And then we're gonna have an axis, which we've created here. So we're gonna clear whatever was on the plot before and plot our new data on that axis. And then the only other thing you need to do is that the very first time it calls it, we want to plot it before running. And d is gonna be passed automatically the frame number. So for the 0th frame, we're gonna not do the update, we're just gonna plot the data as it is already. I guess another way we could have done that would have been just to say, if d, then do the update, I suppose. That should work too. Maybe it's even simpler. Let's see if I just broke it. Okay, so we're gonna clone our data. We're gonna create our figure and our subplots. We're gonna call func animation, calling do one five times. And then we're gonna display the animation. And so let's see. So HTML takes some HTML and displays it. And to jsHTML creates some HTML. So that's why it's created this. HTML includes JavaScript. And so we'll click Run. One, two, three, four, five. There's the five steps. So if I click Loop, you'll see them running again and again. Fantastic. So that's how easy it is to create a matplotlib animation. So hopefully now you can use that to play around with some fun stable diffusion animations as well. You don't just have to use to jsHTML. You can also create, Oopsie daisy. You can also create movies, for example. So you can call toHTML5Video would be another option. And you can save an animation as a movie file. So there's all these different options for that. But hopefully that's enough to get you started. So for your homework, I would like you, when you create your K-means or whatever, to try to create your own animation. Or create an animation of some stable diffusion thing that you're playing with. So don't forget this important ax.clear. Without the ax.clear, it prints it on top of the last one. Which sometimes is what you want, to be fair. But in this case, it's not what I wanted. All right, so kind of slow. Half a second for not that much data. I'm sure it would be nice if it was faster. Well, the good news is we can GPU accelerate it. The bad news is it's not gonna GPU accelerate that well because of this loop. This is looping 1,500 times. So looping's not gonna run on the GPU. So the best we could do with this would be to move all this to the GPU. Now the problem is that calling something on the GPU 1,500 times from Python is a really bad idea. Because there's this kind of huge communication overhead of this kind of flow of control and data switching back between the CPU and the GPU. It's the kernel launching overhead. It's bad news. So you don't wanna have a really big, fast Python loop that inside it calls CUDA code, it calls GPU code. So we need to make all of this run without the loop, which we could do with broadcasting. So let's roll up our sleeves and try to get the broadcast version of this working. So generally speaking, the way we tend to do things with broadcasting on a GPU is we create batches or mini-batches. So to create batches or mini-batches, we normally just call them batches nowadays, we create a batch size. So let's say we're gonna do a batch size of five. So we're gonna do five at a time. All right, so how do we do five at a time? This is only doing one at a time. How do we do five at a time? As before, let's clone our data. And this time, little x for our testing. So we're gonna do everything ahead of time, little tests, as we always do. This is not now x0 anymore, but it's x colon bs. So it's the first five, this is now the first five items. Okay, so little x is now a 5 by 2 matrix. This is our mini-batch, the first five items. As before, our data itself is 1500 by 2. All right, so we need a distance calculation. But previously, our distance calculation, Previously, our distance calculation only worked if little x was a single number. And it returned just the distances from that to everything in big X. But we need something that's actually going to be return a matrix, right? We've got, Let's see, we've got 5 by 2 in little x. And then in big X, we've got something much bigger. Not to scale, obviously. We've got 1500 by 2. And what is the distance between these two things? Well, if you think about it, there's gonna be a distance between item 1 and item 1. But there's also gonna be a distance between item 1 and item 2. And there's gonna be a distance between, let's use a different color for the next one, item 2 and item 1. Right? So the output of this is actually going to be a matrix. The distances are actually gonna give us a matrix. Where, I mean, it doesn't matter which way around we do it, we can decide. If we do it this way around, for each of the five things in the mini-batch, there will be 1500 distances, the distance between every one. So we're gonna need to do broadcasting to do this calculation. So, This is the function that we're gonna create. And it's gonna create this, as you can see, 5 by 1500 output. But let's see how we get it. So can we do x minus x? No, we can't. Why is that? That's because big X is 1500 by 2, and little x is 5 by 2. So it's going to look at, remember our rules, right to left. Are these compatible? Yes, they are. They're the same. Are these compatible? No, they're not. Okay, because they're different. So that's not possible to do. What if, though, we wanted to, What if we insert in big X an axis at the start here? And in little x, we add an axis in the middle here. Then now, these are compatible. Because you've got, they're the same. I guess I should use arrows, really. These are compatible, because one of them's a 1. And these are compatible, because one of them's a 1 as well. So they are all compatible. And what it's gonna do is it's going to Do the subtraction between these directly. And it's gonna copy this across all 1500 rows. It'll copy it. This is gonna be copied. And then this, sorry, across five rows. And then this will be copied across these 1500 rows. Cuz that's what broadcasting does. I mean, it's not really copying, but it's effectively copying. And so that gives us, we can now subtract them, and that gives us what we wanted, which is 5 by 1500. And there's also by 2, because there's both the x and the y. So that's why this works. That's what this is doing here. It's taking the subtraction, it's squaring them, and then summing over that last shortest axis. Summing over the x and the y squareds. And then take square root. I don't know why I said torch.square root. We could have just put dot square root at the end. But same, same. In fact, it's worth mentioning that. So most things that you can do on tensors, you can either write torch.as a function, or you can write it as a method. Generally speaking, both should be fine. Not everything, but most things work in both spots. Okay, so now we've got this matrix, which is 5 by 1500. And the nice thing is that our Gaussian kernel doesn't actually have to be changed to get the weights, believe it or not. And the reason for that is, now how do we get the source code? I could move back up there, or I can just type Gaussian question mark, question mark, and see it. And the nice thing is that this is just, this is a scalar, so it broadcasts over anything. And then this is also just a scalar. So this is all gonna work fine without any fiddling around. Okay, so now we've got a 5 by 1500 weight. So that's the weight for each of the five things in our mini-batch, which are the 1500 things each of them is compared to. And then we've got the shape of the data itself, x.shape, which is the 1500 points. So now we want to apply each one of these weights to each of these columns. So we need to add a unit axis to the end. So to add a unit axis to the end, we could say colon, comma, colon, comma, none, but dot, dot, dot means all of the axes up until however many you need, so in this case the last one, comma, none. So this is gonna add an axis to the end. So this is gonna turn weight.shape from 5, 1500 to 5, 1500, 1. And this is gonna add an axis to the start. Remember it's the same as x, none, colon, colon, colon. And so let's check our rules. Left, right to left. These are compatible because one of them's one. These are compatible because they're both the same. And these are compatible because one of them's one. Okay, so it's going to be copying each weight across to each of the x and y, which is what we want. We want to weight both of those components. And it's going to copy each of the 1500 points, sorry, each of the point five times, because we do in fact want to weight every one of the five things in our mini-batch, a separate set of weights for each of them. So that sounds perfect. So that's how I think through these calculations. Okay, so we can now do that multiplication, which is gonna give us something of 5 by 1500 by 2, cuz we end up with the maximum of our ranks. And then we sum up over those 1500 points, and that's going to give us our five new data points. Now, something that you might notice here is that we've got a product, and a sum. And when you see a product and a sum, that tells you that maybe we should use i and sum. So in this case, we've got our weight, we've got 5 by 1500. So let's call those i and j, those for the 5 and 1500. We've got the x is 1500 by 2. Now we want to take the product of that and that, so we need to use the same name for this row, so we use j again, okay? And then k is the number of rows, that's the 2. And then we want to end up with i by k. So torch.i and sum gives exactly the same result. That's great. But you might recognize this, that's exactly the same i and sum we had just before when we were doing matrix multiplication. That is a matrix multiplication. We've just reinvented matrix multiplication using this rather nifty trick. So we could also just use that. And so again, this is like what I was just playing around with this morning as I started to look at this and I was thinking like, can we simplify this? I don't like this kind of messing around with axes and summing over dimensions and whatnot. And so it's nice to get things down to i and sum or better still get them down to matrix multiplies. It's just clearer, it's stuff that we recognize because we use them all the time. They all work, performance would be pretty similar I suspect. Okay, so now that we've got that, we then need to do our sum and we've got our five points. This is our five denominators. So we've got our numerator that we calculated up here for our weighted average. The denominator is just the sum of the weights, remember. And so numerator divided by denominator is our answer. So again, we've gone through every step, we've checked out all the dimensions all along the way, so nothing's gonna surprise us. Don't try and write a function like this just bang from scratch, right? You're gonna drive yourself crazy. Instead, do it step by step. So here's our mean shift algorithm. Clone the data. Go through five iterations. And now go from 0 to n, batch size at a time. So Python has something called slices. So we can create a slice of x starting at 1 up to i plus batch size, right? Unless you've gone past n, which goes to use n. And so then we're just copying and pasting each of the lines of code that we had before. Actually, I just copy the cells and merge them, of course. I don't actually copy and paste because it's slow and boring. And there's my final step to create the new xs. And so notice here, s is not a single thing, it's a slice of things. You might not have seen slice before, but this is just internally what Python's doing when you use colon. And it's very convenient when you need to use the same slice multiple times. Okay. So let's do that using CUDA. I would run it first without CUDA, but I mean, I've done all the steps before, so it should be fine. So pop it on the GPU and run the main shift. And let's see how long that takes. It takes one millisecond. And previously, without GPU, it took 400 milliseconds. And the other thing we should probably think about doing is looking at other batch sizes as well. Because now we're looping over batches, right? So if we make the batch size bigger, that for loop's gonna do less looping. So what if we make that 16? Will that be any faster? I actually never tried this before. That's interesting, it's actually slower. Huh, there you go, fascinating. What if it was eight? Amazing. So the big patches don't quite seem to be working so well for some reason. So I wonder if I've, Hang on, what's going on? Why is it, Why is it changing how it should be? My batch size was five, why is it slower suddenly? I think it's just a bit varying is probably the answer. So it just varies a lot. Okay, so it doesn't seem like changing the batch size is changing much here. So that's fine, so we'll just leave it where it was. And then it's checked looking at the data. That looks lovely. I see, thank you people on YouTube pointing out that I'm passing batch size. So I actually need to put it here. All right, so if we used a batch size of five, no wonder it was messing up. Look at that, I've totally made it slow now. 157 milliseconds. Ha ha, okay, 64, 13 milliseconds. All right, finally, that makes much more sense, 256. 1024, okay, so the bigger, bigger is better. And I guess we can actually do all 5,000 at once probably. Nice. All right, thank you YouTube friends for solving that bizarre mystery. Okay, all right, so that's pretty great. I mean, to see that we can GPU optimize a mean shift, I actually Googled for this to see if it's been done before. And it's the kind of thing that people write papers about. So I think it's great that we can do it so easily with PyTorch, and it's the kind of thing that previously had been considered a very challenging academic problem to solve. So maybe you can do something similar with some of these. Now, I haven't told you what these are, so part of the homework is to go read about them and learn about them. DBScan, funnily enough, actually, is an algorithm that I accidentally invented, and then discovered a year later had already been invented. That was a long time ago. I was playing around with J, which is the successor to APL, on a very old Windows phone. And I had a long plane flight, and I came up with an algorithm and implemented the whole thing on my phone using J. And then discovered a year later that I just invented DBScan. This is actually a really cool algorithm, and it's got a lot of similarities to mean shift. LSH comes up all the time, so that's great. And in fact, I have a strong feeling, and I've been thinking about this for a while, that something like LSH could be used to speed this whole thing up a lot. Because if you think about it, and again, maybe this already exists, I don't know. But if you think about it, when we did that distance calculation, the vast majority of the weights are nearly zero. And so it seems pointless to create that big, kind of eventually 1500 by 1500 matrix. That's slow. It would be much better if we just found the ones that were pretty close by and just took their average. And so you want an optimized nearest neighbors, basically. And so this is an example of something that can give you a kind of a fast nearest neighbors algorithm. Or there are things like KD trees and oct trees and stuff like that. So if you want to have a bonus bonus, Invent a new mean shift algorithm, Which picks only the closest points. To avoid quadratic type. All right, so not very often you get an assignment, which is to invent a new mean shift algorithm. I guess a super super bonus, Super super bonus, Publish a paper. That describes it. All right, you definitely get four points if you do that. We'll give you a number of points equal to the impact factor of the journal you get it published in. Okay. So what I want to do now is move on to calculus. Which for some of us may not be our favorite topic. That's funny, Stefano wrote the iron sum version here already, I didn't notice. Okay, always ahead of his time, that guy. Let's talk about calculus. If you're not super comfortable with derivatives and what they are and why we care, 3Blue1Brown has a wonderful series called The Essence of Calculus, which I strongly recommend watching. It's just a pleasure, actually, to watch, as it's everything that is on 3Blue1Brown a pleasure to watch. The, And so we're not gonna get into back prop today. Instead we're just gonna have a quick chat about calculus. Where do we start? So the good news is, just like you don't have to know much linear algebra at all. You basically just need to know about matrix multiplication. You also don't need to know much calculus at all. Just derivatives. So let's think about what derivatives are. So I'm gonna borrow actually the same starting point that 3Blue1Brown uses in one of their videos, it's to consider a car. And we're gonna see how far away from home it is. At various time points. Okay, so after a minute, let's say after a second. It's traveled 5 meters. And then after 2 seconds, It's traveled 10 meters. Okay, and after 3 seconds, you can probably guess, it's traveled 15 meters. So there's this concept here of, got it the wrong way around, obviously. So, time, distance. Okay, so there's this concept of, yeah, of like location. It's like how far have you traveled at a particular point in time. So we can look at one of these points and find out how far that car has gone. We could also take two points. And we can say, where did it start at the start of those two points? And where did it finish at the end of those two points? And we can say between those two points, how much time passed? And how far did they travel? In two seconds, they traveled 10 meters. So we could now also say, all right, well, The slope of something is rise over run. Oopsie daisy. 10 meters in 2 seconds. And notice we don't just divide the numbers, we also divide the units. We get 5 meters per second. So this here has now changed the dimensions entirely. We're now not looking at distance, but we're looking at speed or velocity. And it's equal to rise over run. It's equal to the rate of change. And what it says really is, as time, the x-axis, goes up by one second, what happens to the distance in meters? As one second passes, How does the number of meters change? And so maybe these aren't points at all, maybe there's a function. Right, it's a continuum of points. And so you can do that for the function. So the function is a function of time. Distance is a function of time. And so we could say, what's the slope of that function? And we can get the slope from point A to point B using rise over run. So from t1 to t2, the amount of time that's passed Is t2 minus t1, that's how much time has passed. Let's say this is t1, this is t2. And the distance that they've traveled, well, they've moved from Wherever they are at the end to wherever they were at the start. So that's the change in distance divided by the change in time. Change in distance divided by change in time. Okay, let's say that's y. So another way, now the thing is, when we talk about calculus, we talk about finding a slope. But we talk about finding a slope of something That's often more tricky than this, right? We have slopes of things That look more like this. And we say, what's this slope? Oops, I'm terrible at drawing. Let's maybe put it over here, cuz I'm left handed. What's this slope? Now, what does it mean to have the idea of a velocity at an exact moment in time? It doesn't mean anything. At an exact moment in time, you're just like, it's frozen, right? What's happening exactly now? But what you can do is you can say, well, what's the change in time between a bit before our point and a bit after our point? And what's the change in distance between a bit before our point and a bit after our point? And so you can do the same kind of rise over run thing, right? But you can make that distance between t2 and t1 smaller and smaller and smaller. So let's rewrite this in a slightly different way. Let's call the denominator the distance between t1 plus a little bit. We'll call it d. It's that minus t1. So this is t2, right? It's t1 plus a little bit. So we say, here's t1, let's add a little bit. And notice that when we write it this, well, let's actually let's do the rest of it. So now f of t2 becomes f of t1 plus a little bit. And this is the same. And now notice here that t1 plus d minus t1, we can delete all that because it just comes out to d. So this is another way of calculating the slope of our function. And as d gets smaller and smaller and smaller, we're kind of getting a triangle that's tinier and tinier and tinier. And it still makes sense, it's still that some time has passed and the car has moved, right? But it's just smaller and smaller amounts of time. Now if you did calculus at college or at school, you might have done all this stuff messing around with limits and epsilon delta and blah, blah, blah. I've got really good news. It turns out you can actually just think of this d as a really small number. Where d is the difference. Difference. And so when we calculate the slope, We can write it in a slightly different way. As the change in y divided by the change in x. This here is the change in y, and this here is the change in x. And so in other words, this here is a very small number. A very small number. And this here is the result in the function of changing by that very small number. And this way of thinking about calculus is known as the calculus of infinitesimals. And it's how Leibniz originally developed it. And it's been turned into a whole theory nowadays. And the reason I talk about it here is because when we do this, You'll see me doing stuff all the time where I act like dx is a really small number. And when I was at school, I was told I wasn't allowed to do that. I've since learned that it's totally fine to do that. So for example, next lesson, we're gonna be looking at the chain rule. Which looks like this. And we're gonna be looking at the chain rule. Which looks like this. dy dx equals dy du times du dx. And I'm just gonna say, these two small numbers can cancel out. And that's why obviously they're the same thing. And that's all gonna work out nicely. So anywho, what would be very helpful would be if before the next lesson, if you're not totally up to date with your, remembering all the stuff you did in high school about calculus. Is watch the three blue, one brown course. We are not gonna be looking, I don't think at all, at integration. So you don't have to worry about that. Also, we are not going to, on the whole, be doing any derivatives by hand. So for example, there are rules such as, dy dx if y equals x squared is 2x. These kind of rules, you're not really gonna have to learn. Because PyTorch is gonna do them all for you. The one that we care about is gonna be the chain rule. But we're gonna learn about that next time. Okay, I hope I don't get beaten to a bloody pulp the next time I walk into a mathematician's conference. I suspect I might. But hopefully I get away with this. I think it's safe. We'll see how we go. So, Thanks everybody very much for joining me. And I really look forward to seeing you next time where we're gonna do back propagation from scratch. We've already learned to multiply matrices. So once we've got back propagation as well, we'll be ready to train a neural network. All right, thanks all, bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.48, "text": " Hi everybody, welcome back to lesson 12 of practical deep learning for coders.", "tokens": [50364, 2421, 2201, 11, 2928, 646, 281, 6898, 2272, 295, 8496, 2452, 2539, 337, 17656, 433, 13, 50838], "temperature": 0.0, "avg_logprob": -0.2553560406553979, "compression_ratio": 1.5637860082304527, "no_speech_prob": 7.542874664068222e-05}, {"id": 1, "seek": 0, "start": 9.48, "end": 12.92, "text": " So got a lot of stuff to cover today, so let's dive straight in.", "tokens": [50838, 407, 658, 257, 688, 295, 1507, 281, 2060, 965, 11, 370, 718, 311, 9192, 2997, 294, 13, 51010], "temperature": 0.0, "avg_logprob": -0.2553560406553979, "compression_ratio": 1.5637860082304527, "no_speech_prob": 7.542874664068222e-05}, {"id": 2, "seek": 0, "start": 12.92, "end": 18.72, "text": " And I actually thought I would start by sharing something which I've seen been getting a lot", "tokens": [51010, 400, 286, 767, 1194, 286, 576, 722, 538, 5414, 746, 597, 286, 600, 1612, 668, 1242, 257, 688, 51300], "temperature": 0.0, "avg_logprob": -0.2553560406553979, "compression_ratio": 1.5637860082304527, "no_speech_prob": 7.542874664068222e-05}, {"id": 3, "seek": 0, "start": 18.72, "end": 22.72, "text": " of attention recently, which is the Clip Interrogator.", "tokens": [51300, 295, 3202, 3938, 11, 597, 307, 264, 2033, 647, 5751, 6675, 1639, 13, 51500], "temperature": 0.0, "avg_logprob": -0.2553560406553979, "compression_ratio": 1.5637860082304527, "no_speech_prob": 7.542874664068222e-05}, {"id": 4, "seek": 0, "start": 22.72, "end": 28.080000000000002, "text": " So the Clip Interrogator is a Hugging Face Spaces, I guess, Gradio app, where I uploaded", "tokens": [51500, 407, 264, 2033, 647, 5751, 6675, 1639, 307, 257, 46892, 3249, 4047, 1738, 2116, 11, 286, 2041, 11, 2606, 5688, 78, 724, 11, 689, 286, 17135, 51768], "temperature": 0.0, "avg_logprob": -0.2553560406553979, "compression_ratio": 1.5637860082304527, "no_speech_prob": 7.542874664068222e-05}, {"id": 5, "seek": 2808, "start": 28.08, "end": 42.239999999999995, "text": " my image here, and its output, let's just zoom in a bit, its output a text prompt for", "tokens": [50364, 452, 3256, 510, 11, 293, 1080, 5598, 11, 718, 311, 445, 8863, 294, 257, 857, 11, 1080, 5598, 257, 2487, 12391, 337, 51072], "temperature": 0.0, "avg_logprob": -0.2868182083656048, "compression_ratio": 1.403973509933775, "no_speech_prob": 0.0002492307685315609}, {"id": 6, "seek": 2808, "start": 42.239999999999995, "end": 46.76, "text": " creating a clip embedding from, I guess.", "tokens": [51072, 4084, 257, 7353, 12240, 3584, 490, 11, 286, 2041, 13, 51298], "temperature": 0.0, "avg_logprob": -0.2868182083656048, "compression_ratio": 1.403973509933775, "no_speech_prob": 0.0002492307685315609}, {"id": 7, "seek": 2808, "start": 46.76, "end": 53.26, "text": " So I've seen a lot of folks on Twitter and elsewhere on the internet saying that this", "tokens": [51298, 407, 286, 600, 1612, 257, 688, 295, 4024, 322, 5794, 293, 14517, 322, 264, 4705, 1566, 300, 341, 51623], "temperature": 0.0, "avg_logprob": -0.2868182083656048, "compression_ratio": 1.403973509933775, "no_speech_prob": 0.0002492307685315609}, {"id": 8, "seek": 5326, "start": 53.26, "end": 61.9, "text": " is producing the clip prompt that would generate this image.", "tokens": [50364, 307, 10501, 264, 7353, 12391, 300, 576, 8460, 341, 3256, 13, 50796], "temperature": 0.0, "avg_logprob": -0.35223185221354164, "compression_ratio": 1.5194174757281553, "no_speech_prob": 8.092734788078815e-05}, {"id": 9, "seek": 5326, "start": 61.9, "end": 67.56, "text": " And generally speaking, the clip, the prompts it creates are rather rude.", "tokens": [50796, 400, 5101, 4124, 11, 264, 7353, 11, 264, 41095, 309, 7829, 366, 2831, 18895, 13, 51079], "temperature": 0.0, "avg_logprob": -0.35223185221354164, "compression_ratio": 1.5194174757281553, "no_speech_prob": 8.092734788078815e-05}, {"id": 10, "seek": 5326, "start": 67.56, "end": 71.22, "text": " My one's less rude than some, although, you know, extremely long forehead, maybe not,", "tokens": [51079, 1222, 472, 311, 1570, 18895, 813, 512, 11, 4878, 11, 291, 458, 11, 4664, 938, 20472, 11, 1310, 406, 11, 51262], "temperature": 0.0, "avg_logprob": -0.35223185221354164, "compression_ratio": 1.5194174757281553, "no_speech_prob": 8.092734788078815e-05}, {"id": 11, "seek": 5326, "start": 71.22, "end": 77.97999999999999, "text": " thanks very much, but your personal data avatar, funny professional photo, I don't know what", "tokens": [51262, 3231, 588, 709, 11, 457, 428, 2973, 1412, 36205, 11, 4074, 4843, 5052, 11, 286, 500, 380, 458, 437, 51600], "temperature": 0.0, "avg_logprob": -0.35223185221354164, "compression_ratio": 1.5194174757281553, "no_speech_prob": 8.092734788078815e-05}, {"id": 12, "seek": 7798, "start": 77.98, "end": 82.18, "text": " tectonics is meant to mean here, without eyebrows.", "tokens": [50364, 535, 349, 266, 1167, 307, 4140, 281, 914, 510, 11, 1553, 19916, 13, 50574], "temperature": 0.0, "avg_logprob": -0.24135761046677492, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0072326939553022385}, {"id": 13, "seek": 7798, "start": 82.18, "end": 93.0, "text": " So this doesn't actually return the clip prompt that would generate this photo at all.", "tokens": [50574, 407, 341, 1177, 380, 767, 2736, 264, 7353, 12391, 300, 576, 8460, 341, 5052, 412, 439, 13, 51115], "temperature": 0.0, "avg_logprob": -0.24135761046677492, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0072326939553022385}, {"id": 14, "seek": 7798, "start": 93.0, "end": 96.94, "text": " And the fact that some people are saying that makes me realize that some people have no", "tokens": [51115, 400, 264, 1186, 300, 512, 561, 366, 1566, 300, 1669, 385, 4325, 300, 512, 561, 362, 572, 51312], "temperature": 0.0, "avg_logprob": -0.24135761046677492, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0072326939553022385}, {"id": 15, "seek": 7798, "start": 96.94, "end": 100.34, "text": " idea what's going on with stable diffusion.", "tokens": [51312, 1558, 437, 311, 516, 322, 365, 8351, 25242, 13, 51482], "temperature": 0.0, "avg_logprob": -0.24135761046677492, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0072326939553022385}, {"id": 16, "seek": 7798, "start": 100.34, "end": 105.42, "text": " So I thought we might take this as an opportunity to explain why we can't do that, and what", "tokens": [51482, 407, 286, 1194, 321, 1062, 747, 341, 382, 364, 2650, 281, 2903, 983, 321, 393, 380, 360, 300, 11, 293, 437, 51736], "temperature": 0.0, "avg_logprob": -0.24135761046677492, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0072326939553022385}, {"id": 17, "seek": 10542, "start": 105.42, "end": 108.72, "text": " we can try and do instead.", "tokens": [50364, 321, 393, 853, 293, 360, 2602, 13, 50529], "temperature": 0.0, "avg_logprob": -0.21188131968180338, "compression_ratio": 1.3884297520661157, "no_speech_prob": 0.001987769966945052}, {"id": 18, "seek": 10542, "start": 108.72, "end": 123.78, "text": " So let's imagine that my friend took a photo of himself, and he wanted to send me his photo,", "tokens": [50529, 407, 718, 311, 3811, 300, 452, 1277, 1890, 257, 5052, 295, 3647, 11, 293, 415, 1415, 281, 2845, 385, 702, 5052, 11, 51282], "temperature": 0.0, "avg_logprob": -0.21188131968180338, "compression_ratio": 1.3884297520661157, "no_speech_prob": 0.001987769966945052}, {"id": 19, "seek": 10542, "start": 123.78, "end": 126.62, "text": " and he thought he would compress it a whole lot.", "tokens": [51282, 293, 415, 1194, 415, 576, 14778, 309, 257, 1379, 688, 13, 51424], "temperature": 0.0, "avg_logprob": -0.21188131968180338, "compression_ratio": 1.3884297520661157, "no_speech_prob": 0.001987769966945052}, {"id": 20, "seek": 12662, "start": 126.62, "end": 134.22, "text": " So what he did was he put it through the clip image encoder.", "tokens": [50364, 407, 437, 415, 630, 390, 415, 829, 309, 807, 264, 7353, 3256, 2058, 19866, 13, 50744], "temperature": 0.0, "avg_logprob": -0.26578480856759207, "compression_ratio": 1.5, "no_speech_prob": 0.00029136938974261284}, {"id": 21, "seek": 12662, "start": 134.22, "end": 145.34, "text": " Okay, so that's going to take this big image, and it's going to turn it into an embedding.", "tokens": [50744, 1033, 11, 370, 300, 311, 516, 281, 747, 341, 955, 3256, 11, 293, 309, 311, 516, 281, 1261, 309, 666, 364, 12240, 3584, 13, 51300], "temperature": 0.0, "avg_logprob": -0.26578480856759207, "compression_ratio": 1.5, "no_speech_prob": 0.00029136938974261284}, {"id": 22, "seek": 12662, "start": 145.34, "end": 155.66, "text": " And the embedding is much, much smaller than the image, it's just a vector of a few floats.", "tokens": [51300, 400, 264, 12240, 3584, 307, 709, 11, 709, 4356, 813, 264, 3256, 11, 309, 311, 445, 257, 8062, 295, 257, 1326, 37878, 13, 51816], "temperature": 0.0, "avg_logprob": -0.26578480856759207, "compression_ratio": 1.5, "no_speech_prob": 0.00029136938974261284}, {"id": 23, "seek": 15566, "start": 155.7, "end": 166.22, "text": " So then my friend hopes that they could send me this embedding, and so they send that over", "tokens": [50366, 407, 550, 452, 1277, 13681, 300, 436, 727, 2845, 385, 341, 12240, 3584, 11, 293, 370, 436, 2845, 300, 670, 50892], "temperature": 0.0, "avg_logprob": -0.2425515133401622, "compression_ratio": 1.75, "no_speech_prob": 6.302743713604286e-05}, {"id": 24, "seek": 15566, "start": 166.22, "end": 169.42, "text": " in an email, and they say, there you go Jeremy, there's the clip embedding of the photo I", "tokens": [50892, 294, 364, 3796, 11, 293, 436, 584, 11, 456, 291, 352, 17809, 11, 456, 311, 264, 7353, 12240, 3584, 295, 264, 5052, 286, 51052], "temperature": 0.0, "avg_logprob": -0.2425515133401622, "compression_ratio": 1.75, "no_speech_prob": 6.302743713604286e-05}, {"id": 25, "seek": 15566, "start": 169.42, "end": 180.06, "text": " wanted to send you, so now you just have to decode it to turn it back into a picture.", "tokens": [51052, 1415, 281, 2845, 291, 11, 370, 586, 291, 445, 362, 281, 979, 1429, 309, 281, 1261, 309, 646, 666, 257, 3036, 13, 51584], "temperature": 0.0, "avg_logprob": -0.2425515133401622, "compression_ratio": 1.75, "no_speech_prob": 6.302743713604286e-05}, {"id": 26, "seek": 15566, "start": 180.06, "end": 184.26, "text": " So now I've got the embedding, and I have to decode it.", "tokens": [51584, 407, 586, 286, 600, 658, 264, 12240, 3584, 11, 293, 286, 362, 281, 979, 1429, 309, 13, 51794], "temperature": 0.0, "avg_logprob": -0.2425515133401622, "compression_ratio": 1.75, "no_speech_prob": 6.302743713604286e-05}, {"id": 27, "seek": 18426, "start": 184.26, "end": 189.26, "text": " How would you do that?", "tokens": [50364, 1012, 576, 291, 360, 300, 30, 50614], "temperature": 0.0, "avg_logprob": -0.3303018133324313, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.00018814191571436822}, {"id": 28, "seek": 18426, "start": 189.26, "end": 193.26, "text": " Well, you can't.", "tokens": [50614, 1042, 11, 291, 393, 380, 13, 50814], "temperature": 0.0, "avg_logprob": -0.3303018133324313, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.00018814191571436822}, {"id": 29, "seek": 18426, "start": 193.26, "end": 200.06, "text": " Okay, we have a function here, or let's call it f, which is the clip image encoder, which", "tokens": [50814, 1033, 11, 321, 362, 257, 2445, 510, 11, 420, 718, 311, 818, 309, 283, 11, 597, 307, 264, 7353, 3256, 2058, 19866, 11, 597, 51154], "temperature": 0.0, "avg_logprob": -0.3303018133324313, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.00018814191571436822}, {"id": 30, "seek": 18426, "start": 200.06, "end": 206.78, "text": " takes as input an image, which I'll call x, and returns an embedding.", "tokens": [51154, 2516, 382, 4846, 364, 3256, 11, 597, 286, 603, 818, 2031, 11, 293, 11247, 364, 12240, 3584, 13, 51490], "temperature": 0.0, "avg_logprob": -0.3303018133324313, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.00018814191571436822}, {"id": 31, "seek": 18426, "start": 206.78, "end": 211.7, "text": " Does that mean that there is some other function, and inverse functions we normally write with", "tokens": [51490, 4402, 300, 914, 300, 456, 307, 512, 661, 2445, 11, 293, 17340, 6828, 321, 5646, 2464, 365, 51736], "temperature": 0.0, "avg_logprob": -0.3303018133324313, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.00018814191571436822}, {"id": 32, "seek": 21170, "start": 211.7, "end": 217.85999999999999, "text": " the minus one, an inverse function with which I can take that embedding, let's say we call", "tokens": [50364, 264, 3175, 472, 11, 364, 17340, 2445, 365, 597, 286, 393, 747, 300, 12240, 3584, 11, 718, 311, 584, 321, 818, 50672], "temperature": 0.0, "avg_logprob": -0.26176029056697697, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.0009399428963661194}, {"id": 33, "seek": 21170, "start": 217.85999999999999, "end": 233.48, "text": " that y, we pass it y, and it would give us back our photo.", "tokens": [50672, 300, 288, 11, 321, 1320, 309, 288, 11, 293, 309, 576, 976, 505, 646, 527, 5052, 13, 51453], "temperature": 0.0, "avg_logprob": -0.26176029056697697, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.0009399428963661194}, {"id": 34, "seek": 21170, "start": 233.48, "end": 239.72, "text": " And so y, remember, is f of x, so to put it another way, this is f inverse of f of f of", "tokens": [51453, 400, 370, 288, 11, 1604, 11, 307, 283, 295, 2031, 11, 370, 281, 829, 309, 1071, 636, 11, 341, 307, 283, 17340, 295, 283, 295, 283, 295, 51765], "temperature": 0.0, "avg_logprob": -0.26176029056697697, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.0009399428963661194}, {"id": 35, "seek": 21170, "start": 239.72, "end": 241.22, "text": " y.", "tokens": [51765, 288, 13, 51840], "temperature": 0.0, "avg_logprob": -0.26176029056697697, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.0009399428963661194}, {"id": 36, "seek": 24122, "start": 241.74, "end": 248.18, "text": " So an inverse function is something that undoes a function, and so that gives you back y.", "tokens": [50390, 407, 364, 17340, 2445, 307, 746, 300, 23779, 279, 257, 2445, 11, 293, 370, 300, 2709, 291, 646, 288, 13, 50712], "temperature": 0.0, "avg_logprob": -0.29701333296926397, "compression_ratio": 1.625, "no_speech_prob": 3.822909275186248e-05}, {"id": 37, "seek": 24122, "start": 248.18, "end": 254.98, "text": " Is there an inverse function for the clip image encoder?", "tokens": [50712, 1119, 456, 364, 17340, 2445, 337, 264, 7353, 3256, 2058, 19866, 30, 51052], "temperature": 0.0, "avg_logprob": -0.29701333296926397, "compression_ratio": 1.625, "no_speech_prob": 3.822909275186248e-05}, {"id": 38, "seek": 24122, "start": 254.98, "end": 258.26, "text": " Well not everything has an inverse function.", "tokens": [51052, 1042, 406, 1203, 575, 364, 17340, 2445, 13, 51216], "temperature": 0.0, "avg_logprob": -0.29701333296926397, "compression_ratio": 1.625, "no_speech_prob": 3.822909275186248e-05}, {"id": 39, "seek": 24122, "start": 258.26, "end": 270.26, "text": " For example, consider the function, like let's say in Python, which takes def f, oopsie-daisy,", "tokens": [51216, 1171, 1365, 11, 1949, 264, 2445, 11, 411, 718, 311, 584, 294, 15329, 11, 597, 2516, 1060, 283, 11, 34166, 414, 12, 67, 1527, 88, 11, 51816], "temperature": 0.0, "avg_logprob": -0.29701333296926397, "compression_ratio": 1.625, "no_speech_prob": 3.822909275186248e-05}, {"id": 40, "seek": 27026, "start": 270.3, "end": 274.9, "text": " def f of x, return 0.", "tokens": [50366, 1060, 283, 295, 2031, 11, 2736, 1958, 13, 50596], "temperature": 0.0, "avg_logprob": -0.26435074579148066, "compression_ratio": 1.7116279069767442, "no_speech_prob": 2.2827996872365475e-05}, {"id": 41, "seek": 27026, "start": 274.9, "end": 278.26, "text": " Can you invert that function?", "tokens": [50596, 1664, 291, 33966, 300, 2445, 30, 50764], "temperature": 0.0, "avg_logprob": -0.26435074579148066, "compression_ratio": 1.7116279069767442, "no_speech_prob": 2.2827996872365475e-05}, {"id": 42, "seek": 27026, "start": 278.26, "end": 283.5, "text": " If you get back, you pass in 3, you get back 0, is there a function, oopsie, 0, is there", "tokens": [50764, 759, 291, 483, 646, 11, 291, 1320, 294, 805, 11, 291, 483, 646, 1958, 11, 307, 456, 257, 2445, 11, 34166, 414, 11, 1958, 11, 307, 456, 51026], "temperature": 0.0, "avg_logprob": -0.26435074579148066, "compression_ratio": 1.7116279069767442, "no_speech_prob": 2.2827996872365475e-05}, {"id": 43, "seek": 27026, "start": 283.5, "end": 286.74, "text": " a function that's going to take the output and give you back the input?", "tokens": [51026, 257, 2445, 300, 311, 516, 281, 747, 264, 5598, 293, 976, 291, 646, 264, 4846, 30, 51188], "temperature": 0.0, "avg_logprob": -0.26435074579148066, "compression_ratio": 1.7116279069767442, "no_speech_prob": 2.2827996872365475e-05}, {"id": 44, "seek": 27026, "start": 286.74, "end": 291.14, "text": " No, of course not, because you just threw the whole thing away.", "tokens": [51188, 883, 11, 295, 1164, 406, 11, 570, 291, 445, 11918, 264, 1379, 551, 1314, 13, 51408], "temperature": 0.0, "avg_logprob": -0.26435074579148066, "compression_ratio": 1.7116279069767442, "no_speech_prob": 2.2827996872365475e-05}, {"id": 45, "seek": 27026, "start": 291.14, "end": 298.71999999999997, "text": " So not all functions can be inverted, and indeed in this case we've started with a function", "tokens": [51408, 407, 406, 439, 6828, 393, 312, 38969, 11, 293, 6451, 294, 341, 1389, 321, 600, 1409, 365, 257, 2445, 51787], "temperature": 0.0, "avg_logprob": -0.26435074579148066, "compression_ratio": 1.7116279069767442, "no_speech_prob": 2.2827996872365475e-05}, {"id": 46, "seek": 29872, "start": 298.88000000000005, "end": 306.72, "text": " which is whatever, 512 by 512 by 3, say, and we've turned it into something much, much", "tokens": [50372, 597, 307, 2035, 11, 1025, 4762, 538, 1025, 4762, 538, 805, 11, 584, 11, 293, 321, 600, 3574, 309, 666, 746, 709, 11, 709, 50764], "temperature": 0.0, "avg_logprob": -0.25396668767354574, "compression_ratio": 1.5103092783505154, "no_speech_prob": 1.1478763553895988e-05}, {"id": 47, "seek": 29872, "start": 306.72, "end": 307.72, "text": " smaller.", "tokens": [50764, 4356, 13, 50814], "temperature": 0.0, "avg_logprob": -0.25396668767354574, "compression_ratio": 1.5103092783505154, "no_speech_prob": 1.1478763553895988e-05}, {"id": 48, "seek": 29872, "start": 307.72, "end": 313.62, "text": " I can't remember exactly how big a clip image encoding is, embedding is, but it's much smaller.", "tokens": [50814, 286, 393, 380, 1604, 2293, 577, 955, 257, 7353, 3256, 43430, 307, 11, 12240, 3584, 307, 11, 457, 309, 311, 709, 4356, 13, 51109], "temperature": 0.0, "avg_logprob": -0.25396668767354574, "compression_ratio": 1.5103092783505154, "no_speech_prob": 1.1478763553895988e-05}, {"id": 49, "seek": 29872, "start": 313.62, "end": 319.12, "text": " So clearly we're losing something.", "tokens": [51109, 407, 4448, 321, 434, 7027, 746, 13, 51384], "temperature": 0.0, "avg_logprob": -0.25396668767354574, "compression_ratio": 1.5103092783505154, "no_speech_prob": 1.1478763553895988e-05}, {"id": 50, "seek": 29872, "start": 319.12, "end": 327.8, "text": " But what I could do is I could put it through a diffusion process.", "tokens": [51384, 583, 437, 286, 727, 360, 307, 286, 727, 829, 309, 807, 257, 25242, 1399, 13, 51818], "temperature": 0.0, "avg_logprob": -0.25396668767354574, "compression_ratio": 1.5103092783505154, "no_speech_prob": 1.1478763553895988e-05}, {"id": 51, "seek": 32780, "start": 327.88, "end": 334.64, "text": " And so remember a diffusion process is something where we have learnt, we have taught, or we", "tokens": [50368, 400, 370, 1604, 257, 25242, 1399, 307, 746, 689, 321, 362, 18991, 11, 321, 362, 5928, 11, 420, 321, 50706], "temperature": 0.0, "avg_logprob": -0.25126164419609204, "compression_ratio": 1.8803418803418803, "no_speech_prob": 7.722186273895204e-05}, {"id": 52, "seek": 32780, "start": 334.64, "end": 341.6, "text": " shouldn't say, I don't know, taught, an algorithm has learned to take some noise, so we could", "tokens": [50706, 4659, 380, 584, 11, 286, 500, 380, 458, 11, 5928, 11, 364, 9284, 575, 3264, 281, 747, 512, 5658, 11, 370, 321, 727, 51054], "temperature": 0.0, "avg_logprob": -0.25126164419609204, "compression_ratio": 1.8803418803418803, "no_speech_prob": 7.722186273895204e-05}, {"id": 53, "seek": 32780, "start": 341.6, "end": 345.96000000000004, "text": " start with some noise, and we could start with an image embedding.", "tokens": [51054, 722, 365, 512, 5658, 11, 293, 321, 727, 722, 365, 364, 3256, 12240, 3584, 13, 51272], "temperature": 0.0, "avg_logprob": -0.25126164419609204, "compression_ratio": 1.8803418803418803, "no_speech_prob": 7.722186273895204e-05}, {"id": 54, "seek": 32780, "start": 345.96000000000004, "end": 349.28000000000003, "text": " We haven't done this before, but we could do that, we could train something that takes", "tokens": [51272, 492, 2378, 380, 1096, 341, 949, 11, 457, 321, 727, 360, 300, 11, 321, 727, 3847, 746, 300, 2516, 51438], "temperature": 0.0, "avg_logprob": -0.25126164419609204, "compression_ratio": 1.8803418803418803, "no_speech_prob": 7.722186273895204e-05}, {"id": 55, "seek": 32780, "start": 349.28000000000003, "end": 353.64, "text": " noise in an image embedding and removes a bit of the noise.", "tokens": [51438, 5658, 294, 364, 3256, 12240, 3584, 293, 30445, 257, 857, 295, 264, 5658, 13, 51656], "temperature": 0.0, "avg_logprob": -0.25126164419609204, "compression_ratio": 1.8803418803418803, "no_speech_prob": 7.722186273895204e-05}, {"id": 56, "seek": 32780, "start": 353.64, "end": 357.44, "text": " And we could run that a bunch of times.", "tokens": [51656, 400, 321, 727, 1190, 300, 257, 3840, 295, 1413, 13, 51846], "temperature": 0.0, "avg_logprob": -0.25126164419609204, "compression_ratio": 1.8803418803418803, "no_speech_prob": 7.722186273895204e-05}, {"id": 57, "seek": 35744, "start": 358.08, "end": 361.52, "text": " But it wouldn't give us back the original picture, but hopefully it would give us something", "tokens": [50396, 583, 309, 2759, 380, 976, 505, 646, 264, 3380, 3036, 11, 457, 4696, 309, 576, 976, 505, 746, 50568], "temperature": 0.0, "avg_logprob": -0.23081648470175387, "compression_ratio": 1.9406392694063928, "no_speech_prob": 3.3737203921191394e-05}, {"id": 58, "seek": 35744, "start": 361.52, "end": 367.6, "text": " back if it's a conditional, so remember using the conditional diffusion approach, we'd get", "tokens": [50568, 646, 498, 309, 311, 257, 27708, 11, 370, 1604, 1228, 264, 27708, 25242, 3109, 11, 321, 1116, 483, 50872], "temperature": 0.0, "avg_logprob": -0.23081648470175387, "compression_ratio": 1.9406392694063928, "no_speech_prob": 3.3737203921191394e-05}, {"id": 59, "seek": 35744, "start": 367.6, "end": 372.48, "text": " back something that might be something like our original image.", "tokens": [50872, 646, 746, 300, 1062, 312, 746, 411, 527, 3380, 3256, 13, 51116], "temperature": 0.0, "avg_logprob": -0.23081648470175387, "compression_ratio": 1.9406392694063928, "no_speech_prob": 3.3737203921191394e-05}, {"id": 60, "seek": 35744, "start": 372.48, "end": 375.12, "text": " So that's what diffusion is, right?", "tokens": [51116, 407, 300, 311, 437, 25242, 307, 11, 558, 30, 51248], "temperature": 0.0, "avg_logprob": -0.23081648470175387, "compression_ratio": 1.9406392694063928, "no_speech_prob": 3.3737203921191394e-05}, {"id": 61, "seek": 35744, "start": 375.12, "end": 383.0, "text": " Diffusion is something that takes an embedding and inverts an encoder to give you back something", "tokens": [51248, 413, 3661, 5704, 307, 746, 300, 2516, 364, 12240, 3584, 293, 28653, 1373, 364, 2058, 19866, 281, 976, 291, 646, 746, 51642], "temperature": 0.0, "avg_logprob": -0.23081648470175387, "compression_ratio": 1.9406392694063928, "no_speech_prob": 3.3737203921191394e-05}, {"id": 62, "seek": 35744, "start": 383.0, "end": 386.12, "text": " that hopefully might generate that embedding.", "tokens": [51642, 300, 4696, 1062, 8460, 300, 12240, 3584, 13, 51798], "temperature": 0.0, "avg_logprob": -0.23081648470175387, "compression_ratio": 1.9406392694063928, "no_speech_prob": 3.3737203921191394e-05}, {"id": 63, "seek": 38612, "start": 386.12, "end": 392.68, "text": " Now of course remember, we don't actually get image embeddings when we do prompts in", "tokens": [50364, 823, 295, 1164, 1604, 11, 321, 500, 380, 767, 483, 3256, 12240, 29432, 562, 321, 360, 41095, 294, 50692], "temperature": 0.0, "avg_logprob": -0.2636346022288005, "compression_ratio": 1.5542857142857143, "no_speech_prob": 4.092907602171181e-06}, {"id": 64, "seek": 38612, "start": 392.68, "end": 394.4, "text": " stable diffusion.", "tokens": [50692, 8351, 25242, 13, 50778], "temperature": 0.0, "avg_logprob": -0.2636346022288005, "compression_ratio": 1.5542857142857143, "no_speech_prob": 4.092907602171181e-06}, {"id": 65, "seek": 38612, "start": 394.4, "end": 399.36, "text": " Instead we have text embeddings.", "tokens": [50778, 7156, 321, 362, 2487, 12240, 29432, 13, 51026], "temperature": 0.0, "avg_logprob": -0.2636346022288005, "compression_ratio": 1.5542857142857143, "no_speech_prob": 4.092907602171181e-06}, {"id": 66, "seek": 38612, "start": 399.36, "end": 403.6, "text": " But if you remember, that actually doesn't matter.", "tokens": [51026, 583, 498, 291, 1604, 11, 300, 767, 1177, 380, 1871, 13, 51238], "temperature": 0.0, "avg_logprob": -0.2636346022288005, "compression_ratio": 1.5542857142857143, "no_speech_prob": 4.092907602171181e-06}, {"id": 67, "seek": 38612, "start": 403.6, "end": 409.24, "text": " Because do you remember how we actually, or we, OpenAI, trained Clip so that they had", "tokens": [51238, 1436, 360, 291, 1604, 577, 321, 767, 11, 420, 321, 11, 7238, 48698, 11, 8895, 2033, 647, 370, 300, 436, 632, 51520], "temperature": 0.0, "avg_logprob": -0.2636346022288005, "compression_ratio": 1.5542857142857143, "no_speech_prob": 4.092907602171181e-06}, {"id": 68, "seek": 40924, "start": 409.24, "end": 419.28000000000003, "text": " various pictures along with their captions, and they trained an algorithm that was explicitly", "tokens": [50364, 3683, 5242, 2051, 365, 641, 44832, 11, 293, 436, 8895, 364, 9284, 300, 390, 20803, 50866], "temperature": 0.0, "avg_logprob": -0.22972715551202946, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00033534649992361665}, {"id": 69, "seek": 40924, "start": 419.28000000000003, "end": 430.32, "text": " designed to make it so that each image returned a embedding for the image that was similar", "tokens": [50866, 4761, 281, 652, 309, 370, 300, 1184, 3256, 8752, 257, 12240, 3584, 337, 264, 3256, 300, 390, 2531, 51418], "temperature": 0.0, "avg_logprob": -0.22972715551202946, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00033534649992361665}, {"id": 70, "seek": 40924, "start": 430.32, "end": 435.0, "text": " to the embedding that the text encoder created for the caption.", "tokens": [51418, 281, 264, 12240, 3584, 300, 264, 2487, 2058, 19866, 2942, 337, 264, 31974, 13, 51652], "temperature": 0.0, "avg_logprob": -0.22972715551202946, "compression_ratio": 1.631578947368421, "no_speech_prob": 0.00033534649992361665}, {"id": 71, "seek": 43500, "start": 435.0, "end": 440.0, "text": " And remember all of the stuff that didn't match, it was trained to be different.", "tokens": [50364, 400, 1604, 439, 295, 264, 1507, 300, 994, 380, 2995, 11, 309, 390, 8895, 281, 312, 819, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2251059611638387, "compression_ratio": 1.758139534883721, "no_speech_prob": 0.00013765107723884284}, {"id": 72, "seek": 43500, "start": 440.0, "end": 447.54, "text": " And so that means that a text embedding, which describes this picture, and the actual image", "tokens": [50614, 400, 370, 300, 1355, 300, 257, 2487, 12240, 3584, 11, 597, 15626, 341, 3036, 11, 293, 264, 3539, 3256, 50991], "temperature": 0.0, "avg_logprob": -0.2251059611638387, "compression_ratio": 1.758139534883721, "no_speech_prob": 0.00013765107723884284}, {"id": 73, "seek": 43500, "start": 447.54, "end": 452.32, "text": " embedding of this picture, should be very similar, if they're clip embeddings.", "tokens": [50991, 12240, 3584, 295, 341, 3036, 11, 820, 312, 588, 2531, 11, 498, 436, 434, 7353, 12240, 29432, 13, 51230], "temperature": 0.0, "avg_logprob": -0.2251059611638387, "compression_ratio": 1.758139534883721, "no_speech_prob": 0.00013765107723884284}, {"id": 74, "seek": 43500, "start": 452.32, "end": 454.12, "text": " That's the definition of clip embeddings.", "tokens": [51230, 663, 311, 264, 7123, 295, 7353, 12240, 29432, 13, 51320], "temperature": 0.0, "avg_logprob": -0.2251059611638387, "compression_ratio": 1.758139534883721, "no_speech_prob": 0.00013765107723884284}, {"id": 75, "seek": 43500, "start": 454.12, "end": 461.96, "text": " So you see, this idea that you could take a text or image embedding and turn it back", "tokens": [51320, 407, 291, 536, 11, 341, 1558, 300, 291, 727, 747, 257, 2487, 420, 3256, 12240, 3584, 293, 1261, 309, 646, 51712], "temperature": 0.0, "avg_logprob": -0.2251059611638387, "compression_ratio": 1.758139534883721, "no_speech_prob": 0.00013765107723884284}, {"id": 76, "seek": 46196, "start": 461.96, "end": 467.28, "text": " into an image perfectly, makes most sense.", "tokens": [50364, 666, 364, 3256, 6239, 11, 1669, 881, 2020, 13, 50630], "temperature": 0.0, "avg_logprob": -0.26494348966158354, "compression_ratio": 1.5517241379310345, "no_speech_prob": 4.46940612164326e-05}, {"id": 77, "seek": 46196, "start": 467.28, "end": 471.78, "text": " This is the very definition of the thing we're trying to do when we do clip.", "tokens": [50630, 639, 307, 264, 588, 7123, 295, 264, 551, 321, 434, 1382, 281, 360, 562, 321, 360, 7353, 13, 50855], "temperature": 0.0, "avg_logprob": -0.26494348966158354, "compression_ratio": 1.5517241379310345, "no_speech_prob": 4.46940612164326e-05}, {"id": 78, "seek": 46196, "start": 471.78, "end": 479.12, "text": " And because what we're basically trying to do is invert the embedding function, these", "tokens": [50855, 400, 570, 437, 321, 434, 1936, 1382, 281, 360, 307, 33966, 264, 12240, 3584, 2445, 11, 613, 51222], "temperature": 0.0, "avg_logprob": -0.26494348966158354, "compression_ratio": 1.5517241379310345, "no_speech_prob": 4.46940612164326e-05}, {"id": 79, "seek": 46196, "start": 479.12, "end": 485.08, "text": " kinds of problems are generally referred to as inverse problems.", "tokens": [51222, 3685, 295, 2740, 366, 5101, 10839, 281, 382, 17340, 2740, 13, 51520], "temperature": 0.0, "avg_logprob": -0.26494348966158354, "compression_ratio": 1.5517241379310345, "no_speech_prob": 4.46940612164326e-05}, {"id": 80, "seek": 48508, "start": 485.08, "end": 492.0, "text": " So stable diffusion is something that attempts to approximate the solution to an inverse", "tokens": [50364, 407, 8351, 25242, 307, 746, 300, 15257, 281, 30874, 264, 3827, 281, 364, 17340, 50710], "temperature": 0.0, "avg_logprob": -0.2249300479888916, "compression_ratio": 1.5545023696682465, "no_speech_prob": 5.920910552958958e-05}, {"id": 81, "seek": 48508, "start": 492.0, "end": 495.59999999999997, "text": " problem.", "tokens": [50710, 1154, 13, 50890], "temperature": 0.0, "avg_logprob": -0.2249300479888916, "compression_ratio": 1.5545023696682465, "no_speech_prob": 5.920910552958958e-05}, {"id": 82, "seek": 48508, "start": 495.59999999999997, "end": 503.47999999999996, "text": " So why does that mean that ClipInterrogator is not actually inverting the picture to give", "tokens": [50890, 407, 983, 775, 300, 914, 300, 2033, 647, 13406, 6675, 1639, 307, 406, 767, 28653, 783, 264, 3036, 281, 976, 51284], "temperature": 0.0, "avg_logprob": -0.2249300479888916, "compression_ratio": 1.5545023696682465, "no_speech_prob": 5.920910552958958e-05}, {"id": 83, "seek": 48508, "start": 503.47999999999996, "end": 505.15999999999997, "text": " us back the text?", "tokens": [51284, 505, 646, 264, 2487, 30, 51368], "temperature": 0.0, "avg_logprob": -0.2249300479888916, "compression_ratio": 1.5545023696682465, "no_speech_prob": 5.920910552958958e-05}, {"id": 84, "seek": 48508, "start": 505.15999999999997, "end": 507.18, "text": " Well it's just as nonsensical.", "tokens": [51368, 1042, 309, 311, 445, 382, 297, 892, 694, 804, 13, 51469], "temperature": 0.0, "avg_logprob": -0.2249300479888916, "compression_ratio": 1.5545023696682465, "no_speech_prob": 5.920910552958958e-05}, {"id": 85, "seek": 48508, "start": 507.18, "end": 514.3199999999999, "text": " If we've got an image embedding, right, trying to undo that to get back to the picture, and", "tokens": [51469, 759, 321, 600, 658, 364, 3256, 12240, 3584, 11, 558, 11, 1382, 281, 23779, 300, 281, 483, 646, 281, 264, 3036, 11, 293, 51826], "temperature": 0.0, "avg_logprob": -0.2249300479888916, "compression_ratio": 1.5545023696682465, "no_speech_prob": 5.920910552958958e-05}, {"id": 86, "seek": 51432, "start": 514.32, "end": 521.9200000000001, "text": " trying to undo that to get back to a suitable prompt, is equally infeasible.", "tokens": [50364, 1382, 281, 23779, 300, 281, 483, 646, 281, 257, 12873, 12391, 11, 307, 12309, 1536, 68, 296, 964, 13, 50744], "temperature": 0.0, "avg_logprob": -0.28209463755289715, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.4971080418035854e-05}, {"id": 87, "seek": 51432, "start": 521.9200000000001, "end": 526.6800000000001, "text": " Both of them require inverting an encoder.", "tokens": [50744, 6767, 295, 552, 3651, 28653, 783, 364, 2058, 19866, 13, 50982], "temperature": 0.0, "avg_logprob": -0.28209463755289715, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.4971080418035854e-05}, {"id": 88, "seek": 51432, "start": 526.6800000000001, "end": 528.48, "text": " And that just doesn't exist.", "tokens": [50982, 400, 300, 445, 1177, 380, 2514, 13, 51072], "temperature": 0.0, "avg_logprob": -0.28209463755289715, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.4971080418035854e-05}, {"id": 89, "seek": 51432, "start": 528.48, "end": 533.24, "text": " The best we can do is, or at least the best we know how to do at the moment, is to approximate", "tokens": [51072, 440, 1151, 321, 393, 360, 307, 11, 420, 412, 1935, 264, 1151, 321, 458, 577, 281, 360, 412, 264, 1623, 11, 307, 281, 30874, 51310], "temperature": 0.0, "avg_logprob": -0.28209463755289715, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.4971080418035854e-05}, {"id": 90, "seek": 51432, "start": 533.24, "end": 537.5200000000001, "text": " that using a diffusion process.", "tokens": [51310, 300, 1228, 257, 25242, 1399, 13, 51524], "temperature": 0.0, "avg_logprob": -0.28209463755289715, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.4971080418035854e-05}, {"id": 91, "seek": 53752, "start": 537.52, "end": 547.52, "text": " Okay, so that's why these texts that it spits back are fun and interesting, but they are", "tokens": [50364, 1033, 11, 370, 300, 311, 983, 613, 15765, 300, 309, 637, 1208, 646, 366, 1019, 293, 1880, 11, 457, 436, 366, 50864], "temperature": 0.0, "avg_logprob": -0.29194688143795483, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.0024343759287148714}, {"id": 92, "seek": 53752, "start": 547.52, "end": 554.4, "text": " not the thing that you can put back into stable diffusion and have it generate the same photo.", "tokens": [50864, 406, 264, 551, 300, 291, 393, 829, 646, 666, 8351, 25242, 293, 362, 309, 8460, 264, 912, 5052, 13, 51208], "temperature": 0.0, "avg_logprob": -0.29194688143795483, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.0024343759287148714}, {"id": 93, "seek": 53752, "start": 554.4, "end": 562.4399999999999, "text": " And the nice thing is that actually the code for this is available, and you can take a", "tokens": [51208, 400, 264, 1481, 551, 307, 300, 767, 264, 3089, 337, 341, 307, 2435, 11, 293, 291, 393, 747, 257, 51610], "temperature": 0.0, "avg_logprob": -0.29194688143795483, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.0024343759287148714}, {"id": 94, "seek": 53752, "start": 562.4399999999999, "end": 564.56, "text": " look at it.", "tokens": [51610, 574, 412, 309, 13, 51716], "temperature": 0.0, "avg_logprob": -0.29194688143795483, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.0024343759287148714}, {"id": 95, "seek": 56456, "start": 564.56, "end": 568.0799999999999, "text": " Here's the app.", "tokens": [50364, 1692, 311, 264, 724, 13, 50540], "temperature": 0.0, "avg_logprob": -0.30468908406920353, "compression_ratio": 1.5241935483870968, "no_speech_prob": 0.004264624323695898}, {"id": 96, "seek": 56456, "start": 568.0799999999999, "end": 580.52, "text": " And you'll see what it does is it has a big list of, let's have a look at some examples.", "tokens": [50540, 400, 291, 603, 536, 437, 309, 775, 307, 309, 575, 257, 955, 1329, 295, 11, 718, 311, 362, 257, 574, 412, 512, 5110, 13, 51162], "temperature": 0.0, "avg_logprob": -0.30468908406920353, "compression_ratio": 1.5241935483870968, "no_speech_prob": 0.004264624323695898}, {"id": 97, "seek": 56456, "start": 580.52, "end": 588.2399999999999, "text": " So it has a big, this has big lists of examples, for example, a big list of artists.", "tokens": [51162, 407, 309, 575, 257, 955, 11, 341, 575, 955, 14511, 295, 5110, 11, 337, 1365, 11, 257, 955, 1329, 295, 6910, 13, 51548], "temperature": 0.0, "avg_logprob": -0.30468908406920353, "compression_ratio": 1.5241935483870968, "no_speech_prob": 0.004264624323695898}, {"id": 98, "seek": 58824, "start": 588.24, "end": 598.84, "text": " And it has a big list of mediums, and a big list of movements, and so forth.", "tokens": [50364, 400, 309, 575, 257, 955, 1329, 295, 6399, 82, 11, 293, 257, 955, 1329, 295, 9981, 11, 293, 370, 5220, 13, 50894], "temperature": 0.0, "avg_logprob": -0.20365480943159622, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.00012533746485132724}, {"id": 99, "seek": 58824, "start": 598.84, "end": 603.52, "text": " It's got all this hard-coded pieces of text.", "tokens": [50894, 467, 311, 658, 439, 341, 1152, 12, 66, 12340, 3755, 295, 2487, 13, 51128], "temperature": 0.0, "avg_logprob": -0.20365480943159622, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.00012533746485132724}, {"id": 100, "seek": 58824, "start": 603.52, "end": 611.92, "text": " And so what it does is it basically mixes and matches those various things together", "tokens": [51128, 400, 370, 437, 309, 775, 307, 309, 1936, 37121, 293, 10676, 729, 3683, 721, 1214, 51548], "temperature": 0.0, "avg_logprob": -0.20365480943159622, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.00012533746485132724}, {"id": 101, "seek": 58824, "start": 611.92, "end": 614.24, "text": " to see which one works well.", "tokens": [51548, 281, 536, 597, 472, 1985, 731, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20365480943159622, "compression_ratio": 1.4904458598726114, "no_speech_prob": 0.00012533746485132724}, {"id": 102, "seek": 61424, "start": 614.24, "end": 620.4, "text": " And it combines it with the output of something called the Blip language model, which is not", "tokens": [50364, 400, 309, 29520, 309, 365, 264, 5598, 295, 746, 1219, 264, 363, 2081, 79, 2856, 2316, 11, 597, 307, 406, 50672], "temperature": 0.0, "avg_logprob": -0.29082815331148815, "compression_ratio": 1.5518867924528301, "no_speech_prob": 0.00021654393640346825}, {"id": 103, "seek": 61424, "start": 620.4, "end": 626.28, "text": " designed to give you an exactly accurate description of an image, but it has been specifically", "tokens": [50672, 4761, 281, 976, 291, 364, 2293, 8559, 3855, 295, 364, 3256, 11, 457, 309, 575, 668, 4682, 50966], "temperature": 0.0, "avg_logprob": -0.29082815331148815, "compression_ratio": 1.5518867924528301, "no_speech_prob": 0.00021654393640346825}, {"id": 104, "seek": 61424, "start": 626.28, "end": 631.36, "text": " trained to give an okay-ish caption for an image.", "tokens": [50966, 8895, 281, 976, 364, 1392, 12, 742, 31974, 337, 364, 3256, 13, 51220], "temperature": 0.0, "avg_logprob": -0.29082815331148815, "compression_ratio": 1.5518867924528301, "no_speech_prob": 0.00021654393640346825}, {"id": 105, "seek": 61424, "start": 631.36, "end": 632.96, "text": " And it actually works reasonably well.", "tokens": [51220, 400, 309, 767, 1985, 23551, 731, 13, 51300], "temperature": 0.0, "avg_logprob": -0.29082815331148815, "compression_ratio": 1.5518867924528301, "no_speech_prob": 0.00021654393640346825}, {"id": 106, "seek": 61424, "start": 632.96, "end": 639.28, "text": " But again, it's not the inverse of the Clip encoder.", "tokens": [51300, 583, 797, 11, 309, 311, 406, 264, 17340, 295, 264, 2033, 647, 2058, 19866, 13, 51616], "temperature": 0.0, "avg_logprob": -0.29082815331148815, "compression_ratio": 1.5518867924528301, "no_speech_prob": 0.00021654393640346825}, {"id": 107, "seek": 63928, "start": 639.28, "end": 652.9, "text": " So okay, so that's how that all works.", "tokens": [50364, 407, 1392, 11, 370, 300, 311, 577, 300, 439, 1985, 13, 51045], "temperature": 0.0, "avg_logprob": -0.2863495490130256, "compression_ratio": 1.2647058823529411, "no_speech_prob": 0.00046550267143175006}, {"id": 108, "seek": 63928, "start": 652.9, "end": 659.76, "text": " So where we had got to was that we had done matrix multiplication with broadcasting, where", "tokens": [51045, 407, 689, 321, 632, 658, 281, 390, 300, 321, 632, 1096, 8141, 27290, 365, 30024, 11, 689, 51388], "temperature": 0.0, "avg_logprob": -0.2863495490130256, "compression_ratio": 1.2647058823529411, "no_speech_prob": 0.00046550267143175006}, {"id": 109, "seek": 65976, "start": 659.76, "end": 672.6, "text": " we had broadcast the entire column from the right-hand matrix all at once.", "tokens": [50364, 321, 632, 9975, 264, 2302, 7738, 490, 264, 558, 12, 5543, 8141, 439, 412, 1564, 13, 51006], "temperature": 0.0, "avg_logprob": -0.2643556594848633, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.001524750841781497}, {"id": 110, "seek": 65976, "start": 672.6, "end": 676.8199999999999, "text": " And that allowed us to get it down to a point where we only have one for loop written in", "tokens": [51006, 400, 300, 4350, 505, 281, 483, 309, 760, 281, 257, 935, 689, 321, 787, 362, 472, 337, 6367, 3720, 294, 51217], "temperature": 0.0, "avg_logprob": -0.2643556594848633, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.001524750841781497}, {"id": 111, "seek": 65976, "start": 676.8199999999999, "end": 678.4399999999999, "text": " Python.", "tokens": [51217, 15329, 13, 51298], "temperature": 0.0, "avg_logprob": -0.2643556594848633, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.001524750841781497}, {"id": 112, "seek": 65976, "start": 678.4399999999999, "end": 684.2, "text": " And generally speaking, we do not want to be looping through too many things in Python,", "tokens": [51298, 400, 5101, 4124, 11, 321, 360, 406, 528, 281, 312, 6367, 278, 807, 886, 867, 721, 294, 15329, 11, 51586], "temperature": 0.0, "avg_logprob": -0.2643556594848633, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.001524750841781497}, {"id": 113, "seek": 65976, "start": 684.2, "end": 685.58, "text": " because that's a slow bit.", "tokens": [51586, 570, 300, 311, 257, 2964, 857, 13, 51655], "temperature": 0.0, "avg_logprob": -0.2643556594848633, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.001524750841781497}, {"id": 114, "seek": 68558, "start": 685.58, "end": 695.4000000000001, "text": " So the two inner loops we originally had, which just to remind us, originally were here.", "tokens": [50364, 407, 264, 732, 7284, 16121, 321, 7993, 632, 11, 597, 445, 281, 4160, 505, 11, 7993, 645, 510, 13, 50855], "temperature": 0.0, "avg_logprob": -0.30807384691740336, "compression_ratio": 1.482233502538071, "no_speech_prob": 0.00023782142670825124}, {"id": 115, "seek": 68558, "start": 695.4000000000001, "end": 702.1600000000001, "text": " These two inner loops, looping through 10 and then to 784 respectively, have been replaced", "tokens": [50855, 1981, 732, 7284, 16121, 11, 6367, 278, 807, 1266, 293, 550, 281, 1614, 25494, 25009, 11, 362, 668, 10772, 51193], "temperature": 0.0, "avg_logprob": -0.30807384691740336, "compression_ratio": 1.482233502538071, "no_speech_prob": 0.00023782142670825124}, {"id": 116, "seek": 68558, "start": 702.1600000000001, "end": 705.2, "text": " with a single line of code.", "tokens": [51193, 365, 257, 2167, 1622, 295, 3089, 13, 51345], "temperature": 0.0, "avg_logprob": -0.30807384691740336, "compression_ratio": 1.482233502538071, "no_speech_prob": 0.00023782142670825124}, {"id": 117, "seek": 68558, "start": 705.2, "end": 706.6, "text": " So that was pretty great.", "tokens": [51345, 407, 300, 390, 1238, 869, 13, 51415], "temperature": 0.0, "avg_logprob": -0.30807384691740336, "compression_ratio": 1.482233502538071, "no_speech_prob": 0.00023782142670825124}, {"id": 118, "seek": 68558, "start": 706.6, "end": 710.72, "text": " And our times now is increased, is improved by 5000 times.", "tokens": [51415, 400, 527, 1413, 586, 307, 6505, 11, 307, 9689, 538, 23777, 1413, 13, 51621], "temperature": 0.0, "avg_logprob": -0.30807384691740336, "compression_ratio": 1.482233502538071, "no_speech_prob": 0.00023782142670825124}, {"id": 119, "seek": 71072, "start": 710.72, "end": 716.46, "text": " So we're 5000 times faster than we started out.", "tokens": [50364, 407, 321, 434, 23777, 1413, 4663, 813, 321, 1409, 484, 13, 50651], "temperature": 0.0, "avg_logprob": -0.22240736905266256, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.00017952760390471667}, {"id": 120, "seek": 71072, "start": 716.46, "end": 721.78, "text": " So another trick that we can use, which I'm a big fan of, is something called Einstein", "tokens": [50651, 407, 1071, 4282, 300, 321, 393, 764, 11, 597, 286, 478, 257, 955, 3429, 295, 11, 307, 746, 1219, 23486, 50917], "temperature": 0.0, "avg_logprob": -0.22240736905266256, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.00017952760390471667}, {"id": 121, "seek": 71072, "start": 721.78, "end": 723.6600000000001, "text": " summation.", "tokens": [50917, 28811, 13, 51011], "temperature": 0.0, "avg_logprob": -0.22240736905266256, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.00017952760390471667}, {"id": 122, "seek": 71072, "start": 723.6600000000001, "end": 734.14, "text": " And Einstein summation is a compact representation for representing products and sums.", "tokens": [51011, 400, 23486, 28811, 307, 257, 14679, 10290, 337, 13460, 3383, 293, 34499, 13, 51535], "temperature": 0.0, "avg_logprob": -0.22240736905266256, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.00017952760390471667}, {"id": 123, "seek": 71072, "start": 734.14, "end": 739.2, "text": " And this is an example of an Einstein summation.", "tokens": [51535, 400, 341, 307, 364, 1365, 295, 364, 23486, 28811, 13, 51788], "temperature": 0.0, "avg_logprob": -0.22240736905266256, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.00017952760390471667}, {"id": 124, "seek": 73920, "start": 739.22, "end": 744.22, "text": " And what we're going to do now is we're going to replicate our matrix product with an Einstein", "tokens": [50365, 400, 437, 321, 434, 516, 281, 360, 586, 307, 321, 434, 516, 281, 25356, 527, 8141, 1674, 365, 364, 23486, 50615], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 125, "seek": 73920, "start": 744.22, "end": 745.22, "text": " summation.", "tokens": [50615, 28811, 13, 50665], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 126, "seek": 73920, "start": 745.22, "end": 750.9000000000001, "text": " And believe it or not, the entire thing can be pushed down to just these characters, which", "tokens": [50665, 400, 1697, 309, 420, 406, 11, 264, 2302, 551, 393, 312, 9152, 760, 281, 445, 613, 4342, 11, 597, 50949], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 127, "seek": 73920, "start": 750.9000000000001, "end": 752.24, "text": " is pretty amazing.", "tokens": [50949, 307, 1238, 2243, 13, 51016], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 128, "seek": 73920, "start": 752.24, "end": 754.38, "text": " So let me explain what's happening here.", "tokens": [51016, 407, 718, 385, 2903, 437, 311, 2737, 510, 13, 51123], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 129, "seek": 73920, "start": 754.38, "end": 759.0, "text": " The arrow is separating the left-hand side from the right-hand side.", "tokens": [51123, 440, 11610, 307, 29279, 264, 1411, 12, 5543, 1252, 490, 264, 558, 12, 5543, 1252, 13, 51354], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 130, "seek": 73920, "start": 759.0, "end": 761.5600000000001, "text": " The left-hand side is the inputs.", "tokens": [51354, 440, 1411, 12, 5543, 1252, 307, 264, 15743, 13, 51482], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 131, "seek": 73920, "start": 761.5600000000001, "end": 763.98, "text": " The right-hand side is the output.", "tokens": [51482, 440, 558, 12, 5543, 1252, 307, 264, 5598, 13, 51603], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 132, "seek": 73920, "start": 763.98, "end": 765.84, "text": " The comma is between each input.", "tokens": [51603, 440, 22117, 307, 1296, 1184, 4846, 13, 51696], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 133, "seek": 73920, "start": 765.84, "end": 768.12, "text": " So there are two inputs.", "tokens": [51696, 407, 456, 366, 732, 15743, 13, 51810], "temperature": 0.0, "avg_logprob": -0.23001371554242886, "compression_ratio": 1.7587548638132295, "no_speech_prob": 3.9442587876692414e-05}, {"id": 134, "seek": 76812, "start": 768.12, "end": 773.42, "text": " The letters are just names that you're giving to the number of rows and the number of columns.", "tokens": [50364, 440, 7825, 366, 445, 5288, 300, 291, 434, 2902, 281, 264, 1230, 295, 13241, 293, 264, 1230, 295, 13766, 13, 50629], "temperature": 0.0, "avg_logprob": -0.22155637239155015, "compression_ratio": 1.784688995215311, "no_speech_prob": 3.156125956138567e-07}, {"id": 135, "seek": 76812, "start": 773.42, "end": 781.28, "text": " So the first matrix we're multiplying by has i rows and k columns.", "tokens": [50629, 407, 264, 700, 8141, 321, 434, 30955, 538, 575, 741, 13241, 293, 350, 13766, 13, 51022], "temperature": 0.0, "avg_logprob": -0.22155637239155015, "compression_ratio": 1.784688995215311, "no_speech_prob": 3.156125956138567e-07}, {"id": 136, "seek": 76812, "start": 781.28, "end": 787.0, "text": " The second has k rows and j columns.", "tokens": [51022, 440, 1150, 575, 350, 13241, 293, 361, 13766, 13, 51308], "temperature": 0.0, "avg_logprob": -0.22155637239155015, "compression_ratio": 1.784688995215311, "no_speech_prob": 3.156125956138567e-07}, {"id": 137, "seek": 76812, "start": 787.0, "end": 792.2, "text": " It's going to go through a process which creates a new matrix.", "tokens": [51308, 467, 311, 516, 281, 352, 807, 257, 1399, 597, 7829, 257, 777, 8141, 13, 51568], "temperature": 0.0, "avg_logprob": -0.22155637239155015, "compression_ratio": 1.784688995215311, "no_speech_prob": 3.156125956138567e-07}, {"id": 138, "seek": 76812, "start": 792.2, "end": 796.16, "text": " That actually this is not even doing, this is not yet doing the matrix multiplication.", "tokens": [51568, 663, 767, 341, 307, 406, 754, 884, 11, 341, 307, 406, 1939, 884, 264, 8141, 27290, 13, 51766], "temperature": 0.0, "avg_logprob": -0.22155637239155015, "compression_ratio": 1.784688995215311, "no_speech_prob": 3.156125956138567e-07}, {"id": 139, "seek": 76812, "start": 796.16, "end": 797.38, "text": " This is without the sum.", "tokens": [51766, 639, 307, 1553, 264, 2408, 13, 51827], "temperature": 0.0, "avg_logprob": -0.22155637239155015, "compression_ratio": 1.784688995215311, "no_speech_prob": 3.156125956138567e-07}, {"id": 140, "seek": 79738, "start": 797.64, "end": 803.14, "text": " This one's going to create a new matrix that contains i rows and k, well how do we say", "tokens": [50377, 639, 472, 311, 516, 281, 1884, 257, 777, 8141, 300, 8306, 741, 13241, 293, 350, 11, 731, 577, 360, 321, 584, 50652], "temperature": 0.0, "avg_logprob": -0.28474065992567277, "compression_ratio": 1.6298076923076923, "no_speech_prob": 1.9525883544702083e-05}, {"id": 141, "seek": 79738, "start": 803.14, "end": 807.66, "text": " it, i faces and k rows and j columns.", "tokens": [50652, 309, 11, 741, 8475, 293, 350, 13241, 293, 361, 13766, 13, 50878], "temperature": 0.0, "avg_logprob": -0.28474065992567277, "compression_ratio": 1.6298076923076923, "no_speech_prob": 1.9525883544702083e-05}, {"id": 142, "seek": 79738, "start": 807.66, "end": 809.12, "text": " So a rank 3 tensor.", "tokens": [50878, 407, 257, 6181, 805, 40863, 13, 50951], "temperature": 0.0, "avg_logprob": -0.28474065992567277, "compression_ratio": 1.6298076923076923, "no_speech_prob": 1.9525883544702083e-05}, {"id": 143, "seek": 79738, "start": 809.12, "end": 815.02, "text": " So the number of letters is going to be the rank.", "tokens": [50951, 407, 264, 1230, 295, 7825, 307, 516, 281, 312, 264, 6181, 13, 51246], "temperature": 0.0, "avg_logprob": -0.28474065992567277, "compression_ratio": 1.6298076923076923, "no_speech_prob": 1.9525883544702083e-05}, {"id": 144, "seek": 79738, "start": 815.02, "end": 820.46, "text": " And the rules of how this works is that if you repeat letters between input arrays, so", "tokens": [51246, 400, 264, 4474, 295, 577, 341, 1985, 307, 300, 498, 291, 7149, 7825, 1296, 4846, 41011, 11, 370, 51518], "temperature": 0.0, "avg_logprob": -0.28474065992567277, "compression_ratio": 1.6298076923076923, "no_speech_prob": 1.9525883544702083e-05}, {"id": 145, "seek": 79738, "start": 820.46, "end": 825.38, "text": " here's my inputs, ik and kj, we've got a repeated letter.", "tokens": [51518, 510, 311, 452, 15743, 11, 4320, 293, 350, 73, 11, 321, 600, 658, 257, 10477, 5063, 13, 51764], "temperature": 0.0, "avg_logprob": -0.28474065992567277, "compression_ratio": 1.6298076923076923, "no_speech_prob": 1.9525883544702083e-05}, {"id": 146, "seek": 82538, "start": 825.38, "end": 830.14, "text": " It means that values along those axes will be multiplied together.", "tokens": [50364, 467, 1355, 300, 4190, 2051, 729, 35387, 486, 312, 17207, 1214, 13, 50602], "temperature": 0.0, "avg_logprob": -0.23692980266752697, "compression_ratio": 1.5392670157068062, "no_speech_prob": 2.2252811504586134e-06}, {"id": 147, "seek": 82538, "start": 830.14, "end": 838.9, "text": " So it means that each item in each row of, sorry, in each, yeah, across a row will be", "tokens": [50602, 407, 309, 1355, 300, 1184, 3174, 294, 1184, 5386, 295, 11, 2597, 11, 294, 1184, 11, 1338, 11, 2108, 257, 5386, 486, 312, 51040], "temperature": 0.0, "avg_logprob": -0.23692980266752697, "compression_ratio": 1.5392670157068062, "no_speech_prob": 2.2252811504586134e-06}, {"id": 148, "seek": 82538, "start": 838.9, "end": 848.4399999999999, "text": " multiplied by each item down each column to create this i by k by j output tensor.", "tokens": [51040, 17207, 538, 1184, 3174, 760, 1184, 7738, 281, 1884, 341, 741, 538, 350, 538, 361, 5598, 40863, 13, 51517], "temperature": 0.0, "avg_logprob": -0.23692980266752697, "compression_ratio": 1.5392670157068062, "no_speech_prob": 2.2252811504586134e-06}, {"id": 149, "seek": 82538, "start": 848.4399999999999, "end": 853.22, "text": " So to remind you, our first matrix is 5 by 784.", "tokens": [51517, 407, 281, 4160, 291, 11, 527, 700, 8141, 307, 1025, 538, 1614, 25494, 13, 51756], "temperature": 0.0, "avg_logprob": -0.23692980266752697, "compression_ratio": 1.5392670157068062, "no_speech_prob": 2.2252811504586134e-06}, {"id": 150, "seek": 82538, "start": 853.22, "end": 854.22, "text": " That's M1.", "tokens": [51756, 663, 311, 376, 16, 13, 51806], "temperature": 0.0, "avg_logprob": -0.23692980266752697, "compression_ratio": 1.5392670157068062, "no_speech_prob": 2.2252811504586134e-06}, {"id": 151, "seek": 85422, "start": 854.58, "end": 857.78, "text": " Our second matrix is 7084 by 10.", "tokens": [50382, 2621, 1150, 8141, 307, 5285, 25494, 538, 1266, 13, 50542], "temperature": 0.0, "avg_logprob": -0.293740971883138, "compression_ratio": 1.2391304347826086, "no_speech_prob": 1.0129982001672033e-05}, {"id": 152, "seek": 85422, "start": 857.78, "end": 858.78, "text": " That's M2.", "tokens": [50542, 663, 311, 376, 17, 13, 50592], "temperature": 0.0, "avg_logprob": -0.293740971883138, "compression_ratio": 1.2391304347826086, "no_speech_prob": 1.0129982001672033e-05}, {"id": 153, "seek": 85422, "start": 858.78, "end": 868.22, "text": " So i is 5, k is 784, and j is 10.", "tokens": [50592, 407, 741, 307, 1025, 11, 350, 307, 1614, 25494, 11, 293, 361, 307, 1266, 13, 51064], "temperature": 0.0, "avg_logprob": -0.293740971883138, "compression_ratio": 1.2391304347826086, "no_speech_prob": 1.0129982001672033e-05}, {"id": 154, "seek": 85422, "start": 868.22, "end": 876.1800000000001, "text": " So if I do this torch.einsum, then I will end up with a i by k by j.", "tokens": [51064, 407, 498, 286, 360, 341, 27822, 13, 68, 1292, 449, 11, 550, 286, 486, 917, 493, 365, 257, 741, 538, 350, 538, 361, 13, 51462], "temperature": 0.0, "avg_logprob": -0.293740971883138, "compression_ratio": 1.2391304347826086, "no_speech_prob": 1.0129982001672033e-05}, {"id": 155, "seek": 85422, "start": 876.1800000000001, "end": 879.36, "text": " It'll be 5 by 784 by 10.", "tokens": [51462, 467, 603, 312, 1025, 538, 1614, 25494, 538, 1266, 13, 51621], "temperature": 0.0, "avg_logprob": -0.293740971883138, "compression_ratio": 1.2391304347826086, "no_speech_prob": 1.0129982001672033e-05}, {"id": 156, "seek": 87936, "start": 879.4, "end": 884.44, "text": " If you have a look, I've run it here on these two tensors, M1 and M2, and the shape of the", "tokens": [50366, 759, 291, 362, 257, 574, 11, 286, 600, 1190, 309, 510, 322, 613, 732, 10688, 830, 11, 376, 16, 293, 376, 17, 11, 293, 264, 3909, 295, 264, 50618], "temperature": 0.0, "avg_logprob": -0.21376237101938533, "compression_ratio": 1.4948453608247423, "no_speech_prob": 0.0028448926750570536}, {"id": 157, "seek": 87936, "start": 884.44, "end": 888.92, "text": " result is 5 by 784 by 10.", "tokens": [50618, 1874, 307, 1025, 538, 1614, 25494, 538, 1266, 13, 50842], "temperature": 0.0, "avg_logprob": -0.21376237101938533, "compression_ratio": 1.4948453608247423, "no_speech_prob": 0.0028448926750570536}, {"id": 158, "seek": 87936, "start": 888.92, "end": 897.64, "text": " And what it contains is the original five rows of M1, the original 10 columns of M2,", "tokens": [50842, 400, 437, 309, 8306, 307, 264, 3380, 1732, 13241, 295, 376, 16, 11, 264, 3380, 1266, 13766, 295, 376, 17, 11, 51278], "temperature": 0.0, "avg_logprob": -0.21376237101938533, "compression_ratio": 1.4948453608247423, "no_speech_prob": 0.0028448926750570536}, {"id": 159, "seek": 87936, "start": 897.64, "end": 902.84, "text": " and then for the other 784, that dimension, they're all multiplied together because it's", "tokens": [51278, 293, 550, 337, 264, 661, 1614, 25494, 11, 300, 10139, 11, 436, 434, 439, 17207, 1214, 570, 309, 311, 51538], "temperature": 0.0, "avg_logprob": -0.21376237101938533, "compression_ratio": 1.4948453608247423, "no_speech_prob": 0.0028448926750570536}, {"id": 160, "seek": 90284, "start": 902.84, "end": 911.52, "text": " been copied between the two arguments to the einsum.", "tokens": [50364, 668, 25365, 1296, 264, 732, 12869, 281, 264, 308, 1292, 449, 13, 50798], "temperature": 0.0, "avg_logprob": -0.30988874435424807, "compression_ratio": 1.4097222222222223, "no_speech_prob": 9.028030035551637e-05}, {"id": 161, "seek": 90284, "start": 911.52, "end": 923.12, "text": " And so if we now sum up that over this dimension, we get back.", "tokens": [50798, 400, 370, 498, 321, 586, 2408, 493, 300, 670, 341, 10139, 11, 321, 483, 646, 13, 51378], "temperature": 0.0, "avg_logprob": -0.30988874435424807, "compression_ratio": 1.4097222222222223, "no_speech_prob": 9.028030035551637e-05}, {"id": 162, "seek": 90284, "start": 923.12, "end": 929.44, "text": " So what we get back, if we go back to the original matrix multiply we do, we had 10.94,", "tokens": [51378, 407, 437, 321, 483, 646, 11, 498, 321, 352, 646, 281, 264, 3380, 8141, 12972, 321, 360, 11, 321, 632, 1266, 13, 27032, 11, 51694], "temperature": 0.0, "avg_logprob": -0.30988874435424807, "compression_ratio": 1.4097222222222223, "no_speech_prob": 9.028030035551637e-05}, {"id": 163, "seek": 92944, "start": 929.44, "end": 933.72, "text": " negative, negative .68, etc.", "tokens": [50364, 3671, 11, 3671, 2411, 27102, 11, 5183, 13, 50578], "temperature": 0.0, "avg_logprob": -0.26294809121351975, "compression_ratio": 1.342281879194631, "no_speech_prob": 0.0005703154020011425}, {"id": 164, "seek": 92944, "start": 933.72, "end": 944.84, "text": " And so now with this Einstein summation version, we've got back exactly the same thing.", "tokens": [50578, 400, 370, 586, 365, 341, 23486, 28811, 3037, 11, 321, 600, 658, 646, 2293, 264, 912, 551, 13, 51134], "temperature": 0.0, "avg_logprob": -0.26294809121351975, "compression_ratio": 1.342281879194631, "no_speech_prob": 0.0005703154020011425}, {"id": 165, "seek": 92944, "start": 944.84, "end": 952.8800000000001, "text": " Because what it's done is it's taken each of these columns by rows, multiplied them", "tokens": [51134, 1436, 437, 309, 311, 1096, 307, 309, 311, 2726, 1184, 295, 613, 13766, 538, 13241, 11, 17207, 552, 51536], "temperature": 0.0, "avg_logprob": -0.26294809121351975, "compression_ratio": 1.342281879194631, "no_speech_prob": 0.0005703154020011425}, {"id": 166, "seek": 95288, "start": 952.88, "end": 960.0, "text": " together to get this 5 by 784 by 10, and then added up that 784 for each one, which", "tokens": [50364, 1214, 281, 483, 341, 1025, 538, 1614, 25494, 538, 1266, 11, 293, 550, 3869, 493, 300, 1614, 25494, 337, 1184, 472, 11, 597, 50720], "temperature": 0.0, "avg_logprob": -0.24456026289198135, "compression_ratio": 1.5, "no_speech_prob": 0.002359657548367977}, {"id": 167, "seek": 95288, "start": 960.0, "end": 963.88, "text": " is exactly what matrix multiplication does.", "tokens": [50720, 307, 2293, 437, 8141, 27290, 775, 13, 50914], "temperature": 0.0, "avg_logprob": -0.24456026289198135, "compression_ratio": 1.5, "no_speech_prob": 0.002359657548367977}, {"id": 168, "seek": 95288, "start": 963.88, "end": 967.38, "text": " But we're going to use one of the two things from Einstein summation.", "tokens": [50914, 583, 321, 434, 516, 281, 764, 472, 295, 264, 732, 721, 490, 23486, 28811, 13, 51089], "temperature": 0.0, "avg_logprob": -0.24456026289198135, "compression_ratio": 1.5, "no_speech_prob": 0.002359657548367977}, {"id": 169, "seek": 95288, "start": 967.38, "end": 972.32, "text": " The second one says if we omit a letter from the output, so the bit on the right of the", "tokens": [51089, 440, 1150, 472, 1619, 498, 321, 3406, 270, 257, 5063, 490, 264, 5598, 11, 370, 264, 857, 322, 264, 558, 295, 264, 51336], "temperature": 0.0, "avg_logprob": -0.24456026289198135, "compression_ratio": 1.5, "no_speech_prob": 0.002359657548367977}, {"id": 170, "seek": 95288, "start": 972.32, "end": 976.92, "text": " arrow, it means those values will be summed.", "tokens": [51336, 11610, 11, 309, 1355, 729, 4190, 486, 312, 2408, 1912, 13, 51566], "temperature": 0.0, "avg_logprob": -0.24456026289198135, "compression_ratio": 1.5, "no_speech_prob": 0.002359657548367977}, {"id": 171, "seek": 97692, "start": 976.92, "end": 986.88, "text": " So if we remove this k, which gives us ik and kj goes to ij, so we've removed the k", "tokens": [50364, 407, 498, 321, 4159, 341, 350, 11, 597, 2709, 505, 4320, 293, 350, 73, 1709, 281, 741, 73, 11, 370, 321, 600, 7261, 264, 350, 50862], "temperature": 0.0, "avg_logprob": -0.2480267831834696, "compression_ratio": 1.4246575342465753, "no_speech_prob": 0.00020027279970236123}, {"id": 172, "seek": 97692, "start": 986.88, "end": 990.9599999999999, "text": " entirely, that means that sum happens automatically.", "tokens": [50862, 7696, 11, 300, 1355, 300, 2408, 2314, 6772, 13, 51066], "temperature": 0.0, "avg_logprob": -0.2480267831834696, "compression_ratio": 1.4246575342465753, "no_speech_prob": 0.00020027279970236123}, {"id": 173, "seek": 97692, "start": 990.9599999999999, "end": 997.4399999999999, "text": " So if we run this, as you see, we get back again matrix multiplication.", "tokens": [51066, 407, 498, 321, 1190, 341, 11, 382, 291, 536, 11, 321, 483, 646, 797, 8141, 27290, 13, 51390], "temperature": 0.0, "avg_logprob": -0.2480267831834696, "compression_ratio": 1.4246575342465753, "no_speech_prob": 0.00020027279970236123}, {"id": 174, "seek": 99744, "start": 997.44, "end": 1007.0400000000001, "text": " So Einstein summation notation is, you know, it takes some practice getting used to, but", "tokens": [50364, 407, 23486, 28811, 24657, 307, 11, 291, 458, 11, 309, 2516, 512, 3124, 1242, 1143, 281, 11, 457, 50844], "temperature": 0.0, "avg_logprob": -0.2276887610407159, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005792859592474997}, {"id": 175, "seek": 99744, "start": 1007.0400000000001, "end": 1008.9200000000001, "text": " it's very convenient.", "tokens": [50844, 309, 311, 588, 10851, 13, 50938], "temperature": 0.0, "avg_logprob": -0.2276887610407159, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005792859592474997}, {"id": 176, "seek": 99744, "start": 1008.9200000000001, "end": 1012.32, "text": " And once you get used to it, it's actually a really nice way of thinking about what's", "tokens": [50938, 400, 1564, 291, 483, 1143, 281, 309, 11, 309, 311, 767, 257, 534, 1481, 636, 295, 1953, 466, 437, 311, 51108], "temperature": 0.0, "avg_logprob": -0.2276887610407159, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005792859592474997}, {"id": 177, "seek": 99744, "start": 1012.32, "end": 1013.32, "text": " going on.", "tokens": [51108, 516, 322, 13, 51158], "temperature": 0.0, "avg_logprob": -0.2276887610407159, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005792859592474997}, {"id": 178, "seek": 99744, "start": 1013.32, "end": 1019.9200000000001, "text": " And as we'll see in lots of examples, often you can really simplify your code by using", "tokens": [51158, 400, 382, 321, 603, 536, 294, 3195, 295, 5110, 11, 2049, 291, 393, 534, 20460, 428, 3089, 538, 1228, 51488], "temperature": 0.0, "avg_logprob": -0.2276887610407159, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005792859592474997}, {"id": 179, "seek": 99744, "start": 1019.9200000000001, "end": 1023.48, "text": " just a tiny little Einstein summation.", "tokens": [51488, 445, 257, 5870, 707, 23486, 28811, 13, 51666], "temperature": 0.0, "avg_logprob": -0.2276887610407159, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005792859592474997}, {"id": 180, "seek": 99744, "start": 1023.48, "end": 1025.52, "text": " And it doesn't even have to be a sum, right?", "tokens": [51666, 400, 309, 1177, 380, 754, 362, 281, 312, 257, 2408, 11, 558, 30, 51768], "temperature": 0.0, "avg_logprob": -0.2276887610407159, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0005792859592474997}, {"id": 181, "seek": 102552, "start": 1025.6, "end": 1029.92, "text": " You don't have to omit any letters if you're just doing products.", "tokens": [50368, 509, 500, 380, 362, 281, 3406, 270, 604, 7825, 498, 291, 434, 445, 884, 3383, 13, 50584], "temperature": 0.0, "avg_logprob": -0.2854070456131645, "compression_ratio": 1.465, "no_speech_prob": 0.0002824077382683754}, {"id": 182, "seek": 102552, "start": 1029.92, "end": 1032.98, "text": " So maybe it's a bit misnamed.", "tokens": [50584, 407, 1310, 309, 311, 257, 857, 3346, 33465, 13, 50737], "temperature": 0.0, "avg_logprob": -0.2854070456131645, "compression_ratio": 1.465, "no_speech_prob": 0.0002824077382683754}, {"id": 183, "seek": 102552, "start": 1032.98, "end": 1039.52, "text": " So we can now define our matmul as simply this torch.unsum.", "tokens": [50737, 407, 321, 393, 586, 6964, 527, 3803, 76, 425, 382, 2935, 341, 27822, 13, 26684, 449, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2854070456131645, "compression_ratio": 1.465, "no_speech_prob": 0.0002824077382683754}, {"id": 184, "seek": 102552, "start": 1039.52, "end": 1046.52, "text": " So if we now check it, test close that the original result is equal to this new matmul,", "tokens": [51064, 407, 498, 321, 586, 1520, 309, 11, 1500, 1998, 300, 264, 3380, 1874, 307, 2681, 281, 341, 777, 3803, 76, 425, 11, 51414], "temperature": 0.0, "avg_logprob": -0.2854070456131645, "compression_ratio": 1.465, "no_speech_prob": 0.0002824077382683754}, {"id": 185, "seek": 102552, "start": 1046.52, "end": 1048.2, "text": " and yes it is.", "tokens": [51414, 293, 2086, 309, 307, 13, 51498], "temperature": 0.0, "avg_logprob": -0.2854070456131645, "compression_ratio": 1.465, "no_speech_prob": 0.0002824077382683754}, {"id": 186, "seek": 102552, "start": 1048.2, "end": 1050.52, "text": " And let's see how the speed looks.", "tokens": [51498, 400, 718, 311, 536, 577, 264, 3073, 1542, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2854070456131645, "compression_ratio": 1.465, "no_speech_prob": 0.0002824077382683754}, {"id": 187, "seek": 105052, "start": 1050.52, "end": 1055.8, "text": " 15 milliseconds.", "tokens": [50364, 2119, 34184, 13, 50628], "temperature": 0.0, "avg_logprob": -0.3205775357364269, "compression_ratio": 1.541062801932367, "no_speech_prob": 4.985952909919433e-05}, {"id": 188, "seek": 105052, "start": 1055.8, "end": 1061.24, "text": " Okay and that was for the whole thing.", "tokens": [50628, 1033, 293, 300, 390, 337, 264, 1379, 551, 13, 50900], "temperature": 0.0, "avg_logprob": -0.3205775357364269, "compression_ratio": 1.541062801932367, "no_speech_prob": 4.985952909919433e-05}, {"id": 189, "seek": 105052, "start": 1061.24, "end": 1062.92, "text": " So compared to 600 milliseconds.", "tokens": [50900, 407, 5347, 281, 11849, 34184, 13, 50984], "temperature": 0.0, "avg_logprob": -0.3205775357364269, "compression_ratio": 1.541062801932367, "no_speech_prob": 4.985952909919433e-05}, {"id": 190, "seek": 105052, "start": 1062.92, "end": 1068.04, "text": " So as you can see, this is much faster than even the very fast broadcasting approach we", "tokens": [50984, 407, 382, 291, 393, 536, 11, 341, 307, 709, 4663, 813, 754, 264, 588, 2370, 30024, 3109, 321, 51240], "temperature": 0.0, "avg_logprob": -0.3205775357364269, "compression_ratio": 1.541062801932367, "no_speech_prob": 4.985952909919433e-05}, {"id": 191, "seek": 105052, "start": 1068.04, "end": 1069.04, "text": " used.", "tokens": [51240, 1143, 13, 51290], "temperature": 0.0, "avg_logprob": -0.3205775357364269, "compression_ratio": 1.541062801932367, "no_speech_prob": 4.985952909919433e-05}, {"id": 192, "seek": 105052, "start": 1069.04, "end": 1075.8799999999999, "text": " So this is a pretty good trick, is torch.unsum.", "tokens": [51290, 407, 341, 307, 257, 1238, 665, 4282, 11, 307, 27822, 13, 26684, 449, 13, 51632], "temperature": 0.0, "avg_logprob": -0.3205775357364269, "compression_ratio": 1.541062801932367, "no_speech_prob": 4.985952909919433e-05}, {"id": 193, "seek": 105052, "start": 1075.8799999999999, "end": 1079.08, "text": " Okay but of course we don't have to do any of those things because PyTorch already knows", "tokens": [51632, 1033, 457, 295, 1164, 321, 500, 380, 362, 281, 360, 604, 295, 729, 721, 570, 9953, 51, 284, 339, 1217, 3255, 51792], "temperature": 0.0, "avg_logprob": -0.3205775357364269, "compression_ratio": 1.541062801932367, "no_speech_prob": 4.985952909919433e-05}, {"id": 194, "seek": 107908, "start": 1079.08, "end": 1080.84, "text": " how to do matmul.", "tokens": [50364, 577, 281, 360, 3803, 76, 425, 13, 50452], "temperature": 0.0, "avg_logprob": -0.25214022296970173, "compression_ratio": 1.75, "no_speech_prob": 9.46125655900687e-05}, {"id": 195, "seek": 107908, "start": 1080.84, "end": 1085.9199999999998, "text": " So there's two ways we can run matmul directly in PyTorch.", "tokens": [50452, 407, 456, 311, 732, 2098, 321, 393, 1190, 3803, 76, 425, 3838, 294, 9953, 51, 284, 339, 13, 50706], "temperature": 0.0, "avg_logprob": -0.25214022296970173, "compression_ratio": 1.75, "no_speech_prob": 9.46125655900687e-05}, {"id": 196, "seek": 107908, "start": 1085.9199999999998, "end": 1088.48, "text": " You can use this special at operator.", "tokens": [50706, 509, 393, 764, 341, 2121, 412, 12973, 13, 50834], "temperature": 0.0, "avg_logprob": -0.25214022296970173, "compression_ratio": 1.75, "no_speech_prob": 9.46125655900687e-05}, {"id": 197, "seek": 107908, "start": 1088.48, "end": 1095.1999999999998, "text": " So xtrain at weights is the same as matmul train, weights as you see, test close.", "tokens": [50834, 407, 2031, 83, 7146, 412, 17443, 307, 264, 912, 382, 3803, 76, 425, 3847, 11, 17443, 382, 291, 536, 11, 1500, 1998, 13, 51170], "temperature": 0.0, "avg_logprob": -0.25214022296970173, "compression_ratio": 1.75, "no_speech_prob": 9.46125655900687e-05}, {"id": 198, "seek": 107908, "start": 1095.1999999999998, "end": 1098.08, "text": " Or you can say torch.matmul.", "tokens": [51170, 1610, 291, 393, 584, 27822, 13, 15677, 76, 425, 13, 51314], "temperature": 0.0, "avg_logprob": -0.25214022296970173, "compression_ratio": 1.75, "no_speech_prob": 9.46125655900687e-05}, {"id": 199, "seek": 107908, "start": 1098.08, "end": 1104.12, "text": " And interestingly as you can see here, the speed is about the same as the unsum.", "tokens": [51314, 400, 25873, 382, 291, 393, 536, 510, 11, 264, 3073, 307, 466, 264, 912, 382, 264, 2693, 449, 13, 51616], "temperature": 0.0, "avg_logprob": -0.25214022296970173, "compression_ratio": 1.75, "no_speech_prob": 9.46125655900687e-05}, {"id": 200, "seek": 107908, "start": 1104.12, "end": 1108.08, "text": " So there's no particular harm, no particular reason not to do an unsum.", "tokens": [51616, 407, 456, 311, 572, 1729, 6491, 11, 572, 1729, 1778, 406, 281, 360, 364, 2693, 449, 13, 51814], "temperature": 0.0, "avg_logprob": -0.25214022296970173, "compression_ratio": 1.75, "no_speech_prob": 9.46125655900687e-05}, {"id": 201, "seek": 110808, "start": 1108.08, "end": 1114.12, "text": " So when I say unsum, that stands for Einstein summation notation.", "tokens": [50364, 407, 562, 286, 584, 2693, 449, 11, 300, 7382, 337, 23486, 28811, 24657, 13, 50666], "temperature": 0.0, "avg_logprob": -0.27663163405198316, "compression_ratio": 1.2929936305732483, "no_speech_prob": 7.766951057419647e-06}, {"id": 202, "seek": 110808, "start": 1114.12, "end": 1117.96, "text": " All right let's go faster still.", "tokens": [50666, 1057, 558, 718, 311, 352, 4663, 920, 13, 50858], "temperature": 0.0, "avg_logprob": -0.27663163405198316, "compression_ratio": 1.2929936305732483, "no_speech_prob": 7.766951057419647e-06}, {"id": 203, "seek": 110808, "start": 1117.96, "end": 1120.6399999999999, "text": " Currently we're just using my CPU.", "tokens": [50858, 19964, 321, 434, 445, 1228, 452, 13199, 13, 50992], "temperature": 0.0, "avg_logprob": -0.27663163405198316, "compression_ratio": 1.2929936305732483, "no_speech_prob": 7.766951057419647e-06}, {"id": 204, "seek": 110808, "start": 1120.6399999999999, "end": 1122.08, "text": " But I have a GPU.", "tokens": [50992, 583, 286, 362, 257, 18407, 13, 51064], "temperature": 0.0, "avg_logprob": -0.27663163405198316, "compression_ratio": 1.2929936305732483, "no_speech_prob": 7.766951057419647e-06}, {"id": 205, "seek": 110808, "start": 1122.08, "end": 1124.72, "text": " It would be nice to use it.", "tokens": [51064, 467, 576, 312, 1481, 281, 764, 309, 13, 51196], "temperature": 0.0, "avg_logprob": -0.27663163405198316, "compression_ratio": 1.2929936305732483, "no_speech_prob": 7.766951057419647e-06}, {"id": 206, "seek": 110808, "start": 1124.72, "end": 1129.8, "text": " So how does a GPU work?", "tokens": [51196, 407, 577, 775, 257, 18407, 589, 30, 51450], "temperature": 0.0, "avg_logprob": -0.27663163405198316, "compression_ratio": 1.2929936305732483, "no_speech_prob": 7.766951057419647e-06}, {"id": 207, "seek": 112980, "start": 1129.8, "end": 1139.6399999999999, "text": " An NVIDIA GPU, and indeed pretty much all GPUs, the way they work is that they do lots", "tokens": [50364, 1107, 426, 3958, 6914, 18407, 11, 293, 6451, 1238, 709, 439, 18407, 82, 11, 264, 636, 436, 589, 307, 300, 436, 360, 3195, 50856], "temperature": 0.0, "avg_logprob": -0.20827511874112217, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.0014325299998745322}, {"id": 208, "seek": 112980, "start": 1139.6399999999999, "end": 1142.1599999999999, "text": " and lots of things in parallel.", "tokens": [50856, 293, 3195, 295, 721, 294, 8952, 13, 50982], "temperature": 0.0, "avg_logprob": -0.20827511874112217, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.0014325299998745322}, {"id": 209, "seek": 112980, "start": 1142.1599999999999, "end": 1147.76, "text": " And you have to actually tell the GPU what are all the things you want to do in parallel,", "tokens": [50982, 400, 291, 362, 281, 767, 980, 264, 18407, 437, 366, 439, 264, 721, 291, 528, 281, 360, 294, 8952, 11, 51262], "temperature": 0.0, "avg_logprob": -0.20827511874112217, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.0014325299998745322}, {"id": 210, "seek": 112980, "start": 1147.76, "end": 1149.1599999999999, "text": " one at a time.", "tokens": [51262, 472, 412, 257, 565, 13, 51332], "temperature": 0.0, "avg_logprob": -0.20827511874112217, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.0014325299998745322}, {"id": 211, "seek": 112980, "start": 1149.1599999999999, "end": 1154.0, "text": " And so what we're going to do is we're going to write in pure Python something that works", "tokens": [51332, 400, 370, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 2464, 294, 6075, 15329, 746, 300, 1985, 51574], "temperature": 0.0, "avg_logprob": -0.20827511874112217, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.0014325299998745322}, {"id": 212, "seek": 112980, "start": 1154.0, "end": 1158.96, "text": " like a GPU, except it won't actually be in parallel so it won't be fast at all.", "tokens": [51574, 411, 257, 18407, 11, 3993, 309, 1582, 380, 767, 312, 294, 8952, 370, 309, 1582, 380, 312, 2370, 412, 439, 13, 51822], "temperature": 0.0, "avg_logprob": -0.20827511874112217, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.0014325299998745322}, {"id": 213, "seek": 115896, "start": 1159.1200000000001, "end": 1162.64, "text": " But the first thing we have to do if we're going to get something working in parallel", "tokens": [50372, 583, 264, 700, 551, 321, 362, 281, 360, 498, 321, 434, 516, 281, 483, 746, 1364, 294, 8952, 50548], "temperature": 0.0, "avg_logprob": -0.21817600579909335, "compression_ratio": 1.6064814814814814, "no_speech_prob": 5.01473505210015e-06}, {"id": 214, "seek": 115896, "start": 1162.64, "end": 1168.76, "text": " is we have to create a function that can calculate just one thing, even if a thousand other things", "tokens": [50548, 307, 321, 362, 281, 1884, 257, 2445, 300, 393, 8873, 445, 472, 551, 11, 754, 498, 257, 4714, 661, 721, 50854], "temperature": 0.0, "avg_logprob": -0.21817600579909335, "compression_ratio": 1.6064814814814814, "no_speech_prob": 5.01473505210015e-06}, {"id": 215, "seek": 115896, "start": 1168.76, "end": 1173.64, "text": " are happening at the same time, it won't interact with anything else.", "tokens": [50854, 366, 2737, 412, 264, 912, 565, 11, 309, 1582, 380, 4648, 365, 1340, 1646, 13, 51098], "temperature": 0.0, "avg_logprob": -0.21817600579909335, "compression_ratio": 1.6064814814814814, "no_speech_prob": 5.01473505210015e-06}, {"id": 216, "seek": 115896, "start": 1173.64, "end": 1180.44, "text": " And there's actually a very easy way to think about matrix multiplication in this way, which", "tokens": [51098, 400, 456, 311, 767, 257, 588, 1858, 636, 281, 519, 466, 8141, 27290, 294, 341, 636, 11, 597, 51438], "temperature": 0.0, "avg_logprob": -0.21817600579909335, "compression_ratio": 1.6064814814814814, "no_speech_prob": 5.01473505210015e-06}, {"id": 217, "seek": 118044, "start": 1180.44, "end": 1189.0, "text": " is what if we try to create something which just as we've done here, fills in a single", "tokens": [50364, 307, 437, 498, 321, 853, 281, 1884, 746, 597, 445, 382, 321, 600, 1096, 510, 11, 22498, 294, 257, 2167, 50792], "temperature": 0.0, "avg_logprob": -0.2758526025816452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006388183683156967}, {"id": 218, "seek": 118044, "start": 1189.0, "end": 1192.3200000000002, "text": " item of the result.", "tokens": [50792, 3174, 295, 264, 1874, 13, 50958], "temperature": 0.0, "avg_logprob": -0.2758526025816452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006388183683156967}, {"id": 219, "seek": 118044, "start": 1192.3200000000002, "end": 1199.16, "text": " So how do we create something that just fills in row zero, column zero?", "tokens": [50958, 407, 577, 360, 321, 1884, 746, 300, 445, 22498, 294, 5386, 4018, 11, 7738, 4018, 30, 51300], "temperature": 0.0, "avg_logprob": -0.2758526025816452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006388183683156967}, {"id": 220, "seek": 118044, "start": 1199.16, "end": 1203.3600000000001, "text": " Well what we could do is we could create a new matmul where we're going to pass in the", "tokens": [51300, 1042, 437, 321, 727, 360, 307, 321, 727, 1884, 257, 777, 3803, 76, 425, 689, 321, 434, 516, 281, 1320, 294, 264, 51510], "temperature": 0.0, "avg_logprob": -0.2758526025816452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006388183683156967}, {"id": 221, "seek": 118044, "start": 1203.3600000000001, "end": 1209.48, "text": " coordinates of the place that we want to fill in.", "tokens": [51510, 21056, 295, 264, 1081, 300, 321, 528, 281, 2836, 294, 13, 51816], "temperature": 0.0, "avg_logprob": -0.2758526025816452, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.006388183683156967}, {"id": 222, "seek": 120948, "start": 1209.52, "end": 1212.6, "text": " So we're going to start by passing it 0,0.", "tokens": [50366, 407, 321, 434, 516, 281, 722, 538, 8437, 309, 1958, 11, 15, 13, 50520], "temperature": 0.0, "avg_logprob": -0.3228008930499737, "compression_ratio": 1.732394366197183, "no_speech_prob": 3.94425806007348e-05}, {"id": 223, "seek": 120948, "start": 1212.6, "end": 1215.76, "text": " We'll pass it the matrix matrices we want to multiply.", "tokens": [50520, 492, 603, 1320, 309, 264, 8141, 32284, 321, 528, 281, 12972, 13, 50678], "temperature": 0.0, "avg_logprob": -0.3228008930499737, "compression_ratio": 1.732394366197183, "no_speech_prob": 3.94425806007348e-05}, {"id": 224, "seek": 120948, "start": 1215.76, "end": 1221.44, "text": " And we'll pass in a tensor that we've pre-filled in with zeros to put the result into.", "tokens": [50678, 400, 321, 603, 1320, 294, 257, 40863, 300, 321, 600, 659, 12, 35596, 294, 365, 35193, 281, 829, 264, 1874, 666, 13, 50962], "temperature": 0.0, "avg_logprob": -0.3228008930499737, "compression_ratio": 1.732394366197183, "no_speech_prob": 3.94425806007348e-05}, {"id": 225, "seek": 120948, "start": 1221.44, "end": 1229.6, "text": " So we're going to say okay the result is torch.zeros, rows by columns, call matmul for location", "tokens": [50962, 407, 321, 434, 516, 281, 584, 1392, 264, 1874, 307, 27822, 13, 4527, 329, 11, 13241, 538, 13766, 11, 818, 3803, 76, 425, 337, 4914, 51370], "temperature": 0.0, "avg_logprob": -0.3228008930499737, "compression_ratio": 1.732394366197183, "no_speech_prob": 3.94425806007348e-05}, {"id": 226, "seek": 120948, "start": 1229.6, "end": 1235.8, "text": " 0,0, passing in those two matrices and the bunch of zeros matrix ready to put the result", "tokens": [51370, 1958, 11, 15, 11, 8437, 294, 729, 732, 32284, 293, 264, 3840, 295, 35193, 8141, 1919, 281, 829, 264, 1874, 51680], "temperature": 0.0, "avg_logprob": -0.3228008930499737, "compression_ratio": 1.732394366197183, "no_speech_prob": 3.94425806007348e-05}, {"id": 227, "seek": 123580, "start": 1235.8, "end": 1236.8, "text": " in.", "tokens": [50364, 294, 13, 50414], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 228, "seek": 123580, "start": 1236.8, "end": 1240.6, "text": " And if we call that we get the answer in cell 0,0.", "tokens": [50414, 400, 498, 321, 818, 300, 321, 483, 264, 1867, 294, 2815, 1958, 11, 15, 13, 50604], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 229, "seek": 123580, "start": 1240.6, "end": 1243.6399999999999, "text": " So here's an implementation of that.", "tokens": [50604, 407, 510, 311, 364, 11420, 295, 300, 13, 50756], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 230, "seek": 123580, "start": 1243.6399999999999, "end": 1248.44, "text": " So the implementation is first of all we've been passed the 0,0 coordinates.", "tokens": [50756, 407, 264, 11420, 307, 700, 295, 439, 321, 600, 668, 4678, 264, 1958, 11, 15, 21056, 13, 50996], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 231, "seek": 123580, "start": 1248.44, "end": 1250.2, "text": " So let's destructure them.", "tokens": [50996, 407, 718, 311, 2677, 2885, 552, 13, 51084], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 232, "seek": 123580, "start": 1250.2, "end": 1253.24, "text": " So hopefully you've been experimenting with destructuring because it's so important.", "tokens": [51084, 407, 4696, 291, 600, 668, 29070, 365, 2677, 1757, 1345, 570, 309, 311, 370, 1021, 13, 51236], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 233, "seek": 123580, "start": 1253.24, "end": 1254.24, "text": " You see it all the time.", "tokens": [51236, 509, 536, 309, 439, 264, 565, 13, 51286], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 234, "seek": 123580, "start": 1254.24, "end": 1258.6, "text": " Enter i and j, that's the row and the column.", "tokens": [51286, 10399, 741, 293, 361, 11, 300, 311, 264, 5386, 293, 264, 7738, 13, 51504], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 235, "seek": 123580, "start": 1258.6, "end": 1265.24, "text": " Make sure that that is inside the bounds of our output matrix.", "tokens": [51504, 4387, 988, 300, 300, 307, 1854, 264, 29905, 295, 527, 5598, 8141, 13, 51836], "temperature": 0.0, "avg_logprob": -0.25386732715671345, "compression_ratio": 1.6626506024096386, "no_speech_prob": 0.0015487570781260729}, {"id": 236, "seek": 126524, "start": 1265.68, "end": 1270.56, "text": " And we're going to start by start at 0 and loop through all of the rows of A and all", "tokens": [50386, 400, 321, 434, 516, 281, 722, 538, 722, 412, 1958, 293, 6367, 807, 439, 295, 264, 13241, 295, 316, 293, 439, 50630], "temperature": 0.0, "avg_logprob": -0.2589254746070275, "compression_ratio": 1.7740384615384615, "no_speech_prob": 0.00012339447857812047}, {"id": 237, "seek": 126524, "start": 1270.56, "end": 1274.8, "text": " of the columns of B for i and j.", "tokens": [50630, 295, 264, 13766, 295, 363, 337, 741, 293, 361, 13, 50842], "temperature": 0.0, "avg_logprob": -0.2589254746070275, "compression_ratio": 1.7740384615384615, "no_speech_prob": 0.00012339447857812047}, {"id": 238, "seek": 126524, "start": 1274.8, "end": 1280.48, "text": " Sorry all of the columns of A and all of the rows of B for i and j.", "tokens": [50842, 4919, 439, 295, 264, 13766, 295, 316, 293, 439, 295, 264, 13241, 295, 363, 337, 741, 293, 361, 13, 51126], "temperature": 0.0, "avg_logprob": -0.2589254746070275, "compression_ratio": 1.7740384615384615, "no_speech_prob": 0.00012339447857812047}, {"id": 239, "seek": 126524, "start": 1280.48, "end": 1285.96, "text": " Just like the very innermost loop of our very first Python attempt.", "tokens": [51126, 1449, 411, 264, 588, 7714, 966, 555, 6367, 295, 527, 588, 700, 15329, 5217, 13, 51400], "temperature": 0.0, "avg_logprob": -0.2589254746070275, "compression_ratio": 1.7740384615384615, "no_speech_prob": 0.00012339447857812047}, {"id": 240, "seek": 126524, "start": 1285.96, "end": 1288.3, "text": " And then at the end pop that into the output.", "tokens": [51400, 400, 550, 412, 264, 917, 1665, 300, 666, 264, 5598, 13, 51517], "temperature": 0.0, "avg_logprob": -0.2589254746070275, "compression_ratio": 1.7740384615384615, "no_speech_prob": 0.00012339447857812047}, {"id": 241, "seek": 126524, "start": 1288.3, "end": 1293.68, "text": " So here's something that fills in one piece of the grid successfully.", "tokens": [51517, 407, 510, 311, 746, 300, 22498, 294, 472, 2522, 295, 264, 10748, 10727, 13, 51786], "temperature": 0.0, "avg_logprob": -0.2589254746070275, "compression_ratio": 1.7740384615384615, "no_speech_prob": 0.00012339447857812047}, {"id": 242, "seek": 129368, "start": 1293.68, "end": 1300.3600000000001, "text": " So we could call this row by columns times, each time passing in a different grid.", "tokens": [50364, 407, 321, 727, 818, 341, 5386, 538, 13766, 1413, 11, 1184, 565, 8437, 294, 257, 819, 10748, 13, 50698], "temperature": 0.0, "avg_logprob": -0.23928621903206537, "compression_ratio": 1.7280334728033473, "no_speech_prob": 5.4222177823248785e-06}, {"id": 243, "seek": 129368, "start": 1300.3600000000001, "end": 1304.44, "text": " And we could do that in parallel because none of those different locations interact with", "tokens": [50698, 400, 321, 727, 360, 300, 294, 8952, 570, 6022, 295, 729, 819, 9253, 4648, 365, 50902], "temperature": 0.0, "avg_logprob": -0.23928621903206537, "compression_ratio": 1.7280334728033473, "no_speech_prob": 5.4222177823248785e-06}, {"id": 244, "seek": 129368, "start": 1304.44, "end": 1307.18, "text": " any other location.", "tokens": [50902, 604, 661, 4914, 13, 51039], "temperature": 0.0, "avg_logprob": -0.23928621903206537, "compression_ratio": 1.7280334728033473, "no_speech_prob": 5.4222177823248785e-06}, {"id": 245, "seek": 129368, "start": 1307.18, "end": 1314.8400000000001, "text": " So something which can calculate a little piece of an output on a GPU is called a kernel.", "tokens": [51039, 407, 746, 597, 393, 8873, 257, 707, 2522, 295, 364, 5598, 322, 257, 18407, 307, 1219, 257, 28256, 13, 51422], "temperature": 0.0, "avg_logprob": -0.23928621903206537, "compression_ratio": 1.7280334728033473, "no_speech_prob": 5.4222177823248785e-06}, {"id": 246, "seek": 129368, "start": 1314.8400000000001, "end": 1316.72, "text": " So we'd call this a kernel.", "tokens": [51422, 407, 321, 1116, 818, 341, 257, 28256, 13, 51516], "temperature": 0.0, "avg_logprob": -0.23928621903206537, "compression_ratio": 1.7280334728033473, "no_speech_prob": 5.4222177823248785e-06}, {"id": 247, "seek": 129368, "start": 1316.72, "end": 1319.52, "text": " And so now we can create something called launch kernel.", "tokens": [51516, 400, 370, 586, 321, 393, 1884, 746, 1219, 4025, 28256, 13, 51656], "temperature": 0.0, "avg_logprob": -0.23928621903206537, "compression_ratio": 1.7280334728033473, "no_speech_prob": 5.4222177823248785e-06}, {"id": 248, "seek": 129368, "start": 1319.52, "end": 1322.0, "text": " We pass it the kernel, so that's the function.", "tokens": [51656, 492, 1320, 309, 264, 28256, 11, 370, 300, 311, 264, 2445, 13, 51780], "temperature": 0.0, "avg_logprob": -0.23928621903206537, "compression_ratio": 1.7280334728033473, "no_speech_prob": 5.4222177823248785e-06}, {"id": 249, "seek": 132200, "start": 1322.32, "end": 1327.12, "text": " So here's an example, launch kernel passing in the function.", "tokens": [50380, 407, 510, 311, 364, 1365, 11, 4025, 28256, 8437, 294, 264, 2445, 13, 50620], "temperature": 0.0, "avg_logprob": -0.25230467319488525, "compression_ratio": 1.586734693877551, "no_speech_prob": 5.7719180404092185e-06}, {"id": 250, "seek": 132200, "start": 1327.12, "end": 1333.36, "text": " And how many rows and how many columns are there in the output grid.", "tokens": [50620, 400, 577, 867, 13241, 293, 577, 867, 13766, 366, 456, 294, 264, 5598, 10748, 13, 50932], "temperature": 0.0, "avg_logprob": -0.25230467319488525, "compression_ratio": 1.586734693877551, "no_speech_prob": 5.7719180404092185e-06}, {"id": 251, "seek": 132200, "start": 1333.36, "end": 1337.06, "text": " And then give me any arguments that you need to calculate it.", "tokens": [50932, 400, 550, 976, 385, 604, 12869, 300, 291, 643, 281, 8873, 309, 13, 51117], "temperature": 0.0, "avg_logprob": -0.25230467319488525, "compression_ratio": 1.586734693877551, "no_speech_prob": 5.7719180404092185e-06}, {"id": 252, "seek": 132200, "start": 1337.06, "end": 1343.08, "text": " So in Python, star args just says any additional arguments that you pass are going to be put", "tokens": [51117, 407, 294, 15329, 11, 3543, 3882, 82, 445, 1619, 604, 4497, 12869, 300, 291, 1320, 366, 516, 281, 312, 829, 51418], "temperature": 0.0, "avg_logprob": -0.25230467319488525, "compression_ratio": 1.586734693877551, "no_speech_prob": 5.7719180404092185e-06}, {"id": 253, "seek": 132200, "start": 1343.08, "end": 1346.68, "text": " into an array called args.", "tokens": [51418, 666, 364, 10225, 1219, 3882, 82, 13, 51598], "temperature": 0.0, "avg_logprob": -0.25230467319488525, "compression_ratio": 1.586734693877551, "no_speech_prob": 5.7719180404092185e-06}, {"id": 254, "seek": 134668, "start": 1346.68, "end": 1352.64, "text": " If you use something like C, you might have seen like variadic arguments, parameters,", "tokens": [50364, 759, 291, 764, 746, 411, 383, 11, 291, 1062, 362, 1612, 411, 3034, 43341, 12869, 11, 9834, 11, 50662], "temperature": 0.0, "avg_logprob": -0.28596270879109703, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.0006462023593485355}, {"id": 255, "seek": 134668, "start": 1352.64, "end": 1355.0, "text": " it's the same basic idea.", "tokens": [50662, 309, 311, 264, 912, 3875, 1558, 13, 50780], "temperature": 0.0, "avg_logprob": -0.28596270879109703, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.0006462023593485355}, {"id": 256, "seek": 134668, "start": 1355.0, "end": 1358.3600000000001, "text": " So we're going to be calling launch kernel, we're going to be saying launch the kernel", "tokens": [50780, 407, 321, 434, 516, 281, 312, 5141, 4025, 28256, 11, 321, 434, 516, 281, 312, 1566, 4025, 264, 28256, 50948], "temperature": 0.0, "avg_logprob": -0.28596270879109703, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.0006462023593485355}, {"id": 257, "seek": 134668, "start": 1358.3600000000001, "end": 1366.0, "text": " matmul using all the rows of A, all the columns of B. And then the args, which are going to", "tokens": [50948, 3803, 76, 425, 1228, 439, 264, 13241, 295, 316, 11, 439, 264, 13766, 295, 363, 13, 400, 550, 264, 3882, 82, 11, 597, 366, 516, 281, 51330], "temperature": 0.0, "avg_logprob": -0.28596270879109703, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.0006462023593485355}, {"id": 258, "seek": 134668, "start": 1366.0, "end": 1371.88, "text": " be in star args, are going to be m1, the first matrix, m2, the second matrix, and res, another", "tokens": [51330, 312, 294, 3543, 3882, 82, 11, 366, 516, 281, 312, 275, 16, 11, 264, 700, 8141, 11, 275, 17, 11, 264, 1150, 8141, 11, 293, 725, 11, 1071, 51624], "temperature": 0.0, "avg_logprob": -0.28596270879109703, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.0006462023593485355}, {"id": 259, "seek": 134668, "start": 1371.88, "end": 1375.0, "text": " torch.0 as we just created.", "tokens": [51624, 27822, 13, 15, 382, 321, 445, 2942, 13, 51780], "temperature": 0.0, "avg_logprob": -0.28596270879109703, "compression_ratio": 1.7574468085106383, "no_speech_prob": 0.0006462023593485355}, {"id": 260, "seek": 137500, "start": 1375.0, "end": 1382.72, "text": " So launch kernel is going to loop through the rows of A, and then for each row of A", "tokens": [50364, 407, 4025, 28256, 307, 516, 281, 6367, 807, 264, 13241, 295, 316, 11, 293, 550, 337, 1184, 5386, 295, 316, 50750], "temperature": 0.0, "avg_logprob": -0.2527042343502953, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00034062896156683564}, {"id": 261, "seek": 137500, "start": 1382.72, "end": 1390.4, "text": " it will loop through the columns of B, and call the kernel, which is matmul, on that", "tokens": [50750, 309, 486, 6367, 807, 264, 13766, 295, 363, 11, 293, 818, 264, 28256, 11, 597, 307, 3803, 76, 425, 11, 322, 300, 51134], "temperature": 0.0, "avg_logprob": -0.2527042343502953, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00034062896156683564}, {"id": 262, "seek": 137500, "start": 1390.4, "end": 1396.32, "text": " grid location, passing in m1, m2, and res.", "tokens": [51134, 10748, 4914, 11, 8437, 294, 275, 16, 11, 275, 17, 11, 293, 725, 13, 51430], "temperature": 0.0, "avg_logprob": -0.2527042343502953, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00034062896156683564}, {"id": 263, "seek": 137500, "start": 1396.32, "end": 1404.04, "text": " So star args here is going to unpack that and pass them as three separate arguments.", "tokens": [51430, 407, 3543, 3882, 82, 510, 307, 516, 281, 26699, 300, 293, 1320, 552, 382, 1045, 4994, 12869, 13, 51816], "temperature": 0.0, "avg_logprob": -0.2527042343502953, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00034062896156683564}, {"id": 264, "seek": 140404, "start": 1404.08, "end": 1409.68, "text": " And if I run that, run all of that, you'll see it's done it.", "tokens": [50366, 400, 498, 286, 1190, 300, 11, 1190, 439, 295, 300, 11, 291, 603, 536, 309, 311, 1096, 309, 13, 50646], "temperature": 0.0, "avg_logprob": -0.22849298477172852, "compression_ratio": 1.542857142857143, "no_speech_prob": 2.5867431759252213e-05}, {"id": 265, "seek": 140404, "start": 1409.68, "end": 1413.44, "text": " It's filled in the exact same matrix.", "tokens": [50646, 467, 311, 6412, 294, 264, 1900, 912, 8141, 13, 50834], "temperature": 0.0, "avg_logprob": -0.22849298477172852, "compression_ratio": 1.542857142857143, "no_speech_prob": 2.5867431759252213e-05}, {"id": 266, "seek": 140404, "start": 1413.44, "end": 1416.72, "text": " OK, so that's actually not fast at all.", "tokens": [50834, 2264, 11, 370, 300, 311, 767, 406, 2370, 412, 439, 13, 50998], "temperature": 0.0, "avg_logprob": -0.22849298477172852, "compression_ratio": 1.542857142857143, "no_speech_prob": 2.5867431759252213e-05}, {"id": 267, "seek": 140404, "start": 1416.72, "end": 1420.06, "text": " It's not doing anything in parallel, but it's the basic idea.", "tokens": [50998, 467, 311, 406, 884, 1340, 294, 8952, 11, 457, 309, 311, 264, 3875, 1558, 13, 51165], "temperature": 0.0, "avg_logprob": -0.22849298477172852, "compression_ratio": 1.542857142857143, "no_speech_prob": 2.5867431759252213e-05}, {"id": 268, "seek": 140404, "start": 1420.06, "end": 1423.96, "text": " So now to actually do it in parallel, we have to use something called CUDA.", "tokens": [51165, 407, 586, 281, 767, 360, 309, 294, 8952, 11, 321, 362, 281, 764, 746, 1219, 29777, 7509, 13, 51360], "temperature": 0.0, "avg_logprob": -0.22849298477172852, "compression_ratio": 1.542857142857143, "no_speech_prob": 2.5867431759252213e-05}, {"id": 269, "seek": 140404, "start": 1423.96, "end": 1428.36, "text": " So CUDA is a programming model for NVIDIA GPUs.", "tokens": [51360, 407, 29777, 7509, 307, 257, 9410, 2316, 337, 426, 3958, 6914, 18407, 82, 13, 51580], "temperature": 0.0, "avg_logprob": -0.22849298477172852, "compression_ratio": 1.542857142857143, "no_speech_prob": 2.5867431759252213e-05}, {"id": 270, "seek": 142836, "start": 1428.36, "end": 1434.32, "text": " And to program in CUDA from Python, the easiest way currently to do that is with something", "tokens": [50364, 400, 281, 1461, 294, 29777, 7509, 490, 15329, 11, 264, 12889, 636, 4362, 281, 360, 300, 307, 365, 746, 50662], "temperature": 0.0, "avg_logprob": -0.2637166976928711, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.006192950531840324}, {"id": 271, "seek": 142836, "start": 1434.32, "end": 1435.6399999999999, "text": " called Numba.", "tokens": [50662, 1219, 426, 49353, 13, 50728], "temperature": 0.0, "avg_logprob": -0.2637166976928711, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.006192950531840324}, {"id": 272, "seek": 142836, "start": 1435.6399999999999, "end": 1439.76, "text": " And Numba is a compiler, well you've seen it actually already, for non-GPU.", "tokens": [50728, 400, 426, 49353, 307, 257, 31958, 11, 731, 291, 600, 1612, 309, 767, 1217, 11, 337, 2107, 12, 38, 8115, 13, 50934], "temperature": 0.0, "avg_logprob": -0.2637166976928711, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.006192950531840324}, {"id": 273, "seek": 142836, "start": 1439.76, "end": 1445.9599999999998, "text": " It's a compiler that takes Python code and spits out, you know, compiled fast machine", "tokens": [50934, 467, 311, 257, 31958, 300, 2516, 15329, 3089, 293, 637, 1208, 484, 11, 291, 458, 11, 36548, 2370, 3479, 51244], "temperature": 0.0, "avg_logprob": -0.2637166976928711, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.006192950531840324}, {"id": 274, "seek": 142836, "start": 1445.9599999999998, "end": 1447.4399999999998, "text": " code.", "tokens": [51244, 3089, 13, 51318], "temperature": 0.0, "avg_logprob": -0.2637166976928711, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.006192950531840324}, {"id": 275, "seek": 142836, "start": 1447.4399999999998, "end": 1453.58, "text": " If you use its CUDA module, it'll actually spit out GPU accelerated CUDA code.", "tokens": [51318, 759, 291, 764, 1080, 29777, 7509, 10088, 11, 309, 603, 767, 22127, 484, 18407, 29763, 29777, 7509, 3089, 13, 51625], "temperature": 0.0, "avg_logprob": -0.2637166976928711, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.006192950531840324}, {"id": 276, "seek": 145358, "start": 1453.58, "end": 1459.6999999999998, "text": " So rather than using at ngit like before, we now say at cuda.git.", "tokens": [50364, 407, 2831, 813, 1228, 412, 297, 70, 270, 411, 949, 11, 321, 586, 584, 412, 269, 11152, 13, 70, 270, 13, 50670], "temperature": 0.0, "avg_logprob": -0.25125582464810076, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.00035143792047165334}, {"id": 277, "seek": 145358, "start": 1459.6999999999998, "end": 1464.54, "text": " And it behaves a little bit differently, but you'll see that this matmul, let me copy the", "tokens": [50670, 400, 309, 36896, 257, 707, 857, 7614, 11, 457, 291, 603, 536, 300, 341, 3803, 76, 425, 11, 718, 385, 5055, 264, 50912], "temperature": 0.0, "avg_logprob": -0.25125582464810076, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.00035143792047165334}, {"id": 278, "seek": 145358, "start": 1464.54, "end": 1468.8999999999999, "text": " other one over so you can compare, compare it to our Python one.", "tokens": [50912, 661, 472, 670, 370, 291, 393, 6794, 11, 6794, 309, 281, 527, 15329, 472, 13, 51130], "temperature": 0.0, "avg_logprob": -0.25125582464810076, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.00035143792047165334}, {"id": 279, "seek": 145358, "start": 1468.8999999999999, "end": 1476.5, "text": " Our Python matmul and this cuda.git matmul look, I think, identical, except for one thing.", "tokens": [51130, 2621, 15329, 3803, 76, 425, 293, 341, 269, 11152, 13, 70, 270, 3803, 76, 425, 574, 11, 286, 519, 11, 14800, 11, 3993, 337, 472, 551, 13, 51510], "temperature": 0.0, "avg_logprob": -0.25125582464810076, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.00035143792047165334}, {"id": 280, "seek": 145358, "start": 1476.5, "end": 1481.78, "text": " Instead of passing in the grid, there's a special magic thing called cuda.grid.", "tokens": [51510, 7156, 295, 8437, 294, 264, 10748, 11, 456, 311, 257, 2121, 5585, 551, 1219, 269, 11152, 13, 35320, 13, 51774], "temperature": 0.0, "avg_logprob": -0.25125582464810076, "compression_ratio": 1.6224066390041494, "no_speech_prob": 0.00035143792047165334}, {"id": 281, "seek": 148178, "start": 1481.78, "end": 1484.1399999999999, "text": " When you say, how many dimensions does my grid have?", "tokens": [50364, 1133, 291, 584, 11, 577, 867, 12819, 775, 452, 10748, 362, 30, 50482], "temperature": 0.0, "avg_logprob": -0.2162398490585199, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.002019011415541172}, {"id": 282, "seek": 148178, "start": 1484.1399999999999, "end": 1485.26, "text": " And you unpack it.", "tokens": [50482, 400, 291, 26699, 309, 13, 50538], "temperature": 0.0, "avg_logprob": -0.2162398490585199, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.002019011415541172}, {"id": 283, "seek": 148178, "start": 1485.26, "end": 1491.3, "text": " So that's, you don't have to, it's just a little convenience that Numba does for you.", "tokens": [50538, 407, 300, 311, 11, 291, 500, 380, 362, 281, 11, 309, 311, 445, 257, 707, 19283, 300, 426, 49353, 775, 337, 291, 13, 50840], "temperature": 0.0, "avg_logprob": -0.2162398490585199, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.002019011415541172}, {"id": 284, "seek": 148178, "start": 1491.3, "end": 1493.98, "text": " You don't have to pass over the grid, it passes it over for you.", "tokens": [50840, 509, 500, 380, 362, 281, 1320, 670, 264, 10748, 11, 309, 11335, 309, 670, 337, 291, 13, 50974], "temperature": 0.0, "avg_logprob": -0.2162398490585199, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.002019011415541172}, {"id": 285, "seek": 148178, "start": 1493.98, "end": 1496.5, "text": " So it doesn't need this grid.", "tokens": [50974, 407, 309, 1177, 380, 643, 341, 10748, 13, 51100], "temperature": 0.0, "avg_logprob": -0.2162398490585199, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.002019011415541172}, {"id": 286, "seek": 148178, "start": 1496.5, "end": 1499.02, "text": " Other than that, these two are identical.", "tokens": [51100, 5358, 813, 300, 11, 613, 732, 366, 14800, 13, 51226], "temperature": 0.0, "avg_logprob": -0.2162398490585199, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.002019011415541172}, {"id": 287, "seek": 148178, "start": 1499.02, "end": 1503.82, "text": " But the decorator is going to compile that into GPU code.", "tokens": [51226, 583, 264, 7919, 1639, 307, 516, 281, 31413, 300, 666, 18407, 3089, 13, 51466], "temperature": 0.0, "avg_logprob": -0.2162398490585199, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.002019011415541172}, {"id": 288, "seek": 148178, "start": 1503.82, "end": 1509.84, "text": " So now we need to create our output tensor, just like before.", "tokens": [51466, 407, 586, 321, 643, 281, 1884, 527, 5598, 40863, 11, 445, 411, 949, 13, 51767], "temperature": 0.0, "avg_logprob": -0.2162398490585199, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.002019011415541172}, {"id": 289, "seek": 150984, "start": 1509.8999999999999, "end": 1516.4399999999998, "text": " And we need to do something else, which is we have to take our input matrices and our", "tokens": [50367, 400, 321, 643, 281, 360, 746, 1646, 11, 597, 307, 321, 362, 281, 747, 527, 4846, 32284, 293, 527, 50694], "temperature": 0.0, "avg_logprob": -0.2514186299175297, "compression_ratio": 1.841860465116279, "no_speech_prob": 0.00020027373102493584}, {"id": 290, "seek": 150984, "start": 1516.4399999999998, "end": 1521.52, "text": " output, so our input tensors, the matrices in this case, and the output tensor, and we", "tokens": [50694, 5598, 11, 370, 527, 4846, 10688, 830, 11, 264, 32284, 294, 341, 1389, 11, 293, 264, 5598, 40863, 11, 293, 321, 50948], "temperature": 0.0, "avg_logprob": -0.2514186299175297, "compression_ratio": 1.841860465116279, "no_speech_prob": 0.00020027373102493584}, {"id": 291, "seek": 150984, "start": 1521.52, "end": 1525.1599999999999, "text": " have to move them to the GPU, or I should say copy them to the GPU.", "tokens": [50948, 362, 281, 1286, 552, 281, 264, 18407, 11, 420, 286, 820, 584, 5055, 552, 281, 264, 18407, 13, 51130], "temperature": 0.0, "avg_logprob": -0.2514186299175297, "compression_ratio": 1.841860465116279, "no_speech_prob": 0.00020027373102493584}, {"id": 292, "seek": 150984, "start": 1525.1599999999999, "end": 1530.3799999999999, "text": " So cuda.device copies a tensor to the GPU.", "tokens": [51130, 407, 269, 11152, 13, 40343, 573, 14341, 257, 40863, 281, 264, 18407, 13, 51391], "temperature": 0.0, "avg_logprob": -0.2514186299175297, "compression_ratio": 1.841860465116279, "no_speech_prob": 0.00020027373102493584}, {"id": 293, "seek": 150984, "start": 1530.3799999999999, "end": 1535.36, "text": " And so we've got three things getting copied to the GPU here, and therefore we store the", "tokens": [51391, 400, 370, 321, 600, 658, 1045, 721, 1242, 25365, 281, 264, 18407, 510, 11, 293, 4412, 321, 3531, 264, 51640], "temperature": 0.0, "avg_logprob": -0.2514186299175297, "compression_ratio": 1.841860465116279, "no_speech_prob": 0.00020027373102493584}, {"id": 294, "seek": 150984, "start": 1535.36, "end": 1539.4399999999998, "text": " three things over here.", "tokens": [51640, 1045, 721, 670, 510, 13, 51844], "temperature": 0.0, "avg_logprob": -0.2514186299175297, "compression_ratio": 1.841860465116279, "no_speech_prob": 0.00020027373102493584}, {"id": 295, "seek": 153944, "start": 1540.04, "end": 1544.28, "text": " Another way I could have written this is I could have said map, which I kind of quite", "tokens": [50394, 3996, 636, 286, 727, 362, 3720, 341, 307, 286, 727, 362, 848, 4471, 11, 597, 286, 733, 295, 1596, 50606], "temperature": 0.0, "avg_logprob": -0.24007843910379612, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.0006361900013871491}, {"id": 296, "seek": 153944, "start": 1544.28, "end": 1558.24, "text": " like doing, a function which is cuda.device to each of these arguments.", "tokens": [50606, 411, 884, 11, 257, 2445, 597, 307, 269, 11152, 13, 40343, 573, 281, 1184, 295, 613, 12869, 13, 51304], "temperature": 0.0, "avg_logprob": -0.24007843910379612, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.0006361900013871491}, {"id": 297, "seek": 153944, "start": 1558.24, "end": 1559.24, "text": " And this would be the same thing.", "tokens": [51304, 400, 341, 576, 312, 264, 912, 551, 13, 51354], "temperature": 0.0, "avg_logprob": -0.24007843910379612, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.0006361900013871491}, {"id": 298, "seek": 153944, "start": 1559.24, "end": 1564.0800000000002, "text": " So this is going to call cuda.device on X train and put it in here, on weights and put", "tokens": [51354, 407, 341, 307, 516, 281, 818, 269, 11152, 13, 40343, 573, 322, 1783, 3847, 293, 829, 309, 294, 510, 11, 322, 17443, 293, 829, 51596], "temperature": 0.0, "avg_logprob": -0.24007843910379612, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.0006361900013871491}, {"id": 299, "seek": 153944, "start": 1564.0800000000002, "end": 1567.56, "text": " it in here, and on R and put it in here.", "tokens": [51596, 309, 294, 510, 11, 293, 322, 497, 293, 829, 309, 294, 510, 13, 51770], "temperature": 0.0, "avg_logprob": -0.24007843910379612, "compression_ratio": 1.7243243243243243, "no_speech_prob": 0.0006361900013871491}, {"id": 300, "seek": 156756, "start": 1567.56, "end": 1574.2, "text": " That's a slightly more convenient way to do it.", "tokens": [50364, 663, 311, 257, 4748, 544, 10851, 636, 281, 360, 309, 13, 50696], "temperature": 0.0, "avg_logprob": -0.2931200224777748, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.00013982084055896848}, {"id": 301, "seek": 156756, "start": 1574.2, "end": 1579.12, "text": " Okay, so we've got our 50,000 by 10 output.", "tokens": [50696, 1033, 11, 370, 321, 600, 658, 527, 2625, 11, 1360, 538, 1266, 5598, 13, 50942], "temperature": 0.0, "avg_logprob": -0.2931200224777748, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.00013982084055896848}, {"id": 302, "seek": 156756, "start": 1579.12, "end": 1580.6, "text": " That's just all zeros, of course.", "tokens": [50942, 663, 311, 445, 439, 35193, 11, 295, 1164, 13, 51016], "temperature": 0.0, "avg_logprob": -0.2931200224777748, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.00013982084055896848}, {"id": 303, "seek": 156756, "start": 1580.6, "end": 1582.72, "text": " That's just how we created it.", "tokens": [51016, 663, 311, 445, 577, 321, 2942, 309, 13, 51122], "temperature": 0.0, "avg_logprob": -0.2931200224777748, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.00013982084055896848}, {"id": 304, "seek": 156756, "start": 1582.72, "end": 1585.72, "text": " And now we're going to try and fill it in.", "tokens": [51122, 400, 586, 321, 434, 516, 281, 853, 293, 2836, 309, 294, 13, 51272], "temperature": 0.0, "avg_logprob": -0.2931200224777748, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.00013982084055896848}, {"id": 305, "seek": 156756, "start": 1585.72, "end": 1594.84, "text": " There is a particular detail that you don't have to worry about too much, which is in", "tokens": [51272, 821, 307, 257, 1729, 2607, 300, 291, 500, 380, 362, 281, 3292, 466, 886, 709, 11, 597, 307, 294, 51728], "temperature": 0.0, "avg_logprob": -0.2931200224777748, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.00013982084055896848}, {"id": 306, "seek": 159484, "start": 1594.84, "end": 1602.24, "text": " cuda they don't just have a grid, but there's also a concept of blocks.", "tokens": [50364, 269, 11152, 436, 500, 380, 445, 362, 257, 10748, 11, 457, 456, 311, 611, 257, 3410, 295, 8474, 13, 50734], "temperature": 0.0, "avg_logprob": -0.26664499966603405, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.00044421805068850517}, {"id": 307, "seek": 159484, "start": 1602.24, "end": 1606.8799999999999, "text": " And there's something we call here tpb, which is threads per block.", "tokens": [50734, 400, 456, 311, 746, 321, 818, 510, 256, 79, 65, 11, 597, 307, 19314, 680, 3461, 13, 50966], "temperature": 0.0, "avg_logprob": -0.26664499966603405, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.00044421805068850517}, {"id": 308, "seek": 159484, "start": 1606.8799999999999, "end": 1611.32, "text": " This is just a detail of the cuda programming model you don't have to worry about too much.", "tokens": [50966, 639, 307, 445, 257, 2607, 295, 264, 269, 11152, 9410, 2316, 291, 500, 380, 362, 281, 3292, 466, 886, 709, 13, 51188], "temperature": 0.0, "avg_logprob": -0.26664499966603405, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.00044421805068850517}, {"id": 309, "seek": 159484, "start": 1611.32, "end": 1614.3999999999999, "text": " You can just basically copy this.", "tokens": [51188, 509, 393, 445, 1936, 5055, 341, 13, 51342], "temperature": 0.0, "avg_logprob": -0.26664499966603405, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.00044421805068850517}, {"id": 310, "seek": 159484, "start": 1614.3999999999999, "end": 1621.48, "text": " And what it's going to do is it's going to call each grid item in parallel, and with", "tokens": [51342, 400, 437, 309, 311, 516, 281, 360, 307, 309, 311, 516, 281, 818, 1184, 10748, 3174, 294, 8952, 11, 293, 365, 51696], "temperature": 0.0, "avg_logprob": -0.26664499966603405, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.00044421805068850517}, {"id": 311, "seek": 159484, "start": 1621.48, "end": 1624.08, "text": " a number of different processes basically.", "tokens": [51696, 257, 1230, 295, 819, 7555, 1936, 13, 51826], "temperature": 0.0, "avg_logprob": -0.26664499966603405, "compression_ratio": 1.6443514644351465, "no_speech_prob": 0.00044421805068850517}, {"id": 312, "seek": 162408, "start": 1624.32, "end": 1629.12, "text": " This is just the code which turns the grid into blocks.", "tokens": [50376, 639, 307, 445, 264, 3089, 597, 4523, 264, 10748, 666, 8474, 13, 50616], "temperature": 0.0, "avg_logprob": -0.27820849418640137, "compression_ratio": 1.5474137931034482, "no_speech_prob": 4.860447006649338e-06}, {"id": 313, "seek": 162408, "start": 1629.12, "end": 1635.1999999999998, "text": " You don't have to worry too much about the details of that, you just always run it.", "tokens": [50616, 509, 500, 380, 362, 281, 3292, 886, 709, 466, 264, 4365, 295, 300, 11, 291, 445, 1009, 1190, 309, 13, 50920], "temperature": 0.0, "avg_logprob": -0.27820849418640137, "compression_ratio": 1.5474137931034482, "no_speech_prob": 4.860447006649338e-06}, {"id": 314, "seek": 162408, "start": 1635.1999999999998, "end": 1643.32, "text": " Okay, and so now how do you call the equivalent of launch kernel?", "tokens": [50920, 1033, 11, 293, 370, 586, 577, 360, 291, 818, 264, 10344, 295, 4025, 28256, 30, 51326], "temperature": 0.0, "avg_logprob": -0.27820849418640137, "compression_ratio": 1.5474137931034482, "no_speech_prob": 4.860447006649338e-06}, {"id": 315, "seek": 162408, "start": 1643.32, "end": 1648.8, "text": " Well it's a slightly weird way to do it, but it works fine.", "tokens": [51326, 1042, 309, 311, 257, 4748, 3657, 636, 281, 360, 309, 11, 457, 309, 1985, 2489, 13, 51600], "temperature": 0.0, "avg_logprob": -0.27820849418640137, "compression_ratio": 1.5474137931034482, "no_speech_prob": 4.860447006649338e-06}, {"id": 316, "seek": 162408, "start": 1648.8, "end": 1653.3999999999999, "text": " You call matmul, but because matmul has cuda.jit, it's got a special thing, which is you have", "tokens": [51600, 509, 818, 3803, 76, 425, 11, 457, 570, 3803, 76, 425, 575, 269, 11152, 13, 73, 270, 11, 309, 311, 658, 257, 2121, 551, 11, 597, 307, 291, 362, 51830], "temperature": 0.0, "avg_logprob": -0.27820849418640137, "compression_ratio": 1.5474137931034482, "no_speech_prob": 4.860447006649338e-06}, {"id": 317, "seek": 165340, "start": 1653.44, "end": 1656.24, "text": " to put something in square brackets afterwards.", "tokens": [50366, 281, 829, 746, 294, 3732, 26179, 10543, 13, 50506], "temperature": 0.0, "avg_logprob": -0.2347547867718865, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.00012148172390880063}, {"id": 318, "seek": 165340, "start": 1656.24, "end": 1659.4, "text": " Which is you have to tell it how many blocks per grid, that's just the result from the", "tokens": [50506, 3013, 307, 291, 362, 281, 980, 309, 577, 867, 8474, 680, 10748, 11, 300, 311, 445, 264, 1874, 490, 264, 50664], "temperature": 0.0, "avg_logprob": -0.2347547867718865, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.00012148172390880063}, {"id": 319, "seek": 165340, "start": 1659.4, "end": 1664.76, "text": " previous cell, and how many threads per block in each of the two dimensions.", "tokens": [50664, 3894, 2815, 11, 293, 577, 867, 19314, 680, 3461, 294, 1184, 295, 264, 732, 12819, 13, 50932], "temperature": 0.0, "avg_logprob": -0.2347547867718865, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.00012148172390880063}, {"id": 320, "seek": 165340, "start": 1664.76, "end": 1668.24, "text": " So again you can just copy and paste this from my version, but then you pass in the", "tokens": [50932, 407, 797, 291, 393, 445, 5055, 293, 9163, 341, 490, 452, 3037, 11, 457, 550, 291, 1320, 294, 264, 51106], "temperature": 0.0, "avg_logprob": -0.2347547867718865, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.00012148172390880063}, {"id": 321, "seek": 165340, "start": 1668.24, "end": 1670.2, "text": " three arguments to the function.", "tokens": [51106, 1045, 12869, 281, 264, 2445, 13, 51204], "temperature": 0.0, "avg_logprob": -0.2347547867718865, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.00012148172390880063}, {"id": 322, "seek": 165340, "start": 1670.2, "end": 1673.76, "text": " This will be a, b, and c.", "tokens": [51204, 639, 486, 312, 257, 11, 272, 11, 293, 269, 13, 51382], "temperature": 0.0, "avg_logprob": -0.2347547867718865, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.00012148172390880063}, {"id": 323, "seek": 165340, "start": 1673.76, "end": 1676.64, "text": " And this is how you launch a kernel.", "tokens": [51382, 400, 341, 307, 577, 291, 4025, 257, 28256, 13, 51526], "temperature": 0.0, "avg_logprob": -0.2347547867718865, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.00012148172390880063}, {"id": 324, "seek": 165340, "start": 1676.64, "end": 1681.52, "text": " So this will launch the kernel matmul on the GPU.", "tokens": [51526, 407, 341, 486, 4025, 264, 28256, 3803, 76, 425, 322, 264, 18407, 13, 51770], "temperature": 0.0, "avg_logprob": -0.2347547867718865, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.00012148172390880063}, {"id": 325, "seek": 168152, "start": 1681.52, "end": 1684.6, "text": " At the end of it, rg is going to get filled in.", "tokens": [50364, 1711, 264, 917, 295, 309, 11, 367, 70, 307, 516, 281, 483, 6412, 294, 13, 50518], "temperature": 0.0, "avg_logprob": -0.2588282351223928, "compression_ratio": 1.5721153846153846, "no_speech_prob": 2.7108771973871626e-05}, {"id": 326, "seek": 168152, "start": 1684.6, "end": 1688.72, "text": " It's on the GPU, which is not much good to us, so we now have to copy it back to the", "tokens": [50518, 467, 311, 322, 264, 18407, 11, 597, 307, 406, 709, 665, 281, 505, 11, 370, 321, 586, 362, 281, 5055, 309, 646, 281, 264, 50724], "temperature": 0.0, "avg_logprob": -0.2588282351223928, "compression_ratio": 1.5721153846153846, "no_speech_prob": 2.7108771973871626e-05}, {"id": 327, "seek": 168152, "start": 1688.72, "end": 1692.0, "text": " CPU, which is called the host, copy to host.", "tokens": [50724, 13199, 11, 597, 307, 1219, 264, 3975, 11, 5055, 281, 3975, 13, 50888], "temperature": 0.0, "avg_logprob": -0.2588282351223928, "compression_ratio": 1.5721153846153846, "no_speech_prob": 2.7108771973871626e-05}, {"id": 328, "seek": 168152, "start": 1692.0, "end": 1695.0, "text": " So we run that, and it's done.", "tokens": [50888, 407, 321, 1190, 300, 11, 293, 309, 311, 1096, 13, 51038], "temperature": 0.0, "avg_logprob": -0.2588282351223928, "compression_ratio": 1.5721153846153846, "no_speech_prob": 2.7108771973871626e-05}, {"id": 329, "seek": 168152, "start": 1695.0, "end": 1699.76, "text": " And test-close shows us that our result is similar to our original result, so it seems", "tokens": [51038, 400, 1500, 12, 3474, 541, 3110, 505, 300, 527, 1874, 307, 2531, 281, 527, 3380, 1874, 11, 370, 309, 2544, 51276], "temperature": 0.0, "avg_logprob": -0.2588282351223928, "compression_ratio": 1.5721153846153846, "no_speech_prob": 2.7108771973871626e-05}, {"id": 330, "seek": 168152, "start": 1699.76, "end": 1701.98, "text": " to be working.", "tokens": [51276, 281, 312, 1364, 13, 51387], "temperature": 0.0, "avg_logprob": -0.2588282351223928, "compression_ratio": 1.5721153846153846, "no_speech_prob": 2.7108771973871626e-05}, {"id": 331, "seek": 168152, "start": 1701.98, "end": 1704.6399999999999, "text": " So that's great.", "tokens": [51387, 407, 300, 311, 869, 13, 51520], "temperature": 0.0, "avg_logprob": -0.2588282351223928, "compression_ratio": 1.5721153846153846, "no_speech_prob": 2.7108771973871626e-05}, {"id": 332, "seek": 170464, "start": 1704.64, "end": 1711.64, "text": " So I see Siva on the YouTube chat is finding that it's not working on his Mac.", "tokens": [50364, 407, 286, 536, 318, 5931, 322, 264, 3088, 5081, 307, 5006, 300, 309, 311, 406, 1364, 322, 702, 5707, 13, 50714], "temperature": 0.0, "avg_logprob": -0.24396162322073273, "compression_ratio": 1.568888888888889, "no_speech_prob": 4.4693995732814074e-05}, {"id": 333, "seek": 170464, "start": 1711.64, "end": 1717.3200000000002, "text": " That's right, so this will only work on an NVIDIA GPU, as basically all of the GPU, nearly", "tokens": [50714, 663, 311, 558, 11, 370, 341, 486, 787, 589, 322, 364, 426, 3958, 6914, 18407, 11, 382, 1936, 439, 295, 264, 18407, 11, 6217, 50998], "temperature": 0.0, "avg_logprob": -0.24396162322073273, "compression_ratio": 1.568888888888889, "no_speech_prob": 4.4693995732814074e-05}, {"id": 334, "seek": 170464, "start": 1717.3200000000002, "end": 1722.48, "text": " all the GPU stuff we look at, only works on NVIDIA GPUs.", "tokens": [50998, 439, 264, 18407, 1507, 321, 574, 412, 11, 787, 1985, 322, 426, 3958, 6914, 18407, 82, 13, 51256], "temperature": 0.0, "avg_logprob": -0.24396162322073273, "compression_ratio": 1.568888888888889, "no_speech_prob": 4.4693995732814074e-05}, {"id": 335, "seek": 170464, "start": 1722.48, "end": 1730.88, "text": " Mac GPUs are gradually starting to get a little bit of support from machine learning libraries,", "tokens": [51256, 5707, 18407, 82, 366, 13145, 2891, 281, 483, 257, 707, 857, 295, 1406, 490, 3479, 2539, 15148, 11, 51676], "temperature": 0.0, "avg_logprob": -0.24396162322073273, "compression_ratio": 1.568888888888889, "no_speech_prob": 4.4693995732814074e-05}, {"id": 336, "seek": 170464, "start": 1730.88, "end": 1731.96, "text": " but it's taking quite a while.", "tokens": [51676, 457, 309, 311, 1940, 1596, 257, 1339, 13, 51730], "temperature": 0.0, "avg_logprob": -0.24396162322073273, "compression_ratio": 1.568888888888889, "no_speech_prob": 4.4693995732814074e-05}, {"id": 337, "seek": 173196, "start": 1732.28, "end": 1738.8400000000001, "text": " It's got quite a way to go, as I say this, at least towards the end of 2022.", "tokens": [50380, 467, 311, 658, 1596, 257, 636, 281, 352, 11, 382, 286, 584, 341, 11, 412, 1935, 3030, 264, 917, 295, 20229, 13, 50708], "temperature": 0.0, "avg_logprob": -0.26303911711040295, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0001795277785276994}, {"id": 338, "seek": 173196, "start": 1738.8400000000001, "end": 1744.8400000000001, "text": " If this works for you later on, that's great.", "tokens": [50708, 759, 341, 1985, 337, 291, 1780, 322, 11, 300, 311, 869, 13, 51008], "temperature": 0.0, "avg_logprob": -0.26303911711040295, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0001795277785276994}, {"id": 339, "seek": 173196, "start": 1744.8400000000001, "end": 1747.72, "text": " Okay so let's time how fast that is.", "tokens": [51008, 1033, 370, 718, 311, 565, 577, 2370, 300, 307, 13, 51152], "temperature": 0.0, "avg_logprob": -0.26303911711040295, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0001795277785276994}, {"id": 340, "seek": 173196, "start": 1747.72, "end": 1755.72, "text": " Okay so that was 3.61 milliseconds, and so if we compare that to the PyTorch matmul on", "tokens": [51152, 1033, 370, 300, 390, 805, 13, 31537, 34184, 11, 293, 370, 498, 321, 6794, 300, 281, 264, 9953, 51, 284, 339, 3803, 76, 425, 322, 51552], "temperature": 0.0, "avg_logprob": -0.26303911711040295, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0001795277785276994}, {"id": 341, "seek": 173196, "start": 1755.72, "end": 1758.32, "text": " CPU, that was 15 milliseconds.", "tokens": [51552, 13199, 11, 300, 390, 2119, 34184, 13, 51682], "temperature": 0.0, "avg_logprob": -0.26303911711040295, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0001795277785276994}, {"id": 342, "seek": 173196, "start": 1758.32, "end": 1760.48, "text": " So that's great.", "tokens": [51682, 407, 300, 311, 869, 13, 51790], "temperature": 0.0, "avg_logprob": -0.26303911711040295, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0001795277785276994}, {"id": 343, "seek": 176048, "start": 1760.48, "end": 1762.92, "text": " So it's faster still.", "tokens": [50364, 407, 309, 311, 4663, 920, 13, 50486], "temperature": 0.0, "avg_logprob": -0.24479233984853707, "compression_ratio": 1.5, "no_speech_prob": 6.605208909604698e-05}, {"id": 344, "seek": 176048, "start": 1762.92, "end": 1769.32, "text": " So how much faster, oh by the way, we can actually go faster than that, which is we", "tokens": [50486, 407, 577, 709, 4663, 11, 1954, 538, 264, 636, 11, 321, 393, 767, 352, 4663, 813, 300, 11, 597, 307, 321, 50806], "temperature": 0.0, "avg_logprob": -0.24479233984853707, "compression_ratio": 1.5, "no_speech_prob": 6.605208909604698e-05}, {"id": 345, "seek": 176048, "start": 1769.32, "end": 1775.22, "text": " can use the exact same code we had from the PyTorch op, but here's a trick.", "tokens": [50806, 393, 764, 264, 1900, 912, 3089, 321, 632, 490, 264, 9953, 51, 284, 339, 999, 11, 457, 510, 311, 257, 4282, 13, 51101], "temperature": 0.0, "avg_logprob": -0.24479233984853707, "compression_ratio": 1.5, "no_speech_prob": 6.605208909604698e-05}, {"id": 346, "seek": 176048, "start": 1775.22, "end": 1781.6, "text": " If you just take your tensor and write .cuda after it, it copies it over to the GPU.", "tokens": [51101, 759, 291, 445, 747, 428, 40863, 293, 2464, 2411, 66, 11152, 934, 309, 11, 309, 14341, 309, 670, 281, 264, 18407, 13, 51420], "temperature": 0.0, "avg_logprob": -0.24479233984853707, "compression_ratio": 1.5, "no_speech_prob": 6.605208909604698e-05}, {"id": 347, "seek": 176048, "start": 1781.6, "end": 1786.7, "text": " If it's on a NVIDIA GPU, do the same for weights.cuda.", "tokens": [51420, 759, 309, 311, 322, 257, 426, 3958, 6914, 18407, 11, 360, 264, 912, 337, 17443, 13, 66, 11152, 13, 51675], "temperature": 0.0, "avg_logprob": -0.24479233984853707, "compression_ratio": 1.5, "no_speech_prob": 6.605208909604698e-05}, {"id": 348, "seek": 178670, "start": 1786.7, "end": 1792.82, "text": " So these are our two cuda versions, and now I can do the whole thing, and this will actually", "tokens": [50364, 407, 613, 366, 527, 732, 269, 11152, 9606, 11, 293, 586, 286, 393, 360, 264, 1379, 551, 11, 293, 341, 486, 767, 50670], "temperature": 0.0, "avg_logprob": -0.33706556047712055, "compression_ratio": 1.5, "no_speech_prob": 0.0043314858339726925}, {"id": 349, "seek": 178670, "start": 1792.82, "end": 1795.38, "text": " run on the GPU.", "tokens": [50670, 1190, 322, 264, 18407, 13, 50798], "temperature": 0.0, "avg_logprob": -0.33706556047712055, "compression_ratio": 1.5, "no_speech_prob": 0.0043314858339726925}, {"id": 350, "seek": 178670, "start": 1795.38, "end": 1798.8400000000001, "text": " And then to copy it back to the host, you just say .cpu.", "tokens": [50798, 400, 550, 281, 5055, 309, 646, 281, 264, 3975, 11, 291, 445, 584, 2411, 66, 34859, 13, 50971], "temperature": 0.0, "avg_logprob": -0.33706556047712055, "compression_ratio": 1.5, "no_speech_prob": 0.0043314858339726925}, {"id": 351, "seek": 178670, "start": 1798.8400000000001, "end": 1806.1000000000001, "text": " So if we look to see how fast that is, 458 microseconds.", "tokens": [50971, 407, 498, 321, 574, 281, 536, 577, 2370, 300, 307, 11, 6905, 23, 3123, 37841, 28750, 13, 51334], "temperature": 0.0, "avg_logprob": -0.33706556047712055, "compression_ratio": 1.5, "no_speech_prob": 0.0043314858339726925}, {"id": 352, "seek": 178670, "start": 1806.1000000000001, "end": 1813.9, "text": " So oh, that is, somebody just pointed out that I wrote the wrong thing here, 1e neg", "tokens": [51334, 407, 1954, 11, 300, 307, 11, 2618, 445, 10932, 484, 300, 286, 4114, 264, 2085, 551, 510, 11, 502, 68, 2485, 51724], "temperature": 0.0, "avg_logprob": -0.33706556047712055, "compression_ratio": 1.5, "no_speech_prob": 0.0043314858339726925}, {"id": 353, "seek": 178670, "start": 1813.9, "end": 1814.9, "text": " 3.", "tokens": [51724, 805, 13, 51774], "temperature": 0.0, "avg_logprob": -0.33706556047712055, "compression_ratio": 1.5, "no_speech_prob": 0.0043314858339726925}, {"id": 354, "seek": 181490, "start": 1815.1000000000001, "end": 1817.7, "text": " Okay, so how much faster is that?", "tokens": [50374, 1033, 11, 370, 577, 709, 4663, 307, 300, 30, 50504], "temperature": 0.0, "avg_logprob": -0.31684091356065536, "compression_ratio": 1.3356643356643356, "no_speech_prob": 3.3405381145712454e-06}, {"id": 355, "seek": 181490, "start": 1817.7, "end": 1826.38, "text": " Well 458 microseconds, our original, on the whole data set, was 663 microseconds.", "tokens": [50504, 1042, 6905, 23, 3123, 37841, 28750, 11, 527, 3380, 11, 322, 264, 1379, 1412, 992, 11, 390, 21126, 18, 3123, 37841, 28750, 13, 50938], "temperature": 0.0, "avg_logprob": -0.31684091356065536, "compression_ratio": 1.3356643356643356, "no_speech_prob": 3.3405381145712454e-06}, {"id": 356, "seek": 181490, "start": 1826.38, "end": 1834.42, "text": " So compared to our broadcast version, we are another thousand times faster.", "tokens": [50938, 407, 5347, 281, 527, 9975, 3037, 11, 321, 366, 1071, 4714, 1413, 4663, 13, 51340], "temperature": 0.0, "avg_logprob": -0.31684091356065536, "compression_ratio": 1.3356643356643356, "no_speech_prob": 3.3405381145712454e-06}, {"id": 357, "seek": 183442, "start": 1834.42, "end": 1848.9, "text": " So overall, this version here, compared to our original version, which was here, the", "tokens": [50364, 407, 4787, 11, 341, 3037, 510, 11, 5347, 281, 527, 3380, 3037, 11, 597, 390, 510, 11, 264, 51088], "temperature": 0.0, "avg_logprob": -0.3753795921802521, "compression_ratio": 1.2352941176470589, "no_speech_prob": 0.0002034224889939651}, {"id": 358, "seek": 183442, "start": 1848.9, "end": 1856.7, "text": " difference in performance is 5 million x.", "tokens": [51088, 2649, 294, 3389, 307, 1025, 2459, 2031, 13, 51478], "temperature": 0.0, "avg_logprob": -0.3753795921802521, "compression_ratio": 1.2352941176470589, "no_speech_prob": 0.0002034224889939651}, {"id": 359, "seek": 185670, "start": 1856.7, "end": 1865.78, "text": " So when you see people say, yeah, Python can be pretty slow, it can be better to run", "tokens": [50364, 407, 562, 291, 536, 561, 584, 11, 1338, 11, 15329, 393, 312, 1238, 2964, 11, 309, 393, 312, 1101, 281, 1190, 50818], "temperature": 0.0, "avg_logprob": -0.26620383011667353, "compression_ratio": 1.3928571428571428, "no_speech_prob": 0.00030061532743275166}, {"id": 360, "seek": 185670, "start": 1865.78, "end": 1871.78, "text": " stuff on the GPU, if possible, we're not talking about a 20% change, we're talking about a", "tokens": [50818, 1507, 322, 264, 18407, 11, 498, 1944, 11, 321, 434, 406, 1417, 466, 257, 945, 4, 1319, 11, 321, 434, 1417, 466, 257, 51118], "temperature": 0.0, "avg_logprob": -0.26620383011667353, "compression_ratio": 1.3928571428571428, "no_speech_prob": 0.00030061532743275166}, {"id": 361, "seek": 185670, "start": 1871.78, "end": 1878.5, "text": " 5 million x change.", "tokens": [51118, 1025, 2459, 2031, 1319, 13, 51454], "temperature": 0.0, "avg_logprob": -0.26620383011667353, "compression_ratio": 1.3928571428571428, "no_speech_prob": 0.00030061532743275166}, {"id": 362, "seek": 187850, "start": 1878.5, "end": 1885.74, "text": " So that's a big deal, and so that's why you need to be running stuff on the GPU.", "tokens": [50364, 407, 300, 311, 257, 955, 2028, 11, 293, 370, 300, 311, 983, 291, 643, 281, 312, 2614, 1507, 322, 264, 18407, 13, 50726], "temperature": 0.0, "avg_logprob": -0.24697233381725492, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.002323141088709235}, {"id": 363, "seek": 187850, "start": 1885.74, "end": 1895.94, "text": " All right, some folks on YouTube are wondering how on earth I'm running CUDA when I'm on", "tokens": [50726, 1057, 558, 11, 512, 4024, 322, 3088, 366, 6359, 577, 322, 4120, 286, 478, 2614, 29777, 7509, 562, 286, 478, 322, 51236], "temperature": 0.0, "avg_logprob": -0.24697233381725492, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.002323141088709235}, {"id": 364, "seek": 187850, "start": 1895.94, "end": 1902.38, "text": " a Mac, and given it says localhost here, that's because I'm using something called SSH tunneling,", "tokens": [51236, 257, 5707, 11, 293, 2212, 309, 1619, 2654, 6037, 510, 11, 300, 311, 570, 286, 478, 1228, 746, 1219, 12238, 39, 13186, 278, 11, 51558], "temperature": 0.0, "avg_logprob": -0.24697233381725492, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.002323141088709235}, {"id": 365, "seek": 187850, "start": 1902.38, "end": 1903.94, "text": " which we might get to sometime.", "tokens": [51558, 597, 321, 1062, 483, 281, 15053, 13, 51636], "temperature": 0.0, "avg_logprob": -0.24697233381725492, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.002323141088709235}, {"id": 366, "seek": 190394, "start": 1903.94, "end": 1909.94, "text": " I suspect my live coding from the previous course might have covered that already, but", "tokens": [50364, 286, 9091, 452, 1621, 17720, 490, 264, 3894, 1164, 1062, 362, 5343, 300, 1217, 11, 457, 50664], "temperature": 0.0, "avg_logprob": -0.32756211757659914, "compression_ratio": 1.4734513274336283, "no_speech_prob": 0.0004955347976647317}, {"id": 367, "seek": 190394, "start": 1909.94, "end": 1915.38, "text": " this is basically, you can use a Jupyter notebook that's running anywhere in the world from", "tokens": [50664, 341, 307, 1936, 11, 291, 393, 764, 257, 22125, 88, 391, 21060, 300, 311, 2614, 4992, 294, 264, 1002, 490, 50936], "temperature": 0.0, "avg_logprob": -0.32756211757659914, "compression_ratio": 1.4734513274336283, "no_speech_prob": 0.0004955347976647317}, {"id": 368, "seek": 190394, "start": 1915.38, "end": 1926.3400000000001, "text": " your own machine, using something called SSH tunneling, which is a good thing to look up.", "tokens": [50936, 428, 1065, 3479, 11, 1228, 746, 1219, 12238, 39, 13186, 278, 11, 597, 307, 257, 665, 551, 281, 574, 493, 13, 51484], "temperature": 0.0, "avg_logprob": -0.32756211757659914, "compression_ratio": 1.4734513274336283, "no_speech_prob": 0.0004955347976647317}, {"id": 369, "seek": 190394, "start": 1926.3400000000001, "end": 1930.46, "text": " One person asks if Einstein summation borrows anything from APL.", "tokens": [51484, 1485, 954, 8962, 498, 23486, 28811, 14828, 28251, 1340, 490, 5372, 43, 13, 51690], "temperature": 0.0, "avg_logprob": -0.32756211757659914, "compression_ratio": 1.4734513274336283, "no_speech_prob": 0.0004955347976647317}, {"id": 370, "seek": 193046, "start": 1930.46, "end": 1933.46, "text": " Yes, it does actually.", "tokens": [50364, 1079, 11, 309, 775, 767, 13, 50514], "temperature": 0.0, "avg_logprob": -0.26381854521922576, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.8342881958233193e-05}, {"id": 371, "seek": 193046, "start": 1933.46, "end": 1939.82, "text": " So it's kind of the other way around actually, APL borrows it from Einstein notation.", "tokens": [50514, 407, 309, 311, 733, 295, 264, 661, 636, 926, 767, 11, 5372, 43, 14828, 28251, 309, 490, 23486, 24657, 13, 50832], "temperature": 0.0, "avg_logprob": -0.26381854521922576, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.8342881958233193e-05}, {"id": 372, "seek": 193046, "start": 1939.82, "end": 1947.9, "text": " So I don't know if you remember I mentioned that Ken Iverson, when he developed APL, was", "tokens": [50832, 407, 286, 500, 380, 458, 498, 291, 1604, 286, 2835, 300, 8273, 286, 840, 266, 11, 562, 415, 4743, 5372, 43, 11, 390, 51236], "temperature": 0.0, "avg_logprob": -0.26381854521922576, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.8342881958233193e-05}, {"id": 373, "seek": 193046, "start": 1947.9, "end": 1954.3400000000001, "text": " heavily influenced by tensor analysis, and so this Einstein notation is very heavily", "tokens": [51236, 10950, 15269, 538, 40863, 5215, 11, 293, 370, 341, 23486, 24657, 307, 588, 10950, 51558], "temperature": 0.0, "avg_logprob": -0.26381854521922576, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.8342881958233193e-05}, {"id": 374, "seek": 193046, "start": 1954.3400000000001, "end": 1956.02, "text": " used there.", "tokens": [51558, 1143, 456, 13, 51642], "temperature": 0.0, "avg_logprob": -0.26381854521922576, "compression_ratio": 1.4923857868020305, "no_speech_prob": 1.8342881958233193e-05}, {"id": 375, "seek": 195602, "start": 1956.02, "end": 1962.82, "text": " If you'll notice, a key thing that happens in Einstein notation is there's no loop, you", "tokens": [50364, 759, 291, 603, 3449, 11, 257, 2141, 551, 300, 2314, 294, 23486, 24657, 307, 456, 311, 572, 6367, 11, 291, 50704], "temperature": 0.0, "avg_logprob": -0.2244683548256203, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.205044337548316e-05}, {"id": 376, "seek": 195602, "start": 1962.82, "end": 1966.86, "text": " know, there isn't this kind of sigma, you know, i from here to here, and then you put", "tokens": [50704, 458, 11, 456, 1943, 380, 341, 733, 295, 12771, 11, 291, 458, 11, 741, 490, 510, 281, 510, 11, 293, 550, 291, 829, 50906], "temperature": 0.0, "avg_logprob": -0.2244683548256203, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.205044337548316e-05}, {"id": 377, "seek": 195602, "start": 1966.86, "end": 1970.54, "text": " the i inside the function that you're summing up.", "tokens": [50906, 264, 741, 1854, 264, 2445, 300, 291, 434, 2408, 2810, 493, 13, 51090], "temperature": 0.0, "avg_logprob": -0.2244683548256203, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.205044337548316e-05}, {"id": 378, "seek": 195602, "start": 1970.54, "end": 1979.3799999999999, "text": " Everything's implicit, and APL takes that a very long way, and J takes it even further,", "tokens": [51090, 5471, 311, 26947, 11, 293, 5372, 43, 2516, 300, 257, 588, 938, 636, 11, 293, 508, 2516, 309, 754, 3052, 11, 51532], "temperature": 0.0, "avg_logprob": -0.2244683548256203, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.205044337548316e-05}, {"id": 379, "seek": 195602, "start": 1979.3799999999999, "end": 1985.46, "text": " which is what Ken Iverson developed after APL, and this kind of general idea of removing", "tokens": [51532, 597, 307, 437, 8273, 286, 840, 266, 4743, 934, 5372, 43, 11, 293, 341, 733, 295, 2674, 1558, 295, 12720, 51836], "temperature": 0.0, "avg_logprob": -0.2244683548256203, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.205044337548316e-05}, {"id": 380, "seek": 198546, "start": 1985.46, "end": 1993.78, "text": " the index is very important in APL, and it's become very important in NumPy, PyTorch, TensorFlow,", "tokens": [50364, 264, 8186, 307, 588, 1021, 294, 5372, 43, 11, 293, 309, 311, 1813, 588, 1021, 294, 22592, 47, 88, 11, 9953, 51, 284, 339, 11, 37624, 11, 50780], "temperature": 0.0, "avg_logprob": -0.30099923270089285, "compression_ratio": 1.4146341463414633, "no_speech_prob": 6.339210813166574e-06}, {"id": 381, "seek": 198546, "start": 1993.78, "end": 1998.06, "text": " and so forth.", "tokens": [50780, 293, 370, 5220, 13, 50994], "temperature": 0.0, "avg_logprob": -0.30099923270089285, "compression_ratio": 1.4146341463414633, "no_speech_prob": 6.339210813166574e-06}, {"id": 382, "seek": 198546, "start": 1998.06, "end": 2002.5, "text": " So finally we know how to multiply matrices.", "tokens": [50994, 407, 2721, 321, 458, 577, 281, 12972, 32284, 13, 51216], "temperature": 0.0, "avg_logprob": -0.30099923270089285, "compression_ratio": 1.4146341463414633, "no_speech_prob": 6.339210813166574e-06}, {"id": 383, "seek": 198546, "start": 2002.5, "end": 2006.1000000000001, "text": " Congratulations!", "tokens": [51216, 9694, 0, 51396], "temperature": 0.0, "avg_logprob": -0.30099923270089285, "compression_ratio": 1.4146341463414633, "no_speech_prob": 6.339210813166574e-06}, {"id": 384, "seek": 198546, "start": 2006.1000000000001, "end": 2009.22, "text": " So let's practice that.", "tokens": [51396, 407, 718, 311, 3124, 300, 13, 51552], "temperature": 0.0, "avg_logprob": -0.30099923270089285, "compression_ratio": 1.4146341463414633, "no_speech_prob": 6.339210813166574e-06}, {"id": 385, "seek": 198546, "start": 2009.22, "end": 2011.14, "text": " Let's practice what we've learned.", "tokens": [51552, 961, 311, 3124, 437, 321, 600, 3264, 13, 51648], "temperature": 0.0, "avg_logprob": -0.30099923270089285, "compression_ratio": 1.4146341463414633, "no_speech_prob": 6.339210813166574e-06}, {"id": 386, "seek": 201114, "start": 2011.14, "end": 2023.42, "text": " So we're going to go to 0 to mean shift to practice this, and so we're going to try to", "tokens": [50364, 407, 321, 434, 516, 281, 352, 281, 1958, 281, 914, 5513, 281, 3124, 341, 11, 293, 370, 321, 434, 516, 281, 853, 281, 50978], "temperature": 0.0, "avg_logprob": -0.24342715923602765, "compression_ratio": 1.5941176470588236, "no_speech_prob": 7.967257988639176e-05}, {"id": 387, "seek": 201114, "start": 2023.42, "end": 2033.9, "text": " exercise our kind of tensor manipulation operation muscles in this section, and the key actually", "tokens": [50978, 5380, 527, 733, 295, 40863, 26475, 6916, 9530, 294, 341, 3541, 11, 293, 264, 2141, 767, 51502], "temperature": 0.0, "avg_logprob": -0.24342715923602765, "compression_ratio": 1.5941176470588236, "no_speech_prob": 7.967257988639176e-05}, {"id": 388, "seek": 201114, "start": 2033.9, "end": 2039.94, "text": " endpoint for this is the homework, and so what you need to be doing is getting yourself", "tokens": [51502, 35795, 337, 341, 307, 264, 14578, 11, 293, 370, 437, 291, 643, 281, 312, 884, 307, 1242, 1803, 51804], "temperature": 0.0, "avg_logprob": -0.24342715923602765, "compression_ratio": 1.5941176470588236, "no_speech_prob": 7.967257988639176e-05}, {"id": 389, "seek": 203994, "start": 2039.98, "end": 2045.22, "text": " to a point that you can implement something like this, but for a different algorithm.", "tokens": [50366, 281, 257, 935, 300, 291, 393, 4445, 746, 411, 341, 11, 457, 337, 257, 819, 9284, 13, 50628], "temperature": 0.0, "avg_logprob": -0.26101505279541015, "compression_ratio": 1.6982758620689655, "no_speech_prob": 6.643425422225846e-06}, {"id": 390, "seek": 203994, "start": 2045.22, "end": 2047.8600000000001, "text": " Why do we care about this?", "tokens": [50628, 1545, 360, 321, 1127, 466, 341, 30, 50760], "temperature": 0.0, "avg_logprob": -0.26101505279541015, "compression_ratio": 1.6982758620689655, "no_speech_prob": 6.643425422225846e-06}, {"id": 391, "seek": 203994, "start": 2047.8600000000001, "end": 2056.14, "text": " Because this is like learning your times table, your times tables if you're doing, you know,", "tokens": [50760, 1436, 341, 307, 411, 2539, 428, 1413, 3199, 11, 428, 1413, 8020, 498, 291, 434, 884, 11, 291, 458, 11, 51174], "temperature": 0.0, "avg_logprob": -0.26101505279541015, "compression_ratio": 1.6982758620689655, "no_speech_prob": 6.643425422225846e-06}, {"id": 392, "seek": 203994, "start": 2056.14, "end": 2057.62, "text": " mathematics.", "tokens": [51174, 18666, 13, 51248], "temperature": 0.0, "avg_logprob": -0.26101505279541015, "compression_ratio": 1.6982758620689655, "no_speech_prob": 6.643425422225846e-06}, {"id": 393, "seek": 203994, "start": 2057.62, "end": 2061.5, "text": " It's this kind of like thing that's going to come up all the time, and if you're not", "tokens": [51248, 467, 311, 341, 733, 295, 411, 551, 300, 311, 516, 281, 808, 493, 439, 264, 565, 11, 293, 498, 291, 434, 406, 51442], "temperature": 0.0, "avg_logprob": -0.26101505279541015, "compression_ratio": 1.6982758620689655, "no_speech_prob": 6.643425422225846e-06}, {"id": 394, "seek": 203994, "start": 2061.5, "end": 2067.2200000000003, "text": " good at your times tables, everything else, a lot of other things, particularly at primary", "tokens": [51442, 665, 412, 428, 1413, 8020, 11, 1203, 1646, 11, 257, 688, 295, 661, 721, 11, 4098, 412, 6194, 51728], "temperature": 0.0, "avg_logprob": -0.26101505279541015, "compression_ratio": 1.6982758620689655, "no_speech_prob": 6.643425422225846e-06}, {"id": 395, "seek": 206722, "start": 2067.22, "end": 2074.1, "text": " school and high school, you know, they get difficult.", "tokens": [50364, 1395, 293, 1090, 1395, 11, 291, 458, 11, 436, 483, 2252, 13, 50708], "temperature": 0.0, "avg_logprob": -0.2765636872709467, "compression_ratio": 1.64, "no_speech_prob": 2.4300239601871e-05}, {"id": 396, "seek": 206722, "start": 2074.1, "end": 2080.7799999999997, "text": " You get slower, and it's frustrating, and you spend time thinking about these mechanical", "tokens": [50708, 509, 483, 14009, 11, 293, 309, 311, 16522, 11, 293, 291, 3496, 565, 1953, 466, 613, 12070, 51042], "temperature": 0.0, "avg_logprob": -0.2765636872709467, "compression_ratio": 1.64, "no_speech_prob": 2.4300239601871e-05}, {"id": 397, "seek": 206722, "start": 2080.7799999999997, "end": 2083.4599999999996, "text": " operations rather than getting your work done.", "tokens": [51042, 7705, 2831, 813, 1242, 428, 589, 1096, 13, 51176], "temperature": 0.0, "avg_logprob": -0.2765636872709467, "compression_ratio": 1.64, "no_speech_prob": 2.4300239601871e-05}, {"id": 398, "seek": 206722, "start": 2083.4599999999996, "end": 2088.18, "text": " It is, it's important that when you have an idea about something you want to try, or debug,", "tokens": [51176, 467, 307, 11, 309, 311, 1021, 300, 562, 291, 362, 364, 1558, 466, 746, 291, 528, 281, 853, 11, 420, 24083, 11, 51412], "temperature": 0.0, "avg_logprob": -0.2765636872709467, "compression_ratio": 1.64, "no_speech_prob": 2.4300239601871e-05}, {"id": 399, "seek": 206722, "start": 2088.18, "end": 2093.8999999999996, "text": " or profile, or whatever, that you can quickly translate that into working code, and the", "tokens": [51412, 420, 7964, 11, 420, 2035, 11, 300, 291, 393, 2661, 13799, 300, 666, 1364, 3089, 11, 293, 264, 51698], "temperature": 0.0, "avg_logprob": -0.2765636872709467, "compression_ratio": 1.64, "no_speech_prob": 2.4300239601871e-05}, {"id": 400, "seek": 209390, "start": 2093.9, "end": 2105.58, "text": " way that code is written for GPUs, or even for fast running on CPUs, is using broadcasting,", "tokens": [50364, 636, 300, 3089, 307, 3720, 337, 18407, 82, 11, 420, 754, 337, 2370, 2614, 322, 13199, 82, 11, 307, 1228, 30024, 11, 50948], "temperature": 0.0, "avg_logprob": -0.3215874565972222, "compression_ratio": 1.483221476510067, "no_speech_prob": 2.2827893189969473e-05}, {"id": 401, "seek": 209390, "start": 2105.58, "end": 2114.38, "text": " Einstein notation, matrix modifications, and so forth.", "tokens": [50948, 23486, 24657, 11, 8141, 26881, 11, 293, 370, 5220, 13, 51388], "temperature": 0.0, "avg_logprob": -0.3215874565972222, "compression_ratio": 1.483221476510067, "no_speech_prob": 2.2827893189969473e-05}, {"id": 402, "seek": 209390, "start": 2114.38, "end": 2116.58, "text": " So you've got to, you've got to, got to, got to practice.", "tokens": [51388, 407, 291, 600, 658, 281, 11, 291, 600, 658, 281, 11, 658, 281, 11, 658, 281, 3124, 13, 51498], "temperature": 0.0, "avg_logprob": -0.3215874565972222, "compression_ratio": 1.483221476510067, "no_speech_prob": 2.2827893189969473e-05}, {"id": 403, "seek": 209390, "start": 2116.58, "end": 2118.38, "text": " Super important.", "tokens": [51498, 4548, 1021, 13, 51588], "temperature": 0.0, "avg_logprob": -0.3215874565972222, "compression_ratio": 1.483221476510067, "no_speech_prob": 2.2827893189969473e-05}, {"id": 404, "seek": 211838, "start": 2118.38, "end": 2128.42, "text": " So we're going to practice it by running, by developing a clustering algorithm, and", "tokens": [50364, 407, 321, 434, 516, 281, 3124, 309, 538, 2614, 11, 538, 6416, 257, 596, 48673, 9284, 11, 293, 50866], "temperature": 0.0, "avg_logprob": -0.24522269855846057, "compression_ratio": 1.6948356807511737, "no_speech_prob": 9.314585622632876e-05}, {"id": 405, "seek": 211838, "start": 2128.42, "end": 2134.1800000000003, "text": " the clustering algorithm we're going to work on is something called mean shift clustering,", "tokens": [50866, 264, 596, 48673, 9284, 321, 434, 516, 281, 589, 322, 307, 746, 1219, 914, 5513, 596, 48673, 11, 51154], "temperature": 0.0, "avg_logprob": -0.24522269855846057, "compression_ratio": 1.6948356807511737, "no_speech_prob": 9.314585622632876e-05}, {"id": 406, "seek": 211838, "start": 2134.1800000000003, "end": 2137.42, "text": " which hopefully you've never heard of before, and I say that because I just think it's a", "tokens": [51154, 597, 4696, 291, 600, 1128, 2198, 295, 949, 11, 293, 286, 584, 300, 570, 286, 445, 519, 309, 311, 257, 51316], "temperature": 0.0, "avg_logprob": -0.24522269855846057, "compression_ratio": 1.6948356807511737, "no_speech_prob": 9.314585622632876e-05}, {"id": 407, "seek": 211838, "start": 2137.42, "end": 2145.1800000000003, "text": " really fun algorithm that not many people have come across.", "tokens": [51316, 534, 1019, 9284, 300, 406, 867, 561, 362, 808, 2108, 13, 51704], "temperature": 0.0, "avg_logprob": -0.24522269855846057, "compression_ratio": 1.6948356807511737, "no_speech_prob": 9.314585622632876e-05}, {"id": 408, "seek": 211838, "start": 2145.1800000000003, "end": 2148.26, "text": " I think you'll find it really useful.", "tokens": [51704, 286, 519, 291, 603, 915, 309, 534, 4420, 13, 51858], "temperature": 0.0, "avg_logprob": -0.24522269855846057, "compression_ratio": 1.6948356807511737, "no_speech_prob": 9.314585622632876e-05}, {"id": 409, "seek": 214826, "start": 2149.1400000000003, "end": 2150.3, "text": " So what is cluster analysis?", "tokens": [50408, 407, 437, 307, 13630, 5215, 30, 50466], "temperature": 0.0, "avg_logprob": -0.2299063711455374, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.812516749552742e-07}, {"id": 410, "seek": 214826, "start": 2150.3, "end": 2157.26, "text": " Cluster analysis is very different to anything that we've worked on in this course so far,", "tokens": [50466, 2033, 8393, 5215, 307, 588, 819, 281, 1340, 300, 321, 600, 2732, 322, 294, 341, 1164, 370, 1400, 11, 50814], "temperature": 0.0, "avg_logprob": -0.2299063711455374, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.812516749552742e-07}, {"id": 411, "seek": 214826, "start": 2157.26, "end": 2162.6200000000003, "text": " in that there isn't a dependent variable that we're trying to match, but instead we're just", "tokens": [50814, 294, 300, 456, 1943, 380, 257, 12334, 7006, 300, 321, 434, 1382, 281, 2995, 11, 457, 2602, 321, 434, 445, 51082], "temperature": 0.0, "avg_logprob": -0.2299063711455374, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.812516749552742e-07}, {"id": 412, "seek": 214826, "start": 2162.6200000000003, "end": 2169.2200000000003, "text": " trying to find, are there groups of similar things in this data, those groups we call", "tokens": [51082, 1382, 281, 915, 11, 366, 456, 3935, 295, 2531, 721, 294, 341, 1412, 11, 729, 3935, 321, 818, 51412], "temperature": 0.0, "avg_logprob": -0.2299063711455374, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.812516749552742e-07}, {"id": 413, "seek": 214826, "start": 2169.2200000000003, "end": 2170.9, "text": " clusters.", "tokens": [51412, 23313, 13, 51496], "temperature": 0.0, "avg_logprob": -0.2299063711455374, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.812516749552742e-07}, {"id": 414, "seek": 214826, "start": 2170.9, "end": 2177.9, "text": " And as you can see from the wiki page, there's all kinds of applications of cluster analysis", "tokens": [51496, 400, 382, 291, 393, 536, 490, 264, 261, 9850, 3028, 11, 456, 311, 439, 3685, 295, 5821, 295, 13630, 5215, 51846], "temperature": 0.0, "avg_logprob": -0.2299063711455374, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.812516749552742e-07}, {"id": 415, "seek": 217790, "start": 2177.94, "end": 2181.02, "text": " across many different areas.", "tokens": [50366, 2108, 867, 819, 3179, 13, 50520], "temperature": 0.0, "avg_logprob": -0.2711705910532098, "compression_ratio": 1.6045197740112995, "no_speech_prob": 2.1024332852448424e-07}, {"id": 416, "seek": 217790, "start": 2181.02, "end": 2187.9, "text": " I will say that sometimes cluster analysis can be overused or misused.", "tokens": [50520, 286, 486, 584, 300, 2171, 13630, 5215, 393, 312, 670, 4717, 420, 3346, 4717, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2711705910532098, "compression_ratio": 1.6045197740112995, "no_speech_prob": 2.1024332852448424e-07}, {"id": 417, "seek": 217790, "start": 2187.9, "end": 2197.5, "text": " It's really best for when your, your various columns are the same kind of thing and have", "tokens": [50864, 467, 311, 534, 1151, 337, 562, 428, 11, 428, 3683, 13766, 366, 264, 912, 733, 295, 551, 293, 362, 51344], "temperature": 0.0, "avg_logprob": -0.2711705910532098, "compression_ratio": 1.6045197740112995, "no_speech_prob": 2.1024332852448424e-07}, {"id": 418, "seek": 217790, "start": 2197.5, "end": 2201.98, "text": " the same kind of scale.", "tokens": [51344, 264, 912, 733, 295, 4373, 13, 51568], "temperature": 0.0, "avg_logprob": -0.2711705910532098, "compression_ratio": 1.6045197740112995, "no_speech_prob": 2.1024332852448424e-07}, {"id": 419, "seek": 217790, "start": 2201.98, "end": 2205.26, "text": " For example, pixels are all the same kind of thing.", "tokens": [51568, 1171, 1365, 11, 18668, 366, 439, 264, 912, 733, 295, 551, 13, 51732], "temperature": 0.0, "avg_logprob": -0.2711705910532098, "compression_ratio": 1.6045197740112995, "no_speech_prob": 2.1024332852448424e-07}, {"id": 420, "seek": 217790, "start": 2205.26, "end": 2206.26, "text": " They're all pixels.", "tokens": [51732, 814, 434, 439, 18668, 13, 51782], "temperature": 0.0, "avg_logprob": -0.2711705910532098, "compression_ratio": 1.6045197740112995, "no_speech_prob": 2.1024332852448424e-07}, {"id": 421, "seek": 220626, "start": 2206.6200000000003, "end": 2210.0600000000004, "text": " So one of the examples they use is market research.", "tokens": [50382, 407, 472, 295, 264, 5110, 436, 764, 307, 2142, 2132, 13, 50554], "temperature": 0.0, "avg_logprob": -0.2637091080347697, "compression_ratio": 1.5593220338983051, "no_speech_prob": 2.058049176412169e-06}, {"id": 422, "seek": 220626, "start": 2210.0600000000004, "end": 2215.94, "text": " So I wouldn't use cluster analysis for socio-demographic inputs because they're all different kinds", "tokens": [50554, 407, 286, 2759, 380, 764, 13630, 5215, 337, 44303, 12, 10730, 12295, 15743, 570, 436, 434, 439, 819, 3685, 50848], "temperature": 0.0, "avg_logprob": -0.2637091080347697, "compression_ratio": 1.5593220338983051, "no_speech_prob": 2.058049176412169e-06}, {"id": 423, "seek": 220626, "start": 2215.94, "end": 2216.94, "text": " of things.", "tokens": [50848, 295, 721, 13, 50898], "temperature": 0.0, "avg_logprob": -0.2637091080347697, "compression_ratio": 1.5593220338983051, "no_speech_prob": 2.058049176412169e-06}, {"id": 424, "seek": 220626, "start": 2216.94, "end": 2221.34, "text": " But the example they give here makes a lot of sense, which is looking at data from surveys,", "tokens": [50898, 583, 264, 1365, 436, 976, 510, 1669, 257, 688, 295, 2020, 11, 597, 307, 1237, 412, 1412, 490, 22711, 11, 51118], "temperature": 0.0, "avg_logprob": -0.2637091080347697, "compression_ratio": 1.5593220338983051, "no_speech_prob": 2.058049176412169e-06}, {"id": 425, "seek": 220626, "start": 2221.34, "end": 2227.5400000000004, "text": " if you've got a whole bunch of like from one to five answers on surveys.", "tokens": [51118, 498, 291, 600, 658, 257, 1379, 3840, 295, 411, 490, 472, 281, 1732, 6338, 322, 22711, 13, 51428], "temperature": 0.0, "avg_logprob": -0.2637091080347697, "compression_ratio": 1.5593220338983051, "no_speech_prob": 2.058049176412169e-06}, {"id": 426, "seek": 220626, "start": 2227.5400000000004, "end": 2230.86, "text": " All right, so let's take a look at this.", "tokens": [51428, 1057, 558, 11, 370, 718, 311, 747, 257, 574, 412, 341, 13, 51594], "temperature": 0.0, "avg_logprob": -0.2637091080347697, "compression_ratio": 1.5593220338983051, "no_speech_prob": 2.058049176412169e-06}, {"id": 427, "seek": 223086, "start": 2230.86, "end": 2236.46, "text": " And the way I like to build my algorithms is to create some, often to create some synthetic", "tokens": [50364, 400, 264, 636, 286, 411, 281, 1322, 452, 14642, 307, 281, 1884, 512, 11, 2049, 281, 1884, 512, 23420, 50644], "temperature": 0.0, "avg_logprob": -0.20458850082086058, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00023050658637657762}, {"id": 428, "seek": 223086, "start": 2236.46, "end": 2239.7000000000003, "text": " data that I know how I want it to behave.", "tokens": [50644, 1412, 300, 286, 458, 577, 286, 528, 309, 281, 15158, 13, 50806], "temperature": 0.0, "avg_logprob": -0.20458850082086058, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00023050658637657762}, {"id": 429, "seek": 223086, "start": 2239.7000000000003, "end": 2244.94, "text": " And so we're going to create six clusters and each cluster is going to have 750 samples", "tokens": [50806, 400, 370, 321, 434, 516, 281, 1884, 2309, 23313, 293, 1184, 13630, 307, 516, 281, 362, 31682, 10938, 51068], "temperature": 0.0, "avg_logprob": -0.20458850082086058, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00023050658637657762}, {"id": 430, "seek": 223086, "start": 2244.94, "end": 2246.46, "text": " in it.", "tokens": [51068, 294, 309, 13, 51144], "temperature": 0.0, "avg_logprob": -0.20458850082086058, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00023050658637657762}, {"id": 431, "seek": 223086, "start": 2246.46, "end": 2254.6200000000003, "text": " So first of all, I'm going to randomly create six centroids.", "tokens": [51144, 407, 700, 295, 439, 11, 286, 478, 516, 281, 16979, 1884, 2309, 24607, 3742, 13, 51552], "temperature": 0.0, "avg_logprob": -0.20458850082086058, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00023050658637657762}, {"id": 432, "seek": 223086, "start": 2254.6200000000003, "end": 2259.84, "text": " And so the centroid is going to be like the middle of where my clusters are.", "tokens": [51552, 400, 370, 264, 1489, 6490, 307, 516, 281, 312, 411, 264, 2808, 295, 689, 452, 23313, 366, 13, 51813], "temperature": 0.0, "avg_logprob": -0.20458850082086058, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.00023050658637657762}, {"id": 433, "seek": 225984, "start": 2259.84, "end": 2261.48, "text": " So I'm going to randomly create them.", "tokens": [50364, 407, 286, 478, 516, 281, 16979, 1884, 552, 13, 50446], "temperature": 0.0, "avg_logprob": -0.2773833336768212, "compression_ratio": 1.530054644808743, "no_speech_prob": 1.2289182222957606e-06}, {"id": 434, "seek": 225984, "start": 2261.48, "end": 2269.1600000000003, "text": " I need to end clusters by two, because I need an X and a Y coordinate for each one.", "tokens": [50446, 286, 643, 281, 917, 23313, 538, 732, 11, 570, 286, 643, 364, 1783, 293, 257, 398, 15670, 337, 1184, 472, 13, 50830], "temperature": 0.0, "avg_logprob": -0.2773833336768212, "compression_ratio": 1.530054644808743, "no_speech_prob": 1.2289182222957606e-06}, {"id": 435, "seek": 225984, "start": 2269.1600000000003, "end": 2277.84, "text": " And so now I'm going to randomly generate data around those six centroids.", "tokens": [50830, 400, 370, 586, 286, 478, 516, 281, 16979, 8460, 1412, 926, 729, 2309, 24607, 3742, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2773833336768212, "compression_ratio": 1.530054644808743, "no_speech_prob": 1.2289182222957606e-06}, {"id": 436, "seek": 225984, "start": 2277.84, "end": 2286.52, "text": " Okay, so to do that, I'm going to call a little function I made here called sample.", "tokens": [51264, 1033, 11, 370, 281, 360, 300, 11, 286, 478, 516, 281, 818, 257, 707, 2445, 286, 1027, 510, 1219, 6889, 13, 51698], "temperature": 0.0, "avg_logprob": -0.2773833336768212, "compression_ratio": 1.530054644808743, "no_speech_prob": 1.2289182222957606e-06}, {"id": 437, "seek": 228652, "start": 2286.52, "end": 2293.6, "text": " And I'm going to run it on each of those six centroids.", "tokens": [50364, 400, 286, 478, 516, 281, 1190, 309, 322, 1184, 295, 729, 2309, 24607, 3742, 13, 50718], "temperature": 0.0, "avg_logprob": -0.2093127510764382, "compression_ratio": 1.75, "no_speech_prob": 0.001957008382305503}, {"id": 438, "seek": 228652, "start": 2293.6, "end": 2296.16, "text": " And so I'll show you what that looks like.", "tokens": [50718, 400, 370, 286, 603, 855, 291, 437, 300, 1542, 411, 13, 50846], "temperature": 0.0, "avg_logprob": -0.2093127510764382, "compression_ratio": 1.75, "no_speech_prob": 0.001957008382305503}, {"id": 439, "seek": 228652, "start": 2296.16, "end": 2297.48, "text": " So here's what that data looks like.", "tokens": [50846, 407, 510, 311, 437, 300, 1412, 1542, 411, 13, 50912], "temperature": 0.0, "avg_logprob": -0.2093127510764382, "compression_ratio": 1.75, "no_speech_prob": 0.001957008382305503}, {"id": 440, "seek": 228652, "start": 2297.48, "end": 2303.16, "text": " So the X's are the six centroids and the colored dots is the data.", "tokens": [50912, 407, 264, 1783, 311, 366, 264, 2309, 24607, 3742, 293, 264, 14332, 15026, 307, 264, 1412, 13, 51196], "temperature": 0.0, "avg_logprob": -0.2093127510764382, "compression_ratio": 1.75, "no_speech_prob": 0.001957008382305503}, {"id": 441, "seek": 228652, "start": 2303.16, "end": 2311.7599999999998, "text": " So if you were given this data without the X's, the idea would be to come back with figuring", "tokens": [51196, 407, 498, 291, 645, 2212, 341, 1412, 1553, 264, 1783, 311, 11, 264, 1558, 576, 312, 281, 808, 646, 365, 15213, 51626], "temperature": 0.0, "avg_logprob": -0.2093127510764382, "compression_ratio": 1.75, "no_speech_prob": 0.001957008382305503}, {"id": 442, "seek": 228652, "start": 2311.7599999999998, "end": 2313.36, "text": " out where the X's would have been.", "tokens": [51626, 484, 689, 264, 1783, 311, 576, 362, 668, 13, 51706], "temperature": 0.0, "avg_logprob": -0.2093127510764382, "compression_ratio": 1.75, "no_speech_prob": 0.001957008382305503}, {"id": 443, "seek": 228652, "start": 2313.36, "end": 2316.12, "text": " Like where are the, where are these clustering around?", "tokens": [51706, 1743, 689, 366, 264, 11, 689, 366, 613, 596, 48673, 926, 30, 51844], "temperature": 0.0, "avg_logprob": -0.2093127510764382, "compression_ratio": 1.75, "no_speech_prob": 0.001957008382305503}, {"id": 444, "seek": 231612, "start": 2316.72, "end": 2321.6, "text": " And so if you can get clusters, that's the goal here is to find out that there's a few", "tokens": [50394, 400, 370, 498, 291, 393, 483, 23313, 11, 300, 311, 264, 3387, 510, 307, 281, 915, 484, 300, 456, 311, 257, 1326, 50638], "temperature": 0.0, "avg_logprob": -0.2559377902022032, "compression_ratio": 1.7160493827160495, "no_speech_prob": 2.3687989596510306e-06}, {"id": 445, "seek": 231612, "start": 2321.6, "end": 2325.8399999999997, "text": " discreetly distinctly different types of data in your data set.", "tokens": [50638, 2983, 4751, 356, 10644, 356, 819, 3467, 295, 1412, 294, 428, 1412, 992, 13, 50850], "temperature": 0.0, "avg_logprob": -0.2559377902022032, "compression_ratio": 1.7160493827160495, "no_speech_prob": 2.3687989596510306e-06}, {"id": 446, "seek": 231612, "start": 2325.8399999999997, "end": 2331.08, "text": " So for example, for images, I've used this before to discover that there are some images", "tokens": [50850, 407, 337, 1365, 11, 337, 5267, 11, 286, 600, 1143, 341, 949, 281, 4411, 300, 456, 366, 512, 5267, 51112], "temperature": 0.0, "avg_logprob": -0.2559377902022032, "compression_ratio": 1.7160493827160495, "no_speech_prob": 2.3687989596510306e-06}, {"id": 447, "seek": 231612, "start": 2331.08, "end": 2333.12, "text": " that look completely different to all the other ones.", "tokens": [51112, 300, 574, 2584, 819, 281, 439, 264, 661, 2306, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2559377902022032, "compression_ratio": 1.7160493827160495, "no_speech_prob": 2.3687989596510306e-06}, {"id": 448, "seek": 231612, "start": 2333.12, "end": 2336.6, "text": " For example, they were taken at nighttime or they're of a different object or something", "tokens": [51214, 1171, 1365, 11, 436, 645, 2726, 412, 38595, 420, 436, 434, 295, 257, 819, 2657, 420, 746, 51388], "temperature": 0.0, "avg_logprob": -0.2559377902022032, "compression_ratio": 1.7160493827160495, "no_speech_prob": 2.3687989596510306e-06}, {"id": 449, "seek": 231612, "start": 2336.6, "end": 2338.8599999999997, "text": " like that.", "tokens": [51388, 411, 300, 13, 51501], "temperature": 0.0, "avg_logprob": -0.2559377902022032, "compression_ratio": 1.7160493827160495, "no_speech_prob": 2.3687989596510306e-06}, {"id": 450, "seek": 231612, "start": 2338.8599999999997, "end": 2341.2, "text": " So how does sample work?", "tokens": [51501, 407, 577, 775, 6889, 589, 30, 51618], "temperature": 0.0, "avg_logprob": -0.2559377902022032, "compression_ratio": 1.7160493827160495, "no_speech_prob": 2.3687989596510306e-06}, {"id": 451, "seek": 234120, "start": 2341.2799999999997, "end": 2345.4399999999996, "text": " We're passing in the centroid.", "tokens": [50368, 492, 434, 8437, 294, 264, 1489, 6490, 13, 50576], "temperature": 0.0, "avg_logprob": -0.21353191553160203, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0003250355657655746}, {"id": 452, "seek": 234120, "start": 2345.4399999999996, "end": 2355.8799999999997, "text": " And so what we want is we're going to get back.", "tokens": [50576, 400, 370, 437, 321, 528, 307, 321, 434, 516, 281, 483, 646, 13, 51098], "temperature": 0.0, "avg_logprob": -0.21353191553160203, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0003250355657655746}, {"id": 453, "seek": 234120, "start": 2355.8799999999997, "end": 2358.56, "text": " So each of those centroids contains an X and a Y.", "tokens": [51098, 407, 1184, 295, 729, 24607, 3742, 8306, 364, 1783, 293, 257, 398, 13, 51232], "temperature": 0.0, "avg_logprob": -0.21353191553160203, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0003250355657655746}, {"id": 454, "seek": 234120, "start": 2358.56, "end": 2361.0, "text": " So multivariate normal is just like normal.", "tokens": [51232, 407, 2120, 592, 3504, 473, 2710, 307, 445, 411, 2710, 13, 51354], "temperature": 0.0, "avg_logprob": -0.21353191553160203, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0003250355657655746}, {"id": 455, "seek": 234120, "start": 2361.0, "end": 2366.2799999999997, "text": " It's going to give you back normally distributed data, but more than one item.", "tokens": [51354, 467, 311, 516, 281, 976, 291, 646, 5646, 12631, 1412, 11, 457, 544, 813, 472, 3174, 13, 51618], "temperature": 0.0, "avg_logprob": -0.21353191553160203, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0003250355657655746}, {"id": 456, "seek": 234120, "start": 2366.2799999999997, "end": 2367.72, "text": " That's why it's multivariate.", "tokens": [51618, 663, 311, 983, 309, 311, 2120, 592, 3504, 473, 13, 51690], "temperature": 0.0, "avg_logprob": -0.21353191553160203, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0003250355657655746}, {"id": 457, "seek": 236772, "start": 2367.72, "end": 2372.7799999999997, "text": " And so we passed in two means, a mean for X and a mean for our Y.", "tokens": [50364, 400, 370, 321, 4678, 294, 732, 1355, 11, 257, 914, 337, 1783, 293, 257, 914, 337, 527, 398, 13, 50617], "temperature": 0.0, "avg_logprob": -0.2421971913930532, "compression_ratio": 1.7173913043478262, "no_speech_prob": 5.6497843615943566e-05}, {"id": 458, "seek": 236772, "start": 2372.7799999999997, "end": 2375.08, "text": " And so that's the mean that we're going to get.", "tokens": [50617, 400, 370, 300, 311, 264, 914, 300, 321, 434, 516, 281, 483, 13, 50732], "temperature": 0.0, "avg_logprob": -0.2421971913930532, "compression_ratio": 1.7173913043478262, "no_speech_prob": 5.6497843615943566e-05}, {"id": 459, "seek": 236772, "start": 2375.08, "end": 2379.02, "text": " And our standard deviation is going to be 5.", "tokens": [50732, 400, 527, 3832, 25163, 307, 516, 281, 312, 1025, 13, 50929], "temperature": 0.0, "avg_logprob": -0.2421971913930532, "compression_ratio": 1.7173913043478262, "no_speech_prob": 5.6497843615943566e-05}, {"id": 460, "seek": 236772, "start": 2379.02, "end": 2382.24, "text": " Why do we use torch.diag 5,5?", "tokens": [50929, 1545, 360, 321, 764, 27822, 13, 4504, 559, 1025, 11, 20, 30, 51090], "temperature": 0.0, "avg_logprob": -0.2421971913930532, "compression_ratio": 1.7173913043478262, "no_speech_prob": 5.6497843615943566e-05}, {"id": 461, "seek": 236772, "start": 2382.24, "end": 2387.8799999999997, "text": " That's because we're saying that's because for multivariate normal distributions, there's", "tokens": [51090, 663, 311, 570, 321, 434, 1566, 300, 311, 570, 337, 2120, 592, 3504, 473, 2710, 37870, 11, 456, 311, 51372], "temperature": 0.0, "avg_logprob": -0.2421971913930532, "compression_ratio": 1.7173913043478262, "no_speech_prob": 5.6497843615943566e-05}, {"id": 462, "seek": 236772, "start": 2387.8799999999997, "end": 2392.7599999999998, "text": " not just one standard deviation for each column that you get back.", "tokens": [51372, 406, 445, 472, 3832, 25163, 337, 1184, 7738, 300, 291, 483, 646, 13, 51616], "temperature": 0.0, "avg_logprob": -0.2421971913930532, "compression_ratio": 1.7173913043478262, "no_speech_prob": 5.6497843615943566e-05}, {"id": 463, "seek": 236772, "start": 2392.7599999999998, "end": 2395.7599999999998, "text": " There could also be a connection between columns.", "tokens": [51616, 821, 727, 611, 312, 257, 4984, 1296, 13766, 13, 51766], "temperature": 0.0, "avg_logprob": -0.2421971913930532, "compression_ratio": 1.7173913043478262, "no_speech_prob": 5.6497843615943566e-05}, {"id": 464, "seek": 239576, "start": 2395.8, "end": 2398.0800000000004, "text": " So columns might not be independent.", "tokens": [50366, 407, 13766, 1062, 406, 312, 6695, 13, 50480], "temperature": 0.0, "avg_logprob": -0.2458724628795277, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.141899550333619e-05}, {"id": 465, "seek": 239576, "start": 2398.0800000000004, "end": 2404.96, "text": " So you actually need what's called a covariance matrix, not just a variance.", "tokens": [50480, 407, 291, 767, 643, 437, 311, 1219, 257, 49851, 719, 8141, 11, 406, 445, 257, 21977, 13, 50824], "temperature": 0.0, "avg_logprob": -0.2458724628795277, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.141899550333619e-05}, {"id": 466, "seek": 239576, "start": 2404.96, "end": 2408.6400000000003, "text": " We discuss that a little bit more in lesson 9b, if you're interested in learning more", "tokens": [50824, 492, 2248, 300, 257, 707, 857, 544, 294, 6898, 1722, 65, 11, 498, 291, 434, 3102, 294, 2539, 544, 51008], "temperature": 0.0, "avg_logprob": -0.2458724628795277, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.141899550333619e-05}, {"id": 467, "seek": 239576, "start": 2408.6400000000003, "end": 2409.6400000000003, "text": " about that.", "tokens": [51008, 466, 300, 13, 51058], "temperature": 0.0, "avg_logprob": -0.2458724628795277, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.141899550333619e-05}, {"id": 468, "seek": 239576, "start": 2409.6400000000003, "end": 2413.5200000000004, "text": " Okay, so this is something that's going to give us back random columns of data with this", "tokens": [51058, 1033, 11, 370, 341, 307, 746, 300, 311, 516, 281, 976, 505, 646, 4974, 13766, 295, 1412, 365, 341, 51252], "temperature": 0.0, "avg_logprob": -0.2458724628795277, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.141899550333619e-05}, {"id": 469, "seek": 239576, "start": 2413.5200000000004, "end": 2416.5600000000004, "text": " mean and this standard deviation.", "tokens": [51252, 914, 293, 341, 3832, 25163, 13, 51404], "temperature": 0.0, "avg_logprob": -0.2458724628795277, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.141899550333619e-05}, {"id": 470, "seek": 239576, "start": 2416.5600000000004, "end": 2420.32, "text": " And this is the number of samples that we want.", "tokens": [51404, 400, 341, 307, 264, 1230, 295, 10938, 300, 321, 528, 13, 51592], "temperature": 0.0, "avg_logprob": -0.2458724628795277, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.141899550333619e-05}, {"id": 471, "seek": 239576, "start": 2420.32, "end": 2422.1600000000003, "text": " And this is coming from PyTorch.", "tokens": [51592, 400, 341, 307, 1348, 490, 9953, 51, 284, 339, 13, 51684], "temperature": 0.0, "avg_logprob": -0.2458724628795277, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.141899550333619e-05}, {"id": 472, "seek": 242216, "start": 2422.16, "end": 2426.48, "text": " So PyTorch has a whole bunch of different distributions that you can use, which can", "tokens": [50364, 407, 9953, 51, 284, 339, 575, 257, 1379, 3840, 295, 819, 37870, 300, 291, 393, 764, 11, 597, 393, 50580], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 473, "seek": 242216, "start": 2426.48, "end": 2429.2, "text": " be very handy.", "tokens": [50580, 312, 588, 13239, 13, 50716], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 474, "seek": 242216, "start": 2429.2, "end": 2431.12, "text": " So there's our data.", "tokens": [50716, 407, 456, 311, 527, 1412, 13, 50812], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 475, "seek": 242216, "start": 2431.12, "end": 2438.2799999999997, "text": " Okay, so remember for clustering, we don't know the different colors.", "tokens": [50812, 1033, 11, 370, 1604, 337, 596, 48673, 11, 321, 500, 380, 458, 264, 819, 4577, 13, 51170], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 476, "seek": 242216, "start": 2438.2799999999997, "end": 2439.68, "text": " And we don't know where the Xs are.", "tokens": [51170, 400, 321, 500, 380, 458, 689, 264, 1783, 82, 366, 13, 51240], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 477, "seek": 242216, "start": 2439.68, "end": 2442.48, "text": " That's kind of our job is to figure that out.", "tokens": [51240, 663, 311, 733, 295, 527, 1691, 307, 281, 2573, 300, 484, 13, 51380], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 478, "seek": 242216, "start": 2442.48, "end": 2445.12, "text": " We might just briefly also look at how to plot.", "tokens": [51380, 492, 1062, 445, 10515, 611, 574, 412, 577, 281, 7542, 13, 51512], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 479, "seek": 242216, "start": 2445.12, "end": 2448.72, "text": " So in this case, we want to plot the Xs.", "tokens": [51512, 407, 294, 341, 1389, 11, 321, 528, 281, 7542, 264, 1783, 82, 13, 51692], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 480, "seek": 242216, "start": 2448.72, "end": 2450.8799999999997, "text": " And we want to plot the data.", "tokens": [51692, 400, 321, 528, 281, 7542, 264, 1412, 13, 51800], "temperature": 0.0, "avg_logprob": -0.29016456604003904, "compression_ratio": 1.638655462184874, "no_speech_prob": 1.9223169147153385e-05}, {"id": 481, "seek": 245088, "start": 2450.88, "end": 2452.1600000000003, "text": " So it looks like this.", "tokens": [50364, 407, 309, 1542, 411, 341, 13, 50428], "temperature": 0.0, "avg_logprob": -0.22761854212334814, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.002396724885329604}, {"id": 482, "seek": 245088, "start": 2452.1600000000003, "end": 2456.6, "text": " So all I do is I loop through each centroid.", "tokens": [50428, 407, 439, 286, 360, 307, 286, 6367, 807, 1184, 1489, 6490, 13, 50650], "temperature": 0.0, "avg_logprob": -0.22761854212334814, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.002396724885329604}, {"id": 483, "seek": 245088, "start": 2456.6, "end": 2461.28, "text": " And I grab that centroid samples, and they're just all done in order.", "tokens": [50650, 400, 286, 4444, 300, 1489, 6490, 10938, 11, 293, 436, 434, 445, 439, 1096, 294, 1668, 13, 50884], "temperature": 0.0, "avg_logprob": -0.22761854212334814, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.002396724885329604}, {"id": 484, "seek": 245088, "start": 2461.28, "end": 2469.88, "text": " So I grab it from i times n samples up to i plus 1 times n samples.", "tokens": [50884, 407, 286, 4444, 309, 490, 741, 1413, 297, 10938, 493, 281, 741, 1804, 502, 1413, 297, 10938, 13, 51314], "temperature": 0.0, "avg_logprob": -0.22761854212334814, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.002396724885329604}, {"id": 485, "seek": 245088, "start": 2469.88, "end": 2474.04, "text": " And then I create a scatterplot with the samples on them.", "tokens": [51314, 400, 550, 286, 1884, 257, 34951, 564, 310, 365, 264, 10938, 322, 552, 13, 51522], "temperature": 0.0, "avg_logprob": -0.22761854212334814, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.002396724885329604}, {"id": 486, "seek": 245088, "start": 2474.04, "end": 2478.2000000000003, "text": " And what I've done is I've created an axis here.", "tokens": [51522, 400, 437, 286, 600, 1096, 307, 286, 600, 2942, 364, 10298, 510, 13, 51730], "temperature": 0.0, "avg_logprob": -0.22761854212334814, "compression_ratio": 1.6507936507936507, "no_speech_prob": 0.002396724885329604}, {"id": 487, "seek": 247820, "start": 2478.2, "end": 2481.7599999999998, "text": " You'll see why later that we can also pass one in, but I'm not passing one in.", "tokens": [50364, 509, 603, 536, 983, 1780, 300, 321, 393, 611, 1320, 472, 294, 11, 457, 286, 478, 406, 8437, 472, 294, 13, 50542], "temperature": 0.0, "avg_logprob": -0.2629073267397673, "compression_ratio": 1.6872037914691944, "no_speech_prob": 0.00027372140903025866}, {"id": 488, "seek": 247820, "start": 2481.7599999999998, "end": 2484.3599999999997, "text": " So we create a plot and an axis.", "tokens": [50542, 407, 321, 1884, 257, 7542, 293, 364, 10298, 13, 50672], "temperature": 0.0, "avg_logprob": -0.2629073267397673, "compression_ratio": 1.6872037914691944, "no_speech_prob": 0.00027372140903025866}, {"id": 489, "seek": 247820, "start": 2484.3599999999997, "end": 2490.3999999999996, "text": " And so in matplotlib, you can keep plotting things on the same axis.", "tokens": [50672, 400, 370, 294, 3803, 564, 310, 38270, 11, 291, 393, 1066, 41178, 721, 322, 264, 912, 10298, 13, 50974], "temperature": 0.0, "avg_logprob": -0.2629073267397673, "compression_ratio": 1.6872037914691944, "no_speech_prob": 0.00027372140903025866}, {"id": 490, "seek": 247820, "start": 2490.3999999999996, "end": 2500.96, "text": " So then I plot on the centroid a big X, which is black, and then a smaller X, which is,", "tokens": [50974, 407, 550, 286, 7542, 322, 264, 1489, 6490, 257, 955, 1783, 11, 597, 307, 2211, 11, 293, 550, 257, 4356, 1783, 11, 597, 307, 11, 51502], "temperature": 0.0, "avg_logprob": -0.2629073267397673, "compression_ratio": 1.6872037914691944, "no_speech_prob": 0.00027372140903025866}, {"id": 491, "seek": 247820, "start": 2500.96, "end": 2502.04, "text": " what is that, magenta.", "tokens": [51502, 437, 307, 300, 11, 2258, 8938, 13, 51556], "temperature": 0.0, "avg_logprob": -0.2629073267397673, "compression_ratio": 1.6872037914691944, "no_speech_prob": 0.00027372140903025866}, {"id": 492, "seek": 247820, "start": 2502.04, "end": 2503.3599999999997, "text": " And so that's how I get these Xs.", "tokens": [51556, 400, 370, 300, 311, 577, 286, 483, 613, 1783, 82, 13, 51622], "temperature": 0.0, "avg_logprob": -0.2629073267397673, "compression_ratio": 1.6872037914691944, "no_speech_prob": 0.00027372140903025866}, {"id": 493, "seek": 247820, "start": 2503.3599999999997, "end": 2506.16, "text": " So that's how plot data works.", "tokens": [51622, 407, 300, 311, 577, 7542, 1412, 1985, 13, 51762], "temperature": 0.0, "avg_logprob": -0.2629073267397673, "compression_ratio": 1.6872037914691944, "no_speech_prob": 0.00027372140903025866}, {"id": 494, "seek": 250616, "start": 2507.12, "end": 2512.6, "text": " Okay, so how do we create something now that starts with all the dots and returns where", "tokens": [50412, 1033, 11, 370, 577, 360, 321, 1884, 746, 586, 300, 3719, 365, 439, 264, 15026, 293, 11247, 689, 50686], "temperature": 0.0, "avg_logprob": -0.3763808822631836, "compression_ratio": 1.4402985074626866, "no_speech_prob": 3.089493930019671e-06}, {"id": 495, "seek": 250616, "start": 2512.6, "end": 2516.12, "text": " the Xs are?", "tokens": [50686, 264, 1783, 82, 366, 30, 50862], "temperature": 0.0, "avg_logprob": -0.3763808822631836, "compression_ratio": 1.4402985074626866, "no_speech_prob": 3.089493930019671e-06}, {"id": 496, "seek": 250616, "start": 2516.12, "end": 2524.64, "text": " We're going to use a particular algorithm, particular clustering algorithm called mean", "tokens": [50862, 492, 434, 516, 281, 764, 257, 1729, 9284, 11, 1729, 596, 48673, 9284, 1219, 914, 51288], "temperature": 0.0, "avg_logprob": -0.3763808822631836, "compression_ratio": 1.4402985074626866, "no_speech_prob": 3.089493930019671e-06}, {"id": 497, "seek": 250616, "start": 2524.64, "end": 2526.72, "text": " shift.", "tokens": [51288, 5513, 13, 51392], "temperature": 0.0, "avg_logprob": -0.3763808822631836, "compression_ratio": 1.4402985074626866, "no_speech_prob": 3.089493930019671e-06}, {"id": 498, "seek": 252672, "start": 2526.72, "end": 2536.72, "text": " And mean shift is a nice clustering approach, because you don't have to say how many clusters", "tokens": [50364, 400, 914, 5513, 307, 257, 1481, 596, 48673, 3109, 11, 570, 291, 500, 380, 362, 281, 584, 577, 867, 23313, 50864], "temperature": 0.0, "avg_logprob": -0.24859557280669342, "compression_ratio": 1.774468085106383, "no_speech_prob": 9.461258014198393e-05}, {"id": 499, "seek": 252672, "start": 2536.72, "end": 2537.7999999999997, "text": " there are.", "tokens": [50864, 456, 366, 13, 50918], "temperature": 0.0, "avg_logprob": -0.24859557280669342, "compression_ratio": 1.774468085106383, "no_speech_prob": 9.461258014198393e-05}, {"id": 500, "seek": 252672, "start": 2537.7999999999997, "end": 2541.08, "text": " So it's not that often that you actually got to know how many clusters there are.", "tokens": [50918, 407, 309, 311, 406, 300, 2049, 300, 291, 767, 658, 281, 458, 577, 867, 23313, 456, 366, 13, 51082], "temperature": 0.0, "avg_logprob": -0.24859557280669342, "compression_ratio": 1.774468085106383, "no_speech_prob": 9.461258014198393e-05}, {"id": 501, "seek": 252672, "start": 2541.08, "end": 2542.08, "text": " So we don't have to say.", "tokens": [51082, 407, 321, 500, 380, 362, 281, 584, 13, 51132], "temperature": 0.0, "avg_logprob": -0.24859557280669342, "compression_ratio": 1.774468085106383, "no_speech_prob": 9.461258014198393e-05}, {"id": 502, "seek": 252672, "start": 2542.08, "end": 2547.4399999999996, "text": " Quite a few things, like the very popular k-means, require you to say how many.", "tokens": [51132, 20464, 257, 1326, 721, 11, 411, 264, 588, 3743, 350, 12, 1398, 599, 11, 3651, 291, 281, 584, 577, 867, 13, 51400], "temperature": 0.0, "avg_logprob": -0.24859557280669342, "compression_ratio": 1.774468085106383, "no_speech_prob": 9.461258014198393e-05}, {"id": 503, "seek": 252672, "start": 2547.4399999999996, "end": 2549.9599999999996, "text": " Instead we just have to pass them in called a bandwidth, which we'll learn about, which", "tokens": [51400, 7156, 321, 445, 362, 281, 1320, 552, 294, 1219, 257, 23647, 11, 597, 321, 603, 1466, 466, 11, 597, 51526], "temperature": 0.0, "avg_logprob": -0.24859557280669342, "compression_ratio": 1.774468085106383, "no_speech_prob": 9.461258014198393e-05}, {"id": 504, "seek": 252672, "start": 2549.9599999999996, "end": 2552.8399999999997, "text": " can actually be chosen automatically.", "tokens": [51526, 393, 767, 312, 8614, 6772, 13, 51670], "temperature": 0.0, "avg_logprob": -0.24859557280669342, "compression_ratio": 1.774468085106383, "no_speech_prob": 9.461258014198393e-05}, {"id": 505, "seek": 255284, "start": 2552.84, "end": 2555.8, "text": " And it can also handle clusters of any shape.", "tokens": [50364, 400, 309, 393, 611, 4813, 23313, 295, 604, 3909, 13, 50512], "temperature": 0.0, "avg_logprob": -0.2511628203921848, "compression_ratio": 1.5, "no_speech_prob": 0.0008693560375832021}, {"id": 506, "seek": 255284, "start": 2555.8, "end": 2558.6400000000003, "text": " So they don't have to be ball-shaped like they are here.", "tokens": [50512, 407, 436, 500, 380, 362, 281, 312, 2594, 12, 23103, 411, 436, 366, 510, 13, 50654], "temperature": 0.0, "avg_logprob": -0.2511628203921848, "compression_ratio": 1.5, "no_speech_prob": 0.0008693560375832021}, {"id": 507, "seek": 255284, "start": 2558.6400000000003, "end": 2564.1600000000003, "text": " They can be kind of like L-shaped or ellipse-shaped or whatever.", "tokens": [50654, 814, 393, 312, 733, 295, 411, 441, 12, 23103, 420, 8284, 48041, 12, 23103, 420, 2035, 13, 50930], "temperature": 0.0, "avg_logprob": -0.2511628203921848, "compression_ratio": 1.5, "no_speech_prob": 0.0008693560375832021}, {"id": 508, "seek": 255284, "start": 2564.1600000000003, "end": 2572.4, "text": " And so here's what's going to happen.", "tokens": [50930, 400, 370, 510, 311, 437, 311, 516, 281, 1051, 13, 51342], "temperature": 0.0, "avg_logprob": -0.2511628203921848, "compression_ratio": 1.5, "no_speech_prob": 0.0008693560375832021}, {"id": 509, "seek": 255284, "start": 2572.4, "end": 2577.04, "text": " We're going to pick some point.", "tokens": [51342, 492, 434, 516, 281, 1888, 512, 935, 13, 51574], "temperature": 0.0, "avg_logprob": -0.2511628203921848, "compression_ratio": 1.5, "no_speech_prob": 0.0008693560375832021}, {"id": 510, "seek": 257704, "start": 2577.04, "end": 2583.7599999999998, "text": " So let's say we pick that point just there.", "tokens": [50364, 407, 718, 311, 584, 321, 1888, 300, 935, 445, 456, 13, 50700], "temperature": 0.0, "avg_logprob": -0.26681496804220634, "compression_ratio": 1.550387596899225, "no_speech_prob": 0.00011959735275013372}, {"id": 511, "seek": 257704, "start": 2583.7599999999998, "end": 2588.68, "text": " And so what we now do is we go through each data point.", "tokens": [50700, 400, 370, 437, 321, 586, 360, 307, 321, 352, 807, 1184, 1412, 935, 13, 50946], "temperature": 0.0, "avg_logprob": -0.26681496804220634, "compression_ratio": 1.550387596899225, "no_speech_prob": 0.00011959735275013372}, {"id": 512, "seek": 257704, "start": 2588.68, "end": 2590.4, "text": " So we pick the first one.", "tokens": [50946, 407, 321, 1888, 264, 700, 472, 13, 51032], "temperature": 0.0, "avg_logprob": -0.26681496804220634, "compression_ratio": 1.550387596899225, "no_speech_prob": 0.00011959735275013372}, {"id": 513, "seek": 257704, "start": 2590.4, "end": 2597.24, "text": " And so we then find the distance between that point and every other point.", "tokens": [51032, 400, 370, 321, 550, 915, 264, 4560, 1296, 300, 935, 293, 633, 661, 935, 13, 51374], "temperature": 0.0, "avg_logprob": -0.26681496804220634, "compression_ratio": 1.550387596899225, "no_speech_prob": 0.00011959735275013372}, {"id": 514, "seek": 259724, "start": 2597.24, "end": 2610.0, "text": " So we're going to have to say what is the distance between that point and that point,", "tokens": [50364, 407, 321, 434, 516, 281, 362, 281, 584, 437, 307, 264, 4560, 1296, 300, 935, 293, 300, 935, 11, 51002], "temperature": 0.0, "avg_logprob": -0.2911379072401259, "compression_ratio": 1.9235668789808917, "no_speech_prob": 0.0007436899468302727}, {"id": 515, "seek": 259724, "start": 2610.0, "end": 2614.4399999999996, "text": " and that point and that point, and that point and that point, and also the ones further", "tokens": [51002, 293, 300, 935, 293, 300, 935, 11, 293, 300, 935, 293, 300, 935, 11, 293, 611, 264, 2306, 3052, 51224], "temperature": 0.0, "avg_logprob": -0.2911379072401259, "compression_ratio": 1.9235668789808917, "no_speech_prob": 0.0007436899468302727}, {"id": 516, "seek": 259724, "start": 2614.4399999999996, "end": 2615.4399999999996, "text": " away.", "tokens": [51224, 1314, 13, 51274], "temperature": 0.0, "avg_logprob": -0.2911379072401259, "compression_ratio": 1.9235668789808917, "no_speech_prob": 0.0007436899468302727}, {"id": 517, "seek": 259724, "start": 2615.4399999999996, "end": 2616.9599999999996, "text": " That point and that point.", "tokens": [51274, 663, 935, 293, 300, 935, 13, 51350], "temperature": 0.0, "avg_logprob": -0.2911379072401259, "compression_ratio": 1.9235668789808917, "no_speech_prob": 0.0007436899468302727}, {"id": 518, "seek": 259724, "start": 2616.9599999999996, "end": 2622.3599999999997, "text": " And you do it for every single point compared to the one that we're currently looking at.", "tokens": [51350, 400, 291, 360, 309, 337, 633, 2167, 935, 5347, 281, 264, 472, 300, 321, 434, 4362, 1237, 412, 13, 51620], "temperature": 0.0, "avg_logprob": -0.2911379072401259, "compression_ratio": 1.9235668789808917, "no_speech_prob": 0.0007436899468302727}, {"id": 519, "seek": 259724, "start": 2622.3599999999997, "end": 2623.54, "text": " Okay.", "tokens": [51620, 1033, 13, 51679], "temperature": 0.0, "avg_logprob": -0.2911379072401259, "compression_ratio": 1.9235668789808917, "no_speech_prob": 0.0007436899468302727}, {"id": 520, "seek": 262354, "start": 2623.54, "end": 2630.14, "text": " So we get all of those as a big list.", "tokens": [50364, 407, 321, 483, 439, 295, 729, 382, 257, 955, 1329, 13, 50694], "temperature": 0.0, "avg_logprob": -0.2471839359828404, "compression_ratio": 1.8440860215053763, "no_speech_prob": 3.2699255825718865e-05}, {"id": 521, "seek": 262354, "start": 2630.14, "end": 2635.34, "text": " And now what we're going to do is we're going to take a weighted average of all of those", "tokens": [50694, 400, 586, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 747, 257, 32807, 4274, 295, 439, 295, 729, 50954], "temperature": 0.0, "avg_logprob": -0.2471839359828404, "compression_ratio": 1.8440860215053763, "no_speech_prob": 3.2699255825718865e-05}, {"id": 522, "seek": 262354, "start": 2635.34, "end": 2636.86, "text": " points.", "tokens": [50954, 2793, 13, 51030], "temperature": 0.0, "avg_logprob": -0.2471839359828404, "compression_ratio": 1.8440860215053763, "no_speech_prob": 3.2699255825718865e-05}, {"id": 523, "seek": 262354, "start": 2636.86, "end": 2642.34, "text": " Now that's not interesting without the weighting.", "tokens": [51030, 823, 300, 311, 406, 1880, 1553, 264, 3364, 278, 13, 51304], "temperature": 0.0, "avg_logprob": -0.2471839359828404, "compression_ratio": 1.8440860215053763, "no_speech_prob": 3.2699255825718865e-05}, {"id": 524, "seek": 262354, "start": 2642.34, "end": 2647.46, "text": " If we just take an average of all of the points and how far away they are, we're going to", "tokens": [51304, 759, 321, 445, 747, 364, 4274, 295, 439, 295, 264, 2793, 293, 577, 1400, 1314, 436, 366, 11, 321, 434, 516, 281, 51560], "temperature": 0.0, "avg_logprob": -0.2471839359828404, "compression_ratio": 1.8440860215053763, "no_speech_prob": 3.2699255825718865e-05}, {"id": 525, "seek": 262354, "start": 2647.46, "end": 2648.9, "text": " end up somewhere here, right?", "tokens": [51560, 917, 493, 4079, 510, 11, 558, 30, 51632], "temperature": 0.0, "avg_logprob": -0.2471839359828404, "compression_ratio": 1.8440860215053763, "no_speech_prob": 3.2699255825718865e-05}, {"id": 526, "seek": 262354, "start": 2648.9, "end": 2651.18, "text": " This is the average of all the points.", "tokens": [51632, 639, 307, 264, 4274, 295, 439, 264, 2793, 13, 51746], "temperature": 0.0, "avg_logprob": -0.2471839359828404, "compression_ratio": 1.8440860215053763, "no_speech_prob": 3.2699255825718865e-05}, {"id": 527, "seek": 265118, "start": 2651.18, "end": 2654.46, "text": " But the key is that we're going to take an average.", "tokens": [50364, 583, 264, 2141, 307, 300, 321, 434, 516, 281, 747, 364, 4274, 13, 50528], "temperature": 0.0, "avg_logprob": -0.2873163445051326, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.0003740952233783901}, {"id": 528, "seek": 265118, "start": 2654.46, "end": 2660.62, "text": " Let me just find the right spot.", "tokens": [50528, 961, 385, 445, 915, 264, 558, 4008, 13, 50836], "temperature": 0.0, "avg_logprob": -0.2873163445051326, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.0003740952233783901}, {"id": 529, "seek": 265118, "start": 2660.62, "end": 2667.18, "text": " The key is we need to find an average that is weighted by how far away things are.", "tokens": [50836, 440, 2141, 307, 321, 643, 281, 915, 364, 4274, 300, 307, 32807, 538, 577, 1400, 1314, 721, 366, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2873163445051326, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.0003740952233783901}, {"id": 530, "seek": 265118, "start": 2667.18, "end": 2675.02, "text": " So for example, this one over here is a very long way away from our point of interest.", "tokens": [51164, 407, 337, 1365, 11, 341, 472, 670, 510, 307, 257, 588, 938, 636, 1314, 490, 527, 935, 295, 1179, 13, 51556], "temperature": 0.0, "avg_logprob": -0.2873163445051326, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.0003740952233783901}, {"id": 531, "seek": 265118, "start": 2675.02, "end": 2678.18, "text": " And so it should have a very low weight in the weighted average.", "tokens": [51556, 400, 370, 309, 820, 362, 257, 588, 2295, 3364, 294, 264, 32807, 4274, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2873163445051326, "compression_ratio": 1.6528497409326426, "no_speech_prob": 0.0003740952233783901}, {"id": 532, "seek": 267818, "start": 2678.18, "end": 2684.02, "text": " Whereas this point here, which is very close, should have a very high weight in our weighted", "tokens": [50364, 13813, 341, 935, 510, 11, 597, 307, 588, 1998, 11, 820, 362, 257, 588, 1090, 3364, 294, 527, 32807, 50656], "temperature": 0.0, "avg_logprob": -0.2649466951014632, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00021995295537635684}, {"id": 533, "seek": 267818, "start": 2684.02, "end": 2685.44, "text": " average.", "tokens": [50656, 4274, 13, 50727], "temperature": 0.0, "avg_logprob": -0.2649466951014632, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00021995295537635684}, {"id": 534, "seek": 267818, "start": 2685.44, "end": 2691.96, "text": " So what we do is we create weights for every point compared to the one that we're currently", "tokens": [50727, 407, 437, 321, 360, 307, 321, 1884, 17443, 337, 633, 935, 5347, 281, 264, 472, 300, 321, 434, 4362, 51053], "temperature": 0.0, "avg_logprob": -0.2649466951014632, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00021995295537635684}, {"id": 535, "seek": 267818, "start": 2691.96, "end": 2696.14, "text": " interested in, using a what's called a Gaussian kernel that we'll look at.", "tokens": [51053, 3102, 294, 11, 1228, 257, 437, 311, 1219, 257, 39148, 28256, 300, 321, 603, 574, 412, 13, 51262], "temperature": 0.0, "avg_logprob": -0.2649466951014632, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00021995295537635684}, {"id": 536, "seek": 267818, "start": 2696.14, "end": 2702.18, "text": " But the key thing to know is that points that are further away from our point of interest,", "tokens": [51262, 583, 264, 2141, 551, 281, 458, 307, 300, 2793, 300, 366, 3052, 1314, 490, 527, 935, 295, 1179, 11, 51564], "temperature": 0.0, "avg_logprob": -0.2649466951014632, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00021995295537635684}, {"id": 537, "seek": 267818, "start": 2702.18, "end": 2705.02, "text": " which is this one, are going to have lower weights.", "tokens": [51564, 597, 307, 341, 472, 11, 366, 516, 281, 362, 3126, 17443, 13, 51706], "temperature": 0.0, "avg_logprob": -0.2649466951014632, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00021995295537635684}, {"id": 538, "seek": 267818, "start": 2705.02, "end": 2706.02, "text": " That's what we mean there.", "tokens": [51706, 663, 311, 437, 321, 914, 456, 13, 51756], "temperature": 0.0, "avg_logprob": -0.2649466951014632, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00021995295537635684}, {"id": 539, "seek": 267818, "start": 2706.02, "end": 2707.6, "text": " They're penalized.", "tokens": [51756, 814, 434, 13661, 1602, 13, 51835], "temperature": 0.0, "avg_logprob": -0.2649466951014632, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.00021995295537635684}, {"id": 540, "seek": 270760, "start": 2707.6, "end": 2711.6, "text": " The rate at which weights fall to zero is determined by this thing that we set at the", "tokens": [50364, 440, 3314, 412, 597, 17443, 2100, 281, 4018, 307, 9540, 538, 341, 551, 300, 321, 992, 412, 264, 50564], "temperature": 0.0, "avg_logprob": -0.24295407153190451, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.8857119104941376e-05}, {"id": 541, "seek": 270760, "start": 2711.6, "end": 2713.6, "text": " start called the bandwidth.", "tokens": [50564, 722, 1219, 264, 23647, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24295407153190451, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.8857119104941376e-05}, {"id": 542, "seek": 270760, "start": 2713.6, "end": 2717.16, "text": " And that's going to be the standard deviation of our Gaussian.", "tokens": [50664, 400, 300, 311, 516, 281, 312, 264, 3832, 25163, 295, 527, 39148, 13, 50842], "temperature": 0.0, "avg_logprob": -0.24295407153190451, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.8857119104941376e-05}, {"id": 543, "seek": 270760, "start": 2717.16, "end": 2722.36, "text": " So we take an average of all the points in the data set, a weighted average weighted", "tokens": [50842, 407, 321, 747, 364, 4274, 295, 439, 264, 2793, 294, 264, 1412, 992, 11, 257, 32807, 4274, 32807, 51102], "temperature": 0.0, "avg_logprob": -0.24295407153190451, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.8857119104941376e-05}, {"id": 544, "seek": 270760, "start": 2722.36, "end": 2725.16, "text": " by how far away they are.", "tokens": [51102, 538, 577, 1400, 1314, 436, 366, 13, 51242], "temperature": 0.0, "avg_logprob": -0.24295407153190451, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.8857119104941376e-05}, {"id": 545, "seek": 270760, "start": 2725.16, "end": 2736.92, "text": " So for our point of interest, right, this point's going to get a big weight.", "tokens": [51242, 407, 337, 527, 935, 295, 1179, 11, 558, 11, 341, 935, 311, 516, 281, 483, 257, 955, 3364, 13, 51830], "temperature": 0.0, "avg_logprob": -0.24295407153190451, "compression_ratio": 1.6930232558139535, "no_speech_prob": 2.8857119104941376e-05}, {"id": 546, "seek": 273692, "start": 2736.92, "end": 2738.52, "text": " This point's going to get a big weight.", "tokens": [50364, 639, 935, 311, 516, 281, 483, 257, 955, 3364, 13, 50444], "temperature": 0.0, "avg_logprob": -0.2075697382291158, "compression_ratio": 2.2229299363057327, "no_speech_prob": 6.605214002775028e-05}, {"id": 547, "seek": 273692, "start": 2738.52, "end": 2740.7200000000003, "text": " This point's going to get a big weight.", "tokens": [50444, 639, 935, 311, 516, 281, 483, 257, 955, 3364, 13, 50554], "temperature": 0.0, "avg_logprob": -0.2075697382291158, "compression_ratio": 2.2229299363057327, "no_speech_prob": 6.605214002775028e-05}, {"id": 548, "seek": 273692, "start": 2740.7200000000003, "end": 2743.6, "text": " That point's going to get a tiny weight.", "tokens": [50554, 663, 935, 311, 516, 281, 483, 257, 5870, 3364, 13, 50698], "temperature": 0.0, "avg_logprob": -0.2075697382291158, "compression_ratio": 2.2229299363057327, "no_speech_prob": 6.605214002775028e-05}, {"id": 549, "seek": 273692, "start": 2743.6, "end": 2746.1, "text": " That point's going to get an even tinier weight.", "tokens": [50698, 663, 935, 311, 516, 281, 483, 364, 754, 15935, 811, 3364, 13, 50823], "temperature": 0.0, "avg_logprob": -0.2075697382291158, "compression_ratio": 2.2229299363057327, "no_speech_prob": 6.605214002775028e-05}, {"id": 550, "seek": 273692, "start": 2746.1, "end": 2756.4, "text": " So it's mainly going to be a weighted average of these points that are nearby.", "tokens": [50823, 407, 309, 311, 8704, 516, 281, 312, 257, 32807, 4274, 295, 613, 2793, 300, 366, 11184, 13, 51338], "temperature": 0.0, "avg_logprob": -0.2075697382291158, "compression_ratio": 2.2229299363057327, "no_speech_prob": 6.605214002775028e-05}, {"id": 551, "seek": 273692, "start": 2756.4, "end": 2760.76, "text": " And the weighted average of those points, I would guess, is going to be somewhere around", "tokens": [51338, 400, 264, 32807, 4274, 295, 729, 2793, 11, 286, 576, 2041, 11, 307, 516, 281, 312, 4079, 926, 51556], "temperature": 0.0, "avg_logprob": -0.2075697382291158, "compression_ratio": 2.2229299363057327, "no_speech_prob": 6.605214002775028e-05}, {"id": 552, "seek": 273692, "start": 2760.76, "end": 2764.8, "text": " about here.", "tokens": [51556, 466, 510, 13, 51758], "temperature": 0.0, "avg_logprob": -0.2075697382291158, "compression_ratio": 2.2229299363057327, "no_speech_prob": 6.605214002775028e-05}, {"id": 553, "seek": 276480, "start": 2764.84, "end": 2768.6800000000003, "text": " And we'd have a similar thing for the weighted average of the points near this one.", "tokens": [50366, 400, 321, 1116, 362, 257, 2531, 551, 337, 264, 32807, 4274, 295, 264, 2793, 2651, 341, 472, 13, 50558], "temperature": 0.0, "avg_logprob": -0.2751243960472845, "compression_ratio": 1.699530516431925, "no_speech_prob": 6.64343269818346e-06}, {"id": 554, "seek": 276480, "start": 2768.6800000000003, "end": 2774.8, "text": " That's going to probably be somewhere around about here, right, or maybe over here.", "tokens": [50558, 663, 311, 516, 281, 1391, 312, 4079, 926, 466, 510, 11, 558, 11, 420, 1310, 670, 510, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2751243960472845, "compression_ratio": 1.699530516431925, "no_speech_prob": 6.64343269818346e-06}, {"id": 555, "seek": 276480, "start": 2774.8, "end": 2777.6800000000003, "text": " And so it's going to move all of these points in closer.", "tokens": [50864, 400, 370, 309, 311, 516, 281, 1286, 439, 295, 613, 2793, 294, 4966, 13, 51008], "temperature": 0.0, "avg_logprob": -0.2751243960472845, "compression_ratio": 1.699530516431925, "no_speech_prob": 6.64343269818346e-06}, {"id": 556, "seek": 276480, "start": 2777.6800000000003, "end": 2779.84, "text": " It's almost like a gravity, right?", "tokens": [51008, 467, 311, 1920, 411, 257, 12110, 11, 558, 30, 51116], "temperature": 0.0, "avg_logprob": -0.2751243960472845, "compression_ratio": 1.699530516431925, "no_speech_prob": 6.64343269818346e-06}, {"id": 557, "seek": 276480, "start": 2779.84, "end": 2790.8, "text": " They're kind of going to be moved like closer and closer in towards this kind of gravitational", "tokens": [51116, 814, 434, 733, 295, 516, 281, 312, 4259, 411, 4966, 293, 4966, 294, 3030, 341, 733, 295, 28538, 51664], "temperature": 0.0, "avg_logprob": -0.2751243960472845, "compression_ratio": 1.699530516431925, "no_speech_prob": 6.64343269818346e-06}, {"id": 558, "seek": 276480, "start": 2790.8, "end": 2792.5, "text": " center.", "tokens": [51664, 3056, 13, 51749], "temperature": 0.0, "avg_logprob": -0.2751243960472845, "compression_ratio": 1.699530516431925, "no_speech_prob": 6.64343269818346e-06}, {"id": 559, "seek": 279250, "start": 2792.5, "end": 2799.74, "text": " And then these ones will go towards their own gravitational center, and so forth.", "tokens": [50364, 400, 550, 613, 2306, 486, 352, 3030, 641, 1065, 28538, 3056, 11, 293, 370, 5220, 13, 50726], "temperature": 0.0, "avg_logprob": -0.3178000305638169, "compression_ratio": 1.4642857142857142, "no_speech_prob": 3.591297718230635e-05}, {"id": 560, "seek": 279250, "start": 2799.74, "end": 2805.82, "text": " Okay, so let's take a look at it.", "tokens": [50726, 1033, 11, 370, 718, 311, 747, 257, 574, 412, 309, 13, 51030], "temperature": 0.0, "avg_logprob": -0.3178000305638169, "compression_ratio": 1.4642857142857142, "no_speech_prob": 3.591297718230635e-05}, {"id": 561, "seek": 279250, "start": 2805.82, "end": 2814.04, "text": " All right, so what's the Gaussian kernel?", "tokens": [51030, 1057, 558, 11, 370, 437, 311, 264, 39148, 28256, 30, 51441], "temperature": 0.0, "avg_logprob": -0.3178000305638169, "compression_ratio": 1.4642857142857142, "no_speech_prob": 3.591297718230635e-05}, {"id": 562, "seek": 279250, "start": 2814.04, "end": 2819.38, "text": " This is the Gaussian kernel, which was a sign in the original March for Science, back in", "tokens": [51441, 639, 307, 264, 39148, 28256, 11, 597, 390, 257, 1465, 294, 264, 3380, 6129, 337, 8976, 11, 646, 294, 51708], "temperature": 0.0, "avg_logprob": -0.3178000305638169, "compression_ratio": 1.4642857142857142, "no_speech_prob": 3.591297718230635e-05}, {"id": 563, "seek": 281938, "start": 2819.38, "end": 2825.2200000000003, "text": " the days when the idea of not following scientists was considered socially unacceptable.", "tokens": [50364, 264, 1708, 562, 264, 1558, 295, 406, 3480, 7708, 390, 4888, 21397, 31812, 13, 50656], "temperature": 0.0, "avg_logprob": -0.2685354511912276, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0006563722854480147}, {"id": 564, "seek": 281938, "start": 2825.2200000000003, "end": 2827.5, "text": " We used to have March for these things, if you remember.", "tokens": [50656, 492, 1143, 281, 362, 6129, 337, 613, 721, 11, 498, 291, 1604, 13, 50770], "temperature": 0.0, "avg_logprob": -0.2685354511912276, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0006563722854480147}, {"id": 565, "seek": 281938, "start": 2827.5, "end": 2831.1400000000003, "text": " So this is not normal.", "tokens": [50770, 407, 341, 307, 406, 2710, 13, 50952], "temperature": 0.0, "avg_logprob": -0.2685354511912276, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0006563722854480147}, {"id": 566, "seek": 281938, "start": 2831.1400000000003, "end": 2833.98, "text": " So this is the definition of the Gaussian kernel, which is also known as the normal", "tokens": [50952, 407, 341, 307, 264, 7123, 295, 264, 39148, 28256, 11, 597, 307, 611, 2570, 382, 264, 2710, 51094], "temperature": 0.0, "avg_logprob": -0.2685354511912276, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0006563722854480147}, {"id": 567, "seek": 281938, "start": 2833.98, "end": 2835.06, "text": " distribution.", "tokens": [51094, 7316, 13, 51148], "temperature": 0.0, "avg_logprob": -0.2685354511912276, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0006563722854480147}, {"id": 568, "seek": 281938, "start": 2835.06, "end": 2836.98, "text": " This is the shape of it.", "tokens": [51148, 639, 307, 264, 3909, 295, 309, 13, 51244], "temperature": 0.0, "avg_logprob": -0.2685354511912276, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0006563722854480147}, {"id": 569, "seek": 281938, "start": 2836.98, "end": 2840.34, "text": " Sure you've seen it before.", "tokens": [51244, 4894, 291, 600, 1612, 309, 949, 13, 51412], "temperature": 0.0, "avg_logprob": -0.2685354511912276, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0006563722854480147}, {"id": 570, "seek": 284034, "start": 2840.34, "end": 2847.6600000000003, "text": " And here is that formula copied directly off the Science March sign.", "tokens": [50364, 400, 510, 307, 300, 8513, 25365, 3838, 766, 264, 8976, 6129, 1465, 13, 50730], "temperature": 0.0, "avg_logprob": -0.3194977475195816, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0018102072644978762}, {"id": 571, "seek": 284034, "start": 2847.6600000000003, "end": 2851.82, "text": " Okay, here we are.", "tokens": [50730, 1033, 11, 510, 321, 366, 13, 50938], "temperature": 0.0, "avg_logprob": -0.3194977475195816, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0018102072644978762}, {"id": 572, "seek": 284034, "start": 2851.82, "end": 2854.94, "text": " See the square root, 2 pi, etc.", "tokens": [50938, 3008, 264, 3732, 5593, 11, 568, 3895, 11, 5183, 13, 51094], "temperature": 0.0, "avg_logprob": -0.3194977475195816, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0018102072644978762}, {"id": 573, "seek": 284034, "start": 2854.94, "end": 2858.34, "text": " Okay, and this here is the standard deviation.", "tokens": [51094, 1033, 11, 293, 341, 510, 307, 264, 3832, 25163, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3194977475195816, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0018102072644978762}, {"id": 574, "seek": 284034, "start": 2858.34, "end": 2859.5, "text": " Now what does that look like?", "tokens": [51264, 823, 437, 775, 300, 574, 411, 30, 51322], "temperature": 0.0, "avg_logprob": -0.3194977475195816, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0018102072644978762}, {"id": 575, "seek": 284034, "start": 2859.5, "end": 2865.38, "text": " It's very helpful to have something that we can very quickly plot any function.", "tokens": [51322, 467, 311, 588, 4961, 281, 362, 746, 300, 321, 393, 588, 2661, 7542, 604, 2445, 13, 51616], "temperature": 0.0, "avg_logprob": -0.3194977475195816, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0018102072644978762}, {"id": 576, "seek": 284034, "start": 2865.38, "end": 2868.9, "text": " That doesn't come with Matplotlib, but it's very easy to write one.", "tokens": [51616, 663, 1177, 380, 808, 365, 6789, 564, 310, 38270, 11, 457, 309, 311, 588, 1858, 281, 2464, 472, 13, 51792], "temperature": 0.0, "avg_logprob": -0.3194977475195816, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0018102072644978762}, {"id": 577, "seek": 286890, "start": 2869.46, "end": 2875.5, "text": " As x, let's use all the numbers from 0 to 10, 100 of them spaced evenly.", "tokens": [50392, 1018, 2031, 11, 718, 311, 764, 439, 264, 3547, 490, 1958, 281, 1266, 11, 2319, 295, 552, 43766, 17658, 13, 50694], "temperature": 0.0, "avg_logprob": -0.327046841991191, "compression_ratio": 1.5, "no_speech_prob": 0.00044421819620765746}, {"id": 578, "seek": 286890, "start": 2875.5, "end": 2877.54, "text": " That's what linz-based does.", "tokens": [50694, 663, 311, 437, 22896, 89, 12, 6032, 775, 13, 50796], "temperature": 0.0, "avg_logprob": -0.327046841991191, "compression_ratio": 1.5, "no_speech_prob": 0.00044421819620765746}, {"id": 579, "seek": 286890, "start": 2877.54, "end": 2880.62, "text": " Linearly spaced 100 numbers in this range.", "tokens": [50796, 14670, 289, 356, 43766, 2319, 3547, 294, 341, 3613, 13, 50950], "temperature": 0.0, "avg_logprob": -0.327046841991191, "compression_ratio": 1.5, "no_speech_prob": 0.00044421819620765746}, {"id": 580, "seek": 286890, "start": 2880.62, "end": 2882.1600000000003, "text": " That's going to be our x's.", "tokens": [50950, 663, 311, 516, 281, 312, 527, 2031, 311, 13, 51027], "temperature": 0.0, "avg_logprob": -0.327046841991191, "compression_ratio": 1.5, "no_speech_prob": 0.00044421819620765746}, {"id": 581, "seek": 286890, "start": 2882.1600000000003, "end": 2885.14, "text": " So plot those x's and plot f of x's, the y's.", "tokens": [51027, 407, 7542, 729, 2031, 311, 293, 7542, 283, 295, 2031, 311, 11, 264, 288, 311, 13, 51176], "temperature": 0.0, "avg_logprob": -0.327046841991191, "compression_ratio": 1.5, "no_speech_prob": 0.00044421819620765746}, {"id": 582, "seek": 286890, "start": 2885.14, "end": 2889.78, "text": " So here's a very nice little plot funk we want.", "tokens": [51176, 407, 510, 311, 257, 588, 1481, 707, 7542, 283, 3197, 321, 528, 13, 51408], "temperature": 0.0, "avg_logprob": -0.327046841991191, "compression_ratio": 1.5, "no_speech_prob": 0.00044421819620765746}, {"id": 583, "seek": 286890, "start": 2889.78, "end": 2892.14, "text": " And here it is.", "tokens": [51408, 400, 510, 309, 307, 13, 51526], "temperature": 0.0, "avg_logprob": -0.327046841991191, "compression_ratio": 1.5, "no_speech_prob": 0.00044421819620765746}, {"id": 584, "seek": 289214, "start": 2892.14, "end": 2899.98, "text": " And as you can see here, we've now got something where if you are this, like very close to", "tokens": [50364, 400, 382, 291, 393, 536, 510, 11, 321, 600, 586, 658, 746, 689, 498, 291, 366, 341, 11, 411, 588, 1998, 281, 50756], "temperature": 0.0, "avg_logprob": -0.22538279461604294, "compression_ratio": 1.760204081632653, "no_speech_prob": 0.0008558972622267902}, {"id": 585, "seek": 289214, "start": 2899.98, "end": 2902.7799999999997, "text": " the point of interest, you're going to get a very high weight.", "tokens": [50756, 264, 935, 295, 1179, 11, 291, 434, 516, 281, 483, 257, 588, 1090, 3364, 13, 50896], "temperature": 0.0, "avg_logprob": -0.22538279461604294, "compression_ratio": 1.760204081632653, "no_speech_prob": 0.0008558972622267902}, {"id": 586, "seek": 289214, "start": 2902.7799999999997, "end": 2907.4, "text": " And if you're a long way away from the point of interest, you'll get a very low weight.", "tokens": [50896, 400, 498, 291, 434, 257, 938, 636, 1314, 490, 264, 935, 295, 1179, 11, 291, 603, 483, 257, 588, 2295, 3364, 13, 51127], "temperature": 0.0, "avg_logprob": -0.22538279461604294, "compression_ratio": 1.760204081632653, "no_speech_prob": 0.0008558972622267902}, {"id": 587, "seek": 289214, "start": 2907.4, "end": 2912.98, "text": " So that's the key thing that we wanted, remember, is something that penalizes further away points", "tokens": [51127, 407, 300, 311, 264, 2141, 551, 300, 321, 1415, 11, 1604, 11, 307, 746, 300, 13661, 5660, 3052, 1314, 2793, 51406], "temperature": 0.0, "avg_logprob": -0.22538279461604294, "compression_ratio": 1.760204081632653, "no_speech_prob": 0.0008558972622267902}, {"id": 588, "seek": 289214, "start": 2912.98, "end": 2918.14, "text": " more.", "tokens": [51406, 544, 13, 51664], "temperature": 0.0, "avg_logprob": -0.22538279461604294, "compression_ratio": 1.760204081632653, "no_speech_prob": 0.0008558972622267902}, {"id": 589, "seek": 291814, "start": 2918.14, "end": 2927.2999999999997, "text": " Now you'll notice here I managed to plot this function for a bandwidth of 2.5.", "tokens": [50364, 823, 291, 603, 3449, 510, 286, 6453, 281, 7542, 341, 2445, 337, 257, 23647, 295, 568, 13, 20, 13, 50822], "temperature": 0.0, "avg_logprob": -0.22992690916984312, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0004373339470475912}, {"id": 590, "seek": 291814, "start": 2927.2999999999997, "end": 2932.7, "text": " And the way I did that was using this special thing from FuncTools called partial.", "tokens": [50822, 400, 264, 636, 286, 630, 300, 390, 1228, 341, 2121, 551, 490, 11166, 66, 51, 29298, 1219, 14641, 13, 51092], "temperature": 0.0, "avg_logprob": -0.22992690916984312, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0004373339470475912}, {"id": 591, "seek": 291814, "start": 2932.7, "end": 2937.56, "text": " Now the first thing to point out here is that very often, it drives me crazy, I see people", "tokens": [51092, 823, 264, 700, 551, 281, 935, 484, 510, 307, 300, 588, 2049, 11, 309, 11754, 385, 3219, 11, 286, 536, 561, 51335], "temperature": 0.0, "avg_logprob": -0.22992690916984312, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0004373339470475912}, {"id": 592, "seek": 291814, "start": 2937.56, "end": 2940.4, "text": " trying to find out what something is in Jupyter.", "tokens": [51335, 1382, 281, 915, 484, 437, 746, 307, 294, 22125, 88, 391, 13, 51477], "temperature": 0.0, "avg_logprob": -0.22992690916984312, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0004373339470475912}, {"id": 593, "seek": 291814, "start": 2940.4, "end": 2943.8199999999997, "text": " And the way they do it is they'll scroll up to the top of the notebook and search through", "tokens": [51477, 400, 264, 636, 436, 360, 309, 307, 436, 603, 11369, 493, 281, 264, 1192, 295, 264, 21060, 293, 3164, 807, 51648], "temperature": 0.0, "avg_logprob": -0.22992690916984312, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0004373339470475912}, {"id": 594, "seek": 291814, "start": 2943.8199999999997, "end": 2945.8599999999997, "text": " the imports and try to find it.", "tokens": [51648, 264, 41596, 293, 853, 281, 915, 309, 13, 51750], "temperature": 0.0, "avg_logprob": -0.22992690916984312, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0004373339470475912}, {"id": 595, "seek": 291814, "start": 2945.8599999999997, "end": 2947.3799999999997, "text": " That is the dumb way to do it.", "tokens": [51750, 663, 307, 264, 10316, 636, 281, 360, 309, 13, 51826], "temperature": 0.0, "avg_logprob": -0.22992690916984312, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0004373339470475912}, {"id": 596, "seek": 294738, "start": 2947.62, "end": 2949.34, "text": " The smart way to do it is just to type it.", "tokens": [50376, 440, 4069, 636, 281, 360, 309, 307, 445, 281, 2010, 309, 13, 50462], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 597, "seek": 294738, "start": 2949.34, "end": 2952.5, "text": " And press shift-enter and it'll tell you where it comes from.", "tokens": [50462, 400, 1886, 5513, 12, 14278, 293, 309, 603, 980, 291, 689, 309, 1487, 490, 13, 50620], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 598, "seek": 294738, "start": 2952.5, "end": 2957.28, "text": " And you can get its help with question mark, and you can get its source code with two question", "tokens": [50620, 400, 291, 393, 483, 1080, 854, 365, 1168, 1491, 11, 293, 291, 393, 483, 1080, 4009, 3089, 365, 732, 1168, 50859], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 599, "seek": 294738, "start": 2957.28, "end": 2958.28, "text": " marks.", "tokens": [50859, 10640, 13, 50909], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 600, "seek": 294738, "start": 2958.28, "end": 2962.62, "text": " OK, so just type it to find out where it comes from.", "tokens": [50909, 2264, 11, 370, 445, 2010, 309, 281, 915, 484, 689, 309, 1487, 490, 13, 51126], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 601, "seek": 294738, "start": 2962.62, "end": 2969.34, "text": " OK, so this is, as Siva's mentioned in the chat, also known as currying or partial function", "tokens": [51126, 2264, 11, 370, 341, 307, 11, 382, 318, 5931, 311, 2835, 294, 264, 5081, 11, 611, 2570, 382, 18123, 278, 420, 14641, 2445, 51462], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 602, "seek": 294738, "start": 2969.34, "end": 2971.1600000000003, "text": " application.", "tokens": [51462, 3861, 13, 51553], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 603, "seek": 294738, "start": 2971.1600000000003, "end": 2972.7000000000003, "text": " This creates a new function.", "tokens": [51553, 639, 7829, 257, 777, 2445, 13, 51630], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 604, "seek": 294738, "start": 2972.7000000000003, "end": 2976.5, "text": " So let's just grab it.", "tokens": [51630, 407, 718, 311, 445, 4444, 309, 13, 51820], "temperature": 0.0, "avg_logprob": -0.32311475769547393, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.00031015591230243444}, {"id": 605, "seek": 297650, "start": 2976.62, "end": 2979.78, "text": " And we create a new function.", "tokens": [50370, 400, 321, 1884, 257, 777, 2445, 13, 50528], "temperature": 0.0, "avg_logprob": -0.3698761927617061, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00037409545620903373}, {"id": 606, "seek": 297650, "start": 2979.78, "end": 2985.94, "text": " And this function f is the function Gaussian, but it's going to automatically pass bw equals", "tokens": [50528, 400, 341, 2445, 283, 307, 264, 2445, 39148, 11, 457, 309, 311, 516, 281, 6772, 1320, 272, 86, 6915, 50836], "temperature": 0.0, "avg_logprob": -0.3698761927617061, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00037409545620903373}, {"id": 607, "seek": 297650, "start": 2985.94, "end": 2986.94, "text": " 2.5.", "tokens": [50836, 568, 13, 20, 13, 50886], "temperature": 0.0, "avg_logprob": -0.3698761927617061, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00037409545620903373}, {"id": 608, "seek": 297650, "start": 2986.94, "end": 2988.98, "text": " So this is a partially applied function.", "tokens": [50886, 407, 341, 307, 257, 18886, 6456, 2445, 13, 50988], "temperature": 0.0, "avg_logprob": -0.3698761927617061, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00037409545620903373}, {"id": 609, "seek": 297650, "start": 2988.98, "end": 2992.74, "text": " So I could type f of 4, for example.", "tokens": [50988, 407, 286, 727, 2010, 283, 295, 1017, 11, 337, 1365, 13, 51176], "temperature": 0.0, "avg_logprob": -0.3698761927617061, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00037409545620903373}, {"id": 610, "seek": 297650, "start": 2992.74, "end": 2998.38, "text": " That's going to be a tensor.", "tokens": [51176, 663, 311, 516, 281, 312, 257, 40863, 13, 51458], "temperature": 0.0, "avg_logprob": -0.3698761927617061, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00037409545620903373}, {"id": 611, "seek": 297650, "start": 2998.38, "end": 3006.48, "text": " There we go.", "tokens": [51458, 821, 321, 352, 13, 51863], "temperature": 0.0, "avg_logprob": -0.3698761927617061, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00037409545620903373}, {"id": 612, "seek": 300648, "start": 3007.46, "end": 3008.46, "text": " And you can see that's exactly what this is.", "tokens": [50413, 400, 291, 393, 536, 300, 311, 2293, 437, 341, 307, 13, 50463], "temperature": 0.0, "avg_logprob": -0.23233664830525716, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.00013552074960898608}, {"id": 613, "seek": 300648, "start": 3008.46, "end": 3012.12, "text": " Go up to 4, go across, yep, about 0.44.", "tokens": [50463, 1037, 493, 281, 1017, 11, 352, 2108, 11, 18633, 11, 466, 1958, 13, 13912, 13, 50646], "temperature": 0.0, "avg_logprob": -0.23233664830525716, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.00013552074960898608}, {"id": 614, "seek": 300648, "start": 3012.12, "end": 3015.96, "text": " So we use partial function application all the time.", "tokens": [50646, 407, 321, 764, 14641, 2445, 3861, 439, 264, 565, 13, 50838], "temperature": 0.0, "avg_logprob": -0.23233664830525716, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.00013552074960898608}, {"id": 615, "seek": 300648, "start": 3015.96, "end": 3018.7400000000002, "text": " It's a very, very, very important tool.", "tokens": [50838, 467, 311, 257, 588, 11, 588, 11, 588, 1021, 2290, 13, 50977], "temperature": 0.0, "avg_logprob": -0.23233664830525716, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.00013552074960898608}, {"id": 616, "seek": 300648, "start": 3018.7400000000002, "end": 3022.72, "text": " Without it, for example, plotting this function would have been more complicated.", "tokens": [50977, 9129, 309, 11, 337, 1365, 11, 41178, 341, 2445, 576, 362, 668, 544, 6179, 13, 51176], "temperature": 0.0, "avg_logprob": -0.23233664830525716, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.00013552074960898608}, {"id": 617, "seek": 300648, "start": 3022.72, "end": 3025.38, "text": " With it, it was trivially easy.", "tokens": [51176, 2022, 309, 11, 309, 390, 1376, 85, 2270, 1858, 13, 51309], "temperature": 0.0, "avg_logprob": -0.23233664830525716, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.00013552074960898608}, {"id": 618, "seek": 300648, "start": 3025.38, "end": 3031.56, "text": " I guess the alternative, like one alternative, which would be fine but slightly more clunky,", "tokens": [51309, 286, 2041, 264, 8535, 11, 411, 472, 8535, 11, 597, 576, 312, 2489, 457, 4748, 544, 596, 25837, 11, 51618], "temperature": 0.0, "avg_logprob": -0.23233664830525716, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.00013552074960898608}, {"id": 619, "seek": 300648, "start": 3031.56, "end": 3034.68, "text": " would be we could create a little function in line.", "tokens": [51618, 576, 312, 321, 727, 1884, 257, 707, 2445, 294, 1622, 13, 51774], "temperature": 0.0, "avg_logprob": -0.23233664830525716, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.00013552074960898608}, {"id": 620, "seek": 303468, "start": 3034.68, "end": 3039.04, "text": " So we could have said, oh, plot a function that I'm going to define right now, which", "tokens": [50364, 407, 321, 727, 362, 848, 11, 1954, 11, 7542, 257, 2445, 300, 286, 478, 516, 281, 6964, 558, 586, 11, 597, 50582], "temperature": 0.0, "avg_logprob": -0.2694598397055825, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.00013765390031039715}, {"id": 621, "seek": 303468, "start": 3039.04, "end": 3050.68, "text": " is called lambda, which is lambda x, which is Gaussian of x with a bandwidth of 0.25.", "tokens": [50582, 307, 1219, 13607, 11, 597, 307, 13607, 2031, 11, 597, 307, 39148, 295, 2031, 365, 257, 23647, 295, 1958, 13, 6074, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2694598397055825, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.00013765390031039715}, {"id": 622, "seek": 303468, "start": 3050.68, "end": 3051.68, "text": " You could do that too.", "tokens": [51164, 509, 727, 360, 300, 886, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2694598397055825, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.00013765390031039715}, {"id": 623, "seek": 303468, "start": 3051.68, "end": 3052.68, "text": " You know, it's fine.", "tokens": [51214, 509, 458, 11, 309, 311, 2489, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2694598397055825, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.00013765390031039715}, {"id": 624, "seek": 303468, "start": 3052.68, "end": 3058.3199999999997, "text": " But, yeah, partials, I think, are a bit neater, a bit less to think about.", "tokens": [51264, 583, 11, 1338, 11, 644, 12356, 11, 286, 519, 11, 366, 257, 857, 408, 771, 11, 257, 857, 1570, 281, 519, 466, 13, 51546], "temperature": 0.0, "avg_logprob": -0.2694598397055825, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.00013765390031039715}, {"id": 625, "seek": 305832, "start": 3058.32, "end": 3064.2000000000003, "text": " They often produce some neater and clearer code.", "tokens": [50364, 814, 2049, 5258, 512, 408, 771, 293, 26131, 3089, 13, 50658], "temperature": 0.0, "avg_logprob": -0.3145335022832306, "compression_ratio": 1.5, "no_speech_prob": 6.302582914941013e-05}, {"id": 626, "seek": 305832, "start": 3064.2000000000003, "end": 3066.04, "text": " Okay.", "tokens": [50658, 1033, 13, 50750], "temperature": 0.0, "avg_logprob": -0.3145335022832306, "compression_ratio": 1.5, "no_speech_prob": 6.302582914941013e-05}, {"id": 627, "seek": 305832, "start": 3066.04, "end": 3071.8, "text": " Why did we decide to make the bandwidth 2.5?", "tokens": [50750, 1545, 630, 321, 4536, 281, 652, 264, 23647, 568, 13, 20, 30, 51038], "temperature": 0.0, "avg_logprob": -0.3145335022832306, "compression_ratio": 1.5, "no_speech_prob": 6.302582914941013e-05}, {"id": 628, "seek": 305832, "start": 3071.8, "end": 3079.6000000000004, "text": " As a rule of thumb, choose a bandwidth which covers about a third of the data.", "tokens": [51038, 1018, 257, 4978, 295, 9298, 11, 2826, 257, 23647, 597, 10538, 466, 257, 2636, 295, 264, 1412, 13, 51428], "temperature": 0.0, "avg_logprob": -0.3145335022832306, "compression_ratio": 1.5, "no_speech_prob": 6.302582914941013e-05}, {"id": 629, "seek": 305832, "start": 3079.6000000000004, "end": 3085.88, "text": " So if we kind of found ourselves somewhere over here, right, a bandwidth which covers", "tokens": [51428, 407, 498, 321, 733, 295, 1352, 4175, 4079, 670, 510, 11, 558, 11, 257, 23647, 597, 10538, 51742], "temperature": 0.0, "avg_logprob": -0.3145335022832306, "compression_ratio": 1.5, "no_speech_prob": 6.302582914941013e-05}, {"id": 630, "seek": 308588, "start": 3085.88, "end": 3091.4, "text": " about a third of the data would be enough to cover two clusters-ish.", "tokens": [50364, 466, 257, 2636, 295, 264, 1412, 576, 312, 1547, 281, 2060, 732, 23313, 12, 742, 13, 50640], "temperature": 0.0, "avg_logprob": -0.3794381514839504, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.241149402630981e-05}, {"id": 631, "seek": 308588, "start": 3091.4, "end": 3095.6800000000003, "text": " So you'd want to be kind of like this big.", "tokens": [50640, 407, 291, 1116, 528, 281, 312, 733, 295, 411, 341, 955, 13, 50854], "temperature": 0.0, "avg_logprob": -0.3794381514839504, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.241149402630981e-05}, {"id": 632, "seek": 308588, "start": 3095.6800000000003, "end": 3097.88, "text": " So somewhere in the middle there.", "tokens": [50854, 407, 4079, 294, 264, 2808, 456, 13, 50964], "temperature": 0.0, "avg_logprob": -0.3794381514839504, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.241149402630981e-05}, {"id": 633, "seek": 308588, "start": 3097.88, "end": 3101.76, "text": " So that's the basic idea.", "tokens": [50964, 407, 300, 311, 264, 3875, 1558, 13, 51158], "temperature": 0.0, "avg_logprob": -0.3794381514839504, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.241149402630981e-05}, {"id": 634, "seek": 308588, "start": 3101.76, "end": 3104.7200000000003, "text": " Yeah.", "tokens": [51158, 865, 13, 51306], "temperature": 0.0, "avg_logprob": -0.3794381514839504, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.241149402630981e-05}, {"id": 635, "seek": 308588, "start": 3104.7200000000003, "end": 3109.8, "text": " But you can play around with bandwidths and get different amounts of clusters.", "tokens": [51306, 583, 291, 393, 862, 926, 365, 23647, 82, 293, 483, 819, 11663, 295, 23313, 13, 51560], "temperature": 0.0, "avg_logprob": -0.3794381514839504, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.241149402630981e-05}, {"id": 636, "seek": 308588, "start": 3109.8, "end": 3114.04, "text": " I should mention, like often when you see something that's kind of on the complicated", "tokens": [51560, 286, 820, 2152, 11, 411, 2049, 562, 291, 536, 746, 300, 311, 733, 295, 322, 264, 6179, 51772], "temperature": 0.0, "avg_logprob": -0.3794381514839504, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.241149402630981e-05}, {"id": 637, "seek": 311404, "start": 3114.04, "end": 3118.96, "text": " side, like a Gaussian, you can often simplify things.", "tokens": [50364, 1252, 11, 411, 257, 39148, 11, 291, 393, 2049, 20460, 721, 13, 50610], "temperature": 0.0, "avg_logprob": -0.21428523873383143, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.002889576368033886}, {"id": 638, "seek": 311404, "start": 3118.96, "end": 3123.2, "text": " I think most implementations and write-ups I've seen talk about using Gaussians.", "tokens": [50610, 286, 519, 881, 4445, 763, 293, 2464, 12, 7528, 286, 600, 1612, 751, 466, 1228, 10384, 2023, 2567, 13, 50822], "temperature": 0.0, "avg_logprob": -0.21428523873383143, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.002889576368033886}, {"id": 639, "seek": 311404, "start": 3123.2, "end": 3128.44, "text": " But if you look at the shape of it, it looks a lot like this shape.", "tokens": [50822, 583, 498, 291, 574, 412, 264, 3909, 295, 309, 11, 309, 1542, 257, 688, 411, 341, 3909, 13, 51084], "temperature": 0.0, "avg_logprob": -0.21428523873383143, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.002889576368033886}, {"id": 640, "seek": 311404, "start": 3128.44, "end": 3133.7599999999998, "text": " So this is a triangular weighting, which is just using clamp min.", "tokens": [51084, 407, 341, 307, 257, 38190, 3364, 278, 11, 597, 307, 445, 1228, 17690, 923, 13, 51350], "temperature": 0.0, "avg_logprob": -0.21428523873383143, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.002889576368033886}, {"id": 641, "seek": 311404, "start": 3133.7599999999998, "end": 3139.04, "text": " So it's just using a linear with clamp min.", "tokens": [51350, 407, 309, 311, 445, 1228, 257, 8213, 365, 17690, 923, 13, 51614], "temperature": 0.0, "avg_logprob": -0.21428523873383143, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.002889576368033886}, {"id": 642, "seek": 311404, "start": 3139.04, "end": 3142.6, "text": " And yeah, it occurred to me that we could probably use this just as well.", "tokens": [51614, 400, 1338, 11, 309, 11068, 281, 385, 300, 321, 727, 1391, 764, 341, 445, 382, 731, 13, 51792], "temperature": 0.0, "avg_logprob": -0.21428523873383143, "compression_ratio": 1.6425531914893616, "no_speech_prob": 0.002889576368033886}, {"id": 643, "seek": 314260, "start": 3142.64, "end": 3146.36, "text": " So I decided to define this triangular weighting, and then we can try both.", "tokens": [50366, 407, 286, 3047, 281, 6964, 341, 38190, 3364, 278, 11, 293, 550, 321, 393, 853, 1293, 13, 50552], "temperature": 0.0, "avg_logprob": -0.3117873289874781, "compression_ratio": 1.5751072961373391, "no_speech_prob": 5.920916373725049e-05}, {"id": 644, "seek": 314260, "start": 3146.36, "end": 3152.04, "text": " Anyway, so we'll start with, we're going to use the Gaussian version.", "tokens": [50552, 5684, 11, 370, 321, 603, 722, 365, 11, 321, 434, 516, 281, 764, 264, 39148, 3037, 13, 50836], "temperature": 0.0, "avg_logprob": -0.3117873289874781, "compression_ratio": 1.5751072961373391, "no_speech_prob": 5.920916373725049e-05}, {"id": 645, "seek": 314260, "start": 3152.04, "end": 3161.12, "text": " All right, so we're going to be literally moving all the points towards their kind of", "tokens": [50836, 1057, 558, 11, 370, 321, 434, 516, 281, 312, 3736, 2684, 439, 264, 2793, 3030, 641, 733, 295, 51290], "temperature": 0.0, "avg_logprob": -0.3117873289874781, "compression_ratio": 1.5751072961373391, "no_speech_prob": 5.920916373725049e-05}, {"id": 646, "seek": 314260, "start": 3161.12, "end": 3162.8399999999997, "text": " center of gravity.", "tokens": [51290, 3056, 295, 12110, 13, 51376], "temperature": 0.0, "avg_logprob": -0.3117873289874781, "compression_ratio": 1.5751072961373391, "no_speech_prob": 5.920916373725049e-05}, {"id": 647, "seek": 314260, "start": 3162.8399999999997, "end": 3166.04, "text": " So we don't want to mess up our original data, so we clone it.", "tokens": [51376, 407, 321, 500, 380, 528, 281, 2082, 493, 527, 3380, 1412, 11, 370, 321, 26506, 309, 13, 51536], "temperature": 0.0, "avg_logprob": -0.3117873289874781, "compression_ratio": 1.5751072961373391, "no_speech_prob": 5.920916373725049e-05}, {"id": 648, "seek": 314260, "start": 3166.04, "end": 3169.44, "text": " That's a PyTorch thing, it's .clone, it's very handy.", "tokens": [51536, 663, 311, 257, 9953, 51, 284, 339, 551, 11, 309, 311, 2411, 3474, 546, 11, 309, 311, 588, 13239, 13, 51706], "temperature": 0.0, "avg_logprob": -0.3117873289874781, "compression_ratio": 1.5751072961373391, "no_speech_prob": 5.920916373725049e-05}, {"id": 649, "seek": 316944, "start": 3169.44, "end": 3174.48, "text": " And so big X is our matrix of data.", "tokens": [50364, 400, 370, 955, 1783, 307, 527, 8141, 295, 1412, 13, 50616], "temperature": 0.0, "avg_logprob": -0.2881530443827311, "compression_ratio": 1.4214285714285715, "no_speech_prob": 2.078516990877688e-05}, {"id": 650, "seek": 316944, "start": 3174.48, "end": 3184.68, "text": " I mean, it's actually a, that's right, matrix of data, yeah.", "tokens": [50616, 286, 914, 11, 309, 311, 767, 257, 11, 300, 311, 558, 11, 8141, 295, 1412, 11, 1338, 13, 51126], "temperature": 0.0, "avg_logprob": -0.2881530443827311, "compression_ratio": 1.4214285714285715, "no_speech_prob": 2.078516990877688e-05}, {"id": 651, "seek": 316944, "start": 3184.68, "end": 3189.8, "text": " And then little x will be our first point.", "tokens": [51126, 400, 550, 707, 2031, 486, 312, 527, 700, 935, 13, 51382], "temperature": 0.0, "avg_logprob": -0.2881530443827311, "compression_ratio": 1.4214285714285715, "no_speech_prob": 2.078516990877688e-05}, {"id": 652, "seek": 316944, "start": 3189.8, "end": 3196.08, "text": " And it's pretty common to use capital letters for matrices.", "tokens": [51382, 400, 309, 311, 1238, 2689, 281, 764, 4238, 7825, 337, 32284, 13, 51696], "temperature": 0.0, "avg_logprob": -0.2881530443827311, "compression_ratio": 1.4214285714285715, "no_speech_prob": 2.078516990877688e-05}, {"id": 653, "seek": 319608, "start": 3196.08, "end": 3199.68, "text": " So this is our data, this is the first point.", "tokens": [50364, 407, 341, 307, 527, 1412, 11, 341, 307, 264, 700, 935, 13, 50544], "temperature": 0.0, "avg_logprob": -0.249787477346567, "compression_ratio": 1.4335664335664335, "no_speech_prob": 0.00026947850710712373}, {"id": 654, "seek": 319608, "start": 3199.68, "end": 3201.84, "text": " Okay, so there it is.", "tokens": [50544, 1033, 11, 370, 456, 309, 307, 13, 50652], "temperature": 0.0, "avg_logprob": -0.249787477346567, "compression_ratio": 1.4335664335664335, "no_speech_prob": 0.00026947850710712373}, {"id": 655, "seek": 319608, "start": 3201.84, "end": 3205.72, "text": " We're going to start at 26.2, 26.3.", "tokens": [50652, 492, 434, 516, 281, 722, 412, 7551, 13, 17, 11, 7551, 13, 18, 13, 50846], "temperature": 0.0, "avg_logprob": -0.249787477346567, "compression_ratio": 1.4335664335664335, "no_speech_prob": 0.00026947850710712373}, {"id": 656, "seek": 319608, "start": 3205.72, "end": 3214.24, "text": " So 26.2, 26.3, so somewhere up here.", "tokens": [50846, 407, 7551, 13, 17, 11, 7551, 13, 18, 11, 370, 4079, 493, 510, 13, 51272], "temperature": 0.0, "avg_logprob": -0.249787477346567, "compression_ratio": 1.4335664335664335, "no_speech_prob": 0.00026947850710712373}, {"id": 657, "seek": 319608, "start": 3214.24, "end": 3220.52, "text": " So little x, its shape is just, it's a rank 1 tensor of shape 2.", "tokens": [51272, 407, 707, 2031, 11, 1080, 3909, 307, 445, 11, 309, 311, 257, 6181, 502, 40863, 295, 3909, 568, 13, 51586], "temperature": 0.0, "avg_logprob": -0.249787477346567, "compression_ratio": 1.4335664335664335, "no_speech_prob": 0.00026947850710712373}, {"id": 658, "seek": 322052, "start": 3220.52, "end": 3228.72, "text": " Big X is a rank 2 tensor of 1500 data points by 2, the x and y.", "tokens": [50364, 5429, 1783, 307, 257, 6181, 568, 40863, 295, 22671, 1412, 2793, 538, 568, 11, 264, 2031, 293, 288, 13, 50774], "temperature": 0.0, "avg_logprob": -0.21702239248487684, "compression_ratio": 1.4069767441860466, "no_speech_prob": 0.00044421592610888183}, {"id": 659, "seek": 322052, "start": 3228.72, "end": 3236.04, "text": " And if we call x none, that would add a unit axis to that.", "tokens": [50774, 400, 498, 321, 818, 2031, 6022, 11, 300, 576, 909, 257, 4985, 10298, 281, 300, 13, 51140], "temperature": 0.0, "avg_logprob": -0.21702239248487684, "compression_ratio": 1.4069767441860466, "no_speech_prob": 0.00044421592610888183}, {"id": 660, "seek": 322052, "start": 3236.04, "end": 3239.82, "text": " And the reason I'm going to show you that is because we want to find the distance from", "tokens": [51140, 400, 264, 1778, 286, 478, 516, 281, 855, 291, 300, 307, 570, 321, 528, 281, 915, 264, 4560, 490, 51329], "temperature": 0.0, "avg_logprob": -0.21702239248487684, "compression_ratio": 1.4069767441860466, "no_speech_prob": 0.00044421592610888183}, {"id": 661, "seek": 322052, "start": 3239.82, "end": 3242.34, "text": " little x to everything in big X.", "tokens": [51329, 707, 2031, 281, 1203, 294, 955, 1783, 13, 51455], "temperature": 0.0, "avg_logprob": -0.21702239248487684, "compression_ratio": 1.4069767441860466, "no_speech_prob": 0.00044421592610888183}, {"id": 662, "seek": 324234, "start": 3242.46, "end": 3245.3, "text": " And the way we do a distance is with minus.", "tokens": [50370, 400, 264, 636, 321, 360, 257, 4560, 307, 365, 3175, 13, 50512], "temperature": 0.0, "avg_logprob": -0.4488554000854492, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.00669268611818552}, {"id": 663, "seek": 324234, "start": 3245.3, "end": 3252.7400000000002, "text": " But you wouldn't be able to go, you wouldn't be able to go x minus big X and", "tokens": [50512, 583, 291, 2759, 380, 312, 1075, 281, 352, 11, 291, 2759, 380, 312, 1075, 281, 352, 2031, 3175, 955, 1783, 293, 50884], "temperature": 0.0, "avg_logprob": -0.4488554000854492, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.00669268611818552}, {"id": 664, "seek": 324234, "start": 3252.7400000000002, "end": 3258.82, "text": " get the right, actually do you get the right answer?", "tokens": [50884, 483, 264, 558, 11, 767, 360, 291, 483, 264, 558, 1867, 30, 51188], "temperature": 0.0, "avg_logprob": -0.4488554000854492, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.00669268611818552}, {"id": 665, "seek": 324234, "start": 3258.82, "end": 3259.7000000000003, "text": " Let's think about that.", "tokens": [51188, 961, 311, 519, 466, 300, 13, 51232], "temperature": 0.0, "avg_logprob": -0.4488554000854492, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.00669268611818552}, {"id": 666, "seek": 324234, "start": 3259.7000000000003, "end": 3263.7000000000003, "text": " x.shape, we've got that already.", "tokens": [51232, 2031, 13, 82, 42406, 11, 321, 600, 658, 300, 1217, 13, 51432], "temperature": 0.0, "avg_logprob": -0.4488554000854492, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.00669268611818552}, {"id": 667, "seek": 324234, "start": 3263.7000000000003, "end": 3267.78, "text": " No, actually that is going to work, isn't it?", "tokens": [51432, 883, 11, 767, 300, 307, 516, 281, 589, 11, 1943, 380, 309, 30, 51636], "temperature": 0.0, "avg_logprob": -0.4488554000854492, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.00669268611818552}, {"id": 668, "seek": 326778, "start": 3267.78, "end": 3274.46, "text": " So, yes, all right, so you can see why we've got these two versions here.", "tokens": [50364, 407, 11, 2086, 11, 439, 558, 11, 370, 291, 393, 536, 983, 321, 600, 658, 613, 732, 9606, 510, 13, 50698], "temperature": 0.0, "avg_logprob": -0.3119795743156882, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.12019074044656e-05}, {"id": 669, "seek": 326778, "start": 3274.46, "end": 3279.7400000000002, "text": " If we do x none, we've got something of shape 1, 2.", "tokens": [50698, 759, 321, 360, 2031, 6022, 11, 321, 600, 658, 746, 295, 3909, 502, 11, 568, 13, 50962], "temperature": 0.0, "avg_logprob": -0.3119795743156882, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.12019074044656e-05}, {"id": 670, "seek": 326778, "start": 3279.7400000000002, "end": 3283.98, "text": " Now we can subtract that from something of shape 1500, 2.", "tokens": [50962, 823, 321, 393, 16390, 300, 490, 746, 295, 3909, 22671, 11, 568, 13, 51174], "temperature": 0.0, "avg_logprob": -0.3119795743156882, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.12019074044656e-05}, {"id": 671, "seek": 326778, "start": 3283.98, "end": 3287.9, "text": " Because the 2s match up, because they're the same.", "tokens": [51174, 1436, 264, 568, 82, 2995, 493, 11, 570, 436, 434, 264, 912, 13, 51370], "temperature": 0.0, "avg_logprob": -0.3119795743156882, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.12019074044656e-05}, {"id": 672, "seek": 326778, "start": 3287.9, "end": 3292.1800000000003, "text": " And the 1500 and the 1 matches up, because you remember our NumPy rules,", "tokens": [51370, 400, 264, 22671, 293, 264, 502, 10676, 493, 11, 570, 291, 1604, 527, 22592, 47, 88, 4474, 11, 51584], "temperature": 0.0, "avg_logprob": -0.3119795743156882, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.12019074044656e-05}, {"id": 673, "seek": 326778, "start": 3292.1800000000003, "end": 3294.6200000000003, "text": " everything matches up to a unit axis.", "tokens": [51584, 1203, 10676, 493, 281, 257, 4985, 10298, 13, 51706], "temperature": 0.0, "avg_logprob": -0.3119795743156882, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.12019074044656e-05}, {"id": 674, "seek": 329462, "start": 3294.62, "end": 3300.38, "text": " So it's going to copy this matrix across every row of this matrix.", "tokens": [50364, 407, 309, 311, 516, 281, 5055, 341, 8141, 2108, 633, 5386, 295, 341, 8141, 13, 50652], "temperature": 0.0, "avg_logprob": -0.3239224672317505, "compression_ratio": 1.4870466321243523, "no_speech_prob": 8.059445235630847e-07}, {"id": 675, "seek": 329462, "start": 3302.22, "end": 3303.58, "text": " And it works.", "tokens": [50744, 400, 309, 1985, 13, 50812], "temperature": 0.0, "avg_logprob": -0.3239224672317505, "compression_ratio": 1.4870466321243523, "no_speech_prob": 8.059445235630847e-07}, {"id": 676, "seek": 329462, "start": 3305.18, "end": 3309.02, "text": " But do you remember, there's a special trick,", "tokens": [50892, 583, 360, 291, 1604, 11, 456, 311, 257, 2121, 4282, 11, 51084], "temperature": 0.0, "avg_logprob": -0.3239224672317505, "compression_ratio": 1.4870466321243523, "no_speech_prob": 8.059445235630847e-07}, {"id": 677, "seek": 329462, "start": 3309.02, "end": 3314.46, "text": " which is if you've got two shapes of different lengths,", "tokens": [51084, 597, 307, 498, 291, 600, 658, 732, 10854, 295, 819, 26329, 11, 51356], "temperature": 0.0, "avg_logprob": -0.3239224672317505, "compression_ratio": 1.4870466321243523, "no_speech_prob": 8.059445235630847e-07}, {"id": 678, "seek": 329462, "start": 3315.46, "end": 3319.74, "text": " we can use the shorter length and it's gonna add unit axes to the front", "tokens": [51406, 321, 393, 764, 264, 11639, 4641, 293, 309, 311, 799, 909, 4985, 35387, 281, 264, 1868, 51620], "temperature": 0.0, "avg_logprob": -0.3239224672317505, "compression_ratio": 1.4870466321243523, "no_speech_prob": 8.059445235630847e-07}, {"id": 679, "seek": 329462, "start": 3319.74, "end": 3321.94, "text": " to make it as long as necessary.", "tokens": [51620, 281, 652, 309, 382, 938, 382, 4818, 13, 51730], "temperature": 0.0, "avg_logprob": -0.3239224672317505, "compression_ratio": 1.4870466321243523, "no_speech_prob": 8.059445235630847e-07}, {"id": 680, "seek": 332194, "start": 3321.94, "end": 3326.66, "text": " So we actually don't need the x none, we can just use little x.", "tokens": [50364, 407, 321, 767, 500, 380, 643, 264, 2031, 6022, 11, 321, 393, 445, 764, 707, 2031, 13, 50600], "temperature": 0.0, "avg_logprob": -0.2680721082185444, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.786734161323693e-07}, {"id": 681, "seek": 332194, "start": 3326.66, "end": 3332.62, "text": " And it works because it's gonna say, is this compatible with this?", "tokens": [50600, 400, 309, 1985, 570, 309, 311, 799, 584, 11, 307, 341, 18218, 365, 341, 30, 50898], "temperature": 0.0, "avg_logprob": -0.2680721082185444, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.786734161323693e-07}, {"id": 682, "seek": 332194, "start": 3332.62, "end": 3336.38, "text": " Well, the last axis, remember we go right to left, the last axis matches.", "tokens": [50898, 1042, 11, 264, 1036, 10298, 11, 1604, 321, 352, 558, 281, 1411, 11, 264, 1036, 10298, 10676, 13, 51086], "temperature": 0.0, "avg_logprob": -0.2680721082185444, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.786734161323693e-07}, {"id": 683, "seek": 332194, "start": 3337.38, "end": 3342.9, "text": " The second last axis, it doesn't exist, so we pretend that there's a unit axis.", "tokens": [51136, 440, 1150, 1036, 10298, 11, 309, 1177, 380, 2514, 11, 370, 321, 11865, 300, 456, 311, 257, 4985, 10298, 13, 51412], "temperature": 0.0, "avg_logprob": -0.2680721082185444, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.786734161323693e-07}, {"id": 684, "seek": 332194, "start": 3342.9, "end": 3346.66, "text": " And so it's gonna do exactly the same thing as this.", "tokens": [51412, 400, 370, 309, 311, 799, 360, 2293, 264, 912, 551, 382, 341, 13, 51600], "temperature": 0.0, "avg_logprob": -0.2680721082185444, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.786734161323693e-07}, {"id": 685, "seek": 334666, "start": 3347.66, "end": 3353.62, "text": " So, if you have not studied the broadcasting from last week carefully,", "tokens": [50414, 407, 11, 498, 291, 362, 406, 9454, 264, 30024, 490, 1036, 1243, 7500, 11, 50712], "temperature": 0.0, "avg_logprob": -0.34792380954908286, "compression_ratio": 1.7335907335907337, "no_speech_prob": 4.4694017560686916e-05}, {"id": 686, "seek": 334666, "start": 3353.62, "end": 3357.42, "text": " that might not have made a lot of sense to you.", "tokens": [50712, 300, 1062, 406, 362, 1027, 257, 688, 295, 2020, 281, 291, 13, 50902], "temperature": 0.0, "avg_logprob": -0.34792380954908286, "compression_ratio": 1.7335907335907337, "no_speech_prob": 4.4694017560686916e-05}, {"id": 687, "seek": 334666, "start": 3357.42, "end": 3362.54, "text": " And so definitely at this point, you might wanna pause the video and", "tokens": [50902, 400, 370, 2138, 412, 341, 935, 11, 291, 1062, 1948, 10465, 264, 960, 293, 51158], "temperature": 0.0, "avg_logprob": -0.34792380954908286, "compression_ratio": 1.7335907335907337, "no_speech_prob": 4.4694017560686916e-05}, {"id": 688, "seek": 334666, "start": 3362.54, "end": 3366.66, "text": " go back and reread the NumPy broadcasting rules from last time and", "tokens": [51158, 352, 646, 293, 46453, 345, 264, 22592, 47, 88, 30024, 4474, 490, 1036, 565, 293, 51364], "temperature": 0.0, "avg_logprob": -0.34792380954908286, "compression_ratio": 1.7335907335907337, "no_speech_prob": 4.4694017560686916e-05}, {"id": 689, "seek": 334666, "start": 3366.66, "end": 3369.2599999999998, "text": " practice them, because that's what we just did.", "tokens": [51364, 3124, 552, 11, 570, 300, 311, 437, 321, 445, 630, 13, 51494], "temperature": 0.0, "avg_logprob": -0.34792380954908286, "compression_ratio": 1.7335907335907337, "no_speech_prob": 4.4694017560686916e-05}, {"id": 690, "seek": 334666, "start": 3369.2599999999998, "end": 3372.8599999999997, "text": " We used NumPy broadcasting rules, and we're gonna be doing this dozens more", "tokens": [51494, 492, 1143, 22592, 47, 88, 30024, 4474, 11, 293, 321, 434, 799, 312, 884, 341, 18431, 544, 51674], "temperature": 0.0, "avg_logprob": -0.34792380954908286, "compression_ratio": 1.7335907335907337, "no_speech_prob": 4.4694017560686916e-05}, {"id": 691, "seek": 334666, "start": 3372.8599999999997, "end": 3375.98, "text": " times throughout the rest of the course, and many more times, in fact,", "tokens": [51674, 1413, 3710, 264, 1472, 295, 264, 1164, 11, 293, 867, 544, 1413, 11, 294, 1186, 11, 51830], "temperature": 0.0, "avg_logprob": -0.34792380954908286, "compression_ratio": 1.7335907335907337, "no_speech_prob": 4.4694017560686916e-05}, {"id": 692, "seek": 337598, "start": 3376.02, "end": 3376.54, "text": " in this lesson.", "tokens": [50366, 294, 341, 6898, 13, 50392], "temperature": 0.0, "avg_logprob": -0.2704362106323242, "compression_ratio": 1.5898617511520738, "no_speech_prob": 5.475975194713101e-05}, {"id": 693, "seek": 337598, "start": 3378.94, "end": 3382.7400000000002, "text": " Okay, so now I think it's a pretty good place to have a pause.", "tokens": [50512, 1033, 11, 370, 586, 286, 519, 309, 311, 257, 1238, 665, 1081, 281, 362, 257, 10465, 13, 50702], "temperature": 0.0, "avg_logprob": -0.2704362106323242, "compression_ratio": 1.5898617511520738, "no_speech_prob": 5.475975194713101e-05}, {"id": 694, "seek": 337598, "start": 3382.7400000000002, "end": 3386.5, "text": " So I'll see you back here in nine minutes.", "tokens": [50702, 407, 286, 603, 536, 291, 646, 510, 294, 4949, 2077, 13, 50890], "temperature": 0.0, "avg_logprob": -0.2704362106323242, "compression_ratio": 1.5898617511520738, "no_speech_prob": 5.475975194713101e-05}, {"id": 695, "seek": 337598, "start": 3389.54, "end": 3391.3, "text": " Hi everybody, welcome back.", "tokens": [51042, 2421, 2201, 11, 2928, 646, 13, 51130], "temperature": 0.0, "avg_logprob": -0.2704362106323242, "compression_ratio": 1.5898617511520738, "no_speech_prob": 5.475975194713101e-05}, {"id": 696, "seek": 337598, "start": 3391.3, "end": 3395.38, "text": " So we had got to the point where we had managed to get the distance", "tokens": [51130, 407, 321, 632, 658, 281, 264, 935, 689, 321, 632, 6453, 281, 483, 264, 4560, 51334], "temperature": 0.0, "avg_logprob": -0.2704362106323242, "compression_ratio": 1.5898617511520738, "no_speech_prob": 5.475975194713101e-05}, {"id": 697, "seek": 337598, "start": 3395.38, "end": 3402.02, "text": " between our first point, x, and all of the other points in the data.", "tokens": [51334, 1296, 527, 700, 935, 11, 2031, 11, 293, 439, 295, 264, 661, 2793, 294, 264, 1412, 13, 51666], "temperature": 0.0, "avg_logprob": -0.2704362106323242, "compression_ratio": 1.5898617511520738, "no_speech_prob": 5.475975194713101e-05}, {"id": 698, "seek": 337598, "start": 3402.02, "end": 3404.38, "text": " And so we're just looking at the first eight of them here.", "tokens": [51666, 400, 370, 321, 434, 445, 1237, 412, 264, 700, 3180, 295, 552, 510, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2704362106323242, "compression_ratio": 1.5898617511520738, "no_speech_prob": 5.475975194713101e-05}, {"id": 699, "seek": 340438, "start": 3404.38, "end": 3408.7000000000003, "text": " So the very first distance is of course, 0 on the x-axis and", "tokens": [50364, 407, 264, 588, 700, 4560, 307, 295, 1164, 11, 1958, 322, 264, 2031, 12, 24633, 293, 50580], "temperature": 0.0, "avg_logprob": -0.33916141830872154, "compression_ratio": 1.7830188679245282, "no_speech_prob": 8.579229984206904e-07}, {"id": 700, "seek": 340438, "start": 3408.7000000000003, "end": 3411.06, "text": " 0 on the y-axis, because it is the first point.", "tokens": [50580, 1958, 322, 264, 288, 12, 24633, 11, 570, 309, 307, 264, 700, 935, 13, 50698], "temperature": 0.0, "avg_logprob": -0.33916141830872154, "compression_ratio": 1.7830188679245282, "no_speech_prob": 8.579229984206904e-07}, {"id": 701, "seek": 340438, "start": 3412.2200000000003, "end": 3418.54, "text": " The other thing is that because the way we created the clusters is they're all", "tokens": [50756, 440, 661, 551, 307, 300, 570, 264, 636, 321, 2942, 264, 23313, 307, 436, 434, 439, 51072], "temperature": 0.0, "avg_logprob": -0.33916141830872154, "compression_ratio": 1.7830188679245282, "no_speech_prob": 8.579229984206904e-07}, {"id": 702, "seek": 340438, "start": 3418.54, "end": 3422.9, "text": " kind of next to each other in the list, so these are all in the first cluster, so", "tokens": [51072, 733, 295, 958, 281, 1184, 661, 294, 264, 1329, 11, 370, 613, 366, 439, 294, 264, 700, 13630, 11, 370, 51290], "temperature": 0.0, "avg_logprob": -0.33916141830872154, "compression_ratio": 1.7830188679245282, "no_speech_prob": 8.579229984206904e-07}, {"id": 703, "seek": 340438, "start": 3422.9, "end": 3424.38, "text": " none of them are too far away from each other.", "tokens": [51290, 6022, 295, 552, 366, 886, 1400, 1314, 490, 1184, 661, 13, 51364], "temperature": 0.0, "avg_logprob": -0.33916141830872154, "compression_ratio": 1.7830188679245282, "no_speech_prob": 8.579229984206904e-07}, {"id": 704, "seek": 340438, "start": 3426.34, "end": 3431.42, "text": " So now that we've got all the distances, it's easy enough to,", "tokens": [51462, 407, 586, 300, 321, 600, 658, 439, 264, 22182, 11, 309, 311, 1858, 1547, 281, 11, 51716], "temperature": 0.0, "avg_logprob": -0.33916141830872154, "compression_ratio": 1.7830188679245282, "no_speech_prob": 8.579229984206904e-07}, {"id": 705, "seek": 343142, "start": 3431.42, "end": 3435.7000000000003, "text": " well, not the distances on x and y, it's easy enough to get the distance,", "tokens": [50364, 731, 11, 406, 264, 22182, 322, 2031, 293, 288, 11, 309, 311, 1858, 1547, 281, 483, 264, 4560, 11, 50578], "temperature": 0.0, "avg_logprob": -0.36091166178385414, "compression_ratio": 1.569767441860465, "no_speech_prob": 3.5912995372200385e-05}, {"id": 706, "seek": 343142, "start": 3435.7000000000003, "end": 3437.9, "text": " the kind of Euclidean distance.", "tokens": [50578, 264, 733, 295, 462, 1311, 31264, 282, 4560, 13, 50688], "temperature": 0.0, "avg_logprob": -0.36091166178385414, "compression_ratio": 1.569767441860465, "no_speech_prob": 3.5912995372200385e-05}, {"id": 707, "seek": 343142, "start": 3437.9, "end": 3446.58, "text": " So we can just square that difference and sum and square root.", "tokens": [50688, 407, 321, 393, 445, 3732, 300, 2649, 293, 2408, 293, 3732, 5593, 13, 51122], "temperature": 0.0, "avg_logprob": -0.36091166178385414, "compression_ratio": 1.569767441860465, "no_speech_prob": 3.5912995372200385e-05}, {"id": 708, "seek": 343142, "start": 3447.7000000000003, "end": 3452.14, "text": " And actually, maybe this is a good time to talk about norms and", "tokens": [51178, 400, 767, 11, 1310, 341, 307, 257, 665, 565, 281, 751, 466, 24357, 293, 51400], "temperature": 0.0, "avg_logprob": -0.36091166178385414, "compression_ratio": 1.569767441860465, "no_speech_prob": 3.5912995372200385e-05}, {"id": 709, "seek": 343142, "start": 3452.14, "end": 3453.7400000000002, "text": " to talk about what we just did there.", "tokens": [51400, 281, 751, 466, 437, 321, 445, 630, 456, 13, 51480], "temperature": 0.0, "avg_logprob": -0.36091166178385414, "compression_ratio": 1.569767441860465, "no_speech_prob": 3.5912995372200385e-05}, {"id": 710, "seek": 346142, "start": 3462.42, "end": 3464.02, "text": " We've got all these data points.", "tokens": [50414, 492, 600, 658, 439, 613, 1412, 2793, 13, 50494], "temperature": 0.0, "avg_logprob": -0.5236708641052246, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.536018257615069e-07}, {"id": 711, "seek": 346142, "start": 3470.46, "end": 3474.46, "text": " So here's one of our data points, and here's the other one of our data points.", "tokens": [50816, 407, 510, 311, 472, 295, 527, 1412, 2793, 11, 293, 510, 311, 264, 661, 472, 295, 527, 1412, 2793, 13, 51016], "temperature": 0.0, "avg_logprob": -0.5236708641052246, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.536018257615069e-07}, {"id": 712, "seek": 346142, "start": 3476.1, "end": 3482.5, "text": " And there's some distance across the x-axis,", "tokens": [51098, 400, 456, 311, 512, 4560, 2108, 264, 2031, 12, 24633, 11, 51418], "temperature": 0.0, "avg_logprob": -0.5236708641052246, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.536018257615069e-07}, {"id": 713, "seek": 346142, "start": 3482.5, "end": 3489.62, "text": " and there's some distance along the y-axis.", "tokens": [51418, 293, 456, 311, 512, 4560, 2051, 264, 288, 12, 24633, 13, 51774], "temperature": 0.0, "avg_logprob": -0.5236708641052246, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.536018257615069e-07}, {"id": 714, "seek": 348962, "start": 3490.06, "end": 3497.3399999999997, "text": " So we could call that change in x and change in y.", "tokens": [50386, 407, 321, 727, 818, 300, 1319, 294, 2031, 293, 1319, 294, 288, 13, 50750], "temperature": 0.0, "avg_logprob": -0.35997889118809856, "compression_ratio": 1.524822695035461, "no_speech_prob": 1.855391076333035e-07}, {"id": 715, "seek": 348962, "start": 3498.46, "end": 3503.7, "text": " And one way to think about this distance then is it's this distance here.", "tokens": [50806, 400, 472, 636, 281, 519, 466, 341, 4560, 550, 307, 309, 311, 341, 4560, 510, 13, 51068], "temperature": 0.0, "avg_logprob": -0.35997889118809856, "compression_ratio": 1.524822695035461, "no_speech_prob": 1.855391076333035e-07}, {"id": 716, "seek": 348962, "start": 3507.54, "end": 3510.94, "text": " So to calculate that, we can use Pythagoras.", "tokens": [51260, 407, 281, 8873, 300, 11, 321, 393, 764, 9953, 392, 559, 40928, 13, 51430], "temperature": 0.0, "avg_logprob": -0.35997889118809856, "compression_ratio": 1.524822695035461, "no_speech_prob": 1.855391076333035e-07}, {"id": 717, "seek": 348962, "start": 3510.94, "end": 3516.02, "text": " So a squared plus b squared equals c squared.", "tokens": [51430, 407, 257, 8889, 1804, 272, 8889, 6915, 269, 8889, 13, 51684], "temperature": 0.0, "avg_logprob": -0.35997889118809856, "compression_ratio": 1.524822695035461, "no_speech_prob": 1.855391076333035e-07}, {"id": 718, "seek": 351602, "start": 3516.02, "end": 3525.22, "text": " Or in our case, so this would be c, a, and b, say.", "tokens": [50364, 1610, 294, 527, 1389, 11, 370, 341, 576, 312, 269, 11, 257, 11, 293, 272, 11, 584, 13, 50824], "temperature": 0.0, "avg_logprob": -0.3954774179766255, "compression_ratio": 1.608, "no_speech_prob": 9.721544529384119e-07}, {"id": 719, "seek": 351602, "start": 3525.22, "end": 3531.62, "text": " So in our case, it would be the square root of the change in x squared", "tokens": [50824, 407, 294, 527, 1389, 11, 309, 576, 312, 264, 3732, 5593, 295, 264, 1319, 294, 2031, 8889, 51144], "temperature": 0.0, "avg_logprob": -0.3954774179766255, "compression_ratio": 1.608, "no_speech_prob": 9.721544529384119e-07}, {"id": 720, "seek": 351602, "start": 3531.62, "end": 3533.82, "text": " plus the change in y squared.", "tokens": [51144, 1804, 264, 1319, 294, 288, 8889, 13, 51254], "temperature": 0.0, "avg_logprob": -0.3954774179766255, "compression_ratio": 1.608, "no_speech_prob": 9.721544529384119e-07}, {"id": 721, "seek": 351602, "start": 3536.22, "end": 3540.3, "text": " And rather than saying square root, we could say,", "tokens": [51374, 400, 2831, 813, 1566, 3732, 5593, 11, 321, 727, 584, 11, 51578], "temperature": 0.0, "avg_logprob": -0.3954774179766255, "compression_ratio": 1.608, "no_speech_prob": 9.721544529384119e-07}, {"id": 722, "seek": 354602, "start": 3547.02, "end": 3550.62, "text": " To the power of a half, another way of saying the same thing.", "tokens": [50414, 1407, 264, 1347, 295, 257, 1922, 11, 1071, 636, 295, 1566, 264, 912, 551, 13, 50594], "temperature": 0.0, "avg_logprob": -0.36587774185907274, "compression_ratio": 1.6198830409356726, "no_speech_prob": 2.406102339591598e-06}, {"id": 723, "seek": 354602, "start": 3550.62, "end": 3552.66, "text": " But there's a different way we could find the distance.", "tokens": [50594, 583, 456, 311, 257, 819, 636, 321, 727, 915, 264, 4560, 13, 50696], "temperature": 0.0, "avg_logprob": -0.36587774185907274, "compression_ratio": 1.6198830409356726, "no_speech_prob": 2.406102339591598e-06}, {"id": 724, "seek": 354602, "start": 3555.94, "end": 3561.34, "text": " We could first go along here, and then go up here.", "tokens": [50860, 492, 727, 700, 352, 2051, 510, 11, 293, 550, 352, 493, 510, 13, 51130], "temperature": 0.0, "avg_logprob": -0.36587774185907274, "compression_ratio": 1.6198830409356726, "no_speech_prob": 2.406102339591598e-06}, {"id": 725, "seek": 354602, "start": 3563.38, "end": 3568.82, "text": " And so that one would be change in x, if you like,", "tokens": [51232, 400, 370, 300, 472, 576, 312, 1319, 294, 2031, 11, 498, 291, 411, 11, 51504], "temperature": 0.0, "avg_logprob": -0.36587774185907274, "compression_ratio": 1.6198830409356726, "no_speech_prob": 2.406102339591598e-06}, {"id": 726, "seek": 354602, "start": 3568.82, "end": 3575.74, "text": " to the 1 plus change in y to the 1 to the power of 1 1th.", "tokens": [51504, 281, 264, 502, 1804, 1319, 294, 288, 281, 264, 502, 281, 264, 1347, 295, 502, 502, 392, 13, 51850], "temperature": 0.0, "avg_logprob": -0.36587774185907274, "compression_ratio": 1.6198830409356726, "no_speech_prob": 2.406102339591598e-06}, {"id": 727, "seek": 357574, "start": 3576.4599999999996, "end": 3579.22, "text": " I'm writing it a slightly odd way for reasons you'll see in a moment.", "tokens": [50400, 286, 478, 3579, 309, 257, 4748, 7401, 636, 337, 4112, 291, 603, 536, 294, 257, 1623, 13, 50538], "temperature": 0.0, "avg_logprob": -0.44327282905578613, "compression_ratio": 1.4503311258278146, "no_speech_prob": 2.6841976250580046e-06}, {"id": 728, "seek": 357574, "start": 3579.22, "end": 3580.66, "text": " It's just this, otherwise.", "tokens": [50538, 467, 311, 445, 341, 11, 5911, 13, 50610], "temperature": 0.0, "avg_logprob": -0.44327282905578613, "compression_ratio": 1.4503311258278146, "no_speech_prob": 2.6841976250580046e-06}, {"id": 729, "seek": 357574, "start": 3585.2599999999998, "end": 3590.3399999999997, "text": " In general, if we've got a whole list of numbers,", "tokens": [50840, 682, 2674, 11, 498, 321, 600, 658, 257, 1379, 1329, 295, 3547, 11, 51094], "temperature": 0.0, "avg_logprob": -0.44327282905578613, "compression_ratio": 1.4503311258278146, "no_speech_prob": 2.6841976250580046e-06}, {"id": 730, "seek": 357574, "start": 3590.3399999999997, "end": 3593.3399999999997, "text": " we can add them up.", "tokens": [51094, 321, 393, 909, 552, 493, 13, 51244], "temperature": 0.0, "avg_logprob": -0.44327282905578613, "compression_ratio": 1.4503311258278146, "no_speech_prob": 2.6841976250580046e-06}, {"id": 731, "seek": 357574, "start": 3596.3399999999997, "end": 3599.8599999999997, "text": " Let's say there are some list v.", "tokens": [51394, 961, 311, 584, 456, 366, 512, 1329, 371, 13, 51570], "temperature": 0.0, "avg_logprob": -0.44327282905578613, "compression_ratio": 1.4503311258278146, "no_speech_prob": 2.6841976250580046e-06}, {"id": 732, "seek": 357574, "start": 3599.8599999999997, "end": 3600.9799999999996, "text": " We can add them up.", "tokens": [51570, 492, 393, 909, 552, 493, 13, 51626], "temperature": 0.0, "avg_logprob": -0.44327282905578613, "compression_ratio": 1.4503311258278146, "no_speech_prob": 2.6841976250580046e-06}, {"id": 733, "seek": 360098, "start": 3600.98, "end": 3606.82, "text": " We can do each one to the power of some number alpha.", "tokens": [50364, 492, 393, 360, 1184, 472, 281, 264, 1347, 295, 512, 1230, 8961, 13, 50656], "temperature": 0.0, "avg_logprob": -0.3006639877955119, "compression_ratio": 1.6519607843137254, "no_speech_prob": 1.2606943528226111e-05}, {"id": 734, "seek": 360098, "start": 3608.7400000000002, "end": 3612.14, "text": " And take that sum to the 1 over alpha.", "tokens": [50752, 400, 747, 300, 2408, 281, 264, 502, 670, 8961, 13, 50922], "temperature": 0.0, "avg_logprob": -0.3006639877955119, "compression_ratio": 1.6519607843137254, "no_speech_prob": 1.2606943528226111e-05}, {"id": 735, "seek": 360098, "start": 3614.38, "end": 3618.66, "text": " And this thing here is called a norm.", "tokens": [51034, 400, 341, 551, 510, 307, 1219, 257, 2026, 13, 51248], "temperature": 0.0, "avg_logprob": -0.3006639877955119, "compression_ratio": 1.6519607843137254, "no_speech_prob": 1.2606943528226111e-05}, {"id": 736, "seek": 360098, "start": 3620.7400000000002, "end": 3623.34, "text": " So you might have remembered we came across that last week.", "tokens": [51352, 407, 291, 1062, 362, 13745, 321, 1361, 2108, 300, 1036, 1243, 13, 51482], "temperature": 0.0, "avg_logprob": -0.3006639877955119, "compression_ratio": 1.6519607843137254, "no_speech_prob": 1.2606943528226111e-05}, {"id": 737, "seek": 360098, "start": 3623.34, "end": 3625.42, "text": " And we've come across it again this week.", "tokens": [51482, 400, 321, 600, 808, 2108, 309, 797, 341, 1243, 13, 51586], "temperature": 0.0, "avg_logprob": -0.3006639877955119, "compression_ratio": 1.6519607843137254, "no_speech_prob": 1.2606943528226111e-05}, {"id": 738, "seek": 360098, "start": 3625.42, "end": 3628.58, "text": " They basically come up, I don't know, they might end up coming up every week.", "tokens": [51586, 814, 1936, 808, 493, 11, 286, 500, 380, 458, 11, 436, 1062, 917, 493, 1348, 493, 633, 1243, 13, 51744], "temperature": 0.0, "avg_logprob": -0.3006639877955119, "compression_ratio": 1.6519607843137254, "no_speech_prob": 1.2606943528226111e-05}, {"id": 739, "seek": 360098, "start": 3628.58, "end": 3630.3, "text": " They come up all the time.", "tokens": [51744, 814, 808, 493, 439, 264, 565, 13, 51830], "temperature": 0.0, "avg_logprob": -0.3006639877955119, "compression_ratio": 1.6519607843137254, "no_speech_prob": 1.2606943528226111e-05}, {"id": 740, "seek": 363030, "start": 3630.3, "end": 3634.98, "text": " Particularly because the two norm, which we could write like this.", "tokens": [50364, 32281, 570, 264, 732, 2026, 11, 597, 321, 727, 2464, 411, 341, 13, 50598], "temperature": 0.0, "avg_logprob": -0.4880175754941743, "compression_ratio": 1.6991869918699187, "no_speech_prob": 4.450849644399568e-07}, {"id": 741, "seek": 363030, "start": 3636.9, "end": 3638.42, "text": " Or we could write like this.", "tokens": [50694, 1610, 321, 727, 2464, 411, 341, 13, 50770], "temperature": 0.0, "avg_logprob": -0.4880175754941743, "compression_ratio": 1.6991869918699187, "no_speech_prob": 4.450849644399568e-07}, {"id": 742, "seek": 363030, "start": 3639.6600000000003, "end": 3641.1000000000004, "text": " Or we could write like this.", "tokens": [50832, 1610, 321, 727, 2464, 411, 341, 13, 50904], "temperature": 0.0, "avg_logprob": -0.4880175754941743, "compression_ratio": 1.6991869918699187, "no_speech_prob": 4.450849644399568e-07}, {"id": 743, "seek": 363030, "start": 3642.3, "end": 3643.3, "text": " They're all the two norm.", "tokens": [50964, 814, 434, 439, 264, 732, 2026, 13, 51014], "temperature": 0.0, "avg_logprob": -0.4880175754941743, "compression_ratio": 1.6991869918699187, "no_speech_prob": 4.450849644399568e-07}, {"id": 744, "seek": 363030, "start": 3651.7000000000003, "end": 3660.02, "text": " This is just saying it's this equation for alpha equals 2.", "tokens": [51434, 639, 307, 445, 1566, 309, 311, 341, 5367, 337, 8961, 6915, 568, 13, 51850], "temperature": 0.0, "avg_logprob": -0.4880175754941743, "compression_ratio": 1.6991869918699187, "no_speech_prob": 4.450849644399568e-07}, {"id": 745, "seek": 366030, "start": 3661.3, "end": 3664.1000000000004, "text": " And Stefano's pointing out we should actually have an absolute value.", "tokens": [50414, 400, 43421, 3730, 311, 12166, 484, 321, 820, 767, 362, 364, 8236, 2158, 13, 50554], "temperature": 0.0, "avg_logprob": -0.3253724139669667, "compression_ratio": 1.6442687747035574, "no_speech_prob": 3.1381446206069086e-06}, {"id": 746, "seek": 366030, "start": 3664.1000000000004, "end": 3665.1000000000004, "text": " I'm not gonna worry about that.", "tokens": [50554, 286, 478, 406, 799, 3292, 466, 300, 13, 50604], "temperature": 0.0, "avg_logprob": -0.3253724139669667, "compression_ratio": 1.6442687747035574, "no_speech_prob": 3.1381446206069086e-06}, {"id": 747, "seek": 366030, "start": 3665.1000000000004, "end": 3666.82, "text": " We're just doing real numbers here.", "tokens": [50604, 492, 434, 445, 884, 957, 3547, 510, 13, 50690], "temperature": 0.0, "avg_logprob": -0.3253724139669667, "compression_ratio": 1.6442687747035574, "no_speech_prob": 3.1381446206069086e-06}, {"id": 748, "seek": 366030, "start": 3666.82, "end": 3668.26, "text": " So we'll keep things simple.", "tokens": [50690, 407, 321, 603, 1066, 721, 2199, 13, 50762], "temperature": 0.0, "avg_logprob": -0.3253724139669667, "compression_ratio": 1.6442687747035574, "no_speech_prob": 3.1381446206069086e-06}, {"id": 749, "seek": 366030, "start": 3668.26, "end": 3671.2200000000003, "text": " Well, I guess for higher than 1, no, you're probably right.", "tokens": [50762, 1042, 11, 286, 2041, 337, 2946, 813, 502, 11, 572, 11, 291, 434, 1391, 558, 13, 50910], "temperature": 0.0, "avg_logprob": -0.3253724139669667, "compression_ratio": 1.6442687747035574, "no_speech_prob": 3.1381446206069086e-06}, {"id": 750, "seek": 366030, "start": 3672.98, "end": 3675.82, "text": " For something like 3, yeah, I guess we do need an absolute value there.", "tokens": [50998, 1171, 746, 411, 805, 11, 1338, 11, 286, 2041, 321, 360, 643, 364, 8236, 2158, 456, 13, 51140], "temperature": 0.0, "avg_logprob": -0.3253724139669667, "compression_ratio": 1.6442687747035574, "no_speech_prob": 3.1381446206069086e-06}, {"id": 751, "seek": 366030, "start": 3675.82, "end": 3681.1800000000003, "text": " That's a good point because, okay, we could have this one.", "tokens": [51140, 663, 311, 257, 665, 935, 570, 11, 1392, 11, 321, 727, 362, 341, 472, 13, 51408], "temperature": 0.0, "avg_logprob": -0.3253724139669667, "compression_ratio": 1.6442687747035574, "no_speech_prob": 3.1381446206069086e-06}, {"id": 752, "seek": 366030, "start": 3684.0600000000004, "end": 3686.6600000000003, "text": " And so the distance actually has to be the absolute value.", "tokens": [51552, 400, 370, 264, 4560, 767, 575, 281, 312, 264, 8236, 2158, 13, 51682], "temperature": 0.0, "avg_logprob": -0.3253724139669667, "compression_ratio": 1.6442687747035574, "no_speech_prob": 3.1381446206069086e-06}, {"id": 753, "seek": 368666, "start": 3687.66, "end": 3692.46, "text": " So the change in x is the absolute value of that distance.", "tokens": [50414, 407, 264, 1319, 294, 2031, 307, 264, 8236, 2158, 295, 300, 4560, 13, 50654], "temperature": 0.0, "avg_logprob": -0.3805520962446164, "compression_ratio": 1.593939393939394, "no_speech_prob": 5.203569912737294e-07}, {"id": 754, "seek": 368666, "start": 3692.46, "end": 3694.74, "text": " Yes, thank you, Stefano.", "tokens": [50654, 1079, 11, 1309, 291, 11, 43421, 3730, 13, 50768], "temperature": 0.0, "avg_logprob": -0.3805520962446164, "compression_ratio": 1.593939393939394, "no_speech_prob": 5.203569912737294e-07}, {"id": 755, "seek": 368666, "start": 3694.74, "end": 3696.94, "text": " Okay, so we'll have the absolute value.", "tokens": [50768, 1033, 11, 370, 321, 603, 362, 264, 8236, 2158, 13, 50878], "temperature": 0.0, "avg_logprob": -0.3805520962446164, "compression_ratio": 1.593939393939394, "no_speech_prob": 5.203569912737294e-07}, {"id": 756, "seek": 368666, "start": 3696.94, "end": 3700.62, "text": " Okay, so the two norm is what happens when alpha equals 2.", "tokens": [50878, 1033, 11, 370, 264, 732, 2026, 307, 437, 2314, 562, 8961, 6915, 568, 13, 51062], "temperature": 0.0, "avg_logprob": -0.3805520962446164, "compression_ratio": 1.593939393939394, "no_speech_prob": 5.203569912737294e-07}, {"id": 757, "seek": 368666, "start": 3703.02, "end": 3706.8999999999996, "text": " And we would call this, in this case, we would call this the Euclidean distance.", "tokens": [51182, 400, 321, 576, 818, 341, 11, 294, 341, 1389, 11, 321, 576, 818, 341, 264, 462, 1311, 31264, 282, 4560, 13, 51376], "temperature": 0.0, "avg_logprob": -0.3805520962446164, "compression_ratio": 1.593939393939394, "no_speech_prob": 5.203569912737294e-07}, {"id": 758, "seek": 370690, "start": 3706.9, "end": 3719.54, "text": " But actually, where it comes up more often is when you're doing like a loss function.", "tokens": [50364, 583, 767, 11, 689, 309, 1487, 493, 544, 2049, 307, 562, 291, 434, 884, 411, 257, 4470, 2445, 13, 50996], "temperature": 0.0, "avg_logprob": -0.4036511115308078, "compression_ratio": 1.4253731343283582, "no_speech_prob": 3.35967627052014e-07}, {"id": 759, "seek": 370690, "start": 3719.54, "end": 3724.38, "text": " So the mean squared error is just, well,", "tokens": [50996, 407, 264, 914, 8889, 6713, 307, 445, 11, 731, 11, 51238], "temperature": 0.0, "avg_logprob": -0.4036511115308078, "compression_ratio": 1.4253731343283582, "no_speech_prob": 3.35967627052014e-07}, {"id": 760, "seek": 370690, "start": 3724.38, "end": 3727.9, "text": " the root mean squared error, I should say, is just the two norm.", "tokens": [51238, 264, 5593, 914, 8889, 6713, 11, 286, 820, 584, 11, 307, 445, 264, 732, 2026, 13, 51414], "temperature": 0.0, "avg_logprob": -0.4036511115308078, "compression_ratio": 1.4253731343283582, "no_speech_prob": 3.35967627052014e-07}, {"id": 761, "seek": 372790, "start": 3728.42, "end": 3737.58, "text": " Or else the mean absolute error is the one norm.", "tokens": [50390, 1610, 1646, 264, 914, 8236, 6713, 307, 264, 472, 2026, 13, 50848], "temperature": 0.0, "avg_logprob": -0.3478295313168878, "compression_ratio": 1.4518072289156627, "no_speech_prob": 4.2228321035509e-06}, {"id": 762, "seek": 372790, "start": 3737.58, "end": 3746.02, "text": " And these are also known as L2 and L1 loss.", "tokens": [50848, 400, 613, 366, 611, 2570, 382, 441, 17, 293, 441, 16, 4470, 13, 51270], "temperature": 0.0, "avg_logprob": -0.3478295313168878, "compression_ratio": 1.4518072289156627, "no_speech_prob": 4.2228321035509e-06}, {"id": 763, "seek": 372790, "start": 3746.02, "end": 3748.58, "text": " And remember what we saw in that paper last week.", "tokens": [51270, 400, 1604, 437, 321, 1866, 294, 300, 3035, 1036, 1243, 13, 51398], "temperature": 0.0, "avg_logprob": -0.3478295313168878, "compression_ratio": 1.4518072289156627, "no_speech_prob": 4.2228321035509e-06}, {"id": 764, "seek": 372790, "start": 3748.58, "end": 3749.9, "text": " We saw it in this form.", "tokens": [51398, 492, 1866, 309, 294, 341, 1254, 13, 51464], "temperature": 0.0, "avg_logprob": -0.3478295313168878, "compression_ratio": 1.4518072289156627, "no_speech_prob": 4.2228321035509e-06}, {"id": 765, "seek": 372790, "start": 3749.9, "end": 3753.82, "text": " There's a 2 up here, which is where they got rid of the square root again.", "tokens": [51464, 821, 311, 257, 568, 493, 510, 11, 597, 307, 689, 436, 658, 3973, 295, 264, 3732, 5593, 797, 13, 51660], "temperature": 0.0, "avg_logprob": -0.3478295313168878, "compression_ratio": 1.4518072289156627, "no_speech_prob": 4.2228321035509e-06}, {"id": 766, "seek": 375382, "start": 3753.82, "end": 3762.1000000000004, "text": " So that would have just been change in x squared plus change in y squared.", "tokens": [50364, 407, 300, 576, 362, 445, 668, 1319, 294, 2031, 8889, 1804, 1319, 294, 288, 8889, 13, 50778], "temperature": 0.0, "avg_logprob": -0.48873499035835266, "compression_ratio": 1.4078947368421053, "no_speech_prob": 4.4254902604734525e-06}, {"id": 767, "seek": 375382, "start": 3762.1000000000004, "end": 3763.9, "text": " And now we don't even need the parentheses.", "tokens": [50778, 400, 586, 321, 500, 380, 754, 643, 264, 34153, 13, 50868], "temperature": 0.0, "avg_logprob": -0.48873499035835266, "compression_ratio": 1.4078947368421053, "no_speech_prob": 4.4254902604734525e-06}, {"id": 768, "seek": 375382, "start": 3763.9, "end": 3767.1400000000003, "text": " Oopsie daisy.", "tokens": [50868, 21726, 414, 1120, 14169, 13, 51030], "temperature": 0.0, "avg_logprob": -0.48873499035835266, "compression_ratio": 1.4078947368421053, "no_speech_prob": 4.4254902604734525e-06}, {"id": 769, "seek": 375382, "start": 3767.1400000000003, "end": 3772.86, "text": " Okay, so all of this is to say that for,", "tokens": [51030, 1033, 11, 370, 439, 295, 341, 307, 281, 584, 300, 337, 11, 51316], "temperature": 0.0, "avg_logprob": -0.48873499035835266, "compression_ratio": 1.4078947368421053, "no_speech_prob": 4.4254902604734525e-06}, {"id": 770, "seek": 375382, "start": 3772.86, "end": 3778.38, "text": " this comes up all the time because we're", "tokens": [51316, 341, 1487, 493, 439, 264, 565, 570, 321, 434, 51592], "temperature": 0.0, "avg_logprob": -0.48873499035835266, "compression_ratio": 1.4078947368421053, "no_speech_prob": 4.4254902604734525e-06}, {"id": 771, "seek": 377838, "start": 3779.38, "end": 3787.1400000000003, "text": " very, very often interested in distances and errors and things like that.", "tokens": [50414, 588, 11, 588, 2049, 3102, 294, 22182, 293, 13603, 293, 721, 411, 300, 13, 50802], "temperature": 0.0, "avg_logprob": -0.3141565218076601, "compression_ratio": 1.6403940886699508, "no_speech_prob": 2.5215731511707418e-06}, {"id": 772, "seek": 377838, "start": 3787.1400000000003, "end": 3789.2200000000003, "text": " I'm trying to think,", "tokens": [50802, 286, 478, 1382, 281, 519, 11, 50906], "temperature": 0.0, "avg_logprob": -0.3141565218076601, "compression_ratio": 1.6403940886699508, "no_speech_prob": 2.5215731511707418e-06}, {"id": 773, "seek": 377838, "start": 3789.2200000000003, "end": 3793.78, "text": " I don't feel like I've ever seen anything other than one or two.", "tokens": [50906, 286, 500, 380, 841, 411, 286, 600, 1562, 1612, 1340, 661, 813, 472, 420, 732, 13, 51134], "temperature": 0.0, "avg_logprob": -0.3141565218076601, "compression_ratio": 1.6403940886699508, "no_speech_prob": 2.5215731511707418e-06}, {"id": 774, "seek": 377838, "start": 3795.1800000000003, "end": 3800.02, "text": " So although it is a general concept, I don't think we're gonna see", "tokens": [51204, 407, 4878, 309, 307, 257, 2674, 3410, 11, 286, 500, 380, 519, 321, 434, 799, 536, 51446], "temperature": 0.0, "avg_logprob": -0.3141565218076601, "compression_ratio": 1.6403940886699508, "no_speech_prob": 2.5215731511707418e-06}, {"id": 775, "seek": 377838, "start": 3800.02, "end": 3803.1400000000003, "text": " probably things other than one or two in this course.", "tokens": [51446, 1391, 721, 661, 813, 472, 420, 732, 294, 341, 1164, 13, 51602], "temperature": 0.0, "avg_logprob": -0.3141565218076601, "compression_ratio": 1.6403940886699508, "no_speech_prob": 2.5215731511707418e-06}, {"id": 776, "seek": 377838, "start": 3803.1400000000003, "end": 3804.82, "text": " I'd be excited if we do, that would be kind of cool.", "tokens": [51602, 286, 1116, 312, 2919, 498, 321, 360, 11, 300, 576, 312, 733, 295, 1627, 13, 51686], "temperature": 0.0, "avg_logprob": -0.3141565218076601, "compression_ratio": 1.6403940886699508, "no_speech_prob": 2.5215731511707418e-06}, {"id": 777, "seek": 380838, "start": 3808.46, "end": 3814.9, "text": " So here we're taking the Euclidean distance, which is the 2-norm.", "tokens": [50368, 407, 510, 321, 434, 1940, 264, 462, 1311, 31264, 282, 4560, 11, 597, 307, 264, 568, 12, 13403, 13, 50690], "temperature": 0.0, "avg_logprob": -0.4790184901310847, "compression_ratio": 1.368421052631579, "no_speech_prob": 4.0525461031393206e-07}, {"id": 778, "seek": 380838, "start": 3818.6600000000003, "end": 3826.34, "text": " So this has got eight things in it, because we've summed it over dimension 1.", "tokens": [50878, 407, 341, 575, 658, 3180, 721, 294, 309, 11, 570, 321, 600, 2408, 1912, 309, 670, 10139, 502, 13, 51262], "temperature": 0.0, "avg_logprob": -0.4790184901310847, "compression_ratio": 1.368421052631579, "no_speech_prob": 4.0525461031393206e-07}, {"id": 779, "seek": 380838, "start": 3826.34, "end": 3830.78, "text": " So here's your first homework,", "tokens": [51262, 407, 510, 311, 428, 700, 14578, 11, 51484], "temperature": 0.0, "avg_logprob": -0.4790184901310847, "compression_ratio": 1.368421052631579, "no_speech_prob": 4.0525461031393206e-07}, {"id": 780, "seek": 380838, "start": 3830.78, "end": 3837.46, "text": " is to rewrite using torch.einsum.", "tokens": [51484, 307, 281, 28132, 1228, 27822, 13, 68, 1292, 449, 13, 51818], "temperature": 0.0, "avg_logprob": -0.4790184901310847, "compression_ratio": 1.368421052631579, "no_speech_prob": 4.0525461031393206e-07}, {"id": 781, "seek": 383746, "start": 3837.7400000000002, "end": 3839.7400000000002, "text": " You won't be able to get rid of the x minus x,", "tokens": [50378, 509, 1582, 380, 312, 1075, 281, 483, 3973, 295, 264, 2031, 3175, 2031, 11, 50478], "temperature": 0.0, "avg_logprob": -0.24671559035778046, "compression_ratio": 1.8577777777777778, "no_speech_prob": 4.029455794807291e-06}, {"id": 782, "seek": 383746, "start": 3839.7400000000002, "end": 3841.1, "text": " you'll still need to have that in there.", "tokens": [50478, 291, 603, 920, 643, 281, 362, 300, 294, 456, 13, 50546], "temperature": 0.0, "avg_logprob": -0.24671559035778046, "compression_ratio": 1.8577777777777778, "no_speech_prob": 4.029455794807291e-06}, {"id": 783, "seek": 383746, "start": 3842.54, "end": 3846.2200000000003, "text": " But when you've got a multiply followed by a sum,", "tokens": [50618, 583, 562, 291, 600, 658, 257, 12972, 6263, 538, 257, 2408, 11, 50802], "temperature": 0.0, "avg_logprob": -0.24671559035778046, "compression_ratio": 1.8577777777777778, "no_speech_prob": 4.029455794807291e-06}, {"id": 784, "seek": 383746, "start": 3846.2200000000003, "end": 3848.18, "text": " you won't be able to get rid of the square root either.", "tokens": [50802, 291, 1582, 380, 312, 1075, 281, 483, 3973, 295, 264, 3732, 5593, 2139, 13, 50900], "temperature": 0.0, "avg_logprob": -0.24671559035778046, "compression_ratio": 1.8577777777777778, "no_speech_prob": 4.029455794807291e-06}, {"id": 785, "seek": 383746, "start": 3848.18, "end": 3850.1, "text": " You should be able to get rid of the multiply and", "tokens": [50900, 509, 820, 312, 1075, 281, 483, 3973, 295, 264, 12972, 293, 50996], "temperature": 0.0, "avg_logprob": -0.24671559035778046, "compression_ratio": 1.8577777777777778, "no_speech_prob": 4.029455794807291e-06}, {"id": 786, "seek": 383746, "start": 3850.1, "end": 3853.26, "text": " the sum by doing it in a single torch.einsum.", "tokens": [50996, 264, 2408, 538, 884, 309, 294, 257, 2167, 27822, 13, 68, 1292, 449, 13, 51154], "temperature": 0.0, "avg_logprob": -0.24671559035778046, "compression_ratio": 1.8577777777777778, "no_speech_prob": 4.029455794807291e-06}, {"id": 787, "seek": 383746, "start": 3853.26, "end": 3856.86, "text": " So we're summing up over the first dimension, which is this dimension.", "tokens": [51154, 407, 321, 434, 2408, 2810, 493, 670, 264, 700, 10139, 11, 597, 307, 341, 10139, 13, 51334], "temperature": 0.0, "avg_logprob": -0.24671559035778046, "compression_ratio": 1.8577777777777778, "no_speech_prob": 4.029455794807291e-06}, {"id": 788, "seek": 383746, "start": 3856.86, "end": 3859.42, "text": " So in other words, we're summing up the x and the y-axes.", "tokens": [51334, 407, 294, 661, 2283, 11, 321, 434, 2408, 2810, 493, 264, 2031, 293, 264, 288, 12, 2797, 279, 13, 51462], "temperature": 0.0, "avg_logprob": -0.24671559035778046, "compression_ratio": 1.8577777777777778, "no_speech_prob": 4.029455794807291e-06}, {"id": 789, "seek": 385942, "start": 3859.42, "end": 3872.3, "text": " Okay, so now we can get the weights by passing those distances into our Gaussian.", "tokens": [50364, 1033, 11, 370, 586, 321, 393, 483, 264, 17443, 538, 8437, 729, 22182, 666, 527, 39148, 13, 51008], "temperature": 0.0, "avg_logprob": -0.37435398331607683, "compression_ratio": 1.5555555555555556, "no_speech_prob": 6.681515287709772e-07}, {"id": 790, "seek": 385942, "start": 3873.9, "end": 3879.02, "text": " And so as we would expect, the biggest weights, it gets up to 0.16.", "tokens": [51088, 400, 370, 382, 321, 576, 2066, 11, 264, 3880, 17443, 11, 309, 2170, 493, 281, 1958, 13, 6866, 13, 51344], "temperature": 0.0, "avg_logprob": -0.37435398331607683, "compression_ratio": 1.5555555555555556, "no_speech_prob": 6.681515287709772e-07}, {"id": 791, "seek": 385942, "start": 3881.38, "end": 3885.3, "text": " So the closest one is itself, it's gonna be at a big weight.", "tokens": [51462, 407, 264, 13699, 472, 307, 2564, 11, 309, 311, 799, 312, 412, 257, 955, 3364, 13, 51658], "temperature": 0.0, "avg_logprob": -0.37435398331607683, "compression_ratio": 1.5555555555555556, "no_speech_prob": 6.681515287709772e-07}, {"id": 792, "seek": 385942, "start": 3885.3, "end": 3886.7400000000002, "text": " These other ones get reasonable weights.", "tokens": [51658, 1981, 661, 2306, 483, 10585, 17443, 13, 51730], "temperature": 0.0, "avg_logprob": -0.37435398331607683, "compression_ratio": 1.5555555555555556, "no_speech_prob": 6.681515287709772e-07}, {"id": 793, "seek": 385942, "start": 3886.7400000000002, "end": 3889.06, "text": " And the ones that are in totally different clusters have weights small", "tokens": [51730, 400, 264, 2306, 300, 366, 294, 3879, 819, 23313, 362, 17443, 1359, 51846], "temperature": 0.0, "avg_logprob": -0.37435398331607683, "compression_ratio": 1.5555555555555556, "no_speech_prob": 6.681515287709772e-07}, {"id": 794, "seek": 388906, "start": 3889.1, "end": 3892.14, "text": " enough that at three significant figures they appear to be 0.", "tokens": [50366, 1547, 300, 412, 1045, 4776, 9624, 436, 4204, 281, 312, 1958, 13, 50518], "temperature": 0.0, "avg_logprob": -0.3711204304414637, "compression_ratio": 1.5255102040816326, "no_speech_prob": 1.9638032426883e-06}, {"id": 795, "seek": 388906, "start": 3892.14, "end": 3895.14, "text": " Okay, so we've got our weights.", "tokens": [50518, 1033, 11, 370, 321, 600, 658, 527, 17443, 13, 50668], "temperature": 0.0, "avg_logprob": -0.3711204304414637, "compression_ratio": 1.5255102040816326, "no_speech_prob": 1.9638032426883e-06}, {"id": 796, "seek": 388906, "start": 3895.14, "end": 3902.86, "text": " So the weights are 1500 long vector.", "tokens": [50668, 407, 264, 17443, 366, 22671, 938, 8062, 13, 51054], "temperature": 0.0, "avg_logprob": -0.3711204304414637, "compression_ratio": 1.5255102040816326, "no_speech_prob": 1.9638032426883e-06}, {"id": 797, "seek": 388906, "start": 3902.86, "end": 3906.7799999999997, "text": " And of course, our original data is 1500 by 2, the x and the y for each one.", "tokens": [51054, 400, 295, 1164, 11, 527, 3380, 1412, 307, 22671, 538, 568, 11, 264, 2031, 293, 264, 288, 337, 1184, 472, 13, 51250], "temperature": 0.0, "avg_logprob": -0.3711204304414637, "compression_ratio": 1.5255102040816326, "no_speech_prob": 1.9638032426883e-06}, {"id": 798, "seek": 388906, "start": 3908.18, "end": 3910.2999999999997, "text": " So we now want a weighted average.", "tokens": [51320, 407, 321, 586, 528, 257, 32807, 4274, 13, 51426], "temperature": 0.0, "avg_logprob": -0.3711204304414637, "compression_ratio": 1.5255102040816326, "no_speech_prob": 1.9638032426883e-06}, {"id": 799, "seek": 388906, "start": 3910.2999999999997, "end": 3915.5, "text": " We want this data, we want its average weighted by this.", "tokens": [51426, 492, 528, 341, 1412, 11, 321, 528, 1080, 4274, 32807, 538, 341, 13, 51686], "temperature": 0.0, "avg_logprob": -0.3711204304414637, "compression_ratio": 1.5255102040816326, "no_speech_prob": 1.9638032426883e-06}, {"id": 800, "seek": 391550, "start": 3916.5, "end": 3933.46, "text": " So normally, an average is the sum of your data divided by the count.", "tokens": [50414, 407, 5646, 11, 364, 4274, 307, 264, 2408, 295, 428, 1412, 6666, 538, 264, 1207, 13, 51262], "temperature": 0.0, "avg_logprob": -0.36478638648986816, "compression_ratio": 1.411764705882353, "no_speech_prob": 1.2952718009273667e-07}, {"id": 801, "seek": 391550, "start": 3933.46, "end": 3934.86, "text": " That's a normal average.", "tokens": [51262, 663, 311, 257, 2710, 4274, 13, 51332], "temperature": 0.0, "avg_logprob": -0.36478638648986816, "compression_ratio": 1.411764705882353, "no_speech_prob": 1.2952718009273667e-07}, {"id": 802, "seek": 391550, "start": 3934.86, "end": 3938.86, "text": " A weighted average, each item in your data,", "tokens": [51332, 316, 32807, 4274, 11, 1184, 3174, 294, 428, 1412, 11, 51532], "temperature": 0.0, "avg_logprob": -0.36478638648986816, "compression_ratio": 1.411764705882353, "no_speech_prob": 1.2952718009273667e-07}, {"id": 803, "seek": 391550, "start": 3938.86, "end": 3943.58, "text": " let's put some i's around here just to be more clear.", "tokens": [51532, 718, 311, 829, 512, 741, 311, 926, 510, 445, 281, 312, 544, 1850, 13, 51768], "temperature": 0.0, "avg_logprob": -0.36478638648986816, "compression_ratio": 1.411764705882353, "no_speech_prob": 1.2952718009273667e-07}, {"id": 804, "seek": 394358, "start": 3943.58, "end": 3947.7799999999997, "text": " Each item in your data is gonna have a different weight.", "tokens": [50364, 6947, 3174, 294, 428, 1412, 307, 799, 362, 257, 819, 3364, 13, 50574], "temperature": 0.0, "avg_logprob": -0.30483209270320527, "compression_ratio": 1.5738636363636365, "no_speech_prob": 5.285515385367034e-07}, {"id": 805, "seek": 394358, "start": 3949.2599999999998, "end": 3951.54, "text": " And so you multiply each one by the weights.", "tokens": [50648, 400, 370, 291, 12972, 1184, 472, 538, 264, 17443, 13, 50762], "temperature": 0.0, "avg_logprob": -0.30483209270320527, "compression_ratio": 1.5738636363636365, "no_speech_prob": 5.285515385367034e-07}, {"id": 806, "seek": 394358, "start": 3951.54, "end": 3955.62, "text": " And so rather than dividing by n, which is just the sum of ones,", "tokens": [50762, 400, 370, 2831, 813, 26764, 538, 297, 11, 597, 307, 445, 264, 2408, 295, 2306, 11, 50966], "temperature": 0.0, "avg_logprob": -0.30483209270320527, "compression_ratio": 1.5738636363636365, "no_speech_prob": 5.285515385367034e-07}, {"id": 807, "seek": 394358, "start": 3955.62, "end": 3958.74, "text": " we would divide by the sum of weights.", "tokens": [50966, 321, 576, 9845, 538, 264, 2408, 295, 17443, 13, 51122], "temperature": 0.0, "avg_logprob": -0.30483209270320527, "compression_ratio": 1.5738636363636365, "no_speech_prob": 5.285515385367034e-07}, {"id": 808, "seek": 394358, "start": 3959.7799999999997, "end": 3964.34, "text": " So this is an important concept to be familiar with, weighted averages.", "tokens": [51174, 407, 341, 307, 364, 1021, 3410, 281, 312, 4963, 365, 11, 32807, 42257, 13, 51402], "temperature": 0.0, "avg_logprob": -0.30483209270320527, "compression_ratio": 1.5738636363636365, "no_speech_prob": 5.285515385367034e-07}, {"id": 809, "seek": 396434, "start": 3964.34, "end": 3976.46, "text": " So we need to multiply every one of these x's by this.", "tokens": [50364, 407, 321, 643, 281, 12972, 633, 472, 295, 613, 2031, 311, 538, 341, 13, 50970], "temperature": 0.0, "avg_logprob": -0.4024762085505894, "compression_ratio": 1.2384615384615385, "no_speech_prob": 7.0718920142098796e-06}, {"id": 810, "seek": 396434, "start": 3979.02, "end": 3984.86, "text": " Okay, so can we say weight times x?", "tokens": [51098, 1033, 11, 370, 393, 321, 584, 3364, 1413, 2031, 30, 51390], "temperature": 0.0, "avg_logprob": -0.4024762085505894, "compression_ratio": 1.2384615384615385, "no_speech_prob": 7.0718920142098796e-06}, {"id": 811, "seek": 396434, "start": 3984.86, "end": 3985.7400000000002, "text": " No.", "tokens": [51390, 883, 13, 51434], "temperature": 0.0, "avg_logprob": -0.4024762085505894, "compression_ratio": 1.2384615384615385, "no_speech_prob": 7.0718920142098796e-06}, {"id": 812, "seek": 396434, "start": 3985.7400000000002, "end": 3986.9, "text": " All right, why didn't that work?", "tokens": [51434, 1057, 558, 11, 983, 994, 380, 300, 589, 30, 51492], "temperature": 0.0, "avg_logprob": -0.4024762085505894, "compression_ratio": 1.2384615384615385, "no_speech_prob": 7.0718920142098796e-06}, {"id": 813, "seek": 396434, "start": 3989.26, "end": 3992.82, "text": " So remember, we go right to left.", "tokens": [51610, 407, 1604, 11, 321, 352, 558, 281, 1411, 13, 51788], "temperature": 0.0, "avg_logprob": -0.4024762085505894, "compression_ratio": 1.2384615384615385, "no_speech_prob": 7.0718920142098796e-06}, {"id": 814, "seek": 399282, "start": 3992.82, "end": 3996.6600000000003, "text": " So first of all, it's gonna say, let's look at the 2 and", "tokens": [50364, 407, 700, 295, 439, 11, 309, 311, 799, 584, 11, 718, 311, 574, 412, 264, 568, 293, 50556], "temperature": 0.0, "avg_logprob": -0.30540783122434456, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.11243615114654e-07}, {"id": 815, "seek": 399282, "start": 3996.6600000000003, "end": 3998.5, "text": " multiply that by the 15.", "tokens": [50556, 12972, 300, 538, 264, 2119, 13, 50648], "temperature": 0.0, "avg_logprob": -0.30540783122434456, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.11243615114654e-07}, {"id": 816, "seek": 399282, "start": 3998.5, "end": 3999.98, "text": " Are they compatible?", "tokens": [50648, 2014, 436, 18218, 30, 50722], "temperature": 0.0, "avg_logprob": -0.30540783122434456, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.11243615114654e-07}, {"id": 817, "seek": 399282, "start": 3999.98, "end": 4005.1400000000003, "text": " Things are compatible if they're equal, or if at least one of them is 1.", "tokens": [50722, 9514, 366, 18218, 498, 436, 434, 2681, 11, 420, 498, 412, 1935, 472, 295, 552, 307, 502, 13, 50980], "temperature": 0.0, "avg_logprob": -0.30540783122434456, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.11243615114654e-07}, {"id": 818, "seek": 399282, "start": 4005.1400000000003, "end": 4008.9, "text": " These are not equal, and they're not 1, so they're not compatible.", "tokens": [50980, 1981, 366, 406, 2681, 11, 293, 436, 434, 406, 502, 11, 370, 436, 434, 406, 18218, 13, 51168], "temperature": 0.0, "avg_logprob": -0.30540783122434456, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.11243615114654e-07}, {"id": 819, "seek": 399282, "start": 4010.06, "end": 4017.1000000000004, "text": " That's why it says the size of a tensor A must match.", "tokens": [51226, 663, 311, 983, 309, 1619, 264, 2744, 295, 257, 40863, 316, 1633, 2995, 13, 51578], "temperature": 0.0, "avg_logprob": -0.30540783122434456, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.11243615114654e-07}, {"id": 820, "seek": 399282, "start": 4018.3, "end": 4020.6600000000003, "text": " Now when it says match, it doesn't mean they have to be the same.", "tokens": [51638, 823, 562, 309, 1619, 2995, 11, 309, 1177, 380, 914, 436, 362, 281, 312, 264, 912, 13, 51756], "temperature": 0.0, "avg_logprob": -0.30540783122434456, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.11243615114654e-07}, {"id": 821, "seek": 399282, "start": 4020.6600000000003, "end": 4022.2200000000003, "text": " One of them can be 1.", "tokens": [51756, 1485, 295, 552, 393, 312, 502, 13, 51834], "temperature": 0.0, "avg_logprob": -0.30540783122434456, "compression_ratio": 1.6842105263157894, "no_speech_prob": 7.11243615114654e-07}, {"id": 822, "seek": 402222, "start": 4022.22, "end": 4023.54, "text": " Okay, that's what it means to match.", "tokens": [50364, 1033, 11, 300, 311, 437, 309, 1355, 281, 2995, 13, 50430], "temperature": 0.0, "avg_logprob": -0.32281143882057883, "compression_ratio": 1.7538461538461538, "no_speech_prob": 2.190781742683612e-06}, {"id": 823, "seek": 402222, "start": 4023.54, "end": 4025.66, "text": " They're either equal or one of them's 1.", "tokens": [50430, 814, 434, 2139, 2681, 420, 472, 295, 552, 311, 502, 13, 50536], "temperature": 0.0, "avg_logprob": -0.32281143882057883, "compression_ratio": 1.7538461538461538, "no_speech_prob": 2.190781742683612e-06}, {"id": 824, "seek": 402222, "start": 4025.66, "end": 4026.3799999999997, "text": " So that doesn't work.", "tokens": [50536, 407, 300, 1177, 380, 589, 13, 50572], "temperature": 0.0, "avg_logprob": -0.32281143882057883, "compression_ratio": 1.7538461538461538, "no_speech_prob": 2.190781742683612e-06}, {"id": 825, "seek": 402222, "start": 4027.8599999999997, "end": 4034.14, "text": " On the other hand, what if this was 1500, 1?", "tokens": [50646, 1282, 264, 661, 1011, 11, 437, 498, 341, 390, 22671, 11, 502, 30, 50960], "temperature": 0.0, "avg_logprob": -0.32281143882057883, "compression_ratio": 1.7538461538461538, "no_speech_prob": 2.190781742683612e-06}, {"id": 826, "seek": 402222, "start": 4034.14, "end": 4041.3799999999997, "text": " If it was 1500, 1, then they would match,", "tokens": [50960, 759, 309, 390, 22671, 11, 502, 11, 550, 436, 576, 2995, 11, 51322], "temperature": 0.0, "avg_logprob": -0.32281143882057883, "compression_ratio": 1.7538461538461538, "no_speech_prob": 2.190781742683612e-06}, {"id": 827, "seek": 402222, "start": 4041.3799999999997, "end": 4045.8999999999996, "text": " because the 1 and the 2 match, because one of them's a unit axis.", "tokens": [51322, 570, 264, 502, 293, 264, 568, 2995, 11, 570, 472, 295, 552, 311, 257, 4985, 10298, 13, 51548], "temperature": 0.0, "avg_logprob": -0.32281143882057883, "compression_ratio": 1.7538461538461538, "no_speech_prob": 2.190781742683612e-06}, {"id": 828, "seek": 402222, "start": 4045.8999999999996, "end": 4049.14, "text": " And the 1500 and the 1500 match, because they're the same.", "tokens": [51548, 400, 264, 22671, 293, 264, 22671, 2995, 11, 570, 436, 434, 264, 912, 13, 51710], "temperature": 0.0, "avg_logprob": -0.32281143882057883, "compression_ratio": 1.7538461538461538, "no_speech_prob": 2.190781742683612e-06}, {"id": 829, "seek": 402222, "start": 4050.3399999999997, "end": 4051.8199999999997, "text": " So that's what we're gonna do.", "tokens": [51770, 407, 300, 311, 437, 321, 434, 799, 360, 13, 51844], "temperature": 0.0, "avg_logprob": -0.32281143882057883, "compression_ratio": 1.7538461538461538, "no_speech_prob": 2.190781742683612e-06}, {"id": 830, "seek": 405182, "start": 4052.46, "end": 4057.06, "text": " Because that would then copy this to every one of these, which is what we want.", "tokens": [50396, 1436, 300, 576, 550, 5055, 341, 281, 633, 472, 295, 613, 11, 597, 307, 437, 321, 528, 13, 50626], "temperature": 0.0, "avg_logprob": -0.30244811700314894, "compression_ratio": 1.6649746192893402, "no_speech_prob": 2.3090713341389346e-07}, {"id": 831, "seek": 405182, "start": 4057.06, "end": 4060.1400000000003, "text": " We want weights for each of these x, y tuples.", "tokens": [50626, 492, 528, 17443, 337, 1184, 295, 613, 2031, 11, 288, 2604, 2622, 13, 50780], "temperature": 0.0, "avg_logprob": -0.30244811700314894, "compression_ratio": 1.6649746192893402, "no_speech_prob": 2.3090713341389346e-07}, {"id": 832, "seek": 405182, "start": 4063.5, "end": 4069.26, "text": " So to add the trailing unit axis, we say every row and a trailing unit axis.", "tokens": [50948, 407, 281, 909, 264, 944, 4883, 4985, 10298, 11, 321, 584, 633, 5386, 293, 257, 944, 4883, 4985, 10298, 13, 51236], "temperature": 0.0, "avg_logprob": -0.30244811700314894, "compression_ratio": 1.6649746192893402, "no_speech_prob": 2.3090713341389346e-07}, {"id": 833, "seek": 405182, "start": 4071.34, "end": 4073.82, "text": " So that's what that shape looks like.", "tokens": [51340, 407, 300, 311, 437, 300, 3909, 1542, 411, 13, 51464], "temperature": 0.0, "avg_logprob": -0.30244811700314894, "compression_ratio": 1.6649746192893402, "no_speech_prob": 2.3090713341389346e-07}, {"id": 834, "seek": 405182, "start": 4073.82, "end": 4075.94, "text": " So we can now multiply that by x.", "tokens": [51464, 407, 321, 393, 586, 12972, 300, 538, 2031, 13, 51570], "temperature": 0.0, "avg_logprob": -0.30244811700314894, "compression_ratio": 1.6649746192893402, "no_speech_prob": 2.3090713341389346e-07}, {"id": 835, "seek": 405182, "start": 4077.2200000000003, "end": 4080.1400000000003, "text": " And as you can see, it's now weighting each of them.", "tokens": [51634, 400, 382, 291, 393, 536, 11, 309, 311, 586, 3364, 278, 1184, 295, 552, 13, 51780], "temperature": 0.0, "avg_logprob": -0.30244811700314894, "compression_ratio": 1.6649746192893402, "no_speech_prob": 2.3090713341389346e-07}, {"id": 836, "seek": 408014, "start": 4081.14, "end": 4086.62, "text": " And so each of these x's and y's down the bottom, they're all 0.", "tokens": [50414, 400, 370, 1184, 295, 613, 2031, 311, 293, 288, 311, 760, 264, 2767, 11, 436, 434, 439, 1958, 13, 50688], "temperature": 0.0, "avg_logprob": -0.3238301674524943, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.884609162061679e-07}, {"id": 837, "seek": 408014, "start": 4086.62, "end": 4090.02, "text": " So we can sum that up and then divide by the sum of weights.", "tokens": [50688, 407, 321, 393, 2408, 300, 493, 293, 550, 9845, 538, 264, 2408, 295, 17443, 13, 50858], "temperature": 0.0, "avg_logprob": -0.3238301674524943, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.884609162061679e-07}, {"id": 838, "seek": 408014, "start": 4091.2999999999997, "end": 4095.8199999999997, "text": " So let's now write a function that puts all this together.", "tokens": [50922, 407, 718, 311, 586, 2464, 257, 2445, 300, 8137, 439, 341, 1214, 13, 51148], "temperature": 0.0, "avg_logprob": -0.3238301674524943, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.884609162061679e-07}, {"id": 839, "seek": 408014, "start": 4095.8199999999997, "end": 4101.42, "text": " So you can see this really important way of, to me,", "tokens": [51148, 407, 291, 393, 536, 341, 534, 1021, 636, 295, 11, 281, 385, 11, 51428], "temperature": 0.0, "avg_logprob": -0.3238301674524943, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.884609162061679e-07}, {"id": 840, "seek": 408014, "start": 4101.42, "end": 4104.7, "text": " the only way that makes sense to do particularly scientific numerical", "tokens": [51428, 264, 787, 636, 300, 1669, 2020, 281, 360, 4098, 8134, 29054, 51592], "temperature": 0.0, "avg_logprob": -0.3238301674524943, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.884609162061679e-07}, {"id": 841, "seek": 408014, "start": 4104.7, "end": 4107.3, "text": " programming, I actually do all my programming this way,", "tokens": [51592, 9410, 11, 286, 767, 360, 439, 452, 9410, 341, 636, 11, 51722], "temperature": 0.0, "avg_logprob": -0.3238301674524943, "compression_ratio": 1.6160714285714286, "no_speech_prob": 1.884609162061679e-07}, {"id": 842, "seek": 410730, "start": 4107.34, "end": 4110.9800000000005, "text": " particularly scientific and numerical programming, is write it all out step by", "tokens": [50366, 4098, 8134, 293, 29054, 9410, 11, 307, 2464, 309, 439, 484, 1823, 538, 50548], "temperature": 0.0, "avg_logprob": -0.28429266888162363, "compression_ratio": 1.6789667896678966, "no_speech_prob": 2.857316076187999e-06}, {"id": 843, "seek": 410730, "start": 4110.9800000000005, "end": 4115.74, "text": " step, check every piece, have it all there documented for you and for others.", "tokens": [50548, 1823, 11, 1520, 633, 2522, 11, 362, 309, 439, 456, 23007, 337, 291, 293, 337, 2357, 13, 50786], "temperature": 0.0, "avg_logprob": -0.28429266888162363, "compression_ratio": 1.6789667896678966, "no_speech_prob": 2.857316076187999e-06}, {"id": 844, "seek": 410730, "start": 4115.74, "end": 4120.42, "text": " And then copy the cells, merge them together, and", "tokens": [50786, 400, 550, 5055, 264, 5438, 11, 22183, 552, 1214, 11, 293, 51020], "temperature": 0.0, "avg_logprob": -0.28429266888162363, "compression_ratio": 1.6789667896678966, "no_speech_prob": 2.857316076187999e-06}, {"id": 845, "seek": 410730, "start": 4120.42, "end": 4124.3, "text": " indent them to indent its control right square bracket, and", "tokens": [51020, 44494, 552, 281, 44494, 1080, 1969, 558, 3732, 16904, 11, 293, 51214], "temperature": 0.0, "avg_logprob": -0.28429266888162363, "compression_ratio": 1.6789667896678966, "no_speech_prob": 2.857316076187999e-06}, {"id": 846, "seek": 410730, "start": 4124.3, "end": 4125.9400000000005, "text": " put a function header on top.", "tokens": [51214, 829, 257, 2445, 23117, 322, 1192, 13, 51296], "temperature": 0.0, "avg_logprob": -0.28429266888162363, "compression_ratio": 1.6789667896678966, "no_speech_prob": 2.857316076187999e-06}, {"id": 847, "seek": 410730, "start": 4125.9400000000005, "end": 4129.22, "text": " So here's all those things we just did.", "tokens": [51296, 407, 510, 311, 439, 729, 721, 321, 445, 630, 13, 51460], "temperature": 0.0, "avg_logprob": -0.28429266888162363, "compression_ratio": 1.6789667896678966, "no_speech_prob": 2.857316076187999e-06}, {"id": 848, "seek": 410730, "start": 4129.22, "end": 4133.34, "text": " And now rather than just grabbing the first x, we enumerate through all of them.", "tokens": [51460, 400, 586, 2831, 813, 445, 23771, 264, 700, 2031, 11, 321, 465, 15583, 473, 807, 439, 295, 552, 13, 51666], "temperature": 0.0, "avg_logprob": -0.28429266888162363, "compression_ratio": 1.6789667896678966, "no_speech_prob": 2.857316076187999e-06}, {"id": 849, "seek": 410730, "start": 4134.58, "end": 4136.7, "text": " So that's the distance we had before.", "tokens": [51728, 407, 300, 311, 264, 4560, 321, 632, 949, 13, 51834], "temperature": 0.0, "avg_logprob": -0.28429266888162363, "compression_ratio": 1.6789667896678966, "no_speech_prob": 2.857316076187999e-06}, {"id": 850, "seek": 413670, "start": 4136.74, "end": 4138.94, "text": " That's the weight we had before.", "tokens": [50366, 663, 311, 264, 3364, 321, 632, 949, 13, 50476], "temperature": 0.0, "avg_logprob": -0.3088702497811153, "compression_ratio": 1.8761467889908257, "no_speech_prob": 5.9301861199401174e-08}, {"id": 851, "seek": 413670, "start": 4138.94, "end": 4141.0599999999995, "text": " There's the product we had before.", "tokens": [50476, 821, 311, 264, 1674, 321, 632, 949, 13, 50582], "temperature": 0.0, "avg_logprob": -0.3088702497811153, "compression_ratio": 1.8761467889908257, "no_speech_prob": 5.9301861199401174e-08}, {"id": 852, "seek": 413670, "start": 4141.0599999999995, "end": 4145.099999999999, "text": " And then finally, sum across the rows, divide by the sum of the weights.", "tokens": [50582, 400, 550, 2721, 11, 2408, 2108, 264, 13241, 11, 9845, 538, 264, 2408, 295, 264, 17443, 13, 50784], "temperature": 0.0, "avg_logprob": -0.3088702497811153, "compression_ratio": 1.8761467889908257, "no_speech_prob": 5.9301861199401174e-08}, {"id": 853, "seek": 413670, "start": 4145.099999999999, "end": 4152.0599999999995, "text": " So that's gonna calculate for the ith, it's gonna move,", "tokens": [50784, 407, 300, 311, 799, 8873, 337, 264, 309, 71, 11, 309, 311, 799, 1286, 11, 51132], "temperature": 0.0, "avg_logprob": -0.3088702497811153, "compression_ratio": 1.8761467889908257, "no_speech_prob": 5.9301861199401174e-08}, {"id": 854, "seek": 413670, "start": 4152.0599999999995, "end": 4154.22, "text": " so it's actually changing capital X.", "tokens": [51132, 370, 309, 311, 767, 4473, 4238, 1783, 13, 51240], "temperature": 0.0, "avg_logprob": -0.3088702497811153, "compression_ratio": 1.8761467889908257, "no_speech_prob": 5.9301861199401174e-08}, {"id": 855, "seek": 413670, "start": 4154.22, "end": 4158.179999999999, "text": " So it's changing the ith thing in capital X, so that it's now the weighted sum.", "tokens": [51240, 407, 309, 311, 4473, 264, 309, 71, 551, 294, 4238, 1783, 11, 370, 300, 309, 311, 586, 264, 32807, 2408, 13, 51438], "temperature": 0.0, "avg_logprob": -0.3088702497811153, "compression_ratio": 1.8761467889908257, "no_speech_prob": 5.9301861199401174e-08}, {"id": 856, "seek": 413670, "start": 4159.3, "end": 4163.099999999999, "text": " Actually, sorry, the weighted average of all of the other data,", "tokens": [51494, 5135, 11, 2597, 11, 264, 32807, 4274, 295, 439, 295, 264, 661, 1412, 11, 51684], "temperature": 0.0, "avg_logprob": -0.3088702497811153, "compression_ratio": 1.8761467889908257, "no_speech_prob": 5.9301861199401174e-08}, {"id": 857, "seek": 413670, "start": 4163.099999999999, "end": 4164.66, "text": " weighted by how far it is away.", "tokens": [51684, 32807, 538, 577, 1400, 309, 307, 1314, 13, 51762], "temperature": 0.0, "avg_logprob": -0.3088702497811153, "compression_ratio": 1.8761467889908257, "no_speech_prob": 5.9301861199401174e-08}, {"id": 858, "seek": 416670, "start": 4166.78, "end": 4168.34, "text": " So that's gonna do a single step.", "tokens": [50368, 407, 300, 311, 799, 360, 257, 2167, 1823, 13, 50446], "temperature": 0.0, "avg_logprob": -0.2836200344947077, "compression_ratio": 1.5373831775700935, "no_speech_prob": 1.963804152183002e-06}, {"id": 859, "seek": 416670, "start": 4168.34, "end": 4172.74, "text": " So the mean shift update is extremely straightforward,", "tokens": [50446, 407, 264, 914, 5513, 5623, 307, 4664, 15325, 11, 50666], "temperature": 0.0, "avg_logprob": -0.2836200344947077, "compression_ratio": 1.5373831775700935, "no_speech_prob": 1.963804152183002e-06}, {"id": 860, "seek": 416670, "start": 4172.74, "end": 4177.74, "text": " which is clone the data, iterate a few times, and do the update.", "tokens": [50666, 597, 307, 26506, 264, 1412, 11, 44497, 257, 1326, 1413, 11, 293, 360, 264, 5623, 13, 50916], "temperature": 0.0, "avg_logprob": -0.2836200344947077, "compression_ratio": 1.5373831775700935, "no_speech_prob": 1.963804152183002e-06}, {"id": 861, "seek": 416670, "start": 4181.0599999999995, "end": 4185.62, "text": " So if we run it, take 600 milliseconds.", "tokens": [51082, 407, 498, 321, 1190, 309, 11, 747, 11849, 34184, 13, 51310], "temperature": 0.0, "avg_logprob": -0.2836200344947077, "compression_ratio": 1.5373831775700935, "no_speech_prob": 1.963804152183002e-06}, {"id": 862, "seek": 416670, "start": 4185.62, "end": 4192.22, "text": " And what I've done is I've plotted the centroids moved by two pixels,", "tokens": [51310, 400, 437, 286, 600, 1096, 307, 286, 600, 43288, 264, 24607, 3742, 4259, 538, 732, 18668, 11, 51640], "temperature": 0.0, "avg_logprob": -0.2836200344947077, "compression_ratio": 1.5373831775700935, "no_speech_prob": 1.963804152183002e-06}, {"id": 863, "seek": 416670, "start": 4192.22, "end": 4196.62, "text": " or two, well not two pixels, two units, so that you can see them.", "tokens": [51640, 420, 732, 11, 731, 406, 732, 18668, 11, 732, 6815, 11, 370, 300, 291, 393, 536, 552, 13, 51860], "temperature": 0.0, "avg_logprob": -0.2836200344947077, "compression_ratio": 1.5373831775700935, "no_speech_prob": 1.963804152183002e-06}, {"id": 864, "seek": 419662, "start": 4197.54, "end": 4200.94, "text": " And so you can see the dots is where our data is, and they're dots now,", "tokens": [50410, 400, 370, 291, 393, 536, 264, 15026, 307, 689, 527, 1412, 307, 11, 293, 436, 434, 15026, 586, 11, 50580], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 865, "seek": 419662, "start": 4200.94, "end": 4204.98, "text": " because every single data point is on top of each other on a cluster.", "tokens": [50580, 570, 633, 2167, 1412, 935, 307, 322, 1192, 295, 1184, 661, 322, 257, 13630, 13, 50782], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 866, "seek": 419662, "start": 4204.98, "end": 4207.5, "text": " And so you can see they are now in the correct spots.", "tokens": [50782, 400, 370, 291, 393, 536, 436, 366, 586, 294, 264, 3006, 10681, 13, 50908], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 867, "seek": 419662, "start": 4207.5, "end": 4209.22, "text": " So it has successfully clustered our data.", "tokens": [50908, 407, 309, 575, 10727, 596, 38624, 527, 1412, 13, 50994], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 868, "seek": 419662, "start": 4210.34, "end": 4211.78, "text": " So that's great news.", "tokens": [51050, 407, 300, 311, 869, 2583, 13, 51122], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 869, "seek": 419662, "start": 4211.78, "end": 4213.66, "text": " And so we could test out our hypothesis.", "tokens": [51122, 400, 370, 321, 727, 1500, 484, 527, 17291, 13, 51216], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 870, "seek": 419662, "start": 4213.66, "end": 4216.86, "text": " Could we use triangular just as well as we could have used Gaussian?", "tokens": [51216, 7497, 321, 764, 38190, 445, 382, 731, 382, 321, 727, 362, 1143, 39148, 30, 51376], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 871, "seek": 419662, "start": 4216.86, "end": 4219.0599999999995, "text": " So Ctrl slash comments and uncomments.", "tokens": [51376, 407, 35233, 17330, 3053, 293, 8585, 1117, 13, 51486], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 872, "seek": 419662, "start": 4221.58, "end": 4223.66, "text": " Yep, we got exactly the same results.", "tokens": [51612, 7010, 11, 321, 658, 2293, 264, 912, 3542, 13, 51716], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 873, "seek": 419662, "start": 4223.66, "end": 4224.18, "text": " So that's good.", "tokens": [51716, 407, 300, 311, 665, 13, 51742], "temperature": 0.0, "avg_logprob": -0.38195389740226804, "compression_ratio": 1.7471698113207548, "no_speech_prob": 1.2482701094995718e-06}, {"id": 874, "seek": 422418, "start": 4225.18, "end": 4229.14, "text": " It's really important to know these keyboard shortcuts.", "tokens": [50414, 467, 311, 534, 1021, 281, 458, 613, 10186, 34620, 13, 50612], "temperature": 0.0, "avg_logprob": -0.2363090865108945, "compression_ratio": 1.9342723004694835, "no_speech_prob": 4.157363946433179e-06}, {"id": 875, "seek": 422418, "start": 4229.14, "end": 4231.38, "text": " Hit H to get a list of them.", "tokens": [50612, 9217, 389, 281, 483, 257, 1329, 295, 552, 13, 50724], "temperature": 0.0, "avg_logprob": -0.2363090865108945, "compression_ratio": 1.9342723004694835, "no_speech_prob": 4.157363946433179e-06}, {"id": 876, "seek": 422418, "start": 4233.1, "end": 4236.66, "text": " Some things that are really important don't have keyboard shortcuts.", "tokens": [50810, 2188, 721, 300, 366, 534, 1021, 500, 380, 362, 10186, 34620, 13, 50988], "temperature": 0.0, "avg_logprob": -0.2363090865108945, "compression_ratio": 1.9342723004694835, "no_speech_prob": 4.157363946433179e-06}, {"id": 877, "seek": 422418, "start": 4236.66, "end": 4239.14, "text": " So if you click Help, Edit Keyboard Shortcuts,", "tokens": [50988, 407, 498, 291, 2052, 10773, 11, 33241, 12759, 3787, 16881, 26158, 11, 51112], "temperature": 0.0, "avg_logprob": -0.2363090865108945, "compression_ratio": 1.9342723004694835, "no_speech_prob": 4.157363946433179e-06}, {"id": 878, "seek": 422418, "start": 4239.14, "end": 4241.66, "text": " there's a list of all the things Jupyter can do.", "tokens": [51112, 456, 311, 257, 1329, 295, 439, 264, 721, 22125, 88, 391, 393, 360, 13, 51238], "temperature": 0.0, "avg_logprob": -0.2363090865108945, "compression_ratio": 1.9342723004694835, "no_speech_prob": 4.157363946433179e-06}, {"id": 879, "seek": 422418, "start": 4241.66, "end": 4245.38, "text": " And you can add keyboard shortcuts to things that don't have them.", "tokens": [51238, 400, 291, 393, 909, 10186, 34620, 281, 721, 300, 500, 380, 362, 552, 13, 51424], "temperature": 0.0, "avg_logprob": -0.2363090865108945, "compression_ratio": 1.9342723004694835, "no_speech_prob": 4.157363946433179e-06}, {"id": 880, "seek": 422418, "start": 4245.38, "end": 4250.54, "text": " So for example, I always add keyboard shortcuts to run all cells above and", "tokens": [51424, 407, 337, 1365, 11, 286, 1009, 909, 10186, 34620, 281, 1190, 439, 5438, 3673, 293, 51682], "temperature": 0.0, "avg_logprob": -0.2363090865108945, "compression_ratio": 1.9342723004694835, "no_speech_prob": 4.157363946433179e-06}, {"id": 881, "seek": 422418, "start": 4250.54, "end": 4252.1, "text": " run all cells below.", "tokens": [51682, 1190, 439, 5438, 2507, 13, 51760], "temperature": 0.0, "avg_logprob": -0.2363090865108945, "compression_ratio": 1.9342723004694835, "no_speech_prob": 4.157363946433179e-06}, {"id": 882, "seek": 425210, "start": 4252.1, "end": 4255.5, "text": " As you can see, I type Q and then A for above and Q and then B for below.", "tokens": [50364, 1018, 291, 393, 536, 11, 286, 2010, 1249, 293, 550, 316, 337, 3673, 293, 1249, 293, 550, 363, 337, 2507, 13, 50534], "temperature": 0.0, "avg_logprob": -0.3070397478468875, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.966984422731912e-06}, {"id": 883, "seek": 425210, "start": 4259.860000000001, "end": 4266.3, "text": " All right, now that was kind of boring in a way because it did five steps.", "tokens": [50752, 1057, 558, 11, 586, 300, 390, 733, 295, 9989, 294, 257, 636, 570, 309, 630, 1732, 4439, 13, 51074], "temperature": 0.0, "avg_logprob": -0.3070397478468875, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.966984422731912e-06}, {"id": 884, "seek": 425210, "start": 4268.58, "end": 4270.26, "text": " But we just saw the result.", "tokens": [51188, 583, 321, 445, 1866, 264, 1874, 13, 51272], "temperature": 0.0, "avg_logprob": -0.3070397478468875, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.966984422731912e-06}, {"id": 885, "seek": 425210, "start": 4270.26, "end": 4272.46, "text": " What did it look like one step at a time?", "tokens": [51272, 708, 630, 309, 574, 411, 472, 1823, 412, 257, 565, 30, 51382], "temperature": 0.0, "avg_logprob": -0.3070397478468875, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.966984422731912e-06}, {"id": 886, "seek": 425210, "start": 4274.06, "end": 4275.820000000001, "text": " This isn't just fun.", "tokens": [51462, 639, 1943, 380, 445, 1019, 13, 51550], "temperature": 0.0, "avg_logprob": -0.3070397478468875, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.966984422731912e-06}, {"id": 887, "seek": 425210, "start": 4275.820000000001, "end": 4280.22, "text": " It's really important to be able to see things happening one step at a time.", "tokens": [51550, 467, 311, 534, 1021, 281, 312, 1075, 281, 536, 721, 2737, 472, 1823, 412, 257, 565, 13, 51770], "temperature": 0.0, "avg_logprob": -0.3070397478468875, "compression_ratio": 1.5339805825242718, "no_speech_prob": 3.966984422731912e-06}, {"id": 888, "seek": 428022, "start": 4280.26, "end": 4283.34, "text": " Cuz there are so many algorithms we do which are like updating weights or", "tokens": [50366, 27017, 456, 366, 370, 867, 14642, 321, 360, 597, 366, 411, 25113, 17443, 420, 50520], "temperature": 0.0, "avg_logprob": -0.2820594331138154, "compression_ratio": 1.6344086021505377, "no_speech_prob": 2.68420035354211e-06}, {"id": 889, "seek": 428022, "start": 4283.34, "end": 4284.58, "text": " updating data.", "tokens": [50520, 25113, 1412, 13, 50582], "temperature": 0.0, "avg_logprob": -0.2820594331138154, "compression_ratio": 1.6344086021505377, "no_speech_prob": 2.68420035354211e-06}, {"id": 890, "seek": 428022, "start": 4284.58, "end": 4287.9800000000005, "text": " So for stable diffusion, for example, you're very likely to want to show", "tokens": [50582, 407, 337, 8351, 25242, 11, 337, 1365, 11, 291, 434, 588, 3700, 281, 528, 281, 855, 50752], "temperature": 0.0, "avg_logprob": -0.2820594331138154, "compression_ratio": 1.6344086021505377, "no_speech_prob": 2.68420035354211e-06}, {"id": 891, "seek": 428022, "start": 4288.9800000000005, "end": 4292.42, "text": " your incrementally denoising and so forth.", "tokens": [50802, 428, 26200, 379, 1441, 78, 3436, 293, 370, 5220, 13, 50974], "temperature": 0.0, "avg_logprob": -0.2820594331138154, "compression_ratio": 1.6344086021505377, "no_speech_prob": 2.68420035354211e-06}, {"id": 892, "seek": 428022, "start": 4292.42, "end": 4295.46, "text": " So in my opinion, it's important to know how to do animations.", "tokens": [50974, 407, 294, 452, 4800, 11, 309, 311, 1021, 281, 458, 577, 281, 360, 22868, 13, 51126], "temperature": 0.0, "avg_logprob": -0.2820594331138154, "compression_ratio": 1.6344086021505377, "no_speech_prob": 2.68420035354211e-06}, {"id": 893, "seek": 428022, "start": 4296.62, "end": 4301.820000000001, "text": " And I found the documentation for this unnecessarily complicated.", "tokens": [51184, 400, 286, 1352, 264, 14333, 337, 341, 16799, 3289, 6179, 13, 51444], "temperature": 0.0, "avg_logprob": -0.2820594331138154, "compression_ratio": 1.6344086021505377, "no_speech_prob": 2.68420035354211e-06}, {"id": 894, "seek": 428022, "start": 4301.820000000001, "end": 4305.22, "text": " Because a lot of it's about how to make them performant.", "tokens": [51444, 1436, 257, 688, 295, 309, 311, 466, 577, 281, 652, 552, 2042, 394, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2820594331138154, "compression_ratio": 1.6344086021505377, "no_speech_prob": 2.68420035354211e-06}, {"id": 895, "seek": 428022, "start": 4305.22, "end": 4307.5, "text": " But most of the time, we probably don't care too much about that.", "tokens": [51614, 583, 881, 295, 264, 565, 11, 321, 1391, 500, 380, 1127, 886, 709, 466, 300, 13, 51728], "temperature": 0.0, "avg_logprob": -0.2820594331138154, "compression_ratio": 1.6344086021505377, "no_speech_prob": 2.68420035354211e-06}, {"id": 896, "seek": 430750, "start": 4307.5, "end": 4308.74, "text": " So I wanna show you a little trick,", "tokens": [50364, 407, 286, 1948, 855, 291, 257, 707, 4282, 11, 50426], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 897, "seek": 430750, "start": 4308.74, "end": 4312.02, "text": " a simple way to create animations without any trouble.", "tokens": [50426, 257, 2199, 636, 281, 1884, 22868, 1553, 604, 5253, 13, 50590], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 898, "seek": 430750, "start": 4313.62, "end": 4317.02, "text": " So matplotlib.animation has something called funcanimation.", "tokens": [50670, 407, 3803, 564, 310, 38270, 13, 17869, 399, 575, 746, 1219, 1019, 66, 17869, 399, 13, 50840], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 899, "seek": 430750, "start": 4317.02, "end": 4317.94, "text": " That's what we're gonna use.", "tokens": [50840, 663, 311, 437, 321, 434, 799, 764, 13, 50886], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 900, "seek": 430750, "start": 4319.42, "end": 4323.7, "text": " To create an animation, you have to create a function.", "tokens": [50960, 1407, 1884, 364, 9603, 11, 291, 362, 281, 1884, 257, 2445, 13, 51174], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 901, "seek": 430750, "start": 4323.7, "end": 4327.58, "text": " And the function, you're gonna be calling funcanimation,", "tokens": [51174, 400, 264, 2445, 11, 291, 434, 799, 312, 5141, 1019, 66, 17869, 399, 11, 51368], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 902, "seek": 430750, "start": 4327.58, "end": 4332.14, "text": " passing in the name of that function, and saying how many times to run it.", "tokens": [51368, 8437, 294, 264, 1315, 295, 300, 2445, 11, 293, 1566, 577, 867, 1413, 281, 1190, 309, 13, 51596], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 903, "seek": 430750, "start": 4332.14, "end": 4333.5, "text": " And that's what this frames argument.", "tokens": [51596, 400, 300, 311, 437, 341, 12083, 6770, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 904, "seek": 430750, "start": 4333.5, "end": 4336.86, "text": " This says run this function this many times.", "tokens": [51664, 639, 1619, 1190, 341, 2445, 341, 867, 1413, 13, 51832], "temperature": 0.0, "avg_logprob": -0.2416900572229604, "compression_ratio": 1.902542372881356, "no_speech_prob": 2.657724564869568e-07}, {"id": 905, "seek": 433750, "start": 4338.5, "end": 4342.78, "text": " And then create an animation that basically contains the result of that", "tokens": [50414, 400, 550, 1884, 364, 9603, 300, 1936, 8306, 264, 1874, 295, 300, 50628], "temperature": 0.0, "avg_logprob": -0.3927886430607286, "compression_ratio": 1.582010582010582, "no_speech_prob": 9.777224363460846e-08}, {"id": 906, "seek": 433750, "start": 4342.78, "end": 4345.9, "text": " with a 500 millisecond interval between each one.", "tokens": [50628, 365, 257, 5923, 27940, 18882, 15035, 1296, 1184, 472, 13, 50784], "temperature": 0.0, "avg_logprob": -0.3927886430607286, "compression_ratio": 1.582010582010582, "no_speech_prob": 9.777224363460846e-08}, {"id": 907, "seek": 433750, "start": 4348.54, "end": 4351.22, "text": " So what's this do one gonna do?", "tokens": [50916, 407, 437, 311, 341, 360, 472, 799, 360, 30, 51050], "temperature": 0.0, "avg_logprob": -0.3927886430607286, "compression_ratio": 1.582010582010582, "no_speech_prob": 9.777224363460846e-08}, {"id": 908, "seek": 433750, "start": 4351.22, "end": 4353.26, "text": " To create one frame of animation,", "tokens": [51050, 1407, 1884, 472, 3920, 295, 9603, 11, 51152], "temperature": 0.0, "avg_logprob": -0.3927886430607286, "compression_ratio": 1.582010582010582, "no_speech_prob": 9.777224363460846e-08}, {"id": 909, "seek": 433750, "start": 4355.78, "end": 4358.54, "text": " we will call our one update.", "tokens": [51278, 321, 486, 818, 527, 472, 5623, 13, 51416], "temperature": 0.0, "avg_logprob": -0.3927886430607286, "compression_ratio": 1.582010582010582, "no_speech_prob": 9.777224363460846e-08}, {"id": 910, "seek": 433750, "start": 4360.5, "end": 4362.26, "text": " Here it is, one update, right?", "tokens": [51514, 1692, 309, 307, 11, 472, 5623, 11, 558, 30, 51602], "temperature": 0.0, "avg_logprob": -0.3927886430607286, "compression_ratio": 1.582010582010582, "no_speech_prob": 9.777224363460846e-08}, {"id": 911, "seek": 433750, "start": 4362.26, "end": 4363.86, "text": " We're gonna call this.", "tokens": [51602, 492, 434, 799, 818, 341, 13, 51682], "temperature": 0.0, "avg_logprob": -0.3927886430607286, "compression_ratio": 1.582010582010582, "no_speech_prob": 9.777224363460846e-08}, {"id": 912, "seek": 433750, "start": 4363.86, "end": 4366.3, "text": " That's gonna update our x's.", "tokens": [51682, 663, 311, 799, 5623, 527, 2031, 311, 13, 51804], "temperature": 0.0, "avg_logprob": -0.3927886430607286, "compression_ratio": 1.582010582010582, "no_speech_prob": 9.777224363460846e-08}, {"id": 913, "seek": 436630, "start": 4366.34, "end": 4370.7, "text": " And then we're gonna have an axis, which we've created here.", "tokens": [50366, 400, 550, 321, 434, 799, 362, 364, 10298, 11, 597, 321, 600, 2942, 510, 13, 50584], "temperature": 0.0, "avg_logprob": -0.2850230173631148, "compression_ratio": 1.6683673469387754, "no_speech_prob": 2.536018826049258e-07}, {"id": 914, "seek": 436630, "start": 4372.42, "end": 4375.5, "text": " So we're gonna clear whatever was on the plot before and", "tokens": [50670, 407, 321, 434, 799, 1850, 2035, 390, 322, 264, 7542, 949, 293, 50824], "temperature": 0.0, "avg_logprob": -0.2850230173631148, "compression_ratio": 1.6683673469387754, "no_speech_prob": 2.536018826049258e-07}, {"id": 915, "seek": 436630, "start": 4375.5, "end": 4378.66, "text": " plot our new data on that axis.", "tokens": [50824, 7542, 527, 777, 1412, 322, 300, 10298, 13, 50982], "temperature": 0.0, "avg_logprob": -0.2850230173631148, "compression_ratio": 1.6683673469387754, "no_speech_prob": 2.536018826049258e-07}, {"id": 916, "seek": 436630, "start": 4381.900000000001, "end": 4385.34, "text": " And then the only other thing you need to do is that the very first time", "tokens": [51144, 400, 550, 264, 787, 661, 551, 291, 643, 281, 360, 307, 300, 264, 588, 700, 565, 51316], "temperature": 0.0, "avg_logprob": -0.2850230173631148, "compression_ratio": 1.6683673469387754, "no_speech_prob": 2.536018826049258e-07}, {"id": 917, "seek": 436630, "start": 4385.34, "end": 4389.42, "text": " it calls it, we want to plot it before running.", "tokens": [51316, 309, 5498, 309, 11, 321, 528, 281, 7542, 309, 949, 2614, 13, 51520], "temperature": 0.0, "avg_logprob": -0.2850230173631148, "compression_ratio": 1.6683673469387754, "no_speech_prob": 2.536018826049258e-07}, {"id": 918, "seek": 436630, "start": 4389.42, "end": 4393.38, "text": " And d is gonna be passed automatically the frame number.", "tokens": [51520, 400, 274, 307, 799, 312, 4678, 6772, 264, 3920, 1230, 13, 51718], "temperature": 0.0, "avg_logprob": -0.2850230173631148, "compression_ratio": 1.6683673469387754, "no_speech_prob": 2.536018826049258e-07}, {"id": 919, "seek": 439338, "start": 4393.38, "end": 4397.62, "text": " So for the 0th frame, we're gonna not do the update,", "tokens": [50364, 407, 337, 264, 1958, 392, 3920, 11, 321, 434, 799, 406, 360, 264, 5623, 11, 50576], "temperature": 0.0, "avg_logprob": -0.34280163634057137, "compression_ratio": 1.608910891089109, "no_speech_prob": 4.73790436217314e-07}, {"id": 920, "seek": 439338, "start": 4397.62, "end": 4399.5, "text": " we're just gonna plot the data as it is already.", "tokens": [50576, 321, 434, 445, 799, 7542, 264, 1412, 382, 309, 307, 1217, 13, 50670], "temperature": 0.0, "avg_logprob": -0.34280163634057137, "compression_ratio": 1.608910891089109, "no_speech_prob": 4.73790436217314e-07}, {"id": 921, "seek": 439338, "start": 4403.1, "end": 4405.86, "text": " I guess another way we could have done that would have been just to say,", "tokens": [50850, 286, 2041, 1071, 636, 321, 727, 362, 1096, 300, 576, 362, 668, 445, 281, 584, 11, 50988], "temperature": 0.0, "avg_logprob": -0.34280163634057137, "compression_ratio": 1.608910891089109, "no_speech_prob": 4.73790436217314e-07}, {"id": 922, "seek": 439338, "start": 4405.86, "end": 4413.900000000001, "text": " if d, then do the update, I suppose.", "tokens": [50988, 498, 274, 11, 550, 360, 264, 5623, 11, 286, 7297, 13, 51390], "temperature": 0.0, "avg_logprob": -0.34280163634057137, "compression_ratio": 1.608910891089109, "no_speech_prob": 4.73790436217314e-07}, {"id": 923, "seek": 439338, "start": 4415.34, "end": 4416.3, "text": " That should work too.", "tokens": [51462, 663, 820, 589, 886, 13, 51510], "temperature": 0.0, "avg_logprob": -0.34280163634057137, "compression_ratio": 1.608910891089109, "no_speech_prob": 4.73790436217314e-07}, {"id": 924, "seek": 439338, "start": 4416.3, "end": 4417.66, "text": " Maybe it's even simpler.", "tokens": [51510, 2704, 309, 311, 754, 18587, 13, 51578], "temperature": 0.0, "avg_logprob": -0.34280163634057137, "compression_ratio": 1.608910891089109, "no_speech_prob": 4.73790436217314e-07}, {"id": 925, "seek": 439338, "start": 4417.66, "end": 4419.18, "text": " Let's see if I just broke it.", "tokens": [51578, 961, 311, 536, 498, 286, 445, 6902, 309, 13, 51654], "temperature": 0.0, "avg_logprob": -0.34280163634057137, "compression_ratio": 1.608910891089109, "no_speech_prob": 4.73790436217314e-07}, {"id": 926, "seek": 439338, "start": 4419.18, "end": 4421.82, "text": " Okay, so we're gonna clone our data.", "tokens": [51654, 1033, 11, 370, 321, 434, 799, 26506, 527, 1412, 13, 51786], "temperature": 0.0, "avg_logprob": -0.34280163634057137, "compression_ratio": 1.608910891089109, "no_speech_prob": 4.73790436217314e-07}, {"id": 927, "seek": 442182, "start": 4421.82, "end": 4424.42, "text": " We're gonna create our figure and our subplots.", "tokens": [50364, 492, 434, 799, 1884, 527, 2573, 293, 527, 1422, 564, 1971, 13, 50494], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 928, "seek": 442182, "start": 4424.42, "end": 4427.66, "text": " We're gonna call func animation, calling do one five times.", "tokens": [50494, 492, 434, 799, 818, 1019, 66, 9603, 11, 5141, 360, 472, 1732, 1413, 13, 50656], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 929, "seek": 442182, "start": 4429.9, "end": 4432.58, "text": " And then we're gonna display the animation.", "tokens": [50768, 400, 550, 321, 434, 799, 4674, 264, 9603, 13, 50902], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 930, "seek": 442182, "start": 4432.58, "end": 4433.78, "text": " And so let's see.", "tokens": [50902, 400, 370, 718, 311, 536, 13, 50962], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 931, "seek": 442182, "start": 4433.78, "end": 4437.46, "text": " So HTML takes some HTML and displays it.", "tokens": [50962, 407, 17995, 2516, 512, 17995, 293, 20119, 309, 13, 51146], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 932, "seek": 442182, "start": 4437.46, "end": 4439.82, "text": " And to jsHTML creates some HTML.", "tokens": [51146, 400, 281, 42713, 39, 51, 12683, 7829, 512, 17995, 13, 51264], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 933, "seek": 442182, "start": 4439.82, "end": 4440.94, "text": " So that's why it's created this.", "tokens": [51264, 407, 300, 311, 983, 309, 311, 2942, 341, 13, 51320], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 934, "seek": 442182, "start": 4440.94, "end": 4443.0599999999995, "text": " HTML includes JavaScript.", "tokens": [51320, 17995, 5974, 15778, 13, 51426], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 935, "seek": 442182, "start": 4443.0599999999995, "end": 4444.179999999999, "text": " And so we'll click Run.", "tokens": [51426, 400, 370, 321, 603, 2052, 8950, 13, 51482], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 936, "seek": 442182, "start": 4445.54, "end": 4447.219999999999, "text": " One, two, three, four, five.", "tokens": [51550, 1485, 11, 732, 11, 1045, 11, 1451, 11, 1732, 13, 51634], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 937, "seek": 442182, "start": 4447.219999999999, "end": 4448.219999999999, "text": " There's the five steps.", "tokens": [51634, 821, 311, 264, 1732, 4439, 13, 51684], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 938, "seek": 442182, "start": 4448.219999999999, "end": 4450.9, "text": " So if I click Loop, you'll see them running again and again.", "tokens": [51684, 407, 498, 286, 2052, 45660, 11, 291, 603, 536, 552, 2614, 797, 293, 797, 13, 51818], "temperature": 0.0, "avg_logprob": -0.30904441721299114, "compression_ratio": 1.71875, "no_speech_prob": 5.422217327577528e-06}, {"id": 939, "seek": 445182, "start": 4452.82, "end": 4454.42, "text": " Fantastic.", "tokens": [50414, 21320, 13, 50494], "temperature": 0.0, "avg_logprob": -0.40110185984018687, "compression_ratio": 1.4404761904761905, "no_speech_prob": 8.315279274029308e-07}, {"id": 940, "seek": 445182, "start": 4454.42, "end": 4459.58, "text": " So that's how easy it is to create a matplotlib animation.", "tokens": [50494, 407, 300, 311, 577, 1858, 309, 307, 281, 1884, 257, 3803, 564, 310, 38270, 9603, 13, 50752], "temperature": 0.0, "avg_logprob": -0.40110185984018687, "compression_ratio": 1.4404761904761905, "no_speech_prob": 8.315279274029308e-07}, {"id": 941, "seek": 445182, "start": 4461.58, "end": 4464.86, "text": " So hopefully now you can use that to play around with some fun stable", "tokens": [50852, 407, 4696, 586, 291, 393, 764, 300, 281, 862, 926, 365, 512, 1019, 8351, 51016], "temperature": 0.0, "avg_logprob": -0.40110185984018687, "compression_ratio": 1.4404761904761905, "no_speech_prob": 8.315279274029308e-07}, {"id": 942, "seek": 445182, "start": 4464.86, "end": 4466.299999999999, "text": " diffusion animations as well.", "tokens": [51016, 25242, 22868, 382, 731, 13, 51088], "temperature": 0.0, "avg_logprob": -0.40110185984018687, "compression_ratio": 1.4404761904761905, "no_speech_prob": 8.315279274029308e-07}, {"id": 943, "seek": 445182, "start": 4468.62, "end": 4472.54, "text": " You don't just have to use to jsHTML.", "tokens": [51204, 509, 500, 380, 445, 362, 281, 764, 281, 42713, 39, 51, 12683, 13, 51400], "temperature": 0.0, "avg_logprob": -0.40110185984018687, "compression_ratio": 1.4404761904761905, "no_speech_prob": 8.315279274029308e-07}, {"id": 944, "seek": 445182, "start": 4472.54, "end": 4478.139999999999, "text": " You can also create, Oopsie daisy.", "tokens": [51400, 509, 393, 611, 1884, 11, 21726, 414, 1120, 14169, 13, 51680], "temperature": 0.0, "avg_logprob": -0.40110185984018687, "compression_ratio": 1.4404761904761905, "no_speech_prob": 8.315279274029308e-07}, {"id": 945, "seek": 447814, "start": 4479.14, "end": 4481.14, "text": " You can also create movies, for example.", "tokens": [50414, 509, 393, 611, 1884, 6233, 11, 337, 1365, 13, 50514], "temperature": 0.0, "avg_logprob": -0.4502174280866792, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.952587626874447e-05}, {"id": 946, "seek": 447814, "start": 4488.660000000001, "end": 4492.46, "text": " So you can call toHTML5Video would be another option.", "tokens": [50890, 407, 291, 393, 818, 281, 39, 51, 12683, 20, 46287, 576, 312, 1071, 3614, 13, 51080], "temperature": 0.0, "avg_logprob": -0.4502174280866792, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.952587626874447e-05}, {"id": 947, "seek": 447814, "start": 4492.46, "end": 4496.1, "text": " And you can save an animation as a movie file.", "tokens": [51080, 400, 291, 393, 3155, 364, 9603, 382, 257, 3169, 3991, 13, 51262], "temperature": 0.0, "avg_logprob": -0.4502174280866792, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.952587626874447e-05}, {"id": 948, "seek": 447814, "start": 4496.1, "end": 4498.06, "text": " So there's all these different options for that.", "tokens": [51262, 407, 456, 311, 439, 613, 819, 3956, 337, 300, 13, 51360], "temperature": 0.0, "avg_logprob": -0.4502174280866792, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.952587626874447e-05}, {"id": 949, "seek": 447814, "start": 4499.18, "end": 4501.62, "text": " But hopefully that's enough to get you started.", "tokens": [51416, 583, 4696, 300, 311, 1547, 281, 483, 291, 1409, 13, 51538], "temperature": 0.0, "avg_logprob": -0.4502174280866792, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.952587626874447e-05}, {"id": 950, "seek": 447814, "start": 4501.62, "end": 4507.58, "text": " So for your homework, I would like you,", "tokens": [51538, 407, 337, 428, 14578, 11, 286, 576, 411, 291, 11, 51836], "temperature": 0.0, "avg_logprob": -0.4502174280866792, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.952587626874447e-05}, {"id": 951, "seek": 450758, "start": 4507.98, "end": 4514.62, "text": " when you create your K-means or whatever, to try to create your own animation.", "tokens": [50384, 562, 291, 1884, 428, 591, 12, 1398, 599, 420, 2035, 11, 281, 853, 281, 1884, 428, 1065, 9603, 13, 50716], "temperature": 0.0, "avg_logprob": -0.3206032013224664, "compression_ratio": 1.6331877729257642, "no_speech_prob": 4.4001171772833914e-05}, {"id": 952, "seek": 450758, "start": 4514.62, "end": 4518.58, "text": " Or create an animation of some stable diffusion thing that you're playing with.", "tokens": [50716, 1610, 1884, 364, 9603, 295, 512, 8351, 25242, 551, 300, 291, 434, 2433, 365, 13, 50914], "temperature": 0.0, "avg_logprob": -0.3206032013224664, "compression_ratio": 1.6331877729257642, "no_speech_prob": 4.4001171772833914e-05}, {"id": 953, "seek": 450758, "start": 4521.1, "end": 4523.54, "text": " So don't forget this important ax.clear.", "tokens": [51040, 407, 500, 380, 2870, 341, 1021, 6360, 13, 43679, 13, 51162], "temperature": 0.0, "avg_logprob": -0.3206032013224664, "compression_ratio": 1.6331877729257642, "no_speech_prob": 4.4001171772833914e-05}, {"id": 954, "seek": 450758, "start": 4523.54, "end": 4526.38, "text": " Without the ax.clear, it prints it on top of the last one.", "tokens": [51162, 9129, 264, 6360, 13, 43679, 11, 309, 22305, 309, 322, 1192, 295, 264, 1036, 472, 13, 51304], "temperature": 0.0, "avg_logprob": -0.3206032013224664, "compression_ratio": 1.6331877729257642, "no_speech_prob": 4.4001171772833914e-05}, {"id": 955, "seek": 450758, "start": 4528.0199999999995, "end": 4529.98, "text": " Which sometimes is what you want, to be fair.", "tokens": [51386, 3013, 2171, 307, 437, 291, 528, 11, 281, 312, 3143, 13, 51484], "temperature": 0.0, "avg_logprob": -0.3206032013224664, "compression_ratio": 1.6331877729257642, "no_speech_prob": 4.4001171772833914e-05}, {"id": 956, "seek": 450758, "start": 4529.98, "end": 4531.42, "text": " But in this case, it's not what I wanted.", "tokens": [51484, 583, 294, 341, 1389, 11, 309, 311, 406, 437, 286, 1415, 13, 51556], "temperature": 0.0, "avg_logprob": -0.3206032013224664, "compression_ratio": 1.6331877729257642, "no_speech_prob": 4.4001171772833914e-05}, {"id": 957, "seek": 450758, "start": 4533.38, "end": 4535.9, "text": " All right, so kind of slow.", "tokens": [51654, 1057, 558, 11, 370, 733, 295, 2964, 13, 51780], "temperature": 0.0, "avg_logprob": -0.3206032013224664, "compression_ratio": 1.6331877729257642, "no_speech_prob": 4.4001171772833914e-05}, {"id": 958, "seek": 453590, "start": 4536.9, "end": 4539.099999999999, "text": " Half a second for not that much data.", "tokens": [50414, 15917, 257, 1150, 337, 406, 300, 709, 1412, 13, 50524], "temperature": 0.0, "avg_logprob": -0.3561450867425828, "compression_ratio": 1.541899441340782, "no_speech_prob": 1.0677027830752195e-06}, {"id": 959, "seek": 453590, "start": 4540.099999999999, "end": 4542.46, "text": " I'm sure it would be nice if it was faster.", "tokens": [50574, 286, 478, 988, 309, 576, 312, 1481, 498, 309, 390, 4663, 13, 50692], "temperature": 0.0, "avg_logprob": -0.3561450867425828, "compression_ratio": 1.541899441340782, "no_speech_prob": 1.0677027830752195e-06}, {"id": 960, "seek": 453590, "start": 4542.46, "end": 4545.74, "text": " Well, the good news is we can GPU accelerate it.", "tokens": [50692, 1042, 11, 264, 665, 2583, 307, 321, 393, 18407, 21341, 309, 13, 50856], "temperature": 0.0, "avg_logprob": -0.3561450867425828, "compression_ratio": 1.541899441340782, "no_speech_prob": 1.0677027830752195e-06}, {"id": 961, "seek": 453590, "start": 4547.299999999999, "end": 4554.98, "text": " The bad news is it's not gonna GPU accelerate that well because of this loop.", "tokens": [50934, 440, 1578, 2583, 307, 309, 311, 406, 799, 18407, 21341, 300, 731, 570, 295, 341, 6367, 13, 51318], "temperature": 0.0, "avg_logprob": -0.3561450867425828, "compression_ratio": 1.541899441340782, "no_speech_prob": 1.0677027830752195e-06}, {"id": 962, "seek": 453590, "start": 4554.98, "end": 4556.82, "text": " This is looping 1,500 times.", "tokens": [51318, 639, 307, 6367, 278, 502, 11, 7526, 1413, 13, 51410], "temperature": 0.0, "avg_logprob": -0.3561450867425828, "compression_ratio": 1.541899441340782, "no_speech_prob": 1.0677027830752195e-06}, {"id": 963, "seek": 453590, "start": 4556.82, "end": 4561.98, "text": " So looping's not gonna run on the GPU.", "tokens": [51410, 407, 6367, 278, 311, 406, 799, 1190, 322, 264, 18407, 13, 51668], "temperature": 0.0, "avg_logprob": -0.3561450867425828, "compression_ratio": 1.541899441340782, "no_speech_prob": 1.0677027830752195e-06}, {"id": 964, "seek": 456198, "start": 4561.98, "end": 4565.0599999999995, "text": " So the best we could do with this would be to move all this to the GPU.", "tokens": [50364, 407, 264, 1151, 321, 727, 360, 365, 341, 576, 312, 281, 1286, 439, 341, 281, 264, 18407, 13, 50518], "temperature": 0.0, "avg_logprob": -0.2845115260074013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 7.571149467366922e-07}, {"id": 965, "seek": 456198, "start": 4566.139999999999, "end": 4572.339999999999, "text": " Now the problem is that calling something on the GPU 1,500 times from Python", "tokens": [50572, 823, 264, 1154, 307, 300, 5141, 746, 322, 264, 18407, 502, 11, 7526, 1413, 490, 15329, 50882], "temperature": 0.0, "avg_logprob": -0.2845115260074013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 7.571149467366922e-07}, {"id": 966, "seek": 456198, "start": 4572.339999999999, "end": 4573.98, "text": " is a really bad idea.", "tokens": [50882, 307, 257, 534, 1578, 1558, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2845115260074013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 7.571149467366922e-07}, {"id": 967, "seek": 456198, "start": 4573.98, "end": 4578.86, "text": " Because there's this kind of huge communication overhead of this kind of", "tokens": [50964, 1436, 456, 311, 341, 733, 295, 2603, 6101, 19922, 295, 341, 733, 295, 51208], "temperature": 0.0, "avg_logprob": -0.2845115260074013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 7.571149467366922e-07}, {"id": 968, "seek": 456198, "start": 4578.86, "end": 4583.54, "text": " flow of control and data switching back between the CPU and the GPU.", "tokens": [51208, 3095, 295, 1969, 293, 1412, 16493, 646, 1296, 264, 13199, 293, 264, 18407, 13, 51442], "temperature": 0.0, "avg_logprob": -0.2845115260074013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 7.571149467366922e-07}, {"id": 969, "seek": 456198, "start": 4584.7, "end": 4587.0199999999995, "text": " It's the kernel launching overhead.", "tokens": [51500, 467, 311, 264, 28256, 18354, 19922, 13, 51616], "temperature": 0.0, "avg_logprob": -0.2845115260074013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 7.571149467366922e-07}, {"id": 970, "seek": 456198, "start": 4587.0199999999995, "end": 4588.459999999999, "text": " It's bad news.", "tokens": [51616, 467, 311, 1578, 2583, 13, 51688], "temperature": 0.0, "avg_logprob": -0.2845115260074013, "compression_ratio": 1.6061946902654867, "no_speech_prob": 7.571149467366922e-07}, {"id": 971, "seek": 458846, "start": 4588.5, "end": 4592.86, "text": " So you don't wanna have a really big,", "tokens": [50366, 407, 291, 500, 380, 1948, 362, 257, 534, 955, 11, 50584], "temperature": 0.0, "avg_logprob": -0.303498292580629, "compression_ratio": 1.4787234042553192, "no_speech_prob": 8.990961077870452e-07}, {"id": 972, "seek": 458846, "start": 4592.86, "end": 4598.9800000000005, "text": " fast Python loop that inside it calls CUDA code, it calls GPU code.", "tokens": [50584, 2370, 15329, 6367, 300, 1854, 309, 5498, 29777, 7509, 3089, 11, 309, 5498, 18407, 3089, 13, 50890], "temperature": 0.0, "avg_logprob": -0.303498292580629, "compression_ratio": 1.4787234042553192, "no_speech_prob": 8.990961077870452e-07}, {"id": 973, "seek": 458846, "start": 4598.9800000000005, "end": 4602.62, "text": " So we need to make all of this run without the loop,", "tokens": [50890, 407, 321, 643, 281, 652, 439, 295, 341, 1190, 1553, 264, 6367, 11, 51072], "temperature": 0.0, "avg_logprob": -0.303498292580629, "compression_ratio": 1.4787234042553192, "no_speech_prob": 8.990961077870452e-07}, {"id": 974, "seek": 458846, "start": 4603.86, "end": 4605.9, "text": " which we could do with broadcasting.", "tokens": [51134, 597, 321, 727, 360, 365, 30024, 13, 51236], "temperature": 0.0, "avg_logprob": -0.303498292580629, "compression_ratio": 1.4787234042553192, "no_speech_prob": 8.990961077870452e-07}, {"id": 975, "seek": 458846, "start": 4607.42, "end": 4610.14, "text": " So let's roll up our sleeves and", "tokens": [51312, 407, 718, 311, 3373, 493, 527, 24555, 293, 51448], "temperature": 0.0, "avg_logprob": -0.303498292580629, "compression_ratio": 1.4787234042553192, "no_speech_prob": 8.990961077870452e-07}, {"id": 976, "seek": 458846, "start": 4610.14, "end": 4612.06, "text": " try to get the broadcast version of this working.", "tokens": [51448, 853, 281, 483, 264, 9975, 3037, 295, 341, 1364, 13, 51544], "temperature": 0.0, "avg_logprob": -0.303498292580629, "compression_ratio": 1.4787234042553192, "no_speech_prob": 8.990961077870452e-07}, {"id": 977, "seek": 461206, "start": 4612.9800000000005, "end": 4618.620000000001, "text": " So generally speaking, the way we tend to do things with broadcasting on a GPU is", "tokens": [50410, 407, 5101, 4124, 11, 264, 636, 321, 3928, 281, 360, 721, 365, 30024, 322, 257, 18407, 307, 50692], "temperature": 0.0, "avg_logprob": -0.3255126696674764, "compression_ratio": 1.8285714285714285, "no_speech_prob": 3.3405392514396226e-06}, {"id": 978, "seek": 461206, "start": 4618.620000000001, "end": 4621.38, "text": " we create batches or mini-batches.", "tokens": [50692, 321, 1884, 15245, 279, 420, 8382, 12, 65, 852, 279, 13, 50830], "temperature": 0.0, "avg_logprob": -0.3255126696674764, "compression_ratio": 1.8285714285714285, "no_speech_prob": 3.3405392514396226e-06}, {"id": 979, "seek": 461206, "start": 4621.38, "end": 4624.18, "text": " So to create batches or mini-batches,", "tokens": [50830, 407, 281, 1884, 15245, 279, 420, 8382, 12, 65, 852, 279, 11, 50970], "temperature": 0.0, "avg_logprob": -0.3255126696674764, "compression_ratio": 1.8285714285714285, "no_speech_prob": 3.3405392514396226e-06}, {"id": 980, "seek": 461206, "start": 4624.18, "end": 4629.22, "text": " we normally just call them batches nowadays, we create a batch size.", "tokens": [50970, 321, 5646, 445, 818, 552, 15245, 279, 13434, 11, 321, 1884, 257, 15245, 2744, 13, 51222], "temperature": 0.0, "avg_logprob": -0.3255126696674764, "compression_ratio": 1.8285714285714285, "no_speech_prob": 3.3405392514396226e-06}, {"id": 981, "seek": 461206, "start": 4629.22, "end": 4631.820000000001, "text": " So let's say we're gonna do a batch size of five.", "tokens": [51222, 407, 718, 311, 584, 321, 434, 799, 360, 257, 15245, 2744, 295, 1732, 13, 51352], "temperature": 0.0, "avg_logprob": -0.3255126696674764, "compression_ratio": 1.8285714285714285, "no_speech_prob": 3.3405392514396226e-06}, {"id": 982, "seek": 461206, "start": 4631.820000000001, "end": 4634.5, "text": " So we're gonna do five at a time.", "tokens": [51352, 407, 321, 434, 799, 360, 1732, 412, 257, 565, 13, 51486], "temperature": 0.0, "avg_logprob": -0.3255126696674764, "compression_ratio": 1.8285714285714285, "no_speech_prob": 3.3405392514396226e-06}, {"id": 983, "seek": 461206, "start": 4636.34, "end": 4639.700000000001, "text": " All right, so how do we do five at a time?", "tokens": [51578, 1057, 558, 11, 370, 577, 360, 321, 360, 1732, 412, 257, 565, 30, 51746], "temperature": 0.0, "avg_logprob": -0.3255126696674764, "compression_ratio": 1.8285714285714285, "no_speech_prob": 3.3405392514396226e-06}, {"id": 984, "seek": 461206, "start": 4639.700000000001, "end": 4641.06, "text": " This is only doing one at a time.", "tokens": [51746, 639, 307, 787, 884, 472, 412, 257, 565, 13, 51814], "temperature": 0.0, "avg_logprob": -0.3255126696674764, "compression_ratio": 1.8285714285714285, "no_speech_prob": 3.3405392514396226e-06}, {"id": 985, "seek": 464106, "start": 4641.1, "end": 4642.18, "text": " How do we do five at a time?", "tokens": [50366, 1012, 360, 321, 360, 1732, 412, 257, 565, 30, 50420], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 986, "seek": 464106, "start": 4644.46, "end": 4646.5, "text": " As before, let's clone our data.", "tokens": [50534, 1018, 949, 11, 718, 311, 26506, 527, 1412, 13, 50636], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 987, "seek": 464106, "start": 4646.5, "end": 4648.9400000000005, "text": " And this time, little x for our testing.", "tokens": [50636, 400, 341, 565, 11, 707, 2031, 337, 527, 4997, 13, 50758], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 988, "seek": 464106, "start": 4648.9400000000005, "end": 4652.54, "text": " So we're gonna do everything ahead of time, little tests, as we always do.", "tokens": [50758, 407, 321, 434, 799, 360, 1203, 2286, 295, 565, 11, 707, 6921, 11, 382, 321, 1009, 360, 13, 50938], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 989, "seek": 464106, "start": 4652.54, "end": 4656.820000000001, "text": " This is not now x0 anymore, but it's x colon bs.", "tokens": [50938, 639, 307, 406, 586, 2031, 15, 3602, 11, 457, 309, 311, 2031, 8255, 272, 82, 13, 51152], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 990, "seek": 464106, "start": 4656.820000000001, "end": 4659.820000000001, "text": " So it's the first five, this is now the first five items.", "tokens": [51152, 407, 309, 311, 264, 700, 1732, 11, 341, 307, 586, 264, 700, 1732, 4754, 13, 51302], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 991, "seek": 464106, "start": 4660.860000000001, "end": 4664.740000000001, "text": " Okay, so little x is now a 5 by 2 matrix.", "tokens": [51354, 1033, 11, 370, 707, 2031, 307, 586, 257, 1025, 538, 568, 8141, 13, 51548], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 992, "seek": 464106, "start": 4664.740000000001, "end": 4667.14, "text": " This is our mini-batch, the first five items.", "tokens": [51548, 639, 307, 527, 8382, 12, 65, 852, 11, 264, 700, 1732, 4754, 13, 51668], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 993, "seek": 464106, "start": 4668.580000000001, "end": 4670.860000000001, "text": " As before, our data itself is 1500 by 2.", "tokens": [51740, 1018, 949, 11, 527, 1412, 2564, 307, 22671, 538, 568, 13, 51854], "temperature": 0.0, "avg_logprob": -0.2865829180954094, "compression_ratio": 1.7574468085106383, "no_speech_prob": 1.9033847138416604e-06}, {"id": 994, "seek": 467106, "start": 4672.06, "end": 4674.9800000000005, "text": " All right, so we need a distance calculation.", "tokens": [50414, 1057, 558, 11, 370, 321, 643, 257, 4560, 17108, 13, 50560], "temperature": 0.0, "avg_logprob": -0.32090166452768687, "compression_ratio": 1.7049180327868851, "no_speech_prob": 1.855391076333035e-07}, {"id": 995, "seek": 467106, "start": 4674.9800000000005, "end": 4678.22, "text": " But previously, our distance calculation,", "tokens": [50560, 583, 8046, 11, 527, 4560, 17108, 11, 50722], "temperature": 0.0, "avg_logprob": -0.32090166452768687, "compression_ratio": 1.7049180327868851, "no_speech_prob": 1.855391076333035e-07}, {"id": 996, "seek": 467106, "start": 4682.900000000001, "end": 4686.9400000000005, "text": " Previously, our distance calculation only worked if little x was a single number.", "tokens": [50956, 33606, 11, 527, 4560, 17108, 787, 2732, 498, 707, 2031, 390, 257, 2167, 1230, 13, 51158], "temperature": 0.0, "avg_logprob": -0.32090166452768687, "compression_ratio": 1.7049180327868851, "no_speech_prob": 1.855391076333035e-07}, {"id": 997, "seek": 467106, "start": 4688.14, "end": 4692.3, "text": " And it returned just the distances from that to everything in big X.", "tokens": [51218, 400, 309, 8752, 445, 264, 22182, 490, 300, 281, 1203, 294, 955, 1783, 13, 51426], "temperature": 0.0, "avg_logprob": -0.32090166452768687, "compression_ratio": 1.7049180327868851, "no_speech_prob": 1.855391076333035e-07}, {"id": 998, "seek": 467106, "start": 4693.580000000001, "end": 4699.820000000001, "text": " But we need something that's actually going to be return a matrix, right?", "tokens": [51490, 583, 321, 643, 746, 300, 311, 767, 516, 281, 312, 2736, 257, 8141, 11, 558, 30, 51802], "temperature": 0.0, "avg_logprob": -0.32090166452768687, "compression_ratio": 1.7049180327868851, "no_speech_prob": 1.855391076333035e-07}, {"id": 999, "seek": 469982, "start": 4699.82, "end": 4706.62, "text": " We've got, Let's see,", "tokens": [50364, 492, 600, 658, 11, 961, 311, 536, 11, 50704], "temperature": 0.0, "avg_logprob": -0.47042954184792257, "compression_ratio": 1.2735042735042734, "no_speech_prob": 1.3709569657294196e-06}, {"id": 1000, "seek": 469982, "start": 4706.62, "end": 4716.66, "text": " we've got 5 by 2 in little x.", "tokens": [50704, 321, 600, 658, 1025, 538, 568, 294, 707, 2031, 13, 51206], "temperature": 0.0, "avg_logprob": -0.47042954184792257, "compression_ratio": 1.2735042735042734, "no_speech_prob": 1.3709569657294196e-06}, {"id": 1001, "seek": 469982, "start": 4718.259999999999, "end": 4723.86, "text": " And then in big X, we've got something much bigger.", "tokens": [51286, 400, 550, 294, 955, 1783, 11, 321, 600, 658, 746, 709, 3801, 13, 51566], "temperature": 0.0, "avg_logprob": -0.47042954184792257, "compression_ratio": 1.2735042735042734, "no_speech_prob": 1.3709569657294196e-06}, {"id": 1002, "seek": 469982, "start": 4723.86, "end": 4725.179999999999, "text": " Not to scale, obviously.", "tokens": [51566, 1726, 281, 4373, 11, 2745, 13, 51632], "temperature": 0.0, "avg_logprob": -0.47042954184792257, "compression_ratio": 1.2735042735042734, "no_speech_prob": 1.3709569657294196e-06}, {"id": 1003, "seek": 469982, "start": 4726.7, "end": 4728.46, "text": " We've got 1500 by 2.", "tokens": [51708, 492, 600, 658, 22671, 538, 568, 13, 51796], "temperature": 0.0, "avg_logprob": -0.47042954184792257, "compression_ratio": 1.2735042735042734, "no_speech_prob": 1.3709569657294196e-06}, {"id": 1004, "seek": 472982, "start": 4730.82, "end": 4740.0199999999995, "text": " And what is the distance between these two things?", "tokens": [50414, 400, 437, 307, 264, 4560, 1296, 613, 732, 721, 30, 50874], "temperature": 0.0, "avg_logprob": -0.4016731466565813, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.02884046732288e-08}, {"id": 1005, "seek": 472982, "start": 4740.0199999999995, "end": 4742.7, "text": " Well, if you think about it,", "tokens": [50874, 1042, 11, 498, 291, 519, 466, 309, 11, 51008], "temperature": 0.0, "avg_logprob": -0.4016731466565813, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.02884046732288e-08}, {"id": 1006, "seek": 472982, "start": 4742.7, "end": 4749.74, "text": " there's gonna be a distance between item 1 and item 1.", "tokens": [51008, 456, 311, 799, 312, 257, 4560, 1296, 3174, 502, 293, 3174, 502, 13, 51360], "temperature": 0.0, "avg_logprob": -0.4016731466565813, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.02884046732288e-08}, {"id": 1007, "seek": 472982, "start": 4752.0599999999995, "end": 4757.54, "text": " But there's also gonna be a distance between item 1 and item 2.", "tokens": [51476, 583, 456, 311, 611, 799, 312, 257, 4560, 1296, 3174, 502, 293, 3174, 568, 13, 51750], "temperature": 0.0, "avg_logprob": -0.4016731466565813, "compression_ratio": 1.6923076923076923, "no_speech_prob": 3.02884046732288e-08}, {"id": 1008, "seek": 475754, "start": 4757.54, "end": 4761.86, "text": " And there's gonna be a distance between,", "tokens": [50364, 400, 456, 311, 799, 312, 257, 4560, 1296, 11, 50580], "temperature": 0.0, "avg_logprob": -0.39794634650735294, "compression_ratio": 1.5076923076923077, "no_speech_prob": 1.7704263655105024e-07}, {"id": 1009, "seek": 475754, "start": 4761.86, "end": 4767.3, "text": " let's use a different color for the next one, item 2 and item 1.", "tokens": [50580, 718, 311, 764, 257, 819, 2017, 337, 264, 958, 472, 11, 3174, 568, 293, 3174, 502, 13, 50852], "temperature": 0.0, "avg_logprob": -0.39794634650735294, "compression_ratio": 1.5076923076923077, "no_speech_prob": 1.7704263655105024e-07}, {"id": 1010, "seek": 475754, "start": 4767.3, "end": 4770.86, "text": " Right?", "tokens": [50852, 1779, 30, 51030], "temperature": 0.0, "avg_logprob": -0.39794634650735294, "compression_ratio": 1.5076923076923077, "no_speech_prob": 1.7704263655105024e-07}, {"id": 1011, "seek": 475754, "start": 4770.86, "end": 4779.86, "text": " So the output of this is actually going to be a matrix.", "tokens": [51030, 407, 264, 5598, 295, 341, 307, 767, 516, 281, 312, 257, 8141, 13, 51480], "temperature": 0.0, "avg_logprob": -0.39794634650735294, "compression_ratio": 1.5076923076923077, "no_speech_prob": 1.7704263655105024e-07}, {"id": 1012, "seek": 475754, "start": 4779.86, "end": 4783.26, "text": " The distances are actually gonna give us a matrix.", "tokens": [51480, 440, 22182, 366, 767, 799, 976, 505, 257, 8141, 13, 51650], "temperature": 0.0, "avg_logprob": -0.39794634650735294, "compression_ratio": 1.5076923076923077, "no_speech_prob": 1.7704263655105024e-07}, {"id": 1013, "seek": 475754, "start": 4783.26, "end": 4786.42, "text": " Where, I mean, it doesn't matter which way around we do it, we can decide.", "tokens": [51650, 2305, 11, 286, 914, 11, 309, 1177, 380, 1871, 597, 636, 926, 321, 360, 309, 11, 321, 393, 4536, 13, 51808], "temperature": 0.0, "avg_logprob": -0.39794634650735294, "compression_ratio": 1.5076923076923077, "no_speech_prob": 1.7704263655105024e-07}, {"id": 1014, "seek": 478642, "start": 4787.42, "end": 4792.54, "text": " If we do it this way around, for each of the five things in the mini-batch,", "tokens": [50414, 759, 321, 360, 309, 341, 636, 926, 11, 337, 1184, 295, 264, 1732, 721, 294, 264, 8382, 12, 65, 852, 11, 50670], "temperature": 0.0, "avg_logprob": -0.41033655054428997, "compression_ratio": 1.4970059880239521, "no_speech_prob": 7.811483442310418e-07}, {"id": 1015, "seek": 478642, "start": 4792.54, "end": 4796.9800000000005, "text": " there will be 1500 distances, the distance between every one.", "tokens": [50670, 456, 486, 312, 22671, 22182, 11, 264, 4560, 1296, 633, 472, 13, 50892], "temperature": 0.0, "avg_logprob": -0.41033655054428997, "compression_ratio": 1.4970059880239521, "no_speech_prob": 7.811483442310418e-07}, {"id": 1016, "seek": 478642, "start": 4796.9800000000005, "end": 4802.26, "text": " So we're gonna need to do broadcasting to do this calculation.", "tokens": [50892, 407, 321, 434, 799, 643, 281, 360, 30024, 281, 360, 341, 17108, 13, 51156], "temperature": 0.0, "avg_logprob": -0.41033655054428997, "compression_ratio": 1.4970059880239521, "no_speech_prob": 7.811483442310418e-07}, {"id": 1017, "seek": 478642, "start": 4802.26, "end": 4812.14, "text": " So, This is the function that we're gonna create.", "tokens": [51156, 407, 11, 639, 307, 264, 2445, 300, 321, 434, 799, 1884, 13, 51650], "temperature": 0.0, "avg_logprob": -0.41033655054428997, "compression_ratio": 1.4970059880239521, "no_speech_prob": 7.811483442310418e-07}, {"id": 1018, "seek": 481214, "start": 4812.14, "end": 4817.14, "text": " And it's gonna create this, as you can see, 5 by 1500 output.", "tokens": [50364, 400, 309, 311, 799, 1884, 341, 11, 382, 291, 393, 536, 11, 1025, 538, 22671, 5598, 13, 50614], "temperature": 0.0, "avg_logprob": -0.33289018430207906, "compression_ratio": 1.3245033112582782, "no_speech_prob": 3.138146894343663e-06}, {"id": 1019, "seek": 481214, "start": 4817.14, "end": 4819.3, "text": " But let's see how we get it.", "tokens": [50614, 583, 718, 311, 536, 577, 321, 483, 309, 13, 50722], "temperature": 0.0, "avg_logprob": -0.33289018430207906, "compression_ratio": 1.3245033112582782, "no_speech_prob": 3.138146894343663e-06}, {"id": 1020, "seek": 481214, "start": 4820.660000000001, "end": 4824.5, "text": " So can we do x minus x?", "tokens": [50790, 407, 393, 321, 360, 2031, 3175, 2031, 30, 50982], "temperature": 0.0, "avg_logprob": -0.33289018430207906, "compression_ratio": 1.3245033112582782, "no_speech_prob": 3.138146894343663e-06}, {"id": 1021, "seek": 481214, "start": 4825.9400000000005, "end": 4827.1, "text": " No, we can't.", "tokens": [51054, 883, 11, 321, 393, 380, 13, 51112], "temperature": 0.0, "avg_logprob": -0.33289018430207906, "compression_ratio": 1.3245033112582782, "no_speech_prob": 3.138146894343663e-06}, {"id": 1022, "seek": 481214, "start": 4827.1, "end": 4827.9400000000005, "text": " Why is that?", "tokens": [51112, 1545, 307, 300, 30, 51154], "temperature": 0.0, "avg_logprob": -0.33289018430207906, "compression_ratio": 1.3245033112582782, "no_speech_prob": 3.138146894343663e-06}, {"id": 1023, "seek": 481214, "start": 4829.3, "end": 4836.9400000000005, "text": " That's because big X is 1500 by 2, and little x is 5 by 2.", "tokens": [51222, 663, 311, 570, 955, 1783, 307, 22671, 538, 568, 11, 293, 707, 2031, 307, 1025, 538, 568, 13, 51604], "temperature": 0.0, "avg_logprob": -0.33289018430207906, "compression_ratio": 1.3245033112582782, "no_speech_prob": 3.138146894343663e-06}, {"id": 1024, "seek": 483694, "start": 4836.94, "end": 4842.7, "text": " So it's going to look at, remember our rules, right to left.", "tokens": [50364, 407, 309, 311, 516, 281, 574, 412, 11, 1604, 527, 4474, 11, 558, 281, 1411, 13, 50652], "temperature": 0.0, "avg_logprob": -0.4075518830181801, "compression_ratio": 1.4965517241379311, "no_speech_prob": 2.368798732277355e-06}, {"id": 1025, "seek": 483694, "start": 4842.7, "end": 4843.86, "text": " Are these compatible?", "tokens": [50652, 2014, 613, 18218, 30, 50710], "temperature": 0.0, "avg_logprob": -0.4075518830181801, "compression_ratio": 1.4965517241379311, "no_speech_prob": 2.368798732277355e-06}, {"id": 1026, "seek": 483694, "start": 4846.58, "end": 4847.66, "text": " Yes, they are.", "tokens": [50846, 1079, 11, 436, 366, 13, 50900], "temperature": 0.0, "avg_logprob": -0.4075518830181801, "compression_ratio": 1.4965517241379311, "no_speech_prob": 2.368798732277355e-06}, {"id": 1027, "seek": 483694, "start": 4847.66, "end": 4848.219999999999, "text": " They're the same.", "tokens": [50900, 814, 434, 264, 912, 13, 50928], "temperature": 0.0, "avg_logprob": -0.4075518830181801, "compression_ratio": 1.4965517241379311, "no_speech_prob": 2.368798732277355e-06}, {"id": 1028, "seek": 483694, "start": 4849.58, "end": 4850.78, "text": " Are these compatible?", "tokens": [50996, 2014, 613, 18218, 30, 51056], "temperature": 0.0, "avg_logprob": -0.4075518830181801, "compression_ratio": 1.4965517241379311, "no_speech_prob": 2.368798732277355e-06}, {"id": 1029, "seek": 483694, "start": 4854.219999999999, "end": 4854.86, "text": " No, they're not.", "tokens": [51228, 883, 11, 436, 434, 406, 13, 51260], "temperature": 0.0, "avg_logprob": -0.4075518830181801, "compression_ratio": 1.4965517241379311, "no_speech_prob": 2.368798732277355e-06}, {"id": 1030, "seek": 483694, "start": 4856.58, "end": 4858.58, "text": " Okay, because they're different.", "tokens": [51346, 1033, 11, 570, 436, 434, 819, 13, 51446], "temperature": 0.0, "avg_logprob": -0.4075518830181801, "compression_ratio": 1.4965517241379311, "no_speech_prob": 2.368798732277355e-06}, {"id": 1031, "seek": 483694, "start": 4858.58, "end": 4860.259999999999, "text": " So that's not possible to do.", "tokens": [51446, 407, 300, 311, 406, 1944, 281, 360, 13, 51530], "temperature": 0.0, "avg_logprob": -0.4075518830181801, "compression_ratio": 1.4965517241379311, "no_speech_prob": 2.368798732277355e-06}, {"id": 1032, "seek": 486026, "start": 4860.26, "end": 4865.780000000001, "text": " What if, though, we wanted to,", "tokens": [50364, 708, 498, 11, 1673, 11, 321, 1415, 281, 11, 50640], "temperature": 0.0, "avg_logprob": -0.5316107714617694, "compression_ratio": 1.3548387096774193, "no_speech_prob": 5.014733687858097e-06}, {"id": 1033, "seek": 486026, "start": 4870.9800000000005, "end": 4875.06, "text": " What if we insert in big X an axis at the start here?", "tokens": [50900, 708, 498, 321, 8969, 294, 955, 1783, 364, 10298, 412, 264, 722, 510, 30, 51104], "temperature": 0.0, "avg_logprob": -0.5316107714617694, "compression_ratio": 1.3548387096774193, "no_speech_prob": 5.014733687858097e-06}, {"id": 1034, "seek": 486026, "start": 4876.5, "end": 4881.18, "text": " And in little x, we add an axis in the middle here.", "tokens": [51176, 400, 294, 707, 2031, 11, 321, 909, 364, 10298, 294, 264, 2808, 510, 13, 51410], "temperature": 0.0, "avg_logprob": -0.5316107714617694, "compression_ratio": 1.3548387096774193, "no_speech_prob": 5.014733687858097e-06}, {"id": 1035, "seek": 486026, "start": 4883.02, "end": 4885.14, "text": " Then now, these are compatible.", "tokens": [51502, 1396, 586, 11, 613, 366, 18218, 13, 51608], "temperature": 0.0, "avg_logprob": -0.5316107714617694, "compression_ratio": 1.3548387096774193, "no_speech_prob": 5.014733687858097e-06}, {"id": 1036, "seek": 488514, "start": 4885.14, "end": 4890.3, "text": " Because you've got, they're the same.", "tokens": [50364, 1436, 291, 600, 658, 11, 436, 434, 264, 912, 13, 50622], "temperature": 0.0, "avg_logprob": -0.42400147078873274, "compression_ratio": 1.68, "no_speech_prob": 6.083589596528327e-07}, {"id": 1037, "seek": 488514, "start": 4890.3, "end": 4893.660000000001, "text": " I guess I should use arrows, really.", "tokens": [50622, 286, 2041, 286, 820, 764, 19669, 11, 534, 13, 50790], "temperature": 0.0, "avg_logprob": -0.42400147078873274, "compression_ratio": 1.68, "no_speech_prob": 6.083589596528327e-07}, {"id": 1038, "seek": 488514, "start": 4896.660000000001, "end": 4898.38, "text": " These are compatible, because one of them's a 1.", "tokens": [50940, 1981, 366, 18218, 11, 570, 472, 295, 552, 311, 257, 502, 13, 51026], "temperature": 0.0, "avg_logprob": -0.42400147078873274, "compression_ratio": 1.68, "no_speech_prob": 6.083589596528327e-07}, {"id": 1039, "seek": 488514, "start": 4900.660000000001, "end": 4903.58, "text": " And these are compatible, because one of them's a 1 as well.", "tokens": [51140, 400, 613, 366, 18218, 11, 570, 472, 295, 552, 311, 257, 502, 382, 731, 13, 51286], "temperature": 0.0, "avg_logprob": -0.42400147078873274, "compression_ratio": 1.68, "no_speech_prob": 6.083589596528327e-07}, {"id": 1040, "seek": 488514, "start": 4905.22, "end": 4906.9400000000005, "text": " So they are all compatible.", "tokens": [51368, 407, 436, 366, 439, 18218, 13, 51454], "temperature": 0.0, "avg_logprob": -0.42400147078873274, "compression_ratio": 1.68, "no_speech_prob": 6.083589596528327e-07}, {"id": 1041, "seek": 488514, "start": 4906.9400000000005, "end": 4909.14, "text": " And what it's gonna do is it's going to", "tokens": [51454, 400, 437, 309, 311, 799, 360, 307, 309, 311, 516, 281, 51564], "temperature": 0.0, "avg_logprob": -0.42400147078873274, "compression_ratio": 1.68, "no_speech_prob": 6.083589596528327e-07}, {"id": 1042, "seek": 490914, "start": 4909.860000000001, "end": 4914.18, "text": " Do the subtraction between these directly.", "tokens": [50400, 1144, 264, 16390, 313, 1296, 613, 3838, 13, 50616], "temperature": 0.0, "avg_logprob": -0.39335770659394315, "compression_ratio": 1.6494845360824741, "no_speech_prob": 1.3081765928291134e-06}, {"id": 1043, "seek": 490914, "start": 4915.38, "end": 4918.42, "text": " And it's gonna copy this across all 1500 rows.", "tokens": [50676, 400, 309, 311, 799, 5055, 341, 2108, 439, 22671, 13241, 13, 50828], "temperature": 0.0, "avg_logprob": -0.39335770659394315, "compression_ratio": 1.6494845360824741, "no_speech_prob": 1.3081765928291134e-06}, {"id": 1044, "seek": 490914, "start": 4918.42, "end": 4919.54, "text": " It'll copy it.", "tokens": [50828, 467, 603, 5055, 309, 13, 50884], "temperature": 0.0, "avg_logprob": -0.39335770659394315, "compression_ratio": 1.6494845360824741, "no_speech_prob": 1.3081765928291134e-06}, {"id": 1045, "seek": 490914, "start": 4919.54, "end": 4921.22, "text": " This is gonna be copied.", "tokens": [50884, 639, 307, 799, 312, 25365, 13, 50968], "temperature": 0.0, "avg_logprob": -0.39335770659394315, "compression_ratio": 1.6494845360824741, "no_speech_prob": 1.3081765928291134e-06}, {"id": 1046, "seek": 490914, "start": 4921.22, "end": 4924.820000000001, "text": " And then this, sorry, across five rows.", "tokens": [50968, 400, 550, 341, 11, 2597, 11, 2108, 1732, 13241, 13, 51148], "temperature": 0.0, "avg_logprob": -0.39335770659394315, "compression_ratio": 1.6494845360824741, "no_speech_prob": 1.3081765928291134e-06}, {"id": 1047, "seek": 490914, "start": 4924.820000000001, "end": 4927.820000000001, "text": " And then this will be copied across these 1500 rows.", "tokens": [51148, 400, 550, 341, 486, 312, 25365, 2108, 613, 22671, 13241, 13, 51298], "temperature": 0.0, "avg_logprob": -0.39335770659394315, "compression_ratio": 1.6494845360824741, "no_speech_prob": 1.3081765928291134e-06}, {"id": 1048, "seek": 490914, "start": 4928.820000000001, "end": 4930.46, "text": " Cuz that's what broadcasting does.", "tokens": [51348, 27017, 300, 311, 437, 30024, 775, 13, 51430], "temperature": 0.0, "avg_logprob": -0.39335770659394315, "compression_ratio": 1.6494845360824741, "no_speech_prob": 1.3081765928291134e-06}, {"id": 1049, "seek": 490914, "start": 4930.46, "end": 4932.740000000001, "text": " I mean, it's not really copying, but it's effectively copying.", "tokens": [51430, 286, 914, 11, 309, 311, 406, 534, 27976, 11, 457, 309, 311, 8659, 27976, 13, 51544], "temperature": 0.0, "avg_logprob": -0.39335770659394315, "compression_ratio": 1.6494845360824741, "no_speech_prob": 1.3081765928291134e-06}, {"id": 1050, "seek": 493274, "start": 4932.74, "end": 4937.94, "text": " And so that gives us, we can now subtract them,", "tokens": [50364, 400, 370, 300, 2709, 505, 11, 321, 393, 586, 16390, 552, 11, 50624], "temperature": 0.0, "avg_logprob": -0.3574355213912492, "compression_ratio": 1.6205128205128205, "no_speech_prob": 2.1691717222438456e-07}, {"id": 1051, "seek": 493274, "start": 4937.94, "end": 4944.46, "text": " and that gives us what we wanted, which is 5 by 1500.", "tokens": [50624, 293, 300, 2709, 505, 437, 321, 1415, 11, 597, 307, 1025, 538, 22671, 13, 50950], "temperature": 0.0, "avg_logprob": -0.3574355213912492, "compression_ratio": 1.6205128205128205, "no_speech_prob": 2.1691717222438456e-07}, {"id": 1052, "seek": 493274, "start": 4944.46, "end": 4947.62, "text": " And there's also by 2, because there's both the x and the y.", "tokens": [50950, 400, 456, 311, 611, 538, 568, 11, 570, 456, 311, 1293, 264, 2031, 293, 264, 288, 13, 51108], "temperature": 0.0, "avg_logprob": -0.3574355213912492, "compression_ratio": 1.6205128205128205, "no_speech_prob": 2.1691717222438456e-07}, {"id": 1053, "seek": 493274, "start": 4948.9, "end": 4951.7, "text": " So that's why this works.", "tokens": [51172, 407, 300, 311, 983, 341, 1985, 13, 51312], "temperature": 0.0, "avg_logprob": -0.3574355213912492, "compression_ratio": 1.6205128205128205, "no_speech_prob": 2.1691717222438456e-07}, {"id": 1054, "seek": 493274, "start": 4951.7, "end": 4953.26, "text": " That's what this is doing here.", "tokens": [51312, 663, 311, 437, 341, 307, 884, 510, 13, 51390], "temperature": 0.0, "avg_logprob": -0.3574355213912492, "compression_ratio": 1.6205128205128205, "no_speech_prob": 2.1691717222438456e-07}, {"id": 1055, "seek": 493274, "start": 4953.26, "end": 4955.86, "text": " It's taking the subtraction, it's squaring them, and", "tokens": [51390, 467, 311, 1940, 264, 16390, 313, 11, 309, 311, 2339, 1921, 552, 11, 293, 51520], "temperature": 0.0, "avg_logprob": -0.3574355213912492, "compression_ratio": 1.6205128205128205, "no_speech_prob": 2.1691717222438456e-07}, {"id": 1056, "seek": 493274, "start": 4955.86, "end": 4960.66, "text": " then summing over that last shortest axis.", "tokens": [51520, 550, 2408, 2810, 670, 300, 1036, 31875, 10298, 13, 51760], "temperature": 0.0, "avg_logprob": -0.3574355213912492, "compression_ratio": 1.6205128205128205, "no_speech_prob": 2.1691717222438456e-07}, {"id": 1057, "seek": 496066, "start": 4960.66, "end": 4963.62, "text": " Summing over the x and the y squareds.", "tokens": [50364, 8626, 2810, 670, 264, 2031, 293, 264, 288, 8889, 82, 13, 50512], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1058, "seek": 496066, "start": 4963.62, "end": 4964.74, "text": " And then take square root.", "tokens": [50512, 400, 550, 747, 3732, 5593, 13, 50568], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1059, "seek": 496066, "start": 4964.74, "end": 4966.26, "text": " I don't know why I said torch.square root.", "tokens": [50568, 286, 500, 380, 458, 983, 286, 848, 27822, 13, 33292, 543, 5593, 13, 50644], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1060, "seek": 496066, "start": 4966.26, "end": 4968.34, "text": " We could have just put dot square root at the end.", "tokens": [50644, 492, 727, 362, 445, 829, 5893, 3732, 5593, 412, 264, 917, 13, 50748], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1061, "seek": 496066, "start": 4968.34, "end": 4969.74, "text": " But same, same.", "tokens": [50748, 583, 912, 11, 912, 13, 50818], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1062, "seek": 496066, "start": 4969.74, "end": 4971.3, "text": " In fact, it's worth mentioning that.", "tokens": [50818, 682, 1186, 11, 309, 311, 3163, 18315, 300, 13, 50896], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1063, "seek": 496066, "start": 4971.3, "end": 4974.22, "text": " So most things that you can do on tensors,", "tokens": [50896, 407, 881, 721, 300, 291, 393, 360, 322, 10688, 830, 11, 51042], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1064, "seek": 496066, "start": 4974.22, "end": 4980.46, "text": " you can either write torch.as a function, or you can write it as a method.", "tokens": [51042, 291, 393, 2139, 2464, 27822, 13, 296, 257, 2445, 11, 420, 291, 393, 2464, 309, 382, 257, 3170, 13, 51354], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1065, "seek": 496066, "start": 4982.5, "end": 4983.9, "text": " Generally speaking, both should be fine.", "tokens": [51456, 21082, 4124, 11, 1293, 820, 312, 2489, 13, 51526], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1066, "seek": 496066, "start": 4985.98, "end": 4989.58, "text": " Not everything, but most things work in both spots.", "tokens": [51630, 1726, 1203, 11, 457, 881, 721, 589, 294, 1293, 10681, 13, 51810], "temperature": 0.0, "avg_logprob": -0.28541153434693345, "compression_ratio": 1.6852589641434264, "no_speech_prob": 8.530319064448122e-06}, {"id": 1067, "seek": 498958, "start": 4989.58, "end": 4995.3, "text": " Okay, so now we've got this matrix, which is 5 by 1500.", "tokens": [50364, 1033, 11, 370, 586, 321, 600, 658, 341, 8141, 11, 597, 307, 1025, 538, 22671, 13, 50650], "temperature": 0.0, "avg_logprob": -0.2913458188374837, "compression_ratio": 1.7023809523809523, "no_speech_prob": 4.888302100880537e-07}, {"id": 1068, "seek": 498958, "start": 4996.82, "end": 4999.9, "text": " And the nice thing is that our Gaussian kernel doesn't actually have to be", "tokens": [50726, 400, 264, 1481, 551, 307, 300, 527, 39148, 28256, 1177, 380, 767, 362, 281, 312, 50880], "temperature": 0.0, "avg_logprob": -0.2913458188374837, "compression_ratio": 1.7023809523809523, "no_speech_prob": 4.888302100880537e-07}, {"id": 1069, "seek": 498958, "start": 4999.9, "end": 5003.5, "text": " changed to get the weights, believe it or not.", "tokens": [50880, 3105, 281, 483, 264, 17443, 11, 1697, 309, 420, 406, 13, 51060], "temperature": 0.0, "avg_logprob": -0.2913458188374837, "compression_ratio": 1.7023809523809523, "no_speech_prob": 4.888302100880537e-07}, {"id": 1070, "seek": 498958, "start": 5003.5, "end": 5006.5, "text": " And the reason for that is, now how do we get the source code?", "tokens": [51060, 400, 264, 1778, 337, 300, 307, 11, 586, 577, 360, 321, 483, 264, 4009, 3089, 30, 51210], "temperature": 0.0, "avg_logprob": -0.2913458188374837, "compression_ratio": 1.7023809523809523, "no_speech_prob": 4.888302100880537e-07}, {"id": 1071, "seek": 498958, "start": 5006.5, "end": 5008.1, "text": " I could move back up there, or", "tokens": [51210, 286, 727, 1286, 646, 493, 456, 11, 420, 51290], "temperature": 0.0, "avg_logprob": -0.2913458188374837, "compression_ratio": 1.7023809523809523, "no_speech_prob": 4.888302100880537e-07}, {"id": 1072, "seek": 498958, "start": 5008.1, "end": 5011.5, "text": " I can just type Gaussian question mark, question mark, and see it.", "tokens": [51290, 286, 393, 445, 2010, 39148, 1168, 1491, 11, 1168, 1491, 11, 293, 536, 309, 13, 51460], "temperature": 0.0, "avg_logprob": -0.2913458188374837, "compression_ratio": 1.7023809523809523, "no_speech_prob": 4.888302100880537e-07}, {"id": 1073, "seek": 498958, "start": 5012.7, "end": 5016.98, "text": " And the nice thing is that this is just, this is a scalar, so", "tokens": [51520, 400, 264, 1481, 551, 307, 300, 341, 307, 445, 11, 341, 307, 257, 39684, 11, 370, 51734], "temperature": 0.0, "avg_logprob": -0.2913458188374837, "compression_ratio": 1.7023809523809523, "no_speech_prob": 4.888302100880537e-07}, {"id": 1074, "seek": 498958, "start": 5016.98, "end": 5018.46, "text": " it broadcasts over anything.", "tokens": [51734, 309, 9975, 82, 670, 1340, 13, 51808], "temperature": 0.0, "avg_logprob": -0.2913458188374837, "compression_ratio": 1.7023809523809523, "no_speech_prob": 4.888302100880537e-07}, {"id": 1075, "seek": 501958, "start": 5019.98, "end": 5022.7, "text": " And then this is also just a scalar.", "tokens": [50384, 400, 550, 341, 307, 611, 445, 257, 39684, 13, 50520], "temperature": 0.0, "avg_logprob": -0.3719155270120372, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.6688625186798163e-06}, {"id": 1076, "seek": 501958, "start": 5023.7, "end": 5026.7, "text": " So this is all gonna work fine without any fiddling around.", "tokens": [50570, 407, 341, 307, 439, 799, 589, 2489, 1553, 604, 283, 14273, 1688, 926, 13, 50720], "temperature": 0.0, "avg_logprob": -0.3719155270120372, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.6688625186798163e-06}, {"id": 1077, "seek": 501958, "start": 5030.7, "end": 5037.58, "text": " Okay, so now we've got a 5 by 1500 weight.", "tokens": [50920, 1033, 11, 370, 586, 321, 600, 658, 257, 1025, 538, 22671, 3364, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3719155270120372, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.6688625186798163e-06}, {"id": 1078, "seek": 501958, "start": 5037.58, "end": 5040.22, "text": " So that's the weight for each of the five things in our mini-batch,", "tokens": [51264, 407, 300, 311, 264, 3364, 337, 1184, 295, 264, 1732, 721, 294, 527, 8382, 12, 65, 852, 11, 51396], "temperature": 0.0, "avg_logprob": -0.3719155270120372, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.6688625186798163e-06}, {"id": 1079, "seek": 501958, "start": 5040.22, "end": 5043.62, "text": " which are the 1500 things each of them is compared to.", "tokens": [51396, 597, 366, 264, 22671, 721, 1184, 295, 552, 307, 5347, 281, 13, 51566], "temperature": 0.0, "avg_logprob": -0.3719155270120372, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.6688625186798163e-06}, {"id": 1080, "seek": 501958, "start": 5043.62, "end": 5047.66, "text": " And then we've got the shape of the data itself,", "tokens": [51566, 400, 550, 321, 600, 658, 264, 3909, 295, 264, 1412, 2564, 11, 51768], "temperature": 0.0, "avg_logprob": -0.3719155270120372, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.6688625186798163e-06}, {"id": 1081, "seek": 504766, "start": 5047.66, "end": 5050.98, "text": " x.shape, which is the 1500 points.", "tokens": [50364, 2031, 13, 82, 42406, 11, 597, 307, 264, 22671, 2793, 13, 50530], "temperature": 0.0, "avg_logprob": -0.29788600172951957, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.4064044080441818e-05}, {"id": 1082, "seek": 504766, "start": 5050.98, "end": 5057.78, "text": " So now we want to apply each one of these weights to each of these columns.", "tokens": [50530, 407, 586, 321, 528, 281, 3079, 1184, 472, 295, 613, 17443, 281, 1184, 295, 613, 13766, 13, 50870], "temperature": 0.0, "avg_logprob": -0.29788600172951957, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.4064044080441818e-05}, {"id": 1083, "seek": 504766, "start": 5059.82, "end": 5063.78, "text": " So we need to add a unit axis to the end.", "tokens": [50972, 407, 321, 643, 281, 909, 257, 4985, 10298, 281, 264, 917, 13, 51170], "temperature": 0.0, "avg_logprob": -0.29788600172951957, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.4064044080441818e-05}, {"id": 1084, "seek": 504766, "start": 5063.78, "end": 5068.099999999999, "text": " So to add a unit axis to the end, we could say colon, comma, colon,", "tokens": [51170, 407, 281, 909, 257, 4985, 10298, 281, 264, 917, 11, 321, 727, 584, 8255, 11, 22117, 11, 8255, 11, 51386], "temperature": 0.0, "avg_logprob": -0.29788600172951957, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.4064044080441818e-05}, {"id": 1085, "seek": 504766, "start": 5068.099999999999, "end": 5072.38, "text": " comma, none, but dot, dot, dot means all of the axes up until", "tokens": [51386, 22117, 11, 6022, 11, 457, 5893, 11, 5893, 11, 5893, 1355, 439, 295, 264, 35387, 493, 1826, 51600], "temperature": 0.0, "avg_logprob": -0.29788600172951957, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.4064044080441818e-05}, {"id": 1086, "seek": 504766, "start": 5073.46, "end": 5076.7, "text": " however many you need, so in this case the last one, comma, none.", "tokens": [51654, 4461, 867, 291, 643, 11, 370, 294, 341, 1389, 264, 1036, 472, 11, 22117, 11, 6022, 13, 51816], "temperature": 0.0, "avg_logprob": -0.29788600172951957, "compression_ratio": 1.7755102040816326, "no_speech_prob": 1.4064044080441818e-05}, {"id": 1087, "seek": 507670, "start": 5076.7, "end": 5078.46, "text": " So this is gonna add an axis to the end.", "tokens": [50364, 407, 341, 307, 799, 909, 364, 10298, 281, 264, 917, 13, 50452], "temperature": 0.0, "avg_logprob": -0.3745050725248671, "compression_ratio": 1.6685082872928176, "no_speech_prob": 1.2878950883532525e-06}, {"id": 1088, "seek": 507670, "start": 5080.54, "end": 5087.78, "text": " So this is gonna turn weight.shape from 5, 1500 to 5, 1500, 1.", "tokens": [50556, 407, 341, 307, 799, 1261, 3364, 13, 82, 42406, 490, 1025, 11, 22671, 281, 1025, 11, 22671, 11, 502, 13, 50918], "temperature": 0.0, "avg_logprob": -0.3745050725248671, "compression_ratio": 1.6685082872928176, "no_speech_prob": 1.2878950883532525e-06}, {"id": 1089, "seek": 507670, "start": 5089.78, "end": 5091.94, "text": " And this is gonna add an axis to the start.", "tokens": [51018, 400, 341, 307, 799, 909, 364, 10298, 281, 264, 722, 13, 51126], "temperature": 0.0, "avg_logprob": -0.3745050725248671, "compression_ratio": 1.6685082872928176, "no_speech_prob": 1.2878950883532525e-06}, {"id": 1090, "seek": 507670, "start": 5091.94, "end": 5095.26, "text": " Remember it's the same as x, none, colon, colon, colon.", "tokens": [51126, 5459, 309, 311, 264, 912, 382, 2031, 11, 6022, 11, 8255, 11, 8255, 11, 8255, 13, 51292], "temperature": 0.0, "avg_logprob": -0.3745050725248671, "compression_ratio": 1.6685082872928176, "no_speech_prob": 1.2878950883532525e-06}, {"id": 1091, "seek": 507670, "start": 5096.9, "end": 5098.42, "text": " And so let's check our rules.", "tokens": [51374, 400, 370, 718, 311, 1520, 527, 4474, 13, 51450], "temperature": 0.0, "avg_logprob": -0.3745050725248671, "compression_ratio": 1.6685082872928176, "no_speech_prob": 1.2878950883532525e-06}, {"id": 1092, "seek": 507670, "start": 5100.58, "end": 5102.22, "text": " Left, right to left.", "tokens": [51558, 16405, 11, 558, 281, 1411, 13, 51640], "temperature": 0.0, "avg_logprob": -0.3745050725248671, "compression_ratio": 1.6685082872928176, "no_speech_prob": 1.2878950883532525e-06}, {"id": 1093, "seek": 507670, "start": 5102.22, "end": 5105.26, "text": " These are compatible because one of them's one.", "tokens": [51640, 1981, 366, 18218, 570, 472, 295, 552, 311, 472, 13, 51792], "temperature": 0.0, "avg_logprob": -0.3745050725248671, "compression_ratio": 1.6685082872928176, "no_speech_prob": 1.2878950883532525e-06}, {"id": 1094, "seek": 510670, "start": 5106.78, "end": 5110.54, "text": " These are compatible because they're both the same.", "tokens": [50368, 1981, 366, 18218, 570, 436, 434, 1293, 264, 912, 13, 50556], "temperature": 0.0, "avg_logprob": -0.32481898331060644, "compression_ratio": 1.7052023121387283, "no_speech_prob": 1.2952716588188196e-07}, {"id": 1095, "seek": 510670, "start": 5110.54, "end": 5112.7, "text": " And these are compatible because one of them's one.", "tokens": [50556, 400, 613, 366, 18218, 570, 472, 295, 552, 311, 472, 13, 50664], "temperature": 0.0, "avg_logprob": -0.32481898331060644, "compression_ratio": 1.7052023121387283, "no_speech_prob": 1.2952716588188196e-07}, {"id": 1096, "seek": 510670, "start": 5113.82, "end": 5115.98, "text": " Okay, so it's going to be", "tokens": [50720, 1033, 11, 370, 309, 311, 516, 281, 312, 50828], "temperature": 0.0, "avg_logprob": -0.32481898331060644, "compression_ratio": 1.7052023121387283, "no_speech_prob": 1.2952716588188196e-07}, {"id": 1097, "seek": 510670, "start": 5118.86, "end": 5124.74, "text": " copying each weight across to each of the x and y, which is what we want.", "tokens": [50972, 27976, 1184, 3364, 2108, 281, 1184, 295, 264, 2031, 293, 288, 11, 597, 307, 437, 321, 528, 13, 51266], "temperature": 0.0, "avg_logprob": -0.32481898331060644, "compression_ratio": 1.7052023121387283, "no_speech_prob": 1.2952716588188196e-07}, {"id": 1098, "seek": 510670, "start": 5124.74, "end": 5129.099999999999, "text": " We want to weight both of those components.", "tokens": [51266, 492, 528, 281, 3364, 1293, 295, 729, 6677, 13, 51484], "temperature": 0.0, "avg_logprob": -0.32481898331060644, "compression_ratio": 1.7052023121387283, "no_speech_prob": 1.2952716588188196e-07}, {"id": 1099, "seek": 510670, "start": 5129.099999999999, "end": 5133.98, "text": " And it's going to copy each of the 1500 points,", "tokens": [51484, 400, 309, 311, 516, 281, 5055, 1184, 295, 264, 22671, 2793, 11, 51728], "temperature": 0.0, "avg_logprob": -0.32481898331060644, "compression_ratio": 1.7052023121387283, "no_speech_prob": 1.2952716588188196e-07}, {"id": 1100, "seek": 513398, "start": 5134.0599999999995, "end": 5139.7, "text": " sorry, each of the point five times, because we do in fact want to weight", "tokens": [50368, 2597, 11, 1184, 295, 264, 935, 1732, 1413, 11, 570, 321, 360, 294, 1186, 528, 281, 3364, 50650], "temperature": 0.0, "avg_logprob": -0.350127256369289, "compression_ratio": 1.5380434782608696, "no_speech_prob": 6.375545353876078e-07}, {"id": 1101, "seek": 513398, "start": 5139.7, "end": 5141.54, "text": " every one of the five things in our mini-batch,", "tokens": [50650, 633, 472, 295, 264, 1732, 721, 294, 527, 8382, 12, 65, 852, 11, 50742], "temperature": 0.0, "avg_logprob": -0.350127256369289, "compression_ratio": 1.5380434782608696, "no_speech_prob": 6.375545353876078e-07}, {"id": 1102, "seek": 513398, "start": 5141.54, "end": 5143.419999999999, "text": " a separate set of weights for each of them.", "tokens": [50742, 257, 4994, 992, 295, 17443, 337, 1184, 295, 552, 13, 50836], "temperature": 0.0, "avg_logprob": -0.350127256369289, "compression_ratio": 1.5380434782608696, "no_speech_prob": 6.375545353876078e-07}, {"id": 1103, "seek": 513398, "start": 5143.419999999999, "end": 5144.459999999999, "text": " So that sounds perfect.", "tokens": [50836, 407, 300, 3263, 2176, 13, 50888], "temperature": 0.0, "avg_logprob": -0.350127256369289, "compression_ratio": 1.5380434782608696, "no_speech_prob": 6.375545353876078e-07}, {"id": 1104, "seek": 513398, "start": 5146.219999999999, "end": 5149.0199999999995, "text": " So that's how I think through these calculations.", "tokens": [50976, 407, 300, 311, 577, 286, 519, 807, 613, 20448, 13, 51116], "temperature": 0.0, "avg_logprob": -0.350127256369289, "compression_ratio": 1.5380434782608696, "no_speech_prob": 6.375545353876078e-07}, {"id": 1105, "seek": 513398, "start": 5154.66, "end": 5159.0599999999995, "text": " Okay, so we can now do that multiplication,", "tokens": [51398, 1033, 11, 370, 321, 393, 586, 360, 300, 27290, 11, 51618], "temperature": 0.0, "avg_logprob": -0.350127256369289, "compression_ratio": 1.5380434782608696, "no_speech_prob": 6.375545353876078e-07}, {"id": 1106, "seek": 515906, "start": 5159.9800000000005, "end": 5164.14, "text": " which is gonna give us something of 5 by 1500 by 2,", "tokens": [50410, 597, 307, 799, 976, 505, 746, 295, 1025, 538, 22671, 538, 568, 11, 50618], "temperature": 0.0, "avg_logprob": -0.4844695027669271, "compression_ratio": 1.5, "no_speech_prob": 1.7061800008377759e-06}, {"id": 1107, "seek": 515906, "start": 5164.14, "end": 5166.820000000001, "text": " cuz we end up with the maximum of our ranks.", "tokens": [50618, 11910, 321, 917, 493, 365, 264, 6674, 295, 527, 21406, 13, 50752], "temperature": 0.0, "avg_logprob": -0.4844695027669271, "compression_ratio": 1.5, "no_speech_prob": 1.7061800008377759e-06}, {"id": 1108, "seek": 515906, "start": 5168.06, "end": 5172.1, "text": " And then we sum up over those 1500 points, and", "tokens": [50814, 400, 550, 321, 2408, 493, 670, 729, 22671, 2793, 11, 293, 51016], "temperature": 0.0, "avg_logprob": -0.4844695027669271, "compression_ratio": 1.5, "no_speech_prob": 1.7061800008377759e-06}, {"id": 1109, "seek": 515906, "start": 5172.1, "end": 5176.26, "text": " that's going to give us our five new data points.", "tokens": [51016, 300, 311, 516, 281, 976, 505, 527, 1732, 777, 1412, 2793, 13, 51224], "temperature": 0.0, "avg_logprob": -0.4844695027669271, "compression_ratio": 1.5, "no_speech_prob": 1.7061800008377759e-06}, {"id": 1110, "seek": 515906, "start": 5182.740000000001, "end": 5188.5, "text": " Now, something that you might notice here is that we've got a product,", "tokens": [51548, 823, 11, 746, 300, 291, 1062, 3449, 510, 307, 300, 321, 600, 658, 257, 1674, 11, 51836], "temperature": 0.0, "avg_logprob": -0.4844695027669271, "compression_ratio": 1.5, "no_speech_prob": 1.7061800008377759e-06}, {"id": 1111, "seek": 518850, "start": 5188.7, "end": 5189.82, "text": " and a sum.", "tokens": [50374, 293, 257, 2408, 13, 50430], "temperature": 0.0, "avg_logprob": -0.44295279184977215, "compression_ratio": 1.5177304964539007, "no_speech_prob": 3.576358835744031e-07}, {"id": 1112, "seek": 518850, "start": 5189.82, "end": 5194.5, "text": " And when you see a product and a sum,", "tokens": [50430, 400, 562, 291, 536, 257, 1674, 293, 257, 2408, 11, 50664], "temperature": 0.0, "avg_logprob": -0.44295279184977215, "compression_ratio": 1.5177304964539007, "no_speech_prob": 3.576358835744031e-07}, {"id": 1113, "seek": 518850, "start": 5194.5, "end": 5200.3, "text": " that tells you that maybe we should use i and sum.", "tokens": [50664, 300, 5112, 291, 300, 1310, 321, 820, 764, 741, 293, 2408, 13, 50954], "temperature": 0.0, "avg_logprob": -0.44295279184977215, "compression_ratio": 1.5177304964539007, "no_speech_prob": 3.576358835744031e-07}, {"id": 1114, "seek": 518850, "start": 5203.46, "end": 5211.54, "text": " So in this case, we've got our weight, we've got 5 by 1500.", "tokens": [51112, 407, 294, 341, 1389, 11, 321, 600, 658, 527, 3364, 11, 321, 600, 658, 1025, 538, 22671, 13, 51516], "temperature": 0.0, "avg_logprob": -0.44295279184977215, "compression_ratio": 1.5177304964539007, "no_speech_prob": 3.576358835744031e-07}, {"id": 1115, "seek": 518850, "start": 5211.54, "end": 5215.94, "text": " So let's call those i and j, those for the 5 and 1500.", "tokens": [51516, 407, 718, 311, 818, 729, 741, 293, 361, 11, 729, 337, 264, 1025, 293, 22671, 13, 51736], "temperature": 0.0, "avg_logprob": -0.44295279184977215, "compression_ratio": 1.5177304964539007, "no_speech_prob": 3.576358835744031e-07}, {"id": 1116, "seek": 521594, "start": 5215.94, "end": 5219.139999999999, "text": " We've got the x is 1500 by 2.", "tokens": [50364, 492, 600, 658, 264, 2031, 307, 22671, 538, 568, 13, 50524], "temperature": 0.0, "avg_logprob": -0.27708757400512696, "compression_ratio": 1.5408163265306123, "no_speech_prob": 4.0294567043019924e-06}, {"id": 1117, "seek": 521594, "start": 5219.139999999999, "end": 5221.82, "text": " Now we want to take the product of that and that, so", "tokens": [50524, 823, 321, 528, 281, 747, 264, 1674, 295, 300, 293, 300, 11, 370, 50658], "temperature": 0.0, "avg_logprob": -0.27708757400512696, "compression_ratio": 1.5408163265306123, "no_speech_prob": 4.0294567043019924e-06}, {"id": 1118, "seek": 521594, "start": 5221.82, "end": 5227.82, "text": " we need to use the same name for this row, so we use j again, okay?", "tokens": [50658, 321, 643, 281, 764, 264, 912, 1315, 337, 341, 5386, 11, 370, 321, 764, 361, 797, 11, 1392, 30, 50958], "temperature": 0.0, "avg_logprob": -0.27708757400512696, "compression_ratio": 1.5408163265306123, "no_speech_prob": 4.0294567043019924e-06}, {"id": 1119, "seek": 521594, "start": 5227.82, "end": 5233.98, "text": " And then k is the number of rows, that's the 2.", "tokens": [50958, 400, 550, 350, 307, 264, 1230, 295, 13241, 11, 300, 311, 264, 568, 13, 51266], "temperature": 0.0, "avg_logprob": -0.27708757400512696, "compression_ratio": 1.5408163265306123, "no_speech_prob": 4.0294567043019924e-06}, {"id": 1120, "seek": 521594, "start": 5233.98, "end": 5236.9, "text": " And then we want to end up with i by k.", "tokens": [51266, 400, 550, 321, 528, 281, 917, 493, 365, 741, 538, 350, 13, 51412], "temperature": 0.0, "avg_logprob": -0.27708757400512696, "compression_ratio": 1.5408163265306123, "no_speech_prob": 4.0294567043019924e-06}, {"id": 1121, "seek": 521594, "start": 5236.9, "end": 5240.9, "text": " So torch.i and sum gives exactly the same result.", "tokens": [51412, 407, 27822, 13, 72, 293, 2408, 2709, 2293, 264, 912, 1874, 13, 51612], "temperature": 0.0, "avg_logprob": -0.27708757400512696, "compression_ratio": 1.5408163265306123, "no_speech_prob": 4.0294567043019924e-06}, {"id": 1122, "seek": 521594, "start": 5240.9, "end": 5242.0599999999995, "text": " That's great.", "tokens": [51612, 663, 311, 869, 13, 51670], "temperature": 0.0, "avg_logprob": -0.27708757400512696, "compression_ratio": 1.5408163265306123, "no_speech_prob": 4.0294567043019924e-06}, {"id": 1123, "seek": 524206, "start": 5242.06, "end": 5246.54, "text": " But you might recognize this, that's exactly the same i and", "tokens": [50364, 583, 291, 1062, 5521, 341, 11, 300, 311, 2293, 264, 912, 741, 293, 50588], "temperature": 0.0, "avg_logprob": -0.32459684165127306, "compression_ratio": 1.642512077294686, "no_speech_prob": 1.3420008144748863e-05}, {"id": 1124, "seek": 524206, "start": 5246.54, "end": 5249.46, "text": " sum we had just before when we were doing matrix multiplication.", "tokens": [50588, 2408, 321, 632, 445, 949, 562, 321, 645, 884, 8141, 27290, 13, 50734], "temperature": 0.0, "avg_logprob": -0.32459684165127306, "compression_ratio": 1.642512077294686, "no_speech_prob": 1.3420008144748863e-05}, {"id": 1125, "seek": 524206, "start": 5250.9400000000005, "end": 5253.1, "text": " That is a matrix multiplication.", "tokens": [50808, 663, 307, 257, 8141, 27290, 13, 50916], "temperature": 0.0, "avg_logprob": -0.32459684165127306, "compression_ratio": 1.642512077294686, "no_speech_prob": 1.3420008144748863e-05}, {"id": 1126, "seek": 524206, "start": 5253.1, "end": 5262.06, "text": " We've just reinvented matrix multiplication using this rather nifty trick.", "tokens": [50916, 492, 600, 445, 33477, 292, 8141, 27290, 1228, 341, 2831, 297, 37177, 4282, 13, 51364], "temperature": 0.0, "avg_logprob": -0.32459684165127306, "compression_ratio": 1.642512077294686, "no_speech_prob": 1.3420008144748863e-05}, {"id": 1127, "seek": 524206, "start": 5262.06, "end": 5264.620000000001, "text": " So we could also just use that.", "tokens": [51364, 407, 321, 727, 611, 445, 764, 300, 13, 51492], "temperature": 0.0, "avg_logprob": -0.32459684165127306, "compression_ratio": 1.642512077294686, "no_speech_prob": 1.3420008144748863e-05}, {"id": 1128, "seek": 524206, "start": 5266.42, "end": 5270.9800000000005, "text": " And so again, this is like what I was just playing around with this morning", "tokens": [51582, 400, 370, 797, 11, 341, 307, 411, 437, 286, 390, 445, 2433, 926, 365, 341, 2446, 51810], "temperature": 0.0, "avg_logprob": -0.32459684165127306, "compression_ratio": 1.642512077294686, "no_speech_prob": 1.3420008144748863e-05}, {"id": 1129, "seek": 527098, "start": 5270.98, "end": 5274.78, "text": " as I started to look at this and I was thinking like, can we simplify this?", "tokens": [50364, 382, 286, 1409, 281, 574, 412, 341, 293, 286, 390, 1953, 411, 11, 393, 321, 20460, 341, 30, 50554], "temperature": 0.0, "avg_logprob": -0.31929969787597656, "compression_ratio": 1.615686274509804, "no_speech_prob": 2.1444941012305208e-05}, {"id": 1130, "seek": 527098, "start": 5274.78, "end": 5278.74, "text": " I don't like this kind of messing around with axes and", "tokens": [50554, 286, 500, 380, 411, 341, 733, 295, 23258, 926, 365, 35387, 293, 50752], "temperature": 0.0, "avg_logprob": -0.31929969787597656, "compression_ratio": 1.615686274509804, "no_speech_prob": 2.1444941012305208e-05}, {"id": 1131, "seek": 527098, "start": 5278.74, "end": 5281.379999999999, "text": " summing over dimensions and whatnot.", "tokens": [50752, 2408, 2810, 670, 12819, 293, 25882, 13, 50884], "temperature": 0.0, "avg_logprob": -0.31929969787597656, "compression_ratio": 1.615686274509804, "no_speech_prob": 2.1444941012305208e-05}, {"id": 1132, "seek": 527098, "start": 5281.379999999999, "end": 5283.339999999999, "text": " And so it's nice to get things down to i and sum or", "tokens": [50884, 400, 370, 309, 311, 1481, 281, 483, 721, 760, 281, 741, 293, 2408, 420, 50982], "temperature": 0.0, "avg_logprob": -0.31929969787597656, "compression_ratio": 1.615686274509804, "no_speech_prob": 2.1444941012305208e-05}, {"id": 1133, "seek": 527098, "start": 5283.339999999999, "end": 5286.419999999999, "text": " better still get them down to matrix multiplies.", "tokens": [50982, 1101, 920, 483, 552, 760, 281, 8141, 12788, 530, 13, 51136], "temperature": 0.0, "avg_logprob": -0.31929969787597656, "compression_ratio": 1.615686274509804, "no_speech_prob": 2.1444941012305208e-05}, {"id": 1134, "seek": 527098, "start": 5286.419999999999, "end": 5290.86, "text": " It's just clearer, it's stuff that we recognize because we use them all the time.", "tokens": [51136, 467, 311, 445, 26131, 11, 309, 311, 1507, 300, 321, 5521, 570, 321, 764, 552, 439, 264, 565, 13, 51358], "temperature": 0.0, "avg_logprob": -0.31929969787597656, "compression_ratio": 1.615686274509804, "no_speech_prob": 2.1444941012305208e-05}, {"id": 1135, "seek": 527098, "start": 5290.86, "end": 5294.219999999999, "text": " They all work, performance would be pretty similar I suspect.", "tokens": [51358, 814, 439, 589, 11, 3389, 576, 312, 1238, 2531, 286, 9091, 13, 51526], "temperature": 0.0, "avg_logprob": -0.31929969787597656, "compression_ratio": 1.615686274509804, "no_speech_prob": 2.1444941012305208e-05}, {"id": 1136, "seek": 529422, "start": 5295.22, "end": 5299.5, "text": " Okay, so now that we've got that,", "tokens": [50414, 1033, 11, 370, 586, 300, 321, 600, 658, 300, 11, 50628], "temperature": 0.0, "avg_logprob": -0.31051001437874726, "compression_ratio": 1.7307692307692308, "no_speech_prob": 2.5071565687539987e-05}, {"id": 1137, "seek": 529422, "start": 5299.5, "end": 5307.820000000001, "text": " we then need to do our sum and we've got our five points.", "tokens": [50628, 321, 550, 643, 281, 360, 527, 2408, 293, 321, 600, 658, 527, 1732, 2793, 13, 51044], "temperature": 0.0, "avg_logprob": -0.31051001437874726, "compression_ratio": 1.7307692307692308, "no_speech_prob": 2.5071565687539987e-05}, {"id": 1138, "seek": 529422, "start": 5307.820000000001, "end": 5311.06, "text": " This is our five denominators.", "tokens": [51044, 639, 307, 527, 1732, 16244, 3391, 13, 51206], "temperature": 0.0, "avg_logprob": -0.31051001437874726, "compression_ratio": 1.7307692307692308, "no_speech_prob": 2.5071565687539987e-05}, {"id": 1139, "seek": 529422, "start": 5311.06, "end": 5314.42, "text": " So we've got our numerator that we calculated up here for", "tokens": [51206, 407, 321, 600, 658, 527, 30380, 300, 321, 15598, 493, 510, 337, 51374], "temperature": 0.0, "avg_logprob": -0.31051001437874726, "compression_ratio": 1.7307692307692308, "no_speech_prob": 2.5071565687539987e-05}, {"id": 1140, "seek": 529422, "start": 5314.42, "end": 5316.740000000001, "text": " our weighted average.", "tokens": [51374, 527, 32807, 4274, 13, 51490], "temperature": 0.0, "avg_logprob": -0.31051001437874726, "compression_ratio": 1.7307692307692308, "no_speech_prob": 2.5071565687539987e-05}, {"id": 1141, "seek": 529422, "start": 5316.740000000001, "end": 5319.820000000001, "text": " The denominator is just the sum of the weights, remember.", "tokens": [51490, 440, 20687, 307, 445, 264, 2408, 295, 264, 17443, 11, 1604, 13, 51644], "temperature": 0.0, "avg_logprob": -0.31051001437874726, "compression_ratio": 1.7307692307692308, "no_speech_prob": 2.5071565687539987e-05}, {"id": 1142, "seek": 529422, "start": 5319.820000000001, "end": 5323.5, "text": " And so numerator divided by denominator is our answer.", "tokens": [51644, 400, 370, 30380, 6666, 538, 20687, 307, 527, 1867, 13, 51828], "temperature": 0.0, "avg_logprob": -0.31051001437874726, "compression_ratio": 1.7307692307692308, "no_speech_prob": 2.5071565687539987e-05}, {"id": 1143, "seek": 532350, "start": 5323.5, "end": 5326.06, "text": " So again, we've gone through every step,", "tokens": [50364, 407, 797, 11, 321, 600, 2780, 807, 633, 1823, 11, 50492], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1144, "seek": 532350, "start": 5326.06, "end": 5328.5, "text": " we've checked out all the dimensions all along the way, so", "tokens": [50492, 321, 600, 10033, 484, 439, 264, 12819, 439, 2051, 264, 636, 11, 370, 50614], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1145, "seek": 532350, "start": 5328.5, "end": 5330.58, "text": " nothing's gonna surprise us.", "tokens": [50614, 1825, 311, 799, 6365, 505, 13, 50718], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1146, "seek": 532350, "start": 5330.58, "end": 5334.3, "text": " Don't try and write a function like this just bang from scratch, right?", "tokens": [50718, 1468, 380, 853, 293, 2464, 257, 2445, 411, 341, 445, 8550, 490, 8459, 11, 558, 30, 50904], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1147, "seek": 532350, "start": 5334.3, "end": 5335.74, "text": " You're gonna drive yourself crazy.", "tokens": [50904, 509, 434, 799, 3332, 1803, 3219, 13, 50976], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1148, "seek": 532350, "start": 5337.26, "end": 5339.14, "text": " Instead, do it step by step.", "tokens": [51052, 7156, 11, 360, 309, 1823, 538, 1823, 13, 51146], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1149, "seek": 532350, "start": 5339.14, "end": 5340.78, "text": " So here's our mean shift algorithm.", "tokens": [51146, 407, 510, 311, 527, 914, 5513, 9284, 13, 51228], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1150, "seek": 532350, "start": 5341.9, "end": 5342.7, "text": " Clone the data.", "tokens": [51284, 45536, 264, 1412, 13, 51324], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1151, "seek": 532350, "start": 5344.06, "end": 5345.78, "text": " Go through five iterations.", "tokens": [51392, 1037, 807, 1732, 36540, 13, 51478], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1152, "seek": 532350, "start": 5347.06, "end": 5350.66, "text": " And now go from 0 to n, batch size at a time.", "tokens": [51542, 400, 586, 352, 490, 1958, 281, 297, 11, 15245, 2744, 412, 257, 565, 13, 51722], "temperature": 0.0, "avg_logprob": -0.30413625936592575, "compression_ratio": 1.5234375, "no_speech_prob": 3.41258612479578e-07}, {"id": 1153, "seek": 535066, "start": 5351.66, "end": 5355.74, "text": " So Python has something called slices.", "tokens": [50414, 407, 15329, 575, 746, 1219, 19793, 13, 50618], "temperature": 0.0, "avg_logprob": -0.3075125921340216, "compression_ratio": 1.5630252100840336, "no_speech_prob": 7.571149467366922e-07}, {"id": 1154, "seek": 535066, "start": 5355.74, "end": 5365.54, "text": " So we can create a slice of x starting at 1 up to i plus batch size, right?", "tokens": [50618, 407, 321, 393, 1884, 257, 13153, 295, 2031, 2891, 412, 502, 493, 281, 741, 1804, 15245, 2744, 11, 558, 30, 51108], "temperature": 0.0, "avg_logprob": -0.3075125921340216, "compression_ratio": 1.5630252100840336, "no_speech_prob": 7.571149467366922e-07}, {"id": 1155, "seek": 535066, "start": 5365.54, "end": 5367.46, "text": " Unless you've gone past n, which goes to use n.", "tokens": [51108, 16581, 291, 600, 2780, 1791, 297, 11, 597, 1709, 281, 764, 297, 13, 51204], "temperature": 0.0, "avg_logprob": -0.3075125921340216, "compression_ratio": 1.5630252100840336, "no_speech_prob": 7.571149467366922e-07}, {"id": 1156, "seek": 535066, "start": 5368.86, "end": 5370.0599999999995, "text": " And so then we're just copying and", "tokens": [51274, 400, 370, 550, 321, 434, 445, 27976, 293, 51334], "temperature": 0.0, "avg_logprob": -0.3075125921340216, "compression_ratio": 1.5630252100840336, "no_speech_prob": 7.571149467366922e-07}, {"id": 1157, "seek": 535066, "start": 5370.0599999999995, "end": 5373.0199999999995, "text": " pasting each of the lines of code that we had before.", "tokens": [51334, 1791, 278, 1184, 295, 264, 3876, 295, 3089, 300, 321, 632, 949, 13, 51482], "temperature": 0.0, "avg_logprob": -0.3075125921340216, "compression_ratio": 1.5630252100840336, "no_speech_prob": 7.571149467366922e-07}, {"id": 1158, "seek": 535066, "start": 5373.0199999999995, "end": 5375.099999999999, "text": " Actually, I just copy the cells and merge them, of course.", "tokens": [51482, 5135, 11, 286, 445, 5055, 264, 5438, 293, 22183, 552, 11, 295, 1164, 13, 51586], "temperature": 0.0, "avg_logprob": -0.3075125921340216, "compression_ratio": 1.5630252100840336, "no_speech_prob": 7.571149467366922e-07}, {"id": 1159, "seek": 535066, "start": 5375.099999999999, "end": 5378.18, "text": " I don't actually copy and paste because it's slow and boring.", "tokens": [51586, 286, 500, 380, 767, 5055, 293, 9163, 570, 309, 311, 2964, 293, 9989, 13, 51740], "temperature": 0.0, "avg_logprob": -0.3075125921340216, "compression_ratio": 1.5630252100840336, "no_speech_prob": 7.571149467366922e-07}, {"id": 1160, "seek": 537818, "start": 5378.18, "end": 5382.38, "text": " And there's my final step to create the new xs.", "tokens": [50364, 400, 456, 311, 452, 2572, 1823, 281, 1884, 264, 777, 2031, 82, 13, 50574], "temperature": 0.0, "avg_logprob": -0.29326328788835976, "compression_ratio": 1.560747663551402, "no_speech_prob": 7.224440423669876e-07}, {"id": 1161, "seek": 537818, "start": 5382.38, "end": 5387.5, "text": " And so notice here, s is not a single thing, it's a slice of things.", "tokens": [50574, 400, 370, 3449, 510, 11, 262, 307, 406, 257, 2167, 551, 11, 309, 311, 257, 13153, 295, 721, 13, 50830], "temperature": 0.0, "avg_logprob": -0.29326328788835976, "compression_ratio": 1.560747663551402, "no_speech_prob": 7.224440423669876e-07}, {"id": 1162, "seek": 537818, "start": 5387.5, "end": 5389.700000000001, "text": " You might not have seen slice before, but", "tokens": [50830, 509, 1062, 406, 362, 1612, 13153, 949, 11, 457, 50940], "temperature": 0.0, "avg_logprob": -0.29326328788835976, "compression_ratio": 1.560747663551402, "no_speech_prob": 7.224440423669876e-07}, {"id": 1163, "seek": 537818, "start": 5389.700000000001, "end": 5392.9400000000005, "text": " this is just internally what Python's doing when you use colon.", "tokens": [50940, 341, 307, 445, 19501, 437, 15329, 311, 884, 562, 291, 764, 8255, 13, 51102], "temperature": 0.0, "avg_logprob": -0.29326328788835976, "compression_ratio": 1.560747663551402, "no_speech_prob": 7.224440423669876e-07}, {"id": 1164, "seek": 537818, "start": 5392.9400000000005, "end": 5396.46, "text": " And it's very convenient when you need to use the same slice multiple times.", "tokens": [51102, 400, 309, 311, 588, 10851, 562, 291, 643, 281, 764, 264, 912, 13153, 3866, 1413, 13, 51278], "temperature": 0.0, "avg_logprob": -0.29326328788835976, "compression_ratio": 1.560747663551402, "no_speech_prob": 7.224440423669876e-07}, {"id": 1165, "seek": 537818, "start": 5399.26, "end": 5399.76, "text": " Okay.", "tokens": [51418, 1033, 13, 51443], "temperature": 0.0, "avg_logprob": -0.29326328788835976, "compression_ratio": 1.560747663551402, "no_speech_prob": 7.224440423669876e-07}, {"id": 1166, "seek": 537818, "start": 5404.02, "end": 5406.22, "text": " So let's do that using CUDA.", "tokens": [51656, 407, 718, 311, 360, 300, 1228, 29777, 7509, 13, 51766], "temperature": 0.0, "avg_logprob": -0.29326328788835976, "compression_ratio": 1.560747663551402, "no_speech_prob": 7.224440423669876e-07}, {"id": 1167, "seek": 540622, "start": 5406.46, "end": 5409.14, "text": " I would run it first without CUDA, but I mean,", "tokens": [50376, 286, 576, 1190, 309, 700, 1553, 29777, 7509, 11, 457, 286, 914, 11, 50510], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1168, "seek": 540622, "start": 5409.14, "end": 5412.02, "text": " I've done all the steps before, so it should be fine.", "tokens": [50510, 286, 600, 1096, 439, 264, 4439, 949, 11, 370, 309, 820, 312, 2489, 13, 50654], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1169, "seek": 540622, "start": 5412.02, "end": 5415.34, "text": " So pop it on the GPU and run the main shift.", "tokens": [50654, 407, 1665, 309, 322, 264, 18407, 293, 1190, 264, 2135, 5513, 13, 50820], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1170, "seek": 540622, "start": 5416.740000000001, "end": 5419.06, "text": " And let's see how long that takes.", "tokens": [50890, 400, 718, 311, 536, 577, 938, 300, 2516, 13, 51006], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1171, "seek": 540622, "start": 5419.06, "end": 5421.26, "text": " It takes one millisecond.", "tokens": [51006, 467, 2516, 472, 27940, 18882, 13, 51116], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1172, "seek": 540622, "start": 5421.26, "end": 5425.58, "text": " And previously, without GPU, it took 400 milliseconds.", "tokens": [51116, 400, 8046, 11, 1553, 18407, 11, 309, 1890, 8423, 34184, 13, 51332], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1173, "seek": 540622, "start": 5425.58, "end": 5428.780000000001, "text": " And the other thing we should probably think about doing", "tokens": [51332, 400, 264, 661, 551, 321, 820, 1391, 519, 466, 884, 51492], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1174, "seek": 540622, "start": 5428.780000000001, "end": 5430.62, "text": " is looking at other batch sizes as well.", "tokens": [51492, 307, 1237, 412, 661, 15245, 11602, 382, 731, 13, 51584], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1175, "seek": 540622, "start": 5430.62, "end": 5436.02, "text": " Because now we're looping over batches, right?", "tokens": [51584, 1436, 586, 321, 434, 6367, 278, 670, 15245, 279, 11, 558, 30, 51854], "temperature": 0.0, "avg_logprob": -0.3041167881177819, "compression_ratio": 1.5859375, "no_speech_prob": 1.5534973272224306e-06}, {"id": 1176, "seek": 543622, "start": 5436.34, "end": 5439.66, "text": " So if we make the batch size bigger, that for loop's gonna do less looping.", "tokens": [50370, 407, 498, 321, 652, 264, 15245, 2744, 3801, 11, 300, 337, 6367, 311, 799, 360, 1570, 6367, 278, 13, 50536], "temperature": 0.0, "avg_logprob": -0.4602338951754283, "compression_ratio": 1.454054054054054, "no_speech_prob": 1.9223140043322928e-05}, {"id": 1177, "seek": 543622, "start": 5441.02, "end": 5443.02, "text": " So what if we make that 16?", "tokens": [50604, 407, 437, 498, 321, 652, 300, 3165, 30, 50704], "temperature": 0.0, "avg_logprob": -0.4602338951754283, "compression_ratio": 1.454054054054054, "no_speech_prob": 1.9223140043322928e-05}, {"id": 1178, "seek": 543622, "start": 5443.02, "end": 5444.22, "text": " Will that be any faster?", "tokens": [50704, 3099, 300, 312, 604, 4663, 30, 50764], "temperature": 0.0, "avg_logprob": -0.4602338951754283, "compression_ratio": 1.454054054054054, "no_speech_prob": 1.9223140043322928e-05}, {"id": 1179, "seek": 543622, "start": 5445.34, "end": 5446.58, "text": " I actually never tried this before.", "tokens": [50820, 286, 767, 1128, 3031, 341, 949, 13, 50882], "temperature": 0.0, "avg_logprob": -0.4602338951754283, "compression_ratio": 1.454054054054054, "no_speech_prob": 1.9223140043322928e-05}, {"id": 1180, "seek": 543622, "start": 5449.1, "end": 5450.7, "text": " That's interesting, it's actually slower.", "tokens": [51008, 663, 311, 1880, 11, 309, 311, 767, 14009, 13, 51088], "temperature": 0.0, "avg_logprob": -0.4602338951754283, "compression_ratio": 1.454054054054054, "no_speech_prob": 1.9223140043322928e-05}, {"id": 1181, "seek": 543622, "start": 5454.3, "end": 5457.860000000001, "text": " Huh, there you go, fascinating.", "tokens": [51268, 8063, 11, 456, 291, 352, 11, 10343, 13, 51446], "temperature": 0.0, "avg_logprob": -0.4602338951754283, "compression_ratio": 1.454054054054054, "no_speech_prob": 1.9223140043322928e-05}, {"id": 1182, "seek": 543622, "start": 5457.860000000001, "end": 5458.62, "text": " What if it was eight?", "tokens": [51446, 708, 498, 309, 390, 3180, 30, 51484], "temperature": 0.0, "avg_logprob": -0.4602338951754283, "compression_ratio": 1.454054054054054, "no_speech_prob": 1.9223140043322928e-05}, {"id": 1183, "seek": 543622, "start": 5462.9800000000005, "end": 5463.9800000000005, "text": " Amazing.", "tokens": [51702, 14165, 13, 51752], "temperature": 0.0, "avg_logprob": -0.4602338951754283, "compression_ratio": 1.454054054054054, "no_speech_prob": 1.9223140043322928e-05}, {"id": 1184, "seek": 546398, "start": 5463.98, "end": 5468.459999999999, "text": " So the big patches don't quite seem to be working so well for some reason.", "tokens": [50364, 407, 264, 955, 26531, 500, 380, 1596, 1643, 281, 312, 1364, 370, 731, 337, 512, 1778, 13, 50588], "temperature": 0.0, "avg_logprob": -0.31466463109949133, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1478759006422479e-05}, {"id": 1185, "seek": 546398, "start": 5468.459999999999, "end": 5472.86, "text": " So I wonder if I've, Hang on, what's going on?", "tokens": [50588, 407, 286, 2441, 498, 286, 600, 11, 14070, 322, 11, 437, 311, 516, 322, 30, 50808], "temperature": 0.0, "avg_logprob": -0.31466463109949133, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1478759006422479e-05}, {"id": 1186, "seek": 546398, "start": 5472.86, "end": 5479.86, "text": " Why is it, Why is it changing how it should be?", "tokens": [50808, 1545, 307, 309, 11, 1545, 307, 309, 4473, 577, 309, 820, 312, 30, 51158], "temperature": 0.0, "avg_logprob": -0.31466463109949133, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1478759006422479e-05}, {"id": 1187, "seek": 546398, "start": 5479.86, "end": 5482.259999999999, "text": " My batch size was five, why is it slower suddenly?", "tokens": [51158, 1222, 15245, 2744, 390, 1732, 11, 983, 307, 309, 14009, 5800, 30, 51278], "temperature": 0.0, "avg_logprob": -0.31466463109949133, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1478759006422479e-05}, {"id": 1188, "seek": 546398, "start": 5484.86, "end": 5487.5, "text": " I think it's just a bit varying is probably the answer.", "tokens": [51408, 286, 519, 309, 311, 445, 257, 857, 22984, 307, 1391, 264, 1867, 13, 51540], "temperature": 0.0, "avg_logprob": -0.31466463109949133, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1478759006422479e-05}, {"id": 1189, "seek": 546398, "start": 5489.219999999999, "end": 5490.299999999999, "text": " So it just varies a lot.", "tokens": [51626, 407, 309, 445, 21716, 257, 688, 13, 51680], "temperature": 0.0, "avg_logprob": -0.31466463109949133, "compression_ratio": 1.4682926829268292, "no_speech_prob": 1.1478759006422479e-05}, {"id": 1190, "seek": 549030, "start": 5491.3, "end": 5494.9400000000005, "text": " Okay, so it doesn't seem like changing the batch size is changing much here.", "tokens": [50414, 1033, 11, 370, 309, 1177, 380, 1643, 411, 4473, 264, 15245, 2744, 307, 4473, 709, 510, 13, 50596], "temperature": 0.0, "avg_logprob": -0.3769241599149482, "compression_ratio": 1.5226130653266332, "no_speech_prob": 1.1478766282380093e-05}, {"id": 1191, "seek": 549030, "start": 5497.42, "end": 5501.1, "text": " So that's fine, so we'll just leave it where it was.", "tokens": [50720, 407, 300, 311, 2489, 11, 370, 321, 603, 445, 1856, 309, 689, 309, 390, 13, 50904], "temperature": 0.0, "avg_logprob": -0.3769241599149482, "compression_ratio": 1.5226130653266332, "no_speech_prob": 1.1478766282380093e-05}, {"id": 1192, "seek": 549030, "start": 5501.1, "end": 5503.1, "text": " And then it's checked looking at the data.", "tokens": [50904, 400, 550, 309, 311, 10033, 1237, 412, 264, 1412, 13, 51004], "temperature": 0.0, "avg_logprob": -0.3769241599149482, "compression_ratio": 1.5226130653266332, "no_speech_prob": 1.1478766282380093e-05}, {"id": 1193, "seek": 549030, "start": 5503.1, "end": 5503.820000000001, "text": " That looks lovely.", "tokens": [51004, 663, 1542, 7496, 13, 51040], "temperature": 0.0, "avg_logprob": -0.3769241599149482, "compression_ratio": 1.5226130653266332, "no_speech_prob": 1.1478766282380093e-05}, {"id": 1194, "seek": 549030, "start": 5509.820000000001, "end": 5514.66, "text": " I see, thank you people on YouTube pointing out that I'm passing batch size.", "tokens": [51340, 286, 536, 11, 1309, 291, 561, 322, 3088, 12166, 484, 300, 286, 478, 8437, 15245, 2744, 13, 51582], "temperature": 0.0, "avg_logprob": -0.3769241599149482, "compression_ratio": 1.5226130653266332, "no_speech_prob": 1.1478766282380093e-05}, {"id": 1195, "seek": 549030, "start": 5514.66, "end": 5516.1, "text": " So I actually need to put it here.", "tokens": [51582, 407, 286, 767, 643, 281, 829, 309, 510, 13, 51654], "temperature": 0.0, "avg_logprob": -0.3769241599149482, "compression_ratio": 1.5226130653266332, "no_speech_prob": 1.1478766282380093e-05}, {"id": 1196, "seek": 551610, "start": 5517.1, "end": 5521.38, "text": " All right, so if we used a batch size of five, no wonder it was messing up.", "tokens": [50414, 1057, 558, 11, 370, 498, 321, 1143, 257, 15245, 2744, 295, 1732, 11, 572, 2441, 309, 390, 23258, 493, 13, 50628], "temperature": 0.0, "avg_logprob": -0.45119130751665903, "compression_ratio": 1.4210526315789473, "no_speech_prob": 7.368589285761118e-05}, {"id": 1197, "seek": 551610, "start": 5521.38, "end": 5524.06, "text": " Look at that, I've totally made it slow now.", "tokens": [50628, 2053, 412, 300, 11, 286, 600, 3879, 1027, 309, 2964, 586, 13, 50762], "temperature": 0.0, "avg_logprob": -0.45119130751665903, "compression_ratio": 1.4210526315789473, "no_speech_prob": 7.368589285761118e-05}, {"id": 1198, "seek": 551610, "start": 5524.06, "end": 5528.22, "text": " 157 milliseconds.", "tokens": [50762, 2119, 22, 34184, 13, 50970], "temperature": 0.0, "avg_logprob": -0.45119130751665903, "compression_ratio": 1.4210526315789473, "no_speech_prob": 7.368589285761118e-05}, {"id": 1199, "seek": 551610, "start": 5528.22, "end": 5533.700000000001, "text": " Ha ha, okay, 64, 13 milliseconds.", "tokens": [50970, 4064, 324, 11, 1392, 11, 12145, 11, 3705, 34184, 13, 51244], "temperature": 0.0, "avg_logprob": -0.45119130751665903, "compression_ratio": 1.4210526315789473, "no_speech_prob": 7.368589285761118e-05}, {"id": 1200, "seek": 551610, "start": 5533.700000000001, "end": 5536.860000000001, "text": " All right, finally, that makes much more sense, 256.", "tokens": [51244, 1057, 558, 11, 2721, 11, 300, 1669, 709, 544, 2020, 11, 38882, 13, 51402], "temperature": 0.0, "avg_logprob": -0.45119130751665903, "compression_ratio": 1.4210526315789473, "no_speech_prob": 7.368589285761118e-05}, {"id": 1201, "seek": 551610, "start": 5536.860000000001, "end": 5543.820000000001, "text": " 1024, okay, so the bigger, bigger is better.", "tokens": [51402, 1266, 7911, 11, 1392, 11, 370, 264, 3801, 11, 3801, 307, 1101, 13, 51750], "temperature": 0.0, "avg_logprob": -0.45119130751665903, "compression_ratio": 1.4210526315789473, "no_speech_prob": 7.368589285761118e-05}, {"id": 1202, "seek": 554610, "start": 5547.1, "end": 5550.42, "text": " And I guess we can actually do all 5,000 at once probably.", "tokens": [50414, 400, 286, 2041, 321, 393, 767, 360, 439, 1025, 11, 1360, 412, 1564, 1391, 13, 50580], "temperature": 0.0, "avg_logprob": -0.6914090936834162, "compression_ratio": 1.24822695035461, "no_speech_prob": 6.577925546480401e-07}, {"id": 1203, "seek": 554610, "start": 5550.42, "end": 5553.02, "text": " Nice.", "tokens": [50580, 5490, 13, 50710], "temperature": 0.0, "avg_logprob": -0.6914090936834162, "compression_ratio": 1.24822695035461, "no_speech_prob": 6.577925546480401e-07}, {"id": 1204, "seek": 554610, "start": 5553.02, "end": 5558.780000000001, "text": " All right, thank you YouTube friends for", "tokens": [50710, 1057, 558, 11, 1309, 291, 3088, 1855, 337, 50998], "temperature": 0.0, "avg_logprob": -0.6914090936834162, "compression_ratio": 1.24822695035461, "no_speech_prob": 6.577925546480401e-07}, {"id": 1205, "seek": 554610, "start": 5558.780000000001, "end": 5562.700000000001, "text": " solving that bizarre mystery.", "tokens": [50998, 12606, 300, 18265, 11422, 13, 51194], "temperature": 0.0, "avg_logprob": -0.6914090936834162, "compression_ratio": 1.24822695035461, "no_speech_prob": 6.577925546480401e-07}, {"id": 1206, "seek": 554610, "start": 5562.700000000001, "end": 5570.3, "text": " Okay, all right, so", "tokens": [51194, 1033, 11, 439, 558, 11, 370, 51574], "temperature": 0.0, "avg_logprob": -0.6914090936834162, "compression_ratio": 1.24822695035461, "no_speech_prob": 6.577925546480401e-07}, {"id": 1207, "seek": 554610, "start": 5570.3, "end": 5574.34, "text": " that's pretty great.", "tokens": [51574, 300, 311, 1238, 869, 13, 51776], "temperature": 0.0, "avg_logprob": -0.6914090936834162, "compression_ratio": 1.24822695035461, "no_speech_prob": 6.577925546480401e-07}, {"id": 1208, "seek": 557434, "start": 5574.34, "end": 5579.9400000000005, "text": " I mean, to see that we can GPU optimize a mean shift,", "tokens": [50364, 286, 914, 11, 281, 536, 300, 321, 393, 18407, 19719, 257, 914, 5513, 11, 50644], "temperature": 0.0, "avg_logprob": -0.3448500240550322, "compression_ratio": 1.6042780748663101, "no_speech_prob": 4.936966433888301e-06}, {"id": 1209, "seek": 557434, "start": 5579.9400000000005, "end": 5583.18, "text": " I actually Googled for this to see if it's been done before.", "tokens": [50644, 286, 767, 45005, 1493, 337, 341, 281, 536, 498, 309, 311, 668, 1096, 949, 13, 50806], "temperature": 0.0, "avg_logprob": -0.3448500240550322, "compression_ratio": 1.6042780748663101, "no_speech_prob": 4.936966433888301e-06}, {"id": 1210, "seek": 557434, "start": 5586.900000000001, "end": 5590.74, "text": " And it's the kind of thing that people write papers about.", "tokens": [50992, 400, 309, 311, 264, 733, 295, 551, 300, 561, 2464, 10577, 466, 13, 51184], "temperature": 0.0, "avg_logprob": -0.3448500240550322, "compression_ratio": 1.6042780748663101, "no_speech_prob": 4.936966433888301e-06}, {"id": 1211, "seek": 557434, "start": 5593.14, "end": 5597.62, "text": " So I think it's great that we can do it so", "tokens": [51304, 407, 286, 519, 309, 311, 869, 300, 321, 393, 360, 309, 370, 51528], "temperature": 0.0, "avg_logprob": -0.3448500240550322, "compression_ratio": 1.6042780748663101, "no_speech_prob": 4.936966433888301e-06}, {"id": 1212, "seek": 557434, "start": 5597.62, "end": 5602.1, "text": " easily with PyTorch, and it's the kind of thing that previously had been considered", "tokens": [51528, 3612, 365, 9953, 51, 284, 339, 11, 293, 309, 311, 264, 733, 295, 551, 300, 8046, 632, 668, 4888, 51752], "temperature": 0.0, "avg_logprob": -0.3448500240550322, "compression_ratio": 1.6042780748663101, "no_speech_prob": 4.936966433888301e-06}, {"id": 1213, "seek": 560210, "start": 5603.1, "end": 5607.3, "text": " a very challenging academic problem to solve.", "tokens": [50414, 257, 588, 7595, 7778, 1154, 281, 5039, 13, 50624], "temperature": 0.0, "avg_logprob": -0.3083011054992676, "compression_ratio": 1.5573770491803278, "no_speech_prob": 3.726638851730968e-06}, {"id": 1214, "seek": 560210, "start": 5608.660000000001, "end": 5612.18, "text": " So maybe you can do something similar with some of these.", "tokens": [50692, 407, 1310, 291, 393, 360, 746, 2531, 365, 512, 295, 613, 13, 50868], "temperature": 0.0, "avg_logprob": -0.3083011054992676, "compression_ratio": 1.5573770491803278, "no_speech_prob": 3.726638851730968e-06}, {"id": 1215, "seek": 560210, "start": 5612.18, "end": 5613.900000000001, "text": " Now, I haven't told you what these are, so", "tokens": [50868, 823, 11, 286, 2378, 380, 1907, 291, 437, 613, 366, 11, 370, 50954], "temperature": 0.0, "avg_logprob": -0.3083011054992676, "compression_ratio": 1.5573770491803278, "no_speech_prob": 3.726638851730968e-06}, {"id": 1216, "seek": 560210, "start": 5613.900000000001, "end": 5617.26, "text": " part of the homework is to go read about them and learn about them.", "tokens": [50954, 644, 295, 264, 14578, 307, 281, 352, 1401, 466, 552, 293, 1466, 466, 552, 13, 51122], "temperature": 0.0, "avg_logprob": -0.3083011054992676, "compression_ratio": 1.5573770491803278, "no_speech_prob": 3.726638851730968e-06}, {"id": 1217, "seek": 560210, "start": 5617.26, "end": 5622.9800000000005, "text": " DBScan, funnily enough, actually, is an algorithm that I accidentally invented,", "tokens": [51122, 413, 8176, 7035, 11, 1019, 77, 953, 1547, 11, 767, 11, 307, 364, 9284, 300, 286, 15715, 14479, 11, 51408], "temperature": 0.0, "avg_logprob": -0.3083011054992676, "compression_ratio": 1.5573770491803278, "no_speech_prob": 3.726638851730968e-06}, {"id": 1218, "seek": 560210, "start": 5622.9800000000005, "end": 5626.14, "text": " and then discovered a year later had already been invented.", "tokens": [51408, 293, 550, 6941, 257, 1064, 1780, 632, 1217, 668, 14479, 13, 51566], "temperature": 0.0, "avg_logprob": -0.3083011054992676, "compression_ratio": 1.5573770491803278, "no_speech_prob": 3.726638851730968e-06}, {"id": 1219, "seek": 560210, "start": 5626.14, "end": 5628.06, "text": " That was a long time ago.", "tokens": [51566, 663, 390, 257, 938, 565, 2057, 13, 51662], "temperature": 0.0, "avg_logprob": -0.3083011054992676, "compression_ratio": 1.5573770491803278, "no_speech_prob": 3.726638851730968e-06}, {"id": 1220, "seek": 562806, "start": 5628.1, "end": 5631.620000000001, "text": " I was playing around with J, which is the successor to APL,", "tokens": [50366, 286, 390, 2433, 926, 365, 508, 11, 597, 307, 264, 31864, 281, 5372, 43, 11, 50542], "temperature": 0.0, "avg_logprob": -0.29563373801982507, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.2029629942844622e-05}, {"id": 1221, "seek": 562806, "start": 5631.620000000001, "end": 5634.900000000001, "text": " on a very old Windows phone.", "tokens": [50542, 322, 257, 588, 1331, 8591, 2593, 13, 50706], "temperature": 0.0, "avg_logprob": -0.29563373801982507, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.2029629942844622e-05}, {"id": 1222, "seek": 562806, "start": 5634.900000000001, "end": 5638.660000000001, "text": " And I had a long plane flight, and I came up with an algorithm and", "tokens": [50706, 400, 286, 632, 257, 938, 5720, 7018, 11, 293, 286, 1361, 493, 365, 364, 9284, 293, 50894], "temperature": 0.0, "avg_logprob": -0.29563373801982507, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.2029629942844622e-05}, {"id": 1223, "seek": 562806, "start": 5638.660000000001, "end": 5641.580000000001, "text": " implemented the whole thing on my phone using J.", "tokens": [50894, 12270, 264, 1379, 551, 322, 452, 2593, 1228, 508, 13, 51040], "temperature": 0.0, "avg_logprob": -0.29563373801982507, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.2029629942844622e-05}, {"id": 1224, "seek": 562806, "start": 5641.580000000001, "end": 5645.06, "text": " And then discovered a year later that I just invented DBScan.", "tokens": [51040, 400, 550, 6941, 257, 1064, 1780, 300, 286, 445, 14479, 413, 8176, 7035, 13, 51214], "temperature": 0.0, "avg_logprob": -0.29563373801982507, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.2029629942844622e-05}, {"id": 1225, "seek": 562806, "start": 5645.06, "end": 5647.26, "text": " This is actually a really cool algorithm, and", "tokens": [51214, 639, 307, 767, 257, 534, 1627, 9284, 11, 293, 51324], "temperature": 0.0, "avg_logprob": -0.29563373801982507, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.2029629942844622e-05}, {"id": 1226, "seek": 562806, "start": 5647.26, "end": 5649.860000000001, "text": " it's got a lot of similarities to mean shift.", "tokens": [51324, 309, 311, 658, 257, 688, 295, 24197, 281, 914, 5513, 13, 51454], "temperature": 0.0, "avg_logprob": -0.29563373801982507, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.2029629942844622e-05}, {"id": 1227, "seek": 562806, "start": 5652.580000000001, "end": 5656.18, "text": " LSH comes up all the time, so that's great.", "tokens": [51590, 441, 17308, 1487, 493, 439, 264, 565, 11, 370, 300, 311, 869, 13, 51770], "temperature": 0.0, "avg_logprob": -0.29563373801982507, "compression_ratio": 1.558139534883721, "no_speech_prob": 1.2029629942844622e-05}, {"id": 1228, "seek": 565618, "start": 5656.5, "end": 5661.34, "text": " And in fact, I have a strong feeling, and I've been thinking about this for", "tokens": [50380, 400, 294, 1186, 11, 286, 362, 257, 2068, 2633, 11, 293, 286, 600, 668, 1953, 466, 341, 337, 50622], "temperature": 0.0, "avg_logprob": -0.2644135355949402, "compression_ratio": 1.5866666666666667, "no_speech_prob": 3.41258612479578e-07}, {"id": 1229, "seek": 565618, "start": 5661.34, "end": 5665.66, "text": " a while, that something like LSH could be used to speed this whole thing up a lot.", "tokens": [50622, 257, 1339, 11, 300, 746, 411, 441, 17308, 727, 312, 1143, 281, 3073, 341, 1379, 551, 493, 257, 688, 13, 50838], "temperature": 0.0, "avg_logprob": -0.2644135355949402, "compression_ratio": 1.5866666666666667, "no_speech_prob": 3.41258612479578e-07}, {"id": 1230, "seek": 565618, "start": 5666.66, "end": 5669.66, "text": " Because if you think about it, and again, maybe this already exists,", "tokens": [50888, 1436, 498, 291, 519, 466, 309, 11, 293, 797, 11, 1310, 341, 1217, 8198, 11, 51038], "temperature": 0.0, "avg_logprob": -0.2644135355949402, "compression_ratio": 1.5866666666666667, "no_speech_prob": 3.41258612479578e-07}, {"id": 1231, "seek": 565618, "start": 5669.66, "end": 5670.780000000001, "text": " I don't know.", "tokens": [51038, 286, 500, 380, 458, 13, 51094], "temperature": 0.0, "avg_logprob": -0.2644135355949402, "compression_ratio": 1.5866666666666667, "no_speech_prob": 3.41258612479578e-07}, {"id": 1232, "seek": 565618, "start": 5670.780000000001, "end": 5674.9800000000005, "text": " But if you think about it, when we did that distance calculation,", "tokens": [51094, 583, 498, 291, 519, 466, 309, 11, 562, 321, 630, 300, 4560, 17108, 11, 51304], "temperature": 0.0, "avg_logprob": -0.2644135355949402, "compression_ratio": 1.5866666666666667, "no_speech_prob": 3.41258612479578e-07}, {"id": 1233, "seek": 565618, "start": 5674.9800000000005, "end": 5680.34, "text": " the vast majority of the weights are nearly zero.", "tokens": [51304, 264, 8369, 6286, 295, 264, 17443, 366, 6217, 4018, 13, 51572], "temperature": 0.0, "avg_logprob": -0.2644135355949402, "compression_ratio": 1.5866666666666667, "no_speech_prob": 3.41258612479578e-07}, {"id": 1234, "seek": 568034, "start": 5681.22, "end": 5685.22, "text": " And so it seems pointless to create that big,", "tokens": [50408, 400, 370, 309, 2544, 32824, 281, 1884, 300, 955, 11, 50608], "temperature": 0.0, "avg_logprob": -0.41464716889137443, "compression_ratio": 1.5022831050228311, "no_speech_prob": 6.854315870441496e-06}, {"id": 1235, "seek": 568034, "start": 5685.22, "end": 5688.78, "text": " kind of eventually 1500 by 1500 matrix.", "tokens": [50608, 733, 295, 4728, 22671, 538, 22671, 8141, 13, 50786], "temperature": 0.0, "avg_logprob": -0.41464716889137443, "compression_ratio": 1.5022831050228311, "no_speech_prob": 6.854315870441496e-06}, {"id": 1236, "seek": 568034, "start": 5688.78, "end": 5691.46, "text": " That's slow.", "tokens": [50786, 663, 311, 2964, 13, 50920], "temperature": 0.0, "avg_logprob": -0.41464716889137443, "compression_ratio": 1.5022831050228311, "no_speech_prob": 6.854315870441496e-06}, {"id": 1237, "seek": 568034, "start": 5691.46, "end": 5696.38, "text": " It would be much better if we just found the ones that were pretty close by and", "tokens": [50920, 467, 576, 312, 709, 1101, 498, 321, 445, 1352, 264, 2306, 300, 645, 1238, 1998, 538, 293, 51166], "temperature": 0.0, "avg_logprob": -0.41464716889137443, "compression_ratio": 1.5022831050228311, "no_speech_prob": 6.854315870441496e-06}, {"id": 1238, "seek": 568034, "start": 5696.38, "end": 5698.1, "text": " just took their average.", "tokens": [51166, 445, 1890, 641, 4274, 13, 51252], "temperature": 0.0, "avg_logprob": -0.41464716889137443, "compression_ratio": 1.5022831050228311, "no_speech_prob": 6.854315870441496e-06}, {"id": 1239, "seek": 568034, "start": 5698.1, "end": 5703.14, "text": " And so you want an optimized nearest neighbors, basically.", "tokens": [51252, 400, 370, 291, 528, 364, 26941, 23831, 12512, 11, 1936, 13, 51504], "temperature": 0.0, "avg_logprob": -0.41464716889137443, "compression_ratio": 1.5022831050228311, "no_speech_prob": 6.854315870441496e-06}, {"id": 1240, "seek": 568034, "start": 5703.14, "end": 5708.34, "text": " And so this is an example of something that can give you a kind of", "tokens": [51504, 400, 370, 341, 307, 364, 1365, 295, 746, 300, 393, 976, 291, 257, 733, 295, 51764], "temperature": 0.0, "avg_logprob": -0.41464716889137443, "compression_ratio": 1.5022831050228311, "no_speech_prob": 6.854315870441496e-06}, {"id": 1241, "seek": 570834, "start": 5708.34, "end": 5709.900000000001, "text": " a fast nearest neighbors algorithm.", "tokens": [50364, 257, 2370, 23831, 12512, 9284, 13, 50442], "temperature": 0.0, "avg_logprob": -0.5013007471116923, "compression_ratio": 1.4078947368421053, "no_speech_prob": 1.6964377209660597e-05}, {"id": 1242, "seek": 570834, "start": 5712.3, "end": 5716.82, "text": " Or there are things like KD trees and oct trees and stuff like that.", "tokens": [50562, 1610, 456, 366, 721, 411, 591, 35, 5852, 293, 13350, 5852, 293, 1507, 411, 300, 13, 50788], "temperature": 0.0, "avg_logprob": -0.5013007471116923, "compression_ratio": 1.4078947368421053, "no_speech_prob": 1.6964377209660597e-05}, {"id": 1243, "seek": 570834, "start": 5716.82, "end": 5720.14, "text": " So if you want to have a bonus bonus,", "tokens": [50788, 407, 498, 291, 528, 281, 362, 257, 10882, 10882, 11, 50954], "temperature": 0.0, "avg_logprob": -0.5013007471116923, "compression_ratio": 1.4078947368421053, "no_speech_prob": 1.6964377209660597e-05}, {"id": 1244, "seek": 570834, "start": 5723.78, "end": 5726.9400000000005, "text": " Invent a new mean shift algorithm,", "tokens": [51136, 682, 2475, 257, 777, 914, 5513, 9284, 11, 51294], "temperature": 0.0, "avg_logprob": -0.5013007471116923, "compression_ratio": 1.4078947368421053, "no_speech_prob": 1.6964377209660597e-05}, {"id": 1245, "seek": 570834, "start": 5729.06, "end": 5737.46, "text": " Which picks only the closest points.", "tokens": [51400, 3013, 16137, 787, 264, 13699, 2793, 13, 51820], "temperature": 0.0, "avg_logprob": -0.5013007471116923, "compression_ratio": 1.4078947368421053, "no_speech_prob": 1.6964377209660597e-05}, {"id": 1246, "seek": 573746, "start": 5737.5, "end": 5743.3, "text": " To avoid quadratic type.", "tokens": [50366, 1407, 5042, 37262, 2010, 13, 50656], "temperature": 0.0, "avg_logprob": -0.5222945473410866, "compression_ratio": 1.3823529411764706, "no_speech_prob": 8.059442393459904e-07}, {"id": 1247, "seek": 573746, "start": 5743.3, "end": 5749.5, "text": " All right, so not very often you get an assignment,", "tokens": [50656, 1057, 558, 11, 370, 406, 588, 2049, 291, 483, 364, 15187, 11, 50966], "temperature": 0.0, "avg_logprob": -0.5222945473410866, "compression_ratio": 1.3823529411764706, "no_speech_prob": 8.059442393459904e-07}, {"id": 1248, "seek": 573746, "start": 5749.5, "end": 5752.58, "text": " which is to invent a new mean shift algorithm.", "tokens": [50966, 597, 307, 281, 7962, 257, 777, 914, 5513, 9284, 13, 51120], "temperature": 0.0, "avg_logprob": -0.5222945473410866, "compression_ratio": 1.3823529411764706, "no_speech_prob": 8.059442393459904e-07}, {"id": 1249, "seek": 573746, "start": 5752.58, "end": 5754.18, "text": " I guess a super super bonus,", "tokens": [51120, 286, 2041, 257, 1687, 1687, 10882, 11, 51200], "temperature": 0.0, "avg_logprob": -0.5222945473410866, "compression_ratio": 1.3823529411764706, "no_speech_prob": 8.059442393459904e-07}, {"id": 1250, "seek": 573746, "start": 5756.86, "end": 5762.7, "text": " Super super bonus, Publish a paper.", "tokens": [51334, 4548, 1687, 10882, 11, 21808, 1933, 257, 3035, 13, 51626], "temperature": 0.0, "avg_logprob": -0.5222945473410866, "compression_ratio": 1.3823529411764706, "no_speech_prob": 8.059442393459904e-07}, {"id": 1251, "seek": 576270, "start": 5763.7, "end": 5764.66, "text": " That describes it.", "tokens": [50414, 663, 15626, 309, 13, 50462], "temperature": 0.0, "avg_logprob": -0.5071388132431928, "compression_ratio": 1.406060606060606, "no_speech_prob": 3.219170685042627e-05}, {"id": 1252, "seek": 576270, "start": 5767.38, "end": 5769.74, "text": " All right, you definitely get four points if you do that.", "tokens": [50598, 1057, 558, 11, 291, 2138, 483, 1451, 2793, 498, 291, 360, 300, 13, 50716], "temperature": 0.0, "avg_logprob": -0.5071388132431928, "compression_ratio": 1.406060606060606, "no_speech_prob": 3.219170685042627e-05}, {"id": 1253, "seek": 576270, "start": 5770.82, "end": 5773.34, "text": " We'll give you a number of points equal to the impact factor of the journal you", "tokens": [50770, 492, 603, 976, 291, 257, 1230, 295, 2793, 2681, 281, 264, 2712, 5952, 295, 264, 6708, 291, 50896], "temperature": 0.0, "avg_logprob": -0.5071388132431928, "compression_ratio": 1.406060606060606, "no_speech_prob": 3.219170685042627e-05}, {"id": 1254, "seek": 576270, "start": 5773.34, "end": 5774.0599999999995, "text": " get it published in.", "tokens": [50896, 483, 309, 6572, 294, 13, 50932], "temperature": 0.0, "avg_logprob": -0.5071388132431928, "compression_ratio": 1.406060606060606, "no_speech_prob": 3.219170685042627e-05}, {"id": 1255, "seek": 576270, "start": 5776.34, "end": 5776.86, "text": " Okay.", "tokens": [51046, 1033, 13, 51072], "temperature": 0.0, "avg_logprob": -0.5071388132431928, "compression_ratio": 1.406060606060606, "no_speech_prob": 3.219170685042627e-05}, {"id": 1256, "seek": 576270, "start": 5783.54, "end": 5789.78, "text": " So what I want to do now is move on to calculus.", "tokens": [51406, 407, 437, 286, 528, 281, 360, 586, 307, 1286, 322, 281, 33400, 13, 51718], "temperature": 0.0, "avg_logprob": -0.5071388132431928, "compression_ratio": 1.406060606060606, "no_speech_prob": 3.219170685042627e-05}, {"id": 1257, "seek": 578978, "start": 5790.74, "end": 5795.219999999999, "text": " Which for some of us may not be our favorite topic.", "tokens": [50412, 3013, 337, 512, 295, 505, 815, 406, 312, 527, 2954, 4829, 13, 50636], "temperature": 0.0, "avg_logprob": -0.46512975056966144, "compression_ratio": 1.3969072164948453, "no_speech_prob": 1.1841645573440474e-05}, {"id": 1258, "seek": 578978, "start": 5800.66, "end": 5803.34, "text": " That's funny, Stefano wrote the iron sum version here already,", "tokens": [50908, 663, 311, 4074, 11, 43421, 3730, 4114, 264, 6497, 2408, 3037, 510, 1217, 11, 51042], "temperature": 0.0, "avg_logprob": -0.46512975056966144, "compression_ratio": 1.3969072164948453, "no_speech_prob": 1.1841645573440474e-05}, {"id": 1259, "seek": 578978, "start": 5803.34, "end": 5804.259999999999, "text": " I didn't notice.", "tokens": [51042, 286, 994, 380, 3449, 13, 51088], "temperature": 0.0, "avg_logprob": -0.46512975056966144, "compression_ratio": 1.3969072164948453, "no_speech_prob": 1.1841645573440474e-05}, {"id": 1260, "seek": 578978, "start": 5804.259999999999, "end": 5806.82, "text": " Okay, always ahead of his time, that guy.", "tokens": [51088, 1033, 11, 1009, 2286, 295, 702, 565, 11, 300, 2146, 13, 51216], "temperature": 0.0, "avg_logprob": -0.46512975056966144, "compression_ratio": 1.3969072164948453, "no_speech_prob": 1.1841645573440474e-05}, {"id": 1261, "seek": 578978, "start": 5810.219999999999, "end": 5812.3, "text": " Let's talk about calculus.", "tokens": [51386, 961, 311, 751, 466, 33400, 13, 51490], "temperature": 0.0, "avg_logprob": -0.46512975056966144, "compression_ratio": 1.3969072164948453, "no_speech_prob": 1.1841645573440474e-05}, {"id": 1262, "seek": 578978, "start": 5812.3, "end": 5817.62, "text": " If you're not super comfortable with derivatives and what they are and", "tokens": [51490, 759, 291, 434, 406, 1687, 4619, 365, 33733, 293, 437, 436, 366, 293, 51756], "temperature": 0.0, "avg_logprob": -0.46512975056966144, "compression_ratio": 1.3969072164948453, "no_speech_prob": 1.1841645573440474e-05}, {"id": 1263, "seek": 581762, "start": 5817.9, "end": 5822.38, "text": " why we care, 3Blue1Brown has a wonderful series called", "tokens": [50378, 983, 321, 1127, 11, 805, 45231, 16, 22170, 648, 575, 257, 3715, 2638, 1219, 50602], "temperature": 0.0, "avg_logprob": -0.368406554799021, "compression_ratio": 1.4550264550264551, "no_speech_prob": 6.108838715590537e-05}, {"id": 1264, "seek": 581762, "start": 5822.38, "end": 5826.82, "text": " The Essence of Calculus, which I strongly recommend watching.", "tokens": [50602, 440, 14357, 655, 295, 3511, 36002, 11, 597, 286, 10613, 2748, 1976, 13, 50824], "temperature": 0.0, "avg_logprob": -0.368406554799021, "compression_ratio": 1.4550264550264551, "no_speech_prob": 6.108838715590537e-05}, {"id": 1265, "seek": 581762, "start": 5826.82, "end": 5830.099999999999, "text": " It's just a pleasure, actually, to watch,", "tokens": [50824, 467, 311, 445, 257, 6834, 11, 767, 11, 281, 1159, 11, 50988], "temperature": 0.0, "avg_logprob": -0.368406554799021, "compression_ratio": 1.4550264550264551, "no_speech_prob": 6.108838715590537e-05}, {"id": 1266, "seek": 581762, "start": 5830.099999999999, "end": 5834.14, "text": " as it's everything that is on 3Blue1Brown a pleasure to watch.", "tokens": [50988, 382, 309, 311, 1203, 300, 307, 322, 805, 45231, 16, 22170, 648, 257, 6834, 281, 1159, 13, 51190], "temperature": 0.0, "avg_logprob": -0.368406554799021, "compression_ratio": 1.4550264550264551, "no_speech_prob": 6.108838715590537e-05}, {"id": 1267, "seek": 581762, "start": 5837.86, "end": 5844.0199999999995, "text": " The, And so we're not gonna get into back prop today.", "tokens": [51376, 440, 11, 400, 370, 321, 434, 406, 799, 483, 666, 646, 2365, 965, 13, 51684], "temperature": 0.0, "avg_logprob": -0.368406554799021, "compression_ratio": 1.4550264550264551, "no_speech_prob": 6.108838715590537e-05}, {"id": 1268, "seek": 584402, "start": 5844.02, "end": 5848.740000000001, "text": " Instead we're just gonna have a quick chat about calculus.", "tokens": [50364, 7156, 321, 434, 445, 799, 362, 257, 1702, 5081, 466, 33400, 13, 50600], "temperature": 0.0, "avg_logprob": -0.34293874104817706, "compression_ratio": 1.5789473684210527, "no_speech_prob": 4.785094461112749e-06}, {"id": 1269, "seek": 584402, "start": 5856.740000000001, "end": 5857.540000000001, "text": " Where do we start?", "tokens": [51000, 2305, 360, 321, 722, 30, 51040], "temperature": 0.0, "avg_logprob": -0.34293874104817706, "compression_ratio": 1.5789473684210527, "no_speech_prob": 4.785094461112749e-06}, {"id": 1270, "seek": 584402, "start": 5859.34, "end": 5861.580000000001, "text": " So the good news is,", "tokens": [51130, 407, 264, 665, 2583, 307, 11, 51242], "temperature": 0.0, "avg_logprob": -0.34293874104817706, "compression_ratio": 1.5789473684210527, "no_speech_prob": 4.785094461112749e-06}, {"id": 1271, "seek": 584402, "start": 5861.580000000001, "end": 5864.780000000001, "text": " just like you don't have to know much linear algebra at all.", "tokens": [51242, 445, 411, 291, 500, 380, 362, 281, 458, 709, 8213, 21989, 412, 439, 13, 51402], "temperature": 0.0, "avg_logprob": -0.34293874104817706, "compression_ratio": 1.5789473684210527, "no_speech_prob": 4.785094461112749e-06}, {"id": 1272, "seek": 584402, "start": 5864.780000000001, "end": 5867.3, "text": " You basically just need to know about matrix multiplication.", "tokens": [51402, 509, 1936, 445, 643, 281, 458, 466, 8141, 27290, 13, 51528], "temperature": 0.0, "avg_logprob": -0.34293874104817706, "compression_ratio": 1.5789473684210527, "no_speech_prob": 4.785094461112749e-06}, {"id": 1273, "seek": 584402, "start": 5868.740000000001, "end": 5873.860000000001, "text": " You also don't need to know much calculus at all.", "tokens": [51600, 509, 611, 500, 380, 643, 281, 458, 709, 33400, 412, 439, 13, 51856], "temperature": 0.0, "avg_logprob": -0.34293874104817706, "compression_ratio": 1.5789473684210527, "no_speech_prob": 4.785094461112749e-06}, {"id": 1274, "seek": 587402, "start": 5875.02, "end": 5875.9800000000005, "text": " Just derivatives.", "tokens": [50414, 1449, 33733, 13, 50462], "temperature": 0.0, "avg_logprob": -0.4355845580229888, "compression_ratio": 1.4438202247191012, "no_speech_prob": 4.495177108765347e-06}, {"id": 1275, "seek": 587402, "start": 5877.38, "end": 5881.38, "text": " So let's think about what derivatives are.", "tokens": [50532, 407, 718, 311, 519, 466, 437, 33733, 366, 13, 50732], "temperature": 0.0, "avg_logprob": -0.4355845580229888, "compression_ratio": 1.4438202247191012, "no_speech_prob": 4.495177108765347e-06}, {"id": 1276, "seek": 587402, "start": 5882.46, "end": 5887.34, "text": " So I'm gonna borrow actually the same starting point that", "tokens": [50786, 407, 286, 478, 799, 11172, 767, 264, 912, 2891, 935, 300, 51030], "temperature": 0.0, "avg_logprob": -0.4355845580229888, "compression_ratio": 1.4438202247191012, "no_speech_prob": 4.495177108765347e-06}, {"id": 1277, "seek": 587402, "start": 5887.34, "end": 5890.660000000001, "text": " 3Blue1Brown uses in one of their videos, it's to consider a car.", "tokens": [51030, 805, 45231, 16, 22170, 648, 4960, 294, 472, 295, 641, 2145, 11, 309, 311, 281, 1949, 257, 1032, 13, 51196], "temperature": 0.0, "avg_logprob": -0.4355845580229888, "compression_ratio": 1.4438202247191012, "no_speech_prob": 4.495177108765347e-06}, {"id": 1278, "seek": 587402, "start": 5891.9400000000005, "end": 5895.18, "text": " And we're gonna see how far away from home it is.", "tokens": [51260, 400, 321, 434, 799, 536, 577, 1400, 1314, 490, 1280, 309, 307, 13, 51422], "temperature": 0.0, "avg_logprob": -0.4355845580229888, "compression_ratio": 1.4438202247191012, "no_speech_prob": 4.495177108765347e-06}, {"id": 1279, "seek": 587402, "start": 5898.22, "end": 5899.700000000001, "text": " At various time points.", "tokens": [51574, 1711, 3683, 565, 2793, 13, 51648], "temperature": 0.0, "avg_logprob": -0.4355845580229888, "compression_ratio": 1.4438202247191012, "no_speech_prob": 4.495177108765347e-06}, {"id": 1280, "seek": 589970, "start": 5900.42, "end": 5906.98, "text": " Okay, so after a minute, let's say after a second.", "tokens": [50400, 1033, 11, 370, 934, 257, 3456, 11, 718, 311, 584, 934, 257, 1150, 13, 50728], "temperature": 0.0, "avg_logprob": -0.6169027328491211, "compression_ratio": 1.358695652173913, "no_speech_prob": 1.0511486152608995e-06}, {"id": 1281, "seek": 589970, "start": 5910.62, "end": 5913.179999999999, "text": " It's traveled 5 meters.", "tokens": [50910, 467, 311, 16147, 1025, 8146, 13, 51038], "temperature": 0.0, "avg_logprob": -0.6169027328491211, "compression_ratio": 1.358695652173913, "no_speech_prob": 1.0511486152608995e-06}, {"id": 1282, "seek": 589970, "start": 5917.26, "end": 5923.54, "text": " And then after 2 seconds, It's traveled 10 meters.", "tokens": [51242, 400, 550, 934, 568, 3949, 11, 467, 311, 16147, 1266, 8146, 13, 51556], "temperature": 0.0, "avg_logprob": -0.6169027328491211, "compression_ratio": 1.358695652173913, "no_speech_prob": 1.0511486152608995e-06}, {"id": 1283, "seek": 592354, "start": 5924.54, "end": 5929.9, "text": " Okay, and after 3 seconds, you can probably guess, it's traveled 15 meters.", "tokens": [50414, 1033, 11, 293, 934, 805, 3949, 11, 291, 393, 1391, 2041, 11, 309, 311, 16147, 2119, 8146, 13, 50682], "temperature": 0.0, "avg_logprob": -0.6332831573486328, "compression_ratio": 1.2727272727272727, "no_speech_prob": 6.9622465161955915e-06}, {"id": 1284, "seek": 592354, "start": 5933.9, "end": 5937.38, "text": " So there's this concept here of,", "tokens": [50882, 407, 456, 311, 341, 3410, 510, 295, 11, 51056], "temperature": 0.0, "avg_logprob": -0.6332831573486328, "compression_ratio": 1.2727272727272727, "no_speech_prob": 6.9622465161955915e-06}, {"id": 1285, "seek": 592354, "start": 5937.38, "end": 5944.06, "text": " got it the wrong way around, obviously.", "tokens": [51056, 658, 309, 264, 2085, 636, 926, 11, 2745, 13, 51390], "temperature": 0.0, "avg_logprob": -0.6332831573486328, "compression_ratio": 1.2727272727272727, "no_speech_prob": 6.9622465161955915e-06}, {"id": 1286, "seek": 592354, "start": 5946.06, "end": 5951.86, "text": " So, time, distance.", "tokens": [51490, 407, 11, 565, 11, 4560, 13, 51780], "temperature": 0.0, "avg_logprob": -0.6332831573486328, "compression_ratio": 1.2727272727272727, "no_speech_prob": 6.9622465161955915e-06}, {"id": 1287, "seek": 595354, "start": 5954.54, "end": 5963.78, "text": " Okay, so there's this concept of, yeah, of like location.", "tokens": [50414, 1033, 11, 370, 456, 311, 341, 3410, 295, 11, 1338, 11, 295, 411, 4914, 13, 50876], "temperature": 0.0, "avg_logprob": -0.3624710603193803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 1.2407294889271725e-05}, {"id": 1288, "seek": 595354, "start": 5963.78, "end": 5968.42, "text": " It's like how far have you traveled at a particular point in time.", "tokens": [50876, 467, 311, 411, 577, 1400, 362, 291, 16147, 412, 257, 1729, 935, 294, 565, 13, 51108], "temperature": 0.0, "avg_logprob": -0.3624710603193803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 1.2407294889271725e-05}, {"id": 1289, "seek": 595354, "start": 5968.42, "end": 5973.78, "text": " So we can look at one of these points and find out how far that car has gone.", "tokens": [51108, 407, 321, 393, 574, 412, 472, 295, 613, 2793, 293, 915, 484, 577, 1400, 300, 1032, 575, 2780, 13, 51376], "temperature": 0.0, "avg_logprob": -0.3624710603193803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 1.2407294889271725e-05}, {"id": 1290, "seek": 595354, "start": 5976.58, "end": 5979.42, "text": " We could also take two points.", "tokens": [51516, 492, 727, 611, 747, 732, 2793, 13, 51658], "temperature": 0.0, "avg_logprob": -0.3624710603193803, "compression_ratio": 1.4472049689440993, "no_speech_prob": 1.2407294889271725e-05}, {"id": 1291, "seek": 597942, "start": 5979.78, "end": 5985.46, "text": " And we can say, where did it start at the start of those two points?", "tokens": [50382, 400, 321, 393, 584, 11, 689, 630, 309, 722, 412, 264, 722, 295, 729, 732, 2793, 30, 50666], "temperature": 0.0, "avg_logprob": -0.3874938067267923, "compression_ratio": 1.7647058823529411, "no_speech_prob": 6.893596946611069e-07}, {"id": 1292, "seek": 597942, "start": 5986.54, "end": 5989.3, "text": " And where did it finish at the end of those two points?", "tokens": [50720, 400, 689, 630, 309, 2413, 412, 264, 917, 295, 729, 732, 2793, 30, 50858], "temperature": 0.0, "avg_logprob": -0.3874938067267923, "compression_ratio": 1.7647058823529411, "no_speech_prob": 6.893596946611069e-07}, {"id": 1293, "seek": 597942, "start": 5991.66, "end": 5994.66, "text": " And we can say between those two points, how much time passed?", "tokens": [50976, 400, 321, 393, 584, 1296, 729, 732, 2793, 11, 577, 709, 565, 4678, 30, 51126], "temperature": 0.0, "avg_logprob": -0.3874938067267923, "compression_ratio": 1.7647058823529411, "no_speech_prob": 6.893596946611069e-07}, {"id": 1294, "seek": 597942, "start": 5996.58, "end": 5998.22, "text": " And how far did they travel?", "tokens": [51222, 400, 577, 1400, 630, 436, 3147, 30, 51304], "temperature": 0.0, "avg_logprob": -0.3874938067267923, "compression_ratio": 1.7647058823529411, "no_speech_prob": 6.893596946611069e-07}, {"id": 1295, "seek": 597942, "start": 5998.22, "end": 6002.9400000000005, "text": " In two seconds, they traveled 10 meters.", "tokens": [51304, 682, 732, 3949, 11, 436, 16147, 1266, 8146, 13, 51540], "temperature": 0.0, "avg_logprob": -0.3874938067267923, "compression_ratio": 1.7647058823529411, "no_speech_prob": 6.893596946611069e-07}, {"id": 1296, "seek": 597942, "start": 6005.02, "end": 6008.34, "text": " So we could now also say, all right, well,", "tokens": [51644, 407, 321, 727, 586, 611, 584, 11, 439, 558, 11, 731, 11, 51810], "temperature": 0.0, "avg_logprob": -0.3874938067267923, "compression_ratio": 1.7647058823529411, "no_speech_prob": 6.893596946611069e-07}, {"id": 1297, "seek": 600942, "start": 6010.18, "end": 6015.22, "text": " The slope of something is rise over run.", "tokens": [50402, 440, 13525, 295, 746, 307, 6272, 670, 1190, 13, 50654], "temperature": 0.0, "avg_logprob": -0.4643789927164714, "compression_ratio": 1.3111111111111111, "no_speech_prob": 2.1691704432669212e-07}, {"id": 1298, "seek": 600942, "start": 6018.46, "end": 6019.3, "text": " Oopsie daisy.", "tokens": [50816, 21726, 414, 1120, 14169, 13, 50858], "temperature": 0.0, "avg_logprob": -0.4643789927164714, "compression_ratio": 1.3111111111111111, "no_speech_prob": 2.1691704432669212e-07}, {"id": 1299, "seek": 600942, "start": 6022.3, "end": 6028.14, "text": " 10 meters in 2 seconds.", "tokens": [51008, 1266, 8146, 294, 568, 3949, 13, 51300], "temperature": 0.0, "avg_logprob": -0.4643789927164714, "compression_ratio": 1.3111111111111111, "no_speech_prob": 2.1691704432669212e-07}, {"id": 1300, "seek": 600942, "start": 6028.14, "end": 6032.14, "text": " And notice we don't just divide the numbers, we also divide the units.", "tokens": [51300, 400, 3449, 321, 500, 380, 445, 9845, 264, 3547, 11, 321, 611, 9845, 264, 6815, 13, 51500], "temperature": 0.0, "avg_logprob": -0.4643789927164714, "compression_ratio": 1.3111111111111111, "no_speech_prob": 2.1691704432669212e-07}, {"id": 1301, "seek": 600942, "start": 6032.14, "end": 6036.5, "text": " We get 5 meters per second.", "tokens": [51500, 492, 483, 1025, 8146, 680, 1150, 13, 51718], "temperature": 0.0, "avg_logprob": -0.4643789927164714, "compression_ratio": 1.3111111111111111, "no_speech_prob": 2.1691704432669212e-07}, {"id": 1302, "seek": 603942, "start": 6040.42, "end": 6046.06, "text": " So this here has now changed the dimensions entirely.", "tokens": [50414, 407, 341, 510, 575, 586, 3105, 264, 12819, 7696, 13, 50696], "temperature": 0.0, "avg_logprob": -0.3633498451926491, "compression_ratio": 1.4444444444444444, "no_speech_prob": 6.412059150306959e-08}, {"id": 1303, "seek": 603942, "start": 6046.06, "end": 6050.54, "text": " We're now not looking at distance, but we're looking at speed or velocity.", "tokens": [50696, 492, 434, 586, 406, 1237, 412, 4560, 11, 457, 321, 434, 1237, 412, 3073, 420, 9269, 13, 50920], "temperature": 0.0, "avg_logprob": -0.3633498451926491, "compression_ratio": 1.4444444444444444, "no_speech_prob": 6.412059150306959e-08}, {"id": 1304, "seek": 603942, "start": 6052.74, "end": 6057.02, "text": " And it's equal to rise over run.", "tokens": [51030, 400, 309, 311, 2681, 281, 6272, 670, 1190, 13, 51244], "temperature": 0.0, "avg_logprob": -0.3633498451926491, "compression_ratio": 1.4444444444444444, "no_speech_prob": 6.412059150306959e-08}, {"id": 1305, "seek": 603942, "start": 6057.02, "end": 6060.5, "text": " It's equal to the rate of change.", "tokens": [51244, 467, 311, 2681, 281, 264, 3314, 295, 1319, 13, 51418], "temperature": 0.0, "avg_logprob": -0.3633498451926491, "compression_ratio": 1.4444444444444444, "no_speech_prob": 6.412059150306959e-08}, {"id": 1306, "seek": 606050, "start": 6060.5, "end": 6065.78, "text": " And what it says really is,", "tokens": [50364, 400, 437, 309, 1619, 534, 307, 11, 50628], "temperature": 0.0, "avg_logprob": -0.6793478675510572, "compression_ratio": 1.2912621359223302, "no_speech_prob": 2.9480156626959797e-06}, {"id": 1307, "seek": 606050, "start": 6065.78, "end": 6070.42, "text": " as time, the x-axis,", "tokens": [50628, 382, 565, 11, 264, 2031, 12, 24633, 11, 50860], "temperature": 0.0, "avg_logprob": -0.6793478675510572, "compression_ratio": 1.2912621359223302, "no_speech_prob": 2.9480156626959797e-06}, {"id": 1308, "seek": 606050, "start": 6070.42, "end": 6074.7, "text": " goes up by one second,", "tokens": [50860, 1709, 493, 538, 472, 1150, 11, 51074], "temperature": 0.0, "avg_logprob": -0.6793478675510572, "compression_ratio": 1.2912621359223302, "no_speech_prob": 2.9480156626959797e-06}, {"id": 1309, "seek": 606050, "start": 6074.7, "end": 6079.3, "text": " what happens to the distance in meters?", "tokens": [51074, 437, 2314, 281, 264, 4560, 294, 8146, 30, 51304], "temperature": 0.0, "avg_logprob": -0.6793478675510572, "compression_ratio": 1.2912621359223302, "no_speech_prob": 2.9480156626959797e-06}, {"id": 1310, "seek": 606050, "start": 6081.82, "end": 6083.62, "text": " As one second passes,", "tokens": [51430, 1018, 472, 1150, 11335, 11, 51520], "temperature": 0.0, "avg_logprob": -0.6793478675510572, "compression_ratio": 1.2912621359223302, "no_speech_prob": 2.9480156626959797e-06}, {"id": 1311, "seek": 608362, "start": 6083.62, "end": 6093.42, "text": " How does the number of meters change?", "tokens": [50364, 1012, 775, 264, 1230, 295, 8146, 1319, 30, 50854], "temperature": 0.0, "avg_logprob": -0.35375234484672546, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.7479912862181664e-07}, {"id": 1312, "seek": 608362, "start": 6096.5, "end": 6099.42, "text": " And so maybe these aren't points at all, maybe there's a function.", "tokens": [51008, 400, 370, 1310, 613, 3212, 380, 2793, 412, 439, 11, 1310, 456, 311, 257, 2445, 13, 51154], "temperature": 0.0, "avg_logprob": -0.35375234484672546, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.7479912862181664e-07}, {"id": 1313, "seek": 608362, "start": 6102.58, "end": 6104.9, "text": " Right, it's a continuum of points.", "tokens": [51312, 1779, 11, 309, 311, 257, 36120, 295, 2793, 13, 51428], "temperature": 0.0, "avg_logprob": -0.35375234484672546, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.7479912862181664e-07}, {"id": 1314, "seek": 608362, "start": 6104.9, "end": 6106.62, "text": " And so you can do that for the function.", "tokens": [51428, 400, 370, 291, 393, 360, 300, 337, 264, 2445, 13, 51514], "temperature": 0.0, "avg_logprob": -0.35375234484672546, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.7479912862181664e-07}, {"id": 1315, "seek": 608362, "start": 6107.74, "end": 6112.5, "text": " So the function is a function of time.", "tokens": [51570, 407, 264, 2445, 307, 257, 2445, 295, 565, 13, 51808], "temperature": 0.0, "avg_logprob": -0.35375234484672546, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.7479912862181664e-07}, {"id": 1316, "seek": 611250, "start": 6112.5, "end": 6114.02, "text": " Distance is a function of time.", "tokens": [50364, 9840, 719, 307, 257, 2445, 295, 565, 13, 50440], "temperature": 0.0, "avg_logprob": -0.33555689454078674, "compression_ratio": 1.4647887323943662, "no_speech_prob": 1.154461983787769e-06}, {"id": 1317, "seek": 611250, "start": 6116.22, "end": 6119.74, "text": " And so we could say, what's the slope of that function?", "tokens": [50550, 400, 370, 321, 727, 584, 11, 437, 311, 264, 13525, 295, 300, 2445, 30, 50726], "temperature": 0.0, "avg_logprob": -0.33555689454078674, "compression_ratio": 1.4647887323943662, "no_speech_prob": 1.154461983787769e-06}, {"id": 1318, "seek": 611250, "start": 6121.34, "end": 6126.42, "text": " And we can get the slope from point A to point B using rise over run.", "tokens": [50806, 400, 321, 393, 483, 264, 13525, 490, 935, 316, 281, 935, 363, 1228, 6272, 670, 1190, 13, 51060], "temperature": 0.0, "avg_logprob": -0.33555689454078674, "compression_ratio": 1.4647887323943662, "no_speech_prob": 1.154461983787769e-06}, {"id": 1319, "seek": 611250, "start": 6128.06, "end": 6135.26, "text": " So from t1 to t2, the amount of time that's passed", "tokens": [51142, 407, 490, 256, 16, 281, 256, 17, 11, 264, 2372, 295, 565, 300, 311, 4678, 51502], "temperature": 0.0, "avg_logprob": -0.33555689454078674, "compression_ratio": 1.4647887323943662, "no_speech_prob": 1.154461983787769e-06}, {"id": 1320, "seek": 613526, "start": 6135.26, "end": 6144.66, "text": " Is t2 minus t1, that's how much time has passed.", "tokens": [50364, 1119, 256, 17, 3175, 256, 16, 11, 300, 311, 577, 709, 565, 575, 4678, 13, 50834], "temperature": 0.0, "avg_logprob": -0.426950924213116, "compression_ratio": 1.5474452554744527, "no_speech_prob": 8.939689905673731e-06}, {"id": 1321, "seek": 613526, "start": 6144.66, "end": 6147.34, "text": " Let's say this is t1, this is t2.", "tokens": [50834, 961, 311, 584, 341, 307, 256, 16, 11, 341, 307, 256, 17, 13, 50968], "temperature": 0.0, "avg_logprob": -0.426950924213116, "compression_ratio": 1.5474452554744527, "no_speech_prob": 8.939689905673731e-06}, {"id": 1322, "seek": 613526, "start": 6149.46, "end": 6153.54, "text": " And the distance that they've traveled, well, they've moved from", "tokens": [51074, 400, 264, 4560, 300, 436, 600, 16147, 11, 731, 11, 436, 600, 4259, 490, 51278], "temperature": 0.0, "avg_logprob": -0.426950924213116, "compression_ratio": 1.5474452554744527, "no_speech_prob": 8.939689905673731e-06}, {"id": 1323, "seek": 613526, "start": 6157.900000000001, "end": 6163.34, "text": " Wherever they are at the end to wherever they were at the start.", "tokens": [51496, 30903, 436, 366, 412, 264, 917, 281, 8660, 436, 645, 412, 264, 722, 13, 51768], "temperature": 0.0, "avg_logprob": -0.426950924213116, "compression_ratio": 1.5474452554744527, "no_speech_prob": 8.939689905673731e-06}, {"id": 1324, "seek": 616526, "start": 6166.26, "end": 6169.22, "text": " So that's the change in distance divided by the change in time.", "tokens": [50414, 407, 300, 311, 264, 1319, 294, 4560, 6666, 538, 264, 1319, 294, 565, 13, 50562], "temperature": 0.0, "avg_logprob": -0.4272471341219815, "compression_ratio": 1.6962962962962962, "no_speech_prob": 4.338617642929421e-08}, {"id": 1325, "seek": 616526, "start": 6170.66, "end": 6174.42, "text": " Change in distance divided by change in time.", "tokens": [50634, 15060, 294, 4560, 6666, 538, 1319, 294, 565, 13, 50822], "temperature": 0.0, "avg_logprob": -0.4272471341219815, "compression_ratio": 1.6962962962962962, "no_speech_prob": 4.338617642929421e-08}, {"id": 1326, "seek": 616526, "start": 6178.06, "end": 6181.780000000001, "text": " Okay, let's say that's y.", "tokens": [51004, 1033, 11, 718, 311, 584, 300, 311, 288, 13, 51190], "temperature": 0.0, "avg_logprob": -0.4272471341219815, "compression_ratio": 1.6962962962962962, "no_speech_prob": 4.338617642929421e-08}, {"id": 1327, "seek": 616526, "start": 6183.9400000000005, "end": 6187.9800000000005, "text": " So another way, now the thing is,", "tokens": [51298, 407, 1071, 636, 11, 586, 264, 551, 307, 11, 51500], "temperature": 0.0, "avg_logprob": -0.4272471341219815, "compression_ratio": 1.6962962962962962, "no_speech_prob": 4.338617642929421e-08}, {"id": 1328, "seek": 616526, "start": 6187.9800000000005, "end": 6191.42, "text": " when we talk about calculus, we talk about finding a slope.", "tokens": [51500, 562, 321, 751, 466, 33400, 11, 321, 751, 466, 5006, 257, 13525, 13, 51672], "temperature": 0.0, "avg_logprob": -0.4272471341219815, "compression_ratio": 1.6962962962962962, "no_speech_prob": 4.338617642929421e-08}, {"id": 1329, "seek": 619142, "start": 6192.42, "end": 6196.46, "text": " But we talk about finding a slope of something", "tokens": [50414, 583, 321, 751, 466, 5006, 257, 13525, 295, 746, 50616], "temperature": 0.0, "avg_logprob": -0.5243080436409294, "compression_ratio": 1.4293785310734464, "no_speech_prob": 8.315280410897685e-07}, {"id": 1330, "seek": 619142, "start": 6198.9400000000005, "end": 6201.54, "text": " That's often more tricky than this, right?", "tokens": [50740, 663, 311, 2049, 544, 12414, 813, 341, 11, 558, 30, 50870], "temperature": 0.0, "avg_logprob": -0.5243080436409294, "compression_ratio": 1.4293785310734464, "no_speech_prob": 8.315280410897685e-07}, {"id": 1331, "seek": 619142, "start": 6201.54, "end": 6205.34, "text": " We have slopes of things", "tokens": [50870, 492, 362, 37725, 295, 721, 51060], "temperature": 0.0, "avg_logprob": -0.5243080436409294, "compression_ratio": 1.4293785310734464, "no_speech_prob": 8.315280410897685e-07}, {"id": 1332, "seek": 619142, "start": 6209.22, "end": 6210.78, "text": " That look more like this.", "tokens": [51254, 663, 574, 544, 411, 341, 13, 51332], "temperature": 0.0, "avg_logprob": -0.5243080436409294, "compression_ratio": 1.4293785310734464, "no_speech_prob": 8.315280410897685e-07}, {"id": 1333, "seek": 619142, "start": 6210.78, "end": 6216.02, "text": " And we say, what's this slope?", "tokens": [51332, 400, 321, 584, 11, 437, 311, 341, 13525, 30, 51594], "temperature": 0.0, "avg_logprob": -0.5243080436409294, "compression_ratio": 1.4293785310734464, "no_speech_prob": 8.315280410897685e-07}, {"id": 1334, "seek": 619142, "start": 6216.02, "end": 6217.82, "text": " Oops, I'm terrible at drawing.", "tokens": [51594, 21726, 11, 286, 478, 6237, 412, 6316, 13, 51684], "temperature": 0.0, "avg_logprob": -0.5243080436409294, "compression_ratio": 1.4293785310734464, "no_speech_prob": 8.315280410897685e-07}, {"id": 1335, "seek": 619142, "start": 6217.82, "end": 6220.82, "text": " Let's maybe put it over here, cuz I'm left handed.", "tokens": [51684, 961, 311, 1310, 829, 309, 670, 510, 11, 11910, 286, 478, 1411, 16013, 13, 51834], "temperature": 0.0, "avg_logprob": -0.5243080436409294, "compression_ratio": 1.4293785310734464, "no_speech_prob": 8.315280410897685e-07}, {"id": 1336, "seek": 622082, "start": 6220.86, "end": 6222.94, "text": " What's this slope?", "tokens": [50366, 708, 311, 341, 13525, 30, 50470], "temperature": 0.0, "avg_logprob": -0.367133983667346, "compression_ratio": 1.4899328859060403, "no_speech_prob": 7.453768944287731e-07}, {"id": 1337, "seek": 622082, "start": 6226.94, "end": 6232.0199999999995, "text": " Now, what does it mean to have the idea of", "tokens": [50670, 823, 11, 437, 775, 309, 914, 281, 362, 264, 1558, 295, 50924], "temperature": 0.0, "avg_logprob": -0.367133983667346, "compression_ratio": 1.4899328859060403, "no_speech_prob": 7.453768944287731e-07}, {"id": 1338, "seek": 622082, "start": 6232.0199999999995, "end": 6236.66, "text": " a velocity at an exact moment in time?", "tokens": [50924, 257, 9269, 412, 364, 1900, 1623, 294, 565, 30, 51156], "temperature": 0.0, "avg_logprob": -0.367133983667346, "compression_ratio": 1.4899328859060403, "no_speech_prob": 7.453768944287731e-07}, {"id": 1339, "seek": 622082, "start": 6238.259999999999, "end": 6239.179999999999, "text": " It doesn't mean anything.", "tokens": [51236, 467, 1177, 380, 914, 1340, 13, 51282], "temperature": 0.0, "avg_logprob": -0.367133983667346, "compression_ratio": 1.4899328859060403, "no_speech_prob": 7.453768944287731e-07}, {"id": 1340, "seek": 622082, "start": 6240.58, "end": 6245.38, "text": " At an exact moment in time, you're just like, it's frozen, right?", "tokens": [51352, 1711, 364, 1900, 1623, 294, 565, 11, 291, 434, 445, 411, 11, 309, 311, 12496, 11, 558, 30, 51592], "temperature": 0.0, "avg_logprob": -0.367133983667346, "compression_ratio": 1.4899328859060403, "no_speech_prob": 7.453768944287731e-07}, {"id": 1341, "seek": 622082, "start": 6245.38, "end": 6247.34, "text": " What's happening exactly now?", "tokens": [51592, 708, 311, 2737, 2293, 586, 30, 51690], "temperature": 0.0, "avg_logprob": -0.367133983667346, "compression_ratio": 1.4899328859060403, "no_speech_prob": 7.453768944287731e-07}, {"id": 1342, "seek": 624734, "start": 6247.34, "end": 6250.26, "text": " But what you can do is you can say, well,", "tokens": [50364, 583, 437, 291, 393, 360, 307, 291, 393, 584, 11, 731, 11, 50510], "temperature": 0.0, "avg_logprob": -0.22291154572457977, "compression_ratio": 2.1169590643274856, "no_speech_prob": 2.616520475839934e-07}, {"id": 1343, "seek": 624734, "start": 6250.26, "end": 6255.62, "text": " what's the change in time between a bit before our point and a bit after our point?", "tokens": [50510, 437, 311, 264, 1319, 294, 565, 1296, 257, 857, 949, 527, 935, 293, 257, 857, 934, 527, 935, 30, 50778], "temperature": 0.0, "avg_logprob": -0.22291154572457977, "compression_ratio": 2.1169590643274856, "no_speech_prob": 2.616520475839934e-07}, {"id": 1344, "seek": 624734, "start": 6255.62, "end": 6258.54, "text": " And what's the change in distance between a bit before our point and", "tokens": [50778, 400, 437, 311, 264, 1319, 294, 4560, 1296, 257, 857, 949, 527, 935, 293, 50924], "temperature": 0.0, "avg_logprob": -0.22291154572457977, "compression_ratio": 2.1169590643274856, "no_speech_prob": 2.616520475839934e-07}, {"id": 1345, "seek": 624734, "start": 6258.54, "end": 6260.1, "text": " a bit after our point?", "tokens": [50924, 257, 857, 934, 527, 935, 30, 51002], "temperature": 0.0, "avg_logprob": -0.22291154572457977, "compression_ratio": 2.1169590643274856, "no_speech_prob": 2.616520475839934e-07}, {"id": 1346, "seek": 624734, "start": 6260.1, "end": 6263.900000000001, "text": " And so you can do the same kind of rise over run thing, right?", "tokens": [51002, 400, 370, 291, 393, 360, 264, 912, 733, 295, 6272, 670, 1190, 551, 11, 558, 30, 51192], "temperature": 0.0, "avg_logprob": -0.22291154572457977, "compression_ratio": 2.1169590643274856, "no_speech_prob": 2.616520475839934e-07}, {"id": 1347, "seek": 624734, "start": 6265.9400000000005, "end": 6274.82, "text": " But you can make that distance between t2 and t1 smaller and smaller and smaller.", "tokens": [51294, 583, 291, 393, 652, 300, 4560, 1296, 256, 17, 293, 256, 16, 4356, 293, 4356, 293, 4356, 13, 51738], "temperature": 0.0, "avg_logprob": -0.22291154572457977, "compression_ratio": 2.1169590643274856, "no_speech_prob": 2.616520475839934e-07}, {"id": 1348, "seek": 627482, "start": 6274.82, "end": 6279.58, "text": " So let's rewrite this in a slightly different way.", "tokens": [50364, 407, 718, 311, 28132, 341, 294, 257, 4748, 819, 636, 13, 50602], "temperature": 0.0, "avg_logprob": -0.3436947686331613, "compression_ratio": 1.4609929078014185, "no_speech_prob": 2.2033309221569652e-07}, {"id": 1349, "seek": 627482, "start": 6280.78, "end": 6290.58, "text": " Let's call the denominator the distance between t1 plus a little bit.", "tokens": [50662, 961, 311, 818, 264, 20687, 264, 4560, 1296, 256, 16, 1804, 257, 707, 857, 13, 51152], "temperature": 0.0, "avg_logprob": -0.3436947686331613, "compression_ratio": 1.4609929078014185, "no_speech_prob": 2.2033309221569652e-07}, {"id": 1350, "seek": 627482, "start": 6290.58, "end": 6292.62, "text": " We'll call it d.", "tokens": [51152, 492, 603, 818, 309, 274, 13, 51254], "temperature": 0.0, "avg_logprob": -0.3436947686331613, "compression_ratio": 1.4609929078014185, "no_speech_prob": 2.2033309221569652e-07}, {"id": 1351, "seek": 627482, "start": 6294.94, "end": 6299.9, "text": " It's that minus t1.", "tokens": [51370, 467, 311, 300, 3175, 256, 16, 13, 51618], "temperature": 0.0, "avg_logprob": -0.3436947686331613, "compression_ratio": 1.4609929078014185, "no_speech_prob": 2.2033309221569652e-07}, {"id": 1352, "seek": 627482, "start": 6299.9, "end": 6301.9, "text": " So this is t2, right?", "tokens": [51618, 407, 341, 307, 256, 17, 11, 558, 30, 51718], "temperature": 0.0, "avg_logprob": -0.3436947686331613, "compression_ratio": 1.4609929078014185, "no_speech_prob": 2.2033309221569652e-07}, {"id": 1353, "seek": 627482, "start": 6301.9, "end": 6303.54, "text": " It's t1 plus a little bit.", "tokens": [51718, 467, 311, 256, 16, 1804, 257, 707, 857, 13, 51800], "temperature": 0.0, "avg_logprob": -0.3436947686331613, "compression_ratio": 1.4609929078014185, "no_speech_prob": 2.2033309221569652e-07}, {"id": 1354, "seek": 630354, "start": 6303.54, "end": 6306.38, "text": " So we say, here's t1, let's add a little bit.", "tokens": [50364, 407, 321, 584, 11, 510, 311, 256, 16, 11, 718, 311, 909, 257, 707, 857, 13, 50506], "temperature": 0.0, "avg_logprob": -0.3114799839435237, "compression_ratio": 1.687150837988827, "no_speech_prob": 3.7266386243572924e-06}, {"id": 1355, "seek": 630354, "start": 6307.78, "end": 6309.66, "text": " And notice that when we write it this, well,", "tokens": [50576, 400, 3449, 300, 562, 321, 2464, 309, 341, 11, 731, 11, 50670], "temperature": 0.0, "avg_logprob": -0.3114799839435237, "compression_ratio": 1.687150837988827, "no_speech_prob": 3.7266386243572924e-06}, {"id": 1356, "seek": 630354, "start": 6309.66, "end": 6310.94, "text": " let's actually let's do the rest of it.", "tokens": [50670, 718, 311, 767, 718, 311, 360, 264, 1472, 295, 309, 13, 50734], "temperature": 0.0, "avg_logprob": -0.3114799839435237, "compression_ratio": 1.687150837988827, "no_speech_prob": 3.7266386243572924e-06}, {"id": 1357, "seek": 630354, "start": 6310.94, "end": 6316.54, "text": " So now f of t2 becomes f of t1 plus a little bit.", "tokens": [50734, 407, 586, 283, 295, 256, 17, 3643, 283, 295, 256, 16, 1804, 257, 707, 857, 13, 51014], "temperature": 0.0, "avg_logprob": -0.3114799839435237, "compression_ratio": 1.687150837988827, "no_speech_prob": 3.7266386243572924e-06}, {"id": 1358, "seek": 630354, "start": 6318.74, "end": 6319.78, "text": " And this is the same.", "tokens": [51124, 400, 341, 307, 264, 912, 13, 51176], "temperature": 0.0, "avg_logprob": -0.3114799839435237, "compression_ratio": 1.687150837988827, "no_speech_prob": 3.7266386243572924e-06}, {"id": 1359, "seek": 630354, "start": 6323.22, "end": 6327.5, "text": " And now notice here that t1 plus d minus t1,", "tokens": [51348, 400, 586, 3449, 510, 300, 256, 16, 1804, 274, 3175, 256, 16, 11, 51562], "temperature": 0.0, "avg_logprob": -0.3114799839435237, "compression_ratio": 1.687150837988827, "no_speech_prob": 3.7266386243572924e-06}, {"id": 1360, "seek": 630354, "start": 6327.5, "end": 6332.82, "text": " we can delete all that because it just comes out to d.", "tokens": [51562, 321, 393, 12097, 439, 300, 570, 309, 445, 1487, 484, 281, 274, 13, 51828], "temperature": 0.0, "avg_logprob": -0.3114799839435237, "compression_ratio": 1.687150837988827, "no_speech_prob": 3.7266386243572924e-06}, {"id": 1361, "seek": 633354, "start": 6334.06, "end": 6339.06, "text": " So this is another way of calculating the slope of our function.", "tokens": [50390, 407, 341, 307, 1071, 636, 295, 28258, 264, 13525, 295, 527, 2445, 13, 50640], "temperature": 0.0, "avg_logprob": -0.2827337004921653, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.97993706669331e-08}, {"id": 1362, "seek": 633354, "start": 6341.42, "end": 6344.86, "text": " And as d gets smaller and smaller and smaller,", "tokens": [50758, 400, 382, 274, 2170, 4356, 293, 4356, 293, 4356, 11, 50930], "temperature": 0.0, "avg_logprob": -0.2827337004921653, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.97993706669331e-08}, {"id": 1363, "seek": 633354, "start": 6344.86, "end": 6348.7, "text": " we're kind of getting a triangle that's tinier and tinier and tinier.", "tokens": [50930, 321, 434, 733, 295, 1242, 257, 13369, 300, 311, 15935, 811, 293, 15935, 811, 293, 15935, 811, 13, 51122], "temperature": 0.0, "avg_logprob": -0.2827337004921653, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.97993706669331e-08}, {"id": 1364, "seek": 633354, "start": 6348.7, "end": 6353.5, "text": " And it still makes sense, it's still that some time has passed and", "tokens": [51122, 400, 309, 920, 1669, 2020, 11, 309, 311, 920, 300, 512, 565, 575, 4678, 293, 51362], "temperature": 0.0, "avg_logprob": -0.2827337004921653, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.97993706669331e-08}, {"id": 1365, "seek": 633354, "start": 6353.5, "end": 6357.22, "text": " the car has moved, right?", "tokens": [51362, 264, 1032, 575, 4259, 11, 558, 30, 51548], "temperature": 0.0, "avg_logprob": -0.2827337004921653, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.97993706669331e-08}, {"id": 1366, "seek": 633354, "start": 6357.22, "end": 6358.98, "text": " But it's just smaller and smaller amounts of time.", "tokens": [51548, 583, 309, 311, 445, 4356, 293, 4356, 11663, 295, 565, 13, 51636], "temperature": 0.0, "avg_logprob": -0.2827337004921653, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.97993706669331e-08}, {"id": 1367, "seek": 635898, "start": 6359.98, "end": 6364.179999999999, "text": " Now if you did calculus at college or at school,", "tokens": [50414, 823, 498, 291, 630, 33400, 412, 3859, 420, 412, 1395, 11, 50624], "temperature": 0.0, "avg_logprob": -0.47130225686465993, "compression_ratio": 1.4853801169590644, "no_speech_prob": 8.579235100114602e-07}, {"id": 1368, "seek": 635898, "start": 6364.179999999999, "end": 6369.66, "text": " you might have done all this stuff messing around with limits and", "tokens": [50624, 291, 1062, 362, 1096, 439, 341, 1507, 23258, 926, 365, 10406, 293, 50898], "temperature": 0.0, "avg_logprob": -0.47130225686465993, "compression_ratio": 1.4853801169590644, "no_speech_prob": 8.579235100114602e-07}, {"id": 1369, "seek": 635898, "start": 6369.66, "end": 6372.98, "text": " epsilon delta and blah, blah, blah.", "tokens": [50898, 17889, 8289, 293, 12288, 11, 12288, 11, 12288, 13, 51064], "temperature": 0.0, "avg_logprob": -0.47130225686465993, "compression_ratio": 1.4853801169590644, "no_speech_prob": 8.579235100114602e-07}, {"id": 1370, "seek": 635898, "start": 6372.98, "end": 6376.139999999999, "text": " I've got really good news.", "tokens": [51064, 286, 600, 658, 534, 665, 2583, 13, 51222], "temperature": 0.0, "avg_logprob": -0.47130225686465993, "compression_ratio": 1.4853801169590644, "no_speech_prob": 8.579235100114602e-07}, {"id": 1371, "seek": 635898, "start": 6376.139999999999, "end": 6386.74, "text": " It turns out you can actually just think of this d as a really small number.", "tokens": [51222, 467, 4523, 484, 291, 393, 767, 445, 519, 295, 341, 274, 382, 257, 534, 1359, 1230, 13, 51752], "temperature": 0.0, "avg_logprob": -0.47130225686465993, "compression_ratio": 1.4853801169590644, "no_speech_prob": 8.579235100114602e-07}, {"id": 1372, "seek": 638674, "start": 6386.74, "end": 6389.66, "text": " Where d is the difference.", "tokens": [50364, 2305, 274, 307, 264, 2649, 13, 50510], "temperature": 0.0, "avg_logprob": -0.6536841299019608, "compression_ratio": 1.4310344827586208, "no_speech_prob": 1.0677022146410309e-06}, {"id": 1373, "seek": 638674, "start": 6394.179999999999, "end": 6396.54, "text": " Difference.", "tokens": [50736, 413, 12612, 655, 13, 50854], "temperature": 0.0, "avg_logprob": -0.6536841299019608, "compression_ratio": 1.4310344827586208, "no_speech_prob": 1.0677022146410309e-06}, {"id": 1374, "seek": 638674, "start": 6399.98, "end": 6403.099999999999, "text": " And so when we calculate the slope,", "tokens": [51026, 400, 370, 562, 321, 8873, 264, 13525, 11, 51182], "temperature": 0.0, "avg_logprob": -0.6536841299019608, "compression_ratio": 1.4310344827586208, "no_speech_prob": 1.0677022146410309e-06}, {"id": 1375, "seek": 638674, "start": 6405.66, "end": 6408.179999999999, "text": " We can write it in a slightly different way.", "tokens": [51310, 492, 393, 2464, 309, 294, 257, 4748, 819, 636, 13, 51436], "temperature": 0.0, "avg_logprob": -0.6536841299019608, "compression_ratio": 1.4310344827586208, "no_speech_prob": 1.0677022146410309e-06}, {"id": 1376, "seek": 638674, "start": 6409.58, "end": 6416.54, "text": " As the change in y divided by the change in x.", "tokens": [51506, 1018, 264, 1319, 294, 288, 6666, 538, 264, 1319, 294, 2031, 13, 51854], "temperature": 0.0, "avg_logprob": -0.6536841299019608, "compression_ratio": 1.4310344827586208, "no_speech_prob": 1.0677022146410309e-06}, {"id": 1377, "seek": 641674, "start": 6417.38, "end": 6422.42, "text": " This here is the change in y, and this here is the change in x.", "tokens": [50396, 639, 510, 307, 264, 1319, 294, 288, 11, 293, 341, 510, 307, 264, 1319, 294, 2031, 13, 50648], "temperature": 0.0, "avg_logprob": -0.37193707057407926, "compression_ratio": 1.9310344827586208, "no_speech_prob": 6.577925546480401e-07}, {"id": 1378, "seek": 641674, "start": 6422.42, "end": 6427.0599999999995, "text": " And so in other words, this here is a very small number.", "tokens": [50648, 400, 370, 294, 661, 2283, 11, 341, 510, 307, 257, 588, 1359, 1230, 13, 50880], "temperature": 0.0, "avg_logprob": -0.37193707057407926, "compression_ratio": 1.9310344827586208, "no_speech_prob": 6.577925546480401e-07}, {"id": 1379, "seek": 641674, "start": 6430.0599999999995, "end": 6431.0199999999995, "text": " A very small number.", "tokens": [51030, 316, 588, 1359, 1230, 13, 51078], "temperature": 0.0, "avg_logprob": -0.37193707057407926, "compression_ratio": 1.9310344827586208, "no_speech_prob": 6.577925546480401e-07}, {"id": 1380, "seek": 641674, "start": 6433.38, "end": 6438.94, "text": " And this here is the result in the function of changing by that very small number.", "tokens": [51196, 400, 341, 510, 307, 264, 1874, 294, 264, 2445, 295, 4473, 538, 300, 588, 1359, 1230, 13, 51474], "temperature": 0.0, "avg_logprob": -0.37193707057407926, "compression_ratio": 1.9310344827586208, "no_speech_prob": 6.577925546480401e-07}, {"id": 1381, "seek": 643894, "start": 6439.94, "end": 6445.94, "text": " And this way of thinking about calculus is known as the calculus of infinitesimals.", "tokens": [50414, 400, 341, 636, 295, 1953, 466, 33400, 307, 2570, 382, 264, 33400, 295, 7193, 3324, 332, 1124, 13, 50714], "temperature": 0.0, "avg_logprob": -0.5147750160910867, "compression_ratio": 1.4969325153374233, "no_speech_prob": 1.0616116924211383e-05}, {"id": 1382, "seek": 643894, "start": 6445.94, "end": 6452.94, "text": " And it's how Leibniz originally developed it.", "tokens": [50714, 400, 309, 311, 577, 1456, 897, 77, 590, 7993, 4743, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.5147750160910867, "compression_ratio": 1.4969325153374233, "no_speech_prob": 1.0616116924211383e-05}, {"id": 1383, "seek": 643894, "start": 6452.94, "end": 6458.94, "text": " And it's been turned into a whole theory nowadays.", "tokens": [51064, 400, 309, 311, 668, 3574, 666, 257, 1379, 5261, 13434, 13, 51364], "temperature": 0.0, "avg_logprob": -0.5147750160910867, "compression_ratio": 1.4969325153374233, "no_speech_prob": 1.0616116924211383e-05}, {"id": 1384, "seek": 643894, "start": 6458.94, "end": 6464.179999999999, "text": " And the reason I talk about it here is because when we do this,", "tokens": [51364, 400, 264, 1778, 286, 751, 466, 309, 510, 307, 570, 562, 321, 360, 341, 11, 51626], "temperature": 0.0, "avg_logprob": -0.5147750160910867, "compression_ratio": 1.4969325153374233, "no_speech_prob": 1.0616116924211383e-05}, {"id": 1385, "seek": 646418, "start": 6464.18, "end": 6470.700000000001, "text": " You'll see me doing stuff all the time where I act like dx is a really small number.", "tokens": [50364, 509, 603, 536, 385, 884, 1507, 439, 264, 565, 689, 286, 605, 411, 30017, 307, 257, 534, 1359, 1230, 13, 50690], "temperature": 0.0, "avg_logprob": -0.601100220972178, "compression_ratio": 1.72, "no_speech_prob": 1.5446254110429436e-05}, {"id": 1386, "seek": 646418, "start": 6470.700000000001, "end": 6474.18, "text": " And when I was at school, I was told I wasn't allowed to do that.", "tokens": [50690, 400, 562, 286, 390, 412, 1395, 11, 286, 390, 1907, 286, 2067, 380, 4350, 281, 360, 300, 13, 50864], "temperature": 0.0, "avg_logprob": -0.601100220972178, "compression_ratio": 1.72, "no_speech_prob": 1.5446254110429436e-05}, {"id": 1387, "seek": 646418, "start": 6474.18, "end": 6477.06, "text": " I've since learned that it's totally fine to do that.", "tokens": [50864, 286, 600, 1670, 3264, 300, 309, 311, 3879, 2489, 281, 360, 300, 13, 51008], "temperature": 0.0, "avg_logprob": -0.601100220972178, "compression_ratio": 1.72, "no_speech_prob": 1.5446254110429436e-05}, {"id": 1388, "seek": 646418, "start": 6477.06, "end": 6481.06, "text": " So for example, next lesson, we're gonna be looking at the chain rule.", "tokens": [51008, 407, 337, 1365, 11, 958, 6898, 11, 321, 434, 799, 312, 1237, 412, 264, 5021, 4978, 13, 51208], "temperature": 0.0, "avg_logprob": -0.601100220972178, "compression_ratio": 1.72, "no_speech_prob": 1.5446254110429436e-05}, {"id": 1389, "seek": 646418, "start": 6483.860000000001, "end": 6484.9400000000005, "text": " Which looks like this.", "tokens": [51348, 3013, 1542, 411, 341, 13, 51402], "temperature": 0.0, "avg_logprob": -0.601100220972178, "compression_ratio": 1.72, "no_speech_prob": 1.5446254110429436e-05}, {"id": 1390, "seek": 646418, "start": 6486.9400000000005, "end": 6488.5, "text": " And we're gonna be looking at the chain rule.", "tokens": [51502, 400, 321, 434, 799, 312, 1237, 412, 264, 5021, 4978, 13, 51580], "temperature": 0.0, "avg_logprob": -0.601100220972178, "compression_ratio": 1.72, "no_speech_prob": 1.5446254110429436e-05}, {"id": 1391, "seek": 648850, "start": 6488.5, "end": 6492.5, "text": " Which looks like this.", "tokens": [50364, 3013, 1542, 411, 341, 13, 50564], "temperature": 0.0, "avg_logprob": -0.4705618561291304, "compression_ratio": 1.404109589041096, "no_speech_prob": 2.699577521525498e-07}, {"id": 1392, "seek": 648850, "start": 6492.5, "end": 6498.5, "text": " dy dx equals dy du times du dx.", "tokens": [50564, 14584, 30017, 6915, 14584, 1581, 1413, 1581, 30017, 13, 50864], "temperature": 0.0, "avg_logprob": -0.4705618561291304, "compression_ratio": 1.404109589041096, "no_speech_prob": 2.699577521525498e-07}, {"id": 1393, "seek": 648850, "start": 6501.5, "end": 6505.18, "text": " And I'm just gonna say, these two small numbers can cancel out.", "tokens": [51014, 400, 286, 478, 445, 799, 584, 11, 613, 732, 1359, 3547, 393, 10373, 484, 13, 51198], "temperature": 0.0, "avg_logprob": -0.4705618561291304, "compression_ratio": 1.404109589041096, "no_speech_prob": 2.699577521525498e-07}, {"id": 1394, "seek": 648850, "start": 6506.5, "end": 6508.38, "text": " And that's why obviously they're the same thing.", "tokens": [51264, 400, 300, 311, 983, 2745, 436, 434, 264, 912, 551, 13, 51358], "temperature": 0.0, "avg_logprob": -0.4705618561291304, "compression_ratio": 1.404109589041096, "no_speech_prob": 2.699577521525498e-07}, {"id": 1395, "seek": 648850, "start": 6509.86, "end": 6511.22, "text": " And that's all gonna work out nicely.", "tokens": [51432, 400, 300, 311, 439, 799, 589, 484, 9594, 13, 51500], "temperature": 0.0, "avg_logprob": -0.4705618561291304, "compression_ratio": 1.404109589041096, "no_speech_prob": 2.699577521525498e-07}, {"id": 1396, "seek": 651122, "start": 6512.22, "end": 6518.22, "text": " So anywho, what would be very helpful would be if before the next lesson,", "tokens": [50414, 407, 604, 13506, 11, 437, 576, 312, 588, 4961, 576, 312, 498, 949, 264, 958, 6898, 11, 50714], "temperature": 0.0, "avg_logprob": -0.30878335303002663, "compression_ratio": 1.5253456221198156, "no_speech_prob": 1.10159498944995e-06}, {"id": 1397, "seek": 651122, "start": 6518.22, "end": 6522.22, "text": " if you're not totally up to date with your,", "tokens": [50714, 498, 291, 434, 406, 3879, 493, 281, 4002, 365, 428, 11, 50914], "temperature": 0.0, "avg_logprob": -0.30878335303002663, "compression_ratio": 1.5253456221198156, "no_speech_prob": 1.10159498944995e-06}, {"id": 1398, "seek": 651122, "start": 6522.22, "end": 6526.22, "text": " remembering all the stuff you did in high school about calculus.", "tokens": [50914, 20719, 439, 264, 1507, 291, 630, 294, 1090, 1395, 466, 33400, 13, 51114], "temperature": 0.0, "avg_logprob": -0.30878335303002663, "compression_ratio": 1.5253456221198156, "no_speech_prob": 1.10159498944995e-06}, {"id": 1399, "seek": 651122, "start": 6526.22, "end": 6529.22, "text": " Is watch the three blue, one brown course.", "tokens": [51114, 1119, 1159, 264, 1045, 3344, 11, 472, 6292, 1164, 13, 51264], "temperature": 0.0, "avg_logprob": -0.30878335303002663, "compression_ratio": 1.5253456221198156, "no_speech_prob": 1.10159498944995e-06}, {"id": 1400, "seek": 651122, "start": 6529.22, "end": 6535.22, "text": " We are not gonna be looking, I don't think at all, at integration.", "tokens": [51264, 492, 366, 406, 799, 312, 1237, 11, 286, 500, 380, 519, 412, 439, 11, 412, 10980, 13, 51564], "temperature": 0.0, "avg_logprob": -0.30878335303002663, "compression_ratio": 1.5253456221198156, "no_speech_prob": 1.10159498944995e-06}, {"id": 1401, "seek": 651122, "start": 6535.22, "end": 6538.22, "text": " So you don't have to worry about that.", "tokens": [51564, 407, 291, 500, 380, 362, 281, 3292, 466, 300, 13, 51714], "temperature": 0.0, "avg_logprob": -0.30878335303002663, "compression_ratio": 1.5253456221198156, "no_speech_prob": 1.10159498944995e-06}, {"id": 1402, "seek": 653822, "start": 6539.22, "end": 6544.22, "text": " Also, we are not going to, on the whole,", "tokens": [50414, 2743, 11, 321, 366, 406, 516, 281, 11, 322, 264, 1379, 11, 50664], "temperature": 0.0, "avg_logprob": -0.29281161381648135, "compression_ratio": 1.3725490196078431, "no_speech_prob": 6.893607178426464e-07}, {"id": 1403, "seek": 653822, "start": 6544.22, "end": 6548.22, "text": " be doing any derivatives by hand.", "tokens": [50664, 312, 884, 604, 33733, 538, 1011, 13, 50864], "temperature": 0.0, "avg_logprob": -0.29281161381648135, "compression_ratio": 1.3725490196078431, "no_speech_prob": 6.893607178426464e-07}, {"id": 1404, "seek": 653822, "start": 6548.22, "end": 6553.22, "text": " So for example, there are rules such as,", "tokens": [50864, 407, 337, 1365, 11, 456, 366, 4474, 1270, 382, 11, 51114], "temperature": 0.0, "avg_logprob": -0.29281161381648135, "compression_ratio": 1.3725490196078431, "no_speech_prob": 6.893607178426464e-07}, {"id": 1405, "seek": 653822, "start": 6557.22, "end": 6564.22, "text": " dy dx if y equals x squared is 2x.", "tokens": [51314, 14584, 30017, 498, 288, 6915, 2031, 8889, 307, 568, 87, 13, 51664], "temperature": 0.0, "avg_logprob": -0.29281161381648135, "compression_ratio": 1.3725490196078431, "no_speech_prob": 6.893607178426464e-07}, {"id": 1406, "seek": 653822, "start": 6564.22, "end": 6566.22, "text": " These kind of rules, you're not really gonna have to learn.", "tokens": [51664, 1981, 733, 295, 4474, 11, 291, 434, 406, 534, 799, 362, 281, 1466, 13, 51764], "temperature": 0.0, "avg_logprob": -0.29281161381648135, "compression_ratio": 1.3725490196078431, "no_speech_prob": 6.893607178426464e-07}, {"id": 1407, "seek": 656822, "start": 6568.22, "end": 6571.22, "text": " Because PyTorch is gonna do them all for you.", "tokens": [50364, 1436, 9953, 51, 284, 339, 307, 799, 360, 552, 439, 337, 291, 13, 50514], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1408, "seek": 656822, "start": 6571.22, "end": 6575.22, "text": " The one that we care about is gonna be the chain rule.", "tokens": [50514, 440, 472, 300, 321, 1127, 466, 307, 799, 312, 264, 5021, 4978, 13, 50714], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1409, "seek": 656822, "start": 6575.22, "end": 6578.22, "text": " But we're gonna learn about that next time.", "tokens": [50714, 583, 321, 434, 799, 1466, 466, 300, 958, 565, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1410, "seek": 656822, "start": 6578.22, "end": 6582.22, "text": " Okay, I hope I don't get beaten to a bloody pulp the next time I walk", "tokens": [50864, 1033, 11, 286, 1454, 286, 500, 380, 483, 17909, 281, 257, 18938, 37489, 264, 958, 565, 286, 1792, 51064], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1411, "seek": 656822, "start": 6582.22, "end": 6584.22, "text": " into a mathematician's conference.", "tokens": [51064, 666, 257, 48281, 311, 7586, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1412, "seek": 656822, "start": 6584.22, "end": 6585.22, "text": " I suspect I might.", "tokens": [51164, 286, 9091, 286, 1062, 13, 51214], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1413, "seek": 656822, "start": 6587.22, "end": 6591.22, "text": " But hopefully I get away with this.", "tokens": [51314, 583, 4696, 286, 483, 1314, 365, 341, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1414, "seek": 656822, "start": 6591.22, "end": 6593.22, "text": " I think it's safe.", "tokens": [51514, 286, 519, 309, 311, 3273, 13, 51614], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1415, "seek": 656822, "start": 6593.22, "end": 6595.22, "text": " We'll see how we go.", "tokens": [51614, 492, 603, 536, 577, 321, 352, 13, 51714], "temperature": 0.0, "avg_logprob": -0.21799087524414062, "compression_ratio": 1.5495495495495495, "no_speech_prob": 8.664638698974159e-06}, {"id": 1416, "seek": 659522, "start": 6596.22, "end": 6605.22, "text": " So, Thanks everybody very much for joining me.", "tokens": [50414, 407, 11, 2561, 2201, 588, 709, 337, 5549, 385, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2190373738606771, "compression_ratio": 1.5073891625615763, "no_speech_prob": 8.349559357156977e-05}, {"id": 1417, "seek": 659522, "start": 6605.22, "end": 6609.22, "text": " And I really look forward to seeing you next time where we're gonna do", "tokens": [50864, 400, 286, 534, 574, 2128, 281, 2577, 291, 958, 565, 689, 321, 434, 799, 360, 51064], "temperature": 0.0, "avg_logprob": -0.2190373738606771, "compression_ratio": 1.5073891625615763, "no_speech_prob": 8.349559357156977e-05}, {"id": 1418, "seek": 659522, "start": 6609.22, "end": 6611.22, "text": " back propagation from scratch.", "tokens": [51064, 646, 38377, 490, 8459, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2190373738606771, "compression_ratio": 1.5073891625615763, "no_speech_prob": 8.349559357156977e-05}, {"id": 1419, "seek": 659522, "start": 6611.22, "end": 6613.22, "text": " We've already learned to multiply matrices.", "tokens": [51164, 492, 600, 1217, 3264, 281, 12972, 32284, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2190373738606771, "compression_ratio": 1.5073891625615763, "no_speech_prob": 8.349559357156977e-05}, {"id": 1420, "seek": 659522, "start": 6613.22, "end": 6616.22, "text": " So once we've got back propagation as well,", "tokens": [51264, 407, 1564, 321, 600, 658, 646, 38377, 382, 731, 11, 51414], "temperature": 0.0, "avg_logprob": -0.2190373738606771, "compression_ratio": 1.5073891625615763, "no_speech_prob": 8.349559357156977e-05}, {"id": 1421, "seek": 659522, "start": 6616.22, "end": 6619.22, "text": " we'll be ready to train a neural network.", "tokens": [51414, 321, 603, 312, 1919, 281, 3847, 257, 18161, 3209, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2190373738606771, "compression_ratio": 1.5073891625615763, "no_speech_prob": 8.349559357156977e-05}, {"id": 1422, "seek": 659522, "start": 6619.22, "end": 6621.22, "text": " All right, thanks all, bye.", "tokens": [51564, 1057, 558, 11, 3231, 439, 11, 6543, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2190373738606771, "compression_ratio": 1.5073891625615763, "no_speech_prob": 8.349559357156977e-05}], "language": "en"}