{"text": " Welcome to lesson five. We'll be talking about ethics for data science and this corresponds to chapter three of the book. I've also just taught a six-week version of this course. I'm currently teaching an eight-week version of this course and will release some combination or subset of that as a Fast AI and USF ethics for data science class if you want more detail coming in July. I am Rachel Thomas. I am the founding director of the Center for Applied Data Ethics at the University of San Francisco and also co-founder of Fast AI together with Jeremy Howard. My background, I have a PhD in math and worked as a data scientist and software engineer in the tech industry and then have been working at USF and on Fast AI for the past four years now. So ethics issues are in the news. These articles I think are all from this fall, kind of showing up at this intersection of how technology is impacting our world in many kind of increasingly powerful ways, many of which really raise concerns. And I want to start by talking about three cases that I hope everyone working in technology knows about and is on the lookout for. So even if you only watch five minutes of this video, these are kind of the three cases I want you to see. And one is feedback loops. And so feedback loops can occur whenever your model is controlling the next round of data you get. So the data that's returned quickly becomes flawed by the software itself. And this this can show up in many places. One example is with recommendation systems. And so recommendation systems are extensively about predicting what content the user will like, but they're also determining what content the user is even exposed to and helping determine what has a chance of becoming popular. And so YouTube has gotten a lot of a lot of tension about this for kind of highly recommending many conspiracy theories, many kind of very damaging conspiracy theories. There was also they've kind of put together recommendations of pedophilia picked out of what were kind of innocent home movies, but when are kind of strung together ones that happen to have young girls in bathing suits or in their pajamas. So there's some really really concerning results. And this is not something that any anybody intended. And we'll talk about this more later. I think particularly for many of us coming from a science background, we're often used to thinking of like, oh you know, like we observe the data. But really whenever you're building products that interact with the real world, you're also kind of controlling what the data looks like. Second case study I want everyone to know about comes from software that's used to determine poor people's health benefits. It's used in over half of the 50 states. And The Verge did an investigation on what happened when it was rolled out in Arkansas. And what happened is there was a bug in the software implementation that incorrectly cut coverage for people with cerebral palsy or diabetes, including Tammy Dobbs who's pictured here and was interviewed in the article. And so these are people that really needed this health care and it was erroneously cut due to this bug. And so they were really, and they couldn't get any sort of explanation and there was no appeals or recourse process in place. And eventually this all came out through a lengthy court case, but it's something where it caused a lot of suffering in the meantime. And so it's really important to implement systems with a way to identify and address mistakes and to do that quickly and in a way that hopefully minimizes damage. Because we all know software can have bugs, our code can behave in unexpected ways, and we need to be prepared for that. I wrote more about this idea in a post two years ago, What HBR Gets Wrong About Algorithms and Bias. And then third case study that everyone should know about. So this is Latonya Sweeney, who's director of the data privacy lab at Harvard. She has a PhD in computer science and she noticed several years ago that when you Google her name you would get these ads saying Latonya Sweeney arrested, implying that she has a criminal record. She's the only Latonya Sweeney and she has never been arrested. She paid $50 to the background check company and confirmed that she's never been arrested. She tried Googling some other names and she noticed, for example, Kristen Lindquist got much more neutral ads that just say we found Kristen Lindquist even though Kristen Lindquist has been arrested three times. And so being a computer scientist, Dr. Sweeney studied this very systematically. She looked at over 2,000 names and found that this pattern held in which disproportionately African-American names were getting these ads suggesting that the person had a criminal record regardless of whether they did and traditionally European-American or white names were getting more neutral ads. And this problem of kind of bias in advertising shows up a ton. Advertising is kind of the profit model for most of the major tech platforms and it kind of continues to pop up in high-impact ways. Just last year there was research showing how Facebook's ad system discriminates even when the person placing the ad is not trying to do so. So for instance, the same housing ad, exact same text, if you change the photo between a white family and a black family it's served to very different audiences. So this is something that can really impact people when they're looking for housing, when they're applying for jobs, and is a definite area of concern. So now I want to kind of step back and ask why why does this matter? And so a very kind of extreme example is just that data collection has played a pivotal role in several genocides including the Holocaust. And so this is a photo of Adolf Hitler meeting with the CEO of IBM at the time. I think this photo was taken in 1937. And IBM continued to partner with the Nazis kind of long past when many other companies broke their ties. They produced computers that were used in concentration camps to code whether people were Jewish, how they were executed. And this is also different from now where you might sell somebody a computer and they never hear from them again. These machines require a lot of maintenance and kind of ongoing relationship with vendors to kind of upkeep and repair them. It's something that a Swiss judge ruled. It does not seem unreasonable to deduce that IBM's technical assistance facilitated the task of the Nazis in the Commission of their Crimes Against Humanity acts, also involving accountancy and classification by IBM machines and utilized in the concentration camps themselves. I'm told that they haven't gotten around to apologizing yet. Oh that's I guess they've been busy. Terrible too, yeah. Okay, yeah. And so this is a very kind of a very sobering example, but I think it's important to keep in mind kind of what can go wrong and how technology can be used for harm, for very very terrible harm. And so this just kind of raises a question questions that we all need to grapple with of how would you feel if you discovered that you had been part of a system that ended up hurting society? Would you even know? Would you be open to finding out kind of how things you had built may have been harmful? And how can you help make sure this doesn't happen? And so I think these are questions that we all all need to grapple with. It's also important to think about unintended consequences, how your tech could be used or misused, whether that's by harassers, by authoritarian governments, for propaganda or disinformation. And then on a kind of a more concrete level, you could even end up in jail. And so there was a Volkswagen engineer who got prison time for his role in the diesel cheating case. So if you remember, this is where Volkswagen was cheating on emissions test and one of the kind of programmers that was a part of that. And that person was just following orders from what their boss told them to do, but that is not a good excuse for doing something that's unethical and so something to be aware of. So ethics is the discipline dealing with what's good and bad. It's a set of moral principles. It's not a set of answers, but it's kind of learning what sort of questions to ask and even how to weigh these decisions. And I'll say some more about kind of ethical foundations and different ethical philosophies later on in this lesson. But first I'm going to kind of start with some use cases. Ethics is not the same as religion, laws, social norms, or feelings, although it does have overlap with all these things. It's not a fixed set of rules. It's well-founded standards of right and wrong. And this is something where clearly not everybody agrees on the ethical action in every case, but that doesn't mean that kind of anything goes or that all actions are considered equally ethical. There are many things that are widely agreed upon and there are kind of philosophical underpinnings for kind of making these decisions. And ethics is also the ongoing study and development of our ethical standards. It's a kind of never-ending process of learning to kind of practice our ethical wisdom. And I'm going to refer it several times to, so here I'm referring to a few articles from the Marcula Center for Tech Ethics at Santa Clara University, in particular the work of Shannon Valor, Brian Greene, and Irina Reiku is fantastic and they have a lot of resources, some of which I'll circle back to later in this talk. I spent years of my life studying ethics. It was my major at university and so much time on the question of what is ethics. I think my takeaway from that is studying the philosophy ethics was not particularly helpful in learning about ethics. Yes and I will try to keep this kind of very very applied and very practical, also very kind of tech industry specific of what what do you need in terms of applied ethics. Yeah, the Marcula Center is great. They somehow they take stuff that I thought was super dry and turn it into useful checklists and things. I did want to note this is really neat. So Casey Fiesler is a professor at University of Colorado that I really admire and she created a crowd-sourced spreadsheet of tech ethics syllabi. This was maybe two years ago and got over 200 syllabi entered into this this crowd-sourced spreadsheet and then she did a meta analysis on them of kind of looking at all sorts of aspects of the syllabi and what's being taught and how it's being taught and published a paper on it. What do we teach when we teach tech ethics? And a few interesting things about it is it raises there are a lot of ongoing discussions and lack of agreement on how to how to best teach tech ethics. Should it be a standalone course versus worked into every course in the curriculum? Who should teach it? A computer scientist, a philosopher, or a sociologist? And and she analyzed for the syllabi what was the course home and the instructor home and you can see that the the instructors came from a range of courses including computer a range of disciplines. Computer science, information science, philosophy, science and tech studies, engineering, law, math, business. What topics to cover? A huge range of topics that can be covered including law and policy, privacy and surveillance, inequality, justice and human rights, environmental impact, AI and robots, professional ethics, work and labor, cybersecurity. The list goes on and on and so this is clearly more than can be covered in any even a full semester length course and certainly not in kind of a single single lecture. What learning outcomes? This is an area where there's a little bit more agreement where kind of the number one skill that courses were trying to teach was critique followed by spotting issues, making arguments. So a lot of this is just even learning to spot what the issues are and how to critically evaluate kind of a piece of technology or a design proposal to see what could go wrong and what the risk is.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.16, "text": " Welcome to lesson five. We'll be talking about ethics for data science and this", "tokens": [4027, 281, 6898, 1732, 13, 492, 603, 312, 1417, 466, 19769, 337, 1412, 3497, 293, 341], "temperature": 0.0, "avg_logprob": -0.20720075524371603, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0022508897818624973}, {"id": 1, "seek": 0, "start": 4.16, "end": 11.120000000000001, "text": " corresponds to chapter three of the book. I've also just taught a six-week", "tokens": [23249, 281, 7187, 1045, 295, 264, 1446, 13, 286, 600, 611, 445, 5928, 257, 2309, 12, 23188], "temperature": 0.0, "avg_logprob": -0.20720075524371603, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0022508897818624973}, {"id": 2, "seek": 0, "start": 11.120000000000001, "end": 13.76, "text": " version of this course. I'm currently teaching an eight-week version of this", "tokens": [3037, 295, 341, 1164, 13, 286, 478, 4362, 4571, 364, 3180, 12, 23188, 3037, 295, 341], "temperature": 0.0, "avg_logprob": -0.20720075524371603, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0022508897818624973}, {"id": 3, "seek": 0, "start": 13.76, "end": 19.88, "text": " course and will release some combination or subset of that as a Fast AI and", "tokens": [1164, 293, 486, 4374, 512, 6562, 420, 25993, 295, 300, 382, 257, 15968, 7318, 293], "temperature": 0.0, "avg_logprob": -0.20720075524371603, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0022508897818624973}, {"id": 4, "seek": 0, "start": 19.88, "end": 25.6, "text": " USF ethics for data science class if you want more detail coming in July.", "tokens": [2546, 37, 19769, 337, 1412, 3497, 1508, 498, 291, 528, 544, 2607, 1348, 294, 7370, 13], "temperature": 0.0, "avg_logprob": -0.20720075524371603, "compression_ratio": 1.6710526315789473, "no_speech_prob": 0.0022508897818624973}, {"id": 5, "seek": 2560, "start": 25.6, "end": 30.12, "text": " I am Rachel Thomas. I am the founding director of the Center for Applied Data", "tokens": [286, 669, 14246, 8500, 13, 286, 669, 264, 22223, 5391, 295, 264, 5169, 337, 3132, 39459, 11888], "temperature": 0.0, "avg_logprob": -0.10397981828258883, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.0001311758387601003}, {"id": 6, "seek": 2560, "start": 30.12, "end": 33.68, "text": " Ethics at the University of San Francisco and also co-founder of Fast AI", "tokens": [10540, 1167, 412, 264, 3535, 295, 5271, 12279, 293, 611, 598, 12, 33348, 295, 15968, 7318], "temperature": 0.0, "avg_logprob": -0.10397981828258883, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.0001311758387601003}, {"id": 7, "seek": 2560, "start": 33.68, "end": 38.28, "text": " together with Jeremy Howard. My background, I have a PhD in math and", "tokens": [1214, 365, 17809, 17626, 13, 1222, 3678, 11, 286, 362, 257, 14476, 294, 5221, 293], "temperature": 0.0, "avg_logprob": -0.10397981828258883, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.0001311758387601003}, {"id": 8, "seek": 2560, "start": 38.28, "end": 43.24, "text": " worked as a data scientist and software engineer in the tech industry and then", "tokens": [2732, 382, 257, 1412, 12662, 293, 4722, 11403, 294, 264, 7553, 3518, 293, 550], "temperature": 0.0, "avg_logprob": -0.10397981828258883, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.0001311758387601003}, {"id": 9, "seek": 2560, "start": 43.24, "end": 52.72, "text": " have been working at USF and on Fast AI for the past four years now. So ethics", "tokens": [362, 668, 1364, 412, 2546, 37, 293, 322, 15968, 7318, 337, 264, 1791, 1451, 924, 586, 13, 407, 19769], "temperature": 0.0, "avg_logprob": -0.10397981828258883, "compression_ratio": 1.5201612903225807, "no_speech_prob": 0.0001311758387601003}, {"id": 10, "seek": 5272, "start": 52.72, "end": 59.08, "text": " issues are in the news. These articles I think are all from this fall, kind", "tokens": [2663, 366, 294, 264, 2583, 13, 1981, 11290, 286, 519, 366, 439, 490, 341, 2100, 11, 733], "temperature": 0.0, "avg_logprob": -0.12860123162130707, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.00010223747085547075}, {"id": 11, "seek": 5272, "start": 59.08, "end": 64.32, "text": " of showing up at this intersection of how technology is impacting our", "tokens": [295, 4099, 493, 412, 341, 15236, 295, 577, 2899, 307, 29963, 527], "temperature": 0.0, "avg_logprob": -0.12860123162130707, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.00010223747085547075}, {"id": 12, "seek": 5272, "start": 64.32, "end": 69.32, "text": " world in many kind of increasingly powerful ways, many of which really raise", "tokens": [1002, 294, 867, 733, 295, 12980, 4005, 2098, 11, 867, 295, 597, 534, 5300], "temperature": 0.0, "avg_logprob": -0.12860123162130707, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.00010223747085547075}, {"id": 13, "seek": 5272, "start": 69.32, "end": 73.8, "text": " concerns. And I want to start by talking about three cases that I hope", "tokens": [7389, 13, 400, 286, 528, 281, 722, 538, 1417, 466, 1045, 3331, 300, 286, 1454], "temperature": 0.0, "avg_logprob": -0.12860123162130707, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.00010223747085547075}, {"id": 14, "seek": 5272, "start": 73.8, "end": 77.8, "text": " everyone working in technology knows about and is on the lookout for. So even", "tokens": [1518, 1364, 294, 2899, 3255, 466, 293, 307, 322, 264, 41025, 337, 13, 407, 754], "temperature": 0.0, "avg_logprob": -0.12860123162130707, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.00010223747085547075}, {"id": 15, "seek": 5272, "start": 77.8, "end": 81.32, "text": " if you only watch five minutes of this video, these are kind of the three", "tokens": [498, 291, 787, 1159, 1732, 2077, 295, 341, 960, 11, 613, 366, 733, 295, 264, 1045], "temperature": 0.0, "avg_logprob": -0.12860123162130707, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.00010223747085547075}, {"id": 16, "seek": 8132, "start": 81.32, "end": 86.24, "text": " cases I want you to see. And one is feedback loops. And so feedback loops can", "tokens": [3331, 286, 528, 291, 281, 536, 13, 400, 472, 307, 5824, 16121, 13, 400, 370, 5824, 16121, 393], "temperature": 0.0, "avg_logprob": -0.10055809209842494, "compression_ratio": 1.741444866920152, "no_speech_prob": 2.467972990416456e-05}, {"id": 17, "seek": 8132, "start": 86.24, "end": 91.08, "text": " occur whenever your model is controlling the next round of data you get. So the", "tokens": [5160, 5699, 428, 2316, 307, 14905, 264, 958, 3098, 295, 1412, 291, 483, 13, 407, 264], "temperature": 0.0, "avg_logprob": -0.10055809209842494, "compression_ratio": 1.741444866920152, "no_speech_prob": 2.467972990416456e-05}, {"id": 18, "seek": 8132, "start": 91.08, "end": 95.75999999999999, "text": " data that's returned quickly becomes flawed by the software itself. And this", "tokens": [1412, 300, 311, 8752, 2661, 3643, 38823, 538, 264, 4722, 2564, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.10055809209842494, "compression_ratio": 1.741444866920152, "no_speech_prob": 2.467972990416456e-05}, {"id": 19, "seek": 8132, "start": 95.75999999999999, "end": 100.11999999999999, "text": " this can show up in many places. One example is with recommendation systems.", "tokens": [341, 393, 855, 493, 294, 867, 3190, 13, 1485, 1365, 307, 365, 11879, 3652, 13], "temperature": 0.0, "avg_logprob": -0.10055809209842494, "compression_ratio": 1.741444866920152, "no_speech_prob": 2.467972990416456e-05}, {"id": 20, "seek": 8132, "start": 100.11999999999999, "end": 104.08, "text": " And so recommendation systems are extensively about predicting what", "tokens": [400, 370, 11879, 3652, 366, 32636, 466, 32884, 437], "temperature": 0.0, "avg_logprob": -0.10055809209842494, "compression_ratio": 1.741444866920152, "no_speech_prob": 2.467972990416456e-05}, {"id": 21, "seek": 8132, "start": 104.08, "end": 108.39999999999999, "text": " content the user will like, but they're also determining what content the user", "tokens": [2701, 264, 4195, 486, 411, 11, 457, 436, 434, 611, 23751, 437, 2701, 264, 4195], "temperature": 0.0, "avg_logprob": -0.10055809209842494, "compression_ratio": 1.741444866920152, "no_speech_prob": 2.467972990416456e-05}, {"id": 22, "seek": 10840, "start": 108.4, "end": 112.28, "text": " is even exposed to and helping determine what has a chance of", "tokens": [307, 754, 9495, 281, 293, 4315, 6997, 437, 575, 257, 2931, 295], "temperature": 0.0, "avg_logprob": -0.1394722079053337, "compression_ratio": 1.6803652968036529, "no_speech_prob": 3.071436731261201e-05}, {"id": 23, "seek": 10840, "start": 112.28, "end": 118.28, "text": " becoming popular. And so YouTube has gotten a lot of a lot of tension about", "tokens": [5617, 3743, 13, 400, 370, 3088, 575, 5768, 257, 688, 295, 257, 688, 295, 8980, 466], "temperature": 0.0, "avg_logprob": -0.1394722079053337, "compression_ratio": 1.6803652968036529, "no_speech_prob": 3.071436731261201e-05}, {"id": 24, "seek": 10840, "start": 118.28, "end": 125.76, "text": " this for kind of highly recommending many conspiracy theories, many kind of", "tokens": [341, 337, 733, 295, 5405, 30559, 867, 20439, 13667, 11, 867, 733, 295], "temperature": 0.0, "avg_logprob": -0.1394722079053337, "compression_ratio": 1.6803652968036529, "no_speech_prob": 3.071436731261201e-05}, {"id": 25, "seek": 10840, "start": 125.76, "end": 130.28, "text": " very damaging conspiracy theories. There was also they've kind of put together", "tokens": [588, 25342, 20439, 13667, 13, 821, 390, 611, 436, 600, 733, 295, 829, 1214], "temperature": 0.0, "avg_logprob": -0.1394722079053337, "compression_ratio": 1.6803652968036529, "no_speech_prob": 3.071436731261201e-05}, {"id": 26, "seek": 10840, "start": 130.28, "end": 134.1, "text": " recommendations of pedophilia picked out of what were kind of innocent home", "tokens": [10434, 295, 5670, 5317, 24169, 6183, 484, 295, 437, 645, 733, 295, 13171, 1280], "temperature": 0.0, "avg_logprob": -0.1394722079053337, "compression_ratio": 1.6803652968036529, "no_speech_prob": 3.071436731261201e-05}, {"id": 27, "seek": 13410, "start": 134.1, "end": 139.04, "text": " movies, but when are kind of strung together ones that happen to have young", "tokens": [6233, 11, 457, 562, 366, 733, 295, 1056, 1063, 1214, 2306, 300, 1051, 281, 362, 2037], "temperature": 0.0, "avg_logprob": -0.14391473487571435, "compression_ratio": 1.6408450704225352, "no_speech_prob": 1.618595160834957e-05}, {"id": 28, "seek": 13410, "start": 139.04, "end": 146.48, "text": " girls in bathing suits or in their pajamas. So there's some really really", "tokens": [4519, 294, 38948, 15278, 420, 294, 641, 43625, 13, 407, 456, 311, 512, 534, 534], "temperature": 0.0, "avg_logprob": -0.14391473487571435, "compression_ratio": 1.6408450704225352, "no_speech_prob": 1.618595160834957e-05}, {"id": 29, "seek": 13410, "start": 146.48, "end": 150.72, "text": " concerning results. And this is not something that any anybody intended. And", "tokens": [18087, 3542, 13, 400, 341, 307, 406, 746, 300, 604, 4472, 10226, 13, 400], "temperature": 0.0, "avg_logprob": -0.14391473487571435, "compression_ratio": 1.6408450704225352, "no_speech_prob": 1.618595160834957e-05}, {"id": 30, "seek": 13410, "start": 150.72, "end": 154.12, "text": " we'll talk about this more later. I think particularly for many of us coming from", "tokens": [321, 603, 751, 466, 341, 544, 1780, 13, 286, 519, 4098, 337, 867, 295, 505, 1348, 490], "temperature": 0.0, "avg_logprob": -0.14391473487571435, "compression_ratio": 1.6408450704225352, "no_speech_prob": 1.618595160834957e-05}, {"id": 31, "seek": 13410, "start": 154.12, "end": 157.48, "text": " a science background, we're often used to thinking of like, oh you know, like we", "tokens": [257, 3497, 3678, 11, 321, 434, 2049, 1143, 281, 1953, 295, 411, 11, 1954, 291, 458, 11, 411, 321], "temperature": 0.0, "avg_logprob": -0.14391473487571435, "compression_ratio": 1.6408450704225352, "no_speech_prob": 1.618595160834957e-05}, {"id": 32, "seek": 13410, "start": 157.48, "end": 161.16, "text": " observe the data. But really whenever you're building products that interact", "tokens": [11441, 264, 1412, 13, 583, 534, 5699, 291, 434, 2390, 3383, 300, 4648], "temperature": 0.0, "avg_logprob": -0.14391473487571435, "compression_ratio": 1.6408450704225352, "no_speech_prob": 1.618595160834957e-05}, {"id": 33, "seek": 16116, "start": 161.16, "end": 167.28, "text": " with the real world, you're also kind of controlling what the data looks like.", "tokens": [365, 264, 957, 1002, 11, 291, 434, 611, 733, 295, 14905, 437, 264, 1412, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.09666491017758268, "compression_ratio": 1.6389891696750902, "no_speech_prob": 1.8629018086357974e-05}, {"id": 34, "seek": 16116, "start": 167.28, "end": 173.88, "text": " Second case study I want everyone to know about comes from software", "tokens": [5736, 1389, 2979, 286, 528, 1518, 281, 458, 466, 1487, 490, 4722], "temperature": 0.0, "avg_logprob": -0.09666491017758268, "compression_ratio": 1.6389891696750902, "no_speech_prob": 1.8629018086357974e-05}, {"id": 35, "seek": 16116, "start": 173.88, "end": 177.64, "text": " that's used to determine poor people's health benefits. It's used in over half", "tokens": [300, 311, 1143, 281, 6997, 4716, 561, 311, 1585, 5311, 13, 467, 311, 1143, 294, 670, 1922], "temperature": 0.0, "avg_logprob": -0.09666491017758268, "compression_ratio": 1.6389891696750902, "no_speech_prob": 1.8629018086357974e-05}, {"id": 36, "seek": 16116, "start": 177.64, "end": 181.8, "text": " of the 50 states. And The Verge did an investigation on what happened when it", "tokens": [295, 264, 2625, 4368, 13, 400, 440, 4281, 432, 630, 364, 9627, 322, 437, 2011, 562, 309], "temperature": 0.0, "avg_logprob": -0.09666491017758268, "compression_ratio": 1.6389891696750902, "no_speech_prob": 1.8629018086357974e-05}, {"id": 37, "seek": 16116, "start": 181.8, "end": 185.24, "text": " was rolled out in Arkansas. And what happened is there was a bug in the", "tokens": [390, 14306, 484, 294, 31386, 13, 400, 437, 2011, 307, 456, 390, 257, 7426, 294, 264], "temperature": 0.0, "avg_logprob": -0.09666491017758268, "compression_ratio": 1.6389891696750902, "no_speech_prob": 1.8629018086357974e-05}, {"id": 38, "seek": 16116, "start": 185.24, "end": 189.84, "text": " software implementation that incorrectly cut coverage for people with cerebral", "tokens": [4722, 11420, 300, 42892, 1723, 9645, 337, 561, 365, 43561], "temperature": 0.0, "avg_logprob": -0.09666491017758268, "compression_ratio": 1.6389891696750902, "no_speech_prob": 1.8629018086357974e-05}, {"id": 39, "seek": 18984, "start": 189.84, "end": 195.12, "text": " palsy or diabetes, including Tammy Dobbs who's pictured here and was interviewed", "tokens": [43806, 88, 420, 13881, 11, 3009, 48030, 29679, 929, 567, 311, 49896, 510, 293, 390, 19770], "temperature": 0.0, "avg_logprob": -0.12159858782266833, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.4509181710309349e-05}, {"id": 40, "seek": 18984, "start": 195.12, "end": 200.52, "text": " in the article. And so these are people that really needed this health care and", "tokens": [294, 264, 7222, 13, 400, 370, 613, 366, 561, 300, 534, 2978, 341, 1585, 1127, 293], "temperature": 0.0, "avg_logprob": -0.12159858782266833, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.4509181710309349e-05}, {"id": 41, "seek": 18984, "start": 200.52, "end": 206.92000000000002, "text": " it was erroneously cut due to this bug. And so they were really, and they", "tokens": [309, 390, 1189, 26446, 5098, 1723, 3462, 281, 341, 7426, 13, 400, 370, 436, 645, 534, 11, 293, 436], "temperature": 0.0, "avg_logprob": -0.12159858782266833, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.4509181710309349e-05}, {"id": 42, "seek": 18984, "start": 206.92000000000002, "end": 210.52, "text": " couldn't get any sort of explanation and there was no appeals or recourse process", "tokens": [2809, 380, 483, 604, 1333, 295, 10835, 293, 456, 390, 572, 32603, 420, 850, 13656, 1399], "temperature": 0.0, "avg_logprob": -0.12159858782266833, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.4509181710309349e-05}, {"id": 43, "seek": 18984, "start": 210.52, "end": 215.52, "text": " in place. And eventually this all came out through a lengthy court case, but it's", "tokens": [294, 1081, 13, 400, 4728, 341, 439, 1361, 484, 807, 257, 35374, 4753, 1389, 11, 457, 309, 311], "temperature": 0.0, "avg_logprob": -0.12159858782266833, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.4509181710309349e-05}, {"id": 44, "seek": 21552, "start": 215.52, "end": 219.88000000000002, "text": " something where it caused a lot of suffering in the meantime. And so", "tokens": [746, 689, 309, 7008, 257, 688, 295, 7755, 294, 264, 14991, 13, 400, 370], "temperature": 0.0, "avg_logprob": -0.1252739107286608, "compression_ratio": 1.5928571428571427, "no_speech_prob": 1.4969784388085827e-05}, {"id": 45, "seek": 21552, "start": 219.88000000000002, "end": 223.52, "text": " it's really important to implement systems with a way to identify and", "tokens": [309, 311, 534, 1021, 281, 4445, 3652, 365, 257, 636, 281, 5876, 293], "temperature": 0.0, "avg_logprob": -0.1252739107286608, "compression_ratio": 1.5928571428571427, "no_speech_prob": 1.4969784388085827e-05}, {"id": 46, "seek": 21552, "start": 223.52, "end": 228.08, "text": " address mistakes and to do that quickly and in a way that hopefully minimizes", "tokens": [2985, 8038, 293, 281, 360, 300, 2661, 293, 294, 257, 636, 300, 4696, 4464, 5660], "temperature": 0.0, "avg_logprob": -0.1252739107286608, "compression_ratio": 1.5928571428571427, "no_speech_prob": 1.4969784388085827e-05}, {"id": 47, "seek": 21552, "start": 228.08, "end": 232.76000000000002, "text": " damage. Because we all know software can have bugs, our code can behave in", "tokens": [4344, 13, 1436, 321, 439, 458, 4722, 393, 362, 15120, 11, 527, 3089, 393, 15158, 294], "temperature": 0.0, "avg_logprob": -0.1252739107286608, "compression_ratio": 1.5928571428571427, "no_speech_prob": 1.4969784388085827e-05}, {"id": 48, "seek": 21552, "start": 232.76000000000002, "end": 237.84, "text": " unexpected ways, and we need to be prepared for that. I wrote more about", "tokens": [13106, 2098, 11, 293, 321, 643, 281, 312, 4927, 337, 300, 13, 286, 4114, 544, 466], "temperature": 0.0, "avg_logprob": -0.1252739107286608, "compression_ratio": 1.5928571428571427, "no_speech_prob": 1.4969784388085827e-05}, {"id": 49, "seek": 21552, "start": 237.84, "end": 245.04000000000002, "text": " this idea in a post two years ago, What HBR Gets Wrong About Algorithms and Bias.", "tokens": [341, 1558, 294, 257, 2183, 732, 924, 2057, 11, 708, 389, 11609, 460, 1385, 28150, 7769, 35014, 6819, 2592, 293, 363, 4609, 13], "temperature": 0.0, "avg_logprob": -0.1252739107286608, "compression_ratio": 1.5928571428571427, "no_speech_prob": 1.4969784388085827e-05}, {"id": 50, "seek": 24504, "start": 245.04, "end": 250.2, "text": " And then third case study that everyone should know about. So this is Latonya", "tokens": [400, 550, 2636, 1389, 2979, 300, 1518, 820, 458, 466, 13, 407, 341, 307, 7354, 44727], "temperature": 0.0, "avg_logprob": -0.12331105093670706, "compression_ratio": 1.6892857142857143, "no_speech_prob": 1.8341122995479964e-05}, {"id": 51, "seek": 24504, "start": 250.2, "end": 254.39999999999998, "text": " Sweeney, who's director of the data privacy lab at Harvard. She has a PhD in", "tokens": [318, 1259, 2030, 11, 567, 311, 5391, 295, 264, 1412, 11427, 2715, 412, 13378, 13, 1240, 575, 257, 14476, 294], "temperature": 0.0, "avg_logprob": -0.12331105093670706, "compression_ratio": 1.6892857142857143, "no_speech_prob": 1.8341122995479964e-05}, {"id": 52, "seek": 24504, "start": 254.39999999999998, "end": 258.96, "text": " computer science and she noticed several years ago that when you Google her name", "tokens": [3820, 3497, 293, 750, 5694, 2940, 924, 2057, 300, 562, 291, 3329, 720, 1315], "temperature": 0.0, "avg_logprob": -0.12331105093670706, "compression_ratio": 1.6892857142857143, "no_speech_prob": 1.8341122995479964e-05}, {"id": 53, "seek": 24504, "start": 258.96, "end": 264.12, "text": " you would get these ads saying Latonya Sweeney arrested, implying that she has a", "tokens": [291, 576, 483, 613, 10342, 1566, 7354, 44727, 318, 1259, 2030, 12469, 11, 704, 7310, 300, 750, 575, 257], "temperature": 0.0, "avg_logprob": -0.12331105093670706, "compression_ratio": 1.6892857142857143, "no_speech_prob": 1.8341122995479964e-05}, {"id": 54, "seek": 24504, "start": 264.12, "end": 267.88, "text": " criminal record. She's the only Latonya Sweeney and she has never been arrested.", "tokens": [8628, 2136, 13, 1240, 311, 264, 787, 7354, 44727, 318, 1259, 2030, 293, 750, 575, 1128, 668, 12469, 13], "temperature": 0.0, "avg_logprob": -0.12331105093670706, "compression_ratio": 1.6892857142857143, "no_speech_prob": 1.8341122995479964e-05}, {"id": 55, "seek": 24504, "start": 267.88, "end": 271.84, "text": " She paid $50 to the background check company and confirmed that she's never", "tokens": [1240, 4835, 1848, 2803, 281, 264, 3678, 1520, 2237, 293, 11341, 300, 750, 311, 1128], "temperature": 0.0, "avg_logprob": -0.12331105093670706, "compression_ratio": 1.6892857142857143, "no_speech_prob": 1.8341122995479964e-05}, {"id": 56, "seek": 27184, "start": 271.84, "end": 276.03999999999996, "text": " been arrested. She tried Googling some other names and she noticed, for example,", "tokens": [668, 12469, 13, 1240, 3031, 45005, 1688, 512, 661, 5288, 293, 750, 5694, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.16990386522733247, "compression_ratio": 1.6642335766423357, "no_speech_prob": 2.5068578906939365e-05}, {"id": 57, "seek": 27184, "start": 276.03999999999996, "end": 281.35999999999996, "text": " Kristen Lindquist got much more neutral ads that just say we found", "tokens": [35107, 16828, 358, 468, 658, 709, 544, 10598, 10342, 300, 445, 584, 321, 1352], "temperature": 0.0, "avg_logprob": -0.16990386522733247, "compression_ratio": 1.6642335766423357, "no_speech_prob": 2.5068578906939365e-05}, {"id": 58, "seek": 27184, "start": 281.35999999999996, "end": 285.03999999999996, "text": " Kristen Lindquist even though Kristen Lindquist has been arrested three times.", "tokens": [35107, 16828, 358, 468, 754, 1673, 35107, 16828, 358, 468, 575, 668, 12469, 1045, 1413, 13], "temperature": 0.0, "avg_logprob": -0.16990386522733247, "compression_ratio": 1.6642335766423357, "no_speech_prob": 2.5068578906939365e-05}, {"id": 59, "seek": 27184, "start": 285.03999999999996, "end": 290.35999999999996, "text": " And so being a computer scientist, Dr. Sweeney studied this very systematically.", "tokens": [400, 370, 885, 257, 3820, 12662, 11, 2491, 13, 318, 1259, 2030, 9454, 341, 588, 39531, 13], "temperature": 0.0, "avg_logprob": -0.16990386522733247, "compression_ratio": 1.6642335766423357, "no_speech_prob": 2.5068578906939365e-05}, {"id": 60, "seek": 27184, "start": 290.35999999999996, "end": 296.55999999999995, "text": " She looked at over 2,000 names and found that this pattern held in which", "tokens": [1240, 2956, 412, 670, 568, 11, 1360, 5288, 293, 1352, 300, 341, 5102, 5167, 294, 597], "temperature": 0.0, "avg_logprob": -0.16990386522733247, "compression_ratio": 1.6642335766423357, "no_speech_prob": 2.5068578906939365e-05}, {"id": 61, "seek": 27184, "start": 296.55999999999995, "end": 300.64, "text": " disproportionately African-American names were getting these ads suggesting", "tokens": [43397, 7312, 12, 14604, 5288, 645, 1242, 613, 10342, 18094], "temperature": 0.0, "avg_logprob": -0.16990386522733247, "compression_ratio": 1.6642335766423357, "no_speech_prob": 2.5068578906939365e-05}, {"id": 62, "seek": 30064, "start": 300.64, "end": 304.12, "text": " that the person had a criminal record regardless of whether they did and", "tokens": [300, 264, 954, 632, 257, 8628, 2136, 10060, 295, 1968, 436, 630, 293], "temperature": 0.0, "avg_logprob": -0.12766428743855338, "compression_ratio": 1.6075949367088607, "no_speech_prob": 1.5688703570049256e-05}, {"id": 63, "seek": 30064, "start": 304.12, "end": 309.76, "text": " traditionally European-American or white names were getting more neutral ads. And", "tokens": [19067, 6473, 12, 14604, 420, 2418, 5288, 645, 1242, 544, 10598, 10342, 13, 400], "temperature": 0.0, "avg_logprob": -0.12766428743855338, "compression_ratio": 1.6075949367088607, "no_speech_prob": 1.5688703570049256e-05}, {"id": 64, "seek": 30064, "start": 309.76, "end": 316.0, "text": " this problem of kind of bias in advertising shows up a ton. Advertising", "tokens": [341, 1154, 295, 733, 295, 12577, 294, 13097, 3110, 493, 257, 2952, 13, 1999, 3281, 3436], "temperature": 0.0, "avg_logprob": -0.12766428743855338, "compression_ratio": 1.6075949367088607, "no_speech_prob": 1.5688703570049256e-05}, {"id": 65, "seek": 30064, "start": 316.0, "end": 323.12, "text": " is kind of the profit model for most of the major tech platforms and it kind of", "tokens": [307, 733, 295, 264, 7475, 2316, 337, 881, 295, 264, 2563, 7553, 9473, 293, 309, 733, 295], "temperature": 0.0, "avg_logprob": -0.12766428743855338, "compression_ratio": 1.6075949367088607, "no_speech_prob": 1.5688703570049256e-05}, {"id": 66, "seek": 30064, "start": 323.12, "end": 327.84, "text": " continues to pop up in high-impact ways. Just last year there was research", "tokens": [6515, 281, 1665, 493, 294, 1090, 12, 8814, 578, 2098, 13, 1449, 1036, 1064, 456, 390, 2132], "temperature": 0.0, "avg_logprob": -0.12766428743855338, "compression_ratio": 1.6075949367088607, "no_speech_prob": 1.5688703570049256e-05}, {"id": 67, "seek": 32784, "start": 327.84, "end": 332.08, "text": " showing how Facebook's ad system discriminates even when the person", "tokens": [4099, 577, 4384, 311, 614, 1185, 20828, 1024, 754, 562, 264, 954], "temperature": 0.0, "avg_logprob": -0.1337874083392388, "compression_ratio": 1.6738351254480286, "no_speech_prob": 4.468183033168316e-05}, {"id": 68, "seek": 32784, "start": 332.08, "end": 337.0, "text": " placing the ad is not trying to do so. So for instance, the same housing ad, exact", "tokens": [17221, 264, 614, 307, 406, 1382, 281, 360, 370, 13, 407, 337, 5197, 11, 264, 912, 6849, 614, 11, 1900], "temperature": 0.0, "avg_logprob": -0.1337874083392388, "compression_ratio": 1.6738351254480286, "no_speech_prob": 4.468183033168316e-05}, {"id": 69, "seek": 32784, "start": 337.0, "end": 342.12, "text": " same text, if you change the photo between a white family and a black family", "tokens": [912, 2487, 11, 498, 291, 1319, 264, 5052, 1296, 257, 2418, 1605, 293, 257, 2211, 1605], "temperature": 0.0, "avg_logprob": -0.1337874083392388, "compression_ratio": 1.6738351254480286, "no_speech_prob": 4.468183033168316e-05}, {"id": 70, "seek": 32784, "start": 342.12, "end": 345.67999999999995, "text": " it's served to very different audiences. So this is something that can really", "tokens": [309, 311, 7584, 281, 588, 819, 15479, 13, 407, 341, 307, 746, 300, 393, 534], "temperature": 0.0, "avg_logprob": -0.1337874083392388, "compression_ratio": 1.6738351254480286, "no_speech_prob": 4.468183033168316e-05}, {"id": 71, "seek": 32784, "start": 345.67999999999995, "end": 348.55999999999995, "text": " impact people when they're looking for housing, when they're applying for jobs,", "tokens": [2712, 561, 562, 436, 434, 1237, 337, 6849, 11, 562, 436, 434, 9275, 337, 4782, 11], "temperature": 0.0, "avg_logprob": -0.1337874083392388, "compression_ratio": 1.6738351254480286, "no_speech_prob": 4.468183033168316e-05}, {"id": 72, "seek": 32784, "start": 348.55999999999995, "end": 357.55999999999995, "text": " and is a definite area of concern. So now I want to kind of step back and ask why", "tokens": [293, 307, 257, 25131, 1859, 295, 3136, 13, 407, 586, 286, 528, 281, 733, 295, 1823, 646, 293, 1029, 983], "temperature": 0.0, "avg_logprob": -0.1337874083392388, "compression_ratio": 1.6738351254480286, "no_speech_prob": 4.468183033168316e-05}, {"id": 73, "seek": 35756, "start": 357.56, "end": 363.84, "text": " why does this matter? And so a very kind of extreme example is just that", "tokens": [983, 775, 341, 1871, 30, 400, 370, 257, 588, 733, 295, 8084, 1365, 307, 445, 300], "temperature": 0.0, "avg_logprob": -0.14613167270199284, "compression_ratio": 1.5245901639344261, "no_speech_prob": 7.599824311910197e-05}, {"id": 74, "seek": 35756, "start": 363.84, "end": 369.2, "text": " data collection has played a pivotal role in several genocides including", "tokens": [1412, 5765, 575, 3737, 257, 39078, 3090, 294, 2940, 1049, 905, 1875, 3009], "temperature": 0.0, "avg_logprob": -0.14613167270199284, "compression_ratio": 1.5245901639344261, "no_speech_prob": 7.599824311910197e-05}, {"id": 75, "seek": 35756, "start": 369.2, "end": 374.24, "text": " the Holocaust. And so this is a photo of Adolf Hitler meeting with the", "tokens": [264, 28399, 13, 400, 370, 341, 307, 257, 5052, 295, 1999, 7491, 19038, 3440, 365, 264], "temperature": 0.0, "avg_logprob": -0.14613167270199284, "compression_ratio": 1.5245901639344261, "no_speech_prob": 7.599824311910197e-05}, {"id": 76, "seek": 35756, "start": 374.24, "end": 382.28, "text": " CEO of IBM at the time. I think this photo was taken in 1937. And IBM continued", "tokens": [9282, 295, 23487, 412, 264, 565, 13, 286, 519, 341, 5052, 390, 2726, 294, 1294, 12851, 13, 400, 23487, 7014], "temperature": 0.0, "avg_logprob": -0.14613167270199284, "compression_ratio": 1.5245901639344261, "no_speech_prob": 7.599824311910197e-05}, {"id": 77, "seek": 35756, "start": 382.28, "end": 385.8, "text": " to partner with the Nazis kind of long past when many other companies broke", "tokens": [281, 4975, 365, 264, 29812, 733, 295, 938, 1791, 562, 867, 661, 3431, 6902], "temperature": 0.0, "avg_logprob": -0.14613167270199284, "compression_ratio": 1.5245901639344261, "no_speech_prob": 7.599824311910197e-05}, {"id": 78, "seek": 38580, "start": 385.8, "end": 391.6, "text": " their ties. They produced computers that were used in concentration camps to code", "tokens": [641, 14039, 13, 814, 7126, 10807, 300, 645, 1143, 294, 9856, 16573, 281, 3089], "temperature": 0.0, "avg_logprob": -0.13326674526177565, "compression_ratio": 1.6055363321799307, "no_speech_prob": 5.142998998053372e-05}, {"id": 79, "seek": 38580, "start": 391.6, "end": 398.8, "text": " whether people were Jewish, how they were executed. And this is also different from", "tokens": [1968, 561, 645, 9246, 11, 577, 436, 645, 17577, 13, 400, 341, 307, 611, 819, 490], "temperature": 0.0, "avg_logprob": -0.13326674526177565, "compression_ratio": 1.6055363321799307, "no_speech_prob": 5.142998998053372e-05}, {"id": 80, "seek": 38580, "start": 398.8, "end": 401.8, "text": " now where you might sell somebody a computer and they never hear from them", "tokens": [586, 689, 291, 1062, 3607, 2618, 257, 3820, 293, 436, 1128, 1568, 490, 552], "temperature": 0.0, "avg_logprob": -0.13326674526177565, "compression_ratio": 1.6055363321799307, "no_speech_prob": 5.142998998053372e-05}, {"id": 81, "seek": 38580, "start": 401.8, "end": 405.12, "text": " again. These machines require a lot of maintenance and kind of ongoing", "tokens": [797, 13, 1981, 8379, 3651, 257, 688, 295, 11258, 293, 733, 295, 10452], "temperature": 0.0, "avg_logprob": -0.13326674526177565, "compression_ratio": 1.6055363321799307, "no_speech_prob": 5.142998998053372e-05}, {"id": 82, "seek": 38580, "start": 405.12, "end": 410.0, "text": " relationship with vendors to kind of upkeep and repair them. It's something", "tokens": [2480, 365, 22056, 281, 733, 295, 493, 16055, 293, 10535, 552, 13, 467, 311, 746], "temperature": 0.0, "avg_logprob": -0.13326674526177565, "compression_ratio": 1.6055363321799307, "no_speech_prob": 5.142998998053372e-05}, {"id": 83, "seek": 38580, "start": 410.0, "end": 415.28000000000003, "text": " that a Swiss judge ruled. It does not seem unreasonable to deduce that IBM's", "tokens": [300, 257, 21965, 6995, 20077, 13, 467, 775, 406, 1643, 41730, 281, 4172, 4176, 300, 23487, 311], "temperature": 0.0, "avg_logprob": -0.13326674526177565, "compression_ratio": 1.6055363321799307, "no_speech_prob": 5.142998998053372e-05}, {"id": 84, "seek": 41528, "start": 415.28, "end": 419.0, "text": " technical assistance facilitated the task of the Nazis in the Commission of", "tokens": [6191, 9683, 10217, 18266, 264, 5633, 295, 264, 29812, 294, 264, 10766, 295], "temperature": 0.0, "avg_logprob": -0.15547264571738453, "compression_ratio": 1.6013745704467355, "no_speech_prob": 3.119440589216538e-05}, {"id": 85, "seek": 41528, "start": 419.0, "end": 423.67999999999995, "text": " their Crimes Against Humanity acts, also involving accountancy and classification", "tokens": [641, 4779, 1532, 29995, 10294, 507, 10672, 11, 611, 17030, 2696, 6717, 293, 21538], "temperature": 0.0, "avg_logprob": -0.15547264571738453, "compression_ratio": 1.6013745704467355, "no_speech_prob": 3.119440589216538e-05}, {"id": 86, "seek": 41528, "start": 423.67999999999995, "end": 428.0, "text": " by IBM machines and utilized in the concentration camps themselves. I'm told", "tokens": [538, 23487, 8379, 293, 28158, 294, 264, 9856, 16573, 2969, 13, 286, 478, 1907], "temperature": 0.0, "avg_logprob": -0.15547264571738453, "compression_ratio": 1.6013745704467355, "no_speech_prob": 3.119440589216538e-05}, {"id": 87, "seek": 41528, "start": 428.0, "end": 432.08, "text": " that they haven't gotten around to apologizing yet. Oh that's I guess", "tokens": [300, 436, 2378, 380, 5768, 926, 281, 9472, 3319, 1939, 13, 876, 300, 311, 286, 2041], "temperature": 0.0, "avg_logprob": -0.15547264571738453, "compression_ratio": 1.6013745704467355, "no_speech_prob": 3.119440589216538e-05}, {"id": 88, "seek": 41528, "start": 432.08, "end": 438.2, "text": " they've been busy. Terrible too, yeah. Okay, yeah. And so this is a very kind of a", "tokens": [436, 600, 668, 5856, 13, 6564, 4457, 886, 11, 1338, 13, 1033, 11, 1338, 13, 400, 370, 341, 307, 257, 588, 733, 295, 257], "temperature": 0.0, "avg_logprob": -0.15547264571738453, "compression_ratio": 1.6013745704467355, "no_speech_prob": 3.119440589216538e-05}, {"id": 89, "seek": 41528, "start": 438.2, "end": 444.64, "text": " very sobering example, but I think it's important to keep in mind kind of what", "tokens": [588, 26212, 278, 1365, 11, 457, 286, 519, 309, 311, 1021, 281, 1066, 294, 1575, 733, 295, 437], "temperature": 0.0, "avg_logprob": -0.15547264571738453, "compression_ratio": 1.6013745704467355, "no_speech_prob": 3.119440589216538e-05}, {"id": 90, "seek": 44464, "start": 444.64, "end": 449.8, "text": " can go wrong and how technology can be used for harm, for very very terrible", "tokens": [393, 352, 2085, 293, 577, 2899, 393, 312, 1143, 337, 6491, 11, 337, 588, 588, 6237], "temperature": 0.0, "avg_logprob": -0.1516167824728447, "compression_ratio": 1.7265917602996255, "no_speech_prob": 4.83194635307882e-05}, {"id": 91, "seek": 44464, "start": 449.8, "end": 455.24, "text": " harm. And so this just kind of raises a question questions that we all need to", "tokens": [6491, 13, 400, 370, 341, 445, 733, 295, 19658, 257, 1168, 1651, 300, 321, 439, 643, 281], "temperature": 0.0, "avg_logprob": -0.1516167824728447, "compression_ratio": 1.7265917602996255, "no_speech_prob": 4.83194635307882e-05}, {"id": 92, "seek": 44464, "start": 455.24, "end": 458.56, "text": " grapple with of how would you feel if you discovered that you had been part of a", "tokens": [27165, 306, 365, 295, 577, 576, 291, 841, 498, 291, 6941, 300, 291, 632, 668, 644, 295, 257], "temperature": 0.0, "avg_logprob": -0.1516167824728447, "compression_ratio": 1.7265917602996255, "no_speech_prob": 4.83194635307882e-05}, {"id": 93, "seek": 44464, "start": 458.56, "end": 462.88, "text": " system that ended up hurting society? Would you even know? Would you be", "tokens": [1185, 300, 4590, 493, 17744, 4086, 30, 6068, 291, 754, 458, 30, 6068, 291, 312], "temperature": 0.0, "avg_logprob": -0.1516167824728447, "compression_ratio": 1.7265917602996255, "no_speech_prob": 4.83194635307882e-05}, {"id": 94, "seek": 44464, "start": 462.88, "end": 468.59999999999997, "text": " open to finding out kind of how things you had built may have been harmful?", "tokens": [1269, 281, 5006, 484, 733, 295, 577, 721, 291, 632, 3094, 815, 362, 668, 19727, 30], "temperature": 0.0, "avg_logprob": -0.1516167824728447, "compression_ratio": 1.7265917602996255, "no_speech_prob": 4.83194635307882e-05}, {"id": 95, "seek": 44464, "start": 468.59999999999997, "end": 472.36, "text": " And how can you help make sure this doesn't happen? And so I think these are", "tokens": [400, 577, 393, 291, 854, 652, 988, 341, 1177, 380, 1051, 30, 400, 370, 286, 519, 613, 366], "temperature": 0.0, "avg_logprob": -0.1516167824728447, "compression_ratio": 1.7265917602996255, "no_speech_prob": 4.83194635307882e-05}, {"id": 96, "seek": 47236, "start": 472.36, "end": 479.68, "text": " questions that we all all need to grapple with. It's also important to think", "tokens": [1651, 300, 321, 439, 439, 643, 281, 27165, 306, 365, 13, 467, 311, 611, 1021, 281, 519], "temperature": 0.0, "avg_logprob": -0.11803418265448676, "compression_ratio": 1.5495867768595042, "no_speech_prob": 2.97696897177957e-05}, {"id": 97, "seek": 47236, "start": 479.68, "end": 485.32, "text": " about unintended consequences, how your tech could be used or misused, whether", "tokens": [466, 49902, 10098, 11, 577, 428, 7553, 727, 312, 1143, 420, 3346, 4717, 11, 1968], "temperature": 0.0, "avg_logprob": -0.11803418265448676, "compression_ratio": 1.5495867768595042, "no_speech_prob": 2.97696897177957e-05}, {"id": 98, "seek": 47236, "start": 485.32, "end": 489.96000000000004, "text": " that's by harassers, by authoritarian governments, for propaganda or", "tokens": [300, 311, 538, 16910, 433, 11, 538, 37883, 11280, 11, 337, 22968, 420], "temperature": 0.0, "avg_logprob": -0.11803418265448676, "compression_ratio": 1.5495867768595042, "no_speech_prob": 2.97696897177957e-05}, {"id": 99, "seek": 47236, "start": 489.96000000000004, "end": 496.32, "text": " disinformation. And then on a kind of a more concrete level, you could even end", "tokens": [717, 20941, 13, 400, 550, 322, 257, 733, 295, 257, 544, 9859, 1496, 11, 291, 727, 754, 917], "temperature": 0.0, "avg_logprob": -0.11803418265448676, "compression_ratio": 1.5495867768595042, "no_speech_prob": 2.97696897177957e-05}, {"id": 100, "seek": 47236, "start": 496.32, "end": 500.04, "text": " up in jail. And so there was a Volkswagen engineer who got prison time", "tokens": [493, 294, 10511, 13, 400, 370, 456, 390, 257, 39856, 11403, 567, 658, 6168, 565], "temperature": 0.0, "avg_logprob": -0.11803418265448676, "compression_ratio": 1.5495867768595042, "no_speech_prob": 2.97696897177957e-05}, {"id": 101, "seek": 50004, "start": 500.04, "end": 505.44, "text": " for his role in the diesel cheating case. So if you remember, this is where", "tokens": [337, 702, 3090, 294, 264, 21258, 18309, 1389, 13, 407, 498, 291, 1604, 11, 341, 307, 689], "temperature": 0.0, "avg_logprob": -0.10033745818085722, "compression_ratio": 1.6444444444444444, "no_speech_prob": 3.881824159179814e-05}, {"id": 102, "seek": 50004, "start": 505.44, "end": 510.36, "text": " Volkswagen was cheating on emissions test and one of the kind of programmers", "tokens": [39856, 390, 18309, 322, 14607, 1500, 293, 472, 295, 264, 733, 295, 41504], "temperature": 0.0, "avg_logprob": -0.10033745818085722, "compression_ratio": 1.6444444444444444, "no_speech_prob": 3.881824159179814e-05}, {"id": 103, "seek": 50004, "start": 510.36, "end": 514.2, "text": " that was a part of that. And that person was just following orders from what", "tokens": [300, 390, 257, 644, 295, 300, 13, 400, 300, 954, 390, 445, 3480, 9470, 490, 437], "temperature": 0.0, "avg_logprob": -0.10033745818085722, "compression_ratio": 1.6444444444444444, "no_speech_prob": 3.881824159179814e-05}, {"id": 104, "seek": 50004, "start": 514.2, "end": 518.4, "text": " their boss told them to do, but that is not a good excuse for doing", "tokens": [641, 5741, 1907, 552, 281, 360, 11, 457, 300, 307, 406, 257, 665, 8960, 337, 884], "temperature": 0.0, "avg_logprob": -0.10033745818085722, "compression_ratio": 1.6444444444444444, "no_speech_prob": 3.881824159179814e-05}, {"id": 105, "seek": 50004, "start": 518.4, "end": 526.6800000000001, "text": " something that's unethical and so something to be aware of. So ethics is", "tokens": [746, 300, 311, 517, 3293, 804, 293, 370, 746, 281, 312, 3650, 295, 13, 407, 19769, 307], "temperature": 0.0, "avg_logprob": -0.10033745818085722, "compression_ratio": 1.6444444444444444, "no_speech_prob": 3.881824159179814e-05}, {"id": 106, "seek": 52668, "start": 526.68, "end": 531.12, "text": " the discipline dealing with what's good and bad. It's a set of moral principles.", "tokens": [264, 13635, 6260, 365, 437, 311, 665, 293, 1578, 13, 467, 311, 257, 992, 295, 9723, 9156, 13], "temperature": 0.0, "avg_logprob": -0.11456793546676636, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.0782223145943135e-05}, {"id": 107, "seek": 52668, "start": 531.12, "end": 536.88, "text": " It's not a set of answers, but it's kind of learning what sort of", "tokens": [467, 311, 406, 257, 992, 295, 6338, 11, 457, 309, 311, 733, 295, 2539, 437, 1333, 295], "temperature": 0.0, "avg_logprob": -0.11456793546676636, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.0782223145943135e-05}, {"id": 108, "seek": 52668, "start": 536.88, "end": 541.76, "text": " questions to ask and even how to weigh these decisions. And I'll say some more", "tokens": [1651, 281, 1029, 293, 754, 577, 281, 13843, 613, 5327, 13, 400, 286, 603, 584, 512, 544], "temperature": 0.0, "avg_logprob": -0.11456793546676636, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.0782223145943135e-05}, {"id": 109, "seek": 52668, "start": 541.76, "end": 547.3199999999999, "text": " about kind of ethical foundations and different ethical philosophies later", "tokens": [466, 733, 295, 18890, 22467, 293, 819, 18890, 14529, 530, 1780], "temperature": 0.0, "avg_logprob": -0.11456793546676636, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.0782223145943135e-05}, {"id": 110, "seek": 52668, "start": 547.3199999999999, "end": 552.7199999999999, "text": " on in this lesson. But first I'm going to kind of start with some use cases. Ethics", "tokens": [322, 294, 341, 6898, 13, 583, 700, 286, 478, 516, 281, 733, 295, 722, 365, 512, 764, 3331, 13, 10540, 1167], "temperature": 0.0, "avg_logprob": -0.11456793546676636, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.0782223145943135e-05}, {"id": 111, "seek": 55272, "start": 552.72, "end": 557.4, "text": " is not the same as religion, laws, social norms, or feelings, although it does have", "tokens": [307, 406, 264, 912, 382, 7561, 11, 6064, 11, 2093, 24357, 11, 420, 6640, 11, 4878, 309, 775, 362], "temperature": 0.0, "avg_logprob": -0.0955881821481805, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.1443082005134784e-05}, {"id": 112, "seek": 55272, "start": 557.4, "end": 563.84, "text": " overlap with all these things. It's not a fixed set of rules. It's well-founded", "tokens": [19959, 365, 439, 613, 721, 13, 467, 311, 406, 257, 6806, 992, 295, 4474, 13, 467, 311, 731, 12, 49547], "temperature": 0.0, "avg_logprob": -0.0955881821481805, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.1443082005134784e-05}, {"id": 113, "seek": 55272, "start": 563.84, "end": 568.36, "text": " standards of right and wrong. And this is something where clearly not everybody", "tokens": [7787, 295, 558, 293, 2085, 13, 400, 341, 307, 746, 689, 4448, 406, 2201], "temperature": 0.0, "avg_logprob": -0.0955881821481805, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.1443082005134784e-05}, {"id": 114, "seek": 55272, "start": 568.36, "end": 573.44, "text": " agrees on the ethical action in every case, but that doesn't mean that kind of", "tokens": [26383, 322, 264, 18890, 3069, 294, 633, 1389, 11, 457, 300, 1177, 380, 914, 300, 733, 295], "temperature": 0.0, "avg_logprob": -0.0955881821481805, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.1443082005134784e-05}, {"id": 115, "seek": 55272, "start": 573.44, "end": 577.6800000000001, "text": " anything goes or that all actions are considered equally ethical. There are", "tokens": [1340, 1709, 420, 300, 439, 5909, 366, 4888, 12309, 18890, 13, 821, 366], "temperature": 0.0, "avg_logprob": -0.0955881821481805, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.1443082005134784e-05}, {"id": 116, "seek": 57768, "start": 577.68, "end": 583.1999999999999, "text": " many things that are widely agreed upon and there are kind of philosophical", "tokens": [867, 721, 300, 366, 13371, 9166, 3564, 293, 456, 366, 733, 295, 25066], "temperature": 0.0, "avg_logprob": -0.14213188716343472, "compression_ratio": 1.6766917293233083, "no_speech_prob": 1.6698384570190683e-05}, {"id": 117, "seek": 57768, "start": 583.1999999999999, "end": 587.5999999999999, "text": " underpinnings for kind of making these decisions. And ethics is also the", "tokens": [833, 17836, 24451, 337, 733, 295, 1455, 613, 5327, 13, 400, 19769, 307, 611, 264], "temperature": 0.0, "avg_logprob": -0.14213188716343472, "compression_ratio": 1.6766917293233083, "no_speech_prob": 1.6698384570190683e-05}, {"id": 118, "seek": 57768, "start": 587.5999999999999, "end": 591.28, "text": " ongoing study and development of our ethical standards. It's a kind of", "tokens": [10452, 2979, 293, 3250, 295, 527, 18890, 7787, 13, 467, 311, 257, 733, 295], "temperature": 0.0, "avg_logprob": -0.14213188716343472, "compression_ratio": 1.6766917293233083, "no_speech_prob": 1.6698384570190683e-05}, {"id": 119, "seek": 57768, "start": 591.28, "end": 598.04, "text": " never-ending process of learning to kind of practice our ethical wisdom. And I'm", "tokens": [1128, 12, 2029, 1399, 295, 2539, 281, 733, 295, 3124, 527, 18890, 10712, 13, 400, 286, 478], "temperature": 0.0, "avg_logprob": -0.14213188716343472, "compression_ratio": 1.6766917293233083, "no_speech_prob": 1.6698384570190683e-05}, {"id": 120, "seek": 57768, "start": 598.04, "end": 602.24, "text": " going to refer it several times to, so here I'm referring to a few articles", "tokens": [516, 281, 2864, 309, 2940, 1413, 281, 11, 370, 510, 286, 478, 13761, 281, 257, 1326, 11290], "temperature": 0.0, "avg_logprob": -0.14213188716343472, "compression_ratio": 1.6766917293233083, "no_speech_prob": 1.6698384570190683e-05}, {"id": 121, "seek": 57768, "start": 602.24, "end": 607.4399999999999, "text": " from the Marcula Center for Tech Ethics at Santa Clara University, in", "tokens": [490, 264, 18460, 3780, 5169, 337, 13795, 10540, 1167, 412, 9933, 32048, 3535, 11, 294], "temperature": 0.0, "avg_logprob": -0.14213188716343472, "compression_ratio": 1.6766917293233083, "no_speech_prob": 1.6698384570190683e-05}, {"id": 122, "seek": 60744, "start": 607.44, "end": 611.08, "text": " particular the work of Shannon Valor, Brian Greene, and Irina Reiku is", "tokens": [1729, 264, 589, 295, 28974, 7188, 284, 11, 10765, 14986, 1450, 11, 293, 9151, 1426, 1300, 24320, 307], "temperature": 0.0, "avg_logprob": -0.1704392603465489, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.00012722439714707434}, {"id": 123, "seek": 60744, "start": 611.08, "end": 614.7600000000001, "text": " fantastic and they have a lot of resources, some of which I'll circle back", "tokens": [5456, 293, 436, 362, 257, 688, 295, 3593, 11, 512, 295, 597, 286, 603, 6329, 646], "temperature": 0.0, "avg_logprob": -0.1704392603465489, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.00012722439714707434}, {"id": 124, "seek": 60744, "start": 614.7600000000001, "end": 620.6400000000001, "text": " to later in this talk. I spent years of my life studying ethics. It was my", "tokens": [281, 1780, 294, 341, 751, 13, 286, 4418, 924, 295, 452, 993, 7601, 19769, 13, 467, 390, 452], "temperature": 0.0, "avg_logprob": -0.1704392603465489, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.00012722439714707434}, {"id": 125, "seek": 60744, "start": 620.6400000000001, "end": 626.58, "text": " major at university and so much time on the question of what is ethics. I think", "tokens": [2563, 412, 5454, 293, 370, 709, 565, 322, 264, 1168, 295, 437, 307, 19769, 13, 286, 519], "temperature": 0.0, "avg_logprob": -0.1704392603465489, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.00012722439714707434}, {"id": 126, "seek": 60744, "start": 626.58, "end": 630.2800000000001, "text": " my takeaway from that is studying the philosophy ethics was not particularly", "tokens": [452, 30681, 490, 300, 307, 7601, 264, 10675, 19769, 390, 406, 4098], "temperature": 0.0, "avg_logprob": -0.1704392603465489, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.00012722439714707434}, {"id": 127, "seek": 60744, "start": 630.2800000000001, "end": 634.9200000000001, "text": " helpful in learning about ethics. Yes and I will try to keep this kind of very", "tokens": [4961, 294, 2539, 466, 19769, 13, 1079, 293, 286, 486, 853, 281, 1066, 341, 733, 295, 588], "temperature": 0.0, "avg_logprob": -0.1704392603465489, "compression_ratio": 1.6462093862815885, "no_speech_prob": 0.00012722439714707434}, {"id": 128, "seek": 63492, "start": 634.92, "end": 641.28, "text": " very applied and very practical, also very kind of tech industry specific of", "tokens": [588, 6456, 293, 588, 8496, 11, 611, 588, 733, 295, 7553, 3518, 2685, 295], "temperature": 0.0, "avg_logprob": -0.19524744937294408, "compression_ratio": 1.572, "no_speech_prob": 2.143630808859598e-05}, {"id": 129, "seek": 63492, "start": 641.28, "end": 644.5999999999999, "text": " what what do you need in terms of applied ethics. Yeah, the Marcula Center is", "tokens": [437, 437, 360, 291, 643, 294, 2115, 295, 6456, 19769, 13, 865, 11, 264, 18460, 3780, 5169, 307], "temperature": 0.0, "avg_logprob": -0.19524744937294408, "compression_ratio": 1.572, "no_speech_prob": 2.143630808859598e-05}, {"id": 130, "seek": 63492, "start": 644.5999999999999, "end": 649.8, "text": " great. They somehow they take stuff that I thought was super dry and turn it into", "tokens": [869, 13, 814, 6063, 436, 747, 1507, 300, 286, 1194, 390, 1687, 4016, 293, 1261, 309, 666], "temperature": 0.0, "avg_logprob": -0.19524744937294408, "compression_ratio": 1.572, "no_speech_prob": 2.143630808859598e-05}, {"id": 131, "seek": 63492, "start": 649.8, "end": 658.4399999999999, "text": " useful checklists and things. I did want to note this is really neat. So Casey", "tokens": [4420, 1520, 36693, 293, 721, 13, 286, 630, 528, 281, 3637, 341, 307, 534, 10654, 13, 407, 27369], "temperature": 0.0, "avg_logprob": -0.19524744937294408, "compression_ratio": 1.572, "no_speech_prob": 2.143630808859598e-05}, {"id": 132, "seek": 63492, "start": 658.4399999999999, "end": 662.68, "text": " Fiesler is a professor at University of Colorado that I really admire and she", "tokens": [479, 530, 1918, 307, 257, 8304, 412, 3535, 295, 15786, 300, 286, 534, 21951, 293, 750], "temperature": 0.0, "avg_logprob": -0.19524744937294408, "compression_ratio": 1.572, "no_speech_prob": 2.143630808859598e-05}, {"id": 133, "seek": 66268, "start": 662.68, "end": 667.7199999999999, "text": " created a crowd-sourced spreadsheet of tech ethics syllabi. This was maybe two", "tokens": [2942, 257, 6919, 12, 82, 396, 1232, 27733, 295, 7553, 19769, 20223, 18884, 13, 639, 390, 1310, 732], "temperature": 0.0, "avg_logprob": -0.11822238461724643, "compression_ratio": 1.7906976744186047, "no_speech_prob": 8.34559541544877e-05}, {"id": 134, "seek": 66268, "start": 667.7199999999999, "end": 672.7199999999999, "text": " years ago and got over 200 syllabi entered into this this crowd-sourced", "tokens": [924, 2057, 293, 658, 670, 2331, 20223, 18884, 9065, 666, 341, 341, 6919, 12, 82, 396, 1232], "temperature": 0.0, "avg_logprob": -0.11822238461724643, "compression_ratio": 1.7906976744186047, "no_speech_prob": 8.34559541544877e-05}, {"id": 135, "seek": 66268, "start": 672.7199999999999, "end": 677.88, "text": " spreadsheet and then she did a meta analysis on them of kind of looking at", "tokens": [27733, 293, 550, 750, 630, 257, 19616, 5215, 322, 552, 295, 733, 295, 1237, 412], "temperature": 0.0, "avg_logprob": -0.11822238461724643, "compression_ratio": 1.7906976744186047, "no_speech_prob": 8.34559541544877e-05}, {"id": 136, "seek": 66268, "start": 677.88, "end": 681.04, "text": " all sorts of aspects of the syllabi and what's being taught and how it's being", "tokens": [439, 7527, 295, 7270, 295, 264, 20223, 18884, 293, 437, 311, 885, 5928, 293, 577, 309, 311, 885], "temperature": 0.0, "avg_logprob": -0.11822238461724643, "compression_ratio": 1.7906976744186047, "no_speech_prob": 8.34559541544877e-05}, {"id": 137, "seek": 66268, "start": 681.04, "end": 686.56, "text": " taught and published a paper on it. What do we teach when we teach tech ethics?", "tokens": [5928, 293, 6572, 257, 3035, 322, 309, 13, 708, 360, 321, 2924, 562, 321, 2924, 7553, 19769, 30], "temperature": 0.0, "avg_logprob": -0.11822238461724643, "compression_ratio": 1.7906976744186047, "no_speech_prob": 8.34559541544877e-05}, {"id": 138, "seek": 66268, "start": 686.56, "end": 692.56, "text": " And a few interesting things about it is it raises there are a lot of ongoing", "tokens": [400, 257, 1326, 1880, 721, 466, 309, 307, 309, 19658, 456, 366, 257, 688, 295, 10452], "temperature": 0.0, "avg_logprob": -0.11822238461724643, "compression_ratio": 1.7906976744186047, "no_speech_prob": 8.34559541544877e-05}, {"id": 139, "seek": 69256, "start": 692.56, "end": 698.0799999999999, "text": " discussions and lack of agreement on how to how to best teach tech ethics. Should", "tokens": [11088, 293, 5011, 295, 8106, 322, 577, 281, 577, 281, 1151, 2924, 7553, 19769, 13, 6454], "temperature": 0.0, "avg_logprob": -0.12521334148588634, "compression_ratio": 1.754646840148699, "no_speech_prob": 6.921177555341274e-05}, {"id": 140, "seek": 69256, "start": 698.0799999999999, "end": 703.0, "text": " it be a standalone course versus worked into every course in the curriculum? Who", "tokens": [309, 312, 257, 37454, 1164, 5717, 2732, 666, 633, 1164, 294, 264, 14302, 30, 2102], "temperature": 0.0, "avg_logprob": -0.12521334148588634, "compression_ratio": 1.754646840148699, "no_speech_prob": 6.921177555341274e-05}, {"id": 141, "seek": 69256, "start": 703.0, "end": 708.76, "text": " should teach it? A computer scientist, a philosopher, or a sociologist? And and she", "tokens": [820, 2924, 309, 30, 316, 3820, 12662, 11, 257, 29805, 11, 420, 257, 3075, 9201, 30, 400, 293, 750], "temperature": 0.0, "avg_logprob": -0.12521334148588634, "compression_ratio": 1.754646840148699, "no_speech_prob": 6.921177555341274e-05}, {"id": 142, "seek": 69256, "start": 708.76, "end": 712.7199999999999, "text": " analyzed for the syllabi what was the course home and the instructor home and", "tokens": [28181, 337, 264, 20223, 18884, 437, 390, 264, 1164, 1280, 293, 264, 18499, 1280, 293], "temperature": 0.0, "avg_logprob": -0.12521334148588634, "compression_ratio": 1.754646840148699, "no_speech_prob": 6.921177555341274e-05}, {"id": 143, "seek": 69256, "start": 712.7199999999999, "end": 717.16, "text": " you can see that the the instructors came from a range of courses including", "tokens": [291, 393, 536, 300, 264, 264, 28367, 1361, 490, 257, 3613, 295, 7712, 3009], "temperature": 0.0, "avg_logprob": -0.12521334148588634, "compression_ratio": 1.754646840148699, "no_speech_prob": 6.921177555341274e-05}, {"id": 144, "seek": 69256, "start": 717.16, "end": 720.7199999999999, "text": " computer a range of disciplines. Computer science, information science,", "tokens": [3820, 257, 3613, 295, 21919, 13, 22289, 3497, 11, 1589, 3497, 11], "temperature": 0.0, "avg_logprob": -0.12521334148588634, "compression_ratio": 1.754646840148699, "no_speech_prob": 6.921177555341274e-05}, {"id": 145, "seek": 72072, "start": 720.72, "end": 726.8000000000001, "text": " philosophy, science and tech studies, engineering, law, math, business. What", "tokens": [10675, 11, 3497, 293, 7553, 5313, 11, 7043, 11, 2101, 11, 5221, 11, 1606, 13, 708], "temperature": 0.0, "avg_logprob": -0.1362880359996449, "compression_ratio": 1.5791666666666666, "no_speech_prob": 2.0782397768925875e-05}, {"id": 146, "seek": 72072, "start": 726.8000000000001, "end": 732.08, "text": " topics to cover? A huge range of topics that can be covered including law and", "tokens": [8378, 281, 2060, 30, 316, 2603, 3613, 295, 8378, 300, 393, 312, 5343, 3009, 2101, 293], "temperature": 0.0, "avg_logprob": -0.1362880359996449, "compression_ratio": 1.5791666666666666, "no_speech_prob": 2.0782397768925875e-05}, {"id": 147, "seek": 72072, "start": 732.08, "end": 736.96, "text": " policy, privacy and surveillance, inequality, justice and human rights,", "tokens": [3897, 11, 11427, 293, 18475, 11, 16970, 11, 6118, 293, 1952, 4601, 11], "temperature": 0.0, "avg_logprob": -0.1362880359996449, "compression_ratio": 1.5791666666666666, "no_speech_prob": 2.0782397768925875e-05}, {"id": 148, "seek": 72072, "start": 736.96, "end": 742.08, "text": " environmental impact, AI and robots, professional ethics, work and labor,", "tokens": [8303, 2712, 11, 7318, 293, 14733, 11, 4843, 19769, 11, 589, 293, 5938, 11], "temperature": 0.0, "avg_logprob": -0.1362880359996449, "compression_ratio": 1.5791666666666666, "no_speech_prob": 2.0782397768925875e-05}, {"id": 149, "seek": 72072, "start": 742.08, "end": 746.6800000000001, "text": " cybersecurity. The list goes on and on and so this is clearly more than can be", "tokens": [38765, 13, 440, 1329, 1709, 322, 293, 322, 293, 370, 341, 307, 4448, 544, 813, 393, 312], "temperature": 0.0, "avg_logprob": -0.1362880359996449, "compression_ratio": 1.5791666666666666, "no_speech_prob": 2.0782397768925875e-05}, {"id": 150, "seek": 74668, "start": 746.68, "end": 752.92, "text": " covered in any even a full semester length course and certainly not in kind", "tokens": [5343, 294, 604, 754, 257, 1577, 11894, 4641, 1164, 293, 3297, 406, 294, 733], "temperature": 0.0, "avg_logprob": -0.12639830907185873, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2187650504056364e-05}, {"id": 151, "seek": 74668, "start": 752.92, "end": 759.04, "text": " of a single single lecture. What learning outcomes? This is an area where there's a", "tokens": [295, 257, 2167, 2167, 7991, 13, 708, 2539, 10070, 30, 639, 307, 364, 1859, 689, 456, 311, 257], "temperature": 0.0, "avg_logprob": -0.12639830907185873, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2187650504056364e-05}, {"id": 152, "seek": 74668, "start": 759.04, "end": 762.4399999999999, "text": " little bit more agreement where kind of the number one skill that courses were", "tokens": [707, 857, 544, 8106, 689, 733, 295, 264, 1230, 472, 5389, 300, 7712, 645], "temperature": 0.0, "avg_logprob": -0.12639830907185873, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2187650504056364e-05}, {"id": 153, "seek": 74668, "start": 762.4399999999999, "end": 767.3599999999999, "text": " trying to teach was critique followed by spotting issues, making arguments. So a", "tokens": [1382, 281, 2924, 390, 25673, 6263, 538, 4008, 783, 2663, 11, 1455, 12869, 13, 407, 257], "temperature": 0.0, "avg_logprob": -0.12639830907185873, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2187650504056364e-05}, {"id": 154, "seek": 74668, "start": 767.3599999999999, "end": 771.12, "text": " lot of this is just even learning to spot what the issues are and how to", "tokens": [688, 295, 341, 307, 445, 754, 2539, 281, 4008, 437, 264, 2663, 366, 293, 577, 281], "temperature": 0.0, "avg_logprob": -0.12639830907185873, "compression_ratio": 1.6470588235294117, "no_speech_prob": 3.2187650504056364e-05}, {"id": 155, "seek": 77112, "start": 771.12, "end": 777.4, "text": " critically evaluate kind of a piece of technology or a design proposal to see", "tokens": [22797, 13059, 733, 295, 257, 2522, 295, 2899, 420, 257, 1715, 11494, 281, 536], "temperature": 0.0, "avg_logprob": -0.2158194138453557, "compression_ratio": 1.25, "no_speech_prob": 0.0003137571329716593}, {"id": 156, "seek": 77740, "start": 777.4, "end": 802.68, "text": " what could go wrong and what the risk is.", "tokens": [50364, 437, 727, 352, 2085, 293, 437, 264, 3148, 307, 13, 51628], "temperature": 0.0, "avg_logprob": -0.5855625225947454, "compression_ratio": 0.8723404255319149, "no_speech_prob": 0.0004140387463849038}], "language": "en"}