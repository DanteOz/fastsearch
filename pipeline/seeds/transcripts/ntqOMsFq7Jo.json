{"text": " Okay, hi everybody, can you see and hear okay? Great. And that response came back pretty quickly, so hopefully the latency is a bit lower. So Sam asked before we start to give you a reminder that his conference in San Francisco, TermoCon, today is the last day to get early bed tickets, so remember if you're interested, the code is fastai to get an extra 20% off. Okay, I was thinking I would do something crazy today, which is to do some live coding, which is going to be terrifying, so I'm not sure I've really done that before. Oh, hey there Max, welcome. So I was going to try and do some live coding to try to explain what transform does and try and justify why it does it and why it exists, to kind of try to basically see why we ended up where we ended up. I think we did something like 26 rewrites from scratch of the data transform functionality over a many month period because it was just super hard to get everything really easy and clear and, you know, maintainable and stuff like that, so I'm really happy with where we got to and that might be helpful for you to see why we got here. So maybe let's start by writing a function. So our function is going to be called neg and it's going to return negative, which you might recognize actually as the same as the operator.neg function, but we're writing it ourselves. So we can say neg 3, for instance, and that's how Python will do that. What if we did neg of some tuple? Let's create a tuple. 1, 3, neg of some tuple. Oh, doesn't work. That's actually kind of annoying because, I mean, it's the first thing to recognize is like this is, this is a behavior. It's a behavior that can be chosen from a number of possible behaviors and this particular behavior is how Python behaves and it's totally fine. But as you know, if we had an array, for instance, we would get different behavior. So one of the very, very, very nice things, in fact, to me the best part of Python is that Python lets us change how it behaves according to what we want for our domain. In the domain of data processing, we're particularly interested in tuples or tuple-like things because generally speaking, we're going to have an X and a Y. So for example, we would have an image and a label such as a pet. Other possibilities would be a source image and a mask segmentation. Another possibility would be an image tuple and a bool, which would be for Siamese. Segmentation, Siamese, that's a corization. Or it could be a tuple of continuous columns and categorical columns and a target column such as for tabular. So we would quite like Meg to behave for our tuple in a way that's different to Python and perhaps works a little bit more like the way that it works for array. So what we could do is we could repeat our function and to add new behavior to a function or a class in Python, you do it by adding a decorator. So we created a decorator called transform, which will cause our function to work the way we want. So now here we have it, minus one, minus three. So let's say we grab an image. And so we've got a file name FN, which is an image. So let's grab an image, which will be log image FN. OK, there's our image. And so let's create a tensor of the image as well, which we could do like this. OK, maybe just look at a few rows of it. OK. So we could, let's look at some rows more around the middle. OK. So we could, of course, do negative with that. No problem. Or if we had two of those in a tuple, we could create a tuple with a couple of images. And actually, this is not doing a negative. We're not getting a negative here. OK, interesting question. What am I doing wrong? Oh, yes, thanks, here. I mean, the reason my negative is wrong is because I have an unsigned int. So yes. Thank you, everybody. So let's make this a dot float. There we go. OK. And that will work on tuples as well. There we go. OK. So that's useful. And that would be particularly useful if I had an image as an input and an image as an output, such as a mask, you know, as an output or super resolution or something like that. So this is all looking pretty hopeful. So the next thing, let's try and make a more interesting function. Let's create a function called normalize. And that's going to take an image and a mean and a standard deviation. And we're going to return x minus m over s. So I could go normalize t image, comma, say the mean is somewhere around 127. And the standard deviation, let's say it's somewhere around 150. And again, let's actually let's just grab our subset. So it's a little bit easier to see what's going on. So we'll go the subset of the image is a few of those rows. OK, there we go. So we could check now t image.mean, t sub.mean, output t image.mean. I should say, let's say, normed image across that. So t sub, normed image.mean, OK, so that's the right idea. OK. So here's a function that would be actually pretty useful to have in a transformation pipeline. But I will note that we would generally want to run this particular transformation on the GPU. Because even though that doesn't look like a lot of work, it actually turns out that normalizing takes an astonishingly large amount of time as part of something like an ImageNet pipeline. So we would generally want to run it on the GPU. So by the time something has gotten to the GPU, it won't just be an image. It's the thing that our data set returns will be an image and a label. So let's create a image tuple will be image, comma, let's say it's a 1. So this is the kind of thing that we're actually going to be working with. Oh, we should use the tester. We're actually going to be working with on the GPU. So if we want to normalize that, and again, let's grab a mean and a standard deviation. And again, we have a problem. So let's make it a transform. So that's something that will be applied over tuples. So you'll see that none of the stuff we already have is going to change at all because, oh, I made a mistake. I made a mistake. I made a mistake. Oh, takes two additional arguments. That 4 we're given. Ah, yes, that's true. So we do have to use an equalizer. Okay, so one changes that we have to use named arguments. So now we can go M equals S equals. So there we go. So now it's working again. But oh, that's no good. It's also transformed our label, which is definitely not what we want. So we need some way to have it only apply to those things that we would want to normalize. We can't so as we saw, you can add a type annotation to say what to apply it to. The problem is that generally by the time you are getting through the data loader, your everything's everything's a tensor. So how can we decide which bits of our tuple to apply this to? So the answer is that we need to create things that inherit from a tensor. And so we have something called tensor base, which is just a base class for things that inherit the tensor. So we could go class my tensor image, which will inherit from tensor base. And I don't have to add any functionality to it. What I could just do is now say t image equals my tensor image. The image. Actually, let's call this my tensor image. And so this because this inherits from tensor, it looks exactly like a tensor. As all the normal tensor things. But if you check its type, it's one of these. So the nice thing is that we can now start constraining our functions to only work on things we want. So I want this to only work on that type. And so this is the second thing that a transform does is that it's going to make sure that I know you get supplied to these parts of a tuple if you are applying it to a tuple. So again, it's not going to change this behavior because it's not a tuple. But this one, we are applying it to a tuple. Ah, perfect. OK, so now that's not being changed. So it's important to realize that this is like it's no more or less weird or more or less magical or anything than Python's normal function dispatch. Different languages and different libraries have different function dispatch methods. Julia tends to do function dispatch nearly entirely using these kinds of this kind of system that I'm describing here. And by default has a different way of doing things. So we're just picking, we're just picking another way, equally valid, no more strange or no less strange. So Max is asking, does transform only apply to tensor? No, not at all. It's just a, it's just a, so let's go back and have a look. Remember that in our image tuple, the second part of the tuple is just a one. So when I remove that, you'll see it's being applied to that int as well. This is just a, this is nothing PyTorch specific or anything about this. It's just another way of doing function dispatch in Python. And so in this case, we're constraining it to this particular type. But yeah, I mean, I could have instead said, um, class my int and then let's create a my int equals my int one. And then let's say this only applies to a my int. And so now let's not use a one, but let's use my int. So you can see now the tensor, the image tensor hasn't changed, but the int has. So it's just a, yeah, it's just a different way of doing function dispatch. But it's a way that makes a lot more sense for data processing than the default way that Python has. And so the nice thing is that like Python is specifically designed to be able to provide this kind of functionality. So everything we've written, as you'll see, we've written it all. Okay, we've got a few questions here, so let's answer these first. You defined empty I, but when did that get passed to norm? It got passed to norm. Oh, it got passed to norm. Yeah, I think. Yes, okay, so let's go back and check this. So we're going to do my tensor image. So there it is with a my tensor image. If we made the tuple non-my tensor image, just a regular tensor. Oh, it's still running. Why is that? I actually changed the type of t image at some point. I didn't mean to do that. Let's run it together. Okay, so, oh, because I'm actually changing the original. That looks like we found a bug. Okay, let's make a note. Bug. So, let's do it separately. Yes, I do need a dot. Oh, I've got plug. I shouldn't, but I have a bug. Okay, let's do it again. There we go. Okay, so t image is now a tensor. And so, okay, so now when I run this on the tuple, which has a normal tensor, it doesn't run. Okay. And so then if I change it to the subclass, then it does run. And we wanted to make this float. And that should be a tensor array. Okay, there we go. So that one is just being applied to the image and not to the label. And so to answer Max's question, we absolutely could just write int here and put that back to t image here. And now it is being applied. The reason I was showing you subclassing is because this is how we add kind of semantic markers to existing types so that we can get all the functionality of the existing types, but also say that they represent different kinds of information. So for example, in Fast.ai version 2, there is a capital I int, which is basically an int that has a show method. It knows how to show itself. What kind of work do we put int after the pipe? I'm not sure what you mean, Caleb. We don't have a pipe. So feel free to re-ask that question if I'm not understanding. Okay. So this is kind of on the right track. One problem here though is that we don't want to have to pass the mean and standard deviation in every time. So it would be better if we could grab the mean and standard deviation, and we could say mean, standard deviation equals t image dot mean, t image dot standard deviation, oops, equals. I'm not sure what I just did. There we go. Okay. So now we've got a mean and standard deviation. So what we could do is we could create a function which is a partial application of norm over that mean and that standard deviation. So now we could go normed image equals f of that instance. And then of course we'll need to put this back to, let's just make this tensor for now, say. There we go. Or we could do it over our tuple. So f, we don't need an f anymore, an s anymore. So and this is kind of more how we would want something like normalization to work, right? Because we generally want to normalize a bunch of things with the same mean and standard deviation. So this is more kind of the behavior we want. Except there's a few other things we'd want in normalization. One is we generally want to be able to serialize it. We'd want to be able to save the transform that we're using to disk, including the mean and standard deviation. The second thing we'd want to be able to do is we'd want to be able to undo the normalization so that when you get back an image or whatever from some model, we'd want to be able to display it, which means we'd have to be able to denormalize it. So that means that we're going to need proper state. So the easiest way to get proper state is to create a class. Oh, before I do that, I'll just point something out. For those of you that haven't spent much time with decorators, this thing where I went at transform and then I said def norm, that's exactly the same as doing this. I could have just said def say underscore norm equals this, and then I could have said norm equals transform norm. And that's identical. As you can see, it gives exactly the same answers. That's literally the definition of a decorator in Python, is it literally takes this function and passes it to this function. That's what at does. So anytime you see at something, you know that, oh, thank you, transform underscore norm. You know that that's what it's doing. Thanks very much for picking up my silly mistakes. Okay, so yeah, it's important to remember when you see a decorator, it's something you can always run that manually on functions. And yeah, okay. So what I was saying is in order to have state in this, we should turn it into a class. Let's call it capital N norm. And so the way transform works is you can also inherit from it. And so now if you inherit from it, you have to use special names. And encodes is the name that transforms expect. And so normally you wouldn't then pass in those things, but instead you'd pass it. Yeah, and remember, so we could use self dot m comma self dot s equals m comma s, or we could use our little convenient thing we mentioned last time, or doesn't really add as much. So small number, but just to show you the different approaches. So go back to that one. So now we need self dot m, self dot s. I still have my annotation here. So now we will go f equals capital N norm. N equals m, s equals s. Oh, and of course these need the self. And there we go. So why isn't that working? So it worked on this one, but not on our tuple. Why is that? So David asks, why would we inherit versus use decorator? Yeah, so basically, yeah, if you want some state, it's easier to use a class. If you don't, it's probably easier to use a decorator. That sounds about right to me. OK, so let's try and figure out why this isn't working. Oh, I think it's because we forgot to call the super class. Perhaps, yes, that's probably why. Thank you. Oh yeah, we both caught up at the same time. There we go. OK. So that's an interesting point. It's quite annoying to have tuples in it. We actually have something to make that easier, which is borrowed from the idea that Python standard libraries data classes use, which is to have a special thing called postInnit that runs after your init. OK, Jovi and I will come back to that question. It's a very good one. So we actually have, yes, if we inherit from base object, we're going to get a meta class, which we'll learn more about later, called pre postInnit meta, which allows us to have a preInnit and a postInnit. And we may already be using that. Let's have a look. Transforms. Transform. It's using Tiffa meta. So Tiffa meta is a very good one. So we'll have to come back to this. This isn't a great opportunity to use this one. So it must be an inherit. Let's answer some questions first. So can you specify multiple types? So as Max said, it would be nice if we could use union. I can't remember if I actually currently have that working. The problem is that Python's typing system isn't at all well designed for using at runtime. And last time I checked, I don't think I had this working. Let's see. No. There's this really annoying check that they do. So basically, if you want this, then you have to go like this. So actually, probably the easiest way would be to go underscore norm, get rid of that there. And then encodes here would be return self. Underscore norm. X. And we'll do the same here. I think that's what you have to do at the moment. So have it twice, both calling the same thing with the two different types. If anybody can figure out how to get union working, that would be great because this is slightly more clunky than it should be. So if you need multiple different encodes for different types, you absolutely don't need to use class. And so just to confirm again, you can do it with a class like so. So you could also do it like this. Def norm. Well, actually, there's a few ways you can do it. But one way is you partially use a class. You define it like this. But you just write pass here. And then what you do is you write encodes here. And you actually use this as a decorator. Like so. And then you can do this a bunch of times. Like so. And this is another way to do it. So we now have multiple versions of encodes in separate places. So it's still defining a class once, but it's an empty class. But then you can put the encodes in these different places. This is actually, we'll see more about using this later, but this is actually super important because let's say the class was, well, actually, norm's a great class. So let's say you've got a normalized class. And there's somewhere where you defined it for your tensor image class. But then later on, you create a new data type for audio, say. You might have an audio tensor. And then that might have some different implementation where, I don't know, maybe you have to transpose something or you have to add a non somewhere or whatever. So the nice thing is this separate implementation can be in a totally different file, totally different module, totally different project. And it will add the functionality to normalize audio tensors to the library. So this is one of the really helpful things about this style. And so you'll see, yeah, for data augmentation in particular, this is great. We can add data augmentation of their own types to the library with just one line of code, well, two lines of code, one for the decorator. Oh, great question, Julian. So yes, the way that encodes works or the way that in general, this dispatch system works is, let's check it out. Let's put here print A, print B. And this is a tensor and this is a tensor image. So if we call it with MTI, it prints B. Why is it printing B? Because my tensor image is further down the inheritance hierarchy. So that's the more what you would call, Julian, closest match, more specific match. So it uses the most precise type that it can. And this does also work for kind of generic types as well. So we could say type being dot, what's it called? There's a class for this. What's it called? There you go. These things are going to move slowly. Numbers dot, yeah, so Python standard library comes with various type hierarchies. So we could say numbers dot integral, for instance, and then we could say F3, as you can see. Where else if we had one that was on int? And again, it's going to call the most specialized version. OK, so lots of good questions. All right. Or for lunch, to lunch. Check this out later. Thank you for the tip. All right. The next thing that we want to be able to do is we need to be able to go in the opposite direction. So to go in the opposite direction, we create something called decodes. And so this would be x plus self dot s. Sorry, self times self dot s plus m. And so let's check normalized image. And so to run decodes, you have to go F dot decode. And then we would say an image. And there it is. And this works for tuples and everything. It's actually the same way. So if we go F of our tuple, and then we could say F dot decode, F of our tuple. Yep, we've gone back to where we were for the whole tuple. Just to confirm that this did in fact. That's not working. Oh, because this should be an MTI. This we're now saying just put our image type. There we go. MTCode. There we go. OK. So that is some of the key pieces around how this dispatch works and why it works this way. But of course, it's not enough to have just one transform. In practice, we need to not only normalize, but we need to be able to do other things as well. So, for example, maybe we'll have something that flips. And so generally things that flip, we don't need to unflip because data augmentation, we want to see it even later on. We don't generally want to decode data augmentation. So we could probably just use a function for that. So it's going to take one of our image tensors and it's going to return torch.flip our x. And we'll do it on the zeroth axis. No, the first axis. If random.random is greater than 0.5, otherwise we'll leave it alone. So that would be an example of some data augmentation we could do. So how would we combine those two things together? So one simple approach would be we could say transformed image equals, in fact, let's do it for the whole tuple. So transform tuple, tuple is image tuple. So transform tuple equals, let's say first we normalize, which was F of our image, and then we flip it. Actually that won't quite work because, not that nice with our tuple, which tuple, because we can't apply it to tuples. So we could tell it this is a transform. And so now that works, which is good. It's kind of annoying having to say everything's a transform. And it's also kind of annoying because it's kind of normalize and then flip and then do something else and then do something else. These kinds of pipelines are things we often want to define once and use multiple times. One way we could do that is we could say pipeline equals compose. So compose is just a standard functional and mathematical thing that runs a bunch of functions in order. So we could first of all run our normalization function and then our flip image function. And so now we could just go pipe. So that works. The problem is that compose doesn't know anything about transforms. So if we now wanted to go to decode it, we can't. So we would have to go, you know, flip image.decode, which actually isn't going to do anything because we don't have one, but we don't necessarily know which ones have one, which don't. We'd have to do something like this. So it would be great if we could compose things in a way that know how to compose decoding as well as encoding. So to do that, we just change from compose to pipeline. And it's going to do exactly the same thing. But now we can say pipe.decode and it's done. So as you can see, there's this kind of idea of like trying to get the pieces all to work together in this data transformation domain that we're in, specifically kind of couple transformation domain that we're in. So if this pipeline knows that we want to be dealing with transforms, it knows that if it gets a normal image and not a transform, it should turn it into a transform. So let's remove the transform decorator from here and run this again. And oh, I thought that was going to work. Why is it not working? I thought I had made that the default. Sorry. I think I forgot to export something. I guess I just forgot to export it. It, it plants in the right world, not cor \uc0c8. It now rewarded me for doing that Okay I'm sending them to the right order right now. Okay Okay. Okay. Order. Nope. So, pipeline. This item equals false. Let's see. False. So, we put an image tuple. Pipeline, which is going to go... So, if I add a transform back on here. And now I've managed to break everything. Let's go do that. That's a problem with live coding, I guess. Oh, and now it's working again. What did I do wrong? Maybe I just got to restart properly. I guess I did. Okay. Alright, sorry about that delay. So, what I was saying is that a pipeline knows that the things that's being passed need to be transforms. If we pass it something that's not a transform, so I've made this not a transform now. So, the cool thing is that pipeline will turn it into a transform automatically. So, yes, David, from people in the San Francisco study group, they say one of the best things is finding out how many errors I make. Apparently that's extremely encouraging. I make lots. What's the default behavior of the transform for encode and decode? Yeah, so the default behavior of encode and decode is to do nothing at all. So, the decoder doesn't know what the image prior to the flip is. The decoder is not storing any state about what was decoded. It's just a function. So, the decoder simply just returns whatever it's passed. It doesn't do anything. We haven't got to data blocks yet, so we'll talk about data blocks when we get there. And Kip and I find I have a lot of troubles with autoreload, so I don't tend to use it. But you can actually just tap zero twice on the keyboard and it will restart the kernel, which I thought I did before, but I might have forgotten. And the other thing I do I find super handy is I go edit keyboard shortcuts. And, well, why don't I see any edit shortcuts? Edit keyboard shortcuts. Apparently Jupyter is currently broken. That's weird. Anyway, I add a keyboard shortcut for running all the cells above the current cursor, which normally you can do without a keyboard shortcuts. So, I can just go zero zero to restart and then I go A to run above and that gets me back to where I am. Okay. So hopefully you can kind of see how this approach allows us to kind of use normal Python functions, but in a way that is kind of dispatched and composed in a way that makes more sense for data processing pipelines than the default approach that Python gives us. But the nice thing is they're not that different, you know. So like it's just kind of co, you know, the function just behaves like a normal function unless you add type annotations and so forth. Okay, so this is making good progress here. So then, yeah, so we don't need to actually define my tensor image because we already have a tensor image class, which we can use. But as you can see, it's actually defined exactly the same way. So that's the one that we should be using. So that's. Great. And I guess we may as well just say t image dot clone. And let's restart. And then we don't need my int because we've actually defined something called int, as I mentioned, in exactly the same way. Int again, just pass, but it's also got a show on it. So that's now going to be a tensor image. There we go. Cool. There we are. So then the last piece of this puzzle for now is that we might want, let's make our load image thing into a transform as well. So. Define. Create image. With some file name. And we're going to, it's actually going to be like, I guess we're actually going to create an image tensor. And so we're going to return. And so array. Open image. Sorry, load image. X. So we could do that. And so now we could use that here. And let's restart. Image. Done all above. OK, so there you go. Now, the point about this, though, is that what we actually want RISC to be is because, you know, it's an image, not just any odd tensor. We want to avoid having kind of non-semantically typed tensors wherever possible because then we or Bust.ai doesn't know what to do with them. But this is currently just a tensor. So we can just say that should be a. And so image. And it will cast it. Should cast it first. And of course, unless it's in a pipeline, we need to tell it it's a transform. Or any magic to happen. OK. In practice, I basically pretty much never need to run transforms outside of a pipeline except for testing. So you'll see a lot of things that don't have decorators because we basically always use them in the pipeline, which you can see, for example, we just went pipeline. And pass that in. That would work as well, because there's a pipeline with just one function being composed. Or, of course, alternatively. We could do this. And that would work, too. But kind of having return types is kind of nicer because it's just going to ensure that it's it's cast properly for you and it won't bother casting if it's already the right type. OK. Random augmentations we will get to later. But if you're interested in looking ahead, you'll find that there is a thing called efficient augment. But you can find that stuff developed. OK. So, you know, you don't need to learn anything about or understand anything about type dispatch or meta classes or any of that stuff to use this any more than to use Python's default function dispatch. You don't have to learn anything about, you know, the workings of Python's type dispatch system. You just have to know what it does. But we're going to be spending time looking to see how it works because that's what CodeWalker is all about. But you certainly don't have to understand it to use any of this. So the next thing to be aware of is that both pipelines and tensors, when you create them, you can pass an optional additional argument as item, which is true or false. As item equals false gives you the behavior that we've seen, which is that it if given a tuple or some kind of listy type of thing, it will operate on each element of the collection. But if you say as item equals true, then it won't it basically turns that behavior off. So you can actually see that in the definition of transform. Here it says if use as item, which returns self as item, then just call the function and then otherwise it will do the loop. But in this case, it's a tuple comprehension. So you can easily turn off that behavior by saying as item equals true either in the pipeline or in the transform. The there are predefined subclasses of transform, as you can see, called tuple transform and item transform. And they actually set as item force equals false and true. And the force versions of these mean that even if later on you create a pipeline with as item equals something, it won't change those transforms. So if you create a tuple transform or an item transform, then you can know that all the time, no matter what, it will have the behavior that you requested. So why does pipeline have this as item equals true false thing? So what that does is pipeline simply will go through so you can see pipeline in the constructor called set as item that simply goes through each function in the pipeline and sets as item. And the reason we do that is that depending on kind of where you are in the data, the full data processing pipeline, sometimes you want kind of tuple behavior and sometimes you want item behavior. And specifically up until you collate your batch together, you kind of have two separate pipelines going on. So each each pipeline is being separately applied to remind you from the pets tutorial. We have two totally separate pipelines. So since each of those is only being applied to one item at a time, not to tuples, the fast AI pipeline will automatically set as item equals true for those because they don't have they haven't been combined into tuples yet. And then later on in the process, it will set as item equals false. Basically after they've been pulled out of data sets. So by the time they get to the data loader, it'll use false. And we'll see more of that data. But that's a little, little thing to be aware of. So basically it just tries to do the right thing for you. But you know, you don't have to use any of that functionality, of course, if you don't want to. Okay. This one back. Okay. All right. Well, I think that's enough for today. Give us a good introduction to pipelines and transforms. And, yeah, again, happy to take requests on the forum for what you'd like to look at next. Otherwise, yeah, maybe we'll start going deeper dive into how these things are actually put together. We'll see where we go. Okay. Thanks, everybody. See you tomorrow.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 18.76, "text": " Okay, hi everybody, can you see and hear okay?", "tokens": [1033, 11, 4879, 2201, 11, 393, 291, 536, 293, 1568, 1392, 30], "temperature": 0.0, "avg_logprob": -0.5265788078308106, "compression_ratio": 0.9137931034482759, "no_speech_prob": 0.5837681889533997}, {"id": 1, "seek": 0, "start": 18.76, "end": 27.64, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.5265788078308106, "compression_ratio": 0.9137931034482759, "no_speech_prob": 0.5837681889533997}, {"id": 2, "seek": 2764, "start": 27.64, "end": 38.0, "text": " And that response came back pretty quickly, so hopefully the latency is a bit lower.", "tokens": [400, 300, 4134, 1361, 646, 1238, 2661, 11, 370, 4696, 264, 27043, 307, 257, 857, 3126, 13], "temperature": 0.0, "avg_logprob": -0.2586607419527494, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.001148258219473064}, {"id": 3, "seek": 2764, "start": 38.0, "end": 45.040000000000006, "text": " So Sam asked before we start to give you a reminder that his conference in San Francisco,", "tokens": [407, 4832, 2351, 949, 321, 722, 281, 976, 291, 257, 13548, 300, 702, 7586, 294, 5271, 12279, 11], "temperature": 0.0, "avg_logprob": -0.2586607419527494, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.001148258219473064}, {"id": 4, "seek": 2764, "start": 45.040000000000006, "end": 55.8, "text": " TermoCon, today is the last day to get early bed tickets, so remember if you're interested,", "tokens": [19835, 78, 9838, 11, 965, 307, 264, 1036, 786, 281, 483, 2440, 2901, 12628, 11, 370, 1604, 498, 291, 434, 3102, 11], "temperature": 0.0, "avg_logprob": -0.2586607419527494, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.001148258219473064}, {"id": 5, "seek": 5580, "start": 55.8, "end": 64.0, "text": " the code is fastai to get an extra 20% off.", "tokens": [264, 3089, 307, 2370, 1301, 281, 483, 364, 2857, 945, 4, 766, 13], "temperature": 0.0, "avg_logprob": -0.2984292711530413, "compression_ratio": 1.4337349397590362, "no_speech_prob": 4.682752478402108e-05}, {"id": 6, "seek": 5580, "start": 64.0, "end": 73.72, "text": " Okay, I was thinking I would do something crazy today, which is to do some live coding,", "tokens": [1033, 11, 286, 390, 1953, 286, 576, 360, 746, 3219, 965, 11, 597, 307, 281, 360, 512, 1621, 17720, 11], "temperature": 0.0, "avg_logprob": -0.2984292711530413, "compression_ratio": 1.4337349397590362, "no_speech_prob": 4.682752478402108e-05}, {"id": 7, "seek": 5580, "start": 73.72, "end": 77.4, "text": " which is going to be terrifying, so I'm not sure I've really done that before.", "tokens": [597, 307, 516, 281, 312, 18106, 11, 370, 286, 478, 406, 988, 286, 600, 534, 1096, 300, 949, 13], "temperature": 0.0, "avg_logprob": -0.2984292711530413, "compression_ratio": 1.4337349397590362, "no_speech_prob": 4.682752478402108e-05}, {"id": 8, "seek": 5580, "start": 77.4, "end": 83.52, "text": " Oh, hey there Max, welcome.", "tokens": [876, 11, 4177, 456, 7402, 11, 2928, 13], "temperature": 0.0, "avg_logprob": -0.2984292711530413, "compression_ratio": 1.4337349397590362, "no_speech_prob": 4.682752478402108e-05}, {"id": 9, "seek": 8352, "start": 83.52, "end": 94.47999999999999, "text": " So I was going to try and do some live coding to try to explain what transform does and", "tokens": [407, 286, 390, 516, 281, 853, 293, 360, 512, 1621, 17720, 281, 853, 281, 2903, 437, 4088, 775, 293], "temperature": 0.0, "avg_logprob": -0.18711143840443004, "compression_ratio": 1.5572519083969465, "no_speech_prob": 2.2124020688352175e-05}, {"id": 10, "seek": 8352, "start": 94.47999999999999, "end": 104.78, "text": " try and justify why it does it and why it exists, to kind of try to basically see why", "tokens": [853, 293, 20833, 983, 309, 775, 309, 293, 983, 309, 8198, 11, 281, 733, 295, 853, 281, 1936, 536, 983], "temperature": 0.0, "avg_logprob": -0.18711143840443004, "compression_ratio": 1.5572519083969465, "no_speech_prob": 2.2124020688352175e-05}, {"id": 11, "seek": 8352, "start": 104.78, "end": 106.56, "text": " we ended up where we ended up.", "tokens": [321, 4590, 493, 689, 321, 4590, 493, 13], "temperature": 0.0, "avg_logprob": -0.18711143840443004, "compression_ratio": 1.5572519083969465, "no_speech_prob": 2.2124020688352175e-05}, {"id": 12, "seek": 10656, "start": 106.56, "end": 119.2, "text": " I think we did something like 26 rewrites from scratch of the data transform functionality", "tokens": [286, 519, 321, 630, 746, 411, 7551, 319, 86, 30931, 490, 8459, 295, 264, 1412, 4088, 14980], "temperature": 0.0, "avg_logprob": -0.1581358448151619, "compression_ratio": 1.4456521739130435, "no_speech_prob": 7.0710552790842485e-06}, {"id": 13, "seek": 10656, "start": 119.2, "end": 127.2, "text": " over a many month period because it was just super hard to get everything really easy and", "tokens": [670, 257, 867, 1618, 2896, 570, 309, 390, 445, 1687, 1152, 281, 483, 1203, 534, 1858, 293], "temperature": 0.0, "avg_logprob": -0.1581358448151619, "compression_ratio": 1.4456521739130435, "no_speech_prob": 7.0710552790842485e-06}, {"id": 14, "seek": 10656, "start": 127.2, "end": 132.36, "text": " clear and, you know, maintainable and stuff like that, so I'm really happy with where", "tokens": [1850, 293, 11, 291, 458, 11, 6909, 712, 293, 1507, 411, 300, 11, 370, 286, 478, 534, 2055, 365, 689], "temperature": 0.0, "avg_logprob": -0.1581358448151619, "compression_ratio": 1.4456521739130435, "no_speech_prob": 7.0710552790842485e-06}, {"id": 15, "seek": 13236, "start": 132.36, "end": 138.44000000000003, "text": " we got to and that might be helpful for you to see why we got here.", "tokens": [321, 658, 281, 293, 300, 1062, 312, 4961, 337, 291, 281, 536, 983, 321, 658, 510, 13], "temperature": 0.0, "avg_logprob": -0.1282050962801333, "compression_ratio": 1.4666666666666666, "no_speech_prob": 3.535382711561397e-05}, {"id": 16, "seek": 13236, "start": 138.44000000000003, "end": 146.44000000000003, "text": " So maybe let's start by writing a function.", "tokens": [407, 1310, 718, 311, 722, 538, 3579, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1282050962801333, "compression_ratio": 1.4666666666666666, "no_speech_prob": 3.535382711561397e-05}, {"id": 17, "seek": 13236, "start": 146.44000000000003, "end": 158.64000000000001, "text": " So our function is going to be called neg and it's going to return negative, which you", "tokens": [407, 527, 2445, 307, 516, 281, 312, 1219, 2485, 293, 309, 311, 516, 281, 2736, 3671, 11, 597, 291], "temperature": 0.0, "avg_logprob": -0.1282050962801333, "compression_ratio": 1.4666666666666666, "no_speech_prob": 3.535382711561397e-05}, {"id": 18, "seek": 15864, "start": 158.64, "end": 164.35999999999999, "text": " might recognize actually as the same as the operator.neg function, but we're writing it", "tokens": [1062, 5521, 767, 382, 264, 912, 382, 264, 12973, 13, 28561, 2445, 11, 457, 321, 434, 3579, 309], "temperature": 0.0, "avg_logprob": -0.28711868734920726, "compression_ratio": 1.355421686746988, "no_speech_prob": 8.139473720802926e-06}, {"id": 19, "seek": 15864, "start": 164.35999999999999, "end": 166.44, "text": " ourselves.", "tokens": [4175, 13], "temperature": 0.0, "avg_logprob": -0.28711868734920726, "compression_ratio": 1.355421686746988, "no_speech_prob": 8.139473720802926e-06}, {"id": 20, "seek": 15864, "start": 166.44, "end": 178.44, "text": " So we can say neg 3, for instance, and that's how Python will do that.", "tokens": [407, 321, 393, 584, 2485, 805, 11, 337, 5197, 11, 293, 300, 311, 577, 15329, 486, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.28711868734920726, "compression_ratio": 1.355421686746988, "no_speech_prob": 8.139473720802926e-06}, {"id": 21, "seek": 15864, "start": 178.44, "end": 182.88, "text": " What if we did neg of some tuple?", "tokens": [708, 498, 321, 630, 2485, 295, 512, 2604, 781, 30], "temperature": 0.0, "avg_logprob": -0.28711868734920726, "compression_ratio": 1.355421686746988, "no_speech_prob": 8.139473720802926e-06}, {"id": 22, "seek": 15864, "start": 182.88, "end": 184.92, "text": " Let's create a tuple.", "tokens": [961, 311, 1884, 257, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.28711868734920726, "compression_ratio": 1.355421686746988, "no_speech_prob": 8.139473720802926e-06}, {"id": 23, "seek": 18492, "start": 184.92, "end": 190.64, "text": " 1, 3, neg of some tuple.", "tokens": [502, 11, 805, 11, 2485, 295, 512, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.29896997425654165, "compression_ratio": 1.4431818181818181, "no_speech_prob": 5.9550329751800746e-06}, {"id": 24, "seek": 18492, "start": 190.64, "end": 197.04, "text": " Oh, doesn't work.", "tokens": [876, 11, 1177, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.29896997425654165, "compression_ratio": 1.4431818181818181, "no_speech_prob": 5.9550329751800746e-06}, {"id": 25, "seek": 18492, "start": 197.04, "end": 203.2, "text": " That's actually kind of annoying because, I mean, it's the first thing to recognize", "tokens": [663, 311, 767, 733, 295, 11304, 570, 11, 286, 914, 11, 309, 311, 264, 700, 551, 281, 5521], "temperature": 0.0, "avg_logprob": -0.29896997425654165, "compression_ratio": 1.4431818181818181, "no_speech_prob": 5.9550329751800746e-06}, {"id": 26, "seek": 18492, "start": 203.2, "end": 207.83999999999997, "text": " is like this is, this is a behavior.", "tokens": [307, 411, 341, 307, 11, 341, 307, 257, 5223, 13], "temperature": 0.0, "avg_logprob": -0.29896997425654165, "compression_ratio": 1.4431818181818181, "no_speech_prob": 5.9550329751800746e-06}, {"id": 27, "seek": 18492, "start": 207.83999999999997, "end": 212.2, "text": " It's a behavior that can be chosen from a number of possible behaviors and this particular", "tokens": [467, 311, 257, 5223, 300, 393, 312, 8614, 490, 257, 1230, 295, 1944, 15501, 293, 341, 1729], "temperature": 0.0, "avg_logprob": -0.29896997425654165, "compression_ratio": 1.4431818181818181, "no_speech_prob": 5.9550329751800746e-06}, {"id": 28, "seek": 21220, "start": 212.2, "end": 217.32, "text": " behavior is how Python behaves and it's totally fine.", "tokens": [5223, 307, 577, 15329, 36896, 293, 309, 311, 3879, 2489, 13], "temperature": 0.0, "avg_logprob": -0.14200922750657605, "compression_ratio": 1.4203821656050954, "no_speech_prob": 9.223303095495794e-06}, {"id": 29, "seek": 21220, "start": 217.32, "end": 232.35999999999999, "text": " But as you know, if we had an array, for instance, we would get different behavior.", "tokens": [583, 382, 291, 458, 11, 498, 321, 632, 364, 10225, 11, 337, 5197, 11, 321, 576, 483, 819, 5223, 13], "temperature": 0.0, "avg_logprob": -0.14200922750657605, "compression_ratio": 1.4203821656050954, "no_speech_prob": 9.223303095495794e-06}, {"id": 30, "seek": 21220, "start": 232.35999999999999, "end": 238.64, "text": " So one of the very, very, very nice things, in fact, to me the best part of Python is", "tokens": [407, 472, 295, 264, 588, 11, 588, 11, 588, 1481, 721, 11, 294, 1186, 11, 281, 385, 264, 1151, 644, 295, 15329, 307], "temperature": 0.0, "avg_logprob": -0.14200922750657605, "compression_ratio": 1.4203821656050954, "no_speech_prob": 9.223303095495794e-06}, {"id": 31, "seek": 23864, "start": 238.64, "end": 247.88, "text": " that Python lets us change how it behaves according to what we want for our domain.", "tokens": [300, 15329, 6653, 505, 1319, 577, 309, 36896, 4650, 281, 437, 321, 528, 337, 527, 9274, 13], "temperature": 0.0, "avg_logprob": -0.13166211446126302, "compression_ratio": 1.4457831325301205, "no_speech_prob": 1.3287601632328006e-06}, {"id": 32, "seek": 23864, "start": 247.88, "end": 257.88, "text": " In the domain of data processing, we're particularly interested in tuples or tuple-like things", "tokens": [682, 264, 9274, 295, 1412, 9007, 11, 321, 434, 4098, 3102, 294, 2604, 2622, 420, 2604, 781, 12, 4092, 721], "temperature": 0.0, "avg_logprob": -0.13166211446126302, "compression_ratio": 1.4457831325301205, "no_speech_prob": 1.3287601632328006e-06}, {"id": 33, "seek": 23864, "start": 257.88, "end": 263.4, "text": " because generally speaking, we're going to have an X and a Y.", "tokens": [570, 5101, 4124, 11, 321, 434, 516, 281, 362, 364, 1783, 293, 257, 398, 13], "temperature": 0.0, "avg_logprob": -0.13166211446126302, "compression_ratio": 1.4457831325301205, "no_speech_prob": 1.3287601632328006e-06}, {"id": 34, "seek": 26340, "start": 263.4, "end": 277.12, "text": " So for example, we would have an image and a label such as a pet.", "tokens": [407, 337, 1365, 11, 321, 576, 362, 364, 3256, 293, 257, 7645, 1270, 382, 257, 3817, 13], "temperature": 0.0, "avg_logprob": -0.1470940113067627, "compression_ratio": 1.2641509433962264, "no_speech_prob": 8.939600775192957e-06}, {"id": 35, "seek": 26340, "start": 277.12, "end": 286.64, "text": " Other possibilities would be a source image and a mask segmentation.", "tokens": [5358, 12178, 576, 312, 257, 4009, 3256, 293, 257, 6094, 9469, 399, 13], "temperature": 0.0, "avg_logprob": -0.1470940113067627, "compression_ratio": 1.2641509433962264, "no_speech_prob": 8.939600775192957e-06}, {"id": 36, "seek": 28664, "start": 286.64, "end": 296.2, "text": " Another possibility would be an image tuple and a bool, which would be for Siamese.", "tokens": [3996, 7959, 576, 312, 364, 3256, 2604, 781, 293, 257, 748, 401, 11, 597, 576, 312, 337, 318, 2918, 1130, 13], "temperature": 0.0, "avg_logprob": -0.49264233286787823, "compression_ratio": 1.233009708737864, "no_speech_prob": 8.139561941788998e-06}, {"id": 37, "seek": 28664, "start": 296.2, "end": 310.76, "text": " Segmentation, Siamese, that's a corization.", "tokens": [1100, 10433, 399, 11, 318, 2918, 1130, 11, 300, 311, 257, 1181, 2144, 13], "temperature": 0.0, "avg_logprob": -0.49264233286787823, "compression_ratio": 1.233009708737864, "no_speech_prob": 8.139561941788998e-06}, {"id": 38, "seek": 31076, "start": 310.76, "end": 320.28, "text": " Or it could be a tuple of continuous columns and categorical columns and a target column", "tokens": [1610, 309, 727, 312, 257, 2604, 781, 295, 10957, 13766, 293, 19250, 804, 13766, 293, 257, 3779, 7738], "temperature": 0.0, "avg_logprob": -0.070664460842426, "compression_ratio": 1.4202898550724639, "no_speech_prob": 2.601590949780075e-06}, {"id": 39, "seek": 31076, "start": 320.28, "end": 327.96, "text": " such as for tabular.", "tokens": [1270, 382, 337, 4421, 1040, 13], "temperature": 0.0, "avg_logprob": -0.070664460842426, "compression_ratio": 1.4202898550724639, "no_speech_prob": 2.601590949780075e-06}, {"id": 40, "seek": 31076, "start": 327.96, "end": 336.59999999999997, "text": " So we would quite like Meg to behave for our tuple in a way that's different to Python", "tokens": [407, 321, 576, 1596, 411, 9986, 281, 15158, 337, 527, 2604, 781, 294, 257, 636, 300, 311, 819, 281, 15329], "temperature": 0.0, "avg_logprob": -0.070664460842426, "compression_ratio": 1.4202898550724639, "no_speech_prob": 2.601590949780075e-06}, {"id": 41, "seek": 33660, "start": 336.6, "end": 345.40000000000003, "text": " and perhaps works a little bit more like the way that it works for array.", "tokens": [293, 4317, 1985, 257, 707, 857, 544, 411, 264, 636, 300, 309, 1985, 337, 10225, 13], "temperature": 0.0, "avg_logprob": -0.08664872006672185, "compression_ratio": 1.4173913043478261, "no_speech_prob": 4.425402494234731e-06}, {"id": 42, "seek": 33660, "start": 345.40000000000003, "end": 360.04, "text": " So what we could do is we could repeat our function and to add new behavior to a function", "tokens": [407, 437, 321, 727, 360, 307, 321, 727, 7149, 527, 2445, 293, 281, 909, 777, 5223, 281, 257, 2445], "temperature": 0.0, "avg_logprob": -0.08664872006672185, "compression_ratio": 1.4173913043478261, "no_speech_prob": 4.425402494234731e-06}, {"id": 43, "seek": 36004, "start": 360.04, "end": 367.48, "text": " or a class in Python, you do it by adding a decorator.", "tokens": [420, 257, 1508, 294, 15329, 11, 291, 360, 309, 538, 5127, 257, 7919, 1639, 13], "temperature": 0.0, "avg_logprob": -0.12820073305550267, "compression_ratio": 1.425531914893617, "no_speech_prob": 5.955016604275443e-06}, {"id": 44, "seek": 36004, "start": 367.48, "end": 378.36, "text": " So we created a decorator called transform, which will cause our function to work the", "tokens": [407, 321, 2942, 257, 7919, 1639, 1219, 4088, 11, 597, 486, 3082, 527, 2445, 281, 589, 264], "temperature": 0.0, "avg_logprob": -0.12820073305550267, "compression_ratio": 1.425531914893617, "no_speech_prob": 5.955016604275443e-06}, {"id": 45, "seek": 36004, "start": 378.36, "end": 380.76, "text": " way we want.", "tokens": [636, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.12820073305550267, "compression_ratio": 1.425531914893617, "no_speech_prob": 5.955016604275443e-06}, {"id": 46, "seek": 36004, "start": 380.76, "end": 385.44, "text": " So now here we have it, minus one, minus three.", "tokens": [407, 586, 510, 321, 362, 309, 11, 3175, 472, 11, 3175, 1045, 13], "temperature": 0.0, "avg_logprob": -0.12820073305550267, "compression_ratio": 1.425531914893617, "no_speech_prob": 5.955016604275443e-06}, {"id": 47, "seek": 38544, "start": 385.44, "end": 391.56, "text": " So let's say we grab an image.", "tokens": [407, 718, 311, 584, 321, 4444, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.3074485377261513, "compression_ratio": 1.3893805309734513, "no_speech_prob": 9.972537554858718e-06}, {"id": 48, "seek": 38544, "start": 391.56, "end": 394.28, "text": " And so we've got a file name FN, which is an image.", "tokens": [400, 370, 321, 600, 658, 257, 3991, 1315, 479, 45, 11, 597, 307, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.3074485377261513, "compression_ratio": 1.3893805309734513, "no_speech_prob": 9.972537554858718e-06}, {"id": 49, "seek": 38544, "start": 394.28, "end": 402.48, "text": " So let's grab an image, which will be log image FN.", "tokens": [407, 718, 311, 4444, 364, 3256, 11, 597, 486, 312, 3565, 3256, 479, 45, 13], "temperature": 0.0, "avg_logprob": -0.3074485377261513, "compression_ratio": 1.3893805309734513, "no_speech_prob": 9.972537554858718e-06}, {"id": 50, "seek": 38544, "start": 402.48, "end": 409.15999999999997, "text": " OK, there's our image.", "tokens": [2264, 11, 456, 311, 527, 3256, 13], "temperature": 0.0, "avg_logprob": -0.3074485377261513, "compression_ratio": 1.3893805309734513, "no_speech_prob": 9.972537554858718e-06}, {"id": 51, "seek": 40916, "start": 409.16, "end": 428.16, "text": " And so let's create a tensor of the image as well, which we could do like this.", "tokens": [400, 370, 718, 311, 1884, 257, 40863, 295, 264, 3256, 382, 731, 11, 597, 321, 727, 360, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.2867444356282552, "compression_ratio": 1.158878504672897, "no_speech_prob": 1.6963545931503177e-05}, {"id": 52, "seek": 40916, "start": 428.16, "end": 434.88, "text": " OK, maybe just look at a few rows of it.", "tokens": [2264, 11, 1310, 445, 574, 412, 257, 1326, 13241, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.2867444356282552, "compression_ratio": 1.158878504672897, "no_speech_prob": 1.6963545931503177e-05}, {"id": 53, "seek": 40916, "start": 434.88, "end": 438.5, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.2867444356282552, "compression_ratio": 1.158878504672897, "no_speech_prob": 1.6963545931503177e-05}, {"id": 54, "seek": 43850, "start": 438.5, "end": 449.2, "text": " So we could, let's look at some rows more around the middle.", "tokens": [407, 321, 727, 11, 718, 311, 574, 412, 512, 13241, 544, 926, 264, 2808, 13], "temperature": 0.0, "avg_logprob": -0.325969968523298, "compression_ratio": 1.1941747572815533, "no_speech_prob": 9.666037840361241e-06}, {"id": 55, "seek": 43850, "start": 449.2, "end": 453.46, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.325969968523298, "compression_ratio": 1.1941747572815533, "no_speech_prob": 9.666037840361241e-06}, {"id": 56, "seek": 43850, "start": 453.46, "end": 458.56, "text": " So we could, of course, do negative with that.", "tokens": [407, 321, 727, 11, 295, 1164, 11, 360, 3671, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.325969968523298, "compression_ratio": 1.1941747572815533, "no_speech_prob": 9.666037840361241e-06}, {"id": 57, "seek": 43850, "start": 458.56, "end": 460.68, "text": " No problem.", "tokens": [883, 1154, 13], "temperature": 0.0, "avg_logprob": -0.325969968523298, "compression_ratio": 1.1941747572815533, "no_speech_prob": 9.666037840361241e-06}, {"id": 58, "seek": 46068, "start": 460.68, "end": 469.52, "text": " Or if we had two of those in a tuple, we could create a tuple with a couple of images.", "tokens": [1610, 498, 321, 632, 732, 295, 729, 294, 257, 2604, 781, 11, 321, 727, 1884, 257, 2604, 781, 365, 257, 1916, 295, 5267, 13], "temperature": 0.0, "avg_logprob": -0.3293929852937397, "compression_ratio": 1.4044117647058822, "no_speech_prob": 1.3006932931602933e-05}, {"id": 59, "seek": 46068, "start": 469.52, "end": 474.32, "text": " And actually, this is not doing a negative.", "tokens": [400, 767, 11, 341, 307, 406, 884, 257, 3671, 13], "temperature": 0.0, "avg_logprob": -0.3293929852937397, "compression_ratio": 1.4044117647058822, "no_speech_prob": 1.3006932931602933e-05}, {"id": 60, "seek": 46068, "start": 474.32, "end": 478.16, "text": " We're not getting a negative here.", "tokens": [492, 434, 406, 1242, 257, 3671, 510, 13], "temperature": 0.0, "avg_logprob": -0.3293929852937397, "compression_ratio": 1.4044117647058822, "no_speech_prob": 1.3006932931602933e-05}, {"id": 61, "seek": 46068, "start": 478.16, "end": 484.16, "text": " OK, interesting question.", "tokens": [2264, 11, 1880, 1168, 13], "temperature": 0.0, "avg_logprob": -0.3293929852937397, "compression_ratio": 1.4044117647058822, "no_speech_prob": 1.3006932931602933e-05}, {"id": 62, "seek": 48416, "start": 484.16, "end": 499.8, "text": " What am I doing wrong?", "tokens": [708, 669, 286, 884, 2085, 30], "temperature": 0.0, "avg_logprob": -0.7745972156524659, "compression_ratio": 0.7333333333333333, "no_speech_prob": 2.4291173758683726e-05}, {"id": 63, "seek": 49980, "start": 499.8, "end": 515.04, "text": " Oh, yes, thanks, here.", "tokens": [876, 11, 2086, 11, 3231, 11, 510, 13], "temperature": 0.0, "avg_logprob": -0.2728648835962469, "compression_ratio": 1.1981132075471699, "no_speech_prob": 1.9033078615393606e-06}, {"id": 64, "seek": 49980, "start": 515.04, "end": 521.28, "text": " I mean, the reason my negative is wrong is because I have an unsigned int.", "tokens": [286, 914, 11, 264, 1778, 452, 3671, 307, 2085, 307, 570, 286, 362, 364, 2693, 16690, 560, 13], "temperature": 0.0, "avg_logprob": -0.2728648835962469, "compression_ratio": 1.1981132075471699, "no_speech_prob": 1.9033078615393606e-06}, {"id": 65, "seek": 49980, "start": 521.28, "end": 522.28, "text": " So yes.", "tokens": [407, 2086, 13], "temperature": 0.0, "avg_logprob": -0.2728648835962469, "compression_ratio": 1.1981132075471699, "no_speech_prob": 1.9033078615393606e-06}, {"id": 66, "seek": 49980, "start": 522.28, "end": 524.76, "text": " Thank you, everybody.", "tokens": [1044, 291, 11, 2201, 13], "temperature": 0.0, "avg_logprob": -0.2728648835962469, "compression_ratio": 1.1981132075471699, "no_speech_prob": 1.9033078615393606e-06}, {"id": 67, "seek": 52476, "start": 524.76, "end": 531.8, "text": " So let's make this a dot float.", "tokens": [407, 718, 311, 652, 341, 257, 5893, 15706, 13], "temperature": 0.0, "avg_logprob": -0.3048127579362425, "compression_ratio": 1.5294117647058822, "no_speech_prob": 1.3419597053143661e-05}, {"id": 68, "seek": 52476, "start": 531.8, "end": 532.8, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.3048127579362425, "compression_ratio": 1.5294117647058822, "no_speech_prob": 1.3419597053143661e-05}, {"id": 69, "seek": 52476, "start": 532.8, "end": 533.8, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.3048127579362425, "compression_ratio": 1.5294117647058822, "no_speech_prob": 1.3419597053143661e-05}, {"id": 70, "seek": 52476, "start": 533.8, "end": 539.0, "text": " And that will work on tuples as well.", "tokens": [400, 300, 486, 589, 322, 2604, 2622, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.3048127579362425, "compression_ratio": 1.5294117647058822, "no_speech_prob": 1.3419597053143661e-05}, {"id": 71, "seek": 52476, "start": 539.0, "end": 542.0, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.3048127579362425, "compression_ratio": 1.5294117647058822, "no_speech_prob": 1.3419597053143661e-05}, {"id": 72, "seek": 52476, "start": 542.0, "end": 545.34, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.3048127579362425, "compression_ratio": 1.5294117647058822, "no_speech_prob": 1.3419597053143661e-05}, {"id": 73, "seek": 52476, "start": 545.34, "end": 547.24, "text": " So that's useful.", "tokens": [407, 300, 311, 4420, 13], "temperature": 0.0, "avg_logprob": -0.3048127579362425, "compression_ratio": 1.5294117647058822, "no_speech_prob": 1.3419597053143661e-05}, {"id": 74, "seek": 52476, "start": 547.24, "end": 552.2, "text": " And that would be particularly useful if I had an image as an input and an image as an", "tokens": [400, 300, 576, 312, 4098, 4420, 498, 286, 632, 364, 3256, 382, 364, 4846, 293, 364, 3256, 382, 364], "temperature": 0.0, "avg_logprob": -0.3048127579362425, "compression_ratio": 1.5294117647058822, "no_speech_prob": 1.3419597053143661e-05}, {"id": 75, "seek": 55220, "start": 552.2, "end": 563.2, "text": " output, such as a mask, you know, as an output or super resolution or something like that.", "tokens": [5598, 11, 1270, 382, 257, 6094, 11, 291, 458, 11, 382, 364, 5598, 420, 1687, 8669, 420, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.14532855704978662, "compression_ratio": 1.5765306122448979, "no_speech_prob": 6.240857601369498e-06}, {"id": 76, "seek": 55220, "start": 563.2, "end": 566.1800000000001, "text": " So this is all looking pretty hopeful.", "tokens": [407, 341, 307, 439, 1237, 1238, 20531, 13], "temperature": 0.0, "avg_logprob": -0.14532855704978662, "compression_ratio": 1.5765306122448979, "no_speech_prob": 6.240857601369498e-06}, {"id": 77, "seek": 55220, "start": 566.1800000000001, "end": 569.5200000000001, "text": " So the next thing, let's try and make a more interesting function.", "tokens": [407, 264, 958, 551, 11, 718, 311, 853, 293, 652, 257, 544, 1880, 2445, 13], "temperature": 0.0, "avg_logprob": -0.14532855704978662, "compression_ratio": 1.5765306122448979, "no_speech_prob": 6.240857601369498e-06}, {"id": 78, "seek": 55220, "start": 569.5200000000001, "end": 571.84, "text": " Let's create a function called normalize.", "tokens": [961, 311, 1884, 257, 2445, 1219, 2710, 1125, 13], "temperature": 0.0, "avg_logprob": -0.14532855704978662, "compression_ratio": 1.5765306122448979, "no_speech_prob": 6.240857601369498e-06}, {"id": 79, "seek": 55220, "start": 571.84, "end": 581.5600000000001, "text": " And that's going to take an image and a mean and a standard deviation.", "tokens": [400, 300, 311, 516, 281, 747, 364, 3256, 293, 257, 914, 293, 257, 3832, 25163, 13], "temperature": 0.0, "avg_logprob": -0.14532855704978662, "compression_ratio": 1.5765306122448979, "no_speech_prob": 6.240857601369498e-06}, {"id": 80, "seek": 58156, "start": 581.56, "end": 589.5999999999999, "text": " And we're going to return x minus m over s.", "tokens": [400, 321, 434, 516, 281, 2736, 2031, 3175, 275, 670, 262, 13], "temperature": 0.0, "avg_logprob": -0.30549121352861514, "compression_ratio": 1.3478260869565217, "no_speech_prob": 1.5688945495639928e-05}, {"id": 81, "seek": 58156, "start": 589.5999999999999, "end": 604.3599999999999, "text": " So I could go normalize t image, comma, say the mean is somewhere around 127.", "tokens": [407, 286, 727, 352, 2710, 1125, 256, 3256, 11, 22117, 11, 584, 264, 914, 307, 4079, 926, 47561, 13], "temperature": 0.0, "avg_logprob": -0.30549121352861514, "compression_ratio": 1.3478260869565217, "no_speech_prob": 1.5688945495639928e-05}, {"id": 82, "seek": 58156, "start": 604.3599999999999, "end": 611.1199999999999, "text": " And the standard deviation, let's say it's somewhere around 150.", "tokens": [400, 264, 3832, 25163, 11, 718, 311, 584, 309, 311, 4079, 926, 8451, 13], "temperature": 0.0, "avg_logprob": -0.30549121352861514, "compression_ratio": 1.3478260869565217, "no_speech_prob": 1.5688945495639928e-05}, {"id": 83, "seek": 61112, "start": 611.12, "end": 622.24, "text": " And again, let's actually let's just grab our subset.", "tokens": [400, 797, 11, 718, 311, 767, 718, 311, 445, 4444, 527, 25993, 13], "temperature": 0.0, "avg_logprob": -0.342564676322189, "compression_ratio": 1.375, "no_speech_prob": 6.540309641422937e-06}, {"id": 84, "seek": 61112, "start": 622.24, "end": 626.0, "text": " So it's a little bit easier to see what's going on.", "tokens": [407, 309, 311, 257, 707, 857, 3571, 281, 536, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.342564676322189, "compression_ratio": 1.375, "no_speech_prob": 6.540309641422937e-06}, {"id": 85, "seek": 61112, "start": 626.0, "end": 638.92, "text": " So we'll go the subset of the image is a few of those rows.", "tokens": [407, 321, 603, 352, 264, 25993, 295, 264, 3256, 307, 257, 1326, 295, 729, 13241, 13], "temperature": 0.0, "avg_logprob": -0.342564676322189, "compression_ratio": 1.375, "no_speech_prob": 6.540309641422937e-06}, {"id": 86, "seek": 63892, "start": 638.92, "end": 643.3199999999999, "text": " OK, there we go.", "tokens": [2264, 11, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.2944286134507921, "compression_ratio": 1.1643835616438356, "no_speech_prob": 1.40637275762856e-05}, {"id": 87, "seek": 63892, "start": 643.3199999999999, "end": 661.12, "text": " So we could check now t image.mean, t sub.mean, output t image.mean.", "tokens": [407, 321, 727, 1520, 586, 256, 3256, 13, 1398, 282, 11, 256, 1422, 13, 1398, 282, 11, 5598, 256, 3256, 13, 1398, 282, 13], "temperature": 0.0, "avg_logprob": -0.2944286134507921, "compression_ratio": 1.1643835616438356, "no_speech_prob": 1.40637275762856e-05}, {"id": 88, "seek": 66112, "start": 661.12, "end": 670.8, "text": " I should say, let's say, normed image across that.", "tokens": [286, 820, 584, 11, 718, 311, 584, 11, 2026, 292, 3256, 2108, 300, 13], "temperature": 0.0, "avg_logprob": -0.5977228482564291, "compression_ratio": 0.9433962264150944, "no_speech_prob": 6.814111111452803e-05}, {"id": 89, "seek": 67080, "start": 670.8, "end": 695.92, "text": " So t sub, normed image.mean, OK, so that's the right idea.", "tokens": [407, 256, 1422, 11, 2026, 292, 3256, 13, 1398, 282, 11, 2264, 11, 370, 300, 311, 264, 558, 1558, 13], "temperature": 0.0, "avg_logprob": -0.4912791592734201, "compression_ratio": 0.9393939393939394, "no_speech_prob": 2.710656735871453e-05}, {"id": 90, "seek": 67080, "start": 695.92, "end": 697.8, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.4912791592734201, "compression_ratio": 0.9393939393939394, "no_speech_prob": 2.710656735871453e-05}, {"id": 91, "seek": 69780, "start": 697.8, "end": 702.92, "text": " So here's a function that would be actually pretty useful to have in a transformation", "tokens": [407, 510, 311, 257, 2445, 300, 576, 312, 767, 1238, 4420, 281, 362, 294, 257, 9887], "temperature": 0.0, "avg_logprob": -0.1497751149264249, "compression_ratio": 1.5277777777777777, "no_speech_prob": 3.555959438017453e-06}, {"id": 92, "seek": 69780, "start": 702.92, "end": 705.92, "text": " pipeline.", "tokens": [15517, 13], "temperature": 0.0, "avg_logprob": -0.1497751149264249, "compression_ratio": 1.5277777777777777, "no_speech_prob": 3.555959438017453e-06}, {"id": 93, "seek": 69780, "start": 705.92, "end": 717.92, "text": " But I will note that we would generally want to run this particular transformation on the", "tokens": [583, 286, 486, 3637, 300, 321, 576, 5101, 528, 281, 1190, 341, 1729, 9887, 322, 264], "temperature": 0.0, "avg_logprob": -0.1497751149264249, "compression_ratio": 1.5277777777777777, "no_speech_prob": 3.555959438017453e-06}, {"id": 94, "seek": 69780, "start": 717.92, "end": 719.7199999999999, "text": " GPU.", "tokens": [18407, 13], "temperature": 0.0, "avg_logprob": -0.1497751149264249, "compression_ratio": 1.5277777777777777, "no_speech_prob": 3.555959438017453e-06}, {"id": 95, "seek": 69780, "start": 719.7199999999999, "end": 726.4, "text": " Because even though that doesn't look like a lot of work, it actually turns out that", "tokens": [1436, 754, 1673, 300, 1177, 380, 574, 411, 257, 688, 295, 589, 11, 309, 767, 4523, 484, 300], "temperature": 0.0, "avg_logprob": -0.1497751149264249, "compression_ratio": 1.5277777777777777, "no_speech_prob": 3.555959438017453e-06}, {"id": 96, "seek": 72640, "start": 726.4, "end": 731.8, "text": " normalizing takes an astonishingly large amount of time as part of something like an ImageNet", "tokens": [2710, 3319, 2516, 364, 35264, 356, 2416, 2372, 295, 565, 382, 644, 295, 746, 411, 364, 29903, 31890], "temperature": 0.0, "avg_logprob": -0.11923342943191528, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.565918061416596e-06}, {"id": 97, "seek": 72640, "start": 731.8, "end": 732.92, "text": " pipeline.", "tokens": [15517, 13], "temperature": 0.0, "avg_logprob": -0.11923342943191528, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.565918061416596e-06}, {"id": 98, "seek": 72640, "start": 732.92, "end": 736.62, "text": " So we would generally want to run it on the GPU.", "tokens": [407, 321, 576, 5101, 528, 281, 1190, 309, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.11923342943191528, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.565918061416596e-06}, {"id": 99, "seek": 72640, "start": 736.62, "end": 741.6, "text": " So by the time something has gotten to the GPU, it won't just be an image.", "tokens": [407, 538, 264, 565, 746, 575, 5768, 281, 264, 18407, 11, 309, 1582, 380, 445, 312, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.11923342943191528, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.565918061416596e-06}, {"id": 100, "seek": 72640, "start": 741.6, "end": 749.84, "text": " It's the thing that our data set returns will be an image and a label.", "tokens": [467, 311, 264, 551, 300, 527, 1412, 992, 11247, 486, 312, 364, 3256, 293, 257, 7645, 13], "temperature": 0.0, "avg_logprob": -0.11923342943191528, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.565918061416596e-06}, {"id": 101, "seek": 74984, "start": 749.84, "end": 760.84, "text": " So let's create a image tuple will be image, comma, let's say it's a 1.", "tokens": [407, 718, 311, 1884, 257, 3256, 2604, 781, 486, 312, 3256, 11, 22117, 11, 718, 311, 584, 309, 311, 257, 502, 13], "temperature": 0.0, "avg_logprob": -0.22633052217787591, "compression_ratio": 1.5616438356164384, "no_speech_prob": 9.080295967578422e-06}, {"id": 102, "seek": 74984, "start": 760.84, "end": 763.44, "text": " So this is the kind of thing that we're actually going to be working with.", "tokens": [407, 341, 307, 264, 733, 295, 551, 300, 321, 434, 767, 516, 281, 312, 1364, 365, 13], "temperature": 0.0, "avg_logprob": -0.22633052217787591, "compression_ratio": 1.5616438356164384, "no_speech_prob": 9.080295967578422e-06}, {"id": 103, "seek": 74984, "start": 763.44, "end": 767.9200000000001, "text": " Oh, we should use the tester.", "tokens": [876, 11, 321, 820, 764, 264, 36101, 13], "temperature": 0.0, "avg_logprob": -0.22633052217787591, "compression_ratio": 1.5616438356164384, "no_speech_prob": 9.080295967578422e-06}, {"id": 104, "seek": 74984, "start": 767.9200000000001, "end": 771.5, "text": " We're actually going to be working with on the GPU.", "tokens": [492, 434, 767, 516, 281, 312, 1364, 365, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.22633052217787591, "compression_ratio": 1.5616438356164384, "no_speech_prob": 9.080295967578422e-06}, {"id": 105, "seek": 77150, "start": 771.5, "end": 792.52, "text": " So if we want to normalize that, and again, let's grab a mean and a standard deviation.", "tokens": [407, 498, 321, 528, 281, 2710, 1125, 300, 11, 293, 797, 11, 718, 311, 4444, 257, 914, 293, 257, 3832, 25163, 13], "temperature": 0.0, "avg_logprob": -0.22039397557576498, "compression_ratio": 1.2061855670103092, "no_speech_prob": 5.771860742243007e-06}, {"id": 106, "seek": 77150, "start": 792.52, "end": 796.1, "text": " And again, we have a problem.", "tokens": [400, 797, 11, 321, 362, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.22039397557576498, "compression_ratio": 1.2061855670103092, "no_speech_prob": 5.771860742243007e-06}, {"id": 107, "seek": 79610, "start": 796.1, "end": 801.96, "text": " So let's make it a transform.", "tokens": [407, 718, 311, 652, 309, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 108, "seek": 79610, "start": 801.96, "end": 804.96, "text": " So that's something that will be applied over tuples.", "tokens": [407, 300, 311, 746, 300, 486, 312, 6456, 670, 2604, 2622, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 109, "seek": 79610, "start": 804.96, "end": 809.2, "text": " So you'll see that none of the stuff we already have is going to change at all because, oh,", "tokens": [407, 291, 603, 536, 300, 6022, 295, 264, 1507, 321, 1217, 362, 307, 516, 281, 1319, 412, 439, 570, 11, 1954, 11], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 110, "seek": 79610, "start": 809.2, "end": 810.2, "text": " I made a mistake.", "tokens": [286, 1027, 257, 6146, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 111, "seek": 79610, "start": 810.2, "end": 811.2, "text": " I made a mistake.", "tokens": [286, 1027, 257, 6146, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 112, "seek": 79610, "start": 811.2, "end": 812.2, "text": " I made a mistake.", "tokens": [286, 1027, 257, 6146, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 113, "seek": 79610, "start": 812.2, "end": 813.2, "text": " Oh, takes two additional arguments.", "tokens": [876, 11, 2516, 732, 4497, 12869, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 114, "seek": 79610, "start": 813.2, "end": 814.2, "text": " That 4 we're given.", "tokens": [663, 1017, 321, 434, 2212, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 115, "seek": 79610, "start": 814.2, "end": 815.2, "text": " Ah, yes, that's true.", "tokens": [2438, 11, 2086, 11, 300, 311, 2074, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 116, "seek": 79610, "start": 815.2, "end": 816.2, "text": " So we do have to use an equalizer.", "tokens": [407, 321, 360, 362, 281, 764, 364, 2681, 6545, 13], "temperature": 0.0, "avg_logprob": -0.4003975608132102, "compression_ratio": 1.6208530805687205, "no_speech_prob": 2.3552334823762067e-05}, {"id": 117, "seek": 81620, "start": 816.2, "end": 835.72, "text": " Okay, so one changes that we have to use named arguments.", "tokens": [1033, 11, 370, 472, 2962, 300, 321, 362, 281, 764, 4926, 12869, 13], "temperature": 0.0, "avg_logprob": -0.22218237982855904, "compression_ratio": 1.211111111111111, "no_speech_prob": 2.111176036123652e-05}, {"id": 118, "seek": 81620, "start": 835.72, "end": 842.0, "text": " So now we can go M equals S equals.", "tokens": [407, 586, 321, 393, 352, 376, 6915, 318, 6915, 13], "temperature": 0.0, "avg_logprob": -0.22218237982855904, "compression_ratio": 1.211111111111111, "no_speech_prob": 2.111176036123652e-05}, {"id": 119, "seek": 81620, "start": 842.0, "end": 843.0, "text": " So there we go.", "tokens": [407, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.22218237982855904, "compression_ratio": 1.211111111111111, "no_speech_prob": 2.111176036123652e-05}, {"id": 120, "seek": 84300, "start": 843.0, "end": 846.48, "text": " So now it's working again.", "tokens": [407, 586, 309, 311, 1364, 797, 13], "temperature": 0.0, "avg_logprob": -0.1704084521434346, "compression_ratio": 1.394736842105263, "no_speech_prob": 1.3006937479076441e-05}, {"id": 121, "seek": 84300, "start": 846.48, "end": 849.76, "text": " But oh, that's no good.", "tokens": [583, 1954, 11, 300, 311, 572, 665, 13], "temperature": 0.0, "avg_logprob": -0.1704084521434346, "compression_ratio": 1.394736842105263, "no_speech_prob": 1.3006937479076441e-05}, {"id": 122, "seek": 84300, "start": 849.76, "end": 856.64, "text": " It's also transformed our label, which is definitely not what we want.", "tokens": [467, 311, 611, 16894, 527, 7645, 11, 597, 307, 2138, 406, 437, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.1704084521434346, "compression_ratio": 1.394736842105263, "no_speech_prob": 1.3006937479076441e-05}, {"id": 123, "seek": 84300, "start": 856.64, "end": 867.96, "text": " So we need some way to have it only apply to those things that we would want to normalize.", "tokens": [407, 321, 643, 512, 636, 281, 362, 309, 787, 3079, 281, 729, 721, 300, 321, 576, 528, 281, 2710, 1125, 13], "temperature": 0.0, "avg_logprob": -0.1704084521434346, "compression_ratio": 1.394736842105263, "no_speech_prob": 1.3006937479076441e-05}, {"id": 124, "seek": 86796, "start": 867.96, "end": 880.76, "text": " We can't so as we saw, you can add a type annotation to say what to apply it to.", "tokens": [492, 393, 380, 370, 382, 321, 1866, 11, 291, 393, 909, 257, 2010, 48654, 281, 584, 437, 281, 3079, 309, 281, 13], "temperature": 0.0, "avg_logprob": -0.1756942958047945, "compression_ratio": 1.5257142857142858, "no_speech_prob": 4.860406534135109e-06}, {"id": 125, "seek": 86796, "start": 880.76, "end": 888.44, "text": " The problem is that generally by the time you are getting through the data loader, your", "tokens": [440, 1154, 307, 300, 5101, 538, 264, 565, 291, 366, 1242, 807, 264, 1412, 3677, 260, 11, 428], "temperature": 0.0, "avg_logprob": -0.1756942958047945, "compression_ratio": 1.5257142857142858, "no_speech_prob": 4.860406534135109e-06}, {"id": 126, "seek": 86796, "start": 888.44, "end": 890.44, "text": " everything's everything's a tensor.", "tokens": [1203, 311, 1203, 311, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.1756942958047945, "compression_ratio": 1.5257142857142858, "no_speech_prob": 4.860406534135109e-06}, {"id": 127, "seek": 86796, "start": 890.44, "end": 896.52, "text": " So how can we decide which bits of our tuple to apply this to?", "tokens": [407, 577, 393, 321, 4536, 597, 9239, 295, 527, 2604, 781, 281, 3079, 341, 281, 30], "temperature": 0.0, "avg_logprob": -0.1756942958047945, "compression_ratio": 1.5257142857142858, "no_speech_prob": 4.860406534135109e-06}, {"id": 128, "seek": 89652, "start": 896.52, "end": 905.12, "text": " So the answer is that we need to create things that inherit from a tensor.", "tokens": [407, 264, 1867, 307, 300, 321, 643, 281, 1884, 721, 300, 21389, 490, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.15978215634822845, "compression_ratio": 1.7364864864864864, "no_speech_prob": 4.092812105227495e-06}, {"id": 129, "seek": 89652, "start": 905.12, "end": 910.96, "text": " And so we have something called tensor base, which is just a base class for things that", "tokens": [400, 370, 321, 362, 746, 1219, 40863, 3096, 11, 597, 307, 445, 257, 3096, 1508, 337, 721, 300], "temperature": 0.0, "avg_logprob": -0.15978215634822845, "compression_ratio": 1.7364864864864864, "no_speech_prob": 4.092812105227495e-06}, {"id": 130, "seek": 89652, "start": 910.96, "end": 911.96, "text": " inherit the tensor.", "tokens": [21389, 264, 40863, 13], "temperature": 0.0, "avg_logprob": -0.15978215634822845, "compression_ratio": 1.7364864864864864, "no_speech_prob": 4.092812105227495e-06}, {"id": 131, "seek": 89652, "start": 911.96, "end": 925.48, "text": " So we could go class my tensor image, which will inherit from tensor base.", "tokens": [407, 321, 727, 352, 1508, 452, 40863, 3256, 11, 597, 486, 21389, 490, 40863, 3096, 13], "temperature": 0.0, "avg_logprob": -0.15978215634822845, "compression_ratio": 1.7364864864864864, "no_speech_prob": 4.092812105227495e-06}, {"id": 132, "seek": 92548, "start": 925.48, "end": 928.9200000000001, "text": " And I don't have to add any functionality to it.", "tokens": [400, 286, 500, 380, 362, 281, 909, 604, 14980, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.29357860399329144, "compression_ratio": 1.5506329113924051, "no_speech_prob": 2.3923174012452364e-05}, {"id": 133, "seek": 92548, "start": 928.9200000000001, "end": 937.12, "text": " What I could just do is now say t image equals my tensor image.", "tokens": [708, 286, 727, 445, 360, 307, 586, 584, 256, 3256, 6915, 452, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.29357860399329144, "compression_ratio": 1.5506329113924051, "no_speech_prob": 2.3923174012452364e-05}, {"id": 134, "seek": 92548, "start": 937.12, "end": 938.6, "text": " The image.", "tokens": [440, 3256, 13], "temperature": 0.0, "avg_logprob": -0.29357860399329144, "compression_ratio": 1.5506329113924051, "no_speech_prob": 2.3923174012452364e-05}, {"id": 135, "seek": 92548, "start": 938.6, "end": 945.5600000000001, "text": " Actually, let's call this my tensor image.", "tokens": [5135, 11, 718, 311, 818, 341, 452, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.29357860399329144, "compression_ratio": 1.5506329113924051, "no_speech_prob": 2.3923174012452364e-05}, {"id": 136, "seek": 92548, "start": 945.5600000000001, "end": 951.6800000000001, "text": " And so this because this inherits from tensor, it looks exactly like a tensor.", "tokens": [400, 370, 341, 570, 341, 9484, 1208, 490, 40863, 11, 309, 1542, 2293, 411, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.29357860399329144, "compression_ratio": 1.5506329113924051, "no_speech_prob": 2.3923174012452364e-05}, {"id": 137, "seek": 95168, "start": 951.68, "end": 956.3599999999999, "text": " As all the normal tensor things.", "tokens": [1018, 439, 264, 2710, 40863, 721, 13], "temperature": 0.0, "avg_logprob": -0.17700850826570358, "compression_ratio": 1.691891891891892, "no_speech_prob": 2.627440517244395e-05}, {"id": 138, "seek": 95168, "start": 956.3599999999999, "end": 962.8, "text": " But if you check its type, it's one of these.", "tokens": [583, 498, 291, 1520, 1080, 2010, 11, 309, 311, 472, 295, 613, 13], "temperature": 0.0, "avg_logprob": -0.17700850826570358, "compression_ratio": 1.691891891891892, "no_speech_prob": 2.627440517244395e-05}, {"id": 139, "seek": 95168, "start": 962.8, "end": 970.1999999999999, "text": " So the nice thing is that we can now start constraining our functions to only work on", "tokens": [407, 264, 1481, 551, 307, 300, 321, 393, 586, 722, 11525, 1760, 527, 6828, 281, 787, 589, 322], "temperature": 0.0, "avg_logprob": -0.17700850826570358, "compression_ratio": 1.691891891891892, "no_speech_prob": 2.627440517244395e-05}, {"id": 140, "seek": 95168, "start": 970.1999999999999, "end": 971.3199999999999, "text": " things we want.", "tokens": [721, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.17700850826570358, "compression_ratio": 1.691891891891892, "no_speech_prob": 2.627440517244395e-05}, {"id": 141, "seek": 95168, "start": 971.3199999999999, "end": 976.92, "text": " So I want this to only work on that type.", "tokens": [407, 286, 528, 341, 281, 787, 589, 322, 300, 2010, 13], "temperature": 0.0, "avg_logprob": -0.17700850826570358, "compression_ratio": 1.691891891891892, "no_speech_prob": 2.627440517244395e-05}, {"id": 142, "seek": 95168, "start": 976.92, "end": 981.16, "text": " And so this is the second thing that a transform does is that it's going to make sure that", "tokens": [400, 370, 341, 307, 264, 1150, 551, 300, 257, 4088, 775, 307, 300, 309, 311, 516, 281, 652, 988, 300], "temperature": 0.0, "avg_logprob": -0.17700850826570358, "compression_ratio": 1.691891891891892, "no_speech_prob": 2.627440517244395e-05}, {"id": 143, "seek": 98116, "start": 981.16, "end": 987.1999999999999, "text": " I know you get supplied to these parts of a tuple if you are applying it to a tuple.", "tokens": [286, 458, 291, 483, 27625, 281, 613, 3166, 295, 257, 2604, 781, 498, 291, 366, 9275, 309, 281, 257, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.20014430027382046, "compression_ratio": 1.7208121827411167, "no_speech_prob": 4.198552778689191e-05}, {"id": 144, "seek": 98116, "start": 987.1999999999999, "end": 991.48, "text": " So again, it's not going to change this behavior because it's not a tuple.", "tokens": [407, 797, 11, 309, 311, 406, 516, 281, 1319, 341, 5223, 570, 309, 311, 406, 257, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.20014430027382046, "compression_ratio": 1.7208121827411167, "no_speech_prob": 4.198552778689191e-05}, {"id": 145, "seek": 98116, "start": 991.48, "end": 995.16, "text": " But this one, we are applying it to a tuple.", "tokens": [583, 341, 472, 11, 321, 366, 9275, 309, 281, 257, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.20014430027382046, "compression_ratio": 1.7208121827411167, "no_speech_prob": 4.198552778689191e-05}, {"id": 146, "seek": 98116, "start": 995.16, "end": 996.16, "text": " Ah, perfect.", "tokens": [2438, 11, 2176, 13], "temperature": 0.0, "avg_logprob": -0.20014430027382046, "compression_ratio": 1.7208121827411167, "no_speech_prob": 4.198552778689191e-05}, {"id": 147, "seek": 98116, "start": 996.16, "end": 1000.0799999999999, "text": " OK, so now that's not being changed.", "tokens": [2264, 11, 370, 586, 300, 311, 406, 885, 3105, 13], "temperature": 0.0, "avg_logprob": -0.20014430027382046, "compression_ratio": 1.7208121827411167, "no_speech_prob": 4.198552778689191e-05}, {"id": 148, "seek": 98116, "start": 1000.0799999999999, "end": 1009.04, "text": " So it's important to realize that this is like it's no more or less weird or more or", "tokens": [407, 309, 311, 1021, 281, 4325, 300, 341, 307, 411, 309, 311, 572, 544, 420, 1570, 3657, 420, 544, 420], "temperature": 0.0, "avg_logprob": -0.20014430027382046, "compression_ratio": 1.7208121827411167, "no_speech_prob": 4.198552778689191e-05}, {"id": 149, "seek": 100904, "start": 1009.04, "end": 1015.8, "text": " less magical or anything than Python's normal function dispatch.", "tokens": [1570, 12066, 420, 1340, 813, 15329, 311, 2710, 2445, 36729, 13], "temperature": 0.0, "avg_logprob": -0.19817465322989006, "compression_ratio": 1.6303030303030304, "no_speech_prob": 3.966904387198156e-06}, {"id": 150, "seek": 100904, "start": 1015.8, "end": 1021.7199999999999, "text": " Different languages and different libraries have different function dispatch methods.", "tokens": [20825, 8650, 293, 819, 15148, 362, 819, 2445, 36729, 7150, 13], "temperature": 0.0, "avg_logprob": -0.19817465322989006, "compression_ratio": 1.6303030303030304, "no_speech_prob": 3.966904387198156e-06}, {"id": 151, "seek": 100904, "start": 1021.7199999999999, "end": 1030.2, "text": " Julia tends to do function dispatch nearly entirely using these kinds of this kind of", "tokens": [18551, 12258, 281, 360, 2445, 36729, 6217, 7696, 1228, 613, 3685, 295, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.19817465322989006, "compression_ratio": 1.6303030303030304, "no_speech_prob": 3.966904387198156e-06}, {"id": 152, "seek": 100904, "start": 1030.2, "end": 1036.0, "text": " system that I'm describing here.", "tokens": [1185, 300, 286, 478, 16141, 510, 13], "temperature": 0.0, "avg_logprob": -0.19817465322989006, "compression_ratio": 1.6303030303030304, "no_speech_prob": 3.966904387198156e-06}, {"id": 153, "seek": 103600, "start": 1036.0, "end": 1041.48, "text": " And by default has a different way of doing things.", "tokens": [400, 538, 7576, 575, 257, 819, 636, 295, 884, 721, 13], "temperature": 0.0, "avg_logprob": -0.18445231936393527, "compression_ratio": 1.5913043478260869, "no_speech_prob": 1.1842660569527652e-05}, {"id": 154, "seek": 103600, "start": 1041.48, "end": 1046.44, "text": " So we're just picking, we're just picking another way, equally valid, no more strange", "tokens": [407, 321, 434, 445, 8867, 11, 321, 434, 445, 8867, 1071, 636, 11, 12309, 7363, 11, 572, 544, 5861], "temperature": 0.0, "avg_logprob": -0.18445231936393527, "compression_ratio": 1.5913043478260869, "no_speech_prob": 1.1842660569527652e-05}, {"id": 155, "seek": 103600, "start": 1046.44, "end": 1051.12, "text": " or no less strange.", "tokens": [420, 572, 1570, 5861, 13], "temperature": 0.0, "avg_logprob": -0.18445231936393527, "compression_ratio": 1.5913043478260869, "no_speech_prob": 1.1842660569527652e-05}, {"id": 156, "seek": 103600, "start": 1051.12, "end": 1053.92, "text": " So Max is asking, does transform only apply to tensor?", "tokens": [407, 7402, 307, 3365, 11, 775, 4088, 787, 3079, 281, 40863, 30], "temperature": 0.0, "avg_logprob": -0.18445231936393527, "compression_ratio": 1.5913043478260869, "no_speech_prob": 1.1842660569527652e-05}, {"id": 157, "seek": 103600, "start": 1053.92, "end": 1055.24, "text": " No, not at all.", "tokens": [883, 11, 406, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.18445231936393527, "compression_ratio": 1.5913043478260869, "no_speech_prob": 1.1842660569527652e-05}, {"id": 158, "seek": 103600, "start": 1055.24, "end": 1058.4, "text": " It's just a, it's just a, so let's go back and have a look.", "tokens": [467, 311, 445, 257, 11, 309, 311, 445, 257, 11, 370, 718, 311, 352, 646, 293, 362, 257, 574, 13], "temperature": 0.0, "avg_logprob": -0.18445231936393527, "compression_ratio": 1.5913043478260869, "no_speech_prob": 1.1842660569527652e-05}, {"id": 159, "seek": 103600, "start": 1058.4, "end": 1065.4, "text": " Remember that in our image tuple, the second part of the tuple is just a one.", "tokens": [5459, 300, 294, 527, 3256, 2604, 781, 11, 264, 1150, 644, 295, 264, 2604, 781, 307, 445, 257, 472, 13], "temperature": 0.0, "avg_logprob": -0.18445231936393527, "compression_ratio": 1.5913043478260869, "no_speech_prob": 1.1842660569527652e-05}, {"id": 160, "seek": 106540, "start": 1065.4, "end": 1071.96, "text": " So when I remove that, you'll see it's being applied to that int as well.", "tokens": [407, 562, 286, 4159, 300, 11, 291, 603, 536, 309, 311, 885, 6456, 281, 300, 560, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1313632329305013, "compression_ratio": 1.4731182795698925, "no_speech_prob": 5.955054348305566e-06}, {"id": 161, "seek": 106540, "start": 1071.96, "end": 1076.0800000000002, "text": " This is just a, this is nothing PyTorch specific or anything about this.", "tokens": [639, 307, 445, 257, 11, 341, 307, 1825, 9953, 51, 284, 339, 2685, 420, 1340, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.1313632329305013, "compression_ratio": 1.4731182795698925, "no_speech_prob": 5.955054348305566e-06}, {"id": 162, "seek": 106540, "start": 1076.0800000000002, "end": 1084.4, "text": " It's just another way of doing function dispatch in Python.", "tokens": [467, 311, 445, 1071, 636, 295, 884, 2445, 36729, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.1313632329305013, "compression_ratio": 1.4731182795698925, "no_speech_prob": 5.955054348305566e-06}, {"id": 163, "seek": 106540, "start": 1084.4, "end": 1088.72, "text": " And so in this case, we're constraining it to this particular type.", "tokens": [400, 370, 294, 341, 1389, 11, 321, 434, 11525, 1760, 309, 281, 341, 1729, 2010, 13], "temperature": 0.0, "avg_logprob": -0.1313632329305013, "compression_ratio": 1.4731182795698925, "no_speech_prob": 5.955054348305566e-06}, {"id": 164, "seek": 108872, "start": 1088.72, "end": 1100.28, "text": " But yeah, I mean, I could have instead said, um, class my int and then let's create a my", "tokens": [583, 1338, 11, 286, 914, 11, 286, 727, 362, 2602, 848, 11, 1105, 11, 1508, 452, 560, 293, 550, 718, 311, 1884, 257, 452], "temperature": 0.0, "avg_logprob": -0.2352459477443321, "compression_ratio": 1.424778761061947, "no_speech_prob": 2.521559508750215e-06}, {"id": 165, "seek": 108872, "start": 1100.28, "end": 1104.72, "text": " int equals my int one.", "tokens": [560, 6915, 452, 560, 472, 13], "temperature": 0.0, "avg_logprob": -0.2352459477443321, "compression_ratio": 1.424778761061947, "no_speech_prob": 2.521559508750215e-06}, {"id": 166, "seek": 108872, "start": 1104.72, "end": 1111.16, "text": " And then let's say this only applies to a my int.", "tokens": [400, 550, 718, 311, 584, 341, 787, 13165, 281, 257, 452, 560, 13], "temperature": 0.0, "avg_logprob": -0.2352459477443321, "compression_ratio": 1.424778761061947, "no_speech_prob": 2.521559508750215e-06}, {"id": 167, "seek": 111116, "start": 1111.16, "end": 1119.72, "text": " And so now let's not use a one, but let's use my int.", "tokens": [400, 370, 586, 718, 311, 406, 764, 257, 472, 11, 457, 718, 311, 764, 452, 560, 13], "temperature": 0.0, "avg_logprob": -0.14326494932174683, "compression_ratio": 1.5, "no_speech_prob": 1.5294091326722992e-06}, {"id": 168, "seek": 111116, "start": 1119.72, "end": 1128.48, "text": " So you can see now the tensor, the image tensor hasn't changed, but the int has.", "tokens": [407, 291, 393, 536, 586, 264, 40863, 11, 264, 3256, 40863, 6132, 380, 3105, 11, 457, 264, 560, 575, 13], "temperature": 0.0, "avg_logprob": -0.14326494932174683, "compression_ratio": 1.5, "no_speech_prob": 1.5294091326722992e-06}, {"id": 169, "seek": 111116, "start": 1128.48, "end": 1137.68, "text": " So it's just a, yeah, it's just a different way of doing function dispatch.", "tokens": [407, 309, 311, 445, 257, 11, 1338, 11, 309, 311, 445, 257, 819, 636, 295, 884, 2445, 36729, 13], "temperature": 0.0, "avg_logprob": -0.14326494932174683, "compression_ratio": 1.5, "no_speech_prob": 1.5294091326722992e-06}, {"id": 170, "seek": 113768, "start": 1137.68, "end": 1145.04, "text": " But it's a way that makes a lot more sense for data processing than the default way that", "tokens": [583, 309, 311, 257, 636, 300, 1669, 257, 688, 544, 2020, 337, 1412, 9007, 813, 264, 7576, 636, 300], "temperature": 0.0, "avg_logprob": -0.17954301180904858, "compression_ratio": 1.5297297297297296, "no_speech_prob": 2.56123416875198e-06}, {"id": 171, "seek": 113768, "start": 1145.04, "end": 1146.2, "text": " Python has.", "tokens": [15329, 575, 13], "temperature": 0.0, "avg_logprob": -0.17954301180904858, "compression_ratio": 1.5297297297297296, "no_speech_prob": 2.56123416875198e-06}, {"id": 172, "seek": 113768, "start": 1146.2, "end": 1153.0, "text": " And so the nice thing is that like Python is specifically designed to be able to provide", "tokens": [400, 370, 264, 1481, 551, 307, 300, 411, 15329, 307, 4682, 4761, 281, 312, 1075, 281, 2893], "temperature": 0.0, "avg_logprob": -0.17954301180904858, "compression_ratio": 1.5297297297297296, "no_speech_prob": 2.56123416875198e-06}, {"id": 173, "seek": 113768, "start": 1153.0, "end": 1154.72, "text": " this kind of functionality.", "tokens": [341, 733, 295, 14980, 13], "temperature": 0.0, "avg_logprob": -0.17954301180904858, "compression_ratio": 1.5297297297297296, "no_speech_prob": 2.56123416875198e-06}, {"id": 174, "seek": 113768, "start": 1154.72, "end": 1159.4, "text": " So everything we've written, as you'll see, we've written it all.", "tokens": [407, 1203, 321, 600, 3720, 11, 382, 291, 603, 536, 11, 321, 600, 3720, 309, 439, 13], "temperature": 0.0, "avg_logprob": -0.17954301180904858, "compression_ratio": 1.5297297297297296, "no_speech_prob": 2.56123416875198e-06}, {"id": 175, "seek": 115940, "start": 1159.4, "end": 1172.0400000000002, "text": " Okay, we've got a few questions here, so let's answer these first.", "tokens": [1033, 11, 321, 600, 658, 257, 1326, 1651, 510, 11, 370, 718, 311, 1867, 613, 700, 13], "temperature": 0.0, "avg_logprob": -0.453789557180097, "compression_ratio": 1.450381679389313, "no_speech_prob": 1.6186835637199692e-05}, {"id": 176, "seek": 115940, "start": 1172.0400000000002, "end": 1178.8000000000002, "text": " You defined empty I, but when did that get passed to norm?", "tokens": [509, 7642, 6707, 286, 11, 457, 562, 630, 300, 483, 4678, 281, 2026, 30], "temperature": 0.0, "avg_logprob": -0.453789557180097, "compression_ratio": 1.450381679389313, "no_speech_prob": 1.6186835637199692e-05}, {"id": 177, "seek": 115940, "start": 1178.8000000000002, "end": 1180.8000000000002, "text": " It got passed to norm.", "tokens": [467, 658, 4678, 281, 2026, 13], "temperature": 0.0, "avg_logprob": -0.453789557180097, "compression_ratio": 1.450381679389313, "no_speech_prob": 1.6186835637199692e-05}, {"id": 178, "seek": 115940, "start": 1180.8000000000002, "end": 1185.0800000000002, "text": " Oh, it got passed to norm.", "tokens": [876, 11, 309, 658, 4678, 281, 2026, 13], "temperature": 0.0, "avg_logprob": -0.453789557180097, "compression_ratio": 1.450381679389313, "no_speech_prob": 1.6186835637199692e-05}, {"id": 179, "seek": 115940, "start": 1185.0800000000002, "end": 1188.0800000000002, "text": " Yeah, I think.", "tokens": [865, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.453789557180097, "compression_ratio": 1.450381679389313, "no_speech_prob": 1.6186835637199692e-05}, {"id": 180, "seek": 118808, "start": 1188.08, "end": 1192.1999999999998, "text": " Yes, okay, so let's go back and check this.", "tokens": [1079, 11, 1392, 11, 370, 718, 311, 352, 646, 293, 1520, 341, 13], "temperature": 0.0, "avg_logprob": -0.2854845682779948, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.219165591872297e-05}, {"id": 181, "seek": 118808, "start": 1192.1999999999998, "end": 1196.6399999999999, "text": " So we're going to do my tensor image.", "tokens": [407, 321, 434, 516, 281, 360, 452, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2854845682779948, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.219165591872297e-05}, {"id": 182, "seek": 118808, "start": 1196.6399999999999, "end": 1201.36, "text": " So there it is with a my tensor image.", "tokens": [407, 456, 309, 307, 365, 257, 452, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2854845682779948, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.219165591872297e-05}, {"id": 183, "seek": 118808, "start": 1201.36, "end": 1207.96, "text": " If we made the tuple non-my tensor image, just a regular tensor.", "tokens": [759, 321, 1027, 264, 2604, 781, 2107, 12, 2226, 40863, 3256, 11, 445, 257, 3890, 40863, 13], "temperature": 0.0, "avg_logprob": -0.2854845682779948, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.219165591872297e-05}, {"id": 184, "seek": 118808, "start": 1207.96, "end": 1209.8799999999999, "text": " Oh, it's still running.", "tokens": [876, 11, 309, 311, 920, 2614, 13], "temperature": 0.0, "avg_logprob": -0.2854845682779948, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.219165591872297e-05}, {"id": 185, "seek": 118808, "start": 1209.8799999999999, "end": 1212.8799999999999, "text": " Why is that?", "tokens": [1545, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.2854845682779948, "compression_ratio": 1.4605263157894737, "no_speech_prob": 3.219165591872297e-05}, {"id": 186, "seek": 121288, "start": 1212.88, "end": 1223.44, "text": " I actually changed the type of t image at some point.", "tokens": [286, 767, 3105, 264, 2010, 295, 256, 3256, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.5214010126450482, "compression_ratio": 1.146067415730337, "no_speech_prob": 3.02372809528606e-05}, {"id": 187, "seek": 121288, "start": 1223.44, "end": 1230.44, "text": " I didn't mean to do that.", "tokens": [286, 994, 380, 914, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.5214010126450482, "compression_ratio": 1.146067415730337, "no_speech_prob": 3.02372809528606e-05}, {"id": 188, "seek": 121288, "start": 1230.44, "end": 1231.44, "text": " Let's run it together.", "tokens": [961, 311, 1190, 309, 1214, 13], "temperature": 0.0, "avg_logprob": -0.5214010126450482, "compression_ratio": 1.146067415730337, "no_speech_prob": 3.02372809528606e-05}, {"id": 189, "seek": 123144, "start": 1231.44, "end": 1256.64, "text": " Okay, so, oh, because I'm actually changing the original.", "tokens": [1033, 11, 370, 11, 1954, 11, 570, 286, 478, 767, 4473, 264, 3380, 13], "temperature": 0.0, "avg_logprob": -0.4343768869127546, "compression_ratio": 1.0348837209302326, "no_speech_prob": 1.1123592230433132e-05}, {"id": 190, "seek": 123144, "start": 1256.64, "end": 1258.3600000000001, "text": " That looks like we found a bug.", "tokens": [663, 1542, 411, 321, 1352, 257, 7426, 13], "temperature": 0.0, "avg_logprob": -0.4343768869127546, "compression_ratio": 1.0348837209302326, "no_speech_prob": 1.1123592230433132e-05}, {"id": 191, "seek": 125836, "start": 1258.36, "end": 1262.36, "text": " Okay, let's make a note.", "tokens": [1033, 11, 718, 311, 652, 257, 3637, 13], "temperature": 0.0, "avg_logprob": -0.6476099114668997, "compression_ratio": 1.18348623853211, "no_speech_prob": 1.0615794963086955e-05}, {"id": 192, "seek": 125836, "start": 1262.36, "end": 1263.36, "text": " Bug.", "tokens": [23821, 13], "temperature": 0.0, "avg_logprob": -0.6476099114668997, "compression_ratio": 1.18348623853211, "no_speech_prob": 1.0615794963086955e-05}, {"id": 193, "seek": 125836, "start": 1263.36, "end": 1272.36, "text": " So, let's do it separately.", "tokens": [407, 11, 718, 311, 360, 309, 14759, 13], "temperature": 0.0, "avg_logprob": -0.6476099114668997, "compression_ratio": 1.18348623853211, "no_speech_prob": 1.0615794963086955e-05}, {"id": 194, "seek": 125836, "start": 1272.36, "end": 1279.7199999999998, "text": " Yes, I do need a dot.", "tokens": [1079, 11, 286, 360, 643, 257, 5893, 13], "temperature": 0.0, "avg_logprob": -0.6476099114668997, "compression_ratio": 1.18348623853211, "no_speech_prob": 1.0615794963086955e-05}, {"id": 195, "seek": 125836, "start": 1279.7199999999998, "end": 1282.7199999999998, "text": " Oh, I've got plug.", "tokens": [876, 11, 286, 600, 658, 5452, 13], "temperature": 0.0, "avg_logprob": -0.6476099114668997, "compression_ratio": 1.18348623853211, "no_speech_prob": 1.0615794963086955e-05}, {"id": 196, "seek": 125836, "start": 1282.7199999999998, "end": 1285.7199999999998, "text": " I shouldn't, but I have a bug.", "tokens": [286, 4659, 380, 11, 457, 286, 362, 257, 7426, 13], "temperature": 0.0, "avg_logprob": -0.6476099114668997, "compression_ratio": 1.18348623853211, "no_speech_prob": 1.0615794963086955e-05}, {"id": 197, "seek": 128572, "start": 1285.72, "end": 1288.72, "text": " Okay, let's do it again.", "tokens": [1033, 11, 718, 311, 360, 309, 797, 13], "temperature": 0.0, "avg_logprob": -0.21097378363976113, "compression_ratio": 1.3571428571428572, "no_speech_prob": 1.2805314327124506e-05}, {"id": 198, "seek": 128572, "start": 1288.72, "end": 1290.76, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.21097378363976113, "compression_ratio": 1.3571428571428572, "no_speech_prob": 1.2805314327124506e-05}, {"id": 199, "seek": 128572, "start": 1290.76, "end": 1295.92, "text": " Okay, so t image is now a tensor.", "tokens": [1033, 11, 370, 256, 3256, 307, 586, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.21097378363976113, "compression_ratio": 1.3571428571428572, "no_speech_prob": 1.2805314327124506e-05}, {"id": 200, "seek": 128572, "start": 1295.92, "end": 1302.04, "text": " And so, okay, so now when I run this on the tuple, which has a normal tensor, it doesn't", "tokens": [400, 370, 11, 1392, 11, 370, 586, 562, 286, 1190, 341, 322, 264, 2604, 781, 11, 597, 575, 257, 2710, 40863, 11, 309, 1177, 380], "temperature": 0.0, "avg_logprob": -0.21097378363976113, "compression_ratio": 1.3571428571428572, "no_speech_prob": 1.2805314327124506e-05}, {"id": 201, "seek": 128572, "start": 1302.04, "end": 1303.04, "text": " run.", "tokens": [1190, 13], "temperature": 0.0, "avg_logprob": -0.21097378363976113, "compression_ratio": 1.3571428571428572, "no_speech_prob": 1.2805314327124506e-05}, {"id": 202, "seek": 128572, "start": 1303.04, "end": 1304.04, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.21097378363976113, "compression_ratio": 1.3571428571428572, "no_speech_prob": 1.2805314327124506e-05}, {"id": 203, "seek": 130404, "start": 1304.04, "end": 1318.1599999999999, "text": " And so then if I change it to the subclass, then it does run.", "tokens": [400, 370, 550, 498, 286, 1319, 309, 281, 264, 1422, 11665, 11, 550, 309, 775, 1190, 13], "temperature": 0.0, "avg_logprob": -0.23534288714008947, "compression_ratio": 1.130952380952381, "no_speech_prob": 1.8631300918059424e-05}, {"id": 204, "seek": 130404, "start": 1318.1599999999999, "end": 1328.04, "text": " And we wanted to make this float.", "tokens": [400, 321, 1415, 281, 652, 341, 15706, 13], "temperature": 0.0, "avg_logprob": -0.23534288714008947, "compression_ratio": 1.130952380952381, "no_speech_prob": 1.8631300918059424e-05}, {"id": 205, "seek": 132804, "start": 1328.04, "end": 1334.96, "text": " And that should be a tensor array.", "tokens": [400, 300, 820, 312, 257, 40863, 10225, 13], "temperature": 0.0, "avg_logprob": -0.2577399454618755, "compression_ratio": 1.2079207920792079, "no_speech_prob": 1.8162099877372384e-06}, {"id": 206, "seek": 132804, "start": 1334.96, "end": 1343.24, "text": " Okay, there we go.", "tokens": [1033, 11, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.2577399454618755, "compression_ratio": 1.2079207920792079, "no_speech_prob": 1.8162099877372384e-06}, {"id": 207, "seek": 132804, "start": 1343.24, "end": 1349.1, "text": " So that one is just being applied to the image and not to the label.", "tokens": [407, 300, 472, 307, 445, 885, 6456, 281, 264, 3256, 293, 406, 281, 264, 7645, 13], "temperature": 0.0, "avg_logprob": -0.2577399454618755, "compression_ratio": 1.2079207920792079, "no_speech_prob": 1.8162099877372384e-06}, {"id": 208, "seek": 134910, "start": 1349.1, "end": 1359.36, "text": " And so to answer Max's question, we absolutely could just write int here and put that back", "tokens": [400, 370, 281, 1867, 7402, 311, 1168, 11, 321, 3122, 727, 445, 2464, 560, 510, 293, 829, 300, 646], "temperature": 0.0, "avg_logprob": -0.15268917083740235, "compression_ratio": 1.382716049382716, "no_speech_prob": 3.1875517834123457e-06}, {"id": 209, "seek": 134910, "start": 1359.36, "end": 1365.48, "text": " to t image here.", "tokens": [281, 256, 3256, 510, 13], "temperature": 0.0, "avg_logprob": -0.15268917083740235, "compression_ratio": 1.382716049382716, "no_speech_prob": 3.1875517834123457e-06}, {"id": 210, "seek": 134910, "start": 1365.48, "end": 1368.1999999999998, "text": " And now it is being applied.", "tokens": [400, 586, 309, 307, 885, 6456, 13], "temperature": 0.0, "avg_logprob": -0.15268917083740235, "compression_ratio": 1.382716049382716, "no_speech_prob": 3.1875517834123457e-06}, {"id": 211, "seek": 134910, "start": 1368.1999999999998, "end": 1375.6, "text": " The reason I was showing you subclassing is because this is how we add kind of semantic", "tokens": [440, 1778, 286, 390, 4099, 291, 1422, 11665, 278, 307, 570, 341, 307, 577, 321, 909, 733, 295, 47982], "temperature": 0.0, "avg_logprob": -0.15268917083740235, "compression_ratio": 1.382716049382716, "no_speech_prob": 3.1875517834123457e-06}, {"id": 212, "seek": 137560, "start": 1375.6, "end": 1381.08, "text": " markers to existing types so that we can get all the functionality of the existing types,", "tokens": [19175, 281, 6741, 3467, 370, 300, 321, 393, 483, 439, 264, 14980, 295, 264, 6741, 3467, 11], "temperature": 0.0, "avg_logprob": -0.21672237453176013, "compression_ratio": 1.5056179775280898, "no_speech_prob": 3.1875172226136783e-06}, {"id": 213, "seek": 137560, "start": 1381.08, "end": 1389.6, "text": " but also say that they represent different kinds of information.", "tokens": [457, 611, 584, 300, 436, 2906, 819, 3685, 295, 1589, 13], "temperature": 0.0, "avg_logprob": -0.21672237453176013, "compression_ratio": 1.5056179775280898, "no_speech_prob": 3.1875172226136783e-06}, {"id": 214, "seek": 137560, "start": 1389.6, "end": 1396.6, "text": " So for example, in Fast.ai version 2, there is a capital I int, which is basically an", "tokens": [407, 337, 1365, 11, 294, 15968, 13, 1301, 3037, 568, 11, 456, 307, 257, 4238, 286, 560, 11, 597, 307, 1936, 364], "temperature": 0.0, "avg_logprob": -0.21672237453176013, "compression_ratio": 1.5056179775280898, "no_speech_prob": 3.1875172226136783e-06}, {"id": 215, "seek": 137560, "start": 1396.6, "end": 1399.8799999999999, "text": " int that has a show method.", "tokens": [560, 300, 575, 257, 855, 3170, 13], "temperature": 0.0, "avg_logprob": -0.21672237453176013, "compression_ratio": 1.5056179775280898, "no_speech_prob": 3.1875172226136783e-06}, {"id": 216, "seek": 139988, "start": 1399.88, "end": 1407.4, "text": " It knows how to show itself.", "tokens": [467, 3255, 577, 281, 855, 2564, 13], "temperature": 0.0, "avg_logprob": -0.2560517274880711, "compression_ratio": 1.4011627906976745, "no_speech_prob": 1.260678891412681e-05}, {"id": 217, "seek": 139988, "start": 1407.4, "end": 1409.1200000000001, "text": " What kind of work do we put int after the pipe?", "tokens": [708, 733, 295, 589, 360, 321, 829, 560, 934, 264, 11240, 30], "temperature": 0.0, "avg_logprob": -0.2560517274880711, "compression_ratio": 1.4011627906976745, "no_speech_prob": 1.260678891412681e-05}, {"id": 218, "seek": 139988, "start": 1409.1200000000001, "end": 1410.6000000000001, "text": " I'm not sure what you mean, Caleb.", "tokens": [286, 478, 406, 988, 437, 291, 914, 11, 30331, 13], "temperature": 0.0, "avg_logprob": -0.2560517274880711, "compression_ratio": 1.4011627906976745, "no_speech_prob": 1.260678891412681e-05}, {"id": 219, "seek": 139988, "start": 1410.6000000000001, "end": 1413.2, "text": " We don't have a pipe.", "tokens": [492, 500, 380, 362, 257, 11240, 13], "temperature": 0.0, "avg_logprob": -0.2560517274880711, "compression_ratio": 1.4011627906976745, "no_speech_prob": 1.260678891412681e-05}, {"id": 220, "seek": 139988, "start": 1413.2, "end": 1420.44, "text": " So feel free to re-ask that question if I'm not understanding.", "tokens": [407, 841, 1737, 281, 319, 12, 3863, 300, 1168, 498, 286, 478, 406, 3701, 13], "temperature": 0.0, "avg_logprob": -0.2560517274880711, "compression_ratio": 1.4011627906976745, "no_speech_prob": 1.260678891412681e-05}, {"id": 221, "seek": 139988, "start": 1420.44, "end": 1421.6000000000001, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2560517274880711, "compression_ratio": 1.4011627906976745, "no_speech_prob": 1.260678891412681e-05}, {"id": 222, "seek": 139988, "start": 1421.6000000000001, "end": 1425.5600000000002, "text": " So this is kind of on the right track.", "tokens": [407, 341, 307, 733, 295, 322, 264, 558, 2837, 13], "temperature": 0.0, "avg_logprob": -0.2560517274880711, "compression_ratio": 1.4011627906976745, "no_speech_prob": 1.260678891412681e-05}, {"id": 223, "seek": 142556, "start": 1425.56, "end": 1430.12, "text": " One problem here though is that we don't want to have to pass the mean and standard deviation", "tokens": [1485, 1154, 510, 1673, 307, 300, 321, 500, 380, 528, 281, 362, 281, 1320, 264, 914, 293, 3832, 25163], "temperature": 0.0, "avg_logprob": -0.29732830460007126, "compression_ratio": 1.8782051282051282, "no_speech_prob": 1.3211775694799144e-05}, {"id": 224, "seek": 142556, "start": 1430.12, "end": 1431.76, "text": " in every time.", "tokens": [294, 633, 565, 13], "temperature": 0.0, "avg_logprob": -0.29732830460007126, "compression_ratio": 1.8782051282051282, "no_speech_prob": 1.3211775694799144e-05}, {"id": 225, "seek": 142556, "start": 1431.76, "end": 1439.52, "text": " So it would be better if we could grab the mean and standard deviation, and we could", "tokens": [407, 309, 576, 312, 1101, 498, 321, 727, 4444, 264, 914, 293, 3832, 25163, 11, 293, 321, 727], "temperature": 0.0, "avg_logprob": -0.29732830460007126, "compression_ratio": 1.8782051282051282, "no_speech_prob": 1.3211775694799144e-05}, {"id": 226, "seek": 142556, "start": 1439.52, "end": 1449.44, "text": " say mean, standard deviation equals t image dot mean, t image dot standard deviation,", "tokens": [584, 914, 11, 3832, 25163, 6915, 256, 3256, 5893, 914, 11, 256, 3256, 5893, 3832, 25163, 11], "temperature": 0.0, "avg_logprob": -0.29732830460007126, "compression_ratio": 1.8782051282051282, "no_speech_prob": 1.3211775694799144e-05}, {"id": 227, "seek": 142556, "start": 1449.44, "end": 1451.56, "text": " oops, equals.", "tokens": [34166, 11, 6915, 13], "temperature": 0.0, "avg_logprob": -0.29732830460007126, "compression_ratio": 1.8782051282051282, "no_speech_prob": 1.3211775694799144e-05}, {"id": 228, "seek": 145156, "start": 1451.56, "end": 1457.96, "text": " I'm not sure what I just did.", "tokens": [286, 478, 406, 988, 437, 286, 445, 630, 13], "temperature": 0.0, "avg_logprob": -0.33020016185024326, "compression_ratio": 1.3768115942028984, "no_speech_prob": 1.0451381058373954e-05}, {"id": 229, "seek": 145156, "start": 1457.96, "end": 1461.28, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.33020016185024326, "compression_ratio": 1.3768115942028984, "no_speech_prob": 1.0451381058373954e-05}, {"id": 230, "seek": 145156, "start": 1461.28, "end": 1462.28, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.33020016185024326, "compression_ratio": 1.3768115942028984, "no_speech_prob": 1.0451381058373954e-05}, {"id": 231, "seek": 145156, "start": 1462.28, "end": 1472.44, "text": " So now we've got a mean and standard deviation.", "tokens": [407, 586, 321, 600, 658, 257, 914, 293, 3832, 25163, 13], "temperature": 0.0, "avg_logprob": -0.33020016185024326, "compression_ratio": 1.3768115942028984, "no_speech_prob": 1.0451381058373954e-05}, {"id": 232, "seek": 145156, "start": 1472.44, "end": 1481.48, "text": " So what we could do is we could create a function which is a partial application of norm over", "tokens": [407, 437, 321, 727, 360, 307, 321, 727, 1884, 257, 2445, 597, 307, 257, 14641, 3861, 295, 2026, 670], "temperature": 0.0, "avg_logprob": -0.33020016185024326, "compression_ratio": 1.3768115942028984, "no_speech_prob": 1.0451381058373954e-05}, {"id": 233, "seek": 148148, "start": 1481.48, "end": 1486.2, "text": " that mean and that standard deviation.", "tokens": [300, 914, 293, 300, 3832, 25163, 13], "temperature": 0.0, "avg_logprob": -0.2659336152623911, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.0783260222524405e-05}, {"id": 234, "seek": 148148, "start": 1486.2, "end": 1498.28, "text": " So now we could go normed image equals f of that instance.", "tokens": [407, 586, 321, 727, 352, 2026, 292, 3256, 6915, 283, 295, 300, 5197, 13], "temperature": 0.0, "avg_logprob": -0.2659336152623911, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.0783260222524405e-05}, {"id": 235, "seek": 148148, "start": 1498.28, "end": 1504.92, "text": " And then of course we'll need to put this back to, let's just make this tensor for now,", "tokens": [400, 550, 295, 1164, 321, 603, 643, 281, 829, 341, 646, 281, 11, 718, 311, 445, 652, 341, 40863, 337, 586, 11], "temperature": 0.0, "avg_logprob": -0.2659336152623911, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.0783260222524405e-05}, {"id": 236, "seek": 148148, "start": 1504.92, "end": 1505.92, "text": " say.", "tokens": [584, 13], "temperature": 0.0, "avg_logprob": -0.2659336152623911, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.0783260222524405e-05}, {"id": 237, "seek": 148148, "start": 1505.92, "end": 1506.92, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.2659336152623911, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.0783260222524405e-05}, {"id": 238, "seek": 150692, "start": 1506.92, "end": 1511.68, "text": " Or we could do it over our tuple.", "tokens": [1610, 321, 727, 360, 309, 670, 527, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.230113380833676, "compression_ratio": 1.4863387978142077, "no_speech_prob": 5.173850695427973e-06}, {"id": 239, "seek": 150692, "start": 1511.68, "end": 1521.0, "text": " So f, we don't need an f anymore, an s anymore.", "tokens": [407, 283, 11, 321, 500, 380, 643, 364, 283, 3602, 11, 364, 262, 3602, 13], "temperature": 0.0, "avg_logprob": -0.230113380833676, "compression_ratio": 1.4863387978142077, "no_speech_prob": 5.173850695427973e-06}, {"id": 240, "seek": 150692, "start": 1521.0, "end": 1525.04, "text": " So and this is kind of more how we would want something like normalization to work, right?", "tokens": [407, 293, 341, 307, 733, 295, 544, 577, 321, 576, 528, 746, 411, 2710, 2144, 281, 589, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.230113380833676, "compression_ratio": 1.4863387978142077, "no_speech_prob": 5.173850695427973e-06}, {"id": 241, "seek": 150692, "start": 1525.04, "end": 1531.8000000000002, "text": " Because we generally want to normalize a bunch of things with the same mean and standard", "tokens": [1436, 321, 5101, 528, 281, 2710, 1125, 257, 3840, 295, 721, 365, 264, 912, 914, 293, 3832], "temperature": 0.0, "avg_logprob": -0.230113380833676, "compression_ratio": 1.4863387978142077, "no_speech_prob": 5.173850695427973e-06}, {"id": 242, "seek": 150692, "start": 1531.8000000000002, "end": 1534.4, "text": " deviation.", "tokens": [25163, 13], "temperature": 0.0, "avg_logprob": -0.230113380833676, "compression_ratio": 1.4863387978142077, "no_speech_prob": 5.173850695427973e-06}, {"id": 243, "seek": 153440, "start": 1534.4, "end": 1537.8400000000001, "text": " So this is more kind of the behavior we want.", "tokens": [407, 341, 307, 544, 733, 295, 264, 5223, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.136579282356031, "compression_ratio": 1.7941176470588236, "no_speech_prob": 6.33903982816264e-06}, {"id": 244, "seek": 153440, "start": 1537.8400000000001, "end": 1544.0800000000002, "text": " Except there's a few other things we'd want in normalization.", "tokens": [16192, 456, 311, 257, 1326, 661, 721, 321, 1116, 528, 294, 2710, 2144, 13], "temperature": 0.0, "avg_logprob": -0.136579282356031, "compression_ratio": 1.7941176470588236, "no_speech_prob": 6.33903982816264e-06}, {"id": 245, "seek": 153440, "start": 1544.0800000000002, "end": 1546.96, "text": " One is we generally want to be able to serialize it.", "tokens": [1485, 307, 321, 5101, 528, 281, 312, 1075, 281, 17436, 1125, 309, 13], "temperature": 0.0, "avg_logprob": -0.136579282356031, "compression_ratio": 1.7941176470588236, "no_speech_prob": 6.33903982816264e-06}, {"id": 246, "seek": 153440, "start": 1546.96, "end": 1552.3600000000001, "text": " We'd want to be able to save the transform that we're using to disk, including the mean", "tokens": [492, 1116, 528, 281, 312, 1075, 281, 3155, 264, 4088, 300, 321, 434, 1228, 281, 12355, 11, 3009, 264, 914], "temperature": 0.0, "avg_logprob": -0.136579282356031, "compression_ratio": 1.7941176470588236, "no_speech_prob": 6.33903982816264e-06}, {"id": 247, "seek": 153440, "start": 1552.3600000000001, "end": 1556.0400000000002, "text": " and standard deviation.", "tokens": [293, 3832, 25163, 13], "temperature": 0.0, "avg_logprob": -0.136579282356031, "compression_ratio": 1.7941176470588236, "no_speech_prob": 6.33903982816264e-06}, {"id": 248, "seek": 153440, "start": 1556.0400000000002, "end": 1560.4, "text": " The second thing we'd want to be able to do is we'd want to be able to undo the normalization", "tokens": [440, 1150, 551, 321, 1116, 528, 281, 312, 1075, 281, 360, 307, 321, 1116, 528, 281, 312, 1075, 281, 23779, 264, 2710, 2144], "temperature": 0.0, "avg_logprob": -0.136579282356031, "compression_ratio": 1.7941176470588236, "no_speech_prob": 6.33903982816264e-06}, {"id": 249, "seek": 156040, "start": 1560.4, "end": 1566.48, "text": " so that when you get back an image or whatever from some model, we'd want to be able to display", "tokens": [370, 300, 562, 291, 483, 646, 364, 3256, 420, 2035, 490, 512, 2316, 11, 321, 1116, 528, 281, 312, 1075, 281, 4674], "temperature": 0.0, "avg_logprob": -0.16805616446903773, "compression_ratio": 1.6518218623481782, "no_speech_prob": 9.516180398350116e-06}, {"id": 250, "seek": 156040, "start": 1566.48, "end": 1570.0800000000002, "text": " it, which means we'd have to be able to denormalize it.", "tokens": [309, 11, 597, 1355, 321, 1116, 362, 281, 312, 1075, 281, 1441, 24440, 1125, 309, 13], "temperature": 0.0, "avg_logprob": -0.16805616446903773, "compression_ratio": 1.6518218623481782, "no_speech_prob": 9.516180398350116e-06}, {"id": 251, "seek": 156040, "start": 1570.0800000000002, "end": 1572.8400000000001, "text": " So that means that we're going to need proper state.", "tokens": [407, 300, 1355, 300, 321, 434, 516, 281, 643, 2296, 1785, 13], "temperature": 0.0, "avg_logprob": -0.16805616446903773, "compression_ratio": 1.6518218623481782, "no_speech_prob": 9.516180398350116e-06}, {"id": 252, "seek": 156040, "start": 1572.8400000000001, "end": 1577.24, "text": " So the easiest way to get proper state is to create a class.", "tokens": [407, 264, 12889, 636, 281, 483, 2296, 1785, 307, 281, 1884, 257, 1508, 13], "temperature": 0.0, "avg_logprob": -0.16805616446903773, "compression_ratio": 1.6518218623481782, "no_speech_prob": 9.516180398350116e-06}, {"id": 253, "seek": 156040, "start": 1577.24, "end": 1582.68, "text": " Oh, before I do that, I'll just point something out.", "tokens": [876, 11, 949, 286, 360, 300, 11, 286, 603, 445, 935, 746, 484, 13], "temperature": 0.0, "avg_logprob": -0.16805616446903773, "compression_ratio": 1.6518218623481782, "no_speech_prob": 9.516180398350116e-06}, {"id": 254, "seek": 156040, "start": 1582.68, "end": 1587.2800000000002, "text": " For those of you that haven't spent much time with decorators, this thing where I went at", "tokens": [1171, 729, 295, 291, 300, 2378, 380, 4418, 709, 565, 365, 7919, 3391, 11, 341, 551, 689, 286, 1437, 412], "temperature": 0.0, "avg_logprob": -0.16805616446903773, "compression_ratio": 1.6518218623481782, "no_speech_prob": 9.516180398350116e-06}, {"id": 255, "seek": 158728, "start": 1587.28, "end": 1592.0, "text": " transform and then I said def norm, that's exactly the same as doing this.", "tokens": [4088, 293, 550, 286, 848, 1060, 2026, 11, 300, 311, 2293, 264, 912, 382, 884, 341, 13], "temperature": 0.0, "avg_logprob": -0.18936958741605953, "compression_ratio": 1.7889447236180904, "no_speech_prob": 1.045148110279115e-05}, {"id": 256, "seek": 158728, "start": 1592.0, "end": 1597.6, "text": " I could have just said def say underscore norm equals this, and then I could have said", "tokens": [286, 727, 362, 445, 848, 1060, 584, 37556, 2026, 6915, 341, 11, 293, 550, 286, 727, 362, 848], "temperature": 0.0, "avg_logprob": -0.18936958741605953, "compression_ratio": 1.7889447236180904, "no_speech_prob": 1.045148110279115e-05}, {"id": 257, "seek": 158728, "start": 1597.6, "end": 1604.72, "text": " norm equals transform norm.", "tokens": [2026, 6915, 4088, 2026, 13], "temperature": 0.0, "avg_logprob": -0.18936958741605953, "compression_ratio": 1.7889447236180904, "no_speech_prob": 1.045148110279115e-05}, {"id": 258, "seek": 158728, "start": 1604.72, "end": 1605.72, "text": " And that's identical.", "tokens": [400, 300, 311, 14800, 13], "temperature": 0.0, "avg_logprob": -0.18936958741605953, "compression_ratio": 1.7889447236180904, "no_speech_prob": 1.045148110279115e-05}, {"id": 259, "seek": 158728, "start": 1605.72, "end": 1609.32, "text": " As you can see, it gives exactly the same answers.", "tokens": [1018, 291, 393, 536, 11, 309, 2709, 2293, 264, 912, 6338, 13], "temperature": 0.0, "avg_logprob": -0.18936958741605953, "compression_ratio": 1.7889447236180904, "no_speech_prob": 1.045148110279115e-05}, {"id": 260, "seek": 158728, "start": 1609.32, "end": 1617.24, "text": " That's literally the definition of a decorator in Python, is it literally takes this function", "tokens": [663, 311, 3736, 264, 7123, 295, 257, 7919, 1639, 294, 15329, 11, 307, 309, 3736, 2516, 341, 2445], "temperature": 0.0, "avg_logprob": -0.18936958741605953, "compression_ratio": 1.7889447236180904, "no_speech_prob": 1.045148110279115e-05}, {"id": 261, "seek": 161724, "start": 1617.24, "end": 1622.0, "text": " and passes it to this function.", "tokens": [293, 11335, 309, 281, 341, 2445, 13], "temperature": 0.0, "avg_logprob": -0.2567017968021222, "compression_ratio": 1.4903225806451612, "no_speech_prob": 1.012984193948796e-05}, {"id": 262, "seek": 161724, "start": 1622.0, "end": 1624.72, "text": " That's what at does.", "tokens": [663, 311, 437, 412, 775, 13], "temperature": 0.0, "avg_logprob": -0.2567017968021222, "compression_ratio": 1.4903225806451612, "no_speech_prob": 1.012984193948796e-05}, {"id": 263, "seek": 161724, "start": 1624.72, "end": 1629.96, "text": " So anytime you see at something, you know that, oh, thank you, transform underscore", "tokens": [407, 13038, 291, 536, 412, 746, 11, 291, 458, 300, 11, 1954, 11, 1309, 291, 11, 4088, 37556], "temperature": 0.0, "avg_logprob": -0.2567017968021222, "compression_ratio": 1.4903225806451612, "no_speech_prob": 1.012984193948796e-05}, {"id": 264, "seek": 161724, "start": 1629.96, "end": 1632.88, "text": " norm.", "tokens": [2026, 13], "temperature": 0.0, "avg_logprob": -0.2567017968021222, "compression_ratio": 1.4903225806451612, "no_speech_prob": 1.012984193948796e-05}, {"id": 265, "seek": 161724, "start": 1632.88, "end": 1634.96, "text": " You know that that's what it's doing.", "tokens": [509, 458, 300, 300, 311, 437, 309, 311, 884, 13], "temperature": 0.0, "avg_logprob": -0.2567017968021222, "compression_ratio": 1.4903225806451612, "no_speech_prob": 1.012984193948796e-05}, {"id": 266, "seek": 161724, "start": 1634.96, "end": 1639.68, "text": " Thanks very much for picking up my silly mistakes.", "tokens": [2561, 588, 709, 337, 8867, 493, 452, 11774, 8038, 13], "temperature": 0.0, "avg_logprob": -0.2567017968021222, "compression_ratio": 1.4903225806451612, "no_speech_prob": 1.012984193948796e-05}, {"id": 267, "seek": 163968, "start": 1639.68, "end": 1649.04, "text": " Okay, so yeah, it's important to remember when you see a decorator, it's something you", "tokens": [1033, 11, 370, 1338, 11, 309, 311, 1021, 281, 1604, 562, 291, 536, 257, 7919, 1639, 11, 309, 311, 746, 291], "temperature": 0.0, "avg_logprob": -0.2112463398983604, "compression_ratio": 1.445054945054945, "no_speech_prob": 1.2679198562182137e-06}, {"id": 268, "seek": 163968, "start": 1649.04, "end": 1652.28, "text": " can always run that manually on functions.", "tokens": [393, 1009, 1190, 300, 16945, 322, 6828, 13], "temperature": 0.0, "avg_logprob": -0.2112463398983604, "compression_ratio": 1.445054945054945, "no_speech_prob": 1.2679198562182137e-06}, {"id": 269, "seek": 163968, "start": 1652.28, "end": 1655.72, "text": " And yeah, okay.", "tokens": [400, 1338, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.2112463398983604, "compression_ratio": 1.445054945054945, "no_speech_prob": 1.2679198562182137e-06}, {"id": 270, "seek": 163968, "start": 1655.72, "end": 1664.4, "text": " So what I was saying is in order to have state in this, we should turn it into a class.", "tokens": [407, 437, 286, 390, 1566, 307, 294, 1668, 281, 362, 1785, 294, 341, 11, 321, 820, 1261, 309, 666, 257, 1508, 13], "temperature": 0.0, "avg_logprob": -0.2112463398983604, "compression_ratio": 1.445054945054945, "no_speech_prob": 1.2679198562182137e-06}, {"id": 271, "seek": 163968, "start": 1664.4, "end": 1666.6000000000001, "text": " Let's call it capital N norm.", "tokens": [961, 311, 818, 309, 4238, 426, 2026, 13], "temperature": 0.0, "avg_logprob": -0.2112463398983604, "compression_ratio": 1.445054945054945, "no_speech_prob": 1.2679198562182137e-06}, {"id": 272, "seek": 166660, "start": 1666.6, "end": 1672.04, "text": " And so the way transform works is you can also inherit from it.", "tokens": [400, 370, 264, 636, 4088, 1985, 307, 291, 393, 611, 21389, 490, 309, 13], "temperature": 0.0, "avg_logprob": -0.22133006220278534, "compression_ratio": 1.6352201257861636, "no_speech_prob": 6.04884644417325e-06}, {"id": 273, "seek": 166660, "start": 1672.04, "end": 1678.48, "text": " And so now if you inherit from it, you have to use special names.", "tokens": [400, 370, 586, 498, 291, 21389, 490, 309, 11, 291, 362, 281, 764, 2121, 5288, 13], "temperature": 0.0, "avg_logprob": -0.22133006220278534, "compression_ratio": 1.6352201257861636, "no_speech_prob": 6.04884644417325e-06}, {"id": 274, "seek": 166660, "start": 1678.48, "end": 1684.0, "text": " And encodes is the name that transforms expect.", "tokens": [400, 2058, 4789, 307, 264, 1315, 300, 35592, 2066, 13], "temperature": 0.0, "avg_logprob": -0.22133006220278534, "compression_ratio": 1.6352201257861636, "no_speech_prob": 6.04884644417325e-06}, {"id": 275, "seek": 166660, "start": 1684.0, "end": 1695.1599999999999, "text": " And so normally you wouldn't then pass in those things, but instead you'd pass it.", "tokens": [400, 370, 5646, 291, 2759, 380, 550, 1320, 294, 729, 721, 11, 457, 2602, 291, 1116, 1320, 309, 13], "temperature": 0.0, "avg_logprob": -0.22133006220278534, "compression_ratio": 1.6352201257861636, "no_speech_prob": 6.04884644417325e-06}, {"id": 276, "seek": 169516, "start": 1695.16, "end": 1705.48, "text": " Yeah, and remember, so we could use self dot m comma self dot s equals m comma s, or we", "tokens": [865, 11, 293, 1604, 11, 370, 321, 727, 764, 2698, 5893, 275, 22117, 2698, 5893, 262, 6915, 275, 22117, 262, 11, 420, 321], "temperature": 0.0, "avg_logprob": -0.39256531851632254, "compression_ratio": 1.5443037974683544, "no_speech_prob": 2.3186894395621493e-05}, {"id": 277, "seek": 169516, "start": 1705.48, "end": 1716.2, "text": " could use our little convenient thing we mentioned last time, or doesn't really add as much.", "tokens": [727, 764, 527, 707, 10851, 551, 321, 2835, 1036, 565, 11, 420, 1177, 380, 534, 909, 382, 709, 13], "temperature": 0.0, "avg_logprob": -0.39256531851632254, "compression_ratio": 1.5443037974683544, "no_speech_prob": 2.3186894395621493e-05}, {"id": 278, "seek": 169516, "start": 1716.2, "end": 1719.8000000000002, "text": " So small number, but just to show you the different approaches.", "tokens": [407, 1359, 1230, 11, 457, 445, 281, 855, 291, 264, 819, 11587, 13], "temperature": 0.0, "avg_logprob": -0.39256531851632254, "compression_ratio": 1.5443037974683544, "no_speech_prob": 2.3186894395621493e-05}, {"id": 279, "seek": 171980, "start": 1719.8, "end": 1725.8799999999999, "text": " So go back to that one.", "tokens": [407, 352, 646, 281, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.32915393342363075, "compression_ratio": 1.3018867924528301, "no_speech_prob": 1.2218862138979603e-05}, {"id": 280, "seek": 171980, "start": 1725.8799999999999, "end": 1732.56, "text": " So now we need self dot m, self dot s.", "tokens": [407, 586, 321, 643, 2698, 5893, 275, 11, 2698, 5893, 262, 13], "temperature": 0.0, "avg_logprob": -0.32915393342363075, "compression_ratio": 1.3018867924528301, "no_speech_prob": 1.2218862138979603e-05}, {"id": 281, "seek": 171980, "start": 1732.56, "end": 1737.8, "text": " I still have my annotation here.", "tokens": [286, 920, 362, 452, 48654, 510, 13], "temperature": 0.0, "avg_logprob": -0.32915393342363075, "compression_ratio": 1.3018867924528301, "no_speech_prob": 1.2218862138979603e-05}, {"id": 282, "seek": 171980, "start": 1737.8, "end": 1747.2, "text": " So now we will go f equals capital N norm.", "tokens": [407, 586, 321, 486, 352, 283, 6915, 4238, 426, 2026, 13], "temperature": 0.0, "avg_logprob": -0.32915393342363075, "compression_ratio": 1.3018867924528301, "no_speech_prob": 1.2218862138979603e-05}, {"id": 283, "seek": 174720, "start": 1747.2, "end": 1750.92, "text": " N equals m, s equals s.", "tokens": [426, 6915, 275, 11, 262, 6915, 262, 13], "temperature": 0.0, "avg_logprob": -0.3706176280975342, "compression_ratio": 1.127659574468085, "no_speech_prob": 2.1444318917929195e-05}, {"id": 284, "seek": 174720, "start": 1750.92, "end": 1763.8, "text": " Oh, and of course these need the self.", "tokens": [876, 11, 293, 295, 1164, 613, 643, 264, 2698, 13], "temperature": 0.0, "avg_logprob": -0.3706176280975342, "compression_ratio": 1.127659574468085, "no_speech_prob": 2.1444318917929195e-05}, {"id": 285, "seek": 174720, "start": 1763.8, "end": 1764.8, "text": " And there we go.", "tokens": [400, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.3706176280975342, "compression_ratio": 1.127659574468085, "no_speech_prob": 2.1444318917929195e-05}, {"id": 286, "seek": 174720, "start": 1764.8, "end": 1774.4, "text": " So why isn't that working?", "tokens": [407, 983, 1943, 380, 300, 1364, 30], "temperature": 0.0, "avg_logprob": -0.3706176280975342, "compression_ratio": 1.127659574468085, "no_speech_prob": 2.1444318917929195e-05}, {"id": 287, "seek": 177440, "start": 1774.4, "end": 1785.6000000000001, "text": " So it worked on this one, but not on our tuple.", "tokens": [407, 309, 2732, 322, 341, 472, 11, 457, 406, 322, 527, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.32007789611816406, "compression_ratio": 1.145631067961165, "no_speech_prob": 1.2218837582622655e-05}, {"id": 288, "seek": 177440, "start": 1785.6000000000001, "end": 1792.96, "text": " Why is that?", "tokens": [1545, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.32007789611816406, "compression_ratio": 1.145631067961165, "no_speech_prob": 1.2218837582622655e-05}, {"id": 289, "seek": 177440, "start": 1792.96, "end": 1798.0800000000002, "text": " So David asks, why would we inherit versus use decorator?", "tokens": [407, 4389, 8962, 11, 983, 576, 321, 21389, 5717, 764, 7919, 1639, 30], "temperature": 0.0, "avg_logprob": -0.32007789611816406, "compression_ratio": 1.145631067961165, "no_speech_prob": 1.2218837582622655e-05}, {"id": 290, "seek": 179808, "start": 1798.08, "end": 1805.1999999999998, "text": " Yeah, so basically, yeah, if you want some state, it's easier to use a class.", "tokens": [865, 11, 370, 1936, 11, 1338, 11, 498, 291, 528, 512, 1785, 11, 309, 311, 3571, 281, 764, 257, 1508, 13], "temperature": 0.0, "avg_logprob": -0.26653007058536304, "compression_ratio": 1.532967032967033, "no_speech_prob": 5.09365872858325e-06}, {"id": 291, "seek": 179808, "start": 1805.1999999999998, "end": 1808.6, "text": " If you don't, it's probably easier to use a decorator.", "tokens": [759, 291, 500, 380, 11, 309, 311, 1391, 3571, 281, 764, 257, 7919, 1639, 13], "temperature": 0.0, "avg_logprob": -0.26653007058536304, "compression_ratio": 1.532967032967033, "no_speech_prob": 5.09365872858325e-06}, {"id": 292, "seek": 179808, "start": 1808.6, "end": 1811.6, "text": " That sounds about right to me.", "tokens": [663, 3263, 466, 558, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.26653007058536304, "compression_ratio": 1.532967032967033, "no_speech_prob": 5.09365872858325e-06}, {"id": 293, "seek": 179808, "start": 1811.6, "end": 1817.6799999999998, "text": " OK, so let's try and figure out why this isn't working.", "tokens": [2264, 11, 370, 718, 311, 853, 293, 2573, 484, 983, 341, 1943, 380, 1364, 13], "temperature": 0.0, "avg_logprob": -0.26653007058536304, "compression_ratio": 1.532967032967033, "no_speech_prob": 5.09365872858325e-06}, {"id": 294, "seek": 179808, "start": 1817.6799999999998, "end": 1826.6399999999999, "text": " Oh, I think it's because we forgot to call the super class.", "tokens": [876, 11, 286, 519, 309, 311, 570, 321, 5298, 281, 818, 264, 1687, 1508, 13], "temperature": 0.0, "avg_logprob": -0.26653007058536304, "compression_ratio": 1.532967032967033, "no_speech_prob": 5.09365872858325e-06}, {"id": 295, "seek": 182664, "start": 1826.64, "end": 1833.4, "text": " Perhaps, yes, that's probably why.", "tokens": [10517, 11, 2086, 11, 300, 311, 1391, 983, 13], "temperature": 0.0, "avg_logprob": -0.37132716178894043, "compression_ratio": 1.3211678832116789, "no_speech_prob": 4.029320734844077e-06}, {"id": 296, "seek": 182664, "start": 1833.4, "end": 1834.4, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.37132716178894043, "compression_ratio": 1.3211678832116789, "no_speech_prob": 4.029320734844077e-06}, {"id": 297, "seek": 182664, "start": 1834.4, "end": 1837.64, "text": " Oh yeah, we both caught up at the same time.", "tokens": [876, 1338, 11, 321, 1293, 5415, 493, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.37132716178894043, "compression_ratio": 1.3211678832116789, "no_speech_prob": 4.029320734844077e-06}, {"id": 298, "seek": 182664, "start": 1837.64, "end": 1840.64, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.37132716178894043, "compression_ratio": 1.3211678832116789, "no_speech_prob": 4.029320734844077e-06}, {"id": 299, "seek": 182664, "start": 1840.64, "end": 1845.6000000000001, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.37132716178894043, "compression_ratio": 1.3211678832116789, "no_speech_prob": 4.029320734844077e-06}, {"id": 300, "seek": 182664, "start": 1845.6000000000001, "end": 1848.0800000000002, "text": " So that's an interesting point.", "tokens": [407, 300, 311, 364, 1880, 935, 13], "temperature": 0.0, "avg_logprob": -0.37132716178894043, "compression_ratio": 1.3211678832116789, "no_speech_prob": 4.029320734844077e-06}, {"id": 301, "seek": 182664, "start": 1848.0800000000002, "end": 1853.16, "text": " It's quite annoying to have tuples in it.", "tokens": [467, 311, 1596, 11304, 281, 362, 2604, 2622, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.37132716178894043, "compression_ratio": 1.3211678832116789, "no_speech_prob": 4.029320734844077e-06}, {"id": 302, "seek": 185316, "start": 1853.16, "end": 1862.8000000000002, "text": " We actually have something to make that easier, which is borrowed from the idea that Python", "tokens": [492, 767, 362, 746, 281, 652, 300, 3571, 11, 597, 307, 26805, 490, 264, 1558, 300, 15329], "temperature": 0.0, "avg_logprob": -0.33129075455338985, "compression_ratio": 1.4627659574468086, "no_speech_prob": 8.139284545904957e-06}, {"id": 303, "seek": 185316, "start": 1862.8000000000002, "end": 1867.92, "text": " standard libraries data classes use, which is to have a special thing called postInnit", "tokens": [3832, 15148, 1412, 5359, 764, 11, 597, 307, 281, 362, 257, 2121, 551, 1219, 2183, 4575, 77, 270], "temperature": 0.0, "avg_logprob": -0.33129075455338985, "compression_ratio": 1.4627659574468086, "no_speech_prob": 8.139284545904957e-06}, {"id": 304, "seek": 185316, "start": 1867.92, "end": 1871.6000000000001, "text": " that runs after your init.", "tokens": [300, 6676, 934, 428, 3157, 13], "temperature": 0.0, "avg_logprob": -0.33129075455338985, "compression_ratio": 1.4627659574468086, "no_speech_prob": 8.139284545904957e-06}, {"id": 305, "seek": 185316, "start": 1871.6000000000001, "end": 1877.1200000000001, "text": " OK, Jovi and I will come back to that question.", "tokens": [2264, 11, 3139, 4917, 293, 286, 486, 808, 646, 281, 300, 1168, 13], "temperature": 0.0, "avg_logprob": -0.33129075455338985, "compression_ratio": 1.4627659574468086, "no_speech_prob": 8.139284545904957e-06}, {"id": 306, "seek": 185316, "start": 1877.1200000000001, "end": 1880.1200000000001, "text": " It's a very good one.", "tokens": [467, 311, 257, 588, 665, 472, 13], "temperature": 0.0, "avg_logprob": -0.33129075455338985, "compression_ratio": 1.4627659574468086, "no_speech_prob": 8.139284545904957e-06}, {"id": 307, "seek": 188012, "start": 1880.12, "end": 1896.6399999999999, "text": " So we actually have, yes, if we inherit from base object, we're going to get a meta class,", "tokens": [407, 321, 767, 362, 11, 2086, 11, 498, 321, 21389, 490, 3096, 2657, 11, 321, 434, 516, 281, 483, 257, 19616, 1508, 11], "temperature": 0.0, "avg_logprob": -0.3001668046160442, "compression_ratio": 1.4913294797687862, "no_speech_prob": 1.260654244106263e-05}, {"id": 308, "seek": 188012, "start": 1896.6399999999999, "end": 1900.9599999999998, "text": " which we'll learn more about later, called pre postInnit meta, which allows us to have", "tokens": [597, 321, 603, 1466, 544, 466, 1780, 11, 1219, 659, 2183, 4575, 77, 270, 19616, 11, 597, 4045, 505, 281, 362], "temperature": 0.0, "avg_logprob": -0.3001668046160442, "compression_ratio": 1.4913294797687862, "no_speech_prob": 1.260654244106263e-05}, {"id": 309, "seek": 188012, "start": 1900.9599999999998, "end": 1904.6399999999999, "text": " a preInnit and a postInnit.", "tokens": [257, 659, 4575, 77, 270, 293, 257, 2183, 4575, 77, 270, 13], "temperature": 0.0, "avg_logprob": -0.3001668046160442, "compression_ratio": 1.4913294797687862, "no_speech_prob": 1.260654244106263e-05}, {"id": 310, "seek": 188012, "start": 1904.6399999999999, "end": 1906.36, "text": " And we may already be using that.", "tokens": [400, 321, 815, 1217, 312, 1228, 300, 13], "temperature": 0.0, "avg_logprob": -0.3001668046160442, "compression_ratio": 1.4913294797687862, "no_speech_prob": 1.260654244106263e-05}, {"id": 311, "seek": 188012, "start": 1906.36, "end": 1909.36, "text": " Let's have a look.", "tokens": [961, 311, 362, 257, 574, 13], "temperature": 0.0, "avg_logprob": -0.3001668046160442, "compression_ratio": 1.4913294797687862, "no_speech_prob": 1.260654244106263e-05}, {"id": 312, "seek": 190936, "start": 1909.36, "end": 1910.36, "text": " Transforms.", "tokens": [27938, 82, 13], "temperature": 0.0, "avg_logprob": -0.8209342956542969, "compression_ratio": 1.1126760563380282, "no_speech_prob": 0.0002377059281570837}, {"id": 313, "seek": 190936, "start": 1910.36, "end": 1911.36, "text": " Transform.", "tokens": [27938, 13], "temperature": 0.0, "avg_logprob": -0.8209342956542969, "compression_ratio": 1.1126760563380282, "no_speech_prob": 0.0002377059281570837}, {"id": 314, "seek": 190936, "start": 1911.36, "end": 1916.36, "text": " It's using Tiffa meta.", "tokens": [467, 311, 1228, 314, 3661, 64, 19616, 13], "temperature": 0.0, "avg_logprob": -0.8209342956542969, "compression_ratio": 1.1126760563380282, "no_speech_prob": 0.0002377059281570837}, {"id": 315, "seek": 190936, "start": 1916.36, "end": 1934.36, "text": " So Tiffa meta is a very good one.", "tokens": [407, 314, 3661, 64, 19616, 307, 257, 588, 665, 472, 13], "temperature": 0.0, "avg_logprob": -0.8209342956542969, "compression_ratio": 1.1126760563380282, "no_speech_prob": 0.0002377059281570837}, {"id": 316, "seek": 193436, "start": 1934.36, "end": 1942.52, "text": " So we'll have to come back to this.", "tokens": [407, 321, 603, 362, 281, 808, 646, 281, 341, 13], "temperature": 0.0, "avg_logprob": -0.23284108873824, "compression_ratio": 1.3905325443786982, "no_speech_prob": 4.288937816454563e-06}, {"id": 317, "seek": 193436, "start": 1942.52, "end": 1945.52, "text": " This isn't a great opportunity to use this one.", "tokens": [639, 1943, 380, 257, 869, 2650, 281, 764, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.23284108873824, "compression_ratio": 1.3905325443786982, "no_speech_prob": 4.288937816454563e-06}, {"id": 318, "seek": 193436, "start": 1945.52, "end": 1950.84, "text": " So it must be an inherit.", "tokens": [407, 309, 1633, 312, 364, 21389, 13], "temperature": 0.0, "avg_logprob": -0.23284108873824, "compression_ratio": 1.3905325443786982, "no_speech_prob": 4.288937816454563e-06}, {"id": 319, "seek": 193436, "start": 1950.84, "end": 1953.56, "text": " Let's answer some questions first.", "tokens": [961, 311, 1867, 512, 1651, 700, 13], "temperature": 0.0, "avg_logprob": -0.23284108873824, "compression_ratio": 1.3905325443786982, "no_speech_prob": 4.288937816454563e-06}, {"id": 320, "seek": 193436, "start": 1953.56, "end": 1959.9199999999998, "text": " So can you specify multiple types?", "tokens": [407, 393, 291, 16500, 3866, 3467, 30], "temperature": 0.0, "avg_logprob": -0.23284108873824, "compression_ratio": 1.3905325443786982, "no_speech_prob": 4.288937816454563e-06}, {"id": 321, "seek": 193436, "start": 1959.9199999999998, "end": 1963.7199999999998, "text": " So as Max said, it would be nice if we could use union.", "tokens": [407, 382, 7402, 848, 11, 309, 576, 312, 1481, 498, 321, 727, 764, 11671, 13], "temperature": 0.0, "avg_logprob": -0.23284108873824, "compression_ratio": 1.3905325443786982, "no_speech_prob": 4.288937816454563e-06}, {"id": 322, "seek": 196372, "start": 1963.72, "end": 1967.64, "text": " I can't remember if I actually currently have that working.", "tokens": [286, 393, 380, 1604, 498, 286, 767, 4362, 362, 300, 1364, 13], "temperature": 0.0, "avg_logprob": -0.22354063234831156, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.0782505341921933e-05}, {"id": 323, "seek": 196372, "start": 1967.64, "end": 1978.64, "text": " The problem is that Python's typing system isn't at all well designed for using at runtime.", "tokens": [440, 1154, 307, 300, 15329, 311, 18444, 1185, 1943, 380, 412, 439, 731, 4761, 337, 1228, 412, 34474, 13], "temperature": 0.0, "avg_logprob": -0.22354063234831156, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.0782505341921933e-05}, {"id": 324, "seek": 196372, "start": 1978.64, "end": 1984.48, "text": " And last time I checked, I don't think I had this working.", "tokens": [400, 1036, 565, 286, 10033, 11, 286, 500, 380, 519, 286, 632, 341, 1364, 13], "temperature": 0.0, "avg_logprob": -0.22354063234831156, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.0782505341921933e-05}, {"id": 325, "seek": 196372, "start": 1984.48, "end": 1986.68, "text": " Let's see.", "tokens": [961, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.22354063234831156, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.0782505341921933e-05}, {"id": 326, "seek": 196372, "start": 1986.68, "end": 1987.68, "text": " No.", "tokens": [883, 13], "temperature": 0.0, "avg_logprob": -0.22354063234831156, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.0782505341921933e-05}, {"id": 327, "seek": 196372, "start": 1987.68, "end": 1991.84, "text": " There's this really annoying check that they do.", "tokens": [821, 311, 341, 534, 11304, 1520, 300, 436, 360, 13], "temperature": 0.0, "avg_logprob": -0.22354063234831156, "compression_ratio": 1.4891304347826086, "no_speech_prob": 1.0782505341921933e-05}, {"id": 328, "seek": 199184, "start": 1991.84, "end": 2013.1599999999999, "text": " So basically, if you want this, then you have to go like this.", "tokens": [407, 1936, 11, 498, 291, 528, 341, 11, 550, 291, 362, 281, 352, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.2737259387969971, "compression_ratio": 1.0, "no_speech_prob": 8.397867532039527e-06}, {"id": 329, "seek": 201316, "start": 2013.16, "end": 2022.4, "text": " So actually, probably the easiest way would be to go underscore norm, get rid of that", "tokens": [407, 767, 11, 1391, 264, 12889, 636, 576, 312, 281, 352, 37556, 2026, 11, 483, 3973, 295, 300], "temperature": 0.0, "avg_logprob": -0.3023638517960258, "compression_ratio": 1.5897435897435896, "no_speech_prob": 7.296256171684945e-06}, {"id": 330, "seek": 201316, "start": 2022.4, "end": 2023.4, "text": " there.", "tokens": [456, 13], "temperature": 0.0, "avg_logprob": -0.3023638517960258, "compression_ratio": 1.5897435897435896, "no_speech_prob": 7.296256171684945e-06}, {"id": 331, "seek": 201316, "start": 2023.4, "end": 2027.76, "text": " And then encodes here would be return self.", "tokens": [400, 550, 2058, 4789, 510, 576, 312, 2736, 2698, 13], "temperature": 0.0, "avg_logprob": -0.3023638517960258, "compression_ratio": 1.5897435897435896, "no_speech_prob": 7.296256171684945e-06}, {"id": 332, "seek": 201316, "start": 2027.76, "end": 2029.8000000000002, "text": " Underscore norm.", "tokens": [2719, 433, 12352, 2026, 13], "temperature": 0.0, "avg_logprob": -0.3023638517960258, "compression_ratio": 1.5897435897435896, "no_speech_prob": 7.296256171684945e-06}, {"id": 333, "seek": 201316, "start": 2029.8000000000002, "end": 2030.8000000000002, "text": " X.", "tokens": [1783, 13], "temperature": 0.0, "avg_logprob": -0.3023638517960258, "compression_ratio": 1.5897435897435896, "no_speech_prob": 7.296256171684945e-06}, {"id": 334, "seek": 201316, "start": 2030.8000000000002, "end": 2035.0, "text": " And we'll do the same here.", "tokens": [400, 321, 603, 360, 264, 912, 510, 13], "temperature": 0.0, "avg_logprob": -0.3023638517960258, "compression_ratio": 1.5897435897435896, "no_speech_prob": 7.296256171684945e-06}, {"id": 335, "seek": 201316, "start": 2035.0, "end": 2036.48, "text": " I think that's what you have to do at the moment.", "tokens": [286, 519, 300, 311, 437, 291, 362, 281, 360, 412, 264, 1623, 13], "temperature": 0.0, "avg_logprob": -0.3023638517960258, "compression_ratio": 1.5897435897435896, "no_speech_prob": 7.296256171684945e-06}, {"id": 336, "seek": 201316, "start": 2036.48, "end": 2042.24, "text": " So have it twice, both calling the same thing with the two different types.", "tokens": [407, 362, 309, 6091, 11, 1293, 5141, 264, 912, 551, 365, 264, 732, 819, 3467, 13], "temperature": 0.0, "avg_logprob": -0.3023638517960258, "compression_ratio": 1.5897435897435896, "no_speech_prob": 7.296256171684945e-06}, {"id": 337, "seek": 204224, "start": 2042.24, "end": 2047.0, "text": " If anybody can figure out how to get union working, that would be great because this", "tokens": [759, 4472, 393, 2573, 484, 577, 281, 483, 11671, 1364, 11, 300, 576, 312, 869, 570, 341], "temperature": 0.0, "avg_logprob": -0.2062409992875724, "compression_ratio": 1.4375, "no_speech_prob": 3.90540435546427e-06}, {"id": 338, "seek": 204224, "start": 2047.0, "end": 2061.36, "text": " is slightly more clunky than it should be.", "tokens": [307, 4748, 544, 596, 25837, 813, 309, 820, 312, 13], "temperature": 0.0, "avg_logprob": -0.2062409992875724, "compression_ratio": 1.4375, "no_speech_prob": 3.90540435546427e-06}, {"id": 339, "seek": 204224, "start": 2061.36, "end": 2065.68, "text": " So if you need multiple different encodes for different types, you absolutely don't", "tokens": [407, 498, 291, 643, 3866, 819, 2058, 4789, 337, 819, 3467, 11, 291, 3122, 500, 380], "temperature": 0.0, "avg_logprob": -0.2062409992875724, "compression_ratio": 1.4375, "no_speech_prob": 3.90540435546427e-06}, {"id": 340, "seek": 204224, "start": 2065.68, "end": 2071.76, "text": " need to use class.", "tokens": [643, 281, 764, 1508, 13], "temperature": 0.0, "avg_logprob": -0.2062409992875724, "compression_ratio": 1.4375, "no_speech_prob": 3.90540435546427e-06}, {"id": 341, "seek": 207176, "start": 2071.76, "end": 2083.6400000000003, "text": " And so just to confirm again, you can do it with a class like so.", "tokens": [400, 370, 445, 281, 9064, 797, 11, 291, 393, 360, 309, 365, 257, 1508, 411, 370, 13], "temperature": 0.0, "avg_logprob": -0.30396580696105957, "compression_ratio": 1.1627906976744187, "no_speech_prob": 4.860190983890789e-06}, {"id": 342, "seek": 207176, "start": 2083.6400000000003, "end": 2090.7200000000003, "text": " So you could also do it like this.", "tokens": [407, 291, 727, 611, 360, 309, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.30396580696105957, "compression_ratio": 1.1627906976744187, "no_speech_prob": 4.860190983890789e-06}, {"id": 343, "seek": 209072, "start": 2090.72, "end": 2102.08, "text": " Def norm.", "tokens": [9548, 2026, 13], "temperature": 0.0, "avg_logprob": -0.39740657806396484, "compression_ratio": 1.3109243697478992, "no_speech_prob": 1.9524803064996377e-05}, {"id": 344, "seek": 209072, "start": 2102.08, "end": 2105.4399999999996, "text": " Well, actually, there's a few ways you can do it.", "tokens": [1042, 11, 767, 11, 456, 311, 257, 1326, 2098, 291, 393, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.39740657806396484, "compression_ratio": 1.3109243697478992, "no_speech_prob": 1.9524803064996377e-05}, {"id": 345, "seek": 209072, "start": 2105.4399999999996, "end": 2111.7999999999997, "text": " But one way is you partially use a class.", "tokens": [583, 472, 636, 307, 291, 18886, 764, 257, 1508, 13], "temperature": 0.0, "avg_logprob": -0.39740657806396484, "compression_ratio": 1.3109243697478992, "no_speech_prob": 1.9524803064996377e-05}, {"id": 346, "seek": 209072, "start": 2111.7999999999997, "end": 2114.7999999999997, "text": " You define it like this.", "tokens": [509, 6964, 309, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.39740657806396484, "compression_ratio": 1.3109243697478992, "no_speech_prob": 1.9524803064996377e-05}, {"id": 347, "seek": 209072, "start": 2114.7999999999997, "end": 2120.68, "text": " But you just write pass here.", "tokens": [583, 291, 445, 2464, 1320, 510, 13], "temperature": 0.0, "avg_logprob": -0.39740657806396484, "compression_ratio": 1.3109243697478992, "no_speech_prob": 1.9524803064996377e-05}, {"id": 348, "seek": 212068, "start": 2120.68, "end": 2126.48, "text": " And then what you do is you write encodes here.", "tokens": [400, 550, 437, 291, 360, 307, 291, 2464, 2058, 4789, 510, 13], "temperature": 0.0, "avg_logprob": -0.12631500151849562, "compression_ratio": 1.4959349593495934, "no_speech_prob": 1.2411290299496613e-05}, {"id": 349, "seek": 212068, "start": 2126.48, "end": 2131.64, "text": " And you actually use this as a decorator.", "tokens": [400, 291, 767, 764, 341, 382, 257, 7919, 1639, 13], "temperature": 0.0, "avg_logprob": -0.12631500151849562, "compression_ratio": 1.4959349593495934, "no_speech_prob": 1.2411290299496613e-05}, {"id": 350, "seek": 212068, "start": 2131.64, "end": 2133.12, "text": " Like so.", "tokens": [1743, 370, 13], "temperature": 0.0, "avg_logprob": -0.12631500151849562, "compression_ratio": 1.4959349593495934, "no_speech_prob": 1.2411290299496613e-05}, {"id": 351, "seek": 212068, "start": 2133.12, "end": 2137.72, "text": " And then you can do this a bunch of times.", "tokens": [400, 550, 291, 393, 360, 341, 257, 3840, 295, 1413, 13], "temperature": 0.0, "avg_logprob": -0.12631500151849562, "compression_ratio": 1.4959349593495934, "no_speech_prob": 1.2411290299496613e-05}, {"id": 352, "seek": 212068, "start": 2137.72, "end": 2140.08, "text": " Like so.", "tokens": [1743, 370, 13], "temperature": 0.0, "avg_logprob": -0.12631500151849562, "compression_ratio": 1.4959349593495934, "no_speech_prob": 1.2411290299496613e-05}, {"id": 353, "seek": 212068, "start": 2140.08, "end": 2142.3799999999997, "text": " And this is another way to do it.", "tokens": [400, 341, 307, 1071, 636, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.12631500151849562, "compression_ratio": 1.4959349593495934, "no_speech_prob": 1.2411290299496613e-05}, {"id": 354, "seek": 214238, "start": 2142.38, "end": 2150.88, "text": " So we now have multiple versions of encodes in separate places.", "tokens": [407, 321, 586, 362, 3866, 9606, 295, 2058, 4789, 294, 4994, 3190, 13], "temperature": 0.0, "avg_logprob": -0.10183959740858811, "compression_ratio": 1.720524017467249, "no_speech_prob": 6.144049621070735e-06}, {"id": 355, "seek": 214238, "start": 2150.88, "end": 2156.0, "text": " So it's still defining a class once, but it's an empty class.", "tokens": [407, 309, 311, 920, 17827, 257, 1508, 1564, 11, 457, 309, 311, 364, 6707, 1508, 13], "temperature": 0.0, "avg_logprob": -0.10183959740858811, "compression_ratio": 1.720524017467249, "no_speech_prob": 6.144049621070735e-06}, {"id": 356, "seek": 214238, "start": 2156.0, "end": 2158.2400000000002, "text": " But then you can put the encodes in these different places.", "tokens": [583, 550, 291, 393, 829, 264, 2058, 4789, 294, 613, 819, 3190, 13], "temperature": 0.0, "avg_logprob": -0.10183959740858811, "compression_ratio": 1.720524017467249, "no_speech_prob": 6.144049621070735e-06}, {"id": 357, "seek": 214238, "start": 2158.2400000000002, "end": 2161.96, "text": " This is actually, we'll see more about using this later, but this is actually super important", "tokens": [639, 307, 767, 11, 321, 603, 536, 544, 466, 1228, 341, 1780, 11, 457, 341, 307, 767, 1687, 1021], "temperature": 0.0, "avg_logprob": -0.10183959740858811, "compression_ratio": 1.720524017467249, "no_speech_prob": 6.144049621070735e-06}, {"id": 358, "seek": 214238, "start": 2161.96, "end": 2167.56, "text": " because let's say the class was, well, actually, norm's a great class.", "tokens": [570, 718, 311, 584, 264, 1508, 390, 11, 731, 11, 767, 11, 2026, 311, 257, 869, 1508, 13], "temperature": 0.0, "avg_logprob": -0.10183959740858811, "compression_ratio": 1.720524017467249, "no_speech_prob": 6.144049621070735e-06}, {"id": 359, "seek": 214238, "start": 2167.56, "end": 2169.4, "text": " So let's say you've got a normalized class.", "tokens": [407, 718, 311, 584, 291, 600, 658, 257, 48704, 1508, 13], "temperature": 0.0, "avg_logprob": -0.10183959740858811, "compression_ratio": 1.720524017467249, "no_speech_prob": 6.144049621070735e-06}, {"id": 360, "seek": 216940, "start": 2169.4, "end": 2175.12, "text": " And there's somewhere where you defined it for your tensor image class.", "tokens": [400, 456, 311, 4079, 689, 291, 7642, 309, 337, 428, 40863, 3256, 1508, 13], "temperature": 0.0, "avg_logprob": -0.16993171786084588, "compression_ratio": 1.64321608040201, "no_speech_prob": 5.422020876721945e-06}, {"id": 361, "seek": 216940, "start": 2175.12, "end": 2182.76, "text": " But then later on, you create a new data type for audio, say.", "tokens": [583, 550, 1780, 322, 11, 291, 1884, 257, 777, 1412, 2010, 337, 6278, 11, 584, 13], "temperature": 0.0, "avg_logprob": -0.16993171786084588, "compression_ratio": 1.64321608040201, "no_speech_prob": 5.422020876721945e-06}, {"id": 362, "seek": 216940, "start": 2182.76, "end": 2185.2400000000002, "text": " You might have an audio tensor.", "tokens": [509, 1062, 362, 364, 6278, 40863, 13], "temperature": 0.0, "avg_logprob": -0.16993171786084588, "compression_ratio": 1.64321608040201, "no_speech_prob": 5.422020876721945e-06}, {"id": 363, "seek": 216940, "start": 2185.2400000000002, "end": 2193.32, "text": " And then that might have some different implementation where, I don't know, maybe you have to transpose", "tokens": [400, 550, 300, 1062, 362, 512, 819, 11420, 689, 11, 286, 500, 380, 458, 11, 1310, 291, 362, 281, 25167], "temperature": 0.0, "avg_logprob": -0.16993171786084588, "compression_ratio": 1.64321608040201, "no_speech_prob": 5.422020876721945e-06}, {"id": 364, "seek": 216940, "start": 2193.32, "end": 2198.48, "text": " something or you have to add a non somewhere or whatever.", "tokens": [746, 420, 291, 362, 281, 909, 257, 2107, 4079, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.16993171786084588, "compression_ratio": 1.64321608040201, "no_speech_prob": 5.422020876721945e-06}, {"id": 365, "seek": 219848, "start": 2198.48, "end": 2202.88, "text": " So the nice thing is this separate implementation can be in a totally different file, totally", "tokens": [407, 264, 1481, 551, 307, 341, 4994, 11420, 393, 312, 294, 257, 3879, 819, 3991, 11, 3879], "temperature": 0.0, "avg_logprob": -0.12359883671715147, "compression_ratio": 1.710144927536232, "no_speech_prob": 2.769342927422258e-06}, {"id": 366, "seek": 219848, "start": 2202.88, "end": 2205.78, "text": " different module, totally different project.", "tokens": [819, 10088, 11, 3879, 819, 1716, 13], "temperature": 0.0, "avg_logprob": -0.12359883671715147, "compression_ratio": 1.710144927536232, "no_speech_prob": 2.769342927422258e-06}, {"id": 367, "seek": 219848, "start": 2205.78, "end": 2212.28, "text": " And it will add the functionality to normalize audio tensors to the library.", "tokens": [400, 309, 486, 909, 264, 14980, 281, 2710, 1125, 6278, 10688, 830, 281, 264, 6405, 13], "temperature": 0.0, "avg_logprob": -0.12359883671715147, "compression_ratio": 1.710144927536232, "no_speech_prob": 2.769342927422258e-06}, {"id": 368, "seek": 219848, "start": 2212.28, "end": 2218.96, "text": " So this is one of the really helpful things about this style.", "tokens": [407, 341, 307, 472, 295, 264, 534, 4961, 721, 466, 341, 3758, 13], "temperature": 0.0, "avg_logprob": -0.12359883671715147, "compression_ratio": 1.710144927536232, "no_speech_prob": 2.769342927422258e-06}, {"id": 369, "seek": 219848, "start": 2218.96, "end": 2223.04, "text": " And so you'll see, yeah, for data augmentation in particular, this is great.", "tokens": [400, 370, 291, 603, 536, 11, 1338, 11, 337, 1412, 14501, 19631, 294, 1729, 11, 341, 307, 869, 13], "temperature": 0.0, "avg_logprob": -0.12359883671715147, "compression_ratio": 1.710144927536232, "no_speech_prob": 2.769342927422258e-06}, {"id": 370, "seek": 222304, "start": 2223.04, "end": 2232.04, "text": " We can add data augmentation of their own types to the library with just one line of", "tokens": [492, 393, 909, 1412, 14501, 19631, 295, 641, 1065, 3467, 281, 264, 6405, 365, 445, 472, 1622, 295], "temperature": 0.0, "avg_logprob": -0.22186490763788638, "compression_ratio": 1.4970059880239521, "no_speech_prob": 2.406073008387466e-06}, {"id": 371, "seek": 222304, "start": 2232.04, "end": 2236.16, "text": " code, well, two lines of code, one for the decorator.", "tokens": [3089, 11, 731, 11, 732, 3876, 295, 3089, 11, 472, 337, 264, 7919, 1639, 13], "temperature": 0.0, "avg_logprob": -0.22186490763788638, "compression_ratio": 1.4970059880239521, "no_speech_prob": 2.406073008387466e-06}, {"id": 372, "seek": 222304, "start": 2236.16, "end": 2239.2, "text": " Oh, great question, Julian.", "tokens": [876, 11, 869, 1168, 11, 25151, 13], "temperature": 0.0, "avg_logprob": -0.22186490763788638, "compression_ratio": 1.4970059880239521, "no_speech_prob": 2.406073008387466e-06}, {"id": 373, "seek": 222304, "start": 2239.2, "end": 2248.04, "text": " So yes, the way that encodes works or the way that in general, this dispatch system", "tokens": [407, 2086, 11, 264, 636, 300, 2058, 4789, 1985, 420, 264, 636, 300, 294, 2674, 11, 341, 36729, 1185], "temperature": 0.0, "avg_logprob": -0.22186490763788638, "compression_ratio": 1.4970059880239521, "no_speech_prob": 2.406073008387466e-06}, {"id": 374, "seek": 224804, "start": 2248.04, "end": 2260.36, "text": " works is, let's check it out.", "tokens": [1985, 307, 11, 718, 311, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.3508338165283203, "compression_ratio": 1.0163934426229508, "no_speech_prob": 7.1831200330052525e-06}, {"id": 375, "seek": 224804, "start": 2260.36, "end": 2269.88, "text": " Let's put here print A, print B.", "tokens": [961, 311, 829, 510, 4482, 316, 11, 4482, 363, 13], "temperature": 0.0, "avg_logprob": -0.3508338165283203, "compression_ratio": 1.0163934426229508, "no_speech_prob": 7.1831200330052525e-06}, {"id": 376, "seek": 226988, "start": 2269.88, "end": 2278.2400000000002, "text": " And this is a tensor and this is a tensor image.", "tokens": [400, 341, 307, 257, 40863, 293, 341, 307, 257, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.12375643730163574, "compression_ratio": 1.4047619047619047, "no_speech_prob": 3.0894730116415303e-06}, {"id": 377, "seek": 226988, "start": 2278.2400000000002, "end": 2291.88, "text": " So if we call it with MTI, it prints B. Why is it printing B?", "tokens": [407, 498, 321, 818, 309, 365, 376, 5422, 11, 309, 22305, 363, 13, 1545, 307, 309, 14699, 363, 30], "temperature": 0.0, "avg_logprob": -0.12375643730163574, "compression_ratio": 1.4047619047619047, "no_speech_prob": 3.0894730116415303e-06}, {"id": 378, "seek": 226988, "start": 2291.88, "end": 2297.88, "text": " Because my tensor image is further down the inheritance hierarchy.", "tokens": [1436, 452, 40863, 3256, 307, 3052, 760, 264, 32122, 22333, 13], "temperature": 0.0, "avg_logprob": -0.12375643730163574, "compression_ratio": 1.4047619047619047, "no_speech_prob": 3.0894730116415303e-06}, {"id": 379, "seek": 229788, "start": 2297.88, "end": 2304.92, "text": " So that's the more what you would call, Julian, closest match, more specific match.", "tokens": [407, 300, 311, 264, 544, 437, 291, 576, 818, 11, 25151, 11, 13699, 2995, 11, 544, 2685, 2995, 13], "temperature": 0.0, "avg_logprob": -0.1175071959402047, "compression_ratio": 1.3722627737226278, "no_speech_prob": 4.425225597515237e-06}, {"id": 380, "seek": 229788, "start": 2304.92, "end": 2310.4, "text": " So it uses the most precise type that it can.", "tokens": [407, 309, 4960, 264, 881, 13600, 2010, 300, 309, 393, 13], "temperature": 0.0, "avg_logprob": -0.1175071959402047, "compression_ratio": 1.3722627737226278, "no_speech_prob": 4.425225597515237e-06}, {"id": 381, "seek": 229788, "start": 2310.4, "end": 2318.92, "text": " And this does also work for kind of generic types as well.", "tokens": [400, 341, 775, 611, 589, 337, 733, 295, 19577, 3467, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1175071959402047, "compression_ratio": 1.3722627737226278, "no_speech_prob": 4.425225597515237e-06}, {"id": 382, "seek": 231892, "start": 2318.92, "end": 2328.2000000000003, "text": " So we could say type being dot, what's it called?", "tokens": [407, 321, 727, 584, 2010, 885, 5893, 11, 437, 311, 309, 1219, 30], "temperature": 0.0, "avg_logprob": -0.5253511316636029, "compression_ratio": 1.440251572327044, "no_speech_prob": 8.013361366465688e-06}, {"id": 383, "seek": 231892, "start": 2328.2000000000003, "end": 2333.16, "text": " There's a class for this.", "tokens": [821, 311, 257, 1508, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.5253511316636029, "compression_ratio": 1.440251572327044, "no_speech_prob": 8.013361366465688e-06}, {"id": 384, "seek": 231892, "start": 2333.16, "end": 2335.2000000000003, "text": " What's it called?", "tokens": [708, 311, 309, 1219, 30], "temperature": 0.0, "avg_logprob": -0.5253511316636029, "compression_ratio": 1.440251572327044, "no_speech_prob": 8.013361366465688e-06}, {"id": 385, "seek": 231892, "start": 2335.2000000000003, "end": 2336.2000000000003, "text": " There you go.", "tokens": [821, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.5253511316636029, "compression_ratio": 1.440251572327044, "no_speech_prob": 8.013361366465688e-06}, {"id": 386, "seek": 231892, "start": 2336.2000000000003, "end": 2339.2000000000003, "text": " These things are going to move slowly.", "tokens": [1981, 721, 366, 516, 281, 1286, 5692, 13], "temperature": 0.0, "avg_logprob": -0.5253511316636029, "compression_ratio": 1.440251572327044, "no_speech_prob": 8.013361366465688e-06}, {"id": 387, "seek": 231892, "start": 2339.2000000000003, "end": 2342.52, "text": " Numbers dot, yeah, so Python standard library comes with various type hierarchies.", "tokens": [22592, 1616, 5893, 11, 1338, 11, 370, 15329, 3832, 6405, 1487, 365, 3683, 2010, 35250, 530, 13], "temperature": 0.0, "avg_logprob": -0.5253511316636029, "compression_ratio": 1.440251572327044, "no_speech_prob": 8.013361366465688e-06}, {"id": 388, "seek": 234252, "start": 2342.52, "end": 2354.04, "text": " So we could say numbers dot integral, for instance, and then we could say F3, as you", "tokens": [407, 321, 727, 584, 3547, 5893, 11573, 11, 337, 5197, 11, 293, 550, 321, 727, 584, 479, 18, 11, 382, 291], "temperature": 0.0, "avg_logprob": -0.2902710355561355, "compression_ratio": 1.3356164383561644, "no_speech_prob": 3.3405094654881395e-06}, {"id": 389, "seek": 234252, "start": 2354.04, "end": 2356.08, "text": " can see.", "tokens": [393, 536, 13], "temperature": 0.0, "avg_logprob": -0.2902710355561355, "compression_ratio": 1.3356164383561644, "no_speech_prob": 3.3405094654881395e-06}, {"id": 390, "seek": 234252, "start": 2356.08, "end": 2366.0, "text": " Where else if we had one that was on int?", "tokens": [2305, 1646, 498, 321, 632, 472, 300, 390, 322, 560, 30], "temperature": 0.0, "avg_logprob": -0.2902710355561355, "compression_ratio": 1.3356164383561644, "no_speech_prob": 3.3405094654881395e-06}, {"id": 391, "seek": 234252, "start": 2366.0, "end": 2370.32, "text": " And again, it's going to call the most specialized version.", "tokens": [400, 797, 11, 309, 311, 516, 281, 818, 264, 881, 19813, 3037, 13], "temperature": 0.0, "avg_logprob": -0.2902710355561355, "compression_ratio": 1.3356164383561644, "no_speech_prob": 3.3405094654881395e-06}, {"id": 392, "seek": 237032, "start": 2370.32, "end": 2377.32, "text": " OK, so lots of good questions.", "tokens": [2264, 11, 370, 3195, 295, 665, 1651, 13], "temperature": 0.0, "avg_logprob": -0.6956566081327551, "compression_ratio": 0.8367346938775511, "no_speech_prob": 2.391672387602739e-05}, {"id": 393, "seek": 237032, "start": 2377.32, "end": 2382.32, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.6956566081327551, "compression_ratio": 0.8367346938775511, "no_speech_prob": 2.391672387602739e-05}, {"id": 394, "seek": 238232, "start": 2382.32, "end": 2406.6400000000003, "text": " Or for lunch, to lunch.", "tokens": [1610, 337, 6349, 11, 281, 6349, 13], "temperature": 0.0, "avg_logprob": -0.5189090508681077, "compression_ratio": 1.0, "no_speech_prob": 0.0001375649299006909}, {"id": 395, "seek": 238232, "start": 2406.6400000000003, "end": 2407.6400000000003, "text": " Check this out later.", "tokens": [6881, 341, 484, 1780, 13], "temperature": 0.0, "avg_logprob": -0.5189090508681077, "compression_ratio": 1.0, "no_speech_prob": 0.0001375649299006909}, {"id": 396, "seek": 238232, "start": 2407.6400000000003, "end": 2408.6400000000003, "text": " Thank you for the tip.", "tokens": [1044, 291, 337, 264, 4125, 13], "temperature": 0.0, "avg_logprob": -0.5189090508681077, "compression_ratio": 1.0, "no_speech_prob": 0.0001375649299006909}, {"id": 397, "seek": 240864, "start": 2408.64, "end": 2416.68, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.2229311466217041, "compression_ratio": 1.5689655172413792, "no_speech_prob": 2.212282197433524e-05}, {"id": 398, "seek": 240864, "start": 2416.68, "end": 2421.92, "text": " The next thing that we want to be able to do is we need to be able to go in the opposite", "tokens": [440, 958, 551, 300, 321, 528, 281, 312, 1075, 281, 360, 307, 321, 643, 281, 312, 1075, 281, 352, 294, 264, 6182], "temperature": 0.0, "avg_logprob": -0.2229311466217041, "compression_ratio": 1.5689655172413792, "no_speech_prob": 2.212282197433524e-05}, {"id": 399, "seek": 240864, "start": 2421.92, "end": 2422.92, "text": " direction.", "tokens": [3513, 13], "temperature": 0.0, "avg_logprob": -0.2229311466217041, "compression_ratio": 1.5689655172413792, "no_speech_prob": 2.212282197433524e-05}, {"id": 400, "seek": 240864, "start": 2422.92, "end": 2435.8799999999997, "text": " So to go in the opposite direction, we create something called decodes.", "tokens": [407, 281, 352, 294, 264, 6182, 3513, 11, 321, 1884, 746, 1219, 979, 4789, 13], "temperature": 0.0, "avg_logprob": -0.2229311466217041, "compression_ratio": 1.5689655172413792, "no_speech_prob": 2.212282197433524e-05}, {"id": 401, "seek": 243588, "start": 2435.88, "end": 2441.6800000000003, "text": " And so this would be x plus self dot s.", "tokens": [400, 370, 341, 576, 312, 2031, 1804, 2698, 5893, 262, 13], "temperature": 0.0, "avg_logprob": -0.2514770161021839, "compression_ratio": 1.3983050847457628, "no_speech_prob": 7.182954050222179e-06}, {"id": 402, "seek": 243588, "start": 2441.6800000000003, "end": 2451.92, "text": " Sorry, self times self dot s plus m.", "tokens": [4919, 11, 2698, 1413, 2698, 5893, 262, 1804, 275, 13], "temperature": 0.0, "avg_logprob": -0.2514770161021839, "compression_ratio": 1.3983050847457628, "no_speech_prob": 7.182954050222179e-06}, {"id": 403, "seek": 243588, "start": 2451.92, "end": 2458.44, "text": " And so let's check normalized image.", "tokens": [400, 370, 718, 311, 1520, 48704, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2514770161021839, "compression_ratio": 1.3983050847457628, "no_speech_prob": 7.182954050222179e-06}, {"id": 404, "seek": 243588, "start": 2458.44, "end": 2464.76, "text": " And so to run decodes, you have to go F dot decode.", "tokens": [400, 370, 281, 1190, 979, 4789, 11, 291, 362, 281, 352, 479, 5893, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.2514770161021839, "compression_ratio": 1.3983050847457628, "no_speech_prob": 7.182954050222179e-06}, {"id": 405, "seek": 246476, "start": 2464.76, "end": 2468.84, "text": " And then we would say an image.", "tokens": [400, 550, 321, 576, 584, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.23859813914579503, "compression_ratio": 1.5481927710843373, "no_speech_prob": 4.936879122396931e-06}, {"id": 406, "seek": 246476, "start": 2468.84, "end": 2472.5200000000004, "text": " And there it is.", "tokens": [400, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.23859813914579503, "compression_ratio": 1.5481927710843373, "no_speech_prob": 4.936879122396931e-06}, {"id": 407, "seek": 246476, "start": 2472.5200000000004, "end": 2474.44, "text": " And this works for tuples and everything.", "tokens": [400, 341, 1985, 337, 2604, 2622, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.23859813914579503, "compression_ratio": 1.5481927710843373, "no_speech_prob": 4.936879122396931e-06}, {"id": 408, "seek": 246476, "start": 2474.44, "end": 2476.2200000000003, "text": " It's actually the same way.", "tokens": [467, 311, 767, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.23859813914579503, "compression_ratio": 1.5481927710843373, "no_speech_prob": 4.936879122396931e-06}, {"id": 409, "seek": 246476, "start": 2476.2200000000003, "end": 2488.2000000000003, "text": " So if we go F of our tuple, and then we could say F dot decode, F of our tuple.", "tokens": [407, 498, 321, 352, 479, 295, 527, 2604, 781, 11, 293, 550, 321, 727, 584, 479, 5893, 979, 1429, 11, 479, 295, 527, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.23859813914579503, "compression_ratio": 1.5481927710843373, "no_speech_prob": 4.936879122396931e-06}, {"id": 410, "seek": 246476, "start": 2488.2000000000003, "end": 2492.92, "text": " Yep, we've gone back to where we were for the whole tuple.", "tokens": [7010, 11, 321, 600, 2780, 646, 281, 689, 321, 645, 337, 264, 1379, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.23859813914579503, "compression_ratio": 1.5481927710843373, "no_speech_prob": 4.936879122396931e-06}, {"id": 411, "seek": 249292, "start": 2492.92, "end": 2497.6, "text": " Just to confirm that this did in fact.", "tokens": [1449, 281, 9064, 300, 341, 630, 294, 1186, 13], "temperature": 0.0, "avg_logprob": -0.4224852092230498, "compression_ratio": 1.328358208955224, "no_speech_prob": 3.6119506603427e-06}, {"id": 412, "seek": 249292, "start": 2497.6, "end": 2498.6, "text": " That's not working.", "tokens": [663, 311, 406, 1364, 13], "temperature": 0.0, "avg_logprob": -0.4224852092230498, "compression_ratio": 1.328358208955224, "no_speech_prob": 3.6119506603427e-06}, {"id": 413, "seek": 249292, "start": 2498.6, "end": 2500.6, "text": " Oh, because this should be an MTI.", "tokens": [876, 11, 570, 341, 820, 312, 364, 376, 5422, 13], "temperature": 0.0, "avg_logprob": -0.4224852092230498, "compression_ratio": 1.328358208955224, "no_speech_prob": 3.6119506603427e-06}, {"id": 414, "seek": 249292, "start": 2500.6, "end": 2504.08, "text": " This we're now saying just put our image type.", "tokens": [639, 321, 434, 586, 1566, 445, 829, 527, 3256, 2010, 13], "temperature": 0.0, "avg_logprob": -0.4224852092230498, "compression_ratio": 1.328358208955224, "no_speech_prob": 3.6119506603427e-06}, {"id": 415, "seek": 249292, "start": 2504.08, "end": 2505.08, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.4224852092230498, "compression_ratio": 1.328358208955224, "no_speech_prob": 3.6119506603427e-06}, {"id": 416, "seek": 249292, "start": 2505.08, "end": 2506.08, "text": " MTCode.", "tokens": [376, 18238, 1429, 13], "temperature": 0.0, "avg_logprob": -0.4224852092230498, "compression_ratio": 1.328358208955224, "no_speech_prob": 3.6119506603427e-06}, {"id": 417, "seek": 249292, "start": 2506.08, "end": 2509.08, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.4224852092230498, "compression_ratio": 1.328358208955224, "no_speech_prob": 3.6119506603427e-06}, {"id": 418, "seek": 249292, "start": 2509.08, "end": 2510.52, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.4224852092230498, "compression_ratio": 1.328358208955224, "no_speech_prob": 3.6119506603427e-06}, {"id": 419, "seek": 251052, "start": 2510.52, "end": 2527.6, "text": " So that is some of the key pieces around how this dispatch works and why it works this", "tokens": [407, 300, 307, 512, 295, 264, 2141, 3755, 926, 577, 341, 36729, 1985, 293, 983, 309, 1985, 341], "temperature": 0.0, "avg_logprob": -0.15554249854314894, "compression_ratio": 1.271186440677966, "no_speech_prob": 3.7266006529534934e-06}, {"id": 420, "seek": 251052, "start": 2527.6, "end": 2529.0, "text": " way.", "tokens": [636, 13], "temperature": 0.0, "avg_logprob": -0.15554249854314894, "compression_ratio": 1.271186440677966, "no_speech_prob": 3.7266006529534934e-06}, {"id": 421, "seek": 251052, "start": 2529.0, "end": 2536.52, "text": " But of course, it's not enough to have just one transform.", "tokens": [583, 295, 1164, 11, 309, 311, 406, 1547, 281, 362, 445, 472, 4088, 13], "temperature": 0.0, "avg_logprob": -0.15554249854314894, "compression_ratio": 1.271186440677966, "no_speech_prob": 3.7266006529534934e-06}, {"id": 422, "seek": 253652, "start": 2536.52, "end": 2543.6, "text": " In practice, we need to not only normalize, but we need to be able to do other things", "tokens": [682, 3124, 11, 321, 643, 281, 406, 787, 2710, 1125, 11, 457, 321, 643, 281, 312, 1075, 281, 360, 661, 721], "temperature": 0.0, "avg_logprob": -0.16574769434721573, "compression_ratio": 1.694736842105263, "no_speech_prob": 2.1781666873721406e-05}, {"id": 423, "seek": 253652, "start": 2543.6, "end": 2544.6, "text": " as well.", "tokens": [382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16574769434721573, "compression_ratio": 1.694736842105263, "no_speech_prob": 2.1781666873721406e-05}, {"id": 424, "seek": 253652, "start": 2544.6, "end": 2552.68, "text": " So, for example, maybe we'll have something that flips.", "tokens": [407, 11, 337, 1365, 11, 1310, 321, 603, 362, 746, 300, 40249, 13], "temperature": 0.0, "avg_logprob": -0.16574769434721573, "compression_ratio": 1.694736842105263, "no_speech_prob": 2.1781666873721406e-05}, {"id": 425, "seek": 253652, "start": 2552.68, "end": 2556.68, "text": " And so generally things that flip, we don't need to unflip because data augmentation,", "tokens": [400, 370, 5101, 721, 300, 7929, 11, 321, 500, 380, 643, 281, 3971, 75, 647, 570, 1412, 14501, 19631, 11], "temperature": 0.0, "avg_logprob": -0.16574769434721573, "compression_ratio": 1.694736842105263, "no_speech_prob": 2.1781666873721406e-05}, {"id": 426, "seek": 253652, "start": 2556.68, "end": 2559.64, "text": " we want to see it even later on.", "tokens": [321, 528, 281, 536, 309, 754, 1780, 322, 13], "temperature": 0.0, "avg_logprob": -0.16574769434721573, "compression_ratio": 1.694736842105263, "no_speech_prob": 2.1781666873721406e-05}, {"id": 427, "seek": 253652, "start": 2559.64, "end": 2562.8, "text": " We don't generally want to decode data augmentation.", "tokens": [492, 500, 380, 5101, 528, 281, 979, 1429, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.16574769434721573, "compression_ratio": 1.694736842105263, "no_speech_prob": 2.1781666873721406e-05}, {"id": 428, "seek": 256280, "start": 2562.8, "end": 2569.6000000000004, "text": " So we could probably just use a function for that.", "tokens": [407, 321, 727, 1391, 445, 764, 257, 2445, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.23068255469912574, "compression_ratio": 1.308411214953271, "no_speech_prob": 9.817991667659953e-06}, {"id": 429, "seek": 256280, "start": 2569.6000000000004, "end": 2588.36, "text": " So it's going to take one of our image tensors and it's going to return torch.flip our x.", "tokens": [407, 309, 311, 516, 281, 747, 472, 295, 527, 3256, 10688, 830, 293, 309, 311, 516, 281, 2736, 27822, 13, 3423, 647, 527, 2031, 13], "temperature": 0.0, "avg_logprob": -0.23068255469912574, "compression_ratio": 1.308411214953271, "no_speech_prob": 9.817991667659953e-06}, {"id": 430, "seek": 258836, "start": 2588.36, "end": 2593.04, "text": " And we'll do it on the zeroth axis.", "tokens": [400, 321, 603, 360, 309, 322, 264, 44746, 900, 10298, 13], "temperature": 0.0, "avg_logprob": -0.22649535087689962, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.061590501194587e-05}, {"id": 431, "seek": 258836, "start": 2593.04, "end": 2595.7200000000003, "text": " No, the first axis.", "tokens": [883, 11, 264, 700, 10298, 13], "temperature": 0.0, "avg_logprob": -0.22649535087689962, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.061590501194587e-05}, {"id": 432, "seek": 258836, "start": 2595.7200000000003, "end": 2604.6, "text": " If random.random is greater than 0.5, otherwise we'll leave it alone.", "tokens": [759, 4974, 13, 3699, 298, 307, 5044, 813, 1958, 13, 20, 11, 5911, 321, 603, 1856, 309, 3312, 13], "temperature": 0.0, "avg_logprob": -0.22649535087689962, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.061590501194587e-05}, {"id": 433, "seek": 258836, "start": 2604.6, "end": 2608.94, "text": " So that would be an example of some data augmentation we could do.", "tokens": [407, 300, 576, 312, 364, 1365, 295, 512, 1412, 14501, 19631, 321, 727, 360, 13], "temperature": 0.0, "avg_logprob": -0.22649535087689962, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.061590501194587e-05}, {"id": 434, "seek": 258836, "start": 2608.94, "end": 2613.58, "text": " So how would we combine those two things together?", "tokens": [407, 577, 576, 321, 10432, 729, 732, 721, 1214, 30], "temperature": 0.0, "avg_logprob": -0.22649535087689962, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.061590501194587e-05}, {"id": 435, "seek": 261358, "start": 2613.58, "end": 2626.52, "text": " So one simple approach would be we could say transformed image equals, in fact, let's do", "tokens": [407, 472, 2199, 3109, 576, 312, 321, 727, 584, 16894, 3256, 6915, 11, 294, 1186, 11, 718, 311, 360], "temperature": 0.0, "avg_logprob": -0.31658359195875085, "compression_ratio": 1.375, "no_speech_prob": 1.6442274500150234e-05}, {"id": 436, "seek": 261358, "start": 2626.52, "end": 2627.52, "text": " it for the whole tuple.", "tokens": [309, 337, 264, 1379, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.31658359195875085, "compression_ratio": 1.375, "no_speech_prob": 1.6442274500150234e-05}, {"id": 437, "seek": 261358, "start": 2627.52, "end": 2632.0, "text": " So transform tuple, tuple is image tuple.", "tokens": [407, 4088, 2604, 781, 11, 2604, 781, 307, 3256, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.31658359195875085, "compression_ratio": 1.375, "no_speech_prob": 1.6442274500150234e-05}, {"id": 438, "seek": 263200, "start": 2632.0, "end": 2645.04, "text": " So transform tuple equals, let's say first we normalize, which was F of our image, and", "tokens": [407, 4088, 2604, 781, 6915, 11, 718, 311, 584, 700, 321, 2710, 1125, 11, 597, 390, 479, 295, 527, 3256, 11, 293], "temperature": 0.0, "avg_logprob": -0.3279966286250523, "compression_ratio": 1.3857142857142857, "no_speech_prob": 2.2603178422286874e-06}, {"id": 439, "seek": 263200, "start": 2645.04, "end": 2652.52, "text": " then we flip it.", "tokens": [550, 321, 7929, 309, 13], "temperature": 0.0, "avg_logprob": -0.3279966286250523, "compression_ratio": 1.3857142857142857, "no_speech_prob": 2.2603178422286874e-06}, {"id": 440, "seek": 263200, "start": 2652.52, "end": 2661.36, "text": " Actually that won't quite work because, not that nice with our tuple, which tuple, because", "tokens": [5135, 300, 1582, 380, 1596, 589, 570, 11, 406, 300, 1481, 365, 527, 2604, 781, 11, 597, 2604, 781, 11, 570], "temperature": 0.0, "avg_logprob": -0.3279966286250523, "compression_ratio": 1.3857142857142857, "no_speech_prob": 2.2603178422286874e-06}, {"id": 441, "seek": 266136, "start": 2661.36, "end": 2663.4, "text": " we can't apply it to tuples.", "tokens": [321, 393, 380, 3079, 309, 281, 2604, 2622, 13], "temperature": 0.0, "avg_logprob": -0.14139718916809674, "compression_ratio": 1.7522522522522523, "no_speech_prob": 1.7778389519662596e-05}, {"id": 442, "seek": 266136, "start": 2663.4, "end": 2668.88, "text": " So we could tell it this is a transform.", "tokens": [407, 321, 727, 980, 309, 341, 307, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.14139718916809674, "compression_ratio": 1.7522522522522523, "no_speech_prob": 1.7778389519662596e-05}, {"id": 443, "seek": 266136, "start": 2668.88, "end": 2671.44, "text": " And so now that works, which is good.", "tokens": [400, 370, 586, 300, 1985, 11, 597, 307, 665, 13], "temperature": 0.0, "avg_logprob": -0.14139718916809674, "compression_ratio": 1.7522522522522523, "no_speech_prob": 1.7778389519662596e-05}, {"id": 444, "seek": 266136, "start": 2671.44, "end": 2673.7200000000003, "text": " It's kind of annoying having to say everything's a transform.", "tokens": [467, 311, 733, 295, 11304, 1419, 281, 584, 1203, 311, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.14139718916809674, "compression_ratio": 1.7522522522522523, "no_speech_prob": 1.7778389519662596e-05}, {"id": 445, "seek": 266136, "start": 2673.7200000000003, "end": 2680.32, "text": " And it's also kind of annoying because it's kind of normalize and then flip and then do", "tokens": [400, 309, 311, 611, 733, 295, 11304, 570, 309, 311, 733, 295, 2710, 1125, 293, 550, 7929, 293, 550, 360], "temperature": 0.0, "avg_logprob": -0.14139718916809674, "compression_ratio": 1.7522522522522523, "no_speech_prob": 1.7778389519662596e-05}, {"id": 446, "seek": 266136, "start": 2680.32, "end": 2682.56, "text": " something else and then do something else.", "tokens": [746, 1646, 293, 550, 360, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.14139718916809674, "compression_ratio": 1.7522522522522523, "no_speech_prob": 1.7778389519662596e-05}, {"id": 447, "seek": 266136, "start": 2682.56, "end": 2688.1600000000003, "text": " These kinds of pipelines are things we often want to define once and use multiple times.", "tokens": [1981, 3685, 295, 40168, 366, 721, 321, 2049, 528, 281, 6964, 1564, 293, 764, 3866, 1413, 13], "temperature": 0.0, "avg_logprob": -0.14139718916809674, "compression_ratio": 1.7522522522522523, "no_speech_prob": 1.7778389519662596e-05}, {"id": 448, "seek": 268816, "start": 2688.16, "end": 2695.3199999999997, "text": " One way we could do that is we could say pipeline equals compose.", "tokens": [1485, 636, 321, 727, 360, 300, 307, 321, 727, 584, 15517, 6915, 35925, 13], "temperature": 0.0, "avg_logprob": -0.14922675108298278, "compression_ratio": 1.7166666666666666, "no_speech_prob": 3.0894832434569253e-06}, {"id": 449, "seek": 268816, "start": 2695.3199999999997, "end": 2703.3599999999997, "text": " So compose is just a standard functional and mathematical thing that runs a bunch of functions", "tokens": [407, 35925, 307, 445, 257, 3832, 11745, 293, 18894, 551, 300, 6676, 257, 3840, 295, 6828], "temperature": 0.0, "avg_logprob": -0.14922675108298278, "compression_ratio": 1.7166666666666666, "no_speech_prob": 3.0894832434569253e-06}, {"id": 450, "seek": 268816, "start": 2703.3599999999997, "end": 2704.3599999999997, "text": " in order.", "tokens": [294, 1668, 13], "temperature": 0.0, "avg_logprob": -0.14922675108298278, "compression_ratio": 1.7166666666666666, "no_speech_prob": 3.0894832434569253e-06}, {"id": 451, "seek": 268816, "start": 2704.3599999999997, "end": 2710.16, "text": " So we could first of all run our normalization function and then our flip image function.", "tokens": [407, 321, 727, 700, 295, 439, 1190, 527, 2710, 2144, 2445, 293, 550, 527, 7929, 3256, 2445, 13], "temperature": 0.0, "avg_logprob": -0.14922675108298278, "compression_ratio": 1.7166666666666666, "no_speech_prob": 3.0894832434569253e-06}, {"id": 452, "seek": 268816, "start": 2710.16, "end": 2713.64, "text": " And so now we could just go pipe.", "tokens": [400, 370, 586, 321, 727, 445, 352, 11240, 13], "temperature": 0.0, "avg_logprob": -0.14922675108298278, "compression_ratio": 1.7166666666666666, "no_speech_prob": 3.0894832434569253e-06}, {"id": 453, "seek": 268816, "start": 2713.64, "end": 2714.64, "text": " So that works.", "tokens": [407, 300, 1985, 13], "temperature": 0.0, "avg_logprob": -0.14922675108298278, "compression_ratio": 1.7166666666666666, "no_speech_prob": 3.0894832434569253e-06}, {"id": 454, "seek": 271464, "start": 2714.64, "end": 2723.12, "text": " The problem is that compose doesn't know anything about transforms.", "tokens": [440, 1154, 307, 300, 35925, 1177, 380, 458, 1340, 466, 35592, 13], "temperature": 0.0, "avg_logprob": -0.1376582145690918, "compression_ratio": 1.4324324324324325, "no_speech_prob": 1.8162140804633964e-06}, {"id": 455, "seek": 271464, "start": 2723.12, "end": 2734.44, "text": " So if we now wanted to go to decode it, we can't.", "tokens": [407, 498, 321, 586, 1415, 281, 352, 281, 979, 1429, 309, 11, 321, 393, 380, 13], "temperature": 0.0, "avg_logprob": -0.1376582145690918, "compression_ratio": 1.4324324324324325, "no_speech_prob": 1.8162140804633964e-06}, {"id": 456, "seek": 271464, "start": 2734.44, "end": 2741.8399999999997, "text": " So we would have to go, you know, flip image.decode, which actually isn't going to do anything", "tokens": [407, 321, 576, 362, 281, 352, 11, 291, 458, 11, 7929, 3256, 13, 1479, 22332, 11, 597, 767, 1943, 380, 516, 281, 360, 1340], "temperature": 0.0, "avg_logprob": -0.1376582145690918, "compression_ratio": 1.4324324324324325, "no_speech_prob": 1.8162140804633964e-06}, {"id": 457, "seek": 274184, "start": 2741.84, "end": 2745.52, "text": " because we don't have one, but we don't necessarily know which ones have one, which don't.", "tokens": [570, 321, 500, 380, 362, 472, 11, 457, 321, 500, 380, 4725, 458, 597, 2306, 362, 472, 11, 597, 500, 380, 13], "temperature": 0.0, "avg_logprob": -0.17389453725611909, "compression_ratio": 1.6748768472906403, "no_speech_prob": 9.972828593163285e-06}, {"id": 458, "seek": 274184, "start": 2745.52, "end": 2749.36, "text": " We'd have to do something like this.", "tokens": [492, 1116, 362, 281, 360, 746, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.17389453725611909, "compression_ratio": 1.6748768472906403, "no_speech_prob": 9.972828593163285e-06}, {"id": 459, "seek": 274184, "start": 2749.36, "end": 2755.7200000000003, "text": " So it would be great if we could compose things in a way that know how to compose decoding", "tokens": [407, 309, 576, 312, 869, 498, 321, 727, 35925, 721, 294, 257, 636, 300, 458, 577, 281, 35925, 979, 8616], "temperature": 0.0, "avg_logprob": -0.17389453725611909, "compression_ratio": 1.6748768472906403, "no_speech_prob": 9.972828593163285e-06}, {"id": 460, "seek": 274184, "start": 2755.7200000000003, "end": 2756.7200000000003, "text": " as well as encoding.", "tokens": [382, 731, 382, 43430, 13], "temperature": 0.0, "avg_logprob": -0.17389453725611909, "compression_ratio": 1.6748768472906403, "no_speech_prob": 9.972828593163285e-06}, {"id": 461, "seek": 274184, "start": 2756.7200000000003, "end": 2762.7200000000003, "text": " So to do that, we just change from compose to pipeline.", "tokens": [407, 281, 360, 300, 11, 321, 445, 1319, 490, 35925, 281, 15517, 13], "temperature": 0.0, "avg_logprob": -0.17389453725611909, "compression_ratio": 1.6748768472906403, "no_speech_prob": 9.972828593163285e-06}, {"id": 462, "seek": 274184, "start": 2762.7200000000003, "end": 2765.6800000000003, "text": " And it's going to do exactly the same thing.", "tokens": [400, 309, 311, 516, 281, 360, 2293, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.17389453725611909, "compression_ratio": 1.6748768472906403, "no_speech_prob": 9.972828593163285e-06}, {"id": 463, "seek": 276568, "start": 2765.68, "end": 2775.48, "text": " But now we can say pipe.decode and it's done.", "tokens": [583, 586, 321, 393, 584, 11240, 13, 1479, 22332, 293, 309, 311, 1096, 13], "temperature": 0.0, "avg_logprob": -0.12974050465752096, "compression_ratio": 1.639240506329114, "no_speech_prob": 2.2732628224275686e-07}, {"id": 464, "seek": 276568, "start": 2775.48, "end": 2781.68, "text": " So as you can see, there's this kind of idea of like trying to get the pieces all to work", "tokens": [407, 382, 291, 393, 536, 11, 456, 311, 341, 733, 295, 1558, 295, 411, 1382, 281, 483, 264, 3755, 439, 281, 589], "temperature": 0.0, "avg_logprob": -0.12974050465752096, "compression_ratio": 1.639240506329114, "no_speech_prob": 2.2732628224275686e-07}, {"id": 465, "seek": 276568, "start": 2781.68, "end": 2788.0, "text": " together in this data transformation domain that we're in, specifically kind of couple", "tokens": [1214, 294, 341, 1412, 9887, 9274, 300, 321, 434, 294, 11, 4682, 733, 295, 1916], "temperature": 0.0, "avg_logprob": -0.12974050465752096, "compression_ratio": 1.639240506329114, "no_speech_prob": 2.2732628224275686e-07}, {"id": 466, "seek": 276568, "start": 2788.0, "end": 2791.16, "text": " transformation domain that we're in.", "tokens": [9887, 9274, 300, 321, 434, 294, 13], "temperature": 0.0, "avg_logprob": -0.12974050465752096, "compression_ratio": 1.639240506329114, "no_speech_prob": 2.2732628224275686e-07}, {"id": 467, "seek": 279116, "start": 2791.16, "end": 2795.96, "text": " So if this pipeline knows that we want to be dealing with transforms, it knows that", "tokens": [407, 498, 341, 15517, 3255, 300, 321, 528, 281, 312, 6260, 365, 35592, 11, 309, 3255, 300], "temperature": 0.0, "avg_logprob": -0.31117725372314453, "compression_ratio": 1.601063829787234, "no_speech_prob": 6.438923264795449e-06}, {"id": 468, "seek": 279116, "start": 2795.96, "end": 2799.56, "text": " if it gets a normal image and not a transform, it should turn it into a transform.", "tokens": [498, 309, 2170, 257, 2710, 3256, 293, 406, 257, 4088, 11, 309, 820, 1261, 309, 666, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.31117725372314453, "compression_ratio": 1.601063829787234, "no_speech_prob": 6.438923264795449e-06}, {"id": 469, "seek": 279116, "start": 2799.56, "end": 2805.24, "text": " So let's remove the transform decorator from here and run this again.", "tokens": [407, 718, 311, 4159, 264, 4088, 7919, 1639, 490, 510, 293, 1190, 341, 797, 13], "temperature": 0.0, "avg_logprob": -0.31117725372314453, "compression_ratio": 1.601063829787234, "no_speech_prob": 6.438923264795449e-06}, {"id": 470, "seek": 279116, "start": 2805.24, "end": 2810.24, "text": " And oh, I thought that was going to work.", "tokens": [400, 1954, 11, 286, 1194, 300, 390, 516, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.31117725372314453, "compression_ratio": 1.601063829787234, "no_speech_prob": 6.438923264795449e-06}, {"id": 471, "seek": 279116, "start": 2810.24, "end": 2817.56, "text": " Why is it not working?", "tokens": [1545, 307, 309, 406, 1364, 30], "temperature": 0.0, "avg_logprob": -0.31117725372314453, "compression_ratio": 1.601063829787234, "no_speech_prob": 6.438923264795449e-06}, {"id": 472, "seek": 281756, "start": 2817.56, "end": 2833.96, "text": " I thought I had made that the default.", "tokens": [286, 1194, 286, 632, 1027, 300, 264, 7576, 13], "temperature": 0.0, "avg_logprob": -0.5899823153460467, "compression_ratio": 1.0506329113924051, "no_speech_prob": 1.0287643817719072e-05}, {"id": 473, "seek": 281756, "start": 2833.96, "end": 2834.96, "text": " Sorry.", "tokens": [4919, 13], "temperature": 0.0, "avg_logprob": -0.5899823153460467, "compression_ratio": 1.0506329113924051, "no_speech_prob": 1.0287643817719072e-05}, {"id": 474, "seek": 281756, "start": 2834.96, "end": 2841.44, "text": " I think I forgot to export something.", "tokens": [286, 519, 286, 5298, 281, 10725, 746, 13], "temperature": 0.0, "avg_logprob": -0.5899823153460467, "compression_ratio": 1.0506329113924051, "no_speech_prob": 1.0287643817719072e-05}, {"id": 475, "seek": 284144, "start": 2841.44, "end": 2866.42, "text": " I guess I just forgot to export it.", "tokens": [286, 2041, 286, 445, 5298, 281, 10725, 309, 13], "temperature": 0.4, "avg_logprob": -0.9974377705500677, "compression_ratio": 0.813953488372093, "no_speech_prob": 0.0004637496604118496}, {"id": 476, "seek": 286642, "start": 2866.42, "end": 2877.96, "text": " It, it plants in the right world, not cor \uc0c8.", "tokens": [467, 11, 309, 5972, 294, 264, 558, 1002, 11, 406, 1181, 31184, 13], "temperature": 1.0, "avg_logprob": -3.920159628224927, "compression_ratio": 1.2454545454545454, "no_speech_prob": 3.8788715755799785e-05}, {"id": 477, "seek": 286642, "start": 2877.96, "end": 2874.52, "text": " It now rewarded me for doing that", "tokens": [467, 586, 29105, 385, 337, 884, 300], "temperature": 1.0, "avg_logprob": -3.920159628224927, "compression_ratio": 1.2454545454545454, "no_speech_prob": 3.8788715755799785e-05}, {"id": 478, "seek": 286642, "start": 2874.52, "end": 2885.28, "text": " Okay I'm sending them to the right order right now.", "tokens": [1033, 286, 478, 7750, 552, 281, 264, 558, 1668, 558, 586, 13], "temperature": 1.0, "avg_logprob": -3.920159628224927, "compression_ratio": 1.2454545454545454, "no_speech_prob": 3.8788715755799785e-05}, {"id": 479, "seek": 286642, "start": 2885.28, "end": 2868.08, "text": " Okay", "tokens": [1033], "temperature": 1.0, "avg_logprob": -3.920159628224927, "compression_ratio": 1.2454545454545454, "no_speech_prob": 3.8788715755799785e-05}, {"id": 480, "seek": 286808, "start": 2868.08, "end": 2872.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.8344029320610894, "compression_ratio": 0.8888888888888888, "no_speech_prob": 0.1154007837176323}, {"id": 481, "seek": 286808, "start": 2872.08, "end": 2876.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.8344029320610894, "compression_ratio": 0.8888888888888888, "no_speech_prob": 0.1154007837176323}, {"id": 482, "seek": 286808, "start": 2876.08, "end": 2884.08, "text": " Order.", "tokens": [16321, 13], "temperature": 0.0, "avg_logprob": -0.8344029320610894, "compression_ratio": 0.8888888888888888, "no_speech_prob": 0.1154007837176323}, {"id": 483, "seek": 286808, "start": 2884.08, "end": 2888.08, "text": " Nope.", "tokens": [12172, 13], "temperature": 0.0, "avg_logprob": -0.8344029320610894, "compression_ratio": 0.8888888888888888, "no_speech_prob": 0.1154007837176323}, {"id": 484, "seek": 288808, "start": 2888.08, "end": 2898.08, "text": " So, pipeline.", "tokens": [407, 11, 15517, 13], "temperature": 0.0, "avg_logprob": -0.37914594014485675, "compression_ratio": 0.9056603773584906, "no_speech_prob": 0.0005762309301644564}, {"id": 485, "seek": 288808, "start": 2898.08, "end": 2906.08, "text": " This item equals false.", "tokens": [639, 3174, 6915, 7908, 13], "temperature": 0.0, "avg_logprob": -0.37914594014485675, "compression_ratio": 0.9056603773584906, "no_speech_prob": 0.0005762309301644564}, {"id": 486, "seek": 288808, "start": 2906.08, "end": 2912.08, "text": " Let's see.", "tokens": [961, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.37914594014485675, "compression_ratio": 0.9056603773584906, "no_speech_prob": 0.0005762309301644564}, {"id": 487, "seek": 291208, "start": 2912.08, "end": 2940.08, "text": " False.", "tokens": [50040, 13], "temperature": 0.0, "avg_logprob": -0.4701027472813924, "compression_ratio": 0.42857142857142855, "no_speech_prob": 0.000260229833656922}, {"id": 488, "seek": 294008, "start": 2940.08, "end": 2944.08, "text": " So, we put an image tuple.", "tokens": [407, 11, 321, 829, 364, 3256, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.29030723924990054, "compression_ratio": 1.2230769230769232, "no_speech_prob": 7.252794603118673e-05}, {"id": 489, "seek": 294008, "start": 2944.08, "end": 2948.08, "text": " Pipeline, which is going to go...", "tokens": [35396, 5440, 11, 597, 307, 516, 281, 352, 485], "temperature": 0.0, "avg_logprob": -0.29030723924990054, "compression_ratio": 1.2230769230769232, "no_speech_prob": 7.252794603118673e-05}, {"id": 490, "seek": 294008, "start": 2948.08, "end": 2956.08, "text": " So, if I add a transform back on here.", "tokens": [407, 11, 498, 286, 909, 257, 4088, 646, 322, 510, 13], "temperature": 0.0, "avg_logprob": -0.29030723924990054, "compression_ratio": 1.2230769230769232, "no_speech_prob": 7.252794603118673e-05}, {"id": 491, "seek": 294008, "start": 2956.08, "end": 2966.08, "text": " And now I've managed to break everything. Let's go do that.", "tokens": [400, 586, 286, 600, 6453, 281, 1821, 1203, 13, 961, 311, 352, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.29030723924990054, "compression_ratio": 1.2230769230769232, "no_speech_prob": 7.252794603118673e-05}, {"id": 492, "seek": 296608, "start": 2966.08, "end": 2972.08, "text": " That's a problem with live coding, I guess. Oh, and now it's working again.", "tokens": [663, 311, 257, 1154, 365, 1621, 17720, 11, 286, 2041, 13, 876, 11, 293, 586, 309, 311, 1364, 797, 13], "temperature": 0.0, "avg_logprob": -0.1952978582943187, "compression_ratio": 1.220472440944882, "no_speech_prob": 7.253845251398161e-05}, {"id": 493, "seek": 296608, "start": 2972.08, "end": 2982.08, "text": " What did I do wrong?", "tokens": [708, 630, 286, 360, 2085, 30], "temperature": 0.0, "avg_logprob": -0.1952978582943187, "compression_ratio": 1.220472440944882, "no_speech_prob": 7.253845251398161e-05}, {"id": 494, "seek": 296608, "start": 2982.08, "end": 2988.08, "text": " Maybe I just got to restart properly.", "tokens": [2704, 286, 445, 658, 281, 21022, 6108, 13], "temperature": 0.0, "avg_logprob": -0.1952978582943187, "compression_ratio": 1.220472440944882, "no_speech_prob": 7.253845251398161e-05}, {"id": 495, "seek": 296608, "start": 2988.08, "end": 2990.08, "text": " I guess I did. Okay.", "tokens": [286, 2041, 286, 630, 13, 1033, 13], "temperature": 0.0, "avg_logprob": -0.1952978582943187, "compression_ratio": 1.220472440944882, "no_speech_prob": 7.253845251398161e-05}, {"id": 496, "seek": 299008, "start": 2990.08, "end": 3005.08, "text": " Alright, sorry about that delay. So, what I was saying is that a pipeline knows that the things that's being passed need to be transforms.", "tokens": [2798, 11, 2597, 466, 300, 8577, 13, 407, 11, 437, 286, 390, 1566, 307, 300, 257, 15517, 3255, 300, 264, 721, 300, 311, 885, 4678, 643, 281, 312, 35592, 13], "temperature": 0.0, "avg_logprob": -0.1383712417200992, "compression_ratio": 1.5625, "no_speech_prob": 4.710789653472602e-06}, {"id": 497, "seek": 299008, "start": 3005.08, "end": 3015.08, "text": " If we pass it something that's not a transform, so I've made this not a transform now.", "tokens": [759, 321, 1320, 309, 746, 300, 311, 406, 257, 4088, 11, 370, 286, 600, 1027, 341, 406, 257, 4088, 586, 13], "temperature": 0.0, "avg_logprob": -0.1383712417200992, "compression_ratio": 1.5625, "no_speech_prob": 4.710789653472602e-06}, {"id": 498, "seek": 301508, "start": 3015.08, "end": 3023.08, "text": " So, the cool thing is that pipeline will turn it into a transform automatically.", "tokens": [407, 11, 264, 1627, 551, 307, 300, 15517, 486, 1261, 309, 666, 257, 4088, 6772, 13], "temperature": 0.0, "avg_logprob": -0.112839582489758, "compression_ratio": 1.536697247706422, "no_speech_prob": 2.331996256543789e-06}, {"id": 499, "seek": 301508, "start": 3023.08, "end": 3032.08, "text": " So, yes, David, from people in the San Francisco study group, they say one of the best things is finding out how many errors I make.", "tokens": [407, 11, 2086, 11, 4389, 11, 490, 561, 294, 264, 5271, 12279, 2979, 1594, 11, 436, 584, 472, 295, 264, 1151, 721, 307, 5006, 484, 577, 867, 13603, 286, 652, 13], "temperature": 0.0, "avg_logprob": -0.112839582489758, "compression_ratio": 1.536697247706422, "no_speech_prob": 2.331996256543789e-06}, {"id": 500, "seek": 301508, "start": 3032.08, "end": 3037.08, "text": " Apparently that's extremely encouraging. I make lots.", "tokens": [16755, 300, 311, 4664, 14580, 13, 286, 652, 3195, 13], "temperature": 0.0, "avg_logprob": -0.112839582489758, "compression_ratio": 1.536697247706422, "no_speech_prob": 2.331996256543789e-06}, {"id": 501, "seek": 301508, "start": 3037.08, "end": 3041.08, "text": " What's the default behavior of the transform for encode and decode?", "tokens": [708, 311, 264, 7576, 5223, 295, 264, 4088, 337, 2058, 1429, 293, 979, 1429, 30], "temperature": 0.0, "avg_logprob": -0.112839582489758, "compression_ratio": 1.536697247706422, "no_speech_prob": 2.331996256543789e-06}, {"id": 502, "seek": 304108, "start": 3041.08, "end": 3050.08, "text": " Yeah, so the default behavior of encode and decode is to do nothing at all.", "tokens": [865, 11, 370, 264, 7576, 5223, 295, 2058, 1429, 293, 979, 1429, 307, 281, 360, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.07158209856818704, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.0783023753901944e-05}, {"id": 503, "seek": 304108, "start": 3050.08, "end": 3055.08, "text": " So, the decoder doesn't know what the image prior to the flip is.", "tokens": [407, 11, 264, 979, 19866, 1177, 380, 458, 437, 264, 3256, 4059, 281, 264, 7929, 307, 13], "temperature": 0.0, "avg_logprob": -0.07158209856818704, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.0783023753901944e-05}, {"id": 504, "seek": 304108, "start": 3055.08, "end": 3060.08, "text": " The decoder is not storing any state about what was decoded. It's just a function.", "tokens": [440, 979, 19866, 307, 406, 26085, 604, 1785, 466, 437, 390, 979, 12340, 13, 467, 311, 445, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.07158209856818704, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.0783023753901944e-05}, {"id": 505, "seek": 304108, "start": 3060.08, "end": 3068.08, "text": " So, the decoder simply just returns whatever it's passed. It doesn't do anything.", "tokens": [407, 11, 264, 979, 19866, 2935, 445, 11247, 2035, 309, 311, 4678, 13, 467, 1177, 380, 360, 1340, 13], "temperature": 0.0, "avg_logprob": -0.07158209856818704, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.0783023753901944e-05}, {"id": 506, "seek": 306808, "start": 3068.08, "end": 3081.08, "text": " We haven't got to data blocks yet, so we'll talk about data blocks when we get there.", "tokens": [492, 2378, 380, 658, 281, 1412, 8474, 1939, 11, 370, 321, 603, 751, 466, 1412, 8474, 562, 321, 483, 456, 13], "temperature": 0.0, "avg_logprob": -0.1172580829886503, "compression_ratio": 1.5165876777251184, "no_speech_prob": 3.071675746468827e-05}, {"id": 507, "seek": 306808, "start": 3081.08, "end": 3086.08, "text": " And Kip and I find I have a lot of troubles with autoreload, so I don't tend to use it.", "tokens": [400, 591, 647, 293, 286, 915, 286, 362, 257, 688, 295, 15379, 365, 1476, 418, 2907, 11, 370, 286, 500, 380, 3928, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.1172580829886503, "compression_ratio": 1.5165876777251184, "no_speech_prob": 3.071675746468827e-05}, {"id": 508, "seek": 306808, "start": 3086.08, "end": 3095.08, "text": " But you can actually just tap zero twice on the keyboard and it will restart the kernel, which I thought I did before, but I might have forgotten.", "tokens": [583, 291, 393, 767, 445, 5119, 4018, 6091, 322, 264, 10186, 293, 309, 486, 21022, 264, 28256, 11, 597, 286, 1194, 286, 630, 949, 11, 457, 286, 1062, 362, 11832, 13], "temperature": 0.0, "avg_logprob": -0.1172580829886503, "compression_ratio": 1.5165876777251184, "no_speech_prob": 3.071675746468827e-05}, {"id": 509, "seek": 309508, "start": 3095.08, "end": 3100.08, "text": " And the other thing I do I find super handy is I go edit keyboard shortcuts.", "tokens": [400, 264, 661, 551, 286, 360, 286, 915, 1687, 13239, 307, 286, 352, 8129, 10186, 34620, 13], "temperature": 0.0, "avg_logprob": -0.1646165677479335, "compression_ratio": 1.463768115942029, "no_speech_prob": 6.013861275278032e-05}, {"id": 510, "seek": 309508, "start": 3100.08, "end": 3106.08, "text": " And, well, why don't I see any edit shortcuts?", "tokens": [400, 11, 731, 11, 983, 500, 380, 286, 536, 604, 8129, 34620, 30], "temperature": 0.0, "avg_logprob": -0.1646165677479335, "compression_ratio": 1.463768115942029, "no_speech_prob": 6.013861275278032e-05}, {"id": 511, "seek": 309508, "start": 3106.08, "end": 3109.08, "text": " Edit keyboard shortcuts.", "tokens": [33241, 10186, 34620, 13], "temperature": 0.0, "avg_logprob": -0.1646165677479335, "compression_ratio": 1.463768115942029, "no_speech_prob": 6.013861275278032e-05}, {"id": 512, "seek": 309508, "start": 3109.08, "end": 3114.08, "text": " Apparently Jupyter is currently broken. That's weird.", "tokens": [16755, 22125, 88, 391, 307, 4362, 5463, 13, 663, 311, 3657, 13], "temperature": 0.0, "avg_logprob": -0.1646165677479335, "compression_ratio": 1.463768115942029, "no_speech_prob": 6.013861275278032e-05}, {"id": 513, "seek": 311408, "start": 3114.08, "end": 3126.08, "text": " Anyway, I add a keyboard shortcut for running all the cells above the current cursor, which normally you can do without a keyboard shortcuts.", "tokens": [5684, 11, 286, 909, 257, 10186, 24822, 337, 2614, 439, 264, 5438, 3673, 264, 2190, 28169, 11, 597, 5646, 291, 393, 360, 1553, 257, 10186, 34620, 13], "temperature": 0.0, "avg_logprob": -0.14303663693941557, "compression_ratio": 1.5180722891566265, "no_speech_prob": 4.092805738764582e-06}, {"id": 514, "seek": 311408, "start": 3126.08, "end": 3137.08, "text": " So, I can just go zero zero to restart and then I go A to run above and that gets me back to where I am.", "tokens": [407, 11, 286, 393, 445, 352, 4018, 4018, 281, 21022, 293, 550, 286, 352, 316, 281, 1190, 3673, 293, 300, 2170, 385, 646, 281, 689, 286, 669, 13], "temperature": 0.0, "avg_logprob": -0.14303663693941557, "compression_ratio": 1.5180722891566265, "no_speech_prob": 4.092805738764582e-06}, {"id": 515, "seek": 311408, "start": 3137.08, "end": 3142.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.14303663693941557, "compression_ratio": 1.5180722891566265, "no_speech_prob": 4.092805738764582e-06}, {"id": 516, "seek": 314208, "start": 3142.08, "end": 3153.08, "text": " So hopefully you can kind of see how this approach allows us to kind of use normal Python functions,", "tokens": [407, 4696, 291, 393, 733, 295, 536, 577, 341, 3109, 4045, 505, 281, 733, 295, 764, 2710, 15329, 6828, 11], "temperature": 0.0, "avg_logprob": -0.05870123978318839, "compression_ratio": 1.5688622754491017, "no_speech_prob": 2.8129759357398143e-06}, {"id": 517, "seek": 314208, "start": 3153.08, "end": 3167.08, "text": " but in a way that is kind of dispatched and composed in a way that makes more sense for data processing pipelines than the default approach that Python gives us.", "tokens": [457, 294, 257, 636, 300, 307, 733, 295, 4920, 24102, 293, 18204, 294, 257, 636, 300, 1669, 544, 2020, 337, 1412, 9007, 40168, 813, 264, 7576, 3109, 300, 15329, 2709, 505, 13], "temperature": 0.0, "avg_logprob": -0.05870123978318839, "compression_ratio": 1.5688622754491017, "no_speech_prob": 2.8129759357398143e-06}, {"id": 518, "seek": 316708, "start": 3167.08, "end": 3174.08, "text": " But the nice thing is they're not that different, you know.", "tokens": [583, 264, 1481, 551, 307, 436, 434, 406, 300, 819, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.19164703369140626, "compression_ratio": 1.4370370370370371, "no_speech_prob": 2.1232540348137263e-06}, {"id": 519, "seek": 316708, "start": 3174.08, "end": 3185.08, "text": " So like it's just kind of co, you know, the function just behaves like a normal function unless you add type annotations and so forth.", "tokens": [407, 411, 309, 311, 445, 733, 295, 598, 11, 291, 458, 11, 264, 2445, 445, 36896, 411, 257, 2710, 2445, 5969, 291, 909, 2010, 25339, 763, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.19164703369140626, "compression_ratio": 1.4370370370370371, "no_speech_prob": 2.1232540348137263e-06}, {"id": 520, "seek": 318508, "start": 3185.08, "end": 3198.08, "text": " Okay, so this is making good progress here.", "tokens": [1033, 11, 370, 341, 307, 1455, 665, 4205, 510, 13], "temperature": 0.0, "avg_logprob": -0.1303443397794451, "compression_ratio": 0.8775510204081632, "no_speech_prob": 6.048541763448156e-06}, {"id": 521, "seek": 319808, "start": 3198.08, "end": 3218.08, "text": " So then, yeah, so we don't need to actually define my tensor image because we already have a tensor image class, which we can use.", "tokens": [407, 550, 11, 1338, 11, 370, 321, 500, 380, 643, 281, 767, 6964, 452, 40863, 3256, 570, 321, 1217, 362, 257, 40863, 3256, 1508, 11, 597, 321, 393, 764, 13], "temperature": 0.0, "avg_logprob": -0.0875691058588963, "compression_ratio": 1.4696969696969697, "no_speech_prob": 4.222690222377423e-06}, {"id": 522, "seek": 319808, "start": 3218.08, "end": 3225.08, "text": " But as you can see, it's actually defined exactly the same way.", "tokens": [583, 382, 291, 393, 536, 11, 309, 311, 767, 7642, 2293, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.0875691058588963, "compression_ratio": 1.4696969696969697, "no_speech_prob": 4.222690222377423e-06}, {"id": 523, "seek": 322508, "start": 3225.08, "end": 3231.08, "text": " So that's the one that we should be using.", "tokens": [407, 300, 311, 264, 472, 300, 321, 820, 312, 1228, 13], "temperature": 0.0, "avg_logprob": -0.20638078451156616, "compression_ratio": 1.2523364485981308, "no_speech_prob": 1.2411111129040364e-05}, {"id": 524, "seek": 322508, "start": 3231.08, "end": 3237.08, "text": " So that's.", "tokens": [407, 300, 311, 13], "temperature": 0.0, "avg_logprob": -0.20638078451156616, "compression_ratio": 1.2523364485981308, "no_speech_prob": 1.2411111129040364e-05}, {"id": 525, "seek": 322508, "start": 3237.08, "end": 3238.08, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.20638078451156616, "compression_ratio": 1.2523364485981308, "no_speech_prob": 1.2411111129040364e-05}, {"id": 526, "seek": 322508, "start": 3238.08, "end": 3245.08, "text": " And I guess we may as well just say t image dot clone.", "tokens": [400, 286, 2041, 321, 815, 382, 731, 445, 584, 256, 3256, 5893, 26506, 13], "temperature": 0.0, "avg_logprob": -0.20638078451156616, "compression_ratio": 1.2523364485981308, "no_speech_prob": 1.2411111129040364e-05}, {"id": 527, "seek": 322508, "start": 3245.08, "end": 3248.08, "text": " And let's restart.", "tokens": [400, 718, 311, 21022, 13], "temperature": 0.0, "avg_logprob": -0.20638078451156616, "compression_ratio": 1.2523364485981308, "no_speech_prob": 1.2411111129040364e-05}, {"id": 528, "seek": 324808, "start": 3248.08, "end": 3258.08, "text": " And then we don't need my int because we've actually defined something called int, as I mentioned, in exactly the same way.", "tokens": [400, 550, 321, 500, 380, 643, 452, 560, 570, 321, 600, 767, 7642, 746, 1219, 560, 11, 382, 286, 2835, 11, 294, 2293, 264, 912, 636, 13], "temperature": 0.0, "avg_logprob": -0.18164159405616023, "compression_ratio": 1.4129032258064516, "no_speech_prob": 4.289263870305149e-06}, {"id": 529, "seek": 324808, "start": 3258.08, "end": 3265.08, "text": " Int again, just pass, but it's also got a show on it.", "tokens": [5681, 797, 11, 445, 1320, 11, 457, 309, 311, 611, 658, 257, 855, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.18164159405616023, "compression_ratio": 1.4129032258064516, "no_speech_prob": 4.289263870305149e-06}, {"id": 530, "seek": 324808, "start": 3265.08, "end": 3275.08, "text": " So that's now going to be a tensor image.", "tokens": [407, 300, 311, 586, 516, 281, 312, 257, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.18164159405616023, "compression_ratio": 1.4129032258064516, "no_speech_prob": 4.289263870305149e-06}, {"id": 531, "seek": 327508, "start": 3275.08, "end": 3284.08, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.2414171960618761, "compression_ratio": 0.9411764705882353, "no_speech_prob": 3.591185304685496e-05}, {"id": 532, "seek": 327508, "start": 3284.08, "end": 3291.08, "text": " Cool.", "tokens": [8561, 13], "temperature": 0.0, "avg_logprob": -0.2414171960618761, "compression_ratio": 0.9411764705882353, "no_speech_prob": 3.591185304685496e-05}, {"id": 533, "seek": 327508, "start": 3291.08, "end": 3293.08, "text": " There we are.", "tokens": [821, 321, 366, 13], "temperature": 0.0, "avg_logprob": -0.2414171960618761, "compression_ratio": 0.9411764705882353, "no_speech_prob": 3.591185304685496e-05}, {"id": 534, "seek": 329308, "start": 3293.08, "end": 3306.08, "text": " So then the last piece of this puzzle for now is that we might want, let's make our load image thing into a transform as well.", "tokens": [407, 550, 264, 1036, 2522, 295, 341, 12805, 337, 586, 307, 300, 321, 1062, 528, 11, 718, 311, 652, 527, 3677, 3256, 551, 666, 257, 4088, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17698542277018228, "compression_ratio": 1.291044776119403, "no_speech_prob": 6.9621146394638345e-06}, {"id": 535, "seek": 329308, "start": 3306.08, "end": 3308.08, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.17698542277018228, "compression_ratio": 1.291044776119403, "no_speech_prob": 6.9621146394638345e-06}, {"id": 536, "seek": 329308, "start": 3308.08, "end": 3310.08, "text": " Define.", "tokens": [9548, 533, 13], "temperature": 0.0, "avg_logprob": -0.17698542277018228, "compression_ratio": 1.291044776119403, "no_speech_prob": 6.9621146394638345e-06}, {"id": 537, "seek": 329308, "start": 3310.08, "end": 3313.08, "text": " Create image.", "tokens": [20248, 3256, 13], "temperature": 0.0, "avg_logprob": -0.17698542277018228, "compression_ratio": 1.291044776119403, "no_speech_prob": 6.9621146394638345e-06}, {"id": 538, "seek": 329308, "start": 3313.08, "end": 3315.08, "text": " With some file name.", "tokens": [2022, 512, 3991, 1315, 13], "temperature": 0.0, "avg_logprob": -0.17698542277018228, "compression_ratio": 1.291044776119403, "no_speech_prob": 6.9621146394638345e-06}, {"id": 539, "seek": 331508, "start": 3315.08, "end": 3323.08, "text": " And we're going to, it's actually going to be like, I guess we're actually going to create an image tensor.", "tokens": [400, 321, 434, 516, 281, 11, 309, 311, 767, 516, 281, 312, 411, 11, 286, 2041, 321, 434, 767, 516, 281, 1884, 364, 3256, 40863, 13], "temperature": 0.0, "avg_logprob": -0.2264174953583748, "compression_ratio": 1.5546218487394958, "no_speech_prob": 6.540200502058724e-06}, {"id": 540, "seek": 331508, "start": 3323.08, "end": 3327.08, "text": " And so we're going to return.", "tokens": [400, 370, 321, 434, 516, 281, 2736, 13], "temperature": 0.0, "avg_logprob": -0.2264174953583748, "compression_ratio": 1.5546218487394958, "no_speech_prob": 6.540200502058724e-06}, {"id": 541, "seek": 331508, "start": 3327.08, "end": 3331.08, "text": " And so array.", "tokens": [400, 370, 10225, 13], "temperature": 0.0, "avg_logprob": -0.2264174953583748, "compression_ratio": 1.5546218487394958, "no_speech_prob": 6.540200502058724e-06}, {"id": 542, "seek": 331508, "start": 3331.08, "end": 3333.08, "text": " Open image.", "tokens": [7238, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2264174953583748, "compression_ratio": 1.5546218487394958, "no_speech_prob": 6.540200502058724e-06}, {"id": 543, "seek": 331508, "start": 3333.08, "end": 3336.08, "text": " Sorry, load image.", "tokens": [4919, 11, 3677, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2264174953583748, "compression_ratio": 1.5546218487394958, "no_speech_prob": 6.540200502058724e-06}, {"id": 544, "seek": 331508, "start": 3336.08, "end": 3341.08, "text": " X.", "tokens": [1783, 13], "temperature": 0.0, "avg_logprob": -0.2264174953583748, "compression_ratio": 1.5546218487394958, "no_speech_prob": 6.540200502058724e-06}, {"id": 545, "seek": 334108, "start": 3341.08, "end": 3345.08, "text": " So we could do that.", "tokens": [407, 321, 727, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.24967926426937706, "compression_ratio": 1.1547619047619047, "no_speech_prob": 1.0615639439492952e-05}, {"id": 546, "seek": 334108, "start": 3345.08, "end": 3354.08, "text": " And so now we could use that here.", "tokens": [400, 370, 586, 321, 727, 764, 300, 510, 13], "temperature": 0.0, "avg_logprob": -0.24967926426937706, "compression_ratio": 1.1547619047619047, "no_speech_prob": 1.0615639439492952e-05}, {"id": 547, "seek": 334108, "start": 3354.08, "end": 3359.08, "text": " And let's restart.", "tokens": [400, 718, 311, 21022, 13], "temperature": 0.0, "avg_logprob": -0.24967926426937706, "compression_ratio": 1.1547619047619047, "no_speech_prob": 1.0615639439492952e-05}, {"id": 548, "seek": 334108, "start": 3359.08, "end": 3364.08, "text": " Image.", "tokens": [29903, 13], "temperature": 0.0, "avg_logprob": -0.24967926426937706, "compression_ratio": 1.1547619047619047, "no_speech_prob": 1.0615639439492952e-05}, {"id": 549, "seek": 334108, "start": 3364.08, "end": 3367.08, "text": " Done all above.", "tokens": [18658, 439, 3673, 13], "temperature": 0.0, "avg_logprob": -0.24967926426937706, "compression_ratio": 1.1547619047619047, "no_speech_prob": 1.0615639439492952e-05}, {"id": 550, "seek": 336708, "start": 3367.08, "end": 3371.08, "text": " OK, so there you go.", "tokens": [2264, 11, 370, 456, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.15608666068629215, "compression_ratio": 1.5576036866359446, "no_speech_prob": 1.061593047779752e-05}, {"id": 551, "seek": 336708, "start": 3371.08, "end": 3379.08, "text": " Now, the point about this, though, is that what we actually want RISC to be is because, you know, it's an image, not just any odd tensor.", "tokens": [823, 11, 264, 935, 466, 341, 11, 1673, 11, 307, 300, 437, 321, 767, 528, 497, 2343, 34, 281, 312, 307, 570, 11, 291, 458, 11, 309, 311, 364, 3256, 11, 406, 445, 604, 7401, 40863, 13], "temperature": 0.0, "avg_logprob": -0.15608666068629215, "compression_ratio": 1.5576036866359446, "no_speech_prob": 1.061593047779752e-05}, {"id": 552, "seek": 336708, "start": 3379.08, "end": 3388.08, "text": " We want to avoid having kind of non-semantically typed tensors wherever possible because then we or Bust.ai doesn't know what to do with them.", "tokens": [492, 528, 281, 5042, 1419, 733, 295, 2107, 12, 19872, 49505, 33941, 10688, 830, 8660, 1944, 570, 550, 321, 420, 363, 381, 13, 1301, 1177, 380, 458, 437, 281, 360, 365, 552, 13], "temperature": 0.0, "avg_logprob": -0.15608666068629215, "compression_ratio": 1.5576036866359446, "no_speech_prob": 1.061593047779752e-05}, {"id": 553, "seek": 336708, "start": 3388.08, "end": 3394.08, "text": " But this is currently just a tensor.", "tokens": [583, 341, 307, 4362, 445, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.15608666068629215, "compression_ratio": 1.5576036866359446, "no_speech_prob": 1.061593047779752e-05}, {"id": 554, "seek": 339408, "start": 3394.08, "end": 3399.08, "text": " So we can just say that should be a.", "tokens": [407, 321, 393, 445, 584, 300, 820, 312, 257, 13], "temperature": 0.0, "avg_logprob": -0.18661535808018276, "compression_ratio": 1.3986013986013985, "no_speech_prob": 1.7880156519822776e-06}, {"id": 555, "seek": 339408, "start": 3399.08, "end": 3402.08, "text": " And so image.", "tokens": [400, 370, 3256, 13], "temperature": 0.0, "avg_logprob": -0.18661535808018276, "compression_ratio": 1.3986013986013985, "no_speech_prob": 1.7880156519822776e-06}, {"id": 556, "seek": 339408, "start": 3402.08, "end": 3405.08, "text": " And it will cast it.", "tokens": [400, 309, 486, 4193, 309, 13], "temperature": 0.0, "avg_logprob": -0.18661535808018276, "compression_ratio": 1.3986013986013985, "no_speech_prob": 1.7880156519822776e-06}, {"id": 557, "seek": 339408, "start": 3405.08, "end": 3407.08, "text": " Should cast it first.", "tokens": [6454, 4193, 309, 700, 13], "temperature": 0.0, "avg_logprob": -0.18661535808018276, "compression_ratio": 1.3986013986013985, "no_speech_prob": 1.7880156519822776e-06}, {"id": 558, "seek": 339408, "start": 3407.08, "end": 3414.08, "text": " And of course, unless it's in a pipeline, we need to tell it it's a transform.", "tokens": [400, 295, 1164, 11, 5969, 309, 311, 294, 257, 15517, 11, 321, 643, 281, 980, 309, 309, 311, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.18661535808018276, "compression_ratio": 1.3986013986013985, "no_speech_prob": 1.7880156519822776e-06}, {"id": 559, "seek": 339408, "start": 3414.08, "end": 3417.08, "text": " Or any magic to happen.", "tokens": [1610, 604, 5585, 281, 1051, 13], "temperature": 0.0, "avg_logprob": -0.18661535808018276, "compression_ratio": 1.3986013986013985, "no_speech_prob": 1.7880156519822776e-06}, {"id": 560, "seek": 339408, "start": 3417.08, "end": 3420.08, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.18661535808018276, "compression_ratio": 1.3986013986013985, "no_speech_prob": 1.7880156519822776e-06}, {"id": 561, "seek": 342008, "start": 3420.08, "end": 3428.08, "text": " In practice, I basically pretty much never need to run transforms outside of a pipeline except for testing.", "tokens": [682, 3124, 11, 286, 1936, 1238, 709, 1128, 643, 281, 1190, 35592, 2380, 295, 257, 15517, 3993, 337, 4997, 13], "temperature": 0.0, "avg_logprob": -0.11752523694719587, "compression_ratio": 1.5315789473684212, "no_speech_prob": 1.3496643305188627e-06}, {"id": 562, "seek": 342008, "start": 3428.08, "end": 3443.08, "text": " So you'll see a lot of things that don't have decorators because we basically always use them in the pipeline, which you can see, for example, we just went pipeline.", "tokens": [407, 291, 603, 536, 257, 688, 295, 721, 300, 500, 380, 362, 7919, 3391, 570, 321, 1936, 1009, 764, 552, 294, 264, 15517, 11, 597, 291, 393, 536, 11, 337, 1365, 11, 321, 445, 1437, 15517, 13], "temperature": 0.0, "avg_logprob": -0.11752523694719587, "compression_ratio": 1.5315789473684212, "no_speech_prob": 1.3496643305188627e-06}, {"id": 563, "seek": 342008, "start": 3443.08, "end": 3446.08, "text": " And pass that in.", "tokens": [400, 1320, 300, 294, 13], "temperature": 0.0, "avg_logprob": -0.11752523694719587, "compression_ratio": 1.5315789473684212, "no_speech_prob": 1.3496643305188627e-06}, {"id": 564, "seek": 344608, "start": 3446.08, "end": 3454.08, "text": " That would work as well, because there's a pipeline with just one function being composed.", "tokens": [663, 576, 589, 382, 731, 11, 570, 456, 311, 257, 15517, 365, 445, 472, 2445, 885, 18204, 13], "temperature": 0.0, "avg_logprob": -0.12527982393900552, "compression_ratio": 1.28125, "no_speech_prob": 1.6964069800451398e-05}, {"id": 565, "seek": 344608, "start": 3454.08, "end": 3461.08, "text": " Or, of course, alternatively.", "tokens": [1610, 11, 295, 1164, 11, 8535, 356, 13], "temperature": 0.0, "avg_logprob": -0.12527982393900552, "compression_ratio": 1.28125, "no_speech_prob": 1.6964069800451398e-05}, {"id": 566, "seek": 344608, "start": 3461.08, "end": 3464.08, "text": " We could do this.", "tokens": [492, 727, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.12527982393900552, "compression_ratio": 1.28125, "no_speech_prob": 1.6964069800451398e-05}, {"id": 567, "seek": 344608, "start": 3464.08, "end": 3471.08, "text": " And that would work, too.", "tokens": [400, 300, 576, 589, 11, 886, 13], "temperature": 0.0, "avg_logprob": -0.12527982393900552, "compression_ratio": 1.28125, "no_speech_prob": 1.6964069800451398e-05}, {"id": 568, "seek": 347108, "start": 3471.08, "end": 3486.08, "text": " But kind of having return types is kind of nicer because it's just going to ensure that it's it's cast properly for you and it won't bother casting if it's already the right type.", "tokens": [583, 733, 295, 1419, 2736, 3467, 307, 733, 295, 22842, 570, 309, 311, 445, 516, 281, 5586, 300, 309, 311, 309, 311, 4193, 6108, 337, 291, 293, 309, 1582, 380, 8677, 17301, 498, 309, 311, 1217, 264, 558, 2010, 13], "temperature": 0.0, "avg_logprob": -0.1665268377824263, "compression_ratio": 1.4094488188976377, "no_speech_prob": 1.863124816736672e-05}, {"id": 569, "seek": 348608, "start": 3486.08, "end": 3501.08, "text": " OK. Random augmentations we will get to later. But if you're interested in looking ahead, you'll find that there is a thing called efficient augment.", "tokens": [2264, 13, 37603, 29919, 763, 321, 486, 483, 281, 1780, 13, 583, 498, 291, 434, 3102, 294, 1237, 2286, 11, 291, 603, 915, 300, 456, 307, 257, 551, 1219, 7148, 29919, 13], "temperature": 0.0, "avg_logprob": -0.17295650482177735, "compression_ratio": 1.3714285714285714, "no_speech_prob": 7.071533673297381e-06}, {"id": 570, "seek": 348608, "start": 3501.08, "end": 3510.08, "text": " But you can find that stuff developed.", "tokens": [583, 291, 393, 915, 300, 1507, 4743, 13], "temperature": 0.0, "avg_logprob": -0.17295650482177735, "compression_ratio": 1.3714285714285714, "no_speech_prob": 7.071533673297381e-06}, {"id": 571, "seek": 348608, "start": 3510.08, "end": 3512.08, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.17295650482177735, "compression_ratio": 1.3714285714285714, "no_speech_prob": 7.071533673297381e-06}, {"id": 572, "seek": 351208, "start": 3512.08, "end": 3529.08, "text": " So, you know, you don't need to learn anything about or understand anything about type dispatch or meta classes or any of that stuff to use this any more than to use Python's default function dispatch.", "tokens": [407, 11, 291, 458, 11, 291, 500, 380, 643, 281, 1466, 1340, 466, 420, 1223, 1340, 466, 2010, 36729, 420, 19616, 5359, 420, 604, 295, 300, 1507, 281, 764, 341, 604, 544, 813, 281, 764, 15329, 311, 7576, 2445, 36729, 13], "temperature": 0.0, "avg_logprob": -0.08489514779353487, "compression_ratio": 1.8170731707317074, "no_speech_prob": 2.81287634606997e-06}, {"id": 573, "seek": 351208, "start": 3529.08, "end": 3538.08, "text": " You don't have to learn anything about, you know, the workings of Python's type dispatch system.", "tokens": [509, 500, 380, 362, 281, 1466, 1340, 466, 11, 291, 458, 11, 264, 589, 1109, 295, 15329, 311, 2010, 36729, 1185, 13], "temperature": 0.0, "avg_logprob": -0.08489514779353487, "compression_ratio": 1.8170731707317074, "no_speech_prob": 2.81287634606997e-06}, {"id": 574, "seek": 353808, "start": 3538.08, "end": 3547.08, "text": " You just have to know what it does. But we're going to be spending time looking to see how it works because that's what CodeWalker is all about.", "tokens": [509, 445, 362, 281, 458, 437, 309, 775, 13, 583, 321, 434, 516, 281, 312, 6434, 565, 1237, 281, 536, 577, 309, 1985, 570, 300, 311, 437, 15549, 54, 667, 260, 307, 439, 466, 13], "temperature": 0.0, "avg_logprob": -0.10563320772988456, "compression_ratio": 1.4189189189189189, "no_speech_prob": 4.1572702684788965e-06}, {"id": 575, "seek": 353808, "start": 3547.08, "end": 3554.08, "text": " But you certainly don't have to understand it to use any of this.", "tokens": [583, 291, 3297, 500, 380, 362, 281, 1223, 309, 281, 764, 604, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.10563320772988456, "compression_ratio": 1.4189189189189189, "no_speech_prob": 4.1572702684788965e-06}, {"id": 576, "seek": 355408, "start": 3554.08, "end": 3572.08, "text": " So the next thing to be aware of is that both pipelines and tensors, when you create them, you can pass an optional additional argument as item, which is true or false.", "tokens": [407, 264, 958, 551, 281, 312, 3650, 295, 307, 300, 1293, 40168, 293, 10688, 830, 11, 562, 291, 1884, 552, 11, 291, 393, 1320, 364, 17312, 4497, 6770, 382, 3174, 11, 597, 307, 2074, 420, 7908, 13], "temperature": 0.0, "avg_logprob": -0.07690411408742269, "compression_ratio": 1.5471698113207548, "no_speech_prob": 4.860362878389424e-06}, {"id": 577, "seek": 355408, "start": 3572.08, "end": 3580.08, "text": " As item equals false gives you the behavior that we've seen, which is that it", "tokens": [1018, 3174, 6915, 7908, 2709, 291, 264, 5223, 300, 321, 600, 1612, 11, 597, 307, 300, 309], "temperature": 0.0, "avg_logprob": -0.07690411408742269, "compression_ratio": 1.5471698113207548, "no_speech_prob": 4.860362878389424e-06}, {"id": 578, "seek": 358008, "start": 3580.08, "end": 3587.08, "text": " if given a tuple or some kind of listy type of thing, it will operate on each element of the collection.", "tokens": [498, 2212, 257, 2604, 781, 420, 512, 733, 295, 1329, 88, 2010, 295, 551, 11, 309, 486, 9651, 322, 1184, 4478, 295, 264, 5765, 13], "temperature": 0.0, "avg_logprob": -0.0841183955852802, "compression_ratio": 1.4709302325581395, "no_speech_prob": 4.860411081608618e-06}, {"id": 579, "seek": 358008, "start": 3587.08, "end": 3597.08, "text": " But if you say as item equals true, then it won't it basically turns that behavior off.", "tokens": [583, 498, 291, 584, 382, 3174, 6915, 2074, 11, 550, 309, 1582, 380, 309, 1936, 4523, 300, 5223, 766, 13], "temperature": 0.0, "avg_logprob": -0.0841183955852802, "compression_ratio": 1.4709302325581395, "no_speech_prob": 4.860411081608618e-06}, {"id": 580, "seek": 358008, "start": 3597.08, "end": 3603.08, "text": " So you can actually see that in the definition of transform.", "tokens": [407, 291, 393, 767, 536, 300, 294, 264, 7123, 295, 4088, 13], "temperature": 0.0, "avg_logprob": -0.0841183955852802, "compression_ratio": 1.4709302325581395, "no_speech_prob": 4.860411081608618e-06}, {"id": 581, "seek": 360308, "start": 3603.08, "end": 3617.08, "text": " Here it says if use as item, which returns self as item, then just call the function and then otherwise it will do the loop.", "tokens": [1692, 309, 1619, 498, 764, 382, 3174, 11, 597, 11247, 2698, 382, 3174, 11, 550, 445, 818, 264, 2445, 293, 550, 5911, 309, 486, 360, 264, 6367, 13], "temperature": 0.0, "avg_logprob": -0.14850096080614172, "compression_ratio": 1.36, "no_speech_prob": 4.637833626475185e-06}, {"id": 582, "seek": 360308, "start": 3617.08, "end": 3621.08, "text": " But in this case, it's a tuple comprehension.", "tokens": [583, 294, 341, 1389, 11, 309, 311, 257, 2604, 781, 44991, 13], "temperature": 0.0, "avg_logprob": -0.14850096080614172, "compression_ratio": 1.36, "no_speech_prob": 4.637833626475185e-06}, {"id": 583, "seek": 362108, "start": 3621.08, "end": 3636.08, "text": " So you can easily turn off that behavior by saying as item equals true either in the pipeline or in the transform.", "tokens": [407, 291, 393, 3612, 1261, 766, 300, 5223, 538, 1566, 382, 3174, 6915, 2074, 2139, 294, 264, 15517, 420, 294, 264, 4088, 13], "temperature": 0.0, "avg_logprob": -0.13167139269270986, "compression_ratio": 1.5594405594405594, "no_speech_prob": 1.287889176637691e-06}, {"id": 584, "seek": 362108, "start": 3636.08, "end": 3649.08, "text": " The there are predefined subclasses of transform, as you can see, called tuple transform and item transform.", "tokens": [440, 456, 366, 659, 37716, 1422, 11665, 279, 295, 4088, 11, 382, 291, 393, 536, 11, 1219, 2604, 781, 4088, 293, 3174, 4088, 13], "temperature": 0.0, "avg_logprob": -0.13167139269270986, "compression_ratio": 1.5594405594405594, "no_speech_prob": 1.287889176637691e-06}, {"id": 585, "seek": 364908, "start": 3649.08, "end": 3653.08, "text": " And they actually set as item force equals false and true.", "tokens": [400, 436, 767, 992, 382, 3174, 3464, 6915, 7908, 293, 2074, 13], "temperature": 0.0, "avg_logprob": -0.06402015686035156, "compression_ratio": 1.722488038277512, "no_speech_prob": 8.013355909497477e-06}, {"id": 586, "seek": 364908, "start": 3653.08, "end": 3663.08, "text": " And the force versions of these mean that even if later on you create a pipeline with as item equals something, it won't change those transforms.", "tokens": [400, 264, 3464, 9606, 295, 613, 914, 300, 754, 498, 1780, 322, 291, 1884, 257, 15517, 365, 382, 3174, 6915, 746, 11, 309, 1582, 380, 1319, 729, 35592, 13], "temperature": 0.0, "avg_logprob": -0.06402015686035156, "compression_ratio": 1.722488038277512, "no_speech_prob": 8.013355909497477e-06}, {"id": 587, "seek": 364908, "start": 3663.08, "end": 3674.08, "text": " So if you create a tuple transform or an item transform, then you can know that all the time, no matter what, it will have the behavior that you requested.", "tokens": [407, 498, 291, 1884, 257, 2604, 781, 4088, 420, 364, 3174, 4088, 11, 550, 291, 393, 458, 300, 439, 264, 565, 11, 572, 1871, 437, 11, 309, 486, 362, 264, 5223, 300, 291, 16436, 13], "temperature": 0.0, "avg_logprob": -0.06402015686035156, "compression_ratio": 1.722488038277512, "no_speech_prob": 8.013355909497477e-06}, {"id": 588, "seek": 367408, "start": 3674.08, "end": 3680.08, "text": " So why does pipeline have this as item equals true false thing?", "tokens": [407, 983, 775, 15517, 362, 341, 382, 3174, 6915, 2074, 7908, 551, 30], "temperature": 0.0, "avg_logprob": -0.07827278483997692, "compression_ratio": 1.6845637583892616, "no_speech_prob": 4.5659248826268595e-06}, {"id": 589, "seek": 367408, "start": 3680.08, "end": 3696.08, "text": " So what that does is pipeline simply will go through so you can see pipeline in the constructor called set as item that simply goes through each function in the pipeline and sets as item.", "tokens": [407, 437, 300, 775, 307, 15517, 2935, 486, 352, 807, 370, 291, 393, 536, 15517, 294, 264, 47479, 1219, 992, 382, 3174, 300, 2935, 1709, 807, 1184, 2445, 294, 264, 15517, 293, 6352, 382, 3174, 13], "temperature": 0.0, "avg_logprob": -0.07827278483997692, "compression_ratio": 1.6845637583892616, "no_speech_prob": 4.5659248826268595e-06}, {"id": 590, "seek": 369608, "start": 3696.08, "end": 3713.08, "text": " And the reason we do that is that depending on kind of where you are in the data, the full data processing pipeline, sometimes you want kind of tuple behavior and sometimes you want item behavior.", "tokens": [400, 264, 1778, 321, 360, 300, 307, 300, 5413, 322, 733, 295, 689, 291, 366, 294, 264, 1412, 11, 264, 1577, 1412, 9007, 15517, 11, 2171, 291, 528, 733, 295, 2604, 781, 5223, 293, 2171, 291, 528, 3174, 5223, 13], "temperature": 0.0, "avg_logprob": -0.08937031030654907, "compression_ratio": 1.568, "no_speech_prob": 2.2958881800150266e-06}, {"id": 591, "seek": 371308, "start": 3713.08, "end": 3727.08, "text": " And specifically up until you collate your batch together, you kind of have two separate pipelines going on.", "tokens": [400, 4682, 493, 1826, 291, 1263, 473, 428, 15245, 1214, 11, 291, 733, 295, 362, 732, 4994, 40168, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.08762779901194018, "compression_ratio": 1.4306569343065694, "no_speech_prob": 1.844809503381839e-06}, {"id": 592, "seek": 371308, "start": 3727.08, "end": 3738.08, "text": " So each each pipeline is being separately applied to remind you from the pets tutorial.", "tokens": [407, 1184, 1184, 15517, 307, 885, 14759, 6456, 281, 4160, 291, 490, 264, 19897, 7073, 13], "temperature": 0.0, "avg_logprob": -0.08762779901194018, "compression_ratio": 1.4306569343065694, "no_speech_prob": 1.844809503381839e-06}, {"id": 593, "seek": 373808, "start": 3738.08, "end": 3743.08, "text": " We have two totally separate pipelines.", "tokens": [492, 362, 732, 3879, 4994, 40168, 13], "temperature": 0.0, "avg_logprob": -0.11696516313860493, "compression_ratio": 1.5172413793103448, "no_speech_prob": 6.24083804723341e-06}, {"id": 594, "seek": 373808, "start": 3743.08, "end": 3767.08, "text": " So since each of those is only being applied to one item at a time, not to tuples, the fast AI pipeline will automatically set as item equals true for those because they don't have they haven't been combined into tuples yet.", "tokens": [407, 1670, 1184, 295, 729, 307, 787, 885, 6456, 281, 472, 3174, 412, 257, 565, 11, 406, 281, 2604, 2622, 11, 264, 2370, 7318, 15517, 486, 6772, 992, 382, 3174, 6915, 2074, 337, 729, 570, 436, 500, 380, 362, 436, 2378, 380, 668, 9354, 666, 2604, 2622, 1939, 13], "temperature": 0.0, "avg_logprob": -0.11696516313860493, "compression_ratio": 1.5172413793103448, "no_speech_prob": 6.24083804723341e-06}, {"id": 595, "seek": 376708, "start": 3767.08, "end": 3773.08, "text": " And then later on in the process, it will set as item equals false.", "tokens": [400, 550, 1780, 322, 294, 264, 1399, 11, 309, 486, 992, 382, 3174, 6915, 7908, 13], "temperature": 0.0, "avg_logprob": -0.11142278521248464, "compression_ratio": 1.615, "no_speech_prob": 6.540284630318638e-06}, {"id": 596, "seek": 376708, "start": 3773.08, "end": 3782.08, "text": " Basically after they've been pulled out of data sets. So by the time they get to the data loader, it'll use false.", "tokens": [8537, 934, 436, 600, 668, 7373, 484, 295, 1412, 6352, 13, 407, 538, 264, 565, 436, 483, 281, 264, 1412, 3677, 260, 11, 309, 603, 764, 7908, 13], "temperature": 0.0, "avg_logprob": -0.11142278521248464, "compression_ratio": 1.615, "no_speech_prob": 6.540284630318638e-06}, {"id": 597, "seek": 376708, "start": 3782.08, "end": 3789.08, "text": " And we'll see more of that data. But that's a little, little thing to be aware of.", "tokens": [400, 321, 603, 536, 544, 295, 300, 1412, 13, 583, 300, 311, 257, 707, 11, 707, 551, 281, 312, 3650, 295, 13], "temperature": 0.0, "avg_logprob": -0.11142278521248464, "compression_ratio": 1.615, "no_speech_prob": 6.540284630318638e-06}, {"id": 598, "seek": 376708, "start": 3789.08, "end": 3795.08, "text": " So basically it just tries to do the right thing for you.", "tokens": [407, 1936, 309, 445, 9898, 281, 360, 264, 558, 551, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.11142278521248464, "compression_ratio": 1.615, "no_speech_prob": 6.540284630318638e-06}, {"id": 599, "seek": 379508, "start": 3795.08, "end": 3803.08, "text": " But you know, you don't have to use any of that functionality, of course, if you don't want to.", "tokens": [583, 291, 458, 11, 291, 500, 380, 362, 281, 764, 604, 295, 300, 14980, 11, 295, 1164, 11, 498, 291, 500, 380, 528, 281, 13], "temperature": 0.0, "avg_logprob": -0.15795870714409407, "compression_ratio": 1.22, "no_speech_prob": 7.843380444683135e-05}, {"id": 600, "seek": 379508, "start": 3803.08, "end": 3812.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.15795870714409407, "compression_ratio": 1.22, "no_speech_prob": 7.843380444683135e-05}, {"id": 601, "seek": 379508, "start": 3812.08, "end": 3817.08, "text": " This one back.", "tokens": [639, 472, 646, 13], "temperature": 0.0, "avg_logprob": -0.15795870714409407, "compression_ratio": 1.22, "no_speech_prob": 7.843380444683135e-05}, {"id": 602, "seek": 379508, "start": 3817.08, "end": 3819.08, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.15795870714409407, "compression_ratio": 1.22, "no_speech_prob": 7.843380444683135e-05}, {"id": 603, "seek": 381908, "start": 3819.08, "end": 3829.08, "text": " All right. Well, I think that's enough for today. Give us a good introduction to pipelines and transforms.", "tokens": [1057, 558, 13, 1042, 11, 286, 519, 300, 311, 1547, 337, 965, 13, 5303, 505, 257, 665, 9339, 281, 40168, 293, 35592, 13], "temperature": 0.0, "avg_logprob": -0.12521722343530547, "compression_ratio": 1.476595744680851, "no_speech_prob": 8.266822987934574e-06}, {"id": 604, "seek": 381908, "start": 3829.08, "end": 3834.08, "text": " And, yeah, again, happy to take requests on the forum for what you'd like to look at next.", "tokens": [400, 11, 1338, 11, 797, 11, 2055, 281, 747, 12475, 322, 264, 17542, 337, 437, 291, 1116, 411, 281, 574, 412, 958, 13], "temperature": 0.0, "avg_logprob": -0.12521722343530547, "compression_ratio": 1.476595744680851, "no_speech_prob": 8.266822987934574e-06}, {"id": 605, "seek": 381908, "start": 3834.08, "end": 3842.08, "text": " Otherwise, yeah, maybe we'll start going deeper dive into how these things are actually put together.", "tokens": [10328, 11, 1338, 11, 1310, 321, 603, 722, 516, 7731, 9192, 666, 577, 613, 721, 366, 767, 829, 1214, 13], "temperature": 0.0, "avg_logprob": -0.12521722343530547, "compression_ratio": 1.476595744680851, "no_speech_prob": 8.266822987934574e-06}, {"id": 606, "seek": 381908, "start": 3842.08, "end": 3845.08, "text": " We'll see where we go. Okay. Thanks, everybody.", "tokens": [492, 603, 536, 689, 321, 352, 13, 1033, 13, 2561, 11, 2201, 13], "temperature": 0.0, "avg_logprob": -0.12521722343530547, "compression_ratio": 1.476595744680851, "no_speech_prob": 8.266822987934574e-06}, {"id": 607, "seek": 384508, "start": 3845.08, "end": 3850.08, "text": " See you tomorrow.", "tokens": [50364, 3008, 291, 4153, 13, 50614], "temperature": 0.0, "avg_logprob": -0.30465078353881836, "compression_ratio": 0.68, "no_speech_prob": 0.00048569386126473546}], "language": "en"}