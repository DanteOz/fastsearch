{"text": " Hi, we are here for lesson 24, and once again it's becoming a bit of a tradition now. We're joined by Jono and Tanishq, which is always a pleasure. Hi Jono, hi Tanishq. Hello. Another great lesson. Yeah, are you guys looking forward to finally actually completing stable diffusion, at least the unconditional stable diffusion? Well, I should say no, even conditional. So conditional stable diffusion, except for the clip bit from scratch. We should be able to finish today, time permitting. Oh, that's exciting. That is exciting. Yeah. All right, let's do it. Jump in any time. You've got things to talk about. So we're going to start with a very hopefully named 26 diffusion unit. What we're going to do in 26 diffusion unit is to do unconditional diffusion from scratch. And there's not really too many new pieces, if I remember correctly. So all the stuff at the start, we've already seen. And so when I wrote this, it was before I had noticed that the Keras approach was doing less well than the regular cosine schedule approach. So I'm still using Keras noiseifier. But this is all the same as from the Keras notebook, which was 23. Okay, so we can now create a unit that is based on what diffusers has, which is in turn based on lots of other prior art. I mean, the code's not at all based on it, but the basic, the structure is going to be the same as what you'll get in diffusers. The convolution we're going to use is the same as the final kind of convolution we used for tiny image net, which is what's called the pre activation convolution. So the convolution itself happens at the end, and the normalization and activation happen first. So this is a pre act convolution. So then I've got a unit res net block. So I kind of wrote this before I actually did the react version of tiny image net. So I suspect this is actually the same, quite possibly exactly the same as the tiny image net one. This is nothing specific about this for unit. This is just really a pre act conv and a pre act res net block. So we've got the two comms as per usual, and the identity conv. Now there is one difference though, to what we've seen before for res net blocks, which is that this res net block has no option to do down sampling, no option to do a stride. This is always stride one, which is our default. So the reason for that is that when we get to the thing that strings a bunch of them together, which will be called down block, this is where you have the option to add down sampling. If you do add down sampling, we're going to add a stride to convolution after the res block. That's because this is how diffusers and stable diffusion does it. I haven't studied this closely. Tanishka, or Donna, if either of you have, know where this idea came from or why. I'd be curious. The difference is that normally we would have average pooling here in this connection. But yeah, this different approach is what we're using. A lot of the history of the diffusers unconditional unit is to be compatible with the DDPM weights that were released, and some follow on work from that. And I know like then improved DDPM and these others, they all kind of built on that same sort of unit structure, even though it's slightly unconventional if you're coming from like a normal computer vision background. Do you recall where the DDPM architecture came from? Because like some of the ideas came from some of the GAN units, but I don't know if DDPM. Yeah, they had something called efficient unit that was inspired by some prior work that I can't remember the lineage. But anyway, yeah, it just means that the diffusers one has since become, you know, like you can add in parameters to control some of this stuff. But yeah, it's... We shouldn't assume that this is the optimal approach, I suppose. But yeah, I will dig into the history and try and find out how much like what ablation studies have been done. So for those of you who haven't heard of ablation studies, that's where you like try, you know, a bunch of different ways of doing things and score which one works better and which one works less well and kind of create a table of all of those options. And so where you can't find ablation studies for something you're interested in, often that means that, you know, maybe not many other options were tried, because researchers don't have time to try everything. Okay, now, the unit, if we go back to the unit that we used for super resolution, we just go back to our most basic version. What we did, as we went down through the layers in the downsampling section, we stored the activations at each point into a list called layers. And then as we went through the upsampling, we added those downsampling layers back into the upsampling activations. So that's the kind of basic structure of a unit. You don't have to add, you can also concatenate, and actually concatenating is what is, I think it's more common nowadays, and I think the original unit might have been concatenating, although for super resolution, just adding seems pretty sensible. So we're going to concatenate. But what we're going to do is we're going to try to, we're going to kind of exercise our Python muscles a little bit to try to see interesting ways to make some of this a little easier to turn different downsampling backbones into units. And you also use that as an opportunity to learn a bit more Python. So what we're going to do is we're going to create something called a saved res block, and a saved convolution. And so our down, our down blocks, so these are our res blocks containing a certain number of res block layers, followed by this optional stride to conv. We're going to use saved res blocks and saved convs. And what these are going to do, it's going to be the same as a normal convolution, and the same as a normal res block, same as a normal unit res block. But they're going to remember the activations. And the reason for that is that later on in the unit, we're going to go through and grab those saved activations all at once into a big list. So then yeah, we basically don't have to kind of think about it. And so to do that, we create a class called a save module. And all save module does is it calls forward to grab the res block or conv results, and stores that before returning it. Now that's weird, because hopefully you know by now that super calls the thing in the parent class, but save module doesn't have a parent class. So this is what's called a mixin. And it's using something called multiple inheritance. And mixins are, as it describes here, it's a design pattern, which is to say it's not particularly a part of Python per se. It's a design pattern that uses multiple inheritance. Now what multiple inheritance is, is where you can say, oh, this class called saved res block inherits from two things, save module and unit res block. And what that does is it means that all of the methods in both of these will end up in here. Now that would be simple enough, except we've got a bit of a confusion here, which is that unit res block contains forward, and save module contains forward. So it's all very well just combining the methods from both of them, but what if they have the same method? And the answer is that the one you list first, when it calls forward, it's actually calling forward in the later one. And that's why it's a mixin. It's mixing this functionality into this functionality. So it's a unit res block where we've customized forward, so it calls the existing forward and also saves it. So you see mixins quite a lot in the Python standard library. For example, the basic HTTP stuff, some of the basic thread stuff, you know, with networking uses multiple inheritance, using this mixin pattern. So with this approach, then the actual implementation of saved res block is nothing at all. So parse means don't do anything. So this is just literally just a class which has no implementation of its own, other than just to be a mixin of these two classes. So a saved convolution is an nn.conv2d with the saved module mixed in. So what's going to happen now is that we can call a saved res block just like a unit res block, and a saved conv just like an nn.conv2d. But that object is going to end up with the activations inside the .saved attribute. So now a downsampling block is just a sequential of saved res blocks. As per usual, the very first one is going to have the number of in channels to start with, and it'll always have the number of NF, the number of filters output, and then after that the inputs will be else equal to NF, because the first ones change the number of channels. And we'll do that for however many layers we have. And then at the end of that process, as we discussed, we will add to that sequential a saved conv with stride2 to do the downsampling if requested. So we're going to end up with a single nn.sequential for a down block. And then an up block is going to look very similar, but instead of using a nn.conv2d with stride2, upsampling will be done with a sequence of an upsampling layer. And so literally all that does is it just duplicates every pixel four times into a little 2x2 grid. That's all an upsampling layer does, nothing clever. And then follow that by a stride1 convolution. So that allows it to, you know, adjust some of those pixels as if necessary with a simple 3x3 conv. So that's pretty similar to a stride2 downsampling. This is kind of the rough equivalent for upsampling. There are other ways of doing upsampling. This is just the one that stable diffusion does. So an up block looks a lot like a down block, except that now, so as before, we're going to create a bunch of unit res blocks. These are not saved res blocks, of course. We want to use the saved results in the upsampling path of the unit. So we just use normal res blocks. But what we're going to do now is as we go through each resnet, we're going to call it not just on our activations, but we're going to concatenate that with whatever was stored during the downsampling path. So this is going to be a list of all of the things stored in the downsampling path. It'll be passed to the up block. And so .pop will grab the last one off that list, and concatenate it with the activations, and pass that to the resnet. So we need to know how many filters there were, how many activations there were in the downsampling path. So that's stored here. This is the previous number of filters in the downsampling path. And so the res block, we'll need to add those in, in addition to the normal number. So that's what's going to happen there. And so yeah, do that for each layer, as before. And then at the end, add an upsampling layer, if it's been requested. If it's a Boolean. Okay, so that's the upsampling block. Does that all make sense so far? Yeah, it looks good. Okay. Okay, so the unit now is going to look a lot like our previous unit. We're going to start out as we tend to, with a convolution, to now allow us to create a few more channels. And so we're passing to our unit, that's just, you know, how many channels are in your image, and how many channels are in your output image. So for normal images, normal full-color images, that'll be 3, 3. How many filters are there for each of those resnet blocks, up blocks and down blocks you've got. And in the downsampling, how many layers are there in each block. So we go from, the conv will go from in-channel, so that'd be 3, to nf0, which, this is the number of filters in the stable diffusion model. They're pretty big, as you see, by default. And so that's the number of channels we'd create. Which is like, very redundant, in that this is a 3x3 conv, so it only contains 3x3x3 channels equals 27 inputs, and 224 outputs. So it's not, you know, doing computation, useful computation, in a sense. It's just giving it more space to work with down the line. Which I don't think that makes sense, but I haven't played with it enough to be sure. Normally we would do like, you know, like a few res blocks or something at this level to more gradually increase it, because this feels like a lot of wasted effort. But yeah, I haven't studied that closely enough to be sure. Sorry, Jeremy, just to tweet, this is the default, I think, the default settings for the unconditional unit in diffusers. But the stable diffusion unit actually has even more channels. It has 320, 640, and then 1280, 1280. Cool, thanks for clarifying. And it's, yeah, the unconditional one, which is what we're doing right now. That's a great point. Okay, so then we, yeah, we go through all of our number of filters. And actually the first res block contains 224 to 224. So that's why it's kind of keeping track of this stuff. And then the second res block is 224 to 448, and then 448 to 672, and then 672 to 896. That's why we're just going to have to keep track of these things. So yeah, we add, so we have a sequential for our down blocks, and we just add a down block. The very last one doesn't have down sampling, which makes sense, right? Because the very last one, there's nothing after it, so no point down sampling. Other than that, they all have down sampling. And then we have one more res block in the middle, which is that the same as what we did? Okay, so we didn't have a middle res block in our original unit here. What about this one? Do we have any mid blocks? No, so we haven't done, okay, but I mean, it's just another res block that you do after the down sampling. And then we go through the reversed list of filters, and go through those and adding up blocks. And then one convolution at the end to turn it from 224 channels to three channels. Okay, and so the forward then is going to store in saved all the layers, just like we did back with this unit. But we don't really have to do it explicitly now. We just call the sequential model, and thanks to our automatic saving, each of those now will, we can just go through each of those and grab their dot saved. So that's handy. We then call that mid block, which is just another res block, and then same thing, okay, now for the ups, and what we do is we just passed in those saved, right? And just remember, it's going to dot pop them out each time. And then the conv at the end. So that's, yeah, that's it. That's our unconditional model. It's not quite the same as the diffuses unconditional model, because it doesn't have a tension, which is something we're going to add next. But other than that, this is the same. So let's, because we're doing a simpler problem, which is fashion MNIST, we'll use less channels than the default. Using two layers per block is standard. One thing to note though, is that in the up sampling blocks, it actually is going to be three layers, num layers plus one. And the reason for that is that the way stable diffusion and diffuses do it, is that even the output of the down sampling is also saved. So if you have num layers equals two, then there'll be two res blocks saving things here, and one conv saving things here. So you'll have three saved cross connections. So that's why there's an extra plus one here. Okay, and then we can just train it using mini AI, as per usual. Nope, I didn't save it after I last trained it. Sorry about that. So trust me, it trained. Okay, now that, oh, okay, no, that is actually missing something else important, as well as attention. The other thing that's missing is that thing that we discovered is pretty important, which is the time embedding. So we already know that sampling doesn't work particularly well without time embedding, so I didn't even bother sampling this. I didn't want to add all this stuff necessary to make that work a bit better. I thought, let's just go ahead and do time embedding. So time embedding, there's a few ways to do it. The way it's done in stable diffusion is what's called sinusoidal embeddings. The basic idea, maybe we'll skip ahead a bit. The basic idea is that we're going to create a res block with embeddings, where forward is not just going to get the activations, but it's also going to get t, which is a vector that represents the embeddings of each time step. So actually, it'll be a matrix, because it's for everything in the batch, but for one element of the batch, it's a vector. And it's an embedding in exactly the same way as when we did NLP. Each token had an embedding, and so the word the would have an embedding, and the word Jono would have an embedding, and the word Tanishq would have an embedding, although Tanishq would probably actually be multiple tokens, until he's famous enough that he's mentioned in nearly every piece of literature, at which point Tanishq will get his own token, I expect. That's how you know when you've made it. So the time embedding will be the same. T of, you know, time step zero will have a particular vector, time step one will have a particular vector, and so forth. Or actually, you know, we're doing keras, so actually they're not time step one, two, three. They're actually sigmas, you know, so they're continuous, but same idea. A specific value of sigma, which is actually what T is going to be, slightly confusingly, will have a specific embedding. Now we want two values of sigma or T, which are very close to each other, should have similar embeddings, and if they're different to each other, they should have different embeddings. So how do we make that happen, you know, and also make sure there's a lot of variety of the embeddings across all the possibilities. So the way we do that is with these sinusoidal time steps. So let's have a look at how they work. So you first have to decide how big do you want your embeddings to be, just like we do in NLP. Does the word the, is it represented by eight floats, or 16 floats, or 400 floats, or whatever? Let's just assume it's 16. So let's say we're just looking at a bunch of time steps which is between negative 10 and 10, and we'll just do 100 of them. I mean, we don't actually have negative sigmas or T, so it doesn't exactly make sense, but it doesn't matter, it's, you know, it just shows you the idea. And so then we say like, okay, what's the largest time step you could have, or the largest sigma that you could have? Interestingly, every single model I've found, every single model I've found, uses 10,000 for this. Even though that number actually comes from the NLP Transformers literature, and it's based on the idea of like, okay, what's the maximum sequence length we support? You can have up to 10,000 things in a, you know, in a document, or whatever, in a sequence. But we don't actually have a sigmas that go up to 10,000. So I'm using the number that's used in real life in stable diffusion and all the other models, but it's interestingly, this is here purely, as far as I can tell, as a hysterical accident, because this is like the maximum sequence length that NLP Transformers people thought they would need to support. Okay, now, what we're then going to do is we're going to be then doing e to the power of a bunch of things. And so that's going to be our exponent. And so our exponent is going to be equal to log of the period, which is about nine, times the numbers between 0 and 1, 8 of them, because we've got, we said we want 16. So you'll see why we want 8 of them and not 16 in a moment. But basically, here are the 8 exponents we're going to use. So then, not surprisingly, we do e to the power of that. So we do e to the power of that, each of these 8 things. And we've also got the actual time steps. So imagine these are the actual time steps we have in our batch. So there's a batch of 100, and they contain these, this range of sigmas or time steps. So to create our embeddings, what we do is we do a outer product of the exponent.exp and the time steps. This is step 1. And so this is using a broadcasting trick we've seen before. We add a unit access, an access 0 here, and add a unit access, sorry, an access 1 here, and add a unit access, an access 0 here. So if we multiply those together, then it's going to broadcast this one across this axis, and this one across this axis. So we end up with a 100 by 8. So it's basically, you know, a Cartesian product, all the possible combinations of time step and exponent multiplied together. And so here's like, you know, a few of those different exponents for a few different values. Okay, so that's not very interesting yet. We haven't yet reached something where each time step is similar to each next door time step. You know, over here, you know, these embeddings look very different to each other, and over here, they're very similar. So what we then do is we take the sine and the cosine of those. So that is 100 by 8, and that is 100 by 8, and that gives us 100 by 16. So we concatenate those together. And so that's a little bit hard to wrap your head around, so let's take a look. So the, across the 100 time steps, or 100 sigmas, this one here is the first sine wave. And then this one here is the second sine wave. And this one here is the third. And this one here is the fourth and the fifth. So you can see as you go up to higher numbers, you're basically, you know, stretching the sine wave out. And then once you get up to index 8, you're back up to the same frequency as this blue one, because now we're starting the cosine rather than sine. And cosine is identical to sine, it's just shifted across a tiny bit. So you can see these two light blue lines are the same, and these two orange lines are the same, they're just shifted across. I shouldn't say lines, sorry, curves. So when we concatenate those all together, we can actually draw a picture of it. And so this picture is 100 pixels across, and 16 pixels top to bottom. And so if you picked out a particular point, so for example in the middle here, for t equals 0, for sigma equals 0, one column is an embedding. So the bright represents higher numbers, and the dark represents lower numbers. And so you can see every column looks different, even though the columns next to each other look similar. So that's called a time step embedding. And this is definitely something you want to experiment with, right? Like, really, I've tried to do the plots I thought are useful to understand this, but, and Jono and Tanishka also had ideas about plots for these, you know, which we've shown. But you know, the only way to really understand them is to experiment. So then we can put that all into a function, where you just say, okay, well, how many times, sorry, what are the time steps? How many embedding dimensions do you want? What's the maximum period? And then all I did was I just copied and pasted the previous cells, and merged them together. So you can see there's our outer product, and there's our cat of sine and cos. If you end up with a, if you have an odd numbered embedding dimension, you have to pad it to make it even, don't worry about that. So here's something that now you can pass in the number of, sorry, the actual time steps or sigmas, and the number of embedding dimensions, and you will get back something like this. It won't be a nice curve, because your time steps in a batch won't all be next to each other. It's the same idea. Can I call something on that little visualization there, which goes back to your comment about the max period being super high? Yeah. So you said like, okay, adjacent ones are somewhat similar, because that's what we want, but there is some change. But if you look all of this first 100, some, just like the half of the embeddings look like they don't really change at all. And that's because 50 to 100 on a scale of like 0 to 10,000, you want those to be quite similar, because those are still very early in this like super long sequence that these are designed for. Yeah. So here actually we've got wasted space. Yeah. So here we've got a max period of a thousand instead. And I've changed the figure size, you can see it better, and it's using up a bit more of the space. Yeah. Or go to max period of 10. And it's actually now, this is, yeah, using it much better. Yeah. So like, based on, you know, what you're saying, John, I agree. Like it seems like it would be a lot richer to use these time step embeddings with a suitable max period, or maybe you just wouldn't need as many embedding dimensions. I guess if you did use something very wasteful like this, but you used lots of embedding dimensions, then it's going to still capture some useful ones. Yeah. Thanks, John. So, yeah. Yeah. So this is one of these interesting little insights about things that are buried deep in code, which I'm not sure anybody probably much looks at. Okay. So let's do a unit with time step embedding in it. So what do you do once you've got like this column, you know, of embeddings for each item of the batch? What do you do with it? Well, there's a few things you can do with it. What stable diffusion does, I think is correct, I'm not promising because I remember all these details right, is that they make their embedding dimension length twice as big as the number of activations. And what they, what they then do is we can use chunk to take that and split it into two separate variables. So that just literally just, it's the opposite of concatenate, it's two separate variables. One of them is added to the activations and one of them is multiplied by the activations. So this is a scale and a shift. We don't just grab the embeddings as is though, because each layer might want to do, each res block might want to do different things with them. So we have a embedding projection, which is just a linear layer, which allows them to be projected. So it's projected from the number of embeddings to two times the number of filters, so that that torch.chunk works. We also have an activation function called cilu. This is the activation function that's used in stable diffusion. I don't think the details are particularly important, but it looks basically like a rectified linear with a slight curvy bit. And also known as swish. Also known as swish. And it's just equal to x times sigmoid x. And yeah, I think it's like activation functions don't make a huge difference, but it'll, they can make things train a little better or a little faster and swish has been something that's worked pretty well. So people, a lot of people using swish or cilu. I always call it swish. But I think cilu was actually where it was originally, the Galliou paper, which had cilu was where it originally was kind of invented and maybe people didn't quite notice. And then another paper called it swish and everybody called it swish. And then people were like, wait, that wasn't the original paper. So I guess I should try to call it cilu. Okay. So yeah, other than that, it's just a normal res block. So we do our first conv, then we do our embedding projection of the activation function of time steps. And so that's going to be applied to every channel, sorry, to every pixel height and width. So that's why we have to add unit axes on the height and width, that it's going to cause it to broadcast across those two axes. Do our chunk, do the scale and shift, then we're ready for the second conv. And then we add it to the input with a additional conv, one stride one conv if necessary, as we've done before, if we have to change the number of channels. Okay. Yeah, because I like exercising our Python muscles, I decided to use a second approach now for the down block and the up block. I'm not saying which one's better or worse. We're not going to use multiple inheritance anymore, but instead we're going to use, well it's not even a decorator, it's a function which takes a function. What we're going to do now is we're going to use conv2dd and ember as block directly, but we're going to pass them to a function called saved. The function called saved is something which is going to take as input a callable, which could be a function or a module or whatever. So in this case it's a module. Takes an ember as block or a conv2d and it returns a callable. The callable it returns is identical to the callable that's passed into it, except that it saves the result, saves the activations, saves the result of the function. Where does it save it? It's going to save it into a list in the second argument. You pass to it, which is the block. So the saved function, you're going to pass it the module. We're going to grab the forward from it and store that away to remember what it was. And then the function that we want to replace it with, call it underscore f, going to take some arguments and some keyword arguments. Well basically it's just going to call the original modules.forward, passing in the arguments and keyword arguments. And we're then going to store the result in something called the saved attribute inside here. And then we have to return the result. So then we're going to replace the modules forward method with this function and return the module. So that module's now been, yeah I said callable actually, it can't be callable, it has to specifically be a module because with the forward that we're changing. This at wraps is just something which automatically, it's from the Python standard library, it's just going to copy in the documentation and everything from the original forward. So that it all looks like nothing's changed. Now where does this .saved come from? I realized now actually we could make this easier and automate it, but I forgot, didn't think of this at the time. So we have to create the saved here in the down block. It actually would have made more sense I think here for it to have said if the saved attribute doesn't exist then create it. Which would look like this. If not hasAtcher block, saved, block.saved equals, if you do this, then you wouldn't need this anymore. Anyway I didn't think of that at the time, so let's pretend that that's not what we do. So yeah, now the downsampling.conv and the resnets both contain saved versions of modules. We don't have to do anything to make that work, we just have to call them. We can't use sequentials anymore because we have to pass in the time step to the resnets as well. It would be easy enough to create your own sequential for things with time steps, which passes them along. But that's not what we're doing here. Yeah maybe it makes sense for sequential to always pass along all the extra arguments, but I don't think that's how they work. So our up block is basically exactly the same as before, except we're now using ember as blocks instead. Just like before we're going to concatenate. So that's all the same. So a unit model with time embeddings is going to look, if we look at the forward, the thing we're passing into it now is a tuple containing the activations and the time steps, or the sigmas in our case. So split them out, and what we're going to do is we're going to call that time step embedding function we wrote, saying okay, these are the time steps, and the number of time step embeddings we want is equal to however many we asked for, and we're just going to set it equal to the first number of filters. That's all that happens there. And then we want to give the model the ability then to do whatever it wants with those, to make those work the way it wants to, and the easiest smallest way to do that is to create a tiny little MLP. So we create a tiny little MLP, which is going to take the time step embeddings and return the actual embeddings to pass into the resnet blocks. So tiny little MLP is just a linear layer with, let's think in here, hmm, linear layer. That's interesting. I, my linear layer by default has an activation function. I'm pretty sure we should have act equals none here. Should be a linear layer and then an activation and then a linear layer. So I think I've got it back, which we will need to try rerunning. Okay. It won't be the end of the world, it just means all the negatives will be lost here, which makes it half, only half as useful. That's not great. Okay. And these are the kind of things like, you know, as you can see, you've got to be super careful of like, where do you have activation functions? Where do you have batch norms? Is it pre-activation, is it post-activation? It trains, even if you make that mistake, and in this case, probably not too much performance, but often it's like, oh, you've done something where you accidentally zeroed out, you know, all except the last few channels of your like outputs of the block or something like that. And the network tries anyway, it does the best, it uses what it can. Yeah. But yeah. Yeah, it makes it very difficult. Make sure you're not giving it those handicaps. Yeah. It's not like you're making a crud app or something, and you know that it's not working because it crashes, or because like it doesn't show the username, or whatever. Instead you just get like slightly less good results, but since you haven't done it correctly in the first place, you don't know it's a less good result. Yeah, there's not really great ways to do this. It's really nice if you can have an existing model to compare to, or something like that. Which is where Kaggle competitions work really well, actually. If somebody's got a Kaggle result, then you know that's a really good baseline, and you can check whether yours is as good as theirs. All right. So yeah, that's what this mnrlp is for. So the down and up blocks are the same as before, the conv out is the same as before. So yeah, so we grab our time step embeddings, that's just that outer product passed through this sinusoidal, the sine and cosine. We then pass that through the MLP, and then we call our downsampling, passing in those embeddings each time. You know, it's kind of interesting that we pass in the embeddings every time, in the sense I don't exactly know why we don't just pass them in at the start. And in fact, in NLP, these kinds of embeddings, I think, are generally just passed in at the start. So this is kind of a curious difference. I don't know why it's, you know, if there's been ablation studies, or whatever. Do you guys know, are there, like, any popular Diffusiony or generative models with time embeddings that don't pass them in, or is this pretty universal? Some of the fancier architectures, like recurrent interface networks and stuff, just pass in the conditioning. I'm actually not sure, yeah, maybe they do still do it, like, at every stage. I think some of them just take in everything all at once up front, and then do a stack of transformer blocks, or something like that. So I don't know if it's universal, but it definitely seems like all the unit style ones have this, the time step embedding going in at all the different stages. Maybe we should try some ablations to see, yeah, if it matters. I mean, I guess it doesn't matter too much either way. But yeah, if you didn't need it at every step, then it would maybe save you a bit of compute, potentially. Yeah, so now the upsampling, you're passing in the activations, the time step embeddings, and that list of saved activations. So yeah, now we have a non-attention stable diffusion unit. So we can train that, and we can sample from it using the same, I just copied and pasted all the stuff from the Keras notebook that we had. And there we have it. This is our first diffusion from scratch. So we wrote every piece of code for this diffusion model? Yeah, I believe so. I mean, obviously, in terms of the optimized code of implementations of stuff, no. But yeah, we've written our version of everything here, I believe. A big milestone. I think so, yeah. And these fits are about the same as the fits that we get from the stable diffusion one. They're not particularly higher or lower. They bounce around a bit, so it's a little hard to compare. But yeah, they're basically the same. Yeah, so that is an exciting step. And OK, yeah, that's probably a good time to have a five-minute break. Yeah, OK, let's have a five-minute break. OK, normally I would say we're back, but only some of us are back. Jano's internet and electricity in Zimbabwe is not the most reliable thing, and he seems to have disappeared. But we expect him to reappear at some point. So we'll kick on Jano-less and hope that Zimbabwe's infrastructure sorts itself out. All right, so we're going to talk about attention. We're going to talk about attention for a few reasons. Reason number one, very pragmatic. We said that we would replicate stable diffusion, and the stable diffusion unit has attention in it. So we would be lying if we didn't do attention. Number two, attention is one of the two basic building blocks of transformers. A transformer layer is attention attached to a one-layer MLP. We already know how to create a one-layer or one hidden layer MLP. So once we learn how to do attention, we'll know how to create transformer blocks. So those are two good reasons. I'm not including a reason which is our model is going to look a lot better with attention, because I actually haven't had any success seeing any diffusion models I've trained work better with attention. So just to set your expectations, we are going to get it all working. But regardless of whether I use our implementation of attention or the diffuser's one, it's not actually making it better. That might be because we need to use better types of attention than what diffusers has, or it might be because it's just a very subtle difference that you only see on bigger images. I'm not sure. That's something we're still trying to figure out. This is all pretty new, and not many people have done the kind of ablation studies necessary to figure these things out. So yeah, that's just life. Anyway, so there's lots of good reasons to know about attention. We'll certainly be using it a lot once we do an LP, which we'll be coming to pretty shortly, pretty soon. And it looks like Jono is reappearing as well, so that's good. Okay, so let's talk about attention. The basic idea of attention is that we have, you know, an image, and we're going to be sliding a convolution kernel across that image. Right? And, obviously, we've got channels as well, or filters. And so this also has that. Okay. And as we bring it across, we might be, you know, we're trying to figure out, like, what activations do we need to create to eventually, you know, correctly create our outputs. But the correct answer as to what's here may depend on something that's way over here, and or something that's way over here. So, for example, if it's a cute little bunny rabbit, and this is where its ear is, you know, and there might be two different types of bunny rabbit that have different shaped ears, well, it would be really nice to be able to see over here what its other ear looks like, for instance. With just convolutions, that's challenging. It's not impossible. We talked in part one about the receptive field. And as you get deeper and deeper in a conv net, the receptive field gets bigger and bigger. But it's, you know, at higher up, it probably can't see the other ear at all. So it can't put it into those kind of more texture level layers. And later on, you know, even though this might be in the receptive field of here, most of the weight, you know, the vast majority of the activations it's using is the stuff immediately around it. So what attention does is it lets you take a weighted average of other pixels around the image, regardless of how far away they are. And so in this case, for example, we might be interested in bringing in at least a few of the channels of these pixels over here. The way that attention is done in stable diffusion is pretty hacky, and known to be suboptimal. But it's what we're going to implement, because we're implementing stable diffusion, and time permitting maybe we'll look at some other options later. The kind of attention we're going to be doing is 1D attention. And it was attention that was developed for NLP. And NLP is sequences, one-dimensional sequences of tokens. So to do attention stable diffusion style, we're going to take this image, and we're going to flatten out the pixels. So we've got all these pixels. We're going to take this row, and put it here. And then we're going to take this row, we're going to put it here. So we're just going to flatten the whole thing out into one big vector of all the pixels of row one, and then all the pixels of row two, and then all the pixels of row three. Or maybe it's column one, column two, column three. I can't remember if it's row wise or column wise, but it's flattened out. And then it's actually, for each image, it's actually, you know, a matrix, which I'm going to draw it a little bit 3D, because we've got the channel dimension as well. So this is going to be the number across this way is going to be equal to the height times the width. And then the number this way is going to be the number of channels. OK, so how do we decide, yeah, which, you know, bring in these other pixels? Well what we do is we basically create a weighted average of all of these pixels. So maybe these ones get a bit of a negative weight. And these ones get a bit of a positive weight. And you know, these get a weight kind of somewhere in between. And so we're going to have a weighted average. And so basically each pixel, so let's say we're doing this pixel here right now, is going to equal its original pixel plus, so it's called x, plus the weighted average. So the sum across, so maybe this is like x i, plus the sum of all the other pixels. So from 0 to the height times the width, some weight times each pixel. The weights, they're going to sum to 1. And so that way the, you know, the pixel value scale isn't going to change. Well that's not actually quite true. It's going to end up potentially twice as big, I guess, because it's being added to the original pixel. So attention itself is not with the x plus. But the way it's done in stable diffusion, at least, is that the attention is added to the original pixel. So yeah, now I think about it. I'm not going to think about how this is being scaled. Anyhow. So the big question is what values to use for the weights. And the way that we calculate those is we do a, we do a matrix product. And so our, for a particular pixel, we've got, you know, the number of channels for that one pixel. And what we do is we can compare that to all of the number of channels for all the other pixels. So we've got kind of, this is pixel, let's say x1. And then we've got pixel number x2. Right. All those channels. We can take the dot product between those two things. And that will tell us how similar they are. And so one way of doing this would be to say like, okay, well, let's take that dot product for every pair of pixels. And that's very easy dot product to do. Because that's just what the matrix product is equal to. So if we've got h by w by c. And then multiply it by its transpose. H by w by, sorry. I said transpose and then totally failed to do transpose. Multiply by its transpose. And that will give us an h by w by h by w matrix. So each pixel, all the pixels are down here. And for each pixel, as long as these add up to one, then we've got a weight for each pixel. And it's easy to make these add up to one. We could just take this matrix multiplication and take the sigmoid over the last dimension. Sorry, not sigmoid. Man, what's wrong with me? Softmax, right? Yeah. And take the softmax over the last dimension. And that will give me something that adds the sum equals one. Okay. Now the thing is, it's not just that we want to find the places where they look the same, where the channels are basically the same. But we want to find the places where they're like similar in some particular way, you know. And so some particular set of channels are similar in one to some different set of channels in another. And so, you know, in this case, we may be looking for the pointy-erredness activations, you know, which actually are represented by, you know, this, this, and this, you know. And we want to just find those. So the way we do that is before we do this matrix product, we first put our matrix through a projection. So we just basically put our matrix through a matrix multiplication. This one. So it's the same matrix, right? But we put it through two different projections. And so that lets it pick two different kind of sets of channels to focus on or not focus on before it decides, you know, oh, this pixel is similar to this pixel in the way we care about. And then actually, we don't even just multiply it then by the original pixels. We also put that through a different projection as well. So there's these different projections. We'll do projection one, projection two, and projection three. And that gives it the ability to say, like, oh, I want to compare these channels and, you know, these channels to these channels to find similarity. And based on similarity, I then want to pick out these channels, right? Both positive and negative weight. So that's why there's these three different projections. And so the projections are called A, Q, and V. Those are the projections. And so they're all being passed the same matrix. And because they're all being passed the same matrix, we call this self-attention. Okay, Jono, Tindeshk, I know this is, I know you guys know this very well, but you also know it's really confusing. Did you have anything to add, change, anything else? Yeah, I like that you introduced this without resorting to the, let's think of this as queries at all, which I think is, yeah, as we've noted, maybe more confusing than helpful. These actually, yeah, these are actually short for key, query, and value, even though I personally don't find those useful concepts. Yeah. Your note on the scaling, you said, oh, so we set it so that the weights sum to one. And so then we'd need to worry about, are we doubling the scale of X? But because of that P3, aka V, that projection, that can learn to scale this thing that's added to X appropriately. And so it's not just doubling the size of X, it's increasing it a little bit, which is why we scatter normalization in between all of these attention areas. But it's not as bad as it might be because we have that V projection. Yeah, that's a good point. And if this is P3, or it's actually the V projection, is initialized such that it would have a mean of zero, then on average, you know, it should start out by not messing with our scale. Okay, so yeah, I guess I find it easier to think in terms of code. So let's look at the code. You know, there's actually not much code. I think you've got a bit of background noise too, John, maybe. Yes, that's much better, thank you. So in terms of code, there's, you know, this is one of these things, getting everything exactly right. And it's not just right, I wanted to get it identical to the stable diffusion. So we can say we've made it identical to stable diffusion. I've actually imported the attention block from diffusers so we can compare. And it is so nice when you've got an existing version of something to compare to, to make sure you're getting the same results. So we're going to start off by saying, let's say we've got a 16 by 16 pixel image, and this is some deeper level of activation. So it's got 32 channels with a batch size of 64. So nchw, I'm just going to use random numbers for now, but this has the, you know, reasonable dimensions for an activation inside a batch size 64 CNN or diffusion model or whatever. Okay, so the first thing we have to do is to flatten these out. Because as I said, in 1D attention, this is just ignored. So it's easy to flatten things out. You just say .view, and you pass in the dimensions of the, in this case, the three dimensions we want, which is 64, 32, and everything else. Minus one means everything else. So x.shape colon 2, in this case, is, you know, obviously it'd be easier just to type 64, 32, but I'm trying to create something that I can paste into a function later. So it's general. So that's the first two elements, 64, 32. And then the star just inserts them directly in here. So 64, 32, minus one. So 16 by 16. Now then, again, because this is all stolen from the NLP world, in the NLP world, things are, have, they call this sequence. So I'm going to call this sequence, by which we mean height by width. Sequence comes before channel, which is often called D or dimension. So we then transpose those last two dimensions. So we've now got batch by sequence, 16 by 16, by channel or dimension. So N, they generally call this NSD, sequence dimension. Okay, so we've got 32 channels. So we now need three different projections that go from 32 channels in to 32 channels out. So that's just a linear layer. Okay, and just remember a linear layer is just a matrix multiply plus a bias. So there's three of them. And so they're all going to be randomly initialized, different random numbers. We're going to call them SK, SQ, SV. And so we can then, they're just callable, so we can then pass the exact same thing into three, all three, because we're doing self-attention to get back our keys, queries, and values. Or K, Q, and V. I just think of them as K, Q, and V, because they're not really keys, queries, and values to me. So then we have to do the matrix multiply by the transpose. And so then for every one of the 64 items in the batch, for every one of the 256 pixels, there are now 256 weights, or at least there would be if we'd done softmax, which we haven't yet. So we can now put that into a self-attention. As Jono mentioned, we want to make sure that we normalize things. So we can pop a normalization here. We talked about group norm back when we talked about batch norm. So group norm is just batch norm, which has been split into a bunch of sets of channels. Okay, so then we are going to create our K, Q, V. Yep, Jono? I was just going to ask, should those be just bias equals false, so that they're only a matrix multiply to strictly match the traditional implementation? No, because... Okay, they also do it that way. Yeah, they have bias in their attention blocks. Cool. Okay, so we've got our Q, K, and V, self.Q, self.K, self.V being our projections. And so to do 2D self-attention, we need to find the n, c, h, w from our shape. We can do our normalization. We then do our flattening, as discussed. We then transpose the last two dimensions. We then create our Q, K, V by doing the projections. And we then do the matrix multiply. Now we've got to be a bit careful now, because as a result of that matrix multiply, we've changed the scale by multiplying and adding all those things together. So if we then simply divide by the square root of the number of filters, it turns out that's... You can convince yourself of this if you wish to, but that's going to return it to the original scale. We can now do the softmax across the last dimension, and then multiply each of them by V. So using matrix multiply to do them all in one go. We didn't mention, but we then do one final projection. Again, just to give it the opportunity to map things, you know, to some different scale. You know, shift it also if necessary. So we can then shift the last two back to where they started from, and then reshape it back to where it started from, and then add it. Remember I said it's going to be X plus. Add it back to the original. So this is actually kind of self-attention, ResNet style, if you like. Diffuses, if I remember correctly, does include the X plus in theirs, but some implementations, like for example PyTorch implementation, doesn't. Okay, so that's a self-attention module, and all you need to do is tell it how many channels to do attention on. So and you need to tell it that, because that's what we need for our four different projections, and our group and our scale. I guess strictly speaking, it doesn't have to be stored here. You could calculate it here, but anyway, either way is fine. Okay, so if we create a self-attention layer, we can then call it on our little randomly generated numbers, and it doesn't change the shape, because we transpose it back and reshape it back, but we can see that's basically worked. We can see it creates numbers. How do we know if they're right? Well we could create a diffuses attention block, that will randomly generate a QKV projection. Sorry actually they call something else, they call it query key value projection attention and group norm. We call it QKV progen norm, they're the same things. And so then we can just zip those tuples together, so that's going to take each pair, first pair, second pair, third pair, and copy the weight and the bias from their attention block, sorry from our attention block to the diffuses attention block, and then we can check that they give the same value, which you can see they do. So this shows us that our attention block is the same as the diffuses attention block, which is nice. There's a trick which neither diffuses nor PyTorch use, for reasons I don't understand, which is that we don't actually need three separate projections here. We could create one projection from ni to ni times 3, that's basically doing three projections. So we could call this QKV, and so that gives us 64 by 256 by 96, instead of 64 by 256 by 32, because it's the three sets. And then we can use chunk, which we saw earlier, to split that into three separate variables along the last dimension to get us our QKV. And we can then do the same thing, Q at Q dot transpose etc. So here's another version of attention, where we just have one projection for QKV, and we chunkify it into separate Q, K, and V, and this does the same thing, it's just a bit more concise. And it should be faster as well, at least if you're not using some kind of XLA compiler or ONX or Triton or whatever. For normal PyTorch, this should be faster, because it's doing less back and forth between the CPU and the GPU. All right, so that's basic self-attention. This is not what's done basically ever, ever. Because in fact, the kind of question of like, well, which pixels do I care about, depends on which channels you're referring to, you know. Because like, the ones which are about like, oh, what color is its ear, as opposed to how pointy is its ear, might depend more on like, what, you know, is this bunny in the shade or in the sun? And so maybe, you know, you may want to look at its body over here to decide what color to make them, rather than how pointy to make it. And so, yeah, different channels need to bring in information from different parts of the picture, depending on which channel we're talking about. And so the way we do that is with multi-headed attention. And multi-headed attention actually turns out to be really simple. And conceptually, it's also really simple. What we do is we say, let's come back to when we look at C here, and let's split them into four separate vectors. One, two, three, four. Let's split them. Right? And let's do the whole, you know, dot product thing on just, you know, his, the first part with the first part. And then do the whole dot product part with the second part with the second part. And so forth. Right? So we're just going to do it separately. Separate matrix multipliers for different groups of channels. And the reason we do that is it then allows, yeah, different parts, different sets of channels to pull in different parts of the image. And so these different groups are called heads. And I don't know why. But they are. Does that seem reasonable? Anything to add to that? It's maybe worth thinking about why, with just a single head, specifically the softmax starts to come into play. Because, you know, we said it's like a weighted sum, so it's able to bring in information from different parts and whatever else. But with softmax, what tends to happen is whatever weight is highest gets scaled up quite dramatically. And so it's like almost like focused on just that one thing. And then, yeah, like as you said, Jeremy, like different channels might want to refer to different things. And, you know, just having this one like single weight that's across all the channels means that that signal is going to be like focused on maybe only one or two things as opposed to being able to bring in lots of different kinds of information based on the different channels. Right. And you're pointing out... I was going to mention the same thing, actually. That's a good point. So you're mentioning the second interesting important point about softmax. You know, point one is that it creates something that adds to one. But point two is that because of its etithers, it tends to highlight one thing very strongly. And yes, so if we had single-headed attention, your point, guys, I guess, is that you're saying it would end up basically picking nearly all one pixel, which would not be very interesting. Okay, awesome. Oh, I see why everything's got thick. I've accidentally turned it into a marker. Okay. So multi-headed attention, I'll come back to the details of how it's implemented in terms of... But I'm just going to mention the basic idea. This is multi-headed attention, and this is identical to before, except I've just stored one more thing, which is how many heads do you want. And then the forward is actually nearly all the same. So this is identical, identical, identical. This is new. Identical, identical, identical, new. Identical, identical. So there's just two new lines of code, which might be surprising, but that's all we needed to make this work. And they're also pretty wacky, interesting new lines of code to look at. Basically what these two lines of code do is they, first they do the projection, right? And then, they basically take the number of heads. So we're going to do four heads. We've got 32 channels, four heads. So each head's going to contain eight channels. And they basically grab... We're going to keep it as being eight channels, not as 32 channels. And we're going to make each batch four times bigger, right? Because the images in a batch don't combine with each other at all. They're totally separate. So instead of having one image containing 32 channels, we're going to turn that into four images containing eight channels. And that's actually all we need, right? Because remember I told you that each group of channels, each head, we want to have nothing to do with each other. So if we literally turn them into different images, then they can't have anything to do with each other. Because batches don't react to each other at all. So this rearrange, and I'll explain how this works in a moment. But it's basically saying, think of the channel dimension as being of H groups of D, and rearrange it. So instead the batch channel is N groups of H. And the channels is now just D. So that would be eight, instead of four by eight. And then we do everything else exactly the same way as usual. But now that group, that the channels have been split into groups of H, groups of four. And then after that, okay, well, we were thinking of the batches as being of size N by H. Let's now think of the channels as being of size H by D. That's what these rearrangers do. So let me explain how these work. In the diffuser's code, I've, can't remember if I duplicated it or just inspired by it. They've got things called heads to batch and batch to heads, which do exactly these things. And so for heads to batch, they say, okay, you've got 64 per batch by 256 pixels by 32 channels. Okay, let's reshape it. So you've got 64 images by 256 pixels by four heads by the rest. So that would be 32 over 8 channels. So it's split it out into a separate dimension. And then if we transpose these two dimensions, it'll then be N by 4. So N by heads by SL by minus 1. And so then we can reshape. So those first two dimensions get combined into one. So that's what heads to batch does. And batch to heads does the exact opposite, right? Reshapes to bring the batch back to here, and then heads by SL by D, and then transpose it back again and reshape it back again so that the heads gets it. So this is kind of how to do it using just traditional PyTorch methods that we've seen before. But I wanted to show you guys this new-ish library called INOPS, inspired, as it suggests, by Einstein summation notation. But it's absolutely not Einstein summation notation. It's something different. And the main thing it has is this thing called rearrange. And rearrange is kind of like a nifty rethinking of Einstein summation notation as a tensor rearrangement notation. And so we've got a tensor called T, we created earlier, 64 by 256 by 32. And what INOPS rearrange does is you pass it this specification string that says, turn this into this. Okay. This says that I have a rank 3 tensor, three dimensions, three axes, containing the first dimension is of length n, the second dimension is of length s, the third dimension is in parentheses is of length h times d, where h is 8. And then I want you to just move things around so that nothing is, like, broken, you know, so everything's shifted correctly into the right spots, so that we now have each batch is now instead n times 8, n times h. The sequence length is the same. And d is now the number of channels. Previously the number of channels was h by d. Now it's d. So the number of channels has been reduced by a factor of 8. And you can see it here. It's turned T from something of 64 by 256 by 32 into something of size 64 times 8 by 256 by 32 divided by 8. And so this is, like, really nice, because, you know, a, this one line of code to me is clearer and easier, and I like writing it better than these lines of code. But where it's particularly nice is when I had to go the opposite direction. I literally took this, cut it, put it here, and put the arrow in the middle. Like, it's literally backwards. Which is really nice, right? Because we're just rearranging it in the other order. And so if we rearrange it in the other order, we take our 512 by 256 by 4 thing that we just created, and end up with a 64 by 256 by 32 thing, which we started with, and we can confirm that the end thing equals, or every element equals the first thing. So that shows me that my rearrangement has returned its original correctly. Yeah, so multi-headed attention I've already shown you. It's the same thing as before, but pulling everything out into the batch for each head, and then pulling the heads back into the channels. So we can do multi-headed attention with 32 channels and 4 heads, and check that all looks OK. So PyTorch has that all built in. It's called nn.multi-headed attention. Be very careful. Be more careful than me, in fact, because I keep forgetting that it actually expects the batch to be the second dimension. So make sure you write batch first equals true to make batch the first dimension, and that way it'll be the same as diffusers. It might not be identical, but the same. It should be almost the same idea. To make it self-attention, you've got to pass in three things, right? So the three things will all be the same for self-attention. This is the thing that's going to be passed through the Q projection, the K projection, and the V projection. And you can pass different things to those. If you pass different things to those, you'll get something called cross-attention, rather than self-attention, which I'm not sure we're going to talk about until we do it in NLP. Just on the rearrange thing, I know if you've been doing PyTorch and you're used to it, like you really know what transpose and reshape and whatever do, then it can be a little bit weird to see this new notation. But once you get into it, it's really, really nice. And if you look at the self-attention multi-headed implementation there, you've got .view and .transpose and .reshape. It's quite fun practice. If you're just saying, oh, this INOPS thing looks really useful, take an existing implementation like this and say, oh, maybe instead of .reshape or whatever, can I start replacing these individual operations with the equivalent rearrange call? And then checking that the outputs are the same. That's what helped it click for me, was, oh, OK. I can start to express, if it's just transpose, then that's a rearrange with the last two channels switched, if I wanted to do it that way. I only just started using this, and I've obviously had many years of using reshape, transpose, et cetera, in Fiano, TensorFlow, Keras, PyTorch, APL. And I would say within 10 minutes, I was like, oh, I like this much better. You know, like it's fine for me, at least. It didn't take too long to be convinced. It's not part of PyTorch or anything. You've got to pip install it, by the way. And it seems to be becoming super popular now, at least in the kind of diffusion research crowd. Everybody seems to be using INOPS suddenly, even though it's been around for a few years. And I actually put in an issue there, and asked them to add in Einstein summation notation as well, which they've now done. So it's kind of like your one place for everything, which is great. And it also works across TensorFlow and other libraries as well, which is nice. OK, so we can now add that to our unit. So this is basically a copy of the previous notebook, except what I've now done is I did this at the point where it's like, oh, yeah, it turns out that cosine scheduling is better. So I'm back to cosine schedule now. So this is copied from the cosine schedule book. And we're still doing the minus .5 thing, because we love it. And so this time, I actually decided to export stuff into a mini AI.diffusion. So since this point, I felt like things were working pretty well. So I renamed unit.conv to pre.conv. It's a better name. Time step embedding has been exported. Pup sample's been exported. This is like a preact linear version exported. I tried using an n.multi-headed tension, and it didn't work very well for some reason. So I haven't figured out why that is yet. So I'm using this self-attention, which we just talked about. Multi-headed self-attention. You know, just the scale, we have to divide the number of channels by the number of heads, because the effective number of heads is, you know, divided across n heads. And instead of specifying n heads, you specify attention channels. So if you have 32 attention channels, then you calculate. That's what diffuses does, I think. It's not what n.multi-headed tension does. And actually, I think n i divided by n i divided by attention chance is actually just equal to attention chance. So I could have just put that, probably. Anyway, never mind. So that's all copied in from the previous one. The only thing that's different here is I haven't got the dot view minus one thing here. So this is a 1D self-attention. And then 2D self-attention just adds the dot view before we call forward, and then dot reshape it back again. So yeah, so we've got 1D and 2D self-attention. Okay, so now our mBrez block has one extra thing you can pass in, which is attention channels. And so if you pass in attention channels, we're going to create something called self.attention, which is a self-attention 2D layer with the right number of filters and the requested number of channels. And so this is all identical to what we've seen before, except if we've got attention, then we add it. Oh yeah, and the attention that I did here is the non-ResNet-y version. So we have to do x plus, because that's more flexible. You can then choose to have it or not have it this way. Okay, so that's an mBrez block with attention. And so now our down block, you have to tell it how many attention channels you want, because the res blocks need that. The up block, you have to know how many attention channels you want, because again, the res blocks need that. And so now the UNet model, where does the attention go? Okay, we have to say how many attention channels you want. And then you say, which index block do you start adding attention? So why don't we, so then what happens is the attention is done here. Each ResNet has attention. And so as we discussed, you just do the normal res and then the attention. And if you put that in at the very start, right, let's say you've got a 256 by 256 image, then you're going to end up with this matrix here. It's going to be 256 by 256 on one side and 256 by 256 on the other side and contain however many, you know, NF channels. That's huge. And you have to back prop through it. So you have to store all that to allow back prop to happen. It's going to explode your memory. So what happens is basically nobody puts attention in the first layers. So that's why I've added a attention start, which is like at which block do we start adding attention and it's not zero for the reason we just discussed. Another way you could do this is to say like, at what grid size should you start adding attention? So generally speaking, people say at when you get to 16 by 16, that's a good time to start adding attention. Although stable diffusion adds it at 32 by 32. Because remember, they're using latence, which we'll see very shortly, I guess in the next lesson. So it starts at 64 by 64 and then they add attention at 32 by 32. So we're again, we're replicating stable diffusion here. Stable diffusion uses attention start at index one. So when we go self.downs.append, the down block has zero attention channels if we're not up to that block yet. And ditto on the up block, except we have to count from the end blocks. Now I think about it, that should have attention as well. The mid block. So that's missing. Yeah, so the forward actually doesn't change at all for attention. It's only the init. Yeah, so we can train that. And so previously, yeah, we got without attention, we got to 137. And with attention. Oh, we can't compare directly because we've changed from keras to cosine. We can compare the sampling though. So we're getting, what are we getting? Four, five, five, five. It's very hard to tell if it's any better or not, because, well again, you know, a cosine schedules better. When I've done kind of direct like with like, I haven't managed to find any obvious improvements from adding attention. But I mean, it's doing fine, you know, four is great. Yeah. All right. So then finally, did you want to add anything before we go into a conditional model? I was just going to make a note that, like, I guess just to clarify, for the attention, part of the motivation was certainly to do the sort of spatial mixing and kind of like, yeah, to get from different parts of the image and mix it. But then the problem is if it's too early, where you do have one of the more individual pixels, then the memory is very high. So it seems like you have to get that balance of where you don't, you kind of want it to be early so you can do some of that mixing, but you don't want to be too early where then the memory usage is too high. So it seems like there is certainly kind of the balance of trying to find maybe that right place where to add attention into your network. So I just thought I was just thinking about that. And maybe that's a point worth noting. Yeah, for sure. There is a trick, which is like what they do in, for example, vision transformers or the DIT, the diffusion with transformers, which is that if you take like a six, eight by eight patch of the image and you flatten that all out or you run that through some like convolutional thing to turn it into a one by one by some larger number of channels, but you can reduce the spatial dimension by increasing the number of channels. And that gets you down to like a manageable size where you can then start doing attention as well. So that's another trick is like patching where you take a patch of the image and you focus on that as some number, like some embedding dimension or whatever you like to think of it, but as a one by one rather than an eight by eight or a 16 by 16. And so that's how you'll see 32 by 32 patch models, like some of the smaller clip models or 14 by 14 patch for some of the larger like DIT classification models and things like that. So that's another trick. Yeah, I guess that's the, yeah, that's mainly used when you have like a full transformer network, I guess. And then this is one where we have that sort of incorporating the attention into a convolutional network. So there's certainly, I guess, yeah, for different sorts of networks, different tricks, but yeah. Yeah. And I haven't decided yet if we're going to look at VIT or not. Maybe we should, based on what you're describing. I was just going to mention though, that since you mentioned transformers, we've actually now got everything we need to create a transformer. Here's a transformer block with embeddings. And a transformer block with embeddings is exactly the same embeddings that we've seen before. And then we add attention as we've seen before. There's a scale and shift. And then we pass it through an MLP, which is just a linear layer, an activation, a normalize, and a linear layer. For whatever reason, this is, you know, Galue, which is just another activation function, is what people always use in transformers. For reasons I suspect don't quite make sense in vision, everybody uses layer norm. And again, I was just trying to replicate an existing paper, but this is just a standard MLP. So if you do, so in fact, if we get rid of the embeddings, just to show you a true pure transformer. Okay, here's a pure transformer block, right? So it's just normalize, attention, add, normalize, multilayer perceptron, add. That's all a transformer block is. And then what's a transformer network? A transformer network is a sequential of transformers. And so in this diffusion model, I replaced my mid block with a list of sequential transformer blocks. So that is a transformer network. And to prove it, I then replace, this is another version in which I replaced that entire thing with the PyTorch transformers encoder, which is just called encoder. This is just taken from PyTorch. And so that's the encoder. And I just replaced it with that. So yeah, we've now built transformers. Now, okay, why aren't we using them right now? And why did I just say I'm not even sure if we're going to do VIT, which is vision transformers? The reason is that transformers, you know, they're doing something very interesting, right? Which is, remember, we're just doing 1D versions here, right? So transformers are taking something where we've got a sequence, right? Which in our case is pixels height by width, but let's call it a sequence. And everything in that sequence has a bunch of channels, right? Or dimensions. I'm not going to draw them all, but you get the idea. And so for each element of that sequence, which in our case, it's just some particular pixel, right? And these are just the filters, channels, activations, whatever. Activations, I guess. What we're doing is we first do attention, which, you know, remember there's a projection for each. So it's mixing the channels a little bit. But just putting that aside. The main thing it's doing is each row is getting mixed together, you know, into a weighted average. And then after we do that, we put the whole thing through a multilayer perceptron. And what the multilayer perceptron does is it entirely looks at each pixel on its own. So let's say this one, right? And puts that through linear activation norm linear, which we call an MLP. And so a transformer network is a bunch of transformer layers. So it's basically going attention, MLP, attention, MLP, attention, etc, etc. MLP. That's all it's doing. And so in other words, it's mixing together the pixels or sequences, and then it's mixing together the channels. Then it's mixing together the sequences, and then mixing together the channels. And it's repeating this over and over. Because of the projections being done in the attention, it's not just mixing the pixels, but it's kind of, it's largely mixing the pixels. And so this combination is very, very, very flexible. And it's flexible enough that it provably can actually approximate any convolution that you can think of. Given enough layers and enough time and learning the right parameters. The problem is that for this to approximate a combination requires a lot of data, and a lot of layers, and a lot of parameters, and a lot of compute. So if you try to use this, so this is a transformer network, transformer architecture. If you pass images into this, so pass an image in, and try to predict, say from ImageNet, the class of the image. So use SGD to try and find weights for these attention projections and MLPs. If you do that on ImageNet, you will end up with something that does indeed predict the class of each image, but it does it poorly. Now it doesn't do it poorly because it's not capable of approximating a convolution. It does it poorly because ImageNet, the entire ImageNet, as in ImageNet 1k, is not big enough for a transformer to learn how to do this. However, if you pass it a much bigger dataset, many times larger than ImageNet 1k, then it will learn to approximate this very well. And in fact, it'll figure out a way of doing something like convolutions that are actually better than convolutions. And so if you then take that, so that's going to be called a vision transformer, or VIT, that's been pre-trained on a dataset much bigger than ImageNet, and then you fine-tune it on ImageNet, you will end up with something that is actually better than ResNet. And the reason it's better than ResNet is because these combinations, right, which together, when combined, can approximate a convolution, these transformers, you know, convolutions are our best guess as to like a good way to kind of represent the calculations we should do on images. There's actually much more sophisticated things you could do, you know, if you're a computer and you could figure these things out better than a human can. And so a VIT actually figures out things that are even better than convolutions. And so when you fine-tune ImageNet using a very, you know, a VIT that's been pre-trained on lots of data, then that's why it ends up being better than a ResNet. So that's why, you know, the things I'm showing you are not the things that contain transformers in diffusion, because to make that work would require pre-training on a really, really large dataset for a really, really long amount of time. So anyway, so we might only come to transformers, well, not in a very long time, but when we do them in NLP, in Vision, maybe we'll cover them briefly, you know, they're very interesting to use as pre-trained models. The main thing to know about them is, yeah, a VIT, you know, which is a really successful, when pre-trained on lots of data, which they all are nowadays, is a very successful architecture. But like literally the VIT paper says, oh, we wondered what would happen if we take a totally plain 1D transformer, you know, and convert it and use, convert, make it work on images with as few changes as possible. So everything we've learned about attention today and MLPs applies directly, because they haven't changed anything. And so one of the things you might realize that means is that you can't use a VIT that was trained on 224 by 224 pixel images on 128 by 128 pixel images, because, you know, all of these self-attention things are the wrong size, you know. And specifically, the problem is actually the, actually it's not really the attention, let me take that back. All of the position embeddings are the wrong size. And so actually that's something I, sorry, I forgot to mention, is that in transformers, the first thing you do is you always take your, you know, these pixels and you add to them a positional embedding. And that's done, I mean, it can be done lots of different ways, but the most popular way is identical to what we did for the time step embedding, it's a sinusoidal embedding. And so that's specific, you know, to how many, how many pixels there are in your image. So yeah, that's an example of one of the things that makes VITs a little tricky. Anyway, hopefully, yeah, you get the idea that we've got all the pieces that we need. Okay. So with that discussion, I think that's officially taken us over time. So maybe we should do the conditional next time. Do you know what, actually it's tiny. Let's just quickly do it now. You guys got time? Yeah. Okay. So let's just, yeah, let's finish by doing a conditional model. So for a conditional model, we're going to basically say, I want something where I can say, draw me a number, sorry, draw me a shirt, or draw me some pants, or draw me some sandals. So we're going to pick one of the 10 fashion MNIST classes, and, and create an, you know, create an image of a particular class. To do that, we need to know what class each thing is. Now we already know what class each thing is, because it's the Y label, which way back in the beginning of time, we set, okay, it's just called the label. So that tells you what category it is. So we're going to change our collation function. So we call noiseify as per usual, that gives us our noised image, our time step, and our noise. But we're also going to then add to that tuple, what kind of fashion item is this. And so the first tuple will be noised image, noise, and label, and then the dependent variable as per usual is the noise. And so what's going to happen now when we call our unet, which is now a conditioned unet model, is the input is now going to contain not just the activations and the time step, but it's also going to contain the label. Okay, that label will be a number between 0 and 9. So how do we convert the number between 0 and 9 into a vector, which represents that number? Well, we know exactly how to do that, in n.embedding. Okay, so we did that lots in part one. So let's make it exactly, you know, the same size as our time embedding. So n number of activations in the embedding. It's going to be the same as our time step embedding. And so that's convenient. So now in the forward, we do our time step embedding as usual. We'll pass the labels into our conditioned embedding. The time embedding we will put through the embedding layer p and before, and then we're just going to add them together. That's it, right? So this now represents a combination of the time and the fashion item class. And then everything else is identical in both parts. So all we've added is this one thing, and then we just literally sum it up. So we've now got a joint embedding representing two things. And then, yeah, and then we train it. And you know, interestingly, it looks like the loss, well, it ends up about the same, but it's, you know, you don't often see 0.031. You know, it is a bit easier for it to do a conditional embedding model, because you're telling it what it is. Just makes it a bit easier. So then to do conditional sampling, you have to pass in what type of thing do you want from these labels. And so then we create a vector just containing that number repeated, however many times there are in the batch. And we pass it to our model. So our model has now learned how to denoise something of type C. And so now if we say, like, oh, trust me, this noise contains, is a noised image of type C, it should hopefully denoise it into something of type C. That's all there is to it. There's no magic there. So yeah, that's all we have to do to change the sampling. So like we didn't have to change ddimstep at all, right? Literally all we did was we added this one line of code, and we added it there. So now we can say, okay, let's say class ID 0, which is t-shirt top. So we pass that to sample. And there we go. Everything looks like t-shirts and tops. Yeah, okay, I'm glad we didn't leave that till next time, because it's, we can now say we have successfully replicated everything in stable diffusion, except for being able to create whole sentences, which is what we do with Clip. Getting really close. Yes. Well, except that Clip requires like. All of NLP. So I guess we might do that next, or depending on how research goes. All right. We still need the latent diffusion part. Oh, good point. Latents. Okay, we'll definitely do that next time. So let's see. Yeah, so we'll do a VAE and latent diffusion. Which isn't enough for one lesson. So maybe some of the research I'm doing will end up in the next lesson as well. But yes. Okay, thanks for the reminder. Although we've already kind of done autoencoders, so VAEs are going to be pretty, pretty easy. Well thank you, Tanishka and Jono. Fantastic comments, as always. Glad your internet slash power reappeared, Jono. Back up. Yes. All right. Thanks, gang. Cool. Thanks, everybody. That was great.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.32, "text": " Hi, we are here for lesson 24, and once again it's becoming a bit of a tradition now.", "tokens": [50364, 2421, 11, 321, 366, 510, 337, 6898, 4022, 11, 293, 1564, 797, 309, 311, 5617, 257, 857, 295, 257, 6994, 586, 13, 50680], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 1, "seek": 0, "start": 6.32, "end": 9.56, "text": " We're joined by Jono and Tanishq, which is always a pleasure.", "tokens": [50680, 492, 434, 6869, 538, 7745, 78, 293, 314, 7524, 80, 11, 597, 307, 1009, 257, 6834, 13, 50842], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 2, "seek": 0, "start": 9.56, "end": 11.56, "text": " Hi Jono, hi Tanishq.", "tokens": [50842, 2421, 7745, 78, 11, 4879, 314, 7524, 80, 13, 50942], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 3, "seek": 0, "start": 11.56, "end": 12.56, "text": " Hello.", "tokens": [50942, 2425, 13, 50992], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 4, "seek": 0, "start": 12.56, "end": 13.56, "text": " Another great lesson.", "tokens": [50992, 3996, 869, 6898, 13, 51042], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 5, "seek": 0, "start": 13.56, "end": 19.96, "text": " Yeah, are you guys looking forward to finally actually completing stable diffusion, at least", "tokens": [51042, 865, 11, 366, 291, 1074, 1237, 2128, 281, 2721, 767, 19472, 8351, 25242, 11, 412, 1935, 51362], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 6, "seek": 0, "start": 19.96, "end": 21.56, "text": " the unconditional stable diffusion?", "tokens": [51362, 264, 47916, 8351, 25242, 30, 51442], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 7, "seek": 0, "start": 21.56, "end": 23.52, "text": " Well, I should say no, even conditional.", "tokens": [51442, 1042, 11, 286, 820, 584, 572, 11, 754, 27708, 13, 51540], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 8, "seek": 0, "start": 23.52, "end": 29.12, "text": " So conditional stable diffusion, except for the clip bit from scratch.", "tokens": [51540, 407, 27708, 8351, 25242, 11, 3993, 337, 264, 7353, 857, 490, 8459, 13, 51820], "temperature": 0.0, "avg_logprob": -0.3505812822762182, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.13547682762145996}, {"id": 9, "seek": 2912, "start": 29.12, "end": 31.36, "text": " We should be able to finish today, time permitting.", "tokens": [50364, 492, 820, 312, 1075, 281, 2413, 965, 11, 565, 4784, 2414, 13, 50476], "temperature": 0.0, "avg_logprob": -0.289734742580316, "compression_ratio": 1.3908045977011494, "no_speech_prob": 0.0020502330735325813}, {"id": 10, "seek": 2912, "start": 31.36, "end": 32.36, "text": " Oh, that's exciting.", "tokens": [50476, 876, 11, 300, 311, 4670, 13, 50526], "temperature": 0.0, "avg_logprob": -0.289734742580316, "compression_ratio": 1.3908045977011494, "no_speech_prob": 0.0020502330735325813}, {"id": 11, "seek": 2912, "start": 32.36, "end": 33.36, "text": " That is exciting.", "tokens": [50526, 663, 307, 4670, 13, 50576], "temperature": 0.0, "avg_logprob": -0.289734742580316, "compression_ratio": 1.3908045977011494, "no_speech_prob": 0.0020502330735325813}, {"id": 12, "seek": 2912, "start": 33.36, "end": 34.36, "text": " Yeah.", "tokens": [50576, 865, 13, 50626], "temperature": 0.0, "avg_logprob": -0.289734742580316, "compression_ratio": 1.3908045977011494, "no_speech_prob": 0.0020502330735325813}, {"id": 13, "seek": 2912, "start": 34.36, "end": 37.2, "text": " All right, let's do it.", "tokens": [50626, 1057, 558, 11, 718, 311, 360, 309, 13, 50768], "temperature": 0.0, "avg_logprob": -0.289734742580316, "compression_ratio": 1.3908045977011494, "no_speech_prob": 0.0020502330735325813}, {"id": 14, "seek": 2912, "start": 37.2, "end": 40.160000000000004, "text": " Jump in any time.", "tokens": [50768, 18697, 294, 604, 565, 13, 50916], "temperature": 0.0, "avg_logprob": -0.289734742580316, "compression_ratio": 1.3908045977011494, "no_speech_prob": 0.0020502330735325813}, {"id": 15, "seek": 2912, "start": 40.160000000000004, "end": 42.760000000000005, "text": " You've got things to talk about.", "tokens": [50916, 509, 600, 658, 721, 281, 751, 466, 13, 51046], "temperature": 0.0, "avg_logprob": -0.289734742580316, "compression_ratio": 1.3908045977011494, "no_speech_prob": 0.0020502330735325813}, {"id": 16, "seek": 2912, "start": 42.760000000000005, "end": 52.52, "text": " So we're going to start with a very hopefully named 26 diffusion unit.", "tokens": [51046, 407, 321, 434, 516, 281, 722, 365, 257, 588, 4696, 4926, 7551, 25242, 4985, 13, 51534], "temperature": 0.0, "avg_logprob": -0.289734742580316, "compression_ratio": 1.3908045977011494, "no_speech_prob": 0.0020502330735325813}, {"id": 17, "seek": 5252, "start": 52.720000000000006, "end": 64.52000000000001, "text": " What we're going to do in 26 diffusion unit is to do unconditional diffusion from scratch.", "tokens": [50374, 708, 321, 434, 516, 281, 360, 294, 7551, 25242, 4985, 307, 281, 360, 47916, 25242, 490, 8459, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2517474827013518, "compression_ratio": 1.49, "no_speech_prob": 0.0002868120209313929}, {"id": 18, "seek": 5252, "start": 64.52000000000001, "end": 68.92, "text": " And there's not really too many new pieces, if I remember correctly.", "tokens": [50964, 400, 456, 311, 406, 534, 886, 867, 777, 3755, 11, 498, 286, 1604, 8944, 13, 51184], "temperature": 0.0, "avg_logprob": -0.2517474827013518, "compression_ratio": 1.49, "no_speech_prob": 0.0002868120209313929}, {"id": 19, "seek": 5252, "start": 68.92, "end": 74.96000000000001, "text": " So all the stuff at the start, we've already seen.", "tokens": [51184, 407, 439, 264, 1507, 412, 264, 722, 11, 321, 600, 1217, 1612, 13, 51486], "temperature": 0.0, "avg_logprob": -0.2517474827013518, "compression_ratio": 1.49, "no_speech_prob": 0.0002868120209313929}, {"id": 20, "seek": 5252, "start": 74.96000000000001, "end": 79.72, "text": " And so when I wrote this, it was before I had noticed that the Keras approach was doing", "tokens": [51486, 400, 370, 562, 286, 4114, 341, 11, 309, 390, 949, 286, 632, 5694, 300, 264, 591, 6985, 3109, 390, 884, 51724], "temperature": 0.0, "avg_logprob": -0.2517474827013518, "compression_ratio": 1.49, "no_speech_prob": 0.0002868120209313929}, {"id": 21, "seek": 7972, "start": 79.72, "end": 82.48, "text": " less well than the regular cosine schedule approach.", "tokens": [50364, 1570, 731, 813, 264, 3890, 23565, 7567, 3109, 13, 50502], "temperature": 0.0, "avg_logprob": -0.32663173951964447, "compression_ratio": 1.4022988505747127, "no_speech_prob": 1.2029581739625428e-05}, {"id": 22, "seek": 7972, "start": 82.48, "end": 84.44, "text": " So I'm still using Keras noiseifier.", "tokens": [50502, 407, 286, 478, 920, 1228, 591, 6985, 5658, 9902, 13, 50600], "temperature": 0.0, "avg_logprob": -0.32663173951964447, "compression_ratio": 1.4022988505747127, "no_speech_prob": 1.2029581739625428e-05}, {"id": 23, "seek": 7972, "start": 84.44, "end": 90.96, "text": " But this is all the same as from the Keras notebook, which was 23.", "tokens": [50600, 583, 341, 307, 439, 264, 912, 382, 490, 264, 591, 6985, 21060, 11, 597, 390, 6673, 13, 50926], "temperature": 0.0, "avg_logprob": -0.32663173951964447, "compression_ratio": 1.4022988505747127, "no_speech_prob": 1.2029581739625428e-05}, {"id": 24, "seek": 7972, "start": 90.96, "end": 106.24, "text": " Okay, so we can now create a unit that is based on what diffusers has, which is in turn", "tokens": [50926, 1033, 11, 370, 321, 393, 586, 1884, 257, 4985, 300, 307, 2361, 322, 437, 7593, 301, 433, 575, 11, 597, 307, 294, 1261, 51690], "temperature": 0.0, "avg_logprob": -0.32663173951964447, "compression_ratio": 1.4022988505747127, "no_speech_prob": 1.2029581739625428e-05}, {"id": 25, "seek": 10624, "start": 106.24, "end": 109.44, "text": " based on lots of other prior art.", "tokens": [50364, 2361, 322, 3195, 295, 661, 4059, 1523, 13, 50524], "temperature": 0.0, "avg_logprob": -0.28066110610961914, "compression_ratio": 1.6581632653061225, "no_speech_prob": 0.0010649269679561257}, {"id": 26, "seek": 10624, "start": 109.44, "end": 113.83999999999999, "text": " I mean, the code's not at all based on it, but the basic, the structure is going to be", "tokens": [50524, 286, 914, 11, 264, 3089, 311, 406, 412, 439, 2361, 322, 309, 11, 457, 264, 3875, 11, 264, 3877, 307, 516, 281, 312, 50744], "temperature": 0.0, "avg_logprob": -0.28066110610961914, "compression_ratio": 1.6581632653061225, "no_speech_prob": 0.0010649269679561257}, {"id": 27, "seek": 10624, "start": 113.83999999999999, "end": 119.56, "text": " the same as what you'll get in diffusers.", "tokens": [50744, 264, 912, 382, 437, 291, 603, 483, 294, 7593, 301, 433, 13, 51030], "temperature": 0.0, "avg_logprob": -0.28066110610961914, "compression_ratio": 1.6581632653061225, "no_speech_prob": 0.0010649269679561257}, {"id": 28, "seek": 10624, "start": 119.56, "end": 125.44, "text": " The convolution we're going to use is the same as the final kind of convolution we used", "tokens": [51030, 440, 45216, 321, 434, 516, 281, 764, 307, 264, 912, 382, 264, 2572, 733, 295, 45216, 321, 1143, 51324], "temperature": 0.0, "avg_logprob": -0.28066110610961914, "compression_ratio": 1.6581632653061225, "no_speech_prob": 0.0010649269679561257}, {"id": 29, "seek": 10624, "start": 125.44, "end": 130.12, "text": " for tiny image net, which is what's called the pre activation convolution.", "tokens": [51324, 337, 5870, 3256, 2533, 11, 597, 307, 437, 311, 1219, 264, 659, 24433, 45216, 13, 51558], "temperature": 0.0, "avg_logprob": -0.28066110610961914, "compression_ratio": 1.6581632653061225, "no_speech_prob": 0.0010649269679561257}, {"id": 30, "seek": 13012, "start": 130.12, "end": 136.08, "text": " So the convolution itself happens at the end, and the normalization and activation", "tokens": [50364, 407, 264, 45216, 2564, 2314, 412, 264, 917, 11, 293, 264, 2710, 2144, 293, 24433, 50662], "temperature": 0.0, "avg_logprob": -0.236587669538415, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0004802912881132215}, {"id": 31, "seek": 13012, "start": 136.08, "end": 138.04, "text": " happen first.", "tokens": [50662, 1051, 700, 13, 50760], "temperature": 0.0, "avg_logprob": -0.236587669538415, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0004802912881132215}, {"id": 32, "seek": 13012, "start": 138.04, "end": 143.76, "text": " So this is a pre act convolution.", "tokens": [50760, 407, 341, 307, 257, 659, 605, 45216, 13, 51046], "temperature": 0.0, "avg_logprob": -0.236587669538415, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0004802912881132215}, {"id": 33, "seek": 13012, "start": 143.76, "end": 148.70000000000002, "text": " So then I've got a unit res net block.", "tokens": [51046, 407, 550, 286, 600, 658, 257, 4985, 725, 2533, 3461, 13, 51293], "temperature": 0.0, "avg_logprob": -0.236587669538415, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0004802912881132215}, {"id": 34, "seek": 13012, "start": 148.70000000000002, "end": 154.08, "text": " So I kind of wrote this before I actually did the react version of tiny image net.", "tokens": [51293, 407, 286, 733, 295, 4114, 341, 949, 286, 767, 630, 264, 4515, 3037, 295, 5870, 3256, 2533, 13, 51562], "temperature": 0.0, "avg_logprob": -0.236587669538415, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0004802912881132215}, {"id": 35, "seek": 13012, "start": 154.08, "end": 158.36, "text": " So I suspect this is actually the same, quite possibly exactly the same as the tiny image", "tokens": [51562, 407, 286, 9091, 341, 307, 767, 264, 912, 11, 1596, 6264, 2293, 264, 912, 382, 264, 5870, 3256, 51776], "temperature": 0.0, "avg_logprob": -0.236587669538415, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0004802912881132215}, {"id": 36, "seek": 13012, "start": 158.36, "end": 159.36, "text": " net one.", "tokens": [51776, 2533, 472, 13, 51826], "temperature": 0.0, "avg_logprob": -0.236587669538415, "compression_ratio": 1.7462686567164178, "no_speech_prob": 0.0004802912881132215}, {"id": 37, "seek": 15936, "start": 159.60000000000002, "end": 161.84, "text": " This is nothing specific about this for unit.", "tokens": [50376, 639, 307, 1825, 2685, 466, 341, 337, 4985, 13, 50488], "temperature": 0.0, "avg_logprob": -0.27090381823087994, "compression_ratio": 1.6859903381642511, "no_speech_prob": 7.183258730947273e-06}, {"id": 38, "seek": 15936, "start": 161.84, "end": 166.20000000000002, "text": " This is just really a pre act conv and a pre act res net block.", "tokens": [50488, 639, 307, 445, 534, 257, 659, 605, 3754, 293, 257, 659, 605, 725, 2533, 3461, 13, 50706], "temperature": 0.0, "avg_logprob": -0.27090381823087994, "compression_ratio": 1.6859903381642511, "no_speech_prob": 7.183258730947273e-06}, {"id": 39, "seek": 15936, "start": 166.20000000000002, "end": 173.56, "text": " So we've got the two comms as per usual, and the identity conv.", "tokens": [50706, 407, 321, 600, 658, 264, 732, 800, 82, 382, 680, 7713, 11, 293, 264, 6575, 3754, 13, 51074], "temperature": 0.0, "avg_logprob": -0.27090381823087994, "compression_ratio": 1.6859903381642511, "no_speech_prob": 7.183258730947273e-06}, {"id": 40, "seek": 15936, "start": 173.56, "end": 178.88000000000002, "text": " Now there is one difference though, to what we've seen before for res net blocks, which", "tokens": [51074, 823, 456, 307, 472, 2649, 1673, 11, 281, 437, 321, 600, 1612, 949, 337, 725, 2533, 8474, 11, 597, 51340], "temperature": 0.0, "avg_logprob": -0.27090381823087994, "compression_ratio": 1.6859903381642511, "no_speech_prob": 7.183258730947273e-06}, {"id": 41, "seek": 15936, "start": 178.88000000000002, "end": 188.76000000000002, "text": " is that this res net block has no option to do down sampling, no option to do a stride.", "tokens": [51340, 307, 300, 341, 725, 2533, 3461, 575, 572, 3614, 281, 360, 760, 21179, 11, 572, 3614, 281, 360, 257, 1056, 482, 13, 51834], "temperature": 0.0, "avg_logprob": -0.27090381823087994, "compression_ratio": 1.6859903381642511, "no_speech_prob": 7.183258730947273e-06}, {"id": 42, "seek": 18876, "start": 189.16, "end": 192.79999999999998, "text": " This is always stride one, which is our default.", "tokens": [50384, 639, 307, 1009, 1056, 482, 472, 11, 597, 307, 527, 7576, 13, 50566], "temperature": 0.0, "avg_logprob": -0.27102615616538306, "compression_ratio": 1.6927083333333333, "no_speech_prob": 1.9525878087733872e-05}, {"id": 43, "seek": 18876, "start": 192.79999999999998, "end": 198.88, "text": " So the reason for that is that when we get to the thing that strings a bunch of them", "tokens": [50566, 407, 264, 1778, 337, 300, 307, 300, 562, 321, 483, 281, 264, 551, 300, 13985, 257, 3840, 295, 552, 50870], "temperature": 0.0, "avg_logprob": -0.27102615616538306, "compression_ratio": 1.6927083333333333, "no_speech_prob": 1.9525878087733872e-05}, {"id": 44, "seek": 18876, "start": 198.88, "end": 204.84, "text": " together, which will be called down block, this is where you have the option to add down", "tokens": [50870, 1214, 11, 597, 486, 312, 1219, 760, 3461, 11, 341, 307, 689, 291, 362, 264, 3614, 281, 909, 760, 51168], "temperature": 0.0, "avg_logprob": -0.27102615616538306, "compression_ratio": 1.6927083333333333, "no_speech_prob": 1.9525878087733872e-05}, {"id": 45, "seek": 18876, "start": 204.84, "end": 206.07999999999998, "text": " sampling.", "tokens": [51168, 21179, 13, 51230], "temperature": 0.0, "avg_logprob": -0.27102615616538306, "compression_ratio": 1.6927083333333333, "no_speech_prob": 1.9525878087733872e-05}, {"id": 46, "seek": 18876, "start": 206.07999999999998, "end": 211.07999999999998, "text": " If you do add down sampling, we're going to add a stride to convolution after the res", "tokens": [51230, 759, 291, 360, 909, 760, 21179, 11, 321, 434, 516, 281, 909, 257, 1056, 482, 281, 45216, 934, 264, 725, 51480], "temperature": 0.0, "avg_logprob": -0.27102615616538306, "compression_ratio": 1.6927083333333333, "no_speech_prob": 1.9525878087733872e-05}, {"id": 47, "seek": 18876, "start": 211.07999999999998, "end": 212.39999999999998, "text": " block.", "tokens": [51480, 3461, 13, 51546], "temperature": 0.0, "avg_logprob": -0.27102615616538306, "compression_ratio": 1.6927083333333333, "no_speech_prob": 1.9525878087733872e-05}, {"id": 48, "seek": 21240, "start": 212.68, "end": 220.16, "text": " That's because this is how diffusers and stable diffusion does it.", "tokens": [50378, 663, 311, 570, 341, 307, 577, 7593, 301, 433, 293, 8351, 25242, 775, 309, 13, 50752], "temperature": 0.0, "avg_logprob": -0.3980207814798727, "compression_ratio": 1.5053191489361701, "no_speech_prob": 0.0006563145434483886}, {"id": 49, "seek": 21240, "start": 220.16, "end": 221.88, "text": " I haven't studied this closely.", "tokens": [50752, 286, 2378, 380, 9454, 341, 8185, 13, 50838], "temperature": 0.0, "avg_logprob": -0.3980207814798727, "compression_ratio": 1.5053191489361701, "no_speech_prob": 0.0006563145434483886}, {"id": 50, "seek": 21240, "start": 221.88, "end": 227.72, "text": " Tanishka, or Donna, if either of you have, know where this idea came from or why.", "tokens": [50838, 314, 7524, 2330, 11, 420, 31938, 11, 498, 2139, 295, 291, 362, 11, 458, 689, 341, 1558, 1361, 490, 420, 983, 13, 51130], "temperature": 0.0, "avg_logprob": -0.3980207814798727, "compression_ratio": 1.5053191489361701, "no_speech_prob": 0.0006563145434483886}, {"id": 51, "seek": 21240, "start": 227.72, "end": 229.48000000000002, "text": " I'd be curious.", "tokens": [51130, 286, 1116, 312, 6369, 13, 51218], "temperature": 0.0, "avg_logprob": -0.3980207814798727, "compression_ratio": 1.5053191489361701, "no_speech_prob": 0.0006563145434483886}, {"id": 52, "seek": 21240, "start": 229.48000000000002, "end": 239.4, "text": " The difference is that normally we would have average pooling here in this connection.", "tokens": [51218, 440, 2649, 307, 300, 5646, 321, 576, 362, 4274, 7005, 278, 510, 294, 341, 4984, 13, 51714], "temperature": 0.0, "avg_logprob": -0.3980207814798727, "compression_ratio": 1.5053191489361701, "no_speech_prob": 0.0006563145434483886}, {"id": 53, "seek": 23940, "start": 239.4, "end": 244.56, "text": " But yeah, this different approach is what we're using.", "tokens": [50364, 583, 1338, 11, 341, 819, 3109, 307, 437, 321, 434, 1228, 13, 50622], "temperature": 0.0, "avg_logprob": -0.3499921162923177, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.16878929734230042}, {"id": 54, "seek": 23940, "start": 244.56, "end": 252.6, "text": " A lot of the history of the diffusers unconditional unit is to be compatible with the DDPM weights", "tokens": [50622, 316, 688, 295, 264, 2503, 295, 264, 7593, 301, 433, 47916, 4985, 307, 281, 312, 18218, 365, 264, 413, 11373, 44, 17443, 51024], "temperature": 0.0, "avg_logprob": -0.3499921162923177, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.16878929734230042}, {"id": 55, "seek": 23940, "start": 252.6, "end": 255.6, "text": " that were released, and some follow on work from that.", "tokens": [51024, 300, 645, 4736, 11, 293, 512, 1524, 322, 589, 490, 300, 13, 51174], "temperature": 0.0, "avg_logprob": -0.3499921162923177, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.16878929734230042}, {"id": 56, "seek": 23940, "start": 255.6, "end": 260.04, "text": " And I know like then improved DDPM and these others, they all kind of built on that same", "tokens": [51174, 400, 286, 458, 411, 550, 9689, 413, 11373, 44, 293, 613, 2357, 11, 436, 439, 733, 295, 3094, 322, 300, 912, 51396], "temperature": 0.0, "avg_logprob": -0.3499921162923177, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.16878929734230042}, {"id": 57, "seek": 23940, "start": 260.04, "end": 263.88, "text": " sort of unit structure, even though it's slightly unconventional if you're coming from like", "tokens": [51396, 1333, 295, 4985, 3877, 11, 754, 1673, 309, 311, 4748, 35847, 46105, 498, 291, 434, 1348, 490, 411, 51588], "temperature": 0.0, "avg_logprob": -0.3499921162923177, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.16878929734230042}, {"id": 58, "seek": 23940, "start": 263.88, "end": 267.48, "text": " a normal computer vision background.", "tokens": [51588, 257, 2710, 3820, 5201, 3678, 13, 51768], "temperature": 0.0, "avg_logprob": -0.3499921162923177, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.16878929734230042}, {"id": 59, "seek": 26748, "start": 267.56, "end": 270.68, "text": " Do you recall where the DDPM architecture came from?", "tokens": [50368, 1144, 291, 9901, 689, 264, 413, 11373, 44, 9482, 1361, 490, 30, 50524], "temperature": 0.0, "avg_logprob": -0.3888998031616211, "compression_ratio": 1.6047430830039526, "no_speech_prob": 0.017703015357255936}, {"id": 60, "seek": 26748, "start": 270.68, "end": 277.88, "text": " Because like some of the ideas came from some of the GAN units, but I don't know if DDPM.", "tokens": [50524, 1436, 411, 512, 295, 264, 3487, 1361, 490, 512, 295, 264, 460, 1770, 6815, 11, 457, 286, 500, 380, 458, 498, 413, 11373, 44, 13, 50884], "temperature": 0.0, "avg_logprob": -0.3888998031616211, "compression_ratio": 1.6047430830039526, "no_speech_prob": 0.017703015357255936}, {"id": 61, "seek": 26748, "start": 277.88, "end": 282.84000000000003, "text": " Yeah, they had something called efficient unit that was inspired by some prior work", "tokens": [50884, 865, 11, 436, 632, 746, 1219, 7148, 4985, 300, 390, 7547, 538, 512, 4059, 589, 51132], "temperature": 0.0, "avg_logprob": -0.3888998031616211, "compression_ratio": 1.6047430830039526, "no_speech_prob": 0.017703015357255936}, {"id": 62, "seek": 26748, "start": 282.84000000000003, "end": 285.48, "text": " that I can't remember the lineage.", "tokens": [51132, 300, 286, 393, 380, 1604, 264, 38257, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3888998031616211, "compression_ratio": 1.6047430830039526, "no_speech_prob": 0.017703015357255936}, {"id": 63, "seek": 26748, "start": 285.48, "end": 291.72, "text": " But anyway, yeah, it just means that the diffusers one has since become, you know, like you can", "tokens": [51264, 583, 4033, 11, 1338, 11, 309, 445, 1355, 300, 264, 7593, 301, 433, 472, 575, 1670, 1813, 11, 291, 458, 11, 411, 291, 393, 51576], "temperature": 0.0, "avg_logprob": -0.3888998031616211, "compression_ratio": 1.6047430830039526, "no_speech_prob": 0.017703015357255936}, {"id": 64, "seek": 26748, "start": 291.72, "end": 294.36, "text": " add in parameters to control some of this stuff.", "tokens": [51576, 909, 294, 9834, 281, 1969, 512, 295, 341, 1507, 13, 51708], "temperature": 0.0, "avg_logprob": -0.3888998031616211, "compression_ratio": 1.6047430830039526, "no_speech_prob": 0.017703015357255936}, {"id": 65, "seek": 29436, "start": 294.36, "end": 296.28000000000003, "text": " But yeah, it's...", "tokens": [50364, 583, 1338, 11, 309, 311, 485, 50460], "temperature": 0.0, "avg_logprob": -0.26792963403854925, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.034083422273397446}, {"id": 66, "seek": 29436, "start": 296.28000000000003, "end": 299.64, "text": " We shouldn't assume that this is the optimal approach, I suppose.", "tokens": [50460, 492, 4659, 380, 6552, 300, 341, 307, 264, 16252, 3109, 11, 286, 7297, 13, 50628], "temperature": 0.0, "avg_logprob": -0.26792963403854925, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.034083422273397446}, {"id": 67, "seek": 29436, "start": 299.64, "end": 304.88, "text": " But yeah, I will dig into the history and try and find out how much like what ablation", "tokens": [50628, 583, 1338, 11, 286, 486, 2528, 666, 264, 2503, 293, 853, 293, 915, 484, 577, 709, 411, 437, 410, 24278, 50890], "temperature": 0.0, "avg_logprob": -0.26792963403854925, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.034083422273397446}, {"id": 68, "seek": 29436, "start": 304.88, "end": 305.88, "text": " studies have been done.", "tokens": [50890, 5313, 362, 668, 1096, 13, 50940], "temperature": 0.0, "avg_logprob": -0.26792963403854925, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.034083422273397446}, {"id": 69, "seek": 29436, "start": 305.88, "end": 309.68, "text": " So for those of you who haven't heard of ablation studies, that's where you like try, you know,", "tokens": [50940, 407, 337, 729, 295, 291, 567, 2378, 380, 2198, 295, 410, 24278, 5313, 11, 300, 311, 689, 291, 411, 853, 11, 291, 458, 11, 51130], "temperature": 0.0, "avg_logprob": -0.26792963403854925, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.034083422273397446}, {"id": 70, "seek": 29436, "start": 309.68, "end": 313.92, "text": " a bunch of different ways of doing things and score which one works better and which", "tokens": [51130, 257, 3840, 295, 819, 2098, 295, 884, 721, 293, 6175, 597, 472, 1985, 1101, 293, 597, 51342], "temperature": 0.0, "avg_logprob": -0.26792963403854925, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.034083422273397446}, {"id": 71, "seek": 29436, "start": 313.92, "end": 319.04, "text": " one works less well and kind of create a table of all of those options.", "tokens": [51342, 472, 1985, 1570, 731, 293, 733, 295, 1884, 257, 3199, 295, 439, 295, 729, 3956, 13, 51598], "temperature": 0.0, "avg_logprob": -0.26792963403854925, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.034083422273397446}, {"id": 72, "seek": 29436, "start": 319.04, "end": 324.04, "text": " And so where you can't find ablation studies for something you're interested in, often", "tokens": [51598, 400, 370, 689, 291, 393, 380, 915, 410, 24278, 5313, 337, 746, 291, 434, 3102, 294, 11, 2049, 51848], "temperature": 0.0, "avg_logprob": -0.26792963403854925, "compression_ratio": 1.797979797979798, "no_speech_prob": 0.034083422273397446}, {"id": 73, "seek": 32404, "start": 324.72, "end": 328.56, "text": " that means that, you know, maybe not many other options were tried, because researchers", "tokens": [50398, 300, 1355, 300, 11, 291, 458, 11, 1310, 406, 867, 661, 3956, 645, 3031, 11, 570, 10309, 50590], "temperature": 0.0, "avg_logprob": -0.33096244118430396, "compression_ratio": 1.496969696969697, "no_speech_prob": 4.264737799530849e-05}, {"id": 74, "seek": 32404, "start": 328.56, "end": 331.28000000000003, "text": " don't have time to try everything.", "tokens": [50590, 500, 380, 362, 565, 281, 853, 1203, 13, 50726], "temperature": 0.0, "avg_logprob": -0.33096244118430396, "compression_ratio": 1.496969696969697, "no_speech_prob": 4.264737799530849e-05}, {"id": 75, "seek": 32404, "start": 331.28000000000003, "end": 341.56, "text": " Okay, now, the unit, if we go back to the unit that we used for super resolution, we", "tokens": [50726, 1033, 11, 586, 11, 264, 4985, 11, 498, 321, 352, 646, 281, 264, 4985, 300, 321, 1143, 337, 1687, 8669, 11, 321, 51240], "temperature": 0.0, "avg_logprob": -0.33096244118430396, "compression_ratio": 1.496969696969697, "no_speech_prob": 4.264737799530849e-05}, {"id": 76, "seek": 32404, "start": 341.56, "end": 348.08000000000004, "text": " just go back to our most basic version.", "tokens": [51240, 445, 352, 646, 281, 527, 881, 3875, 3037, 13, 51566], "temperature": 0.0, "avg_logprob": -0.33096244118430396, "compression_ratio": 1.496969696969697, "no_speech_prob": 4.264737799530849e-05}, {"id": 77, "seek": 34808, "start": 348.08, "end": 358.71999999999997, "text": " What we did, as we went down through the layers in the downsampling section, we stored", "tokens": [50364, 708, 321, 630, 11, 382, 321, 1437, 760, 807, 264, 7914, 294, 264, 760, 19988, 11970, 3541, 11, 321, 12187, 50896], "temperature": 0.0, "avg_logprob": -0.2133646287779877, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.0010986669221892953}, {"id": 78, "seek": 34808, "start": 358.71999999999997, "end": 366.64, "text": " the activations at each point into a list called layers.", "tokens": [50896, 264, 2430, 763, 412, 1184, 935, 666, 257, 1329, 1219, 7914, 13, 51292], "temperature": 0.0, "avg_logprob": -0.2133646287779877, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.0010986669221892953}, {"id": 79, "seek": 34808, "start": 366.64, "end": 373.12, "text": " And then as we went through the upsampling, we added those downsampling layers back into", "tokens": [51292, 400, 550, 382, 321, 1437, 807, 264, 15497, 335, 11970, 11, 321, 3869, 729, 760, 19988, 11970, 7914, 646, 666, 51616], "temperature": 0.0, "avg_logprob": -0.2133646287779877, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.0010986669221892953}, {"id": 80, "seek": 34808, "start": 373.12, "end": 376.68, "text": " the upsampling activations.", "tokens": [51616, 264, 15497, 335, 11970, 2430, 763, 13, 51794], "temperature": 0.0, "avg_logprob": -0.2133646287779877, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.0010986669221892953}, {"id": 81, "seek": 37668, "start": 376.68, "end": 380.16, "text": " So that's the kind of basic structure of a unit.", "tokens": [50364, 407, 300, 311, 264, 733, 295, 3875, 3877, 295, 257, 4985, 13, 50538], "temperature": 0.0, "avg_logprob": -0.2491130974456554, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0012065368937328458}, {"id": 82, "seek": 37668, "start": 380.16, "end": 386.96, "text": " You don't have to add, you can also concatenate, and actually concatenating is what is, I think", "tokens": [50538, 509, 500, 380, 362, 281, 909, 11, 291, 393, 611, 1588, 7186, 473, 11, 293, 767, 1588, 7186, 990, 307, 437, 307, 11, 286, 519, 50878], "temperature": 0.0, "avg_logprob": -0.2491130974456554, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0012065368937328458}, {"id": 83, "seek": 37668, "start": 386.96, "end": 391.76, "text": " it's more common nowadays, and I think the original unit might have been concatenating,", "tokens": [50878, 309, 311, 544, 2689, 13434, 11, 293, 286, 519, 264, 3380, 4985, 1062, 362, 668, 1588, 7186, 990, 11, 51118], "temperature": 0.0, "avg_logprob": -0.2491130974456554, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0012065368937328458}, {"id": 84, "seek": 37668, "start": 391.76, "end": 396.48, "text": " although for super resolution, just adding seems pretty sensible.", "tokens": [51118, 4878, 337, 1687, 8669, 11, 445, 5127, 2544, 1238, 25380, 13, 51354], "temperature": 0.0, "avg_logprob": -0.2491130974456554, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0012065368937328458}, {"id": 85, "seek": 37668, "start": 396.48, "end": 397.92, "text": " So we're going to concatenate.", "tokens": [51354, 407, 321, 434, 516, 281, 1588, 7186, 473, 13, 51426], "temperature": 0.0, "avg_logprob": -0.2491130974456554, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0012065368937328458}, {"id": 86, "seek": 37668, "start": 397.92, "end": 401.9, "text": " But what we're going to do is we're going to try to, we're going to kind of exercise", "tokens": [51426, 583, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 853, 281, 11, 321, 434, 516, 281, 733, 295, 5380, 51625], "temperature": 0.0, "avg_logprob": -0.2491130974456554, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0012065368937328458}, {"id": 87, "seek": 37668, "start": 401.9, "end": 405.36, "text": " our Python muscles a little bit to try to see interesting ways to make some of this", "tokens": [51625, 527, 15329, 9530, 257, 707, 857, 281, 853, 281, 536, 1880, 2098, 281, 652, 512, 295, 341, 51798], "temperature": 0.0, "avg_logprob": -0.2491130974456554, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0012065368937328458}, {"id": 88, "seek": 40536, "start": 405.52000000000004, "end": 414.40000000000003, "text": " a little easier to turn different downsampling backbones into units.", "tokens": [50372, 257, 707, 3571, 281, 1261, 819, 760, 19988, 11970, 646, 44954, 666, 6815, 13, 50816], "temperature": 0.0, "avg_logprob": -0.2753867506980896, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.000636186043266207}, {"id": 89, "seek": 40536, "start": 414.40000000000003, "end": 418.2, "text": " And you also use that as an opportunity to learn a bit more Python.", "tokens": [50816, 400, 291, 611, 764, 300, 382, 364, 2650, 281, 1466, 257, 857, 544, 15329, 13, 51006], "temperature": 0.0, "avg_logprob": -0.2753867506980896, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.000636186043266207}, {"id": 90, "seek": 40536, "start": 418.2, "end": 427.16, "text": " So what we're going to do is we're going to create something called a saved res block,", "tokens": [51006, 407, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 1884, 746, 1219, 257, 6624, 725, 3461, 11, 51454], "temperature": 0.0, "avg_logprob": -0.2753867506980896, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.000636186043266207}, {"id": 91, "seek": 40536, "start": 427.16, "end": 429.12, "text": " and a saved convolution.", "tokens": [51454, 293, 257, 6624, 45216, 13, 51552], "temperature": 0.0, "avg_logprob": -0.2753867506980896, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.000636186043266207}, {"id": 92, "seek": 42912, "start": 429.12, "end": 433.68, "text": " And so our down, our down blocks, so these are our res blocks containing a certain number", "tokens": [50364, 400, 370, 527, 760, 11, 527, 760, 8474, 11, 370, 613, 366, 527, 725, 8474, 19273, 257, 1629, 1230, 50592], "temperature": 0.0, "avg_logprob": -0.2968695988164884, "compression_ratio": 1.9423076923076923, "no_speech_prob": 0.0037071527913212776}, {"id": 93, "seek": 42912, "start": 433.68, "end": 439.56, "text": " of res block layers, followed by this optional stride to conv.", "tokens": [50592, 295, 725, 3461, 7914, 11, 6263, 538, 341, 17312, 1056, 482, 281, 3754, 13, 50886], "temperature": 0.0, "avg_logprob": -0.2968695988164884, "compression_ratio": 1.9423076923076923, "no_speech_prob": 0.0037071527913212776}, {"id": 94, "seek": 42912, "start": 439.56, "end": 442.4, "text": " We're going to use saved res blocks and saved convs.", "tokens": [50886, 492, 434, 516, 281, 764, 6624, 725, 8474, 293, 6624, 3754, 82, 13, 51028], "temperature": 0.0, "avg_logprob": -0.2968695988164884, "compression_ratio": 1.9423076923076923, "no_speech_prob": 0.0037071527913212776}, {"id": 95, "seek": 42912, "start": 442.4, "end": 445.68, "text": " And what these are going to do, it's going to be the same as a normal convolution, and", "tokens": [51028, 400, 437, 613, 366, 516, 281, 360, 11, 309, 311, 516, 281, 312, 264, 912, 382, 257, 2710, 45216, 11, 293, 51192], "temperature": 0.0, "avg_logprob": -0.2968695988164884, "compression_ratio": 1.9423076923076923, "no_speech_prob": 0.0037071527913212776}, {"id": 96, "seek": 42912, "start": 445.68, "end": 451.04, "text": " the same as a normal res block, same as a normal unit res block.", "tokens": [51192, 264, 912, 382, 257, 2710, 725, 3461, 11, 912, 382, 257, 2710, 4985, 725, 3461, 13, 51460], "temperature": 0.0, "avg_logprob": -0.2968695988164884, "compression_ratio": 1.9423076923076923, "no_speech_prob": 0.0037071527913212776}, {"id": 97, "seek": 42912, "start": 451.04, "end": 455.2, "text": " But they're going to remember the activations.", "tokens": [51460, 583, 436, 434, 516, 281, 1604, 264, 2430, 763, 13, 51668], "temperature": 0.0, "avg_logprob": -0.2968695988164884, "compression_ratio": 1.9423076923076923, "no_speech_prob": 0.0037071527913212776}, {"id": 98, "seek": 45520, "start": 455.2, "end": 461.28, "text": " And the reason for that is that later on in the unit, we're going to go through and", "tokens": [50364, 400, 264, 1778, 337, 300, 307, 300, 1780, 322, 294, 264, 4985, 11, 321, 434, 516, 281, 352, 807, 293, 50668], "temperature": 0.0, "avg_logprob": -0.21188130249848236, "compression_ratio": 1.497175141242938, "no_speech_prob": 4.539735891739838e-05}, {"id": 99, "seek": 45520, "start": 461.28, "end": 467.0, "text": " grab those saved activations all at once into a big list.", "tokens": [50668, 4444, 729, 6624, 2430, 763, 439, 412, 1564, 666, 257, 955, 1329, 13, 50954], "temperature": 0.0, "avg_logprob": -0.21188130249848236, "compression_ratio": 1.497175141242938, "no_speech_prob": 4.539735891739838e-05}, {"id": 100, "seek": 45520, "start": 467.0, "end": 473.48, "text": " So then yeah, we basically don't have to kind of think about it.", "tokens": [50954, 407, 550, 1338, 11, 321, 1936, 500, 380, 362, 281, 733, 295, 519, 466, 309, 13, 51278], "temperature": 0.0, "avg_logprob": -0.21188130249848236, "compression_ratio": 1.497175141242938, "no_speech_prob": 4.539735891739838e-05}, {"id": 101, "seek": 45520, "start": 473.48, "end": 477.9, "text": " And so to do that, we create a class called a save module.", "tokens": [51278, 400, 370, 281, 360, 300, 11, 321, 1884, 257, 1508, 1219, 257, 3155, 10088, 13, 51499], "temperature": 0.0, "avg_logprob": -0.21188130249848236, "compression_ratio": 1.497175141242938, "no_speech_prob": 4.539735891739838e-05}, {"id": 102, "seek": 47790, "start": 477.9, "end": 488.78, "text": " And all save module does is it calls forward to grab the res block or conv results, and", "tokens": [50364, 400, 439, 3155, 10088, 775, 307, 309, 5498, 2128, 281, 4444, 264, 725, 3461, 420, 3754, 3542, 11, 293, 50908], "temperature": 0.0, "avg_logprob": -0.29104559349291254, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.00012148063979111612}, {"id": 103, "seek": 47790, "start": 488.78, "end": 492.85999999999996, "text": " stores that before returning it.", "tokens": [50908, 9512, 300, 949, 12678, 309, 13, 51112], "temperature": 0.0, "avg_logprob": -0.29104559349291254, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.00012148063979111612}, {"id": 104, "seek": 47790, "start": 492.85999999999996, "end": 500.5, "text": " Now that's weird, because hopefully you know by now that super calls the thing in the parent", "tokens": [51112, 823, 300, 311, 3657, 11, 570, 4696, 291, 458, 538, 586, 300, 1687, 5498, 264, 551, 294, 264, 2596, 51494], "temperature": 0.0, "avg_logprob": -0.29104559349291254, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.00012148063979111612}, {"id": 105, "seek": 47790, "start": 500.5, "end": 504.82, "text": " class, but save module doesn't have a parent class.", "tokens": [51494, 1508, 11, 457, 3155, 10088, 1177, 380, 362, 257, 2596, 1508, 13, 51710], "temperature": 0.0, "avg_logprob": -0.29104559349291254, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.00012148063979111612}, {"id": 106, "seek": 50482, "start": 504.82, "end": 508.3, "text": " So this is what's called a mixin.", "tokens": [50364, 407, 341, 307, 437, 311, 1219, 257, 2890, 259, 13, 50538], "temperature": 0.0, "avg_logprob": -0.26823581589592826, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.002323062624782324}, {"id": 107, "seek": 50482, "start": 508.3, "end": 518.42, "text": " And it's using something called multiple inheritance.", "tokens": [50538, 400, 309, 311, 1228, 746, 1219, 3866, 32122, 13, 51044], "temperature": 0.0, "avg_logprob": -0.26823581589592826, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.002323062624782324}, {"id": 108, "seek": 50482, "start": 518.42, "end": 529.9, "text": " And mixins are, as it describes here, it's a design pattern, which is to say it's not", "tokens": [51044, 400, 2890, 1292, 366, 11, 382, 309, 15626, 510, 11, 309, 311, 257, 1715, 5102, 11, 597, 307, 281, 584, 309, 311, 406, 51618], "temperature": 0.0, "avg_logprob": -0.26823581589592826, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.002323062624782324}, {"id": 109, "seek": 50482, "start": 529.9, "end": 531.78, "text": " particularly a part of Python per se.", "tokens": [51618, 4098, 257, 644, 295, 15329, 680, 369, 13, 51712], "temperature": 0.0, "avg_logprob": -0.26823581589592826, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.002323062624782324}, {"id": 110, "seek": 50482, "start": 531.78, "end": 534.46, "text": " It's a design pattern that uses multiple inheritance.", "tokens": [51712, 467, 311, 257, 1715, 5102, 300, 4960, 3866, 32122, 13, 51846], "temperature": 0.0, "avg_logprob": -0.26823581589592826, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.002323062624782324}, {"id": 111, "seek": 53446, "start": 535.1, "end": 539.62, "text": " Now what multiple inheritance is, is where you can say, oh, this class called saved res", "tokens": [50396, 823, 437, 3866, 32122, 307, 11, 307, 689, 291, 393, 584, 11, 1954, 11, 341, 1508, 1219, 6624, 725, 50622], "temperature": 0.0, "avg_logprob": -0.2438962459564209, "compression_ratio": 1.6105769230769231, "no_speech_prob": 1.0616131476126611e-05}, {"id": 112, "seek": 53446, "start": 539.62, "end": 548.74, "text": " block inherits from two things, save module and unit res block.", "tokens": [50622, 3461, 9484, 1208, 490, 732, 721, 11, 3155, 10088, 293, 4985, 725, 3461, 13, 51078], "temperature": 0.0, "avg_logprob": -0.2438962459564209, "compression_ratio": 1.6105769230769231, "no_speech_prob": 1.0616131476126611e-05}, {"id": 113, "seek": 53446, "start": 548.74, "end": 554.22, "text": " And what that does is it means that all of the methods in both of these will end up in", "tokens": [51078, 400, 437, 300, 775, 307, 309, 1355, 300, 439, 295, 264, 7150, 294, 1293, 295, 613, 486, 917, 493, 294, 51352], "temperature": 0.0, "avg_logprob": -0.2438962459564209, "compression_ratio": 1.6105769230769231, "no_speech_prob": 1.0616131476126611e-05}, {"id": 114, "seek": 53446, "start": 554.22, "end": 556.0600000000001, "text": " here.", "tokens": [51352, 510, 13, 51444], "temperature": 0.0, "avg_logprob": -0.2438962459564209, "compression_ratio": 1.6105769230769231, "no_speech_prob": 1.0616131476126611e-05}, {"id": 115, "seek": 53446, "start": 556.0600000000001, "end": 560.7800000000001, "text": " Now that would be simple enough, except we've got a bit of a confusion here, which is that", "tokens": [51444, 823, 300, 576, 312, 2199, 1547, 11, 3993, 321, 600, 658, 257, 857, 295, 257, 15075, 510, 11, 597, 307, 300, 51680], "temperature": 0.0, "avg_logprob": -0.2438962459564209, "compression_ratio": 1.6105769230769231, "no_speech_prob": 1.0616131476126611e-05}, {"id": 116, "seek": 56078, "start": 560.78, "end": 565.66, "text": " unit res block contains forward, and save module contains forward.", "tokens": [50364, 4985, 725, 3461, 8306, 2128, 11, 293, 3155, 10088, 8306, 2128, 13, 50608], "temperature": 0.0, "avg_logprob": -0.26376001224961393, "compression_ratio": 1.641025641025641, "no_speech_prob": 4.5397686335491017e-05}, {"id": 117, "seek": 56078, "start": 565.66, "end": 569.3399999999999, "text": " So it's all very well just combining the methods from both of them, but what if they have the", "tokens": [50608, 407, 309, 311, 439, 588, 731, 445, 21928, 264, 7150, 490, 1293, 295, 552, 11, 457, 437, 498, 436, 362, 264, 50792], "temperature": 0.0, "avg_logprob": -0.26376001224961393, "compression_ratio": 1.641025641025641, "no_speech_prob": 4.5397686335491017e-05}, {"id": 118, "seek": 56078, "start": 569.3399999999999, "end": 572.22, "text": " same method?", "tokens": [50792, 912, 3170, 30, 50936], "temperature": 0.0, "avg_logprob": -0.26376001224961393, "compression_ratio": 1.641025641025641, "no_speech_prob": 4.5397686335491017e-05}, {"id": 119, "seek": 56078, "start": 572.22, "end": 581.9599999999999, "text": " And the answer is that the one you list first, when it calls forward, it's actually calling", "tokens": [50936, 400, 264, 1867, 307, 300, 264, 472, 291, 1329, 700, 11, 562, 309, 5498, 2128, 11, 309, 311, 767, 5141, 51423], "temperature": 0.0, "avg_logprob": -0.26376001224961393, "compression_ratio": 1.641025641025641, "no_speech_prob": 4.5397686335491017e-05}, {"id": 120, "seek": 56078, "start": 581.9599999999999, "end": 585.24, "text": " forward in the later one.", "tokens": [51423, 2128, 294, 264, 1780, 472, 13, 51587], "temperature": 0.0, "avg_logprob": -0.26376001224961393, "compression_ratio": 1.641025641025641, "no_speech_prob": 4.5397686335491017e-05}, {"id": 121, "seek": 56078, "start": 585.24, "end": 586.64, "text": " And that's why it's a mixin.", "tokens": [51587, 400, 300, 311, 983, 309, 311, 257, 2890, 259, 13, 51657], "temperature": 0.0, "avg_logprob": -0.26376001224961393, "compression_ratio": 1.641025641025641, "no_speech_prob": 4.5397686335491017e-05}, {"id": 122, "seek": 58664, "start": 586.64, "end": 591.62, "text": " It's mixing this functionality into this functionality.", "tokens": [50364, 467, 311, 11983, 341, 14980, 666, 341, 14980, 13, 50613], "temperature": 0.0, "avg_logprob": -0.28302455853812303, "compression_ratio": 1.5485436893203883, "no_speech_prob": 6.814821972511709e-05}, {"id": 123, "seek": 58664, "start": 591.62, "end": 597.56, "text": " So it's a unit res block where we've customized forward, so it calls the existing forward", "tokens": [50613, 407, 309, 311, 257, 4985, 725, 3461, 689, 321, 600, 30581, 2128, 11, 370, 309, 5498, 264, 6741, 2128, 50910], "temperature": 0.0, "avg_logprob": -0.28302455853812303, "compression_ratio": 1.5485436893203883, "no_speech_prob": 6.814821972511709e-05}, {"id": 124, "seek": 58664, "start": 597.56, "end": 600.22, "text": " and also saves it.", "tokens": [50910, 293, 611, 19155, 309, 13, 51043], "temperature": 0.0, "avg_logprob": -0.28302455853812303, "compression_ratio": 1.5485436893203883, "no_speech_prob": 6.814821972511709e-05}, {"id": 125, "seek": 58664, "start": 600.22, "end": 604.6, "text": " So you see mixins quite a lot in the Python standard library.", "tokens": [51043, 407, 291, 536, 2890, 1292, 1596, 257, 688, 294, 264, 15329, 3832, 6405, 13, 51262], "temperature": 0.0, "avg_logprob": -0.28302455853812303, "compression_ratio": 1.5485436893203883, "no_speech_prob": 6.814821972511709e-05}, {"id": 126, "seek": 58664, "start": 604.6, "end": 613.52, "text": " For example, the basic HTTP stuff, some of the basic thread stuff, you know, with networking", "tokens": [51262, 1171, 1365, 11, 264, 3875, 33283, 1507, 11, 512, 295, 264, 3875, 7207, 1507, 11, 291, 458, 11, 365, 17985, 51708], "temperature": 0.0, "avg_logprob": -0.28302455853812303, "compression_ratio": 1.5485436893203883, "no_speech_prob": 6.814821972511709e-05}, {"id": 127, "seek": 61352, "start": 613.52, "end": 618.98, "text": " uses multiple inheritance, using this mixin pattern.", "tokens": [50364, 4960, 3866, 32122, 11, 1228, 341, 2890, 259, 5102, 13, 50637], "temperature": 0.0, "avg_logprob": -0.2851620711289443, "compression_ratio": 1.6524064171122994, "no_speech_prob": 4.908654227619991e-05}, {"id": 128, "seek": 61352, "start": 618.98, "end": 625.06, "text": " So with this approach, then the actual implementation of saved res block is nothing at all.", "tokens": [50637, 407, 365, 341, 3109, 11, 550, 264, 3539, 11420, 295, 6624, 725, 3461, 307, 1825, 412, 439, 13, 50941], "temperature": 0.0, "avg_logprob": -0.2851620711289443, "compression_ratio": 1.6524064171122994, "no_speech_prob": 4.908654227619991e-05}, {"id": 129, "seek": 61352, "start": 625.06, "end": 627.74, "text": " So parse means don't do anything.", "tokens": [50941, 407, 48377, 1355, 500, 380, 360, 1340, 13, 51075], "temperature": 0.0, "avg_logprob": -0.2851620711289443, "compression_ratio": 1.6524064171122994, "no_speech_prob": 4.908654227619991e-05}, {"id": 130, "seek": 61352, "start": 627.74, "end": 635.14, "text": " So this is just literally just a class which has no implementation of its own, other than", "tokens": [51075, 407, 341, 307, 445, 3736, 445, 257, 1508, 597, 575, 572, 11420, 295, 1080, 1065, 11, 661, 813, 51445], "temperature": 0.0, "avg_logprob": -0.2851620711289443, "compression_ratio": 1.6524064171122994, "no_speech_prob": 4.908654227619991e-05}, {"id": 131, "seek": 61352, "start": 635.14, "end": 638.38, "text": " just to be a mixin of these two classes.", "tokens": [51445, 445, 281, 312, 257, 2890, 259, 295, 613, 732, 5359, 13, 51607], "temperature": 0.0, "avg_logprob": -0.2851620711289443, "compression_ratio": 1.6524064171122994, "no_speech_prob": 4.908654227619991e-05}, {"id": 132, "seek": 63838, "start": 638.48, "end": 647.84, "text": " So a saved convolution is an nn.conv2d with the saved module mixed in.", "tokens": [50369, 407, 257, 6624, 45216, 307, 364, 297, 77, 13, 1671, 85, 17, 67, 365, 264, 6624, 10088, 7467, 294, 13, 50837], "temperature": 0.0, "avg_logprob": -0.26474582189801094, "compression_ratio": 1.697674418604651, "no_speech_prob": 6.709215813316405e-05}, {"id": 133, "seek": 63838, "start": 647.84, "end": 654.32, "text": " So what's going to happen now is that we can call a saved res block just like a unit res", "tokens": [50837, 407, 437, 311, 516, 281, 1051, 586, 307, 300, 321, 393, 818, 257, 6624, 725, 3461, 445, 411, 257, 4985, 725, 51161], "temperature": 0.0, "avg_logprob": -0.26474582189801094, "compression_ratio": 1.697674418604651, "no_speech_prob": 6.709215813316405e-05}, {"id": 134, "seek": 63838, "start": 654.32, "end": 659.36, "text": " block, and a saved conv just like an nn.conv2d.", "tokens": [51161, 3461, 11, 293, 257, 6624, 3754, 445, 411, 364, 297, 77, 13, 1671, 85, 17, 67, 13, 51413], "temperature": 0.0, "avg_logprob": -0.26474582189801094, "compression_ratio": 1.697674418604651, "no_speech_prob": 6.709215813316405e-05}, {"id": 135, "seek": 63838, "start": 659.36, "end": 666.62, "text": " But that object is going to end up with the activations inside the .saved attribute.", "tokens": [51413, 583, 300, 2657, 307, 516, 281, 917, 493, 365, 264, 2430, 763, 1854, 264, 2411, 82, 12865, 19667, 13, 51776], "temperature": 0.0, "avg_logprob": -0.26474582189801094, "compression_ratio": 1.697674418604651, "no_speech_prob": 6.709215813316405e-05}, {"id": 136, "seek": 66662, "start": 666.64, "end": 675.44, "text": " So now a downsampling block is just a sequential of saved res blocks.", "tokens": [50365, 407, 586, 257, 760, 19988, 11970, 3461, 307, 445, 257, 42881, 295, 6624, 725, 8474, 13, 50805], "temperature": 0.0, "avg_logprob": -0.3014429916035045, "compression_ratio": 1.688118811881188, "no_speech_prob": 5.955134383839322e-06}, {"id": 137, "seek": 66662, "start": 675.44, "end": 683.84, "text": " As per usual, the very first one is going to have the number of in channels to start", "tokens": [50805, 1018, 680, 7713, 11, 264, 588, 700, 472, 307, 516, 281, 362, 264, 1230, 295, 294, 9235, 281, 722, 51225], "temperature": 0.0, "avg_logprob": -0.3014429916035045, "compression_ratio": 1.688118811881188, "no_speech_prob": 5.955134383839322e-06}, {"id": 138, "seek": 66662, "start": 683.84, "end": 688.44, "text": " with, and it'll always have the number of NF, the number of filters output, and then", "tokens": [51225, 365, 11, 293, 309, 603, 1009, 362, 264, 1230, 295, 13576, 11, 264, 1230, 295, 15995, 5598, 11, 293, 550, 51455], "temperature": 0.0, "avg_logprob": -0.3014429916035045, "compression_ratio": 1.688118811881188, "no_speech_prob": 5.955134383839322e-06}, {"id": 139, "seek": 66662, "start": 688.44, "end": 693.16, "text": " after that the inputs will be else equal to NF, because the first ones change the number", "tokens": [51455, 934, 300, 264, 15743, 486, 312, 1646, 2681, 281, 13576, 11, 570, 264, 700, 2306, 1319, 264, 1230, 51691], "temperature": 0.0, "avg_logprob": -0.3014429916035045, "compression_ratio": 1.688118811881188, "no_speech_prob": 5.955134383839322e-06}, {"id": 140, "seek": 66662, "start": 693.16, "end": 694.16, "text": " of channels.", "tokens": [51691, 295, 9235, 13, 51741], "temperature": 0.0, "avg_logprob": -0.3014429916035045, "compression_ratio": 1.688118811881188, "no_speech_prob": 5.955134383839322e-06}, {"id": 141, "seek": 69416, "start": 694.6999999999999, "end": 698.68, "text": " And we'll do that for however many layers we have.", "tokens": [50391, 400, 321, 603, 360, 300, 337, 4461, 867, 7914, 321, 362, 13, 50590], "temperature": 0.0, "avg_logprob": -0.2531568849241579, "compression_ratio": 1.5197740112994351, "no_speech_prob": 2.796928492898587e-05}, {"id": 142, "seek": 69416, "start": 698.68, "end": 703.8, "text": " And then at the end of that process, as we discussed, we will add to that sequential", "tokens": [50590, 400, 550, 412, 264, 917, 295, 300, 1399, 11, 382, 321, 7152, 11, 321, 486, 909, 281, 300, 42881, 50846], "temperature": 0.0, "avg_logprob": -0.2531568849241579, "compression_ratio": 1.5197740112994351, "no_speech_prob": 2.796928492898587e-05}, {"id": 143, "seek": 69416, "start": 703.8, "end": 709.02, "text": " a saved conv with stride2 to do the downsampling if requested.", "tokens": [50846, 257, 6624, 3754, 365, 1056, 482, 17, 281, 360, 264, 760, 19988, 11970, 498, 16436, 13, 51107], "temperature": 0.0, "avg_logprob": -0.2531568849241579, "compression_ratio": 1.5197740112994351, "no_speech_prob": 2.796928492898587e-05}, {"id": 144, "seek": 69416, "start": 709.02, "end": 715.26, "text": " So we're going to end up with a single nn.sequential for a down block.", "tokens": [51107, 407, 321, 434, 516, 281, 917, 493, 365, 257, 2167, 297, 77, 13, 11834, 2549, 337, 257, 760, 3461, 13, 51419], "temperature": 0.0, "avg_logprob": -0.2531568849241579, "compression_ratio": 1.5197740112994351, "no_speech_prob": 2.796928492898587e-05}, {"id": 145, "seek": 71526, "start": 715.26, "end": 725.78, "text": " And then an up block is going to look very similar, but instead of using a nn.conv2d", "tokens": [50364, 400, 550, 364, 493, 3461, 307, 516, 281, 574, 588, 2531, 11, 457, 2602, 295, 1228, 257, 297, 77, 13, 1671, 85, 17, 67, 50890], "temperature": 0.0, "avg_logprob": -0.24878717237903225, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0004802786570508033}, {"id": 146, "seek": 71526, "start": 725.78, "end": 733.48, "text": " with stride2, upsampling will be done with a sequence of an upsampling layer.", "tokens": [50890, 365, 1056, 482, 17, 11, 15497, 335, 11970, 486, 312, 1096, 365, 257, 8310, 295, 364, 15497, 335, 11970, 4583, 13, 51275], "temperature": 0.0, "avg_logprob": -0.24878717237903225, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0004802786570508033}, {"id": 147, "seek": 71526, "start": 733.48, "end": 737.4399999999999, "text": " And so literally all that does is it just duplicates every pixel four times into a little", "tokens": [51275, 400, 370, 3736, 439, 300, 775, 307, 309, 445, 17154, 1024, 633, 19261, 1451, 1413, 666, 257, 707, 51473], "temperature": 0.0, "avg_logprob": -0.24878717237903225, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0004802786570508033}, {"id": 148, "seek": 71526, "start": 737.4399999999999, "end": 739.36, "text": " 2x2 grid.", "tokens": [51473, 568, 87, 17, 10748, 13, 51569], "temperature": 0.0, "avg_logprob": -0.24878717237903225, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0004802786570508033}, {"id": 149, "seek": 71526, "start": 739.36, "end": 742.02, "text": " That's all an upsampling layer does, nothing clever.", "tokens": [51569, 663, 311, 439, 364, 15497, 335, 11970, 4583, 775, 11, 1825, 13494, 13, 51702], "temperature": 0.0, "avg_logprob": -0.24878717237903225, "compression_ratio": 1.5594059405940595, "no_speech_prob": 0.0004802786570508033}, {"id": 150, "seek": 74202, "start": 742.02, "end": 746.84, "text": " And then follow that by a stride1 convolution.", "tokens": [50364, 400, 550, 1524, 300, 538, 257, 1056, 482, 16, 45216, 13, 50605], "temperature": 0.0, "avg_logprob": -0.2438950205958167, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0013044927036389709}, {"id": 151, "seek": 74202, "start": 746.84, "end": 753.4, "text": " So that allows it to, you know, adjust some of those pixels as if necessary with a simple", "tokens": [50605, 407, 300, 4045, 309, 281, 11, 291, 458, 11, 4369, 512, 295, 729, 18668, 382, 498, 4818, 365, 257, 2199, 50933], "temperature": 0.0, "avg_logprob": -0.2438950205958167, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0013044927036389709}, {"id": 152, "seek": 74202, "start": 753.4, "end": 755.84, "text": " 3x3 conv.", "tokens": [50933, 805, 87, 18, 3754, 13, 51055], "temperature": 0.0, "avg_logprob": -0.2438950205958167, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0013044927036389709}, {"id": 153, "seek": 74202, "start": 755.84, "end": 760.0799999999999, "text": " So that's pretty similar to a stride2 downsampling.", "tokens": [51055, 407, 300, 311, 1238, 2531, 281, 257, 1056, 482, 17, 760, 19988, 11970, 13, 51267], "temperature": 0.0, "avg_logprob": -0.2438950205958167, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0013044927036389709}, {"id": 154, "seek": 74202, "start": 760.0799999999999, "end": 765.36, "text": " This is kind of the rough equivalent for upsampling.", "tokens": [51267, 639, 307, 733, 295, 264, 5903, 10344, 337, 15497, 335, 11970, 13, 51531], "temperature": 0.0, "avg_logprob": -0.2438950205958167, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0013044927036389709}, {"id": 155, "seek": 74202, "start": 765.36, "end": 767.16, "text": " There are other ways of doing upsampling.", "tokens": [51531, 821, 366, 661, 2098, 295, 884, 15497, 335, 11970, 13, 51621], "temperature": 0.0, "avg_logprob": -0.2438950205958167, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0013044927036389709}, {"id": 156, "seek": 76716, "start": 767.16, "end": 772.6, "text": " This is just the one that stable diffusion does.", "tokens": [50364, 639, 307, 445, 264, 472, 300, 8351, 25242, 775, 13, 50636], "temperature": 0.0, "avg_logprob": -0.28337183103456604, "compression_ratio": 1.6294416243654823, "no_speech_prob": 0.0011160055873915553}, {"id": 157, "seek": 76716, "start": 772.6, "end": 779.68, "text": " So an up block looks a lot like a down block, except that now, so as before, we're going", "tokens": [50636, 407, 364, 493, 3461, 1542, 257, 688, 411, 257, 760, 3461, 11, 3993, 300, 586, 11, 370, 382, 949, 11, 321, 434, 516, 50990], "temperature": 0.0, "avg_logprob": -0.28337183103456604, "compression_ratio": 1.6294416243654823, "no_speech_prob": 0.0011160055873915553}, {"id": 158, "seek": 76716, "start": 779.68, "end": 782.4, "text": " to create a bunch of unit res blocks.", "tokens": [50990, 281, 1884, 257, 3840, 295, 4985, 725, 8474, 13, 51126], "temperature": 0.0, "avg_logprob": -0.28337183103456604, "compression_ratio": 1.6294416243654823, "no_speech_prob": 0.0011160055873915553}, {"id": 159, "seek": 76716, "start": 782.4, "end": 784.0, "text": " These are not saved res blocks, of course.", "tokens": [51126, 1981, 366, 406, 6624, 725, 8474, 11, 295, 1164, 13, 51206], "temperature": 0.0, "avg_logprob": -0.28337183103456604, "compression_ratio": 1.6294416243654823, "no_speech_prob": 0.0011160055873915553}, {"id": 160, "seek": 76716, "start": 784.0, "end": 789.12, "text": " We want to use the saved results in the upsampling path of the unit.", "tokens": [51206, 492, 528, 281, 764, 264, 6624, 3542, 294, 264, 15497, 335, 11970, 3100, 295, 264, 4985, 13, 51462], "temperature": 0.0, "avg_logprob": -0.28337183103456604, "compression_ratio": 1.6294416243654823, "no_speech_prob": 0.0011160055873915553}, {"id": 161, "seek": 76716, "start": 789.12, "end": 792.3199999999999, "text": " So we just use normal res blocks.", "tokens": [51462, 407, 321, 445, 764, 2710, 725, 8474, 13, 51622], "temperature": 0.0, "avg_logprob": -0.28337183103456604, "compression_ratio": 1.6294416243654823, "no_speech_prob": 0.0011160055873915553}, {"id": 162, "seek": 79232, "start": 792.32, "end": 798.48, "text": " But what we're going to do now is as we go through each resnet, we're going to call it", "tokens": [50364, 583, 437, 321, 434, 516, 281, 360, 586, 307, 382, 321, 352, 807, 1184, 725, 7129, 11, 321, 434, 516, 281, 818, 309, 50672], "temperature": 0.0, "avg_logprob": -0.21347976767498514, "compression_ratio": 1.7554347826086956, "no_speech_prob": 0.0018968414515256882}, {"id": 163, "seek": 79232, "start": 798.48, "end": 807.4000000000001, "text": " not just on our activations, but we're going to concatenate that with whatever was stored", "tokens": [50672, 406, 445, 322, 527, 2430, 763, 11, 457, 321, 434, 516, 281, 1588, 7186, 473, 300, 365, 2035, 390, 12187, 51118], "temperature": 0.0, "avg_logprob": -0.21347976767498514, "compression_ratio": 1.7554347826086956, "no_speech_prob": 0.0018968414515256882}, {"id": 164, "seek": 79232, "start": 807.4000000000001, "end": 809.48, "text": " during the downsampling path.", "tokens": [51118, 1830, 264, 760, 19988, 11970, 3100, 13, 51222], "temperature": 0.0, "avg_logprob": -0.21347976767498514, "compression_ratio": 1.7554347826086956, "no_speech_prob": 0.0018968414515256882}, {"id": 165, "seek": 79232, "start": 809.48, "end": 814.7600000000001, "text": " So this is going to be a list of all of the things stored in the downsampling path.", "tokens": [51222, 407, 341, 307, 516, 281, 312, 257, 1329, 295, 439, 295, 264, 721, 12187, 294, 264, 760, 19988, 11970, 3100, 13, 51486], "temperature": 0.0, "avg_logprob": -0.21347976767498514, "compression_ratio": 1.7554347826086956, "no_speech_prob": 0.0018968414515256882}, {"id": 166, "seek": 79232, "start": 814.7600000000001, "end": 817.12, "text": " It'll be passed to the up block.", "tokens": [51486, 467, 603, 312, 4678, 281, 264, 493, 3461, 13, 51604], "temperature": 0.0, "avg_logprob": -0.21347976767498514, "compression_ratio": 1.7554347826086956, "no_speech_prob": 0.0018968414515256882}, {"id": 167, "seek": 81712, "start": 817.12, "end": 822.68, "text": " And so .pop will grab the last one off that list, and concatenate it with the activations,", "tokens": [50364, 400, 370, 2411, 13872, 486, 4444, 264, 1036, 472, 766, 300, 1329, 11, 293, 1588, 7186, 473, 309, 365, 264, 2430, 763, 11, 50642], "temperature": 0.0, "avg_logprob": -0.2112516553214427, "compression_ratio": 1.7197802197802199, "no_speech_prob": 0.00013341866724658757}, {"id": 168, "seek": 81712, "start": 822.68, "end": 825.52, "text": " and pass that to the resnet.", "tokens": [50642, 293, 1320, 300, 281, 264, 725, 7129, 13, 50784], "temperature": 0.0, "avg_logprob": -0.2112516553214427, "compression_ratio": 1.7197802197802199, "no_speech_prob": 0.00013341866724658757}, {"id": 169, "seek": 81712, "start": 825.52, "end": 832.8, "text": " So we need to know how many filters there were, how many activations there were in the", "tokens": [50784, 407, 321, 643, 281, 458, 577, 867, 15995, 456, 645, 11, 577, 867, 2430, 763, 456, 645, 294, 264, 51148], "temperature": 0.0, "avg_logprob": -0.2112516553214427, "compression_ratio": 1.7197802197802199, "no_speech_prob": 0.00013341866724658757}, {"id": 170, "seek": 81712, "start": 832.8, "end": 834.04, "text": " downsampling path.", "tokens": [51148, 760, 19988, 11970, 3100, 13, 51210], "temperature": 0.0, "avg_logprob": -0.2112516553214427, "compression_ratio": 1.7197802197802199, "no_speech_prob": 0.00013341866724658757}, {"id": 171, "seek": 81712, "start": 834.04, "end": 835.04, "text": " So that's stored here.", "tokens": [51210, 407, 300, 311, 12187, 510, 13, 51260], "temperature": 0.0, "avg_logprob": -0.2112516553214427, "compression_ratio": 1.7197802197802199, "no_speech_prob": 0.00013341866724658757}, {"id": 172, "seek": 81712, "start": 835.04, "end": 838.92, "text": " This is the previous number of filters in the downsampling path.", "tokens": [51260, 639, 307, 264, 3894, 1230, 295, 15995, 294, 264, 760, 19988, 11970, 3100, 13, 51454], "temperature": 0.0, "avg_logprob": -0.2112516553214427, "compression_ratio": 1.7197802197802199, "no_speech_prob": 0.00013341866724658757}, {"id": 173, "seek": 83892, "start": 838.92, "end": 851.8, "text": " And so the res block, we'll need to add those in, in addition to the normal number.", "tokens": [50364, 400, 370, 264, 725, 3461, 11, 321, 603, 643, 281, 909, 729, 294, 11, 294, 4500, 281, 264, 2710, 1230, 13, 51008], "temperature": 0.0, "avg_logprob": -0.2686410668778093, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.0020828787237405777}, {"id": 174, "seek": 83892, "start": 851.8, "end": 857.9599999999999, "text": " So that's what's going to happen there.", "tokens": [51008, 407, 300, 311, 437, 311, 516, 281, 1051, 456, 13, 51316], "temperature": 0.0, "avg_logprob": -0.2686410668778093, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.0020828787237405777}, {"id": 175, "seek": 83892, "start": 857.9599999999999, "end": 859.8, "text": " And so yeah, do that for each layer, as before.", "tokens": [51316, 400, 370, 1338, 11, 360, 300, 337, 1184, 4583, 11, 382, 949, 13, 51408], "temperature": 0.0, "avg_logprob": -0.2686410668778093, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.0020828787237405777}, {"id": 176, "seek": 83892, "start": 859.8, "end": 866.4399999999999, "text": " And then at the end, add an upsampling layer, if it's been requested.", "tokens": [51408, 400, 550, 412, 264, 917, 11, 909, 364, 15497, 335, 11970, 4583, 11, 498, 309, 311, 668, 16436, 13, 51740], "temperature": 0.0, "avg_logprob": -0.2686410668778093, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.0020828787237405777}, {"id": 177, "seek": 86644, "start": 866.44, "end": 869.36, "text": " If it's a Boolean.", "tokens": [50364, 759, 309, 311, 257, 23351, 28499, 13, 50510], "temperature": 0.0, "avg_logprob": -0.3935356140136719, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0003858747077174485}, {"id": 178, "seek": 86644, "start": 869.36, "end": 872.24, "text": " Okay, so that's the upsampling block.", "tokens": [50510, 1033, 11, 370, 300, 311, 264, 15497, 335, 11970, 3461, 13, 50654], "temperature": 0.0, "avg_logprob": -0.3935356140136719, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0003858747077174485}, {"id": 179, "seek": 86644, "start": 872.24, "end": 874.24, "text": " Does that all make sense so far?", "tokens": [50654, 4402, 300, 439, 652, 2020, 370, 1400, 30, 50754], "temperature": 0.0, "avg_logprob": -0.3935356140136719, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0003858747077174485}, {"id": 180, "seek": 86644, "start": 874.24, "end": 878.24, "text": " Yeah, it looks good.", "tokens": [50754, 865, 11, 309, 1542, 665, 13, 50954], "temperature": 0.0, "avg_logprob": -0.3935356140136719, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0003858747077174485}, {"id": 181, "seek": 86644, "start": 878.24, "end": 879.24, "text": " Okay.", "tokens": [50954, 1033, 13, 51004], "temperature": 0.0, "avg_logprob": -0.3935356140136719, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0003858747077174485}, {"id": 182, "seek": 86644, "start": 879.24, "end": 889.08, "text": " Okay, so the unit now is going to look a lot like our previous unit.", "tokens": [51004, 1033, 11, 370, 264, 4985, 586, 307, 516, 281, 574, 257, 688, 411, 527, 3894, 4985, 13, 51496], "temperature": 0.0, "avg_logprob": -0.3935356140136719, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0003858747077174485}, {"id": 183, "seek": 86644, "start": 889.08, "end": 894.6400000000001, "text": " We're going to start out as we tend to, with a convolution, to now allow us to create a", "tokens": [51496, 492, 434, 516, 281, 722, 484, 382, 321, 3928, 281, 11, 365, 257, 45216, 11, 281, 586, 2089, 505, 281, 1884, 257, 51774], "temperature": 0.0, "avg_logprob": -0.3935356140136719, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0003858747077174485}, {"id": 184, "seek": 89464, "start": 894.64, "end": 897.12, "text": " few more channels.", "tokens": [50364, 1326, 544, 9235, 13, 50488], "temperature": 0.0, "avg_logprob": -0.2529725508256392, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00020342651987448335}, {"id": 185, "seek": 89464, "start": 897.12, "end": 902.28, "text": " And so we're passing to our unit, that's just, you know, how many channels are in your image,", "tokens": [50488, 400, 370, 321, 434, 8437, 281, 527, 4985, 11, 300, 311, 445, 11, 291, 458, 11, 577, 867, 9235, 366, 294, 428, 3256, 11, 50746], "temperature": 0.0, "avg_logprob": -0.2529725508256392, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00020342651987448335}, {"id": 186, "seek": 89464, "start": 902.28, "end": 904.4399999999999, "text": " and how many channels are in your output image.", "tokens": [50746, 293, 577, 867, 9235, 366, 294, 428, 5598, 3256, 13, 50854], "temperature": 0.0, "avg_logprob": -0.2529725508256392, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00020342651987448335}, {"id": 187, "seek": 89464, "start": 904.4399999999999, "end": 908.84, "text": " So for normal images, normal full-color images, that'll be 3, 3.", "tokens": [50854, 407, 337, 2710, 5267, 11, 2710, 1577, 12, 23851, 5267, 11, 300, 603, 312, 805, 11, 805, 13, 51074], "temperature": 0.0, "avg_logprob": -0.2529725508256392, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00020342651987448335}, {"id": 188, "seek": 89464, "start": 908.84, "end": 914.04, "text": " How many filters are there for each of those resnet blocks, up blocks and down blocks you've", "tokens": [51074, 1012, 867, 15995, 366, 456, 337, 1184, 295, 729, 725, 7129, 8474, 11, 493, 8474, 293, 760, 8474, 291, 600, 51334], "temperature": 0.0, "avg_logprob": -0.2529725508256392, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00020342651987448335}, {"id": 189, "seek": 89464, "start": 914.04, "end": 915.52, "text": " got.", "tokens": [51334, 658, 13, 51408], "temperature": 0.0, "avg_logprob": -0.2529725508256392, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00020342651987448335}, {"id": 190, "seek": 89464, "start": 915.52, "end": 920.4, "text": " And in the downsampling, how many layers are there in each block.", "tokens": [51408, 400, 294, 264, 760, 19988, 11970, 11, 577, 867, 7914, 366, 456, 294, 1184, 3461, 13, 51652], "temperature": 0.0, "avg_logprob": -0.2529725508256392, "compression_ratio": 1.8009259259259258, "no_speech_prob": 0.00020342651987448335}, {"id": 191, "seek": 92040, "start": 920.4, "end": 926.0799999999999, "text": " So we go from, the conv will go from in-channel, so that'd be 3, to nf0, which, this is the", "tokens": [50364, 407, 321, 352, 490, 11, 264, 3754, 486, 352, 490, 294, 12, 339, 11444, 11, 370, 300, 1116, 312, 805, 11, 281, 297, 69, 15, 11, 597, 11, 341, 307, 264, 50648], "temperature": 0.0, "avg_logprob": -0.301367565266137, "compression_ratio": 1.569377990430622, "no_speech_prob": 0.002434153575450182}, {"id": 192, "seek": 92040, "start": 926.0799999999999, "end": 930.64, "text": " number of filters in the stable diffusion model.", "tokens": [50648, 1230, 295, 15995, 294, 264, 8351, 25242, 2316, 13, 50876], "temperature": 0.0, "avg_logprob": -0.301367565266137, "compression_ratio": 1.569377990430622, "no_speech_prob": 0.002434153575450182}, {"id": 193, "seek": 92040, "start": 930.64, "end": 936.88, "text": " They're pretty big, as you see, by default.", "tokens": [50876, 814, 434, 1238, 955, 11, 382, 291, 536, 11, 538, 7576, 13, 51188], "temperature": 0.0, "avg_logprob": -0.301367565266137, "compression_ratio": 1.569377990430622, "no_speech_prob": 0.002434153575450182}, {"id": 194, "seek": 92040, "start": 936.88, "end": 940.0, "text": " And so that's the number of channels we'd create.", "tokens": [51188, 400, 370, 300, 311, 264, 1230, 295, 9235, 321, 1116, 1884, 13, 51344], "temperature": 0.0, "avg_logprob": -0.301367565266137, "compression_ratio": 1.569377990430622, "no_speech_prob": 0.002434153575450182}, {"id": 195, "seek": 92040, "start": 940.0, "end": 949.1999999999999, "text": " Which is like, very redundant, in that this is a 3x3 conv, so it only contains 3x3x3 channels", "tokens": [51344, 3013, 307, 411, 11, 588, 40997, 11, 294, 300, 341, 307, 257, 805, 87, 18, 3754, 11, 370, 309, 787, 8306, 805, 87, 18, 87, 18, 9235, 51804], "temperature": 0.0, "avg_logprob": -0.301367565266137, "compression_ratio": 1.569377990430622, "no_speech_prob": 0.002434153575450182}, {"id": 196, "seek": 94920, "start": 949.2, "end": 953.4000000000001, "text": " equals 27 inputs, and 224 outputs.", "tokens": [50364, 6915, 7634, 15743, 11, 293, 5853, 19, 23930, 13, 50574], "temperature": 0.0, "avg_logprob": -0.2695705865019111, "compression_ratio": 1.5133928571428572, "no_speech_prob": 5.920900730416179e-05}, {"id": 197, "seek": 94920, "start": 953.4000000000001, "end": 958.36, "text": " So it's not, you know, doing computation, useful computation, in a sense.", "tokens": [50574, 407, 309, 311, 406, 11, 291, 458, 11, 884, 24903, 11, 4420, 24903, 11, 294, 257, 2020, 13, 50822], "temperature": 0.0, "avg_logprob": -0.2695705865019111, "compression_ratio": 1.5133928571428572, "no_speech_prob": 5.920900730416179e-05}, {"id": 198, "seek": 94920, "start": 958.36, "end": 962.36, "text": " It's just giving it more space to work with down the line.", "tokens": [50822, 467, 311, 445, 2902, 309, 544, 1901, 281, 589, 365, 760, 264, 1622, 13, 51022], "temperature": 0.0, "avg_logprob": -0.2695705865019111, "compression_ratio": 1.5133928571428572, "no_speech_prob": 5.920900730416179e-05}, {"id": 199, "seek": 94920, "start": 962.36, "end": 970.84, "text": " Which I don't think that makes sense, but I haven't played with it enough to be sure.", "tokens": [51022, 3013, 286, 500, 380, 519, 300, 1669, 2020, 11, 457, 286, 2378, 380, 3737, 365, 309, 1547, 281, 312, 988, 13, 51446], "temperature": 0.0, "avg_logprob": -0.2695705865019111, "compression_ratio": 1.5133928571428572, "no_speech_prob": 5.920900730416179e-05}, {"id": 200, "seek": 94920, "start": 970.84, "end": 976.2, "text": " Normally we would do like, you know, like a few res blocks or something at this level", "tokens": [51446, 17424, 321, 576, 360, 411, 11, 291, 458, 11, 411, 257, 1326, 725, 8474, 420, 746, 412, 341, 1496, 51714], "temperature": 0.0, "avg_logprob": -0.2695705865019111, "compression_ratio": 1.5133928571428572, "no_speech_prob": 5.920900730416179e-05}, {"id": 201, "seek": 97620, "start": 976.2, "end": 980.6, "text": " to more gradually increase it, because this feels like a lot of wasted effort.", "tokens": [50364, 281, 544, 13145, 3488, 309, 11, 570, 341, 3417, 411, 257, 688, 295, 19496, 4630, 13, 50584], "temperature": 0.0, "avg_logprob": -0.35572919249534607, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.08878462016582489}, {"id": 202, "seek": 97620, "start": 980.6, "end": 984.2, "text": " But yeah, I haven't studied that closely enough to be sure.", "tokens": [50584, 583, 1338, 11, 286, 2378, 380, 9454, 300, 8185, 1547, 281, 312, 988, 13, 50764], "temperature": 0.0, "avg_logprob": -0.35572919249534607, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.08878462016582489}, {"id": 203, "seek": 97620, "start": 984.2, "end": 989.12, "text": " Sorry, Jeremy, just to tweet, this is the default, I think, the default settings for", "tokens": [50764, 4919, 11, 17809, 11, 445, 281, 15258, 11, 341, 307, 264, 7576, 11, 286, 519, 11, 264, 7576, 6257, 337, 51010], "temperature": 0.0, "avg_logprob": -0.35572919249534607, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.08878462016582489}, {"id": 204, "seek": 97620, "start": 989.12, "end": 991.2, "text": " the unconditional unit in diffusers.", "tokens": [51010, 264, 47916, 4985, 294, 7593, 301, 433, 13, 51114], "temperature": 0.0, "avg_logprob": -0.35572919249534607, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.08878462016582489}, {"id": 205, "seek": 97620, "start": 991.2, "end": 994.2, "text": " But the stable diffusion unit actually has even more channels.", "tokens": [51114, 583, 264, 8351, 25242, 4985, 767, 575, 754, 544, 9235, 13, 51264], "temperature": 0.0, "avg_logprob": -0.35572919249534607, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.08878462016582489}, {"id": 206, "seek": 97620, "start": 994.2, "end": 999.2, "text": " It has 320, 640, and then 1280, 1280.", "tokens": [51264, 467, 575, 42429, 11, 1386, 5254, 11, 293, 550, 2272, 4702, 11, 2272, 4702, 13, 51514], "temperature": 0.0, "avg_logprob": -0.35572919249534607, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.08878462016582489}, {"id": 207, "seek": 97620, "start": 999.2, "end": 1001.32, "text": " Cool, thanks for clarifying.", "tokens": [51514, 8561, 11, 3231, 337, 6093, 5489, 13, 51620], "temperature": 0.0, "avg_logprob": -0.35572919249534607, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.08878462016582489}, {"id": 208, "seek": 97620, "start": 1001.32, "end": 1004.4000000000001, "text": " And it's, yeah, the unconditional one, which is what we're doing right now.", "tokens": [51620, 400, 309, 311, 11, 1338, 11, 264, 47916, 472, 11, 597, 307, 437, 321, 434, 884, 558, 586, 13, 51774], "temperature": 0.0, "avg_logprob": -0.35572919249534607, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.08878462016582489}, {"id": 209, "seek": 100440, "start": 1004.6, "end": 1006.6, "text": " That's a great point.", "tokens": [50374, 663, 311, 257, 869, 935, 13, 50474], "temperature": 0.0, "avg_logprob": -0.24105080691250888, "compression_ratio": 1.6192660550458715, "no_speech_prob": 4.7576406359439716e-05}, {"id": 210, "seek": 100440, "start": 1006.6, "end": 1013.36, "text": " Okay, so then we, yeah, we go through all of our number of filters.", "tokens": [50474, 1033, 11, 370, 550, 321, 11, 1338, 11, 321, 352, 807, 439, 295, 527, 1230, 295, 15995, 13, 50812], "temperature": 0.0, "avg_logprob": -0.24105080691250888, "compression_ratio": 1.6192660550458715, "no_speech_prob": 4.7576406359439716e-05}, {"id": 211, "seek": 100440, "start": 1013.36, "end": 1019.48, "text": " And actually the first res block contains 224 to 224.", "tokens": [50812, 400, 767, 264, 700, 725, 3461, 8306, 5853, 19, 281, 5853, 19, 13, 51118], "temperature": 0.0, "avg_logprob": -0.24105080691250888, "compression_ratio": 1.6192660550458715, "no_speech_prob": 4.7576406359439716e-05}, {"id": 212, "seek": 100440, "start": 1019.48, "end": 1021.36, "text": " So that's why it's kind of keeping track of this stuff.", "tokens": [51118, 407, 300, 311, 983, 309, 311, 733, 295, 5145, 2837, 295, 341, 1507, 13, 51212], "temperature": 0.0, "avg_logprob": -0.24105080691250888, "compression_ratio": 1.6192660550458715, "no_speech_prob": 4.7576406359439716e-05}, {"id": 213, "seek": 100440, "start": 1021.36, "end": 1027.8, "text": " And then the second res block is 224 to 448, and then 448 to 672, and then 672 to 896.", "tokens": [51212, 400, 550, 264, 1150, 725, 3461, 307, 5853, 19, 281, 1017, 13318, 11, 293, 550, 1017, 13318, 281, 23879, 17, 11, 293, 550, 23879, 17, 281, 1649, 22962, 13, 51534], "temperature": 0.0, "avg_logprob": -0.24105080691250888, "compression_ratio": 1.6192660550458715, "no_speech_prob": 4.7576406359439716e-05}, {"id": 214, "seek": 100440, "start": 1027.8, "end": 1031.4, "text": " That's why we're just going to have to keep track of these things.", "tokens": [51534, 663, 311, 983, 321, 434, 445, 516, 281, 362, 281, 1066, 2837, 295, 613, 721, 13, 51714], "temperature": 0.0, "avg_logprob": -0.24105080691250888, "compression_ratio": 1.6192660550458715, "no_speech_prob": 4.7576406359439716e-05}, {"id": 215, "seek": 103140, "start": 1031.4, "end": 1036.44, "text": " So yeah, we add, so we have a sequential for our down blocks, and we just add a down block.", "tokens": [50364, 407, 1338, 11, 321, 909, 11, 370, 321, 362, 257, 42881, 337, 527, 760, 8474, 11, 293, 321, 445, 909, 257, 760, 3461, 13, 50616], "temperature": 0.0, "avg_logprob": -0.2663534421187181, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.004007203504443169}, {"id": 216, "seek": 103140, "start": 1036.44, "end": 1041.64, "text": " The very last one doesn't have down sampling, which makes sense, right?", "tokens": [50616, 440, 588, 1036, 472, 1177, 380, 362, 760, 21179, 11, 597, 1669, 2020, 11, 558, 30, 50876], "temperature": 0.0, "avg_logprob": -0.2663534421187181, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.004007203504443169}, {"id": 217, "seek": 103140, "start": 1041.64, "end": 1045.24, "text": " Because the very last one, there's nothing after it, so no point down sampling.", "tokens": [50876, 1436, 264, 588, 1036, 472, 11, 456, 311, 1825, 934, 309, 11, 370, 572, 935, 760, 21179, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2663534421187181, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.004007203504443169}, {"id": 218, "seek": 103140, "start": 1045.24, "end": 1049.2800000000002, "text": " Other than that, they all have down sampling.", "tokens": [51056, 5358, 813, 300, 11, 436, 439, 362, 760, 21179, 13, 51258], "temperature": 0.0, "avg_logprob": -0.2663534421187181, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.004007203504443169}, {"id": 219, "seek": 103140, "start": 1049.2800000000002, "end": 1057.0800000000002, "text": " And then we have one more res block in the middle, which is that the same as what we", "tokens": [51258, 400, 550, 321, 362, 472, 544, 725, 3461, 294, 264, 2808, 11, 597, 307, 300, 264, 912, 382, 437, 321, 51648], "temperature": 0.0, "avg_logprob": -0.2663534421187181, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.004007203504443169}, {"id": 220, "seek": 103140, "start": 1057.0800000000002, "end": 1058.0800000000002, "text": " did?", "tokens": [51648, 630, 30, 51698], "temperature": 0.0, "avg_logprob": -0.2663534421187181, "compression_ratio": 1.7227272727272727, "no_speech_prob": 0.004007203504443169}, {"id": 221, "seek": 105808, "start": 1058.12, "end": 1062.48, "text": " Okay, so we didn't have a middle res block in our original unit here.", "tokens": [50366, 1033, 11, 370, 321, 994, 380, 362, 257, 2808, 725, 3461, 294, 527, 3380, 4985, 510, 13, 50584], "temperature": 0.0, "avg_logprob": -0.34447996077998994, "compression_ratio": 1.5686274509803921, "no_speech_prob": 4.425487077241996e-06}, {"id": 222, "seek": 105808, "start": 1062.48, "end": 1067.9199999999998, "text": " What about this one?", "tokens": [50584, 708, 466, 341, 472, 30, 50856], "temperature": 0.0, "avg_logprob": -0.34447996077998994, "compression_ratio": 1.5686274509803921, "no_speech_prob": 4.425487077241996e-06}, {"id": 223, "seek": 105808, "start": 1067.9199999999998, "end": 1069.12, "text": " Do we have any mid blocks?", "tokens": [50856, 1144, 321, 362, 604, 2062, 8474, 30, 50916], "temperature": 0.0, "avg_logprob": -0.34447996077998994, "compression_ratio": 1.5686274509803921, "no_speech_prob": 4.425487077241996e-06}, {"id": 224, "seek": 105808, "start": 1069.12, "end": 1073.6799999999998, "text": " No, so we haven't done, okay, but I mean, it's just another res block that you do after", "tokens": [50916, 883, 11, 370, 321, 2378, 380, 1096, 11, 1392, 11, 457, 286, 914, 11, 309, 311, 445, 1071, 725, 3461, 300, 291, 360, 934, 51144], "temperature": 0.0, "avg_logprob": -0.34447996077998994, "compression_ratio": 1.5686274509803921, "no_speech_prob": 4.425487077241996e-06}, {"id": 225, "seek": 105808, "start": 1073.6799999999998, "end": 1076.32, "text": " the down sampling.", "tokens": [51144, 264, 760, 21179, 13, 51276], "temperature": 0.0, "avg_logprob": -0.34447996077998994, "compression_ratio": 1.5686274509803921, "no_speech_prob": 4.425487077241996e-06}, {"id": 226, "seek": 105808, "start": 1076.32, "end": 1080.24, "text": " And then we go through the reversed list of filters, and go through those and adding up", "tokens": [51276, 400, 550, 321, 352, 807, 264, 30563, 1329, 295, 15995, 11, 293, 352, 807, 729, 293, 5127, 493, 51472], "temperature": 0.0, "avg_logprob": -0.34447996077998994, "compression_ratio": 1.5686274509803921, "no_speech_prob": 4.425487077241996e-06}, {"id": 227, "seek": 105808, "start": 1080.24, "end": 1081.8, "text": " blocks.", "tokens": [51472, 8474, 13, 51550], "temperature": 0.0, "avg_logprob": -0.34447996077998994, "compression_ratio": 1.5686274509803921, "no_speech_prob": 4.425487077241996e-06}, {"id": 228, "seek": 108180, "start": 1081.8, "end": 1089.24, "text": " And then one convolution at the end to turn it from 224 channels to three channels.", "tokens": [50364, 400, 550, 472, 45216, 412, 264, 917, 281, 1261, 309, 490, 5853, 19, 9235, 281, 1045, 9235, 13, 50736], "temperature": 0.0, "avg_logprob": -0.31728666478937323, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.0010817102156579494}, {"id": 229, "seek": 108180, "start": 1089.24, "end": 1099.52, "text": " Okay, and so the forward then is going to store in saved all the layers, just like we", "tokens": [50736, 1033, 11, 293, 370, 264, 2128, 550, 307, 516, 281, 3531, 294, 6624, 439, 264, 7914, 11, 445, 411, 321, 51250], "temperature": 0.0, "avg_logprob": -0.31728666478937323, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.0010817102156579494}, {"id": 230, "seek": 108180, "start": 1099.52, "end": 1107.04, "text": " did back with this unit.", "tokens": [51250, 630, 646, 365, 341, 4985, 13, 51626], "temperature": 0.0, "avg_logprob": -0.31728666478937323, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.0010817102156579494}, {"id": 231, "seek": 108180, "start": 1107.04, "end": 1108.68, "text": " But we don't really have to do it explicitly now.", "tokens": [51626, 583, 321, 500, 380, 534, 362, 281, 360, 309, 20803, 586, 13, 51708], "temperature": 0.0, "avg_logprob": -0.31728666478937323, "compression_ratio": 1.4523809523809523, "no_speech_prob": 0.0010817102156579494}, {"id": 232, "seek": 110868, "start": 1108.68, "end": 1115.2, "text": " We just call the sequential model, and thanks to our automatic saving, each of those now", "tokens": [50364, 492, 445, 818, 264, 42881, 2316, 11, 293, 3231, 281, 527, 12509, 6816, 11, 1184, 295, 729, 586, 50690], "temperature": 0.0, "avg_logprob": -0.3308762372550318, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.000527472875546664}, {"id": 233, "seek": 110868, "start": 1115.2, "end": 1119.92, "text": " will, we can just go through each of those and grab their dot saved.", "tokens": [50690, 486, 11, 321, 393, 445, 352, 807, 1184, 295, 729, 293, 4444, 641, 5893, 6624, 13, 50926], "temperature": 0.0, "avg_logprob": -0.3308762372550318, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.000527472875546664}, {"id": 234, "seek": 110868, "start": 1119.92, "end": 1122.3600000000001, "text": " So that's handy.", "tokens": [50926, 407, 300, 311, 13239, 13, 51048], "temperature": 0.0, "avg_logprob": -0.3308762372550318, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.000527472875546664}, {"id": 235, "seek": 110868, "start": 1122.3600000000001, "end": 1125.8, "text": " We then call that mid block, which is just another res block, and then same thing, okay,", "tokens": [51048, 492, 550, 818, 300, 2062, 3461, 11, 597, 307, 445, 1071, 725, 3461, 11, 293, 550, 912, 551, 11, 1392, 11, 51220], "temperature": 0.0, "avg_logprob": -0.3308762372550318, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.000527472875546664}, {"id": 236, "seek": 110868, "start": 1125.8, "end": 1130.4, "text": " now for the ups, and what we do is we just passed in those saved, right?", "tokens": [51220, 586, 337, 264, 15497, 11, 293, 437, 321, 360, 307, 321, 445, 4678, 294, 729, 6624, 11, 558, 30, 51450], "temperature": 0.0, "avg_logprob": -0.3308762372550318, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.000527472875546664}, {"id": 237, "seek": 110868, "start": 1130.4, "end": 1134.68, "text": " And just remember, it's going to dot pop them out each time.", "tokens": [51450, 400, 445, 1604, 11, 309, 311, 516, 281, 5893, 1665, 552, 484, 1184, 565, 13, 51664], "temperature": 0.0, "avg_logprob": -0.3308762372550318, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.000527472875546664}, {"id": 238, "seek": 110868, "start": 1134.68, "end": 1138.24, "text": " And then the conv at the end.", "tokens": [51664, 400, 550, 264, 3754, 412, 264, 917, 13, 51842], "temperature": 0.0, "avg_logprob": -0.3308762372550318, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.000527472875546664}, {"id": 239, "seek": 113824, "start": 1138.8, "end": 1140.08, "text": " So that's, yeah, that's it.", "tokens": [50392, 407, 300, 311, 11, 1338, 11, 300, 311, 309, 13, 50456], "temperature": 0.0, "avg_logprob": -0.2649464478363862, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.6964422684395686e-05}, {"id": 240, "seek": 113824, "start": 1140.08, "end": 1146.24, "text": " That's our unconditional model.", "tokens": [50456, 663, 311, 527, 47916, 2316, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2649464478363862, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.6964422684395686e-05}, {"id": 241, "seek": 113824, "start": 1146.24, "end": 1149.8, "text": " It's not quite the same as the diffuses unconditional model, because it doesn't have a tension,", "tokens": [50764, 467, 311, 406, 1596, 264, 912, 382, 264, 7593, 8355, 47916, 2316, 11, 570, 309, 1177, 380, 362, 257, 8980, 11, 50942], "temperature": 0.0, "avg_logprob": -0.2649464478363862, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.6964422684395686e-05}, {"id": 242, "seek": 113824, "start": 1149.8, "end": 1154.52, "text": " which is something we're going to add next.", "tokens": [50942, 597, 307, 746, 321, 434, 516, 281, 909, 958, 13, 51178], "temperature": 0.0, "avg_logprob": -0.2649464478363862, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.6964422684395686e-05}, {"id": 243, "seek": 113824, "start": 1154.52, "end": 1156.78, "text": " But other than that, this is the same.", "tokens": [51178, 583, 661, 813, 300, 11, 341, 307, 264, 912, 13, 51291], "temperature": 0.0, "avg_logprob": -0.2649464478363862, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.6964422684395686e-05}, {"id": 244, "seek": 113824, "start": 1156.78, "end": 1161.6, "text": " So let's, because we're doing a simpler problem, which is fashion MNIST, we'll use less channels", "tokens": [51291, 407, 718, 311, 11, 570, 321, 434, 884, 257, 18587, 1154, 11, 597, 307, 6700, 376, 45, 19756, 11, 321, 603, 764, 1570, 9235, 51532], "temperature": 0.0, "avg_logprob": -0.2649464478363862, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.6964422684395686e-05}, {"id": 245, "seek": 113824, "start": 1161.6, "end": 1163.56, "text": " than the default.", "tokens": [51532, 813, 264, 7576, 13, 51630], "temperature": 0.0, "avg_logprob": -0.2649464478363862, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.6964422684395686e-05}, {"id": 246, "seek": 113824, "start": 1163.56, "end": 1168.04, "text": " Using two layers per block is standard.", "tokens": [51630, 11142, 732, 7914, 680, 3461, 307, 3832, 13, 51854], "temperature": 0.0, "avg_logprob": -0.2649464478363862, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.6964422684395686e-05}, {"id": 247, "seek": 116804, "start": 1168.84, "end": 1172.32, "text": " One thing to note though, is that in the up sampling blocks, it actually is going to be", "tokens": [50404, 1485, 551, 281, 3637, 1673, 11, 307, 300, 294, 264, 493, 21179, 8474, 11, 309, 767, 307, 516, 281, 312, 50578], "temperature": 0.0, "avg_logprob": -0.27085332003506746, "compression_ratio": 1.8135593220338984, "no_speech_prob": 2.6688518119044602e-05}, {"id": 248, "seek": 116804, "start": 1172.32, "end": 1175.92, "text": " three layers, num layers plus one.", "tokens": [50578, 1045, 7914, 11, 1031, 7914, 1804, 472, 13, 50758], "temperature": 0.0, "avg_logprob": -0.27085332003506746, "compression_ratio": 1.8135593220338984, "no_speech_prob": 2.6688518119044602e-05}, {"id": 249, "seek": 116804, "start": 1175.92, "end": 1182.12, "text": " And the reason for that is that the way stable diffusion and diffuses do it, is that even", "tokens": [50758, 400, 264, 1778, 337, 300, 307, 300, 264, 636, 8351, 25242, 293, 7593, 8355, 360, 309, 11, 307, 300, 754, 51068], "temperature": 0.0, "avg_logprob": -0.27085332003506746, "compression_ratio": 1.8135593220338984, "no_speech_prob": 2.6688518119044602e-05}, {"id": 250, "seek": 116804, "start": 1182.12, "end": 1186.36, "text": " the output of the down sampling is also saved.", "tokens": [51068, 264, 5598, 295, 264, 760, 21179, 307, 611, 6624, 13, 51280], "temperature": 0.0, "avg_logprob": -0.27085332003506746, "compression_ratio": 1.8135593220338984, "no_speech_prob": 2.6688518119044602e-05}, {"id": 251, "seek": 116804, "start": 1186.36, "end": 1192.18, "text": " So if you have num layers equals two, then there'll be two res blocks saving things here,", "tokens": [51280, 407, 498, 291, 362, 1031, 7914, 6915, 732, 11, 550, 456, 603, 312, 732, 725, 8474, 6816, 721, 510, 11, 51571], "temperature": 0.0, "avg_logprob": -0.27085332003506746, "compression_ratio": 1.8135593220338984, "no_speech_prob": 2.6688518119044602e-05}, {"id": 252, "seek": 116804, "start": 1192.18, "end": 1194.1599999999999, "text": " and one conv saving things here.", "tokens": [51571, 293, 472, 3754, 6816, 721, 510, 13, 51670], "temperature": 0.0, "avg_logprob": -0.27085332003506746, "compression_ratio": 1.8135593220338984, "no_speech_prob": 2.6688518119044602e-05}, {"id": 253, "seek": 116804, "start": 1194.1599999999999, "end": 1197.98, "text": " So you'll have three saved cross connections.", "tokens": [51670, 407, 291, 603, 362, 1045, 6624, 3278, 9271, 13, 51861], "temperature": 0.0, "avg_logprob": -0.27085332003506746, "compression_ratio": 1.8135593220338984, "no_speech_prob": 2.6688518119044602e-05}, {"id": 254, "seek": 119798, "start": 1198.92, "end": 1204.6200000000001, "text": " So that's why there's an extra plus one here.", "tokens": [50411, 407, 300, 311, 983, 456, 311, 364, 2857, 1804, 472, 510, 13, 50696], "temperature": 0.0, "avg_logprob": -0.3965588641423051, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.00011774330050684512}, {"id": 255, "seek": 119798, "start": 1204.6200000000001, "end": 1211.42, "text": " Okay, and then we can just train it using mini AI, as per usual.", "tokens": [50696, 1033, 11, 293, 550, 321, 393, 445, 3847, 309, 1228, 8382, 7318, 11, 382, 680, 7713, 13, 51036], "temperature": 0.0, "avg_logprob": -0.3965588641423051, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.00011774330050684512}, {"id": 256, "seek": 119798, "start": 1211.42, "end": 1214.5, "text": " Nope, I didn't save it after I last trained it.", "tokens": [51036, 12172, 11, 286, 994, 380, 3155, 309, 934, 286, 1036, 8895, 309, 13, 51190], "temperature": 0.0, "avg_logprob": -0.3965588641423051, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.00011774330050684512}, {"id": 257, "seek": 119798, "start": 1214.5, "end": 1215.5, "text": " Sorry about that.", "tokens": [51190, 4919, 466, 300, 13, 51240], "temperature": 0.0, "avg_logprob": -0.3965588641423051, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.00011774330050684512}, {"id": 258, "seek": 119798, "start": 1215.5, "end": 1218.74, "text": " So trust me, it trained.", "tokens": [51240, 407, 3361, 385, 11, 309, 8895, 13, 51402], "temperature": 0.0, "avg_logprob": -0.3965588641423051, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.00011774330050684512}, {"id": 259, "seek": 119798, "start": 1218.74, "end": 1225.54, "text": " Okay, now that, oh, okay, no, that is actually missing something else important, as well", "tokens": [51402, 1033, 11, 586, 300, 11, 1954, 11, 1392, 11, 572, 11, 300, 307, 767, 5361, 746, 1646, 1021, 11, 382, 731, 51742], "temperature": 0.0, "avg_logprob": -0.3965588641423051, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.00011774330050684512}, {"id": 260, "seek": 119798, "start": 1225.54, "end": 1226.66, "text": " as attention.", "tokens": [51742, 382, 3202, 13, 51798], "temperature": 0.0, "avg_logprob": -0.3965588641423051, "compression_ratio": 1.5510204081632653, "no_speech_prob": 0.00011774330050684512}, {"id": 261, "seek": 122666, "start": 1226.66, "end": 1230.5800000000002, "text": " The other thing that's missing is that thing that we discovered is pretty important, which", "tokens": [50364, 440, 661, 551, 300, 311, 5361, 307, 300, 551, 300, 321, 6941, 307, 1238, 1021, 11, 597, 50560], "temperature": 0.0, "avg_logprob": -0.2564366427334872, "compression_ratio": 1.7721518987341771, "no_speech_prob": 7.141863170545548e-05}, {"id": 262, "seek": 122666, "start": 1230.5800000000002, "end": 1234.66, "text": " is the time embedding.", "tokens": [50560, 307, 264, 565, 12240, 3584, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2564366427334872, "compression_ratio": 1.7721518987341771, "no_speech_prob": 7.141863170545548e-05}, {"id": 263, "seek": 122666, "start": 1234.66, "end": 1238.3400000000001, "text": " So we already know that sampling doesn't work particularly well without time embedding,", "tokens": [50764, 407, 321, 1217, 458, 300, 21179, 1177, 380, 589, 4098, 731, 1553, 565, 12240, 3584, 11, 50948], "temperature": 0.0, "avg_logprob": -0.2564366427334872, "compression_ratio": 1.7721518987341771, "no_speech_prob": 7.141863170545548e-05}, {"id": 264, "seek": 122666, "start": 1238.3400000000001, "end": 1240.38, "text": " so I didn't even bother sampling this.", "tokens": [50948, 370, 286, 994, 380, 754, 8677, 21179, 341, 13, 51050], "temperature": 0.0, "avg_logprob": -0.2564366427334872, "compression_ratio": 1.7721518987341771, "no_speech_prob": 7.141863170545548e-05}, {"id": 265, "seek": 122666, "start": 1240.38, "end": 1243.94, "text": " I didn't want to add all this stuff necessary to make that work a bit better.", "tokens": [51050, 286, 994, 380, 528, 281, 909, 439, 341, 1507, 4818, 281, 652, 300, 589, 257, 857, 1101, 13, 51228], "temperature": 0.0, "avg_logprob": -0.2564366427334872, "compression_ratio": 1.7721518987341771, "no_speech_prob": 7.141863170545548e-05}, {"id": 266, "seek": 122666, "start": 1243.94, "end": 1248.5600000000002, "text": " I thought, let's just go ahead and do time embedding.", "tokens": [51228, 286, 1194, 11, 718, 311, 445, 352, 2286, 293, 360, 565, 12240, 3584, 13, 51459], "temperature": 0.0, "avg_logprob": -0.2564366427334872, "compression_ratio": 1.7721518987341771, "no_speech_prob": 7.141863170545548e-05}, {"id": 267, "seek": 122666, "start": 1248.5600000000002, "end": 1253.14, "text": " So time embedding, there's a few ways to do it.", "tokens": [51459, 407, 565, 12240, 3584, 11, 456, 311, 257, 1326, 2098, 281, 360, 309, 13, 51688], "temperature": 0.0, "avg_logprob": -0.2564366427334872, "compression_ratio": 1.7721518987341771, "no_speech_prob": 7.141863170545548e-05}, {"id": 268, "seek": 125314, "start": 1253.22, "end": 1260.5800000000002, "text": " The way it's done in stable diffusion is what's called sinusoidal embeddings.", "tokens": [50368, 440, 636, 309, 311, 1096, 294, 8351, 25242, 307, 437, 311, 1219, 41503, 17079, 304, 12240, 29432, 13, 50736], "temperature": 0.0, "avg_logprob": -0.21686877273931737, "compression_ratio": 1.6538461538461537, "no_speech_prob": 3.8228849007282406e-05}, {"id": 269, "seek": 125314, "start": 1260.5800000000002, "end": 1264.74, "text": " The basic idea, maybe we'll skip ahead a bit.", "tokens": [50736, 440, 3875, 1558, 11, 1310, 321, 603, 10023, 2286, 257, 857, 13, 50944], "temperature": 0.0, "avg_logprob": -0.21686877273931737, "compression_ratio": 1.6538461538461537, "no_speech_prob": 3.8228849007282406e-05}, {"id": 270, "seek": 125314, "start": 1264.74, "end": 1271.1000000000001, "text": " The basic idea is that we're going to create a res block with embeddings, where forward", "tokens": [50944, 440, 3875, 1558, 307, 300, 321, 434, 516, 281, 1884, 257, 725, 3461, 365, 12240, 29432, 11, 689, 2128, 51262], "temperature": 0.0, "avg_logprob": -0.21686877273931737, "compression_ratio": 1.6538461538461537, "no_speech_prob": 3.8228849007282406e-05}, {"id": 271, "seek": 125314, "start": 1271.1000000000001, "end": 1279.5, "text": " is not just going to get the activations, but it's also going to get t, which is a vector", "tokens": [51262, 307, 406, 445, 516, 281, 483, 264, 2430, 763, 11, 457, 309, 311, 611, 516, 281, 483, 256, 11, 597, 307, 257, 8062, 51682], "temperature": 0.0, "avg_logprob": -0.21686877273931737, "compression_ratio": 1.6538461538461537, "no_speech_prob": 3.8228849007282406e-05}, {"id": 272, "seek": 127950, "start": 1279.66, "end": 1283.7, "text": " that represents the embeddings of each time step.", "tokens": [50372, 300, 8855, 264, 12240, 29432, 295, 1184, 565, 1823, 13, 50574], "temperature": 0.0, "avg_logprob": -0.26725034360532407, "compression_ratio": 1.9490196078431372, "no_speech_prob": 0.0007096573826856911}, {"id": 273, "seek": 127950, "start": 1283.7, "end": 1287.38, "text": " So actually, it'll be a matrix, because it's for everything in the batch, but for one element", "tokens": [50574, 407, 767, 11, 309, 603, 312, 257, 8141, 11, 570, 309, 311, 337, 1203, 294, 264, 15245, 11, 457, 337, 472, 4478, 50758], "temperature": 0.0, "avg_logprob": -0.26725034360532407, "compression_ratio": 1.9490196078431372, "no_speech_prob": 0.0007096573826856911}, {"id": 274, "seek": 127950, "start": 1287.38, "end": 1289.22, "text": " of the batch, it's a vector.", "tokens": [50758, 295, 264, 15245, 11, 309, 311, 257, 8062, 13, 50850], "temperature": 0.0, "avg_logprob": -0.26725034360532407, "compression_ratio": 1.9490196078431372, "no_speech_prob": 0.0007096573826856911}, {"id": 275, "seek": 127950, "start": 1289.22, "end": 1293.32, "text": " And it's an embedding in exactly the same way as when we did NLP.", "tokens": [50850, 400, 309, 311, 364, 12240, 3584, 294, 2293, 264, 912, 636, 382, 562, 321, 630, 426, 45196, 13, 51055], "temperature": 0.0, "avg_logprob": -0.26725034360532407, "compression_ratio": 1.9490196078431372, "no_speech_prob": 0.0007096573826856911}, {"id": 276, "seek": 127950, "start": 1293.32, "end": 1299.14, "text": " Each token had an embedding, and so the word the would have an embedding, and the word", "tokens": [51055, 6947, 14862, 632, 364, 12240, 3584, 11, 293, 370, 264, 1349, 264, 576, 362, 364, 12240, 3584, 11, 293, 264, 1349, 51346], "temperature": 0.0, "avg_logprob": -0.26725034360532407, "compression_ratio": 1.9490196078431372, "no_speech_prob": 0.0007096573826856911}, {"id": 277, "seek": 127950, "start": 1299.14, "end": 1303.02, "text": " Jono would have an embedding, and the word Tanishq would have an embedding, although", "tokens": [51346, 7745, 78, 576, 362, 364, 12240, 3584, 11, 293, 264, 1349, 314, 7524, 80, 576, 362, 364, 12240, 3584, 11, 4878, 51540], "temperature": 0.0, "avg_logprob": -0.26725034360532407, "compression_ratio": 1.9490196078431372, "no_speech_prob": 0.0007096573826856911}, {"id": 278, "seek": 127950, "start": 1303.02, "end": 1308.26, "text": " Tanishq would probably actually be multiple tokens, until he's famous enough that he's", "tokens": [51540, 314, 7524, 80, 576, 1391, 767, 312, 3866, 22667, 11, 1826, 415, 311, 4618, 1547, 300, 415, 311, 51802], "temperature": 0.0, "avg_logprob": -0.26725034360532407, "compression_ratio": 1.9490196078431372, "no_speech_prob": 0.0007096573826856911}, {"id": 279, "seek": 130826, "start": 1308.3, "end": 1312.98, "text": " mentioned in nearly every piece of literature, at which point Tanishq will get his own token,", "tokens": [50366, 2835, 294, 6217, 633, 2522, 295, 10394, 11, 412, 597, 935, 314, 7524, 80, 486, 483, 702, 1065, 14862, 11, 50600], "temperature": 0.0, "avg_logprob": -0.346875928795856, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.007574687711894512}, {"id": 280, "seek": 130826, "start": 1312.98, "end": 1313.98, "text": " I expect.", "tokens": [50600, 286, 2066, 13, 50650], "temperature": 0.0, "avg_logprob": -0.346875928795856, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.007574687711894512}, {"id": 281, "seek": 130826, "start": 1313.98, "end": 1319.5, "text": " That's how you know when you've made it.", "tokens": [50650, 663, 311, 577, 291, 458, 562, 291, 600, 1027, 309, 13, 50926], "temperature": 0.0, "avg_logprob": -0.346875928795856, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.007574687711894512}, {"id": 282, "seek": 130826, "start": 1319.5, "end": 1321.9, "text": " So the time embedding will be the same.", "tokens": [50926, 407, 264, 565, 12240, 3584, 486, 312, 264, 912, 13, 51046], "temperature": 0.0, "avg_logprob": -0.346875928795856, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.007574687711894512}, {"id": 283, "seek": 130826, "start": 1321.9, "end": 1327.22, "text": " T of, you know, time step zero will have a particular vector, time step one will have", "tokens": [51046, 314, 295, 11, 291, 458, 11, 565, 1823, 4018, 486, 362, 257, 1729, 8062, 11, 565, 1823, 472, 486, 362, 51312], "temperature": 0.0, "avg_logprob": -0.346875928795856, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.007574687711894512}, {"id": 284, "seek": 130826, "start": 1327.22, "end": 1330.62, "text": " a particular vector, and so forth.", "tokens": [51312, 257, 1729, 8062, 11, 293, 370, 5220, 13, 51482], "temperature": 0.0, "avg_logprob": -0.346875928795856, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.007574687711894512}, {"id": 285, "seek": 130826, "start": 1330.62, "end": 1335.02, "text": " Or actually, you know, we're doing keras, so actually they're not time step one, two,", "tokens": [51482, 1610, 767, 11, 291, 458, 11, 321, 434, 884, 350, 6985, 11, 370, 767, 436, 434, 406, 565, 1823, 472, 11, 732, 11, 51702], "temperature": 0.0, "avg_logprob": -0.346875928795856, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.007574687711894512}, {"id": 286, "seek": 130826, "start": 1335.02, "end": 1336.02, "text": " three.", "tokens": [51702, 1045, 13, 51752], "temperature": 0.0, "avg_logprob": -0.346875928795856, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.007574687711894512}, {"id": 287, "seek": 133602, "start": 1336.06, "end": 1341.74, "text": " They're actually sigmas, you know, so they're continuous, but same idea.", "tokens": [50366, 814, 434, 767, 4556, 3799, 11, 291, 458, 11, 370, 436, 434, 10957, 11, 457, 912, 1558, 13, 50650], "temperature": 0.0, "avg_logprob": -0.2865096028645833, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.00015843499568291008}, {"id": 288, "seek": 133602, "start": 1341.74, "end": 1349.74, "text": " A specific value of sigma, which is actually what T is going to be, slightly confusingly,", "tokens": [50650, 316, 2685, 2158, 295, 12771, 11, 597, 307, 767, 437, 314, 307, 516, 281, 312, 11, 4748, 13181, 356, 11, 51050], "temperature": 0.0, "avg_logprob": -0.2865096028645833, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.00015843499568291008}, {"id": 289, "seek": 133602, "start": 1349.74, "end": 1352.66, "text": " will have a specific embedding.", "tokens": [51050, 486, 362, 257, 2685, 12240, 3584, 13, 51196], "temperature": 0.0, "avg_logprob": -0.2865096028645833, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.00015843499568291008}, {"id": 290, "seek": 133602, "start": 1352.66, "end": 1361.1, "text": " Now we want two values of sigma or T, which are very close to each other, should have", "tokens": [51196, 823, 321, 528, 732, 4190, 295, 12771, 420, 314, 11, 597, 366, 588, 1998, 281, 1184, 661, 11, 820, 362, 51618], "temperature": 0.0, "avg_logprob": -0.2865096028645833, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.00015843499568291008}, {"id": 291, "seek": 136110, "start": 1361.82, "end": 1366.86, "text": " similar embeddings, and if they're different to each other, they should have different", "tokens": [50400, 2531, 12240, 29432, 11, 293, 498, 436, 434, 819, 281, 1184, 661, 11, 436, 820, 362, 819, 50652], "temperature": 0.0, "avg_logprob": -0.26123597886827254, "compression_ratio": 1.6700507614213198, "no_speech_prob": 5.064460856374353e-05}, {"id": 292, "seek": 136110, "start": 1366.86, "end": 1367.86, "text": " embeddings.", "tokens": [50652, 12240, 29432, 13, 50702], "temperature": 0.0, "avg_logprob": -0.26123597886827254, "compression_ratio": 1.6700507614213198, "no_speech_prob": 5.064460856374353e-05}, {"id": 293, "seek": 136110, "start": 1367.86, "end": 1375.6599999999999, "text": " So how do we make that happen, you know, and also make sure there's a lot of variety of", "tokens": [50702, 407, 577, 360, 321, 652, 300, 1051, 11, 291, 458, 11, 293, 611, 652, 988, 456, 311, 257, 688, 295, 5673, 295, 51092], "temperature": 0.0, "avg_logprob": -0.26123597886827254, "compression_ratio": 1.6700507614213198, "no_speech_prob": 5.064460856374353e-05}, {"id": 294, "seek": 136110, "start": 1375.6599999999999, "end": 1378.4199999999998, "text": " the embeddings across all the possibilities.", "tokens": [51092, 264, 12240, 29432, 2108, 439, 264, 12178, 13, 51230], "temperature": 0.0, "avg_logprob": -0.26123597886827254, "compression_ratio": 1.6700507614213198, "no_speech_prob": 5.064460856374353e-05}, {"id": 295, "seek": 136110, "start": 1378.4199999999998, "end": 1384.34, "text": " So the way we do that is with these sinusoidal time steps.", "tokens": [51230, 407, 264, 636, 321, 360, 300, 307, 365, 613, 41503, 17079, 304, 565, 4439, 13, 51526], "temperature": 0.0, "avg_logprob": -0.26123597886827254, "compression_ratio": 1.6700507614213198, "no_speech_prob": 5.064460856374353e-05}, {"id": 296, "seek": 136110, "start": 1384.34, "end": 1386.56, "text": " So let's have a look at how they work.", "tokens": [51526, 407, 718, 311, 362, 257, 574, 412, 577, 436, 589, 13, 51637], "temperature": 0.0, "avg_logprob": -0.26123597886827254, "compression_ratio": 1.6700507614213198, "no_speech_prob": 5.064460856374353e-05}, {"id": 297, "seek": 138656, "start": 1386.56, "end": 1391.48, "text": " So you first have to decide how big do you want your embeddings to be, just like we do", "tokens": [50364, 407, 291, 700, 362, 281, 4536, 577, 955, 360, 291, 528, 428, 12240, 29432, 281, 312, 11, 445, 411, 321, 360, 50610], "temperature": 0.0, "avg_logprob": -0.3083675497829324, "compression_ratio": 1.52, "no_speech_prob": 0.002182526048272848}, {"id": 298, "seek": 138656, "start": 1391.48, "end": 1392.48, "text": " in NLP.", "tokens": [50610, 294, 426, 45196, 13, 50660], "temperature": 0.0, "avg_logprob": -0.3083675497829324, "compression_ratio": 1.52, "no_speech_prob": 0.002182526048272848}, {"id": 299, "seek": 138656, "start": 1392.48, "end": 1400.32, "text": " Does the word the, is it represented by eight floats, or 16 floats, or 400 floats, or whatever?", "tokens": [50660, 4402, 264, 1349, 264, 11, 307, 309, 10379, 538, 3180, 37878, 11, 420, 3165, 37878, 11, 420, 8423, 37878, 11, 420, 2035, 30, 51052], "temperature": 0.0, "avg_logprob": -0.3083675497829324, "compression_ratio": 1.52, "no_speech_prob": 0.002182526048272848}, {"id": 300, "seek": 138656, "start": 1400.32, "end": 1403.22, "text": " Let's just assume it's 16.", "tokens": [51052, 961, 311, 445, 6552, 309, 311, 3165, 13, 51197], "temperature": 0.0, "avg_logprob": -0.3083675497829324, "compression_ratio": 1.52, "no_speech_prob": 0.002182526048272848}, {"id": 301, "seek": 138656, "start": 1403.22, "end": 1409.3999999999999, "text": " So let's say we're just looking at a bunch of time steps which is between negative 10", "tokens": [51197, 407, 718, 311, 584, 321, 434, 445, 1237, 412, 257, 3840, 295, 565, 4439, 597, 307, 1296, 3671, 1266, 51506], "temperature": 0.0, "avg_logprob": -0.3083675497829324, "compression_ratio": 1.52, "no_speech_prob": 0.002182526048272848}, {"id": 302, "seek": 138656, "start": 1409.3999999999999, "end": 1411.44, "text": " and 10, and we'll just do 100 of them.", "tokens": [51506, 293, 1266, 11, 293, 321, 603, 445, 360, 2319, 295, 552, 13, 51608], "temperature": 0.0, "avg_logprob": -0.3083675497829324, "compression_ratio": 1.52, "no_speech_prob": 0.002182526048272848}, {"id": 303, "seek": 141144, "start": 1411.52, "end": 1416.6000000000001, "text": " I mean, we don't actually have negative sigmas or T, so it doesn't exactly make sense, but", "tokens": [50368, 286, 914, 11, 321, 500, 380, 767, 362, 3671, 4556, 3799, 420, 314, 11, 370, 309, 1177, 380, 2293, 652, 2020, 11, 457, 50622], "temperature": 0.0, "avg_logprob": -0.34285829652030514, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.0005884025013074279}, {"id": 304, "seek": 141144, "start": 1416.6000000000001, "end": 1421.88, "text": " it doesn't matter, it's, you know, it just shows you the idea.", "tokens": [50622, 309, 1177, 380, 1871, 11, 309, 311, 11, 291, 458, 11, 309, 445, 3110, 291, 264, 1558, 13, 50886], "temperature": 0.0, "avg_logprob": -0.34285829652030514, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.0005884025013074279}, {"id": 305, "seek": 141144, "start": 1421.88, "end": 1427.6000000000001, "text": " And so then we say like, okay, what's the largest time step you could have, or the largest", "tokens": [50886, 400, 370, 550, 321, 584, 411, 11, 1392, 11, 437, 311, 264, 6443, 565, 1823, 291, 727, 362, 11, 420, 264, 6443, 51172], "temperature": 0.0, "avg_logprob": -0.34285829652030514, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.0005884025013074279}, {"id": 306, "seek": 141144, "start": 1427.6000000000001, "end": 1429.8, "text": " sigma that you could have?", "tokens": [51172, 12771, 300, 291, 727, 362, 30, 51282], "temperature": 0.0, "avg_logprob": -0.34285829652030514, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.0005884025013074279}, {"id": 307, "seek": 141144, "start": 1429.8, "end": 1435.56, "text": " Interestingly, every single model I've found, every single model I've found, uses 10,000", "tokens": [51282, 30564, 11, 633, 2167, 2316, 286, 600, 1352, 11, 633, 2167, 2316, 286, 600, 1352, 11, 4960, 1266, 11, 1360, 51570], "temperature": 0.0, "avg_logprob": -0.34285829652030514, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.0005884025013074279}, {"id": 308, "seek": 141144, "start": 1435.56, "end": 1436.56, "text": " for this.", "tokens": [51570, 337, 341, 13, 51620], "temperature": 0.0, "avg_logprob": -0.34285829652030514, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.0005884025013074279}, {"id": 309, "seek": 143656, "start": 1437.28, "end": 1441.6799999999998, "text": " Even though that number actually comes from the NLP Transformers literature, and it's", "tokens": [50400, 2754, 1673, 300, 1230, 767, 1487, 490, 264, 426, 45196, 27938, 433, 10394, 11, 293, 309, 311, 50620], "temperature": 0.0, "avg_logprob": -0.28702752981612933, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0010004943469539285}, {"id": 310, "seek": 143656, "start": 1441.6799999999998, "end": 1445.8, "text": " based on the idea of like, okay, what's the maximum sequence length we support?", "tokens": [50620, 2361, 322, 264, 1558, 295, 411, 11, 1392, 11, 437, 311, 264, 6674, 8310, 4641, 321, 1406, 30, 50826], "temperature": 0.0, "avg_logprob": -0.28702752981612933, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0010004943469539285}, {"id": 311, "seek": 143656, "start": 1445.8, "end": 1454.28, "text": " You can have up to 10,000 things in a, you know, in a document, or whatever, in a sequence.", "tokens": [50826, 509, 393, 362, 493, 281, 1266, 11, 1360, 721, 294, 257, 11, 291, 458, 11, 294, 257, 4166, 11, 420, 2035, 11, 294, 257, 8310, 13, 51250], "temperature": 0.0, "avg_logprob": -0.28702752981612933, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0010004943469539285}, {"id": 312, "seek": 143656, "start": 1454.28, "end": 1456.36, "text": " But we don't actually have a sigmas that go up to 10,000.", "tokens": [51250, 583, 321, 500, 380, 767, 362, 257, 4556, 3799, 300, 352, 493, 281, 1266, 11, 1360, 13, 51354], "temperature": 0.0, "avg_logprob": -0.28702752981612933, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0010004943469539285}, {"id": 313, "seek": 143656, "start": 1456.36, "end": 1460.1599999999999, "text": " So I'm using the number that's used in real life in stable diffusion and all the other", "tokens": [51354, 407, 286, 478, 1228, 264, 1230, 300, 311, 1143, 294, 957, 993, 294, 8351, 25242, 293, 439, 264, 661, 51544], "temperature": 0.0, "avg_logprob": -0.28702752981612933, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0010004943469539285}, {"id": 314, "seek": 143656, "start": 1460.1599999999999, "end": 1465.32, "text": " models, but it's interestingly, this is here purely, as far as I can tell, as a hysterical", "tokens": [51544, 5245, 11, 457, 309, 311, 25873, 11, 341, 307, 510, 17491, 11, 382, 1400, 382, 286, 393, 980, 11, 382, 257, 35915, 804, 51802], "temperature": 0.0, "avg_logprob": -0.28702752981612933, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0010004943469539285}, {"id": 315, "seek": 146532, "start": 1465.32, "end": 1471.24, "text": " accident, because this is like the maximum sequence length that NLP Transformers people", "tokens": [50364, 6398, 11, 570, 341, 307, 411, 264, 6674, 8310, 4641, 300, 426, 45196, 27938, 433, 561, 50660], "temperature": 0.0, "avg_logprob": -0.2766329275595175, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.00015356228686869144}, {"id": 316, "seek": 146532, "start": 1471.24, "end": 1473.9199999999998, "text": " thought they would need to support.", "tokens": [50660, 1194, 436, 576, 643, 281, 1406, 13, 50794], "temperature": 0.0, "avg_logprob": -0.2766329275595175, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.00015356228686869144}, {"id": 317, "seek": 146532, "start": 1473.9199999999998, "end": 1482.6799999999998, "text": " Okay, now, what we're then going to do is we're going to be then doing e to the power", "tokens": [50794, 1033, 11, 586, 11, 437, 321, 434, 550, 516, 281, 360, 307, 321, 434, 516, 281, 312, 550, 884, 308, 281, 264, 1347, 51232], "temperature": 0.0, "avg_logprob": -0.2766329275595175, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.00015356228686869144}, {"id": 318, "seek": 146532, "start": 1482.6799999999998, "end": 1485.32, "text": " of a bunch of things.", "tokens": [51232, 295, 257, 3840, 295, 721, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2766329275595175, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.00015356228686869144}, {"id": 319, "seek": 146532, "start": 1485.32, "end": 1487.76, "text": " And so that's going to be our exponent.", "tokens": [51364, 400, 370, 300, 311, 516, 281, 312, 527, 37871, 13, 51486], "temperature": 0.0, "avg_logprob": -0.2766329275595175, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.00015356228686869144}, {"id": 320, "seek": 148776, "start": 1487.76, "end": 1494.32, "text": " And so our exponent is going to be equal to log of the period, which is about nine,", "tokens": [50364, 400, 370, 527, 37871, 307, 516, 281, 312, 2681, 281, 3565, 295, 264, 2896, 11, 597, 307, 466, 4949, 11, 50692], "temperature": 0.0, "avg_logprob": -0.30322804170496326, "compression_ratio": 1.5078534031413613, "no_speech_prob": 0.0008295495645143092}, {"id": 321, "seek": 148776, "start": 1494.32, "end": 1504.28, "text": " times the numbers between 0 and 1, 8 of them, because we've got, we said we want 16.", "tokens": [50692, 1413, 264, 3547, 1296, 1958, 293, 502, 11, 1649, 295, 552, 11, 570, 321, 600, 658, 11, 321, 848, 321, 528, 3165, 13, 51190], "temperature": 0.0, "avg_logprob": -0.30322804170496326, "compression_ratio": 1.5078534031413613, "no_speech_prob": 0.0008295495645143092}, {"id": 322, "seek": 148776, "start": 1504.28, "end": 1507.12, "text": " So you'll see why we want 8 of them and not 16 in a moment.", "tokens": [51190, 407, 291, 603, 536, 983, 321, 528, 1649, 295, 552, 293, 406, 3165, 294, 257, 1623, 13, 51332], "temperature": 0.0, "avg_logprob": -0.30322804170496326, "compression_ratio": 1.5078534031413613, "no_speech_prob": 0.0008295495645143092}, {"id": 323, "seek": 148776, "start": 1507.12, "end": 1513.52, "text": " But basically, here are the 8 exponents we're going to use.", "tokens": [51332, 583, 1936, 11, 510, 366, 264, 1649, 12680, 791, 321, 434, 516, 281, 764, 13, 51652], "temperature": 0.0, "avg_logprob": -0.30322804170496326, "compression_ratio": 1.5078534031413613, "no_speech_prob": 0.0008295495645143092}, {"id": 324, "seek": 151352, "start": 1513.52, "end": 1518.48, "text": " So then, not surprisingly, we do e to the power of that.", "tokens": [50364, 407, 550, 11, 406, 17600, 11, 321, 360, 308, 281, 264, 1347, 295, 300, 13, 50612], "temperature": 0.0, "avg_logprob": -0.28289072701100554, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.0009697246132418513}, {"id": 325, "seek": 151352, "start": 1518.48, "end": 1524.02, "text": " So we do e to the power of that, each of these 8 things.", "tokens": [50612, 407, 321, 360, 308, 281, 264, 1347, 295, 300, 11, 1184, 295, 613, 1649, 721, 13, 50889], "temperature": 0.0, "avg_logprob": -0.28289072701100554, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.0009697246132418513}, {"id": 326, "seek": 151352, "start": 1524.02, "end": 1529.04, "text": " And we've also got the actual time steps.", "tokens": [50889, 400, 321, 600, 611, 658, 264, 3539, 565, 4439, 13, 51140], "temperature": 0.0, "avg_logprob": -0.28289072701100554, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.0009697246132418513}, {"id": 327, "seek": 151352, "start": 1529.04, "end": 1532.32, "text": " So imagine these are the actual time steps we have in our batch.", "tokens": [51140, 407, 3811, 613, 366, 264, 3539, 565, 4439, 321, 362, 294, 527, 15245, 13, 51304], "temperature": 0.0, "avg_logprob": -0.28289072701100554, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.0009697246132418513}, {"id": 328, "seek": 151352, "start": 1532.32, "end": 1540.12, "text": " So there's a batch of 100, and they contain these, this range of sigmas or time steps.", "tokens": [51304, 407, 456, 311, 257, 15245, 295, 2319, 11, 293, 436, 5304, 613, 11, 341, 3613, 295, 4556, 3799, 420, 565, 4439, 13, 51694], "temperature": 0.0, "avg_logprob": -0.28289072701100554, "compression_ratio": 1.7542857142857142, "no_speech_prob": 0.0009697246132418513}, {"id": 329, "seek": 154012, "start": 1540.12, "end": 1551.1599999999999, "text": " So to create our embeddings, what we do is we do a outer product of the exponent.exp", "tokens": [50364, 407, 281, 1884, 527, 12240, 29432, 11, 437, 321, 360, 307, 321, 360, 257, 10847, 1674, 295, 264, 37871, 13, 15952, 50916], "temperature": 0.0, "avg_logprob": -0.3105327606201172, "compression_ratio": 1.5730994152046784, "no_speech_prob": 7.843726052669808e-05}, {"id": 330, "seek": 154012, "start": 1551.1599999999999, "end": 1552.1599999999999, "text": " and the time steps.", "tokens": [50916, 293, 264, 565, 4439, 13, 50966], "temperature": 0.0, "avg_logprob": -0.3105327606201172, "compression_ratio": 1.5730994152046784, "no_speech_prob": 7.843726052669808e-05}, {"id": 331, "seek": 154012, "start": 1552.1599999999999, "end": 1554.1599999999999, "text": " This is step 1.", "tokens": [50966, 639, 307, 1823, 502, 13, 51066], "temperature": 0.0, "avg_logprob": -0.3105327606201172, "compression_ratio": 1.5730994152046784, "no_speech_prob": 7.843726052669808e-05}, {"id": 332, "seek": 154012, "start": 1554.1599999999999, "end": 1559.1999999999998, "text": " And so this is using a broadcasting trick we've seen before.", "tokens": [51066, 400, 370, 341, 307, 1228, 257, 30024, 4282, 321, 600, 1612, 949, 13, 51318], "temperature": 0.0, "avg_logprob": -0.3105327606201172, "compression_ratio": 1.5730994152046784, "no_speech_prob": 7.843726052669808e-05}, {"id": 333, "seek": 154012, "start": 1559.1999999999998, "end": 1568.9599999999998, "text": " We add a unit access, an access 0 here, and add a unit access, sorry, an access 1 here,", "tokens": [51318, 492, 909, 257, 4985, 2105, 11, 364, 2105, 1958, 510, 11, 293, 909, 257, 4985, 2105, 11, 2597, 11, 364, 2105, 502, 510, 11, 51806], "temperature": 0.0, "avg_logprob": -0.3105327606201172, "compression_ratio": 1.5730994152046784, "no_speech_prob": 7.843726052669808e-05}, {"id": 334, "seek": 156896, "start": 1568.96, "end": 1573.76, "text": " and add a unit access, an access 0 here.", "tokens": [50364, 293, 909, 257, 4985, 2105, 11, 364, 2105, 1958, 510, 13, 50604], "temperature": 0.0, "avg_logprob": -0.2610140512155932, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.00011774350423365831}, {"id": 335, "seek": 156896, "start": 1573.76, "end": 1582.52, "text": " So if we multiply those together, then it's going to broadcast this one across this axis,", "tokens": [50604, 407, 498, 321, 12972, 729, 1214, 11, 550, 309, 311, 516, 281, 9975, 341, 472, 2108, 341, 10298, 11, 51042], "temperature": 0.0, "avg_logprob": -0.2610140512155932, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.00011774350423365831}, {"id": 336, "seek": 156896, "start": 1582.52, "end": 1584.6000000000001, "text": " and this one across this axis.", "tokens": [51042, 293, 341, 472, 2108, 341, 10298, 13, 51146], "temperature": 0.0, "avg_logprob": -0.2610140512155932, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.00011774350423365831}, {"id": 337, "seek": 156896, "start": 1584.6000000000001, "end": 1586.72, "text": " So we end up with a 100 by 8.", "tokens": [51146, 407, 321, 917, 493, 365, 257, 2319, 538, 1649, 13, 51252], "temperature": 0.0, "avg_logprob": -0.2610140512155932, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.00011774350423365831}, {"id": 338, "seek": 156896, "start": 1586.72, "end": 1591.44, "text": " So it's basically, you know, a Cartesian product, all the possible combinations of time step", "tokens": [51252, 407, 309, 311, 1936, 11, 291, 458, 11, 257, 22478, 42434, 1674, 11, 439, 264, 1944, 21267, 295, 565, 1823, 51488], "temperature": 0.0, "avg_logprob": -0.2610140512155932, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.00011774350423365831}, {"id": 339, "seek": 156896, "start": 1591.44, "end": 1596.1000000000001, "text": " and exponent multiplied together.", "tokens": [51488, 293, 37871, 17207, 1214, 13, 51721], "temperature": 0.0, "avg_logprob": -0.2610140512155932, "compression_ratio": 1.5979899497487438, "no_speech_prob": 0.00011774350423365831}, {"id": 340, "seek": 159610, "start": 1596.24, "end": 1605.1, "text": " And so here's like, you know, a few of those different exponents for a few different values.", "tokens": [50371, 400, 370, 510, 311, 411, 11, 291, 458, 11, 257, 1326, 295, 729, 819, 12680, 791, 337, 257, 1326, 819, 4190, 13, 50814], "temperature": 0.0, "avg_logprob": -0.3007229850405738, "compression_ratio": 1.6580310880829014, "no_speech_prob": 4.6837998525006697e-05}, {"id": 341, "seek": 159610, "start": 1605.1, "end": 1614.4199999999998, "text": " Okay, so that's not very interesting yet.", "tokens": [50814, 1033, 11, 370, 300, 311, 406, 588, 1880, 1939, 13, 51280], "temperature": 0.0, "avg_logprob": -0.3007229850405738, "compression_ratio": 1.6580310880829014, "no_speech_prob": 4.6837998525006697e-05}, {"id": 342, "seek": 159610, "start": 1614.4199999999998, "end": 1619.2199999999998, "text": " We haven't yet reached something where each time step is similar to each next door time", "tokens": [51280, 492, 2378, 380, 1939, 6488, 746, 689, 1184, 565, 1823, 307, 2531, 281, 1184, 958, 2853, 565, 51520], "temperature": 0.0, "avg_logprob": -0.3007229850405738, "compression_ratio": 1.6580310880829014, "no_speech_prob": 4.6837998525006697e-05}, {"id": 343, "seek": 159610, "start": 1619.2199999999998, "end": 1620.2199999999998, "text": " step.", "tokens": [51520, 1823, 13, 51570], "temperature": 0.0, "avg_logprob": -0.3007229850405738, "compression_ratio": 1.6580310880829014, "no_speech_prob": 4.6837998525006697e-05}, {"id": 344, "seek": 159610, "start": 1620.2199999999998, "end": 1625.1399999999999, "text": " You know, over here, you know, these embeddings look very different to each other, and over", "tokens": [51570, 509, 458, 11, 670, 510, 11, 291, 458, 11, 613, 12240, 29432, 574, 588, 819, 281, 1184, 661, 11, 293, 670, 51816], "temperature": 0.0, "avg_logprob": -0.3007229850405738, "compression_ratio": 1.6580310880829014, "no_speech_prob": 4.6837998525006697e-05}, {"id": 345, "seek": 162514, "start": 1625.18, "end": 1627.94, "text": " here, they're very similar.", "tokens": [50366, 510, 11, 436, 434, 588, 2531, 13, 50504], "temperature": 0.0, "avg_logprob": -0.18428873637365917, "compression_ratio": 1.5511811023622046, "no_speech_prob": 5.5621927458560094e-05}, {"id": 346, "seek": 162514, "start": 1627.94, "end": 1638.2800000000002, "text": " So what we then do is we take the sine and the cosine of those.", "tokens": [50504, 407, 437, 321, 550, 360, 307, 321, 747, 264, 18609, 293, 264, 23565, 295, 729, 13, 51021], "temperature": 0.0, "avg_logprob": -0.18428873637365917, "compression_ratio": 1.5511811023622046, "no_speech_prob": 5.5621927458560094e-05}, {"id": 347, "seek": 162514, "start": 1638.2800000000002, "end": 1650.0200000000002, "text": " So that is 100 by 8, and that is 100 by 8, and that gives us 100 by 16.", "tokens": [51021, 407, 300, 307, 2319, 538, 1649, 11, 293, 300, 307, 2319, 538, 1649, 11, 293, 300, 2709, 505, 2319, 538, 3165, 13, 51608], "temperature": 0.0, "avg_logprob": -0.18428873637365917, "compression_ratio": 1.5511811023622046, "no_speech_prob": 5.5621927458560094e-05}, {"id": 348, "seek": 162514, "start": 1650.0200000000002, "end": 1653.98, "text": " So we concatenate those together.", "tokens": [51608, 407, 321, 1588, 7186, 473, 729, 1214, 13, 51806], "temperature": 0.0, "avg_logprob": -0.18428873637365917, "compression_ratio": 1.5511811023622046, "no_speech_prob": 5.5621927458560094e-05}, {"id": 349, "seek": 165398, "start": 1654.02, "end": 1658.06, "text": " And so that's a little bit hard to wrap your head around, so let's take a look.", "tokens": [50366, 400, 370, 300, 311, 257, 707, 857, 1152, 281, 7019, 428, 1378, 926, 11, 370, 718, 311, 747, 257, 574, 13, 50568], "temperature": 0.0, "avg_logprob": -0.28650047665550593, "compression_ratio": 1.4930555555555556, "no_speech_prob": 0.0006666327826678753}, {"id": 350, "seek": 165398, "start": 1658.06, "end": 1671.02, "text": " So the, across the 100 time steps, or 100 sigmas, this one here is the first sine wave.", "tokens": [50568, 407, 264, 11, 2108, 264, 2319, 565, 4439, 11, 420, 2319, 4556, 3799, 11, 341, 472, 510, 307, 264, 700, 18609, 5772, 13, 51216], "temperature": 0.0, "avg_logprob": -0.28650047665550593, "compression_ratio": 1.4930555555555556, "no_speech_prob": 0.0006666327826678753}, {"id": 351, "seek": 165398, "start": 1671.02, "end": 1677.34, "text": " And then this one here is the second sine wave.", "tokens": [51216, 400, 550, 341, 472, 510, 307, 264, 1150, 18609, 5772, 13, 51532], "temperature": 0.0, "avg_logprob": -0.28650047665550593, "compression_ratio": 1.4930555555555556, "no_speech_prob": 0.0006666327826678753}, {"id": 352, "seek": 167734, "start": 1677.34, "end": 1680.54, "text": " And this one here is the third.", "tokens": [50364, 400, 341, 472, 510, 307, 264, 2636, 13, 50524], "temperature": 0.0, "avg_logprob": -0.2570155502913834, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0008295772131532431}, {"id": 353, "seek": 167734, "start": 1680.54, "end": 1685.02, "text": " And this one here is the fourth and the fifth.", "tokens": [50524, 400, 341, 472, 510, 307, 264, 6409, 293, 264, 9266, 13, 50748], "temperature": 0.0, "avg_logprob": -0.2570155502913834, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0008295772131532431}, {"id": 354, "seek": 167734, "start": 1685.02, "end": 1693.58, "text": " So you can see as you go up to higher numbers, you're basically, you know, stretching the", "tokens": [50748, 407, 291, 393, 536, 382, 291, 352, 493, 281, 2946, 3547, 11, 291, 434, 1936, 11, 291, 458, 11, 19632, 264, 51176], "temperature": 0.0, "avg_logprob": -0.2570155502913834, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0008295772131532431}, {"id": 355, "seek": 167734, "start": 1693.58, "end": 1697.1399999999999, "text": " sine wave out.", "tokens": [51176, 18609, 5772, 484, 13, 51354], "temperature": 0.0, "avg_logprob": -0.2570155502913834, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0008295772131532431}, {"id": 356, "seek": 167734, "start": 1697.1399999999999, "end": 1704.58, "text": " And then once you get up to index 8, you're back up to the same frequency as this blue", "tokens": [51354, 400, 550, 1564, 291, 483, 493, 281, 8186, 1649, 11, 291, 434, 646, 493, 281, 264, 912, 7893, 382, 341, 3344, 51726], "temperature": 0.0, "avg_logprob": -0.2570155502913834, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0008295772131532431}, {"id": 357, "seek": 170458, "start": 1704.58, "end": 1708.62, "text": " one, because now we're starting the cosine rather than sine.", "tokens": [50364, 472, 11, 570, 586, 321, 434, 2891, 264, 23565, 2831, 813, 18609, 13, 50566], "temperature": 0.0, "avg_logprob": -0.2882107925415039, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.010817167349159718}, {"id": 358, "seek": 170458, "start": 1708.62, "end": 1711.78, "text": " And cosine is identical to sine, it's just shifted across a tiny bit.", "tokens": [50566, 400, 23565, 307, 14800, 281, 18609, 11, 309, 311, 445, 18892, 2108, 257, 5870, 857, 13, 50724], "temperature": 0.0, "avg_logprob": -0.2882107925415039, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.010817167349159718}, {"id": 359, "seek": 170458, "start": 1711.78, "end": 1716.3799999999999, "text": " So you can see these two light blue lines are the same, and these two orange lines are", "tokens": [50724, 407, 291, 393, 536, 613, 732, 1442, 3344, 3876, 366, 264, 912, 11, 293, 613, 732, 7671, 3876, 366, 50954], "temperature": 0.0, "avg_logprob": -0.2882107925415039, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.010817167349159718}, {"id": 360, "seek": 170458, "start": 1716.3799999999999, "end": 1718.1799999999998, "text": " the same, they're just shifted across.", "tokens": [50954, 264, 912, 11, 436, 434, 445, 18892, 2108, 13, 51044], "temperature": 0.0, "avg_logprob": -0.2882107925415039, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.010817167349159718}, {"id": 361, "seek": 170458, "start": 1718.1799999999998, "end": 1722.9399999999998, "text": " I shouldn't say lines, sorry, curves.", "tokens": [51044, 286, 4659, 380, 584, 3876, 11, 2597, 11, 19490, 13, 51282], "temperature": 0.0, "avg_logprob": -0.2882107925415039, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.010817167349159718}, {"id": 362, "seek": 170458, "start": 1722.9399999999998, "end": 1727.32, "text": " So when we concatenate those all together, we can actually draw a picture of it.", "tokens": [51282, 407, 562, 321, 1588, 7186, 473, 729, 439, 1214, 11, 321, 393, 767, 2642, 257, 3036, 295, 309, 13, 51501], "temperature": 0.0, "avg_logprob": -0.2882107925415039, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.010817167349159718}, {"id": 363, "seek": 172732, "start": 1727.32, "end": 1736.2, "text": " And so this picture is 100 pixels across, and 16 pixels top to bottom.", "tokens": [50364, 400, 370, 341, 3036, 307, 2319, 18668, 2108, 11, 293, 3165, 18668, 1192, 281, 2767, 13, 50808], "temperature": 0.0, "avg_logprob": -0.29223734537760415, "compression_ratio": 1.5638297872340425, "no_speech_prob": 0.0005702790804207325}, {"id": 364, "seek": 172732, "start": 1736.2, "end": 1741.0, "text": " And so if you picked out a particular point, so for example in the middle here, for t equals", "tokens": [50808, 400, 370, 498, 291, 6183, 484, 257, 1729, 935, 11, 370, 337, 1365, 294, 264, 2808, 510, 11, 337, 256, 6915, 51048], "temperature": 0.0, "avg_logprob": -0.29223734537760415, "compression_ratio": 1.5638297872340425, "no_speech_prob": 0.0005702790804207325}, {"id": 365, "seek": 172732, "start": 1741.0, "end": 1747.24, "text": " 0, for sigma equals 0, one column is an embedding.", "tokens": [51048, 1958, 11, 337, 12771, 6915, 1958, 11, 472, 7738, 307, 364, 12240, 3584, 13, 51360], "temperature": 0.0, "avg_logprob": -0.29223734537760415, "compression_ratio": 1.5638297872340425, "no_speech_prob": 0.0005702790804207325}, {"id": 366, "seek": 172732, "start": 1747.24, "end": 1753.36, "text": " So the bright represents higher numbers, and the dark represents lower numbers.", "tokens": [51360, 407, 264, 4730, 8855, 2946, 3547, 11, 293, 264, 2877, 8855, 3126, 3547, 13, 51666], "temperature": 0.0, "avg_logprob": -0.29223734537760415, "compression_ratio": 1.5638297872340425, "no_speech_prob": 0.0005702790804207325}, {"id": 367, "seek": 175336, "start": 1753.3999999999999, "end": 1759.8, "text": " And so you can see every column looks different, even though the columns next to each other", "tokens": [50366, 400, 370, 291, 393, 536, 633, 7738, 1542, 819, 11, 754, 1673, 264, 13766, 958, 281, 1184, 661, 50686], "temperature": 0.0, "avg_logprob": -0.3297566995992289, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.00016603102267254144}, {"id": 368, "seek": 175336, "start": 1759.8, "end": 1762.84, "text": " look similar.", "tokens": [50686, 574, 2531, 13, 50838], "temperature": 0.0, "avg_logprob": -0.3297566995992289, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.00016603102267254144}, {"id": 369, "seek": 175336, "start": 1762.84, "end": 1766.1999999999998, "text": " So that's called a time step embedding.", "tokens": [50838, 407, 300, 311, 1219, 257, 565, 1823, 12240, 3584, 13, 51006], "temperature": 0.0, "avg_logprob": -0.3297566995992289, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.00016603102267254144}, {"id": 370, "seek": 175336, "start": 1766.1999999999998, "end": 1770.9199999999998, "text": " And this is definitely something you want to experiment with, right?", "tokens": [51006, 400, 341, 307, 2138, 746, 291, 528, 281, 5120, 365, 11, 558, 30, 51242], "temperature": 0.0, "avg_logprob": -0.3297566995992289, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.00016603102267254144}, {"id": 371, "seek": 175336, "start": 1770.9199999999998, "end": 1778.9199999999998, "text": " Like, really, I've tried to do the plots I thought are useful to understand this, but,", "tokens": [51242, 1743, 11, 534, 11, 286, 600, 3031, 281, 360, 264, 28609, 286, 1194, 366, 4420, 281, 1223, 341, 11, 457, 11, 51642], "temperature": 0.0, "avg_logprob": -0.3297566995992289, "compression_ratio": 1.4827586206896552, "no_speech_prob": 0.00016603102267254144}, {"id": 372, "seek": 177892, "start": 1778.92, "end": 1784.8000000000002, "text": " and Jono and Tanishka also had ideas about plots for these, you know, which we've shown.", "tokens": [50364, 293, 7745, 78, 293, 314, 7524, 2330, 611, 632, 3487, 466, 28609, 337, 613, 11, 291, 458, 11, 597, 321, 600, 4898, 13, 50658], "temperature": 0.0, "avg_logprob": -0.27300131125528304, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0017273863777518272}, {"id": 373, "seek": 177892, "start": 1784.8000000000002, "end": 1789.0800000000002, "text": " But you know, the only way to really understand them is to experiment.", "tokens": [50658, 583, 291, 458, 11, 264, 787, 636, 281, 534, 1223, 552, 307, 281, 5120, 13, 50872], "temperature": 0.0, "avg_logprob": -0.27300131125528304, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0017273863777518272}, {"id": 374, "seek": 177892, "start": 1789.0800000000002, "end": 1793.3600000000001, "text": " So then we can put that all into a function, where you just say, okay, well, how many times,", "tokens": [50872, 407, 550, 321, 393, 829, 300, 439, 666, 257, 2445, 11, 689, 291, 445, 584, 11, 1392, 11, 731, 11, 577, 867, 1413, 11, 51086], "temperature": 0.0, "avg_logprob": -0.27300131125528304, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0017273863777518272}, {"id": 375, "seek": 177892, "start": 1793.3600000000001, "end": 1795.42, "text": " sorry, what are the time steps?", "tokens": [51086, 2597, 11, 437, 366, 264, 565, 4439, 30, 51189], "temperature": 0.0, "avg_logprob": -0.27300131125528304, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0017273863777518272}, {"id": 376, "seek": 177892, "start": 1795.42, "end": 1797.28, "text": " How many embedding dimensions do you want?", "tokens": [51189, 1012, 867, 12240, 3584, 12819, 360, 291, 528, 30, 51282], "temperature": 0.0, "avg_logprob": -0.27300131125528304, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0017273863777518272}, {"id": 377, "seek": 177892, "start": 1797.28, "end": 1799.0800000000002, "text": " What's the maximum period?", "tokens": [51282, 708, 311, 264, 6674, 2896, 30, 51372], "temperature": 0.0, "avg_logprob": -0.27300131125528304, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0017273863777518272}, {"id": 378, "seek": 177892, "start": 1799.0800000000002, "end": 1806.76, "text": " And then all I did was I just copied and pasted the previous cells, and merged them together.", "tokens": [51372, 400, 550, 439, 286, 630, 390, 286, 445, 25365, 293, 1791, 292, 264, 3894, 5438, 11, 293, 36427, 552, 1214, 13, 51756], "temperature": 0.0, "avg_logprob": -0.27300131125528304, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0017273863777518272}, {"id": 379, "seek": 180676, "start": 1806.76, "end": 1815.06, "text": " So you can see there's our outer product, and there's our cat of sine and cos.", "tokens": [50364, 407, 291, 393, 536, 456, 311, 527, 10847, 1674, 11, 293, 456, 311, 527, 3857, 295, 18609, 293, 3792, 13, 50779], "temperature": 0.0, "avg_logprob": -0.23839810209454232, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00040446710772812366}, {"id": 380, "seek": 180676, "start": 1815.06, "end": 1818.96, "text": " If you end up with a, if you have an odd numbered embedding dimension, you have to pad it to", "tokens": [50779, 759, 291, 917, 493, 365, 257, 11, 498, 291, 362, 364, 7401, 40936, 12240, 3584, 10139, 11, 291, 362, 281, 6887, 309, 281, 50974], "temperature": 0.0, "avg_logprob": -0.23839810209454232, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00040446710772812366}, {"id": 381, "seek": 180676, "start": 1818.96, "end": 1821.12, "text": " make it even, don't worry about that.", "tokens": [50974, 652, 309, 754, 11, 500, 380, 3292, 466, 300, 13, 51082], "temperature": 0.0, "avg_logprob": -0.23839810209454232, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00040446710772812366}, {"id": 382, "seek": 180676, "start": 1821.12, "end": 1825.64, "text": " So here's something that now you can pass in the number of, sorry, the actual time steps", "tokens": [51082, 407, 510, 311, 746, 300, 586, 291, 393, 1320, 294, 264, 1230, 295, 11, 2597, 11, 264, 3539, 565, 4439, 51308], "temperature": 0.0, "avg_logprob": -0.23839810209454232, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00040446710772812366}, {"id": 383, "seek": 180676, "start": 1825.64, "end": 1833.0, "text": " or sigmas, and the number of embedding dimensions, and you will get back something like this.", "tokens": [51308, 420, 4556, 3799, 11, 293, 264, 1230, 295, 12240, 3584, 12819, 11, 293, 291, 486, 483, 646, 746, 411, 341, 13, 51676], "temperature": 0.0, "avg_logprob": -0.23839810209454232, "compression_ratio": 1.7818181818181817, "no_speech_prob": 0.00040446710772812366}, {"id": 384, "seek": 183300, "start": 1833.0, "end": 1837.0, "text": " It won't be a nice curve, because your time steps in a batch won't all be next to each", "tokens": [50364, 467, 1582, 380, 312, 257, 1481, 7605, 11, 570, 428, 565, 4439, 294, 257, 15245, 1582, 380, 439, 312, 958, 281, 1184, 50564], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 385, "seek": 183300, "start": 1837.0, "end": 1838.0, "text": " other.", "tokens": [50564, 661, 13, 50614], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 386, "seek": 183300, "start": 1838.0, "end": 1839.0, "text": " It's the same idea.", "tokens": [50614, 467, 311, 264, 912, 1558, 13, 50664], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 387, "seek": 183300, "start": 1839.0, "end": 1845.48, "text": " Can I call something on that little visualization there, which goes back to your comment about", "tokens": [50664, 1664, 286, 818, 746, 322, 300, 707, 25801, 456, 11, 597, 1709, 646, 281, 428, 2871, 466, 50988], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 388, "seek": 183300, "start": 1845.48, "end": 1847.0, "text": " the max period being super high?", "tokens": [50988, 264, 11469, 2896, 885, 1687, 1090, 30, 51064], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 389, "seek": 183300, "start": 1847.0, "end": 1848.0, "text": " Yeah.", "tokens": [51064, 865, 13, 51114], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 390, "seek": 183300, "start": 1848.0, "end": 1852.6, "text": " So you said like, okay, adjacent ones are somewhat similar, because that's what we want,", "tokens": [51114, 407, 291, 848, 411, 11, 1392, 11, 24441, 2306, 366, 8344, 2531, 11, 570, 300, 311, 437, 321, 528, 11, 51344], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 391, "seek": 183300, "start": 1852.6, "end": 1853.6, "text": " but there is some change.", "tokens": [51344, 457, 456, 307, 512, 1319, 13, 51394], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 392, "seek": 183300, "start": 1853.6, "end": 1859.72, "text": " But if you look all of this first 100, some, just like the half of the embeddings look", "tokens": [51394, 583, 498, 291, 574, 439, 295, 341, 700, 2319, 11, 512, 11, 445, 411, 264, 1922, 295, 264, 12240, 29432, 574, 51700], "temperature": 0.0, "avg_logprob": -0.29298217897492695, "compression_ratio": 1.6093189964157706, "no_speech_prob": 0.10517925024032593}, {"id": 393, "seek": 185972, "start": 1859.72, "end": 1861.2, "text": " like they don't really change at all.", "tokens": [50364, 411, 436, 500, 380, 534, 1319, 412, 439, 13, 50438], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 394, "seek": 185972, "start": 1861.2, "end": 1867.32, "text": " And that's because 50 to 100 on a scale of like 0 to 10,000, you want those to be quite", "tokens": [50438, 400, 300, 311, 570, 2625, 281, 2319, 322, 257, 4373, 295, 411, 1958, 281, 1266, 11, 1360, 11, 291, 528, 729, 281, 312, 1596, 50744], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 395, "seek": 185972, "start": 1867.32, "end": 1870.72, "text": " similar, because those are still very early in this like super long sequence that these", "tokens": [50744, 2531, 11, 570, 729, 366, 920, 588, 2440, 294, 341, 411, 1687, 938, 8310, 300, 613, 50914], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 396, "seek": 185972, "start": 1870.72, "end": 1871.72, "text": " are designed for.", "tokens": [50914, 366, 4761, 337, 13, 50964], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 397, "seek": 185972, "start": 1871.72, "end": 1872.72, "text": " Yeah.", "tokens": [50964, 865, 13, 51014], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 398, "seek": 185972, "start": 1872.72, "end": 1873.72, "text": " So here actually we've got wasted space.", "tokens": [51014, 407, 510, 767, 321, 600, 658, 19496, 1901, 13, 51064], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 399, "seek": 185972, "start": 1873.72, "end": 1874.72, "text": " Yeah.", "tokens": [51064, 865, 13, 51114], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 400, "seek": 185972, "start": 1874.72, "end": 1877.72, "text": " So here we've got a max period of a thousand instead.", "tokens": [51114, 407, 510, 321, 600, 658, 257, 11469, 2896, 295, 257, 4714, 2602, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 401, "seek": 185972, "start": 1877.72, "end": 1883.1200000000001, "text": " And I've changed the figure size, you can see it better, and it's using up a bit more", "tokens": [51264, 400, 286, 600, 3105, 264, 2573, 2744, 11, 291, 393, 536, 309, 1101, 11, 293, 309, 311, 1228, 493, 257, 857, 544, 51534], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 402, "seek": 185972, "start": 1883.1200000000001, "end": 1884.6000000000001, "text": " of the space.", "tokens": [51534, 295, 264, 1901, 13, 51608], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 403, "seek": 185972, "start": 1884.6000000000001, "end": 1885.6000000000001, "text": " Yeah.", "tokens": [51608, 865, 13, 51658], "temperature": 0.0, "avg_logprob": -0.3415607714471016, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.09008292853832245}, {"id": 404, "seek": 188560, "start": 1886.6, "end": 1891.32, "text": " Or go to max period of 10.", "tokens": [50414, 1610, 352, 281, 11469, 2896, 295, 1266, 13, 50650], "temperature": 0.0, "avg_logprob": -0.26234530587481636, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.011507656425237656}, {"id": 405, "seek": 188560, "start": 1891.32, "end": 1894.7199999999998, "text": " And it's actually now, this is, yeah, using it much better.", "tokens": [50650, 400, 309, 311, 767, 586, 11, 341, 307, 11, 1338, 11, 1228, 309, 709, 1101, 13, 50820], "temperature": 0.0, "avg_logprob": -0.26234530587481636, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.011507656425237656}, {"id": 406, "seek": 188560, "start": 1894.7199999999998, "end": 1895.7199999999998, "text": " Yeah.", "tokens": [50820, 865, 13, 50870], "temperature": 0.0, "avg_logprob": -0.26234530587481636, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.011507656425237656}, {"id": 407, "seek": 188560, "start": 1895.7199999999998, "end": 1898.6799999999998, "text": " So like, based on, you know, what you're saying, John, I agree.", "tokens": [50870, 407, 411, 11, 2361, 322, 11, 291, 458, 11, 437, 291, 434, 1566, 11, 2619, 11, 286, 3986, 13, 51018], "temperature": 0.0, "avg_logprob": -0.26234530587481636, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.011507656425237656}, {"id": 408, "seek": 188560, "start": 1898.6799999999998, "end": 1906.48, "text": " Like it seems like it would be a lot richer to use these time step embeddings with a suitable", "tokens": [51018, 1743, 309, 2544, 411, 309, 576, 312, 257, 688, 29021, 281, 764, 613, 565, 1823, 12240, 29432, 365, 257, 12873, 51408], "temperature": 0.0, "avg_logprob": -0.26234530587481636, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.011507656425237656}, {"id": 409, "seek": 188560, "start": 1906.48, "end": 1911.32, "text": " max period, or maybe you just wouldn't need as many embedding dimensions.", "tokens": [51408, 11469, 2896, 11, 420, 1310, 291, 445, 2759, 380, 643, 382, 867, 12240, 3584, 12819, 13, 51650], "temperature": 0.0, "avg_logprob": -0.26234530587481636, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.011507656425237656}, {"id": 410, "seek": 188560, "start": 1911.32, "end": 1914.76, "text": " I guess if you did use something very wasteful like this, but you used lots of embedding", "tokens": [51650, 286, 2041, 498, 291, 630, 764, 746, 588, 5964, 906, 411, 341, 11, 457, 291, 1143, 3195, 295, 12240, 3584, 51822], "temperature": 0.0, "avg_logprob": -0.26234530587481636, "compression_ratio": 1.5884615384615384, "no_speech_prob": 0.011507656425237656}, {"id": 411, "seek": 191476, "start": 1914.92, "end": 1919.92, "text": " dimensions, then it's going to still capture some useful ones.", "tokens": [50372, 12819, 11, 550, 309, 311, 516, 281, 920, 7983, 512, 4420, 2306, 13, 50622], "temperature": 0.0, "avg_logprob": -0.40737500061859955, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.00020987825701013207}, {"id": 412, "seek": 191476, "start": 1919.92, "end": 1920.92, "text": " Yeah.", "tokens": [50622, 865, 13, 50672], "temperature": 0.0, "avg_logprob": -0.40737500061859955, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.00020987825701013207}, {"id": 413, "seek": 191476, "start": 1920.92, "end": 1922.92, "text": " Thanks, John.", "tokens": [50672, 2561, 11, 2619, 13, 50772], "temperature": 0.0, "avg_logprob": -0.40737500061859955, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.00020987825701013207}, {"id": 414, "seek": 191476, "start": 1922.92, "end": 1924.92, "text": " So, yeah.", "tokens": [50772, 407, 11, 1338, 13, 50872], "temperature": 0.0, "avg_logprob": -0.40737500061859955, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.00020987825701013207}, {"id": 415, "seek": 191476, "start": 1924.92, "end": 1925.92, "text": " Yeah.", "tokens": [50872, 865, 13, 50922], "temperature": 0.0, "avg_logprob": -0.40737500061859955, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.00020987825701013207}, {"id": 416, "seek": 191476, "start": 1925.92, "end": 1932.24, "text": " So this is one of these interesting little insights about things that are buried deep", "tokens": [50922, 407, 341, 307, 472, 295, 613, 1880, 707, 14310, 466, 721, 300, 366, 14101, 2452, 51238], "temperature": 0.0, "avg_logprob": -0.40737500061859955, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.00020987825701013207}, {"id": 417, "seek": 191476, "start": 1932.24, "end": 1938.76, "text": " in code, which I'm not sure anybody probably much looks at.", "tokens": [51238, 294, 3089, 11, 597, 286, 478, 406, 988, 4472, 1391, 709, 1542, 412, 13, 51564], "temperature": 0.0, "avg_logprob": -0.40737500061859955, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.00020987825701013207}, {"id": 418, "seek": 191476, "start": 1938.76, "end": 1942.0, "text": " Okay.", "tokens": [51564, 1033, 13, 51726], "temperature": 0.0, "avg_logprob": -0.40737500061859955, "compression_ratio": 1.3888888888888888, "no_speech_prob": 0.00020987825701013207}, {"id": 419, "seek": 194200, "start": 1942.0, "end": 1948.04, "text": " So let's do a unit with time step embedding in it.", "tokens": [50364, 407, 718, 311, 360, 257, 4985, 365, 565, 1823, 12240, 3584, 294, 309, 13, 50666], "temperature": 0.0, "avg_logprob": -0.2439059595907888, "compression_ratio": 1.6, "no_speech_prob": 0.0001214788862853311}, {"id": 420, "seek": 194200, "start": 1948.04, "end": 1955.28, "text": " So what do you do once you've got like this column, you know, of embeddings for each item", "tokens": [50666, 407, 437, 360, 291, 360, 1564, 291, 600, 658, 411, 341, 7738, 11, 291, 458, 11, 295, 12240, 29432, 337, 1184, 3174, 51028], "temperature": 0.0, "avg_logprob": -0.2439059595907888, "compression_ratio": 1.6, "no_speech_prob": 0.0001214788862853311}, {"id": 421, "seek": 194200, "start": 1955.28, "end": 1956.28, "text": " of the batch?", "tokens": [51028, 295, 264, 15245, 30, 51078], "temperature": 0.0, "avg_logprob": -0.2439059595907888, "compression_ratio": 1.6, "no_speech_prob": 0.0001214788862853311}, {"id": 422, "seek": 194200, "start": 1956.28, "end": 1957.28, "text": " What do you do with it?", "tokens": [51078, 708, 360, 291, 360, 365, 309, 30, 51128], "temperature": 0.0, "avg_logprob": -0.2439059595907888, "compression_ratio": 1.6, "no_speech_prob": 0.0001214788862853311}, {"id": 423, "seek": 194200, "start": 1957.28, "end": 1960.92, "text": " Well, there's a few things you can do with it.", "tokens": [51128, 1042, 11, 456, 311, 257, 1326, 721, 291, 393, 360, 365, 309, 13, 51310], "temperature": 0.0, "avg_logprob": -0.2439059595907888, "compression_ratio": 1.6, "no_speech_prob": 0.0001214788862853311}, {"id": 424, "seek": 194200, "start": 1960.92, "end": 1966.24, "text": " What stable diffusion does, I think is correct, I'm not promising because I remember all these", "tokens": [51310, 708, 8351, 25242, 775, 11, 286, 519, 307, 3006, 11, 286, 478, 406, 20257, 570, 286, 1604, 439, 613, 51576], "temperature": 0.0, "avg_logprob": -0.2439059595907888, "compression_ratio": 1.6, "no_speech_prob": 0.0001214788862853311}, {"id": 425, "seek": 196624, "start": 1966.24, "end": 1978.76, "text": " details right, is that they make their embedding dimension length twice as big as the number", "tokens": [50364, 4365, 558, 11, 307, 300, 436, 652, 641, 12240, 3584, 10139, 4641, 6091, 382, 955, 382, 264, 1230, 50990], "temperature": 0.0, "avg_logprob": -0.2608688451066802, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.0028008841909468174}, {"id": 426, "seek": 196624, "start": 1978.76, "end": 1981.06, "text": " of activations.", "tokens": [50990, 295, 2430, 763, 13, 51105], "temperature": 0.0, "avg_logprob": -0.2608688451066802, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.0028008841909468174}, {"id": 427, "seek": 196624, "start": 1981.06, "end": 1988.16, "text": " And what they, what they then do is we can use chunk to take that and split it into two", "tokens": [51105, 400, 437, 436, 11, 437, 436, 550, 360, 307, 321, 393, 764, 16635, 281, 747, 300, 293, 7472, 309, 666, 732, 51460], "temperature": 0.0, "avg_logprob": -0.2608688451066802, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.0028008841909468174}, {"id": 428, "seek": 196624, "start": 1988.16, "end": 1989.16, "text": " separate variables.", "tokens": [51460, 4994, 9102, 13, 51510], "temperature": 0.0, "avg_logprob": -0.2608688451066802, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.0028008841909468174}, {"id": 429, "seek": 196624, "start": 1989.16, "end": 1993.72, "text": " So that just literally just, it's the opposite of concatenate, it's two separate variables.", "tokens": [51510, 407, 300, 445, 3736, 445, 11, 309, 311, 264, 6182, 295, 1588, 7186, 473, 11, 309, 311, 732, 4994, 9102, 13, 51738], "temperature": 0.0, "avg_logprob": -0.2608688451066802, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.0028008841909468174}, {"id": 430, "seek": 199372, "start": 1994.08, "end": 2001.72, "text": " One of them is added to the activations and one of them is multiplied by the activations.", "tokens": [50382, 1485, 295, 552, 307, 3869, 281, 264, 2430, 763, 293, 472, 295, 552, 307, 17207, 538, 264, 2430, 763, 13, 50764], "temperature": 0.0, "avg_logprob": -0.28946632062885125, "compression_ratio": 1.6319018404907975, "no_speech_prob": 2.0462921384023502e-05}, {"id": 431, "seek": 199372, "start": 2001.72, "end": 2006.78, "text": " So this is a scale and a shift.", "tokens": [50764, 407, 341, 307, 257, 4373, 293, 257, 5513, 13, 51017], "temperature": 0.0, "avg_logprob": -0.28946632062885125, "compression_ratio": 1.6319018404907975, "no_speech_prob": 2.0462921384023502e-05}, {"id": 432, "seek": 199372, "start": 2006.78, "end": 2014.6000000000001, "text": " We don't just grab the embeddings as is though, because each layer might want to do, each", "tokens": [51017, 492, 500, 380, 445, 4444, 264, 12240, 29432, 382, 307, 1673, 11, 570, 1184, 4583, 1062, 528, 281, 360, 11, 1184, 51408], "temperature": 0.0, "avg_logprob": -0.28946632062885125, "compression_ratio": 1.6319018404907975, "no_speech_prob": 2.0462921384023502e-05}, {"id": 433, "seek": 199372, "start": 2014.6000000000001, "end": 2017.5, "text": " res block might want to do different things with them.", "tokens": [51408, 725, 3461, 1062, 528, 281, 360, 819, 721, 365, 552, 13, 51553], "temperature": 0.0, "avg_logprob": -0.28946632062885125, "compression_ratio": 1.6319018404907975, "no_speech_prob": 2.0462921384023502e-05}, {"id": 434, "seek": 201750, "start": 2017.5, "end": 2023.02, "text": " So we have a embedding projection, which is just a linear layer, which allows them", "tokens": [50364, 407, 321, 362, 257, 12240, 3584, 22743, 11, 597, 307, 445, 257, 8213, 4583, 11, 597, 4045, 552, 50640], "temperature": 0.0, "avg_logprob": -0.3242718674415766, "compression_ratio": 1.6871794871794872, "no_speech_prob": 0.003649796126410365}, {"id": 435, "seek": 201750, "start": 2023.02, "end": 2024.54, "text": " to be projected.", "tokens": [50640, 281, 312, 26231, 13, 50716], "temperature": 0.0, "avg_logprob": -0.3242718674415766, "compression_ratio": 1.6871794871794872, "no_speech_prob": 0.003649796126410365}, {"id": 436, "seek": 201750, "start": 2024.54, "end": 2029.94, "text": " So it's projected from the number of embeddings to two times the number of filters, so that", "tokens": [50716, 407, 309, 311, 26231, 490, 264, 1230, 295, 12240, 29432, 281, 732, 1413, 264, 1230, 295, 15995, 11, 370, 300, 50986], "temperature": 0.0, "avg_logprob": -0.3242718674415766, "compression_ratio": 1.6871794871794872, "no_speech_prob": 0.003649796126410365}, {"id": 437, "seek": 201750, "start": 2029.94, "end": 2034.14, "text": " that torch.chunk works.", "tokens": [50986, 300, 27822, 13, 339, 3197, 1985, 13, 51196], "temperature": 0.0, "avg_logprob": -0.3242718674415766, "compression_ratio": 1.6871794871794872, "no_speech_prob": 0.003649796126410365}, {"id": 438, "seek": 201750, "start": 2034.14, "end": 2038.98, "text": " We also have an activation function called cilu.", "tokens": [51196, 492, 611, 362, 364, 24433, 2445, 1219, 269, 388, 84, 13, 51438], "temperature": 0.0, "avg_logprob": -0.3242718674415766, "compression_ratio": 1.6871794871794872, "no_speech_prob": 0.003649796126410365}, {"id": 439, "seek": 201750, "start": 2038.98, "end": 2043.78, "text": " This is the activation function that's used in stable diffusion.", "tokens": [51438, 639, 307, 264, 24433, 2445, 300, 311, 1143, 294, 8351, 25242, 13, 51678], "temperature": 0.0, "avg_logprob": -0.3242718674415766, "compression_ratio": 1.6871794871794872, "no_speech_prob": 0.003649796126410365}, {"id": 440, "seek": 204378, "start": 2043.78, "end": 2055.14, "text": " I don't think the details are particularly important, but it looks basically like a rectified", "tokens": [50364, 286, 500, 380, 519, 264, 4365, 366, 4098, 1021, 11, 457, 309, 1542, 1936, 411, 257, 11048, 2587, 50932], "temperature": 0.0, "avg_logprob": -0.36509599491041533, "compression_ratio": 1.3790322580645162, "no_speech_prob": 0.0047550806775689125}, {"id": 441, "seek": 204378, "start": 2055.14, "end": 2059.98, "text": " linear with a slight curvy bit.", "tokens": [50932, 8213, 365, 257, 4036, 1262, 11869, 857, 13, 51174], "temperature": 0.0, "avg_logprob": -0.36509599491041533, "compression_ratio": 1.3790322580645162, "no_speech_prob": 0.0047550806775689125}, {"id": 442, "seek": 204378, "start": 2059.98, "end": 2061.86, "text": " And also known as swish.", "tokens": [51174, 400, 611, 2570, 382, 1693, 742, 13, 51268], "temperature": 0.0, "avg_logprob": -0.36509599491041533, "compression_ratio": 1.3790322580645162, "no_speech_prob": 0.0047550806775689125}, {"id": 443, "seek": 204378, "start": 2061.86, "end": 2065.7, "text": " Also known as swish.", "tokens": [51268, 2743, 2570, 382, 1693, 742, 13, 51460], "temperature": 0.0, "avg_logprob": -0.36509599491041533, "compression_ratio": 1.3790322580645162, "no_speech_prob": 0.0047550806775689125}, {"id": 444, "seek": 206570, "start": 2065.7, "end": 2074.1, "text": " And it's just equal to x times sigmoid x.", "tokens": [50364, 400, 309, 311, 445, 2681, 281, 2031, 1413, 4556, 3280, 327, 2031, 13, 50784], "temperature": 0.0, "avg_logprob": -0.2681393116078478, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.018544504418969154}, {"id": 445, "seek": 206570, "start": 2074.1, "end": 2081.8199999999997, "text": " And yeah, I think it's like activation functions don't make a huge difference, but it'll, they", "tokens": [50784, 400, 1338, 11, 286, 519, 309, 311, 411, 24433, 6828, 500, 380, 652, 257, 2603, 2649, 11, 457, 309, 603, 11, 436, 51170], "temperature": 0.0, "avg_logprob": -0.2681393116078478, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.018544504418969154}, {"id": 446, "seek": 206570, "start": 2081.8199999999997, "end": 2085.7, "text": " can make things train a little better or a little faster and swish has been something", "tokens": [51170, 393, 652, 721, 3847, 257, 707, 1101, 420, 257, 707, 4663, 293, 1693, 742, 575, 668, 746, 51364], "temperature": 0.0, "avg_logprob": -0.2681393116078478, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.018544504418969154}, {"id": 447, "seek": 206570, "start": 2085.7, "end": 2086.7, "text": " that's worked pretty well.", "tokens": [51364, 300, 311, 2732, 1238, 731, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2681393116078478, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.018544504418969154}, {"id": 448, "seek": 206570, "start": 2086.7, "end": 2090.4199999999996, "text": " So people, a lot of people using swish or cilu.", "tokens": [51414, 407, 561, 11, 257, 688, 295, 561, 1228, 1693, 742, 420, 269, 388, 84, 13, 51600], "temperature": 0.0, "avg_logprob": -0.2681393116078478, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.018544504418969154}, {"id": 449, "seek": 206570, "start": 2090.4199999999996, "end": 2092.7, "text": " I always call it swish.", "tokens": [51600, 286, 1009, 818, 309, 1693, 742, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2681393116078478, "compression_ratio": 1.5358851674641147, "no_speech_prob": 0.018544504418969154}, {"id": 450, "seek": 209270, "start": 2092.7, "end": 2098.1, "text": " But I think cilu was actually where it was originally, the Galliou paper, which had cilu", "tokens": [50364, 583, 286, 519, 269, 388, 84, 390, 767, 689, 309, 390, 7993, 11, 264, 14588, 72, 263, 3035, 11, 597, 632, 269, 388, 84, 50634], "temperature": 0.0, "avg_logprob": -0.32971033556707974, "compression_ratio": 1.7041666666666666, "no_speech_prob": 8.092740608844906e-05}, {"id": 451, "seek": 209270, "start": 2098.1, "end": 2101.74, "text": " was where it originally was kind of invented and maybe people didn't quite notice.", "tokens": [50634, 390, 689, 309, 7993, 390, 733, 295, 14479, 293, 1310, 561, 994, 380, 1596, 3449, 13, 50816], "temperature": 0.0, "avg_logprob": -0.32971033556707974, "compression_ratio": 1.7041666666666666, "no_speech_prob": 8.092740608844906e-05}, {"id": 452, "seek": 209270, "start": 2101.74, "end": 2105.1, "text": " And then another paper called it swish and everybody called it swish.", "tokens": [50816, 400, 550, 1071, 3035, 1219, 309, 1693, 742, 293, 2201, 1219, 309, 1693, 742, 13, 50984], "temperature": 0.0, "avg_logprob": -0.32971033556707974, "compression_ratio": 1.7041666666666666, "no_speech_prob": 8.092740608844906e-05}, {"id": 453, "seek": 209270, "start": 2105.1, "end": 2108.02, "text": " And then people were like, wait, that wasn't the original paper.", "tokens": [50984, 400, 550, 561, 645, 411, 11, 1699, 11, 300, 2067, 380, 264, 3380, 3035, 13, 51130], "temperature": 0.0, "avg_logprob": -0.32971033556707974, "compression_ratio": 1.7041666666666666, "no_speech_prob": 8.092740608844906e-05}, {"id": 454, "seek": 209270, "start": 2108.02, "end": 2113.14, "text": " So I guess I should try to call it cilu.", "tokens": [51130, 407, 286, 2041, 286, 820, 853, 281, 818, 309, 269, 388, 84, 13, 51386], "temperature": 0.0, "avg_logprob": -0.32971033556707974, "compression_ratio": 1.7041666666666666, "no_speech_prob": 8.092740608844906e-05}, {"id": 455, "seek": 209270, "start": 2113.14, "end": 2114.22, "text": " Okay.", "tokens": [51386, 1033, 13, 51440], "temperature": 0.0, "avg_logprob": -0.32971033556707974, "compression_ratio": 1.7041666666666666, "no_speech_prob": 8.092740608844906e-05}, {"id": 456, "seek": 209270, "start": 2114.22, "end": 2116.8199999999997, "text": " So yeah, other than that, it's just a normal res block.", "tokens": [51440, 407, 1338, 11, 661, 813, 300, 11, 309, 311, 445, 257, 2710, 725, 3461, 13, 51570], "temperature": 0.0, "avg_logprob": -0.32971033556707974, "compression_ratio": 1.7041666666666666, "no_speech_prob": 8.092740608844906e-05}, {"id": 457, "seek": 211682, "start": 2116.82, "end": 2123.6600000000003, "text": " So we do our first conv, then we do our embedding projection of the activation function of time", "tokens": [50364, 407, 321, 360, 527, 700, 3754, 11, 550, 321, 360, 527, 12240, 3584, 22743, 295, 264, 24433, 2445, 295, 565, 50706], "temperature": 0.0, "avg_logprob": -0.2723161556102611, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.0016483957879245281}, {"id": 458, "seek": 211682, "start": 2123.6600000000003, "end": 2124.6600000000003, "text": " steps.", "tokens": [50706, 4439, 13, 50756], "temperature": 0.0, "avg_logprob": -0.2723161556102611, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.0016483957879245281}, {"id": 459, "seek": 211682, "start": 2124.6600000000003, "end": 2131.86, "text": " And so that's going to be applied to every channel, sorry, to every pixel height and", "tokens": [50756, 400, 370, 300, 311, 516, 281, 312, 6456, 281, 633, 2269, 11, 2597, 11, 281, 633, 19261, 6681, 293, 51116], "temperature": 0.0, "avg_logprob": -0.2723161556102611, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.0016483957879245281}, {"id": 460, "seek": 211682, "start": 2131.86, "end": 2132.86, "text": " width.", "tokens": [51116, 11402, 13, 51166], "temperature": 0.0, "avg_logprob": -0.2723161556102611, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.0016483957879245281}, {"id": 461, "seek": 211682, "start": 2132.86, "end": 2136.2200000000003, "text": " So that's why we have to add unit axes on the height and width, that it's going to cause", "tokens": [51166, 407, 300, 311, 983, 321, 362, 281, 909, 4985, 35387, 322, 264, 6681, 293, 11402, 11, 300, 309, 311, 516, 281, 3082, 51334], "temperature": 0.0, "avg_logprob": -0.2723161556102611, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.0016483957879245281}, {"id": 462, "seek": 211682, "start": 2136.2200000000003, "end": 2139.46, "text": " it to broadcast across those two axes.", "tokens": [51334, 309, 281, 9975, 2108, 729, 732, 35387, 13, 51496], "temperature": 0.0, "avg_logprob": -0.2723161556102611, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.0016483957879245281}, {"id": 463, "seek": 211682, "start": 2139.46, "end": 2144.34, "text": " Do our chunk, do the scale and shift, then we're ready for the second conv.", "tokens": [51496, 1144, 527, 16635, 11, 360, 264, 4373, 293, 5513, 11, 550, 321, 434, 1919, 337, 264, 1150, 3754, 13, 51740], "temperature": 0.0, "avg_logprob": -0.2723161556102611, "compression_ratio": 1.737991266375546, "no_speech_prob": 0.0016483957879245281}, {"id": 464, "seek": 214434, "start": 2144.34, "end": 2152.46, "text": " And then we add it to the input with a additional conv, one stride one conv if necessary, as", "tokens": [50364, 400, 550, 321, 909, 309, 281, 264, 4846, 365, 257, 4497, 3754, 11, 472, 1056, 482, 472, 3754, 498, 4818, 11, 382, 50770], "temperature": 0.0, "avg_logprob": -0.3078915313049987, "compression_ratio": 1.518181818181818, "no_speech_prob": 3.373717481736094e-05}, {"id": 465, "seek": 214434, "start": 2152.46, "end": 2157.06, "text": " we've done before, if we have to change the number of channels.", "tokens": [50770, 321, 600, 1096, 949, 11, 498, 321, 362, 281, 1319, 264, 1230, 295, 9235, 13, 51000], "temperature": 0.0, "avg_logprob": -0.3078915313049987, "compression_ratio": 1.518181818181818, "no_speech_prob": 3.373717481736094e-05}, {"id": 466, "seek": 214434, "start": 2157.06, "end": 2158.46, "text": " Okay.", "tokens": [51000, 1033, 13, 51070], "temperature": 0.0, "avg_logprob": -0.3078915313049987, "compression_ratio": 1.518181818181818, "no_speech_prob": 3.373717481736094e-05}, {"id": 467, "seek": 214434, "start": 2158.46, "end": 2164.86, "text": " Yeah, because I like exercising our Python muscles, I decided to use a second approach", "tokens": [51070, 865, 11, 570, 286, 411, 27272, 527, 15329, 9530, 11, 286, 3047, 281, 764, 257, 1150, 3109, 51390], "temperature": 0.0, "avg_logprob": -0.3078915313049987, "compression_ratio": 1.518181818181818, "no_speech_prob": 3.373717481736094e-05}, {"id": 468, "seek": 214434, "start": 2164.86, "end": 2168.5, "text": " now for the down block and the up block.", "tokens": [51390, 586, 337, 264, 760, 3461, 293, 264, 493, 3461, 13, 51572], "temperature": 0.0, "avg_logprob": -0.3078915313049987, "compression_ratio": 1.518181818181818, "no_speech_prob": 3.373717481736094e-05}, {"id": 469, "seek": 214434, "start": 2168.5, "end": 2171.38, "text": " I'm not saying which one's better or worse.", "tokens": [51572, 286, 478, 406, 1566, 597, 472, 311, 1101, 420, 5324, 13, 51716], "temperature": 0.0, "avg_logprob": -0.3078915313049987, "compression_ratio": 1.518181818181818, "no_speech_prob": 3.373717481736094e-05}, {"id": 470, "seek": 217138, "start": 2171.42, "end": 2180.78, "text": " We're not going to use multiple inheritance anymore, but instead we're going to use, well", "tokens": [50366, 492, 434, 406, 516, 281, 764, 3866, 32122, 3602, 11, 457, 2602, 321, 434, 516, 281, 764, 11, 731, 50834], "temperature": 0.0, "avg_logprob": -0.2803316116333008, "compression_ratio": 1.9113300492610839, "no_speech_prob": 0.0007096668123267591}, {"id": 471, "seek": 217138, "start": 2180.78, "end": 2185.1, "text": " it's not even a decorator, it's a function which takes a function.", "tokens": [50834, 309, 311, 406, 754, 257, 7919, 1639, 11, 309, 311, 257, 2445, 597, 2516, 257, 2445, 13, 51050], "temperature": 0.0, "avg_logprob": -0.2803316116333008, "compression_ratio": 1.9113300492610839, "no_speech_prob": 0.0007096668123267591}, {"id": 472, "seek": 217138, "start": 2185.1, "end": 2190.62, "text": " What we're going to do now is we're going to use conv2dd and ember as block directly,", "tokens": [51050, 708, 321, 434, 516, 281, 360, 586, 307, 321, 434, 516, 281, 764, 3754, 17, 24810, 293, 846, 607, 382, 3461, 3838, 11, 51326], "temperature": 0.0, "avg_logprob": -0.2803316116333008, "compression_ratio": 1.9113300492610839, "no_speech_prob": 0.0007096668123267591}, {"id": 473, "seek": 217138, "start": 2190.62, "end": 2193.6600000000003, "text": " but we're going to pass them to a function called saved.", "tokens": [51326, 457, 321, 434, 516, 281, 1320, 552, 281, 257, 2445, 1219, 6624, 13, 51478], "temperature": 0.0, "avg_logprob": -0.2803316116333008, "compression_ratio": 1.9113300492610839, "no_speech_prob": 0.0007096668123267591}, {"id": 474, "seek": 217138, "start": 2193.6600000000003, "end": 2201.06, "text": " The function called saved is something which is going to take as input a callable, which", "tokens": [51478, 440, 2445, 1219, 6624, 307, 746, 597, 307, 516, 281, 747, 382, 4846, 257, 818, 712, 11, 597, 51848], "temperature": 0.0, "avg_logprob": -0.2803316116333008, "compression_ratio": 1.9113300492610839, "no_speech_prob": 0.0007096668123267591}, {"id": 475, "seek": 220106, "start": 2201.06, "end": 2203.98, "text": " could be a function or a module or whatever.", "tokens": [50364, 727, 312, 257, 2445, 420, 257, 10088, 420, 2035, 13, 50510], "temperature": 0.0, "avg_logprob": -0.26859043716290676, "compression_ratio": 1.75, "no_speech_prob": 1.5294127706511063e-06}, {"id": 476, "seek": 220106, "start": 2203.98, "end": 2206.9, "text": " So in this case it's a module.", "tokens": [50510, 407, 294, 341, 1389, 309, 311, 257, 10088, 13, 50656], "temperature": 0.0, "avg_logprob": -0.26859043716290676, "compression_ratio": 1.75, "no_speech_prob": 1.5294127706511063e-06}, {"id": 477, "seek": 220106, "start": 2206.9, "end": 2213.42, "text": " Takes an ember as block or a conv2d and it returns a callable.", "tokens": [50656, 44347, 364, 846, 607, 382, 3461, 420, 257, 3754, 17, 67, 293, 309, 11247, 257, 818, 712, 13, 50982], "temperature": 0.0, "avg_logprob": -0.26859043716290676, "compression_ratio": 1.75, "no_speech_prob": 1.5294127706511063e-06}, {"id": 478, "seek": 220106, "start": 2213.42, "end": 2217.54, "text": " The callable it returns is identical to the callable that's passed into it, except that", "tokens": [50982, 440, 818, 712, 309, 11247, 307, 14800, 281, 264, 818, 712, 300, 311, 4678, 666, 309, 11, 3993, 300, 51188], "temperature": 0.0, "avg_logprob": -0.26859043716290676, "compression_ratio": 1.75, "no_speech_prob": 1.5294127706511063e-06}, {"id": 479, "seek": 220106, "start": 2217.54, "end": 2222.74, "text": " it saves the result, saves the activations, saves the result of the function.", "tokens": [51188, 309, 19155, 264, 1874, 11, 19155, 264, 2430, 763, 11, 19155, 264, 1874, 295, 264, 2445, 13, 51448], "temperature": 0.0, "avg_logprob": -0.26859043716290676, "compression_ratio": 1.75, "no_speech_prob": 1.5294127706511063e-06}, {"id": 480, "seek": 220106, "start": 2222.74, "end": 2224.34, "text": " Where does it save it?", "tokens": [51448, 2305, 775, 309, 3155, 309, 30, 51528], "temperature": 0.0, "avg_logprob": -0.26859043716290676, "compression_ratio": 1.75, "no_speech_prob": 1.5294127706511063e-06}, {"id": 481, "seek": 220106, "start": 2224.34, "end": 2230.22, "text": " It's going to save it into a list in the second argument.", "tokens": [51528, 467, 311, 516, 281, 3155, 309, 666, 257, 1329, 294, 264, 1150, 6770, 13, 51822], "temperature": 0.0, "avg_logprob": -0.26859043716290676, "compression_ratio": 1.75, "no_speech_prob": 1.5294127706511063e-06}, {"id": 482, "seek": 223022, "start": 2230.22, "end": 2234.54, "text": " You pass to it, which is the block.", "tokens": [50364, 509, 1320, 281, 309, 11, 597, 307, 264, 3461, 13, 50580], "temperature": 0.0, "avg_logprob": -0.30642082073070387, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.0007793640834279358}, {"id": 483, "seek": 223022, "start": 2234.54, "end": 2239.7799999999997, "text": " So the saved function, you're going to pass it the module.", "tokens": [50580, 407, 264, 6624, 2445, 11, 291, 434, 516, 281, 1320, 309, 264, 10088, 13, 50842], "temperature": 0.0, "avg_logprob": -0.30642082073070387, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.0007793640834279358}, {"id": 484, "seek": 223022, "start": 2239.7799999999997, "end": 2245.06, "text": " We're going to grab the forward from it and store that away to remember what it was.", "tokens": [50842, 492, 434, 516, 281, 4444, 264, 2128, 490, 309, 293, 3531, 300, 1314, 281, 1604, 437, 309, 390, 13, 51106], "temperature": 0.0, "avg_logprob": -0.30642082073070387, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.0007793640834279358}, {"id": 485, "seek": 223022, "start": 2245.06, "end": 2249.62, "text": " And then the function that we want to replace it with, call it underscore f, going to take", "tokens": [51106, 400, 550, 264, 2445, 300, 321, 528, 281, 7406, 309, 365, 11, 818, 309, 37556, 283, 11, 516, 281, 747, 51334], "temperature": 0.0, "avg_logprob": -0.30642082073070387, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.0007793640834279358}, {"id": 486, "seek": 223022, "start": 2249.62, "end": 2251.66, "text": " some arguments and some keyword arguments.", "tokens": [51334, 512, 12869, 293, 512, 20428, 12869, 13, 51436], "temperature": 0.0, "avg_logprob": -0.30642082073070387, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.0007793640834279358}, {"id": 487, "seek": 223022, "start": 2251.66, "end": 2256.7799999999997, "text": " Well basically it's just going to call the original modules.forward, passing in the arguments", "tokens": [51436, 1042, 1936, 309, 311, 445, 516, 281, 818, 264, 3380, 16679, 13, 13305, 11, 8437, 294, 264, 12869, 51692], "temperature": 0.0, "avg_logprob": -0.30642082073070387, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.0007793640834279358}, {"id": 488, "seek": 223022, "start": 2256.7799999999997, "end": 2259.2999999999997, "text": " and keyword arguments.", "tokens": [51692, 293, 20428, 12869, 13, 51818], "temperature": 0.0, "avg_logprob": -0.30642082073070387, "compression_ratio": 1.8454935622317596, "no_speech_prob": 0.0007793640834279358}, {"id": 489, "seek": 225930, "start": 2259.38, "end": 2267.7000000000003, "text": " And we're then going to store the result in something called the saved attribute inside", "tokens": [50368, 400, 321, 434, 550, 516, 281, 3531, 264, 1874, 294, 746, 1219, 264, 6624, 19667, 1854, 50784], "temperature": 0.0, "avg_logprob": -0.3182977040608724, "compression_ratio": 1.694736842105263, "no_speech_prob": 4.936988261761144e-06}, {"id": 490, "seek": 225930, "start": 2267.7000000000003, "end": 2271.02, "text": " here.", "tokens": [50784, 510, 13, 50950], "temperature": 0.0, "avg_logprob": -0.3182977040608724, "compression_ratio": 1.694736842105263, "no_speech_prob": 4.936988261761144e-06}, {"id": 491, "seek": 225930, "start": 2271.02, "end": 2274.1400000000003, "text": " And then we have to return the result.", "tokens": [50950, 400, 550, 321, 362, 281, 2736, 264, 1874, 13, 51106], "temperature": 0.0, "avg_logprob": -0.3182977040608724, "compression_ratio": 1.694736842105263, "no_speech_prob": 4.936988261761144e-06}, {"id": 492, "seek": 225930, "start": 2274.1400000000003, "end": 2280.94, "text": " So then we're going to replace the modules forward method with this function and return", "tokens": [51106, 407, 550, 321, 434, 516, 281, 7406, 264, 16679, 2128, 3170, 365, 341, 2445, 293, 2736, 51446], "temperature": 0.0, "avg_logprob": -0.3182977040608724, "compression_ratio": 1.694736842105263, "no_speech_prob": 4.936988261761144e-06}, {"id": 493, "seek": 225930, "start": 2280.94, "end": 2281.94, "text": " the module.", "tokens": [51446, 264, 10088, 13, 51496], "temperature": 0.0, "avg_logprob": -0.3182977040608724, "compression_ratio": 1.694736842105263, "no_speech_prob": 4.936988261761144e-06}, {"id": 494, "seek": 225930, "start": 2281.94, "end": 2286.02, "text": " So that module's now been, yeah I said callable actually, it can't be callable, it has to", "tokens": [51496, 407, 300, 10088, 311, 586, 668, 11, 1338, 286, 848, 818, 712, 767, 11, 309, 393, 380, 312, 818, 712, 11, 309, 575, 281, 51700], "temperature": 0.0, "avg_logprob": -0.3182977040608724, "compression_ratio": 1.694736842105263, "no_speech_prob": 4.936988261761144e-06}, {"id": 495, "seek": 228602, "start": 2286.02, "end": 2290.42, "text": " specifically be a module because with the forward that we're changing.", "tokens": [50364, 4682, 312, 257, 10088, 570, 365, 264, 2128, 300, 321, 434, 4473, 13, 50584], "temperature": 0.0, "avg_logprob": -0.32148958135534217, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.00109871756285429}, {"id": 496, "seek": 228602, "start": 2290.42, "end": 2294.78, "text": " This at wraps is just something which automatically, it's from the Python standard library, it's", "tokens": [50584, 639, 412, 25831, 307, 445, 746, 597, 6772, 11, 309, 311, 490, 264, 15329, 3832, 6405, 11, 309, 311, 50802], "temperature": 0.0, "avg_logprob": -0.32148958135534217, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.00109871756285429}, {"id": 497, "seek": 228602, "start": 2294.78, "end": 2299.14, "text": " just going to copy in the documentation and everything from the original forward.", "tokens": [50802, 445, 516, 281, 5055, 294, 264, 14333, 293, 1203, 490, 264, 3380, 2128, 13, 51020], "temperature": 0.0, "avg_logprob": -0.32148958135534217, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.00109871756285429}, {"id": 498, "seek": 228602, "start": 2299.14, "end": 2306.3, "text": " So that it all looks like nothing's changed.", "tokens": [51020, 407, 300, 309, 439, 1542, 411, 1825, 311, 3105, 13, 51378], "temperature": 0.0, "avg_logprob": -0.32148958135534217, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.00109871756285429}, {"id": 499, "seek": 228602, "start": 2306.3, "end": 2308.42, "text": " Now where does this .saved come from?", "tokens": [51378, 823, 689, 775, 341, 2411, 82, 12865, 808, 490, 30, 51484], "temperature": 0.0, "avg_logprob": -0.32148958135534217, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.00109871756285429}, {"id": 500, "seek": 228602, "start": 2308.42, "end": 2313.14, "text": " I realized now actually we could make this easier and automate it, but I forgot, didn't", "tokens": [51484, 286, 5334, 586, 767, 321, 727, 652, 341, 3571, 293, 31605, 309, 11, 457, 286, 5298, 11, 994, 380, 51720], "temperature": 0.0, "avg_logprob": -0.32148958135534217, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.00109871756285429}, {"id": 501, "seek": 228602, "start": 2313.14, "end": 2314.82, "text": " think of this at the time.", "tokens": [51720, 519, 295, 341, 412, 264, 565, 13, 51804], "temperature": 0.0, "avg_logprob": -0.32148958135534217, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.00109871756285429}, {"id": 502, "seek": 231482, "start": 2314.82, "end": 2320.1800000000003, "text": " So we have to create the saved here in the down block.", "tokens": [50364, 407, 321, 362, 281, 1884, 264, 6624, 510, 294, 264, 760, 3461, 13, 50632], "temperature": 0.0, "avg_logprob": -0.3618001705262719, "compression_ratio": 1.6312849162011174, "no_speech_prob": 0.0005274777649901807}, {"id": 503, "seek": 231482, "start": 2320.1800000000003, "end": 2323.94, "text": " It actually would have made more sense I think here for it to have said if the saved attribute", "tokens": [50632, 467, 767, 576, 362, 1027, 544, 2020, 286, 519, 510, 337, 309, 281, 362, 848, 498, 264, 6624, 19667, 50820], "temperature": 0.0, "avg_logprob": -0.3618001705262719, "compression_ratio": 1.6312849162011174, "no_speech_prob": 0.0005274777649901807}, {"id": 504, "seek": 231482, "start": 2323.94, "end": 2327.06, "text": " doesn't exist then create it.", "tokens": [50820, 1177, 380, 2514, 550, 1884, 309, 13, 50976], "temperature": 0.0, "avg_logprob": -0.3618001705262719, "compression_ratio": 1.6312849162011174, "no_speech_prob": 0.0005274777649901807}, {"id": 505, "seek": 231482, "start": 2327.06, "end": 2328.6600000000003, "text": " Which would look like this.", "tokens": [50976, 3013, 576, 574, 411, 341, 13, 51056], "temperature": 0.0, "avg_logprob": -0.3618001705262719, "compression_ratio": 1.6312849162011174, "no_speech_prob": 0.0005274777649901807}, {"id": 506, "seek": 231482, "start": 2328.6600000000003, "end": 2341.1800000000003, "text": " If not hasAtcher block, saved, block.saved equals, if you do this, then you wouldn't", "tokens": [51056, 759, 406, 575, 32, 83, 6759, 3461, 11, 6624, 11, 3461, 13, 82, 12865, 6915, 11, 498, 291, 360, 341, 11, 550, 291, 2759, 380, 51682], "temperature": 0.0, "avg_logprob": -0.3618001705262719, "compression_ratio": 1.6312849162011174, "no_speech_prob": 0.0005274777649901807}, {"id": 507, "seek": 234118, "start": 2341.18, "end": 2345.18, "text": " need this anymore.", "tokens": [50364, 643, 341, 3602, 13, 50564], "temperature": 0.0, "avg_logprob": -0.3019727875914755, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.006589559838175774}, {"id": 508, "seek": 234118, "start": 2345.18, "end": 2352.2599999999998, "text": " Anyway I didn't think of that at the time, so let's pretend that that's not what we do.", "tokens": [50564, 5684, 286, 994, 380, 519, 295, 300, 412, 264, 565, 11, 370, 718, 311, 11865, 300, 300, 311, 406, 437, 321, 360, 13, 50918], "temperature": 0.0, "avg_logprob": -0.3019727875914755, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.006589559838175774}, {"id": 509, "seek": 234118, "start": 2352.2599999999998, "end": 2364.54, "text": " So yeah, now the downsampling.conv and the resnets both contain saved versions of modules.", "tokens": [50918, 407, 1338, 11, 586, 264, 760, 19988, 11970, 13, 1671, 85, 293, 264, 725, 77, 1385, 1293, 5304, 6624, 9606, 295, 16679, 13, 51532], "temperature": 0.0, "avg_logprob": -0.3019727875914755, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.006589559838175774}, {"id": 510, "seek": 234118, "start": 2364.54, "end": 2368.3799999999997, "text": " We don't have to do anything to make that work, we just have to call them.", "tokens": [51532, 492, 500, 380, 362, 281, 360, 1340, 281, 652, 300, 589, 11, 321, 445, 362, 281, 818, 552, 13, 51724], "temperature": 0.0, "avg_logprob": -0.3019727875914755, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.006589559838175774}, {"id": 511, "seek": 236838, "start": 2368.38, "end": 2374.1400000000003, "text": " We can't use sequentials anymore because we have to pass in the time step to the resnets", "tokens": [50364, 492, 393, 380, 764, 5123, 2549, 82, 3602, 570, 321, 362, 281, 1320, 294, 264, 565, 1823, 281, 264, 725, 77, 1385, 50652], "temperature": 0.0, "avg_logprob": -0.3126040371981534, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00010889574332395568}, {"id": 512, "seek": 236838, "start": 2374.1400000000003, "end": 2375.94, "text": " as well.", "tokens": [50652, 382, 731, 13, 50742], "temperature": 0.0, "avg_logprob": -0.3126040371981534, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00010889574332395568}, {"id": 513, "seek": 236838, "start": 2375.94, "end": 2380.54, "text": " It would be easy enough to create your own sequential for things with time steps, which", "tokens": [50742, 467, 576, 312, 1858, 1547, 281, 1884, 428, 1065, 42881, 337, 721, 365, 565, 4439, 11, 597, 50972], "temperature": 0.0, "avg_logprob": -0.3126040371981534, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00010889574332395568}, {"id": 514, "seek": 236838, "start": 2380.54, "end": 2383.82, "text": " passes them along.", "tokens": [50972, 11335, 552, 2051, 13, 51136], "temperature": 0.0, "avg_logprob": -0.3126040371981534, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00010889574332395568}, {"id": 515, "seek": 236838, "start": 2383.82, "end": 2388.5, "text": " But that's not what we're doing here.", "tokens": [51136, 583, 300, 311, 406, 437, 321, 434, 884, 510, 13, 51370], "temperature": 0.0, "avg_logprob": -0.3126040371981534, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00010889574332395568}, {"id": 516, "seek": 236838, "start": 2388.5, "end": 2392.06, "text": " Yeah maybe it makes sense for sequential to always pass along all the extra arguments,", "tokens": [51370, 865, 1310, 309, 1669, 2020, 337, 42881, 281, 1009, 1320, 2051, 439, 264, 2857, 12869, 11, 51548], "temperature": 0.0, "avg_logprob": -0.3126040371981534, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00010889574332395568}, {"id": 517, "seek": 236838, "start": 2392.06, "end": 2396.3, "text": " but I don't think that's how they work.", "tokens": [51548, 457, 286, 500, 380, 519, 300, 311, 577, 436, 589, 13, 51760], "temperature": 0.0, "avg_logprob": -0.3126040371981534, "compression_ratio": 1.618421052631579, "no_speech_prob": 0.00010889574332395568}, {"id": 518, "seek": 239630, "start": 2396.54, "end": 2402.7000000000003, "text": " So our up block is basically exactly the same as before, except we're now using ember as", "tokens": [50376, 407, 527, 493, 3461, 307, 1936, 2293, 264, 912, 382, 949, 11, 3993, 321, 434, 586, 1228, 846, 607, 382, 50684], "temperature": 0.0, "avg_logprob": -0.30465370178222656, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0012842551805078983}, {"id": 519, "seek": 239630, "start": 2402.7000000000003, "end": 2403.7000000000003, "text": " blocks instead.", "tokens": [50684, 8474, 2602, 13, 50734], "temperature": 0.0, "avg_logprob": -0.30465370178222656, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0012842551805078983}, {"id": 520, "seek": 239630, "start": 2403.7000000000003, "end": 2408.94, "text": " Just like before we're going to concatenate.", "tokens": [50734, 1449, 411, 949, 321, 434, 516, 281, 1588, 7186, 473, 13, 50996], "temperature": 0.0, "avg_logprob": -0.30465370178222656, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0012842551805078983}, {"id": 521, "seek": 239630, "start": 2408.94, "end": 2411.1800000000003, "text": " So that's all the same.", "tokens": [50996, 407, 300, 311, 439, 264, 912, 13, 51108], "temperature": 0.0, "avg_logprob": -0.30465370178222656, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0012842551805078983}, {"id": 522, "seek": 239630, "start": 2411.1800000000003, "end": 2423.2200000000003, "text": " So a unit model with time embeddings is going to look, if we look at the forward, the thing", "tokens": [51108, 407, 257, 4985, 2316, 365, 565, 12240, 29432, 307, 516, 281, 574, 11, 498, 321, 574, 412, 264, 2128, 11, 264, 551, 51710], "temperature": 0.0, "avg_logprob": -0.30465370178222656, "compression_ratio": 1.5497076023391814, "no_speech_prob": 0.0012842551805078983}, {"id": 523, "seek": 242322, "start": 2423.22, "end": 2428.62, "text": " we're passing into it now is a tuple containing the activations and the time steps, or the", "tokens": [50364, 321, 434, 8437, 666, 309, 586, 307, 257, 2604, 781, 19273, 264, 2430, 763, 293, 264, 565, 4439, 11, 420, 264, 50634], "temperature": 0.0, "avg_logprob": -0.28317963250792855, "compression_ratio": 1.816425120772947, "no_speech_prob": 0.0014778529293835163}, {"id": 524, "seek": 242322, "start": 2428.62, "end": 2430.7, "text": " sigmas in our case.", "tokens": [50634, 4556, 3799, 294, 527, 1389, 13, 50738], "temperature": 0.0, "avg_logprob": -0.28317963250792855, "compression_ratio": 1.816425120772947, "no_speech_prob": 0.0014778529293835163}, {"id": 525, "seek": 242322, "start": 2430.7, "end": 2437.1, "text": " So split them out, and what we're going to do is we're going to call that time step embedding", "tokens": [50738, 407, 7472, 552, 484, 11, 293, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 818, 300, 565, 1823, 12240, 3584, 51058], "temperature": 0.0, "avg_logprob": -0.28317963250792855, "compression_ratio": 1.816425120772947, "no_speech_prob": 0.0014778529293835163}, {"id": 526, "seek": 242322, "start": 2437.1, "end": 2443.3399999999997, "text": " function we wrote, saying okay, these are the time steps, and the number of time step", "tokens": [51058, 2445, 321, 4114, 11, 1566, 1392, 11, 613, 366, 264, 565, 4439, 11, 293, 264, 1230, 295, 565, 1823, 51370], "temperature": 0.0, "avg_logprob": -0.28317963250792855, "compression_ratio": 1.816425120772947, "no_speech_prob": 0.0014778529293835163}, {"id": 527, "seek": 242322, "start": 2443.3399999999997, "end": 2449.58, "text": " embeddings we want is equal to however many we asked for, and we're just going to set", "tokens": [51370, 12240, 29432, 321, 528, 307, 2681, 281, 4461, 867, 321, 2351, 337, 11, 293, 321, 434, 445, 516, 281, 992, 51682], "temperature": 0.0, "avg_logprob": -0.28317963250792855, "compression_ratio": 1.816425120772947, "no_speech_prob": 0.0014778529293835163}, {"id": 528, "seek": 244958, "start": 2449.58, "end": 2453.9, "text": " it equal to the first number of filters.", "tokens": [50364, 309, 2681, 281, 264, 700, 1230, 295, 15995, 13, 50580], "temperature": 0.0, "avg_logprob": -0.2463350381937113, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.02405170537531376}, {"id": 529, "seek": 244958, "start": 2453.9, "end": 2456.7, "text": " That's all that happens there.", "tokens": [50580, 663, 311, 439, 300, 2314, 456, 13, 50720], "temperature": 0.0, "avg_logprob": -0.2463350381937113, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.02405170537531376}, {"id": 530, "seek": 244958, "start": 2456.7, "end": 2463.2999999999997, "text": " And then we want to give the model the ability then to do whatever it wants with those, to", "tokens": [50720, 400, 550, 321, 528, 281, 976, 264, 2316, 264, 3485, 550, 281, 360, 2035, 309, 2738, 365, 729, 11, 281, 51050], "temperature": 0.0, "avg_logprob": -0.2463350381937113, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.02405170537531376}, {"id": 531, "seek": 244958, "start": 2463.2999999999997, "end": 2467.06, "text": " make those work the way it wants to, and the easiest smallest way to do that is to create", "tokens": [51050, 652, 729, 589, 264, 636, 309, 2738, 281, 11, 293, 264, 12889, 16998, 636, 281, 360, 300, 307, 281, 1884, 51238], "temperature": 0.0, "avg_logprob": -0.2463350381937113, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.02405170537531376}, {"id": 532, "seek": 244958, "start": 2467.06, "end": 2469.38, "text": " a tiny little MLP.", "tokens": [51238, 257, 5870, 707, 21601, 47, 13, 51354], "temperature": 0.0, "avg_logprob": -0.2463350381937113, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.02405170537531376}, {"id": 533, "seek": 244958, "start": 2469.38, "end": 2474.58, "text": " So we create a tiny little MLP, which is going to take the time step embeddings and return", "tokens": [51354, 407, 321, 1884, 257, 5870, 707, 21601, 47, 11, 597, 307, 516, 281, 747, 264, 565, 1823, 12240, 29432, 293, 2736, 51614], "temperature": 0.0, "avg_logprob": -0.2463350381937113, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.02405170537531376}, {"id": 534, "seek": 244958, "start": 2474.58, "end": 2477.98, "text": " the actual embeddings to pass into the resnet blocks.", "tokens": [51614, 264, 3539, 12240, 29432, 281, 1320, 666, 264, 725, 7129, 8474, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2463350381937113, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.02405170537531376}, {"id": 535, "seek": 247798, "start": 2477.98, "end": 2495.58, "text": " So tiny little MLP is just a linear layer with, let's think in here, hmm, linear layer.", "tokens": [50364, 407, 5870, 707, 21601, 47, 307, 445, 257, 8213, 4583, 365, 11, 718, 311, 519, 294, 510, 11, 16478, 11, 8213, 4583, 13, 51244], "temperature": 0.0, "avg_logprob": -0.39017332361099566, "compression_ratio": 1.3414634146341464, "no_speech_prob": 0.012624246068298817}, {"id": 536, "seek": 247798, "start": 2495.58, "end": 2496.58, "text": " That's interesting.", "tokens": [51244, 663, 311, 1880, 13, 51294], "temperature": 0.0, "avg_logprob": -0.39017332361099566, "compression_ratio": 1.3414634146341464, "no_speech_prob": 0.012624246068298817}, {"id": 537, "seek": 247798, "start": 2496.58, "end": 2502.7400000000002, "text": " I, my linear layer by default has an activation function.", "tokens": [51294, 286, 11, 452, 8213, 4583, 538, 7576, 575, 364, 24433, 2445, 13, 51602], "temperature": 0.0, "avg_logprob": -0.39017332361099566, "compression_ratio": 1.3414634146341464, "no_speech_prob": 0.012624246068298817}, {"id": 538, "seek": 250274, "start": 2502.74, "end": 2507.8999999999996, "text": " I'm pretty sure we should have act equals none here.", "tokens": [50364, 286, 478, 1238, 988, 321, 820, 362, 605, 6915, 6022, 510, 13, 50622], "temperature": 0.0, "avg_logprob": -0.4599361754300302, "compression_ratio": 1.4275362318840579, "no_speech_prob": 0.0005883976118639112}, {"id": 539, "seek": 250274, "start": 2507.8999999999996, "end": 2511.1, "text": " Should be a linear layer and then an activation and then a linear layer.", "tokens": [50622, 6454, 312, 257, 8213, 4583, 293, 550, 364, 24433, 293, 550, 257, 8213, 4583, 13, 50782], "temperature": 0.0, "avg_logprob": -0.4599361754300302, "compression_ratio": 1.4275362318840579, "no_speech_prob": 0.0005883976118639112}, {"id": 540, "seek": 250274, "start": 2511.1, "end": 2518.9799999999996, "text": " So I think I've got it back, which we will need to try rerunning.", "tokens": [50782, 407, 286, 519, 286, 600, 658, 309, 646, 11, 597, 321, 486, 643, 281, 853, 43819, 25589, 13, 51176], "temperature": 0.0, "avg_logprob": -0.4599361754300302, "compression_ratio": 1.4275362318840579, "no_speech_prob": 0.0005883976118639112}, {"id": 541, "seek": 250274, "start": 2518.9799999999996, "end": 2521.9799999999996, "text": " Okay.", "tokens": [51176, 1033, 13, 51326], "temperature": 0.0, "avg_logprob": -0.4599361754300302, "compression_ratio": 1.4275362318840579, "no_speech_prob": 0.0005883976118639112}, {"id": 542, "seek": 252198, "start": 2521.98, "end": 2533.06, "text": " It won't be the end of the world, it just means all the negatives will be lost here,", "tokens": [50364, 467, 1582, 380, 312, 264, 917, 295, 264, 1002, 11, 309, 445, 1355, 439, 264, 40019, 486, 312, 2731, 510, 11, 50918], "temperature": 0.0, "avg_logprob": -0.2881217554995888, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.005139280576258898}, {"id": 543, "seek": 252198, "start": 2533.06, "end": 2538.5, "text": " which makes it half, only half as useful.", "tokens": [50918, 597, 1669, 309, 1922, 11, 787, 1922, 382, 4420, 13, 51190], "temperature": 0.0, "avg_logprob": -0.2881217554995888, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.005139280576258898}, {"id": 544, "seek": 252198, "start": 2538.5, "end": 2539.5, "text": " That's not great.", "tokens": [51190, 663, 311, 406, 869, 13, 51240], "temperature": 0.0, "avg_logprob": -0.2881217554995888, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.005139280576258898}, {"id": 545, "seek": 252198, "start": 2539.5, "end": 2540.5, "text": " Okay.", "tokens": [51240, 1033, 13, 51290], "temperature": 0.0, "avg_logprob": -0.2881217554995888, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.005139280576258898}, {"id": 546, "seek": 252198, "start": 2540.5, "end": 2544.82, "text": " And these are the kind of things like, you know, as you can see, you've got to be super", "tokens": [51290, 400, 613, 366, 264, 733, 295, 721, 411, 11, 291, 458, 11, 382, 291, 393, 536, 11, 291, 600, 658, 281, 312, 1687, 51506], "temperature": 0.0, "avg_logprob": -0.2881217554995888, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.005139280576258898}, {"id": 547, "seek": 252198, "start": 2544.82, "end": 2548.78, "text": " careful of like, where do you have activation functions?", "tokens": [51506, 5026, 295, 411, 11, 689, 360, 291, 362, 24433, 6828, 30, 51704], "temperature": 0.0, "avg_logprob": -0.2881217554995888, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.005139280576258898}, {"id": 548, "seek": 252198, "start": 2548.78, "end": 2551.1, "text": " Where do you have batch norms?", "tokens": [51704, 2305, 360, 291, 362, 15245, 24357, 30, 51820], "temperature": 0.0, "avg_logprob": -0.2881217554995888, "compression_ratio": 1.5673076923076923, "no_speech_prob": 0.005139280576258898}, {"id": 549, "seek": 255110, "start": 2551.22, "end": 2556.22, "text": " Is it pre-activation, is it post-activation?", "tokens": [50370, 1119, 309, 659, 12, 23397, 399, 11, 307, 309, 2183, 12, 23397, 399, 30, 50620], "temperature": 0.0, "avg_logprob": -0.3822394852089671, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.04957977309823036}, {"id": 550, "seek": 255110, "start": 2556.22, "end": 2560.98, "text": " It trains, even if you make that mistake, and in this case, probably not too much performance,", "tokens": [50620, 467, 16329, 11, 754, 498, 291, 652, 300, 6146, 11, 293, 294, 341, 1389, 11, 1391, 406, 886, 709, 3389, 11, 50858], "temperature": 0.0, "avg_logprob": -0.3822394852089671, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.04957977309823036}, {"id": 551, "seek": 255110, "start": 2560.98, "end": 2567.06, "text": " but often it's like, oh, you've done something where you accidentally zeroed out, you know,", "tokens": [50858, 457, 2049, 309, 311, 411, 11, 1954, 11, 291, 600, 1096, 746, 689, 291, 15715, 4018, 292, 484, 11, 291, 458, 11, 51162], "temperature": 0.0, "avg_logprob": -0.3822394852089671, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.04957977309823036}, {"id": 552, "seek": 255110, "start": 2567.06, "end": 2573.2599999999998, "text": " all except the last few channels of your like outputs of the block or something like that.", "tokens": [51162, 439, 3993, 264, 1036, 1326, 9235, 295, 428, 411, 23930, 295, 264, 3461, 420, 746, 411, 300, 13, 51472], "temperature": 0.0, "avg_logprob": -0.3822394852089671, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.04957977309823036}, {"id": 553, "seek": 255110, "start": 2573.2599999999998, "end": 2577.66, "text": " And the network tries anyway, it does the best, it uses what it can.", "tokens": [51472, 400, 264, 3209, 9898, 4033, 11, 309, 775, 264, 1151, 11, 309, 4960, 437, 309, 393, 13, 51692], "temperature": 0.0, "avg_logprob": -0.3822394852089671, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.04957977309823036}, {"id": 554, "seek": 255110, "start": 2577.66, "end": 2578.66, "text": " Yeah.", "tokens": [51692, 865, 13, 51742], "temperature": 0.0, "avg_logprob": -0.3822394852089671, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.04957977309823036}, {"id": 555, "seek": 255110, "start": 2578.66, "end": 2579.66, "text": " But yeah.", "tokens": [51742, 583, 1338, 13, 51792], "temperature": 0.0, "avg_logprob": -0.3822394852089671, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.04957977309823036}, {"id": 556, "seek": 257966, "start": 2579.74, "end": 2580.74, "text": " Yeah, it makes it very difficult.", "tokens": [50368, 865, 11, 309, 1669, 309, 588, 2252, 13, 50418], "temperature": 0.0, "avg_logprob": -0.29988236581125566, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.001727414084598422}, {"id": 557, "seek": 257966, "start": 2580.74, "end": 2584.1, "text": " Make sure you're not giving it those handicaps.", "tokens": [50418, 4387, 988, 291, 434, 406, 2902, 309, 729, 31369, 2382, 13, 50586], "temperature": 0.0, "avg_logprob": -0.29988236581125566, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.001727414084598422}, {"id": 558, "seek": 257966, "start": 2584.1, "end": 2585.1, "text": " Yeah.", "tokens": [50586, 865, 13, 50636], "temperature": 0.0, "avg_logprob": -0.29988236581125566, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.001727414084598422}, {"id": 559, "seek": 257966, "start": 2585.1, "end": 2588.14, "text": " It's not like you're making a crud app or something, and you know that it's not working", "tokens": [50636, 467, 311, 406, 411, 291, 434, 1455, 257, 941, 532, 724, 420, 746, 11, 293, 291, 458, 300, 309, 311, 406, 1364, 50788], "temperature": 0.0, "avg_logprob": -0.29988236581125566, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.001727414084598422}, {"id": 560, "seek": 257966, "start": 2588.14, "end": 2597.14, "text": " because it crashes, or because like it doesn't show the username, or whatever.", "tokens": [50788, 570, 309, 28642, 11, 420, 570, 411, 309, 1177, 380, 855, 264, 30351, 11, 420, 2035, 13, 51238], "temperature": 0.0, "avg_logprob": -0.29988236581125566, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.001727414084598422}, {"id": 561, "seek": 257966, "start": 2597.14, "end": 2601.66, "text": " Instead you just get like slightly less good results, but since you haven't done it correctly", "tokens": [51238, 7156, 291, 445, 483, 411, 4748, 1570, 665, 3542, 11, 457, 1670, 291, 2378, 380, 1096, 309, 8944, 51464], "temperature": 0.0, "avg_logprob": -0.29988236581125566, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.001727414084598422}, {"id": 562, "seek": 257966, "start": 2601.66, "end": 2603.94, "text": " in the first place, you don't know it's a less good result.", "tokens": [51464, 294, 264, 700, 1081, 11, 291, 500, 380, 458, 309, 311, 257, 1570, 665, 1874, 13, 51578], "temperature": 0.0, "avg_logprob": -0.29988236581125566, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.001727414084598422}, {"id": 563, "seek": 257966, "start": 2603.94, "end": 2607.1, "text": " Yeah, there's not really great ways to do this.", "tokens": [51578, 865, 11, 456, 311, 406, 534, 869, 2098, 281, 360, 341, 13, 51736], "temperature": 0.0, "avg_logprob": -0.29988236581125566, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.001727414084598422}, {"id": 564, "seek": 260710, "start": 2607.1, "end": 2613.8199999999997, "text": " It's really nice if you can have an existing model to compare to, or something like that.", "tokens": [50364, 467, 311, 534, 1481, 498, 291, 393, 362, 364, 6741, 2316, 281, 6794, 281, 11, 420, 746, 411, 300, 13, 50700], "temperature": 0.0, "avg_logprob": -0.3450721482099113, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.022285155951976776}, {"id": 565, "seek": 260710, "start": 2613.8199999999997, "end": 2616.02, "text": " Which is where Kaggle competitions work really well, actually.", "tokens": [50700, 3013, 307, 689, 48751, 22631, 26185, 589, 534, 731, 11, 767, 13, 50810], "temperature": 0.0, "avg_logprob": -0.3450721482099113, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.022285155951976776}, {"id": 566, "seek": 260710, "start": 2616.02, "end": 2620.14, "text": " If somebody's got a Kaggle result, then you know that's a really good baseline, and you", "tokens": [50810, 759, 2618, 311, 658, 257, 48751, 22631, 1874, 11, 550, 291, 458, 300, 311, 257, 534, 665, 20518, 11, 293, 291, 51016], "temperature": 0.0, "avg_logprob": -0.3450721482099113, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.022285155951976776}, {"id": 567, "seek": 260710, "start": 2620.14, "end": 2624.1, "text": " can check whether yours is as good as theirs.", "tokens": [51016, 393, 1520, 1968, 6342, 307, 382, 665, 382, 22760, 13, 51214], "temperature": 0.0, "avg_logprob": -0.3450721482099113, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.022285155951976776}, {"id": 568, "seek": 260710, "start": 2624.1, "end": 2626.94, "text": " All right.", "tokens": [51214, 1057, 558, 13, 51356], "temperature": 0.0, "avg_logprob": -0.3450721482099113, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.022285155951976776}, {"id": 569, "seek": 260710, "start": 2626.94, "end": 2630.54, "text": " So yeah, that's what this mnrlp is for.", "tokens": [51356, 407, 1338, 11, 300, 311, 437, 341, 275, 77, 81, 75, 79, 307, 337, 13, 51536], "temperature": 0.0, "avg_logprob": -0.3450721482099113, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.022285155951976776}, {"id": 570, "seek": 260710, "start": 2630.54, "end": 2636.06, "text": " So the down and up blocks are the same as before, the conv out is the same as before.", "tokens": [51536, 407, 264, 760, 293, 493, 8474, 366, 264, 912, 382, 949, 11, 264, 3754, 484, 307, 264, 912, 382, 949, 13, 51812], "temperature": 0.0, "avg_logprob": -0.3450721482099113, "compression_ratio": 1.6987951807228916, "no_speech_prob": 0.022285155951976776}, {"id": 571, "seek": 263606, "start": 2636.06, "end": 2640.46, "text": " So yeah, so we grab our time step embeddings, that's just that outer product passed through", "tokens": [50364, 407, 1338, 11, 370, 321, 4444, 527, 565, 1823, 12240, 29432, 11, 300, 311, 445, 300, 10847, 1674, 4678, 807, 50584], "temperature": 0.0, "avg_logprob": -0.3239142894744873, "compression_ratio": 1.6395939086294415, "no_speech_prob": 0.0005792826414108276}, {"id": 572, "seek": 263606, "start": 2640.46, "end": 2643.34, "text": " this sinusoidal, the sine and cosine.", "tokens": [50584, 341, 41503, 17079, 304, 11, 264, 18609, 293, 23565, 13, 50728], "temperature": 0.0, "avg_logprob": -0.3239142894744873, "compression_ratio": 1.6395939086294415, "no_speech_prob": 0.0005792826414108276}, {"id": 573, "seek": 263606, "start": 2643.34, "end": 2658.54, "text": " We then pass that through the MLP, and then we call our downsampling, passing in those", "tokens": [50728, 492, 550, 1320, 300, 807, 264, 21601, 47, 11, 293, 550, 321, 818, 527, 760, 19988, 11970, 11, 8437, 294, 729, 51488], "temperature": 0.0, "avg_logprob": -0.3239142894744873, "compression_ratio": 1.6395939086294415, "no_speech_prob": 0.0005792826414108276}, {"id": 574, "seek": 263606, "start": 2658.54, "end": 2659.94, "text": " embeddings each time.", "tokens": [51488, 12240, 29432, 1184, 565, 13, 51558], "temperature": 0.0, "avg_logprob": -0.3239142894744873, "compression_ratio": 1.6395939086294415, "no_speech_prob": 0.0005792826414108276}, {"id": 575, "seek": 263606, "start": 2659.94, "end": 2664.18, "text": " You know, it's kind of interesting that we pass in the embeddings every time, in the", "tokens": [51558, 509, 458, 11, 309, 311, 733, 295, 1880, 300, 321, 1320, 294, 264, 12240, 29432, 633, 565, 11, 294, 264, 51770], "temperature": 0.0, "avg_logprob": -0.3239142894744873, "compression_ratio": 1.6395939086294415, "no_speech_prob": 0.0005792826414108276}, {"id": 576, "seek": 266418, "start": 2664.18, "end": 2668.5, "text": " sense I don't exactly know why we don't just pass them in at the start.", "tokens": [50364, 2020, 286, 500, 380, 2293, 458, 983, 321, 500, 380, 445, 1320, 552, 294, 412, 264, 722, 13, 50580], "temperature": 0.0, "avg_logprob": -0.33199128159531605, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0041986801661551}, {"id": 577, "seek": 266418, "start": 2668.5, "end": 2674.18, "text": " And in fact, in NLP, these kinds of embeddings, I think, are generally just passed in at the", "tokens": [50580, 400, 294, 1186, 11, 294, 426, 45196, 11, 613, 3685, 295, 12240, 29432, 11, 286, 519, 11, 366, 5101, 445, 4678, 294, 412, 264, 50864], "temperature": 0.0, "avg_logprob": -0.33199128159531605, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0041986801661551}, {"id": 578, "seek": 266418, "start": 2674.18, "end": 2675.18, "text": " start.", "tokens": [50864, 722, 13, 50914], "temperature": 0.0, "avg_logprob": -0.33199128159531605, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0041986801661551}, {"id": 579, "seek": 266418, "start": 2675.18, "end": 2677.8999999999996, "text": " So this is kind of a curious difference.", "tokens": [50914, 407, 341, 307, 733, 295, 257, 6369, 2649, 13, 51050], "temperature": 0.0, "avg_logprob": -0.33199128159531605, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0041986801661551}, {"id": 580, "seek": 266418, "start": 2677.8999999999996, "end": 2684.4199999999996, "text": " I don't know why it's, you know, if there's been ablation studies, or whatever.", "tokens": [51050, 286, 500, 380, 458, 983, 309, 311, 11, 291, 458, 11, 498, 456, 311, 668, 410, 24278, 5313, 11, 420, 2035, 13, 51376], "temperature": 0.0, "avg_logprob": -0.33199128159531605, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0041986801661551}, {"id": 581, "seek": 266418, "start": 2684.4199999999996, "end": 2690.98, "text": " Do you guys know, are there, like, any popular Diffusiony or generative models with time", "tokens": [51376, 1144, 291, 1074, 458, 11, 366, 456, 11, 411, 11, 604, 3743, 413, 3661, 301, 46184, 420, 1337, 1166, 5245, 365, 565, 51704], "temperature": 0.0, "avg_logprob": -0.33199128159531605, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.0041986801661551}, {"id": 582, "seek": 269098, "start": 2690.98, "end": 2700.5, "text": " embeddings that don't pass them in, or is this pretty universal?", "tokens": [50364, 12240, 29432, 300, 500, 380, 1320, 552, 294, 11, 420, 307, 341, 1238, 11455, 30, 50840], "temperature": 0.0, "avg_logprob": -0.33432129753960504, "compression_ratio": 1.5596330275229358, "no_speech_prob": 0.14031554758548737}, {"id": 583, "seek": 269098, "start": 2700.5, "end": 2706.18, "text": " Some of the fancier architectures, like recurrent interface networks and stuff, just pass in", "tokens": [50840, 2188, 295, 264, 3429, 27674, 6331, 1303, 11, 411, 18680, 1753, 9226, 9590, 293, 1507, 11, 445, 1320, 294, 51124], "temperature": 0.0, "avg_logprob": -0.33432129753960504, "compression_ratio": 1.5596330275229358, "no_speech_prob": 0.14031554758548737}, {"id": 584, "seek": 269098, "start": 2706.18, "end": 2707.18, "text": " the conditioning.", "tokens": [51124, 264, 21901, 13, 51174], "temperature": 0.0, "avg_logprob": -0.33432129753960504, "compression_ratio": 1.5596330275229358, "no_speech_prob": 0.14031554758548737}, {"id": 585, "seek": 269098, "start": 2707.18, "end": 2714.62, "text": " I'm actually not sure, yeah, maybe they do still do it, like, at every stage.", "tokens": [51174, 286, 478, 767, 406, 988, 11, 1338, 11, 1310, 436, 360, 920, 360, 309, 11, 411, 11, 412, 633, 3233, 13, 51546], "temperature": 0.0, "avg_logprob": -0.33432129753960504, "compression_ratio": 1.5596330275229358, "no_speech_prob": 0.14031554758548737}, {"id": 586, "seek": 269098, "start": 2714.62, "end": 2718.82, "text": " I think some of them just take in everything all at once up front, and then do a stack", "tokens": [51546, 286, 519, 512, 295, 552, 445, 747, 294, 1203, 439, 412, 1564, 493, 1868, 11, 293, 550, 360, 257, 8630, 51756], "temperature": 0.0, "avg_logprob": -0.33432129753960504, "compression_ratio": 1.5596330275229358, "no_speech_prob": 0.14031554758548737}, {"id": 587, "seek": 271882, "start": 2718.82, "end": 2720.46, "text": " of transformer blocks, or something like that.", "tokens": [50364, 295, 31782, 8474, 11, 420, 746, 411, 300, 13, 50446], "temperature": 0.0, "avg_logprob": -0.3416601278014102, "compression_ratio": 1.6278195488721805, "no_speech_prob": 0.11594057828187943}, {"id": 588, "seek": 271882, "start": 2720.46, "end": 2724.98, "text": " So I don't know if it's universal, but it definitely seems like all the unit style ones", "tokens": [50446, 407, 286, 500, 380, 458, 498, 309, 311, 11455, 11, 457, 309, 2138, 2544, 411, 439, 264, 4985, 3758, 2306, 50672], "temperature": 0.0, "avg_logprob": -0.3416601278014102, "compression_ratio": 1.6278195488721805, "no_speech_prob": 0.11594057828187943}, {"id": 589, "seek": 271882, "start": 2724.98, "end": 2729.34, "text": " have this, the time step embedding going in at all the different stages.", "tokens": [50672, 362, 341, 11, 264, 565, 1823, 12240, 3584, 516, 294, 412, 439, 264, 819, 10232, 13, 50890], "temperature": 0.0, "avg_logprob": -0.3416601278014102, "compression_ratio": 1.6278195488721805, "no_speech_prob": 0.11594057828187943}, {"id": 590, "seek": 271882, "start": 2729.34, "end": 2733.38, "text": " Maybe we should try some ablations to see, yeah, if it matters.", "tokens": [50890, 2704, 321, 820, 853, 512, 410, 75, 763, 281, 536, 11, 1338, 11, 498, 309, 7001, 13, 51092], "temperature": 0.0, "avg_logprob": -0.3416601278014102, "compression_ratio": 1.6278195488721805, "no_speech_prob": 0.11594057828187943}, {"id": 591, "seek": 271882, "start": 2733.38, "end": 2736.86, "text": " I mean, I guess it doesn't matter too much either way.", "tokens": [51092, 286, 914, 11, 286, 2041, 309, 1177, 380, 1871, 886, 709, 2139, 636, 13, 51266], "temperature": 0.0, "avg_logprob": -0.3416601278014102, "compression_ratio": 1.6278195488721805, "no_speech_prob": 0.11594057828187943}, {"id": 592, "seek": 271882, "start": 2736.86, "end": 2743.02, "text": " But yeah, if you didn't need it at every step, then it would maybe save you a bit of compute,", "tokens": [51266, 583, 1338, 11, 498, 291, 994, 380, 643, 309, 412, 633, 1823, 11, 550, 309, 576, 1310, 3155, 291, 257, 857, 295, 14722, 11, 51574], "temperature": 0.0, "avg_logprob": -0.3416601278014102, "compression_ratio": 1.6278195488721805, "no_speech_prob": 0.11594057828187943}, {"id": 593, "seek": 271882, "start": 2743.02, "end": 2744.02, "text": " potentially.", "tokens": [51574, 7263, 13, 51624], "temperature": 0.0, "avg_logprob": -0.3416601278014102, "compression_ratio": 1.6278195488721805, "no_speech_prob": 0.11594057828187943}, {"id": 594, "seek": 274402, "start": 2745.02, "end": 2750.58, "text": " Yeah, so now the upsampling, you're passing in the activations, the time step embeddings,", "tokens": [50414, 865, 11, 370, 586, 264, 15497, 335, 11970, 11, 291, 434, 8437, 294, 264, 2430, 763, 11, 264, 565, 1823, 12240, 29432, 11, 50692], "temperature": 0.0, "avg_logprob": -0.26223569446139866, "compression_ratio": 1.4015151515151516, "no_speech_prob": 0.0020829502027481794}, {"id": 595, "seek": 274402, "start": 2750.58, "end": 2754.74, "text": " and that list of saved activations.", "tokens": [50692, 293, 300, 1329, 295, 6624, 2430, 763, 13, 50900], "temperature": 0.0, "avg_logprob": -0.26223569446139866, "compression_ratio": 1.4015151515151516, "no_speech_prob": 0.0020829502027481794}, {"id": 596, "seek": 274402, "start": 2754.74, "end": 2762.82, "text": " So yeah, now we have a non-attention stable diffusion unit.", "tokens": [50900, 407, 1338, 11, 586, 321, 362, 257, 2107, 12, 1591, 1251, 8351, 25242, 4985, 13, 51304], "temperature": 0.0, "avg_logprob": -0.26223569446139866, "compression_ratio": 1.4015151515151516, "no_speech_prob": 0.0020829502027481794}, {"id": 597, "seek": 276282, "start": 2762.82, "end": 2775.7000000000003, "text": " So we can train that, and we can sample from it using the same, I just copied and pasted", "tokens": [50364, 407, 321, 393, 3847, 300, 11, 293, 321, 393, 6889, 490, 309, 1228, 264, 912, 11, 286, 445, 25365, 293, 1791, 292, 51008], "temperature": 0.0, "avg_logprob": -0.270617649472993, "compression_ratio": 1.4295774647887325, "no_speech_prob": 0.11752814799547195}, {"id": 598, "seek": 276282, "start": 2775.7000000000003, "end": 2780.26, "text": " all the stuff from the Keras notebook that we had.", "tokens": [51008, 439, 264, 1507, 490, 264, 591, 6985, 21060, 300, 321, 632, 13, 51236], "temperature": 0.0, "avg_logprob": -0.270617649472993, "compression_ratio": 1.4295774647887325, "no_speech_prob": 0.11752814799547195}, {"id": 599, "seek": 276282, "start": 2780.26, "end": 2781.26, "text": " And there we have it.", "tokens": [51236, 400, 456, 321, 362, 309, 13, 51286], "temperature": 0.0, "avg_logprob": -0.270617649472993, "compression_ratio": 1.4295774647887325, "no_speech_prob": 0.11752814799547195}, {"id": 600, "seek": 276282, "start": 2781.26, "end": 2788.7400000000002, "text": " This is our first diffusion from scratch.", "tokens": [51286, 639, 307, 527, 700, 25242, 490, 8459, 13, 51660], "temperature": 0.0, "avg_logprob": -0.270617649472993, "compression_ratio": 1.4295774647887325, "no_speech_prob": 0.11752814799547195}, {"id": 601, "seek": 278874, "start": 2789.74, "end": 2792.74, "text": " So we wrote every piece of code for this diffusion model?", "tokens": [50414, 407, 321, 4114, 633, 2522, 295, 3089, 337, 341, 25242, 2316, 30, 50564], "temperature": 0.0, "avg_logprob": -0.3338534987975504, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.012819725088775158}, {"id": 602, "seek": 278874, "start": 2792.74, "end": 2794.5, "text": " Yeah, I believe so.", "tokens": [50564, 865, 11, 286, 1697, 370, 13, 50652], "temperature": 0.0, "avg_logprob": -0.3338534987975504, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.012819725088775158}, {"id": 603, "seek": 278874, "start": 2794.5, "end": 2799.7799999999997, "text": " I mean, obviously, in terms of the optimized code of implementations of stuff, no.", "tokens": [50652, 286, 914, 11, 2745, 11, 294, 2115, 295, 264, 26941, 3089, 295, 4445, 763, 295, 1507, 11, 572, 13, 50916], "temperature": 0.0, "avg_logprob": -0.3338534987975504, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.012819725088775158}, {"id": 604, "seek": 278874, "start": 2799.7799999999997, "end": 2805.4599999999996, "text": " But yeah, we've written our version of everything here, I believe.", "tokens": [50916, 583, 1338, 11, 321, 600, 3720, 527, 3037, 295, 1203, 510, 11, 286, 1697, 13, 51200], "temperature": 0.0, "avg_logprob": -0.3338534987975504, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.012819725088775158}, {"id": 605, "seek": 278874, "start": 2805.4599999999996, "end": 2806.4599999999996, "text": " A big milestone.", "tokens": [51200, 316, 955, 28048, 13, 51250], "temperature": 0.0, "avg_logprob": -0.3338534987975504, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.012819725088775158}, {"id": 606, "seek": 278874, "start": 2806.4599999999996, "end": 2808.2999999999997, "text": " I think so, yeah.", "tokens": [51250, 286, 519, 370, 11, 1338, 13, 51342], "temperature": 0.0, "avg_logprob": -0.3338534987975504, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.012819725088775158}, {"id": 607, "seek": 278874, "start": 2808.2999999999997, "end": 2813.06, "text": " And these fits are about the same as the fits that we get from the stable diffusion one.", "tokens": [51342, 400, 613, 9001, 366, 466, 264, 912, 382, 264, 9001, 300, 321, 483, 490, 264, 8351, 25242, 472, 13, 51580], "temperature": 0.0, "avg_logprob": -0.3338534987975504, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.012819725088775158}, {"id": 608, "seek": 278874, "start": 2813.06, "end": 2816.02, "text": " They're not particularly higher or lower.", "tokens": [51580, 814, 434, 406, 4098, 2946, 420, 3126, 13, 51728], "temperature": 0.0, "avg_logprob": -0.3338534987975504, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.012819725088775158}, {"id": 609, "seek": 281602, "start": 2816.02, "end": 2818.42, "text": " They bounce around a bit, so it's a little hard to compare.", "tokens": [50364, 814, 15894, 926, 257, 857, 11, 370, 309, 311, 257, 707, 1152, 281, 6794, 13, 50484], "temperature": 0.0, "avg_logprob": -0.3722496280422458, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.007693449500948191}, {"id": 610, "seek": 281602, "start": 2818.42, "end": 2820.62, "text": " But yeah, they're basically the same.", "tokens": [50484, 583, 1338, 11, 436, 434, 1936, 264, 912, 13, 50594], "temperature": 0.0, "avg_logprob": -0.3722496280422458, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.007693449500948191}, {"id": 611, "seek": 281602, "start": 2820.62, "end": 2825.9, "text": " Yeah, so that is an exciting step.", "tokens": [50594, 865, 11, 370, 300, 307, 364, 4670, 1823, 13, 50858], "temperature": 0.0, "avg_logprob": -0.3722496280422458, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.007693449500948191}, {"id": 612, "seek": 281602, "start": 2825.9, "end": 2836.9, "text": " And OK, yeah, that's probably a good time to have a five-minute break.", "tokens": [50858, 400, 2264, 11, 1338, 11, 300, 311, 1391, 257, 665, 565, 281, 362, 257, 1732, 12, 18256, 1821, 13, 51408], "temperature": 0.0, "avg_logprob": -0.3722496280422458, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.007693449500948191}, {"id": 613, "seek": 281602, "start": 2836.9, "end": 2843.02, "text": " Yeah, OK, let's have a five-minute break.", "tokens": [51408, 865, 11, 2264, 11, 718, 311, 362, 257, 1732, 12, 18256, 1821, 13, 51714], "temperature": 0.0, "avg_logprob": -0.3722496280422458, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.007693449500948191}, {"id": 614, "seek": 284302, "start": 2844.02, "end": 2851.7, "text": " OK, normally I would say we're back, but only some of us are back.", "tokens": [50414, 2264, 11, 5646, 286, 576, 584, 321, 434, 646, 11, 457, 787, 512, 295, 505, 366, 646, 13, 50798], "temperature": 0.0, "avg_logprob": -0.3207094669342041, "compression_ratio": 1.5, "no_speech_prob": 0.0013453413266688585}, {"id": 615, "seek": 284302, "start": 2851.7, "end": 2856.9, "text": " Jano's internet and electricity in Zimbabwe is not the most reliable thing, and he seems", "tokens": [50798, 508, 3730, 311, 4705, 293, 10356, 294, 1176, 17306, 455, 826, 307, 406, 264, 881, 12924, 551, 11, 293, 415, 2544, 51058], "temperature": 0.0, "avg_logprob": -0.3207094669342041, "compression_ratio": 1.5, "no_speech_prob": 0.0013453413266688585}, {"id": 616, "seek": 284302, "start": 2856.9, "end": 2857.9, "text": " to have disappeared.", "tokens": [51058, 281, 362, 13954, 13, 51108], "temperature": 0.0, "avg_logprob": -0.3207094669342041, "compression_ratio": 1.5, "no_speech_prob": 0.0013453413266688585}, {"id": 617, "seek": 284302, "start": 2857.9, "end": 2860.02, "text": " But we expect him to reappear at some point.", "tokens": [51108, 583, 321, 2066, 796, 281, 35638, 14881, 412, 512, 935, 13, 51214], "temperature": 0.0, "avg_logprob": -0.3207094669342041, "compression_ratio": 1.5, "no_speech_prob": 0.0013453413266688585}, {"id": 618, "seek": 284302, "start": 2860.02, "end": 2872.02, "text": " So we'll kick on Jano-less and hope that Zimbabwe's infrastructure sorts itself out.", "tokens": [51214, 407, 321, 603, 4437, 322, 508, 3730, 12, 1832, 293, 1454, 300, 1176, 17306, 455, 826, 311, 6896, 7527, 2564, 484, 13, 51814], "temperature": 0.0, "avg_logprob": -0.3207094669342041, "compression_ratio": 1.5, "no_speech_prob": 0.0013453413266688585}, {"id": 619, "seek": 287202, "start": 2873.02, "end": 2877.34, "text": " All right, so we're going to talk about attention.", "tokens": [50414, 1057, 558, 11, 370, 321, 434, 516, 281, 751, 466, 3202, 13, 50630], "temperature": 0.0, "avg_logprob": -0.24202078961311502, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0016856933943927288}, {"id": 620, "seek": 287202, "start": 2877.34, "end": 2880.22, "text": " We're going to talk about attention for a few reasons.", "tokens": [50630, 492, 434, 516, 281, 751, 466, 3202, 337, 257, 1326, 4112, 13, 50774], "temperature": 0.0, "avg_logprob": -0.24202078961311502, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0016856933943927288}, {"id": 621, "seek": 287202, "start": 2880.22, "end": 2882.2599999999998, "text": " Reason number one, very pragmatic.", "tokens": [50774, 39693, 1230, 472, 11, 588, 46904, 13, 50876], "temperature": 0.0, "avg_logprob": -0.24202078961311502, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0016856933943927288}, {"id": 622, "seek": 287202, "start": 2882.2599999999998, "end": 2886.42, "text": " We said that we would replicate stable diffusion, and the stable diffusion unit has attention", "tokens": [50876, 492, 848, 300, 321, 576, 25356, 8351, 25242, 11, 293, 264, 8351, 25242, 4985, 575, 3202, 51084], "temperature": 0.0, "avg_logprob": -0.24202078961311502, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0016856933943927288}, {"id": 623, "seek": 287202, "start": 2886.42, "end": 2887.66, "text": " in it.", "tokens": [51084, 294, 309, 13, 51146], "temperature": 0.0, "avg_logprob": -0.24202078961311502, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0016856933943927288}, {"id": 624, "seek": 287202, "start": 2887.66, "end": 2892.66, "text": " So we would be lying if we didn't do attention.", "tokens": [51146, 407, 321, 576, 312, 8493, 498, 321, 994, 380, 360, 3202, 13, 51396], "temperature": 0.0, "avg_logprob": -0.24202078961311502, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0016856933943927288}, {"id": 625, "seek": 287202, "start": 2892.66, "end": 2899.98, "text": " Number two, attention is one of the two basic building blocks of transformers.", "tokens": [51396, 5118, 732, 11, 3202, 307, 472, 295, 264, 732, 3875, 2390, 8474, 295, 4088, 433, 13, 51762], "temperature": 0.0, "avg_logprob": -0.24202078961311502, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0016856933943927288}, {"id": 626, "seek": 289998, "start": 2899.98, "end": 2905.9, "text": " A transformer layer is attention attached to a one-layer MLP.", "tokens": [50364, 316, 31782, 4583, 307, 3202, 8570, 281, 257, 472, 12, 8376, 260, 21601, 47, 13, 50660], "temperature": 0.0, "avg_logprob": -0.23805825975206163, "compression_ratio": 1.7128205128205127, "no_speech_prob": 8.219991286750883e-05}, {"id": 627, "seek": 289998, "start": 2905.9, "end": 2910.34, "text": " We already know how to create a one-layer or one hidden layer MLP.", "tokens": [50660, 492, 1217, 458, 577, 281, 1884, 257, 472, 12, 8376, 260, 420, 472, 7633, 4583, 21601, 47, 13, 50882], "temperature": 0.0, "avg_logprob": -0.23805825975206163, "compression_ratio": 1.7128205128205127, "no_speech_prob": 8.219991286750883e-05}, {"id": 628, "seek": 289998, "start": 2910.34, "end": 2918.86, "text": " So once we learn how to do attention, we'll know how to create transformer blocks.", "tokens": [50882, 407, 1564, 321, 1466, 577, 281, 360, 3202, 11, 321, 603, 458, 577, 281, 1884, 31782, 8474, 13, 51308], "temperature": 0.0, "avg_logprob": -0.23805825975206163, "compression_ratio": 1.7128205128205127, "no_speech_prob": 8.219991286750883e-05}, {"id": 629, "seek": 289998, "start": 2918.86, "end": 2924.66, "text": " So those are two good reasons.", "tokens": [51308, 407, 729, 366, 732, 665, 4112, 13, 51598], "temperature": 0.0, "avg_logprob": -0.23805825975206163, "compression_ratio": 1.7128205128205127, "no_speech_prob": 8.219991286750883e-05}, {"id": 630, "seek": 289998, "start": 2924.66, "end": 2928.42, "text": " I'm not including a reason which is our model is going to look a lot better with attention,", "tokens": [51598, 286, 478, 406, 3009, 257, 1778, 597, 307, 527, 2316, 307, 516, 281, 574, 257, 688, 1101, 365, 3202, 11, 51786], "temperature": 0.0, "avg_logprob": -0.23805825975206163, "compression_ratio": 1.7128205128205127, "no_speech_prob": 8.219991286750883e-05}, {"id": 631, "seek": 292842, "start": 2928.5, "end": 2934.78, "text": " because I actually haven't had any success seeing any diffusion models I've trained work", "tokens": [50368, 570, 286, 767, 2378, 380, 632, 604, 2245, 2577, 604, 25242, 5245, 286, 600, 8895, 589, 50682], "temperature": 0.0, "avg_logprob": -0.2641825218723245, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.000969689863268286}, {"id": 632, "seek": 292842, "start": 2934.78, "end": 2937.1, "text": " better with attention.", "tokens": [50682, 1101, 365, 3202, 13, 50798], "temperature": 0.0, "avg_logprob": -0.2641825218723245, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.000969689863268286}, {"id": 633, "seek": 292842, "start": 2937.1, "end": 2942.7000000000003, "text": " So just to set your expectations, we are going to get it all working.", "tokens": [50798, 407, 445, 281, 992, 428, 9843, 11, 321, 366, 516, 281, 483, 309, 439, 1364, 13, 51078], "temperature": 0.0, "avg_logprob": -0.2641825218723245, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.000969689863268286}, {"id": 634, "seek": 292842, "start": 2942.7000000000003, "end": 2948.94, "text": " But regardless of whether I use our implementation of attention or the diffuser's one, it's not", "tokens": [51078, 583, 10060, 295, 1968, 286, 764, 527, 11420, 295, 3202, 420, 264, 7593, 18088, 311, 472, 11, 309, 311, 406, 51390], "temperature": 0.0, "avg_logprob": -0.2641825218723245, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.000969689863268286}, {"id": 635, "seek": 292842, "start": 2948.94, "end": 2952.42, "text": " actually making it better.", "tokens": [51390, 767, 1455, 309, 1101, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2641825218723245, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.000969689863268286}, {"id": 636, "seek": 295242, "start": 2952.42, "end": 2959.2200000000003, "text": " That might be because we need to use better types of attention than what diffusers has,", "tokens": [50364, 663, 1062, 312, 570, 321, 643, 281, 764, 1101, 3467, 295, 3202, 813, 437, 7593, 301, 433, 575, 11, 50704], "temperature": 0.0, "avg_logprob": -0.24170910043919341, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004904424771666527}, {"id": 637, "seek": 295242, "start": 2959.2200000000003, "end": 2965.62, "text": " or it might be because it's just a very subtle difference that you only see on bigger images.", "tokens": [50704, 420, 309, 1062, 312, 570, 309, 311, 445, 257, 588, 13743, 2649, 300, 291, 787, 536, 322, 3801, 5267, 13, 51024], "temperature": 0.0, "avg_logprob": -0.24170910043919341, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004904424771666527}, {"id": 638, "seek": 295242, "start": 2965.62, "end": 2966.7400000000002, "text": " I'm not sure.", "tokens": [51024, 286, 478, 406, 988, 13, 51080], "temperature": 0.0, "avg_logprob": -0.24170910043919341, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004904424771666527}, {"id": 639, "seek": 295242, "start": 2966.7400000000002, "end": 2969.7400000000002, "text": " That's something we're still trying to figure out.", "tokens": [51080, 663, 311, 746, 321, 434, 920, 1382, 281, 2573, 484, 13, 51230], "temperature": 0.0, "avg_logprob": -0.24170910043919341, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004904424771666527}, {"id": 640, "seek": 295242, "start": 2969.7400000000002, "end": 2976.62, "text": " This is all pretty new, and not many people have done the kind of ablation studies necessary", "tokens": [51230, 639, 307, 439, 1238, 777, 11, 293, 406, 867, 561, 362, 1096, 264, 733, 295, 410, 24278, 5313, 4818, 51574], "temperature": 0.0, "avg_logprob": -0.24170910043919341, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004904424771666527}, {"id": 641, "seek": 295242, "start": 2976.62, "end": 2978.9, "text": " to figure these things out.", "tokens": [51574, 281, 2573, 613, 721, 484, 13, 51688], "temperature": 0.0, "avg_logprob": -0.24170910043919341, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.004904424771666527}, {"id": 642, "seek": 297890, "start": 2978.9, "end": 2982.26, "text": " So yeah, that's just life.", "tokens": [50364, 407, 1338, 11, 300, 311, 445, 993, 13, 50532], "temperature": 0.0, "avg_logprob": -0.3413743865623903, "compression_ratio": 1.523076923076923, "no_speech_prob": 0.0013668134342879057}, {"id": 643, "seek": 297890, "start": 2982.26, "end": 2985.98, "text": " Anyway, so there's lots of good reasons to know about attention.", "tokens": [50532, 5684, 11, 370, 456, 311, 3195, 295, 665, 4112, 281, 458, 466, 3202, 13, 50718], "temperature": 0.0, "avg_logprob": -0.3413743865623903, "compression_ratio": 1.523076923076923, "no_speech_prob": 0.0013668134342879057}, {"id": 644, "seek": 297890, "start": 2985.98, "end": 2989.54, "text": " We'll certainly be using it a lot once we do an LP, which we'll be coming to pretty", "tokens": [50718, 492, 603, 3297, 312, 1228, 309, 257, 688, 1564, 321, 360, 364, 38095, 11, 597, 321, 603, 312, 1348, 281, 1238, 50896], "temperature": 0.0, "avg_logprob": -0.3413743865623903, "compression_ratio": 1.523076923076923, "no_speech_prob": 0.0013668134342879057}, {"id": 645, "seek": 297890, "start": 2989.54, "end": 2993.98, "text": " shortly, pretty soon.", "tokens": [50896, 13392, 11, 1238, 2321, 13, 51118], "temperature": 0.0, "avg_logprob": -0.3413743865623903, "compression_ratio": 1.523076923076923, "no_speech_prob": 0.0013668134342879057}, {"id": 646, "seek": 297890, "start": 2993.98, "end": 2997.9, "text": " And it looks like Jono is reappearing as well, so that's good.", "tokens": [51118, 400, 309, 1542, 411, 7745, 78, 307, 35638, 68, 1921, 382, 731, 11, 370, 300, 311, 665, 13, 51314], "temperature": 0.0, "avg_logprob": -0.3413743865623903, "compression_ratio": 1.523076923076923, "no_speech_prob": 0.0013668134342879057}, {"id": 647, "seek": 297890, "start": 2997.9, "end": 3006.1, "text": " Okay, so let's talk about attention.", "tokens": [51314, 1033, 11, 370, 718, 311, 751, 466, 3202, 13, 51724], "temperature": 0.0, "avg_logprob": -0.3413743865623903, "compression_ratio": 1.523076923076923, "no_speech_prob": 0.0013668134342879057}, {"id": 648, "seek": 300610, "start": 3006.1, "end": 3021.2599999999998, "text": " The basic idea of attention is that we have, you know, an image, and we're going to be", "tokens": [50364, 440, 3875, 1558, 295, 3202, 307, 300, 321, 362, 11, 291, 458, 11, 364, 3256, 11, 293, 321, 434, 516, 281, 312, 51122], "temperature": 0.0, "avg_logprob": -0.3204289504459926, "compression_ratio": 1.3586206896551725, "no_speech_prob": 5.56218292331323e-05}, {"id": 649, "seek": 300610, "start": 3021.2599999999998, "end": 3026.7799999999997, "text": " sliding a convolution kernel across that image.", "tokens": [51122, 21169, 257, 45216, 28256, 2108, 300, 3256, 13, 51398], "temperature": 0.0, "avg_logprob": -0.3204289504459926, "compression_ratio": 1.3586206896551725, "no_speech_prob": 5.56218292331323e-05}, {"id": 650, "seek": 300610, "start": 3026.7799999999997, "end": 3027.7799999999997, "text": " Right?", "tokens": [51398, 1779, 30, 51448], "temperature": 0.0, "avg_logprob": -0.3204289504459926, "compression_ratio": 1.3586206896551725, "no_speech_prob": 5.56218292331323e-05}, {"id": 651, "seek": 300610, "start": 3027.7799999999997, "end": 3035.14, "text": " And, obviously, we've got channels as well, or filters.", "tokens": [51448, 400, 11, 2745, 11, 321, 600, 658, 9235, 382, 731, 11, 420, 15995, 13, 51816], "temperature": 0.0, "avg_logprob": -0.3204289504459926, "compression_ratio": 1.3586206896551725, "no_speech_prob": 5.56218292331323e-05}, {"id": 652, "seek": 303514, "start": 3035.18, "end": 3037.18, "text": " And so this also has that.", "tokens": [50366, 400, 370, 341, 611, 575, 300, 13, 50466], "temperature": 0.0, "avg_logprob": -0.272249262820008, "compression_ratio": 1.675, "no_speech_prob": 4.069439455633983e-05}, {"id": 653, "seek": 303514, "start": 3037.18, "end": 3038.5, "text": " Okay.", "tokens": [50466, 1033, 13, 50532], "temperature": 0.0, "avg_logprob": -0.272249262820008, "compression_ratio": 1.675, "no_speech_prob": 4.069439455633983e-05}, {"id": 654, "seek": 303514, "start": 3038.5, "end": 3045.74, "text": " And as we bring it across, we might be, you know, we're trying to figure out, like, what", "tokens": [50532, 400, 382, 321, 1565, 309, 2108, 11, 321, 1062, 312, 11, 291, 458, 11, 321, 434, 1382, 281, 2573, 484, 11, 411, 11, 437, 50894], "temperature": 0.0, "avg_logprob": -0.272249262820008, "compression_ratio": 1.675, "no_speech_prob": 4.069439455633983e-05}, {"id": 655, "seek": 303514, "start": 3045.74, "end": 3053.7, "text": " activations do we need to create to eventually, you know, correctly create our outputs.", "tokens": [50894, 2430, 763, 360, 321, 643, 281, 1884, 281, 4728, 11, 291, 458, 11, 8944, 1884, 527, 23930, 13, 51292], "temperature": 0.0, "avg_logprob": -0.272249262820008, "compression_ratio": 1.675, "no_speech_prob": 4.069439455633983e-05}, {"id": 656, "seek": 303514, "start": 3053.7, "end": 3061.94, "text": " But the correct answer as to what's here may depend on something that's way over here,", "tokens": [51292, 583, 264, 3006, 1867, 382, 281, 437, 311, 510, 815, 5672, 322, 746, 300, 311, 636, 670, 510, 11, 51704], "temperature": 0.0, "avg_logprob": -0.272249262820008, "compression_ratio": 1.675, "no_speech_prob": 4.069439455633983e-05}, {"id": 657, "seek": 303514, "start": 3061.94, "end": 3064.7799999999997, "text": " and or something that's way over here.", "tokens": [51704, 293, 420, 746, 300, 311, 636, 670, 510, 13, 51846], "temperature": 0.0, "avg_logprob": -0.272249262820008, "compression_ratio": 1.675, "no_speech_prob": 4.069439455633983e-05}, {"id": 658, "seek": 306478, "start": 3065.42, "end": 3072.5800000000004, "text": " So, for example, if it's a cute little bunny rabbit, and this is where its ear is, you", "tokens": [50396, 407, 11, 337, 1365, 11, 498, 309, 311, 257, 4052, 707, 28588, 19509, 11, 293, 341, 307, 689, 1080, 1273, 307, 11, 291, 50754], "temperature": 0.0, "avg_logprob": -0.24597649933189475, "compression_ratio": 1.5746606334841629, "no_speech_prob": 1.5294122022169176e-06}, {"id": 659, "seek": 306478, "start": 3072.5800000000004, "end": 3076.5400000000004, "text": " know, and there might be two different types of bunny rabbit that have different shaped", "tokens": [50754, 458, 11, 293, 456, 1062, 312, 732, 819, 3467, 295, 28588, 19509, 300, 362, 819, 13475, 50952], "temperature": 0.0, "avg_logprob": -0.24597649933189475, "compression_ratio": 1.5746606334841629, "no_speech_prob": 1.5294122022169176e-06}, {"id": 660, "seek": 306478, "start": 3076.5400000000004, "end": 3082.5400000000004, "text": " ears, well, it would be really nice to be able to see over here what its other ear looks", "tokens": [50952, 8798, 11, 731, 11, 309, 576, 312, 534, 1481, 281, 312, 1075, 281, 536, 670, 510, 437, 1080, 661, 1273, 1542, 51252], "temperature": 0.0, "avg_logprob": -0.24597649933189475, "compression_ratio": 1.5746606334841629, "no_speech_prob": 1.5294122022169176e-06}, {"id": 661, "seek": 306478, "start": 3082.5400000000004, "end": 3087.26, "text": " like, for instance.", "tokens": [51252, 411, 11, 337, 5197, 13, 51488], "temperature": 0.0, "avg_logprob": -0.24597649933189475, "compression_ratio": 1.5746606334841629, "no_speech_prob": 1.5294122022169176e-06}, {"id": 662, "seek": 306478, "start": 3087.26, "end": 3089.1000000000004, "text": " With just convolutions, that's challenging.", "tokens": [51488, 2022, 445, 3754, 15892, 11, 300, 311, 7595, 13, 51580], "temperature": 0.0, "avg_logprob": -0.24597649933189475, "compression_ratio": 1.5746606334841629, "no_speech_prob": 1.5294122022169176e-06}, {"id": 663, "seek": 306478, "start": 3089.1000000000004, "end": 3090.1000000000004, "text": " It's not impossible.", "tokens": [51580, 467, 311, 406, 6243, 13, 51630], "temperature": 0.0, "avg_logprob": -0.24597649933189475, "compression_ratio": 1.5746606334841629, "no_speech_prob": 1.5294122022169176e-06}, {"id": 664, "seek": 309010, "start": 3090.1, "end": 3094.38, "text": " We talked in part one about the receptive field.", "tokens": [50364, 492, 2825, 294, 644, 472, 466, 264, 45838, 2519, 13, 50578], "temperature": 0.0, "avg_logprob": -0.2828661918640137, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.0018967926735058427}, {"id": 665, "seek": 309010, "start": 3094.38, "end": 3101.2599999999998, "text": " And as you get deeper and deeper in a conv net, the receptive field gets bigger and bigger.", "tokens": [50578, 400, 382, 291, 483, 7731, 293, 7731, 294, 257, 3754, 2533, 11, 264, 45838, 2519, 2170, 3801, 293, 3801, 13, 50922], "temperature": 0.0, "avg_logprob": -0.2828661918640137, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.0018967926735058427}, {"id": 666, "seek": 309010, "start": 3101.2599999999998, "end": 3104.94, "text": " But it's, you know, at higher up, it probably can't see the other ear at all.", "tokens": [50922, 583, 309, 311, 11, 291, 458, 11, 412, 2946, 493, 11, 309, 1391, 393, 380, 536, 264, 661, 1273, 412, 439, 13, 51106], "temperature": 0.0, "avg_logprob": -0.2828661918640137, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.0018967926735058427}, {"id": 667, "seek": 309010, "start": 3104.94, "end": 3109.54, "text": " So it can't put it into those kind of more texture level layers.", "tokens": [51106, 407, 309, 393, 380, 829, 309, 666, 729, 733, 295, 544, 8091, 1496, 7914, 13, 51336], "temperature": 0.0, "avg_logprob": -0.2828661918640137, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.0018967926735058427}, {"id": 668, "seek": 309010, "start": 3109.54, "end": 3116.1, "text": " And later on, you know, even though this might be in the receptive field of here, most of", "tokens": [51336, 400, 1780, 322, 11, 291, 458, 11, 754, 1673, 341, 1062, 312, 294, 264, 45838, 2519, 295, 510, 11, 881, 295, 51664], "temperature": 0.0, "avg_logprob": -0.2828661918640137, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.0018967926735058427}, {"id": 669, "seek": 311610, "start": 3116.1, "end": 3119.98, "text": " the weight, you know, the vast majority of the activations it's using is the stuff immediately", "tokens": [50364, 264, 3364, 11, 291, 458, 11, 264, 8369, 6286, 295, 264, 2430, 763, 309, 311, 1228, 307, 264, 1507, 4258, 50558], "temperature": 0.0, "avg_logprob": -0.2246566865502334, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.0003740874817594886}, {"id": 670, "seek": 311610, "start": 3119.98, "end": 3120.98, "text": " around it.", "tokens": [50558, 926, 309, 13, 50608], "temperature": 0.0, "avg_logprob": -0.2246566865502334, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.0003740874817594886}, {"id": 671, "seek": 311610, "start": 3120.98, "end": 3132.54, "text": " So what attention does is it lets you take a weighted average of other pixels around", "tokens": [50608, 407, 437, 3202, 775, 307, 309, 6653, 291, 747, 257, 32807, 4274, 295, 661, 18668, 926, 51186], "temperature": 0.0, "avg_logprob": -0.2246566865502334, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.0003740874817594886}, {"id": 672, "seek": 311610, "start": 3132.54, "end": 3137.22, "text": " the image, regardless of how far away they are.", "tokens": [51186, 264, 3256, 11, 10060, 295, 577, 1400, 1314, 436, 366, 13, 51420], "temperature": 0.0, "avg_logprob": -0.2246566865502334, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.0003740874817594886}, {"id": 673, "seek": 311610, "start": 3137.22, "end": 3141.74, "text": " And so in this case, for example, we might be interested in bringing in at least a few", "tokens": [51420, 400, 370, 294, 341, 1389, 11, 337, 1365, 11, 321, 1062, 312, 3102, 294, 5062, 294, 412, 1935, 257, 1326, 51646], "temperature": 0.0, "avg_logprob": -0.2246566865502334, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.0003740874817594886}, {"id": 674, "seek": 314174, "start": 3141.74, "end": 3148.5, "text": " of the channels of these pixels over here.", "tokens": [50364, 295, 264, 9235, 295, 613, 18668, 670, 510, 13, 50702], "temperature": 0.0, "avg_logprob": -0.2693079047732883, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.027155842632055283}, {"id": 675, "seek": 314174, "start": 3148.5, "end": 3162.2999999999997, "text": " The way that attention is done in stable diffusion is pretty hacky, and known to be suboptimal.", "tokens": [50702, 440, 636, 300, 3202, 307, 1096, 294, 8351, 25242, 307, 1238, 10339, 88, 11, 293, 2570, 281, 312, 1422, 5747, 10650, 13, 51392], "temperature": 0.0, "avg_logprob": -0.2693079047732883, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.027155842632055283}, {"id": 676, "seek": 314174, "start": 3162.2999999999997, "end": 3165.5, "text": " But it's what we're going to implement, because we're implementing stable diffusion, and time", "tokens": [51392, 583, 309, 311, 437, 321, 434, 516, 281, 4445, 11, 570, 321, 434, 18114, 8351, 25242, 11, 293, 565, 51552], "temperature": 0.0, "avg_logprob": -0.2693079047732883, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.027155842632055283}, {"id": 677, "seek": 314174, "start": 3165.5, "end": 3169.2799999999997, "text": " permitting maybe we'll look at some other options later.", "tokens": [51552, 4784, 2414, 1310, 321, 603, 574, 412, 512, 661, 3956, 1780, 13, 51741], "temperature": 0.0, "avg_logprob": -0.2693079047732883, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.027155842632055283}, {"id": 678, "seek": 316928, "start": 3169.32, "end": 3173.0, "text": " The kind of attention we're going to be doing is 1D attention.", "tokens": [50366, 440, 733, 295, 3202, 321, 434, 516, 281, 312, 884, 307, 502, 35, 3202, 13, 50550], "temperature": 0.0, "avg_logprob": -0.2597338797032148, "compression_ratio": 1.7243243243243243, "no_speech_prob": 9.461147419642657e-05}, {"id": 679, "seek": 316928, "start": 3173.0, "end": 3178.1200000000003, "text": " And it was attention that was developed for NLP.", "tokens": [50550, 400, 309, 390, 3202, 300, 390, 4743, 337, 426, 45196, 13, 50806], "temperature": 0.0, "avg_logprob": -0.2597338797032148, "compression_ratio": 1.7243243243243243, "no_speech_prob": 9.461147419642657e-05}, {"id": 680, "seek": 316928, "start": 3178.1200000000003, "end": 3182.2400000000002, "text": " And NLP is sequences, one-dimensional sequences of tokens.", "tokens": [50806, 400, 426, 45196, 307, 22978, 11, 472, 12, 18759, 22978, 295, 22667, 13, 51012], "temperature": 0.0, "avg_logprob": -0.2597338797032148, "compression_ratio": 1.7243243243243243, "no_speech_prob": 9.461147419642657e-05}, {"id": 681, "seek": 316928, "start": 3182.2400000000002, "end": 3187.84, "text": " So to do attention stable diffusion style, we're going to take this image, and we're", "tokens": [51012, 407, 281, 360, 3202, 8351, 25242, 3758, 11, 321, 434, 516, 281, 747, 341, 3256, 11, 293, 321, 434, 51292], "temperature": 0.0, "avg_logprob": -0.2597338797032148, "compression_ratio": 1.7243243243243243, "no_speech_prob": 9.461147419642657e-05}, {"id": 682, "seek": 316928, "start": 3187.84, "end": 3192.88, "text": " going to flatten out the pixels.", "tokens": [51292, 516, 281, 24183, 484, 264, 18668, 13, 51544], "temperature": 0.0, "avg_logprob": -0.2597338797032148, "compression_ratio": 1.7243243243243243, "no_speech_prob": 9.461147419642657e-05}, {"id": 683, "seek": 316928, "start": 3192.88, "end": 3194.2000000000003, "text": " So we've got all these pixels.", "tokens": [51544, 407, 321, 600, 658, 439, 613, 18668, 13, 51610], "temperature": 0.0, "avg_logprob": -0.2597338797032148, "compression_ratio": 1.7243243243243243, "no_speech_prob": 9.461147419642657e-05}, {"id": 684, "seek": 319420, "start": 3194.2, "end": 3198.68, "text": " We're going to take this row, and put it here.", "tokens": [50364, 492, 434, 516, 281, 747, 341, 5386, 11, 293, 829, 309, 510, 13, 50588], "temperature": 0.0, "avg_logprob": -0.318057212509027, "compression_ratio": 2.080402010050251, "no_speech_prob": 0.07263120263814926}, {"id": 685, "seek": 319420, "start": 3198.68, "end": 3201.08, "text": " And then we're going to take this row, we're going to put it here.", "tokens": [50588, 400, 550, 321, 434, 516, 281, 747, 341, 5386, 11, 321, 434, 516, 281, 829, 309, 510, 13, 50708], "temperature": 0.0, "avg_logprob": -0.318057212509027, "compression_ratio": 2.080402010050251, "no_speech_prob": 0.07263120263814926}, {"id": 686, "seek": 319420, "start": 3201.08, "end": 3207.52, "text": " So we're just going to flatten the whole thing out into one big vector of all the pixels", "tokens": [50708, 407, 321, 434, 445, 516, 281, 24183, 264, 1379, 551, 484, 666, 472, 955, 8062, 295, 439, 264, 18668, 51030], "temperature": 0.0, "avg_logprob": -0.318057212509027, "compression_ratio": 2.080402010050251, "no_speech_prob": 0.07263120263814926}, {"id": 687, "seek": 319420, "start": 3207.52, "end": 3210.8399999999997, "text": " of row one, and then all the pixels of row two, and then all the pixels of row three.", "tokens": [51030, 295, 5386, 472, 11, 293, 550, 439, 264, 18668, 295, 5386, 732, 11, 293, 550, 439, 264, 18668, 295, 5386, 1045, 13, 51196], "temperature": 0.0, "avg_logprob": -0.318057212509027, "compression_ratio": 2.080402010050251, "no_speech_prob": 0.07263120263814926}, {"id": 688, "seek": 319420, "start": 3210.8399999999997, "end": 3212.3199999999997, "text": " Or maybe it's column one, column two, column three.", "tokens": [51196, 1610, 1310, 309, 311, 7738, 472, 11, 7738, 732, 11, 7738, 1045, 13, 51270], "temperature": 0.0, "avg_logprob": -0.318057212509027, "compression_ratio": 2.080402010050251, "no_speech_prob": 0.07263120263814926}, {"id": 689, "seek": 319420, "start": 3212.3199999999997, "end": 3219.64, "text": " I can't remember if it's row wise or column wise, but it's flattened out.", "tokens": [51270, 286, 393, 380, 1604, 498, 309, 311, 5386, 10829, 420, 7738, 10829, 11, 457, 309, 311, 24183, 292, 484, 13, 51636], "temperature": 0.0, "avg_logprob": -0.318057212509027, "compression_ratio": 2.080402010050251, "no_speech_prob": 0.07263120263814926}, {"id": 690, "seek": 321964, "start": 3219.64, "end": 3228.2, "text": " And then it's actually, for each image, it's actually, you know, a matrix, which I'm going", "tokens": [50364, 400, 550, 309, 311, 767, 11, 337, 1184, 3256, 11, 309, 311, 767, 11, 291, 458, 11, 257, 8141, 11, 597, 286, 478, 516, 50792], "temperature": 0.0, "avg_logprob": -0.2550956826460989, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0010987221030518413}, {"id": 691, "seek": 321964, "start": 3228.2, "end": 3236.24, "text": " to draw it a little bit 3D, because we've got the channel dimension as well.", "tokens": [50792, 281, 2642, 309, 257, 707, 857, 805, 35, 11, 570, 321, 600, 658, 264, 2269, 10139, 382, 731, 13, 51194], "temperature": 0.0, "avg_logprob": -0.2550956826460989, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0010987221030518413}, {"id": 692, "seek": 321964, "start": 3236.24, "end": 3241.4, "text": " So this is going to be the number across this way is going to be equal to the height times", "tokens": [51194, 407, 341, 307, 516, 281, 312, 264, 1230, 2108, 341, 636, 307, 516, 281, 312, 2681, 281, 264, 6681, 1413, 51452], "temperature": 0.0, "avg_logprob": -0.2550956826460989, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0010987221030518413}, {"id": 693, "seek": 321964, "start": 3241.4, "end": 3243.52, "text": " the width.", "tokens": [51452, 264, 11402, 13, 51558], "temperature": 0.0, "avg_logprob": -0.2550956826460989, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0010987221030518413}, {"id": 694, "seek": 324352, "start": 3243.52, "end": 3251.36, "text": " And then the number this way is going to be the number of channels.", "tokens": [50364, 400, 550, 264, 1230, 341, 636, 307, 516, 281, 312, 264, 1230, 295, 9235, 13, 50756], "temperature": 0.0, "avg_logprob": -0.2897184090536149, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.00013552021118812263}, {"id": 695, "seek": 324352, "start": 3251.36, "end": 3264.64, "text": " OK, so how do we decide, yeah, which, you know, bring in these other pixels?", "tokens": [50756, 2264, 11, 370, 577, 360, 321, 4536, 11, 1338, 11, 597, 11, 291, 458, 11, 1565, 294, 613, 661, 18668, 30, 51420], "temperature": 0.0, "avg_logprob": -0.2897184090536149, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.00013552021118812263}, {"id": 696, "seek": 324352, "start": 3264.64, "end": 3272.52, "text": " Well what we do is we basically create a weighted average of all of these pixels.", "tokens": [51420, 1042, 437, 321, 360, 307, 321, 1936, 1884, 257, 32807, 4274, 295, 439, 295, 613, 18668, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2897184090536149, "compression_ratio": 1.4580645161290322, "no_speech_prob": 0.00013552021118812263}, {"id": 697, "seek": 327252, "start": 3272.52, "end": 3279.24, "text": " So maybe these ones get a bit of a negative weight.", "tokens": [50364, 407, 1310, 613, 2306, 483, 257, 857, 295, 257, 3671, 3364, 13, 50700], "temperature": 0.0, "avg_logprob": -0.2072286605834961, "compression_ratio": 1.7914110429447854, "no_speech_prob": 4.63787182525266e-06}, {"id": 698, "seek": 327252, "start": 3279.24, "end": 3284.44, "text": " And these ones get a bit of a positive weight.", "tokens": [50700, 400, 613, 2306, 483, 257, 857, 295, 257, 3353, 3364, 13, 50960], "temperature": 0.0, "avg_logprob": -0.2072286605834961, "compression_ratio": 1.7914110429447854, "no_speech_prob": 4.63787182525266e-06}, {"id": 699, "seek": 327252, "start": 3284.44, "end": 3289.4, "text": " And you know, these get a weight kind of somewhere in between.", "tokens": [50960, 400, 291, 458, 11, 613, 483, 257, 3364, 733, 295, 4079, 294, 1296, 13, 51208], "temperature": 0.0, "avg_logprob": -0.2072286605834961, "compression_ratio": 1.7914110429447854, "no_speech_prob": 4.63787182525266e-06}, {"id": 700, "seek": 327252, "start": 3289.4, "end": 3291.2599999999998, "text": " And so we're going to have a weighted average.", "tokens": [51208, 400, 370, 321, 434, 516, 281, 362, 257, 32807, 4274, 13, 51301], "temperature": 0.0, "avg_logprob": -0.2072286605834961, "compression_ratio": 1.7914110429447854, "no_speech_prob": 4.63787182525266e-06}, {"id": 701, "seek": 327252, "start": 3291.2599999999998, "end": 3297.8, "text": " And so basically each pixel, so let's say we're doing this pixel here right now, is", "tokens": [51301, 400, 370, 1936, 1184, 19261, 11, 370, 718, 311, 584, 321, 434, 884, 341, 19261, 510, 558, 586, 11, 307, 51628], "temperature": 0.0, "avg_logprob": -0.2072286605834961, "compression_ratio": 1.7914110429447854, "no_speech_prob": 4.63787182525266e-06}, {"id": 702, "seek": 329780, "start": 3297.8, "end": 3305.2400000000002, "text": " going to equal its original pixel plus, so it's called x, plus the weighted average.", "tokens": [50364, 516, 281, 2681, 1080, 3380, 19261, 1804, 11, 370, 309, 311, 1219, 2031, 11, 1804, 264, 32807, 4274, 13, 50736], "temperature": 0.0, "avg_logprob": -0.3511865899917927, "compression_ratio": 1.4, "no_speech_prob": 0.015906039625406265}, {"id": 703, "seek": 329780, "start": 3305.2400000000002, "end": 3321.44, "text": " So the sum across, so maybe this is like x i, plus the sum of all the other pixels.", "tokens": [50736, 407, 264, 2408, 2108, 11, 370, 1310, 341, 307, 411, 2031, 741, 11, 1804, 264, 2408, 295, 439, 264, 661, 18668, 13, 51546], "temperature": 0.0, "avg_logprob": -0.3511865899917927, "compression_ratio": 1.4, "no_speech_prob": 0.015906039625406265}, {"id": 704, "seek": 332144, "start": 3321.44, "end": 3342.36, "text": " So from 0 to the height times the width, some weight times each pixel.", "tokens": [50364, 407, 490, 1958, 281, 264, 6681, 1413, 264, 11402, 11, 512, 3364, 1413, 1184, 19261, 13, 51410], "temperature": 0.0, "avg_logprob": -0.321539763248328, "compression_ratio": 1.2359550561797752, "no_speech_prob": 0.003324074437841773}, {"id": 705, "seek": 332144, "start": 3342.36, "end": 3348.64, "text": " The weights, they're going to sum to 1.", "tokens": [51410, 440, 17443, 11, 436, 434, 516, 281, 2408, 281, 502, 13, 51724], "temperature": 0.0, "avg_logprob": -0.321539763248328, "compression_ratio": 1.2359550561797752, "no_speech_prob": 0.003324074437841773}, {"id": 706, "seek": 334864, "start": 3348.64, "end": 3355.8399999999997, "text": " And so that way the, you know, the pixel value scale isn't going to change.", "tokens": [50364, 400, 370, 300, 636, 264, 11, 291, 458, 11, 264, 19261, 2158, 4373, 1943, 380, 516, 281, 1319, 13, 50724], "temperature": 0.0, "avg_logprob": -0.27529546192714144, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.0018675235332921147}, {"id": 707, "seek": 334864, "start": 3355.8399999999997, "end": 3357.12, "text": " Well that's not actually quite true.", "tokens": [50724, 1042, 300, 311, 406, 767, 1596, 2074, 13, 50788], "temperature": 0.0, "avg_logprob": -0.27529546192714144, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.0018675235332921147}, {"id": 708, "seek": 334864, "start": 3357.12, "end": 3360.3199999999997, "text": " It's going to end up potentially twice as big, I guess, because it's being added to", "tokens": [50788, 467, 311, 516, 281, 917, 493, 7263, 6091, 382, 955, 11, 286, 2041, 11, 570, 309, 311, 885, 3869, 281, 50948], "temperature": 0.0, "avg_logprob": -0.27529546192714144, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.0018675235332921147}, {"id": 709, "seek": 334864, "start": 3360.3199999999997, "end": 3362.7999999999997, "text": " the original pixel.", "tokens": [50948, 264, 3380, 19261, 13, 51072], "temperature": 0.0, "avg_logprob": -0.27529546192714144, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.0018675235332921147}, {"id": 710, "seek": 334864, "start": 3362.7999999999997, "end": 3367.96, "text": " So attention itself is not with the x plus.", "tokens": [51072, 407, 3202, 2564, 307, 406, 365, 264, 2031, 1804, 13, 51330], "temperature": 0.0, "avg_logprob": -0.27529546192714144, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.0018675235332921147}, {"id": 711, "seek": 334864, "start": 3367.96, "end": 3372.44, "text": " But the way it's done in stable diffusion, at least, is that the attention is added to", "tokens": [51330, 583, 264, 636, 309, 311, 1096, 294, 8351, 25242, 11, 412, 1935, 11, 307, 300, 264, 3202, 307, 3869, 281, 51554], "temperature": 0.0, "avg_logprob": -0.27529546192714144, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.0018675235332921147}, {"id": 712, "seek": 334864, "start": 3372.44, "end": 3374.6, "text": " the original pixel.", "tokens": [51554, 264, 3380, 19261, 13, 51662], "temperature": 0.0, "avg_logprob": -0.27529546192714144, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.0018675235332921147}, {"id": 713, "seek": 334864, "start": 3374.6, "end": 3376.16, "text": " So yeah, now I think about it.", "tokens": [51662, 407, 1338, 11, 586, 286, 519, 466, 309, 13, 51740], "temperature": 0.0, "avg_logprob": -0.27529546192714144, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.0018675235332921147}, {"id": 714, "seek": 337616, "start": 3377.16, "end": 3380.56, "text": " I'm not going to think about how this is being scaled.", "tokens": [50414, 286, 478, 406, 516, 281, 519, 466, 577, 341, 307, 885, 36039, 13, 50584], "temperature": 0.0, "avg_logprob": -0.4384899139404297, "compression_ratio": 1.3884892086330936, "no_speech_prob": 5.47580020793248e-05}, {"id": 715, "seek": 337616, "start": 3380.56, "end": 3381.56, "text": " Anyhow.", "tokens": [50584, 2639, 4286, 13, 50634], "temperature": 0.0, "avg_logprob": -0.4384899139404297, "compression_ratio": 1.3884892086330936, "no_speech_prob": 5.47580020793248e-05}, {"id": 716, "seek": 337616, "start": 3381.56, "end": 3392.8399999999997, "text": " So the big question is what values to use for the weights.", "tokens": [50634, 407, 264, 955, 1168, 307, 437, 4190, 281, 764, 337, 264, 17443, 13, 51198], "temperature": 0.0, "avg_logprob": -0.4384899139404297, "compression_ratio": 1.3884892086330936, "no_speech_prob": 5.47580020793248e-05}, {"id": 717, "seek": 337616, "start": 3392.8399999999997, "end": 3401.68, "text": " And the way that we calculate those is we do a, we do a matrix product.", "tokens": [51198, 400, 264, 636, 300, 321, 8873, 729, 307, 321, 360, 257, 11, 321, 360, 257, 8141, 1674, 13, 51640], "temperature": 0.0, "avg_logprob": -0.4384899139404297, "compression_ratio": 1.3884892086330936, "no_speech_prob": 5.47580020793248e-05}, {"id": 718, "seek": 340168, "start": 3401.68, "end": 3418.3599999999997, "text": " And so our, for a particular pixel, we've got, you know, the number of channels for", "tokens": [50364, 400, 370, 527, 11, 337, 257, 1729, 19261, 11, 321, 600, 658, 11, 291, 458, 11, 264, 1230, 295, 9235, 337, 51198], "temperature": 0.0, "avg_logprob": -0.22975392495432206, "compression_ratio": 1.125, "no_speech_prob": 0.00020662833412643522}, {"id": 719, "seek": 340168, "start": 3418.3599999999997, "end": 3422.56, "text": " that one pixel.", "tokens": [51198, 300, 472, 19261, 13, 51408], "temperature": 0.0, "avg_logprob": -0.22975392495432206, "compression_ratio": 1.125, "no_speech_prob": 0.00020662833412643522}, {"id": 720, "seek": 342256, "start": 3422.56, "end": 3433.12, "text": " And what we do is we can compare that to all of the number of channels for all the other", "tokens": [50364, 400, 437, 321, 360, 307, 321, 393, 6794, 300, 281, 439, 295, 264, 1230, 295, 9235, 337, 439, 264, 661, 50892], "temperature": 0.0, "avg_logprob": -0.2757268998681045, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00048784830141812563}, {"id": 721, "seek": 342256, "start": 3433.12, "end": 3434.56, "text": " pixels.", "tokens": [50892, 18668, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2757268998681045, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00048784830141812563}, {"id": 722, "seek": 342256, "start": 3434.56, "end": 3439.92, "text": " So we've got kind of, this is pixel, let's say x1.", "tokens": [50964, 407, 321, 600, 658, 733, 295, 11, 341, 307, 19261, 11, 718, 311, 584, 2031, 16, 13, 51232], "temperature": 0.0, "avg_logprob": -0.2757268998681045, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00048784830141812563}, {"id": 723, "seek": 342256, "start": 3439.92, "end": 3443.08, "text": " And then we've got pixel number x2.", "tokens": [51232, 400, 550, 321, 600, 658, 19261, 1230, 2031, 17, 13, 51390], "temperature": 0.0, "avg_logprob": -0.2757268998681045, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00048784830141812563}, {"id": 724, "seek": 342256, "start": 3443.08, "end": 3445.6, "text": " Right.", "tokens": [51390, 1779, 13, 51516], "temperature": 0.0, "avg_logprob": -0.2757268998681045, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00048784830141812563}, {"id": 725, "seek": 342256, "start": 3445.6, "end": 3446.7599999999998, "text": " All those channels.", "tokens": [51516, 1057, 729, 9235, 13, 51574], "temperature": 0.0, "avg_logprob": -0.2757268998681045, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00048784830141812563}, {"id": 726, "seek": 342256, "start": 3446.7599999999998, "end": 3452.36, "text": " We can take the dot product between those two things.", "tokens": [51574, 492, 393, 747, 264, 5893, 1674, 1296, 729, 732, 721, 13, 51854], "temperature": 0.0, "avg_logprob": -0.2757268998681045, "compression_ratio": 1.5260115606936415, "no_speech_prob": 0.00048784830141812563}, {"id": 727, "seek": 345236, "start": 3453.1600000000003, "end": 3458.52, "text": " And that will tell us how similar they are.", "tokens": [50404, 400, 300, 486, 980, 505, 577, 2531, 436, 366, 13, 50672], "temperature": 0.0, "avg_logprob": -0.2463289499282837, "compression_ratio": 1.5931372549019607, "no_speech_prob": 2.0145685994066298e-05}, {"id": 728, "seek": 345236, "start": 3458.52, "end": 3462.48, "text": " And so one way of doing this would be to say like, okay, well, let's take that dot product", "tokens": [50672, 400, 370, 472, 636, 295, 884, 341, 576, 312, 281, 584, 411, 11, 1392, 11, 731, 11, 718, 311, 747, 300, 5893, 1674, 50870], "temperature": 0.0, "avg_logprob": -0.2463289499282837, "compression_ratio": 1.5931372549019607, "no_speech_prob": 2.0145685994066298e-05}, {"id": 729, "seek": 345236, "start": 3462.48, "end": 3464.96, "text": " for every pair of pixels.", "tokens": [50870, 337, 633, 6119, 295, 18668, 13, 50994], "temperature": 0.0, "avg_logprob": -0.2463289499282837, "compression_ratio": 1.5931372549019607, "no_speech_prob": 2.0145685994066298e-05}, {"id": 730, "seek": 345236, "start": 3464.96, "end": 3468.48, "text": " And that's very easy dot product to do.", "tokens": [50994, 400, 300, 311, 588, 1858, 5893, 1674, 281, 360, 13, 51170], "temperature": 0.0, "avg_logprob": -0.2463289499282837, "compression_ratio": 1.5931372549019607, "no_speech_prob": 2.0145685994066298e-05}, {"id": 731, "seek": 345236, "start": 3468.48, "end": 3471.28, "text": " Because that's just what the matrix product is equal to.", "tokens": [51170, 1436, 300, 311, 445, 437, 264, 8141, 1674, 307, 2681, 281, 13, 51310], "temperature": 0.0, "avg_logprob": -0.2463289499282837, "compression_ratio": 1.5931372549019607, "no_speech_prob": 2.0145685994066298e-05}, {"id": 732, "seek": 345236, "start": 3471.28, "end": 3477.84, "text": " So if we've got h by w by c.", "tokens": [51310, 407, 498, 321, 600, 658, 276, 538, 261, 538, 269, 13, 51638], "temperature": 0.0, "avg_logprob": -0.2463289499282837, "compression_ratio": 1.5931372549019607, "no_speech_prob": 2.0145685994066298e-05}, {"id": 733, "seek": 345236, "start": 3477.84, "end": 3481.28, "text": " And then multiply it by its transpose.", "tokens": [51638, 400, 550, 12972, 309, 538, 1080, 25167, 13, 51810], "temperature": 0.0, "avg_logprob": -0.2463289499282837, "compression_ratio": 1.5931372549019607, "no_speech_prob": 2.0145685994066298e-05}, {"id": 734, "seek": 348128, "start": 3481.28, "end": 3487.2000000000003, "text": " H by w by, sorry.", "tokens": [50364, 389, 538, 261, 538, 11, 2597, 13, 50660], "temperature": 0.0, "avg_logprob": -0.5608459711074829, "compression_ratio": 1.2142857142857142, "no_speech_prob": 0.010985271073877811}, {"id": 735, "seek": 348128, "start": 3487.2000000000003, "end": 3499.32, "text": " I said transpose and then totally failed to do transpose.", "tokens": [50660, 286, 848, 25167, 293, 550, 3879, 7612, 281, 360, 25167, 13, 51266], "temperature": 0.0, "avg_logprob": -0.5608459711074829, "compression_ratio": 1.2142857142857142, "no_speech_prob": 0.010985271073877811}, {"id": 736, "seek": 348128, "start": 3499.32, "end": 3504.96, "text": " Multiply by its transpose.", "tokens": [51266, 31150, 356, 538, 1080, 25167, 13, 51548], "temperature": 0.0, "avg_logprob": -0.5608459711074829, "compression_ratio": 1.2142857142857142, "no_speech_prob": 0.010985271073877811}, {"id": 737, "seek": 350496, "start": 3504.96, "end": 3511.44, "text": " And that will give us an h by w by h by w matrix.", "tokens": [50364, 400, 300, 486, 976, 505, 364, 276, 538, 261, 538, 276, 538, 261, 8141, 13, 50688], "temperature": 0.0, "avg_logprob": -0.24719236208044965, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.0016743410378694534}, {"id": 738, "seek": 350496, "start": 3511.44, "end": 3514.08, "text": " So each pixel, all the pixels are down here.", "tokens": [50688, 407, 1184, 19261, 11, 439, 264, 18668, 366, 760, 510, 13, 50820], "temperature": 0.0, "avg_logprob": -0.24719236208044965, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.0016743410378694534}, {"id": 739, "seek": 350496, "start": 3514.08, "end": 3521.7200000000003, "text": " And for each pixel, as long as these add up to one, then we've got a weight for each pixel.", "tokens": [50820, 400, 337, 1184, 19261, 11, 382, 938, 382, 613, 909, 493, 281, 472, 11, 550, 321, 600, 658, 257, 3364, 337, 1184, 19261, 13, 51202], "temperature": 0.0, "avg_logprob": -0.24719236208044965, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.0016743410378694534}, {"id": 740, "seek": 350496, "start": 3521.7200000000003, "end": 3523.52, "text": " And it's easy to make these add up to one.", "tokens": [51202, 400, 309, 311, 1858, 281, 652, 613, 909, 493, 281, 472, 13, 51292], "temperature": 0.0, "avg_logprob": -0.24719236208044965, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.0016743410378694534}, {"id": 741, "seek": 350496, "start": 3523.52, "end": 3534.36, "text": " We could just take this matrix multiplication and take the sigmoid over the last dimension.", "tokens": [51292, 492, 727, 445, 747, 341, 8141, 27290, 293, 747, 264, 4556, 3280, 327, 670, 264, 1036, 10139, 13, 51834], "temperature": 0.0, "avg_logprob": -0.24719236208044965, "compression_ratio": 1.6894736842105262, "no_speech_prob": 0.0016743410378694534}, {"id": 742, "seek": 353436, "start": 3534.76, "end": 3535.76, "text": " Sorry, not sigmoid.", "tokens": [50384, 4919, 11, 406, 4556, 3280, 327, 13, 50434], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 743, "seek": 353436, "start": 3535.76, "end": 3538.76, "text": " Man, what's wrong with me?", "tokens": [50434, 2458, 11, 437, 311, 2085, 365, 385, 30, 50584], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 744, "seek": 353436, "start": 3538.76, "end": 3539.76, "text": " Softmax, right?", "tokens": [50584, 16985, 41167, 11, 558, 30, 50634], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 745, "seek": 353436, "start": 3539.76, "end": 3540.76, "text": " Yeah.", "tokens": [50634, 865, 13, 50684], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 746, "seek": 353436, "start": 3540.76, "end": 3547.76, "text": " And take the softmax over the last dimension.", "tokens": [50684, 400, 747, 264, 2787, 41167, 670, 264, 1036, 10139, 13, 51034], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 747, "seek": 353436, "start": 3547.76, "end": 3553.36, "text": " And that will give me something that adds the sum equals one.", "tokens": [51034, 400, 300, 486, 976, 385, 746, 300, 10860, 264, 2408, 6915, 472, 13, 51314], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 748, "seek": 353436, "start": 3553.36, "end": 3555.08, "text": " Okay.", "tokens": [51314, 1033, 13, 51400], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 749, "seek": 353436, "start": 3555.08, "end": 3562.04, "text": " Now the thing is, it's not just that we want to find the places where they look the same,", "tokens": [51400, 823, 264, 551, 307, 11, 309, 311, 406, 445, 300, 321, 528, 281, 915, 264, 3190, 689, 436, 574, 264, 912, 11, 51748], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 750, "seek": 353436, "start": 3562.04, "end": 3563.88, "text": " where the channels are basically the same.", "tokens": [51748, 689, 264, 9235, 366, 1936, 264, 912, 13, 51840], "temperature": 0.0, "avg_logprob": -0.36093202571278993, "compression_ratio": 1.5441176470588236, "no_speech_prob": 0.001016229740343988}, {"id": 751, "seek": 356388, "start": 3564.4, "end": 3570.36, "text": " But we want to find the places where they're like similar in some particular way, you know.", "tokens": [50390, 583, 321, 528, 281, 915, 264, 3190, 689, 436, 434, 411, 2531, 294, 512, 1729, 636, 11, 291, 458, 13, 50688], "temperature": 0.0, "avg_logprob": -0.2254460361025749, "compression_ratio": 1.8873239436619718, "no_speech_prob": 2.9772869311273098e-05}, {"id": 752, "seek": 356388, "start": 3570.36, "end": 3576.0, "text": " And so some particular set of channels are similar in one to some different set of channels", "tokens": [50688, 400, 370, 512, 1729, 992, 295, 9235, 366, 2531, 294, 472, 281, 512, 819, 992, 295, 9235, 50970], "temperature": 0.0, "avg_logprob": -0.2254460361025749, "compression_ratio": 1.8873239436619718, "no_speech_prob": 2.9772869311273098e-05}, {"id": 753, "seek": 356388, "start": 3576.0, "end": 3577.44, "text": " in another.", "tokens": [50970, 294, 1071, 13, 51042], "temperature": 0.0, "avg_logprob": -0.2254460361025749, "compression_ratio": 1.8873239436619718, "no_speech_prob": 2.9772869311273098e-05}, {"id": 754, "seek": 356388, "start": 3577.44, "end": 3583.08, "text": " And so, you know, in this case, we may be looking for the pointy-erredness activations,", "tokens": [51042, 400, 370, 11, 291, 458, 11, 294, 341, 1389, 11, 321, 815, 312, 1237, 337, 264, 935, 88, 12, 260, 986, 1287, 2430, 763, 11, 51324], "temperature": 0.0, "avg_logprob": -0.2254460361025749, "compression_ratio": 1.8873239436619718, "no_speech_prob": 2.9772869311273098e-05}, {"id": 755, "seek": 356388, "start": 3583.08, "end": 3589.4, "text": " you know, which actually are represented by, you know, this, this, and this, you know.", "tokens": [51324, 291, 458, 11, 597, 767, 366, 10379, 538, 11, 291, 458, 11, 341, 11, 341, 11, 293, 341, 11, 291, 458, 13, 51640], "temperature": 0.0, "avg_logprob": -0.2254460361025749, "compression_ratio": 1.8873239436619718, "no_speech_prob": 2.9772869311273098e-05}, {"id": 756, "seek": 356388, "start": 3589.4, "end": 3591.44, "text": " And we want to just find those.", "tokens": [51640, 400, 321, 528, 281, 445, 915, 729, 13, 51742], "temperature": 0.0, "avg_logprob": -0.2254460361025749, "compression_ratio": 1.8873239436619718, "no_speech_prob": 2.9772869311273098e-05}, {"id": 757, "seek": 359144, "start": 3591.44, "end": 3602.4, "text": " So the way we do that is before we do this matrix product, we first put our matrix through", "tokens": [50364, 407, 264, 636, 321, 360, 300, 307, 949, 321, 360, 341, 8141, 1674, 11, 321, 700, 829, 527, 8141, 807, 50912], "temperature": 0.0, "avg_logprob": -0.23913495200020926, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.0003920186427421868}, {"id": 758, "seek": 359144, "start": 3602.4, "end": 3606.08, "text": " a projection.", "tokens": [50912, 257, 22743, 13, 51096], "temperature": 0.0, "avg_logprob": -0.23913495200020926, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.0003920186427421868}, {"id": 759, "seek": 359144, "start": 3606.08, "end": 3612.04, "text": " So we just basically put our matrix through a matrix multiplication.", "tokens": [51096, 407, 321, 445, 1936, 829, 527, 8141, 807, 257, 8141, 27290, 13, 51394], "temperature": 0.0, "avg_logprob": -0.23913495200020926, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.0003920186427421868}, {"id": 760, "seek": 359144, "start": 3612.04, "end": 3613.04, "text": " This one.", "tokens": [51394, 639, 472, 13, 51444], "temperature": 0.0, "avg_logprob": -0.23913495200020926, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.0003920186427421868}, {"id": 761, "seek": 359144, "start": 3613.04, "end": 3614.12, "text": " So it's the same matrix, right?", "tokens": [51444, 407, 309, 311, 264, 912, 8141, 11, 558, 30, 51498], "temperature": 0.0, "avg_logprob": -0.23913495200020926, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.0003920186427421868}, {"id": 762, "seek": 359144, "start": 3614.12, "end": 3617.0, "text": " But we put it through two different projections.", "tokens": [51498, 583, 321, 829, 309, 807, 732, 819, 32371, 13, 51642], "temperature": 0.0, "avg_logprob": -0.23913495200020926, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.0003920186427421868}, {"id": 763, "seek": 361700, "start": 3617.0, "end": 3622.16, "text": " And so that lets it pick two different kind of sets of channels to focus on or not focus", "tokens": [50364, 400, 370, 300, 6653, 309, 1888, 732, 819, 733, 295, 6352, 295, 9235, 281, 1879, 322, 420, 406, 1879, 50622], "temperature": 0.0, "avg_logprob": -0.28571314232371675, "compression_ratio": 1.7782426778242677, "no_speech_prob": 0.00048029073514044285}, {"id": 764, "seek": 361700, "start": 3622.16, "end": 3627.08, "text": " on before it decides, you know, oh, this pixel is similar to this pixel in the way we care", "tokens": [50622, 322, 949, 309, 14898, 11, 291, 458, 11, 1954, 11, 341, 19261, 307, 2531, 281, 341, 19261, 294, 264, 636, 321, 1127, 50868], "temperature": 0.0, "avg_logprob": -0.28571314232371675, "compression_ratio": 1.7782426778242677, "no_speech_prob": 0.00048029073514044285}, {"id": 765, "seek": 361700, "start": 3627.08, "end": 3628.44, "text": " about.", "tokens": [50868, 466, 13, 50936], "temperature": 0.0, "avg_logprob": -0.28571314232371675, "compression_ratio": 1.7782426778242677, "no_speech_prob": 0.00048029073514044285}, {"id": 766, "seek": 361700, "start": 3628.44, "end": 3632.16, "text": " And then actually, we don't even just multiply it then by the original pixels.", "tokens": [50936, 400, 550, 767, 11, 321, 500, 380, 754, 445, 12972, 309, 550, 538, 264, 3380, 18668, 13, 51122], "temperature": 0.0, "avg_logprob": -0.28571314232371675, "compression_ratio": 1.7782426778242677, "no_speech_prob": 0.00048029073514044285}, {"id": 767, "seek": 361700, "start": 3632.16, "end": 3636.8, "text": " We also put that through a different projection as well.", "tokens": [51122, 492, 611, 829, 300, 807, 257, 819, 22743, 382, 731, 13, 51354], "temperature": 0.0, "avg_logprob": -0.28571314232371675, "compression_ratio": 1.7782426778242677, "no_speech_prob": 0.00048029073514044285}, {"id": 768, "seek": 361700, "start": 3636.8, "end": 3638.4, "text": " So there's these different projections.", "tokens": [51354, 407, 456, 311, 613, 819, 32371, 13, 51434], "temperature": 0.0, "avg_logprob": -0.28571314232371675, "compression_ratio": 1.7782426778242677, "no_speech_prob": 0.00048029073514044285}, {"id": 769, "seek": 361700, "start": 3638.4, "end": 3643.08, "text": " We'll do projection one, projection two, and projection three.", "tokens": [51434, 492, 603, 360, 22743, 472, 11, 22743, 732, 11, 293, 22743, 1045, 13, 51668], "temperature": 0.0, "avg_logprob": -0.28571314232371675, "compression_ratio": 1.7782426778242677, "no_speech_prob": 0.00048029073514044285}, {"id": 770, "seek": 364308, "start": 3643.08, "end": 3647.08, "text": " And that gives it the ability to say, like, oh, I want to compare these channels and,", "tokens": [50364, 400, 300, 2709, 309, 264, 3485, 281, 584, 11, 411, 11, 1954, 11, 286, 528, 281, 6794, 613, 9235, 293, 11, 50564], "temperature": 0.0, "avg_logprob": -0.24862476271025988, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.00021318662038538605}, {"id": 771, "seek": 364308, "start": 3647.08, "end": 3650.92, "text": " you know, these channels to these channels to find similarity.", "tokens": [50564, 291, 458, 11, 613, 9235, 281, 613, 9235, 281, 915, 32194, 13, 50756], "temperature": 0.0, "avg_logprob": -0.24862476271025988, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.00021318662038538605}, {"id": 772, "seek": 364308, "start": 3650.92, "end": 3655.2799999999997, "text": " And based on similarity, I then want to pick out these channels, right?", "tokens": [50756, 400, 2361, 322, 32194, 11, 286, 550, 528, 281, 1888, 484, 613, 9235, 11, 558, 30, 50974], "temperature": 0.0, "avg_logprob": -0.24862476271025988, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.00021318662038538605}, {"id": 773, "seek": 364308, "start": 3655.2799999999997, "end": 3656.7599999999998, "text": " Both positive and negative weight.", "tokens": [50974, 6767, 3353, 293, 3671, 3364, 13, 51048], "temperature": 0.0, "avg_logprob": -0.24862476271025988, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.00021318662038538605}, {"id": 774, "seek": 364308, "start": 3656.7599999999998, "end": 3661.16, "text": " So that's why there's these three different projections.", "tokens": [51048, 407, 300, 311, 983, 456, 311, 613, 1045, 819, 32371, 13, 51268], "temperature": 0.0, "avg_logprob": -0.24862476271025988, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.00021318662038538605}, {"id": 775, "seek": 364308, "start": 3661.16, "end": 3670.56, "text": " And so the projections are called A, Q, and V. Those are the projections.", "tokens": [51268, 400, 370, 264, 32371, 366, 1219, 316, 11, 1249, 11, 293, 691, 13, 3950, 366, 264, 32371, 13, 51738], "temperature": 0.0, "avg_logprob": -0.24862476271025988, "compression_ratio": 1.7788018433179724, "no_speech_prob": 0.00021318662038538605}, {"id": 776, "seek": 367056, "start": 3670.56, "end": 3675.84, "text": " And so they're all being passed the same matrix.", "tokens": [50364, 400, 370, 436, 434, 439, 885, 4678, 264, 912, 8141, 13, 50628], "temperature": 0.0, "avg_logprob": -0.3650131006350463, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.022284580394625664}, {"id": 777, "seek": 367056, "start": 3675.84, "end": 3680.24, "text": " And because they're all being passed the same matrix, we call this self-attention.", "tokens": [50628, 400, 570, 436, 434, 439, 885, 4678, 264, 912, 8141, 11, 321, 818, 341, 2698, 12, 1591, 1251, 13, 50848], "temperature": 0.0, "avg_logprob": -0.3650131006350463, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.022284580394625664}, {"id": 778, "seek": 367056, "start": 3680.24, "end": 3688.08, "text": " Okay, Jono, Tindeshk, I know this is, I know you guys know this very well, but you also", "tokens": [50848, 1033, 11, 7745, 78, 11, 314, 471, 14935, 74, 11, 286, 458, 341, 307, 11, 286, 458, 291, 1074, 458, 341, 588, 731, 11, 457, 291, 611, 51240], "temperature": 0.0, "avg_logprob": -0.3650131006350463, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.022284580394625664}, {"id": 779, "seek": 367056, "start": 3688.08, "end": 3689.08, "text": " know it's really confusing.", "tokens": [51240, 458, 309, 311, 534, 13181, 13, 51290], "temperature": 0.0, "avg_logprob": -0.3650131006350463, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.022284580394625664}, {"id": 780, "seek": 367056, "start": 3689.08, "end": 3695.12, "text": " Did you have anything to add, change, anything else?", "tokens": [51290, 2589, 291, 362, 1340, 281, 909, 11, 1319, 11, 1340, 1646, 30, 51592], "temperature": 0.0, "avg_logprob": -0.3650131006350463, "compression_ratio": 1.6483516483516483, "no_speech_prob": 0.022284580394625664}, {"id": 781, "seek": 369512, "start": 3695.68, "end": 3702.64, "text": " Yeah, I like that you introduced this without resorting to the, let's think of this as queries", "tokens": [50392, 865, 11, 286, 411, 300, 291, 7268, 341, 1553, 19606, 278, 281, 264, 11, 718, 311, 519, 295, 341, 382, 24109, 50740], "temperature": 0.0, "avg_logprob": -0.31533648989616186, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.004982010927051306}, {"id": 782, "seek": 369512, "start": 3702.64, "end": 3706.88, "text": " at all, which I think is, yeah, as we've noted, maybe more confusing than helpful.", "tokens": [50740, 412, 439, 11, 597, 286, 519, 307, 11, 1338, 11, 382, 321, 600, 12964, 11, 1310, 544, 13181, 813, 4961, 13, 50952], "temperature": 0.0, "avg_logprob": -0.31533648989616186, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.004982010927051306}, {"id": 783, "seek": 369512, "start": 3706.88, "end": 3713.8399999999997, "text": " These actually, yeah, these are actually short for key, query, and value, even though I personally", "tokens": [50952, 1981, 767, 11, 1338, 11, 613, 366, 767, 2099, 337, 2141, 11, 14581, 11, 293, 2158, 11, 754, 1673, 286, 5665, 51300], "temperature": 0.0, "avg_logprob": -0.31533648989616186, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.004982010927051306}, {"id": 784, "seek": 369512, "start": 3713.8399999999997, "end": 3716.4, "text": " don't find those useful concepts.", "tokens": [51300, 500, 380, 915, 729, 4420, 10392, 13, 51428], "temperature": 0.0, "avg_logprob": -0.31533648989616186, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.004982010927051306}, {"id": 785, "seek": 369512, "start": 3716.4, "end": 3717.4, "text": " Yeah.", "tokens": [51428, 865, 13, 51478], "temperature": 0.0, "avg_logprob": -0.31533648989616186, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.004982010927051306}, {"id": 786, "seek": 369512, "start": 3717.4, "end": 3723.6, "text": " Your note on the scaling, you said, oh, so we set it so that the weights sum to one.", "tokens": [51478, 2260, 3637, 322, 264, 21589, 11, 291, 848, 11, 1954, 11, 370, 321, 992, 309, 370, 300, 264, 17443, 2408, 281, 472, 13, 51788], "temperature": 0.0, "avg_logprob": -0.31533648989616186, "compression_ratio": 1.6234817813765183, "no_speech_prob": 0.004982010927051306}, {"id": 787, "seek": 372360, "start": 3723.6, "end": 3727.68, "text": " And so then we'd need to worry about, are we doubling the scale of X?", "tokens": [50364, 400, 370, 550, 321, 1116, 643, 281, 3292, 466, 11, 366, 321, 33651, 264, 4373, 295, 1783, 30, 50568], "temperature": 0.0, "avg_logprob": -0.3108880001565684, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.24194306135177612}, {"id": 788, "seek": 372360, "start": 3727.68, "end": 3739.0, "text": " But because of that P3, aka V, that projection, that can learn to scale this thing that's", "tokens": [50568, 583, 570, 295, 300, 430, 18, 11, 28042, 691, 11, 300, 22743, 11, 300, 393, 1466, 281, 4373, 341, 551, 300, 311, 51134], "temperature": 0.0, "avg_logprob": -0.3108880001565684, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.24194306135177612}, {"id": 789, "seek": 372360, "start": 3739.0, "end": 3740.0, "text": " added to X appropriately.", "tokens": [51134, 3869, 281, 1783, 23505, 13, 51184], "temperature": 0.0, "avg_logprob": -0.3108880001565684, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.24194306135177612}, {"id": 790, "seek": 372360, "start": 3740.0, "end": 3744.44, "text": " And so it's not just doubling the size of X, it's increasing it a little bit, which", "tokens": [51184, 400, 370, 309, 311, 406, 445, 33651, 264, 2744, 295, 1783, 11, 309, 311, 5662, 309, 257, 707, 857, 11, 597, 51406], "temperature": 0.0, "avg_logprob": -0.3108880001565684, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.24194306135177612}, {"id": 791, "seek": 372360, "start": 3744.44, "end": 3750.44, "text": " is why we scatter normalization in between all of these attention areas.", "tokens": [51406, 307, 983, 321, 34951, 2710, 2144, 294, 1296, 439, 295, 613, 3202, 3179, 13, 51706], "temperature": 0.0, "avg_logprob": -0.3108880001565684, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.24194306135177612}, {"id": 792, "seek": 375044, "start": 3750.44, "end": 3755.48, "text": " But it's not as bad as it might be because we have that V projection.", "tokens": [50364, 583, 309, 311, 406, 382, 1578, 382, 309, 1062, 312, 570, 321, 362, 300, 691, 22743, 13, 50616], "temperature": 0.0, "avg_logprob": -0.3854898429778685, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.12420234829187393}, {"id": 793, "seek": 375044, "start": 3755.48, "end": 3761.2400000000002, "text": " Yeah, that's a good point.", "tokens": [50616, 865, 11, 300, 311, 257, 665, 935, 13, 50904], "temperature": 0.0, "avg_logprob": -0.3854898429778685, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.12420234829187393}, {"id": 794, "seek": 375044, "start": 3761.2400000000002, "end": 3770.2000000000003, "text": " And if this is P3, or it's actually the V projection, is initialized such that it would", "tokens": [50904, 400, 498, 341, 307, 430, 18, 11, 420, 309, 311, 767, 264, 691, 22743, 11, 307, 5883, 1602, 1270, 300, 309, 576, 51352], "temperature": 0.0, "avg_logprob": -0.3854898429778685, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.12420234829187393}, {"id": 795, "seek": 375044, "start": 3770.2000000000003, "end": 3775.36, "text": " have a mean of zero, then on average, you know, it should start out by not messing with", "tokens": [51352, 362, 257, 914, 295, 4018, 11, 550, 322, 4274, 11, 291, 458, 11, 309, 820, 722, 484, 538, 406, 23258, 365, 51610], "temperature": 0.0, "avg_logprob": -0.3854898429778685, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.12420234829187393}, {"id": 796, "seek": 375044, "start": 3775.36, "end": 3776.36, "text": " our scale.", "tokens": [51610, 527, 4373, 13, 51660], "temperature": 0.0, "avg_logprob": -0.3854898429778685, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.12420234829187393}, {"id": 797, "seek": 377636, "start": 3777.36, "end": 3784.7200000000003, "text": " Okay, so yeah, I guess I find it easier to think in terms of code.", "tokens": [50414, 1033, 11, 370, 1338, 11, 286, 2041, 286, 915, 309, 3571, 281, 519, 294, 2115, 295, 3089, 13, 50782], "temperature": 0.0, "avg_logprob": -0.38769518362509237, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0007436966407112777}, {"id": 798, "seek": 377636, "start": 3784.7200000000003, "end": 3785.7200000000003, "text": " So let's look at the code.", "tokens": [50782, 407, 718, 311, 574, 412, 264, 3089, 13, 50832], "temperature": 0.0, "avg_logprob": -0.38769518362509237, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0007436966407112777}, {"id": 799, "seek": 377636, "start": 3785.7200000000003, "end": 3787.96, "text": " You know, there's actually not much code.", "tokens": [50832, 509, 458, 11, 456, 311, 767, 406, 709, 3089, 13, 50944], "temperature": 0.0, "avg_logprob": -0.38769518362509237, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0007436966407112777}, {"id": 800, "seek": 377636, "start": 3787.96, "end": 3793.96, "text": " I think you've got a bit of background noise too, John, maybe.", "tokens": [50944, 286, 519, 291, 600, 658, 257, 857, 295, 3678, 5658, 886, 11, 2619, 11, 1310, 13, 51244], "temperature": 0.0, "avg_logprob": -0.38769518362509237, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0007436966407112777}, {"id": 801, "seek": 377636, "start": 3793.96, "end": 3799.6800000000003, "text": " Yes, that's much better, thank you.", "tokens": [51244, 1079, 11, 300, 311, 709, 1101, 11, 1309, 291, 13, 51530], "temperature": 0.0, "avg_logprob": -0.38769518362509237, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.0007436966407112777}, {"id": 802, "seek": 379968, "start": 3799.68, "end": 3806.3999999999996, "text": " So in terms of code, there's, you know, this is one of these things, getting everything", "tokens": [50364, 407, 294, 2115, 295, 3089, 11, 456, 311, 11, 291, 458, 11, 341, 307, 472, 295, 613, 721, 11, 1242, 1203, 50700], "temperature": 0.0, "avg_logprob": -0.24053883759871772, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002672860398888588}, {"id": 803, "seek": 379968, "start": 3806.3999999999996, "end": 3807.3999999999996, "text": " exactly right.", "tokens": [50700, 2293, 558, 13, 50750], "temperature": 0.0, "avg_logprob": -0.24053883759871772, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002672860398888588}, {"id": 804, "seek": 379968, "start": 3807.3999999999996, "end": 3811.2799999999997, "text": " And it's not just right, I wanted to get it identical to the stable diffusion.", "tokens": [50750, 400, 309, 311, 406, 445, 558, 11, 286, 1415, 281, 483, 309, 14800, 281, 264, 8351, 25242, 13, 50944], "temperature": 0.0, "avg_logprob": -0.24053883759871772, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002672860398888588}, {"id": 805, "seek": 379968, "start": 3811.2799999999997, "end": 3814.9199999999996, "text": " So we can say we've made it identical to stable diffusion.", "tokens": [50944, 407, 321, 393, 584, 321, 600, 1027, 309, 14800, 281, 8351, 25242, 13, 51126], "temperature": 0.0, "avg_logprob": -0.24053883759871772, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002672860398888588}, {"id": 806, "seek": 379968, "start": 3814.9199999999996, "end": 3819.56, "text": " I've actually imported the attention block from diffusers so we can compare.", "tokens": [51126, 286, 600, 767, 25524, 264, 3202, 3461, 490, 7593, 301, 433, 370, 321, 393, 6794, 13, 51358], "temperature": 0.0, "avg_logprob": -0.24053883759871772, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002672860398888588}, {"id": 807, "seek": 379968, "start": 3819.56, "end": 3823.0, "text": " And it is so nice when you've got an existing version of something to compare to, to make", "tokens": [51358, 400, 309, 307, 370, 1481, 562, 291, 600, 658, 364, 6741, 3037, 295, 746, 281, 6794, 281, 11, 281, 652, 51530], "temperature": 0.0, "avg_logprob": -0.24053883759871772, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002672860398888588}, {"id": 808, "seek": 379968, "start": 3823.0, "end": 3828.2799999999997, "text": " sure you're getting the same results.", "tokens": [51530, 988, 291, 434, 1242, 264, 912, 3542, 13, 51794], "temperature": 0.0, "avg_logprob": -0.24053883759871772, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.002672860398888588}, {"id": 809, "seek": 382828, "start": 3828.28, "end": 3834.6000000000004, "text": " So we're going to start off by saying, let's say we've got a 16 by 16 pixel image, and", "tokens": [50364, 407, 321, 434, 516, 281, 722, 766, 538, 1566, 11, 718, 311, 584, 321, 600, 658, 257, 3165, 538, 3165, 19261, 3256, 11, 293, 50680], "temperature": 0.0, "avg_logprob": -0.33801000945422116, "compression_ratio": 1.5299145299145298, "no_speech_prob": 0.0008040645625442266}, {"id": 810, "seek": 382828, "start": 3834.6000000000004, "end": 3836.4, "text": " this is some deeper level of activation.", "tokens": [50680, 341, 307, 512, 7731, 1496, 295, 24433, 13, 50770], "temperature": 0.0, "avg_logprob": -0.33801000945422116, "compression_ratio": 1.5299145299145298, "no_speech_prob": 0.0008040645625442266}, {"id": 811, "seek": 382828, "start": 3836.4, "end": 3839.92, "text": " So it's got 32 channels with a batch size of 64.", "tokens": [50770, 407, 309, 311, 658, 8858, 9235, 365, 257, 15245, 2744, 295, 12145, 13, 50946], "temperature": 0.0, "avg_logprob": -0.33801000945422116, "compression_ratio": 1.5299145299145298, "no_speech_prob": 0.0008040645625442266}, {"id": 812, "seek": 382828, "start": 3839.92, "end": 3846.78, "text": " So nchw, I'm just going to use random numbers for now, but this has the, you know, reasonable", "tokens": [50946, 407, 297, 339, 86, 11, 286, 478, 445, 516, 281, 764, 4974, 3547, 337, 586, 11, 457, 341, 575, 264, 11, 291, 458, 11, 10585, 51289], "temperature": 0.0, "avg_logprob": -0.33801000945422116, "compression_ratio": 1.5299145299145298, "no_speech_prob": 0.0008040645625442266}, {"id": 813, "seek": 382828, "start": 3846.78, "end": 3853.48, "text": " dimensions for an activation inside a batch size 64 CNN or diffusion model or whatever.", "tokens": [51289, 12819, 337, 364, 24433, 1854, 257, 15245, 2744, 12145, 24859, 420, 25242, 2316, 420, 2035, 13, 51624], "temperature": 0.0, "avg_logprob": -0.33801000945422116, "compression_ratio": 1.5299145299145298, "no_speech_prob": 0.0008040645625442266}, {"id": 814, "seek": 385348, "start": 3853.68, "end": 3860.4, "text": " Okay, so the first thing we have to do is to flatten these out.", "tokens": [50374, 1033, 11, 370, 264, 700, 551, 321, 362, 281, 360, 307, 281, 24183, 613, 484, 13, 50710], "temperature": 0.0, "avg_logprob": -0.2746286590894063, "compression_ratio": 1.6067961165048543, "no_speech_prob": 0.00016603773110546172}, {"id": 815, "seek": 385348, "start": 3860.4, "end": 3865.64, "text": " Because as I said, in 1D attention, this is just ignored.", "tokens": [50710, 1436, 382, 286, 848, 11, 294, 502, 35, 3202, 11, 341, 307, 445, 19735, 13, 50972], "temperature": 0.0, "avg_logprob": -0.2746286590894063, "compression_ratio": 1.6067961165048543, "no_speech_prob": 0.00016603773110546172}, {"id": 816, "seek": 385348, "start": 3865.64, "end": 3867.54, "text": " So it's easy to flatten things out.", "tokens": [50972, 407, 309, 311, 1858, 281, 24183, 721, 484, 13, 51067], "temperature": 0.0, "avg_logprob": -0.2746286590894063, "compression_ratio": 1.6067961165048543, "no_speech_prob": 0.00016603773110546172}, {"id": 817, "seek": 385348, "start": 3867.54, "end": 3874.2400000000002, "text": " You just say .view, and you pass in the dimensions of the, in this case, the three dimensions", "tokens": [51067, 509, 445, 584, 2411, 1759, 11, 293, 291, 1320, 294, 264, 12819, 295, 264, 11, 294, 341, 1389, 11, 264, 1045, 12819, 51402], "temperature": 0.0, "avg_logprob": -0.2746286590894063, "compression_ratio": 1.6067961165048543, "no_speech_prob": 0.00016603773110546172}, {"id": 818, "seek": 385348, "start": 3874.2400000000002, "end": 3877.64, "text": " we want, which is 64, 32, and everything else.", "tokens": [51402, 321, 528, 11, 597, 307, 12145, 11, 8858, 11, 293, 1203, 1646, 13, 51572], "temperature": 0.0, "avg_logprob": -0.2746286590894063, "compression_ratio": 1.6067961165048543, "no_speech_prob": 0.00016603773110546172}, {"id": 819, "seek": 385348, "start": 3877.64, "end": 3879.46, "text": " Minus one means everything else.", "tokens": [51572, 2829, 301, 472, 1355, 1203, 1646, 13, 51663], "temperature": 0.0, "avg_logprob": -0.2746286590894063, "compression_ratio": 1.6067961165048543, "no_speech_prob": 0.00016603773110546172}, {"id": 820, "seek": 387946, "start": 3879.46, "end": 3883.66, "text": " So x.shape colon 2, in this case, is, you know, obviously it'd be easier just to type", "tokens": [50364, 407, 2031, 13, 82, 42406, 8255, 568, 11, 294, 341, 1389, 11, 307, 11, 291, 458, 11, 2745, 309, 1116, 312, 3571, 445, 281, 2010, 50574], "temperature": 0.0, "avg_logprob": -0.33057355505274977, "compression_ratio": 1.58203125, "no_speech_prob": 0.010488773696124554}, {"id": 821, "seek": 387946, "start": 3883.66, "end": 3887.98, "text": " 64, 32, but I'm trying to create something that I can paste into a function later.", "tokens": [50574, 12145, 11, 8858, 11, 457, 286, 478, 1382, 281, 1884, 746, 300, 286, 393, 9163, 666, 257, 2445, 1780, 13, 50790], "temperature": 0.0, "avg_logprob": -0.33057355505274977, "compression_ratio": 1.58203125, "no_speech_prob": 0.010488773696124554}, {"id": 822, "seek": 387946, "start": 3887.98, "end": 3888.98, "text": " So it's general.", "tokens": [50790, 407, 309, 311, 2674, 13, 50840], "temperature": 0.0, "avg_logprob": -0.33057355505274977, "compression_ratio": 1.58203125, "no_speech_prob": 0.010488773696124554}, {"id": 823, "seek": 387946, "start": 3888.98, "end": 3891.94, "text": " So that's the first two elements, 64, 32.", "tokens": [50840, 407, 300, 311, 264, 700, 732, 4959, 11, 12145, 11, 8858, 13, 50988], "temperature": 0.0, "avg_logprob": -0.33057355505274977, "compression_ratio": 1.58203125, "no_speech_prob": 0.010488773696124554}, {"id": 824, "seek": 387946, "start": 3891.94, "end": 3894.86, "text": " And then the star just inserts them directly in here.", "tokens": [50988, 400, 550, 264, 3543, 445, 49163, 552, 3838, 294, 510, 13, 51134], "temperature": 0.0, "avg_logprob": -0.33057355505274977, "compression_ratio": 1.58203125, "no_speech_prob": 0.010488773696124554}, {"id": 825, "seek": 387946, "start": 3894.86, "end": 3897.2200000000003, "text": " So 64, 32, minus one.", "tokens": [51134, 407, 12145, 11, 8858, 11, 3175, 472, 13, 51252], "temperature": 0.0, "avg_logprob": -0.33057355505274977, "compression_ratio": 1.58203125, "no_speech_prob": 0.010488773696124554}, {"id": 826, "seek": 387946, "start": 3897.2200000000003, "end": 3899.42, "text": " So 16 by 16.", "tokens": [51252, 407, 3165, 538, 3165, 13, 51362], "temperature": 0.0, "avg_logprob": -0.33057355505274977, "compression_ratio": 1.58203125, "no_speech_prob": 0.010488773696124554}, {"id": 827, "seek": 387946, "start": 3899.42, "end": 3905.98, "text": " Now then, again, because this is all stolen from the NLP world, in the NLP world, things", "tokens": [51362, 823, 550, 11, 797, 11, 570, 341, 307, 439, 15900, 490, 264, 426, 45196, 1002, 11, 294, 264, 426, 45196, 1002, 11, 721, 51690], "temperature": 0.0, "avg_logprob": -0.33057355505274977, "compression_ratio": 1.58203125, "no_speech_prob": 0.010488773696124554}, {"id": 828, "seek": 390598, "start": 3905.98, "end": 3911.7400000000002, "text": " are, have, they call this sequence.", "tokens": [50364, 366, 11, 362, 11, 436, 818, 341, 8310, 13, 50652], "temperature": 0.0, "avg_logprob": -0.2610921980459479, "compression_ratio": 1.6647727272727273, "no_speech_prob": 5.738756590289995e-05}, {"id": 829, "seek": 390598, "start": 3911.7400000000002, "end": 3914.94, "text": " So I'm going to call this sequence, by which we mean height by width.", "tokens": [50652, 407, 286, 478, 516, 281, 818, 341, 8310, 11, 538, 597, 321, 914, 6681, 538, 11402, 13, 50812], "temperature": 0.0, "avg_logprob": -0.2610921980459479, "compression_ratio": 1.6647727272727273, "no_speech_prob": 5.738756590289995e-05}, {"id": 830, "seek": 390598, "start": 3914.94, "end": 3919.46, "text": " Sequence comes before channel, which is often called D or dimension.", "tokens": [50812, 46859, 655, 1487, 949, 2269, 11, 597, 307, 2049, 1219, 413, 420, 10139, 13, 51038], "temperature": 0.0, "avg_logprob": -0.2610921980459479, "compression_ratio": 1.6647727272727273, "no_speech_prob": 5.738756590289995e-05}, {"id": 831, "seek": 390598, "start": 3919.46, "end": 3924.1, "text": " So we then transpose those last two dimensions.", "tokens": [51038, 407, 321, 550, 25167, 729, 1036, 732, 12819, 13, 51270], "temperature": 0.0, "avg_logprob": -0.2610921980459479, "compression_ratio": 1.6647727272727273, "no_speech_prob": 5.738756590289995e-05}, {"id": 832, "seek": 390598, "start": 3924.1, "end": 3932.3, "text": " So we've now got batch by sequence, 16 by 16, by channel or dimension.", "tokens": [51270, 407, 321, 600, 586, 658, 15245, 538, 8310, 11, 3165, 538, 3165, 11, 538, 2269, 420, 10139, 13, 51680], "temperature": 0.0, "avg_logprob": -0.2610921980459479, "compression_ratio": 1.6647727272727273, "no_speech_prob": 5.738756590289995e-05}, {"id": 833, "seek": 393230, "start": 3932.3, "end": 3937.34, "text": " So N, they generally call this NSD, sequence dimension.", "tokens": [50364, 407, 426, 11, 436, 5101, 818, 341, 426, 23969, 11, 8310, 10139, 13, 50616], "temperature": 0.0, "avg_logprob": -0.2993836836381392, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0005112545914016664}, {"id": 834, "seek": 393230, "start": 3937.34, "end": 3942.86, "text": " Okay, so we've got 32 channels.", "tokens": [50616, 1033, 11, 370, 321, 600, 658, 8858, 9235, 13, 50892], "temperature": 0.0, "avg_logprob": -0.2993836836381392, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0005112545914016664}, {"id": 835, "seek": 393230, "start": 3942.86, "end": 3950.34, "text": " So we now need three different projections that go from 32 channels in to 32 channels", "tokens": [50892, 407, 321, 586, 643, 1045, 819, 32371, 300, 352, 490, 8858, 9235, 294, 281, 8858, 9235, 51266], "temperature": 0.0, "avg_logprob": -0.2993836836381392, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0005112545914016664}, {"id": 836, "seek": 393230, "start": 3950.34, "end": 3951.34, "text": " out.", "tokens": [51266, 484, 13, 51316], "temperature": 0.0, "avg_logprob": -0.2993836836381392, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0005112545914016664}, {"id": 837, "seek": 393230, "start": 3951.34, "end": 3952.7400000000002, "text": " So that's just a linear layer.", "tokens": [51316, 407, 300, 311, 445, 257, 8213, 4583, 13, 51386], "temperature": 0.0, "avg_logprob": -0.2993836836381392, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0005112545914016664}, {"id": 838, "seek": 393230, "start": 3952.7400000000002, "end": 3958.82, "text": " Okay, and just remember a linear layer is just a matrix multiply plus a bias.", "tokens": [51386, 1033, 11, 293, 445, 1604, 257, 8213, 4583, 307, 445, 257, 8141, 12972, 1804, 257, 12577, 13, 51690], "temperature": 0.0, "avg_logprob": -0.2993836836381392, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0005112545914016664}, {"id": 839, "seek": 393230, "start": 3958.82, "end": 3961.1800000000003, "text": " So there's three of them.", "tokens": [51690, 407, 456, 311, 1045, 295, 552, 13, 51808], "temperature": 0.0, "avg_logprob": -0.2993836836381392, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0005112545914016664}, {"id": 840, "seek": 396118, "start": 3961.2599999999998, "end": 3963.98, "text": " And so they're all going to be randomly initialized, different random numbers.", "tokens": [50368, 400, 370, 436, 434, 439, 516, 281, 312, 16979, 5883, 1602, 11, 819, 4974, 3547, 13, 50504], "temperature": 0.0, "avg_logprob": -0.29220476767999665, "compression_ratio": 1.7649253731343284, "no_speech_prob": 2.0145649614278227e-05}, {"id": 841, "seek": 396118, "start": 3963.98, "end": 3969.3799999999997, "text": " We're going to call them SK, SQ, SV.", "tokens": [50504, 492, 434, 516, 281, 818, 552, 21483, 11, 318, 48, 11, 31910, 13, 50774], "temperature": 0.0, "avg_logprob": -0.29220476767999665, "compression_ratio": 1.7649253731343284, "no_speech_prob": 2.0145649614278227e-05}, {"id": 842, "seek": 396118, "start": 3969.3799999999997, "end": 3973.1, "text": " And so we can then, they're just callable, so we can then pass the exact same thing into", "tokens": [50774, 400, 370, 321, 393, 550, 11, 436, 434, 445, 818, 712, 11, 370, 321, 393, 550, 1320, 264, 1900, 912, 551, 666, 50960], "temperature": 0.0, "avg_logprob": -0.29220476767999665, "compression_ratio": 1.7649253731343284, "no_speech_prob": 2.0145649614278227e-05}, {"id": 843, "seek": 396118, "start": 3973.1, "end": 3979.8199999999997, "text": " three, all three, because we're doing self-attention to get back our keys, queries, and values.", "tokens": [50960, 1045, 11, 439, 1045, 11, 570, 321, 434, 884, 2698, 12, 1591, 1251, 281, 483, 646, 527, 9317, 11, 24109, 11, 293, 4190, 13, 51296], "temperature": 0.0, "avg_logprob": -0.29220476767999665, "compression_ratio": 1.7649253731343284, "no_speech_prob": 2.0145649614278227e-05}, {"id": 844, "seek": 396118, "start": 3979.8199999999997, "end": 3983.5, "text": " Or K, Q, and V. I just think of them as K, Q, and V, because they're not really keys,", "tokens": [51296, 1610, 591, 11, 1249, 11, 293, 691, 13, 286, 445, 519, 295, 552, 382, 591, 11, 1249, 11, 293, 691, 11, 570, 436, 434, 406, 534, 9317, 11, 51480], "temperature": 0.0, "avg_logprob": -0.29220476767999665, "compression_ratio": 1.7649253731343284, "no_speech_prob": 2.0145649614278227e-05}, {"id": 845, "seek": 396118, "start": 3983.5, "end": 3986.8199999999997, "text": " queries, and values to me.", "tokens": [51480, 24109, 11, 293, 4190, 281, 385, 13, 51646], "temperature": 0.0, "avg_logprob": -0.29220476767999665, "compression_ratio": 1.7649253731343284, "no_speech_prob": 2.0145649614278227e-05}, {"id": 846, "seek": 396118, "start": 3986.8199999999997, "end": 3990.94, "text": " So then we have to do the matrix multiply by the transpose.", "tokens": [51646, 407, 550, 321, 362, 281, 360, 264, 8141, 12972, 538, 264, 25167, 13, 51852], "temperature": 0.0, "avg_logprob": -0.29220476767999665, "compression_ratio": 1.7649253731343284, "no_speech_prob": 2.0145649614278227e-05}, {"id": 847, "seek": 399094, "start": 3991.7000000000003, "end": 4000.54, "text": " And so then for every one of the 64 items in the batch, for every one of the 256 pixels,", "tokens": [50402, 400, 370, 550, 337, 633, 472, 295, 264, 12145, 4754, 294, 264, 15245, 11, 337, 633, 472, 295, 264, 38882, 18668, 11, 50844], "temperature": 0.0, "avg_logprob": -0.23462462843510143, "compression_ratio": 1.6694560669456067, "no_speech_prob": 1.5689540305174887e-05}, {"id": 848, "seek": 399094, "start": 4000.54, "end": 4005.38, "text": " there are now 256 weights, or at least there would be if we'd done softmax, which we haven't", "tokens": [50844, 456, 366, 586, 38882, 17443, 11, 420, 412, 1935, 456, 576, 312, 498, 321, 1116, 1096, 2787, 41167, 11, 597, 321, 2378, 380, 51086], "temperature": 0.0, "avg_logprob": -0.23462462843510143, "compression_ratio": 1.6694560669456067, "no_speech_prob": 1.5689540305174887e-05}, {"id": 849, "seek": 399094, "start": 4005.38, "end": 4006.62, "text": " yet.", "tokens": [51086, 1939, 13, 51148], "temperature": 0.0, "avg_logprob": -0.23462462843510143, "compression_ratio": 1.6694560669456067, "no_speech_prob": 1.5689540305174887e-05}, {"id": 850, "seek": 399094, "start": 4006.62, "end": 4010.2200000000003, "text": " So we can now put that into a self-attention.", "tokens": [51148, 407, 321, 393, 586, 829, 300, 666, 257, 2698, 12, 1591, 1251, 13, 51328], "temperature": 0.0, "avg_logprob": -0.23462462843510143, "compression_ratio": 1.6694560669456067, "no_speech_prob": 1.5689540305174887e-05}, {"id": 851, "seek": 399094, "start": 4010.2200000000003, "end": 4014.3, "text": " As Jono mentioned, we want to make sure that we normalize things.", "tokens": [51328, 1018, 7745, 78, 2835, 11, 321, 528, 281, 652, 988, 300, 321, 2710, 1125, 721, 13, 51532], "temperature": 0.0, "avg_logprob": -0.23462462843510143, "compression_ratio": 1.6694560669456067, "no_speech_prob": 1.5689540305174887e-05}, {"id": 852, "seek": 399094, "start": 4014.3, "end": 4016.66, "text": " So we can pop a normalization here.", "tokens": [51532, 407, 321, 393, 1665, 257, 2710, 2144, 510, 13, 51650], "temperature": 0.0, "avg_logprob": -0.23462462843510143, "compression_ratio": 1.6694560669456067, "no_speech_prob": 1.5689540305174887e-05}, {"id": 853, "seek": 399094, "start": 4016.66, "end": 4019.18, "text": " We talked about group norm back when we talked about batch norm.", "tokens": [51650, 492, 2825, 466, 1594, 2026, 646, 562, 321, 2825, 466, 15245, 2026, 13, 51776], "temperature": 0.0, "avg_logprob": -0.23462462843510143, "compression_ratio": 1.6694560669456067, "no_speech_prob": 1.5689540305174887e-05}, {"id": 854, "seek": 401918, "start": 4019.22, "end": 4025.4199999999996, "text": " So group norm is just batch norm, which has been split into a bunch of sets of channels.", "tokens": [50366, 407, 1594, 2026, 307, 445, 15245, 2026, 11, 597, 575, 668, 7472, 666, 257, 3840, 295, 6352, 295, 9235, 13, 50676], "temperature": 0.0, "avg_logprob": -0.40047529008653426, "compression_ratio": 1.4107142857142858, "no_speech_prob": 0.0036498464178293943}, {"id": 855, "seek": 401918, "start": 4031.4199999999996, "end": 4037.74, "text": " Okay, so then we are going to create our K, Q, V.", "tokens": [50976, 1033, 11, 370, 550, 321, 366, 516, 281, 1884, 527, 591, 11, 1249, 11, 691, 13, 51292], "temperature": 0.0, "avg_logprob": -0.40047529008653426, "compression_ratio": 1.4107142857142858, "no_speech_prob": 0.0036498464178293943}, {"id": 856, "seek": 401918, "start": 4037.74, "end": 4038.74, "text": " Yep, Jono?", "tokens": [51292, 7010, 11, 7745, 78, 30, 51342], "temperature": 0.0, "avg_logprob": -0.40047529008653426, "compression_ratio": 1.4107142857142858, "no_speech_prob": 0.0036498464178293943}, {"id": 857, "seek": 401918, "start": 4038.74, "end": 4043.2599999999998, "text": " I was just going to ask, should those be just bias equals false, so that they're only a", "tokens": [51342, 286, 390, 445, 516, 281, 1029, 11, 820, 729, 312, 445, 12577, 6915, 7908, 11, 370, 300, 436, 434, 787, 257, 51568], "temperature": 0.0, "avg_logprob": -0.40047529008653426, "compression_ratio": 1.4107142857142858, "no_speech_prob": 0.0036498464178293943}, {"id": 858, "seek": 404326, "start": 4043.34, "end": 4049.34, "text": " matrix multiply to strictly match the traditional implementation?", "tokens": [50368, 8141, 12972, 281, 20792, 2995, 264, 5164, 11420, 30, 50668], "temperature": 0.0, "avg_logprob": -0.5003532326739767, "compression_ratio": 1.296875, "no_speech_prob": 0.14021672308444977}, {"id": 859, "seek": 404326, "start": 4053.34, "end": 4056.34, "text": " No, because...", "tokens": [50868, 883, 11, 570, 485, 51018], "temperature": 0.0, "avg_logprob": -0.5003532326739767, "compression_ratio": 1.296875, "no_speech_prob": 0.14021672308444977}, {"id": 860, "seek": 404326, "start": 4056.34, "end": 4059.34, "text": " Okay, they also do it that way.", "tokens": [51018, 1033, 11, 436, 611, 360, 309, 300, 636, 13, 51168], "temperature": 0.0, "avg_logprob": -0.5003532326739767, "compression_ratio": 1.296875, "no_speech_prob": 0.14021672308444977}, {"id": 861, "seek": 404326, "start": 4064.34, "end": 4067.34, "text": " Yeah, they have bias in their attention blocks.", "tokens": [51418, 865, 11, 436, 362, 12577, 294, 641, 3202, 8474, 13, 51568], "temperature": 0.0, "avg_logprob": -0.5003532326739767, "compression_ratio": 1.296875, "no_speech_prob": 0.14021672308444977}, {"id": 862, "seek": 404326, "start": 4067.34, "end": 4068.34, "text": " Cool.", "tokens": [51568, 8561, 13, 51618], "temperature": 0.0, "avg_logprob": -0.5003532326739767, "compression_ratio": 1.296875, "no_speech_prob": 0.14021672308444977}, {"id": 863, "seek": 406834, "start": 4068.42, "end": 4080.42, "text": " Okay, so we've got our Q, K, and V, self.Q, self.K, self.V being our projections.", "tokens": [50368, 1033, 11, 370, 321, 600, 658, 527, 1249, 11, 591, 11, 293, 691, 11, 2698, 13, 48, 11, 2698, 13, 42, 11, 2698, 13, 53, 885, 527, 32371, 13, 50968], "temperature": 0.0, "avg_logprob": -0.25634466191773775, "compression_ratio": 1.4918032786885247, "no_speech_prob": 2.0462839529500343e-05}, {"id": 864, "seek": 406834, "start": 4080.42, "end": 4088.78, "text": " And so to do 2D self-attention, we need to find the n, c, h, w from our shape.", "tokens": [50968, 400, 370, 281, 360, 568, 35, 2698, 12, 1591, 1251, 11, 321, 643, 281, 915, 264, 297, 11, 269, 11, 276, 11, 261, 490, 527, 3909, 13, 51386], "temperature": 0.0, "avg_logprob": -0.25634466191773775, "compression_ratio": 1.4918032786885247, "no_speech_prob": 2.0462839529500343e-05}, {"id": 865, "seek": 406834, "start": 4088.78, "end": 4090.9, "text": " We can do our normalization.", "tokens": [51386, 492, 393, 360, 527, 2710, 2144, 13, 51492], "temperature": 0.0, "avg_logprob": -0.25634466191773775, "compression_ratio": 1.4918032786885247, "no_speech_prob": 2.0462839529500343e-05}, {"id": 866, "seek": 406834, "start": 4090.9, "end": 4093.42, "text": " We then do our flattening, as discussed.", "tokens": [51492, 492, 550, 360, 527, 24183, 278, 11, 382, 7152, 13, 51618], "temperature": 0.0, "avg_logprob": -0.25634466191773775, "compression_ratio": 1.4918032786885247, "no_speech_prob": 2.0462839529500343e-05}, {"id": 867, "seek": 406834, "start": 4093.42, "end": 4097.04, "text": " We then transpose the last two dimensions.", "tokens": [51618, 492, 550, 25167, 264, 1036, 732, 12819, 13, 51799], "temperature": 0.0, "avg_logprob": -0.25634466191773775, "compression_ratio": 1.4918032786885247, "no_speech_prob": 2.0462839529500343e-05}, {"id": 868, "seek": 409704, "start": 4097.74, "end": 4100.68, "text": " We then create our Q, K, V by doing the projections.", "tokens": [50399, 492, 550, 1884, 527, 1249, 11, 591, 11, 691, 538, 884, 264, 32371, 13, 50546], "temperature": 0.0, "avg_logprob": -0.25356680828592054, "compression_ratio": 1.6641509433962265, "no_speech_prob": 4.832552804145962e-05}, {"id": 869, "seek": 409704, "start": 4100.68, "end": 4104.04, "text": " And we then do the matrix multiply.", "tokens": [50546, 400, 321, 550, 360, 264, 8141, 12972, 13, 50714], "temperature": 0.0, "avg_logprob": -0.25356680828592054, "compression_ratio": 1.6641509433962265, "no_speech_prob": 4.832552804145962e-05}, {"id": 870, "seek": 409704, "start": 4104.04, "end": 4107.84, "text": " Now we've got to be a bit careful now, because as a result of that matrix multiply, we've", "tokens": [50714, 823, 321, 600, 658, 281, 312, 257, 857, 5026, 586, 11, 570, 382, 257, 1874, 295, 300, 8141, 12972, 11, 321, 600, 50904], "temperature": 0.0, "avg_logprob": -0.25356680828592054, "compression_ratio": 1.6641509433962265, "no_speech_prob": 4.832552804145962e-05}, {"id": 871, "seek": 409704, "start": 4107.84, "end": 4113.76, "text": " changed the scale by multiplying and adding all those things together.", "tokens": [50904, 3105, 264, 4373, 538, 30955, 293, 5127, 439, 729, 721, 1214, 13, 51200], "temperature": 0.0, "avg_logprob": -0.25356680828592054, "compression_ratio": 1.6641509433962265, "no_speech_prob": 4.832552804145962e-05}, {"id": 872, "seek": 409704, "start": 4113.76, "end": 4119.5199999999995, "text": " So if we then simply divide by the square root of the number of filters, it turns out", "tokens": [51200, 407, 498, 321, 550, 2935, 9845, 538, 264, 3732, 5593, 295, 264, 1230, 295, 15995, 11, 309, 4523, 484, 51488], "temperature": 0.0, "avg_logprob": -0.25356680828592054, "compression_ratio": 1.6641509433962265, "no_speech_prob": 4.832552804145962e-05}, {"id": 873, "seek": 409704, "start": 4119.5199999999995, "end": 4121.2, "text": " that's...", "tokens": [51488, 300, 311, 485, 51572], "temperature": 0.0, "avg_logprob": -0.25356680828592054, "compression_ratio": 1.6641509433962265, "no_speech_prob": 4.832552804145962e-05}, {"id": 874, "seek": 409704, "start": 4121.2, "end": 4124.84, "text": " You can convince yourself of this if you wish to, but that's going to return it to the original", "tokens": [51572, 509, 393, 13447, 1803, 295, 341, 498, 291, 3172, 281, 11, 457, 300, 311, 516, 281, 2736, 309, 281, 264, 3380, 51754], "temperature": 0.0, "avg_logprob": -0.25356680828592054, "compression_ratio": 1.6641509433962265, "no_speech_prob": 4.832552804145962e-05}, {"id": 875, "seek": 412484, "start": 4124.84, "end": 4127.64, "text": " scale.", "tokens": [50364, 4373, 13, 50504], "temperature": 0.0, "avg_logprob": -0.3273296146602421, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.00017400280921719968}, {"id": 876, "seek": 412484, "start": 4127.64, "end": 4133.68, "text": " We can now do the softmax across the last dimension, and then multiply each of them", "tokens": [50504, 492, 393, 586, 360, 264, 2787, 41167, 2108, 264, 1036, 10139, 11, 293, 550, 12972, 1184, 295, 552, 50806], "temperature": 0.0, "avg_logprob": -0.3273296146602421, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.00017400280921719968}, {"id": 877, "seek": 412484, "start": 4133.68, "end": 4138.92, "text": " by V. So using matrix multiply to do them all in one go.", "tokens": [50806, 538, 691, 13, 407, 1228, 8141, 12972, 281, 360, 552, 439, 294, 472, 352, 13, 51068], "temperature": 0.0, "avg_logprob": -0.3273296146602421, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.00017400280921719968}, {"id": 878, "seek": 412484, "start": 4138.92, "end": 4144.32, "text": " We didn't mention, but we then do one final projection.", "tokens": [51068, 492, 994, 380, 2152, 11, 457, 321, 550, 360, 472, 2572, 22743, 13, 51338], "temperature": 0.0, "avg_logprob": -0.3273296146602421, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.00017400280921719968}, {"id": 879, "seek": 412484, "start": 4144.32, "end": 4151.4800000000005, "text": " Again, just to give it the opportunity to map things, you know, to some different scale.", "tokens": [51338, 3764, 11, 445, 281, 976, 309, 264, 2650, 281, 4471, 721, 11, 291, 458, 11, 281, 512, 819, 4373, 13, 51696], "temperature": 0.0, "avg_logprob": -0.3273296146602421, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.00017400280921719968}, {"id": 880, "seek": 412484, "start": 4151.4800000000005, "end": 4154.72, "text": " You know, shift it also if necessary.", "tokens": [51696, 509, 458, 11, 5513, 309, 611, 498, 4818, 13, 51858], "temperature": 0.0, "avg_logprob": -0.3273296146602421, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.00017400280921719968}, {"id": 881, "seek": 415472, "start": 4155.6, "end": 4158.320000000001, "text": " So we can then shift the last two back to where they started from, and then reshape", "tokens": [50408, 407, 321, 393, 550, 5513, 264, 1036, 732, 646, 281, 689, 436, 1409, 490, 11, 293, 550, 725, 42406, 50544], "temperature": 0.0, "avg_logprob": -0.40064470307165834, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.00015597837045788765}, {"id": 882, "seek": 415472, "start": 4158.320000000001, "end": 4160.72, "text": " it back to where it started from, and then add it.", "tokens": [50544, 309, 646, 281, 689, 309, 1409, 490, 11, 293, 550, 909, 309, 13, 50664], "temperature": 0.0, "avg_logprob": -0.40064470307165834, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.00015597837045788765}, {"id": 883, "seek": 415472, "start": 4160.72, "end": 4163.04, "text": " Remember I said it's going to be X plus.", "tokens": [50664, 5459, 286, 848, 309, 311, 516, 281, 312, 1783, 1804, 13, 50780], "temperature": 0.0, "avg_logprob": -0.40064470307165834, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.00015597837045788765}, {"id": 884, "seek": 415472, "start": 4163.04, "end": 4164.04, "text": " Add it back to the original.", "tokens": [50780, 5349, 309, 646, 281, 264, 3380, 13, 50830], "temperature": 0.0, "avg_logprob": -0.40064470307165834, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.00015597837045788765}, {"id": 885, "seek": 415472, "start": 4164.04, "end": 4170.56, "text": " So this is actually kind of self-attention, ResNet style, if you like.", "tokens": [50830, 407, 341, 307, 767, 733, 295, 2698, 12, 1591, 1251, 11, 5015, 31890, 3758, 11, 498, 291, 411, 13, 51156], "temperature": 0.0, "avg_logprob": -0.40064470307165834, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.00015597837045788765}, {"id": 886, "seek": 415472, "start": 4170.56, "end": 4177.56, "text": " Diffuses, if I remember correctly, does include the X plus in theirs, but some implementations,", "tokens": [51156, 413, 3661, 8355, 11, 498, 286, 1604, 8944, 11, 775, 4090, 264, 1783, 1804, 294, 22760, 11, 457, 512, 4445, 763, 11, 51506], "temperature": 0.0, "avg_logprob": -0.40064470307165834, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.00015597837045788765}, {"id": 887, "seek": 415472, "start": 4177.56, "end": 4180.68, "text": " like for example PyTorch implementation, doesn't.", "tokens": [51506, 411, 337, 1365, 9953, 51, 284, 339, 11420, 11, 1177, 380, 13, 51662], "temperature": 0.0, "avg_logprob": -0.40064470307165834, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.00015597837045788765}, {"id": 888, "seek": 418068, "start": 4180.72, "end": 4185.56, "text": " Okay, so that's a self-attention module, and all you need to do is tell it how many channels", "tokens": [50366, 1033, 11, 370, 300, 311, 257, 2698, 12, 1591, 1251, 10088, 11, 293, 439, 291, 643, 281, 360, 307, 980, 309, 577, 867, 9235, 50608], "temperature": 0.0, "avg_logprob": -0.2869439558549361, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.00036258529871702194}, {"id": 889, "seek": 418068, "start": 4185.56, "end": 4188.72, "text": " to do attention on.", "tokens": [50608, 281, 360, 3202, 322, 13, 50766], "temperature": 0.0, "avg_logprob": -0.2869439558549361, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.00036258529871702194}, {"id": 890, "seek": 418068, "start": 4188.72, "end": 4194.12, "text": " So and you need to tell it that, because that's what we need for our four different projections,", "tokens": [50766, 407, 293, 291, 643, 281, 980, 309, 300, 11, 570, 300, 311, 437, 321, 643, 337, 527, 1451, 819, 32371, 11, 51036], "temperature": 0.0, "avg_logprob": -0.2869439558549361, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.00036258529871702194}, {"id": 891, "seek": 418068, "start": 4194.12, "end": 4198.4400000000005, "text": " and our group and our scale.", "tokens": [51036, 293, 527, 1594, 293, 527, 4373, 13, 51252], "temperature": 0.0, "avg_logprob": -0.2869439558549361, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.00036258529871702194}, {"id": 892, "seek": 418068, "start": 4198.4400000000005, "end": 4200.68, "text": " I guess strictly speaking, it doesn't have to be stored here.", "tokens": [51252, 286, 2041, 20792, 4124, 11, 309, 1177, 380, 362, 281, 312, 12187, 510, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2869439558549361, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.00036258529871702194}, {"id": 893, "seek": 418068, "start": 4200.68, "end": 4205.280000000001, "text": " You could calculate it here, but anyway, either way is fine.", "tokens": [51364, 509, 727, 8873, 309, 510, 11, 457, 4033, 11, 2139, 636, 307, 2489, 13, 51594], "temperature": 0.0, "avg_logprob": -0.2869439558549361, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.00036258529871702194}, {"id": 894, "seek": 420528, "start": 4205.28, "end": 4213.36, "text": " Okay, so if we create a self-attention layer, we can then call it on our little randomly", "tokens": [50364, 1033, 11, 370, 498, 321, 1884, 257, 2698, 12, 1591, 1251, 4583, 11, 321, 393, 550, 818, 309, 322, 527, 707, 16979, 50768], "temperature": 0.0, "avg_logprob": -0.27543009063343943, "compression_ratio": 1.5392670157068062, "no_speech_prob": 8.39804397401167e-06}, {"id": 895, "seek": 420528, "start": 4213.36, "end": 4220.96, "text": " generated numbers, and it doesn't change the shape, because we transpose it back and reshape", "tokens": [50768, 10833, 3547, 11, 293, 309, 1177, 380, 1319, 264, 3909, 11, 570, 321, 25167, 309, 646, 293, 725, 42406, 51148], "temperature": 0.0, "avg_logprob": -0.27543009063343943, "compression_ratio": 1.5392670157068062, "no_speech_prob": 8.39804397401167e-06}, {"id": 896, "seek": 420528, "start": 4220.96, "end": 4223.0, "text": " it back, but we can see that's basically worked.", "tokens": [51148, 309, 646, 11, 457, 321, 393, 536, 300, 311, 1936, 2732, 13, 51250], "temperature": 0.0, "avg_logprob": -0.27543009063343943, "compression_ratio": 1.5392670157068062, "no_speech_prob": 8.39804397401167e-06}, {"id": 897, "seek": 420528, "start": 4223.0, "end": 4224.84, "text": " We can see it creates numbers.", "tokens": [51250, 492, 393, 536, 309, 7829, 3547, 13, 51342], "temperature": 0.0, "avg_logprob": -0.27543009063343943, "compression_ratio": 1.5392670157068062, "no_speech_prob": 8.39804397401167e-06}, {"id": 898, "seek": 420528, "start": 4224.84, "end": 4227.32, "text": " How do we know if they're right?", "tokens": [51342, 1012, 360, 321, 458, 498, 436, 434, 558, 30, 51466], "temperature": 0.0, "avg_logprob": -0.27543009063343943, "compression_ratio": 1.5392670157068062, "no_speech_prob": 8.39804397401167e-06}, {"id": 899, "seek": 422732, "start": 4227.32, "end": 4237.96, "text": " Well we could create a diffuses attention block, that will randomly generate a QKV projection.", "tokens": [50364, 1042, 321, 727, 1884, 257, 7593, 8355, 3202, 3461, 11, 300, 486, 16979, 8460, 257, 1249, 42, 53, 22743, 13, 50896], "temperature": 0.0, "avg_logprob": -0.3617243923983731, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.009267413057386875}, {"id": 900, "seek": 422732, "start": 4237.96, "end": 4241.96, "text": " Sorry actually they call something else, they call it query key value projection attention", "tokens": [50896, 4919, 767, 436, 818, 746, 1646, 11, 436, 818, 309, 14581, 2141, 2158, 22743, 3202, 51096], "temperature": 0.0, "avg_logprob": -0.3617243923983731, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.009267413057386875}, {"id": 901, "seek": 422732, "start": 4241.96, "end": 4243.719999999999, "text": " and group norm.", "tokens": [51096, 293, 1594, 2026, 13, 51184], "temperature": 0.0, "avg_logprob": -0.3617243923983731, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.009267413057386875}, {"id": 902, "seek": 422732, "start": 4243.719999999999, "end": 4247.84, "text": " We call it QKV progen norm, they're the same things.", "tokens": [51184, 492, 818, 309, 1249, 42, 53, 447, 1766, 2026, 11, 436, 434, 264, 912, 721, 13, 51390], "temperature": 0.0, "avg_logprob": -0.3617243923983731, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.009267413057386875}, {"id": 903, "seek": 422732, "start": 4247.84, "end": 4254.5199999999995, "text": " And so then we can just zip those tuples together, so that's going to take each pair, first pair,", "tokens": [51390, 400, 370, 550, 321, 393, 445, 20730, 729, 2604, 2622, 1214, 11, 370, 300, 311, 516, 281, 747, 1184, 6119, 11, 700, 6119, 11, 51724], "temperature": 0.0, "avg_logprob": -0.3617243923983731, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.009267413057386875}, {"id": 904, "seek": 425452, "start": 4254.52, "end": 4264.280000000001, "text": " second pair, third pair, and copy the weight and the bias from their attention block, sorry", "tokens": [50364, 1150, 6119, 11, 2636, 6119, 11, 293, 5055, 264, 3364, 293, 264, 12577, 490, 641, 3202, 3461, 11, 2597, 50852], "temperature": 0.0, "avg_logprob": -0.2687316802610834, "compression_ratio": 2.0306748466257667, "no_speech_prob": 2.9773109417874366e-05}, {"id": 905, "seek": 425452, "start": 4264.280000000001, "end": 4270.8, "text": " from our attention block to the diffuses attention block, and then we can check that they give", "tokens": [50852, 490, 527, 3202, 3461, 281, 264, 7593, 8355, 3202, 3461, 11, 293, 550, 321, 393, 1520, 300, 436, 976, 51178], "temperature": 0.0, "avg_logprob": -0.2687316802610834, "compression_ratio": 2.0306748466257667, "no_speech_prob": 2.9773109417874366e-05}, {"id": 906, "seek": 425452, "start": 4270.8, "end": 4273.280000000001, "text": " the same value, which you can see they do.", "tokens": [51178, 264, 912, 2158, 11, 597, 291, 393, 536, 436, 360, 13, 51302], "temperature": 0.0, "avg_logprob": -0.2687316802610834, "compression_ratio": 2.0306748466257667, "no_speech_prob": 2.9773109417874366e-05}, {"id": 907, "seek": 425452, "start": 4273.280000000001, "end": 4278.0, "text": " So this shows us that our attention block is the same as the diffuses attention block,", "tokens": [51302, 407, 341, 3110, 505, 300, 527, 3202, 3461, 307, 264, 912, 382, 264, 7593, 8355, 3202, 3461, 11, 51538], "temperature": 0.0, "avg_logprob": -0.2687316802610834, "compression_ratio": 2.0306748466257667, "no_speech_prob": 2.9773109417874366e-05}, {"id": 908, "seek": 425452, "start": 4278.0, "end": 4282.120000000001, "text": " which is nice.", "tokens": [51538, 597, 307, 1481, 13, 51744], "temperature": 0.0, "avg_logprob": -0.2687316802610834, "compression_ratio": 2.0306748466257667, "no_speech_prob": 2.9773109417874366e-05}, {"id": 909, "seek": 428212, "start": 4282.12, "end": 4290.72, "text": " There's a trick which neither diffuses nor PyTorch use, for reasons I don't understand,", "tokens": [50364, 821, 311, 257, 4282, 597, 9662, 7593, 8355, 6051, 9953, 51, 284, 339, 764, 11, 337, 4112, 286, 500, 380, 1223, 11, 50794], "temperature": 0.0, "avg_logprob": -0.22814206154115738, "compression_ratio": 1.5240963855421688, "no_speech_prob": 0.0018386320443823934}, {"id": 910, "seek": 428212, "start": 4290.72, "end": 4295.24, "text": " which is that we don't actually need three separate projections here.", "tokens": [50794, 597, 307, 300, 321, 500, 380, 767, 643, 1045, 4994, 32371, 510, 13, 51020], "temperature": 0.0, "avg_logprob": -0.22814206154115738, "compression_ratio": 1.5240963855421688, "no_speech_prob": 0.0018386320443823934}, {"id": 911, "seek": 428212, "start": 4295.24, "end": 4302.12, "text": " We could create one projection from ni to ni times 3, that's basically doing three projections.", "tokens": [51020, 492, 727, 1884, 472, 22743, 490, 3867, 281, 3867, 1413, 805, 11, 300, 311, 1936, 884, 1045, 32371, 13, 51364], "temperature": 0.0, "avg_logprob": -0.22814206154115738, "compression_ratio": 1.5240963855421688, "no_speech_prob": 0.0018386320443823934}, {"id": 912, "seek": 430212, "start": 4302.12, "end": 4314.0, "text": " So we could call this QKV, and so that gives us 64 by 256 by 96, instead of 64 by 256 by", "tokens": [50364, 407, 321, 727, 818, 341, 1249, 42, 53, 11, 293, 370, 300, 2709, 505, 12145, 538, 38882, 538, 24124, 11, 2602, 295, 12145, 538, 38882, 538, 50958], "temperature": 0.0, "avg_logprob": -0.2663172052261677, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.027163729071617126}, {"id": 913, "seek": 430212, "start": 4314.0, "end": 4317.92, "text": " 32, because it's the three sets.", "tokens": [50958, 8858, 11, 570, 309, 311, 264, 1045, 6352, 13, 51154], "temperature": 0.0, "avg_logprob": -0.2663172052261677, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.027163729071617126}, {"id": 914, "seek": 430212, "start": 4317.92, "end": 4323.5199999999995, "text": " And then we can use chunk, which we saw earlier, to split that into three separate variables", "tokens": [51154, 400, 550, 321, 393, 764, 16635, 11, 597, 321, 1866, 3071, 11, 281, 7472, 300, 666, 1045, 4994, 9102, 51434], "temperature": 0.0, "avg_logprob": -0.2663172052261677, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.027163729071617126}, {"id": 915, "seek": 430212, "start": 4323.5199999999995, "end": 4327.64, "text": " along the last dimension to get us our QKV.", "tokens": [51434, 2051, 264, 1036, 10139, 281, 483, 505, 527, 1249, 42, 53, 13, 51640], "temperature": 0.0, "avg_logprob": -0.2663172052261677, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.027163729071617126}, {"id": 916, "seek": 430212, "start": 4327.64, "end": 4331.24, "text": " And we can then do the same thing, Q at Q dot transpose etc.", "tokens": [51640, 400, 321, 393, 550, 360, 264, 912, 551, 11, 1249, 412, 1249, 5893, 25167, 5183, 13, 51820], "temperature": 0.0, "avg_logprob": -0.2663172052261677, "compression_ratio": 1.5118483412322274, "no_speech_prob": 0.027163729071617126}, {"id": 917, "seek": 433124, "start": 4331.36, "end": 4340.24, "text": " So here's another version of attention, where we just have one projection for QKV, and we", "tokens": [50370, 407, 510, 311, 1071, 3037, 295, 3202, 11, 689, 321, 445, 362, 472, 22743, 337, 1249, 42, 53, 11, 293, 321, 50814], "temperature": 0.0, "avg_logprob": -0.28179921160687454, "compression_ratio": 1.4502369668246446, "no_speech_prob": 0.00016865190991666168}, {"id": 918, "seek": 433124, "start": 4340.24, "end": 4345.5599999999995, "text": " chunkify it into separate Q, K, and V, and this does the same thing, it's just a bit", "tokens": [50814, 16635, 2505, 309, 666, 4994, 1249, 11, 591, 11, 293, 691, 11, 293, 341, 775, 264, 912, 551, 11, 309, 311, 445, 257, 857, 51080], "temperature": 0.0, "avg_logprob": -0.28179921160687454, "compression_ratio": 1.4502369668246446, "no_speech_prob": 0.00016865190991666168}, {"id": 919, "seek": 433124, "start": 4345.5599999999995, "end": 4346.5599999999995, "text": " more concise.", "tokens": [51080, 544, 44882, 13, 51130], "temperature": 0.0, "avg_logprob": -0.28179921160687454, "compression_ratio": 1.4502369668246446, "no_speech_prob": 0.00016865190991666168}, {"id": 920, "seek": 433124, "start": 4346.5599999999995, "end": 4353.8, "text": " And it should be faster as well, at least if you're not using some kind of XLA compiler", "tokens": [51130, 400, 309, 820, 312, 4663, 382, 731, 11, 412, 1935, 498, 291, 434, 406, 1228, 512, 733, 295, 1783, 11435, 31958, 51492], "temperature": 0.0, "avg_logprob": -0.28179921160687454, "compression_ratio": 1.4502369668246446, "no_speech_prob": 0.00016865190991666168}, {"id": 921, "seek": 433124, "start": 4353.8, "end": 4356.76, "text": " or ONX or Triton or whatever.", "tokens": [51492, 420, 9299, 55, 420, 1765, 270, 266, 420, 2035, 13, 51640], "temperature": 0.0, "avg_logprob": -0.28179921160687454, "compression_ratio": 1.4502369668246446, "no_speech_prob": 0.00016865190991666168}, {"id": 922, "seek": 435676, "start": 4356.92, "end": 4361.24, "text": " For normal PyTorch, this should be faster, because it's doing less back and forth between", "tokens": [50372, 1171, 2710, 9953, 51, 284, 339, 11, 341, 820, 312, 4663, 11, 570, 309, 311, 884, 1570, 646, 293, 5220, 1296, 50588], "temperature": 0.0, "avg_logprob": -0.3726342519124349, "compression_ratio": 1.3178807947019868, "no_speech_prob": 0.0008830158039927483}, {"id": 923, "seek": 435676, "start": 4361.24, "end": 4364.04, "text": " the CPU and the GPU.", "tokens": [50588, 264, 13199, 293, 264, 18407, 13, 50728], "temperature": 0.0, "avg_logprob": -0.3726342519124349, "compression_ratio": 1.3178807947019868, "no_speech_prob": 0.0008830158039927483}, {"id": 924, "seek": 435676, "start": 4364.04, "end": 4371.72, "text": " All right, so that's basic self-attention.", "tokens": [50728, 1057, 558, 11, 370, 300, 311, 3875, 2698, 12, 1591, 1251, 13, 51112], "temperature": 0.0, "avg_logprob": -0.3726342519124349, "compression_ratio": 1.3178807947019868, "no_speech_prob": 0.0008830158039927483}, {"id": 925, "seek": 435676, "start": 4371.72, "end": 4380.320000000001, "text": " This is not what's done basically ever, ever.", "tokens": [51112, 639, 307, 406, 437, 311, 1096, 1936, 1562, 11, 1562, 13, 51542], "temperature": 0.0, "avg_logprob": -0.3726342519124349, "compression_ratio": 1.3178807947019868, "no_speech_prob": 0.0008830158039927483}, {"id": 926, "seek": 438032, "start": 4380.32, "end": 4390.28, "text": " Because in fact, the kind of question of like, well, which pixels do I care about,", "tokens": [50364, 1436, 294, 1186, 11, 264, 733, 295, 1168, 295, 411, 11, 731, 11, 597, 18668, 360, 286, 1127, 466, 11, 50862], "temperature": 0.0, "avg_logprob": -0.2529506074621322, "compression_ratio": 1.6733668341708543, "no_speech_prob": 0.0017545776208862662}, {"id": 927, "seek": 438032, "start": 4390.28, "end": 4393.28, "text": " depends on which channels you're referring to, you know.", "tokens": [50862, 5946, 322, 597, 9235, 291, 434, 13761, 281, 11, 291, 458, 13, 51012], "temperature": 0.0, "avg_logprob": -0.2529506074621322, "compression_ratio": 1.6733668341708543, "no_speech_prob": 0.0017545776208862662}, {"id": 928, "seek": 438032, "start": 4393.28, "end": 4400.44, "text": " Because like, the ones which are about like, oh, what color is its ear, as opposed to how", "tokens": [51012, 1436, 411, 11, 264, 2306, 597, 366, 466, 411, 11, 1954, 11, 437, 2017, 307, 1080, 1273, 11, 382, 8851, 281, 577, 51370], "temperature": 0.0, "avg_logprob": -0.2529506074621322, "compression_ratio": 1.6733668341708543, "no_speech_prob": 0.0017545776208862662}, {"id": 929, "seek": 438032, "start": 4400.44, "end": 4407.719999999999, "text": " pointy is its ear, might depend more on like, what, you know, is this bunny in the shade", "tokens": [51370, 935, 88, 307, 1080, 1273, 11, 1062, 5672, 544, 322, 411, 11, 437, 11, 291, 458, 11, 307, 341, 28588, 294, 264, 11466, 51734], "temperature": 0.0, "avg_logprob": -0.2529506074621322, "compression_ratio": 1.6733668341708543, "no_speech_prob": 0.0017545776208862662}, {"id": 930, "seek": 438032, "start": 4407.719999999999, "end": 4409.16, "text": " or in the sun?", "tokens": [51734, 420, 294, 264, 3295, 30, 51806], "temperature": 0.0, "avg_logprob": -0.2529506074621322, "compression_ratio": 1.6733668341708543, "no_speech_prob": 0.0017545776208862662}, {"id": 931, "seek": 440916, "start": 4409.2, "end": 4414.04, "text": " And so maybe, you know, you may want to look at its body over here to decide what color", "tokens": [50366, 400, 370, 1310, 11, 291, 458, 11, 291, 815, 528, 281, 574, 412, 1080, 1772, 670, 510, 281, 4536, 437, 2017, 50608], "temperature": 0.0, "avg_logprob": -0.2835060032931241, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.5071441996260546e-05}, {"id": 932, "seek": 440916, "start": 4414.04, "end": 4418.04, "text": " to make them, rather than how pointy to make it.", "tokens": [50608, 281, 652, 552, 11, 2831, 813, 577, 935, 88, 281, 652, 309, 13, 50808], "temperature": 0.0, "avg_logprob": -0.2835060032931241, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.5071441996260546e-05}, {"id": 933, "seek": 440916, "start": 4418.04, "end": 4427.5199999999995, "text": " And so, yeah, different channels need to bring in information from different parts of the", "tokens": [50808, 400, 370, 11, 1338, 11, 819, 9235, 643, 281, 1565, 294, 1589, 490, 819, 3166, 295, 264, 51282], "temperature": 0.0, "avg_logprob": -0.2835060032931241, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.5071441996260546e-05}, {"id": 934, "seek": 440916, "start": 4427.5199999999995, "end": 4431.4, "text": " picture, depending on which channel we're talking about.", "tokens": [51282, 3036, 11, 5413, 322, 597, 2269, 321, 434, 1417, 466, 13, 51476], "temperature": 0.0, "avg_logprob": -0.2835060032931241, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.5071441996260546e-05}, {"id": 935, "seek": 440916, "start": 4431.4, "end": 4436.5199999999995, "text": " And so the way we do that is with multi-headed attention.", "tokens": [51476, 400, 370, 264, 636, 321, 360, 300, 307, 365, 4825, 12, 28409, 3202, 13, 51732], "temperature": 0.0, "avg_logprob": -0.2835060032931241, "compression_ratio": 1.6161137440758293, "no_speech_prob": 2.5071441996260546e-05}, {"id": 936, "seek": 443652, "start": 4436.52, "end": 4441.120000000001, "text": " And multi-headed attention actually turns out to be really simple.", "tokens": [50364, 400, 4825, 12, 28409, 3202, 767, 4523, 484, 281, 312, 534, 2199, 13, 50594], "temperature": 0.0, "avg_logprob": -0.3167287149736958, "compression_ratio": 1.457516339869281, "no_speech_prob": 7.141841342672706e-05}, {"id": 937, "seek": 443652, "start": 4441.120000000001, "end": 4443.84, "text": " And conceptually, it's also really simple.", "tokens": [50594, 400, 3410, 671, 11, 309, 311, 611, 534, 2199, 13, 50730], "temperature": 0.0, "avg_logprob": -0.3167287149736958, "compression_ratio": 1.457516339869281, "no_speech_prob": 7.141841342672706e-05}, {"id": 938, "seek": 443652, "start": 4443.84, "end": 4455.64, "text": " What we do is we say, let's come back to when we look at C here, and let's split them into", "tokens": [50730, 708, 321, 360, 307, 321, 584, 11, 718, 311, 808, 646, 281, 562, 321, 574, 412, 383, 510, 11, 293, 718, 311, 7472, 552, 666, 51320], "temperature": 0.0, "avg_logprob": -0.3167287149736958, "compression_ratio": 1.457516339869281, "no_speech_prob": 7.141841342672706e-05}, {"id": 939, "seek": 443652, "start": 4455.64, "end": 4461.52, "text": " four separate vectors.", "tokens": [51320, 1451, 4994, 18875, 13, 51614], "temperature": 0.0, "avg_logprob": -0.3167287149736958, "compression_ratio": 1.457516339869281, "no_speech_prob": 7.141841342672706e-05}, {"id": 940, "seek": 446152, "start": 4461.52, "end": 4468.8, "text": " One, two, three, four.", "tokens": [50364, 1485, 11, 732, 11, 1045, 11, 1451, 13, 50728], "temperature": 0.0, "avg_logprob": -0.32645792643229166, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.002889563562348485}, {"id": 941, "seek": 446152, "start": 4468.8, "end": 4469.8, "text": " Let's split them.", "tokens": [50728, 961, 311, 7472, 552, 13, 50778], "temperature": 0.0, "avg_logprob": -0.32645792643229166, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.002889563562348485}, {"id": 942, "seek": 446152, "start": 4469.8, "end": 4470.8, "text": " Right?", "tokens": [50778, 1779, 30, 50828], "temperature": 0.0, "avg_logprob": -0.32645792643229166, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.002889563562348485}, {"id": 943, "seek": 446152, "start": 4470.8, "end": 4482.72, "text": " And let's do the whole, you know, dot product thing on just, you know, his, the first part", "tokens": [50828, 400, 718, 311, 360, 264, 1379, 11, 291, 458, 11, 5893, 1674, 551, 322, 445, 11, 291, 458, 11, 702, 11, 264, 700, 644, 51424], "temperature": 0.0, "avg_logprob": -0.32645792643229166, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.002889563562348485}, {"id": 944, "seek": 446152, "start": 4482.72, "end": 4484.240000000001, "text": " with the first part.", "tokens": [51424, 365, 264, 700, 644, 13, 51500], "temperature": 0.0, "avg_logprob": -0.32645792643229166, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.002889563562348485}, {"id": 945, "seek": 446152, "start": 4484.240000000001, "end": 4490.68, "text": " And then do the whole dot product part with the second part with the second part.", "tokens": [51500, 400, 550, 360, 264, 1379, 5893, 1674, 644, 365, 264, 1150, 644, 365, 264, 1150, 644, 13, 51822], "temperature": 0.0, "avg_logprob": -0.32645792643229166, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.002889563562348485}, {"id": 946, "seek": 449068, "start": 4490.84, "end": 4491.84, "text": " And so forth.", "tokens": [50372, 400, 370, 5220, 13, 50422], "temperature": 0.0, "avg_logprob": -0.22775730405535016, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.649789090966806e-05}, {"id": 947, "seek": 449068, "start": 4491.84, "end": 4492.84, "text": " Right?", "tokens": [50422, 1779, 30, 50472], "temperature": 0.0, "avg_logprob": -0.22775730405535016, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.649789090966806e-05}, {"id": 948, "seek": 449068, "start": 4492.84, "end": 4495.56, "text": " So we're just going to do it separately.", "tokens": [50472, 407, 321, 434, 445, 516, 281, 360, 309, 14759, 13, 50608], "temperature": 0.0, "avg_logprob": -0.22775730405535016, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.649789090966806e-05}, {"id": 949, "seek": 449068, "start": 4495.56, "end": 4502.280000000001, "text": " Separate matrix multipliers for different groups of channels.", "tokens": [50608, 43480, 473, 8141, 12788, 4890, 337, 819, 3935, 295, 9235, 13, 50944], "temperature": 0.0, "avg_logprob": -0.22775730405535016, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.649789090966806e-05}, {"id": 950, "seek": 449068, "start": 4502.280000000001, "end": 4510.400000000001, "text": " And the reason we do that is it then allows, yeah, different parts, different sets of channels", "tokens": [50944, 400, 264, 1778, 321, 360, 300, 307, 309, 550, 4045, 11, 1338, 11, 819, 3166, 11, 819, 6352, 295, 9235, 51350], "temperature": 0.0, "avg_logprob": -0.22775730405535016, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.649789090966806e-05}, {"id": 951, "seek": 449068, "start": 4510.400000000001, "end": 4514.52, "text": " to pull in different parts of the image.", "tokens": [51350, 281, 2235, 294, 819, 3166, 295, 264, 3256, 13, 51556], "temperature": 0.0, "avg_logprob": -0.22775730405535016, "compression_ratio": 1.5987654320987654, "no_speech_prob": 5.649789090966806e-05}, {"id": 952, "seek": 451452, "start": 4514.52, "end": 4524.76, "text": " And so these different groups are called heads.", "tokens": [50364, 400, 370, 613, 819, 3935, 366, 1219, 8050, 13, 50876], "temperature": 0.0, "avg_logprob": -0.3796220430186097, "compression_ratio": 1.417142857142857, "no_speech_prob": 0.025949161499738693}, {"id": 953, "seek": 451452, "start": 4524.76, "end": 4525.76, "text": " And I don't know why.", "tokens": [50876, 400, 286, 500, 380, 458, 983, 13, 50926], "temperature": 0.0, "avg_logprob": -0.3796220430186097, "compression_ratio": 1.417142857142857, "no_speech_prob": 0.025949161499738693}, {"id": 954, "seek": 451452, "start": 4525.76, "end": 4526.76, "text": " But they are.", "tokens": [50926, 583, 436, 366, 13, 50976], "temperature": 0.0, "avg_logprob": -0.3796220430186097, "compression_ratio": 1.417142857142857, "no_speech_prob": 0.025949161499738693}, {"id": 955, "seek": 451452, "start": 4526.76, "end": 4527.76, "text": " Does that seem reasonable?", "tokens": [50976, 4402, 300, 1643, 10585, 30, 51026], "temperature": 0.0, "avg_logprob": -0.3796220430186097, "compression_ratio": 1.417142857142857, "no_speech_prob": 0.025949161499738693}, {"id": 956, "seek": 451452, "start": 4527.76, "end": 4534.320000000001, "text": " Anything to add to that?", "tokens": [51026, 11998, 281, 909, 281, 300, 30, 51354], "temperature": 0.0, "avg_logprob": -0.3796220430186097, "compression_ratio": 1.417142857142857, "no_speech_prob": 0.025949161499738693}, {"id": 957, "seek": 451452, "start": 4534.320000000001, "end": 4540.84, "text": " It's maybe worth thinking about why, with just a single head, specifically the softmax", "tokens": [51354, 467, 311, 1310, 3163, 1953, 466, 983, 11, 365, 445, 257, 2167, 1378, 11, 4682, 264, 2787, 41167, 51680], "temperature": 0.0, "avg_logprob": -0.3796220430186097, "compression_ratio": 1.417142857142857, "no_speech_prob": 0.025949161499738693}, {"id": 958, "seek": 451452, "start": 4540.84, "end": 4543.400000000001, "text": " starts to come into play.", "tokens": [51680, 3719, 281, 808, 666, 862, 13, 51808], "temperature": 0.0, "avg_logprob": -0.3796220430186097, "compression_ratio": 1.417142857142857, "no_speech_prob": 0.025949161499738693}, {"id": 959, "seek": 454340, "start": 4543.4, "end": 4546.92, "text": " Because, you know, we said it's like a weighted sum, so it's able to bring in information", "tokens": [50364, 1436, 11, 291, 458, 11, 321, 848, 309, 311, 411, 257, 32807, 2408, 11, 370, 309, 311, 1075, 281, 1565, 294, 1589, 50540], "temperature": 0.0, "avg_logprob": -0.2955563552980501, "compression_ratio": 1.786231884057971, "no_speech_prob": 0.40669751167297363}, {"id": 960, "seek": 454340, "start": 4546.92, "end": 4549.5199999999995, "text": " from different parts and whatever else.", "tokens": [50540, 490, 819, 3166, 293, 2035, 1646, 13, 50670], "temperature": 0.0, "avg_logprob": -0.2955563552980501, "compression_ratio": 1.786231884057971, "no_speech_prob": 0.40669751167297363}, {"id": 961, "seek": 454340, "start": 4549.5199999999995, "end": 4554.639999999999, "text": " But with softmax, what tends to happen is whatever weight is highest gets scaled up", "tokens": [50670, 583, 365, 2787, 41167, 11, 437, 12258, 281, 1051, 307, 2035, 3364, 307, 6343, 2170, 36039, 493, 50926], "temperature": 0.0, "avg_logprob": -0.2955563552980501, "compression_ratio": 1.786231884057971, "no_speech_prob": 0.40669751167297363}, {"id": 962, "seek": 454340, "start": 4554.639999999999, "end": 4555.639999999999, "text": " quite dramatically.", "tokens": [50926, 1596, 17548, 13, 50976], "temperature": 0.0, "avg_logprob": -0.2955563552980501, "compression_ratio": 1.786231884057971, "no_speech_prob": 0.40669751167297363}, {"id": 963, "seek": 454340, "start": 4555.639999999999, "end": 4560.28, "text": " And so it's like almost like focused on just that one thing.", "tokens": [50976, 400, 370, 309, 311, 411, 1920, 411, 5178, 322, 445, 300, 472, 551, 13, 51208], "temperature": 0.0, "avg_logprob": -0.2955563552980501, "compression_ratio": 1.786231884057971, "no_speech_prob": 0.40669751167297363}, {"id": 964, "seek": 454340, "start": 4560.28, "end": 4563.0, "text": " And then, yeah, like as you said, Jeremy, like different channels might want to refer", "tokens": [51208, 400, 550, 11, 1338, 11, 411, 382, 291, 848, 11, 17809, 11, 411, 819, 9235, 1062, 528, 281, 2864, 51344], "temperature": 0.0, "avg_logprob": -0.2955563552980501, "compression_ratio": 1.786231884057971, "no_speech_prob": 0.40669751167297363}, {"id": 965, "seek": 454340, "start": 4563.0, "end": 4564.0, "text": " to different things.", "tokens": [51344, 281, 819, 721, 13, 51394], "temperature": 0.0, "avg_logprob": -0.2955563552980501, "compression_ratio": 1.786231884057971, "no_speech_prob": 0.40669751167297363}, {"id": 966, "seek": 454340, "start": 4564.0, "end": 4569.5599999999995, "text": " And, you know, just having this one like single weight that's across all the channels means", "tokens": [51394, 400, 11, 291, 458, 11, 445, 1419, 341, 472, 411, 2167, 3364, 300, 311, 2108, 439, 264, 9235, 1355, 51672], "temperature": 0.0, "avg_logprob": -0.2955563552980501, "compression_ratio": 1.786231884057971, "no_speech_prob": 0.40669751167297363}, {"id": 967, "seek": 456956, "start": 4569.56, "end": 4574.400000000001, "text": " that that signal is going to be like focused on maybe only one or two things as opposed", "tokens": [50364, 300, 300, 6358, 307, 516, 281, 312, 411, 5178, 322, 1310, 787, 472, 420, 732, 721, 382, 8851, 50606], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 968, "seek": 456956, "start": 4574.400000000001, "end": 4578.160000000001, "text": " to being able to bring in lots of different kinds of information based on the different", "tokens": [50606, 281, 885, 1075, 281, 1565, 294, 3195, 295, 819, 3685, 295, 1589, 2361, 322, 264, 819, 50794], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 969, "seek": 456956, "start": 4578.160000000001, "end": 4579.160000000001, "text": " channels.", "tokens": [50794, 9235, 13, 50844], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 970, "seek": 456956, "start": 4579.160000000001, "end": 4580.160000000001, "text": " Right.", "tokens": [50844, 1779, 13, 50894], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 971, "seek": 456956, "start": 4580.160000000001, "end": 4581.160000000001, "text": " And you're pointing out...", "tokens": [50894, 400, 291, 434, 12166, 484, 485, 50944], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 972, "seek": 456956, "start": 4581.160000000001, "end": 4585.04, "text": " I was going to mention the same thing, actually.", "tokens": [50944, 286, 390, 516, 281, 2152, 264, 912, 551, 11, 767, 13, 51138], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 973, "seek": 456956, "start": 4585.04, "end": 4586.04, "text": " That's a good point.", "tokens": [51138, 663, 311, 257, 665, 935, 13, 51188], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 974, "seek": 456956, "start": 4586.04, "end": 4590.6, "text": " So you're mentioning the second interesting important point about softmax.", "tokens": [51188, 407, 291, 434, 18315, 264, 1150, 1880, 1021, 935, 466, 2787, 41167, 13, 51416], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 975, "seek": 456956, "start": 4590.6, "end": 4594.360000000001, "text": " You know, point one is that it creates something that adds to one.", "tokens": [51416, 509, 458, 11, 935, 472, 307, 300, 309, 7829, 746, 300, 10860, 281, 472, 13, 51604], "temperature": 0.0, "avg_logprob": -0.3063121410684848, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.341463178396225}, {"id": 976, "seek": 459436, "start": 4594.639999999999, "end": 4602.48, "text": " But point two is that because of its etithers, it tends to highlight one thing very strongly.", "tokens": [50378, 583, 935, 732, 307, 300, 570, 295, 1080, 308, 83, 355, 433, 11, 309, 12258, 281, 5078, 472, 551, 588, 10613, 13, 50770], "temperature": 0.0, "avg_logprob": -0.4089154636158663, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.030673611909151077}, {"id": 977, "seek": 459436, "start": 4602.48, "end": 4607.04, "text": " And yes, so if we had single-headed attention, your point, guys, I guess, is that you're", "tokens": [50770, 400, 2086, 11, 370, 498, 321, 632, 2167, 12, 28409, 3202, 11, 428, 935, 11, 1074, 11, 286, 2041, 11, 307, 300, 291, 434, 50998], "temperature": 0.0, "avg_logprob": -0.4089154636158663, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.030673611909151077}, {"id": 978, "seek": 459436, "start": 4607.04, "end": 4613.839999999999, "text": " saying it would end up basically picking nearly all one pixel, which would not be very interesting.", "tokens": [50998, 1566, 309, 576, 917, 493, 1936, 8867, 6217, 439, 472, 19261, 11, 597, 576, 406, 312, 588, 1880, 13, 51338], "temperature": 0.0, "avg_logprob": -0.4089154636158663, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.030673611909151077}, {"id": 979, "seek": 459436, "start": 4613.839999999999, "end": 4615.36, "text": " Okay, awesome.", "tokens": [51338, 1033, 11, 3476, 13, 51414], "temperature": 0.0, "avg_logprob": -0.4089154636158663, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.030673611909151077}, {"id": 980, "seek": 459436, "start": 4615.36, "end": 4619.679999999999, "text": " Oh, I see why everything's got thick.", "tokens": [51414, 876, 11, 286, 536, 983, 1203, 311, 658, 5060, 13, 51630], "temperature": 0.0, "avg_logprob": -0.4089154636158663, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.030673611909151077}, {"id": 981, "seek": 459436, "start": 4619.679999999999, "end": 4623.36, "text": " I've accidentally turned it into a marker.", "tokens": [51630, 286, 600, 15715, 3574, 309, 666, 257, 15247, 13, 51814], "temperature": 0.0, "avg_logprob": -0.4089154636158663, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.030673611909151077}, {"id": 982, "seek": 462336, "start": 4624.36, "end": 4628.16, "text": " Okay.", "tokens": [50414, 1033, 13, 50604], "temperature": 0.0, "avg_logprob": -0.26053122532220535, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5867104341159575e-05}, {"id": 983, "seek": 462336, "start": 4628.16, "end": 4634.5599999999995, "text": " So multi-headed attention, I'll come back to the details of how it's implemented in", "tokens": [50604, 407, 4825, 12, 28409, 3202, 11, 286, 603, 808, 646, 281, 264, 4365, 295, 577, 309, 311, 12270, 294, 50924], "temperature": 0.0, "avg_logprob": -0.26053122532220535, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5867104341159575e-05}, {"id": 984, "seek": 462336, "start": 4634.5599999999995, "end": 4635.5599999999995, "text": " terms of...", "tokens": [50924, 2115, 295, 485, 50974], "temperature": 0.0, "avg_logprob": -0.26053122532220535, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5867104341159575e-05}, {"id": 985, "seek": 462336, "start": 4635.5599999999995, "end": 4639.179999999999, "text": " But I'm just going to mention the basic idea.", "tokens": [50974, 583, 286, 478, 445, 516, 281, 2152, 264, 3875, 1558, 13, 51155], "temperature": 0.0, "avg_logprob": -0.26053122532220535, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5867104341159575e-05}, {"id": 986, "seek": 462336, "start": 4639.179999999999, "end": 4644.799999999999, "text": " This is multi-headed attention, and this is identical to before, except I've just stored", "tokens": [51155, 639, 307, 4825, 12, 28409, 3202, 11, 293, 341, 307, 14800, 281, 949, 11, 3993, 286, 600, 445, 12187, 51436], "temperature": 0.0, "avg_logprob": -0.26053122532220535, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5867104341159575e-05}, {"id": 987, "seek": 462336, "start": 4644.799999999999, "end": 4651.44, "text": " one more thing, which is how many heads do you want.", "tokens": [51436, 472, 544, 551, 11, 597, 307, 577, 867, 8050, 360, 291, 528, 13, 51768], "temperature": 0.0, "avg_logprob": -0.26053122532220535, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.5867104341159575e-05}, {"id": 988, "seek": 465144, "start": 4651.5199999999995, "end": 4654.5599999999995, "text": " And then the forward is actually nearly all the same.", "tokens": [50368, 400, 550, 264, 2128, 307, 767, 6217, 439, 264, 912, 13, 50520], "temperature": 0.0, "avg_logprob": -0.31917231010668207, "compression_ratio": 1.8385416666666667, "no_speech_prob": 2.710871740418952e-05}, {"id": 989, "seek": 465144, "start": 4654.5599999999995, "end": 4658.599999999999, "text": " So this is identical, identical, identical.", "tokens": [50520, 407, 341, 307, 14800, 11, 14800, 11, 14800, 13, 50722], "temperature": 0.0, "avg_logprob": -0.31917231010668207, "compression_ratio": 1.8385416666666667, "no_speech_prob": 2.710871740418952e-05}, {"id": 990, "seek": 465144, "start": 4658.599999999999, "end": 4659.599999999999, "text": " This is new.", "tokens": [50722, 639, 307, 777, 13, 50772], "temperature": 0.0, "avg_logprob": -0.31917231010668207, "compression_ratio": 1.8385416666666667, "no_speech_prob": 2.710871740418952e-05}, {"id": 991, "seek": 465144, "start": 4659.599999999999, "end": 4665.599999999999, "text": " Identical, identical, identical, new.", "tokens": [50772, 25905, 804, 11, 14800, 11, 14800, 11, 777, 13, 51072], "temperature": 0.0, "avg_logprob": -0.31917231010668207, "compression_ratio": 1.8385416666666667, "no_speech_prob": 2.710871740418952e-05}, {"id": 992, "seek": 465144, "start": 4665.599999999999, "end": 4667.46, "text": " Identical, identical.", "tokens": [51072, 25905, 804, 11, 14800, 13, 51165], "temperature": 0.0, "avg_logprob": -0.31917231010668207, "compression_ratio": 1.8385416666666667, "no_speech_prob": 2.710871740418952e-05}, {"id": 993, "seek": 465144, "start": 4667.46, "end": 4672.28, "text": " So there's just two new lines of code, which might be surprising, but that's all we needed", "tokens": [51165, 407, 456, 311, 445, 732, 777, 3876, 295, 3089, 11, 597, 1062, 312, 8830, 11, 457, 300, 311, 439, 321, 2978, 51406], "temperature": 0.0, "avg_logprob": -0.31917231010668207, "compression_ratio": 1.8385416666666667, "no_speech_prob": 2.710871740418952e-05}, {"id": 994, "seek": 465144, "start": 4672.28, "end": 4674.04, "text": " to make this work.", "tokens": [51406, 281, 652, 341, 589, 13, 51494], "temperature": 0.0, "avg_logprob": -0.31917231010668207, "compression_ratio": 1.8385416666666667, "no_speech_prob": 2.710871740418952e-05}, {"id": 995, "seek": 465144, "start": 4674.04, "end": 4678.28, "text": " And they're also pretty wacky, interesting new lines of code to look at.", "tokens": [51494, 400, 436, 434, 611, 1238, 42138, 88, 11, 1880, 777, 3876, 295, 3089, 281, 574, 412, 13, 51706], "temperature": 0.0, "avg_logprob": -0.31917231010668207, "compression_ratio": 1.8385416666666667, "no_speech_prob": 2.710871740418952e-05}, {"id": 996, "seek": 467828, "start": 4678.28, "end": 4686.4, "text": " Basically what these two lines of code do is they, first they do the projection, right?", "tokens": [50364, 8537, 437, 613, 732, 3876, 295, 3089, 360, 307, 436, 11, 700, 436, 360, 264, 22743, 11, 558, 30, 50770], "temperature": 0.0, "avg_logprob": -0.35721143995012555, "compression_ratio": 1.5393939393939393, "no_speech_prob": 0.003945311065763235}, {"id": 997, "seek": 467828, "start": 4686.4, "end": 4702.24, "text": " And then, they basically take the number of heads.", "tokens": [50770, 400, 550, 11, 436, 1936, 747, 264, 1230, 295, 8050, 13, 51562], "temperature": 0.0, "avg_logprob": -0.35721143995012555, "compression_ratio": 1.5393939393939393, "no_speech_prob": 0.003945311065763235}, {"id": 998, "seek": 467828, "start": 4702.24, "end": 4703.599999999999, "text": " So we're going to do four heads.", "tokens": [51562, 407, 321, 434, 516, 281, 360, 1451, 8050, 13, 51630], "temperature": 0.0, "avg_logprob": -0.35721143995012555, "compression_ratio": 1.5393939393939393, "no_speech_prob": 0.003945311065763235}, {"id": 999, "seek": 467828, "start": 4703.599999999999, "end": 4705.2, "text": " We've got 32 channels, four heads.", "tokens": [51630, 492, 600, 658, 8858, 9235, 11, 1451, 8050, 13, 51710], "temperature": 0.0, "avg_logprob": -0.35721143995012555, "compression_ratio": 1.5393939393939393, "no_speech_prob": 0.003945311065763235}, {"id": 1000, "seek": 467828, "start": 4705.2, "end": 4708.04, "text": " So each head's going to contain eight channels.", "tokens": [51710, 407, 1184, 1378, 311, 516, 281, 5304, 3180, 9235, 13, 51852], "temperature": 0.0, "avg_logprob": -0.35721143995012555, "compression_ratio": 1.5393939393939393, "no_speech_prob": 0.003945311065763235}, {"id": 1001, "seek": 470804, "start": 4708.08, "end": 4713.56, "text": " And they basically grab...", "tokens": [50366, 400, 436, 1936, 4444, 485, 50640], "temperature": 0.0, "avg_logprob": -0.300413017842307, "compression_ratio": 1.456140350877193, "no_speech_prob": 1.34199763124343e-05}, {"id": 1002, "seek": 470804, "start": 4713.56, "end": 4717.6, "text": " We're going to keep it as being eight channels, not as 32 channels.", "tokens": [50640, 492, 434, 516, 281, 1066, 309, 382, 885, 3180, 9235, 11, 406, 382, 8858, 9235, 13, 50842], "temperature": 0.0, "avg_logprob": -0.300413017842307, "compression_ratio": 1.456140350877193, "no_speech_prob": 1.34199763124343e-05}, {"id": 1003, "seek": 470804, "start": 4717.6, "end": 4722.28, "text": " And we're going to make each batch four times bigger, right?", "tokens": [50842, 400, 321, 434, 516, 281, 652, 1184, 15245, 1451, 1413, 3801, 11, 558, 30, 51076], "temperature": 0.0, "avg_logprob": -0.300413017842307, "compression_ratio": 1.456140350877193, "no_speech_prob": 1.34199763124343e-05}, {"id": 1004, "seek": 470804, "start": 4722.28, "end": 4728.76, "text": " Because the images in a batch don't combine with each other at all.", "tokens": [51076, 1436, 264, 5267, 294, 257, 15245, 500, 380, 10432, 365, 1184, 661, 412, 439, 13, 51400], "temperature": 0.0, "avg_logprob": -0.300413017842307, "compression_ratio": 1.456140350877193, "no_speech_prob": 1.34199763124343e-05}, {"id": 1005, "seek": 470804, "start": 4728.76, "end": 4730.4, "text": " They're totally separate.", "tokens": [51400, 814, 434, 3879, 4994, 13, 51482], "temperature": 0.0, "avg_logprob": -0.300413017842307, "compression_ratio": 1.456140350877193, "no_speech_prob": 1.34199763124343e-05}, {"id": 1006, "seek": 473040, "start": 4730.4, "end": 4739.36, "text": " So instead of having one image containing 32 channels, we're going to turn that into", "tokens": [50364, 407, 2602, 295, 1419, 472, 3256, 19273, 8858, 9235, 11, 321, 434, 516, 281, 1261, 300, 666, 50812], "temperature": 0.0, "avg_logprob": -0.2257769266764323, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.003707010531798005}, {"id": 1007, "seek": 473040, "start": 4739.36, "end": 4744.04, "text": " four images containing eight channels.", "tokens": [50812, 1451, 5267, 19273, 3180, 9235, 13, 51046], "temperature": 0.0, "avg_logprob": -0.2257769266764323, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.003707010531798005}, {"id": 1008, "seek": 473040, "start": 4744.04, "end": 4745.839999999999, "text": " And that's actually all we need, right?", "tokens": [51046, 400, 300, 311, 767, 439, 321, 643, 11, 558, 30, 51136], "temperature": 0.0, "avg_logprob": -0.2257769266764323, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.003707010531798005}, {"id": 1009, "seek": 473040, "start": 4745.839999999999, "end": 4752.32, "text": " Because remember I told you that each group of channels, each head, we want to have nothing", "tokens": [51136, 1436, 1604, 286, 1907, 291, 300, 1184, 1594, 295, 9235, 11, 1184, 1378, 11, 321, 528, 281, 362, 1825, 51460], "temperature": 0.0, "avg_logprob": -0.2257769266764323, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.003707010531798005}, {"id": 1010, "seek": 473040, "start": 4752.32, "end": 4754.0599999999995, "text": " to do with each other.", "tokens": [51460, 281, 360, 365, 1184, 661, 13, 51547], "temperature": 0.0, "avg_logprob": -0.2257769266764323, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.003707010531798005}, {"id": 1011, "seek": 473040, "start": 4754.0599999999995, "end": 4758.839999999999, "text": " So if we literally turn them into different images, then they can't have anything to do", "tokens": [51547, 407, 498, 321, 3736, 1261, 552, 666, 819, 5267, 11, 550, 436, 393, 380, 362, 1340, 281, 360, 51786], "temperature": 0.0, "avg_logprob": -0.2257769266764323, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.003707010531798005}, {"id": 1012, "seek": 475884, "start": 4758.84, "end": 4759.84, "text": " with each other.", "tokens": [50364, 365, 1184, 661, 13, 50414], "temperature": 0.0, "avg_logprob": -0.30661062176307935, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.001838651136495173}, {"id": 1013, "seek": 475884, "start": 4759.84, "end": 4764.360000000001, "text": " Because batches don't react to each other at all.", "tokens": [50414, 1436, 15245, 279, 500, 380, 4515, 281, 1184, 661, 412, 439, 13, 50640], "temperature": 0.0, "avg_logprob": -0.30661062176307935, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.001838651136495173}, {"id": 1014, "seek": 475884, "start": 4764.360000000001, "end": 4769.32, "text": " So this rearrange, and I'll explain how this works in a moment.", "tokens": [50640, 407, 341, 39568, 11, 293, 286, 603, 2903, 577, 341, 1985, 294, 257, 1623, 13, 50888], "temperature": 0.0, "avg_logprob": -0.30661062176307935, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.001838651136495173}, {"id": 1015, "seek": 475884, "start": 4769.32, "end": 4779.04, "text": " But it's basically saying, think of the channel dimension as being of H groups of D, and rearrange", "tokens": [50888, 583, 309, 311, 1936, 1566, 11, 519, 295, 264, 2269, 10139, 382, 885, 295, 389, 3935, 295, 413, 11, 293, 39568, 51374], "temperature": 0.0, "avg_logprob": -0.30661062176307935, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.001838651136495173}, {"id": 1016, "seek": 475884, "start": 4779.04, "end": 4780.04, "text": " it.", "tokens": [51374, 309, 13, 51424], "temperature": 0.0, "avg_logprob": -0.30661062176307935, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.001838651136495173}, {"id": 1017, "seek": 475884, "start": 4780.04, "end": 4786.2, "text": " So instead the batch channel is N groups of H. And the channels is now just D. So that", "tokens": [51424, 407, 2602, 264, 15245, 2269, 307, 426, 3935, 295, 389, 13, 400, 264, 9235, 307, 586, 445, 413, 13, 407, 300, 51732], "temperature": 0.0, "avg_logprob": -0.30661062176307935, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.001838651136495173}, {"id": 1018, "seek": 478620, "start": 4786.2, "end": 4790.74, "text": " would be eight, instead of four by eight.", "tokens": [50364, 576, 312, 3180, 11, 2602, 295, 1451, 538, 3180, 13, 50591], "temperature": 0.0, "avg_logprob": -0.26294965403420584, "compression_ratio": 1.6707818930041152, "no_speech_prob": 0.0035935421474277973}, {"id": 1019, "seek": 478620, "start": 4790.74, "end": 4794.7, "text": " And then we do everything else exactly the same way as usual.", "tokens": [50591, 400, 550, 321, 360, 1203, 1646, 2293, 264, 912, 636, 382, 7713, 13, 50789], "temperature": 0.0, "avg_logprob": -0.26294965403420584, "compression_ratio": 1.6707818930041152, "no_speech_prob": 0.0035935421474277973}, {"id": 1020, "seek": 478620, "start": 4794.7, "end": 4800.74, "text": " But now that group, that the channels have been split into groups of H, groups of four.", "tokens": [50789, 583, 586, 300, 1594, 11, 300, 264, 9235, 362, 668, 7472, 666, 3935, 295, 389, 11, 3935, 295, 1451, 13, 51091], "temperature": 0.0, "avg_logprob": -0.26294965403420584, "compression_ratio": 1.6707818930041152, "no_speech_prob": 0.0035935421474277973}, {"id": 1021, "seek": 478620, "start": 4800.74, "end": 4806.58, "text": " And then after that, okay, well, we were thinking of the batches as being of size N by H. Let's", "tokens": [51091, 400, 550, 934, 300, 11, 1392, 11, 731, 11, 321, 645, 1953, 295, 264, 15245, 279, 382, 885, 295, 2744, 426, 538, 389, 13, 961, 311, 51383], "temperature": 0.0, "avg_logprob": -0.26294965403420584, "compression_ratio": 1.6707818930041152, "no_speech_prob": 0.0035935421474277973}, {"id": 1022, "seek": 478620, "start": 4806.58, "end": 4811.639999999999, "text": " now think of the channels as being of size H by D. That's what these rearrangers do.", "tokens": [51383, 586, 519, 295, 264, 9235, 382, 885, 295, 2744, 389, 538, 413, 13, 663, 311, 437, 613, 29875, 11186, 360, 13, 51636], "temperature": 0.0, "avg_logprob": -0.26294965403420584, "compression_ratio": 1.6707818930041152, "no_speech_prob": 0.0035935421474277973}, {"id": 1023, "seek": 478620, "start": 4811.639999999999, "end": 4815.5199999999995, "text": " So let me explain how these work.", "tokens": [51636, 407, 718, 385, 2903, 577, 613, 589, 13, 51830], "temperature": 0.0, "avg_logprob": -0.26294965403420584, "compression_ratio": 1.6707818930041152, "no_speech_prob": 0.0035935421474277973}, {"id": 1024, "seek": 481552, "start": 4815.540000000001, "end": 4822.88, "text": " In the diffuser's code, I've, can't remember if I duplicated it or just inspired by it.", "tokens": [50365, 682, 264, 7593, 18088, 311, 3089, 11, 286, 600, 11, 393, 380, 1604, 498, 286, 1581, 564, 3587, 309, 420, 445, 7547, 538, 309, 13, 50732], "temperature": 0.0, "avg_logprob": -0.3187976365678766, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.0953101082122885e-05}, {"id": 1025, "seek": 481552, "start": 4822.88, "end": 4827.660000000001, "text": " They've got things called heads to batch and batch to heads, which do exactly these things.", "tokens": [50732, 814, 600, 658, 721, 1219, 8050, 281, 15245, 293, 15245, 281, 8050, 11, 597, 360, 2293, 613, 721, 13, 50971], "temperature": 0.0, "avg_logprob": -0.3187976365678766, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.0953101082122885e-05}, {"id": 1026, "seek": 481552, "start": 4827.660000000001, "end": 4838.52, "text": " And so for heads to batch, they say, okay, you've got 64 per batch by 256 pixels by 32", "tokens": [50971, 400, 370, 337, 8050, 281, 15245, 11, 436, 584, 11, 1392, 11, 291, 600, 658, 12145, 680, 15245, 538, 38882, 18668, 538, 8858, 51514], "temperature": 0.0, "avg_logprob": -0.3187976365678766, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.0953101082122885e-05}, {"id": 1027, "seek": 481552, "start": 4838.52, "end": 4839.52, "text": " channels.", "tokens": [51514, 9235, 13, 51564], "temperature": 0.0, "avg_logprob": -0.3187976365678766, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.0953101082122885e-05}, {"id": 1028, "seek": 481552, "start": 4839.52, "end": 4843.8, "text": " Okay, let's reshape it.", "tokens": [51564, 1033, 11, 718, 311, 725, 42406, 309, 13, 51778], "temperature": 0.0, "avg_logprob": -0.3187976365678766, "compression_ratio": 1.4851485148514851, "no_speech_prob": 1.0953101082122885e-05}, {"id": 1029, "seek": 484380, "start": 4843.8, "end": 4856.02, "text": " So you've got 64 images by 256 pixels by four heads by the rest.", "tokens": [50364, 407, 291, 600, 658, 12145, 5267, 538, 38882, 18668, 538, 1451, 8050, 538, 264, 1472, 13, 50975], "temperature": 0.0, "avg_logprob": -0.23710443756797098, "compression_ratio": 1.2416666666666667, "no_speech_prob": 0.0001233934744959697}, {"id": 1030, "seek": 484380, "start": 4856.02, "end": 4866.4800000000005, "text": " So that would be 32 over 8 channels.", "tokens": [50975, 407, 300, 576, 312, 8858, 670, 1649, 9235, 13, 51498], "temperature": 0.0, "avg_logprob": -0.23710443756797098, "compression_ratio": 1.2416666666666667, "no_speech_prob": 0.0001233934744959697}, {"id": 1031, "seek": 484380, "start": 4866.4800000000005, "end": 4870.22, "text": " So it's split it out into a separate dimension.", "tokens": [51498, 407, 309, 311, 7472, 309, 484, 666, 257, 4994, 10139, 13, 51685], "temperature": 0.0, "avg_logprob": -0.23710443756797098, "compression_ratio": 1.2416666666666667, "no_speech_prob": 0.0001233934744959697}, {"id": 1032, "seek": 487022, "start": 4870.22, "end": 4876.860000000001, "text": " And then if we transpose these two dimensions, it'll then be N by 4.", "tokens": [50364, 400, 550, 498, 321, 25167, 613, 732, 12819, 11, 309, 603, 550, 312, 426, 538, 1017, 13, 50696], "temperature": 0.0, "avg_logprob": -0.2623255436237042, "compression_ratio": 1.7623762376237624, "no_speech_prob": 0.00033534629619680345}, {"id": 1033, "seek": 487022, "start": 4876.860000000001, "end": 4879.76, "text": " So N by heads by SL by minus 1.", "tokens": [50696, 407, 426, 538, 8050, 538, 22999, 538, 3175, 502, 13, 50841], "temperature": 0.0, "avg_logprob": -0.2623255436237042, "compression_ratio": 1.7623762376237624, "no_speech_prob": 0.00033534629619680345}, {"id": 1034, "seek": 487022, "start": 4879.76, "end": 4881.9800000000005, "text": " And so then we can reshape.", "tokens": [50841, 400, 370, 550, 321, 393, 725, 42406, 13, 50952], "temperature": 0.0, "avg_logprob": -0.2623255436237042, "compression_ratio": 1.7623762376237624, "no_speech_prob": 0.00033534629619680345}, {"id": 1035, "seek": 487022, "start": 4881.9800000000005, "end": 4885.5, "text": " So those first two dimensions get combined into one.", "tokens": [50952, 407, 729, 700, 732, 12819, 483, 9354, 666, 472, 13, 51128], "temperature": 0.0, "avg_logprob": -0.2623255436237042, "compression_ratio": 1.7623762376237624, "no_speech_prob": 0.00033534629619680345}, {"id": 1036, "seek": 487022, "start": 4885.5, "end": 4887.54, "text": " So that's what heads to batch does.", "tokens": [51128, 407, 300, 311, 437, 8050, 281, 15245, 775, 13, 51230], "temperature": 0.0, "avg_logprob": -0.2623255436237042, "compression_ratio": 1.7623762376237624, "no_speech_prob": 0.00033534629619680345}, {"id": 1037, "seek": 487022, "start": 4887.54, "end": 4890.8, "text": " And batch to heads does the exact opposite, right?", "tokens": [51230, 400, 15245, 281, 8050, 775, 264, 1900, 6182, 11, 558, 30, 51393], "temperature": 0.0, "avg_logprob": -0.2623255436237042, "compression_ratio": 1.7623762376237624, "no_speech_prob": 0.00033534629619680345}, {"id": 1038, "seek": 487022, "start": 4890.8, "end": 4895.88, "text": " Reshapes to bring the batch back to here, and then heads by SL by D, and then transpose", "tokens": [51393, 5015, 71, 569, 279, 281, 1565, 264, 15245, 646, 281, 510, 11, 293, 550, 8050, 538, 22999, 538, 413, 11, 293, 550, 25167, 51647], "temperature": 0.0, "avg_logprob": -0.2623255436237042, "compression_ratio": 1.7623762376237624, "no_speech_prob": 0.00033534629619680345}, {"id": 1039, "seek": 489588, "start": 4895.88, "end": 4902.08, "text": " it back again and reshape it back again so that the heads gets it.", "tokens": [50364, 309, 646, 797, 293, 725, 42406, 309, 646, 797, 370, 300, 264, 8050, 2170, 309, 13, 50674], "temperature": 0.0, "avg_logprob": -0.289021466229413, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.005553534720093012}, {"id": 1040, "seek": 489588, "start": 4902.08, "end": 4908.52, "text": " So this is kind of how to do it using just traditional PyTorch methods that we've seen", "tokens": [50674, 407, 341, 307, 733, 295, 577, 281, 360, 309, 1228, 445, 5164, 9953, 51, 284, 339, 7150, 300, 321, 600, 1612, 50996], "temperature": 0.0, "avg_logprob": -0.289021466229413, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.005553534720093012}, {"id": 1041, "seek": 489588, "start": 4908.52, "end": 4909.52, "text": " before.", "tokens": [50996, 949, 13, 51046], "temperature": 0.0, "avg_logprob": -0.289021466229413, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.005553534720093012}, {"id": 1042, "seek": 489588, "start": 4909.52, "end": 4916.4800000000005, "text": " But I wanted to show you guys this new-ish library called INOPS, inspired, as it suggests,", "tokens": [51046, 583, 286, 1415, 281, 855, 291, 1074, 341, 777, 12, 742, 6405, 1219, 6892, 46, 6273, 11, 7547, 11, 382, 309, 13409, 11, 51394], "temperature": 0.0, "avg_logprob": -0.289021466229413, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.005553534720093012}, {"id": 1043, "seek": 489588, "start": 4916.4800000000005, "end": 4918.24, "text": " by Einstein summation notation.", "tokens": [51394, 538, 23486, 28811, 24657, 13, 51482], "temperature": 0.0, "avg_logprob": -0.289021466229413, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.005553534720093012}, {"id": 1044, "seek": 489588, "start": 4918.24, "end": 4920.4800000000005, "text": " But it's absolutely not Einstein summation notation.", "tokens": [51482, 583, 309, 311, 3122, 406, 23486, 28811, 24657, 13, 51594], "temperature": 0.0, "avg_logprob": -0.289021466229413, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.005553534720093012}, {"id": 1045, "seek": 489588, "start": 4920.4800000000005, "end": 4921.4800000000005, "text": " It's something different.", "tokens": [51594, 467, 311, 746, 819, 13, 51644], "temperature": 0.0, "avg_logprob": -0.289021466229413, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.005553534720093012}, {"id": 1046, "seek": 489588, "start": 4921.4800000000005, "end": 4925.04, "text": " And the main thing it has is this thing called rearrange.", "tokens": [51644, 400, 264, 2135, 551, 309, 575, 307, 341, 551, 1219, 39568, 13, 51822], "temperature": 0.0, "avg_logprob": -0.289021466229413, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.005553534720093012}, {"id": 1047, "seek": 492504, "start": 4925.2, "end": 4933.76, "text": " And rearrange is kind of like a nifty rethinking of Einstein summation notation as a tensor", "tokens": [50372, 400, 39568, 307, 733, 295, 411, 257, 297, 37177, 319, 39873, 295, 23486, 28811, 24657, 382, 257, 40863, 50800], "temperature": 0.0, "avg_logprob": -0.2788440431867327, "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.0002959559205919504}, {"id": 1048, "seek": 492504, "start": 4933.76, "end": 4936.84, "text": " rearrangement notation.", "tokens": [50800, 39568, 518, 24657, 13, 50954], "temperature": 0.0, "avg_logprob": -0.2788440431867327, "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.0002959559205919504}, {"id": 1049, "seek": 492504, "start": 4936.84, "end": 4945.2, "text": " And so we've got a tensor called T, we created earlier, 64 by 256 by 32.", "tokens": [50954, 400, 370, 321, 600, 658, 257, 40863, 1219, 314, 11, 321, 2942, 3071, 11, 12145, 538, 38882, 538, 8858, 13, 51372], "temperature": 0.0, "avg_logprob": -0.2788440431867327, "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.0002959559205919504}, {"id": 1050, "seek": 492504, "start": 4945.2, "end": 4952.24, "text": " And what INOPS rearrange does is you pass it this specification string that says, turn", "tokens": [51372, 400, 437, 6892, 46, 6273, 39568, 775, 307, 291, 1320, 309, 341, 31256, 6798, 300, 1619, 11, 1261, 51724], "temperature": 0.0, "avg_logprob": -0.2788440431867327, "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.0002959559205919504}, {"id": 1051, "seek": 495224, "start": 4952.24, "end": 4957.12, "text": " this into this.", "tokens": [50364, 341, 666, 341, 13, 50608], "temperature": 0.0, "avg_logprob": -0.3860365902936017, "compression_ratio": 1.6260162601626016, "no_speech_prob": 0.0002034253702731803}, {"id": 1052, "seek": 495224, "start": 4957.12, "end": 4959.32, "text": " Okay.", "tokens": [50608, 1033, 13, 50718], "temperature": 0.0, "avg_logprob": -0.3860365902936017, "compression_ratio": 1.6260162601626016, "no_speech_prob": 0.0002034253702731803}, {"id": 1053, "seek": 495224, "start": 4959.32, "end": 4970.84, "text": " This says that I have a rank 3 tensor, three dimensions, three axes, containing the first", "tokens": [50718, 639, 1619, 300, 286, 362, 257, 6181, 805, 40863, 11, 1045, 12819, 11, 1045, 35387, 11, 19273, 264, 700, 51294], "temperature": 0.0, "avg_logprob": -0.3860365902936017, "compression_ratio": 1.6260162601626016, "no_speech_prob": 0.0002034253702731803}, {"id": 1054, "seek": 495224, "start": 4970.84, "end": 4978.84, "text": " dimension is of length n, the second dimension is of length s, the third dimension is in", "tokens": [51294, 10139, 307, 295, 4641, 297, 11, 264, 1150, 10139, 307, 295, 4641, 262, 11, 264, 2636, 10139, 307, 294, 51694], "temperature": 0.0, "avg_logprob": -0.3860365902936017, "compression_ratio": 1.6260162601626016, "no_speech_prob": 0.0002034253702731803}, {"id": 1055, "seek": 497884, "start": 4978.84, "end": 4987.6, "text": " parentheses is of length h times d, where h is 8.", "tokens": [50364, 34153, 307, 295, 4641, 276, 1413, 274, 11, 689, 276, 307, 1649, 13, 50802], "temperature": 0.0, "avg_logprob": -0.31090612411499025, "compression_ratio": 1.4367088607594938, "no_speech_prob": 0.000646189961116761}, {"id": 1056, "seek": 497884, "start": 4987.6, "end": 4994.4400000000005, "text": " And then I want you to just move things around so that nothing is, like, broken, you know,", "tokens": [50802, 400, 550, 286, 528, 291, 281, 445, 1286, 721, 926, 370, 300, 1825, 307, 11, 411, 11, 5463, 11, 291, 458, 11, 51144], "temperature": 0.0, "avg_logprob": -0.31090612411499025, "compression_ratio": 1.4367088607594938, "no_speech_prob": 0.000646189961116761}, {"id": 1057, "seek": 497884, "start": 4994.4400000000005, "end": 5003.12, "text": " so everything's shifted correctly into the right spots, so that we now have each batch", "tokens": [51144, 370, 1203, 311, 18892, 8944, 666, 264, 558, 10681, 11, 370, 300, 321, 586, 362, 1184, 15245, 51578], "temperature": 0.0, "avg_logprob": -0.31090612411499025, "compression_ratio": 1.4367088607594938, "no_speech_prob": 0.000646189961116761}, {"id": 1058, "seek": 500312, "start": 5003.12, "end": 5008.599999999999, "text": " is now instead n times 8, n times h.", "tokens": [50364, 307, 586, 2602, 297, 1413, 1649, 11, 297, 1413, 276, 13, 50638], "temperature": 0.0, "avg_logprob": -0.2667522619266321, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.006589679047465324}, {"id": 1059, "seek": 500312, "start": 5008.599999999999, "end": 5011.92, "text": " The sequence length is the same.", "tokens": [50638, 440, 8310, 4641, 307, 264, 912, 13, 50804], "temperature": 0.0, "avg_logprob": -0.2667522619266321, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.006589679047465324}, {"id": 1060, "seek": 500312, "start": 5011.92, "end": 5014.0, "text": " And d is now the number of channels.", "tokens": [50804, 400, 274, 307, 586, 264, 1230, 295, 9235, 13, 50908], "temperature": 0.0, "avg_logprob": -0.2667522619266321, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.006589679047465324}, {"id": 1061, "seek": 500312, "start": 5014.0, "end": 5015.92, "text": " Previously the number of channels was h by d.", "tokens": [50908, 33606, 264, 1230, 295, 9235, 390, 276, 538, 274, 13, 51004], "temperature": 0.0, "avg_logprob": -0.2667522619266321, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.006589679047465324}, {"id": 1062, "seek": 500312, "start": 5015.92, "end": 5016.92, "text": " Now it's d.", "tokens": [51004, 823, 309, 311, 274, 13, 51054], "temperature": 0.0, "avg_logprob": -0.2667522619266321, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.006589679047465324}, {"id": 1063, "seek": 500312, "start": 5016.92, "end": 5019.96, "text": " So the number of channels has been reduced by a factor of 8.", "tokens": [51054, 407, 264, 1230, 295, 9235, 575, 668, 9212, 538, 257, 5952, 295, 1649, 13, 51206], "temperature": 0.0, "avg_logprob": -0.2667522619266321, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.006589679047465324}, {"id": 1064, "seek": 500312, "start": 5019.96, "end": 5020.96, "text": " And you can see it here.", "tokens": [51206, 400, 291, 393, 536, 309, 510, 13, 51256], "temperature": 0.0, "avg_logprob": -0.2667522619266321, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.006589679047465324}, {"id": 1065, "seek": 500312, "start": 5020.96, "end": 5029.64, "text": " It's turned T from something of 64 by 256 by 32 into something of size 64 times 8 by", "tokens": [51256, 467, 311, 3574, 314, 490, 746, 295, 12145, 538, 38882, 538, 8858, 666, 746, 295, 2744, 12145, 1413, 1649, 538, 51690], "temperature": 0.0, "avg_logprob": -0.2667522619266321, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.006589679047465324}, {"id": 1066, "seek": 502964, "start": 5029.64, "end": 5034.72, "text": " 256 by 32 divided by 8.", "tokens": [50364, 38882, 538, 8858, 6666, 538, 1649, 13, 50618], "temperature": 0.0, "avg_logprob": -0.27589863538742065, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.002251792699098587}, {"id": 1067, "seek": 502964, "start": 5034.72, "end": 5042.64, "text": " And so this is, like, really nice, because, you know, a, this one line of code to me is", "tokens": [50618, 400, 370, 341, 307, 11, 411, 11, 534, 1481, 11, 570, 11, 291, 458, 11, 257, 11, 341, 472, 1622, 295, 3089, 281, 385, 307, 51014], "temperature": 0.0, "avg_logprob": -0.27589863538742065, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.002251792699098587}, {"id": 1068, "seek": 502964, "start": 5042.64, "end": 5047.92, "text": " clearer and easier, and I like writing it better than these lines of code.", "tokens": [51014, 26131, 293, 3571, 11, 293, 286, 411, 3579, 309, 1101, 813, 613, 3876, 295, 3089, 13, 51278], "temperature": 0.0, "avg_logprob": -0.27589863538742065, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.002251792699098587}, {"id": 1069, "seek": 502964, "start": 5047.92, "end": 5051.96, "text": " But where it's particularly nice is when I had to go the opposite direction.", "tokens": [51278, 583, 689, 309, 311, 4098, 1481, 307, 562, 286, 632, 281, 352, 264, 6182, 3513, 13, 51480], "temperature": 0.0, "avg_logprob": -0.27589863538742065, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.002251792699098587}, {"id": 1070, "seek": 502964, "start": 5051.96, "end": 5057.92, "text": " I literally took this, cut it, put it here, and put the arrow in the middle.", "tokens": [51480, 286, 3736, 1890, 341, 11, 1723, 309, 11, 829, 309, 510, 11, 293, 829, 264, 11610, 294, 264, 2808, 13, 51778], "temperature": 0.0, "avg_logprob": -0.27589863538742065, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.002251792699098587}, {"id": 1071, "seek": 505792, "start": 5058.2, "end": 5061.24, "text": " Like, it's literally backwards.", "tokens": [50378, 1743, 11, 309, 311, 3736, 12204, 13, 50530], "temperature": 0.0, "avg_logprob": -0.292928148024153, "compression_ratio": 1.6531531531531531, "no_speech_prob": 9.314587077824399e-05}, {"id": 1072, "seek": 505792, "start": 5061.24, "end": 5062.24, "text": " Which is really nice, right?", "tokens": [50530, 3013, 307, 534, 1481, 11, 558, 30, 50580], "temperature": 0.0, "avg_logprob": -0.292928148024153, "compression_ratio": 1.6531531531531531, "no_speech_prob": 9.314587077824399e-05}, {"id": 1073, "seek": 505792, "start": 5062.24, "end": 5066.04, "text": " Because we're just rearranging it in the other order.", "tokens": [50580, 1436, 321, 434, 445, 29875, 9741, 309, 294, 264, 661, 1668, 13, 50770], "temperature": 0.0, "avg_logprob": -0.292928148024153, "compression_ratio": 1.6531531531531531, "no_speech_prob": 9.314587077824399e-05}, {"id": 1074, "seek": 505792, "start": 5066.04, "end": 5070.28, "text": " And so if we rearrange it in the other order, we take our 512 by 256 by 4 thing that we", "tokens": [50770, 400, 370, 498, 321, 39568, 309, 294, 264, 661, 1668, 11, 321, 747, 527, 1025, 4762, 538, 38882, 538, 1017, 551, 300, 321, 50982], "temperature": 0.0, "avg_logprob": -0.292928148024153, "compression_ratio": 1.6531531531531531, "no_speech_prob": 9.314587077824399e-05}, {"id": 1075, "seek": 505792, "start": 5070.28, "end": 5077.0, "text": " just created, and end up with a 64 by 256 by 32 thing, which we started with, and we", "tokens": [50982, 445, 2942, 11, 293, 917, 493, 365, 257, 12145, 538, 38882, 538, 8858, 551, 11, 597, 321, 1409, 365, 11, 293, 321, 51318], "temperature": 0.0, "avg_logprob": -0.292928148024153, "compression_ratio": 1.6531531531531531, "no_speech_prob": 9.314587077824399e-05}, {"id": 1076, "seek": 505792, "start": 5077.0, "end": 5083.08, "text": " can confirm that the end thing equals, or every element equals the first thing.", "tokens": [51318, 393, 9064, 300, 264, 917, 551, 6915, 11, 420, 633, 4478, 6915, 264, 700, 551, 13, 51622], "temperature": 0.0, "avg_logprob": -0.292928148024153, "compression_ratio": 1.6531531531531531, "no_speech_prob": 9.314587077824399e-05}, {"id": 1077, "seek": 508308, "start": 5083.24, "end": 5088.96, "text": " So that shows me that my rearrangement has returned its original correctly.", "tokens": [50372, 407, 300, 3110, 385, 300, 452, 39568, 518, 575, 8752, 1080, 3380, 8944, 13, 50658], "temperature": 0.0, "avg_logprob": -0.33843413266268646, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0005703115602955222}, {"id": 1078, "seek": 508308, "start": 5088.96, "end": 5092.96, "text": " Yeah, so multi-headed attention I've already shown you.", "tokens": [50658, 865, 11, 370, 4825, 12, 28409, 3202, 286, 600, 1217, 4898, 291, 13, 50858], "temperature": 0.0, "avg_logprob": -0.33843413266268646, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0005703115602955222}, {"id": 1079, "seek": 508308, "start": 5092.96, "end": 5099.96, "text": " It's the same thing as before, but pulling everything out into the batch for each head,", "tokens": [50858, 467, 311, 264, 912, 551, 382, 949, 11, 457, 8407, 1203, 484, 666, 264, 15245, 337, 1184, 1378, 11, 51208], "temperature": 0.0, "avg_logprob": -0.33843413266268646, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0005703115602955222}, {"id": 1080, "seek": 508308, "start": 5099.96, "end": 5103.5, "text": " and then pulling the heads back into the channels.", "tokens": [51208, 293, 550, 8407, 264, 8050, 646, 666, 264, 9235, 13, 51385], "temperature": 0.0, "avg_logprob": -0.33843413266268646, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0005703115602955222}, {"id": 1081, "seek": 508308, "start": 5103.5, "end": 5111.5199999999995, "text": " So we can do multi-headed attention with 32 channels and 4 heads, and check that all looks", "tokens": [51385, 407, 321, 393, 360, 4825, 12, 28409, 3202, 365, 8858, 9235, 293, 1017, 8050, 11, 293, 1520, 300, 439, 1542, 51786], "temperature": 0.0, "avg_logprob": -0.33843413266268646, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.0005703115602955222}, {"id": 1082, "seek": 511152, "start": 5111.52, "end": 5112.52, "text": " OK.", "tokens": [50364, 2264, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2984834558823529, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00015843550499994308}, {"id": 1083, "seek": 511152, "start": 5112.52, "end": 5116.120000000001, "text": " So PyTorch has that all built in.", "tokens": [50414, 407, 9953, 51, 284, 339, 575, 300, 439, 3094, 294, 13, 50594], "temperature": 0.0, "avg_logprob": -0.2984834558823529, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00015843550499994308}, {"id": 1084, "seek": 511152, "start": 5116.120000000001, "end": 5120.4400000000005, "text": " It's called nn.multi-headed attention.", "tokens": [50594, 467, 311, 1219, 297, 77, 13, 76, 723, 72, 12, 28409, 3202, 13, 50810], "temperature": 0.0, "avg_logprob": -0.2984834558823529, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00015843550499994308}, {"id": 1085, "seek": 511152, "start": 5120.4400000000005, "end": 5121.84, "text": " Be very careful.", "tokens": [50810, 879, 588, 5026, 13, 50880], "temperature": 0.0, "avg_logprob": -0.2984834558823529, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00015843550499994308}, {"id": 1086, "seek": 511152, "start": 5121.84, "end": 5125.96, "text": " Be more careful than me, in fact, because I keep forgetting that it actually expects", "tokens": [50880, 879, 544, 5026, 813, 385, 11, 294, 1186, 11, 570, 286, 1066, 25428, 300, 309, 767, 33280, 51086], "temperature": 0.0, "avg_logprob": -0.2984834558823529, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00015843550499994308}, {"id": 1087, "seek": 511152, "start": 5125.96, "end": 5130.280000000001, "text": " the batch to be the second dimension.", "tokens": [51086, 264, 15245, 281, 312, 264, 1150, 10139, 13, 51302], "temperature": 0.0, "avg_logprob": -0.2984834558823529, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00015843550499994308}, {"id": 1088, "seek": 511152, "start": 5130.280000000001, "end": 5134.8, "text": " So make sure you write batch first equals true to make batch the first dimension, and", "tokens": [51302, 407, 652, 988, 291, 2464, 15245, 700, 6915, 2074, 281, 652, 15245, 264, 700, 10139, 11, 293, 51528], "temperature": 0.0, "avg_logprob": -0.2984834558823529, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00015843550499994308}, {"id": 1089, "seek": 511152, "start": 5134.8, "end": 5141.080000000001, "text": " that way it'll be the same as diffusers.", "tokens": [51528, 300, 636, 309, 603, 312, 264, 912, 382, 7593, 301, 433, 13, 51842], "temperature": 0.0, "avg_logprob": -0.2984834558823529, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.00015843550499994308}, {"id": 1090, "seek": 514108, "start": 5141.64, "end": 5143.5599999999995, "text": " It might not be identical, but the same.", "tokens": [50392, 467, 1062, 406, 312, 14800, 11, 457, 264, 912, 13, 50488], "temperature": 0.0, "avg_logprob": -0.26650428771972656, "compression_ratio": 1.887029288702929, "no_speech_prob": 4.425483439263189e-06}, {"id": 1091, "seek": 514108, "start": 5143.5599999999995, "end": 5147.44, "text": " It should be almost the same idea.", "tokens": [50488, 467, 820, 312, 1920, 264, 912, 1558, 13, 50682], "temperature": 0.0, "avg_logprob": -0.26650428771972656, "compression_ratio": 1.887029288702929, "no_speech_prob": 4.425483439263189e-06}, {"id": 1092, "seek": 514108, "start": 5147.44, "end": 5151.88, "text": " To make it self-attention, you've got to pass in three things, right?", "tokens": [50682, 1407, 652, 309, 2698, 12, 1591, 1251, 11, 291, 600, 658, 281, 1320, 294, 1045, 721, 11, 558, 30, 50904], "temperature": 0.0, "avg_logprob": -0.26650428771972656, "compression_ratio": 1.887029288702929, "no_speech_prob": 4.425483439263189e-06}, {"id": 1093, "seek": 514108, "start": 5151.88, "end": 5154.32, "text": " So the three things will all be the same for self-attention.", "tokens": [50904, 407, 264, 1045, 721, 486, 439, 312, 264, 912, 337, 2698, 12, 1591, 1251, 13, 51026], "temperature": 0.0, "avg_logprob": -0.26650428771972656, "compression_ratio": 1.887029288702929, "no_speech_prob": 4.425483439263189e-06}, {"id": 1094, "seek": 514108, "start": 5154.32, "end": 5161.84, "text": " This is the thing that's going to be passed through the Q projection, the K projection,", "tokens": [51026, 639, 307, 264, 551, 300, 311, 516, 281, 312, 4678, 807, 264, 1249, 22743, 11, 264, 591, 22743, 11, 51402], "temperature": 0.0, "avg_logprob": -0.26650428771972656, "compression_ratio": 1.887029288702929, "no_speech_prob": 4.425483439263189e-06}, {"id": 1095, "seek": 514108, "start": 5161.84, "end": 5162.84, "text": " and the V projection.", "tokens": [51402, 293, 264, 691, 22743, 13, 51452], "temperature": 0.0, "avg_logprob": -0.26650428771972656, "compression_ratio": 1.887029288702929, "no_speech_prob": 4.425483439263189e-06}, {"id": 1096, "seek": 514108, "start": 5162.84, "end": 5164.8, "text": " And you can pass different things to those.", "tokens": [51452, 400, 291, 393, 1320, 819, 721, 281, 729, 13, 51550], "temperature": 0.0, "avg_logprob": -0.26650428771972656, "compression_ratio": 1.887029288702929, "no_speech_prob": 4.425483439263189e-06}, {"id": 1097, "seek": 514108, "start": 5164.8, "end": 5169.76, "text": " If you pass different things to those, you'll get something called cross-attention, rather", "tokens": [51550, 759, 291, 1320, 819, 721, 281, 729, 11, 291, 603, 483, 746, 1219, 3278, 12, 1591, 1251, 11, 2831, 51798], "temperature": 0.0, "avg_logprob": -0.26650428771972656, "compression_ratio": 1.887029288702929, "no_speech_prob": 4.425483439263189e-06}, {"id": 1098, "seek": 516976, "start": 5169.76, "end": 5179.2, "text": " than self-attention, which I'm not sure we're going to talk about until we do it in NLP.", "tokens": [50364, 813, 2698, 12, 1591, 1251, 11, 597, 286, 478, 406, 988, 321, 434, 516, 281, 751, 466, 1826, 321, 360, 309, 294, 426, 45196, 13, 50836], "temperature": 0.0, "avg_logprob": -0.2798767998105004, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.14413215219974518}, {"id": 1099, "seek": 516976, "start": 5179.2, "end": 5184.320000000001, "text": " Just on the rearrange thing, I know if you've been doing PyTorch and you're used to it,", "tokens": [50836, 1449, 322, 264, 39568, 551, 11, 286, 458, 498, 291, 600, 668, 884, 9953, 51, 284, 339, 293, 291, 434, 1143, 281, 309, 11, 51092], "temperature": 0.0, "avg_logprob": -0.2798767998105004, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.14413215219974518}, {"id": 1100, "seek": 516976, "start": 5184.320000000001, "end": 5189.84, "text": " like you really know what transpose and reshape and whatever do, then it can be a little bit", "tokens": [51092, 411, 291, 534, 458, 437, 25167, 293, 725, 42406, 293, 2035, 360, 11, 550, 309, 393, 312, 257, 707, 857, 51368], "temperature": 0.0, "avg_logprob": -0.2798767998105004, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.14413215219974518}, {"id": 1101, "seek": 516976, "start": 5189.84, "end": 5190.84, "text": " weird to see this new notation.", "tokens": [51368, 3657, 281, 536, 341, 777, 24657, 13, 51418], "temperature": 0.0, "avg_logprob": -0.2798767998105004, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.14413215219974518}, {"id": 1102, "seek": 516976, "start": 5190.84, "end": 5193.72, "text": " But once you get into it, it's really, really nice.", "tokens": [51418, 583, 1564, 291, 483, 666, 309, 11, 309, 311, 534, 11, 534, 1481, 13, 51562], "temperature": 0.0, "avg_logprob": -0.2798767998105004, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.14413215219974518}, {"id": 1103, "seek": 516976, "start": 5193.72, "end": 5197.88, "text": " And if you look at the self-attention multi-headed implementation there, you've got .view and", "tokens": [51562, 400, 498, 291, 574, 412, 264, 2698, 12, 1591, 1251, 4825, 12, 28409, 11420, 456, 11, 291, 600, 658, 2411, 1759, 293, 51770], "temperature": 0.0, "avg_logprob": -0.2798767998105004, "compression_ratio": 1.6313868613138687, "no_speech_prob": 0.14413215219974518}, {"id": 1104, "seek": 519788, "start": 5197.88, "end": 5200.92, "text": " .transpose and .reshape.", "tokens": [50364, 2411, 24999, 43501, 293, 2411, 495, 42406, 13, 50516], "temperature": 0.0, "avg_logprob": -0.3334815979003906, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.1581026017665863}, {"id": 1105, "seek": 519788, "start": 5200.92, "end": 5202.52, "text": " It's quite fun practice.", "tokens": [50516, 467, 311, 1596, 1019, 3124, 13, 50596], "temperature": 0.0, "avg_logprob": -0.3334815979003906, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.1581026017665863}, {"id": 1106, "seek": 519788, "start": 5202.52, "end": 5207.6, "text": " If you're just saying, oh, this INOPS thing looks really useful, take an existing implementation", "tokens": [50596, 759, 291, 434, 445, 1566, 11, 1954, 11, 341, 6892, 46, 6273, 551, 1542, 534, 4420, 11, 747, 364, 6741, 11420, 50850], "temperature": 0.0, "avg_logprob": -0.3334815979003906, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.1581026017665863}, {"id": 1107, "seek": 519788, "start": 5207.6, "end": 5213.76, "text": " like this and say, oh, maybe instead of .reshape or whatever, can I start replacing these individual", "tokens": [50850, 411, 341, 293, 584, 11, 1954, 11, 1310, 2602, 295, 2411, 495, 42406, 420, 2035, 11, 393, 286, 722, 19139, 613, 2609, 51158], "temperature": 0.0, "avg_logprob": -0.3334815979003906, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.1581026017665863}, {"id": 1108, "seek": 519788, "start": 5213.76, "end": 5217.92, "text": " operations with the equivalent rearrange call?", "tokens": [51158, 7705, 365, 264, 10344, 39568, 818, 30, 51366], "temperature": 0.0, "avg_logprob": -0.3334815979003906, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.1581026017665863}, {"id": 1109, "seek": 519788, "start": 5217.92, "end": 5220.52, "text": " And then checking that the outputs are the same.", "tokens": [51366, 400, 550, 8568, 300, 264, 23930, 366, 264, 912, 13, 51496], "temperature": 0.0, "avg_logprob": -0.3334815979003906, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.1581026017665863}, {"id": 1110, "seek": 519788, "start": 5220.52, "end": 5223.36, "text": " That's what helped it click for me, was, oh, OK.", "tokens": [51496, 663, 311, 437, 4254, 309, 2052, 337, 385, 11, 390, 11, 1954, 11, 2264, 13, 51638], "temperature": 0.0, "avg_logprob": -0.3334815979003906, "compression_ratio": 1.5193798449612403, "no_speech_prob": 0.1581026017665863}, {"id": 1111, "seek": 522336, "start": 5223.36, "end": 5228.5199999999995, "text": " I can start to express, if it's just transpose, then that's a rearrange with the last two", "tokens": [50364, 286, 393, 722, 281, 5109, 11, 498, 309, 311, 445, 25167, 11, 550, 300, 311, 257, 39568, 365, 264, 1036, 732, 50622], "temperature": 0.0, "avg_logprob": -0.3086259590004975, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.05580170825123787}, {"id": 1112, "seek": 522336, "start": 5228.5199999999995, "end": 5232.16, "text": " channels switched, if I wanted to do it that way.", "tokens": [50622, 9235, 16858, 11, 498, 286, 1415, 281, 360, 309, 300, 636, 13, 50804], "temperature": 0.0, "avg_logprob": -0.3086259590004975, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.05580170825123787}, {"id": 1113, "seek": 522336, "start": 5232.16, "end": 5237.599999999999, "text": " I only just started using this, and I've obviously had many years of using reshape, transpose,", "tokens": [50804, 286, 787, 445, 1409, 1228, 341, 11, 293, 286, 600, 2745, 632, 867, 924, 295, 1228, 725, 42406, 11, 25167, 11, 51076], "temperature": 0.0, "avg_logprob": -0.3086259590004975, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.05580170825123787}, {"id": 1114, "seek": 522336, "start": 5237.599999999999, "end": 5245.799999999999, "text": " et cetera, in Fiano, TensorFlow, Keras, PyTorch, APL.", "tokens": [51076, 1030, 11458, 11, 294, 479, 6254, 11, 37624, 11, 591, 6985, 11, 9953, 51, 284, 339, 11, 5372, 43, 13, 51486], "temperature": 0.0, "avg_logprob": -0.3086259590004975, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.05580170825123787}, {"id": 1115, "seek": 522336, "start": 5245.799999999999, "end": 5251.2, "text": " And I would say within 10 minutes, I was like, oh, I like this much better.", "tokens": [51486, 400, 286, 576, 584, 1951, 1266, 2077, 11, 286, 390, 411, 11, 1954, 11, 286, 411, 341, 709, 1101, 13, 51756], "temperature": 0.0, "avg_logprob": -0.3086259590004975, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.05580170825123787}, {"id": 1116, "seek": 525120, "start": 5251.24, "end": 5255.04, "text": " You know, like it's fine for me, at least.", "tokens": [50366, 509, 458, 11, 411, 309, 311, 2489, 337, 385, 11, 412, 1935, 13, 50556], "temperature": 0.0, "avg_logprob": -0.27404260635375977, "compression_ratio": 1.4830508474576272, "no_speech_prob": 0.00040445735794492066}, {"id": 1117, "seek": 525120, "start": 5255.04, "end": 5257.88, "text": " It didn't take too long to be convinced.", "tokens": [50556, 467, 994, 380, 747, 886, 938, 281, 312, 12561, 13, 50698], "temperature": 0.0, "avg_logprob": -0.27404260635375977, "compression_ratio": 1.4830508474576272, "no_speech_prob": 0.00040445735794492066}, {"id": 1118, "seek": 525120, "start": 5257.88, "end": 5260.32, "text": " It's not part of PyTorch or anything.", "tokens": [50698, 467, 311, 406, 644, 295, 9953, 51, 284, 339, 420, 1340, 13, 50820], "temperature": 0.0, "avg_logprob": -0.27404260635375977, "compression_ratio": 1.4830508474576272, "no_speech_prob": 0.00040445735794492066}, {"id": 1119, "seek": 525120, "start": 5260.32, "end": 5265.679999999999, "text": " You've got to pip install it, by the way.", "tokens": [50820, 509, 600, 658, 281, 8489, 3625, 309, 11, 538, 264, 636, 13, 51088], "temperature": 0.0, "avg_logprob": -0.27404260635375977, "compression_ratio": 1.4830508474576272, "no_speech_prob": 0.00040445735794492066}, {"id": 1120, "seek": 525120, "start": 5265.679999999999, "end": 5270.08, "text": " And it seems to be becoming super popular now, at least in the kind of diffusion research", "tokens": [51088, 400, 309, 2544, 281, 312, 5617, 1687, 3743, 586, 11, 412, 1935, 294, 264, 733, 295, 25242, 2132, 51308], "temperature": 0.0, "avg_logprob": -0.27404260635375977, "compression_ratio": 1.4830508474576272, "no_speech_prob": 0.00040445735794492066}, {"id": 1121, "seek": 525120, "start": 5270.08, "end": 5271.08, "text": " crowd.", "tokens": [51308, 6919, 13, 51358], "temperature": 0.0, "avg_logprob": -0.27404260635375977, "compression_ratio": 1.4830508474576272, "no_speech_prob": 0.00040445735794492066}, {"id": 1122, "seek": 525120, "start": 5271.08, "end": 5277.16, "text": " Everybody seems to be using INOPS suddenly, even though it's been around for a few years.", "tokens": [51358, 7646, 2544, 281, 312, 1228, 6892, 46, 6273, 5800, 11, 754, 1673, 309, 311, 668, 926, 337, 257, 1326, 924, 13, 51662], "temperature": 0.0, "avg_logprob": -0.27404260635375977, "compression_ratio": 1.4830508474576272, "no_speech_prob": 0.00040445735794492066}, {"id": 1123, "seek": 527716, "start": 5277.16, "end": 5283.0, "text": " And I actually put in an issue there, and asked them to add in Einstein summation notation", "tokens": [50364, 400, 286, 767, 829, 294, 364, 2734, 456, 11, 293, 2351, 552, 281, 909, 294, 23486, 28811, 24657, 50656], "temperature": 0.0, "avg_logprob": -0.26555865643972376, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0005527706234715879}, {"id": 1124, "seek": 527716, "start": 5283.0, "end": 5284.44, "text": " as well, which they've now done.", "tokens": [50656, 382, 731, 11, 597, 436, 600, 586, 1096, 13, 50728], "temperature": 0.0, "avg_logprob": -0.26555865643972376, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0005527706234715879}, {"id": 1125, "seek": 527716, "start": 5284.44, "end": 5287.639999999999, "text": " So it's kind of like your one place for everything, which is great.", "tokens": [50728, 407, 309, 311, 733, 295, 411, 428, 472, 1081, 337, 1203, 11, 597, 307, 869, 13, 50888], "temperature": 0.0, "avg_logprob": -0.26555865643972376, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0005527706234715879}, {"id": 1126, "seek": 527716, "start": 5287.639999999999, "end": 5296.48, "text": " And it also works across TensorFlow and other libraries as well, which is nice.", "tokens": [50888, 400, 309, 611, 1985, 2108, 37624, 293, 661, 15148, 382, 731, 11, 597, 307, 1481, 13, 51330], "temperature": 0.0, "avg_logprob": -0.26555865643972376, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0005527706234715879}, {"id": 1127, "seek": 527716, "start": 5296.48, "end": 5304.04, "text": " OK, so we can now add that to our unit.", "tokens": [51330, 2264, 11, 370, 321, 393, 586, 909, 300, 281, 527, 4985, 13, 51708], "temperature": 0.0, "avg_logprob": -0.26555865643972376, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0005527706234715879}, {"id": 1128, "seek": 530404, "start": 5304.04, "end": 5308.84, "text": " So this is basically a copy of the previous notebook, except what I've now done is I did", "tokens": [50364, 407, 341, 307, 1936, 257, 5055, 295, 264, 3894, 21060, 11, 3993, 437, 286, 600, 586, 1096, 307, 286, 630, 50604], "temperature": 0.0, "avg_logprob": -0.33235904363196667, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.007121007889509201}, {"id": 1129, "seek": 530404, "start": 5308.84, "end": 5313.72, "text": " this at the point where it's like, oh, yeah, it turns out that cosine scheduling is better.", "tokens": [50604, 341, 412, 264, 935, 689, 309, 311, 411, 11, 1954, 11, 1338, 11, 309, 4523, 484, 300, 23565, 29055, 307, 1101, 13, 50848], "temperature": 0.0, "avg_logprob": -0.33235904363196667, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.007121007889509201}, {"id": 1130, "seek": 530404, "start": 5313.72, "end": 5316.12, "text": " So I'm back to cosine schedule now.", "tokens": [50848, 407, 286, 478, 646, 281, 23565, 7567, 586, 13, 50968], "temperature": 0.0, "avg_logprob": -0.33235904363196667, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.007121007889509201}, {"id": 1131, "seek": 530404, "start": 5316.12, "end": 5318.48, "text": " So this is copied from the cosine schedule book.", "tokens": [50968, 407, 341, 307, 25365, 490, 264, 23565, 7567, 1446, 13, 51086], "temperature": 0.0, "avg_logprob": -0.33235904363196667, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.007121007889509201}, {"id": 1132, "seek": 530404, "start": 5318.48, "end": 5324.88, "text": " And we're still doing the minus .5 thing, because we love it.", "tokens": [51086, 400, 321, 434, 920, 884, 264, 3175, 2411, 20, 551, 11, 570, 321, 959, 309, 13, 51406], "temperature": 0.0, "avg_logprob": -0.33235904363196667, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.007121007889509201}, {"id": 1133, "seek": 530404, "start": 5324.88, "end": 5330.56, "text": " And so this time, I actually decided to export stuff into a mini AI.diffusion.", "tokens": [51406, 400, 370, 341, 565, 11, 286, 767, 3047, 281, 10725, 1507, 666, 257, 8382, 7318, 13, 67, 3661, 5704, 13, 51690], "temperature": 0.0, "avg_logprob": -0.33235904363196667, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.007121007889509201}, {"id": 1134, "seek": 530404, "start": 5330.56, "end": 5333.5199999999995, "text": " So since this point, I felt like things were working pretty well.", "tokens": [51690, 407, 1670, 341, 935, 11, 286, 2762, 411, 721, 645, 1364, 1238, 731, 13, 51838], "temperature": 0.0, "avg_logprob": -0.33235904363196667, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.007121007889509201}, {"id": 1135, "seek": 533352, "start": 5334.0, "end": 5336.0, "text": " So I renamed unit.conv to pre.conv.", "tokens": [50388, 407, 286, 40949, 4985, 13, 1671, 85, 281, 659, 13, 1671, 85, 13, 50488], "temperature": 0.0, "avg_logprob": -0.3974353991056743, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0018675558967515826}, {"id": 1136, "seek": 533352, "start": 5336.0, "end": 5337.8, "text": " It's a better name.", "tokens": [50488, 467, 311, 257, 1101, 1315, 13, 50578], "temperature": 0.0, "avg_logprob": -0.3974353991056743, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0018675558967515826}, {"id": 1137, "seek": 533352, "start": 5337.8, "end": 5340.160000000001, "text": " Time step embedding has been exported.", "tokens": [50578, 6161, 1823, 12240, 3584, 575, 668, 42055, 13, 50696], "temperature": 0.0, "avg_logprob": -0.3974353991056743, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0018675558967515826}, {"id": 1138, "seek": 533352, "start": 5340.160000000001, "end": 5342.280000000001, "text": " Pup sample's been exported.", "tokens": [50696, 430, 1010, 6889, 311, 668, 42055, 13, 50802], "temperature": 0.0, "avg_logprob": -0.3974353991056743, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0018675558967515826}, {"id": 1139, "seek": 533352, "start": 5342.280000000001, "end": 5349.72, "text": " This is like a preact linear version exported.", "tokens": [50802, 639, 307, 411, 257, 659, 578, 8213, 3037, 42055, 13, 51174], "temperature": 0.0, "avg_logprob": -0.3974353991056743, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0018675558967515826}, {"id": 1140, "seek": 533352, "start": 5349.72, "end": 5354.200000000001, "text": " I tried using an n.multi-headed tension, and it didn't work very well for some reason.", "tokens": [51174, 286, 3031, 1228, 364, 297, 13, 76, 723, 72, 12, 28409, 8980, 11, 293, 309, 994, 380, 589, 588, 731, 337, 512, 1778, 13, 51398], "temperature": 0.0, "avg_logprob": -0.3974353991056743, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0018675558967515826}, {"id": 1141, "seek": 533352, "start": 5354.200000000001, "end": 5358.64, "text": " So I haven't figured out why that is yet.", "tokens": [51398, 407, 286, 2378, 380, 8932, 484, 983, 300, 307, 1939, 13, 51620], "temperature": 0.0, "avg_logprob": -0.3974353991056743, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.0018675558967515826}, {"id": 1142, "seek": 535864, "start": 5358.64, "end": 5365.12, "text": " So I'm using this self-attention, which we just talked about.", "tokens": [50364, 407, 286, 478, 1228, 341, 2698, 12, 1591, 1251, 11, 597, 321, 445, 2825, 466, 13, 50688], "temperature": 0.0, "avg_logprob": -0.34406379914619556, "compression_ratio": 1.6163522012578617, "no_speech_prob": 0.03904268518090248}, {"id": 1143, "seek": 535864, "start": 5365.12, "end": 5366.12, "text": " Multi-headed self-attention.", "tokens": [50688, 29238, 12, 28409, 2698, 12, 1591, 1251, 13, 50738], "temperature": 0.0, "avg_logprob": -0.34406379914619556, "compression_ratio": 1.6163522012578617, "no_speech_prob": 0.03904268518090248}, {"id": 1144, "seek": 535864, "start": 5366.12, "end": 5374.0, "text": " You know, just the scale, we have to divide the number of channels by the number of heads,", "tokens": [50738, 509, 458, 11, 445, 264, 4373, 11, 321, 362, 281, 9845, 264, 1230, 295, 9235, 538, 264, 1230, 295, 8050, 11, 51132], "temperature": 0.0, "avg_logprob": -0.34406379914619556, "compression_ratio": 1.6163522012578617, "no_speech_prob": 0.03904268518090248}, {"id": 1145, "seek": 535864, "start": 5374.0, "end": 5380.56, "text": " because the effective number of heads is, you know, divided across n heads.", "tokens": [51132, 570, 264, 4942, 1230, 295, 8050, 307, 11, 291, 458, 11, 6666, 2108, 297, 8050, 13, 51460], "temperature": 0.0, "avg_logprob": -0.34406379914619556, "compression_ratio": 1.6163522012578617, "no_speech_prob": 0.03904268518090248}, {"id": 1146, "seek": 538056, "start": 5380.56, "end": 5387.72, "text": " And instead of specifying n heads, you specify attention channels.", "tokens": [50364, 400, 2602, 295, 1608, 5489, 297, 8050, 11, 291, 16500, 3202, 9235, 13, 50722], "temperature": 0.0, "avg_logprob": -0.4259753116341524, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.027167685329914093}, {"id": 1147, "seek": 538056, "start": 5387.72, "end": 5393.160000000001, "text": " So if you have 32 attention channels, then you calculate.", "tokens": [50722, 407, 498, 291, 362, 8858, 3202, 9235, 11, 550, 291, 8873, 13, 50994], "temperature": 0.0, "avg_logprob": -0.4259753116341524, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.027167685329914093}, {"id": 1148, "seek": 538056, "start": 5393.160000000001, "end": 5395.160000000001, "text": " That's what diffuses does, I think.", "tokens": [50994, 663, 311, 437, 7593, 8355, 775, 11, 286, 519, 13, 51094], "temperature": 0.0, "avg_logprob": -0.4259753116341524, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.027167685329914093}, {"id": 1149, "seek": 538056, "start": 5395.160000000001, "end": 5398.120000000001, "text": " It's not what n.multi-headed tension does.", "tokens": [51094, 467, 311, 406, 437, 297, 13, 76, 723, 72, 12, 28409, 8980, 775, 13, 51242], "temperature": 0.0, "avg_logprob": -0.4259753116341524, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.027167685329914093}, {"id": 1150, "seek": 538056, "start": 5398.120000000001, "end": 5403.64, "text": " And actually, I think n i divided by n i divided by attention chance is actually just equal", "tokens": [51242, 400, 767, 11, 286, 519, 297, 741, 6666, 538, 297, 741, 6666, 538, 3202, 2931, 307, 767, 445, 2681, 51518], "temperature": 0.0, "avg_logprob": -0.4259753116341524, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.027167685329914093}, {"id": 1151, "seek": 538056, "start": 5403.64, "end": 5406.080000000001, "text": " to attention chance.", "tokens": [51518, 281, 3202, 2931, 13, 51640], "temperature": 0.0, "avg_logprob": -0.4259753116341524, "compression_ratio": 1.7362637362637363, "no_speech_prob": 0.027167685329914093}, {"id": 1152, "seek": 540608, "start": 5406.08, "end": 5410.4, "text": " So I could have just put that, probably.", "tokens": [50364, 407, 286, 727, 362, 445, 829, 300, 11, 1391, 13, 50580], "temperature": 0.0, "avg_logprob": -0.40507587488146796, "compression_ratio": 1.4074074074074074, "no_speech_prob": 0.0005527751054614782}, {"id": 1153, "seek": 540608, "start": 5410.4, "end": 5414.32, "text": " Anyway, never mind.", "tokens": [50580, 5684, 11, 1128, 1575, 13, 50776], "temperature": 0.0, "avg_logprob": -0.40507587488146796, "compression_ratio": 1.4074074074074074, "no_speech_prob": 0.0005527751054614782}, {"id": 1154, "seek": 540608, "start": 5414.32, "end": 5417.88, "text": " So that's all copied in from the previous one.", "tokens": [50776, 407, 300, 311, 439, 25365, 294, 490, 264, 3894, 472, 13, 50954], "temperature": 0.0, "avg_logprob": -0.40507587488146796, "compression_ratio": 1.4074074074074074, "no_speech_prob": 0.0005527751054614782}, {"id": 1155, "seek": 540608, "start": 5417.88, "end": 5425.4, "text": " The only thing that's different here is I haven't got the dot view minus one thing here.", "tokens": [50954, 440, 787, 551, 300, 311, 819, 510, 307, 286, 2378, 380, 658, 264, 5893, 1910, 3175, 472, 551, 510, 13, 51330], "temperature": 0.0, "avg_logprob": -0.40507587488146796, "compression_ratio": 1.4074074074074074, "no_speech_prob": 0.0005527751054614782}, {"id": 1156, "seek": 540608, "start": 5425.4, "end": 5427.84, "text": " So this is a 1D self-attention.", "tokens": [51330, 407, 341, 307, 257, 502, 35, 2698, 12, 1591, 1251, 13, 51452], "temperature": 0.0, "avg_logprob": -0.40507587488146796, "compression_ratio": 1.4074074074074074, "no_speech_prob": 0.0005527751054614782}, {"id": 1157, "seek": 542784, "start": 5427.84, "end": 5435.88, "text": " And then 2D self-attention just adds the dot view before we call forward, and then dot", "tokens": [50364, 400, 550, 568, 35, 2698, 12, 1591, 1251, 445, 10860, 264, 5893, 1910, 949, 321, 818, 2128, 11, 293, 550, 5893, 50766], "temperature": 0.0, "avg_logprob": -0.2920888451968922, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.003765302011743188}, {"id": 1158, "seek": 542784, "start": 5435.88, "end": 5442.24, "text": " reshape it back again.", "tokens": [50766, 725, 42406, 309, 646, 797, 13, 51084], "temperature": 0.0, "avg_logprob": -0.2920888451968922, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.003765302011743188}, {"id": 1159, "seek": 542784, "start": 5442.24, "end": 5444.6, "text": " So yeah, so we've got 1D and 2D self-attention.", "tokens": [51084, 407, 1338, 11, 370, 321, 600, 658, 502, 35, 293, 568, 35, 2698, 12, 1591, 1251, 13, 51202], "temperature": 0.0, "avg_logprob": -0.2920888451968922, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.003765302011743188}, {"id": 1160, "seek": 542784, "start": 5444.6, "end": 5450.04, "text": " Okay, so now our mBrez block has one extra thing you can pass in, which is attention", "tokens": [51202, 1033, 11, 370, 586, 527, 275, 33, 17693, 3461, 575, 472, 2857, 551, 291, 393, 1320, 294, 11, 597, 307, 3202, 51474], "temperature": 0.0, "avg_logprob": -0.2920888451968922, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.003765302011743188}, {"id": 1161, "seek": 542784, "start": 5450.04, "end": 5452.84, "text": " channels.", "tokens": [51474, 9235, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2920888451968922, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.003765302011743188}, {"id": 1162, "seek": 542784, "start": 5452.84, "end": 5457.28, "text": " And so if you pass in attention channels, we're going to create something called self.attention,", "tokens": [51614, 400, 370, 498, 291, 1320, 294, 3202, 9235, 11, 321, 434, 516, 281, 1884, 746, 1219, 2698, 13, 1591, 1251, 11, 51836], "temperature": 0.0, "avg_logprob": -0.2920888451968922, "compression_ratio": 1.6384976525821595, "no_speech_prob": 0.003765302011743188}, {"id": 1163, "seek": 545728, "start": 5457.719999999999, "end": 5463.32, "text": " which is a self-attention 2D layer with the right number of filters and the requested", "tokens": [50386, 597, 307, 257, 2698, 12, 1591, 1251, 568, 35, 4583, 365, 264, 558, 1230, 295, 15995, 293, 264, 16436, 50666], "temperature": 0.0, "avg_logprob": -0.26063476290021625, "compression_ratio": 1.6024590163934427, "no_speech_prob": 3.705295966938138e-05}, {"id": 1164, "seek": 545728, "start": 5463.32, "end": 5465.5199999999995, "text": " number of channels.", "tokens": [50666, 1230, 295, 9235, 13, 50776], "temperature": 0.0, "avg_logprob": -0.26063476290021625, "compression_ratio": 1.6024590163934427, "no_speech_prob": 3.705295966938138e-05}, {"id": 1165, "seek": 545728, "start": 5465.5199999999995, "end": 5471.599999999999, "text": " And so this is all identical to what we've seen before, except if we've got attention,", "tokens": [50776, 400, 370, 341, 307, 439, 14800, 281, 437, 321, 600, 1612, 949, 11, 3993, 498, 321, 600, 658, 3202, 11, 51080], "temperature": 0.0, "avg_logprob": -0.26063476290021625, "compression_ratio": 1.6024590163934427, "no_speech_prob": 3.705295966938138e-05}, {"id": 1166, "seek": 545728, "start": 5471.599999999999, "end": 5472.599999999999, "text": " then we add it.", "tokens": [51080, 550, 321, 909, 309, 13, 51130], "temperature": 0.0, "avg_logprob": -0.26063476290021625, "compression_ratio": 1.6024590163934427, "no_speech_prob": 3.705295966938138e-05}, {"id": 1167, "seek": 545728, "start": 5472.599999999999, "end": 5477.32, "text": " Oh yeah, and the attention that I did here is the non-ResNet-y version.", "tokens": [51130, 876, 1338, 11, 293, 264, 3202, 300, 286, 630, 510, 307, 264, 2107, 12, 33274, 31890, 12, 88, 3037, 13, 51366], "temperature": 0.0, "avg_logprob": -0.26063476290021625, "compression_ratio": 1.6024590163934427, "no_speech_prob": 3.705295966938138e-05}, {"id": 1168, "seek": 545728, "start": 5477.32, "end": 5481.5199999999995, "text": " So we have to do x plus, because that's more flexible.", "tokens": [51366, 407, 321, 362, 281, 360, 2031, 1804, 11, 570, 300, 311, 544, 11358, 13, 51576], "temperature": 0.0, "avg_logprob": -0.26063476290021625, "compression_ratio": 1.6024590163934427, "no_speech_prob": 3.705295966938138e-05}, {"id": 1169, "seek": 545728, "start": 5481.5199999999995, "end": 5485.04, "text": " You can then choose to have it or not have it this way.", "tokens": [51576, 509, 393, 550, 2826, 281, 362, 309, 420, 406, 362, 309, 341, 636, 13, 51752], "temperature": 0.0, "avg_logprob": -0.26063476290021625, "compression_ratio": 1.6024590163934427, "no_speech_prob": 3.705295966938138e-05}, {"id": 1170, "seek": 548504, "start": 5485.8, "end": 5491.36, "text": " Okay, so that's an mBrez block with attention.", "tokens": [50402, 1033, 11, 370, 300, 311, 364, 275, 33, 17693, 3461, 365, 3202, 13, 50680], "temperature": 0.0, "avg_logprob": -0.26077938079833984, "compression_ratio": 2.1311475409836067, "no_speech_prob": 7.646534868399613e-06}, {"id": 1171, "seek": 548504, "start": 5491.36, "end": 5496.72, "text": " And so now our down block, you have to tell it how many attention channels you want, because", "tokens": [50680, 400, 370, 586, 527, 760, 3461, 11, 291, 362, 281, 980, 309, 577, 867, 3202, 9235, 291, 528, 11, 570, 50948], "temperature": 0.0, "avg_logprob": -0.26077938079833984, "compression_ratio": 2.1311475409836067, "no_speech_prob": 7.646534868399613e-06}, {"id": 1172, "seek": 548504, "start": 5496.72, "end": 5498.36, "text": " the res blocks need that.", "tokens": [50948, 264, 725, 8474, 643, 300, 13, 51030], "temperature": 0.0, "avg_logprob": -0.26077938079833984, "compression_ratio": 2.1311475409836067, "no_speech_prob": 7.646534868399613e-06}, {"id": 1173, "seek": 548504, "start": 5498.36, "end": 5502.44, "text": " The up block, you have to know how many attention channels you want, because again, the res", "tokens": [51030, 440, 493, 3461, 11, 291, 362, 281, 458, 577, 867, 3202, 9235, 291, 528, 11, 570, 797, 11, 264, 725, 51234], "temperature": 0.0, "avg_logprob": -0.26077938079833984, "compression_ratio": 2.1311475409836067, "no_speech_prob": 7.646534868399613e-06}, {"id": 1174, "seek": 548504, "start": 5502.44, "end": 5504.4, "text": " blocks need that.", "tokens": [51234, 8474, 643, 300, 13, 51332], "temperature": 0.0, "avg_logprob": -0.26077938079833984, "compression_ratio": 2.1311475409836067, "no_speech_prob": 7.646534868399613e-06}, {"id": 1175, "seek": 548504, "start": 5504.4, "end": 5508.64, "text": " And so now the UNet model, where does the attention go?", "tokens": [51332, 400, 370, 586, 264, 624, 31890, 2316, 11, 689, 775, 264, 3202, 352, 30, 51544], "temperature": 0.0, "avg_logprob": -0.26077938079833984, "compression_ratio": 2.1311475409836067, "no_speech_prob": 7.646534868399613e-06}, {"id": 1176, "seek": 548504, "start": 5508.64, "end": 5512.84, "text": " Okay, we have to say how many attention channels you want.", "tokens": [51544, 1033, 11, 321, 362, 281, 584, 577, 867, 3202, 9235, 291, 528, 13, 51754], "temperature": 0.0, "avg_logprob": -0.26077938079833984, "compression_ratio": 2.1311475409836067, "no_speech_prob": 7.646534868399613e-06}, {"id": 1177, "seek": 551284, "start": 5512.84, "end": 5517.8, "text": " And then you say, which index block do you start adding attention?", "tokens": [50364, 400, 550, 291, 584, 11, 597, 8186, 3461, 360, 291, 722, 5127, 3202, 30, 50612], "temperature": 0.0, "avg_logprob": -0.27674606442451477, "compression_ratio": 1.5192307692307692, "no_speech_prob": 6.502809264929965e-05}, {"id": 1178, "seek": 551284, "start": 5517.8, "end": 5529.04, "text": " So why don't we, so then what happens is the attention is done here.", "tokens": [50612, 407, 983, 500, 380, 321, 11, 370, 550, 437, 2314, 307, 264, 3202, 307, 1096, 510, 13, 51174], "temperature": 0.0, "avg_logprob": -0.27674606442451477, "compression_ratio": 1.5192307692307692, "no_speech_prob": 6.502809264929965e-05}, {"id": 1179, "seek": 551284, "start": 5529.04, "end": 5533.88, "text": " Each ResNet has attention.", "tokens": [51174, 6947, 5015, 31890, 575, 3202, 13, 51416], "temperature": 0.0, "avg_logprob": -0.27674606442451477, "compression_ratio": 1.5192307692307692, "no_speech_prob": 6.502809264929965e-05}, {"id": 1180, "seek": 551284, "start": 5533.88, "end": 5538.92, "text": " And so as we discussed, you just do the normal res and then the attention.", "tokens": [51416, 400, 370, 382, 321, 7152, 11, 291, 445, 360, 264, 2710, 725, 293, 550, 264, 3202, 13, 51668], "temperature": 0.0, "avg_logprob": -0.27674606442451477, "compression_ratio": 1.5192307692307692, "no_speech_prob": 6.502809264929965e-05}, {"id": 1181, "seek": 553892, "start": 5538.92, "end": 5560.68, "text": " And if you put that in at the very start, right, let's say you've got a 256 by 256 image,", "tokens": [50364, 400, 498, 291, 829, 300, 294, 412, 264, 588, 722, 11, 558, 11, 718, 311, 584, 291, 600, 658, 257, 38882, 538, 38882, 3256, 11, 51452], "temperature": 0.0, "avg_logprob": -0.3921872171862372, "compression_ratio": 1.072289156626506, "no_speech_prob": 0.008187106810510159}, {"id": 1182, "seek": 556068, "start": 5560.72, "end": 5565.68, "text": " then you're going to end up with this matrix here.", "tokens": [50366, 550, 291, 434, 516, 281, 917, 493, 365, 341, 8141, 510, 13, 50614], "temperature": 0.0, "avg_logprob": -0.29124225478574456, "compression_ratio": 1.5722222222222222, "no_speech_prob": 0.0008166790357790887}, {"id": 1183, "seek": 556068, "start": 5565.68, "end": 5576.8, "text": " It's going to be 256 by 256 on one side and 256 by 256 on the other side and contain however", "tokens": [50614, 467, 311, 516, 281, 312, 38882, 538, 38882, 322, 472, 1252, 293, 38882, 538, 38882, 322, 264, 661, 1252, 293, 5304, 4461, 51170], "temperature": 0.0, "avg_logprob": -0.29124225478574456, "compression_ratio": 1.5722222222222222, "no_speech_prob": 0.0008166790357790887}, {"id": 1184, "seek": 556068, "start": 5576.8, "end": 5580.76, "text": " many, you know, NF channels.", "tokens": [51170, 867, 11, 291, 458, 11, 13576, 9235, 13, 51368], "temperature": 0.0, "avg_logprob": -0.29124225478574456, "compression_ratio": 1.5722222222222222, "no_speech_prob": 0.0008166790357790887}, {"id": 1185, "seek": 556068, "start": 5580.76, "end": 5584.0, "text": " That's huge.", "tokens": [51368, 663, 311, 2603, 13, 51530], "temperature": 0.0, "avg_logprob": -0.29124225478574456, "compression_ratio": 1.5722222222222222, "no_speech_prob": 0.0008166790357790887}, {"id": 1186, "seek": 556068, "start": 5584.0, "end": 5586.96, "text": " And you have to back prop through it.", "tokens": [51530, 400, 291, 362, 281, 646, 2365, 807, 309, 13, 51678], "temperature": 0.0, "avg_logprob": -0.29124225478574456, "compression_ratio": 1.5722222222222222, "no_speech_prob": 0.0008166790357790887}, {"id": 1187, "seek": 556068, "start": 5586.96, "end": 5590.400000000001, "text": " So you have to store all that to allow back prop to happen.", "tokens": [51678, 407, 291, 362, 281, 3531, 439, 300, 281, 2089, 646, 2365, 281, 1051, 13, 51850], "temperature": 0.0, "avg_logprob": -0.29124225478574456, "compression_ratio": 1.5722222222222222, "no_speech_prob": 0.0008166790357790887}, {"id": 1188, "seek": 559040, "start": 5591.12, "end": 5592.759999999999, "text": " It's going to explode your memory.", "tokens": [50400, 467, 311, 516, 281, 21411, 428, 4675, 13, 50482], "temperature": 0.0, "avg_logprob": -0.23370401594373916, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3007117559027392e-05}, {"id": 1189, "seek": 559040, "start": 5592.759999999999, "end": 5600.04, "text": " So what happens is basically nobody puts attention in the first layers.", "tokens": [50482, 407, 437, 2314, 307, 1936, 5079, 8137, 3202, 294, 264, 700, 7914, 13, 50846], "temperature": 0.0, "avg_logprob": -0.23370401594373916, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3007117559027392e-05}, {"id": 1190, "seek": 559040, "start": 5600.04, "end": 5606.639999999999, "text": " So that's why I've added a attention start, which is like at which block do we start adding", "tokens": [50846, 407, 300, 311, 983, 286, 600, 3869, 257, 3202, 722, 11, 597, 307, 411, 412, 597, 3461, 360, 321, 722, 5127, 51176], "temperature": 0.0, "avg_logprob": -0.23370401594373916, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3007117559027392e-05}, {"id": 1191, "seek": 559040, "start": 5606.639999999999, "end": 5614.639999999999, "text": " attention and it's not zero for the reason we just discussed.", "tokens": [51176, 3202, 293, 309, 311, 406, 4018, 337, 264, 1778, 321, 445, 7152, 13, 51576], "temperature": 0.0, "avg_logprob": -0.23370401594373916, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3007117559027392e-05}, {"id": 1192, "seek": 559040, "start": 5614.639999999999, "end": 5619.36, "text": " Another way you could do this is to say like, at what grid size should you start adding", "tokens": [51576, 3996, 636, 291, 727, 360, 341, 307, 281, 584, 411, 11, 412, 437, 10748, 2744, 820, 291, 722, 5127, 51812], "temperature": 0.0, "avg_logprob": -0.23370401594373916, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3007117559027392e-05}, {"id": 1193, "seek": 559040, "start": 5619.36, "end": 5620.36, "text": " attention?", "tokens": [51812, 3202, 30, 51862], "temperature": 0.0, "avg_logprob": -0.23370401594373916, "compression_ratio": 1.6318181818181818, "no_speech_prob": 1.3007117559027392e-05}, {"id": 1194, "seek": 562036, "start": 5620.36, "end": 5626.2, "text": " So generally speaking, people say at when you get to 16 by 16, that's a good time to", "tokens": [50364, 407, 5101, 4124, 11, 561, 584, 412, 562, 291, 483, 281, 3165, 538, 3165, 11, 300, 311, 257, 665, 565, 281, 50656], "temperature": 0.0, "avg_logprob": -0.2899911668565538, "compression_ratio": 1.716, "no_speech_prob": 4.985940540791489e-05}, {"id": 1195, "seek": 562036, "start": 5626.2, "end": 5628.639999999999, "text": " start adding attention.", "tokens": [50656, 722, 5127, 3202, 13, 50778], "temperature": 0.0, "avg_logprob": -0.2899911668565538, "compression_ratio": 1.716, "no_speech_prob": 4.985940540791489e-05}, {"id": 1196, "seek": 562036, "start": 5628.639999999999, "end": 5633.48, "text": " Although stable diffusion adds it at 32 by 32.", "tokens": [50778, 5780, 8351, 25242, 10860, 309, 412, 8858, 538, 8858, 13, 51020], "temperature": 0.0, "avg_logprob": -0.2899911668565538, "compression_ratio": 1.716, "no_speech_prob": 4.985940540791489e-05}, {"id": 1197, "seek": 562036, "start": 5633.48, "end": 5637.44, "text": " Because remember, they're using latence, which we'll see very shortly, I guess in the next", "tokens": [51020, 1436, 1604, 11, 436, 434, 1228, 287, 267, 655, 11, 597, 321, 603, 536, 588, 13392, 11, 286, 2041, 294, 264, 958, 51218], "temperature": 0.0, "avg_logprob": -0.2899911668565538, "compression_ratio": 1.716, "no_speech_prob": 4.985940540791489e-05}, {"id": 1198, "seek": 562036, "start": 5637.44, "end": 5638.44, "text": " lesson.", "tokens": [51218, 6898, 13, 51268], "temperature": 0.0, "avg_logprob": -0.2899911668565538, "compression_ratio": 1.716, "no_speech_prob": 4.985940540791489e-05}, {"id": 1199, "seek": 562036, "start": 5638.44, "end": 5642.719999999999, "text": " So it starts at 64 by 64 and then they add attention at 32 by 32.", "tokens": [51268, 407, 309, 3719, 412, 12145, 538, 12145, 293, 550, 436, 909, 3202, 412, 8858, 538, 8858, 13, 51482], "temperature": 0.0, "avg_logprob": -0.2899911668565538, "compression_ratio": 1.716, "no_speech_prob": 4.985940540791489e-05}, {"id": 1200, "seek": 562036, "start": 5642.719999999999, "end": 5645.44, "text": " So we're again, we're replicating stable diffusion here.", "tokens": [51482, 407, 321, 434, 797, 11, 321, 434, 3248, 30541, 8351, 25242, 510, 13, 51618], "temperature": 0.0, "avg_logprob": -0.2899911668565538, "compression_ratio": 1.716, "no_speech_prob": 4.985940540791489e-05}, {"id": 1201, "seek": 562036, "start": 5645.44, "end": 5649.639999999999, "text": " Stable diffusion uses attention start at index one.", "tokens": [51618, 745, 712, 25242, 4960, 3202, 722, 412, 8186, 472, 13, 51828], "temperature": 0.0, "avg_logprob": -0.2899911668565538, "compression_ratio": 1.716, "no_speech_prob": 4.985940540791489e-05}, {"id": 1202, "seek": 564964, "start": 5649.92, "end": 5657.08, "text": " So when we go self.downs.append, the down block has zero attention channels if we're", "tokens": [50378, 407, 562, 321, 352, 2698, 13, 5093, 82, 13, 1746, 521, 11, 264, 760, 3461, 575, 4018, 3202, 9235, 498, 321, 434, 50736], "temperature": 0.0, "avg_logprob": -0.3104616717288369, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.00019411291577853262}, {"id": 1203, "seek": 564964, "start": 5657.08, "end": 5660.88, "text": " not up to that block yet.", "tokens": [50736, 406, 493, 281, 300, 3461, 1939, 13, 50926], "temperature": 0.0, "avg_logprob": -0.3104616717288369, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.00019411291577853262}, {"id": 1204, "seek": 564964, "start": 5660.88, "end": 5672.52, "text": " And ditto on the up block, except we have to count from the end blocks.", "tokens": [50926, 400, 274, 34924, 322, 264, 493, 3461, 11, 3993, 321, 362, 281, 1207, 490, 264, 917, 8474, 13, 51508], "temperature": 0.0, "avg_logprob": -0.3104616717288369, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.00019411291577853262}, {"id": 1205, "seek": 564964, "start": 5672.52, "end": 5676.92, "text": " Now I think about it, that should have attention as well.", "tokens": [51508, 823, 286, 519, 466, 309, 11, 300, 820, 362, 3202, 382, 731, 13, 51728], "temperature": 0.0, "avg_logprob": -0.3104616717288369, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.00019411291577853262}, {"id": 1206, "seek": 564964, "start": 5676.92, "end": 5679.0, "text": " The mid block.", "tokens": [51728, 440, 2062, 3461, 13, 51832], "temperature": 0.0, "avg_logprob": -0.3104616717288369, "compression_ratio": 1.4912280701754386, "no_speech_prob": 0.00019411291577853262}, {"id": 1207, "seek": 567900, "start": 5679.0, "end": 5681.44, "text": " So that's missing.", "tokens": [50364, 407, 300, 311, 5361, 13, 50486], "temperature": 0.0, "avg_logprob": -0.3917751873240751, "compression_ratio": 1.5, "no_speech_prob": 2.796917578962166e-05}, {"id": 1208, "seek": 567900, "start": 5681.44, "end": 5687.16, "text": " Yeah, so the forward actually doesn't change at all for attention.", "tokens": [50486, 865, 11, 370, 264, 2128, 767, 1177, 380, 1319, 412, 439, 337, 3202, 13, 50772], "temperature": 0.0, "avg_logprob": -0.3917751873240751, "compression_ratio": 1.5, "no_speech_prob": 2.796917578962166e-05}, {"id": 1209, "seek": 567900, "start": 5687.16, "end": 5689.16, "text": " It's only the init.", "tokens": [50772, 467, 311, 787, 264, 3157, 13, 50872], "temperature": 0.0, "avg_logprob": -0.3917751873240751, "compression_ratio": 1.5, "no_speech_prob": 2.796917578962166e-05}, {"id": 1210, "seek": 567900, "start": 5689.16, "end": 5692.92, "text": " Yeah, so we can train that.", "tokens": [50872, 865, 11, 370, 321, 393, 3847, 300, 13, 51060], "temperature": 0.0, "avg_logprob": -0.3917751873240751, "compression_ratio": 1.5, "no_speech_prob": 2.796917578962166e-05}, {"id": 1211, "seek": 567900, "start": 5692.92, "end": 5703.92, "text": " And so previously, yeah, we got without attention, we got to 137.", "tokens": [51060, 400, 370, 8046, 11, 1338, 11, 321, 658, 1553, 3202, 11, 321, 658, 281, 3705, 22, 13, 51610], "temperature": 0.0, "avg_logprob": -0.3917751873240751, "compression_ratio": 1.5, "no_speech_prob": 2.796917578962166e-05}, {"id": 1212, "seek": 567900, "start": 5703.92, "end": 5704.92, "text": " And with attention.", "tokens": [51610, 400, 365, 3202, 13, 51660], "temperature": 0.0, "avg_logprob": -0.3917751873240751, "compression_ratio": 1.5, "no_speech_prob": 2.796917578962166e-05}, {"id": 1213, "seek": 570492, "start": 5704.92, "end": 5713.8, "text": " Oh, we can't compare directly because we've changed from keras to cosine.", "tokens": [50364, 876, 11, 321, 393, 380, 6794, 3838, 570, 321, 600, 3105, 490, 350, 6985, 281, 23565, 13, 50808], "temperature": 0.0, "avg_logprob": -0.37555432606892414, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0010322205489501357}, {"id": 1214, "seek": 570492, "start": 5713.8, "end": 5718.32, "text": " We can compare the sampling though.", "tokens": [50808, 492, 393, 6794, 264, 21179, 1673, 13, 51034], "temperature": 0.0, "avg_logprob": -0.37555432606892414, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0010322205489501357}, {"id": 1215, "seek": 570492, "start": 5718.32, "end": 5720.92, "text": " So we're getting, what are we getting?", "tokens": [51034, 407, 321, 434, 1242, 11, 437, 366, 321, 1242, 30, 51164], "temperature": 0.0, "avg_logprob": -0.37555432606892414, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0010322205489501357}, {"id": 1216, "seek": 570492, "start": 5720.92, "end": 5723.86, "text": " Four, five, five, five.", "tokens": [51164, 7451, 11, 1732, 11, 1732, 11, 1732, 13, 51311], "temperature": 0.0, "avg_logprob": -0.37555432606892414, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0010322205489501357}, {"id": 1217, "seek": 570492, "start": 5723.86, "end": 5732.28, "text": " It's very hard to tell if it's any better or not, because, well again, you know, a cosine", "tokens": [51311, 467, 311, 588, 1152, 281, 980, 498, 309, 311, 604, 1101, 420, 406, 11, 570, 11, 731, 797, 11, 291, 458, 11, 257, 23565, 51732], "temperature": 0.0, "avg_logprob": -0.37555432606892414, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0010322205489501357}, {"id": 1218, "seek": 570492, "start": 5732.28, "end": 5733.28, "text": " schedules better.", "tokens": [51732, 28078, 1101, 13, 51782], "temperature": 0.0, "avg_logprob": -0.37555432606892414, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.0010322205489501357}, {"id": 1219, "seek": 573328, "start": 5733.639999999999, "end": 5740.88, "text": " When I've done kind of direct like with like, I haven't managed to find any obvious improvements", "tokens": [50382, 1133, 286, 600, 1096, 733, 295, 2047, 411, 365, 411, 11, 286, 2378, 380, 6453, 281, 915, 604, 6322, 13797, 50744], "temperature": 0.0, "avg_logprob": -0.3806990444070042, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.00031015119748190045}, {"id": 1220, "seek": 573328, "start": 5740.88, "end": 5741.88, "text": " from adding attention.", "tokens": [50744, 490, 5127, 3202, 13, 50794], "temperature": 0.0, "avg_logprob": -0.3806990444070042, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.00031015119748190045}, {"id": 1221, "seek": 573328, "start": 5741.88, "end": 5745.5599999999995, "text": " But I mean, it's doing fine, you know, four is great.", "tokens": [50794, 583, 286, 914, 11, 309, 311, 884, 2489, 11, 291, 458, 11, 1451, 307, 869, 13, 50978], "temperature": 0.0, "avg_logprob": -0.3806990444070042, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.00031015119748190045}, {"id": 1222, "seek": 573328, "start": 5745.5599999999995, "end": 5746.5599999999995, "text": " Yeah.", "tokens": [50978, 865, 13, 51028], "temperature": 0.0, "avg_logprob": -0.3806990444070042, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.00031015119748190045}, {"id": 1223, "seek": 573328, "start": 5746.5599999999995, "end": 5749.639999999999, "text": " All right.", "tokens": [51028, 1057, 558, 13, 51182], "temperature": 0.0, "avg_logprob": -0.3806990444070042, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.00031015119748190045}, {"id": 1224, "seek": 573328, "start": 5749.639999999999, "end": 5754.16, "text": " So then finally, did you want to add anything before we go into a conditional model?", "tokens": [51182, 407, 550, 2721, 11, 630, 291, 528, 281, 909, 1340, 949, 321, 352, 666, 257, 27708, 2316, 30, 51408], "temperature": 0.0, "avg_logprob": -0.3806990444070042, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.00031015119748190045}, {"id": 1225, "seek": 573328, "start": 5754.16, "end": 5760.5599999999995, "text": " I was just going to make a note that, like, I guess just to clarify, for the attention,", "tokens": [51408, 286, 390, 445, 516, 281, 652, 257, 3637, 300, 11, 411, 11, 286, 2041, 445, 281, 17594, 11, 337, 264, 3202, 11, 51728], "temperature": 0.0, "avg_logprob": -0.3806990444070042, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.00031015119748190045}, {"id": 1226, "seek": 576056, "start": 5760.56, "end": 5765.0, "text": " part of the motivation was certainly to do the sort of spatial mixing and kind of like,", "tokens": [50364, 644, 295, 264, 12335, 390, 3297, 281, 360, 264, 1333, 295, 23598, 11983, 293, 733, 295, 411, 11, 50586], "temperature": 0.0, "avg_logprob": -0.26945969462394714, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.2449294924736023}, {"id": 1227, "seek": 576056, "start": 5765.0, "end": 5768.64, "text": " yeah, to get from different parts of the image and mix it.", "tokens": [50586, 1338, 11, 281, 483, 490, 819, 3166, 295, 264, 3256, 293, 2890, 309, 13, 50768], "temperature": 0.0, "avg_logprob": -0.26945969462394714, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.2449294924736023}, {"id": 1228, "seek": 576056, "start": 5768.64, "end": 5773.92, "text": " But then the problem is if it's too early, where you do have one of the more individual", "tokens": [50768, 583, 550, 264, 1154, 307, 498, 309, 311, 886, 2440, 11, 689, 291, 360, 362, 472, 295, 264, 544, 2609, 51032], "temperature": 0.0, "avg_logprob": -0.26945969462394714, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.2449294924736023}, {"id": 1229, "seek": 576056, "start": 5773.92, "end": 5777.8, "text": " pixels, then the memory is very high.", "tokens": [51032, 18668, 11, 550, 264, 4675, 307, 588, 1090, 13, 51226], "temperature": 0.0, "avg_logprob": -0.26945969462394714, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.2449294924736023}, {"id": 1230, "seek": 576056, "start": 5777.8, "end": 5782.360000000001, "text": " So it seems like you have to get that balance of where you don't, you kind of want it to", "tokens": [51226, 407, 309, 2544, 411, 291, 362, 281, 483, 300, 4772, 295, 689, 291, 500, 380, 11, 291, 733, 295, 528, 309, 281, 51454], "temperature": 0.0, "avg_logprob": -0.26945969462394714, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.2449294924736023}, {"id": 1231, "seek": 576056, "start": 5782.360000000001, "end": 5786.4800000000005, "text": " be early so you can do some of that mixing, but you don't want to be too early where then", "tokens": [51454, 312, 2440, 370, 291, 393, 360, 512, 295, 300, 11983, 11, 457, 291, 500, 380, 528, 281, 312, 886, 2440, 689, 550, 51660], "temperature": 0.0, "avg_logprob": -0.26945969462394714, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.2449294924736023}, {"id": 1232, "seek": 576056, "start": 5786.4800000000005, "end": 5789.6, "text": " the memory usage is too high.", "tokens": [51660, 264, 4675, 14924, 307, 886, 1090, 13, 51816], "temperature": 0.0, "avg_logprob": -0.26945969462394714, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.2449294924736023}, {"id": 1233, "seek": 578960, "start": 5789.64, "end": 5793.4400000000005, "text": " So it seems like there is certainly kind of the balance of trying to find maybe that right", "tokens": [50366, 407, 309, 2544, 411, 456, 307, 3297, 733, 295, 264, 4772, 295, 1382, 281, 915, 1310, 300, 558, 50556], "temperature": 0.0, "avg_logprob": -0.28667502447005805, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.0488445907831192}, {"id": 1234, "seek": 578960, "start": 5793.4400000000005, "end": 5796.52, "text": " place where to add attention into your network.", "tokens": [50556, 1081, 689, 281, 909, 3202, 666, 428, 3209, 13, 50710], "temperature": 0.0, "avg_logprob": -0.28667502447005805, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.0488445907831192}, {"id": 1235, "seek": 578960, "start": 5796.52, "end": 5798.320000000001, "text": " So I just thought I was just thinking about that.", "tokens": [50710, 407, 286, 445, 1194, 286, 390, 445, 1953, 466, 300, 13, 50800], "temperature": 0.0, "avg_logprob": -0.28667502447005805, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.0488445907831192}, {"id": 1236, "seek": 578960, "start": 5798.320000000001, "end": 5800.72, "text": " And maybe that's a point worth noting.", "tokens": [50800, 400, 1310, 300, 311, 257, 935, 3163, 26801, 13, 50920], "temperature": 0.0, "avg_logprob": -0.28667502447005805, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.0488445907831192}, {"id": 1237, "seek": 578960, "start": 5800.72, "end": 5803.0, "text": " Yeah, for sure.", "tokens": [50920, 865, 11, 337, 988, 13, 51034], "temperature": 0.0, "avg_logprob": -0.28667502447005805, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.0488445907831192}, {"id": 1238, "seek": 578960, "start": 5803.0, "end": 5806.6, "text": " There is a trick, which is like what they do in, for example, vision transformers or", "tokens": [51034, 821, 307, 257, 4282, 11, 597, 307, 411, 437, 436, 360, 294, 11, 337, 1365, 11, 5201, 4088, 433, 420, 51214], "temperature": 0.0, "avg_logprob": -0.28667502447005805, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.0488445907831192}, {"id": 1239, "seek": 578960, "start": 5806.6, "end": 5814.88, "text": " the DIT, the diffusion with transformers, which is that if you take like a six, eight", "tokens": [51214, 264, 413, 3927, 11, 264, 25242, 365, 4088, 433, 11, 597, 307, 300, 498, 291, 747, 411, 257, 2309, 11, 3180, 51628], "temperature": 0.0, "avg_logprob": -0.28667502447005805, "compression_ratio": 1.6693548387096775, "no_speech_prob": 0.0488445907831192}, {"id": 1240, "seek": 581488, "start": 5814.88, "end": 5820.12, "text": " by eight patch of the image and you flatten that all out or you run that through some", "tokens": [50364, 538, 3180, 9972, 295, 264, 3256, 293, 291, 24183, 300, 439, 484, 420, 291, 1190, 300, 807, 512, 50626], "temperature": 0.0, "avg_logprob": -0.27325302992409806, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.32722461223602295}, {"id": 1241, "seek": 581488, "start": 5820.12, "end": 5825.16, "text": " like convolutional thing to turn it into a one by one by some larger number of channels,", "tokens": [50626, 411, 45216, 304, 551, 281, 1261, 309, 666, 257, 472, 538, 472, 538, 512, 4833, 1230, 295, 9235, 11, 50878], "temperature": 0.0, "avg_logprob": -0.27325302992409806, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.32722461223602295}, {"id": 1242, "seek": 581488, "start": 5825.16, "end": 5830.52, "text": " but you can reduce the spatial dimension by increasing the number of channels.", "tokens": [50878, 457, 291, 393, 5407, 264, 23598, 10139, 538, 5662, 264, 1230, 295, 9235, 13, 51146], "temperature": 0.0, "avg_logprob": -0.27325302992409806, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.32722461223602295}, {"id": 1243, "seek": 581488, "start": 5830.52, "end": 5834.24, "text": " And that gets you down to like a manageable size where you can then start doing attention", "tokens": [51146, 400, 300, 2170, 291, 760, 281, 411, 257, 38798, 2744, 689, 291, 393, 550, 722, 884, 3202, 51332], "temperature": 0.0, "avg_logprob": -0.27325302992409806, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.32722461223602295}, {"id": 1244, "seek": 581488, "start": 5834.24, "end": 5838.4800000000005, "text": " as well. So that's another trick is like patching where you take a patch of the image and you", "tokens": [51332, 382, 731, 13, 407, 300, 311, 1071, 4282, 307, 411, 9972, 278, 689, 291, 747, 257, 9972, 295, 264, 3256, 293, 291, 51544], "temperature": 0.0, "avg_logprob": -0.27325302992409806, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.32722461223602295}, {"id": 1245, "seek": 581488, "start": 5838.4800000000005, "end": 5843.16, "text": " focus on that as some number, like some embedding dimension or whatever you like to think of", "tokens": [51544, 1879, 322, 300, 382, 512, 1230, 11, 411, 512, 12240, 3584, 10139, 420, 2035, 291, 411, 281, 519, 295, 51778], "temperature": 0.0, "avg_logprob": -0.27325302992409806, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.32722461223602295}, {"id": 1246, "seek": 584316, "start": 5843.16, "end": 5847.96, "text": " it, but as a one by one rather than an eight by eight or a 16 by 16.", "tokens": [50364, 309, 11, 457, 382, 257, 472, 538, 472, 2831, 813, 364, 3180, 538, 3180, 420, 257, 3165, 538, 3165, 13, 50604], "temperature": 0.0, "avg_logprob": -0.2886717210122205, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.020328089594841003}, {"id": 1247, "seek": 584316, "start": 5847.96, "end": 5854.48, "text": " And so that's how you'll see 32 by 32 patch models, like some of the smaller clip models", "tokens": [50604, 400, 370, 300, 311, 577, 291, 603, 536, 8858, 538, 8858, 9972, 5245, 11, 411, 512, 295, 264, 4356, 7353, 5245, 50930], "temperature": 0.0, "avg_logprob": -0.2886717210122205, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.020328089594841003}, {"id": 1248, "seek": 584316, "start": 5854.48, "end": 5860.2, "text": " or 14 by 14 patch for some of the larger like DIT classification models and things like", "tokens": [50930, 420, 3499, 538, 3499, 9972, 337, 512, 295, 264, 4833, 411, 413, 3927, 21538, 5245, 293, 721, 411, 51216], "temperature": 0.0, "avg_logprob": -0.2886717210122205, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.020328089594841003}, {"id": 1249, "seek": 584316, "start": 5860.2, "end": 5861.2, "text": " that.", "tokens": [51216, 300, 13, 51266], "temperature": 0.0, "avg_logprob": -0.2886717210122205, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.020328089594841003}, {"id": 1250, "seek": 584316, "start": 5861.2, "end": 5862.2, "text": " So that's another trick.", "tokens": [51266, 407, 300, 311, 1071, 4282, 13, 51316], "temperature": 0.0, "avg_logprob": -0.2886717210122205, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.020328089594841003}, {"id": 1251, "seek": 584316, "start": 5862.2, "end": 5866.599999999999, "text": " Yeah, I guess that's the, yeah, that's mainly used when you have like a full transformer", "tokens": [51316, 865, 11, 286, 2041, 300, 311, 264, 11, 1338, 11, 300, 311, 8704, 1143, 562, 291, 362, 411, 257, 1577, 31782, 51536], "temperature": 0.0, "avg_logprob": -0.2886717210122205, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.020328089594841003}, {"id": 1252, "seek": 584316, "start": 5866.599999999999, "end": 5868.5599999999995, "text": " network, I guess.", "tokens": [51536, 3209, 11, 286, 2041, 13, 51634], "temperature": 0.0, "avg_logprob": -0.2886717210122205, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.020328089594841003}, {"id": 1253, "seek": 586856, "start": 5868.56, "end": 5873.360000000001, "text": " And then this is one where we have that sort of incorporating the attention into a convolutional", "tokens": [50364, 400, 550, 341, 307, 472, 689, 321, 362, 300, 1333, 295, 33613, 264, 3202, 666, 257, 45216, 304, 50604], "temperature": 0.0, "avg_logprob": -0.28556064356153255, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.03566887602210045}, {"id": 1254, "seek": 586856, "start": 5873.360000000001, "end": 5874.68, "text": " network.", "tokens": [50604, 3209, 13, 50670], "temperature": 0.0, "avg_logprob": -0.28556064356153255, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.03566887602210045}, {"id": 1255, "seek": 586856, "start": 5874.68, "end": 5880.160000000001, "text": " So there's certainly, I guess, yeah, for different sorts of networks, different tricks, but yeah.", "tokens": [50670, 407, 456, 311, 3297, 11, 286, 2041, 11, 1338, 11, 337, 819, 7527, 295, 9590, 11, 819, 11733, 11, 457, 1338, 13, 50944], "temperature": 0.0, "avg_logprob": -0.28556064356153255, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.03566887602210045}, {"id": 1256, "seek": 586856, "start": 5880.160000000001, "end": 5881.160000000001, "text": " Yeah.", "tokens": [50944, 865, 13, 50994], "temperature": 0.0, "avg_logprob": -0.28556064356153255, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.03566887602210045}, {"id": 1257, "seek": 586856, "start": 5881.160000000001, "end": 5888.52, "text": " And I haven't decided yet if we're going to look at VIT or not.", "tokens": [50994, 400, 286, 2378, 380, 3047, 1939, 498, 321, 434, 516, 281, 574, 412, 691, 3927, 420, 406, 13, 51362], "temperature": 0.0, "avg_logprob": -0.28556064356153255, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.03566887602210045}, {"id": 1258, "seek": 586856, "start": 5888.52, "end": 5890.160000000001, "text": " Maybe we should, based on what you're describing.", "tokens": [51362, 2704, 321, 820, 11, 2361, 322, 437, 291, 434, 16141, 13, 51444], "temperature": 0.0, "avg_logprob": -0.28556064356153255, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.03566887602210045}, {"id": 1259, "seek": 586856, "start": 5890.160000000001, "end": 5897.84, "text": " I was just going to mention though, that since you mentioned transformers, we've actually", "tokens": [51444, 286, 390, 445, 516, 281, 2152, 1673, 11, 300, 1670, 291, 2835, 4088, 433, 11, 321, 600, 767, 51828], "temperature": 0.0, "avg_logprob": -0.28556064356153255, "compression_ratio": 1.6070038910505837, "no_speech_prob": 0.03566887602210045}, {"id": 1260, "seek": 589784, "start": 5898.12, "end": 5900.68, "text": " now got everything we need to create a transformer.", "tokens": [50378, 586, 658, 1203, 321, 643, 281, 1884, 257, 31782, 13, 50506], "temperature": 0.0, "avg_logprob": -0.3246037011007661, "compression_ratio": 1.8309178743961352, "no_speech_prob": 2.885710637201555e-05}, {"id": 1261, "seek": 589784, "start": 5900.68, "end": 5903.88, "text": " Here's a transformer block with embeddings.", "tokens": [50506, 1692, 311, 257, 31782, 3461, 365, 12240, 29432, 13, 50666], "temperature": 0.0, "avg_logprob": -0.3246037011007661, "compression_ratio": 1.8309178743961352, "no_speech_prob": 2.885710637201555e-05}, {"id": 1262, "seek": 589784, "start": 5903.88, "end": 5907.16, "text": " And a transformer block with embeddings is exactly the same embeddings that we've seen", "tokens": [50666, 400, 257, 31782, 3461, 365, 12240, 29432, 307, 2293, 264, 912, 12240, 29432, 300, 321, 600, 1612, 50830], "temperature": 0.0, "avg_logprob": -0.3246037011007661, "compression_ratio": 1.8309178743961352, "no_speech_prob": 2.885710637201555e-05}, {"id": 1263, "seek": 589784, "start": 5907.16, "end": 5908.84, "text": " before.", "tokens": [50830, 949, 13, 50914], "temperature": 0.0, "avg_logprob": -0.3246037011007661, "compression_ratio": 1.8309178743961352, "no_speech_prob": 2.885710637201555e-05}, {"id": 1264, "seek": 589784, "start": 5908.84, "end": 5911.88, "text": " And then we add attention as we've seen before.", "tokens": [50914, 400, 550, 321, 909, 3202, 382, 321, 600, 1612, 949, 13, 51066], "temperature": 0.0, "avg_logprob": -0.3246037011007661, "compression_ratio": 1.8309178743961352, "no_speech_prob": 2.885710637201555e-05}, {"id": 1265, "seek": 589784, "start": 5911.88, "end": 5913.96, "text": " There's a scale and shift.", "tokens": [51066, 821, 311, 257, 4373, 293, 5513, 13, 51170], "temperature": 0.0, "avg_logprob": -0.3246037011007661, "compression_ratio": 1.8309178743961352, "no_speech_prob": 2.885710637201555e-05}, {"id": 1266, "seek": 589784, "start": 5913.96, "end": 5923.52, "text": " And then we pass it through an MLP, which is just a linear layer, an activation, a normalize,", "tokens": [51170, 400, 550, 321, 1320, 309, 807, 364, 21601, 47, 11, 597, 307, 445, 257, 8213, 4583, 11, 364, 24433, 11, 257, 2710, 1125, 11, 51648], "temperature": 0.0, "avg_logprob": -0.3246037011007661, "compression_ratio": 1.8309178743961352, "no_speech_prob": 2.885710637201555e-05}, {"id": 1267, "seek": 589784, "start": 5923.52, "end": 5924.52, "text": " and a linear layer.", "tokens": [51648, 293, 257, 8213, 4583, 13, 51698], "temperature": 0.0, "avg_logprob": -0.3246037011007661, "compression_ratio": 1.8309178743961352, "no_speech_prob": 2.885710637201555e-05}, {"id": 1268, "seek": 592452, "start": 5925.240000000001, "end": 5929.280000000001, "text": " For whatever reason, this is, you know, Galue, which is just another activation function,", "tokens": [50400, 1171, 2035, 1778, 11, 341, 307, 11, 291, 458, 11, 7336, 622, 11, 597, 307, 445, 1071, 24433, 2445, 11, 50602], "temperature": 0.0, "avg_logprob": -0.3432821469886281, "compression_ratio": 1.5387596899224807, "no_speech_prob": 3.071804530918598e-05}, {"id": 1269, "seek": 592452, "start": 5929.280000000001, "end": 5931.64, "text": " is what people always use in transformers.", "tokens": [50602, 307, 437, 561, 1009, 764, 294, 4088, 433, 13, 50720], "temperature": 0.0, "avg_logprob": -0.3432821469886281, "compression_ratio": 1.5387596899224807, "no_speech_prob": 3.071804530918598e-05}, {"id": 1270, "seek": 592452, "start": 5931.64, "end": 5938.240000000001, "text": " For reasons I suspect don't quite make sense in vision, everybody uses layer norm.", "tokens": [50720, 1171, 4112, 286, 9091, 500, 380, 1596, 652, 2020, 294, 5201, 11, 2201, 4960, 4583, 2026, 13, 51050], "temperature": 0.0, "avg_logprob": -0.3432821469886281, "compression_ratio": 1.5387596899224807, "no_speech_prob": 3.071804530918598e-05}, {"id": 1271, "seek": 592452, "start": 5938.240000000001, "end": 5941.64, "text": " And again, I was just trying to replicate an existing paper, but this is just a standard", "tokens": [51050, 400, 797, 11, 286, 390, 445, 1382, 281, 25356, 364, 6741, 3035, 11, 457, 341, 307, 445, 257, 3832, 51220], "temperature": 0.0, "avg_logprob": -0.3432821469886281, "compression_ratio": 1.5387596899224807, "no_speech_prob": 3.071804530918598e-05}, {"id": 1272, "seek": 592452, "start": 5941.64, "end": 5942.64, "text": " MLP.", "tokens": [51220, 21601, 47, 13, 51270], "temperature": 0.0, "avg_logprob": -0.3432821469886281, "compression_ratio": 1.5387596899224807, "no_speech_prob": 3.071804530918598e-05}, {"id": 1273, "seek": 592452, "start": 5942.64, "end": 5949.92, "text": " So if you do, so in fact, if we get rid of the embeddings, just to show you a true pure", "tokens": [51270, 407, 498, 291, 360, 11, 370, 294, 1186, 11, 498, 321, 483, 3973, 295, 264, 12240, 29432, 11, 445, 281, 855, 291, 257, 2074, 6075, 51634], "temperature": 0.0, "avg_logprob": -0.3432821469886281, "compression_ratio": 1.5387596899224807, "no_speech_prob": 3.071804530918598e-05}, {"id": 1274, "seek": 594992, "start": 5949.92, "end": 5953.92, "text": " transformer.", "tokens": [50364, 31782, 13, 50564], "temperature": 0.0, "avg_logprob": -0.30737874348958333, "compression_ratio": 1.694267515923567, "no_speech_prob": 0.026354502886533737}, {"id": 1275, "seek": 594992, "start": 5953.92, "end": 5960.52, "text": " Okay, here's a pure transformer block, right?", "tokens": [50564, 1033, 11, 510, 311, 257, 6075, 31782, 3461, 11, 558, 30, 50894], "temperature": 0.0, "avg_logprob": -0.30737874348958333, "compression_ratio": 1.694267515923567, "no_speech_prob": 0.026354502886533737}, {"id": 1276, "seek": 594992, "start": 5960.52, "end": 5967.6, "text": " So it's just normalize, attention, add, normalize, multilayer perceptron, add.", "tokens": [50894, 407, 309, 311, 445, 2710, 1125, 11, 3202, 11, 909, 11, 2710, 1125, 11, 2120, 388, 11167, 43276, 2044, 11, 909, 13, 51248], "temperature": 0.0, "avg_logprob": -0.30737874348958333, "compression_ratio": 1.694267515923567, "no_speech_prob": 0.026354502886533737}, {"id": 1277, "seek": 594992, "start": 5967.6, "end": 5969.96, "text": " That's all a transformer block is.", "tokens": [51248, 663, 311, 439, 257, 31782, 3461, 307, 13, 51366], "temperature": 0.0, "avg_logprob": -0.30737874348958333, "compression_ratio": 1.694267515923567, "no_speech_prob": 0.026354502886533737}, {"id": 1278, "seek": 594992, "start": 5969.96, "end": 5972.08, "text": " And then what's a transformer network?", "tokens": [51366, 400, 550, 437, 311, 257, 31782, 3209, 30, 51472], "temperature": 0.0, "avg_logprob": -0.30737874348958333, "compression_ratio": 1.694267515923567, "no_speech_prob": 0.026354502886533737}, {"id": 1279, "seek": 594992, "start": 5972.08, "end": 5975.72, "text": " A transformer network is a sequential of transformers.", "tokens": [51472, 316, 31782, 3209, 307, 257, 42881, 295, 4088, 433, 13, 51654], "temperature": 0.0, "avg_logprob": -0.30737874348958333, "compression_ratio": 1.694267515923567, "no_speech_prob": 0.026354502886533737}, {"id": 1280, "seek": 597572, "start": 5975.8, "end": 5985.04, "text": " And so in this diffusion model, I replaced my mid block with a list of sequential transformer", "tokens": [50368, 400, 370, 294, 341, 25242, 2316, 11, 286, 10772, 452, 2062, 3461, 365, 257, 1329, 295, 42881, 31782, 50830], "temperature": 0.0, "avg_logprob": -0.3105485594117796, "compression_ratio": 1.6162162162162161, "no_speech_prob": 0.0185457244515419}, {"id": 1281, "seek": 597572, "start": 5985.04, "end": 5986.56, "text": " blocks.", "tokens": [50830, 8474, 13, 50906], "temperature": 0.0, "avg_logprob": -0.3105485594117796, "compression_ratio": 1.6162162162162161, "no_speech_prob": 0.0185457244515419}, {"id": 1282, "seek": 597572, "start": 5986.56, "end": 5990.280000000001, "text": " So that is a transformer network.", "tokens": [50906, 407, 300, 307, 257, 31782, 3209, 13, 51092], "temperature": 0.0, "avg_logprob": -0.3105485594117796, "compression_ratio": 1.6162162162162161, "no_speech_prob": 0.0185457244515419}, {"id": 1283, "seek": 597572, "start": 5990.280000000001, "end": 5997.52, "text": " And to prove it, I then replace, this is another version in which I replaced that entire thing", "tokens": [51092, 400, 281, 7081, 309, 11, 286, 550, 7406, 11, 341, 307, 1071, 3037, 294, 597, 286, 10772, 300, 2302, 551, 51454], "temperature": 0.0, "avg_logprob": -0.3105485594117796, "compression_ratio": 1.6162162162162161, "no_speech_prob": 0.0185457244515419}, {"id": 1284, "seek": 597572, "start": 5997.52, "end": 6004.26, "text": " with the PyTorch transformers encoder, which is just called encoder.", "tokens": [51454, 365, 264, 9953, 51, 284, 339, 4088, 433, 2058, 19866, 11, 597, 307, 445, 1219, 2058, 19866, 13, 51791], "temperature": 0.0, "avg_logprob": -0.3105485594117796, "compression_ratio": 1.6162162162162161, "no_speech_prob": 0.0185457244515419}, {"id": 1285, "seek": 600426, "start": 6004.3, "end": 6006.860000000001, "text": " This is just taken from PyTorch.", "tokens": [50366, 639, 307, 445, 2726, 490, 9953, 51, 284, 339, 13, 50494], "temperature": 0.0, "avg_logprob": -0.2707449197769165, "compression_ratio": 1.593073593073593, "no_speech_prob": 2.6688448997447267e-05}, {"id": 1286, "seek": 600426, "start": 6006.860000000001, "end": 6009.38, "text": " And so that's the encoder.", "tokens": [50494, 400, 370, 300, 311, 264, 2058, 19866, 13, 50620], "temperature": 0.0, "avg_logprob": -0.2707449197769165, "compression_ratio": 1.593073593073593, "no_speech_prob": 2.6688448997447267e-05}, {"id": 1287, "seek": 600426, "start": 6009.38, "end": 6013.3, "text": " And I just replaced it with that.", "tokens": [50620, 400, 286, 445, 10772, 309, 365, 300, 13, 50816], "temperature": 0.0, "avg_logprob": -0.2707449197769165, "compression_ratio": 1.593073593073593, "no_speech_prob": 2.6688448997447267e-05}, {"id": 1288, "seek": 600426, "start": 6013.3, "end": 6016.9400000000005, "text": " So yeah, we've now built transformers.", "tokens": [50816, 407, 1338, 11, 321, 600, 586, 3094, 4088, 433, 13, 50998], "temperature": 0.0, "avg_logprob": -0.2707449197769165, "compression_ratio": 1.593073593073593, "no_speech_prob": 2.6688448997447267e-05}, {"id": 1289, "seek": 600426, "start": 6016.9400000000005, "end": 6020.3, "text": " Now, okay, why aren't we using them right now?", "tokens": [50998, 823, 11, 1392, 11, 983, 3212, 380, 321, 1228, 552, 558, 586, 30, 51166], "temperature": 0.0, "avg_logprob": -0.2707449197769165, "compression_ratio": 1.593073593073593, "no_speech_prob": 2.6688448997447267e-05}, {"id": 1290, "seek": 600426, "start": 6020.3, "end": 6024.7, "text": " And why did I just say I'm not even sure if we're going to do VIT, which is vision transformers?", "tokens": [51166, 400, 983, 630, 286, 445, 584, 286, 478, 406, 754, 988, 498, 321, 434, 516, 281, 360, 691, 3927, 11, 597, 307, 5201, 4088, 433, 30, 51386], "temperature": 0.0, "avg_logprob": -0.2707449197769165, "compression_ratio": 1.593073593073593, "no_speech_prob": 2.6688448997447267e-05}, {"id": 1291, "seek": 600426, "start": 6024.7, "end": 6031.7, "text": " The reason is that transformers, you know, they're doing something very interesting,", "tokens": [51386, 440, 1778, 307, 300, 4088, 433, 11, 291, 458, 11, 436, 434, 884, 746, 588, 1880, 11, 51736], "temperature": 0.0, "avg_logprob": -0.2707449197769165, "compression_ratio": 1.593073593073593, "no_speech_prob": 2.6688448997447267e-05}, {"id": 1292, "seek": 600426, "start": 6031.7, "end": 6032.7, "text": " right?", "tokens": [51736, 558, 30, 51786], "temperature": 0.0, "avg_logprob": -0.2707449197769165, "compression_ratio": 1.593073593073593, "no_speech_prob": 2.6688448997447267e-05}, {"id": 1293, "seek": 603270, "start": 6032.7, "end": 6038.0599999999995, "text": " Which is, remember, we're just doing 1D versions here, right?", "tokens": [50364, 3013, 307, 11, 1604, 11, 321, 434, 445, 884, 502, 35, 9606, 510, 11, 558, 30, 50632], "temperature": 0.0, "avg_logprob": -0.3206694466727121, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.0001313517423113808}, {"id": 1294, "seek": 603270, "start": 6038.0599999999995, "end": 6047.42, "text": " So transformers are taking something where we've got a sequence, right?", "tokens": [50632, 407, 4088, 433, 366, 1940, 746, 689, 321, 600, 658, 257, 8310, 11, 558, 30, 51100], "temperature": 0.0, "avg_logprob": -0.3206694466727121, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.0001313517423113808}, {"id": 1295, "seek": 603270, "start": 6047.42, "end": 6052.38, "text": " Which in our case is pixels height by width, but let's call it a sequence.", "tokens": [51100, 3013, 294, 527, 1389, 307, 18668, 6681, 538, 11402, 11, 457, 718, 311, 818, 309, 257, 8310, 13, 51348], "temperature": 0.0, "avg_logprob": -0.3206694466727121, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.0001313517423113808}, {"id": 1296, "seek": 603270, "start": 6052.38, "end": 6056.62, "text": " And everything in that sequence has a bunch of channels, right?", "tokens": [51348, 400, 1203, 294, 300, 8310, 575, 257, 3840, 295, 9235, 11, 558, 30, 51560], "temperature": 0.0, "avg_logprob": -0.3206694466727121, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.0001313517423113808}, {"id": 1297, "seek": 603270, "start": 6056.62, "end": 6057.62, "text": " Or dimensions.", "tokens": [51560, 1610, 12819, 13, 51610], "temperature": 0.0, "avg_logprob": -0.3206694466727121, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.0001313517423113808}, {"id": 1298, "seek": 605762, "start": 6057.62, "end": 6064.86, "text": " I'm not going to draw them all, but you get the idea.", "tokens": [50364, 286, 478, 406, 516, 281, 2642, 552, 439, 11, 457, 291, 483, 264, 1558, 13, 50726], "temperature": 0.0, "avg_logprob": -0.30426121741226037, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.008577290922403336}, {"id": 1299, "seek": 605762, "start": 6064.86, "end": 6068.94, "text": " And so for each element of that sequence, which in our case, it's just some particular", "tokens": [50726, 400, 370, 337, 1184, 4478, 295, 300, 8310, 11, 597, 294, 527, 1389, 11, 309, 311, 445, 512, 1729, 50930], "temperature": 0.0, "avg_logprob": -0.30426121741226037, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.008577290922403336}, {"id": 1300, "seek": 605762, "start": 6068.94, "end": 6069.94, "text": " pixel, right?", "tokens": [50930, 19261, 11, 558, 30, 50980], "temperature": 0.0, "avg_logprob": -0.30426121741226037, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.008577290922403336}, {"id": 1301, "seek": 605762, "start": 6069.94, "end": 6075.3, "text": " And these are just the filters, channels, activations, whatever.", "tokens": [50980, 400, 613, 366, 445, 264, 15995, 11, 9235, 11, 2430, 763, 11, 2035, 13, 51248], "temperature": 0.0, "avg_logprob": -0.30426121741226037, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.008577290922403336}, {"id": 1302, "seek": 605762, "start": 6075.3, "end": 6079.38, "text": " Activations, I guess.", "tokens": [51248, 28550, 763, 11, 286, 2041, 13, 51452], "temperature": 0.0, "avg_logprob": -0.30426121741226037, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.008577290922403336}, {"id": 1303, "seek": 605762, "start": 6079.38, "end": 6086.0599999999995, "text": " What we're doing is we first do attention, which, you know, remember there's a projection", "tokens": [51452, 708, 321, 434, 884, 307, 321, 700, 360, 3202, 11, 597, 11, 291, 458, 11, 1604, 456, 311, 257, 22743, 51786], "temperature": 0.0, "avg_logprob": -0.30426121741226037, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.008577290922403336}, {"id": 1304, "seek": 605762, "start": 6086.0599999999995, "end": 6087.0599999999995, "text": " for each.", "tokens": [51786, 337, 1184, 13, 51836], "temperature": 0.0, "avg_logprob": -0.30426121741226037, "compression_ratio": 1.5360360360360361, "no_speech_prob": 0.008577290922403336}, {"id": 1305, "seek": 608706, "start": 6087.5, "end": 6088.900000000001, "text": " So it's mixing the channels a little bit.", "tokens": [50386, 407, 309, 311, 11983, 264, 9235, 257, 707, 857, 13, 50456], "temperature": 0.0, "avg_logprob": -0.27181685311453685, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.00012533630069810897}, {"id": 1306, "seek": 608706, "start": 6088.900000000001, "end": 6090.34, "text": " But just putting that aside.", "tokens": [50456, 583, 445, 3372, 300, 7359, 13, 50528], "temperature": 0.0, "avg_logprob": -0.27181685311453685, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.00012533630069810897}, {"id": 1307, "seek": 608706, "start": 6090.34, "end": 6101.02, "text": " The main thing it's doing is each row is getting mixed together, you know, into a weighted", "tokens": [50528, 440, 2135, 551, 309, 311, 884, 307, 1184, 5386, 307, 1242, 7467, 1214, 11, 291, 458, 11, 666, 257, 32807, 51062], "temperature": 0.0, "avg_logprob": -0.27181685311453685, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.00012533630069810897}, {"id": 1308, "seek": 608706, "start": 6101.02, "end": 6107.1, "text": " average.", "tokens": [51062, 4274, 13, 51366], "temperature": 0.0, "avg_logprob": -0.27181685311453685, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.00012533630069810897}, {"id": 1309, "seek": 608706, "start": 6107.1, "end": 6112.9800000000005, "text": " And then after we do that, we put the whole thing through a multilayer perceptron.", "tokens": [51366, 400, 550, 934, 321, 360, 300, 11, 321, 829, 264, 1379, 551, 807, 257, 2120, 388, 11167, 43276, 2044, 13, 51660], "temperature": 0.0, "avg_logprob": -0.27181685311453685, "compression_ratio": 1.4709302325581395, "no_speech_prob": 0.00012533630069810897}, {"id": 1310, "seek": 611298, "start": 6112.98, "end": 6122.0199999999995, "text": " And what the multilayer perceptron does is it entirely looks at each pixel on its own.", "tokens": [50364, 400, 437, 264, 2120, 388, 11167, 43276, 2044, 775, 307, 309, 7696, 1542, 412, 1184, 19261, 322, 1080, 1065, 13, 50816], "temperature": 0.0, "avg_logprob": -0.2561226970744583, "compression_ratio": 1.3172413793103448, "no_speech_prob": 0.00026947830338031054}, {"id": 1311, "seek": 611298, "start": 6122.0199999999995, "end": 6126.259999999999, "text": " So let's say this one, right?", "tokens": [50816, 407, 718, 311, 584, 341, 472, 11, 558, 30, 51028], "temperature": 0.0, "avg_logprob": -0.2561226970744583, "compression_ratio": 1.3172413793103448, "no_speech_prob": 0.00026947830338031054}, {"id": 1312, "seek": 611298, "start": 6126.259999999999, "end": 6140.9, "text": " And puts that through linear activation norm linear, which we call an MLP.", "tokens": [51028, 400, 8137, 300, 807, 8213, 24433, 2026, 8213, 11, 597, 321, 818, 364, 21601, 47, 13, 51760], "temperature": 0.0, "avg_logprob": -0.2561226970744583, "compression_ratio": 1.3172413793103448, "no_speech_prob": 0.00026947830338031054}, {"id": 1313, "seek": 614090, "start": 6140.9, "end": 6145.7, "text": " And so a transformer network is a bunch of transformer layers.", "tokens": [50364, 400, 370, 257, 31782, 3209, 307, 257, 3840, 295, 31782, 7914, 13, 50604], "temperature": 0.0, "avg_logprob": -0.24818913777669271, "compression_ratio": 1.6163522012578617, "no_speech_prob": 1.0783275683934335e-05}, {"id": 1314, "seek": 614090, "start": 6145.7, "end": 6156.099999999999, "text": " So it's basically going attention, MLP, attention, MLP, attention, etc, etc.", "tokens": [50604, 407, 309, 311, 1936, 516, 3202, 11, 21601, 47, 11, 3202, 11, 21601, 47, 11, 3202, 11, 5183, 11, 5183, 13, 51124], "temperature": 0.0, "avg_logprob": -0.24818913777669271, "compression_ratio": 1.6163522012578617, "no_speech_prob": 1.0783275683934335e-05}, {"id": 1315, "seek": 614090, "start": 6156.099999999999, "end": 6157.099999999999, "text": " MLP.", "tokens": [51124, 21601, 47, 13, 51174], "temperature": 0.0, "avg_logprob": -0.24818913777669271, "compression_ratio": 1.6163522012578617, "no_speech_prob": 1.0783275683934335e-05}, {"id": 1316, "seek": 614090, "start": 6157.099999999999, "end": 6161.42, "text": " That's all it's doing.", "tokens": [51174, 663, 311, 439, 309, 311, 884, 13, 51390], "temperature": 0.0, "avg_logprob": -0.24818913777669271, "compression_ratio": 1.6163522012578617, "no_speech_prob": 1.0783275683934335e-05}, {"id": 1317, "seek": 614090, "start": 6161.42, "end": 6168.98, "text": " And so in other words, it's mixing together the pixels or sequences, and then it's mixing", "tokens": [51390, 400, 370, 294, 661, 2283, 11, 309, 311, 11983, 1214, 264, 18668, 420, 22978, 11, 293, 550, 309, 311, 11983, 51768], "temperature": 0.0, "avg_logprob": -0.24818913777669271, "compression_ratio": 1.6163522012578617, "no_speech_prob": 1.0783275683934335e-05}, {"id": 1318, "seek": 616898, "start": 6169.0599999999995, "end": 6170.0599999999995, "text": " together the channels.", "tokens": [50368, 1214, 264, 9235, 13, 50418], "temperature": 0.0, "avg_logprob": -0.2898085650275735, "compression_ratio": 1.835164835164835, "no_speech_prob": 4.4000818888889626e-05}, {"id": 1319, "seek": 616898, "start": 6170.0599999999995, "end": 6173.379999999999, "text": " Then it's mixing together the sequences, and then mixing together the channels.", "tokens": [50418, 1396, 309, 311, 11983, 1214, 264, 22978, 11, 293, 550, 11983, 1214, 264, 9235, 13, 50584], "temperature": 0.0, "avg_logprob": -0.2898085650275735, "compression_ratio": 1.835164835164835, "no_speech_prob": 4.4000818888889626e-05}, {"id": 1320, "seek": 616898, "start": 6173.379999999999, "end": 6175.58, "text": " And it's repeating this over and over.", "tokens": [50584, 400, 309, 311, 18617, 341, 670, 293, 670, 13, 50694], "temperature": 0.0, "avg_logprob": -0.2898085650275735, "compression_ratio": 1.835164835164835, "no_speech_prob": 4.4000818888889626e-05}, {"id": 1321, "seek": 616898, "start": 6175.58, "end": 6185.419999999999, "text": " Because of the projections being done in the attention, it's not just mixing the pixels,", "tokens": [50694, 1436, 295, 264, 32371, 885, 1096, 294, 264, 3202, 11, 309, 311, 406, 445, 11983, 264, 18668, 11, 51186], "temperature": 0.0, "avg_logprob": -0.2898085650275735, "compression_ratio": 1.835164835164835, "no_speech_prob": 4.4000818888889626e-05}, {"id": 1322, "seek": 616898, "start": 6185.419999999999, "end": 6188.78, "text": " but it's kind of, it's largely mixing the pixels.", "tokens": [51186, 457, 309, 311, 733, 295, 11, 309, 311, 11611, 11983, 264, 18668, 13, 51354], "temperature": 0.0, "avg_logprob": -0.2898085650275735, "compression_ratio": 1.835164835164835, "no_speech_prob": 4.4000818888889626e-05}, {"id": 1323, "seek": 616898, "start": 6188.78, "end": 6197.58, "text": " And so this combination is very, very, very flexible.", "tokens": [51354, 400, 370, 341, 6562, 307, 588, 11, 588, 11, 588, 11358, 13, 51794], "temperature": 0.0, "avg_logprob": -0.2898085650275735, "compression_ratio": 1.835164835164835, "no_speech_prob": 4.4000818888889626e-05}, {"id": 1324, "seek": 619758, "start": 6197.58, "end": 6205.5, "text": " And it's flexible enough that it provably can actually approximate any convolution that", "tokens": [50364, 400, 309, 311, 11358, 1547, 300, 309, 1439, 1188, 393, 767, 30874, 604, 45216, 300, 50760], "temperature": 0.0, "avg_logprob": -0.2559851791899083, "compression_ratio": 1.5502958579881656, "no_speech_prob": 3.219231803086586e-05}, {"id": 1325, "seek": 619758, "start": 6205.5, "end": 6208.9, "text": " you can think of.", "tokens": [50760, 291, 393, 519, 295, 13, 50930], "temperature": 0.0, "avg_logprob": -0.2559851791899083, "compression_ratio": 1.5502958579881656, "no_speech_prob": 3.219231803086586e-05}, {"id": 1326, "seek": 619758, "start": 6208.9, "end": 6217.14, "text": " Given enough layers and enough time and learning the right parameters.", "tokens": [50930, 18600, 1547, 7914, 293, 1547, 565, 293, 2539, 264, 558, 9834, 13, 51342], "temperature": 0.0, "avg_logprob": -0.2559851791899083, "compression_ratio": 1.5502958579881656, "no_speech_prob": 3.219231803086586e-05}, {"id": 1327, "seek": 619758, "start": 6217.14, "end": 6225.22, "text": " The problem is that for this to approximate a combination requires a lot of data, and", "tokens": [51342, 440, 1154, 307, 300, 337, 341, 281, 30874, 257, 6562, 7029, 257, 688, 295, 1412, 11, 293, 51746], "temperature": 0.0, "avg_logprob": -0.2559851791899083, "compression_ratio": 1.5502958579881656, "no_speech_prob": 3.219231803086586e-05}, {"id": 1328, "seek": 622522, "start": 6225.22, "end": 6230.240000000001, "text": " a lot of layers, and a lot of parameters, and a lot of compute.", "tokens": [50364, 257, 688, 295, 7914, 11, 293, 257, 688, 295, 9834, 11, 293, 257, 688, 295, 14722, 13, 50615], "temperature": 0.0, "avg_logprob": -0.23314707988017314, "compression_ratio": 1.6708860759493671, "no_speech_prob": 9.761544788489118e-05}, {"id": 1329, "seek": 622522, "start": 6230.240000000001, "end": 6238.860000000001, "text": " So if you try to use this, so this is a transformer network, transformer architecture.", "tokens": [50615, 407, 498, 291, 853, 281, 764, 341, 11, 370, 341, 307, 257, 31782, 3209, 11, 31782, 9482, 13, 51046], "temperature": 0.0, "avg_logprob": -0.23314707988017314, "compression_ratio": 1.6708860759493671, "no_speech_prob": 9.761544788489118e-05}, {"id": 1330, "seek": 622522, "start": 6238.860000000001, "end": 6248.900000000001, "text": " If you pass images into this, so pass an image in, and try to predict, say from ImageNet,", "tokens": [51046, 759, 291, 1320, 5267, 666, 341, 11, 370, 1320, 364, 3256, 294, 11, 293, 853, 281, 6069, 11, 584, 490, 29903, 31890, 11, 51548], "temperature": 0.0, "avg_logprob": -0.23314707988017314, "compression_ratio": 1.6708860759493671, "no_speech_prob": 9.761544788489118e-05}, {"id": 1331, "seek": 622522, "start": 6248.900000000001, "end": 6250.34, "text": " the class of the image.", "tokens": [51548, 264, 1508, 295, 264, 3256, 13, 51620], "temperature": 0.0, "avg_logprob": -0.23314707988017314, "compression_ratio": 1.6708860759493671, "no_speech_prob": 9.761544788489118e-05}, {"id": 1332, "seek": 625034, "start": 6250.34, "end": 6259.46, "text": " So use SGD to try and find weights for these attention projections and MLPs.", "tokens": [50364, 407, 764, 34520, 35, 281, 853, 293, 915, 17443, 337, 613, 3202, 32371, 293, 21601, 23043, 13, 50820], "temperature": 0.0, "avg_logprob": -0.2362677508061475, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0001713075616862625}, {"id": 1333, "seek": 625034, "start": 6259.46, "end": 6263.5, "text": " If you do that on ImageNet, you will end up with something that does indeed predict the", "tokens": [50820, 759, 291, 360, 300, 322, 29903, 31890, 11, 291, 486, 917, 493, 365, 746, 300, 775, 6451, 6069, 264, 51022], "temperature": 0.0, "avg_logprob": -0.2362677508061475, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0001713075616862625}, {"id": 1334, "seek": 625034, "start": 6263.5, "end": 6267.22, "text": " class of each image, but it does it poorly.", "tokens": [51022, 1508, 295, 1184, 3256, 11, 457, 309, 775, 309, 22271, 13, 51208], "temperature": 0.0, "avg_logprob": -0.2362677508061475, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0001713075616862625}, {"id": 1335, "seek": 625034, "start": 6267.22, "end": 6271.34, "text": " Now it doesn't do it poorly because it's not capable of approximating a convolution.", "tokens": [51208, 823, 309, 1177, 380, 360, 309, 22271, 570, 309, 311, 406, 8189, 295, 8542, 990, 257, 45216, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2362677508061475, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0001713075616862625}, {"id": 1336, "seek": 625034, "start": 6271.34, "end": 6278.5, "text": " It does it poorly because ImageNet, the entire ImageNet, as in ImageNet 1k, is not big enough", "tokens": [51414, 467, 775, 309, 22271, 570, 29903, 31890, 11, 264, 2302, 29903, 31890, 11, 382, 294, 29903, 31890, 502, 74, 11, 307, 406, 955, 1547, 51772], "temperature": 0.0, "avg_logprob": -0.2362677508061475, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0001713075616862625}, {"id": 1337, "seek": 627850, "start": 6278.66, "end": 6282.62, "text": " for a transformer to learn how to do this.", "tokens": [50372, 337, 257, 31782, 281, 1466, 577, 281, 360, 341, 13, 50570], "temperature": 0.0, "avg_logprob": -0.28813281812165914, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.977308577101212e-05}, {"id": 1338, "seek": 627850, "start": 6282.62, "end": 6290.18, "text": " However, if you pass it a much bigger dataset, many times larger than ImageNet 1k, then it", "tokens": [50570, 2908, 11, 498, 291, 1320, 309, 257, 709, 3801, 28872, 11, 867, 1413, 4833, 813, 29903, 31890, 502, 74, 11, 550, 309, 50948], "temperature": 0.0, "avg_logprob": -0.28813281812165914, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.977308577101212e-05}, {"id": 1339, "seek": 627850, "start": 6290.18, "end": 6293.78, "text": " will learn to approximate this very well.", "tokens": [50948, 486, 1466, 281, 30874, 341, 588, 731, 13, 51128], "temperature": 0.0, "avg_logprob": -0.28813281812165914, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.977308577101212e-05}, {"id": 1340, "seek": 627850, "start": 6293.78, "end": 6298.5, "text": " And in fact, it'll figure out a way of doing something like convolutions that are actually", "tokens": [51128, 400, 294, 1186, 11, 309, 603, 2573, 484, 257, 636, 295, 884, 746, 411, 3754, 15892, 300, 366, 767, 51364], "temperature": 0.0, "avg_logprob": -0.28813281812165914, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.977308577101212e-05}, {"id": 1341, "seek": 627850, "start": 6298.5, "end": 6300.82, "text": " better than convolutions.", "tokens": [51364, 1101, 813, 3754, 15892, 13, 51480], "temperature": 0.0, "avg_logprob": -0.28813281812165914, "compression_ratio": 1.4747474747474747, "no_speech_prob": 2.977308577101212e-05}, {"id": 1342, "seek": 630082, "start": 6300.82, "end": 6308.98, "text": " And so if you then take that, so that's going to be called a vision transformer, or VIT,", "tokens": [50364, 400, 370, 498, 291, 550, 747, 300, 11, 370, 300, 311, 516, 281, 312, 1219, 257, 5201, 31782, 11, 420, 691, 3927, 11, 50772], "temperature": 0.0, "avg_logprob": -0.23327106319061697, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.00016603109543211758}, {"id": 1343, "seek": 630082, "start": 6308.98, "end": 6312.62, "text": " that's been pre-trained on a dataset much bigger than ImageNet, and then you fine-tune", "tokens": [50772, 300, 311, 668, 659, 12, 17227, 2001, 322, 257, 28872, 709, 3801, 813, 29903, 31890, 11, 293, 550, 291, 2489, 12, 83, 2613, 50954], "temperature": 0.0, "avg_logprob": -0.23327106319061697, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.00016603109543211758}, {"id": 1344, "seek": 630082, "start": 6312.62, "end": 6321.66, "text": " it on ImageNet, you will end up with something that is actually better than ResNet.", "tokens": [50954, 309, 322, 29903, 31890, 11, 291, 486, 917, 493, 365, 746, 300, 307, 767, 1101, 813, 5015, 31890, 13, 51406], "temperature": 0.0, "avg_logprob": -0.23327106319061697, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.00016603109543211758}, {"id": 1345, "seek": 632166, "start": 6321.66, "end": 6331.34, "text": " And the reason it's better than ResNet is because these combinations, right, which together,", "tokens": [50364, 400, 264, 1778, 309, 311, 1101, 813, 5015, 31890, 307, 570, 613, 21267, 11, 558, 11, 597, 1214, 11, 50848], "temperature": 0.0, "avg_logprob": -0.24512192782233744, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.0005883008125238121}, {"id": 1346, "seek": 632166, "start": 6331.34, "end": 6338.42, "text": " when combined, can approximate a convolution, these transformers, you know, convolutions", "tokens": [50848, 562, 9354, 11, 393, 30874, 257, 45216, 11, 613, 4088, 433, 11, 291, 458, 11, 3754, 15892, 51202], "temperature": 0.0, "avg_logprob": -0.24512192782233744, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.0005883008125238121}, {"id": 1347, "seek": 632166, "start": 6338.42, "end": 6345.66, "text": " are our best guess as to like a good way to kind of represent the calculations we should", "tokens": [51202, 366, 527, 1151, 2041, 382, 281, 411, 257, 665, 636, 281, 733, 295, 2906, 264, 20448, 321, 820, 51564], "temperature": 0.0, "avg_logprob": -0.24512192782233744, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.0005883008125238121}, {"id": 1348, "seek": 632166, "start": 6345.66, "end": 6347.18, "text": " do on images.", "tokens": [51564, 360, 322, 5267, 13, 51640], "temperature": 0.0, "avg_logprob": -0.24512192782233744, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.0005883008125238121}, {"id": 1349, "seek": 634718, "start": 6347.58, "end": 6351.740000000001, "text": " There's actually much more sophisticated things you could do, you know, if you're a computer", "tokens": [50384, 821, 311, 767, 709, 544, 16950, 721, 291, 727, 360, 11, 291, 458, 11, 498, 291, 434, 257, 3820, 50592], "temperature": 0.0, "avg_logprob": -0.20266277990608572, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.002182647353038192}, {"id": 1350, "seek": 634718, "start": 6351.740000000001, "end": 6354.700000000001, "text": " and you could figure these things out better than a human can.", "tokens": [50592, 293, 291, 727, 2573, 613, 721, 484, 1101, 813, 257, 1952, 393, 13, 50740], "temperature": 0.0, "avg_logprob": -0.20266277990608572, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.002182647353038192}, {"id": 1351, "seek": 634718, "start": 6354.700000000001, "end": 6360.12, "text": " And so a VIT actually figures out things that are even better than convolutions.", "tokens": [50740, 400, 370, 257, 691, 3927, 767, 9624, 484, 721, 300, 366, 754, 1101, 813, 3754, 15892, 13, 51011], "temperature": 0.0, "avg_logprob": -0.20266277990608572, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.002182647353038192}, {"id": 1352, "seek": 634718, "start": 6360.12, "end": 6366.1, "text": " And so when you fine-tune ImageNet using a very, you know, a VIT that's been pre-trained", "tokens": [51011, 400, 370, 562, 291, 2489, 12, 83, 2613, 29903, 31890, 1228, 257, 588, 11, 291, 458, 11, 257, 691, 3927, 300, 311, 668, 659, 12, 17227, 2001, 51310], "temperature": 0.0, "avg_logprob": -0.20266277990608572, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.002182647353038192}, {"id": 1353, "seek": 634718, "start": 6366.1, "end": 6371.62, "text": " on lots of data, then that's why it ends up being better than a ResNet.", "tokens": [51310, 322, 3195, 295, 1412, 11, 550, 300, 311, 983, 309, 5314, 493, 885, 1101, 813, 257, 5015, 31890, 13, 51586], "temperature": 0.0, "avg_logprob": -0.20266277990608572, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.002182647353038192}, {"id": 1354, "seek": 637162, "start": 6371.62, "end": 6382.18, "text": " So that's why, you know, the things I'm showing you are not the things that contain transformers", "tokens": [50364, 407, 300, 311, 983, 11, 291, 458, 11, 264, 721, 286, 478, 4099, 291, 366, 406, 264, 721, 300, 5304, 4088, 433, 50892], "temperature": 0.0, "avg_logprob": -0.23302516718020386, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0001253348746104166}, {"id": 1355, "seek": 637162, "start": 6382.18, "end": 6389.5, "text": " in diffusion, because to make that work would require pre-training on a really, really large", "tokens": [50892, 294, 25242, 11, 570, 281, 652, 300, 589, 576, 3651, 659, 12, 17227, 1760, 322, 257, 534, 11, 534, 2416, 51258], "temperature": 0.0, "avg_logprob": -0.23302516718020386, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0001253348746104166}, {"id": 1356, "seek": 637162, "start": 6389.5, "end": 6393.86, "text": " dataset for a really, really long amount of time.", "tokens": [51258, 28872, 337, 257, 534, 11, 534, 938, 2372, 295, 565, 13, 51476], "temperature": 0.0, "avg_logprob": -0.23302516718020386, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0001253348746104166}, {"id": 1357, "seek": 637162, "start": 6393.86, "end": 6400.78, "text": " So anyway, so we might only come to transformers, well, not in a very long time, but when we", "tokens": [51476, 407, 4033, 11, 370, 321, 1062, 787, 808, 281, 4088, 433, 11, 731, 11, 406, 294, 257, 588, 938, 565, 11, 457, 562, 321, 51822], "temperature": 0.0, "avg_logprob": -0.23302516718020386, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0001253348746104166}, {"id": 1358, "seek": 640078, "start": 6400.94, "end": 6408.74, "text": " do them in NLP, in Vision, maybe we'll cover them briefly, you know, they're very interesting", "tokens": [50372, 360, 552, 294, 426, 45196, 11, 294, 25170, 11, 1310, 321, 603, 2060, 552, 10515, 11, 291, 458, 11, 436, 434, 588, 1880, 50762], "temperature": 0.0, "avg_logprob": -0.2524724960327148, "compression_ratio": 1.6178861788617886, "no_speech_prob": 4.331874515628442e-05}, {"id": 1359, "seek": 640078, "start": 6408.74, "end": 6411.3, "text": " to use as pre-trained models.", "tokens": [50762, 281, 764, 382, 659, 12, 17227, 2001, 5245, 13, 50890], "temperature": 0.0, "avg_logprob": -0.2524724960327148, "compression_ratio": 1.6178861788617886, "no_speech_prob": 4.331874515628442e-05}, {"id": 1360, "seek": 640078, "start": 6411.3, "end": 6417.94, "text": " The main thing to know about them is, yeah, a VIT, you know, which is a really successful,", "tokens": [50890, 440, 2135, 551, 281, 458, 466, 552, 307, 11, 1338, 11, 257, 691, 3927, 11, 291, 458, 11, 597, 307, 257, 534, 4406, 11, 51222], "temperature": 0.0, "avg_logprob": -0.2524724960327148, "compression_ratio": 1.6178861788617886, "no_speech_prob": 4.331874515628442e-05}, {"id": 1361, "seek": 640078, "start": 6417.94, "end": 6422.38, "text": " when pre-trained on lots of data, which they all are nowadays, is a very successful architecture.", "tokens": [51222, 562, 659, 12, 17227, 2001, 322, 3195, 295, 1412, 11, 597, 436, 439, 366, 13434, 11, 307, 257, 588, 4406, 9482, 13, 51444], "temperature": 0.0, "avg_logprob": -0.2524724960327148, "compression_ratio": 1.6178861788617886, "no_speech_prob": 4.331874515628442e-05}, {"id": 1362, "seek": 640078, "start": 6422.38, "end": 6426.219999999999, "text": " But like literally the VIT paper says, oh, we wondered what would happen if we take a", "tokens": [51444, 583, 411, 3736, 264, 691, 3927, 3035, 1619, 11, 1954, 11, 321, 17055, 437, 576, 1051, 498, 321, 747, 257, 51636], "temperature": 0.0, "avg_logprob": -0.2524724960327148, "compression_ratio": 1.6178861788617886, "no_speech_prob": 4.331874515628442e-05}, {"id": 1363, "seek": 642622, "start": 6426.22, "end": 6433.9400000000005, "text": " totally plain 1D transformer, you know, and convert it and use, convert, make it work", "tokens": [50364, 3879, 11121, 502, 35, 31782, 11, 291, 458, 11, 293, 7620, 309, 293, 764, 11, 7620, 11, 652, 309, 589, 50750], "temperature": 0.0, "avg_logprob": -0.25526464990822667, "compression_ratio": 1.497737556561086, "no_speech_prob": 0.001187879708595574}, {"id": 1364, "seek": 642622, "start": 6433.9400000000005, "end": 6437.3, "text": " on images with as few changes as possible.", "tokens": [50750, 322, 5267, 365, 382, 1326, 2962, 382, 1944, 13, 50918], "temperature": 0.0, "avg_logprob": -0.25526464990822667, "compression_ratio": 1.497737556561086, "no_speech_prob": 0.001187879708595574}, {"id": 1365, "seek": 642622, "start": 6437.3, "end": 6444.34, "text": " So everything we've learned about attention today and MLPs applies directly, because they", "tokens": [50918, 407, 1203, 321, 600, 3264, 466, 3202, 965, 293, 21601, 23043, 13165, 3838, 11, 570, 436, 51270], "temperature": 0.0, "avg_logprob": -0.25526464990822667, "compression_ratio": 1.497737556561086, "no_speech_prob": 0.001187879708595574}, {"id": 1366, "seek": 642622, "start": 6444.34, "end": 6447.1, "text": " haven't changed anything.", "tokens": [51270, 2378, 380, 3105, 1340, 13, 51408], "temperature": 0.0, "avg_logprob": -0.25526464990822667, "compression_ratio": 1.497737556561086, "no_speech_prob": 0.001187879708595574}, {"id": 1367, "seek": 642622, "start": 6447.1, "end": 6453.740000000001, "text": " And so one of the things you might realize that means is that you can't use a VIT that", "tokens": [51408, 400, 370, 472, 295, 264, 721, 291, 1062, 4325, 300, 1355, 307, 300, 291, 393, 380, 764, 257, 691, 3927, 300, 51740], "temperature": 0.0, "avg_logprob": -0.25526464990822667, "compression_ratio": 1.497737556561086, "no_speech_prob": 0.001187879708595574}, {"id": 1368, "seek": 645374, "start": 6453.74, "end": 6461.66, "text": " was trained on 224 by 224 pixel images on 128 by 128 pixel images, because, you know,", "tokens": [50364, 390, 8895, 322, 5853, 19, 538, 5853, 19, 19261, 5267, 322, 29810, 538, 29810, 19261, 5267, 11, 570, 11, 291, 458, 11, 50760], "temperature": 0.0, "avg_logprob": -0.2932833819322183, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.0008040536195039749}, {"id": 1369, "seek": 645374, "start": 6461.66, "end": 6470.38, "text": " all of these self-attention things are the wrong size, you know.", "tokens": [50760, 439, 295, 613, 2698, 12, 1591, 1251, 721, 366, 264, 2085, 2744, 11, 291, 458, 13, 51196], "temperature": 0.0, "avg_logprob": -0.2932833819322183, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.0008040536195039749}, {"id": 1370, "seek": 645374, "start": 6470.38, "end": 6475.82, "text": " And specifically, the problem is actually the, actually it's not really the attention,", "tokens": [51196, 400, 4682, 11, 264, 1154, 307, 767, 264, 11, 767, 309, 311, 406, 534, 264, 3202, 11, 51468], "temperature": 0.0, "avg_logprob": -0.2932833819322183, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.0008040536195039749}, {"id": 1371, "seek": 645374, "start": 6475.82, "end": 6477.7, "text": " let me take that back.", "tokens": [51468, 718, 385, 747, 300, 646, 13, 51562], "temperature": 0.0, "avg_logprob": -0.2932833819322183, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.0008040536195039749}, {"id": 1372, "seek": 647770, "start": 6477.78, "end": 6485.179999999999, "text": " All of the position embeddings are the wrong size.", "tokens": [50368, 1057, 295, 264, 2535, 12240, 29432, 366, 264, 2085, 2744, 13, 50738], "temperature": 0.0, "avg_logprob": -0.27004236414812616, "compression_ratio": 1.5301204819277108, "no_speech_prob": 0.0008167258347384632}, {"id": 1373, "seek": 647770, "start": 6485.179999999999, "end": 6492.54, "text": " And so actually that's something I, sorry, I forgot to mention, is that in transformers,", "tokens": [50738, 400, 370, 767, 300, 311, 746, 286, 11, 2597, 11, 286, 5298, 281, 2152, 11, 307, 300, 294, 4088, 433, 11, 51106], "temperature": 0.0, "avg_logprob": -0.27004236414812616, "compression_ratio": 1.5301204819277108, "no_speech_prob": 0.0008167258347384632}, {"id": 1374, "seek": 647770, "start": 6492.54, "end": 6501.94, "text": " the first thing you do is you always take your, you know, these pixels and you add to", "tokens": [51106, 264, 700, 551, 291, 360, 307, 291, 1009, 747, 428, 11, 291, 458, 11, 613, 18668, 293, 291, 909, 281, 51576], "temperature": 0.0, "avg_logprob": -0.27004236414812616, "compression_ratio": 1.5301204819277108, "no_speech_prob": 0.0008167258347384632}, {"id": 1375, "seek": 647770, "start": 6501.94, "end": 6506.9, "text": " them a positional embedding.", "tokens": [51576, 552, 257, 2535, 304, 12240, 3584, 13, 51824], "temperature": 0.0, "avg_logprob": -0.27004236414812616, "compression_ratio": 1.5301204819277108, "no_speech_prob": 0.0008167258347384632}, {"id": 1376, "seek": 650690, "start": 6507.099999999999, "end": 6510.259999999999, "text": " And that's done, I mean, it can be done lots of different ways, but the most popular way", "tokens": [50374, 400, 300, 311, 1096, 11, 286, 914, 11, 309, 393, 312, 1096, 3195, 295, 819, 2098, 11, 457, 264, 881, 3743, 636, 50532], "temperature": 0.0, "avg_logprob": -0.2470158055885551, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.004331418313086033}, {"id": 1377, "seek": 650690, "start": 6510.259999999999, "end": 6516.0599999999995, "text": " is identical to what we did for the time step embedding, it's a sinusoidal embedding.", "tokens": [50532, 307, 14800, 281, 437, 321, 630, 337, 264, 565, 1823, 12240, 3584, 11, 309, 311, 257, 41503, 17079, 304, 12240, 3584, 13, 50822], "temperature": 0.0, "avg_logprob": -0.2470158055885551, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.004331418313086033}, {"id": 1378, "seek": 650690, "start": 6516.0599999999995, "end": 6524.86, "text": " And so that's specific, you know, to how many, how many pixels there are in your image.", "tokens": [50822, 400, 370, 300, 311, 2685, 11, 291, 458, 11, 281, 577, 867, 11, 577, 867, 18668, 456, 366, 294, 428, 3256, 13, 51262], "temperature": 0.0, "avg_logprob": -0.2470158055885551, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.004331418313086033}, {"id": 1379, "seek": 650690, "start": 6524.86, "end": 6530.5, "text": " So yeah, that's an example of one of the things that makes VITs a little tricky.", "tokens": [51262, 407, 1338, 11, 300, 311, 364, 1365, 295, 472, 295, 264, 721, 300, 1669, 691, 3927, 82, 257, 707, 12414, 13, 51544], "temperature": 0.0, "avg_logprob": -0.2470158055885551, "compression_ratio": 1.559090909090909, "no_speech_prob": 0.004331418313086033}, {"id": 1380, "seek": 653050, "start": 6530.66, "end": 6539.5, "text": " Anyway, hopefully, yeah, you get the idea that we've got all the pieces that we need.", "tokens": [50372, 5684, 11, 4696, 11, 1338, 11, 291, 483, 264, 1558, 300, 321, 600, 658, 439, 264, 3755, 300, 321, 643, 13, 50814], "temperature": 0.0, "avg_logprob": -0.3631823309536638, "compression_ratio": 1.3973509933774835, "no_speech_prob": 1.7499538444099016e-05}, {"id": 1381, "seek": 653050, "start": 6539.5, "end": 6544.18, "text": " Okay.", "tokens": [50814, 1033, 13, 51048], "temperature": 0.0, "avg_logprob": -0.3631823309536638, "compression_ratio": 1.3973509933774835, "no_speech_prob": 1.7499538444099016e-05}, {"id": 1382, "seek": 653050, "start": 6544.18, "end": 6552.22, "text": " So with that discussion, I think that's officially taken us over time.", "tokens": [51048, 407, 365, 300, 5017, 11, 286, 519, 300, 311, 12053, 2726, 505, 670, 565, 13, 51450], "temperature": 0.0, "avg_logprob": -0.3631823309536638, "compression_ratio": 1.3973509933774835, "no_speech_prob": 1.7499538444099016e-05}, {"id": 1383, "seek": 653050, "start": 6552.22, "end": 6558.26, "text": " So maybe we should do the conditional next time.", "tokens": [51450, 407, 1310, 321, 820, 360, 264, 27708, 958, 565, 13, 51752], "temperature": 0.0, "avg_logprob": -0.3631823309536638, "compression_ratio": 1.3973509933774835, "no_speech_prob": 1.7499538444099016e-05}, {"id": 1384, "seek": 655826, "start": 6558.38, "end": 6562.5, "text": " Do you know what, actually it's tiny.", "tokens": [50370, 1144, 291, 458, 437, 11, 767, 309, 311, 5870, 13, 50576], "temperature": 0.0, "avg_logprob": -0.26809517691068563, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.00018522297614254057}, {"id": 1385, "seek": 655826, "start": 6562.5, "end": 6563.5, "text": " Let's just quickly do it now.", "tokens": [50576, 961, 311, 445, 2661, 360, 309, 586, 13, 50626], "temperature": 0.0, "avg_logprob": -0.26809517691068563, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.00018522297614254057}, {"id": 1386, "seek": 655826, "start": 6563.5, "end": 6565.5, "text": " You guys got time?", "tokens": [50626, 509, 1074, 658, 565, 30, 50726], "temperature": 0.0, "avg_logprob": -0.26809517691068563, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.00018522297614254057}, {"id": 1387, "seek": 655826, "start": 6565.5, "end": 6566.5, "text": " Yeah.", "tokens": [50726, 865, 13, 50776], "temperature": 0.0, "avg_logprob": -0.26809517691068563, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.00018522297614254057}, {"id": 1388, "seek": 655826, "start": 6566.5, "end": 6567.5, "text": " Okay.", "tokens": [50776, 1033, 13, 50826], "temperature": 0.0, "avg_logprob": -0.26809517691068563, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.00018522297614254057}, {"id": 1389, "seek": 655826, "start": 6567.5, "end": 6570.820000000001, "text": " So let's just, yeah, let's finish by doing a conditional model.", "tokens": [50826, 407, 718, 311, 445, 11, 1338, 11, 718, 311, 2413, 538, 884, 257, 27708, 2316, 13, 50992], "temperature": 0.0, "avg_logprob": -0.26809517691068563, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.00018522297614254057}, {"id": 1390, "seek": 655826, "start": 6570.820000000001, "end": 6576.9400000000005, "text": " So for a conditional model, we're going to basically say, I want something where I can", "tokens": [50992, 407, 337, 257, 27708, 2316, 11, 321, 434, 516, 281, 1936, 584, 11, 286, 528, 746, 689, 286, 393, 51298], "temperature": 0.0, "avg_logprob": -0.26809517691068563, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.00018522297614254057}, {"id": 1391, "seek": 655826, "start": 6576.9400000000005, "end": 6583.5, "text": " say, draw me a number, sorry, draw me a shirt, or draw me some pants, or draw me some sandals.", "tokens": [51298, 584, 11, 2642, 385, 257, 1230, 11, 2597, 11, 2642, 385, 257, 8336, 11, 420, 2642, 385, 512, 10082, 11, 420, 2642, 385, 512, 4932, 1124, 13, 51626], "temperature": 0.0, "avg_logprob": -0.26809517691068563, "compression_ratio": 1.645933014354067, "no_speech_prob": 0.00018522297614254057}, {"id": 1392, "seek": 658350, "start": 6583.5, "end": 6589.62, "text": " So we're going to pick one of the 10 fashion MNIST classes, and, and create an, you know,", "tokens": [50364, 407, 321, 434, 516, 281, 1888, 472, 295, 264, 1266, 6700, 376, 45, 19756, 5359, 11, 293, 11, 293, 1884, 364, 11, 291, 458, 11, 50670], "temperature": 0.0, "avg_logprob": -0.2848873386135349, "compression_ratio": 1.5549132947976878, "no_speech_prob": 4.908483970211819e-05}, {"id": 1393, "seek": 658350, "start": 6589.62, "end": 6593.34, "text": " create an image of a particular class.", "tokens": [50670, 1884, 364, 3256, 295, 257, 1729, 1508, 13, 50856], "temperature": 0.0, "avg_logprob": -0.2848873386135349, "compression_ratio": 1.5549132947976878, "no_speech_prob": 4.908483970211819e-05}, {"id": 1394, "seek": 658350, "start": 6593.34, "end": 6602.62, "text": " To do that, we need to know what class each thing is.", "tokens": [50856, 1407, 360, 300, 11, 321, 643, 281, 458, 437, 1508, 1184, 551, 307, 13, 51320], "temperature": 0.0, "avg_logprob": -0.2848873386135349, "compression_ratio": 1.5549132947976878, "no_speech_prob": 4.908483970211819e-05}, {"id": 1395, "seek": 658350, "start": 6602.62, "end": 6609.9, "text": " Now we already know what class each thing is, because it's the Y label, which way back", "tokens": [51320, 823, 321, 1217, 458, 437, 1508, 1184, 551, 307, 11, 570, 309, 311, 264, 398, 7645, 11, 597, 636, 646, 51684], "temperature": 0.0, "avg_logprob": -0.2848873386135349, "compression_ratio": 1.5549132947976878, "no_speech_prob": 4.908483970211819e-05}, {"id": 1396, "seek": 660990, "start": 6609.9, "end": 6616.86, "text": " in the beginning of time, we set, okay, it's just called the label.", "tokens": [50364, 294, 264, 2863, 295, 565, 11, 321, 992, 11, 1392, 11, 309, 311, 445, 1219, 264, 7645, 13, 50712], "temperature": 0.0, "avg_logprob": -0.30175135294596356, "compression_ratio": 1.5212121212121212, "no_speech_prob": 0.0002694762370083481}, {"id": 1397, "seek": 660990, "start": 6616.86, "end": 6623.58, "text": " So that tells you what category it is.", "tokens": [50712, 407, 300, 5112, 291, 437, 7719, 309, 307, 13, 51048], "temperature": 0.0, "avg_logprob": -0.30175135294596356, "compression_ratio": 1.5212121212121212, "no_speech_prob": 0.0002694762370083481}, {"id": 1398, "seek": 660990, "start": 6623.58, "end": 6627.099999999999, "text": " So we're going to change our collation function.", "tokens": [51048, 407, 321, 434, 516, 281, 1319, 527, 1263, 399, 2445, 13, 51224], "temperature": 0.0, "avg_logprob": -0.30175135294596356, "compression_ratio": 1.5212121212121212, "no_speech_prob": 0.0002694762370083481}, {"id": 1399, "seek": 660990, "start": 6627.099999999999, "end": 6633.74, "text": " So we call noiseify as per usual, that gives us our noised image, our time step, and our", "tokens": [51224, 407, 321, 818, 5658, 2505, 382, 680, 7713, 11, 300, 2709, 505, 527, 572, 2640, 3256, 11, 527, 565, 1823, 11, 293, 527, 51556], "temperature": 0.0, "avg_logprob": -0.30175135294596356, "compression_ratio": 1.5212121212121212, "no_speech_prob": 0.0002694762370083481}, {"id": 1400, "seek": 660990, "start": 6633.74, "end": 6638.139999999999, "text": " noise.", "tokens": [51556, 5658, 13, 51776], "temperature": 0.0, "avg_logprob": -0.30175135294596356, "compression_ratio": 1.5212121212121212, "no_speech_prob": 0.0002694762370083481}, {"id": 1401, "seek": 663814, "start": 6638.38, "end": 6646.62, "text": " But we're also going to then add to that tuple, what kind of fashion item is this.", "tokens": [50376, 583, 321, 434, 611, 516, 281, 550, 909, 281, 300, 2604, 781, 11, 437, 733, 295, 6700, 3174, 307, 341, 13, 50788], "temperature": 0.0, "avg_logprob": -0.253940749168396, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.264738890924491e-05}, {"id": 1402, "seek": 663814, "start": 6646.62, "end": 6651.54, "text": " And so the first tuple will be noised image, noise, and label, and then the dependent variable", "tokens": [50788, 400, 370, 264, 700, 2604, 781, 486, 312, 572, 2640, 3256, 11, 5658, 11, 293, 7645, 11, 293, 550, 264, 12334, 7006, 51034], "temperature": 0.0, "avg_logprob": -0.253940749168396, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.264738890924491e-05}, {"id": 1403, "seek": 663814, "start": 6651.54, "end": 6656.68, "text": " as per usual is the noise.", "tokens": [51034, 382, 680, 7713, 307, 264, 5658, 13, 51291], "temperature": 0.0, "avg_logprob": -0.253940749168396, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.264738890924491e-05}, {"id": 1404, "seek": 663814, "start": 6656.68, "end": 6660.38, "text": " And so what's going to happen now when we call our unet, which is now a conditioned", "tokens": [51291, 400, 370, 437, 311, 516, 281, 1051, 586, 562, 321, 818, 527, 517, 302, 11, 597, 307, 586, 257, 35833, 51476], "temperature": 0.0, "avg_logprob": -0.253940749168396, "compression_ratio": 1.6363636363636365, "no_speech_prob": 4.264738890924491e-05}, {"id": 1405, "seek": 666038, "start": 6660.38, "end": 6668.38, "text": " unet model, is the input is now going to contain not just the activations and the time", "tokens": [50364, 517, 302, 2316, 11, 307, 264, 4846, 307, 586, 516, 281, 5304, 406, 445, 264, 2430, 763, 293, 264, 565, 50764], "temperature": 0.0, "avg_logprob": -0.2941403870188862, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.01941700465977192}, {"id": 1406, "seek": 666038, "start": 6668.38, "end": 6671.22, "text": " step, but it's also going to contain the label.", "tokens": [50764, 1823, 11, 457, 309, 311, 611, 516, 281, 5304, 264, 7645, 13, 50906], "temperature": 0.0, "avg_logprob": -0.2941403870188862, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.01941700465977192}, {"id": 1407, "seek": 666038, "start": 6671.22, "end": 6675.74, "text": " Okay, that label will be a number between 0 and 9.", "tokens": [50906, 1033, 11, 300, 7645, 486, 312, 257, 1230, 1296, 1958, 293, 1722, 13, 51132], "temperature": 0.0, "avg_logprob": -0.2941403870188862, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.01941700465977192}, {"id": 1408, "seek": 666038, "start": 6675.74, "end": 6680.82, "text": " So how do we convert the number between 0 and 9 into a vector, which represents that", "tokens": [51132, 407, 577, 360, 321, 7620, 264, 1230, 1296, 1958, 293, 1722, 666, 257, 8062, 11, 597, 8855, 300, 51386], "temperature": 0.0, "avg_logprob": -0.2941403870188862, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.01941700465977192}, {"id": 1409, "seek": 666038, "start": 6680.82, "end": 6681.82, "text": " number?", "tokens": [51386, 1230, 30, 51436], "temperature": 0.0, "avg_logprob": -0.2941403870188862, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.01941700465977192}, {"id": 1410, "seek": 666038, "start": 6681.82, "end": 6684.62, "text": " Well, we know exactly how to do that, in n.embedding.", "tokens": [51436, 1042, 11, 321, 458, 2293, 577, 281, 360, 300, 11, 294, 297, 13, 443, 2883, 3584, 13, 51576], "temperature": 0.0, "avg_logprob": -0.2941403870188862, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.01941700465977192}, {"id": 1411, "seek": 666038, "start": 6684.62, "end": 6688.900000000001, "text": " Okay, so we did that lots in part one.", "tokens": [51576, 1033, 11, 370, 321, 630, 300, 3195, 294, 644, 472, 13, 51790], "temperature": 0.0, "avg_logprob": -0.2941403870188862, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.01941700465977192}, {"id": 1412, "seek": 668890, "start": 6688.9, "end": 6701.7, "text": " So let's make it exactly, you know, the same size as our time embedding.", "tokens": [50364, 407, 718, 311, 652, 309, 2293, 11, 291, 458, 11, 264, 912, 2744, 382, 527, 565, 12240, 3584, 13, 51004], "temperature": 0.0, "avg_logprob": -0.23672054975460738, "compression_ratio": 1.6883116883116882, "no_speech_prob": 1.8631728380569257e-05}, {"id": 1413, "seek": 668890, "start": 6701.7, "end": 6708.54, "text": " So n number of activations in the embedding.", "tokens": [51004, 407, 297, 1230, 295, 2430, 763, 294, 264, 12240, 3584, 13, 51346], "temperature": 0.0, "avg_logprob": -0.23672054975460738, "compression_ratio": 1.6883116883116882, "no_speech_prob": 1.8631728380569257e-05}, {"id": 1414, "seek": 668890, "start": 6708.54, "end": 6711.179999999999, "text": " It's going to be the same as our time step embedding.", "tokens": [51346, 467, 311, 516, 281, 312, 264, 912, 382, 527, 565, 1823, 12240, 3584, 13, 51478], "temperature": 0.0, "avg_logprob": -0.23672054975460738, "compression_ratio": 1.6883116883116882, "no_speech_prob": 1.8631728380569257e-05}, {"id": 1415, "seek": 668890, "start": 6711.179999999999, "end": 6712.179999999999, "text": " And so that's convenient.", "tokens": [51478, 400, 370, 300, 311, 10851, 13, 51528], "temperature": 0.0, "avg_logprob": -0.23672054975460738, "compression_ratio": 1.6883116883116882, "no_speech_prob": 1.8631728380569257e-05}, {"id": 1416, "seek": 668890, "start": 6712.179999999999, "end": 6716.78, "text": " So now in the forward, we do our time step embedding as usual.", "tokens": [51528, 407, 586, 294, 264, 2128, 11, 321, 360, 527, 565, 1823, 12240, 3584, 382, 7713, 13, 51758], "temperature": 0.0, "avg_logprob": -0.23672054975460738, "compression_ratio": 1.6883116883116882, "no_speech_prob": 1.8631728380569257e-05}, {"id": 1417, "seek": 671678, "start": 6716.78, "end": 6722.46, "text": " We'll pass the labels into our conditioned embedding.", "tokens": [50364, 492, 603, 1320, 264, 16949, 666, 527, 35833, 12240, 3584, 13, 50648], "temperature": 0.0, "avg_logprob": -0.31959388369605657, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.002472566906362772}, {"id": 1418, "seek": 671678, "start": 6722.46, "end": 6726.54, "text": " The time embedding we will put through the embedding layer p and before, and then we're", "tokens": [50648, 440, 565, 12240, 3584, 321, 486, 829, 807, 264, 12240, 3584, 287, 11167, 280, 293, 949, 11, 293, 550, 321, 434, 50852], "temperature": 0.0, "avg_logprob": -0.31959388369605657, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.002472566906362772}, {"id": 1419, "seek": 671678, "start": 6726.54, "end": 6728.66, "text": " just going to add them together.", "tokens": [50852, 445, 516, 281, 909, 552, 1214, 13, 50958], "temperature": 0.0, "avg_logprob": -0.31959388369605657, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.002472566906362772}, {"id": 1420, "seek": 671678, "start": 6728.66, "end": 6729.66, "text": " That's it, right?", "tokens": [50958, 663, 311, 309, 11, 558, 30, 51008], "temperature": 0.0, "avg_logprob": -0.31959388369605657, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.002472566906362772}, {"id": 1421, "seek": 671678, "start": 6729.66, "end": 6736.179999999999, "text": " So this now represents a combination of the time and the fashion item class.", "tokens": [51008, 407, 341, 586, 8855, 257, 6562, 295, 264, 565, 293, 264, 6700, 3174, 1508, 13, 51334], "temperature": 0.0, "avg_logprob": -0.31959388369605657, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.002472566906362772}, {"id": 1422, "seek": 671678, "start": 6736.179999999999, "end": 6741.0, "text": " And then everything else is identical in both parts.", "tokens": [51334, 400, 550, 1203, 1646, 307, 14800, 294, 1293, 3166, 13, 51575], "temperature": 0.0, "avg_logprob": -0.31959388369605657, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.002472566906362772}, {"id": 1423, "seek": 674100, "start": 6741.0, "end": 6746.96, "text": " So all we've added is this one thing, and then we just literally sum it up.", "tokens": [50364, 407, 439, 321, 600, 3869, 307, 341, 472, 551, 11, 293, 550, 321, 445, 3736, 2408, 309, 493, 13, 50662], "temperature": 0.0, "avg_logprob": -0.26963240524818155, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.004982066340744495}, {"id": 1424, "seek": 674100, "start": 6746.96, "end": 6751.84, "text": " So we've now got a joint embedding representing two things.", "tokens": [50662, 407, 321, 600, 586, 658, 257, 7225, 12240, 3584, 13460, 732, 721, 13, 50906], "temperature": 0.0, "avg_logprob": -0.26963240524818155, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.004982066340744495}, {"id": 1425, "seek": 674100, "start": 6751.84, "end": 6757.8, "text": " And then, yeah, and then we train it.", "tokens": [50906, 400, 550, 11, 1338, 11, 293, 550, 321, 3847, 309, 13, 51204], "temperature": 0.0, "avg_logprob": -0.26963240524818155, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.004982066340744495}, {"id": 1426, "seek": 674100, "start": 6757.8, "end": 6761.88, "text": " And you know, interestingly, it looks like the loss, well, it ends up about the same,", "tokens": [51204, 400, 291, 458, 11, 25873, 11, 309, 1542, 411, 264, 4470, 11, 731, 11, 309, 5314, 493, 466, 264, 912, 11, 51408], "temperature": 0.0, "avg_logprob": -0.26963240524818155, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.004982066340744495}, {"id": 1427, "seek": 674100, "start": 6761.88, "end": 6764.2, "text": " but it's, you know, you don't often see 0.031.", "tokens": [51408, 457, 309, 311, 11, 291, 458, 11, 291, 500, 380, 2049, 536, 1958, 13, 11592, 16, 13, 51524], "temperature": 0.0, "avg_logprob": -0.26963240524818155, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.004982066340744495}, {"id": 1428, "seek": 674100, "start": 6764.2, "end": 6769.02, "text": " You know, it is a bit easier for it to do a conditional embedding model, because you're", "tokens": [51524, 509, 458, 11, 309, 307, 257, 857, 3571, 337, 309, 281, 360, 257, 27708, 12240, 3584, 2316, 11, 570, 291, 434, 51765], "temperature": 0.0, "avg_logprob": -0.26963240524818155, "compression_ratio": 1.6554621848739495, "no_speech_prob": 0.004982066340744495}, {"id": 1429, "seek": 676902, "start": 6769.02, "end": 6771.1, "text": " telling it what it is.", "tokens": [50364, 3585, 309, 437, 309, 307, 13, 50468], "temperature": 0.0, "avg_logprob": -0.310779776939979, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.00036829590681008995}, {"id": 1430, "seek": 676902, "start": 6771.1, "end": 6772.740000000001, "text": " Just makes it a bit easier.", "tokens": [50468, 1449, 1669, 309, 257, 857, 3571, 13, 50550], "temperature": 0.0, "avg_logprob": -0.310779776939979, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.00036829590681008995}, {"id": 1431, "seek": 676902, "start": 6772.740000000001, "end": 6782.860000000001, "text": " So then to do conditional sampling, you have to pass in what type of thing do you want", "tokens": [50550, 407, 550, 281, 360, 27708, 21179, 11, 291, 362, 281, 1320, 294, 437, 2010, 295, 551, 360, 291, 528, 51056], "temperature": 0.0, "avg_logprob": -0.310779776939979, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.00036829590681008995}, {"id": 1432, "seek": 676902, "start": 6782.860000000001, "end": 6786.9800000000005, "text": " from these labels.", "tokens": [51056, 490, 613, 16949, 13, 51262], "temperature": 0.0, "avg_logprob": -0.310779776939979, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.00036829590681008995}, {"id": 1433, "seek": 676902, "start": 6786.9800000000005, "end": 6798.9800000000005, "text": " And so then we create a vector just containing that number repeated, however many times there", "tokens": [51262, 400, 370, 550, 321, 1884, 257, 8062, 445, 19273, 300, 1230, 10477, 11, 4461, 867, 1413, 456, 51862], "temperature": 0.0, "avg_logprob": -0.310779776939979, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.00036829590681008995}, {"id": 1434, "seek": 679898, "start": 6799.139999999999, "end": 6801.339999999999, "text": " are in the batch.", "tokens": [50372, 366, 294, 264, 15245, 13, 50482], "temperature": 0.0, "avg_logprob": -0.24806989942278182, "compression_ratio": 1.7083333333333333, "no_speech_prob": 2.282796958752442e-05}, {"id": 1435, "seek": 679898, "start": 6801.339999999999, "end": 6804.299999999999, "text": " And we pass it to our model.", "tokens": [50482, 400, 321, 1320, 309, 281, 527, 2316, 13, 50630], "temperature": 0.0, "avg_logprob": -0.24806989942278182, "compression_ratio": 1.7083333333333333, "no_speech_prob": 2.282796958752442e-05}, {"id": 1436, "seek": 679898, "start": 6804.299999999999, "end": 6810.139999999999, "text": " So our model has now learned how to denoise something of type C. And so now if we say,", "tokens": [50630, 407, 527, 2316, 575, 586, 3264, 577, 281, 1441, 38800, 746, 295, 2010, 383, 13, 400, 370, 586, 498, 321, 584, 11, 50922], "temperature": 0.0, "avg_logprob": -0.24806989942278182, "compression_ratio": 1.7083333333333333, "no_speech_prob": 2.282796958752442e-05}, {"id": 1437, "seek": 679898, "start": 6810.139999999999, "end": 6816.419999999999, "text": " like, oh, trust me, this noise contains, is a noised image of type C, it should hopefully", "tokens": [50922, 411, 11, 1954, 11, 3361, 385, 11, 341, 5658, 8306, 11, 307, 257, 572, 2640, 3256, 295, 2010, 383, 11, 309, 820, 4696, 51236], "temperature": 0.0, "avg_logprob": -0.24806989942278182, "compression_ratio": 1.7083333333333333, "no_speech_prob": 2.282796958752442e-05}, {"id": 1438, "seek": 679898, "start": 6816.419999999999, "end": 6821.86, "text": " denoise it into something of type C. That's all there is to it.", "tokens": [51236, 1441, 38800, 309, 666, 746, 295, 2010, 383, 13, 663, 311, 439, 456, 307, 281, 309, 13, 51508], "temperature": 0.0, "avg_logprob": -0.24806989942278182, "compression_ratio": 1.7083333333333333, "no_speech_prob": 2.282796958752442e-05}, {"id": 1439, "seek": 679898, "start": 6821.86, "end": 6825.0599999999995, "text": " There's no magic there.", "tokens": [51508, 821, 311, 572, 5585, 456, 13, 51668], "temperature": 0.0, "avg_logprob": -0.24806989942278182, "compression_ratio": 1.7083333333333333, "no_speech_prob": 2.282796958752442e-05}, {"id": 1440, "seek": 679898, "start": 6825.0599999999995, "end": 6827.82, "text": " So yeah, that's all we have to do to change the sampling.", "tokens": [51668, 407, 1338, 11, 300, 311, 439, 321, 362, 281, 360, 281, 1319, 264, 21179, 13, 51806], "temperature": 0.0, "avg_logprob": -0.24806989942278182, "compression_ratio": 1.7083333333333333, "no_speech_prob": 2.282796958752442e-05}, {"id": 1441, "seek": 682782, "start": 6827.82, "end": 6832.0599999999995, "text": " So like we didn't have to change ddimstep at all, right?", "tokens": [50364, 407, 411, 321, 994, 380, 362, 281, 1319, 274, 13595, 16792, 412, 439, 11, 558, 30, 50576], "temperature": 0.0, "avg_logprob": -0.36091663526452106, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.00027371980831958354}, {"id": 1442, "seek": 682782, "start": 6832.0599999999995, "end": 6837.9, "text": " Literally all we did was we added this one line of code, and we added it there.", "tokens": [50576, 23768, 439, 321, 630, 390, 321, 3869, 341, 472, 1622, 295, 3089, 11, 293, 321, 3869, 309, 456, 13, 50868], "temperature": 0.0, "avg_logprob": -0.36091663526452106, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.00027371980831958354}, {"id": 1443, "seek": 682782, "start": 6837.9, "end": 6842.86, "text": " So now we can say, okay, let's say class ID 0, which is t-shirt top.", "tokens": [50868, 407, 586, 321, 393, 584, 11, 1392, 11, 718, 311, 584, 1508, 7348, 1958, 11, 597, 307, 256, 12, 15313, 1192, 13, 51116], "temperature": 0.0, "avg_logprob": -0.36091663526452106, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.00027371980831958354}, {"id": 1444, "seek": 682782, "start": 6842.86, "end": 6846.42, "text": " So we pass that to sample.", "tokens": [51116, 407, 321, 1320, 300, 281, 6889, 13, 51294], "temperature": 0.0, "avg_logprob": -0.36091663526452106, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.00027371980831958354}, {"id": 1445, "seek": 682782, "start": 6846.42, "end": 6847.42, "text": " And there we go.", "tokens": [51294, 400, 456, 321, 352, 13, 51344], "temperature": 0.0, "avg_logprob": -0.36091663526452106, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.00027371980831958354}, {"id": 1446, "seek": 682782, "start": 6847.42, "end": 6850.46, "text": " Everything looks like t-shirts and tops.", "tokens": [51344, 5471, 1542, 411, 256, 12, 25892, 293, 22836, 13, 51496], "temperature": 0.0, "avg_logprob": -0.36091663526452106, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.00027371980831958354}, {"id": 1447, "seek": 685046, "start": 6850.46, "end": 6862.1, "text": " Yeah, okay, I'm glad we didn't leave that till next time, because it's, we can now say", "tokens": [50364, 865, 11, 1392, 11, 286, 478, 5404, 321, 994, 380, 1856, 300, 4288, 958, 565, 11, 570, 309, 311, 11, 321, 393, 586, 584, 50946], "temperature": 0.0, "avg_logprob": -0.34605228900909424, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.08879917114973068}, {"id": 1448, "seek": 685046, "start": 6862.1, "end": 6870.9800000000005, "text": " we have successfully replicated everything in stable diffusion, except for being able", "tokens": [50946, 321, 362, 10727, 46365, 1203, 294, 8351, 25242, 11, 3993, 337, 885, 1075, 51390], "temperature": 0.0, "avg_logprob": -0.34605228900909424, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.08879917114973068}, {"id": 1449, "seek": 685046, "start": 6870.9800000000005, "end": 6875.5, "text": " to create whole sentences, which is what we do with Clip.", "tokens": [51390, 281, 1884, 1379, 16579, 11, 597, 307, 437, 321, 360, 365, 2033, 647, 13, 51616], "temperature": 0.0, "avg_logprob": -0.34605228900909424, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.08879917114973068}, {"id": 1450, "seek": 685046, "start": 6875.5, "end": 6876.5, "text": " Getting really close.", "tokens": [51616, 13674, 534, 1998, 13, 51666], "temperature": 0.0, "avg_logprob": -0.34605228900909424, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.08879917114973068}, {"id": 1451, "seek": 685046, "start": 6876.5, "end": 6877.5, "text": " Yes.", "tokens": [51666, 1079, 13, 51716], "temperature": 0.0, "avg_logprob": -0.34605228900909424, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.08879917114973068}, {"id": 1452, "seek": 685046, "start": 6877.5, "end": 6880.14, "text": " Well, except that Clip requires like.", "tokens": [51716, 1042, 11, 3993, 300, 2033, 647, 7029, 411, 13, 51848], "temperature": 0.0, "avg_logprob": -0.34605228900909424, "compression_ratio": 1.4676616915422886, "no_speech_prob": 0.08879917114973068}, {"id": 1453, "seek": 688014, "start": 6880.820000000001, "end": 6882.06, "text": " All of NLP.", "tokens": [50398, 1057, 295, 426, 45196, 13, 50460], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1454, "seek": 688014, "start": 6882.06, "end": 6889.34, "text": " So I guess we might do that next, or depending on how research goes.", "tokens": [50460, 407, 286, 2041, 321, 1062, 360, 300, 958, 11, 420, 5413, 322, 577, 2132, 1709, 13, 50824], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1455, "seek": 688014, "start": 6889.34, "end": 6891.34, "text": " All right.", "tokens": [50824, 1057, 558, 13, 50924], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1456, "seek": 688014, "start": 6891.34, "end": 6896.54, "text": " We still need the latent diffusion part.", "tokens": [50924, 492, 920, 643, 264, 48994, 25242, 644, 13, 51184], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1457, "seek": 688014, "start": 6896.54, "end": 6898.54, "text": " Oh, good point.", "tokens": [51184, 876, 11, 665, 935, 13, 51284], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1458, "seek": 688014, "start": 6898.54, "end": 6899.54, "text": " Latents.", "tokens": [51284, 7354, 791, 13, 51334], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1459, "seek": 688014, "start": 6899.54, "end": 6902.42, "text": " Okay, we'll definitely do that next time.", "tokens": [51334, 1033, 11, 321, 603, 2138, 360, 300, 958, 565, 13, 51478], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1460, "seek": 688014, "start": 6902.42, "end": 6903.42, "text": " So let's see.", "tokens": [51478, 407, 718, 311, 536, 13, 51528], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1461, "seek": 688014, "start": 6903.42, "end": 6909.02, "text": " Yeah, so we'll do a VAE and latent diffusion.", "tokens": [51528, 865, 11, 370, 321, 603, 360, 257, 18527, 36, 293, 48994, 25242, 13, 51808], "temperature": 0.0, "avg_logprob": -0.42181088707663794, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.010319397784769535}, {"id": 1462, "seek": 690902, "start": 6910.02, "end": 6912.620000000001, "text": " Which isn't enough for one lesson.", "tokens": [50414, 3013, 1943, 380, 1547, 337, 472, 6898, 13, 50544], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1463, "seek": 690902, "start": 6912.620000000001, "end": 6915.820000000001, "text": " So maybe some of the research I'm doing will end up in the next lesson as well.", "tokens": [50544, 407, 1310, 512, 295, 264, 2132, 286, 478, 884, 486, 917, 493, 294, 264, 958, 6898, 382, 731, 13, 50704], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1464, "seek": 690902, "start": 6915.820000000001, "end": 6916.820000000001, "text": " But yes.", "tokens": [50704, 583, 2086, 13, 50754], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1465, "seek": 690902, "start": 6916.820000000001, "end": 6919.42, "text": " Okay, thanks for the reminder.", "tokens": [50754, 1033, 11, 3231, 337, 264, 13548, 13, 50884], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1466, "seek": 690902, "start": 6919.42, "end": 6928.3, "text": " Although we've already kind of done autoencoders, so VAEs are going to be pretty, pretty easy.", "tokens": [50884, 5780, 321, 600, 1217, 733, 295, 1096, 8399, 22660, 378, 433, 11, 370, 18527, 20442, 366, 516, 281, 312, 1238, 11, 1238, 1858, 13, 51328], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1467, "seek": 690902, "start": 6928.3, "end": 6930.38, "text": " Well thank you, Tanishka and Jono.", "tokens": [51328, 1042, 1309, 291, 11, 314, 7524, 2330, 293, 7745, 78, 13, 51432], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1468, "seek": 690902, "start": 6930.38, "end": 6932.46, "text": " Fantastic comments, as always.", "tokens": [51432, 21320, 3053, 11, 382, 1009, 13, 51536], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1469, "seek": 690902, "start": 6932.46, "end": 6936.22, "text": " Glad your internet slash power reappeared, Jono.", "tokens": [51536, 28301, 428, 4705, 17330, 1347, 35638, 68, 1642, 11, 7745, 78, 13, 51724], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1470, "seek": 690902, "start": 6936.22, "end": 6938.22, "text": " Back up.", "tokens": [51724, 5833, 493, 13, 51824], "temperature": 0.0, "avg_logprob": -0.40216753124135785, "compression_ratio": 1.492, "no_speech_prob": 0.0016742023872211576}, {"id": 1471, "seek": 693822, "start": 6938.42, "end": 6940.42, "text": " Yes.", "tokens": [50374, 1079, 13, 50474], "temperature": 0.0, "avg_logprob": -0.5566433668136597, "compression_ratio": 1.0606060606060606, "no_speech_prob": 0.06938407570123672}, {"id": 1472, "seek": 693822, "start": 6940.42, "end": 6942.42, "text": " All right.", "tokens": [50474, 1057, 558, 13, 50574], "temperature": 0.0, "avg_logprob": -0.5566433668136597, "compression_ratio": 1.0606060606060606, "no_speech_prob": 0.06938407570123672}, {"id": 1473, "seek": 693822, "start": 6942.42, "end": 6944.42, "text": " Thanks, gang.", "tokens": [50574, 2561, 11, 10145, 13, 50674], "temperature": 0.0, "avg_logprob": -0.5566433668136597, "compression_ratio": 1.0606060606060606, "no_speech_prob": 0.06938407570123672}, {"id": 1474, "seek": 693822, "start": 6944.42, "end": 6945.42, "text": " Cool.", "tokens": [50674, 8561, 13, 50724], "temperature": 0.0, "avg_logprob": -0.5566433668136597, "compression_ratio": 1.0606060606060606, "no_speech_prob": 0.06938407570123672}, {"id": 1475, "seek": 693822, "start": 6945.42, "end": 6946.42, "text": " Thanks, everybody.", "tokens": [50724, 2561, 11, 2201, 13, 50774], "temperature": 0.0, "avg_logprob": -0.5566433668136597, "compression_ratio": 1.0606060606060606, "no_speech_prob": 0.06938407570123672}, {"id": 1476, "seek": 693822, "start": 6946.42, "end": 6947.42, "text": " That was great.", "tokens": [50774, 663, 390, 869, 13, 50824], "temperature": 0.0, "avg_logprob": -0.5566433668136597, "compression_ratio": 1.0606060606060606, "no_speech_prob": 0.06938407570123672}], "language": "en"}