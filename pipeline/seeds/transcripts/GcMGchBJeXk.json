{"text": " Okay, is that better? Can you see and hear me now? Great. Sorry about the delay. Okay. I just had to restart Chrome for some reason. All right. So there's a few possible directions we can go, but maybe we could just dive into transforms. Not because particularly it's code that many people need to understand, but I think it's kind of interesting code. It's interesting Python code. So it's fun to see how the basics, the lowest level stuff is put together. And then we can kind of build back from there, look at data source and look at data blocks. Maybe first of all, though, we'll have a quick look at data blocks. Because you can kind of see where we're heading with this, which we can simplify. I guess that makes sense. Okay. So basically where we're getting to is here are some examples. So here's an example of MNIST using the new data blocks API. And as you can see, it's not a fluent API anymore. Just a moment. Sorry about that. Okay. So it's not a fluent API anymore. But now it's more of a, I don't know how to describe it. It's kind of similar to these other callbacks slash subclass APIs like the data loader one. So you can now subclass from a data block and define the normal things that we're used to from version one. Or you can construct it and pass in exactly the same things as functions. So the data blocks API ends up looking kind of similar. But in some ways it's kind of easier to use because you can see easily what things you can pass to it. But then it ends up looking pretty similar. So there's MNIST, here's pets. As you can see, it looks pretty familiar. Here's planet. Again, same kind of output. And so planet, there's a few ways to do it. One is again, by passing things in. Actually, here's a super simple way to do it. Very nice and easy. Here's segmentation. Sorry, here's camvod. Here is the BEE points one. And finally, here is Cocoa, bounding boxes. So you can see we're going to end up with a nice simple data block API. But here's the coolest part. Here is the entire definition of the data block class. As you can see, it fits on less than one screen of code. And the reason for that is all that intermediate API stuff we built makes creating stuff like this super, super simple. For questions about any of the data sets I just showed, have a look at the most recent courses. Because they're all described there. And yes, David, this new API does present accidental wrong ordering because there's no order to these things. They're just either subclasses. They're either subclasses or parameters. I think I'm getting a cold. Excuse me. So yeah, that's one of the nice things here. OK. So that's the kind of payoff of all this. It's just so easy to create these kinds of things. So yeah, let's start pretty close to the bottom of the layers now. And let's look at transforms. So before we do, I will answer this question from Gocor, which is my thought process when designing an API. I don't design really anything much at all. I just throw code out there. And I then refactor it again and again and again. So I try to make sure I've got pretty good tests. And I keep refactoring it until it gets to the point where I feel like it's so easy that even I will understand it in six months' time. With previous versions of fast.ai, I haven't had the time to fully do that. But with this version, I do. So as you can see, every function is super short and easy, which is really nice. So yeah, lots and lots of refactoring. So transforms, the basic transform class is here. Again, less than a line of code. Sorry, a screen of code. But the work's really happening in the meta class. Because what happens is when we call dundercall or decode, it's going to call encodes and decodes by this little intermediate thing, underscore call. Which we haven't really looked at filters much yet, but once we get to data source, you'll see this is how we do things on just the training set or just the validation set or both. That's what filters are. But basically we check whether we're doing as item is true or false. If we're doing as item, then we just call the function, decodes or encodes. If it's tuple behavior rather than item behavior, then we call it for each element of the list and turn it into a tuple. So that's all pretty simple. But the trick is what are encodes and decodes, because we know these are things which have a few cool things we can do. We can, let's see what we can do. We can pass methods in or we can subclass. And most interestingly, we can have a type annotation and we can have multiple encodes slash decodes with each with different type annotation. So there's some other things we'll look at. Okay, so let's look at how we, okay, so the first two are pretty straightforward. Our init, you can pass in an encoder and or a decoder. And if you pass either of those in, then it will create the encoder and decoder, encodes and decodes based on what you pass in. But as you can see, they are not just methods. There's something called type dispatch. So that's what we're going to have to look at. If you don't pass in an enc or dec, which will be, that means this will be false, then somehow encodes and decodes have already been created for us. So I have to figure out how that happens. Okay, so let's take a look. So answering questions, mixing tabular and text, for example, yes, we certainly want to do that, but we haven't started on it. Not sure what you're asking exactly AJ about student projects at USF, but maybe ask on the forums. Joseph to subclass something simply means to type class something and then put something in brackets. So for example, there is a subclass of transform. In other words, I am subclassing transform. Okay, so if we look underneath here, we can see some of the kind of behaviors being used. Oh, here's another interesting behavior, which is that we can we can use a class, a subclass of transform as a decorator to add a encodes or decodes to an existing class. So let's add that decorator behavior. Okay, yeah, Max, we're going to be talking about filters later when we look at data source. But basically just it's something that we're going to have a zero generally as a training set filter zero is training set filter one is generally the validation set, you can have more than just those two and transforms know basically which data set they're being applied to so they can have different behavior for training versus validation optionally, but we'll look at that later. Okay, so here's an example of class transform a, which is getting an encodes, which is just x plus one. So we can check that that works, we should be able to subclass that transform so that checks that works. And here's an empty transform. So it should do nothing at all. So that checks that that works. But then later on, we'll get to the tests where, for example, we are making sure things only work on a particular subclass, in this case, tensor image. So here's the test, we're going to create one of these objects. And we will call it, we should end up with a negative number, assuming that this was a something of type tensor image. Whereas if we pass something which is not a type tensor image, in this case, an int, nothing should happen at all. Okay. Also, when we do this, we should not be changing the type, so we check that the type is still a tensor image. Okay, so let's see how some of that works. So the trick is that all the stuff is happening in the meta class. What's a meta class? RedX given some good examples and code walkthroughs with some meta class stuff on the forums. So check that out. But basically, when you go class something like that, that's creating a new class. By the way, if you don't know, dot dot dot is basically the same as typing pass in Python. So that's created a new class, as you can see. And how does it do that? Well, class foo, writing this, is basically syntax sugar for calling type and passing in these three things. A name, so foo, let's call this one foo2. Some bases, so the base class is always implicitly, unless you write otherwise, object. So it's object. And a dictionary of stuff to put in the class, which in this case is empty. Oh, tap or not on this. That seems a little fussy. And so let's call that foo2. Foo2. You can see they're very similar looking things. So in other words, this is just syntax sugar for calling this thing called type. What is type? You can find out the type of something by using the single argument version of type. And the type of type is type. In other words, type is a class. And so this is a constructor. And it constructs something. So if I go type foo2, it constructs something of type type. And so there are all kinds of attributes that a type has. So in particular, one of the important ones is I can put here a colon one. The most important is dunderdict. And dunderdict is basically a dictionary. It's a slightly special kind of dictionary. It's a dictionary which contains a mapping from names to values. And in particular, anything that I passed in here ends up in that dictionary. There's another way to put things in the dictionary, which is to use this special syntax sugar that we get in Python, which is like this. And so now if I say foo.dict, you can see it's got the same thing, a equals one. So when you type that into a class, it's actually just a shortcut for creating an a attribute in the dunderdict attribute of the class. OK, a bunch of questions. What's for recommended systems? No plans yet. Why are we using meta class? Basically, among the reasons I started using meta classes in version two is because I wanted to change the things about how Python worked that I didn't really have the time to change version one. So things like this, all the stuff we're going to look at doing with transforms are impossible to do without meta classes. So yes, max type creates class objects and then class objects create instances, exactly right. OK. So it also means in Python, it's worth knowing how these syntax sugar things work. When you go like this, if you go like that, for example, then that's the same as saying f equals and then passing in some function. And so if you look at the dict, you'll see you end up with f and then some function. So really, you know, there's not that much. There's a small, concise, elegant set of foundations in Python and the kind of stuff that we type day to day is a bunch of kind of little bits of syntax sugar for those foundations. So if I go to dot a, that is also syntax sugar. And specifically, it's syntax sugar for Dunder dict. A. OK, so this is all important to understand when we look at meta classes. And the reason why is because a meta class is something where we're going to replace type. We're going to say I want to create a class that does not use the type constructor but uses some other constructor. And the way you do that in Python is you type meta class equals and then you type the name of the class you want to construct this class. You can create a class from scratch, but normally you wouldn't. It's easiest to subclass type. So here I'm going to inherit from type. And if you remember, type takes three things, object or name, basis, dict. So Dunder new always requires class first. And then here it is, name, basis, dict. So if I wanted to create a super simple meta class, then I could just. So here's something which just returns super. So it's not going to change anything at all, but it will work, right? Meta class equals m. There you go, I have a class. It has a Dunder dict. So you can now start inserting things in here. And see how this printed as soon as I typed class T pass, right? It didn't print after I created an object of type T. It appeared as soon as I created the class. So Python is going to call this code any time I try to actually create a class, not when I try to instantiate it. Yep, res is result. So in this case we are replacing three things, new, call, and prepare. So there is a really cool piece of documentation called the Python data model. And the Python data model describes how all this works. Not just all this, but everything. It describes how Python is, how everything happens. So there's a section called customizing class creation where you can see all of the stuff that happens, including 3.3.3.1 meta classes. By default they are constructed using type. So I could click on type. And we can see in three arguments it returns a new type object. And then we can find out about type objects. And so forth. Okay. So meta classes, as it says, you say meta class equals blah. And the first thing that happens is it has to prepare the class namespace. And the class namespace is the thunder dict object. So if we were to keep creating our underscore m, we could just return an empty dictionary. And as you can see, it all works. And I guess we should be able to put something in it even. Okay, there it is. Right. So you can see thunder dict is created by calling your thunder prepare. And this is actually a way you can insert something into every single class which has a meta class. So to understand the difference between the different arguments to the meta class constructor, you would want to read 3.3.3 of the data model reference in the Python docs. Okay. So in our case, we've replaced prepare so it's not returning a dictionary. But instead it's returning some special kind of dictionary called a tfm dict. So a tfm dict is a dictionary that overrides under set item. Actually, I'm planning to change this. So I had things set up so you could use either underscore or encodes. I'm actually going to rip rid of the thing that lets you use underscore. So ignore that. So basically, if you're calling something that isn't encodes or decodes, then it's just the normal dictionary. As you can see, this inherits from dict. But if it is encodes or decodes, then what I do is I check whether or not I already have an encodes or decodes in my class. And if I don't, then I create one using dicts set item. And what I set it to is I set it to a type dispatch object. So in other words, this tfm dict is something which behaves exactly like a normal dictionary. And so it's going to be inside my dunder dict for anything that uses this meta class. And it's not going to work differently at all, except for two special things called encodes and decodes. And in those cases, it's going to use something called type dispatch. So let's try that. So if I go class a meta class equals def meta. Well, let's and then let's say def encodes self turn x. So a dot encodes. Oh, that's not a normal function. What type is it? Oh, it's a type dispatch. And that's because of this. So why create a meta class instead of inheriting from the class? They do different things. By inheriting from a class, you can't change the behavior of type creation. So we're trying to create something where anything that is inheriting from transform gets a different class behavior. And so it's impossible to do the things we're describing by inheriting. There's no way, for example, normally to be able to say, I want to have two different encodes for two different types, for instance, that would normally be impossible. But thanks to meta classes and to dunder prepare, we know that each time it sees this, it's going to call our replacement dicts dunder set item with a key of encodes and the value of the function. And we can do whatever we like. And so what we're going to do is we're going to create an encodes decodes type dispatch object if we don't already have one. And then we're going to add this function to that type dispatch object. So let's try that. If I add this twice with two different things, you can see now float has one thing and int has a different thing. So let's then have a look at type dispatch. So yeah, this is like a huge rabbit hole. It's basically how do you make Python do whatever you want it to do. Python is a dynamic language. And so they created this amazing data model to allow us to customize anything we like in Python. But it takes some time to get used to. So it taught me a lot of reading and studying and looking at lots of different places to get the hang of all this. And so I don't expect to understand it all the first time around. I'm not sure what built in functionality you're referring to, Max. I don't think Python has anything which does what I just described, which is why I'm doing something I don't think it does before. OK. So here is the type dispatch class. And basically it's going to be something which we know it's going to have to work a lot like a dictionary because we're going to be adding things to it. And what's going to happen, actually, I haven't quite shown you all this yet. What's going to happen is we're going to let's see, we're going to grab encodes. We're going to call, yes, so we're going to call the function. And when we call the function, well, Max, we're not just checking types. We're dispatching on types. There's a big difference between checking types and dispatching on types. So we're actually building something where we're able to call different code depending on types. So, yeah, so there isn't a way to do that in Python. So as we've discussed in previous walkthroughs, when you look at, for example, data augmentation, we're going to have class rotate, which when we first define it might be empty. And then later on when you say, oh, I've got something for a tensor image, then we'll say at rotate. And it'll say def encodes, X colon tensor image, and then degrees. And then there'll be some functionality for that. And then in some other place, there's going to be X colon bounding box. And it's going to be different also whether we're encoding or decoding. So it's quite different functionality. So, yeah, so type dispatch. Dispatch is referring to how does a programming language decide what piece of code to run when you call something? So for example, there's all kinds of different ways of doing dispatch in Python. The main one that is used for methods, for example, is something called MRO, which is a method resolution order. Yeah, so it's basically all the rules in a language about how do you decide which piece of code to call when you call some function. And different languages do it all kinds of different ways. And yeah, check out some of the earlier walkthroughs if you want more information about why we're doing this dispatch. Yes, thank you. I mentioned that should have been transform if we want that to work. Okay. So what we want is we want something which looks like a function. So that means it has to have a Dunder call. But when you call it with some argument, we're not just going to call a function, but we're going to look at the type of that argument and we're going to try to find the appropriate function or method to call based on the type of that argument and based on which methods have been created so far. And so what's going to happen is that inside our type dispatch object, there will be a dictionary called funcs and that's going to contain a dictionary where the key is the type. So for example, in this case, we're going to have keys tensor image and B box and the value is the actual function to call. So that's, that's the key thing is the funcs. So then there was an add method and that is what the firm dict calls. It adds this function and the add method is going to find out the type annotation for the first parameter. P1 and O is parameter number one annotation. So it'll grab the type. If there is none, then it's assuming that it's object because that's the highest level of the type hierarchy and it's going to pop that into our functions dictionary. So then later on, when you call done to call, it's going to look up the type of the parameter that you're calling this function on and it's going to look it up in this object. If it doesn't find it, then it does nothing at all. So that's kind of the rule, right? If you only have like a rotate defined for tensor image and B box and then you call it with int, then nothing happens because that function isn't defined. If we did find it, then we just call it with that argument and anything else that you passed along. And you can actually tag things to say, I want you to turn it into a method, which is something we might talk about later if people are interested. But basically it's just going to create a normal function unless you ask it to be a method. So the key thing then is how does this line of code work? How does it look up the type? So as you can see, it's calling done to get item. And basically what we're going to do is we're going to keep a cache, which is a dictionary mapping from types to functions. And we need a special cache dictionary because the way type dispatch works is it doesn't just look up say tensor image or B box, but it also looks for any subclasses of those things. So for example, we could have also, as we discussed in an earlier walkthrough, tensor. And in this case, then it's going to, if you pass a tensor image, it'll grab the most specific version it can, which is a tensor image version. So, right, so I think I just answered your question, which is the opposite of that. If you call it on something, which is a subclass of tensor image, it will be invoked. And the reason why is because of how we create this cache. And so if we don't find it in the cache, then we're going to add it to the cache. And what we do is we create a list of all of the types that are registered for which there is the appropriate subclass relationship. And we, how do we do this? And notice that the functions have been ordered by a comparator which checks for subclass relationships. And so we grab the first one, so the first one is the most specific type of the ones that are, that it's a subclass of. This takes a little bit of time, we don't want to have to do this every time we call this function. So once we find the right one, we pop it in the cache. So next time around, we can just grab it. Okay, so that is type dispatch. And so the key way to understand it really is to look at the tests, right? So you can see here we've got things at lots of different levels of hierarchy. There's a parameter that's a collection, some kind of integer, tensor, mask or image, a ball, some kind of number, right? So these are all functions. So we can create a type dispatch object with all of those different functions in. And so we should try, if we look up int, for instance, then we should get back this one, because none of them were defined with int specifically, but it's going to match number and integral. Integral is more specific type than number, so that's why it matches bad. String doesn't match any of them, so it's a none. So here's the same kind of thing, but this time after creating the object, we'll actually start calling some functions and make sure that they do the right thing. Okay, so that is type dispatch. So yeah, it's, to get the Python data model in your head requires kind of putting all these things together, but the nice thing is once it is all in your head, you can put it together the way we have here. So we were able to replace the normal dictionary by replacing prepare with tiffmdict. Tiffmdict is something which, instead of a normal dictionary, when you set the item as encodes or decodes, it actually creates a type dispatch object and adds to it. And that means that now, when we inherit from transform and we create an encodes or decodes attribute, it will actually add it to the encodes or decodes type dispatch. And so when we call encodes or decodes, we get this behavior, which is to get a negative version of this because it's a tensor image and a non-negative version of this because it's not a tensor image. So this specifically is single dispatch, not multiple dispatch. So it only looks up. Let's find it. When you add it, it only adds the, so p1ano is a function, teeny tiny little function here, which just grabs the first parameter annotation. So this will only do type dispatch based on the first non-self parameter. So, Hiromi, that's a very good question. Why not throw an error? Basically because of what I was describing before, if you are defining, say, rotate data augmentation for various types, then generally speaking, if you don't have it defined for your type, then probably what we want to do is nothing at all. So the basic idea is that these kind of transforms are things you can opt into. If you do want to create a transform, if you do want to create a transform which throws an error, if you call it with something that doesn't exist, you certainly can. Let's do it. So here's a transform. And so if we say def encodes, and we'll say here raise, not implemented, and then we'll go def encodes self, comma, x, colon, int, return x plus one. So let's go a equals a, and then we can go a one, that returns two, a high, and that's going to return, oh, is that not the right one? Not implemented error. There we go, not implemented error. So you can certainly add that. And so the reason this works is because remember that if you don't have an annotation, it's the same as saying object, that's kind of the way Python normally does things, that's the way we do things too. And since that's the highest thing up in the inheritance hierarchy, that's the one that it would end up calling if you don't provide some other behavior. So thank you for that excellent question. Okay, so that is the way that we handle dispatch. So the next thing is what about the way we can treat a transform subclass as a decorator? So if you remember, a decorator, when you see something like this, will actually call this as a callable and pass this function to it. So that is basically identical to saying something like def underscore encodes equals that, and then encodes equals a parenthesis, and actually what I should say is, no, I just say, yeah, a underscore encodes. It's basically the same as doing that. And we should find that the same test then passes. We have to say a equals that. Let's see. Ah, yes, it's slightly different because it thinks of it as not as a method. Okay, so it's not exactly the same. It's nearly the same, not because of Python, because of stuff we do. So we'll come back to that later. Okay, so the reason we can use this as a decorator is because that means that our class is going to have to support, be a callable basically. Now classes are normally callables because you can instantiate a class, obviously. So if you go class B like this, then you go B equals B, then you're calling B as a callable, or B's type, B's meta type as a callable. So that means if we go to our meta class, we can redefine done to call. And that means we can redefine what happens when we instantiate this class. So if we instantiate this class, or if we done to call this class, and we pass in some argument, and if that argument is callable, and it's not decodes or encodes, then we are going to add that function to our type dispatch. And so that's exactly what happens when we say at A def encodes blah blah blah. It's just going to add that function to this class's type dispatch. So you can see here it calls.add, which is the.add that we had here in type dispatch. So this is the thing that basically registers another type. Okay, so that's that. There's one last piece which is done to new. So this is the thing that first gets called when you're creating a new type. And one of the things I discovered which is super annoying is that if I create a new type, like so, any type of type even without being a meta type, and I define a done to new, like so. So here's some class, and then I define some subclass, and I say init, like so. And then so I want to instantiate that, and then I shift tab, oh that was not what I expected to happen, oh sorry, and class B inherits from A, and I shift tab. You can see the signature is star arg star star quarks, or else I would have expected the signature to be A, as it would be if I removed my base class. So I found that super annoying because like you want to customize new all the time, not all the time, but very frequently, and pretty much most of the time when you customize it, you're going to use star arg star star quarks because you don't want to define what base classes can do. But as soon as you do that, you kill the signature, like so. So I don't know why it works that way, and maybe I'm missing something, but what I did here was I replaced the signature for the class with a signature for the dunder init, so that we get the right nice signature. So if we try that, here we have a look at transform, you can see we get the correct signature as we would want. Because otherwise it's not just dunder new, it would also be dunder call from the meta class, it would also replace the signature otherwise. So that's why that's there. So believe it or not, that's actually all the pieces. And so if you want to study this, like so the first thing to point out is none of this is at all necessary to understand fast AI version 2. It's no more important than understanding the meta object data model is to use Python day to day. It's an advanced technique which you can learn about if you're interested, and if you're interested in learning more about how Python works behind the scenes, so you can try doing stuff like this yourself if you want to create, change how Python works and fully use its dynamic features. So if you want to fully understand what transform does, just check out all the tests. We've tried to make it so that each test does one thing, you know, one shows one clear type of behavior, and we try to add comments explaining what each behavior is that it's showing. So yeah, hopefully that all is useful for those of you that are interested. So then you can see tuple transform and item transform just force add item to be true or false. And lots more tests of that behavior, as you can see. All right. Well, I think that's enough for today because that was super dense. And yeah, if you start looking through this code and want to learn more about it, feel free to ask any questions you like. All right. Thanks, everybody. Bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 18.080000000000002, "text": " Okay, is that better?", "tokens": [50364, 1033, 11, 307, 300, 1101, 30, 51268], "temperature": 0.0, "avg_logprob": -0.8009208043416342, "compression_ratio": 0.7241379310344828, "no_speech_prob": 0.18298350274562836}, {"id": 1, "seek": 3000, "start": 30.0, "end": 44.44, "text": " Can you see and hear me now?", "tokens": [1664, 291, 536, 293, 1568, 385, 586, 30], "temperature": 0.0, "avg_logprob": -0.38149474916004, "compression_ratio": 0.8787878787878788, "no_speech_prob": 0.016879083588719368}, {"id": 2, "seek": 3000, "start": 44.44, "end": 49.519999999999996, "text": " Great. Sorry about the delay.", "tokens": [3769, 13, 4919, 466, 264, 8577, 13], "temperature": 0.0, "avg_logprob": -0.38149474916004, "compression_ratio": 0.8787878787878788, "no_speech_prob": 0.016879083588719368}, {"id": 3, "seek": 4952, "start": 49.52, "end": 60.0, "text": " Okay. I just had to restart Chrome for some reason.", "tokens": [1033, 13, 286, 445, 632, 281, 21022, 15327, 337, 512, 1778, 13], "temperature": 0.0, "avg_logprob": -0.4307672679424286, "compression_ratio": 0.9107142857142857, "no_speech_prob": 2.4282133381348103e-05}, {"id": 4, "seek": 6000, "start": 60.0, "end": 85.2, "text": " All right. So there's a few possible directions we can go, but maybe we could just dive into", "tokens": [1057, 558, 13, 407, 456, 311, 257, 1326, 1944, 11095, 321, 393, 352, 11, 457, 1310, 321, 727, 445, 9192, 666], "temperature": 0.0, "avg_logprob": -0.20377649307250978, "compression_ratio": 1.0574712643678161, "no_speech_prob": 5.3057490731589496e-05}, {"id": 5, "seek": 8520, "start": 85.2, "end": 95.12, "text": " transforms. Not because particularly it's code that many people need to understand, but", "tokens": [35592, 13, 1726, 570, 4098, 309, 311, 3089, 300, 867, 561, 643, 281, 1223, 11, 457], "temperature": 0.0, "avg_logprob": -0.17435296376546225, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.648299338645302e-05}, {"id": 6, "seek": 8520, "start": 95.12, "end": 100.58, "text": " I think it's kind of interesting code. It's interesting Python code. So it's fun to see", "tokens": [286, 519, 309, 311, 733, 295, 1880, 3089, 13, 467, 311, 1880, 15329, 3089, 13, 407, 309, 311, 1019, 281, 536], "temperature": 0.0, "avg_logprob": -0.17435296376546225, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.648299338645302e-05}, {"id": 7, "seek": 8520, "start": 100.58, "end": 105.28, "text": " how the basics, the lowest level stuff is put together. And then we can kind of build", "tokens": [577, 264, 14688, 11, 264, 12437, 1496, 1507, 307, 829, 1214, 13, 400, 550, 321, 393, 733, 295, 1322], "temperature": 0.0, "avg_logprob": -0.17435296376546225, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.648299338645302e-05}, {"id": 8, "seek": 8520, "start": 105.28, "end": 114.0, "text": " back from there, look at data source and look at data blocks. Maybe first of all, though,", "tokens": [646, 490, 456, 11, 574, 412, 1412, 4009, 293, 574, 412, 1412, 8474, 13, 2704, 700, 295, 439, 11, 1673, 11], "temperature": 0.0, "avg_logprob": -0.17435296376546225, "compression_ratio": 1.5669642857142858, "no_speech_prob": 5.648299338645302e-05}, {"id": 9, "seek": 11400, "start": 114.0, "end": 124.76, "text": " we'll have a quick look at data blocks. Because you can kind of see where we're heading with", "tokens": [321, 603, 362, 257, 1702, 574, 412, 1412, 8474, 13, 1436, 291, 393, 733, 295, 536, 689, 321, 434, 9864, 365], "temperature": 0.0, "avg_logprob": -0.1625197796111411, "compression_ratio": 1.3185185185185184, "no_speech_prob": 2.3921780666569248e-05}, {"id": 10, "seek": 11400, "start": 124.76, "end": 139.9, "text": " this, which we can simplify. I guess that makes sense. Okay. So basically where we're", "tokens": [341, 11, 597, 321, 393, 20460, 13, 286, 2041, 300, 1669, 2020, 13, 1033, 13, 407, 1936, 689, 321, 434], "temperature": 0.0, "avg_logprob": -0.1625197796111411, "compression_ratio": 1.3185185185185184, "no_speech_prob": 2.3921780666569248e-05}, {"id": 11, "seek": 13990, "start": 139.9, "end": 151.76, "text": " getting to is here are some examples. So here's an example of MNIST using the new data blocks", "tokens": [1242, 281, 307, 510, 366, 512, 5110, 13, 407, 510, 311, 364, 1365, 295, 376, 45, 19756, 1228, 264, 777, 1412, 8474], "temperature": 0.0, "avg_logprob": -0.22388089620150053, "compression_ratio": 1.2907801418439717, "no_speech_prob": 9.972301995730959e-06}, {"id": 12, "seek": 13990, "start": 151.76, "end": 169.56, "text": " API. And as you can see, it's not a fluent API anymore. Just a moment. Sorry about that.", "tokens": [9362, 13, 400, 382, 291, 393, 536, 11, 309, 311, 406, 257, 40799, 9362, 3602, 13, 1449, 257, 1623, 13, 4919, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.22388089620150053, "compression_ratio": 1.2907801418439717, "no_speech_prob": 9.972301995730959e-06}, {"id": 13, "seek": 16956, "start": 169.56, "end": 179.28, "text": " Okay. So it's not a fluent API anymore. But now it's more of a, I don't know how to describe", "tokens": [1033, 13, 407, 309, 311, 406, 257, 40799, 9362, 3602, 13, 583, 586, 309, 311, 544, 295, 257, 11, 286, 500, 380, 458, 577, 281, 6786], "temperature": 0.0, "avg_logprob": -0.1494257324620297, "compression_ratio": 1.4705882352941178, "no_speech_prob": 1.7502226910437457e-05}, {"id": 14, "seek": 16956, "start": 179.28, "end": 186.72, "text": " it. It's kind of similar to these other callbacks slash subclass APIs like the data loader one.", "tokens": [309, 13, 467, 311, 733, 295, 2531, 281, 613, 661, 818, 17758, 17330, 1422, 11665, 21445, 411, 264, 1412, 3677, 260, 472, 13], "temperature": 0.0, "avg_logprob": -0.1494257324620297, "compression_ratio": 1.4705882352941178, "no_speech_prob": 1.7502226910437457e-05}, {"id": 15, "seek": 16956, "start": 186.72, "end": 194.38, "text": " So you can now subclass from a data block and define the normal things that we're used", "tokens": [407, 291, 393, 586, 1422, 11665, 490, 257, 1412, 3461, 293, 6964, 264, 2710, 721, 300, 321, 434, 1143], "temperature": 0.0, "avg_logprob": -0.1494257324620297, "compression_ratio": 1.4705882352941178, "no_speech_prob": 1.7502226910437457e-05}, {"id": 16, "seek": 19438, "start": 194.38, "end": 203.56, "text": " to from version one. Or you can construct it and pass in exactly the same things as", "tokens": [281, 490, 3037, 472, 13, 1610, 291, 393, 7690, 309, 293, 1320, 294, 2293, 264, 912, 721, 382], "temperature": 0.0, "avg_logprob": -0.1772552728652954, "compression_ratio": 1.5149700598802396, "no_speech_prob": 4.157171588303754e-06}, {"id": 17, "seek": 19438, "start": 203.56, "end": 211.85999999999999, "text": " functions. So the data blocks API ends up looking kind of similar. But in some ways", "tokens": [6828, 13, 407, 264, 1412, 8474, 9362, 5314, 493, 1237, 733, 295, 2531, 13, 583, 294, 512, 2098], "temperature": 0.0, "avg_logprob": -0.1772552728652954, "compression_ratio": 1.5149700598802396, "no_speech_prob": 4.157171588303754e-06}, {"id": 18, "seek": 19438, "start": 211.85999999999999, "end": 218.56, "text": " it's kind of easier to use because you can see easily what things you can pass to it.", "tokens": [309, 311, 733, 295, 3571, 281, 764, 570, 291, 393, 536, 3612, 437, 721, 291, 393, 1320, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.1772552728652954, "compression_ratio": 1.5149700598802396, "no_speech_prob": 4.157171588303754e-06}, {"id": 19, "seek": 21856, "start": 218.56, "end": 225.84, "text": " But then it ends up looking pretty similar. So there's MNIST, here's pets. As you can", "tokens": [583, 550, 309, 5314, 493, 1237, 1238, 2531, 13, 407, 456, 311, 376, 45, 19756, 11, 510, 311, 19897, 13, 1018, 291, 393], "temperature": 0.0, "avg_logprob": -0.20928630581149807, "compression_ratio": 1.5085714285714287, "no_speech_prob": 6.339064384519588e-06}, {"id": 20, "seek": 21856, "start": 225.84, "end": 241.32, "text": " see, it looks pretty familiar. Here's planet. Again, same kind of output. And so planet,", "tokens": [536, 11, 309, 1542, 1238, 4963, 13, 1692, 311, 5054, 13, 3764, 11, 912, 733, 295, 5598, 13, 400, 370, 5054, 11], "temperature": 0.0, "avg_logprob": -0.20928630581149807, "compression_ratio": 1.5085714285714287, "no_speech_prob": 6.339064384519588e-06}, {"id": 21, "seek": 21856, "start": 241.32, "end": 248.52, "text": " there's a few ways to do it. One is again, by passing things in. Actually, here's a super", "tokens": [456, 311, 257, 1326, 2098, 281, 360, 309, 13, 1485, 307, 797, 11, 538, 8437, 721, 294, 13, 5135, 11, 510, 311, 257, 1687], "temperature": 0.0, "avg_logprob": -0.20928630581149807, "compression_ratio": 1.5085714285714287, "no_speech_prob": 6.339064384519588e-06}, {"id": 22, "seek": 24852, "start": 248.52, "end": 261.08, "text": " simple way to do it. Very nice and easy. Here's segmentation. Sorry, here's camvod. Here is", "tokens": [2199, 636, 281, 360, 309, 13, 4372, 1481, 293, 1858, 13, 1692, 311, 9469, 399, 13, 4919, 11, 510, 311, 1945, 85, 378, 13, 1692, 307], "temperature": 0.0, "avg_logprob": -0.2568889082523814, "compression_ratio": 1.3, "no_speech_prob": 3.2377247407566756e-06}, {"id": 23, "seek": 24852, "start": 261.08, "end": 270.84000000000003, "text": " the BEE points one. And finally, here is Cocoa, bounding boxes. So you can see we're going", "tokens": [264, 363, 7258, 2793, 472, 13, 400, 2721, 11, 510, 307, 29787, 64, 11, 5472, 278, 9002, 13, 407, 291, 393, 536, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.2568889082523814, "compression_ratio": 1.3, "no_speech_prob": 3.2377247407566756e-06}, {"id": 24, "seek": 27084, "start": 270.84, "end": 279.03999999999996, "text": " to end up with a nice simple data block API. But here's the coolest part. Here is the entire", "tokens": [281, 917, 493, 365, 257, 1481, 2199, 1412, 3461, 9362, 13, 583, 510, 311, 264, 22013, 644, 13, 1692, 307, 264, 2302], "temperature": 0.0, "avg_logprob": -0.10767096615909191, "compression_ratio": 1.5903083700440528, "no_speech_prob": 4.710814664576901e-06}, {"id": 25, "seek": 27084, "start": 279.03999999999996, "end": 285.32, "text": " definition of the data block class. As you can see, it fits on less than one screen of", "tokens": [7123, 295, 264, 1412, 3461, 1508, 13, 1018, 291, 393, 536, 11, 309, 9001, 322, 1570, 813, 472, 2568, 295], "temperature": 0.0, "avg_logprob": -0.10767096615909191, "compression_ratio": 1.5903083700440528, "no_speech_prob": 4.710814664576901e-06}, {"id": 26, "seek": 27084, "start": 285.32, "end": 293.2, "text": " code. And the reason for that is all that intermediate API stuff we built makes creating", "tokens": [3089, 13, 400, 264, 1778, 337, 300, 307, 439, 300, 19376, 9362, 1507, 321, 3094, 1669, 4084], "temperature": 0.0, "avg_logprob": -0.10767096615909191, "compression_ratio": 1.5903083700440528, "no_speech_prob": 4.710814664576901e-06}, {"id": 27, "seek": 27084, "start": 293.2, "end": 298.88, "text": " stuff like this super, super simple. For questions about any of the data sets I just showed,", "tokens": [1507, 411, 341, 1687, 11, 1687, 2199, 13, 1171, 1651, 466, 604, 295, 264, 1412, 6352, 286, 445, 4712, 11], "temperature": 0.0, "avg_logprob": -0.10767096615909191, "compression_ratio": 1.5903083700440528, "no_speech_prob": 4.710814664576901e-06}, {"id": 28, "seek": 29888, "start": 298.88, "end": 306.96, "text": " have a look at the most recent courses. Because they're all described there. And yes, David,", "tokens": [362, 257, 574, 412, 264, 881, 5162, 7712, 13, 1436, 436, 434, 439, 7619, 456, 13, 400, 2086, 11, 4389, 11], "temperature": 0.0, "avg_logprob": -0.18395681523565036, "compression_ratio": 1.5485714285714285, "no_speech_prob": 4.539214933174662e-05}, {"id": 29, "seek": 29888, "start": 306.96, "end": 312.32, "text": " this new API does present accidental wrong ordering because there's no order to these", "tokens": [341, 777, 9362, 775, 1974, 38094, 2085, 21739, 570, 456, 311, 572, 1668, 281, 613], "temperature": 0.0, "avg_logprob": -0.18395681523565036, "compression_ratio": 1.5485714285714285, "no_speech_prob": 4.539214933174662e-05}, {"id": 30, "seek": 29888, "start": 312.32, "end": 322.36, "text": " things. They're just either subclasses. They're either subclasses or parameters. I think I'm", "tokens": [721, 13, 814, 434, 445, 2139, 1422, 11665, 279, 13, 814, 434, 2139, 1422, 11665, 279, 420, 9834, 13, 286, 519, 286, 478], "temperature": 0.0, "avg_logprob": -0.18395681523565036, "compression_ratio": 1.5485714285714285, "no_speech_prob": 4.539214933174662e-05}, {"id": 31, "seek": 32236, "start": 322.36, "end": 334.76, "text": " getting a cold. Excuse me. So yeah, that's one of the nice things here. OK. So that's", "tokens": [1242, 257, 3554, 13, 11359, 385, 13, 407, 1338, 11, 300, 311, 472, 295, 264, 1481, 721, 510, 13, 2264, 13, 407, 300, 311], "temperature": 0.0, "avg_logprob": -0.12506292978922526, "compression_ratio": 1.5317919075144508, "no_speech_prob": 2.355195101699792e-05}, {"id": 32, "seek": 32236, "start": 334.76, "end": 341.88, "text": " the kind of payoff of all this. It's just so easy to create these kinds of things. So", "tokens": [264, 733, 295, 46547, 295, 439, 341, 13, 467, 311, 445, 370, 1858, 281, 1884, 613, 3685, 295, 721, 13, 407], "temperature": 0.0, "avg_logprob": -0.12506292978922526, "compression_ratio": 1.5317919075144508, "no_speech_prob": 2.355195101699792e-05}, {"id": 33, "seek": 32236, "start": 341.88, "end": 350.5, "text": " yeah, let's start pretty close to the bottom of the layers now. And let's look at transforms.", "tokens": [1338, 11, 718, 311, 722, 1238, 1998, 281, 264, 2767, 295, 264, 7914, 586, 13, 400, 718, 311, 574, 412, 35592, 13], "temperature": 0.0, "avg_logprob": -0.12506292978922526, "compression_ratio": 1.5317919075144508, "no_speech_prob": 2.355195101699792e-05}, {"id": 34, "seek": 35050, "start": 350.5, "end": 355.72, "text": " So before we do, I will answer this question from Gocor, which is my thought process when", "tokens": [407, 949, 321, 360, 11, 286, 486, 1867, 341, 1168, 490, 460, 905, 284, 11, 597, 307, 452, 1194, 1399, 562], "temperature": 0.0, "avg_logprob": -0.11419814825057983, "compression_ratio": 1.5682819383259912, "no_speech_prob": 1.2218212759762537e-05}, {"id": 35, "seek": 35050, "start": 355.72, "end": 364.8, "text": " designing an API. I don't design really anything much at all. I just throw code out there.", "tokens": [14685, 364, 9362, 13, 286, 500, 380, 1715, 534, 1340, 709, 412, 439, 13, 286, 445, 3507, 3089, 484, 456, 13], "temperature": 0.0, "avg_logprob": -0.11419814825057983, "compression_ratio": 1.5682819383259912, "no_speech_prob": 1.2218212759762537e-05}, {"id": 36, "seek": 35050, "start": 364.8, "end": 369.64, "text": " And I then refactor it again and again and again. So I try to make sure I've got pretty", "tokens": [400, 286, 550, 1895, 15104, 309, 797, 293, 797, 293, 797, 13, 407, 286, 853, 281, 652, 988, 286, 600, 658, 1238], "temperature": 0.0, "avg_logprob": -0.11419814825057983, "compression_ratio": 1.5682819383259912, "no_speech_prob": 1.2218212759762537e-05}, {"id": 37, "seek": 35050, "start": 369.64, "end": 373.84, "text": " good tests. And I keep refactoring it until it gets to the point where I feel like it's", "tokens": [665, 6921, 13, 400, 286, 1066, 1895, 578, 3662, 309, 1826, 309, 2170, 281, 264, 935, 689, 286, 841, 411, 309, 311], "temperature": 0.0, "avg_logprob": -0.11419814825057983, "compression_ratio": 1.5682819383259912, "no_speech_prob": 1.2218212759762537e-05}, {"id": 38, "seek": 37384, "start": 373.84, "end": 380.64, "text": " so easy that even I will understand it in six months' time. With previous versions of", "tokens": [370, 1858, 300, 754, 286, 486, 1223, 309, 294, 2309, 2493, 6, 565, 13, 2022, 3894, 9606, 295], "temperature": 0.0, "avg_logprob": -0.17160161336263022, "compression_ratio": 1.463276836158192, "no_speech_prob": 7.76672732172301e-06}, {"id": 39, "seek": 37384, "start": 380.64, "end": 388.67999999999995, "text": " fast.ai, I haven't had the time to fully do that. But with this version, I do. So as you", "tokens": [2370, 13, 1301, 11, 286, 2378, 380, 632, 264, 565, 281, 4498, 360, 300, 13, 583, 365, 341, 3037, 11, 286, 360, 13, 407, 382, 291], "temperature": 0.0, "avg_logprob": -0.17160161336263022, "compression_ratio": 1.463276836158192, "no_speech_prob": 7.76672732172301e-06}, {"id": 40, "seek": 37384, "start": 388.67999999999995, "end": 398.12, "text": " can see, every function is super short and easy, which is really nice. So yeah, lots", "tokens": [393, 536, 11, 633, 2445, 307, 1687, 2099, 293, 1858, 11, 597, 307, 534, 1481, 13, 407, 1338, 11, 3195], "temperature": 0.0, "avg_logprob": -0.17160161336263022, "compression_ratio": 1.463276836158192, "no_speech_prob": 7.76672732172301e-06}, {"id": 41, "seek": 39812, "start": 398.12, "end": 413.2, "text": " and lots of refactoring. So transforms, the basic transform class is here. Again, less", "tokens": [293, 3195, 295, 1895, 578, 3662, 13, 407, 35592, 11, 264, 3875, 4088, 1508, 307, 510, 13, 3764, 11, 1570], "temperature": 0.0, "avg_logprob": -0.19963063796361288, "compression_ratio": 1.375, "no_speech_prob": 5.862586931471014e-06}, {"id": 42, "seek": 39812, "start": 413.2, "end": 422.2, "text": " than a line of code. Sorry, a screen of code. But the work's really happening in the meta", "tokens": [813, 257, 1622, 295, 3089, 13, 4919, 11, 257, 2568, 295, 3089, 13, 583, 264, 589, 311, 534, 2737, 294, 264, 19616], "temperature": 0.0, "avg_logprob": -0.19963063796361288, "compression_ratio": 1.375, "no_speech_prob": 5.862586931471014e-06}, {"id": 43, "seek": 42220, "start": 422.2, "end": 437.32, "text": " class. Because what happens is when we call dundercall or decode, it's going to call encodes", "tokens": [1508, 13, 1436, 437, 2314, 307, 562, 321, 818, 274, 6617, 45459, 420, 979, 1429, 11, 309, 311, 516, 281, 818, 2058, 4789], "temperature": 0.0, "avg_logprob": -0.20454772089568662, "compression_ratio": 1.5164835164835164, "no_speech_prob": 3.822774669970386e-05}, {"id": 44, "seek": 42220, "start": 437.32, "end": 446.24, "text": " and decodes by this little intermediate thing, underscore call. Which we haven't really looked", "tokens": [293, 979, 4789, 538, 341, 707, 19376, 551, 11, 37556, 818, 13, 3013, 321, 2378, 380, 534, 2956], "temperature": 0.0, "avg_logprob": -0.20454772089568662, "compression_ratio": 1.5164835164835164, "no_speech_prob": 3.822774669970386e-05}, {"id": 45, "seek": 42220, "start": 446.24, "end": 451.12, "text": " at filters much yet, but once we get to data source, you'll see this is how we do things", "tokens": [412, 15995, 709, 1939, 11, 457, 1564, 321, 483, 281, 1412, 4009, 11, 291, 603, 536, 341, 307, 577, 321, 360, 721], "temperature": 0.0, "avg_logprob": -0.20454772089568662, "compression_ratio": 1.5164835164835164, "no_speech_prob": 3.822774669970386e-05}, {"id": 46, "seek": 45112, "start": 451.12, "end": 457.32, "text": " on just the training set or just the validation set or both. That's what filters are. But", "tokens": [322, 445, 264, 3097, 992, 420, 445, 264, 24071, 992, 420, 1293, 13, 663, 311, 437, 15995, 366, 13, 583], "temperature": 0.0, "avg_logprob": -0.17669812611171176, "compression_ratio": 1.5963855421686748, "no_speech_prob": 4.356810222816421e-06}, {"id": 47, "seek": 45112, "start": 457.32, "end": 463.88, "text": " basically we check whether we're doing as item is true or false. If we're doing as item,", "tokens": [1936, 321, 1520, 1968, 321, 434, 884, 382, 3174, 307, 2074, 420, 7908, 13, 759, 321, 434, 884, 382, 3174, 11], "temperature": 0.0, "avg_logprob": -0.17669812611171176, "compression_ratio": 1.5963855421686748, "no_speech_prob": 4.356810222816421e-06}, {"id": 48, "seek": 45112, "start": 463.88, "end": 472.56, "text": " then we just call the function, decodes or encodes. If it's tuple behavior rather than", "tokens": [550, 321, 445, 818, 264, 2445, 11, 979, 4789, 420, 2058, 4789, 13, 759, 309, 311, 2604, 781, 5223, 2831, 813], "temperature": 0.0, "avg_logprob": -0.17669812611171176, "compression_ratio": 1.5963855421686748, "no_speech_prob": 4.356810222816421e-06}, {"id": 49, "seek": 47256, "start": 472.56, "end": 484.36, "text": " item behavior, then we call it for each element of the list and turn it into a tuple. So that's", "tokens": [3174, 5223, 11, 550, 321, 818, 309, 337, 1184, 4478, 295, 264, 1329, 293, 1261, 309, 666, 257, 2604, 781, 13, 407, 300, 311], "temperature": 0.0, "avg_logprob": -0.12771156311035156, "compression_ratio": 1.3863636363636365, "no_speech_prob": 9.132521654464654e-07}, {"id": 50, "seek": 47256, "start": 484.36, "end": 496.14, "text": " all pretty simple. But the trick is what are encodes and decodes, because we know these", "tokens": [439, 1238, 2199, 13, 583, 264, 4282, 307, 437, 366, 2058, 4789, 293, 979, 4789, 11, 570, 321, 458, 613], "temperature": 0.0, "avg_logprob": -0.12771156311035156, "compression_ratio": 1.3863636363636365, "no_speech_prob": 9.132521654464654e-07}, {"id": 51, "seek": 49614, "start": 496.14, "end": 505.47999999999996, "text": " are things which have a few cool things we can do. We can, let's see what we can do.", "tokens": [366, 721, 597, 362, 257, 1326, 1627, 721, 321, 393, 360, 13, 492, 393, 11, 718, 311, 536, 437, 321, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.17133193113365952, "compression_ratio": 1.4782608695652173, "no_speech_prob": 3.668835233838763e-06}, {"id": 52, "seek": 49614, "start": 505.47999999999996, "end": 518.8, "text": " We can pass methods in or we can subclass. And most interestingly, we can have a type", "tokens": [492, 393, 1320, 7150, 294, 420, 321, 393, 1422, 11665, 13, 400, 881, 25873, 11, 321, 393, 362, 257, 2010], "temperature": 0.0, "avg_logprob": -0.17133193113365952, "compression_ratio": 1.4782608695652173, "no_speech_prob": 3.668835233838763e-06}, {"id": 53, "seek": 51880, "start": 518.8, "end": 535.3199999999999, "text": " annotation and we can have multiple encodes slash decodes with each with different type", "tokens": [48654, 293, 321, 393, 362, 3866, 2058, 4789, 17330, 979, 4789, 365, 1184, 365, 819, 2010], "temperature": 0.0, "avg_logprob": -0.3042694091796875, "compression_ratio": 1.2083333333333333, "no_speech_prob": 1.0289382771588862e-05}, {"id": 54, "seek": 53532, "start": 535.32, "end": 551.6, "text": " annotation. So there's some other things we'll look at. Okay, so let's look at how we, okay,", "tokens": [48654, 13, 407, 456, 311, 512, 661, 721, 321, 603, 574, 412, 13, 1033, 11, 370, 718, 311, 574, 412, 577, 321, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.25026573854334216, "compression_ratio": 1.371212121212121, "no_speech_prob": 2.295905915161711e-06}, {"id": 55, "seek": 53532, "start": 551.6, "end": 562.32, "text": " so the first two are pretty straightforward. Our init, you can pass in an encoder and or", "tokens": [370, 264, 700, 732, 366, 1238, 15325, 13, 2621, 3157, 11, 291, 393, 1320, 294, 364, 2058, 19866, 293, 420], "temperature": 0.0, "avg_logprob": -0.25026573854334216, "compression_ratio": 1.371212121212121, "no_speech_prob": 2.295905915161711e-06}, {"id": 56, "seek": 56232, "start": 562.32, "end": 574.2800000000001, "text": " a decoder. And if you pass either of those in, then it will create the encoder and decoder,", "tokens": [257, 979, 19866, 13, 400, 498, 291, 1320, 2139, 295, 729, 294, 11, 550, 309, 486, 1884, 264, 2058, 19866, 293, 979, 19866, 11], "temperature": 0.0, "avg_logprob": -0.1412524532627415, "compression_ratio": 1.5491329479768785, "no_speech_prob": 2.5612700937927e-06}, {"id": 57, "seek": 56232, "start": 574.2800000000001, "end": 584.08, "text": " encodes and decodes based on what you pass in. But as you can see, they are not just", "tokens": [2058, 4789, 293, 979, 4789, 2361, 322, 437, 291, 1320, 294, 13, 583, 382, 291, 393, 536, 11, 436, 366, 406, 445], "temperature": 0.0, "avg_logprob": -0.1412524532627415, "compression_ratio": 1.5491329479768785, "no_speech_prob": 2.5612700937927e-06}, {"id": 58, "seek": 56232, "start": 584.08, "end": 589.96, "text": " methods. There's something called type dispatch. So that's what we're going to have to look", "tokens": [7150, 13, 821, 311, 746, 1219, 2010, 36729, 13, 407, 300, 311, 437, 321, 434, 516, 281, 362, 281, 574], "temperature": 0.0, "avg_logprob": -0.1412524532627415, "compression_ratio": 1.5491329479768785, "no_speech_prob": 2.5612700937927e-06}, {"id": 59, "seek": 58996, "start": 589.96, "end": 599.48, "text": " at. If you don't pass in an enc or dec, which will be, that means this will be false, then", "tokens": [412, 13, 759, 291, 500, 380, 1320, 294, 364, 2058, 420, 979, 11, 597, 486, 312, 11, 300, 1355, 341, 486, 312, 7908, 11, 550], "temperature": 0.0, "avg_logprob": -0.15915531001678884, "compression_ratio": 1.4640883977900552, "no_speech_prob": 9.223243068845477e-06}, {"id": 60, "seek": 58996, "start": 599.48, "end": 604.88, "text": " somehow encodes and decodes have already been created for us. So I have to figure out how", "tokens": [6063, 2058, 4789, 293, 979, 4789, 362, 1217, 668, 2942, 337, 505, 13, 407, 286, 362, 281, 2573, 484, 577], "temperature": 0.0, "avg_logprob": -0.15915531001678884, "compression_ratio": 1.4640883977900552, "no_speech_prob": 9.223243068845477e-06}, {"id": 61, "seek": 58996, "start": 604.88, "end": 616.36, "text": " that happens. Okay, so let's take a look. So answering questions, mixing tabular and", "tokens": [300, 2314, 13, 1033, 11, 370, 718, 311, 747, 257, 574, 13, 407, 13430, 1651, 11, 11983, 4421, 1040, 293], "temperature": 0.0, "avg_logprob": -0.15915531001678884, "compression_ratio": 1.4640883977900552, "no_speech_prob": 9.223243068845477e-06}, {"id": 62, "seek": 61636, "start": 616.36, "end": 625.0, "text": " text, for example, yes, we certainly want to do that, but we haven't started on it.", "tokens": [2487, 11, 337, 1365, 11, 2086, 11, 321, 3297, 528, 281, 360, 300, 11, 457, 321, 2378, 380, 1409, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.15879053419286554, "compression_ratio": 1.583710407239819, "no_speech_prob": 1.4063798516872339e-05}, {"id": 63, "seek": 61636, "start": 625.0, "end": 629.84, "text": " Not sure what you're asking exactly AJ about student projects at USF, but maybe ask on", "tokens": [1726, 988, 437, 291, 434, 3365, 2293, 32759, 466, 3107, 4455, 412, 2546, 37, 11, 457, 1310, 1029, 322], "temperature": 0.0, "avg_logprob": -0.15879053419286554, "compression_ratio": 1.583710407239819, "no_speech_prob": 1.4063798516872339e-05}, {"id": 64, "seek": 61636, "start": 629.84, "end": 636.52, "text": " the forums. Joseph to subclass something simply means to type class something and then put", "tokens": [264, 26998, 13, 11170, 281, 1422, 11665, 746, 2935, 1355, 281, 2010, 1508, 746, 293, 550, 829], "temperature": 0.0, "avg_logprob": -0.15879053419286554, "compression_ratio": 1.583710407239819, "no_speech_prob": 1.4063798516872339e-05}, {"id": 65, "seek": 61636, "start": 636.52, "end": 645.4, "text": " something in brackets. So for example, there is a subclass of transform. In other words,", "tokens": [746, 294, 26179, 13, 407, 337, 1365, 11, 456, 307, 257, 1422, 11665, 295, 4088, 13, 682, 661, 2283, 11], "temperature": 0.0, "avg_logprob": -0.15879053419286554, "compression_ratio": 1.583710407239819, "no_speech_prob": 1.4063798516872339e-05}, {"id": 66, "seek": 64540, "start": 645.4, "end": 657.64, "text": " I am subclassing transform. Okay, so if we look underneath here, we can see some of the", "tokens": [286, 669, 1422, 11665, 278, 4088, 13, 1033, 11, 370, 498, 321, 574, 7223, 510, 11, 321, 393, 536, 512, 295, 264], "temperature": 0.0, "avg_logprob": -0.11147723299391726, "compression_ratio": 1.376923076923077, "no_speech_prob": 3.024012221430894e-05}, {"id": 67, "seek": 64540, "start": 657.64, "end": 669.0799999999999, "text": " kind of behaviors being used. Oh, here's another interesting behavior, which is that we can", "tokens": [733, 295, 15501, 885, 1143, 13, 876, 11, 510, 311, 1071, 1880, 5223, 11, 597, 307, 300, 321, 393], "temperature": 0.0, "avg_logprob": -0.11147723299391726, "compression_ratio": 1.376923076923077, "no_speech_prob": 3.024012221430894e-05}, {"id": 68, "seek": 66908, "start": 669.08, "end": 679.2800000000001, "text": " we can use a class, a subclass of transform as a decorator to add a encodes or decodes", "tokens": [321, 393, 764, 257, 1508, 11, 257, 1422, 11665, 295, 4088, 382, 257, 7919, 1639, 281, 909, 257, 2058, 4789, 420, 979, 4789], "temperature": 0.0, "avg_logprob": -0.19979036079262788, "compression_ratio": 1.390625, "no_speech_prob": 1.733042836349341e-06}, {"id": 69, "seek": 66908, "start": 679.2800000000001, "end": 694.72, "text": " to an existing class. So let's add that decorator behavior. Okay, yeah, Max, we're going to", "tokens": [281, 364, 6741, 1508, 13, 407, 718, 311, 909, 300, 7919, 1639, 5223, 13, 1033, 11, 1338, 11, 7402, 11, 321, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.19979036079262788, "compression_ratio": 1.390625, "no_speech_prob": 1.733042836349341e-06}, {"id": 70, "seek": 69472, "start": 694.72, "end": 701.8000000000001, "text": " be talking about filters later when we look at data source. But basically just it's something", "tokens": [312, 1417, 466, 15995, 1780, 562, 321, 574, 412, 1412, 4009, 13, 583, 1936, 445, 309, 311, 746], "temperature": 0.0, "avg_logprob": -0.2373934283698957, "compression_ratio": 1.8416666666666666, "no_speech_prob": 7.646306585229468e-06}, {"id": 71, "seek": 69472, "start": 701.8000000000001, "end": 705.84, "text": " that we're going to have a zero generally as a training set filter zero is training", "tokens": [300, 321, 434, 516, 281, 362, 257, 4018, 5101, 382, 257, 3097, 992, 6608, 4018, 307, 3097], "temperature": 0.0, "avg_logprob": -0.2373934283698957, "compression_ratio": 1.8416666666666666, "no_speech_prob": 7.646306585229468e-06}, {"id": 72, "seek": 69472, "start": 705.84, "end": 709.76, "text": " set filter one is generally the validation set, you can have more than just those two", "tokens": [992, 6608, 472, 307, 5101, 264, 24071, 992, 11, 291, 393, 362, 544, 813, 445, 729, 732], "temperature": 0.0, "avg_logprob": -0.2373934283698957, "compression_ratio": 1.8416666666666666, "no_speech_prob": 7.646306585229468e-06}, {"id": 73, "seek": 69472, "start": 709.76, "end": 715.48, "text": " and transforms know basically which data set they're being applied to so they can have", "tokens": [293, 35592, 458, 1936, 597, 1412, 992, 436, 434, 885, 6456, 281, 370, 436, 393, 362], "temperature": 0.0, "avg_logprob": -0.2373934283698957, "compression_ratio": 1.8416666666666666, "no_speech_prob": 7.646306585229468e-06}, {"id": 74, "seek": 69472, "start": 715.48, "end": 722.48, "text": " different behavior for training versus validation optionally, but we'll look at that later.", "tokens": [819, 5223, 337, 3097, 5717, 24071, 3614, 379, 11, 457, 321, 603, 574, 412, 300, 1780, 13], "temperature": 0.0, "avg_logprob": -0.2373934283698957, "compression_ratio": 1.8416666666666666, "no_speech_prob": 7.646306585229468e-06}, {"id": 75, "seek": 72248, "start": 722.48, "end": 730.72, "text": " Okay, so here's an example of class transform a, which is getting an encodes, which is just", "tokens": [1033, 11, 370, 510, 311, 364, 1365, 295, 1508, 4088, 257, 11, 597, 307, 1242, 364, 2058, 4789, 11, 597, 307, 445], "temperature": 0.0, "avg_logprob": -0.13978938466494845, "compression_ratio": 1.7804878048780488, "no_speech_prob": 2.111211506417021e-05}, {"id": 76, "seek": 72248, "start": 730.72, "end": 737.6, "text": " x plus one. So we can check that that works, we should be able to subclass that transform", "tokens": [2031, 1804, 472, 13, 407, 321, 393, 1520, 300, 300, 1985, 11, 321, 820, 312, 1075, 281, 1422, 11665, 300, 4088], "temperature": 0.0, "avg_logprob": -0.13978938466494845, "compression_ratio": 1.7804878048780488, "no_speech_prob": 2.111211506417021e-05}, {"id": 77, "seek": 72248, "start": 737.6, "end": 744.4, "text": " so that checks that works. And here's an empty transform. So it should do nothing at all.", "tokens": [370, 300, 13834, 300, 1985, 13, 400, 510, 311, 364, 6707, 4088, 13, 407, 309, 820, 360, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.13978938466494845, "compression_ratio": 1.7804878048780488, "no_speech_prob": 2.111211506417021e-05}, {"id": 78, "seek": 72248, "start": 744.4, "end": 752.0600000000001, "text": " So that checks that that works. But then later on, we'll get to the tests where, for example,", "tokens": [407, 300, 13834, 300, 300, 1985, 13, 583, 550, 1780, 322, 11, 321, 603, 483, 281, 264, 6921, 689, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.13978938466494845, "compression_ratio": 1.7804878048780488, "no_speech_prob": 2.111211506417021e-05}, {"id": 79, "seek": 75206, "start": 752.06, "end": 760.28, "text": " we are making sure things only work on a particular subclass, in this case, tensor image. So here's", "tokens": [321, 366, 1455, 988, 721, 787, 589, 322, 257, 1729, 1422, 11665, 11, 294, 341, 1389, 11, 40863, 3256, 13, 407, 510, 311], "temperature": 0.0, "avg_logprob": -0.16153415720513525, "compression_ratio": 1.7222222222222223, "no_speech_prob": 1.3006922017666511e-05}, {"id": 80, "seek": 75206, "start": 760.28, "end": 769.3, "text": " the test, we're going to create one of these objects. And we will call it, we should end", "tokens": [264, 1500, 11, 321, 434, 516, 281, 1884, 472, 295, 613, 6565, 13, 400, 321, 486, 818, 309, 11, 321, 820, 917], "temperature": 0.0, "avg_logprob": -0.16153415720513525, "compression_ratio": 1.7222222222222223, "no_speech_prob": 1.3006922017666511e-05}, {"id": 81, "seek": 75206, "start": 769.3, "end": 775.5999999999999, "text": " up with a negative number, assuming that this was a something of type tensor image. Whereas", "tokens": [493, 365, 257, 3671, 1230, 11, 11926, 300, 341, 390, 257, 746, 295, 2010, 40863, 3256, 13, 13813], "temperature": 0.0, "avg_logprob": -0.16153415720513525, "compression_ratio": 1.7222222222222223, "no_speech_prob": 1.3006922017666511e-05}, {"id": 82, "seek": 75206, "start": 775.5999999999999, "end": 779.5999999999999, "text": " if we pass something which is not a type tensor image, in this case, an int, nothing should", "tokens": [498, 321, 1320, 746, 597, 307, 406, 257, 2010, 40863, 3256, 11, 294, 341, 1389, 11, 364, 560, 11, 1825, 820], "temperature": 0.0, "avg_logprob": -0.16153415720513525, "compression_ratio": 1.7222222222222223, "no_speech_prob": 1.3006922017666511e-05}, {"id": 83, "seek": 77960, "start": 779.6, "end": 789.6, "text": " happen at all. Okay. Also, when we do this, we should not be changing the type, so we", "tokens": [1051, 412, 439, 13, 1033, 13, 2743, 11, 562, 321, 360, 341, 11, 321, 820, 406, 312, 4473, 264, 2010, 11, 370, 321], "temperature": 0.0, "avg_logprob": -0.11597332201505962, "compression_ratio": 1.52, "no_speech_prob": 3.4465460885257926e-06}, {"id": 84, "seek": 77960, "start": 789.6, "end": 798.5600000000001, "text": " check that the type is still a tensor image. Okay, so let's see how some of that works.", "tokens": [1520, 300, 264, 2010, 307, 920, 257, 40863, 3256, 13, 1033, 11, 370, 718, 311, 536, 577, 512, 295, 300, 1985, 13], "temperature": 0.0, "avg_logprob": -0.11597332201505962, "compression_ratio": 1.52, "no_speech_prob": 3.4465460885257926e-06}, {"id": 85, "seek": 77960, "start": 798.5600000000001, "end": 807.24, "text": " So the trick is that all the stuff is happening in the meta class. What's a meta class? RedX", "tokens": [407, 264, 4282, 307, 300, 439, 264, 1507, 307, 2737, 294, 264, 19616, 1508, 13, 708, 311, 257, 19616, 1508, 30, 4477, 55], "temperature": 0.0, "avg_logprob": -0.11597332201505962, "compression_ratio": 1.52, "no_speech_prob": 3.4465460885257926e-06}, {"id": 86, "seek": 80724, "start": 807.24, "end": 811.92, "text": " given some good examples and code walkthroughs with some meta class stuff on the forums.", "tokens": [2212, 512, 665, 5110, 293, 3089, 1792, 11529, 82, 365, 512, 19616, 1508, 1507, 322, 264, 26998, 13], "temperature": 0.0, "avg_logprob": -0.21393618864171646, "compression_ratio": 1.5317919075144508, "no_speech_prob": 2.2959061425353866e-06}, {"id": 87, "seek": 80724, "start": 811.92, "end": 824.6800000000001, "text": " So check that out. But basically, when you go class something like that, that's creating", "tokens": [407, 1520, 300, 484, 13, 583, 1936, 11, 562, 291, 352, 1508, 746, 411, 300, 11, 300, 311, 4084], "temperature": 0.0, "avg_logprob": -0.21393618864171646, "compression_ratio": 1.5317919075144508, "no_speech_prob": 2.2959061425353866e-06}, {"id": 88, "seek": 80724, "start": 824.6800000000001, "end": 828.28, "text": " a new class. By the way, if you don't know, dot dot dot is basically the same as typing", "tokens": [257, 777, 1508, 13, 3146, 264, 636, 11, 498, 291, 500, 380, 458, 11, 5893, 5893, 5893, 307, 1936, 264, 912, 382, 18444], "temperature": 0.0, "avg_logprob": -0.21393618864171646, "compression_ratio": 1.5317919075144508, "no_speech_prob": 2.2959061425353866e-06}, {"id": 89, "seek": 82828, "start": 828.28, "end": 840.4399999999999, "text": " pass in Python. So that's created a new class, as you can see. And how does it do that? Well,", "tokens": [1320, 294, 15329, 13, 407, 300, 311, 2942, 257, 777, 1508, 11, 382, 291, 393, 536, 13, 400, 577, 775, 309, 360, 300, 30, 1042, 11], "temperature": 0.0, "avg_logprob": -0.11351375579833985, "compression_ratio": 1.318840579710145, "no_speech_prob": 5.093651452625636e-06}, {"id": 90, "seek": 82828, "start": 840.4399999999999, "end": 850.8399999999999, "text": " class foo, writing this, is basically syntax sugar for calling type and passing in these", "tokens": [1508, 726, 78, 11, 3579, 341, 11, 307, 1936, 28431, 5076, 337, 5141, 2010, 293, 8437, 294, 613], "temperature": 0.0, "avg_logprob": -0.11351375579833985, "compression_ratio": 1.318840579710145, "no_speech_prob": 5.093651452625636e-06}, {"id": 91, "seek": 85084, "start": 850.84, "end": 864.34, "text": " three things. A name, so foo, let's call this one foo2. Some bases, so the base class is", "tokens": [1045, 721, 13, 316, 1315, 11, 370, 726, 78, 11, 718, 311, 818, 341, 472, 726, 78, 17, 13, 2188, 17949, 11, 370, 264, 3096, 1508, 307], "temperature": 0.0, "avg_logprob": -0.12567957392278709, "compression_ratio": 1.3458646616541354, "no_speech_prob": 1.805819738365244e-05}, {"id": 92, "seek": 85084, "start": 864.34, "end": 873.48, "text": " always implicitly, unless you write otherwise, object. So it's object. And a dictionary of", "tokens": [1009, 26947, 356, 11, 5969, 291, 2464, 5911, 11, 2657, 13, 407, 309, 311, 2657, 13, 400, 257, 25890, 295], "temperature": 0.0, "avg_logprob": -0.12567957392278709, "compression_ratio": 1.3458646616541354, "no_speech_prob": 1.805819738365244e-05}, {"id": 93, "seek": 87348, "start": 873.48, "end": 881.16, "text": " stuff to put in the class, which in this case is empty. Oh, tap or not on this. That seems", "tokens": [1507, 281, 829, 294, 264, 1508, 11, 597, 294, 341, 1389, 307, 6707, 13, 876, 11, 5119, 420, 406, 322, 341, 13, 663, 2544], "temperature": 0.0, "avg_logprob": -0.23626603578266345, "compression_ratio": 1.318840579710145, "no_speech_prob": 1.4738785466761328e-05}, {"id": 94, "seek": 87348, "start": 881.16, "end": 899.28, "text": " a little fussy. And so let's call that foo2. Foo2. You can see they're very similar looking", "tokens": [257, 707, 283, 26394, 13, 400, 370, 718, 311, 818, 300, 726, 78, 17, 13, 8564, 78, 17, 13, 509, 393, 536, 436, 434, 588, 2531, 1237], "temperature": 0.0, "avg_logprob": -0.23626603578266345, "compression_ratio": 1.318840579710145, "no_speech_prob": 1.4738785466761328e-05}, {"id": 95, "seek": 89928, "start": 899.28, "end": 909.8399999999999, "text": " things. So in other words, this is just syntax sugar for calling this thing called type.", "tokens": [721, 13, 407, 294, 661, 2283, 11, 341, 307, 445, 28431, 5076, 337, 5141, 341, 551, 1219, 2010, 13], "temperature": 0.0, "avg_logprob": -0.09005049396963681, "compression_ratio": 1.6273291925465838, "no_speech_prob": 1.5689258361817338e-05}, {"id": 96, "seek": 89928, "start": 909.8399999999999, "end": 916.6, "text": " What is type? You can find out the type of something by using the single argument version", "tokens": [708, 307, 2010, 30, 509, 393, 915, 484, 264, 2010, 295, 746, 538, 1228, 264, 2167, 6770, 3037], "temperature": 0.0, "avg_logprob": -0.09005049396963681, "compression_ratio": 1.6273291925465838, "no_speech_prob": 1.5689258361817338e-05}, {"id": 97, "seek": 89928, "start": 916.6, "end": 926.28, "text": " of type. And the type of type is type. In other words, type is a class. And so this", "tokens": [295, 2010, 13, 400, 264, 2010, 295, 2010, 307, 2010, 13, 682, 661, 2283, 11, 2010, 307, 257, 1508, 13, 400, 370, 341], "temperature": 0.0, "avg_logprob": -0.09005049396963681, "compression_ratio": 1.6273291925465838, "no_speech_prob": 1.5689258361817338e-05}, {"id": 98, "seek": 92628, "start": 926.28, "end": 939.36, "text": " is a constructor. And it constructs something. So if I go type foo2, it constructs something", "tokens": [307, 257, 47479, 13, 400, 309, 7690, 82, 746, 13, 407, 498, 286, 352, 2010, 726, 78, 17, 11, 309, 7690, 82, 746], "temperature": 0.0, "avg_logprob": -0.08658124782420971, "compression_ratio": 1.3142857142857143, "no_speech_prob": 1.2218975825817324e-05}, {"id": 99, "seek": 93936, "start": 939.36, "end": 965.0, "text": " of type type. And so there are all kinds of attributes that a type has. So in particular,", "tokens": [295, 2010, 2010, 13, 400, 370, 456, 366, 439, 3685, 295, 17212, 300, 257, 2010, 575, 13, 407, 294, 1729, 11], "temperature": 0.0, "avg_logprob": -0.11296821594238281, "compression_ratio": 1.0987654320987654, "no_speech_prob": 8.139566489262506e-06}, {"id": 100, "seek": 96500, "start": 965.0, "end": 979.8, "text": " one of the important ones is I can put here a colon one. The most important is dunderdict.", "tokens": [472, 295, 264, 1021, 2306, 307, 286, 393, 829, 510, 257, 8255, 472, 13, 440, 881, 1021, 307, 274, 6617, 67, 985, 13], "temperature": 0.0, "avg_logprob": -0.1453376313050588, "compression_ratio": 1.4545454545454546, "no_speech_prob": 2.212502295151353e-05}, {"id": 101, "seek": 96500, "start": 979.8, "end": 985.32, "text": " And dunderdict is basically a dictionary. It's a slightly special kind of dictionary.", "tokens": [400, 274, 6617, 67, 985, 307, 1936, 257, 25890, 13, 467, 311, 257, 4748, 2121, 733, 295, 25890, 13], "temperature": 0.0, "avg_logprob": -0.1453376313050588, "compression_ratio": 1.4545454545454546, "no_speech_prob": 2.212502295151353e-05}, {"id": 102, "seek": 98532, "start": 985.32, "end": 1002.08, "text": " It's a dictionary which contains a mapping from names to values. And in particular, anything", "tokens": [467, 311, 257, 25890, 597, 8306, 257, 18350, 490, 5288, 281, 4190, 13, 400, 294, 1729, 11, 1340], "temperature": 0.0, "avg_logprob": -0.11518593456434167, "compression_ratio": 1.4444444444444444, "no_speech_prob": 4.3568270484684035e-06}, {"id": 103, "seek": 98532, "start": 1002.08, "end": 1008.12, "text": " that I passed in here ends up in that dictionary. There's another way to put things in the dictionary,", "tokens": [300, 286, 4678, 294, 510, 5314, 493, 294, 300, 25890, 13, 821, 311, 1071, 636, 281, 829, 721, 294, 264, 25890, 11], "temperature": 0.0, "avg_logprob": -0.11518593456434167, "compression_ratio": 1.4444444444444444, "no_speech_prob": 4.3568270484684035e-06}, {"id": 104, "seek": 100812, "start": 1008.12, "end": 1016.96, "text": " which is to use this special syntax sugar that we get in Python, which is like this.", "tokens": [597, 307, 281, 764, 341, 2121, 28431, 5076, 300, 321, 483, 294, 15329, 11, 597, 307, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.09159747453836295, "compression_ratio": 1.302325581395349, "no_speech_prob": 6.748011401214171e-06}, {"id": 105, "seek": 100812, "start": 1016.96, "end": 1031.24, "text": " And so now if I say foo.dict, you can see it's got the same thing, a equals one. So", "tokens": [400, 370, 586, 498, 286, 584, 726, 78, 13, 67, 985, 11, 291, 393, 536, 309, 311, 658, 264, 912, 551, 11, 257, 6915, 472, 13, 407], "temperature": 0.0, "avg_logprob": -0.09159747453836295, "compression_ratio": 1.302325581395349, "no_speech_prob": 6.748011401214171e-06}, {"id": 106, "seek": 103124, "start": 1031.24, "end": 1041.32, "text": " when you type that into a class, it's actually just a shortcut for creating an a attribute", "tokens": [562, 291, 2010, 300, 666, 257, 1508, 11, 309, 311, 767, 445, 257, 24822, 337, 4084, 364, 257, 19667], "temperature": 0.0, "avg_logprob": -0.16925439428775868, "compression_ratio": 1.371212121212121, "no_speech_prob": 1.8448059790898697e-06}, {"id": 107, "seek": 103124, "start": 1041.32, "end": 1056.52, "text": " in the dunderdict attribute of the class. OK, a bunch of questions. What's for recommended", "tokens": [294, 264, 274, 6617, 67, 985, 19667, 295, 264, 1508, 13, 2264, 11, 257, 3840, 295, 1651, 13, 708, 311, 337, 9628], "temperature": 0.0, "avg_logprob": -0.16925439428775868, "compression_ratio": 1.371212121212121, "no_speech_prob": 1.8448059790898697e-06}, {"id": 108, "seek": 105652, "start": 1056.52, "end": 1067.96, "text": " systems? No plans yet. Why are we using meta class? Basically, among the reasons I started", "tokens": [3652, 30, 883, 5482, 1939, 13, 1545, 366, 321, 1228, 19616, 1508, 30, 8537, 11, 3654, 264, 4112, 286, 1409], "temperature": 0.0, "avg_logprob": -0.1507684737443924, "compression_ratio": 1.5491329479768785, "no_speech_prob": 1.0129627298738342e-05}, {"id": 109, "seek": 105652, "start": 1067.96, "end": 1078.2, "text": " using meta classes in version two is because I wanted to change the things about how Python", "tokens": [1228, 19616, 5359, 294, 3037, 732, 307, 570, 286, 1415, 281, 1319, 264, 721, 466, 577, 15329], "temperature": 0.0, "avg_logprob": -0.1507684737443924, "compression_ratio": 1.5491329479768785, "no_speech_prob": 1.0129627298738342e-05}, {"id": 110, "seek": 105652, "start": 1078.2, "end": 1085.08, "text": " worked that I didn't really have the time to change version one. So things like this,", "tokens": [2732, 300, 286, 994, 380, 534, 362, 264, 565, 281, 1319, 3037, 472, 13, 407, 721, 411, 341, 11], "temperature": 0.0, "avg_logprob": -0.1507684737443924, "compression_ratio": 1.5491329479768785, "no_speech_prob": 1.0129627298738342e-05}, {"id": 111, "seek": 108508, "start": 1085.08, "end": 1088.72, "text": " all the stuff we're going to look at doing with transforms are impossible to do without", "tokens": [439, 264, 1507, 321, 434, 516, 281, 574, 412, 884, 365, 35592, 366, 6243, 281, 360, 1553], "temperature": 0.0, "avg_logprob": -0.1756222134544736, "compression_ratio": 1.5, "no_speech_prob": 2.3551991034764796e-05}, {"id": 112, "seek": 108508, "start": 1088.72, "end": 1096.6399999999999, "text": " meta classes. So yes, max type creates class objects and then class objects create instances,", "tokens": [19616, 5359, 13, 407, 2086, 11, 11469, 2010, 7829, 1508, 6565, 293, 550, 1508, 6565, 1884, 14519, 11], "temperature": 0.0, "avg_logprob": -0.1756222134544736, "compression_ratio": 1.5, "no_speech_prob": 2.3551991034764796e-05}, {"id": 113, "seek": 108508, "start": 1096.6399999999999, "end": 1107.6, "text": " exactly right. OK. So it also means in Python, it's worth knowing how these syntax sugar", "tokens": [2293, 558, 13, 2264, 13, 407, 309, 611, 1355, 294, 15329, 11, 309, 311, 3163, 5276, 577, 613, 28431, 5076], "temperature": 0.0, "avg_logprob": -0.1756222134544736, "compression_ratio": 1.5, "no_speech_prob": 2.3551991034764796e-05}, {"id": 114, "seek": 110760, "start": 1107.6, "end": 1118.28, "text": " things work. When you go like this, if you go like that, for example, then that's the", "tokens": [721, 589, 13, 1133, 291, 352, 411, 341, 11, 498, 291, 352, 411, 300, 11, 337, 1365, 11, 550, 300, 311, 264], "temperature": 0.0, "avg_logprob": -0.14023309824418048, "compression_ratio": 1.3968253968253967, "no_speech_prob": 3.0894696010363987e-06}, {"id": 115, "seek": 110760, "start": 1118.28, "end": 1126.8, "text": " same as saying f equals and then passing in some function. And so if you look at the dict,", "tokens": [912, 382, 1566, 283, 6915, 293, 550, 8437, 294, 512, 2445, 13, 400, 370, 498, 291, 574, 412, 264, 12569, 11], "temperature": 0.0, "avg_logprob": -0.14023309824418048, "compression_ratio": 1.3968253968253967, "no_speech_prob": 3.0894696010363987e-06}, {"id": 116, "seek": 112680, "start": 1126.8, "end": 1137.52, "text": " you'll see you end up with f and then some function. So really, you know, there's not", "tokens": [291, 603, 536, 291, 917, 493, 365, 283, 293, 550, 512, 2445, 13, 407, 534, 11, 291, 458, 11, 456, 311, 406], "temperature": 0.0, "avg_logprob": -0.14205516594043677, "compression_ratio": 1.5146198830409356, "no_speech_prob": 3.6119213291385677e-06}, {"id": 117, "seek": 112680, "start": 1137.52, "end": 1145.68, "text": " that much. There's a small, concise, elegant set of foundations in Python and the kind", "tokens": [300, 709, 13, 821, 311, 257, 1359, 11, 44882, 11, 21117, 992, 295, 22467, 294, 15329, 293, 264, 733], "temperature": 0.0, "avg_logprob": -0.14205516594043677, "compression_ratio": 1.5146198830409356, "no_speech_prob": 3.6119213291385677e-06}, {"id": 118, "seek": 112680, "start": 1145.68, "end": 1151.76, "text": " of stuff that we type day to day is a bunch of kind of little bits of syntax sugar for", "tokens": [295, 1507, 300, 321, 2010, 786, 281, 786, 307, 257, 3840, 295, 733, 295, 707, 9239, 295, 28431, 5076, 337], "temperature": 0.0, "avg_logprob": -0.14205516594043677, "compression_ratio": 1.5146198830409356, "no_speech_prob": 3.6119213291385677e-06}, {"id": 119, "seek": 115176, "start": 1151.76, "end": 1161.64, "text": " those foundations. So if I go to dot a, that is also syntax sugar. And specifically, it's", "tokens": [729, 22467, 13, 407, 498, 286, 352, 281, 5893, 257, 11, 300, 307, 611, 28431, 5076, 13, 400, 4682, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.27215698787144255, "compression_ratio": 1.3185185185185184, "no_speech_prob": 9.972785846912302e-06}, {"id": 120, "seek": 115176, "start": 1161.64, "end": 1177.16, "text": " syntax sugar for Dunder dict. A. OK, so this is all important to understand when we look", "tokens": [28431, 5076, 337, 413, 6617, 12569, 13, 316, 13, 2264, 11, 370, 341, 307, 439, 1021, 281, 1223, 562, 321, 574], "temperature": 0.0, "avg_logprob": -0.27215698787144255, "compression_ratio": 1.3185185185185184, "no_speech_prob": 9.972785846912302e-06}, {"id": 121, "seek": 117716, "start": 1177.16, "end": 1184.76, "text": " at meta classes. And the reason why is because a meta class is something where we're going", "tokens": [412, 19616, 5359, 13, 400, 264, 1778, 983, 307, 570, 257, 19616, 1508, 307, 746, 689, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.10339499067986148, "compression_ratio": 1.8704663212435233, "no_speech_prob": 5.014651378587587e-06}, {"id": 122, "seek": 117716, "start": 1184.76, "end": 1192.0, "text": " to replace type. We're going to say I want to create a class that does not use the type", "tokens": [281, 7406, 2010, 13, 492, 434, 516, 281, 584, 286, 528, 281, 1884, 257, 1508, 300, 775, 406, 764, 264, 2010], "temperature": 0.0, "avg_logprob": -0.10339499067986148, "compression_ratio": 1.8704663212435233, "no_speech_prob": 5.014651378587587e-06}, {"id": 123, "seek": 117716, "start": 1192.0, "end": 1199.0800000000002, "text": " constructor but uses some other constructor. And the way you do that in Python is you type", "tokens": [47479, 457, 4960, 512, 661, 47479, 13, 400, 264, 636, 291, 360, 300, 294, 15329, 307, 291, 2010], "temperature": 0.0, "avg_logprob": -0.10339499067986148, "compression_ratio": 1.8704663212435233, "no_speech_prob": 5.014651378587587e-06}, {"id": 124, "seek": 117716, "start": 1199.0800000000002, "end": 1205.76, "text": " meta class equals and then you type the name of the class you want to construct this class.", "tokens": [19616, 1508, 6915, 293, 550, 291, 2010, 264, 1315, 295, 264, 1508, 291, 528, 281, 7690, 341, 1508, 13], "temperature": 0.0, "avg_logprob": -0.10339499067986148, "compression_ratio": 1.8704663212435233, "no_speech_prob": 5.014651378587587e-06}, {"id": 125, "seek": 120576, "start": 1205.76, "end": 1213.24, "text": " You can create a class from scratch, but normally you wouldn't. It's easiest to subclass type.", "tokens": [509, 393, 1884, 257, 1508, 490, 8459, 11, 457, 5646, 291, 2759, 380, 13, 467, 311, 12889, 281, 1422, 11665, 2010, 13], "temperature": 0.0, "avg_logprob": -0.163450254712786, "compression_ratio": 1.453551912568306, "no_speech_prob": 6.540339200000744e-06}, {"id": 126, "seek": 120576, "start": 1213.24, "end": 1224.36, "text": " So here I'm going to inherit from type. And if you remember, type takes three things,", "tokens": [407, 510, 286, 478, 516, 281, 21389, 490, 2010, 13, 400, 498, 291, 1604, 11, 2010, 2516, 1045, 721, 11], "temperature": 0.0, "avg_logprob": -0.163450254712786, "compression_ratio": 1.453551912568306, "no_speech_prob": 6.540339200000744e-06}, {"id": 127, "seek": 120576, "start": 1224.36, "end": 1232.28, "text": " object or name, basis, dict. So Dunder new always requires class first. And then here", "tokens": [2657, 420, 1315, 11, 5143, 11, 12569, 13, 407, 413, 6617, 777, 1009, 7029, 1508, 700, 13, 400, 550, 510], "temperature": 0.0, "avg_logprob": -0.163450254712786, "compression_ratio": 1.453551912568306, "no_speech_prob": 6.540339200000744e-06}, {"id": 128, "seek": 123228, "start": 1232.28, "end": 1243.8, "text": " it is, name, basis, dict. So if I wanted to create a super simple meta class, then I could", "tokens": [309, 307, 11, 1315, 11, 5143, 11, 12569, 13, 407, 498, 286, 1415, 281, 1884, 257, 1687, 2199, 19616, 1508, 11, 550, 286, 727], "temperature": 0.0, "avg_logprob": -0.1378406894450285, "compression_ratio": 1.3984375, "no_speech_prob": 4.78504898637766e-06}, {"id": 129, "seek": 123228, "start": 1243.8, "end": 1260.8799999999999, "text": " just. So here's something which just returns super. So it's not going to change anything", "tokens": [445, 13, 407, 510, 311, 746, 597, 445, 11247, 1687, 13, 407, 309, 311, 406, 516, 281, 1319, 1340], "temperature": 0.0, "avg_logprob": -0.1378406894450285, "compression_ratio": 1.3984375, "no_speech_prob": 4.78504898637766e-06}, {"id": 130, "seek": 126088, "start": 1260.88, "end": 1275.24, "text": " at all, but it will work, right? Meta class equals m. There you go, I have a class. It", "tokens": [412, 439, 11, 457, 309, 486, 589, 11, 558, 30, 6377, 64, 1508, 6915, 275, 13, 821, 291, 352, 11, 286, 362, 257, 1508, 13, 467], "temperature": 0.0, "avg_logprob": -0.16357217011628328, "compression_ratio": 1.313868613138686, "no_speech_prob": 2.1907758309680503e-06}, {"id": 131, "seek": 126088, "start": 1275.24, "end": 1287.92, "text": " has a Dunder dict. So you can now start inserting things in here. And see how this printed as", "tokens": [575, 257, 413, 6617, 12569, 13, 407, 291, 393, 586, 722, 46567, 721, 294, 510, 13, 400, 536, 577, 341, 13567, 382], "temperature": 0.0, "avg_logprob": -0.16357217011628328, "compression_ratio": 1.313868613138686, "no_speech_prob": 2.1907758309680503e-06}, {"id": 132, "seek": 128792, "start": 1287.92, "end": 1294.52, "text": " soon as I typed class T pass, right? It didn't print after I created an object of type T.", "tokens": [2321, 382, 286, 33941, 1508, 314, 1320, 11, 558, 30, 467, 994, 380, 4482, 934, 286, 2942, 364, 2657, 295, 2010, 314, 13], "temperature": 0.0, "avg_logprob": -0.1599705154831345, "compression_ratio": 1.5170454545454546, "no_speech_prob": 1.3006995686737355e-05}, {"id": 133, "seek": 128792, "start": 1294.52, "end": 1301.6000000000001, "text": " It appeared as soon as I created the class. So Python is going to call this code any time", "tokens": [467, 8516, 382, 2321, 382, 286, 2942, 264, 1508, 13, 407, 15329, 307, 516, 281, 818, 341, 3089, 604, 565], "temperature": 0.0, "avg_logprob": -0.1599705154831345, "compression_ratio": 1.5170454545454546, "no_speech_prob": 1.3006995686737355e-05}, {"id": 134, "seek": 128792, "start": 1301.6000000000001, "end": 1311.3200000000002, "text": " I try to actually create a class, not when I try to instantiate it. Yep, res is result.", "tokens": [286, 853, 281, 767, 1884, 257, 1508, 11, 406, 562, 286, 853, 281, 9836, 13024, 309, 13, 7010, 11, 725, 307, 1874, 13], "temperature": 0.0, "avg_logprob": -0.1599705154831345, "compression_ratio": 1.5170454545454546, "no_speech_prob": 1.3006995686737355e-05}, {"id": 135, "seek": 131132, "start": 1311.32, "end": 1328.62, "text": " So in this case we are replacing three things, new, call, and prepare. So there is a really", "tokens": [407, 294, 341, 1389, 321, 366, 19139, 1045, 721, 11, 777, 11, 818, 11, 293, 5940, 13, 407, 456, 307, 257, 534], "temperature": 0.0, "avg_logprob": -0.10367810726165771, "compression_ratio": 1.4566929133858268, "no_speech_prob": 1.9333522232045652e-06}, {"id": 136, "seek": 131132, "start": 1328.62, "end": 1337.56, "text": " cool piece of documentation called the Python data model. And the Python data model describes", "tokens": [1627, 2522, 295, 14333, 1219, 264, 15329, 1412, 2316, 13, 400, 264, 15329, 1412, 2316, 15626], "temperature": 0.0, "avg_logprob": -0.10367810726165771, "compression_ratio": 1.4566929133858268, "no_speech_prob": 1.9333522232045652e-06}, {"id": 137, "seek": 133756, "start": 1337.56, "end": 1345.48, "text": " how all this works. Not just all this, but everything. It describes how Python is, how", "tokens": [577, 439, 341, 1985, 13, 1726, 445, 439, 341, 11, 457, 1203, 13, 467, 15626, 577, 15329, 307, 11, 577], "temperature": 0.0, "avg_logprob": -0.20542324913872612, "compression_ratio": 1.5814977973568283, "no_speech_prob": 1.983275251404848e-05}, {"id": 138, "seek": 133756, "start": 1345.48, "end": 1354.2, "text": " everything happens. So there's a section called customizing class creation where you can see", "tokens": [1203, 2314, 13, 407, 456, 311, 257, 3541, 1219, 2375, 3319, 1508, 8016, 689, 291, 393, 536], "temperature": 0.0, "avg_logprob": -0.20542324913872612, "compression_ratio": 1.5814977973568283, "no_speech_prob": 1.983275251404848e-05}, {"id": 139, "seek": 133756, "start": 1354.2, "end": 1359.9199999999998, "text": " all of the stuff that happens, including 3.3.3.1 meta classes. By default they are constructed", "tokens": [439, 295, 264, 1507, 300, 2314, 11, 3009, 805, 13, 18, 13, 18, 13, 16, 19616, 5359, 13, 3146, 7576, 436, 366, 17083], "temperature": 0.0, "avg_logprob": -0.20542324913872612, "compression_ratio": 1.5814977973568283, "no_speech_prob": 1.983275251404848e-05}, {"id": 140, "seek": 133756, "start": 1359.9199999999998, "end": 1366.8799999999999, "text": " using type. So I could click on type. And we can see in three arguments it returns a", "tokens": [1228, 2010, 13, 407, 286, 727, 2052, 322, 2010, 13, 400, 321, 393, 536, 294, 1045, 12869, 309, 11247, 257], "temperature": 0.0, "avg_logprob": -0.20542324913872612, "compression_ratio": 1.5814977973568283, "no_speech_prob": 1.983275251404848e-05}, {"id": 141, "seek": 136688, "start": 1366.88, "end": 1377.48, "text": " new type object. And then we can find out about type objects. And so forth. Okay. So", "tokens": [777, 2010, 2657, 13, 400, 550, 321, 393, 915, 484, 466, 2010, 6565, 13, 400, 370, 5220, 13, 1033, 13, 407], "temperature": 0.0, "avg_logprob": -0.16634535282216173, "compression_ratio": 1.4112903225806452, "no_speech_prob": 8.801021067483816e-06}, {"id": 142, "seek": 136688, "start": 1377.48, "end": 1391.1000000000001, "text": " meta classes, as it says, you say meta class equals blah. And the first thing that happens", "tokens": [19616, 5359, 11, 382, 309, 1619, 11, 291, 584, 19616, 1508, 6915, 12288, 13, 400, 264, 700, 551, 300, 2314], "temperature": 0.0, "avg_logprob": -0.16634535282216173, "compression_ratio": 1.4112903225806452, "no_speech_prob": 8.801021067483816e-06}, {"id": 143, "seek": 139110, "start": 1391.1, "end": 1401.1599999999999, "text": " is it has to prepare the class namespace. And the class namespace is the thunder dict", "tokens": [307, 309, 575, 281, 5940, 264, 1508, 5288, 17940, 13, 400, 264, 1508, 5288, 17940, 307, 264, 19898, 12569], "temperature": 0.0, "avg_logprob": -0.2204194690870202, "compression_ratio": 1.2686567164179106, "no_speech_prob": 1.5936118870740756e-05}, {"id": 144, "seek": 140116, "start": 1401.16, "end": 1421.88, "text": " object. So if we were to keep creating our underscore m, we could just return an empty", "tokens": [2657, 13, 407, 498, 321, 645, 281, 1066, 4084, 527, 37556, 275, 11, 321, 727, 445, 2736, 364, 6707], "temperature": 0.0, "avg_logprob": -0.17529978650681516, "compression_ratio": 1.335820895522388, "no_speech_prob": 9.516133104625624e-06}, {"id": 145, "seek": 140116, "start": 1421.88, "end": 1430.8000000000002, "text": " dictionary. And as you can see, it all works. And I guess we should be able to put something", "tokens": [25890, 13, 400, 382, 291, 393, 536, 11, 309, 439, 1985, 13, 400, 286, 2041, 321, 820, 312, 1075, 281, 829, 746], "temperature": 0.0, "avg_logprob": -0.17529978650681516, "compression_ratio": 1.335820895522388, "no_speech_prob": 9.516133104625624e-06}, {"id": 146, "seek": 143080, "start": 1430.8, "end": 1446.0, "text": " in it even. Okay, there it is. Right. So you can see thunder dict is created by calling", "tokens": [294, 309, 754, 13, 1033, 11, 456, 309, 307, 13, 1779, 13, 407, 291, 393, 536, 19898, 12569, 307, 2942, 538, 5141], "temperature": 0.0, "avg_logprob": -0.12100500410253351, "compression_ratio": 1.3650793650793651, "no_speech_prob": 1.3006754670641385e-05}, {"id": 147, "seek": 143080, "start": 1446.0, "end": 1450.68, "text": " your thunder prepare. And this is actually a way you can insert something into every", "tokens": [428, 19898, 5940, 13, 400, 341, 307, 767, 257, 636, 291, 393, 8969, 746, 666, 633], "temperature": 0.0, "avg_logprob": -0.12100500410253351, "compression_ratio": 1.3650793650793651, "no_speech_prob": 1.3006754670641385e-05}, {"id": 148, "seek": 145068, "start": 1450.68, "end": 1461.52, "text": " single class which has a meta class. So to understand the difference between the different", "tokens": [2167, 1508, 597, 575, 257, 19616, 1508, 13, 407, 281, 1223, 264, 2649, 1296, 264, 819], "temperature": 0.0, "avg_logprob": -0.11255278698233671, "compression_ratio": 1.435483870967742, "no_speech_prob": 4.092849849257618e-06}, {"id": 149, "seek": 145068, "start": 1461.52, "end": 1471.16, "text": " arguments to the meta class constructor, you would want to read 3.3.3 of the data model", "tokens": [12869, 281, 264, 19616, 1508, 47479, 11, 291, 576, 528, 281, 1401, 805, 13, 18, 13, 18, 295, 264, 1412, 2316], "temperature": 0.0, "avg_logprob": -0.11255278698233671, "compression_ratio": 1.435483870967742, "no_speech_prob": 4.092849849257618e-06}, {"id": 150, "seek": 147116, "start": 1471.16, "end": 1484.24, "text": " reference in the Python docs. Okay. So in our case, we've replaced prepare so it's", "tokens": [6408, 294, 264, 15329, 45623, 13, 1033, 13, 407, 294, 527, 1389, 11, 321, 600, 10772, 5940, 370, 309, 311], "temperature": 0.0, "avg_logprob": -0.1613913861716666, "compression_ratio": 1.3412698412698412, "no_speech_prob": 2.902296046158881e-06}, {"id": 151, "seek": 147116, "start": 1484.24, "end": 1489.3600000000001, "text": " not returning a dictionary. But instead it's returning some special kind of dictionary", "tokens": [406, 12678, 257, 25890, 13, 583, 2602, 309, 311, 12678, 512, 2121, 733, 295, 25890], "temperature": 0.0, "avg_logprob": -0.1613913861716666, "compression_ratio": 1.3412698412698412, "no_speech_prob": 2.902296046158881e-06}, {"id": 152, "seek": 148936, "start": 1489.36, "end": 1505.56, "text": " called a tfm dict. So a tfm dict is a dictionary that overrides under set item. Actually, I'm", "tokens": [1219, 257, 256, 69, 76, 12569, 13, 407, 257, 256, 69, 76, 12569, 307, 257, 25890, 300, 670, 81, 1875, 833, 992, 3174, 13, 5135, 11, 286, 478], "temperature": 0.0, "avg_logprob": -0.2019471750630961, "compression_ratio": 1.6198830409356726, "no_speech_prob": 8.013395927264355e-06}, {"id": 153, "seek": 148936, "start": 1505.56, "end": 1511.6799999999998, "text": " planning to change this. So I had things set up so you could use either underscore or encodes.", "tokens": [5038, 281, 1319, 341, 13, 407, 286, 632, 721, 992, 493, 370, 291, 727, 764, 2139, 37556, 420, 2058, 4789, 13], "temperature": 0.0, "avg_logprob": -0.2019471750630961, "compression_ratio": 1.6198830409356726, "no_speech_prob": 8.013395927264355e-06}, {"id": 154, "seek": 148936, "start": 1511.6799999999998, "end": 1516.4399999999998, "text": " I'm actually going to rip rid of the thing that lets you use underscore. So ignore that.", "tokens": [286, 478, 767, 516, 281, 12782, 3973, 295, 264, 551, 300, 6653, 291, 764, 37556, 13, 407, 11200, 300, 13], "temperature": 0.0, "avg_logprob": -0.2019471750630961, "compression_ratio": 1.6198830409356726, "no_speech_prob": 8.013395927264355e-06}, {"id": 155, "seek": 151644, "start": 1516.44, "end": 1523.3600000000001, "text": " So basically, if you're calling something that isn't encodes or decodes, then it's just", "tokens": [407, 1936, 11, 498, 291, 434, 5141, 746, 300, 1943, 380, 2058, 4789, 420, 979, 4789, 11, 550, 309, 311, 445], "temperature": 0.0, "avg_logprob": -0.13780268577680196, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.1125438504677732e-05}, {"id": 156, "seek": 151644, "start": 1523.3600000000001, "end": 1530.48, "text": " the normal dictionary. As you can see, this inherits from dict. But if it is encodes or", "tokens": [264, 2710, 25890, 13, 1018, 291, 393, 536, 11, 341, 9484, 1208, 490, 12569, 13, 583, 498, 309, 307, 2058, 4789, 420], "temperature": 0.0, "avg_logprob": -0.13780268577680196, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.1125438504677732e-05}, {"id": 157, "seek": 151644, "start": 1530.48, "end": 1538.68, "text": " decodes, then what I do is I check whether or not I already have an encodes or decodes", "tokens": [979, 4789, 11, 550, 437, 286, 360, 307, 286, 1520, 1968, 420, 406, 286, 1217, 362, 364, 2058, 4789, 420, 979, 4789], "temperature": 0.0, "avg_logprob": -0.13780268577680196, "compression_ratio": 1.6582278481012658, "no_speech_prob": 1.1125438504677732e-05}, {"id": 158, "seek": 153868, "start": 1538.68, "end": 1552.24, "text": " in my class. And if I don't, then I create one using dicts set item. And what I set it", "tokens": [294, 452, 1508, 13, 400, 498, 286, 500, 380, 11, 550, 286, 1884, 472, 1228, 12569, 82, 992, 3174, 13, 400, 437, 286, 992, 309], "temperature": 0.0, "avg_logprob": -0.10030988410667137, "compression_ratio": 1.392, "no_speech_prob": 6.048852810636163e-06}, {"id": 159, "seek": 153868, "start": 1552.24, "end": 1564.0, "text": " to is I set it to a type dispatch object. So in other words, this tfm dict is something", "tokens": [281, 307, 286, 992, 309, 281, 257, 2010, 36729, 2657, 13, 407, 294, 661, 2283, 11, 341, 256, 69, 76, 12569, 307, 746], "temperature": 0.0, "avg_logprob": -0.10030988410667137, "compression_ratio": 1.392, "no_speech_prob": 6.048852810636163e-06}, {"id": 160, "seek": 156400, "start": 1564.0, "end": 1569.32, "text": " which behaves exactly like a normal dictionary. And so it's going to be inside my dunder dict", "tokens": [597, 36896, 2293, 411, 257, 2710, 25890, 13, 400, 370, 309, 311, 516, 281, 312, 1854, 452, 274, 6617, 12569], "temperature": 0.0, "avg_logprob": -0.13483962728016413, "compression_ratio": 1.563953488372093, "no_speech_prob": 8.267736120615155e-06}, {"id": 161, "seek": 156400, "start": 1569.32, "end": 1573.68, "text": " for anything that uses this meta class. And it's not going to work differently at all,", "tokens": [337, 1340, 300, 4960, 341, 19616, 1508, 13, 400, 309, 311, 406, 516, 281, 589, 7614, 412, 439, 11], "temperature": 0.0, "avg_logprob": -0.13483962728016413, "compression_ratio": 1.563953488372093, "no_speech_prob": 8.267736120615155e-06}, {"id": 162, "seek": 156400, "start": 1573.68, "end": 1579.0, "text": " except for two special things called encodes and decodes. And in those cases, it's going", "tokens": [3993, 337, 732, 2121, 721, 1219, 2058, 4789, 293, 979, 4789, 13, 400, 294, 729, 3331, 11, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.13483962728016413, "compression_ratio": 1.563953488372093, "no_speech_prob": 8.267736120615155e-06}, {"id": 163, "seek": 157900, "start": 1579.0, "end": 1603.2, "text": " to use something called type dispatch. So let's try that. So if I go class a meta class", "tokens": [281, 764, 746, 1219, 2010, 36729, 13, 407, 718, 311, 853, 300, 13, 407, 498, 286, 352, 1508, 257, 19616, 1508], "temperature": 0.0, "avg_logprob": -0.20507434844970704, "compression_ratio": 1.0875, "no_speech_prob": 2.0261213649064302e-06}, {"id": 164, "seek": 160320, "start": 1603.2, "end": 1624.44, "text": " equals def meta. Well, let's and then let's say def encodes self turn x. So a dot encodes.", "tokens": [6915, 1060, 19616, 13, 1042, 11, 718, 311, 293, 550, 718, 311, 584, 1060, 2058, 4789, 2698, 1261, 2031, 13, 407, 257, 5893, 2058, 4789, 13], "temperature": 0.0, "avg_logprob": -0.2562395731608073, "compression_ratio": 1.3587786259541985, "no_speech_prob": 6.643363576586125e-06}, {"id": 165, "seek": 160320, "start": 1624.44, "end": 1632.3600000000001, "text": " Oh, that's not a normal function. What type is it? Oh, it's a type dispatch. And that's", "tokens": [876, 11, 300, 311, 406, 257, 2710, 2445, 13, 708, 2010, 307, 309, 30, 876, 11, 309, 311, 257, 2010, 36729, 13, 400, 300, 311], "temperature": 0.0, "avg_logprob": -0.2562395731608073, "compression_ratio": 1.3587786259541985, "no_speech_prob": 6.643363576586125e-06}, {"id": 166, "seek": 163236, "start": 1632.36, "end": 1638.8, "text": " because of this. So why create a meta class instead of inheriting from the class? They", "tokens": [570, 295, 341, 13, 407, 983, 1884, 257, 19616, 1508, 2602, 295, 9484, 1748, 490, 264, 1508, 30, 814], "temperature": 0.0, "avg_logprob": -0.14848968781620622, "compression_ratio": 1.7549019607843137, "no_speech_prob": 8.939551662479062e-06}, {"id": 167, "seek": 163236, "start": 1638.8, "end": 1644.6399999999999, "text": " do different things. By inheriting from a class, you can't change the behavior of type", "tokens": [360, 819, 721, 13, 3146, 9484, 1748, 490, 257, 1508, 11, 291, 393, 380, 1319, 264, 5223, 295, 2010], "temperature": 0.0, "avg_logprob": -0.14848968781620622, "compression_ratio": 1.7549019607843137, "no_speech_prob": 8.939551662479062e-06}, {"id": 168, "seek": 163236, "start": 1644.6399999999999, "end": 1655.3999999999999, "text": " creation. So we're trying to create something where anything that is inheriting from transform", "tokens": [8016, 13, 407, 321, 434, 1382, 281, 1884, 746, 689, 1340, 300, 307, 9484, 1748, 490, 4088], "temperature": 0.0, "avg_logprob": -0.14848968781620622, "compression_ratio": 1.7549019607843137, "no_speech_prob": 8.939551662479062e-06}, {"id": 169, "seek": 163236, "start": 1655.3999999999999, "end": 1660.9199999999998, "text": " gets a different class behavior. And so it's impossible to do the things we're describing", "tokens": [2170, 257, 819, 1508, 5223, 13, 400, 370, 309, 311, 6243, 281, 360, 264, 721, 321, 434, 16141], "temperature": 0.0, "avg_logprob": -0.14848968781620622, "compression_ratio": 1.7549019607843137, "no_speech_prob": 8.939551662479062e-06}, {"id": 170, "seek": 166092, "start": 1660.92, "end": 1670.28, "text": " by inheriting. There's no way, for example, normally to be able to say, I want to have", "tokens": [538, 9484, 1748, 13, 821, 311, 572, 636, 11, 337, 1365, 11, 5646, 281, 312, 1075, 281, 584, 11, 286, 528, 281, 362], "temperature": 0.0, "avg_logprob": -0.1338151475073586, "compression_ratio": 1.5222222222222221, "no_speech_prob": 6.048884642950725e-06}, {"id": 171, "seek": 166092, "start": 1670.28, "end": 1679.16, "text": " two different encodes for two different types, for instance, that would normally be impossible.", "tokens": [732, 819, 2058, 4789, 337, 732, 819, 3467, 11, 337, 5197, 11, 300, 576, 5646, 312, 6243, 13], "temperature": 0.0, "avg_logprob": -0.1338151475073586, "compression_ratio": 1.5222222222222221, "no_speech_prob": 6.048884642950725e-06}, {"id": 172, "seek": 166092, "start": 1679.16, "end": 1685.24, "text": " But thanks to meta classes and to dunder prepare, we know that each time it sees this, it's", "tokens": [583, 3231, 281, 19616, 5359, 293, 281, 274, 6617, 5940, 11, 321, 458, 300, 1184, 565, 309, 8194, 341, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.1338151475073586, "compression_ratio": 1.5222222222222221, "no_speech_prob": 6.048884642950725e-06}, {"id": 173, "seek": 168524, "start": 1685.24, "end": 1691.6, "text": " going to call our replacement dicts dunder set item with a key of encodes and the value", "tokens": [516, 281, 818, 527, 14419, 12569, 82, 274, 6617, 992, 3174, 365, 257, 2141, 295, 2058, 4789, 293, 264, 2158], "temperature": 0.0, "avg_logprob": -0.14143826564153036, "compression_ratio": 1.7783251231527093, "no_speech_prob": 1.0676993724700878e-06}, {"id": 174, "seek": 168524, "start": 1691.6, "end": 1698.0, "text": " of the function. And we can do whatever we like. And so what we're going to do is we're", "tokens": [295, 264, 2445, 13, 400, 321, 393, 360, 2035, 321, 411, 13, 400, 370, 437, 321, 434, 516, 281, 360, 307, 321, 434], "temperature": 0.0, "avg_logprob": -0.14143826564153036, "compression_ratio": 1.7783251231527093, "no_speech_prob": 1.0676993724700878e-06}, {"id": 175, "seek": 168524, "start": 1698.0, "end": 1703.72, "text": " going to create an encodes decodes type dispatch object if we don't already have one. And then", "tokens": [516, 281, 1884, 364, 2058, 4789, 979, 4789, 2010, 36729, 2657, 498, 321, 500, 380, 1217, 362, 472, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.14143826564153036, "compression_ratio": 1.7783251231527093, "no_speech_prob": 1.0676993724700878e-06}, {"id": 176, "seek": 168524, "start": 1703.72, "end": 1713.8, "text": " we're going to add this function to that type dispatch object. So let's try that. If I add", "tokens": [321, 434, 516, 281, 909, 341, 2445, 281, 300, 2010, 36729, 2657, 13, 407, 718, 311, 853, 300, 13, 759, 286, 909], "temperature": 0.0, "avg_logprob": -0.14143826564153036, "compression_ratio": 1.7783251231527093, "no_speech_prob": 1.0676993724700878e-06}, {"id": 177, "seek": 171380, "start": 1713.8, "end": 1721.36, "text": " this twice with two different things, you can see now float has one thing and int has", "tokens": [341, 6091, 365, 732, 819, 721, 11, 291, 393, 536, 586, 15706, 575, 472, 551, 293, 560, 575], "temperature": 0.0, "avg_logprob": -0.19292562148150275, "compression_ratio": 1.5146198830409356, "no_speech_prob": 4.356846147857141e-06}, {"id": 178, "seek": 171380, "start": 1721.36, "end": 1734.1599999999999, "text": " a different thing. So let's then have a look at type dispatch. So yeah, this is like a", "tokens": [257, 819, 551, 13, 407, 718, 311, 550, 362, 257, 574, 412, 2010, 36729, 13, 407, 1338, 11, 341, 307, 411, 257], "temperature": 0.0, "avg_logprob": -0.19292562148150275, "compression_ratio": 1.5146198830409356, "no_speech_prob": 4.356846147857141e-06}, {"id": 179, "seek": 171380, "start": 1734.1599999999999, "end": 1742.6, "text": " huge rabbit hole. It's basically how do you make Python do whatever you want it to do.", "tokens": [2603, 19509, 5458, 13, 467, 311, 1936, 577, 360, 291, 652, 15329, 360, 2035, 291, 528, 309, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.19292562148150275, "compression_ratio": 1.5146198830409356, "no_speech_prob": 4.356846147857141e-06}, {"id": 180, "seek": 174260, "start": 1742.6, "end": 1755.34, "text": " Python is a dynamic language. And so they created this amazing data model to allow us", "tokens": [15329, 307, 257, 8546, 2856, 13, 400, 370, 436, 2942, 341, 2243, 1412, 2316, 281, 2089, 505], "temperature": 0.0, "avg_logprob": -0.09915363788604736, "compression_ratio": 1.5344827586206897, "no_speech_prob": 8.664082997711375e-06}, {"id": 181, "seek": 174260, "start": 1755.34, "end": 1763.24, "text": " to customize anything we like in Python. But it takes some time to get used to. So it taught", "tokens": [281, 19734, 1340, 321, 411, 294, 15329, 13, 583, 309, 2516, 512, 565, 281, 483, 1143, 281, 13, 407, 309, 5928], "temperature": 0.0, "avg_logprob": -0.09915363788604736, "compression_ratio": 1.5344827586206897, "no_speech_prob": 8.664082997711375e-06}, {"id": 182, "seek": 174260, "start": 1763.24, "end": 1768.1999999999998, "text": " me a lot of reading and studying and looking at lots of different places to get the hang", "tokens": [385, 257, 688, 295, 3760, 293, 7601, 293, 1237, 412, 3195, 295, 819, 3190, 281, 483, 264, 3967], "temperature": 0.0, "avg_logprob": -0.09915363788604736, "compression_ratio": 1.5344827586206897, "no_speech_prob": 8.664082997711375e-06}, {"id": 183, "seek": 176820, "start": 1768.2, "end": 1774.32, "text": " of all this. And so I don't expect to understand it all the first time around. I'm not sure", "tokens": [295, 439, 341, 13, 400, 370, 286, 500, 380, 2066, 281, 1223, 309, 439, 264, 700, 565, 926, 13, 286, 478, 406, 988], "temperature": 0.0, "avg_logprob": -0.1351166704426641, "compression_ratio": 1.6061946902654867, "no_speech_prob": 9.818138096306939e-06}, {"id": 184, "seek": 176820, "start": 1774.32, "end": 1779.96, "text": " what built in functionality you're referring to, Max. I don't think Python has anything", "tokens": [437, 3094, 294, 14980, 291, 434, 13761, 281, 11, 7402, 13, 286, 500, 380, 519, 15329, 575, 1340], "temperature": 0.0, "avg_logprob": -0.1351166704426641, "compression_ratio": 1.6061946902654867, "no_speech_prob": 9.818138096306939e-06}, {"id": 185, "seek": 176820, "start": 1779.96, "end": 1786.68, "text": " which does what I just described, which is why I'm doing something I don't think it does", "tokens": [597, 775, 437, 286, 445, 7619, 11, 597, 307, 983, 286, 478, 884, 746, 286, 500, 380, 519, 309, 775], "temperature": 0.0, "avg_logprob": -0.1351166704426641, "compression_ratio": 1.6061946902654867, "no_speech_prob": 9.818138096306939e-06}, {"id": 186, "seek": 176820, "start": 1786.68, "end": 1797.68, "text": " before. OK. So here is the type dispatch class. And basically it's going to be something which", "tokens": [949, 13, 2264, 13, 407, 510, 307, 264, 2010, 36729, 1508, 13, 400, 1936, 309, 311, 516, 281, 312, 746, 597], "temperature": 0.0, "avg_logprob": -0.1351166704426641, "compression_ratio": 1.6061946902654867, "no_speech_prob": 9.818138096306939e-06}, {"id": 187, "seek": 179768, "start": 1797.68, "end": 1802.92, "text": " we know it's going to have to work a lot like a dictionary because we're going to be adding", "tokens": [321, 458, 309, 311, 516, 281, 362, 281, 589, 257, 688, 411, 257, 25890, 570, 321, 434, 516, 281, 312, 5127], "temperature": 0.0, "avg_logprob": -0.16392587971042943, "compression_ratio": 1.736842105263158, "no_speech_prob": 1.451020852982765e-05}, {"id": 188, "seek": 179768, "start": 1802.92, "end": 1810.5600000000002, "text": " things to it. And what's going to happen, actually, I haven't quite shown you all this", "tokens": [721, 281, 309, 13, 400, 437, 311, 516, 281, 1051, 11, 767, 11, 286, 2378, 380, 1596, 4898, 291, 439, 341], "temperature": 0.0, "avg_logprob": -0.16392587971042943, "compression_ratio": 1.736842105263158, "no_speech_prob": 1.451020852982765e-05}, {"id": 189, "seek": 179768, "start": 1810.5600000000002, "end": 1821.64, "text": " yet. What's going to happen is we're going to let's see, we're going to grab encodes.", "tokens": [1939, 13, 708, 311, 516, 281, 1051, 307, 321, 434, 516, 281, 718, 311, 536, 11, 321, 434, 516, 281, 4444, 2058, 4789, 13], "temperature": 0.0, "avg_logprob": -0.16392587971042943, "compression_ratio": 1.736842105263158, "no_speech_prob": 1.451020852982765e-05}, {"id": 190, "seek": 182164, "start": 1821.64, "end": 1828.16, "text": " We're going to call, yes, so we're going to call the function. And when we call the function,", "tokens": [492, 434, 516, 281, 818, 11, 2086, 11, 370, 321, 434, 516, 281, 818, 264, 2445, 13, 400, 562, 321, 818, 264, 2445, 11], "temperature": 0.0, "avg_logprob": -0.18341779206928455, "compression_ratio": 1.9067357512953367, "no_speech_prob": 3.966874828620348e-06}, {"id": 191, "seek": 182164, "start": 1828.16, "end": 1834.24, "text": " well, Max, we're not just checking types. We're dispatching on types. There's a big", "tokens": [731, 11, 7402, 11, 321, 434, 406, 445, 8568, 3467, 13, 492, 434, 4920, 29569, 322, 3467, 13, 821, 311, 257, 955], "temperature": 0.0, "avg_logprob": -0.18341779206928455, "compression_ratio": 1.9067357512953367, "no_speech_prob": 3.966874828620348e-06}, {"id": 192, "seek": 182164, "start": 1834.24, "end": 1838.48, "text": " difference between checking types and dispatching on types. So we're actually building something", "tokens": [2649, 1296, 8568, 3467, 293, 4920, 29569, 322, 3467, 13, 407, 321, 434, 767, 2390, 746], "temperature": 0.0, "avg_logprob": -0.18341779206928455, "compression_ratio": 1.9067357512953367, "no_speech_prob": 3.966874828620348e-06}, {"id": 193, "seek": 182164, "start": 1838.48, "end": 1846.64, "text": " where we're able to call different code depending on types. So, yeah, so there isn't a way to", "tokens": [689, 321, 434, 1075, 281, 818, 819, 3089, 5413, 322, 3467, 13, 407, 11, 1338, 11, 370, 456, 1943, 380, 257, 636, 281], "temperature": 0.0, "avg_logprob": -0.18341779206928455, "compression_ratio": 1.9067357512953367, "no_speech_prob": 3.966874828620348e-06}, {"id": 194, "seek": 184664, "start": 1846.64, "end": 1855.2, "text": " do that in Python. So as we've discussed in previous walkthroughs, when you look at, for", "tokens": [360, 300, 294, 15329, 13, 407, 382, 321, 600, 7152, 294, 3894, 1792, 11529, 82, 11, 562, 291, 574, 412, 11, 337], "temperature": 0.0, "avg_logprob": -0.13010730206126897, "compression_ratio": 1.434782608695652, "no_speech_prob": 2.9944135349069256e-06}, {"id": 195, "seek": 184664, "start": 1855.2, "end": 1861.16, "text": " example, data augmentation, we're going to have class rotate, which when we first define", "tokens": [1365, 11, 1412, 14501, 19631, 11, 321, 434, 516, 281, 362, 1508, 13121, 11, 597, 562, 321, 700, 6964], "temperature": 0.0, "avg_logprob": -0.13010730206126897, "compression_ratio": 1.434782608695652, "no_speech_prob": 2.9944135349069256e-06}, {"id": 196, "seek": 184664, "start": 1861.16, "end": 1865.64, "text": " it might be empty. And then later on when you say, oh, I've got something for a tensor", "tokens": [309, 1062, 312, 6707, 13, 400, 550, 1780, 322, 562, 291, 584, 11, 1954, 11, 286, 600, 658, 746, 337, 257, 40863], "temperature": 0.0, "avg_logprob": -0.13010730206126897, "compression_ratio": 1.434782608695652, "no_speech_prob": 2.9944135349069256e-06}, {"id": 197, "seek": 186564, "start": 1865.64, "end": 1879.0, "text": " image, then we'll say at rotate. And it'll say def encodes, X colon tensor image, and", "tokens": [3256, 11, 550, 321, 603, 584, 412, 13121, 13, 400, 309, 603, 584, 1060, 2058, 4789, 11, 1783, 8255, 40863, 3256, 11, 293], "temperature": 0.0, "avg_logprob": -0.18076539683986353, "compression_ratio": 1.6867469879518073, "no_speech_prob": 2.2959102352615446e-06}, {"id": 198, "seek": 186564, "start": 1879.0, "end": 1884.76, "text": " then degrees. And then there'll be some functionality for that. And then in some other place, there's", "tokens": [550, 5310, 13, 400, 550, 456, 603, 312, 512, 14980, 337, 300, 13, 400, 550, 294, 512, 661, 1081, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.18076539683986353, "compression_ratio": 1.6867469879518073, "no_speech_prob": 2.2959102352615446e-06}, {"id": 199, "seek": 186564, "start": 1884.76, "end": 1890.42, "text": " going to be X colon bounding box. And it's going to be different also whether we're encoding", "tokens": [516, 281, 312, 1783, 8255, 5472, 278, 2424, 13, 400, 309, 311, 516, 281, 312, 819, 611, 1968, 321, 434, 43430], "temperature": 0.0, "avg_logprob": -0.18076539683986353, "compression_ratio": 1.6867469879518073, "no_speech_prob": 2.2959102352615446e-06}, {"id": 200, "seek": 189042, "start": 1890.42, "end": 1903.6000000000001, "text": " or decoding. So it's quite different functionality. So, yeah, so type dispatch. Dispatch is referring", "tokens": [420, 979, 8616, 13, 407, 309, 311, 1596, 819, 14980, 13, 407, 11, 1338, 11, 370, 2010, 36729, 13, 4208, 79, 852, 307, 13761], "temperature": 0.0, "avg_logprob": -0.13168072700500488, "compression_ratio": 1.3472222222222223, "no_speech_prob": 3.288730567874154e-06}, {"id": 201, "seek": 189042, "start": 1903.6000000000001, "end": 1912.52, "text": " to how does a programming language decide what piece of code to run when you call something?", "tokens": [281, 577, 775, 257, 9410, 2856, 4536, 437, 2522, 295, 3089, 281, 1190, 562, 291, 818, 746, 30], "temperature": 0.0, "avg_logprob": -0.13168072700500488, "compression_ratio": 1.3472222222222223, "no_speech_prob": 3.288730567874154e-06}, {"id": 202, "seek": 191252, "start": 1912.52, "end": 1922.12, "text": " So for example, there's all kinds of different ways of doing dispatch in Python. The main", "tokens": [407, 337, 1365, 11, 456, 311, 439, 3685, 295, 819, 2098, 295, 884, 36729, 294, 15329, 13, 440, 2135], "temperature": 0.0, "avg_logprob": -0.13972275184862543, "compression_ratio": 1.4886363636363635, "no_speech_prob": 3.7852919376746286e-06}, {"id": 203, "seek": 191252, "start": 1922.12, "end": 1930.24, "text": " one that is used for methods, for example, is something called MRO, which is a method", "tokens": [472, 300, 307, 1143, 337, 7150, 11, 337, 1365, 11, 307, 746, 1219, 376, 7142, 11, 597, 307, 257, 3170], "temperature": 0.0, "avg_logprob": -0.13972275184862543, "compression_ratio": 1.4886363636363635, "no_speech_prob": 3.7852919376746286e-06}, {"id": 204, "seek": 191252, "start": 1930.24, "end": 1938.28, "text": " resolution order. Yeah, so it's basically all the rules in a language about how do you", "tokens": [8669, 1668, 13, 865, 11, 370, 309, 311, 1936, 439, 264, 4474, 294, 257, 2856, 466, 577, 360, 291], "temperature": 0.0, "avg_logprob": -0.13972275184862543, "compression_ratio": 1.4886363636363635, "no_speech_prob": 3.7852919376746286e-06}, {"id": 205, "seek": 193828, "start": 1938.28, "end": 1945.16, "text": " decide which piece of code to call when you call some function. And different languages", "tokens": [4536, 597, 2522, 295, 3089, 281, 818, 562, 291, 818, 512, 2445, 13, 400, 819, 8650], "temperature": 0.0, "avg_logprob": -0.13598501682281494, "compression_ratio": 1.4861878453038675, "no_speech_prob": 7.646284757356625e-06}, {"id": 206, "seek": 193828, "start": 1945.16, "end": 1950.56, "text": " do it all kinds of different ways. And yeah, check out some of the earlier walkthroughs", "tokens": [360, 309, 439, 3685, 295, 819, 2098, 13, 400, 1338, 11, 1520, 484, 512, 295, 264, 3071, 1792, 11529, 82], "temperature": 0.0, "avg_logprob": -0.13598501682281494, "compression_ratio": 1.4861878453038675, "no_speech_prob": 7.646284757356625e-06}, {"id": 207, "seek": 193828, "start": 1950.56, "end": 1960.92, "text": " if you want more information about why we're doing this dispatch. Yes, thank you. I mentioned", "tokens": [498, 291, 528, 544, 1589, 466, 983, 321, 434, 884, 341, 36729, 13, 1079, 11, 1309, 291, 13, 286, 2835], "temperature": 0.0, "avg_logprob": -0.13598501682281494, "compression_ratio": 1.4861878453038675, "no_speech_prob": 7.646284757356625e-06}, {"id": 208, "seek": 196092, "start": 1960.92, "end": 1976.8400000000001, "text": " that should have been transform if we want that to work. Okay. So what we want is we", "tokens": [300, 820, 362, 668, 4088, 498, 321, 528, 300, 281, 589, 13, 1033, 13, 407, 437, 321, 528, 307, 321], "temperature": 0.0, "avg_logprob": -0.24058702717656674, "compression_ratio": 1.376, "no_speech_prob": 6.854169441794511e-06}, {"id": 209, "seek": 196092, "start": 1976.8400000000001, "end": 1984.5600000000002, "text": " want something which looks like a function. So that means it has to have a Dunder call.", "tokens": [528, 746, 597, 1542, 411, 257, 2445, 13, 407, 300, 1355, 309, 575, 281, 362, 257, 413, 6617, 818, 13], "temperature": 0.0, "avg_logprob": -0.24058702717656674, "compression_ratio": 1.376, "no_speech_prob": 6.854169441794511e-06}, {"id": 210, "seek": 198456, "start": 1984.56, "end": 1991.9199999999998, "text": " But when you call it with some argument, we're not just going to call a function, but we're", "tokens": [583, 562, 291, 818, 309, 365, 512, 6770, 11, 321, 434, 406, 445, 516, 281, 818, 257, 2445, 11, 457, 321, 434], "temperature": 0.0, "avg_logprob": -0.12237837820342093, "compression_ratio": 1.8620689655172413, "no_speech_prob": 8.664469532959629e-06}, {"id": 211, "seek": 198456, "start": 1991.9199999999998, "end": 1998.08, "text": " going to look at the type of that argument and we're going to try to find the appropriate", "tokens": [516, 281, 574, 412, 264, 2010, 295, 300, 6770, 293, 321, 434, 516, 281, 853, 281, 915, 264, 6854], "temperature": 0.0, "avg_logprob": -0.12237837820342093, "compression_ratio": 1.8620689655172413, "no_speech_prob": 8.664469532959629e-06}, {"id": 212, "seek": 198456, "start": 1998.08, "end": 2009.04, "text": " function or method to call based on the type of that argument and based on which methods", "tokens": [2445, 420, 3170, 281, 818, 2361, 322, 264, 2010, 295, 300, 6770, 293, 2361, 322, 597, 7150], "temperature": 0.0, "avg_logprob": -0.12237837820342093, "compression_ratio": 1.8620689655172413, "no_speech_prob": 8.664469532959629e-06}, {"id": 213, "seek": 200904, "start": 2009.04, "end": 2018.32, "text": " have been created so far. And so what's going to happen is that inside our type dispatch", "tokens": [362, 668, 2942, 370, 1400, 13, 400, 370, 437, 311, 516, 281, 1051, 307, 300, 1854, 527, 2010, 36729], "temperature": 0.0, "avg_logprob": -0.12334144649220936, "compression_ratio": 1.5739644970414202, "no_speech_prob": 2.3320417312788777e-06}, {"id": 214, "seek": 200904, "start": 2018.32, "end": 2024.6, "text": " object, there will be a dictionary called funcs and that's going to contain a dictionary", "tokens": [2657, 11, 456, 486, 312, 257, 25890, 1219, 1019, 14368, 293, 300, 311, 516, 281, 5304, 257, 25890], "temperature": 0.0, "avg_logprob": -0.12334144649220936, "compression_ratio": 1.5739644970414202, "no_speech_prob": 2.3320417312788777e-06}, {"id": 215, "seek": 200904, "start": 2024.6, "end": 2031.1599999999999, "text": " where the key is the type. So for example, in this case, we're going to have keys tensor", "tokens": [689, 264, 2141, 307, 264, 2010, 13, 407, 337, 1365, 11, 294, 341, 1389, 11, 321, 434, 516, 281, 362, 9317, 40863], "temperature": 0.0, "avg_logprob": -0.12334144649220936, "compression_ratio": 1.5739644970414202, "no_speech_prob": 2.3320417312788777e-06}, {"id": 216, "seek": 203116, "start": 2031.16, "end": 2041.6000000000001, "text": " image and B box and the value is the actual function to call. So that's, that's the key", "tokens": [3256, 293, 363, 2424, 293, 264, 2158, 307, 264, 3539, 2445, 281, 818, 13, 407, 300, 311, 11, 300, 311, 264, 2141], "temperature": 0.0, "avg_logprob": -0.25915090560913084, "compression_ratio": 1.462809917355372, "no_speech_prob": 3.3930828067241237e-06}, {"id": 217, "seek": 203116, "start": 2041.6000000000001, "end": 2057.56, "text": " thing is the funcs. So then there was an add method and that is what the firm dict calls.", "tokens": [551, 307, 264, 1019, 14368, 13, 407, 550, 456, 390, 364, 909, 3170, 293, 300, 307, 437, 264, 6174, 12569, 5498, 13], "temperature": 0.0, "avg_logprob": -0.25915090560913084, "compression_ratio": 1.462809917355372, "no_speech_prob": 3.3930828067241237e-06}, {"id": 218, "seek": 205756, "start": 2057.56, "end": 2067.48, "text": " It adds this function and the add method is going to find out the type annotation for", "tokens": [467, 10860, 341, 2445, 293, 264, 909, 3170, 307, 516, 281, 915, 484, 264, 2010, 48654, 337], "temperature": 0.0, "avg_logprob": -0.12619453878963696, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.090450152536505e-06}, {"id": 219, "seek": 205756, "start": 2067.48, "end": 2074.4, "text": " the first parameter. P1 and O is parameter number one annotation. So it'll grab the type.", "tokens": [264, 700, 13075, 13, 430, 16, 293, 422, 307, 13075, 1230, 472, 48654, 13, 407, 309, 603, 4444, 264, 2010, 13], "temperature": 0.0, "avg_logprob": -0.12619453878963696, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.090450152536505e-06}, {"id": 220, "seek": 205756, "start": 2074.4, "end": 2077.7599999999998, "text": " If there is none, then it's assuming that it's object because that's the highest level", "tokens": [759, 456, 307, 6022, 11, 550, 309, 311, 11926, 300, 309, 311, 2657, 570, 300, 311, 264, 6343, 1496], "temperature": 0.0, "avg_logprob": -0.12619453878963696, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.090450152536505e-06}, {"id": 221, "seek": 205756, "start": 2077.7599999999998, "end": 2084.64, "text": " of the type hierarchy and it's going to pop that into our functions dictionary. So then", "tokens": [295, 264, 2010, 22333, 293, 309, 311, 516, 281, 1665, 300, 666, 527, 6828, 25890, 13, 407, 550], "temperature": 0.0, "avg_logprob": -0.12619453878963696, "compression_ratio": 1.7241379310344827, "no_speech_prob": 2.090450152536505e-06}, {"id": 222, "seek": 208464, "start": 2084.64, "end": 2093.56, "text": " later on, when you call done to call, it's going to look up the type of the parameter", "tokens": [1780, 322, 11, 562, 291, 818, 1096, 281, 818, 11, 309, 311, 516, 281, 574, 493, 264, 2010, 295, 264, 13075], "temperature": 0.0, "avg_logprob": -0.14344111909257604, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.733046133267635e-06}, {"id": 223, "seek": 208464, "start": 2093.56, "end": 2101.7599999999998, "text": " that you're calling this function on and it's going to look it up in this object. If it", "tokens": [300, 291, 434, 5141, 341, 2445, 322, 293, 309, 311, 516, 281, 574, 309, 493, 294, 341, 2657, 13, 759, 309], "temperature": 0.0, "avg_logprob": -0.14344111909257604, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.733046133267635e-06}, {"id": 224, "seek": 208464, "start": 2101.7599999999998, "end": 2107.72, "text": " doesn't find it, then it does nothing at all. So that's kind of the rule, right? If you", "tokens": [1177, 380, 915, 309, 11, 550, 309, 775, 1825, 412, 439, 13, 407, 300, 311, 733, 295, 264, 4978, 11, 558, 30, 759, 291], "temperature": 0.0, "avg_logprob": -0.14344111909257604, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.733046133267635e-06}, {"id": 225, "seek": 208464, "start": 2107.72, "end": 2112.7999999999997, "text": " only have like a rotate defined for tensor image and B box and then you call it with", "tokens": [787, 362, 411, 257, 13121, 7642, 337, 40863, 3256, 293, 363, 2424, 293, 550, 291, 818, 309, 365], "temperature": 0.0, "avg_logprob": -0.14344111909257604, "compression_ratio": 1.6476190476190475, "no_speech_prob": 1.733046133267635e-06}, {"id": 226, "seek": 211280, "start": 2112.8, "end": 2125.7200000000003, "text": " int, then nothing happens because that function isn't defined. If we did find it, then we", "tokens": [560, 11, 550, 1825, 2314, 570, 300, 2445, 1943, 380, 7642, 13, 759, 321, 630, 915, 309, 11, 550, 321], "temperature": 0.0, "avg_logprob": -0.11022584829757463, "compression_ratio": 1.5454545454545454, "no_speech_prob": 7.0718042479711585e-06}, {"id": 227, "seek": 211280, "start": 2125.7200000000003, "end": 2133.2000000000003, "text": " just call it with that argument and anything else that you passed along. And you can actually", "tokens": [445, 818, 309, 365, 300, 6770, 293, 1340, 1646, 300, 291, 4678, 2051, 13, 400, 291, 393, 767], "temperature": 0.0, "avg_logprob": -0.11022584829757463, "compression_ratio": 1.5454545454545454, "no_speech_prob": 7.0718042479711585e-06}, {"id": 228, "seek": 211280, "start": 2133.2000000000003, "end": 2138.6400000000003, "text": " tag things to say, I want you to turn it into a method, which is something we might talk", "tokens": [6162, 721, 281, 584, 11, 286, 528, 291, 281, 1261, 309, 666, 257, 3170, 11, 597, 307, 746, 321, 1062, 751], "temperature": 0.0, "avg_logprob": -0.11022584829757463, "compression_ratio": 1.5454545454545454, "no_speech_prob": 7.0718042479711585e-06}, {"id": 229, "seek": 213864, "start": 2138.64, "end": 2143.12, "text": " about later if people are interested. But basically it's just going to create a normal", "tokens": [466, 1780, 498, 561, 366, 3102, 13, 583, 1936, 309, 311, 445, 516, 281, 1884, 257, 2710], "temperature": 0.0, "avg_logprob": -0.11692112748340894, "compression_ratio": 1.599078341013825, "no_speech_prob": 6.048839168215636e-06}, {"id": 230, "seek": 213864, "start": 2143.12, "end": 2151.12, "text": " function unless you ask it to be a method. So the key thing then is how does this line", "tokens": [2445, 5969, 291, 1029, 309, 281, 312, 257, 3170, 13, 407, 264, 2141, 551, 550, 307, 577, 775, 341, 1622], "temperature": 0.0, "avg_logprob": -0.11692112748340894, "compression_ratio": 1.599078341013825, "no_speech_prob": 6.048839168215636e-06}, {"id": 231, "seek": 213864, "start": 2151.12, "end": 2156.4, "text": " of code work? How does it look up the type? So as you can see, it's calling done to get", "tokens": [295, 3089, 589, 30, 1012, 775, 309, 574, 493, 264, 2010, 30, 407, 382, 291, 393, 536, 11, 309, 311, 5141, 1096, 281, 483], "temperature": 0.0, "avg_logprob": -0.11692112748340894, "compression_ratio": 1.599078341013825, "no_speech_prob": 6.048839168215636e-06}, {"id": 232, "seek": 213864, "start": 2156.4, "end": 2163.48, "text": " item. And basically what we're going to do is we're going to keep a cache, which is a", "tokens": [3174, 13, 400, 1936, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 1066, 257, 19459, 11, 597, 307, 257], "temperature": 0.0, "avg_logprob": -0.11692112748340894, "compression_ratio": 1.599078341013825, "no_speech_prob": 6.048839168215636e-06}, {"id": 233, "seek": 216348, "start": 2163.48, "end": 2172.68, "text": " dictionary mapping from types to functions. And we need a special cache dictionary because", "tokens": [25890, 18350, 490, 3467, 281, 6828, 13, 400, 321, 643, 257, 2121, 19459, 25890, 570], "temperature": 0.0, "avg_logprob": -0.1621800661087036, "compression_ratio": 1.4802259887005649, "no_speech_prob": 2.123363174177939e-06}, {"id": 234, "seek": 216348, "start": 2172.68, "end": 2180.6, "text": " the way type dispatch works is it doesn't just look up say tensor image or B box, but", "tokens": [264, 636, 2010, 36729, 1985, 307, 309, 1177, 380, 445, 574, 493, 584, 40863, 3256, 420, 363, 2424, 11, 457], "temperature": 0.0, "avg_logprob": -0.1621800661087036, "compression_ratio": 1.4802259887005649, "no_speech_prob": 2.123363174177939e-06}, {"id": 235, "seek": 216348, "start": 2180.6, "end": 2186.64, "text": " it also looks for any subclasses of those things. So for example, we could have also,", "tokens": [309, 611, 1542, 337, 604, 1422, 11665, 279, 295, 729, 721, 13, 407, 337, 1365, 11, 321, 727, 362, 611, 11], "temperature": 0.0, "avg_logprob": -0.1621800661087036, "compression_ratio": 1.4802259887005649, "no_speech_prob": 2.123363174177939e-06}, {"id": 236, "seek": 218664, "start": 2186.64, "end": 2193.64, "text": " as we discussed in an earlier walkthrough, tensor. And in this case, then it's going", "tokens": [382, 321, 7152, 294, 364, 3071, 1792, 11529, 11, 40863, 13, 400, 294, 341, 1389, 11, 550, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.14504848642552154, "compression_ratio": 1.6842105263157894, "no_speech_prob": 8.8009610408335e-06}, {"id": 237, "seek": 218664, "start": 2193.64, "end": 2197.12, "text": " to, if you pass a tensor image, it'll grab the most specific version it can, which is", "tokens": [281, 11, 498, 291, 1320, 257, 40863, 3256, 11, 309, 603, 4444, 264, 881, 2685, 3037, 309, 393, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.14504848642552154, "compression_ratio": 1.6842105263157894, "no_speech_prob": 8.8009610408335e-06}, {"id": 238, "seek": 218664, "start": 2197.12, "end": 2209.4, "text": " a tensor image version. So, right, so I think I just answered your question, which is the", "tokens": [257, 40863, 3256, 3037, 13, 407, 11, 558, 11, 370, 286, 519, 286, 445, 10103, 428, 1168, 11, 597, 307, 264], "temperature": 0.0, "avg_logprob": -0.14504848642552154, "compression_ratio": 1.6842105263157894, "no_speech_prob": 8.8009610408335e-06}, {"id": 239, "seek": 218664, "start": 2209.4, "end": 2213.2799999999997, "text": " opposite of that. If you call it on something, which is a subclass of tensor image, it will", "tokens": [6182, 295, 300, 13, 759, 291, 818, 309, 322, 746, 11, 597, 307, 257, 1422, 11665, 295, 40863, 3256, 11, 309, 486], "temperature": 0.0, "avg_logprob": -0.14504848642552154, "compression_ratio": 1.6842105263157894, "no_speech_prob": 8.8009610408335e-06}, {"id": 240, "seek": 221328, "start": 2213.28, "end": 2223.92, "text": " be invoked. And the reason why is because of how we create this cache. And so if we", "tokens": [312, 1048, 9511, 13, 400, 264, 1778, 983, 307, 570, 295, 577, 321, 1884, 341, 19459, 13, 400, 370, 498, 321], "temperature": 0.0, "avg_logprob": -0.0941249283266739, "compression_ratio": 1.617283950617284, "no_speech_prob": 4.637834081222536e-06}, {"id": 241, "seek": 221328, "start": 2223.92, "end": 2230.0, "text": " don't find it in the cache, then we're going to add it to the cache. And what we do is", "tokens": [500, 380, 915, 309, 294, 264, 19459, 11, 550, 321, 434, 516, 281, 909, 309, 281, 264, 19459, 13, 400, 437, 321, 360, 307], "temperature": 0.0, "avg_logprob": -0.0941249283266739, "compression_ratio": 1.617283950617284, "no_speech_prob": 4.637834081222536e-06}, {"id": 242, "seek": 221328, "start": 2230.0, "end": 2239.52, "text": " we create a list of all of the types that are registered for which there is the appropriate", "tokens": [321, 1884, 257, 1329, 295, 439, 295, 264, 3467, 300, 366, 13968, 337, 597, 456, 307, 264, 6854], "temperature": 0.0, "avg_logprob": -0.0941249283266739, "compression_ratio": 1.617283950617284, "no_speech_prob": 4.637834081222536e-06}, {"id": 243, "seek": 223952, "start": 2239.52, "end": 2258.0, "text": " subclass relationship. And we, how do we do this? And notice that the functions have been", "tokens": [1422, 11665, 2480, 13, 400, 321, 11, 577, 360, 321, 360, 341, 30, 400, 3449, 300, 264, 6828, 362, 668], "temperature": 0.0, "avg_logprob": -0.15071621148482614, "compression_ratio": 1.4603174603174602, "no_speech_prob": 1.260680437553674e-05}, {"id": 244, "seek": 223952, "start": 2258.0, "end": 2268.52, "text": " ordered by a comparator which checks for subclass relationships. And so we grab the first one,", "tokens": [8866, 538, 257, 6311, 1639, 597, 13834, 337, 1422, 11665, 6159, 13, 400, 370, 321, 4444, 264, 700, 472, 11], "temperature": 0.0, "avg_logprob": -0.15071621148482614, "compression_ratio": 1.4603174603174602, "no_speech_prob": 1.260680437553674e-05}, {"id": 245, "seek": 226852, "start": 2268.52, "end": 2274.2, "text": " so the first one is the most specific type of the ones that are, that it's a subclass", "tokens": [370, 264, 700, 472, 307, 264, 881, 2685, 2010, 295, 264, 2306, 300, 366, 11, 300, 309, 311, 257, 1422, 11665], "temperature": 0.0, "avg_logprob": -0.11614579518636067, "compression_ratio": 1.5773809523809523, "no_speech_prob": 2.318675979040563e-05}, {"id": 246, "seek": 226852, "start": 2274.2, "end": 2279.6, "text": " of. This takes a little bit of time, we don't want to have to do this every time we call", "tokens": [295, 13, 639, 2516, 257, 707, 857, 295, 565, 11, 321, 500, 380, 528, 281, 362, 281, 360, 341, 633, 565, 321, 818], "temperature": 0.0, "avg_logprob": -0.11614579518636067, "compression_ratio": 1.5773809523809523, "no_speech_prob": 2.318675979040563e-05}, {"id": 247, "seek": 226852, "start": 2279.6, "end": 2285.6, "text": " this function. So once we find the right one, we pop it in the cache. So next time around,", "tokens": [341, 2445, 13, 407, 1564, 321, 915, 264, 558, 472, 11, 321, 1665, 309, 294, 264, 19459, 13, 407, 958, 565, 926, 11], "temperature": 0.0, "avg_logprob": -0.11614579518636067, "compression_ratio": 1.5773809523809523, "no_speech_prob": 2.318675979040563e-05}, {"id": 248, "seek": 228560, "start": 2285.6, "end": 2300.48, "text": " we can just grab it. Okay, so that is type dispatch. And so the key way to understand", "tokens": [321, 393, 445, 4444, 309, 13, 1033, 11, 370, 300, 307, 2010, 36729, 13, 400, 370, 264, 2141, 636, 281, 1223], "temperature": 0.0, "avg_logprob": -0.11021388979519114, "compression_ratio": 1.4357541899441342, "no_speech_prob": 2.4824589672789443e-06}, {"id": 249, "seek": 228560, "start": 2300.48, "end": 2304.92, "text": " it really is to look at the tests, right? So you can see here we've got things at lots", "tokens": [309, 534, 307, 281, 574, 412, 264, 6921, 11, 558, 30, 407, 291, 393, 536, 510, 321, 600, 658, 721, 412, 3195], "temperature": 0.0, "avg_logprob": -0.11021388979519114, "compression_ratio": 1.4357541899441342, "no_speech_prob": 2.4824589672789443e-06}, {"id": 250, "seek": 228560, "start": 2304.92, "end": 2312.36, "text": " of different levels of hierarchy. There's a parameter that's a collection, some kind", "tokens": [295, 819, 4358, 295, 22333, 13, 821, 311, 257, 13075, 300, 311, 257, 5765, 11, 512, 733], "temperature": 0.0, "avg_logprob": -0.11021388979519114, "compression_ratio": 1.4357541899441342, "no_speech_prob": 2.4824589672789443e-06}, {"id": 251, "seek": 231236, "start": 2312.36, "end": 2319.88, "text": " of integer, tensor, mask or image, a ball, some kind of number, right? So these are all", "tokens": [295, 24922, 11, 40863, 11, 6094, 420, 3256, 11, 257, 2594, 11, 512, 733, 295, 1230, 11, 558, 30, 407, 613, 366, 439], "temperature": 0.0, "avg_logprob": -0.19689087337917752, "compression_ratio": 1.3435114503816794, "no_speech_prob": 3.089479605478118e-06}, {"id": 252, "seek": 231236, "start": 2319.88, "end": 2331.2400000000002, "text": " functions. So we can create a type dispatch object with all of those different functions", "tokens": [6828, 13, 407, 321, 393, 1884, 257, 2010, 36729, 2657, 365, 439, 295, 729, 819, 6828], "temperature": 0.0, "avg_logprob": -0.19689087337917752, "compression_ratio": 1.3435114503816794, "no_speech_prob": 3.089479605478118e-06}, {"id": 253, "seek": 233124, "start": 2331.24, "end": 2342.72, "text": " in. And so we should try, if we look up int, for instance, then we should get back this", "tokens": [294, 13, 400, 370, 321, 820, 853, 11, 498, 321, 574, 493, 560, 11, 337, 5197, 11, 550, 321, 820, 483, 646, 341], "temperature": 0.0, "avg_logprob": -0.16309316018048456, "compression_ratio": 1.5290697674418605, "no_speech_prob": 2.0580459931807127e-06}, {"id": 254, "seek": 233124, "start": 2342.72, "end": 2348.2799999999997, "text": " one, because none of them were defined with int specifically, but it's going to match", "tokens": [472, 11, 570, 6022, 295, 552, 645, 7642, 365, 560, 4682, 11, 457, 309, 311, 516, 281, 2995], "temperature": 0.0, "avg_logprob": -0.16309316018048456, "compression_ratio": 1.5290697674418605, "no_speech_prob": 2.0580459931807127e-06}, {"id": 255, "seek": 233124, "start": 2348.2799999999997, "end": 2357.3599999999997, "text": " number and integral. Integral is more specific type than number, so that's why it matches", "tokens": [1230, 293, 11573, 13, 23894, 304, 307, 544, 2685, 2010, 813, 1230, 11, 370, 300, 311, 983, 309, 10676], "temperature": 0.0, "avg_logprob": -0.16309316018048456, "compression_ratio": 1.5290697674418605, "no_speech_prob": 2.0580459931807127e-06}, {"id": 256, "seek": 235736, "start": 2357.36, "end": 2372.08, "text": " bad. String doesn't match any of them, so it's a none. So here's the same kind of thing,", "tokens": [1578, 13, 745, 2937, 1177, 380, 2995, 604, 295, 552, 11, 370, 309, 311, 257, 6022, 13, 407, 510, 311, 264, 912, 733, 295, 551, 11], "temperature": 0.0, "avg_logprob": -0.10615936915079753, "compression_ratio": 1.3615384615384616, "no_speech_prob": 1.3631200999952853e-05}, {"id": 257, "seek": 235736, "start": 2372.08, "end": 2377.52, "text": " but this time after creating the object, we'll actually start calling some functions and", "tokens": [457, 341, 565, 934, 4084, 264, 2657, 11, 321, 603, 767, 722, 5141, 512, 6828, 293], "temperature": 0.0, "avg_logprob": -0.10615936915079753, "compression_ratio": 1.3615384615384616, "no_speech_prob": 1.3631200999952853e-05}, {"id": 258, "seek": 237752, "start": 2377.52, "end": 2394.4, "text": " make sure that they do the right thing. Okay, so that is type dispatch. So yeah, it's, to", "tokens": [652, 988, 300, 436, 360, 264, 558, 551, 13, 1033, 11, 370, 300, 307, 2010, 36729, 13, 407, 1338, 11, 309, 311, 11, 281], "temperature": 0.0, "avg_logprob": -0.1640261126236177, "compression_ratio": 1.5847953216374269, "no_speech_prob": 2.22527432924835e-06}, {"id": 259, "seek": 237752, "start": 2394.4, "end": 2398.44, "text": " get the Python data model in your head requires kind of putting all these things together,", "tokens": [483, 264, 15329, 1412, 2316, 294, 428, 1378, 7029, 733, 295, 3372, 439, 613, 721, 1214, 11], "temperature": 0.0, "avg_logprob": -0.1640261126236177, "compression_ratio": 1.5847953216374269, "no_speech_prob": 2.22527432924835e-06}, {"id": 260, "seek": 237752, "start": 2398.44, "end": 2403.56, "text": " but the nice thing is once it is all in your head, you can put it together the way we have", "tokens": [457, 264, 1481, 551, 307, 1564, 309, 307, 439, 294, 428, 1378, 11, 291, 393, 829, 309, 1214, 264, 636, 321, 362], "temperature": 0.0, "avg_logprob": -0.1640261126236177, "compression_ratio": 1.5847953216374269, "no_speech_prob": 2.22527432924835e-06}, {"id": 261, "seek": 240356, "start": 2403.56, "end": 2416.52, "text": " here. So we were able to replace the normal dictionary by replacing prepare with tiffmdict.", "tokens": [510, 13, 407, 321, 645, 1075, 281, 7406, 264, 2710, 25890, 538, 19139, 5940, 365, 256, 3661, 76, 67, 985, 13], "temperature": 0.0, "avg_logprob": -0.19845995221819196, "compression_ratio": 1.5375722543352601, "no_speech_prob": 2.6841826183954254e-06}, {"id": 262, "seek": 240356, "start": 2416.52, "end": 2423.12, "text": " Tiffmdict is something which, instead of a normal dictionary, when you set the item as", "tokens": [314, 3661, 76, 67, 985, 307, 746, 597, 11, 2602, 295, 257, 2710, 25890, 11, 562, 291, 992, 264, 3174, 382], "temperature": 0.0, "avg_logprob": -0.19845995221819196, "compression_ratio": 1.5375722543352601, "no_speech_prob": 2.6841826183954254e-06}, {"id": 263, "seek": 240356, "start": 2423.12, "end": 2433.36, "text": " encodes or decodes, it actually creates a type dispatch object and adds to it. And that", "tokens": [2058, 4789, 420, 979, 4789, 11, 309, 767, 7829, 257, 2010, 36729, 2657, 293, 10860, 281, 309, 13, 400, 300], "temperature": 0.0, "avg_logprob": -0.19845995221819196, "compression_ratio": 1.5375722543352601, "no_speech_prob": 2.6841826183954254e-06}, {"id": 264, "seek": 243336, "start": 2433.36, "end": 2444.6400000000003, "text": " means that now, when we inherit from transform and we create an encodes or decodes attribute,", "tokens": [1355, 300, 586, 11, 562, 321, 21389, 490, 4088, 293, 321, 1884, 364, 2058, 4789, 420, 979, 4789, 19667, 11], "temperature": 0.0, "avg_logprob": -0.1085659907414363, "compression_ratio": 1.872340425531915, "no_speech_prob": 5.955111191724427e-06}, {"id": 265, "seek": 243336, "start": 2444.6400000000003, "end": 2449.92, "text": " it will actually add it to the encodes or decodes type dispatch. And so when we call", "tokens": [309, 486, 767, 909, 309, 281, 264, 2058, 4789, 420, 979, 4789, 2010, 36729, 13, 400, 370, 562, 321, 818], "temperature": 0.0, "avg_logprob": -0.1085659907414363, "compression_ratio": 1.872340425531915, "no_speech_prob": 5.955111191724427e-06}, {"id": 266, "seek": 243336, "start": 2449.92, "end": 2458.6400000000003, "text": " encodes or decodes, we get this behavior, which is to get a negative version of this", "tokens": [2058, 4789, 420, 979, 4789, 11, 321, 483, 341, 5223, 11, 597, 307, 281, 483, 257, 3671, 3037, 295, 341], "temperature": 0.0, "avg_logprob": -0.1085659907414363, "compression_ratio": 1.872340425531915, "no_speech_prob": 5.955111191724427e-06}, {"id": 267, "seek": 243336, "start": 2458.6400000000003, "end": 2462.88, "text": " because it's a tensor image and a non-negative version of this because it's not a tensor", "tokens": [570, 309, 311, 257, 40863, 3256, 293, 257, 2107, 12, 28561, 1166, 3037, 295, 341, 570, 309, 311, 406, 257, 40863], "temperature": 0.0, "avg_logprob": -0.1085659907414363, "compression_ratio": 1.872340425531915, "no_speech_prob": 5.955111191724427e-06}, {"id": 268, "seek": 246288, "start": 2462.88, "end": 2478.8, "text": " image. So this specifically is single dispatch, not multiple dispatch. So it only looks up.", "tokens": [3256, 13, 407, 341, 4682, 307, 2167, 36729, 11, 406, 3866, 36729, 13, 407, 309, 787, 1542, 493, 13], "temperature": 0.0, "avg_logprob": -0.23670338649375766, "compression_ratio": 1.3863636363636365, "no_speech_prob": 1.5206172975013033e-05}, {"id": 269, "seek": 246288, "start": 2478.8, "end": 2491.7200000000003, "text": " Let's find it. When you add it, it only adds the, so p1ano is a function, teeny tiny little", "tokens": [961, 311, 915, 309, 13, 1133, 291, 909, 309, 11, 309, 787, 10860, 264, 11, 370, 280, 16, 3730, 307, 257, 2445, 11, 48232, 5870, 707], "temperature": 0.0, "avg_logprob": -0.23670338649375766, "compression_ratio": 1.3863636363636365, "no_speech_prob": 1.5206172975013033e-05}, {"id": 270, "seek": 249172, "start": 2491.72, "end": 2500.8399999999997, "text": " function here, which just grabs the first parameter annotation. So this will only do", "tokens": [2445, 510, 11, 597, 445, 30028, 264, 700, 13075, 48654, 13, 407, 341, 486, 787, 360], "temperature": 0.0, "avg_logprob": -0.15373467642163474, "compression_ratio": 1.4222222222222223, "no_speech_prob": 2.4439796106889844e-06}, {"id": 271, "seek": 249172, "start": 2500.8399999999997, "end": 2509.52, "text": " type dispatch based on the first non-self parameter. So, Hiromi, that's a very good", "tokens": [2010, 36729, 2361, 322, 264, 700, 2107, 12, 927, 13075, 13, 407, 11, 23192, 9220, 11, 300, 311, 257, 588, 665], "temperature": 0.0, "avg_logprob": -0.15373467642163474, "compression_ratio": 1.4222222222222223, "no_speech_prob": 2.4439796106889844e-06}, {"id": 272, "seek": 249172, "start": 2509.52, "end": 2516.2, "text": " question. Why not throw an error? Basically because of what I was describing before, if", "tokens": [1168, 13, 1545, 406, 3507, 364, 6713, 30, 8537, 570, 295, 437, 286, 390, 16141, 949, 11, 498], "temperature": 0.0, "avg_logprob": -0.15373467642163474, "compression_ratio": 1.4222222222222223, "no_speech_prob": 2.4439796106889844e-06}, {"id": 273, "seek": 251620, "start": 2516.2, "end": 2526.8999999999996, "text": " you are defining, say, rotate data augmentation for various types, then generally speaking,", "tokens": [291, 366, 17827, 11, 584, 11, 13121, 1412, 14501, 19631, 337, 3683, 3467, 11, 550, 5101, 4124, 11], "temperature": 0.0, "avg_logprob": -0.0740778229453347, "compression_ratio": 1.552325581395349, "no_speech_prob": 3.3404644455004018e-06}, {"id": 274, "seek": 251620, "start": 2526.8999999999996, "end": 2534.2, "text": " if you don't have it defined for your type, then probably what we want to do is nothing", "tokens": [498, 291, 500, 380, 362, 309, 7642, 337, 428, 2010, 11, 550, 1391, 437, 321, 528, 281, 360, 307, 1825], "temperature": 0.0, "avg_logprob": -0.0740778229453347, "compression_ratio": 1.552325581395349, "no_speech_prob": 3.3404644455004018e-06}, {"id": 275, "seek": 251620, "start": 2534.2, "end": 2542.6, "text": " at all. So the basic idea is that these kind of transforms are things you can opt into.", "tokens": [412, 439, 13, 407, 264, 3875, 1558, 307, 300, 613, 733, 295, 35592, 366, 721, 291, 393, 2427, 666, 13], "temperature": 0.0, "avg_logprob": -0.0740778229453347, "compression_ratio": 1.552325581395349, "no_speech_prob": 3.3404644455004018e-06}, {"id": 276, "seek": 254260, "start": 2542.6, "end": 2558.52, "text": " If you do want to create a transform, if you do want to create a transform which throws", "tokens": [759, 291, 360, 528, 281, 1884, 257, 4088, 11, 498, 291, 360, 528, 281, 1884, 257, 4088, 597, 19251], "temperature": 0.0, "avg_logprob": -0.1211618651514468, "compression_ratio": 1.5625, "no_speech_prob": 3.5008133636438288e-06}, {"id": 277, "seek": 254260, "start": 2558.52, "end": 2567.7999999999997, "text": " an error, if you call it with something that doesn't exist, you certainly can. Let's do", "tokens": [364, 6713, 11, 498, 291, 818, 309, 365, 746, 300, 1177, 380, 2514, 11, 291, 3297, 393, 13, 961, 311, 360], "temperature": 0.0, "avg_logprob": -0.1211618651514468, "compression_ratio": 1.5625, "no_speech_prob": 3.5008133636438288e-06}, {"id": 278, "seek": 256780, "start": 2567.8, "end": 2581.6000000000004, "text": " it. So here's a transform. And so if we say def encodes, and we'll say here raise, not", "tokens": [309, 13, 407, 510, 311, 257, 4088, 13, 400, 370, 498, 321, 584, 1060, 2058, 4789, 11, 293, 321, 603, 584, 510, 5300, 11, 406], "temperature": 0.0, "avg_logprob": -0.1952508467215079, "compression_ratio": 1.3790322580645162, "no_speech_prob": 3.500832917779917e-06}, {"id": 279, "seek": 256780, "start": 2581.6000000000004, "end": 2592.52, "text": " implemented, and then we'll go def encodes self, comma, x, colon, int, return x plus", "tokens": [12270, 11, 293, 550, 321, 603, 352, 1060, 2058, 4789, 2698, 11, 22117, 11, 2031, 11, 8255, 11, 560, 11, 2736, 2031, 1804], "temperature": 0.0, "avg_logprob": -0.1952508467215079, "compression_ratio": 1.3790322580645162, "no_speech_prob": 3.500832917779917e-06}, {"id": 280, "seek": 259252, "start": 2592.52, "end": 2607.48, "text": " one. So let's go a equals a, and then we can go a one, that returns two, a high, and that's", "tokens": [472, 13, 407, 718, 311, 352, 257, 6915, 257, 11, 293, 550, 321, 393, 352, 257, 472, 11, 300, 11247, 732, 11, 257, 1090, 11, 293, 300, 311], "temperature": 0.0, "avg_logprob": -0.23000177315303258, "compression_ratio": 1.4206349206349207, "no_speech_prob": 6.240895345399622e-06}, {"id": 281, "seek": 259252, "start": 2607.48, "end": 2617.32, "text": " going to return, oh, is that not the right one? Not implemented error. There we go, not", "tokens": [516, 281, 2736, 11, 1954, 11, 307, 300, 406, 264, 558, 472, 30, 1726, 12270, 6713, 13, 821, 321, 352, 11, 406], "temperature": 0.0, "avg_logprob": -0.23000177315303258, "compression_ratio": 1.4206349206349207, "no_speech_prob": 6.240895345399622e-06}, {"id": 282, "seek": 261732, "start": 2617.32, "end": 2624.1600000000003, "text": " implemented error. So you can certainly add that. And so the reason this works is because", "tokens": [12270, 6713, 13, 407, 291, 393, 3297, 909, 300, 13, 400, 370, 264, 1778, 341, 1985, 307, 570], "temperature": 0.0, "avg_logprob": -0.12469305617086003, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.6823473641998135e-06}, {"id": 283, "seek": 261732, "start": 2624.1600000000003, "end": 2628.6400000000003, "text": " remember that if you don't have an annotation, it's the same as saying object, that's kind", "tokens": [1604, 300, 498, 291, 500, 380, 362, 364, 48654, 11, 309, 311, 264, 912, 382, 1566, 2657, 11, 300, 311, 733], "temperature": 0.0, "avg_logprob": -0.12469305617086003, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.6823473641998135e-06}, {"id": 284, "seek": 261732, "start": 2628.6400000000003, "end": 2633.2400000000002, "text": " of the way Python normally does things, that's the way we do things too. And since that's", "tokens": [295, 264, 636, 15329, 5646, 775, 721, 11, 300, 311, 264, 636, 321, 360, 721, 886, 13, 400, 1670, 300, 311], "temperature": 0.0, "avg_logprob": -0.12469305617086003, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.6823473641998135e-06}, {"id": 285, "seek": 261732, "start": 2633.2400000000002, "end": 2638.6800000000003, "text": " the highest thing up in the inheritance hierarchy, that's the one that it would end up calling", "tokens": [264, 6343, 551, 493, 294, 264, 32122, 22333, 11, 300, 311, 264, 472, 300, 309, 576, 917, 493, 5141], "temperature": 0.0, "avg_logprob": -0.12469305617086003, "compression_ratio": 1.6743119266055047, "no_speech_prob": 5.6823473641998135e-06}, {"id": 286, "seek": 263868, "start": 2638.68, "end": 2651.56, "text": " if you don't provide some other behavior. So thank you for that excellent question.", "tokens": [498, 291, 500, 380, 2893, 512, 661, 5223, 13, 407, 1309, 291, 337, 300, 7103, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2528580256870815, "compression_ratio": 1.064102564102564, "no_speech_prob": 1.1478397937025875e-05}, {"id": 287, "seek": 265156, "start": 2651.56, "end": 2676.64, "text": " Okay, so that is the way that we handle dispatch. So the next thing is what about the way we", "tokens": [1033, 11, 370, 300, 307, 264, 636, 300, 321, 4813, 36729, 13, 407, 264, 958, 551, 307, 437, 466, 264, 636, 321], "temperature": 0.0, "avg_logprob": -0.16568143551166242, "compression_ratio": 1.1645569620253164, "no_speech_prob": 1.6536823750357144e-06}, {"id": 288, "seek": 267664, "start": 2676.64, "end": 2690.12, "text": " can treat a transform subclass as a decorator? So if you remember, a decorator, when you", "tokens": [393, 2387, 257, 4088, 1422, 11665, 382, 257, 7919, 1639, 30, 407, 498, 291, 1604, 11, 257, 7919, 1639, 11, 562, 291], "temperature": 0.0, "avg_logprob": -0.10439302656385634, "compression_ratio": 1.403225806451613, "no_speech_prob": 4.710882421932183e-06}, {"id": 289, "seek": 267664, "start": 2690.12, "end": 2697.24, "text": " see something like this, will actually call this as a callable and pass this function", "tokens": [536, 746, 411, 341, 11, 486, 767, 818, 341, 382, 257, 818, 712, 293, 1320, 341, 2445], "temperature": 0.0, "avg_logprob": -0.10439302656385634, "compression_ratio": 1.403225806451613, "no_speech_prob": 4.710882421932183e-06}, {"id": 290, "seek": 269724, "start": 2697.24, "end": 2707.3599999999997, "text": " to it. So that is basically identical to saying something like def underscore encodes equals", "tokens": [281, 309, 13, 407, 300, 307, 1936, 14800, 281, 1566, 746, 411, 1060, 37556, 2058, 4789, 6915], "temperature": 0.0, "avg_logprob": -0.19807693232660709, "compression_ratio": 1.4409448818897639, "no_speech_prob": 2.5215647383447504e-06}, {"id": 291, "seek": 269724, "start": 2707.3599999999997, "end": 2720.04, "text": " that, and then encodes equals a parenthesis, and actually what I should say is, no, I just", "tokens": [300, 11, 293, 550, 2058, 4789, 6915, 257, 23350, 9374, 11, 293, 767, 437, 286, 820, 584, 307, 11, 572, 11, 286, 445], "temperature": 0.0, "avg_logprob": -0.19807693232660709, "compression_ratio": 1.4409448818897639, "no_speech_prob": 2.5215647383447504e-06}, {"id": 292, "seek": 272004, "start": 2720.04, "end": 2732.52, "text": " say, yeah, a underscore encodes. It's basically the same as doing that. And we should find", "tokens": [584, 11, 1338, 11, 257, 37556, 2058, 4789, 13, 467, 311, 1936, 264, 912, 382, 884, 300, 13, 400, 321, 820, 915], "temperature": 0.0, "avg_logprob": -0.18497969554020807, "compression_ratio": 1.0714285714285714, "no_speech_prob": 9.080255949811544e-06}, {"id": 293, "seek": 273252, "start": 2732.52, "end": 2751.56, "text": " that the same test then passes. We have to say a equals that. Let's see. Ah, yes, it's", "tokens": [300, 264, 912, 1500, 550, 11335, 13, 492, 362, 281, 584, 257, 6915, 300, 13, 961, 311, 536, 13, 2438, 11, 2086, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.20551359887216605, "compression_ratio": 1.3565891472868217, "no_speech_prob": 7.646377525816206e-06}, {"id": 294, "seek": 273252, "start": 2751.56, "end": 2760.36, "text": " slightly different because it thinks of it as not as a method. Okay, so it's not exactly", "tokens": [4748, 819, 570, 309, 7309, 295, 309, 382, 406, 382, 257, 3170, 13, 1033, 11, 370, 309, 311, 406, 2293], "temperature": 0.0, "avg_logprob": -0.20551359887216605, "compression_ratio": 1.3565891472868217, "no_speech_prob": 7.646377525816206e-06}, {"id": 295, "seek": 276036, "start": 2760.36, "end": 2764.44, "text": " the same. It's nearly the same, not because of Python, because of stuff we do. So we'll", "tokens": [264, 912, 13, 467, 311, 6217, 264, 912, 11, 406, 570, 295, 15329, 11, 570, 295, 1507, 321, 360, 13, 407, 321, 603], "temperature": 0.0, "avg_logprob": -0.13787776894039577, "compression_ratio": 1.5375722543352601, "no_speech_prob": 9.516144928056747e-06}, {"id": 296, "seek": 276036, "start": 2764.44, "end": 2775.1600000000003, "text": " come back to that later. Okay, so the reason we can use this as a decorator is because", "tokens": [808, 646, 281, 300, 1780, 13, 1033, 11, 370, 264, 1778, 321, 393, 764, 341, 382, 257, 7919, 1639, 307, 570], "temperature": 0.0, "avg_logprob": -0.13787776894039577, "compression_ratio": 1.5375722543352601, "no_speech_prob": 9.516144928056747e-06}, {"id": 297, "seek": 276036, "start": 2775.1600000000003, "end": 2787.96, "text": " that means that our class is going to have to support, be a callable basically. Now classes", "tokens": [300, 1355, 300, 527, 1508, 307, 516, 281, 362, 281, 1406, 11, 312, 257, 818, 712, 1936, 13, 823, 5359], "temperature": 0.0, "avg_logprob": -0.13787776894039577, "compression_ratio": 1.5375722543352601, "no_speech_prob": 9.516144928056747e-06}, {"id": 298, "seek": 278796, "start": 2787.96, "end": 2797.28, "text": " are normally callables because you can instantiate a class, obviously. So if you go class B like", "tokens": [366, 5646, 818, 2965, 570, 291, 393, 9836, 13024, 257, 1508, 11, 2745, 13, 407, 498, 291, 352, 1508, 363, 411], "temperature": 0.0, "avg_logprob": -0.16722518969804812, "compression_ratio": 1.6144578313253013, "no_speech_prob": 2.813010041791131e-06}, {"id": 299, "seek": 278796, "start": 2797.28, "end": 2805.56, "text": " this, then you go B equals B, then you're calling B as a callable, or B's type, B's", "tokens": [341, 11, 550, 291, 352, 363, 6915, 363, 11, 550, 291, 434, 5141, 363, 382, 257, 818, 712, 11, 420, 363, 311, 2010, 11, 363, 311], "temperature": 0.0, "avg_logprob": -0.16722518969804812, "compression_ratio": 1.6144578313253013, "no_speech_prob": 2.813010041791131e-06}, {"id": 300, "seek": 278796, "start": 2805.56, "end": 2813.2, "text": " meta type as a callable. So that means if we go to our meta class, we can redefine done", "tokens": [19616, 2010, 382, 257, 818, 712, 13, 407, 300, 1355, 498, 321, 352, 281, 527, 19616, 1508, 11, 321, 393, 38818, 533, 1096], "temperature": 0.0, "avg_logprob": -0.16722518969804812, "compression_ratio": 1.6144578313253013, "no_speech_prob": 2.813010041791131e-06}, {"id": 301, "seek": 281320, "start": 2813.2, "end": 2823.12, "text": " to call. And that means we can redefine what happens when we instantiate this class. So", "tokens": [281, 818, 13, 400, 300, 1355, 321, 393, 38818, 533, 437, 2314, 562, 321, 9836, 13024, 341, 1508, 13, 407], "temperature": 0.0, "avg_logprob": -0.09892795523818658, "compression_ratio": 1.5603448275862069, "no_speech_prob": 6.240867151063867e-06}, {"id": 302, "seek": 281320, "start": 2823.12, "end": 2838.8799999999997, "text": " if we instantiate this class, or if we done to call this class, and we pass in some argument,", "tokens": [498, 321, 9836, 13024, 341, 1508, 11, 420, 498, 321, 1096, 281, 818, 341, 1508, 11, 293, 321, 1320, 294, 512, 6770, 11], "temperature": 0.0, "avg_logprob": -0.09892795523818658, "compression_ratio": 1.5603448275862069, "no_speech_prob": 6.240867151063867e-06}, {"id": 303, "seek": 283888, "start": 2838.88, "end": 2849.32, "text": " and if that argument is callable, and it's not decodes or encodes, then we are going", "tokens": [293, 498, 300, 6770, 307, 818, 712, 11, 293, 309, 311, 406, 979, 4789, 420, 2058, 4789, 11, 550, 321, 366, 516], "temperature": 0.0, "avg_logprob": -0.11542089089103368, "compression_ratio": 1.3709677419354838, "no_speech_prob": 7.224430191854481e-07}, {"id": 304, "seek": 283888, "start": 2849.32, "end": 2860.04, "text": " to add that function to our type dispatch. And so that's exactly what happens when we", "tokens": [281, 909, 300, 2445, 281, 527, 2010, 36729, 13, 400, 370, 300, 311, 2293, 437, 2314, 562, 321], "temperature": 0.0, "avg_logprob": -0.11542089089103368, "compression_ratio": 1.3709677419354838, "no_speech_prob": 7.224430191854481e-07}, {"id": 305, "seek": 286004, "start": 2860.04, "end": 2869.48, "text": " say at A def encodes blah blah blah. It's just going to add that function to this class's", "tokens": [584, 412, 316, 1060, 2058, 4789, 12288, 12288, 12288, 13, 467, 311, 445, 516, 281, 909, 300, 2445, 281, 341, 1508, 311], "temperature": 0.0, "avg_logprob": -0.15943069084017886, "compression_ratio": 1.3671875, "no_speech_prob": 1.0030126986748655e-06}, {"id": 306, "seek": 286004, "start": 2869.48, "end": 2882.6, "text": " type dispatch. So you can see here it calls.add, which is the.add that we had here in", "tokens": [2010, 36729, 13, 407, 291, 393, 536, 510, 309, 5498, 2411, 25224, 11, 597, 307, 264, 2411, 25224, 300, 321, 632, 510, 294], "temperature": 0.0, "avg_logprob": -0.15943069084017886, "compression_ratio": 1.3671875, "no_speech_prob": 1.0030126986748655e-06}, {"id": 307, "seek": 288260, "start": 2882.6, "end": 2901.16, "text": " type dispatch. So this is the thing that basically registers another type. Okay, so that's that.", "tokens": [2010, 36729, 13, 407, 341, 307, 264, 551, 300, 1936, 38351, 1071, 2010, 13, 1033, 11, 370, 300, 311, 300, 13], "temperature": 0.0, "avg_logprob": -0.16053719216204704, "compression_ratio": 1.48, "no_speech_prob": 1.2411310308380052e-05}, {"id": 308, "seek": 288260, "start": 2901.16, "end": 2906.48, "text": " There's one last piece which is done to new. So this is the thing that first gets called", "tokens": [821, 311, 472, 1036, 2522, 597, 307, 1096, 281, 777, 13, 407, 341, 307, 264, 551, 300, 700, 2170, 1219], "temperature": 0.0, "avg_logprob": -0.16053719216204704, "compression_ratio": 1.48, "no_speech_prob": 1.2411310308380052e-05}, {"id": 309, "seek": 290648, "start": 2906.48, "end": 2916.2400000000002, "text": " when you're creating a new type. And one of the things I discovered which is super annoying", "tokens": [562, 291, 434, 4084, 257, 777, 2010, 13, 400, 472, 295, 264, 721, 286, 6941, 597, 307, 1687, 11304], "temperature": 0.0, "avg_logprob": -0.13214965661366782, "compression_ratio": 1.3923076923076922, "no_speech_prob": 1.5446034012711607e-05}, {"id": 310, "seek": 290648, "start": 2916.2400000000002, "end": 2923.2400000000002, "text": " is that if I create a new type, like so, any type of type even without being a meta type,", "tokens": [307, 300, 498, 286, 1884, 257, 777, 2010, 11, 411, 370, 11, 604, 2010, 295, 2010, 754, 1553, 885, 257, 19616, 2010, 11], "temperature": 0.0, "avg_logprob": -0.13214965661366782, "compression_ratio": 1.3923076923076922, "no_speech_prob": 1.5446034012711607e-05}, {"id": 311, "seek": 292324, "start": 2923.24, "end": 2947.04, "text": " and I define a done to new, like so. So here's some class, and then I define some subclass,", "tokens": [293, 286, 6964, 257, 1096, 281, 777, 11, 411, 370, 13, 407, 510, 311, 512, 1508, 11, 293, 550, 286, 6964, 512, 1422, 11665, 11], "temperature": 0.0, "avg_logprob": -0.19494507230561356, "compression_ratio": 1.1375, "no_speech_prob": 1.568909465277102e-05}, {"id": 312, "seek": 294704, "start": 2947.04, "end": 2959.92, "text": " and I say init, like so. And then so I want to instantiate that, and then I shift tab,", "tokens": [293, 286, 584, 3157, 11, 411, 370, 13, 400, 550, 370, 286, 528, 281, 9836, 13024, 300, 11, 293, 550, 286, 5513, 4421, 11], "temperature": 0.0, "avg_logprob": -0.2795818035419171, "compression_ratio": 1.3983739837398375, "no_speech_prob": 1.034851152326155e-06}, {"id": 313, "seek": 294704, "start": 2959.92, "end": 2972.64, "text": " oh that was not what I expected to happen, oh sorry, and class B inherits from A, and", "tokens": [1954, 300, 390, 406, 437, 286, 5176, 281, 1051, 11, 1954, 2597, 11, 293, 1508, 363, 9484, 1208, 490, 316, 11, 293], "temperature": 0.0, "avg_logprob": -0.2795818035419171, "compression_ratio": 1.3983739837398375, "no_speech_prob": 1.034851152326155e-06}, {"id": 314, "seek": 297264, "start": 2972.64, "end": 2978.2, "text": " I shift tab. You can see the signature is star arg star star quarks, or else I would", "tokens": [286, 5513, 4421, 13, 509, 393, 536, 264, 13397, 307, 3543, 3882, 3543, 3543, 421, 20851, 11, 420, 1646, 286, 576], "temperature": 0.0, "avg_logprob": -0.17158829082142224, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.13959923107177e-06}, {"id": 315, "seek": 297264, "start": 2978.2, "end": 2987.48, "text": " have expected the signature to be A, as it would be if I removed my base class. So I", "tokens": [362, 5176, 264, 13397, 281, 312, 316, 11, 382, 309, 576, 312, 498, 286, 7261, 452, 3096, 1508, 13, 407, 286], "temperature": 0.0, "avg_logprob": -0.17158829082142224, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.13959923107177e-06}, {"id": 316, "seek": 297264, "start": 2987.48, "end": 2992.08, "text": " found that super annoying because like you want to customize new all the time, not all", "tokens": [1352, 300, 1687, 11304, 570, 411, 291, 528, 281, 19734, 777, 439, 264, 565, 11, 406, 439], "temperature": 0.0, "avg_logprob": -0.17158829082142224, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.13959923107177e-06}, {"id": 317, "seek": 297264, "start": 2992.08, "end": 2997.2, "text": " the time, but very frequently, and pretty much most of the time when you customize it,", "tokens": [264, 565, 11, 457, 588, 10374, 11, 293, 1238, 709, 881, 295, 264, 565, 562, 291, 19734, 309, 11], "temperature": 0.0, "avg_logprob": -0.17158829082142224, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.13959923107177e-06}, {"id": 318, "seek": 297264, "start": 2997.2, "end": 3001.6, "text": " you're going to use star arg star star quarks because you don't want to define what base", "tokens": [291, 434, 516, 281, 764, 3543, 3882, 3543, 3543, 421, 20851, 570, 291, 500, 380, 528, 281, 6964, 437, 3096], "temperature": 0.0, "avg_logprob": -0.17158829082142224, "compression_ratio": 1.7489878542510122, "no_speech_prob": 8.13959923107177e-06}, {"id": 319, "seek": 300160, "start": 3001.6, "end": 3019.68, "text": " classes can do. But as soon as you do that, you kill the signature, like so. So I don't", "tokens": [5359, 393, 360, 13, 583, 382, 2321, 382, 291, 360, 300, 11, 291, 1961, 264, 13397, 11, 411, 370, 13, 407, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.13302286148071288, "compression_ratio": 1.3129770992366412, "no_speech_prob": 8.219920709962025e-05}, {"id": 320, "seek": 300160, "start": 3019.68, "end": 3026.96, "text": " know why it works that way, and maybe I'm missing something, but what I did here was", "tokens": [458, 983, 309, 1985, 300, 636, 11, 293, 1310, 286, 478, 5361, 746, 11, 457, 437, 286, 630, 510, 390], "temperature": 0.0, "avg_logprob": -0.13302286148071288, "compression_ratio": 1.3129770992366412, "no_speech_prob": 8.219920709962025e-05}, {"id": 321, "seek": 302696, "start": 3026.96, "end": 3034.28, "text": " I replaced the signature for the class with a signature for the dunder init, so that we", "tokens": [286, 10772, 264, 13397, 337, 264, 1508, 365, 257, 13397, 337, 264, 274, 6617, 3157, 11, 370, 300, 321], "temperature": 0.0, "avg_logprob": -0.16085626139785303, "compression_ratio": 1.6211180124223603, "no_speech_prob": 8.398014870181214e-06}, {"id": 322, "seek": 302696, "start": 3034.28, "end": 3044.0, "text": " get the right nice signature. So if we try that, here we have a look at transform, you", "tokens": [483, 264, 558, 1481, 13397, 13, 407, 498, 321, 853, 300, 11, 510, 321, 362, 257, 574, 412, 4088, 11, 291], "temperature": 0.0, "avg_logprob": -0.16085626139785303, "compression_ratio": 1.6211180124223603, "no_speech_prob": 8.398014870181214e-06}, {"id": 323, "seek": 302696, "start": 3044.0, "end": 3054.16, "text": " can see we get the correct signature as we would want. Because otherwise it's not just", "tokens": [393, 536, 321, 483, 264, 3006, 13397, 382, 321, 576, 528, 13, 1436, 5911, 309, 311, 406, 445], "temperature": 0.0, "avg_logprob": -0.16085626139785303, "compression_ratio": 1.6211180124223603, "no_speech_prob": 8.398014870181214e-06}, {"id": 324, "seek": 305416, "start": 3054.16, "end": 3058.2, "text": " dunder new, it would also be dunder call from the meta class, it would also replace the", "tokens": [274, 6617, 777, 11, 309, 576, 611, 312, 274, 6617, 818, 490, 264, 19616, 1508, 11, 309, 576, 611, 7406, 264], "temperature": 0.0, "avg_logprob": -0.14568275990693466, "compression_ratio": 1.6495327102803738, "no_speech_prob": 8.139570127241313e-06}, {"id": 325, "seek": 305416, "start": 3058.2, "end": 3068.2799999999997, "text": " signature otherwise. So that's why that's there. So believe it or not, that's actually", "tokens": [13397, 5911, 13, 407, 300, 311, 983, 300, 311, 456, 13, 407, 1697, 309, 420, 406, 11, 300, 311, 767], "temperature": 0.0, "avg_logprob": -0.14568275990693466, "compression_ratio": 1.6495327102803738, "no_speech_prob": 8.139570127241313e-06}, {"id": 326, "seek": 305416, "start": 3068.2799999999997, "end": 3076.2799999999997, "text": " all the pieces. And so if you want to study this, like so the first thing to point out", "tokens": [439, 264, 3755, 13, 400, 370, 498, 291, 528, 281, 2979, 341, 11, 411, 370, 264, 700, 551, 281, 935, 484], "temperature": 0.0, "avg_logprob": -0.14568275990693466, "compression_ratio": 1.6495327102803738, "no_speech_prob": 8.139570127241313e-06}, {"id": 327, "seek": 305416, "start": 3076.2799999999997, "end": 3083.7599999999998, "text": " is none of this is at all necessary to understand fast AI version 2. It's no more important", "tokens": [307, 6022, 295, 341, 307, 412, 439, 4818, 281, 1223, 2370, 7318, 3037, 568, 13, 467, 311, 572, 544, 1021], "temperature": 0.0, "avg_logprob": -0.14568275990693466, "compression_ratio": 1.6495327102803738, "no_speech_prob": 8.139570127241313e-06}, {"id": 328, "seek": 308376, "start": 3083.76, "end": 3092.5200000000004, "text": " than understanding the meta object data model is to use Python day to day. It's an advanced", "tokens": [813, 3701, 264, 19616, 2657, 1412, 2316, 307, 281, 764, 15329, 786, 281, 786, 13, 467, 311, 364, 7339], "temperature": 0.0, "avg_logprob": -0.13341048785618373, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.3921880710986443e-05}, {"id": 329, "seek": 308376, "start": 3092.5200000000004, "end": 3098.2400000000002, "text": " technique which you can learn about if you're interested, and if you're interested in learning", "tokens": [6532, 597, 291, 393, 1466, 466, 498, 291, 434, 3102, 11, 293, 498, 291, 434, 3102, 294, 2539], "temperature": 0.0, "avg_logprob": -0.13341048785618373, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.3921880710986443e-05}, {"id": 330, "seek": 308376, "start": 3098.2400000000002, "end": 3102.6400000000003, "text": " more about how Python works behind the scenes, so you can try doing stuff like this yourself", "tokens": [544, 466, 577, 15329, 1985, 2261, 264, 8026, 11, 370, 291, 393, 853, 884, 1507, 411, 341, 1803], "temperature": 0.0, "avg_logprob": -0.13341048785618373, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.3921880710986443e-05}, {"id": 331, "seek": 308376, "start": 3102.6400000000003, "end": 3110.0800000000004, "text": " if you want to create, change how Python works and fully use its dynamic features. So if", "tokens": [498, 291, 528, 281, 1884, 11, 1319, 577, 15329, 1985, 293, 4498, 764, 1080, 8546, 4122, 13, 407, 498], "temperature": 0.0, "avg_logprob": -0.13341048785618373, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.3921880710986443e-05}, {"id": 332, "seek": 311008, "start": 3110.08, "end": 3115.96, "text": " you want to fully understand what transform does, just check out all the tests. We've", "tokens": [291, 528, 281, 4498, 1223, 437, 4088, 775, 11, 445, 1520, 484, 439, 264, 6921, 13, 492, 600], "temperature": 0.0, "avg_logprob": -0.19270646933353308, "compression_ratio": 1.5113636363636365, "no_speech_prob": 1.1842663298011757e-05}, {"id": 333, "seek": 311008, "start": 3115.96, "end": 3123.6, "text": " tried to make it so that each test does one thing, you know, one shows one clear type", "tokens": [3031, 281, 652, 309, 370, 300, 1184, 1500, 775, 472, 551, 11, 291, 458, 11, 472, 3110, 472, 1850, 2010], "temperature": 0.0, "avg_logprob": -0.19270646933353308, "compression_ratio": 1.5113636363636365, "no_speech_prob": 1.1842663298011757e-05}, {"id": 334, "seek": 311008, "start": 3123.6, "end": 3133.7999999999997, "text": " of behavior, and we try to add comments explaining what each behavior is that it's showing. So", "tokens": [295, 5223, 11, 293, 321, 853, 281, 909, 3053, 13468, 437, 1184, 5223, 307, 300, 309, 311, 4099, 13, 407], "temperature": 0.0, "avg_logprob": -0.19270646933353308, "compression_ratio": 1.5113636363636365, "no_speech_prob": 1.1842663298011757e-05}, {"id": 335, "seek": 313380, "start": 3133.8, "end": 3140.52, "text": " yeah, hopefully that all is useful for those of you that are interested. So then you can", "tokens": [1338, 11, 4696, 300, 439, 307, 4420, 337, 729, 295, 291, 300, 366, 3102, 13, 407, 550, 291, 393], "temperature": 0.0, "avg_logprob": -0.14918971061706543, "compression_ratio": 1.5497076023391814, "no_speech_prob": 9.368536666443106e-06}, {"id": 336, "seek": 313380, "start": 3140.52, "end": 3148.92, "text": " see tuple transform and item transform just force add item to be true or false. And lots", "tokens": [536, 2604, 781, 4088, 293, 3174, 4088, 445, 3464, 909, 3174, 281, 312, 2074, 420, 7908, 13, 400, 3195], "temperature": 0.0, "avg_logprob": -0.14918971061706543, "compression_ratio": 1.5497076023391814, "no_speech_prob": 9.368536666443106e-06}, {"id": 337, "seek": 313380, "start": 3148.92, "end": 3158.4, "text": " more tests of that behavior, as you can see. All right. Well, I think that's enough for", "tokens": [544, 6921, 295, 300, 5223, 11, 382, 291, 393, 536, 13, 1057, 558, 13, 1042, 11, 286, 519, 300, 311, 1547, 337], "temperature": 0.0, "avg_logprob": -0.14918971061706543, "compression_ratio": 1.5497076023391814, "no_speech_prob": 9.368536666443106e-06}, {"id": 338, "seek": 315840, "start": 3158.4, "end": 3164.36, "text": " today because that was super dense. And yeah, if you start looking through this code and", "tokens": [965, 570, 300, 390, 1687, 18011, 13, 400, 1338, 11, 498, 291, 722, 1237, 807, 341, 3089, 293], "temperature": 0.0, "avg_logprob": -0.19194446563720702, "compression_ratio": 1.3310344827586207, "no_speech_prob": 7.963136158650741e-05}, {"id": 339, "seek": 315840, "start": 3164.36, "end": 3170.04, "text": " want to learn more about it, feel free to ask any questions you like. All right. Thanks,", "tokens": [528, 281, 1466, 544, 466, 309, 11, 841, 1737, 281, 1029, 604, 1651, 291, 411, 13, 1057, 558, 13, 2561, 11], "temperature": 0.0, "avg_logprob": -0.19194446563720702, "compression_ratio": 1.3310344827586207, "no_speech_prob": 7.963136158650741e-05}, {"id": 340, "seek": 317004, "start": 3170.04, "end": 3189.04, "text": " everybody. Bye.", "tokens": [50364, 2201, 13, 4621, 13, 51314], "temperature": 0.0, "avg_logprob": -0.8033999034336635, "compression_ratio": 0.6521739130434783, "no_speech_prob": 0.00011216167331440374}], "language": "en"}