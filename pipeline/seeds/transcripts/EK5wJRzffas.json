{"text": " Okay, we're recording. So I know there was some questions on the forum. Matt, I think it was you, right? A couple of questions. Yep, that's correct. I can read them out for you if you like. Oh yeah, or you can express them in your own terms, whatever. Yeah, tell me. So I guess they weren't so much, first of all, there weren't a couple of, there weren't questions. There were just sort of differences when working on paper space, you're working on your local GPU. And I found SimLinking the Kaggle folder into storage with my API keys, something that I did to make it a little bit easier to restart. Just wanting to verify that that's sort of a good thing to do. And the one thing that I would be really keen to know about is the, when I did the PIP install of Kim, it was fine, it was installed, but I had to restart the kernel. And I'm wondering, that might be a bit of a pain going forward. I'd prefer to have it persistently just there, ready to go. But it's not a conda package, so I wasn't sure how to... Yeah, so it's actually PIP packages are the only ones we've actually got the persistence working for. So let's do that one first. So the key thing when you install Tim, let's see, do I already have it installed? Okay, great. I don't, so let's do it. So the key thing to remember is when you install Tim is to do it with dash dash user. Now, in order to make that easier, I think what I would be inclined to do would be to edit our slash storage slash dot bash dot local and add to it alias, let's do PI for PIP install equals PIP install. Let's do minus U for upgrade. That should work even if it's not installed already. Minus minus user. Okay. Now, if I, so I could close and reopen my terminal or I could just type source and then the name of the script, which of course in this case is exclamation mark dollar. Whoopsie-daisy. Exclamation mark vim will rerun this. This whole thing needs to be in quotes because it's a single thing. It's my alias. Okay. Up arrow twice. Okay. So now I can just type PI. And by the way, if you want to know what something is, if you type which PI, it won't tell you anything useful because it's an alias, not a binary. But if you type, type PI, it will tell you exactly what it is in this case. Oh, it's something that's an alias. So I can type PI, Tim. And the key thing about minus minus user is that's going to put it in my dash dash local directory. Sorry, my dot local directory. So there it is, Tim. So then all you need to make sure is that your local directory is SIM linked to dot slash storage config local. Oh, now that's interesting. Our this is here is telling us we've got a broken SIM link. So that's what that means. Yeah. Dot get config is SIM linked to slash storage. But there is no dot get config there. So I might have maybe forgot to move that or something. So that's okay. Next time we try to commit, it'll tell us and we'll know to fix that then. To create a file that's empty, you just use touch. So I'm just going to go ahead and create an empty file. So at least it exists and then things won't get horribly confused. Did I not touch it correctly? Slash storage slash dot get config. Oh, there's a slash at the end. Oh, that's why. That's why it's confused. So that would be a directory, but this is not a directory. So my guess is that there's a bug in our pre run script for dot get config. Yes, I've got a slash at the end. So that's why that didn't work. So if I source that, now it's happy. Great. So now, yeah, so now since it's been installed, it's available. And if I run ipython, we can confirm it did install. That should be all good. Does that answer that part of the question, Matt? Yes, thank you. So then the second one, yeah, it was not a question, but a comment, which is about Kaggle. So yeah, when I get back to using Kaggle on this machine, we will do that for sure. Which will probably be next time. And you also had a question about jumping around to, you know, the end of a string, for example. Which... Which... Let's grab the fast AI repo, for example. Oh, and you also had a question about loading and serving models. Great. So, I mean, one thing obviously is it'd be nice to have a tags file. At some point, we could even talk about how to set up Vim to automatically create that for us from time to time. But let's have a look at, I don't know, layers for example. So, a few things to mention. The first is something which sounds very obscure, but actually isn't, is F in Vim. F in Vim is like slash. Now slash searches. So we've seen it before. Slash, in it. We'll search for the next thing called in it. Okay. Oh, maybe something we haven't discussed is to go back to where we were, regardless of whether it was a tag or a search or anything. It's control O. And right next to control O is the letter I, which goes forward again. Okay. So control O and control I go kind of, it's like pressing the back button and the forward button on your browser. There's something a lot like slash, but which just finds a single letter, which is F. If I type F, it's going to, and it's under search on the current line. It'll search on this line for the next thing I type. So if I type F double quote, actually maybe more interesting would be F full stop. So if I type F full stop, it's going to jump to the full stop. F dot. So you see it jumps to the full stop. Right. And so your question was, well, what about jumping to the end of a string? Now, obviously in this case, the end of a string is the last character of the line. So there's a better answer, which is to start inserting at the end of the line. It's shift A. Just one moment. My daughter's got kicked off her zoom call. Always technical problems. Okay. So I can undo that. Control O to go back to where I was. But yeah, so let's say there was some stuff at the end, hash some comment. Right. And we wanted to, yeah, we wanted to go to the next double quote. I can just type F double quote and it takes me there. And then shift F does the opposite. It searches backwards. And the reason it's interesting mainly is that that's emotion. And therefore I can combine things with it. So for example, if I wanted to delete everything up to the next quote, I can press D F double quote. Right. And then I could press slash double quote to search the next one and press dot and it'll do the same thing again. Right. Or maybe delete everything up to the next comment would be D F hash. So yeah, those are a couple of useful things. Another really useful one is percent. Percent jumps to between the start and the end of a of a set of paired parentheses or braces or brackets. So if I press percent here, it goes to the start, it goes to the start of end of the next parentheses and then press it again. You can see it jumps between the two. Right. And so if I do it from here, you can see it jumps to the end of this one. Right. If I do it at the very end, it'll jump to this one. So if I want to delete from here to the end of the parenthesized parenthetical expression, let's say to delete this bit, I could press D F sorry, D F percent. Sorry, not D F percent, just D percent. There you go. D percent. You see. Although there's actually something even better for that, which is I and I is refers to an area, the whole area that is surrounded by some kind of parentheses. So even when I'm in the middle of these, this these parentheses, the the enclosing parentheses would go from here to here. And so I stands for inside. So if I want to delete everything inside those parentheses, I can type D I open round, do it again, D I open round parentheses and it deletes the contents, which is really nice. So let's say I wanted to like replace all my parameters with something else like A comma B, then I would use C for change inside parentheses. I would type my change like A comma B, right. And then I can come down here and type dot and it will do the same thing. So, yeah, it's like maybe your work you can kind of really crush with these tricks. Great. Fantastic. Yeah, it's cool. There's a lot of them and you don't have to know them all. You know, it's like you can learn one thing each day or something. Yeah, I'm not using any plugins or anything, you know. Okay, so we're going to save a model in a moment. Any other questions or comments before I go back to our notebook? I want to make one comment about the Tim installation. I don't know if maybe you discussed this yesterday because I came a little late, but with the Tim installation, sometimes it might be better to install from master because there are some changes that Ross has made that you might not receive. Yeah, we did mention that yesterday. Actually, I think the conclusion we came to was to install the latest pre-release because that's like something that's more stable than installing from master, but you know, better than his. Sometimes, like here, he went six months without updating. So, yeah, I agree. In fact, so let's do that. So, this is 0.6.2 dev. So, I think we decided that we'd go, let's use our new PI thing. Tim is greater than or equal to 0.6.2 dev. Great. Yeah, thanks for the reminder, Tanisha. All right, great. All right, great. It's kind of this thing in Python modules and quite a lot of other things. If there's like an extra.dev at the end, that means it's a pre-release, basically. So, pip has this convention that if you say I want to install something that is at least as recent as 0.6.2 dev, then that's a way of signaling to pip that you're happy to include pre-release options. Is there any reason that when you do the installation of Tim and then you try to use the learner, it says that Tim doesn't exist when you try to load the model. Right. That's because you have to restart the kernel after installing it. So, now that it's installed in.local every time I start a machine, it's going to be there anyway. So, you won't have to worry about that again. Okay. So, this was our notebook from yesterday. And I wanted to try and improve the model. And one of the reasons I wanted to try to improve the model is because our result was worse than the top 50%. There you go, top 50%. I didn't know that was a tip. That's handy. And so, we should, you know, I want to aim to at least be as good as this helpful fast AI out of the box person. So, they got.97385. How far off are we? That was me. That was my number. Fantastic. I like it. It's a good notebook. So, we're going to try to beat you. I hope you don't mind. But then you'll know how to beat us. Because at least you know how to match us. So, yeah. I saw that what you did here was you trained for longer, which makes sense. And you also used some data augmentation, which makes sense. So, let's talk about this. So, if we're going to train for, so, what's your name? Gerardo, is it Gerardo or Gerardo? Either way, that's fine. Which is right. I want to be accurate. Gerardo. My name is Gerardo. In Spanish, it's Gerardo. I see. So, both are right. No worries. Thank you, Gerardo. Okay. So, if we're going to train as long as Gerardo did, then, you know, if you train more than about five epochs, you're in danger of overfitting. And certainly 10, I feel like you're in significant danger of overfitting. Because your model's going to have seen every image, you know, 10 times. So, in order to avoid overfitting to the specific images it's seeing, we should make it so that it sees a slightly different image each time. And this is discussed in the book in some detail. But basically, if you pass in batch transforms, these are things that are going to be applied to each mini batch. So, to each bunch of however many, 32 or 64 or whatever images. And this is basically a bunch of functions that are going to be applied. So, what does this function do? Org transforms. So, this is transforms for data augmentation. So, we know that the best way to find out what something's going to do is to check its help. So, let's start there. Not help, doc. Okay, so, it's going to do things like flip our images, rotate them, zoom them, change their brightness, their warp. Let's see, show in docs. Okay, and here's some examples of a very cute puppy that Sylvia found. I think Sylvia found it. So, this is all the same puppy, it's all the same picture. And as you can see, each time the model sees it, it sees a somewhat skewed or rotated or brightened or darkened or whatever version of that picture. And so, this is called data augmentation. So, let's try then running that. And so, org transforms actually returns a list, right? It returns a list of transformations. So, here's the flip transformation with a probability of 0.5, it'll flip. It's got a brightness transformation with a probability of 1, it will change the lighting by up to 0.2. And then random resized crop is perhaps the most interesting one, which is it will zoom in such that it has at least 75% of the height width and it will basically pick a smaller zoomed in section randomly chosen each time. So, what we can do is when we say show batch, if you say unique equals true, it'll show the same picture each time. And so, here you can see four versions of the same picture. You can see sometimes it's flipped, sometimes it's moved a little bit up and down, sometimes it's a little bit darker or less dark and it's also a little bit rotated. So, that's what data augmentation is and that really helps us if we want to train a few more epochs. Then the second thing I figured we should do is, you know, ResNet's actually great, but there are things which are greater. And as we talked about, Tim has a bunch of them and in particular, ConvNext is pretty good. And the other thing, you know, we could do is think about learning rates. The default learning rate used by Fast.ai is one where I would say I picked it on the conservative side, which means it's a little bit lower than you probably need because I wanted things to always be able to train. But there's actually a downside to using a couple of downsides to using a lower learning rate than you need. The first is that, you know, if you're using a lower learning rate, the first is that given fixed resources, fixed amount of time, you're going to have less epochs, not less epochs, sorry, less distance that the weights can move. The second is, it turns out, a high learning rate helps the optimizer to explore the space of options by jumping further to see if there's better places to go. So the learning rate finder is suggesting things around about 0.002, which is indeed the default. But you can see that all the way up to like 10 to the negative 2, it still looks like a pretty nice slope. And the other thing to remember is, you know, as we saw after answering Nick's question yesterday, we're using one cycle training schedule, which means we're gradually increasing the learning rate. And my claim was that by doing that, we can reach higher learning rates. So I would also say that even these recommendations are going to be a bit on the conservative side. So what I did just before I started this call was I tried training at a learning rate of 0.01, which is five times higher than the default. And so that's up here. And I did find actually that that did give us a quite a better result with a 2% error. So let's see, I mean, obviously, you've got different training sets, but this is hopeful, right, that we're going to get a better result than our target. It's nice to have a target aim for. Okay, so that's that was the next thing. So then it's since this took, you know, six minutes to train, it's probably a good idea to save it. So there's a couple of different things we can save with. One is dot save and the other is dot export. So learner dot export saves the contents, that's not very well written self, the learner self means that this learner, and it saves it to self dot path slash FNAME, so learner dot path slash FNAME using pickle. So basically, what that means is if you if you call this, learn dot export, it's going to save it into learn dot path. So let's find out learn dot path is what train images. And so this is actually whatever we passed in here. So if we want to save things somewhere else, there's we've got a couple of options. One is to change learn dot path by setting it equal to some other path. Or we can just use an absolute path. So an absolute path is a path. So an absolute path is something that starts with slash. And so if I want to save it somewhere in storage, for example, that I can type slash storage slash whatever. Or maybe I want to put it in slash notebooks somewhere. So these are the these are some ways you can change where it's going to save. I might even just put it into the current directory. I think that seems fine to me. Well, actually, where are we current directory? Yeah, put it in git patty. That sounds fine. Or maybe to be a bit more sure just in case the directory ever changes. So then the other option is learn dot save. So learn dot save doesn't save the whole learner. It just saves the model and the optimizer state. The difference is that remember a learner doesn't just contain the model, but it also contains it also contains information about the data loaders and specifically what transformations are applied. So I think that's a good point. So I don't really often, if ever, use dot save. The only reason I would use dot save is like if I was writing something to like, and we already have stuff in fast.ai. Let's give an example. In fast.ai, we have something that's a callback that can save the model at the end of each epoch or each time it gets a better result than its previous best or whatever. In those cases, we might use dot save because then you recreate a learner and you can dot load into the learner. But yeah, for exporting something, I want to be able to just load that exact thing with all the same details next time. Dot export is the way to go. So I'm going to call dot export. I'm going to use it's a conv next. It's small and I did 12 epochs. Oh, and this needs to be an actual path. Normally we actually try to make these things do that for you, but this is less friendly than I would like. Sorry about that. There we go. Okay. So we should now be able to see it. There it is. Okay. And it looks like we need to give it a dot pick or whatever. By default, with org transforms, which uses random resize crop, it will randomly pick a subset of the crop of the image of this size or bigger. And the validation set, it will pick out the center. It'll, you know, as all the width it can or all the height it can without changing the aspect ratio. If you say squish instead, it will grab the whole thing and change the aspect ratio to squish it into a square. Matt, you don't have to raise your hand. Just talk to me, mate. What's up? Can you hear me? I can't hear you. Does that mean you can't hear me? I can hear you, but I don't think you can hear anybody. You do need to raise your hand. I can't hear you. Why can't I hear you? But you guys can hear me? Okay. Yes. Yes, we can hear you, Jeremy. We can hear you. I see why. Okay. Say something. Can you hear me now? Yeah. Yeah, I can. All right. Okay. All right. Did you guys, were you guys saying anything I was meant to be hearing? Did I miss anything? Yeah. Why did you choose 12 epochs? Oh, no particular reason. I just saw that this one was using 14 and I thought, oh, I'm for something around there, but maybe just do a little bit less. I guess I often do around 12-ish epochs. Like, it seems to, like, for fine-tuning things, which are somewhat similar to the original, it often seems to get pretty close to, you know, getting all the information it can, just as a rule of thumb. And I have a question. And it runs at a reasonable amount of time too, I'd say. My assumptions were that the number 460 is because of the size of the images were 460. And then another assumption was 224 because when you show the team with the different, the convex and the image size was 224, that's the reason that I selected that. Is that okay? Is that a correct assumption? Well, that was 620. By 480. So actually, so we do this, look it up in the book. It's under the section called pre-sizing. And I think this is around what we always pre-size to. So actually, maybe 480 would have been better because then it wouldn't have had to change one of the dimensions because there was 640 by 480. And then your size you picked, I actually changed it. So Gerardo picked 230. But actually, most of these models that are trained on ImageNet are generally trained on 224. So I wanted them to be the same size as what they trained on. So that's why I picked 224. Yeah, so then Squish I've talked about. Oh, and then the other thing is the model I picked is one with a suffix in 22k. IN here refers to ImageNet. And the 22k refers to the version of ImageNet with 22,000 categories, as opposed to the version that's normally used, which only has a thousand categories. So this is a ConvNext, which is small, but is trained on ImageNet with a 22,000 category version. The 22,000 category version, it just has a lot more images covering a lot more different things. So there's a much higher chance that it's going to have seen something like rice paddy illness than the one with a thousand images. And it's just seen a lot more different pics. So yeah, I would recommend always using the IN22k pre-trained models. So those are, I think, the key differences at the training stage. Yeah, I think when you had put the export and then the error came, that's when it cut off. So I don't think you explained what you did to, well, you didn't catch the part where you explained the fix. The fix. Well, because the export had an error, right? And then I guess you've now added the path. I don't think it had an error, but I just, oh, I see. Yes, yes, yes. Okay. Yeah, the export had an error because this was a string and it actually needs to be a path, which I'd say is an oversight on my part. I try to make it so that everything can accept a path or a string. So I would consider that a bug that ought to be fixed. So hopefully by the time people watch this video, that might've been fixed. But yes, at the moment I had to change this to a path. Thank you. All right. So there's a few things we could do here, right? But one key issue is that the, is that particularly if you don't have method equals squish, when we do validation, it's only selecting the center of the image and that's a problem, right? We would like it to see all the image. And then another thing is that we've been training it with various different augmentations, but the validation set, we don't use any of those augmentations. So there's a trick you can use, which you should particularly use if you don't use squish, and that's effectively cropping into the center, which is something called test time augmentation. And in test time augmentation, we basically get multiple versions of each image. We actually by default get four different randomly augmented versions of each image, plus the unaugmented version. We get the prediction on every one, and then we take the average, and that's called test time augmentation. And as I said, it would work particularly well without the squish, but it ought to work well even with the squish. So to get those predictions, let's first of all make sure we can replicate this error rate. Manually, right? So if we go probabilities, targets equals learn.getPreds, and we pass in the validation set, and then we should find that if we ask now for the error rate, shift tab, so the inputs are the probabilities, and the targets are the targets. There we go. Okay, so that's our 2.02% error rate, so we've replicated that. Okay, so now we've got that 2.02. I would then try out tta, and of course before we use a new function, we would always read its documentation. Here we are,.tta. So return the predictions on some data set or some data loader. We get the predictions n times by default four, using the training set transformations. Great. Oh, and instead of getting the average of predictions, we could also get the max of predictions. Cool. And the other thing which I definitely encourage you to do is always good to look at the source code, because my claim is that fast AI functions are generally not very big. And also quite a bit of its stuff you can skip over, right? This is like, oh, what if it's none, what if it's none? This is setting defaults. You can skip it. Try finales, you can skip because it's just error handling. Widths, you can pretty much split. Progress bars, you can pretty much skip. So the error rate is the average of the progress bars you can pretty much skip. So the actual work starts happening here. We're going to call self.getPreds, passes in a data loader, and then it concatenates that all together, and then it takes either the maximum or the mean, depending on whether you asked for the max or not, and it also grabs it for the validation set data loader. Yeah, so you kind of get the idea. So let's run it. See if we can beat 2.02%. So you can see here it's running it four times for each of the four augmented versions. And then it'll run it one time for the non-augmented version. Okay, and it beat it, but just by a little bit. And then, you know, another thing is, well, what if we did the non-maximum? Use max equals false. Use max equals true. Use the maximum instead of the average. Yeah, I kind of wish I didn't have the squish in now, but I don't want you guys to have to wait 10 minutes for it to retrain because then you'd much more clearly see the benefit of using TTA. That's interesting. That one's worse. So I generally find that when not using squish, that using TTA and use max equals true is best. Okay, so now we've done all that. We can try and submit this one to Kaggle. So we can just repeat basically what we had yesterday, but instead of get preds, we'll do TTA. Now there's no with decoded, I don't think, for TTA. So we're going to have to do a bit of extra work here. So this is going to give us the probabilities and the targets. So the probabilities, each row is going to contain a probability for each element of the vocab. So we can take a look. So for each of the 3,469 things in the test set, there are 10 probabilities, which presumably means the length of the vocab is 10, which it is. Great. So what we want to do is find out, well, what's it actually predicting? And the thing it's predicting is whatever thing has the highest probability. So we're going to go through each row and find the index of the thing with the highest probability. So in math and PyTorch, numpy, that's called argmax. So argmax is the index of the thing with the highest value. So probs.argmax. And so what do we want to take the maximum over, which dimension? So we want to do it over rows, which I think we say dimension equals one. There we go. So that's the correct shape. So now we should be able to do the same thing we did yesterday, which is to convert that into a series. And we can see that the matrix is now going to be running the same thing. So we're going to use this to convert that into a series. And now we should be able to run this mapping. Now I realize actually this thing we did yesterday a really long way of just saying create a dictionary from those tuples. So when you create a dictionary, you can do it like this. Or you could do this. Here's a tuple of tuples. Here's a tuple of tuples. Okay, sorry. Here's a tuple of tuples. And ideally what we'd like is to call dict and pass in each pair of these as an argument to it. And so Python actually has syntax to do exactly that for any function, not just dict, which is the function star star. And star star means take a mapping and pass it in as pairs. So that's what this does, right? That's going to be a mapping, which enumerate already is. So that's what star star. Let's just pop this here. Why is this not working? I expected this to work. How annoying. How annoying. Well, so much for that discussion. Annoying. All right, I'm going to have to try to think of a better way to make this work. Because so far, similar problem to what we had yesterday. I think you don't need the star star in that case. Wow, that's nice, isn't it? Even better. Thanks for the trick. Okay. I didn't quite get to show you about how cool star star is, but never mind. Okay. So what I'm going to do is I'm going to make a copy of the last time we did ahead of the submission. And one reason I like to do that for my new submission is to confirm that our new one looks somewhat similar. So previously, we went hisp-normal, downy, blast-blast. Now we go hisp-normal, blast-blast-blast. And so this makes me feel comfortable that, okay, we haven't totally broken things. It's still giving largely the same results as before with a few changes. And so that's just something I like to do. Okay. And then another thing I like to do is kind of keep track of stuff I've done before. I try not to delete things I've used before and just pop it into a different notebook or a comment. So down here, I'm just going to have non-TTA version just in case I want that again later. All right. So we should be able to submit that now. Okay. So I used Ctrl-R and then started typing competitions. Okay. So this is now a squish, convnext, small, 12 epoch, fine-tune, tta. Uh-huh. What on earth did it do to my window? How do I get it back? Oh, it... Oh, I see, I've got to... How does that happen? I've got to... It just stops going. I didn't notice that. Alright, let's go and check out Kaggle. My submissions. Oh, look at that. Harada's still beating us, I think. But at least we've beaten our previous one. That's amazing. That's great. Jump to our leadable position, we're going to have a good battle on... 34. No, I think you beat me up. Wait, I thought yours was better than that. I think I'm a little bit lower. Code. Oh, you were 97385. Okay, 979. Ah, okay. That's not bad, right? Actually, 34th out of... I mean, it's just a fun competition. Nobody's really trying too hard, but still, you know, it's nice to feel like you're... in the mix. How far are we? Okay, so... This person's still way ahead, right? They've got an error of 1.3%, and we've got an error of 2.1%. You know, something else that would be fun would be... You know, you can kind of super easily create an ensemble. So maybe I'll show you how I would go about creating an ensemble. To create an ensemble, I would be inclined to maybe... We could create an ensemble with an unsquished version, for instance. So what I would do is I'd kind of like copy all the stuff that we used to get our predictions. Right? And then I would kind of paste them down here. Go through and remove the stuff that isn't quite needed. Like so. This one's going to be... No squish. And... I'll do max. Use max. Calls true. And so then to merge cells, it's shift-M, M for merge. And... Don't need the error rate anymore. And so this is going to be a second set of probabilities and a second set of targets. Yeah, so we could just run that and take the average of these two models. Oh, remove squish here. Okay, so that might be our third model. And then another model I would be inclined to try is one that doesn't use square. So we've got 640 by 480 images, right? So the aspect ratio is 4 to 3. So I would be inclined to say take that and multiply that by the smaller side we want. Okay, that gives us 298.66. It'd be nice to find something that works a bit more evenly, wouldn't it? What if we did it the other way around? So we could create 168 by 224 images, for instance, or... 336 maybe? 336 by 252 images? Yeah, let's do that. So let's change this size. And I never quite remember which way around it is, but that's okay, we'll check it. So 336 by 252 images. And so the reason I'm doing rectangular, sorry, rectangular images is that all of our input images are the same aspect ratio, so there's no particular reason to make them square. You know, when some of your images are wider than tall and some are taller than wide, then it makes perfect sense to, you know, use square as your, you know, the thing that everything gets changed to. But when everything's wider than they are tall, especially when they're all the same aspect ratio, it makes more sense to keep them at that same aspect ratio. And, you know, another thing I guess we should consider doing for 640 by 380 is to, you know, you can change their resolution more gracefully without weird interpolating fuzziness by doing it by, you know, a factor of 2. So we could do 320 instead of 640 and by 240. So that would be another one I'd be inclined to try. Yeah, in fact, let's just do that. Let's make that the aspect ratio. There we go. And so obviously we should check it and we know how to check it, which is to go show batch. OK, so you can see I've got it the wrong way around. There we go. That's better. Cool. And like, given that we're going to have such nice clear images, I would probably do the, the affine transforms are the ones where we're zooming and rotating and stuff. So to say don't do those so often, we can change the probability of affine transforms from 0.75 to 0.5. The probability of affine transforms to 0.5. So in theory, I feel like this one feels the most correct, given that the data that we have is a fixed input size of that type. So I would be inclined to. Well, you know, we'll take a look afterwards, but. Oh, did I just do. Copy. We'll save a different set. So we can easily then check the accuracy of each of them. And this one's going to be rectangular. Rectangular. OK. Now that we're saving a few, I guess I'm a little worried that paper space might disappear. And so I'm actually inclined to save these into my notebooks directory. Just to be a bit paranoid. Copy. And so let's move. Let's move this one into slash notebooks. Oh, that's right. I'm not using paper space, so I don't have to. I forgot. Never mind. I'm on my own machine. I like the fact that I've got paper space so well set up now that I don't even remember I'm using paper space. OK. Great. I think that's that. All right, I'm going to not have you guys watch that run for 20 minutes so I'm going to go. Any questions or comments before we wrap up. So I see that you're like focusing a lot on like the data transformations and augmentations. When would you focus on that versus, you know, playing around with different models and things like that instead. Given that this is a image classification task for natural length for natural photos. Yeah, well almost certainly have exactly the same characteristics as image net in terms of accuracy, or at least try any fine tuning on image net. So, I would, I'm working on the assumption which I could read off we can test later but I'm pretty sure it's going to be true that the things that are in that that notebook showing which which Tim models are better than others will apply to this data set. So, I would. Once everything else is working really well. You know, I would then try it on a couple of models or at least run it on a bigger one like base or large or whatever I can get away with. If it was like a segmentation problem or an object detection problem or a medical imaging data set which has the kind of pictures that aren't an image net you know for all of these things I would try more different architectures but then for those cases, I would say it was a segmentation problem which is about recognizing what each pixel is, it always is, is a pixel of. Even there I would not try to replicate the research of others instead I would go and look at something like papers with code calm to find out which techniques have the best results on segmentation and better still I would go and find two or three previous competitions that have a similar problem type and see who won and see what they did. Now when you look at who won. They always say oh we made an ensemble, which is fine. The important thing isn't that they did an ensemble it'll be they'll always say pretty much the best model in our ensemble was X. And so I would just use X, and I would use this kind of like smallest version of X I can get away with. Now generally, fiddling with architectures tends not to be very useful nowadays for any kind of problem that like people have fairly regularly studied, which almost any computer vision problem is of that type. I guess the only interesting question for this one would be, there is something saying what kind of rice is in this patty, which is like a category, but I'm fairly sure that using that information is not going to be helpful in this case, because the model can perfectly well see what kind of rice it is, so I very much doubt we have to tell it. Because it's got pictures. Jeremy. Yeah, it's, it's, it's going to take me a while to work through all of the videos. Yeah, they're going to be virtually available. Yes. Cool. Yes. And don't feel like you can only join if you've watched all the previous videos, and don't feel like you can only ask a question if you've watched all the previous videos, like, it's totally fine to ask a question about a video we did a week ago, or about something that we just covered yesterday or whatever. If the answer to your question is, oh, we cover this in this video. Here's where you go, I will tell you that, and that's totally fine but and if it's like, okay you said this thing in this other video but I don't get it, say it again. It's totally fine to like, we're moving at quite a fast pace, because people can go back and rewatch the videos and because people can come back later and ask questions about things that aren't clear. So yeah, definitely does rely on people turning up and saying, I'm not clear on this or, or whatever. So I sort of started from ground zero in this whole environment, but it is starting to make sense now. I'm starting to feel a little bit more comfy with it. Nice. Let's take the time to work through my way through and absorb what you've been talking about. Daniel I will say like, there's a couple more lesson lessons to come. Like, what is it next week or the week after I suspect during those two weeks I'll probably stop the walkthroughs. So, there'll be a couple of weeks there to catch up but yeah like feel free to. Join in anytime or not join in anytime and ask questions about any video or even about things that's not covered in a video but you feel like would be something useful to know in order to understand. I'm really looking forward to the tabular data actually. Oh cool. Okay, thank you. Thanks all. See you next time. Bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.52, "text": " Okay, we're recording. So I know there was some questions on the forum.", "tokens": [1033, 11, 321, 434, 6613, 13, 407, 286, 458, 456, 390, 512, 1651, 322, 264, 17542, 13], "temperature": 0.0, "avg_logprob": -0.23068240903458506, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.0446152538061142}, {"id": 1, "seek": 0, "start": 4.4, "end": 7.92, "text": " Matt, I think it was you, right? A couple of questions.", "tokens": [7397, 11, 286, 519, 309, 390, 291, 11, 558, 30, 316, 1916, 295, 1651, 13], "temperature": 0.0, "avg_logprob": -0.23068240903458506, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.0446152538061142}, {"id": 2, "seek": 0, "start": 10.88, "end": 13.52, "text": " Yep, that's correct. I can read them out for you if you like.", "tokens": [7010, 11, 300, 311, 3006, 13, 286, 393, 1401, 552, 484, 337, 291, 498, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.23068240903458506, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.0446152538061142}, {"id": 3, "seek": 0, "start": 13.52, "end": 18.080000000000002, "text": " Oh yeah, or you can express them in your own terms, whatever. Yeah, tell me.", "tokens": [876, 1338, 11, 420, 291, 393, 5109, 552, 294, 428, 1065, 2115, 11, 2035, 13, 865, 11, 980, 385, 13], "temperature": 0.0, "avg_logprob": -0.23068240903458506, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.0446152538061142}, {"id": 4, "seek": 0, "start": 19.12, "end": 26.16, "text": " So I guess they weren't so much, first of all, there weren't a couple of, there weren't questions.", "tokens": [407, 286, 2041, 436, 4999, 380, 370, 709, 11, 700, 295, 439, 11, 456, 4999, 380, 257, 1916, 295, 11, 456, 4999, 380, 1651, 13], "temperature": 0.0, "avg_logprob": -0.23068240903458506, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.0446152538061142}, {"id": 5, "seek": 2616, "start": 26.16, "end": 32.24, "text": " There were just sort of differences when working on paper space, you're working on your local GPU.", "tokens": [821, 645, 445, 1333, 295, 7300, 562, 1364, 322, 3035, 1901, 11, 291, 434, 1364, 322, 428, 2654, 18407, 13], "temperature": 0.0, "avg_logprob": -0.16584857304890951, "compression_ratio": 1.4416243654822336, "no_speech_prob": 0.00030961379525251687}, {"id": 6, "seek": 2616, "start": 33.52, "end": 34.24, "text": " And I found", "tokens": [400, 286, 1352], "temperature": 0.0, "avg_logprob": -0.16584857304890951, "compression_ratio": 1.4416243654822336, "no_speech_prob": 0.00030961379525251687}, {"id": 7, "seek": 2616, "start": 36.96, "end": 44.32, "text": " SimLinking the Kaggle folder into storage with my API keys, something that I did", "tokens": [3998, 43, 12408, 264, 48751, 22631, 10820, 666, 6725, 365, 452, 9362, 9317, 11, 746, 300, 286, 630], "temperature": 0.0, "avg_logprob": -0.16584857304890951, "compression_ratio": 1.4416243654822336, "no_speech_prob": 0.00030961379525251687}, {"id": 8, "seek": 2616, "start": 44.32, "end": 50.08, "text": " to make it a little bit easier to restart. Just wanting to verify that that's sort of a good", "tokens": [281, 652, 309, 257, 707, 857, 3571, 281, 21022, 13, 1449, 7935, 281, 16888, 300, 300, 311, 1333, 295, 257, 665], "temperature": 0.0, "avg_logprob": -0.16584857304890951, "compression_ratio": 1.4416243654822336, "no_speech_prob": 0.00030961379525251687}, {"id": 9, "seek": 5008, "start": 50.08, "end": 62.4, "text": " thing to do. And the one thing that I would be really keen to know about is the, when I did the", "tokens": [551, 281, 360, 13, 400, 264, 472, 551, 300, 286, 576, 312, 534, 20297, 281, 458, 466, 307, 264, 11, 562, 286, 630, 264], "temperature": 0.0, "avg_logprob": -0.1590571403503418, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.00016329073696397245}, {"id": 10, "seek": 5008, "start": 62.4, "end": 72.8, "text": " PIP install of Kim, it was fine, it was installed, but I had to restart the kernel. And I'm wondering,", "tokens": [430, 9139, 3625, 295, 5652, 11, 309, 390, 2489, 11, 309, 390, 8899, 11, 457, 286, 632, 281, 21022, 264, 28256, 13, 400, 286, 478, 6359, 11], "temperature": 0.0, "avg_logprob": -0.1590571403503418, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.00016329073696397245}, {"id": 11, "seek": 5008, "start": 73.92, "end": 77.68, "text": " that might be a bit of a pain going forward. I'd prefer to have it persistently", "tokens": [300, 1062, 312, 257, 857, 295, 257, 1822, 516, 2128, 13, 286, 1116, 4382, 281, 362, 309, 13233, 2276], "temperature": 0.0, "avg_logprob": -0.1590571403503418, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.00016329073696397245}, {"id": 12, "seek": 7768, "start": 77.68, "end": 85.2, "text": " just there, ready to go. But it's not a conda package, so I wasn't sure how to...", "tokens": [445, 456, 11, 1919, 281, 352, 13, 583, 309, 311, 406, 257, 2224, 64, 7372, 11, 370, 286, 2067, 380, 988, 577, 281, 485], "temperature": 0.0, "avg_logprob": -0.2994060897827148, "compression_ratio": 1.5613207547169812, "no_speech_prob": 1.9220982721890323e-05}, {"id": 13, "seek": 7768, "start": 85.2, "end": 89.92, "text": " Yeah, so it's actually PIP packages are the only ones we've actually got the persistence", "tokens": [865, 11, 370, 309, 311, 767, 430, 9139, 17401, 366, 264, 787, 2306, 321, 600, 767, 658, 264, 37617], "temperature": 0.0, "avg_logprob": -0.2994060897827148, "compression_ratio": 1.5613207547169812, "no_speech_prob": 1.9220982721890323e-05}, {"id": 14, "seek": 7768, "start": 89.92, "end": 95.44000000000001, "text": " working for. So let's do that one first. So the key thing when you install Tim,", "tokens": [1364, 337, 13, 407, 718, 311, 360, 300, 472, 700, 13, 407, 264, 2141, 551, 562, 291, 3625, 7172, 11], "temperature": 0.0, "avg_logprob": -0.2994060897827148, "compression_ratio": 1.5613207547169812, "no_speech_prob": 1.9220982721890323e-05}, {"id": 15, "seek": 7768, "start": 96.0, "end": 97.76, "text": " let's see, do I already have it installed?", "tokens": [718, 311, 536, 11, 360, 286, 1217, 362, 309, 8899, 30], "temperature": 0.0, "avg_logprob": -0.2994060897827148, "compression_ratio": 1.5613207547169812, "no_speech_prob": 1.9220982721890323e-05}, {"id": 16, "seek": 7768, "start": 103.2, "end": 105.36000000000001, "text": " Okay, great. I don't, so let's do it.", "tokens": [1033, 11, 869, 13, 286, 500, 380, 11, 370, 718, 311, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.2994060897827148, "compression_ratio": 1.5613207547169812, "no_speech_prob": 1.9220982721890323e-05}, {"id": 17, "seek": 10536, "start": 105.36, "end": 115.03999999999999, "text": " So the key thing to remember is when you install Tim is to do it with dash dash user. Now,", "tokens": [407, 264, 2141, 551, 281, 1604, 307, 562, 291, 3625, 7172, 307, 281, 360, 309, 365, 8240, 8240, 4195, 13, 823, 11], "temperature": 0.0, "avg_logprob": -0.2781644548688616, "compression_ratio": 1.3846153846153846, "no_speech_prob": 2.02603655452549e-06}, {"id": 18, "seek": 10536, "start": 115.84, "end": 123.36, "text": " in order to make that easier, I think what I would be inclined to do would be to edit our", "tokens": [294, 1668, 281, 652, 300, 3571, 11, 286, 519, 437, 286, 576, 312, 28173, 281, 360, 576, 312, 281, 8129, 527], "temperature": 0.0, "avg_logprob": -0.2781644548688616, "compression_ratio": 1.3846153846153846, "no_speech_prob": 2.02603655452549e-06}, {"id": 19, "seek": 12336, "start": 123.36, "end": 141.68, "text": " slash storage slash dot bash dot local and add to it alias, let's do PI for PIP install equals PIP", "tokens": [17330, 6725, 17330, 5893, 46183, 5893, 2654, 293, 909, 281, 309, 419, 4609, 11, 718, 311, 360, 27176, 337, 430, 9139, 3625, 6915, 430, 9139], "temperature": 0.0, "avg_logprob": -0.1915889519911546, "compression_ratio": 1.4074074074074074, "no_speech_prob": 3.966931217291858e-06}, {"id": 20, "seek": 12336, "start": 142.64, "end": 151.12, "text": " install. Let's do minus U for upgrade. That should work even if it's not installed already.", "tokens": [3625, 13, 961, 311, 360, 3175, 624, 337, 11484, 13, 663, 820, 589, 754, 498, 309, 311, 406, 8899, 1217, 13], "temperature": 0.0, "avg_logprob": -0.1915889519911546, "compression_ratio": 1.4074074074074074, "no_speech_prob": 3.966931217291858e-06}, {"id": 21, "seek": 15112, "start": 151.12, "end": 160.96, "text": " Minus minus user. Okay. Now, if I, so I could close and reopen my terminal or I could just", "tokens": [2829, 301, 3175, 4195, 13, 1033, 13, 823, 11, 498, 286, 11, 370, 286, 727, 1998, 293, 33861, 452, 14709, 420, 286, 727, 445], "temperature": 0.0, "avg_logprob": -0.26798605617088606, "compression_ratio": 1.507936507936508, "no_speech_prob": 3.90545028494671e-06}, {"id": 22, "seek": 15112, "start": 160.96, "end": 165.52, "text": " type source and then the name of the script, which of course in this case is exclamation mark dollar.", "tokens": [2010, 4009, 293, 550, 264, 1315, 295, 264, 5755, 11, 597, 295, 1164, 294, 341, 1389, 307, 1624, 43233, 1491, 7241, 13], "temperature": 0.0, "avg_logprob": -0.26798605617088606, "compression_ratio": 1.507936507936508, "no_speech_prob": 3.90545028494671e-06}, {"id": 23, "seek": 15112, "start": 166.88, "end": 172.48000000000002, "text": " Whoopsie-daisy. Exclamation mark vim will rerun this. This whole thing needs to be in quotes", "tokens": [45263, 414, 12, 67, 1527, 88, 13, 2111, 41411, 1491, 371, 332, 486, 43819, 409, 341, 13, 639, 1379, 551, 2203, 281, 312, 294, 19963], "temperature": 0.0, "avg_logprob": -0.26798605617088606, "compression_ratio": 1.507936507936508, "no_speech_prob": 3.90545028494671e-06}, {"id": 24, "seek": 17248, "start": 172.48, "end": 184.56, "text": " because it's a single thing. It's my alias. Okay. Up arrow twice. Okay. So now I can just type PI.", "tokens": [570, 309, 311, 257, 2167, 551, 13, 467, 311, 452, 419, 4609, 13, 1033, 13, 5858, 11610, 6091, 13, 1033, 13, 407, 586, 286, 393, 445, 2010, 27176, 13], "temperature": 0.0, "avg_logprob": -0.15432462692260743, "compression_ratio": 1.3591549295774648, "no_speech_prob": 1.873863425316813e-06}, {"id": 25, "seek": 17248, "start": 186.23999999999998, "end": 196.0, "text": " And by the way, if you want to know what something is, if you type which PI, it won't tell you", "tokens": [400, 538, 264, 636, 11, 498, 291, 528, 281, 458, 437, 746, 307, 11, 498, 291, 2010, 597, 27176, 11, 309, 1582, 380, 980, 291], "temperature": 0.0, "avg_logprob": -0.15432462692260743, "compression_ratio": 1.3591549295774648, "no_speech_prob": 1.873863425316813e-06}, {"id": 26, "seek": 19600, "start": 196.0, "end": 202.96, "text": " anything useful because it's an alias, not a binary. But if you type, type PI, it will tell", "tokens": [1340, 4420, 570, 309, 311, 364, 419, 4609, 11, 406, 257, 17434, 13, 583, 498, 291, 2010, 11, 2010, 27176, 11, 309, 486, 980], "temperature": 0.0, "avg_logprob": -0.12187618213695484, "compression_ratio": 1.6294416243654823, "no_speech_prob": 3.689868606215896e-07}, {"id": 27, "seek": 19600, "start": 202.96, "end": 209.2, "text": " you exactly what it is in this case. Oh, it's something that's an alias. So I can type PI, Tim.", "tokens": [291, 2293, 437, 309, 307, 294, 341, 1389, 13, 876, 11, 309, 311, 746, 300, 311, 364, 419, 4609, 13, 407, 286, 393, 2010, 27176, 11, 7172, 13], "temperature": 0.0, "avg_logprob": -0.12187618213695484, "compression_ratio": 1.6294416243654823, "no_speech_prob": 3.689868606215896e-07}, {"id": 28, "seek": 19600, "start": 212.08, "end": 217.28, "text": " And the key thing about minus minus user is that's going to put it in my dash dash local directory.", "tokens": [400, 264, 2141, 551, 466, 3175, 3175, 4195, 307, 300, 311, 516, 281, 829, 309, 294, 452, 8240, 8240, 2654, 21120, 13], "temperature": 0.0, "avg_logprob": -0.12187618213695484, "compression_ratio": 1.6294416243654823, "no_speech_prob": 3.689868606215896e-07}, {"id": 29, "seek": 21728, "start": 217.28, "end": 231.52, "text": " Sorry, my dot local directory. So there it is, Tim. So then all you need to make sure is that", "tokens": [4919, 11, 452, 5893, 2654, 21120, 13, 407, 456, 309, 307, 11, 7172, 13, 407, 550, 439, 291, 643, 281, 652, 988, 307, 300], "temperature": 0.0, "avg_logprob": -0.24320980072021484, "compression_ratio": 1.4148148148148147, "no_speech_prob": 1.9637825516838348e-06}, {"id": 30, "seek": 21728, "start": 233.44, "end": 243.28, "text": " your local directory is SIM linked to dot slash storage config local. Oh, now that's interesting.", "tokens": [428, 2654, 21120, 307, 24738, 9408, 281, 5893, 17330, 6725, 6662, 2654, 13, 876, 11, 586, 300, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.24320980072021484, "compression_ratio": 1.4148148148148147, "no_speech_prob": 1.9637825516838348e-06}, {"id": 31, "seek": 24328, "start": 243.28, "end": 249.28, "text": " Our this is here is telling us we've got a broken SIM link. So that's what that means. Yeah.", "tokens": [2621, 341, 307, 510, 307, 3585, 505, 321, 600, 658, 257, 5463, 24738, 2113, 13, 407, 300, 311, 437, 300, 1355, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.1826169307415302, "compression_ratio": 1.4029850746268657, "no_speech_prob": 1.0952603588521015e-05}, {"id": 32, "seek": 24328, "start": 249.28, "end": 262.56, "text": " Dot get config is SIM linked to slash storage. But there is no dot get config there. So I might", "tokens": [38753, 483, 6662, 307, 24738, 9408, 281, 17330, 6725, 13, 583, 456, 307, 572, 5893, 483, 6662, 456, 13, 407, 286, 1062], "temperature": 0.0, "avg_logprob": -0.1826169307415302, "compression_ratio": 1.4029850746268657, "no_speech_prob": 1.0952603588521015e-05}, {"id": 33, "seek": 26256, "start": 262.56, "end": 275.68, "text": " have maybe forgot to move that or something. So that's okay. Next time we try to commit,", "tokens": [362, 1310, 5298, 281, 1286, 300, 420, 746, 13, 407, 300, 311, 1392, 13, 3087, 565, 321, 853, 281, 5599, 11], "temperature": 0.0, "avg_logprob": -0.08556024334098719, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.438977834477555e-06}, {"id": 34, "seek": 26256, "start": 275.68, "end": 285.84000000000003, "text": " it'll tell us and we'll know to fix that then. To create a file that's empty, you just use touch.", "tokens": [309, 603, 980, 505, 293, 321, 603, 458, 281, 3191, 300, 550, 13, 1407, 1884, 257, 3991, 300, 311, 6707, 11, 291, 445, 764, 2557, 13], "temperature": 0.0, "avg_logprob": -0.08556024334098719, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.438977834477555e-06}, {"id": 35, "seek": 26256, "start": 285.84000000000003, "end": 292.16, "text": " So I'm just going to go ahead and create an empty file. So at least it exists and then things won't", "tokens": [407, 286, 478, 445, 516, 281, 352, 2286, 293, 1884, 364, 6707, 3991, 13, 407, 412, 1935, 309, 8198, 293, 550, 721, 1582, 380], "temperature": 0.0, "avg_logprob": -0.08556024334098719, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.438977834477555e-06}, {"id": 36, "seek": 29216, "start": 292.16, "end": 307.04, "text": " get horribly confused. Did I not touch it correctly? Slash storage slash dot get config.", "tokens": [483, 45028, 9019, 13, 2589, 286, 406, 2557, 309, 8944, 30, 6187, 1299, 6725, 17330, 5893, 483, 6662, 13], "temperature": 0.0, "avg_logprob": -0.10234529253036256, "compression_ratio": 1.483221476510067, "no_speech_prob": 2.295896592841018e-06}, {"id": 37, "seek": 29216, "start": 309.52000000000004, "end": 316.48, "text": " Oh, there's a slash at the end. Oh, that's why. That's why it's confused. So", "tokens": [876, 11, 456, 311, 257, 17330, 412, 264, 917, 13, 876, 11, 300, 311, 983, 13, 663, 311, 983, 309, 311, 9019, 13, 407], "temperature": 0.0, "avg_logprob": -0.10234529253036256, "compression_ratio": 1.483221476510067, "no_speech_prob": 2.295896592841018e-06}, {"id": 38, "seek": 31648, "start": 316.48, "end": 326.08000000000004, "text": " that would be a directory, but this is not a directory. So my guess is that there's a bug in", "tokens": [300, 576, 312, 257, 21120, 11, 457, 341, 307, 406, 257, 21120, 13, 407, 452, 2041, 307, 300, 456, 311, 257, 7426, 294], "temperature": 0.0, "avg_logprob": -0.19004106521606445, "compression_ratio": 1.4148148148148147, "no_speech_prob": 2.947911752926302e-06}, {"id": 39, "seek": 31648, "start": 326.08000000000004, "end": 334.0, "text": " our pre run script for dot get config. Yes, I've got a slash at the end. So that's why that didn't", "tokens": [527, 659, 1190, 5755, 337, 5893, 483, 6662, 13, 1079, 11, 286, 600, 658, 257, 17330, 412, 264, 917, 13, 407, 300, 311, 983, 300, 994, 380], "temperature": 0.0, "avg_logprob": -0.19004106521606445, "compression_ratio": 1.4148148148148147, "no_speech_prob": 2.947911752926302e-06}, {"id": 40, "seek": 33400, "start": 334.0, "end": 363.92, "text": " work. So if I source that, now it's happy. Great. So now, yeah, so now since it's been installed,", "tokens": [589, 13, 407, 498, 286, 4009, 300, 11, 586, 309, 311, 2055, 13, 3769, 13, 407, 586, 11, 1338, 11, 370, 586, 1670, 309, 311, 668, 8899, 11], "temperature": 0.0, "avg_logprob": -0.2249477505683899, "compression_ratio": 1.1149425287356323, "no_speech_prob": 6.338740604405757e-06}, {"id": 41, "seek": 36392, "start": 363.92, "end": 373.04, "text": " it's available. And if I run ipython, we can confirm it did install. That should be all good.", "tokens": [309, 311, 2435, 13, 400, 498, 286, 1190, 28501, 88, 11943, 11, 321, 393, 9064, 309, 630, 3625, 13, 663, 820, 312, 439, 665, 13], "temperature": 0.0, "avg_logprob": -0.20714029899010292, "compression_ratio": 1.51440329218107, "no_speech_prob": 3.882767123286612e-05}, {"id": 42, "seek": 36392, "start": 373.04, "end": 379.04, "text": " Does that answer that part of the question, Matt? Yes, thank you. So then the second one,", "tokens": [4402, 300, 1867, 300, 644, 295, 264, 1168, 11, 7397, 30, 1079, 11, 1309, 291, 13, 407, 550, 264, 1150, 472, 11], "temperature": 0.0, "avg_logprob": -0.20714029899010292, "compression_ratio": 1.51440329218107, "no_speech_prob": 3.882767123286612e-05}, {"id": 43, "seek": 36392, "start": 379.04, "end": 384.88, "text": " yeah, it was not a question, but a comment, which is about Kaggle. So yeah, when I get back to", "tokens": [1338, 11, 309, 390, 406, 257, 1168, 11, 457, 257, 2871, 11, 597, 307, 466, 48751, 22631, 13, 407, 1338, 11, 562, 286, 483, 646, 281], "temperature": 0.0, "avg_logprob": -0.20714029899010292, "compression_ratio": 1.51440329218107, "no_speech_prob": 3.882767123286612e-05}, {"id": 44, "seek": 36392, "start": 384.88, "end": 391.52000000000004, "text": " using Kaggle on this machine, we will do that for sure. Which will probably be next time.", "tokens": [1228, 48751, 22631, 322, 341, 3479, 11, 321, 486, 360, 300, 337, 988, 13, 3013, 486, 1391, 312, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.20714029899010292, "compression_ratio": 1.51440329218107, "no_speech_prob": 3.882767123286612e-05}, {"id": 45, "seek": 39152, "start": 391.52, "end": 400.56, "text": " And you also had a question about jumping around to, you know, the end of a string, for example.", "tokens": [400, 291, 611, 632, 257, 1168, 466, 11233, 926, 281, 11, 291, 458, 11, 264, 917, 295, 257, 6798, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.23250746726989746, "compression_ratio": 1.2608695652173914, "no_speech_prob": 5.594080903392751e-06}, {"id": 46, "seek": 39152, "start": 404.4, "end": 404.71999999999997, "text": " Which...", "tokens": [3013, 485], "temperature": 0.0, "avg_logprob": -0.23250746726989746, "compression_ratio": 1.2608695652173914, "no_speech_prob": 5.594080903392751e-06}, {"id": 47, "seek": 40472, "start": 404.72, "end": 417.36, "text": " Which... Let's grab the fast AI repo, for example.", "tokens": [50364, 3013, 485, 961, 311, 4444, 264, 2370, 7318, 49040, 11, 337, 1365, 13, 50996], "temperature": 0.0, "avg_logprob": -0.8926249146461487, "compression_ratio": 0.8620689655172413, "no_speech_prob": 8.396559678658377e-06}, {"id": 48, "seek": 43472, "start": 434.72, "end": 459.36, "text": " Oh, and you also had a question about loading and serving models. Great.", "tokens": [50364, 876, 11, 293, 291, 611, 632, 257, 1168, 466, 15114, 293, 8148, 5245, 13, 3769, 13, 51596], "temperature": 0.0, "avg_logprob": -0.26627417614585475, "compression_ratio": 0.9863013698630136, "no_speech_prob": 0.008564280346035957}, {"id": 49, "seek": 46472, "start": 464.72, "end": 486.8, "text": " So, I mean, one thing obviously is it'd be nice to have a tags file.", "tokens": [407, 11, 286, 914, 11, 472, 551, 2745, 307, 309, 1116, 312, 1481, 281, 362, 257, 18632, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1608208634636619, "compression_ratio": 1.24, "no_speech_prob": 0.008311184123158455}, {"id": 50, "seek": 46472, "start": 489.44000000000005, "end": 492.8, "text": " At some point, we could even talk about how to set up Vim to automatically create that", "tokens": [1711, 512, 935, 11, 321, 727, 754, 751, 466, 577, 281, 992, 493, 691, 332, 281, 6772, 1884, 300], "temperature": 0.0, "avg_logprob": -0.1608208634636619, "compression_ratio": 1.24, "no_speech_prob": 0.008311184123158455}, {"id": 51, "seek": 49280, "start": 492.8, "end": 500.40000000000003, "text": " for us from time to time. But let's have a look at, I don't know, layers for example.", "tokens": [337, 505, 490, 565, 281, 565, 13, 583, 718, 311, 362, 257, 574, 412, 11, 286, 500, 380, 458, 11, 7914, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.2943431230691763, "compression_ratio": 1.2867132867132867, "no_speech_prob": 1.0952119737339672e-05}, {"id": 52, "seek": 49280, "start": 507.04, "end": 513.44, "text": " So, a few things to mention. The first is something which sounds very obscure, but actually isn't,", "tokens": [407, 11, 257, 1326, 721, 281, 2152, 13, 440, 700, 307, 746, 597, 3263, 588, 34443, 11, 457, 767, 1943, 380, 11], "temperature": 0.0, "avg_logprob": -0.2943431230691763, "compression_ratio": 1.2867132867132867, "no_speech_prob": 1.0952119737339672e-05}, {"id": 53, "seek": 51344, "start": 513.44, "end": 523.7600000000001, "text": " is F in Vim. F in Vim is like slash. Now slash searches. So we've seen it before. Slash,", "tokens": [307, 479, 294, 691, 332, 13, 479, 294, 691, 332, 307, 411, 17330, 13, 823, 17330, 26701, 13, 407, 321, 600, 1612, 309, 949, 13, 6187, 1299, 11], "temperature": 0.0, "avg_logprob": -0.23422068641299293, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.473787324357545e-05}, {"id": 54, "seek": 51344, "start": 523.7600000000001, "end": 529.44, "text": " in it. We'll search for the next thing called in it. Okay. Oh, maybe something we haven't discussed", "tokens": [294, 309, 13, 492, 603, 3164, 337, 264, 958, 551, 1219, 294, 309, 13, 1033, 13, 876, 11, 1310, 746, 321, 2378, 380, 7152], "temperature": 0.0, "avg_logprob": -0.23422068641299293, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.473787324357545e-05}, {"id": 55, "seek": 51344, "start": 529.44, "end": 534.48, "text": " is to go back to where we were, regardless of whether it was a tag or a search or anything.", "tokens": [307, 281, 352, 646, 281, 689, 321, 645, 11, 10060, 295, 1968, 309, 390, 257, 6162, 420, 257, 3164, 420, 1340, 13], "temperature": 0.0, "avg_logprob": -0.23422068641299293, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.473787324357545e-05}, {"id": 56, "seek": 51344, "start": 534.48, "end": 541.7600000000001, "text": " It's control O. And right next to control O is the letter I, which goes forward again.", "tokens": [467, 311, 1969, 422, 13, 400, 558, 958, 281, 1969, 422, 307, 264, 5063, 286, 11, 597, 1709, 2128, 797, 13], "temperature": 0.0, "avg_logprob": -0.23422068641299293, "compression_ratio": 1.6238938053097345, "no_speech_prob": 1.473787324357545e-05}, {"id": 57, "seek": 54176, "start": 541.76, "end": 546.88, "text": " Okay. So control O and control I go kind of, it's like pressing the back button and the forward", "tokens": [1033, 13, 407, 1969, 422, 293, 1969, 286, 352, 733, 295, 11, 309, 311, 411, 12417, 264, 646, 2960, 293, 264, 2128], "temperature": 0.0, "avg_logprob": -0.19954103455507666, "compression_ratio": 1.8178438661710037, "no_speech_prob": 1.2218627489346545e-05}, {"id": 58, "seek": 54176, "start": 546.88, "end": 552.3199999999999, "text": " button on your browser. There's something a lot like slash, but which just finds a single letter,", "tokens": [2960, 322, 428, 11185, 13, 821, 311, 746, 257, 688, 411, 17330, 11, 457, 597, 445, 10704, 257, 2167, 5063, 11], "temperature": 0.0, "avg_logprob": -0.19954103455507666, "compression_ratio": 1.8178438661710037, "no_speech_prob": 1.2218627489346545e-05}, {"id": 59, "seek": 54176, "start": 552.3199999999999, "end": 556.64, "text": " which is F. If I type F, it's going to, and it's under search on the current line. It'll search on", "tokens": [597, 307, 479, 13, 759, 286, 2010, 479, 11, 309, 311, 516, 281, 11, 293, 309, 311, 833, 3164, 322, 264, 2190, 1622, 13, 467, 603, 3164, 322], "temperature": 0.0, "avg_logprob": -0.19954103455507666, "compression_ratio": 1.8178438661710037, "no_speech_prob": 1.2218627489346545e-05}, {"id": 60, "seek": 54176, "start": 556.64, "end": 562.8, "text": " this line for the next thing I type. So if I type F double quote, actually maybe more interesting", "tokens": [341, 1622, 337, 264, 958, 551, 286, 2010, 13, 407, 498, 286, 2010, 479, 3834, 6513, 11, 767, 1310, 544, 1880], "temperature": 0.0, "avg_logprob": -0.19954103455507666, "compression_ratio": 1.8178438661710037, "no_speech_prob": 1.2218627489346545e-05}, {"id": 61, "seek": 54176, "start": 562.8, "end": 569.2, "text": " would be F full stop. So if I type F full stop, it's going to jump to the full stop. F dot. So you", "tokens": [576, 312, 479, 1577, 1590, 13, 407, 498, 286, 2010, 479, 1577, 1590, 11, 309, 311, 516, 281, 3012, 281, 264, 1577, 1590, 13, 479, 5893, 13, 407, 291], "temperature": 0.0, "avg_logprob": -0.19954103455507666, "compression_ratio": 1.8178438661710037, "no_speech_prob": 1.2218627489346545e-05}, {"id": 62, "seek": 56920, "start": 569.2, "end": 574.5600000000001, "text": " see it jumps to the full stop. Right. And so your question was, well, what about jumping to the end", "tokens": [536, 309, 16704, 281, 264, 1577, 1590, 13, 1779, 13, 400, 370, 428, 1168, 390, 11, 731, 11, 437, 466, 11233, 281, 264, 917], "temperature": 0.0, "avg_logprob": -0.17015795988195082, "compression_ratio": 1.5824742268041236, "no_speech_prob": 1.4063166418054607e-05}, {"id": 63, "seek": 56920, "start": 574.5600000000001, "end": 579.9200000000001, "text": " of a string? Now, obviously in this case, the end of a string is the last character of the line. So", "tokens": [295, 257, 6798, 30, 823, 11, 2745, 294, 341, 1389, 11, 264, 917, 295, 257, 6798, 307, 264, 1036, 2517, 295, 264, 1622, 13, 407], "temperature": 0.0, "avg_logprob": -0.17015795988195082, "compression_ratio": 1.5824742268041236, "no_speech_prob": 1.4063166418054607e-05}, {"id": 64, "seek": 56920, "start": 579.9200000000001, "end": 584.1600000000001, "text": " there's a better answer, which is to start inserting at the end of the line. It's shift A.", "tokens": [456, 311, 257, 1101, 1867, 11, 597, 307, 281, 722, 46567, 412, 264, 917, 295, 264, 1622, 13, 467, 311, 5513, 316, 13], "temperature": 0.0, "avg_logprob": -0.17015795988195082, "compression_ratio": 1.5824742268041236, "no_speech_prob": 1.4063166418054607e-05}, {"id": 65, "seek": 58416, "start": 584.16, "end": 597.4399999999999, "text": " Just one moment.", "tokens": [50364, 1449, 472, 1623, 13, 51028], "temperature": 0.0, "avg_logprob": -0.7119494165693011, "compression_ratio": 0.6666666666666666, "no_speech_prob": 7.592275505885482e-05}, {"id": 66, "seek": 61416, "start": 614.56, "end": 625.68, "text": " My daughter's got kicked off her zoom call. Always technical problems. Okay. So I can undo that.", "tokens": [1222, 4653, 311, 658, 14609, 766, 720, 8863, 818, 13, 11270, 6191, 2740, 13, 1033, 13, 407, 286, 393, 23779, 300, 13], "temperature": 0.0, "avg_logprob": -0.17692823899097931, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.004609103314578533}, {"id": 67, "seek": 61416, "start": 626.8, "end": 634.88, "text": " Control O to go back to where I was. But yeah, so let's say there was some stuff at the end,", "tokens": [12912, 422, 281, 352, 646, 281, 689, 286, 390, 13, 583, 1338, 11, 370, 718, 311, 584, 456, 390, 512, 1507, 412, 264, 917, 11], "temperature": 0.0, "avg_logprob": -0.17692823899097931, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.004609103314578533}, {"id": 68, "seek": 61416, "start": 634.88, "end": 642.3199999999999, "text": " hash some comment. Right. And we wanted to, yeah, we wanted to go to the next double quote.", "tokens": [22019, 512, 2871, 13, 1779, 13, 400, 321, 1415, 281, 11, 1338, 11, 321, 1415, 281, 352, 281, 264, 958, 3834, 6513, 13], "temperature": 0.0, "avg_logprob": -0.17692823899097931, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.004609103314578533}, {"id": 69, "seek": 64232, "start": 642.32, "end": 648.72, "text": " I can just type F double quote and it takes me there. And then shift F does the opposite.", "tokens": [286, 393, 445, 2010, 479, 3834, 6513, 293, 309, 2516, 385, 456, 13, 400, 550, 5513, 479, 775, 264, 6182, 13], "temperature": 0.0, "avg_logprob": -0.16034053166707357, "compression_ratio": 1.6278026905829597, "no_speech_prob": 8.139600140566472e-06}, {"id": 70, "seek": 64232, "start": 648.72, "end": 654.5600000000001, "text": " It searches backwards. And the reason it's interesting mainly is that that's emotion.", "tokens": [467, 26701, 12204, 13, 400, 264, 1778, 309, 311, 1880, 8704, 307, 300, 300, 311, 8913, 13], "temperature": 0.0, "avg_logprob": -0.16034053166707357, "compression_ratio": 1.6278026905829597, "no_speech_prob": 8.139600140566472e-06}, {"id": 71, "seek": 64232, "start": 654.5600000000001, "end": 659.6800000000001, "text": " And therefore I can combine things with it. So for example, if I wanted to delete everything", "tokens": [400, 4412, 286, 393, 10432, 721, 365, 309, 13, 407, 337, 1365, 11, 498, 286, 1415, 281, 12097, 1203], "temperature": 0.0, "avg_logprob": -0.16034053166707357, "compression_ratio": 1.6278026905829597, "no_speech_prob": 8.139600140566472e-06}, {"id": 72, "seek": 64232, "start": 659.6800000000001, "end": 666.0, "text": " up to the next quote, I can press D F double quote. Right. And then I could press slash double", "tokens": [493, 281, 264, 958, 6513, 11, 286, 393, 1886, 413, 479, 3834, 6513, 13, 1779, 13, 400, 550, 286, 727, 1886, 17330, 3834], "temperature": 0.0, "avg_logprob": -0.16034053166707357, "compression_ratio": 1.6278026905829597, "no_speech_prob": 8.139600140566472e-06}, {"id": 73, "seek": 66600, "start": 666.0, "end": 673.36, "text": " quote to search the next one and press dot and it'll do the same thing again. Right. Or maybe", "tokens": [6513, 281, 3164, 264, 958, 472, 293, 1886, 5893, 293, 309, 603, 360, 264, 912, 551, 797, 13, 1779, 13, 1610, 1310], "temperature": 0.0, "avg_logprob": -0.14319590999655527, "compression_ratio": 1.5052083333333333, "no_speech_prob": 3.1875481454335386e-06}, {"id": 74, "seek": 66600, "start": 673.36, "end": 683.28, "text": " delete everything up to the next comment would be D F hash. So yeah, those are a couple of useful", "tokens": [12097, 1203, 493, 281, 264, 958, 2871, 576, 312, 413, 479, 22019, 13, 407, 1338, 11, 729, 366, 257, 1916, 295, 4420], "temperature": 0.0, "avg_logprob": -0.14319590999655527, "compression_ratio": 1.5052083333333333, "no_speech_prob": 3.1875481454335386e-06}, {"id": 75, "seek": 66600, "start": 683.28, "end": 692.48, "text": " things. Another really useful one is percent. Percent jumps to between the start and the end of a", "tokens": [721, 13, 3996, 534, 4420, 472, 307, 3043, 13, 3026, 2207, 16704, 281, 1296, 264, 722, 293, 264, 917, 295, 257], "temperature": 0.0, "avg_logprob": -0.14319590999655527, "compression_ratio": 1.5052083333333333, "no_speech_prob": 3.1875481454335386e-06}, {"id": 76, "seek": 69248, "start": 692.48, "end": 699.52, "text": " of a set of paired parentheses or braces or brackets. So if I press percent here,", "tokens": [295, 257, 992, 295, 25699, 34153, 420, 41537, 420, 26179, 13, 407, 498, 286, 1886, 3043, 510, 11], "temperature": 0.0, "avg_logprob": -0.12624871848833444, "compression_ratio": 1.87434554973822, "no_speech_prob": 2.026122729148483e-06}, {"id": 77, "seek": 69248, "start": 700.48, "end": 704.5600000000001, "text": " it goes to the start, it goes to the start of end of the next parentheses and then press it again.", "tokens": [309, 1709, 281, 264, 722, 11, 309, 1709, 281, 264, 722, 295, 917, 295, 264, 958, 34153, 293, 550, 1886, 309, 797, 13], "temperature": 0.0, "avg_logprob": -0.12624871848833444, "compression_ratio": 1.87434554973822, "no_speech_prob": 2.026122729148483e-06}, {"id": 78, "seek": 69248, "start": 704.5600000000001, "end": 709.12, "text": " You can see it jumps between the two. Right. And so if I do it from here,", "tokens": [509, 393, 536, 309, 16704, 1296, 264, 732, 13, 1779, 13, 400, 370, 498, 286, 360, 309, 490, 510, 11], "temperature": 0.0, "avg_logprob": -0.12624871848833444, "compression_ratio": 1.87434554973822, "no_speech_prob": 2.026122729148483e-06}, {"id": 79, "seek": 69248, "start": 710.8000000000001, "end": 716.48, "text": " you can see it jumps to the end of this one. Right. If I do it at the very end, it'll jump to this one.", "tokens": [291, 393, 536, 309, 16704, 281, 264, 917, 295, 341, 472, 13, 1779, 13, 759, 286, 360, 309, 412, 264, 588, 917, 11, 309, 603, 3012, 281, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.12624871848833444, "compression_ratio": 1.87434554973822, "no_speech_prob": 2.026122729148483e-06}, {"id": 80, "seek": 71648, "start": 716.48, "end": 721.2, "text": " So if I want to delete from here to the end of the parenthesized parenthetical expression,", "tokens": [407, 498, 286, 528, 281, 12097, 490, 510, 281, 264, 917, 295, 264, 23350, 279, 1602, 23350, 27800, 6114, 11], "temperature": 0.0, "avg_logprob": -0.2772973378499349, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.637779056793079e-06}, {"id": 81, "seek": 71648, "start": 722.4, "end": 732.4, "text": " let's say to delete this bit, I could press D F sorry, D F percent. Sorry, not D F percent,", "tokens": [718, 311, 584, 281, 12097, 341, 857, 11, 286, 727, 1886, 413, 479, 2597, 11, 413, 479, 3043, 13, 4919, 11, 406, 413, 479, 3043, 11], "temperature": 0.0, "avg_logprob": -0.2772973378499349, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.637779056793079e-06}, {"id": 82, "seek": 71648, "start": 732.4, "end": 739.76, "text": " just D percent. There you go. D percent. You see. Although there's actually something even better", "tokens": [445, 413, 3043, 13, 821, 291, 352, 13, 413, 3043, 13, 509, 536, 13, 5780, 456, 311, 767, 746, 754, 1101], "temperature": 0.0, "avg_logprob": -0.2772973378499349, "compression_ratio": 1.5555555555555556, "no_speech_prob": 4.637779056793079e-06}, {"id": 83, "seek": 73976, "start": 739.76, "end": 752.48, "text": " for that, which is I and I is refers to an area, the whole area that is surrounded by some kind of", "tokens": [337, 300, 11, 597, 307, 286, 293, 286, 307, 14942, 281, 364, 1859, 11, 264, 1379, 1859, 300, 307, 13221, 538, 512, 733, 295], "temperature": 0.0, "avg_logprob": -0.15244859059651691, "compression_ratio": 1.608695652173913, "no_speech_prob": 5.0935932449647225e-06}, {"id": 84, "seek": 73976, "start": 752.48, "end": 758.64, "text": " parentheses. So even when I'm in the middle of these, this these parentheses, the the enclosing", "tokens": [34153, 13, 407, 754, 562, 286, 478, 294, 264, 2808, 295, 613, 11, 341, 613, 34153, 11, 264, 264, 20987, 6110], "temperature": 0.0, "avg_logprob": -0.15244859059651691, "compression_ratio": 1.608695652173913, "no_speech_prob": 5.0935932449647225e-06}, {"id": 85, "seek": 73976, "start": 758.64, "end": 764.88, "text": " parentheses would go from here to here. And so I stands for inside. So if I want to delete everything", "tokens": [34153, 576, 352, 490, 510, 281, 510, 13, 400, 370, 286, 7382, 337, 1854, 13, 407, 498, 286, 528, 281, 12097, 1203], "temperature": 0.0, "avg_logprob": -0.15244859059651691, "compression_ratio": 1.608695652173913, "no_speech_prob": 5.0935932449647225e-06}, {"id": 86, "seek": 76488, "start": 764.88, "end": 773.2, "text": " inside those parentheses, I can type D I open round, do it again, D I open round parentheses", "tokens": [1854, 729, 34153, 11, 286, 393, 2010, 413, 286, 1269, 3098, 11, 360, 309, 797, 11, 413, 286, 1269, 3098, 34153], "temperature": 0.0, "avg_logprob": -0.252852480176469, "compression_ratio": 1.5573770491803278, "no_speech_prob": 2.332034682694939e-06}, {"id": 87, "seek": 76488, "start": 773.2, "end": 779.84, "text": " and it deletes the contents, which is really nice. So let's say I wanted to like replace all my", "tokens": [293, 309, 1103, 37996, 264, 15768, 11, 597, 307, 534, 1481, 13, 407, 718, 311, 584, 286, 1415, 281, 411, 7406, 439, 452], "temperature": 0.0, "avg_logprob": -0.252852480176469, "compression_ratio": 1.5573770491803278, "no_speech_prob": 2.332034682694939e-06}, {"id": 88, "seek": 76488, "start": 779.84, "end": 788.32, "text": " parameters with something else like A comma B, then I would use C for change inside parentheses.", "tokens": [9834, 365, 746, 1646, 411, 316, 22117, 363, 11, 550, 286, 576, 764, 383, 337, 1319, 1854, 34153, 13], "temperature": 0.0, "avg_logprob": -0.252852480176469, "compression_ratio": 1.5573770491803278, "no_speech_prob": 2.332034682694939e-06}, {"id": 89, "seek": 78832, "start": 788.32, "end": 797.84, "text": " I would type my change like A comma B, right. And then I can come down here and type dot", "tokens": [286, 576, 2010, 452, 1319, 411, 316, 22117, 363, 11, 558, 13, 400, 550, 286, 393, 808, 760, 510, 293, 2010, 5893], "temperature": 0.0, "avg_logprob": -0.1617675271145133, "compression_ratio": 1.4924623115577889, "no_speech_prob": 1.209856463901815e-06}, {"id": 90, "seek": 78832, "start": 799.36, "end": 806.48, "text": " and it will do the same thing. So, yeah, it's like maybe your work you can kind of really", "tokens": [293, 309, 486, 360, 264, 912, 551, 13, 407, 11, 1338, 11, 309, 311, 411, 1310, 428, 589, 291, 393, 733, 295, 534], "temperature": 0.0, "avg_logprob": -0.1617675271145133, "compression_ratio": 1.4924623115577889, "no_speech_prob": 1.209856463901815e-06}, {"id": 91, "seek": 78832, "start": 807.44, "end": 809.0400000000001, "text": " crush with these tricks.", "tokens": [10321, 365, 613, 11733, 13], "temperature": 0.0, "avg_logprob": -0.1617675271145133, "compression_ratio": 1.4924623115577889, "no_speech_prob": 1.209856463901815e-06}, {"id": 92, "seek": 78832, "start": 812.72, "end": 818.0, "text": " Great. Fantastic. Yeah, it's cool. There's a lot of them and you don't have to know them all.", "tokens": [3769, 13, 21320, 13, 865, 11, 309, 311, 1627, 13, 821, 311, 257, 688, 295, 552, 293, 291, 500, 380, 362, 281, 458, 552, 439, 13], "temperature": 0.0, "avg_logprob": -0.1617675271145133, "compression_ratio": 1.4924623115577889, "no_speech_prob": 1.209856463901815e-06}, {"id": 93, "seek": 81800, "start": 818.0, "end": 820.72, "text": " You know, it's like you can learn one thing each day or something.", "tokens": [509, 458, 11, 309, 311, 411, 291, 393, 1466, 472, 551, 1184, 786, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.11640922321992762, "compression_ratio": 1.5142857142857142, "no_speech_prob": 1.1478227861516643e-05}, {"id": 94, "seek": 81800, "start": 822.08, "end": 825.2, "text": " Yeah, I'm not using any plugins or anything, you know.", "tokens": [865, 11, 286, 478, 406, 1228, 604, 33759, 420, 1340, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.11640922321992762, "compression_ratio": 1.5142857142857142, "no_speech_prob": 1.1478227861516643e-05}, {"id": 95, "seek": 81800, "start": 833.52, "end": 838.4, "text": " Okay, so we're going to save a model in a moment. Any other questions or comments before I go back", "tokens": [1033, 11, 370, 321, 434, 516, 281, 3155, 257, 2316, 294, 257, 1623, 13, 2639, 661, 1651, 420, 3053, 949, 286, 352, 646], "temperature": 0.0, "avg_logprob": -0.11640922321992762, "compression_ratio": 1.5142857142857142, "no_speech_prob": 1.1478227861516643e-05}, {"id": 96, "seek": 81800, "start": 838.4, "end": 845.84, "text": " to our notebook? I want to make one comment about the Tim installation. I don't know if maybe you", "tokens": [281, 527, 21060, 30, 286, 528, 281, 652, 472, 2871, 466, 264, 7172, 13260, 13, 286, 500, 380, 458, 498, 1310, 291], "temperature": 0.0, "avg_logprob": -0.11640922321992762, "compression_ratio": 1.5142857142857142, "no_speech_prob": 1.1478227861516643e-05}, {"id": 97, "seek": 84584, "start": 845.84, "end": 849.76, "text": " discussed this yesterday because I came a little late, but with the Tim installation,", "tokens": [7152, 341, 5186, 570, 286, 1361, 257, 707, 3469, 11, 457, 365, 264, 7172, 13260, 11], "temperature": 0.0, "avg_logprob": -0.11554194688796997, "compression_ratio": 1.631336405529954, "no_speech_prob": 9.367527127324138e-06}, {"id": 98, "seek": 84584, "start": 851.52, "end": 856.08, "text": " sometimes it might be better to install from master because there are some changes", "tokens": [2171, 309, 1062, 312, 1101, 281, 3625, 490, 4505, 570, 456, 366, 512, 2962], "temperature": 0.0, "avg_logprob": -0.11554194688796997, "compression_ratio": 1.631336405529954, "no_speech_prob": 9.367527127324138e-06}, {"id": 99, "seek": 84584, "start": 856.08, "end": 862.1600000000001, "text": " that Ross has made that you might not receive. Yeah, we did mention that yesterday. Actually,", "tokens": [300, 16140, 575, 1027, 300, 291, 1062, 406, 4774, 13, 865, 11, 321, 630, 2152, 300, 5186, 13, 5135, 11], "temperature": 0.0, "avg_logprob": -0.11554194688796997, "compression_ratio": 1.631336405529954, "no_speech_prob": 9.367527127324138e-06}, {"id": 100, "seek": 84584, "start": 862.1600000000001, "end": 870.08, "text": " I think the conclusion we came to was to install the latest pre-release because that's like", "tokens": [286, 519, 264, 10063, 321, 1361, 281, 390, 281, 3625, 264, 6792, 659, 12, 265, 1122, 570, 300, 311, 411], "temperature": 0.0, "avg_logprob": -0.11554194688796997, "compression_ratio": 1.631336405529954, "no_speech_prob": 9.367527127324138e-06}, {"id": 101, "seek": 87008, "start": 870.08, "end": 881.5200000000001, "text": " something that's more stable than installing from master, but you know, better than his.", "tokens": [746, 300, 311, 544, 8351, 813, 20762, 490, 4505, 11, 457, 291, 458, 11, 1101, 813, 702, 13], "temperature": 0.0, "avg_logprob": -0.16482433818635486, "compression_ratio": 1.4867724867724867, "no_speech_prob": 1.4061836736800615e-05}, {"id": 102, "seek": 87008, "start": 881.5200000000001, "end": 888.24, "text": " Sometimes, like here, he went six months without updating. So, yeah, I agree. In fact, so let's do", "tokens": [4803, 11, 411, 510, 11, 415, 1437, 2309, 2493, 1553, 25113, 13, 407, 11, 1338, 11, 286, 3986, 13, 682, 1186, 11, 370, 718, 311, 360], "temperature": 0.0, "avg_logprob": -0.16482433818635486, "compression_ratio": 1.4867724867724867, "no_speech_prob": 1.4061836736800615e-05}, {"id": 103, "seek": 87008, "start": 888.24, "end": 896.1600000000001, "text": " that. So, this is 0.6.2 dev. So, I think we decided that we'd go, let's use our new PI thing.", "tokens": [300, 13, 407, 11, 341, 307, 1958, 13, 21, 13, 17, 1905, 13, 407, 11, 286, 519, 321, 3047, 300, 321, 1116, 352, 11, 718, 311, 764, 527, 777, 27176, 551, 13], "temperature": 0.0, "avg_logprob": -0.16482433818635486, "compression_ratio": 1.4867724867724867, "no_speech_prob": 1.4061836736800615e-05}, {"id": 104, "seek": 89616, "start": 896.16, "end": 903.76, "text": " Tim is greater than or equal to 0.6.2 dev.", "tokens": [7172, 307, 5044, 813, 420, 2681, 281, 1958, 13, 21, 13, 17, 1905, 13], "temperature": 0.0, "avg_logprob": -0.47342581748962403, "compression_ratio": 1.1263157894736842, "no_speech_prob": 3.822256257990375e-05}, {"id": 105, "seek": 89616, "start": 906.9599999999999, "end": 909.76, "text": " Great. Yeah, thanks for the reminder, Tanisha.", "tokens": [3769, 13, 865, 11, 3231, 337, 264, 13548, 11, 314, 7524, 64, 13], "temperature": 0.0, "avg_logprob": -0.47342581748962403, "compression_ratio": 1.1263157894736842, "no_speech_prob": 3.822256257990375e-05}, {"id": 106, "seek": 89616, "start": 914.8, "end": 916.8, "text": " All right, great.", "tokens": [1057, 558, 11, 869, 13], "temperature": 0.0, "avg_logprob": -0.47342581748962403, "compression_ratio": 1.1263157894736842, "no_speech_prob": 3.822256257990375e-05}, {"id": 107, "seek": 91680, "start": 916.8, "end": 928.24, "text": " All right, great. It's kind of this thing in Python modules and quite a lot of other things.", "tokens": [1057, 558, 11, 869, 13, 467, 311, 733, 295, 341, 551, 294, 15329, 16679, 293, 1596, 257, 688, 295, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.11647614137625989, "compression_ratio": 1.4512820512820512, "no_speech_prob": 1.209836455018376e-06}, {"id": 108, "seek": 91680, "start": 928.24, "end": 935.12, "text": " If there's like an extra.dev at the end, that means it's a pre-release, basically. So, pip has", "tokens": [759, 456, 311, 411, 364, 2857, 2411, 40343, 412, 264, 917, 11, 300, 1355, 309, 311, 257, 659, 12, 265, 1122, 11, 1936, 13, 407, 11, 8489, 575], "temperature": 0.0, "avg_logprob": -0.11647614137625989, "compression_ratio": 1.4512820512820512, "no_speech_prob": 1.209836455018376e-06}, {"id": 109, "seek": 91680, "start": 935.12, "end": 945.92, "text": " this convention that if you say I want to install something that is at least as recent as 0.6.2", "tokens": [341, 10286, 300, 498, 291, 584, 286, 528, 281, 3625, 746, 300, 307, 412, 1935, 382, 5162, 382, 1958, 13, 21, 13, 17], "temperature": 0.0, "avg_logprob": -0.11647614137625989, "compression_ratio": 1.4512820512820512, "no_speech_prob": 1.209836455018376e-06}, {"id": 110, "seek": 94592, "start": 945.92, "end": 951.92, "text": " dev, then that's a way of signaling to pip that you're happy to include pre-release options.", "tokens": [1905, 11, 550, 300, 311, 257, 636, 295, 38639, 281, 8489, 300, 291, 434, 2055, 281, 4090, 659, 12, 265, 1122, 3956, 13], "temperature": 0.0, "avg_logprob": -0.09004076417670193, "compression_ratio": 1.626865671641791, "no_speech_prob": 4.157249804848107e-06}, {"id": 111, "seek": 94592, "start": 953.5999999999999, "end": 962.88, "text": " Is there any reason that when you do the installation of Tim and then you try to use the", "tokens": [1119, 456, 604, 1778, 300, 562, 291, 360, 264, 13260, 295, 7172, 293, 550, 291, 853, 281, 764, 264], "temperature": 0.0, "avg_logprob": -0.09004076417670193, "compression_ratio": 1.626865671641791, "no_speech_prob": 4.157249804848107e-06}, {"id": 112, "seek": 94592, "start": 962.88, "end": 968.7199999999999, "text": " learner, it says that Tim doesn't exist when you try to load the model.", "tokens": [33347, 11, 309, 1619, 300, 7172, 1177, 380, 2514, 562, 291, 853, 281, 3677, 264, 2316, 13], "temperature": 0.0, "avg_logprob": -0.09004076417670193, "compression_ratio": 1.626865671641791, "no_speech_prob": 4.157249804848107e-06}, {"id": 113, "seek": 96872, "start": 968.72, "end": 976.96, "text": " Right. That's because you have to restart the kernel after installing it. So, now that it's", "tokens": [1779, 13, 663, 311, 570, 291, 362, 281, 21022, 264, 28256, 934, 20762, 309, 13, 407, 11, 586, 300, 309, 311], "temperature": 0.0, "avg_logprob": -0.1532251070130546, "compression_ratio": 1.3868613138686132, "no_speech_prob": 4.425187853485113e-06}, {"id": 114, "seek": 96872, "start": 976.96, "end": 981.44, "text": " installed in.local every time I start a machine, it's going to be there anyway. So, you won't have", "tokens": [8899, 294, 2411, 5842, 304, 633, 565, 286, 722, 257, 3479, 11, 309, 311, 516, 281, 312, 456, 4033, 13, 407, 11, 291, 1582, 380, 362], "temperature": 0.0, "avg_logprob": -0.1532251070130546, "compression_ratio": 1.3868613138686132, "no_speech_prob": 4.425187853485113e-06}, {"id": 115, "seek": 98144, "start": 981.44, "end": 1001.6800000000001, "text": " to worry about that again. Okay. So, this was our notebook from yesterday.", "tokens": [281, 3292, 466, 300, 797, 13, 1033, 13, 407, 11, 341, 390, 527, 21060, 490, 5186, 13], "temperature": 0.0, "avg_logprob": -0.11848883401779901, "compression_ratio": 1.0, "no_speech_prob": 2.72620150099101e-06}, {"id": 116, "seek": 100168, "start": 1001.68, "end": 1009.28, "text": " And I wanted to try and improve the model. And one of the reasons I wanted to try to improve the model", "tokens": [400, 286, 1415, 281, 853, 293, 3470, 264, 2316, 13, 400, 472, 295, 264, 4112, 286, 1415, 281, 853, 281, 3470, 264, 2316], "temperature": 0.0, "avg_logprob": -0.32596600309331364, "compression_ratio": 1.4830508474576272, "no_speech_prob": 1.2288803645787993e-06}, {"id": 117, "seek": 100168, "start": 1010.2399999999999, "end": 1027.76, "text": " is because our result was worse than the top 50%. There you go, top 50%.", "tokens": [307, 570, 527, 1874, 390, 5324, 813, 264, 1192, 2625, 6856, 821, 291, 352, 11, 1192, 2625, 6856], "temperature": 0.0, "avg_logprob": -0.32596600309331364, "compression_ratio": 1.4830508474576272, "no_speech_prob": 1.2288803645787993e-06}, {"id": 118, "seek": 102776, "start": 1027.76, "end": 1041.76, "text": " I didn't know that was a tip. That's handy. And so, we should, you know, I want to aim to at least", "tokens": [286, 994, 380, 458, 300, 390, 257, 4125, 13, 663, 311, 13239, 13, 400, 370, 11, 321, 820, 11, 291, 458, 11, 286, 528, 281, 5939, 281, 412, 1935], "temperature": 0.0, "avg_logprob": -0.17160002938632307, "compression_ratio": 1.2661870503597121, "no_speech_prob": 3.288637117293547e-06}, {"id": 119, "seek": 102776, "start": 1044.24, "end": 1051.6, "text": " be as good as this helpful fast AI out of the box person. So, they got.97385.", "tokens": [312, 382, 665, 382, 341, 4961, 2370, 7318, 484, 295, 264, 2424, 954, 13, 407, 11, 436, 658, 2411, 23247, 12625, 20, 13], "temperature": 0.0, "avg_logprob": -0.17160002938632307, "compression_ratio": 1.2661870503597121, "no_speech_prob": 3.288637117293547e-06}, {"id": 120, "seek": 105160, "start": 1051.6, "end": 1064.48, "text": " How far off are we? That was me. That was my number. Fantastic. I like it. It's a good notebook.", "tokens": [1012, 1400, 766, 366, 321, 30, 663, 390, 385, 13, 663, 390, 452, 1230, 13, 21320, 13, 286, 411, 309, 13, 467, 311, 257, 665, 21060, 13], "temperature": 0.0, "avg_logprob": -0.16342855870038614, "compression_ratio": 1.5104166666666667, "no_speech_prob": 2.318298902537208e-05}, {"id": 121, "seek": 105160, "start": 1064.48, "end": 1068.0, "text": " So, we're going to try to beat you. I hope you don't mind. But then you'll know how to beat us.", "tokens": [407, 11, 321, 434, 516, 281, 853, 281, 4224, 291, 13, 286, 1454, 291, 500, 380, 1575, 13, 583, 550, 291, 603, 458, 577, 281, 4224, 505, 13], "temperature": 0.0, "avg_logprob": -0.16342855870038614, "compression_ratio": 1.5104166666666667, "no_speech_prob": 2.318298902537208e-05}, {"id": 122, "seek": 105160, "start": 1068.0, "end": 1080.6399999999999, "text": " Because at least you know how to match us. So, yeah. I saw that what you did here was you trained", "tokens": [1436, 412, 1935, 291, 458, 577, 281, 2995, 505, 13, 407, 11, 1338, 13, 286, 1866, 300, 437, 291, 630, 510, 390, 291, 8895], "temperature": 0.0, "avg_logprob": -0.16342855870038614, "compression_ratio": 1.5104166666666667, "no_speech_prob": 2.318298902537208e-05}, {"id": 123, "seek": 108064, "start": 1080.64, "end": 1088.5600000000002, "text": " for longer, which makes sense. And you also used some data augmentation, which makes sense. So,", "tokens": [337, 2854, 11, 597, 1669, 2020, 13, 400, 291, 611, 1143, 512, 1412, 14501, 19631, 11, 597, 1669, 2020, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.17702705477490838, "compression_ratio": 1.5027624309392265, "no_speech_prob": 8.46651746542193e-05}, {"id": 124, "seek": 108064, "start": 1089.2800000000002, "end": 1099.2800000000002, "text": " let's talk about this. So, if we're going to train for, so, what's your name? Gerardo, is it", "tokens": [718, 311, 751, 466, 341, 13, 407, 11, 498, 321, 434, 516, 281, 3847, 337, 11, 370, 11, 437, 311, 428, 1315, 30, 9409, 12850, 11, 307, 309], "temperature": 0.0, "avg_logprob": -0.17702705477490838, "compression_ratio": 1.5027624309392265, "no_speech_prob": 8.46651746542193e-05}, {"id": 125, "seek": 108064, "start": 1101.0400000000002, "end": 1107.76, "text": " Gerardo or Gerardo? Either way, that's fine. Which is right. I want to be accurate.", "tokens": [9409, 12850, 420, 9409, 12850, 30, 13746, 636, 11, 300, 311, 2489, 13, 3013, 307, 558, 13, 286, 528, 281, 312, 8559, 13], "temperature": 0.0, "avg_logprob": -0.17702705477490838, "compression_ratio": 1.5027624309392265, "no_speech_prob": 8.46651746542193e-05}, {"id": 126, "seek": 110776, "start": 1107.76, "end": 1110.8799999999999, "text": " Gerardo. My name is Gerardo. In Spanish, it's Gerardo.", "tokens": [9409, 12850, 13, 1222, 1315, 307, 9409, 12850, 13, 682, 8058, 11, 309, 311, 9409, 12850, 13], "temperature": 0.0, "avg_logprob": -0.16937074065208435, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.593873695237562e-05}, {"id": 127, "seek": 110776, "start": 1110.8799999999999, "end": 1117.12, "text": " I see. So, both are right. No worries. Thank you, Gerardo. Okay. So, if we're going to train", "tokens": [286, 536, 13, 407, 11, 1293, 366, 558, 13, 883, 16340, 13, 1044, 291, 11, 9409, 12850, 13, 1033, 13, 407, 11, 498, 321, 434, 516, 281, 3847], "temperature": 0.0, "avg_logprob": -0.16937074065208435, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.593873695237562e-05}, {"id": 128, "seek": 110776, "start": 1117.12, "end": 1123.6, "text": " as long as Gerardo did, then, you know, if you train more than about five epochs, you're in danger", "tokens": [382, 938, 382, 9409, 12850, 630, 11, 550, 11, 291, 458, 11, 498, 291, 3847, 544, 813, 466, 1732, 30992, 28346, 11, 291, 434, 294, 4330], "temperature": 0.0, "avg_logprob": -0.16937074065208435, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.593873695237562e-05}, {"id": 129, "seek": 110776, "start": 1123.6, "end": 1129.36, "text": " of overfitting. And certainly 10, I feel like you're in significant danger of overfitting.", "tokens": [295, 670, 69, 2414, 13, 400, 3297, 1266, 11, 286, 841, 411, 291, 434, 294, 4776, 4330, 295, 670, 69, 2414, 13], "temperature": 0.0, "avg_logprob": -0.16937074065208435, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.593873695237562e-05}, {"id": 130, "seek": 110776, "start": 1129.36, "end": 1135.52, "text": " Because your model's going to have seen every image, you know, 10 times. So, in order to avoid", "tokens": [1436, 428, 2316, 311, 516, 281, 362, 1612, 633, 3256, 11, 291, 458, 11, 1266, 1413, 13, 407, 11, 294, 1668, 281, 5042], "temperature": 0.0, "avg_logprob": -0.16937074065208435, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.593873695237562e-05}, {"id": 131, "seek": 113552, "start": 1135.52, "end": 1140.16, "text": " overfitting to the specific images it's seeing, we should make it so that it sees a slightly", "tokens": [670, 69, 2414, 281, 264, 2685, 5267, 309, 311, 2577, 11, 321, 820, 652, 309, 370, 300, 309, 8194, 257, 4748], "temperature": 0.0, "avg_logprob": -0.06303002617575905, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.593499291629996e-05}, {"id": 132, "seek": 113552, "start": 1140.16, "end": 1154.4, "text": " different image each time. And this is discussed in the book in some detail. But basically,", "tokens": [819, 3256, 1184, 565, 13, 400, 341, 307, 7152, 294, 264, 1446, 294, 512, 2607, 13, 583, 1936, 11], "temperature": 0.0, "avg_logprob": -0.06303002617575905, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.593499291629996e-05}, {"id": 133, "seek": 113552, "start": 1155.28, "end": 1159.04, "text": " if you pass in batch transforms, these are things that are going to be applied to each", "tokens": [498, 291, 1320, 294, 15245, 35592, 11, 613, 366, 721, 300, 366, 516, 281, 312, 6456, 281, 1184], "temperature": 0.0, "avg_logprob": -0.06303002617575905, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.593499291629996e-05}, {"id": 134, "seek": 115904, "start": 1159.04, "end": 1166.6399999999999, "text": " mini batch. So, to each bunch of however many, 32 or 64 or whatever images. And this is basically", "tokens": [8382, 15245, 13, 407, 11, 281, 1184, 3840, 295, 4461, 867, 11, 8858, 420, 12145, 420, 2035, 5267, 13, 400, 341, 307, 1936], "temperature": 0.0, "avg_logprob": -0.10492911338806152, "compression_ratio": 1.6504424778761062, "no_speech_prob": 2.014367601077538e-05}, {"id": 135, "seek": 115904, "start": 1166.6399999999999, "end": 1172.1599999999999, "text": " a bunch of functions that are going to be applied. So, what does this function do? Org transforms.", "tokens": [257, 3840, 295, 6828, 300, 366, 516, 281, 312, 6456, 13, 407, 11, 437, 775, 341, 2445, 360, 30, 1610, 70, 35592, 13], "temperature": 0.0, "avg_logprob": -0.10492911338806152, "compression_ratio": 1.6504424778761062, "no_speech_prob": 2.014367601077538e-05}, {"id": 136, "seek": 115904, "start": 1172.1599999999999, "end": 1177.36, "text": " So, this is transforms for data augmentation. So, we know that the best way to find out what", "tokens": [407, 11, 341, 307, 35592, 337, 1412, 14501, 19631, 13, 407, 11, 321, 458, 300, 264, 1151, 636, 281, 915, 484, 437], "temperature": 0.0, "avg_logprob": -0.10492911338806152, "compression_ratio": 1.6504424778761062, "no_speech_prob": 2.014367601077538e-05}, {"id": 137, "seek": 117736, "start": 1177.36, "end": 1190.3999999999999, "text": " something's going to do is to check its help. So, let's start there. Not help, doc. Okay, so,", "tokens": [746, 311, 516, 281, 360, 307, 281, 1520, 1080, 854, 13, 407, 11, 718, 311, 722, 456, 13, 1726, 854, 11, 3211, 13, 1033, 11, 370, 11], "temperature": 0.0, "avg_logprob": -0.10892004436916775, "compression_ratio": 1.4242424242424243, "no_speech_prob": 9.665659490565304e-06}, {"id": 138, "seek": 117736, "start": 1192.24, "end": 1198.08, "text": " it's going to do things like flip our images, rotate them, zoom them, change their brightness,", "tokens": [309, 311, 516, 281, 360, 721, 411, 7929, 527, 5267, 11, 13121, 552, 11, 8863, 552, 11, 1319, 641, 21367, 11], "temperature": 0.0, "avg_logprob": -0.10892004436916775, "compression_ratio": 1.4242424242424243, "no_speech_prob": 9.665659490565304e-06}, {"id": 139, "seek": 119808, "start": 1198.08, "end": 1209.4399999999998, "text": " their warp. Let's see, show in docs. Okay, and here's some examples of a very cute puppy that", "tokens": [641, 36030, 13, 961, 311, 536, 11, 855, 294, 45623, 13, 1033, 11, 293, 510, 311, 512, 5110, 295, 257, 588, 4052, 18196, 300], "temperature": 0.0, "avg_logprob": -0.16285311258756197, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.2029019671899732e-05}, {"id": 140, "seek": 119808, "start": 1209.4399999999998, "end": 1215.1999999999998, "text": " Sylvia found. I think Sylvia found it. So, this is all the same puppy, it's all the same picture.", "tokens": [33349, 11617, 1352, 13, 286, 519, 33349, 11617, 1352, 309, 13, 407, 11, 341, 307, 439, 264, 912, 18196, 11, 309, 311, 439, 264, 912, 3036, 13], "temperature": 0.0, "avg_logprob": -0.16285311258756197, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.2029019671899732e-05}, {"id": 141, "seek": 119808, "start": 1215.1999999999998, "end": 1221.76, "text": " And as you can see, each time the model sees it, it sees a somewhat skewed or rotated or brightened", "tokens": [400, 382, 291, 393, 536, 11, 1184, 565, 264, 2316, 8194, 309, 11, 309, 8194, 257, 8344, 8756, 26896, 420, 42146, 420, 4730, 5320], "temperature": 0.0, "avg_logprob": -0.16285311258756197, "compression_ratio": 1.6977777777777778, "no_speech_prob": 1.2029019671899732e-05}, {"id": 142, "seek": 122176, "start": 1221.76, "end": 1229.04, "text": " or darkened or whatever version of that picture. And so, this is called data augmentation.", "tokens": [420, 2877, 5320, 420, 2035, 3037, 295, 300, 3036, 13, 400, 370, 11, 341, 307, 1219, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.1580646832784017, "compression_ratio": 1.3571428571428572, "no_speech_prob": 2.2603071556659415e-06}, {"id": 143, "seek": 122176, "start": 1232.08, "end": 1246.32, "text": " So, let's try then running that. And so, org transforms actually returns a list,", "tokens": [407, 11, 718, 311, 853, 550, 2614, 300, 13, 400, 370, 11, 14045, 35592, 767, 11247, 257, 1329, 11], "temperature": 0.0, "avg_logprob": -0.1580646832784017, "compression_ratio": 1.3571428571428572, "no_speech_prob": 2.2603071556659415e-06}, {"id": 144, "seek": 124632, "start": 1246.32, "end": 1253.36, "text": " right? It returns a list of transformations. So, here's the flip transformation with a", "tokens": [558, 30, 467, 11247, 257, 1329, 295, 34852, 13, 407, 11, 510, 311, 264, 7929, 9887, 365, 257], "temperature": 0.0, "avg_logprob": -0.1899568117581881, "compression_ratio": 1.6431924882629108, "no_speech_prob": 2.857302206393797e-06}, {"id": 145, "seek": 124632, "start": 1253.36, "end": 1260.56, "text": " probability of 0.5, it'll flip. It's got a brightness transformation with a probability", "tokens": [8482, 295, 1958, 13, 20, 11, 309, 603, 7929, 13, 467, 311, 658, 257, 21367, 9887, 365, 257, 8482], "temperature": 0.0, "avg_logprob": -0.1899568117581881, "compression_ratio": 1.6431924882629108, "no_speech_prob": 2.857302206393797e-06}, {"id": 146, "seek": 124632, "start": 1260.56, "end": 1269.12, "text": " of 1, it will change the lighting by up to 0.2. And then random resized crop is perhaps", "tokens": [295, 502, 11, 309, 486, 1319, 264, 9577, 538, 493, 281, 1958, 13, 17, 13, 400, 550, 4974, 725, 1602, 9086, 307, 4317], "temperature": 0.0, "avg_logprob": -0.1899568117581881, "compression_ratio": 1.6431924882629108, "no_speech_prob": 2.857302206393797e-06}, {"id": 147, "seek": 124632, "start": 1269.12, "end": 1274.6399999999999, "text": " the most interesting one, which is it will zoom in such that it has at least 75% of the", "tokens": [264, 881, 1880, 472, 11, 597, 307, 309, 486, 8863, 294, 1270, 300, 309, 575, 412, 1935, 9562, 4, 295, 264], "temperature": 0.0, "avg_logprob": -0.1899568117581881, "compression_ratio": 1.6431924882629108, "no_speech_prob": 2.857302206393797e-06}, {"id": 148, "seek": 127464, "start": 1274.64, "end": 1285.5200000000002, "text": " height width and it will basically pick a smaller zoomed in section randomly chosen each time.", "tokens": [6681, 11402, 293, 309, 486, 1936, 1888, 257, 4356, 8863, 292, 294, 3541, 16979, 8614, 1184, 565, 13], "temperature": 0.0, "avg_logprob": -0.13601414529900802, "compression_ratio": 1.7534883720930232, "no_speech_prob": 5.771837550128112e-06}, {"id": 149, "seek": 127464, "start": 1286.88, "end": 1292.24, "text": " So, what we can do is when we say show batch, if you say unique equals true, it'll show the same", "tokens": [407, 11, 437, 321, 393, 360, 307, 562, 321, 584, 855, 15245, 11, 498, 291, 584, 3845, 6915, 2074, 11, 309, 603, 855, 264, 912], "temperature": 0.0, "avg_logprob": -0.13601414529900802, "compression_ratio": 1.7534883720930232, "no_speech_prob": 5.771837550128112e-06}, {"id": 150, "seek": 127464, "start": 1292.24, "end": 1296.96, "text": " picture each time. And so, here you can see four versions of the same picture. You can see", "tokens": [3036, 1184, 565, 13, 400, 370, 11, 510, 291, 393, 536, 1451, 9606, 295, 264, 912, 3036, 13, 509, 393, 536], "temperature": 0.0, "avg_logprob": -0.13601414529900802, "compression_ratio": 1.7534883720930232, "no_speech_prob": 5.771837550128112e-06}, {"id": 151, "seek": 127464, "start": 1296.96, "end": 1301.6000000000001, "text": " sometimes it's flipped, sometimes it's moved a little bit up and down, sometimes it's a little", "tokens": [2171, 309, 311, 26273, 11, 2171, 309, 311, 4259, 257, 707, 857, 493, 293, 760, 11, 2171, 309, 311, 257, 707], "temperature": 0.0, "avg_logprob": -0.13601414529900802, "compression_ratio": 1.7534883720930232, "no_speech_prob": 5.771837550128112e-06}, {"id": 152, "seek": 130160, "start": 1301.6, "end": 1309.28, "text": " bit darker or less dark and it's also a little bit rotated. So, that's what data augmentation is and", "tokens": [857, 12741, 420, 1570, 2877, 293, 309, 311, 611, 257, 707, 857, 42146, 13, 407, 11, 300, 311, 437, 1412, 14501, 19631, 307, 293], "temperature": 0.0, "avg_logprob": -0.1307155704498291, "compression_ratio": 1.540983606557377, "no_speech_prob": 5.6823273553163745e-06}, {"id": 153, "seek": 130160, "start": 1309.28, "end": 1315.4399999999998, "text": " that really helps us if we want to train a few more epochs. Then the second thing I figured we", "tokens": [300, 534, 3665, 505, 498, 321, 528, 281, 3847, 257, 1326, 544, 30992, 28346, 13, 1396, 264, 1150, 551, 286, 8932, 321], "temperature": 0.0, "avg_logprob": -0.1307155704498291, "compression_ratio": 1.540983606557377, "no_speech_prob": 5.6823273553163745e-06}, {"id": 154, "seek": 130160, "start": 1315.4399999999998, "end": 1324.3999999999999, "text": " should do is, you know, ResNet's actually great, but there are things which are greater. And as we", "tokens": [820, 360, 307, 11, 291, 458, 11, 5015, 31890, 311, 767, 869, 11, 457, 456, 366, 721, 597, 366, 5044, 13, 400, 382, 321], "temperature": 0.0, "avg_logprob": -0.1307155704498291, "compression_ratio": 1.540983606557377, "no_speech_prob": 5.6823273553163745e-06}, {"id": 155, "seek": 130160, "start": 1324.3999999999999, "end": 1328.08, "text": " talked about, Tim has a bunch of them and in particular, ConvNext is pretty good.", "tokens": [2825, 466, 11, 7172, 575, 257, 3840, 295, 552, 293, 294, 1729, 11, 2656, 85, 31002, 307, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.1307155704498291, "compression_ratio": 1.540983606557377, "no_speech_prob": 5.6823273553163745e-06}, {"id": 156, "seek": 132808, "start": 1328.08, "end": 1334.24, "text": " And the other thing, you know, we could do is think about learning rates. The default learning", "tokens": [400, 264, 661, 551, 11, 291, 458, 11, 321, 727, 360, 307, 519, 466, 2539, 6846, 13, 440, 7576, 2539], "temperature": 0.0, "avg_logprob": -0.2671454885731573, "compression_ratio": 1.8274509803921568, "no_speech_prob": 2.9942893888801336e-06}, {"id": 157, "seek": 132808, "start": 1334.24, "end": 1339.84, "text": " rate used by Fast.ai is one where I would say I picked it on the conservative side,", "tokens": [3314, 1143, 538, 15968, 13, 1301, 307, 472, 689, 286, 576, 584, 286, 6183, 309, 322, 264, 13780, 1252, 11], "temperature": 0.0, "avg_logprob": -0.2671454885731573, "compression_ratio": 1.8274509803921568, "no_speech_prob": 2.9942893888801336e-06}, {"id": 158, "seek": 132808, "start": 1339.84, "end": 1345.76, "text": " which means it's a little bit lower than you probably need because I wanted things to always", "tokens": [597, 1355, 309, 311, 257, 707, 857, 3126, 813, 291, 1391, 643, 570, 286, 1415, 721, 281, 1009], "temperature": 0.0, "avg_logprob": -0.2671454885731573, "compression_ratio": 1.8274509803921568, "no_speech_prob": 2.9942893888801336e-06}, {"id": 159, "seek": 132808, "start": 1345.76, "end": 1353.04, "text": " be able to train. But there's actually a downside to using a couple of downsides to using a lower", "tokens": [312, 1075, 281, 3847, 13, 583, 456, 311, 767, 257, 25060, 281, 1228, 257, 1916, 295, 21554, 1875, 281, 1228, 257, 3126], "temperature": 0.0, "avg_logprob": -0.2671454885731573, "compression_ratio": 1.8274509803921568, "no_speech_prob": 2.9942893888801336e-06}, {"id": 160, "seek": 132808, "start": 1353.04, "end": 1357.04, "text": " learning rate than you need. The first is that, you know, if you're using a lower learning rate,", "tokens": [2539, 3314, 813, 291, 643, 13, 440, 700, 307, 300, 11, 291, 458, 11, 498, 291, 434, 1228, 257, 3126, 2539, 3314, 11], "temperature": 0.0, "avg_logprob": -0.2671454885731573, "compression_ratio": 1.8274509803921568, "no_speech_prob": 2.9942893888801336e-06}, {"id": 161, "seek": 135704, "start": 1357.04, "end": 1365.92, "text": " the first is that given fixed resources, fixed amount of time, you're going to have less epochs,", "tokens": [264, 700, 307, 300, 2212, 6806, 3593, 11, 6806, 2372, 295, 565, 11, 291, 434, 516, 281, 362, 1570, 30992, 28346, 11], "temperature": 0.0, "avg_logprob": -0.09037441526140486, "compression_ratio": 1.540983606557377, "no_speech_prob": 1.9333060663484503e-06}, {"id": 162, "seek": 135704, "start": 1365.92, "end": 1372.8, "text": " not less epochs, sorry, less distance that the weights can move. The second is, it turns out,", "tokens": [406, 1570, 30992, 28346, 11, 2597, 11, 1570, 4560, 300, 264, 17443, 393, 1286, 13, 440, 1150, 307, 11, 309, 4523, 484, 11], "temperature": 0.0, "avg_logprob": -0.09037441526140486, "compression_ratio": 1.540983606557377, "no_speech_prob": 1.9333060663484503e-06}, {"id": 163, "seek": 135704, "start": 1372.8, "end": 1380.8, "text": " a high learning rate helps the optimizer to explore the space of options by jumping further", "tokens": [257, 1090, 2539, 3314, 3665, 264, 5028, 6545, 281, 6839, 264, 1901, 295, 3956, 538, 11233, 3052], "temperature": 0.0, "avg_logprob": -0.09037441526140486, "compression_ratio": 1.540983606557377, "no_speech_prob": 1.9333060663484503e-06}, {"id": 164, "seek": 138080, "start": 1380.8, "end": 1389.68, "text": " to see if there's better places to go. So the learning rate finder is suggesting things around", "tokens": [281, 536, 498, 456, 311, 1101, 3190, 281, 352, 13, 407, 264, 2539, 3314, 915, 260, 307, 18094, 721, 926], "temperature": 0.0, "avg_logprob": -0.1406612777709961, "compression_ratio": 1.4894736842105263, "no_speech_prob": 3.187488346156897e-06}, {"id": 165, "seek": 138080, "start": 1389.68, "end": 1398.08, "text": " about 0.002, which is indeed the default. But you can see that all the way up to like 10 to the", "tokens": [466, 1958, 13, 628, 17, 11, 597, 307, 6451, 264, 7576, 13, 583, 291, 393, 536, 300, 439, 264, 636, 493, 281, 411, 1266, 281, 264], "temperature": 0.0, "avg_logprob": -0.1406612777709961, "compression_ratio": 1.4894736842105263, "no_speech_prob": 3.187488346156897e-06}, {"id": 166, "seek": 138080, "start": 1398.08, "end": 1403.76, "text": " negative 2, it still looks like a pretty nice slope. And the other thing to remember is, you", "tokens": [3671, 568, 11, 309, 920, 1542, 411, 257, 1238, 1481, 13525, 13, 400, 264, 661, 551, 281, 1604, 307, 11, 291], "temperature": 0.0, "avg_logprob": -0.1406612777709961, "compression_ratio": 1.4894736842105263, "no_speech_prob": 3.187488346156897e-06}, {"id": 167, "seek": 140376, "start": 1403.76, "end": 1411.12, "text": " know, as we saw after answering Nick's question yesterday, we're using one cycle training schedule,", "tokens": [458, 11, 382, 321, 1866, 934, 13430, 9449, 311, 1168, 5186, 11, 321, 434, 1228, 472, 6586, 3097, 7567, 11], "temperature": 0.0, "avg_logprob": -0.08033195408907803, "compression_ratio": 1.5916666666666666, "no_speech_prob": 2.156757773263962e-06}, {"id": 168, "seek": 140376, "start": 1411.12, "end": 1416.08, "text": " which means we're gradually increasing the learning rate. And my claim was that by doing that,", "tokens": [597, 1355, 321, 434, 13145, 5662, 264, 2539, 3314, 13, 400, 452, 3932, 390, 300, 538, 884, 300, 11], "temperature": 0.0, "avg_logprob": -0.08033195408907803, "compression_ratio": 1.5916666666666666, "no_speech_prob": 2.156757773263962e-06}, {"id": 169, "seek": 140376, "start": 1416.08, "end": 1421.68, "text": " we can reach higher learning rates. So I would also say that even these recommendations are", "tokens": [321, 393, 2524, 2946, 2539, 6846, 13, 407, 286, 576, 611, 584, 300, 754, 613, 10434, 366], "temperature": 0.0, "avg_logprob": -0.08033195408907803, "compression_ratio": 1.5916666666666666, "no_speech_prob": 2.156757773263962e-06}, {"id": 170, "seek": 140376, "start": 1421.68, "end": 1426.24, "text": " going to be a bit on the conservative side. So what I did just before I started this call was I", "tokens": [516, 281, 312, 257, 857, 322, 264, 13780, 1252, 13, 407, 437, 286, 630, 445, 949, 286, 1409, 341, 818, 390, 286], "temperature": 0.0, "avg_logprob": -0.08033195408907803, "compression_ratio": 1.5916666666666666, "no_speech_prob": 2.156757773263962e-06}, {"id": 171, "seek": 142624, "start": 1426.24, "end": 1439.28, "text": " tried training at a learning rate of 0.01, which is five times higher than the default. And so that's", "tokens": [3031, 3097, 412, 257, 2539, 3314, 295, 1958, 13, 10607, 11, 597, 307, 1732, 1413, 2946, 813, 264, 7576, 13, 400, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.09575259991181202, "compression_ratio": 1.4568527918781726, "no_speech_prob": 1.8738561493591988e-06}, {"id": 172, "seek": 142624, "start": 1439.28, "end": 1448.64, "text": " up here. And I did find actually that that did give us a quite a better result with a 2% error.", "tokens": [493, 510, 13, 400, 286, 630, 915, 767, 300, 300, 630, 976, 505, 257, 1596, 257, 1101, 1874, 365, 257, 568, 4, 6713, 13], "temperature": 0.0, "avg_logprob": -0.09575259991181202, "compression_ratio": 1.4568527918781726, "no_speech_prob": 1.8738561493591988e-06}, {"id": 173, "seek": 142624, "start": 1448.64, "end": 1452.96, "text": " So let's see, I mean, obviously, you've got different training sets, but this is hopeful,", "tokens": [407, 718, 311, 536, 11, 286, 914, 11, 2745, 11, 291, 600, 658, 819, 3097, 6352, 11, 457, 341, 307, 20531, 11], "temperature": 0.0, "avg_logprob": -0.09575259991181202, "compression_ratio": 1.4568527918781726, "no_speech_prob": 1.8738561493591988e-06}, {"id": 174, "seek": 145296, "start": 1452.96, "end": 1459.3600000000001, "text": " right, that we're going to get a better result than our target. It's nice to have a target aim for.", "tokens": [558, 11, 300, 321, 434, 516, 281, 483, 257, 1101, 1874, 813, 527, 3779, 13, 467, 311, 1481, 281, 362, 257, 3779, 5939, 337, 13], "temperature": 0.0, "avg_logprob": -0.16053697797987196, "compression_ratio": 1.5449735449735449, "no_speech_prob": 1.1910796047231997e-06}, {"id": 175, "seek": 145296, "start": 1461.92, "end": 1467.6000000000001, "text": " Okay, so that's that was the next thing. So then it's since this took, you know, six minutes to", "tokens": [1033, 11, 370, 300, 311, 300, 390, 264, 958, 551, 13, 407, 550, 309, 311, 1670, 341, 1890, 11, 291, 458, 11, 2309, 2077, 281], "temperature": 0.0, "avg_logprob": -0.16053697797987196, "compression_ratio": 1.5449735449735449, "no_speech_prob": 1.1910796047231997e-06}, {"id": 176, "seek": 145296, "start": 1467.6000000000001, "end": 1473.8400000000001, "text": " train, it's probably a good idea to save it. So there's a couple of different things we can save", "tokens": [3847, 11, 309, 311, 1391, 257, 665, 1558, 281, 3155, 309, 13, 407, 456, 311, 257, 1916, 295, 819, 721, 321, 393, 3155], "temperature": 0.0, "avg_logprob": -0.16053697797987196, "compression_ratio": 1.5449735449735449, "no_speech_prob": 1.1910796047231997e-06}, {"id": 177, "seek": 147384, "start": 1473.84, "end": 1489.28, "text": " with. One is dot save and the other is dot export. So learner dot export", "tokens": [365, 13, 1485, 307, 5893, 3155, 293, 264, 661, 307, 5893, 10725, 13, 407, 33347, 5893, 10725], "temperature": 0.0, "avg_logprob": -0.28638673383136126, "compression_ratio": 1.4695652173913043, "no_speech_prob": 2.482426452843356e-06}, {"id": 178, "seek": 147384, "start": 1492.6399999999999, "end": 1499.76, "text": " saves the contents, that's not very well written self, the learner self means that this learner,", "tokens": [19155, 264, 15768, 11, 300, 311, 406, 588, 731, 3720, 2698, 11, 264, 33347, 2698, 1355, 300, 341, 33347, 11], "temperature": 0.0, "avg_logprob": -0.28638673383136126, "compression_ratio": 1.4695652173913043, "no_speech_prob": 2.482426452843356e-06}, {"id": 179, "seek": 149976, "start": 1499.76, "end": 1507.12, "text": " and it saves it to self dot path slash FNAME, so learner dot path slash FNAME using pickle.", "tokens": [293, 309, 19155, 309, 281, 2698, 5893, 3100, 17330, 479, 45, 31296, 11, 370, 33347, 5893, 3100, 17330, 479, 45, 31296, 1228, 31433, 13], "temperature": 0.0, "avg_logprob": -0.3165832841900033, "compression_ratio": 1.6193548387096774, "no_speech_prob": 2.8129873044235865e-06}, {"id": 180, "seek": 149976, "start": 1511.2, "end": 1516.8, "text": " So basically, what that means is if you if you call this, learn dot export,", "tokens": [407, 1936, 11, 437, 300, 1355, 307, 498, 291, 498, 291, 818, 341, 11, 1466, 5893, 10725, 11], "temperature": 0.0, "avg_logprob": -0.3165832841900033, "compression_ratio": 1.6193548387096774, "no_speech_prob": 2.8129873044235865e-06}, {"id": 181, "seek": 149976, "start": 1518.32, "end": 1523.84, "text": " it's going to save it into learn dot path. So let's find out learn dot path is what", "tokens": [309, 311, 516, 281, 3155, 309, 666, 1466, 5893, 3100, 13, 407, 718, 311, 915, 484, 1466, 5893, 3100, 307, 437], "temperature": 0.0, "avg_logprob": -0.3165832841900033, "compression_ratio": 1.6193548387096774, "no_speech_prob": 2.8129873044235865e-06}, {"id": 182, "seek": 152384, "start": 1523.84, "end": 1536.1599999999999, "text": " train images. And so this is actually whatever we passed in here. So if we want to save things", "tokens": [3847, 5267, 13, 400, 370, 341, 307, 767, 2035, 321, 4678, 294, 510, 13, 407, 498, 321, 528, 281, 3155, 721], "temperature": 0.0, "avg_logprob": -0.1743467781278822, "compression_ratio": 1.5271739130434783, "no_speech_prob": 2.6015645744337235e-06}, {"id": 183, "seek": 152384, "start": 1536.1599999999999, "end": 1540.32, "text": " somewhere else, there's we've got a couple of options. One is to change learn dot path by", "tokens": [4079, 1646, 11, 456, 311, 321, 600, 658, 257, 1916, 295, 3956, 13, 1485, 307, 281, 1319, 1466, 5893, 3100, 538], "temperature": 0.0, "avg_logprob": -0.1743467781278822, "compression_ratio": 1.5271739130434783, "no_speech_prob": 2.6015645744337235e-06}, {"id": 184, "seek": 152384, "start": 1540.32, "end": 1548.0, "text": " setting it equal to some other path. Or we can just use an absolute path. So an absolute path is", "tokens": [3287, 309, 2681, 281, 512, 661, 3100, 13, 1610, 321, 393, 445, 764, 364, 8236, 3100, 13, 407, 364, 8236, 3100, 307], "temperature": 0.0, "avg_logprob": -0.1743467781278822, "compression_ratio": 1.5271739130434783, "no_speech_prob": 2.6015645744337235e-06}, {"id": 185, "seek": 154800, "start": 1548.0, "end": 1554.0, "text": " a path. So an absolute path is something that starts with slash. And so if I want to save it", "tokens": [257, 3100, 13, 407, 364, 8236, 3100, 307, 746, 300, 3719, 365, 17330, 13, 400, 370, 498, 286, 528, 281, 3155, 309], "temperature": 0.0, "avg_logprob": -0.11342322361933721, "compression_ratio": 1.6594594594594594, "no_speech_prob": 4.029257524962304e-06}, {"id": 186, "seek": 154800, "start": 1554.0, "end": 1562.48, "text": " somewhere in storage, for example, that I can type slash storage slash whatever. Or maybe I want to", "tokens": [4079, 294, 6725, 11, 337, 1365, 11, 300, 286, 393, 2010, 17330, 6725, 17330, 2035, 13, 1610, 1310, 286, 528, 281], "temperature": 0.0, "avg_logprob": -0.11342322361933721, "compression_ratio": 1.6594594594594594, "no_speech_prob": 4.029257524962304e-06}, {"id": 187, "seek": 154800, "start": 1562.48, "end": 1570.72, "text": " put it in slash notebooks somewhere. So these are the these are some ways you can change", "tokens": [829, 309, 294, 17330, 43782, 4079, 13, 407, 613, 366, 264, 613, 366, 512, 2098, 291, 393, 1319], "temperature": 0.0, "avg_logprob": -0.11342322361933721, "compression_ratio": 1.6594594594594594, "no_speech_prob": 4.029257524962304e-06}, {"id": 188, "seek": 157072, "start": 1570.72, "end": 1582.96, "text": " where it's going to save. I might even just put it into the current directory. I think that seems", "tokens": [689, 309, 311, 516, 281, 3155, 13, 286, 1062, 754, 445, 829, 309, 666, 264, 2190, 21120, 13, 286, 519, 300, 2544], "temperature": 0.0, "avg_logprob": -0.22407943797561358, "compression_ratio": 1.4202898550724639, "no_speech_prob": 1.8630948034115136e-05}, {"id": 189, "seek": 157072, "start": 1582.96, "end": 1592.48, "text": " fine to me. Well, actually, where are we current directory? Yeah, put it in git patty. That sounds", "tokens": [2489, 281, 385, 13, 1042, 11, 767, 11, 689, 366, 321, 2190, 21120, 30, 865, 11, 829, 309, 294, 18331, 1947, 874, 13, 663, 3263], "temperature": 0.0, "avg_logprob": -0.22407943797561358, "compression_ratio": 1.4202898550724639, "no_speech_prob": 1.8630948034115136e-05}, {"id": 190, "seek": 159248, "start": 1592.48, "end": 1601.28, "text": " fine. Or maybe to be a bit more sure just in case the directory ever changes.", "tokens": [2489, 13, 1610, 1310, 281, 312, 257, 857, 544, 988, 445, 294, 1389, 264, 21120, 1562, 2962, 13], "temperature": 0.0, "avg_logprob": -0.298266241285536, "compression_ratio": 1.4369747899159664, "no_speech_prob": 1.4367436733664363e-06}, {"id": 191, "seek": 159248, "start": 1604.08, "end": 1614.72, "text": " So then the other option is learn dot save. So learn dot save doesn't save the whole learner.", "tokens": [407, 550, 264, 661, 3614, 307, 1466, 5893, 3155, 13, 407, 1466, 5893, 3155, 1177, 380, 3155, 264, 1379, 33347, 13], "temperature": 0.0, "avg_logprob": -0.298266241285536, "compression_ratio": 1.4369747899159664, "no_speech_prob": 1.4367436733664363e-06}, {"id": 192, "seek": 161472, "start": 1614.72, "end": 1622.4, "text": " It just saves the model and the optimizer state. The difference is that remember a learner doesn't", "tokens": [467, 445, 19155, 264, 2316, 293, 264, 5028, 6545, 1785, 13, 440, 2649, 307, 300, 1604, 257, 33347, 1177, 380], "temperature": 0.0, "avg_logprob": -0.34925743841355844, "compression_ratio": 1.6352941176470588, "no_speech_prob": 7.571084097435232e-07}, {"id": 193, "seek": 161472, "start": 1622.4, "end": 1633.2, "text": " just contain the model, but it also contains it also contains information about the data loaders", "tokens": [445, 5304, 264, 2316, 11, 457, 309, 611, 8306, 309, 611, 8306, 1589, 466, 264, 1412, 3677, 433], "temperature": 0.0, "avg_logprob": -0.34925743841355844, "compression_ratio": 1.6352941176470588, "no_speech_prob": 7.571084097435232e-07}, {"id": 194, "seek": 161472, "start": 1633.2, "end": 1642.0, "text": " and specifically what transformations are applied. So I think that's a good point.", "tokens": [293, 4682, 437, 34852, 366, 6456, 13, 407, 286, 519, 300, 311, 257, 665, 935, 13], "temperature": 0.0, "avg_logprob": -0.34925743841355844, "compression_ratio": 1.6352941176470588, "no_speech_prob": 7.571084097435232e-07}, {"id": 195, "seek": 164200, "start": 1642.0, "end": 1652.56, "text": " So I don't really often, if ever, use dot save. The only reason I would use dot save is like if I was", "tokens": [407, 286, 500, 380, 534, 2049, 11, 498, 1562, 11, 764, 5893, 3155, 13, 440, 787, 1778, 286, 576, 764, 5893, 3155, 307, 411, 498, 286, 390], "temperature": 0.0, "avg_logprob": -0.19838122786762558, "compression_ratio": 1.6822033898305084, "no_speech_prob": 5.682308255927637e-06}, {"id": 196, "seek": 164200, "start": 1652.56, "end": 1658.24, "text": " writing something to like, and we already have stuff in fast.ai. Let's give an example. In fast.ai,", "tokens": [3579, 746, 281, 411, 11, 293, 321, 1217, 362, 1507, 294, 2370, 13, 1301, 13, 961, 311, 976, 364, 1365, 13, 682, 2370, 13, 1301, 11], "temperature": 0.0, "avg_logprob": -0.19838122786762558, "compression_ratio": 1.6822033898305084, "no_speech_prob": 5.682308255927637e-06}, {"id": 197, "seek": 164200, "start": 1658.24, "end": 1664.64, "text": " we have something that's a callback that can save the model at the end of each epoch or each time", "tokens": [321, 362, 746, 300, 311, 257, 818, 3207, 300, 393, 3155, 264, 2316, 412, 264, 917, 295, 1184, 30992, 339, 420, 1184, 565], "temperature": 0.0, "avg_logprob": -0.19838122786762558, "compression_ratio": 1.6822033898305084, "no_speech_prob": 5.682308255927637e-06}, {"id": 198, "seek": 164200, "start": 1664.64, "end": 1669.52, "text": " it gets a better result than its previous best or whatever. In those cases, we might use dot save", "tokens": [309, 2170, 257, 1101, 1874, 813, 1080, 3894, 1151, 420, 2035, 13, 682, 729, 3331, 11, 321, 1062, 764, 5893, 3155], "temperature": 0.0, "avg_logprob": -0.19838122786762558, "compression_ratio": 1.6822033898305084, "no_speech_prob": 5.682308255927637e-06}, {"id": 199, "seek": 166952, "start": 1669.52, "end": 1677.04, "text": " because then you recreate a learner and you can dot load into the learner. But yeah, for exporting", "tokens": [570, 550, 291, 25833, 257, 33347, 293, 291, 393, 5893, 3677, 666, 264, 33347, 13, 583, 1338, 11, 337, 44686], "temperature": 0.0, "avg_logprob": -0.2007044782542219, "compression_ratio": 1.625, "no_speech_prob": 3.7266074741637567e-06}, {"id": 200, "seek": 166952, "start": 1677.04, "end": 1681.84, "text": " something, I want to be able to just load that exact thing with all the same details next time.", "tokens": [746, 11, 286, 528, 281, 312, 1075, 281, 445, 3677, 300, 1900, 551, 365, 439, 264, 912, 4365, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.2007044782542219, "compression_ratio": 1.625, "no_speech_prob": 3.7266074741637567e-06}, {"id": 201, "seek": 166952, "start": 1681.84, "end": 1687.44, "text": " Dot export is the way to go. So I'm going to call dot export. I'm going to use it's a conv next.", "tokens": [38753, 10725, 307, 264, 636, 281, 352, 13, 407, 286, 478, 516, 281, 818, 5893, 10725, 13, 286, 478, 516, 281, 764, 309, 311, 257, 3754, 958, 13], "temperature": 0.0, "avg_logprob": -0.2007044782542219, "compression_ratio": 1.625, "no_speech_prob": 3.7266074741637567e-06}, {"id": 202, "seek": 168744, "start": 1687.44, "end": 1701.52, "text": " It's small and I did 12 epochs. Oh, and this needs to be an actual path. Normally we actually try", "tokens": [467, 311, 1359, 293, 286, 630, 2272, 30992, 28346, 13, 876, 11, 293, 341, 2203, 281, 312, 364, 3539, 3100, 13, 17424, 321, 767, 853], "temperature": 0.0, "avg_logprob": -0.08292571041319105, "compression_ratio": 1.4540229885057472, "no_speech_prob": 7.183206435001921e-06}, {"id": 203, "seek": 168744, "start": 1701.52, "end": 1706.0800000000002, "text": " to make these things do that for you, but this is less friendly than I would like. Sorry about that.", "tokens": [281, 652, 613, 721, 360, 300, 337, 291, 11, 457, 341, 307, 1570, 9208, 813, 286, 576, 411, 13, 4919, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.08292571041319105, "compression_ratio": 1.4540229885057472, "no_speech_prob": 7.183206435001921e-06}, {"id": 204, "seek": 168744, "start": 1707.68, "end": 1712.48, "text": " There we go. Okay. So we should now be able to see it.", "tokens": [821, 321, 352, 13, 1033, 13, 407, 321, 820, 586, 312, 1075, 281, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.08292571041319105, "compression_ratio": 1.4540229885057472, "no_speech_prob": 7.183206435001921e-06}, {"id": 205, "seek": 171248, "start": 1712.48, "end": 1719.1200000000001, "text": " There it is. Okay. And it looks like we need to give it a dot pick or whatever.", "tokens": [821, 309, 307, 13, 1033, 13, 400, 309, 1542, 411, 321, 643, 281, 976, 309, 257, 5893, 1888, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1885765186254529, "compression_ratio": 1.5348837209302326, "no_speech_prob": 7.88900888437638e-06}, {"id": 206, "seek": 171248, "start": 1724.08, "end": 1730.0, "text": " By default, with org transforms, which uses random resize crop, it will randomly pick", "tokens": [3146, 7576, 11, 365, 14045, 35592, 11, 597, 4960, 4974, 50069, 9086, 11, 309, 486, 16979, 1888], "temperature": 0.0, "avg_logprob": -0.1885765186254529, "compression_ratio": 1.5348837209302326, "no_speech_prob": 7.88900888437638e-06}, {"id": 207, "seek": 171248, "start": 1730.72, "end": 1739.3600000000001, "text": " a subset of the crop of the image of this size or bigger. And the validation set, it will pick out", "tokens": [257, 25993, 295, 264, 9086, 295, 264, 3256, 295, 341, 2744, 420, 3801, 13, 400, 264, 24071, 992, 11, 309, 486, 1888, 484], "temperature": 0.0, "avg_logprob": -0.1885765186254529, "compression_ratio": 1.5348837209302326, "no_speech_prob": 7.88900888437638e-06}, {"id": 208, "seek": 173936, "start": 1739.36, "end": 1745.6, "text": " the center. It'll, you know, as all the width it can or all the height it can without changing", "tokens": [264, 3056, 13, 467, 603, 11, 291, 458, 11, 382, 439, 264, 11402, 309, 393, 420, 439, 264, 6681, 309, 393, 1553, 4473], "temperature": 0.0, "avg_logprob": -0.16568547542964188, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.836778968339786e-05}, {"id": 209, "seek": 173936, "start": 1745.6, "end": 1755.36, "text": " the aspect ratio. If you say squish instead, it will grab the whole thing and change the aspect", "tokens": [264, 4171, 8509, 13, 759, 291, 584, 31379, 2602, 11, 309, 486, 4444, 264, 1379, 551, 293, 1319, 264, 4171], "temperature": 0.0, "avg_logprob": -0.16568547542964188, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.836778968339786e-05}, {"id": 210, "seek": 173936, "start": 1755.36, "end": 1759.4399999999998, "text": " ratio to squish it into a square. Matt, you don't have to raise your hand. Just talk to me, mate.", "tokens": [8509, 281, 31379, 309, 666, 257, 3732, 13, 7397, 11, 291, 500, 380, 362, 281, 5300, 428, 1011, 13, 1449, 751, 281, 385, 11, 11709, 13], "temperature": 0.0, "avg_logprob": -0.16568547542964188, "compression_ratio": 1.7297297297297298, "no_speech_prob": 7.836778968339786e-05}, {"id": 211, "seek": 175944, "start": 1759.44, "end": 1769.76, "text": " What's up? Can you hear me? I can't hear you. Does that mean you can't hear me? I can hear you, but", "tokens": [708, 311, 493, 30, 1664, 291, 1568, 385, 30, 286, 393, 380, 1568, 291, 13, 4402, 300, 914, 291, 393, 380, 1568, 385, 30, 286, 393, 1568, 291, 11, 457], "temperature": 0.0, "avg_logprob": -0.29948804518755745, "compression_ratio": 1.769736842105263, "no_speech_prob": 0.00048643688205629587}, {"id": 212, "seek": 175944, "start": 1769.76, "end": 1776.72, "text": " I don't think you can hear anybody. You do need to raise your hand. I can't hear you.", "tokens": [286, 500, 380, 519, 291, 393, 1568, 4472, 13, 509, 360, 643, 281, 5300, 428, 1011, 13, 286, 393, 380, 1568, 291, 13], "temperature": 0.0, "avg_logprob": -0.29948804518755745, "compression_ratio": 1.769736842105263, "no_speech_prob": 0.00048643688205629587}, {"id": 213, "seek": 177672, "start": 1776.72, "end": 1786.8, "text": " Why can't I hear you? But you guys can hear me? Okay. Yes. Yes, we can hear you, Jeremy.", "tokens": [1545, 393, 380, 286, 1568, 291, 30, 583, 291, 1074, 393, 1568, 385, 30, 1033, 13, 1079, 13, 1079, 11, 321, 393, 1568, 291, 11, 17809, 13], "temperature": 0.0, "avg_logprob": -0.15497467734596945, "compression_ratio": 1.4477611940298507, "no_speech_prob": 1.8051981896860525e-05}, {"id": 214, "seek": 177672, "start": 1787.44, "end": 1791.1200000000001, "text": " We can hear you. I see why.", "tokens": [492, 393, 1568, 291, 13, 286, 536, 983, 13], "temperature": 0.0, "avg_logprob": -0.15497467734596945, "compression_ratio": 1.4477611940298507, "no_speech_prob": 1.8051981896860525e-05}, {"id": 215, "seek": 179112, "start": 1791.12, "end": 1805.28, "text": " Okay. Say something. Can you hear me now? Yeah. Yeah, I can. All right. Okay.", "tokens": [1033, 13, 6463, 746, 13, 1664, 291, 1568, 385, 586, 30, 865, 13, 865, 11, 286, 393, 13, 1057, 558, 13, 1033, 13], "temperature": 0.0, "avg_logprob": -0.16399522622426352, "compression_ratio": 1.3140495867768596, "no_speech_prob": 8.662983418616932e-06}, {"id": 216, "seek": 179112, "start": 1810.1599999999999, "end": 1813.6799999999998, "text": " All right. Did you guys, were you guys saying anything I was meant to be hearing?", "tokens": [1057, 558, 13, 2589, 291, 1074, 11, 645, 291, 1074, 1566, 1340, 286, 390, 4140, 281, 312, 4763, 30], "temperature": 0.0, "avg_logprob": -0.16399522622426352, "compression_ratio": 1.3140495867768596, "no_speech_prob": 8.662983418616932e-06}, {"id": 217, "seek": 181368, "start": 1813.68, "end": 1823.28, "text": " Did I miss anything? Yeah. Why did you choose 12 epochs? Oh, no particular reason. I just saw", "tokens": [2589, 286, 1713, 1340, 30, 865, 13, 1545, 630, 291, 2826, 2272, 30992, 28346, 30, 876, 11, 572, 1729, 1778, 13, 286, 445, 1866], "temperature": 0.0, "avg_logprob": -0.17525205494445048, "compression_ratio": 1.3969849246231156, "no_speech_prob": 7.182793979154667e-06}, {"id": 218, "seek": 181368, "start": 1823.28, "end": 1830.8, "text": " that this one was using 14 and I thought, oh, I'm for something around there, but maybe just do a", "tokens": [300, 341, 472, 390, 1228, 3499, 293, 286, 1194, 11, 1954, 11, 286, 478, 337, 746, 926, 456, 11, 457, 1310, 445, 360, 257], "temperature": 0.0, "avg_logprob": -0.17525205494445048, "compression_ratio": 1.3969849246231156, "no_speech_prob": 7.182793979154667e-06}, {"id": 219, "seek": 181368, "start": 1830.8, "end": 1837.68, "text": " little bit less. I guess I often do around 12-ish epochs. Like, it seems to, like, for", "tokens": [707, 857, 1570, 13, 286, 2041, 286, 2049, 360, 926, 2272, 12, 742, 30992, 28346, 13, 1743, 11, 309, 2544, 281, 11, 411, 11, 337], "temperature": 0.0, "avg_logprob": -0.17525205494445048, "compression_ratio": 1.3969849246231156, "no_speech_prob": 7.182793979154667e-06}, {"id": 220, "seek": 183768, "start": 1837.68, "end": 1844.0, "text": " fine-tuning things, which are somewhat similar to the original, it", "tokens": [2489, 12, 83, 37726, 721, 11, 597, 366, 8344, 2531, 281, 264, 3380, 11, 309], "temperature": 0.0, "avg_logprob": -0.3729780722355497, "compression_ratio": 1.4540229885057472, "no_speech_prob": 2.5461496989009902e-05}, {"id": 221, "seek": 183768, "start": 1845.04, "end": 1852.4, "text": " often seems to get pretty close to, you know, getting all the information it can, just as a rule of thumb.", "tokens": [2049, 2544, 281, 483, 1238, 1998, 281, 11, 291, 458, 11, 1242, 439, 264, 1589, 309, 393, 11, 445, 382, 257, 4978, 295, 9298, 13], "temperature": 0.0, "avg_logprob": -0.3729780722355497, "compression_ratio": 1.4540229885057472, "no_speech_prob": 2.5461496989009902e-05}, {"id": 222, "seek": 183768, "start": 1854.4, "end": 1858.0, "text": " And I have a question. And it runs at a reasonable amount of time too, I'd say.", "tokens": [400, 286, 362, 257, 1168, 13, 400, 309, 6676, 412, 257, 10585, 2372, 295, 565, 886, 11, 286, 1116, 584, 13], "temperature": 0.0, "avg_logprob": -0.3729780722355497, "compression_ratio": 1.4540229885057472, "no_speech_prob": 2.5461496989009902e-05}, {"id": 223, "seek": 185800, "start": 1858.0, "end": 1867.92, "text": " My assumptions were that the number 460 is because of the size of the images were 460.", "tokens": [1222, 17695, 645, 300, 264, 1230, 1017, 4550, 307, 570, 295, 264, 2744, 295, 264, 5267, 645, 1017, 4550, 13], "temperature": 0.0, "avg_logprob": -0.33782807315688534, "compression_ratio": 1.6808510638297873, "no_speech_prob": 1.1658860785246361e-05}, {"id": 224, "seek": 185800, "start": 1869.04, "end": 1876.64, "text": " And then another assumption was 224 because when you show the team with the different,", "tokens": [400, 550, 1071, 15302, 390, 5853, 19, 570, 562, 291, 855, 264, 1469, 365, 264, 819, 11], "temperature": 0.0, "avg_logprob": -0.33782807315688534, "compression_ratio": 1.6808510638297873, "no_speech_prob": 1.1658860785246361e-05}, {"id": 225, "seek": 185800, "start": 1876.64, "end": 1882.96, "text": " the convex and the image size was 224, that's the reason that I selected that. Is that okay?", "tokens": [264, 42432, 293, 264, 3256, 2744, 390, 5853, 19, 11, 300, 311, 264, 1778, 300, 286, 8209, 300, 13, 1119, 300, 1392, 30], "temperature": 0.0, "avg_logprob": -0.33782807315688534, "compression_ratio": 1.6808510638297873, "no_speech_prob": 1.1658860785246361e-05}, {"id": 226, "seek": 185800, "start": 1882.96, "end": 1885.44, "text": " Is that a correct assumption? Well, that was 620.", "tokens": [1119, 300, 257, 3006, 15302, 30, 1042, 11, 300, 390, 1386, 2009, 13], "temperature": 0.0, "avg_logprob": -0.33782807315688534, "compression_ratio": 1.6808510638297873, "no_speech_prob": 1.1658860785246361e-05}, {"id": 227, "seek": 188544, "start": 1885.44, "end": 1894.88, "text": " By 480. So actually, so we do this, look it up in the book. It's under the section called", "tokens": [3146, 1017, 4702, 13, 407, 767, 11, 370, 321, 360, 341, 11, 574, 309, 493, 294, 264, 1446, 13, 467, 311, 833, 264, 3541, 1219], "temperature": 0.0, "avg_logprob": -0.12530924723698542, "compression_ratio": 1.5957446808510638, "no_speech_prob": 9.759201930137351e-05}, {"id": 228, "seek": 188544, "start": 1894.88, "end": 1901.44, "text": " pre-sizing. And I think this is around what we always pre-size to. So actually, maybe 480 would", "tokens": [659, 12, 82, 3319, 13, 400, 286, 519, 341, 307, 926, 437, 321, 1009, 659, 12, 27553, 281, 13, 407, 767, 11, 1310, 1017, 4702, 576], "temperature": 0.0, "avg_logprob": -0.12530924723698542, "compression_ratio": 1.5957446808510638, "no_speech_prob": 9.759201930137351e-05}, {"id": 229, "seek": 188544, "start": 1901.44, "end": 1905.2, "text": " have been better because then it wouldn't have had to change one of the dimensions because there was", "tokens": [362, 668, 1101, 570, 550, 309, 2759, 380, 362, 632, 281, 1319, 472, 295, 264, 12819, 570, 456, 390], "temperature": 0.0, "avg_logprob": -0.12530924723698542, "compression_ratio": 1.5957446808510638, "no_speech_prob": 9.759201930137351e-05}, {"id": 230, "seek": 188544, "start": 1905.2, "end": 1914.0, "text": " 640 by 480. And then your size you picked, I actually changed it. So Gerardo picked 230.", "tokens": [1386, 5254, 538, 1017, 4702, 13, 400, 550, 428, 2744, 291, 6183, 11, 286, 767, 3105, 309, 13, 407, 9409, 12850, 6183, 35311, 13], "temperature": 0.0, "avg_logprob": -0.12530924723698542, "compression_ratio": 1.5957446808510638, "no_speech_prob": 9.759201930137351e-05}, {"id": 231, "seek": 191400, "start": 1914.0, "end": 1919.76, "text": " But actually, most of these models that are trained on ImageNet are generally trained on", "tokens": [583, 767, 11, 881, 295, 613, 5245, 300, 366, 8895, 322, 29903, 31890, 366, 5101, 8895, 322], "temperature": 0.0, "avg_logprob": -0.10817808317906648, "compression_ratio": 1.6576576576576576, "no_speech_prob": 2.99440284834418e-06}, {"id": 232, "seek": 191400, "start": 1919.76, "end": 1925.6, "text": " 224. So I wanted them to be the same size as what they trained on. So that's why I picked 224.", "tokens": [5853, 19, 13, 407, 286, 1415, 552, 281, 312, 264, 912, 2744, 382, 437, 436, 8895, 322, 13, 407, 300, 311, 983, 286, 6183, 5853, 19, 13], "temperature": 0.0, "avg_logprob": -0.10817808317906648, "compression_ratio": 1.6576576576576576, "no_speech_prob": 2.99440284834418e-06}, {"id": 233, "seek": 191400, "start": 1927.28, "end": 1933.76, "text": " Yeah, so then Squish I've talked about. Oh, and then the other thing is the model I picked", "tokens": [865, 11, 370, 550, 8683, 742, 286, 600, 2825, 466, 13, 876, 11, 293, 550, 264, 661, 551, 307, 264, 2316, 286, 6183], "temperature": 0.0, "avg_logprob": -0.10817808317906648, "compression_ratio": 1.6576576576576576, "no_speech_prob": 2.99440284834418e-06}, {"id": 234, "seek": 191400, "start": 1934.64, "end": 1943.76, "text": " is one with a suffix in 22k. IN here refers to ImageNet. And the 22k refers to the version of", "tokens": [307, 472, 365, 257, 3889, 970, 294, 5853, 74, 13, 6892, 510, 14942, 281, 29903, 31890, 13, 400, 264, 5853, 74, 14942, 281, 264, 3037, 295], "temperature": 0.0, "avg_logprob": -0.10817808317906648, "compression_ratio": 1.6576576576576576, "no_speech_prob": 2.99440284834418e-06}, {"id": 235, "seek": 194376, "start": 1943.76, "end": 1949.2, "text": " ImageNet with 22,000 categories, as opposed to the version that's normally used, which only has", "tokens": [29903, 31890, 365, 5853, 11, 1360, 10479, 11, 382, 8851, 281, 264, 3037, 300, 311, 5646, 1143, 11, 597, 787, 575], "temperature": 0.0, "avg_logprob": -0.09607977025649127, "compression_ratio": 1.8076923076923077, "no_speech_prob": 1.3211728401074652e-05}, {"id": 236, "seek": 194376, "start": 1949.2, "end": 1955.04, "text": " a thousand categories. So this is a ConvNext, which is small, but is trained on ImageNet", "tokens": [257, 4714, 10479, 13, 407, 341, 307, 257, 2656, 85, 31002, 11, 597, 307, 1359, 11, 457, 307, 8895, 322, 29903, 31890], "temperature": 0.0, "avg_logprob": -0.09607977025649127, "compression_ratio": 1.8076923076923077, "no_speech_prob": 1.3211728401074652e-05}, {"id": 237, "seek": 194376, "start": 1956.0, "end": 1961.12, "text": " with a 22,000 category version. The 22,000 category version, it just has a lot more images", "tokens": [365, 257, 5853, 11, 1360, 7719, 3037, 13, 440, 5853, 11, 1360, 7719, 3037, 11, 309, 445, 575, 257, 688, 544, 5267], "temperature": 0.0, "avg_logprob": -0.09607977025649127, "compression_ratio": 1.8076923076923077, "no_speech_prob": 1.3211728401074652e-05}, {"id": 238, "seek": 194376, "start": 1961.12, "end": 1965.28, "text": " covering a lot more different things. So there's a much higher chance that it's going to have seen", "tokens": [10322, 257, 688, 544, 819, 721, 13, 407, 456, 311, 257, 709, 2946, 2931, 300, 309, 311, 516, 281, 362, 1612], "temperature": 0.0, "avg_logprob": -0.09607977025649127, "compression_ratio": 1.8076923076923077, "no_speech_prob": 1.3211728401074652e-05}, {"id": 239, "seek": 194376, "start": 1965.28, "end": 1972.4, "text": " something like rice paddy illness than the one with a thousand images. And it's just seen a lot", "tokens": [746, 411, 5090, 6887, 3173, 10152, 813, 264, 472, 365, 257, 4714, 5267, 13, 400, 309, 311, 445, 1612, 257, 688], "temperature": 0.0, "avg_logprob": -0.09607977025649127, "compression_ratio": 1.8076923076923077, "no_speech_prob": 1.3211728401074652e-05}, {"id": 240, "seek": 197240, "start": 1972.4, "end": 1983.44, "text": " more different pics. So yeah, I would recommend always using the IN22k pre-trained models.", "tokens": [544, 819, 46690, 13, 407, 1338, 11, 286, 576, 2748, 1009, 1228, 264, 6892, 7490, 74, 659, 12, 17227, 2001, 5245, 13], "temperature": 0.0, "avg_logprob": -0.11574193014614824, "compression_ratio": 1.4880952380952381, "no_speech_prob": 3.5006828511541244e-06}, {"id": 241, "seek": 197240, "start": 1984.48, "end": 1990.72, "text": " So those are, I think, the key differences at the training stage.", "tokens": [407, 729, 366, 11, 286, 519, 11, 264, 2141, 7300, 412, 264, 3097, 3233, 13], "temperature": 0.0, "avg_logprob": -0.11574193014614824, "compression_ratio": 1.4880952380952381, "no_speech_prob": 3.5006828511541244e-06}, {"id": 242, "seek": 197240, "start": 1994.5600000000002, "end": 2000.72, "text": " Yeah, I think when you had put the export and then the error came, that's when it cut off. So", "tokens": [865, 11, 286, 519, 562, 291, 632, 829, 264, 10725, 293, 550, 264, 6713, 1361, 11, 300, 311, 562, 309, 1723, 766, 13, 407], "temperature": 0.0, "avg_logprob": -0.11574193014614824, "compression_ratio": 1.4880952380952381, "no_speech_prob": 3.5006828511541244e-06}, {"id": 243, "seek": 200072, "start": 2000.72, "end": 2005.04, "text": " I don't think you explained what you did to, well, you didn't catch the part where you explained the fix.", "tokens": [286, 500, 380, 519, 291, 8825, 437, 291, 630, 281, 11, 731, 11, 291, 994, 380, 3745, 264, 644, 689, 291, 8825, 264, 3191, 13], "temperature": 0.0, "avg_logprob": -0.11851341074163263, "compression_ratio": 1.782442748091603, "no_speech_prob": 1.892339059850201e-05}, {"id": 244, "seek": 200072, "start": 2006.64, "end": 2013.1200000000001, "text": " The fix. Well, because the export had an error, right? And then I guess you've now", "tokens": [440, 3191, 13, 1042, 11, 570, 264, 10725, 632, 364, 6713, 11, 558, 30, 400, 550, 286, 2041, 291, 600, 586], "temperature": 0.0, "avg_logprob": -0.11851341074163263, "compression_ratio": 1.782442748091603, "no_speech_prob": 1.892339059850201e-05}, {"id": 245, "seek": 200072, "start": 2013.76, "end": 2019.1200000000001, "text": " added the path. I don't think it had an error, but I just, oh, I see. Yes, yes, yes. Okay. Yeah,", "tokens": [3869, 264, 3100, 13, 286, 500, 380, 519, 309, 632, 364, 6713, 11, 457, 286, 445, 11, 1954, 11, 286, 536, 13, 1079, 11, 2086, 11, 2086, 13, 1033, 13, 865, 11], "temperature": 0.0, "avg_logprob": -0.11851341074163263, "compression_ratio": 1.782442748091603, "no_speech_prob": 1.892339059850201e-05}, {"id": 246, "seek": 200072, "start": 2019.1200000000001, "end": 2022.64, "text": " the export had an error because this was a string and it actually needs to be a path,", "tokens": [264, 10725, 632, 364, 6713, 570, 341, 390, 257, 6798, 293, 309, 767, 2203, 281, 312, 257, 3100, 11], "temperature": 0.0, "avg_logprob": -0.11851341074163263, "compression_ratio": 1.782442748091603, "no_speech_prob": 1.892339059850201e-05}, {"id": 247, "seek": 200072, "start": 2023.3600000000001, "end": 2028.24, "text": " which I'd say is an oversight on my part. I try to make it so that everything can accept a path", "tokens": [597, 286, 1116, 584, 307, 364, 29146, 322, 452, 644, 13, 286, 853, 281, 652, 309, 370, 300, 1203, 393, 3241, 257, 3100], "temperature": 0.0, "avg_logprob": -0.11851341074163263, "compression_ratio": 1.782442748091603, "no_speech_prob": 1.892339059850201e-05}, {"id": 248, "seek": 202824, "start": 2028.24, "end": 2033.28, "text": " or a string. So I would consider that a bug that ought to be fixed. So hopefully by the time people", "tokens": [420, 257, 6798, 13, 407, 286, 576, 1949, 300, 257, 7426, 300, 13416, 281, 312, 6806, 13, 407, 4696, 538, 264, 565, 561], "temperature": 0.0, "avg_logprob": -0.08969769654450593, "compression_ratio": 1.49746192893401, "no_speech_prob": 1.4970320080465171e-05}, {"id": 249, "seek": 202824, "start": 2033.28, "end": 2038.72, "text": " watch this video, that might've been fixed. But yes, at the moment I had to change this to a path.", "tokens": [1159, 341, 960, 11, 300, 1062, 600, 668, 6806, 13, 583, 2086, 11, 412, 264, 1623, 286, 632, 281, 1319, 341, 281, 257, 3100, 13], "temperature": 0.0, "avg_logprob": -0.08969769654450593, "compression_ratio": 1.49746192893401, "no_speech_prob": 1.4970320080465171e-05}, {"id": 250, "seek": 202824, "start": 2039.68, "end": 2052.64, "text": " Thank you. All right. So there's a few things we could do here, right? But one key issue is that", "tokens": [1044, 291, 13, 1057, 558, 13, 407, 456, 311, 257, 1326, 721, 321, 727, 360, 510, 11, 558, 30, 583, 472, 2141, 2734, 307, 300], "temperature": 0.0, "avg_logprob": -0.08969769654450593, "compression_ratio": 1.49746192893401, "no_speech_prob": 1.4970320080465171e-05}, {"id": 251, "seek": 205264, "start": 2052.64, "end": 2059.12, "text": " the, is that particularly if you don't have method equals squish, when we do validation,", "tokens": [264, 11, 307, 300, 4098, 498, 291, 500, 380, 362, 3170, 6915, 31379, 11, 562, 321, 360, 24071, 11], "temperature": 0.0, "avg_logprob": -0.07166835394772617, "compression_ratio": 1.6227272727272728, "no_speech_prob": 1.3845078683516476e-05}, {"id": 252, "seek": 205264, "start": 2059.12, "end": 2065.92, "text": " it's only selecting the center of the image and that's a problem, right? We would like it to", "tokens": [309, 311, 787, 18182, 264, 3056, 295, 264, 3256, 293, 300, 311, 257, 1154, 11, 558, 30, 492, 576, 411, 309, 281], "temperature": 0.0, "avg_logprob": -0.07166835394772617, "compression_ratio": 1.6227272727272728, "no_speech_prob": 1.3845078683516476e-05}, {"id": 253, "seek": 205264, "start": 2066.56, "end": 2071.8399999999997, "text": " see all the image. And then another thing is that we've been training it with various different", "tokens": [536, 439, 264, 3256, 13, 400, 550, 1071, 551, 307, 300, 321, 600, 668, 3097, 309, 365, 3683, 819], "temperature": 0.0, "avg_logprob": -0.07166835394772617, "compression_ratio": 1.6227272727272728, "no_speech_prob": 1.3845078683516476e-05}, {"id": 254, "seek": 205264, "start": 2071.8399999999997, "end": 2077.6, "text": " augmentations, but the validation set, we don't use any of those augmentations.", "tokens": [29919, 763, 11, 457, 264, 24071, 992, 11, 321, 500, 380, 764, 604, 295, 729, 29919, 763, 13], "temperature": 0.0, "avg_logprob": -0.07166835394772617, "compression_ratio": 1.6227272727272728, "no_speech_prob": 1.3845078683516476e-05}, {"id": 255, "seek": 207760, "start": 2077.6, "end": 2081.7599999999998, "text": " So there's a trick you can use, which you should particularly use if you don't use squish,", "tokens": [407, 456, 311, 257, 4282, 291, 393, 764, 11, 597, 291, 820, 4098, 764, 498, 291, 500, 380, 764, 31379, 11], "temperature": 0.0, "avg_logprob": -0.1988140360514323, "compression_ratio": 1.6225490196078431, "no_speech_prob": 7.889005246397574e-06}, {"id": 256, "seek": 207760, "start": 2081.7599999999998, "end": 2087.12, "text": " and that's effectively cropping into the center, which is something called test time augmentation.", "tokens": [293, 300, 311, 8659, 4848, 3759, 666, 264, 3056, 11, 597, 307, 746, 1219, 1500, 565, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.1988140360514323, "compression_ratio": 1.6225490196078431, "no_speech_prob": 7.889005246397574e-06}, {"id": 257, "seek": 207760, "start": 2087.12, "end": 2093.52, "text": " And in test time augmentation, we basically get", "tokens": [400, 294, 1500, 565, 14501, 19631, 11, 321, 1936, 483], "temperature": 0.0, "avg_logprob": -0.1988140360514323, "compression_ratio": 1.6225490196078431, "no_speech_prob": 7.889005246397574e-06}, {"id": 258, "seek": 207760, "start": 2098.56, "end": 2103.2, "text": " multiple versions of each image. We actually by default get four different randomly augmented", "tokens": [3866, 9606, 295, 1184, 3256, 13, 492, 767, 538, 7576, 483, 1451, 819, 16979, 36155], "temperature": 0.0, "avg_logprob": -0.1988140360514323, "compression_ratio": 1.6225490196078431, "no_speech_prob": 7.889005246397574e-06}, {"id": 259, "seek": 210320, "start": 2103.2, "end": 2111.7599999999998, "text": " versions of each image, plus the unaugmented version. We get the prediction on every one,", "tokens": [9606, 295, 1184, 3256, 11, 1804, 264, 517, 20056, 14684, 3037, 13, 492, 483, 264, 17630, 322, 633, 472, 11], "temperature": 0.0, "avg_logprob": -0.1722311816372714, "compression_ratio": 1.6502242152466369, "no_speech_prob": 7.5277935138728935e-06}, {"id": 260, "seek": 210320, "start": 2111.7599999999998, "end": 2117.2, "text": " and then we take the average, and that's called test time augmentation. And as I said,", "tokens": [293, 550, 321, 747, 264, 4274, 11, 293, 300, 311, 1219, 1500, 565, 14501, 19631, 13, 400, 382, 286, 848, 11], "temperature": 0.0, "avg_logprob": -0.1722311816372714, "compression_ratio": 1.6502242152466369, "no_speech_prob": 7.5277935138728935e-06}, {"id": 261, "seek": 210320, "start": 2117.2, "end": 2122.16, "text": " it would work particularly well without the squish, but it ought to work well even with the squish.", "tokens": [309, 576, 589, 4098, 731, 1553, 264, 31379, 11, 457, 309, 13416, 281, 589, 731, 754, 365, 264, 31379, 13], "temperature": 0.0, "avg_logprob": -0.1722311816372714, "compression_ratio": 1.6502242152466369, "no_speech_prob": 7.5277935138728935e-06}, {"id": 262, "seek": 210320, "start": 2122.16, "end": 2130.3999999999996, "text": " So to get those predictions, let's first of all make sure we can replicate this error rate.", "tokens": [407, 281, 483, 729, 21264, 11, 718, 311, 700, 295, 439, 652, 988, 321, 393, 25356, 341, 6713, 3314, 13], "temperature": 0.0, "avg_logprob": -0.1722311816372714, "compression_ratio": 1.6502242152466369, "no_speech_prob": 7.5277935138728935e-06}, {"id": 263, "seek": 213040, "start": 2130.4, "end": 2136.64, "text": " Manually, right? So if we go", "tokens": [2458, 671, 11, 558, 30, 407, 498, 321, 352], "temperature": 0.0, "avg_logprob": -0.2820567819807265, "compression_ratio": 1.1122448979591837, "no_speech_prob": 8.530226295988541e-06}, {"id": 264, "seek": 213040, "start": 2143.52, "end": 2148.64, "text": " probabilities, targets equals learn.getPreds,", "tokens": [33783, 11, 12911, 6915, 1466, 13, 847, 47, 986, 82, 11], "temperature": 0.0, "avg_logprob": -0.2820567819807265, "compression_ratio": 1.1122448979591837, "no_speech_prob": 8.530226295988541e-06}, {"id": 265, "seek": 213040, "start": 2151.28, "end": 2154.0, "text": " and we pass in the validation set,", "tokens": [293, 321, 1320, 294, 264, 24071, 992, 11], "temperature": 0.0, "avg_logprob": -0.2820567819807265, "compression_ratio": 1.1122448979591837, "no_speech_prob": 8.530226295988541e-06}, {"id": 266, "seek": 215400, "start": 2154.0, "end": 2159.84, "text": " and then we should find that if we ask now for the error rate, shift tab,", "tokens": [293, 550, 321, 820, 915, 300, 498, 321, 1029, 586, 337, 264, 6713, 3314, 11, 5513, 4421, 11], "temperature": 0.0, "avg_logprob": -0.2587180328369141, "compression_ratio": 1.6387096774193548, "no_speech_prob": 5.453281914924446e-07}, {"id": 267, "seek": 215400, "start": 2160.8, "end": 2167.12, "text": " so the inputs are the probabilities, and the targets are the targets. There we go. Okay,", "tokens": [370, 264, 15743, 366, 264, 33783, 11, 293, 264, 12911, 366, 264, 12911, 13, 821, 321, 352, 13, 1033, 11], "temperature": 0.0, "avg_logprob": -0.2587180328369141, "compression_ratio": 1.6387096774193548, "no_speech_prob": 5.453281914924446e-07}, {"id": 268, "seek": 215400, "start": 2167.12, "end": 2175.04, "text": " so that's our 2.02% error rate, so we've replicated that. Okay, so now we've got that 2.02.", "tokens": [370, 300, 311, 527, 568, 13, 12756, 4, 6713, 3314, 11, 370, 321, 600, 46365, 300, 13, 1033, 11, 370, 586, 321, 600, 658, 300, 568, 13, 12756, 13], "temperature": 0.0, "avg_logprob": -0.2587180328369141, "compression_ratio": 1.6387096774193548, "no_speech_prob": 5.453281914924446e-07}, {"id": 269, "seek": 217504, "start": 2175.04, "end": 2184.16, "text": " I would then try out tta, and of course before we use a new function, we would always read its", "tokens": [286, 576, 550, 853, 484, 256, 1328, 11, 293, 295, 1164, 949, 321, 764, 257, 777, 2445, 11, 321, 576, 1009, 1401, 1080], "temperature": 0.0, "avg_logprob": -0.29582337599534253, "compression_ratio": 1.5320512820512822, "no_speech_prob": 2.058033942375914e-06}, {"id": 270, "seek": 217504, "start": 2184.16, "end": 2194.4, "text": " documentation. Here we are,.tta. So return the predictions on some data set or some data loader.", "tokens": [14333, 13, 1692, 321, 366, 11, 2411, 83, 1328, 13, 407, 2736, 264, 21264, 322, 512, 1412, 992, 420, 512, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.29582337599534253, "compression_ratio": 1.5320512820512822, "no_speech_prob": 2.058033942375914e-06}, {"id": 271, "seek": 217504, "start": 2196.0, "end": 2198.88, "text": " We get the predictions n times by default four,", "tokens": [492, 483, 264, 21264, 297, 1413, 538, 7576, 1451, 11], "temperature": 0.0, "avg_logprob": -0.29582337599534253, "compression_ratio": 1.5320512820512822, "no_speech_prob": 2.058033942375914e-06}, {"id": 272, "seek": 219888, "start": 2198.88, "end": 2205.6800000000003, "text": " using the training set transformations. Great. Oh, and instead of getting the average of", "tokens": [1228, 264, 3097, 992, 34852, 13, 3769, 13, 876, 11, 293, 2602, 295, 1242, 264, 4274, 295], "temperature": 0.0, "avg_logprob": -0.18512276240757533, "compression_ratio": 1.5397727272727273, "no_speech_prob": 2.1568005195149453e-06}, {"id": 273, "seek": 219888, "start": 2205.6800000000003, "end": 2213.12, "text": " predictions, we could also get the max of predictions. Cool. And the other thing which", "tokens": [21264, 11, 321, 727, 611, 483, 264, 11469, 295, 21264, 13, 8561, 13, 400, 264, 661, 551, 597], "temperature": 0.0, "avg_logprob": -0.18512276240757533, "compression_ratio": 1.5397727272727273, "no_speech_prob": 2.1568005195149453e-06}, {"id": 274, "seek": 219888, "start": 2213.12, "end": 2221.92, "text": " I definitely encourage you to do is always good to look at the source code, because my claim is", "tokens": [286, 2138, 5373, 291, 281, 360, 307, 1009, 665, 281, 574, 412, 264, 4009, 3089, 11, 570, 452, 3932, 307], "temperature": 0.0, "avg_logprob": -0.18512276240757533, "compression_ratio": 1.5397727272727273, "no_speech_prob": 2.1568005195149453e-06}, {"id": 275, "seek": 222192, "start": 2221.92, "end": 2228.7200000000003, "text": " that fast AI functions are generally not very big. And also quite a bit of its stuff you can skip", "tokens": [300, 2370, 7318, 6828, 366, 5101, 406, 588, 955, 13, 400, 611, 1596, 257, 857, 295, 1080, 1507, 291, 393, 10023], "temperature": 0.0, "avg_logprob": -0.4091358366466704, "compression_ratio": 1.7035398230088497, "no_speech_prob": 1.1658751645882148e-05}, {"id": 276, "seek": 222192, "start": 2228.7200000000003, "end": 2233.6800000000003, "text": " over, right? This is like, oh, what if it's none, what if it's none? This is setting defaults. You", "tokens": [670, 11, 558, 30, 639, 307, 411, 11, 1954, 11, 437, 498, 309, 311, 6022, 11, 437, 498, 309, 311, 6022, 30, 639, 307, 3287, 7576, 82, 13, 509], "temperature": 0.0, "avg_logprob": -0.4091358366466704, "compression_ratio": 1.7035398230088497, "no_speech_prob": 1.1658751645882148e-05}, {"id": 277, "seek": 222192, "start": 2233.6800000000003, "end": 2240.56, "text": " can skip it. Try finales, you can skip because it's just error handling. Widths, you can pretty", "tokens": [393, 10023, 309, 13, 6526, 2572, 279, 11, 291, 393, 10023, 570, 309, 311, 445, 6713, 13175, 13, 28331, 32184, 11, 291, 393, 1238], "temperature": 0.0, "avg_logprob": -0.4091358366466704, "compression_ratio": 1.7035398230088497, "no_speech_prob": 1.1658751645882148e-05}, {"id": 278, "seek": 222192, "start": 2240.56, "end": 2247.36, "text": " much split. Progress bars, you can pretty much skip. So the error rate is the average of the", "tokens": [709, 7472, 13, 32587, 10228, 11, 291, 393, 1238, 709, 10023, 13, 407, 264, 6713, 3314, 307, 264, 4274, 295, 264], "temperature": 0.0, "avg_logprob": -0.4091358366466704, "compression_ratio": 1.7035398230088497, "no_speech_prob": 1.1658751645882148e-05}, {"id": 279, "seek": 224736, "start": 2247.36, "end": 2254.7200000000003, "text": " progress bars you can pretty much skip. So the actual work starts happening here.", "tokens": [4205, 10228, 291, 393, 1238, 709, 10023, 13, 407, 264, 3539, 589, 3719, 2737, 510, 13], "temperature": 0.0, "avg_logprob": -0.19510766150246203, "compression_ratio": 1.5222222222222221, "no_speech_prob": 7.1831236709840596e-06}, {"id": 280, "seek": 224736, "start": 2256.0, "end": 2262.4, "text": " We're going to call self.getPreds, passes in a data loader, and then it concatenates that all", "tokens": [492, 434, 516, 281, 818, 2698, 13, 847, 47, 986, 82, 11, 11335, 294, 257, 1412, 3677, 260, 11, 293, 550, 309, 1588, 7186, 1024, 300, 439], "temperature": 0.0, "avg_logprob": -0.19510766150246203, "compression_ratio": 1.5222222222222221, "no_speech_prob": 7.1831236709840596e-06}, {"id": 281, "seek": 224736, "start": 2262.4, "end": 2268.56, "text": " together, and then it takes either the maximum or the mean, depending on whether you asked for the", "tokens": [1214, 11, 293, 550, 309, 2516, 2139, 264, 6674, 420, 264, 914, 11, 5413, 322, 1968, 291, 2351, 337, 264], "temperature": 0.0, "avg_logprob": -0.19510766150246203, "compression_ratio": 1.5222222222222221, "no_speech_prob": 7.1831236709840596e-06}, {"id": 282, "seek": 226856, "start": 2268.56, "end": 2277.68, "text": " max or not, and it also grabs it for the validation set data loader.", "tokens": [11469, 420, 406, 11, 293, 309, 611, 30028, 309, 337, 264, 24071, 992, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.12035635539463588, "compression_ratio": 1.2372881355932204, "no_speech_prob": 1.1911052979485248e-06}, {"id": 283, "seek": 226856, "start": 2285.04, "end": 2286.7999999999997, "text": " Yeah, so you kind of get the idea.", "tokens": [865, 11, 370, 291, 733, 295, 483, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.12035635539463588, "compression_ratio": 1.2372881355932204, "no_speech_prob": 1.1911052979485248e-06}, {"id": 284, "seek": 228680, "start": 2286.8, "end": 2302.8, "text": " So let's run it. See if we can beat 2.02%. So you can see here it's running it four times for each", "tokens": [407, 718, 311, 1190, 309, 13, 3008, 498, 321, 393, 4224, 568, 13, 12756, 6856, 407, 291, 393, 536, 510, 309, 311, 2614, 309, 1451, 1413, 337, 1184], "temperature": 0.0, "avg_logprob": -0.24276910509381974, "compression_ratio": 1.443609022556391, "no_speech_prob": 1.4593695141229546e-06}, {"id": 285, "seek": 228680, "start": 2302.8, "end": 2310.32, "text": " of the four augmented versions. And then it'll run it one time for the non-augmented version.", "tokens": [295, 264, 1451, 36155, 9606, 13, 400, 550, 309, 603, 1190, 309, 472, 565, 337, 264, 2107, 12, 20056, 14684, 3037, 13], "temperature": 0.0, "avg_logprob": -0.24276910509381974, "compression_ratio": 1.443609022556391, "no_speech_prob": 1.4593695141229546e-06}, {"id": 286, "seek": 231032, "start": 2310.32, "end": 2320.32, "text": " Okay, and it beat it, but just by a little bit. And then, you know, another thing is, well, what if we did", "tokens": [1033, 11, 293, 309, 4224, 309, 11, 457, 445, 538, 257, 707, 857, 13, 400, 550, 11, 291, 458, 11, 1071, 551, 307, 11, 731, 11, 437, 498, 321, 630], "temperature": 0.0, "avg_logprob": -0.20622822595021081, "compression_ratio": 1.4714285714285715, "no_speech_prob": 2.8129900329076918e-06}, {"id": 287, "seek": 231032, "start": 2323.6800000000003, "end": 2324.6400000000003, "text": " the non-maximum?", "tokens": [264, 2107, 12, 1696, 3081, 449, 30], "temperature": 0.0, "avg_logprob": -0.20622822595021081, "compression_ratio": 1.4714285714285715, "no_speech_prob": 2.8129900329076918e-06}, {"id": 288, "seek": 231032, "start": 2330.2400000000002, "end": 2337.04, "text": " Use max equals false. Use max equals true. Use the maximum instead of the average.", "tokens": [8278, 11469, 6915, 7908, 13, 8278, 11469, 6915, 2074, 13, 8278, 264, 6674, 2602, 295, 264, 4274, 13], "temperature": 0.0, "avg_logprob": -0.20622822595021081, "compression_ratio": 1.4714285714285715, "no_speech_prob": 2.8129900329076918e-06}, {"id": 289, "seek": 233704, "start": 2337.04, "end": 2340.24, "text": " Yeah, I kind of wish I didn't have the squish in now, but I don't want you guys to have to wait", "tokens": [865, 11, 286, 733, 295, 3172, 286, 994, 380, 362, 264, 31379, 294, 586, 11, 457, 286, 500, 380, 528, 291, 1074, 281, 362, 281, 1699], "temperature": 0.0, "avg_logprob": -0.20677555084228516, "compression_ratio": 1.4734042553191489, "no_speech_prob": 1.7230977391591296e-05}, {"id": 290, "seek": 233704, "start": 2340.24, "end": 2344.96, "text": " 10 minutes for it to retrain because then you'd much more clearly see the benefit of using TTA.", "tokens": [1266, 2077, 337, 309, 281, 1533, 7146, 570, 550, 291, 1116, 709, 544, 4448, 536, 264, 5121, 295, 1228, 314, 8241, 13], "temperature": 0.0, "avg_logprob": -0.20677555084228516, "compression_ratio": 1.4734042553191489, "no_speech_prob": 1.7230977391591296e-05}, {"id": 291, "seek": 233704, "start": 2357.52, "end": 2364.08, "text": " That's interesting. That one's worse. So I generally find that when not using squish,", "tokens": [663, 311, 1880, 13, 663, 472, 311, 5324, 13, 407, 286, 5101, 915, 300, 562, 406, 1228, 31379, 11], "temperature": 0.0, "avg_logprob": -0.20677555084228516, "compression_ratio": 1.4734042553191489, "no_speech_prob": 1.7230977391591296e-05}, {"id": 292, "seek": 236408, "start": 2364.08, "end": 2373.7599999999998, "text": " that using TTA and use max equals true is best. Okay, so now we've done all that. We can try and", "tokens": [300, 1228, 314, 8241, 293, 764, 11469, 6915, 2074, 307, 1151, 13, 1033, 11, 370, 586, 321, 600, 1096, 439, 300, 13, 492, 393, 853, 293], "temperature": 0.0, "avg_logprob": -0.15467706716285562, "compression_ratio": 1.3129251700680271, "no_speech_prob": 2.123370904882904e-06}, {"id": 293, "seek": 236408, "start": 2373.7599999999998, "end": 2383.12, "text": " submit this one to Kaggle. So we can just repeat basically what we had yesterday, but instead of", "tokens": [10315, 341, 472, 281, 48751, 22631, 13, 407, 321, 393, 445, 7149, 1936, 437, 321, 632, 5186, 11, 457, 2602, 295], "temperature": 0.0, "avg_logprob": -0.15467706716285562, "compression_ratio": 1.3129251700680271, "no_speech_prob": 2.123370904882904e-06}, {"id": 294, "seek": 238312, "start": 2383.12, "end": 2398.72, "text": " get preds, we'll do TTA. Now there's no with decoded, I don't think, for TTA. So we're going", "tokens": [483, 3852, 82, 11, 321, 603, 360, 314, 8241, 13, 823, 456, 311, 572, 365, 979, 12340, 11, 286, 500, 380, 519, 11, 337, 314, 8241, 13, 407, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.22522466977437336, "compression_ratio": 1.3541666666666667, "no_speech_prob": 1.9947196960856672e-06}, {"id": 295, "seek": 239872, "start": 2398.72, "end": 2414.16, "text": " to have to do a bit of extra work here. So this is going to give us the probabilities and the targets.", "tokens": [281, 362, 281, 360, 257, 857, 295, 2857, 589, 510, 13, 407, 341, 307, 516, 281, 976, 505, 264, 33783, 293, 264, 12911, 13], "temperature": 0.0, "avg_logprob": -0.26268208026885986, "compression_ratio": 1.186046511627907, "no_speech_prob": 1.4970860320318025e-05}, {"id": 296, "seek": 241416, "start": 2414.16, "end": 2430.64, "text": " So the probabilities, each row is going to contain a probability for each element of the vocab.", "tokens": [50364, 407, 264, 33783, 11, 1184, 5386, 307, 516, 281, 5304, 257, 8482, 337, 1184, 4478, 295, 264, 2329, 455, 13, 51188], "temperature": 0.0, "avg_logprob": -0.2914890413698943, "compression_ratio": 1.1875, "no_speech_prob": 3.555760258677765e-06}, {"id": 297, "seek": 244416, "start": 2444.3999999999996, "end": 2446.64, "text": " So we can take a look.", "tokens": [407, 321, 393, 747, 257, 574, 13], "temperature": 0.0, "avg_logprob": -0.13050525328692267, "compression_ratio": 1.3070866141732282, "no_speech_prob": 0.0004878253967035562}, {"id": 298, "seek": 244416, "start": 2453.2, "end": 2458.3999999999996, "text": " So for each of the 3,469 things in the test set, there are 10 probabilities,", "tokens": [407, 337, 1184, 295, 264, 805, 11, 16169, 24, 721, 294, 264, 1500, 992, 11, 456, 366, 1266, 33783, 11], "temperature": 0.0, "avg_logprob": -0.13050525328692267, "compression_ratio": 1.3070866141732282, "no_speech_prob": 0.0004878253967035562}, {"id": 299, "seek": 244416, "start": 2458.3999999999996, "end": 2466.72, "text": " which presumably means the length of the vocab is 10, which it is.", "tokens": [597, 26742, 1355, 264, 4641, 295, 264, 2329, 455, 307, 1266, 11, 597, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.13050525328692267, "compression_ratio": 1.3070866141732282, "no_speech_prob": 0.0004878253967035562}, {"id": 300, "seek": 246672, "start": 2466.72, "end": 2472.0, "text": " Great. So what we want to do is find out, well, what's it actually predicting? And the thing", "tokens": [3769, 13, 407, 437, 321, 528, 281, 360, 307, 915, 484, 11, 731, 11, 437, 311, 309, 767, 32884, 30, 400, 264, 551], "temperature": 0.0, "avg_logprob": -0.22241337445317483, "compression_ratio": 1.8366336633663367, "no_speech_prob": 6.438812306441832e-06}, {"id": 301, "seek": 246672, "start": 2472.0, "end": 2476.7999999999997, "text": " it's predicting is whatever thing has the highest probability. So we're going to go through each row", "tokens": [309, 311, 32884, 307, 2035, 551, 575, 264, 6343, 8482, 13, 407, 321, 434, 516, 281, 352, 807, 1184, 5386], "temperature": 0.0, "avg_logprob": -0.22241337445317483, "compression_ratio": 1.8366336633663367, "no_speech_prob": 6.438812306441832e-06}, {"id": 302, "seek": 246672, "start": 2476.7999999999997, "end": 2482.72, "text": " and find the index of the thing with the highest probability. So in math and PyTorch, numpy,", "tokens": [293, 915, 264, 8186, 295, 264, 551, 365, 264, 6343, 8482, 13, 407, 294, 5221, 293, 9953, 51, 284, 339, 11, 1031, 8200, 11], "temperature": 0.0, "avg_logprob": -0.22241337445317483, "compression_ratio": 1.8366336633663367, "no_speech_prob": 6.438812306441832e-06}, {"id": 303, "seek": 246672, "start": 2482.72, "end": 2489.2, "text": " that's called argmax. So argmax is the index of the thing with the highest value. So", "tokens": [300, 311, 1219, 3882, 41167, 13, 407, 3882, 41167, 307, 264, 8186, 295, 264, 551, 365, 264, 6343, 2158, 13, 407], "temperature": 0.0, "avg_logprob": -0.22241337445317483, "compression_ratio": 1.8366336633663367, "no_speech_prob": 6.438812306441832e-06}, {"id": 304, "seek": 248920, "start": 2489.2, "end": 2497.6, "text": " probs.argmax. And so what do we want to take the maximum over, which dimension?", "tokens": [1239, 82, 13, 33544, 41167, 13, 400, 370, 437, 360, 321, 528, 281, 747, 264, 6674, 670, 11, 597, 10139, 30], "temperature": 0.0, "avg_logprob": -0.42201054890950523, "compression_ratio": 1.3539823008849559, "no_speech_prob": 4.157299827056704e-06}, {"id": 305, "seek": 248920, "start": 2498.3199999999997, "end": 2505.12, "text": " So we want to do it over rows, which I think we say dimension equals one.", "tokens": [407, 321, 528, 281, 360, 309, 670, 13241, 11, 597, 286, 519, 321, 584, 10139, 6915, 472, 13], "temperature": 0.0, "avg_logprob": -0.42201054890950523, "compression_ratio": 1.3539823008849559, "no_speech_prob": 4.157299827056704e-06}, {"id": 306, "seek": 250512, "start": 2505.12, "end": 2512.08, "text": " There we go. So that's the correct shape. So now we should be able to do the same thing we did yesterday,", "tokens": [821, 321, 352, 13, 407, 300, 311, 264, 3006, 3909, 13, 407, 586, 321, 820, 312, 1075, 281, 360, 264, 912, 551, 321, 630, 5186, 11], "temperature": 0.2, "avg_logprob": -0.3675075693333403, "compression_ratio": 1.3412698412698412, "no_speech_prob": 3.08947551275196e-06}, {"id": 307, "seek": 250512, "start": 2512.08, "end": 2529.6, "text": " which is to convert that into a series. And we can see that the", "tokens": [597, 307, 281, 7620, 300, 666, 257, 2638, 13, 400, 321, 393, 536, 300, 264], "temperature": 0.2, "avg_logprob": -0.3675075693333403, "compression_ratio": 1.3412698412698412, "no_speech_prob": 3.08947551275196e-06}, {"id": 308, "seek": 252960, "start": 2529.6, "end": 2535.68, "text": " matrix is now going to be running the same thing. So we're going to use this to convert that into a series.", "tokens": [8141, 307, 586, 516, 281, 312, 2614, 264, 912, 551, 13, 407, 321, 434, 516, 281, 764, 341, 281, 7620, 300, 666, 257, 2638, 13], "temperature": 0.2, "avg_logprob": -0.8600294075760186, "compression_ratio": 1.4335664335664335, "no_speech_prob": 1.3925341590947937e-06}, {"id": 309, "seek": 252960, "start": 2539.52, "end": 2550.56, "text": " And now we should be able to run this mapping. Now I realize actually this thing we did yesterday", "tokens": [400, 586, 321, 820, 312, 1075, 281, 1190, 341, 18350, 13, 823, 286, 4325, 767, 341, 551, 321, 630, 5186], "temperature": 0.2, "avg_logprob": -0.8600294075760186, "compression_ratio": 1.4335664335664335, "no_speech_prob": 1.3925341590947937e-06}, {"id": 310, "seek": 255056, "start": 2550.56, "end": 2562.88, "text": " a really long way of just saying create a dictionary from those tuples.", "tokens": [257, 534, 938, 636, 295, 445, 1566, 1884, 257, 25890, 490, 729, 2604, 2622, 13], "temperature": 0.0, "avg_logprob": -0.13042467662266322, "compression_ratio": 1.3298969072164948, "no_speech_prob": 1.1842924322991166e-05}, {"id": 311, "seek": 255056, "start": 2563.68, "end": 2568.4, "text": " So when you create a dictionary, you can do it like this.", "tokens": [407, 562, 291, 1884, 257, 25890, 11, 291, 393, 360, 309, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.13042467662266322, "compression_ratio": 1.3298969072164948, "no_speech_prob": 1.1842924322991166e-05}, {"id": 312, "seek": 256840, "start": 2568.4, "end": 2572.7200000000003, "text": " Or you could do this.", "tokens": [1610, 291, 727, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.7169211251395089, "compression_ratio": 0.94, "no_speech_prob": 3.0716426408616826e-05}, {"id": 313, "seek": 256840, "start": 2578.56, "end": 2582.7200000000003, "text": " Here's a tuple of tuples.", "tokens": [1692, 311, 257, 2604, 781, 295, 2604, 2622, 13], "temperature": 0.0, "avg_logprob": -0.7169211251395089, "compression_ratio": 0.94, "no_speech_prob": 3.0716426408616826e-05}, {"id": 314, "seek": 258272, "start": 2582.72, "end": 2592.9599999999996, "text": " Here's a tuple of tuples.", "tokens": [1692, 311, 257, 2604, 781, 295, 2604, 2622, 13], "temperature": 0.0, "avg_logprob": -0.34522247314453125, "compression_ratio": 1.391304347826087, "no_speech_prob": 4.7850394366832916e-06}, {"id": 315, "seek": 258272, "start": 2599.12, "end": 2601.4399999999996, "text": " Okay, sorry. Here's a tuple of tuples.", "tokens": [1033, 11, 2597, 13, 1692, 311, 257, 2604, 781, 295, 2604, 2622, 13], "temperature": 0.0, "avg_logprob": -0.34522247314453125, "compression_ratio": 1.391304347826087, "no_speech_prob": 4.7850394366832916e-06}, {"id": 316, "seek": 260144, "start": 2601.44, "end": 2615.36, "text": " And ideally what we'd like is to call dict and pass in each pair of these as an argument to it.", "tokens": [400, 22915, 437, 321, 1116, 411, 307, 281, 818, 12569, 293, 1320, 294, 1184, 6119, 295, 613, 382, 364, 6770, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.09387701115709671, "compression_ratio": 1.3507462686567164, "no_speech_prob": 2.9479801924026106e-06}, {"id": 317, "seek": 260144, "start": 2616.48, "end": 2621.6, "text": " And so Python actually has syntax to do exactly that for any function, not just dict,", "tokens": [400, 370, 15329, 767, 575, 28431, 281, 360, 2293, 300, 337, 604, 2445, 11, 406, 445, 12569, 11], "temperature": 0.0, "avg_logprob": -0.09387701115709671, "compression_ratio": 1.3507462686567164, "no_speech_prob": 2.9479801924026106e-06}, {"id": 318, "seek": 262160, "start": 2621.6, "end": 2631.92, "text": " which is the function star star. And star star means take a mapping and pass it in as pairs.", "tokens": [597, 307, 264, 2445, 3543, 3543, 13, 400, 3543, 3543, 1355, 747, 257, 18350, 293, 1320, 309, 294, 382, 15494, 13], "temperature": 0.0, "avg_logprob": -0.13803033395247025, "compression_ratio": 1.3478260869565217, "no_speech_prob": 2.190732175222365e-06}, {"id": 319, "seek": 262160, "start": 2636.88, "end": 2642.08, "text": " So that's what this does, right? That's going to be a mapping,", "tokens": [407, 300, 311, 437, 341, 775, 11, 558, 30, 663, 311, 516, 281, 312, 257, 18350, 11], "temperature": 0.0, "avg_logprob": -0.13803033395247025, "compression_ratio": 1.3478260869565217, "no_speech_prob": 2.190732175222365e-06}, {"id": 320, "seek": 264208, "start": 2642.08, "end": 2651.92, "text": " which enumerate already is. So that's what star star. Let's just pop this here.", "tokens": [597, 465, 15583, 473, 1217, 307, 13, 407, 300, 311, 437, 3543, 3543, 13, 961, 311, 445, 1665, 341, 510, 13], "temperature": 0.0, "avg_logprob": -0.32020363153195847, "compression_ratio": 1.3088235294117647, "no_speech_prob": 5.862736088602105e-06}, {"id": 321, "seek": 264208, "start": 2653.92, "end": 2659.12, "text": " Why is this not working? I expected this to work. How annoying.", "tokens": [1545, 307, 341, 406, 1364, 30, 286, 5176, 341, 281, 589, 13, 1012, 11304, 13], "temperature": 0.0, "avg_logprob": -0.32020363153195847, "compression_ratio": 1.3088235294117647, "no_speech_prob": 5.862736088602105e-06}, {"id": 322, "seek": 265912, "start": 2659.12, "end": 2668.96, "text": " How annoying. Well, so much for that discussion.", "tokens": [1012, 11304, 13, 1042, 11, 370, 709, 337, 300, 5017, 13], "temperature": 0.0, "avg_logprob": -0.1910779564468949, "compression_ratio": 1.323943661971831, "no_speech_prob": 5.014678208681289e-06}, {"id": 323, "seek": 265912, "start": 2676.56, "end": 2681.3599999999997, "text": " Annoying. All right, I'm going to have to try to think of a better way to make this work.", "tokens": [8860, 939, 278, 13, 1057, 558, 11, 286, 478, 516, 281, 362, 281, 853, 281, 519, 295, 257, 1101, 636, 281, 652, 341, 589, 13], "temperature": 0.0, "avg_logprob": -0.1910779564468949, "compression_ratio": 1.323943661971831, "no_speech_prob": 5.014678208681289e-06}, {"id": 324, "seek": 268136, "start": 2681.36, "end": 2688.48, "text": " Because so far, similar problem to what we had yesterday.", "tokens": [1436, 370, 1400, 11, 2531, 1154, 281, 437, 321, 632, 5186, 13], "temperature": 0.0, "avg_logprob": -0.2094942569732666, "compression_ratio": 1.3161290322580645, "no_speech_prob": 3.169214687659405e-05}, {"id": 325, "seek": 268136, "start": 2693.6800000000003, "end": 2696.2400000000002, "text": " I think you don't need the star star in that case.", "tokens": [286, 519, 291, 500, 380, 643, 264, 3543, 3543, 294, 300, 1389, 13], "temperature": 0.0, "avg_logprob": -0.2094942569732666, "compression_ratio": 1.3161290322580645, "no_speech_prob": 3.169214687659405e-05}, {"id": 326, "seek": 268136, "start": 2699.36, "end": 2706.2400000000002, "text": " Wow, that's nice, isn't it? Even better. Thanks for the trick. Okay. I didn't quite get to show", "tokens": [3153, 11, 300, 311, 1481, 11, 1943, 380, 309, 30, 2754, 1101, 13, 2561, 337, 264, 4282, 13, 1033, 13, 286, 994, 380, 1596, 483, 281, 855], "temperature": 0.0, "avg_logprob": -0.2094942569732666, "compression_ratio": 1.3161290322580645, "no_speech_prob": 3.169214687659405e-05}, {"id": 327, "seek": 270624, "start": 2706.24, "end": 2716.7999999999997, "text": " you about how cool star star is, but never mind. Okay. So what I'm going to do is I'm going to", "tokens": [291, 466, 577, 1627, 3543, 3543, 307, 11, 457, 1128, 1575, 13, 1033, 13, 407, 437, 286, 478, 516, 281, 360, 307, 286, 478, 516, 281], "temperature": 0.0, "avg_logprob": -0.13083562227053064, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.777738543751184e-05}, {"id": 328, "seek": 270624, "start": 2716.7999999999997, "end": 2722.3999999999996, "text": " make a copy of the last time we did ahead of the submission. And one reason I like to do that", "tokens": [652, 257, 5055, 295, 264, 1036, 565, 321, 630, 2286, 295, 264, 23689, 13, 400, 472, 1778, 286, 411, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.13083562227053064, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.777738543751184e-05}, {"id": 329, "seek": 270624, "start": 2722.3999999999996, "end": 2727.52, "text": " for my new submission is to confirm that our new one looks somewhat similar. So previously,", "tokens": [337, 452, 777, 23689, 307, 281, 9064, 300, 527, 777, 472, 1542, 8344, 2531, 13, 407, 8046, 11], "temperature": 0.0, "avg_logprob": -0.13083562227053064, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.777738543751184e-05}, {"id": 330, "seek": 270624, "start": 2727.52, "end": 2732.3199999999997, "text": " we went hisp-normal, downy, blast-blast. Now we go hisp-normal, blast-blast-blast.", "tokens": [321, 1437, 702, 79, 12, 23157, 11, 760, 88, 11, 12035, 12, 5199, 525, 13, 823, 321, 352, 702, 79, 12, 23157, 11, 12035, 12, 5199, 525, 12, 5199, 525, 13], "temperature": 0.0, "avg_logprob": -0.13083562227053064, "compression_ratio": 1.665137614678899, "no_speech_prob": 1.777738543751184e-05}, {"id": 331, "seek": 273232, "start": 2732.32, "end": 2737.28, "text": " And so this makes me feel comfortable that, okay, we haven't totally broken things. It's still giving", "tokens": [400, 370, 341, 1669, 385, 841, 4619, 300, 11, 1392, 11, 321, 2378, 380, 3879, 5463, 721, 13, 467, 311, 920, 2902], "temperature": 0.0, "avg_logprob": -0.1014831795984385, "compression_ratio": 1.652542372881356, "no_speech_prob": 9.223042980011087e-06}, {"id": 332, "seek": 273232, "start": 2738.4, "end": 2744.0800000000004, "text": " largely the same results as before with a few changes. And so that's just something I like to do.", "tokens": [11611, 264, 912, 3542, 382, 949, 365, 257, 1326, 2962, 13, 400, 370, 300, 311, 445, 746, 286, 411, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.1014831795984385, "compression_ratio": 1.652542372881356, "no_speech_prob": 9.223042980011087e-06}, {"id": 333, "seek": 273232, "start": 2744.0800000000004, "end": 2753.6800000000003, "text": " Okay. And then another thing I like to do is kind of keep track of stuff I've done before. I try", "tokens": [1033, 13, 400, 550, 1071, 551, 286, 411, 281, 360, 307, 733, 295, 1066, 2837, 295, 1507, 286, 600, 1096, 949, 13, 286, 853], "temperature": 0.0, "avg_logprob": -0.1014831795984385, "compression_ratio": 1.652542372881356, "no_speech_prob": 9.223042980011087e-06}, {"id": 334, "seek": 273232, "start": 2753.6800000000003, "end": 2757.6000000000004, "text": " not to delete things I've used before and just pop it into a different notebook or a comment.", "tokens": [406, 281, 12097, 721, 286, 600, 1143, 949, 293, 445, 1665, 309, 666, 257, 819, 21060, 420, 257, 2871, 13], "temperature": 0.0, "avg_logprob": -0.1014831795984385, "compression_ratio": 1.652542372881356, "no_speech_prob": 9.223042980011087e-06}, {"id": 335, "seek": 275760, "start": 2757.6, "end": 2763.04, "text": " So down here, I'm just going to have non-TTA version just in case I want that again later.", "tokens": [407, 760, 510, 11, 286, 478, 445, 516, 281, 362, 2107, 12, 51, 8241, 3037, 445, 294, 1389, 286, 528, 300, 797, 1780, 13], "temperature": 0.0, "avg_logprob": -0.13699500505314316, "compression_ratio": 1.2347826086956522, "no_speech_prob": 7.889107109804172e-06}, {"id": 336, "seek": 275760, "start": 2765.36, "end": 2769.2799999999997, "text": " All right. So we should be able to submit that now.", "tokens": [1057, 558, 13, 407, 321, 820, 312, 1075, 281, 10315, 300, 586, 13], "temperature": 0.0, "avg_logprob": -0.13699500505314316, "compression_ratio": 1.2347826086956522, "no_speech_prob": 7.889107109804172e-06}, {"id": 337, "seek": 276928, "start": 2769.28, "end": 2778.5600000000004, "text": " Okay. So I used Ctrl-R and then started typing competitions. Okay. So this is now a", "tokens": [1033, 13, 407, 286, 1143, 35233, 12, 49, 293, 550, 1409, 18444, 26185, 13, 1033, 13, 407, 341, 307, 586, 257], "temperature": 0.0, "avg_logprob": -0.4496913528442383, "compression_ratio": 1.0121951219512195, "no_speech_prob": 3.393103042981238e-06}, {"id": 338, "seek": 277856, "start": 2778.56, "end": 2801.92, "text": " squish, convnext, small, 12 epoch, fine-tune, tta.", "tokens": [31379, 11, 3754, 716, 734, 11, 1359, 11, 2272, 30992, 339, 11, 2489, 12, 83, 2613, 11, 256, 1328, 13], "temperature": 0.0, "avg_logprob": -0.5519291957219442, "compression_ratio": 0.8771929824561403, "no_speech_prob": 1.9637870991573436e-06}, {"id": 339, "seek": 280192, "start": 2801.92, "end": 2815.36, "text": " Uh-huh.", "tokens": [50364, 4019, 12, 18710, 13, 51036], "temperature": 1.0, "avg_logprob": -2.226806776864188, "compression_ratio": 0.4666666666666667, "no_speech_prob": 0.0003679848159663379}, {"id": 340, "seek": 283192, "start": 2831.92, "end": 2834.92, "text": " What on earth did it do to my window?", "tokens": [708, 322, 4120, 630, 309, 360, 281, 452, 4910, 30], "temperature": 0.0, "avg_logprob": -0.2830783231758777, "compression_ratio": 1.4183006535947713, "no_speech_prob": 0.0054670716635882854}, {"id": 341, "seek": 283192, "start": 2834.92, "end": 2837.92, "text": " How do I get it back?", "tokens": [1012, 360, 286, 483, 309, 646, 30], "temperature": 0.0, "avg_logprob": -0.2830783231758777, "compression_ratio": 1.4183006535947713, "no_speech_prob": 0.0054670716635882854}, {"id": 342, "seek": 283192, "start": 2843.92, "end": 2845.92, "text": " Oh, it...", "tokens": [876, 11, 309, 485], "temperature": 0.0, "avg_logprob": -0.2830783231758777, "compression_ratio": 1.4183006535947713, "no_speech_prob": 0.0054670716635882854}, {"id": 343, "seek": 283192, "start": 2845.92, "end": 2847.92, "text": " Oh, I see, I've got to...", "tokens": [876, 11, 286, 536, 11, 286, 600, 658, 281, 485], "temperature": 0.0, "avg_logprob": -0.2830783231758777, "compression_ratio": 1.4183006535947713, "no_speech_prob": 0.0054670716635882854}, {"id": 344, "seek": 283192, "start": 2847.92, "end": 2849.92, "text": " How does that happen? I've got to...", "tokens": [1012, 775, 300, 1051, 30, 286, 600, 658, 281, 485], "temperature": 0.0, "avg_logprob": -0.2830783231758777, "compression_ratio": 1.4183006535947713, "no_speech_prob": 0.0054670716635882854}, {"id": 345, "seek": 283192, "start": 2849.92, "end": 2851.92, "text": " It just stops going.", "tokens": [467, 445, 10094, 516, 13], "temperature": 0.0, "avg_logprob": -0.2830783231758777, "compression_ratio": 1.4183006535947713, "no_speech_prob": 0.0054670716635882854}, {"id": 346, "seek": 283192, "start": 2851.92, "end": 2853.92, "text": " I didn't notice that.", "tokens": [286, 994, 380, 3449, 300, 13], "temperature": 0.0, "avg_logprob": -0.2830783231758777, "compression_ratio": 1.4183006535947713, "no_speech_prob": 0.0054670716635882854}, {"id": 347, "seek": 285392, "start": 2853.92, "end": 2861.92, "text": " Alright, let's go and check out Kaggle.", "tokens": [2798, 11, 718, 311, 352, 293, 1520, 484, 48751, 22631, 13], "temperature": 0.0, "avg_logprob": -0.19224165331932805, "compression_ratio": 1.2797202797202798, "no_speech_prob": 4.677946344600059e-05}, {"id": 348, "seek": 285392, "start": 2865.92, "end": 2867.92, "text": " My submissions.", "tokens": [1222, 40429, 13], "temperature": 0.0, "avg_logprob": -0.19224165331932805, "compression_ratio": 1.2797202797202798, "no_speech_prob": 4.677946344600059e-05}, {"id": 349, "seek": 285392, "start": 2870.92, "end": 2873.92, "text": " Oh, look at that. Harada's still beating us, I think.", "tokens": [876, 11, 574, 412, 300, 13, 3653, 1538, 311, 920, 13497, 505, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.19224165331932805, "compression_ratio": 1.2797202797202798, "no_speech_prob": 4.677946344600059e-05}, {"id": 350, "seek": 285392, "start": 2873.92, "end": 2876.92, "text": " But at least we've beaten our previous one.", "tokens": [583, 412, 1935, 321, 600, 17909, 527, 3894, 472, 13], "temperature": 0.0, "avg_logprob": -0.19224165331932805, "compression_ratio": 1.2797202797202798, "no_speech_prob": 4.677946344600059e-05}, {"id": 351, "seek": 285392, "start": 2876.92, "end": 2878.92, "text": " That's amazing.", "tokens": [663, 311, 2243, 13], "temperature": 0.0, "avg_logprob": -0.19224165331932805, "compression_ratio": 1.2797202797202798, "no_speech_prob": 4.677946344600059e-05}, {"id": 352, "seek": 285392, "start": 2878.92, "end": 2880.92, "text": " That's great.", "tokens": [663, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.19224165331932805, "compression_ratio": 1.2797202797202798, "no_speech_prob": 4.677946344600059e-05}, {"id": 353, "seek": 288092, "start": 2880.92, "end": 2887.92, "text": " Jump to our leadable position, we're going to have a good battle on...", "tokens": [18697, 281, 527, 1477, 712, 2535, 11, 321, 434, 516, 281, 362, 257, 665, 4635, 322, 485], "temperature": 0.0, "avg_logprob": -0.14300994267539371, "compression_ratio": 1.3049645390070923, "no_speech_prob": 9.154838335234672e-05}, {"id": 354, "seek": 288092, "start": 2887.92, "end": 2890.92, "text": " 34.", "tokens": [12790, 13], "temperature": 0.0, "avg_logprob": -0.14300994267539371, "compression_ratio": 1.3049645390070923, "no_speech_prob": 9.154838335234672e-05}, {"id": 355, "seek": 288092, "start": 2890.92, "end": 2893.92, "text": " No, I think you beat me up.", "tokens": [883, 11, 286, 519, 291, 4224, 385, 493, 13], "temperature": 0.0, "avg_logprob": -0.14300994267539371, "compression_ratio": 1.3049645390070923, "no_speech_prob": 9.154838335234672e-05}, {"id": 356, "seek": 288092, "start": 2893.92, "end": 2897.92, "text": " Wait, I thought yours was better than that.", "tokens": [3802, 11, 286, 1194, 6342, 390, 1101, 813, 300, 13], "temperature": 0.0, "avg_logprob": -0.14300994267539371, "compression_ratio": 1.3049645390070923, "no_speech_prob": 9.154838335234672e-05}, {"id": 357, "seek": 288092, "start": 2897.92, "end": 2902.92, "text": " I think I'm a little bit lower.", "tokens": [286, 519, 286, 478, 257, 707, 857, 3126, 13], "temperature": 0.0, "avg_logprob": -0.14300994267539371, "compression_ratio": 1.3049645390070923, "no_speech_prob": 9.154838335234672e-05}, {"id": 358, "seek": 288092, "start": 2902.92, "end": 2905.92, "text": " Code.", "tokens": [15549, 13], "temperature": 0.0, "avg_logprob": -0.14300994267539371, "compression_ratio": 1.3049645390070923, "no_speech_prob": 9.154838335234672e-05}, {"id": 359, "seek": 290592, "start": 2905.92, "end": 2910.92, "text": " Oh, you were 97385.", "tokens": [876, 11, 291, 645, 23399, 12625, 20, 13], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 360, "seek": 290592, "start": 2910.92, "end": 2912.92, "text": " Okay, 979.", "tokens": [1033, 11, 23399, 24, 13], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 361, "seek": 290592, "start": 2912.92, "end": 2914.92, "text": " Ah, okay.", "tokens": [2438, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 362, "seek": 290592, "start": 2914.92, "end": 2917.92, "text": " That's not bad, right? Actually, 34th out of...", "tokens": [663, 311, 406, 1578, 11, 558, 30, 5135, 11, 12790, 392, 484, 295, 485], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 363, "seek": 290592, "start": 2917.92, "end": 2919.92, "text": " I mean, it's just a fun competition.", "tokens": [286, 914, 11, 309, 311, 445, 257, 1019, 6211, 13], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 364, "seek": 290592, "start": 2919.92, "end": 2925.92, "text": " Nobody's really trying too hard, but still, you know, it's nice to feel like you're...", "tokens": [9297, 311, 534, 1382, 886, 1152, 11, 457, 920, 11, 291, 458, 11, 309, 311, 1481, 281, 841, 411, 291, 434, 485], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 365, "seek": 290592, "start": 2925.92, "end": 2927.92, "text": " in the mix. How far are we?", "tokens": [294, 264, 2890, 13, 1012, 1400, 366, 321, 30], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 366, "seek": 290592, "start": 2927.92, "end": 2930.92, "text": " Okay, so...", "tokens": [1033, 11, 370, 485], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 367, "seek": 290592, "start": 2930.92, "end": 2933.92, "text": " This person's still way ahead, right?", "tokens": [639, 954, 311, 920, 636, 2286, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14200787317185176, "compression_ratio": 1.4077669902912622, "no_speech_prob": 3.761932021006942e-05}, {"id": 368, "seek": 293392, "start": 2933.92, "end": 2939.92, "text": " They've got an error of 1.3%, and we've got an error of 2.1%.", "tokens": [814, 600, 658, 364, 6713, 295, 502, 13, 18, 8923, 293, 321, 600, 658, 364, 6713, 295, 568, 13, 16, 6856], "temperature": 0.0, "avg_logprob": -0.12495144320205903, "compression_ratio": 1.544871794871795, "no_speech_prob": 0.00010675481462385505}, {"id": 369, "seek": 293392, "start": 2943.92, "end": 2947.92, "text": " You know, something else that would be fun would be...", "tokens": [509, 458, 11, 746, 1646, 300, 576, 312, 1019, 576, 312, 485], "temperature": 0.0, "avg_logprob": -0.12495144320205903, "compression_ratio": 1.544871794871795, "no_speech_prob": 0.00010675481462385505}, {"id": 370, "seek": 293392, "start": 2950.92, "end": 2954.92, "text": " You know, you can kind of super easily create an ensemble.", "tokens": [509, 458, 11, 291, 393, 733, 295, 1687, 3612, 1884, 364, 19492, 13], "temperature": 0.0, "avg_logprob": -0.12495144320205903, "compression_ratio": 1.544871794871795, "no_speech_prob": 0.00010675481462385505}, {"id": 371, "seek": 293392, "start": 2954.92, "end": 2958.92, "text": " So maybe I'll show you how I would go about creating an ensemble.", "tokens": [407, 1310, 286, 603, 855, 291, 577, 286, 576, 352, 466, 4084, 364, 19492, 13], "temperature": 0.0, "avg_logprob": -0.12495144320205903, "compression_ratio": 1.544871794871795, "no_speech_prob": 0.00010675481462385505}, {"id": 372, "seek": 295892, "start": 2958.92, "end": 2965.92, "text": " To create an ensemble, I would be inclined to maybe...", "tokens": [1407, 1884, 364, 19492, 11, 286, 576, 312, 28173, 281, 1310, 485], "temperature": 0.0, "avg_logprob": -0.12232556836358432, "compression_ratio": 1.4407894736842106, "no_speech_prob": 9.665366633271333e-06}, {"id": 373, "seek": 295892, "start": 2970.92, "end": 2976.92, "text": " We could create an ensemble with an unsquished version, for instance.", "tokens": [492, 727, 1884, 364, 19492, 365, 364, 2693, 358, 4729, 3037, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.12232556836358432, "compression_ratio": 1.4407894736842106, "no_speech_prob": 9.665366633271333e-06}, {"id": 374, "seek": 295892, "start": 2976.92, "end": 2983.92, "text": " So what I would do is I'd kind of like copy all the stuff that we used to get our predictions.", "tokens": [407, 437, 286, 576, 360, 307, 286, 1116, 733, 295, 411, 5055, 439, 264, 1507, 300, 321, 1143, 281, 483, 527, 21264, 13], "temperature": 0.0, "avg_logprob": -0.12232556836358432, "compression_ratio": 1.4407894736842106, "no_speech_prob": 9.665366633271333e-06}, {"id": 375, "seek": 298392, "start": 2983.92, "end": 2988.92, "text": " Right? And then I would kind of paste them down here.", "tokens": [1779, 30, 400, 550, 286, 576, 733, 295, 9163, 552, 760, 510, 13], "temperature": 0.0, "avg_logprob": -0.1952156639099121, "compression_ratio": 1.2283464566929134, "no_speech_prob": 5.649130616802722e-05}, {"id": 376, "seek": 298392, "start": 2988.92, "end": 2994.92, "text": " Go through and remove the stuff that isn't quite needed.", "tokens": [1037, 807, 293, 4159, 264, 1507, 300, 1943, 380, 1596, 2978, 13], "temperature": 0.0, "avg_logprob": -0.1952156639099121, "compression_ratio": 1.2283464566929134, "no_speech_prob": 5.649130616802722e-05}, {"id": 377, "seek": 298392, "start": 2994.92, "end": 2996.92, "text": " Like so.", "tokens": [1743, 370, 13], "temperature": 0.0, "avg_logprob": -0.1952156639099121, "compression_ratio": 1.2283464566929134, "no_speech_prob": 5.649130616802722e-05}, {"id": 378, "seek": 298392, "start": 3003.92, "end": 3006.92, "text": " This one's going to be...", "tokens": [639, 472, 311, 516, 281, 312, 485], "temperature": 0.0, "avg_logprob": -0.1952156639099121, "compression_ratio": 1.2283464566929134, "no_speech_prob": 5.649130616802722e-05}, {"id": 379, "seek": 298392, "start": 3007.92, "end": 3009.92, "text": " No squish.", "tokens": [883, 31379, 13], "temperature": 0.0, "avg_logprob": -0.1952156639099121, "compression_ratio": 1.2283464566929134, "no_speech_prob": 5.649130616802722e-05}, {"id": 380, "seek": 300992, "start": 3009.92, "end": 3012.92, "text": " And...", "tokens": [400, 485], "temperature": 0.0, "avg_logprob": -0.30253662381853375, "compression_ratio": 1.2123893805309736, "no_speech_prob": 2.1781450413982384e-05}, {"id": 381, "seek": 300992, "start": 3013.92, "end": 3015.92, "text": " I'll do max.", "tokens": [286, 603, 360, 11469, 13], "temperature": 0.0, "avg_logprob": -0.30253662381853375, "compression_ratio": 1.2123893805309736, "no_speech_prob": 2.1781450413982384e-05}, {"id": 382, "seek": 300992, "start": 3015.92, "end": 3017.92, "text": " Use max.", "tokens": [8278, 11469, 13], "temperature": 0.0, "avg_logprob": -0.30253662381853375, "compression_ratio": 1.2123893805309736, "no_speech_prob": 2.1781450413982384e-05}, {"id": 383, "seek": 300992, "start": 3018.92, "end": 3020.92, "text": " Calls true.", "tokens": [7807, 82, 2074, 13], "temperature": 0.0, "avg_logprob": -0.30253662381853375, "compression_ratio": 1.2123893805309736, "no_speech_prob": 2.1781450413982384e-05}, {"id": 384, "seek": 300992, "start": 3022.92, "end": 3027.92, "text": " And so then to merge cells, it's shift-M, M for merge.", "tokens": [400, 370, 550, 281, 22183, 5438, 11, 309, 311, 5513, 12, 44, 11, 376, 337, 22183, 13], "temperature": 0.0, "avg_logprob": -0.30253662381853375, "compression_ratio": 1.2123893805309736, "no_speech_prob": 2.1781450413982384e-05}, {"id": 385, "seek": 300992, "start": 3031.92, "end": 3033.92, "text": " And...", "tokens": [400, 485], "temperature": 0.0, "avg_logprob": -0.30253662381853375, "compression_ratio": 1.2123893805309736, "no_speech_prob": 2.1781450413982384e-05}, {"id": 386, "seek": 303392, "start": 3033.92, "end": 3038.92, "text": " Don't need the error rate anymore.", "tokens": [1468, 380, 643, 264, 6713, 3314, 3602, 13], "temperature": 0.0, "avg_logprob": -0.1478223482767741, "compression_ratio": 1.4533333333333334, "no_speech_prob": 4.092801191291073e-06}, {"id": 387, "seek": 303392, "start": 3044.92, "end": 3050.92, "text": " And so this is going to be a second set of probabilities and a second set of targets.", "tokens": [400, 370, 341, 307, 516, 281, 312, 257, 1150, 992, 295, 33783, 293, 257, 1150, 992, 295, 12911, 13], "temperature": 0.0, "avg_logprob": -0.1478223482767741, "compression_ratio": 1.4533333333333334, "no_speech_prob": 4.092801191291073e-06}, {"id": 388, "seek": 303392, "start": 3051.92, "end": 3058.92, "text": " Yeah, so we could just run that and take the average of these two models.", "tokens": [865, 11, 370, 321, 727, 445, 1190, 300, 293, 747, 264, 4274, 295, 613, 732, 5245, 13], "temperature": 0.0, "avg_logprob": -0.1478223482767741, "compression_ratio": 1.4533333333333334, "no_speech_prob": 4.092801191291073e-06}, {"id": 389, "seek": 303392, "start": 3058.92, "end": 3060.92, "text": " Oh, remove squish here.", "tokens": [876, 11, 4159, 31379, 510, 13], "temperature": 0.0, "avg_logprob": -0.1478223482767741, "compression_ratio": 1.4533333333333334, "no_speech_prob": 4.092801191291073e-06}, {"id": 390, "seek": 306092, "start": 3060.92, "end": 3064.92, "text": " Okay, so that might be our third model.", "tokens": [1033, 11, 370, 300, 1062, 312, 527, 2636, 2316, 13], "temperature": 0.0, "avg_logprob": -0.12691476345062255, "compression_ratio": 1.2733333333333334, "no_speech_prob": 8.013194019440562e-06}, {"id": 391, "seek": 306092, "start": 3064.92, "end": 3070.92, "text": " And then another model I would be inclined to try is one that doesn't use square.", "tokens": [400, 550, 1071, 2316, 286, 576, 312, 28173, 281, 853, 307, 472, 300, 1177, 380, 764, 3732, 13], "temperature": 0.0, "avg_logprob": -0.12691476345062255, "compression_ratio": 1.2733333333333334, "no_speech_prob": 8.013194019440562e-06}, {"id": 392, "seek": 306092, "start": 3072.92, "end": 3078.92, "text": " So we've got 640 by 480 images, right?", "tokens": [407, 321, 600, 658, 1386, 5254, 538, 1017, 4702, 5267, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.12691476345062255, "compression_ratio": 1.2733333333333334, "no_speech_prob": 8.013194019440562e-06}, {"id": 393, "seek": 306092, "start": 3080.92, "end": 3084.92, "text": " So the aspect ratio is 4 to 3.", "tokens": [407, 264, 4171, 8509, 307, 1017, 281, 805, 13], "temperature": 0.0, "avg_logprob": -0.12691476345062255, "compression_ratio": 1.2733333333333334, "no_speech_prob": 8.013194019440562e-06}, {"id": 394, "seek": 308492, "start": 3084.92, "end": 3094.92, "text": " So I would be inclined to say take that and multiply that by the smaller side we want.", "tokens": [407, 286, 576, 312, 28173, 281, 584, 747, 300, 293, 12972, 300, 538, 264, 4356, 1252, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.10205107024221709, "compression_ratio": 1.3652694610778444, "no_speech_prob": 2.123350895999465e-06}, {"id": 395, "seek": 308492, "start": 3094.92, "end": 3100.92, "text": " Okay, that gives us 298.66.", "tokens": [1033, 11, 300, 2709, 505, 9413, 23, 13, 15237, 13], "temperature": 0.0, "avg_logprob": -0.10205107024221709, "compression_ratio": 1.3652694610778444, "no_speech_prob": 2.123350895999465e-06}, {"id": 396, "seek": 308492, "start": 3103.92, "end": 3108.92, "text": " It'd be nice to find something that works a bit more evenly, wouldn't it?", "tokens": [467, 1116, 312, 1481, 281, 915, 746, 300, 1985, 257, 857, 544, 17658, 11, 2759, 380, 309, 30], "temperature": 0.0, "avg_logprob": -0.10205107024221709, "compression_ratio": 1.3652694610778444, "no_speech_prob": 2.123350895999465e-06}, {"id": 397, "seek": 310892, "start": 3108.92, "end": 3113.92, "text": " What if we did it the other way around?", "tokens": [708, 498, 321, 630, 309, 264, 661, 636, 926, 30], "temperature": 0.0, "avg_logprob": -0.20407600402832032, "compression_ratio": 1.1746031746031746, "no_speech_prob": 7.888976142567117e-06}, {"id": 398, "seek": 310892, "start": 3114.92, "end": 3121.92, "text": " So we could create 168 by 224 images, for instance, or...", "tokens": [407, 321, 727, 1884, 3165, 23, 538, 5853, 19, 5267, 11, 337, 5197, 11, 420, 485], "temperature": 0.0, "avg_logprob": -0.20407600402832032, "compression_ratio": 1.1746031746031746, "no_speech_prob": 7.888976142567117e-06}, {"id": 399, "seek": 310892, "start": 3129.92, "end": 3131.92, "text": " 336 maybe?", "tokens": [805, 11309, 1310, 30], "temperature": 0.0, "avg_logprob": -0.20407600402832032, "compression_ratio": 1.1746031746031746, "no_speech_prob": 7.888976142567117e-06}, {"id": 400, "seek": 310892, "start": 3132.92, "end": 3134.92, "text": " 336 by 252 images?", "tokens": [805, 11309, 538, 3552, 17, 5267, 30], "temperature": 0.0, "avg_logprob": -0.20407600402832032, "compression_ratio": 1.1746031746031746, "no_speech_prob": 7.888976142567117e-06}, {"id": 401, "seek": 313492, "start": 3134.92, "end": 3138.92, "text": " Yeah, let's do that.", "tokens": [865, 11, 718, 311, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.13706427354079026, "compression_ratio": 1.1953125, "no_speech_prob": 8.939449799072463e-06}, {"id": 402, "seek": 313492, "start": 3138.92, "end": 3142.92, "text": " So let's change this size.", "tokens": [407, 718, 311, 1319, 341, 2744, 13], "temperature": 0.0, "avg_logprob": -0.13706427354079026, "compression_ratio": 1.1953125, "no_speech_prob": 8.939449799072463e-06}, {"id": 403, "seek": 313492, "start": 3150.92, "end": 3154.92, "text": " And I never quite remember which way around it is, but that's okay, we'll check it.", "tokens": [400, 286, 1128, 1596, 1604, 597, 636, 926, 309, 307, 11, 457, 300, 311, 1392, 11, 321, 603, 1520, 309, 13], "temperature": 0.0, "avg_logprob": -0.13706427354079026, "compression_ratio": 1.1953125, "no_speech_prob": 8.939449799072463e-06}, {"id": 404, "seek": 315492, "start": 3154.92, "end": 3164.92, "text": " So 336 by 252 images.", "tokens": [407, 805, 11309, 538, 3552, 17, 5267, 13], "temperature": 0.0, "avg_logprob": -0.07801506970379804, "compression_ratio": 1.5977653631284916, "no_speech_prob": 6.854060302430298e-06}, {"id": 405, "seek": 315492, "start": 3164.92, "end": 3169.92, "text": " And so the reason I'm doing rectangular, sorry, rectangular images is that", "tokens": [400, 370, 264, 1778, 286, 478, 884, 31167, 11, 2597, 11, 31167, 5267, 307, 300], "temperature": 0.0, "avg_logprob": -0.07801506970379804, "compression_ratio": 1.5977653631284916, "no_speech_prob": 6.854060302430298e-06}, {"id": 406, "seek": 315492, "start": 3169.92, "end": 3175.92, "text": " all of our input images are the same aspect ratio, so there's no particular reason to make them square.", "tokens": [439, 295, 527, 4846, 5267, 366, 264, 912, 4171, 8509, 11, 370, 456, 311, 572, 1729, 1778, 281, 652, 552, 3732, 13], "temperature": 0.0, "avg_logprob": -0.07801506970379804, "compression_ratio": 1.5977653631284916, "no_speech_prob": 6.854060302430298e-06}, {"id": 407, "seek": 315492, "start": 3175.92, "end": 3180.92, "text": " You know, when some of your images are wider than tall and some are taller than wide,", "tokens": [509, 458, 11, 562, 512, 295, 428, 5267, 366, 11842, 813, 6764, 293, 512, 366, 22406, 813, 4874, 11], "temperature": 0.0, "avg_logprob": -0.07801506970379804, "compression_ratio": 1.5977653631284916, "no_speech_prob": 6.854060302430298e-06}, {"id": 408, "seek": 318092, "start": 3180.92, "end": 3188.92, "text": " then it makes perfect sense to, you know, use square as your, you know, the thing that everything gets changed to.", "tokens": [550, 309, 1669, 2176, 2020, 281, 11, 291, 458, 11, 764, 3732, 382, 428, 11, 291, 458, 11, 264, 551, 300, 1203, 2170, 3105, 281, 13], "temperature": 0.0, "avg_logprob": -0.1028666191912712, "compression_ratio": 1.7149532710280373, "no_speech_prob": 2.212139224866405e-05}, {"id": 409, "seek": 318092, "start": 3188.92, "end": 3193.92, "text": " But when everything's wider than they are tall, especially when they're all the same aspect ratio,", "tokens": [583, 562, 1203, 311, 11842, 813, 436, 366, 6764, 11, 2318, 562, 436, 434, 439, 264, 912, 4171, 8509, 11], "temperature": 0.0, "avg_logprob": -0.1028666191912712, "compression_ratio": 1.7149532710280373, "no_speech_prob": 2.212139224866405e-05}, {"id": 410, "seek": 318092, "start": 3193.92, "end": 3198.92, "text": " it makes more sense to keep them at that same aspect ratio.", "tokens": [309, 1669, 544, 2020, 281, 1066, 552, 412, 300, 912, 4171, 8509, 13], "temperature": 0.0, "avg_logprob": -0.1028666191912712, "compression_ratio": 1.7149532710280373, "no_speech_prob": 2.212139224866405e-05}, {"id": 411, "seek": 318092, "start": 3198.92, "end": 3206.92, "text": " And, you know, another thing I guess we should consider doing for 640 by 380 is to, you know,", "tokens": [400, 11, 291, 458, 11, 1071, 551, 286, 2041, 321, 820, 1949, 884, 337, 1386, 5254, 538, 805, 4702, 307, 281, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1028666191912712, "compression_ratio": 1.7149532710280373, "no_speech_prob": 2.212139224866405e-05}, {"id": 412, "seek": 320692, "start": 3206.92, "end": 3213.92, "text": " you can change their resolution more gracefully without weird interpolating fuzziness", "tokens": [291, 393, 1319, 641, 8669, 544, 10042, 2277, 1553, 3657, 44902, 990, 283, 16740, 1324], "temperature": 0.0, "avg_logprob": -0.09751848947434198, "compression_ratio": 1.4271844660194175, "no_speech_prob": 1.1841839295811951e-05}, {"id": 413, "seek": 320692, "start": 3213.92, "end": 3217.92, "text": " by doing it by, you know, a factor of 2.", "tokens": [538, 884, 309, 538, 11, 291, 458, 11, 257, 5952, 295, 568, 13], "temperature": 0.0, "avg_logprob": -0.09751848947434198, "compression_ratio": 1.4271844660194175, "no_speech_prob": 1.1841839295811951e-05}, {"id": 414, "seek": 320692, "start": 3217.92, "end": 3224.92, "text": " So we could do 320 instead of 640 and by 240.", "tokens": [407, 321, 727, 360, 42429, 2602, 295, 1386, 5254, 293, 538, 26837, 13], "temperature": 0.0, "avg_logprob": -0.09751848947434198, "compression_ratio": 1.4271844660194175, "no_speech_prob": 1.1841839295811951e-05}, {"id": 415, "seek": 320692, "start": 3224.92, "end": 3227.92, "text": " So that would be another one I'd be inclined to try.", "tokens": [407, 300, 576, 312, 1071, 472, 286, 1116, 312, 28173, 281, 853, 13], "temperature": 0.0, "avg_logprob": -0.09751848947434198, "compression_ratio": 1.4271844660194175, "no_speech_prob": 1.1841839295811951e-05}, {"id": 416, "seek": 322792, "start": 3227.92, "end": 3236.92, "text": " Yeah, in fact, let's just do that. Let's make that the aspect ratio.", "tokens": [865, 11, 294, 1186, 11, 718, 311, 445, 360, 300, 13, 961, 311, 652, 300, 264, 4171, 8509, 13], "temperature": 0.0, "avg_logprob": -0.09208245370902267, "compression_ratio": 1.3307692307692307, "no_speech_prob": 1.65365963766817e-06}, {"id": 417, "seek": 322792, "start": 3236.92, "end": 3250.92, "text": " There we go. And so obviously we should check it and we know how to check it, which is to go show batch.", "tokens": [821, 321, 352, 13, 400, 370, 2745, 321, 820, 1520, 309, 293, 321, 458, 577, 281, 1520, 309, 11, 597, 307, 281, 352, 855, 15245, 13], "temperature": 0.0, "avg_logprob": -0.09208245370902267, "compression_ratio": 1.3307692307692307, "no_speech_prob": 1.65365963766817e-06}, {"id": 418, "seek": 325092, "start": 3250.92, "end": 3260.92, "text": " OK, so you can see I've got it the wrong way around.", "tokens": [2264, 11, 370, 291, 393, 536, 286, 600, 658, 309, 264, 2085, 636, 926, 13], "temperature": 0.0, "avg_logprob": -0.11689035645846663, "compression_ratio": 1.0, "no_speech_prob": 2.84070338238962e-05}, {"id": 419, "seek": 325092, "start": 3260.92, "end": 3272.92, "text": " There we go. That's better.", "tokens": [821, 321, 352, 13, 663, 311, 1101, 13], "temperature": 0.0, "avg_logprob": -0.11689035645846663, "compression_ratio": 1.0, "no_speech_prob": 2.84070338238962e-05}, {"id": 420, "seek": 327292, "start": 3272.92, "end": 3280.92, "text": " Cool.", "tokens": [8561, 13], "temperature": 0.0, "avg_logprob": -0.10487661733255758, "compression_ratio": 1.4946236559139785, "no_speech_prob": 5.421942660177592e-06}, {"id": 421, "seek": 327292, "start": 3280.92, "end": 3286.92, "text": " And like, given that we're going to have such nice clear images, I would probably do the,", "tokens": [400, 411, 11, 2212, 300, 321, 434, 516, 281, 362, 1270, 1481, 1850, 5267, 11, 286, 576, 1391, 360, 264, 11], "temperature": 0.0, "avg_logprob": -0.10487661733255758, "compression_ratio": 1.4946236559139785, "no_speech_prob": 5.421942660177592e-06}, {"id": 422, "seek": 327292, "start": 3286.92, "end": 3291.92, "text": " the affine transforms are the ones where we're zooming and rotating and stuff.", "tokens": [264, 2096, 533, 35592, 366, 264, 2306, 689, 321, 434, 48226, 293, 19627, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.10487661733255758, "compression_ratio": 1.4946236559139785, "no_speech_prob": 5.421942660177592e-06}, {"id": 423, "seek": 327292, "start": 3291.92, "end": 3300.92, "text": " So to say don't do those so often, we can change the probability of affine transforms from 0.75 to 0.5.", "tokens": [407, 281, 584, 500, 380, 360, 729, 370, 2049, 11, 321, 393, 1319, 264, 8482, 295, 2096, 533, 35592, 490, 1958, 13, 11901, 281, 1958, 13, 20, 13], "temperature": 0.0, "avg_logprob": -0.10487661733255758, "compression_ratio": 1.4946236559139785, "no_speech_prob": 5.421942660177592e-06}, {"id": 424, "seek": 330092, "start": 3300.92, "end": 3306.92, "text": " The probability of affine transforms to 0.5.", "tokens": [440, 8482, 295, 2096, 533, 35592, 281, 1958, 13, 20, 13], "temperature": 0.0, "avg_logprob": -0.12364493097577776, "compression_ratio": 1.3630136986301369, "no_speech_prob": 1.7603209698791034e-06}, {"id": 425, "seek": 330092, "start": 3306.92, "end": 3320.92, "text": " So in theory, I feel like this one feels the most correct, given that the data that we have is a fixed input size of that type.", "tokens": [407, 294, 5261, 11, 286, 841, 411, 341, 472, 3417, 264, 881, 3006, 11, 2212, 300, 264, 1412, 300, 321, 362, 307, 257, 6806, 4846, 2744, 295, 300, 2010, 13], "temperature": 0.0, "avg_logprob": -0.12364493097577776, "compression_ratio": 1.3630136986301369, "no_speech_prob": 1.7603209698791034e-06}, {"id": 426, "seek": 330092, "start": 3320.92, "end": 3325.92, "text": " So I would be inclined to.", "tokens": [407, 286, 576, 312, 28173, 281, 13], "temperature": 0.0, "avg_logprob": -0.12364493097577776, "compression_ratio": 1.3630136986301369, "no_speech_prob": 1.7603209698791034e-06}, {"id": 427, "seek": 332592, "start": 3325.92, "end": 3340.92, "text": " Well, you know, we'll take a look afterwards, but.", "tokens": [1042, 11, 291, 458, 11, 321, 603, 747, 257, 574, 10543, 11, 457, 13], "temperature": 0.0, "avg_logprob": -0.22710878618301883, "compression_ratio": 0.9615384615384616, "no_speech_prob": 2.318530277989339e-05}, {"id": 428, "seek": 332592, "start": 3340.92, "end": 3348.92, "text": " Oh, did I just do.", "tokens": [876, 11, 630, 286, 445, 360, 13], "temperature": 0.0, "avg_logprob": -0.22710878618301883, "compression_ratio": 0.9615384615384616, "no_speech_prob": 2.318530277989339e-05}, {"id": 429, "seek": 332592, "start": 3348.92, "end": 3353.92, "text": " Copy.", "tokens": [25653, 13], "temperature": 0.0, "avg_logprob": -0.22710878618301883, "compression_ratio": 0.9615384615384616, "no_speech_prob": 2.318530277989339e-05}, {"id": 430, "seek": 335392, "start": 3353.92, "end": 3359.92, "text": " We'll save a different set. So we can easily then check the accuracy of each of them.", "tokens": [492, 603, 3155, 257, 819, 992, 13, 407, 321, 393, 3612, 550, 1520, 264, 14170, 295, 1184, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.14669114351272583, "compression_ratio": 1.3486842105263157, "no_speech_prob": 5.682267783413408e-06}, {"id": 431, "seek": 335392, "start": 3359.92, "end": 3364.92, "text": " And this one's going to be rectangular.", "tokens": [400, 341, 472, 311, 516, 281, 312, 31167, 13], "temperature": 0.0, "avg_logprob": -0.14669114351272583, "compression_ratio": 1.3486842105263157, "no_speech_prob": 5.682267783413408e-06}, {"id": 432, "seek": 335392, "start": 3364.92, "end": 3366.92, "text": " Rectangular.", "tokens": [497, 557, 656, 1040, 13], "temperature": 0.0, "avg_logprob": -0.14669114351272583, "compression_ratio": 1.3486842105263157, "no_speech_prob": 5.682267783413408e-06}, {"id": 433, "seek": 335392, "start": 3366.92, "end": 3371.92, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.14669114351272583, "compression_ratio": 1.3486842105263157, "no_speech_prob": 5.682267783413408e-06}, {"id": 434, "seek": 335392, "start": 3371.92, "end": 3376.92, "text": " Now that we're saving a few, I guess I'm a little worried that", "tokens": [823, 300, 321, 434, 6816, 257, 1326, 11, 286, 2041, 286, 478, 257, 707, 5804, 300], "temperature": 0.0, "avg_logprob": -0.14669114351272583, "compression_ratio": 1.3486842105263157, "no_speech_prob": 5.682267783413408e-06}, {"id": 435, "seek": 337692, "start": 3376.92, "end": 3383.92, "text": " paper space might disappear.", "tokens": [3035, 1901, 1062, 11596, 13], "temperature": 0.0, "avg_logprob": -0.18338963859959653, "compression_ratio": 1.1981981981981982, "no_speech_prob": 1.8447783531883033e-06}, {"id": 436, "seek": 337692, "start": 3383.92, "end": 3388.92, "text": " And so I'm actually inclined to save these into my notebooks directory.", "tokens": [400, 370, 286, 478, 767, 28173, 281, 3155, 613, 666, 452, 43782, 21120, 13], "temperature": 0.0, "avg_logprob": -0.18338963859959653, "compression_ratio": 1.1981981981981982, "no_speech_prob": 1.8447783531883033e-06}, {"id": 437, "seek": 337692, "start": 3388.92, "end": 3397.92, "text": " Just to be a bit paranoid.", "tokens": [1449, 281, 312, 257, 857, 43948, 13], "temperature": 0.0, "avg_logprob": -0.18338963859959653, "compression_ratio": 1.1981981981981982, "no_speech_prob": 1.8447783531883033e-06}, {"id": 438, "seek": 337692, "start": 3397.92, "end": 3400.92, "text": " Copy.", "tokens": [25653, 13], "temperature": 0.0, "avg_logprob": -0.18338963859959653, "compression_ratio": 1.1981981981981982, "no_speech_prob": 1.8447783531883033e-06}, {"id": 439, "seek": 340092, "start": 3400.92, "end": 3406.92, "text": " And so let's move.", "tokens": [400, 370, 718, 311, 1286, 13], "temperature": 0.0, "avg_logprob": -0.12026698937576809, "compression_ratio": 1.6057142857142856, "no_speech_prob": 4.289149728720076e-06}, {"id": 440, "seek": 340092, "start": 3406.92, "end": 3412.92, "text": " Let's move this one into slash notebooks.", "tokens": [961, 311, 1286, 341, 472, 666, 17330, 43782, 13], "temperature": 0.0, "avg_logprob": -0.12026698937576809, "compression_ratio": 1.6057142857142856, "no_speech_prob": 4.289149728720076e-06}, {"id": 441, "seek": 340092, "start": 3412.92, "end": 3415.92, "text": " Oh, that's right. I'm not using paper space, so I don't have to.", "tokens": [876, 11, 300, 311, 558, 13, 286, 478, 406, 1228, 3035, 1901, 11, 370, 286, 500, 380, 362, 281, 13], "temperature": 0.0, "avg_logprob": -0.12026698937576809, "compression_ratio": 1.6057142857142856, "no_speech_prob": 4.289149728720076e-06}, {"id": 442, "seek": 340092, "start": 3415.92, "end": 3417.92, "text": " I forgot.", "tokens": [286, 5298, 13], "temperature": 0.0, "avg_logprob": -0.12026698937576809, "compression_ratio": 1.6057142857142856, "no_speech_prob": 4.289149728720076e-06}, {"id": 443, "seek": 340092, "start": 3417.92, "end": 3419.92, "text": " Never mind.", "tokens": [7344, 1575, 13], "temperature": 0.0, "avg_logprob": -0.12026698937576809, "compression_ratio": 1.6057142857142856, "no_speech_prob": 4.289149728720076e-06}, {"id": 444, "seek": 340092, "start": 3419.92, "end": 3428.92, "text": " I'm on my own machine. I like the fact that I've got paper space so well set up now that I don't even remember I'm using paper space.", "tokens": [286, 478, 322, 452, 1065, 3479, 13, 286, 411, 264, 1186, 300, 286, 600, 658, 3035, 1901, 370, 731, 992, 493, 586, 300, 286, 500, 380, 754, 1604, 286, 478, 1228, 3035, 1901, 13], "temperature": 0.0, "avg_logprob": -0.12026698937576809, "compression_ratio": 1.6057142857142856, "no_speech_prob": 4.289149728720076e-06}, {"id": 445, "seek": 342892, "start": 3428.92, "end": 3433.92, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.14393108031328986, "compression_ratio": 1.2923076923076924, "no_speech_prob": 2.2251524569583125e-06}, {"id": 446, "seek": 342892, "start": 3433.92, "end": 3434.92, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.14393108031328986, "compression_ratio": 1.2923076923076924, "no_speech_prob": 2.2251524569583125e-06}, {"id": 447, "seek": 342892, "start": 3434.92, "end": 3448.92, "text": " I think that's that. All right, I'm going to not have you guys watch that run for 20 minutes so I'm going to go. Any questions or comments before we wrap up.", "tokens": [286, 519, 300, 311, 300, 13, 1057, 558, 11, 286, 478, 516, 281, 406, 362, 291, 1074, 1159, 300, 1190, 337, 945, 2077, 370, 286, 478, 516, 281, 352, 13, 2639, 1651, 420, 3053, 949, 321, 7019, 493, 13], "temperature": 0.0, "avg_logprob": -0.14393108031328986, "compression_ratio": 1.2923076923076924, "no_speech_prob": 2.2251524569583125e-06}, {"id": 448, "seek": 344892, "start": 3448.92, "end": 3466.92, "text": " So I see that you're like focusing a lot on like the data transformations and augmentations. When would you focus on that versus, you know, playing around with different models and things like that instead.", "tokens": [407, 286, 536, 300, 291, 434, 411, 8416, 257, 688, 322, 411, 264, 1412, 34852, 293, 29919, 763, 13, 1133, 576, 291, 1879, 322, 300, 5717, 11, 291, 458, 11, 2433, 926, 365, 819, 5245, 293, 721, 411, 300, 2602, 13], "temperature": 0.0, "avg_logprob": -0.08686034910140498, "compression_ratio": 1.5614973262032086, "no_speech_prob": 2.7692165076587116e-06}, {"id": 449, "seek": 344892, "start": 3466.92, "end": 3476.92, "text": " Given that this is a image classification task for natural length for natural photos.", "tokens": [18600, 300, 341, 307, 257, 3256, 21538, 5633, 337, 3303, 4641, 337, 3303, 5787, 13], "temperature": 0.0, "avg_logprob": -0.08686034910140498, "compression_ratio": 1.5614973262032086, "no_speech_prob": 2.7692165076587116e-06}, {"id": 450, "seek": 347692, "start": 3476.92, "end": 3487.92, "text": " Yeah, well almost certainly have exactly the same characteristics as image net in terms of accuracy, or at least try any fine tuning on image net.", "tokens": [865, 11, 731, 1920, 3297, 362, 2293, 264, 912, 10891, 382, 3256, 2533, 294, 2115, 295, 14170, 11, 420, 412, 1935, 853, 604, 2489, 15164, 322, 3256, 2533, 13], "temperature": 0.0, "avg_logprob": -0.13894020332084908, "compression_ratio": 1.6341463414634145, "no_speech_prob": 5.594072263193084e-06}, {"id": 451, "seek": 347692, "start": 3487.92, "end": 3504.92, "text": " So, I would, I'm working on the assumption which I could read off we can test later but I'm pretty sure it's going to be true that the things that are in that that notebook showing which which Tim models are better than others will apply to this data set.", "tokens": [407, 11, 286, 576, 11, 286, 478, 1364, 322, 264, 15302, 597, 286, 727, 1401, 766, 321, 393, 1500, 1780, 457, 286, 478, 1238, 988, 309, 311, 516, 281, 312, 2074, 300, 264, 721, 300, 366, 294, 300, 300, 21060, 4099, 597, 597, 7172, 5245, 366, 1101, 813, 2357, 486, 3079, 281, 341, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.13894020332084908, "compression_ratio": 1.6341463414634145, "no_speech_prob": 5.594072263193084e-06}, {"id": 452, "seek": 350492, "start": 3504.92, "end": 3507.92, "text": " So, I would.", "tokens": [407, 11, 286, 576, 13], "temperature": 0.0, "avg_logprob": -0.05257373289628462, "compression_ratio": 1.410071942446043, "no_speech_prob": 5.862524176336592e-06}, {"id": 453, "seek": 350492, "start": 3507.92, "end": 3510.92, "text": " Once everything else is working really well.", "tokens": [3443, 1203, 1646, 307, 1364, 534, 731, 13], "temperature": 0.0, "avg_logprob": -0.05257373289628462, "compression_ratio": 1.410071942446043, "no_speech_prob": 5.862524176336592e-06}, {"id": 454, "seek": 350492, "start": 3510.92, "end": 3520.92, "text": " You know, I would then try it on a couple of models or at least run it on a bigger one like base or large or whatever I can get away with.", "tokens": [509, 458, 11, 286, 576, 550, 853, 309, 322, 257, 1916, 295, 5245, 420, 412, 1935, 1190, 309, 322, 257, 3801, 472, 411, 3096, 420, 2416, 420, 2035, 286, 393, 483, 1314, 365, 13], "temperature": 0.0, "avg_logprob": -0.05257373289628462, "compression_ratio": 1.410071942446043, "no_speech_prob": 5.862524176336592e-06}, {"id": 455, "seek": 352092, "start": 3520.92, "end": 3537.92, "text": " If it was like a segmentation problem or an object detection problem or a medical imaging data set which has the kind of pictures that aren't an image net you know for all of these things I would try more different architectures but then for those cases,", "tokens": [759, 309, 390, 411, 257, 9469, 399, 1154, 420, 364, 2657, 17784, 1154, 420, 257, 4625, 25036, 1412, 992, 597, 575, 264, 733, 295, 5242, 300, 3212, 380, 364, 3256, 2533, 291, 458, 337, 439, 295, 613, 721, 286, 576, 853, 544, 819, 6331, 1303, 457, 550, 337, 729, 3331, 11], "temperature": 0.0, "avg_logprob": -0.09848296074640184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 5.7716820265341084e-06}, {"id": 456, "seek": 352092, "start": 3537.92, "end": 3547.92, "text": " I would say it was a segmentation problem which is about recognizing what each pixel is, it always is, is a pixel of.", "tokens": [286, 576, 584, 309, 390, 257, 9469, 399, 1154, 597, 307, 466, 18538, 437, 1184, 19261, 307, 11, 309, 1009, 307, 11, 307, 257, 19261, 295, 13], "temperature": 0.0, "avg_logprob": -0.09848296074640184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 5.7716820265341084e-06}, {"id": 457, "seek": 354792, "start": 3547.92, "end": 3563.92, "text": " Even there I would not try to replicate the research of others instead I would go and look at something like papers with code calm to find out which techniques have the best results on segmentation and better still I would go and find two or three previous", "tokens": [2754, 456, 286, 576, 406, 853, 281, 25356, 264, 2132, 295, 2357, 2602, 286, 576, 352, 293, 574, 412, 746, 411, 10577, 365, 3089, 7151, 281, 915, 484, 597, 7512, 362, 264, 1151, 3542, 322, 9469, 399, 293, 1101, 920, 286, 576, 352, 293, 915, 732, 420, 1045, 3894], "temperature": 0.0, "avg_logprob": -0.08249588732449513, "compression_ratio": 1.5609756097560976, "no_speech_prob": 7.766497219563462e-06}, {"id": 458, "seek": 356392, "start": 3563.92, "end": 3577.92, "text": " competitions that have a similar problem type and see who won and see what they did. Now when you look at who won. They always say oh we made an ensemble, which is fine.", "tokens": [26185, 300, 362, 257, 2531, 1154, 2010, 293, 536, 567, 1582, 293, 536, 437, 436, 630, 13, 823, 562, 291, 574, 412, 567, 1582, 13, 814, 1009, 584, 1954, 321, 1027, 364, 19492, 11, 597, 307, 2489, 13], "temperature": 0.0, "avg_logprob": -0.12130411303773218, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.4063508388062473e-05}, {"id": 459, "seek": 356392, "start": 3577.92, "end": 3590.92, "text": " The important thing isn't that they did an ensemble it'll be they'll always say pretty much the best model in our ensemble was X. And so I would just use X, and I would use this kind of like smallest version of X I can get away with.", "tokens": [440, 1021, 551, 1943, 380, 300, 436, 630, 364, 19492, 309, 603, 312, 436, 603, 1009, 584, 1238, 709, 264, 1151, 2316, 294, 527, 19492, 390, 1783, 13, 400, 370, 286, 576, 445, 764, 1783, 11, 293, 286, 576, 764, 341, 733, 295, 411, 16998, 3037, 295, 1783, 286, 393, 483, 1314, 365, 13], "temperature": 0.0, "avg_logprob": -0.12130411303773218, "compression_ratio": 1.6861924686192469, "no_speech_prob": 1.4063508388062473e-05}, {"id": 460, "seek": 359092, "start": 3590.92, "end": 3607.92, "text": " Now generally, fiddling with architectures tends not to be very useful nowadays for any kind of problem that like people have fairly regularly studied, which almost any computer vision problem is of that type.", "tokens": [823, 5101, 11, 283, 14273, 1688, 365, 6331, 1303, 12258, 406, 281, 312, 588, 4420, 13434, 337, 604, 733, 295, 1154, 300, 411, 561, 362, 6457, 11672, 9454, 11, 597, 1920, 604, 3820, 5201, 1154, 307, 295, 300, 2010, 13], "temperature": 0.0, "avg_logprob": -0.10800637982108376, "compression_ratio": 1.3933333333333333, "no_speech_prob": 2.3184744350146502e-05}, {"id": 461, "seek": 360792, "start": 3607.92, "end": 3625.92, "text": " I guess the only interesting question for this one would be, there is something saying what kind of rice is in this patty, which is like a category, but I'm fairly sure that using that information is not going to be helpful in this case, because the model can perfectly", "tokens": [286, 2041, 264, 787, 1880, 1168, 337, 341, 472, 576, 312, 11, 456, 307, 746, 1566, 437, 733, 295, 5090, 307, 294, 341, 1947, 874, 11, 597, 307, 411, 257, 7719, 11, 457, 286, 478, 6457, 988, 300, 1228, 300, 1589, 307, 406, 516, 281, 312, 4961, 294, 341, 1389, 11, 570, 264, 2316, 393, 6239], "temperature": 0.0, "avg_logprob": -0.13528098000420463, "compression_ratio": 1.6343612334801763, "no_speech_prob": 6.917335122125223e-05}, {"id": 462, "seek": 360792, "start": 3625.92, "end": 3629.92, "text": " well see what kind of rice it is, so I very much doubt we have to tell it.", "tokens": [731, 536, 437, 733, 295, 5090, 309, 307, 11, 370, 286, 588, 709, 6385, 321, 362, 281, 980, 309, 13], "temperature": 0.0, "avg_logprob": -0.13528098000420463, "compression_ratio": 1.6343612334801763, "no_speech_prob": 6.917335122125223e-05}, {"id": 463, "seek": 360792, "start": 3629.92, "end": 3632.92, "text": " Because it's got pictures.", "tokens": [1436, 309, 311, 658, 5242, 13], "temperature": 0.0, "avg_logprob": -0.13528098000420463, "compression_ratio": 1.6343612334801763, "no_speech_prob": 6.917335122125223e-05}, {"id": 464, "seek": 363292, "start": 3632.92, "end": 3653.92, "text": " Jeremy. Yeah, it's, it's, it's going to take me a while to work through all of the videos. Yeah, they're going to be virtually available. Yes. Cool. Yes. And don't feel like you can only join if you've watched all the previous videos, and don't feel like you can only ask a question", "tokens": [17809, 13, 865, 11, 309, 311, 11, 309, 311, 11, 309, 311, 516, 281, 747, 385, 257, 1339, 281, 589, 807, 439, 295, 264, 2145, 13, 865, 11, 436, 434, 516, 281, 312, 14103, 2435, 13, 1079, 13, 8561, 13, 1079, 13, 400, 500, 380, 841, 411, 291, 393, 787, 3917, 498, 291, 600, 6337, 439, 264, 3894, 2145, 11, 293, 500, 380, 841, 411, 291, 393, 787, 1029, 257, 1168], "temperature": 0.0, "avg_logprob": -0.191112060546875, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.00010382596519775689}, {"id": 465, "seek": 365392, "start": 3653.92, "end": 3668.92, "text": " if you've watched all the previous videos, like, it's totally fine to ask a question about a video we did a week ago, or about something that we just covered yesterday or whatever. If the answer to your question is, oh, we cover this in this video.", "tokens": [498, 291, 600, 6337, 439, 264, 3894, 2145, 11, 411, 11, 309, 311, 3879, 2489, 281, 1029, 257, 1168, 466, 257, 960, 321, 630, 257, 1243, 2057, 11, 420, 466, 746, 300, 321, 445, 5343, 5186, 420, 2035, 13, 759, 264, 1867, 281, 428, 1168, 307, 11, 1954, 11, 321, 2060, 341, 294, 341, 960, 13], "temperature": 0.0, "avg_logprob": -0.11052108260820497, "compression_ratio": 1.7405857740585775, "no_speech_prob": 1.4969422409194522e-05}, {"id": 466, "seek": 365392, "start": 3668.92, "end": 3677.92, "text": " Here's where you go, I will tell you that, and that's totally fine but and if it's like, okay you said this thing in this other video but I don't get it, say it again.", "tokens": [1692, 311, 689, 291, 352, 11, 286, 486, 980, 291, 300, 11, 293, 300, 311, 3879, 2489, 457, 293, 498, 309, 311, 411, 11, 1392, 291, 848, 341, 551, 294, 341, 661, 960, 457, 286, 500, 380, 483, 309, 11, 584, 309, 797, 13], "temperature": 0.0, "avg_logprob": -0.11052108260820497, "compression_ratio": 1.7405857740585775, "no_speech_prob": 1.4969422409194522e-05}, {"id": 467, "seek": 367792, "start": 3677.92, "end": 3690.92, "text": " It's totally fine to like, we're moving at quite a fast pace, because people can go back and rewatch the videos and because people can come back later and ask questions about things that aren't clear.", "tokens": [467, 311, 3879, 2489, 281, 411, 11, 321, 434, 2684, 412, 1596, 257, 2370, 11638, 11, 570, 561, 393, 352, 646, 293, 319, 15219, 264, 2145, 293, 570, 561, 393, 808, 646, 1780, 293, 1029, 1651, 466, 721, 300, 3212, 380, 1850, 13], "temperature": 0.0, "avg_logprob": -0.09339893027527692, "compression_ratio": 1.5647668393782384, "no_speech_prob": 4.608337985700928e-05}, {"id": 468, "seek": 367792, "start": 3690.92, "end": 3698.92, "text": " So yeah, definitely does rely on people turning up and saying, I'm not clear on this or, or whatever.", "tokens": [407, 1338, 11, 2138, 775, 10687, 322, 561, 6246, 493, 293, 1566, 11, 286, 478, 406, 1850, 322, 341, 420, 11, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.09339893027527692, "compression_ratio": 1.5647668393782384, "no_speech_prob": 4.608337985700928e-05}, {"id": 469, "seek": 369892, "start": 3698.92, "end": 3708.92, "text": " So I sort of started from ground zero in this whole environment, but it is starting to make sense now. I'm starting to feel a little bit more comfy with it.", "tokens": [407, 286, 1333, 295, 1409, 490, 2727, 4018, 294, 341, 1379, 2823, 11, 457, 309, 307, 2891, 281, 652, 2020, 586, 13, 286, 478, 2891, 281, 841, 257, 707, 857, 544, 34523, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.23319818103124226, "compression_ratio": 1.4463276836158192, "no_speech_prob": 6.294895138125867e-05}, {"id": 470, "seek": 369892, "start": 3708.92, "end": 3716.92, "text": " Nice. Let's take the time to work through my way through and absorb what you've been talking about.", "tokens": [5490, 13, 961, 311, 747, 264, 565, 281, 589, 807, 452, 636, 807, 293, 15631, 437, 291, 600, 668, 1417, 466, 13], "temperature": 0.0, "avg_logprob": -0.23319818103124226, "compression_ratio": 1.4463276836158192, "no_speech_prob": 6.294895138125867e-05}, {"id": 471, "seek": 371692, "start": 3716.92, "end": 3728.92, "text": " Daniel I will say like, there's a couple more lesson lessons to come. Like, what is it next week or the week after I suspect during those two weeks I'll probably stop the walkthroughs.", "tokens": [8033, 286, 486, 584, 411, 11, 456, 311, 257, 1916, 544, 6898, 8820, 281, 808, 13, 1743, 11, 437, 307, 309, 958, 1243, 420, 264, 1243, 934, 286, 9091, 1830, 729, 732, 3259, 286, 603, 1391, 1590, 264, 1792, 11529, 82, 13], "temperature": 0.0, "avg_logprob": -0.14350519460790298, "compression_ratio": 1.5260115606936415, "no_speech_prob": 5.2131901611573994e-05}, {"id": 472, "seek": 371692, "start": 3728.92, "end": 3734.92, "text": " So, there'll be a couple of weeks there to catch up but yeah like feel free to.", "tokens": [407, 11, 456, 603, 312, 257, 1916, 295, 3259, 456, 281, 3745, 493, 457, 1338, 411, 841, 1737, 281, 13], "temperature": 0.0, "avg_logprob": -0.14350519460790298, "compression_ratio": 1.5260115606936415, "no_speech_prob": 5.2131901611573994e-05}, {"id": 473, "seek": 373492, "start": 3734.92, "end": 3747.92, "text": " Join in anytime or not join in anytime and ask questions about any video or even about things that's not covered in a video but you feel like would be something useful to know in order to understand.", "tokens": [19642, 294, 13038, 420, 406, 3917, 294, 13038, 293, 1029, 1651, 466, 604, 960, 420, 754, 466, 721, 300, 311, 406, 5343, 294, 257, 960, 457, 291, 841, 411, 576, 312, 746, 4420, 281, 458, 294, 1668, 281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.1434383141367059, "compression_ratio": 1.5572139303482586, "no_speech_prob": 4.324737165006809e-05}, {"id": 474, "seek": 373492, "start": 3747.92, "end": 3752.92, "text": " I'm really looking forward to the tabular data actually. Oh cool.", "tokens": [286, 478, 534, 1237, 2128, 281, 264, 4421, 1040, 1412, 767, 13, 876, 1627, 13], "temperature": 0.0, "avg_logprob": -0.1434383141367059, "compression_ratio": 1.5572139303482586, "no_speech_prob": 4.324737165006809e-05}, {"id": 475, "seek": 373492, "start": 3752.92, "end": 3759.92, "text": " Okay, thank you. Thanks all. See you next time.", "tokens": [1033, 11, 1309, 291, 13, 2561, 439, 13, 3008, 291, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.1434383141367059, "compression_ratio": 1.5572139303482586, "no_speech_prob": 4.324737165006809e-05}, {"id": 476, "seek": 375992, "start": 3759.92, "end": 3764.92, "text": " Bye.", "tokens": [50364, 4621, 13, 50614], "temperature": 0.0, "avg_logprob": -0.7292644023895264, "compression_ratio": 0.3333333333333333, "no_speech_prob": 0.0001370570680592209}], "language": "en"}