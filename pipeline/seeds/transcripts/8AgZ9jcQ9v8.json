{"text": " Hi everybody and welcome to the last lesson of part two. Greetings Jono and greetings Tanishka. How are you guys doing? Good thanks. Doing well. Excited for the last lesson. It's been an interesting fun journey. Yeah. I should explain we're not quite completing all of stable diffusion in this part of the course. There's going to be one piece left for the next part of the course, which is the clip embeddings. Because clip is NLP and so the next part of the course we will be looking at NLP. So we will end up finishing stable diffusion from scratch, but we're going to have to have a significant diversion. And what we thought was given everything that's happened with GPT-4 and stuff since we started this course, we thought it makes more sense to delve into that quite deeply more soon. And delay clip as a result. So hopefully people feel comfortable with that decision. But I think we'll have a lot of exciting NLP material coming up. So that's the rough plan. All right. So I think what we might do is maybe start by looking at a really interesting and quite successful application of pixel level diffusion by applying it not to pixels that represent an image, but pixels that represent a sound. Which is pretty crazy. So maybe Jono, of course it's going to be Jono, he does the crazy stuff, which is great. So Jono, show your crazy and crazily successful approach to diffusion for pixels of sounds, please. Sure thing. Right. So this is going to be a little bit of show and tell. Most of the code in the notebook is just copied and pasted from, I think, notebook 30. But we're going to be trying to generate something other than just images. So specifically I'm going to be loading up a dataset of bird calls. These are just like short samples of, I think, 10 different classes of birds calling. And so we need to understand like, okay, well, this is a totally different domain, right? This is audio. If you look at the data, like let's look at an example of the data. This is coming from a hugging face dataset. So that, that line of code will download it automatically if you haven't got it before. Right. Yeah. Yeah. So this will download it into a cache and then sort of handle a lot of the data. You created this dataset, right? Did you, is this already a dataset you found somewhere else or you made it or what? This is a subset that I made from a much larger dataset of longer call recordings from an open website called ZenoCanto. So they collect all of these sound recordings from people. They have experts who help identify what birds are calling. And so all I did was find the audio peaks, like where is there most likely to be a bird call and clip around those just to get a smaller dataset of things where there's actually something happening. Nice. Not a particularly amazing dataset in terms of like the recordings have a lot of background noise and stuff, but a fun, small audio one to play with. Yeah. And so when we talk about audio, you've got a microphone somewhere it's reading like a pressure level essentially in the air with these sound waves. And it's doing that some number of times per second. So we have a sample rate. And in this case, the data has a sample rate of 32,000 samples per second. So every second that's recorded. This is a waveform that's being approximated as lots of little up across, up across, up across kind of things basically. Yeah. Is that right? Yeah. So that's great for capturing the audio, but it's not so good for modeling because we now have 30,000 values per second in this one big 1D array. And so, yeah, you can try and find models that can work with that kind of data. But what we're going to do is a little hack and we're instead going to use something called a spectrogram. So illustrate that. The original data is the main issue. It's too big and slow to work with. It's too big. But also you have some, like some sound waves are at a hundred hertz, right? So they're going up and down a hundred times a second. And some are at a thousand and some are at 10,000. And often there's background noise that can have extremely high frequency components. And so if you're looking just at the waveform, there's lots and lots of change second to second and there's some very long range dependencies of like, oh, generally high here. It's generally low there. And so it can be quite hard to capture those patterns. And so part of it is, it's just a lot of samples to deal with. But part of it also is that it's not like an image where you can just do like convolution and things nearby each other tend to be related or something like that. It's quite tricky to disentangle what's going on. And so we have this idea of something called a spectrogram. This is a fancy 3D visualization, but it's basically just taking that audio and mapping time on one axis. So you can see as time goes by, we're moving along the X axis. And then on the Y axis is frequency. And so the peaks here show like intensity at different frequencies. And so if I make a pure note, you can see that that is being mapped in the frequency domain. But when I'm talking, there's lots and lots of peaks. And that's because our voices tend to produce a lot of overtones. So if I go eee, you can see there's a main note, but there's also the subsequent notes. And if I play something like a chord, you can see there's maybe three main peaks and then each of those have these harmonics as well. So it captures a lot of information about the signal. And so we're going to turn our audio data into something like this, where even just visually, if I'm a bird, you can see this really nice spatial pattern. And the hope is if we can generate that, and then if we can find some way to turn it back into audio, then we'll be off to the races. And so, yeah, that's what I'm doing in this notebook. We have, I'm leaning on the diffusers.pipelines.audiodiffusion.mel class. And so within the realm of spectrograms, there's a few different ways you can do it. So this is from the Torch Audio Docs, but this notebook is from the Hugging Face Diffusion Models class. So we had that waveform, that's those raw samples. And we'd like to convert that into what they call the frequency domain, which is things like these spectrograms. And so you can do a normal spectrogram, a power spectrogram or something like that. But we often use something called a MEL spectrogram, which is exactly the same. It's actually probably what's being visualized here. And it's something that's designed to map the frequency ranges into a range that's tied to what human hearing is based on. And so rather than trying to capture all frequencies from zero hertz to 40,000 hertz, a lot of which we can't even hear, it focuses in on the range of values that we tend to be interested in as humans. And also it does a transformation into a log space so that the intensities like highs and lows correspond to loud and quiet for human hearing. So it's very tuned for the types of audio information that we actually might care about rather than tens of thousands of kilohertz that only bats can hear. So we're going to rely on a class to abstract this away, but it's going to basically give us a transformation from waveform to spectrogram. And then it's also going to help us go from spectrogram back to waveform. And so let me show you my data. I have this two image function. It's going to take the audio array. It's going to use the MEL class to handle turning that into spectrograms. And the class also does things like it splits it up into chunks based on, you can set like a desired resolution. So if I wanted like 128 by 128 spectrogram, it says, okay, great. I know how many, I know you need 128 frequency bins for the frequency axis and 128 steps on the time axis. So it kind of handles that converting and resizing. And then it gives us these audio slice to image. So that's taking a chunk of audio and turning it into the spectrogram. And it also has the inverse. So our dataset is fairly simple. We're just referencing our original audio datasets, but we're calling that two image function and then returning it into a tensor and we're mapping it to minus 0.5 to 0.5. Similarly to what we've done with like the grayscale images in the past. So if you look at a sample from that data, we now have, instead of an audio waveform of 32,000 or 64,000, if it's two seconds samples, we now have this 128 by 128 pixel spectrogram, which looks like this. And it's just, it's grayscale. So this is just matplotlibs colors. But we can test out going from the spectrogram back to audio using the image to audio function that the MEL class has. And that should give us, it sounds kind of like birdsong. Now this isn't perfect because the spectrogram shows the intensity at different frequencies, but with audio, you've also got to worry about something called the phase. And so this image to audio function is actually behind the scenes doing a kind of iterative approximation with something called the Griffin-Linn algorithm. So I'm not going to try and describe that here, but it's just, it's approximating, it's guessing what the phase should be. It's creating a spectrogram, it's comparing that to the original. It's updating, it's doing sort of like iterative, very similar to like an optimization thing to try and generate an audio signal that would produce the spectrogram, which we're trying to invert. So just to clarify, so my understanding, what you're saying is that the spectrogram is a lossy conversion of the sound into an image. And specifically it's lossy because it tells you the kind of intensity at each point, but it's not, it's kind of like, is it like the difference between a sine wave and a cosine wave? Like they're just shifted in different ways and we don't know how much it's shifted. So coming back to the sound, you do have to get that, that shifting, the phase correct. And so it's trying to guess something and it's, sounds like it's not doing a great guess from the thing you showed. The original audio is also not that amazing, but yes, the spectrogram back to audio task, these dotted lines are like highlighting, this is, yeah, it's an approximation. And there are deep learning methods now that can do that better, or at least that sound much higher quality, because you can train a model somehow to go from this image-like representation back to an audio signal. But we just use the approximation for this notebook. Okay. So now that we can represent our data as like a grayscale 128 by 128 pixel image, everything else becomes very much the same as the previous diffusion models examples. We're going to use this noiseify function to add different amounts of noise. And so we can see now we have our spectrograms, but with varying amounts of noise added, we can create a simple diffusion model. I'm just copying and pasting the results, but with one extra layer, just with very few channels to go from 128 to 64, to 36, I mean, to 16 by 8, to 8. No attention, just, I think pretty much copied and pasted from notebook 30 and train it for in this case, 15 epochs, it took about. Oh, this is interesting. You're using simple diffusion. Yes. So specifically this is the simple diffusion model that you, I think I've already introduced, maybe not. Yeah. So it has some number of... I think we briefly looked at it, so let's remind ourselves of what it does. Yeah. Oh, okay. Yeah. So we have some number of down blocks with a specified number of channels. And then the key insight from simple diffusion was that you often want to concentrate the compute in the sort of middle at the low resolution. So that's these mid blocks. And they're transformers. Yes. Yeah. And so we can stack some number of those and then the corresponding up path. And this is a unit. So we passing in the features from the down path as we go through those up blocks. And so we're going to go take an image and time step. We can embed the time step. We're going to go through our down blocks and saving the results. We're going to go through the mid blocks. There we go. Through the mid blocks. Yeah. And before that, you've also got the embedding of the locations that self.le is the learnable embeddings using scale and shift, I remember. Right. So this is preparing it to go through the transformer blocks by adding some learnable embeddings. Cool. All right. And then we're reshaping it to be effectively a sequence, since that's how we had written our transformer to expect a 1D sequence of embeddings. And so once you've gone through those mid blocks, we reshape it back and then we go through the up blocks passing in and also our saved outputs from the down path. Yeah. So it's a nice, it's the nice model. You can really control how much parameters and compute you're doing just by setting like what are the number of features or channels at each of those down block stages and how many mid blocks are you going to stack. And so if you want to scale it up, it's quite easy to say, let me just add more mid blocks, maybe I'll add more channels to the down and up paths. And there's a very easy model to tweak to get a larger or smaller model. One fun thought I know is simple diffusion only came out a couple of months ago. And I don't think, I think ours might be the first publicly available code for it. I don't think the authors released the code. I suspect this is probably the first time maybe it's ever been used to generate audio before. Possibly. Yeah, I guess. I know a couple of people who've at least privately done their implementations. When I asked the author if he was releasing code, he said, oh, but it's simple. It's just a bunch of transformer blocks. I'll release it eventually. No, maybe, maybe not. I'm not, I don't want to malign them, but they were like, oh, you can see the pseudocode. It's pretty easy. Yeah, it is pretty easy. Yeah. Cool. So the trains, the last goes down as we hope. Sampling is exactly the same as generating images normally. And that's going to give us the spectrograms. So I'm using DDAM sampling with a hundred steps. And to actually listen to these samples, we then are just going to use that image to audio function again to take our grayscale image. And in this case, actually it expects a PIL image. So I first converted it to PIL and then turn that back into audio. And so we can play some of the generated samples. Wow. That's so cool. I don't know that I could guarantee what bird is making these calls and some of them are better than others. Like some of them have better calls. Some of the original samples sound like that. So. Exactly. Yeah. So yeah, that's generating bird calls with spectrogram diffusion. There's projects that do this on music. So the Refusion project generates a picture based on text. And yeah, there's various other like pre-trained models that do diffusion on spectrograms to produce music clips or voice or whatever. I may have frozen. Refusion is actually this stable diffusion model that's fine tuned specifically for the spectrogram generation, which I find very impressive. It's like a model that was originally for text to image is instead can also generate these spectrograms. I guess there's still some useful information in this sort of text to image model that kind of generalizes or you can still be used for text to audio. So I found that a very interesting, impressive application as well. So Refusion is an awesome name. Indeed it is. Yeah. Cool. And I guess since it's a latent model that leads us on to the next topic, right? I was just going to say we've got a natural segue there. Yes. So if we want to replicate Refusion, then we'll need Latents. Yeah. So the final non-NLP part of stable diffusion is this ability to use the more compressed representation created by a VAE called Latents instead of pixels. So we're going to start today by creating a VAE, taking a look at how it works. So to remind you, as we learned back in the first lesson of this part, of part two, the VAE model converts the 256 by 256 pixel 3 channel into a 64 by 64 by 4? It'll be 32 if it's 256. It's 512 to 64. Oh, 512 to 64. Okay. So to a 32 by 32 by 4. So dramatically smaller, which makes life so much easier. Which is really nice. Having said that, you know, simple diffusion does the first, you know, few, in fact, you know, all the downsampling pretty quickly and all the hard work happens, you know, at a 16 by 16 anyway. So maybe it's, you know, with simple diffusion, it's not as big a deal as it used to be, but it's still, you know, it's very handy, particularly because for us folks with more normal amounts of compute, we can take advantage of all that hard work that the stability.ai computers did for us by creating the stable diffusion VAE. So that's what we're going to do today. But first of all, we're going to create our own. So let's do a VAE using fashion-mnist. So the first, all the first stuff is just the normal. One thing I am going to do for this simple example, though, is I'm going to flatten the fashion-mnist pixels into a vector to make it as simple as possible. Okay. So we've, we're going to end up with vectors of length 784, because 28 by 28 is 784. We're going to create a single hidden layer MLP with 400 hidden, and then 200 outputs. So here's a linear layer. So it's a sequential containing a linear, and then an optimal activation function, and an optional normalization. We'll update init weights so that we initialize linear layers as well. So before we create a VAE, which is a variational autoencoder, we'll create a normal autoencoder. We've done this once before, and we didn't have any luck. In fact, we were so unsuccessful that we decided to go back and create a learner, and come back a few weeks later, once we knew what we were doing. So here we are. We're back. We think we know what we're doing. So we're just going to recreate an autoencoder, just like we did some lessons ago. So there's going to be an encoder, which is a sequential, which goes from our 768 inputs to our 400 hidden, and then a linear layer with our 400 hidden, and then an output layer from the 400 hidden to the 200 outputs of the encoder. So there we've got our latency. And then the decoder will go from those 200 latents to our 400 hidden, have our hidden layer, and then come back to our 768 inputs. All right. So we can optimize that in the usual way, using Adam. And we'll do it for 20 epochs. Runs pretty quickly, because it's quite a small data set, and quite a small model. And so what we can then do, is we can grab a batch of our X, or actually grab the batch of X earlier, way back here. So I've got a batch of images. And we can put it through our model, pop it back on the CPU, and we can then have a look at our original mini-batch. And we have to reshape it to 28 by 28, because we previously had flattened it. So there's our original. And then we can look at the result after putting it through our model. And there it is. So you can see, it's very roughly regenerated. And so this is not a massive compression. It's compressing it from 768 to 200. And it's also not doing an amazing job of recreating the original details. But this is the simplest possible autoencoder. So it's doing, you know, it's a lot better than our previous attempt. So that's good. So what we could now do, is we could just generate some noise. And then, we're not even going to do diffusion. We're just going to go and say, like, okay, we've got a decoder. So let's just decode that noise. And see what it creates. And the answer is, not anything great. I mean, I could kind of recognize that might be the start of a shoe. Maybe that's the start of a bag. I don't know. But it's not doing anything amazing. So we have not successfully created an image generator here. But there's a very simple step we can do to make something that's more like an image generator. The problem is that these 200, this vector of length 200 we're creating, there's no particular reason that things that are not in the data set are going to create items of clothing. We haven't done anything to try to make that happen. We've only tried to make this work for things in the data set. And therefore, when we just randomly generate a bunch of, you know, a vector of length 200, or 16 vectors of length 200, in this case, and then decode them, there's no particular reason to think that they're going to create something that's recognizable as clothing. So the way a VAE tries to fix this is by, we've got the exact same encoder as before, except it's just missing its final layer. Its final layer has been moved over to here. I'll explain why there's two of them in a moment. So we've got the inputs to hidden, the hidden to hidden, and then the hidden to latence. The decoder is identical. OK, latence to hidden, hidden to hidden, hidden to inputs. And then just as before, we call the encoder. But we do something a little bit weird next, which is that we actually have two separate final layers. We've got one called mu for the final of the encoder, and one called LV, which stands for log variance. So our encoder has two different final layers. So we're going to call both of them. OK, so we've now got two encoded 200 long lots of latence. What do we do with them? What we do is we use them to generate random numbers. And the random numbers have a mean of mu. So when you take a random 0, 1, so this creates 0, 1 random numbers, mean 0, standard deviation 1. So if we add mu to it, then you have a mean of mu, approximately. And if you multiply the random numbers by half of log variance e to the power of that, so given this log of variance, this is going to give you standard deviation. So this is going to give you a standard deviation of e to the half LV and a mean of mu. Why the half? It doesn't matter too much. But if you think about it, standard deviation is the square root. So the variance is squared. So when you take the log, you can move that half into the multiplication because of the log trick. That's why we just got the half here instead of the square root, which would be to the power of a half. So this is just the standard deviation. So we've got the standard deviation times normally distributed random noise plus mu. Now we end up with normally distributed numbers. We're going to have 200 of them for each element of the batch, where they have a standard deviation of the result of this final layer and a variance, which is the result, or log variance, of the result of this final layer. And then finally we pass that through the decoder as usual. I'll explain why we pass back three things, but for now we're just worried about the fact we pass back the result of the decoder. So what this is going to do is it's going to generate the result of calling encode is going to be a little bit random. On average, you know, it's still generating exactly the same as before, which is the result of a sequential model with, you know, MLP with one hidden layer. But it's also going to add some randomness around that, right? So this is, here's the bit which is exactly the same as before. This is the same as calling encode before, but then here's the bit that adds some randomness to it. And the amount of randomness is also itself random. Okay. So then that gets run through the decoder. Okay. So if we now just, well, you know, trained that, right? Using the result of the decoder and using, I think we didn't use MSC loss, we used a binary cross-entropy loss, which we've seen before. So if you've forgotten, you should definitely go back and rewatch that, really part one, or we've done a bit of it in part two as well, binary cross-entropy loss. So if we just optimize this using BCE now, you would expect, and it would, I believe I haven't checked, that it would basically take this final, this layer here, and turn these all into zeros. As a result of which it would have no variance at all. And therefore it would behave exactly the same as the previous autoencoder. Does that sound reasonable to you guys? Yeah. Okay. So that wouldn't help at all, because what we actually want is we want some variance. And the reason we want some variance is we actually want to have it generate some latents, which are not exactly our data. They're around our data, but not exactly our data. And when it generates latents that are around our data, we want them to decode to the same thing. We want them to decode to the correct image. And so as a result, if we can train that, right, something that it does include some variation and still decodes back to the original image, then we've created a much more robust model. And then that's something that we would hope then when we say, okay, well now decode some noise, that it's going to decode to something better than this. So that's the idea of a VAE. So how do we get it to create a log variance, which doesn't just go to zero? Well we have a second loss term. It's called the KL divergence loss. We've got a key called KLD loss. And what we're going to do is our VAE loss is going to take the binary cross entropy between the actual decoded bit, so that's input zero, and the target. Okay, so this is exactly the same as before, it's just binary cross entropy. And we're going to add it to this KLD loss, KL divergence. Now KL divergence, the details don't matter terribly much. What's important is when we look at the KLD loss, it's getting past the input and the targets. But if you look, it's not actually using the targets at all. So if we pull out the input into its three pieces, which is our predicted image, our mu and our log variance, we don't use this either. So the BCE loss only uses the predicted image and the actual image. The KL divergence loss only uses mu and log variance. And all it does is it returns a number which says, for each item in the batch, is mu close to zero, and is log variance close to one. How does it do that? Well for mu it's very easy. Mu squared. So if mu is close to zero, then minimizing mu squared does exactly that, right? If mu is one, then mu squared is one. If mu is minus one, mu squared is one. If mu is zero, mu squared is zero. That's the lowest you can get for a squared. Okay so we've got a mu squared piece here. And we've got a dot mean, so we're just taking, that's just basically taking the mean of all the mus. And then there's another piece, which is we've got log variance minus e to the power of log variance. So if we look at that, so let's just grab a bunch of numbers between neg three and three, and do number minus e to the power of that number. And I'm just going to pop in the one plus and the point five times as well, they don't matter much. And you can see that's got a minimum of zero. So when that's a minimum of zero, e to the power of that, which is what we're going to be using, actually half times e to the power of that, but that's okay, is what we're going to be using in our dot forward method. That's going to be e to the power of zero, which is going to be one. So this is going to be minimized, where log variance exp equals one. So therefore this whole piece here will be minimized when mu is zero, and LV is also zero. And so therefore LV, e to the power of LV is one. Now the reason that it's specifically this form is basically because there's a specific mathematical thing called the KL divergence, which compares how similar two distributions are. And so a normal distribution can be fully characterized by its mean and its variance. And so this is actually more precisely calculating the similarity, specifically the KL divergence. Between the actual mu and LV that we have, and a distribution with a mean of zero and a variance of one. But you can see hopefully why conceptually we have this mu dot power two, and why we have this LV minus LV dot exp here. So that is our VAE loss. Did you guys have anything to add to any of that description? So maybe to highlight the objective of this is to say, rather than having it so that the exact point that an input is encoded to decodes back to that input, we're saying number one, the space around that point should also decode to that input, because we're going to try and force some variance. And number two, the overall variance should be like, yeah, the overall space that it uses should be roughly zero mean and units and variance. So instead of being able to map each input to an arbitrary point and then decode only that exact point to an input, we're now mapping them to a restricted range. And we're saying that not just each point, but its surroundings as well, should also decode back to something that looks like that image. And that's trying to condition this latent space to be much nicer so that any arbitrary point within that range will hopefully map to something useful. Which is a harder problem to solve, right? So we would expect, given that this is exactly the same architecture, we would expect its ability to actually decode would be worse than our previous attempt, because it's a harder problem that we're trying to solve, which is to just, we've got random numbers in there as well now. We're hoping that this ability to generate images will improve. Thanks, Jono. Okay, so I actually asked Bing about this. This is more of an example of like, I think for, you know, now that we've got GPT-4 and Bing and stuff, I find they're pretty good at answering questions that, like, I wanted to explain to students. What would happen if the variance of the latents was very low? Or what if they were very high? So why do we want them to be one? And I thought, like, oh gosh, this is hard to explain. So maybe Bing can help. So I actually thought it was pretty good. So I'll just say what Bing said. So Bing says if the variance of the latents are very low, then the encoder distribution would be very peaked and concentrated around the mean. So that was the thing we were describing earlier. If we had trained this without the KLD loss at all, right, it would probably make the variance zero. And so therefore the latent space would be less diverse and expressive and limit the ability of the decoder to reconstruct the data accurately, make it harder to generate new data that's different from the training data, which is exactly what we're trying to do. And if the variance is very high, then the encoder would be very spread out and diffuse. It would be more, the latents would be more noisy and random. Make it easier to generate new data that's unrealistic or nonsensical. Okay. So that's why we want it to be exactly at a particular point. So when we train this, we can just pass VAE loss as our loss function, but it'd be nice to see how well it's going at reconstructing the original image and how it's going at creating zero, one distribution data separately. So what I ended up doing was creating just a really simple thing called func metric, which I derived from the capital M mean class in the Torch, just trying to find it here, from the Torch eval.metrics. So they've already got something that can just calculate means. So obviously this stuff's all very simple and we've created our own metrics class ourselves back a while ago. But since we're using Torch eval, I thought this is useful to see how we can create one, a custom metric where you can pass in some function to call before it calculates the mean. So if you call, so you might remember that the way Torch eval works is it has this thing called update, which gets past the input and the targets. So I add to the weighted sum, the result of calling some function on the input and the targets. So we want two kind of new metrics. One is the, we're going to print it out as KLD, which is a func metric on KLD loss. And one which we'll print out as BCE, which is a func metric on BCE loss. And so the actual, when we call the learner, the loss function we'll use is VAE loss. But we're going to pass in as metrics, this list of additional metrics to print out. So it's just going to print them out. And in some ways it's a little inefficient because it's going to calculate KLD loss twice and BCE loss twice, one to print it out and one to go into the, you know, actual loss function, but it doesn't take long for that bit. So I think that's fine. So now when we call learn.fit, you can see it's printing them all out. So the BCE that we got last time was 0.26. And so this time, yeah, it's not as good. It's 0.31. It's a harder problem. And it's got random, randomness in it. And you can see here that the BCE and KLD are pretty similar scale when it starts. That's a good sign. If they weren't, you know, I could always in the loss function scale one of them up or down. But they're pretty similar to start with. So that's fine. So we train this for a while. And then we can use exactly the same code for sampling as before. And yeah, as we suspected, its ability to decode is worse. So it's actually not capturing the LEE at all, in fact, and the shoes got very blurry. The hope is that when we call it on noise, called the decoder on random noise, that's much better. We're getting, it's not amazing, but we are getting some recognizable shapes. So you know, VAEs are, you know, not generally going to get you as good a results as diffusion models are. Although actually, if you train really good ones for a really long time, they can be pretty impressive. So yeah, even in this extremely simple quick case, we've got something that can generate recognizable items of clothing. Did you guys want to add anything before we move on to the stable diffusion VAE? Okay. So this, yeah, so this VAE is very crappy. And as we mentioned, like one of the, one of the key reasons to use a VAE is actually that you can benefit from all the compute time that somebody else has put into training a good VAE. Maybe just also like one thing of when we say good VAE, the one that we've trained here is good at generating because it maps down to this like one, let's turn a dimensional vector and then back in a very useful way. And like, if you look at VAEs for generating, they'll often have a pretty small dimension in the middle. And it'll just be like this vector that gets mapped back up. And so VAE that's good for generating is slightly different to one that's good for compressing. And like the stable diffusion one we'll see has this like spatial component still, it doesn't map it down to a single vector, it maps it down to a 64 by 64 or whatever. And I think that's smaller than the original, but for generating, we can't just put random noise in there and hope like a cohesive image will come out. So it's less good as a generator, but it is good because it has this like compression and reconstruction ability. Cool. Yeah. So let's take a look. Now to demonstrate this, we want to move to a more difficult task because we want to show off how using latency lets us do stuff we couldn't do well before. So the more difficult task we're going to do is generating bigger images and specifically generate images of bedrooms using the Lsun bedrooms dataset. So Lsun is a really nice dataset which has many, many, many millions of images across 10 scene categories and 20 object categories. And so very, it's very rare for people to use all the object categories, to be honest, but people quite often use the scene categories. They're a little, well more than a little, can be extremely slow to download. The website they come from is very often down. So what I did was I put a subset of 20% of them onto AWS. They kindly provide some free dataset hosting for our students. And also the original Lsun is in a slightly complicated form. It's in something called an LMDB database. So I turned them into just normal images in folders. So you can download them directly from the AWS dataset site that they provided for us. So I'm just using fast core to save it, and then using Python's SHU tool to unpack the gzipped tar file. Okay. So that's given us, once that runs, which is going to take a long time. And you know, if, it might be, you know, even more reliable just to do this in the shell with Wget or ARIA2C or something, than doing it through Python. So this will work, but if it's taking a long time or whatever, maybe just delete it and do it in the shell instead. Okay. So then I thought, all right, how do we turn these into latents? Well, we could create a dataset in the usual way. So it's going to have a length. So we're going to grab all the files. So glob is a built into Python, which we'll search for, in this case, star.jpg. And if you've got star star slash, that's going to search recursively, as long as you pass recursive. So we're going to search for all of the jpg files inside our data slash bedroom folder. So that's what this is going to do. It's going to put them all into the files attribute. And so then when we get an item, the ith item, it will find the ith file. It will read that image. So this is PyTorch's read image. It's the fastest way to read a jpg image. People often use pal, but it's quite hard to find a really well optimized pal version that's really compiled fast, where else the PyTorch TorchVision team have created a very, very fast read image. So that's why I'm using theirs. And if you pass in image read mode dot RGB, it'll automatically turn any one channel black and white images into three channel images for you. Or if there are four channel images with transparency, it'll turn those. So this is a nice way to make sure they're all the same. And then this turns it into floats from not to one. And these images are generally very close to 256 by 256 pixels. So I just crop out the top 256 by 256 bit, because I didn't really care that much. And we do need them to all be the same size in order that we can then pass them to the VAE, stable diffusion VAE decoder as a batch. Otherwise it's going to take forever. So I can create a data loader that's going to go through a bunch of them at a time. So 64 at a time. And use however many CPUs I have as the number of workers. It's going to do it in parallel. And so the parallel bit is the bit that's actually reading the JPEGs, which is otherwise going to be pretty slow. So if we grab a batch, here it is. Here's what it looks like. Generally speaking, they're just bedrooms. Although we've got one pretty risque situation in the bedroom. But on the whole, they're not safe for work. This is the first time I've actually seen an actual bedroom scene taking place, as it were. All right. So as you can see, this mini batch of, if I just grab the first 16 images, has three channels and 256 by 256 pixels. So that's how big that is for 16 images. So that's 728. So 3.145 million floats to represent this. Okay. So as we learned in the first lesson of part two, we can grab an autoencoder directly using diffusers using from pretrained. We can pop it onto our GPU. And importantly, we don't have to say with torch.no grad anymore. If we pass requires grad false. Remember this neat trick in PyTorch, if it ends in an underscore, it actually changes the thing that you're calling in place. So this is going to stop it from computing gradients, which would take a lot of time and a lot of memory otherwise. So let's test it out. Let's encode our mini batch. And so just like Jono was saying, this has now made it much smaller. It's got just in our 16 batch of 16, it's now a four channel 32 by 32. So if we can compare the previous size to the new size, it's 48 times smaller. So that's 48 times less memory it's going to need. And it's also going to be a lot less compute for a convolution to go across that image. So it's no good unless we can turn it back into the original image. So let's just have a look at what it looks like first. Now it's a four channel image, so we can't naturally look at it. But what I could do is just grab the first three channels. And then they're not going to be between 0 and 1. So if I just do dot sigmoid, now they're between 0 and 1. And so you can see that our risque bedroom scene, you can still recognize it. Or this bedroom, this bed here, you can still recognize it. So there's still that kind of like, the basic geometry is still clearly there. But it's, yeah, it's clearly changed it a lot as well. So importantly, we can call decode on this 48 times smaller tensor. And it's really, I think, absolutely remarkable how good it is. I can't tell the difference to the original. If I zoom in a bit. Her face is a bit blurry. Was her face always a bit blurry? It's always a bit blurry. First, second, third. Oh, hang on. Did that used to look like a proper ND? Yeah, okay. So you can see this. You see there, clearly there's an ND here. And now you can't see those letters. So, and this is actually a classic thing that's known for this particular VAE, is it's not able to regenerate writing correctly at small font sizes. I think it's also pretty, it's like, I think we hear with the faces are already pretty well resolution. But if you're at a higher resolution, the faces also would probably not be converted appropriately. Okay, cool. But overall, yeah, it's done a great job. A couple of other things I wanted to note was like, so like you mentioned like a 40, I guess a factor of 48 decrease. Oftentimes people refer to mostly at the spatial resolution. So since it's going from 256 by 256 to 32 by 32, so that's like a factor of eight. So they sometimes will know like, I think it's like F8 or something like this, they'll note the spatial resolution. So sometimes you may see that written out like that. And of course, F8 is an eight squared decrease in the number of pixels, which is interesting. Right. And then the other thing I wanted to note was that the VAE is also trained with a perceptual loss objective, as well as a technically like a discriminator again, objective. I don't know if you were going to go into that a little bit later. So yeah, so perceptual loss, we've already discussed, right? So the VAE is going to, you know, when they trained it, so I think this was trained by CompViz, right? The, you know, Robin and gang and used stability.ai donated compute for that. And they went to... To be clear, actually, no, the VAE was actually trained separately and it's actually trained on the open images dataset. And it was just this VAE that they trained by themselves on, you know, a small subset of data, but because the VAE is so powerful, it's actually able to be applied to all these other datasets as well. Okay, great. Yeah. So they would have had a KL diversion loss and they would have either had an MSC or BCE loss, I think it might've been an MSC loss. They also had a perceptual loss, which is the thing we learned about when we talked about super resolution, which is where when they compared the output images to the original images, they would have run that through a, you know, ImageNet trained or similar classifier and confirmed that the activations they got through that model were similar. And then the final bit is, as Tanejka was mentioning, is the adversarial loss, which is also known as a GAN loss. So a GAN is a generative adversarial network. And the GAN loss, what it does is it grabs... It's actually more specifically what's called a patchwise GAN loss. And what it does is it takes like a little section of an image, right? And what they've done is they train it's... Let's just simplify it for a moment and imagine that they've pre-trained a classifier, right? They've basically got something that you can pass it a real, you know, patch from a bedroom scene and a fake patch from a bedroom scene. And they both go into the, what's called the discriminator. And this is just a normal, you know, ResNet or whatever, which basically outputs something that either says, yep, the image is real. Or nope, the image is fake. So sorry, I said it passes in two things. You just, that was wrong. You just pass in one thing and it returns either it's real or it's fake. And specifically it's going to give you something like the probability that it's real. There is another version. I don't think it's what they use. You pass in two and it tells you which one's relative. Do you remember, Tanisha, is it a relativistic GAN or a normal GAN? I think it's a normal one. Yeah. So the relativistic GAN is when you pass in two images and it says which is more real. The one we think that we, if I remember correctly, they use as a regular GAN, which just tells you the probability that it's real. And so you can just train that by passing in real images and fake images and having it learn to classify which ones are real and which ones are fake. So now that once you've got that model trained, then as you train your GAN, you pass in the patches of each image into the discriminator, let's call D here, right? And it's going to spit out the probability that that's real. And so if it spat out, you know, 0.1 or something, then you're like, oh dear, that's terrible. Our VAE is spitting out pictures of bedrooms where the patches of it are easily recognized as not real. But the good news is that's going to generate derivatives, right? And so those derivatives then is going to tell you how to change the pixels of the original generated image to make it trick the GAN better. And so what it'll do is it'll then use those derivatives as per usual to update our VAE. And the VAE in this case is going to be called a generator, right? That's the thing that's generating the pixels. And so the generator gets updated to be better and better at tricking the discriminator. And after a while, what's going to happen is the generator is going to get so good that the discriminator gets fooled every time, right? And so then at that point, you can fine tune the discriminator better by putting in your better generated images, right? And then once your discriminator learns again how to recognize the difference between real and fake, you can then use it to train the generator. And so this is kind of ping ponging back and forth between the discriminator and the generator. Back when GANs were first created, you know, people were finding them very difficult to train and actually a method we developed at Fast.ai, I don't know if we were the first to do it or not, was this idea of kind of pre-training a generator just using perceptual loss and then pre-training a discriminator to be able to fool the generator and then ping ponging backwards and forwards between them after that, basically whenever the discriminator got too good, start using the generator. Anytime the generator got too good, start using the discriminator. Nowadays that's pretty standard, I think, to do it this way. And so, yeah, this GAN loss, which is basically saying penalize for failing to fool the discriminator, is called an adversarial loss. To maybe motivate why you do this, if you just did it with like a mean squared error or even a perceptual loss with such a high compression ratio, the VAEs tend to like produce a fairly blurry output because it's not sure whether there's texture or not, you know, in this image or the edges aren't like super well defined where they'll be because it's going from like one four dimensional thing up to like this whole patch of the image. And so it tends to be a little bit blurry and hazy because it's kind of hedging its bets, whereas that's something that the discriminator can quite easily pick up. Oh, like it's blurry. It must be fake, you know. And so then it's having the discriminator that is adversarial loss is just kind of saying like even if you're not sure exactly where this texture goes, rather go with a sharper looking texture that looks real than with some blurry thing that's going to maximize your MSC. And so it like tricks it into kind of faking this high resolution looking sharper output. Yeah, and I'm not sure if we're going to come back and like train our own GAN at some point, but if you're interested in training your own GAN or I mean, you shouldn't call it a GAN, right? I mean, nowadays we never really just use a GAN. We have an adversarial loss as part of a training process. If you want to learn how to use adversarial loss, like in detail and see the code, the 2019 fast AI course, lesson seven, part one has a walkthrough. So we have sample code there and you know, yeah, maybe given time we'll come back to it. Okay. So quite often people will call the VAE encoder when they're training a model, which to me makes no sense, right? Because the encoded version of an image never changes unless you are using data augmentation and want to do augmentation on, sorry, do you know, encode augmented images. I think it makes a lot more sense to just do a single run through your whole training set and encode everything once. So naturally the question is then, well, what do you, where do you save that? So it's going to be a lot of RAM. If you put this, leave it in RAM. And also if you, you know, as soon as you restart your computer, we've lost all that work. There's a very nifty file format you can use called a memory mapped NumPy file, which is what I'm going to use to save our latency. A memory mapped NumPy file is basically what happens is you take the memory in RAM that NumPy would normally be using, and you literally like copy it onto the hard disk, basically. That's what they mean by memory mapped. There's a mapping between the memory in RAM and the memory on hard disk. And if you change one, it changes the other and vice versa. They're kind of two ways of seeing the same thing. And so if you, and so if you create a memory mapped NumPy array, then when you modify it, it's actually modifying it on disk. But thanks to the magic of your operating system, it's using all kinds of beautiful caching and stuff to not make that slower than using a normal NumPy array. And it's going to be very clever at, it doesn't have to store it all in RAM. It only stores the bits in RAM that you need at the moment or that you've used recently. It's really nifty, a kind of caching and stuff. So it's kind of, it's like magic, but it's using the, your operating system to do that magic for you. So we're going to create a memory mapped file using np.memmap. And so it's going to be stored somewhere on your disk, right? So we're just going to put it here. And we're going to say, okay, so create a memory mapped file in this place. And it's going to contain 32 bit floats. So write the file. And the shape of this array is going to be the size of our dataset. So 303,125 images, and each one is 4 by 32 by 32. Okay, so that's our memory mapped file. And so now we're going to go through our data loader, one mini batch of 24 at a time. And we're going to VAE encode that mini batch. And then we're going to grab the means from its latency, right? We don't want random numbers, we want the actual, you know, the midpoints, the means. So this is using the diffuser's version of that VAE. So pop that onto the CPU after we're done. And so that's going to be mini batch of size 64 as PyTorch. Let's turn that into NumPy, because PyTorch doesn't have a memory mapped thing, as far as I'm aware, but NumPy does. And so now that we've got this memory mapped array called A, then everything from, initially from 0 up to 64, or 60, yeah, 0 to 64, not including the 64, that whole sub part of the array is going to be set to the encoded version. So it looks like we're just changing it in memory. But because this is a magic memory mapped file, it's actually going to save it to disk as well. So yeah, that's it, amazingly enough. That's all you need to create a memory mapped NumPy array of our latency. When you're done, you actually have to call .flush, and that's just something that says, like, anything that's just in cache at the moment, make sure it's actually written to disk. Then I delete it, because I just want to make sure that then I read it back correctly. So that's only going to happen once, if the path doesn't exist. And then after that, this whole thing will be skipped, and instead we're going to call mp.memmap again, with our mpath, but this time in the same data type, in the same shape, this time we're going to read it. Node equals R, means read it. And so let's check it. Let's just grab the first 16 latents that we read, and decode them. And there they are. So this is, like, not a very well-known technique, I would say, sadly. But it's a really good one. You might be wondering, like, well, what about, like, compression? Like shouldn't you be zipping them, or something like that? But actually, remember, these latents are already, the whole point is, they're highly compressed. So generally speaking, zipping latents from a good VAE doesn't do much. Because they're, like, they almost look a bit random, numberish. Okay, so we've now saved our entire LSUN bedroom. That's a 20% subset, the bit that I've provided. And now, latents. So we can now run it through. This is the nice thing. We can use exactly the same process from here on in, as usual. Okay, so we've got the noisify of our usual collated version. Now the latents are much higher than one standard deviation. So if we about divide it by five, that takes it back to a standard deviation of about one. I think in the paper, they use like 0.18 or something. But this is close enough to make it a unit standard deviation. So we can split it into a training and a validation set. So just grab the first 90% for the training set, and the last 10% for the validation set. So those are our data sets. We use a batch size of 128. So now we can use our data loaders class we created with the getDLs we created. So these are all things we've created ourselves with the training set, the validation set, the batch size, and our collation function. So now it's kind of nice. It's amazing, you know, how easy it is. Like, you know, a data set has the same interface as a NumPy array, or a list, or whatever. So we can literally just use the NumPy array directly as a data set, which I think is really neat. This is why it's useful to know about these foundational concepts, because you don't have to start thinking, like, oh, I wonder if there's some Torch vision thing to use memmap NumPy files or something. It's like, oh, wait, they already do provide a data set interface. I don't have to do anything. I just use them. So that's pretty magical. We can test that now by grabbing a batch. And so this is being noisified. So here we can see our noisified images. And so here's something crazy, is that we can actually decode noisified images. And so, you know, here's, I guess this one wasn't noisified much, because it's a recognizable bedroom. And this is what happens when you just decode random noise. Something in between. So I think that's pretty fun. Yeah. This next bit is all just copied from our previous notebook. Create a model, initialize it. Train for a while. So this took me a few hours on a single GPU. Everything I'm doing is on a single GPU. Literally nothing in this course, other than the stable diffusion stuff itself, is trained on more than one GPU. The loss is much higher than usual. And that's not surprising, because it's trying to generate latent pixels, which where, like, it's much more precise as to exactly what it wants. You know, it's not like lots of pixels where the ones next to each other are really similar, or the whole background looks the same, or a lot of that stuff, it's being compressed out. It's a more difficult thing to predict latent pixels. So now we can sample from it in exactly the same way that we always have, using DDIM. But now we need to make sure that we decode it. Because the thing that it's sampled are latents. Because the thing that we asked it to learn to predict are latents. And so now we can take a look. And we have bedrooms. Ah-ha! And some of them look pretty good. I think this one looks pretty good. I think this one looks pretty good. This one I don't have any idea what it is. And this one, like, clearly there's bedroom-y bits, but there's something, I don't know, there's weird bits. So the fact that we're able to create 256 by 256 pixel images, where at least some of them look quite good, in a couple of hours, I can't remember how long it took to train, it's a small number of hours on a single GPU, is something that was not previously possible. And we're, in a sense, we're totally cheating. Because we're using the stable diffusion VAE to do a lot of the hard work for us. But that's fine, you know, because that VAE knows how to create all kinds of natural images, and drawings, and portraits, and oil paintings, or whatever. So you can, I think, work in that latent space quite comfortably. Yeah. Do you guys have anything you wanted to add about that? Oh, actually, Tanishka, I know you've trained this for longer. I only trained it for 25 epochs. How long did you, how many hours did you train it for? Because you did, you did 100 epochs, right? Yes, I did 100 epochs. I didn't keep track exactly, but I think it was about 15 hours. On that single GPU? On an A100. Okay, it's a single A100. Yeah. I argue, I mean, the results, yeah, I'll show it. It's, it's, yeah, it's, I guess, maybe slightly better. But you know, I guess you can, I'd see maybe. No, it is definitely slightly better. The good ones are certainly slightly better. Yeah. Yeah. Like the bottom left one is better than any of mine, I think. So it's possible, maybe at this point, we just may need to use more data, I guess. I guess we were using a 20% subset. So maybe having more of that data to provide more diversity or something like that, maybe that might help. Yeah, or maybe, have you tried doing the diffusers one for 100? No, I'm using just our code here. Yeah. So I've got, all right, so I'll share my screen if you want to stop sharing yours. So I do have, if we get around to this, maybe we can add the results back to this notebook. Because I do have a version that uses diffusers. So everything else is identical. 25 epochs, except for the model for the previous one, I was using our, our own MVNet model. So I have to change the channels now to four. And number of filters, I think I might have increased it a bit. So then I tried using, yeah, the diffusers unit, just with whatever their defaults were. And so I got, what did I get here? 243 with diffusers. I got a little bit better, 239. And yeah, I don't know if they're obviously better or not. Like, this is a bit weird. I think like, actually, another thing we could try maybe is do 100 epochs, but use the diffusers number of channels and stuff that they used for. Because I think the defaults that they use actually for diffusers is not the same as stable diffusion. So maybe we could try stable diffusion matched unit for a hundred epochs. And if we get any nice results, maybe we can paste them into the bottom to show people. Yeah. Yeah. Cool. Yeah. Do you guys have anything else to add at this point? All right. So I'll just mention one more thought in terms of like a bit of a interesting project people could play with. I don't know if this is too crazy. I don't think it's been done before. But my thought was like, there was a huge difference in our super resolution. Do you remember a huge difference in our super resolution results when we used a pre-trained model and when we used perceptual loss, but particularly when we used a pre-trained model? I thought we could use a pre-trained model, but we would need a pre-trained latence model, right? We would want something where our, you know, down sampling backbone was pre-trained model on latence. And so I just want to just show you what I've done. And you guys, you know, if anybody watching wanted to try taking this further, I've just done the first bit for you to give you a sense, which is I've pre-trained an ImageNet model, not tiny ImageNet, but a full ImageNet model on latence as a classifier. And if you use this as a backbone, you know, and also try maybe some of the other tricks that we found helpful, like having ResNets on the cross connections. These are all things that I don't think anybody's done before. I don't know, the scientific literature is vast and I might've missed it, but I've not come across anybody do these tricks before. So obviously like we're, one of the interesting parts of this, which is designed to be challenging is that we're using bigger datasets now, but they're datasets that you can absolutely like run on a single GPU, you know, a few tens of gigabytes, which fits on any modern hard drive easily. So these like are good tests of your ability to kind of like move things around. If you're somewhere that doesn't have access to a decent internet connection or whatever, this might be out of the question, in which case don't worry about it. But if you can, yes, try this because it's good practice, I think, to make sure you can use these larger datasets. So ImageNet itself, you can actually grab from Kaggle nowadays. So they call it the object localization challenge, but actually this contains the full ImageNet dataset. Well, the version that's used for the ImageNet competition. So I think people generally call it ImageNet one case. You just have to accept the terms because it has like some distribution terms. Yeah, exactly. So you've got to kind of sign in and then join the competition and then yeah, accept the terms. So you can then download the dataset or you can also download it from Hugging Face. That'll be in a somewhat different format, but that'll work as well. So I think I grabbed my version from Kaggle. So on Kaggle, you know, it's just a zip file. You unzip it and it creates an ILSVRC directory, which I think is what they call the competition. Yeah, ImageNet large scale visual recognition challenge. Okay. So then inside there, there is a data and inside there, there is a CLS lock and that's actually where the, that's where actually everything's going to be. So just like before, I wanted to turn these all into latency. So I created in that directory, I created a latency sub directory and this time partly just to demonstrate how these things work, I want to do it a slightly different way. Okay. So again, we're going to create our pre-trained VAE, pop it on the GPU, turn off gradients for it, and I'm going to create a dataset. Now one thing that's a bit weird about this is that because this is really quite a big dataset, like it's got 1.3 million files, the thing where we go glob star star slash star dot jpg takes a few seconds, you know, and particularly if you're doing this on like, you know, an AWS file system or something, it can take really quite a long time. On mine, it only took like three seconds, but I don't want to wait three seconds. So I, you know, a common trick for these kinds of big things is to create a cache, which is literally just a list of the files. So that's what this, this is. So I decided that Z pickle means a g zipped pickle. So what I do is if, if, if the cache exists, we just g zip dot open the files. If it doesn't, we use blob exactly like before to find all the files. And then we also save a g zip file containing pickle dot dump files. So pickle dot dump is what we use in Python to take basically any Python object list of dictionaries and dictionary of lists, whatever you like and save them. It's super fast, right? And I use g zip with compressed level one to basically be like compress it pretty well, but pretty fast. So this is a really nice way to create a little cache of that. So this is the same as always. And so our get item is going to grab the file. It's going to read it in, turn it into a float. And what I did here was, you know, I'm being a little bit lazy, but I just decided to center crop the middle, you know, so let's say it was a 300 by 400 file. It's going to center crop the middle 300 by 300 section. And then resize it to 256 by 256. So they'll all be the same size. So yeah, we can now, oh, I managed to create the VAU twice. So I can now just confirm. I can grab a batch from that data loader, encode it. And here it is. And then decode it again. And here it is. So perhaps the first category must have been computer or something. So here's, as you can see, the VAU is doing a good job of decoding pictures of computers. So I can do something really very similar to what we did before. If we haven't got that destination directory yet created, go through our data loader, encode a batch. And this time I'm not using a mem mapped file. I'm actually going to save separate numpy files for each one. So go through each element of the batch, each item. So I'm going to save it into the destination directory, which is the latent directory. And I'm going to give it exactly the same path as the original one contained, because it contains the, you know, the folder of like what the label is. Make sure that the directory exists that we're saving it to, and save that just as a numpy file. This is another way to do it. So this is going to be a separate numpy file for each item. Does that make sense so far? Okay, cool. So I could create a thing called a numpy dataset, which is exactly the same as our images dataset. To get an item, we don't have to use, you know, open a JPEG anymore. We just call mp.load. So this is a nice way to like take something you've already got and change it slightly. So it's going to return the... Where did you do this versus the memory mapped file, Jeremy? Just out of interest. Sorry? Where did you do this versus the memory mapped file? Was it just to show a different way? Just to show a different way. Yeah. Yeah. I think that's definitely no particularly good reason, honestly. Yeah, I like to kind of like demonstrate different approaches. And I think it's good for people's Python coding if you make sure you understand what all the lines of code do. Yeah, they both work fine, actually. It's partly also for my own experimental interest. It's like, oh, which one seems to kind of feel better? Yeah. All right. So create out training and validation datasets by grabbing all the NumPy files inside the training and validation folders. And then I'm going to just create a training data loader for the training dataset, just to see what the mean and standard deviation is on the channel dimension. So this is every dimension except channel, what I mean, over. And so there it is. And as you can see there, the mean and standard deviation are not close to zero and one. So we're going to store away that mean and standard deviation such that we then, we've seen transform dataset before. This is just applying a transform to a dataset. We're going to apply the normalization transform. In the past, we've just, we've used our own normalization. That TorchVision has one as well. So this is just demonstrating how to just use TorchVision's version. But it's literally just subtracting the mean and dividing by the standard deviation. We're also going to apply some data augmentation. We're going to use the same trick we've used before for images that are very small, which is we're going to add a little bit of padding and then randomly crop our original image size from that. So it's just like shifting it slightly each time. And we're also going to use our random erasing. And it's nice because we did it all with broadcasting. This is going to apply equally well to a four channel image as it is to a three, or I think we did originally for one. Now, you know, I don't think anybody as far as I know has built classifiers from Latents before. So like I didn't even know if this is going to work. So I visualized it. So we could have a TIFM X and a TIFM Y. So for TIFM X, you can optionally add augmentation. And if you do, then apply the augmentation transforms. Now this is going to be applied one image at a time. But our augmentation transforms, some of them expect to batch. So we create a extra unit axis on the front to be a batch of one and then remove it again. And then TIFM Y, very much like we've seen before, we're going to turn those path names into IDs. So there's our validation and training transform datasets. So that we can look at our results, we need a denormalization. So let's create our data loaders and grab mini batches and show us. And so I was very pleased to see that the random arrays works actually extremely nicely. So you can see you get these kind of like weird patches, you know, weird patches. But it's still, they're still recognizable. So this is, this is like something I very, very often do is to answer like, oh, is this like thing I'm doing in computer vision reasonable? It's like, well, can my human brain recognize it? So if I couldn't recognize this was a drilling platform myself, then I shouldn't expect a computer to be able to do it. Or that this is a compass or whatever. I'm so glad they've got otters, so cute. And you can see the cropping it's done has also been fine. Like it's a little bit of a fuzzy edge, but basically like it's not destroying the image at all. They're still recognizable. It's also a good example here of how difficult like this problem is. Like the fact that this is seashore, I would have called this surface, you know, but maybe surface is not an image in that category. But yeah. Okay. This could be food, but actually it's a refrigerator. Okay. So our augmentation seems to be working well. So then I, yeah, basically I've just copied and pasted, you know, our basic pieces here. And I kind of wanted to have it all in one place, just to remind myself of exactly what it is. So this is the pre activation version of convolutions. The reason for that is if I want this to be a backbone for a diffusion model or a unit, then I remember that we found that pre activation works best for units. So therefore our backbone needs to be trained with pre activation. So we've got a pre activation conv, got a res block, res blocks model with dropouts. This is all just copied from previous. So I decided, like, I wanted to try to, you know, use the basic trick that we learned about from simple diffusion of trying to put most of our work in the later layers. So the first layer just has one block, then two blocks, and then four blocks. And then I figured that we might then delete these final blocks. Because maybe you're going to just end up being for classification. This might end up being our pre trained backbone. Or maybe we keep them. I don't know. You know, it's like, as I said, this hasn't been done before. So anyway, I tried to design it in a way that we've got some, you know, we can mess around a little bit with how many of these we keep. And so also I tried to use very few channels in the first blocks. And so I jump up for the channels that are where the work's going to do. So I jump from 128 to 512. So that's why I designed it this way. You know, I haven't even taken it any further than this. So I don't know if it's going to be a useful backbone or not. I didn't even know if this is going to be possible to classify. It seemed very likely it was possible to classify, even based on the fact that you can still kind of recognize it almost. Like I could probably recognize it's a computer, maybe. So I thought it was going to be possible. But yeah, this is all new. So that was the model I created. And then I, yeah, trained it for 40 epochs. And you can see after one epoch, it was already 25% accurate. And that's it recognizing which one of a thousand categories is it. So I thought that was pretty amazing. And so after 40 epochs, I ended up at 66%, which is really quite fantastic, because a ResNet 34 is kind of like 73 or 74% accuracy when trained for quite a lot longer. You know, so to me, this is extremely encouraging that, you know, this is a really pretty good ResNet at recognizing images from their latent representations without any decoding or whatever. So from here, you know, if you want to, you guys could try, yeah, building a better bedroom diffusion model, or whatever you like. It doesn't have to be bedrooms. Actually, one of our colleagues, Molly, I'm just going to find it. So one of our colleagues, Molly, actually used the, do you guys remember, was it the CelebFaces that she used? So there's a CelebAHQ dataset that consists of images of faces of celebrities. And so what Molly did was she basically, yeah, used this exact notebook, but used this faces dataset instead. And this one's really pretty good, isn't it? You know, this one's really pretty good. They certainly look like celebrities, that's for sure. So yeah, you could try this dataset or whatever, but yeah, try it. Maybe try it with the pre-trained backbone. Try it with ResNets on the cross connections. Try it with all the tricks we used in SuperRes. Try it with perceptual loss. Some folks we spoke to about the perceptual loss think it won't help with latents because the underlying VAE was already trained with perceptual loss, but we should try, you know, or you guys should try all these things. Yeah. So be sure to check out the forum as well to see what other people have already tried here because it's a whole new world. But it's just an example of the kind of like fun research ideas I guess we can play with. Yeah. What do you guys think about this? Are you like surprised that we're able to quickly get this kind of accuracy from latents? Or do you think this is a useful research path? What are your thoughts? Yeah, I think it's very interesting. Oh, go ahead. I was going to say the latents are already like a slightly compressed richer representation of an image, right? So it makes sense that that's a useful thing to train on. 66%, I think AlexNet is like 63% or something like that. So you know, we were already at state of the art, what, eight years ago or whatever. Yeah, it's pretty cool. I'm going to say it might be more like 10 years ago. I know time passes quickly. Yeah, yeah, I guess next year. Yeah, next year it is 10 years ago. But yeah, I'm kind of curious with the pre-training, the whole value for me for like using a pre-trained network was someone else has done lots and lots of compute on ImageNet to learn some features and I'm going to use that. So it's kind of funny to be like, oh, well, let's pre-train for ourselves and then try and use that. I'm curious whether, like how best you'd allocate that compute, whether you should, if you've got 10 hours of GPU, just do 10 hours of training versus like five hours of pre-training and five hours of training. I mean, based on our super res thing, the pre-training like was so much better. So that's why I'm feeling somewhat hopeful about this direction. Yeah, I'm really curious to see how it goes. I guess I was going to say it's like, yeah, I think there's just a lot of opportunities for I guess the latent, doing stuff in the latents. And like, I guess maybe like, yeah, you could, I mean, here you're trading classifier as a backbone, but you could think of like trading classifiers on other things for guidance or things like this. Of course, we've done some experiments with that. I know Jono has his mid-year guidance approach for some of this sort of things, but there are different approaches that you can play around here that exploring in the latent space can make it computationally cheaper than having to decode it every time you want to, like you have to look at the image and then maybe apply a classifier or apply some sort of guidance on the image. But if you can do it directly in the latent space, a lot of interesting opportunities there as well. And now we're showing that indeed. On latents. Everything on latents. You can also distill existing models. That's something I've done to make a latent clip is just have it try and mirror an image space clip. And so for classifiers as well, you could distill an ImageNet classifier. Rather than just having the label, you try and copy the logits. And then that's an even richer signal. You get more value per example. So then you can create your latent version of some existing image classifier or object detector or, yeah, like multimodal model like that. I feel like I feel funny about this because I'm like both excited about simple diffusion on the basis that it gets rid of latents. But I'm also excited about latents on the basis of gets rid of most of the pixels. I don't know how I can be cheering for both, but somehow I am. I guess may the best method win. So you know, the folks that are finishing this course, well, first of all, congratulations because it's been a journey, particularly part two. It's a journey which requires a lot of patience and tenacity. You know, if you've kind of zipped through by binging on the videos, that's totally fine. It's a good approach. But, you know, maybe go back now and do it more slowly and do the, you know, build it yourself and really experiment. But assuming, you know, for folks who have got to the end of this and feel like, OK, I get it more or less. Yeah. Do you guys have any sense of like what kind of things make sense to do now? You know, where would you guys go from here? I think that a great opportunity is implementing papers that I guess come along these days. And I think at this stage... Wait, there'll be more papers? No way. Yeah. But also at this stage, I think, you know, we're already discussing research ideas and I think, you know, we're in a solid position to come up with our own research ideas and explore those ideas. So I think that's a real opportunity that we have here. Yeah, I would say, I think that's best done often collaboratively. So I'll just mention that Fast.ai has a Discord, which if you've got to this point, then you're probably somebody who would benefit from being there. And yeah, just pop your head in and say, like, there's an introduction, so just say hello and you don't, you know, maybe say what you're interested in or whatever, because it's nice to work with others, I think. I mean, both Jono and Tanishka I only know because of the Discord and the forums and so forth. So that would be one. And we also have a, we have a generative channel. So anything related to generative models, that's the place. So for example, Molly was posting some of her experiments in that channel. I think there are other Fast.ai members posting their experiments. So if you're doing anything generative model related, that's a great way to also get feedback and thoughts from the community. Yeah. I'd also say that, like, there's this, if you're at the stage where you finish this course, you actually understand how diffusion models work. You've got a good handle on what the different components and like stable diffusion are. And you know how to wrangle data for training and all these things. You're like so far ahead of most people who are building in this space. And I've got lots of, lots of companies and people reaching out to me to say, do you know anybody who has like more than just, oh, I know how to like load stable diffusion and make an image. And I know someone who knows how to actually like tinker with it and make it better. And if you've got those skills, like, don't feel like, oh, I'm definitely not qualified to like apply or like, there's lots of stuff where, yeah, just taking these ideas now and like just simple, sensible ideas that we've covered in the course that have come up and say, like, oh, actually, maybe I could try that. Maybe I could play with this, you know, take this experimentalist approach. I feel like there's actually a lot of people who would love to have you helping them build a million and one little stable diffusion based apps or whatever that you're working on. And particularly like the thing we always talk about at Fast.ai, which is particularly if you can combine that with your domain expertise, you know, whether it be from your, your hobbies or your work in some completely different field or whatever, you know, there'll be lots of interesting ways to combine, you know, you probably are one of the only people in the world right now that understand your areas of passion or of vocation as well as these techniques. So, and again, that's a good place to kind of get on the forum or the discord or whatever and start having those conversations. Because it can be, yeah, it can be difficult when you're at the cutting edge, which you now are by definition. All right. Well, we better go away and start figuring out how on earth GPT-4 works. I don't think we're going to necessarily build the whole GPT-4 from scratch, at least not at that scale, but I'm sure we're going to have some interesting things happening with NLP. And Jono, Tanisha, thank you so much. It's been a real pleasure. It was nice doing things with the, with a live audience, but I've got to say, I really enjoyed this experience of doing stuff with you guys the last few lessons. So thank you so much. Yeah. Thanks for having us. This is really, really fun. All right. Bye. Cool. See you in part three. Bye. Yeah. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.92, "text": " Hi everybody and welcome to the last lesson of part two.", "tokens": [50364, 2421, 2201, 293, 2928, 281, 264, 1036, 6898, 295, 644, 732, 13, 50660], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 1, "seek": 0, "start": 5.92, "end": 7.16, "text": " Greetings Jono and greetings Tanishka.", "tokens": [50660, 20032, 7745, 78, 293, 33667, 314, 7524, 2330, 13, 50722], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 2, "seek": 0, "start": 7.16, "end": 8.84, "text": " How are you guys doing?", "tokens": [50722, 1012, 366, 291, 1074, 884, 30, 50806], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 3, "seek": 0, "start": 8.84, "end": 11.120000000000001, "text": " Good thanks.", "tokens": [50806, 2205, 3231, 13, 50920], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 4, "seek": 0, "start": 11.120000000000001, "end": 12.120000000000001, "text": " Doing well.", "tokens": [50920, 18496, 731, 13, 50970], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 5, "seek": 0, "start": 12.120000000000001, "end": 13.44, "text": " Excited for the last lesson.", "tokens": [50970, 9368, 1226, 337, 264, 1036, 6898, 13, 51036], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 6, "seek": 0, "start": 13.44, "end": 16.04, "text": " It's been an interesting fun journey.", "tokens": [51036, 467, 311, 668, 364, 1880, 1019, 4671, 13, 51166], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 7, "seek": 0, "start": 16.04, "end": 17.04, "text": " Yeah.", "tokens": [51166, 865, 13, 51216], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 8, "seek": 0, "start": 17.04, "end": 23.48, "text": " I should explain we're not quite completing all of stable diffusion in this part of the", "tokens": [51216, 286, 820, 2903, 321, 434, 406, 1596, 19472, 439, 295, 8351, 25242, 294, 341, 644, 295, 264, 51538], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 9, "seek": 0, "start": 23.48, "end": 24.48, "text": " course.", "tokens": [51538, 1164, 13, 51588], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 10, "seek": 0, "start": 24.48, "end": 28.32, "text": " There's going to be one piece left for the next part of the course, which is the clip", "tokens": [51588, 821, 311, 516, 281, 312, 472, 2522, 1411, 337, 264, 958, 644, 295, 264, 1164, 11, 597, 307, 264, 7353, 51780], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 11, "seek": 0, "start": 28.32, "end": 29.32, "text": " embeddings.", "tokens": [51780, 12240, 29432, 13, 51830], "temperature": 0.0, "avg_logprob": -0.3657803616281283, "compression_ratio": 1.6181102362204725, "no_speech_prob": 0.004464816302061081}, {"id": 12, "seek": 2932, "start": 29.64, "end": 35.480000000000004, "text": " Because clip is NLP and so the next part of the course we will be looking at NLP.", "tokens": [50380, 1436, 7353, 307, 426, 45196, 293, 370, 264, 958, 644, 295, 264, 1164, 321, 486, 312, 1237, 412, 426, 45196, 13, 50672], "temperature": 0.0, "avg_logprob": -0.3041092487091714, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.091967174550518e-05}, {"id": 13, "seek": 2932, "start": 35.480000000000004, "end": 41.36, "text": " So we will end up finishing stable diffusion from scratch, but we're going to have to have", "tokens": [50672, 407, 321, 486, 917, 493, 12693, 8351, 25242, 490, 8459, 11, 457, 321, 434, 516, 281, 362, 281, 362, 50966], "temperature": 0.0, "avg_logprob": -0.3041092487091714, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.091967174550518e-05}, {"id": 14, "seek": 2932, "start": 41.36, "end": 43.4, "text": " a significant diversion.", "tokens": [50966, 257, 4776, 49422, 13, 51068], "temperature": 0.0, "avg_logprob": -0.3041092487091714, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.091967174550518e-05}, {"id": 15, "seek": 2932, "start": 43.4, "end": 51.2, "text": " And what we thought was given everything that's happened with GPT-4 and stuff since we started", "tokens": [51068, 400, 437, 321, 1194, 390, 2212, 1203, 300, 311, 2011, 365, 26039, 51, 12, 19, 293, 1507, 1670, 321, 1409, 51458], "temperature": 0.0, "avg_logprob": -0.3041092487091714, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.091967174550518e-05}, {"id": 16, "seek": 2932, "start": 51.2, "end": 58.68, "text": " this course, we thought it makes more sense to delve into that quite deeply more soon.", "tokens": [51458, 341, 1164, 11, 321, 1194, 309, 1669, 544, 2020, 281, 43098, 666, 300, 1596, 8760, 544, 2321, 13, 51832], "temperature": 0.0, "avg_logprob": -0.3041092487091714, "compression_ratio": 1.5726141078838174, "no_speech_prob": 8.091967174550518e-05}, {"id": 17, "seek": 5868, "start": 59.68, "end": 62.88, "text": " And delay clip as a result.", "tokens": [50414, 400, 8577, 7353, 382, 257, 1874, 13, 50574], "temperature": 0.0, "avg_logprob": -0.33151379147091425, "compression_ratio": 1.4421052631578948, "no_speech_prob": 6.50236033834517e-05}, {"id": 18, "seek": 5868, "start": 62.88, "end": 66.0, "text": " So hopefully people feel comfortable with that decision.", "tokens": [50574, 407, 4696, 561, 841, 4619, 365, 300, 3537, 13, 50730], "temperature": 0.0, "avg_logprob": -0.33151379147091425, "compression_ratio": 1.4421052631578948, "no_speech_prob": 6.50236033834517e-05}, {"id": 19, "seek": 5868, "start": 66.0, "end": 72.0, "text": " But I think we'll have a lot of exciting NLP material coming up.", "tokens": [50730, 583, 286, 519, 321, 603, 362, 257, 688, 295, 4670, 426, 45196, 2527, 1348, 493, 13, 51030], "temperature": 0.0, "avg_logprob": -0.33151379147091425, "compression_ratio": 1.4421052631578948, "no_speech_prob": 6.50236033834517e-05}, {"id": 20, "seek": 5868, "start": 72.0, "end": 74.2, "text": " So that's the rough plan.", "tokens": [51030, 407, 300, 311, 264, 5903, 1393, 13, 51140], "temperature": 0.0, "avg_logprob": -0.33151379147091425, "compression_ratio": 1.4421052631578948, "no_speech_prob": 6.50236033834517e-05}, {"id": 21, "seek": 5868, "start": 74.2, "end": 75.88, "text": " All right.", "tokens": [51140, 1057, 558, 13, 51224], "temperature": 0.0, "avg_logprob": -0.33151379147091425, "compression_ratio": 1.4421052631578948, "no_speech_prob": 6.50236033834517e-05}, {"id": 22, "seek": 5868, "start": 75.88, "end": 83.8, "text": " So I think what we might do is maybe start by looking at a really interesting and quite", "tokens": [51224, 407, 286, 519, 437, 321, 1062, 360, 307, 1310, 722, 538, 1237, 412, 257, 534, 1880, 293, 1596, 51620], "temperature": 0.0, "avg_logprob": -0.33151379147091425, "compression_ratio": 1.4421052631578948, "no_speech_prob": 6.50236033834517e-05}, {"id": 23, "seek": 8380, "start": 83.8, "end": 90.44, "text": " successful application of pixel level diffusion by applying it not to pixels that represent", "tokens": [50364, 4406, 3861, 295, 19261, 1496, 25242, 538, 9275, 309, 406, 281, 18668, 300, 2906, 50696], "temperature": 0.0, "avg_logprob": -0.3041137330075528, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.11427915841341019}, {"id": 24, "seek": 8380, "start": 90.44, "end": 94.16, "text": " an image, but pixels that represent a sound.", "tokens": [50696, 364, 3256, 11, 457, 18668, 300, 2906, 257, 1626, 13, 50882], "temperature": 0.0, "avg_logprob": -0.3041137330075528, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.11427915841341019}, {"id": 25, "seek": 8380, "start": 94.16, "end": 95.24, "text": " Which is pretty crazy.", "tokens": [50882, 3013, 307, 1238, 3219, 13, 50936], "temperature": 0.0, "avg_logprob": -0.3041137330075528, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.11427915841341019}, {"id": 26, "seek": 8380, "start": 95.24, "end": 98.96, "text": " So maybe Jono, of course it's going to be Jono, he does the crazy stuff, which is great.", "tokens": [50936, 407, 1310, 7745, 78, 11, 295, 1164, 309, 311, 516, 281, 312, 7745, 78, 11, 415, 775, 264, 3219, 1507, 11, 597, 307, 869, 13, 51122], "temperature": 0.0, "avg_logprob": -0.3041137330075528, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.11427915841341019}, {"id": 27, "seek": 8380, "start": 98.96, "end": 106.75999999999999, "text": " So Jono, show your crazy and crazily successful approach to diffusion for pixels of sounds,", "tokens": [51122, 407, 7745, 78, 11, 855, 428, 3219, 293, 46348, 953, 4406, 3109, 281, 25242, 337, 18668, 295, 3263, 11, 51512], "temperature": 0.0, "avg_logprob": -0.3041137330075528, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.11427915841341019}, {"id": 28, "seek": 8380, "start": 106.75999999999999, "end": 107.75999999999999, "text": " please.", "tokens": [51512, 1767, 13, 51562], "temperature": 0.0, "avg_logprob": -0.3041137330075528, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.11427915841341019}, {"id": 29, "seek": 8380, "start": 107.75999999999999, "end": 108.75999999999999, "text": " Sure thing.", "tokens": [51562, 4894, 551, 13, 51612], "temperature": 0.0, "avg_logprob": -0.3041137330075528, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.11427915841341019}, {"id": 30, "seek": 10876, "start": 109.76, "end": 110.76, "text": " Right.", "tokens": [50414, 1779, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2573569118976593, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.0912102535367012}, {"id": 31, "seek": 10876, "start": 110.76, "end": 114.2, "text": " So this is going to be a little bit of show and tell.", "tokens": [50464, 407, 341, 307, 516, 281, 312, 257, 707, 857, 295, 855, 293, 980, 13, 50636], "temperature": 0.0, "avg_logprob": -0.2573569118976593, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.0912102535367012}, {"id": 32, "seek": 10876, "start": 114.2, "end": 119.72, "text": " Most of the code in the notebook is just copied and pasted from, I think, notebook 30.", "tokens": [50636, 4534, 295, 264, 3089, 294, 264, 21060, 307, 445, 25365, 293, 1791, 292, 490, 11, 286, 519, 11, 21060, 2217, 13, 50912], "temperature": 0.0, "avg_logprob": -0.2573569118976593, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.0912102535367012}, {"id": 33, "seek": 10876, "start": 119.72, "end": 123.68, "text": " But we're going to be trying to generate something other than just images.", "tokens": [50912, 583, 321, 434, 516, 281, 312, 1382, 281, 8460, 746, 661, 813, 445, 5267, 13, 51110], "temperature": 0.0, "avg_logprob": -0.2573569118976593, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.0912102535367012}, {"id": 34, "seek": 10876, "start": 123.68, "end": 127.08000000000001, "text": " So specifically I'm going to be loading up a dataset of bird calls.", "tokens": [51110, 407, 4682, 286, 478, 516, 281, 312, 15114, 493, 257, 28872, 295, 5255, 5498, 13, 51280], "temperature": 0.0, "avg_logprob": -0.2573569118976593, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.0912102535367012}, {"id": 35, "seek": 10876, "start": 127.08000000000001, "end": 132.68, "text": " These are just like short samples of, I think, 10 different classes of birds calling.", "tokens": [51280, 1981, 366, 445, 411, 2099, 10938, 295, 11, 286, 519, 11, 1266, 819, 5359, 295, 9009, 5141, 13, 51560], "temperature": 0.0, "avg_logprob": -0.2573569118976593, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.0912102535367012}, {"id": 36, "seek": 10876, "start": 132.68, "end": 136.12, "text": " And so we need to understand like, okay, well, this is a totally different domain, right?", "tokens": [51560, 400, 370, 321, 643, 281, 1223, 411, 11, 1392, 11, 731, 11, 341, 307, 257, 3879, 819, 9274, 11, 558, 30, 51732], "temperature": 0.0, "avg_logprob": -0.2573569118976593, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.0912102535367012}, {"id": 37, "seek": 10876, "start": 136.12, "end": 137.44, "text": " This is audio.", "tokens": [51732, 639, 307, 6278, 13, 51798], "temperature": 0.0, "avg_logprob": -0.2573569118976593, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.0912102535367012}, {"id": 38, "seek": 13744, "start": 137.44, "end": 139.76, "text": " If you look at the data, like let's look at an example of the data.", "tokens": [50364, 759, 291, 574, 412, 264, 1412, 11, 411, 718, 311, 574, 412, 364, 1365, 295, 264, 1412, 13, 50480], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 39, "seek": 13744, "start": 139.76, "end": 141.8, "text": " This is coming from a hugging face dataset.", "tokens": [50480, 639, 307, 1348, 490, 257, 41706, 1851, 28872, 13, 50582], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 40, "seek": 13744, "start": 141.8, "end": 145.48, "text": " So that, that line of code will download it automatically if you haven't got it before.", "tokens": [50582, 407, 300, 11, 300, 1622, 295, 3089, 486, 5484, 309, 6772, 498, 291, 2378, 380, 658, 309, 949, 13, 50766], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 41, "seek": 13744, "start": 145.48, "end": 146.48, "text": " Right.", "tokens": [50766, 1779, 13, 50816], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 42, "seek": 13744, "start": 146.48, "end": 147.48, "text": " Yeah.", "tokens": [50816, 865, 13, 50866], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 43, "seek": 13744, "start": 147.48, "end": 148.48, "text": " Yeah.", "tokens": [50866, 865, 13, 50916], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 44, "seek": 13744, "start": 148.48, "end": 152.28, "text": " So this will download it into a cache and then sort of handle a lot of the data.", "tokens": [50916, 407, 341, 486, 5484, 309, 666, 257, 19459, 293, 550, 1333, 295, 4813, 257, 688, 295, 264, 1412, 13, 51106], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 45, "seek": 13744, "start": 152.28, "end": 153.72, "text": " You created this dataset, right?", "tokens": [51106, 509, 2942, 341, 28872, 11, 558, 30, 51178], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 46, "seek": 13744, "start": 153.72, "end": 158.4, "text": " Did you, is this already a dataset you found somewhere else or you made it or what?", "tokens": [51178, 2589, 291, 11, 307, 341, 1217, 257, 28872, 291, 1352, 4079, 1646, 420, 291, 1027, 309, 420, 437, 30, 51412], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 47, "seek": 13744, "start": 158.4, "end": 163.4, "text": " This is a subset that I made from a much larger dataset of longer call recordings from an", "tokens": [51412, 639, 307, 257, 25993, 300, 286, 1027, 490, 257, 709, 4833, 28872, 295, 2854, 818, 25162, 490, 364, 51662], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 48, "seek": 13744, "start": 163.4, "end": 165.74, "text": " open website called ZenoCanto.", "tokens": [51662, 1269, 3144, 1219, 1176, 5808, 34, 5857, 13, 51779], "temperature": 0.0, "avg_logprob": -0.3070674299382839, "compression_ratio": 1.7840531561461794, "no_speech_prob": 0.06278137117624283}, {"id": 49, "seek": 16574, "start": 165.74, "end": 168.34, "text": " So they collect all of these sound recordings from people.", "tokens": [50364, 407, 436, 2500, 439, 295, 613, 1626, 25162, 490, 561, 13, 50494], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 50, "seek": 16574, "start": 168.34, "end": 171.66, "text": " They have experts who help identify what birds are calling.", "tokens": [50494, 814, 362, 8572, 567, 854, 5876, 437, 9009, 366, 5141, 13, 50660], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 51, "seek": 16574, "start": 171.66, "end": 176.86, "text": " And so all I did was find the audio peaks, like where is there most likely to be a bird", "tokens": [50660, 400, 370, 439, 286, 630, 390, 915, 264, 6278, 26897, 11, 411, 689, 307, 456, 881, 3700, 281, 312, 257, 5255, 50920], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 52, "seek": 16574, "start": 176.86, "end": 182.9, "text": " call and clip around those just to get a smaller dataset of things where there's actually something", "tokens": [50920, 818, 293, 7353, 926, 729, 445, 281, 483, 257, 4356, 28872, 295, 721, 689, 456, 311, 767, 746, 51222], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 53, "seek": 16574, "start": 182.9, "end": 183.9, "text": " happening.", "tokens": [51222, 2737, 13, 51272], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 54, "seek": 16574, "start": 183.9, "end": 184.9, "text": " Nice.", "tokens": [51272, 5490, 13, 51322], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 55, "seek": 16574, "start": 184.9, "end": 189.02, "text": " Not a particularly amazing dataset in terms of like the recordings have a lot of background", "tokens": [51322, 1726, 257, 4098, 2243, 28872, 294, 2115, 295, 411, 264, 25162, 362, 257, 688, 295, 3678, 51528], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 56, "seek": 16574, "start": 189.02, "end": 192.38, "text": " noise and stuff, but a fun, small audio one to play with.", "tokens": [51528, 5658, 293, 1507, 11, 457, 257, 1019, 11, 1359, 6278, 472, 281, 862, 365, 13, 51696], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 57, "seek": 16574, "start": 192.38, "end": 193.38, "text": " Yeah.", "tokens": [51696, 865, 13, 51746], "temperature": 0.0, "avg_logprob": -0.26184735055697167, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.09134173393249512}, {"id": 58, "seek": 19338, "start": 193.38, "end": 197.18, "text": " And so when we talk about audio, you've got a microphone somewhere it's reading like a", "tokens": [50364, 400, 370, 562, 321, 751, 466, 6278, 11, 291, 600, 658, 257, 10952, 4079, 309, 311, 3760, 411, 257, 50554], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 59, "seek": 19338, "start": 197.18, "end": 200.85999999999999, "text": " pressure level essentially in the air with these sound waves.", "tokens": [50554, 3321, 1496, 4476, 294, 264, 1988, 365, 613, 1626, 9417, 13, 50738], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 60, "seek": 19338, "start": 200.85999999999999, "end": 203.18, "text": " And it's doing that some number of times per second.", "tokens": [50738, 400, 309, 311, 884, 300, 512, 1230, 295, 1413, 680, 1150, 13, 50854], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 61, "seek": 19338, "start": 203.18, "end": 204.85999999999999, "text": " So we have a sample rate.", "tokens": [50854, 407, 321, 362, 257, 6889, 3314, 13, 50938], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 62, "seek": 19338, "start": 204.85999999999999, "end": 209.82, "text": " And in this case, the data has a sample rate of 32,000 samples per second.", "tokens": [50938, 400, 294, 341, 1389, 11, 264, 1412, 575, 257, 6889, 3314, 295, 8858, 11, 1360, 10938, 680, 1150, 13, 51186], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 63, "seek": 19338, "start": 209.82, "end": 210.82, "text": " So every second that's recorded.", "tokens": [51186, 407, 633, 1150, 300, 311, 8287, 13, 51236], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 64, "seek": 19338, "start": 210.82, "end": 214.57999999999998, "text": " This is a waveform that's being approximated as lots of little up across, up across, up", "tokens": [51236, 639, 307, 257, 36512, 300, 311, 885, 8542, 770, 382, 3195, 295, 707, 493, 2108, 11, 493, 2108, 11, 493, 51424], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 65, "seek": 19338, "start": 214.57999999999998, "end": 217.22, "text": " across kind of things basically.", "tokens": [51424, 2108, 733, 295, 721, 1936, 13, 51556], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 66, "seek": 19338, "start": 217.22, "end": 218.22, "text": " Yeah.", "tokens": [51556, 865, 13, 51606], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 67, "seek": 19338, "start": 218.22, "end": 219.22, "text": " Is that right?", "tokens": [51606, 1119, 300, 558, 30, 51656], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 68, "seek": 19338, "start": 219.22, "end": 220.22, "text": " Yeah.", "tokens": [51656, 865, 13, 51706], "temperature": 0.0, "avg_logprob": -0.33171230689027253, "compression_ratio": 1.725, "no_speech_prob": 0.05418647080659866}, {"id": 69, "seek": 22022, "start": 220.22, "end": 225.34, "text": " So that's great for capturing the audio, but it's not so good for modeling because we now", "tokens": [50364, 407, 300, 311, 869, 337, 23384, 264, 6278, 11, 457, 309, 311, 406, 370, 665, 337, 15983, 570, 321, 586, 50620], "temperature": 0.0, "avg_logprob": -0.2677772839864095, "compression_ratio": 1.591760299625468, "no_speech_prob": 0.1384148895740509}, {"id": 70, "seek": 22022, "start": 225.34, "end": 231.94, "text": " have 30,000 values per second in this one big 1D array.", "tokens": [50620, 362, 2217, 11, 1360, 4190, 680, 1150, 294, 341, 472, 955, 502, 35, 10225, 13, 50950], "temperature": 0.0, "avg_logprob": -0.2677772839864095, "compression_ratio": 1.591760299625468, "no_speech_prob": 0.1384148895740509}, {"id": 71, "seek": 22022, "start": 231.94, "end": 237.7, "text": " And so, yeah, you can try and find models that can work with that kind of data.", "tokens": [50950, 400, 370, 11, 1338, 11, 291, 393, 853, 293, 915, 5245, 300, 393, 589, 365, 300, 733, 295, 1412, 13, 51238], "temperature": 0.0, "avg_logprob": -0.2677772839864095, "compression_ratio": 1.591760299625468, "no_speech_prob": 0.1384148895740509}, {"id": 72, "seek": 22022, "start": 237.7, "end": 241.02, "text": " But what we're going to do is a little hack and we're instead going to use something called", "tokens": [51238, 583, 437, 321, 434, 516, 281, 360, 307, 257, 707, 10339, 293, 321, 434, 2602, 516, 281, 764, 746, 1219, 51404], "temperature": 0.0, "avg_logprob": -0.2677772839864095, "compression_ratio": 1.591760299625468, "no_speech_prob": 0.1384148895740509}, {"id": 73, "seek": 22022, "start": 241.02, "end": 242.74, "text": " a spectrogram.", "tokens": [51404, 257, 6177, 340, 1342, 13, 51490], "temperature": 0.0, "avg_logprob": -0.2677772839864095, "compression_ratio": 1.591760299625468, "no_speech_prob": 0.1384148895740509}, {"id": 74, "seek": 22022, "start": 242.74, "end": 243.74, "text": " So illustrate that.", "tokens": [51490, 407, 23221, 300, 13, 51540], "temperature": 0.0, "avg_logprob": -0.2677772839864095, "compression_ratio": 1.591760299625468, "no_speech_prob": 0.1384148895740509}, {"id": 75, "seek": 22022, "start": 243.74, "end": 245.9, "text": " The original data is the main issue.", "tokens": [51540, 440, 3380, 1412, 307, 264, 2135, 2734, 13, 51648], "temperature": 0.0, "avg_logprob": -0.2677772839864095, "compression_ratio": 1.591760299625468, "no_speech_prob": 0.1384148895740509}, {"id": 76, "seek": 22022, "start": 245.9, "end": 250.02, "text": " It's too big and slow to work with.", "tokens": [51648, 467, 311, 886, 955, 293, 2964, 281, 589, 365, 13, 51854], "temperature": 0.0, "avg_logprob": -0.2677772839864095, "compression_ratio": 1.591760299625468, "no_speech_prob": 0.1384148895740509}, {"id": 77, "seek": 25002, "start": 250.82000000000002, "end": 251.82000000000002, "text": " It's too big.", "tokens": [50404, 467, 311, 886, 955, 13, 50454], "temperature": 0.0, "avg_logprob": -0.2863218216668992, "compression_ratio": 1.76, "no_speech_prob": 0.010011064819991589}, {"id": 78, "seek": 25002, "start": 251.82000000000002, "end": 258.42, "text": " But also you have some, like some sound waves are at a hundred hertz, right?", "tokens": [50454, 583, 611, 291, 362, 512, 11, 411, 512, 1626, 9417, 366, 412, 257, 3262, 45830, 11, 558, 30, 50784], "temperature": 0.0, "avg_logprob": -0.2863218216668992, "compression_ratio": 1.76, "no_speech_prob": 0.010011064819991589}, {"id": 79, "seek": 25002, "start": 258.42, "end": 260.58, "text": " So they're going up and down a hundred times a second.", "tokens": [50784, 407, 436, 434, 516, 493, 293, 760, 257, 3262, 1413, 257, 1150, 13, 50892], "temperature": 0.0, "avg_logprob": -0.2863218216668992, "compression_ratio": 1.76, "no_speech_prob": 0.010011064819991589}, {"id": 80, "seek": 25002, "start": 260.58, "end": 263.1, "text": " And some are at a thousand and some are at 10,000.", "tokens": [50892, 400, 512, 366, 412, 257, 4714, 293, 512, 366, 412, 1266, 11, 1360, 13, 51018], "temperature": 0.0, "avg_logprob": -0.2863218216668992, "compression_ratio": 1.76, "no_speech_prob": 0.010011064819991589}, {"id": 81, "seek": 25002, "start": 263.1, "end": 267.3, "text": " And often there's background noise that can have extremely high frequency components.", "tokens": [51018, 400, 2049, 456, 311, 3678, 5658, 300, 393, 362, 4664, 1090, 7893, 6677, 13, 51228], "temperature": 0.0, "avg_logprob": -0.2863218216668992, "compression_ratio": 1.76, "no_speech_prob": 0.010011064819991589}, {"id": 82, "seek": 25002, "start": 267.3, "end": 272.62, "text": " And so if you're looking just at the waveform, there's lots and lots of change second to", "tokens": [51228, 400, 370, 498, 291, 434, 1237, 445, 412, 264, 36512, 11, 456, 311, 3195, 293, 3195, 295, 1319, 1150, 281, 51494], "temperature": 0.0, "avg_logprob": -0.2863218216668992, "compression_ratio": 1.76, "no_speech_prob": 0.010011064819991589}, {"id": 83, "seek": 25002, "start": 272.62, "end": 277.5, "text": " second and there's some very long range dependencies of like, oh, generally high here.", "tokens": [51494, 1150, 293, 456, 311, 512, 588, 938, 3613, 36606, 295, 411, 11, 1954, 11, 5101, 1090, 510, 13, 51738], "temperature": 0.0, "avg_logprob": -0.2863218216668992, "compression_ratio": 1.76, "no_speech_prob": 0.010011064819991589}, {"id": 84, "seek": 25002, "start": 277.5, "end": 279.3, "text": " It's generally low there.", "tokens": [51738, 467, 311, 5101, 2295, 456, 13, 51828], "temperature": 0.0, "avg_logprob": -0.2863218216668992, "compression_ratio": 1.76, "no_speech_prob": 0.010011064819991589}, {"id": 85, "seek": 27930, "start": 279.3, "end": 281.90000000000003, "text": " And so it can be quite hard to capture those patterns.", "tokens": [50364, 400, 370, 309, 393, 312, 1596, 1152, 281, 7983, 729, 8294, 13, 50494], "temperature": 0.0, "avg_logprob": -0.20752148474416426, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.024793926626443863}, {"id": 86, "seek": 27930, "start": 281.90000000000003, "end": 285.84000000000003, "text": " And so part of it is, it's just a lot of samples to deal with.", "tokens": [50494, 400, 370, 644, 295, 309, 307, 11, 309, 311, 445, 257, 688, 295, 10938, 281, 2028, 365, 13, 50691], "temperature": 0.0, "avg_logprob": -0.20752148474416426, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.024793926626443863}, {"id": 87, "seek": 27930, "start": 285.84000000000003, "end": 291.1, "text": " But part of it also is that it's not like an image where you can just do like convolution", "tokens": [50691, 583, 644, 295, 309, 611, 307, 300, 309, 311, 406, 411, 364, 3256, 689, 291, 393, 445, 360, 411, 45216, 50954], "temperature": 0.0, "avg_logprob": -0.20752148474416426, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.024793926626443863}, {"id": 88, "seek": 27930, "start": 291.1, "end": 295.1, "text": " and things nearby each other tend to be related or something like that.", "tokens": [50954, 293, 721, 11184, 1184, 661, 3928, 281, 312, 4077, 420, 746, 411, 300, 13, 51154], "temperature": 0.0, "avg_logprob": -0.20752148474416426, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.024793926626443863}, {"id": 89, "seek": 27930, "start": 295.1, "end": 298.90000000000003, "text": " It's quite tricky to disentangle what's going on.", "tokens": [51154, 467, 311, 1596, 12414, 281, 37313, 7846, 437, 311, 516, 322, 13, 51344], "temperature": 0.0, "avg_logprob": -0.20752148474416426, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.024793926626443863}, {"id": 90, "seek": 27930, "start": 298.90000000000003, "end": 302.90000000000003, "text": " And so we have this idea of something called a spectrogram.", "tokens": [51344, 400, 370, 321, 362, 341, 1558, 295, 746, 1219, 257, 6177, 340, 1342, 13, 51544], "temperature": 0.0, "avg_logprob": -0.20752148474416426, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.024793926626443863}, {"id": 91, "seek": 27930, "start": 302.90000000000003, "end": 308.46000000000004, "text": " This is a fancy 3D visualization, but it's basically just taking that audio and mapping", "tokens": [51544, 639, 307, 257, 10247, 805, 35, 25801, 11, 457, 309, 311, 1936, 445, 1940, 300, 6278, 293, 18350, 51822], "temperature": 0.0, "avg_logprob": -0.20752148474416426, "compression_ratio": 1.697508896797153, "no_speech_prob": 0.024793926626443863}, {"id": 92, "seek": 30846, "start": 308.46, "end": 309.46, "text": " time on one axis.", "tokens": [50364, 565, 322, 472, 10298, 13, 50414], "temperature": 0.0, "avg_logprob": -0.26694112164633615, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.3516506552696228}, {"id": 93, "seek": 30846, "start": 309.46, "end": 313.06, "text": " So you can see as time goes by, we're moving along the X axis.", "tokens": [50414, 407, 291, 393, 536, 382, 565, 1709, 538, 11, 321, 434, 2684, 2051, 264, 1783, 10298, 13, 50594], "temperature": 0.0, "avg_logprob": -0.26694112164633615, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.3516506552696228}, {"id": 94, "seek": 30846, "start": 313.06, "end": 315.5, "text": " And then on the Y axis is frequency.", "tokens": [50594, 400, 550, 322, 264, 398, 10298, 307, 7893, 13, 50716], "temperature": 0.0, "avg_logprob": -0.26694112164633615, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.3516506552696228}, {"id": 95, "seek": 30846, "start": 315.5, "end": 320.02, "text": " And so the peaks here show like intensity at different frequencies.", "tokens": [50716, 400, 370, 264, 26897, 510, 855, 411, 13749, 412, 819, 20250, 13, 50942], "temperature": 0.0, "avg_logprob": -0.26694112164633615, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.3516506552696228}, {"id": 96, "seek": 30846, "start": 320.02, "end": 327.17999999999995, "text": " And so if I make a pure note, you can see that that is being mapped in the frequency", "tokens": [50942, 400, 370, 498, 286, 652, 257, 6075, 3637, 11, 291, 393, 536, 300, 300, 307, 885, 33318, 294, 264, 7893, 51300], "temperature": 0.0, "avg_logprob": -0.26694112164633615, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.3516506552696228}, {"id": 97, "seek": 30846, "start": 327.17999999999995, "end": 328.17999999999995, "text": " domain.", "tokens": [51300, 9274, 13, 51350], "temperature": 0.0, "avg_logprob": -0.26694112164633615, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.3516506552696228}, {"id": 98, "seek": 30846, "start": 328.17999999999995, "end": 330.5, "text": " But when I'm talking, there's lots and lots of peaks.", "tokens": [51350, 583, 562, 286, 478, 1417, 11, 456, 311, 3195, 293, 3195, 295, 26897, 13, 51466], "temperature": 0.0, "avg_logprob": -0.26694112164633615, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.3516506552696228}, {"id": 99, "seek": 30846, "start": 330.5, "end": 333.94, "text": " And that's because our voices tend to produce a lot of overtones.", "tokens": [51466, 400, 300, 311, 570, 527, 9802, 3928, 281, 5258, 257, 688, 295, 670, 46272, 13, 51638], "temperature": 0.0, "avg_logprob": -0.26694112164633615, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.3516506552696228}, {"id": 100, "seek": 33394, "start": 333.94, "end": 338.98, "text": " So if I go eee, you can see there's a main note, but there's also the subsequent notes.", "tokens": [50364, 407, 498, 286, 352, 308, 1653, 11, 291, 393, 536, 456, 311, 257, 2135, 3637, 11, 457, 456, 311, 611, 264, 19962, 5570, 13, 50616], "temperature": 0.0, "avg_logprob": -0.2776964689555921, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.03358064219355583}, {"id": 101, "seek": 33394, "start": 338.98, "end": 347.58, "text": " And if I play something like a chord, you can see there's maybe three main peaks and", "tokens": [50616, 400, 498, 286, 862, 746, 411, 257, 14137, 11, 291, 393, 536, 456, 311, 1310, 1045, 2135, 26897, 293, 51046], "temperature": 0.0, "avg_logprob": -0.2776964689555921, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.03358064219355583}, {"id": 102, "seek": 33394, "start": 347.58, "end": 351.18, "text": " then each of those have these harmonics as well.", "tokens": [51046, 550, 1184, 295, 729, 362, 613, 14750, 1167, 382, 731, 13, 51226], "temperature": 0.0, "avg_logprob": -0.2776964689555921, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.03358064219355583}, {"id": 103, "seek": 33394, "start": 351.18, "end": 354.98, "text": " So it captures a lot of information about the signal.", "tokens": [51226, 407, 309, 27986, 257, 688, 295, 1589, 466, 264, 6358, 13, 51416], "temperature": 0.0, "avg_logprob": -0.2776964689555921, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.03358064219355583}, {"id": 104, "seek": 33394, "start": 354.98, "end": 359.74, "text": " And so we're going to turn our audio data into something like this, where even just", "tokens": [51416, 400, 370, 321, 434, 516, 281, 1261, 527, 6278, 1412, 666, 746, 411, 341, 11, 689, 754, 445, 51654], "temperature": 0.0, "avg_logprob": -0.2776964689555921, "compression_ratio": 1.662037037037037, "no_speech_prob": 0.03358064219355583}, {"id": 105, "seek": 35974, "start": 359.78000000000003, "end": 365.62, "text": " visually, if I'm a bird, you can see this really nice spatial pattern.", "tokens": [50366, 19622, 11, 498, 286, 478, 257, 5255, 11, 291, 393, 536, 341, 534, 1481, 23598, 5102, 13, 50658], "temperature": 0.0, "avg_logprob": -0.22328800625271267, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.081488698720932}, {"id": 106, "seek": 35974, "start": 365.62, "end": 369.18, "text": " And the hope is if we can generate that, and then if we can find some way to turn it back", "tokens": [50658, 400, 264, 1454, 307, 498, 321, 393, 8460, 300, 11, 293, 550, 498, 321, 393, 915, 512, 636, 281, 1261, 309, 646, 50836], "temperature": 0.0, "avg_logprob": -0.22328800625271267, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.081488698720932}, {"id": 107, "seek": 35974, "start": 369.18, "end": 373.74, "text": " into audio, then we'll be off to the races.", "tokens": [50836, 666, 6278, 11, 550, 321, 603, 312, 766, 281, 264, 15484, 13, 51064], "temperature": 0.0, "avg_logprob": -0.22328800625271267, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.081488698720932}, {"id": 108, "seek": 35974, "start": 373.74, "end": 375.82, "text": " And so, yeah, that's what I'm doing in this notebook.", "tokens": [51064, 400, 370, 11, 1338, 11, 300, 311, 437, 286, 478, 884, 294, 341, 21060, 13, 51168], "temperature": 0.0, "avg_logprob": -0.22328800625271267, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.081488698720932}, {"id": 109, "seek": 35974, "start": 375.82, "end": 385.28000000000003, "text": " We have, I'm leaning on the diffusers.pipelines.audiodiffusion.mel class.", "tokens": [51168, 492, 362, 11, 286, 478, 23390, 322, 264, 7593, 301, 433, 13, 79, 647, 9173, 13, 3751, 2695, 3661, 5704, 13, 10909, 1508, 13, 51641], "temperature": 0.0, "avg_logprob": -0.22328800625271267, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.081488698720932}, {"id": 110, "seek": 35974, "start": 385.28000000000003, "end": 389.7, "text": " And so within the realm of spectrograms, there's a few different ways you can do it.", "tokens": [51641, 400, 370, 1951, 264, 15355, 295, 6177, 340, 1342, 82, 11, 456, 311, 257, 1326, 819, 2098, 291, 393, 360, 309, 13, 51862], "temperature": 0.0, "avg_logprob": -0.22328800625271267, "compression_ratio": 1.6814516129032258, "no_speech_prob": 0.081488698720932}, {"id": 111, "seek": 38970, "start": 390.65999999999997, "end": 393.94, "text": " So this is from the Torch Audio Docs, but this notebook is from the Hugging Face Diffusion", "tokens": [50412, 407, 341, 307, 490, 264, 7160, 339, 25706, 16024, 82, 11, 457, 341, 21060, 307, 490, 264, 46892, 3249, 4047, 413, 3661, 5704, 50576], "temperature": 0.0, "avg_logprob": -0.25670276988636365, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0037041311152279377}, {"id": 112, "seek": 38970, "start": 393.94, "end": 395.34, "text": " Models class.", "tokens": [50576, 6583, 1625, 1508, 13, 50646], "temperature": 0.0, "avg_logprob": -0.25670276988636365, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0037041311152279377}, {"id": 113, "seek": 38970, "start": 395.34, "end": 397.86, "text": " So we had that waveform, that's those raw samples.", "tokens": [50646, 407, 321, 632, 300, 36512, 11, 300, 311, 729, 8936, 10938, 13, 50772], "temperature": 0.0, "avg_logprob": -0.25670276988636365, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0037041311152279377}, {"id": 114, "seek": 38970, "start": 397.86, "end": 403.18, "text": " And we'd like to convert that into what they call the frequency domain, which is things", "tokens": [50772, 400, 321, 1116, 411, 281, 7620, 300, 666, 437, 436, 818, 264, 7893, 9274, 11, 597, 307, 721, 51038], "temperature": 0.0, "avg_logprob": -0.25670276988636365, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0037041311152279377}, {"id": 115, "seek": 38970, "start": 403.18, "end": 405.78, "text": " like these spectrograms.", "tokens": [51038, 411, 613, 6177, 340, 1342, 82, 13, 51168], "temperature": 0.0, "avg_logprob": -0.25670276988636365, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0037041311152279377}, {"id": 116, "seek": 38970, "start": 405.78, "end": 411.76, "text": " And so you can do a normal spectrogram, a power spectrogram or something like that.", "tokens": [51168, 400, 370, 291, 393, 360, 257, 2710, 6177, 340, 1342, 11, 257, 1347, 6177, 340, 1342, 420, 746, 411, 300, 13, 51467], "temperature": 0.0, "avg_logprob": -0.25670276988636365, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0037041311152279377}, {"id": 117, "seek": 38970, "start": 411.76, "end": 416.46, "text": " But we often use something called a MEL spectrogram, which is exactly the same.", "tokens": [51467, 583, 321, 2049, 764, 746, 1219, 257, 38005, 6177, 340, 1342, 11, 597, 307, 2293, 264, 912, 13, 51702], "temperature": 0.0, "avg_logprob": -0.25670276988636365, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0037041311152279377}, {"id": 118, "seek": 38970, "start": 416.46, "end": 419.34, "text": " It's actually probably what's being visualized here.", "tokens": [51702, 467, 311, 767, 1391, 437, 311, 885, 5056, 1602, 510, 13, 51846], "temperature": 0.0, "avg_logprob": -0.25670276988636365, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.0037041311152279377}, {"id": 119, "seek": 41934, "start": 419.97999999999996, "end": 429.38, "text": " And it's something that's designed to map the frequency ranges into a range that's tied", "tokens": [50396, 400, 309, 311, 746, 300, 311, 4761, 281, 4471, 264, 7893, 22526, 666, 257, 3613, 300, 311, 9601, 50866], "temperature": 0.0, "avg_logprob": -0.24165982291811988, "compression_ratio": 1.6119402985074627, "no_speech_prob": 0.020013684406876564}, {"id": 120, "seek": 41934, "start": 429.38, "end": 432.34, "text": " to what human hearing is based on.", "tokens": [50866, 281, 437, 1952, 4763, 307, 2361, 322, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24165982291811988, "compression_ratio": 1.6119402985074627, "no_speech_prob": 0.020013684406876564}, {"id": 121, "seek": 41934, "start": 432.34, "end": 437.78, "text": " And so rather than trying to capture all frequencies from zero hertz to 40,000 hertz, a lot of", "tokens": [51014, 400, 370, 2831, 813, 1382, 281, 7983, 439, 20250, 490, 4018, 45830, 281, 3356, 11, 1360, 45830, 11, 257, 688, 295, 51286], "temperature": 0.0, "avg_logprob": -0.24165982291811988, "compression_ratio": 1.6119402985074627, "no_speech_prob": 0.020013684406876564}, {"id": 122, "seek": 41934, "start": 437.78, "end": 444.26, "text": " which we can't even hear, it focuses in on the range of values that we tend to be interested", "tokens": [51286, 597, 321, 393, 380, 754, 1568, 11, 309, 16109, 294, 322, 264, 3613, 295, 4190, 300, 321, 3928, 281, 312, 3102, 51610], "temperature": 0.0, "avg_logprob": -0.24165982291811988, "compression_ratio": 1.6119402985074627, "no_speech_prob": 0.020013684406876564}, {"id": 123, "seek": 41934, "start": 444.26, "end": 445.41999999999996, "text": " in as humans.", "tokens": [51610, 294, 382, 6255, 13, 51668], "temperature": 0.0, "avg_logprob": -0.24165982291811988, "compression_ratio": 1.6119402985074627, "no_speech_prob": 0.020013684406876564}, {"id": 124, "seek": 44542, "start": 445.5, "end": 454.42, "text": " And also it does a transformation into a log space so that the intensities like highs and", "tokens": [50368, 400, 611, 309, 775, 257, 9887, 666, 257, 3565, 1901, 370, 300, 264, 14056, 1088, 411, 29687, 293, 50814], "temperature": 0.0, "avg_logprob": -0.25641688056614087, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.008984727784991264}, {"id": 125, "seek": 44542, "start": 454.42, "end": 457.02000000000004, "text": " lows correspond to loud and quiet for human hearing.", "tokens": [50814, 34794, 6805, 281, 6588, 293, 5677, 337, 1952, 4763, 13, 50944], "temperature": 0.0, "avg_logprob": -0.25641688056614087, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.008984727784991264}, {"id": 126, "seek": 44542, "start": 457.02000000000004, "end": 463.26, "text": " So it's very tuned for the types of audio information that we actually might care about", "tokens": [50944, 407, 309, 311, 588, 10870, 337, 264, 3467, 295, 6278, 1589, 300, 321, 767, 1062, 1127, 466, 51256], "temperature": 0.0, "avg_logprob": -0.25641688056614087, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.008984727784991264}, {"id": 127, "seek": 44542, "start": 463.26, "end": 469.14, "text": " rather than tens of thousands of kilohertz that only bats can hear.", "tokens": [51256, 2831, 813, 10688, 295, 5383, 295, 21112, 35655, 300, 787, 26943, 393, 1568, 13, 51550], "temperature": 0.0, "avg_logprob": -0.25641688056614087, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.008984727784991264}, {"id": 128, "seek": 44542, "start": 469.14, "end": 472.22, "text": " So we're going to rely on a class to abstract this away, but it's going to basically give", "tokens": [51550, 407, 321, 434, 516, 281, 10687, 322, 257, 1508, 281, 12649, 341, 1314, 11, 457, 309, 311, 516, 281, 1936, 976, 51704], "temperature": 0.0, "avg_logprob": -0.25641688056614087, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.008984727784991264}, {"id": 129, "seek": 47222, "start": 472.22, "end": 476.38000000000005, "text": " us a transformation from waveform to spectrogram.", "tokens": [50364, 505, 257, 9887, 490, 36512, 281, 6177, 340, 1342, 13, 50572], "temperature": 0.0, "avg_logprob": -0.24582942186203677, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.024794721975922585}, {"id": 130, "seek": 47222, "start": 476.38000000000005, "end": 481.14000000000004, "text": " And then it's also going to help us go from spectrogram back to waveform.", "tokens": [50572, 400, 550, 309, 311, 611, 516, 281, 854, 505, 352, 490, 6177, 340, 1342, 646, 281, 36512, 13, 50810], "temperature": 0.0, "avg_logprob": -0.24582942186203677, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.024794721975922585}, {"id": 131, "seek": 47222, "start": 481.14000000000004, "end": 483.42, "text": " And so let me show you my data.", "tokens": [50810, 400, 370, 718, 385, 855, 291, 452, 1412, 13, 50924], "temperature": 0.0, "avg_logprob": -0.24582942186203677, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.024794721975922585}, {"id": 132, "seek": 47222, "start": 483.42, "end": 485.46000000000004, "text": " I have this two image function.", "tokens": [50924, 286, 362, 341, 732, 3256, 2445, 13, 51026], "temperature": 0.0, "avg_logprob": -0.24582942186203677, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.024794721975922585}, {"id": 133, "seek": 47222, "start": 485.46000000000004, "end": 487.46000000000004, "text": " It's going to take the audio array.", "tokens": [51026, 467, 311, 516, 281, 747, 264, 6278, 10225, 13, 51126], "temperature": 0.0, "avg_logprob": -0.24582942186203677, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.024794721975922585}, {"id": 134, "seek": 47222, "start": 487.46000000000004, "end": 494.38000000000005, "text": " It's going to use the MEL class to handle turning that into spectrograms.", "tokens": [51126, 467, 311, 516, 281, 764, 264, 38005, 1508, 281, 4813, 6246, 300, 666, 6177, 340, 1342, 82, 13, 51472], "temperature": 0.0, "avg_logprob": -0.24582942186203677, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.024794721975922585}, {"id": 135, "seek": 47222, "start": 494.38000000000005, "end": 498.46000000000004, "text": " And the class also does things like it splits it up into chunks based on, you can set like", "tokens": [51472, 400, 264, 1508, 611, 775, 721, 411, 309, 37741, 309, 493, 666, 24004, 2361, 322, 11, 291, 393, 992, 411, 51676], "temperature": 0.0, "avg_logprob": -0.24582942186203677, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.024794721975922585}, {"id": 136, "seek": 47222, "start": 498.46000000000004, "end": 501.02000000000004, "text": " a desired resolution.", "tokens": [51676, 257, 14721, 8669, 13, 51804], "temperature": 0.0, "avg_logprob": -0.24582942186203677, "compression_ratio": 1.7672413793103448, "no_speech_prob": 0.024794721975922585}, {"id": 137, "seek": 50102, "start": 501.06, "end": 505.02, "text": " So if I wanted like 128 by 128 spectrogram, it says, okay, great.", "tokens": [50366, 407, 498, 286, 1415, 411, 29810, 538, 29810, 6177, 340, 1342, 11, 309, 1619, 11, 1392, 11, 869, 13, 50564], "temperature": 0.0, "avg_logprob": -0.27962381797924374, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.0062871635891497135}, {"id": 138, "seek": 50102, "start": 505.02, "end": 511.65999999999997, "text": " I know how many, I know you need 128 frequency bins for the frequency axis and 128 steps", "tokens": [50564, 286, 458, 577, 867, 11, 286, 458, 291, 643, 29810, 7893, 41275, 337, 264, 7893, 10298, 293, 29810, 4439, 50896], "temperature": 0.0, "avg_logprob": -0.27962381797924374, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.0062871635891497135}, {"id": 139, "seek": 50102, "start": 511.65999999999997, "end": 513.66, "text": " on the time axis.", "tokens": [50896, 322, 264, 565, 10298, 13, 50996], "temperature": 0.0, "avg_logprob": -0.27962381797924374, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.0062871635891497135}, {"id": 140, "seek": 50102, "start": 513.66, "end": 517.98, "text": " So it kind of handles that converting and resizing.", "tokens": [50996, 407, 309, 733, 295, 18722, 300, 29942, 293, 725, 3319, 13, 51212], "temperature": 0.0, "avg_logprob": -0.27962381797924374, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.0062871635891497135}, {"id": 141, "seek": 50102, "start": 517.98, "end": 520.56, "text": " And then it gives us these audio slice to image.", "tokens": [51212, 400, 550, 309, 2709, 505, 613, 6278, 13153, 281, 3256, 13, 51341], "temperature": 0.0, "avg_logprob": -0.27962381797924374, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.0062871635891497135}, {"id": 142, "seek": 50102, "start": 520.56, "end": 524.02, "text": " So that's taking a chunk of audio and turning it into the spectrogram.", "tokens": [51341, 407, 300, 311, 1940, 257, 16635, 295, 6278, 293, 6246, 309, 666, 264, 6177, 340, 1342, 13, 51514], "temperature": 0.0, "avg_logprob": -0.27962381797924374, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.0062871635891497135}, {"id": 143, "seek": 50102, "start": 524.02, "end": 526.62, "text": " And it also has the inverse.", "tokens": [51514, 400, 309, 611, 575, 264, 17340, 13, 51644], "temperature": 0.0, "avg_logprob": -0.27962381797924374, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.0062871635891497135}, {"id": 144, "seek": 50102, "start": 526.62, "end": 529.26, "text": " So our dataset is fairly simple.", "tokens": [51644, 407, 527, 28872, 307, 6457, 2199, 13, 51776], "temperature": 0.0, "avg_logprob": -0.27962381797924374, "compression_ratio": 1.6370967741935485, "no_speech_prob": 0.0062871635891497135}, {"id": 145, "seek": 52926, "start": 529.5, "end": 534.62, "text": " We're just referencing our original audio datasets, but we're calling that two image", "tokens": [50376, 492, 434, 445, 40582, 527, 3380, 6278, 42856, 11, 457, 321, 434, 5141, 300, 732, 3256, 50632], "temperature": 0.0, "avg_logprob": -0.29574764606564546, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.051833588629961014}, {"id": 146, "seek": 52926, "start": 534.62, "end": 541.98, "text": " function and then returning it into a tensor and we're mapping it to minus 0.5 to 0.5.", "tokens": [50632, 2445, 293, 550, 12678, 309, 666, 257, 40863, 293, 321, 434, 18350, 309, 281, 3175, 1958, 13, 20, 281, 1958, 13, 20, 13, 51000], "temperature": 0.0, "avg_logprob": -0.29574764606564546, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.051833588629961014}, {"id": 147, "seek": 52926, "start": 541.98, "end": 546.3, "text": " Similarly to what we've done with like the grayscale images in the past.", "tokens": [51000, 13157, 281, 437, 321, 600, 1096, 365, 411, 264, 677, 3772, 37088, 5267, 294, 264, 1791, 13, 51216], "temperature": 0.0, "avg_logprob": -0.29574764606564546, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.051833588629961014}, {"id": 148, "seek": 52926, "start": 546.3, "end": 550.26, "text": " So if you look at a sample from that data, we now have, instead of an audio waveform", "tokens": [51216, 407, 498, 291, 574, 412, 257, 6889, 490, 300, 1412, 11, 321, 586, 362, 11, 2602, 295, 364, 6278, 36512, 51414], "temperature": 0.0, "avg_logprob": -0.29574764606564546, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.051833588629961014}, {"id": 149, "seek": 55026, "start": 550.26, "end": 559.3, "text": " of 32,000 or 64,000, if it's two seconds samples, we now have this 128 by 128 pixel", "tokens": [50364, 295, 8858, 11, 1360, 420, 12145, 11, 1360, 11, 498, 309, 311, 732, 3949, 10938, 11, 321, 586, 362, 341, 29810, 538, 29810, 19261, 50816], "temperature": 0.0, "avg_logprob": -0.31007774754574424, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.12927119433879852}, {"id": 150, "seek": 55026, "start": 559.3, "end": 562.58, "text": " spectrogram, which looks like this.", "tokens": [50816, 6177, 340, 1342, 11, 597, 1542, 411, 341, 13, 50980], "temperature": 0.0, "avg_logprob": -0.31007774754574424, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.12927119433879852}, {"id": 151, "seek": 55026, "start": 562.58, "end": 563.8199999999999, "text": " And it's just, it's grayscale.", "tokens": [50980, 400, 309, 311, 445, 11, 309, 311, 677, 3772, 37088, 13, 51042], "temperature": 0.0, "avg_logprob": -0.31007774754574424, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.12927119433879852}, {"id": 152, "seek": 55026, "start": 563.8199999999999, "end": 566.14, "text": " So this is just matplotlibs colors.", "tokens": [51042, 407, 341, 307, 445, 3803, 564, 310, 38270, 82, 4577, 13, 51158], "temperature": 0.0, "avg_logprob": -0.31007774754574424, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.12927119433879852}, {"id": 153, "seek": 55026, "start": 566.14, "end": 572.58, "text": " But we can test out going from the spectrogram back to audio using the image to audio function", "tokens": [51158, 583, 321, 393, 1500, 484, 516, 490, 264, 6177, 340, 1342, 646, 281, 6278, 1228, 264, 3256, 281, 6278, 2445, 51480], "temperature": 0.0, "avg_logprob": -0.31007774754574424, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.12927119433879852}, {"id": 154, "seek": 55026, "start": 572.58, "end": 575.38, "text": " that the MEL class has.", "tokens": [51480, 300, 264, 38005, 1508, 575, 13, 51620], "temperature": 0.0, "avg_logprob": -0.31007774754574424, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.12927119433879852}, {"id": 155, "seek": 57538, "start": 575.38, "end": 581.3, "text": " And that should give us, it sounds kind of like birdsong.", "tokens": [50364, 400, 300, 820, 976, 505, 11, 309, 3263, 733, 295, 411, 9009, 556, 13, 50660], "temperature": 0.0, "avg_logprob": -0.2709593521921258, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.03257618099451065}, {"id": 156, "seek": 57538, "start": 581.3, "end": 586.7, "text": " Now this isn't perfect because the spectrogram shows the intensity at different frequencies,", "tokens": [50660, 823, 341, 1943, 380, 2176, 570, 264, 6177, 340, 1342, 3110, 264, 13749, 412, 819, 20250, 11, 50930], "temperature": 0.0, "avg_logprob": -0.2709593521921258, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.03257618099451065}, {"id": 157, "seek": 57538, "start": 586.7, "end": 590.06, "text": " but with audio, you've also got to worry about something called the phase.", "tokens": [50930, 457, 365, 6278, 11, 291, 600, 611, 658, 281, 3292, 466, 746, 1219, 264, 5574, 13, 51098], "temperature": 0.0, "avg_logprob": -0.2709593521921258, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.03257618099451065}, {"id": 158, "seek": 57538, "start": 590.06, "end": 595.86, "text": " And so this image to audio function is actually behind the scenes doing a kind of iterative", "tokens": [51098, 400, 370, 341, 3256, 281, 6278, 2445, 307, 767, 2261, 264, 8026, 884, 257, 733, 295, 17138, 1166, 51388], "temperature": 0.0, "avg_logprob": -0.2709593521921258, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.03257618099451065}, {"id": 159, "seek": 57538, "start": 595.86, "end": 600.58, "text": " approximation with something called the Griffin-Linn algorithm.", "tokens": [51388, 28023, 365, 746, 1219, 264, 39188, 12, 43, 7729, 9284, 13, 51624], "temperature": 0.0, "avg_logprob": -0.2709593521921258, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.03257618099451065}, {"id": 160, "seek": 57538, "start": 600.58, "end": 604.74, "text": " So I'm not going to try and describe that here, but it's just, it's approximating, it's", "tokens": [51624, 407, 286, 478, 406, 516, 281, 853, 293, 6786, 300, 510, 11, 457, 309, 311, 445, 11, 309, 311, 8542, 990, 11, 309, 311, 51832], "temperature": 0.0, "avg_logprob": -0.2709593521921258, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.03257618099451065}, {"id": 161, "seek": 60474, "start": 605.1, "end": 606.66, "text": " guessing what the phase should be.", "tokens": [50382, 17939, 437, 264, 5574, 820, 312, 13, 50460], "temperature": 0.0, "avg_logprob": -0.265351482800075, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00017952691996470094}, {"id": 162, "seek": 60474, "start": 606.66, "end": 609.5, "text": " It's creating a spectrogram, it's comparing that to the original.", "tokens": [50460, 467, 311, 4084, 257, 6177, 340, 1342, 11, 309, 311, 15763, 300, 281, 264, 3380, 13, 50602], "temperature": 0.0, "avg_logprob": -0.265351482800075, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00017952691996470094}, {"id": 163, "seek": 60474, "start": 609.5, "end": 614.62, "text": " It's updating, it's doing sort of like iterative, very similar to like an optimization thing", "tokens": [50602, 467, 311, 25113, 11, 309, 311, 884, 1333, 295, 411, 17138, 1166, 11, 588, 2531, 281, 411, 364, 19618, 551, 50858], "temperature": 0.0, "avg_logprob": -0.265351482800075, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00017952691996470094}, {"id": 164, "seek": 60474, "start": 614.62, "end": 618.62, "text": " to try and generate an audio signal that would produce the spectrogram, which we're trying", "tokens": [50858, 281, 853, 293, 8460, 364, 6278, 6358, 300, 576, 5258, 264, 6177, 340, 1342, 11, 597, 321, 434, 1382, 51058], "temperature": 0.0, "avg_logprob": -0.265351482800075, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00017952691996470094}, {"id": 165, "seek": 60474, "start": 618.62, "end": 619.62, "text": " to invert.", "tokens": [51058, 281, 33966, 13, 51108], "temperature": 0.0, "avg_logprob": -0.265351482800075, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00017952691996470094}, {"id": 166, "seek": 60474, "start": 619.62, "end": 626.26, "text": " So just to clarify, so my understanding, what you're saying is that the spectrogram is a", "tokens": [51108, 407, 445, 281, 17594, 11, 370, 452, 3701, 11, 437, 291, 434, 1566, 307, 300, 264, 6177, 340, 1342, 307, 257, 51440], "temperature": 0.0, "avg_logprob": -0.265351482800075, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00017952691996470094}, {"id": 167, "seek": 60474, "start": 626.26, "end": 632.14, "text": " lossy conversion of the sound into an image.", "tokens": [51440, 4470, 88, 14298, 295, 264, 1626, 666, 364, 3256, 13, 51734], "temperature": 0.0, "avg_logprob": -0.265351482800075, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00017952691996470094}, {"id": 168, "seek": 63214, "start": 632.14, "end": 639.58, "text": " And specifically it's lossy because it tells you the kind of intensity at each point, but", "tokens": [50364, 400, 4682, 309, 311, 4470, 88, 570, 309, 5112, 291, 264, 733, 295, 13749, 412, 1184, 935, 11, 457, 50736], "temperature": 0.0, "avg_logprob": -0.2642431410532149, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.09802186489105225}, {"id": 169, "seek": 63214, "start": 639.58, "end": 643.1, "text": " it's not, it's kind of like, is it like the difference between a sine wave and a cosine", "tokens": [50736, 309, 311, 406, 11, 309, 311, 733, 295, 411, 11, 307, 309, 411, 264, 2649, 1296, 257, 18609, 5772, 293, 257, 23565, 50912], "temperature": 0.0, "avg_logprob": -0.2642431410532149, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.09802186489105225}, {"id": 170, "seek": 63214, "start": 643.1, "end": 644.1, "text": " wave?", "tokens": [50912, 5772, 30, 50962], "temperature": 0.0, "avg_logprob": -0.2642431410532149, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.09802186489105225}, {"id": 171, "seek": 63214, "start": 644.1, "end": 647.34, "text": " Like they're just shifted in different ways and we don't know how much it's shifted.", "tokens": [50962, 1743, 436, 434, 445, 18892, 294, 819, 2098, 293, 321, 500, 380, 458, 577, 709, 309, 311, 18892, 13, 51124], "temperature": 0.0, "avg_logprob": -0.2642431410532149, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.09802186489105225}, {"id": 172, "seek": 63214, "start": 647.34, "end": 653.22, "text": " So coming back to the sound, you do have to get that, that shifting, the phase correct.", "tokens": [51124, 407, 1348, 646, 281, 264, 1626, 11, 291, 360, 362, 281, 483, 300, 11, 300, 17573, 11, 264, 5574, 3006, 13, 51418], "temperature": 0.0, "avg_logprob": -0.2642431410532149, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.09802186489105225}, {"id": 173, "seek": 63214, "start": 653.22, "end": 657.02, "text": " And so it's trying to guess something and it's, sounds like it's not doing a great guess", "tokens": [51418, 400, 370, 309, 311, 1382, 281, 2041, 746, 293, 309, 311, 11, 3263, 411, 309, 311, 406, 884, 257, 869, 2041, 51608], "temperature": 0.0, "avg_logprob": -0.2642431410532149, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.09802186489105225}, {"id": 174, "seek": 63214, "start": 657.02, "end": 659.86, "text": " from the thing you showed.", "tokens": [51608, 490, 264, 551, 291, 4712, 13, 51750], "temperature": 0.0, "avg_logprob": -0.2642431410532149, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.09802186489105225}, {"id": 175, "seek": 65986, "start": 659.86, "end": 666.14, "text": " The original audio is also not that amazing, but yes, the spectrogram back to audio task,", "tokens": [50364, 440, 3380, 6278, 307, 611, 406, 300, 2243, 11, 457, 2086, 11, 264, 6177, 340, 1342, 646, 281, 6278, 5633, 11, 50678], "temperature": 0.0, "avg_logprob": -0.29623258681524367, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.002322521759197116}, {"id": 176, "seek": 65986, "start": 666.14, "end": 669.86, "text": " these dotted lines are like highlighting, this is, yeah, it's an approximation.", "tokens": [50678, 613, 37459, 3876, 366, 411, 26551, 11, 341, 307, 11, 1338, 11, 309, 311, 364, 28023, 13, 50864], "temperature": 0.0, "avg_logprob": -0.29623258681524367, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.002322521759197116}, {"id": 177, "seek": 65986, "start": 669.86, "end": 674.98, "text": " And there are deep learning methods now that can do that better, or at least that sound", "tokens": [50864, 400, 456, 366, 2452, 2539, 7150, 586, 300, 393, 360, 300, 1101, 11, 420, 412, 1935, 300, 1626, 51120], "temperature": 0.0, "avg_logprob": -0.29623258681524367, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.002322521759197116}, {"id": 178, "seek": 65986, "start": 674.98, "end": 680.66, "text": " much higher quality, because you can train a model somehow to go from this image-like", "tokens": [51120, 709, 2946, 3125, 11, 570, 291, 393, 3847, 257, 2316, 6063, 281, 352, 490, 341, 3256, 12, 4092, 51404], "temperature": 0.0, "avg_logprob": -0.29623258681524367, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.002322521759197116}, {"id": 179, "seek": 65986, "start": 680.66, "end": 684.1800000000001, "text": " representation back to an audio signal.", "tokens": [51404, 10290, 646, 281, 364, 6278, 6358, 13, 51580], "temperature": 0.0, "avg_logprob": -0.29623258681524367, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.002322521759197116}, {"id": 180, "seek": 65986, "start": 684.1800000000001, "end": 687.26, "text": " But we just use the approximation for this notebook.", "tokens": [51580, 583, 321, 445, 764, 264, 28023, 337, 341, 21060, 13, 51734], "temperature": 0.0, "avg_logprob": -0.29623258681524367, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.002322521759197116}, {"id": 181, "seek": 68726, "start": 687.66, "end": 688.66, "text": " Okay.", "tokens": [50384, 1033, 13, 50434], "temperature": 0.0, "avg_logprob": -0.27899286302469545, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0008039071108214557}, {"id": 182, "seek": 68726, "start": 688.66, "end": 695.1, "text": " So now that we can represent our data as like a grayscale 128 by 128 pixel image, everything", "tokens": [50434, 407, 586, 300, 321, 393, 2906, 527, 1412, 382, 411, 257, 677, 3772, 37088, 29810, 538, 29810, 19261, 3256, 11, 1203, 50756], "temperature": 0.0, "avg_logprob": -0.27899286302469545, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0008039071108214557}, {"id": 183, "seek": 68726, "start": 695.1, "end": 698.8199999999999, "text": " else becomes very much the same as the previous diffusion models examples.", "tokens": [50756, 1646, 3643, 588, 709, 264, 912, 382, 264, 3894, 25242, 5245, 5110, 13, 50942], "temperature": 0.0, "avg_logprob": -0.27899286302469545, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0008039071108214557}, {"id": 184, "seek": 68726, "start": 698.8199999999999, "end": 703.54, "text": " We're going to use this noiseify function to add different amounts of noise.", "tokens": [50942, 492, 434, 516, 281, 764, 341, 5658, 2505, 2445, 281, 909, 819, 11663, 295, 5658, 13, 51178], "temperature": 0.0, "avg_logprob": -0.27899286302469545, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0008039071108214557}, {"id": 185, "seek": 68726, "start": 703.54, "end": 708.9399999999999, "text": " And so we can see now we have our spectrograms, but with varying amounts of noise added, we", "tokens": [51178, 400, 370, 321, 393, 536, 586, 321, 362, 527, 6177, 340, 1342, 82, 11, 457, 365, 22984, 11663, 295, 5658, 3869, 11, 321, 51448], "temperature": 0.0, "avg_logprob": -0.27899286302469545, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0008039071108214557}, {"id": 186, "seek": 68726, "start": 708.9399999999999, "end": 710.98, "text": " can create a simple diffusion model.", "tokens": [51448, 393, 1884, 257, 2199, 25242, 2316, 13, 51550], "temperature": 0.0, "avg_logprob": -0.27899286302469545, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0008039071108214557}, {"id": 187, "seek": 68726, "start": 710.98, "end": 716.34, "text": " I'm just copying and pasting the results, but with one extra layer, just with very few", "tokens": [51550, 286, 478, 445, 27976, 293, 1791, 278, 264, 3542, 11, 457, 365, 472, 2857, 4583, 11, 445, 365, 588, 1326, 51818], "temperature": 0.0, "avg_logprob": -0.27899286302469545, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0008039071108214557}, {"id": 188, "seek": 71634, "start": 716.4200000000001, "end": 723.94, "text": " channels to go from 128 to 64, to 36, I mean, to 16 by 8, to 8.", "tokens": [50368, 9235, 281, 352, 490, 29810, 281, 12145, 11, 281, 220, 11309, 11, 286, 914, 11, 281, 3165, 538, 1649, 11, 281, 1649, 13, 50744], "temperature": 0.0, "avg_logprob": -0.4442076451570085, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.10637246072292328}, {"id": 189, "seek": 71634, "start": 723.94, "end": 731.02, "text": " No attention, just, I think pretty much copied and pasted from notebook 30 and train it for", "tokens": [50744, 883, 3202, 11, 445, 11, 286, 519, 1238, 709, 25365, 293, 1791, 292, 490, 21060, 2217, 293, 3847, 309, 337, 51098], "temperature": 0.0, "avg_logprob": -0.4442076451570085, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.10637246072292328}, {"id": 190, "seek": 71634, "start": 731.02, "end": 733.22, "text": " in this case, 15 epochs, it took about.", "tokens": [51098, 294, 341, 1389, 11, 2119, 30992, 28346, 11, 309, 1890, 466, 13, 51208], "temperature": 0.0, "avg_logprob": -0.4442076451570085, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.10637246072292328}, {"id": 191, "seek": 71634, "start": 733.22, "end": 734.46, "text": " Oh, this is interesting.", "tokens": [51208, 876, 11, 341, 307, 1880, 13, 51270], "temperature": 0.0, "avg_logprob": -0.4442076451570085, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.10637246072292328}, {"id": 192, "seek": 71634, "start": 734.46, "end": 737.94, "text": " You're using simple diffusion.", "tokens": [51270, 509, 434, 1228, 2199, 25242, 13, 51444], "temperature": 0.0, "avg_logprob": -0.4442076451570085, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.10637246072292328}, {"id": 193, "seek": 71634, "start": 737.94, "end": 740.3000000000001, "text": " Yes.", "tokens": [51444, 1079, 13, 51562], "temperature": 0.0, "avg_logprob": -0.4442076451570085, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.10637246072292328}, {"id": 194, "seek": 71634, "start": 740.3000000000001, "end": 745.3000000000001, "text": " So specifically this is the simple diffusion model that you, I think I've already introduced,", "tokens": [51562, 407, 4682, 341, 307, 264, 2199, 25242, 2316, 300, 291, 11, 286, 519, 286, 600, 1217, 7268, 11, 51812], "temperature": 0.0, "avg_logprob": -0.4442076451570085, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.10637246072292328}, {"id": 195, "seek": 74530, "start": 745.3, "end": 746.3, "text": " maybe not.", "tokens": [50364, 1310, 406, 13, 50414], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 196, "seek": 74530, "start": 746.3, "end": 747.3, "text": " Yeah.", "tokens": [50414, 865, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 197, "seek": 74530, "start": 747.3, "end": 748.3, "text": " So it has some number of...", "tokens": [50464, 407, 309, 575, 512, 1230, 295, 485, 50514], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 198, "seek": 74530, "start": 748.3, "end": 750.6999999999999, "text": " I think we briefly looked at it, so let's remind ourselves of what it does.", "tokens": [50514, 286, 519, 321, 10515, 2956, 412, 309, 11, 370, 718, 311, 4160, 4175, 295, 437, 309, 775, 13, 50634], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 199, "seek": 74530, "start": 750.6999999999999, "end": 751.6999999999999, "text": " Yeah.", "tokens": [50634, 865, 13, 50684], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 200, "seek": 74530, "start": 751.6999999999999, "end": 752.6999999999999, "text": " Oh, okay.", "tokens": [50684, 876, 11, 1392, 13, 50734], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 201, "seek": 74530, "start": 752.6999999999999, "end": 753.6999999999999, "text": " Yeah.", "tokens": [50734, 865, 13, 50784], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 202, "seek": 74530, "start": 753.6999999999999, "end": 757.74, "text": " So we have some number of down blocks with a specified number of channels.", "tokens": [50784, 407, 321, 362, 512, 1230, 295, 760, 8474, 365, 257, 22206, 1230, 295, 9235, 13, 50986], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 203, "seek": 74530, "start": 757.74, "end": 761.5, "text": " And then the key insight from simple diffusion was that you often want to concentrate the", "tokens": [50986, 400, 550, 264, 2141, 11269, 490, 2199, 25242, 390, 300, 291, 2049, 528, 281, 18089, 264, 51174], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 204, "seek": 74530, "start": 761.5, "end": 765.06, "text": " compute in the sort of middle at the low resolution.", "tokens": [51174, 14722, 294, 264, 1333, 295, 2808, 412, 264, 2295, 8669, 13, 51352], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 205, "seek": 74530, "start": 765.06, "end": 766.8599999999999, "text": " So that's these mid blocks.", "tokens": [51352, 407, 300, 311, 613, 2062, 8474, 13, 51442], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 206, "seek": 74530, "start": 766.8599999999999, "end": 769.14, "text": " And they're transformers.", "tokens": [51442, 400, 436, 434, 4088, 433, 13, 51556], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 207, "seek": 74530, "start": 769.14, "end": 771.06, "text": " Yes.", "tokens": [51556, 1079, 13, 51652], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 208, "seek": 74530, "start": 771.06, "end": 772.0999999999999, "text": " Yeah.", "tokens": [51652, 865, 13, 51704], "temperature": 0.0, "avg_logprob": -0.3250723110409234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0015007995534688234}, {"id": 209, "seek": 77210, "start": 772.1, "end": 777.66, "text": " And so we can stack some number of those and then the corresponding up path.", "tokens": [50364, 400, 370, 321, 393, 8630, 512, 1230, 295, 729, 293, 550, 264, 11760, 493, 3100, 13, 50642], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 210, "seek": 77210, "start": 777.66, "end": 778.66, "text": " And this is a unit.", "tokens": [50642, 400, 341, 307, 257, 4985, 13, 50692], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 211, "seek": 77210, "start": 778.66, "end": 784.7, "text": " So we passing in the features from the down path as we go through those up blocks.", "tokens": [50692, 407, 321, 8437, 294, 264, 4122, 490, 264, 760, 3100, 382, 321, 352, 807, 729, 493, 8474, 13, 50994], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 212, "seek": 77210, "start": 784.7, "end": 789.0600000000001, "text": " And so we're going to go take an image and time step.", "tokens": [50994, 400, 370, 321, 434, 516, 281, 352, 747, 364, 3256, 293, 565, 1823, 13, 51212], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 213, "seek": 77210, "start": 789.0600000000001, "end": 790.94, "text": " We can embed the time step.", "tokens": [51212, 492, 393, 12240, 264, 565, 1823, 13, 51306], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 214, "seek": 77210, "start": 790.94, "end": 795.78, "text": " We're going to go through our down blocks and saving the results.", "tokens": [51306, 492, 434, 516, 281, 352, 807, 527, 760, 8474, 293, 6816, 264, 3542, 13, 51548], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 215, "seek": 77210, "start": 795.78, "end": 798.74, "text": " We're going to go through the mid blocks.", "tokens": [51548, 492, 434, 516, 281, 352, 807, 264, 2062, 8474, 13, 51696], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 216, "seek": 77210, "start": 798.74, "end": 799.74, "text": " There we go.", "tokens": [51696, 821, 321, 352, 13, 51746], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 217, "seek": 77210, "start": 799.74, "end": 800.74, "text": " Through the mid blocks.", "tokens": [51746, 8927, 264, 2062, 8474, 13, 51796], "temperature": 0.0, "avg_logprob": -0.35445698520593477, "compression_ratio": 1.9804878048780488, "no_speech_prob": 0.19640012085437775}, {"id": 218, "seek": 80074, "start": 800.9, "end": 801.9, "text": " Yeah.", "tokens": [50372, 865, 13, 50422], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 219, "seek": 80074, "start": 801.9, "end": 810.34, "text": " And before that, you've also got the embedding of the locations that self.le is the learnable", "tokens": [50422, 400, 949, 300, 11, 291, 600, 611, 658, 264, 12240, 3584, 295, 264, 9253, 300, 2698, 13, 306, 307, 264, 1466, 712, 50844], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 220, "seek": 80074, "start": 810.34, "end": 813.46, "text": " embeddings using scale and shift, I remember.", "tokens": [50844, 12240, 29432, 1228, 4373, 293, 5513, 11, 286, 1604, 13, 51000], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 221, "seek": 80074, "start": 813.46, "end": 814.46, "text": " Right.", "tokens": [51000, 1779, 13, 51050], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 222, "seek": 80074, "start": 814.46, "end": 818.26, "text": " So this is preparing it to go through the transformer blocks by adding some learnable", "tokens": [51050, 407, 341, 307, 10075, 309, 281, 352, 807, 264, 31782, 8474, 538, 5127, 512, 1466, 712, 51240], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 223, "seek": 80074, "start": 818.26, "end": 819.26, "text": " embeddings.", "tokens": [51240, 12240, 29432, 13, 51290], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 224, "seek": 80074, "start": 819.26, "end": 820.26, "text": " Cool.", "tokens": [51290, 8561, 13, 51340], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 225, "seek": 80074, "start": 820.26, "end": 821.26, "text": " All right.", "tokens": [51340, 1057, 558, 13, 51390], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 226, "seek": 80074, "start": 821.26, "end": 828.94, "text": " And then we're reshaping it to be effectively a sequence, since that's how we had written", "tokens": [51390, 400, 550, 321, 434, 725, 71, 569, 278, 309, 281, 312, 8659, 257, 8310, 11, 1670, 300, 311, 577, 321, 632, 3720, 51774], "temperature": 0.0, "avg_logprob": -0.29680442810058594, "compression_ratio": 1.6227272727272728, "no_speech_prob": 0.0028447837103158236}, {"id": 227, "seek": 82894, "start": 828.94, "end": 833.86, "text": " our transformer to expect a 1D sequence of embeddings.", "tokens": [50364, 527, 31782, 281, 2066, 257, 502, 35, 8310, 295, 12240, 29432, 13, 50610], "temperature": 0.0, "avg_logprob": -0.30273245046804614, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.00985776912420988}, {"id": 228, "seek": 82894, "start": 833.86, "end": 837.1800000000001, "text": " And so once you've gone through those mid blocks, we reshape it back and then we go", "tokens": [50610, 400, 370, 1564, 291, 600, 2780, 807, 729, 2062, 8474, 11, 321, 725, 42406, 309, 646, 293, 550, 321, 352, 50776], "temperature": 0.0, "avg_logprob": -0.30273245046804614, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.00985776912420988}, {"id": 229, "seek": 82894, "start": 837.1800000000001, "end": 842.94, "text": " through the up blocks passing in and also our saved outputs from the down path.", "tokens": [50776, 807, 264, 493, 8474, 8437, 294, 293, 611, 527, 6624, 23930, 490, 264, 760, 3100, 13, 51064], "temperature": 0.0, "avg_logprob": -0.30273245046804614, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.00985776912420988}, {"id": 230, "seek": 82894, "start": 842.94, "end": 843.94, "text": " Yeah.", "tokens": [51064, 865, 13, 51114], "temperature": 0.0, "avg_logprob": -0.30273245046804614, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.00985776912420988}, {"id": 231, "seek": 82894, "start": 843.94, "end": 846.34, "text": " So it's a nice, it's the nice model.", "tokens": [51114, 407, 309, 311, 257, 1481, 11, 309, 311, 264, 1481, 2316, 13, 51234], "temperature": 0.0, "avg_logprob": -0.30273245046804614, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.00985776912420988}, {"id": 232, "seek": 82894, "start": 846.34, "end": 851.6600000000001, "text": " You can really control how much parameters and compute you're doing just by setting like", "tokens": [51234, 509, 393, 534, 1969, 577, 709, 9834, 293, 14722, 291, 434, 884, 445, 538, 3287, 411, 51500], "temperature": 0.0, "avg_logprob": -0.30273245046804614, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.00985776912420988}, {"id": 233, "seek": 82894, "start": 851.6600000000001, "end": 856.74, "text": " what are the number of features or channels at each of those down block stages and how", "tokens": [51500, 437, 366, 264, 1230, 295, 4122, 420, 9235, 412, 1184, 295, 729, 760, 3461, 10232, 293, 577, 51754], "temperature": 0.0, "avg_logprob": -0.30273245046804614, "compression_ratio": 1.6185185185185185, "no_speech_prob": 0.00985776912420988}, {"id": 234, "seek": 85674, "start": 856.74, "end": 859.82, "text": " many mid blocks are you going to stack.", "tokens": [50364, 867, 2062, 8474, 366, 291, 516, 281, 8630, 13, 50518], "temperature": 0.0, "avg_logprob": -0.29703406682090155, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.13472433388233185}, {"id": 235, "seek": 85674, "start": 859.82, "end": 863.38, "text": " And so if you want to scale it up, it's quite easy to say, let me just add more mid blocks,", "tokens": [50518, 400, 370, 498, 291, 528, 281, 4373, 309, 493, 11, 309, 311, 1596, 1858, 281, 584, 11, 718, 385, 445, 909, 544, 2062, 8474, 11, 50696], "temperature": 0.0, "avg_logprob": -0.29703406682090155, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.13472433388233185}, {"id": 236, "seek": 85674, "start": 863.38, "end": 868.3, "text": " maybe I'll add more channels to the down and up paths.", "tokens": [50696, 1310, 286, 603, 909, 544, 9235, 281, 264, 760, 293, 493, 14518, 13, 50942], "temperature": 0.0, "avg_logprob": -0.29703406682090155, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.13472433388233185}, {"id": 237, "seek": 85674, "start": 868.3, "end": 872.34, "text": " And there's a very easy model to tweak to get a larger or smaller model.", "tokens": [50942, 400, 456, 311, 257, 588, 1858, 2316, 281, 29879, 281, 483, 257, 4833, 420, 4356, 2316, 13, 51144], "temperature": 0.0, "avg_logprob": -0.29703406682090155, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.13472433388233185}, {"id": 238, "seek": 85674, "start": 872.34, "end": 877.94, "text": " One fun thought I know is simple diffusion only came out a couple of months ago.", "tokens": [51144, 1485, 1019, 1194, 286, 458, 307, 2199, 25242, 787, 1361, 484, 257, 1916, 295, 2493, 2057, 13, 51424], "temperature": 0.0, "avg_logprob": -0.29703406682090155, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.13472433388233185}, {"id": 239, "seek": 85674, "start": 877.94, "end": 883.86, "text": " And I don't think, I think ours might be the first publicly available code for it.", "tokens": [51424, 400, 286, 500, 380, 519, 11, 286, 519, 11896, 1062, 312, 264, 700, 14843, 2435, 3089, 337, 309, 13, 51720], "temperature": 0.0, "avg_logprob": -0.29703406682090155, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.13472433388233185}, {"id": 240, "seek": 85674, "start": 883.86, "end": 885.86, "text": " I don't think the authors released the code.", "tokens": [51720, 286, 500, 380, 519, 264, 16552, 4736, 264, 3089, 13, 51820], "temperature": 0.0, "avg_logprob": -0.29703406682090155, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.13472433388233185}, {"id": 241, "seek": 88586, "start": 885.98, "end": 889.66, "text": " I suspect this is probably the first time maybe it's ever been used to generate audio", "tokens": [50370, 286, 9091, 341, 307, 1391, 264, 700, 565, 1310, 309, 311, 1562, 668, 1143, 281, 8460, 6278, 50554], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 242, "seek": 88586, "start": 889.66, "end": 890.66, "text": " before.", "tokens": [50554, 949, 13, 50604], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 243, "seek": 88586, "start": 890.66, "end": 891.66, "text": " Possibly.", "tokens": [50604, 33112, 3545, 13, 50654], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 244, "seek": 88586, "start": 891.66, "end": 892.66, "text": " Yeah, I guess.", "tokens": [50654, 865, 11, 286, 2041, 13, 50704], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 245, "seek": 88586, "start": 892.66, "end": 897.66, "text": " I know a couple of people who've at least privately done their implementations.", "tokens": [50704, 286, 458, 257, 1916, 295, 561, 567, 600, 412, 1935, 31919, 1096, 641, 4445, 763, 13, 50954], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 246, "seek": 88586, "start": 897.66, "end": 901.0600000000001, "text": " When I asked the author if he was releasing code, he said, oh, but it's simple.", "tokens": [50954, 1133, 286, 2351, 264, 3793, 498, 415, 390, 16327, 3089, 11, 415, 848, 11, 1954, 11, 457, 309, 311, 2199, 13, 51124], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 247, "seek": 88586, "start": 901.0600000000001, "end": 904.1800000000001, "text": " It's just a bunch of transformer blocks.", "tokens": [51124, 467, 311, 445, 257, 3840, 295, 31782, 8474, 13, 51280], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 248, "seek": 88586, "start": 904.1800000000001, "end": 905.1800000000001, "text": " I'll release it eventually.", "tokens": [51280, 286, 603, 4374, 309, 4728, 13, 51330], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 249, "seek": 88586, "start": 905.1800000000001, "end": 906.1800000000001, "text": " No, maybe, maybe not.", "tokens": [51330, 883, 11, 1310, 11, 1310, 406, 13, 51380], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 250, "seek": 88586, "start": 906.1800000000001, "end": 911.1800000000001, "text": " I'm not, I don't want to malign them, but they were like, oh, you can see the pseudocode.", "tokens": [51380, 286, 478, 406, 11, 286, 500, 380, 528, 281, 2806, 788, 552, 11, 457, 436, 645, 411, 11, 1954, 11, 291, 393, 536, 264, 25505, 532, 905, 1429, 13, 51630], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 251, "seek": 88586, "start": 911.1800000000001, "end": 912.1800000000001, "text": " It's pretty easy.", "tokens": [51630, 467, 311, 1238, 1858, 13, 51680], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 252, "seek": 88586, "start": 912.1800000000001, "end": 913.1800000000001, "text": " Yeah, it is pretty easy.", "tokens": [51680, 865, 11, 309, 307, 1238, 1858, 13, 51730], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 253, "seek": 88586, "start": 913.1800000000001, "end": 914.1800000000001, "text": " Yeah.", "tokens": [51730, 865, 13, 51780], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 254, "seek": 88586, "start": 914.1800000000001, "end": 915.1800000000001, "text": " Cool.", "tokens": [51780, 8561, 13, 51830], "temperature": 0.0, "avg_logprob": -0.26877463678395525, "compression_ratio": 1.6852459016393442, "no_speech_prob": 0.015420151874423027}, {"id": 255, "seek": 91518, "start": 915.5, "end": 919.7399999999999, "text": " So the trains, the last goes down as we hope.", "tokens": [50380, 407, 264, 16329, 11, 264, 1036, 1709, 760, 382, 321, 1454, 13, 50592], "temperature": 0.0, "avg_logprob": -0.29247413491303065, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.028413357213139534}, {"id": 256, "seek": 91518, "start": 919.7399999999999, "end": 923.6999999999999, "text": " Sampling is exactly the same as generating images normally.", "tokens": [50592, 4832, 11970, 307, 2293, 264, 912, 382, 17746, 5267, 5646, 13, 50790], "temperature": 0.0, "avg_logprob": -0.29247413491303065, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.028413357213139534}, {"id": 257, "seek": 91518, "start": 923.6999999999999, "end": 925.9, "text": " And that's going to give us the spectrograms.", "tokens": [50790, 400, 300, 311, 516, 281, 976, 505, 264, 6177, 340, 1342, 82, 13, 50900], "temperature": 0.0, "avg_logprob": -0.29247413491303065, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.028413357213139534}, {"id": 258, "seek": 91518, "start": 925.9, "end": 930.3, "text": " So I'm using DDAM sampling with a hundred steps.", "tokens": [50900, 407, 286, 478, 1228, 30778, 2865, 21179, 365, 257, 3262, 4439, 13, 51120], "temperature": 0.0, "avg_logprob": -0.29247413491303065, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.028413357213139534}, {"id": 259, "seek": 91518, "start": 930.3, "end": 934.54, "text": " And to actually listen to these samples, we then are just going to use that image to audio", "tokens": [51120, 400, 281, 767, 2140, 281, 613, 10938, 11, 321, 550, 366, 445, 516, 281, 764, 300, 3256, 281, 6278, 51332], "temperature": 0.0, "avg_logprob": -0.29247413491303065, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.028413357213139534}, {"id": 260, "seek": 91518, "start": 934.54, "end": 939.4599999999999, "text": " function again to take our grayscale image.", "tokens": [51332, 2445, 797, 281, 747, 527, 677, 3772, 37088, 3256, 13, 51578], "temperature": 0.0, "avg_logprob": -0.29247413491303065, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.028413357213139534}, {"id": 261, "seek": 91518, "start": 939.4599999999999, "end": 941.5, "text": " And in this case, actually it expects a PIL image.", "tokens": [51578, 400, 294, 341, 1389, 11, 767, 309, 33280, 257, 430, 4620, 3256, 13, 51680], "temperature": 0.0, "avg_logprob": -0.29247413491303065, "compression_ratio": 1.628691983122363, "no_speech_prob": 0.028413357213139534}, {"id": 262, "seek": 94150, "start": 941.5, "end": 947.26, "text": " So I first converted it to PIL and then turn that back into audio.", "tokens": [50364, 407, 286, 700, 16424, 309, 281, 430, 4620, 293, 550, 1261, 300, 646, 666, 6278, 13, 50652], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 263, "seek": 94150, "start": 947.26, "end": 950.5, "text": " And so we can play some of the generated samples.", "tokens": [50652, 400, 370, 321, 393, 862, 512, 295, 264, 10833, 10938, 13, 50814], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 264, "seek": 94150, "start": 950.5, "end": 951.5, "text": " Wow.", "tokens": [50814, 3153, 13, 50864], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 265, "seek": 94150, "start": 951.5, "end": 953.5, "text": " That's so cool.", "tokens": [50864, 663, 311, 370, 1627, 13, 50964], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 266, "seek": 94150, "start": 953.5, "end": 962.54, "text": " I don't know that I could guarantee what bird is making these calls and some of them are", "tokens": [50964, 286, 500, 380, 458, 300, 286, 727, 10815, 437, 5255, 307, 1455, 613, 5498, 293, 512, 295, 552, 366, 51416], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 267, "seek": 94150, "start": 962.54, "end": 963.54, "text": " better than others.", "tokens": [51416, 1101, 813, 2357, 13, 51466], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 268, "seek": 94150, "start": 963.54, "end": 964.54, "text": " Like some of them have better calls.", "tokens": [51466, 1743, 512, 295, 552, 362, 1101, 5498, 13, 51516], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 269, "seek": 94150, "start": 964.54, "end": 969.78, "text": " Some of the original samples sound like that.", "tokens": [51516, 2188, 295, 264, 3380, 10938, 1626, 411, 300, 13, 51778], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 270, "seek": 94150, "start": 969.78, "end": 970.78, "text": " So.", "tokens": [51778, 407, 13, 51828], "temperature": 0.0, "avg_logprob": -0.46435002485911053, "compression_ratio": 1.6009615384615385, "no_speech_prob": 0.19675418734550476}, {"id": 271, "seek": 97078, "start": 971.06, "end": 972.06, "text": " Exactly.", "tokens": [50378, 7587, 13, 50428], "temperature": 0.0, "avg_logprob": -0.3405655985293181, "compression_ratio": 1.5857142857142856, "no_speech_prob": 0.0011875595664605498}, {"id": 272, "seek": 97078, "start": 972.06, "end": 973.06, "text": " Yeah.", "tokens": [50428, 865, 13, 50478], "temperature": 0.0, "avg_logprob": -0.3405655985293181, "compression_ratio": 1.5857142857142856, "no_speech_prob": 0.0011875595664605498}, {"id": 273, "seek": 97078, "start": 973.06, "end": 978.14, "text": " So yeah, that's generating bird calls with spectrogram diffusion.", "tokens": [50478, 407, 1338, 11, 300, 311, 17746, 5255, 5498, 365, 6177, 340, 1342, 25242, 13, 50732], "temperature": 0.0, "avg_logprob": -0.3405655985293181, "compression_ratio": 1.5857142857142856, "no_speech_prob": 0.0011875595664605498}, {"id": 274, "seek": 97078, "start": 978.14, "end": 980.22, "text": " There's projects that do this on music.", "tokens": [50732, 821, 311, 4455, 300, 360, 341, 322, 1318, 13, 50836], "temperature": 0.0, "avg_logprob": -0.3405655985293181, "compression_ratio": 1.5857142857142856, "no_speech_prob": 0.0011875595664605498}, {"id": 275, "seek": 97078, "start": 980.22, "end": 987.38, "text": " So the Refusion project generates a picture based on text.", "tokens": [50836, 407, 264, 16957, 5704, 1716, 23815, 257, 3036, 2361, 322, 2487, 13, 51194], "temperature": 0.0, "avg_logprob": -0.3405655985293181, "compression_ratio": 1.5857142857142856, "no_speech_prob": 0.0011875595664605498}, {"id": 276, "seek": 97078, "start": 987.38, "end": 992.54, "text": " And yeah, there's various other like pre-trained models that do diffusion on spectrograms to", "tokens": [51194, 400, 1338, 11, 456, 311, 3683, 661, 411, 659, 12, 17227, 2001, 5245, 300, 360, 25242, 322, 6177, 340, 1342, 82, 281, 51452], "temperature": 0.0, "avg_logprob": -0.3405655985293181, "compression_ratio": 1.5857142857142856, "no_speech_prob": 0.0011875595664605498}, {"id": 277, "seek": 97078, "start": 992.54, "end": 999.18, "text": " produce music clips or voice or whatever.", "tokens": [51452, 5258, 1318, 13117, 420, 3177, 420, 2035, 13, 51784], "temperature": 0.0, "avg_logprob": -0.3405655985293181, "compression_ratio": 1.5857142857142856, "no_speech_prob": 0.0011875595664605498}, {"id": 278, "seek": 97078, "start": 999.18, "end": 1000.18, "text": " I may have frozen.", "tokens": [51784, 286, 815, 362, 12496, 13, 51834], "temperature": 0.0, "avg_logprob": -0.3405655985293181, "compression_ratio": 1.5857142857142856, "no_speech_prob": 0.0011875595664605498}, {"id": 279, "seek": 100018, "start": 1000.5799999999999, "end": 1006.4599999999999, "text": " Refusion is actually this stable diffusion model that's fine tuned specifically for the", "tokens": [50384, 16957, 5704, 307, 767, 341, 8351, 25242, 2316, 300, 311, 2489, 10870, 4682, 337, 264, 50678], "temperature": 0.0, "avg_logprob": -0.27520916678688745, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.040815696120262146}, {"id": 280, "seek": 100018, "start": 1006.4599999999999, "end": 1009.9799999999999, "text": " spectrogram generation, which I find very impressive.", "tokens": [50678, 6177, 340, 1342, 5125, 11, 597, 286, 915, 588, 8992, 13, 50854], "temperature": 0.0, "avg_logprob": -0.27520916678688745, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.040815696120262146}, {"id": 281, "seek": 100018, "start": 1009.9799999999999, "end": 1014.7399999999999, "text": " It's like a model that was originally for text to image is instead can also generate", "tokens": [50854, 467, 311, 411, 257, 2316, 300, 390, 7993, 337, 2487, 281, 3256, 307, 2602, 393, 611, 8460, 51092], "temperature": 0.0, "avg_logprob": -0.27520916678688745, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.040815696120262146}, {"id": 282, "seek": 100018, "start": 1014.7399999999999, "end": 1015.7399999999999, "text": " these spectrograms.", "tokens": [51092, 613, 6177, 340, 1342, 82, 13, 51142], "temperature": 0.0, "avg_logprob": -0.27520916678688745, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.040815696120262146}, {"id": 283, "seek": 100018, "start": 1015.7399999999999, "end": 1021.02, "text": " I guess there's still some useful information in this sort of text to image model that kind", "tokens": [51142, 286, 2041, 456, 311, 920, 512, 4420, 1589, 294, 341, 1333, 295, 2487, 281, 3256, 2316, 300, 733, 51406], "temperature": 0.0, "avg_logprob": -0.27520916678688745, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.040815696120262146}, {"id": 284, "seek": 100018, "start": 1021.02, "end": 1024.58, "text": " of generalizes or you can still be used for text to audio.", "tokens": [51406, 295, 2674, 5660, 420, 291, 393, 920, 312, 1143, 337, 2487, 281, 6278, 13, 51584], "temperature": 0.0, "avg_logprob": -0.27520916678688745, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.040815696120262146}, {"id": 285, "seek": 100018, "start": 1024.58, "end": 1028.1799999999998, "text": " So I found that a very interesting, impressive application as well.", "tokens": [51584, 407, 286, 1352, 300, 257, 588, 1880, 11, 8992, 3861, 382, 731, 13, 51764], "temperature": 0.0, "avg_logprob": -0.27520916678688745, "compression_ratio": 1.8379446640316206, "no_speech_prob": 0.040815696120262146}, {"id": 286, "seek": 102818, "start": 1028.18, "end": 1030.18, "text": " So Refusion is an awesome name.", "tokens": [50364, 407, 16957, 5704, 307, 364, 3476, 1315, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3624051116233648, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.05497751757502556}, {"id": 287, "seek": 102818, "start": 1030.18, "end": 1032.18, "text": " Indeed it is.", "tokens": [50464, 15061, 309, 307, 13, 50564], "temperature": 0.0, "avg_logprob": -0.3624051116233648, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.05497751757502556}, {"id": 288, "seek": 102818, "start": 1032.18, "end": 1033.18, "text": " Yeah.", "tokens": [50564, 865, 13, 50614], "temperature": 0.0, "avg_logprob": -0.3624051116233648, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.05497751757502556}, {"id": 289, "seek": 102818, "start": 1033.18, "end": 1034.18, "text": " Cool.", "tokens": [50614, 8561, 13, 50664], "temperature": 0.0, "avg_logprob": -0.3624051116233648, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.05497751757502556}, {"id": 290, "seek": 102818, "start": 1034.18, "end": 1038.8600000000001, "text": " And I guess since it's a latent model that leads us on to the next topic, right?", "tokens": [50664, 400, 286, 2041, 1670, 309, 311, 257, 48994, 2316, 300, 6689, 505, 322, 281, 264, 958, 4829, 11, 558, 30, 50898], "temperature": 0.0, "avg_logprob": -0.3624051116233648, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.05497751757502556}, {"id": 291, "seek": 102818, "start": 1038.8600000000001, "end": 1041.38, "text": " I was just going to say we've got a natural segue there.", "tokens": [50898, 286, 390, 445, 516, 281, 584, 321, 600, 658, 257, 3303, 33850, 456, 13, 51024], "temperature": 0.0, "avg_logprob": -0.3624051116233648, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.05497751757502556}, {"id": 292, "seek": 102818, "start": 1041.38, "end": 1042.38, "text": " Yes.", "tokens": [51024, 1079, 13, 51074], "temperature": 0.0, "avg_logprob": -0.3624051116233648, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.05497751757502556}, {"id": 293, "seek": 102818, "start": 1042.38, "end": 1051.78, "text": " So if we want to replicate Refusion, then we'll need Latents.", "tokens": [51074, 407, 498, 321, 528, 281, 25356, 16957, 5704, 11, 550, 321, 603, 643, 7354, 791, 13, 51544], "temperature": 0.0, "avg_logprob": -0.3624051116233648, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.05497751757502556}, {"id": 294, "seek": 105178, "start": 1052.78, "end": 1053.54, "text": " Yeah.", "tokens": [50414, 865, 13, 50452], "temperature": 0.0, "avg_logprob": -0.27008655254657454, "compression_ratio": 1.3872832369942196, "no_speech_prob": 0.00010228814062429592}, {"id": 295, "seek": 105178, "start": 1053.54, "end": 1061.22, "text": " So the final non-NLP part of stable diffusion is this ability to use the more compressed", "tokens": [50452, 407, 264, 2572, 2107, 12, 45, 45196, 644, 295, 8351, 25242, 307, 341, 3485, 281, 764, 264, 544, 30353, 50836], "temperature": 0.0, "avg_logprob": -0.27008655254657454, "compression_ratio": 1.3872832369942196, "no_speech_prob": 0.00010228814062429592}, {"id": 296, "seek": 105178, "start": 1061.22, "end": 1069.58, "text": " representation created by a VAE called Latents instead of pixels.", "tokens": [50836, 10290, 2942, 538, 257, 18527, 36, 1219, 7354, 791, 2602, 295, 18668, 13, 51254], "temperature": 0.0, "avg_logprob": -0.27008655254657454, "compression_ratio": 1.3872832369942196, "no_speech_prob": 0.00010228814062429592}, {"id": 297, "seek": 105178, "start": 1069.58, "end": 1076.66, "text": " So we're going to start today by creating a VAE, taking a look at how it works.", "tokens": [51254, 407, 321, 434, 516, 281, 722, 965, 538, 4084, 257, 18527, 36, 11, 1940, 257, 574, 412, 577, 309, 1985, 13, 51608], "temperature": 0.0, "avg_logprob": -0.27008655254657454, "compression_ratio": 1.3872832369942196, "no_speech_prob": 0.00010228814062429592}, {"id": 298, "seek": 107666, "start": 1076.7, "end": 1083.6200000000001, "text": " So to remind you, as we learned back in the first lesson of this part, of part two, the", "tokens": [50366, 407, 281, 4160, 291, 11, 382, 321, 3264, 646, 294, 264, 700, 6898, 295, 341, 644, 11, 295, 644, 732, 11, 264, 50712], "temperature": 0.0, "avg_logprob": -0.4468219656693308, "compression_ratio": 1.360759493670886, "no_speech_prob": 0.023313049226999283}, {"id": 299, "seek": 107666, "start": 1083.6200000000001, "end": 1098.5800000000002, "text": " VAE model converts the 256 by 256 pixel 3 channel into a 64 by 64 by 4?", "tokens": [50712, 18527, 36, 2316, 38874, 264, 38882, 538, 38882, 19261, 805, 2269, 666, 257, 12145, 538, 12145, 538, 1017, 30, 51460], "temperature": 0.0, "avg_logprob": -0.4468219656693308, "compression_ratio": 1.360759493670886, "no_speech_prob": 0.023313049226999283}, {"id": 300, "seek": 107666, "start": 1098.5800000000002, "end": 1100.3400000000001, "text": " It'll be 32 if it's 256.", "tokens": [51460, 467, 603, 312, 8858, 498, 309, 311, 38882, 13, 51548], "temperature": 0.0, "avg_logprob": -0.4468219656693308, "compression_ratio": 1.360759493670886, "no_speech_prob": 0.023313049226999283}, {"id": 301, "seek": 107666, "start": 1100.3400000000001, "end": 1102.3400000000001, "text": " It's 512 to 64.", "tokens": [51548, 467, 311, 1025, 4762, 281, 12145, 13, 51648], "temperature": 0.0, "avg_logprob": -0.4468219656693308, "compression_ratio": 1.360759493670886, "no_speech_prob": 0.023313049226999283}, {"id": 302, "seek": 107666, "start": 1102.3400000000001, "end": 1103.74, "text": " Oh, 512 to 64.", "tokens": [51648, 876, 11, 1025, 4762, 281, 12145, 13, 51718], "temperature": 0.0, "avg_logprob": -0.4468219656693308, "compression_ratio": 1.360759493670886, "no_speech_prob": 0.023313049226999283}, {"id": 303, "seek": 110374, "start": 1103.82, "end": 1104.1, "text": " Okay.", "tokens": [50368, 1033, 13, 50382], "temperature": 0.0, "avg_logprob": -0.33352355118636245, "compression_ratio": 1.556701030927835, "no_speech_prob": 0.0002233979175798595}, {"id": 304, "seek": 110374, "start": 1104.1, "end": 1106.9, "text": " So to a 32 by 32 by 4.", "tokens": [50382, 407, 281, 257, 8858, 538, 8858, 538, 1017, 13, 50522], "temperature": 0.0, "avg_logprob": -0.33352355118636245, "compression_ratio": 1.556701030927835, "no_speech_prob": 0.0002233979175798595}, {"id": 305, "seek": 110374, "start": 1106.9, "end": 1113.58, "text": " So dramatically smaller, which makes life so much easier.", "tokens": [50522, 407, 17548, 4356, 11, 597, 1669, 993, 370, 709, 3571, 13, 50856], "temperature": 0.0, "avg_logprob": -0.33352355118636245, "compression_ratio": 1.556701030927835, "no_speech_prob": 0.0002233979175798595}, {"id": 306, "seek": 110374, "start": 1113.58, "end": 1116.94, "text": " Which is really nice.", "tokens": [50856, 3013, 307, 534, 1481, 13, 51024], "temperature": 0.0, "avg_logprob": -0.33352355118636245, "compression_ratio": 1.556701030927835, "no_speech_prob": 0.0002233979175798595}, {"id": 307, "seek": 110374, "start": 1116.94, "end": 1124.78, "text": " Having said that, you know, simple diffusion does the first, you know, few, in fact, you", "tokens": [51024, 10222, 848, 300, 11, 291, 458, 11, 2199, 25242, 775, 264, 700, 11, 291, 458, 11, 1326, 11, 294, 1186, 11, 291, 51416], "temperature": 0.0, "avg_logprob": -0.33352355118636245, "compression_ratio": 1.556701030927835, "no_speech_prob": 0.0002233979175798595}, {"id": 308, "seek": 110374, "start": 1124.78, "end": 1129.58, "text": " know, all the downsampling pretty quickly and all the hard work happens, you know, at", "tokens": [51416, 458, 11, 439, 264, 760, 19988, 11970, 1238, 2661, 293, 439, 264, 1152, 589, 2314, 11, 291, 458, 11, 412, 51656], "temperature": 0.0, "avg_logprob": -0.33352355118636245, "compression_ratio": 1.556701030927835, "no_speech_prob": 0.0002233979175798595}, {"id": 309, "seek": 110374, "start": 1129.58, "end": 1131.9, "text": " a 16 by 16 anyway.", "tokens": [51656, 257, 3165, 538, 3165, 4033, 13, 51772], "temperature": 0.0, "avg_logprob": -0.33352355118636245, "compression_ratio": 1.556701030927835, "no_speech_prob": 0.0002233979175798595}, {"id": 310, "seek": 113190, "start": 1131.98, "end": 1136.5400000000002, "text": " So maybe it's, you know, with simple diffusion, it's not as big a deal as it used to be, but", "tokens": [50368, 407, 1310, 309, 311, 11, 291, 458, 11, 365, 2199, 25242, 11, 309, 311, 406, 382, 955, 257, 2028, 382, 309, 1143, 281, 312, 11, 457, 50596], "temperature": 0.0, "avg_logprob": -0.21780238235205934, "compression_ratio": 1.6774193548387097, "no_speech_prob": 4.98592562507838e-05}, {"id": 311, "seek": 113190, "start": 1136.5400000000002, "end": 1141.8200000000002, "text": " it's still, you know, it's very handy, particularly because for us folks with more normal amounts", "tokens": [50596, 309, 311, 920, 11, 291, 458, 11, 309, 311, 588, 13239, 11, 4098, 570, 337, 505, 4024, 365, 544, 2710, 11663, 50860], "temperature": 0.0, "avg_logprob": -0.21780238235205934, "compression_ratio": 1.6774193548387097, "no_speech_prob": 4.98592562507838e-05}, {"id": 312, "seek": 113190, "start": 1141.8200000000002, "end": 1149.02, "text": " of compute, we can take advantage of all that hard work that the stability.ai computers", "tokens": [50860, 295, 14722, 11, 321, 393, 747, 5002, 295, 439, 300, 1152, 589, 300, 264, 11826, 13, 1301, 10807, 51220], "temperature": 0.0, "avg_logprob": -0.21780238235205934, "compression_ratio": 1.6774193548387097, "no_speech_prob": 4.98592562507838e-05}, {"id": 313, "seek": 113190, "start": 1149.02, "end": 1154.22, "text": " did for us by creating the stable diffusion VAE.", "tokens": [51220, 630, 337, 505, 538, 4084, 264, 8351, 25242, 18527, 36, 13, 51480], "temperature": 0.0, "avg_logprob": -0.21780238235205934, "compression_ratio": 1.6774193548387097, "no_speech_prob": 4.98592562507838e-05}, {"id": 314, "seek": 113190, "start": 1154.22, "end": 1155.22, "text": " So that's what we're going to do today.", "tokens": [51480, 407, 300, 311, 437, 321, 434, 516, 281, 360, 965, 13, 51530], "temperature": 0.0, "avg_logprob": -0.21780238235205934, "compression_ratio": 1.6774193548387097, "no_speech_prob": 4.98592562507838e-05}, {"id": 315, "seek": 113190, "start": 1155.22, "end": 1159.22, "text": " But first of all, we're going to create our own.", "tokens": [51530, 583, 700, 295, 439, 11, 321, 434, 516, 281, 1884, 527, 1065, 13, 51730], "temperature": 0.0, "avg_logprob": -0.21780238235205934, "compression_ratio": 1.6774193548387097, "no_speech_prob": 4.98592562507838e-05}, {"id": 316, "seek": 115922, "start": 1159.22, "end": 1163.38, "text": " So let's do a VAE using fashion-mnist.", "tokens": [50364, 407, 718, 311, 360, 257, 18527, 36, 1228, 6700, 12, 40459, 468, 13, 50572], "temperature": 0.0, "avg_logprob": -0.2701510466062106, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.00013341884186957031}, {"id": 317, "seek": 115922, "start": 1163.38, "end": 1166.54, "text": " So the first, all the first stuff is just the normal.", "tokens": [50572, 407, 264, 700, 11, 439, 264, 700, 1507, 307, 445, 264, 2710, 13, 50730], "temperature": 0.0, "avg_logprob": -0.2701510466062106, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.00013341884186957031}, {"id": 318, "seek": 115922, "start": 1166.54, "end": 1172.42, "text": " One thing I am going to do for this simple example, though, is I'm going to flatten the", "tokens": [50730, 1485, 551, 286, 669, 516, 281, 360, 337, 341, 2199, 1365, 11, 1673, 11, 307, 286, 478, 516, 281, 24183, 264, 51024], "temperature": 0.0, "avg_logprob": -0.2701510466062106, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.00013341884186957031}, {"id": 319, "seek": 115922, "start": 1172.42, "end": 1178.74, "text": " fashion-mnist pixels into a vector to make it as simple as possible.", "tokens": [51024, 6700, 12, 40459, 468, 18668, 666, 257, 8062, 281, 652, 309, 382, 2199, 382, 1944, 13, 51340], "temperature": 0.0, "avg_logprob": -0.2701510466062106, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.00013341884186957031}, {"id": 320, "seek": 115922, "start": 1178.74, "end": 1180.8600000000001, "text": " Okay.", "tokens": [51340, 1033, 13, 51446], "temperature": 0.0, "avg_logprob": -0.2701510466062106, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.00013341884186957031}, {"id": 321, "seek": 115922, "start": 1180.8600000000001, "end": 1188.14, "text": " So we've, we're going to end up with vectors of length 784, because 28 by 28 is 784.", "tokens": [51446, 407, 321, 600, 11, 321, 434, 516, 281, 917, 493, 365, 18875, 295, 4641, 1614, 25494, 11, 570, 7562, 538, 7562, 307, 1614, 25494, 13, 51810], "temperature": 0.0, "avg_logprob": -0.2701510466062106, "compression_ratio": 1.566820276497696, "no_speech_prob": 0.00013341884186957031}, {"id": 322, "seek": 118814, "start": 1188.14, "end": 1201.9, "text": " We're going to create a single hidden layer MLP with 400 hidden, and then 200 outputs.", "tokens": [50364, 492, 434, 516, 281, 1884, 257, 2167, 7633, 4583, 21601, 47, 365, 8423, 7633, 11, 293, 550, 2331, 23930, 13, 51052], "temperature": 0.0, "avg_logprob": -0.29745800212278206, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.00019110353605356067}, {"id": 323, "seek": 118814, "start": 1201.9, "end": 1203.48, "text": " So here's a linear layer.", "tokens": [51052, 407, 510, 311, 257, 8213, 4583, 13, 51131], "temperature": 0.0, "avg_logprob": -0.29745800212278206, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.00019110353605356067}, {"id": 324, "seek": 118814, "start": 1203.48, "end": 1207.6200000000001, "text": " So it's a sequential containing a linear, and then an optimal activation function, and", "tokens": [51131, 407, 309, 311, 257, 42881, 19273, 257, 8213, 11, 293, 550, 364, 16252, 24433, 2445, 11, 293, 51338], "temperature": 0.0, "avg_logprob": -0.29745800212278206, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.00019110353605356067}, {"id": 325, "seek": 118814, "start": 1207.6200000000001, "end": 1211.5800000000002, "text": " an optional normalization.", "tokens": [51338, 364, 17312, 2710, 2144, 13, 51536], "temperature": 0.0, "avg_logprob": -0.29745800212278206, "compression_ratio": 1.486842105263158, "no_speech_prob": 0.00019110353605356067}, {"id": 326, "seek": 121158, "start": 1211.58, "end": 1218.1799999999998, "text": " We'll update init weights so that we initialize linear layers as well.", "tokens": [50364, 492, 603, 5623, 3157, 17443, 370, 300, 321, 5883, 1125, 8213, 7914, 382, 731, 13, 50694], "temperature": 0.0, "avg_logprob": -0.1858575325312577, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.01665177009999752}, {"id": 327, "seek": 121158, "start": 1218.1799999999998, "end": 1223.86, "text": " So before we create a VAE, which is a variational autoencoder, we'll create a normal autoencoder.", "tokens": [50694, 407, 949, 321, 1884, 257, 18527, 36, 11, 597, 307, 257, 3034, 1478, 8399, 22660, 19866, 11, 321, 603, 1884, 257, 2710, 8399, 22660, 19866, 13, 50978], "temperature": 0.0, "avg_logprob": -0.1858575325312577, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.01665177009999752}, {"id": 328, "seek": 121158, "start": 1223.86, "end": 1228.1799999999998, "text": " We've done this once before, and we didn't have any luck.", "tokens": [50978, 492, 600, 1096, 341, 1564, 949, 11, 293, 321, 994, 380, 362, 604, 3668, 13, 51194], "temperature": 0.0, "avg_logprob": -0.1858575325312577, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.01665177009999752}, {"id": 329, "seek": 121158, "start": 1228.1799999999998, "end": 1233.72, "text": " In fact, we were so unsuccessful that we decided to go back and create a learner, and come", "tokens": [51194, 682, 1186, 11, 321, 645, 370, 46258, 300, 321, 3047, 281, 352, 646, 293, 1884, 257, 476, 22916, 11, 293, 808, 51471], "temperature": 0.0, "avg_logprob": -0.1858575325312577, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.01665177009999752}, {"id": 330, "seek": 121158, "start": 1233.72, "end": 1236.46, "text": " back a few weeks later, once we knew what we were doing.", "tokens": [51471, 646, 257, 1326, 3259, 1780, 11, 1564, 321, 2586, 437, 321, 645, 884, 13, 51608], "temperature": 0.0, "avg_logprob": -0.1858575325312577, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.01665177009999752}, {"id": 331, "seek": 121158, "start": 1236.46, "end": 1237.46, "text": " So here we are.", "tokens": [51608, 407, 510, 321, 366, 13, 51658], "temperature": 0.0, "avg_logprob": -0.1858575325312577, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.01665177009999752}, {"id": 332, "seek": 121158, "start": 1237.46, "end": 1238.46, "text": " We're back.", "tokens": [51658, 492, 434, 646, 13, 51708], "temperature": 0.0, "avg_logprob": -0.1858575325312577, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.01665177009999752}, {"id": 333, "seek": 121158, "start": 1238.46, "end": 1240.6999999999998, "text": " We think we know what we're doing.", "tokens": [51708, 492, 519, 321, 458, 437, 321, 434, 884, 13, 51820], "temperature": 0.0, "avg_logprob": -0.1858575325312577, "compression_ratio": 1.7410358565737052, "no_speech_prob": 0.01665177009999752}, {"id": 334, "seek": 124070, "start": 1240.82, "end": 1246.02, "text": " So we're just going to recreate an autoencoder, just like we did some lessons ago.", "tokens": [50370, 407, 321, 434, 445, 516, 281, 25833, 364, 8399, 22660, 19866, 11, 445, 411, 321, 630, 512, 8820, 2057, 13, 50630], "temperature": 0.0, "avg_logprob": -0.22292478461014598, "compression_ratio": 1.743718592964824, "no_speech_prob": 5.920854164287448e-05}, {"id": 335, "seek": 124070, "start": 1246.02, "end": 1250.9, "text": " So there's going to be an encoder, which is a sequential, which goes from our 768 inputs", "tokens": [50630, 407, 456, 311, 516, 281, 312, 364, 2058, 19866, 11, 597, 307, 257, 42881, 11, 597, 1709, 490, 527, 24733, 23, 15743, 50874], "temperature": 0.0, "avg_logprob": -0.22292478461014598, "compression_ratio": 1.743718592964824, "no_speech_prob": 5.920854164287448e-05}, {"id": 336, "seek": 124070, "start": 1250.9, "end": 1256.7, "text": " to our 400 hidden, and then a linear layer with our 400 hidden, and then an output layer", "tokens": [50874, 281, 527, 8423, 7633, 11, 293, 550, 257, 8213, 4583, 365, 527, 8423, 7633, 11, 293, 550, 364, 5598, 4583, 51164], "temperature": 0.0, "avg_logprob": -0.22292478461014598, "compression_ratio": 1.743718592964824, "no_speech_prob": 5.920854164287448e-05}, {"id": 337, "seek": 124070, "start": 1256.7, "end": 1262.38, "text": " from the 400 hidden to the 200 outputs of the encoder.", "tokens": [51164, 490, 264, 8423, 7633, 281, 264, 2331, 23930, 295, 264, 2058, 19866, 13, 51448], "temperature": 0.0, "avg_logprob": -0.22292478461014598, "compression_ratio": 1.743718592964824, "no_speech_prob": 5.920854164287448e-05}, {"id": 338, "seek": 124070, "start": 1262.38, "end": 1265.42, "text": " So there we've got our latency.", "tokens": [51448, 407, 456, 321, 600, 658, 527, 27043, 13, 51600], "temperature": 0.0, "avg_logprob": -0.22292478461014598, "compression_ratio": 1.743718592964824, "no_speech_prob": 5.920854164287448e-05}, {"id": 339, "seek": 126542, "start": 1265.42, "end": 1273.18, "text": " And then the decoder will go from those 200 latents to our 400 hidden, have our hidden", "tokens": [50364, 400, 550, 264, 979, 19866, 486, 352, 490, 729, 2331, 4465, 791, 281, 527, 8423, 7633, 11, 362, 527, 7633, 50752], "temperature": 0.0, "avg_logprob": -0.4081566909263874, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.001727376482449472}, {"id": 340, "seek": 126542, "start": 1273.18, "end": 1280.94, "text": " layer, and then come back to our 768 inputs.", "tokens": [50752, 4583, 11, 293, 550, 808, 646, 281, 527, 24733, 23, 15743, 13, 51140], "temperature": 0.0, "avg_logprob": -0.4081566909263874, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.001727376482449472}, {"id": 341, "seek": 126542, "start": 1280.94, "end": 1283.8200000000002, "text": " All right.", "tokens": [51140, 1057, 558, 13, 51284], "temperature": 0.0, "avg_logprob": -0.4081566909263874, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.001727376482449472}, {"id": 342, "seek": 126542, "start": 1283.8200000000002, "end": 1289.9, "text": " So we can optimize that in the usual way, using Adam.", "tokens": [51284, 407, 321, 393, 19719, 300, 294, 264, 7713, 636, 11, 1228, 7938, 13, 51588], "temperature": 0.0, "avg_logprob": -0.4081566909263874, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.001727376482449472}, {"id": 343, "seek": 128990, "start": 1290.9, "end": 1294.22, "text": " And we'll do it for 20 epochs.", "tokens": [50414, 400, 321, 603, 360, 309, 337, 945, 30992, 28346, 13, 50580], "temperature": 0.0, "avg_logprob": -0.2583366254480874, "compression_ratio": 1.5, "no_speech_prob": 0.00011959778203163296}, {"id": 344, "seek": 128990, "start": 1294.22, "end": 1300.38, "text": " Runs pretty quickly, because it's quite a small data set, and quite a small model.", "tokens": [50580, 8950, 82, 1238, 2661, 11, 570, 309, 311, 1596, 257, 1359, 1412, 992, 11, 293, 1596, 257, 1359, 2316, 13, 50888], "temperature": 0.0, "avg_logprob": -0.2583366254480874, "compression_ratio": 1.5, "no_speech_prob": 0.00011959778203163296}, {"id": 345, "seek": 128990, "start": 1300.38, "end": 1308.38, "text": " And so what we can then do, is we can grab a batch of our X, or actually grab the batch", "tokens": [50888, 400, 370, 437, 321, 393, 550, 360, 11, 307, 321, 393, 4444, 257, 15245, 295, 527, 1783, 11, 420, 767, 4444, 264, 15245, 51288], "temperature": 0.0, "avg_logprob": -0.2583366254480874, "compression_ratio": 1.5, "no_speech_prob": 0.00011959778203163296}, {"id": 346, "seek": 128990, "start": 1308.38, "end": 1313.46, "text": " of X earlier, way back here.", "tokens": [51288, 295, 1783, 3071, 11, 636, 646, 510, 13, 51542], "temperature": 0.0, "avg_logprob": -0.2583366254480874, "compression_ratio": 1.5, "no_speech_prob": 0.00011959778203163296}, {"id": 347, "seek": 128990, "start": 1313.46, "end": 1317.6200000000001, "text": " So I've got a batch of images.", "tokens": [51542, 407, 286, 600, 658, 257, 15245, 295, 5267, 13, 51750], "temperature": 0.0, "avg_logprob": -0.2583366254480874, "compression_ratio": 1.5, "no_speech_prob": 0.00011959778203163296}, {"id": 348, "seek": 131762, "start": 1317.62, "end": 1326.1, "text": " And we can put it through our model, pop it back on the CPU, and we can then have a", "tokens": [50364, 400, 321, 393, 829, 309, 807, 527, 2316, 11, 1665, 309, 646, 322, 264, 13199, 11, 293, 321, 393, 550, 362, 257, 50788], "temperature": 0.0, "avg_logprob": -0.22397777012416295, "compression_ratio": 1.6382978723404256, "no_speech_prob": 6.814717926317826e-05}, {"id": 349, "seek": 131762, "start": 1326.1, "end": 1329.3, "text": " look at our original mini-batch.", "tokens": [50788, 574, 412, 527, 3380, 8382, 12, 65, 852, 13, 50948], "temperature": 0.0, "avg_logprob": -0.22397777012416295, "compression_ratio": 1.6382978723404256, "no_speech_prob": 6.814717926317826e-05}, {"id": 350, "seek": 131762, "start": 1329.3, "end": 1333.86, "text": " And we have to reshape it to 28 by 28, because we previously had flattened it.", "tokens": [50948, 400, 321, 362, 281, 725, 42406, 309, 281, 7562, 538, 7562, 11, 570, 321, 8046, 632, 24183, 292, 309, 13, 51176], "temperature": 0.0, "avg_logprob": -0.22397777012416295, "compression_ratio": 1.6382978723404256, "no_speech_prob": 6.814717926317826e-05}, {"id": 351, "seek": 131762, "start": 1333.86, "end": 1335.82, "text": " So there's our original.", "tokens": [51176, 407, 456, 311, 527, 3380, 13, 51274], "temperature": 0.0, "avg_logprob": -0.22397777012416295, "compression_ratio": 1.6382978723404256, "no_speech_prob": 6.814717926317826e-05}, {"id": 352, "seek": 131762, "start": 1335.82, "end": 1341.78, "text": " And then we can look at the result after putting it through our model.", "tokens": [51274, 400, 550, 321, 393, 574, 412, 264, 1874, 934, 3372, 309, 807, 527, 2316, 13, 51572], "temperature": 0.0, "avg_logprob": -0.22397777012416295, "compression_ratio": 1.6382978723404256, "no_speech_prob": 6.814717926317826e-05}, {"id": 353, "seek": 131762, "start": 1341.78, "end": 1342.78, "text": " And there it is.", "tokens": [51572, 400, 456, 309, 307, 13, 51622], "temperature": 0.0, "avg_logprob": -0.22397777012416295, "compression_ratio": 1.6382978723404256, "no_speech_prob": 6.814717926317826e-05}, {"id": 354, "seek": 134278, "start": 1342.78, "end": 1347.62, "text": " So you can see, it's very roughly regenerated.", "tokens": [50364, 407, 291, 393, 536, 11, 309, 311, 588, 9810, 26358, 770, 13, 50606], "temperature": 0.0, "avg_logprob": -0.26456707040059196, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.05499596893787384}, {"id": 355, "seek": 134278, "start": 1347.62, "end": 1350.54, "text": " And so this is not a massive compression.", "tokens": [50606, 400, 370, 341, 307, 406, 257, 5994, 19355, 13, 50752], "temperature": 0.0, "avg_logprob": -0.26456707040059196, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.05499596893787384}, {"id": 356, "seek": 134278, "start": 1350.54, "end": 1355.1399999999999, "text": " It's compressing it from 768 to 200.", "tokens": [50752, 467, 311, 14778, 278, 309, 490, 24733, 23, 281, 2331, 13, 50982], "temperature": 0.0, "avg_logprob": -0.26456707040059196, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.05499596893787384}, {"id": 357, "seek": 134278, "start": 1355.1399999999999, "end": 1358.46, "text": " And it's also not doing an amazing job of recreating the original details.", "tokens": [50982, 400, 309, 311, 611, 406, 884, 364, 2243, 1691, 295, 850, 44613, 264, 3380, 4365, 13, 51148], "temperature": 0.0, "avg_logprob": -0.26456707040059196, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.05499596893787384}, {"id": 358, "seek": 134278, "start": 1358.46, "end": 1362.42, "text": " But this is the simplest possible autoencoder.", "tokens": [51148, 583, 341, 307, 264, 22811, 1944, 8399, 22660, 19866, 13, 51346], "temperature": 0.0, "avg_logprob": -0.26456707040059196, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.05499596893787384}, {"id": 359, "seek": 134278, "start": 1362.42, "end": 1366.8999999999999, "text": " So it's doing, you know, it's a lot better than our previous attempt.", "tokens": [51346, 407, 309, 311, 884, 11, 291, 458, 11, 309, 311, 257, 688, 1101, 813, 527, 3894, 5217, 13, 51570], "temperature": 0.0, "avg_logprob": -0.26456707040059196, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.05499596893787384}, {"id": 360, "seek": 134278, "start": 1366.8999999999999, "end": 1369.54, "text": " So that's good.", "tokens": [51570, 407, 300, 311, 665, 13, 51702], "temperature": 0.0, "avg_logprob": -0.26456707040059196, "compression_ratio": 1.5136363636363637, "no_speech_prob": 0.05499596893787384}, {"id": 361, "seek": 136954, "start": 1369.54, "end": 1373.86, "text": " So what we could now do, is we could just generate some noise.", "tokens": [50364, 407, 437, 321, 727, 586, 360, 11, 307, 321, 727, 445, 8460, 512, 5658, 13, 50580], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 362, "seek": 136954, "start": 1373.86, "end": 1375.86, "text": " And then, we're not even going to do diffusion.", "tokens": [50580, 400, 550, 11, 321, 434, 406, 754, 516, 281, 360, 25242, 13, 50680], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 363, "seek": 136954, "start": 1375.86, "end": 1378.18, "text": " We're just going to go and say, like, okay, we've got a decoder.", "tokens": [50680, 492, 434, 445, 516, 281, 352, 293, 584, 11, 411, 11, 1392, 11, 321, 600, 658, 257, 979, 19866, 13, 50796], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 364, "seek": 136954, "start": 1378.18, "end": 1380.82, "text": " So let's just decode that noise.", "tokens": [50796, 407, 718, 311, 445, 979, 1429, 300, 5658, 13, 50928], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 365, "seek": 136954, "start": 1380.82, "end": 1383.44, "text": " And see what it creates.", "tokens": [50928, 400, 536, 437, 309, 7829, 13, 51059], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 366, "seek": 136954, "start": 1383.44, "end": 1386.58, "text": " And the answer is, not anything great.", "tokens": [51059, 400, 264, 1867, 307, 11, 406, 1340, 869, 13, 51216], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 367, "seek": 136954, "start": 1386.58, "end": 1391.94, "text": " I mean, I could kind of recognize that might be the start of a shoe.", "tokens": [51216, 286, 914, 11, 286, 727, 733, 295, 5521, 300, 1062, 312, 264, 722, 295, 257, 12796, 13, 51484], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 368, "seek": 136954, "start": 1391.94, "end": 1392.94, "text": " Maybe that's the start of a bag.", "tokens": [51484, 2704, 300, 311, 264, 722, 295, 257, 3411, 13, 51534], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 369, "seek": 136954, "start": 1392.94, "end": 1393.94, "text": " I don't know.", "tokens": [51534, 286, 500, 380, 458, 13, 51584], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 370, "seek": 136954, "start": 1393.94, "end": 1396.18, "text": " But it's not doing anything amazing.", "tokens": [51584, 583, 309, 311, 406, 884, 1340, 2243, 13, 51696], "temperature": 0.0, "avg_logprob": -0.24099956859241833, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.0003858954878523946}, {"id": 371, "seek": 139618, "start": 1396.18, "end": 1401.74, "text": " So we have not successfully created an image generator here.", "tokens": [50364, 407, 321, 362, 406, 10727, 2942, 364, 3256, 19265, 510, 13, 50642], "temperature": 0.0, "avg_logprob": -0.2145684003829956, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.0039451830089092255}, {"id": 372, "seek": 139618, "start": 1401.74, "end": 1406.3, "text": " But there's a very simple step we can do to make something that's more like an image generator.", "tokens": [50642, 583, 456, 311, 257, 588, 2199, 1823, 321, 393, 360, 281, 652, 746, 300, 311, 544, 411, 364, 3256, 19265, 13, 50870], "temperature": 0.0, "avg_logprob": -0.2145684003829956, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.0039451830089092255}, {"id": 373, "seek": 139618, "start": 1406.3, "end": 1416.42, "text": " The problem is that these 200, this vector of length 200 we're creating, there's no particular", "tokens": [50870, 440, 1154, 307, 300, 613, 2331, 11, 341, 8062, 295, 4641, 2331, 321, 434, 4084, 11, 456, 311, 572, 1729, 51376], "temperature": 0.0, "avg_logprob": -0.2145684003829956, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.0039451830089092255}, {"id": 374, "seek": 139618, "start": 1416.42, "end": 1424.5800000000002, "text": " reason that things that are not in the data set are going to create items of clothing.", "tokens": [51376, 1778, 300, 721, 300, 366, 406, 294, 264, 1412, 992, 366, 516, 281, 1884, 4754, 295, 11502, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2145684003829956, "compression_ratio": 1.6407766990291262, "no_speech_prob": 0.0039451830089092255}, {"id": 375, "seek": 142458, "start": 1424.58, "end": 1426.6599999999999, "text": " We haven't done anything to try to make that happen.", "tokens": [50364, 492, 2378, 380, 1096, 1340, 281, 853, 281, 652, 300, 1051, 13, 50468], "temperature": 0.0, "avg_logprob": -0.26962933097918007, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0043313889764249325}, {"id": 376, "seek": 142458, "start": 1426.6599999999999, "end": 1430.78, "text": " We've only tried to make this work for things in the data set.", "tokens": [50468, 492, 600, 787, 3031, 281, 652, 341, 589, 337, 721, 294, 264, 1412, 992, 13, 50674], "temperature": 0.0, "avg_logprob": -0.26962933097918007, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0043313889764249325}, {"id": 377, "seek": 142458, "start": 1430.78, "end": 1441.06, "text": " And therefore, when we just randomly generate a bunch of, you know, a vector of length 200,", "tokens": [50674, 400, 4412, 11, 562, 321, 445, 16979, 8460, 257, 3840, 295, 11, 291, 458, 11, 257, 8062, 295, 4641, 2331, 11, 51188], "temperature": 0.0, "avg_logprob": -0.26962933097918007, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0043313889764249325}, {"id": 378, "seek": 142458, "start": 1441.06, "end": 1446.82, "text": " or 16 vectors of length 200, in this case, and then decode them, there's no particular", "tokens": [51188, 420, 3165, 18875, 295, 4641, 2331, 11, 294, 341, 1389, 11, 293, 550, 979, 1429, 552, 11, 456, 311, 572, 1729, 51476], "temperature": 0.0, "avg_logprob": -0.26962933097918007, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0043313889764249325}, {"id": 379, "seek": 142458, "start": 1446.82, "end": 1453.8999999999999, "text": " reason to think that they're going to create something that's recognizable as clothing.", "tokens": [51476, 1778, 281, 519, 300, 436, 434, 516, 281, 1884, 746, 300, 311, 40757, 382, 11502, 13, 51830], "temperature": 0.0, "avg_logprob": -0.26962933097918007, "compression_ratio": 1.6118143459915613, "no_speech_prob": 0.0043313889764249325}, {"id": 380, "seek": 145390, "start": 1454.22, "end": 1465.46, "text": " So the way a VAE tries to fix this is by, we've got the exact same encoder as before,", "tokens": [50380, 407, 264, 636, 257, 18527, 36, 9898, 281, 3191, 341, 307, 538, 11, 321, 600, 658, 264, 1900, 912, 2058, 19866, 382, 949, 11, 50942], "temperature": 0.0, "avg_logprob": -0.2838263078169389, "compression_ratio": 1.6519607843137254, "no_speech_prob": 3.1196337658911943e-05}, {"id": 381, "seek": 145390, "start": 1465.46, "end": 1469.1000000000001, "text": " except it's just missing its final layer.", "tokens": [50942, 3993, 309, 311, 445, 5361, 1080, 2572, 4583, 13, 51124], "temperature": 0.0, "avg_logprob": -0.2838263078169389, "compression_ratio": 1.6519607843137254, "no_speech_prob": 3.1196337658911943e-05}, {"id": 382, "seek": 145390, "start": 1469.1000000000001, "end": 1471.5400000000002, "text": " Its final layer has been moved over to here.", "tokens": [51124, 6953, 2572, 4583, 575, 668, 4259, 670, 281, 510, 13, 51246], "temperature": 0.0, "avg_logprob": -0.2838263078169389, "compression_ratio": 1.6519607843137254, "no_speech_prob": 3.1196337658911943e-05}, {"id": 383, "seek": 145390, "start": 1471.5400000000002, "end": 1474.0600000000002, "text": " I'll explain why there's two of them in a moment.", "tokens": [51246, 286, 603, 2903, 983, 456, 311, 732, 295, 552, 294, 257, 1623, 13, 51372], "temperature": 0.0, "avg_logprob": -0.2838263078169389, "compression_ratio": 1.6519607843137254, "no_speech_prob": 3.1196337658911943e-05}, {"id": 384, "seek": 145390, "start": 1474.0600000000002, "end": 1479.7, "text": " So we've got the inputs to hidden, the hidden to hidden, and then the hidden to latence.", "tokens": [51372, 407, 321, 600, 658, 264, 15743, 281, 7633, 11, 264, 7633, 281, 7633, 11, 293, 550, 264, 7633, 281, 287, 267, 655, 13, 51654], "temperature": 0.0, "avg_logprob": -0.2838263078169389, "compression_ratio": 1.6519607843137254, "no_speech_prob": 3.1196337658911943e-05}, {"id": 385, "seek": 145390, "start": 1479.7, "end": 1481.3000000000002, "text": " The decoder is identical.", "tokens": [51654, 440, 979, 19866, 307, 14800, 13, 51734], "temperature": 0.0, "avg_logprob": -0.2838263078169389, "compression_ratio": 1.6519607843137254, "no_speech_prob": 3.1196337658911943e-05}, {"id": 386, "seek": 148130, "start": 1482.1399999999999, "end": 1489.3, "text": " OK, latence to hidden, hidden to hidden, hidden to inputs.", "tokens": [50406, 2264, 11, 287, 267, 655, 281, 7633, 11, 7633, 281, 7633, 11, 7633, 281, 15743, 13, 50764], "temperature": 0.0, "avg_logprob": -0.34470894377110367, "compression_ratio": 1.4475524475524475, "no_speech_prob": 1.3630244211526588e-05}, {"id": 387, "seek": 148130, "start": 1489.3, "end": 1495.78, "text": " And then just as before, we call the encoder.", "tokens": [50764, 400, 550, 445, 382, 949, 11, 321, 818, 264, 2058, 19866, 13, 51088], "temperature": 0.0, "avg_logprob": -0.34470894377110367, "compression_ratio": 1.4475524475524475, "no_speech_prob": 1.3630244211526588e-05}, {"id": 388, "seek": 148130, "start": 1495.78, "end": 1503.86, "text": " But we do something a little bit weird next, which is that we actually have two separate", "tokens": [51088, 583, 321, 360, 746, 257, 707, 857, 3657, 958, 11, 597, 307, 300, 321, 767, 362, 732, 4994, 51492], "temperature": 0.0, "avg_logprob": -0.34470894377110367, "compression_ratio": 1.4475524475524475, "no_speech_prob": 1.3630244211526588e-05}, {"id": 389, "seek": 148130, "start": 1503.86, "end": 1505.1, "text": " final layers.", "tokens": [51492, 2572, 7914, 13, 51554], "temperature": 0.0, "avg_logprob": -0.34470894377110367, "compression_ratio": 1.4475524475524475, "no_speech_prob": 1.3630244211526588e-05}, {"id": 390, "seek": 150510, "start": 1505.1, "end": 1511.82, "text": " We've got one called mu for the final of the encoder, and one called LV, which stands", "tokens": [50364, 492, 600, 658, 472, 1219, 2992, 337, 264, 2572, 295, 264, 2058, 19866, 11, 293, 472, 1219, 441, 53, 11, 597, 7382, 50700], "temperature": 0.0, "avg_logprob": -0.30179557800292967, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00020026530546601862}, {"id": 391, "seek": 150510, "start": 1511.82, "end": 1513.9399999999998, "text": " for log variance.", "tokens": [50700, 337, 3565, 21977, 13, 50806], "temperature": 0.0, "avg_logprob": -0.30179557800292967, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00020026530546601862}, {"id": 392, "seek": 150510, "start": 1513.9399999999998, "end": 1517.02, "text": " So our encoder has two different final layers.", "tokens": [50806, 407, 527, 2058, 19866, 575, 732, 819, 2572, 7914, 13, 50960], "temperature": 0.0, "avg_logprob": -0.30179557800292967, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00020026530546601862}, {"id": 393, "seek": 150510, "start": 1517.02, "end": 1519.1799999999998, "text": " So we're going to call both of them.", "tokens": [50960, 407, 321, 434, 516, 281, 818, 1293, 295, 552, 13, 51068], "temperature": 0.0, "avg_logprob": -0.30179557800292967, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00020026530546601862}, {"id": 394, "seek": 150510, "start": 1519.1799999999998, "end": 1526.2199999999998, "text": " OK, so we've now got two encoded 200 long lots of latence.", "tokens": [51068, 2264, 11, 370, 321, 600, 586, 658, 732, 2058, 12340, 2331, 938, 3195, 295, 287, 267, 655, 13, 51420], "temperature": 0.0, "avg_logprob": -0.30179557800292967, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00020026530546601862}, {"id": 395, "seek": 150510, "start": 1526.2199999999998, "end": 1527.8999999999999, "text": " What do we do with them?", "tokens": [51420, 708, 360, 321, 360, 365, 552, 30, 51504], "temperature": 0.0, "avg_logprob": -0.30179557800292967, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00020026530546601862}, {"id": 396, "seek": 152790, "start": 1527.9, "end": 1536.7800000000002, "text": " What we do is we use them to generate random numbers.", "tokens": [50364, 708, 321, 360, 307, 321, 764, 552, 281, 8460, 4974, 3547, 13, 50808], "temperature": 0.0, "avg_logprob": -0.29978042993790066, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0005112285725772381}, {"id": 397, "seek": 152790, "start": 1536.7800000000002, "end": 1541.46, "text": " And the random numbers have a mean of mu.", "tokens": [50808, 400, 264, 4974, 3547, 362, 257, 914, 295, 2992, 13, 51042], "temperature": 0.0, "avg_logprob": -0.29978042993790066, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0005112285725772381}, {"id": 398, "seek": 152790, "start": 1541.46, "end": 1549.02, "text": " So when you take a random 0, 1, so this creates 0, 1 random numbers, mean 0, standard deviation", "tokens": [51042, 407, 562, 291, 747, 257, 4974, 1958, 11, 502, 11, 370, 341, 7829, 1958, 11, 502, 4974, 3547, 11, 914, 1958, 11, 3832, 25163, 51420], "temperature": 0.0, "avg_logprob": -0.29978042993790066, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0005112285725772381}, {"id": 399, "seek": 152790, "start": 1549.02, "end": 1550.02, "text": " 1.", "tokens": [51420, 502, 13, 51470], "temperature": 0.0, "avg_logprob": -0.29978042993790066, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0005112285725772381}, {"id": 400, "seek": 152790, "start": 1550.02, "end": 1554.8000000000002, "text": " So if we add mu to it, then you have a mean of mu, approximately.", "tokens": [51470, 407, 498, 321, 909, 2992, 281, 309, 11, 550, 291, 362, 257, 914, 295, 2992, 11, 10447, 13, 51709], "temperature": 0.0, "avg_logprob": -0.29978042993790066, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.0005112285725772381}, {"id": 401, "seek": 155480, "start": 1554.8, "end": 1562.6, "text": " And if you multiply the random numbers by half of log variance e to the power of that,", "tokens": [50364, 400, 498, 291, 12972, 264, 4974, 3547, 538, 1922, 295, 3565, 21977, 308, 281, 264, 1347, 295, 300, 11, 50754], "temperature": 0.0, "avg_logprob": -0.26153359953890143, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.0002453621127642691}, {"id": 402, "seek": 155480, "start": 1562.6, "end": 1568.72, "text": " so given this log of variance, this is going to give you standard deviation.", "tokens": [50754, 370, 2212, 341, 3565, 295, 21977, 11, 341, 307, 516, 281, 976, 291, 3832, 25163, 13, 51060], "temperature": 0.0, "avg_logprob": -0.26153359953890143, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.0002453621127642691}, {"id": 403, "seek": 155480, "start": 1568.72, "end": 1576.28, "text": " So this is going to give you a standard deviation of e to the half LV and a mean of mu.", "tokens": [51060, 407, 341, 307, 516, 281, 976, 291, 257, 3832, 25163, 295, 308, 281, 264, 1922, 441, 53, 293, 257, 914, 295, 2992, 13, 51438], "temperature": 0.0, "avg_logprob": -0.26153359953890143, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.0002453621127642691}, {"id": 404, "seek": 155480, "start": 1576.28, "end": 1577.68, "text": " Why the half?", "tokens": [51438, 1545, 264, 1922, 30, 51508], "temperature": 0.0, "avg_logprob": -0.26153359953890143, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.0002453621127642691}, {"id": 405, "seek": 155480, "start": 1577.68, "end": 1578.98, "text": " It doesn't matter too much.", "tokens": [51508, 467, 1177, 380, 1871, 886, 709, 13, 51573], "temperature": 0.0, "avg_logprob": -0.26153359953890143, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.0002453621127642691}, {"id": 406, "seek": 155480, "start": 1578.98, "end": 1583.86, "text": " But if you think about it, standard deviation is the square root.", "tokens": [51573, 583, 498, 291, 519, 466, 309, 11, 3832, 25163, 307, 264, 3732, 5593, 13, 51817], "temperature": 0.0, "avg_logprob": -0.26153359953890143, "compression_ratio": 1.7684729064039408, "no_speech_prob": 0.0002453621127642691}, {"id": 407, "seek": 158386, "start": 1583.9199999999998, "end": 1586.5, "text": " So the variance is squared.", "tokens": [50367, 407, 264, 21977, 307, 8889, 13, 50496], "temperature": 0.0, "avg_logprob": -0.27116622505607185, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0003859640855807811}, {"id": 408, "seek": 158386, "start": 1586.5, "end": 1594.82, "text": " So when you take the log, you can move that half into the multiplication because of the", "tokens": [50496, 407, 562, 291, 747, 264, 3565, 11, 291, 393, 1286, 300, 1922, 666, 264, 27290, 570, 295, 264, 50912], "temperature": 0.0, "avg_logprob": -0.27116622505607185, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0003859640855807811}, {"id": 409, "seek": 158386, "start": 1594.82, "end": 1596.6999999999998, "text": " log trick.", "tokens": [50912, 3565, 4282, 13, 51006], "temperature": 0.0, "avg_logprob": -0.27116622505607185, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0003859640855807811}, {"id": 410, "seek": 158386, "start": 1596.6999999999998, "end": 1601.06, "text": " That's why we just got the half here instead of the square root, which would be to the", "tokens": [51006, 663, 311, 983, 321, 445, 658, 264, 1922, 510, 2602, 295, 264, 3732, 5593, 11, 597, 576, 312, 281, 264, 51224], "temperature": 0.0, "avg_logprob": -0.27116622505607185, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0003859640855807811}, {"id": 411, "seek": 158386, "start": 1601.06, "end": 1604.28, "text": " power of a half.", "tokens": [51224, 1347, 295, 257, 1922, 13, 51385], "temperature": 0.0, "avg_logprob": -0.27116622505607185, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0003859640855807811}, {"id": 412, "seek": 158386, "start": 1604.28, "end": 1608.1799999999998, "text": " So this is just the standard deviation.", "tokens": [51385, 407, 341, 307, 445, 264, 3832, 25163, 13, 51580], "temperature": 0.0, "avg_logprob": -0.27116622505607185, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0003859640855807811}, {"id": 413, "seek": 158386, "start": 1608.1799999999998, "end": 1612.1, "text": " So we've got the standard deviation times normally distributed random noise plus mu.", "tokens": [51580, 407, 321, 600, 658, 264, 3832, 25163, 1413, 5646, 12631, 4974, 5658, 1804, 2992, 13, 51776], "temperature": 0.0, "avg_logprob": -0.27116622505607185, "compression_ratio": 1.6824644549763033, "no_speech_prob": 0.0003859640855807811}, {"id": 414, "seek": 161210, "start": 1612.1399999999999, "end": 1618.4599999999998, "text": " Now we end up with normally distributed numbers.", "tokens": [50366, 823, 321, 917, 493, 365, 5646, 12631, 3547, 13, 50682], "temperature": 0.0, "avg_logprob": -0.3291893005371094, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00044420306221581995}, {"id": 415, "seek": 161210, "start": 1618.4599999999998, "end": 1624.2199999999998, "text": " We're going to have 200 of them for each element of the batch, where they have a standard deviation", "tokens": [50682, 492, 434, 516, 281, 362, 2331, 295, 552, 337, 1184, 4478, 295, 264, 15245, 11, 689, 436, 362, 257, 3832, 25163, 50970], "temperature": 0.0, "avg_logprob": -0.3291893005371094, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00044420306221581995}, {"id": 416, "seek": 161210, "start": 1624.2199999999998, "end": 1633.86, "text": " of the result of this final layer and a variance, which is the result, or log variance, of the", "tokens": [50970, 295, 264, 1874, 295, 341, 2572, 4583, 293, 257, 21977, 11, 597, 307, 264, 1874, 11, 420, 3565, 21977, 11, 295, 264, 51452], "temperature": 0.0, "avg_logprob": -0.3291893005371094, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00044420306221581995}, {"id": 417, "seek": 161210, "start": 1633.86, "end": 1637.02, "text": " result of this final layer.", "tokens": [51452, 1874, 295, 341, 2572, 4583, 13, 51610], "temperature": 0.0, "avg_logprob": -0.3291893005371094, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00044420306221581995}, {"id": 418, "seek": 161210, "start": 1637.02, "end": 1641.34, "text": " And then finally we pass that through the decoder as usual.", "tokens": [51610, 400, 550, 2721, 321, 1320, 300, 807, 264, 979, 19866, 382, 7713, 13, 51826], "temperature": 0.0, "avg_logprob": -0.3291893005371094, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.00044420306221581995}, {"id": 419, "seek": 164134, "start": 1641.58, "end": 1644.22, "text": " I'll explain why we pass back three things, but for now we're just worried about the fact", "tokens": [50376, 286, 603, 2903, 983, 321, 1320, 646, 1045, 721, 11, 457, 337, 586, 321, 434, 445, 5804, 466, 264, 1186, 50508], "temperature": 0.0, "avg_logprob": -0.27296042972140844, "compression_ratio": 1.6748768472906403, "no_speech_prob": 2.7535652407095768e-05}, {"id": 420, "seek": 164134, "start": 1644.22, "end": 1647.4599999999998, "text": " we pass back the result of the decoder.", "tokens": [50508, 321, 1320, 646, 264, 1874, 295, 264, 979, 19866, 13, 50670], "temperature": 0.0, "avg_logprob": -0.27296042972140844, "compression_ratio": 1.6748768472906403, "no_speech_prob": 2.7535652407095768e-05}, {"id": 421, "seek": 164134, "start": 1647.4599999999998, "end": 1657.6599999999999, "text": " So what this is going to do is it's going to generate the result of calling encode is", "tokens": [50670, 407, 437, 341, 307, 516, 281, 360, 307, 309, 311, 516, 281, 8460, 264, 1874, 295, 5141, 2058, 1429, 307, 51180], "temperature": 0.0, "avg_logprob": -0.27296042972140844, "compression_ratio": 1.6748768472906403, "no_speech_prob": 2.7535652407095768e-05}, {"id": 422, "seek": 164134, "start": 1657.6599999999999, "end": 1660.5, "text": " going to be a little bit random.", "tokens": [51180, 516, 281, 312, 257, 707, 857, 4974, 13, 51322], "temperature": 0.0, "avg_logprob": -0.27296042972140844, "compression_ratio": 1.6748768472906403, "no_speech_prob": 2.7535652407095768e-05}, {"id": 423, "seek": 164134, "start": 1660.5, "end": 1665.6599999999999, "text": " On average, you know, it's still generating exactly the same as before, which is the result", "tokens": [51322, 1282, 4274, 11, 291, 458, 11, 309, 311, 920, 17746, 2293, 264, 912, 382, 949, 11, 597, 307, 264, 1874, 51580], "temperature": 0.0, "avg_logprob": -0.27296042972140844, "compression_ratio": 1.6748768472906403, "no_speech_prob": 2.7535652407095768e-05}, {"id": 424, "seek": 166566, "start": 1665.8200000000002, "end": 1671.66, "text": " of a sequential model with, you know, MLP with one hidden layer.", "tokens": [50372, 295, 257, 42881, 2316, 365, 11, 291, 458, 11, 21601, 47, 365, 472, 7633, 4583, 13, 50664], "temperature": 0.0, "avg_logprob": -0.29384020396641325, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.000216540414839983}, {"id": 425, "seek": 166566, "start": 1671.66, "end": 1675.9, "text": " But it's also going to add some randomness around that, right?", "tokens": [50664, 583, 309, 311, 611, 516, 281, 909, 512, 4974, 1287, 926, 300, 11, 558, 30, 50876], "temperature": 0.0, "avg_logprob": -0.29384020396641325, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.000216540414839983}, {"id": 426, "seek": 166566, "start": 1675.9, "end": 1678.38, "text": " So this is, here's the bit which is exactly the same as before.", "tokens": [50876, 407, 341, 307, 11, 510, 311, 264, 857, 597, 307, 2293, 264, 912, 382, 949, 13, 51000], "temperature": 0.0, "avg_logprob": -0.29384020396641325, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.000216540414839983}, {"id": 427, "seek": 166566, "start": 1678.38, "end": 1683.18, "text": " This is the same as calling encode before, but then here's the bit that adds some randomness", "tokens": [51000, 639, 307, 264, 912, 382, 5141, 2058, 1429, 949, 11, 457, 550, 510, 311, 264, 857, 300, 10860, 512, 4974, 1287, 51240], "temperature": 0.0, "avg_logprob": -0.29384020396641325, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.000216540414839983}, {"id": 428, "seek": 166566, "start": 1683.18, "end": 1684.18, "text": " to it.", "tokens": [51240, 281, 309, 13, 51290], "temperature": 0.0, "avg_logprob": -0.29384020396641325, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.000216540414839983}, {"id": 429, "seek": 166566, "start": 1684.18, "end": 1688.5800000000002, "text": " And the amount of randomness is also itself random.", "tokens": [51290, 400, 264, 2372, 295, 4974, 1287, 307, 611, 2564, 4974, 13, 51510], "temperature": 0.0, "avg_logprob": -0.29384020396641325, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.000216540414839983}, {"id": 430, "seek": 166566, "start": 1688.5800000000002, "end": 1689.6200000000001, "text": " Okay.", "tokens": [51510, 1033, 13, 51562], "temperature": 0.0, "avg_logprob": -0.29384020396641325, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.000216540414839983}, {"id": 431, "seek": 166566, "start": 1689.6200000000001, "end": 1692.14, "text": " So then that gets run through the decoder.", "tokens": [51562, 407, 550, 300, 2170, 1190, 807, 264, 979, 19866, 13, 51688], "temperature": 0.0, "avg_logprob": -0.29384020396641325, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.000216540414839983}, {"id": 432, "seek": 169214, "start": 1692.14, "end": 1693.7800000000002, "text": " Okay.", "tokens": [50364, 1033, 13, 50446], "temperature": 0.0, "avg_logprob": -0.3086816630232225, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0007672692881897092}, {"id": 433, "seek": 169214, "start": 1693.7800000000002, "end": 1701.3400000000001, "text": " So if we now just, well, you know, trained that, right?", "tokens": [50446, 407, 498, 321, 586, 445, 11, 731, 11, 291, 458, 11, 8895, 300, 11, 558, 30, 50824], "temperature": 0.0, "avg_logprob": -0.3086816630232225, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0007672692881897092}, {"id": 434, "seek": 169214, "start": 1701.3400000000001, "end": 1706.9, "text": " Using the result of the decoder and using, I think we didn't use MSC loss, we used a", "tokens": [50824, 11142, 264, 1874, 295, 264, 979, 19866, 293, 1228, 11, 286, 519, 321, 994, 380, 764, 7395, 34, 4470, 11, 321, 1143, 257, 51102], "temperature": 0.0, "avg_logprob": -0.3086816630232225, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0007672692881897092}, {"id": 435, "seek": 169214, "start": 1706.9, "end": 1710.7, "text": " binary cross-entropy loss, which we've seen before.", "tokens": [51102, 17434, 3278, 12, 317, 27514, 4470, 11, 597, 321, 600, 1612, 949, 13, 51292], "temperature": 0.0, "avg_logprob": -0.3086816630232225, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0007672692881897092}, {"id": 436, "seek": 169214, "start": 1710.7, "end": 1714.9, "text": " So if you've forgotten, you should definitely go back and rewatch that, really part one,", "tokens": [51292, 407, 498, 291, 600, 11832, 11, 291, 820, 2138, 352, 646, 293, 319, 15219, 300, 11, 534, 644, 472, 11, 51502], "temperature": 0.0, "avg_logprob": -0.3086816630232225, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0007672692881897092}, {"id": 437, "seek": 169214, "start": 1714.9, "end": 1721.74, "text": " or we've done a bit of it in part two as well, binary cross-entropy loss.", "tokens": [51502, 420, 321, 600, 1096, 257, 857, 295, 309, 294, 644, 732, 382, 731, 11, 17434, 3278, 12, 317, 27514, 4470, 13, 51844], "temperature": 0.0, "avg_logprob": -0.3086816630232225, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0007672692881897092}, {"id": 438, "seek": 172174, "start": 1722.34, "end": 1735.82, "text": " So if we just optimize this using BCE now, you would expect, and it would, I believe", "tokens": [50394, 407, 498, 321, 445, 19719, 341, 1228, 49369, 586, 11, 291, 576, 2066, 11, 293, 309, 576, 11, 286, 1697, 51068], "temperature": 0.0, "avg_logprob": -0.3131810658013643, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.0010322204325348139}, {"id": 439, "seek": 172174, "start": 1735.82, "end": 1740.9, "text": " I haven't checked, that it would basically take this final, this layer here, and turn", "tokens": [51068, 286, 2378, 380, 10033, 11, 300, 309, 576, 1936, 747, 341, 2572, 11, 341, 4583, 510, 11, 293, 1261, 51322], "temperature": 0.0, "avg_logprob": -0.3131810658013643, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.0010322204325348139}, {"id": 440, "seek": 172174, "start": 1740.9, "end": 1743.18, "text": " these all into zeros.", "tokens": [51322, 613, 439, 666, 35193, 13, 51436], "temperature": 0.0, "avg_logprob": -0.3131810658013643, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.0010322204325348139}, {"id": 441, "seek": 172174, "start": 1743.18, "end": 1746.94, "text": " As a result of which it would have no variance at all.", "tokens": [51436, 1018, 257, 1874, 295, 597, 309, 576, 362, 572, 21977, 412, 439, 13, 51624], "temperature": 0.0, "avg_logprob": -0.3131810658013643, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.0010322204325348139}, {"id": 442, "seek": 174694, "start": 1746.94, "end": 1753.22, "text": " And therefore it would behave exactly the same as the previous autoencoder.", "tokens": [50364, 400, 4412, 309, 576, 15158, 2293, 264, 912, 382, 264, 3894, 8399, 22660, 19866, 13, 50678], "temperature": 0.0, "avg_logprob": -0.3080255452869008, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.010487545281648636}, {"id": 443, "seek": 174694, "start": 1753.22, "end": 1756.1000000000001, "text": " Does that sound reasonable to you guys?", "tokens": [50678, 4402, 300, 1626, 10585, 281, 291, 1074, 30, 50822], "temperature": 0.0, "avg_logprob": -0.3080255452869008, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.010487545281648636}, {"id": 444, "seek": 174694, "start": 1756.1000000000001, "end": 1757.1000000000001, "text": " Yeah.", "tokens": [50822, 865, 13, 50872], "temperature": 0.0, "avg_logprob": -0.3080255452869008, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.010487545281648636}, {"id": 445, "seek": 174694, "start": 1757.1000000000001, "end": 1758.1000000000001, "text": " Okay.", "tokens": [50872, 1033, 13, 50922], "temperature": 0.0, "avg_logprob": -0.3080255452869008, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.010487545281648636}, {"id": 446, "seek": 174694, "start": 1758.1000000000001, "end": 1761.42, "text": " So that wouldn't help at all, because what we actually want is we want some variance.", "tokens": [50922, 407, 300, 2759, 380, 854, 412, 439, 11, 570, 437, 321, 767, 528, 307, 321, 528, 512, 21977, 13, 51088], "temperature": 0.0, "avg_logprob": -0.3080255452869008, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.010487545281648636}, {"id": 447, "seek": 174694, "start": 1761.42, "end": 1770.18, "text": " And the reason we want some variance is we actually want to have it generate some latents,", "tokens": [51088, 400, 264, 1778, 321, 528, 512, 21977, 307, 321, 767, 528, 281, 362, 309, 8460, 512, 287, 267, 791, 11, 51526], "temperature": 0.0, "avg_logprob": -0.3080255452869008, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.010487545281648636}, {"id": 448, "seek": 174694, "start": 1770.18, "end": 1772.8200000000002, "text": " which are not exactly our data.", "tokens": [51526, 597, 366, 406, 2293, 527, 1412, 13, 51658], "temperature": 0.0, "avg_logprob": -0.3080255452869008, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.010487545281648636}, {"id": 449, "seek": 174694, "start": 1772.8200000000002, "end": 1775.06, "text": " They're around our data, but not exactly our data.", "tokens": [51658, 814, 434, 926, 527, 1412, 11, 457, 406, 2293, 527, 1412, 13, 51770], "temperature": 0.0, "avg_logprob": -0.3080255452869008, "compression_ratio": 1.7671232876712328, "no_speech_prob": 0.010487545281648636}, {"id": 450, "seek": 177506, "start": 1775.1799999999998, "end": 1781.78, "text": " And when it generates latents that are around our data, we want them to decode to the same", "tokens": [50370, 400, 562, 309, 23815, 4465, 791, 300, 366, 926, 527, 1412, 11, 321, 528, 552, 281, 979, 1429, 281, 264, 912, 50700], "temperature": 0.0, "avg_logprob": -0.24190480368477957, "compression_ratio": 1.7863247863247864, "no_speech_prob": 8.481094118906185e-05}, {"id": 451, "seek": 177506, "start": 1781.78, "end": 1782.78, "text": " thing.", "tokens": [50700, 551, 13, 50750], "temperature": 0.0, "avg_logprob": -0.24190480368477957, "compression_ratio": 1.7863247863247864, "no_speech_prob": 8.481094118906185e-05}, {"id": 452, "seek": 177506, "start": 1782.78, "end": 1785.06, "text": " We want them to decode to the correct image.", "tokens": [50750, 492, 528, 552, 281, 979, 1429, 281, 264, 3006, 3256, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24190480368477957, "compression_ratio": 1.7863247863247864, "no_speech_prob": 8.481094118906185e-05}, {"id": 453, "seek": 177506, "start": 1785.06, "end": 1790.1799999999998, "text": " And so as a result, if we can train that, right, something that it does include some", "tokens": [50864, 400, 370, 382, 257, 1874, 11, 498, 321, 393, 3847, 300, 11, 558, 11, 746, 300, 309, 775, 4090, 512, 51120], "temperature": 0.0, "avg_logprob": -0.24190480368477957, "compression_ratio": 1.7863247863247864, "no_speech_prob": 8.481094118906185e-05}, {"id": 454, "seek": 177506, "start": 1790.1799999999998, "end": 1797.3, "text": " variation and still decodes back to the original image, then we've created a much more robust", "tokens": [51120, 12990, 293, 920, 979, 4789, 646, 281, 264, 3380, 3256, 11, 550, 321, 600, 2942, 257, 709, 544, 13956, 51476], "temperature": 0.0, "avg_logprob": -0.24190480368477957, "compression_ratio": 1.7863247863247864, "no_speech_prob": 8.481094118906185e-05}, {"id": 455, "seek": 177506, "start": 1797.3, "end": 1798.34, "text": " model.", "tokens": [51476, 2316, 13, 51528], "temperature": 0.0, "avg_logprob": -0.24190480368477957, "compression_ratio": 1.7863247863247864, "no_speech_prob": 8.481094118906185e-05}, {"id": 456, "seek": 177506, "start": 1798.34, "end": 1803.82, "text": " And then that's something that we would hope then when we say, okay, well now decode some", "tokens": [51528, 400, 550, 300, 311, 746, 300, 321, 576, 1454, 550, 562, 321, 584, 11, 1392, 11, 731, 586, 979, 1429, 512, 51802], "temperature": 0.0, "avg_logprob": -0.24190480368477957, "compression_ratio": 1.7863247863247864, "no_speech_prob": 8.481094118906185e-05}, {"id": 457, "seek": 180382, "start": 1803.86, "end": 1808.34, "text": " noise, that it's going to decode to something better than this.", "tokens": [50366, 5658, 11, 300, 309, 311, 516, 281, 979, 1429, 281, 746, 1101, 813, 341, 13, 50590], "temperature": 0.0, "avg_logprob": -0.30627129498650046, "compression_ratio": 1.4414893617021276, "no_speech_prob": 2.546635914768558e-05}, {"id": 458, "seek": 180382, "start": 1808.34, "end": 1810.46, "text": " So that's the idea of a VAE.", "tokens": [50590, 407, 300, 311, 264, 1558, 295, 257, 18527, 36, 13, 50696], "temperature": 0.0, "avg_logprob": -0.30627129498650046, "compression_ratio": 1.4414893617021276, "no_speech_prob": 2.546635914768558e-05}, {"id": 459, "seek": 180382, "start": 1810.46, "end": 1821.74, "text": " So how do we get it to create a log variance, which doesn't just go to zero?", "tokens": [50696, 407, 577, 360, 321, 483, 309, 281, 1884, 257, 3565, 21977, 11, 597, 1177, 380, 445, 352, 281, 4018, 30, 51260], "temperature": 0.0, "avg_logprob": -0.30627129498650046, "compression_ratio": 1.4414893617021276, "no_speech_prob": 2.546635914768558e-05}, {"id": 460, "seek": 180382, "start": 1821.74, "end": 1824.8999999999999, "text": " Well we have a second loss term.", "tokens": [51260, 1042, 321, 362, 257, 1150, 4470, 1433, 13, 51418], "temperature": 0.0, "avg_logprob": -0.30627129498650046, "compression_ratio": 1.4414893617021276, "no_speech_prob": 2.546635914768558e-05}, {"id": 461, "seek": 180382, "start": 1824.8999999999999, "end": 1827.3, "text": " It's called the KL divergence loss.", "tokens": [51418, 467, 311, 1219, 264, 47991, 47387, 4470, 13, 51538], "temperature": 0.0, "avg_logprob": -0.30627129498650046, "compression_ratio": 1.4414893617021276, "no_speech_prob": 2.546635914768558e-05}, {"id": 462, "seek": 180382, "start": 1827.3, "end": 1829.34, "text": " We've got a key called KLD loss.", "tokens": [51538, 492, 600, 658, 257, 2141, 1219, 47991, 35, 4470, 13, 51640], "temperature": 0.0, "avg_logprob": -0.30627129498650046, "compression_ratio": 1.4414893617021276, "no_speech_prob": 2.546635914768558e-05}, {"id": 463, "seek": 182934, "start": 1829.34, "end": 1835.62, "text": " And what we're going to do is our VAE loss is going to take the binary cross entropy", "tokens": [50364, 400, 437, 321, 434, 516, 281, 360, 307, 527, 18527, 36, 4470, 307, 516, 281, 747, 264, 17434, 3278, 30867, 50678], "temperature": 0.0, "avg_logprob": -0.27154631363718135, "compression_ratio": 1.6157407407407407, "no_speech_prob": 0.0007208224851638079}, {"id": 464, "seek": 182934, "start": 1835.62, "end": 1843.54, "text": " between the actual decoded bit, so that's input zero, and the target.", "tokens": [50678, 1296, 264, 3539, 979, 12340, 857, 11, 370, 300, 311, 4846, 4018, 11, 293, 264, 3779, 13, 51074], "temperature": 0.0, "avg_logprob": -0.27154631363718135, "compression_ratio": 1.6157407407407407, "no_speech_prob": 0.0007208224851638079}, {"id": 465, "seek": 182934, "start": 1843.54, "end": 1848.4199999999998, "text": " Okay, so this is exactly the same as before, it's just binary cross entropy.", "tokens": [51074, 1033, 11, 370, 341, 307, 2293, 264, 912, 382, 949, 11, 309, 311, 445, 17434, 3278, 30867, 13, 51318], "temperature": 0.0, "avg_logprob": -0.27154631363718135, "compression_ratio": 1.6157407407407407, "no_speech_prob": 0.0007208224851638079}, {"id": 466, "seek": 182934, "start": 1848.4199999999998, "end": 1852.3, "text": " And we're going to add it to this KLD loss, KL divergence.", "tokens": [51318, 400, 321, 434, 516, 281, 909, 309, 281, 341, 47991, 35, 4470, 11, 47991, 47387, 13, 51512], "temperature": 0.0, "avg_logprob": -0.27154631363718135, "compression_ratio": 1.6157407407407407, "no_speech_prob": 0.0007208224851638079}, {"id": 467, "seek": 182934, "start": 1852.3, "end": 1855.98, "text": " Now KL divergence, the details don't matter terribly much.", "tokens": [51512, 823, 47991, 47387, 11, 264, 4365, 500, 380, 1871, 22903, 709, 13, 51696], "temperature": 0.0, "avg_logprob": -0.27154631363718135, "compression_ratio": 1.6157407407407407, "no_speech_prob": 0.0007208224851638079}, {"id": 468, "seek": 185598, "start": 1855.98, "end": 1861.34, "text": " What's important is when we look at the KLD loss, it's getting past the input and the", "tokens": [50364, 708, 311, 1021, 307, 562, 321, 574, 412, 264, 47991, 35, 4470, 11, 309, 311, 1242, 1791, 264, 4846, 293, 264, 50632], "temperature": 0.0, "avg_logprob": -0.24977520533970424, "compression_ratio": 1.6854460093896713, "no_speech_prob": 0.0011513871140778065}, {"id": 469, "seek": 185598, "start": 1861.34, "end": 1862.78, "text": " targets.", "tokens": [50632, 12911, 13, 50704], "temperature": 0.0, "avg_logprob": -0.24977520533970424, "compression_ratio": 1.6854460093896713, "no_speech_prob": 0.0011513871140778065}, {"id": 470, "seek": 185598, "start": 1862.78, "end": 1867.54, "text": " But if you look, it's not actually using the targets at all.", "tokens": [50704, 583, 498, 291, 574, 11, 309, 311, 406, 767, 1228, 264, 12911, 412, 439, 13, 50942], "temperature": 0.0, "avg_logprob": -0.24977520533970424, "compression_ratio": 1.6854460093896713, "no_speech_prob": 0.0011513871140778065}, {"id": 471, "seek": 185598, "start": 1867.54, "end": 1874.34, "text": " So if we pull out the input into its three pieces, which is our predicted image, our", "tokens": [50942, 407, 498, 321, 2235, 484, 264, 4846, 666, 1080, 1045, 3755, 11, 597, 307, 527, 19147, 3256, 11, 527, 51282], "temperature": 0.0, "avg_logprob": -0.24977520533970424, "compression_ratio": 1.6854460093896713, "no_speech_prob": 0.0011513871140778065}, {"id": 472, "seek": 185598, "start": 1874.34, "end": 1878.26, "text": " mu and our log variance, we don't use this either.", "tokens": [51282, 2992, 293, 527, 3565, 21977, 11, 321, 500, 380, 764, 341, 2139, 13, 51478], "temperature": 0.0, "avg_logprob": -0.24977520533970424, "compression_ratio": 1.6854460093896713, "no_speech_prob": 0.0011513871140778065}, {"id": 473, "seek": 185598, "start": 1878.26, "end": 1882.98, "text": " So the BCE loss only uses the predicted image and the actual image.", "tokens": [51478, 407, 264, 49369, 4470, 787, 4960, 264, 19147, 3256, 293, 264, 3539, 3256, 13, 51714], "temperature": 0.0, "avg_logprob": -0.24977520533970424, "compression_ratio": 1.6854460093896713, "no_speech_prob": 0.0011513871140778065}, {"id": 474, "seek": 188298, "start": 1882.98, "end": 1889.3600000000001, "text": " The KL divergence loss only uses mu and log variance.", "tokens": [50364, 440, 47991, 47387, 4470, 787, 4960, 2992, 293, 3565, 21977, 13, 50683], "temperature": 0.0, "avg_logprob": -0.2762660471598307, "compression_ratio": 1.441860465116279, "no_speech_prob": 2.392319765931461e-05}, {"id": 475, "seek": 188298, "start": 1889.3600000000001, "end": 1899.22, "text": " And all it does is it returns a number which says, for each item in the batch, is mu close", "tokens": [50683, 400, 439, 309, 775, 307, 309, 11247, 257, 1230, 597, 1619, 11, 337, 1184, 3174, 294, 264, 15245, 11, 307, 2992, 1998, 51176], "temperature": 0.0, "avg_logprob": -0.2762660471598307, "compression_ratio": 1.441860465116279, "no_speech_prob": 2.392319765931461e-05}, {"id": 476, "seek": 188298, "start": 1899.22, "end": 1903.6200000000001, "text": " to zero, and is log variance close to one.", "tokens": [51176, 281, 4018, 11, 293, 307, 3565, 21977, 1998, 281, 472, 13, 51396], "temperature": 0.0, "avg_logprob": -0.2762660471598307, "compression_ratio": 1.441860465116279, "no_speech_prob": 2.392319765931461e-05}, {"id": 477, "seek": 188298, "start": 1903.6200000000001, "end": 1905.06, "text": " How does it do that?", "tokens": [51396, 1012, 775, 309, 360, 300, 30, 51468], "temperature": 0.0, "avg_logprob": -0.2762660471598307, "compression_ratio": 1.441860465116279, "no_speech_prob": 2.392319765931461e-05}, {"id": 478, "seek": 188298, "start": 1905.06, "end": 1908.54, "text": " Well for mu it's very easy.", "tokens": [51468, 1042, 337, 2992, 309, 311, 588, 1858, 13, 51642], "temperature": 0.0, "avg_logprob": -0.2762660471598307, "compression_ratio": 1.441860465116279, "no_speech_prob": 2.392319765931461e-05}, {"id": 479, "seek": 188298, "start": 1908.54, "end": 1909.78, "text": " Mu squared.", "tokens": [51642, 15601, 8889, 13, 51704], "temperature": 0.0, "avg_logprob": -0.2762660471598307, "compression_ratio": 1.441860465116279, "no_speech_prob": 2.392319765931461e-05}, {"id": 480, "seek": 190978, "start": 1909.78, "end": 1915.34, "text": " So if mu is close to zero, then minimizing mu squared does exactly that, right?", "tokens": [50364, 407, 498, 2992, 307, 1998, 281, 4018, 11, 550, 46608, 2992, 8889, 775, 2293, 300, 11, 558, 30, 50642], "temperature": 0.0, "avg_logprob": -0.234921225186052, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00011959762196056545}, {"id": 481, "seek": 190978, "start": 1915.34, "end": 1918.06, "text": " If mu is one, then mu squared is one.", "tokens": [50642, 759, 2992, 307, 472, 11, 550, 2992, 8889, 307, 472, 13, 50778], "temperature": 0.0, "avg_logprob": -0.234921225186052, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00011959762196056545}, {"id": 482, "seek": 190978, "start": 1918.06, "end": 1921.02, "text": " If mu is minus one, mu squared is one.", "tokens": [50778, 759, 2992, 307, 3175, 472, 11, 2992, 8889, 307, 472, 13, 50926], "temperature": 0.0, "avg_logprob": -0.234921225186052, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00011959762196056545}, {"id": 483, "seek": 190978, "start": 1921.02, "end": 1923.3799999999999, "text": " If mu is zero, mu squared is zero.", "tokens": [50926, 759, 2992, 307, 4018, 11, 2992, 8889, 307, 4018, 13, 51044], "temperature": 0.0, "avg_logprob": -0.234921225186052, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00011959762196056545}, {"id": 484, "seek": 190978, "start": 1923.3799999999999, "end": 1928.54, "text": " That's the lowest you can get for a squared.", "tokens": [51044, 663, 311, 264, 12437, 291, 393, 483, 337, 257, 8889, 13, 51302], "temperature": 0.0, "avg_logprob": -0.234921225186052, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00011959762196056545}, {"id": 485, "seek": 190978, "start": 1928.54, "end": 1934.5, "text": " Okay so we've got a mu squared piece here.", "tokens": [51302, 1033, 370, 321, 600, 658, 257, 2992, 8889, 2522, 510, 13, 51600], "temperature": 0.0, "avg_logprob": -0.234921225186052, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00011959762196056545}, {"id": 486, "seek": 190978, "start": 1934.5, "end": 1937.78, "text": " And we've got a dot mean, so we're just taking, that's just basically taking the mean of all", "tokens": [51600, 400, 321, 600, 658, 257, 5893, 914, 11, 370, 321, 434, 445, 1940, 11, 300, 311, 445, 1936, 1940, 264, 914, 295, 439, 51764], "temperature": 0.0, "avg_logprob": -0.234921225186052, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00011959762196056545}, {"id": 487, "seek": 190978, "start": 1937.78, "end": 1939.1, "text": " the mus.", "tokens": [51764, 264, 1038, 13, 51830], "temperature": 0.0, "avg_logprob": -0.234921225186052, "compression_ratio": 1.8317307692307692, "no_speech_prob": 0.00011959762196056545}, {"id": 488, "seek": 193910, "start": 1939.1, "end": 1946.3, "text": " And then there's another piece, which is we've got log variance minus e to the power of log", "tokens": [50364, 400, 550, 456, 311, 1071, 2522, 11, 597, 307, 321, 600, 658, 3565, 21977, 3175, 308, 281, 264, 1347, 295, 3565, 50724], "temperature": 0.0, "avg_logprob": -0.27562058188698507, "compression_ratio": 1.7092511013215859, "no_speech_prob": 1.012993379845284e-05}, {"id": 489, "seek": 193910, "start": 1946.3, "end": 1949.02, "text": " variance.", "tokens": [50724, 21977, 13, 50860], "temperature": 0.0, "avg_logprob": -0.27562058188698507, "compression_ratio": 1.7092511013215859, "no_speech_prob": 1.012993379845284e-05}, {"id": 490, "seek": 193910, "start": 1949.02, "end": 1955.62, "text": " So if we look at that, so let's just grab a bunch of numbers between neg three and three,", "tokens": [50860, 407, 498, 321, 574, 412, 300, 11, 370, 718, 311, 445, 4444, 257, 3840, 295, 3547, 1296, 2485, 1045, 293, 1045, 11, 51190], "temperature": 0.0, "avg_logprob": -0.27562058188698507, "compression_ratio": 1.7092511013215859, "no_speech_prob": 1.012993379845284e-05}, {"id": 491, "seek": 193910, "start": 1955.62, "end": 1958.82, "text": " and do number minus e to the power of that number.", "tokens": [51190, 293, 360, 1230, 3175, 308, 281, 264, 1347, 295, 300, 1230, 13, 51350], "temperature": 0.0, "avg_logprob": -0.27562058188698507, "compression_ratio": 1.7092511013215859, "no_speech_prob": 1.012993379845284e-05}, {"id": 492, "seek": 193910, "start": 1958.82, "end": 1963.1799999999998, "text": " And I'm just going to pop in the one plus and the point five times as well, they don't", "tokens": [51350, 400, 286, 478, 445, 516, 281, 1665, 294, 264, 472, 1804, 293, 264, 935, 1732, 1413, 382, 731, 11, 436, 500, 380, 51568], "temperature": 0.0, "avg_logprob": -0.27562058188698507, "compression_ratio": 1.7092511013215859, "no_speech_prob": 1.012993379845284e-05}, {"id": 493, "seek": 193910, "start": 1963.1799999999998, "end": 1964.1799999999998, "text": " matter much.", "tokens": [51568, 1871, 709, 13, 51618], "temperature": 0.0, "avg_logprob": -0.27562058188698507, "compression_ratio": 1.7092511013215859, "no_speech_prob": 1.012993379845284e-05}, {"id": 494, "seek": 193910, "start": 1964.1799999999998, "end": 1967.62, "text": " And you can see that's got a minimum of zero.", "tokens": [51618, 400, 291, 393, 536, 300, 311, 658, 257, 7285, 295, 4018, 13, 51790], "temperature": 0.0, "avg_logprob": -0.27562058188698507, "compression_ratio": 1.7092511013215859, "no_speech_prob": 1.012993379845284e-05}, {"id": 495, "seek": 196762, "start": 1967.62, "end": 1974.1799999999998, "text": " So when that's a minimum of zero, e to the power of that, which is what we're going to", "tokens": [50364, 407, 562, 300, 311, 257, 7285, 295, 4018, 11, 308, 281, 264, 1347, 295, 300, 11, 597, 307, 437, 321, 434, 516, 281, 50692], "temperature": 0.0, "avg_logprob": -0.18246187482561385, "compression_ratio": 1.9256756756756757, "no_speech_prob": 4.1986255382653326e-05}, {"id": 496, "seek": 196762, "start": 1974.1799999999998, "end": 1978.9399999999998, "text": " be using, actually half times e to the power of that, but that's okay, is what we're going", "tokens": [50692, 312, 1228, 11, 767, 1922, 1413, 308, 281, 264, 1347, 295, 300, 11, 457, 300, 311, 1392, 11, 307, 437, 321, 434, 516, 50930], "temperature": 0.0, "avg_logprob": -0.18246187482561385, "compression_ratio": 1.9256756756756757, "no_speech_prob": 4.1986255382653326e-05}, {"id": 497, "seek": 196762, "start": 1978.9399999999998, "end": 1985.4199999999998, "text": " to be using in our dot forward method.", "tokens": [50930, 281, 312, 1228, 294, 527, 5893, 2128, 3170, 13, 51254], "temperature": 0.0, "avg_logprob": -0.18246187482561385, "compression_ratio": 1.9256756756756757, "no_speech_prob": 4.1986255382653326e-05}, {"id": 498, "seek": 196762, "start": 1985.4199999999998, "end": 1990.2199999999998, "text": " That's going to be e to the power of zero, which is going to be one.", "tokens": [51254, 663, 311, 516, 281, 312, 308, 281, 264, 1347, 295, 4018, 11, 597, 307, 516, 281, 312, 472, 13, 51494], "temperature": 0.0, "avg_logprob": -0.18246187482561385, "compression_ratio": 1.9256756756756757, "no_speech_prob": 4.1986255382653326e-05}, {"id": 499, "seek": 199022, "start": 1990.22, "end": 1999.66, "text": " So this is going to be minimized, where log variance exp equals one.", "tokens": [50364, 407, 341, 307, 516, 281, 312, 4464, 1602, 11, 689, 3565, 21977, 1278, 6915, 472, 13, 50836], "temperature": 0.0, "avg_logprob": -0.24454841017723083, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0014549390180036426}, {"id": 500, "seek": 199022, "start": 1999.66, "end": 2007.58, "text": " So therefore this whole piece here will be minimized when mu is zero, and LV is also", "tokens": [50836, 407, 4412, 341, 1379, 2522, 510, 486, 312, 4464, 1602, 562, 2992, 307, 4018, 11, 293, 441, 53, 307, 611, 51232], "temperature": 0.0, "avg_logprob": -0.24454841017723083, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0014549390180036426}, {"id": 501, "seek": 199022, "start": 2007.58, "end": 2010.7, "text": " zero.", "tokens": [51232, 4018, 13, 51388], "temperature": 0.0, "avg_logprob": -0.24454841017723083, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0014549390180036426}, {"id": 502, "seek": 199022, "start": 2010.7, "end": 2014.46, "text": " And so therefore LV, e to the power of LV is one.", "tokens": [51388, 400, 370, 4412, 441, 53, 11, 308, 281, 264, 1347, 295, 441, 53, 307, 472, 13, 51576], "temperature": 0.0, "avg_logprob": -0.24454841017723083, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0014549390180036426}, {"id": 503, "seek": 201446, "start": 2014.46, "end": 2024.14, "text": " Now the reason that it's specifically this form is basically because there's a specific", "tokens": [50364, 823, 264, 1778, 300, 309, 311, 4682, 341, 1254, 307, 1936, 570, 456, 311, 257, 2685, 50848], "temperature": 0.0, "avg_logprob": -0.3064500172932943, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.004398964811116457}, {"id": 504, "seek": 201446, "start": 2024.14, "end": 2030.9, "text": " mathematical thing called the KL divergence, which compares how similar two distributions", "tokens": [50848, 18894, 551, 1219, 264, 47991, 47387, 11, 597, 38334, 577, 2531, 732, 37870, 51186], "temperature": 0.0, "avg_logprob": -0.3064500172932943, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.004398964811116457}, {"id": 505, "seek": 201446, "start": 2030.9, "end": 2031.9, "text": " are.", "tokens": [51186, 366, 13, 51236], "temperature": 0.0, "avg_logprob": -0.3064500172932943, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.004398964811116457}, {"id": 506, "seek": 201446, "start": 2031.9, "end": 2037.16, "text": " And so a normal distribution can be fully characterized by its mean and its variance.", "tokens": [51236, 400, 370, 257, 2710, 7316, 393, 312, 4498, 29361, 538, 1080, 914, 293, 1080, 21977, 13, 51499], "temperature": 0.0, "avg_logprob": -0.3064500172932943, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.004398964811116457}, {"id": 507, "seek": 201446, "start": 2037.16, "end": 2044.42, "text": " And so this is actually more precisely calculating the similarity, specifically the KL divergence.", "tokens": [51499, 400, 370, 341, 307, 767, 544, 13402, 28258, 264, 32194, 11, 4682, 264, 47991, 47387, 13, 51862], "temperature": 0.0, "avg_logprob": -0.3064500172932943, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.004398964811116457}, {"id": 508, "seek": 204442, "start": 2044.5800000000002, "end": 2052.5, "text": " Between the actual mu and LV that we have, and a distribution with a mean of zero and", "tokens": [50372, 18967, 264, 3539, 2992, 293, 441, 53, 300, 321, 362, 11, 293, 257, 7316, 365, 257, 914, 295, 4018, 293, 50768], "temperature": 0.0, "avg_logprob": -0.2993920355132132, "compression_ratio": 1.5, "no_speech_prob": 2.014566052821465e-05}, {"id": 509, "seek": 204442, "start": 2052.5, "end": 2056.58, "text": " a variance of one.", "tokens": [50768, 257, 21977, 295, 472, 13, 50972], "temperature": 0.0, "avg_logprob": -0.2993920355132132, "compression_ratio": 1.5, "no_speech_prob": 2.014566052821465e-05}, {"id": 510, "seek": 204442, "start": 2056.58, "end": 2062.46, "text": " But you can see hopefully why conceptually we have this mu dot power two, and why we", "tokens": [50972, 583, 291, 393, 536, 4696, 983, 3410, 671, 321, 362, 341, 2992, 5893, 3388, 260, 732, 11, 293, 983, 321, 51266], "temperature": 0.0, "avg_logprob": -0.2993920355132132, "compression_ratio": 1.5, "no_speech_prob": 2.014566052821465e-05}, {"id": 511, "seek": 204442, "start": 2062.46, "end": 2071.34, "text": " have this LV minus LV dot exp here.", "tokens": [51266, 362, 341, 441, 53, 3175, 441, 53, 5893, 1278, 510, 13, 51710], "temperature": 0.0, "avg_logprob": -0.2993920355132132, "compression_ratio": 1.5, "no_speech_prob": 2.014566052821465e-05}, {"id": 512, "seek": 207134, "start": 2071.34, "end": 2075.1000000000004, "text": " So that is our VAE loss.", "tokens": [50364, 407, 300, 307, 527, 18527, 36, 4470, 13, 50552], "temperature": 0.0, "avg_logprob": -0.2490018844604492, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.06462918221950531}, {"id": 513, "seek": 207134, "start": 2075.1000000000004, "end": 2080.86, "text": " Did you guys have anything to add to any of that description?", "tokens": [50552, 2589, 291, 1074, 362, 1340, 281, 909, 281, 604, 295, 300, 3855, 30, 50840], "temperature": 0.0, "avg_logprob": -0.2490018844604492, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.06462918221950531}, {"id": 514, "seek": 207134, "start": 2080.86, "end": 2085.82, "text": " So maybe to highlight the objective of this is to say, rather than having it so that the", "tokens": [50840, 407, 1310, 281, 5078, 264, 10024, 295, 341, 307, 281, 584, 11, 2831, 813, 1419, 309, 370, 300, 264, 51088], "temperature": 0.0, "avg_logprob": -0.2490018844604492, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.06462918221950531}, {"id": 515, "seek": 207134, "start": 2085.82, "end": 2092.82, "text": " exact point that an input is encoded to decodes back to that input, we're saying number one,", "tokens": [51088, 1900, 935, 300, 364, 4846, 307, 2058, 12340, 281, 979, 4789, 646, 281, 300, 4846, 11, 321, 434, 1566, 1230, 472, 11, 51438], "temperature": 0.0, "avg_logprob": -0.2490018844604492, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.06462918221950531}, {"id": 516, "seek": 207134, "start": 2092.82, "end": 2096.34, "text": " the space around that point should also decode to that input, because we're going to try", "tokens": [51438, 264, 1901, 926, 300, 935, 820, 611, 979, 1429, 281, 300, 4846, 11, 570, 321, 434, 516, 281, 853, 51614], "temperature": 0.0, "avg_logprob": -0.2490018844604492, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.06462918221950531}, {"id": 517, "seek": 207134, "start": 2096.34, "end": 2097.34, "text": " and force some variance.", "tokens": [51614, 293, 3464, 512, 21977, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2490018844604492, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.06462918221950531}, {"id": 518, "seek": 209734, "start": 2097.86, "end": 2104.42, "text": " And number two, the overall variance should be like, yeah, the overall space that it uses", "tokens": [50390, 400, 1230, 732, 11, 264, 4787, 21977, 820, 312, 411, 11, 1338, 11, 264, 4787, 1901, 300, 309, 4960, 50718], "temperature": 0.0, "avg_logprob": -0.29493549382575207, "compression_ratio": 1.743083003952569, "no_speech_prob": 0.2041953206062317}, {"id": 519, "seek": 209734, "start": 2104.42, "end": 2109.06, "text": " should be roughly zero mean and units and variance.", "tokens": [50718, 820, 312, 9810, 4018, 914, 293, 6815, 293, 21977, 13, 50950], "temperature": 0.0, "avg_logprob": -0.29493549382575207, "compression_ratio": 1.743083003952569, "no_speech_prob": 0.2041953206062317}, {"id": 520, "seek": 209734, "start": 2109.06, "end": 2113.42, "text": " So instead of being able to map each input to an arbitrary point and then decode only", "tokens": [50950, 407, 2602, 295, 885, 1075, 281, 4471, 1184, 4846, 281, 364, 23211, 935, 293, 550, 979, 1429, 787, 51168], "temperature": 0.0, "avg_logprob": -0.29493549382575207, "compression_ratio": 1.743083003952569, "no_speech_prob": 0.2041953206062317}, {"id": 521, "seek": 209734, "start": 2113.42, "end": 2117.54, "text": " that exact point to an input, we're now mapping them to a restricted range.", "tokens": [51168, 300, 1900, 935, 281, 364, 4846, 11, 321, 434, 586, 18350, 552, 281, 257, 20608, 3613, 13, 51374], "temperature": 0.0, "avg_logprob": -0.29493549382575207, "compression_ratio": 1.743083003952569, "no_speech_prob": 0.2041953206062317}, {"id": 522, "seek": 209734, "start": 2117.54, "end": 2121.58, "text": " And we're saying that not just each point, but its surroundings as well, should also", "tokens": [51374, 400, 321, 434, 1566, 300, 406, 445, 1184, 935, 11, 457, 1080, 25314, 382, 731, 11, 820, 611, 51576], "temperature": 0.0, "avg_logprob": -0.29493549382575207, "compression_ratio": 1.743083003952569, "no_speech_prob": 0.2041953206062317}, {"id": 523, "seek": 209734, "start": 2121.58, "end": 2125.06, "text": " decode back to something that looks like that image.", "tokens": [51576, 979, 1429, 646, 281, 746, 300, 1542, 411, 300, 3256, 13, 51750], "temperature": 0.0, "avg_logprob": -0.29493549382575207, "compression_ratio": 1.743083003952569, "no_speech_prob": 0.2041953206062317}, {"id": 524, "seek": 212506, "start": 2125.06, "end": 2129.2999999999997, "text": " And that's trying to condition this latent space to be much nicer so that any arbitrary", "tokens": [50364, 400, 300, 311, 1382, 281, 4188, 341, 48994, 1901, 281, 312, 709, 22842, 370, 300, 604, 23211, 50576], "temperature": 0.0, "avg_logprob": -0.23033498462877774, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.016401922330260277}, {"id": 525, "seek": 212506, "start": 2129.2999999999997, "end": 2134.62, "text": " point within that range will hopefully map to something useful.", "tokens": [50576, 935, 1951, 300, 3613, 486, 4696, 4471, 281, 746, 4420, 13, 50842], "temperature": 0.0, "avg_logprob": -0.23033498462877774, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.016401922330260277}, {"id": 526, "seek": 212506, "start": 2134.62, "end": 2136.7, "text": " Which is a harder problem to solve, right?", "tokens": [50842, 3013, 307, 257, 6081, 1154, 281, 5039, 11, 558, 30, 50946], "temperature": 0.0, "avg_logprob": -0.23033498462877774, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.016401922330260277}, {"id": 527, "seek": 212506, "start": 2136.7, "end": 2141.74, "text": " So we would expect, given that this is exactly the same architecture, we would expect its", "tokens": [50946, 407, 321, 576, 2066, 11, 2212, 300, 341, 307, 2293, 264, 912, 9482, 11, 321, 576, 2066, 1080, 51198], "temperature": 0.0, "avg_logprob": -0.23033498462877774, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.016401922330260277}, {"id": 528, "seek": 212506, "start": 2141.74, "end": 2149.22, "text": " ability to actually decode would be worse than our previous attempt, because it's a", "tokens": [51198, 3485, 281, 767, 979, 1429, 576, 312, 5324, 813, 527, 3894, 5217, 11, 570, 309, 311, 257, 51572], "temperature": 0.0, "avg_logprob": -0.23033498462877774, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.016401922330260277}, {"id": 529, "seek": 212506, "start": 2149.22, "end": 2152.54, "text": " harder problem that we're trying to solve, which is to just, we've got random numbers", "tokens": [51572, 6081, 1154, 300, 321, 434, 1382, 281, 5039, 11, 597, 307, 281, 445, 11, 321, 600, 658, 4974, 3547, 51738], "temperature": 0.0, "avg_logprob": -0.23033498462877774, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.016401922330260277}, {"id": 530, "seek": 212506, "start": 2152.54, "end": 2153.54, "text": " in there as well now.", "tokens": [51738, 294, 456, 382, 731, 586, 13, 51788], "temperature": 0.0, "avg_logprob": -0.23033498462877774, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.016401922330260277}, {"id": 531, "seek": 215354, "start": 2154.02, "end": 2157.82, "text": " We're hoping that this ability to generate images will improve.", "tokens": [50388, 492, 434, 7159, 300, 341, 3485, 281, 8460, 5267, 486, 3470, 13, 50578], "temperature": 0.0, "avg_logprob": -0.3322552738026676, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0001686498726485297}, {"id": 532, "seek": 215354, "start": 2157.82, "end": 2160.46, "text": " Thanks, Jono.", "tokens": [50578, 2561, 11, 7745, 78, 13, 50710], "temperature": 0.0, "avg_logprob": -0.3322552738026676, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0001686498726485297}, {"id": 533, "seek": 215354, "start": 2160.46, "end": 2167.7799999999997, "text": " Okay, so I actually asked Bing about this.", "tokens": [50710, 1033, 11, 370, 286, 767, 2351, 30755, 466, 341, 13, 51076], "temperature": 0.0, "avg_logprob": -0.3322552738026676, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0001686498726485297}, {"id": 534, "seek": 215354, "start": 2167.7799999999997, "end": 2172.74, "text": " This is more of an example of like, I think for, you know, now that we've got GPT-4 and", "tokens": [51076, 639, 307, 544, 295, 364, 1365, 295, 411, 11, 286, 519, 337, 11, 291, 458, 11, 586, 300, 321, 600, 658, 26039, 51, 12, 19, 293, 51324], "temperature": 0.0, "avg_logprob": -0.3322552738026676, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0001686498726485297}, {"id": 535, "seek": 215354, "start": 2172.74, "end": 2177.7, "text": " Bing and stuff, I find they're pretty good at answering questions that, like, I wanted", "tokens": [51324, 30755, 293, 1507, 11, 286, 915, 436, 434, 1238, 665, 412, 13430, 1651, 300, 11, 411, 11, 286, 1415, 51572], "temperature": 0.0, "avg_logprob": -0.3322552738026676, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0001686498726485297}, {"id": 536, "seek": 215354, "start": 2177.7, "end": 2179.46, "text": " to explain to students.", "tokens": [51572, 281, 2903, 281, 1731, 13, 51660], "temperature": 0.0, "avg_logprob": -0.3322552738026676, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0001686498726485297}, {"id": 537, "seek": 215354, "start": 2179.46, "end": 2181.7799999999997, "text": " What would happen if the variance of the latents was very low?", "tokens": [51660, 708, 576, 1051, 498, 264, 21977, 295, 264, 4465, 791, 390, 588, 2295, 30, 51776], "temperature": 0.0, "avg_logprob": -0.3322552738026676, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0001686498726485297}, {"id": 538, "seek": 215354, "start": 2181.7799999999997, "end": 2183.16, "text": " Or what if they were very high?", "tokens": [51776, 1610, 437, 498, 436, 645, 588, 1090, 30, 51845], "temperature": 0.0, "avg_logprob": -0.3322552738026676, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0001686498726485297}, {"id": 539, "seek": 218316, "start": 2183.7799999999997, "end": 2184.7799999999997, "text": " So why do we want them to be one?", "tokens": [50395, 407, 983, 360, 321, 528, 552, 281, 312, 472, 30, 50445], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 540, "seek": 218316, "start": 2184.7799999999997, "end": 2187.2799999999997, "text": " And I thought, like, oh gosh, this is hard to explain.", "tokens": [50445, 400, 286, 1194, 11, 411, 11, 1954, 6502, 11, 341, 307, 1152, 281, 2903, 13, 50570], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 541, "seek": 218316, "start": 2187.2799999999997, "end": 2189.8399999999997, "text": " So maybe Bing can help.", "tokens": [50570, 407, 1310, 30755, 393, 854, 13, 50698], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 542, "seek": 218316, "start": 2189.8399999999997, "end": 2191.16, "text": " So I actually thought it was pretty good.", "tokens": [50698, 407, 286, 767, 1194, 309, 390, 1238, 665, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 543, "seek": 218316, "start": 2191.16, "end": 2192.3199999999997, "text": " So I'll just say what Bing said.", "tokens": [50764, 407, 286, 603, 445, 584, 437, 30755, 848, 13, 50822], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 544, "seek": 218316, "start": 2192.3199999999997, "end": 2198.0, "text": " So Bing says if the variance of the latents are very low, then the encoder distribution", "tokens": [50822, 407, 30755, 1619, 498, 264, 21977, 295, 264, 4465, 791, 366, 588, 2295, 11, 550, 264, 2058, 19866, 7316, 51106], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 545, "seek": 218316, "start": 2198.0, "end": 2201.8399999999997, "text": " would be very peaked and concentrated around the mean.", "tokens": [51106, 576, 312, 588, 520, 7301, 293, 21321, 926, 264, 914, 13, 51298], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 546, "seek": 218316, "start": 2201.8399999999997, "end": 2203.3999999999996, "text": " So that was the thing we were describing earlier.", "tokens": [51298, 407, 300, 390, 264, 551, 321, 645, 16141, 3071, 13, 51376], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 547, "seek": 218316, "start": 2203.3999999999996, "end": 2208.48, "text": " If we had trained this without the KLD loss at all, right, it would probably make the", "tokens": [51376, 759, 321, 632, 8895, 341, 1553, 264, 47991, 35, 4470, 412, 439, 11, 558, 11, 309, 576, 1391, 652, 264, 51630], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 548, "seek": 218316, "start": 2208.48, "end": 2210.56, "text": " variance zero.", "tokens": [51630, 21977, 4018, 13, 51734], "temperature": 0.0, "avg_logprob": -0.2860761044630364, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.001622918527573347}, {"id": 549, "seek": 221056, "start": 2210.56, "end": 2214.0, "text": " And so therefore the latent space would be less diverse and expressive and limit the", "tokens": [50364, 400, 370, 4412, 264, 48994, 1901, 576, 312, 1570, 9521, 293, 40189, 293, 4948, 264, 50536], "temperature": 0.0, "avg_logprob": -0.2675644987720554, "compression_ratio": 1.8264150943396227, "no_speech_prob": 9.028005297295749e-05}, {"id": 550, "seek": 221056, "start": 2214.0, "end": 2218.6, "text": " ability of the decoder to reconstruct the data accurately, make it harder to generate", "tokens": [50536, 3485, 295, 264, 979, 19866, 281, 31499, 264, 1412, 20095, 11, 652, 309, 6081, 281, 8460, 50766], "temperature": 0.0, "avg_logprob": -0.2675644987720554, "compression_ratio": 1.8264150943396227, "no_speech_prob": 9.028005297295749e-05}, {"id": 551, "seek": 221056, "start": 2218.6, "end": 2223.0, "text": " new data that's different from the training data, which is exactly what we're trying to", "tokens": [50766, 777, 1412, 300, 311, 819, 490, 264, 3097, 1412, 11, 597, 307, 2293, 437, 321, 434, 1382, 281, 50986], "temperature": 0.0, "avg_logprob": -0.2675644987720554, "compression_ratio": 1.8264150943396227, "no_speech_prob": 9.028005297295749e-05}, {"id": 552, "seek": 221056, "start": 2223.0, "end": 2224.44, "text": " do.", "tokens": [50986, 360, 13, 51058], "temperature": 0.0, "avg_logprob": -0.2675644987720554, "compression_ratio": 1.8264150943396227, "no_speech_prob": 9.028005297295749e-05}, {"id": 553, "seek": 221056, "start": 2224.44, "end": 2229.44, "text": " And if the variance is very high, then the encoder would be very spread out and diffuse.", "tokens": [51058, 400, 498, 264, 21977, 307, 588, 1090, 11, 550, 264, 2058, 19866, 576, 312, 588, 3974, 484, 293, 42165, 13, 51308], "temperature": 0.0, "avg_logprob": -0.2675644987720554, "compression_ratio": 1.8264150943396227, "no_speech_prob": 9.028005297295749e-05}, {"id": 554, "seek": 221056, "start": 2229.44, "end": 2235.88, "text": " It would be more, the latents would be more noisy and random.", "tokens": [51308, 467, 576, 312, 544, 11, 264, 4465, 791, 576, 312, 544, 24518, 293, 4974, 13, 51630], "temperature": 0.0, "avg_logprob": -0.2675644987720554, "compression_ratio": 1.8264150943396227, "no_speech_prob": 9.028005297295749e-05}, {"id": 555, "seek": 221056, "start": 2235.88, "end": 2239.84, "text": " Make it easier to generate new data that's unrealistic or nonsensical.", "tokens": [51630, 4387, 309, 3571, 281, 8460, 777, 1412, 300, 311, 42867, 420, 297, 892, 694, 804, 13, 51828], "temperature": 0.0, "avg_logprob": -0.2675644987720554, "compression_ratio": 1.8264150943396227, "no_speech_prob": 9.028005297295749e-05}, {"id": 556, "seek": 223984, "start": 2240.1200000000003, "end": 2241.1200000000003, "text": " Okay.", "tokens": [50378, 1033, 13, 50428], "temperature": 0.0, "avg_logprob": -0.2484028490283821, "compression_ratio": 1.5025906735751295, "no_speech_prob": 1.4063995877222624e-05}, {"id": 557, "seek": 223984, "start": 2241.1200000000003, "end": 2245.48, "text": " So that's why we want it to be exactly at a particular point.", "tokens": [50428, 407, 300, 311, 983, 321, 528, 309, 281, 312, 2293, 412, 257, 1729, 935, 13, 50646], "temperature": 0.0, "avg_logprob": -0.2484028490283821, "compression_ratio": 1.5025906735751295, "no_speech_prob": 1.4063995877222624e-05}, {"id": 558, "seek": 223984, "start": 2245.48, "end": 2251.6000000000004, "text": " So when we train this, we can just pass VAE loss as our loss function, but it'd be nice", "tokens": [50646, 407, 562, 321, 3847, 341, 11, 321, 393, 445, 1320, 18527, 36, 4470, 382, 527, 4470, 2445, 11, 457, 309, 1116, 312, 1481, 50952], "temperature": 0.0, "avg_logprob": -0.2484028490283821, "compression_ratio": 1.5025906735751295, "no_speech_prob": 1.4063995877222624e-05}, {"id": 559, "seek": 223984, "start": 2251.6000000000004, "end": 2257.8, "text": " to see how well it's going at reconstructing the original image and how it's going at creating", "tokens": [50952, 281, 536, 577, 731, 309, 311, 516, 412, 31499, 278, 264, 3380, 3256, 293, 577, 309, 311, 516, 412, 4084, 51262], "temperature": 0.0, "avg_logprob": -0.2484028490283821, "compression_ratio": 1.5025906735751295, "no_speech_prob": 1.4063995877222624e-05}, {"id": 560, "seek": 223984, "start": 2257.8, "end": 2264.04, "text": " zero, one distribution data separately.", "tokens": [51262, 4018, 11, 472, 7316, 1412, 14759, 13, 51574], "temperature": 0.0, "avg_logprob": -0.2484028490283821, "compression_ratio": 1.5025906735751295, "no_speech_prob": 1.4063995877222624e-05}, {"id": 561, "seek": 226404, "start": 2264.04, "end": 2270.96, "text": " So what I ended up doing was creating just a really simple thing called func metric,", "tokens": [50364, 407, 437, 286, 4590, 493, 884, 390, 4084, 445, 257, 534, 2199, 551, 1219, 1019, 66, 20678, 11, 50710], "temperature": 0.0, "avg_logprob": -0.3370099597507053, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.008981214836239815}, {"id": 562, "seek": 226404, "start": 2270.96, "end": 2283.12, "text": " which I derived from the capital M mean class in the Torch, just trying to find it here,", "tokens": [50710, 597, 286, 18949, 490, 264, 4238, 376, 914, 1508, 294, 264, 7160, 339, 11, 445, 1382, 281, 915, 309, 510, 11, 51318], "temperature": 0.0, "avg_logprob": -0.3370099597507053, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.008981214836239815}, {"id": 563, "seek": 226404, "start": 2283.12, "end": 2286.48, "text": " from the Torch eval.metrics.", "tokens": [51318, 490, 264, 7160, 339, 1073, 304, 13, 5537, 10716, 13, 51486], "temperature": 0.0, "avg_logprob": -0.3370099597507053, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.008981214836239815}, {"id": 564, "seek": 226404, "start": 2286.48, "end": 2289.08, "text": " So they've already got something that can just calculate means.", "tokens": [51486, 407, 436, 600, 1217, 658, 746, 300, 393, 445, 8873, 1355, 13, 51616], "temperature": 0.0, "avg_logprob": -0.3370099597507053, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.008981214836239815}, {"id": 565, "seek": 226404, "start": 2289.08, "end": 2292.84, "text": " So obviously this stuff's all very simple and we've created our own metrics class ourselves", "tokens": [51616, 407, 2745, 341, 1507, 311, 439, 588, 2199, 293, 321, 600, 2942, 527, 1065, 16367, 1508, 4175, 51804], "temperature": 0.0, "avg_logprob": -0.3370099597507053, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.008981214836239815}, {"id": 566, "seek": 229284, "start": 2292.84, "end": 2293.84, "text": " back a while ago.", "tokens": [50364, 646, 257, 1339, 2057, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2710357205621127, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.0003920298768207431}, {"id": 567, "seek": 229284, "start": 2293.84, "end": 2298.2400000000002, "text": " But since we're using Torch eval, I thought this is useful to see how we can create one,", "tokens": [50414, 583, 1670, 321, 434, 1228, 7160, 339, 1073, 304, 11, 286, 1194, 341, 307, 4420, 281, 536, 577, 321, 393, 1884, 472, 11, 50634], "temperature": 0.0, "avg_logprob": -0.2710357205621127, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.0003920298768207431}, {"id": 568, "seek": 229284, "start": 2298.2400000000002, "end": 2303.56, "text": " a custom metric where you can pass in some function to call before it calculates the", "tokens": [50634, 257, 2375, 20678, 689, 291, 393, 1320, 294, 512, 2445, 281, 818, 949, 309, 4322, 1024, 264, 50900], "temperature": 0.0, "avg_logprob": -0.2710357205621127, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.0003920298768207431}, {"id": 569, "seek": 229284, "start": 2303.56, "end": 2304.8, "text": " mean.", "tokens": [50900, 914, 13, 50962], "temperature": 0.0, "avg_logprob": -0.2710357205621127, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.0003920298768207431}, {"id": 570, "seek": 229284, "start": 2304.8, "end": 2310.48, "text": " So if you call, so you might remember that the way Torch eval works is it has this thing", "tokens": [50962, 407, 498, 291, 818, 11, 370, 291, 1062, 1604, 300, 264, 636, 7160, 339, 1073, 304, 1985, 307, 309, 575, 341, 551, 51246], "temperature": 0.0, "avg_logprob": -0.2710357205621127, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.0003920298768207431}, {"id": 571, "seek": 229284, "start": 2310.48, "end": 2314.08, "text": " called update, which gets past the input and the targets.", "tokens": [51246, 1219, 5623, 11, 597, 2170, 1791, 264, 4846, 293, 264, 12911, 13, 51426], "temperature": 0.0, "avg_logprob": -0.2710357205621127, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.0003920298768207431}, {"id": 572, "seek": 229284, "start": 2314.08, "end": 2319.84, "text": " So I add to the weighted sum, the result of calling some function on the input and the", "tokens": [51426, 407, 286, 909, 281, 264, 32807, 2408, 11, 264, 1874, 295, 5141, 512, 2445, 322, 264, 4846, 293, 264, 51714], "temperature": 0.0, "avg_logprob": -0.2710357205621127, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.0003920298768207431}, {"id": 573, "seek": 231984, "start": 2319.84, "end": 2323.2000000000003, "text": " targets.", "tokens": [50364, 12911, 13, 50532], "temperature": 0.0, "avg_logprob": -0.2986548706725404, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0009107307414524257}, {"id": 574, "seek": 231984, "start": 2323.2000000000003, "end": 2327.4, "text": " So we want two kind of new metrics.", "tokens": [50532, 407, 321, 528, 732, 733, 295, 777, 16367, 13, 50742], "temperature": 0.0, "avg_logprob": -0.2986548706725404, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0009107307414524257}, {"id": 575, "seek": 231984, "start": 2327.4, "end": 2333.6800000000003, "text": " One is the, we're going to print it out as KLD, which is a func metric on KLD loss.", "tokens": [50742, 1485, 307, 264, 11, 321, 434, 516, 281, 4482, 309, 484, 382, 47991, 35, 11, 597, 307, 257, 1019, 66, 20678, 322, 47991, 35, 4470, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2986548706725404, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0009107307414524257}, {"id": 576, "seek": 231984, "start": 2333.6800000000003, "end": 2340.7000000000003, "text": " And one which we'll print out as BCE, which is a func metric on BCE loss.", "tokens": [51056, 400, 472, 597, 321, 603, 4482, 484, 382, 49369, 11, 597, 307, 257, 1019, 66, 20678, 322, 49369, 4470, 13, 51407], "temperature": 0.0, "avg_logprob": -0.2986548706725404, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0009107307414524257}, {"id": 577, "seek": 231984, "start": 2340.7000000000003, "end": 2346.0, "text": " And so the actual, when we call the learner, the loss function we'll use is VAE loss.", "tokens": [51407, 400, 370, 264, 3539, 11, 562, 321, 818, 264, 33347, 11, 264, 4470, 2445, 321, 603, 764, 307, 18527, 36, 4470, 13, 51672], "temperature": 0.0, "avg_logprob": -0.2986548706725404, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0009107307414524257}, {"id": 578, "seek": 234600, "start": 2346.0, "end": 2355.12, "text": " But we're going to pass in as metrics, this list of additional metrics to print out.", "tokens": [50364, 583, 321, 434, 516, 281, 1320, 294, 382, 16367, 11, 341, 1329, 295, 4497, 16367, 281, 4482, 484, 13, 50820], "temperature": 0.0, "avg_logprob": -0.25195530922182147, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.003944931551814079}, {"id": 579, "seek": 234600, "start": 2355.12, "end": 2357.08, "text": " So it's just going to print them out.", "tokens": [50820, 407, 309, 311, 445, 516, 281, 4482, 552, 484, 13, 50918], "temperature": 0.0, "avg_logprob": -0.25195530922182147, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.003944931551814079}, {"id": 580, "seek": 234600, "start": 2357.08, "end": 2361.4, "text": " And in some ways it's a little inefficient because it's going to calculate KLD loss twice", "tokens": [50918, 400, 294, 512, 2098, 309, 311, 257, 707, 43495, 570, 309, 311, 516, 281, 8873, 47991, 35, 4470, 6091, 51134], "temperature": 0.0, "avg_logprob": -0.25195530922182147, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.003944931551814079}, {"id": 581, "seek": 234600, "start": 2361.4, "end": 2366.0, "text": " and BCE loss twice, one to print it out and one to go into the, you know, actual loss", "tokens": [51134, 293, 49369, 4470, 6091, 11, 472, 281, 4482, 309, 484, 293, 472, 281, 352, 666, 264, 11, 291, 458, 11, 3539, 4470, 51364], "temperature": 0.0, "avg_logprob": -0.25195530922182147, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.003944931551814079}, {"id": 582, "seek": 234600, "start": 2366.0, "end": 2368.4, "text": " function, but it doesn't take long for that bit.", "tokens": [51364, 2445, 11, 457, 309, 1177, 380, 747, 938, 337, 300, 857, 13, 51484], "temperature": 0.0, "avg_logprob": -0.25195530922182147, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.003944931551814079}, {"id": 583, "seek": 234600, "start": 2368.4, "end": 2371.48, "text": " So I think that's fine.", "tokens": [51484, 407, 286, 519, 300, 311, 2489, 13, 51638], "temperature": 0.0, "avg_logprob": -0.25195530922182147, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.003944931551814079}, {"id": 584, "seek": 234600, "start": 2371.48, "end": 2374.68, "text": " So now when we call learn.fit, you can see it's printing them all out.", "tokens": [51638, 407, 586, 562, 321, 818, 1466, 13, 6845, 11, 291, 393, 536, 309, 311, 14699, 552, 439, 484, 13, 51798], "temperature": 0.0, "avg_logprob": -0.25195530922182147, "compression_ratio": 1.7198443579766538, "no_speech_prob": 0.003944931551814079}, {"id": 585, "seek": 237468, "start": 2374.68, "end": 2381.24, "text": " So the BCE that we got last time was 0.26.", "tokens": [50364, 407, 264, 49369, 300, 321, 658, 1036, 565, 390, 1958, 13, 10880, 13, 50692], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 586, "seek": 237468, "start": 2381.24, "end": 2383.44, "text": " And so this time, yeah, it's not as good.", "tokens": [50692, 400, 370, 341, 565, 11, 1338, 11, 309, 311, 406, 382, 665, 13, 50802], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 587, "seek": 237468, "start": 2383.44, "end": 2384.44, "text": " It's 0.31.", "tokens": [50802, 467, 311, 1958, 13, 12967, 13, 50852], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 588, "seek": 237468, "start": 2384.44, "end": 2385.44, "text": " It's a harder problem.", "tokens": [50852, 467, 311, 257, 6081, 1154, 13, 50902], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 589, "seek": 237468, "start": 2385.44, "end": 2390.52, "text": " And it's got random, randomness in it.", "tokens": [50902, 400, 309, 311, 658, 4974, 11, 4974, 1287, 294, 309, 13, 51156], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 590, "seek": 237468, "start": 2390.52, "end": 2396.04, "text": " And you can see here that the BCE and KLD are pretty similar scale when it starts.", "tokens": [51156, 400, 291, 393, 536, 510, 300, 264, 49369, 293, 47991, 35, 366, 1238, 2531, 4373, 562, 309, 3719, 13, 51432], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 591, "seek": 237468, "start": 2396.04, "end": 2397.04, "text": " That's a good sign.", "tokens": [51432, 663, 311, 257, 665, 1465, 13, 51482], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 592, "seek": 237468, "start": 2397.04, "end": 2401.8799999999997, "text": " If they weren't, you know, I could always in the loss function scale one of them up", "tokens": [51482, 759, 436, 4999, 380, 11, 291, 458, 11, 286, 727, 1009, 294, 264, 4470, 2445, 4373, 472, 295, 552, 493, 51724], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 593, "seek": 237468, "start": 2401.8799999999997, "end": 2403.72, "text": " or down.", "tokens": [51724, 420, 760, 13, 51816], "temperature": 0.0, "avg_logprob": -0.2690413711417435, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.00014883391850162297}, {"id": 594, "seek": 240372, "start": 2403.7599999999998, "end": 2405.16, "text": " But they're pretty similar to start with.", "tokens": [50366, 583, 436, 434, 1238, 2531, 281, 722, 365, 13, 50436], "temperature": 0.0, "avg_logprob": -0.2397852272822939, "compression_ratio": 1.5333333333333334, "no_speech_prob": 5.5622014770051464e-05}, {"id": 595, "seek": 240372, "start": 2405.16, "end": 2406.7599999999998, "text": " So that's fine.", "tokens": [50436, 407, 300, 311, 2489, 13, 50516], "temperature": 0.0, "avg_logprob": -0.2397852272822939, "compression_ratio": 1.5333333333333334, "no_speech_prob": 5.5622014770051464e-05}, {"id": 596, "seek": 240372, "start": 2406.7599999999998, "end": 2409.12, "text": " So we train this for a while.", "tokens": [50516, 407, 321, 3847, 341, 337, 257, 1339, 13, 50634], "temperature": 0.0, "avg_logprob": -0.2397852272822939, "compression_ratio": 1.5333333333333334, "no_speech_prob": 5.5622014770051464e-05}, {"id": 597, "seek": 240372, "start": 2409.12, "end": 2415.2, "text": " And then we can use exactly the same code for sampling as before.", "tokens": [50634, 400, 550, 321, 393, 764, 2293, 264, 912, 3089, 337, 21179, 382, 949, 13, 50938], "temperature": 0.0, "avg_logprob": -0.2397852272822939, "compression_ratio": 1.5333333333333334, "no_speech_prob": 5.5622014770051464e-05}, {"id": 598, "seek": 240372, "start": 2415.2, "end": 2419.8799999999997, "text": " And yeah, as we suspected, its ability to decode is worse.", "tokens": [50938, 400, 1338, 11, 382, 321, 26439, 11, 1080, 3485, 281, 979, 1429, 307, 5324, 13, 51172], "temperature": 0.0, "avg_logprob": -0.2397852272822939, "compression_ratio": 1.5333333333333334, "no_speech_prob": 5.5622014770051464e-05}, {"id": 599, "seek": 240372, "start": 2419.8799999999997, "end": 2429.04, "text": " So it's actually not capturing the LEE at all, in fact, and the shoes got very blurry.", "tokens": [51172, 407, 309, 311, 767, 406, 23384, 264, 441, 7258, 412, 439, 11, 294, 1186, 11, 293, 264, 6654, 658, 588, 37644, 13, 51630], "temperature": 0.0, "avg_logprob": -0.2397852272822939, "compression_ratio": 1.5333333333333334, "no_speech_prob": 5.5622014770051464e-05}, {"id": 600, "seek": 242904, "start": 2429.12, "end": 2435.04, "text": " The hope is that when we call it on noise, called the decoder on random noise, that's", "tokens": [50368, 440, 1454, 307, 300, 562, 321, 818, 309, 322, 5658, 11, 1219, 264, 979, 19866, 322, 4974, 5658, 11, 300, 311, 50664], "temperature": 0.0, "avg_logprob": -0.2732219696044922, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0009849590715020895}, {"id": 601, "seek": 242904, "start": 2435.04, "end": 2436.04, "text": " much better.", "tokens": [50664, 709, 1101, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2732219696044922, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0009849590715020895}, {"id": 602, "seek": 242904, "start": 2436.04, "end": 2440.52, "text": " We're getting, it's not amazing, but we are getting some recognizable shapes.", "tokens": [50714, 492, 434, 1242, 11, 309, 311, 406, 2243, 11, 457, 321, 366, 1242, 512, 40757, 10854, 13, 50938], "temperature": 0.0, "avg_logprob": -0.2732219696044922, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0009849590715020895}, {"id": 603, "seek": 242904, "start": 2440.52, "end": 2451.48, "text": " So you know, VAEs are, you know, not generally going to get you as good a results as diffusion", "tokens": [50938, 407, 291, 458, 11, 18527, 20442, 366, 11, 291, 458, 11, 406, 5101, 516, 281, 483, 291, 382, 665, 257, 3542, 382, 25242, 51486], "temperature": 0.0, "avg_logprob": -0.2732219696044922, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0009849590715020895}, {"id": 604, "seek": 242904, "start": 2451.48, "end": 2452.48, "text": " models are.", "tokens": [51486, 5245, 366, 13, 51536], "temperature": 0.0, "avg_logprob": -0.2732219696044922, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0009849590715020895}, {"id": 605, "seek": 242904, "start": 2452.48, "end": 2456.56, "text": " Although actually, if you train really good ones for a really long time, they can be pretty", "tokens": [51536, 5780, 767, 11, 498, 291, 3847, 534, 665, 2306, 337, 257, 534, 938, 565, 11, 436, 393, 312, 1238, 51740], "temperature": 0.0, "avg_logprob": -0.2732219696044922, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0009849590715020895}, {"id": 606, "seek": 242904, "start": 2456.56, "end": 2457.56, "text": " impressive.", "tokens": [51740, 8992, 13, 51790], "temperature": 0.0, "avg_logprob": -0.2732219696044922, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0009849590715020895}, {"id": 607, "seek": 245756, "start": 2457.56, "end": 2461.84, "text": " So yeah, even in this extremely simple quick case, we've got something that can generate", "tokens": [50364, 407, 1338, 11, 754, 294, 341, 4664, 2199, 1702, 1389, 11, 321, 600, 658, 746, 300, 393, 8460, 50578], "temperature": 0.0, "avg_logprob": -0.26909566962200665, "compression_ratio": 1.506726457399103, "no_speech_prob": 0.004538319539278746}, {"id": 608, "seek": 245756, "start": 2461.84, "end": 2466.56, "text": " recognizable items of clothing.", "tokens": [50578, 40757, 4754, 295, 11502, 13, 50814], "temperature": 0.0, "avg_logprob": -0.26909566962200665, "compression_ratio": 1.506726457399103, "no_speech_prob": 0.004538319539278746}, {"id": 609, "seek": 245756, "start": 2466.56, "end": 2472.32, "text": " Did you guys want to add anything before we move on to the stable diffusion VAE?", "tokens": [50814, 2589, 291, 1074, 528, 281, 909, 1340, 949, 321, 1286, 322, 281, 264, 8351, 25242, 18527, 36, 30, 51102], "temperature": 0.0, "avg_logprob": -0.26909566962200665, "compression_ratio": 1.506726457399103, "no_speech_prob": 0.004538319539278746}, {"id": 610, "seek": 245756, "start": 2472.32, "end": 2475.16, "text": " Okay.", "tokens": [51102, 1033, 13, 51244], "temperature": 0.0, "avg_logprob": -0.26909566962200665, "compression_ratio": 1.506726457399103, "no_speech_prob": 0.004538319539278746}, {"id": 611, "seek": 245756, "start": 2475.16, "end": 2482.52, "text": " So this, yeah, so this VAE is very crappy.", "tokens": [51244, 407, 341, 11, 1338, 11, 370, 341, 18527, 36, 307, 588, 36531, 13, 51612], "temperature": 0.0, "avg_logprob": -0.26909566962200665, "compression_ratio": 1.506726457399103, "no_speech_prob": 0.004538319539278746}, {"id": 612, "seek": 245756, "start": 2482.52, "end": 2486.7999999999997, "text": " And as we mentioned, like one of the, one of the key reasons to use a VAE is actually", "tokens": [51612, 400, 382, 321, 2835, 11, 411, 472, 295, 264, 11, 472, 295, 264, 2141, 4112, 281, 764, 257, 18527, 36, 307, 767, 51826], "temperature": 0.0, "avg_logprob": -0.26909566962200665, "compression_ratio": 1.506726457399103, "no_speech_prob": 0.004538319539278746}, {"id": 613, "seek": 248680, "start": 2487.04, "end": 2492.4, "text": " that you can benefit from all the compute time that somebody else has put into training", "tokens": [50376, 300, 291, 393, 5121, 490, 439, 264, 14722, 565, 300, 2618, 1646, 575, 829, 666, 3097, 50644], "temperature": 0.0, "avg_logprob": -0.3081892453707181, "compression_ratio": 1.6305220883534137, "no_speech_prob": 0.008710666559636593}, {"id": 614, "seek": 248680, "start": 2492.4, "end": 2496.28, "text": " a good VAE.", "tokens": [50644, 257, 665, 18527, 36, 13, 50838], "temperature": 0.0, "avg_logprob": -0.3081892453707181, "compression_ratio": 1.6305220883534137, "no_speech_prob": 0.008710666559636593}, {"id": 615, "seek": 248680, "start": 2496.28, "end": 2501.2000000000003, "text": " Maybe just also like one thing of when we say good VAE, the one that we've trained here", "tokens": [50838, 2704, 445, 611, 411, 472, 551, 295, 562, 321, 584, 665, 18527, 36, 11, 264, 472, 300, 321, 600, 8895, 510, 51084], "temperature": 0.0, "avg_logprob": -0.3081892453707181, "compression_ratio": 1.6305220883534137, "no_speech_prob": 0.008710666559636593}, {"id": 616, "seek": 248680, "start": 2501.2000000000003, "end": 2506.52, "text": " is good at generating because it maps down to this like one, let's turn a dimensional", "tokens": [51084, 307, 665, 412, 17746, 570, 309, 11317, 760, 281, 341, 411, 472, 11, 718, 311, 1261, 257, 18795, 51350], "temperature": 0.0, "avg_logprob": -0.3081892453707181, "compression_ratio": 1.6305220883534137, "no_speech_prob": 0.008710666559636593}, {"id": 617, "seek": 248680, "start": 2506.52, "end": 2509.7200000000003, "text": " vector and then back in a very useful way.", "tokens": [51350, 8062, 293, 550, 646, 294, 257, 588, 4420, 636, 13, 51510], "temperature": 0.0, "avg_logprob": -0.3081892453707181, "compression_ratio": 1.6305220883534137, "no_speech_prob": 0.008710666559636593}, {"id": 618, "seek": 248680, "start": 2509.7200000000003, "end": 2514.2400000000002, "text": " And like, if you look at VAEs for generating, they'll often have a pretty small dimension", "tokens": [51510, 400, 411, 11, 498, 291, 574, 412, 18527, 20442, 337, 17746, 11, 436, 603, 2049, 362, 257, 1238, 1359, 10139, 51736], "temperature": 0.0, "avg_logprob": -0.3081892453707181, "compression_ratio": 1.6305220883534137, "no_speech_prob": 0.008710666559636593}, {"id": 619, "seek": 251424, "start": 2514.24, "end": 2515.24, "text": " in the middle.", "tokens": [50364, 294, 264, 2808, 13, 50414], "temperature": 0.0, "avg_logprob": -0.285140510619156, "compression_ratio": 1.7761732851985559, "no_speech_prob": 0.0850878432393074}, {"id": 620, "seek": 251424, "start": 2515.24, "end": 2519.16, "text": " And it'll just be like this vector that gets mapped back up.", "tokens": [50414, 400, 309, 603, 445, 312, 411, 341, 8062, 300, 2170, 33318, 646, 493, 13, 50610], "temperature": 0.0, "avg_logprob": -0.285140510619156, "compression_ratio": 1.7761732851985559, "no_speech_prob": 0.0850878432393074}, {"id": 621, "seek": 251424, "start": 2519.16, "end": 2523.3999999999996, "text": " And so VAE that's good for generating is slightly different to one that's good for compressing.", "tokens": [50610, 400, 370, 18527, 36, 300, 311, 665, 337, 17746, 307, 4748, 819, 281, 472, 300, 311, 665, 337, 14778, 278, 13, 50822], "temperature": 0.0, "avg_logprob": -0.285140510619156, "compression_ratio": 1.7761732851985559, "no_speech_prob": 0.0850878432393074}, {"id": 622, "seek": 251424, "start": 2523.3999999999996, "end": 2526.7999999999997, "text": " And like the stable diffusion one we'll see has this like spatial component still, it", "tokens": [50822, 400, 411, 264, 8351, 25242, 472, 321, 603, 536, 575, 341, 411, 23598, 6542, 920, 11, 309, 50992], "temperature": 0.0, "avg_logprob": -0.285140510619156, "compression_ratio": 1.7761732851985559, "no_speech_prob": 0.0850878432393074}, {"id": 623, "seek": 251424, "start": 2526.7999999999997, "end": 2532.72, "text": " doesn't map it down to a single vector, it maps it down to a 64 by 64 or whatever.", "tokens": [50992, 1177, 380, 4471, 309, 760, 281, 257, 2167, 8062, 11, 309, 11317, 309, 760, 281, 257, 12145, 538, 12145, 420, 2035, 13, 51288], "temperature": 0.0, "avg_logprob": -0.285140510619156, "compression_ratio": 1.7761732851985559, "no_speech_prob": 0.0850878432393074}, {"id": 624, "seek": 251424, "start": 2532.72, "end": 2537.2, "text": " And I think that's smaller than the original, but for generating, we can't just put random", "tokens": [51288, 400, 286, 519, 300, 311, 4356, 813, 264, 3380, 11, 457, 337, 17746, 11, 321, 393, 380, 445, 829, 4974, 51512], "temperature": 0.0, "avg_logprob": -0.285140510619156, "compression_ratio": 1.7761732851985559, "no_speech_prob": 0.0850878432393074}, {"id": 625, "seek": 251424, "start": 2537.2, "end": 2541.12, "text": " noise in there and hope like a cohesive image will come out.", "tokens": [51512, 5658, 294, 456, 293, 1454, 411, 257, 43025, 3256, 486, 808, 484, 13, 51708], "temperature": 0.0, "avg_logprob": -0.285140510619156, "compression_ratio": 1.7761732851985559, "no_speech_prob": 0.0850878432393074}, {"id": 626, "seek": 254112, "start": 2541.12, "end": 2545.92, "text": " So it's less good as a generator, but it is good because it has this like compression", "tokens": [50364, 407, 309, 311, 1570, 665, 382, 257, 19265, 11, 457, 309, 307, 665, 570, 309, 575, 341, 411, 19355, 50604], "temperature": 0.0, "avg_logprob": -0.2678528286161877, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.05183565244078636}, {"id": 627, "seek": 254112, "start": 2545.92, "end": 2547.56, "text": " and reconstruction ability.", "tokens": [50604, 293, 31565, 3485, 13, 50686], "temperature": 0.0, "avg_logprob": -0.2678528286161877, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.05183565244078636}, {"id": 628, "seek": 254112, "start": 2547.56, "end": 2548.56, "text": " Cool.", "tokens": [50686, 8561, 13, 50736], "temperature": 0.0, "avg_logprob": -0.2678528286161877, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.05183565244078636}, {"id": 629, "seek": 254112, "start": 2548.56, "end": 2549.56, "text": " Yeah.", "tokens": [50736, 865, 13, 50786], "temperature": 0.0, "avg_logprob": -0.2678528286161877, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.05183565244078636}, {"id": 630, "seek": 254112, "start": 2549.56, "end": 2552.08, "text": " So let's take a look.", "tokens": [50786, 407, 718, 311, 747, 257, 574, 13, 50912], "temperature": 0.0, "avg_logprob": -0.2678528286161877, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.05183565244078636}, {"id": 631, "seek": 254112, "start": 2552.08, "end": 2561.5, "text": " Now to demonstrate this, we want to move to a more difficult task because we want to show", "tokens": [50912, 823, 281, 11698, 341, 11, 321, 528, 281, 1286, 281, 257, 544, 2252, 5633, 570, 321, 528, 281, 855, 51383], "temperature": 0.0, "avg_logprob": -0.2678528286161877, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.05183565244078636}, {"id": 632, "seek": 254112, "start": 2561.5, "end": 2567.7999999999997, "text": " off how using latency lets us do stuff we couldn't do well before.", "tokens": [51383, 766, 577, 1228, 27043, 6653, 505, 360, 1507, 321, 2809, 380, 360, 731, 949, 13, 51698], "temperature": 0.0, "avg_logprob": -0.2678528286161877, "compression_ratio": 1.5353535353535352, "no_speech_prob": 0.05183565244078636}, {"id": 633, "seek": 256780, "start": 2567.8, "end": 2573.96, "text": " So the more difficult task we're going to do is generating bigger images and specifically", "tokens": [50364, 407, 264, 544, 2252, 5633, 321, 434, 516, 281, 360, 307, 17746, 3801, 5267, 293, 4682, 50672], "temperature": 0.0, "avg_logprob": -0.30898631702769885, "compression_ratio": 1.5838926174496644, "no_speech_prob": 0.0007552117458544672}, {"id": 634, "seek": 256780, "start": 2573.96, "end": 2581.36, "text": " generate images of bedrooms using the Lsun bedrooms dataset.", "tokens": [50672, 8460, 5267, 295, 39955, 1228, 264, 441, 11314, 2901, 32346, 28872, 13, 51042], "temperature": 0.0, "avg_logprob": -0.30898631702769885, "compression_ratio": 1.5838926174496644, "no_speech_prob": 0.0007552117458544672}, {"id": 635, "seek": 256780, "start": 2581.36, "end": 2595.76, "text": " So Lsun is a really nice dataset which has many, many, many millions of images across", "tokens": [51042, 407, 441, 11314, 307, 257, 534, 1481, 28872, 597, 575, 867, 11, 867, 11, 867, 6803, 295, 5267, 2108, 51762], "temperature": 0.0, "avg_logprob": -0.30898631702769885, "compression_ratio": 1.5838926174496644, "no_speech_prob": 0.0007552117458544672}, {"id": 636, "seek": 259576, "start": 2595.76, "end": 2601.6400000000003, "text": " 10 scene categories and 20 object categories.", "tokens": [50364, 1266, 4145, 10479, 293, 945, 2657, 10479, 13, 50658], "temperature": 0.0, "avg_logprob": -0.36789463727902144, "compression_ratio": 1.6906077348066297, "no_speech_prob": 0.014727099798619747}, {"id": 637, "seek": 259576, "start": 2601.6400000000003, "end": 2606.32, "text": " And so very, it's very rare for people to use all the object categories, to be honest,", "tokens": [50658, 400, 370, 588, 11, 309, 311, 588, 5892, 337, 561, 281, 764, 439, 264, 2657, 10479, 11, 281, 312, 3245, 11, 50892], "temperature": 0.0, "avg_logprob": -0.36789463727902144, "compression_ratio": 1.6906077348066297, "no_speech_prob": 0.014727099798619747}, {"id": 638, "seek": 259576, "start": 2606.32, "end": 2609.88, "text": " but people quite often use the scene categories.", "tokens": [50892, 457, 561, 1596, 2049, 764, 264, 4145, 10479, 13, 51070], "temperature": 0.0, "avg_logprob": -0.36789463727902144, "compression_ratio": 1.6906077348066297, "no_speech_prob": 0.014727099798619747}, {"id": 639, "seek": 259576, "start": 2609.88, "end": 2614.0, "text": " They're a little, well more than a little, can be extremely slow to download.", "tokens": [51070, 814, 434, 257, 707, 11, 731, 544, 813, 257, 707, 11, 393, 312, 4664, 2964, 281, 5484, 13, 51276], "temperature": 0.0, "avg_logprob": -0.36789463727902144, "compression_ratio": 1.6906077348066297, "no_speech_prob": 0.014727099798619747}, {"id": 640, "seek": 259576, "start": 2614.0, "end": 2616.5200000000004, "text": " The website they come from is very often down.", "tokens": [51276, 440, 3144, 436, 808, 490, 307, 588, 2049, 760, 13, 51402], "temperature": 0.0, "avg_logprob": -0.36789463727902144, "compression_ratio": 1.6906077348066297, "no_speech_prob": 0.014727099798619747}, {"id": 641, "seek": 261652, "start": 2616.52, "end": 2624.2, "text": " So what I did was I put a subset of 20% of them onto AWS.", "tokens": [50364, 407, 437, 286, 630, 390, 286, 829, 257, 25993, 295, 945, 4, 295, 552, 3911, 17650, 13, 50748], "temperature": 0.0, "avg_logprob": -0.34881398484513565, "compression_ratio": 1.3880597014925373, "no_speech_prob": 0.009699813090264797}, {"id": 642, "seek": 261652, "start": 2624.2, "end": 2630.96, "text": " They kindly provide some free dataset hosting for our students.", "tokens": [50748, 814, 29736, 2893, 512, 1737, 28872, 16058, 337, 527, 1731, 13, 51086], "temperature": 0.0, "avg_logprob": -0.34881398484513565, "compression_ratio": 1.3880597014925373, "no_speech_prob": 0.009699813090264797}, {"id": 643, "seek": 261652, "start": 2630.96, "end": 2633.88, "text": " And also the original Lsun is in a slightly complicated form.", "tokens": [51086, 400, 611, 264, 3380, 441, 11314, 307, 294, 257, 4748, 6179, 1254, 13, 51232], "temperature": 0.0, "avg_logprob": -0.34881398484513565, "compression_ratio": 1.3880597014925373, "no_speech_prob": 0.009699813090264797}, {"id": 644, "seek": 261652, "start": 2633.88, "end": 2635.88, "text": " It's in something called an LMDB database.", "tokens": [51232, 467, 311, 294, 746, 1219, 364, 46529, 27735, 8149, 13, 51332], "temperature": 0.0, "avg_logprob": -0.34881398484513565, "compression_ratio": 1.3880597014925373, "no_speech_prob": 0.009699813090264797}, {"id": 645, "seek": 261652, "start": 2635.88, "end": 2639.7599999999998, "text": " So I turned them into just normal images in folders.", "tokens": [51332, 407, 286, 3574, 552, 666, 445, 2710, 5267, 294, 31082, 13, 51526], "temperature": 0.0, "avg_logprob": -0.34881398484513565, "compression_ratio": 1.3880597014925373, "no_speech_prob": 0.009699813090264797}, {"id": 646, "seek": 263976, "start": 2639.76, "end": 2648.94, "text": " So you can download them directly from the AWS dataset site that they provided for us.", "tokens": [50364, 407, 291, 393, 5484, 552, 3838, 490, 264, 17650, 28872, 3621, 300, 436, 5649, 337, 505, 13, 50823], "temperature": 0.0, "avg_logprob": -0.35074644822340745, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.0011510656913742423}, {"id": 647, "seek": 263976, "start": 2648.94, "end": 2656.48, "text": " So I'm just using fast core to save it, and then using Python's SHU tool to unpack the", "tokens": [50823, 407, 286, 478, 445, 1228, 2370, 4965, 281, 3155, 309, 11, 293, 550, 1228, 15329, 311, 7405, 52, 2290, 281, 26699, 264, 51200], "temperature": 0.0, "avg_logprob": -0.35074644822340745, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.0011510656913742423}, {"id": 648, "seek": 263976, "start": 2656.48, "end": 2659.36, "text": " gzipped tar file.", "tokens": [51200, 290, 89, 5529, 3112, 3991, 13, 51344], "temperature": 0.0, "avg_logprob": -0.35074644822340745, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.0011510656913742423}, {"id": 649, "seek": 263976, "start": 2659.36, "end": 2661.32, "text": " Okay.", "tokens": [51344, 1033, 13, 51442], "temperature": 0.0, "avg_logprob": -0.35074644822340745, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.0011510656913742423}, {"id": 650, "seek": 263976, "start": 2661.32, "end": 2668.44, "text": " So that's given us, once that runs, which is going to take a long time.", "tokens": [51442, 407, 300, 311, 2212, 505, 11, 1564, 300, 6676, 11, 597, 307, 516, 281, 747, 257, 938, 565, 13, 51798], "temperature": 0.0, "avg_logprob": -0.35074644822340745, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.0011510656913742423}, {"id": 651, "seek": 266844, "start": 2668.44, "end": 2675.88, "text": " And you know, if, it might be, you know, even more reliable just to do this in the", "tokens": [50364, 400, 291, 458, 11, 498, 11, 309, 1062, 312, 11, 291, 458, 11, 754, 544, 12924, 445, 281, 360, 341, 294, 264, 50736], "temperature": 0.0, "avg_logprob": -0.3275796611134599, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.00013551201845984906}, {"id": 652, "seek": 266844, "start": 2675.88, "end": 2681.8, "text": " shell with Wget or ARIA2C or something, than doing it through Python.", "tokens": [50736, 8720, 365, 343, 847, 420, 316, 41125, 17, 34, 420, 746, 11, 813, 884, 309, 807, 15329, 13, 51032], "temperature": 0.0, "avg_logprob": -0.3275796611134599, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.00013551201845984906}, {"id": 653, "seek": 266844, "start": 2681.8, "end": 2685.04, "text": " So this will work, but if it's taking a long time or whatever, maybe just delete it and", "tokens": [51032, 407, 341, 486, 589, 11, 457, 498, 309, 311, 1940, 257, 938, 565, 420, 2035, 11, 1310, 445, 12097, 309, 293, 51194], "temperature": 0.0, "avg_logprob": -0.3275796611134599, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.00013551201845984906}, {"id": 654, "seek": 266844, "start": 2685.04, "end": 2688.04, "text": " do it in the shell instead.", "tokens": [51194, 360, 309, 294, 264, 8720, 2602, 13, 51344], "temperature": 0.0, "avg_logprob": -0.3275796611134599, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.00013551201845984906}, {"id": 655, "seek": 266844, "start": 2688.04, "end": 2690.7200000000003, "text": " Okay.", "tokens": [51344, 1033, 13, 51478], "temperature": 0.0, "avg_logprob": -0.3275796611134599, "compression_ratio": 1.4574468085106382, "no_speech_prob": 0.00013551201845984906}, {"id": 656, "seek": 269072, "start": 2690.72, "end": 2697.68, "text": " So then I thought, all right, how do we turn these into latents?", "tokens": [50364, 407, 550, 286, 1194, 11, 439, 558, 11, 577, 360, 321, 1261, 613, 666, 287, 267, 791, 30, 50712], "temperature": 0.0, "avg_logprob": -0.35884957086472286, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.00020342304196674377}, {"id": 657, "seek": 269072, "start": 2697.68, "end": 2704.04, "text": " Well, we could create a dataset in the usual way.", "tokens": [50712, 1042, 11, 321, 727, 1884, 257, 28872, 294, 264, 7713, 636, 13, 51030], "temperature": 0.0, "avg_logprob": -0.35884957086472286, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.00020342304196674377}, {"id": 658, "seek": 269072, "start": 2704.04, "end": 2705.56, "text": " So it's going to have a length.", "tokens": [51030, 407, 309, 311, 516, 281, 362, 257, 4641, 13, 51106], "temperature": 0.0, "avg_logprob": -0.35884957086472286, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.00020342304196674377}, {"id": 659, "seek": 269072, "start": 2705.56, "end": 2708.2, "text": " So we're going to grab all the files.", "tokens": [51106, 407, 321, 434, 516, 281, 4444, 439, 264, 7098, 13, 51238], "temperature": 0.0, "avg_logprob": -0.35884957086472286, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.00020342304196674377}, {"id": 660, "seek": 269072, "start": 2708.2, "end": 2717.24, "text": " So glob is a built into Python, which we'll search for, in this case, star.jpg.", "tokens": [51238, 407, 16125, 307, 257, 3094, 666, 15329, 11, 597, 321, 603, 3164, 337, 11, 294, 341, 1389, 11, 3543, 13, 73, 49861, 13, 51690], "temperature": 0.0, "avg_logprob": -0.35884957086472286, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.00020342304196674377}, {"id": 661, "seek": 271724, "start": 2717.24, "end": 2721.4399999999996, "text": " And if you've got star star slash, that's going to search recursively, as long as you", "tokens": [50364, 400, 498, 291, 600, 658, 3543, 3543, 17330, 11, 300, 311, 516, 281, 3164, 20560, 3413, 11, 382, 938, 382, 291, 50574], "temperature": 0.0, "avg_logprob": -0.25909491430355025, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.000437327689724043}, {"id": 662, "seek": 271724, "start": 2721.4399999999996, "end": 2723.04, "text": " pass recursive.", "tokens": [50574, 1320, 20560, 488, 13, 50654], "temperature": 0.0, "avg_logprob": -0.25909491430355025, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.000437327689724043}, {"id": 663, "seek": 271724, "start": 2723.04, "end": 2734.7599999999998, "text": " So we're going to search for all of the jpg files inside our data slash bedroom folder.", "tokens": [50654, 407, 321, 434, 516, 281, 3164, 337, 439, 295, 264, 361, 49861, 7098, 1854, 527, 1412, 17330, 11211, 10820, 13, 51240], "temperature": 0.0, "avg_logprob": -0.25909491430355025, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.000437327689724043}, {"id": 664, "seek": 271724, "start": 2734.7599999999998, "end": 2736.68, "text": " So that's what this is going to do.", "tokens": [51240, 407, 300, 311, 437, 341, 307, 516, 281, 360, 13, 51336], "temperature": 0.0, "avg_logprob": -0.25909491430355025, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.000437327689724043}, {"id": 665, "seek": 271724, "start": 2736.68, "end": 2740.3599999999997, "text": " It's going to put them all into the files attribute.", "tokens": [51336, 467, 311, 516, 281, 829, 552, 439, 666, 264, 7098, 19667, 13, 51520], "temperature": 0.0, "avg_logprob": -0.25909491430355025, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.000437327689724043}, {"id": 666, "seek": 274036, "start": 2740.36, "end": 2746.32, "text": " And so then when we get an item, the ith item, it will find the ith file.", "tokens": [50364, 400, 370, 550, 562, 321, 483, 364, 3174, 11, 264, 309, 71, 3174, 11, 309, 486, 915, 264, 309, 71, 3991, 13, 50662], "temperature": 0.0, "avg_logprob": -0.2774112269563495, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.0017544199945405126}, {"id": 667, "seek": 274036, "start": 2746.32, "end": 2748.04, "text": " It will read that image.", "tokens": [50662, 467, 486, 1401, 300, 3256, 13, 50748], "temperature": 0.0, "avg_logprob": -0.2774112269563495, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.0017544199945405126}, {"id": 668, "seek": 274036, "start": 2748.04, "end": 2751.46, "text": " So this is PyTorch's read image.", "tokens": [50748, 407, 341, 307, 9953, 51, 284, 339, 311, 1401, 3256, 13, 50919], "temperature": 0.0, "avg_logprob": -0.2774112269563495, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.0017544199945405126}, {"id": 669, "seek": 274036, "start": 2751.46, "end": 2756.94, "text": " It's the fastest way to read a jpg image.", "tokens": [50919, 467, 311, 264, 14573, 636, 281, 1401, 257, 361, 49861, 3256, 13, 51193], "temperature": 0.0, "avg_logprob": -0.2774112269563495, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.0017544199945405126}, {"id": 670, "seek": 274036, "start": 2756.94, "end": 2762.52, "text": " People often use pal, but it's quite hard to find a really well optimized pal version", "tokens": [51193, 3432, 2049, 764, 3984, 11, 457, 309, 311, 1596, 1152, 281, 915, 257, 534, 731, 26941, 3984, 3037, 51472], "temperature": 0.0, "avg_logprob": -0.2774112269563495, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.0017544199945405126}, {"id": 671, "seek": 274036, "start": 2762.52, "end": 2768.1200000000003, "text": " that's really compiled fast, where else the PyTorch TorchVision team have created a very,", "tokens": [51472, 300, 311, 534, 36548, 2370, 11, 689, 1646, 264, 9953, 51, 284, 339, 7160, 339, 53, 1991, 1469, 362, 2942, 257, 588, 11, 51752], "temperature": 0.0, "avg_logprob": -0.2774112269563495, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.0017544199945405126}, {"id": 672, "seek": 276812, "start": 2768.24, "end": 2771.3599999999997, "text": " very fast read image.", "tokens": [50370, 588, 2370, 1401, 3256, 13, 50526], "temperature": 0.0, "avg_logprob": -0.2722641217826617, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.0006878463318571448}, {"id": 673, "seek": 276812, "start": 2771.3599999999997, "end": 2774.7599999999998, "text": " So that's why I'm using theirs.", "tokens": [50526, 407, 300, 311, 983, 286, 478, 1228, 22760, 13, 50696], "temperature": 0.0, "avg_logprob": -0.2722641217826617, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.0006878463318571448}, {"id": 674, "seek": 276812, "start": 2774.7599999999998, "end": 2779.92, "text": " And if you pass in image read mode dot RGB, it'll automatically turn any one channel black", "tokens": [50696, 400, 498, 291, 1320, 294, 3256, 1401, 4391, 5893, 31231, 11, 309, 603, 6772, 1261, 604, 472, 2269, 2211, 50954], "temperature": 0.0, "avg_logprob": -0.2722641217826617, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.0006878463318571448}, {"id": 675, "seek": 276812, "start": 2779.92, "end": 2782.92, "text": " and white images into three channel images for you.", "tokens": [50954, 293, 2418, 5267, 666, 1045, 2269, 5267, 337, 291, 13, 51104], "temperature": 0.0, "avg_logprob": -0.2722641217826617, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.0006878463318571448}, {"id": 676, "seek": 276812, "start": 2782.92, "end": 2786.04, "text": " Or if there are four channel images with transparency, it'll turn those.", "tokens": [51104, 1610, 498, 456, 366, 1451, 2269, 5267, 365, 17131, 11, 309, 603, 1261, 729, 13, 51260], "temperature": 0.0, "avg_logprob": -0.2722641217826617, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.0006878463318571448}, {"id": 677, "seek": 276812, "start": 2786.04, "end": 2789.6, "text": " So this is a nice way to make sure they're all the same.", "tokens": [51260, 407, 341, 307, 257, 1481, 636, 281, 652, 988, 436, 434, 439, 264, 912, 13, 51438], "temperature": 0.0, "avg_logprob": -0.2722641217826617, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.0006878463318571448}, {"id": 678, "seek": 276812, "start": 2789.6, "end": 2795.16, "text": " And then this turns it into floats from not to one.", "tokens": [51438, 400, 550, 341, 4523, 309, 666, 37878, 490, 406, 281, 472, 13, 51716], "temperature": 0.0, "avg_logprob": -0.2722641217826617, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.0006878463318571448}, {"id": 679, "seek": 279516, "start": 2795.2, "end": 2799.52, "text": " And these images are generally very close to 256 by 256 pixels.", "tokens": [50366, 400, 613, 5267, 366, 5101, 588, 1998, 281, 38882, 538, 38882, 18668, 13, 50582], "temperature": 0.0, "avg_logprob": -0.29573837193575775, "compression_ratio": 1.4813084112149533, "no_speech_prob": 9.314545604865998e-05}, {"id": 680, "seek": 279516, "start": 2799.52, "end": 2808.04, "text": " So I just crop out the top 256 by 256 bit, because I didn't really care that much.", "tokens": [50582, 407, 286, 445, 9086, 484, 264, 1192, 38882, 538, 38882, 857, 11, 570, 286, 994, 380, 534, 1127, 300, 709, 13, 51008], "temperature": 0.0, "avg_logprob": -0.29573837193575775, "compression_ratio": 1.4813084112149533, "no_speech_prob": 9.314545604865998e-05}, {"id": 681, "seek": 279516, "start": 2808.04, "end": 2812.72, "text": " And we do need them to all be the same size in order that we can then pass them to the", "tokens": [51008, 400, 321, 360, 643, 552, 281, 439, 312, 264, 912, 2744, 294, 1668, 300, 321, 393, 550, 1320, 552, 281, 264, 51242], "temperature": 0.0, "avg_logprob": -0.29573837193575775, "compression_ratio": 1.4813084112149533, "no_speech_prob": 9.314545604865998e-05}, {"id": 682, "seek": 279516, "start": 2812.72, "end": 2816.2, "text": " VAE, stable diffusion VAE decoder as a batch.", "tokens": [51242, 18527, 36, 11, 8351, 25242, 18527, 36, 979, 19866, 382, 257, 15245, 13, 51416], "temperature": 0.0, "avg_logprob": -0.29573837193575775, "compression_ratio": 1.4813084112149533, "no_speech_prob": 9.314545604865998e-05}, {"id": 683, "seek": 279516, "start": 2816.2, "end": 2819.24, "text": " Otherwise it's going to take forever.", "tokens": [51416, 10328, 309, 311, 516, 281, 747, 5680, 13, 51568], "temperature": 0.0, "avg_logprob": -0.29573837193575775, "compression_ratio": 1.4813084112149533, "no_speech_prob": 9.314545604865998e-05}, {"id": 684, "seek": 281924, "start": 2819.24, "end": 2825.56, "text": " So I can create a data loader that's going to go through a bunch of them at a time.", "tokens": [50364, 407, 286, 393, 1884, 257, 1412, 3677, 260, 300, 311, 516, 281, 352, 807, 257, 3840, 295, 552, 412, 257, 565, 13, 50680], "temperature": 0.0, "avg_logprob": -0.2740523245482318, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.001700628432445228}, {"id": 685, "seek": 281924, "start": 2825.56, "end": 2828.12, "text": " So 64 at a time.", "tokens": [50680, 407, 12145, 412, 257, 565, 13, 50808], "temperature": 0.0, "avg_logprob": -0.2740523245482318, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.001700628432445228}, {"id": 686, "seek": 281924, "start": 2828.12, "end": 2832.68, "text": " And use however many CPUs I have as the number of workers.", "tokens": [50808, 400, 764, 4461, 867, 13199, 82, 286, 362, 382, 264, 1230, 295, 5600, 13, 51036], "temperature": 0.0, "avg_logprob": -0.2740523245482318, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.001700628432445228}, {"id": 687, "seek": 281924, "start": 2832.68, "end": 2835.4799999999996, "text": " It's going to do it in parallel.", "tokens": [51036, 467, 311, 516, 281, 360, 309, 294, 8952, 13, 51176], "temperature": 0.0, "avg_logprob": -0.2740523245482318, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.001700628432445228}, {"id": 688, "seek": 281924, "start": 2835.4799999999996, "end": 2840.4399999999996, "text": " And so the parallel bit is the bit that's actually reading the JPEGs, which is otherwise", "tokens": [51176, 400, 370, 264, 8952, 857, 307, 264, 857, 300, 311, 767, 3760, 264, 508, 5208, 33715, 11, 597, 307, 5911, 51424], "temperature": 0.0, "avg_logprob": -0.2740523245482318, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.001700628432445228}, {"id": 689, "seek": 281924, "start": 2840.4399999999996, "end": 2841.7599999999998, "text": " going to be pretty slow.", "tokens": [51424, 516, 281, 312, 1238, 2964, 13, 51490], "temperature": 0.0, "avg_logprob": -0.2740523245482318, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.001700628432445228}, {"id": 690, "seek": 281924, "start": 2841.7599999999998, "end": 2843.52, "text": " So if we grab a batch, here it is.", "tokens": [51490, 407, 498, 321, 4444, 257, 15245, 11, 510, 309, 307, 13, 51578], "temperature": 0.0, "avg_logprob": -0.2740523245482318, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.001700628432445228}, {"id": 691, "seek": 281924, "start": 2843.52, "end": 2846.16, "text": " Here's what it looks like.", "tokens": [51578, 1692, 311, 437, 309, 1542, 411, 13, 51710], "temperature": 0.0, "avg_logprob": -0.2740523245482318, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.001700628432445228}, {"id": 692, "seek": 284616, "start": 2846.16, "end": 2848.2, "text": " Generally speaking, they're just bedrooms.", "tokens": [50364, 21082, 4124, 11, 436, 434, 445, 39955, 13, 50466], "temperature": 0.0, "avg_logprob": -0.2869039797315411, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.011683841235935688}, {"id": 693, "seek": 284616, "start": 2848.2, "end": 2850.92, "text": " Although we've got one pretty risque situation in the bedroom.", "tokens": [50466, 5780, 321, 600, 658, 472, 1238, 37574, 2590, 294, 264, 11211, 13, 50602], "temperature": 0.0, "avg_logprob": -0.2869039797315411, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.011683841235935688}, {"id": 694, "seek": 284616, "start": 2850.92, "end": 2854.2, "text": " But on the whole, they're not safe for work.", "tokens": [50602, 583, 322, 264, 1379, 11, 436, 434, 406, 3273, 337, 589, 13, 50766], "temperature": 0.0, "avg_logprob": -0.2869039797315411, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.011683841235935688}, {"id": 695, "seek": 284616, "start": 2854.2, "end": 2859.04, "text": " This is the first time I've actually seen an actual bedroom scene taking place, as it", "tokens": [50766, 639, 307, 264, 700, 565, 286, 600, 767, 1612, 364, 3539, 11211, 4145, 1940, 1081, 11, 382, 309, 51008], "temperature": 0.0, "avg_logprob": -0.2869039797315411, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.011683841235935688}, {"id": 696, "seek": 284616, "start": 2859.04, "end": 2860.04, "text": " were.", "tokens": [51008, 645, 13, 51058], "temperature": 0.0, "avg_logprob": -0.2869039797315411, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.011683841235935688}, {"id": 697, "seek": 284616, "start": 2860.04, "end": 2861.04, "text": " All right.", "tokens": [51058, 1057, 558, 13, 51108], "temperature": 0.0, "avg_logprob": -0.2869039797315411, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.011683841235935688}, {"id": 698, "seek": 284616, "start": 2861.04, "end": 2869.08, "text": " So as you can see, this mini batch of, if I just grab the first 16 images, has three", "tokens": [51108, 407, 382, 291, 393, 536, 11, 341, 8382, 15245, 295, 11, 498, 286, 445, 4444, 264, 700, 3165, 5267, 11, 575, 1045, 51510], "temperature": 0.0, "avg_logprob": -0.2869039797315411, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.011683841235935688}, {"id": 699, "seek": 284616, "start": 2869.08, "end": 2874.56, "text": " channels and 256 by 256 pixels.", "tokens": [51510, 9235, 293, 38882, 538, 38882, 18668, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2869039797315411, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.011683841235935688}, {"id": 700, "seek": 287456, "start": 2874.56, "end": 2879.04, "text": " So that's how big that is for 16 images.", "tokens": [50364, 407, 300, 311, 577, 955, 300, 307, 337, 3165, 5267, 13, 50588], "temperature": 0.0, "avg_logprob": -0.3694555988050487, "compression_ratio": 1.4049079754601228, "no_speech_prob": 0.00011412138701416552}, {"id": 701, "seek": 287456, "start": 2879.04, "end": 2882.7599999999998, "text": " So that's 728.", "tokens": [50588, 407, 300, 311, 1614, 11205, 13, 50774], "temperature": 0.0, "avg_logprob": -0.3694555988050487, "compression_ratio": 1.4049079754601228, "no_speech_prob": 0.00011412138701416552}, {"id": 702, "seek": 287456, "start": 2882.7599999999998, "end": 2890.44, "text": " So 3.145 million floats to represent this.", "tokens": [50774, 407, 805, 13, 7271, 20, 2459, 37878, 281, 2906, 341, 13, 51158], "temperature": 0.0, "avg_logprob": -0.3694555988050487, "compression_ratio": 1.4049079754601228, "no_speech_prob": 0.00011412138701416552}, {"id": 703, "seek": 287456, "start": 2890.44, "end": 2891.74, "text": " Okay.", "tokens": [51158, 1033, 13, 51223], "temperature": 0.0, "avg_logprob": -0.3694555988050487, "compression_ratio": 1.4049079754601228, "no_speech_prob": 0.00011412138701416552}, {"id": 704, "seek": 287456, "start": 2891.74, "end": 2900.4, "text": " So as we learned in the first lesson of part two, we can grab an autoencoder directly using", "tokens": [51223, 407, 382, 321, 3264, 294, 264, 700, 6898, 295, 644, 732, 11, 321, 393, 4444, 364, 8399, 22660, 19866, 3838, 1228, 51656], "temperature": 0.0, "avg_logprob": -0.3694555988050487, "compression_ratio": 1.4049079754601228, "no_speech_prob": 0.00011412138701416552}, {"id": 705, "seek": 287456, "start": 2900.4, "end": 2904.08, "text": " diffusers using from pretrained.", "tokens": [51656, 7593, 301, 433, 1228, 490, 1162, 31774, 13, 51840], "temperature": 0.0, "avg_logprob": -0.3694555988050487, "compression_ratio": 1.4049079754601228, "no_speech_prob": 0.00011412138701416552}, {"id": 706, "seek": 290408, "start": 2904.6, "end": 2906.7599999999998, "text": " We can pop it onto our GPU.", "tokens": [50390, 492, 393, 1665, 309, 3911, 527, 18407, 13, 50498], "temperature": 0.0, "avg_logprob": -0.27477405307529207, "compression_ratio": 1.531496062992126, "no_speech_prob": 7.722184818703681e-05}, {"id": 707, "seek": 290408, "start": 2906.7599999999998, "end": 2912.16, "text": " And importantly, we don't have to say with torch.no grad anymore.", "tokens": [50498, 400, 8906, 11, 321, 500, 380, 362, 281, 584, 365, 27822, 13, 1771, 2771, 3602, 13, 50768], "temperature": 0.0, "avg_logprob": -0.27477405307529207, "compression_ratio": 1.531496062992126, "no_speech_prob": 7.722184818703681e-05}, {"id": 708, "seek": 290408, "start": 2912.16, "end": 2915.7599999999998, "text": " If we pass requires grad false.", "tokens": [50768, 759, 321, 1320, 7029, 2771, 7908, 13, 50948], "temperature": 0.0, "avg_logprob": -0.27477405307529207, "compression_ratio": 1.531496062992126, "no_speech_prob": 7.722184818703681e-05}, {"id": 709, "seek": 290408, "start": 2915.7599999999998, "end": 2919.52, "text": " Remember this neat trick in PyTorch, if it ends in an underscore, it actually changes", "tokens": [50948, 5459, 341, 10654, 4282, 294, 9953, 51, 284, 339, 11, 498, 309, 5314, 294, 364, 37556, 11, 309, 767, 2962, 51136], "temperature": 0.0, "avg_logprob": -0.27477405307529207, "compression_ratio": 1.531496062992126, "no_speech_prob": 7.722184818703681e-05}, {"id": 710, "seek": 290408, "start": 2919.52, "end": 2922.12, "text": " the thing that you're calling in place.", "tokens": [51136, 264, 551, 300, 291, 434, 5141, 294, 1081, 13, 51266], "temperature": 0.0, "avg_logprob": -0.27477405307529207, "compression_ratio": 1.531496062992126, "no_speech_prob": 7.722184818703681e-05}, {"id": 711, "seek": 290408, "start": 2922.12, "end": 2926.08, "text": " So this is going to stop it from computing gradients, which would take a lot of time", "tokens": [51266, 407, 341, 307, 516, 281, 1590, 309, 490, 15866, 2771, 2448, 11, 597, 576, 747, 257, 688, 295, 565, 51464], "temperature": 0.0, "avg_logprob": -0.27477405307529207, "compression_ratio": 1.531496062992126, "no_speech_prob": 7.722184818703681e-05}, {"id": 712, "seek": 290408, "start": 2926.08, "end": 2929.68, "text": " and a lot of memory otherwise.", "tokens": [51464, 293, 257, 688, 295, 4675, 5911, 13, 51644], "temperature": 0.0, "avg_logprob": -0.27477405307529207, "compression_ratio": 1.531496062992126, "no_speech_prob": 7.722184818703681e-05}, {"id": 713, "seek": 290408, "start": 2929.68, "end": 2930.86, "text": " So let's test it out.", "tokens": [51644, 407, 718, 311, 1500, 309, 484, 13, 51703], "temperature": 0.0, "avg_logprob": -0.27477405307529207, "compression_ratio": 1.531496062992126, "no_speech_prob": 7.722184818703681e-05}, {"id": 714, "seek": 293086, "start": 2930.86, "end": 2935.7400000000002, "text": " Let's encode our mini batch.", "tokens": [50364, 961, 311, 2058, 1429, 527, 8382, 15245, 13, 50608], "temperature": 0.0, "avg_logprob": -0.2577155007256402, "compression_ratio": 1.49, "no_speech_prob": 0.00041730934754014015}, {"id": 715, "seek": 293086, "start": 2935.7400000000002, "end": 2938.98, "text": " And so just like Jono was saying, this has now made it much smaller.", "tokens": [50608, 400, 370, 445, 411, 7745, 78, 390, 1566, 11, 341, 575, 586, 1027, 309, 709, 4356, 13, 50770], "temperature": 0.0, "avg_logprob": -0.2577155007256402, "compression_ratio": 1.49, "no_speech_prob": 0.00041730934754014015}, {"id": 716, "seek": 293086, "start": 2938.98, "end": 2946.1, "text": " It's got just in our 16 batch of 16, it's now a four channel 32 by 32.", "tokens": [50770, 467, 311, 658, 445, 294, 527, 3165, 15245, 295, 3165, 11, 309, 311, 586, 257, 1451, 2269, 8858, 538, 8858, 13, 51126], "temperature": 0.0, "avg_logprob": -0.2577155007256402, "compression_ratio": 1.49, "no_speech_prob": 0.00041730934754014015}, {"id": 717, "seek": 293086, "start": 2946.1, "end": 2953.08, "text": " So if we can compare the previous size to the new size, it's 48 times smaller.", "tokens": [51126, 407, 498, 321, 393, 6794, 264, 3894, 2744, 281, 264, 777, 2744, 11, 309, 311, 11174, 1413, 4356, 13, 51475], "temperature": 0.0, "avg_logprob": -0.2577155007256402, "compression_ratio": 1.49, "no_speech_prob": 0.00041730934754014015}, {"id": 718, "seek": 293086, "start": 2953.08, "end": 2956.7000000000003, "text": " So that's 48 times less memory it's going to need.", "tokens": [51475, 407, 300, 311, 11174, 1413, 1570, 4675, 309, 311, 516, 281, 643, 13, 51656], "temperature": 0.0, "avg_logprob": -0.2577155007256402, "compression_ratio": 1.49, "no_speech_prob": 0.00041730934754014015}, {"id": 719, "seek": 295670, "start": 2956.7, "end": 2961.2999999999997, "text": " And it's also going to be a lot less compute for a convolution to go across that image.", "tokens": [50364, 400, 309, 311, 611, 516, 281, 312, 257, 688, 1570, 14722, 337, 257, 45216, 281, 352, 2108, 300, 3256, 13, 50594], "temperature": 0.0, "avg_logprob": -0.22291566443255567, "compression_ratio": 1.7470355731225296, "no_speech_prob": 0.008061074651777744}, {"id": 720, "seek": 295670, "start": 2961.2999999999997, "end": 2966.58, "text": " So it's no good unless we can turn it back into the original image.", "tokens": [50594, 407, 309, 311, 572, 665, 5969, 321, 393, 1261, 309, 646, 666, 264, 3380, 3256, 13, 50858], "temperature": 0.0, "avg_logprob": -0.22291566443255567, "compression_ratio": 1.7470355731225296, "no_speech_prob": 0.008061074651777744}, {"id": 721, "seek": 295670, "start": 2966.58, "end": 2968.22, "text": " So let's just have a look at what it looks like first.", "tokens": [50858, 407, 718, 311, 445, 362, 257, 574, 412, 437, 309, 1542, 411, 700, 13, 50940], "temperature": 0.0, "avg_logprob": -0.22291566443255567, "compression_ratio": 1.7470355731225296, "no_speech_prob": 0.008061074651777744}, {"id": 722, "seek": 295670, "start": 2968.22, "end": 2972.5, "text": " Now it's a four channel image, so we can't naturally look at it.", "tokens": [50940, 823, 309, 311, 257, 1451, 2269, 3256, 11, 370, 321, 393, 380, 8195, 574, 412, 309, 13, 51154], "temperature": 0.0, "avg_logprob": -0.22291566443255567, "compression_ratio": 1.7470355731225296, "no_speech_prob": 0.008061074651777744}, {"id": 723, "seek": 295670, "start": 2972.5, "end": 2976.66, "text": " But what I could do is just grab the first three channels.", "tokens": [51154, 583, 437, 286, 727, 360, 307, 445, 4444, 264, 700, 1045, 9235, 13, 51362], "temperature": 0.0, "avg_logprob": -0.22291566443255567, "compression_ratio": 1.7470355731225296, "no_speech_prob": 0.008061074651777744}, {"id": 724, "seek": 295670, "start": 2976.66, "end": 2979.58, "text": " And then they're not going to be between 0 and 1.", "tokens": [51362, 400, 550, 436, 434, 406, 516, 281, 312, 1296, 1958, 293, 502, 13, 51508], "temperature": 0.0, "avg_logprob": -0.22291566443255567, "compression_ratio": 1.7470355731225296, "no_speech_prob": 0.008061074651777744}, {"id": 725, "seek": 295670, "start": 2979.58, "end": 2982.9399999999996, "text": " So if I just do dot sigmoid, now they're between 0 and 1.", "tokens": [51508, 407, 498, 286, 445, 360, 5893, 4556, 3280, 327, 11, 586, 436, 434, 1296, 1958, 293, 502, 13, 51676], "temperature": 0.0, "avg_logprob": -0.22291566443255567, "compression_ratio": 1.7470355731225296, "no_speech_prob": 0.008061074651777744}, {"id": 726, "seek": 298294, "start": 2982.94, "end": 2988.3, "text": " And so you can see that our risque bedroom scene, you can still recognize it.", "tokens": [50364, 400, 370, 291, 393, 536, 300, 527, 37574, 11211, 4145, 11, 291, 393, 920, 5521, 309, 13, 50632], "temperature": 0.0, "avg_logprob": -0.2611609278498469, "compression_ratio": 1.69375, "no_speech_prob": 0.0004238508699927479}, {"id": 727, "seek": 298294, "start": 2988.3, "end": 2992.66, "text": " Or this bedroom, this bed here, you can still recognize it.", "tokens": [50632, 1610, 341, 11211, 11, 341, 2901, 510, 11, 291, 393, 920, 5521, 309, 13, 50850], "temperature": 0.0, "avg_logprob": -0.2611609278498469, "compression_ratio": 1.69375, "no_speech_prob": 0.0004238508699927479}, {"id": 728, "seek": 298294, "start": 2992.66, "end": 2998.58, "text": " So there's still that kind of like, the basic geometry is still clearly there.", "tokens": [50850, 407, 456, 311, 920, 300, 733, 295, 411, 11, 264, 3875, 18426, 307, 920, 4448, 456, 13, 51146], "temperature": 0.0, "avg_logprob": -0.2611609278498469, "compression_ratio": 1.69375, "no_speech_prob": 0.0004238508699927479}, {"id": 729, "seek": 298294, "start": 2998.58, "end": 3004.54, "text": " But it's, yeah, it's clearly changed it a lot as well.", "tokens": [51146, 583, 309, 311, 11, 1338, 11, 309, 311, 4448, 3105, 309, 257, 688, 382, 731, 13, 51444], "temperature": 0.0, "avg_logprob": -0.2611609278498469, "compression_ratio": 1.69375, "no_speech_prob": 0.0004238508699927479}, {"id": 730, "seek": 300454, "start": 3004.54, "end": 3013.58, "text": " So importantly, we can call decode on this 48 times smaller tensor.", "tokens": [50364, 407, 8906, 11, 321, 393, 818, 979, 1429, 322, 341, 11174, 1413, 4356, 40863, 13, 50816], "temperature": 0.0, "avg_logprob": -0.32992557057163174, "compression_ratio": 1.3243243243243243, "no_speech_prob": 0.0015487124910578132}, {"id": 731, "seek": 300454, "start": 3013.58, "end": 3020.22, "text": " And it's really, I think, absolutely remarkable how good it is.", "tokens": [50816, 400, 309, 311, 534, 11, 286, 519, 11, 3122, 12802, 577, 665, 309, 307, 13, 51148], "temperature": 0.0, "avg_logprob": -0.32992557057163174, "compression_ratio": 1.3243243243243243, "no_speech_prob": 0.0015487124910578132}, {"id": 732, "seek": 300454, "start": 3020.22, "end": 3027.82, "text": " I can't tell the difference to the original.", "tokens": [51148, 286, 393, 380, 980, 264, 2649, 281, 264, 3380, 13, 51528], "temperature": 0.0, "avg_logprob": -0.32992557057163174, "compression_ratio": 1.3243243243243243, "no_speech_prob": 0.0015487124910578132}, {"id": 733, "seek": 300454, "start": 3027.82, "end": 3032.38, "text": " If I zoom in a bit.", "tokens": [51528, 759, 286, 8863, 294, 257, 857, 13, 51756], "temperature": 0.0, "avg_logprob": -0.32992557057163174, "compression_ratio": 1.3243243243243243, "no_speech_prob": 0.0015487124910578132}, {"id": 734, "seek": 303238, "start": 3032.38, "end": 3034.06, "text": " Her face is a bit blurry.", "tokens": [50364, 3204, 1851, 307, 257, 857, 37644, 13, 50448], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 735, "seek": 303238, "start": 3034.06, "end": 3036.06, "text": " Was her face always a bit blurry?", "tokens": [50448, 3027, 720, 1851, 1009, 257, 857, 37644, 30, 50548], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 736, "seek": 303238, "start": 3036.06, "end": 3039.2200000000003, "text": " It's always a bit blurry.", "tokens": [50548, 467, 311, 1009, 257, 857, 37644, 13, 50706], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 737, "seek": 303238, "start": 3039.2200000000003, "end": 3041.2200000000003, "text": " First, second, third.", "tokens": [50706, 2386, 11, 1150, 11, 2636, 13, 50806], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 738, "seek": 303238, "start": 3041.2200000000003, "end": 3043.7000000000003, "text": " Oh, hang on.", "tokens": [50806, 876, 11, 3967, 322, 13, 50930], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 739, "seek": 303238, "start": 3043.7000000000003, "end": 3046.2200000000003, "text": " Did that used to look like a proper ND?", "tokens": [50930, 2589, 300, 1143, 281, 574, 411, 257, 2296, 40709, 30, 51056], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 740, "seek": 303238, "start": 3046.2200000000003, "end": 3047.2200000000003, "text": " Yeah, okay.", "tokens": [51056, 865, 11, 1392, 13, 51106], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 741, "seek": 303238, "start": 3047.2200000000003, "end": 3048.2200000000003, "text": " So you can see this.", "tokens": [51106, 407, 291, 393, 536, 341, 13, 51156], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 742, "seek": 303238, "start": 3048.2200000000003, "end": 3053.46, "text": " You see there, clearly there's an ND here.", "tokens": [51156, 509, 536, 456, 11, 4448, 456, 311, 364, 40709, 510, 13, 51418], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 743, "seek": 303238, "start": 3053.46, "end": 3055.3, "text": " And now you can't see those letters.", "tokens": [51418, 400, 586, 291, 393, 380, 536, 729, 7825, 13, 51510], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 744, "seek": 303238, "start": 3055.3, "end": 3061.82, "text": " So, and this is actually a classic thing that's known for this particular VAE, is it's not", "tokens": [51510, 407, 11, 293, 341, 307, 767, 257, 7230, 551, 300, 311, 2570, 337, 341, 1729, 18527, 36, 11, 307, 309, 311, 406, 51836], "temperature": 0.0, "avg_logprob": -0.39299456812754396, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.01744069717824459}, {"id": 745, "seek": 306182, "start": 3061.82, "end": 3069.26, "text": " able to regenerate writing correctly at small font sizes.", "tokens": [50364, 1075, 281, 26358, 473, 3579, 8944, 412, 1359, 10703, 11602, 13, 50736], "temperature": 0.0, "avg_logprob": -0.2761758874963831, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0022871557157486677}, {"id": 746, "seek": 306182, "start": 3069.26, "end": 3072.9, "text": " I think it's also pretty, it's like, I think we hear with the faces are already pretty", "tokens": [50736, 286, 519, 309, 311, 611, 1238, 11, 309, 311, 411, 11, 286, 519, 321, 1568, 365, 264, 8475, 366, 1217, 1238, 50918], "temperature": 0.0, "avg_logprob": -0.2761758874963831, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0022871557157486677}, {"id": 747, "seek": 306182, "start": 3072.9, "end": 3073.9, "text": " well resolution.", "tokens": [50918, 731, 8669, 13, 50968], "temperature": 0.0, "avg_logprob": -0.2761758874963831, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0022871557157486677}, {"id": 748, "seek": 306182, "start": 3073.9, "end": 3079.78, "text": " But if you're at a higher resolution, the faces also would probably not be converted", "tokens": [50968, 583, 498, 291, 434, 412, 257, 2946, 8669, 11, 264, 8475, 611, 576, 1391, 406, 312, 16424, 51262], "temperature": 0.0, "avg_logprob": -0.2761758874963831, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0022871557157486677}, {"id": 749, "seek": 306182, "start": 3079.78, "end": 3080.78, "text": " appropriately.", "tokens": [51262, 23505, 13, 51312], "temperature": 0.0, "avg_logprob": -0.2761758874963831, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0022871557157486677}, {"id": 750, "seek": 306182, "start": 3080.78, "end": 3081.78, "text": " Okay, cool.", "tokens": [51312, 1033, 11, 1627, 13, 51362], "temperature": 0.0, "avg_logprob": -0.2761758874963831, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0022871557157486677}, {"id": 751, "seek": 306182, "start": 3081.78, "end": 3085.98, "text": " But overall, yeah, it's done a great job.", "tokens": [51362, 583, 4787, 11, 1338, 11, 309, 311, 1096, 257, 869, 1691, 13, 51572], "temperature": 0.0, "avg_logprob": -0.2761758874963831, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0022871557157486677}, {"id": 752, "seek": 306182, "start": 3085.98, "end": 3090.2200000000003, "text": " A couple of other things I wanted to note was like, so like you mentioned like a 40,", "tokens": [51572, 316, 1916, 295, 661, 721, 286, 1415, 281, 3637, 390, 411, 11, 370, 411, 291, 2835, 411, 257, 3356, 11, 51784], "temperature": 0.0, "avg_logprob": -0.2761758874963831, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.0022871557157486677}, {"id": 753, "seek": 309022, "start": 3090.2599999999998, "end": 3092.62, "text": " I guess a factor of 48 decrease.", "tokens": [50366, 286, 2041, 257, 5952, 295, 11174, 11514, 13, 50484], "temperature": 0.0, "avg_logprob": -0.30800482708474863, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.08507096767425537}, {"id": 754, "seek": 309022, "start": 3092.62, "end": 3097.3399999999997, "text": " Oftentimes people refer to mostly at the spatial resolution.", "tokens": [50484, 46636, 561, 2864, 281, 5240, 412, 264, 23598, 8669, 13, 50720], "temperature": 0.0, "avg_logprob": -0.30800482708474863, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.08507096767425537}, {"id": 755, "seek": 309022, "start": 3097.3399999999997, "end": 3105.22, "text": " So since it's going from 256 by 256 to 32 by 32, so that's like a factor of eight.", "tokens": [50720, 407, 1670, 309, 311, 516, 490, 38882, 538, 38882, 281, 8858, 538, 8858, 11, 370, 300, 311, 411, 257, 5952, 295, 3180, 13, 51114], "temperature": 0.0, "avg_logprob": -0.30800482708474863, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.08507096767425537}, {"id": 756, "seek": 309022, "start": 3105.22, "end": 3108.4199999999996, "text": " So they sometimes will know like, I think it's like F8 or something like this, they'll", "tokens": [51114, 407, 436, 2171, 486, 458, 411, 11, 286, 519, 309, 311, 411, 479, 23, 420, 746, 411, 341, 11, 436, 603, 51274], "temperature": 0.0, "avg_logprob": -0.30800482708474863, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.08507096767425537}, {"id": 757, "seek": 309022, "start": 3108.4199999999996, "end": 3110.4599999999996, "text": " note the spatial resolution.", "tokens": [51274, 3637, 264, 23598, 8669, 13, 51376], "temperature": 0.0, "avg_logprob": -0.30800482708474863, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.08507096767425537}, {"id": 758, "seek": 309022, "start": 3110.4599999999996, "end": 3113.8999999999996, "text": " So sometimes you may see that written out like that.", "tokens": [51376, 407, 2171, 291, 815, 536, 300, 3720, 484, 411, 300, 13, 51548], "temperature": 0.0, "avg_logprob": -0.30800482708474863, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.08507096767425537}, {"id": 759, "seek": 309022, "start": 3113.8999999999996, "end": 3120.14, "text": " And of course, F8 is an eight squared decrease in the number of pixels, which is interesting.", "tokens": [51548, 400, 295, 1164, 11, 479, 23, 307, 364, 3180, 8889, 11514, 294, 264, 1230, 295, 18668, 11, 597, 307, 1880, 13, 51860], "temperature": 0.0, "avg_logprob": -0.30800482708474863, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.08507096767425537}, {"id": 760, "seek": 312014, "start": 3121.06, "end": 3122.06, "text": " Right.", "tokens": [50410, 1779, 13, 50460], "temperature": 0.0, "avg_logprob": -0.3310878018298781, "compression_ratio": 1.5049019607843137, "no_speech_prob": 0.0008829950820654631}, {"id": 761, "seek": 312014, "start": 3122.06, "end": 3129.46, "text": " And then the other thing I wanted to note was that the VAE is also trained with a perceptual", "tokens": [50460, 400, 550, 264, 661, 551, 286, 1415, 281, 3637, 390, 300, 264, 18527, 36, 307, 611, 8895, 365, 257, 43276, 901, 50830], "temperature": 0.0, "avg_logprob": -0.3310878018298781, "compression_ratio": 1.5049019607843137, "no_speech_prob": 0.0008829950820654631}, {"id": 762, "seek": 312014, "start": 3129.46, "end": 3136.8599999999997, "text": " loss objective, as well as a technically like a discriminator again, objective.", "tokens": [50830, 4470, 10024, 11, 382, 731, 382, 257, 12120, 411, 257, 20828, 1639, 797, 11, 10024, 13, 51200], "temperature": 0.0, "avg_logprob": -0.3310878018298781, "compression_ratio": 1.5049019607843137, "no_speech_prob": 0.0008829950820654631}, {"id": 763, "seek": 312014, "start": 3136.8599999999997, "end": 3139.62, "text": " I don't know if you were going to go into that a little bit later.", "tokens": [51200, 286, 500, 380, 458, 498, 291, 645, 516, 281, 352, 666, 300, 257, 707, 857, 1780, 13, 51338], "temperature": 0.0, "avg_logprob": -0.3310878018298781, "compression_ratio": 1.5049019607843137, "no_speech_prob": 0.0008829950820654631}, {"id": 764, "seek": 312014, "start": 3139.62, "end": 3144.8199999999997, "text": " So yeah, so perceptual loss, we've already discussed, right?", "tokens": [51338, 407, 1338, 11, 370, 43276, 901, 4470, 11, 321, 600, 1217, 7152, 11, 558, 30, 51598], "temperature": 0.0, "avg_logprob": -0.3310878018298781, "compression_ratio": 1.5049019607843137, "no_speech_prob": 0.0008829950820654631}, {"id": 765, "seek": 314482, "start": 3144.82, "end": 3151.38, "text": " So the VAE is going to, you know, when they trained it, so I think this was trained by", "tokens": [50364, 407, 264, 18527, 36, 307, 516, 281, 11, 291, 458, 11, 562, 436, 8895, 309, 11, 370, 286, 519, 341, 390, 8895, 538, 50692], "temperature": 0.0, "avg_logprob": -0.38085145535676374, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.01363134104758501}, {"id": 766, "seek": 314482, "start": 3151.38, "end": 3153.54, "text": " CompViz, right?", "tokens": [50692, 6620, 53, 590, 11, 558, 30, 50800], "temperature": 0.0, "avg_logprob": -0.38085145535676374, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.01363134104758501}, {"id": 767, "seek": 314482, "start": 3153.54, "end": 3164.6600000000003, "text": " The, you know, Robin and gang and used stability.ai donated compute for that.", "tokens": [50800, 440, 11, 291, 458, 11, 16533, 293, 10145, 293, 1143, 11826, 13, 1301, 23723, 14722, 337, 300, 13, 51356], "temperature": 0.0, "avg_logprob": -0.38085145535676374, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.01363134104758501}, {"id": 768, "seek": 314482, "start": 3164.6600000000003, "end": 3165.6600000000003, "text": " And they went to...", "tokens": [51356, 400, 436, 1437, 281, 485, 51406], "temperature": 0.0, "avg_logprob": -0.38085145535676374, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.01363134104758501}, {"id": 769, "seek": 314482, "start": 3165.6600000000003, "end": 3170.86, "text": " To be clear, actually, no, the VAE was actually trained separately and it's actually trained", "tokens": [51406, 1407, 312, 1850, 11, 767, 11, 572, 11, 264, 18527, 36, 390, 767, 8895, 14759, 293, 309, 311, 767, 8895, 51666], "temperature": 0.0, "avg_logprob": -0.38085145535676374, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.01363134104758501}, {"id": 770, "seek": 314482, "start": 3170.86, "end": 3173.34, "text": " on the open images dataset.", "tokens": [51666, 322, 264, 1269, 5267, 28872, 13, 51790], "temperature": 0.0, "avg_logprob": -0.38085145535676374, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.01363134104758501}, {"id": 771, "seek": 317334, "start": 3173.38, "end": 3178.3, "text": " And it was just this VAE that they trained by themselves on, you know, a small subset", "tokens": [50366, 400, 309, 390, 445, 341, 18527, 36, 300, 436, 8895, 538, 2969, 322, 11, 291, 458, 11, 257, 1359, 25993, 50612], "temperature": 0.0, "avg_logprob": -0.3182622872146906, "compression_ratio": 1.5064377682403434, "no_speech_prob": 0.00041730550583451986}, {"id": 772, "seek": 317334, "start": 3178.3, "end": 3184.38, "text": " of data, but because the VAE is so powerful, it's actually able to be applied to all these", "tokens": [50612, 295, 1412, 11, 457, 570, 264, 18527, 36, 307, 370, 4005, 11, 309, 311, 767, 1075, 281, 312, 6456, 281, 439, 613, 50916], "temperature": 0.0, "avg_logprob": -0.3182622872146906, "compression_ratio": 1.5064377682403434, "no_speech_prob": 0.00041730550583451986}, {"id": 773, "seek": 317334, "start": 3184.38, "end": 3187.1800000000003, "text": " other datasets as well.", "tokens": [50916, 661, 42856, 382, 731, 13, 51056], "temperature": 0.0, "avg_logprob": -0.3182622872146906, "compression_ratio": 1.5064377682403434, "no_speech_prob": 0.00041730550583451986}, {"id": 774, "seek": 317334, "start": 3187.1800000000003, "end": 3188.5, "text": " Okay, great.", "tokens": [51056, 1033, 11, 869, 13, 51122], "temperature": 0.0, "avg_logprob": -0.3182622872146906, "compression_ratio": 1.5064377682403434, "no_speech_prob": 0.00041730550583451986}, {"id": 775, "seek": 317334, "start": 3188.5, "end": 3189.5, "text": " Yeah.", "tokens": [51122, 865, 13, 51172], "temperature": 0.0, "avg_logprob": -0.3182622872146906, "compression_ratio": 1.5064377682403434, "no_speech_prob": 0.00041730550583451986}, {"id": 776, "seek": 317334, "start": 3189.5, "end": 3196.6600000000003, "text": " So they would have had a KL diversion loss and they would have either had an MSC or BCE", "tokens": [51172, 407, 436, 576, 362, 632, 257, 47991, 49422, 4470, 293, 436, 576, 362, 2139, 632, 364, 7395, 34, 420, 49369, 51530], "temperature": 0.0, "avg_logprob": -0.3182622872146906, "compression_ratio": 1.5064377682403434, "no_speech_prob": 0.00041730550583451986}, {"id": 777, "seek": 317334, "start": 3196.6600000000003, "end": 3199.26, "text": " loss, I think it might've been an MSC loss.", "tokens": [51530, 4470, 11, 286, 519, 309, 1062, 600, 668, 364, 7395, 34, 4470, 13, 51660], "temperature": 0.0, "avg_logprob": -0.3182622872146906, "compression_ratio": 1.5064377682403434, "no_speech_prob": 0.00041730550583451986}, {"id": 778, "seek": 319926, "start": 3199.26, "end": 3203.1400000000003, "text": " They also had a perceptual loss, which is the thing we learned about when we talked", "tokens": [50364, 814, 611, 632, 257, 43276, 901, 4470, 11, 597, 307, 264, 551, 321, 3264, 466, 562, 321, 2825, 50558], "temperature": 0.0, "avg_logprob": -0.22225397061078978, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0021487174089998007}, {"id": 779, "seek": 319926, "start": 3203.1400000000003, "end": 3211.5400000000004, "text": " about super resolution, which is where when they compared the output images to the original", "tokens": [50558, 466, 1687, 8669, 11, 597, 307, 689, 562, 436, 5347, 264, 5598, 5267, 281, 264, 3380, 50978], "temperature": 0.0, "avg_logprob": -0.22225397061078978, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0021487174089998007}, {"id": 780, "seek": 319926, "start": 3211.5400000000004, "end": 3219.42, "text": " images, they would have run that through a, you know, ImageNet trained or similar classifier", "tokens": [50978, 5267, 11, 436, 576, 362, 1190, 300, 807, 257, 11, 291, 458, 11, 29903, 31890, 8895, 420, 2531, 1508, 9902, 51372], "temperature": 0.0, "avg_logprob": -0.22225397061078978, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0021487174089998007}, {"id": 781, "seek": 319926, "start": 3219.42, "end": 3225.5800000000004, "text": " and confirmed that the activations they got through that model were similar.", "tokens": [51372, 293, 11341, 300, 264, 2430, 763, 436, 658, 807, 300, 2316, 645, 2531, 13, 51680], "temperature": 0.0, "avg_logprob": -0.22225397061078978, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0021487174089998007}, {"id": 782, "seek": 322558, "start": 3225.58, "end": 3234.58, "text": " And then the final bit is, as Tanejka was mentioning, is the adversarial loss, which", "tokens": [50364, 400, 550, 264, 2572, 857, 307, 11, 382, 314, 1929, 73, 2330, 390, 18315, 11, 307, 264, 17641, 44745, 4470, 11, 597, 50814], "temperature": 0.0, "avg_logprob": -0.31976179643110797, "compression_ratio": 1.4855072463768115, "no_speech_prob": 0.0035374395083636045}, {"id": 783, "seek": 322558, "start": 3234.58, "end": 3238.58, "text": " is also known as a GAN loss.", "tokens": [50814, 307, 611, 2570, 382, 257, 460, 1770, 4470, 13, 51014], "temperature": 0.0, "avg_logprob": -0.31976179643110797, "compression_ratio": 1.4855072463768115, "no_speech_prob": 0.0035374395083636045}, {"id": 784, "seek": 322558, "start": 3238.58, "end": 3243.9, "text": " So a GAN is a generative adversarial network.", "tokens": [51014, 407, 257, 460, 1770, 307, 257, 1337, 1166, 17641, 44745, 3209, 13, 51280], "temperature": 0.0, "avg_logprob": -0.31976179643110797, "compression_ratio": 1.4855072463768115, "no_speech_prob": 0.0035374395083636045}, {"id": 785, "seek": 322558, "start": 3243.9, "end": 3248.8199999999997, "text": " And the GAN loss, what it does is it grabs...", "tokens": [51280, 400, 264, 460, 1770, 4470, 11, 437, 309, 775, 307, 309, 30028, 485, 51526], "temperature": 0.0, "avg_logprob": -0.31976179643110797, "compression_ratio": 1.4855072463768115, "no_speech_prob": 0.0035374395083636045}, {"id": 786, "seek": 324882, "start": 3248.82, "end": 3257.7000000000003, "text": " It's actually more specifically what's called a patchwise GAN loss.", "tokens": [50364, 467, 311, 767, 544, 4682, 437, 311, 1219, 257, 9972, 3711, 460, 1770, 4470, 13, 50808], "temperature": 0.0, "avg_logprob": -0.22631045391685084, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.002757504815235734}, {"id": 787, "seek": 324882, "start": 3257.7000000000003, "end": 3264.54, "text": " And what it does is it takes like a little section of an image, right?", "tokens": [50808, 400, 437, 309, 775, 307, 309, 2516, 411, 257, 707, 3541, 295, 364, 3256, 11, 558, 30, 51150], "temperature": 0.0, "avg_logprob": -0.22631045391685084, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.002757504815235734}, {"id": 788, "seek": 324882, "start": 3264.54, "end": 3268.94, "text": " And what they've done is they train it's...", "tokens": [51150, 400, 437, 436, 600, 1096, 307, 436, 3847, 309, 311, 485, 51370], "temperature": 0.0, "avg_logprob": -0.22631045391685084, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.002757504815235734}, {"id": 789, "seek": 324882, "start": 3268.94, "end": 3274.2200000000003, "text": " Let's just simplify it for a moment and imagine that they've pre-trained a classifier, right?", "tokens": [51370, 961, 311, 445, 20460, 309, 337, 257, 1623, 293, 3811, 300, 436, 600, 659, 12, 17227, 2001, 257, 1508, 9902, 11, 558, 30, 51634], "temperature": 0.0, "avg_logprob": -0.22631045391685084, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.002757504815235734}, {"id": 790, "seek": 327422, "start": 3274.3799999999997, "end": 3281.4199999999996, "text": " They've basically got something that you can pass it a real, you know, patch from a bedroom", "tokens": [50372, 814, 600, 1936, 658, 746, 300, 291, 393, 1320, 309, 257, 957, 11, 291, 458, 11, 9972, 490, 257, 11211, 50724], "temperature": 0.0, "avg_logprob": -0.3169401486714681, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.0006166182574816048}, {"id": 791, "seek": 327422, "start": 3281.4199999999996, "end": 3292.74, "text": " scene and a fake patch from a bedroom scene.", "tokens": [50724, 4145, 293, 257, 7592, 9972, 490, 257, 11211, 4145, 13, 51290], "temperature": 0.0, "avg_logprob": -0.3169401486714681, "compression_ratio": 1.3737373737373737, "no_speech_prob": 0.0006166182574816048}, {"id": 792, "seek": 329274, "start": 3292.74, "end": 3304.9799999999996, "text": " And they both go into the, what's called the discriminator.", "tokens": [50364, 400, 436, 1293, 352, 666, 264, 11, 437, 311, 1219, 264, 20828, 1639, 13, 50976], "temperature": 0.0, "avg_logprob": -0.2655493907439403, "compression_ratio": 1.25, "no_speech_prob": 0.004133423790335655}, {"id": 793, "seek": 329274, "start": 3304.9799999999996, "end": 3312.7799999999997, "text": " And this is just a normal, you know, ResNet or whatever, which basically outputs something", "tokens": [50976, 400, 341, 307, 445, 257, 2710, 11, 291, 458, 11, 5015, 31890, 420, 2035, 11, 597, 1936, 23930, 746, 51366], "temperature": 0.0, "avg_logprob": -0.2655493907439403, "compression_ratio": 1.25, "no_speech_prob": 0.004133423790335655}, {"id": 794, "seek": 331278, "start": 3312.78, "end": 3322.1000000000004, "text": " that either says, yep, the image is real.", "tokens": [50364, 300, 2139, 1619, 11, 18633, 11, 264, 3256, 307, 957, 13, 50830], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 795, "seek": 331278, "start": 3322.1000000000004, "end": 3323.9, "text": " Or nope, the image is fake.", "tokens": [50830, 1610, 23444, 11, 264, 3256, 307, 7592, 13, 50920], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 796, "seek": 331278, "start": 3323.9, "end": 3325.98, "text": " So sorry, I said it passes in two things.", "tokens": [50920, 407, 2597, 11, 286, 848, 309, 11335, 294, 732, 721, 13, 51024], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 797, "seek": 331278, "start": 3325.98, "end": 3326.98, "text": " You just, that was wrong.", "tokens": [51024, 509, 445, 11, 300, 390, 2085, 13, 51074], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 798, "seek": 331278, "start": 3326.98, "end": 3330.26, "text": " You just pass in one thing and it returns either it's real or it's fake.", "tokens": [51074, 509, 445, 1320, 294, 472, 551, 293, 309, 11247, 2139, 309, 311, 957, 420, 309, 311, 7592, 13, 51238], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 799, "seek": 331278, "start": 3330.26, "end": 3336.0600000000004, "text": " And specifically it's going to give you something like the probability that it's real.", "tokens": [51238, 400, 4682, 309, 311, 516, 281, 976, 291, 746, 411, 264, 8482, 300, 309, 311, 957, 13, 51528], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 800, "seek": 331278, "start": 3336.0600000000004, "end": 3337.0600000000004, "text": " There is another version.", "tokens": [51528, 821, 307, 1071, 3037, 13, 51578], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 801, "seek": 331278, "start": 3337.0600000000004, "end": 3338.0600000000004, "text": " I don't think it's what they use.", "tokens": [51578, 286, 500, 380, 519, 309, 311, 437, 436, 764, 13, 51628], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 802, "seek": 331278, "start": 3338.0600000000004, "end": 3340.5400000000004, "text": " You pass in two and it tells you which one's relative.", "tokens": [51628, 509, 1320, 294, 732, 293, 309, 5112, 291, 597, 472, 311, 4972, 13, 51752], "temperature": 0.0, "avg_logprob": -0.290369447072347, "compression_ratio": 1.7457627118644068, "no_speech_prob": 0.030203429982066154}, {"id": 803, "seek": 334054, "start": 3340.82, "end": 3344.82, "text": " Do you remember, Tanisha, is it a relativistic GAN or a normal GAN?", "tokens": [50378, 1144, 291, 1604, 11, 314, 7524, 64, 11, 307, 309, 257, 21960, 3142, 460, 1770, 420, 257, 2710, 460, 1770, 30, 50578], "temperature": 0.0, "avg_logprob": -0.23692339116876776, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.03621360659599304}, {"id": 804, "seek": 334054, "start": 3344.82, "end": 3346.02, "text": " I think it's a normal one.", "tokens": [50578, 286, 519, 309, 311, 257, 2710, 472, 13, 50638], "temperature": 0.0, "avg_logprob": -0.23692339116876776, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.03621360659599304}, {"id": 805, "seek": 334054, "start": 3346.02, "end": 3347.02, "text": " Yeah.", "tokens": [50638, 865, 13, 50688], "temperature": 0.0, "avg_logprob": -0.23692339116876776, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.03621360659599304}, {"id": 806, "seek": 334054, "start": 3347.02, "end": 3350.7, "text": " So the relativistic GAN is when you pass in two images and it says which is more real.", "tokens": [50688, 407, 264, 21960, 3142, 460, 1770, 307, 562, 291, 1320, 294, 732, 5267, 293, 309, 1619, 597, 307, 544, 957, 13, 50872], "temperature": 0.0, "avg_logprob": -0.23692339116876776, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.03621360659599304}, {"id": 807, "seek": 334054, "start": 3350.7, "end": 3354.42, "text": " The one we think that we, if I remember correctly, they use as a regular GAN, which just tells", "tokens": [50872, 440, 472, 321, 519, 300, 321, 11, 498, 286, 1604, 8944, 11, 436, 764, 382, 257, 3890, 460, 1770, 11, 597, 445, 5112, 51058], "temperature": 0.0, "avg_logprob": -0.23692339116876776, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.03621360659599304}, {"id": 808, "seek": 334054, "start": 3354.42, "end": 3357.9, "text": " you the probability that it's real.", "tokens": [51058, 291, 264, 8482, 300, 309, 311, 957, 13, 51232], "temperature": 0.0, "avg_logprob": -0.23692339116876776, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.03621360659599304}, {"id": 809, "seek": 334054, "start": 3357.9, "end": 3362.46, "text": " And so you can just train that by passing in real images and fake images and having", "tokens": [51232, 400, 370, 291, 393, 445, 3847, 300, 538, 8437, 294, 957, 5267, 293, 7592, 5267, 293, 1419, 51460], "temperature": 0.0, "avg_logprob": -0.23692339116876776, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.03621360659599304}, {"id": 810, "seek": 334054, "start": 3362.46, "end": 3367.2599999999998, "text": " it learn to classify which ones are real and which ones are fake.", "tokens": [51460, 309, 1466, 281, 33872, 597, 2306, 366, 957, 293, 597, 2306, 366, 7592, 13, 51700], "temperature": 0.0, "avg_logprob": -0.23692339116876776, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.03621360659599304}, {"id": 811, "seek": 336726, "start": 3367.26, "end": 3374.1800000000003, "text": " So now that once you've got that model trained, then as you train your GAN, you pass in the", "tokens": [50364, 407, 586, 300, 1564, 291, 600, 658, 300, 2316, 8895, 11, 550, 382, 291, 3847, 428, 460, 1770, 11, 291, 1320, 294, 264, 50710], "temperature": 0.0, "avg_logprob": -0.2568363314089568, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0004583051195368171}, {"id": 812, "seek": 336726, "start": 3374.1800000000003, "end": 3383.6400000000003, "text": " patches of each image into the discriminator, let's call D here, right?", "tokens": [50710, 26531, 295, 1184, 3256, 666, 264, 20828, 1639, 11, 718, 311, 818, 413, 510, 11, 558, 30, 51183], "temperature": 0.0, "avg_logprob": -0.2568363314089568, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0004583051195368171}, {"id": 813, "seek": 336726, "start": 3383.6400000000003, "end": 3388.6400000000003, "text": " And it's going to spit out the probability that that's real.", "tokens": [51183, 400, 309, 311, 516, 281, 22127, 484, 264, 8482, 300, 300, 311, 957, 13, 51433], "temperature": 0.0, "avg_logprob": -0.2568363314089568, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0004583051195368171}, {"id": 814, "seek": 336726, "start": 3388.6400000000003, "end": 3397.1000000000004, "text": " And so if it spat out, you know, 0.1 or something, then you're like, oh dear, that's terrible.", "tokens": [51433, 400, 370, 498, 309, 15000, 484, 11, 291, 458, 11, 1958, 13, 16, 420, 746, 11, 550, 291, 434, 411, 11, 1954, 6875, 11, 300, 311, 6237, 13, 51856], "temperature": 0.0, "avg_logprob": -0.2568363314089568, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.0004583051195368171}, {"id": 815, "seek": 339710, "start": 3397.94, "end": 3403.66, "text": " Our VAE is spitting out pictures of bedrooms where the patches of it are easily recognized", "tokens": [50406, 2621, 18527, 36, 307, 637, 2414, 484, 5242, 295, 39955, 689, 264, 26531, 295, 309, 366, 3612, 9823, 50692], "temperature": 0.0, "avg_logprob": -0.23790317386775822, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00016346314805559814}, {"id": 816, "seek": 339710, "start": 3403.66, "end": 3405.54, "text": " as not real.", "tokens": [50692, 382, 406, 957, 13, 50786], "temperature": 0.0, "avg_logprob": -0.23790317386775822, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00016346314805559814}, {"id": 817, "seek": 339710, "start": 3405.54, "end": 3409.8199999999997, "text": " But the good news is that's going to generate derivatives, right?", "tokens": [50786, 583, 264, 665, 2583, 307, 300, 311, 516, 281, 8460, 33733, 11, 558, 30, 51000], "temperature": 0.0, "avg_logprob": -0.23790317386775822, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00016346314805559814}, {"id": 818, "seek": 339710, "start": 3409.8199999999997, "end": 3416.86, "text": " And so those derivatives then is going to tell you how to change the pixels of the original", "tokens": [51000, 400, 370, 729, 33733, 550, 307, 516, 281, 980, 291, 577, 281, 1319, 264, 18668, 295, 264, 3380, 51352], "temperature": 0.0, "avg_logprob": -0.23790317386775822, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00016346314805559814}, {"id": 819, "seek": 339710, "start": 3416.86, "end": 3422.48, "text": " generated image to make it trick the GAN better.", "tokens": [51352, 10833, 3256, 281, 652, 309, 4282, 264, 460, 1770, 1101, 13, 51633], "temperature": 0.0, "avg_logprob": -0.23790317386775822, "compression_ratio": 1.5346534653465347, "no_speech_prob": 0.00016346314805559814}, {"id": 820, "seek": 342248, "start": 3422.48, "end": 3431.52, "text": " And so what it'll do is it'll then use those derivatives as per usual to update our VAE.", "tokens": [50364, 400, 370, 437, 309, 603, 360, 307, 309, 603, 550, 764, 729, 33733, 382, 680, 7713, 281, 5623, 527, 18527, 36, 13, 50816], "temperature": 0.0, "avg_logprob": -0.21546831997958096, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.002472391352057457}, {"id": 821, "seek": 342248, "start": 3431.52, "end": 3437.16, "text": " And the VAE in this case is going to be called a generator, right?", "tokens": [50816, 400, 264, 18527, 36, 294, 341, 1389, 307, 516, 281, 312, 1219, 257, 19265, 11, 558, 30, 51098], "temperature": 0.0, "avg_logprob": -0.21546831997958096, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.002472391352057457}, {"id": 822, "seek": 342248, "start": 3437.16, "end": 3439.36, "text": " That's the thing that's generating the pixels.", "tokens": [51098, 663, 311, 264, 551, 300, 311, 17746, 264, 18668, 13, 51208], "temperature": 0.0, "avg_logprob": -0.21546831997958096, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.002472391352057457}, {"id": 823, "seek": 342248, "start": 3439.36, "end": 3445.38, "text": " And so the generator gets updated to be better and better at tricking the discriminator.", "tokens": [51208, 400, 370, 264, 19265, 2170, 10588, 281, 312, 1101, 293, 1101, 412, 4282, 278, 264, 20828, 1639, 13, 51509], "temperature": 0.0, "avg_logprob": -0.21546831997958096, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.002472391352057457}, {"id": 824, "seek": 342248, "start": 3445.38, "end": 3450.36, "text": " And after a while, what's going to happen is the generator is going to get so good that", "tokens": [51509, 400, 934, 257, 1339, 11, 437, 311, 516, 281, 1051, 307, 264, 19265, 307, 516, 281, 483, 370, 665, 300, 51758], "temperature": 0.0, "avg_logprob": -0.21546831997958096, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.002472391352057457}, {"id": 825, "seek": 345036, "start": 3450.36, "end": 3453.7200000000003, "text": " the discriminator gets fooled every time, right?", "tokens": [50364, 264, 20828, 1639, 2170, 33372, 633, 565, 11, 558, 30, 50532], "temperature": 0.0, "avg_logprob": -0.23713733240501167, "compression_ratio": 1.9339622641509433, "no_speech_prob": 0.00025315515813417733}, {"id": 826, "seek": 345036, "start": 3453.7200000000003, "end": 3459.92, "text": " And so then at that point, you can fine tune the discriminator better by putting in your", "tokens": [50532, 400, 370, 550, 412, 300, 935, 11, 291, 393, 2489, 10864, 264, 20828, 1639, 1101, 538, 3372, 294, 428, 50842], "temperature": 0.0, "avg_logprob": -0.23713733240501167, "compression_ratio": 1.9339622641509433, "no_speech_prob": 0.00025315515813417733}, {"id": 827, "seek": 345036, "start": 3459.92, "end": 3462.32, "text": " better generated images, right?", "tokens": [50842, 1101, 10833, 5267, 11, 558, 30, 50962], "temperature": 0.0, "avg_logprob": -0.23713733240501167, "compression_ratio": 1.9339622641509433, "no_speech_prob": 0.00025315515813417733}, {"id": 828, "seek": 345036, "start": 3462.32, "end": 3465.94, "text": " And then once your discriminator learns again how to recognize the difference between real", "tokens": [50962, 400, 550, 1564, 428, 20828, 1639, 27152, 797, 577, 281, 5521, 264, 2649, 1296, 957, 51143], "temperature": 0.0, "avg_logprob": -0.23713733240501167, "compression_ratio": 1.9339622641509433, "no_speech_prob": 0.00025315515813417733}, {"id": 829, "seek": 345036, "start": 3465.94, "end": 3470.6200000000003, "text": " and fake, you can then use it to train the generator.", "tokens": [51143, 293, 7592, 11, 291, 393, 550, 764, 309, 281, 3847, 264, 19265, 13, 51377], "temperature": 0.0, "avg_logprob": -0.23713733240501167, "compression_ratio": 1.9339622641509433, "no_speech_prob": 0.00025315515813417733}, {"id": 830, "seek": 345036, "start": 3470.6200000000003, "end": 3476.1200000000003, "text": " And so this is kind of ping ponging back and forth between the discriminator and the generator.", "tokens": [51377, 400, 370, 341, 307, 733, 295, 26151, 36164, 278, 646, 293, 5220, 1296, 264, 20828, 1639, 293, 264, 19265, 13, 51652], "temperature": 0.0, "avg_logprob": -0.23713733240501167, "compression_ratio": 1.9339622641509433, "no_speech_prob": 0.00025315515813417733}, {"id": 831, "seek": 347612, "start": 3476.12, "end": 3483.6, "text": " Back when GANs were first created, you know, people were finding them very difficult to", "tokens": [50364, 5833, 562, 460, 1770, 82, 645, 700, 2942, 11, 291, 458, 11, 561, 645, 5006, 552, 588, 2252, 281, 50738], "temperature": 0.0, "avg_logprob": -0.2576279596451226, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.008059707470238209}, {"id": 832, "seek": 347612, "start": 3483.6, "end": 3488.18, "text": " train and actually a method we developed at Fast.ai, I don't know if we were the first", "tokens": [50738, 3847, 293, 767, 257, 3170, 321, 4743, 412, 15968, 13, 1301, 11, 286, 500, 380, 458, 498, 321, 645, 264, 700, 50967], "temperature": 0.0, "avg_logprob": -0.2576279596451226, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.008059707470238209}, {"id": 833, "seek": 347612, "start": 3488.18, "end": 3495.4, "text": " to do it or not, was this idea of kind of pre-training a generator just using perceptual", "tokens": [50967, 281, 360, 309, 420, 406, 11, 390, 341, 1558, 295, 733, 295, 659, 12, 17227, 1760, 257, 19265, 445, 1228, 43276, 901, 51328], "temperature": 0.0, "avg_logprob": -0.2576279596451226, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.008059707470238209}, {"id": 834, "seek": 347612, "start": 3495.4, "end": 3499.72, "text": " loss and then pre-training a discriminator to be able to fool the generator and then", "tokens": [51328, 4470, 293, 550, 659, 12, 17227, 1760, 257, 20828, 1639, 281, 312, 1075, 281, 7979, 264, 19265, 293, 550, 51544], "temperature": 0.0, "avg_logprob": -0.2576279596451226, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.008059707470238209}, {"id": 835, "seek": 347612, "start": 3499.72, "end": 3505.5, "text": " ping ponging backwards and forwards between them after that, basically whenever the discriminator", "tokens": [51544, 26151, 36164, 278, 12204, 293, 30126, 1296, 552, 934, 300, 11, 1936, 5699, 264, 20828, 1639, 51833], "temperature": 0.0, "avg_logprob": -0.2576279596451226, "compression_ratio": 1.7088122605363985, "no_speech_prob": 0.008059707470238209}, {"id": 836, "seek": 350550, "start": 3505.58, "end": 3508.14, "text": " got too good, start using the generator.", "tokens": [50368, 658, 886, 665, 11, 722, 1228, 264, 19265, 13, 50496], "temperature": 0.0, "avg_logprob": -0.3507807731628418, "compression_ratio": 1.7062146892655368, "no_speech_prob": 0.0004044802626594901}, {"id": 837, "seek": 350550, "start": 3508.14, "end": 3510.94, "text": " Anytime the generator got too good, start using the discriminator.", "tokens": [50496, 39401, 264, 19265, 658, 886, 665, 11, 722, 1228, 264, 20828, 1639, 13, 50636], "temperature": 0.0, "avg_logprob": -0.3507807731628418, "compression_ratio": 1.7062146892655368, "no_speech_prob": 0.0004044802626594901}, {"id": 838, "seek": 350550, "start": 3510.94, "end": 3515.86, "text": " Nowadays that's pretty standard, I think, to do it this way.", "tokens": [50636, 28908, 300, 311, 1238, 3832, 11, 286, 519, 11, 281, 360, 309, 341, 636, 13, 50882], "temperature": 0.0, "avg_logprob": -0.3507807731628418, "compression_ratio": 1.7062146892655368, "no_speech_prob": 0.0004044802626594901}, {"id": 839, "seek": 350550, "start": 3515.86, "end": 3526.58, "text": " And so, yeah, this GAN loss, which is basically saying penalize for failing to fool the discriminator,", "tokens": [50882, 400, 370, 11, 1338, 11, 341, 460, 1770, 4470, 11, 597, 307, 1936, 1566, 13661, 1125, 337, 18223, 281, 7979, 264, 20828, 1639, 11, 51418], "temperature": 0.0, "avg_logprob": -0.3507807731628418, "compression_ratio": 1.7062146892655368, "no_speech_prob": 0.0004044802626594901}, {"id": 840, "seek": 350550, "start": 3526.58, "end": 3533.5, "text": " is called an adversarial loss.", "tokens": [51418, 307, 1219, 364, 17641, 44745, 4470, 13, 51764], "temperature": 0.0, "avg_logprob": -0.3507807731628418, "compression_ratio": 1.7062146892655368, "no_speech_prob": 0.0004044802626594901}, {"id": 841, "seek": 353350, "start": 3534.5, "end": 3540.9, "text": " To maybe motivate why you do this, if you just did it with like a mean squared error", "tokens": [50414, 1407, 1310, 28497, 983, 291, 360, 341, 11, 498, 291, 445, 630, 309, 365, 411, 257, 914, 8889, 6713, 50734], "temperature": 0.0, "avg_logprob": -0.2732411527085578, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0030732774175703526}, {"id": 842, "seek": 353350, "start": 3540.9, "end": 3548.06, "text": " or even a perceptual loss with such a high compression ratio, the VAEs tend to like produce", "tokens": [50734, 420, 754, 257, 43276, 901, 4470, 365, 1270, 257, 1090, 19355, 8509, 11, 264, 18527, 20442, 3928, 281, 411, 5258, 51092], "temperature": 0.0, "avg_logprob": -0.2732411527085578, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0030732774175703526}, {"id": 843, "seek": 353350, "start": 3548.06, "end": 3553.82, "text": " a fairly blurry output because it's not sure whether there's texture or not, you know,", "tokens": [51092, 257, 6457, 37644, 5598, 570, 309, 311, 406, 988, 1968, 456, 311, 8091, 420, 406, 11, 291, 458, 11, 51380], "temperature": 0.0, "avg_logprob": -0.2732411527085578, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0030732774175703526}, {"id": 844, "seek": 353350, "start": 3553.82, "end": 3557.7, "text": " in this image or the edges aren't like super well defined where they'll be because it's", "tokens": [51380, 294, 341, 3256, 420, 264, 8819, 3212, 380, 411, 1687, 731, 7642, 689, 436, 603, 312, 570, 309, 311, 51574], "temperature": 0.0, "avg_logprob": -0.2732411527085578, "compression_ratio": 1.5530973451327434, "no_speech_prob": 0.0030732774175703526}, {"id": 845, "seek": 355770, "start": 3557.74, "end": 3564.74, "text": " going from like one four dimensional thing up to like this whole patch of the image.", "tokens": [50366, 516, 490, 411, 472, 1451, 18795, 551, 493, 281, 411, 341, 1379, 9972, 295, 264, 3256, 13, 50716], "temperature": 0.0, "avg_logprob": -0.3165799750656378, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.09265187382698059}, {"id": 846, "seek": 355770, "start": 3564.74, "end": 3568.4199999999996, "text": " And so it tends to be a little bit blurry and hazy because it's kind of hedging its", "tokens": [50716, 400, 370, 309, 12258, 281, 312, 257, 707, 857, 37644, 293, 324, 1229, 570, 309, 311, 733, 295, 33653, 3249, 1080, 50900], "temperature": 0.0, "avg_logprob": -0.3165799750656378, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.09265187382698059}, {"id": 847, "seek": 355770, "start": 3568.4199999999996, "end": 3572.8999999999996, "text": " bets, whereas that's something that the discriminator can quite easily pick up.", "tokens": [50900, 39922, 11, 9735, 300, 311, 746, 300, 264, 20828, 1639, 393, 1596, 3612, 1888, 493, 13, 51124], "temperature": 0.0, "avg_logprob": -0.3165799750656378, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.09265187382698059}, {"id": 848, "seek": 355770, "start": 3572.8999999999996, "end": 3574.62, "text": " Oh, like it's blurry.", "tokens": [51124, 876, 11, 411, 309, 311, 37644, 13, 51210], "temperature": 0.0, "avg_logprob": -0.3165799750656378, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.09265187382698059}, {"id": 849, "seek": 355770, "start": 3574.62, "end": 3575.7, "text": " It must be fake, you know.", "tokens": [51210, 467, 1633, 312, 7592, 11, 291, 458, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3165799750656378, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.09265187382698059}, {"id": 850, "seek": 355770, "start": 3575.7, "end": 3579.7, "text": " And so then it's having the discriminator that is adversarial loss is just kind of saying", "tokens": [51264, 400, 370, 550, 309, 311, 1419, 264, 20828, 1639, 300, 307, 17641, 44745, 4470, 307, 445, 733, 295, 1566, 51464], "temperature": 0.0, "avg_logprob": -0.3165799750656378, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.09265187382698059}, {"id": 851, "seek": 355770, "start": 3579.7, "end": 3583.9399999999996, "text": " like even if you're not sure exactly where this texture goes, rather go with a sharper", "tokens": [51464, 411, 754, 498, 291, 434, 406, 988, 2293, 689, 341, 8091, 1709, 11, 2831, 352, 365, 257, 44670, 51676], "temperature": 0.0, "avg_logprob": -0.3165799750656378, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.09265187382698059}, {"id": 852, "seek": 358394, "start": 3584.02, "end": 3590.02, "text": " looking texture that looks real than with some blurry thing that's going to maximize", "tokens": [50368, 1237, 8091, 300, 1542, 957, 813, 365, 512, 37644, 551, 300, 311, 516, 281, 19874, 50668], "temperature": 0.0, "avg_logprob": -0.3517820659436678, "compression_ratio": 1.5739130434782609, "no_speech_prob": 0.14998172223567963}, {"id": 853, "seek": 358394, "start": 3590.02, "end": 3591.02, "text": " your MSC.", "tokens": [50668, 428, 7395, 34, 13, 50718], "temperature": 0.0, "avg_logprob": -0.3517820659436678, "compression_ratio": 1.5739130434782609, "no_speech_prob": 0.14998172223567963}, {"id": 854, "seek": 358394, "start": 3591.02, "end": 3597.2200000000003, "text": " And so it like tricks it into kind of faking this high resolution looking sharper output.", "tokens": [50718, 400, 370, 309, 411, 11733, 309, 666, 733, 295, 283, 2456, 341, 1090, 8669, 1237, 44670, 5598, 13, 51028], "temperature": 0.0, "avg_logprob": -0.3517820659436678, "compression_ratio": 1.5739130434782609, "no_speech_prob": 0.14998172223567963}, {"id": 855, "seek": 358394, "start": 3599.06, "end": 3605.86, "text": " Yeah, and I'm not sure if we're going to come back and like train our own GAN at some point,", "tokens": [51120, 865, 11, 293, 286, 478, 406, 988, 498, 321, 434, 516, 281, 808, 646, 293, 411, 3847, 527, 1065, 460, 1770, 412, 512, 935, 11, 51460], "temperature": 0.0, "avg_logprob": -0.3517820659436678, "compression_ratio": 1.5739130434782609, "no_speech_prob": 0.14998172223567963}, {"id": 856, "seek": 358394, "start": 3605.86, "end": 3612.86, "text": " but if you're interested in training your own GAN or I mean, you shouldn't call it a", "tokens": [51460, 457, 498, 291, 434, 3102, 294, 3097, 428, 1065, 460, 1770, 420, 286, 914, 11, 291, 4659, 380, 818, 309, 257, 51810], "temperature": 0.0, "avg_logprob": -0.3517820659436678, "compression_ratio": 1.5739130434782609, "no_speech_prob": 0.14998172223567963}, {"id": 857, "seek": 361286, "start": 3612.86, "end": 3613.86, "text": " GAN, right?", "tokens": [50364, 460, 1770, 11, 558, 30, 50414], "temperature": 0.0, "avg_logprob": -0.37451331129351867, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.0005033084307797253}, {"id": 858, "seek": 361286, "start": 3613.86, "end": 3618.1, "text": " I mean, nowadays we never really just use a GAN.", "tokens": [50414, 286, 914, 11, 13434, 321, 1128, 534, 445, 764, 257, 460, 1770, 13, 50626], "temperature": 0.0, "avg_logprob": -0.37451331129351867, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.0005033084307797253}, {"id": 859, "seek": 361286, "start": 3618.1, "end": 3621.02, "text": " We have an adversarial loss as part of a training process.", "tokens": [50626, 492, 362, 364, 17641, 44745, 4470, 382, 644, 295, 257, 3097, 1399, 13, 50772], "temperature": 0.0, "avg_logprob": -0.37451331129351867, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.0005033084307797253}, {"id": 860, "seek": 361286, "start": 3621.02, "end": 3625.42, "text": " If you want to learn how to use adversarial loss, like in detail and see the code, the", "tokens": [50772, 759, 291, 528, 281, 1466, 577, 281, 764, 17641, 44745, 4470, 11, 411, 294, 2607, 293, 536, 264, 3089, 11, 264, 50992], "temperature": 0.0, "avg_logprob": -0.37451331129351867, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.0005033084307797253}, {"id": 861, "seek": 361286, "start": 3625.42, "end": 3632.1, "text": " 2019 fast AI course, lesson seven, part one has a walkthrough.", "tokens": [50992, 6071, 2370, 7318, 1164, 11, 6898, 3407, 11, 644, 472, 575, 257, 1792, 11529, 13, 51326], "temperature": 0.0, "avg_logprob": -0.37451331129351867, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.0005033084307797253}, {"id": 862, "seek": 361286, "start": 3632.1, "end": 3636.86, "text": " So we have sample code there and you know, yeah, maybe given time we'll come back to it.", "tokens": [51326, 407, 321, 362, 6889, 3089, 456, 293, 291, 458, 11, 1338, 11, 1310, 2212, 565, 321, 603, 808, 646, 281, 309, 13, 51564], "temperature": 0.0, "avg_logprob": -0.37451331129351867, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.0005033084307797253}, {"id": 863, "seek": 363686, "start": 3636.86, "end": 3637.86, "text": " Okay.", "tokens": [50364, 1033, 13, 50414], "temperature": 0.0, "avg_logprob": -0.3040261949811663, "compression_ratio": 1.5052083333333333, "no_speech_prob": 2.210953061876353e-05}, {"id": 864, "seek": 363686, "start": 3637.86, "end": 3653.42, "text": " So quite often people will call the VAE encoder when they're training a model, which to me", "tokens": [50414, 407, 1596, 2049, 561, 486, 818, 264, 18527, 36, 2058, 19866, 562, 436, 434, 3097, 257, 2316, 11, 597, 281, 385, 51192], "temperature": 0.0, "avg_logprob": -0.3040261949811663, "compression_ratio": 1.5052083333333333, "no_speech_prob": 2.210953061876353e-05}, {"id": 865, "seek": 363686, "start": 3653.42, "end": 3654.7400000000002, "text": " makes no sense, right?", "tokens": [51192, 1669, 572, 2020, 11, 558, 30, 51258], "temperature": 0.0, "avg_logprob": -0.3040261949811663, "compression_ratio": 1.5052083333333333, "no_speech_prob": 2.210953061876353e-05}, {"id": 866, "seek": 363686, "start": 3654.7400000000002, "end": 3660.98, "text": " Because the encoded version of an image never changes unless you are using data augmentation", "tokens": [51258, 1436, 264, 2058, 12340, 3037, 295, 364, 3256, 1128, 2962, 5969, 291, 366, 1228, 1412, 14501, 19631, 51570], "temperature": 0.0, "avg_logprob": -0.3040261949811663, "compression_ratio": 1.5052083333333333, "no_speech_prob": 2.210953061876353e-05}, {"id": 867, "seek": 363686, "start": 3660.98, "end": 3666.34, "text": " and want to do augmentation on, sorry, do you know, encode augmented images.", "tokens": [51570, 293, 528, 281, 360, 14501, 19631, 322, 11, 2597, 11, 360, 291, 458, 11, 2058, 1429, 36155, 5267, 13, 51838], "temperature": 0.0, "avg_logprob": -0.3040261949811663, "compression_ratio": 1.5052083333333333, "no_speech_prob": 2.210953061876353e-05}, {"id": 868, "seek": 366634, "start": 3666.34, "end": 3670.5, "text": " I think it makes a lot more sense to just do a single run through your whole training", "tokens": [50364, 286, 519, 309, 1669, 257, 688, 544, 2020, 281, 445, 360, 257, 2167, 1190, 807, 428, 1379, 3097, 50572], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 869, "seek": 366634, "start": 3670.5, "end": 3672.78, "text": " set and encode everything once.", "tokens": [50572, 992, 293, 2058, 1429, 1203, 1564, 13, 50686], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 870, "seek": 366634, "start": 3672.78, "end": 3676.1400000000003, "text": " So naturally the question is then, well, what do you, where do you save that?", "tokens": [50686, 407, 8195, 264, 1168, 307, 550, 11, 731, 11, 437, 360, 291, 11, 689, 360, 291, 3155, 300, 30, 50854], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 871, "seek": 366634, "start": 3676.1400000000003, "end": 3678.58, "text": " So it's going to be a lot of RAM.", "tokens": [50854, 407, 309, 311, 516, 281, 312, 257, 688, 295, 14561, 13, 50976], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 872, "seek": 366634, "start": 3678.58, "end": 3679.82, "text": " If you put this, leave it in RAM.", "tokens": [50976, 759, 291, 829, 341, 11, 1856, 309, 294, 14561, 13, 51038], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 873, "seek": 366634, "start": 3679.82, "end": 3683.1000000000004, "text": " And also if you, you know, as soon as you restart your computer, we've lost all that", "tokens": [51038, 400, 611, 498, 291, 11, 291, 458, 11, 382, 2321, 382, 291, 21022, 428, 3820, 11, 321, 600, 2731, 439, 300, 51202], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 874, "seek": 366634, "start": 3683.1000000000004, "end": 3684.54, "text": " work.", "tokens": [51202, 589, 13, 51274], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 875, "seek": 366634, "start": 3684.54, "end": 3692.34, "text": " There's a very nifty file format you can use called a memory mapped NumPy file, which is", "tokens": [51274, 821, 311, 257, 588, 297, 37177, 3991, 7877, 291, 393, 764, 1219, 257, 4675, 33318, 22592, 47, 88, 3991, 11, 597, 307, 51664], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 876, "seek": 366634, "start": 3692.34, "end": 3695.34, "text": " what I'm going to use to save our latency.", "tokens": [51664, 437, 286, 478, 516, 281, 764, 281, 3155, 527, 27043, 13, 51814], "temperature": 0.0, "avg_logprob": -0.26146465328568264, "compression_ratio": 1.6308724832214765, "no_speech_prob": 6.709103763569146e-05}, {"id": 877, "seek": 369534, "start": 3695.34, "end": 3703.7400000000002, "text": " A memory mapped NumPy file is basically what happens is you take the memory in RAM that", "tokens": [50364, 316, 4675, 33318, 22592, 47, 88, 3991, 307, 1936, 437, 2314, 307, 291, 747, 264, 4675, 294, 14561, 300, 50784], "temperature": 0.0, "avg_logprob": -0.26120352972121463, "compression_ratio": 1.748917748917749, "no_speech_prob": 3.944234049413353e-05}, {"id": 878, "seek": 369534, "start": 3703.7400000000002, "end": 3713.5, "text": " NumPy would normally be using, and you literally like copy it onto the hard disk, basically.", "tokens": [50784, 22592, 47, 88, 576, 5646, 312, 1228, 11, 293, 291, 3736, 411, 5055, 309, 3911, 264, 1152, 12355, 11, 1936, 13, 51272], "temperature": 0.0, "avg_logprob": -0.26120352972121463, "compression_ratio": 1.748917748917749, "no_speech_prob": 3.944234049413353e-05}, {"id": 879, "seek": 369534, "start": 3713.5, "end": 3715.02, "text": " That's what they mean by memory mapped.", "tokens": [51272, 663, 311, 437, 436, 914, 538, 4675, 33318, 13, 51348], "temperature": 0.0, "avg_logprob": -0.26120352972121463, "compression_ratio": 1.748917748917749, "no_speech_prob": 3.944234049413353e-05}, {"id": 880, "seek": 369534, "start": 3715.02, "end": 3719.42, "text": " There's a mapping between the memory in RAM and the memory on hard disk.", "tokens": [51348, 821, 311, 257, 18350, 1296, 264, 4675, 294, 14561, 293, 264, 4675, 322, 1152, 12355, 13, 51568], "temperature": 0.0, "avg_logprob": -0.26120352972121463, "compression_ratio": 1.748917748917749, "no_speech_prob": 3.944234049413353e-05}, {"id": 881, "seek": 369534, "start": 3719.42, "end": 3721.94, "text": " And if you change one, it changes the other and vice versa.", "tokens": [51568, 400, 498, 291, 1319, 472, 11, 309, 2962, 264, 661, 293, 11964, 25650, 13, 51694], "temperature": 0.0, "avg_logprob": -0.26120352972121463, "compression_ratio": 1.748917748917749, "no_speech_prob": 3.944234049413353e-05}, {"id": 882, "seek": 369534, "start": 3721.94, "end": 3724.5, "text": " They're kind of two ways of seeing the same thing.", "tokens": [51694, 814, 434, 733, 295, 732, 2098, 295, 2577, 264, 912, 551, 13, 51822], "temperature": 0.0, "avg_logprob": -0.26120352972121463, "compression_ratio": 1.748917748917749, "no_speech_prob": 3.944234049413353e-05}, {"id": 883, "seek": 372450, "start": 3724.66, "end": 3731.82, "text": " And so if you, and so if you create a memory mapped NumPy array, then when you modify it,", "tokens": [50372, 400, 370, 498, 291, 11, 293, 370, 498, 291, 1884, 257, 4675, 33318, 22592, 47, 88, 10225, 11, 550, 562, 291, 16927, 309, 11, 50730], "temperature": 0.0, "avg_logprob": -0.2083157157897949, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.451035222999053e-05}, {"id": 884, "seek": 372450, "start": 3731.82, "end": 3734.86, "text": " it's actually modifying it on disk.", "tokens": [50730, 309, 311, 767, 42626, 309, 322, 12355, 13, 50882], "temperature": 0.0, "avg_logprob": -0.2083157157897949, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.451035222999053e-05}, {"id": 885, "seek": 372450, "start": 3734.86, "end": 3740.14, "text": " But thanks to the magic of your operating system, it's using all kinds of beautiful", "tokens": [50882, 583, 3231, 281, 264, 5585, 295, 428, 7447, 1185, 11, 309, 311, 1228, 439, 3685, 295, 2238, 51146], "temperature": 0.0, "avg_logprob": -0.2083157157897949, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.451035222999053e-05}, {"id": 886, "seek": 372450, "start": 3740.14, "end": 3747.58, "text": " caching and stuff to not make that slower than using a normal NumPy array.", "tokens": [51146, 269, 2834, 293, 1507, 281, 406, 652, 300, 14009, 813, 1228, 257, 2710, 22592, 47, 88, 10225, 13, 51518], "temperature": 0.0, "avg_logprob": -0.2083157157897949, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.451035222999053e-05}, {"id": 887, "seek": 372450, "start": 3747.58, "end": 3753.82, "text": " And it's going to be very clever at, it doesn't have to store it all in RAM.", "tokens": [51518, 400, 309, 311, 516, 281, 312, 588, 13494, 412, 11, 309, 1177, 380, 362, 281, 3531, 309, 439, 294, 14561, 13, 51830], "temperature": 0.0, "avg_logprob": -0.2083157157897949, "compression_ratio": 1.6261261261261262, "no_speech_prob": 1.451035222999053e-05}, {"id": 888, "seek": 375382, "start": 3753.82, "end": 3757.9, "text": " It only stores the bits in RAM that you need at the moment or that you've used recently.", "tokens": [50364, 467, 787, 9512, 264, 9239, 294, 14561, 300, 291, 643, 412, 264, 1623, 420, 300, 291, 600, 1143, 3938, 13, 50568], "temperature": 0.0, "avg_logprob": -0.22878715460248988, "compression_ratio": 1.8129770992366412, "no_speech_prob": 1.280546985071851e-05}, {"id": 889, "seek": 375382, "start": 3757.9, "end": 3759.7400000000002, "text": " It's really nifty, a kind of caching and stuff.", "tokens": [50568, 467, 311, 534, 297, 37177, 11, 257, 733, 295, 269, 2834, 293, 1507, 13, 50660], "temperature": 0.0, "avg_logprob": -0.22878715460248988, "compression_ratio": 1.8129770992366412, "no_speech_prob": 1.280546985071851e-05}, {"id": 890, "seek": 375382, "start": 3759.7400000000002, "end": 3764.82, "text": " So it's kind of, it's like magic, but it's using the, your operating system to do that", "tokens": [50660, 407, 309, 311, 733, 295, 11, 309, 311, 411, 5585, 11, 457, 309, 311, 1228, 264, 11, 428, 7447, 1185, 281, 360, 300, 50914], "temperature": 0.0, "avg_logprob": -0.22878715460248988, "compression_ratio": 1.8129770992366412, "no_speech_prob": 1.280546985071851e-05}, {"id": 891, "seek": 375382, "start": 3764.82, "end": 3766.6200000000003, "text": " magic for you.", "tokens": [50914, 5585, 337, 291, 13, 51004], "temperature": 0.0, "avg_logprob": -0.22878715460248988, "compression_ratio": 1.8129770992366412, "no_speech_prob": 1.280546985071851e-05}, {"id": 892, "seek": 375382, "start": 3766.6200000000003, "end": 3772.6200000000003, "text": " So we're going to create a memory mapped file using np.memmap.", "tokens": [51004, 407, 321, 434, 516, 281, 1884, 257, 4675, 33318, 3991, 1228, 33808, 13, 17886, 24223, 13, 51304], "temperature": 0.0, "avg_logprob": -0.22878715460248988, "compression_ratio": 1.8129770992366412, "no_speech_prob": 1.280546985071851e-05}, {"id": 893, "seek": 375382, "start": 3772.6200000000003, "end": 3775.1000000000004, "text": " And so it's going to be stored somewhere on your disk, right?", "tokens": [51304, 400, 370, 309, 311, 516, 281, 312, 12187, 4079, 322, 428, 12355, 11, 558, 30, 51428], "temperature": 0.0, "avg_logprob": -0.22878715460248988, "compression_ratio": 1.8129770992366412, "no_speech_prob": 1.280546985071851e-05}, {"id": 894, "seek": 375382, "start": 3775.1000000000004, "end": 3777.5800000000004, "text": " So we're just going to put it here.", "tokens": [51428, 407, 321, 434, 445, 516, 281, 829, 309, 510, 13, 51552], "temperature": 0.0, "avg_logprob": -0.22878715460248988, "compression_ratio": 1.8129770992366412, "no_speech_prob": 1.280546985071851e-05}, {"id": 895, "seek": 375382, "start": 3777.5800000000004, "end": 3780.9, "text": " And we're going to say, okay, so create a memory mapped file in this place.", "tokens": [51552, 400, 321, 434, 516, 281, 584, 11, 1392, 11, 370, 1884, 257, 4675, 33318, 3991, 294, 341, 1081, 13, 51718], "temperature": 0.0, "avg_logprob": -0.22878715460248988, "compression_ratio": 1.8129770992366412, "no_speech_prob": 1.280546985071851e-05}, {"id": 896, "seek": 378090, "start": 3780.98, "end": 3784.46, "text": " And it's going to contain 32 bit floats.", "tokens": [50368, 400, 309, 311, 516, 281, 5304, 8858, 857, 37878, 13, 50542], "temperature": 0.0, "avg_logprob": -0.29511598285875823, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.883104000124149e-05}, {"id": 897, "seek": 378090, "start": 3784.46, "end": 3786.7000000000003, "text": " So write the file.", "tokens": [50542, 407, 2464, 264, 3991, 13, 50654], "temperature": 0.0, "avg_logprob": -0.29511598285875823, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.883104000124149e-05}, {"id": 898, "seek": 378090, "start": 3786.7000000000003, "end": 3790.98, "text": " And the shape of this array is going to be the size of our dataset.", "tokens": [50654, 400, 264, 3909, 295, 341, 10225, 307, 516, 281, 312, 264, 2744, 295, 527, 28872, 13, 50868], "temperature": 0.0, "avg_logprob": -0.29511598285875823, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.883104000124149e-05}, {"id": 899, "seek": 378090, "start": 3790.98, "end": 3796.9, "text": " So 303,125 images, and each one is 4 by 32 by 32.", "tokens": [50868, 407, 2217, 18, 11, 48804, 5267, 11, 293, 1184, 472, 307, 1017, 538, 8858, 538, 8858, 13, 51164], "temperature": 0.0, "avg_logprob": -0.29511598285875823, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.883104000124149e-05}, {"id": 900, "seek": 378090, "start": 3796.9, "end": 3801.42, "text": " Okay, so that's our memory mapped file.", "tokens": [51164, 1033, 11, 370, 300, 311, 527, 4675, 33318, 3991, 13, 51390], "temperature": 0.0, "avg_logprob": -0.29511598285875823, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.883104000124149e-05}, {"id": 901, "seek": 378090, "start": 3801.42, "end": 3809.2200000000003, "text": " And so now we're going to go through our data loader, one mini batch of 24 at a time.", "tokens": [51390, 400, 370, 586, 321, 434, 516, 281, 352, 807, 527, 1412, 3677, 260, 11, 472, 8382, 15245, 295, 4022, 412, 257, 565, 13, 51780], "temperature": 0.0, "avg_logprob": -0.29511598285875823, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.883104000124149e-05}, {"id": 902, "seek": 380922, "start": 3809.22, "end": 3814.5, "text": " And we're going to VAE encode that mini batch.", "tokens": [50364, 400, 321, 434, 516, 281, 18527, 36, 2058, 1429, 300, 8382, 15245, 13, 50628], "temperature": 0.0, "avg_logprob": -0.2535131827168081, "compression_ratio": 1.5051546391752577, "no_speech_prob": 2.8409687729435973e-05}, {"id": 903, "seek": 380922, "start": 3814.5, "end": 3819.54, "text": " And then we're going to grab the means from its latency, right?", "tokens": [50628, 400, 550, 321, 434, 516, 281, 4444, 264, 1355, 490, 1080, 27043, 11, 558, 30, 50880], "temperature": 0.0, "avg_logprob": -0.2535131827168081, "compression_ratio": 1.5051546391752577, "no_speech_prob": 2.8409687729435973e-05}, {"id": 904, "seek": 380922, "start": 3819.54, "end": 3825.98, "text": " We don't want random numbers, we want the actual, you know, the midpoints, the means.", "tokens": [50880, 492, 500, 380, 528, 4974, 3547, 11, 321, 528, 264, 3539, 11, 291, 458, 11, 264, 2062, 20552, 11, 264, 1355, 13, 51202], "temperature": 0.0, "avg_logprob": -0.2535131827168081, "compression_ratio": 1.5051546391752577, "no_speech_prob": 2.8409687729435973e-05}, {"id": 905, "seek": 380922, "start": 3825.98, "end": 3832.0, "text": " So this is using the diffuser's version of that VAE.", "tokens": [51202, 407, 341, 307, 1228, 264, 7593, 18088, 311, 3037, 295, 300, 18527, 36, 13, 51503], "temperature": 0.0, "avg_logprob": -0.2535131827168081, "compression_ratio": 1.5051546391752577, "no_speech_prob": 2.8409687729435973e-05}, {"id": 906, "seek": 380922, "start": 3832.0, "end": 3834.8199999999997, "text": " So pop that onto the CPU after we're done.", "tokens": [51503, 407, 1665, 300, 3911, 264, 13199, 934, 321, 434, 1096, 13, 51644], "temperature": 0.0, "avg_logprob": -0.2535131827168081, "compression_ratio": 1.5051546391752577, "no_speech_prob": 2.8409687729435973e-05}, {"id": 907, "seek": 383482, "start": 3834.9, "end": 3839.34, "text": " And so that's going to be mini batch of size 64 as PyTorch.", "tokens": [50368, 400, 370, 300, 311, 516, 281, 312, 8382, 15245, 295, 2744, 12145, 382, 9953, 51, 284, 339, 13, 50590], "temperature": 0.0, "avg_logprob": -0.24964843257780997, "compression_ratio": 1.624, "no_speech_prob": 0.0005357488407753408}, {"id": 908, "seek": 383482, "start": 3839.34, "end": 3842.7000000000003, "text": " Let's turn that into NumPy, because PyTorch doesn't have a memory mapped thing, as far", "tokens": [50590, 961, 311, 1261, 300, 666, 22592, 47, 88, 11, 570, 9953, 51, 284, 339, 1177, 380, 362, 257, 4675, 33318, 551, 11, 382, 1400, 50758], "temperature": 0.0, "avg_logprob": -0.24964843257780997, "compression_ratio": 1.624, "no_speech_prob": 0.0005357488407753408}, {"id": 909, "seek": 383482, "start": 3842.7000000000003, "end": 3844.7000000000003, "text": " as I'm aware, but NumPy does.", "tokens": [50758, 382, 286, 478, 3650, 11, 457, 22592, 47, 88, 775, 13, 50858], "temperature": 0.0, "avg_logprob": -0.24964843257780997, "compression_ratio": 1.624, "no_speech_prob": 0.0005357488407753408}, {"id": 910, "seek": 383482, "start": 3844.7000000000003, "end": 3850.5800000000004, "text": " And so now that we've got this memory mapped array called A, then everything from, initially", "tokens": [50858, 400, 370, 586, 300, 321, 600, 658, 341, 4675, 33318, 10225, 1219, 316, 11, 550, 1203, 490, 11, 9105, 51152], "temperature": 0.0, "avg_logprob": -0.24964843257780997, "compression_ratio": 1.624, "no_speech_prob": 0.0005357488407753408}, {"id": 911, "seek": 383482, "start": 3850.5800000000004, "end": 3860.9, "text": " from 0 up to 64, or 60, yeah, 0 to 64, not including the 64, that whole sub part of the", "tokens": [51152, 490, 1958, 493, 281, 12145, 11, 420, 4060, 11, 1338, 11, 1958, 281, 12145, 11, 406, 3009, 264, 12145, 11, 300, 1379, 1422, 644, 295, 264, 51668], "temperature": 0.0, "avg_logprob": -0.24964843257780997, "compression_ratio": 1.624, "no_speech_prob": 0.0005357488407753408}, {"id": 912, "seek": 383482, "start": 3860.9, "end": 3864.06, "text": " array is going to be set to the encoded version.", "tokens": [51668, 10225, 307, 516, 281, 312, 992, 281, 264, 2058, 12340, 3037, 13, 51826], "temperature": 0.0, "avg_logprob": -0.24964843257780997, "compression_ratio": 1.624, "no_speech_prob": 0.0005357488407753408}, {"id": 913, "seek": 386406, "start": 3864.2999999999997, "end": 3868.7799999999997, "text": " So it looks like we're just changing it in memory.", "tokens": [50376, 407, 309, 1542, 411, 321, 434, 445, 4473, 309, 294, 4675, 13, 50600], "temperature": 0.0, "avg_logprob": -0.2796870596040555, "compression_ratio": 1.681992337164751, "no_speech_prob": 2.710869193833787e-05}, {"id": 914, "seek": 386406, "start": 3868.7799999999997, "end": 3871.98, "text": " But because this is a magic memory mapped file, it's actually going to save it to disk", "tokens": [50600, 583, 570, 341, 307, 257, 5585, 4675, 33318, 3991, 11, 309, 311, 767, 516, 281, 3155, 309, 281, 12355, 50760], "temperature": 0.0, "avg_logprob": -0.2796870596040555, "compression_ratio": 1.681992337164751, "no_speech_prob": 2.710869193833787e-05}, {"id": 915, "seek": 386406, "start": 3871.98, "end": 3872.98, "text": " as well.", "tokens": [50760, 382, 731, 13, 50810], "temperature": 0.0, "avg_logprob": -0.2796870596040555, "compression_ratio": 1.681992337164751, "no_speech_prob": 2.710869193833787e-05}, {"id": 916, "seek": 386406, "start": 3872.98, "end": 3877.62, "text": " So yeah, that's it, amazingly enough.", "tokens": [50810, 407, 1338, 11, 300, 311, 309, 11, 31762, 1547, 13, 51042], "temperature": 0.0, "avg_logprob": -0.2796870596040555, "compression_ratio": 1.681992337164751, "no_speech_prob": 2.710869193833787e-05}, {"id": 917, "seek": 386406, "start": 3877.62, "end": 3883.02, "text": " That's all you need to create a memory mapped NumPy array of our latency.", "tokens": [51042, 663, 311, 439, 291, 643, 281, 1884, 257, 4675, 33318, 22592, 47, 88, 10225, 295, 527, 27043, 13, 51312], "temperature": 0.0, "avg_logprob": -0.2796870596040555, "compression_ratio": 1.681992337164751, "no_speech_prob": 2.710869193833787e-05}, {"id": 918, "seek": 386406, "start": 3883.02, "end": 3886.86, "text": " When you're done, you actually have to call .flush, and that's just something that says,", "tokens": [51312, 1133, 291, 434, 1096, 11, 291, 767, 362, 281, 818, 2411, 3423, 1498, 11, 293, 300, 311, 445, 746, 300, 1619, 11, 51504], "temperature": 0.0, "avg_logprob": -0.2796870596040555, "compression_ratio": 1.681992337164751, "no_speech_prob": 2.710869193833787e-05}, {"id": 919, "seek": 386406, "start": 3886.86, "end": 3889.82, "text": " like, anything that's just in cache at the moment, make sure it's actually written to", "tokens": [51504, 411, 11, 1340, 300, 311, 445, 294, 19459, 412, 264, 1623, 11, 652, 988, 309, 311, 767, 3720, 281, 51652], "temperature": 0.0, "avg_logprob": -0.2796870596040555, "compression_ratio": 1.681992337164751, "no_speech_prob": 2.710869193833787e-05}, {"id": 920, "seek": 386406, "start": 3889.82, "end": 3892.7799999999997, "text": " disk.", "tokens": [51652, 12355, 13, 51800], "temperature": 0.0, "avg_logprob": -0.2796870596040555, "compression_ratio": 1.681992337164751, "no_speech_prob": 2.710869193833787e-05}, {"id": 921, "seek": 389278, "start": 3893.5, "end": 3898.02, "text": " Then I delete it, because I just want to make sure that then I read it back correctly.", "tokens": [50400, 1396, 286, 12097, 309, 11, 570, 286, 445, 528, 281, 652, 988, 300, 550, 286, 1401, 309, 646, 8944, 13, 50626], "temperature": 0.0, "avg_logprob": -0.32954097779329156, "compression_ratio": 1.6653225806451613, "no_speech_prob": 5.4759653721703216e-05}, {"id": 922, "seek": 389278, "start": 3898.02, "end": 3903.1400000000003, "text": " So that's only going to happen once, if the path doesn't exist.", "tokens": [50626, 407, 300, 311, 787, 516, 281, 1051, 1564, 11, 498, 264, 3100, 1177, 380, 2514, 13, 50882], "temperature": 0.0, "avg_logprob": -0.32954097779329156, "compression_ratio": 1.6653225806451613, "no_speech_prob": 5.4759653721703216e-05}, {"id": 923, "seek": 389278, "start": 3903.1400000000003, "end": 3905.98, "text": " And then after that, this whole thing will be skipped, and instead we're going to call", "tokens": [50882, 400, 550, 934, 300, 11, 341, 1379, 551, 486, 312, 30193, 11, 293, 2602, 321, 434, 516, 281, 818, 51024], "temperature": 0.0, "avg_logprob": -0.32954097779329156, "compression_ratio": 1.6653225806451613, "no_speech_prob": 5.4759653721703216e-05}, {"id": 924, "seek": 389278, "start": 3905.98, "end": 3912.7000000000003, "text": " mp.memmap again, with our mpath, but this time in the same data type, in the same shape,", "tokens": [51024, 275, 79, 13, 17886, 24223, 797, 11, 365, 527, 275, 31852, 11, 457, 341, 565, 294, 264, 912, 1412, 2010, 11, 294, 264, 912, 3909, 11, 51360], "temperature": 0.0, "avg_logprob": -0.32954097779329156, "compression_ratio": 1.6653225806451613, "no_speech_prob": 5.4759653721703216e-05}, {"id": 925, "seek": 389278, "start": 3912.7000000000003, "end": 3913.7000000000003, "text": " this time we're going to read it.", "tokens": [51360, 341, 565, 321, 434, 516, 281, 1401, 309, 13, 51410], "temperature": 0.0, "avg_logprob": -0.32954097779329156, "compression_ratio": 1.6653225806451613, "no_speech_prob": 5.4759653721703216e-05}, {"id": 926, "seek": 389278, "start": 3913.7000000000003, "end": 3917.86, "text": " Node equals R, means read it.", "tokens": [51410, 38640, 6915, 497, 11, 1355, 1401, 309, 13, 51618], "temperature": 0.0, "avg_logprob": -0.32954097779329156, "compression_ratio": 1.6653225806451613, "no_speech_prob": 5.4759653721703216e-05}, {"id": 927, "seek": 389278, "start": 3917.86, "end": 3919.0600000000004, "text": " And so let's check it.", "tokens": [51618, 400, 370, 718, 311, 1520, 309, 13, 51678], "temperature": 0.0, "avg_logprob": -0.32954097779329156, "compression_ratio": 1.6653225806451613, "no_speech_prob": 5.4759653721703216e-05}, {"id": 928, "seek": 391906, "start": 3919.06, "end": 3926.02, "text": " Let's just grab the first 16 latents that we read, and decode them.", "tokens": [50364, 961, 311, 445, 4444, 264, 700, 3165, 4465, 791, 300, 321, 1401, 11, 293, 979, 1429, 552, 13, 50712], "temperature": 0.0, "avg_logprob": -0.2769166042930202, "compression_ratio": 1.4490740740740742, "no_speech_prob": 9.610033157514408e-05}, {"id": 929, "seek": 391906, "start": 3926.02, "end": 3928.02, "text": " And there they are.", "tokens": [50712, 400, 456, 436, 366, 13, 50812], "temperature": 0.0, "avg_logprob": -0.2769166042930202, "compression_ratio": 1.4490740740740742, "no_speech_prob": 9.610033157514408e-05}, {"id": 930, "seek": 391906, "start": 3928.02, "end": 3937.1, "text": " So this is, like, not a very well-known technique, I would say, sadly.", "tokens": [50812, 407, 341, 307, 11, 411, 11, 406, 257, 588, 731, 12, 6861, 6532, 11, 286, 576, 584, 11, 22023, 13, 51266], "temperature": 0.0, "avg_logprob": -0.2769166042930202, "compression_ratio": 1.4490740740740742, "no_speech_prob": 9.610033157514408e-05}, {"id": 931, "seek": 391906, "start": 3937.1, "end": 3939.66, "text": " But it's a really good one.", "tokens": [51266, 583, 309, 311, 257, 534, 665, 472, 13, 51394], "temperature": 0.0, "avg_logprob": -0.2769166042930202, "compression_ratio": 1.4490740740740742, "no_speech_prob": 9.610033157514408e-05}, {"id": 932, "seek": 391906, "start": 3939.66, "end": 3942.9, "text": " You might be wondering, like, well, what about, like, compression?", "tokens": [51394, 509, 1062, 312, 6359, 11, 411, 11, 731, 11, 437, 466, 11, 411, 11, 19355, 30, 51556], "temperature": 0.0, "avg_logprob": -0.2769166042930202, "compression_ratio": 1.4490740740740742, "no_speech_prob": 9.610033157514408e-05}, {"id": 933, "seek": 391906, "start": 3942.9, "end": 3945.7, "text": " Like shouldn't you be zipping them, or something like that?", "tokens": [51556, 1743, 4659, 380, 291, 312, 710, 6297, 552, 11, 420, 746, 411, 300, 30, 51696], "temperature": 0.0, "avg_logprob": -0.2769166042930202, "compression_ratio": 1.4490740740740742, "no_speech_prob": 9.610033157514408e-05}, {"id": 934, "seek": 394570, "start": 3945.7, "end": 3951.7799999999997, "text": " But actually, remember, these latents are already, the whole point is, they're highly", "tokens": [50364, 583, 767, 11, 1604, 11, 613, 4465, 791, 366, 1217, 11, 264, 1379, 935, 307, 11, 436, 434, 5405, 50668], "temperature": 0.0, "avg_logprob": -0.3958430732648397, "compression_ratio": 1.4230769230769231, "no_speech_prob": 3.373696017661132e-05}, {"id": 935, "seek": 394570, "start": 3951.7799999999997, "end": 3952.7799999999997, "text": " compressed.", "tokens": [50668, 30353, 13, 50718], "temperature": 0.0, "avg_logprob": -0.3958430732648397, "compression_ratio": 1.4230769230769231, "no_speech_prob": 3.373696017661132e-05}, {"id": 936, "seek": 394570, "start": 3952.7799999999997, "end": 3959.02, "text": " So generally speaking, zipping latents from a good VAE doesn't do much.", "tokens": [50718, 407, 5101, 4124, 11, 710, 6297, 4465, 791, 490, 257, 665, 18527, 36, 1177, 380, 360, 709, 13, 51030], "temperature": 0.0, "avg_logprob": -0.3958430732648397, "compression_ratio": 1.4230769230769231, "no_speech_prob": 3.373696017661132e-05}, {"id": 937, "seek": 394570, "start": 3959.02, "end": 3964.9399999999996, "text": " Because they're, like, they almost look a bit random, numberish.", "tokens": [51030, 1436, 436, 434, 11, 411, 11, 436, 1920, 574, 257, 857, 4974, 11, 1230, 742, 13, 51326], "temperature": 0.0, "avg_logprob": -0.3958430732648397, "compression_ratio": 1.4230769230769231, "no_speech_prob": 3.373696017661132e-05}, {"id": 938, "seek": 394570, "start": 3964.9399999999996, "end": 3969.58, "text": " Okay, so we've now saved our entire LSUN bedroom.", "tokens": [51326, 1033, 11, 370, 321, 600, 586, 6624, 527, 2302, 441, 50, 3979, 11211, 13, 51558], "temperature": 0.0, "avg_logprob": -0.3958430732648397, "compression_ratio": 1.4230769230769231, "no_speech_prob": 3.373696017661132e-05}, {"id": 939, "seek": 394570, "start": 3969.58, "end": 3974.8599999999997, "text": " That's a 20% subset, the bit that I've provided.", "tokens": [51558, 663, 311, 257, 945, 4, 25993, 11, 264, 857, 300, 286, 600, 5649, 13, 51822], "temperature": 0.0, "avg_logprob": -0.3958430732648397, "compression_ratio": 1.4230769230769231, "no_speech_prob": 3.373696017661132e-05}, {"id": 940, "seek": 397486, "start": 3975.02, "end": 3976.6600000000003, "text": " And now, latents.", "tokens": [50372, 400, 586, 11, 4465, 791, 13, 50454], "temperature": 0.0, "avg_logprob": -0.3212736526338181, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003799693949986249}, {"id": 941, "seek": 397486, "start": 3976.6600000000003, "end": 3978.1, "text": " So we can now run it through.", "tokens": [50454, 407, 321, 393, 586, 1190, 309, 807, 13, 50526], "temperature": 0.0, "avg_logprob": -0.3212736526338181, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003799693949986249}, {"id": 942, "seek": 397486, "start": 3978.1, "end": 3979.1, "text": " This is the nice thing.", "tokens": [50526, 639, 307, 264, 1481, 551, 13, 50576], "temperature": 0.0, "avg_logprob": -0.3212736526338181, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003799693949986249}, {"id": 943, "seek": 397486, "start": 3979.1, "end": 3982.9, "text": " We can use exactly the same process from here on in, as usual.", "tokens": [50576, 492, 393, 764, 2293, 264, 912, 1399, 490, 510, 322, 294, 11, 382, 7713, 13, 50766], "temperature": 0.0, "avg_logprob": -0.3212736526338181, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003799693949986249}, {"id": 944, "seek": 397486, "start": 3982.9, "end": 3988.42, "text": " Okay, so we've got the noisify of our usual collated version.", "tokens": [50766, 1033, 11, 370, 321, 600, 658, 264, 572, 271, 2505, 295, 527, 7713, 1263, 770, 3037, 13, 51042], "temperature": 0.0, "avg_logprob": -0.3212736526338181, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003799693949986249}, {"id": 945, "seek": 397486, "start": 3988.42, "end": 3996.78, "text": " Now the latents are much higher than one standard deviation.", "tokens": [51042, 823, 264, 4465, 791, 366, 709, 2946, 813, 472, 3832, 25163, 13, 51460], "temperature": 0.0, "avg_logprob": -0.3212736526338181, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003799693949986249}, {"id": 946, "seek": 397486, "start": 3996.78, "end": 4002.6200000000003, "text": " So if we about divide it by five, that takes it back to a standard deviation of about one.", "tokens": [51460, 407, 498, 321, 466, 9845, 309, 538, 1732, 11, 300, 2516, 309, 646, 281, 257, 3832, 25163, 295, 466, 472, 13, 51752], "temperature": 0.0, "avg_logprob": -0.3212736526338181, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0003799693949986249}, {"id": 947, "seek": 400262, "start": 4002.62, "end": 4006.2999999999997, "text": " I think in the paper, they use like 0.18 or something.", "tokens": [50364, 286, 519, 294, 264, 3035, 11, 436, 764, 411, 1958, 13, 6494, 420, 746, 13, 50548], "temperature": 0.0, "avg_logprob": -0.27545016744862433, "compression_ratio": 1.680672268907563, "no_speech_prob": 4.006317612947896e-05}, {"id": 948, "seek": 400262, "start": 4006.2999999999997, "end": 4013.74, "text": " But this is close enough to make it a unit standard deviation.", "tokens": [50548, 583, 341, 307, 1998, 1547, 281, 652, 309, 257, 4985, 3832, 25163, 13, 50920], "temperature": 0.0, "avg_logprob": -0.27545016744862433, "compression_ratio": 1.680672268907563, "no_speech_prob": 4.006317612947896e-05}, {"id": 949, "seek": 400262, "start": 4013.74, "end": 4016.5, "text": " So we can split it into a training and a validation set.", "tokens": [50920, 407, 321, 393, 7472, 309, 666, 257, 3097, 293, 257, 24071, 992, 13, 51058], "temperature": 0.0, "avg_logprob": -0.27545016744862433, "compression_ratio": 1.680672268907563, "no_speech_prob": 4.006317612947896e-05}, {"id": 950, "seek": 400262, "start": 4016.5, "end": 4022.62, "text": " So just grab the first 90% for the training set, and the last 10% for the validation set.", "tokens": [51058, 407, 445, 4444, 264, 700, 4289, 4, 337, 264, 3097, 992, 11, 293, 264, 1036, 1266, 4, 337, 264, 24071, 992, 13, 51364], "temperature": 0.0, "avg_logprob": -0.27545016744862433, "compression_ratio": 1.680672268907563, "no_speech_prob": 4.006317612947896e-05}, {"id": 951, "seek": 400262, "start": 4022.62, "end": 4024.7, "text": " So those are our data sets.", "tokens": [51364, 407, 729, 366, 527, 1412, 6352, 13, 51468], "temperature": 0.0, "avg_logprob": -0.27545016744862433, "compression_ratio": 1.680672268907563, "no_speech_prob": 4.006317612947896e-05}, {"id": 952, "seek": 400262, "start": 4024.7, "end": 4027.3399999999997, "text": " We use a batch size of 128.", "tokens": [51468, 492, 764, 257, 15245, 2744, 295, 29810, 13, 51600], "temperature": 0.0, "avg_logprob": -0.27545016744862433, "compression_ratio": 1.680672268907563, "no_speech_prob": 4.006317612947896e-05}, {"id": 953, "seek": 400262, "start": 4027.3399999999997, "end": 4031.14, "text": " So now we can use our data loaders class we created with the getDLs we created.", "tokens": [51600, 407, 586, 321, 393, 764, 527, 1412, 3677, 433, 1508, 321, 2942, 365, 264, 483, 35, 43, 82, 321, 2942, 13, 51790], "temperature": 0.0, "avg_logprob": -0.27545016744862433, "compression_ratio": 1.680672268907563, "no_speech_prob": 4.006317612947896e-05}, {"id": 954, "seek": 403114, "start": 4031.14, "end": 4035.54, "text": " So these are all things we've created ourselves with the training set, the validation set,", "tokens": [50364, 407, 613, 366, 439, 721, 321, 600, 2942, 4175, 365, 264, 3097, 992, 11, 264, 24071, 992, 11, 50584], "temperature": 0.0, "avg_logprob": -0.2644389637729578, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00022693033679388463}, {"id": 955, "seek": 403114, "start": 4035.54, "end": 4040.62, "text": " the batch size, and our collation function.", "tokens": [50584, 264, 15245, 2744, 11, 293, 527, 1263, 399, 2445, 13, 50838], "temperature": 0.0, "avg_logprob": -0.2644389637729578, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00022693033679388463}, {"id": 956, "seek": 403114, "start": 4040.62, "end": 4043.18, "text": " So now it's kind of nice.", "tokens": [50838, 407, 586, 309, 311, 733, 295, 1481, 13, 50966], "temperature": 0.0, "avg_logprob": -0.2644389637729578, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00022693033679388463}, {"id": 957, "seek": 403114, "start": 4043.18, "end": 4045.54, "text": " It's amazing, you know, how easy it is.", "tokens": [50966, 467, 311, 2243, 11, 291, 458, 11, 577, 1858, 309, 307, 13, 51084], "temperature": 0.0, "avg_logprob": -0.2644389637729578, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00022693033679388463}, {"id": 958, "seek": 403114, "start": 4045.54, "end": 4053.58, "text": " Like, you know, a data set has the same interface as a NumPy array, or a list, or whatever.", "tokens": [51084, 1743, 11, 291, 458, 11, 257, 1412, 992, 575, 264, 912, 9226, 382, 257, 22592, 47, 88, 10225, 11, 420, 257, 1329, 11, 420, 2035, 13, 51486], "temperature": 0.0, "avg_logprob": -0.2644389637729578, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00022693033679388463}, {"id": 959, "seek": 403114, "start": 4053.58, "end": 4058.5, "text": " So we can literally just use the NumPy array directly as a data set, which I think is really", "tokens": [51486, 407, 321, 393, 3736, 445, 764, 264, 22592, 47, 88, 10225, 3838, 382, 257, 1412, 992, 11, 597, 286, 519, 307, 534, 51732], "temperature": 0.0, "avg_logprob": -0.2644389637729578, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00022693033679388463}, {"id": 960, "seek": 403114, "start": 4058.5, "end": 4060.04, "text": " neat.", "tokens": [51732, 10654, 13, 51809], "temperature": 0.0, "avg_logprob": -0.2644389637729578, "compression_ratio": 1.6359832635983265, "no_speech_prob": 0.00022693033679388463}, {"id": 961, "seek": 406004, "start": 4060.04, "end": 4064.96, "text": " This is why it's useful to know about these foundational concepts, because you don't have", "tokens": [50364, 639, 307, 983, 309, 311, 4420, 281, 458, 466, 613, 32195, 10392, 11, 570, 291, 500, 380, 362, 50610], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 962, "seek": 406004, "start": 4064.96, "end": 4070.2799999999997, "text": " to start thinking, like, oh, I wonder if there's some Torch vision thing to use memmap NumPy", "tokens": [50610, 281, 722, 1953, 11, 411, 11, 1954, 11, 286, 2441, 498, 456, 311, 512, 7160, 339, 5201, 551, 281, 764, 1334, 24223, 22592, 47, 88, 50876], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 963, "seek": 406004, "start": 4070.2799999999997, "end": 4071.2799999999997, "text": " files or something.", "tokens": [50876, 7098, 420, 746, 13, 50926], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 964, "seek": 406004, "start": 4071.2799999999997, "end": 4074.6, "text": " It's like, oh, wait, they already do provide a data set interface.", "tokens": [50926, 467, 311, 411, 11, 1954, 11, 1699, 11, 436, 1217, 360, 2893, 257, 1412, 992, 9226, 13, 51092], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 965, "seek": 406004, "start": 4074.6, "end": 4076.36, "text": " I don't have to do anything.", "tokens": [51092, 286, 500, 380, 362, 281, 360, 1340, 13, 51180], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 966, "seek": 406004, "start": 4076.36, "end": 4078.2799999999997, "text": " I just use them.", "tokens": [51180, 286, 445, 764, 552, 13, 51276], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 967, "seek": 406004, "start": 4078.2799999999997, "end": 4080.52, "text": " So that's pretty magical.", "tokens": [51276, 407, 300, 311, 1238, 12066, 13, 51388], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 968, "seek": 406004, "start": 4080.52, "end": 4084.16, "text": " We can test that now by grabbing a batch.", "tokens": [51388, 492, 393, 1500, 300, 586, 538, 23771, 257, 15245, 13, 51570], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 969, "seek": 406004, "start": 4084.16, "end": 4085.92, "text": " And so this is being noisified.", "tokens": [51570, 400, 370, 341, 307, 885, 572, 271, 2587, 13, 51658], "temperature": 0.0, "avg_logprob": -0.2879255638747919, "compression_ratio": 1.5779467680608366, "no_speech_prob": 3.120179462712258e-05}, {"id": 970, "seek": 408592, "start": 4086.04, "end": 4090.08, "text": " So here we can see our noisified images.", "tokens": [50370, 407, 510, 321, 393, 536, 527, 572, 271, 2587, 5267, 13, 50572], "temperature": 0.0, "avg_logprob": -0.27386297498430523, "compression_ratio": 1.6584158415841583, "no_speech_prob": 1.5936011550365947e-05}, {"id": 971, "seek": 408592, "start": 4090.08, "end": 4097.36, "text": " And so here's something crazy, is that we can actually decode noisified images.", "tokens": [50572, 400, 370, 510, 311, 746, 3219, 11, 307, 300, 321, 393, 767, 979, 1429, 572, 271, 2587, 5267, 13, 50936], "temperature": 0.0, "avg_logprob": -0.27386297498430523, "compression_ratio": 1.6584158415841583, "no_speech_prob": 1.5936011550365947e-05}, {"id": 972, "seek": 408592, "start": 4097.36, "end": 4102.24, "text": " And so, you know, here's, I guess this one wasn't noisified much, because it's a recognizable", "tokens": [50936, 400, 370, 11, 291, 458, 11, 510, 311, 11, 286, 2041, 341, 472, 2067, 380, 572, 271, 2587, 709, 11, 570, 309, 311, 257, 40757, 51180], "temperature": 0.0, "avg_logprob": -0.27386297498430523, "compression_ratio": 1.6584158415841583, "no_speech_prob": 1.5936011550365947e-05}, {"id": 973, "seek": 408592, "start": 4102.24, "end": 4103.64, "text": " bedroom.", "tokens": [51180, 11211, 13, 51250], "temperature": 0.0, "avg_logprob": -0.27386297498430523, "compression_ratio": 1.6584158415841583, "no_speech_prob": 1.5936011550365947e-05}, {"id": 974, "seek": 408592, "start": 4103.64, "end": 4107.32, "text": " And this is what happens when you just decode random noise.", "tokens": [51250, 400, 341, 307, 437, 2314, 562, 291, 445, 979, 1429, 4974, 5658, 13, 51434], "temperature": 0.0, "avg_logprob": -0.27386297498430523, "compression_ratio": 1.6584158415841583, "no_speech_prob": 1.5936011550365947e-05}, {"id": 975, "seek": 408592, "start": 4107.32, "end": 4108.32, "text": " Something in between.", "tokens": [51434, 6595, 294, 1296, 13, 51484], "temperature": 0.0, "avg_logprob": -0.27386297498430523, "compression_ratio": 1.6584158415841583, "no_speech_prob": 1.5936011550365947e-05}, {"id": 976, "seek": 408592, "start": 4108.32, "end": 4112.52, "text": " So I think that's pretty fun.", "tokens": [51484, 407, 286, 519, 300, 311, 1238, 1019, 13, 51694], "temperature": 0.0, "avg_logprob": -0.27386297498430523, "compression_ratio": 1.6584158415841583, "no_speech_prob": 1.5936011550365947e-05}, {"id": 977, "seek": 411252, "start": 4112.72, "end": 4114.76, "text": " Yeah.", "tokens": [50374, 865, 13, 50476], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 978, "seek": 411252, "start": 4114.76, "end": 4118.160000000001, "text": " This next bit is all just copied from our previous notebook.", "tokens": [50476, 639, 958, 857, 307, 439, 445, 25365, 490, 527, 3894, 21060, 13, 50646], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 979, "seek": 411252, "start": 4118.160000000001, "end": 4121.6, "text": " Create a model, initialize it.", "tokens": [50646, 20248, 257, 2316, 11, 5883, 1125, 309, 13, 50818], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 980, "seek": 411252, "start": 4121.6, "end": 4122.72, "text": " Train for a while.", "tokens": [50818, 28029, 337, 257, 1339, 13, 50874], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 981, "seek": 411252, "start": 4122.72, "end": 4125.080000000001, "text": " So this took me a few hours on a single GPU.", "tokens": [50874, 407, 341, 1890, 385, 257, 1326, 2496, 322, 257, 2167, 18407, 13, 50992], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 982, "seek": 411252, "start": 4125.080000000001, "end": 4127.160000000001, "text": " Everything I'm doing is on a single GPU.", "tokens": [50992, 5471, 286, 478, 884, 307, 322, 257, 2167, 18407, 13, 51096], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 983, "seek": 411252, "start": 4127.160000000001, "end": 4131.52, "text": " Literally nothing in this course, other than the stable diffusion stuff itself, is trained", "tokens": [51096, 23768, 1825, 294, 341, 1164, 11, 661, 813, 264, 8351, 25242, 1507, 2564, 11, 307, 8895, 51314], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 984, "seek": 411252, "start": 4131.52, "end": 4134.080000000001, "text": " on more than one GPU.", "tokens": [51314, 322, 544, 813, 472, 18407, 13, 51442], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 985, "seek": 411252, "start": 4134.080000000001, "end": 4137.5, "text": " The loss is much higher than usual.", "tokens": [51442, 440, 4470, 307, 709, 2946, 813, 7713, 13, 51613], "temperature": 0.0, "avg_logprob": -0.29071624832923965, "compression_ratio": 1.5462555066079295, "no_speech_prob": 5.225204222369939e-05}, {"id": 986, "seek": 413750, "start": 4137.5, "end": 4144.94, "text": " And that's not surprising, because it's trying to generate latent pixels, which where, like,", "tokens": [50364, 400, 300, 311, 406, 8830, 11, 570, 309, 311, 1382, 281, 8460, 48994, 18668, 11, 597, 689, 11, 411, 11, 50736], "temperature": 0.0, "avg_logprob": -0.3035306256226819, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0018674643943086267}, {"id": 987, "seek": 413750, "start": 4144.94, "end": 4147.74, "text": " it's much more precise as to exactly what it wants.", "tokens": [50736, 309, 311, 709, 544, 13600, 382, 281, 2293, 437, 309, 2738, 13, 50876], "temperature": 0.0, "avg_logprob": -0.3035306256226819, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0018674643943086267}, {"id": 988, "seek": 413750, "start": 4147.74, "end": 4153.26, "text": " You know, it's not like lots of pixels where the ones next to each other are really similar,", "tokens": [50876, 509, 458, 11, 309, 311, 406, 411, 3195, 295, 18668, 689, 264, 2306, 958, 281, 1184, 661, 366, 534, 2531, 11, 51152], "temperature": 0.0, "avg_logprob": -0.3035306256226819, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0018674643943086267}, {"id": 989, "seek": 413750, "start": 4153.26, "end": 4156.7, "text": " or the whole background looks the same, or a lot of that stuff, it's being compressed", "tokens": [51152, 420, 264, 1379, 3678, 1542, 264, 912, 11, 420, 257, 688, 295, 300, 1507, 11, 309, 311, 885, 30353, 51324], "temperature": 0.0, "avg_logprob": -0.3035306256226819, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0018674643943086267}, {"id": 990, "seek": 413750, "start": 4156.7, "end": 4157.7, "text": " out.", "tokens": [51324, 484, 13, 51374], "temperature": 0.0, "avg_logprob": -0.3035306256226819, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0018674643943086267}, {"id": 991, "seek": 413750, "start": 4157.7, "end": 4164.34, "text": " It's a more difficult thing to predict latent pixels.", "tokens": [51374, 467, 311, 257, 544, 2252, 551, 281, 6069, 48994, 18668, 13, 51706], "temperature": 0.0, "avg_logprob": -0.3035306256226819, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.0018674643943086267}, {"id": 992, "seek": 416434, "start": 4164.34, "end": 4169.9800000000005, "text": " So now we can sample from it in exactly the same way that we always have, using DDIM.", "tokens": [50364, 407, 586, 321, 393, 6889, 490, 309, 294, 2293, 264, 912, 636, 300, 321, 1009, 362, 11, 1228, 413, 3085, 44, 13, 50646], "temperature": 0.0, "avg_logprob": -0.31977395216623944, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0006666748085990548}, {"id": 993, "seek": 416434, "start": 4169.9800000000005, "end": 4174.8, "text": " But now we need to make sure that we decode it.", "tokens": [50646, 583, 586, 321, 643, 281, 652, 988, 300, 321, 979, 1429, 309, 13, 50887], "temperature": 0.0, "avg_logprob": -0.31977395216623944, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0006666748085990548}, {"id": 994, "seek": 416434, "start": 4174.8, "end": 4179.62, "text": " Because the thing that it's sampled are latents.", "tokens": [50887, 1436, 264, 551, 300, 309, 311, 3247, 15551, 366, 4465, 791, 13, 51128], "temperature": 0.0, "avg_logprob": -0.31977395216623944, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0006666748085990548}, {"id": 995, "seek": 416434, "start": 4179.62, "end": 4184.14, "text": " Because the thing that we asked it to learn to predict are latents.", "tokens": [51128, 1436, 264, 551, 300, 321, 2351, 309, 281, 1466, 281, 6069, 366, 4465, 791, 13, 51354], "temperature": 0.0, "avg_logprob": -0.31977395216623944, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0006666748085990548}, {"id": 996, "seek": 416434, "start": 4184.14, "end": 4186.860000000001, "text": " And so now we can take a look.", "tokens": [51354, 400, 370, 586, 321, 393, 747, 257, 574, 13, 51490], "temperature": 0.0, "avg_logprob": -0.31977395216623944, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0006666748085990548}, {"id": 997, "seek": 416434, "start": 4186.860000000001, "end": 4189.9800000000005, "text": " And we have bedrooms.", "tokens": [51490, 400, 321, 362, 39955, 13, 51646], "temperature": 0.0, "avg_logprob": -0.31977395216623944, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0006666748085990548}, {"id": 998, "seek": 416434, "start": 4189.9800000000005, "end": 4193.46, "text": " Ah-ha!", "tokens": [51646, 2438, 12, 1641, 0, 51820], "temperature": 0.0, "avg_logprob": -0.31977395216623944, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.0006666748085990548}, {"id": 999, "seek": 419346, "start": 4193.58, "end": 4194.58, "text": " And some of them look pretty good.", "tokens": [50370, 400, 512, 295, 552, 574, 1238, 665, 13, 50420], "temperature": 0.0, "avg_logprob": -0.26478822160475324, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0002489500038791448}, {"id": 1000, "seek": 419346, "start": 4194.58, "end": 4196.74, "text": " I think this one looks pretty good.", "tokens": [50420, 286, 519, 341, 472, 1542, 1238, 665, 13, 50528], "temperature": 0.0, "avg_logprob": -0.26478822160475324, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0002489500038791448}, {"id": 1001, "seek": 419346, "start": 4196.74, "end": 4198.9, "text": " I think this one looks pretty good.", "tokens": [50528, 286, 519, 341, 472, 1542, 1238, 665, 13, 50636], "temperature": 0.0, "avg_logprob": -0.26478822160475324, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0002489500038791448}, {"id": 1002, "seek": 419346, "start": 4198.9, "end": 4202.58, "text": " This one I don't have any idea what it is.", "tokens": [50636, 639, 472, 286, 500, 380, 362, 604, 1558, 437, 309, 307, 13, 50820], "temperature": 0.0, "avg_logprob": -0.26478822160475324, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0002489500038791448}, {"id": 1003, "seek": 419346, "start": 4202.58, "end": 4207.86, "text": " And this one, like, clearly there's bedroom-y bits, but there's something, I don't know,", "tokens": [50820, 400, 341, 472, 11, 411, 11, 4448, 456, 311, 11211, 12, 88, 9239, 11, 457, 456, 311, 746, 11, 286, 500, 380, 458, 11, 51084], "temperature": 0.0, "avg_logprob": -0.26478822160475324, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0002489500038791448}, {"id": 1004, "seek": 419346, "start": 4207.86, "end": 4211.1, "text": " there's weird bits.", "tokens": [51084, 456, 311, 3657, 9239, 13, 51246], "temperature": 0.0, "avg_logprob": -0.26478822160475324, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0002489500038791448}, {"id": 1005, "seek": 419346, "start": 4211.1, "end": 4219.06, "text": " So the fact that we're able to create 256 by 256 pixel images, where at least some of", "tokens": [51246, 407, 264, 1186, 300, 321, 434, 1075, 281, 1884, 38882, 538, 38882, 19261, 5267, 11, 689, 412, 1935, 512, 295, 51644], "temperature": 0.0, "avg_logprob": -0.26478822160475324, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0002489500038791448}, {"id": 1006, "seek": 421906, "start": 4219.06, "end": 4224.22, "text": " them look quite good, in a couple of hours, I can't remember how long it took to train,", "tokens": [50364, 552, 574, 1596, 665, 11, 294, 257, 1916, 295, 2496, 11, 286, 393, 380, 1604, 577, 938, 309, 1890, 281, 3847, 11, 50622], "temperature": 0.0, "avg_logprob": -0.2829358193182176, "compression_ratio": 1.6360424028268552, "no_speech_prob": 0.014727926813066006}, {"id": 1007, "seek": 421906, "start": 4224.22, "end": 4230.780000000001, "text": " it's a small number of hours on a single GPU, is something that was not previously possible.", "tokens": [50622, 309, 311, 257, 1359, 1230, 295, 2496, 322, 257, 2167, 18407, 11, 307, 746, 300, 390, 406, 8046, 1944, 13, 50950], "temperature": 0.0, "avg_logprob": -0.2829358193182176, "compression_ratio": 1.6360424028268552, "no_speech_prob": 0.014727926813066006}, {"id": 1008, "seek": 421906, "start": 4230.780000000001, "end": 4233.06, "text": " And we're, in a sense, we're totally cheating.", "tokens": [50950, 400, 321, 434, 11, 294, 257, 2020, 11, 321, 434, 3879, 18309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2829358193182176, "compression_ratio": 1.6360424028268552, "no_speech_prob": 0.014727926813066006}, {"id": 1009, "seek": 421906, "start": 4233.06, "end": 4238.780000000001, "text": " Because we're using the stable diffusion VAE to do a lot of the hard work for us.", "tokens": [51064, 1436, 321, 434, 1228, 264, 8351, 25242, 18527, 36, 281, 360, 257, 688, 295, 264, 1152, 589, 337, 505, 13, 51350], "temperature": 0.0, "avg_logprob": -0.2829358193182176, "compression_ratio": 1.6360424028268552, "no_speech_prob": 0.014727926813066006}, {"id": 1010, "seek": 421906, "start": 4238.780000000001, "end": 4244.900000000001, "text": " But that's fine, you know, because that VAE knows how to create all kinds of natural images,", "tokens": [51350, 583, 300, 311, 2489, 11, 291, 458, 11, 570, 300, 18527, 36, 3255, 577, 281, 1884, 439, 3685, 295, 3303, 5267, 11, 51656], "temperature": 0.0, "avg_logprob": -0.2829358193182176, "compression_ratio": 1.6360424028268552, "no_speech_prob": 0.014727926813066006}, {"id": 1011, "seek": 421906, "start": 4244.900000000001, "end": 4247.620000000001, "text": " and drawings, and portraits, and oil paintings, or whatever.", "tokens": [51656, 293, 18618, 11, 293, 31880, 11, 293, 3184, 14880, 11, 420, 2035, 13, 51792], "temperature": 0.0, "avg_logprob": -0.2829358193182176, "compression_ratio": 1.6360424028268552, "no_speech_prob": 0.014727926813066006}, {"id": 1012, "seek": 424762, "start": 4247.66, "end": 4254.66, "text": " So you can, I think, work in that latent space quite comfortably.", "tokens": [50366, 407, 291, 393, 11, 286, 519, 11, 589, 294, 300, 48994, 1901, 1596, 25101, 13, 50716], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1013, "seek": 424762, "start": 4254.66, "end": 4255.66, "text": " Yeah.", "tokens": [50716, 865, 13, 50766], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1014, "seek": 424762, "start": 4258.66, "end": 4260.74, "text": " Do you guys have anything you wanted to add about that?", "tokens": [50916, 1144, 291, 1074, 362, 1340, 291, 1415, 281, 909, 466, 300, 30, 51020], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1015, "seek": 424762, "start": 4260.74, "end": 4263.14, "text": " Oh, actually, Tanishka, I know you've trained this for longer.", "tokens": [51020, 876, 11, 767, 11, 314, 7524, 2330, 11, 286, 458, 291, 600, 8895, 341, 337, 2854, 13, 51140], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1016, "seek": 424762, "start": 4263.14, "end": 4265.9, "text": " I only trained it for 25 epochs.", "tokens": [51140, 286, 787, 8895, 309, 337, 3552, 30992, 28346, 13, 51278], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1017, "seek": 424762, "start": 4265.9, "end": 4267.86, "text": " How long did you, how many hours did you train it for?", "tokens": [51278, 1012, 938, 630, 291, 11, 577, 867, 2496, 630, 291, 3847, 309, 337, 30, 51376], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1018, "seek": 424762, "start": 4267.86, "end": 4269.98, "text": " Because you did, you did 100 epochs, right?", "tokens": [51376, 1436, 291, 630, 11, 291, 630, 2319, 30992, 28346, 11, 558, 30, 51482], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1019, "seek": 424762, "start": 4269.98, "end": 4271.86, "text": " Yes, I did 100 epochs.", "tokens": [51482, 1079, 11, 286, 630, 2319, 30992, 28346, 13, 51576], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1020, "seek": 424762, "start": 4271.86, "end": 4274.82, "text": " I didn't keep track exactly, but I think it was about 15 hours.", "tokens": [51576, 286, 994, 380, 1066, 2837, 2293, 11, 457, 286, 519, 309, 390, 466, 2119, 2496, 13, 51724], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1021, "seek": 424762, "start": 4274.82, "end": 4277.099999999999, "text": " On that single GPU?", "tokens": [51724, 1282, 300, 2167, 18407, 30, 51838], "temperature": 0.0, "avg_logprob": -0.3617241888335257, "compression_ratio": 1.612781954887218, "no_speech_prob": 0.0012642880901694298}, {"id": 1022, "seek": 427710, "start": 4277.58, "end": 4278.58, "text": " On an A100.", "tokens": [50388, 1282, 364, 316, 6879, 13, 50438], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1023, "seek": 427710, "start": 4278.58, "end": 4279.58, "text": " Okay, it's a single A100.", "tokens": [50438, 1033, 11, 309, 311, 257, 2167, 316, 6879, 13, 50488], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1024, "seek": 427710, "start": 4279.58, "end": 4280.58, "text": " Yeah.", "tokens": [50488, 865, 13, 50538], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1025, "seek": 427710, "start": 4280.58, "end": 4283.740000000001, "text": " I argue, I mean, the results, yeah, I'll show it.", "tokens": [50538, 286, 9695, 11, 286, 914, 11, 264, 3542, 11, 1338, 11, 286, 603, 855, 309, 13, 50696], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1026, "seek": 427710, "start": 4283.740000000001, "end": 4290.54, "text": " It's, it's, yeah, it's, I guess, maybe slightly better.", "tokens": [50696, 467, 311, 11, 309, 311, 11, 1338, 11, 309, 311, 11, 286, 2041, 11, 1310, 4748, 1101, 13, 51036], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1027, "seek": 427710, "start": 4290.54, "end": 4293.5, "text": " But you know, I guess you can, I'd see maybe.", "tokens": [51036, 583, 291, 458, 11, 286, 2041, 291, 393, 11, 286, 1116, 536, 1310, 13, 51184], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1028, "seek": 427710, "start": 4293.5, "end": 4294.820000000001, "text": " No, it is definitely slightly better.", "tokens": [51184, 883, 11, 309, 307, 2138, 4748, 1101, 13, 51250], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1029, "seek": 427710, "start": 4294.820000000001, "end": 4296.780000000001, "text": " The good ones are certainly slightly better.", "tokens": [51250, 440, 665, 2306, 366, 3297, 4748, 1101, 13, 51348], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1030, "seek": 427710, "start": 4296.780000000001, "end": 4297.780000000001, "text": " Yeah.", "tokens": [51348, 865, 13, 51398], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1031, "seek": 427710, "start": 4297.780000000001, "end": 4298.780000000001, "text": " Yeah.", "tokens": [51398, 865, 13, 51448], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1032, "seek": 427710, "start": 4298.780000000001, "end": 4302.1, "text": " Like the bottom left one is better than any of mine, I think.", "tokens": [51448, 1743, 264, 2767, 1411, 472, 307, 1101, 813, 604, 295, 3892, 11, 286, 519, 13, 51614], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1033, "seek": 427710, "start": 4302.1, "end": 4305.780000000001, "text": " So it's possible, maybe at this point, we just may need to use more data, I guess.", "tokens": [51614, 407, 309, 311, 1944, 11, 1310, 412, 341, 935, 11, 321, 445, 815, 643, 281, 764, 544, 1412, 11, 286, 2041, 13, 51798], "temperature": 0.0, "avg_logprob": -0.34656288510277156, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.021603114902973175}, {"id": 1034, "seek": 430578, "start": 4305.98, "end": 4308.139999999999, "text": " I guess we were using a 20% subset.", "tokens": [50374, 286, 2041, 321, 645, 1228, 257, 945, 4, 25993, 13, 50482], "temperature": 0.0, "avg_logprob": -0.32639715622882454, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.00638749822974205}, {"id": 1035, "seek": 430578, "start": 4308.139999999999, "end": 4312.34, "text": " So maybe having more of that data to provide more diversity or something like that, maybe", "tokens": [50482, 407, 1310, 1419, 544, 295, 300, 1412, 281, 2893, 544, 8811, 420, 746, 411, 300, 11, 1310, 50692], "temperature": 0.0, "avg_logprob": -0.32639715622882454, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.00638749822974205}, {"id": 1036, "seek": 430578, "start": 4312.34, "end": 4313.34, "text": " that might help.", "tokens": [50692, 300, 1062, 854, 13, 50742], "temperature": 0.0, "avg_logprob": -0.32639715622882454, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.00638749822974205}, {"id": 1037, "seek": 430578, "start": 4313.34, "end": 4317.86, "text": " Yeah, or maybe, have you tried doing the diffusers one for 100?", "tokens": [50742, 865, 11, 420, 1310, 11, 362, 291, 3031, 884, 264, 7593, 301, 433, 472, 337, 2319, 30, 50968], "temperature": 0.0, "avg_logprob": -0.32639715622882454, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.00638749822974205}, {"id": 1038, "seek": 430578, "start": 4317.86, "end": 4321.66, "text": " No, I'm using just our code here.", "tokens": [50968, 883, 11, 286, 478, 1228, 445, 527, 3089, 510, 13, 51158], "temperature": 0.0, "avg_logprob": -0.32639715622882454, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.00638749822974205}, {"id": 1039, "seek": 430578, "start": 4321.66, "end": 4322.66, "text": " Yeah.", "tokens": [51158, 865, 13, 51208], "temperature": 0.0, "avg_logprob": -0.32639715622882454, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.00638749822974205}, {"id": 1040, "seek": 430578, "start": 4322.66, "end": 4330.3, "text": " So I've got, all right, so I'll share my screen if you want to stop sharing yours.", "tokens": [51208, 407, 286, 600, 658, 11, 439, 558, 11, 370, 286, 603, 2073, 452, 2568, 498, 291, 528, 281, 1590, 5414, 6342, 13, 51590], "temperature": 0.0, "avg_logprob": -0.32639715622882454, "compression_ratio": 1.5231481481481481, "no_speech_prob": 0.00638749822974205}, {"id": 1041, "seek": 433030, "start": 4330.3, "end": 4338.1, "text": " So I do have, if we get around to this, maybe we can add the results back to this notebook.", "tokens": [50364, 407, 286, 360, 362, 11, 498, 321, 483, 926, 281, 341, 11, 1310, 321, 393, 909, 264, 3542, 646, 281, 341, 21060, 13, 50754], "temperature": 0.0, "avg_logprob": -0.34684274461534287, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.0009547049994580448}, {"id": 1042, "seek": 433030, "start": 4338.1, "end": 4341.26, "text": " Because I do have a version that uses diffusers.", "tokens": [50754, 1436, 286, 360, 362, 257, 3037, 300, 4960, 7593, 301, 433, 13, 50912], "temperature": 0.0, "avg_logprob": -0.34684274461534287, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.0009547049994580448}, {"id": 1043, "seek": 433030, "start": 4341.26, "end": 4343.06, "text": " So everything else is identical.", "tokens": [50912, 407, 1203, 1646, 307, 14800, 13, 51002], "temperature": 0.0, "avg_logprob": -0.34684274461534287, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.0009547049994580448}, {"id": 1044, "seek": 433030, "start": 4343.06, "end": 4353.46, "text": " 25 epochs, except for the model for the previous one, I was using our, our own MVNet model.", "tokens": [51002, 3552, 30992, 28346, 11, 3993, 337, 264, 2316, 337, 264, 3894, 472, 11, 286, 390, 1228, 527, 11, 527, 1065, 376, 53, 45, 302, 2316, 13, 51522], "temperature": 0.0, "avg_logprob": -0.34684274461534287, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.0009547049994580448}, {"id": 1045, "seek": 433030, "start": 4353.46, "end": 4356.78, "text": " So I have to change the channels now to four.", "tokens": [51522, 407, 286, 362, 281, 1319, 264, 9235, 586, 281, 1451, 13, 51688], "temperature": 0.0, "avg_logprob": -0.34684274461534287, "compression_ratio": 1.5170731707317073, "no_speech_prob": 0.0009547049994580448}, {"id": 1046, "seek": 435678, "start": 4356.78, "end": 4361.179999999999, "text": " And number of filters, I think I might have increased it a bit.", "tokens": [50364, 400, 1230, 295, 15995, 11, 286, 519, 286, 1062, 362, 6505, 309, 257, 857, 13, 50584], "temperature": 0.0, "avg_logprob": -0.2873022896902902, "compression_ratio": 1.4058823529411764, "no_speech_prob": 0.023684149608016014}, {"id": 1047, "seek": 435678, "start": 4361.179999999999, "end": 4369.62, "text": " So then I tried using, yeah, the diffusers unit, just with whatever their defaults were.", "tokens": [50584, 407, 550, 286, 3031, 1228, 11, 1338, 11, 264, 7593, 301, 433, 4985, 11, 445, 365, 2035, 641, 7576, 82, 645, 13, 51006], "temperature": 0.0, "avg_logprob": -0.2873022896902902, "compression_ratio": 1.4058823529411764, "no_speech_prob": 0.023684149608016014}, {"id": 1048, "seek": 435678, "start": 4369.62, "end": 4372.34, "text": " And so I got, what did I get here?", "tokens": [51006, 400, 370, 286, 658, 11, 437, 630, 286, 483, 510, 30, 51142], "temperature": 0.0, "avg_logprob": -0.2873022896902902, "compression_ratio": 1.4058823529411764, "no_speech_prob": 0.023684149608016014}, {"id": 1049, "seek": 435678, "start": 4372.34, "end": 4374.3, "text": " 243 with diffusers.", "tokens": [51142, 4022, 18, 365, 7593, 301, 433, 13, 51240], "temperature": 0.0, "avg_logprob": -0.2873022896902902, "compression_ratio": 1.4058823529411764, "no_speech_prob": 0.023684149608016014}, {"id": 1050, "seek": 435678, "start": 4374.3, "end": 4381.7, "text": " I got a little bit better, 239.", "tokens": [51240, 286, 658, 257, 707, 857, 1101, 11, 6673, 24, 13, 51610], "temperature": 0.0, "avg_logprob": -0.2873022896902902, "compression_ratio": 1.4058823529411764, "no_speech_prob": 0.023684149608016014}, {"id": 1051, "seek": 438170, "start": 4381.7, "end": 4387.139999999999, "text": " And yeah, I don't know if they're obviously better or not.", "tokens": [50364, 400, 1338, 11, 286, 500, 380, 458, 498, 436, 434, 2745, 1101, 420, 406, 13, 50636], "temperature": 0.0, "avg_logprob": -0.3215940331899992, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.013217040337622166}, {"id": 1052, "seek": 438170, "start": 4387.139999999999, "end": 4392.22, "text": " Like, this is a bit weird.", "tokens": [50636, 1743, 11, 341, 307, 257, 857, 3657, 13, 50890], "temperature": 0.0, "avg_logprob": -0.3215940331899992, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.013217040337622166}, {"id": 1053, "seek": 438170, "start": 4392.22, "end": 4400.98, "text": " I think like, actually, another thing we could try maybe is do 100 epochs, but use the diffusers", "tokens": [50890, 286, 519, 411, 11, 767, 11, 1071, 551, 321, 727, 853, 1310, 307, 360, 2319, 30992, 28346, 11, 457, 764, 264, 7593, 301, 433, 51328], "temperature": 0.0, "avg_logprob": -0.3215940331899992, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.013217040337622166}, {"id": 1054, "seek": 438170, "start": 4400.98, "end": 4403.66, "text": " number of channels and stuff that they used for.", "tokens": [51328, 1230, 295, 9235, 293, 1507, 300, 436, 1143, 337, 13, 51462], "temperature": 0.0, "avg_logprob": -0.3215940331899992, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.013217040337622166}, {"id": 1055, "seek": 438170, "start": 4403.66, "end": 4406.94, "text": " Because I think the defaults that they use actually for diffusers is not the same as", "tokens": [51462, 1436, 286, 519, 264, 7576, 82, 300, 436, 764, 767, 337, 7593, 301, 433, 307, 406, 264, 912, 382, 51626], "temperature": 0.0, "avg_logprob": -0.3215940331899992, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.013217040337622166}, {"id": 1056, "seek": 438170, "start": 4406.94, "end": 4407.94, "text": " stable diffusion.", "tokens": [51626, 8351, 25242, 13, 51676], "temperature": 0.0, "avg_logprob": -0.3215940331899992, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.013217040337622166}, {"id": 1057, "seek": 440794, "start": 4407.94, "end": 4412.78, "text": " So maybe we could try stable diffusion matched unit for a hundred epochs.", "tokens": [50364, 407, 1310, 321, 727, 853, 8351, 25242, 21447, 4985, 337, 257, 3262, 30992, 28346, 13, 50606], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1058, "seek": 440794, "start": 4412.78, "end": 4418.0599999999995, "text": " And if we get any nice results, maybe we can paste them into the bottom to show people.", "tokens": [50606, 400, 498, 321, 483, 604, 1481, 3542, 11, 1310, 321, 393, 9163, 552, 666, 264, 2767, 281, 855, 561, 13, 50870], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1059, "seek": 440794, "start": 4418.0599999999995, "end": 4419.0599999999995, "text": " Yeah.", "tokens": [50870, 865, 13, 50920], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1060, "seek": 440794, "start": 4419.0599999999995, "end": 4420.0599999999995, "text": " Yeah.", "tokens": [50920, 865, 13, 50970], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1061, "seek": 440794, "start": 4420.0599999999995, "end": 4421.0599999999995, "text": " Cool.", "tokens": [50970, 8561, 13, 51020], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1062, "seek": 440794, "start": 4421.0599999999995, "end": 4422.0599999999995, "text": " Yeah.", "tokens": [51020, 865, 13, 51070], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1063, "seek": 440794, "start": 4422.0599999999995, "end": 4428.46, "text": " Do you guys have anything else to add at this point?", "tokens": [51070, 1144, 291, 1074, 362, 1340, 1646, 281, 909, 412, 341, 935, 30, 51390], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1064, "seek": 440794, "start": 4428.46, "end": 4431.54, "text": " All right.", "tokens": [51390, 1057, 558, 13, 51544], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1065, "seek": 440794, "start": 4431.54, "end": 4436.98, "text": " So I'll just mention one more thought in terms of like a bit of a interesting project people", "tokens": [51544, 407, 286, 603, 445, 2152, 472, 544, 1194, 294, 2115, 295, 411, 257, 857, 295, 257, 1880, 1716, 561, 51816], "temperature": 0.0, "avg_logprob": -0.3243137634906572, "compression_ratio": 1.52, "no_speech_prob": 0.004537905566394329}, {"id": 1066, "seek": 443698, "start": 4437.0199999999995, "end": 4440.58, "text": " could play with.", "tokens": [50366, 727, 862, 365, 13, 50544], "temperature": 0.0, "avg_logprob": -0.27511734658099235, "compression_ratio": 1.8134715025906736, "no_speech_prob": 0.0006986547377891839}, {"id": 1067, "seek": 443698, "start": 4440.58, "end": 4441.9, "text": " I don't know if this is too crazy.", "tokens": [50544, 286, 500, 380, 458, 498, 341, 307, 886, 3219, 13, 50610], "temperature": 0.0, "avg_logprob": -0.27511734658099235, "compression_ratio": 1.8134715025906736, "no_speech_prob": 0.0006986547377891839}, {"id": 1068, "seek": 443698, "start": 4441.9, "end": 4443.66, "text": " I don't think it's been done before.", "tokens": [50610, 286, 500, 380, 519, 309, 311, 668, 1096, 949, 13, 50698], "temperature": 0.0, "avg_logprob": -0.27511734658099235, "compression_ratio": 1.8134715025906736, "no_speech_prob": 0.0006986547377891839}, {"id": 1069, "seek": 443698, "start": 4443.66, "end": 4448.74, "text": " But my thought was like, there was a huge difference in our super resolution.", "tokens": [50698, 583, 452, 1194, 390, 411, 11, 456, 390, 257, 2603, 2649, 294, 527, 1687, 8669, 13, 50952], "temperature": 0.0, "avg_logprob": -0.27511734658099235, "compression_ratio": 1.8134715025906736, "no_speech_prob": 0.0006986547377891839}, {"id": 1070, "seek": 443698, "start": 4448.74, "end": 4452.86, "text": " Do you remember a huge difference in our super resolution results when we used a pre-trained", "tokens": [50952, 1144, 291, 1604, 257, 2603, 2649, 294, 527, 1687, 8669, 3542, 562, 321, 1143, 257, 659, 12, 17227, 2001, 51158], "temperature": 0.0, "avg_logprob": -0.27511734658099235, "compression_ratio": 1.8134715025906736, "no_speech_prob": 0.0006986547377891839}, {"id": 1071, "seek": 443698, "start": 4452.86, "end": 4462.58, "text": " model and when we used perceptual loss, but particularly when we used a pre-trained model?", "tokens": [51158, 2316, 293, 562, 321, 1143, 43276, 901, 4470, 11, 457, 4098, 562, 321, 1143, 257, 659, 12, 17227, 2001, 2316, 30, 51644], "temperature": 0.0, "avg_logprob": -0.27511734658099235, "compression_ratio": 1.8134715025906736, "no_speech_prob": 0.0006986547377891839}, {"id": 1072, "seek": 446258, "start": 4462.58, "end": 4467.3, "text": " I thought we could use a pre-trained model, but we would need a pre-trained latence model,", "tokens": [50364, 286, 1194, 321, 727, 764, 257, 659, 12, 17227, 2001, 2316, 11, 457, 321, 576, 643, 257, 659, 12, 17227, 2001, 287, 267, 655, 2316, 11, 50600], "temperature": 0.0, "avg_logprob": -0.25470009751207245, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.0003150209377054125}, {"id": 1073, "seek": 446258, "start": 4467.3, "end": 4468.3, "text": " right?", "tokens": [50600, 558, 30, 50650], "temperature": 0.0, "avg_logprob": -0.25470009751207245, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.0003150209377054125}, {"id": 1074, "seek": 446258, "start": 4468.3, "end": 4475.9, "text": " We would want something where our, you know, down sampling backbone was pre-trained model", "tokens": [50650, 492, 576, 528, 746, 689, 527, 11, 291, 458, 11, 760, 21179, 34889, 390, 659, 12, 17227, 2001, 2316, 51030], "temperature": 0.0, "avg_logprob": -0.25470009751207245, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.0003150209377054125}, {"id": 1075, "seek": 446258, "start": 4475.9, "end": 4478.22, "text": " on latence.", "tokens": [51030, 322, 287, 7186, 384, 13, 51146], "temperature": 0.0, "avg_logprob": -0.25470009751207245, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.0003150209377054125}, {"id": 1076, "seek": 446258, "start": 4478.22, "end": 4480.0599999999995, "text": " And so I just want to just show you what I've done.", "tokens": [51146, 400, 370, 286, 445, 528, 281, 445, 855, 291, 437, 286, 600, 1096, 13, 51238], "temperature": 0.0, "avg_logprob": -0.25470009751207245, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.0003150209377054125}, {"id": 1077, "seek": 446258, "start": 4480.0599999999995, "end": 4485.22, "text": " And you guys, you know, if anybody watching wanted to try taking this further, I've just", "tokens": [51238, 400, 291, 1074, 11, 291, 458, 11, 498, 4472, 1976, 1415, 281, 853, 1940, 341, 3052, 11, 286, 600, 445, 51496], "temperature": 0.0, "avg_logprob": -0.25470009751207245, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.0003150209377054125}, {"id": 1078, "seek": 446258, "start": 4485.22, "end": 4489.46, "text": " done the first bit for you to give you a sense, which is I've pre-trained an ImageNet model,", "tokens": [51496, 1096, 264, 700, 857, 337, 291, 281, 976, 291, 257, 2020, 11, 597, 307, 286, 600, 659, 12, 17227, 2001, 364, 29903, 31890, 2316, 11, 51708], "temperature": 0.0, "avg_logprob": -0.25470009751207245, "compression_ratio": 1.7818930041152263, "no_speech_prob": 0.0003150209377054125}, {"id": 1079, "seek": 448946, "start": 4489.46, "end": 4495.34, "text": " not tiny ImageNet, but a full ImageNet model on latence as a classifier.", "tokens": [50364, 406, 5870, 29903, 31890, 11, 457, 257, 1577, 29903, 31890, 2316, 322, 287, 7186, 384, 382, 257, 1508, 9902, 13, 50658], "temperature": 0.0, "avg_logprob": -0.2591744144405939, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.007814438082277775}, {"id": 1080, "seek": 448946, "start": 4495.34, "end": 4499.42, "text": " And if you use this as a backbone, you know, and also try maybe some of the other tricks", "tokens": [50658, 400, 498, 291, 764, 341, 382, 257, 34889, 11, 291, 458, 11, 293, 611, 853, 1310, 512, 295, 264, 661, 11733, 50862], "temperature": 0.0, "avg_logprob": -0.2591744144405939, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.007814438082277775}, {"id": 1081, "seek": 448946, "start": 4499.42, "end": 4502.58, "text": " that we found helpful, like having ResNets on the cross connections.", "tokens": [50862, 300, 321, 1352, 4961, 11, 411, 1419, 5015, 45, 1385, 322, 264, 3278, 9271, 13, 51020], "temperature": 0.0, "avg_logprob": -0.2591744144405939, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.007814438082277775}, {"id": 1082, "seek": 448946, "start": 4502.58, "end": 4505.18, "text": " These are all things that I don't think anybody's done before.", "tokens": [51020, 1981, 366, 439, 721, 300, 286, 500, 380, 519, 4472, 311, 1096, 949, 13, 51150], "temperature": 0.0, "avg_logprob": -0.2591744144405939, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.007814438082277775}, {"id": 1083, "seek": 448946, "start": 4505.18, "end": 4510.42, "text": " I don't know, the scientific literature is vast and I might've missed it, but I've not", "tokens": [51150, 286, 500, 380, 458, 11, 264, 8134, 10394, 307, 8369, 293, 286, 1062, 600, 6721, 309, 11, 457, 286, 600, 406, 51412], "temperature": 0.0, "avg_logprob": -0.2591744144405939, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.007814438082277775}, {"id": 1084, "seek": 448946, "start": 4510.42, "end": 4514.62, "text": " come across anybody do these tricks before.", "tokens": [51412, 808, 2108, 4472, 360, 613, 11733, 949, 13, 51622], "temperature": 0.0, "avg_logprob": -0.2591744144405939, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.007814438082277775}, {"id": 1085, "seek": 451462, "start": 4514.62, "end": 4520.38, "text": " So obviously like we're, one of the interesting parts of this, which is designed to be challenging", "tokens": [50364, 407, 2745, 411, 321, 434, 11, 472, 295, 264, 1880, 3166, 295, 341, 11, 597, 307, 4761, 281, 312, 7595, 50652], "temperature": 0.0, "avg_logprob": -0.23857167002918955, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001150830532424152}, {"id": 1086, "seek": 451462, "start": 4520.38, "end": 4526.0199999999995, "text": " is that we're using bigger datasets now, but they're datasets that you can absolutely like", "tokens": [50652, 307, 300, 321, 434, 1228, 3801, 42856, 586, 11, 457, 436, 434, 42856, 300, 291, 393, 3122, 411, 50934], "temperature": 0.0, "avg_logprob": -0.23857167002918955, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001150830532424152}, {"id": 1087, "seek": 451462, "start": 4526.0199999999995, "end": 4535.14, "text": " run on a single GPU, you know, a few tens of gigabytes, which fits on any modern hard", "tokens": [50934, 1190, 322, 257, 2167, 18407, 11, 291, 458, 11, 257, 1326, 10688, 295, 42741, 11, 597, 9001, 322, 604, 4363, 1152, 51390], "temperature": 0.0, "avg_logprob": -0.23857167002918955, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001150830532424152}, {"id": 1088, "seek": 451462, "start": 4535.14, "end": 4537.26, "text": " drive easily.", "tokens": [51390, 3332, 3612, 13, 51496], "temperature": 0.0, "avg_logprob": -0.23857167002918955, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001150830532424152}, {"id": 1089, "seek": 451462, "start": 4537.26, "end": 4542.0599999999995, "text": " So these like are good tests of your ability to kind of like move things around.", "tokens": [51496, 407, 613, 411, 366, 665, 6921, 295, 428, 3485, 281, 733, 295, 411, 1286, 721, 926, 13, 51736], "temperature": 0.0, "avg_logprob": -0.23857167002918955, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.001150830532424152}, {"id": 1090, "seek": 454206, "start": 4542.900000000001, "end": 4546.9400000000005, "text": " If you're somewhere that doesn't have access to a decent internet connection or whatever,", "tokens": [50406, 759, 291, 434, 4079, 300, 1177, 380, 362, 2105, 281, 257, 8681, 4705, 4984, 420, 2035, 11, 50608], "temperature": 0.0, "avg_logprob": -0.23765565667833602, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0001141218890552409}, {"id": 1091, "seek": 454206, "start": 4546.9400000000005, "end": 4549.860000000001, "text": " this might be out of the question, in which case don't worry about it.", "tokens": [50608, 341, 1062, 312, 484, 295, 264, 1168, 11, 294, 597, 1389, 500, 380, 3292, 466, 309, 13, 50754], "temperature": 0.0, "avg_logprob": -0.23765565667833602, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0001141218890552409}, {"id": 1092, "seek": 454206, "start": 4549.860000000001, "end": 4555.38, "text": " But if you can, yes, try this because it's good practice, I think, to make sure you can", "tokens": [50754, 583, 498, 291, 393, 11, 2086, 11, 853, 341, 570, 309, 311, 665, 3124, 11, 286, 519, 11, 281, 652, 988, 291, 393, 51030], "temperature": 0.0, "avg_logprob": -0.23765565667833602, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0001141218890552409}, {"id": 1093, "seek": 454206, "start": 4555.38, "end": 4559.52, "text": " use these larger datasets.", "tokens": [51030, 764, 613, 4833, 42856, 13, 51237], "temperature": 0.0, "avg_logprob": -0.23765565667833602, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0001141218890552409}, {"id": 1094, "seek": 454206, "start": 4559.52, "end": 4565.580000000001, "text": " So ImageNet itself, you can actually grab from Kaggle nowadays.", "tokens": [51237, 407, 29903, 31890, 2564, 11, 291, 393, 767, 4444, 490, 48751, 22631, 13434, 13, 51540], "temperature": 0.0, "avg_logprob": -0.23765565667833602, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0001141218890552409}, {"id": 1095, "seek": 454206, "start": 4565.580000000001, "end": 4570.620000000001, "text": " So they call it the object localization challenge, but actually this contains the full ImageNet", "tokens": [51540, 407, 436, 818, 309, 264, 2657, 2654, 2144, 3430, 11, 457, 767, 341, 8306, 264, 1577, 29903, 31890, 51792], "temperature": 0.0, "avg_logprob": -0.23765565667833602, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0001141218890552409}, {"id": 1096, "seek": 454206, "start": 4570.620000000001, "end": 4571.620000000001, "text": " dataset.", "tokens": [51792, 28872, 13, 51842], "temperature": 0.0, "avg_logprob": -0.23765565667833602, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0001141218890552409}, {"id": 1097, "seek": 457162, "start": 4572.18, "end": 4576.3, "text": " Well, the version that's used for the ImageNet competition.", "tokens": [50392, 1042, 11, 264, 3037, 300, 311, 1143, 337, 264, 29903, 31890, 6211, 13, 50598], "temperature": 0.0, "avg_logprob": -0.30996557235717775, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0018674597376957536}, {"id": 1098, "seek": 457162, "start": 4576.3, "end": 4579.58, "text": " So I think people generally call it ImageNet one case.", "tokens": [50598, 407, 286, 519, 561, 5101, 818, 309, 29903, 31890, 472, 1389, 13, 50762], "temperature": 0.0, "avg_logprob": -0.30996557235717775, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0018674597376957536}, {"id": 1099, "seek": 457162, "start": 4579.58, "end": 4583.3, "text": " You just have to accept the terms because it has like some distribution terms.", "tokens": [50762, 509, 445, 362, 281, 3241, 264, 2115, 570, 309, 575, 411, 512, 7316, 2115, 13, 50948], "temperature": 0.0, "avg_logprob": -0.30996557235717775, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0018674597376957536}, {"id": 1100, "seek": 457162, "start": 4583.3, "end": 4584.3, "text": " Yeah, exactly.", "tokens": [50948, 865, 11, 2293, 13, 50998], "temperature": 0.0, "avg_logprob": -0.30996557235717775, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0018674597376957536}, {"id": 1101, "seek": 457162, "start": 4584.3, "end": 4589.26, "text": " So you've got to kind of sign in and then join the competition and then yeah, accept", "tokens": [50998, 407, 291, 600, 658, 281, 733, 295, 1465, 294, 293, 550, 3917, 264, 6211, 293, 550, 1338, 11, 3241, 51246], "temperature": 0.0, "avg_logprob": -0.30996557235717775, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0018674597376957536}, {"id": 1102, "seek": 457162, "start": 4589.26, "end": 4590.78, "text": " the terms.", "tokens": [51246, 264, 2115, 13, 51322], "temperature": 0.0, "avg_logprob": -0.30996557235717775, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0018674597376957536}, {"id": 1103, "seek": 457162, "start": 4590.78, "end": 4600.3, "text": " So you can then download the dataset or you can also download it from Hugging Face.", "tokens": [51322, 407, 291, 393, 550, 5484, 264, 28872, 420, 291, 393, 611, 5484, 309, 490, 46892, 3249, 4047, 13, 51798], "temperature": 0.0, "avg_logprob": -0.30996557235717775, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0018674597376957536}, {"id": 1104, "seek": 460030, "start": 4600.3, "end": 4604.28, "text": " That'll be in a somewhat different format, but that'll work as well.", "tokens": [50364, 663, 603, 312, 294, 257, 8344, 819, 7877, 11, 457, 300, 603, 589, 382, 731, 13, 50563], "temperature": 0.0, "avg_logprob": -0.33876723828523053, "compression_ratio": 1.4349775784753362, "no_speech_prob": 0.001597794471308589}, {"id": 1105, "seek": 460030, "start": 4604.28, "end": 4607.76, "text": " So I think I grabbed my version from Kaggle.", "tokens": [50563, 407, 286, 519, 286, 18607, 452, 3037, 490, 48751, 22631, 13, 50737], "temperature": 0.0, "avg_logprob": -0.33876723828523053, "compression_ratio": 1.4349775784753362, "no_speech_prob": 0.001597794471308589}, {"id": 1106, "seek": 460030, "start": 4607.76, "end": 4609.74, "text": " So on Kaggle, you know, it's just a zip file.", "tokens": [50737, 407, 322, 48751, 22631, 11, 291, 458, 11, 309, 311, 445, 257, 20730, 3991, 13, 50836], "temperature": 0.0, "avg_logprob": -0.33876723828523053, "compression_ratio": 1.4349775784753362, "no_speech_prob": 0.001597794471308589}, {"id": 1107, "seek": 460030, "start": 4609.74, "end": 4618.54, "text": " You unzip it and it creates an ILSVRC directory, which I think is what they call the competition.", "tokens": [50836, 509, 517, 27268, 309, 293, 309, 7829, 364, 286, 19198, 53, 28437, 21120, 11, 597, 286, 519, 307, 437, 436, 818, 264, 6211, 13, 51276], "temperature": 0.0, "avg_logprob": -0.33876723828523053, "compression_ratio": 1.4349775784753362, "no_speech_prob": 0.001597794471308589}, {"id": 1108, "seek": 460030, "start": 4618.54, "end": 4622.34, "text": " Yeah, ImageNet large scale visual recognition challenge.", "tokens": [51276, 865, 11, 29903, 31890, 2416, 4373, 5056, 11150, 3430, 13, 51466], "temperature": 0.0, "avg_logprob": -0.33876723828523053, "compression_ratio": 1.4349775784753362, "no_speech_prob": 0.001597794471308589}, {"id": 1109, "seek": 460030, "start": 4622.34, "end": 4624.14, "text": " Okay.", "tokens": [51466, 1033, 13, 51556], "temperature": 0.0, "avg_logprob": -0.33876723828523053, "compression_ratio": 1.4349775784753362, "no_speech_prob": 0.001597794471308589}, {"id": 1110, "seek": 462414, "start": 4624.14, "end": 4630.5, "text": " So then inside there, there is a data and inside there, there is a CLS lock and that's", "tokens": [50364, 407, 550, 1854, 456, 11, 456, 307, 257, 1412, 293, 1854, 456, 11, 456, 307, 257, 12855, 50, 4017, 293, 300, 311, 50682], "temperature": 0.0, "avg_logprob": -0.29528183512168354, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.0002737094182521105}, {"id": 1111, "seek": 462414, "start": 4630.5, "end": 4634.1, "text": " actually where the, that's where actually everything's going to be.", "tokens": [50682, 767, 689, 264, 11, 300, 311, 689, 767, 1203, 311, 516, 281, 312, 13, 50862], "temperature": 0.0, "avg_logprob": -0.29528183512168354, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.0002737094182521105}, {"id": 1112, "seek": 462414, "start": 4634.1, "end": 4638.320000000001, "text": " So just like before, I wanted to turn these all into latency.", "tokens": [50862, 407, 445, 411, 949, 11, 286, 1415, 281, 1261, 613, 439, 666, 27043, 13, 51073], "temperature": 0.0, "avg_logprob": -0.29528183512168354, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.0002737094182521105}, {"id": 1113, "seek": 462414, "start": 4638.320000000001, "end": 4644.26, "text": " So I created in that directory, I created a latency sub directory and this time partly", "tokens": [51073, 407, 286, 2942, 294, 300, 21120, 11, 286, 2942, 257, 27043, 1422, 21120, 293, 341, 565, 17031, 51370], "temperature": 0.0, "avg_logprob": -0.29528183512168354, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.0002737094182521105}, {"id": 1114, "seek": 462414, "start": 4644.26, "end": 4647.9400000000005, "text": " just to demonstrate how these things work, I want to do it a slightly different way.", "tokens": [51370, 445, 281, 11698, 577, 613, 721, 589, 11, 286, 528, 281, 360, 309, 257, 4748, 819, 636, 13, 51554], "temperature": 0.0, "avg_logprob": -0.29528183512168354, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.0002737094182521105}, {"id": 1115, "seek": 462414, "start": 4647.9400000000005, "end": 4648.9400000000005, "text": " Okay.", "tokens": [51554, 1033, 13, 51604], "temperature": 0.0, "avg_logprob": -0.29528183512168354, "compression_ratio": 1.7668161434977578, "no_speech_prob": 0.0002737094182521105}, {"id": 1116, "seek": 464894, "start": 4648.94, "end": 4654.98, "text": " So again, we're going to create our pre-trained VAE, pop it on the GPU, turn off gradients", "tokens": [50364, 407, 797, 11, 321, 434, 516, 281, 1884, 527, 659, 12, 17227, 2001, 18527, 36, 11, 1665, 309, 322, 264, 18407, 11, 1261, 766, 2771, 2448, 50666], "temperature": 0.0, "avg_logprob": -0.23638371987776322, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.00985929649323225}, {"id": 1117, "seek": 464894, "start": 4654.98, "end": 4659.139999999999, "text": " for it, and I'm going to create a dataset.", "tokens": [50666, 337, 309, 11, 293, 286, 478, 516, 281, 1884, 257, 28872, 13, 50874], "temperature": 0.0, "avg_logprob": -0.23638371987776322, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.00985929649323225}, {"id": 1118, "seek": 464894, "start": 4659.139999999999, "end": 4664.54, "text": " Now one thing that's a bit weird about this is that because this is really quite a big", "tokens": [50874, 823, 472, 551, 300, 311, 257, 857, 3657, 466, 341, 307, 300, 570, 341, 307, 534, 1596, 257, 955, 51144], "temperature": 0.0, "avg_logprob": -0.23638371987776322, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.00985929649323225}, {"id": 1119, "seek": 464894, "start": 4664.54, "end": 4675.179999999999, "text": " dataset, like it's got 1.3 million files, the thing where we go glob star star slash", "tokens": [51144, 28872, 11, 411, 309, 311, 658, 502, 13, 18, 2459, 7098, 11, 264, 551, 689, 321, 352, 16125, 3543, 3543, 17330, 51676], "temperature": 0.0, "avg_logprob": -0.23638371987776322, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.00985929649323225}, {"id": 1120, "seek": 467518, "start": 4675.18, "end": 4682.62, "text": " star dot jpg takes a few seconds, you know, and particularly if you're doing this on like,", "tokens": [50364, 3543, 5893, 361, 49861, 2516, 257, 1326, 3949, 11, 291, 458, 11, 293, 4098, 498, 291, 434, 884, 341, 322, 411, 11, 50736], "temperature": 0.0, "avg_logprob": -0.27341692997859074, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.058340635150671005}, {"id": 1121, "seek": 467518, "start": 4682.62, "end": 4687.66, "text": " you know, an AWS file system or something, it can take really quite a long time.", "tokens": [50736, 291, 458, 11, 364, 17650, 3991, 1185, 420, 746, 11, 309, 393, 747, 534, 1596, 257, 938, 565, 13, 50988], "temperature": 0.0, "avg_logprob": -0.27341692997859074, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.058340635150671005}, {"id": 1122, "seek": 467518, "start": 4687.66, "end": 4690.780000000001, "text": " On mine, it only took like three seconds, but I don't want to wait three seconds.", "tokens": [50988, 1282, 3892, 11, 309, 787, 1890, 411, 1045, 3949, 11, 457, 286, 500, 380, 528, 281, 1699, 1045, 3949, 13, 51144], "temperature": 0.0, "avg_logprob": -0.27341692997859074, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.058340635150671005}, {"id": 1123, "seek": 467518, "start": 4690.780000000001, "end": 4696.02, "text": " So I, you know, a common trick for these kinds of big things is to create a cache, which", "tokens": [51144, 407, 286, 11, 291, 458, 11, 257, 2689, 4282, 337, 613, 3685, 295, 955, 721, 307, 281, 1884, 257, 19459, 11, 597, 51406], "temperature": 0.0, "avg_logprob": -0.27341692997859074, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.058340635150671005}, {"id": 1124, "seek": 467518, "start": 4696.02, "end": 4698.320000000001, "text": " is literally just a list of the files.", "tokens": [51406, 307, 3736, 445, 257, 1329, 295, 264, 7098, 13, 51521], "temperature": 0.0, "avg_logprob": -0.27341692997859074, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.058340635150671005}, {"id": 1125, "seek": 467518, "start": 4698.320000000001, "end": 4699.9800000000005, "text": " So that's what this, this is.", "tokens": [51521, 407, 300, 311, 437, 341, 11, 341, 307, 13, 51604], "temperature": 0.0, "avg_logprob": -0.27341692997859074, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.058340635150671005}, {"id": 1126, "seek": 467518, "start": 4699.9800000000005, "end": 4704.34, "text": " So I decided that Z pickle means a g zipped pickle.", "tokens": [51604, 407, 286, 3047, 300, 1176, 31433, 1355, 257, 290, 710, 5529, 31433, 13, 51822], "temperature": 0.0, "avg_logprob": -0.27341692997859074, "compression_ratio": 1.6836363636363636, "no_speech_prob": 0.058340635150671005}, {"id": 1127, "seek": 470434, "start": 4704.34, "end": 4711.46, "text": " So what I do is if, if, if the cache exists, we just g zip dot open the files.", "tokens": [50364, 407, 437, 286, 360, 307, 498, 11, 498, 11, 498, 264, 19459, 8198, 11, 321, 445, 290, 20730, 5893, 1269, 264, 7098, 13, 50720], "temperature": 0.0, "avg_logprob": -0.2588480361784347, "compression_ratio": 1.6936936936936937, "no_speech_prob": 5.3074778406880796e-05}, {"id": 1128, "seek": 470434, "start": 4711.46, "end": 4715.1, "text": " If it doesn't, we use blob exactly like before to find all the files.", "tokens": [50720, 759, 309, 1177, 380, 11, 321, 764, 46115, 2293, 411, 949, 281, 915, 439, 264, 7098, 13, 50902], "temperature": 0.0, "avg_logprob": -0.2588480361784347, "compression_ratio": 1.6936936936936937, "no_speech_prob": 5.3074778406880796e-05}, {"id": 1129, "seek": 470434, "start": 4715.1, "end": 4721.7, "text": " And then we also save a g zip file containing pickle dot dump files.", "tokens": [50902, 400, 550, 321, 611, 3155, 257, 290, 20730, 3991, 19273, 31433, 5893, 11430, 7098, 13, 51232], "temperature": 0.0, "avg_logprob": -0.2588480361784347, "compression_ratio": 1.6936936936936937, "no_speech_prob": 5.3074778406880796e-05}, {"id": 1130, "seek": 470434, "start": 4721.7, "end": 4728.1, "text": " So pickle dot dump is what we use in Python to take basically any Python object list of", "tokens": [51232, 407, 31433, 5893, 11430, 307, 437, 321, 764, 294, 15329, 281, 747, 1936, 604, 15329, 2657, 1329, 295, 51552], "temperature": 0.0, "avg_logprob": -0.2588480361784347, "compression_ratio": 1.6936936936936937, "no_speech_prob": 5.3074778406880796e-05}, {"id": 1131, "seek": 470434, "start": 4728.1, "end": 4732.54, "text": " dictionaries and dictionary of lists, whatever you like and save them.", "tokens": [51552, 22352, 4889, 293, 25890, 295, 14511, 11, 2035, 291, 411, 293, 3155, 552, 13, 51774], "temperature": 0.0, "avg_logprob": -0.2588480361784347, "compression_ratio": 1.6936936936936937, "no_speech_prob": 5.3074778406880796e-05}, {"id": 1132, "seek": 473254, "start": 4732.54, "end": 4734.7, "text": " It's super fast, right?", "tokens": [50364, 467, 311, 1687, 2370, 11, 558, 30, 50472], "temperature": 0.0, "avg_logprob": -0.2209894816080729, "compression_ratio": 1.6465863453815262, "no_speech_prob": 6.50280635454692e-05}, {"id": 1133, "seek": 473254, "start": 4734.7, "end": 4739.54, "text": " And I use g zip with compressed level one to basically be like compress it pretty well,", "tokens": [50472, 400, 286, 764, 290, 20730, 365, 30353, 1496, 472, 281, 1936, 312, 411, 14778, 309, 1238, 731, 11, 50714], "temperature": 0.0, "avg_logprob": -0.2209894816080729, "compression_ratio": 1.6465863453815262, "no_speech_prob": 6.50280635454692e-05}, {"id": 1134, "seek": 473254, "start": 4739.54, "end": 4740.98, "text": " but pretty fast.", "tokens": [50714, 457, 1238, 2370, 13, 50786], "temperature": 0.0, "avg_logprob": -0.2209894816080729, "compression_ratio": 1.6465863453815262, "no_speech_prob": 6.50280635454692e-05}, {"id": 1135, "seek": 473254, "start": 4740.98, "end": 4747.74, "text": " So this is a really nice way to create a little cache of that.", "tokens": [50786, 407, 341, 307, 257, 534, 1481, 636, 281, 1884, 257, 707, 19459, 295, 300, 13, 51124], "temperature": 0.0, "avg_logprob": -0.2209894816080729, "compression_ratio": 1.6465863453815262, "no_speech_prob": 6.50280635454692e-05}, {"id": 1136, "seek": 473254, "start": 4747.74, "end": 4749.42, "text": " So this is the same as always.", "tokens": [51124, 407, 341, 307, 264, 912, 382, 1009, 13, 51208], "temperature": 0.0, "avg_logprob": -0.2209894816080729, "compression_ratio": 1.6465863453815262, "no_speech_prob": 6.50280635454692e-05}, {"id": 1137, "seek": 473254, "start": 4749.42, "end": 4753.24, "text": " And so our get item is going to grab the file.", "tokens": [51208, 400, 370, 527, 483, 3174, 307, 516, 281, 4444, 264, 3991, 13, 51399], "temperature": 0.0, "avg_logprob": -0.2209894816080729, "compression_ratio": 1.6465863453815262, "no_speech_prob": 6.50280635454692e-05}, {"id": 1138, "seek": 473254, "start": 4753.24, "end": 4756.58, "text": " It's going to read it in, turn it into a float.", "tokens": [51399, 467, 311, 516, 281, 1401, 309, 294, 11, 1261, 309, 666, 257, 15706, 13, 51566], "temperature": 0.0, "avg_logprob": -0.2209894816080729, "compression_ratio": 1.6465863453815262, "no_speech_prob": 6.50280635454692e-05}, {"id": 1139, "seek": 473254, "start": 4756.58, "end": 4761.1, "text": " And what I did here was, you know, I'm being a little bit lazy, but I just decided to center", "tokens": [51566, 400, 437, 286, 630, 510, 390, 11, 291, 458, 11, 286, 478, 885, 257, 707, 857, 14847, 11, 457, 286, 445, 3047, 281, 3056, 51792], "temperature": 0.0, "avg_logprob": -0.2209894816080729, "compression_ratio": 1.6465863453815262, "no_speech_prob": 6.50280635454692e-05}, {"id": 1140, "seek": 476110, "start": 4761.1, "end": 4767.5, "text": " crop the middle, you know, so let's say it was a 300 by 400 file.", "tokens": [50364, 9086, 264, 2808, 11, 291, 458, 11, 370, 718, 311, 584, 309, 390, 257, 6641, 538, 8423, 3991, 13, 50684], "temperature": 0.0, "avg_logprob": -0.2937674790285946, "compression_ratio": 1.5164835164835164, "no_speech_prob": 8.481052645947784e-05}, {"id": 1141, "seek": 476110, "start": 4767.5, "end": 4771.820000000001, "text": " It's going to center crop the middle 300 by 300 section.", "tokens": [50684, 467, 311, 516, 281, 3056, 9086, 264, 2808, 6641, 538, 6641, 3541, 13, 50900], "temperature": 0.0, "avg_logprob": -0.2937674790285946, "compression_ratio": 1.5164835164835164, "no_speech_prob": 8.481052645947784e-05}, {"id": 1142, "seek": 476110, "start": 4771.820000000001, "end": 4776.660000000001, "text": " And then resize it to 256 by 256.", "tokens": [50900, 400, 550, 50069, 309, 281, 38882, 538, 38882, 13, 51142], "temperature": 0.0, "avg_logprob": -0.2937674790285946, "compression_ratio": 1.5164835164835164, "no_speech_prob": 8.481052645947784e-05}, {"id": 1143, "seek": 476110, "start": 4776.660000000001, "end": 4779.5, "text": " So they'll all be the same size.", "tokens": [51142, 407, 436, 603, 439, 312, 264, 912, 2744, 13, 51284], "temperature": 0.0, "avg_logprob": -0.2937674790285946, "compression_ratio": 1.5164835164835164, "no_speech_prob": 8.481052645947784e-05}, {"id": 1144, "seek": 476110, "start": 4779.5, "end": 4785.34, "text": " So yeah, we can now, oh, I managed to create the VAU twice.", "tokens": [51284, 407, 1338, 11, 321, 393, 586, 11, 1954, 11, 286, 6453, 281, 1884, 264, 691, 2340, 6091, 13, 51576], "temperature": 0.0, "avg_logprob": -0.2937674790285946, "compression_ratio": 1.5164835164835164, "no_speech_prob": 8.481052645947784e-05}, {"id": 1145, "seek": 476110, "start": 4785.34, "end": 4786.5, "text": " So I can now just confirm.", "tokens": [51576, 407, 286, 393, 586, 445, 9064, 13, 51634], "temperature": 0.0, "avg_logprob": -0.2937674790285946, "compression_ratio": 1.5164835164835164, "no_speech_prob": 8.481052645947784e-05}, {"id": 1146, "seek": 478650, "start": 4786.5, "end": 4791.06, "text": " I can grab a batch from that data loader, encode it.", "tokens": [50364, 286, 393, 4444, 257, 15245, 490, 300, 1412, 3677, 260, 11, 2058, 1429, 309, 13, 50592], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1147, "seek": 478650, "start": 4791.06, "end": 4792.74, "text": " And here it is.", "tokens": [50592, 400, 510, 309, 307, 13, 50676], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1148, "seek": 478650, "start": 4792.74, "end": 4794.3, "text": " And then decode it again.", "tokens": [50676, 400, 550, 979, 1429, 309, 797, 13, 50754], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1149, "seek": 478650, "start": 4794.3, "end": 4795.3, "text": " And here it is.", "tokens": [50754, 400, 510, 309, 307, 13, 50804], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1150, "seek": 478650, "start": 4795.3, "end": 4798.14, "text": " So perhaps the first category must have been computer or something.", "tokens": [50804, 407, 4317, 264, 700, 7719, 1633, 362, 668, 3820, 420, 746, 13, 50946], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1151, "seek": 478650, "start": 4798.14, "end": 4805.82, "text": " So here's, as you can see, the VAU is doing a good job of decoding pictures of computers.", "tokens": [50946, 407, 510, 311, 11, 382, 291, 393, 536, 11, 264, 691, 2340, 307, 884, 257, 665, 1691, 295, 979, 8616, 5242, 295, 10807, 13, 51330], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1152, "seek": 478650, "start": 4805.82, "end": 4809.08, "text": " So I can do something really very similar to what we did before.", "tokens": [51330, 407, 286, 393, 360, 746, 534, 588, 2531, 281, 437, 321, 630, 949, 13, 51493], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1153, "seek": 478650, "start": 4809.08, "end": 4813.82, "text": " If we haven't got that destination directory yet created, go through our data loader, encode", "tokens": [51493, 759, 321, 2378, 380, 658, 300, 12236, 21120, 1939, 2942, 11, 352, 807, 527, 1412, 3677, 260, 11, 2058, 1429, 51730], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1154, "seek": 478650, "start": 4813.82, "end": 4815.5, "text": " a batch.", "tokens": [51730, 257, 15245, 13, 51814], "temperature": 0.0, "avg_logprob": -0.23975407409667968, "compression_ratio": 1.74, "no_speech_prob": 0.012428131885826588}, {"id": 1155, "seek": 481550, "start": 4815.5, "end": 4817.26, "text": " And this time I'm not using a mem mapped file.", "tokens": [50364, 400, 341, 565, 286, 478, 406, 1228, 257, 1334, 33318, 3991, 13, 50452], "temperature": 0.0, "avg_logprob": -0.28381905465755825, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.757632268592715e-05}, {"id": 1156, "seek": 481550, "start": 4817.26, "end": 4821.78, "text": " I'm actually going to save separate numpy files for each one.", "tokens": [50452, 286, 478, 767, 516, 281, 3155, 4994, 1031, 8200, 7098, 337, 1184, 472, 13, 50678], "temperature": 0.0, "avg_logprob": -0.28381905465755825, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.757632268592715e-05}, {"id": 1157, "seek": 481550, "start": 4821.78, "end": 4826.42, "text": " So go through each element of the batch, each item.", "tokens": [50678, 407, 352, 807, 1184, 4478, 295, 264, 15245, 11, 1184, 3174, 13, 50910], "temperature": 0.0, "avg_logprob": -0.28381905465755825, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.757632268592715e-05}, {"id": 1158, "seek": 481550, "start": 4826.42, "end": 4830.02, "text": " So I'm going to save it into the destination directory, which is the latent directory.", "tokens": [50910, 407, 286, 478, 516, 281, 3155, 309, 666, 264, 12236, 21120, 11, 597, 307, 264, 287, 267, 317, 21120, 13, 51090], "temperature": 0.0, "avg_logprob": -0.28381905465755825, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.757632268592715e-05}, {"id": 1159, "seek": 481550, "start": 4830.02, "end": 4834.9, "text": " And I'm going to give it exactly the same path as the original one contained, because", "tokens": [51090, 400, 286, 478, 516, 281, 976, 309, 2293, 264, 912, 3100, 382, 264, 3380, 472, 16212, 11, 570, 51334], "temperature": 0.0, "avg_logprob": -0.28381905465755825, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.757632268592715e-05}, {"id": 1160, "seek": 481550, "start": 4834.9, "end": 4843.98, "text": " it contains the, you know, the folder of like what the label is.", "tokens": [51334, 309, 8306, 264, 11, 291, 458, 11, 264, 10820, 295, 411, 437, 264, 7645, 307, 13, 51788], "temperature": 0.0, "avg_logprob": -0.28381905465755825, "compression_ratio": 1.7081545064377683, "no_speech_prob": 4.757632268592715e-05}, {"id": 1161, "seek": 484398, "start": 4843.98, "end": 4849.5, "text": " Make sure that the directory exists that we're saving it to, and save that just as", "tokens": [50364, 4387, 988, 300, 264, 21120, 8198, 300, 321, 434, 6816, 309, 281, 11, 293, 3155, 300, 445, 382, 50640], "temperature": 0.0, "avg_logprob": -0.31067107351202716, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0013884245418012142}, {"id": 1162, "seek": 484398, "start": 4849.5, "end": 4851.0199999999995, "text": " a numpy file.", "tokens": [50640, 257, 1031, 8200, 3991, 13, 50716], "temperature": 0.0, "avg_logprob": -0.31067107351202716, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0013884245418012142}, {"id": 1163, "seek": 484398, "start": 4851.0199999999995, "end": 4852.259999999999, "text": " This is another way to do it.", "tokens": [50716, 639, 307, 1071, 636, 281, 360, 309, 13, 50778], "temperature": 0.0, "avg_logprob": -0.31067107351202716, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0013884245418012142}, {"id": 1164, "seek": 484398, "start": 4852.259999999999, "end": 4856.299999999999, "text": " So this is going to be a separate numpy file for each item.", "tokens": [50778, 407, 341, 307, 516, 281, 312, 257, 4994, 1031, 8200, 3991, 337, 1184, 3174, 13, 50980], "temperature": 0.0, "avg_logprob": -0.31067107351202716, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0013884245418012142}, {"id": 1165, "seek": 484398, "start": 4856.299999999999, "end": 4860.86, "text": " Does that make sense so far?", "tokens": [50980, 4402, 300, 652, 2020, 370, 1400, 30, 51208], "temperature": 0.0, "avg_logprob": -0.31067107351202716, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0013884245418012142}, {"id": 1166, "seek": 484398, "start": 4860.86, "end": 4864.099999999999, "text": " Okay, cool.", "tokens": [51208, 1033, 11, 1627, 13, 51370], "temperature": 0.0, "avg_logprob": -0.31067107351202716, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0013884245418012142}, {"id": 1167, "seek": 484398, "start": 4864.099999999999, "end": 4869.419999999999, "text": " So I could create a thing called a numpy dataset, which is exactly the same as our images dataset.", "tokens": [51370, 407, 286, 727, 1884, 257, 551, 1219, 257, 1031, 8200, 28872, 11, 597, 307, 2293, 264, 912, 382, 527, 5267, 28872, 13, 51636], "temperature": 0.0, "avg_logprob": -0.31067107351202716, "compression_ratio": 1.5377358490566038, "no_speech_prob": 0.0013884245418012142}, {"id": 1168, "seek": 486942, "start": 4869.5, "end": 4874.42, "text": " To get an item, we don't have to use, you know, open a JPEG anymore.", "tokens": [50368, 1407, 483, 364, 3174, 11, 321, 500, 380, 362, 281, 764, 11, 291, 458, 11, 1269, 257, 508, 5208, 38, 3602, 13, 50614], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1169, "seek": 486942, "start": 4874.42, "end": 4875.78, "text": " We just call mp.load.", "tokens": [50614, 492, 445, 818, 275, 79, 13, 2907, 13, 50682], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1170, "seek": 486942, "start": 4875.78, "end": 4882.82, "text": " So this is a nice way to like take something you've already got and change it slightly.", "tokens": [50682, 407, 341, 307, 257, 1481, 636, 281, 411, 747, 746, 291, 600, 1217, 658, 293, 1319, 309, 4748, 13, 51034], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1171, "seek": 486942, "start": 4882.82, "end": 4884.3, "text": " So it's going to return the...", "tokens": [51034, 407, 309, 311, 516, 281, 2736, 264, 485, 51108], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1172, "seek": 486942, "start": 4884.3, "end": 4887.1, "text": " Where did you do this versus the memory mapped file, Jeremy?", "tokens": [51108, 2305, 630, 291, 360, 341, 5717, 264, 4675, 33318, 3991, 11, 17809, 30, 51248], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1173, "seek": 486942, "start": 4887.1, "end": 4888.1, "text": " Just out of interest.", "tokens": [51248, 1449, 484, 295, 1179, 13, 51298], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1174, "seek": 486942, "start": 4888.1, "end": 4889.1, "text": " Sorry?", "tokens": [51298, 4919, 30, 51348], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1175, "seek": 486942, "start": 4889.1, "end": 4893.1, "text": " Where did you do this versus the memory mapped file?", "tokens": [51348, 2305, 630, 291, 360, 341, 5717, 264, 4675, 33318, 3991, 30, 51548], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1176, "seek": 486942, "start": 4893.1, "end": 4894.1, "text": " Was it just to show a different way?", "tokens": [51548, 3027, 309, 445, 281, 855, 257, 819, 636, 30, 51598], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1177, "seek": 486942, "start": 4894.1, "end": 4895.7, "text": " Just to show a different way.", "tokens": [51598, 1449, 281, 855, 257, 819, 636, 13, 51678], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1178, "seek": 486942, "start": 4895.7, "end": 4896.7, "text": " Yeah.", "tokens": [51678, 865, 13, 51728], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1179, "seek": 486942, "start": 4896.7, "end": 4897.7, "text": " Yeah.", "tokens": [51728, 865, 13, 51778], "temperature": 0.0, "avg_logprob": -0.3548406914098939, "compression_ratio": 1.7520325203252032, "no_speech_prob": 0.005219890736043453}, {"id": 1180, "seek": 489770, "start": 4897.7, "end": 4902.179999999999, "text": " I think that's definitely no particularly good reason, honestly.", "tokens": [50364, 286, 519, 300, 311, 2138, 572, 4098, 665, 1778, 11, 6095, 13, 50588], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1181, "seek": 489770, "start": 4902.179999999999, "end": 4906.94, "text": " Yeah, I like to kind of like demonstrate different approaches.", "tokens": [50588, 865, 11, 286, 411, 281, 733, 295, 411, 11698, 819, 11587, 13, 50826], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1182, "seek": 489770, "start": 4906.94, "end": 4911.7, "text": " And I think it's good for people's Python coding if you make sure you understand what", "tokens": [50826, 400, 286, 519, 309, 311, 665, 337, 561, 311, 15329, 17720, 498, 291, 652, 988, 291, 1223, 437, 51064], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1183, "seek": 489770, "start": 4911.7, "end": 4912.9, "text": " all the lines of code do.", "tokens": [51064, 439, 264, 3876, 295, 3089, 360, 13, 51124], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1184, "seek": 489770, "start": 4912.9, "end": 4915.58, "text": " Yeah, they both work fine, actually.", "tokens": [51124, 865, 11, 436, 1293, 589, 2489, 11, 767, 13, 51258], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1185, "seek": 489770, "start": 4915.58, "end": 4919.139999999999, "text": " It's partly also for my own experimental interest.", "tokens": [51258, 467, 311, 17031, 611, 337, 452, 1065, 17069, 1179, 13, 51436], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1186, "seek": 489770, "start": 4919.139999999999, "end": 4922.38, "text": " It's like, oh, which one seems to kind of feel better?", "tokens": [51436, 467, 311, 411, 11, 1954, 11, 597, 472, 2544, 281, 733, 295, 841, 1101, 30, 51598], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1187, "seek": 489770, "start": 4922.38, "end": 4923.38, "text": " Yeah.", "tokens": [51598, 865, 13, 51648], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1188, "seek": 489770, "start": 4923.38, "end": 4926.38, "text": " All right.", "tokens": [51648, 1057, 558, 13, 51798], "temperature": 0.0, "avg_logprob": -0.4606667271366826, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.06275931000709534}, {"id": 1189, "seek": 492638, "start": 4926.38, "end": 4932.74, "text": " So create out training and validation datasets by grabbing all the NumPy files inside the", "tokens": [50364, 407, 1884, 484, 3097, 293, 24071, 42856, 538, 23771, 439, 264, 22592, 47, 88, 7098, 1854, 264, 50682], "temperature": 0.0, "avg_logprob": -0.2571986602233337, "compression_ratio": 1.9075630252100841, "no_speech_prob": 0.017710885033011436}, {"id": 1190, "seek": 492638, "start": 4932.74, "end": 4935.74, "text": " training and validation folders.", "tokens": [50682, 3097, 293, 24071, 31082, 13, 50832], "temperature": 0.0, "avg_logprob": -0.2571986602233337, "compression_ratio": 1.9075630252100841, "no_speech_prob": 0.017710885033011436}, {"id": 1191, "seek": 492638, "start": 4935.74, "end": 4941.06, "text": " And then I'm going to just create a training data loader for the training dataset, just", "tokens": [50832, 400, 550, 286, 478, 516, 281, 445, 1884, 257, 3097, 1412, 3677, 260, 337, 264, 3097, 28872, 11, 445, 51098], "temperature": 0.0, "avg_logprob": -0.2571986602233337, "compression_ratio": 1.9075630252100841, "no_speech_prob": 0.017710885033011436}, {"id": 1192, "seek": 492638, "start": 4941.06, "end": 4945.58, "text": " to see what the mean and standard deviation is on the channel dimension.", "tokens": [51098, 281, 536, 437, 264, 914, 293, 3832, 25163, 307, 322, 264, 2269, 10139, 13, 51324], "temperature": 0.0, "avg_logprob": -0.2571986602233337, "compression_ratio": 1.9075630252100841, "no_speech_prob": 0.017710885033011436}, {"id": 1193, "seek": 492638, "start": 4945.58, "end": 4948.7, "text": " So this is every dimension except channel, what I mean, over.", "tokens": [51324, 407, 341, 307, 633, 10139, 3993, 2269, 11, 437, 286, 914, 11, 670, 13, 51480], "temperature": 0.0, "avg_logprob": -0.2571986602233337, "compression_ratio": 1.9075630252100841, "no_speech_prob": 0.017710885033011436}, {"id": 1194, "seek": 492638, "start": 4948.7, "end": 4949.7, "text": " And so there it is.", "tokens": [51480, 400, 370, 456, 309, 307, 13, 51530], "temperature": 0.0, "avg_logprob": -0.2571986602233337, "compression_ratio": 1.9075630252100841, "no_speech_prob": 0.017710885033011436}, {"id": 1195, "seek": 492638, "start": 4949.7, "end": 4954.3, "text": " And as you can see there, the mean and standard deviation are not close to zero and one.", "tokens": [51530, 400, 382, 291, 393, 536, 456, 11, 264, 914, 293, 3832, 25163, 366, 406, 1998, 281, 4018, 293, 472, 13, 51760], "temperature": 0.0, "avg_logprob": -0.2571986602233337, "compression_ratio": 1.9075630252100841, "no_speech_prob": 0.017710885033011436}, {"id": 1196, "seek": 495430, "start": 4954.3, "end": 4961.1, "text": " So we're going to store away that mean and standard deviation such that we then, we've", "tokens": [50364, 407, 321, 434, 516, 281, 3531, 1314, 300, 914, 293, 3832, 25163, 1270, 300, 321, 550, 11, 321, 600, 50704], "temperature": 0.0, "avg_logprob": -0.3228404998779297, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.00011235216516070068}, {"id": 1197, "seek": 495430, "start": 4961.1, "end": 4962.5, "text": " seen transform dataset before.", "tokens": [50704, 1612, 4088, 28872, 949, 13, 50774], "temperature": 0.0, "avg_logprob": -0.3228404998779297, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.00011235216516070068}, {"id": 1198, "seek": 495430, "start": 4962.5, "end": 4964.7, "text": " This is just applying a transform to a dataset.", "tokens": [50774, 639, 307, 445, 9275, 257, 4088, 281, 257, 28872, 13, 50884], "temperature": 0.0, "avg_logprob": -0.3228404998779297, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.00011235216516070068}, {"id": 1199, "seek": 495430, "start": 4964.7, "end": 4968.5, "text": " We're going to apply the normalization transform.", "tokens": [50884, 492, 434, 516, 281, 3079, 264, 2710, 2144, 4088, 13, 51074], "temperature": 0.0, "avg_logprob": -0.3228404998779297, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.00011235216516070068}, {"id": 1200, "seek": 495430, "start": 4968.5, "end": 4971.62, "text": " In the past, we've just, we've used our own normalization.", "tokens": [51074, 682, 264, 1791, 11, 321, 600, 445, 11, 321, 600, 1143, 527, 1065, 2710, 2144, 13, 51230], "temperature": 0.0, "avg_logprob": -0.3228404998779297, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.00011235216516070068}, {"id": 1201, "seek": 495430, "start": 4971.62, "end": 4974.22, "text": " That TorchVision has one as well.", "tokens": [51230, 663, 7160, 339, 53, 1991, 575, 472, 382, 731, 13, 51360], "temperature": 0.0, "avg_logprob": -0.3228404998779297, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.00011235216516070068}, {"id": 1202, "seek": 495430, "start": 4974.22, "end": 4977.820000000001, "text": " So this is just demonstrating how to just use TorchVision's version.", "tokens": [51360, 407, 341, 307, 445, 29889, 577, 281, 445, 764, 7160, 339, 53, 1991, 311, 3037, 13, 51540], "temperature": 0.0, "avg_logprob": -0.3228404998779297, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.00011235216516070068}, {"id": 1203, "seek": 495430, "start": 4977.820000000001, "end": 4984.26, "text": " But it's literally just subtracting the mean and dividing by the standard deviation.", "tokens": [51540, 583, 309, 311, 3736, 445, 16390, 278, 264, 914, 293, 26764, 538, 264, 3832, 25163, 13, 51862], "temperature": 0.0, "avg_logprob": -0.3228404998779297, "compression_ratio": 1.8780487804878048, "no_speech_prob": 0.00011235216516070068}, {"id": 1204, "seek": 498426, "start": 4984.9800000000005, "end": 4988.42, "text": " We're also going to apply some data augmentation.", "tokens": [50400, 492, 434, 611, 516, 281, 3079, 512, 1412, 14501, 19631, 13, 50572], "temperature": 0.0, "avg_logprob": -0.2565544545650482, "compression_ratio": 1.7366548042704626, "no_speech_prob": 4.029449428344378e-06}, {"id": 1205, "seek": 498426, "start": 4988.42, "end": 4992.54, "text": " We're going to use the same trick we've used before for images that are very small, which", "tokens": [50572, 492, 434, 516, 281, 764, 264, 912, 4282, 321, 600, 1143, 949, 337, 5267, 300, 366, 588, 1359, 11, 597, 50778], "temperature": 0.0, "avg_logprob": -0.2565544545650482, "compression_ratio": 1.7366548042704626, "no_speech_prob": 4.029449428344378e-06}, {"id": 1206, "seek": 498426, "start": 4992.54, "end": 4997.54, "text": " is we're going to add a little bit of padding and then randomly crop our original image", "tokens": [50778, 307, 321, 434, 516, 281, 909, 257, 707, 857, 295, 39562, 293, 550, 16979, 9086, 527, 3380, 3256, 51028], "temperature": 0.0, "avg_logprob": -0.2565544545650482, "compression_ratio": 1.7366548042704626, "no_speech_prob": 4.029449428344378e-06}, {"id": 1207, "seek": 498426, "start": 4997.54, "end": 4999.14, "text": " size from that.", "tokens": [51028, 2744, 490, 300, 13, 51108], "temperature": 0.0, "avg_logprob": -0.2565544545650482, "compression_ratio": 1.7366548042704626, "no_speech_prob": 4.029449428344378e-06}, {"id": 1208, "seek": 498426, "start": 4999.14, "end": 5003.5, "text": " So it's just like shifting it slightly each time.", "tokens": [51108, 407, 309, 311, 445, 411, 17573, 309, 4748, 1184, 565, 13, 51326], "temperature": 0.0, "avg_logprob": -0.2565544545650482, "compression_ratio": 1.7366548042704626, "no_speech_prob": 4.029449428344378e-06}, {"id": 1209, "seek": 498426, "start": 5003.5, "end": 5005.06, "text": " And we're also going to use our random erasing.", "tokens": [51326, 400, 321, 434, 611, 516, 281, 764, 527, 4974, 1189, 3349, 13, 51404], "temperature": 0.0, "avg_logprob": -0.2565544545650482, "compression_ratio": 1.7366548042704626, "no_speech_prob": 4.029449428344378e-06}, {"id": 1210, "seek": 498426, "start": 5005.06, "end": 5008.780000000001, "text": " And it's nice because we did it all with broadcasting.", "tokens": [51404, 400, 309, 311, 1481, 570, 321, 630, 309, 439, 365, 30024, 13, 51590], "temperature": 0.0, "avg_logprob": -0.2565544545650482, "compression_ratio": 1.7366548042704626, "no_speech_prob": 4.029449428344378e-06}, {"id": 1211, "seek": 498426, "start": 5008.780000000001, "end": 5013.780000000001, "text": " This is going to apply equally well to a four channel image as it is to a three, or I think", "tokens": [51590, 639, 307, 516, 281, 3079, 12309, 731, 281, 257, 1451, 2269, 3256, 382, 309, 307, 281, 257, 1045, 11, 420, 286, 519, 51840], "temperature": 0.0, "avg_logprob": -0.2565544545650482, "compression_ratio": 1.7366548042704626, "no_speech_prob": 4.029449428344378e-06}, {"id": 1212, "seek": 501378, "start": 5013.78, "end": 5017.099999999999, "text": " we did originally for one.", "tokens": [50364, 321, 630, 7993, 337, 472, 13, 50530], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1213, "seek": 501378, "start": 5017.099999999999, "end": 5021.98, "text": " Now, you know, I don't think anybody as far as I know has built classifiers from Latents", "tokens": [50530, 823, 11, 291, 458, 11, 286, 500, 380, 519, 4472, 382, 1400, 382, 286, 458, 575, 3094, 1508, 23463, 490, 7354, 791, 50774], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1214, "seek": 501378, "start": 5021.98, "end": 5022.98, "text": " before.", "tokens": [50774, 949, 13, 50824], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1215, "seek": 501378, "start": 5022.98, "end": 5025.0599999999995, "text": " So like I didn't even know if this is going to work.", "tokens": [50824, 407, 411, 286, 994, 380, 754, 458, 498, 341, 307, 516, 281, 589, 13, 50928], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1216, "seek": 501378, "start": 5025.0599999999995, "end": 5026.58, "text": " So I visualized it.", "tokens": [50928, 407, 286, 5056, 1602, 309, 13, 51004], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1217, "seek": 501378, "start": 5026.58, "end": 5030.46, "text": " So we could have a TIFM X and a TIFM Y.", "tokens": [51004, 407, 321, 727, 362, 257, 314, 12775, 44, 1783, 293, 257, 314, 12775, 44, 398, 13, 51198], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1218, "seek": 501378, "start": 5030.46, "end": 5034.5, "text": " So for TIFM X, you can optionally add augmentation.", "tokens": [51198, 407, 337, 314, 12775, 44, 1783, 11, 291, 393, 3614, 379, 909, 14501, 19631, 13, 51400], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1219, "seek": 501378, "start": 5034.5, "end": 5038.0599999999995, "text": " And if you do, then apply the augmentation transforms.", "tokens": [51400, 400, 498, 291, 360, 11, 550, 3079, 264, 14501, 19631, 35592, 13, 51578], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1220, "seek": 501378, "start": 5038.0599999999995, "end": 5040.5, "text": " Now this is going to be applied one image at a time.", "tokens": [51578, 823, 341, 307, 516, 281, 312, 6456, 472, 3256, 412, 257, 565, 13, 51700], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1221, "seek": 501378, "start": 5040.5, "end": 5043.42, "text": " But our augmentation transforms, some of them expect to batch.", "tokens": [51700, 583, 527, 14501, 19631, 35592, 11, 512, 295, 552, 2066, 281, 15245, 13, 51846], "temperature": 0.0, "avg_logprob": -0.31262271962267285, "compression_ratio": 1.7, "no_speech_prob": 2.467910962877795e-05}, {"id": 1222, "seek": 504342, "start": 5044.06, "end": 5050.78, "text": " So we create a extra unit axis on the front to be a batch of one and then remove it again.", "tokens": [50396, 407, 321, 1884, 257, 2857, 4985, 10298, 322, 264, 1868, 281, 312, 257, 15245, 295, 472, 293, 550, 4159, 309, 797, 13, 50732], "temperature": 0.0, "avg_logprob": -0.25442795420801917, "compression_ratio": 1.5270935960591132, "no_speech_prob": 5.421848072728608e-06}, {"id": 1223, "seek": 504342, "start": 5050.78, "end": 5056.54, "text": " And then TIFM Y, very much like we've seen before, we're going to turn those path names", "tokens": [50732, 400, 550, 314, 12775, 44, 398, 11, 588, 709, 411, 321, 600, 1612, 949, 11, 321, 434, 516, 281, 1261, 729, 3100, 5288, 51020], "temperature": 0.0, "avg_logprob": -0.25442795420801917, "compression_ratio": 1.5270935960591132, "no_speech_prob": 5.421848072728608e-06}, {"id": 1224, "seek": 504342, "start": 5056.54, "end": 5057.54, "text": " into IDs.", "tokens": [51020, 666, 48212, 13, 51070], "temperature": 0.0, "avg_logprob": -0.25442795420801917, "compression_ratio": 1.5270935960591132, "no_speech_prob": 5.421848072728608e-06}, {"id": 1225, "seek": 504342, "start": 5057.54, "end": 5063.9, "text": " So there's our validation and training transform datasets.", "tokens": [51070, 407, 456, 311, 527, 24071, 293, 3097, 4088, 42856, 13, 51388], "temperature": 0.0, "avg_logprob": -0.25442795420801917, "compression_ratio": 1.5270935960591132, "no_speech_prob": 5.421848072728608e-06}, {"id": 1226, "seek": 504342, "start": 5063.9, "end": 5070.38, "text": " So that we can look at our results, we need a denormalization.", "tokens": [51388, 407, 300, 321, 393, 574, 412, 527, 3542, 11, 321, 643, 257, 1441, 24440, 2144, 13, 51712], "temperature": 0.0, "avg_logprob": -0.25442795420801917, "compression_ratio": 1.5270935960591132, "no_speech_prob": 5.421848072728608e-06}, {"id": 1227, "seek": 507038, "start": 5070.38, "end": 5077.26, "text": " So let's create our data loaders and grab mini batches and show us.", "tokens": [50364, 407, 718, 311, 1884, 527, 1412, 3677, 433, 293, 4444, 8382, 15245, 279, 293, 855, 505, 13, 50708], "temperature": 0.0, "avg_logprob": -0.2780826915394176, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.00020661455346271396}, {"id": 1228, "seek": 507038, "start": 5077.26, "end": 5080.7, "text": " And so I was very pleased to see that the random arrays works actually extremely nicely.", "tokens": [50708, 400, 370, 286, 390, 588, 10587, 281, 536, 300, 264, 4974, 41011, 1985, 767, 4664, 9594, 13, 50880], "temperature": 0.0, "avg_logprob": -0.2780826915394176, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.00020661455346271396}, {"id": 1229, "seek": 507038, "start": 5080.7, "end": 5089.14, "text": " So you can see you get these kind of like weird patches, you know, weird patches.", "tokens": [50880, 407, 291, 393, 536, 291, 483, 613, 733, 295, 411, 3657, 26531, 11, 291, 458, 11, 3657, 26531, 13, 51302], "temperature": 0.0, "avg_logprob": -0.2780826915394176, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.00020661455346271396}, {"id": 1230, "seek": 507038, "start": 5089.14, "end": 5092.06, "text": " But it's still, they're still recognizable.", "tokens": [51302, 583, 309, 311, 920, 11, 436, 434, 920, 40757, 13, 51448], "temperature": 0.0, "avg_logprob": -0.2780826915394176, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.00020661455346271396}, {"id": 1231, "seek": 507038, "start": 5092.06, "end": 5096.66, "text": " So this is, this is like something I very, very often do is to answer like, oh, is this", "tokens": [51448, 407, 341, 307, 11, 341, 307, 411, 746, 286, 588, 11, 588, 2049, 360, 307, 281, 1867, 411, 11, 1954, 11, 307, 341, 51678], "temperature": 0.0, "avg_logprob": -0.2780826915394176, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.00020661455346271396}, {"id": 1232, "seek": 507038, "start": 5096.66, "end": 5098.900000000001, "text": " like thing I'm doing in computer vision reasonable?", "tokens": [51678, 411, 551, 286, 478, 884, 294, 3820, 5201, 10585, 30, 51790], "temperature": 0.0, "avg_logprob": -0.2780826915394176, "compression_ratio": 1.66798418972332, "no_speech_prob": 0.00020661455346271396}, {"id": 1233, "seek": 509890, "start": 5099.42, "end": 5101.7, "text": " It's like, well, can my human brain recognize it?", "tokens": [50390, 467, 311, 411, 11, 731, 11, 393, 452, 1952, 3567, 5521, 309, 30, 50504], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1234, "seek": 509890, "start": 5101.7, "end": 5106.339999999999, "text": " So if I couldn't recognize this was a drilling platform myself, then I shouldn't expect a", "tokens": [50504, 407, 498, 286, 2809, 380, 5521, 341, 390, 257, 26290, 3663, 2059, 11, 550, 286, 4659, 380, 2066, 257, 50736], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1235, "seek": 509890, "start": 5106.339999999999, "end": 5108.0199999999995, "text": " computer to be able to do it.", "tokens": [50736, 3820, 281, 312, 1075, 281, 360, 309, 13, 50820], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1236, "seek": 509890, "start": 5108.0199999999995, "end": 5111.62, "text": " Or that this is a compass or whatever.", "tokens": [50820, 1610, 300, 341, 307, 257, 10707, 420, 2035, 13, 51000], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1237, "seek": 509890, "start": 5111.62, "end": 5113.82, "text": " I'm so glad they've got otters, so cute.", "tokens": [51000, 286, 478, 370, 5404, 436, 600, 658, 4337, 1559, 11, 370, 4052, 13, 51110], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1238, "seek": 509890, "start": 5113.82, "end": 5116.9, "text": " And you can see the cropping it's done has also been fine.", "tokens": [51110, 400, 291, 393, 536, 264, 4848, 3759, 309, 311, 1096, 575, 611, 668, 2489, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1239, "seek": 509890, "start": 5116.9, "end": 5121.86, "text": " Like it's a little bit of a fuzzy edge, but basically like it's not destroying the image", "tokens": [51264, 1743, 309, 311, 257, 707, 857, 295, 257, 34710, 4691, 11, 457, 1936, 411, 309, 311, 406, 19926, 264, 3256, 51512], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1240, "seek": 509890, "start": 5121.86, "end": 5122.86, "text": " at all.", "tokens": [51512, 412, 439, 13, 51562], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1241, "seek": 509890, "start": 5122.86, "end": 5126.94, "text": " They're still recognizable.", "tokens": [51562, 814, 434, 920, 40757, 13, 51766], "temperature": 0.0, "avg_logprob": -0.23927949523925782, "compression_ratio": 1.5745454545454545, "no_speech_prob": 0.00012731042806990445}, {"id": 1242, "seek": 512694, "start": 5126.98, "end": 5130.78, "text": " It's also a good example here of how difficult like this problem is.", "tokens": [50366, 467, 311, 611, 257, 665, 1365, 510, 295, 577, 2252, 411, 341, 1154, 307, 13, 50556], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1243, "seek": 512694, "start": 5130.78, "end": 5134.0199999999995, "text": " Like the fact that this is seashore, I would have called this surface, you know, but maybe", "tokens": [50556, 1743, 264, 1186, 300, 341, 307, 369, 1299, 418, 11, 286, 576, 362, 1219, 341, 3753, 11, 291, 458, 11, 457, 1310, 50718], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1244, "seek": 512694, "start": 5134.0199999999995, "end": 5137.339999999999, "text": " surface is not an image in that category.", "tokens": [50718, 3753, 307, 406, 364, 3256, 294, 300, 7719, 13, 50884], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1245, "seek": 512694, "start": 5137.339999999999, "end": 5139.94, "text": " But yeah.", "tokens": [50884, 583, 1338, 13, 51014], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1246, "seek": 512694, "start": 5139.94, "end": 5141.5, "text": " Okay.", "tokens": [51014, 1033, 13, 51092], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1247, "seek": 512694, "start": 5141.5, "end": 5146.179999999999, "text": " This could be food, but actually it's a refrigerator.", "tokens": [51092, 639, 727, 312, 1755, 11, 457, 767, 309, 311, 257, 19655, 13, 51326], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1248, "seek": 512694, "start": 5146.179999999999, "end": 5147.179999999999, "text": " Okay.", "tokens": [51326, 1033, 13, 51376], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1249, "seek": 512694, "start": 5147.179999999999, "end": 5148.82, "text": " So our augmentation seems to be working well.", "tokens": [51376, 407, 527, 14501, 19631, 2544, 281, 312, 1364, 731, 13, 51458], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1250, "seek": 512694, "start": 5148.82, "end": 5155.339999999999, "text": " So then I, yeah, basically I've just copied and pasted, you know, our basic pieces here.", "tokens": [51458, 407, 550, 286, 11, 1338, 11, 1936, 286, 600, 445, 25365, 293, 1791, 292, 11, 291, 458, 11, 527, 3875, 3755, 510, 13, 51784], "temperature": 0.0, "avg_logprob": -0.33011494652699613, "compression_ratio": 1.609375, "no_speech_prob": 0.00011061067198170349}, {"id": 1251, "seek": 515534, "start": 5155.34, "end": 5158.62, "text": " And I kind of wanted to have it all in one place, just to remind myself of exactly what", "tokens": [50364, 400, 286, 733, 295, 1415, 281, 362, 309, 439, 294, 472, 1081, 11, 445, 281, 4160, 2059, 295, 2293, 437, 50528], "temperature": 0.0, "avg_logprob": -0.2701904814122087, "compression_ratio": 1.8366533864541832, "no_speech_prob": 8.481025724904612e-05}, {"id": 1252, "seek": 515534, "start": 5158.62, "end": 5159.62, "text": " it is.", "tokens": [50528, 309, 307, 13, 50578], "temperature": 0.0, "avg_logprob": -0.2701904814122087, "compression_ratio": 1.8366533864541832, "no_speech_prob": 8.481025724904612e-05}, {"id": 1253, "seek": 515534, "start": 5159.62, "end": 5161.66, "text": " So this is the pre activation version of convolutions.", "tokens": [50578, 407, 341, 307, 264, 659, 24433, 3037, 295, 3754, 15892, 13, 50680], "temperature": 0.0, "avg_logprob": -0.2701904814122087, "compression_ratio": 1.8366533864541832, "no_speech_prob": 8.481025724904612e-05}, {"id": 1254, "seek": 515534, "start": 5161.66, "end": 5168.3, "text": " The reason for that is if I want this to be a backbone for a diffusion model or a unit,", "tokens": [50680, 440, 1778, 337, 300, 307, 498, 286, 528, 341, 281, 312, 257, 34889, 337, 257, 25242, 2316, 420, 257, 4985, 11, 51012], "temperature": 0.0, "avg_logprob": -0.2701904814122087, "compression_ratio": 1.8366533864541832, "no_speech_prob": 8.481025724904612e-05}, {"id": 1255, "seek": 515534, "start": 5168.3, "end": 5173.82, "text": " then I remember that we found that pre activation works best for units.", "tokens": [51012, 550, 286, 1604, 300, 321, 1352, 300, 659, 24433, 1985, 1151, 337, 6815, 13, 51288], "temperature": 0.0, "avg_logprob": -0.2701904814122087, "compression_ratio": 1.8366533864541832, "no_speech_prob": 8.481025724904612e-05}, {"id": 1256, "seek": 515534, "start": 5173.82, "end": 5176.54, "text": " So therefore our backbone needs to be trained with pre activation.", "tokens": [51288, 407, 4412, 527, 34889, 2203, 281, 312, 8895, 365, 659, 24433, 13, 51424], "temperature": 0.0, "avg_logprob": -0.2701904814122087, "compression_ratio": 1.8366533864541832, "no_speech_prob": 8.481025724904612e-05}, {"id": 1257, "seek": 515534, "start": 5176.54, "end": 5183.74, "text": " So we've got a pre activation conv, got a res block, res blocks model with dropouts.", "tokens": [51424, 407, 321, 600, 658, 257, 659, 24433, 3754, 11, 658, 257, 725, 3461, 11, 725, 8474, 2316, 365, 3270, 7711, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2701904814122087, "compression_ratio": 1.8366533864541832, "no_speech_prob": 8.481025724904612e-05}, {"id": 1258, "seek": 518374, "start": 5183.74, "end": 5188.679999999999, "text": " This is all just copied from previous.", "tokens": [50364, 639, 307, 439, 445, 25365, 490, 3894, 13, 50611], "temperature": 0.0, "avg_logprob": -0.25899039374457467, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0015247573610395193}, {"id": 1259, "seek": 518374, "start": 5188.679999999999, "end": 5193.62, "text": " So I decided, like, I wanted to try to, you know, use the basic trick that we learned", "tokens": [50611, 407, 286, 3047, 11, 411, 11, 286, 1415, 281, 853, 281, 11, 291, 458, 11, 764, 264, 3875, 4282, 300, 321, 3264, 50858], "temperature": 0.0, "avg_logprob": -0.25899039374457467, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0015247573610395193}, {"id": 1260, "seek": 518374, "start": 5193.62, "end": 5201.2, "text": " about from simple diffusion of trying to put most of our work in the later layers.", "tokens": [50858, 466, 490, 2199, 25242, 295, 1382, 281, 829, 881, 295, 527, 589, 294, 264, 1780, 7914, 13, 51237], "temperature": 0.0, "avg_logprob": -0.25899039374457467, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0015247573610395193}, {"id": 1261, "seek": 518374, "start": 5201.2, "end": 5207.74, "text": " So the first layer just has one block, then two blocks, and then four blocks.", "tokens": [51237, 407, 264, 700, 4583, 445, 575, 472, 3461, 11, 550, 732, 8474, 11, 293, 550, 1451, 8474, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25899039374457467, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0015247573610395193}, {"id": 1262, "seek": 518374, "start": 5207.74, "end": 5211.96, "text": " And then I figured that we might then delete these final blocks.", "tokens": [51564, 400, 550, 286, 8932, 300, 321, 1062, 550, 12097, 613, 2572, 8474, 13, 51775], "temperature": 0.0, "avg_logprob": -0.25899039374457467, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0015247573610395193}, {"id": 1263, "seek": 521196, "start": 5212.2, "end": 5214.0, "text": " Because maybe you're going to just end up being for classification.", "tokens": [50376, 1436, 1310, 291, 434, 516, 281, 445, 917, 493, 885, 337, 21538, 13, 50466], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1264, "seek": 521196, "start": 5214.0, "end": 5216.7, "text": " This might end up being our pre trained backbone.", "tokens": [50466, 639, 1062, 917, 493, 885, 527, 659, 8895, 34889, 13, 50601], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1265, "seek": 521196, "start": 5216.7, "end": 5217.9800000000005, "text": " Or maybe we keep them.", "tokens": [50601, 1610, 1310, 321, 1066, 552, 13, 50665], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1266, "seek": 521196, "start": 5217.9800000000005, "end": 5218.9800000000005, "text": " I don't know.", "tokens": [50665, 286, 500, 380, 458, 13, 50715], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1267, "seek": 521196, "start": 5218.9800000000005, "end": 5222.58, "text": " You know, it's like, as I said, this hasn't been done before.", "tokens": [50715, 509, 458, 11, 309, 311, 411, 11, 382, 286, 848, 11, 341, 6132, 380, 668, 1096, 949, 13, 50895], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1268, "seek": 521196, "start": 5222.58, "end": 5227.22, "text": " So anyway, I tried to design it in a way that we've got some, you know, we can mess around", "tokens": [50895, 407, 4033, 11, 286, 3031, 281, 1715, 309, 294, 257, 636, 300, 321, 600, 658, 512, 11, 291, 458, 11, 321, 393, 2082, 926, 51127], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1269, "seek": 521196, "start": 5227.22, "end": 5230.52, "text": " a little bit with how many of these we keep.", "tokens": [51127, 257, 707, 857, 365, 577, 867, 295, 613, 321, 1066, 13, 51292], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1270, "seek": 521196, "start": 5230.52, "end": 5235.4800000000005, "text": " And so also I tried to use very few channels in the first blocks.", "tokens": [51292, 400, 370, 611, 286, 3031, 281, 764, 588, 1326, 9235, 294, 264, 700, 8474, 13, 51540], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1271, "seek": 521196, "start": 5235.4800000000005, "end": 5240.72, "text": " And so I jump up for the channels that are where the work's going to do.", "tokens": [51540, 400, 370, 286, 3012, 493, 337, 264, 9235, 300, 366, 689, 264, 589, 311, 516, 281, 360, 13, 51802], "temperature": 0.0, "avg_logprob": -0.2566722869873047, "compression_ratio": 1.6815068493150684, "no_speech_prob": 0.0011694408021867275}, {"id": 1272, "seek": 524072, "start": 5240.76, "end": 5245.2, "text": " So I jump from 128 to 512.", "tokens": [50366, 407, 286, 3012, 490, 29810, 281, 1025, 4762, 13, 50588], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1273, "seek": 524072, "start": 5245.2, "end": 5246.4800000000005, "text": " So that's why I designed it this way.", "tokens": [50588, 407, 300, 311, 983, 286, 4761, 309, 341, 636, 13, 50652], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1274, "seek": 524072, "start": 5246.4800000000005, "end": 5249.12, "text": " You know, I haven't even taken it any further than this.", "tokens": [50652, 509, 458, 11, 286, 2378, 380, 754, 2726, 309, 604, 3052, 813, 341, 13, 50784], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1275, "seek": 524072, "start": 5249.12, "end": 5251.8, "text": " So I don't know if it's going to be a useful backbone or not.", "tokens": [50784, 407, 286, 500, 380, 458, 498, 309, 311, 516, 281, 312, 257, 4420, 34889, 420, 406, 13, 50918], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1276, "seek": 524072, "start": 5251.8, "end": 5255.0, "text": " I didn't even know if this is going to be possible to classify.", "tokens": [50918, 286, 994, 380, 754, 458, 498, 341, 307, 516, 281, 312, 1944, 281, 33872, 13, 51078], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1277, "seek": 524072, "start": 5255.0, "end": 5258.400000000001, "text": " It seemed very likely it was possible to classify, even based on the fact that you can still", "tokens": [51078, 467, 6576, 588, 3700, 309, 390, 1944, 281, 33872, 11, 754, 2361, 322, 264, 1186, 300, 291, 393, 920, 51248], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1278, "seek": 524072, "start": 5258.400000000001, "end": 5261.04, "text": " kind of recognize it almost.", "tokens": [51248, 733, 295, 5521, 309, 1920, 13, 51380], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1279, "seek": 524072, "start": 5261.04, "end": 5263.240000000001, "text": " Like I could probably recognize it's a computer, maybe.", "tokens": [51380, 1743, 286, 727, 1391, 5521, 309, 311, 257, 3820, 11, 1310, 13, 51490], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1280, "seek": 524072, "start": 5263.240000000001, "end": 5265.92, "text": " So I thought it was going to be possible.", "tokens": [51490, 407, 286, 1194, 309, 390, 516, 281, 312, 1944, 13, 51624], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1281, "seek": 524072, "start": 5265.92, "end": 5268.22, "text": " But yeah, this is all new.", "tokens": [51624, 583, 1338, 11, 341, 307, 439, 777, 13, 51739], "temperature": 0.0, "avg_logprob": -0.2848705775301221, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0020506419241428375}, {"id": 1282, "seek": 526822, "start": 5268.22, "end": 5270.06, "text": " So that was the model I created.", "tokens": [50364, 407, 300, 390, 264, 2316, 286, 2942, 13, 50456], "temperature": 0.0, "avg_logprob": -0.2261486053466797, "compression_ratio": 1.5492957746478873, "no_speech_prob": 0.002287136623635888}, {"id": 1283, "seek": 526822, "start": 5270.06, "end": 5276.34, "text": " And then I, yeah, trained it for 40 epochs.", "tokens": [50456, 400, 550, 286, 11, 1338, 11, 8895, 309, 337, 3356, 30992, 28346, 13, 50770], "temperature": 0.0, "avg_logprob": -0.2261486053466797, "compression_ratio": 1.5492957746478873, "no_speech_prob": 0.002287136623635888}, {"id": 1284, "seek": 526822, "start": 5276.34, "end": 5283.14, "text": " And you can see after one epoch, it was already 25% accurate.", "tokens": [50770, 400, 291, 393, 536, 934, 472, 30992, 339, 11, 309, 390, 1217, 3552, 4, 8559, 13, 51110], "temperature": 0.0, "avg_logprob": -0.2261486053466797, "compression_ratio": 1.5492957746478873, "no_speech_prob": 0.002287136623635888}, {"id": 1285, "seek": 526822, "start": 5283.14, "end": 5287.1, "text": " And that's it recognizing which one of a thousand categories is it.", "tokens": [51110, 400, 300, 311, 309, 18538, 597, 472, 295, 257, 4714, 10479, 307, 309, 13, 51308], "temperature": 0.0, "avg_logprob": -0.2261486053466797, "compression_ratio": 1.5492957746478873, "no_speech_prob": 0.002287136623635888}, {"id": 1286, "seek": 526822, "start": 5287.1, "end": 5289.3, "text": " So I thought that was pretty amazing.", "tokens": [51308, 407, 286, 1194, 300, 390, 1238, 2243, 13, 51418], "temperature": 0.0, "avg_logprob": -0.2261486053466797, "compression_ratio": 1.5492957746478873, "no_speech_prob": 0.002287136623635888}, {"id": 1287, "seek": 526822, "start": 5289.3, "end": 5297.18, "text": " And so after 40 epochs, I ended up at 66%, which is really quite fantastic, because a", "tokens": [51418, 400, 370, 934, 3356, 30992, 28346, 11, 286, 4590, 493, 412, 21126, 8923, 597, 307, 534, 1596, 5456, 11, 570, 257, 51812], "temperature": 0.0, "avg_logprob": -0.2261486053466797, "compression_ratio": 1.5492957746478873, "no_speech_prob": 0.002287136623635888}, {"id": 1288, "seek": 529718, "start": 5297.18, "end": 5308.14, "text": " ResNet 34 is kind of like 73 or 74% accuracy when trained for quite a lot longer.", "tokens": [50364, 5015, 31890, 12790, 307, 733, 295, 411, 28387, 420, 28868, 4, 14170, 562, 8895, 337, 1596, 257, 688, 2854, 13, 50912], "temperature": 0.0, "avg_logprob": -0.2355762394991788, "compression_ratio": 1.4293193717277486, "no_speech_prob": 6.68141808546352e-07}, {"id": 1289, "seek": 529718, "start": 5308.14, "end": 5314.9400000000005, "text": " You know, so to me, this is extremely encouraging that, you know, this is a really pretty good", "tokens": [50912, 509, 458, 11, 370, 281, 385, 11, 341, 307, 4664, 14580, 300, 11, 291, 458, 11, 341, 307, 257, 534, 1238, 665, 51252], "temperature": 0.0, "avg_logprob": -0.2355762394991788, "compression_ratio": 1.4293193717277486, "no_speech_prob": 6.68141808546352e-07}, {"id": 1290, "seek": 529718, "start": 5314.9400000000005, "end": 5324.38, "text": " ResNet at recognizing images from their latent representations without any decoding or whatever.", "tokens": [51252, 5015, 31890, 412, 18538, 5267, 490, 641, 48994, 33358, 1553, 604, 979, 8616, 420, 2035, 13, 51724], "temperature": 0.0, "avg_logprob": -0.2355762394991788, "compression_ratio": 1.4293193717277486, "no_speech_prob": 6.68141808546352e-07}, {"id": 1291, "seek": 532438, "start": 5324.38, "end": 5333.66, "text": " So from here, you know, if you want to, you guys could try, yeah, building a better bedroom", "tokens": [50364, 407, 490, 510, 11, 291, 458, 11, 498, 291, 528, 281, 11, 291, 1074, 727, 853, 11, 1338, 11, 2390, 257, 1101, 11211, 50828], "temperature": 0.0, "avg_logprob": -0.33364779298955743, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0003250203444622457}, {"id": 1292, "seek": 532438, "start": 5333.66, "end": 5335.58, "text": " diffusion model, or whatever you like.", "tokens": [50828, 25242, 2316, 11, 420, 2035, 291, 411, 13, 50924], "temperature": 0.0, "avg_logprob": -0.33364779298955743, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0003250203444622457}, {"id": 1293, "seek": 532438, "start": 5335.58, "end": 5337.46, "text": " It doesn't have to be bedrooms.", "tokens": [50924, 467, 1177, 380, 362, 281, 312, 39955, 13, 51018], "temperature": 0.0, "avg_logprob": -0.33364779298955743, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0003250203444622457}, {"id": 1294, "seek": 532438, "start": 5337.46, "end": 5345.38, "text": " Actually, one of our colleagues, Molly, I'm just going to find it.", "tokens": [51018, 5135, 11, 472, 295, 527, 7734, 11, 26665, 11, 286, 478, 445, 516, 281, 915, 309, 13, 51414], "temperature": 0.0, "avg_logprob": -0.33364779298955743, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0003250203444622457}, {"id": 1295, "seek": 532438, "start": 5345.38, "end": 5351.26, "text": " So one of our colleagues, Molly, actually used the, do you guys remember, was it the", "tokens": [51414, 407, 472, 295, 527, 7734, 11, 26665, 11, 767, 1143, 264, 11, 360, 291, 1074, 1604, 11, 390, 309, 264, 51708], "temperature": 0.0, "avg_logprob": -0.33364779298955743, "compression_ratio": 1.5939086294416243, "no_speech_prob": 0.0003250203444622457}, {"id": 1296, "seek": 535126, "start": 5351.26, "end": 5357.900000000001, "text": " CelebFaces that she used?", "tokens": [50364, 8257, 28512, 37, 2116, 300, 750, 1143, 30, 50696], "temperature": 0.0, "avg_logprob": -0.274706963931813, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.001700680935755372}, {"id": 1297, "seek": 535126, "start": 5357.900000000001, "end": 5366.66, "text": " So there's a CelebAHQ dataset that consists of images of faces of celebrities.", "tokens": [50696, 407, 456, 311, 257, 8257, 28512, 10566, 48, 28872, 300, 14689, 295, 5267, 295, 8475, 295, 23200, 13, 51134], "temperature": 0.0, "avg_logprob": -0.274706963931813, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.001700680935755372}, {"id": 1298, "seek": 535126, "start": 5366.66, "end": 5372.9400000000005, "text": " And so what Molly did was she basically, yeah, used this exact notebook, but used this faces", "tokens": [51134, 400, 370, 437, 26665, 630, 390, 750, 1936, 11, 1338, 11, 1143, 341, 1900, 21060, 11, 457, 1143, 341, 8475, 51448], "temperature": 0.0, "avg_logprob": -0.274706963931813, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.001700680935755372}, {"id": 1299, "seek": 535126, "start": 5372.9400000000005, "end": 5374.9800000000005, "text": " dataset instead.", "tokens": [51448, 28872, 2602, 13, 51550], "temperature": 0.0, "avg_logprob": -0.274706963931813, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.001700680935755372}, {"id": 1300, "seek": 535126, "start": 5374.9800000000005, "end": 5377.42, "text": " And this one's really pretty good, isn't it?", "tokens": [51550, 400, 341, 472, 311, 534, 1238, 665, 11, 1943, 380, 309, 30, 51672], "temperature": 0.0, "avg_logprob": -0.274706963931813, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.001700680935755372}, {"id": 1301, "seek": 535126, "start": 5377.42, "end": 5380.5, "text": " You know, this one's really pretty good.", "tokens": [51672, 509, 458, 11, 341, 472, 311, 534, 1238, 665, 13, 51826], "temperature": 0.0, "avg_logprob": -0.274706963931813, "compression_ratio": 1.6129032258064515, "no_speech_prob": 0.001700680935755372}, {"id": 1302, "seek": 538050, "start": 5380.74, "end": 5383.98, "text": " They certainly look like celebrities, that's for sure.", "tokens": [50376, 814, 3297, 574, 411, 23200, 11, 300, 311, 337, 988, 13, 50538], "temperature": 0.0, "avg_logprob": -0.3285765874953497, "compression_ratio": 1.695067264573991, "no_speech_prob": 3.88301741622854e-05}, {"id": 1303, "seek": 538050, "start": 5383.98, "end": 5388.26, "text": " So yeah, you could try this dataset or whatever, but yeah, try it.", "tokens": [50538, 407, 1338, 11, 291, 727, 853, 341, 28872, 420, 2035, 11, 457, 1338, 11, 853, 309, 13, 50752], "temperature": 0.0, "avg_logprob": -0.3285765874953497, "compression_ratio": 1.695067264573991, "no_speech_prob": 3.88301741622854e-05}, {"id": 1304, "seek": 538050, "start": 5388.26, "end": 5391.98, "text": " Maybe try it with the pre-trained backbone.", "tokens": [50752, 2704, 853, 309, 365, 264, 659, 12, 17227, 2001, 34889, 13, 50938], "temperature": 0.0, "avg_logprob": -0.3285765874953497, "compression_ratio": 1.695067264573991, "no_speech_prob": 3.88301741622854e-05}, {"id": 1305, "seek": 538050, "start": 5391.98, "end": 5395.18, "text": " Try it with ResNets on the cross connections.", "tokens": [50938, 6526, 309, 365, 5015, 45, 1385, 322, 264, 3278, 9271, 13, 51098], "temperature": 0.0, "avg_logprob": -0.3285765874953497, "compression_ratio": 1.695067264573991, "no_speech_prob": 3.88301741622854e-05}, {"id": 1306, "seek": 538050, "start": 5395.18, "end": 5397.26, "text": " Try it with all the tricks we used in SuperRes.", "tokens": [51098, 6526, 309, 365, 439, 264, 11733, 321, 1143, 294, 4548, 33274, 13, 51202], "temperature": 0.0, "avg_logprob": -0.3285765874953497, "compression_ratio": 1.695067264573991, "no_speech_prob": 3.88301741622854e-05}, {"id": 1307, "seek": 538050, "start": 5397.26, "end": 5399.86, "text": " Try it with perceptual loss.", "tokens": [51202, 6526, 309, 365, 43276, 901, 4470, 13, 51332], "temperature": 0.0, "avg_logprob": -0.3285765874953497, "compression_ratio": 1.695067264573991, "no_speech_prob": 3.88301741622854e-05}, {"id": 1308, "seek": 538050, "start": 5399.86, "end": 5405.98, "text": " Some folks we spoke to about the perceptual loss think it won't help with latents because", "tokens": [51332, 2188, 4024, 321, 7179, 281, 466, 264, 43276, 901, 4470, 519, 309, 1582, 380, 854, 365, 287, 7186, 1373, 570, 51638], "temperature": 0.0, "avg_logprob": -0.3285765874953497, "compression_ratio": 1.695067264573991, "no_speech_prob": 3.88301741622854e-05}, {"id": 1309, "seek": 540598, "start": 5405.98, "end": 5411.139999999999, "text": " the underlying VAE was already trained with perceptual loss, but we should try, you know,", "tokens": [50364, 264, 14217, 18527, 36, 390, 1217, 8895, 365, 43276, 901, 4470, 11, 457, 321, 820, 853, 11, 291, 458, 11, 50622], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1310, "seek": 540598, "start": 5411.139999999999, "end": 5413.459999999999, "text": " or you guys should try all these things.", "tokens": [50622, 420, 291, 1074, 820, 853, 439, 613, 721, 13, 50738], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1311, "seek": 540598, "start": 5413.459999999999, "end": 5414.459999999999, "text": " Yeah.", "tokens": [50738, 865, 13, 50788], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1312, "seek": 540598, "start": 5414.459999999999, "end": 5419.299999999999, "text": " So be sure to check out the forum as well to see what other people have already tried", "tokens": [50788, 407, 312, 988, 281, 1520, 484, 264, 17542, 382, 731, 281, 536, 437, 661, 561, 362, 1217, 3031, 51030], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1313, "seek": 540598, "start": 5419.299999999999, "end": 5421.459999999999, "text": " here because it's a whole new world.", "tokens": [51030, 510, 570, 309, 311, 257, 1379, 777, 1002, 13, 51138], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1314, "seek": 540598, "start": 5421.459999999999, "end": 5427.139999999999, "text": " But it's just an example of the kind of like fun research ideas I guess we can play with.", "tokens": [51138, 583, 309, 311, 445, 364, 1365, 295, 264, 733, 295, 411, 1019, 2132, 3487, 286, 2041, 321, 393, 862, 365, 13, 51422], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1315, "seek": 540598, "start": 5427.139999999999, "end": 5428.139999999999, "text": " Yeah.", "tokens": [51422, 865, 13, 51472], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1316, "seek": 540598, "start": 5428.139999999999, "end": 5429.379999999999, "text": " What do you guys think about this?", "tokens": [51472, 708, 360, 291, 1074, 519, 466, 341, 30, 51534], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1317, "seek": 540598, "start": 5429.379999999999, "end": 5433.86, "text": " Are you like surprised that we're able to quickly get this kind of accuracy from latents?", "tokens": [51534, 2014, 291, 411, 6100, 300, 321, 434, 1075, 281, 2661, 483, 341, 733, 295, 14170, 490, 4465, 791, 30, 51758], "temperature": 0.0, "avg_logprob": -0.30295827984809875, "compression_ratio": 1.6326530612244898, "no_speech_prob": 0.04270512983202934}, {"id": 1318, "seek": 543386, "start": 5433.94, "end": 5436.42, "text": " Or do you think this is a useful research path?", "tokens": [50368, 1610, 360, 291, 519, 341, 307, 257, 4420, 2132, 3100, 30, 50492], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1319, "seek": 543386, "start": 5436.42, "end": 5437.42, "text": " What are your thoughts?", "tokens": [50492, 708, 366, 428, 4598, 30, 50542], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1320, "seek": 543386, "start": 5437.42, "end": 5440.42, "text": " Yeah, I think it's very interesting.", "tokens": [50542, 865, 11, 286, 519, 309, 311, 588, 1880, 13, 50692], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1321, "seek": 543386, "start": 5440.42, "end": 5441.42, "text": " Oh, go ahead.", "tokens": [50692, 876, 11, 352, 2286, 13, 50742], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1322, "seek": 543386, "start": 5441.42, "end": 5446.299999999999, "text": " I was going to say the latents are already like a slightly compressed richer representation", "tokens": [50742, 286, 390, 516, 281, 584, 264, 4465, 791, 366, 1217, 411, 257, 4748, 30353, 29021, 10290, 50986], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1323, "seek": 543386, "start": 5446.299999999999, "end": 5448.0599999999995, "text": " of an image, right?", "tokens": [50986, 295, 364, 3256, 11, 558, 30, 51074], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1324, "seek": 543386, "start": 5448.0599999999995, "end": 5450.259999999999, "text": " So it makes sense that that's a useful thing to train on.", "tokens": [51074, 407, 309, 1669, 2020, 300, 300, 311, 257, 4420, 551, 281, 3847, 322, 13, 51184], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1325, "seek": 543386, "start": 5450.259999999999, "end": 5455.219999999999, "text": " 66%, I think AlexNet is like 63% or something like that.", "tokens": [51184, 21126, 8923, 286, 519, 5202, 31890, 307, 411, 25082, 4, 420, 746, 411, 300, 13, 51432], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1326, "seek": 543386, "start": 5455.219999999999, "end": 5460.339999999999, "text": " So you know, we were already at state of the art, what, eight years ago or whatever.", "tokens": [51432, 407, 291, 458, 11, 321, 645, 1217, 412, 1785, 295, 264, 1523, 11, 437, 11, 3180, 924, 2057, 420, 2035, 13, 51688], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1327, "seek": 543386, "start": 5460.339999999999, "end": 5461.339999999999, "text": " Yeah, it's pretty cool.", "tokens": [51688, 865, 11, 309, 311, 1238, 1627, 13, 51738], "temperature": 0.0, "avg_logprob": -0.3875836379655445, "compression_ratio": 1.6357142857142857, "no_speech_prob": 0.05745106190443039}, {"id": 1328, "seek": 546134, "start": 5461.82, "end": 5463.66, "text": " I'm going to say it might be more like 10 years ago.", "tokens": [50388, 286, 478, 516, 281, 584, 309, 1062, 312, 544, 411, 1266, 924, 2057, 13, 50480], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1329, "seek": 546134, "start": 5463.66, "end": 5465.22, "text": " I know time passes quickly.", "tokens": [50480, 286, 458, 565, 11335, 2661, 13, 50558], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1330, "seek": 546134, "start": 5465.22, "end": 5467.66, "text": " Yeah, yeah, I guess next year.", "tokens": [50558, 865, 11, 1338, 11, 286, 2041, 958, 1064, 13, 50680], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1331, "seek": 546134, "start": 5467.66, "end": 5471.34, "text": " Yeah, next year it is 10 years ago.", "tokens": [50680, 865, 11, 958, 1064, 309, 307, 1266, 924, 2057, 13, 50864], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1332, "seek": 546134, "start": 5471.34, "end": 5476.18, "text": " But yeah, I'm kind of curious with the pre-training, the whole value for me for like using a pre-trained", "tokens": [50864, 583, 1338, 11, 286, 478, 733, 295, 6369, 365, 264, 659, 12, 17227, 1760, 11, 264, 1379, 2158, 337, 385, 337, 411, 1228, 257, 659, 12, 17227, 2001, 51106], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1333, "seek": 546134, "start": 5476.18, "end": 5480.62, "text": " network was someone else has done lots and lots of compute on ImageNet to learn some", "tokens": [51106, 3209, 390, 1580, 1646, 575, 1096, 3195, 293, 3195, 295, 14722, 322, 29903, 31890, 281, 1466, 512, 51328], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1334, "seek": 546134, "start": 5480.62, "end": 5482.42, "text": " features and I'm going to use that.", "tokens": [51328, 4122, 293, 286, 478, 516, 281, 764, 300, 13, 51418], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1335, "seek": 546134, "start": 5482.42, "end": 5486.78, "text": " So it's kind of funny to be like, oh, well, let's pre-train for ourselves and then try", "tokens": [51418, 407, 309, 311, 733, 295, 4074, 281, 312, 411, 11, 1954, 11, 731, 11, 718, 311, 659, 12, 83, 7146, 337, 4175, 293, 550, 853, 51636], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1336, "seek": 546134, "start": 5486.78, "end": 5488.54, "text": " and use that.", "tokens": [51636, 293, 764, 300, 13, 51724], "temperature": 0.0, "avg_logprob": -0.31801041079239106, "compression_ratio": 1.7490774907749078, "no_speech_prob": 0.010484668426215649}, {"id": 1337, "seek": 548854, "start": 5488.54, "end": 5493.66, "text": " I'm curious whether, like how best you'd allocate that compute, whether you should,", "tokens": [50364, 286, 478, 6369, 1968, 11, 411, 577, 1151, 291, 1116, 35713, 300, 14722, 11, 1968, 291, 820, 11, 50620], "temperature": 0.0, "avg_logprob": -0.3042615607932762, "compression_ratio": 1.6736401673640167, "no_speech_prob": 0.014955689199268818}, {"id": 1338, "seek": 548854, "start": 5493.66, "end": 5497.66, "text": " if you've got 10 hours of GPU, just do 10 hours of training versus like five hours of", "tokens": [50620, 498, 291, 600, 658, 1266, 2496, 295, 18407, 11, 445, 360, 1266, 2496, 295, 3097, 5717, 411, 1732, 2496, 295, 50820], "temperature": 0.0, "avg_logprob": -0.3042615607932762, "compression_ratio": 1.6736401673640167, "no_speech_prob": 0.014955689199268818}, {"id": 1339, "seek": 548854, "start": 5497.66, "end": 5500.26, "text": " pre-training and five hours of training.", "tokens": [50820, 659, 12, 17227, 1760, 293, 1732, 2496, 295, 3097, 13, 50950], "temperature": 0.0, "avg_logprob": -0.3042615607932762, "compression_ratio": 1.6736401673640167, "no_speech_prob": 0.014955689199268818}, {"id": 1340, "seek": 548854, "start": 5500.26, "end": 5506.94, "text": " I mean, based on our super res thing, the pre-training like was so much better.", "tokens": [50950, 286, 914, 11, 2361, 322, 527, 1687, 725, 551, 11, 264, 659, 12, 17227, 1760, 411, 390, 370, 709, 1101, 13, 51284], "temperature": 0.0, "avg_logprob": -0.3042615607932762, "compression_ratio": 1.6736401673640167, "no_speech_prob": 0.014955689199268818}, {"id": 1341, "seek": 548854, "start": 5506.94, "end": 5510.38, "text": " So that's why I'm feeling somewhat hopeful about this direction.", "tokens": [51284, 407, 300, 311, 983, 286, 478, 2633, 8344, 20531, 466, 341, 3513, 13, 51456], "temperature": 0.0, "avg_logprob": -0.3042615607932762, "compression_ratio": 1.6736401673640167, "no_speech_prob": 0.014955689199268818}, {"id": 1342, "seek": 548854, "start": 5510.38, "end": 5515.38, "text": " Yeah, I'm really curious to see how it goes.", "tokens": [51456, 865, 11, 286, 478, 534, 6369, 281, 536, 577, 309, 1709, 13, 51706], "temperature": 0.0, "avg_logprob": -0.3042615607932762, "compression_ratio": 1.6736401673640167, "no_speech_prob": 0.014955689199268818}, {"id": 1343, "seek": 551538, "start": 5515.38, "end": 5518.82, "text": " I guess I was going to say it's like, yeah, I think there's just a lot of opportunities", "tokens": [50364, 286, 2041, 286, 390, 516, 281, 584, 309, 311, 411, 11, 1338, 11, 286, 519, 456, 311, 445, 257, 688, 295, 4786, 50536], "temperature": 0.0, "avg_logprob": -0.3069388219552447, "compression_ratio": 1.7902621722846441, "no_speech_prob": 0.01149938814342022}, {"id": 1344, "seek": 551538, "start": 5518.82, "end": 5522.5, "text": " for I guess the latent, doing stuff in the latents.", "tokens": [50536, 337, 286, 2041, 264, 48994, 11, 884, 1507, 294, 264, 287, 267, 791, 13, 50720], "temperature": 0.0, "avg_logprob": -0.3069388219552447, "compression_ratio": 1.7902621722846441, "no_speech_prob": 0.01149938814342022}, {"id": 1345, "seek": 551538, "start": 5522.5, "end": 5526.74, "text": " And like, I guess maybe like, yeah, you could, I mean, here you're trading classifier as", "tokens": [50720, 400, 411, 11, 286, 2041, 1310, 411, 11, 1338, 11, 291, 727, 11, 286, 914, 11, 510, 291, 434, 9529, 1508, 9902, 382, 50932], "temperature": 0.0, "avg_logprob": -0.3069388219552447, "compression_ratio": 1.7902621722846441, "no_speech_prob": 0.01149938814342022}, {"id": 1346, "seek": 551538, "start": 5526.74, "end": 5531.900000000001, "text": " a backbone, but you could think of like trading classifiers on other things for guidance or", "tokens": [50932, 257, 34889, 11, 457, 291, 727, 519, 295, 411, 9529, 1508, 23463, 322, 661, 721, 337, 10056, 420, 51190], "temperature": 0.0, "avg_logprob": -0.3069388219552447, "compression_ratio": 1.7902621722846441, "no_speech_prob": 0.01149938814342022}, {"id": 1347, "seek": 551538, "start": 5531.900000000001, "end": 5532.900000000001, "text": " things like this.", "tokens": [51190, 721, 411, 341, 13, 51240], "temperature": 0.0, "avg_logprob": -0.3069388219552447, "compression_ratio": 1.7902621722846441, "no_speech_prob": 0.01149938814342022}, {"id": 1348, "seek": 551538, "start": 5532.900000000001, "end": 5535.14, "text": " Of course, we've done some experiments with that.", "tokens": [51240, 2720, 1164, 11, 321, 600, 1096, 512, 12050, 365, 300, 13, 51352], "temperature": 0.0, "avg_logprob": -0.3069388219552447, "compression_ratio": 1.7902621722846441, "no_speech_prob": 0.01149938814342022}, {"id": 1349, "seek": 551538, "start": 5535.14, "end": 5540.62, "text": " I know Jono has his mid-year guidance approach for some of this sort of things, but there", "tokens": [51352, 286, 458, 7745, 78, 575, 702, 2062, 12, 5294, 10056, 3109, 337, 512, 295, 341, 1333, 295, 721, 11, 457, 456, 51626], "temperature": 0.0, "avg_logprob": -0.3069388219552447, "compression_ratio": 1.7902621722846441, "no_speech_prob": 0.01149938814342022}, {"id": 1350, "seek": 554062, "start": 5540.62, "end": 5547.58, "text": " are different approaches that you can play around here that exploring in the latent space", "tokens": [50364, 366, 819, 11587, 300, 291, 393, 862, 926, 510, 300, 12736, 294, 264, 48994, 1901, 50712], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1351, "seek": 554062, "start": 5547.58, "end": 5552.54, "text": " can make it computationally cheaper than having to decode it every time you want to, like", "tokens": [50712, 393, 652, 309, 24903, 379, 12284, 813, 1419, 281, 979, 1429, 309, 633, 565, 291, 528, 281, 11, 411, 50960], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1352, "seek": 554062, "start": 5552.54, "end": 5556.38, "text": " you have to look at the image and then maybe apply a classifier or apply some sort of guidance", "tokens": [50960, 291, 362, 281, 574, 412, 264, 3256, 293, 550, 1310, 3079, 257, 1508, 9902, 420, 3079, 512, 1333, 295, 10056, 51152], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1353, "seek": 554062, "start": 5556.38, "end": 5557.38, "text": " on the image.", "tokens": [51152, 322, 264, 3256, 13, 51202], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1354, "seek": 554062, "start": 5557.38, "end": 5560.62, "text": " But if you can do it directly in the latent space, a lot of interesting opportunities", "tokens": [51202, 583, 498, 291, 393, 360, 309, 3838, 294, 264, 48994, 1901, 11, 257, 688, 295, 1880, 4786, 51364], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1355, "seek": 554062, "start": 5560.62, "end": 5561.62, "text": " there as well.", "tokens": [51364, 456, 382, 731, 13, 51414], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1356, "seek": 554062, "start": 5561.62, "end": 5564.62, "text": " And now we're showing that indeed.", "tokens": [51414, 400, 586, 321, 434, 4099, 300, 6451, 13, 51564], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1357, "seek": 554062, "start": 5564.62, "end": 5568.3, "text": " On latents.", "tokens": [51564, 1282, 287, 267, 791, 13, 51748], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1358, "seek": 554062, "start": 5568.3, "end": 5569.3, "text": " Everything on latents.", "tokens": [51748, 5471, 322, 287, 267, 791, 13, 51798], "temperature": 0.0, "avg_logprob": -0.34750295089463057, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.4721877872943878}, {"id": 1359, "seek": 556930, "start": 5569.9800000000005, "end": 5571.9800000000005, "text": " You can also distill existing models.", "tokens": [50398, 509, 393, 611, 1483, 388, 75, 6741, 5245, 13, 50498], "temperature": 0.0, "avg_logprob": -0.307595972429242, "compression_ratio": 1.6953125, "no_speech_prob": 0.11900337785482407}, {"id": 1360, "seek": 556930, "start": 5571.9800000000005, "end": 5576.5, "text": " That's something I've done to make a latent clip is just have it try and mirror an image", "tokens": [50498, 663, 311, 746, 286, 600, 1096, 281, 652, 257, 48994, 7353, 307, 445, 362, 309, 853, 293, 8013, 364, 3256, 50724], "temperature": 0.0, "avg_logprob": -0.307595972429242, "compression_ratio": 1.6953125, "no_speech_prob": 0.11900337785482407}, {"id": 1361, "seek": 556930, "start": 5576.5, "end": 5577.5, "text": " space clip.", "tokens": [50724, 1901, 7353, 13, 50774], "temperature": 0.0, "avg_logprob": -0.307595972429242, "compression_ratio": 1.6953125, "no_speech_prob": 0.11900337785482407}, {"id": 1362, "seek": 556930, "start": 5577.5, "end": 5581.66, "text": " And so for classifiers as well, you could distill an ImageNet classifier.", "tokens": [50774, 400, 370, 337, 1508, 23463, 382, 731, 11, 291, 727, 42923, 364, 29903, 31890, 1508, 9902, 13, 50982], "temperature": 0.0, "avg_logprob": -0.307595972429242, "compression_ratio": 1.6953125, "no_speech_prob": 0.11900337785482407}, {"id": 1363, "seek": 556930, "start": 5581.66, "end": 5586.18, "text": " Rather than just having the label, you try and copy the logits.", "tokens": [50982, 16571, 813, 445, 1419, 264, 7645, 11, 291, 853, 293, 5055, 264, 3565, 1208, 13, 51208], "temperature": 0.0, "avg_logprob": -0.307595972429242, "compression_ratio": 1.6953125, "no_speech_prob": 0.11900337785482407}, {"id": 1364, "seek": 556930, "start": 5586.18, "end": 5588.78, "text": " And then that's an even richer signal.", "tokens": [51208, 400, 550, 300, 311, 364, 754, 29021, 6358, 13, 51338], "temperature": 0.0, "avg_logprob": -0.307595972429242, "compression_ratio": 1.6953125, "no_speech_prob": 0.11900337785482407}, {"id": 1365, "seek": 556930, "start": 5588.78, "end": 5592.34, "text": " You get more value per example.", "tokens": [51338, 509, 483, 544, 2158, 680, 1365, 13, 51516], "temperature": 0.0, "avg_logprob": -0.307595972429242, "compression_ratio": 1.6953125, "no_speech_prob": 0.11900337785482407}, {"id": 1366, "seek": 556930, "start": 5592.34, "end": 5598.34, "text": " So then you can create your latent version of some existing image classifier or object", "tokens": [51516, 407, 550, 291, 393, 1884, 428, 48994, 3037, 295, 512, 6741, 3256, 1508, 9902, 420, 2657, 51816], "temperature": 0.0, "avg_logprob": -0.307595972429242, "compression_ratio": 1.6953125, "no_speech_prob": 0.11900337785482407}, {"id": 1367, "seek": 559834, "start": 5598.38, "end": 5601.38, "text": " detector or, yeah, like multimodal model like that.", "tokens": [50366, 25712, 420, 11, 1338, 11, 411, 32972, 378, 304, 2316, 411, 300, 13, 50516], "temperature": 0.0, "avg_logprob": -0.3811281989602482, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.02032727561891079}, {"id": 1368, "seek": 559834, "start": 5601.38, "end": 5606.22, "text": " I feel like I feel funny about this because I'm like both excited about simple diffusion", "tokens": [50516, 286, 841, 411, 286, 841, 4074, 466, 341, 570, 286, 478, 411, 1293, 2919, 466, 2199, 25242, 50758], "temperature": 0.0, "avg_logprob": -0.3811281989602482, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.02032727561891079}, {"id": 1369, "seek": 559834, "start": 5606.22, "end": 5607.9400000000005, "text": " on the basis that it gets rid of latents.", "tokens": [50758, 322, 264, 5143, 300, 309, 2170, 3973, 295, 287, 267, 791, 13, 50844], "temperature": 0.0, "avg_logprob": -0.3811281989602482, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.02032727561891079}, {"id": 1370, "seek": 559834, "start": 5607.9400000000005, "end": 5613.3, "text": " But I'm also excited about latents on the basis of gets rid of most of the pixels.", "tokens": [50844, 583, 286, 478, 611, 2919, 466, 287, 267, 791, 322, 264, 5143, 295, 2170, 3973, 295, 881, 295, 264, 18668, 13, 51112], "temperature": 0.0, "avg_logprob": -0.3811281989602482, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.02032727561891079}, {"id": 1371, "seek": 559834, "start": 5613.3, "end": 5616.34, "text": " I don't know how I can be cheering for both, but somehow I am.", "tokens": [51112, 286, 500, 380, 458, 577, 286, 393, 312, 11060, 337, 1293, 11, 457, 6063, 286, 669, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3811281989602482, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.02032727561891079}, {"id": 1372, "seek": 559834, "start": 5616.34, "end": 5622.22, "text": " I guess may the best method win.", "tokens": [51264, 286, 2041, 815, 264, 1151, 3170, 1942, 13, 51558], "temperature": 0.0, "avg_logprob": -0.3811281989602482, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.02032727561891079}, {"id": 1373, "seek": 562222, "start": 5622.22, "end": 5630.1, "text": " So you know, the folks that are finishing this course, well, first of all, congratulations", "tokens": [50364, 407, 291, 458, 11, 264, 4024, 300, 366, 12693, 341, 1164, 11, 731, 11, 700, 295, 439, 11, 13568, 50758], "temperature": 0.0, "avg_logprob": -0.2654108567671342, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0036466659512370825}, {"id": 1374, "seek": 562222, "start": 5630.1, "end": 5633.66, "text": " because it's been a journey, particularly part two.", "tokens": [50758, 570, 309, 311, 668, 257, 4671, 11, 4098, 644, 732, 13, 50936], "temperature": 0.0, "avg_logprob": -0.2654108567671342, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0036466659512370825}, {"id": 1375, "seek": 562222, "start": 5633.66, "end": 5638.66, "text": " It's a journey which requires a lot of patience and tenacity.", "tokens": [50936, 467, 311, 257, 4671, 597, 7029, 257, 688, 295, 14826, 293, 2064, 19008, 13, 51186], "temperature": 0.0, "avg_logprob": -0.2654108567671342, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0036466659512370825}, {"id": 1376, "seek": 562222, "start": 5638.66, "end": 5642.54, "text": " You know, if you've kind of zipped through by binging on the videos, that's totally fine.", "tokens": [51186, 509, 458, 11, 498, 291, 600, 733, 295, 710, 5529, 807, 538, 272, 8716, 322, 264, 2145, 11, 300, 311, 3879, 2489, 13, 51380], "temperature": 0.0, "avg_logprob": -0.2654108567671342, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0036466659512370825}, {"id": 1377, "seek": 562222, "start": 5642.54, "end": 5643.54, "text": " It's a good approach.", "tokens": [51380, 467, 311, 257, 665, 3109, 13, 51430], "temperature": 0.0, "avg_logprob": -0.2654108567671342, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0036466659512370825}, {"id": 1378, "seek": 562222, "start": 5643.54, "end": 5648.9800000000005, "text": " But, you know, maybe go back now and do it more slowly and do the, you know, build it", "tokens": [51430, 583, 11, 291, 458, 11, 1310, 352, 646, 586, 293, 360, 309, 544, 5692, 293, 360, 264, 11, 291, 458, 11, 1322, 309, 51702], "temperature": 0.0, "avg_logprob": -0.2654108567671342, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0036466659512370825}, {"id": 1379, "seek": 564898, "start": 5648.98, "end": 5651.58, "text": " yourself and really experiment.", "tokens": [50364, 1803, 293, 534, 5120, 13, 50494], "temperature": 0.0, "avg_logprob": -0.31341253008161274, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.11429457366466522}, {"id": 1380, "seek": 564898, "start": 5651.58, "end": 5657.0599999999995, "text": " But assuming, you know, for folks who have got to the end of this and feel like, OK,", "tokens": [50494, 583, 11926, 11, 291, 458, 11, 337, 4024, 567, 362, 658, 281, 264, 917, 295, 341, 293, 841, 411, 11, 2264, 11, 50768], "temperature": 0.0, "avg_logprob": -0.31341253008161274, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.11429457366466522}, {"id": 1381, "seek": 564898, "start": 5657.0599999999995, "end": 5658.82, "text": " I get it more or less.", "tokens": [50768, 286, 483, 309, 544, 420, 1570, 13, 50856], "temperature": 0.0, "avg_logprob": -0.31341253008161274, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.11429457366466522}, {"id": 1382, "seek": 564898, "start": 5658.82, "end": 5659.82, "text": " Yeah.", "tokens": [50856, 865, 13, 50906], "temperature": 0.0, "avg_logprob": -0.31341253008161274, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.11429457366466522}, {"id": 1383, "seek": 564898, "start": 5659.82, "end": 5666.7, "text": " Do you guys have any sense of like what kind of things make sense to do now?", "tokens": [50906, 1144, 291, 1074, 362, 604, 2020, 295, 411, 437, 733, 295, 721, 652, 2020, 281, 360, 586, 30, 51250], "temperature": 0.0, "avg_logprob": -0.31341253008161274, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.11429457366466522}, {"id": 1384, "seek": 564898, "start": 5666.7, "end": 5670.94, "text": " You know, where would you guys go from here?", "tokens": [51250, 509, 458, 11, 689, 576, 291, 1074, 352, 490, 510, 30, 51462], "temperature": 0.0, "avg_logprob": -0.31341253008161274, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.11429457366466522}, {"id": 1385, "seek": 564898, "start": 5670.94, "end": 5676.5, "text": " I think that a great opportunity is implementing papers that I guess come along these days.", "tokens": [51462, 286, 519, 300, 257, 869, 2650, 307, 18114, 10577, 300, 286, 2041, 808, 2051, 613, 1708, 13, 51740], "temperature": 0.0, "avg_logprob": -0.31341253008161274, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.11429457366466522}, {"id": 1386, "seek": 567650, "start": 5677.02, "end": 5678.02, "text": " And I think at this stage...", "tokens": [50390, 400, 286, 519, 412, 341, 3233, 485, 50440], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1387, "seek": 567650, "start": 5678.02, "end": 5679.02, "text": " Wait, there'll be more papers?", "tokens": [50440, 3802, 11, 456, 603, 312, 544, 10577, 30, 50490], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1388, "seek": 567650, "start": 5679.02, "end": 5680.02, "text": " No way.", "tokens": [50490, 883, 636, 13, 50540], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1389, "seek": 567650, "start": 5680.02, "end": 5681.02, "text": " Yeah.", "tokens": [50540, 865, 13, 50590], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1390, "seek": 567650, "start": 5681.02, "end": 5687.54, "text": " But also at this stage, I think, you know, we're already discussing research ideas and", "tokens": [50590, 583, 611, 412, 341, 3233, 11, 286, 519, 11, 291, 458, 11, 321, 434, 1217, 10850, 2132, 3487, 293, 50916], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1391, "seek": 567650, "start": 5687.54, "end": 5691.58, "text": " I think, you know, we're in a solid position to come up with our own research ideas and", "tokens": [50916, 286, 519, 11, 291, 458, 11, 321, 434, 294, 257, 5100, 2535, 281, 808, 493, 365, 527, 1065, 2132, 3487, 293, 51118], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1392, "seek": 567650, "start": 5691.58, "end": 5693.54, "text": " explore those ideas.", "tokens": [51118, 6839, 729, 3487, 13, 51216], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1393, "seek": 567650, "start": 5693.54, "end": 5697.22, "text": " So I think that's a real opportunity that we have here.", "tokens": [51216, 407, 286, 519, 300, 311, 257, 957, 2650, 300, 321, 362, 510, 13, 51400], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1394, "seek": 567650, "start": 5697.22, "end": 5700.94, "text": " Yeah, I would say, I think that's best done often collaboratively.", "tokens": [51400, 865, 11, 286, 576, 584, 11, 286, 519, 300, 311, 1151, 1096, 2049, 16555, 356, 13, 51586], "temperature": 0.0, "avg_logprob": -0.33666708617083796, "compression_ratio": 1.7043478260869565, "no_speech_prob": 0.0037064331118017435}, {"id": 1395, "seek": 570094, "start": 5700.94, "end": 5708.339999999999, "text": " So I'll just mention that Fast.ai has a Discord, which if you've got to this point, then you're", "tokens": [50364, 407, 286, 603, 445, 2152, 300, 15968, 13, 1301, 575, 257, 32623, 11, 597, 498, 291, 600, 658, 281, 341, 935, 11, 550, 291, 434, 50734], "temperature": 0.0, "avg_logprob": -0.283734944241106, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.1359841227531433}, {"id": 1396, "seek": 570094, "start": 5708.339999999999, "end": 5713.179999999999, "text": " probably somebody who would benefit from being there.", "tokens": [50734, 1391, 2618, 567, 576, 5121, 490, 885, 456, 13, 50976], "temperature": 0.0, "avg_logprob": -0.283734944241106, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.1359841227531433}, {"id": 1397, "seek": 570094, "start": 5713.179999999999, "end": 5717.54, "text": " And yeah, just pop your head in and say, like, there's an introduction, so just say hello", "tokens": [50976, 400, 1338, 11, 445, 1665, 428, 1378, 294, 293, 584, 11, 411, 11, 456, 311, 364, 9339, 11, 370, 445, 584, 7751, 51194], "temperature": 0.0, "avg_logprob": -0.283734944241106, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.1359841227531433}, {"id": 1398, "seek": 570094, "start": 5717.54, "end": 5722.94, "text": " and you don't, you know, maybe say what you're interested in or whatever, because it's nice", "tokens": [51194, 293, 291, 500, 380, 11, 291, 458, 11, 1310, 584, 437, 291, 434, 3102, 294, 420, 2035, 11, 570, 309, 311, 1481, 51464], "temperature": 0.0, "avg_logprob": -0.283734944241106, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.1359841227531433}, {"id": 1399, "seek": 570094, "start": 5722.94, "end": 5724.66, "text": " to work with others, I think.", "tokens": [51464, 281, 589, 365, 2357, 11, 286, 519, 13, 51550], "temperature": 0.0, "avg_logprob": -0.283734944241106, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.1359841227531433}, {"id": 1400, "seek": 570094, "start": 5724.66, "end": 5730.099999999999, "text": " I mean, both Jono and Tanishka I only know because of the Discord and the forums and", "tokens": [51550, 286, 914, 11, 1293, 7745, 78, 293, 314, 7524, 2330, 286, 787, 458, 570, 295, 264, 32623, 293, 264, 26998, 293, 51822], "temperature": 0.0, "avg_logprob": -0.283734944241106, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.1359841227531433}, {"id": 1401, "seek": 573010, "start": 5730.26, "end": 5731.26, "text": " so forth.", "tokens": [50372, 370, 5220, 13, 50422], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1402, "seek": 573010, "start": 5731.26, "end": 5732.26, "text": " So that would be one.", "tokens": [50422, 407, 300, 576, 312, 472, 13, 50472], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1403, "seek": 573010, "start": 5732.26, "end": 5735.780000000001, "text": " And we also have a, we have a generative channel.", "tokens": [50472, 400, 321, 611, 362, 257, 11, 321, 362, 257, 1337, 1166, 2269, 13, 50648], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1404, "seek": 573010, "start": 5735.780000000001, "end": 5739.42, "text": " So anything related to generative models, that's the place.", "tokens": [50648, 407, 1340, 4077, 281, 1337, 1166, 5245, 11, 300, 311, 264, 1081, 13, 50830], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1405, "seek": 573010, "start": 5739.42, "end": 5743.46, "text": " So for example, Molly was posting some of her experiments in that channel.", "tokens": [50830, 407, 337, 1365, 11, 26665, 390, 15978, 512, 295, 720, 12050, 294, 300, 2269, 13, 51032], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1406, "seek": 573010, "start": 5743.46, "end": 5746.9400000000005, "text": " I think there are other Fast.ai members posting their experiments.", "tokens": [51032, 286, 519, 456, 366, 661, 15968, 13, 1301, 2679, 15978, 641, 12050, 13, 51206], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1407, "seek": 573010, "start": 5746.9400000000005, "end": 5752.34, "text": " So if you're doing anything generative model related, that's a great way to also get feedback", "tokens": [51206, 407, 498, 291, 434, 884, 1340, 1337, 1166, 2316, 4077, 11, 300, 311, 257, 869, 636, 281, 611, 483, 5824, 51476], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1408, "seek": 573010, "start": 5752.34, "end": 5754.38, "text": " and thoughts from the community.", "tokens": [51476, 293, 4598, 490, 264, 1768, 13, 51578], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1409, "seek": 573010, "start": 5754.38, "end": 5755.38, "text": " Yeah.", "tokens": [51578, 865, 13, 51628], "temperature": 0.0, "avg_logprob": -0.28406297838365707, "compression_ratio": 1.7261410788381744, "no_speech_prob": 0.007106611970812082}, {"id": 1410, "seek": 575538, "start": 5755.900000000001, "end": 5759.86, "text": " I'd also say that, like, there's this, if you're at the stage where you finish this", "tokens": [50390, 286, 1116, 611, 584, 300, 11, 411, 11, 456, 311, 341, 11, 498, 291, 434, 412, 264, 3233, 689, 291, 2413, 341, 50588], "temperature": 0.0, "avg_logprob": -0.26695910367098724, "compression_ratio": 1.8129032258064517, "no_speech_prob": 0.2745334506034851}, {"id": 1411, "seek": 575538, "start": 5759.86, "end": 5762.9400000000005, "text": " course, you actually understand how diffusion models work.", "tokens": [50588, 1164, 11, 291, 767, 1223, 577, 25242, 5245, 589, 13, 50742], "temperature": 0.0, "avg_logprob": -0.26695910367098724, "compression_ratio": 1.8129032258064517, "no_speech_prob": 0.2745334506034851}, {"id": 1412, "seek": 575538, "start": 5762.9400000000005, "end": 5767.1, "text": " You've got a good handle on what the different components and like stable diffusion are.", "tokens": [50742, 509, 600, 658, 257, 665, 4813, 322, 437, 264, 819, 6677, 293, 411, 8351, 25242, 366, 13, 50950], "temperature": 0.0, "avg_logprob": -0.26695910367098724, "compression_ratio": 1.8129032258064517, "no_speech_prob": 0.2745334506034851}, {"id": 1413, "seek": 575538, "start": 5767.1, "end": 5770.66, "text": " And you know how to wrangle data for training and all these things.", "tokens": [50950, 400, 291, 458, 577, 281, 928, 7846, 1412, 337, 3097, 293, 439, 613, 721, 13, 51128], "temperature": 0.0, "avg_logprob": -0.26695910367098724, "compression_ratio": 1.8129032258064517, "no_speech_prob": 0.2745334506034851}, {"id": 1414, "seek": 575538, "start": 5770.66, "end": 5774.46, "text": " You're like so far ahead of most people who are building in this space.", "tokens": [51128, 509, 434, 411, 370, 1400, 2286, 295, 881, 561, 567, 366, 2390, 294, 341, 1901, 13, 51318], "temperature": 0.0, "avg_logprob": -0.26695910367098724, "compression_ratio": 1.8129032258064517, "no_speech_prob": 0.2745334506034851}, {"id": 1415, "seek": 575538, "start": 5774.46, "end": 5779.22, "text": " And I've got lots of, lots of companies and people reaching out to me to say, do you know", "tokens": [51318, 400, 286, 600, 658, 3195, 295, 11, 3195, 295, 3431, 293, 561, 9906, 484, 281, 385, 281, 584, 11, 360, 291, 458, 51556], "temperature": 0.0, "avg_logprob": -0.26695910367098724, "compression_ratio": 1.8129032258064517, "no_speech_prob": 0.2745334506034851}, {"id": 1416, "seek": 575538, "start": 5779.22, "end": 5783.54, "text": " anybody who has like more than just, oh, I know how to like load stable diffusion and", "tokens": [51556, 4472, 567, 575, 411, 544, 813, 445, 11, 1954, 11, 286, 458, 577, 281, 411, 3677, 8351, 25242, 293, 51772], "temperature": 0.0, "avg_logprob": -0.26695910367098724, "compression_ratio": 1.8129032258064517, "no_speech_prob": 0.2745334506034851}, {"id": 1417, "seek": 575538, "start": 5783.54, "end": 5784.54, "text": " make an image.", "tokens": [51772, 652, 364, 3256, 13, 51822], "temperature": 0.0, "avg_logprob": -0.26695910367098724, "compression_ratio": 1.8129032258064517, "no_speech_prob": 0.2745334506034851}, {"id": 1418, "seek": 578454, "start": 5784.7, "end": 5787.78, "text": " And I know someone who knows how to actually like tinker with it and make it better.", "tokens": [50372, 400, 286, 458, 1580, 567, 3255, 577, 281, 767, 411, 256, 40467, 365, 309, 293, 652, 309, 1101, 13, 50526], "temperature": 0.0, "avg_logprob": -0.2793879541857489, "compression_ratio": 1.779874213836478, "no_speech_prob": 0.46843844652175903}, {"id": 1419, "seek": 578454, "start": 5787.78, "end": 5790.5, "text": " And if you've got those skills, like, don't feel like, oh, I'm definitely not qualified", "tokens": [50526, 400, 498, 291, 600, 658, 729, 3942, 11, 411, 11, 500, 380, 841, 411, 11, 1954, 11, 286, 478, 2138, 406, 15904, 50662], "temperature": 0.0, "avg_logprob": -0.2793879541857489, "compression_ratio": 1.779874213836478, "no_speech_prob": 0.46843844652175903}, {"id": 1420, "seek": 578454, "start": 5790.5, "end": 5796.98, "text": " to like apply or like, there's lots of stuff where, yeah, just taking these ideas now and", "tokens": [50662, 281, 411, 3079, 420, 411, 11, 456, 311, 3195, 295, 1507, 689, 11, 1338, 11, 445, 1940, 613, 3487, 586, 293, 50986], "temperature": 0.0, "avg_logprob": -0.2793879541857489, "compression_ratio": 1.779874213836478, "no_speech_prob": 0.46843844652175903}, {"id": 1421, "seek": 578454, "start": 5796.98, "end": 5800.46, "text": " like just simple, sensible ideas that we've covered in the course that have come up and", "tokens": [50986, 411, 445, 2199, 11, 25380, 3487, 300, 321, 600, 5343, 294, 264, 1164, 300, 362, 808, 493, 293, 51160], "temperature": 0.0, "avg_logprob": -0.2793879541857489, "compression_ratio": 1.779874213836478, "no_speech_prob": 0.46843844652175903}, {"id": 1422, "seek": 578454, "start": 5800.46, "end": 5802.54, "text": " say, like, oh, actually, maybe I could try that.", "tokens": [51160, 584, 11, 411, 11, 1954, 11, 767, 11, 1310, 286, 727, 853, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2793879541857489, "compression_ratio": 1.779874213836478, "no_speech_prob": 0.46843844652175903}, {"id": 1423, "seek": 578454, "start": 5802.54, "end": 5805.82, "text": " Maybe I could play with this, you know, take this experimentalist approach.", "tokens": [51264, 2704, 286, 727, 862, 365, 341, 11, 291, 458, 11, 747, 341, 17069, 468, 3109, 13, 51428], "temperature": 0.0, "avg_logprob": -0.2793879541857489, "compression_ratio": 1.779874213836478, "no_speech_prob": 0.46843844652175903}, {"id": 1424, "seek": 578454, "start": 5805.82, "end": 5810.86, "text": " I feel like there's actually a lot of people who would love to have you helping them build", "tokens": [51428, 286, 841, 411, 456, 311, 767, 257, 688, 295, 561, 567, 576, 959, 281, 362, 291, 4315, 552, 1322, 51680], "temperature": 0.0, "avg_logprob": -0.2793879541857489, "compression_ratio": 1.779874213836478, "no_speech_prob": 0.46843844652175903}, {"id": 1425, "seek": 581086, "start": 5810.86, "end": 5814.78, "text": " a million and one little stable diffusion based apps or whatever that you're working", "tokens": [50364, 257, 2459, 293, 472, 707, 8351, 25242, 2361, 7733, 420, 2035, 300, 291, 434, 1364, 50560], "temperature": 0.0, "avg_logprob": -0.31296106974283855, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.35915979743003845}, {"id": 1426, "seek": 581086, "start": 5814.78, "end": 5815.78, "text": " on.", "tokens": [50560, 322, 13, 50610], "temperature": 0.0, "avg_logprob": -0.31296106974283855, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.35915979743003845}, {"id": 1427, "seek": 581086, "start": 5815.78, "end": 5818.54, "text": " And particularly like the thing we always talk about at Fast.ai, which is particularly", "tokens": [50610, 400, 4098, 411, 264, 551, 321, 1009, 751, 466, 412, 15968, 13, 1301, 11, 597, 307, 4098, 50748], "temperature": 0.0, "avg_logprob": -0.31296106974283855, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.35915979743003845}, {"id": 1428, "seek": 581086, "start": 5818.54, "end": 5825.339999999999, "text": " if you can combine that with your domain expertise, you know, whether it be from your, your hobbies", "tokens": [50748, 498, 291, 393, 10432, 300, 365, 428, 9274, 11769, 11, 291, 458, 11, 1968, 309, 312, 490, 428, 11, 428, 35750, 51088], "temperature": 0.0, "avg_logprob": -0.31296106974283855, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.35915979743003845}, {"id": 1429, "seek": 581086, "start": 5825.339999999999, "end": 5831.099999999999, "text": " or your work in some completely different field or whatever, you know, there'll be lots", "tokens": [51088, 420, 428, 589, 294, 512, 2584, 819, 2519, 420, 2035, 11, 291, 458, 11, 456, 603, 312, 3195, 51376], "temperature": 0.0, "avg_logprob": -0.31296106974283855, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.35915979743003845}, {"id": 1430, "seek": 581086, "start": 5831.099999999999, "end": 5835.42, "text": " of interesting ways to combine, you know, you probably are one of the only people in", "tokens": [51376, 295, 1880, 2098, 281, 10432, 11, 291, 458, 11, 291, 1391, 366, 472, 295, 264, 787, 561, 294, 51592], "temperature": 0.0, "avg_logprob": -0.31296106974283855, "compression_ratio": 1.7431906614785992, "no_speech_prob": 0.35915979743003845}, {"id": 1431, "seek": 583542, "start": 5835.42, "end": 5843.9800000000005, "text": " the world right now that understand your areas of passion or of vocation as well as", "tokens": [50364, 264, 1002, 558, 586, 300, 1223, 428, 3179, 295, 5418, 420, 295, 2329, 399, 382, 731, 382, 50792], "temperature": 0.0, "avg_logprob": -0.31873731715704806, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.24770668148994446}, {"id": 1432, "seek": 583542, "start": 5843.9800000000005, "end": 5844.9800000000005, "text": " these techniques.", "tokens": [50792, 613, 7512, 13, 50842], "temperature": 0.0, "avg_logprob": -0.31873731715704806, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.24770668148994446}, {"id": 1433, "seek": 583542, "start": 5844.9800000000005, "end": 5851.14, "text": " So, and again, that's a good place to kind of get on the forum or the discord or whatever", "tokens": [50842, 407, 11, 293, 797, 11, 300, 311, 257, 665, 1081, 281, 733, 295, 483, 322, 264, 17542, 420, 264, 32989, 420, 2035, 51150], "temperature": 0.0, "avg_logprob": -0.31873731715704806, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.24770668148994446}, {"id": 1434, "seek": 583542, "start": 5851.14, "end": 5854.18, "text": " and start having those conversations.", "tokens": [51150, 293, 722, 1419, 729, 7315, 13, 51302], "temperature": 0.0, "avg_logprob": -0.31873731715704806, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.24770668148994446}, {"id": 1435, "seek": 583542, "start": 5854.18, "end": 5858.3, "text": " Because it can be, yeah, it can be difficult when you're at the cutting edge, which you", "tokens": [51302, 1436, 309, 393, 312, 11, 1338, 11, 309, 393, 312, 2252, 562, 291, 434, 412, 264, 6492, 4691, 11, 597, 291, 51508], "temperature": 0.0, "avg_logprob": -0.31873731715704806, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.24770668148994446}, {"id": 1436, "seek": 583542, "start": 5858.3, "end": 5861.42, "text": " now are by definition.", "tokens": [51508, 586, 366, 538, 7123, 13, 51664], "temperature": 0.0, "avg_logprob": -0.31873731715704806, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.24770668148994446}, {"id": 1437, "seek": 583542, "start": 5861.42, "end": 5864.02, "text": " All right.", "tokens": [51664, 1057, 558, 13, 51794], "temperature": 0.0, "avg_logprob": -0.31873731715704806, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.24770668148994446}, {"id": 1438, "seek": 586402, "start": 5864.02, "end": 5870.540000000001, "text": " Well, we better go away and start figuring out how on earth GPT-4 works.", "tokens": [50364, 1042, 11, 321, 1101, 352, 1314, 293, 722, 15213, 484, 577, 322, 4120, 26039, 51, 12, 19, 1985, 13, 50690], "temperature": 0.0, "avg_logprob": -0.28302456537882487, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.035664480179548264}, {"id": 1439, "seek": 586402, "start": 5870.540000000001, "end": 5875.26, "text": " I don't think we're going to necessarily build the whole GPT-4 from scratch, at least not", "tokens": [50690, 286, 500, 380, 519, 321, 434, 516, 281, 4725, 1322, 264, 1379, 26039, 51, 12, 19, 490, 8459, 11, 412, 1935, 406, 50926], "temperature": 0.0, "avg_logprob": -0.28302456537882487, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.035664480179548264}, {"id": 1440, "seek": 586402, "start": 5875.26, "end": 5879.820000000001, "text": " at that scale, but I'm sure we're going to have some interesting things happening with", "tokens": [50926, 412, 300, 4373, 11, 457, 286, 478, 988, 321, 434, 516, 281, 362, 512, 1880, 721, 2737, 365, 51154], "temperature": 0.0, "avg_logprob": -0.28302456537882487, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.035664480179548264}, {"id": 1441, "seek": 586402, "start": 5879.820000000001, "end": 5880.820000000001, "text": " NLP.", "tokens": [51154, 426, 45196, 13, 51204], "temperature": 0.0, "avg_logprob": -0.28302456537882487, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.035664480179548264}, {"id": 1442, "seek": 586402, "start": 5880.820000000001, "end": 5883.820000000001, "text": " And Jono, Tanisha, thank you so much.", "tokens": [51204, 400, 7745, 78, 11, 314, 7524, 64, 11, 1309, 291, 370, 709, 13, 51354], "temperature": 0.0, "avg_logprob": -0.28302456537882487, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.035664480179548264}, {"id": 1443, "seek": 586402, "start": 5883.820000000001, "end": 5884.820000000001, "text": " It's been a real pleasure.", "tokens": [51354, 467, 311, 668, 257, 957, 6834, 13, 51404], "temperature": 0.0, "avg_logprob": -0.28302456537882487, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.035664480179548264}, {"id": 1444, "seek": 586402, "start": 5884.820000000001, "end": 5889.9800000000005, "text": " It was nice doing things with the, with a live audience, but I've got to say, I really", "tokens": [51404, 467, 390, 1481, 884, 721, 365, 264, 11, 365, 257, 1621, 4034, 11, 457, 286, 600, 658, 281, 584, 11, 286, 534, 51662], "temperature": 0.0, "avg_logprob": -0.28302456537882487, "compression_ratio": 1.5675675675675675, "no_speech_prob": 0.035664480179548264}, {"id": 1445, "seek": 588998, "start": 5889.98, "end": 5895.219999999999, "text": " enjoyed this experience of doing stuff with you guys the last few lessons.", "tokens": [50364, 4626, 341, 1752, 295, 884, 1507, 365, 291, 1074, 264, 1036, 1326, 8820, 13, 50626], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1446, "seek": 588998, "start": 5895.219999999999, "end": 5896.219999999999, "text": " So thank you so much.", "tokens": [50626, 407, 1309, 291, 370, 709, 13, 50676], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1447, "seek": 588998, "start": 5896.219999999999, "end": 5897.219999999999, "text": " Yeah.", "tokens": [50676, 865, 13, 50726], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1448, "seek": 588998, "start": 5897.219999999999, "end": 5898.219999999999, "text": " Thanks for having us.", "tokens": [50726, 2561, 337, 1419, 505, 13, 50776], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1449, "seek": 588998, "start": 5898.219999999999, "end": 5899.219999999999, "text": " This is really, really fun.", "tokens": [50776, 639, 307, 534, 11, 534, 1019, 13, 50826], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1450, "seek": 588998, "start": 5899.219999999999, "end": 5900.219999999999, "text": " All right.", "tokens": [50826, 1057, 558, 13, 50876], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1451, "seek": 588998, "start": 5900.219999999999, "end": 5901.219999999999, "text": " Bye.", "tokens": [50876, 4621, 13, 50926], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1452, "seek": 588998, "start": 5901.219999999999, "end": 5902.219999999999, "text": " Cool.", "tokens": [50926, 8561, 13, 50976], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1453, "seek": 588998, "start": 5902.219999999999, "end": 5903.219999999999, "text": " See you in part three.", "tokens": [50976, 3008, 291, 294, 644, 1045, 13, 51026], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1454, "seek": 588998, "start": 5903.219999999999, "end": 5904.219999999999, "text": " Bye.", "tokens": [51026, 4621, 13, 51076], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1455, "seek": 588998, "start": 5904.219999999999, "end": 5905.219999999999, "text": " Yeah.", "tokens": [51076, 865, 13, 51126], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1456, "seek": 588998, "start": 5905.219999999999, "end": 5906.219999999999, "text": " Bye.", "tokens": [51126, 4621, 13, 51176], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1457, "seek": 588998, "start": 5906.219999999999, "end": 5907.219999999999, "text": " Bye.", "tokens": [51176, 4621, 13, 51226], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1458, "seek": 588998, "start": 5907.219999999999, "end": 5908.219999999999, "text": " Bye.", "tokens": [51226, 4621, 13, 51276], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1459, "seek": 588998, "start": 5908.219999999999, "end": 5909.219999999999, "text": " Bye.", "tokens": [51276, 4621, 13, 51326], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1460, "seek": 588998, "start": 5909.219999999999, "end": 5910.219999999999, "text": " Bye.", "tokens": [51326, 4621, 13, 51376], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1461, "seek": 588998, "start": 5910.219999999999, "end": 5911.219999999999, "text": " Bye.", "tokens": [51376, 4621, 13, 51426], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1462, "seek": 588998, "start": 5911.219999999999, "end": 5912.219999999999, "text": " Bye.", "tokens": [51426, 4621, 13, 51476], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1463, "seek": 588998, "start": 5912.219999999999, "end": 5913.219999999999, "text": " Bye.", "tokens": [51476, 4621, 13, 51526], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1464, "seek": 588998, "start": 5913.219999999999, "end": 5914.219999999999, "text": " Bye.", "tokens": [51526, 4621, 13, 51576], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1465, "seek": 588998, "start": 5914.219999999999, "end": 5915.219999999999, "text": " Bye.", "tokens": [51576, 4621, 13, 51626], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1466, "seek": 588998, "start": 5915.219999999999, "end": 5916.219999999999, "text": " Bye.", "tokens": [51626, 4621, 13, 51676], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1467, "seek": 588998, "start": 5916.219999999999, "end": 5917.219999999999, "text": " Bye.", "tokens": [51676, 4621, 13, 51726], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1468, "seek": 588998, "start": 5917.219999999999, "end": 5918.219999999999, "text": " Bye.", "tokens": [51726, 4621, 13, 51776], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}, {"id": 1469, "seek": 588998, "start": 5918.219999999999, "end": 5919.219999999999, "text": " Bye.", "tokens": [51776, 4621, 13, 51826], "temperature": 0.0, "avg_logprob": -0.2735093386118649, "compression_ratio": 1.793548387096774, "no_speech_prob": 0.23324379324913025}], "language": "en"}