{"text": " Welcome back everybody I'm sure you've noticed But there's been a lot of cool activity on the forum this week and one of the things that's been really great to see is That a lot of you have started creating really helpful materials both for your classmates to better understand stuff and also for you to better understand stuff by Trying to teach what you've learned. I just wanted to highlight a few I've actually actually Posted to the wiki thread a few of these but there's there's lots more Rashima's posted a whole bunch of nice introductory tutorials. So for example if you're having any trouble getting connected with AWS She's got a whole step-by-step How to go about logging in and getting everything working which I think is a really terrific thing and so it's a kind of thing that if you do Writing some notes for yourself to remind you how to do it You may as well post them for others to do it to do it as well and by using a markdown file like this And it's actually good practice if you haven't used github before if you put it up on github Everybody can now use it or of course you can just put it in the forum so more advanced Thing that Rashima wrote up about is she noticed that I like using T max Which is a handy little thing which lets me Let's me basically have a window So as soon as I log into my computer If I run T max You'll see that all of my windows pop straight up basically and I can like Continue running stuff in the background and I can like I've got them over here and I can kind of zoom into it or I Can move over to the top which is his by Jupiter kernel running and so forth so if that sounds interesting Rashima has a Tutorial here on how you can use T max And it's actually got a whole bunch of stuff in her github, so that's that's really cool Uphill tomorrow has written a very nice kind of summary basically of our last lesson Which kind of covers What are the key things we did and why did we do them so if you're if you're kind of? Wondering like how does it fit together? I think this is a really helpful summary of like What did those couple of hours look like if we summarize it all into a page or two? I also really like a bell has Duck kind of done a deep dive on the learning rate finder which is a Topic that a lot of you have been interested in learning more about particularly Those of you who have done deep learning before I've realized that this is like a solution to a problem that you've been having for A long time and haven't seen before and so it's kind of something which hasn't really been blocked about before so this is the first Time I've seen this blogged about so when I put this on Twitter a link to The bells post it's been shared now hundreds of times It's been really really popular and viewed many thousands of times, so that's some great content I Redeck has posted lots of cool stuff. I really like this practitioners guide to pie torch which again This is more for more advanced students, but it's like digging into people who have never used pie torch before but know a bit about Numerical programming in general it's a quick introduction to how pie torch is different And then there's been some interesting little bits of research like what's the relationship between learning rate and batch size? So one of the students actually asked me this before class and I said that well one of the other students has written an analysis of exactly that So what he's done is basically looked through and tried different batch sizes and different learning rates and tried to see how they seem to Relate together and these are all like cool experiments, which you know you can try yourself Redeck again, he's written something again a kind of a research into this question. I made a claim that the Stochastic gradient descent with restarts finds more Generalizable parts of the function surface because they're kind of flatter and he's been trying to figure out is there a way to measure that More directly not quite successful yet, but a really interesting piece of research Got some introductions to convolutional neural networks and then Something that we'll be learning about towards the end of this course, but I'm sure you've noticed we're using something called ResNet and Anand Sahar actually posted a Pretty impressive analysis of like what's a ResNet? And why is it interesting and this one's actually been very already shared very widely around the internet. I've seen also So some more advanced students who are interested in jumping ahead can look at that and Uphill to mine also has done something similar so lots of Yeah, lots of stuff going on on the forums. I'm sure you've also noticed we have a beginner forum now specifically for you know asking questions which You know There's always the case that there are no Dumb questions, but when there's lots of people around you talking about advanced topics it might not feel that way so hopefully the beginners forum is just a less intimidating space and If you're a more advanced student who can help answer those questions Please do but remember when you do answer those questions try to answer in a way That's friendly to people that maybe you know have no more than a year of programming experience and haven't done any machine learning before So you know I hope Other people in the class Feel like you can contribute as well and just remember all of the people we just looked at or many of them I believe have never Hosted anything to the internet before right I mean you don't have to be a particular kind of person to be allowed to blog or something you can just jot down your notes throw it up there and one handy thing is if you just put it on the forum and you're not quite sure of some of the details then Then you know you have an opportunity to get feedback and say like ah well That's not quite how that works You know actually it works this way instead or or that's a really interesting insight had you thought about taking this further and so forth so what we've done so far is a kind of a an introduction as a just as a practitioner to Convolutional neural networks for images, and we haven't really talked much at all about The theory or why they work or the math of them, but on the other hand what we have done is seen how to Build a model which actually works exceptionally well in fact world-class level models And we'll kind of review a little bit of that today and Then also today we're going to dig in a little bit quite a lot more actually into the underlying theory of like what is a what? Is a CNN? What's a convolution? How does this work? And then we're going to kind of go through this this cycle where we're going to dig We're going to do a little intro into a whole bunch of application areas using neural nets for structured data So kind of like logistics or forecasting or you know financial data or that kind of thing and then looking at language applications and LP applications using recurrent neural nets and then collaborative filtering for Recommendation systems and so these will all be like Similar to what we've done for for CNNs images It'll be like here's how you can get a state-of-the-art result without digging into the theory But but knowing how to actually make it work And then we're kind of go go to go back through those almost in reverse order So then we're going to dig right into collaborative filtering in a lot of detail and see how how to write the code Underneath and how the math works underneath and then we're going to do the same thing for structured data analysis We're going to do the same thing for confidence for images and finally an in-depth deep dive into recurrent neural networks So that's kind of where we're getting So let's start by Doing a little bit of a review and I want to Also provide a bit more detail on some on some steps that we only briefly skipped over So I want to make sure that we're all able to complete Kind of last week's assignment, which was the the dog breeds I mean to basically apply what you've learned to it another data set and I thought the easiest one to do would be the dog Breeds kaggle competition and so I want to make sure everybody has everything you need to do this right now So the first thing is to make sure that you know How to download data and so there's there's two main places at the moment We're kind of downloading data from one is from kaggle And the other is from like anywhere else And so I'll first of all do the the kaggle version So to download from kaggle we use something called kaggle CLI Which is here and to install it I think it's already in Let's just double check Yeah, so it's already should already be in your environment But to make sure one thing that happens is because this is downloading from the kaggle website through like screen scraping every time kaggle changes The website it breaks so anytime you try to use it and If kaggle's websites changed recently you'll need to make sure you get the most recent version so you can always go pip install kaggle dash CLI Minus minus upgrade and so that'll just make sure that you've got the latest version of of it and everything that it depends on okay And so then having done that you can follow the instructions actually I think Reshma was kind enough to there you go. There's a kaggle CLI feel like everything you need to know can be found at Reshma's Github So basically to do that the next step you go KG download And then you provide your username with minus you you provide your password with minus P And then minus C You did the competition name and a lot of people in the forum is being confused about what to enter here And so the key thing to note is that when you're at a kaggle competition After the slash C There's a specific name planet dash understanding dash etc right that's the name you need Okay The other thing you'll need to make sure is that you've on your own computer Have attempted to click download at least once because when you do it will ask you to accept the rules If you've forgotten to do that KG download will give you a hint it'll say oh it looks like you might have forgotten the rules If you log into kaggle with like a Google account like anything other than a username password this won't work So you'll need to click forgot password on kaggle and get them to send you a normal password So that's the kaggle version right and so when you do that you end up with a whole folder Created for you with all of that competition data in it So a couple of reasons you might want to not use that the first is that you're using a data set That's not on kaggle the second is that you don't want all of the data sets in a kaggle competition for example the planet Competition that we've been looking at a little bit will look at again today Has data in two formats tiff and jpeg the tiff is 19 gigabytes and the jpeg is 600 megabytes So you probably don't want to download both So I'll show you a really cool tip which actually somebody on the forum taught me I think it was one of the msan students here at usf. There's a Chrome extension called curl wget So you can just search for curl wget And then you install it by just clicking on install if you haven't installed extension before and then from now on Every time you try to download something so I'll try and download this file And I'll just go ahead and cancel it right and now you see this little yellow button that's added up here There's a whole command here right so I can copy that and Paste it into my window and Hit go and it's there it goes okay So what that does is like all of your cookies and headers and everything else needed to download that file is like saved So this is not just useful for Downloading data it's also useful if you like trying to download some I don't know TV show or something anything where you're hidden behind a Login or something you can you can grab it and actually that is very useful for data science because quite often We want to analyze things like videos on our on our consoles So this is a good trick all right, so there's two ways to get the data So then Having got the data you then need to Build your model right? So what I tend to do like you'll notice that I tend to assume that the data is in a directory called data That's a sub directory of wherever your notebook is right Now you don't necessarily Actually want to put your data there you might want to put it directly in your home directory Or you might want to put it on another drive or whatever so what I do is If you look inside my courses deal one folder. You'll see that data is actually a symbolic link To a different drive right so you can put it anywhere you like and then you can just add a symbolic link Or you can just put it there directly it's up to you. You haven't used sim links before they're like Aliases or shortcuts on the Mac or Windows? Very handy, and there's some threads on the forum about how to use them if you want to help with that That's for example is also how we actually have the Fast AI modules available from the same place as our notebooks. It's just a sim link to where they come from anytime you want to see like Where things actually point to in Linux you can just use the minus L flag to? To listing a directory and that'll show you where the sim links Exists to law show show you which things are directories so forth Okay, so one thing which May be a little unclear based on what we've done so far is like How little code you actually need to do this end-to-end? So what I've got here is is in a single window is an entire End to end process to get a state-of-the-art result for cats versus dogs right I've the only Step I've skipped is the bit where we've downloaded it from Kaggle, and then where we unzipped it right so These are literally all the steps and so we import our Libraries and actually if you import this one Conflearner that basically imports everything else So that's that we need to tell it the path of where things are The size that we want the batch size that we want all right So then and we're going to learn a lot more about what these do very shortly But basically we say how do we want to transform our data? So we want to transform it in a way that's suitable to this particular kind of model and that's Assumes that the photos aside on photos and that we're going to zoom in up to 10% each time We say that we want to get some data based on paths And so remember this is this idea that there's a path called cats and a path called dogs And they're inside a path called train and a path called valid Note that you can always Overwrite these with other things so if your things are in different known folders You could either rename them or you can see here There's like a train name and a bowel name you can always pick something else here also Notice there's a test name So if you want to submit something to cattle you'll need to fill in the name the name of the folder where the test set is And obviously those those won't be labeled So then we create a model from a pre trained model It's from a resnet 50 model using this data, and then we call fit and remember by default That has all of the layers, but the last few frozen and again. We'll learn a lot more about what that means And so that's that's what that does so that That took two and a half minutes Notice here. I didn't say pre compute equals true again There's been some confusion on the forums about like what that means It's it's only a it's only something that makes it a little faster for this first step right so you can always skip it And if you're at all confused about it, or it's causing you any problems. Just leave it off right because it's just a It's just a shortcut which caches some of that intermediate steps that don't have to be recapitulated each time Okay, and remember that when we are using pre computed activations data augmentation doesn't work right so even if you ask for a data Augmentation if you've got pre compute equals true It doesn't actually do any data augmentation because it's using the cached non augmented activations So in this case to keep this as simple as possible. I have no pre computed anything going on So I do three cycles of length one and Then I can then unfreeze So it's now got to train the whole thing something we haven't seen before and we'll learn about in the second half is Called be and freeze for now all you need to know is that if you're using a Model like a bigger deeper model like resnet 50 or res next 101 On a data set that's very very similar to image net like these cats and dogs data sets on other words It's like side on photos of standard objects You know of a similar size to image net like somewhere between 200 and 500 pixels You should probably add this line When you unfreeze for those of you that are more advanced what it's doing is it's it's causing the batch normalization Moving averages to not be updated, but in the second half of this course you're going to learn all about why we do that It's something that's not supported by any other library But it turns out to be super important anyway, so we do one more epoch with training the whole network And then at the end we use test time augmentation To ensure that we get the best predictions we can and that gives us 99.45 percent So that's that's it right so when you try a new data set. They're basically the minimum set of steps That you would need to follow You'll notice this is assuming. I already know what learning right to use so you'd use a learning rate finder for that To assuming that I know that the directory layout and so forth So that's kind of a minimum set now one of the things that I wanted to make sure You had an understanding of how to do is how to use other libraries other than fast AI And so I feel like the best thing to look at is to look at Keras Because Keras is a library just like fast AI sits on top of pytorch Keras sits on top of actually a whole variety of different back ends it fits Mainly people nowadays use it with tensorflow There's also an MX net version. There's also a Microsoft CNTK version So what I've got if you do a git pull you'll see that there's a Something called Keras lesson one where I've attempted to replicate at least parts of lesson one in Keras just To give you a sense of how that works. Yeah I'm not going to talk more about batch norm freeze now other than to say If you're using something Which has got a number larger than 34 at the end so like resnet 50 or res next 101 and you're Trading a data set that has that is very similar to image net so it's like normal photos of normal sizes Where the thing of interest takes up most of the frame then you probably should add the end freeze true after unfreeze If in doubt try trading it with and then try trading it without More advanced students will can certainly talk about it on the forums this week And we will be talking about the details of it in the second half of the course when we come back to our CNN in depth section in the second last lesson So with Keras again, we import a bunch of stuff and Remember I mentioned that this idea that you've got a thing called train and a thing called valid and inside that you've got a thing Called dogs and the things called cats is a standard way of providing image Labeled images so Keras does that too right so it's going to tell it where the training set and the validation set are Twice what batch size to use Now you're noticing Keras we did much much much more code to do the same thing More importantly each part of that code has many many many more things you have to set and if you set them wrong Everything breaks right so I'll give you a summary of what they are so you're basically rather than creating a single Data object in Keras we first of all have to define something called a data generator To say how to generate the data and so a data generator. We basically have to say what kind of data augmentation do we want to do and We also we actually have to say what kind of Normalization Do we want to do so where else with fast AI we just say whatever resnet 50 requires just do that for me Please we actually have to kind of know a little bit about what's expected of us Generally speaking copy and pasting Keras code from the internet is a good way to make sure you've got the right the right stuff to make that work And again, it doesn't have a kind of a standard set of like here are the best data augmentation parameters to use for photos So you know I've copied and pasted all of this from the Keras documentation So I don't know if it's I don't think it's the best set to use at all, but it's the set that they're using in their Docs So having said this is how I want to generate data so horizontally flip sometimes you know zoom sometimes she is sometimes We then create a generator from that by taking that data generator and saying I want to generate Images by looking from a directory and we pass in the directory which is of the same directory structure that fast AI uses and You'll see there's some overlaps with kind of how fast AI works here You tell it what size images you want to create you tell it what batch size you want in your mini batches and Then there's something here not to worry about too much, but basically if you're just got two possible outcomes You would generally say binary here if you've got multiple possible outcomes would say categorical. Yeah, so we've only got cats or dogs So it's binary So an example of like where things get a little more complex is you have to do the same thing for the validation set So it's up to you to create a data generator That doesn't have data orientation because obviously for the validation set unless you're using TTA that's gonna stuff things up you also when you train You randomly reorder the images so that they're always shown in different orders to make it more random but with the validation it's Vital that you don't do that because if you shuffle the validation set you then can't track how well you're doing It's in a different order for the labels. That's a the Basically, these are the kind of steps you have to do every time with Keras So again the reason I was using ResNet 50 for is Keras doesn't have ResNet 34 unfortunately So I just wanted to compare like with like so we've got to use ResNet 50 here There isn't the same idea with Keras of saying like construct a model that is suitable for this data set for me So you have to do it by hand right so the way you do it is to basically say this is my base model and Then you have to construct on top of that manually The layers that you want to add and so by the end of this course you'll understand why it is that these Particular three layers are the layers that we add So having done that in Keras you basically say okay This is my model and then again there isn't like a concept of like automatically freezing things or an API for that So you just have to now loop through the layers that you want to freeze and call dot trainable equals false on them In Keras there's a concept. We don't have in fast AI or pytorch of compiling a model So basically once your model is ready to use you have to compile it Passing in what kind of optimizer to use what kind of loss to look for or what metrics so again with fast AI You don't have to pass this in because we know what loss is the right loss to use you can always override it But for a particular model we give you good defaults Okay, so having done all that Rather than calling fit you call fit generator Passing in those two generators that you saw earlier the train generator and the validation generator for Reasons I don't quite understand Keras expects you to also tell it how many batches there are per epoch So the number of batches is equal to the size of the generator divided by the batch size You can tell it how many epochs? just like in Fast AI you can say how many? Processes or how many workers to use for pre-processing? Unlike fast AI the default in Keras is basically not to use any So you to get good speed you're going to make sure you include this And so that's basically enough to start fine-tuning the last layers So as you can see I got to a validation accuracy of 95% 95% But as you can also see something really weird happened where after one it was like 49 and then it was 69 and then 95 I don't know Why these are so low that's not normal. I may have there may be a bug in Keras. They may be a bug in my code I reached out on Twitter to see if anybody could figure it out, but they couldn't I guess this is one of the challenges with using Something like this is one of the reasons I wanted to use fast AI for this course is it's much harder to screw things up So I don't know if I screwed something up or somebody else did yes, you know This is using the tensorflow back-end yeah, yeah, and if you want to run this to try it out yourself You just can just go pip install tensorflow dash GPU Keras Okay, because it's not part of the fast AI environment by default But that should be all you need to do to get that working So then There isn't a concept of like layer groups or differential learning rates or partial unfreezing or whatever So you have to decide like I had to print out all of the layers and decide manually How many I wanted to fine-tune so I decided to fine-tune everything from a layer 140 onwards So that's why I just look through like this after you change that you have to recompile the model And then after that I then ran another step and again I don't know what happened here the accuracy of the training set stayed about the same but the validation set totally fell in the hole But I mean the main thing to note is even if we put aside the validation set We're getting I mean, I guess the main thing is there's a hell of a lot more code here Which is kind of annoying but also the performance is very different so we're also here even on the training set We were getting like 97 percent after four epochs that took a total of about eight minutes You know over here we had 99.5 percent on the validation set and it ran a lot faster, so it's like four or five minutes right so um Depending on what you do particularly if you end up wanting to deploy stuff to mobile devices at the moment The kind of pie torch on mobile situation is very early So you may find yourself wanting to use tensorflow or you may work for a company that's kind of settled on tensorflow So if you need to convert something like redo something you've learned here in tensorflow You probably want to do it with Keras, but just recognize you know it's going to take a bit more work to get there and By default it's much harder to get I mean I to get the same state-of-the-art results you get with fast AI You'd have to like replicate all of the state-of-the-art Algorithms that are in fast AI so it's hard to get the same Level of results, but you can say the basic ideas are similar Okay, and it's certainly It's certainly possible You know like there's nothing I'm doing in fast AI that like would be impossible but like you would have to implement stochastic gradient descent with restarts you would have to Implement differential learning rates you would have to implement batch norm freezing Which you probably don't want to do I know well that's not quite true I think somewhat one person at least on the forum is Attempting to create a Keras compatible version of or a tensorflow compatible version of fast AI which I think I hope we'll get there I actually spoke to Google about this a few weeks ago, and they're very interested in getting fast AI ported to tensorflow So maybe by the time you're looking at this on the MOOC. Maybe that will exist. I certainly hope so We will see Anyway so Keras is Keras in tensorflow was certainly not You know That difficult to handle and so I don't think you should worry if you're told you have to learn them After this course for some reason it'll only take you a couple of days. I'm sure So that's kind of most of the stuff you would need to Kind of complete this this kind of assignment from last week Which is like try to do everything you've seen already, but on the dog breeds data set And just to remind you The kind of last few minutes of last week's lesson. I show you how to do much of that Including like how I actually explored the data to find out like what the classes were and how big the images were and stuff like that Right so if you've forgotten that or didn't quite follow it all last week check out the video from last week to see One thing that we didn't talk about is how do you actually submit to Kaggle? So how do you actually get predictions? So I just wanted to show you that last piece as well And on the wiki thread this week. I've already put a little image of this to show you these steps But if you go to the Kaggle Website for every competition there's a section called evaluation and they tell you what to submit and so I just copied and pasted these two lines from From there, and so it says we're expected to submit a file where the first line Contains the the word the word ID and then a comma separated list of all of the possible dot breeds And then every line after that will contain the ID itself Followed by all the probabilities of all the different dot breeds so How do you create that? So I recognize that inside our data object. There's a dot classes Which has got in alphabetical order all of the all of the classes? and then So it's got all of the different classes and then inside Data dot test data set test es you can also see there's all the file names So and just to remind you dogs and cats sorry not dogs and cats dog breeds Was not provided in the kind of Keras style format where the dogs and cats were in different folders But instead it was provided as a CSV file of labels right so when you get a CSV file of labels you use image classifier data from the CSV rather than image classifier data from paths There isn't an equivalent in Keras, so you'll see like on the Kaggle forums people Share scripts for how to convert it to a Keras style folders, but in our case We don't have to we just go image classifier data from CSV passing in that CSV file And so the CSV file will you know has automatically told the data rid of what the classes are? And then also we can see from the folder of test images what the file names of those are So with those two pieces of information We're ready to go So I always think it's a good idea to use TTA as you saw with that dogs and cats example Just now it can really improve things particularly when your model is less good So I can say learn dot TTA and if you pass in If you pass in is test equals true Then it's going to give you predictions on the test set rather than the validation set okay, and now obviously we can't now get An accuracy or anything because by definition we don't know the labels for the test set right So by default most Pytorch models give you back the log of the predictions So then we just have to go exp of that to get back our probabilities So in this case the test set had ten thousand three hundred and fifty seven images in it, and there are 120 possible breeds All right, so we get back a matrix of of that size and so we now need to turn that into something that looks like this and So the easiest way to do that is with pandas if you're not familiar with pandas There's lots of information online about it or check out the machine learning course intro to machine learning that we have Where we do lots of stuff with pandas, but basically we can just go PD data frame and pass in that matrix And then we can say the names of the columns are equal to data dot classes And then finally we can insert a new column at position zero called ID that contains the file names But you'll notice that the file names contain Five letters at the end with a start we don't want and four letters at the end. We don't want so I just Subset in like so right so at that point I've got a data frame that looks like this Which is what we want so you can now Call data frame data stuff such a few days DF not DS Let's fix it now Data frame Okay, so you can now call data frame to CSV and Quite often you'll find these files actually get quite big so it's a good idea to say compression equals gzip and that'll zip it up on the server for you and that's going to create a Zipped up CSV file on the server on wherever you're running this Jupiter notebook So you need an app that you now need to get that back to your computer so you can upload it Or you can use kaggle CLA so you can type kg submit and do it that way I've Generally download it to my computer because I like I often like to just like double check it all looks okay So to do that there's a cool little thing called file link and if you run file link With a path on your server it gives you back a URL Which you can click on and it'll download that file from the server onto your computer So if I click on that now I Can go ahead and save it and then I can see in my downloads There it is here's my submission file If you want to open area and As you can see it's exactly what I asked for there's my ID in the hundred and twenty different dog breeds and Then here's my first row containing the file name and the hundred and twenty different probabilities Okay, so then you can go ahead and submit that to kaggle through their Through their regular form and so this is also a good way you can see we've now got a good way of both Grabbing any file off the internet and getting it to our AWS instance or a paper space or whatever by using the Cool little extension in Chrome, and we've also got a way of grabbing stuff off our server easily those of you that are more Command line oriented you can also use SCP of course, but I kind of like doing everything through the notebook All right One other question I had during the week was like what if I want to just get a single single file That I want to you know get a prediction for so for example You know maybe I want to get this first file from my validation set so there's its name So you can always look at a file just by calling image dot open That just uses the regular Python imaging library and So what you can do is there's actually I'll show you the shortest version you can just call learn dot predict array Passing in your your image Okay, now the image needs to have been transformed So you've seen transform transform transforms from model before normally We just put put it all in one variable, but actually behind the scenes it was returning two things It was returning training transforms and validation transforms, so I can actually split them apart And so here you can see I'm actually applying for example my training transforms or probably more likely. I would apply validation transforms That gives me back an array containing the image the transformed image which I can then pass to predict array Everything that gets passed to or returned from our models is generally assumed to be a mini-batch, right? It's generally assumed to be a bunch of images So we'll talk more about some numpy tricks later, but basically in this case We only have one image so we have to turn that into a mini batch of images so in other words We need to create a tensor that basically is not just Rows by columns by channels, but it's number of image by rows by columns by channels and and as one image So it's basically becomes a four-dimensional tensor, so there's a cool little trick in numpy that if you index into an array with none That basically adds additional unit access to the start so it turns it from an image Into a mini batch of one images and so that's why we had to do that So if you basically find you're trying to do things with a single image With any kind of pie torch or fast AI thing this is just something you might you might find it says like expecting four Dimensions only got three probably means that or if you get back a return Value from something that has like some weird first axis. That's probably why it's probably giving you like back a mini-batch Okay, and so we'll learn a lot more about this, but it's just something to be aware of Okay, so that's kind of Everything you need to do in practice So Now we're going to kind of get into a little bit of theory What's actually going on behind the scenes with these convolutional neural networks, and you might remember? Back in lesson one We actually saw Our first little bit of theory Which we stole from this fantastic website, so tosa.io e be explained visually And we learned that a that a convolution is something where we basically have a little matrix in deep learning nearly always three by three a Little matrix that we basically multiply every element of that matrix by every element of a three by three section of an image Add them all together To get the result of that convolution at one point right now Let's see how that all gets turned together to create these These various layers that we saw in the the xyla and burgus paper and to do that again I'm going to steal off somebody who's much smarter than I am We're going to steal from a Guy called a Tavio good a Tavio good was the guy who? Created word lens which nowadays is part of Google Translate if on Google Translate you've ever like done that thing where you Point your camera at something At something with it which has any kind of foreign language on it and in real time it overlays it with a translation That was the Tavio's company that built that And so a Tavio was kind enough to share this fantastic video he created he's at Google now And I want to kind of step you through it because I think it explains really really well What's going on and then after we look at the video? We're going to see how to implement the whole a whole Sequence of combo an entire set of layers of convolutional neural network in Microsoft Excel So with your visual learner or a spreadsheet learner, hopefully you'll be able to understand all this So we're going to start with an image And something that we're going to do later in the course is we're going to learn to recognize digits And we'll do it like end to end we'll do the whole thing so this is pretty similar So we're going to try and recognize in this case letters So here's an a which obviously it's actually a grid of numbers right? And so there's the grid of numbers and so what we do is we take our first Convolutional filter so we're assuming this is always this is assuming that these are already learnt right and you can see this one It's got white down the right hand side right and black down the left So it's like zero zero zero or maybe negative one negative one negative one zero zero zero one one one And so we're taking each three by three part of the image and multiplying it by that three by three Matrix not as a matrix product but an element wise product and so you can see what happens is everywhere where the the white edge is Matching the edge of the a and the black edge isn't we're getting green We're getting a positive and everywhere where it's the opposite we're getting a negative. We're getting a red right and so that's the first filter creating the first The result of the first kernel right and so here's a here's a new kernel This one is is got a white stripe along the top right so we literally scan it through every three by three part of the matrix Modifying those three bits of the a and I bits of the a by the nine bits of that filter to find out whether it's red Or green and how red or green it is okay? And so this is assuming we had two filters one was a bottom edge One was a left edge, and you can see here the top edge not surprisingly It's red here, so a bottom edge was red here and green here the right edge Red here and green here and then in the next step we add a non-linearity Okay, the rectified linear unit which literally means throw away the negatives so here the reds all gone Okay, so here's layer one the input here's layer two the result of two convolutional filters Here's layer three which is which is throw away all of the red stuff And that's called a rectified linear unit and then layer four is something called a max pull and a layer four we replace every two by two Part of this grid and we replace it with its maximum right so it basically makes it half the size It's basically the same thing but half the size and then we can go through and do exactly the same thing we can have some New filter three by three filter that we put through each of the two results of the previous layer Okay And again we can throw away the red bits right so get rid of all the negatives, so we just keep the positives That's called applying a rectified linear unit and That gets us to our next layer of this convolutional neural network So you can see that by you know at this layer back here. It was kind of very interpretable It's like we've either got bottom edges or left edges, but then the next layer was combining The results of convolution so it's starting to become a lot less clear like intuitively what's happening But it's doing the same thing and then we do another max pull right so we replace every two by two or three by three Section with a single digit so here this two by two. It's all black so we replaced it with a black All right, and then we go and we take that and we we compare it To basically a kind of a template of what we would expect to see if it was an a it was a B It was a C It was D and we see how closely it matches and we can do it in exactly the same way we can multiply Every one of the values in this or by eight Matrix with every one of the four by eight in this one and this one and this one and we add we just add them Together to say like how often does it match versus? How often does it not match and then that could be converted to give us a percentage? image probability that this is an a so in this case this particular template matched well with a So notice we're not doing any training here right this is how it would work if we have a pre-trained model All right So when we download a pre-trained image net model off the internet and is it on an image without any changing to it? This is what's happening Or if we take a model that you've trained and you're applying it to some test set or to some new image This is what it's doing right is it's basically taking it through its applying a convolution to each layer to each multiple convolutional filters to each layer and then Doing the rectified linear unit so throw away the negatives and then do the max pull And then repeat that a bunch of times and so then we can do it with a new letter a or letter B or whatever and keep going through that process So as you can see that's far nicer visualization thing and I could have created because I'm not a table So thanks to him for for sharing this with us because it's totally awesome He actually this is not done by hand. He actually wrote a piece of computer software to actually do these convolutions This is actually being actually being done dynamically. It's pretty cool So I'm more of a spreadsheet guy personally. I'm a simple person So here is the same thing now in spreadsheet form right and so you'll find this in the github repo so you can either Get clone the repo to your own computer to open up the spreadsheet or you can just go to github.com fast AI and Click on this it sits inside If you go to my repo And just go to courses as usual go to deal one as usual you'll see there's an Excel section there Okay, and so here they all are so you can just download them by clicking them or you can clone the whole repo and we're looking at conv example convolution example, right so you can see I have here an Input right so in this case the input is the number seven so I grabbed this from a data set called M list M and IST which we'll be looking at in a lot of detail And I just took one of those digits at random and I put it into Excel and so you can see every Pixel is actually just a number between naught and one Okay, very often actually it'll be a Byte between naught and 255 Or sometimes it might be a float between naught and one it doesn't really matter by the time it gets to pie torch We're generally dealing with floats So we if one of the steps we often will take will be to convert it to a number between naught and one So then you can see I've just used conditional formatting in Excel to kind of make the higher numbers more red So you can clearly see that this is a red that this is a seven But but it's just a bunch of numbers that have been imported into Excel. Okay, so here's our input So remember what a table you did was he then applied two filters right with different shapes So here I've created a filter which is designed to detect top edges So this is a three by three filter Okay, and I've got ones along the top zeros in the middle minus ones at the bottom, right? So let's take a look at an example that's here, right? And so if I hit F2 you can see here highlighted This is the three by three part of the input that this particular thing is calculating, right? so here you can see it's got one one one are all being multiplied by one and Point one zero zero are all being multiplied by negative one Okay, so in other words all the positive bits are getting a lot of positive the negative bits are getting really nearly nothing at all So we end up with a high number Okay, where else on the other side of this bit of the seven? Right you can see how you know this is basically zeros here or perhaps more interestingly on the top of it, right? Here we've got High numbers at the top, but we've also got high numbers at the bottom which are negating it Okay, so you can see that the only place that we end up Activating is Where we're actually at an edge Okay So in this case this here this number three This is called an activation Okay, so when I say an activation, I mean a number a number a Number that is calculated and it is calculated by taking some numbers from the input and Applying some kind of linear operation in this case a convolutional kernel to calculate an output Right you'll notice that other than going inputs multiplied by kernel and Summing it together All right, so here's my sum and here's my multiply. I then take that and I go max of zero comma that And so that's my rectified linear unit. So it sounds very fancy Rectified linear unit, but what they actually mean is open up Excel and type equals max zero comma thing. Okay That's all around then you'll see people in the biz still to say rally you okay, so rally you means Rectified linear unit means max zero comma thing and I'm not like simplifying it I really mean it like when I say like if I'm simplifying I'll always say I'm simplifying But if I'm not saying I'm simplifying that's the entirety. Okay, so a rectified linear unit in its entirety is this and a convolution in its entirety is Is this? Okay, so a single layer of a convolutional neural network is being implemented in its entirety Here in Excel, okay, and so you can see what it's done is it's deleted Pretty much the vertical edges and highlighted the horizontal edges so again, this is assuming that our network is trained and That at the end of training it had created a convolutional filter with these specific nine numbers in And so here is a second convolutional filter It's just a different nine numbers Now pi torch doesn't store them as two separate nine digit arrays It stores it as a tensor. Remember a tensor just means an array with More dimensions. Okay, you can use the word array as well It's the same thing but in pi torch. They always use the word tensor. So I'm going to say tensor Okay, so it's just a tensor with an additional axis which allows us to stack Each of these filters together, right a filter and kernel Pretty much mean the same thing. Yeah, right. It refers to one of these three by three Matrices or one of these three by three slices of a three-dimensional tensor So if I take this one and here I've literally just copied the formulas in Excel from above Okay And so you can see this one is now finding a vertical edge as we would expect Okay, so We've now created One Layer right this here is a layer and specifically we'd say it's a hidden layer Which is it's not an input layer and it's not an output layer. So everything else is a hidden layer Okay, and this particular hidden layer has is A size two on this dimension, right because it has two Filters right two kernels So what happens next Well Let's do another one. Okay. So as we kind of go along things can Multiply a little bit in complexity right because my next filter is going to have to contain Two of these three by threes because I'm going to have to say how do I want to bring how do I want to? Wait these three things and at the same time How do I want to wait the corresponding three things down here? But because in pytorch this is going to be this whole thing here is going to be stored as a As a multi-dimensional tensor right so you shouldn't really think of this now as two three by three kernels but one two by three by three kernel Okay, so to calculate this value here I've got the sum product of all of that plus the sum product of Let's scroll down all of that Okay, and So the top ones are being multiplied by this part of the kernel and the bottom ones are being multiplied by this part of the Kernel and so over time You want to start to get very comfortable with the idea of these like higher dimensional? linear combinations Right like it's it's harder to draw it on the screen like I had to put one above the other But conceptually just stack it in your mind like this. That's really how you want to think Right and actually Jeffrey Hinton in his original 2012 neural nets Coursera class has a tip which is how all computer scientists deal with like very high dimensional spaces Which is that they basically just visualize the two-dimensional space and then say like 12 dimensions really fast in their head lots of times So that's it right we can see two dimensions on the screen, and then you just got a try to trust That you can have more dimensions like the concepts Just you know there's there's nothing different about them and so you can see in Excel You know Excel doesn't have the ability to handle three dimensional tensors, so I had to like say okay take this two-dimensional Dot product add on this two-dimensional dot product right, but if there was some kind of 3d Excel I could have just done that in a single formula right and then again apply Max zero comma otherwise known as rectified linear unit otherwise known as reality okay, so here is My second layer and so when people create different architectures right and architecture means Like how big is your kernel at layer one how many filters are in your kernel at layer one so here? I've got a three by three Where's number one and a three by three there's number two so like this? Architecture I've created starts off with two three by three convolutional kernels and then my Second layer has another two kernels of size two by three by three So there's the first one and then down here is the second two by three by three kernel okay, and so Remember one of these specific where any one of these numbers is an activation Okay, so this activation is being calculated from these three things here another three things up there And we're using these this two by three by three kernel okay And so what tends to happen is people generally give names to their layers, so I say okay Let's call this layer here cons one and this layer here and this and This layer here Conv two right so that's you know generally you'll just see that like when you print out a summary Of a network every layer will have some kind of name okay, and so then what happens next? Well part of the architecture is like do you have some max pooling whereabouts is that max pooling happens? So in this architecture, we're inventing we're going to next step is to max pooling Okay max pooling is a little hard to Kind of show in Excel, but we've got it So max pooling if I do a two by two max pooling It's going to have the resolution both height and width So you can see here that I've replaced These four numbers With the maximum of those four numbers Right and so because I'm having the resolution it only makes sense to actually have something every two cells Okay, so you can see here the way. I've got kind of the same Looking shape as I had back here, okay, but it's now half the resolution because I've replaced every two by two With its max and you'll notice like it's not every possible two by two I skip over from here So this is like starting at BQ and then the next one starts at BS Right so they're like non overlapping. That's why it's decreasing the resolution Okay, so anybody who's comfortable with spreadsheets You know you can open this and have a look and so after our max pooling There's a number of different things we could do next and I'm going to show you a kind of Classic old style approach nowadays in fact what generally happens nowadays is we do a max pool where we kind of like max Across the entire size right? But on older architectures and also on all the structured data stuff we do We actually do something called a fully connected layer, and so here's a fully connected layer I'm going to take every single one of these activations and I'm going to give every single one of them a weight Right and so then I'm going to take over here Here is the sum product of every one of the activations by every one of the weights for both of the Two Levels of my three-dimensional tensor right and so this is called a fully connected layer notice. It's different to a convolution I'm not going through a few at a time right, but I'm creating a really big weight matrix Right so rather than having a couple of little three by three kernels my weight matrix is now as big as the entire input And so as you can imagine Architectures that make heavy use of fully convolutional layers can have a lot of weights Which means they can have trouble with overfitting and they can also be slow and so you're going to see a lot An architecture called VGG because it was the first kind of successful deeper architecture It has up to 19 layers and VGG Actually contains a fully connected layer with 4096 weights Connected to a hidden layer with 4000 sorry 4096 Activations connected to a hidden layer with 4096 activations, so you've got like 4096 by 4096 6096 multiplied by remember multiplied by the number of kind of kernels that we have calculated so in VGG There's This I think it's like 300 million Weights of which something like 250 million of them are in these fully connected layers So we'll learn later on in the course about how we can kind of avoid using these big fully connected layers and behind the scenes All the stuff that you've seen us using like resnet and res next none of them use very large fully connected layers You know you had a question So can you tell us more about for example if we had like three channels of the input what would be the The shape yeah these filters right so that's a great question So if we had three channels of input it would look exactly like con one right con one kind of has two channels Right and so you can see with con one we had two channels so therefore our filters had to have like two channels per filter and so you could like Imagine that this input didn't exist you know and actually this was the input right so when you have a multi-channel input It just means that your filters look like this and so images often For color they have three red green and blue sometimes they also have an alpha channel So however many you have that's how many inputs you need and so something which I know You know that was playing with recently was like using a full color image net model In medical imaging for something called bone age calculations Which has a single channel and so what she did was basically take the the input The single channel input and make three copies of it So you end up with basically like one two three versions of the same thing which is like It's kind of it's not ideal like it's kind of redundant information that we don't quite want But it does mean that then if you had a something that expected a three channel Convolution or filter you can use it right and so at the moment There's a Kaggle competition for iceberg detection using Some funky satellite specific data format that has two channels So here's how you could do that you could Either copy one of those two channels into the third channel Or I think what people on Kaggle are doing is to take the average of the two Again, it's not ideal, but it's a way that you can use pre-trained networks Yeah, I've done a lot of Fiddling around like that you can also actually I've actually done things where I wanted to use a Three channel image net network on four channel data. I had satellite data where the fourth channel was near infrared And so basically I added an extra Kind of Level to my convolutional kernels that were all zeros and so basically like started off by ignoring the new infrared band And so what happens it basically and you'll see this next week is that? Rather than having these like carefully trained filters when you're actually training something from scratch We're actually going to start with random numbers That's actually what we do We actually start with random numbers and then we use this thing called stochastic gradient descent Which we've kind of seen conceptually to slightly improve those random numbers to make them less random And we basically do that again and again and again Okay, great. Let's take a seven minute break and we'll come back at 750 All right, so what happens next so we've got as far as Doing a Fully connected layer right so we had our the results of our max pooling layer got fed to a fully connected layer And you might notice those of you that remember your linear algebra The fully connected layer is actually doing a classic traditional matrix product Okay, so it's basically just going through each pair in turn multiplying them together and then adding them up to do a matrix product Now In practice if we want to Calculate which one of the ten digits we're looking at This single number we've calculated isn't enough We would actually calculate ten numbers so what we would have is rather than just having one set of fully connected weights like this and I say set because remember there's like a whole 3d kind of tensor of them we would actually need ten of those Right so you can see that these tensors start to get a little bit High dimensional right and so this is where my patients with doing it in Excel ran out But imagine that I had done this ten times I could now have ten Different numbers all being calculated here using exactly the same process right it just be ten of these fully connected To by and by and Arise basically and So then we would have ten numbers being spat out so what happens next? So next up we can open up a different Excel worksheet entropy example dot XLS that's got two different Worksheets one of them is called softmax And what happens here? I'm sorry I've changed domains rather than predicting whether it's the number from one to naught to nine I'm going to predict whether something is a cat a dog a plane a fish or building okay So out of our that fully connected layer We've got in this case. We'd have five numbers and notice at this point There's no value okay, and then last layer. There's no value okay, so I can have negatives Okay, so I want to turn these five numbers Each into a probability. I want to turn it into a probability from naught to one that it's a cat That it's a dog that it's a plane that it's a fish that it's a building and I want those probabilities to have a couple of characteristics first is that each of them should be between zero and one and The second is that they should they together should add up to one right? It's definitely one of these five things Okay, so to do that. We use a different kind of activation function What's an activation function an? Activation function is a function that is applied to activations so for example max zero comma Something is a function that I applied to an activation for an activation function always takes in One number and spits out one number so max of zero comma X Takes in a number X and spits out some different number rather you have X That's all an activation function is and if you remember back to that PowerPoint we saw in lesson one Each of our layers was just a linear function and then after every layer We said we needed some non-linearity right because if you stack a bunch of Linear layers together right then all you end up with is a linear layer right So somebody's talking can can you not I'm slightly distracting. Thank you If you stack a number of linear Functions together you just end up with a linear function And nobody does any cool deep learning with just linear functions right, but you remember we also learned That by stacking linear functions With between each one a non-linearity we could create like arbitrarily complex shapes and so the non-linearity that we're using after every hidden layer is a relu rectified linear unit a non-linearity is an activation function an Activation function is a non-linearity in Within deep learning obviously there's lots of other non-linearities in the world, but in deep learning This is what we mean so an activation function is any function that takes some activation in That's a single number and spits out some new activation like max of zero comma So I'm now going to tell you about a different activation function. It's slightly more complicated than Than relu, but not too much. It's called softmax Softmax only ever occurs in the final layer at the very end and the reason why is that softmax always spits out numbers as an activation function that always spits out a number between naught and one and It always spits out a bunch of numbers that add to one So a softmax gives us what we want right in theory This isn't strictly necessary right like we could ask our neural net to learn a set of kernels Which have you know which which give probabilities that line up as closely as possible with what we want But in general with deep learning if you can construct your architecture so that the desired Characteristics are as easy to express as possible You'll end up with better models like they'll learn more quickly with less parameters So in this case we know that our probabilities should end up being between naught and one We know that they should end up adding to one So if we construct an activation function which always has those features Then we're going to make our neural network do a better job. It's going to make it easier for it It doesn't have to learn to do those things because it all happened automatically Automatically okay, so in order to make this work We first of all have to get rid of all of the negatives Right like we can't have negative probabilities So to make things not be negative one way we could do it is just go a to the power of Right so here you can see my first step is to go X of the previous one right, and I think I've mentioned this before but of All the math that you just need to be super familiar with to do deep learning The one you really need is logarithms and X's right all of deep learning and all of machine learning they appear all the time right, so For example You absolutely need to know that log of X times Y equals log of X plus log of Y Right and like not just know that that's a formula that exists, but have a sense of like what does that mean? Why is that interesting? Oh, I can turn multiplications into additions that could be really handy right and therefore log of X over Y equals log of X minus log of Y Again that's going to come in pretty handy. You know rather than dividing I can just subtract things right and also remember that If I've got log of X equals Y Then that means a to the Y Equals X in other words log Log and a to the are the inverse of each other Okay again, you just you need to really really understand these things and like so if you if you haven't spent much time with logs And X for a while Try plotting them in Excel or a notebook have a sense of what shape they are how they combine together Just make sure you're really comfortable with them, so We're using it here, right? We're using it here, so one of the things that we know is a to the power of something is positive Okay, so that's great the other thing you'll notice about a to the power of something is because it's a power Numbers that are slightly bigger than other numbers like 4 is a little bit bigger than 2.8 When you go a to the power of it really accentuates that difference Okay, so we're going to take advantage of both of these features for the purpose of deep learning okay, so we take our the Results of this fully connected layer we go a to the power of for each of them and Then we're going to And then we're going to add them up Okay, so here is the sum of a to the power of so then here We're going to take a to the power of divided by the sum of a to the power of so if you take All of these things divided by their sum then by definition all of those things must add up to one and Furthermore since we're dividing by their sum They must always vary between 0 and 1 because they are always positive alright, and that's it so that's what softmax is Okay, so I've got this kind of doing random numbers each time right and so you can see like as I as I look through My softmax generally has quite a few things that are so close to zero that they round down to zero and you know Maybe one thing that's nearly one right and the reason for that is what we just talked about that is with the X Just having one number a bit bigger than the others tends to like push it out further Right so even though my inputs here are random numbers between negative 5 and 5 Right my outputs from the softmax don't really look that random at all in the sense that They tend to have one big number and a bunch of small numbers And now that's what we want Right we want to say like in terms of like is this a cat dog a plane a fish or a building We really wanted to say like it's it's that you know it's it's a dog or it's a plane not like I don't know Okay, so softmax has lots of these cool Properties right it's going to return a probability that adds up to one and it's going to tend to want to pick one thing particularly strongly Okay, so that's softmax your net could you pass actually bust me up? We How would we do something that has let's say you have an image and you want to categorize as like cat and the dog or Like has multiple things What what kind of function would we try to use? So happens we're going to do that right now so So how to think about why we might want to do that and so one reason we might want to do that is to do multi-label cat classification, so we're looking now at less than two image models and specifically we're going to take a look at the planet competition satellite imaging competition Now the satellite imaging competition has Some similarities to stuff we've seen before right so before we've seen cat versus dog and these images are a cat or a dog They're not neither. They're not both right, but the satellite imaging competition Has stayed as images that look like this and in fact every single one of the images is classified by weather There's four kinds of weather one of which is haze and another of which is clear in Addition to which there is a list of features that may be present including agriculture Which is like some some cleared area used for agriculture? Primary which means primary rainforest and water which means a river or a creek so here is a clear day satellite image showing some agriculture some primary rainforest and some water features and Here's one which is in haze and is entirely primary rainforest So in this case, we're going to want to be able to show We're going to be able to predict multiple things and so softmax wouldn't be good because softmax doesn't like predicting multiple things and like I would definitely recommend anthropomorphizing your activation functions Right they have personalities. Okay, and the personality of the softmax is it wants to pick a thing Okay, and people forget this all the time. I've seen many people even well regarded researchers in famous academic papers Using like softmax for multi-label classification it happens all the time right And it's kind of ridiculous because they're not understanding the personality of their activation function, so For multi-label classification where each sample can belong to one or more classes we have to change a few things But here's the good news in fast AI. We don't have to change anything Right so fast AI will look at the labels in the CSP and if there is more than one label ever for any Item it will automatically switch into like multi-label mode So I'm going to show you how it works behind the scenes, but the good news is you don't actually have to care All right, it happens anyway so if you have multi-label Images multi-label objects you obviously can't use the classic keras style approach where things are in folders Because something can't conveniently be in multiple folders at the same time right, so that's why we you basically have to use the from CSV The approach right so if we look at an example Actually, I'll show you I tend to take you through it right so we can say okay This is the CSV file containing our labels this looks exactly the same as it did before but rather than side on it's top-down Right and top-down. I've mentioned before that can do a vertical flips it actually does more than that there's actually eight possible symmetries for a square Which is it can be rotated through? 90 180 270 or zero degrees and for each of those it can be flipped and if you think about it for a while You'll realize that that's a complete Enumeration of everything that you can do In terms of symmetries to a square so they're called. It's called the dihedral group of eight So if you see in the code, there's actually a transform called dihedral. That's why it's called that So this transforms will basically do the full set of eight symmetric dihedral rotations and flips Plus everything which we can do to dogs and cats you know small 10 degree rotations a little bit of zooming Little bit of contrast and brightness adjustment So these images are a size 256 by 256, so I just created a little function here to let me quickly grab You know a data loader of any size, so here's a 256 by 256 Once you've got a data object Inside it we've already seen that there's things called Val DS test DS train DS They're things that you can just index into and grab a particular image, so you can just use square brackets zero You'll also see that all of those things have a DL. That's a data loader So DS is data set DL is data loader these are concepts from pytorch So if you google pytorch data set or pytorch data loader you can basically see what it means But the basic idea is a data set gives you a single image or a single object back at data loader gives you back a mini-batch and Specifically it gives you back a transformed mini-batch so that's why when we create our data object we can pass in num workers and Transforms like how many processes do you want to use what transforms do you want and so with a data loader? You can't ask for an individual image You can only get back at a mini-batch and you can't get that back a particular mini-batch You can only get back the next mini-batch so something we risk is loop through grabbing a mini-batch at a time and so in Python The thing that does that is called a generator Right or an iterator there's slightly different versions of the same thing So to turn a data loader into an iterator you use the standard Python function called itta That's a Python function just a regular part of the Python Basic language that returns to an iterator and an iterator is something that takes you can pass the static give pass it to the standard Python Function or statement next and that just says give me another batch from this iterator So we're basically this is one of the things I really like about pytorch is it really leverages Modern pythons kind of stuff you know in in tensorflow they invent their whole new world of ways of doing things And so it's kind of more In a sense it's more like cross-platform, but in another sense like it's not a good fit to any platform So it's nice if you if you know Python well PyTorch comes very naturally if you don't know Python well PyTorch is a good reason to learn Python well a PyTorch near a module neural network module is a standard Python bus for example So any work you put into learning Python better will pay off with PyTorch so here. I am using standard Python iterators and next to grab my next mini batch From the validation sets data loader, and that's going to return two things It's going to return the images in the mini batch and the labels in the mini batch So standard Python approach I can pull them apart like so and so here is one mini batch of labels and so not surprisingly since I said that my batch size Oh actually, it's the batch size by default is 64, so I didn't pass in a batch size And so just remember shift tab to see like what are the things you can pass and what are the defaults so by default? My batch size is 64, so I've got back something of size 64 by 17 so there are 17 of the possible classes right So let's take a look at the zeroes Set of labels so the zeroes images labels So I can zip again standard Python things it takes two lists and combines It's they get the zero thing from the first list the zero thing from the second list And the first thing from the first first this first thing from the second list and so forth So I can zip them together and that way I can find out For the zero image in the validation set its agriculture It's clear Its primary rainforest its slash and burn its water Okay, so as you can see here. This is a multi-label You see here's a way to do multi-label classification So by the same token right if we go back to our single label classification It's a cat dog playing fish or building Behind the scenes we haven't actually looked at it, but behind the scenes Fast AI and pie torch are turning our labels into something called one hot Encoded labels and so if it was actually a dog then the actual values Would be like that right so these are like the actuals Okay, so do you remember at the very end of a Tavio's video? He showed how like the template had to match to one of the like five a b c d or e templates And so what it's actually doing is it's comparing When I said it's basically doing a dot product it's actually a fully connected layer at the end right that calculates an output activation that goes through a soft max and then the soft max is compared to The one hot encoded label right so if it was a dog there would be a one here and Then we take the difference between the actuals and the soft max Activations to say and add those add up those differences to say how much error is there essentially And we're skipping over something called a loss function that we'll learn about next week, but essentially we're basically doing that Now if it's one hot encoded like there's only one thing which have a one in it then actually storing it as 0 1 0 0 0 is terribly inefficient Right like we could basically say what are the index of each of these things? Right so we can say it's like 0 1 2 3 4 Like so right and so rather than storing it as 0 1 0 0 0 We actually just store the index value Right so if you look at the the y values for the cats and dogs competition or the dog breeds competition You won't actually see a big lists of ones and zeros like this. You'll see a single integer Right which is like what's what class index is it right and internally? Inside PyTorch it will actually turn that into a one hot encoded vector, but like you will literally never see it Okay, and and PyTorch has different loss functions where you basically say this thing's one This thing is one hot encoded or this thing is not and it uses different boss functions That's all hidden by the fast AI library Right so like you don't have to worry about it But it's but the the cool thing to realize is that this approach for multi-label encoding with these ones and zeros Behind the scenes the exact same thing happens for single level classification Does it make sense to change the peakiness of the sigmoid of the softmax function by changing the base um No, because when you change the more math Log base a of B equals log B over log a so changing the base is just a linear scaling and Linear scaling is something which the neural net can learn with that very easily Good question Okay, so here is that image right here is the image with slash and burn water etc etc One of the things to notice here is like when I first displayed this image it was So Washed out I really couldn't see it right but remember images Now you know we know images are just Matrices of numbers and so you can see here. I just said times 1.4 Just to make it more visible right so like now that you're kind of it's the kind of thing I want you to get familiar with is the idea that this stuff you're dealing with they're just matrices of numbers Then you can fiddle around with them so if you're looking at something you're like oh, it's a bit washed out You can just multiply it by something to Brighten it up a bit. Okay, so here we can see I guess this is the slash and burn Here's the river. That's the water. Here's the primary rainforest. Maybe that's the agriculture and so forth. Okay, so So, you know with all that background How do we actually use this? Exactly the same way as everything we've done before right so you know size and and The interesting thing about playing around with this planet competition is that these images are not at all like image net and I Would guess that the vast majority of the stuff that the vast majority of you do involving convolutional neural nets Won't actually be anything like image net, you know it'll be it'll be medical imaging or it'll be like classifying different kinds of steel tube or figuring out whether a world you know is going to break or not or Looking at satellite images or you know, whatever, right? So It's it's good to experiment with stuff like this planet Competition to get a sense of kind of what you want to do and so you'll see here I start out by resizing my data to 64 by 64 it starts out at 256 by 256 Right now I wouldn't want to do this for the cats and dogs competition because the cats and dogs competition We start with a pre-trained image net network. It's it's nearly it's it starts off nearly perfect Right, so if we resized everything to 64 by 64 and then retrained the whole set We basically destroy the weights That are already pre trained to be very good remember image net most image net models are trained at either 224 by 224 or 299 by 299 right? So if we like retrain them at 64 by 64, we're gonna we're gonna kill it on the other hand There's nothing in image net that looks at anything like this You know, there's no satellite images So the only useful bits of the image net network for us are kind of Layers like this one, you know finding edges and gradients and this one, you know finding kind of textures and repeating patterns And maybe these ones are kind of finding more complex textures, but that's probably about it Right. So so in other words You know Starting out by training very small images Works pretty well when you're using stuff like satellites. So in this case, I started right back at 64 by 64 Grab some data Built my model Found out what learning rate to use Interestingly, it turned out to be quite high it Seems that because like it's so unlike image net I I needed to do quite a bit more fitting of just that last layer before it started to flatten out Then I unfreezed it and again, this is the difference to image net like Datasets is my learning rate in the initial layer. I set to divided by 9 the middle layers I set to divided by 3 where else to stuff like it's like image net. I had a multiple of 10 For each of those, you know again the idea being that the earlier layers Probably are not as close to what they need to be compared to the image net like datasets Again unfreeze train for a while And you can kind of see here, you know, there's cycle one. There's cycle two. There's cycle three And then I kind of increased double the size of my images Fit for a while unfreeze fit for a while double the size of the images again fit for a while unfreeze fit for a while And then add TTA and so as I mentioned last time we looked at this this process ends up You know getting us about 30th place in this competition Which is really cool because people you know a lot of very very smart people just a few months ago Worked very very hard on this competition A Couple of things people have asked about one is What is this data dot resize do so a Couple of different pieces here. The first is that when we say Back here What transforms do we apply and here's our transforms we actually pass in a size, right? So one of the things that one of the things that data loaded does is to resize the images like on demand every time it sees them This has got nothing to do with that dot resize method, right? So this is this is the thing that happens at the end like whatever's passed in before it hits out before our data loaders fits It out. It's going to resize it to this size if the initial input is like a thousand by a thousand Reading that jpeg and resizing it to 64 by 64 Turns out to actually take more time than training the confident dots for each batch Right. So basically all resize does is it says hey I'm not going to be using any images bigger than size times 1.3 So just go through once and create new jpegs of this size Right and and they're rectangular right so new jpegs were the smallest Edges of this size and again, it's like you never have to do this There's no reason to ever use it if you don't want to it's just a speed up Okay, but if you've got really big images coming in it saves you a lot of time and you'll often see on like Kaggle kernels or forum posts or whatever people will have like bash scripts stuff like that to like loop through and resize images to save time you never have to do that right just you can Just say dot resize and it'll just Create you know once off it'll go through and create that if it's already there It'll use the resized ones for you. Okay, so it's just it's just a Speed up convenience function no more Okay So for those of you that are kind of past dog breeds I Would be looking at planet next you know like try like play around with With trying to get a sense of like how can you get this as an accurate model? One thing to mention and I'm not really going to go into it in detail There's nothing to do with deep learning particularly is that I'm using a different metric I didn't use metrics equals accuracy, but I said metrics equals f2 Just remember from last week that confusion matrix that like two by two you know Correct incorrect for each of dogs and cats There's a lot of different ways you could turn that confusion matrix into a score You know do you care more about false negatives? Or do you care more about false positives, and how do you weight them, and how do you combine them together right? There's a base. There's basically a function called f beta Where the beta says how much do you weight false negatives versus false positives and so f2 is? F beta with beta equals 2 and it's basically as particular way of waiting false negatives and false positives And the reason we use it is because cattle told us that planet who were running this competition Wanted to use this particular? F beta metric The important thing for you to know is that you can create Custom metrics so in this case you can see here It says from planet import f2 and really I've got this here so that you can see how to do it right so if you look inside Courses deal one You can see there's something called planet dot py right and so if I look at planet dot py You'll see there's a function there called F2 right and so f2 simply calls f beta score from psychic Or sci-pi and can't remember where it came from And does a couple little tweaks that are particularly important but The important thing is like you can write any metric you like right as long as it takes in set of predictions and A set of targets and they're both going to be numpy arrays one dimensional numpy arrays, and then you return back a number Okay, and so as you create a function that takes two Vectors and returns art number you can call it as a metric and so then when we said Learn metrics equals and then passed in that array which just contains a single function f2 Then it's just going to be printed out after every epoch for you Okay, so in general like the the fast AI library everything is customizable so kind of the idea is that everything is Everything is Kind of gives you what you might want by default, but also everything can be changed as well Yes, you know We have a little bit of confusion about the difference between multi-label To single label uh-huh do you buy any chance an example in which you compute? similarly to the example of the You just show us oh I didn't get to that activation function. Yeah, so So I'm so sorry. I said I'd do that and then I didn't so the activation the output activation function for single label Classification is softmax for all the reasons that we talked about but If we were trying to predict something that was like zero zero one one zero Then softmax would be a terrible choice because it's very hard to come up with something where both of these are high in fact It's impossible because they have to add up to one so the closest they could be would be point five so for multi-label classification Activation function is called Sigmoid okay and again the fast AI library does this automatically for you if it notices you have a multi-label Problem and it does that by checking your data set to see if anything has more than one label applied to it and so sigmoid is a function which is equal to It's basically the same thing Except rather than we never add up All of these X's but instead we just take this X when we say it's just equal to it divided by one plus It And so the nice thing about that is that now like multiple things can be high at once right And so generally then if something is less than zero its sigmoid is going to be less than point five If it's greater than zero its sigmoid is going to be greater than point five And so the important thing to know about a sigmoid function is that its shape is Something which Asymptotes at the top to one and asymptotes. Oh, I drew that as Some totes at the bottom To zero and so therefore it's a good thing to model a probability with Anybody who has done any? logistic regression Will be familiar with this. It's what we do in logistic regression So it kind of appears everywhere in machine learning and you'll see that kind of a sigmoid and a softmax. They're very close To each other Conceptually, but this is what we want is our activation function for multi-label And this is what we want the single label and again fast AI does it all for you. There was a question over here. Yes I have a question about the initial training that you do if I understand correctly you have we have frozen the The pre-trained model and you only need initially try to train the latest Layer right, right But from the other hand we said that only the initial layer So let's last probably the first layer Is like important to us and the other two are more like features that are image net related and we didn't apply in this case What's that they? The layers are very important But the pre-trained weights in them aren't so it's the later layers that we really want to train the most So earlier layers Like me to be like already Closer to the initial layers Me to be like already closer to what we want Okay, so you start with the latest one and then you go right so if you go back to our quick dogs and cats right? When we create a model from pre-trained from a pre-trained model it returns something where all of the convolutional layers are frozen and some randomly set Fully connected layers we add to the end Unfrozen and so when we go fit at first it just trains The randomly set a randomly initialized fully connected layers right and If something is like really close to image net that's often all we need right because the other layer layers are already Good at finding edges gradients repeating patterns for Ears and dog's heads, you know So Then when we unfreeze We set the learning rates for the early layers to be really low Because we don't want to change them much for us the later ones we set them to be higher Where else for satellite data? right This is no longer true. You know the early layers are still like Better than the later layers, but we still probably need to change them quite a bit So that's right. This learning rate is nine times smaller than the final learning rate rather than a thousand times smaller Yeah, normally Most of the stuff you see online if they talk about this at all they'll talk about unfreezing different subsets of layers And indeed we do unfreeze our randomly generated ones But what I found is although the fast AI library you can type learned up freeze to and just freeze a subset of layers this approach of using differential learning rates seems to be like More flexible to the point that I never find myself unfreezing subsets of layers So but what I didn't understand is that I would expect you to start with that with a differential the different Learning rates rather than trying to learn the last layer. So the reason okay, so you could skip this Training just the last layers and just go straight to differential learning rates But you probably don't want to the reason you probably don't want to is that there's a difference the convolutional layers all contain Pre-trained weights, so they're like they're not random for things that are close to image net They're actually really good for things that are not close to image net. They're better than nothing All of our fully connected layers, however are totally random So therefore you would always want to make the fully connected weights better than random by training them a bit first Because otherwise if you go straight to unfreeze Then you're actually going to be like Fiddling around to those early early can early layer weights when the later ones are still random. That's probably not what you want. I Think there's another question here So when we unfreeze What are the things? We're trying to change there when it changed the kernels themselves or That that's always what SGD does. Yeah, so the only thing What training means is? setting these numbers right and These numbers and These numbers the weights so the weights are the weights of the fully connected layers and The weights in those kernels in the convolution, so that's what training means It's and we'll learn about how to do it with SGD, but training literally is setting those numbers These numbers on the other hand Activations they're calculated. They're calculated from the weights and the previous layers activations or inputs I have a question so can you lift it up higher and speak about it? So in your example of a training a satellite image Examples are you starting with very small size access before yeah So does it literally mean that you know the model takes a small area from the entire image that is 64 by 64? So how do we get that 64 by 64 depends on? the transforms by default our transform takes the smallest edge and Resight zooms the whole thing out resamples it so the smallest edge is the size 64 and then it takes a center crop of that okay, although When we're using data augmentation it actually takes a randomly chosen crop But in the case where the image has multiple objects like in this case like Would it be possible like you would just lose the other things that I tried to forget yeah Which is why data augmentation is important so by and particularly their Test time augmentation is going to be particularly important because you would you wouldn't want to you know that there may be a Artisanal mine out in the corner which if you take a center crop you you don't see so data augmentation becomes very important Yeah One other question so So when we talk about metrics like either is our here see the floor or f2 That's not really what the model tries to that's a great point. That's not the loss function Yeah, right the loss function is something. We'll be learning about next week And it uses cross entropy or otherwise known as like negative log likelihood The metric is just the thing that's printed so we can see what's going on just next year So in the context of multi class Modeling cannot training data does a training data also have to be multiclass or can I train on just like images of pure cats and pure dogs and expect it at prediction time to Predict if I give it a picture of both having cat and a dog I've never tried that and I've never seen an example of something that needed it I Guess conceptually there's no reason it wouldn't work But it's kind of out there And you still use a sigmoid activation you would have to make sure you're using a sigmoid loss function So in this case fast AI's default would not work because by default fast I would say your training data never has both a cat and a dog so you would have to override the loss function When you use the differential learning rates Those three learning rates do they just kind of spread evenly across the layers Yeah, we'll talk more about this later in the course, but I'm in the fast AI library There's a concept of layer groups so in something like a resonant 50 You know there's hundreds of layers, and I figured you don't want to write down hundreds of learning rates, so I've basically decided for you how to split them and the the last one always refers just to the Fully connected layers that we've randomly initialized and added to the end and then these ones are split generally about halfway through to basically I've tried to make it so that these you know these ones are kind of the ones which you hardly want to change at all and these are the ones you might want to change a little bit and I don't think we'll cover it in the course But if you're interested we can talk about in the forum there are ways you can override this behavior to define your own way Of groups if you want to and is there any way to visualize the model easily or like dump dump the layers of the model? Yeah, absolutely You can let's make sure we've got one here Okay So if you just type learn it doesn't tell you much at all, but what you can do is go learn dot summary and That spits out basically everything There's all the letters and so you can see in this case These are the names I mentioned how they all got names right so the first layer is called conv 2d-1 And it's going to take his input This is useful to actually look at it's taking 64 by 64 images, which is what we told it We're going to transform things to this is three channels pi torch Like most things have channels at the end would say 64 by 64 by 3 pi torch moves it to the front So it's 3 by 64 by 64. That's because it turns out that some of the GPU Computations run faster when it's in that order okay, but that happens all behind the scenes automatically so part of that transformation Stuff that's kind of all done automatically is to do that minus 1 Means however however big the batch size is In Keras they use the number they use a special number none in pi torch They use minus 1 so this is a four dimensional mini batch the number of Elements in the number of images in the image mini batch is dynamic you can change that the number of channels is three Number of images is 64 by 64 okay, and so then you can basically see that this particular convolutional kernel Apparently has 64 kernels in it And it's also Halving we haven't talked about this but convolutions can have something called a stride that it's like max pooling the changes the size So it's returning a 32 by 32 by 64 kernel tensor and so on and so forth So that summary and we'll learn all about what that's doing in detail in the second half of the course one more I Collected my own data set and I try to use the it is a really small data set these currencies from Google images, and I tried to do a Learning rate find and then the plot and it just it gave me some numbers which I didn't understand on the learning rate font Yeah, and then the plot was empty so yeah, I mean let's let's talk about that on the forum, but basically The learning rate finder is going to go through a mini batch at a time if you've got a tiny data set There's just not enough mini batches so the trick is to make your mini that it makes your batch size really small Like try making it like four or eight Okay, they were great questions nothing online to add in it They were great questions we've got a little bit past where I hope to but let's let's quickly talk about Structured data so we can start thinking about it for next week So This is really weird right to me there's basically two types of data set we use in machine learning There's a type of data like audio images natural language text Where all of the all of the things inside an object like all of the pixels inside an image? Are all the same kind of thing they're all pixels or they're all? amplitudes of a waveform or They're all words I call this kind of data unstructured and then there's data sets like a profit and loss statement or the information about a Facebook user Where each column is like? Structurally quite different you know one thing is representing like how many pageviews last month another one is there sex Another one is what zip code there in and I call this structured data That particular terminology is not unusual like lots of people use that terminology, but lots of people don't there's no particularly agreed upon Terminology so when I say structured data, I'm referring to kind of columnar data as you might find in a database Or a spreadsheet where different columns represent different kinds of things and each row represents an observation And so structured data is Probably what most of you? Analyzing most of the time Funnily enough you know academics in the deep learning world don't really give a shit about structured data Because it's pretty hard to get published in fancy conference proceed proceedings If you're like if you've got a better logistics model, you know it's the thing that makes the world goes round It's a thing that makes everybody you know money and efficiency and makes stuff work But it's largely ignored sadly So We're not going to ignore it because we're practical deep learning And Kaggle doesn't ignore it either because people put prize money up on Kaggle to solve real-world problems So there are some great Kaggle competitions. We can look at there's one running right now Which is the grocery sales forecasting competition for Ecuador's largest chain? It's always a little I've got to be a little careful about how much I show you about currently running competitions because I don't want to you know Help you cheat, but it so happens there was a competition a year or two ago For one of Germany's largest grocery chains, which is almost identical, so I'm going to show you how to do that So that was called the Rossman stores data and So I would suggest you know first of all try practicing what we're learning on Rossman, right? But then see if you can get it working on on grocery because currently On the leaderboard no one seems to basically know what they're doing in the groceries competition if you look at the leaderboard The Let's see here. Yeah, these ones around five to nine five three Oh are people that are literally finding like group averages and submitting those I know because they're the kernels that they're using so you know the basically the people around 20th place Are not actually doing any machine learning So yeah, let's see if we can improve things So you'll see there's a lesson three Rossman Notebook make sure you get pull okay in fact you know just reminder you know before you start working Get pool in your fast AI repo and from time to time Condor and update for you guys doing the in-person course the condor and update you should do it more often because we're Changing things a little bit folks in the MOOC. You know more like once a month should be fine So anyway, I just I just changed this a little bit so make sure you get pulled get less than three Rossman And there's a couple of new libraries here one is fast AI dot structured Fast AI dot structured contains stuff which is actually not at all pie torch specific We actually use that in the machine learning course as well for doing random forests with no pie torch at all I mentioned that because you can use that particular library without any of the other parts of fast AI So that can be handy And then we're also going to use faster column data Which is basically some stuff that allows us to do fast AI pie torch stuff with columnar structured data The structured data we need to use pandas a lot Anybody who's used our data frames will be very familiar with pandas pandas is basically an attempt to kind of replicate data frames in Python You know and a bit more if you're Not entirely familiar with pandas. There's a great book Which I think I might have mentioned before Python for data analysis by Wes McKinney, there's a new addition that just came out a couple of weeks ago Obviously being by the pandas author its coverage of pandas is excellent, but it also covers numpy sci-fi plot lib scikit-learn I Python and Jupiter really well, okay, and so I'm kind of going to assume That you know your way around these libraries to some extent Also, there was the workshop we did before this started and there's a video of that online where we kind of have a brief mention of all of those tools I'm Structured data is generally shared as CSV files. That was no different in this competition As you'll see there's a hyperlink to the Rossman data set here All right Now if you look at the bottom of my screen you'll see this goes to files dot faster AI Because this doesn't require any login or anything to grab this data set. It's as simple as right-clicking copy link address head over to wherever you want it and and just type W get and The URL okay, so that's because you know it's it's not behind a login or anything So you can grab the grab it from there and You can always read a CSV file with just pandas dot read CSV now in this particular case. There's a lot of pre-processing that we do and what I've actually done here is I've I've actually Stolen the entire Pipeline from the third place winner of Rossman. Okay, so they made all their data They're really great You know they've had a github available with everything that we need and I've ported it all across and simplified it and tried to make it pretty easy to understand this Course is about deep learning not about data processing, so I'm not going to go through it But we will be going through it in the machine learning course in some detail because feature engineering is really important So if you're interested You know check out the machine learning course for that I Will however show you Kind of what it looks like so once we read the CSVs in You can see basically what's there so the key one is For a particular store We have the We have the date and we have the sales For that particular store. We know whether that Thing is on promo or not We know the number of customers that that particular store had We know whether that date was a school holiday We also know What kind of store it is so like this is pretty common right you'll often get Data sets where there's some column with like just some kind of code. We don't really know what the code means Most of the time I find it doesn't matter what it means like normally you get given a data dictionary When you start on a project and obviously if you're working on an internal project you can ask the people at your company What does this column mean I? Kind of stay away from learning too much about it. I prefer to like see what the data says first There's something about what kind of product are we selling in this particular row And then there's information about like how far away is the nearest competitor how long have they been open for How long has the promo been on for For each store we can find out what state it's in for each state we can find out the name of the state this is in Germany and Interestingly they were allowed to download any data external data They wanted in this competition just very common as long as you share it with everybody else and so some folks tried downloading data from Google Trends I'm not sure exactly what it was that they were checking the trend of but we have this information from Google Trends Somebody downloaded the weather for every day in Germany every state And yeah, that's about it right so You can get a data frame summary With pandas which kind of lets you see how many observations and means and standard deviations Again, I don't do a hell of a lot with that early on But it's nice to note there So what we do you know this is called a relational data set a relational data set is one where there's quite a few tables We have to join together. It's very easy to do that in pandas There's a thing called merge so a great little function to do that and so I just started joining everything together I join in the weather the Google Trends the stores Yeah, that's about everything I guess You'll see there's one thing that I'm using from the fast AI library, which is called add date part We talk about this a lot in the machine learning course But basically this is going to take a date and pull out of a bunch of columns day of week is at the start of a Quarter month of year so on and so forth and add them all in to the data set okay, so this is all standard pre-processing Right so we join everything together we fiddle around with some of the dates a little bit some of them are in month and year Format we turn it into date format We spend a lot of time trying to Take information about for example holidays and add a column for like how long until the next holiday How long has it been since the last holiday? Did over promos? So on and so forth okay, so we do all that and at the very end we basically save a big Structured data file that contains all that stuff Something that those of you that use pandas may not be aware of is that there's a very cool new format called feather Which you can save a pandas? Data frame into this feather format. It's kind of pretty much takes it as it sits in RAM and dumps it to the disk and so it's like really really really fast the reason that you need to know this is because the Ecuadorian grocery competition that's on now has 350 million records So you will care about how long things take it took I believe about six seconds for me to save 350 million records to feather format so it's pretty cool So at the end of all that I'd save it as feather format and for the rest of this discussion I'm just going to take it as given that we've got this nicely pre-processed Feature engineered file and I can just go read better Okay, but for you to play along at home you will have to run those previous cells oh except the See these ones are commented out You don't have to run those because the file that you download from files dot faster day I has already done that for you, okay All right So we basically have all these columns So it basically is going to tell us You know how many of this thing was sold on? This date at this store and so the goal of this competition is to find out How many things will be sold for each store for each type of thing in the future? Okay, and so that's basically what we're going to be trying to do And so here's an example of what some of the data looks like And so Next week we're going to see how to go through these steps But basically what we're going to learn is we're going to learn to split the columns into two types some Columns we're going to treat as categorical which is to say Store ID one and store ID two are not numerically related to each other their categories All right, we're going to treat day of week like that to Monday and Tuesday day zero and day one not numerically related to each other Where else distance in kilometers to the nearest? competitor That's a number that we're going to treat numerically Right so in other words the categorical variables. We basically are going to one-hot encode them You can think of it as one-hot encoding them where else the continuous variables. We're going to be feeding into fully connected layers Just as is Okay So what we'll be doing is we'll be basically creating a Validation set and you'll see like a lot of these are start to look familiar This is the same function we used on planet and dog breeds to create a validation set There's some stuff that you haven't seen before Where we're going to? Basically rather than saying image data dot from CSV We're going to say column our data from data frame, right? So you can see like the basic API concepts will be the same, but they're a little different right? but just like before we're going to get a learner and We're going to go LR find to find our best learning rate and Then we're going to go dot fit with a metric with a cycle length Okay, so the basic sequence is going to end up looking Hopefully very familiar okay, so we're out of time so what I suggest you do this week is like try to Enter as many Kaggle image competitions as possible like like try to really get this feel for like cycle lengths learning rates plotting things You know that That post I showed you at the start of class today that kind of took you through lesson one like Really go through that on as many image data sets as you can to just feel Really comfortable with it right? Because you want to get to the point where next week when we start talking about structured data That this idea of like how learners kind of work and data works and data loaders and data sets and looking at pictures Should be really you know intuitive all right good luck. See you next week you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.0, "text": " Welcome back everybody", "tokens": [4027, 646, 2201], "temperature": 0.0, "avg_logprob": -0.20795654763980786, "compression_ratio": 1.7178423236514522, "no_speech_prob": 0.0047532618045806885}, {"id": 1, "seek": 0, "start": 3.52, "end": 5.5200000000000005, "text": " I'm sure you've noticed", "tokens": [286, 478, 988, 291, 600, 5694], "temperature": 0.0, "avg_logprob": -0.20795654763980786, "compression_ratio": 1.7178423236514522, "no_speech_prob": 0.0047532618045806885}, {"id": 2, "seek": 0, "start": 6.84, "end": 11.68, "text": " But there's been a lot of cool activity on the forum this week and one of the things that's been really great to see is", "tokens": [583, 456, 311, 668, 257, 688, 295, 1627, 5191, 322, 264, 17542, 341, 1243, 293, 472, 295, 264, 721, 300, 311, 668, 534, 869, 281, 536, 307], "temperature": 0.0, "avg_logprob": -0.20795654763980786, "compression_ratio": 1.7178423236514522, "no_speech_prob": 0.0047532618045806885}, {"id": 3, "seek": 0, "start": 11.68, "end": 13.76, "text": " That a lot of you have started creating", "tokens": [663, 257, 688, 295, 291, 362, 1409, 4084], "temperature": 0.0, "avg_logprob": -0.20795654763980786, "compression_ratio": 1.7178423236514522, "no_speech_prob": 0.0047532618045806885}, {"id": 4, "seek": 0, "start": 14.68, "end": 20.16, "text": " really helpful materials both for your classmates to better understand stuff and also for you to", "tokens": [534, 4961, 5319, 1293, 337, 428, 24964, 281, 1101, 1223, 1507, 293, 611, 337, 291, 281], "temperature": 0.0, "avg_logprob": -0.20795654763980786, "compression_ratio": 1.7178423236514522, "no_speech_prob": 0.0047532618045806885}, {"id": 5, "seek": 0, "start": 20.6, "end": 22.6, "text": " better understand stuff by", "tokens": [1101, 1223, 1507, 538], "temperature": 0.0, "avg_logprob": -0.20795654763980786, "compression_ratio": 1.7178423236514522, "no_speech_prob": 0.0047532618045806885}, {"id": 6, "seek": 0, "start": 22.72, "end": 27.44, "text": " Trying to teach what you've learned. I just wanted to highlight a few I've actually", "tokens": [20180, 281, 2924, 437, 291, 600, 3264, 13, 286, 445, 1415, 281, 5078, 257, 1326, 286, 600, 767], "temperature": 0.0, "avg_logprob": -0.20795654763980786, "compression_ratio": 1.7178423236514522, "no_speech_prob": 0.0047532618045806885}, {"id": 7, "seek": 2744, "start": 27.44, "end": 29.080000000000002, "text": " actually", "tokens": [767], "temperature": 0.0, "avg_logprob": -0.21816570242655645, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.1199113436741754e-05}, {"id": 8, "seek": 2744, "start": 29.080000000000002, "end": 33.260000000000005, "text": " Posted to the wiki thread a few of these but there's there's lots more", "tokens": [10223, 292, 281, 264, 261, 9850, 7207, 257, 1326, 295, 613, 457, 456, 311, 456, 311, 3195, 544], "temperature": 0.0, "avg_logprob": -0.21816570242655645, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.1199113436741754e-05}, {"id": 9, "seek": 2744, "start": 36.28, "end": 44.28, "text": " Rashima's posted a whole bunch of nice introductory tutorials. So for example if you're having any trouble getting connected with AWS", "tokens": [46298, 4775, 311, 9437, 257, 1379, 3840, 295, 1481, 39048, 17616, 13, 407, 337, 1365, 498, 291, 434, 1419, 604, 5253, 1242, 4582, 365, 17650], "temperature": 0.0, "avg_logprob": -0.21816570242655645, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.1199113436741754e-05}, {"id": 10, "seek": 2744, "start": 45.08, "end": 47.08, "text": " She's got a whole step-by-step", "tokens": [1240, 311, 658, 257, 1379, 1823, 12, 2322, 12, 16792], "temperature": 0.0, "avg_logprob": -0.21816570242655645, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.1199113436741754e-05}, {"id": 11, "seek": 2744, "start": 47.96, "end": 53.22, "text": " How to go about logging in and getting everything working which I think is a really terrific thing", "tokens": [1012, 281, 352, 466, 27991, 294, 293, 1242, 1203, 1364, 597, 286, 519, 307, 257, 534, 20899, 551], "temperature": 0.0, "avg_logprob": -0.21816570242655645, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.1199113436741754e-05}, {"id": 12, "seek": 2744, "start": 53.22, "end": 55.3, "text": " and so it's a kind of thing that if you", "tokens": [293, 370, 309, 311, 257, 733, 295, 551, 300, 498, 291], "temperature": 0.0, "avg_logprob": -0.21816570242655645, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.1199113436741754e-05}, {"id": 13, "seek": 5530, "start": 55.3, "end": 57.3, "text": " do", "tokens": [360], "temperature": 0.0, "avg_logprob": -0.2023745992909307, "compression_ratio": 1.6814516129032258, "no_speech_prob": 1.7502326954854652e-05}, {"id": 14, "seek": 5530, "start": 57.66, "end": 60.559999999999995, "text": " Writing some notes for yourself to remind you how to do it", "tokens": [32774, 512, 5570, 337, 1803, 281, 4160, 291, 577, 281, 360, 309], "temperature": 0.0, "avg_logprob": -0.2023745992909307, "compression_ratio": 1.6814516129032258, "no_speech_prob": 1.7502326954854652e-05}, {"id": 15, "seek": 5530, "start": 61.14, "end": 66.34, "text": " You may as well post them for others to do it to do it as well and by using a markdown file like this", "tokens": [509, 815, 382, 731, 2183, 552, 337, 2357, 281, 360, 309, 281, 360, 309, 382, 731, 293, 538, 1228, 257, 1491, 5093, 3991, 411, 341], "temperature": 0.0, "avg_logprob": -0.2023745992909307, "compression_ratio": 1.6814516129032258, "no_speech_prob": 1.7502326954854652e-05}, {"id": 16, "seek": 5530, "start": 66.34, "end": 70.74, "text": " And it's actually good practice if you haven't used github before if you put it up on github", "tokens": [400, 309, 311, 767, 665, 3124, 498, 291, 2378, 380, 1143, 290, 355, 836, 949, 498, 291, 829, 309, 493, 322, 290, 355, 836], "temperature": 0.0, "avg_logprob": -0.2023745992909307, "compression_ratio": 1.6814516129032258, "no_speech_prob": 1.7502326954854652e-05}, {"id": 17, "seek": 5530, "start": 71.08, "end": 75.0, "text": " Everybody can now use it or of course you can just put it in the forum", "tokens": [7646, 393, 586, 764, 309, 420, 295, 1164, 291, 393, 445, 829, 309, 294, 264, 17542], "temperature": 0.0, "avg_logprob": -0.2023745992909307, "compression_ratio": 1.6814516129032258, "no_speech_prob": 1.7502326954854652e-05}, {"id": 18, "seek": 5530, "start": 75.62, "end": 76.66, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.2023745992909307, "compression_ratio": 1.6814516129032258, "no_speech_prob": 1.7502326954854652e-05}, {"id": 19, "seek": 5530, "start": 76.66, "end": 78.22, "text": " more advanced", "tokens": [544, 7339], "temperature": 0.0, "avg_logprob": -0.2023745992909307, "compression_ratio": 1.6814516129032258, "no_speech_prob": 1.7502326954854652e-05}, {"id": 20, "seek": 5530, "start": 78.22, "end": 82.62, "text": " Thing that Rashima wrote up about is she noticed that I like using T max", "tokens": [30902, 300, 46298, 4775, 4114, 493, 466, 307, 750, 5694, 300, 286, 411, 1228, 314, 11469], "temperature": 0.0, "avg_logprob": -0.2023745992909307, "compression_ratio": 1.6814516129032258, "no_speech_prob": 1.7502326954854652e-05}, {"id": 21, "seek": 8262, "start": 82.62, "end": 85.7, "text": " Which is a handy little thing which lets me", "tokens": [3013, 307, 257, 13239, 707, 551, 597, 6653, 385], "temperature": 0.0, "avg_logprob": -0.2213295709519159, "compression_ratio": 1.65, "no_speech_prob": 8.939542567532044e-06}, {"id": 22, "seek": 8262, "start": 87.82000000000001, "end": 89.82000000000001, "text": " Let's me basically have a window", "tokens": [961, 311, 385, 1936, 362, 257, 4910], "temperature": 0.0, "avg_logprob": -0.2213295709519159, "compression_ratio": 1.65, "no_speech_prob": 8.939542567532044e-06}, {"id": 23, "seek": 8262, "start": 92.26, "end": 94.26, "text": " So as soon as I log into my computer", "tokens": [407, 382, 2321, 382, 286, 3565, 666, 452, 3820], "temperature": 0.0, "avg_logprob": -0.2213295709519159, "compression_ratio": 1.65, "no_speech_prob": 8.939542567532044e-06}, {"id": 24, "seek": 8262, "start": 95.42, "end": 97.34, "text": " If I run T max", "tokens": [759, 286, 1190, 314, 11469], "temperature": 0.0, "avg_logprob": -0.2213295709519159, "compression_ratio": 1.65, "no_speech_prob": 8.939542567532044e-06}, {"id": 25, "seek": 8262, "start": 97.34, "end": 99.9, "text": " You'll see that all of my windows pop straight up", "tokens": [509, 603, 536, 300, 439, 295, 452, 9309, 1665, 2997, 493], "temperature": 0.0, "avg_logprob": -0.2213295709519159, "compression_ratio": 1.65, "no_speech_prob": 8.939542567532044e-06}, {"id": 26, "seek": 8262, "start": 100.30000000000001, "end": 101.62, "text": " basically and I can like", "tokens": [1936, 293, 286, 393, 411], "temperature": 0.0, "avg_logprob": -0.2213295709519159, "compression_ratio": 1.65, "no_speech_prob": 8.939542567532044e-06}, {"id": 27, "seek": 8262, "start": 101.62, "end": 107.92, "text": " Continue running stuff in the background and I can like I've got them over here and I can kind of zoom into it or I", "tokens": [24472, 2614, 1507, 294, 264, 3678, 293, 286, 393, 411, 286, 600, 658, 552, 670, 510, 293, 286, 393, 733, 295, 8863, 666, 309, 420, 286], "temperature": 0.0, "avg_logprob": -0.2213295709519159, "compression_ratio": 1.65, "no_speech_prob": 8.939542567532044e-06}, {"id": 28, "seek": 10792, "start": 107.92, "end": 113.96000000000001, "text": " Can move over to the top which is his by Jupiter kernel running and so forth so if that sounds interesting", "tokens": [1664, 1286, 670, 281, 264, 1192, 597, 307, 702, 538, 24567, 28256, 2614, 293, 370, 5220, 370, 498, 300, 3263, 1880], "temperature": 0.0, "avg_logprob": -0.2302465336297148, "compression_ratio": 1.5458515283842795, "no_speech_prob": 4.637819529307308e-06}, {"id": 29, "seek": 10792, "start": 114.62, "end": 116.44, "text": " Rashima has a", "tokens": [46298, 4775, 575, 257], "temperature": 0.0, "avg_logprob": -0.2302465336297148, "compression_ratio": 1.5458515283842795, "no_speech_prob": 4.637819529307308e-06}, {"id": 30, "seek": 10792, "start": 116.44, "end": 118.58, "text": " Tutorial here on how you can use T max", "tokens": [18392, 5181, 510, 322, 577, 291, 393, 764, 314, 11469], "temperature": 0.0, "avg_logprob": -0.2302465336297148, "compression_ratio": 1.5458515283842795, "no_speech_prob": 4.637819529307308e-06}, {"id": 31, "seek": 10792, "start": 119.26, "end": 124.58, "text": " And it's actually got a whole bunch of stuff in her github, so that's that's really cool", "tokens": [400, 309, 311, 767, 658, 257, 1379, 3840, 295, 1507, 294, 720, 290, 355, 836, 11, 370, 300, 311, 300, 311, 534, 1627], "temperature": 0.0, "avg_logprob": -0.2302465336297148, "compression_ratio": 1.5458515283842795, "no_speech_prob": 4.637819529307308e-06}, {"id": 32, "seek": 10792, "start": 126.34, "end": 132.22, "text": " Uphill tomorrow has written a very nice kind of summary basically of our last lesson", "tokens": [624, 950, 373, 4153, 575, 3720, 257, 588, 1481, 733, 295, 12691, 1936, 295, 527, 1036, 6898], "temperature": 0.0, "avg_logprob": -0.2302465336297148, "compression_ratio": 1.5458515283842795, "no_speech_prob": 4.637819529307308e-06}, {"id": 33, "seek": 10792, "start": 133.96, "end": 135.96, "text": " Which kind of covers", "tokens": [3013, 733, 295, 10538], "temperature": 0.0, "avg_logprob": -0.2302465336297148, "compression_ratio": 1.5458515283842795, "no_speech_prob": 4.637819529307308e-06}, {"id": 34, "seek": 13596, "start": 135.96, "end": 140.12, "text": " What are the key things we did and why did we do them so if you're if you're kind of?", "tokens": [708, 366, 264, 2141, 721, 321, 630, 293, 983, 630, 321, 360, 552, 370, 498, 291, 434, 498, 291, 434, 733, 295, 30], "temperature": 0.0, "avg_logprob": -0.24700633133992111, "compression_ratio": 1.6422018348623852, "no_speech_prob": 4.4951266318093985e-06}, {"id": 35, "seek": 13596, "start": 141.72, "end": 146.58, "text": " Wondering like how does it fit together? I think this is a really helpful summary of like", "tokens": [343, 684, 1794, 411, 577, 775, 309, 3318, 1214, 30, 286, 519, 341, 307, 257, 534, 4961, 12691, 295, 411], "temperature": 0.0, "avg_logprob": -0.24700633133992111, "compression_ratio": 1.6422018348623852, "no_speech_prob": 4.4951266318093985e-06}, {"id": 36, "seek": 13596, "start": 147.12, "end": 150.8, "text": " What did those couple of hours look like if we summarize it all into a page or two?", "tokens": [708, 630, 729, 1916, 295, 2496, 574, 411, 498, 321, 20858, 309, 439, 666, 257, 3028, 420, 732, 30], "temperature": 0.0, "avg_logprob": -0.24700633133992111, "compression_ratio": 1.6422018348623852, "no_speech_prob": 4.4951266318093985e-06}, {"id": 37, "seek": 13596, "start": 151.84, "end": 153.52, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.24700633133992111, "compression_ratio": 1.6422018348623852, "no_speech_prob": 4.4951266318093985e-06}, {"id": 38, "seek": 13596, "start": 153.52, "end": 156.08, "text": " also really like a bell has", "tokens": [611, 534, 411, 257, 4549, 575], "temperature": 0.0, "avg_logprob": -0.24700633133992111, "compression_ratio": 1.6422018348623852, "no_speech_prob": 4.4951266318093985e-06}, {"id": 39, "seek": 13596, "start": 158.0, "end": 161.42000000000002, "text": " Duck kind of done a deep dive on the learning rate finder", "tokens": [29266, 733, 295, 1096, 257, 2452, 9192, 322, 264, 2539, 3314, 915, 260], "temperature": 0.0, "avg_logprob": -0.24700633133992111, "compression_ratio": 1.6422018348623852, "no_speech_prob": 4.4951266318093985e-06}, {"id": 40, "seek": 13596, "start": 162.20000000000002, "end": 164.20000000000002, "text": " which is a", "tokens": [597, 307, 257], "temperature": 0.0, "avg_logprob": -0.24700633133992111, "compression_ratio": 1.6422018348623852, "no_speech_prob": 4.4951266318093985e-06}, {"id": 41, "seek": 16420, "start": 164.2, "end": 167.67999999999998, "text": " Topic that a lot of you have been interested in learning more about particularly", "tokens": [8840, 299, 300, 257, 688, 295, 291, 362, 668, 3102, 294, 2539, 544, 466, 4098], "temperature": 0.0, "avg_logprob": -0.19697527451948685, "compression_ratio": 1.8269230769230769, "no_speech_prob": 4.425437055033399e-06}, {"id": 42, "seek": 16420, "start": 168.35999999999999, "end": 174.11999999999998, "text": " Those of you who have done deep learning before I've realized that this is like a solution to a problem that you've been having for", "tokens": [3950, 295, 291, 567, 362, 1096, 2452, 2539, 949, 286, 600, 5334, 300, 341, 307, 411, 257, 3827, 281, 257, 1154, 300, 291, 600, 668, 1419, 337], "temperature": 0.0, "avg_logprob": -0.19697527451948685, "compression_ratio": 1.8269230769230769, "no_speech_prob": 4.425437055033399e-06}, {"id": 43, "seek": 16420, "start": 174.11999999999998, "end": 179.92, "text": " A long time and haven't seen before and so it's kind of something which hasn't really been blocked about before so this is the first", "tokens": [316, 938, 565, 293, 2378, 380, 1612, 949, 293, 370, 309, 311, 733, 295, 746, 597, 6132, 380, 534, 668, 15470, 466, 949, 370, 341, 307, 264, 700], "temperature": 0.0, "avg_logprob": -0.19697527451948685, "compression_ratio": 1.8269230769230769, "no_speech_prob": 4.425437055033399e-06}, {"id": 44, "seek": 16420, "start": 179.92, "end": 183.79999999999998, "text": " Time I've seen this blogged about so when I put this on Twitter a link to", "tokens": [6161, 286, 600, 1612, 341, 6968, 3004, 466, 370, 562, 286, 829, 341, 322, 5794, 257, 2113, 281], "temperature": 0.0, "avg_logprob": -0.19697527451948685, "compression_ratio": 1.8269230769230769, "no_speech_prob": 4.425437055033399e-06}, {"id": 45, "seek": 16420, "start": 184.6, "end": 187.28, "text": " The bells post it's been shared now hundreds of times", "tokens": [440, 25474, 2183, 309, 311, 668, 5507, 586, 6779, 295, 1413], "temperature": 0.0, "avg_logprob": -0.19697527451948685, "compression_ratio": 1.8269230769230769, "no_speech_prob": 4.425437055033399e-06}, {"id": 46, "seek": 16420, "start": 187.72, "end": 192.95999999999998, "text": " It's been really really popular and viewed many thousands of times, so that's some great content", "tokens": [467, 311, 668, 534, 534, 3743, 293, 19174, 867, 5383, 295, 1413, 11, 370, 300, 311, 512, 869, 2701], "temperature": 0.0, "avg_logprob": -0.19697527451948685, "compression_ratio": 1.8269230769230769, "no_speech_prob": 4.425437055033399e-06}, {"id": 47, "seek": 19296, "start": 192.96, "end": 194.12, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.21633344483607023, "compression_ratio": 1.625, "no_speech_prob": 1.4510191249428317e-05}, {"id": 48, "seek": 19296, "start": 194.12, "end": 200.38, "text": " Redeck has posted lots of cool stuff. I really like this practitioners guide to pie torch which again", "tokens": [4477, 68, 547, 575, 9437, 3195, 295, 1627, 1507, 13, 286, 534, 411, 341, 25742, 5934, 281, 1730, 27822, 597, 797], "temperature": 0.0, "avg_logprob": -0.21633344483607023, "compression_ratio": 1.625, "no_speech_prob": 1.4510191249428317e-05}, {"id": 49, "seek": 19296, "start": 200.38, "end": 203.60000000000002, "text": " This is more for more advanced students, but it's like digging into", "tokens": [639, 307, 544, 337, 544, 7339, 1731, 11, 457, 309, 311, 411, 17343, 666], "temperature": 0.0, "avg_logprob": -0.21633344483607023, "compression_ratio": 1.625, "no_speech_prob": 1.4510191249428317e-05}, {"id": 50, "seek": 19296, "start": 204.36, "end": 207.24, "text": " people who have never used pie torch before but know a bit about", "tokens": [561, 567, 362, 1128, 1143, 1730, 27822, 949, 457, 458, 257, 857, 466], "temperature": 0.0, "avg_logprob": -0.21633344483607023, "compression_ratio": 1.625, "no_speech_prob": 1.4510191249428317e-05}, {"id": 51, "seek": 19296, "start": 209.16, "end": 213.12, "text": " Numerical programming in general it's a quick introduction to how pie torch is different", "tokens": [426, 15583, 804, 9410, 294, 2674, 309, 311, 257, 1702, 9339, 281, 577, 1730, 27822, 307, 819], "temperature": 0.0, "avg_logprob": -0.21633344483607023, "compression_ratio": 1.625, "no_speech_prob": 1.4510191249428317e-05}, {"id": 52, "seek": 19296, "start": 214.64000000000001, "end": 219.98000000000002, "text": " And then there's been some interesting little bits of research like what's the relationship between learning rate and batch size?", "tokens": [400, 550, 456, 311, 668, 512, 1880, 707, 9239, 295, 2132, 411, 437, 311, 264, 2480, 1296, 2539, 3314, 293, 15245, 2744, 30], "temperature": 0.0, "avg_logprob": -0.21633344483607023, "compression_ratio": 1.625, "no_speech_prob": 1.4510191249428317e-05}, {"id": 53, "seek": 21998, "start": 219.98, "end": 226.29999999999998, "text": " So one of the students actually asked me this before class and I said that well one of the other students has written an analysis", "tokens": [407, 472, 295, 264, 1731, 767, 2351, 385, 341, 949, 1508, 293, 286, 848, 300, 731, 472, 295, 264, 661, 1731, 575, 3720, 364, 5215], "temperature": 0.0, "avg_logprob": -0.20669516810664423, "compression_ratio": 1.7311827956989247, "no_speech_prob": 1.8448104128765408e-06}, {"id": 54, "seek": 21998, "start": 226.29999999999998, "end": 228.29999999999998, "text": " of exactly that", "tokens": [295, 2293, 300], "temperature": 0.0, "avg_logprob": -0.20669516810664423, "compression_ratio": 1.7311827956989247, "no_speech_prob": 1.8448104128765408e-06}, {"id": 55, "seek": 21998, "start": 229.1, "end": 234.98, "text": " So what he's done is basically looked through and tried different batch sizes and different learning rates and tried to see how they seem to", "tokens": [407, 437, 415, 311, 1096, 307, 1936, 2956, 807, 293, 3031, 819, 15245, 11602, 293, 819, 2539, 6846, 293, 3031, 281, 536, 577, 436, 1643, 281], "temperature": 0.0, "avg_logprob": -0.20669516810664423, "compression_ratio": 1.7311827956989247, "no_speech_prob": 1.8448104128765408e-06}, {"id": 56, "seek": 21998, "start": 234.98, "end": 239.73999999999998, "text": " Relate together and these are all like cool experiments, which you know you can try yourself", "tokens": [8738, 473, 1214, 293, 613, 366, 439, 411, 1627, 12050, 11, 597, 291, 458, 291, 393, 853, 1803], "temperature": 0.0, "avg_logprob": -0.20669516810664423, "compression_ratio": 1.7311827956989247, "no_speech_prob": 1.8448104128765408e-06}, {"id": 57, "seek": 21998, "start": 241.73999999999998, "end": 247.98, "text": " Redeck again, he's written something again a kind of a research into this question. I made a claim that", "tokens": [4477, 68, 547, 797, 11, 415, 311, 3720, 746, 797, 257, 733, 295, 257, 2132, 666, 341, 1168, 13, 286, 1027, 257, 3932, 300], "temperature": 0.0, "avg_logprob": -0.20669516810664423, "compression_ratio": 1.7311827956989247, "no_speech_prob": 1.8448104128765408e-06}, {"id": 58, "seek": 24798, "start": 247.98, "end": 249.98, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.19219379799038755, "compression_ratio": 1.6240875912408759, "no_speech_prob": 2.2125250325188972e-05}, {"id": 59, "seek": 24798, "start": 250.85999999999999, "end": 253.29999999999998, "text": " Stochastic gradient descent with restarts finds more", "tokens": [745, 8997, 2750, 16235, 23475, 365, 1472, 11814, 10704, 544], "temperature": 0.0, "avg_logprob": -0.19219379799038755, "compression_ratio": 1.6240875912408759, "no_speech_prob": 2.2125250325188972e-05}, {"id": 60, "seek": 24798, "start": 253.7, "end": 259.86, "text": " Generalizable parts of the function surface because they're kind of flatter and he's been trying to figure out is there a way to measure that", "tokens": [6996, 22395, 3166, 295, 264, 2445, 3753, 570, 436, 434, 733, 295, 41247, 293, 415, 311, 668, 1382, 281, 2573, 484, 307, 456, 257, 636, 281, 3481, 300], "temperature": 0.0, "avg_logprob": -0.19219379799038755, "compression_ratio": 1.6240875912408759, "no_speech_prob": 2.2125250325188972e-05}, {"id": 61, "seek": 24798, "start": 259.86, "end": 264.14, "text": " More directly not quite successful yet, but a really interesting piece of research", "tokens": [5048, 3838, 406, 1596, 4406, 1939, 11, 457, 257, 534, 1880, 2522, 295, 2132], "temperature": 0.0, "avg_logprob": -0.19219379799038755, "compression_ratio": 1.6240875912408759, "no_speech_prob": 2.2125250325188972e-05}, {"id": 62, "seek": 24798, "start": 265.38, "end": 267.21999999999997, "text": " Got some", "tokens": [5803, 512], "temperature": 0.0, "avg_logprob": -0.19219379799038755, "compression_ratio": 1.6240875912408759, "no_speech_prob": 2.2125250325188972e-05}, {"id": 63, "seek": 24798, "start": 267.21999999999997, "end": 269.21999999999997, "text": " introductions to convolutional neural networks", "tokens": [48032, 281, 45216, 304, 18161, 9590], "temperature": 0.0, "avg_logprob": -0.19219379799038755, "compression_ratio": 1.6240875912408759, "no_speech_prob": 2.2125250325188972e-05}, {"id": 64, "seek": 24798, "start": 269.94, "end": 271.94, "text": " and then", "tokens": [293, 550], "temperature": 0.0, "avg_logprob": -0.19219379799038755, "compression_ratio": 1.6240875912408759, "no_speech_prob": 2.2125250325188972e-05}, {"id": 65, "seek": 24798, "start": 273.02, "end": 277.06, "text": " Something that we'll be learning about towards the end of this course, but I'm sure you've noticed", "tokens": [6595, 300, 321, 603, 312, 2539, 466, 3030, 264, 917, 295, 341, 1164, 11, 457, 286, 478, 988, 291, 600, 5694], "temperature": 0.0, "avg_logprob": -0.19219379799038755, "compression_ratio": 1.6240875912408759, "no_speech_prob": 2.2125250325188972e-05}, {"id": 66, "seek": 27706, "start": 277.06, "end": 279.06, "text": " we're using something called ResNet and", "tokens": [321, 434, 1228, 746, 1219, 5015, 31890, 293], "temperature": 0.0, "avg_logprob": -0.27061751454146865, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.3006811968807597e-05}, {"id": 67, "seek": 27706, "start": 279.66, "end": 281.66, "text": " Anand Sahar actually posted a", "tokens": [1107, 474, 18280, 289, 767, 9437, 257], "temperature": 0.0, "avg_logprob": -0.27061751454146865, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.3006811968807597e-05}, {"id": 68, "seek": 27706, "start": 282.22, "end": 285.34, "text": " Pretty impressive analysis of like what's a ResNet?", "tokens": [10693, 8992, 5215, 295, 411, 437, 311, 257, 5015, 31890, 30], "temperature": 0.0, "avg_logprob": -0.27061751454146865, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.3006811968807597e-05}, {"id": 69, "seek": 27706, "start": 285.34, "end": 291.26, "text": " And why is it interesting and this one's actually been very already shared very widely around the internet. I've seen also", "tokens": [400, 983, 307, 309, 1880, 293, 341, 472, 311, 767, 668, 588, 1217, 5507, 588, 13371, 926, 264, 4705, 13, 286, 600, 1612, 611], "temperature": 0.0, "avg_logprob": -0.27061751454146865, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.3006811968807597e-05}, {"id": 70, "seek": 27706, "start": 292.34000000000003, "end": 295.02, "text": " So some more advanced students who are interested in", "tokens": [407, 512, 544, 7339, 1731, 567, 366, 3102, 294], "temperature": 0.0, "avg_logprob": -0.27061751454146865, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.3006811968807597e-05}, {"id": 71, "seek": 27706, "start": 295.98, "end": 297.98, "text": " jumping ahead can look at that and", "tokens": [11233, 2286, 393, 574, 412, 300, 293], "temperature": 0.0, "avg_logprob": -0.27061751454146865, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.3006811968807597e-05}, {"id": 72, "seek": 27706, "start": 298.14, "end": 300.82, "text": " Uphill to mine also has done something similar", "tokens": [624, 950, 373, 281, 3892, 611, 575, 1096, 746, 2531], "temperature": 0.0, "avg_logprob": -0.27061751454146865, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.3006811968807597e-05}, {"id": 73, "seek": 27706, "start": 301.9, "end": 303.62, "text": " so lots of", "tokens": [370, 3195, 295], "temperature": 0.0, "avg_logprob": -0.27061751454146865, "compression_ratio": 1.6182572614107884, "no_speech_prob": 1.3006811968807597e-05}, {"id": 74, "seek": 30362, "start": 303.62, "end": 311.74, "text": " Yeah, lots of stuff going on on the forums. I'm sure you've also noticed we have a beginner forum now specifically for you know asking questions", "tokens": [865, 11, 3195, 295, 1507, 516, 322, 322, 264, 26998, 13, 286, 478, 988, 291, 600, 611, 5694, 321, 362, 257, 22080, 17542, 586, 4682, 337, 291, 458, 3365, 1651], "temperature": 0.0, "avg_logprob": -0.14450290853326972, "compression_ratio": 1.6931407942238268, "no_speech_prob": 1.3845613466401119e-05}, {"id": 75, "seek": 30362, "start": 312.38, "end": 314.3, "text": " which", "tokens": [597], "temperature": 0.0, "avg_logprob": -0.14450290853326972, "compression_ratio": 1.6931407942238268, "no_speech_prob": 1.3845613466401119e-05}, {"id": 76, "seek": 30362, "start": 314.3, "end": 315.74, "text": " You know", "tokens": [509, 458], "temperature": 0.0, "avg_logprob": -0.14450290853326972, "compression_ratio": 1.6931407942238268, "no_speech_prob": 1.3845613466401119e-05}, {"id": 77, "seek": 30362, "start": 315.74, "end": 317.74, "text": " There's always the case that there are no", "tokens": [821, 311, 1009, 264, 1389, 300, 456, 366, 572], "temperature": 0.0, "avg_logprob": -0.14450290853326972, "compression_ratio": 1.6931407942238268, "no_speech_prob": 1.3845613466401119e-05}, {"id": 78, "seek": 30362, "start": 317.98, "end": 323.34000000000003, "text": " Dumb questions, but when there's lots of people around you talking about advanced topics it might not feel that way", "tokens": [413, 2860, 1651, 11, 457, 562, 456, 311, 3195, 295, 561, 926, 291, 1417, 466, 7339, 8378, 309, 1062, 406, 841, 300, 636], "temperature": 0.0, "avg_logprob": -0.14450290853326972, "compression_ratio": 1.6931407942238268, "no_speech_prob": 1.3845613466401119e-05}, {"id": 79, "seek": 30362, "start": 323.34000000000003, "end": 325.34000000000003, "text": " so hopefully the beginners forum is just a", "tokens": [370, 4696, 264, 26992, 17542, 307, 445, 257], "temperature": 0.0, "avg_logprob": -0.14450290853326972, "compression_ratio": 1.6931407942238268, "no_speech_prob": 1.3845613466401119e-05}, {"id": 80, "seek": 30362, "start": 325.82, "end": 327.82, "text": " less intimidating space and", "tokens": [1570, 29714, 1901, 293], "temperature": 0.0, "avg_logprob": -0.14450290853326972, "compression_ratio": 1.6931407942238268, "no_speech_prob": 1.3845613466401119e-05}, {"id": 81, "seek": 32782, "start": 327.82, "end": 332.98, "text": " If you're a more advanced student who can help answer those questions", "tokens": [759, 291, 434, 257, 544, 7339, 3107, 567, 393, 854, 1867, 729, 1651], "temperature": 0.0, "avg_logprob": -0.10369875879570989, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.962072347960202e-06}, {"id": 82, "seek": 32782, "start": 332.98, "end": 337.58, "text": " Please do but remember when you do answer those questions try to answer in a way", "tokens": [2555, 360, 457, 1604, 562, 291, 360, 1867, 729, 1651, 853, 281, 1867, 294, 257, 636], "temperature": 0.0, "avg_logprob": -0.10369875879570989, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.962072347960202e-06}, {"id": 83, "seek": 32782, "start": 337.58, "end": 343.38, "text": " That's friendly to people that maybe you know have no more than a year of programming experience and haven't done any machine learning before", "tokens": [663, 311, 9208, 281, 561, 300, 1310, 291, 458, 362, 572, 544, 813, 257, 1064, 295, 9410, 1752, 293, 2378, 380, 1096, 604, 3479, 2539, 949], "temperature": 0.0, "avg_logprob": -0.10369875879570989, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.962072347960202e-06}, {"id": 84, "seek": 32782, "start": 346.78, "end": 348.78, "text": " So you know I hope", "tokens": [407, 291, 458, 286, 1454], "temperature": 0.0, "avg_logprob": -0.10369875879570989, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.962072347960202e-06}, {"id": 85, "seek": 32782, "start": 349.9, "end": 351.74, "text": " Other people in the class", "tokens": [5358, 561, 294, 264, 1508], "temperature": 0.0, "avg_logprob": -0.10369875879570989, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.962072347960202e-06}, {"id": 86, "seek": 32782, "start": 351.74, "end": 356.46, "text": " Feel like you can contribute as well and just remember all of the people we just looked at or many of them", "tokens": [14113, 411, 291, 393, 10586, 382, 731, 293, 445, 1604, 439, 295, 264, 561, 321, 445, 2956, 412, 420, 867, 295, 552], "temperature": 0.0, "avg_logprob": -0.10369875879570989, "compression_ratio": 1.7142857142857142, "no_speech_prob": 6.962072347960202e-06}, {"id": 87, "seek": 35646, "start": 356.46, "end": 358.46, "text": " I believe have never", "tokens": [286, 1697, 362, 1128], "temperature": 0.0, "avg_logprob": -0.14375318930699274, "compression_ratio": 1.6852589641434264, "no_speech_prob": 4.092832114110934e-06}, {"id": 88, "seek": 35646, "start": 358.5, "end": 364.78, "text": " Hosted anything to the internet before right I mean you don't have to be a particular kind of person to be allowed to blog", "tokens": [22047, 292, 1340, 281, 264, 4705, 949, 558, 286, 914, 291, 500, 380, 362, 281, 312, 257, 1729, 733, 295, 954, 281, 312, 4350, 281, 6968], "temperature": 0.0, "avg_logprob": -0.14375318930699274, "compression_ratio": 1.6852589641434264, "no_speech_prob": 4.092832114110934e-06}, {"id": 89, "seek": 35646, "start": 364.78, "end": 368.9, "text": " or something you can just jot down your notes throw it up there and", "tokens": [420, 746, 291, 393, 445, 27873, 760, 428, 5570, 3507, 309, 493, 456, 293], "temperature": 0.0, "avg_logprob": -0.14375318930699274, "compression_ratio": 1.6852589641434264, "no_speech_prob": 4.092832114110934e-06}, {"id": 90, "seek": 35646, "start": 370.29999999999995, "end": 376.85999999999996, "text": " one handy thing is if you just put it on the forum and you're not quite sure of some of the details then", "tokens": [472, 13239, 551, 307, 498, 291, 445, 829, 309, 322, 264, 17542, 293, 291, 434, 406, 1596, 988, 295, 512, 295, 264, 4365, 550], "temperature": 0.0, "avg_logprob": -0.14375318930699274, "compression_ratio": 1.6852589641434264, "no_speech_prob": 4.092832114110934e-06}, {"id": 91, "seek": 35646, "start": 377.21999999999997, "end": 380.78, "text": " Then you know you have an opportunity to get feedback and say like ah well", "tokens": [1396, 291, 458, 291, 362, 364, 2650, 281, 483, 5824, 293, 584, 411, 3716, 731], "temperature": 0.0, "avg_logprob": -0.14375318930699274, "compression_ratio": 1.6852589641434264, "no_speech_prob": 4.092832114110934e-06}, {"id": 92, "seek": 35646, "start": 380.78, "end": 382.06, "text": " That's not quite how that works", "tokens": [663, 311, 406, 1596, 577, 300, 1985], "temperature": 0.0, "avg_logprob": -0.14375318930699274, "compression_ratio": 1.6852589641434264, "no_speech_prob": 4.092832114110934e-06}, {"id": 93, "seek": 38206, "start": 382.06, "end": 388.82, "text": " You know actually it works this way instead or or that's a really interesting insight had you thought about taking this further and so forth", "tokens": [509, 458, 767, 309, 1985, 341, 636, 2602, 420, 420, 300, 311, 257, 534, 1880, 11269, 632, 291, 1194, 466, 1940, 341, 3052, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.1401988279472277, "compression_ratio": 1.6975806451612903, "no_speech_prob": 5.2553400564647745e-06}, {"id": 94, "seek": 38206, "start": 389.58, "end": 396.34000000000003, "text": " so what we've done so far is a kind of a an introduction as a just as a practitioner to", "tokens": [370, 437, 321, 600, 1096, 370, 1400, 307, 257, 733, 295, 257, 364, 9339, 382, 257, 445, 382, 257, 32125, 281], "temperature": 0.0, "avg_logprob": -0.1401988279472277, "compression_ratio": 1.6975806451612903, "no_speech_prob": 5.2553400564647745e-06}, {"id": 95, "seek": 38206, "start": 398.3, "end": 402.54, "text": " Convolutional neural networks for images, and we haven't really talked much at all about", "tokens": [2656, 85, 3386, 304, 18161, 9590, 337, 5267, 11, 293, 321, 2378, 380, 534, 2825, 709, 412, 439, 466], "temperature": 0.0, "avg_logprob": -0.1401988279472277, "compression_ratio": 1.6975806451612903, "no_speech_prob": 5.2553400564647745e-06}, {"id": 96, "seek": 38206, "start": 403.34000000000003, "end": 409.26, "text": " The theory or why they work or the math of them, but on the other hand what we have done is seen", "tokens": [440, 5261, 420, 983, 436, 589, 420, 264, 5221, 295, 552, 11, 457, 322, 264, 661, 1011, 437, 321, 362, 1096, 307, 1612], "temperature": 0.0, "avg_logprob": -0.1401988279472277, "compression_ratio": 1.6975806451612903, "no_speech_prob": 5.2553400564647745e-06}, {"id": 97, "seek": 38206, "start": 409.98, "end": 411.46, "text": " how to", "tokens": [577, 281], "temperature": 0.0, "avg_logprob": -0.1401988279472277, "compression_ratio": 1.6975806451612903, "no_speech_prob": 5.2553400564647745e-06}, {"id": 98, "seek": 41146, "start": 411.46, "end": 418.14, "text": " Build a model which actually works exceptionally well in fact world-class level models", "tokens": [11875, 257, 2316, 597, 767, 1985, 37807, 731, 294, 1186, 1002, 12, 11665, 1496, 5245], "temperature": 0.0, "avg_logprob": -0.21857061480531598, "compression_ratio": 1.7276595744680852, "no_speech_prob": 4.222798906994285e-06}, {"id": 99, "seek": 41146, "start": 418.85999999999996, "end": 422.53999999999996, "text": " And we'll kind of review a little bit of that today", "tokens": [400, 321, 603, 733, 295, 3131, 257, 707, 857, 295, 300, 965], "temperature": 0.0, "avg_logprob": -0.21857061480531598, "compression_ratio": 1.7276595744680852, "no_speech_prob": 4.222798906994285e-06}, {"id": 100, "seek": 41146, "start": 423.82, "end": 425.26, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.21857061480531598, "compression_ratio": 1.7276595744680852, "no_speech_prob": 4.222798906994285e-06}, {"id": 101, "seek": 41146, "start": 425.26, "end": 431.03999999999996, "text": " Then also today we're going to dig in a little bit quite a lot more actually into the underlying theory of like what is a what?", "tokens": [1396, 611, 965, 321, 434, 516, 281, 2528, 294, 257, 707, 857, 1596, 257, 688, 544, 767, 666, 264, 14217, 5261, 295, 411, 437, 307, 257, 437, 30], "temperature": 0.0, "avg_logprob": -0.21857061480531598, "compression_ratio": 1.7276595744680852, "no_speech_prob": 4.222798906994285e-06}, {"id": 102, "seek": 41146, "start": 431.03999999999996, "end": 438.26, "text": " Is a CNN? What's a convolution? How does this work? And then we're going to kind of go through this this cycle where we're going to dig", "tokens": [1119, 257, 24859, 30, 708, 311, 257, 45216, 30, 1012, 775, 341, 589, 30, 400, 550, 321, 434, 516, 281, 733, 295, 352, 807, 341, 341, 6586, 689, 321, 434, 516, 281, 2528], "temperature": 0.0, "avg_logprob": -0.21857061480531598, "compression_ratio": 1.7276595744680852, "no_speech_prob": 4.222798906994285e-06}, {"id": 103, "seek": 43826, "start": 438.26, "end": 444.98, "text": " We're going to do a little intro into a whole bunch of application areas using neural nets for structured data", "tokens": [492, 434, 516, 281, 360, 257, 707, 12897, 666, 257, 1379, 3840, 295, 3861, 3179, 1228, 18161, 36170, 337, 18519, 1412], "temperature": 0.0, "avg_logprob": -0.19156973361968993, "compression_ratio": 1.7272727272727273, "no_speech_prob": 9.223283086612355e-06}, {"id": 104, "seek": 43826, "start": 445.14, "end": 453.12, "text": " So kind of like logistics or forecasting or you know financial data or that kind of thing and then looking at", "tokens": [407, 733, 295, 411, 27420, 420, 44331, 420, 291, 458, 4669, 1412, 420, 300, 733, 295, 551, 293, 550, 1237, 412], "temperature": 0.0, "avg_logprob": -0.19156973361968993, "compression_ratio": 1.7272727272727273, "no_speech_prob": 9.223283086612355e-06}, {"id": 105, "seek": 43826, "start": 454.14, "end": 458.9, "text": " language applications and LP applications using recurrent neural nets and then", "tokens": [2856, 5821, 293, 38095, 5821, 1228, 18680, 1753, 18161, 36170, 293, 550], "temperature": 0.0, "avg_logprob": -0.19156973361968993, "compression_ratio": 1.7272727272727273, "no_speech_prob": 9.223283086612355e-06}, {"id": 106, "seek": 43826, "start": 459.74, "end": 461.74, "text": " collaborative filtering for", "tokens": [16555, 30822, 337], "temperature": 0.0, "avg_logprob": -0.19156973361968993, "compression_ratio": 1.7272727272727273, "no_speech_prob": 9.223283086612355e-06}, {"id": 107, "seek": 43826, "start": 463.18, "end": 466.2, "text": " Recommendation systems and so these will all be like", "tokens": [49545, 521, 399, 3652, 293, 370, 613, 486, 439, 312, 411], "temperature": 0.0, "avg_logprob": -0.19156973361968993, "compression_ratio": 1.7272727272727273, "no_speech_prob": 9.223283086612355e-06}, {"id": 108, "seek": 46620, "start": 466.2, "end": 469.82, "text": " Similar to what we've done for for CNNs images", "tokens": [10905, 281, 437, 321, 600, 1096, 337, 337, 24859, 82, 5267], "temperature": 0.0, "avg_logprob": -0.14873607099548844, "compression_ratio": 1.7247386759581882, "no_speech_prob": 4.495139364735223e-06}, {"id": 109, "seek": 46620, "start": 469.82, "end": 473.78, "text": " It'll be like here's how you can get a state-of-the-art result without digging into the theory", "tokens": [467, 603, 312, 411, 510, 311, 577, 291, 393, 483, 257, 1785, 12, 2670, 12, 3322, 12, 446, 1874, 1553, 17343, 666, 264, 5261], "temperature": 0.0, "avg_logprob": -0.14873607099548844, "compression_ratio": 1.7247386759581882, "no_speech_prob": 4.495139364735223e-06}, {"id": 110, "seek": 46620, "start": 473.78, "end": 475.92, "text": " But but knowing how to actually make it work", "tokens": [583, 457, 5276, 577, 281, 767, 652, 309, 589], "temperature": 0.0, "avg_logprob": -0.14873607099548844, "compression_ratio": 1.7247386759581882, "no_speech_prob": 4.495139364735223e-06}, {"id": 111, "seek": 46620, "start": 475.92, "end": 481.03999999999996, "text": " And then we're kind of go go to go back through those almost in reverse order", "tokens": [400, 550, 321, 434, 733, 295, 352, 352, 281, 352, 646, 807, 729, 1920, 294, 9943, 1668], "temperature": 0.0, "avg_logprob": -0.14873607099548844, "compression_ratio": 1.7247386759581882, "no_speech_prob": 4.495139364735223e-06}, {"id": 112, "seek": 46620, "start": 481.03999999999996, "end": 487.0, "text": " So then we're going to dig right into collaborative filtering in a lot of detail and see how how to write the code", "tokens": [407, 550, 321, 434, 516, 281, 2528, 558, 666, 16555, 30822, 294, 257, 688, 295, 2607, 293, 536, 577, 577, 281, 2464, 264, 3089], "temperature": 0.0, "avg_logprob": -0.14873607099548844, "compression_ratio": 1.7247386759581882, "no_speech_prob": 4.495139364735223e-06}, {"id": 113, "seek": 46620, "start": 487.4, "end": 492.8, "text": " Underneath and how the math works underneath and then we're going to do the same thing for structured data analysis", "tokens": [6974, 7000, 293, 577, 264, 5221, 1985, 7223, 293, 550, 321, 434, 516, 281, 360, 264, 912, 551, 337, 18519, 1412, 5215], "temperature": 0.0, "avg_logprob": -0.14873607099548844, "compression_ratio": 1.7247386759581882, "no_speech_prob": 4.495139364735223e-06}, {"id": 114, "seek": 49280, "start": 492.8, "end": 499.6, "text": " We're going to do the same thing for confidence for images and finally an in-depth deep dive into recurrent neural networks", "tokens": [492, 434, 516, 281, 360, 264, 912, 551, 337, 6687, 337, 5267, 293, 2721, 364, 294, 12, 25478, 2452, 9192, 666, 18680, 1753, 18161, 9590], "temperature": 0.0, "avg_logprob": -0.16549844008225661, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.1365602858859347e-06}, {"id": 115, "seek": 49280, "start": 499.88, "end": 501.88, "text": " So that's kind of where we're getting", "tokens": [407, 300, 311, 733, 295, 689, 321, 434, 1242], "temperature": 0.0, "avg_logprob": -0.16549844008225661, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.1365602858859347e-06}, {"id": 116, "seek": 49280, "start": 503.24, "end": 505.24, "text": " So let's start by", "tokens": [407, 718, 311, 722, 538], "temperature": 0.0, "avg_logprob": -0.16549844008225661, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.1365602858859347e-06}, {"id": 117, "seek": 49280, "start": 506.76, "end": 509.36, "text": " Doing a little bit of a review and I want to", "tokens": [18496, 257, 707, 857, 295, 257, 3131, 293, 286, 528, 281], "temperature": 0.0, "avg_logprob": -0.16549844008225661, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.1365602858859347e-06}, {"id": 118, "seek": 49280, "start": 510.6, "end": 515.92, "text": " Also provide a bit more detail on some on some steps that we only briefly skipped over", "tokens": [2743, 2893, 257, 857, 544, 2607, 322, 512, 322, 512, 4439, 300, 321, 787, 10515, 30193, 670], "temperature": 0.0, "avg_logprob": -0.16549844008225661, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.1365602858859347e-06}, {"id": 119, "seek": 49280, "start": 516.04, "end": 518.96, "text": " So I want to make sure that we're all able to complete", "tokens": [407, 286, 528, 281, 652, 988, 300, 321, 434, 439, 1075, 281, 3566], "temperature": 0.0, "avg_logprob": -0.16549844008225661, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.1365602858859347e-06}, {"id": 120, "seek": 51896, "start": 518.96, "end": 524.12, "text": " Kind of last week's assignment, which was the the dog breeds", "tokens": [9242, 295, 1036, 1243, 311, 15187, 11, 597, 390, 264, 264, 3000, 41609], "temperature": 0.0, "avg_logprob": -0.17272513488243366, "compression_ratio": 1.7462686567164178, "no_speech_prob": 8.530243576387875e-06}, {"id": 121, "seek": 51896, "start": 524.12, "end": 529.6, "text": " I mean to basically apply what you've learned to it another data set and I thought the easiest one to do would be the dog", "tokens": [286, 914, 281, 1936, 3079, 437, 291, 600, 3264, 281, 309, 1071, 1412, 992, 293, 286, 1194, 264, 12889, 472, 281, 360, 576, 312, 264, 3000], "temperature": 0.0, "avg_logprob": -0.17272513488243366, "compression_ratio": 1.7462686567164178, "no_speech_prob": 8.530243576387875e-06}, {"id": 122, "seek": 51896, "start": 529.6, "end": 534.32, "text": " Breeds kaggle competition and so I want to make sure everybody has everything you need to do this right now", "tokens": [7090, 5147, 350, 559, 22631, 6211, 293, 370, 286, 528, 281, 652, 988, 2201, 575, 1203, 291, 643, 281, 360, 341, 558, 586], "temperature": 0.0, "avg_logprob": -0.17272513488243366, "compression_ratio": 1.7462686567164178, "no_speech_prob": 8.530243576387875e-06}, {"id": 123, "seek": 51896, "start": 534.44, "end": 537.5600000000001, "text": " So the first thing is to make sure that you know", "tokens": [407, 264, 700, 551, 307, 281, 652, 988, 300, 291, 458], "temperature": 0.0, "avg_logprob": -0.17272513488243366, "compression_ratio": 1.7462686567164178, "no_speech_prob": 8.530243576387875e-06}, {"id": 124, "seek": 51896, "start": 537.96, "end": 543.0400000000001, "text": " How to download data and so there's there's two main places at the moment", "tokens": [1012, 281, 5484, 1412, 293, 370, 456, 311, 456, 311, 732, 2135, 3190, 412, 264, 1623], "temperature": 0.0, "avg_logprob": -0.17272513488243366, "compression_ratio": 1.7462686567164178, "no_speech_prob": 8.530243576387875e-06}, {"id": 125, "seek": 51896, "start": 543.0400000000001, "end": 545.64, "text": " We're kind of downloading data from one is from kaggle", "tokens": [492, 434, 733, 295, 32529, 1412, 490, 472, 307, 490, 350, 559, 22631], "temperature": 0.0, "avg_logprob": -0.17272513488243366, "compression_ratio": 1.7462686567164178, "no_speech_prob": 8.530243576387875e-06}, {"id": 126, "seek": 54564, "start": 545.64, "end": 548.72, "text": " And the other is from like anywhere else", "tokens": [400, 264, 661, 307, 490, 411, 4992, 1646], "temperature": 0.0, "avg_logprob": -0.21951069551355698, "compression_ratio": 1.4472049689440993, "no_speech_prob": 3.4465444969100645e-06}, {"id": 127, "seek": 54564, "start": 549.24, "end": 553.84, "text": " And so I'll first of all do the the kaggle version", "tokens": [400, 370, 286, 603, 700, 295, 439, 360, 264, 264, 350, 559, 22631, 3037], "temperature": 0.0, "avg_logprob": -0.21951069551355698, "compression_ratio": 1.4472049689440993, "no_speech_prob": 3.4465444969100645e-06}, {"id": 128, "seek": 54564, "start": 554.76, "end": 560.4, "text": " So to download from kaggle we use something called kaggle CLI", "tokens": [407, 281, 5484, 490, 350, 559, 22631, 321, 764, 746, 1219, 350, 559, 22631, 12855, 40], "temperature": 0.0, "avg_logprob": -0.21951069551355698, "compression_ratio": 1.4472049689440993, "no_speech_prob": 3.4465444969100645e-06}, {"id": 129, "seek": 54564, "start": 562.36, "end": 566.66, "text": " Which is here and to install it I think it's already in", "tokens": [3013, 307, 510, 293, 281, 3625, 309, 286, 519, 309, 311, 1217, 294], "temperature": 0.0, "avg_logprob": -0.21951069551355698, "compression_ratio": 1.4472049689440993, "no_speech_prob": 3.4465444969100645e-06}, {"id": 130, "seek": 54564, "start": 567.96, "end": 569.96, "text": " Let's just double check", "tokens": [961, 311, 445, 3834, 1520], "temperature": 0.0, "avg_logprob": -0.21951069551355698, "compression_ratio": 1.4472049689440993, "no_speech_prob": 3.4465444969100645e-06}, {"id": 131, "seek": 56996, "start": 569.96, "end": 576.0, "text": " Yeah, so it's already should already be in your environment", "tokens": [865, 11, 370, 309, 311, 1217, 820, 1217, 312, 294, 428, 2823], "temperature": 0.0, "avg_logprob": -0.26666089762812073, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.1381096050608903e-06}, {"id": 132, "seek": 56996, "start": 578.64, "end": 585.44, "text": " But to make sure one thing that happens is because this is downloading from the kaggle website through like screen scraping every time kaggle changes", "tokens": [583, 281, 652, 988, 472, 551, 300, 2314, 307, 570, 341, 307, 32529, 490, 264, 350, 559, 22631, 3144, 807, 411, 2568, 43738, 633, 565, 350, 559, 22631, 2962], "temperature": 0.0, "avg_logprob": -0.26666089762812073, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.1381096050608903e-06}, {"id": 133, "seek": 56996, "start": 585.44, "end": 588.9200000000001, "text": " The website it breaks so anytime you try to use it and", "tokens": [440, 3144, 309, 9857, 370, 13038, 291, 853, 281, 764, 309, 293], "temperature": 0.0, "avg_logprob": -0.26666089762812073, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.1381096050608903e-06}, {"id": 134, "seek": 56996, "start": 589.84, "end": 596.52, "text": " If kaggle's websites changed recently you'll need to make sure you get the most recent version so you can always go pip", "tokens": [759, 350, 559, 22631, 311, 12891, 3105, 3938, 291, 603, 643, 281, 652, 988, 291, 483, 264, 881, 5162, 3037, 370, 291, 393, 1009, 352, 8489], "temperature": 0.0, "avg_logprob": -0.26666089762812073, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.1381096050608903e-06}, {"id": 135, "seek": 56996, "start": 597.2, "end": 599.2, "text": " install", "tokens": [3625], "temperature": 0.0, "avg_logprob": -0.26666089762812073, "compression_ratio": 1.696969696969697, "no_speech_prob": 3.1381096050608903e-06}, {"id": 136, "seek": 59920, "start": 599.2, "end": 600.96, "text": " kaggle dash", "tokens": [350, 559, 22631, 8240], "temperature": 0.0, "avg_logprob": -0.25316474363975916, "compression_ratio": 1.579646017699115, "no_speech_prob": 5.093651452625636e-06}, {"id": 137, "seek": 59920, "start": 600.96, "end": 602.96, "text": " CLI", "tokens": [12855, 40], "temperature": 0.0, "avg_logprob": -0.25316474363975916, "compression_ratio": 1.579646017699115, "no_speech_prob": 5.093651452625636e-06}, {"id": 138, "seek": 59920, "start": 603.76, "end": 611.44, "text": " Minus minus upgrade and so that'll just make sure that you've got the latest version of of it and everything that it depends on okay", "tokens": [2829, 301, 3175, 11484, 293, 370, 300, 603, 445, 652, 988, 300, 291, 600, 658, 264, 6792, 3037, 295, 295, 309, 293, 1203, 300, 309, 5946, 322, 1392], "temperature": 0.0, "avg_logprob": -0.25316474363975916, "compression_ratio": 1.579646017699115, "no_speech_prob": 5.093651452625636e-06}, {"id": 139, "seek": 59920, "start": 612.0400000000001, "end": 617.1600000000001, "text": " And so then having done that you can follow the instructions actually I think", "tokens": [400, 370, 550, 1419, 1096, 300, 291, 393, 1524, 264, 9415, 767, 286, 519], "temperature": 0.0, "avg_logprob": -0.25316474363975916, "compression_ratio": 1.579646017699115, "no_speech_prob": 5.093651452625636e-06}, {"id": 140, "seek": 59920, "start": 617.8000000000001, "end": 624.12, "text": " Reshma was kind enough to there you go. There's a kaggle CLI feel like everything you need to know can be found at Reshma's", "tokens": [5015, 22061, 390, 733, 1547, 281, 456, 291, 352, 13, 821, 311, 257, 350, 559, 22631, 12855, 40, 841, 411, 1203, 291, 643, 281, 458, 393, 312, 1352, 412, 5015, 22061, 311], "temperature": 0.0, "avg_logprob": -0.25316474363975916, "compression_ratio": 1.579646017699115, "no_speech_prob": 5.093651452625636e-06}, {"id": 141, "seek": 59920, "start": 626.08, "end": 627.6400000000001, "text": " Github", "tokens": [460, 355, 836], "temperature": 0.0, "avg_logprob": -0.25316474363975916, "compression_ratio": 1.579646017699115, "no_speech_prob": 5.093651452625636e-06}, {"id": 142, "seek": 62764, "start": 627.64, "end": 632.16, "text": " So basically to do that the next step you go", "tokens": [407, 1936, 281, 360, 300, 264, 958, 1823, 291, 352], "temperature": 0.0, "avg_logprob": -0.19588306675786557, "compression_ratio": 1.6886792452830188, "no_speech_prob": 4.710857865575235e-06}, {"id": 143, "seek": 62764, "start": 633.64, "end": 635.56, "text": " KG download", "tokens": [591, 38, 5484], "temperature": 0.0, "avg_logprob": -0.19588306675786557, "compression_ratio": 1.6886792452830188, "no_speech_prob": 4.710857865575235e-06}, {"id": 144, "seek": 62764, "start": 635.56, "end": 641.1, "text": " And then you provide your username with minus you you provide your password with minus P", "tokens": [400, 550, 291, 2893, 428, 30351, 365, 3175, 291, 291, 2893, 428, 11524, 365, 3175, 430], "temperature": 0.0, "avg_logprob": -0.19588306675786557, "compression_ratio": 1.6886792452830188, "no_speech_prob": 4.710857865575235e-06}, {"id": 145, "seek": 62764, "start": 641.1, "end": 642.68, "text": " And then minus C", "tokens": [400, 550, 3175, 383], "temperature": 0.0, "avg_logprob": -0.19588306675786557, "compression_ratio": 1.6886792452830188, "no_speech_prob": 4.710857865575235e-06}, {"id": 146, "seek": 62764, "start": 642.68, "end": 647.72, "text": " You did the competition name and a lot of people in the forum is being confused about what to enter here", "tokens": [509, 630, 264, 6211, 1315, 293, 257, 688, 295, 561, 294, 264, 17542, 307, 885, 9019, 466, 437, 281, 3242, 510], "temperature": 0.0, "avg_logprob": -0.19588306675786557, "compression_ratio": 1.6886792452830188, "no_speech_prob": 4.710857865575235e-06}, {"id": 147, "seek": 62764, "start": 647.72, "end": 651.24, "text": " And so the key thing to note is that when you're at a kaggle competition", "tokens": [400, 370, 264, 2141, 551, 281, 3637, 307, 300, 562, 291, 434, 412, 257, 350, 559, 22631, 6211], "temperature": 0.0, "avg_logprob": -0.19588306675786557, "compression_ratio": 1.6886792452830188, "no_speech_prob": 4.710857865575235e-06}, {"id": 148, "seek": 62764, "start": 651.92, "end": 653.64, "text": " After the slash C", "tokens": [2381, 264, 17330, 383], "temperature": 0.0, "avg_logprob": -0.19588306675786557, "compression_ratio": 1.6886792452830188, "no_speech_prob": 4.710857865575235e-06}, {"id": 149, "seek": 65364, "start": 653.64, "end": 659.24, "text": " There's a specific name planet dash understanding dash etc right that's the name you need", "tokens": [821, 311, 257, 2685, 1315, 5054, 8240, 3701, 8240, 5183, 558, 300, 311, 264, 1315, 291, 643], "temperature": 0.0, "avg_logprob": -0.23011506464063508, "compression_ratio": 1.7391304347826086, "no_speech_prob": 6.240879883989692e-06}, {"id": 150, "seek": 65364, "start": 660.3199999999999, "end": 661.6, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.23011506464063508, "compression_ratio": 1.7391304347826086, "no_speech_prob": 6.240879883989692e-06}, {"id": 151, "seek": 65364, "start": 661.6, "end": 665.92, "text": " The other thing you'll need to make sure is that you've on your own computer", "tokens": [440, 661, 551, 291, 603, 643, 281, 652, 988, 307, 300, 291, 600, 322, 428, 1065, 3820], "temperature": 0.0, "avg_logprob": -0.23011506464063508, "compression_ratio": 1.7391304347826086, "no_speech_prob": 6.240879883989692e-06}, {"id": 152, "seek": 65364, "start": 666.3199999999999, "end": 671.04, "text": " Have attempted to click download at least once because when you do it will ask you to accept the rules", "tokens": [3560, 18997, 281, 2052, 5484, 412, 1935, 1564, 570, 562, 291, 360, 309, 486, 1029, 291, 281, 3241, 264, 4474], "temperature": 0.0, "avg_logprob": -0.23011506464063508, "compression_ratio": 1.7391304347826086, "no_speech_prob": 6.240879883989692e-06}, {"id": 153, "seek": 65364, "start": 672.1999999999999, "end": 674.1999999999999, "text": " If you've forgotten to do that", "tokens": [759, 291, 600, 11832, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.23011506464063508, "compression_ratio": 1.7391304347826086, "no_speech_prob": 6.240879883989692e-06}, {"id": 154, "seek": 65364, "start": 674.6, "end": 678.92, "text": " KG download will give you a hint it'll say oh it looks like you might have forgotten the rules", "tokens": [591, 38, 5484, 486, 976, 291, 257, 12075, 309, 603, 584, 1954, 309, 1542, 411, 291, 1062, 362, 11832, 264, 4474], "temperature": 0.0, "avg_logprob": -0.23011506464063508, "compression_ratio": 1.7391304347826086, "no_speech_prob": 6.240879883989692e-06}, {"id": 155, "seek": 67892, "start": 678.92, "end": 685.9599999999999, "text": " If you log into kaggle with like a Google account like anything other than a username password this won't work", "tokens": [759, 291, 3565, 666, 350, 559, 22631, 365, 411, 257, 3329, 2696, 411, 1340, 661, 813, 257, 30351, 11524, 341, 1582, 380, 589], "temperature": 0.0, "avg_logprob": -0.13387741361345565, "compression_ratio": 1.7588932806324111, "no_speech_prob": 8.714305863577465e-07}, {"id": 156, "seek": 67892, "start": 686.28, "end": 691.3, "text": " So you'll need to click forgot password on kaggle and get them to send you a normal password", "tokens": [407, 291, 603, 643, 281, 2052, 5298, 11524, 322, 350, 559, 22631, 293, 483, 552, 281, 2845, 291, 257, 2710, 11524], "temperature": 0.0, "avg_logprob": -0.13387741361345565, "compression_ratio": 1.7588932806324111, "no_speech_prob": 8.714305863577465e-07}, {"id": 157, "seek": 67892, "start": 692.04, "end": 697.04, "text": " So that's the kaggle version right and so when you do that you end up with a whole folder", "tokens": [407, 300, 311, 264, 350, 559, 22631, 3037, 558, 293, 370, 562, 291, 360, 300, 291, 917, 493, 365, 257, 1379, 10820], "temperature": 0.0, "avg_logprob": -0.13387741361345565, "compression_ratio": 1.7588932806324111, "no_speech_prob": 8.714305863577465e-07}, {"id": 158, "seek": 67892, "start": 697.28, "end": 700.36, "text": " Created for you with all of that competition data in it", "tokens": [11972, 292, 337, 291, 365, 439, 295, 300, 6211, 1412, 294, 309], "temperature": 0.0, "avg_logprob": -0.13387741361345565, "compression_ratio": 1.7588932806324111, "no_speech_prob": 8.714305863577465e-07}, {"id": 159, "seek": 67892, "start": 701.9599999999999, "end": 707.12, "text": " So a couple of reasons you might want to not use that the first is that you're using a data set", "tokens": [407, 257, 1916, 295, 4112, 291, 1062, 528, 281, 406, 764, 300, 264, 700, 307, 300, 291, 434, 1228, 257, 1412, 992], "temperature": 0.0, "avg_logprob": -0.13387741361345565, "compression_ratio": 1.7588932806324111, "no_speech_prob": 8.714305863577465e-07}, {"id": 160, "seek": 70712, "start": 707.12, "end": 714.0, "text": " That's not on kaggle the second is that you don't want all of the data sets in a kaggle competition for example the planet", "tokens": [663, 311, 406, 322, 350, 559, 22631, 264, 1150, 307, 300, 291, 500, 380, 528, 439, 295, 264, 1412, 6352, 294, 257, 350, 559, 22631, 6211, 337, 1365, 264, 5054], "temperature": 0.0, "avg_logprob": -0.1715421939114912, "compression_ratio": 1.678714859437751, "no_speech_prob": 7.646468475286383e-06}, {"id": 161, "seek": 70712, "start": 714.2, "end": 717.4, "text": " Competition that we've been looking at a little bit will look at again today", "tokens": [43634, 300, 321, 600, 668, 1237, 412, 257, 707, 857, 486, 574, 412, 797, 965], "temperature": 0.0, "avg_logprob": -0.1715421939114912, "compression_ratio": 1.678714859437751, "no_speech_prob": 7.646468475286383e-06}, {"id": 162, "seek": 70712, "start": 718.32, "end": 726.44, "text": " Has data in two formats tiff and jpeg the tiff is 19 gigabytes and the jpeg is 600 megabytes", "tokens": [8646, 1412, 294, 732, 25879, 256, 3661, 293, 361, 494, 70, 264, 256, 3661, 307, 1294, 42741, 293, 264, 361, 494, 70, 307, 11849, 10816, 24538], "temperature": 0.0, "avg_logprob": -0.1715421939114912, "compression_ratio": 1.678714859437751, "no_speech_prob": 7.646468475286383e-06}, {"id": 163, "seek": 70712, "start": 726.68, "end": 728.72, "text": " So you probably don't want to download both", "tokens": [407, 291, 1391, 500, 380, 528, 281, 5484, 1293], "temperature": 0.0, "avg_logprob": -0.1715421939114912, "compression_ratio": 1.678714859437751, "no_speech_prob": 7.646468475286383e-06}, {"id": 164, "seek": 70712, "start": 729.48, "end": 734.04, "text": " So I'll show you a really cool tip which actually somebody on the forum taught me", "tokens": [407, 286, 603, 855, 291, 257, 534, 1627, 4125, 597, 767, 2618, 322, 264, 17542, 5928, 385], "temperature": 0.0, "avg_logprob": -0.1715421939114912, "compression_ratio": 1.678714859437751, "no_speech_prob": 7.646468475286383e-06}, {"id": 165, "seek": 73404, "start": 734.04, "end": 737.8399999999999, "text": " I think it was one of the msan students here at usf. There's a", "tokens": [286, 519, 309, 390, 472, 295, 264, 275, 11491, 1731, 510, 412, 505, 69, 13, 821, 311, 257], "temperature": 0.0, "avg_logprob": -0.29386124959806115, "compression_ratio": 1.6281407035175879, "no_speech_prob": 2.482467607478611e-06}, {"id": 166, "seek": 73404, "start": 739.4, "end": 742.48, "text": " Chrome extension called curl wget", "tokens": [15327, 10320, 1219, 22591, 261, 847], "temperature": 0.0, "avg_logprob": -0.29386124959806115, "compression_ratio": 1.6281407035175879, "no_speech_prob": 2.482467607478611e-06}, {"id": 167, "seek": 73404, "start": 743.56, "end": 746.1999999999999, "text": " So you can just search for curl wget", "tokens": [407, 291, 393, 445, 3164, 337, 22591, 261, 847], "temperature": 0.0, "avg_logprob": -0.29386124959806115, "compression_ratio": 1.6281407035175879, "no_speech_prob": 2.482467607478611e-06}, {"id": 168, "seek": 73404, "start": 747.0, "end": 753.52, "text": " And then you install it by just clicking on install if you haven't installed extension before and then from now on", "tokens": [400, 550, 291, 3625, 309, 538, 445, 9697, 322, 3625, 498, 291, 2378, 380, 8899, 10320, 949, 293, 550, 490, 586, 322], "temperature": 0.0, "avg_logprob": -0.29386124959806115, "compression_ratio": 1.6281407035175879, "no_speech_prob": 2.482467607478611e-06}, {"id": 169, "seek": 73404, "start": 754.28, "end": 757.88, "text": " Every time you try to download something so I'll try and download this file", "tokens": [2048, 565, 291, 853, 281, 5484, 746, 370, 286, 603, 853, 293, 5484, 341, 3991], "temperature": 0.0, "avg_logprob": -0.29386124959806115, "compression_ratio": 1.6281407035175879, "no_speech_prob": 2.482467607478611e-06}, {"id": 170, "seek": 75788, "start": 757.88, "end": 766.4, "text": " And I'll just go ahead and cancel it right and now you see this little yellow button that's added up here", "tokens": [400, 286, 603, 445, 352, 2286, 293, 10373, 309, 558, 293, 586, 291, 536, 341, 707, 5566, 2960, 300, 311, 3869, 493, 510], "temperature": 0.0, "avg_logprob": -0.1979909868382696, "compression_ratio": 1.4966887417218544, "no_speech_prob": 8.059428182605188e-07}, {"id": 171, "seek": 75788, "start": 767.0, "end": 769.0, "text": " There's a whole command here", "tokens": [821, 311, 257, 1379, 5622, 510], "temperature": 0.0, "avg_logprob": -0.1979909868382696, "compression_ratio": 1.4966887417218544, "no_speech_prob": 8.059428182605188e-07}, {"id": 172, "seek": 75788, "start": 770.12, "end": 772.12, "text": " right so I can copy that and", "tokens": [558, 370, 286, 393, 5055, 300, 293], "temperature": 0.0, "avg_logprob": -0.1979909868382696, "compression_ratio": 1.4966887417218544, "no_speech_prob": 8.059428182605188e-07}, {"id": 173, "seek": 75788, "start": 774.0, "end": 776.0, "text": " Paste it", "tokens": [43827, 309], "temperature": 0.0, "avg_logprob": -0.1979909868382696, "compression_ratio": 1.4966887417218544, "no_speech_prob": 8.059428182605188e-07}, {"id": 174, "seek": 75788, "start": 776.2, "end": 777.8, "text": " into my", "tokens": [666, 452], "temperature": 0.0, "avg_logprob": -0.1979909868382696, "compression_ratio": 1.4966887417218544, "no_speech_prob": 8.059428182605188e-07}, {"id": 175, "seek": 75788, "start": 777.8, "end": 779.48, "text": " window and", "tokens": [4910, 293], "temperature": 0.0, "avg_logprob": -0.1979909868382696, "compression_ratio": 1.4966887417218544, "no_speech_prob": 8.059428182605188e-07}, {"id": 176, "seek": 75788, "start": 779.48, "end": 783.04, "text": " Hit go and it's there it goes okay", "tokens": [9217, 352, 293, 309, 311, 456, 309, 1709, 1392], "temperature": 0.0, "avg_logprob": -0.1979909868382696, "compression_ratio": 1.4966887417218544, "no_speech_prob": 8.059428182605188e-07}, {"id": 177, "seek": 78304, "start": 783.04, "end": 789.64, "text": " So what that does is like all of your cookies and headers and everything else needed to download that file is like saved", "tokens": [407, 437, 300, 775, 307, 411, 439, 295, 428, 13670, 293, 45101, 293, 1203, 1646, 2978, 281, 5484, 300, 3991, 307, 411, 6624], "temperature": 0.0, "avg_logprob": -0.15455709184919084, "compression_ratio": 1.7961538461538462, "no_speech_prob": 4.356847966846544e-06}, {"id": 178, "seek": 78304, "start": 789.64, "end": 792.12, "text": " So this is not just useful for", "tokens": [407, 341, 307, 406, 445, 4420, 337], "temperature": 0.0, "avg_logprob": -0.15455709184919084, "compression_ratio": 1.7961538461538462, "no_speech_prob": 4.356847966846544e-06}, {"id": 179, "seek": 78304, "start": 793.0799999999999, "end": 800.28, "text": " Downloading data it's also useful if you like trying to download some I don't know TV show or something anything where you're hidden behind a", "tokens": [32282, 278, 1412, 309, 311, 611, 4420, 498, 291, 411, 1382, 281, 5484, 512, 286, 500, 380, 458, 3558, 855, 420, 746, 1340, 689, 291, 434, 7633, 2261, 257], "temperature": 0.0, "avg_logprob": -0.15455709184919084, "compression_ratio": 1.7961538461538462, "no_speech_prob": 4.356847966846544e-06}, {"id": 180, "seek": 78304, "start": 801.7199999999999, "end": 807.16, "text": " Login or something you can you can grab it and actually that is very useful for data science because quite often", "tokens": [10824, 259, 420, 746, 291, 393, 291, 393, 4444, 309, 293, 767, 300, 307, 588, 4420, 337, 1412, 3497, 570, 1596, 2049], "temperature": 0.0, "avg_logprob": -0.15455709184919084, "compression_ratio": 1.7961538461538462, "no_speech_prob": 4.356847966846544e-06}, {"id": 181, "seek": 78304, "start": 807.16, "end": 810.42, "text": " We want to analyze things like videos on our on our consoles", "tokens": [492, 528, 281, 12477, 721, 411, 2145, 322, 527, 322, 527, 28948], "temperature": 0.0, "avg_logprob": -0.15455709184919084, "compression_ratio": 1.7961538461538462, "no_speech_prob": 4.356847966846544e-06}, {"id": 182, "seek": 81042, "start": 810.42, "end": 814.5, "text": " So this is a good trick all right, so there's two ways to get the data", "tokens": [407, 341, 307, 257, 665, 4282, 439, 558, 11, 370, 456, 311, 732, 2098, 281, 483, 264, 1412], "temperature": 0.0, "avg_logprob": -0.1661998663055763, "compression_ratio": 1.645, "no_speech_prob": 1.8738643348115147e-06}, {"id": 183, "seek": 81042, "start": 816.42, "end": 818.42, "text": " So then", "tokens": [407, 550], "temperature": 0.0, "avg_logprob": -0.1661998663055763, "compression_ratio": 1.645, "no_speech_prob": 1.8738643348115147e-06}, {"id": 184, "seek": 81042, "start": 819.54, "end": 822.1999999999999, "text": " Having got the data you then need to", "tokens": [10222, 658, 264, 1412, 291, 550, 643, 281], "temperature": 0.0, "avg_logprob": -0.1661998663055763, "compression_ratio": 1.645, "no_speech_prob": 1.8738643348115147e-06}, {"id": 185, "seek": 81042, "start": 823.14, "end": 825.14, "text": " Build your model right?", "tokens": [11875, 428, 2316, 558, 30], "temperature": 0.0, "avg_logprob": -0.1661998663055763, "compression_ratio": 1.645, "no_speech_prob": 1.8738643348115147e-06}, {"id": 186, "seek": 81042, "start": 825.66, "end": 831.86, "text": " So what I tend to do like you'll notice that I tend to assume that the data is in a directory called data", "tokens": [407, 437, 286, 3928, 281, 360, 411, 291, 603, 3449, 300, 286, 3928, 281, 6552, 300, 264, 1412, 307, 294, 257, 21120, 1219, 1412], "temperature": 0.0, "avg_logprob": -0.1661998663055763, "compression_ratio": 1.645, "no_speech_prob": 1.8738643348115147e-06}, {"id": 187, "seek": 81042, "start": 832.0999999999999, "end": 835.62, "text": " That's a sub directory of wherever your notebook is right", "tokens": [663, 311, 257, 1422, 21120, 295, 8660, 428, 21060, 307, 558], "temperature": 0.0, "avg_logprob": -0.1661998663055763, "compression_ratio": 1.645, "no_speech_prob": 1.8738643348115147e-06}, {"id": 188, "seek": 81042, "start": 836.8199999999999, "end": 838.8199999999999, "text": " Now you don't necessarily", "tokens": [823, 291, 500, 380, 4725], "temperature": 0.0, "avg_logprob": -0.1661998663055763, "compression_ratio": 1.645, "no_speech_prob": 1.8738643348115147e-06}, {"id": 189, "seek": 83882, "start": 838.82, "end": 842.74, "text": " Actually want to put your data there you might want to put it directly in your home directory", "tokens": [5135, 528, 281, 829, 428, 1412, 456, 291, 1062, 528, 281, 829, 309, 3838, 294, 428, 1280, 21120], "temperature": 0.0, "avg_logprob": -0.19376643636952276, "compression_ratio": 1.8795180722891567, "no_speech_prob": 4.222807092446601e-06}, {"id": 190, "seek": 83882, "start": 842.98, "end": 846.82, "text": " Or you might want to put it on another drive or whatever so what I do is", "tokens": [1610, 291, 1062, 528, 281, 829, 309, 322, 1071, 3332, 420, 2035, 370, 437, 286, 360, 307], "temperature": 0.0, "avg_logprob": -0.19376643636952276, "compression_ratio": 1.8795180722891567, "no_speech_prob": 4.222807092446601e-06}, {"id": 191, "seek": 83882, "start": 847.34, "end": 853.22, "text": " If you look inside my courses deal one folder. You'll see that data is actually a", "tokens": [759, 291, 574, 1854, 452, 7712, 2028, 472, 10820, 13, 509, 603, 536, 300, 1412, 307, 767, 257], "temperature": 0.0, "avg_logprob": -0.19376643636952276, "compression_ratio": 1.8795180722891567, "no_speech_prob": 4.222807092446601e-06}, {"id": 192, "seek": 83882, "start": 854.1, "end": 855.6600000000001, "text": " symbolic link", "tokens": [25755, 2113], "temperature": 0.0, "avg_logprob": -0.19376643636952276, "compression_ratio": 1.8795180722891567, "no_speech_prob": 4.222807092446601e-06}, {"id": 193, "seek": 83882, "start": 855.6600000000001, "end": 860.82, "text": " To a different drive right so you can put it anywhere you like and then you can just add a symbolic link", "tokens": [1407, 257, 819, 3332, 558, 370, 291, 393, 829, 309, 4992, 291, 411, 293, 550, 291, 393, 445, 909, 257, 25755, 2113], "temperature": 0.0, "avg_logprob": -0.19376643636952276, "compression_ratio": 1.8795180722891567, "no_speech_prob": 4.222807092446601e-06}, {"id": 194, "seek": 83882, "start": 861.38, "end": 867.2600000000001, "text": " Or you can just put it there directly it's up to you. You haven't used sim links before they're like", "tokens": [1610, 291, 393, 445, 829, 309, 456, 3838, 309, 311, 493, 281, 291, 13, 509, 2378, 380, 1143, 1034, 6123, 949, 436, 434, 411], "temperature": 0.0, "avg_logprob": -0.19376643636952276, "compression_ratio": 1.8795180722891567, "no_speech_prob": 4.222807092446601e-06}, {"id": 195, "seek": 86726, "start": 867.26, "end": 870.34, "text": " Aliases or shortcuts on the Mac or Windows?", "tokens": [12020, 1957, 420, 34620, 322, 264, 5707, 420, 8591, 30], "temperature": 0.0, "avg_logprob": -0.2616466008699857, "compression_ratio": 1.61328125, "no_speech_prob": 3.905461653630482e-06}, {"id": 196, "seek": 86726, "start": 870.9, "end": 876.0, "text": " Very handy, and there's some threads on the forum about how to use them if you want to help with that", "tokens": [4372, 13239, 11, 293, 456, 311, 512, 19314, 322, 264, 17542, 466, 577, 281, 764, 552, 498, 291, 528, 281, 854, 365, 300], "temperature": 0.0, "avg_logprob": -0.2616466008699857, "compression_ratio": 1.61328125, "no_speech_prob": 3.905461653630482e-06}, {"id": 197, "seek": 86726, "start": 876.8199999999999, "end": 879.42, "text": " That's for example is also how we actually have the", "tokens": [663, 311, 337, 1365, 307, 611, 577, 321, 767, 362, 264], "temperature": 0.0, "avg_logprob": -0.2616466008699857, "compression_ratio": 1.61328125, "no_speech_prob": 3.905461653630482e-06}, {"id": 198, "seek": 86726, "start": 880.1, "end": 886.54, "text": " Fast AI modules available from the same place as our notebooks. It's just a sim link to where they come from", "tokens": [15968, 7318, 16679, 2435, 490, 264, 912, 1081, 382, 527, 43782, 13, 467, 311, 445, 257, 1034, 2113, 281, 689, 436, 808, 490], "temperature": 0.0, "avg_logprob": -0.2616466008699857, "compression_ratio": 1.61328125, "no_speech_prob": 3.905461653630482e-06}, {"id": 199, "seek": 86726, "start": 887.78, "end": 889.78, "text": " anytime you want to see like", "tokens": [13038, 291, 528, 281, 536, 411], "temperature": 0.0, "avg_logprob": -0.2616466008699857, "compression_ratio": 1.61328125, "no_speech_prob": 3.905461653630482e-06}, {"id": 200, "seek": 86726, "start": 890.34, "end": 895.66, "text": " Where things actually point to in Linux you can just use the minus L flag to?", "tokens": [2305, 721, 767, 935, 281, 294, 18734, 291, 393, 445, 764, 264, 3175, 441, 7166, 281, 30], "temperature": 0.0, "avg_logprob": -0.2616466008699857, "compression_ratio": 1.61328125, "no_speech_prob": 3.905461653630482e-06}, {"id": 201, "seek": 89566, "start": 895.66, "end": 899.1, "text": " To listing a directory and that'll show you where the sim links", "tokens": [1407, 22161, 257, 21120, 293, 300, 603, 855, 291, 689, 264, 1034, 6123], "temperature": 0.0, "avg_logprob": -0.22988754770030145, "compression_ratio": 1.580188679245283, "no_speech_prob": 5.6823951126716565e-06}, {"id": 202, "seek": 89566, "start": 900.02, "end": 903.0799999999999, "text": " Exists to law show show you which things are directories so forth", "tokens": [2111, 1751, 281, 2101, 855, 855, 291, 597, 721, 366, 5391, 530, 370, 5220], "temperature": 0.0, "avg_logprob": -0.22988754770030145, "compression_ratio": 1.580188679245283, "no_speech_prob": 5.6823951126716565e-06}, {"id": 203, "seek": 89566, "start": 904.06, "end": 906.6, "text": " Okay, so one thing which", "tokens": [1033, 11, 370, 472, 551, 597], "temperature": 0.0, "avg_logprob": -0.22988754770030145, "compression_ratio": 1.580188679245283, "no_speech_prob": 5.6823951126716565e-06}, {"id": 204, "seek": 89566, "start": 910.9399999999999, "end": 914.78, "text": " May be a little unclear based on what we've done so far is like", "tokens": [1891, 312, 257, 707, 25636, 2361, 322, 437, 321, 600, 1096, 370, 1400, 307, 411], "temperature": 0.0, "avg_logprob": -0.22988754770030145, "compression_ratio": 1.580188679245283, "no_speech_prob": 5.6823951126716565e-06}, {"id": 205, "seek": 89566, "start": 915.26, "end": 918.4599999999999, "text": " How little code you actually need to do this end-to-end?", "tokens": [1012, 707, 3089, 291, 767, 643, 281, 360, 341, 917, 12, 1353, 12, 521, 30], "temperature": 0.0, "avg_logprob": -0.22988754770030145, "compression_ratio": 1.580188679245283, "no_speech_prob": 5.6823951126716565e-06}, {"id": 206, "seek": 89566, "start": 919.02, "end": 922.9, "text": " So what I've got here is is in a single window is an entire", "tokens": [407, 437, 286, 600, 658, 510, 307, 307, 294, 257, 2167, 4910, 307, 364, 2302], "temperature": 0.0, "avg_logprob": -0.22988754770030145, "compression_ratio": 1.580188679245283, "no_speech_prob": 5.6823951126716565e-06}, {"id": 207, "seek": 92290, "start": 922.9, "end": 929.4599999999999, "text": " End to end process to get a state-of-the-art result for cats versus dogs right I've the only", "tokens": [6967, 281, 917, 1399, 281, 483, 257, 1785, 12, 2670, 12, 3322, 12, 446, 1874, 337, 11111, 5717, 7197, 558, 286, 600, 264, 787], "temperature": 0.0, "avg_logprob": -0.24542435540093316, "compression_ratio": 1.5810810810810811, "no_speech_prob": 4.029437604913255e-06}, {"id": 208, "seek": 92290, "start": 929.62, "end": 936.26, "text": " Step I've skipped is the bit where we've downloaded it from Kaggle, and then where we unzipped it right so", "tokens": [5470, 286, 600, 30193, 307, 264, 857, 689, 321, 600, 21748, 309, 490, 48751, 22631, 11, 293, 550, 689, 321, 517, 89, 5529, 309, 558, 370], "temperature": 0.0, "avg_logprob": -0.24542435540093316, "compression_ratio": 1.5810810810810811, "no_speech_prob": 4.029437604913255e-06}, {"id": 209, "seek": 92290, "start": 937.26, "end": 939.5, "text": " These are literally all the steps", "tokens": [1981, 366, 3736, 439, 264, 4439], "temperature": 0.0, "avg_logprob": -0.24542435540093316, "compression_ratio": 1.5810810810810811, "no_speech_prob": 4.029437604913255e-06}, {"id": 210, "seek": 92290, "start": 940.3, "end": 943.4599999999999, "text": " and so we import our", "tokens": [293, 370, 321, 974, 527], "temperature": 0.0, "avg_logprob": -0.24542435540093316, "compression_ratio": 1.5810810810810811, "no_speech_prob": 4.029437604913255e-06}, {"id": 211, "seek": 92290, "start": 944.26, "end": 948.9399999999999, "text": " Libraries and actually if you import this one Conflearner that basically imports everything else", "tokens": [12006, 4889, 293, 767, 498, 291, 974, 341, 472, 11701, 306, 22916, 300, 1936, 41596, 1203, 1646], "temperature": 0.0, "avg_logprob": -0.24542435540093316, "compression_ratio": 1.5810810810810811, "no_speech_prob": 4.029437604913255e-06}, {"id": 212, "seek": 94894, "start": 948.94, "end": 953.5, "text": " So that's that we need to tell it the path of where things are", "tokens": [407, 300, 311, 300, 321, 643, 281, 980, 309, 264, 3100, 295, 689, 721, 366], "temperature": 0.0, "avg_logprob": -0.17246921373450239, "compression_ratio": 1.8204081632653062, "no_speech_prob": 6.643388132943073e-06}, {"id": 213, "seek": 94894, "start": 953.9000000000001, "end": 957.36, "text": " The size that we want the batch size that we want all right", "tokens": [440, 2744, 300, 321, 528, 264, 15245, 2744, 300, 321, 528, 439, 558], "temperature": 0.0, "avg_logprob": -0.17246921373450239, "compression_ratio": 1.8204081632653062, "no_speech_prob": 6.643388132943073e-06}, {"id": 214, "seek": 94894, "start": 958.5400000000001, "end": 962.34, "text": " So then and we're going to learn a lot more about what these do very shortly", "tokens": [407, 550, 293, 321, 434, 516, 281, 1466, 257, 688, 544, 466, 437, 613, 360, 588, 13392], "temperature": 0.0, "avg_logprob": -0.17246921373450239, "compression_ratio": 1.8204081632653062, "no_speech_prob": 6.643388132943073e-06}, {"id": 215, "seek": 94894, "start": 962.34, "end": 965.7800000000001, "text": " But basically we say how do we want to transform our data?", "tokens": [583, 1936, 321, 584, 577, 360, 321, 528, 281, 4088, 527, 1412, 30], "temperature": 0.0, "avg_logprob": -0.17246921373450239, "compression_ratio": 1.8204081632653062, "no_speech_prob": 6.643388132943073e-06}, {"id": 216, "seek": 94894, "start": 965.7800000000001, "end": 970.7800000000001, "text": " So we want to transform it in a way that's suitable to this particular kind of model and that's", "tokens": [407, 321, 528, 281, 4088, 309, 294, 257, 636, 300, 311, 12873, 281, 341, 1729, 733, 295, 2316, 293, 300, 311], "temperature": 0.0, "avg_logprob": -0.17246921373450239, "compression_ratio": 1.8204081632653062, "no_speech_prob": 6.643388132943073e-06}, {"id": 217, "seek": 94894, "start": 971.1, "end": 976.24, "text": " Assumes that the photos aside on photos and that we're going to zoom in up to 10% each time", "tokens": [6281, 10018, 300, 264, 5787, 7359, 322, 5787, 293, 300, 321, 434, 516, 281, 8863, 294, 493, 281, 1266, 4, 1184, 565], "temperature": 0.0, "avg_logprob": -0.17246921373450239, "compression_ratio": 1.8204081632653062, "no_speech_prob": 6.643388132943073e-06}, {"id": 218, "seek": 97624, "start": 976.24, "end": 980.88, "text": " We say that we want to get some data based on paths", "tokens": [492, 584, 300, 321, 528, 281, 483, 512, 1412, 2361, 322, 14518], "temperature": 0.0, "avg_logprob": -0.18975575170784353, "compression_ratio": 1.8851063829787233, "no_speech_prob": 3.0894766496203374e-06}, {"id": 219, "seek": 97624, "start": 980.88, "end": 985.2, "text": " And so remember this is this idea that there's a path called cats and a path called dogs", "tokens": [400, 370, 1604, 341, 307, 341, 1558, 300, 456, 311, 257, 3100, 1219, 11111, 293, 257, 3100, 1219, 7197], "temperature": 0.0, "avg_logprob": -0.18975575170784353, "compression_ratio": 1.8851063829787233, "no_speech_prob": 3.0894766496203374e-06}, {"id": 220, "seek": 97624, "start": 985.2, "end": 988.36, "text": " And they're inside a path called train and a path called valid", "tokens": [400, 436, 434, 1854, 257, 3100, 1219, 3847, 293, 257, 3100, 1219, 7363], "temperature": 0.0, "avg_logprob": -0.18975575170784353, "compression_ratio": 1.8851063829787233, "no_speech_prob": 3.0894766496203374e-06}, {"id": 221, "seek": 97624, "start": 989.0, "end": 991.0, "text": " Note that you can always", "tokens": [11633, 300, 291, 393, 1009], "temperature": 0.0, "avg_logprob": -0.18975575170784353, "compression_ratio": 1.8851063829787233, "no_speech_prob": 3.0894766496203374e-06}, {"id": 222, "seek": 97624, "start": 993.52, "end": 997.32, "text": " Overwrite these with other things so if your things are in different known folders", "tokens": [4886, 21561, 613, 365, 661, 721, 370, 498, 428, 721, 366, 294, 819, 2570, 31082], "temperature": 0.0, "avg_logprob": -0.18975575170784353, "compression_ratio": 1.8851063829787233, "no_speech_prob": 3.0894766496203374e-06}, {"id": 223, "seek": 97624, "start": 997.32, "end": 1000.38, "text": " You could either rename them or you can see here", "tokens": [509, 727, 2139, 36741, 552, 420, 291, 393, 536, 510], "temperature": 0.0, "avg_logprob": -0.18975575170784353, "compression_ratio": 1.8851063829787233, "no_speech_prob": 3.0894766496203374e-06}, {"id": 224, "seek": 97624, "start": 1000.38, "end": 1005.04, "text": " There's like a train name and a bowel name you can always pick something else here", "tokens": [821, 311, 411, 257, 3847, 1315, 293, 257, 40094, 1315, 291, 393, 1009, 1888, 746, 1646, 510], "temperature": 0.0, "avg_logprob": -0.18975575170784353, "compression_ratio": 1.8851063829787233, "no_speech_prob": 3.0894766496203374e-06}, {"id": 225, "seek": 100504, "start": 1005.04, "end": 1007.04, "text": " also", "tokens": [611], "temperature": 0.0, "avg_logprob": -0.22753336212851785, "compression_ratio": 1.6047619047619048, "no_speech_prob": 1.788061240404204e-06}, {"id": 226, "seek": 100504, "start": 1007.28, "end": 1009.28, "text": " Notice there's a test name", "tokens": [13428, 456, 311, 257, 1500, 1315], "temperature": 0.0, "avg_logprob": -0.22753336212851785, "compression_ratio": 1.6047619047619048, "no_speech_prob": 1.788061240404204e-06}, {"id": 227, "seek": 100504, "start": 1009.36, "end": 1014.78, "text": " So if you want to submit something to cattle you'll need to fill in the name the name of the folder where the test set is", "tokens": [407, 498, 291, 528, 281, 10315, 746, 281, 19992, 291, 603, 643, 281, 2836, 294, 264, 1315, 264, 1315, 295, 264, 10820, 689, 264, 1500, 992, 307], "temperature": 0.0, "avg_logprob": -0.22753336212851785, "compression_ratio": 1.6047619047619048, "no_speech_prob": 1.788061240404204e-06}, {"id": 228, "seek": 100504, "start": 1014.78, "end": 1016.88, "text": " And obviously those those won't be labeled", "tokens": [400, 2745, 729, 729, 1582, 380, 312, 21335], "temperature": 0.0, "avg_logprob": -0.22753336212851785, "compression_ratio": 1.6047619047619048, "no_speech_prob": 1.788061240404204e-06}, {"id": 229, "seek": 100504, "start": 1020.28, "end": 1023.76, "text": " So then we create a model from a pre trained model", "tokens": [407, 550, 321, 1884, 257, 2316, 490, 257, 659, 8895, 2316], "temperature": 0.0, "avg_logprob": -0.22753336212851785, "compression_ratio": 1.6047619047619048, "no_speech_prob": 1.788061240404204e-06}, {"id": 230, "seek": 100504, "start": 1023.76, "end": 1030.44, "text": " It's from a resnet 50 model using this data, and then we call fit and remember by default", "tokens": [467, 311, 490, 257, 725, 7129, 2625, 2316, 1228, 341, 1412, 11, 293, 550, 321, 818, 3318, 293, 1604, 538, 7576], "temperature": 0.0, "avg_logprob": -0.22753336212851785, "compression_ratio": 1.6047619047619048, "no_speech_prob": 1.788061240404204e-06}, {"id": 231, "seek": 103044, "start": 1030.44, "end": 1036.44, "text": " That has all of the layers, but the last few frozen and again. We'll learn a lot more about what that means", "tokens": [663, 575, 439, 295, 264, 7914, 11, 457, 264, 1036, 1326, 12496, 293, 797, 13, 492, 603, 1466, 257, 688, 544, 466, 437, 300, 1355], "temperature": 0.0, "avg_logprob": -0.14908032898509174, "compression_ratio": 1.68503937007874, "no_speech_prob": 6.048881459719269e-06}, {"id": 232, "seek": 103044, "start": 1037.24, "end": 1039.56, "text": " And so that's that's what that does so that", "tokens": [400, 370, 300, 311, 300, 311, 437, 300, 775, 370, 300], "temperature": 0.0, "avg_logprob": -0.14908032898509174, "compression_ratio": 1.68503937007874, "no_speech_prob": 6.048881459719269e-06}, {"id": 233, "seek": 103044, "start": 1040.24, "end": 1042.24, "text": " That took two and a half minutes", "tokens": [663, 1890, 732, 293, 257, 1922, 2077], "temperature": 0.0, "avg_logprob": -0.14908032898509174, "compression_ratio": 1.68503937007874, "no_speech_prob": 6.048881459719269e-06}, {"id": 234, "seek": 103044, "start": 1043.6000000000001, "end": 1047.3600000000001, "text": " Notice here. I didn't say pre compute equals true again", "tokens": [13428, 510, 13, 286, 994, 380, 584, 659, 14722, 6915, 2074, 797], "temperature": 0.0, "avg_logprob": -0.14908032898509174, "compression_ratio": 1.68503937007874, "no_speech_prob": 6.048881459719269e-06}, {"id": 235, "seek": 103044, "start": 1047.3600000000001, "end": 1050.3200000000002, "text": " There's been some confusion on the forums about like what that means", "tokens": [821, 311, 668, 512, 15075, 322, 264, 26998, 466, 411, 437, 300, 1355], "temperature": 0.0, "avg_logprob": -0.14908032898509174, "compression_ratio": 1.68503937007874, "no_speech_prob": 6.048881459719269e-06}, {"id": 236, "seek": 103044, "start": 1050.72, "end": 1057.68, "text": " It's it's only a it's only something that makes it a little faster for this first step right so you can always skip it", "tokens": [467, 311, 309, 311, 787, 257, 309, 311, 787, 746, 300, 1669, 309, 257, 707, 4663, 337, 341, 700, 1823, 558, 370, 291, 393, 1009, 10023, 309], "temperature": 0.0, "avg_logprob": -0.14908032898509174, "compression_ratio": 1.68503937007874, "no_speech_prob": 6.048881459719269e-06}, {"id": 237, "seek": 105768, "start": 1057.68, "end": 1063.76, "text": " And if you're at all confused about it, or it's causing you any problems. Just leave it off right because it's just a", "tokens": [400, 498, 291, 434, 412, 439, 9019, 466, 309, 11, 420, 309, 311, 9853, 291, 604, 2740, 13, 1449, 1856, 309, 766, 558, 570, 309, 311, 445, 257], "temperature": 0.0, "avg_logprob": -0.18198429009853265, "compression_ratio": 1.8111111111111111, "no_speech_prob": 1.7603356354811694e-06}, {"id": 238, "seek": 105768, "start": 1065.52, "end": 1072.0800000000002, "text": " It's just a shortcut which caches some of that intermediate steps that don't have to be recapitulated each time", "tokens": [467, 311, 445, 257, 24822, 597, 269, 13272, 512, 295, 300, 19376, 4439, 300, 500, 380, 362, 281, 312, 20928, 270, 6987, 1184, 565], "temperature": 0.0, "avg_logprob": -0.18198429009853265, "compression_ratio": 1.8111111111111111, "no_speech_prob": 1.7603356354811694e-06}, {"id": 239, "seek": 105768, "start": 1072.0800000000002, "end": 1080.44, "text": " Okay, and remember that when we are using pre computed activations data augmentation doesn't work right so even if you ask for a data", "tokens": [1033, 11, 293, 1604, 300, 562, 321, 366, 1228, 659, 40610, 2430, 763, 1412, 14501, 19631, 1177, 380, 589, 558, 370, 754, 498, 291, 1029, 337, 257, 1412], "temperature": 0.0, "avg_logprob": -0.18198429009853265, "compression_ratio": 1.8111111111111111, "no_speech_prob": 1.7603356354811694e-06}, {"id": 240, "seek": 105768, "start": 1080.68, "end": 1082.9, "text": " Augmentation if you've got pre compute equals true", "tokens": [6088, 19631, 498, 291, 600, 658, 659, 14722, 6915, 2074], "temperature": 0.0, "avg_logprob": -0.18198429009853265, "compression_ratio": 1.8111111111111111, "no_speech_prob": 1.7603356354811694e-06}, {"id": 241, "seek": 108290, "start": 1082.9, "end": 1088.5800000000002, "text": " It doesn't actually do any data augmentation because it's using the cached non augmented", "tokens": [467, 1177, 380, 767, 360, 604, 1412, 14501, 19631, 570, 309, 311, 1228, 264, 269, 15095, 2107, 36155], "temperature": 0.0, "avg_logprob": -0.1644687847215302, "compression_ratio": 1.6304347826086956, "no_speech_prob": 6.475939926531282e-07}, {"id": 242, "seek": 108290, "start": 1089.3400000000001, "end": 1090.6200000000001, "text": " activations", "tokens": [2430, 763], "temperature": 0.0, "avg_logprob": -0.1644687847215302, "compression_ratio": 1.6304347826086956, "no_speech_prob": 6.475939926531282e-07}, {"id": 243, "seek": 108290, "start": 1090.6200000000001, "end": 1095.22, "text": " So in this case to keep this as simple as possible. I have no pre computed anything going on", "tokens": [407, 294, 341, 1389, 281, 1066, 341, 382, 2199, 382, 1944, 13, 286, 362, 572, 659, 40610, 1340, 516, 322], "temperature": 0.0, "avg_logprob": -0.1644687847215302, "compression_ratio": 1.6304347826086956, "no_speech_prob": 6.475939926531282e-07}, {"id": 244, "seek": 108290, "start": 1095.6000000000001, "end": 1099.3400000000001, "text": " So I do three cycles of length one and", "tokens": [407, 286, 360, 1045, 17796, 295, 4641, 472, 293], "temperature": 0.0, "avg_logprob": -0.1644687847215302, "compression_ratio": 1.6304347826086956, "no_speech_prob": 6.475939926531282e-07}, {"id": 245, "seek": 108290, "start": 1100.3000000000002, "end": 1102.94, "text": " Then I can then unfreeze", "tokens": [1396, 286, 393, 550, 3971, 701, 1381], "temperature": 0.0, "avg_logprob": -0.1644687847215302, "compression_ratio": 1.6304347826086956, "no_speech_prob": 6.475939926531282e-07}, {"id": 246, "seek": 108290, "start": 1103.5400000000002, "end": 1105.5400000000002, "text": " So it's now got to train the whole thing", "tokens": [407, 309, 311, 586, 658, 281, 3847, 264, 1379, 551], "temperature": 0.0, "avg_logprob": -0.1644687847215302, "compression_ratio": 1.6304347826086956, "no_speech_prob": 6.475939926531282e-07}, {"id": 247, "seek": 108290, "start": 1106.42, "end": 1109.66, "text": " something we haven't seen before and we'll learn about in the second half is", "tokens": [746, 321, 2378, 380, 1612, 949, 293, 321, 603, 1466, 466, 294, 264, 1150, 1922, 307], "temperature": 0.0, "avg_logprob": -0.1644687847215302, "compression_ratio": 1.6304347826086956, "no_speech_prob": 6.475939926531282e-07}, {"id": 248, "seek": 110966, "start": 1109.66, "end": 1114.98, "text": " Called be and freeze for now all you need to know is that if you're using a", "tokens": [45001, 312, 293, 15959, 337, 586, 439, 291, 643, 281, 458, 307, 300, 498, 291, 434, 1228, 257], "temperature": 0.0, "avg_logprob": -0.20210913773421402, "compression_ratio": 1.6211453744493391, "no_speech_prob": 1.2679232668233453e-06}, {"id": 249, "seek": 110966, "start": 1115.5400000000002, "end": 1121.2, "text": " Model like a bigger deeper model like resnet 50 or res next 101", "tokens": [17105, 411, 257, 3801, 7731, 2316, 411, 725, 7129, 2625, 420, 725, 958, 21055], "temperature": 0.0, "avg_logprob": -0.20210913773421402, "compression_ratio": 1.6211453744493391, "no_speech_prob": 1.2679232668233453e-06}, {"id": 250, "seek": 110966, "start": 1121.5400000000002, "end": 1128.14, "text": " On a data set that's very very similar to image net like these cats and dogs data sets on other words", "tokens": [1282, 257, 1412, 992, 300, 311, 588, 588, 2531, 281, 3256, 2533, 411, 613, 11111, 293, 7197, 1412, 6352, 322, 661, 2283], "temperature": 0.0, "avg_logprob": -0.20210913773421402, "compression_ratio": 1.6211453744493391, "no_speech_prob": 1.2679232668233453e-06}, {"id": 251, "seek": 110966, "start": 1128.14, "end": 1131.8600000000001, "text": " It's like side on photos of standard objects", "tokens": [467, 311, 411, 1252, 322, 5787, 295, 3832, 6565], "temperature": 0.0, "avg_logprob": -0.20210913773421402, "compression_ratio": 1.6211453744493391, "no_speech_prob": 1.2679232668233453e-06}, {"id": 252, "seek": 110966, "start": 1131.8600000000001, "end": 1137.3400000000001, "text": " You know of a similar size to image net like somewhere between 200 and 500 pixels", "tokens": [509, 458, 295, 257, 2531, 2744, 281, 3256, 2533, 411, 4079, 1296, 2331, 293, 5923, 18668], "temperature": 0.0, "avg_logprob": -0.20210913773421402, "compression_ratio": 1.6211453744493391, "no_speech_prob": 1.2679232668233453e-06}, {"id": 253, "seek": 113734, "start": 1137.34, "end": 1140.34, "text": " You should probably add this line", "tokens": [509, 820, 1391, 909, 341, 1622], "temperature": 0.0, "avg_logprob": -0.1950066884358724, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.8572947030625073e-06}, {"id": 254, "seek": 113734, "start": 1140.8999999999999, "end": 1147.98, "text": " When you unfreeze for those of you that are more advanced what it's doing is it's it's causing the batch normalization", "tokens": [1133, 291, 3971, 701, 1381, 337, 729, 295, 291, 300, 366, 544, 7339, 437, 309, 311, 884, 307, 309, 311, 309, 311, 9853, 264, 15245, 2710, 2144], "temperature": 0.0, "avg_logprob": -0.1950066884358724, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.8572947030625073e-06}, {"id": 255, "seek": 113734, "start": 1148.82, "end": 1154.3799999999999, "text": " Moving averages to not be updated, but in the second half of this course you're going to learn all about why we do that", "tokens": [14242, 42257, 281, 406, 312, 10588, 11, 457, 294, 264, 1150, 1922, 295, 341, 1164, 291, 434, 516, 281, 1466, 439, 466, 983, 321, 360, 300], "temperature": 0.0, "avg_logprob": -0.1950066884358724, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.8572947030625073e-06}, {"id": 256, "seek": 113734, "start": 1154.3799999999999, "end": 1156.4599999999998, "text": " It's something that's not supported by any other library", "tokens": [467, 311, 746, 300, 311, 406, 8104, 538, 604, 661, 6405], "temperature": 0.0, "avg_logprob": -0.1950066884358724, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.8572947030625073e-06}, {"id": 257, "seek": 113734, "start": 1157.1, "end": 1161.72, "text": " But it turns out to be super important anyway, so we do one more epoch", "tokens": [583, 309, 4523, 484, 281, 312, 1687, 1021, 4033, 11, 370, 321, 360, 472, 544, 30992, 339], "temperature": 0.0, "avg_logprob": -0.1950066884358724, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.8572947030625073e-06}, {"id": 258, "seek": 113734, "start": 1162.54, "end": 1163.86, "text": " with", "tokens": [365], "temperature": 0.0, "avg_logprob": -0.1950066884358724, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.8572947030625073e-06}, {"id": 259, "seek": 113734, "start": 1163.86, "end": 1165.86, "text": " training the whole network", "tokens": [3097, 264, 1379, 3209], "temperature": 0.0, "avg_logprob": -0.1950066884358724, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.8572947030625073e-06}, {"id": 260, "seek": 116586, "start": 1165.86, "end": 1169.58, "text": " And then at the end we use test time augmentation", "tokens": [400, 550, 412, 264, 917, 321, 764, 1500, 565, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.1997486783057144, "compression_ratio": 1.5875, "no_speech_prob": 4.565918970911298e-06}, {"id": 261, "seek": 116586, "start": 1170.4199999999998, "end": 1177.2199999999998, "text": " To ensure that we get the best predictions we can and that gives us 99.45 percent", "tokens": [1407, 5586, 300, 321, 483, 264, 1151, 21264, 321, 393, 293, 300, 2709, 505, 11803, 13, 8465, 3043], "temperature": 0.0, "avg_logprob": -0.1997486783057144, "compression_ratio": 1.5875, "no_speech_prob": 4.565918970911298e-06}, {"id": 262, "seek": 116586, "start": 1178.1399999999999, "end": 1185.62, "text": " So that's that's it right so when you try a new data set. They're basically the minimum set of steps", "tokens": [407, 300, 311, 300, 311, 309, 558, 370, 562, 291, 853, 257, 777, 1412, 992, 13, 814, 434, 1936, 264, 7285, 992, 295, 4439], "temperature": 0.0, "avg_logprob": -0.1997486783057144, "compression_ratio": 1.5875, "no_speech_prob": 4.565918970911298e-06}, {"id": 263, "seek": 116586, "start": 1186.34, "end": 1188.34, "text": " That you would need to follow", "tokens": [663, 291, 576, 643, 281, 1524], "temperature": 0.0, "avg_logprob": -0.1997486783057144, "compression_ratio": 1.5875, "no_speech_prob": 4.565918970911298e-06}, {"id": 264, "seek": 116586, "start": 1188.3799999999999, "end": 1194.34, "text": " You'll notice this is assuming. I already know what learning right to use so you'd use a learning rate finder for that", "tokens": [509, 603, 3449, 341, 307, 11926, 13, 286, 1217, 458, 437, 2539, 558, 281, 764, 370, 291, 1116, 764, 257, 2539, 3314, 915, 260, 337, 300], "temperature": 0.0, "avg_logprob": -0.1997486783057144, "compression_ratio": 1.5875, "no_speech_prob": 4.565918970911298e-06}, {"id": 265, "seek": 119434, "start": 1194.34, "end": 1197.86, "text": " To assuming that I know that the directory layout", "tokens": [1407, 11926, 300, 286, 458, 300, 264, 21120, 13333], "temperature": 0.0, "avg_logprob": -0.22452220720114166, "compression_ratio": 1.6883720930232557, "no_speech_prob": 3.90546574635664e-06}, {"id": 266, "seek": 119434, "start": 1198.8999999999999, "end": 1200.8999999999999, "text": " and so forth", "tokens": [293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.22452220720114166, "compression_ratio": 1.6883720930232557, "no_speech_prob": 3.90546574635664e-06}, {"id": 267, "seek": 119434, "start": 1201.06, "end": 1205.06, "text": " So that's kind of a minimum set now one of the things that I wanted to make sure", "tokens": [407, 300, 311, 733, 295, 257, 7285, 992, 586, 472, 295, 264, 721, 300, 286, 1415, 281, 652, 988], "temperature": 0.0, "avg_logprob": -0.22452220720114166, "compression_ratio": 1.6883720930232557, "no_speech_prob": 3.90546574635664e-06}, {"id": 268, "seek": 119434, "start": 1205.82, "end": 1211.26, "text": " You had an understanding of how to do is how to use other libraries other than fast AI", "tokens": [509, 632, 364, 3701, 295, 577, 281, 360, 307, 577, 281, 764, 661, 15148, 661, 813, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.22452220720114166, "compression_ratio": 1.6883720930232557, "no_speech_prob": 3.90546574635664e-06}, {"id": 269, "seek": 119434, "start": 1211.86, "end": 1215.6999999999998, "text": " And so I feel like the best thing to look at is to look at Keras", "tokens": [400, 370, 286, 841, 411, 264, 1151, 551, 281, 574, 412, 307, 281, 574, 412, 591, 6985], "temperature": 0.0, "avg_logprob": -0.22452220720114166, "compression_ratio": 1.6883720930232557, "no_speech_prob": 3.90546574635664e-06}, {"id": 270, "seek": 119434, "start": 1216.1799999999998, "end": 1220.8999999999999, "text": " Because Keras is a library just like fast AI sits on top of pytorch", "tokens": [1436, 591, 6985, 307, 257, 6405, 445, 411, 2370, 7318, 12696, 322, 1192, 295, 25878, 284, 339], "temperature": 0.0, "avg_logprob": -0.22452220720114166, "compression_ratio": 1.6883720930232557, "no_speech_prob": 3.90546574635664e-06}, {"id": 271, "seek": 122090, "start": 1220.9, "end": 1225.7, "text": " Keras sits on top of actually a whole variety of different back ends it fits", "tokens": [591, 6985, 12696, 322, 1192, 295, 767, 257, 1379, 5673, 295, 819, 646, 5314, 309, 9001], "temperature": 0.0, "avg_logprob": -0.2057974442191746, "compression_ratio": 1.6017699115044248, "no_speech_prob": 4.356832960183965e-06}, {"id": 272, "seek": 122090, "start": 1226.3000000000002, "end": 1228.5400000000002, "text": " Mainly people nowadays use it with tensorflow", "tokens": [47468, 561, 13434, 764, 309, 365, 40863, 10565], "temperature": 0.0, "avg_logprob": -0.2057974442191746, "compression_ratio": 1.6017699115044248, "no_speech_prob": 4.356832960183965e-06}, {"id": 273, "seek": 122090, "start": 1229.26, "end": 1235.0600000000002, "text": " There's also an MX net version. There's also a Microsoft CNTK version", "tokens": [821, 311, 611, 364, 47509, 2533, 3037, 13, 821, 311, 611, 257, 8116, 14589, 51, 42, 3037], "temperature": 0.0, "avg_logprob": -0.2057974442191746, "compression_ratio": 1.6017699115044248, "no_speech_prob": 4.356832960183965e-06}, {"id": 274, "seek": 122090, "start": 1236.74, "end": 1240.18, "text": " So what I've got if you do a git pull you'll see that there's a", "tokens": [407, 437, 286, 600, 658, 498, 291, 360, 257, 18331, 2235, 291, 603, 536, 300, 456, 311, 257], "temperature": 0.0, "avg_logprob": -0.2057974442191746, "compression_ratio": 1.6017699115044248, "no_speech_prob": 4.356832960183965e-06}, {"id": 275, "seek": 122090, "start": 1242.3400000000001, "end": 1249.0600000000002, "text": " Something called Keras lesson one where I've attempted to replicate at least parts of lesson one in Keras", "tokens": [6595, 1219, 591, 6985, 6898, 472, 689, 286, 600, 18997, 281, 25356, 412, 1935, 3166, 295, 6898, 472, 294, 591, 6985], "temperature": 0.0, "avg_logprob": -0.2057974442191746, "compression_ratio": 1.6017699115044248, "no_speech_prob": 4.356832960183965e-06}, {"id": 276, "seek": 124906, "start": 1249.06, "end": 1250.26, "text": " just", "tokens": [445], "temperature": 0.0, "avg_logprob": -0.25409605843680244, "compression_ratio": 1.409356725146199, "no_speech_prob": 6.3390830291609745e-06}, {"id": 277, "seek": 124906, "start": 1250.26, "end": 1253.06, "text": " To give you a sense of how that works. Yeah", "tokens": [1407, 976, 291, 257, 2020, 295, 577, 300, 1985, 13, 865], "temperature": 0.0, "avg_logprob": -0.25409605843680244, "compression_ratio": 1.409356725146199, "no_speech_prob": 6.3390830291609745e-06}, {"id": 278, "seek": 124906, "start": 1258.06, "end": 1261.94, "text": " I'm not going to talk more about batch norm freeze now other than to say", "tokens": [286, 478, 406, 516, 281, 751, 544, 466, 15245, 2026, 15959, 586, 661, 813, 281, 584], "temperature": 0.0, "avg_logprob": -0.25409605843680244, "compression_ratio": 1.409356725146199, "no_speech_prob": 6.3390830291609745e-06}, {"id": 279, "seek": 124906, "start": 1262.74, "end": 1264.74, "text": " If you're using", "tokens": [759, 291, 434, 1228], "temperature": 0.0, "avg_logprob": -0.25409605843680244, "compression_ratio": 1.409356725146199, "no_speech_prob": 6.3390830291609745e-06}, {"id": 280, "seek": 124906, "start": 1264.86, "end": 1266.1, "text": " something", "tokens": [746], "temperature": 0.0, "avg_logprob": -0.25409605843680244, "compression_ratio": 1.409356725146199, "no_speech_prob": 6.3390830291609745e-06}, {"id": 281, "seek": 124906, "start": 1266.1, "end": 1272.6599999999999, "text": " Which has got a number larger than 34 at the end so like resnet 50 or res next 101 and you're", "tokens": [3013, 575, 658, 257, 1230, 4833, 813, 12790, 412, 264, 917, 370, 411, 725, 7129, 2625, 420, 725, 958, 21055, 293, 291, 434], "temperature": 0.0, "avg_logprob": -0.25409605843680244, "compression_ratio": 1.409356725146199, "no_speech_prob": 6.3390830291609745e-06}, {"id": 282, "seek": 127266, "start": 1272.66, "end": 1280.26, "text": " Trading a data set that has that is very similar to image net so it's like normal photos of normal sizes", "tokens": [49929, 257, 1412, 992, 300, 575, 300, 307, 588, 2531, 281, 3256, 2533, 370, 309, 311, 411, 2710, 5787, 295, 2710, 11602], "temperature": 0.0, "avg_logprob": -0.18652197999774284, "compression_ratio": 1.7350746268656716, "no_speech_prob": 2.2603132947551785e-06}, {"id": 283, "seek": 127266, "start": 1280.26, "end": 1287.24, "text": " Where the thing of interest takes up most of the frame then you probably should add the end freeze true after unfreeze", "tokens": [2305, 264, 551, 295, 1179, 2516, 493, 881, 295, 264, 3920, 550, 291, 1391, 820, 909, 264, 917, 15959, 2074, 934, 3971, 701, 1381], "temperature": 0.0, "avg_logprob": -0.18652197999774284, "compression_ratio": 1.7350746268656716, "no_speech_prob": 2.2603132947551785e-06}, {"id": 284, "seek": 127266, "start": 1287.7, "end": 1291.38, "text": " If in doubt try trading it with and then try trading it without", "tokens": [759, 294, 6385, 853, 9529, 309, 365, 293, 550, 853, 9529, 309, 1553], "temperature": 0.0, "avg_logprob": -0.18652197999774284, "compression_ratio": 1.7350746268656716, "no_speech_prob": 2.2603132947551785e-06}, {"id": 285, "seek": 127266, "start": 1292.74, "end": 1296.52, "text": " More advanced students will can certainly talk about it on the forums this week", "tokens": [5048, 7339, 1731, 486, 393, 3297, 751, 466, 309, 322, 264, 26998, 341, 1243], "temperature": 0.0, "avg_logprob": -0.18652197999774284, "compression_ratio": 1.7350746268656716, "no_speech_prob": 2.2603132947551785e-06}, {"id": 286, "seek": 127266, "start": 1296.52, "end": 1301.72, "text": " And we will be talking about the details of it in the second half of the course when we come back", "tokens": [400, 321, 486, 312, 1417, 466, 264, 4365, 295, 309, 294, 264, 1150, 1922, 295, 264, 1164, 562, 321, 808, 646], "temperature": 0.0, "avg_logprob": -0.18652197999774284, "compression_ratio": 1.7350746268656716, "no_speech_prob": 2.2603132947551785e-06}, {"id": 287, "seek": 130172, "start": 1301.72, "end": 1303.64, "text": " to our", "tokens": [281, 527], "temperature": 0.0, "avg_logprob": -0.21116645336151124, "compression_ratio": 1.6559139784946237, "no_speech_prob": 3.237734745198395e-06}, {"id": 288, "seek": 130172, "start": 1303.64, "end": 1305.64, "text": " CNN in depth section", "tokens": [24859, 294, 7161, 3541], "temperature": 0.0, "avg_logprob": -0.21116645336151124, "compression_ratio": 1.6559139784946237, "no_speech_prob": 3.237734745198395e-06}, {"id": 289, "seek": 130172, "start": 1306.1200000000001, "end": 1308.1200000000001, "text": " in the second last lesson", "tokens": [294, 264, 1150, 1036, 6898], "temperature": 0.0, "avg_logprob": -0.21116645336151124, "compression_ratio": 1.6559139784946237, "no_speech_prob": 3.237734745198395e-06}, {"id": 290, "seek": 130172, "start": 1312.3600000000001, "end": 1314.3600000000001, "text": " So with Keras", "tokens": [407, 365, 591, 6985], "temperature": 0.0, "avg_logprob": -0.21116645336151124, "compression_ratio": 1.6559139784946237, "no_speech_prob": 3.237734745198395e-06}, {"id": 291, "seek": 130172, "start": 1315.16, "end": 1318.1200000000001, "text": " again, we import a bunch of stuff and", "tokens": [797, 11, 321, 974, 257, 3840, 295, 1507, 293], "temperature": 0.0, "avg_logprob": -0.21116645336151124, "compression_ratio": 1.6559139784946237, "no_speech_prob": 3.237734745198395e-06}, {"id": 292, "seek": 130172, "start": 1321.0, "end": 1326.44, "text": " Remember I mentioned that this idea that you've got a thing called train and a thing called valid and inside that you've got a thing", "tokens": [5459, 286, 2835, 300, 341, 1558, 300, 291, 600, 658, 257, 551, 1219, 3847, 293, 257, 551, 1219, 7363, 293, 1854, 300, 291, 600, 658, 257, 551], "temperature": 0.0, "avg_logprob": -0.21116645336151124, "compression_ratio": 1.6559139784946237, "no_speech_prob": 3.237734745198395e-06}, {"id": 293, "seek": 130172, "start": 1326.44, "end": 1330.64, "text": " Called dogs and the things called cats is a standard way of providing", "tokens": [45001, 7197, 293, 264, 721, 1219, 11111, 307, 257, 3832, 636, 295, 6530], "temperature": 0.0, "avg_logprob": -0.21116645336151124, "compression_ratio": 1.6559139784946237, "no_speech_prob": 3.237734745198395e-06}, {"id": 294, "seek": 133064, "start": 1330.64, "end": 1332.64, "text": " image", "tokens": [3256], "temperature": 0.0, "avg_logprob": -0.21562323459359103, "compression_ratio": 1.7079207920792079, "no_speech_prob": 1.7880544191939407e-06}, {"id": 295, "seek": 133064, "start": 1332.64, "end": 1338.88, "text": " Labeled images so Keras does that too right so it's going to tell it where the training set and the validation set are", "tokens": [10137, 31689, 5267, 370, 591, 6985, 775, 300, 886, 558, 370, 309, 311, 516, 281, 980, 309, 689, 264, 3097, 992, 293, 264, 24071, 992, 366], "temperature": 0.0, "avg_logprob": -0.21562323459359103, "compression_ratio": 1.7079207920792079, "no_speech_prob": 1.7880544191939407e-06}, {"id": 296, "seek": 133064, "start": 1340.6000000000001, "end": 1342.92, "text": " Twice what batch size to use", "tokens": [46964, 437, 15245, 2744, 281, 764], "temperature": 0.0, "avg_logprob": -0.21562323459359103, "compression_ratio": 1.7079207920792079, "no_speech_prob": 1.7880544191939407e-06}, {"id": 297, "seek": 133064, "start": 1343.8400000000001, "end": 1350.72, "text": " Now you're noticing Keras we did much much much more code to do the same thing", "tokens": [823, 291, 434, 21814, 591, 6985, 321, 630, 709, 709, 709, 544, 3089, 281, 360, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.21562323459359103, "compression_ratio": 1.7079207920792079, "no_speech_prob": 1.7880544191939407e-06}, {"id": 298, "seek": 133064, "start": 1351.5600000000002, "end": 1357.72, "text": " More importantly each part of that code has many many many more things you have to set and if you set them wrong", "tokens": [5048, 8906, 1184, 644, 295, 300, 3089, 575, 867, 867, 867, 544, 721, 291, 362, 281, 992, 293, 498, 291, 992, 552, 2085], "temperature": 0.0, "avg_logprob": -0.21562323459359103, "compression_ratio": 1.7079207920792079, "no_speech_prob": 1.7880544191939407e-06}, {"id": 299, "seek": 135772, "start": 1357.72, "end": 1360.3600000000001, "text": " Everything breaks right so", "tokens": [5471, 9857, 558, 370], "temperature": 0.0, "avg_logprob": -0.20190001697075077, "compression_ratio": 1.6439024390243901, "no_speech_prob": 1.2878878123956383e-06}, {"id": 300, "seek": 135772, "start": 1362.68, "end": 1367.76, "text": " I'll give you a summary of what they are so you're basically rather than creating a single", "tokens": [286, 603, 976, 291, 257, 12691, 295, 437, 436, 366, 370, 291, 434, 1936, 2831, 813, 4084, 257, 2167], "temperature": 0.0, "avg_logprob": -0.20190001697075077, "compression_ratio": 1.6439024390243901, "no_speech_prob": 1.2878878123956383e-06}, {"id": 301, "seek": 135772, "start": 1368.56, "end": 1372.98, "text": " Data object in Keras we first of all have to define something called a data generator", "tokens": [11888, 2657, 294, 591, 6985, 321, 700, 295, 439, 362, 281, 6964, 746, 1219, 257, 1412, 19265], "temperature": 0.0, "avg_logprob": -0.20190001697075077, "compression_ratio": 1.6439024390243901, "no_speech_prob": 1.2878878123956383e-06}, {"id": 302, "seek": 135772, "start": 1373.56, "end": 1380.84, "text": " To say how to generate the data and so a data generator. We basically have to say what kind of data augmentation", "tokens": [1407, 584, 577, 281, 8460, 264, 1412, 293, 370, 257, 1412, 19265, 13, 492, 1936, 362, 281, 584, 437, 733, 295, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.20190001697075077, "compression_ratio": 1.6439024390243901, "no_speech_prob": 1.2878878123956383e-06}, {"id": 303, "seek": 135772, "start": 1381.6000000000001, "end": 1383.6000000000001, "text": " do we want to do and", "tokens": [360, 321, 528, 281, 360, 293], "temperature": 0.0, "avg_logprob": -0.20190001697075077, "compression_ratio": 1.6439024390243901, "no_speech_prob": 1.2878878123956383e-06}, {"id": 304, "seek": 138360, "start": 1383.6, "end": 1387.32, "text": " We also we actually have to say what kind of", "tokens": [492, 611, 321, 767, 362, 281, 584, 437, 733, 295], "temperature": 0.0, "avg_logprob": -0.18698612524538624, "compression_ratio": 1.6317991631799162, "no_speech_prob": 3.905453468178166e-06}, {"id": 305, "seek": 138360, "start": 1388.9199999999998, "end": 1390.0, "text": " Normalization", "tokens": [21277, 2144], "temperature": 0.0, "avg_logprob": -0.18698612524538624, "compression_ratio": 1.6317991631799162, "no_speech_prob": 3.905453468178166e-06}, {"id": 306, "seek": 138360, "start": 1390.0, "end": 1396.54, "text": " Do we want to do so where else with fast AI we just say whatever resnet 50 requires just do that for me", "tokens": [1144, 321, 528, 281, 360, 370, 689, 1646, 365, 2370, 7318, 321, 445, 584, 2035, 725, 7129, 2625, 7029, 445, 360, 300, 337, 385], "temperature": 0.0, "avg_logprob": -0.18698612524538624, "compression_ratio": 1.6317991631799162, "no_speech_prob": 3.905453468178166e-06}, {"id": 307, "seek": 138360, "start": 1396.54, "end": 1400.86, "text": " Please we actually have to kind of know a little bit about what's expected of us", "tokens": [2555, 321, 767, 362, 281, 733, 295, 458, 257, 707, 857, 466, 437, 311, 5176, 295, 505], "temperature": 0.0, "avg_logprob": -0.18698612524538624, "compression_ratio": 1.6317991631799162, "no_speech_prob": 3.905453468178166e-06}, {"id": 308, "seek": 138360, "start": 1401.8799999999999, "end": 1407.8, "text": " Generally speaking copy and pasting Keras code from the internet is a good way to make sure you've got the right the right stuff to", "tokens": [21082, 4124, 5055, 293, 1791, 278, 591, 6985, 3089, 490, 264, 4705, 307, 257, 665, 636, 281, 652, 988, 291, 600, 658, 264, 558, 264, 558, 1507, 281], "temperature": 0.0, "avg_logprob": -0.18698612524538624, "compression_ratio": 1.6317991631799162, "no_speech_prob": 3.905453468178166e-06}, {"id": 309, "seek": 138360, "start": 1407.8, "end": 1409.3999999999999, "text": " make that work", "tokens": [652, 300, 589], "temperature": 0.0, "avg_logprob": -0.18698612524538624, "compression_ratio": 1.6317991631799162, "no_speech_prob": 3.905453468178166e-06}, {"id": 310, "seek": 140940, "start": 1409.4, "end": 1416.02, "text": " And again, it doesn't have a kind of a standard set of like here are the best data augmentation parameters to use for photos", "tokens": [400, 797, 11, 309, 1177, 380, 362, 257, 733, 295, 257, 3832, 992, 295, 411, 510, 366, 264, 1151, 1412, 14501, 19631, 9834, 281, 764, 337, 5787], "temperature": 0.0, "avg_logprob": -0.14980644557787023, "compression_ratio": 1.7480314960629921, "no_speech_prob": 3.844903858407633e-06}, {"id": 311, "seek": 140940, "start": 1416.0400000000002, "end": 1419.7800000000002, "text": " So you know I've copied and pasted all of this from the Keras", "tokens": [407, 291, 458, 286, 600, 25365, 293, 1791, 292, 439, 295, 341, 490, 264, 591, 6985], "temperature": 0.0, "avg_logprob": -0.14980644557787023, "compression_ratio": 1.7480314960629921, "no_speech_prob": 3.844903858407633e-06}, {"id": 312, "seek": 140940, "start": 1421.0, "end": 1422.6000000000001, "text": " documentation", "tokens": [14333], "temperature": 0.0, "avg_logprob": -0.14980644557787023, "compression_ratio": 1.7480314960629921, "no_speech_prob": 3.844903858407633e-06}, {"id": 313, "seek": 140940, "start": 1422.6000000000001, "end": 1427.6000000000001, "text": " So I don't know if it's I don't think it's the best set to use at all, but it's the set that they're using in their", "tokens": [407, 286, 500, 380, 458, 498, 309, 311, 286, 500, 380, 519, 309, 311, 264, 1151, 992, 281, 764, 412, 439, 11, 457, 309, 311, 264, 992, 300, 436, 434, 1228, 294, 641], "temperature": 0.0, "avg_logprob": -0.14980644557787023, "compression_ratio": 1.7480314960629921, "no_speech_prob": 3.844903858407633e-06}, {"id": 314, "seek": 140940, "start": 1427.6000000000001, "end": 1428.48, "text": " Docs", "tokens": [16024, 82], "temperature": 0.0, "avg_logprob": -0.14980644557787023, "compression_ratio": 1.7480314960629921, "no_speech_prob": 3.844903858407633e-06}, {"id": 315, "seek": 140940, "start": 1428.48, "end": 1435.46, "text": " So having said this is how I want to generate data so horizontally flip sometimes you know zoom sometimes she is sometimes", "tokens": [407, 1419, 848, 341, 307, 577, 286, 528, 281, 8460, 1412, 370, 33796, 7929, 2171, 291, 458, 8863, 2171, 750, 307, 2171], "temperature": 0.0, "avg_logprob": -0.14980644557787023, "compression_ratio": 1.7480314960629921, "no_speech_prob": 3.844903858407633e-06}, {"id": 316, "seek": 143546, "start": 1435.46, "end": 1442.32, "text": " We then create a generator from that by taking that data generator and saying I want to generate", "tokens": [492, 550, 1884, 257, 19265, 490, 300, 538, 1940, 300, 1412, 19265, 293, 1566, 286, 528, 281, 8460], "temperature": 0.0, "avg_logprob": -0.17064989993446752, "compression_ratio": 1.8525345622119815, "no_speech_prob": 3.187542688465328e-06}, {"id": 317, "seek": 143546, "start": 1443.3600000000001, "end": 1447.72, "text": " Images by looking from a directory and we pass in the directory which is of the same", "tokens": [4331, 1660, 538, 1237, 490, 257, 21120, 293, 321, 1320, 294, 264, 21120, 597, 307, 295, 264, 912], "temperature": 0.0, "avg_logprob": -0.17064989993446752, "compression_ratio": 1.8525345622119815, "no_speech_prob": 3.187542688465328e-06}, {"id": 318, "seek": 143546, "start": 1448.3600000000001, "end": 1450.72, "text": " directory structure that fast AI uses and", "tokens": [21120, 3877, 300, 2370, 7318, 4960, 293], "temperature": 0.0, "avg_logprob": -0.17064989993446752, "compression_ratio": 1.8525345622119815, "no_speech_prob": 3.187542688465328e-06}, {"id": 319, "seek": 143546, "start": 1451.6000000000001, "end": 1454.76, "text": " You'll see there's some overlaps with kind of how fast AI works here", "tokens": [509, 603, 536, 456, 311, 512, 15986, 2382, 365, 733, 295, 577, 2370, 7318, 1985, 510], "temperature": 0.0, "avg_logprob": -0.17064989993446752, "compression_ratio": 1.8525345622119815, "no_speech_prob": 3.187542688465328e-06}, {"id": 320, "seek": 143546, "start": 1454.76, "end": 1460.4, "text": " You tell it what size images you want to create you tell it what batch size you want in your mini batches and", "tokens": [509, 980, 309, 437, 2744, 5267, 291, 528, 281, 1884, 291, 980, 309, 437, 15245, 2744, 291, 528, 294, 428, 8382, 15245, 279, 293], "temperature": 0.0, "avg_logprob": -0.17064989993446752, "compression_ratio": 1.8525345622119815, "no_speech_prob": 3.187542688465328e-06}, {"id": 321, "seek": 146040, "start": 1460.4, "end": 1466.4, "text": " Then there's something here not to worry about too much, but basically if you're just got two possible outcomes", "tokens": [1396, 456, 311, 746, 510, 406, 281, 3292, 466, 886, 709, 11, 457, 1936, 498, 291, 434, 445, 658, 732, 1944, 10070], "temperature": 0.0, "avg_logprob": -0.14179404707979565, "compression_ratio": 1.8075601374570447, "no_speech_prob": 3.3931103189388523e-06}, {"id": 322, "seek": 146040, "start": 1466.48, "end": 1473.2800000000002, "text": " You would generally say binary here if you've got multiple possible outcomes would say categorical. Yeah, so we've only got cats or dogs", "tokens": [509, 576, 5101, 584, 17434, 510, 498, 291, 600, 658, 3866, 1944, 10070, 576, 584, 19250, 804, 13, 865, 11, 370, 321, 600, 787, 658, 11111, 420, 7197], "temperature": 0.0, "avg_logprob": -0.14179404707979565, "compression_ratio": 1.8075601374570447, "no_speech_prob": 3.3931103189388523e-06}, {"id": 323, "seek": 146040, "start": 1473.5600000000002, "end": 1475.5600000000002, "text": " So it's binary", "tokens": [407, 309, 311, 17434], "temperature": 0.0, "avg_logprob": -0.14179404707979565, "compression_ratio": 1.8075601374570447, "no_speech_prob": 3.3931103189388523e-06}, {"id": 324, "seek": 146040, "start": 1476.4, "end": 1482.3200000000002, "text": " So an example of like where things get a little more complex is you have to do the same thing for the validation set", "tokens": [407, 364, 1365, 295, 411, 689, 721, 483, 257, 707, 544, 3997, 307, 291, 362, 281, 360, 264, 912, 551, 337, 264, 24071, 992], "temperature": 0.0, "avg_logprob": -0.14179404707979565, "compression_ratio": 1.8075601374570447, "no_speech_prob": 3.3931103189388523e-06}, {"id": 325, "seek": 146040, "start": 1482.3200000000002, "end": 1484.3200000000002, "text": " So it's up to you to create a data generator", "tokens": [407, 309, 311, 493, 281, 291, 281, 1884, 257, 1412, 19265], "temperature": 0.0, "avg_logprob": -0.14179404707979565, "compression_ratio": 1.8075601374570447, "no_speech_prob": 3.3931103189388523e-06}, {"id": 326, "seek": 148432, "start": 1484.32, "end": 1492.04, "text": " That doesn't have data orientation because obviously for the validation set unless you're using TTA that's gonna stuff things up", "tokens": [663, 1177, 380, 362, 1412, 14764, 570, 2745, 337, 264, 24071, 992, 5969, 291, 434, 1228, 314, 8241, 300, 311, 799, 1507, 721, 493], "temperature": 0.0, "avg_logprob": -0.19043689303927952, "compression_ratio": 1.8, "no_speech_prob": 4.860421995545039e-06}, {"id": 327, "seek": 148432, "start": 1492.76, "end": 1494.3999999999999, "text": " you also", "tokens": [291, 611], "temperature": 0.0, "avg_logprob": -0.19043689303927952, "compression_ratio": 1.8, "no_speech_prob": 4.860421995545039e-06}, {"id": 328, "seek": 148432, "start": 1494.3999999999999, "end": 1496.1599999999999, "text": " when you train", "tokens": [562, 291, 3847], "temperature": 0.0, "avg_logprob": -0.19043689303927952, "compression_ratio": 1.8, "no_speech_prob": 4.860421995545039e-06}, {"id": 329, "seek": 148432, "start": 1496.1599999999999, "end": 1501.6799999999998, "text": " You randomly reorder the images so that they're always shown in different orders to make it more random", "tokens": [509, 16979, 319, 4687, 264, 5267, 370, 300, 436, 434, 1009, 4898, 294, 819, 9470, 281, 652, 309, 544, 4974], "temperature": 0.0, "avg_logprob": -0.19043689303927952, "compression_ratio": 1.8, "no_speech_prob": 4.860421995545039e-06}, {"id": 330, "seek": 148432, "start": 1502.08, "end": 1504.08, "text": " but with the validation it's", "tokens": [457, 365, 264, 24071, 309, 311], "temperature": 0.0, "avg_logprob": -0.19043689303927952, "compression_ratio": 1.8, "no_speech_prob": 4.860421995545039e-06}, {"id": 331, "seek": 148432, "start": 1504.8, "end": 1509.8, "text": " Vital that you don't do that because if you shuffle the validation set you then can't track how well you're doing", "tokens": [48307, 300, 291, 500, 380, 360, 300, 570, 498, 291, 39426, 264, 24071, 992, 291, 550, 393, 380, 2837, 577, 731, 291, 434, 884], "temperature": 0.0, "avg_logprob": -0.19043689303927952, "compression_ratio": 1.8, "no_speech_prob": 4.860421995545039e-06}, {"id": 332, "seek": 148432, "start": 1509.8, "end": 1512.4399999999998, "text": " It's in a different order for the labels. That's a", "tokens": [467, 311, 294, 257, 819, 1668, 337, 264, 16949, 13, 663, 311, 257], "temperature": 0.0, "avg_logprob": -0.19043689303927952, "compression_ratio": 1.8, "no_speech_prob": 4.860421995545039e-06}, {"id": 333, "seek": 151244, "start": 1512.44, "end": 1513.6000000000001, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.20275753102404007, "compression_ratio": 1.6116071428571428, "no_speech_prob": 2.4824714728310937e-06}, {"id": 334, "seek": 151244, "start": 1513.6000000000001, "end": 1517.56, "text": " Basically, these are the kind of steps you have to do every time with Keras", "tokens": [8537, 11, 613, 366, 264, 733, 295, 4439, 291, 362, 281, 360, 633, 565, 365, 591, 6985], "temperature": 0.0, "avg_logprob": -0.20275753102404007, "compression_ratio": 1.6116071428571428, "no_speech_prob": 2.4824714728310937e-06}, {"id": 335, "seek": 151244, "start": 1520.3600000000001, "end": 1526.14, "text": " So again the reason I was using ResNet 50 for is Keras doesn't have ResNet 34 unfortunately", "tokens": [407, 797, 264, 1778, 286, 390, 1228, 5015, 31890, 2625, 337, 307, 591, 6985, 1177, 380, 362, 5015, 31890, 12790, 7015], "temperature": 0.0, "avg_logprob": -0.20275753102404007, "compression_ratio": 1.6116071428571428, "no_speech_prob": 2.4824714728310937e-06}, {"id": 336, "seek": 151244, "start": 1526.14, "end": 1529.72, "text": " So I just wanted to compare like with like so we've got to use ResNet 50 here", "tokens": [407, 286, 445, 1415, 281, 6794, 411, 365, 411, 370, 321, 600, 658, 281, 764, 5015, 31890, 2625, 510], "temperature": 0.0, "avg_logprob": -0.20275753102404007, "compression_ratio": 1.6116071428571428, "no_speech_prob": 2.4824714728310937e-06}, {"id": 337, "seek": 151244, "start": 1531.8400000000001, "end": 1539.28, "text": " There isn't the same idea with Keras of saying like construct a model that is suitable for this data set for me", "tokens": [821, 1943, 380, 264, 912, 1558, 365, 591, 6985, 295, 1566, 411, 7690, 257, 2316, 300, 307, 12873, 337, 341, 1412, 992, 337, 385], "temperature": 0.0, "avg_logprob": -0.20275753102404007, "compression_ratio": 1.6116071428571428, "no_speech_prob": 2.4824714728310937e-06}, {"id": 338, "seek": 153928, "start": 1539.28, "end": 1544.6, "text": " So you have to do it by hand right so the way you do it is to basically say this is my base model and", "tokens": [407, 291, 362, 281, 360, 309, 538, 1011, 558, 370, 264, 636, 291, 360, 309, 307, 281, 1936, 584, 341, 307, 452, 3096, 2316, 293], "temperature": 0.0, "avg_logprob": -0.14424083016135475, "compression_ratio": 1.8461538461538463, "no_speech_prob": 1.933351541083539e-06}, {"id": 339, "seek": 153928, "start": 1545.24, "end": 1548.12, "text": " Then you have to construct on top of that manually", "tokens": [1396, 291, 362, 281, 7690, 322, 1192, 295, 300, 16945], "temperature": 0.0, "avg_logprob": -0.14424083016135475, "compression_ratio": 1.8461538461538463, "no_speech_prob": 1.933351541083539e-06}, {"id": 340, "seek": 153928, "start": 1548.72, "end": 1553.76, "text": " The layers that you want to add and so by the end of this course you'll understand why it is that these", "tokens": [440, 7914, 300, 291, 528, 281, 909, 293, 370, 538, 264, 917, 295, 341, 1164, 291, 603, 1223, 983, 309, 307, 300, 613], "temperature": 0.0, "avg_logprob": -0.14424083016135475, "compression_ratio": 1.8461538461538463, "no_speech_prob": 1.933351541083539e-06}, {"id": 341, "seek": 153928, "start": 1554.36, "end": 1557.08, "text": " Particular three layers are the layers that we add", "tokens": [4100, 14646, 1045, 7914, 366, 264, 7914, 300, 321, 909], "temperature": 0.0, "avg_logprob": -0.14424083016135475, "compression_ratio": 1.8461538461538463, "no_speech_prob": 1.933351541083539e-06}, {"id": 342, "seek": 153928, "start": 1559.52, "end": 1562.48, "text": " So having done that in Keras you basically say okay", "tokens": [407, 1419, 1096, 300, 294, 591, 6985, 291, 1936, 584, 1392], "temperature": 0.0, "avg_logprob": -0.14424083016135475, "compression_ratio": 1.8461538461538463, "no_speech_prob": 1.933351541083539e-06}, {"id": 343, "seek": 156248, "start": 1562.48, "end": 1570.68, "text": " This is my model and then again there isn't like a concept of like automatically freezing things or an API for that", "tokens": [639, 307, 452, 2316, 293, 550, 797, 456, 1943, 380, 411, 257, 3410, 295, 411, 6772, 20200, 721, 420, 364, 9362, 337, 300], "temperature": 0.0, "avg_logprob": -0.17847671508789062, "compression_ratio": 1.6340425531914893, "no_speech_prob": 3.905462563125184e-06}, {"id": 344, "seek": 156248, "start": 1570.68, "end": 1578.88, "text": " So you just have to now loop through the layers that you want to freeze and call dot trainable equals false on them", "tokens": [407, 291, 445, 362, 281, 586, 6367, 807, 264, 7914, 300, 291, 528, 281, 15959, 293, 818, 5893, 3847, 712, 6915, 7908, 322, 552], "temperature": 0.0, "avg_logprob": -0.17847671508789062, "compression_ratio": 1.6340425531914893, "no_speech_prob": 3.905462563125184e-06}, {"id": 345, "seek": 156248, "start": 1580.08, "end": 1585.68, "text": " In Keras there's a concept. We don't have in fast AI or pytorch of compiling a model", "tokens": [682, 591, 6985, 456, 311, 257, 3410, 13, 492, 500, 380, 362, 294, 2370, 7318, 420, 25878, 284, 339, 295, 715, 4883, 257, 2316], "temperature": 0.0, "avg_logprob": -0.17847671508789062, "compression_ratio": 1.6340425531914893, "no_speech_prob": 3.905462563125184e-06}, {"id": 346, "seek": 156248, "start": 1585.68, "end": 1588.76, "text": " So basically once your model is ready to use you have to compile it", "tokens": [407, 1936, 1564, 428, 2316, 307, 1919, 281, 764, 291, 362, 281, 31413, 309], "temperature": 0.0, "avg_logprob": -0.17847671508789062, "compression_ratio": 1.6340425531914893, "no_speech_prob": 3.905462563125184e-06}, {"id": 347, "seek": 158876, "start": 1588.76, "end": 1596.0, "text": " Passing in what kind of optimizer to use what kind of loss to look for or what metrics so again with fast AI", "tokens": [10319, 278, 294, 437, 733, 295, 5028, 6545, 281, 764, 437, 733, 295, 4470, 281, 574, 337, 420, 437, 16367, 370, 797, 365, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.1468813214983259, "compression_ratio": 1.75390625, "no_speech_prob": 2.090449697789154e-06}, {"id": 348, "seek": 158876, "start": 1596.4, "end": 1602.68, "text": " You don't have to pass this in because we know what loss is the right loss to use you can always override it", "tokens": [509, 500, 380, 362, 281, 1320, 341, 294, 570, 321, 458, 437, 4470, 307, 264, 558, 4470, 281, 764, 291, 393, 1009, 42321, 309], "temperature": 0.0, "avg_logprob": -0.1468813214983259, "compression_ratio": 1.75390625, "no_speech_prob": 2.090449697789154e-06}, {"id": 349, "seek": 158876, "start": 1602.68, "end": 1605.08, "text": " But for a particular model we give you good defaults", "tokens": [583, 337, 257, 1729, 2316, 321, 976, 291, 665, 7576, 82], "temperature": 0.0, "avg_logprob": -0.1468813214983259, "compression_ratio": 1.75390625, "no_speech_prob": 2.090449697789154e-06}, {"id": 350, "seek": 158876, "start": 1606.08, "end": 1608.08, "text": " Okay, so having done all that", "tokens": [1033, 11, 370, 1419, 1096, 439, 300], "temperature": 0.0, "avg_logprob": -0.1468813214983259, "compression_ratio": 1.75390625, "no_speech_prob": 2.090449697789154e-06}, {"id": 351, "seek": 158876, "start": 1608.6, "end": 1611.04, "text": " Rather than calling fit you call fit generator", "tokens": [16571, 813, 5141, 3318, 291, 818, 3318, 19265], "temperature": 0.0, "avg_logprob": -0.1468813214983259, "compression_ratio": 1.75390625, "no_speech_prob": 2.090449697789154e-06}, {"id": 352, "seek": 161104, "start": 1611.04, "end": 1618.48, "text": " Passing in those two generators that you saw earlier the train generator and the validation generator for", "tokens": [10319, 278, 294, 729, 732, 38662, 300, 291, 1866, 3071, 264, 3847, 19265, 293, 264, 24071, 19265, 337], "temperature": 0.0, "avg_logprob": -0.19229853521917284, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.15733347836067e-06}, {"id": 353, "seek": 161104, "start": 1618.92, "end": 1624.08, "text": " Reasons I don't quite understand Keras expects you to also tell it how many batches there are per epoch", "tokens": [1300, 3646, 286, 500, 380, 1596, 1223, 591, 6985, 33280, 291, 281, 611, 980, 309, 577, 867, 15245, 279, 456, 366, 680, 30992, 339], "temperature": 0.0, "avg_logprob": -0.19229853521917284, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.15733347836067e-06}, {"id": 354, "seek": 161104, "start": 1625.02, "end": 1628.3999999999999, "text": " So the number of batches is equal to the size of the generator", "tokens": [407, 264, 1230, 295, 15245, 279, 307, 2681, 281, 264, 2744, 295, 264, 19265], "temperature": 0.0, "avg_logprob": -0.19229853521917284, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.15733347836067e-06}, {"id": 355, "seek": 161104, "start": 1629.28, "end": 1631.04, "text": " divided by the batch size", "tokens": [6666, 538, 264, 15245, 2744], "temperature": 0.0, "avg_logprob": -0.19229853521917284, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.15733347836067e-06}, {"id": 356, "seek": 161104, "start": 1631.04, "end": 1633.04, "text": " You can tell it how many epochs?", "tokens": [509, 393, 980, 309, 577, 867, 30992, 28346, 30], "temperature": 0.0, "avg_logprob": -0.19229853521917284, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.15733347836067e-06}, {"id": 357, "seek": 161104, "start": 1633.48, "end": 1635.48, "text": " just like in", "tokens": [445, 411, 294], "temperature": 0.0, "avg_logprob": -0.19229853521917284, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.15733347836067e-06}, {"id": 358, "seek": 161104, "start": 1635.48, "end": 1637.48, "text": " Fast AI you can say how many?", "tokens": [15968, 7318, 291, 393, 584, 577, 867, 30], "temperature": 0.0, "avg_logprob": -0.19229853521917284, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.15733347836067e-06}, {"id": 359, "seek": 163748, "start": 1637.48, "end": 1640.92, "text": " Processes or how many workers to use for pre-processing?", "tokens": [31093, 279, 420, 577, 867, 5600, 281, 764, 337, 659, 12, 41075, 278, 30], "temperature": 0.0, "avg_logprob": -0.21232332502092635, "compression_ratio": 1.4857142857142858, "no_speech_prob": 6.747984116373118e-06}, {"id": 360, "seek": 163748, "start": 1643.68, "end": 1647.52, "text": " Unlike fast AI the default in Keras is basically not to use any", "tokens": [17657, 2370, 7318, 264, 7576, 294, 591, 6985, 307, 1936, 406, 281, 764, 604], "temperature": 0.0, "avg_logprob": -0.21232332502092635, "compression_ratio": 1.4857142857142858, "no_speech_prob": 6.747984116373118e-06}, {"id": 361, "seek": 163748, "start": 1648.68, "end": 1652.64, "text": " So you to get good speed you're going to make sure you include this", "tokens": [407, 291, 281, 483, 665, 3073, 291, 434, 516, 281, 652, 988, 291, 4090, 341], "temperature": 0.0, "avg_logprob": -0.21232332502092635, "compression_ratio": 1.4857142857142858, "no_speech_prob": 6.747984116373118e-06}, {"id": 362, "seek": 163748, "start": 1653.84, "end": 1659.6, "text": " And so that's basically enough to start fine-tuning the last layers", "tokens": [400, 370, 300, 311, 1936, 1547, 281, 722, 2489, 12, 83, 37726, 264, 1036, 7914], "temperature": 0.0, "avg_logprob": -0.21232332502092635, "compression_ratio": 1.4857142857142858, "no_speech_prob": 6.747984116373118e-06}, {"id": 363, "seek": 163748, "start": 1662.84, "end": 1666.08, "text": " So as you can see I got to a validation accuracy of 95%", "tokens": [407, 382, 291, 393, 536, 286, 658, 281, 257, 24071, 14170, 295, 13420, 4], "temperature": 0.0, "avg_logprob": -0.21232332502092635, "compression_ratio": 1.4857142857142858, "no_speech_prob": 6.747984116373118e-06}, {"id": 364, "seek": 166608, "start": 1666.08, "end": 1667.08, "text": " 95%", "tokens": [13420, 4], "temperature": 0.0, "avg_logprob": -0.1552187306012294, "compression_ratio": 1.683673469387755, "no_speech_prob": 3.9054598346410785e-06}, {"id": 365, "seek": 166608, "start": 1667.08, "end": 1673.08, "text": " But as you can also see something really weird happened where after one it was like 49 and then it was 69 and then 95", "tokens": [583, 382, 291, 393, 611, 536, 746, 534, 3657, 2011, 689, 934, 472, 309, 390, 411, 16513, 293, 550, 309, 390, 28267, 293, 550, 13420], "temperature": 0.0, "avg_logprob": -0.1552187306012294, "compression_ratio": 1.683673469387755, "no_speech_prob": 3.9054598346410785e-06}, {"id": 366, "seek": 166608, "start": 1673.08, "end": 1674.96, "text": " I don't know", "tokens": [286, 500, 380, 458], "temperature": 0.0, "avg_logprob": -0.1552187306012294, "compression_ratio": 1.683673469387755, "no_speech_prob": 3.9054598346410785e-06}, {"id": 367, "seek": 166608, "start": 1674.96, "end": 1681.52, "text": " Why these are so low that's not normal. I may have there may be a bug in Keras. They may be a bug in my code", "tokens": [1545, 613, 366, 370, 2295, 300, 311, 406, 2710, 13, 286, 815, 362, 456, 815, 312, 257, 7426, 294, 591, 6985, 13, 814, 815, 312, 257, 7426, 294, 452, 3089], "temperature": 0.0, "avg_logprob": -0.1552187306012294, "compression_ratio": 1.683673469387755, "no_speech_prob": 3.9054598346410785e-06}, {"id": 368, "seek": 166608, "start": 1682.0, "end": 1688.12, "text": " I reached out on Twitter to see if anybody could figure it out, but they couldn't I guess this is one of the challenges with using", "tokens": [286, 6488, 484, 322, 5794, 281, 536, 498, 4472, 727, 2573, 309, 484, 11, 457, 436, 2809, 380, 286, 2041, 341, 307, 472, 295, 264, 4759, 365, 1228], "temperature": 0.0, "avg_logprob": -0.1552187306012294, "compression_ratio": 1.683673469387755, "no_speech_prob": 3.9054598346410785e-06}, {"id": 369, "seek": 166608, "start": 1688.9199999999998, "end": 1694.8, "text": " Something like this is one of the reasons I wanted to use fast AI for this course is it's much harder to screw things up", "tokens": [6595, 411, 341, 307, 472, 295, 264, 4112, 286, 1415, 281, 764, 2370, 7318, 337, 341, 1164, 307, 309, 311, 709, 6081, 281, 5630, 721, 493], "temperature": 0.0, "avg_logprob": -0.1552187306012294, "compression_ratio": 1.683673469387755, "no_speech_prob": 3.9054598346410785e-06}, {"id": 370, "seek": 169480, "start": 1694.8, "end": 1698.76, "text": " So I don't know if I screwed something up or somebody else did yes, you know", "tokens": [407, 286, 500, 380, 458, 498, 286, 20331, 746, 493, 420, 2618, 1646, 630, 2086, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.23365969990575036, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.500809953038697e-06}, {"id": 371, "seek": 169480, "start": 1702.24, "end": 1708.56, "text": " This is using the tensorflow back-end yeah, yeah, and if you want to run this to try it out yourself", "tokens": [639, 307, 1228, 264, 40863, 10565, 646, 12, 521, 1338, 11, 1338, 11, 293, 498, 291, 528, 281, 1190, 341, 281, 853, 309, 484, 1803], "temperature": 0.0, "avg_logprob": -0.23365969990575036, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.500809953038697e-06}, {"id": 372, "seek": 169480, "start": 1709.9199999999998, "end": 1712.56, "text": " You just can just go pip install", "tokens": [509, 445, 393, 445, 352, 8489, 3625], "temperature": 0.0, "avg_logprob": -0.23365969990575036, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.500809953038697e-06}, {"id": 373, "seek": 169480, "start": 1713.48, "end": 1715.36, "text": " tensorflow dash", "tokens": [40863, 10565, 8240], "temperature": 0.0, "avg_logprob": -0.23365969990575036, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.500809953038697e-06}, {"id": 374, "seek": 169480, "start": 1715.36, "end": 1717.04, "text": " GPU", "tokens": [18407], "temperature": 0.0, "avg_logprob": -0.23365969990575036, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.500809953038697e-06}, {"id": 375, "seek": 169480, "start": 1717.04, "end": 1718.56, "text": " Keras", "tokens": [591, 6985], "temperature": 0.0, "avg_logprob": -0.23365969990575036, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.500809953038697e-06}, {"id": 376, "seek": 169480, "start": 1718.56, "end": 1722.76, "text": " Okay, because it's not part of the fast AI environment by default", "tokens": [1033, 11, 570, 309, 311, 406, 644, 295, 264, 2370, 7318, 2823, 538, 7576], "temperature": 0.0, "avg_logprob": -0.23365969990575036, "compression_ratio": 1.4660194174757282, "no_speech_prob": 3.500809953038697e-06}, {"id": 377, "seek": 172276, "start": 1722.76, "end": 1727.6, "text": " But that should be all you need to do to get that working", "tokens": [583, 300, 820, 312, 439, 291, 643, 281, 360, 281, 483, 300, 1364], "temperature": 0.0, "avg_logprob": -0.11719625646417792, "compression_ratio": 1.6055045871559632, "no_speech_prob": 3.3931171401491156e-06}, {"id": 378, "seek": 172276, "start": 1732.2, "end": 1734.16, "text": " So then", "tokens": [407, 550], "temperature": 0.0, "avg_logprob": -0.11719625646417792, "compression_ratio": 1.6055045871559632, "no_speech_prob": 3.3931171401491156e-06}, {"id": 379, "seek": 172276, "start": 1734.16, "end": 1740.5, "text": " There isn't a concept of like layer groups or differential learning rates or partial unfreezing or whatever", "tokens": [821, 1943, 380, 257, 3410, 295, 411, 4583, 3935, 420, 15756, 2539, 6846, 420, 14641, 3971, 701, 8781, 420, 2035], "temperature": 0.0, "avg_logprob": -0.11719625646417792, "compression_ratio": 1.6055045871559632, "no_speech_prob": 3.3931171401491156e-06}, {"id": 380, "seek": 172276, "start": 1740.5, "end": 1744.48, "text": " So you have to decide like I had to print out all of the layers and decide manually", "tokens": [407, 291, 362, 281, 4536, 411, 286, 632, 281, 4482, 484, 439, 295, 264, 7914, 293, 4536, 16945], "temperature": 0.0, "avg_logprob": -0.11719625646417792, "compression_ratio": 1.6055045871559632, "no_speech_prob": 3.3931171401491156e-06}, {"id": 381, "seek": 172276, "start": 1745.04, "end": 1750.36, "text": " How many I wanted to fine-tune so I decided to fine-tune everything from a layer 140 onwards", "tokens": [1012, 867, 286, 1415, 281, 2489, 12, 83, 2613, 370, 286, 3047, 281, 2489, 12, 83, 2613, 1203, 490, 257, 4583, 21548, 34230], "temperature": 0.0, "avg_logprob": -0.11719625646417792, "compression_ratio": 1.6055045871559632, "no_speech_prob": 3.3931171401491156e-06}, {"id": 382, "seek": 175036, "start": 1750.36, "end": 1755.6, "text": " So that's why I just look through like this after you change that you have to recompile the model", "tokens": [407, 300, 311, 983, 286, 445, 574, 807, 411, 341, 934, 291, 1319, 300, 291, 362, 281, 48000, 794, 264, 2316], "temperature": 0.0, "avg_logprob": -0.11226410908741993, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.24086351308506e-06}, {"id": 383, "seek": 175036, "start": 1756.12, "end": 1759.6, "text": " And then after that I then ran another step and again", "tokens": [400, 550, 934, 300, 286, 550, 5872, 1071, 1823, 293, 797], "temperature": 0.0, "avg_logprob": -0.11226410908741993, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.24086351308506e-06}, {"id": 384, "seek": 175036, "start": 1759.6, "end": 1765.1999999999998, "text": " I don't know what happened here the accuracy of the training set stayed about the same but the validation set totally fell in", "tokens": [286, 500, 380, 458, 437, 2011, 510, 264, 14170, 295, 264, 3097, 992, 9181, 466, 264, 912, 457, 264, 24071, 992, 3879, 5696, 294], "temperature": 0.0, "avg_logprob": -0.11226410908741993, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.24086351308506e-06}, {"id": 385, "seek": 175036, "start": 1765.1999999999998, "end": 1767.12, "text": " the hole", "tokens": [264, 5458], "temperature": 0.0, "avg_logprob": -0.11226410908741993, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.24086351308506e-06}, {"id": 386, "seek": 175036, "start": 1767.12, "end": 1771.1999999999998, "text": " But I mean the main thing to note is even if we put aside the validation set", "tokens": [583, 286, 914, 264, 2135, 551, 281, 3637, 307, 754, 498, 321, 829, 7359, 264, 24071, 992], "temperature": 0.0, "avg_logprob": -0.11226410908741993, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.24086351308506e-06}, {"id": 387, "seek": 175036, "start": 1772.3999999999999, "end": 1776.3999999999999, "text": " We're getting I mean, I guess the main thing is there's a hell of a lot more code here", "tokens": [492, 434, 1242, 286, 914, 11, 286, 2041, 264, 2135, 551, 307, 456, 311, 257, 4921, 295, 257, 688, 544, 3089, 510], "temperature": 0.0, "avg_logprob": -0.11226410908741993, "compression_ratio": 1.7509727626459144, "no_speech_prob": 6.24086351308506e-06}, {"id": 388, "seek": 177640, "start": 1776.4, "end": 1782.92, "text": " Which is kind of annoying but also the performance is very different so we're also here even on the training set", "tokens": [3013, 307, 733, 295, 11304, 457, 611, 264, 3389, 307, 588, 819, 370, 321, 434, 611, 510, 754, 322, 264, 3097, 992], "temperature": 0.0, "avg_logprob": -0.24733606974283853, "compression_ratio": 1.5809523809523809, "no_speech_prob": 1.3496951396518853e-06}, {"id": 389, "seek": 177640, "start": 1782.92, "end": 1788.72, "text": " We were getting like 97 percent after four epochs that took a total of about eight minutes", "tokens": [492, 645, 1242, 411, 23399, 3043, 934, 1451, 30992, 28346, 300, 1890, 257, 3217, 295, 466, 3180, 2077], "temperature": 0.0, "avg_logprob": -0.24733606974283853, "compression_ratio": 1.5809523809523809, "no_speech_prob": 1.3496951396518853e-06}, {"id": 390, "seek": 177640, "start": 1789.2, "end": 1791.2, "text": " You know over here we had", "tokens": [509, 458, 670, 510, 321, 632], "temperature": 0.0, "avg_logprob": -0.24733606974283853, "compression_ratio": 1.5809523809523809, "no_speech_prob": 1.3496951396518853e-06}, {"id": 391, "seek": 177640, "start": 1792.3600000000001, "end": 1798.16, "text": " 99.5 percent on the validation set and it ran a lot faster, so it's like", "tokens": [11803, 13, 20, 3043, 322, 264, 24071, 992, 293, 309, 5872, 257, 688, 4663, 11, 370, 309, 311, 411], "temperature": 0.0, "avg_logprob": -0.24733606974283853, "compression_ratio": 1.5809523809523809, "no_speech_prob": 1.3496951396518853e-06}, {"id": 392, "seek": 177640, "start": 1799.1200000000001, "end": 1801.1200000000001, "text": " four or five minutes", "tokens": [1451, 420, 1732, 2077], "temperature": 0.0, "avg_logprob": -0.24733606974283853, "compression_ratio": 1.5809523809523809, "no_speech_prob": 1.3496951396518853e-06}, {"id": 393, "seek": 177640, "start": 1801.0400000000002, "end": 1802.92, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.24733606974283853, "compression_ratio": 1.5809523809523809, "no_speech_prob": 1.3496951396518853e-06}, {"id": 394, "seek": 177640, "start": 1802.92, "end": 1804.92, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.24733606974283853, "compression_ratio": 1.5809523809523809, "no_speech_prob": 1.3496951396518853e-06}, {"id": 395, "seek": 180492, "start": 1804.92, "end": 1806.92, "text": " um", "tokens": [1105], "temperature": 0.0, "avg_logprob": -0.19268641360970432, "compression_ratio": 1.7395348837209301, "no_speech_prob": 6.540355116158025e-06}, {"id": 396, "seek": 180492, "start": 1807.3600000000001, "end": 1812.9, "text": " Depending on what you do particularly if you end up wanting to deploy stuff to mobile devices at the moment", "tokens": [22539, 322, 437, 291, 360, 4098, 498, 291, 917, 493, 7935, 281, 7274, 1507, 281, 6013, 5759, 412, 264, 1623], "temperature": 0.0, "avg_logprob": -0.19268641360970432, "compression_ratio": 1.7395348837209301, "no_speech_prob": 6.540355116158025e-06}, {"id": 397, "seek": 180492, "start": 1814.0800000000002, "end": 1818.04, "text": " The kind of pie torch on mobile situation is very early", "tokens": [440, 733, 295, 1730, 27822, 322, 6013, 2590, 307, 588, 2440], "temperature": 0.0, "avg_logprob": -0.19268641360970432, "compression_ratio": 1.7395348837209301, "no_speech_prob": 6.540355116158025e-06}, {"id": 398, "seek": 180492, "start": 1818.24, "end": 1824.2, "text": " So you may find yourself wanting to use tensorflow or you may work for a company that's kind of settled on tensorflow", "tokens": [407, 291, 815, 915, 1803, 7935, 281, 764, 40863, 10565, 420, 291, 815, 589, 337, 257, 2237, 300, 311, 733, 295, 14819, 322, 40863, 10565], "temperature": 0.0, "avg_logprob": -0.19268641360970432, "compression_ratio": 1.7395348837209301, "no_speech_prob": 6.540355116158025e-06}, {"id": 399, "seek": 180492, "start": 1825.48, "end": 1830.28, "text": " So if you need to convert something like redo something you've learned here in tensorflow", "tokens": [407, 498, 291, 643, 281, 7620, 746, 411, 29956, 746, 291, 600, 3264, 510, 294, 40863, 10565], "temperature": 0.0, "avg_logprob": -0.19268641360970432, "compression_ratio": 1.7395348837209301, "no_speech_prob": 6.540355116158025e-06}, {"id": 400, "seek": 183028, "start": 1830.28, "end": 1835.2, "text": " You probably want to do it with Keras, but just recognize", "tokens": [509, 1391, 528, 281, 360, 309, 365, 591, 6985, 11, 457, 445, 5521], "temperature": 0.0, "avg_logprob": -0.2003860971202021, "compression_ratio": 1.7004219409282701, "no_speech_prob": 1.6797231410237146e-06}, {"id": 401, "seek": 183028, "start": 1835.8, "end": 1838.72, "text": " you know it's going to take a bit more work to get there and", "tokens": [291, 458, 309, 311, 516, 281, 747, 257, 857, 544, 589, 281, 483, 456, 293], "temperature": 0.0, "avg_logprob": -0.2003860971202021, "compression_ratio": 1.7004219409282701, "no_speech_prob": 1.6797231410237146e-06}, {"id": 402, "seek": 183028, "start": 1840.12, "end": 1846.16, "text": " By default it's much harder to get I mean I to get the same state-of-the-art results you get with fast AI", "tokens": [3146, 7576, 309, 311, 709, 6081, 281, 483, 286, 914, 286, 281, 483, 264, 912, 1785, 12, 2670, 12, 3322, 12, 446, 3542, 291, 483, 365, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.2003860971202021, "compression_ratio": 1.7004219409282701, "no_speech_prob": 1.6797231410237146e-06}, {"id": 403, "seek": 183028, "start": 1846.16, "end": 1849.68, "text": " You'd have to like replicate all of the state-of-the-art", "tokens": [509, 1116, 362, 281, 411, 25356, 439, 295, 264, 1785, 12, 2670, 12, 3322, 12, 446], "temperature": 0.0, "avg_logprob": -0.2003860971202021, "compression_ratio": 1.7004219409282701, "no_speech_prob": 1.6797231410237146e-06}, {"id": 404, "seek": 183028, "start": 1850.44, "end": 1853.32, "text": " Algorithms that are in fast AI so it's hard to get the same", "tokens": [35014, 6819, 2592, 300, 366, 294, 2370, 7318, 370, 309, 311, 1152, 281, 483, 264, 912], "temperature": 0.0, "avg_logprob": -0.2003860971202021, "compression_ratio": 1.7004219409282701, "no_speech_prob": 1.6797231410237146e-06}, {"id": 405, "seek": 183028, "start": 1854.08, "end": 1858.6, "text": " Level of results, but you can say the basic ideas are similar", "tokens": [16872, 295, 3542, 11, 457, 291, 393, 584, 264, 3875, 3487, 366, 2531], "temperature": 0.0, "avg_logprob": -0.2003860971202021, "compression_ratio": 1.7004219409282701, "no_speech_prob": 1.6797231410237146e-06}, {"id": 406, "seek": 185860, "start": 1858.6, "end": 1860.6, "text": " Okay, and it's certainly", "tokens": [1033, 11, 293, 309, 311, 3297], "temperature": 0.0, "avg_logprob": -0.20514534740913204, "compression_ratio": 1.8281786941580755, "no_speech_prob": 1.0511457730899565e-06}, {"id": 407, "seek": 185860, "start": 1861.1599999999999, "end": 1863.0, "text": " It's certainly possible", "tokens": [467, 311, 3297, 1944], "temperature": 0.0, "avg_logprob": -0.20514534740913204, "compression_ratio": 1.8281786941580755, "no_speech_prob": 1.0511457730899565e-06}, {"id": 408, "seek": 185860, "start": 1863.0, "end": 1867.3999999999999, "text": " You know like there's nothing I'm doing in fast AI that like would be impossible", "tokens": [509, 458, 411, 456, 311, 1825, 286, 478, 884, 294, 2370, 7318, 300, 411, 576, 312, 6243], "temperature": 0.0, "avg_logprob": -0.20514534740913204, "compression_ratio": 1.8281786941580755, "no_speech_prob": 1.0511457730899565e-06}, {"id": 409, "seek": 185860, "start": 1867.3999999999999, "end": 1871.28, "text": " but like you would have to implement stochastic gradient descent with restarts you would have to", "tokens": [457, 411, 291, 576, 362, 281, 4445, 342, 8997, 2750, 16235, 23475, 365, 1472, 11814, 291, 576, 362, 281], "temperature": 0.0, "avg_logprob": -0.20514534740913204, "compression_ratio": 1.8281786941580755, "no_speech_prob": 1.0511457730899565e-06}, {"id": 410, "seek": 185860, "start": 1872.36, "end": 1876.6799999999998, "text": " Implement differential learning rates you would have to implement batch norm freezing", "tokens": [4331, 43704, 15756, 2539, 6846, 291, 576, 362, 281, 4445, 15245, 2026, 20200], "temperature": 0.0, "avg_logprob": -0.20514534740913204, "compression_ratio": 1.8281786941580755, "no_speech_prob": 1.0511457730899565e-06}, {"id": 411, "seek": 185860, "start": 1877.3999999999999, "end": 1881.0, "text": " Which you probably don't want to do I know well that's not quite true", "tokens": [3013, 291, 1391, 500, 380, 528, 281, 360, 286, 458, 731, 300, 311, 406, 1596, 2074], "temperature": 0.0, "avg_logprob": -0.20514534740913204, "compression_ratio": 1.8281786941580755, "no_speech_prob": 1.0511457730899565e-06}, {"id": 412, "seek": 185860, "start": 1881.0, "end": 1883.12, "text": " I think somewhat one person at least on the forum is", "tokens": [286, 519, 8344, 472, 954, 412, 1935, 322, 264, 17542, 307], "temperature": 0.0, "avg_logprob": -0.20514534740913204, "compression_ratio": 1.8281786941580755, "no_speech_prob": 1.0511457730899565e-06}, {"id": 413, "seek": 188312, "start": 1883.12, "end": 1890.6399999999999, "text": " Attempting to create a Keras compatible version of or a tensorflow compatible version of fast AI which I think I hope we'll get there", "tokens": [7298, 4543, 278, 281, 1884, 257, 591, 6985, 18218, 3037, 295, 420, 257, 40863, 10565, 18218, 3037, 295, 2370, 7318, 597, 286, 519, 286, 1454, 321, 603, 483, 456], "temperature": 0.0, "avg_logprob": -0.16845186180043442, "compression_ratio": 1.6865079365079365, "no_speech_prob": 5.955052074568812e-06}, {"id": 414, "seek": 188312, "start": 1890.6399999999999, "end": 1896.6399999999999, "text": " I actually spoke to Google about this a few weeks ago, and they're very interested in getting fast AI ported to tensorflow", "tokens": [286, 767, 7179, 281, 3329, 466, 341, 257, 1326, 3259, 2057, 11, 293, 436, 434, 588, 3102, 294, 1242, 2370, 7318, 2436, 292, 281, 40863, 10565], "temperature": 0.0, "avg_logprob": -0.16845186180043442, "compression_ratio": 1.6865079365079365, "no_speech_prob": 5.955052074568812e-06}, {"id": 415, "seek": 188312, "start": 1897.1599999999999, "end": 1901.8999999999999, "text": " So maybe by the time you're looking at this on the MOOC. Maybe that will exist. I certainly hope so", "tokens": [407, 1310, 538, 264, 565, 291, 434, 1237, 412, 341, 322, 264, 49197, 34, 13, 2704, 300, 486, 2514, 13, 286, 3297, 1454, 370], "temperature": 0.0, "avg_logprob": -0.16845186180043442, "compression_ratio": 1.6865079365079365, "no_speech_prob": 5.955052074568812e-06}, {"id": 416, "seek": 188312, "start": 1902.6799999999998, "end": 1904.6799999999998, "text": " We will see", "tokens": [492, 486, 536], "temperature": 0.0, "avg_logprob": -0.16845186180043442, "compression_ratio": 1.6865079365079365, "no_speech_prob": 5.955052074568812e-06}, {"id": 417, "seek": 188312, "start": 1905.7199999999998, "end": 1909.9799999999998, "text": " Anyway so Keras is Keras in tensorflow was certainly not", "tokens": [5684, 370, 591, 6985, 307, 591, 6985, 294, 40863, 10565, 390, 3297, 406], "temperature": 0.0, "avg_logprob": -0.16845186180043442, "compression_ratio": 1.6865079365079365, "no_speech_prob": 5.955052074568812e-06}, {"id": 418, "seek": 190998, "start": 1909.98, "end": 1911.98, "text": " You know", "tokens": [509, 458], "temperature": 0.0, "avg_logprob": -0.1648050880432129, "compression_ratio": 1.5617529880478087, "no_speech_prob": 1.9333451746206265e-06}, {"id": 419, "seek": 190998, "start": 1913.02, "end": 1917.66, "text": " That difficult to handle and so I don't think you should worry if you're told you have to learn them", "tokens": [663, 2252, 281, 4813, 293, 370, 286, 500, 380, 519, 291, 820, 3292, 498, 291, 434, 1907, 291, 362, 281, 1466, 552], "temperature": 0.0, "avg_logprob": -0.1648050880432129, "compression_ratio": 1.5617529880478087, "no_speech_prob": 1.9333451746206265e-06}, {"id": 420, "seek": 190998, "start": 1918.18, "end": 1922.1, "text": " After this course for some reason it'll only take you a couple of days. I'm sure", "tokens": [2381, 341, 1164, 337, 512, 1778, 309, 603, 787, 747, 291, 257, 1916, 295, 1708, 13, 286, 478, 988], "temperature": 0.0, "avg_logprob": -0.1648050880432129, "compression_ratio": 1.5617529880478087, "no_speech_prob": 1.9333451746206265e-06}, {"id": 421, "seek": 190998, "start": 1926.46, "end": 1930.82, "text": " So that's kind of most of the stuff you would need to", "tokens": [407, 300, 311, 733, 295, 881, 295, 264, 1507, 291, 576, 643, 281], "temperature": 0.0, "avg_logprob": -0.1648050880432129, "compression_ratio": 1.5617529880478087, "no_speech_prob": 1.9333451746206265e-06}, {"id": 422, "seek": 190998, "start": 1931.6200000000001, "end": 1934.52, "text": " Kind of complete this this kind of assignment from last week", "tokens": [9242, 295, 3566, 341, 341, 733, 295, 15187, 490, 1036, 1243], "temperature": 0.0, "avg_logprob": -0.1648050880432129, "compression_ratio": 1.5617529880478087, "no_speech_prob": 1.9333451746206265e-06}, {"id": 423, "seek": 190998, "start": 1934.52, "end": 1938.72, "text": " Which is like try to do everything you've seen already, but on the dog breeds data set", "tokens": [3013, 307, 411, 853, 281, 360, 1203, 291, 600, 1612, 1217, 11, 457, 322, 264, 3000, 41609, 1412, 992], "temperature": 0.0, "avg_logprob": -0.1648050880432129, "compression_ratio": 1.5617529880478087, "no_speech_prob": 1.9333451746206265e-06}, {"id": 424, "seek": 193872, "start": 1938.72, "end": 1940.72, "text": " And just to remind you", "tokens": [400, 445, 281, 4160, 291], "temperature": 0.0, "avg_logprob": -0.15873552738935098, "compression_ratio": 1.669767441860465, "no_speech_prob": 3.905446646967903e-06}, {"id": 425, "seek": 193872, "start": 1941.32, "end": 1949.0, "text": " The kind of last few minutes of last week's lesson. I show you how to do much of that", "tokens": [440, 733, 295, 1036, 1326, 2077, 295, 1036, 1243, 311, 6898, 13, 286, 855, 291, 577, 281, 360, 709, 295, 300], "temperature": 0.0, "avg_logprob": -0.15873552738935098, "compression_ratio": 1.669767441860465, "no_speech_prob": 3.905446646967903e-06}, {"id": 426, "seek": 193872, "start": 1950.2, "end": 1957.92, "text": " Including like how I actually explored the data to find out like what the classes were and how big the images were and stuff like that", "tokens": [27137, 411, 577, 286, 767, 24016, 264, 1412, 281, 915, 484, 411, 437, 264, 5359, 645, 293, 577, 955, 264, 5267, 645, 293, 1507, 411, 300], "temperature": 0.0, "avg_logprob": -0.15873552738935098, "compression_ratio": 1.669767441860465, "no_speech_prob": 3.905446646967903e-06}, {"id": 427, "seek": 193872, "start": 1957.92, "end": 1964.28, "text": " Right so if you've forgotten that or didn't quite follow it all last week check out the video from last week to see", "tokens": [1779, 370, 498, 291, 600, 11832, 300, 420, 994, 380, 1596, 1524, 309, 439, 1036, 1243, 1520, 484, 264, 960, 490, 1036, 1243, 281, 536], "temperature": 0.0, "avg_logprob": -0.15873552738935098, "compression_ratio": 1.669767441860465, "no_speech_prob": 3.905446646967903e-06}, {"id": 428, "seek": 196428, "start": 1964.28, "end": 1971.24, "text": " One thing that we didn't talk about is how do you actually submit to Kaggle? So how do you actually get predictions?", "tokens": [1485, 551, 300, 321, 994, 380, 751, 466, 307, 577, 360, 291, 767, 10315, 281, 48751, 22631, 30, 407, 577, 360, 291, 767, 483, 21264, 30], "temperature": 0.0, "avg_logprob": -0.15113329254420457, "compression_ratio": 1.7061068702290076, "no_speech_prob": 4.565930794342421e-06}, {"id": 429, "seek": 196428, "start": 1971.76, "end": 1974.2, "text": " So I just wanted to show you that last piece as well", "tokens": [407, 286, 445, 1415, 281, 855, 291, 300, 1036, 2522, 382, 731], "temperature": 0.0, "avg_logprob": -0.15113329254420457, "compression_ratio": 1.7061068702290076, "no_speech_prob": 4.565930794342421e-06}, {"id": 430, "seek": 196428, "start": 1974.84, "end": 1980.0, "text": " And on the wiki thread this week. I've already put a little image of this to show you these steps", "tokens": [400, 322, 264, 261, 9850, 7207, 341, 1243, 13, 286, 600, 1217, 829, 257, 707, 3256, 295, 341, 281, 855, 291, 613, 4439], "temperature": 0.0, "avg_logprob": -0.15113329254420457, "compression_ratio": 1.7061068702290076, "no_speech_prob": 4.565930794342421e-06}, {"id": 431, "seek": 196428, "start": 1981.04, "end": 1983.04, "text": " But if you go to the Kaggle", "tokens": [583, 498, 291, 352, 281, 264, 48751, 22631], "temperature": 0.0, "avg_logprob": -0.15113329254420457, "compression_ratio": 1.7061068702290076, "no_speech_prob": 4.565930794342421e-06}, {"id": 432, "seek": 196428, "start": 1983.6, "end": 1990.96, "text": " Website for every competition there's a section called evaluation and they tell you what to submit and so I just copied and pasted these", "tokens": [45347, 642, 337, 633, 6211, 456, 311, 257, 3541, 1219, 13344, 293, 436, 980, 291, 437, 281, 10315, 293, 370, 286, 445, 25365, 293, 1791, 292, 613], "temperature": 0.0, "avg_logprob": -0.15113329254420457, "compression_ratio": 1.7061068702290076, "no_speech_prob": 4.565930794342421e-06}, {"id": 433, "seek": 196428, "start": 1990.96, "end": 1992.84, "text": " two lines from", "tokens": [732, 3876, 490], "temperature": 0.0, "avg_logprob": -0.15113329254420457, "compression_ratio": 1.7061068702290076, "no_speech_prob": 4.565930794342421e-06}, {"id": 434, "seek": 199284, "start": 1992.84, "end": 1997.1, "text": " From there, and so it says we're expected to submit a file where the first line", "tokens": [3358, 456, 11, 293, 370, 309, 1619, 321, 434, 5176, 281, 10315, 257, 3991, 689, 264, 700, 1622], "temperature": 0.0, "avg_logprob": -0.18970115738685686, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.438982381951064e-06}, {"id": 435, "seek": 199284, "start": 1997.8, "end": 2004.3999999999999, "text": " Contains the the word the word ID and then a comma separated list of all of the possible dot breeds", "tokens": [4839, 2315, 264, 264, 1349, 264, 1349, 7348, 293, 550, 257, 22117, 12005, 1329, 295, 439, 295, 264, 1944, 5893, 41609], "temperature": 0.0, "avg_logprob": -0.18970115738685686, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.438982381951064e-06}, {"id": 436, "seek": 199284, "start": 2004.3999999999999, "end": 2008.76, "text": " And then every line after that will contain the ID itself", "tokens": [400, 550, 633, 1622, 934, 300, 486, 5304, 264, 7348, 2564], "temperature": 0.0, "avg_logprob": -0.18970115738685686, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.438982381951064e-06}, {"id": 437, "seek": 199284, "start": 2009.6, "end": 2012.56, "text": " Followed by all the probabilities of all the different dot breeds", "tokens": [9876, 292, 538, 439, 264, 33783, 295, 439, 264, 819, 5893, 41609], "temperature": 0.0, "avg_logprob": -0.18970115738685686, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.438982381951064e-06}, {"id": 438, "seek": 199284, "start": 2013.24, "end": 2014.8799999999999, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.18970115738685686, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.438982381951064e-06}, {"id": 439, "seek": 199284, "start": 2014.8799999999999, "end": 2016.8799999999999, "text": " How do you create that?", "tokens": [1012, 360, 291, 1884, 300, 30], "temperature": 0.0, "avg_logprob": -0.18970115738685686, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.438982381951064e-06}, {"id": 440, "seek": 199284, "start": 2017.72, "end": 2021.4399999999998, "text": " So I recognize that inside our data object. There's a dot classes", "tokens": [407, 286, 5521, 300, 1854, 527, 1412, 2657, 13, 821, 311, 257, 5893, 5359], "temperature": 0.0, "avg_logprob": -0.18970115738685686, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.438982381951064e-06}, {"id": 441, "seek": 202144, "start": 2021.44, "end": 2027.5800000000002, "text": " Which has got in alphabetical order all of the all of the classes?", "tokens": [3013, 575, 658, 294, 23339, 804, 1668, 439, 295, 264, 439, 295, 264, 5359, 30], "temperature": 0.0, "avg_logprob": -0.2575607557554503, "compression_ratio": 1.7407407407407407, "no_speech_prob": 2.3320646960200975e-06}, {"id": 442, "seek": 202144, "start": 2028.52, "end": 2030.52, "text": " and then", "tokens": [293, 550], "temperature": 0.0, "avg_logprob": -0.2575607557554503, "compression_ratio": 1.7407407407407407, "no_speech_prob": 2.3320646960200975e-06}, {"id": 443, "seek": 202144, "start": 2031.48, "end": 2034.6200000000001, "text": " So it's got all of the different classes and then inside", "tokens": [407, 309, 311, 658, 439, 295, 264, 819, 5359, 293, 550, 1854], "temperature": 0.0, "avg_logprob": -0.2575607557554503, "compression_ratio": 1.7407407407407407, "no_speech_prob": 2.3320646960200975e-06}, {"id": 444, "seek": 202144, "start": 2035.3600000000001, "end": 2040.48, "text": " Data dot test data set test es you can also see there's all the file names", "tokens": [11888, 5893, 1500, 1412, 992, 1500, 785, 291, 393, 611, 536, 456, 311, 439, 264, 3991, 5288], "temperature": 0.0, "avg_logprob": -0.2575607557554503, "compression_ratio": 1.7407407407407407, "no_speech_prob": 2.3320646960200975e-06}, {"id": 445, "seek": 202144, "start": 2041.8400000000001, "end": 2048.12, "text": " So and just to remind you dogs and cats sorry not dogs and cats dog breeds", "tokens": [407, 293, 445, 281, 4160, 291, 7197, 293, 11111, 2597, 406, 7197, 293, 11111, 3000, 41609], "temperature": 0.0, "avg_logprob": -0.2575607557554503, "compression_ratio": 1.7407407407407407, "no_speech_prob": 2.3320646960200975e-06}, {"id": 446, "seek": 204812, "start": 2048.12, "end": 2055.2799999999997, "text": " Was not provided in the kind of Keras style format where the dogs and cats were in different folders", "tokens": [3027, 406, 5649, 294, 264, 733, 295, 591, 6985, 3758, 7877, 689, 264, 7197, 293, 11111, 645, 294, 819, 31082], "temperature": 0.0, "avg_logprob": -0.2067964727228338, "compression_ratio": 1.7023255813953488, "no_speech_prob": 3.3931253256014315e-06}, {"id": 447, "seek": 204812, "start": 2055.44, "end": 2062.8399999999997, "text": " But instead it was provided as a CSV file of labels right so when you get a CSV file of labels you use", "tokens": [583, 2602, 309, 390, 5649, 382, 257, 48814, 3991, 295, 16949, 558, 370, 562, 291, 483, 257, 48814, 3991, 295, 16949, 291, 764], "temperature": 0.0, "avg_logprob": -0.2067964727228338, "compression_ratio": 1.7023255813953488, "no_speech_prob": 3.3931253256014315e-06}, {"id": 448, "seek": 204812, "start": 2063.88, "end": 2069.48, "text": " image classifier data from the CSV rather than image classifier data from paths", "tokens": [3256, 1508, 9902, 1412, 490, 264, 48814, 2831, 813, 3256, 1508, 9902, 1412, 490, 14518], "temperature": 0.0, "avg_logprob": -0.2067964727228338, "compression_ratio": 1.7023255813953488, "no_speech_prob": 3.3931253256014315e-06}, {"id": 449, "seek": 204812, "start": 2070.96, "end": 2075.14, "text": " There isn't an equivalent in Keras, so you'll see like on the Kaggle forums people", "tokens": [821, 1943, 380, 364, 10344, 294, 591, 6985, 11, 370, 291, 603, 536, 411, 322, 264, 48751, 22631, 26998, 561], "temperature": 0.0, "avg_logprob": -0.2067964727228338, "compression_ratio": 1.7023255813953488, "no_speech_prob": 3.3931253256014315e-06}, {"id": 450, "seek": 207514, "start": 2075.14, "end": 2079.98, "text": " Share scripts for how to convert it to a Keras style folders, but in our case", "tokens": [14945, 23294, 337, 577, 281, 7620, 309, 281, 257, 591, 6985, 3758, 31082, 11, 457, 294, 527, 1389], "temperature": 0.0, "avg_logprob": -0.17822683233963815, "compression_ratio": 1.6523605150214593, "no_speech_prob": 2.5612680474296212e-06}, {"id": 451, "seek": 207514, "start": 2079.98, "end": 2084.8799999999997, "text": " We don't have to we just go image classifier data from CSV passing in that CSV file", "tokens": [492, 500, 380, 362, 281, 321, 445, 352, 3256, 1508, 9902, 1412, 490, 48814, 8437, 294, 300, 48814, 3991], "temperature": 0.0, "avg_logprob": -0.17822683233963815, "compression_ratio": 1.6523605150214593, "no_speech_prob": 2.5612680474296212e-06}, {"id": 452, "seek": 207514, "start": 2085.8399999999997, "end": 2092.16, "text": " And so the CSV file will you know has automatically told the data rid of what the classes are?", "tokens": [400, 370, 264, 48814, 3991, 486, 291, 458, 575, 6772, 1907, 264, 1412, 3973, 295, 437, 264, 5359, 366, 30], "temperature": 0.0, "avg_logprob": -0.17822683233963815, "compression_ratio": 1.6523605150214593, "no_speech_prob": 2.5612680474296212e-06}, {"id": 453, "seek": 207514, "start": 2093.2799999999997, "end": 2099.7599999999998, "text": " And then also we can see from the folder of test images what the file names of those are", "tokens": [400, 550, 611, 321, 393, 536, 490, 264, 10820, 295, 1500, 5267, 437, 264, 3991, 5288, 295, 729, 366], "temperature": 0.0, "avg_logprob": -0.17822683233963815, "compression_ratio": 1.6523605150214593, "no_speech_prob": 2.5612680474296212e-06}, {"id": 454, "seek": 207514, "start": 2100.68, "end": 2102.68, "text": " So with those two pieces of information", "tokens": [407, 365, 729, 732, 3755, 295, 1589], "temperature": 0.0, "avg_logprob": -0.17822683233963815, "compression_ratio": 1.6523605150214593, "no_speech_prob": 2.5612680474296212e-06}, {"id": 455, "seek": 210268, "start": 2102.68, "end": 2105.2, "text": " We're ready to go", "tokens": [492, 434, 1919, 281, 352], "temperature": 0.0, "avg_logprob": -0.17837020754814148, "compression_ratio": 1.45, "no_speech_prob": 4.710879238700727e-06}, {"id": 456, "seek": 210268, "start": 2105.2, "end": 2111.0, "text": " So I always think it's a good idea to use TTA as you saw with that dogs and cats example", "tokens": [407, 286, 1009, 519, 309, 311, 257, 665, 1558, 281, 764, 314, 8241, 382, 291, 1866, 365, 300, 7197, 293, 11111, 1365], "temperature": 0.0, "avg_logprob": -0.17837020754814148, "compression_ratio": 1.45, "no_speech_prob": 4.710879238700727e-06}, {"id": 457, "seek": 210268, "start": 2111.0, "end": 2115.22, "text": " Just now it can really improve things particularly when your model is less good", "tokens": [1449, 586, 309, 393, 534, 3470, 721, 4098, 562, 428, 2316, 307, 1570, 665], "temperature": 0.0, "avg_logprob": -0.17837020754814148, "compression_ratio": 1.45, "no_speech_prob": 4.710879238700727e-06}, {"id": 458, "seek": 210268, "start": 2116.3599999999997, "end": 2120.12, "text": " So I can say learn dot TTA and if you pass in", "tokens": [407, 286, 393, 584, 1466, 5893, 314, 8241, 293, 498, 291, 1320, 294], "temperature": 0.0, "avg_logprob": -0.17837020754814148, "compression_ratio": 1.45, "no_speech_prob": 4.710879238700727e-06}, {"id": 459, "seek": 212012, "start": 2120.12, "end": 2129.6, "text": " If you pass in is test equals true", "tokens": [759, 291, 1320, 294, 307, 1500, 6915, 2074], "temperature": 0.0, "avg_logprob": -0.17977225194211865, "compression_ratio": 1.532934131736527, "no_speech_prob": 1.3709532140637748e-06}, {"id": 460, "seek": 212012, "start": 2130.16, "end": 2137.48, "text": " Then it's going to give you predictions on the test set rather than the validation set okay, and now obviously we can't now get", "tokens": [1396, 309, 311, 516, 281, 976, 291, 21264, 322, 264, 1500, 992, 2831, 813, 264, 24071, 992, 1392, 11, 293, 586, 2745, 321, 393, 380, 586, 483], "temperature": 0.0, "avg_logprob": -0.17977225194211865, "compression_ratio": 1.532934131736527, "no_speech_prob": 1.3709532140637748e-06}, {"id": 461, "seek": 212012, "start": 2139.0, "end": 2143.88, "text": " An accuracy or anything because by definition we don't know the labels for the test set right", "tokens": [1107, 14170, 420, 1340, 570, 538, 7123, 321, 500, 380, 458, 264, 16949, 337, 264, 1500, 992, 558], "temperature": 0.0, "avg_logprob": -0.17977225194211865, "compression_ratio": 1.532934131736527, "no_speech_prob": 1.3709532140637748e-06}, {"id": 462, "seek": 214388, "start": 2143.88, "end": 2148.52, "text": " So by default most", "tokens": [407, 538, 7576, 881], "temperature": 0.0, "avg_logprob": -0.25564060416272893, "compression_ratio": 1.6136363636363635, "no_speech_prob": 1.328772214037599e-06}, {"id": 463, "seek": 214388, "start": 2149.1600000000003, "end": 2152.7000000000003, "text": " Pytorch models give you back the log of the predictions", "tokens": [430, 4328, 284, 339, 5245, 976, 291, 646, 264, 3565, 295, 264, 21264], "temperature": 0.0, "avg_logprob": -0.25564060416272893, "compression_ratio": 1.6136363636363635, "no_speech_prob": 1.328772214037599e-06}, {"id": 464, "seek": 214388, "start": 2153.28, "end": 2157.7200000000003, "text": " So then we just have to go exp of that to get back our probabilities", "tokens": [407, 550, 321, 445, 362, 281, 352, 1278, 295, 300, 281, 483, 646, 527, 33783], "temperature": 0.0, "avg_logprob": -0.25564060416272893, "compression_ratio": 1.6136363636363635, "no_speech_prob": 1.328772214037599e-06}, {"id": 465, "seek": 214388, "start": 2158.44, "end": 2165.08, "text": " So in this case the test set had ten thousand three hundred and fifty seven images in it, and there are 120 possible breeds", "tokens": [407, 294, 341, 1389, 264, 1500, 992, 632, 2064, 4714, 1045, 3262, 293, 13442, 3407, 5267, 294, 309, 11, 293, 456, 366, 10411, 1944, 41609], "temperature": 0.0, "avg_logprob": -0.25564060416272893, "compression_ratio": 1.6136363636363635, "no_speech_prob": 1.328772214037599e-06}, {"id": 466, "seek": 214388, "start": 2165.52, "end": 2168.6800000000003, "text": " All right, so we get back a matrix of of that size", "tokens": [1057, 558, 11, 370, 321, 483, 646, 257, 8141, 295, 295, 300, 2744], "temperature": 0.0, "avg_logprob": -0.25564060416272893, "compression_ratio": 1.6136363636363635, "no_speech_prob": 1.328772214037599e-06}, {"id": 467, "seek": 214388, "start": 2169.6, "end": 2171.6800000000003, "text": " and so we now need to turn that into", "tokens": [293, 370, 321, 586, 643, 281, 1261, 300, 666], "temperature": 0.0, "avg_logprob": -0.25564060416272893, "compression_ratio": 1.6136363636363635, "no_speech_prob": 1.328772214037599e-06}, {"id": 468, "seek": 217168, "start": 2171.68, "end": 2173.3599999999997, "text": " something", "tokens": [746], "temperature": 0.0, "avg_logprob": -0.1651460817544767, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.801021976978518e-06}, {"id": 469, "seek": 217168, "start": 2173.3599999999997, "end": 2175.3599999999997, "text": " that looks like this and", "tokens": [300, 1542, 411, 341, 293], "temperature": 0.0, "avg_logprob": -0.1651460817544767, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.801021976978518e-06}, {"id": 470, "seek": 217168, "start": 2176.0, "end": 2179.98, "text": " So the easiest way to do that is with pandas if you're not familiar with pandas", "tokens": [407, 264, 12889, 636, 281, 360, 300, 307, 365, 4565, 296, 498, 291, 434, 406, 4963, 365, 4565, 296], "temperature": 0.0, "avg_logprob": -0.1651460817544767, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.801021976978518e-06}, {"id": 471, "seek": 217168, "start": 2180.16, "end": 2185.52, "text": " There's lots of information online about it or check out the machine learning course intro to machine learning that we have", "tokens": [821, 311, 3195, 295, 1589, 2950, 466, 309, 420, 1520, 484, 264, 3479, 2539, 1164, 12897, 281, 3479, 2539, 300, 321, 362], "temperature": 0.0, "avg_logprob": -0.1651460817544767, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.801021976978518e-06}, {"id": 472, "seek": 217168, "start": 2185.56, "end": 2191.9199999999996, "text": " Where we do lots of stuff with pandas, but basically we can just go PD data frame and pass in that matrix", "tokens": [2305, 321, 360, 3195, 295, 1507, 365, 4565, 296, 11, 457, 1936, 321, 393, 445, 352, 10464, 1412, 3920, 293, 1320, 294, 300, 8141], "temperature": 0.0, "avg_logprob": -0.1651460817544767, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.801021976978518e-06}, {"id": 473, "seek": 217168, "start": 2191.9199999999996, "end": 2196.72, "text": " And then we can say the names of the columns are equal to data dot classes", "tokens": [400, 550, 321, 393, 584, 264, 5288, 295, 264, 13766, 366, 2681, 281, 1412, 5893, 5359], "temperature": 0.0, "avg_logprob": -0.1651460817544767, "compression_ratio": 1.6963562753036436, "no_speech_prob": 8.801021976978518e-06}, {"id": 474, "seek": 219672, "start": 2196.72, "end": 2204.12, "text": " And then finally we can insert a new column at position zero called ID that contains the file names", "tokens": [400, 550, 2721, 321, 393, 8969, 257, 777, 7738, 412, 2535, 4018, 1219, 7348, 300, 8306, 264, 3991, 5288], "temperature": 0.0, "avg_logprob": -0.17415756403013719, "compression_ratio": 1.6733668341708543, "no_speech_prob": 2.4824694264680147e-06}, {"id": 475, "seek": 219672, "start": 2205.08, "end": 2208.3199999999997, "text": " But you'll notice that the file names contain", "tokens": [583, 291, 603, 3449, 300, 264, 3991, 5288, 5304], "temperature": 0.0, "avg_logprob": -0.17415756403013719, "compression_ratio": 1.6733668341708543, "no_speech_prob": 2.4824694264680147e-06}, {"id": 476, "seek": 219672, "start": 2209.3999999999996, "end": 2215.2999999999997, "text": " Five letters at the end with a start we don't want and four letters at the end. We don't want so I just", "tokens": [9436, 7825, 412, 264, 917, 365, 257, 722, 321, 500, 380, 528, 293, 1451, 7825, 412, 264, 917, 13, 492, 500, 380, 528, 370, 286, 445], "temperature": 0.0, "avg_logprob": -0.17415756403013719, "compression_ratio": 1.6733668341708543, "no_speech_prob": 2.4824694264680147e-06}, {"id": 477, "seek": 219672, "start": 2216.16, "end": 2220.3199999999997, "text": " Subset in like so right so at that point", "tokens": [8511, 3854, 294, 411, 370, 558, 370, 412, 300, 935], "temperature": 0.0, "avg_logprob": -0.17415756403013719, "compression_ratio": 1.6733668341708543, "no_speech_prob": 2.4824694264680147e-06}, {"id": 478, "seek": 219672, "start": 2222.08, "end": 2224.8799999999997, "text": " I've got a data frame that looks like this", "tokens": [286, 600, 658, 257, 1412, 3920, 300, 1542, 411, 341], "temperature": 0.0, "avg_logprob": -0.17415756403013719, "compression_ratio": 1.6733668341708543, "no_speech_prob": 2.4824694264680147e-06}, {"id": 479, "seek": 222488, "start": 2224.88, "end": 2228.6400000000003, "text": " Which is what we want so you can now", "tokens": [3013, 307, 437, 321, 528, 370, 291, 393, 586], "temperature": 0.0, "avg_logprob": -0.3190525348369892, "compression_ratio": 1.5033557046979866, "no_speech_prob": 3.905473477061605e-06}, {"id": 480, "seek": 222488, "start": 2229.44, "end": 2234.2400000000002, "text": " Call data frame data stuff such a few days DF not DS", "tokens": [7807, 1412, 3920, 1412, 1507, 1270, 257, 1326, 1708, 48336, 406, 15816], "temperature": 0.0, "avg_logprob": -0.3190525348369892, "compression_ratio": 1.5033557046979866, "no_speech_prob": 3.905473477061605e-06}, {"id": 481, "seek": 222488, "start": 2235.04, "end": 2237.04, "text": " Let's fix it now", "tokens": [961, 311, 3191, 309, 586], "temperature": 0.0, "avg_logprob": -0.3190525348369892, "compression_ratio": 1.5033557046979866, "no_speech_prob": 3.905473477061605e-06}, {"id": 482, "seek": 222488, "start": 2240.7200000000003, "end": 2242.7200000000003, "text": " Data frame", "tokens": [11888, 3920], "temperature": 0.0, "avg_logprob": -0.3190525348369892, "compression_ratio": 1.5033557046979866, "no_speech_prob": 3.905473477061605e-06}, {"id": 483, "seek": 222488, "start": 2243.52, "end": 2247.44, "text": " Okay, so you can now call data frame to CSV and", "tokens": [1033, 11, 370, 291, 393, 586, 818, 1412, 3920, 281, 48814, 293], "temperature": 0.0, "avg_logprob": -0.3190525348369892, "compression_ratio": 1.5033557046979866, "no_speech_prob": 3.905473477061605e-06}, {"id": 484, "seek": 222488, "start": 2248.28, "end": 2252.08, "text": " Quite often you'll find these files actually get quite big", "tokens": [20464, 2049, 291, 603, 915, 613, 7098, 767, 483, 1596, 955], "temperature": 0.0, "avg_logprob": -0.3190525348369892, "compression_ratio": 1.5033557046979866, "no_speech_prob": 3.905473477061605e-06}, {"id": 485, "seek": 225208, "start": 2252.08, "end": 2258.92, "text": " so it's a good idea to say compression equals gzip and that'll zip it up on the server for you and that's going to create a", "tokens": [370, 309, 311, 257, 665, 1558, 281, 584, 19355, 6915, 290, 27268, 293, 300, 603, 20730, 309, 493, 322, 264, 7154, 337, 291, 293, 300, 311, 516, 281, 1884, 257], "temperature": 0.0, "avg_logprob": -0.2723704217707069, "compression_ratio": 1.6431718061674008, "no_speech_prob": 3.5008404211112065e-06}, {"id": 486, "seek": 225208, "start": 2260.08, "end": 2261.68, "text": " Zipped up", "tokens": [1176, 5529, 493], "temperature": 0.0, "avg_logprob": -0.2723704217707069, "compression_ratio": 1.6431718061674008, "no_speech_prob": 3.5008404211112065e-06}, {"id": 487, "seek": 225208, "start": 2261.68, "end": 2265.6, "text": " CSV file on the server on wherever you're running this Jupiter notebook", "tokens": [48814, 3991, 322, 264, 7154, 322, 8660, 291, 434, 2614, 341, 24567, 21060], "temperature": 0.0, "avg_logprob": -0.2723704217707069, "compression_ratio": 1.6431718061674008, "no_speech_prob": 3.5008404211112065e-06}, {"id": 488, "seek": 225208, "start": 2265.7599999999998, "end": 2269.88, "text": " So you need an app that you now need to get that back to your computer so you can upload it", "tokens": [407, 291, 643, 364, 724, 300, 291, 586, 643, 281, 483, 300, 646, 281, 428, 3820, 370, 291, 393, 6580, 309], "temperature": 0.0, "avg_logprob": -0.2723704217707069, "compression_ratio": 1.6431718061674008, "no_speech_prob": 3.5008404211112065e-06}, {"id": 489, "seek": 225208, "start": 2270.56, "end": 2275.7999999999997, "text": " Or you can use kaggle CLA so you can type kg submit and do it that way", "tokens": [1610, 291, 393, 764, 350, 559, 22631, 383, 11435, 370, 291, 393, 2010, 15696, 10315, 293, 360, 309, 300, 636], "temperature": 0.0, "avg_logprob": -0.2723704217707069, "compression_ratio": 1.6431718061674008, "no_speech_prob": 3.5008404211112065e-06}, {"id": 490, "seek": 225208, "start": 2276.3199999999997, "end": 2277.44, "text": " I've", "tokens": [286, 600], "temperature": 0.0, "avg_logprob": -0.2723704217707069, "compression_ratio": 1.6431718061674008, "no_speech_prob": 3.5008404211112065e-06}, {"id": 491, "seek": 227744, "start": 2277.44, "end": 2282.56, "text": " Generally download it to my computer because I like I often like to just like double check it all looks okay", "tokens": [21082, 5484, 309, 281, 452, 3820, 570, 286, 411, 286, 2049, 411, 281, 445, 411, 3834, 1520, 309, 439, 1542, 1392], "temperature": 0.0, "avg_logprob": -0.1813287829408551, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.6688493310066406e-06}, {"id": 492, "seek": 227744, "start": 2283.4, "end": 2288.12, "text": " So to do that there's a cool little thing called file link and if you run file link", "tokens": [407, 281, 360, 300, 456, 311, 257, 1627, 707, 551, 1219, 3991, 2113, 293, 498, 291, 1190, 3991, 2113], "temperature": 0.0, "avg_logprob": -0.1813287829408551, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.6688493310066406e-06}, {"id": 493, "seek": 227744, "start": 2288.8, "end": 2292.2400000000002, "text": " With a path on your server it gives you back a URL", "tokens": [2022, 257, 3100, 322, 428, 7154, 309, 2709, 291, 646, 257, 12905], "temperature": 0.0, "avg_logprob": -0.1813287829408551, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.6688493310066406e-06}, {"id": 494, "seek": 227744, "start": 2292.84, "end": 2299.04, "text": " Which you can click on and it'll download that file from the server onto your computer", "tokens": [3013, 291, 393, 2052, 322, 293, 309, 603, 5484, 300, 3991, 490, 264, 7154, 3911, 428, 3820], "temperature": 0.0, "avg_logprob": -0.1813287829408551, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.6688493310066406e-06}, {"id": 495, "seek": 227744, "start": 2300.04, "end": 2302.04, "text": " So if I click on that now I", "tokens": [407, 498, 286, 2052, 322, 300, 586, 286], "temperature": 0.0, "avg_logprob": -0.1813287829408551, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.6688493310066406e-06}, {"id": 496, "seek": 230204, "start": 2302.04, "end": 2309.52, "text": " Can go ahead and save it and then I can see in my downloads", "tokens": [1664, 352, 2286, 293, 3155, 309, 293, 550, 286, 393, 536, 294, 452, 36553], "temperature": 0.0, "avg_logprob": -0.25517575190617486, "compression_ratio": 1.4936708860759493, "no_speech_prob": 1.553492666062084e-06}, {"id": 497, "seek": 230204, "start": 2313.96, "end": 2316.6, "text": " There it is here's my submission file", "tokens": [821, 309, 307, 510, 311, 452, 23689, 3991], "temperature": 0.0, "avg_logprob": -0.25517575190617486, "compression_ratio": 1.4936708860759493, "no_speech_prob": 1.553492666062084e-06}, {"id": 498, "seek": 230204, "start": 2320.48, "end": 2322.32, "text": " If you want to open", "tokens": [759, 291, 528, 281, 1269], "temperature": 0.0, "avg_logprob": -0.25517575190617486, "compression_ratio": 1.4936708860759493, "no_speech_prob": 1.553492666062084e-06}, {"id": 499, "seek": 230204, "start": 2322.32, "end": 2323.92, "text": " area and", "tokens": [1859, 293], "temperature": 0.0, "avg_logprob": -0.25517575190617486, "compression_ratio": 1.4936708860759493, "no_speech_prob": 1.553492666062084e-06}, {"id": 500, "seek": 230204, "start": 2323.92, "end": 2329.8, "text": " As you can see it's exactly what I asked for there's my ID in the hundred and twenty different dog breeds and", "tokens": [1018, 291, 393, 536, 309, 311, 2293, 437, 286, 2351, 337, 456, 311, 452, 7348, 294, 264, 3262, 293, 7699, 819, 3000, 41609, 293], "temperature": 0.0, "avg_logprob": -0.25517575190617486, "compression_ratio": 1.4936708860759493, "no_speech_prob": 1.553492666062084e-06}, {"id": 501, "seek": 232980, "start": 2329.8, "end": 2334.8, "text": " Then here's my first row containing the file name and the hundred and twenty different probabilities", "tokens": [1396, 510, 311, 452, 700, 5386, 19273, 264, 3991, 1315, 293, 264, 3262, 293, 7699, 819, 33783], "temperature": 0.0, "avg_logprob": -0.1913404977449807, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.733042836349341e-06}, {"id": 502, "seek": 232980, "start": 2335.2000000000003, "end": 2338.6400000000003, "text": " Okay, so then you can go ahead and submit that to kaggle through their", "tokens": [1033, 11, 370, 550, 291, 393, 352, 2286, 293, 10315, 300, 281, 350, 559, 22631, 807, 641], "temperature": 0.0, "avg_logprob": -0.1913404977449807, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.733042836349341e-06}, {"id": 503, "seek": 232980, "start": 2339.44, "end": 2344.92, "text": " Through their regular form and so this is also a good way you can see we've now got a good way of both", "tokens": [8927, 641, 3890, 1254, 293, 370, 341, 307, 611, 257, 665, 636, 291, 393, 536, 321, 600, 586, 658, 257, 665, 636, 295, 1293], "temperature": 0.0, "avg_logprob": -0.1913404977449807, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.733042836349341e-06}, {"id": 504, "seek": 232980, "start": 2346.44, "end": 2352.5600000000004, "text": " Grabbing any file off the internet and getting it to our AWS instance or a paper space or whatever by using", "tokens": [20357, 4324, 604, 3991, 766, 264, 4705, 293, 1242, 309, 281, 527, 17650, 5197, 420, 257, 3035, 1901, 420, 2035, 538, 1228], "temperature": 0.0, "avg_logprob": -0.1913404977449807, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.733042836349341e-06}, {"id": 505, "seek": 232980, "start": 2353.52, "end": 2354.6400000000003, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.1913404977449807, "compression_ratio": 1.6425531914893616, "no_speech_prob": 1.733042836349341e-06}, {"id": 506, "seek": 235464, "start": 2354.64, "end": 2360.0, "text": " Cool little extension in Chrome, and we've also got a way of grabbing stuff off our server easily", "tokens": [8561, 707, 10320, 294, 15327, 11, 293, 321, 600, 611, 658, 257, 636, 295, 23771, 1507, 766, 527, 7154, 3612], "temperature": 0.0, "avg_logprob": -0.21059812818254744, "compression_ratio": 1.53125, "no_speech_prob": 4.495160283113364e-06}, {"id": 507, "seek": 235464, "start": 2360.56, "end": 2362.56, "text": " those of you that are more", "tokens": [729, 295, 291, 300, 366, 544], "temperature": 0.0, "avg_logprob": -0.21059812818254744, "compression_ratio": 1.53125, "no_speech_prob": 4.495160283113364e-06}, {"id": 508, "seek": 235464, "start": 2362.72, "end": 2368.96, "text": " Command line oriented you can also use SCP of course, but I kind of like doing everything through the notebook", "tokens": [17901, 1622, 21841, 291, 393, 611, 764, 18489, 295, 1164, 11, 457, 286, 733, 295, 411, 884, 1203, 807, 264, 21060], "temperature": 0.0, "avg_logprob": -0.21059812818254744, "compression_ratio": 1.53125, "no_speech_prob": 4.495160283113364e-06}, {"id": 509, "seek": 235464, "start": 2370.72, "end": 2372.72, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.21059812818254744, "compression_ratio": 1.53125, "no_speech_prob": 4.495160283113364e-06}, {"id": 510, "seek": 235464, "start": 2372.92, "end": 2378.3199999999997, "text": " One other question I had during the week was like what if I want to just get a single", "tokens": [1485, 661, 1168, 286, 632, 1830, 264, 1243, 390, 411, 437, 498, 286, 528, 281, 445, 483, 257, 2167], "temperature": 0.0, "avg_logprob": -0.21059812818254744, "compression_ratio": 1.53125, "no_speech_prob": 4.495160283113364e-06}, {"id": 511, "seek": 235464, "start": 2379.64, "end": 2381.12, "text": " single file", "tokens": [2167, 3991], "temperature": 0.0, "avg_logprob": -0.21059812818254744, "compression_ratio": 1.53125, "no_speech_prob": 4.495160283113364e-06}, {"id": 512, "seek": 238112, "start": 2381.12, "end": 2385.64, "text": " That I want to you know get a prediction for so for example", "tokens": [663, 286, 528, 281, 291, 458, 483, 257, 17630, 337, 370, 337, 1365], "temperature": 0.0, "avg_logprob": -0.17914326985677084, "compression_ratio": 1.6710526315789473, "no_speech_prob": 5.014705038774991e-06}, {"id": 513, "seek": 238112, "start": 2385.64, "end": 2390.16, "text": " You know maybe I want to get this first file from my validation set so there's its name", "tokens": [509, 458, 1310, 286, 528, 281, 483, 341, 700, 3991, 490, 452, 24071, 992, 370, 456, 311, 1080, 1315], "temperature": 0.0, "avg_logprob": -0.17914326985677084, "compression_ratio": 1.6710526315789473, "no_speech_prob": 5.014705038774991e-06}, {"id": 514, "seek": 238112, "start": 2391.48, "end": 2394.56, "text": " So you can always look at a file just by calling image dot open", "tokens": [407, 291, 393, 1009, 574, 412, 257, 3991, 445, 538, 5141, 3256, 5893, 1269], "temperature": 0.0, "avg_logprob": -0.17914326985677084, "compression_ratio": 1.6710526315789473, "no_speech_prob": 5.014705038774991e-06}, {"id": 515, "seek": 238112, "start": 2395.56, "end": 2397.56, "text": " That just uses the regular", "tokens": [663, 445, 4960, 264, 3890], "temperature": 0.0, "avg_logprob": -0.17914326985677084, "compression_ratio": 1.6710526315789473, "no_speech_prob": 5.014705038774991e-06}, {"id": 516, "seek": 238112, "start": 2398.48, "end": 2400.48, "text": " Python imaging library", "tokens": [15329, 25036, 6405], "temperature": 0.0, "avg_logprob": -0.17914326985677084, "compression_ratio": 1.6710526315789473, "no_speech_prob": 5.014705038774991e-06}, {"id": 517, "seek": 238112, "start": 2400.64, "end": 2402.56, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.17914326985677084, "compression_ratio": 1.6710526315789473, "no_speech_prob": 5.014705038774991e-06}, {"id": 518, "seek": 238112, "start": 2402.56, "end": 2408.3599999999997, "text": " So what you can do is there's actually I'll show you the shortest version you can just call", "tokens": [407, 437, 291, 393, 360, 307, 456, 311, 767, 286, 603, 855, 291, 264, 31875, 3037, 291, 393, 445, 818], "temperature": 0.0, "avg_logprob": -0.17914326985677084, "compression_ratio": 1.6710526315789473, "no_speech_prob": 5.014705038774991e-06}, {"id": 519, "seek": 240836, "start": 2408.36, "end": 2410.44, "text": " learn dot predict array", "tokens": [1466, 5893, 6069, 10225], "temperature": 0.0, "avg_logprob": -0.2668278475841844, "compression_ratio": 1.7714285714285714, "no_speech_prob": 5.33811908098869e-06}, {"id": 520, "seek": 240836, "start": 2412.1200000000003, "end": 2415.6, "text": " Passing in your your image", "tokens": [10319, 278, 294, 428, 428, 3256], "temperature": 0.0, "avg_logprob": -0.2668278475841844, "compression_ratio": 1.7714285714285714, "no_speech_prob": 5.33811908098869e-06}, {"id": 521, "seek": 240836, "start": 2416.7200000000003, "end": 2419.36, "text": " Okay, now the image needs to have been", "tokens": [1033, 11, 586, 264, 3256, 2203, 281, 362, 668], "temperature": 0.0, "avg_logprob": -0.2668278475841844, "compression_ratio": 1.7714285714285714, "no_speech_prob": 5.33811908098869e-06}, {"id": 522, "seek": 240836, "start": 2420.7200000000003, "end": 2421.84, "text": " transformed", "tokens": [16894], "temperature": 0.0, "avg_logprob": -0.2668278475841844, "compression_ratio": 1.7714285714285714, "no_speech_prob": 5.33811908098869e-06}, {"id": 523, "seek": 240836, "start": 2421.84, "end": 2427.6, "text": " So you've seen transform transform transforms from model before normally", "tokens": [407, 291, 600, 1612, 4088, 4088, 35592, 490, 2316, 949, 5646], "temperature": 0.0, "avg_logprob": -0.2668278475841844, "compression_ratio": 1.7714285714285714, "no_speech_prob": 5.33811908098869e-06}, {"id": 524, "seek": 240836, "start": 2427.6, "end": 2432.2000000000003, "text": " We just put put it all in one variable, but actually behind the scenes it was returning two things", "tokens": [492, 445, 829, 829, 309, 439, 294, 472, 7006, 11, 457, 767, 2261, 264, 8026, 309, 390, 12678, 732, 721], "temperature": 0.0, "avg_logprob": -0.2668278475841844, "compression_ratio": 1.7714285714285714, "no_speech_prob": 5.33811908098869e-06}, {"id": 525, "seek": 240836, "start": 2432.36, "end": 2436.84, "text": " It was returning training transforms and validation transforms, so I can actually split them apart", "tokens": [467, 390, 12678, 3097, 35592, 293, 24071, 35592, 11, 370, 286, 393, 767, 7472, 552, 4936], "temperature": 0.0, "avg_logprob": -0.2668278475841844, "compression_ratio": 1.7714285714285714, "no_speech_prob": 5.33811908098869e-06}, {"id": 526, "seek": 243684, "start": 2436.84, "end": 2444.04, "text": " And so here you can see I'm actually applying for example my training transforms or probably more likely. I would apply", "tokens": [400, 370, 510, 291, 393, 536, 286, 478, 767, 9275, 337, 1365, 452, 3097, 35592, 420, 1391, 544, 3700, 13, 286, 576, 3079], "temperature": 0.0, "avg_logprob": -0.1574777603149414, "compression_ratio": 1.7088607594936709, "no_speech_prob": 5.0936737352458294e-06}, {"id": 527, "seek": 243684, "start": 2444.76, "end": 2446.76, "text": " validation transforms", "tokens": [24071, 35592], "temperature": 0.0, "avg_logprob": -0.1574777603149414, "compression_ratio": 1.7088607594936709, "no_speech_prob": 5.0936737352458294e-06}, {"id": 528, "seek": 243684, "start": 2446.96, "end": 2453.8, "text": " That gives me back an array containing the image the transformed image which I can then pass to predict array", "tokens": [663, 2709, 385, 646, 364, 10225, 19273, 264, 3256, 264, 16894, 3256, 597, 286, 393, 550, 1320, 281, 6069, 10225], "temperature": 0.0, "avg_logprob": -0.1574777603149414, "compression_ratio": 1.7088607594936709, "no_speech_prob": 5.0936737352458294e-06}, {"id": 529, "seek": 243684, "start": 2455.92, "end": 2463.32, "text": " Everything that gets passed to or returned from our models is generally assumed to be a mini-batch, right?", "tokens": [5471, 300, 2170, 4678, 281, 420, 8752, 490, 527, 5245, 307, 5101, 15895, 281, 312, 257, 8382, 12, 65, 852, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1574777603149414, "compression_ratio": 1.7088607594936709, "no_speech_prob": 5.0936737352458294e-06}, {"id": 530, "seek": 243684, "start": 2463.32, "end": 2465.76, "text": " It's generally assumed to be a bunch of images", "tokens": [467, 311, 5101, 15895, 281, 312, 257, 3840, 295, 5267], "temperature": 0.0, "avg_logprob": -0.1574777603149414, "compression_ratio": 1.7088607594936709, "no_speech_prob": 5.0936737352458294e-06}, {"id": 531, "seek": 246576, "start": 2465.76, "end": 2470.96, "text": " So we'll talk more about some numpy tricks later, but basically in this case", "tokens": [407, 321, 603, 751, 544, 466, 512, 1031, 8200, 11733, 1780, 11, 457, 1936, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.15390491485595703, "compression_ratio": 1.8181818181818181, "no_speech_prob": 6.048876457498409e-06}, {"id": 532, "seek": 246576, "start": 2470.96, "end": 2476.44, "text": " We only have one image so we have to turn that into a mini batch of images so in other words", "tokens": [492, 787, 362, 472, 3256, 370, 321, 362, 281, 1261, 300, 666, 257, 8382, 15245, 295, 5267, 370, 294, 661, 2283], "temperature": 0.0, "avg_logprob": -0.15390491485595703, "compression_ratio": 1.8181818181818181, "no_speech_prob": 6.048876457498409e-06}, {"id": 533, "seek": 246576, "start": 2476.44, "end": 2479.7200000000003, "text": " We need to create a tensor that basically is not just", "tokens": [492, 643, 281, 1884, 257, 40863, 300, 1936, 307, 406, 445], "temperature": 0.0, "avg_logprob": -0.15390491485595703, "compression_ratio": 1.8181818181818181, "no_speech_prob": 6.048876457498409e-06}, {"id": 534, "seek": 246576, "start": 2481.0, "end": 2488.0, "text": " Rows by columns by channels, but it's number of image by rows by columns by channels and and as one image", "tokens": [497, 1509, 538, 13766, 538, 9235, 11, 457, 309, 311, 1230, 295, 3256, 538, 13241, 538, 13766, 538, 9235, 293, 293, 382, 472, 3256], "temperature": 0.0, "avg_logprob": -0.15390491485595703, "compression_ratio": 1.8181818181818181, "no_speech_prob": 6.048876457498409e-06}, {"id": 535, "seek": 246576, "start": 2488.1600000000003, "end": 2494.36, "text": " So it's basically becomes a four-dimensional tensor, so there's a cool little trick in numpy that if you index", "tokens": [407, 309, 311, 1936, 3643, 257, 1451, 12, 18759, 40863, 11, 370, 456, 311, 257, 1627, 707, 4282, 294, 1031, 8200, 300, 498, 291, 8186], "temperature": 0.0, "avg_logprob": -0.15390491485595703, "compression_ratio": 1.8181818181818181, "no_speech_prob": 6.048876457498409e-06}, {"id": 536, "seek": 249436, "start": 2494.36, "end": 2496.96, "text": " into an array with none", "tokens": [666, 364, 10225, 365, 6022], "temperature": 0.0, "avg_logprob": -0.22164042612140097, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.4593731521017617e-06}, {"id": 537, "seek": 249436, "start": 2497.52, "end": 2501.7200000000003, "text": " That basically adds additional unit access to the start so it turns it from an image", "tokens": [663, 1936, 10860, 4497, 4985, 2105, 281, 264, 722, 370, 309, 4523, 309, 490, 364, 3256], "temperature": 0.0, "avg_logprob": -0.22164042612140097, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.4593731521017617e-06}, {"id": 538, "seek": 249436, "start": 2502.1600000000003, "end": 2505.84, "text": " Into a mini batch of one images and so that's why we had to do that", "tokens": [23373, 257, 8382, 15245, 295, 472, 5267, 293, 370, 300, 311, 983, 321, 632, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.22164042612140097, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.4593731521017617e-06}, {"id": 539, "seek": 249436, "start": 2506.0, "end": 2511.36, "text": " So if you basically find you're trying to do things with a single image", "tokens": [407, 498, 291, 1936, 915, 291, 434, 1382, 281, 360, 721, 365, 257, 2167, 3256], "temperature": 0.0, "avg_logprob": -0.22164042612140097, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.4593731521017617e-06}, {"id": 540, "seek": 249436, "start": 2511.96, "end": 2519.1600000000003, "text": " With any kind of pie torch or fast AI thing this is just something you might you might find it says like expecting four", "tokens": [2022, 604, 733, 295, 1730, 27822, 420, 2370, 7318, 551, 341, 307, 445, 746, 291, 1062, 291, 1062, 915, 309, 1619, 411, 9650, 1451], "temperature": 0.0, "avg_logprob": -0.22164042612140097, "compression_ratio": 1.7037037037037037, "no_speech_prob": 1.4593731521017617e-06}, {"id": 541, "seek": 251916, "start": 2519.16, "end": 2524.44, "text": " Dimensions only got three probably means that or if you get back a return", "tokens": [20975, 8302, 787, 658, 1045, 1391, 1355, 300, 420, 498, 291, 483, 646, 257, 2736], "temperature": 0.0, "avg_logprob": -0.15792389975653753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 1.9947253804275533e-06}, {"id": 542, "seek": 251916, "start": 2525.2, "end": 2531.92, "text": " Value from something that has like some weird first axis. That's probably why it's probably giving you like back a mini-batch", "tokens": [39352, 490, 746, 300, 575, 411, 512, 3657, 700, 10298, 13, 663, 311, 1391, 983, 309, 311, 1391, 2902, 291, 411, 646, 257, 8382, 12, 65, 852], "temperature": 0.0, "avg_logprob": -0.15792389975653753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 1.9947253804275533e-06}, {"id": 543, "seek": 251916, "start": 2532.2, "end": 2536.04, "text": " Okay, and so we'll learn a lot more about this, but it's just something to be aware of", "tokens": [1033, 11, 293, 370, 321, 603, 1466, 257, 688, 544, 466, 341, 11, 457, 309, 311, 445, 746, 281, 312, 3650, 295], "temperature": 0.0, "avg_logprob": -0.15792389975653753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 1.9947253804275533e-06}, {"id": 544, "seek": 251916, "start": 2537.8799999999997, "end": 2540.04, "text": " Okay, so that's kind of", "tokens": [1033, 11, 370, 300, 311, 733, 295], "temperature": 0.0, "avg_logprob": -0.15792389975653753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 1.9947253804275533e-06}, {"id": 545, "seek": 251916, "start": 2542.2799999999997, "end": 2545.08, "text": " Everything you need to do in practice", "tokens": [5471, 291, 643, 281, 360, 294, 3124], "temperature": 0.0, "avg_logprob": -0.15792389975653753, "compression_ratio": 1.6111111111111112, "no_speech_prob": 1.9947253804275533e-06}, {"id": 546, "seek": 254508, "start": 2545.08, "end": 2547.08, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.2374525377827306, "compression_ratio": 1.475, "no_speech_prob": 6.5403946791775525e-06}, {"id": 547, "seek": 254508, "start": 2547.96, "end": 2550.44, "text": " Now we're going to kind of get into a little bit of theory", "tokens": [823, 321, 434, 516, 281, 733, 295, 483, 666, 257, 707, 857, 295, 5261], "temperature": 0.0, "avg_logprob": -0.2374525377827306, "compression_ratio": 1.475, "no_speech_prob": 6.5403946791775525e-06}, {"id": 548, "seek": 254508, "start": 2551.68, "end": 2557.48, "text": " What's actually going on behind the scenes with these convolutional neural networks, and you might remember?", "tokens": [708, 311, 767, 516, 322, 2261, 264, 8026, 365, 613, 45216, 304, 18161, 9590, 11, 293, 291, 1062, 1604, 30], "temperature": 0.0, "avg_logprob": -0.2374525377827306, "compression_ratio": 1.475, "no_speech_prob": 6.5403946791775525e-06}, {"id": 549, "seek": 254508, "start": 2559.04, "end": 2561.04, "text": " Back in lesson one", "tokens": [5833, 294, 6898, 472], "temperature": 0.0, "avg_logprob": -0.2374525377827306, "compression_ratio": 1.475, "no_speech_prob": 6.5403946791775525e-06}, {"id": 550, "seek": 254508, "start": 2563.96, "end": 2565.96, "text": " We actually saw", "tokens": [492, 767, 1866], "temperature": 0.0, "avg_logprob": -0.2374525377827306, "compression_ratio": 1.475, "no_speech_prob": 6.5403946791775525e-06}, {"id": 551, "seek": 254508, "start": 2567.24, "end": 2569.24, "text": " Our first little bit of theory", "tokens": [2621, 700, 707, 857, 295, 5261], "temperature": 0.0, "avg_logprob": -0.2374525377827306, "compression_ratio": 1.475, "no_speech_prob": 6.5403946791775525e-06}, {"id": 552, "seek": 256924, "start": 2569.24, "end": 2575.04, "text": " Which we stole from this fantastic website, so tosa.io e be explained visually", "tokens": [3013, 321, 16326, 490, 341, 5456, 3144, 11, 370, 281, 5790, 13, 1004, 308, 312, 8825, 19622], "temperature": 0.0, "avg_logprob": -0.26845473431526345, "compression_ratio": 1.8181818181818181, "no_speech_prob": 4.4254379645281006e-06}, {"id": 553, "seek": 256924, "start": 2575.72, "end": 2581.08, "text": " And we learned that a that a convolution is something where we basically have a little matrix", "tokens": [400, 321, 3264, 300, 257, 300, 257, 45216, 307, 746, 689, 321, 1936, 362, 257, 707, 8141], "temperature": 0.0, "avg_logprob": -0.26845473431526345, "compression_ratio": 1.8181818181818181, "no_speech_prob": 4.4254379645281006e-06}, {"id": 554, "seek": 256924, "start": 2581.64, "end": 2584.3999999999996, "text": " in deep learning nearly always three by three a", "tokens": [294, 2452, 2539, 6217, 1009, 1045, 538, 1045, 257], "temperature": 0.0, "avg_logprob": -0.26845473431526345, "compression_ratio": 1.8181818181818181, "no_speech_prob": 4.4254379645281006e-06}, {"id": 555, "seek": 256924, "start": 2584.7999999999997, "end": 2592.6, "text": " Little matrix that we basically multiply every element of that matrix by every element of a three by three section of an image", "tokens": [8022, 8141, 300, 321, 1936, 12972, 633, 4478, 295, 300, 8141, 538, 633, 4478, 295, 257, 1045, 538, 1045, 3541, 295, 364, 3256], "temperature": 0.0, "avg_logprob": -0.26845473431526345, "compression_ratio": 1.8181818181818181, "no_speech_prob": 4.4254379645281006e-06}, {"id": 556, "seek": 256924, "start": 2593.16, "end": 2594.8399999999997, "text": " Add them all together", "tokens": [5349, 552, 439, 1214], "temperature": 0.0, "avg_logprob": -0.26845473431526345, "compression_ratio": 1.8181818181818181, "no_speech_prob": 4.4254379645281006e-06}, {"id": 557, "seek": 256924, "start": 2594.8399999999997, "end": 2597.9199999999996, "text": " To get the result of that convolution at one point", "tokens": [1407, 483, 264, 1874, 295, 300, 45216, 412, 472, 935], "temperature": 0.0, "avg_logprob": -0.26845473431526345, "compression_ratio": 1.8181818181818181, "no_speech_prob": 4.4254379645281006e-06}, {"id": 558, "seek": 259792, "start": 2597.92, "end": 2599.92, "text": " right now", "tokens": [558, 586], "temperature": 0.0, "avg_logprob": -0.28233672832620554, "compression_ratio": 1.5904255319148937, "no_speech_prob": 7.766891940264031e-06}, {"id": 559, "seek": 259792, "start": 2600.16, "end": 2604.76, "text": " Let's see how that all gets turned together to create these", "tokens": [961, 311, 536, 577, 300, 439, 2170, 3574, 1214, 281, 1884, 613], "temperature": 0.0, "avg_logprob": -0.28233672832620554, "compression_ratio": 1.5904255319148937, "no_speech_prob": 7.766891940264031e-06}, {"id": 560, "seek": 259792, "start": 2605.4, "end": 2611.7200000000003, "text": " These various layers that we saw in the the xyla and burgus paper and to do that again", "tokens": [1981, 3683, 7914, 300, 321, 1866, 294, 264, 264, 2031, 88, 875, 293, 2779, 21956, 3035, 293, 281, 360, 300, 797], "temperature": 0.0, "avg_logprob": -0.28233672832620554, "compression_ratio": 1.5904255319148937, "no_speech_prob": 7.766891940264031e-06}, {"id": 561, "seek": 259792, "start": 2611.7200000000003, "end": 2614.08, "text": " I'm going to steal off somebody who's much smarter than I am", "tokens": [286, 478, 516, 281, 11009, 766, 2618, 567, 311, 709, 20294, 813, 286, 669], "temperature": 0.0, "avg_logprob": -0.28233672832620554, "compression_ratio": 1.5904255319148937, "no_speech_prob": 7.766891940264031e-06}, {"id": 562, "seek": 259792, "start": 2615.08, "end": 2617.08, "text": " We're going to steal from a", "tokens": [492, 434, 516, 281, 11009, 490, 257], "temperature": 0.0, "avg_logprob": -0.28233672832620554, "compression_ratio": 1.5904255319148937, "no_speech_prob": 7.766891940264031e-06}, {"id": 563, "seek": 259792, "start": 2617.52, "end": 2621.76, "text": " Guy called a Tavio good a Tavio good was the guy who?", "tokens": [14690, 1219, 257, 314, 706, 1004, 665, 257, 314, 706, 1004, 665, 390, 264, 2146, 567, 30], "temperature": 0.0, "avg_logprob": -0.28233672832620554, "compression_ratio": 1.5904255319148937, "no_speech_prob": 7.766891940264031e-06}, {"id": 564, "seek": 262176, "start": 2621.76, "end": 2629.0, "text": " Created word lens which nowadays is part of Google Translate if on Google Translate you've ever like done that thing where you", "tokens": [11972, 292, 1349, 6765, 597, 13434, 307, 644, 295, 3329, 6531, 17593, 498, 322, 3329, 6531, 17593, 291, 600, 1562, 411, 1096, 300, 551, 689, 291], "temperature": 0.0, "avg_logprob": -0.2566599990382339, "compression_ratio": 1.7083333333333333, "no_speech_prob": 9.665899597166572e-06}, {"id": 565, "seek": 262176, "start": 2629.48, "end": 2631.48, "text": " Point your camera at something", "tokens": [12387, 428, 2799, 412, 746], "temperature": 0.0, "avg_logprob": -0.2566599990382339, "compression_ratio": 1.7083333333333333, "no_speech_prob": 9.665899597166572e-06}, {"id": 566, "seek": 262176, "start": 2632.28, "end": 2637.5200000000004, "text": " At something with it which has any kind of foreign language on it and in real time it overlays it with a translation", "tokens": [1711, 746, 365, 309, 597, 575, 604, 733, 295, 5329, 2856, 322, 309, 293, 294, 957, 565, 309, 15986, 3772, 309, 365, 257, 12853], "temperature": 0.0, "avg_logprob": -0.2566599990382339, "compression_ratio": 1.7083333333333333, "no_speech_prob": 9.665899597166572e-06}, {"id": 567, "seek": 262176, "start": 2637.6000000000004, "end": 2640.1600000000003, "text": " That was the Tavio's company that built that", "tokens": [663, 390, 264, 314, 706, 1004, 311, 2237, 300, 3094, 300], "temperature": 0.0, "avg_logprob": -0.2566599990382339, "compression_ratio": 1.7083333333333333, "no_speech_prob": 9.665899597166572e-06}, {"id": 568, "seek": 262176, "start": 2640.96, "end": 2646.6200000000003, "text": " And so a Tavio was kind enough to share this fantastic video he created he's at Google now", "tokens": [400, 370, 257, 314, 706, 1004, 390, 733, 1547, 281, 2073, 341, 5456, 960, 415, 2942, 415, 311, 412, 3329, 586], "temperature": 0.0, "avg_logprob": -0.2566599990382339, "compression_ratio": 1.7083333333333333, "no_speech_prob": 9.665899597166572e-06}, {"id": 569, "seek": 264662, "start": 2646.62, "end": 2651.8199999999997, "text": " And I want to kind of step you through it because I think it explains really really well", "tokens": [400, 286, 528, 281, 733, 295, 1823, 291, 807, 309, 570, 286, 519, 309, 13948, 534, 534, 731], "temperature": 0.0, "avg_logprob": -0.17955341184042334, "compression_ratio": 1.7287581699346406, "no_speech_prob": 5.014666839997517e-06}, {"id": 570, "seek": 264662, "start": 2652.5, "end": 2657.2599999999998, "text": " What's going on and then after we look at the video? We're going to see how to implement the whole a whole", "tokens": [708, 311, 516, 322, 293, 550, 934, 321, 574, 412, 264, 960, 30, 492, 434, 516, 281, 536, 577, 281, 4445, 264, 1379, 257, 1379], "temperature": 0.0, "avg_logprob": -0.17955341184042334, "compression_ratio": 1.7287581699346406, "no_speech_prob": 5.014666839997517e-06}, {"id": 571, "seek": 264662, "start": 2657.98, "end": 2663.06, "text": " Sequence of combo an entire set of layers of convolutional neural network in Microsoft Excel", "tokens": [46859, 655, 295, 16859, 364, 2302, 992, 295, 7914, 295, 45216, 304, 18161, 3209, 294, 8116, 19060], "temperature": 0.0, "avg_logprob": -0.17955341184042334, "compression_ratio": 1.7287581699346406, "no_speech_prob": 5.014666839997517e-06}, {"id": 572, "seek": 264662, "start": 2663.7799999999997, "end": 2668.6, "text": " So with your visual learner or a spreadsheet learner, hopefully you'll be able to understand all this", "tokens": [407, 365, 428, 5056, 33347, 420, 257, 27733, 33347, 11, 4696, 291, 603, 312, 1075, 281, 1223, 439, 341], "temperature": 0.0, "avg_logprob": -0.17955341184042334, "compression_ratio": 1.7287581699346406, "no_speech_prob": 5.014666839997517e-06}, {"id": 573, "seek": 264662, "start": 2669.42, "end": 2671.42, "text": " So we're going to start with an image", "tokens": [407, 321, 434, 516, 281, 722, 365, 364, 3256], "temperature": 0.0, "avg_logprob": -0.17955341184042334, "compression_ratio": 1.7287581699346406, "no_speech_prob": 5.014666839997517e-06}, {"id": 574, "seek": 264662, "start": 2671.98, "end": 2676.02, "text": " And something that we're going to do later in the course is we're going to learn to recognize digits", "tokens": [400, 746, 300, 321, 434, 516, 281, 360, 1780, 294, 264, 1164, 307, 321, 434, 516, 281, 1466, 281, 5521, 27011], "temperature": 0.0, "avg_logprob": -0.17955341184042334, "compression_ratio": 1.7287581699346406, "no_speech_prob": 5.014666839997517e-06}, {"id": 575, "seek": 267602, "start": 2676.02, "end": 2679.82, "text": " And we'll do it like end to end we'll do the whole thing so this is pretty similar", "tokens": [400, 321, 603, 360, 309, 411, 917, 281, 917, 321, 603, 360, 264, 1379, 551, 370, 341, 307, 1238, 2531], "temperature": 0.0, "avg_logprob": -0.193437466855909, "compression_ratio": 1.830188679245283, "no_speech_prob": 2.4824678348522866e-06}, {"id": 576, "seek": 267602, "start": 2680.38, "end": 2683.22, "text": " So we're going to try and recognize in this case letters", "tokens": [407, 321, 434, 516, 281, 853, 293, 5521, 294, 341, 1389, 7825], "temperature": 0.0, "avg_logprob": -0.193437466855909, "compression_ratio": 1.830188679245283, "no_speech_prob": 2.4824678348522866e-06}, {"id": 577, "seek": 267602, "start": 2683.3, "end": 2688.44, "text": " So here's an a which obviously it's actually a grid of numbers right?", "tokens": [407, 510, 311, 364, 257, 597, 2745, 309, 311, 767, 257, 10748, 295, 3547, 558, 30], "temperature": 0.0, "avg_logprob": -0.193437466855909, "compression_ratio": 1.830188679245283, "no_speech_prob": 2.4824678348522866e-06}, {"id": 578, "seek": 267602, "start": 2688.98, "end": 2692.82, "text": " And so there's the grid of numbers and so what we do is we take our first", "tokens": [400, 370, 456, 311, 264, 10748, 295, 3547, 293, 370, 437, 321, 360, 307, 321, 747, 527, 700], "temperature": 0.0, "avg_logprob": -0.193437466855909, "compression_ratio": 1.830188679245283, "no_speech_prob": 2.4824678348522866e-06}, {"id": 579, "seek": 267602, "start": 2694.46, "end": 2700.84, "text": " Convolutional filter so we're assuming this is always this is assuming that these are already learnt right and you can see this one", "tokens": [2656, 85, 3386, 304, 6608, 370, 321, 434, 11926, 341, 307, 1009, 341, 307, 11926, 300, 613, 366, 1217, 18991, 558, 293, 291, 393, 536, 341, 472], "temperature": 0.0, "avg_logprob": -0.193437466855909, "compression_ratio": 1.830188679245283, "no_speech_prob": 2.4824678348522866e-06}, {"id": 580, "seek": 267602, "start": 2700.84, "end": 2704.46, "text": " It's got white down the right hand side right and black down the left", "tokens": [467, 311, 658, 2418, 760, 264, 558, 1011, 1252, 558, 293, 2211, 760, 264, 1411], "temperature": 0.0, "avg_logprob": -0.193437466855909, "compression_ratio": 1.830188679245283, "no_speech_prob": 2.4824678348522866e-06}, {"id": 581, "seek": 270446, "start": 2704.46, "end": 2709.64, "text": " So it's like zero zero zero or maybe negative one negative one negative one zero zero zero one one one", "tokens": [407, 309, 311, 411, 4018, 4018, 4018, 420, 1310, 3671, 472, 3671, 472, 3671, 472, 4018, 4018, 4018, 472, 472, 472], "temperature": 0.0, "avg_logprob": -0.16515589175016984, "compression_ratio": 2.0580912863070537, "no_speech_prob": 5.771849373559235e-06}, {"id": 582, "seek": 270446, "start": 2709.64, "end": 2715.42, "text": " And so we're taking each three by three part of the image and multiplying it by that three by three", "tokens": [400, 370, 321, 434, 1940, 1184, 1045, 538, 1045, 644, 295, 264, 3256, 293, 30955, 309, 538, 300, 1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.16515589175016984, "compression_ratio": 2.0580912863070537, "no_speech_prob": 5.771849373559235e-06}, {"id": 583, "seek": 270446, "start": 2716.14, "end": 2721.54, "text": " Matrix not as a matrix product but an element wise product and so you can see what happens is", "tokens": [36274, 406, 382, 257, 8141, 1674, 457, 364, 4478, 10829, 1674, 293, 370, 291, 393, 536, 437, 2314, 307], "temperature": 0.0, "avg_logprob": -0.16515589175016984, "compression_ratio": 2.0580912863070537, "no_speech_prob": 5.771849373559235e-06}, {"id": 584, "seek": 270446, "start": 2722.02, "end": 2725.14, "text": " everywhere where the the white edge is", "tokens": [5315, 689, 264, 264, 2418, 4691, 307], "temperature": 0.0, "avg_logprob": -0.16515589175016984, "compression_ratio": 2.0580912863070537, "no_speech_prob": 5.771849373559235e-06}, {"id": 585, "seek": 270446, "start": 2725.7400000000002, "end": 2730.18, "text": " Matching the edge of the a and the black edge isn't we're getting green", "tokens": [26178, 278, 264, 4691, 295, 264, 257, 293, 264, 2211, 4691, 1943, 380, 321, 434, 1242, 3092], "temperature": 0.0, "avg_logprob": -0.16515589175016984, "compression_ratio": 2.0580912863070537, "no_speech_prob": 5.771849373559235e-06}, {"id": 586, "seek": 273018, "start": 2730.18, "end": 2737.1, "text": " We're getting a positive and everywhere where it's the opposite we're getting a negative. We're getting a red right and so that's the first", "tokens": [492, 434, 1242, 257, 3353, 293, 5315, 689, 309, 311, 264, 6182, 321, 434, 1242, 257, 3671, 13, 492, 434, 1242, 257, 2182, 558, 293, 370, 300, 311, 264, 700], "temperature": 0.0, "avg_logprob": -0.1372800476249607, "compression_ratio": 1.9259259259259258, "no_speech_prob": 1.1015940799552482e-06}, {"id": 587, "seek": 273018, "start": 2737.62, "end": 2739.62, "text": " filter creating the first", "tokens": [6608, 4084, 264, 700], "temperature": 0.0, "avg_logprob": -0.1372800476249607, "compression_ratio": 1.9259259259259258, "no_speech_prob": 1.1015940799552482e-06}, {"id": 588, "seek": 273018, "start": 2740.74, "end": 2744.7799999999997, "text": " The result of the first kernel right and so here's a here's a new kernel", "tokens": [440, 1874, 295, 264, 700, 28256, 558, 293, 370, 510, 311, 257, 510, 311, 257, 777, 28256], "temperature": 0.0, "avg_logprob": -0.1372800476249607, "compression_ratio": 1.9259259259259258, "no_speech_prob": 1.1015940799552482e-06}, {"id": 589, "seek": 273018, "start": 2744.7799999999997, "end": 2752.4199999999996, "text": " This one is is got a white stripe along the top right so we literally scan it through every three by three part of the matrix", "tokens": [639, 472, 307, 307, 658, 257, 2418, 42957, 2051, 264, 1192, 558, 370, 321, 3736, 11049, 309, 807, 633, 1045, 538, 1045, 644, 295, 264, 8141], "temperature": 0.0, "avg_logprob": -0.1372800476249607, "compression_ratio": 1.9259259259259258, "no_speech_prob": 1.1015940799552482e-06}, {"id": 590, "seek": 275242, "start": 2752.42, "end": 2759.78, "text": " Modifying those three bits of the a and I bits of the a by the nine bits of that filter to find out whether it's red", "tokens": [6583, 5489, 729, 1045, 9239, 295, 264, 257, 293, 286, 9239, 295, 264, 257, 538, 264, 4949, 9239, 295, 300, 6608, 281, 915, 484, 1968, 309, 311, 2182], "temperature": 0.0, "avg_logprob": -0.23535262035722493, "compression_ratio": 1.869198312236287, "no_speech_prob": 1.2482693136917078e-06}, {"id": 591, "seek": 275242, "start": 2759.78, "end": 2762.4, "text": " Or green and how red or green it is okay?", "tokens": [1610, 3092, 293, 577, 2182, 420, 3092, 309, 307, 1392, 30], "temperature": 0.0, "avg_logprob": -0.23535262035722493, "compression_ratio": 1.869198312236287, "no_speech_prob": 1.2482693136917078e-06}, {"id": 592, "seek": 275242, "start": 2762.4, "end": 2765.94, "text": " And so this is assuming we had two filters one was a bottom edge", "tokens": [400, 370, 341, 307, 11926, 321, 632, 732, 15995, 472, 390, 257, 2767, 4691], "temperature": 0.0, "avg_logprob": -0.23535262035722493, "compression_ratio": 1.869198312236287, "no_speech_prob": 1.2482693136917078e-06}, {"id": 593, "seek": 275242, "start": 2766.14, "end": 2769.94, "text": " One was a left edge, and you can see here the top edge not surprisingly", "tokens": [1485, 390, 257, 1411, 4691, 11, 293, 291, 393, 536, 510, 264, 1192, 4691, 406, 17600], "temperature": 0.0, "avg_logprob": -0.23535262035722493, "compression_ratio": 1.869198312236287, "no_speech_prob": 1.2482693136917078e-06}, {"id": 594, "seek": 275242, "start": 2769.94, "end": 2773.84, "text": " It's red here, so a bottom edge was red here and green here the right edge", "tokens": [467, 311, 2182, 510, 11, 370, 257, 2767, 4691, 390, 2182, 510, 293, 3092, 510, 264, 558, 4691], "temperature": 0.0, "avg_logprob": -0.23535262035722493, "compression_ratio": 1.869198312236287, "no_speech_prob": 1.2482693136917078e-06}, {"id": 595, "seek": 275242, "start": 2774.1800000000003, "end": 2778.48, "text": " Red here and green here and then in the next step we add a non-linearity", "tokens": [4477, 510, 293, 3092, 510, 293, 550, 294, 264, 958, 1823, 321, 909, 257, 2107, 12, 1889, 17409], "temperature": 0.0, "avg_logprob": -0.23535262035722493, "compression_ratio": 1.869198312236287, "no_speech_prob": 1.2482693136917078e-06}, {"id": 596, "seek": 277848, "start": 2778.48, "end": 2785.26, "text": " Okay, the rectified linear unit which literally means throw away the negatives so here the reds all gone", "tokens": [1033, 11, 264, 11048, 2587, 8213, 4985, 597, 3736, 1355, 3507, 1314, 264, 40019, 370, 510, 264, 2182, 82, 439, 2780], "temperature": 0.0, "avg_logprob": -0.1782628088882289, "compression_ratio": 1.9238095238095239, "no_speech_prob": 1.6536874909434118e-06}, {"id": 597, "seek": 277848, "start": 2786.0, "end": 2792.0, "text": " Okay, so here's layer one the input here's layer two the result of two convolutional filters", "tokens": [1033, 11, 370, 510, 311, 4583, 472, 264, 4846, 510, 311, 4583, 732, 264, 1874, 295, 732, 45216, 304, 15995], "temperature": 0.0, "avg_logprob": -0.1782628088882289, "compression_ratio": 1.9238095238095239, "no_speech_prob": 1.6536874909434118e-06}, {"id": 598, "seek": 277848, "start": 2792.36, "end": 2796.64, "text": " Here's layer three which is which is throw away all of the red stuff", "tokens": [1692, 311, 4583, 1045, 597, 307, 597, 307, 3507, 1314, 439, 295, 264, 2182, 1507], "temperature": 0.0, "avg_logprob": -0.1782628088882289, "compression_ratio": 1.9238095238095239, "no_speech_prob": 1.6536874909434118e-06}, {"id": 599, "seek": 277848, "start": 2796.8, "end": 2805.04, "text": " And that's called a rectified linear unit and then layer four is something called a max pull and a layer four we replace every", "tokens": [400, 300, 311, 1219, 257, 11048, 2587, 8213, 4985, 293, 550, 4583, 1451, 307, 746, 1219, 257, 11469, 2235, 293, 257, 4583, 1451, 321, 7406, 633], "temperature": 0.0, "avg_logprob": -0.1782628088882289, "compression_ratio": 1.9238095238095239, "no_speech_prob": 1.6536874909434118e-06}, {"id": 600, "seek": 277848, "start": 2805.64, "end": 2807.2, "text": " two by two", "tokens": [732, 538, 732], "temperature": 0.0, "avg_logprob": -0.1782628088882289, "compression_ratio": 1.9238095238095239, "no_speech_prob": 1.6536874909434118e-06}, {"id": 601, "seek": 280720, "start": 2807.2, "end": 2812.98, "text": " Part of this grid and we replace it with its maximum right so it basically makes it half the size", "tokens": [4100, 295, 341, 10748, 293, 321, 7406, 309, 365, 1080, 6674, 558, 370, 309, 1936, 1669, 309, 1922, 264, 2744], "temperature": 0.0, "avg_logprob": -0.13719244514192855, "compression_ratio": 1.8045112781954886, "no_speech_prob": 6.786728476981807e-07}, {"id": 602, "seek": 280720, "start": 2813.56, "end": 2819.7999999999997, "text": " It's basically the same thing but half the size and then we can go through and do exactly the same thing we can have some", "tokens": [467, 311, 1936, 264, 912, 551, 457, 1922, 264, 2744, 293, 550, 321, 393, 352, 807, 293, 360, 2293, 264, 912, 551, 321, 393, 362, 512], "temperature": 0.0, "avg_logprob": -0.13719244514192855, "compression_ratio": 1.8045112781954886, "no_speech_prob": 6.786728476981807e-07}, {"id": 603, "seek": 280720, "start": 2819.7999999999997, "end": 2826.48, "text": " New filter three by three filter that we put through each of the two results of the previous layer", "tokens": [1873, 6608, 1045, 538, 1045, 6608, 300, 321, 829, 807, 1184, 295, 264, 732, 3542, 295, 264, 3894, 4583], "temperature": 0.0, "avg_logprob": -0.13719244514192855, "compression_ratio": 1.8045112781954886, "no_speech_prob": 6.786728476981807e-07}, {"id": 604, "seek": 280720, "start": 2827.04, "end": 2828.2, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.13719244514192855, "compression_ratio": 1.8045112781954886, "no_speech_prob": 6.786728476981807e-07}, {"id": 605, "seek": 280720, "start": 2828.2, "end": 2833.8799999999997, "text": " And again we can throw away the red bits right so get rid of all the negatives, so we just keep the positives", "tokens": [400, 797, 321, 393, 3507, 1314, 264, 2182, 9239, 558, 370, 483, 3973, 295, 439, 264, 40019, 11, 370, 321, 445, 1066, 264, 35127], "temperature": 0.0, "avg_logprob": -0.13719244514192855, "compression_ratio": 1.8045112781954886, "no_speech_prob": 6.786728476981807e-07}, {"id": 606, "seek": 283388, "start": 2833.88, "end": 2837.92, "text": " That's called applying a rectified linear unit and", "tokens": [663, 311, 1219, 9275, 257, 11048, 2587, 8213, 4985, 293], "temperature": 0.0, "avg_logprob": -0.1654874098928351, "compression_ratio": 1.628, "no_speech_prob": 5.203566502132162e-07}, {"id": 607, "seek": 283388, "start": 2838.8, "end": 2842.7400000000002, "text": " That gets us to our next layer of this convolutional neural network", "tokens": [663, 2170, 505, 281, 527, 958, 4583, 295, 341, 45216, 304, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.1654874098928351, "compression_ratio": 1.628, "no_speech_prob": 5.203566502132162e-07}, {"id": 608, "seek": 283388, "start": 2842.84, "end": 2849.2000000000003, "text": " So you can see that by you know at this layer back here. It was kind of very interpretable", "tokens": [407, 291, 393, 536, 300, 538, 291, 458, 412, 341, 4583, 646, 510, 13, 467, 390, 733, 295, 588, 7302, 712], "temperature": 0.0, "avg_logprob": -0.1654874098928351, "compression_ratio": 1.628, "no_speech_prob": 5.203566502132162e-07}, {"id": 609, "seek": 283388, "start": 2849.2000000000003, "end": 2854.36, "text": " It's like we've either got bottom edges or left edges, but then the next layer was combining", "tokens": [467, 311, 411, 321, 600, 2139, 658, 2767, 8819, 420, 1411, 8819, 11, 457, 550, 264, 958, 4583, 390, 21928], "temperature": 0.0, "avg_logprob": -0.1654874098928351, "compression_ratio": 1.628, "no_speech_prob": 5.203566502132162e-07}, {"id": 610, "seek": 283388, "start": 2855.0, "end": 2860.5, "text": " The results of convolution so it's starting to become a lot less clear like intuitively what's happening", "tokens": [440, 3542, 295, 45216, 370, 309, 311, 2891, 281, 1813, 257, 688, 1570, 1850, 411, 46506, 437, 311, 2737], "temperature": 0.0, "avg_logprob": -0.1654874098928351, "compression_ratio": 1.628, "no_speech_prob": 5.203566502132162e-07}, {"id": 611, "seek": 286050, "start": 2860.5, "end": 2867.38, "text": " But it's doing the same thing and then we do another max pull right so we replace every two by two or three by three", "tokens": [583, 309, 311, 884, 264, 912, 551, 293, 550, 321, 360, 1071, 11469, 2235, 558, 370, 321, 7406, 633, 732, 538, 732, 420, 1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.17877459526062012, "compression_ratio": 1.7720930232558139, "no_speech_prob": 1.0348512660129927e-06}, {"id": 612, "seek": 286050, "start": 2867.7, "end": 2873.82, "text": " Section with a single digit so here this two by two. It's all black so we replaced it with a black", "tokens": [21804, 365, 257, 2167, 14293, 370, 510, 341, 732, 538, 732, 13, 467, 311, 439, 2211, 370, 321, 10772, 309, 365, 257, 2211], "temperature": 0.0, "avg_logprob": -0.17877459526062012, "compression_ratio": 1.7720930232558139, "no_speech_prob": 1.0348512660129927e-06}, {"id": 613, "seek": 286050, "start": 2873.82, "end": 2878.22, "text": " All right, and then we go and we take that and we we compare it", "tokens": [1057, 558, 11, 293, 550, 321, 352, 293, 321, 747, 300, 293, 321, 321, 6794, 309], "temperature": 0.0, "avg_logprob": -0.17877459526062012, "compression_ratio": 1.7720930232558139, "no_speech_prob": 1.0348512660129927e-06}, {"id": 614, "seek": 286050, "start": 2878.78, "end": 2884.78, "text": " To basically a kind of a template of what we would expect to see if it was an a it was a B", "tokens": [1407, 1936, 257, 733, 295, 257, 12379, 295, 437, 321, 576, 2066, 281, 536, 498, 309, 390, 364, 257, 309, 390, 257, 363], "temperature": 0.0, "avg_logprob": -0.17877459526062012, "compression_ratio": 1.7720930232558139, "no_speech_prob": 1.0348512660129927e-06}, {"id": 615, "seek": 286050, "start": 2884.78, "end": 2885.38, "text": " It was a C", "tokens": [467, 390, 257, 383], "temperature": 0.0, "avg_logprob": -0.17877459526062012, "compression_ratio": 1.7720930232558139, "no_speech_prob": 1.0348512660129927e-06}, {"id": 616, "seek": 288538, "start": 2885.38, "end": 2892.2200000000003, "text": " It was D and we see how closely it matches and we can do it in exactly the same way we can multiply", "tokens": [467, 390, 413, 293, 321, 536, 577, 8185, 309, 10676, 293, 321, 393, 360, 309, 294, 2293, 264, 912, 636, 321, 393, 12972], "temperature": 0.0, "avg_logprob": -0.19273946742818812, "compression_ratio": 1.8186046511627907, "no_speech_prob": 3.7266242998157395e-06}, {"id": 617, "seek": 288538, "start": 2892.5, "end": 2896.02, "text": " Every one of the values in this or by eight", "tokens": [2048, 472, 295, 264, 4190, 294, 341, 420, 538, 3180], "temperature": 0.0, "avg_logprob": -0.19273946742818812, "compression_ratio": 1.8186046511627907, "no_speech_prob": 3.7266242998157395e-06}, {"id": 618, "seek": 288538, "start": 2896.62, "end": 2902.42, "text": " Matrix with every one of the four by eight in this one and this one and this one and we add we just add them", "tokens": [36274, 365, 633, 472, 295, 264, 1451, 538, 3180, 294, 341, 472, 293, 341, 472, 293, 341, 472, 293, 321, 909, 321, 445, 909, 552], "temperature": 0.0, "avg_logprob": -0.19273946742818812, "compression_ratio": 1.8186046511627907, "no_speech_prob": 3.7266242998157395e-06}, {"id": 619, "seek": 288538, "start": 2902.42, "end": 2905.7400000000002, "text": " Together to say like how often does it match versus?", "tokens": [15911, 281, 584, 411, 577, 2049, 775, 309, 2995, 5717, 30], "temperature": 0.0, "avg_logprob": -0.19273946742818812, "compression_ratio": 1.8186046511627907, "no_speech_prob": 3.7266242998157395e-06}, {"id": 620, "seek": 288538, "start": 2905.7400000000002, "end": 2910.78, "text": " How often does it not match and then that could be converted to give us a percentage?", "tokens": [1012, 2049, 775, 309, 406, 2995, 293, 550, 300, 727, 312, 16424, 281, 976, 505, 257, 9668, 30], "temperature": 0.0, "avg_logprob": -0.19273946742818812, "compression_ratio": 1.8186046511627907, "no_speech_prob": 3.7266242998157395e-06}, {"id": 621, "seek": 291078, "start": 2910.78, "end": 2917.94, "text": " image probability that this is an a so in this case this particular template matched well with a", "tokens": [3256, 8482, 300, 341, 307, 364, 257, 370, 294, 341, 1389, 341, 1729, 12379, 21447, 731, 365, 257], "temperature": 0.0, "avg_logprob": -0.20252848086149797, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.8448179162078304e-06}, {"id": 622, "seek": 291078, "start": 2918.78, "end": 2925.1000000000004, "text": " So notice we're not doing any training here right this is how it would work if we have a pre-trained model", "tokens": [407, 3449, 321, 434, 406, 884, 604, 3097, 510, 558, 341, 307, 577, 309, 576, 589, 498, 321, 362, 257, 659, 12, 17227, 2001, 2316], "temperature": 0.0, "avg_logprob": -0.20252848086149797, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.8448179162078304e-06}, {"id": 623, "seek": 291078, "start": 2925.38, "end": 2925.94, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.20252848086149797, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.8448179162078304e-06}, {"id": 624, "seek": 291078, "start": 2925.94, "end": 2931.86, "text": " So when we download a pre-trained image net model off the internet and is it on an image without any changing to it?", "tokens": [407, 562, 321, 5484, 257, 659, 12, 17227, 2001, 3256, 2533, 2316, 766, 264, 4705, 293, 307, 309, 322, 364, 3256, 1553, 604, 4473, 281, 309, 30], "temperature": 0.0, "avg_logprob": -0.20252848086149797, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.8448179162078304e-06}, {"id": 625, "seek": 291078, "start": 2932.0600000000004, "end": 2933.26, "text": " This is what's happening", "tokens": [639, 307, 437, 311, 2737], "temperature": 0.0, "avg_logprob": -0.20252848086149797, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.8448179162078304e-06}, {"id": 626, "seek": 291078, "start": 2933.26, "end": 2938.9, "text": " Or if we take a model that you've trained and you're applying it to some test set or to some new image", "tokens": [1610, 498, 321, 747, 257, 2316, 300, 291, 600, 8895, 293, 291, 434, 9275, 309, 281, 512, 1500, 992, 420, 281, 512, 777, 3256], "temperature": 0.0, "avg_logprob": -0.20252848086149797, "compression_ratio": 1.7547892720306513, "no_speech_prob": 1.8448179162078304e-06}, {"id": 627, "seek": 293890, "start": 2938.9, "end": 2946.0, "text": " This is what it's doing right is it's basically taking it through its applying a convolution to each layer to each multiple", "tokens": [639, 307, 437, 309, 311, 884, 558, 307, 309, 311, 1936, 1940, 309, 807, 1080, 9275, 257, 45216, 281, 1184, 4583, 281, 1184, 3866], "temperature": 0.0, "avg_logprob": -0.2103057114974312, "compression_ratio": 1.7649769585253456, "no_speech_prob": 1.8738682001639972e-06}, {"id": 628, "seek": 293890, "start": 2947.14, "end": 2949.14, "text": " convolutional filters to each layer", "tokens": [45216, 304, 15995, 281, 1184, 4583], "temperature": 0.0, "avg_logprob": -0.2103057114974312, "compression_ratio": 1.7649769585253456, "no_speech_prob": 1.8738682001639972e-06}, {"id": 629, "seek": 293890, "start": 2950.1, "end": 2951.78, "text": " and then", "tokens": [293, 550], "temperature": 0.0, "avg_logprob": -0.2103057114974312, "compression_ratio": 1.7649769585253456, "no_speech_prob": 1.8738682001639972e-06}, {"id": 630, "seek": 293890, "start": 2951.78, "end": 2956.38, "text": " Doing the rectified linear unit so throw away the negatives and then do the max pull", "tokens": [18496, 264, 11048, 2587, 8213, 4985, 370, 3507, 1314, 264, 40019, 293, 550, 360, 264, 11469, 2235], "temperature": 0.0, "avg_logprob": -0.2103057114974312, "compression_ratio": 1.7649769585253456, "no_speech_prob": 1.8738682001639972e-06}, {"id": 631, "seek": 293890, "start": 2957.38, "end": 2961.9, "text": " And then repeat that a bunch of times and so then we can do it with a new", "tokens": [400, 550, 7149, 300, 257, 3840, 295, 1413, 293, 370, 550, 321, 393, 360, 309, 365, 257, 777], "temperature": 0.0, "avg_logprob": -0.2103057114974312, "compression_ratio": 1.7649769585253456, "no_speech_prob": 1.8738682001639972e-06}, {"id": 632, "seek": 293890, "start": 2962.42, "end": 2966.46, "text": " letter a or letter B or whatever and keep going through", "tokens": [5063, 257, 420, 5063, 363, 420, 2035, 293, 1066, 516, 807], "temperature": 0.0, "avg_logprob": -0.2103057114974312, "compression_ratio": 1.7649769585253456, "no_speech_prob": 1.8738682001639972e-06}, {"id": 633, "seek": 296646, "start": 2966.46, "end": 2967.98, "text": " that", "tokens": [300], "temperature": 0.0, "avg_logprob": -0.18831720891988502, "compression_ratio": 1.7364341085271318, "no_speech_prob": 1.4823532410446205e-06}, {"id": 634, "seek": 296646, "start": 2967.98, "end": 2969.98, "text": " process", "tokens": [1399], "temperature": 0.0, "avg_logprob": -0.18831720891988502, "compression_ratio": 1.7364341085271318, "no_speech_prob": 1.4823532410446205e-06}, {"id": 635, "seek": 296646, "start": 2969.98, "end": 2975.42, "text": " So as you can see that's far nicer visualization thing and I could have created because I'm not a table", "tokens": [407, 382, 291, 393, 536, 300, 311, 1400, 22842, 25801, 551, 293, 286, 727, 362, 2942, 570, 286, 478, 406, 257, 3199], "temperature": 0.0, "avg_logprob": -0.18831720891988502, "compression_ratio": 1.7364341085271318, "no_speech_prob": 1.4823532410446205e-06}, {"id": 636, "seek": 296646, "start": 2975.42, "end": 2979.54, "text": " So thanks to him for for sharing this with us because it's totally awesome", "tokens": [407, 3231, 281, 796, 337, 337, 5414, 341, 365, 505, 570, 309, 311, 3879, 3476], "temperature": 0.0, "avg_logprob": -0.18831720891988502, "compression_ratio": 1.7364341085271318, "no_speech_prob": 1.4823532410446205e-06}, {"id": 637, "seek": 296646, "start": 2980.18, "end": 2985.78, "text": " He actually this is not done by hand. He actually wrote a piece of computer software to actually do these convolutions", "tokens": [634, 767, 341, 307, 406, 1096, 538, 1011, 13, 634, 767, 4114, 257, 2522, 295, 3820, 4722, 281, 767, 360, 613, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.18831720891988502, "compression_ratio": 1.7364341085271318, "no_speech_prob": 1.4823532410446205e-06}, {"id": 638, "seek": 296646, "start": 2985.78, "end": 2990.26, "text": " This is actually being actually being done dynamically. It's pretty cool", "tokens": [639, 307, 767, 885, 767, 885, 1096, 43492, 13, 467, 311, 1238, 1627], "temperature": 0.0, "avg_logprob": -0.18831720891988502, "compression_ratio": 1.7364341085271318, "no_speech_prob": 1.4823532410446205e-06}, {"id": 639, "seek": 296646, "start": 2990.9, "end": 2995.2200000000003, "text": " So I'm more of a spreadsheet guy personally. I'm a simple person", "tokens": [407, 286, 478, 544, 295, 257, 27733, 2146, 5665, 13, 286, 478, 257, 2199, 954], "temperature": 0.0, "avg_logprob": -0.18831720891988502, "compression_ratio": 1.7364341085271318, "no_speech_prob": 1.4823532410446205e-06}, {"id": 640, "seek": 299522, "start": 2995.22, "end": 3002.3399999999997, "text": " So here is the same thing now in spreadsheet form right and so you'll find this in the github repo", "tokens": [407, 510, 307, 264, 912, 551, 586, 294, 27733, 1254, 558, 293, 370, 291, 603, 915, 341, 294, 264, 290, 355, 836, 49040], "temperature": 0.0, "avg_logprob": -0.22474541664123535, "compression_ratio": 1.6162790697674418, "no_speech_prob": 7.5279376687831245e-06}, {"id": 641, "seek": 299522, "start": 3002.3399999999997, "end": 3004.3399999999997, "text": " so you can either", "tokens": [370, 291, 393, 2139], "temperature": 0.0, "avg_logprob": -0.22474541664123535, "compression_ratio": 1.6162790697674418, "no_speech_prob": 7.5279376687831245e-06}, {"id": 642, "seek": 299522, "start": 3004.3799999999997, "end": 3009.9399999999996, "text": " Get clone the repo to your own computer to open up the spreadsheet or you can just go to github.com", "tokens": [3240, 26506, 264, 49040, 281, 428, 1065, 3820, 281, 1269, 493, 264, 27733, 420, 291, 393, 445, 352, 281, 290, 355, 836, 13, 1112], "temperature": 0.0, "avg_logprob": -0.22474541664123535, "compression_ratio": 1.6162790697674418, "no_speech_prob": 7.5279376687831245e-06}, {"id": 643, "seek": 299522, "start": 3010.4599999999996, "end": 3012.18, "text": " fast AI and", "tokens": [2370, 7318, 293], "temperature": 0.0, "avg_logprob": -0.22474541664123535, "compression_ratio": 1.6162790697674418, "no_speech_prob": 7.5279376687831245e-06}, {"id": 644, "seek": 299522, "start": 3012.18, "end": 3014.3399999999997, "text": " Click on this it sits inside", "tokens": [8230, 322, 341, 309, 12696, 1854], "temperature": 0.0, "avg_logprob": -0.22474541664123535, "compression_ratio": 1.6162790697674418, "no_speech_prob": 7.5279376687831245e-06}, {"id": 645, "seek": 299522, "start": 3020.3799999999997, "end": 3022.3399999999997, "text": " If you go to my repo", "tokens": [759, 291, 352, 281, 452, 49040], "temperature": 0.0, "avg_logprob": -0.22474541664123535, "compression_ratio": 1.6162790697674418, "no_speech_prob": 7.5279376687831245e-06}, {"id": 646, "seek": 302234, "start": 3022.34, "end": 3028.5, "text": " And just go to courses as usual go to deal one as usual you'll see there's an Excel section there", "tokens": [400, 445, 352, 281, 7712, 382, 7713, 352, 281, 2028, 472, 382, 7713, 291, 603, 536, 456, 311, 364, 19060, 3541, 456], "temperature": 0.0, "avg_logprob": -0.22216819536567914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 1.459368945688766e-06}, {"id": 647, "seek": 302234, "start": 3028.54, "end": 3034.34, "text": " Okay, and so here they all are so you can just download them by clicking them or you can clone the whole repo and we're looking", "tokens": [1033, 11, 293, 370, 510, 436, 439, 366, 370, 291, 393, 445, 5484, 552, 538, 9697, 552, 420, 291, 393, 26506, 264, 1379, 49040, 293, 321, 434, 1237], "temperature": 0.0, "avg_logprob": -0.22216819536567914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 1.459368945688766e-06}, {"id": 648, "seek": 302234, "start": 3034.34, "end": 3035.26, "text": " at", "tokens": [412], "temperature": 0.0, "avg_logprob": -0.22216819536567914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 1.459368945688766e-06}, {"id": 649, "seek": 302234, "start": 3035.26, "end": 3041.6200000000003, "text": " conv example convolution example, right so you can see I have here an", "tokens": [3754, 1365, 45216, 1365, 11, 558, 370, 291, 393, 536, 286, 362, 510, 364], "temperature": 0.0, "avg_logprob": -0.22216819536567914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 1.459368945688766e-06}, {"id": 650, "seek": 302234, "start": 3042.98, "end": 3049.82, "text": " Input right so in this case the input is the number seven so I grabbed this from a data set called M list", "tokens": [682, 2582, 558, 370, 294, 341, 1389, 264, 4846, 307, 264, 1230, 3407, 370, 286, 18607, 341, 490, 257, 1412, 992, 1219, 376, 1329], "temperature": 0.0, "avg_logprob": -0.22216819536567914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 1.459368945688766e-06}, {"id": 651, "seek": 304982, "start": 3049.82, "end": 3052.96, "text": " M and IST which we'll be looking at in a lot of detail", "tokens": [376, 293, 6205, 51, 597, 321, 603, 312, 1237, 412, 294, 257, 688, 295, 2607], "temperature": 0.0, "avg_logprob": -0.24367111508208927, "compression_ratio": 1.658008658008658, "no_speech_prob": 5.682404207618674e-06}, {"id": 652, "seek": 304982, "start": 3053.6600000000003, "end": 3060.02, "text": " And I just took one of those digits at random and I put it into Excel and so you can see every", "tokens": [400, 286, 445, 1890, 472, 295, 729, 27011, 412, 4974, 293, 286, 829, 309, 666, 19060, 293, 370, 291, 393, 536, 633], "temperature": 0.0, "avg_logprob": -0.24367111508208927, "compression_ratio": 1.658008658008658, "no_speech_prob": 5.682404207618674e-06}, {"id": 653, "seek": 304982, "start": 3060.5800000000004, "end": 3063.7400000000002, "text": " Pixel is actually just a number between naught and one", "tokens": [28323, 307, 767, 445, 257, 1230, 1296, 13138, 293, 472], "temperature": 0.0, "avg_logprob": -0.24367111508208927, "compression_ratio": 1.658008658008658, "no_speech_prob": 5.682404207618674e-06}, {"id": 654, "seek": 304982, "start": 3064.7000000000003, "end": 3067.5, "text": " Okay, very often actually it'll be a", "tokens": [1033, 11, 588, 2049, 767, 309, 603, 312, 257], "temperature": 0.0, "avg_logprob": -0.24367111508208927, "compression_ratio": 1.658008658008658, "no_speech_prob": 5.682404207618674e-06}, {"id": 655, "seek": 304982, "start": 3069.1400000000003, "end": 3071.1400000000003, "text": " Byte between naught and 255", "tokens": [3146, 975, 1296, 13138, 293, 3552, 20], "temperature": 0.0, "avg_logprob": -0.24367111508208927, "compression_ratio": 1.658008658008658, "no_speech_prob": 5.682404207618674e-06}, {"id": 656, "seek": 304982, "start": 3071.86, "end": 3078.2200000000003, "text": " Or sometimes it might be a float between naught and one it doesn't really matter by the time it gets to pie torch", "tokens": [1610, 2171, 309, 1062, 312, 257, 15706, 1296, 13138, 293, 472, 309, 1177, 380, 534, 1871, 538, 264, 565, 309, 2170, 281, 1730, 27822], "temperature": 0.0, "avg_logprob": -0.24367111508208927, "compression_ratio": 1.658008658008658, "no_speech_prob": 5.682404207618674e-06}, {"id": 657, "seek": 307822, "start": 3078.22, "end": 3080.22, "text": " We're generally dealing with floats", "tokens": [492, 434, 5101, 6260, 365, 37878], "temperature": 0.0, "avg_logprob": -0.12081104278564453, "compression_ratio": 1.626984126984127, "no_speech_prob": 1.6028056961658876e-06}, {"id": 658, "seek": 307822, "start": 3081.5, "end": 3086.52, "text": " So we if one of the steps we often will take will be to convert it to a number between naught and one", "tokens": [407, 321, 498, 472, 295, 264, 4439, 321, 2049, 486, 747, 486, 312, 281, 7620, 309, 281, 257, 1230, 1296, 13138, 293, 472], "temperature": 0.0, "avg_logprob": -0.12081104278564453, "compression_ratio": 1.626984126984127, "no_speech_prob": 1.6028056961658876e-06}, {"id": 659, "seek": 307822, "start": 3088.3399999999997, "end": 3094.5, "text": " So then you can see I've just used conditional formatting in Excel to kind of make the higher numbers more red", "tokens": [407, 550, 291, 393, 536, 286, 600, 445, 1143, 27708, 39366, 294, 19060, 281, 733, 295, 652, 264, 2946, 3547, 544, 2182], "temperature": 0.0, "avg_logprob": -0.12081104278564453, "compression_ratio": 1.626984126984127, "no_speech_prob": 1.6028056961658876e-06}, {"id": 660, "seek": 307822, "start": 3094.5, "end": 3098.4399999999996, "text": " So you can clearly see that this is a red that this is a seven", "tokens": [407, 291, 393, 4448, 536, 300, 341, 307, 257, 2182, 300, 341, 307, 257, 3407], "temperature": 0.0, "avg_logprob": -0.12081104278564453, "compression_ratio": 1.626984126984127, "no_speech_prob": 1.6028056961658876e-06}, {"id": 661, "seek": 309844, "start": 3098.44, "end": 3108.08, "text": " But but it's just a bunch of numbers that have been imported into Excel. Okay, so here's our input", "tokens": [583, 457, 309, 311, 445, 257, 3840, 295, 3547, 300, 362, 668, 25524, 666, 19060, 13, 1033, 11, 370, 510, 311, 527, 4846], "temperature": 0.0, "avg_logprob": -0.238510529200236, "compression_ratio": 1.4773869346733668, "no_speech_prob": 2.026138645305764e-06}, {"id": 662, "seek": 309844, "start": 3109.0, "end": 3116.12, "text": " So remember what a table you did was he then applied two filters right with different shapes", "tokens": [407, 1604, 437, 257, 3199, 291, 630, 390, 415, 550, 6456, 732, 15995, 558, 365, 819, 10854], "temperature": 0.0, "avg_logprob": -0.238510529200236, "compression_ratio": 1.4773869346733668, "no_speech_prob": 2.026138645305764e-06}, {"id": 663, "seek": 309844, "start": 3116.2000000000003, "end": 3121.12, "text": " So here I've created a filter which is designed to detect top edges", "tokens": [407, 510, 286, 600, 2942, 257, 6608, 597, 307, 4761, 281, 5531, 1192, 8819], "temperature": 0.0, "avg_logprob": -0.238510529200236, "compression_ratio": 1.4773869346733668, "no_speech_prob": 2.026138645305764e-06}, {"id": 664, "seek": 309844, "start": 3121.56, "end": 3123.78, "text": " So this is a three by three filter", "tokens": [407, 341, 307, 257, 1045, 538, 1045, 6608], "temperature": 0.0, "avg_logprob": -0.238510529200236, "compression_ratio": 1.4773869346733668, "no_speech_prob": 2.026138645305764e-06}, {"id": 665, "seek": 312378, "start": 3123.78, "end": 3129.5400000000004, "text": " Okay, and I've got ones along the top zeros in the middle minus ones at the bottom, right?", "tokens": [1033, 11, 293, 286, 600, 658, 2306, 2051, 264, 1192, 35193, 294, 264, 2808, 3175, 2306, 412, 264, 2767, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15964845735199598, "compression_ratio": 1.6515837104072397, "no_speech_prob": 1.4593741752833012e-06}, {"id": 666, "seek": 312378, "start": 3129.6200000000003, "end": 3133.5400000000004, "text": " So let's take a look at an example that's here, right?", "tokens": [407, 718, 311, 747, 257, 574, 412, 364, 1365, 300, 311, 510, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15964845735199598, "compression_ratio": 1.6515837104072397, "no_speech_prob": 1.4593741752833012e-06}, {"id": 667, "seek": 312378, "start": 3133.5400000000004, "end": 3138.1000000000004, "text": " And so if I hit F2 you can see here highlighted", "tokens": [400, 370, 498, 286, 2045, 479, 17, 291, 393, 536, 510, 17173], "temperature": 0.0, "avg_logprob": -0.15964845735199598, "compression_ratio": 1.6515837104072397, "no_speech_prob": 1.4593741752833012e-06}, {"id": 668, "seek": 312378, "start": 3138.38, "end": 3143.76, "text": " This is the three by three part of the input that this particular thing is calculating, right?", "tokens": [639, 307, 264, 1045, 538, 1045, 644, 295, 264, 4846, 300, 341, 1729, 551, 307, 28258, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15964845735199598, "compression_ratio": 1.6515837104072397, "no_speech_prob": 1.4593741752833012e-06}, {"id": 669, "seek": 312378, "start": 3144.02, "end": 3149.5800000000004, "text": " so here you can see it's got one one one are all being multiplied by one and", "tokens": [370, 510, 291, 393, 536, 309, 311, 658, 472, 472, 472, 366, 439, 885, 17207, 538, 472, 293], "temperature": 0.0, "avg_logprob": -0.15964845735199598, "compression_ratio": 1.6515837104072397, "no_speech_prob": 1.4593741752833012e-06}, {"id": 670, "seek": 314958, "start": 3149.58, "end": 3154.88, "text": " Point one zero zero are all being multiplied by negative one", "tokens": [12387, 472, 4018, 4018, 366, 439, 885, 17207, 538, 3671, 472], "temperature": 0.0, "avg_logprob": -0.14980642846290101, "compression_ratio": 1.7566371681415929, "no_speech_prob": 2.3320683339989046e-06}, {"id": 671, "seek": 314958, "start": 3155.74, "end": 3161.58, "text": " Okay, so in other words all the positive bits are getting a lot of positive the negative bits are getting really nearly nothing at all", "tokens": [1033, 11, 370, 294, 661, 2283, 439, 264, 3353, 9239, 366, 1242, 257, 688, 295, 3353, 264, 3671, 9239, 366, 1242, 534, 6217, 1825, 412, 439], "temperature": 0.0, "avg_logprob": -0.14980642846290101, "compression_ratio": 1.7566371681415929, "no_speech_prob": 2.3320683339989046e-06}, {"id": 672, "seek": 314958, "start": 3161.74, "end": 3163.74, "text": " So we end up with a high number", "tokens": [407, 321, 917, 493, 365, 257, 1090, 1230], "temperature": 0.0, "avg_logprob": -0.14980642846290101, "compression_ratio": 1.7566371681415929, "no_speech_prob": 2.3320683339989046e-06}, {"id": 673, "seek": 314958, "start": 3164.62, "end": 3168.2599999999998, "text": " Okay, where else on the other side of this bit of the seven?", "tokens": [1033, 11, 689, 1646, 322, 264, 661, 1252, 295, 341, 857, 295, 264, 3407, 30], "temperature": 0.0, "avg_logprob": -0.14980642846290101, "compression_ratio": 1.7566371681415929, "no_speech_prob": 2.3320683339989046e-06}, {"id": 674, "seek": 316826, "start": 3168.26, "end": 3179.3, "text": " Right you can see how you know this is basically zeros here or perhaps more interestingly on the top of it, right?", "tokens": [1779, 291, 393, 536, 577, 291, 458, 341, 307, 1936, 35193, 510, 420, 4317, 544, 25873, 322, 264, 1192, 295, 309, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17345231154869342, "compression_ratio": 1.6281407035175879, "no_speech_prob": 6.475938789662905e-07}, {"id": 675, "seek": 316826, "start": 3181.5400000000004, "end": 3183.38, "text": " Here we've got", "tokens": [1692, 321, 600, 658], "temperature": 0.0, "avg_logprob": -0.17345231154869342, "compression_ratio": 1.6281407035175879, "no_speech_prob": 6.475938789662905e-07}, {"id": 676, "seek": 316826, "start": 3183.38, "end": 3187.86, "text": " High numbers at the top, but we've also got high numbers at the bottom which are negating it", "tokens": [5229, 3547, 412, 264, 1192, 11, 457, 321, 600, 611, 658, 1090, 3547, 412, 264, 2767, 597, 366, 2485, 990, 309], "temperature": 0.0, "avg_logprob": -0.17345231154869342, "compression_ratio": 1.6281407035175879, "no_speech_prob": 6.475938789662905e-07}, {"id": 677, "seek": 316826, "start": 3188.38, "end": 3191.38, "text": " Okay, so you can see that the only place that we end up", "tokens": [1033, 11, 370, 291, 393, 536, 300, 264, 787, 1081, 300, 321, 917, 493], "temperature": 0.0, "avg_logprob": -0.17345231154869342, "compression_ratio": 1.6281407035175879, "no_speech_prob": 6.475938789662905e-07}, {"id": 678, "seek": 316826, "start": 3192.42, "end": 3194.0600000000004, "text": " Activating is", "tokens": [28550, 990, 307], "temperature": 0.0, "avg_logprob": -0.17345231154869342, "compression_ratio": 1.6281407035175879, "no_speech_prob": 6.475938789662905e-07}, {"id": 679, "seek": 316826, "start": 3194.0600000000004, "end": 3196.0600000000004, "text": " Where we're actually at an edge", "tokens": [2305, 321, 434, 767, 412, 364, 4691], "temperature": 0.0, "avg_logprob": -0.17345231154869342, "compression_ratio": 1.6281407035175879, "no_speech_prob": 6.475938789662905e-07}, {"id": 680, "seek": 319606, "start": 3196.06, "end": 3197.7799999999997, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.24991008883616964, "compression_ratio": 1.6764705882352942, "no_speech_prob": 6.786727908547618e-07}, {"id": 681, "seek": 319606, "start": 3197.7799999999997, "end": 3200.2999999999997, "text": " So in this case this here this number three", "tokens": [407, 294, 341, 1389, 341, 510, 341, 1230, 1045], "temperature": 0.0, "avg_logprob": -0.24991008883616964, "compression_ratio": 1.6764705882352942, "no_speech_prob": 6.786727908547618e-07}, {"id": 682, "seek": 319606, "start": 3201.22, "end": 3203.22, "text": " This is called an activation", "tokens": [639, 307, 1219, 364, 24433], "temperature": 0.0, "avg_logprob": -0.24991008883616964, "compression_ratio": 1.6764705882352942, "no_speech_prob": 6.786727908547618e-07}, {"id": 683, "seek": 319606, "start": 3204.06, "end": 3210.34, "text": " Okay, so when I say an activation, I mean a number a number a", "tokens": [1033, 11, 370, 562, 286, 584, 364, 24433, 11, 286, 914, 257, 1230, 257, 1230, 257], "temperature": 0.0, "avg_logprob": -0.24991008883616964, "compression_ratio": 1.6764705882352942, "no_speech_prob": 6.786727908547618e-07}, {"id": 684, "seek": 319606, "start": 3211.94, "end": 3216.82, "text": " Number that is calculated and it is calculated by taking", "tokens": [5118, 300, 307, 15598, 293, 309, 307, 15598, 538, 1940], "temperature": 0.0, "avg_logprob": -0.24991008883616964, "compression_ratio": 1.6764705882352942, "no_speech_prob": 6.786727908547618e-07}, {"id": 685, "seek": 319606, "start": 3217.98, "end": 3220.1, "text": " some numbers from the input and", "tokens": [512, 3547, 490, 264, 4846, 293], "temperature": 0.0, "avg_logprob": -0.24991008883616964, "compression_ratio": 1.6764705882352942, "no_speech_prob": 6.786727908547618e-07}, {"id": 686, "seek": 322010, "start": 3220.1, "end": 3228.62, "text": " Applying some kind of linear operation in this case a convolutional kernel to calculate an output", "tokens": [3132, 7310, 512, 733, 295, 8213, 6916, 294, 341, 1389, 257, 45216, 304, 28256, 281, 8873, 364, 5598], "temperature": 0.0, "avg_logprob": -0.29337041671961955, "compression_ratio": 1.553191489361702, "no_speech_prob": 1.1015943073289236e-06}, {"id": 687, "seek": 322010, "start": 3229.46, "end": 3232.98, "text": " Right you'll notice that other than going", "tokens": [1779, 291, 603, 3449, 300, 661, 813, 516], "temperature": 0.0, "avg_logprob": -0.29337041671961955, "compression_ratio": 1.553191489361702, "no_speech_prob": 1.1015943073289236e-06}, {"id": 688, "seek": 322010, "start": 3234.5, "end": 3237.18, "text": " inputs multiplied by kernel and", "tokens": [15743, 17207, 538, 28256, 293], "temperature": 0.0, "avg_logprob": -0.29337041671961955, "compression_ratio": 1.553191489361702, "no_speech_prob": 1.1015943073289236e-06}, {"id": 689, "seek": 322010, "start": 3238.02, "end": 3239.7, "text": " Summing it together", "tokens": [8626, 2810, 309, 1214], "temperature": 0.0, "avg_logprob": -0.29337041671961955, "compression_ratio": 1.553191489361702, "no_speech_prob": 1.1015943073289236e-06}, {"id": 690, "seek": 322010, "start": 3239.7, "end": 3247.6, "text": " All right, so here's my sum and here's my multiply. I then take that and I go max of zero comma that", "tokens": [1057, 558, 11, 370, 510, 311, 452, 2408, 293, 510, 311, 452, 12972, 13, 286, 550, 747, 300, 293, 286, 352, 11469, 295, 4018, 22117, 300], "temperature": 0.0, "avg_logprob": -0.29337041671961955, "compression_ratio": 1.553191489361702, "no_speech_prob": 1.1015943073289236e-06}, {"id": 691, "seek": 324760, "start": 3247.6, "end": 3252.2799999999997, "text": " And so that's my rectified linear unit. So it sounds very fancy", "tokens": [400, 370, 300, 311, 452, 11048, 2587, 8213, 4985, 13, 407, 309, 3263, 588, 10247], "temperature": 0.0, "avg_logprob": -0.22701081169976128, "compression_ratio": 1.7233009708737863, "no_speech_prob": 2.190777649957454e-06}, {"id": 692, "seek": 324760, "start": 3253.24, "end": 3259.56, "text": " Rectified linear unit, but what they actually mean is open up Excel and type equals max zero comma thing. Okay", "tokens": [497, 557, 2587, 8213, 4985, 11, 457, 437, 436, 767, 914, 307, 1269, 493, 19060, 293, 2010, 6915, 11469, 4018, 22117, 551, 13, 1033], "temperature": 0.0, "avg_logprob": -0.22701081169976128, "compression_ratio": 1.7233009708737863, "no_speech_prob": 2.190777649957454e-06}, {"id": 693, "seek": 324760, "start": 3261.16, "end": 3267.2, "text": " That's all around then you'll see people in the biz still to say rally you okay, so rally you means", "tokens": [663, 311, 439, 926, 550, 291, 603, 536, 561, 294, 264, 7390, 920, 281, 584, 17584, 291, 1392, 11, 370, 17584, 291, 1355], "temperature": 0.0, "avg_logprob": -0.22701081169976128, "compression_ratio": 1.7233009708737863, "no_speech_prob": 2.190777649957454e-06}, {"id": 694, "seek": 324760, "start": 3267.7999999999997, "end": 3273.74, "text": " Rectified linear unit means max zero comma thing and I'm not like simplifying it", "tokens": [497, 557, 2587, 8213, 4985, 1355, 11469, 4018, 22117, 551, 293, 286, 478, 406, 411, 6883, 5489, 309], "temperature": 0.0, "avg_logprob": -0.22701081169976128, "compression_ratio": 1.7233009708737863, "no_speech_prob": 2.190777649957454e-06}, {"id": 695, "seek": 327374, "start": 3273.74, "end": 3277.7999999999997, "text": " I really mean it like when I say like if I'm simplifying I'll always say I'm simplifying", "tokens": [286, 534, 914, 309, 411, 562, 286, 584, 411, 498, 286, 478, 6883, 5489, 286, 603, 1009, 584, 286, 478, 6883, 5489], "temperature": 0.0, "avg_logprob": -0.21225613488091363, "compression_ratio": 1.875, "no_speech_prob": 2.96490412665662e-07}, {"id": 696, "seek": 327374, "start": 3278.12, "end": 3284.4799999999996, "text": " But if I'm not saying I'm simplifying that's the entirety. Okay, so a rectified linear unit in its entirety is this", "tokens": [583, 498, 286, 478, 406, 1566, 286, 478, 6883, 5489, 300, 311, 264, 31557, 13, 1033, 11, 370, 257, 11048, 2587, 8213, 4985, 294, 1080, 31557, 307, 341], "temperature": 0.0, "avg_logprob": -0.21225613488091363, "compression_ratio": 1.875, "no_speech_prob": 2.96490412665662e-07}, {"id": 697, "seek": 327374, "start": 3285.2, "end": 3288.2799999999997, "text": " and a convolution in its entirety is", "tokens": [293, 257, 45216, 294, 1080, 31557, 307], "temperature": 0.0, "avg_logprob": -0.21225613488091363, "compression_ratio": 1.875, "no_speech_prob": 2.96490412665662e-07}, {"id": 698, "seek": 327374, "start": 3289.24, "end": 3290.9799999999996, "text": " Is this?", "tokens": [1119, 341, 30], "temperature": 0.0, "avg_logprob": -0.21225613488091363, "compression_ratio": 1.875, "no_speech_prob": 2.96490412665662e-07}, {"id": 699, "seek": 327374, "start": 3290.9799999999996, "end": 3298.7799999999997, "text": " Okay, so a single layer of a convolutional neural network is being implemented in its entirety", "tokens": [1033, 11, 370, 257, 2167, 4583, 295, 257, 45216, 304, 18161, 3209, 307, 885, 12270, 294, 1080, 31557], "temperature": 0.0, "avg_logprob": -0.21225613488091363, "compression_ratio": 1.875, "no_speech_prob": 2.96490412665662e-07}, {"id": 700, "seek": 329878, "start": 3298.78, "end": 3305.6200000000003, "text": " Here in Excel, okay, and so you can see what it's done is it's deleted", "tokens": [1692, 294, 19060, 11, 1392, 11, 293, 370, 291, 393, 536, 437, 309, 311, 1096, 307, 309, 311, 22981], "temperature": 0.0, "avg_logprob": -0.2260631514184269, "compression_ratio": 1.6226415094339623, "no_speech_prob": 7.690367169743695e-07}, {"id": 701, "seek": 329878, "start": 3306.2200000000003, "end": 3310.6200000000003, "text": " Pretty much the vertical edges and highlighted the horizontal edges", "tokens": [10693, 709, 264, 9429, 8819, 293, 17173, 264, 12750, 8819], "temperature": 0.0, "avg_logprob": -0.2260631514184269, "compression_ratio": 1.6226415094339623, "no_speech_prob": 7.690367169743695e-07}, {"id": 702, "seek": 329878, "start": 3311.6200000000003, "end": 3315.94, "text": " so again, this is assuming that our network is trained and", "tokens": [370, 797, 11, 341, 307, 11926, 300, 527, 3209, 307, 8895, 293], "temperature": 0.0, "avg_logprob": -0.2260631514184269, "compression_ratio": 1.6226415094339623, "no_speech_prob": 7.690367169743695e-07}, {"id": 703, "seek": 329878, "start": 3316.46, "end": 3322.0600000000004, "text": " That at the end of training it had created a convolutional filter with these specific nine numbers in", "tokens": [663, 412, 264, 917, 295, 3097, 309, 632, 2942, 257, 45216, 304, 6608, 365, 613, 2685, 4949, 3547, 294], "temperature": 0.0, "avg_logprob": -0.2260631514184269, "compression_ratio": 1.6226415094339623, "no_speech_prob": 7.690367169743695e-07}, {"id": 704, "seek": 329878, "start": 3323.3, "end": 3326.9, "text": " And so here is a second convolutional filter", "tokens": [400, 370, 510, 307, 257, 1150, 45216, 304, 6608], "temperature": 0.0, "avg_logprob": -0.2260631514184269, "compression_ratio": 1.6226415094339623, "no_speech_prob": 7.690367169743695e-07}, {"id": 705, "seek": 332690, "start": 3326.9, "end": 3329.7400000000002, "text": " It's just a different nine numbers", "tokens": [467, 311, 445, 257, 819, 4949, 3547], "temperature": 0.0, "avg_logprob": -0.2640532766069685, "compression_ratio": 1.62, "no_speech_prob": 3.5559760362957604e-06}, {"id": 706, "seek": 332690, "start": 3330.46, "end": 3336.02, "text": " Now pi torch doesn't store them as two separate nine digit arrays", "tokens": [823, 3895, 27822, 1177, 380, 3531, 552, 382, 732, 4994, 4949, 14293, 41011], "temperature": 0.0, "avg_logprob": -0.2640532766069685, "compression_ratio": 1.62, "no_speech_prob": 3.5559760362957604e-06}, {"id": 707, "seek": 332690, "start": 3336.5, "end": 3342.6800000000003, "text": " It stores it as a tensor. Remember a tensor just means an array with", "tokens": [467, 9512, 309, 382, 257, 40863, 13, 5459, 257, 40863, 445, 1355, 364, 10225, 365], "temperature": 0.0, "avg_logprob": -0.2640532766069685, "compression_ratio": 1.62, "no_speech_prob": 3.5559760362957604e-06}, {"id": 708, "seek": 332690, "start": 3343.5, "end": 3348.3, "text": " More dimensions. Okay, you can use the word array as well", "tokens": [5048, 12819, 13, 1033, 11, 291, 393, 764, 264, 1349, 10225, 382, 731], "temperature": 0.0, "avg_logprob": -0.2640532766069685, "compression_ratio": 1.62, "no_speech_prob": 3.5559760362957604e-06}, {"id": 709, "seek": 332690, "start": 3349.3, "end": 3354.7400000000002, "text": " It's the same thing but in pi torch. They always use the word tensor. So I'm going to say tensor", "tokens": [467, 311, 264, 912, 551, 457, 294, 3895, 27822, 13, 814, 1009, 764, 264, 1349, 40863, 13, 407, 286, 478, 516, 281, 584, 40863], "temperature": 0.0, "avg_logprob": -0.2640532766069685, "compression_ratio": 1.62, "no_speech_prob": 3.5559760362957604e-06}, {"id": 710, "seek": 335474, "start": 3354.74, "end": 3360.22, "text": " Okay, so it's just a tensor with an additional axis which allows us to stack", "tokens": [1033, 11, 370, 309, 311, 445, 257, 40863, 365, 364, 4497, 10298, 597, 4045, 505, 281, 8630], "temperature": 0.0, "avg_logprob": -0.22242705354985504, "compression_ratio": 1.6623931623931625, "no_speech_prob": 1.6797273474367103e-06}, {"id": 711, "seek": 335474, "start": 3360.7799999999997, "end": 3365.3799999999997, "text": " Each of these filters together, right a filter and kernel", "tokens": [6947, 295, 613, 15995, 1214, 11, 558, 257, 6608, 293, 28256], "temperature": 0.0, "avg_logprob": -0.22242705354985504, "compression_ratio": 1.6623931623931625, "no_speech_prob": 1.6797273474367103e-06}, {"id": 712, "seek": 335474, "start": 3366.2599999999998, "end": 3370.7799999999997, "text": " Pretty much mean the same thing. Yeah, right. It refers to one of these three by three", "tokens": [10693, 709, 914, 264, 912, 551, 13, 865, 11, 558, 13, 467, 14942, 281, 472, 295, 613, 1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.22242705354985504, "compression_ratio": 1.6623931623931625, "no_speech_prob": 1.6797273474367103e-06}, {"id": 713, "seek": 335474, "start": 3372.2999999999997, "end": 3374.3799999999997, "text": " Matrices or one of these three by three", "tokens": [6789, 24373, 420, 472, 295, 613, 1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.22242705354985504, "compression_ratio": 1.6623931623931625, "no_speech_prob": 1.6797273474367103e-06}, {"id": 714, "seek": 335474, "start": 3375.4599999999996, "end": 3378.3799999999997, "text": " slices of a three-dimensional tensor", "tokens": [19793, 295, 257, 1045, 12, 18759, 40863], "temperature": 0.0, "avg_logprob": -0.22242705354985504, "compression_ratio": 1.6623931623931625, "no_speech_prob": 1.6797273474367103e-06}, {"id": 715, "seek": 335474, "start": 3378.8999999999996, "end": 3383.9799999999996, "text": " So if I take this one and here I've literally just copied the formulas in Excel from above", "tokens": [407, 498, 286, 747, 341, 472, 293, 510, 286, 600, 3736, 445, 25365, 264, 30546, 294, 19060, 490, 3673], "temperature": 0.0, "avg_logprob": -0.22242705354985504, "compression_ratio": 1.6623931623931625, "no_speech_prob": 1.6797273474367103e-06}, {"id": 716, "seek": 338398, "start": 3383.98, "end": 3385.54, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.1645071680952863, "compression_ratio": 1.6132596685082874, "no_speech_prob": 7.811475484231778e-07}, {"id": 717, "seek": 338398, "start": 3385.54, "end": 3390.78, "text": " And so you can see this one is now finding a vertical edge as we would expect", "tokens": [400, 370, 291, 393, 536, 341, 472, 307, 586, 5006, 257, 9429, 4691, 382, 321, 576, 2066], "temperature": 0.0, "avg_logprob": -0.1645071680952863, "compression_ratio": 1.6132596685082874, "no_speech_prob": 7.811475484231778e-07}, {"id": 718, "seek": 338398, "start": 3391.3, "end": 3393.3, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.1645071680952863, "compression_ratio": 1.6132596685082874, "no_speech_prob": 7.811475484231778e-07}, {"id": 719, "seek": 338398, "start": 3394.86, "end": 3396.86, "text": " We've now created", "tokens": [492, 600, 586, 2942], "temperature": 0.0, "avg_logprob": -0.1645071680952863, "compression_ratio": 1.6132596685082874, "no_speech_prob": 7.811475484231778e-07}, {"id": 720, "seek": 338398, "start": 3398.3, "end": 3399.54, "text": " One", "tokens": [1485], "temperature": 0.0, "avg_logprob": -0.1645071680952863, "compression_ratio": 1.6132596685082874, "no_speech_prob": 7.811475484231778e-07}, {"id": 721, "seek": 338398, "start": 3399.54, "end": 3404.5, "text": " Layer right this here is a layer and specifically we'd say it's a hidden layer", "tokens": [35166, 558, 341, 510, 307, 257, 4583, 293, 4682, 321, 1116, 584, 309, 311, 257, 7633, 4583], "temperature": 0.0, "avg_logprob": -0.1645071680952863, "compression_ratio": 1.6132596685082874, "no_speech_prob": 7.811475484231778e-07}, {"id": 722, "seek": 338398, "start": 3404.82, "end": 3409.98, "text": " Which is it's not an input layer and it's not an output layer. So everything else is a hidden layer", "tokens": [3013, 307, 309, 311, 406, 364, 4846, 4583, 293, 309, 311, 406, 364, 5598, 4583, 13, 407, 1203, 1646, 307, 257, 7633, 4583], "temperature": 0.0, "avg_logprob": -0.1645071680952863, "compression_ratio": 1.6132596685082874, "no_speech_prob": 7.811475484231778e-07}, {"id": 723, "seek": 340998, "start": 3409.98, "end": 3415.22, "text": " Okay, and this particular hidden layer has is", "tokens": [1033, 11, 293, 341, 1729, 7633, 4583, 575, 307], "temperature": 0.0, "avg_logprob": -0.2327070993090433, "compression_ratio": 1.3734177215189873, "no_speech_prob": 5.804998295388941e-07}, {"id": 724, "seek": 340998, "start": 3416.14, "end": 3420.06, "text": " A size two on this dimension, right because it has two", "tokens": [316, 2744, 732, 322, 341, 10139, 11, 558, 570, 309, 575, 732], "temperature": 0.0, "avg_logprob": -0.2327070993090433, "compression_ratio": 1.3734177215189873, "no_speech_prob": 5.804998295388941e-07}, {"id": 725, "seek": 340998, "start": 3422.06, "end": 3425.06, "text": " Filters right two kernels", "tokens": [7905, 1559, 558, 732, 23434, 1625], "temperature": 0.0, "avg_logprob": -0.2327070993090433, "compression_ratio": 1.3734177215189873, "no_speech_prob": 5.804998295388941e-07}, {"id": 726, "seek": 340998, "start": 3426.78, "end": 3428.78, "text": " So what happens next", "tokens": [407, 437, 2314, 958], "temperature": 0.0, "avg_logprob": -0.2327070993090433, "compression_ratio": 1.3734177215189873, "no_speech_prob": 5.804998295388941e-07}, {"id": 727, "seek": 340998, "start": 3429.9, "end": 3431.26, "text": " Well", "tokens": [1042], "temperature": 0.0, "avg_logprob": -0.2327070993090433, "compression_ratio": 1.3734177215189873, "no_speech_prob": 5.804998295388941e-07}, {"id": 728, "seek": 340998, "start": 3431.26, "end": 3436.34, "text": " Let's do another one. Okay. So as we kind of go along things can", "tokens": [961, 311, 360, 1071, 472, 13, 1033, 13, 407, 382, 321, 733, 295, 352, 2051, 721, 393], "temperature": 0.0, "avg_logprob": -0.2327070993090433, "compression_ratio": 1.3734177215189873, "no_speech_prob": 5.804998295388941e-07}, {"id": 729, "seek": 343634, "start": 3436.34, "end": 3444.06, "text": " Multiply a little bit in complexity right because my next filter is going to have to contain", "tokens": [31150, 356, 257, 707, 857, 294, 14024, 558, 570, 452, 958, 6608, 307, 516, 281, 362, 281, 5304], "temperature": 0.0, "avg_logprob": -0.19061594670361812, "compression_ratio": 1.894736842105263, "no_speech_prob": 1.154460733232554e-06}, {"id": 730, "seek": 343634, "start": 3445.34, "end": 3450.58, "text": " Two of these three by threes because I'm going to have to say how do I want to bring how do I want to?", "tokens": [4453, 295, 613, 1045, 538, 258, 4856, 570, 286, 478, 516, 281, 362, 281, 584, 577, 360, 286, 528, 281, 1565, 577, 360, 286, 528, 281, 30], "temperature": 0.0, "avg_logprob": -0.19061594670361812, "compression_ratio": 1.894736842105263, "no_speech_prob": 1.154460733232554e-06}, {"id": 731, "seek": 343634, "start": 3450.9, "end": 3454.1400000000003, "text": " Wait these three things and at the same time", "tokens": [3802, 613, 1045, 721, 293, 412, 264, 912, 565], "temperature": 0.0, "avg_logprob": -0.19061594670361812, "compression_ratio": 1.894736842105263, "no_speech_prob": 1.154460733232554e-06}, {"id": 732, "seek": 343634, "start": 3454.1400000000003, "end": 3457.26, "text": " How do I want to wait the corresponding three things down here?", "tokens": [1012, 360, 286, 528, 281, 1699, 264, 11760, 1045, 721, 760, 510, 30], "temperature": 0.0, "avg_logprob": -0.19061594670361812, "compression_ratio": 1.894736842105263, "no_speech_prob": 1.154460733232554e-06}, {"id": 733, "seek": 343634, "start": 3457.34, "end": 3463.46, "text": " But because in pytorch this is going to be this whole thing here is going to be stored as a", "tokens": [583, 570, 294, 25878, 284, 339, 341, 307, 516, 281, 312, 341, 1379, 551, 510, 307, 516, 281, 312, 12187, 382, 257], "temperature": 0.0, "avg_logprob": -0.19061594670361812, "compression_ratio": 1.894736842105263, "no_speech_prob": 1.154460733232554e-06}, {"id": 734, "seek": 346346, "start": 3463.46, "end": 3470.38, "text": " As a multi-dimensional tensor right so you shouldn't really think of this now as two three by three kernels", "tokens": [1018, 257, 4825, 12, 18759, 40863, 558, 370, 291, 4659, 380, 534, 519, 295, 341, 586, 382, 732, 1045, 538, 1045, 23434, 1625], "temperature": 0.0, "avg_logprob": -0.22688770294189453, "compression_ratio": 1.6, "no_speech_prob": 9.422435596206924e-07}, {"id": 735, "seek": 346346, "start": 3470.78, "end": 3472.46, "text": " but one", "tokens": [457, 472], "temperature": 0.0, "avg_logprob": -0.22688770294189453, "compression_ratio": 1.6, "no_speech_prob": 9.422435596206924e-07}, {"id": 736, "seek": 346346, "start": 3472.46, "end": 3475.02, "text": " two by three by three kernel", "tokens": [732, 538, 1045, 538, 1045, 28256], "temperature": 0.0, "avg_logprob": -0.22688770294189453, "compression_ratio": 1.6, "no_speech_prob": 9.422435596206924e-07}, {"id": 737, "seek": 346346, "start": 3475.94, "end": 3479.5, "text": " Okay, so to calculate this value here", "tokens": [1033, 11, 370, 281, 8873, 341, 2158, 510], "temperature": 0.0, "avg_logprob": -0.22688770294189453, "compression_ratio": 1.6, "no_speech_prob": 9.422435596206924e-07}, {"id": 738, "seek": 346346, "start": 3480.42, "end": 3484.02, "text": " I've got the sum product of all of that", "tokens": [286, 600, 658, 264, 2408, 1674, 295, 439, 295, 300], "temperature": 0.0, "avg_logprob": -0.22688770294189453, "compression_ratio": 1.6, "no_speech_prob": 9.422435596206924e-07}, {"id": 739, "seek": 346346, "start": 3484.7400000000002, "end": 3486.26, "text": " plus", "tokens": [1804], "temperature": 0.0, "avg_logprob": -0.22688770294189453, "compression_ratio": 1.6, "no_speech_prob": 9.422435596206924e-07}, {"id": 740, "seek": 346346, "start": 3486.26, "end": 3488.26, "text": " the sum product of", "tokens": [264, 2408, 1674, 295], "temperature": 0.0, "avg_logprob": -0.22688770294189453, "compression_ratio": 1.6, "no_speech_prob": 9.422435596206924e-07}, {"id": 741, "seek": 346346, "start": 3489.66, "end": 3491.66, "text": " Let's scroll down", "tokens": [961, 311, 11369, 760], "temperature": 0.0, "avg_logprob": -0.22688770294189453, "compression_ratio": 1.6, "no_speech_prob": 9.422435596206924e-07}, {"id": 742, "seek": 349166, "start": 3491.66, "end": 3493.66, "text": " all of that", "tokens": [439, 295, 300], "temperature": 0.0, "avg_logprob": -0.15024495632090468, "compression_ratio": 1.7751196172248804, "no_speech_prob": 2.1907737846049713e-06}, {"id": 743, "seek": 349166, "start": 3494.94, "end": 3496.66, "text": " Okay, and", "tokens": [1033, 11, 293], "temperature": 0.0, "avg_logprob": -0.15024495632090468, "compression_ratio": 1.7751196172248804, "no_speech_prob": 2.1907737846049713e-06}, {"id": 744, "seek": 349166, "start": 3496.66, "end": 3502.42, "text": " So the top ones are being multiplied by this part of the kernel and the bottom ones are being multiplied by this part of the", "tokens": [407, 264, 1192, 2306, 366, 885, 17207, 538, 341, 644, 295, 264, 28256, 293, 264, 2767, 2306, 366, 885, 17207, 538, 341, 644, 295, 264], "temperature": 0.0, "avg_logprob": -0.15024495632090468, "compression_ratio": 1.7751196172248804, "no_speech_prob": 2.1907737846049713e-06}, {"id": 745, "seek": 349166, "start": 3502.42, "end": 3504.42, "text": " Kernel and so over time", "tokens": [40224, 338, 293, 370, 670, 565], "temperature": 0.0, "avg_logprob": -0.15024495632090468, "compression_ratio": 1.7751196172248804, "no_speech_prob": 2.1907737846049713e-06}, {"id": 746, "seek": 349166, "start": 3505.06, "end": 3511.02, "text": " You want to start to get very comfortable with the idea of these like higher dimensional?", "tokens": [509, 528, 281, 722, 281, 483, 588, 4619, 365, 264, 1558, 295, 613, 411, 2946, 18795, 30], "temperature": 0.0, "avg_logprob": -0.15024495632090468, "compression_ratio": 1.7751196172248804, "no_speech_prob": 2.1907737846049713e-06}, {"id": 747, "seek": 349166, "start": 3511.8199999999997, "end": 3513.2999999999997, "text": " linear combinations", "tokens": [8213, 21267], "temperature": 0.0, "avg_logprob": -0.15024495632090468, "compression_ratio": 1.7751196172248804, "no_speech_prob": 2.1907737846049713e-06}, {"id": 748, "seek": 349166, "start": 3513.2999999999997, "end": 3519.3799999999997, "text": " Right like it's it's harder to draw it on the screen like I had to put one above the other", "tokens": [1779, 411, 309, 311, 309, 311, 6081, 281, 2642, 309, 322, 264, 2568, 411, 286, 632, 281, 829, 472, 3673, 264, 661], "temperature": 0.0, "avg_logprob": -0.15024495632090468, "compression_ratio": 1.7751196172248804, "no_speech_prob": 2.1907737846049713e-06}, {"id": 749, "seek": 351938, "start": 3519.38, "end": 3524.7000000000003, "text": " But conceptually just stack it in your mind like this. That's really how you want to think", "tokens": [583, 3410, 671, 445, 8630, 309, 294, 428, 1575, 411, 341, 13, 663, 311, 534, 577, 291, 528, 281, 519], "temperature": 0.0, "avg_logprob": -0.17556807200113933, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.9944253583380487e-06}, {"id": 750, "seek": 351938, "start": 3525.2200000000003, "end": 3527.9, "text": " Right and actually Jeffrey Hinton in his original", "tokens": [1779, 293, 767, 28721, 389, 12442, 294, 702, 3380], "temperature": 0.0, "avg_logprob": -0.17556807200113933, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.9944253583380487e-06}, {"id": 751, "seek": 351938, "start": 3528.7400000000002, "end": 3530.7400000000002, "text": " 2012 neural nets", "tokens": [9125, 18161, 36170], "temperature": 0.0, "avg_logprob": -0.17556807200113933, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.9944253583380487e-06}, {"id": 752, "seek": 351938, "start": 3530.86, "end": 3537.6600000000003, "text": " Coursera class has a tip which is how all computer scientists deal with like very high dimensional spaces", "tokens": [383, 5067, 1663, 1508, 575, 257, 4125, 597, 307, 577, 439, 3820, 7708, 2028, 365, 411, 588, 1090, 18795, 7673], "temperature": 0.0, "avg_logprob": -0.17556807200113933, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.9944253583380487e-06}, {"id": 753, "seek": 351938, "start": 3538.2200000000003, "end": 3546.1, "text": " Which is that they basically just visualize the two-dimensional space and then say like 12 dimensions really fast in their head lots of times", "tokens": [3013, 307, 300, 436, 1936, 445, 23273, 264, 732, 12, 18759, 1901, 293, 550, 584, 411, 2272, 12819, 534, 2370, 294, 641, 1378, 3195, 295, 1413], "temperature": 0.0, "avg_logprob": -0.17556807200113933, "compression_ratio": 1.646341463414634, "no_speech_prob": 2.9944253583380487e-06}, {"id": 754, "seek": 354610, "start": 3546.1, "end": 3551.62, "text": " So that's it right we can see two dimensions on the screen, and then you just got a try to trust", "tokens": [407, 300, 311, 309, 558, 321, 393, 536, 732, 12819, 322, 264, 2568, 11, 293, 550, 291, 445, 658, 257, 853, 281, 3361], "temperature": 0.0, "avg_logprob": -0.1951354946102108, "compression_ratio": 1.811764705882353, "no_speech_prob": 1.7061768176063197e-06}, {"id": 755, "seek": 354610, "start": 3552.66, "end": 3555.94, "text": " That you can have more dimensions like the concepts", "tokens": [663, 291, 393, 362, 544, 12819, 411, 264, 10392], "temperature": 0.0, "avg_logprob": -0.1951354946102108, "compression_ratio": 1.811764705882353, "no_speech_prob": 1.7061768176063197e-06}, {"id": 756, "seek": 354610, "start": 3555.94, "end": 3560.42, "text": " Just you know there's there's nothing different about them and so you can see in Excel", "tokens": [1449, 291, 458, 456, 311, 456, 311, 1825, 819, 466, 552, 293, 370, 291, 393, 536, 294, 19060], "temperature": 0.0, "avg_logprob": -0.1951354946102108, "compression_ratio": 1.811764705882353, "no_speech_prob": 1.7061768176063197e-06}, {"id": 757, "seek": 354610, "start": 3560.54, "end": 3567.38, "text": " You know Excel doesn't have the ability to handle three dimensional tensors, so I had to like say okay take this two-dimensional", "tokens": [509, 458, 19060, 1177, 380, 362, 264, 3485, 281, 4813, 1045, 18795, 10688, 830, 11, 370, 286, 632, 281, 411, 584, 1392, 747, 341, 732, 12, 18759], "temperature": 0.0, "avg_logprob": -0.1951354946102108, "compression_ratio": 1.811764705882353, "no_speech_prob": 1.7061768176063197e-06}, {"id": 758, "seek": 354610, "start": 3568.2599999999998, "end": 3574.46, "text": " Dot product add on this two-dimensional dot product right, but if there was some kind of 3d Excel", "tokens": [38753, 1674, 909, 322, 341, 732, 12, 18759, 5893, 1674, 558, 11, 457, 498, 456, 390, 512, 733, 295, 805, 67, 19060], "temperature": 0.0, "avg_logprob": -0.1951354946102108, "compression_ratio": 1.811764705882353, "no_speech_prob": 1.7061768176063197e-06}, {"id": 759, "seek": 357446, "start": 3574.46, "end": 3580.02, "text": " I could have just done that in a single formula right and then again apply", "tokens": [286, 727, 362, 445, 1096, 300, 294, 257, 2167, 8513, 558, 293, 550, 797, 3079], "temperature": 0.0, "avg_logprob": -0.2467532100447689, "compression_ratio": 1.7358490566037736, "no_speech_prob": 5.4222055041464046e-06}, {"id": 760, "seek": 357446, "start": 3580.54, "end": 3587.06, "text": " Max zero comma otherwise known as rectified linear unit otherwise known as reality okay, so here is", "tokens": [7402, 4018, 22117, 5911, 2570, 382, 11048, 2587, 8213, 4985, 5911, 2570, 382, 4103, 1392, 11, 370, 510, 307], "temperature": 0.0, "avg_logprob": -0.2467532100447689, "compression_ratio": 1.7358490566037736, "no_speech_prob": 5.4222055041464046e-06}, {"id": 761, "seek": 357446, "start": 3587.62, "end": 3591.62, "text": " My second layer and so when people create different", "tokens": [1222, 1150, 4583, 293, 370, 562, 561, 1884, 819], "temperature": 0.0, "avg_logprob": -0.2467532100447689, "compression_ratio": 1.7358490566037736, "no_speech_prob": 5.4222055041464046e-06}, {"id": 762, "seek": 357446, "start": 3592.46, "end": 3595.1, "text": " architectures right and architecture means", "tokens": [6331, 1303, 558, 293, 9482, 1355], "temperature": 0.0, "avg_logprob": -0.2467532100447689, "compression_ratio": 1.7358490566037736, "no_speech_prob": 5.4222055041464046e-06}, {"id": 763, "seek": 357446, "start": 3596.38, "end": 3603.28, "text": " Like how big is your kernel at layer one how many filters are in your kernel at layer one so here?", "tokens": [1743, 577, 955, 307, 428, 28256, 412, 4583, 472, 577, 867, 15995, 366, 294, 428, 28256, 412, 4583, 472, 370, 510, 30], "temperature": 0.0, "avg_logprob": -0.2467532100447689, "compression_ratio": 1.7358490566037736, "no_speech_prob": 5.4222055041464046e-06}, {"id": 764, "seek": 360328, "start": 3603.28, "end": 3605.1400000000003, "text": " I've got a three by three", "tokens": [286, 600, 658, 257, 1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.1945466072328629, "compression_ratio": 1.9385474860335195, "no_speech_prob": 1.505699401604943e-06}, {"id": 765, "seek": 360328, "start": 3605.1400000000003, "end": 3610.02, "text": " Where's number one and a three by three there's number two so like this?", "tokens": [2305, 311, 1230, 472, 293, 257, 1045, 538, 1045, 456, 311, 1230, 732, 370, 411, 341, 30], "temperature": 0.0, "avg_logprob": -0.1945466072328629, "compression_ratio": 1.9385474860335195, "no_speech_prob": 1.505699401604943e-06}, {"id": 766, "seek": 360328, "start": 3610.7000000000003, "end": 3613.5400000000004, "text": " Architecture I've created starts off with two", "tokens": [43049, 286, 600, 2942, 3719, 766, 365, 732], "temperature": 0.0, "avg_logprob": -0.1945466072328629, "compression_ratio": 1.9385474860335195, "no_speech_prob": 1.505699401604943e-06}, {"id": 767, "seek": 360328, "start": 3614.0600000000004, "end": 3615.78, "text": " three by three", "tokens": [1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.1945466072328629, "compression_ratio": 1.9385474860335195, "no_speech_prob": 1.505699401604943e-06}, {"id": 768, "seek": 360328, "start": 3615.78, "end": 3617.78, "text": " convolutional kernels and", "tokens": [45216, 304, 23434, 1625, 293], "temperature": 0.0, "avg_logprob": -0.1945466072328629, "compression_ratio": 1.9385474860335195, "no_speech_prob": 1.505699401604943e-06}, {"id": 769, "seek": 360328, "start": 3617.82, "end": 3619.82, "text": " then my", "tokens": [550, 452], "temperature": 0.0, "avg_logprob": -0.1945466072328629, "compression_ratio": 1.9385474860335195, "no_speech_prob": 1.505699401604943e-06}, {"id": 770, "seek": 360328, "start": 3620.02, "end": 3625.94, "text": " Second layer has another two kernels of size two by three by three", "tokens": [5736, 4583, 575, 1071, 732, 23434, 1625, 295, 2744, 732, 538, 1045, 538, 1045], "temperature": 0.0, "avg_logprob": -0.1945466072328629, "compression_ratio": 1.9385474860335195, "no_speech_prob": 1.505699401604943e-06}, {"id": 771, "seek": 360328, "start": 3625.94, "end": 3631.7000000000003, "text": " So there's the first one and then down here is the second two by three by three kernel", "tokens": [407, 456, 311, 264, 700, 472, 293, 550, 760, 510, 307, 264, 1150, 732, 538, 1045, 538, 1045, 28256], "temperature": 0.0, "avg_logprob": -0.1945466072328629, "compression_ratio": 1.9385474860335195, "no_speech_prob": 1.505699401604943e-06}, {"id": 772, "seek": 363170, "start": 3631.7, "end": 3633.7, "text": " okay, and so", "tokens": [1392, 11, 293, 370], "temperature": 0.0, "avg_logprob": -0.17828290462493895, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.422431617167604e-07}, {"id": 773, "seek": 363170, "start": 3633.7799999999997, "end": 3638.54, "text": " Remember one of these specific where any one of these numbers is an activation", "tokens": [5459, 472, 295, 613, 2685, 689, 604, 472, 295, 613, 3547, 307, 364, 24433], "temperature": 0.0, "avg_logprob": -0.17828290462493895, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.422431617167604e-07}, {"id": 774, "seek": 363170, "start": 3639.54, "end": 3646.48, "text": " Okay, so this activation is being calculated from these three things here another three things up there", "tokens": [1033, 11, 370, 341, 24433, 307, 885, 15598, 490, 613, 1045, 721, 510, 1071, 1045, 721, 493, 456], "temperature": 0.0, "avg_logprob": -0.17828290462493895, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.422431617167604e-07}, {"id": 775, "seek": 363170, "start": 3646.48, "end": 3651.54, "text": " And we're using these this two by three by three kernel okay", "tokens": [400, 321, 434, 1228, 613, 341, 732, 538, 1045, 538, 1045, 28256, 1392], "temperature": 0.0, "avg_logprob": -0.17828290462493895, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.422431617167604e-07}, {"id": 776, "seek": 363170, "start": 3651.54, "end": 3657.8199999999997, "text": " And so what tends to happen is people generally give names to their layers, so I say okay", "tokens": [400, 370, 437, 12258, 281, 1051, 307, 561, 5101, 976, 5288, 281, 641, 7914, 11, 370, 286, 584, 1392], "temperature": 0.0, "avg_logprob": -0.17828290462493895, "compression_ratio": 1.7128712871287128, "no_speech_prob": 9.422431617167604e-07}, {"id": 777, "seek": 365782, "start": 3657.82, "end": 3662.7400000000002, "text": " Let's call this layer here cons one and this layer here", "tokens": [961, 311, 818, 341, 4583, 510, 1014, 472, 293, 341, 4583, 510], "temperature": 0.0, "avg_logprob": -0.3000410132937961, "compression_ratio": 1.5872093023255813, "no_speech_prob": 1.4823539231656468e-06}, {"id": 778, "seek": 365782, "start": 3663.5800000000004, "end": 3665.5800000000004, "text": " and this and", "tokens": [293, 341, 293], "temperature": 0.0, "avg_logprob": -0.3000410132937961, "compression_ratio": 1.5872093023255813, "no_speech_prob": 1.4823539231656468e-06}, {"id": 779, "seek": 365782, "start": 3666.9, "end": 3668.5800000000004, "text": " This layer here", "tokens": [639, 4583, 510], "temperature": 0.0, "avg_logprob": -0.3000410132937961, "compression_ratio": 1.5872093023255813, "no_speech_prob": 1.4823539231656468e-06}, {"id": 780, "seek": 365782, "start": 3668.5800000000004, "end": 3674.94, "text": " Conv two right so that's you know generally you'll just see that like when you print out a summary", "tokens": [2656, 85, 732, 558, 370, 300, 311, 291, 458, 5101, 291, 603, 445, 536, 300, 411, 562, 291, 4482, 484, 257, 12691], "temperature": 0.0, "avg_logprob": -0.3000410132937961, "compression_ratio": 1.5872093023255813, "no_speech_prob": 1.4823539231656468e-06}, {"id": 781, "seek": 365782, "start": 3675.26, "end": 3682.5, "text": " Of a network every layer will have some kind of name okay, and so then what happens next?", "tokens": [2720, 257, 3209, 633, 4583, 486, 362, 512, 733, 295, 1315, 1392, 11, 293, 370, 550, 437, 2314, 958, 30], "temperature": 0.0, "avg_logprob": -0.3000410132937961, "compression_ratio": 1.5872093023255813, "no_speech_prob": 1.4823539231656468e-06}, {"id": 782, "seek": 368250, "start": 3682.5, "end": 3690.14, "text": " Well part of the architecture is like do you have some max pooling whereabouts is that max pooling happens?", "tokens": [1042, 644, 295, 264, 9482, 307, 411, 360, 291, 362, 512, 11469, 7005, 278, 689, 41620, 307, 300, 11469, 7005, 278, 2314, 30], "temperature": 0.0, "avg_logprob": -0.21306191238702513, "compression_ratio": 1.7464788732394365, "no_speech_prob": 4.356863883003825e-06}, {"id": 783, "seek": 368250, "start": 3690.14, "end": 3695.46, "text": " So in this architecture, we're inventing we're going to next step is to max pooling", "tokens": [407, 294, 341, 9482, 11, 321, 434, 7962, 278, 321, 434, 516, 281, 958, 1823, 307, 281, 11469, 7005, 278], "temperature": 0.0, "avg_logprob": -0.21306191238702513, "compression_ratio": 1.7464788732394365, "no_speech_prob": 4.356863883003825e-06}, {"id": 784, "seek": 368250, "start": 3695.98, "end": 3698.66, "text": " Okay max pooling is a little hard to", "tokens": [1033, 11469, 7005, 278, 307, 257, 707, 1152, 281], "temperature": 0.0, "avg_logprob": -0.21306191238702513, "compression_ratio": 1.7464788732394365, "no_speech_prob": 4.356863883003825e-06}, {"id": 785, "seek": 368250, "start": 3699.74, "end": 3701.98, "text": " Kind of show in Excel, but we've got it", "tokens": [9242, 295, 855, 294, 19060, 11, 457, 321, 600, 658, 309], "temperature": 0.0, "avg_logprob": -0.21306191238702513, "compression_ratio": 1.7464788732394365, "no_speech_prob": 4.356863883003825e-06}, {"id": 786, "seek": 368250, "start": 3702.74, "end": 3706.16, "text": " So max pooling if I do a two by two max pooling", "tokens": [407, 11469, 7005, 278, 498, 286, 360, 257, 732, 538, 732, 11469, 7005, 278], "temperature": 0.0, "avg_logprob": -0.21306191238702513, "compression_ratio": 1.7464788732394365, "no_speech_prob": 4.356863883003825e-06}, {"id": 787, "seek": 368250, "start": 3706.16, "end": 3709.98, "text": " It's going to have the resolution both height and width", "tokens": [467, 311, 516, 281, 362, 264, 8669, 1293, 6681, 293, 11402], "temperature": 0.0, "avg_logprob": -0.21306191238702513, "compression_ratio": 1.7464788732394365, "no_speech_prob": 4.356863883003825e-06}, {"id": 788, "seek": 370998, "start": 3709.98, "end": 3712.7, "text": " So you can see here that I've replaced", "tokens": [407, 291, 393, 536, 510, 300, 286, 600, 10772], "temperature": 0.0, "avg_logprob": -0.1656712241794752, "compression_ratio": 1.6803652968036529, "no_speech_prob": 1.1911074579984415e-06}, {"id": 789, "seek": 370998, "start": 3715.34, "end": 3717.34, "text": " These four numbers", "tokens": [1981, 1451, 3547], "temperature": 0.0, "avg_logprob": -0.1656712241794752, "compression_ratio": 1.6803652968036529, "no_speech_prob": 1.1911074579984415e-06}, {"id": 790, "seek": 370998, "start": 3717.86, "end": 3719.86, "text": " With the maximum of those four numbers", "tokens": [2022, 264, 6674, 295, 729, 1451, 3547], "temperature": 0.0, "avg_logprob": -0.1656712241794752, "compression_ratio": 1.6803652968036529, "no_speech_prob": 1.1911074579984415e-06}, {"id": 791, "seek": 370998, "start": 3720.7400000000002, "end": 3725.98, "text": " Right and so because I'm having the resolution it only makes sense to actually have something every two cells", "tokens": [1779, 293, 370, 570, 286, 478, 1419, 264, 8669, 309, 787, 1669, 2020, 281, 767, 362, 746, 633, 732, 5438], "temperature": 0.0, "avg_logprob": -0.1656712241794752, "compression_ratio": 1.6803652968036529, "no_speech_prob": 1.1911074579984415e-06}, {"id": 792, "seek": 370998, "start": 3727.26, "end": 3731.5, "text": " Okay, so you can see here the way. I've got kind of the same", "tokens": [1033, 11, 370, 291, 393, 536, 510, 264, 636, 13, 286, 600, 658, 733, 295, 264, 912], "temperature": 0.0, "avg_logprob": -0.1656712241794752, "compression_ratio": 1.6803652968036529, "no_speech_prob": 1.1911074579984415e-06}, {"id": 793, "seek": 370998, "start": 3732.14, "end": 3737.86, "text": " Looking shape as I had back here, okay, but it's now half the resolution because I've replaced every", "tokens": [11053, 3909, 382, 286, 632, 646, 510, 11, 1392, 11, 457, 309, 311, 586, 1922, 264, 8669, 570, 286, 600, 10772, 633], "temperature": 0.0, "avg_logprob": -0.1656712241794752, "compression_ratio": 1.6803652968036529, "no_speech_prob": 1.1911074579984415e-06}, {"id": 794, "seek": 373786, "start": 3737.86, "end": 3739.86, "text": " two by two", "tokens": [732, 538, 732], "temperature": 0.0, "avg_logprob": -0.17602603289545798, "compression_ratio": 1.5625, "no_speech_prob": 2.857307890735683e-06}, {"id": 795, "seek": 373786, "start": 3739.86, "end": 3745.58, "text": " With its max and you'll notice like it's not every possible two by two I skip over from here", "tokens": [2022, 1080, 11469, 293, 291, 603, 3449, 411, 309, 311, 406, 633, 1944, 732, 538, 732, 286, 10023, 670, 490, 510], "temperature": 0.0, "avg_logprob": -0.17602603289545798, "compression_ratio": 1.5625, "no_speech_prob": 2.857307890735683e-06}, {"id": 796, "seek": 373786, "start": 3745.58, "end": 3750.2200000000003, "text": " So this is like starting at BQ and then the next one starts at", "tokens": [407, 341, 307, 411, 2891, 412, 363, 48, 293, 550, 264, 958, 472, 3719, 412], "temperature": 0.0, "avg_logprob": -0.17602603289545798, "compression_ratio": 1.5625, "no_speech_prob": 2.857307890735683e-06}, {"id": 797, "seek": 373786, "start": 3751.26, "end": 3752.38, "text": " BS", "tokens": [27253], "temperature": 0.0, "avg_logprob": -0.17602603289545798, "compression_ratio": 1.5625, "no_speech_prob": 2.857307890735683e-06}, {"id": 798, "seek": 373786, "start": 3752.38, "end": 3756.96, "text": " Right so they're like non overlapping. That's why it's decreasing the resolution", "tokens": [1779, 370, 436, 434, 411, 2107, 33535, 13, 663, 311, 983, 309, 311, 23223, 264, 8669], "temperature": 0.0, "avg_logprob": -0.17602603289545798, "compression_ratio": 1.5625, "no_speech_prob": 2.857307890735683e-06}, {"id": 799, "seek": 373786, "start": 3757.38, "end": 3760.82, "text": " Okay, so anybody who's comfortable with spreadsheets", "tokens": [1033, 11, 370, 4472, 567, 311, 4619, 365, 23651, 1385], "temperature": 0.0, "avg_logprob": -0.17602603289545798, "compression_ratio": 1.5625, "no_speech_prob": 2.857307890735683e-06}, {"id": 800, "seek": 376082, "start": 3760.82, "end": 3767.3, "text": " You know you can open this and have a look and so after our max pooling", "tokens": [509, 458, 291, 393, 1269, 341, 293, 362, 257, 574, 293, 370, 934, 527, 11469, 7005, 278], "temperature": 0.0, "avg_logprob": -0.17696225797975218, "compression_ratio": 1.541871921182266, "no_speech_prob": 1.3925432540418115e-06}, {"id": 801, "seek": 376082, "start": 3770.3, "end": 3775.1000000000004, "text": " There's a number of different things we could do next and I'm going to show you a kind of", "tokens": [821, 311, 257, 1230, 295, 819, 721, 321, 727, 360, 958, 293, 286, 478, 516, 281, 855, 291, 257, 733, 295], "temperature": 0.0, "avg_logprob": -0.17696225797975218, "compression_ratio": 1.541871921182266, "no_speech_prob": 1.3925432540418115e-06}, {"id": 802, "seek": 376082, "start": 3776.6600000000003, "end": 3784.2200000000003, "text": " Classic old style approach nowadays in fact what generally happens nowadays is we do a max pool where we kind of like max", "tokens": [25008, 1331, 3758, 3109, 13434, 294, 1186, 437, 5101, 2314, 13434, 307, 321, 360, 257, 11469, 7005, 689, 321, 733, 295, 411, 11469], "temperature": 0.0, "avg_logprob": -0.17696225797975218, "compression_ratio": 1.541871921182266, "no_speech_prob": 1.3925432540418115e-06}, {"id": 803, "seek": 376082, "start": 3784.2200000000003, "end": 3786.5800000000004, "text": " Across the entire size right?", "tokens": [34527, 264, 2302, 2744, 558, 30], "temperature": 0.0, "avg_logprob": -0.17696225797975218, "compression_ratio": 1.541871921182266, "no_speech_prob": 1.3925432540418115e-06}, {"id": 804, "seek": 378658, "start": 3786.58, "end": 3791.46, "text": " But on older architectures and also on all the structured data stuff we do", "tokens": [583, 322, 4906, 6331, 1303, 293, 611, 322, 439, 264, 18519, 1412, 1507, 321, 360], "temperature": 0.0, "avg_logprob": -0.13842436732078084, "compression_ratio": 1.9855072463768115, "no_speech_prob": 2.948004521385883e-06}, {"id": 805, "seek": 378658, "start": 3792.14, "end": 3797.14, "text": " We actually do something called a fully connected layer, and so here's a fully connected layer", "tokens": [492, 767, 360, 746, 1219, 257, 4498, 4582, 4583, 11, 293, 370, 510, 311, 257, 4498, 4582, 4583], "temperature": 0.0, "avg_logprob": -0.13842436732078084, "compression_ratio": 1.9855072463768115, "no_speech_prob": 2.948004521385883e-06}, {"id": 806, "seek": 378658, "start": 3797.14, "end": 3803.74, "text": " I'm going to take every single one of these activations and I'm going to give every single one of them a weight", "tokens": [286, 478, 516, 281, 747, 633, 2167, 472, 295, 613, 2430, 763, 293, 286, 478, 516, 281, 976, 633, 2167, 472, 295, 552, 257, 3364], "temperature": 0.0, "avg_logprob": -0.13842436732078084, "compression_ratio": 1.9855072463768115, "no_speech_prob": 2.948004521385883e-06}, {"id": 807, "seek": 378658, "start": 3805.02, "end": 3808.98, "text": " Right and so then I'm going to take over here", "tokens": [1779, 293, 370, 550, 286, 478, 516, 281, 747, 670, 510], "temperature": 0.0, "avg_logprob": -0.13842436732078084, "compression_ratio": 1.9855072463768115, "no_speech_prob": 2.948004521385883e-06}, {"id": 808, "seek": 380898, "start": 3808.98, "end": 3816.06, "text": " Here is the sum product of every one of the activations by every one of the weights", "tokens": [1692, 307, 264, 2408, 1674, 295, 633, 472, 295, 264, 2430, 763, 538, 633, 472, 295, 264, 17443], "temperature": 0.0, "avg_logprob": -0.16199218936082793, "compression_ratio": 1.5784313725490196, "no_speech_prob": 2.406094608886633e-06}, {"id": 809, "seek": 380898, "start": 3816.7, "end": 3818.7, "text": " for both of the", "tokens": [337, 1293, 295, 264], "temperature": 0.0, "avg_logprob": -0.16199218936082793, "compression_ratio": 1.5784313725490196, "no_speech_prob": 2.406094608886633e-06}, {"id": 810, "seek": 380898, "start": 3820.42, "end": 3821.58, "text": " Two", "tokens": [4453], "temperature": 0.0, "avg_logprob": -0.16199218936082793, "compression_ratio": 1.5784313725490196, "no_speech_prob": 2.406094608886633e-06}, {"id": 811, "seek": 380898, "start": 3821.58, "end": 3828.86, "text": " Levels of my three-dimensional tensor right and so this is called a fully connected layer notice. It's different to a convolution", "tokens": [16872, 82, 295, 452, 1045, 12, 18759, 40863, 558, 293, 370, 341, 307, 1219, 257, 4498, 4582, 4583, 3449, 13, 467, 311, 819, 281, 257, 45216], "temperature": 0.0, "avg_logprob": -0.16199218936082793, "compression_ratio": 1.5784313725490196, "no_speech_prob": 2.406094608886633e-06}, {"id": 812, "seek": 380898, "start": 3828.86, "end": 3834.66, "text": " I'm not going through a few at a time right, but I'm creating a really big weight matrix", "tokens": [286, 478, 406, 516, 807, 257, 1326, 412, 257, 565, 558, 11, 457, 286, 478, 4084, 257, 534, 955, 3364, 8141], "temperature": 0.0, "avg_logprob": -0.16199218936082793, "compression_ratio": 1.5784313725490196, "no_speech_prob": 2.406094608886633e-06}, {"id": 813, "seek": 383466, "start": 3834.66, "end": 3841.54, "text": " Right so rather than having a couple of little three by three kernels my weight matrix is now as big as the entire input", "tokens": [1779, 370, 2831, 813, 1419, 257, 1916, 295, 707, 1045, 538, 1045, 23434, 1625, 452, 3364, 8141, 307, 586, 382, 955, 382, 264, 2302, 4846], "temperature": 0.0, "avg_logprob": -0.14559389596962066, "compression_ratio": 1.6168224299065421, "no_speech_prob": 1.349698550257017e-06}, {"id": 814, "seek": 383466, "start": 3842.1, "end": 3844.1, "text": " And so as you can imagine", "tokens": [400, 370, 382, 291, 393, 3811], "temperature": 0.0, "avg_logprob": -0.14559389596962066, "compression_ratio": 1.6168224299065421, "no_speech_prob": 1.349698550257017e-06}, {"id": 815, "seek": 383466, "start": 3846.18, "end": 3851.8799999999997, "text": " Architectures that make heavy use of fully convolutional layers can have a lot of weights", "tokens": [29306, 1303, 300, 652, 4676, 764, 295, 4498, 45216, 304, 7914, 393, 362, 257, 688, 295, 17443], "temperature": 0.0, "avg_logprob": -0.14559389596962066, "compression_ratio": 1.6168224299065421, "no_speech_prob": 1.349698550257017e-06}, {"id": 816, "seek": 383466, "start": 3852.8199999999997, "end": 3858.74, "text": " Which means they can have trouble with overfitting and they can also be slow and so you're going to see a lot", "tokens": [3013, 1355, 436, 393, 362, 5253, 365, 670, 69, 2414, 293, 436, 393, 611, 312, 2964, 293, 370, 291, 434, 516, 281, 536, 257, 688], "temperature": 0.0, "avg_logprob": -0.14559389596962066, "compression_ratio": 1.6168224299065421, "no_speech_prob": 1.349698550257017e-06}, {"id": 817, "seek": 385874, "start": 3858.74, "end": 3865.06, "text": " An architecture called VGG because it was the first kind of successful deeper architecture", "tokens": [1107, 9482, 1219, 691, 27561, 570, 309, 390, 264, 700, 733, 295, 4406, 7731, 9482], "temperature": 0.0, "avg_logprob": -0.23455254624529584, "compression_ratio": 1.7379679144385027, "no_speech_prob": 3.5559673960960936e-06}, {"id": 818, "seek": 385874, "start": 3865.06, "end": 3867.3799999999997, "text": " It has up to 19 layers and VGG", "tokens": [467, 575, 493, 281, 1294, 7914, 293, 691, 27561], "temperature": 0.0, "avg_logprob": -0.23455254624529584, "compression_ratio": 1.7379679144385027, "no_speech_prob": 3.5559673960960936e-06}, {"id": 819, "seek": 385874, "start": 3868.3799999999997, "end": 3871.5, "text": " Actually contains a fully connected layer with", "tokens": [5135, 8306, 257, 4498, 4582, 4583, 365], "temperature": 0.0, "avg_logprob": -0.23455254624529584, "compression_ratio": 1.7379679144385027, "no_speech_prob": 3.5559673960960936e-06}, {"id": 820, "seek": 385874, "start": 3872.22, "end": 3874.04, "text": " 4096 weights", "tokens": [3356, 22962, 17443], "temperature": 0.0, "avg_logprob": -0.23455254624529584, "compression_ratio": 1.7379679144385027, "no_speech_prob": 3.5559673960960936e-06}, {"id": 821, "seek": 385874, "start": 3874.04, "end": 3878.06, "text": " Connected to a hidden layer with 4000 sorry 4096", "tokens": [11653, 292, 281, 257, 7633, 4583, 365, 31104, 2597, 3356, 22962], "temperature": 0.0, "avg_logprob": -0.23455254624529584, "compression_ratio": 1.7379679144385027, "no_speech_prob": 3.5559673960960936e-06}, {"id": 822, "seek": 385874, "start": 3879.22, "end": 3887.14, "text": " Activations connected to a hidden layer with 4096 activations, so you've got like 4096 by 4096", "tokens": [28550, 763, 4582, 281, 257, 7633, 4583, 365, 3356, 22962, 2430, 763, 11, 370, 291, 600, 658, 411, 3356, 22962, 538, 3356, 22962], "temperature": 0.0, "avg_logprob": -0.23455254624529584, "compression_ratio": 1.7379679144385027, "no_speech_prob": 3.5559673960960936e-06}, {"id": 823, "seek": 388714, "start": 3887.14, "end": 3887.98, "text": " 6096", "tokens": [4060, 22962], "temperature": 0.0, "avg_logprob": -0.2623360882634702, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.5294094737328123e-06}, {"id": 824, "seek": 388714, "start": 3887.98, "end": 3893.7799999999997, "text": " multiplied by remember multiplied by the number of kind of kernels that we have calculated", "tokens": [17207, 538, 1604, 17207, 538, 264, 1230, 295, 733, 295, 23434, 1625, 300, 321, 362, 15598], "temperature": 0.0, "avg_logprob": -0.2623360882634702, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.5294094737328123e-06}, {"id": 825, "seek": 388714, "start": 3894.58, "end": 3896.18, "text": " so in", "tokens": [370, 294], "temperature": 0.0, "avg_logprob": -0.2623360882634702, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.5294094737328123e-06}, {"id": 826, "seek": 388714, "start": 3896.18, "end": 3897.3799999999997, "text": " VGG", "tokens": [691, 27561], "temperature": 0.0, "avg_logprob": -0.2623360882634702, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.5294094737328123e-06}, {"id": 827, "seek": 388714, "start": 3897.3799999999997, "end": 3899.02, "text": " There's", "tokens": [821, 311], "temperature": 0.0, "avg_logprob": -0.2623360882634702, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.5294094737328123e-06}, {"id": 828, "seek": 388714, "start": 3899.02, "end": 3901.2999999999997, "text": " This I think it's like 300 million", "tokens": [639, 286, 519, 309, 311, 411, 6641, 2459], "temperature": 0.0, "avg_logprob": -0.2623360882634702, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.5294094737328123e-06}, {"id": 829, "seek": 388714, "start": 3902.3799999999997, "end": 3907.7799999999997, "text": " Weights of which something like 250 million of them are in these fully connected layers", "tokens": [492, 5761, 295, 597, 746, 411, 11650, 2459, 295, 552, 366, 294, 613, 4498, 4582, 7914], "temperature": 0.0, "avg_logprob": -0.2623360882634702, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.5294094737328123e-06}, {"id": 830, "seek": 388714, "start": 3908.9, "end": 3915.74, "text": " So we'll learn later on in the course about how we can kind of avoid using these big fully connected layers and behind the scenes", "tokens": [407, 321, 603, 1466, 1780, 322, 294, 264, 1164, 466, 577, 321, 393, 733, 295, 5042, 1228, 613, 955, 4498, 4582, 7914, 293, 2261, 264, 8026], "temperature": 0.0, "avg_logprob": -0.2623360882634702, "compression_ratio": 1.6486486486486487, "no_speech_prob": 1.5294094737328123e-06}, {"id": 831, "seek": 391574, "start": 3915.74, "end": 3921.66, "text": " All the stuff that you've seen us using like resnet and res next none of them use very large", "tokens": [1057, 264, 1507, 300, 291, 600, 1612, 505, 1228, 411, 725, 7129, 293, 725, 958, 6022, 295, 552, 764, 588, 2416], "temperature": 0.0, "avg_logprob": -0.23998589264719108, "compression_ratio": 1.54, "no_speech_prob": 6.339146693790099e-06}, {"id": 832, "seek": 391574, "start": 3922.02, "end": 3923.5, "text": " fully connected layers", "tokens": [4498, 4582, 7914], "temperature": 0.0, "avg_logprob": -0.23998589264719108, "compression_ratio": 1.54, "no_speech_prob": 6.339146693790099e-06}, {"id": 833, "seek": 391574, "start": 3923.5, "end": 3925.5, "text": " You know you had a question", "tokens": [509, 458, 291, 632, 257, 1168], "temperature": 0.0, "avg_logprob": -0.23998589264719108, "compression_ratio": 1.54, "no_speech_prob": 6.339146693790099e-06}, {"id": 834, "seek": 391574, "start": 3929.3799999999997, "end": 3935.7799999999997, "text": " So can you tell us more about for example if we had like three channels of the input what would be the", "tokens": [407, 393, 291, 980, 505, 544, 466, 337, 1365, 498, 321, 632, 411, 1045, 9235, 295, 264, 4846, 437, 576, 312, 264], "temperature": 0.0, "avg_logprob": -0.23998589264719108, "compression_ratio": 1.54, "no_speech_prob": 6.339146693790099e-06}, {"id": 835, "seek": 391574, "start": 3937.22, "end": 3941.7799999999997, "text": " The shape yeah these filters right so that's a great question", "tokens": [440, 3909, 1338, 613, 15995, 558, 370, 300, 311, 257, 869, 1168], "temperature": 0.0, "avg_logprob": -0.23998589264719108, "compression_ratio": 1.54, "no_speech_prob": 6.339146693790099e-06}, {"id": 836, "seek": 394178, "start": 3941.78, "end": 3949.78, "text": " So if we had three channels of input it would look exactly like con one right con one kind of has two channels", "tokens": [407, 498, 321, 632, 1045, 9235, 295, 4846, 309, 576, 574, 2293, 411, 416, 472, 558, 416, 472, 733, 295, 575, 732, 9235], "temperature": 0.0, "avg_logprob": -0.1756113673863786, "compression_ratio": 1.857843137254902, "no_speech_prob": 1.7603373407837353e-06}, {"id": 837, "seek": 394178, "start": 3950.46, "end": 3955.86, "text": " Right and so you can see with con one we had two channels so therefore our filters", "tokens": [1779, 293, 370, 291, 393, 536, 365, 416, 472, 321, 632, 732, 9235, 370, 4412, 527, 15995], "temperature": 0.0, "avg_logprob": -0.1756113673863786, "compression_ratio": 1.857843137254902, "no_speech_prob": 1.7603373407837353e-06}, {"id": 838, "seek": 394178, "start": 3956.38, "end": 3960.5, "text": " had to have like two channels per filter and so you could like", "tokens": [632, 281, 362, 411, 732, 9235, 680, 6608, 293, 370, 291, 727, 411], "temperature": 0.0, "avg_logprob": -0.1756113673863786, "compression_ratio": 1.857843137254902, "no_speech_prob": 1.7603373407837353e-06}, {"id": 839, "seek": 394178, "start": 3961.46, "end": 3968.1200000000003, "text": " Imagine that this input didn't exist you know and actually this was the input right so when you have a multi-channel input", "tokens": [11739, 300, 341, 4846, 994, 380, 2514, 291, 458, 293, 767, 341, 390, 264, 4846, 558, 370, 562, 291, 362, 257, 4825, 12, 339, 11444, 4846], "temperature": 0.0, "avg_logprob": -0.1756113673863786, "compression_ratio": 1.857843137254902, "no_speech_prob": 1.7603373407837353e-06}, {"id": 840, "seek": 396812, "start": 3968.12, "end": 3973.3199999999997, "text": " It just means that your filters look like this and so images often", "tokens": [467, 445, 1355, 300, 428, 15995, 574, 411, 341, 293, 370, 5267, 2049], "temperature": 0.0, "avg_logprob": -0.2192410757375318, "compression_ratio": 1.6782608695652175, "no_speech_prob": 4.052539850363246e-07}, {"id": 841, "seek": 396812, "start": 3973.7, "end": 3979.02, "text": " For color they have three red green and blue sometimes they also have an alpha channel", "tokens": [1171, 2017, 436, 362, 1045, 2182, 3092, 293, 3344, 2171, 436, 611, 362, 364, 8961, 2269], "temperature": 0.0, "avg_logprob": -0.2192410757375318, "compression_ratio": 1.6782608695652175, "no_speech_prob": 4.052539850363246e-07}, {"id": 842, "seek": 396812, "start": 3979.02, "end": 3984.68, "text": " So however many you have that's how many inputs you need and so something which I know", "tokens": [407, 4461, 867, 291, 362, 300, 311, 577, 867, 15743, 291, 643, 293, 370, 746, 597, 286, 458], "temperature": 0.0, "avg_logprob": -0.2192410757375318, "compression_ratio": 1.6782608695652175, "no_speech_prob": 4.052539850363246e-07}, {"id": 843, "seek": 396812, "start": 3984.98, "end": 3988.02, "text": " You know that was playing with recently was like using a", "tokens": [509, 458, 300, 390, 2433, 365, 3938, 390, 411, 1228, 257], "temperature": 0.0, "avg_logprob": -0.2192410757375318, "compression_ratio": 1.6782608695652175, "no_speech_prob": 4.052539850363246e-07}, {"id": 844, "seek": 396812, "start": 3988.74, "end": 3990.74, "text": " full color image net model", "tokens": [1577, 2017, 3256, 2533, 2316], "temperature": 0.0, "avg_logprob": -0.2192410757375318, "compression_ratio": 1.6782608695652175, "no_speech_prob": 4.052539850363246e-07}, {"id": 845, "seek": 396812, "start": 3991.14, "end": 3994.88, "text": " In medical imaging for something called bone age calculations", "tokens": [682, 4625, 25036, 337, 746, 1219, 9026, 3205, 20448], "temperature": 0.0, "avg_logprob": -0.2192410757375318, "compression_ratio": 1.6782608695652175, "no_speech_prob": 4.052539850363246e-07}, {"id": 846, "seek": 399488, "start": 3994.88, "end": 4000.98, "text": " Which has a single channel and so what she did was basically take the the input", "tokens": [3013, 575, 257, 2167, 2269, 293, 370, 437, 750, 630, 390, 1936, 747, 264, 264, 4846], "temperature": 0.0, "avg_logprob": -0.14887106290427587, "compression_ratio": 1.751111111111111, "no_speech_prob": 1.8738708149612648e-06}, {"id": 847, "seek": 399488, "start": 4001.26, "end": 4004.84, "text": " The single channel input and make three copies of it", "tokens": [440, 2167, 2269, 4846, 293, 652, 1045, 14341, 295, 309], "temperature": 0.0, "avg_logprob": -0.14887106290427587, "compression_ratio": 1.751111111111111, "no_speech_prob": 1.8738708149612648e-06}, {"id": 848, "seek": 399488, "start": 4005.1400000000003, "end": 4011.46, "text": " So you end up with basically like one two three versions of the same thing which is like", "tokens": [407, 291, 917, 493, 365, 1936, 411, 472, 732, 1045, 9606, 295, 264, 912, 551, 597, 307, 411], "temperature": 0.0, "avg_logprob": -0.14887106290427587, "compression_ratio": 1.751111111111111, "no_speech_prob": 1.8738708149612648e-06}, {"id": 849, "seek": 399488, "start": 4013.34, "end": 4018.26, "text": " It's kind of it's not ideal like it's kind of redundant information that we don't quite want", "tokens": [467, 311, 733, 295, 309, 311, 406, 7157, 411, 309, 311, 733, 295, 40997, 1589, 300, 321, 500, 380, 1596, 528], "temperature": 0.0, "avg_logprob": -0.14887106290427587, "compression_ratio": 1.751111111111111, "no_speech_prob": 1.8738708149612648e-06}, {"id": 850, "seek": 399488, "start": 4018.26, "end": 4023.42, "text": " But it does mean that then if you had a something that expected a three channel", "tokens": [583, 309, 775, 914, 300, 550, 498, 291, 632, 257, 746, 300, 5176, 257, 1045, 2269], "temperature": 0.0, "avg_logprob": -0.14887106290427587, "compression_ratio": 1.751111111111111, "no_speech_prob": 1.8738708149612648e-06}, {"id": 851, "seek": 402342, "start": 4023.42, "end": 4028.66, "text": " Convolution or filter you can use it right and so at the moment", "tokens": [2656, 85, 3386, 420, 6608, 291, 393, 764, 309, 558, 293, 370, 412, 264, 1623], "temperature": 0.0, "avg_logprob": -0.18763886798511853, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.5056979236760526e-06}, {"id": 852, "seek": 402342, "start": 4028.7400000000002, "end": 4033.06, "text": " There's a Kaggle competition for iceberg detection using", "tokens": [821, 311, 257, 48751, 22631, 6211, 337, 38880, 17784, 1228], "temperature": 0.0, "avg_logprob": -0.18763886798511853, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.5056979236760526e-06}, {"id": 853, "seek": 402342, "start": 4033.86, "end": 4038.04, "text": " Some funky satellite specific data format that has two channels", "tokens": [2188, 33499, 16016, 2685, 1412, 7877, 300, 575, 732, 9235], "temperature": 0.0, "avg_logprob": -0.18763886798511853, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.5056979236760526e-06}, {"id": 854, "seek": 402342, "start": 4038.94, "end": 4041.3, "text": " So here's how you could do that you could", "tokens": [407, 510, 311, 577, 291, 727, 360, 300, 291, 727], "temperature": 0.0, "avg_logprob": -0.18763886798511853, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.5056979236760526e-06}, {"id": 855, "seek": 402342, "start": 4042.02, "end": 4045.1800000000003, "text": " Either copy one of those two channels into the third channel", "tokens": [13746, 5055, 472, 295, 729, 732, 9235, 666, 264, 2636, 2269], "temperature": 0.0, "avg_logprob": -0.18763886798511853, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.5056979236760526e-06}, {"id": 856, "seek": 402342, "start": 4045.1800000000003, "end": 4049.66, "text": " Or I think what people on Kaggle are doing is to take the average of the two", "tokens": [1610, 286, 519, 437, 561, 322, 48751, 22631, 366, 884, 307, 281, 747, 264, 4274, 295, 264, 732], "temperature": 0.0, "avg_logprob": -0.18763886798511853, "compression_ratio": 1.6470588235294117, "no_speech_prob": 1.5056979236760526e-06}, {"id": 857, "seek": 404966, "start": 4049.66, "end": 4054.7799999999997, "text": " Again, it's not ideal, but it's a way that you can use pre-trained networks", "tokens": [3764, 11, 309, 311, 406, 7157, 11, 457, 309, 311, 257, 636, 300, 291, 393, 764, 659, 12, 17227, 2001, 9590], "temperature": 0.0, "avg_logprob": -0.20636633609203583, "compression_ratio": 1.6199095022624435, "no_speech_prob": 8.851547477206623e-07}, {"id": 858, "seek": 404966, "start": 4056.74, "end": 4058.74, "text": " Yeah, I've done a lot of", "tokens": [865, 11, 286, 600, 1096, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.20636633609203583, "compression_ratio": 1.6199095022624435, "no_speech_prob": 8.851547477206623e-07}, {"id": 859, "seek": 404966, "start": 4059.66, "end": 4064.3799999999997, "text": " Fiddling around like that you can also actually I've actually done things where I wanted to use a", "tokens": [479, 14273, 1688, 926, 411, 300, 291, 393, 611, 767, 286, 600, 767, 1096, 721, 689, 286, 1415, 281, 764, 257], "temperature": 0.0, "avg_logprob": -0.20636633609203583, "compression_ratio": 1.6199095022624435, "no_speech_prob": 8.851547477206623e-07}, {"id": 860, "seek": 404966, "start": 4065.02, "end": 4071.46, "text": " Three channel image net network on four channel data. I had satellite data where the fourth channel was near infrared", "tokens": [6244, 2269, 3256, 2533, 3209, 322, 1451, 2269, 1412, 13, 286, 632, 16016, 1412, 689, 264, 6409, 2269, 390, 2651, 30361], "temperature": 0.0, "avg_logprob": -0.20636633609203583, "compression_ratio": 1.6199095022624435, "no_speech_prob": 8.851547477206623e-07}, {"id": 861, "seek": 404966, "start": 4072.3399999999997, "end": 4075.3399999999997, "text": " And so basically I added an extra", "tokens": [400, 370, 1936, 286, 3869, 364, 2857], "temperature": 0.0, "avg_logprob": -0.20636633609203583, "compression_ratio": 1.6199095022624435, "no_speech_prob": 8.851547477206623e-07}, {"id": 862, "seek": 404966, "start": 4077.42, "end": 4078.7999999999997, "text": " Kind of", "tokens": [9242, 295], "temperature": 0.0, "avg_logprob": -0.20636633609203583, "compression_ratio": 1.6199095022624435, "no_speech_prob": 8.851547477206623e-07}, {"id": 863, "seek": 407880, "start": 4078.8, "end": 4086.9, "text": " Level to my convolutional kernels that were all zeros and so basically like started off by ignoring the new infrared band", "tokens": [16872, 281, 452, 45216, 304, 23434, 1625, 300, 645, 439, 35193, 293, 370, 1936, 411, 1409, 766, 538, 26258, 264, 777, 30361, 4116], "temperature": 0.0, "avg_logprob": -0.183804848614861, "compression_ratio": 1.8143939393939394, "no_speech_prob": 1.9033785747524234e-06}, {"id": 864, "seek": 407880, "start": 4087.38, "end": 4091.78, "text": " And so what happens it basically and you'll see this next week is that?", "tokens": [400, 370, 437, 2314, 309, 1936, 293, 291, 603, 536, 341, 958, 1243, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.183804848614861, "compression_ratio": 1.8143939393939394, "no_speech_prob": 1.9033785747524234e-06}, {"id": 865, "seek": 407880, "start": 4092.78, "end": 4098.860000000001, "text": " Rather than having these like carefully trained filters when you're actually training something from scratch", "tokens": [16571, 813, 1419, 613, 411, 7500, 8895, 15995, 562, 291, 434, 767, 3097, 746, 490, 8459], "temperature": 0.0, "avg_logprob": -0.183804848614861, "compression_ratio": 1.8143939393939394, "no_speech_prob": 1.9033785747524234e-06}, {"id": 866, "seek": 407880, "start": 4099.26, "end": 4101.46, "text": " We're actually going to start with random numbers", "tokens": [492, 434, 767, 516, 281, 722, 365, 4974, 3547], "temperature": 0.0, "avg_logprob": -0.183804848614861, "compression_ratio": 1.8143939393939394, "no_speech_prob": 1.9033785747524234e-06}, {"id": 867, "seek": 407880, "start": 4101.9800000000005, "end": 4103.1, "text": " That's actually what we do", "tokens": [663, 311, 767, 437, 321, 360], "temperature": 0.0, "avg_logprob": -0.183804848614861, "compression_ratio": 1.8143939393939394, "no_speech_prob": 1.9033785747524234e-06}, {"id": 868, "seek": 407880, "start": 4103.1, "end": 4107.22, "text": " We actually start with random numbers and then we use this thing called stochastic gradient descent", "tokens": [492, 767, 722, 365, 4974, 3547, 293, 550, 321, 764, 341, 551, 1219, 342, 8997, 2750, 16235, 23475], "temperature": 0.0, "avg_logprob": -0.183804848614861, "compression_ratio": 1.8143939393939394, "no_speech_prob": 1.9033785747524234e-06}, {"id": 869, "seek": 410722, "start": 4107.22, "end": 4112.42, "text": " Which we've kind of seen conceptually to slightly improve those random numbers to make them less random", "tokens": [3013, 321, 600, 733, 295, 1612, 3410, 671, 281, 4748, 3470, 729, 4974, 3547, 281, 652, 552, 1570, 4974], "temperature": 0.0, "avg_logprob": -0.17755146821339926, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.123370222761878e-06}, {"id": 870, "seek": 410722, "start": 4112.42, "end": 4115.5, "text": " And we basically do that again and again and again", "tokens": [400, 321, 1936, 360, 300, 797, 293, 797, 293, 797], "temperature": 0.0, "avg_logprob": -0.17755146821339926, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.123370222761878e-06}, {"id": 871, "seek": 410722, "start": 4116.7, "end": 4121.84, "text": " Okay, great. Let's take a seven minute break and we'll come back at 750", "tokens": [1033, 11, 869, 13, 961, 311, 747, 257, 3407, 3456, 1821, 293, 321, 603, 808, 646, 412, 1614, 2803], "temperature": 0.0, "avg_logprob": -0.17755146821339926, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.123370222761878e-06}, {"id": 872, "seek": 410722, "start": 4127.900000000001, "end": 4132.9400000000005, "text": " All right, so what happens next so we've got as far as", "tokens": [1057, 558, 11, 370, 437, 2314, 958, 370, 321, 600, 658, 382, 1400, 382], "temperature": 0.0, "avg_logprob": -0.17755146821339926, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.123370222761878e-06}, {"id": 873, "seek": 413294, "start": 4132.94, "end": 4134.94, "text": " Doing a", "tokens": [18496, 257], "temperature": 0.0, "avg_logprob": -0.20253810015591708, "compression_ratio": 1.6986899563318778, "no_speech_prob": 7.646480298717506e-06}, {"id": 874, "seek": 413294, "start": 4137.139999999999, "end": 4143.419999999999, "text": " Fully connected layer right so we had our the results of our max pooling layer got fed to a fully connected layer", "tokens": [479, 2150, 4582, 4583, 558, 370, 321, 632, 527, 264, 3542, 295, 527, 11469, 7005, 278, 4583, 658, 4636, 281, 257, 4498, 4582, 4583], "temperature": 0.0, "avg_logprob": -0.20253810015591708, "compression_ratio": 1.6986899563318778, "no_speech_prob": 7.646480298717506e-06}, {"id": 875, "seek": 413294, "start": 4143.419999999999, "end": 4147.94, "text": " And you might notice those of you that remember your linear algebra", "tokens": [400, 291, 1062, 3449, 729, 295, 291, 300, 1604, 428, 8213, 21989], "temperature": 0.0, "avg_logprob": -0.20253810015591708, "compression_ratio": 1.6986899563318778, "no_speech_prob": 7.646480298717506e-06}, {"id": 876, "seek": 413294, "start": 4148.0599999999995, "end": 4151.339999999999, "text": " The fully connected layer is actually doing a classic traditional", "tokens": [440, 4498, 4582, 4583, 307, 767, 884, 257, 7230, 5164], "temperature": 0.0, "avg_logprob": -0.20253810015591708, "compression_ratio": 1.6986899563318778, "no_speech_prob": 7.646480298717506e-06}, {"id": 877, "seek": 413294, "start": 4152.0199999999995, "end": 4153.62, "text": " matrix product", "tokens": [8141, 1674], "temperature": 0.0, "avg_logprob": -0.20253810015591708, "compression_ratio": 1.6986899563318778, "no_speech_prob": 7.646480298717506e-06}, {"id": 878, "seek": 413294, "start": 4153.62, "end": 4161.0599999999995, "text": " Okay, so it's basically just going through each pair in turn multiplying them together and then adding them up to do a", "tokens": [1033, 11, 370, 309, 311, 1936, 445, 516, 807, 1184, 6119, 294, 1261, 30955, 552, 1214, 293, 550, 5127, 552, 493, 281, 360, 257], "temperature": 0.0, "avg_logprob": -0.20253810015591708, "compression_ratio": 1.6986899563318778, "no_speech_prob": 7.646480298717506e-06}, {"id": 879, "seek": 416106, "start": 4161.06, "end": 4163.06, "text": " matrix product", "tokens": [8141, 1674], "temperature": 0.0, "avg_logprob": -0.2620062981882403, "compression_ratio": 1.4720496894409938, "no_speech_prob": 1.0676998272174387e-06}, {"id": 880, "seek": 416106, "start": 4164.46, "end": 4166.46, "text": " Now", "tokens": [823], "temperature": 0.0, "avg_logprob": -0.2620062981882403, "compression_ratio": 1.4720496894409938, "no_speech_prob": 1.0676998272174387e-06}, {"id": 881, "seek": 416106, "start": 4168.22, "end": 4171.860000000001, "text": " In practice if we want to", "tokens": [682, 3124, 498, 321, 528, 281], "temperature": 0.0, "avg_logprob": -0.2620062981882403, "compression_ratio": 1.4720496894409938, "no_speech_prob": 1.0676998272174387e-06}, {"id": 882, "seek": 416106, "start": 4173.620000000001, "end": 4176.900000000001, "text": " Calculate which one of the ten digits we're looking at", "tokens": [3511, 2444, 473, 597, 472, 295, 264, 2064, 27011, 321, 434, 1237, 412], "temperature": 0.0, "avg_logprob": -0.2620062981882403, "compression_ratio": 1.4720496894409938, "no_speech_prob": 1.0676998272174387e-06}, {"id": 883, "seek": 416106, "start": 4179.620000000001, "end": 4182.900000000001, "text": " This single number we've calculated isn't enough", "tokens": [639, 2167, 1230, 321, 600, 15598, 1943, 380, 1547], "temperature": 0.0, "avg_logprob": -0.2620062981882403, "compression_ratio": 1.4720496894409938, "no_speech_prob": 1.0676998272174387e-06}, {"id": 884, "seek": 416106, "start": 4184.1, "end": 4186.1, "text": " We would actually calculate", "tokens": [492, 576, 767, 8873], "temperature": 0.0, "avg_logprob": -0.2620062981882403, "compression_ratio": 1.4720496894409938, "no_speech_prob": 1.0676998272174387e-06}, {"id": 885, "seek": 418610, "start": 4186.1, "end": 4192.06, "text": " ten numbers so what we would have is rather than just having one set of", "tokens": [2064, 3547, 370, 437, 321, 576, 362, 307, 2831, 813, 445, 1419, 472, 992, 295], "temperature": 0.0, "avg_logprob": -0.19992203764863067, "compression_ratio": 1.6103896103896105, "no_speech_prob": 1.7880590803542873e-06}, {"id": 886, "seek": 418610, "start": 4193.14, "end": 4198.34, "text": " fully connected weights like this and I say set because remember there's like a whole", "tokens": [4498, 4582, 17443, 411, 341, 293, 286, 584, 992, 570, 1604, 456, 311, 411, 257, 1379], "temperature": 0.0, "avg_logprob": -0.19992203764863067, "compression_ratio": 1.6103896103896105, "no_speech_prob": 1.7880590803542873e-06}, {"id": 887, "seek": 418610, "start": 4199.02, "end": 4202.46, "text": " 3d kind of tensor of them we would actually need", "tokens": [805, 67, 733, 295, 40863, 295, 552, 321, 576, 767, 643], "temperature": 0.0, "avg_logprob": -0.19992203764863067, "compression_ratio": 1.6103896103896105, "no_speech_prob": 1.7880590803542873e-06}, {"id": 888, "seek": 418610, "start": 4203.5, "end": 4205.3, "text": " ten of those", "tokens": [2064, 295, 729], "temperature": 0.0, "avg_logprob": -0.19992203764863067, "compression_ratio": 1.6103896103896105, "no_speech_prob": 1.7880590803542873e-06}, {"id": 889, "seek": 418610, "start": 4205.3, "end": 4208.54, "text": " Right so you can see that these tensors start to get a little bit", "tokens": [1779, 370, 291, 393, 536, 300, 613, 10688, 830, 722, 281, 483, 257, 707, 857], "temperature": 0.0, "avg_logprob": -0.19992203764863067, "compression_ratio": 1.6103896103896105, "no_speech_prob": 1.7880590803542873e-06}, {"id": 890, "seek": 418610, "start": 4209.3, "end": 4214.9400000000005, "text": " High dimensional right and so this is where my patients with doing it in Excel ran out", "tokens": [5229, 18795, 558, 293, 370, 341, 307, 689, 452, 4209, 365, 884, 309, 294, 19060, 5872, 484], "temperature": 0.0, "avg_logprob": -0.19992203764863067, "compression_ratio": 1.6103896103896105, "no_speech_prob": 1.7880590803542873e-06}, {"id": 891, "seek": 421494, "start": 4214.94, "end": 4218.82, "text": " But imagine that I had done this ten times I could now have ten", "tokens": [583, 3811, 300, 286, 632, 1096, 341, 2064, 1413, 286, 727, 586, 362, 2064], "temperature": 0.0, "avg_logprob": -0.2967005549250422, "compression_ratio": 1.5368421052631578, "no_speech_prob": 1.9033792568734498e-06}, {"id": 892, "seek": 421494, "start": 4219.299999999999, "end": 4225.219999999999, "text": " Different numbers all being calculated here using exactly the same process right it just be ten of these", "tokens": [20825, 3547, 439, 885, 15598, 510, 1228, 2293, 264, 912, 1399, 558, 309, 445, 312, 2064, 295, 613], "temperature": 0.0, "avg_logprob": -0.2967005549250422, "compression_ratio": 1.5368421052631578, "no_speech_prob": 1.9033792568734498e-06}, {"id": 893, "seek": 421494, "start": 4226.62, "end": 4228.62, "text": " fully connected", "tokens": [4498, 4582], "temperature": 0.0, "avg_logprob": -0.2967005549250422, "compression_ratio": 1.5368421052631578, "no_speech_prob": 1.9033792568734498e-06}, {"id": 894, "seek": 421494, "start": 4229.62, "end": 4232.179999999999, "text": " To by and by and", "tokens": [1407, 538, 293, 538, 293], "temperature": 0.0, "avg_logprob": -0.2967005549250422, "compression_ratio": 1.5368421052631578, "no_speech_prob": 1.9033792568734498e-06}, {"id": 895, "seek": 421494, "start": 4234.179999999999, "end": 4236.179999999999, "text": " Arise basically", "tokens": [1587, 908, 1936], "temperature": 0.0, "avg_logprob": -0.2967005549250422, "compression_ratio": 1.5368421052631578, "no_speech_prob": 1.9033792568734498e-06}, {"id": 896, "seek": 421494, "start": 4236.179999999999, "end": 4237.62, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.2967005549250422, "compression_ratio": 1.5368421052631578, "no_speech_prob": 1.9033792568734498e-06}, {"id": 897, "seek": 421494, "start": 4237.62, "end": 4242.86, "text": " So then we would have ten numbers being spat out so what happens next?", "tokens": [407, 550, 321, 576, 362, 2064, 3547, 885, 15000, 484, 370, 437, 2314, 958, 30], "temperature": 0.0, "avg_logprob": -0.2967005549250422, "compression_ratio": 1.5368421052631578, "no_speech_prob": 1.9033792568734498e-06}, {"id": 898, "seek": 424286, "start": 4242.86, "end": 4247.5, "text": " So next up we can open up a different Excel", "tokens": [407, 958, 493, 321, 393, 1269, 493, 257, 819, 19060], "temperature": 0.0, "avg_logprob": -0.27413152611773944, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.933350631588837e-06}, {"id": 899, "seek": 424286, "start": 4248.7, "end": 4249.94, "text": " worksheet", "tokens": [49890], "temperature": 0.0, "avg_logprob": -0.27413152611773944, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.933350631588837e-06}, {"id": 900, "seek": 424286, "start": 4249.94, "end": 4252.54, "text": " entropy example dot XLS that's got two", "tokens": [30867, 1365, 5893, 1783, 19198, 300, 311, 658, 732], "temperature": 0.0, "avg_logprob": -0.27413152611773944, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.933350631588837e-06}, {"id": 901, "seek": 424286, "start": 4253.42, "end": 4255.0199999999995, "text": " different", "tokens": [819], "temperature": 0.0, "avg_logprob": -0.27413152611773944, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.933350631588837e-06}, {"id": 902, "seek": 424286, "start": 4255.0199999999995, "end": 4257.339999999999, "text": " Worksheets one of them is called softmax", "tokens": [6603, 9611, 1385, 472, 295, 552, 307, 1219, 2787, 41167], "temperature": 0.0, "avg_logprob": -0.27413152611773944, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.933350631588837e-06}, {"id": 903, "seek": 424286, "start": 4258.219999999999, "end": 4265.62, "text": " And what happens here? I'm sorry I've changed domains rather than predicting whether it's the number from one to naught to nine", "tokens": [400, 437, 2314, 510, 30, 286, 478, 2597, 286, 600, 3105, 25514, 2831, 813, 32884, 1968, 309, 311, 264, 1230, 490, 472, 281, 13138, 281, 4949], "temperature": 0.0, "avg_logprob": -0.27413152611773944, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.933350631588837e-06}, {"id": 904, "seek": 424286, "start": 4265.62, "end": 4269.719999999999, "text": " I'm going to predict whether something is a cat a dog a plane a fish or building okay", "tokens": [286, 478, 516, 281, 6069, 1968, 746, 307, 257, 3857, 257, 3000, 257, 5720, 257, 3506, 420, 2390, 1392], "temperature": 0.0, "avg_logprob": -0.27413152611773944, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.933350631588837e-06}, {"id": 905, "seek": 426972, "start": 4269.72, "end": 4273.16, "text": " So out of our that fully connected layer", "tokens": [407, 484, 295, 527, 300, 4498, 4582, 4583], "temperature": 0.0, "avg_logprob": -0.20161165509905135, "compression_ratio": 1.75, "no_speech_prob": 1.051148046826711e-06}, {"id": 906, "seek": 426972, "start": 4273.68, "end": 4278.64, "text": " We've got in this case. We'd have five numbers and notice at this point", "tokens": [492, 600, 658, 294, 341, 1389, 13, 492, 1116, 362, 1732, 3547, 293, 3449, 412, 341, 935], "temperature": 0.0, "avg_logprob": -0.20161165509905135, "compression_ratio": 1.75, "no_speech_prob": 1.051148046826711e-06}, {"id": 907, "seek": 426972, "start": 4279.240000000001, "end": 4285.0, "text": " There's no value okay, and then last layer. There's no value okay, so I can have negatives", "tokens": [821, 311, 572, 2158, 1392, 11, 293, 550, 1036, 4583, 13, 821, 311, 572, 2158, 1392, 11, 370, 286, 393, 362, 40019], "temperature": 0.0, "avg_logprob": -0.20161165509905135, "compression_ratio": 1.75, "no_speech_prob": 1.051148046826711e-06}, {"id": 908, "seek": 426972, "start": 4285.88, "end": 4290.16, "text": " Okay, so I want to turn these five numbers", "tokens": [1033, 11, 370, 286, 528, 281, 1261, 613, 1732, 3547], "temperature": 0.0, "avg_logprob": -0.20161165509905135, "compression_ratio": 1.75, "no_speech_prob": 1.051148046826711e-06}, {"id": 909, "seek": 426972, "start": 4291.240000000001, "end": 4297.400000000001, "text": " Each into a probability. I want to turn it into a probability from naught to one that it's a cat", "tokens": [6947, 666, 257, 8482, 13, 286, 528, 281, 1261, 309, 666, 257, 8482, 490, 13138, 281, 472, 300, 309, 311, 257, 3857], "temperature": 0.0, "avg_logprob": -0.20161165509905135, "compression_ratio": 1.75, "no_speech_prob": 1.051148046826711e-06}, {"id": 910, "seek": 429740, "start": 4297.4, "end": 4301.679999999999, "text": " That it's a dog that it's a plane that it's a fish that it's a building and", "tokens": [663, 309, 311, 257, 3000, 300, 309, 311, 257, 5720, 300, 309, 311, 257, 3506, 300, 309, 311, 257, 2390, 293], "temperature": 0.0, "avg_logprob": -0.19161492527121365, "compression_ratio": 1.7405857740585775, "no_speech_prob": 1.2878939514848753e-06}, {"id": 911, "seek": 429740, "start": 4302.24, "end": 4307.92, "text": " I want those probabilities to have a couple of characteristics first is that each of them should be between zero and one and", "tokens": [286, 528, 729, 33783, 281, 362, 257, 1916, 295, 10891, 700, 307, 300, 1184, 295, 552, 820, 312, 1296, 4018, 293, 472, 293], "temperature": 0.0, "avg_logprob": -0.19161492527121365, "compression_ratio": 1.7405857740585775, "no_speech_prob": 1.2878939514848753e-06}, {"id": 912, "seek": 429740, "start": 4308.759999999999, "end": 4314.44, "text": " The second is that they should they together should add up to one right? It's definitely one of these five things", "tokens": [440, 1150, 307, 300, 436, 820, 436, 1214, 820, 909, 493, 281, 472, 558, 30, 467, 311, 2138, 472, 295, 613, 1732, 721], "temperature": 0.0, "avg_logprob": -0.19161492527121365, "compression_ratio": 1.7405857740585775, "no_speech_prob": 1.2878939514848753e-06}, {"id": 913, "seek": 429740, "start": 4315.5199999999995, "end": 4319.48, "text": " Okay, so to do that. We use a different kind of activation function", "tokens": [1033, 11, 370, 281, 360, 300, 13, 492, 764, 257, 819, 733, 295, 24433, 2445], "temperature": 0.0, "avg_logprob": -0.19161492527121365, "compression_ratio": 1.7405857740585775, "no_speech_prob": 1.2878939514848753e-06}, {"id": 914, "seek": 429740, "start": 4320.28, "end": 4322.28, "text": " What's an activation function an?", "tokens": [708, 311, 364, 24433, 2445, 364, 30], "temperature": 0.0, "avg_logprob": -0.19161492527121365, "compression_ratio": 1.7405857740585775, "no_speech_prob": 1.2878939514848753e-06}, {"id": 915, "seek": 432228, "start": 4322.28, "end": 4327.4, "text": " Activation function is a function that is applied to activations", "tokens": [28550, 399, 2445, 307, 257, 2445, 300, 307, 6456, 281, 2430, 763], "temperature": 0.0, "avg_logprob": -0.25939295842097354, "compression_ratio": 1.9757575757575758, "no_speech_prob": 1.4823536957919714e-06}, {"id": 916, "seek": 432228, "start": 4327.96, "end": 4330.96, "text": " so for example max zero comma", "tokens": [370, 337, 1365, 11469, 4018, 22117], "temperature": 0.0, "avg_logprob": -0.25939295842097354, "compression_ratio": 1.9757575757575758, "no_speech_prob": 1.4823536957919714e-06}, {"id": 917, "seek": 432228, "start": 4332.08, "end": 4337.0, "text": " Something is a function that I applied to an activation", "tokens": [6595, 307, 257, 2445, 300, 286, 6456, 281, 364, 24433], "temperature": 0.0, "avg_logprob": -0.25939295842097354, "compression_ratio": 1.9757575757575758, "no_speech_prob": 1.4823536957919714e-06}, {"id": 918, "seek": 432228, "start": 4337.759999999999, "end": 4340.48, "text": " for an activation function always takes in", "tokens": [337, 364, 24433, 2445, 1009, 2516, 294], "temperature": 0.0, "avg_logprob": -0.25939295842097354, "compression_ratio": 1.9757575757575758, "no_speech_prob": 1.4823536957919714e-06}, {"id": 919, "seek": 432228, "start": 4341.32, "end": 4346.599999999999, "text": " One number and spits out one number so max of zero comma X", "tokens": [1485, 1230, 293, 637, 1208, 484, 472, 1230, 370, 11469, 295, 4018, 22117, 1783], "temperature": 0.0, "avg_logprob": -0.25939295842097354, "compression_ratio": 1.9757575757575758, "no_speech_prob": 1.4823536957919714e-06}, {"id": 920, "seek": 434660, "start": 4346.6, "end": 4352.360000000001, "text": " Takes in a number X and spits out some different number rather you have X", "tokens": [44347, 294, 257, 1230, 1783, 293, 637, 1208, 484, 512, 819, 1230, 2831, 291, 362, 1783], "temperature": 0.0, "avg_logprob": -0.29706068961851056, "compression_ratio": 1.503030303030303, "no_speech_prob": 8.186352715711109e-07}, {"id": 921, "seek": 434660, "start": 4353.56, "end": 4360.64, "text": " That's all an activation function is and if you remember back to that PowerPoint we saw in", "tokens": [663, 311, 439, 364, 24433, 2445, 307, 293, 498, 291, 1604, 646, 281, 300, 25584, 321, 1866, 294], "temperature": 0.0, "avg_logprob": -0.29706068961851056, "compression_ratio": 1.503030303030303, "no_speech_prob": 8.186352715711109e-07}, {"id": 922, "seek": 434660, "start": 4361.72, "end": 4363.72, "text": " lesson one", "tokens": [6898, 472], "temperature": 0.0, "avg_logprob": -0.29706068961851056, "compression_ratio": 1.503030303030303, "no_speech_prob": 8.186352715711109e-07}, {"id": 923, "seek": 434660, "start": 4366.08, "end": 4369.64, "text": " Each of our layers was just a linear", "tokens": [6947, 295, 527, 7914, 390, 445, 257, 8213], "temperature": 0.0, "avg_logprob": -0.29706068961851056, "compression_ratio": 1.503030303030303, "no_speech_prob": 8.186352715711109e-07}, {"id": 924, "seek": 434660, "start": 4371.04, "end": 4373.88, "text": " function and then after every layer", "tokens": [2445, 293, 550, 934, 633, 4583], "temperature": 0.0, "avg_logprob": -0.29706068961851056, "compression_ratio": 1.503030303030303, "no_speech_prob": 8.186352715711109e-07}, {"id": 925, "seek": 437388, "start": 4373.88, "end": 4376.92, "text": " We said we needed some non-linearity", "tokens": [492, 848, 321, 2978, 512, 2107, 12, 1889, 17409], "temperature": 0.0, "avg_logprob": -0.2516226419588415, "compression_ratio": 1.6808510638297873, "no_speech_prob": 5.043465876042319e-07}, {"id": 926, "seek": 437388, "start": 4377.96, "end": 4379.96, "text": " right because if you stack a bunch of", "tokens": [558, 570, 498, 291, 8630, 257, 3840, 295], "temperature": 0.0, "avg_logprob": -0.2516226419588415, "compression_ratio": 1.6808510638297873, "no_speech_prob": 5.043465876042319e-07}, {"id": 927, "seek": 437388, "start": 4380.84, "end": 4385.34, "text": " Linear layers together right then all you end up with is a linear layer", "tokens": [14670, 289, 7914, 1214, 558, 550, 439, 291, 917, 493, 365, 307, 257, 8213, 4583], "temperature": 0.0, "avg_logprob": -0.2516226419588415, "compression_ratio": 1.6808510638297873, "no_speech_prob": 5.043465876042319e-07}, {"id": 928, "seek": 437388, "start": 4386.12, "end": 4387.32, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.2516226419588415, "compression_ratio": 1.6808510638297873, "no_speech_prob": 5.043465876042319e-07}, {"id": 929, "seek": 437388, "start": 4387.32, "end": 4391.400000000001, "text": " So somebody's talking can can you not I'm slightly distracting. Thank you", "tokens": [407, 2618, 311, 1417, 393, 393, 291, 406, 286, 478, 4748, 36689, 13, 1044, 291], "temperature": 0.0, "avg_logprob": -0.2516226419588415, "compression_ratio": 1.6808510638297873, "no_speech_prob": 5.043465876042319e-07}, {"id": 930, "seek": 437388, "start": 4393.56, "end": 4395.56, "text": " If you stack a number of linear", "tokens": [759, 291, 8630, 257, 1230, 295, 8213], "temperature": 0.0, "avg_logprob": -0.2516226419588415, "compression_ratio": 1.6808510638297873, "no_speech_prob": 5.043465876042319e-07}, {"id": 931, "seek": 437388, "start": 4396.52, "end": 4399.08, "text": " Functions together you just end up with a linear function", "tokens": [11166, 3916, 1214, 291, 445, 917, 493, 365, 257, 8213, 2445], "temperature": 0.0, "avg_logprob": -0.2516226419588415, "compression_ratio": 1.6808510638297873, "no_speech_prob": 5.043465876042319e-07}, {"id": 932, "seek": 439908, "start": 4399.08, "end": 4404.72, "text": " And nobody does any cool deep learning with just linear functions right, but you remember we also learned", "tokens": [400, 5079, 775, 604, 1627, 2452, 2539, 365, 445, 8213, 6828, 558, 11, 457, 291, 1604, 321, 611, 3264], "temperature": 0.0, "avg_logprob": -0.25246928458990053, "compression_ratio": 1.716279069767442, "no_speech_prob": 2.5612719127821038e-06}, {"id": 933, "seek": 439908, "start": 4405.48, "end": 4408.36, "text": " That by stacking linear functions", "tokens": [663, 538, 41376, 8213, 6828], "temperature": 0.0, "avg_logprob": -0.25246928458990053, "compression_ratio": 1.716279069767442, "no_speech_prob": 2.5612719127821038e-06}, {"id": 934, "seek": 439908, "start": 4409.72, "end": 4415.12, "text": " With between each one a non-linearity we could create like arbitrarily complex shapes", "tokens": [2022, 1296, 1184, 472, 257, 2107, 12, 1889, 17409, 321, 727, 1884, 411, 19071, 3289, 3997, 10854], "temperature": 0.0, "avg_logprob": -0.25246928458990053, "compression_ratio": 1.716279069767442, "no_speech_prob": 2.5612719127821038e-06}, {"id": 935, "seek": 439908, "start": 4415.12, "end": 4422.12, "text": " and so the non-linearity that we're using after every hidden layer is a relu rectified linear unit a", "tokens": [293, 370, 264, 2107, 12, 1889, 17409, 300, 321, 434, 1228, 934, 633, 7633, 4583, 307, 257, 1039, 84, 11048, 2587, 8213, 4985, 257], "temperature": 0.0, "avg_logprob": -0.25246928458990053, "compression_ratio": 1.716279069767442, "no_speech_prob": 2.5612719127821038e-06}, {"id": 936, "seek": 439908, "start": 4423.2, "end": 4426.16, "text": " non-linearity is an activation function an", "tokens": [2107, 12, 1889, 17409, 307, 364, 24433, 2445, 364], "temperature": 0.0, "avg_logprob": -0.25246928458990053, "compression_ratio": 1.716279069767442, "no_speech_prob": 2.5612719127821038e-06}, {"id": 937, "seek": 442616, "start": 4426.16, "end": 4429.44, "text": " Activation function is a non-linearity in", "tokens": [28550, 399, 2445, 307, 257, 2107, 12, 1889, 17409, 294], "temperature": 0.0, "avg_logprob": -0.20162552902378986, "compression_ratio": 1.8111587982832618, "no_speech_prob": 3.966963504353771e-06}, {"id": 938, "seek": 442616, "start": 4430.32, "end": 4435.12, "text": " Within deep learning obviously there's lots of other non-linearities in the world, but in deep learning", "tokens": [15996, 2452, 2539, 2745, 456, 311, 3195, 295, 661, 2107, 12, 28263, 1088, 294, 264, 1002, 11, 457, 294, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.20162552902378986, "compression_ratio": 1.8111587982832618, "no_speech_prob": 3.966963504353771e-06}, {"id": 939, "seek": 442616, "start": 4436.2, "end": 4441.84, "text": " This is what we mean so an activation function is any function that takes some activation in", "tokens": [639, 307, 437, 321, 914, 370, 364, 24433, 2445, 307, 604, 2445, 300, 2516, 512, 24433, 294], "temperature": 0.0, "avg_logprob": -0.20162552902378986, "compression_ratio": 1.8111587982832618, "no_speech_prob": 3.966963504353771e-06}, {"id": 940, "seek": 442616, "start": 4442.12, "end": 4446.92, "text": " That's a single number and spits out some new activation like max of zero comma", "tokens": [663, 311, 257, 2167, 1230, 293, 637, 1208, 484, 512, 777, 24433, 411, 11469, 295, 4018, 22117], "temperature": 0.0, "avg_logprob": -0.20162552902378986, "compression_ratio": 1.8111587982832618, "no_speech_prob": 3.966963504353771e-06}, {"id": 941, "seek": 442616, "start": 4448.04, "end": 4453.0, "text": " So I'm now going to tell you about a different activation function. It's slightly more complicated than", "tokens": [407, 286, 478, 586, 516, 281, 980, 291, 466, 257, 819, 24433, 2445, 13, 467, 311, 4748, 544, 6179, 813], "temperature": 0.0, "avg_logprob": -0.20162552902378986, "compression_ratio": 1.8111587982832618, "no_speech_prob": 3.966963504353771e-06}, {"id": 942, "seek": 445300, "start": 4453.0, "end": 4456.68, "text": " Than relu, but not too much. It's called softmax", "tokens": [18289, 1039, 84, 11, 457, 406, 886, 709, 13, 467, 311, 1219, 2787, 41167], "temperature": 0.0, "avg_logprob": -0.22328888742547287, "compression_ratio": 1.7722772277227723, "no_speech_prob": 4.888298121841217e-07}, {"id": 943, "seek": 445300, "start": 4457.44, "end": 4465.16, "text": " Softmax only ever occurs in the final layer at the very end and the reason why is that softmax always spits out", "tokens": [16985, 41167, 787, 1562, 11843, 294, 264, 2572, 4583, 412, 264, 588, 917, 293, 264, 1778, 983, 307, 300, 2787, 41167, 1009, 637, 1208, 484], "temperature": 0.0, "avg_logprob": -0.22328888742547287, "compression_ratio": 1.7722772277227723, "no_speech_prob": 4.888298121841217e-07}, {"id": 944, "seek": 445300, "start": 4466.24, "end": 4470.48, "text": " numbers as an activation function that always spits out a number between naught and one and", "tokens": [3547, 382, 364, 24433, 2445, 300, 1009, 637, 1208, 484, 257, 1230, 1296, 13138, 293, 472, 293], "temperature": 0.0, "avg_logprob": -0.22328888742547287, "compression_ratio": 1.7722772277227723, "no_speech_prob": 4.888298121841217e-07}, {"id": 945, "seek": 445300, "start": 4471.28, "end": 4473.9, "text": " It always spits out a bunch of numbers that add to one", "tokens": [467, 1009, 637, 1208, 484, 257, 3840, 295, 3547, 300, 909, 281, 472], "temperature": 0.0, "avg_logprob": -0.22328888742547287, "compression_ratio": 1.7722772277227723, "no_speech_prob": 4.888298121841217e-07}, {"id": 946, "seek": 445300, "start": 4474.56, "end": 4477.8, "text": " So a softmax gives us what we want right in", "tokens": [407, 257, 2787, 41167, 2709, 505, 437, 321, 528, 558, 294], "temperature": 0.0, "avg_logprob": -0.22328888742547287, "compression_ratio": 1.7722772277227723, "no_speech_prob": 4.888298121841217e-07}, {"id": 947, "seek": 445300, "start": 4478.92, "end": 4480.44, "text": " theory", "tokens": [5261], "temperature": 0.0, "avg_logprob": -0.22328888742547287, "compression_ratio": 1.7722772277227723, "no_speech_prob": 4.888298121841217e-07}, {"id": 948, "seek": 448044, "start": 4480.44, "end": 4487.28, "text": " This isn't strictly necessary right like we could ask our neural net to learn a set of", "tokens": [639, 1943, 380, 20792, 4818, 558, 411, 321, 727, 1029, 527, 18161, 2533, 281, 1466, 257, 992, 295], "temperature": 0.0, "avg_logprob": -0.17194948698344983, "compression_ratio": 1.587962962962963, "no_speech_prob": 2.6425791475048754e-06}, {"id": 949, "seek": 448044, "start": 4487.96, "end": 4489.24, "text": " kernels", "tokens": [23434, 1625], "temperature": 0.0, "avg_logprob": -0.17194948698344983, "compression_ratio": 1.587962962962963, "no_speech_prob": 2.6425791475048754e-06}, {"id": 950, "seek": 448044, "start": 4489.24, "end": 4495.0, "text": " Which have you know which which give probabilities that line up as closely as possible with what we want", "tokens": [3013, 362, 291, 458, 597, 597, 976, 33783, 300, 1622, 493, 382, 8185, 382, 1944, 365, 437, 321, 528], "temperature": 0.0, "avg_logprob": -0.17194948698344983, "compression_ratio": 1.587962962962963, "no_speech_prob": 2.6425791475048754e-06}, {"id": 951, "seek": 448044, "start": 4495.04, "end": 4500.719999999999, "text": " But in general with deep learning if you can construct your architecture so that the desired", "tokens": [583, 294, 2674, 365, 2452, 2539, 498, 291, 393, 7690, 428, 9482, 370, 300, 264, 14721], "temperature": 0.0, "avg_logprob": -0.17194948698344983, "compression_ratio": 1.587962962962963, "no_speech_prob": 2.6425791475048754e-06}, {"id": 952, "seek": 448044, "start": 4501.32, "end": 4504.04, "text": " Characteristics are as easy to express as possible", "tokens": [36786, 6006, 366, 382, 1858, 281, 5109, 382, 1944], "temperature": 0.0, "avg_logprob": -0.17194948698344983, "compression_ratio": 1.587962962962963, "no_speech_prob": 2.6425791475048754e-06}, {"id": 953, "seek": 450404, "start": 4504.04, "end": 4509.48, "text": " You'll end up with better models like they'll learn more quickly with less parameters", "tokens": [509, 603, 917, 493, 365, 1101, 5245, 411, 436, 603, 1466, 544, 2661, 365, 1570, 9834], "temperature": 0.0, "avg_logprob": -0.13928992725978387, "compression_ratio": 1.7050359712230216, "no_speech_prob": 2.190774239352322e-06}, {"id": 954, "seek": 450404, "start": 4509.48, "end": 4514.96, "text": " So in this case we know that our probabilities should end up being between naught and one", "tokens": [407, 294, 341, 1389, 321, 458, 300, 527, 33783, 820, 917, 493, 885, 1296, 13138, 293, 472], "temperature": 0.0, "avg_logprob": -0.13928992725978387, "compression_ratio": 1.7050359712230216, "no_speech_prob": 2.190774239352322e-06}, {"id": 955, "seek": 450404, "start": 4515.48, "end": 4517.8, "text": " We know that they should end up adding to one", "tokens": [492, 458, 300, 436, 820, 917, 493, 5127, 281, 472], "temperature": 0.0, "avg_logprob": -0.13928992725978387, "compression_ratio": 1.7050359712230216, "no_speech_prob": 2.190774239352322e-06}, {"id": 956, "seek": 450404, "start": 4518.12, "end": 4522.12, "text": " So if we construct an activation function which always has those features", "tokens": [407, 498, 321, 7690, 364, 24433, 2445, 597, 1009, 575, 729, 4122], "temperature": 0.0, "avg_logprob": -0.13928992725978387, "compression_ratio": 1.7050359712230216, "no_speech_prob": 2.190774239352322e-06}, {"id": 957, "seek": 450404, "start": 4522.84, "end": 4527.84, "text": " Then we're going to make our neural network do a better job. It's going to make it easier for it", "tokens": [1396, 321, 434, 516, 281, 652, 527, 18161, 3209, 360, 257, 1101, 1691, 13, 467, 311, 516, 281, 652, 309, 3571, 337, 309], "temperature": 0.0, "avg_logprob": -0.13928992725978387, "compression_ratio": 1.7050359712230216, "no_speech_prob": 2.190774239352322e-06}, {"id": 958, "seek": 450404, "start": 4527.84, "end": 4530.8, "text": " It doesn't have to learn to do those things because it all happened automatically", "tokens": [467, 1177, 380, 362, 281, 1466, 281, 360, 729, 721, 570, 309, 439, 2011, 6772], "temperature": 0.0, "avg_logprob": -0.13928992725978387, "compression_ratio": 1.7050359712230216, "no_speech_prob": 2.190774239352322e-06}, {"id": 959, "seek": 453080, "start": 4530.8, "end": 4535.62, "text": " Automatically okay, so in order to make this work", "tokens": [24619, 5030, 1392, 11, 370, 294, 1668, 281, 652, 341, 589], "temperature": 0.0, "avg_logprob": -0.2097856601079305, "compression_ratio": 1.6425339366515836, "no_speech_prob": 2.156806431230507e-06}, {"id": 960, "seek": 453080, "start": 4536.68, "end": 4539.400000000001, "text": " We first of all have to get rid of all of the negatives", "tokens": [492, 700, 295, 439, 362, 281, 483, 3973, 295, 439, 295, 264, 40019], "temperature": 0.0, "avg_logprob": -0.2097856601079305, "compression_ratio": 1.6425339366515836, "no_speech_prob": 2.156806431230507e-06}, {"id": 961, "seek": 453080, "start": 4540.28, "end": 4542.76, "text": " Right like we can't have negative probabilities", "tokens": [1779, 411, 321, 393, 380, 362, 3671, 33783], "temperature": 0.0, "avg_logprob": -0.2097856601079305, "compression_ratio": 1.6425339366515836, "no_speech_prob": 2.156806431230507e-06}, {"id": 962, "seek": 453080, "start": 4543.24, "end": 4548.2, "text": " So to make things not be negative one way we could do it is just go a to the power of", "tokens": [407, 281, 652, 721, 406, 312, 3671, 472, 636, 321, 727, 360, 309, 307, 445, 352, 257, 281, 264, 1347, 295], "temperature": 0.0, "avg_logprob": -0.2097856601079305, "compression_ratio": 1.6425339366515836, "no_speech_prob": 2.156806431230507e-06}, {"id": 963, "seek": 453080, "start": 4548.72, "end": 4554.04, "text": " Right so here you can see my first step is to go X of the previous one", "tokens": [1779, 370, 510, 291, 393, 536, 452, 700, 1823, 307, 281, 352, 1783, 295, 264, 3894, 472], "temperature": 0.0, "avg_logprob": -0.2097856601079305, "compression_ratio": 1.6425339366515836, "no_speech_prob": 2.156806431230507e-06}, {"id": 964, "seek": 453080, "start": 4554.320000000001, "end": 4557.72, "text": " right, and I think I've mentioned this before but of", "tokens": [558, 11, 293, 286, 519, 286, 600, 2835, 341, 949, 457, 295], "temperature": 0.0, "avg_logprob": -0.2097856601079305, "compression_ratio": 1.6425339366515836, "no_speech_prob": 2.156806431230507e-06}, {"id": 965, "seek": 455772, "start": 4557.72, "end": 4562.56, "text": " All the math that you just need to be super familiar with to do deep learning", "tokens": [1057, 264, 5221, 300, 291, 445, 643, 281, 312, 1687, 4963, 365, 281, 360, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.23805615743001302, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.482466925357585e-06}, {"id": 966, "seek": 455772, "start": 4562.96, "end": 4570.92, "text": " The one you really need is logarithms and X's right all of deep learning and all of machine learning they appear all the time", "tokens": [440, 472, 291, 534, 643, 307, 41473, 355, 2592, 293, 1783, 311, 558, 439, 295, 2452, 2539, 293, 439, 295, 3479, 2539, 436, 4204, 439, 264, 565], "temperature": 0.0, "avg_logprob": -0.23805615743001302, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.482466925357585e-06}, {"id": 967, "seek": 455772, "start": 4571.280000000001, "end": 4573.280000000001, "text": " right, so", "tokens": [558, 11, 370], "temperature": 0.0, "avg_logprob": -0.23805615743001302, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.482466925357585e-06}, {"id": 968, "seek": 455772, "start": 4574.16, "end": 4576.16, "text": " For example", "tokens": [1171, 1365], "temperature": 0.0, "avg_logprob": -0.23805615743001302, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.482466925357585e-06}, {"id": 969, "seek": 455772, "start": 4578.400000000001, "end": 4580.400000000001, "text": " You absolutely need to know that", "tokens": [509, 3122, 643, 281, 458, 300], "temperature": 0.0, "avg_logprob": -0.23805615743001302, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.482466925357585e-06}, {"id": 970, "seek": 455772, "start": 4582.0, "end": 4583.64, "text": " log of", "tokens": [3565, 295], "temperature": 0.0, "avg_logprob": -0.23805615743001302, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.482466925357585e-06}, {"id": 971, "seek": 455772, "start": 4583.64, "end": 4585.64, "text": " X times Y", "tokens": [1783, 1413, 398], "temperature": 0.0, "avg_logprob": -0.23805615743001302, "compression_ratio": 1.5714285714285714, "no_speech_prob": 2.482466925357585e-06}, {"id": 972, "seek": 458564, "start": 4585.64, "end": 4588.360000000001, "text": " equals log of X", "tokens": [6915, 3565, 295, 1783], "temperature": 0.0, "avg_logprob": -0.21830863044375465, "compression_ratio": 1.6, "no_speech_prob": 2.123371359630255e-06}, {"id": 973, "seek": 458564, "start": 4589.400000000001, "end": 4592.0, "text": " plus log of Y", "tokens": [1804, 3565, 295, 398], "temperature": 0.0, "avg_logprob": -0.21830863044375465, "compression_ratio": 1.6, "no_speech_prob": 2.123371359630255e-06}, {"id": 974, "seek": 458564, "start": 4592.6, "end": 4598.240000000001, "text": " Right and like not just know that that's a formula that exists, but have a sense of like what does that mean?", "tokens": [1779, 293, 411, 406, 445, 458, 300, 300, 311, 257, 8513, 300, 8198, 11, 457, 362, 257, 2020, 295, 411, 437, 775, 300, 914, 30], "temperature": 0.0, "avg_logprob": -0.21830863044375465, "compression_ratio": 1.6, "no_speech_prob": 2.123371359630255e-06}, {"id": 975, "seek": 458564, "start": 4598.56, "end": 4606.18, "text": " Why is that interesting? Oh, I can turn multiplications into additions that could be really handy right and therefore", "tokens": [1545, 307, 300, 1880, 30, 876, 11, 286, 393, 1261, 17596, 763, 666, 35113, 300, 727, 312, 534, 13239, 558, 293, 4412], "temperature": 0.0, "avg_logprob": -0.21830863044375465, "compression_ratio": 1.6, "no_speech_prob": 2.123371359630255e-06}, {"id": 976, "seek": 458564, "start": 4606.88, "end": 4608.88, "text": " log of X over Y", "tokens": [3565, 295, 1783, 670, 398], "temperature": 0.0, "avg_logprob": -0.21830863044375465, "compression_ratio": 1.6, "no_speech_prob": 2.123371359630255e-06}, {"id": 977, "seek": 458564, "start": 4609.72, "end": 4611.72, "text": " equals log of X", "tokens": [6915, 3565, 295, 1783], "temperature": 0.0, "avg_logprob": -0.21830863044375465, "compression_ratio": 1.6, "no_speech_prob": 2.123371359630255e-06}, {"id": 978, "seek": 458564, "start": 4612.160000000001, "end": 4614.160000000001, "text": " minus log of Y", "tokens": [3175, 3565, 295, 398], "temperature": 0.0, "avg_logprob": -0.21830863044375465, "compression_ratio": 1.6, "no_speech_prob": 2.123371359630255e-06}, {"id": 979, "seek": 461416, "start": 4614.16, "end": 4621.92, "text": " Again that's going to come in pretty handy. You know rather than dividing I can just subtract things right and also remember that", "tokens": [3764, 300, 311, 516, 281, 808, 294, 1238, 13239, 13, 509, 458, 2831, 813, 26764, 286, 393, 445, 16390, 721, 558, 293, 611, 1604, 300], "temperature": 0.0, "avg_logprob": -0.243419203039718, "compression_ratio": 1.5, "no_speech_prob": 4.664447033064789e-07}, {"id": 980, "seek": 461416, "start": 4622.28, "end": 4624.28, "text": " If I've got log of X", "tokens": [759, 286, 600, 658, 3565, 295, 1783], "temperature": 0.0, "avg_logprob": -0.243419203039718, "compression_ratio": 1.5, "no_speech_prob": 4.664447033064789e-07}, {"id": 981, "seek": 461416, "start": 4625.08, "end": 4626.639999999999, "text": " equals Y", "tokens": [6915, 398], "temperature": 0.0, "avg_logprob": -0.243419203039718, "compression_ratio": 1.5, "no_speech_prob": 4.664447033064789e-07}, {"id": 982, "seek": 461416, "start": 4626.639999999999, "end": 4628.639999999999, "text": " Then that means a to the Y", "tokens": [1396, 300, 1355, 257, 281, 264, 398], "temperature": 0.0, "avg_logprob": -0.243419203039718, "compression_ratio": 1.5, "no_speech_prob": 4.664447033064789e-07}, {"id": 983, "seek": 461416, "start": 4629.5599999999995, "end": 4631.88, "text": " Equals X in other words log", "tokens": [15624, 1124, 1783, 294, 661, 2283, 3565], "temperature": 0.0, "avg_logprob": -0.243419203039718, "compression_ratio": 1.5, "no_speech_prob": 4.664447033064789e-07}, {"id": 984, "seek": 461416, "start": 4633.92, "end": 4637.5599999999995, "text": " Log and a to the are the inverse of each other", "tokens": [10824, 293, 257, 281, 264, 366, 264, 17340, 295, 1184, 661], "temperature": 0.0, "avg_logprob": -0.243419203039718, "compression_ratio": 1.5, "no_speech_prob": 4.664447033064789e-07}, {"id": 985, "seek": 463756, "start": 4637.56, "end": 4646.240000000001, "text": " Okay again, you just you need to really really understand these things and like so if you if you haven't spent much time with logs", "tokens": [1033, 797, 11, 291, 445, 291, 643, 281, 534, 534, 1223, 613, 721, 293, 411, 370, 498, 291, 498, 291, 2378, 380, 4418, 709, 565, 365, 20820], "temperature": 0.0, "avg_logprob": -0.18731395329270406, "compression_ratio": 1.6875, "no_speech_prob": 7.002163897595892e-07}, {"id": 986, "seek": 463756, "start": 4646.240000000001, "end": 4648.240000000001, "text": " And X for a while", "tokens": [400, 1783, 337, 257, 1339], "temperature": 0.0, "avg_logprob": -0.18731395329270406, "compression_ratio": 1.6875, "no_speech_prob": 7.002163897595892e-07}, {"id": 987, "seek": 463756, "start": 4648.320000000001, "end": 4654.4400000000005, "text": " Try plotting them in Excel or a notebook have a sense of what shape they are how they combine together", "tokens": [6526, 41178, 552, 294, 19060, 420, 257, 21060, 362, 257, 2020, 295, 437, 3909, 436, 366, 577, 436, 10432, 1214], "temperature": 0.0, "avg_logprob": -0.18731395329270406, "compression_ratio": 1.6875, "no_speech_prob": 7.002163897595892e-07}, {"id": 988, "seek": 463756, "start": 4654.84, "end": 4657.280000000001, "text": " Just make sure you're really comfortable with them, so", "tokens": [1449, 652, 988, 291, 434, 534, 4619, 365, 552, 11, 370], "temperature": 0.0, "avg_logprob": -0.18731395329270406, "compression_ratio": 1.6875, "no_speech_prob": 7.002163897595892e-07}, {"id": 989, "seek": 463756, "start": 4658.64, "end": 4660.64, "text": " We're using it here, right?", "tokens": [492, 434, 1228, 309, 510, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18731395329270406, "compression_ratio": 1.6875, "no_speech_prob": 7.002163897595892e-07}, {"id": 990, "seek": 466064, "start": 4660.64, "end": 4667.360000000001, "text": " We're using it here, so one of the things that we know is a to the power of something is positive", "tokens": [492, 434, 1228, 309, 510, 11, 370, 472, 295, 264, 721, 300, 321, 458, 307, 257, 281, 264, 1347, 295, 746, 307, 3353], "temperature": 0.0, "avg_logprob": -0.14308449427286785, "compression_ratio": 1.87984496124031, "no_speech_prob": 1.8162169226343394e-06}, {"id": 991, "seek": 466064, "start": 4667.6, "end": 4672.88, "text": " Okay, so that's great the other thing you'll notice about a to the power of something is because it's a power", "tokens": [1033, 11, 370, 300, 311, 869, 264, 661, 551, 291, 603, 3449, 466, 257, 281, 264, 1347, 295, 746, 307, 570, 309, 311, 257, 1347], "temperature": 0.0, "avg_logprob": -0.14308449427286785, "compression_ratio": 1.87984496124031, "no_speech_prob": 1.8162169226343394e-06}, {"id": 992, "seek": 466064, "start": 4674.92, "end": 4679.280000000001, "text": " Numbers that are slightly bigger than other numbers like 4 is a little bit bigger than 2.8", "tokens": [22592, 1616, 300, 366, 4748, 3801, 813, 661, 3547, 411, 1017, 307, 257, 707, 857, 3801, 813, 568, 13, 23], "temperature": 0.0, "avg_logprob": -0.14308449427286785, "compression_ratio": 1.87984496124031, "no_speech_prob": 1.8162169226343394e-06}, {"id": 993, "seek": 466064, "start": 4679.64, "end": 4683.12, "text": " When you go a to the power of it really accentuates that difference", "tokens": [1133, 291, 352, 257, 281, 264, 1347, 295, 309, 534, 11982, 27710, 300, 2649], "temperature": 0.0, "avg_logprob": -0.14308449427286785, "compression_ratio": 1.87984496124031, "no_speech_prob": 1.8162169226343394e-06}, {"id": 994, "seek": 466064, "start": 4683.4400000000005, "end": 4689.200000000001, "text": " Okay, so we're going to take advantage of both of these features for the purpose of deep learning okay, so we take our", "tokens": [1033, 11, 370, 321, 434, 516, 281, 747, 5002, 295, 1293, 295, 613, 4122, 337, 264, 4334, 295, 2452, 2539, 1392, 11, 370, 321, 747, 527], "temperature": 0.0, "avg_logprob": -0.14308449427286785, "compression_ratio": 1.87984496124031, "no_speech_prob": 1.8162169226343394e-06}, {"id": 995, "seek": 468920, "start": 4689.2, "end": 4690.8, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.2105427675468977, "compression_ratio": 1.8979591836734695, "no_speech_prob": 3.844916136586107e-06}, {"id": 996, "seek": 468920, "start": 4690.8, "end": 4696.12, "text": " Results of this fully connected layer we go a to the power of for each of them and", "tokens": [5015, 33361, 295, 341, 4498, 4582, 4583, 321, 352, 257, 281, 264, 1347, 295, 337, 1184, 295, 552, 293], "temperature": 0.0, "avg_logprob": -0.2105427675468977, "compression_ratio": 1.8979591836734695, "no_speech_prob": 3.844916136586107e-06}, {"id": 997, "seek": 468920, "start": 4697.44, "end": 4699.44, "text": " Then we're going to", "tokens": [1396, 321, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.2105427675468977, "compression_ratio": 1.8979591836734695, "no_speech_prob": 3.844916136586107e-06}, {"id": 998, "seek": 468920, "start": 4703.28, "end": 4705.28, "text": " And then we're going to add them up", "tokens": [400, 550, 321, 434, 516, 281, 909, 552, 493], "temperature": 0.0, "avg_logprob": -0.2105427675468977, "compression_ratio": 1.8979591836734695, "no_speech_prob": 3.844916136586107e-06}, {"id": 999, "seek": 468920, "start": 4706.639999999999, "end": 4709.5599999999995, "text": " Okay, so here is the sum of a to the power of", "tokens": [1033, 11, 370, 510, 307, 264, 2408, 295, 257, 281, 264, 1347, 295], "temperature": 0.0, "avg_logprob": -0.2105427675468977, "compression_ratio": 1.8979591836734695, "no_speech_prob": 3.844916136586107e-06}, {"id": 1000, "seek": 468920, "start": 4710.88, "end": 4712.84, "text": " so then here", "tokens": [370, 550, 510], "temperature": 0.0, "avg_logprob": -0.2105427675468977, "compression_ratio": 1.8979591836734695, "no_speech_prob": 3.844916136586107e-06}, {"id": 1001, "seek": 468920, "start": 4712.84, "end": 4717.96, "text": " We're going to take a to the power of divided by the sum of a to the power of", "tokens": [492, 434, 516, 281, 747, 257, 281, 264, 1347, 295, 6666, 538, 264, 2408, 295, 257, 281, 264, 1347, 295], "temperature": 0.0, "avg_logprob": -0.2105427675468977, "compression_ratio": 1.8979591836734695, "no_speech_prob": 3.844916136586107e-06}, {"id": 1002, "seek": 471796, "start": 4717.96, "end": 4719.96, "text": " so if you take", "tokens": [370, 498, 291, 747], "temperature": 0.0, "avg_logprob": -0.22339050769805907, "compression_ratio": 1.5858585858585859, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1003, "seek": 471796, "start": 4720.16, "end": 4727.4, "text": " All of these things divided by their sum then by definition all of those things must add up to one and", "tokens": [1057, 295, 613, 721, 6666, 538, 641, 2408, 550, 538, 7123, 439, 295, 729, 721, 1633, 909, 493, 281, 472, 293], "temperature": 0.0, "avg_logprob": -0.22339050769805907, "compression_ratio": 1.5858585858585859, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1004, "seek": 471796, "start": 4729.6, "end": 4732.12, "text": " Furthermore since we're dividing by their sum", "tokens": [23999, 1670, 321, 434, 26764, 538, 641, 2408], "temperature": 0.0, "avg_logprob": -0.22339050769805907, "compression_ratio": 1.5858585858585859, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1005, "seek": 471796, "start": 4732.84, "end": 4740.76, "text": " They must always vary between 0 and 1 because they are always positive alright, and that's it so that's what softmax is", "tokens": [814, 1633, 1009, 10559, 1296, 1958, 293, 502, 570, 436, 366, 1009, 3353, 5845, 11, 293, 300, 311, 309, 370, 300, 311, 437, 2787, 41167, 307], "temperature": 0.0, "avg_logprob": -0.22339050769805907, "compression_ratio": 1.5858585858585859, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1006, "seek": 471796, "start": 4743.4, "end": 4745.4, "text": " Okay, so I've got this kind of", "tokens": [1033, 11, 370, 286, 600, 658, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.22339050769805907, "compression_ratio": 1.5858585858585859, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1007, "seek": 474540, "start": 4745.4, "end": 4751.5199999999995, "text": " doing random numbers each time right and so you can see like as I as I look through", "tokens": [884, 4974, 3547, 1184, 565, 558, 293, 370, 291, 393, 536, 411, 382, 286, 382, 286, 574, 807], "temperature": 0.0, "avg_logprob": -0.17166386881182272, "compression_ratio": 1.6939655172413792, "no_speech_prob": 8.714324621905689e-07}, {"id": 1008, "seek": 474540, "start": 4752.24, "end": 4759.2, "text": " My softmax generally has quite a few things that are so close to zero that they round down to zero and you know", "tokens": [1222, 2787, 41167, 5101, 575, 1596, 257, 1326, 721, 300, 366, 370, 1998, 281, 4018, 300, 436, 3098, 760, 281, 4018, 293, 291, 458], "temperature": 0.0, "avg_logprob": -0.17166386881182272, "compression_ratio": 1.6939655172413792, "no_speech_prob": 8.714324621905689e-07}, {"id": 1009, "seek": 474540, "start": 4759.2, "end": 4765.32, "text": " Maybe one thing that's nearly one right and the reason for that is what we just talked about that is with the X", "tokens": [2704, 472, 551, 300, 311, 6217, 472, 558, 293, 264, 1778, 337, 300, 307, 437, 321, 445, 2825, 466, 300, 307, 365, 264, 1783], "temperature": 0.0, "avg_logprob": -0.17166386881182272, "compression_ratio": 1.6939655172413792, "no_speech_prob": 8.714324621905689e-07}, {"id": 1010, "seek": 474540, "start": 4765.879999999999, "end": 4771.0, "text": " Just having one number a bit bigger than the others tends to like push it out further", "tokens": [1449, 1419, 472, 1230, 257, 857, 3801, 813, 264, 2357, 12258, 281, 411, 2944, 309, 484, 3052], "temperature": 0.0, "avg_logprob": -0.17166386881182272, "compression_ratio": 1.6939655172413792, "no_speech_prob": 8.714324621905689e-07}, {"id": 1011, "seek": 477100, "start": 4771.0, "end": 4776.44, "text": " Right so even though my inputs here are random numbers between negative 5 and 5", "tokens": [1779, 370, 754, 1673, 452, 15743, 510, 366, 4974, 3547, 1296, 3671, 1025, 293, 1025], "temperature": 0.0, "avg_logprob": -0.16004301648621166, "compression_ratio": 1.771186440677966, "no_speech_prob": 5.285510837893526e-07}, {"id": 1012, "seek": 477100, "start": 4777.12, "end": 4782.48, "text": " Right my outputs from the softmax don't really look that random at all in the sense that", "tokens": [1779, 452, 23930, 490, 264, 2787, 41167, 500, 380, 534, 574, 300, 4974, 412, 439, 294, 264, 2020, 300], "temperature": 0.0, "avg_logprob": -0.16004301648621166, "compression_ratio": 1.771186440677966, "no_speech_prob": 5.285510837893526e-07}, {"id": 1013, "seek": 477100, "start": 4783.6, "end": 4787.64, "text": " They tend to have one big number and a bunch of small numbers", "tokens": [814, 3928, 281, 362, 472, 955, 1230, 293, 257, 3840, 295, 1359, 3547], "temperature": 0.0, "avg_logprob": -0.16004301648621166, "compression_ratio": 1.771186440677966, "no_speech_prob": 5.285510837893526e-07}, {"id": 1014, "seek": 477100, "start": 4789.28, "end": 4791.28, "text": " And now that's what we want", "tokens": [400, 586, 300, 311, 437, 321, 528], "temperature": 0.0, "avg_logprob": -0.16004301648621166, "compression_ratio": 1.771186440677966, "no_speech_prob": 5.285510837893526e-07}, {"id": 1015, "seek": 477100, "start": 4791.48, "end": 4796.24, "text": " Right we want to say like in terms of like is this a cat dog a plane a fish or a building", "tokens": [1779, 321, 528, 281, 584, 411, 294, 2115, 295, 411, 307, 341, 257, 3857, 3000, 257, 5720, 257, 3506, 420, 257, 2390], "temperature": 0.0, "avg_logprob": -0.16004301648621166, "compression_ratio": 1.771186440677966, "no_speech_prob": 5.285510837893526e-07}, {"id": 1016, "seek": 479624, "start": 4796.24, "end": 4804.16, "text": " We really wanted to say like it's it's that you know it's it's a dog or it's a plane not like I don't know", "tokens": [492, 534, 1415, 281, 584, 411, 309, 311, 309, 311, 300, 291, 458, 309, 311, 309, 311, 257, 3000, 420, 309, 311, 257, 5720, 406, 411, 286, 500, 380, 458], "temperature": 0.0, "avg_logprob": -0.19284410374138944, "compression_ratio": 1.6568627450980393, "no_speech_prob": 1.0845157021321938e-06}, {"id": 1017, "seek": 479624, "start": 4804.84, "end": 4807.92, "text": " Okay, so softmax has lots of these cool", "tokens": [1033, 11, 370, 2787, 41167, 575, 3195, 295, 613, 1627], "temperature": 0.0, "avg_logprob": -0.19284410374138944, "compression_ratio": 1.6568627450980393, "no_speech_prob": 1.0845157021321938e-06}, {"id": 1018, "seek": 479624, "start": 4808.84, "end": 4815.719999999999, "text": " Properties right it's going to return a probability that adds up to one and it's going to tend to want to pick one thing", "tokens": [27627, 6097, 558, 309, 311, 516, 281, 2736, 257, 8482, 300, 10860, 493, 281, 472, 293, 309, 311, 516, 281, 3928, 281, 528, 281, 1888, 472, 551], "temperature": 0.0, "avg_logprob": -0.19284410374138944, "compression_ratio": 1.6568627450980393, "no_speech_prob": 1.0845157021321938e-06}, {"id": 1019, "seek": 479624, "start": 4817.08, "end": 4818.92, "text": " particularly strongly", "tokens": [4098, 10613], "temperature": 0.0, "avg_logprob": -0.19284410374138944, "compression_ratio": 1.6568627450980393, "no_speech_prob": 1.0845157021321938e-06}, {"id": 1020, "seek": 481892, "start": 4818.92, "end": 4826.92, "text": " Okay, so that's softmax your net could you pass actually bust me up? We", "tokens": [1033, 11, 370, 300, 311, 2787, 41167, 428, 2533, 727, 291, 1320, 767, 19432, 385, 493, 30, 492], "temperature": 0.0, "avg_logprob": -0.27499876583323757, "compression_ratio": 1.54, "no_speech_prob": 3.3405208341719117e-06}, {"id": 1021, "seek": 481892, "start": 4827.4800000000005, "end": 4834.4, "text": " How would we do something that has let's say you have an image and you want to categorize as like cat and the dog or", "tokens": [1012, 576, 321, 360, 746, 300, 575, 718, 311, 584, 291, 362, 364, 3256, 293, 291, 528, 281, 19250, 1125, 382, 411, 3857, 293, 264, 3000, 420], "temperature": 0.0, "avg_logprob": -0.27499876583323757, "compression_ratio": 1.54, "no_speech_prob": 3.3405208341719117e-06}, {"id": 1022, "seek": 481892, "start": 4834.4, "end": 4836.0, "text": " Like has multiple things", "tokens": [1743, 575, 3866, 721], "temperature": 0.0, "avg_logprob": -0.27499876583323757, "compression_ratio": 1.54, "no_speech_prob": 3.3405208341719117e-06}, {"id": 1023, "seek": 481892, "start": 4836.0, "end": 4838.56, "text": " What what kind of function would we try to use?", "tokens": [708, 437, 733, 295, 2445, 576, 321, 853, 281, 764, 30], "temperature": 0.0, "avg_logprob": -0.27499876583323757, "compression_ratio": 1.54, "no_speech_prob": 3.3405208341719117e-06}, {"id": 1024, "seek": 481892, "start": 4839.36, "end": 4841.36, "text": " So happens we're going to do that right now", "tokens": [407, 2314, 321, 434, 516, 281, 360, 300, 558, 586], "temperature": 0.0, "avg_logprob": -0.27499876583323757, "compression_ratio": 1.54, "no_speech_prob": 3.3405208341719117e-06}, {"id": 1025, "seek": 481892, "start": 4841.8, "end": 4843.8, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.27499876583323757, "compression_ratio": 1.54, "no_speech_prob": 3.3405208341719117e-06}, {"id": 1026, "seek": 484380, "start": 4843.8, "end": 4850.08, "text": " So how to think about why we might want to do that and so one reason we might want to do that is to do", "tokens": [407, 577, 281, 519, 466, 983, 321, 1062, 528, 281, 360, 300, 293, 370, 472, 1778, 321, 1062, 528, 281, 360, 300, 307, 281, 360], "temperature": 0.0, "avg_logprob": -0.19680300260844982, "compression_ratio": 1.8904109589041096, "no_speech_prob": 8.990940614239662e-07}, {"id": 1027, "seek": 484380, "start": 4850.4400000000005, "end": 4855.24, "text": " multi-label cat classification, so we're looking now at less than two image models and", "tokens": [4825, 12, 75, 18657, 3857, 21538, 11, 370, 321, 434, 1237, 586, 412, 1570, 813, 732, 3256, 5245, 293], "temperature": 0.0, "avg_logprob": -0.19680300260844982, "compression_ratio": 1.8904109589041096, "no_speech_prob": 8.990940614239662e-07}, {"id": 1028, "seek": 484380, "start": 4855.92, "end": 4857.92, "text": " specifically we're going to take a look at the", "tokens": [4682, 321, 434, 516, 281, 747, 257, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.19680300260844982, "compression_ratio": 1.8904109589041096, "no_speech_prob": 8.990940614239662e-07}, {"id": 1029, "seek": 484380, "start": 4858.4800000000005, "end": 4861.320000000001, "text": " planet competition satellite imaging competition", "tokens": [5054, 6211, 16016, 25036, 6211], "temperature": 0.0, "avg_logprob": -0.19680300260844982, "compression_ratio": 1.8904109589041096, "no_speech_prob": 8.990940614239662e-07}, {"id": 1030, "seek": 484380, "start": 4863.08, "end": 4865.68, "text": " Now the satellite imaging competition has", "tokens": [823, 264, 16016, 25036, 6211, 575], "temperature": 0.0, "avg_logprob": -0.19680300260844982, "compression_ratio": 1.8904109589041096, "no_speech_prob": 8.990940614239662e-07}, {"id": 1031, "seek": 486568, "start": 4865.68, "end": 4875.68, "text": " Some similarities to stuff we've seen before right so before we've seen cat versus dog and these images are a cat or a dog", "tokens": [2188, 24197, 281, 1507, 321, 600, 1612, 949, 558, 370, 949, 321, 600, 1612, 3857, 5717, 3000, 293, 613, 5267, 366, 257, 3857, 420, 257, 3000], "temperature": 0.0, "avg_logprob": -0.19670759836832682, "compression_ratio": 1.724890829694323, "no_speech_prob": 1.3287725550981122e-06}, {"id": 1032, "seek": 486568, "start": 4876.400000000001, "end": 4881.900000000001, "text": " They're not neither. They're not both right, but the satellite imaging competition", "tokens": [814, 434, 406, 9662, 13, 814, 434, 406, 1293, 558, 11, 457, 264, 16016, 25036, 6211], "temperature": 0.0, "avg_logprob": -0.19670759836832682, "compression_ratio": 1.724890829694323, "no_speech_prob": 1.3287725550981122e-06}, {"id": 1033, "seek": 486568, "start": 4883.04, "end": 4889.64, "text": " Has stayed as images that look like this and in fact every single one of the images is classified by weather", "tokens": [8646, 9181, 382, 5267, 300, 574, 411, 341, 293, 294, 1186, 633, 2167, 472, 295, 264, 5267, 307, 20627, 538, 5503], "temperature": 0.0, "avg_logprob": -0.19670759836832682, "compression_ratio": 1.724890829694323, "no_speech_prob": 1.3287725550981122e-06}, {"id": 1034, "seek": 488964, "start": 4889.64, "end": 4895.56, "text": " There's four kinds of weather one of which is haze and another of which is clear in", "tokens": [821, 311, 1451, 3685, 295, 5503, 472, 295, 597, 307, 324, 1381, 293, 1071, 295, 597, 307, 1850, 294], "temperature": 0.0, "avg_logprob": -0.2088458412571957, "compression_ratio": 1.743455497382199, "no_speech_prob": 1.577957164045074e-06}, {"id": 1035, "seek": 488964, "start": 4896.360000000001, "end": 4901.92, "text": " Addition to which there is a list of features that may be present including agriculture", "tokens": [5349, 849, 281, 597, 456, 307, 257, 1329, 295, 4122, 300, 815, 312, 1974, 3009, 14837], "temperature": 0.0, "avg_logprob": -0.2088458412571957, "compression_ratio": 1.743455497382199, "no_speech_prob": 1.577957164045074e-06}, {"id": 1036, "seek": 488964, "start": 4901.96, "end": 4905.5, "text": " Which is like some some cleared area used for agriculture?", "tokens": [3013, 307, 411, 512, 512, 19725, 1859, 1143, 337, 14837, 30], "temperature": 0.0, "avg_logprob": -0.2088458412571957, "compression_ratio": 1.743455497382199, "no_speech_prob": 1.577957164045074e-06}, {"id": 1037, "seek": 488964, "start": 4906.280000000001, "end": 4913.76, "text": " Primary which means primary rainforest and water which means a river or a creek so here is a clear day", "tokens": [42576, 597, 1355, 6194, 48531, 293, 1281, 597, 1355, 257, 6810, 420, 257, 41868, 370, 510, 307, 257, 1850, 786], "temperature": 0.0, "avg_logprob": -0.2088458412571957, "compression_ratio": 1.743455497382199, "no_speech_prob": 1.577957164045074e-06}, {"id": 1038, "seek": 491376, "start": 4913.76, "end": 4920.280000000001, "text": " satellite image showing some agriculture some primary rainforest and some water features and", "tokens": [16016, 3256, 4099, 512, 14837, 512, 6194, 48531, 293, 512, 1281, 4122, 293], "temperature": 0.0, "avg_logprob": -0.1643545405069987, "compression_ratio": 1.6858638743455496, "no_speech_prob": 3.156122261316341e-07}, {"id": 1039, "seek": 491376, "start": 4920.4800000000005, "end": 4925.320000000001, "text": " Here's one which is in haze and is entirely primary rainforest", "tokens": [1692, 311, 472, 597, 307, 294, 324, 1381, 293, 307, 7696, 6194, 48531], "temperature": 0.0, "avg_logprob": -0.1643545405069987, "compression_ratio": 1.6858638743455496, "no_speech_prob": 3.156122261316341e-07}, {"id": 1040, "seek": 491376, "start": 4926.24, "end": 4930.280000000001, "text": " So in this case, we're going to want to be able to show", "tokens": [407, 294, 341, 1389, 11, 321, 434, 516, 281, 528, 281, 312, 1075, 281, 855], "temperature": 0.0, "avg_logprob": -0.1643545405069987, "compression_ratio": 1.6858638743455496, "no_speech_prob": 3.156122261316341e-07}, {"id": 1041, "seek": 491376, "start": 4931.400000000001, "end": 4937.64, "text": " We're going to be able to predict multiple things and so softmax wouldn't be good because softmax doesn't like", "tokens": [492, 434, 516, 281, 312, 1075, 281, 6069, 3866, 721, 293, 370, 2787, 41167, 2759, 380, 312, 665, 570, 2787, 41167, 1177, 380, 411], "temperature": 0.0, "avg_logprob": -0.1643545405069987, "compression_ratio": 1.6858638743455496, "no_speech_prob": 3.156122261316341e-07}, {"id": 1042, "seek": 493764, "start": 4937.64, "end": 4945.08, "text": " predicting multiple things and like I would definitely recommend anthropomorphizing your activation functions", "tokens": [32884, 3866, 721, 293, 411, 286, 576, 2138, 2748, 22727, 32702, 3319, 428, 24433, 6828], "temperature": 0.0, "avg_logprob": -0.2304173181223315, "compression_ratio": 1.646341463414634, "no_speech_prob": 1.3287749425217044e-06}, {"id": 1043, "seek": 493764, "start": 4945.160000000001, "end": 4951.8, "text": " Right they have personalities. Okay, and the personality of the softmax is it wants to pick a thing", "tokens": [1779, 436, 362, 25308, 13, 1033, 11, 293, 264, 9033, 295, 264, 2787, 41167, 307, 309, 2738, 281, 1888, 257, 551], "temperature": 0.0, "avg_logprob": -0.2304173181223315, "compression_ratio": 1.646341463414634, "no_speech_prob": 1.3287749425217044e-06}, {"id": 1044, "seek": 493764, "start": 4952.320000000001, "end": 4957.72, "text": " Okay, and people forget this all the time. I've seen many people even well regarded", "tokens": [1033, 11, 293, 561, 2870, 341, 439, 264, 565, 13, 286, 600, 1612, 867, 561, 754, 731, 26047], "temperature": 0.0, "avg_logprob": -0.2304173181223315, "compression_ratio": 1.646341463414634, "no_speech_prob": 1.3287749425217044e-06}, {"id": 1045, "seek": 493764, "start": 4958.360000000001, "end": 4960.52, "text": " researchers in famous academic papers", "tokens": [10309, 294, 4618, 7778, 10577], "temperature": 0.0, "avg_logprob": -0.2304173181223315, "compression_ratio": 1.646341463414634, "no_speech_prob": 1.3287749425217044e-06}, {"id": 1046, "seek": 493764, "start": 4961.8, "end": 4966.64, "text": " Using like softmax for multi-label classification it happens all the time", "tokens": [11142, 411, 2787, 41167, 337, 4825, 12, 75, 18657, 21538, 309, 2314, 439, 264, 565], "temperature": 0.0, "avg_logprob": -0.2304173181223315, "compression_ratio": 1.646341463414634, "no_speech_prob": 1.3287749425217044e-06}, {"id": 1047, "seek": 496664, "start": 4966.64, "end": 4968.160000000001, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.2289405663808187, "compression_ratio": 1.5151515151515151, "no_speech_prob": 2.4439843855361687e-06}, {"id": 1048, "seek": 496664, "start": 4968.160000000001, "end": 4970.88, "text": " And it's kind of ridiculous because they're not", "tokens": [400, 309, 311, 733, 295, 11083, 570, 436, 434, 406], "temperature": 0.0, "avg_logprob": -0.2289405663808187, "compression_ratio": 1.5151515151515151, "no_speech_prob": 2.4439843855361687e-06}, {"id": 1049, "seek": 496664, "start": 4971.8, "end": 4976.240000000001, "text": " understanding the personality of their activation function, so", "tokens": [3701, 264, 9033, 295, 641, 24433, 2445, 11, 370], "temperature": 0.0, "avg_logprob": -0.2289405663808187, "compression_ratio": 1.5151515151515151, "no_speech_prob": 2.4439843855361687e-06}, {"id": 1050, "seek": 496664, "start": 4977.12, "end": 4984.0, "text": " For multi-label classification where each sample can belong to one or more classes we have to change a few things", "tokens": [1171, 4825, 12, 75, 18657, 21538, 689, 1184, 6889, 393, 5784, 281, 472, 420, 544, 5359, 321, 362, 281, 1319, 257, 1326, 721], "temperature": 0.0, "avg_logprob": -0.2289405663808187, "compression_ratio": 1.5151515151515151, "no_speech_prob": 2.4439843855361687e-06}, {"id": 1051, "seek": 496664, "start": 4984.68, "end": 4988.8, "text": " But here's the good news in fast AI. We don't have to change anything", "tokens": [583, 510, 311, 264, 665, 2583, 294, 2370, 7318, 13, 492, 500, 380, 362, 281, 1319, 1340], "temperature": 0.0, "avg_logprob": -0.2289405663808187, "compression_ratio": 1.5151515151515151, "no_speech_prob": 2.4439843855361687e-06}, {"id": 1052, "seek": 498880, "start": 4988.8, "end": 4997.88, "text": " Right so fast AI will look at the labels in the CSP and if there is more than one label ever", "tokens": [1779, 370, 2370, 7318, 486, 574, 412, 264, 16949, 294, 264, 9460, 47, 293, 498, 456, 307, 544, 813, 472, 7645, 1562], "temperature": 0.0, "avg_logprob": -0.243184739893133, "compression_ratio": 1.507177033492823, "no_speech_prob": 3.866961151288706e-07}, {"id": 1053, "seek": 498880, "start": 4998.72, "end": 5000.72, "text": " for any", "tokens": [337, 604], "temperature": 0.0, "avg_logprob": -0.243184739893133, "compression_ratio": 1.507177033492823, "no_speech_prob": 3.866961151288706e-07}, {"id": 1054, "seek": 498880, "start": 5000.76, "end": 5004.72, "text": " Item it will automatically switch into like multi-label mode", "tokens": [31066, 309, 486, 6772, 3679, 666, 411, 4825, 12, 75, 18657, 4391], "temperature": 0.0, "avg_logprob": -0.243184739893133, "compression_ratio": 1.507177033492823, "no_speech_prob": 3.866961151288706e-07}, {"id": 1055, "seek": 498880, "start": 5004.72, "end": 5010.24, "text": " So I'm going to show you how it works behind the scenes, but the good news is you don't actually have to care", "tokens": [407, 286, 478, 516, 281, 855, 291, 577, 309, 1985, 2261, 264, 8026, 11, 457, 264, 665, 2583, 307, 291, 500, 380, 767, 362, 281, 1127], "temperature": 0.0, "avg_logprob": -0.243184739893133, "compression_ratio": 1.507177033492823, "no_speech_prob": 3.866961151288706e-07}, {"id": 1056, "seek": 498880, "start": 5010.24, "end": 5012.24, "text": " All right, it happens anyway", "tokens": [1057, 558, 11, 309, 2314, 4033], "temperature": 0.0, "avg_logprob": -0.243184739893133, "compression_ratio": 1.507177033492823, "no_speech_prob": 3.866961151288706e-07}, {"id": 1057, "seek": 498880, "start": 5012.6, "end": 5014.6, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.243184739893133, "compression_ratio": 1.507177033492823, "no_speech_prob": 3.866961151288706e-07}, {"id": 1058, "seek": 498880, "start": 5014.6, "end": 5016.6, "text": " if you have", "tokens": [498, 291, 362], "temperature": 0.0, "avg_logprob": -0.243184739893133, "compression_ratio": 1.507177033492823, "no_speech_prob": 3.866961151288706e-07}, {"id": 1059, "seek": 501660, "start": 5016.6, "end": 5018.6, "text": " multi-label", "tokens": [4825, 12, 75, 18657], "temperature": 0.0, "avg_logprob": -0.21766087883397153, "compression_ratio": 1.5526315789473684, "no_speech_prob": 2.6015927687694784e-06}, {"id": 1060, "seek": 501660, "start": 5019.320000000001, "end": 5026.88, "text": " Images multi-label objects you obviously can't use the classic keras style approach where things are in folders", "tokens": [4331, 1660, 4825, 12, 75, 18657, 6565, 291, 2745, 393, 380, 764, 264, 7230, 350, 6985, 3758, 3109, 689, 721, 366, 294, 31082], "temperature": 0.0, "avg_logprob": -0.21766087883397153, "compression_ratio": 1.5526315789473684, "no_speech_prob": 2.6015927687694784e-06}, {"id": 1061, "seek": 501660, "start": 5027.4400000000005, "end": 5032.400000000001, "text": " Because something can't conveniently be in multiple folders at the same time", "tokens": [1436, 746, 393, 380, 44375, 312, 294, 3866, 31082, 412, 264, 912, 565], "temperature": 0.0, "avg_logprob": -0.21766087883397153, "compression_ratio": 1.5526315789473684, "no_speech_prob": 2.6015927687694784e-06}, {"id": 1062, "seek": 501660, "start": 5033.160000000001, "end": 5037.320000000001, "text": " right, so that's why we you basically have to use the", "tokens": [558, 11, 370, 300, 311, 983, 321, 291, 1936, 362, 281, 764, 264], "temperature": 0.0, "avg_logprob": -0.21766087883397153, "compression_ratio": 1.5526315789473684, "no_speech_prob": 2.6015927687694784e-06}, {"id": 1063, "seek": 501660, "start": 5038.04, "end": 5040.04, "text": " from CSV", "tokens": [490, 48814], "temperature": 0.0, "avg_logprob": -0.21766087883397153, "compression_ratio": 1.5526315789473684, "no_speech_prob": 2.6015927687694784e-06}, {"id": 1064, "seek": 504004, "start": 5040.04, "end": 5048.04, "text": " The approach right so if we look at an example", "tokens": [440, 3109, 558, 370, 498, 321, 574, 412, 364, 1365], "temperature": 0.0, "avg_logprob": -0.2517389466490927, "compression_ratio": 1.4950980392156863, "no_speech_prob": 7.002151392043743e-07}, {"id": 1065, "seek": 504004, "start": 5051.08, "end": 5054.88, "text": " Actually, I'll show you I tend to take you through it right so we can say okay", "tokens": [5135, 11, 286, 603, 855, 291, 286, 3928, 281, 747, 291, 807, 309, 558, 370, 321, 393, 584, 1392], "temperature": 0.0, "avg_logprob": -0.2517389466490927, "compression_ratio": 1.4950980392156863, "no_speech_prob": 7.002151392043743e-07}, {"id": 1066, "seek": 504004, "start": 5054.88, "end": 5062.14, "text": " This is the CSV file containing our labels this looks exactly the same as it did before but rather than side on it's top-down", "tokens": [639, 307, 264, 48814, 3991, 19273, 527, 16949, 341, 1542, 2293, 264, 912, 382, 309, 630, 949, 457, 2831, 813, 1252, 322, 309, 311, 1192, 12, 5093], "temperature": 0.0, "avg_logprob": -0.2517389466490927, "compression_ratio": 1.4950980392156863, "no_speech_prob": 7.002151392043743e-07}, {"id": 1067, "seek": 504004, "start": 5063.0, "end": 5065.86, "text": " Right and top-down. I've mentioned before that can do", "tokens": [1779, 293, 1192, 12, 5093, 13, 286, 600, 2835, 949, 300, 393, 360], "temperature": 0.0, "avg_logprob": -0.2517389466490927, "compression_ratio": 1.4950980392156863, "no_speech_prob": 7.002151392043743e-07}, {"id": 1068, "seek": 506586, "start": 5065.86, "end": 5071.58, "text": " a vertical flips it actually does more than that there's actually eight possible symmetries for a square", "tokens": [257, 9429, 40249, 309, 767, 775, 544, 813, 300, 456, 311, 767, 3180, 1944, 14232, 302, 2244, 337, 257, 3732], "temperature": 0.0, "avg_logprob": -0.1938568364794009, "compression_ratio": 1.624031007751938, "no_speech_prob": 4.936951881973073e-06}, {"id": 1069, "seek": 506586, "start": 5071.66, "end": 5073.66, "text": " Which is it can be rotated through?", "tokens": [3013, 307, 309, 393, 312, 42146, 807, 30], "temperature": 0.0, "avg_logprob": -0.1938568364794009, "compression_ratio": 1.624031007751938, "no_speech_prob": 4.936951881973073e-06}, {"id": 1070, "seek": 506586, "start": 5073.7, "end": 5080.099999999999, "text": " 90 180 270 or zero degrees and for each of those it can be flipped and if you think about it for a while", "tokens": [4289, 11971, 40774, 420, 4018, 5310, 293, 337, 1184, 295, 729, 309, 393, 312, 26273, 293, 498, 291, 519, 466, 309, 337, 257, 1339], "temperature": 0.0, "avg_logprob": -0.1938568364794009, "compression_ratio": 1.624031007751938, "no_speech_prob": 4.936951881973073e-06}, {"id": 1071, "seek": 506586, "start": 5080.219999999999, "end": 5082.66, "text": " You'll realize that that's a complete", "tokens": [509, 603, 4325, 300, 300, 311, 257, 3566], "temperature": 0.0, "avg_logprob": -0.1938568364794009, "compression_ratio": 1.624031007751938, "no_speech_prob": 4.936951881973073e-06}, {"id": 1072, "seek": 506586, "start": 5083.5, "end": 5085.639999999999, "text": " Enumeration of everything that you can do", "tokens": [2193, 449, 5053, 295, 1203, 300, 291, 393, 360], "temperature": 0.0, "avg_logprob": -0.1938568364794009, "compression_ratio": 1.624031007751938, "no_speech_prob": 4.936951881973073e-06}, {"id": 1073, "seek": 506586, "start": 5086.339999999999, "end": 5092.46, "text": " In terms of symmetries to a square so they're called. It's called the dihedral group of eight", "tokens": [682, 2115, 295, 14232, 302, 2244, 281, 257, 3732, 370, 436, 434, 1219, 13, 467, 311, 1219, 264, 1026, 71, 24764, 1594, 295, 3180], "temperature": 0.0, "avg_logprob": -0.1938568364794009, "compression_ratio": 1.624031007751938, "no_speech_prob": 4.936951881973073e-06}, {"id": 1074, "seek": 509246, "start": 5092.46, "end": 5097.9800000000005, "text": " So if you see in the code, there's actually a transform called dihedral. That's why it's called that", "tokens": [407, 498, 291, 536, 294, 264, 3089, 11, 456, 311, 767, 257, 4088, 1219, 1026, 71, 24764, 13, 663, 311, 983, 309, 311, 1219, 300], "temperature": 0.0, "avg_logprob": -0.21813073409231085, "compression_ratio": 1.6307053941908713, "no_speech_prob": 2.4060952910076594e-06}, {"id": 1075, "seek": 509246, "start": 5099.14, "end": 5103.34, "text": " So this transforms will basically do the full set of eight symmetric", "tokens": [407, 341, 35592, 486, 1936, 360, 264, 1577, 992, 295, 3180, 32330], "temperature": 0.0, "avg_logprob": -0.21813073409231085, "compression_ratio": 1.6307053941908713, "no_speech_prob": 2.4060952910076594e-06}, {"id": 1076, "seek": 509246, "start": 5104.54, "end": 5106.18, "text": " dihedral", "tokens": [1026, 71, 24764], "temperature": 0.0, "avg_logprob": -0.21813073409231085, "compression_ratio": 1.6307053941908713, "no_speech_prob": 2.4060952910076594e-06}, {"id": 1077, "seek": 509246, "start": 5106.18, "end": 5108.18, "text": " rotations and flips", "tokens": [44796, 293, 40249], "temperature": 0.0, "avg_logprob": -0.21813073409231085, "compression_ratio": 1.6307053941908713, "no_speech_prob": 2.4060952910076594e-06}, {"id": 1078, "seek": 509246, "start": 5108.18, "end": 5114.94, "text": " Plus everything which we can do to dogs and cats you know small 10 degree rotations a little bit of zooming", "tokens": [7721, 1203, 597, 321, 393, 360, 281, 7197, 293, 11111, 291, 458, 1359, 1266, 4314, 44796, 257, 707, 857, 295, 48226], "temperature": 0.0, "avg_logprob": -0.21813073409231085, "compression_ratio": 1.6307053941908713, "no_speech_prob": 2.4060952910076594e-06}, {"id": 1079, "seek": 509246, "start": 5115.58, "end": 5117.7, "text": " Little bit of contrast and brightness adjustment", "tokens": [8022, 857, 295, 8712, 293, 21367, 17132], "temperature": 0.0, "avg_logprob": -0.21813073409231085, "compression_ratio": 1.6307053941908713, "no_speech_prob": 2.4060952910076594e-06}, {"id": 1080, "seek": 511770, "start": 5117.7, "end": 5125.78, "text": " So these images are a size 256 by 256, so I just created a little function here to let me quickly grab", "tokens": [407, 613, 5267, 366, 257, 2744, 38882, 538, 38882, 11, 370, 286, 445, 2942, 257, 707, 2445, 510, 281, 718, 385, 2661, 4444], "temperature": 0.0, "avg_logprob": -0.24440100698760062, "compression_ratio": 1.5778688524590163, "no_speech_prob": 2.3320637865253957e-06}, {"id": 1081, "seek": 511770, "start": 5125.94, "end": 5131.0599999999995, "text": " You know a data loader of any size, so here's a 256 by 256", "tokens": [509, 458, 257, 1412, 3677, 260, 295, 604, 2744, 11, 370, 510, 311, 257, 38882, 538, 38882], "temperature": 0.0, "avg_logprob": -0.24440100698760062, "compression_ratio": 1.5778688524590163, "no_speech_prob": 2.3320637865253957e-06}, {"id": 1082, "seek": 511770, "start": 5131.94, "end": 5134.66, "text": " Once you've got a data object", "tokens": [3443, 291, 600, 658, 257, 1412, 2657], "temperature": 0.0, "avg_logprob": -0.24440100698760062, "compression_ratio": 1.5778688524590163, "no_speech_prob": 2.3320637865253957e-06}, {"id": 1083, "seek": 511770, "start": 5135.3, "end": 5141.04, "text": " Inside it we've already seen that there's things called Val DS test DS train DS", "tokens": [15123, 309, 321, 600, 1217, 1612, 300, 456, 311, 721, 1219, 7188, 15816, 1500, 15816, 3847, 15816], "temperature": 0.0, "avg_logprob": -0.24440100698760062, "compression_ratio": 1.5778688524590163, "no_speech_prob": 2.3320637865253957e-06}, {"id": 1084, "seek": 511770, "start": 5141.04, "end": 5146.62, "text": " They're things that you can just index into and grab a particular image, so you can just use square brackets zero", "tokens": [814, 434, 721, 300, 291, 393, 445, 8186, 666, 293, 4444, 257, 1729, 3256, 11, 370, 291, 393, 445, 764, 3732, 26179, 4018], "temperature": 0.0, "avg_logprob": -0.24440100698760062, "compression_ratio": 1.5778688524590163, "no_speech_prob": 2.3320637865253957e-06}, {"id": 1085, "seek": 514662, "start": 5146.62, "end": 5150.98, "text": " You'll also see that all of those things have a DL. That's a data loader", "tokens": [509, 603, 611, 536, 300, 439, 295, 729, 721, 362, 257, 413, 43, 13, 663, 311, 257, 1412, 3677, 260], "temperature": 0.0, "avg_logprob": -0.19658895639272836, "compression_ratio": 1.8744394618834082, "no_speech_prob": 4.785070359503152e-06}, {"id": 1086, "seek": 514662, "start": 5150.98, "end": 5155.7, "text": " So DS is data set DL is data loader these are concepts from pytorch", "tokens": [407, 15816, 307, 1412, 992, 413, 43, 307, 1412, 3677, 260, 613, 366, 10392, 490, 25878, 284, 339], "temperature": 0.0, "avg_logprob": -0.19658895639272836, "compression_ratio": 1.8744394618834082, "no_speech_prob": 4.785070359503152e-06}, {"id": 1087, "seek": 514662, "start": 5155.98, "end": 5161.42, "text": " So if you google pytorch data set or pytorch data loader you can basically see what it means", "tokens": [407, 498, 291, 20742, 25878, 284, 339, 1412, 992, 420, 25878, 284, 339, 1412, 3677, 260, 291, 393, 1936, 536, 437, 309, 1355], "temperature": 0.0, "avg_logprob": -0.19658895639272836, "compression_ratio": 1.8744394618834082, "no_speech_prob": 4.785070359503152e-06}, {"id": 1088, "seek": 514662, "start": 5161.58, "end": 5166.9, "text": " But the basic idea is a data set gives you a single image or a single", "tokens": [583, 264, 3875, 1558, 307, 257, 1412, 992, 2709, 291, 257, 2167, 3256, 420, 257, 2167], "temperature": 0.0, "avg_logprob": -0.19658895639272836, "compression_ratio": 1.8744394618834082, "no_speech_prob": 4.785070359503152e-06}, {"id": 1089, "seek": 514662, "start": 5167.38, "end": 5170.66, "text": " object back at data loader gives you back a mini-batch and", "tokens": [2657, 646, 412, 1412, 3677, 260, 2709, 291, 646, 257, 8382, 12, 65, 852, 293], "temperature": 0.0, "avg_logprob": -0.19658895639272836, "compression_ratio": 1.8744394618834082, "no_speech_prob": 4.785070359503152e-06}, {"id": 1090, "seek": 514662, "start": 5171.86, "end": 5174.16, "text": " Specifically it gives you back a transformed mini-batch", "tokens": [26058, 309, 2709, 291, 646, 257, 16894, 8382, 12, 65, 852], "temperature": 0.0, "avg_logprob": -0.19658895639272836, "compression_ratio": 1.8744394618834082, "no_speech_prob": 4.785070359503152e-06}, {"id": 1091, "seek": 517416, "start": 5174.16, "end": 5181.5599999999995, "text": " so that's why when we create our data object we can pass in num workers and", "tokens": [370, 300, 311, 983, 562, 321, 1884, 527, 1412, 2657, 321, 393, 1320, 294, 1031, 5600, 293], "temperature": 0.0, "avg_logprob": -0.23425409631821717, "compression_ratio": 1.7533632286995515, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1092, "seek": 517416, "start": 5182.5199999999995, "end": 5188.8, "text": " Transforms like how many processes do you want to use what transforms do you want and so with a data loader?", "tokens": [27938, 82, 411, 577, 867, 7555, 360, 291, 528, 281, 764, 437, 35592, 360, 291, 528, 293, 370, 365, 257, 1412, 3677, 260, 30], "temperature": 0.0, "avg_logprob": -0.23425409631821717, "compression_ratio": 1.7533632286995515, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1093, "seek": 517416, "start": 5188.96, "end": 5191.34, "text": " You can't ask for an individual image", "tokens": [509, 393, 380, 1029, 337, 364, 2609, 3256], "temperature": 0.0, "avg_logprob": -0.23425409631821717, "compression_ratio": 1.7533632286995515, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1094, "seek": 517416, "start": 5191.34, "end": 5196.18, "text": " You can only get back at a mini-batch and you can't get that back a particular mini-batch", "tokens": [509, 393, 787, 483, 646, 412, 257, 8382, 12, 65, 852, 293, 291, 393, 380, 483, 300, 646, 257, 1729, 8382, 12, 65, 852], "temperature": 0.0, "avg_logprob": -0.23425409631821717, "compression_ratio": 1.7533632286995515, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1095, "seek": 517416, "start": 5196.2, "end": 5201.5599999999995, "text": " You can only get back the next mini-batch so something we risk is loop through", "tokens": [509, 393, 787, 483, 646, 264, 958, 8382, 12, 65, 852, 370, 746, 321, 3148, 307, 6367, 807], "temperature": 0.0, "avg_logprob": -0.23425409631821717, "compression_ratio": 1.7533632286995515, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1096, "seek": 520156, "start": 5201.56, "end": 5205.4800000000005, "text": " grabbing a mini-batch at a time and so in Python", "tokens": [23771, 257, 8382, 12, 65, 852, 412, 257, 565, 293, 370, 294, 15329], "temperature": 0.0, "avg_logprob": -0.20965942314692906, "compression_ratio": 1.9053497942386832, "no_speech_prob": 1.628048380553082e-06}, {"id": 1097, "seek": 520156, "start": 5206.080000000001, "end": 5208.400000000001, "text": " The thing that does that is called a generator", "tokens": [440, 551, 300, 775, 300, 307, 1219, 257, 19265], "temperature": 0.0, "avg_logprob": -0.20965942314692906, "compression_ratio": 1.9053497942386832, "no_speech_prob": 1.628048380553082e-06}, {"id": 1098, "seek": 520156, "start": 5208.84, "end": 5212.3, "text": " Right or an iterator there's slightly different versions of the same thing", "tokens": [1779, 420, 364, 17138, 1639, 456, 311, 4748, 819, 9606, 295, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.20965942314692906, "compression_ratio": 1.9053497942386832, "no_speech_prob": 1.628048380553082e-06}, {"id": 1099, "seek": 520156, "start": 5212.4800000000005, "end": 5217.400000000001, "text": " So to turn a data loader into an iterator you use the standard Python function called itta", "tokens": [407, 281, 1261, 257, 1412, 3677, 260, 666, 364, 17138, 1639, 291, 764, 264, 3832, 15329, 2445, 1219, 309, 1328], "temperature": 0.0, "avg_logprob": -0.20965942314692906, "compression_ratio": 1.9053497942386832, "no_speech_prob": 1.628048380553082e-06}, {"id": 1100, "seek": 520156, "start": 5217.6, "end": 5220.88, "text": " That's a Python function just a regular part of the Python", "tokens": [663, 311, 257, 15329, 2445, 445, 257, 3890, 644, 295, 264, 15329], "temperature": 0.0, "avg_logprob": -0.20965942314692906, "compression_ratio": 1.9053497942386832, "no_speech_prob": 1.628048380553082e-06}, {"id": 1101, "seek": 520156, "start": 5221.160000000001, "end": 5228.96, "text": " Basic language that returns to an iterator and an iterator is something that takes you can pass the static give pass it to the standard", "tokens": [31598, 2856, 300, 11247, 281, 364, 17138, 1639, 293, 364, 17138, 1639, 307, 746, 300, 2516, 291, 393, 1320, 264, 13437, 976, 1320, 309, 281, 264, 3832], "temperature": 0.0, "avg_logprob": -0.20965942314692906, "compression_ratio": 1.9053497942386832, "no_speech_prob": 1.628048380553082e-06}, {"id": 1102, "seek": 520156, "start": 5229.320000000001, "end": 5231.120000000001, "text": " Python", "tokens": [15329], "temperature": 0.0, "avg_logprob": -0.20965942314692906, "compression_ratio": 1.9053497942386832, "no_speech_prob": 1.628048380553082e-06}, {"id": 1103, "seek": 523112, "start": 5231.12, "end": 5237.32, "text": " Function or statement next and that just says give me another batch from this iterator", "tokens": [11166, 882, 420, 5629, 958, 293, 300, 445, 1619, 976, 385, 1071, 15245, 490, 341, 17138, 1639], "temperature": 0.0, "avg_logprob": -0.1863929510116577, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.6841951239475748e-06}, {"id": 1104, "seek": 523112, "start": 5239.32, "end": 5244.24, "text": " So we're basically this is one of the things I really like about pytorch is it really leverages", "tokens": [407, 321, 434, 1936, 341, 307, 472, 295, 264, 721, 286, 534, 411, 466, 25878, 284, 339, 307, 309, 534, 12451, 1660], "temperature": 0.0, "avg_logprob": -0.1863929510116577, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.6841951239475748e-06}, {"id": 1105, "seek": 523112, "start": 5245.16, "end": 5253.4, "text": " Modern pythons kind of stuff you know in in tensorflow they invent their whole new world of ways of doing things", "tokens": [19814, 10664, 392, 892, 733, 295, 1507, 291, 458, 294, 294, 40863, 10565, 436, 7962, 641, 1379, 777, 1002, 295, 2098, 295, 884, 721], "temperature": 0.0, "avg_logprob": -0.1863929510116577, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.6841951239475748e-06}, {"id": 1106, "seek": 523112, "start": 5254.76, "end": 5256.76, "text": " And so it's kind of more", "tokens": [400, 370, 309, 311, 733, 295, 544], "temperature": 0.0, "avg_logprob": -0.1863929510116577, "compression_ratio": 1.5533980582524272, "no_speech_prob": 2.6841951239475748e-06}, {"id": 1107, "seek": 525676, "start": 5256.76, "end": 5262.88, "text": " In a sense it's more like cross-platform, but in another sense like it's not a good fit to any platform", "tokens": [682, 257, 2020, 309, 311, 544, 411, 3278, 12, 39975, 837, 11, 457, 294, 1071, 2020, 411, 309, 311, 406, 257, 665, 3318, 281, 604, 3663], "temperature": 0.0, "avg_logprob": -0.20029346073899312, "compression_ratio": 1.8468468468468469, "no_speech_prob": 1.5056959909998113e-06}, {"id": 1108, "seek": 525676, "start": 5263.12, "end": 5267.320000000001, "text": " So it's nice if you if you know Python well", "tokens": [407, 309, 311, 1481, 498, 291, 498, 291, 458, 15329, 731], "temperature": 0.0, "avg_logprob": -0.20029346073899312, "compression_ratio": 1.8468468468468469, "no_speech_prob": 1.5056959909998113e-06}, {"id": 1109, "seek": 525676, "start": 5267.88, "end": 5274.8, "text": " PyTorch comes very naturally if you don't know Python well PyTorch is a good reason to learn Python well a", "tokens": [9953, 51, 284, 339, 1487, 588, 8195, 498, 291, 500, 380, 458, 15329, 731, 9953, 51, 284, 339, 307, 257, 665, 1778, 281, 1466, 15329, 731, 257], "temperature": 0.0, "avg_logprob": -0.20029346073899312, "compression_ratio": 1.8468468468468469, "no_speech_prob": 1.5056959909998113e-06}, {"id": 1110, "seek": 525676, "start": 5275.96, "end": 5282.24, "text": " PyTorch near a module neural network module is a standard Python bus for example", "tokens": [9953, 51, 284, 339, 2651, 257, 10088, 18161, 3209, 10088, 307, 257, 3832, 15329, 1255, 337, 1365], "temperature": 0.0, "avg_logprob": -0.20029346073899312, "compression_ratio": 1.8468468468468469, "no_speech_prob": 1.5056959909998113e-06}, {"id": 1111, "seek": 528224, "start": 5282.24, "end": 5288.76, "text": " So any work you put into learning Python better will pay off with PyTorch so here. I am using standard", "tokens": [407, 604, 589, 291, 829, 666, 2539, 15329, 1101, 486, 1689, 766, 365, 9953, 51, 284, 339, 370, 510, 13, 286, 669, 1228, 3832], "temperature": 0.0, "avg_logprob": -0.1885072267972506, "compression_ratio": 1.8070175438596492, "no_speech_prob": 5.203557407185144e-07}, {"id": 1112, "seek": 528224, "start": 5289.4, "end": 5290.5599999999995, "text": " Python", "tokens": [15329], "temperature": 0.0, "avg_logprob": -0.1885072267972506, "compression_ratio": 1.8070175438596492, "no_speech_prob": 5.203557407185144e-07}, {"id": 1113, "seek": 528224, "start": 5290.5599999999995, "end": 5294.4, "text": " iterators and next to grab my next mini batch", "tokens": [17138, 3391, 293, 958, 281, 4444, 452, 958, 8382, 15245], "temperature": 0.0, "avg_logprob": -0.1885072267972506, "compression_ratio": 1.8070175438596492, "no_speech_prob": 5.203557407185144e-07}, {"id": 1114, "seek": 528224, "start": 5295.04, "end": 5298.76, "text": " From the validation sets data loader, and that's going to return two things", "tokens": [3358, 264, 24071, 6352, 1412, 3677, 260, 11, 293, 300, 311, 516, 281, 2736, 732, 721], "temperature": 0.0, "avg_logprob": -0.1885072267972506, "compression_ratio": 1.8070175438596492, "no_speech_prob": 5.203557407185144e-07}, {"id": 1115, "seek": 528224, "start": 5298.76, "end": 5302.639999999999, "text": " It's going to return the images in the mini batch and the labels in the mini batch", "tokens": [467, 311, 516, 281, 2736, 264, 5267, 294, 264, 8382, 15245, 293, 264, 16949, 294, 264, 8382, 15245], "temperature": 0.0, "avg_logprob": -0.1885072267972506, "compression_ratio": 1.8070175438596492, "no_speech_prob": 5.203557407185144e-07}, {"id": 1116, "seek": 528224, "start": 5302.8, "end": 5308.8, "text": " So standard Python approach I can pull them apart like so and so here is", "tokens": [407, 3832, 15329, 3109, 286, 393, 2235, 552, 4936, 411, 370, 293, 370, 510, 307], "temperature": 0.0, "avg_logprob": -0.1885072267972506, "compression_ratio": 1.8070175438596492, "no_speech_prob": 5.203557407185144e-07}, {"id": 1117, "seek": 530880, "start": 5308.8, "end": 5315.28, "text": " one mini batch of labels and so not surprisingly since I said that my batch size", "tokens": [472, 8382, 15245, 295, 16949, 293, 370, 406, 17600, 1670, 286, 848, 300, 452, 15245, 2744], "temperature": 0.0, "avg_logprob": -0.21717284785376656, "compression_ratio": 1.6242774566473988, "no_speech_prob": 6.144123290141579e-06}, {"id": 1118, "seek": 530880, "start": 5321.88, "end": 5328.28, "text": " Oh actually, it's the batch size by default is 64, so I didn't pass in a batch size", "tokens": [876, 767, 11, 309, 311, 264, 15245, 2744, 538, 7576, 307, 12145, 11, 370, 286, 994, 380, 1320, 294, 257, 15245, 2744], "temperature": 0.0, "avg_logprob": -0.21717284785376656, "compression_ratio": 1.6242774566473988, "no_speech_prob": 6.144123290141579e-06}, {"id": 1119, "seek": 530880, "start": 5328.28, "end": 5334.92, "text": " And so just remember shift tab to see like what are the things you can pass and what are the defaults so by default?", "tokens": [400, 370, 445, 1604, 5513, 4421, 281, 536, 411, 437, 366, 264, 721, 291, 393, 1320, 293, 437, 366, 264, 7576, 82, 370, 538, 7576, 30], "temperature": 0.0, "avg_logprob": -0.21717284785376656, "compression_ratio": 1.6242774566473988, "no_speech_prob": 6.144123290141579e-06}, {"id": 1120, "seek": 533492, "start": 5334.92, "end": 5339.72, "text": " My batch size is 64, so I've got back something of size 64 by", "tokens": [1222, 15245, 2744, 307, 12145, 11, 370, 286, 600, 658, 646, 746, 295, 2744, 12145, 538], "temperature": 0.0, "avg_logprob": -0.2818952178955078, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.0261368263163604e-06}, {"id": 1121, "seek": 533492, "start": 5340.4, "end": 5343.08, "text": " 17 so there are 17 of the possible", "tokens": [3282, 370, 456, 366, 3282, 295, 264, 1944], "temperature": 0.0, "avg_logprob": -0.2818952178955078, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.0261368263163604e-06}, {"id": 1122, "seek": 533492, "start": 5343.96, "end": 5345.96, "text": " classes right", "tokens": [5359, 558], "temperature": 0.0, "avg_logprob": -0.2818952178955078, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.0261368263163604e-06}, {"id": 1123, "seek": 533492, "start": 5346.56, "end": 5349.52, "text": " So let's take a look at the", "tokens": [407, 718, 311, 747, 257, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.2818952178955078, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.0261368263163604e-06}, {"id": 1124, "seek": 533492, "start": 5350.4800000000005, "end": 5351.88, "text": " zeroes", "tokens": [4018, 279], "temperature": 0.0, "avg_logprob": -0.2818952178955078, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.0261368263163604e-06}, {"id": 1125, "seek": 533492, "start": 5351.88, "end": 5354.4800000000005, "text": " Set of labels so the zeroes images labels", "tokens": [8928, 295, 16949, 370, 264, 4018, 279, 5267, 16949], "temperature": 0.0, "avg_logprob": -0.2818952178955078, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.0261368263163604e-06}, {"id": 1126, "seek": 533492, "start": 5355.32, "end": 5360.68, "text": " So I can zip again standard Python things it takes two lists and combines", "tokens": [407, 286, 393, 20730, 797, 3832, 15329, 721, 309, 2516, 732, 14511, 293, 29520], "temperature": 0.0, "avg_logprob": -0.2818952178955078, "compression_ratio": 1.4662921348314606, "no_speech_prob": 2.0261368263163604e-06}, {"id": 1127, "seek": 536068, "start": 5360.68, "end": 5364.96, "text": " It's they get the zero thing from the first list the zero thing from the second list", "tokens": [467, 311, 436, 483, 264, 4018, 551, 490, 264, 700, 1329, 264, 4018, 551, 490, 264, 1150, 1329], "temperature": 0.0, "avg_logprob": -0.2709341145525075, "compression_ratio": 1.8888888888888888, "no_speech_prob": 3.6688370528281666e-06}, {"id": 1128, "seek": 536068, "start": 5364.96, "end": 5369.46, "text": " And the first thing from the first first this first thing from the second list and so forth", "tokens": [400, 264, 700, 551, 490, 264, 700, 700, 341, 700, 551, 490, 264, 1150, 1329, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.2709341145525075, "compression_ratio": 1.8888888888888888, "no_speech_prob": 3.6688370528281666e-06}, {"id": 1129, "seek": 536068, "start": 5369.56, "end": 5372.64, "text": " So I can zip them together and that way I can find out", "tokens": [407, 286, 393, 20730, 552, 1214, 293, 300, 636, 286, 393, 915, 484], "temperature": 0.0, "avg_logprob": -0.2709341145525075, "compression_ratio": 1.8888888888888888, "no_speech_prob": 3.6688370528281666e-06}, {"id": 1130, "seek": 536068, "start": 5373.16, "end": 5377.76, "text": " For the zero image in the validation set its agriculture", "tokens": [1171, 264, 4018, 3256, 294, 264, 24071, 992, 1080, 14837], "temperature": 0.0, "avg_logprob": -0.2709341145525075, "compression_ratio": 1.8888888888888888, "no_speech_prob": 3.6688370528281666e-06}, {"id": 1131, "seek": 536068, "start": 5378.200000000001, "end": 5380.04, "text": " It's clear", "tokens": [467, 311, 1850], "temperature": 0.0, "avg_logprob": -0.2709341145525075, "compression_ratio": 1.8888888888888888, "no_speech_prob": 3.6688370528281666e-06}, {"id": 1132, "seek": 536068, "start": 5380.04, "end": 5384.6, "text": " Its primary rainforest its slash and burn its water", "tokens": [6953, 6194, 48531, 1080, 17330, 293, 5064, 1080, 1281], "temperature": 0.0, "avg_logprob": -0.2709341145525075, "compression_ratio": 1.8888888888888888, "no_speech_prob": 3.6688370528281666e-06}, {"id": 1133, "seek": 536068, "start": 5385.34, "end": 5389.08, "text": " Okay, so as you can see here. This is a", "tokens": [1033, 11, 370, 382, 291, 393, 536, 510, 13, 639, 307, 257], "temperature": 0.0, "avg_logprob": -0.2709341145525075, "compression_ratio": 1.8888888888888888, "no_speech_prob": 3.6688370528281666e-06}, {"id": 1134, "seek": 538908, "start": 5389.08, "end": 5391.08, "text": " multi-label", "tokens": [4825, 12, 75, 18657], "temperature": 0.0, "avg_logprob": -0.2447628066653297, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.482473746567848e-06}, {"id": 1135, "seek": 538908, "start": 5391.4, "end": 5394.16, "text": " You see here's a way to do multi-label classification", "tokens": [509, 536, 510, 311, 257, 636, 281, 360, 4825, 12, 75, 18657, 21538], "temperature": 0.0, "avg_logprob": -0.2447628066653297, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.482473746567848e-06}, {"id": 1136, "seek": 538908, "start": 5395.24, "end": 5402.0, "text": " So by the same token right if we go back to our single label classification", "tokens": [407, 538, 264, 912, 14862, 558, 498, 321, 352, 646, 281, 527, 2167, 7645, 21538], "temperature": 0.0, "avg_logprob": -0.2447628066653297, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.482473746567848e-06}, {"id": 1137, "seek": 538908, "start": 5402.0, "end": 5404.0, "text": " It's a cat dog playing fish or building", "tokens": [467, 311, 257, 3857, 3000, 2433, 3506, 420, 2390], "temperature": 0.0, "avg_logprob": -0.2447628066653297, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.482473746567848e-06}, {"id": 1138, "seek": 538908, "start": 5405.08, "end": 5409.1, "text": " Behind the scenes we haven't actually looked at it, but behind the scenes", "tokens": [20475, 264, 8026, 321, 2378, 380, 767, 2956, 412, 309, 11, 457, 2261, 264, 8026], "temperature": 0.0, "avg_logprob": -0.2447628066653297, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.482473746567848e-06}, {"id": 1139, "seek": 538908, "start": 5410.5199999999995, "end": 5416.0, "text": " Fast AI and pie torch are turning our labels into something called one hot", "tokens": [15968, 7318, 293, 1730, 27822, 366, 6246, 527, 16949, 666, 746, 1219, 472, 2368], "temperature": 0.0, "avg_logprob": -0.2447628066653297, "compression_ratio": 1.625615763546798, "no_speech_prob": 2.482473746567848e-06}, {"id": 1140, "seek": 541600, "start": 5416.0, "end": 5421.44, "text": " Encoded labels and so if it was actually a dog then the actual values", "tokens": [29584, 12340, 16949, 293, 370, 498, 309, 390, 767, 257, 3000, 550, 264, 3539, 4190], "temperature": 0.0, "avg_logprob": -0.19547101563098385, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.6536851035198197e-06}, {"id": 1141, "seek": 541600, "start": 5423.44, "end": 5426.8, "text": " Would be like that right so these are like the actuals", "tokens": [6068, 312, 411, 300, 558, 370, 613, 366, 411, 264, 3539, 82], "temperature": 0.0, "avg_logprob": -0.19547101563098385, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.6536851035198197e-06}, {"id": 1142, "seek": 541600, "start": 5428.0, "end": 5431.84, "text": " Okay, so do you remember at the very end of a Tavio's video?", "tokens": [1033, 11, 370, 360, 291, 1604, 412, 264, 588, 917, 295, 257, 314, 706, 1004, 311, 960, 30], "temperature": 0.0, "avg_logprob": -0.19547101563098385, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.6536851035198197e-06}, {"id": 1143, "seek": 541600, "start": 5431.84, "end": 5437.68, "text": " He showed how like the template had to match to one of the like five a b c d or e templates", "tokens": [634, 4712, 577, 411, 264, 12379, 632, 281, 2995, 281, 472, 295, 264, 411, 1732, 257, 272, 269, 274, 420, 308, 21165], "temperature": 0.0, "avg_logprob": -0.19547101563098385, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.6536851035198197e-06}, {"id": 1144, "seek": 541600, "start": 5437.68, "end": 5441.44, "text": " And so what it's actually doing is it's comparing", "tokens": [400, 370, 437, 309, 311, 767, 884, 307, 309, 311, 15763], "temperature": 0.0, "avg_logprob": -0.19547101563098385, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.6536851035198197e-06}, {"id": 1145, "seek": 541600, "start": 5442.0, "end": 5444.32, "text": " When I said it's basically doing a dot product", "tokens": [1133, 286, 848, 309, 311, 1936, 884, 257, 5893, 1674], "temperature": 0.0, "avg_logprob": -0.19547101563098385, "compression_ratio": 1.6696428571428572, "no_speech_prob": 1.6536851035198197e-06}, {"id": 1146, "seek": 544432, "start": 5444.32, "end": 5448.5199999999995, "text": " it's actually a fully connected layer at the end right that calculates an", "tokens": [309, 311, 767, 257, 4498, 4582, 4583, 412, 264, 917, 558, 300, 4322, 1024, 364], "temperature": 0.0, "avg_logprob": -0.21039579332489328, "compression_ratio": 1.811659192825112, "no_speech_prob": 1.0348516070735059e-06}, {"id": 1147, "seek": 544432, "start": 5449.5599999999995, "end": 5455.88, "text": " output activation that goes through a soft max and then the soft max is compared to", "tokens": [5598, 24433, 300, 1709, 807, 257, 2787, 11469, 293, 550, 264, 2787, 11469, 307, 5347, 281], "temperature": 0.0, "avg_logprob": -0.21039579332489328, "compression_ratio": 1.811659192825112, "no_speech_prob": 1.0348516070735059e-06}, {"id": 1148, "seek": 544432, "start": 5456.48, "end": 5462.0, "text": " The one hot encoded label right so if it was a dog there would be a one here", "tokens": [440, 472, 2368, 2058, 12340, 7645, 558, 370, 498, 309, 390, 257, 3000, 456, 576, 312, 257, 472, 510], "temperature": 0.0, "avg_logprob": -0.21039579332489328, "compression_ratio": 1.811659192825112, "no_speech_prob": 1.0348516070735059e-06}, {"id": 1149, "seek": 544432, "start": 5462.0, "end": 5463.04, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.21039579332489328, "compression_ratio": 1.811659192825112, "no_speech_prob": 1.0348516070735059e-06}, {"id": 1150, "seek": 544432, "start": 5463.04, "end": 5467.5599999999995, "text": " Then we take the difference between the actuals and the soft max", "tokens": [1396, 321, 747, 264, 2649, 1296, 264, 3539, 82, 293, 264, 2787, 11469], "temperature": 0.0, "avg_logprob": -0.21039579332489328, "compression_ratio": 1.811659192825112, "no_speech_prob": 1.0348516070735059e-06}, {"id": 1151, "seek": 544432, "start": 5467.799999999999, "end": 5473.32, "text": " Activations to say and add those add up those differences to say how much error is there essentially", "tokens": [28550, 763, 281, 584, 293, 909, 729, 909, 493, 729, 7300, 281, 584, 577, 709, 6713, 307, 456, 4476], "temperature": 0.0, "avg_logprob": -0.21039579332489328, "compression_ratio": 1.811659192825112, "no_speech_prob": 1.0348516070735059e-06}, {"id": 1152, "seek": 547332, "start": 5473.32, "end": 5479.299999999999, "text": " And we're skipping over something called a loss function that we'll learn about next week, but essentially we're basically doing that", "tokens": [400, 321, 434, 31533, 670, 746, 1219, 257, 4470, 2445, 300, 321, 603, 1466, 466, 958, 1243, 11, 457, 4476, 321, 434, 1936, 884, 300], "temperature": 0.0, "avg_logprob": -0.19553681307060775, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.5779594377818285e-06}, {"id": 1153, "seek": 547332, "start": 5481.5599999999995, "end": 5487.639999999999, "text": " Now if it's one hot encoded like there's only one thing which have a one in it", "tokens": [823, 498, 309, 311, 472, 2368, 2058, 12340, 411, 456, 311, 787, 472, 551, 597, 362, 257, 472, 294, 309], "temperature": 0.0, "avg_logprob": -0.19553681307060775, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.5779594377818285e-06}, {"id": 1154, "seek": 547332, "start": 5487.759999999999, "end": 5491.84, "text": " then actually storing it as 0 1 0 0 0 is", "tokens": [550, 767, 26085, 309, 382, 1958, 502, 1958, 1958, 1958, 307], "temperature": 0.0, "avg_logprob": -0.19553681307060775, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.5779594377818285e-06}, {"id": 1155, "seek": 547332, "start": 5492.96, "end": 5494.799999999999, "text": " terribly inefficient", "tokens": [22903, 43495], "temperature": 0.0, "avg_logprob": -0.19553681307060775, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.5779594377818285e-06}, {"id": 1156, "seek": 547332, "start": 5494.799999999999, "end": 5498.599999999999, "text": " Right like we could basically say what are the index of each of these things?", "tokens": [1779, 411, 321, 727, 1936, 584, 437, 366, 264, 8186, 295, 1184, 295, 613, 721, 30], "temperature": 0.0, "avg_logprob": -0.19553681307060775, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.5779594377818285e-06}, {"id": 1157, "seek": 549860, "start": 5498.6, "end": 5502.64, "text": " Right so we can say it's like 0 1 2 3 4", "tokens": [1779, 370, 321, 393, 584, 309, 311, 411, 1958, 502, 568, 805, 1017], "temperature": 0.0, "avg_logprob": -0.1982206923238347, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.7880603309095022e-06}, {"id": 1158, "seek": 549860, "start": 5503.320000000001, "end": 5508.320000000001, "text": " Like so right and so rather than storing it as 0 1 0 0 0", "tokens": [1743, 370, 558, 293, 370, 2831, 813, 26085, 309, 382, 1958, 502, 1958, 1958, 1958], "temperature": 0.0, "avg_logprob": -0.1982206923238347, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.7880603309095022e-06}, {"id": 1159, "seek": 549860, "start": 5509.04, "end": 5512.400000000001, "text": " We actually just store the index value", "tokens": [492, 767, 445, 3531, 264, 8186, 2158], "temperature": 0.0, "avg_logprob": -0.1982206923238347, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.7880603309095022e-06}, {"id": 1160, "seek": 549860, "start": 5512.88, "end": 5520.120000000001, "text": " Right so if you look at the the y values for the cats and dogs competition or the dog breeds competition", "tokens": [1779, 370, 498, 291, 574, 412, 264, 264, 288, 4190, 337, 264, 11111, 293, 7197, 6211, 420, 264, 3000, 41609, 6211], "temperature": 0.0, "avg_logprob": -0.1982206923238347, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.7880603309095022e-06}, {"id": 1161, "seek": 549860, "start": 5520.400000000001, "end": 5525.360000000001, "text": " You won't actually see a big lists of ones and zeros like this. You'll see a single integer", "tokens": [509, 1582, 380, 767, 536, 257, 955, 14511, 295, 2306, 293, 35193, 411, 341, 13, 509, 603, 536, 257, 2167, 24922], "temperature": 0.0, "avg_logprob": -0.1982206923238347, "compression_ratio": 1.6274509803921569, "no_speech_prob": 1.7880603309095022e-06}, {"id": 1162, "seek": 552536, "start": 5525.36, "end": 5530.88, "text": " Right which is like what's what class index is it right and internally?", "tokens": [1779, 597, 307, 411, 437, 311, 437, 1508, 8186, 307, 309, 558, 293, 19501, 30], "temperature": 0.0, "avg_logprob": -0.23682771682739256, "compression_ratio": 1.75, "no_speech_prob": 3.0115933213892276e-07}, {"id": 1163, "seek": 552536, "start": 5532.2, "end": 5539.32, "text": " Inside PyTorch it will actually turn that into a one hot encoded vector, but like you will literally never see it", "tokens": [15123, 9953, 51, 284, 339, 309, 486, 767, 1261, 300, 666, 257, 472, 2368, 2058, 12340, 8062, 11, 457, 411, 291, 486, 3736, 1128, 536, 309], "temperature": 0.0, "avg_logprob": -0.23682771682739256, "compression_ratio": 1.75, "no_speech_prob": 3.0115933213892276e-07}, {"id": 1164, "seek": 552536, "start": 5539.839999999999, "end": 5546.62, "text": " Okay, and and PyTorch has different loss functions where you basically say this thing's one", "tokens": [1033, 11, 293, 293, 9953, 51, 284, 339, 575, 819, 4470, 6828, 689, 291, 1936, 584, 341, 551, 311, 472], "temperature": 0.0, "avg_logprob": -0.23682771682739256, "compression_ratio": 1.75, "no_speech_prob": 3.0115933213892276e-07}, {"id": 1165, "seek": 552536, "start": 5546.639999999999, "end": 5551.4, "text": " This thing is one hot encoded or this thing is not and it uses different boss functions", "tokens": [639, 551, 307, 472, 2368, 2058, 12340, 420, 341, 551, 307, 406, 293, 309, 4960, 819, 5741, 6828], "temperature": 0.0, "avg_logprob": -0.23682771682739256, "compression_ratio": 1.75, "no_speech_prob": 3.0115933213892276e-07}, {"id": 1166, "seek": 552536, "start": 5552.32, "end": 5554.719999999999, "text": " That's all hidden by the fast AI library", "tokens": [663, 311, 439, 7633, 538, 264, 2370, 7318, 6405], "temperature": 0.0, "avg_logprob": -0.23682771682739256, "compression_ratio": 1.75, "no_speech_prob": 3.0115933213892276e-07}, {"id": 1167, "seek": 555472, "start": 5554.72, "end": 5557.240000000001, "text": " Right so like you don't have to worry about it", "tokens": [1779, 370, 411, 291, 500, 380, 362, 281, 3292, 466, 309], "temperature": 0.0, "avg_logprob": -0.19382191881721403, "compression_ratio": 1.5852534562211982, "no_speech_prob": 9.422428206562472e-07}, {"id": 1168, "seek": 555472, "start": 5557.96, "end": 5565.92, "text": " But it's but the the cool thing to realize is that this approach for multi-label encoding with these ones and zeros", "tokens": [583, 309, 311, 457, 264, 264, 1627, 551, 281, 4325, 307, 300, 341, 3109, 337, 4825, 12, 75, 18657, 43430, 365, 613, 2306, 293, 35193], "temperature": 0.0, "avg_logprob": -0.19382191881721403, "compression_ratio": 1.5852534562211982, "no_speech_prob": 9.422428206562472e-07}, {"id": 1169, "seek": 555472, "start": 5566.8, "end": 5571.76, "text": " Behind the scenes the exact same thing happens for single level classification", "tokens": [20475, 264, 8026, 264, 1900, 912, 551, 2314, 337, 2167, 1496, 21538], "temperature": 0.0, "avg_logprob": -0.19382191881721403, "compression_ratio": 1.5852534562211982, "no_speech_prob": 9.422428206562472e-07}, {"id": 1170, "seek": 555472, "start": 5574.76, "end": 5581.12, "text": " Does it make sense to change the peakiness of the sigmoid of the softmax function by changing the base", "tokens": [4402, 309, 652, 2020, 281, 1319, 264, 10651, 1324, 295, 264, 4556, 3280, 327, 295, 264, 2787, 41167, 2445, 538, 4473, 264, 3096], "temperature": 0.0, "avg_logprob": -0.19382191881721403, "compression_ratio": 1.5852534562211982, "no_speech_prob": 9.422428206562472e-07}, {"id": 1171, "seek": 558112, "start": 5581.12, "end": 5582.96, "text": " um", "tokens": [1105], "temperature": 0.0, "avg_logprob": -0.32911359502914106, "compression_ratio": 1.2641509433962264, "no_speech_prob": 9.132521654464654e-07}, {"id": 1172, "seek": 558112, "start": 5582.96, "end": 5585.92, "text": " No, because when you change the", "tokens": [883, 11, 570, 562, 291, 1319, 264], "temperature": 0.0, "avg_logprob": -0.32911359502914106, "compression_ratio": 1.2641509433962264, "no_speech_prob": 9.132521654464654e-07}, {"id": 1173, "seek": 558112, "start": 5587.44, "end": 5589.44, "text": " more math", "tokens": [544, 5221], "temperature": 0.0, "avg_logprob": -0.32911359502914106, "compression_ratio": 1.2641509433962264, "no_speech_prob": 9.132521654464654e-07}, {"id": 1174, "seek": 558112, "start": 5591.96, "end": 5595.5599999999995, "text": " Log base a of B equals", "tokens": [10824, 3096, 257, 295, 363, 6915], "temperature": 0.0, "avg_logprob": -0.32911359502914106, "compression_ratio": 1.2641509433962264, "no_speech_prob": 9.132521654464654e-07}, {"id": 1175, "seek": 558112, "start": 5597.08, "end": 5599.08, "text": " log B over", "tokens": [3565, 363, 670], "temperature": 0.0, "avg_logprob": -0.32911359502914106, "compression_ratio": 1.2641509433962264, "no_speech_prob": 9.132521654464654e-07}, {"id": 1176, "seek": 558112, "start": 5599.96, "end": 5601.96, "text": " log a", "tokens": [3565, 257], "temperature": 0.0, "avg_logprob": -0.32911359502914106, "compression_ratio": 1.2641509433962264, "no_speech_prob": 9.132521654464654e-07}, {"id": 1177, "seek": 558112, "start": 5602.12, "end": 5605.24, "text": " so changing the base is just a linear scaling and", "tokens": [370, 4473, 264, 3096, 307, 445, 257, 8213, 21589, 293], "temperature": 0.0, "avg_logprob": -0.32911359502914106, "compression_ratio": 1.2641509433962264, "no_speech_prob": 9.132521654464654e-07}, {"id": 1178, "seek": 560524, "start": 5605.24, "end": 5611.08, "text": " Linear scaling is something which the neural net can learn with that very easily", "tokens": [14670, 289, 21589, 307, 746, 597, 264, 18161, 2533, 393, 1466, 365, 300, 588, 3612], "temperature": 0.0, "avg_logprob": -0.16876529511951266, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.933349039973109e-06}, {"id": 1179, "seek": 560524, "start": 5615.96, "end": 5617.96, "text": " Good question", "tokens": [2205, 1168], "temperature": 0.0, "avg_logprob": -0.16876529511951266, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.933349039973109e-06}, {"id": 1180, "seek": 560524, "start": 5619.92, "end": 5626.48, "text": " Okay, so here is that image right here is the image with slash and burn water etc etc", "tokens": [1033, 11, 370, 510, 307, 300, 3256, 558, 510, 307, 264, 3256, 365, 17330, 293, 5064, 1281, 5183, 5183], "temperature": 0.0, "avg_logprob": -0.16876529511951266, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.933349039973109e-06}, {"id": 1181, "seek": 560524, "start": 5627.2, "end": 5631.639999999999, "text": " One of the things to notice here is like when I first displayed this image it was", "tokens": [1485, 295, 264, 721, 281, 3449, 510, 307, 411, 562, 286, 700, 16372, 341, 3256, 309, 390], "temperature": 0.0, "avg_logprob": -0.16876529511951266, "compression_ratio": 1.5595238095238095, "no_speech_prob": 1.933349039973109e-06}, {"id": 1182, "seek": 563164, "start": 5631.64, "end": 5633.64, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.16382308233351933, "compression_ratio": 1.8181818181818181, "no_speech_prob": 1.4367456060426775e-06}, {"id": 1183, "seek": 563164, "start": 5634.0, "end": 5638.72, "text": " Washed out I really couldn't see it right but remember images", "tokens": [343, 12219, 484, 286, 534, 2809, 380, 536, 309, 558, 457, 1604, 5267], "temperature": 0.0, "avg_logprob": -0.16382308233351933, "compression_ratio": 1.8181818181818181, "no_speech_prob": 1.4367456060426775e-06}, {"id": 1184, "seek": 563164, "start": 5639.4800000000005, "end": 5641.56, "text": " Now you know we know images are just", "tokens": [823, 291, 458, 321, 458, 5267, 366, 445], "temperature": 0.0, "avg_logprob": -0.16382308233351933, "compression_ratio": 1.8181818181818181, "no_speech_prob": 1.4367456060426775e-06}, {"id": 1185, "seek": 563164, "start": 5642.320000000001, "end": 5646.320000000001, "text": " Matrices of numbers and so you can see here. I just said times 1.4", "tokens": [6789, 24373, 295, 3547, 293, 370, 291, 393, 536, 510, 13, 286, 445, 848, 1413, 502, 13, 19], "temperature": 0.0, "avg_logprob": -0.16382308233351933, "compression_ratio": 1.8181818181818181, "no_speech_prob": 1.4367456060426775e-06}, {"id": 1186, "seek": 563164, "start": 5647.0, "end": 5652.52, "text": " Just to make it more visible right so like now that you're kind of it's the kind of thing", "tokens": [1449, 281, 652, 309, 544, 8974, 558, 370, 411, 586, 300, 291, 434, 733, 295, 309, 311, 264, 733, 295, 551], "temperature": 0.0, "avg_logprob": -0.16382308233351933, "compression_ratio": 1.8181818181818181, "no_speech_prob": 1.4367456060426775e-06}, {"id": 1187, "seek": 563164, "start": 5652.52, "end": 5657.280000000001, "text": " I want you to get familiar with is the idea that this stuff you're dealing with they're just matrices of numbers", "tokens": [286, 528, 291, 281, 483, 4963, 365, 307, 264, 1558, 300, 341, 1507, 291, 434, 6260, 365, 436, 434, 445, 32284, 295, 3547], "temperature": 0.0, "avg_logprob": -0.16382308233351933, "compression_ratio": 1.8181818181818181, "no_speech_prob": 1.4367456060426775e-06}, {"id": 1188, "seek": 563164, "start": 5657.4400000000005, "end": 5661.52, "text": " Then you can fiddle around with them so if you're looking at something you're like oh, it's a bit washed out", "tokens": [1396, 291, 393, 24553, 2285, 926, 365, 552, 370, 498, 291, 434, 1237, 412, 746, 291, 434, 411, 1954, 11, 309, 311, 257, 857, 16300, 484], "temperature": 0.0, "avg_logprob": -0.16382308233351933, "compression_ratio": 1.8181818181818181, "no_speech_prob": 1.4367456060426775e-06}, {"id": 1189, "seek": 566152, "start": 5661.52, "end": 5663.52, "text": " You can just multiply it by something to", "tokens": [509, 393, 445, 12972, 309, 538, 746, 281], "temperature": 0.0, "avg_logprob": -0.19195802395160383, "compression_ratio": 1.6, "no_speech_prob": 4.289310254534939e-06}, {"id": 1190, "seek": 566152, "start": 5664.320000000001, "end": 5668.8, "text": " Brighten it up a bit. Okay, so here we can see I guess this is the slash and burn", "tokens": [24271, 268, 309, 493, 257, 857, 13, 1033, 11, 370, 510, 321, 393, 536, 286, 2041, 341, 307, 264, 17330, 293, 5064], "temperature": 0.0, "avg_logprob": -0.19195802395160383, "compression_ratio": 1.6, "no_speech_prob": 4.289310254534939e-06}, {"id": 1191, "seek": 566152, "start": 5669.280000000001, "end": 5676.68, "text": " Here's the river. That's the water. Here's the primary rainforest. Maybe that's the agriculture and so forth. Okay, so", "tokens": [1692, 311, 264, 6810, 13, 663, 311, 264, 1281, 13, 1692, 311, 264, 6194, 48531, 13, 2704, 300, 311, 264, 14837, 293, 370, 5220, 13, 1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.19195802395160383, "compression_ratio": 1.6, "no_speech_prob": 4.289310254534939e-06}, {"id": 1192, "seek": 566152, "start": 5679.0, "end": 5681.4400000000005, "text": " So, you know with all that background", "tokens": [407, 11, 291, 458, 365, 439, 300, 3678], "temperature": 0.0, "avg_logprob": -0.19195802395160383, "compression_ratio": 1.6, "no_speech_prob": 4.289310254534939e-06}, {"id": 1193, "seek": 566152, "start": 5682.320000000001, "end": 5684.320000000001, "text": " How do we actually use this?", "tokens": [1012, 360, 321, 767, 764, 341, 30], "temperature": 0.0, "avg_logprob": -0.19195802395160383, "compression_ratio": 1.6, "no_speech_prob": 4.289310254534939e-06}, {"id": 1194, "seek": 566152, "start": 5684.88, "end": 5689.8, "text": " Exactly the same way as everything we've done before right so you know size and and", "tokens": [7587, 264, 912, 636, 382, 1203, 321, 600, 1096, 949, 558, 370, 291, 458, 2744, 293, 293], "temperature": 0.0, "avg_logprob": -0.19195802395160383, "compression_ratio": 1.6, "no_speech_prob": 4.289310254534939e-06}, {"id": 1195, "seek": 568980, "start": 5689.8, "end": 5698.6, "text": " The interesting thing about playing around with this planet competition is that these images are not at all like image net and I", "tokens": [440, 1880, 551, 466, 2433, 926, 365, 341, 5054, 6211, 307, 300, 613, 5267, 366, 406, 412, 439, 411, 3256, 2533, 293, 286], "temperature": 0.0, "avg_logprob": -0.22673457942596853, "compression_ratio": 1.7421052631578948, "no_speech_prob": 2.857304252756876e-06}, {"id": 1196, "seek": 568980, "start": 5699.4800000000005, "end": 5703.6, "text": " Would guess that the vast majority of the stuff that the vast majority of you do", "tokens": [6068, 2041, 300, 264, 8369, 6286, 295, 264, 1507, 300, 264, 8369, 6286, 295, 291, 360], "temperature": 0.0, "avg_logprob": -0.22673457942596853, "compression_ratio": 1.7421052631578948, "no_speech_prob": 2.857304252756876e-06}, {"id": 1197, "seek": 568980, "start": 5704.56, "end": 5706.56, "text": " involving convolutional neural nets", "tokens": [17030, 45216, 304, 18161, 36170], "temperature": 0.0, "avg_logprob": -0.22673457942596853, "compression_ratio": 1.7421052631578948, "no_speech_prob": 2.857304252756876e-06}, {"id": 1198, "seek": 568980, "start": 5707.0, "end": 5713.12, "text": " Won't actually be anything like image net, you know it'll be it'll be medical imaging", "tokens": [14710, 380, 767, 312, 1340, 411, 3256, 2533, 11, 291, 458, 309, 603, 312, 309, 603, 312, 4625, 25036], "temperature": 0.0, "avg_logprob": -0.22673457942596853, "compression_ratio": 1.7421052631578948, "no_speech_prob": 2.857304252756876e-06}, {"id": 1199, "seek": 571312, "start": 5713.12, "end": 5721.76, "text": " or it'll be like classifying different kinds of steel tube or figuring out whether a world you know is going to break or not or", "tokens": [420, 309, 603, 312, 411, 1508, 5489, 819, 3685, 295, 8269, 9917, 420, 15213, 484, 1968, 257, 1002, 291, 458, 307, 516, 281, 1821, 420, 406, 420], "temperature": 0.0, "avg_logprob": -0.202336940359562, "compression_ratio": 1.5611814345991561, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1200, "seek": 571312, "start": 5722.88, "end": 5727.16, "text": " Looking at satellite images or you know, whatever, right? So", "tokens": [11053, 412, 16016, 5267, 420, 291, 458, 11, 2035, 11, 558, 30, 407], "temperature": 0.0, "avg_logprob": -0.202336940359562, "compression_ratio": 1.5611814345991561, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1201, "seek": 571312, "start": 5729.16, "end": 5732.72, "text": " It's it's good to experiment with stuff like this planet", "tokens": [467, 311, 309, 311, 665, 281, 5120, 365, 1507, 411, 341, 5054], "temperature": 0.0, "avg_logprob": -0.202336940359562, "compression_ratio": 1.5611814345991561, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1202, "seek": 571312, "start": 5733.24, "end": 5737.5199999999995, "text": " Competition to get a sense of kind of what you want to do and so you'll see here", "tokens": [43634, 281, 483, 257, 2020, 295, 733, 295, 437, 291, 528, 281, 360, 293, 370, 291, 603, 536, 510], "temperature": 0.0, "avg_logprob": -0.202336940359562, "compression_ratio": 1.5611814345991561, "no_speech_prob": 1.2679240626312094e-06}, {"id": 1203, "seek": 573752, "start": 5737.52, "end": 5745.280000000001, "text": " I start out by resizing my data to 64 by 64 it starts out at 256 by 256", "tokens": [286, 722, 484, 538, 725, 3319, 452, 1412, 281, 12145, 538, 12145, 309, 3719, 484, 412, 38882, 538, 38882], "temperature": 0.0, "avg_logprob": -0.18895570755004884, "compression_ratio": 1.722466960352423, "no_speech_prob": 2.9480054308805848e-06}, {"id": 1204, "seek": 573752, "start": 5745.280000000001, "end": 5751.120000000001, "text": " Right now I wouldn't want to do this for the cats and dogs competition because the cats and dogs competition", "tokens": [1779, 586, 286, 2759, 380, 528, 281, 360, 341, 337, 264, 11111, 293, 7197, 6211, 570, 264, 11111, 293, 7197, 6211], "temperature": 0.0, "avg_logprob": -0.18895570755004884, "compression_ratio": 1.722466960352423, "no_speech_prob": 2.9480054308805848e-06}, {"id": 1205, "seek": 573752, "start": 5751.400000000001, "end": 5757.4400000000005, "text": " We start with a pre-trained image net network. It's it's nearly it's it starts off nearly perfect", "tokens": [492, 722, 365, 257, 659, 12, 17227, 2001, 3256, 2533, 3209, 13, 467, 311, 309, 311, 6217, 309, 311, 309, 3719, 766, 6217, 2176], "temperature": 0.0, "avg_logprob": -0.18895570755004884, "compression_ratio": 1.722466960352423, "no_speech_prob": 2.9480054308805848e-06}, {"id": 1206, "seek": 573752, "start": 5757.92, "end": 5763.84, "text": " Right, so if we resized everything to 64 by 64 and then retrained the whole set", "tokens": [1779, 11, 370, 498, 321, 725, 1602, 1203, 281, 12145, 538, 12145, 293, 550, 1533, 31774, 264, 1379, 992], "temperature": 0.0, "avg_logprob": -0.18895570755004884, "compression_ratio": 1.722466960352423, "no_speech_prob": 2.9480054308805848e-06}, {"id": 1207, "seek": 573752, "start": 5764.4800000000005, "end": 5766.4800000000005, "text": " We basically destroy the weights", "tokens": [492, 1936, 5293, 264, 17443], "temperature": 0.0, "avg_logprob": -0.18895570755004884, "compression_ratio": 1.722466960352423, "no_speech_prob": 2.9480054308805848e-06}, {"id": 1208, "seek": 576648, "start": 5766.48, "end": 5768.879999999999, "text": " That are already pre trained to be very good", "tokens": [663, 366, 1217, 659, 8895, 281, 312, 588, 665], "temperature": 0.0, "avg_logprob": -0.2012077442650656, "compression_ratio": 1.711111111111111, "no_speech_prob": 4.157349394517951e-06}, {"id": 1209, "seek": 576648, "start": 5769.36, "end": 5774.44, "text": " remember image net most image net models are trained at either 224 by 224 or", "tokens": [1604, 3256, 2533, 881, 3256, 2533, 5245, 366, 8895, 412, 2139, 5853, 19, 538, 5853, 19, 420], "temperature": 0.0, "avg_logprob": -0.2012077442650656, "compression_ratio": 1.711111111111111, "no_speech_prob": 4.157349394517951e-06}, {"id": 1210, "seek": 576648, "start": 5775.12, "end": 5782.879999999999, "text": " 299 by 299 right? So if we like retrain them at 64 by 64, we're gonna we're gonna kill it on the other hand", "tokens": [568, 8494, 538, 568, 8494, 558, 30, 407, 498, 321, 411, 1533, 7146, 552, 412, 12145, 538, 12145, 11, 321, 434, 799, 321, 434, 799, 1961, 309, 322, 264, 661, 1011], "temperature": 0.0, "avg_logprob": -0.2012077442650656, "compression_ratio": 1.711111111111111, "no_speech_prob": 4.157349394517951e-06}, {"id": 1211, "seek": 576648, "start": 5784.0, "end": 5786.54, "text": " There's nothing in image net that looks at anything like this", "tokens": [821, 311, 1825, 294, 3256, 2533, 300, 1542, 412, 1340, 411, 341], "temperature": 0.0, "avg_logprob": -0.2012077442650656, "compression_ratio": 1.711111111111111, "no_speech_prob": 4.157349394517951e-06}, {"id": 1212, "seek": 576648, "start": 5787.24, "end": 5789.24, "text": " You know, there's no satellite images", "tokens": [509, 458, 11, 456, 311, 572, 16016, 5267], "temperature": 0.0, "avg_logprob": -0.2012077442650656, "compression_ratio": 1.711111111111111, "no_speech_prob": 4.157349394517951e-06}, {"id": 1213, "seek": 576648, "start": 5789.599999999999, "end": 5794.44, "text": " So the only useful bits of the image net network for us", "tokens": [407, 264, 787, 4420, 9239, 295, 264, 3256, 2533, 3209, 337, 505], "temperature": 0.0, "avg_logprob": -0.2012077442650656, "compression_ratio": 1.711111111111111, "no_speech_prob": 4.157349394517951e-06}, {"id": 1214, "seek": 579444, "start": 5794.44, "end": 5796.44, "text": " are kind of", "tokens": [366, 733, 295], "temperature": 0.0, "avg_logprob": -0.2322634659804307, "compression_ratio": 1.6702127659574468, "no_speech_prob": 1.370953555124288e-06}, {"id": 1215, "seek": 579444, "start": 5796.799999999999, "end": 5805.2, "text": " Layers like this one, you know finding edges and gradients and this one, you know finding kind of textures and repeating patterns", "tokens": [20084, 433, 411, 341, 472, 11, 291, 458, 5006, 8819, 293, 2771, 2448, 293, 341, 472, 11, 291, 458, 5006, 733, 295, 24501, 293, 18617, 8294], "temperature": 0.0, "avg_logprob": -0.2322634659804307, "compression_ratio": 1.6702127659574468, "no_speech_prob": 1.370953555124288e-06}, {"id": 1216, "seek": 579444, "start": 5806.2, "end": 5812.36, "text": " And maybe these ones are kind of finding more complex textures, but that's probably about it", "tokens": [400, 1310, 613, 2306, 366, 733, 295, 5006, 544, 3997, 24501, 11, 457, 300, 311, 1391, 466, 309], "temperature": 0.0, "avg_logprob": -0.2322634659804307, "compression_ratio": 1.6702127659574468, "no_speech_prob": 1.370953555124288e-06}, {"id": 1217, "seek": 579444, "start": 5813.04, "end": 5815.82, "text": " Right. So so in other words", "tokens": [1779, 13, 407, 370, 294, 661, 2283], "temperature": 0.0, "avg_logprob": -0.2322634659804307, "compression_ratio": 1.6702127659574468, "no_speech_prob": 1.370953555124288e-06}, {"id": 1218, "seek": 579444, "start": 5816.759999999999, "end": 5818.0, "text": " You know", "tokens": [509, 458], "temperature": 0.0, "avg_logprob": -0.2322634659804307, "compression_ratio": 1.6702127659574468, "no_speech_prob": 1.370953555124288e-06}, {"id": 1219, "seek": 579444, "start": 5818.0, "end": 5820.599999999999, "text": " Starting out by training very small images", "tokens": [16217, 484, 538, 3097, 588, 1359, 5267], "temperature": 0.0, "avg_logprob": -0.2322634659804307, "compression_ratio": 1.6702127659574468, "no_speech_prob": 1.370953555124288e-06}, {"id": 1220, "seek": 582060, "start": 5820.6, "end": 5827.200000000001, "text": " Works pretty well when you're using stuff like satellites. So in this case, I started right back at 64 by 64", "tokens": [27914, 1238, 731, 562, 291, 434, 1228, 1507, 411, 24960, 13, 407, 294, 341, 1389, 11, 286, 1409, 558, 646, 412, 12145, 538, 12145], "temperature": 0.0, "avg_logprob": -0.2428031319066098, "compression_ratio": 1.5185185185185186, "no_speech_prob": 1.0289384590578265e-05}, {"id": 1221, "seek": 582060, "start": 5827.96, "end": 5829.96, "text": " Grab some data", "tokens": [20357, 512, 1412], "temperature": 0.0, "avg_logprob": -0.2428031319066098, "compression_ratio": 1.5185185185185186, "no_speech_prob": 1.0289384590578265e-05}, {"id": 1222, "seek": 582060, "start": 5830.6, "end": 5832.6, "text": " Built my model", "tokens": [49822, 452, 2316], "temperature": 0.0, "avg_logprob": -0.2428031319066098, "compression_ratio": 1.5185185185185186, "no_speech_prob": 1.0289384590578265e-05}, {"id": 1223, "seek": 582060, "start": 5832.68, "end": 5834.76, "text": " Found out what learning rate to use", "tokens": [8207, 484, 437, 2539, 3314, 281, 764], "temperature": 0.0, "avg_logprob": -0.2428031319066098, "compression_ratio": 1.5185185185185186, "no_speech_prob": 1.0289384590578265e-05}, {"id": 1224, "seek": 582060, "start": 5835.84, "end": 5837.84, "text": " Interestingly, it turned out to be quite high", "tokens": [30564, 11, 309, 3574, 484, 281, 312, 1596, 1090], "temperature": 0.0, "avg_logprob": -0.2428031319066098, "compression_ratio": 1.5185185185185186, "no_speech_prob": 1.0289384590578265e-05}, {"id": 1225, "seek": 582060, "start": 5838.64, "end": 5839.92, "text": " it", "tokens": [309], "temperature": 0.0, "avg_logprob": -0.2428031319066098, "compression_ratio": 1.5185185185185186, "no_speech_prob": 1.0289384590578265e-05}, {"id": 1226, "seek": 582060, "start": 5839.92, "end": 5843.84, "text": " Seems that because like it's so unlike image net I", "tokens": [22524, 300, 570, 411, 309, 311, 370, 8343, 3256, 2533, 286], "temperature": 0.0, "avg_logprob": -0.2428031319066098, "compression_ratio": 1.5185185185185186, "no_speech_prob": 1.0289384590578265e-05}, {"id": 1227, "seek": 584384, "start": 5843.84, "end": 5850.360000000001, "text": " I needed to do quite a bit more fitting of just that last layer before it started to flatten out", "tokens": [286, 2978, 281, 360, 1596, 257, 857, 544, 15669, 295, 445, 300, 1036, 4583, 949, 309, 1409, 281, 24183, 484], "temperature": 0.0, "avg_logprob": -0.23285152066138484, "compression_ratio": 1.6355140186915889, "no_speech_prob": 3.7266047456796514e-06}, {"id": 1228, "seek": 584384, "start": 5850.860000000001, "end": 5854.400000000001, "text": " Then I unfreezed it and again, this is the difference to", "tokens": [1396, 286, 3971, 701, 11312, 309, 293, 797, 11, 341, 307, 264, 2649, 281], "temperature": 0.0, "avg_logprob": -0.23285152066138484, "compression_ratio": 1.6355140186915889, "no_speech_prob": 3.7266047456796514e-06}, {"id": 1229, "seek": 584384, "start": 5855.72, "end": 5857.72, "text": " image net like", "tokens": [3256, 2533, 411], "temperature": 0.0, "avg_logprob": -0.23285152066138484, "compression_ratio": 1.6355140186915889, "no_speech_prob": 3.7266047456796514e-06}, {"id": 1230, "seek": 584384, "start": 5858.64, "end": 5864.360000000001, "text": " Datasets is my learning rate in the initial layer. I set to divided by 9 the middle layers", "tokens": [9315, 296, 1385, 307, 452, 2539, 3314, 294, 264, 5883, 4583, 13, 286, 992, 281, 6666, 538, 1722, 264, 2808, 7914], "temperature": 0.0, "avg_logprob": -0.23285152066138484, "compression_ratio": 1.6355140186915889, "no_speech_prob": 3.7266047456796514e-06}, {"id": 1231, "seek": 584384, "start": 5864.360000000001, "end": 5869.82, "text": " I set to divided by 3 where else to stuff like it's like image net. I had a multiple of 10", "tokens": [286, 992, 281, 6666, 538, 805, 689, 1646, 281, 1507, 411, 309, 311, 411, 3256, 2533, 13, 286, 632, 257, 3866, 295, 1266], "temperature": 0.0, "avg_logprob": -0.23285152066138484, "compression_ratio": 1.6355140186915889, "no_speech_prob": 3.7266047456796514e-06}, {"id": 1232, "seek": 586982, "start": 5869.82, "end": 5875.04, "text": " For each of those, you know again the idea being that the earlier layers", "tokens": [1171, 1184, 295, 729, 11, 291, 458, 797, 264, 1558, 885, 300, 264, 3071, 7914], "temperature": 0.0, "avg_logprob": -0.20216831953629202, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.989262490402325e-07}, {"id": 1233, "seek": 586982, "start": 5876.04, "end": 5880.36, "text": " Probably are not as close to what they need to be compared to the image net", "tokens": [9210, 366, 406, 382, 1998, 281, 437, 436, 643, 281, 312, 5347, 281, 264, 3256, 2533], "temperature": 0.0, "avg_logprob": -0.20216831953629202, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.989262490402325e-07}, {"id": 1234, "seek": 586982, "start": 5881.04, "end": 5883.04, "text": " like datasets", "tokens": [411, 42856], "temperature": 0.0, "avg_logprob": -0.20216831953629202, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.989262490402325e-07}, {"id": 1235, "seek": 586982, "start": 5884.08, "end": 5886.219999999999, "text": " Again unfreeze train for a while", "tokens": [3764, 3971, 701, 1381, 3847, 337, 257, 1339], "temperature": 0.0, "avg_logprob": -0.20216831953629202, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.989262490402325e-07}, {"id": 1236, "seek": 586982, "start": 5887.44, "end": 5893.12, "text": " And you can kind of see here, you know, there's cycle one. There's cycle two. There's cycle three", "tokens": [400, 291, 393, 733, 295, 536, 510, 11, 291, 458, 11, 456, 311, 6586, 472, 13, 821, 311, 6586, 732, 13, 821, 311, 6586, 1045], "temperature": 0.0, "avg_logprob": -0.20216831953629202, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.989262490402325e-07}, {"id": 1237, "seek": 586982, "start": 5893.799999999999, "end": 5897.96, "text": " And then I kind of increased double the size of my images", "tokens": [400, 550, 286, 733, 295, 6505, 3834, 264, 2744, 295, 452, 5267], "temperature": 0.0, "avg_logprob": -0.20216831953629202, "compression_ratio": 1.6956521739130435, "no_speech_prob": 5.989262490402325e-07}, {"id": 1238, "seek": 589796, "start": 5897.96, "end": 5906.08, "text": " Fit for a while unfreeze fit for a while double the size of the images again fit for a while unfreeze fit for a while", "tokens": [29263, 337, 257, 1339, 3971, 701, 1381, 3318, 337, 257, 1339, 3834, 264, 2744, 295, 264, 5267, 797, 3318, 337, 257, 1339, 3971, 701, 1381, 3318, 337, 257, 1339], "temperature": 0.0, "avg_logprob": -0.1942913818359375, "compression_ratio": 1.7831858407079646, "no_speech_prob": 1.0845124052139e-06}, {"id": 1239, "seek": 589796, "start": 5906.72, "end": 5911.96, "text": " And then add TTA and so as I mentioned last time we looked at this this process ends up", "tokens": [400, 550, 909, 314, 8241, 293, 370, 382, 286, 2835, 1036, 565, 321, 2956, 412, 341, 341, 1399, 5314, 493], "temperature": 0.0, "avg_logprob": -0.1942913818359375, "compression_ratio": 1.7831858407079646, "no_speech_prob": 1.0845124052139e-06}, {"id": 1240, "seek": 589796, "start": 5911.96, "end": 5915.2, "text": " You know getting us about 30th place in this competition", "tokens": [509, 458, 1242, 505, 466, 2217, 392, 1081, 294, 341, 6211], "temperature": 0.0, "avg_logprob": -0.1942913818359375, "compression_ratio": 1.7831858407079646, "no_speech_prob": 1.0845124052139e-06}, {"id": 1241, "seek": 589796, "start": 5915.8, "end": 5921.08, "text": " Which is really cool because people you know a lot of very very smart people just a few months ago", "tokens": [3013, 307, 534, 1627, 570, 561, 291, 458, 257, 688, 295, 588, 588, 4069, 561, 445, 257, 1326, 2493, 2057], "temperature": 0.0, "avg_logprob": -0.1942913818359375, "compression_ratio": 1.7831858407079646, "no_speech_prob": 1.0845124052139e-06}, {"id": 1242, "seek": 589796, "start": 5921.32, "end": 5923.32, "text": " Worked very very hard on this competition", "tokens": [6603, 292, 588, 588, 1152, 322, 341, 6211], "temperature": 0.0, "avg_logprob": -0.1942913818359375, "compression_ratio": 1.7831858407079646, "no_speech_prob": 1.0845124052139e-06}, {"id": 1243, "seek": 592332, "start": 5923.32, "end": 5925.32, "text": " A", "tokens": [316], "temperature": 0.0, "avg_logprob": -0.2535535328423799, "compression_ratio": 1.503030303030303, "no_speech_prob": 2.332063331778045e-06}, {"id": 1244, "seek": 592332, "start": 5926.2, "end": 5929.16, "text": " Couple of things people have asked about one is", "tokens": [38266, 295, 721, 561, 362, 2351, 466, 472, 307], "temperature": 0.0, "avg_logprob": -0.2535535328423799, "compression_ratio": 1.503030303030303, "no_speech_prob": 2.332063331778045e-06}, {"id": 1245, "seek": 592332, "start": 5931.719999999999, "end": 5936.0, "text": " What is this data dot resize do so a", "tokens": [708, 307, 341, 1412, 5893, 50069, 360, 370, 257], "temperature": 0.0, "avg_logprob": -0.2535535328423799, "compression_ratio": 1.503030303030303, "no_speech_prob": 2.332063331778045e-06}, {"id": 1246, "seek": 592332, "start": 5937.5599999999995, "end": 5940.719999999999, "text": " Couple of different pieces here. The first is that when we say", "tokens": [38266, 295, 819, 3755, 510, 13, 440, 700, 307, 300, 562, 321, 584], "temperature": 0.0, "avg_logprob": -0.2535535328423799, "compression_ratio": 1.503030303030303, "no_speech_prob": 2.332063331778045e-06}, {"id": 1247, "seek": 592332, "start": 5943.08, "end": 5945.08, "text": " Back here", "tokens": [5833, 510], "temperature": 0.0, "avg_logprob": -0.2535535328423799, "compression_ratio": 1.503030303030303, "no_speech_prob": 2.332063331778045e-06}, {"id": 1248, "seek": 592332, "start": 5945.08, "end": 5950.92, "text": " What transforms do we apply and here's our transforms we actually pass in a size, right?", "tokens": [708, 35592, 360, 321, 3079, 293, 510, 311, 527, 35592, 321, 767, 1320, 294, 257, 2744, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2535535328423799, "compression_ratio": 1.503030303030303, "no_speech_prob": 2.332063331778045e-06}, {"id": 1249, "seek": 595092, "start": 5950.92, "end": 5958.32, "text": " So one of the things that one of the things that data loaded does is to resize the images like on demand every time it sees them", "tokens": [407, 472, 295, 264, 721, 300, 472, 295, 264, 721, 300, 1412, 13210, 775, 307, 281, 50069, 264, 5267, 411, 322, 4733, 633, 565, 309, 8194, 552], "temperature": 0.0, "avg_logprob": -0.19635118756975448, "compression_ratio": 1.8699551569506727, "no_speech_prob": 3.6688343243440613e-06}, {"id": 1250, "seek": 595092, "start": 5961.04, "end": 5964.64, "text": " This has got nothing to do with that dot resize method, right?", "tokens": [639, 575, 658, 1825, 281, 360, 365, 300, 5893, 50069, 3170, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19635118756975448, "compression_ratio": 1.8699551569506727, "no_speech_prob": 3.6688343243440613e-06}, {"id": 1251, "seek": 595092, "start": 5964.64, "end": 5971.14, "text": " So this is this is the thing that happens at the end like whatever's passed in before it hits out before our data loaders fits", "tokens": [407, 341, 307, 341, 307, 264, 551, 300, 2314, 412, 264, 917, 411, 2035, 311, 4678, 294, 949, 309, 8664, 484, 949, 527, 1412, 3677, 433, 9001], "temperature": 0.0, "avg_logprob": -0.19635118756975448, "compression_ratio": 1.8699551569506727, "no_speech_prob": 3.6688343243440613e-06}, {"id": 1252, "seek": 595092, "start": 5971.14, "end": 5973.4800000000005, "text": " It out. It's going to resize it to this size", "tokens": [467, 484, 13, 467, 311, 516, 281, 50069, 309, 281, 341, 2744], "temperature": 0.0, "avg_logprob": -0.19635118756975448, "compression_ratio": 1.8699551569506727, "no_speech_prob": 3.6688343243440613e-06}, {"id": 1253, "seek": 595092, "start": 5974.68, "end": 5977.64, "text": " if the initial input is like a", "tokens": [498, 264, 5883, 4846, 307, 411, 257], "temperature": 0.0, "avg_logprob": -0.19635118756975448, "compression_ratio": 1.8699551569506727, "no_speech_prob": 3.6688343243440613e-06}, {"id": 1254, "seek": 595092, "start": 5978.0, "end": 5979.92, "text": " thousand by a thousand", "tokens": [4714, 538, 257, 4714], "temperature": 0.0, "avg_logprob": -0.19635118756975448, "compression_ratio": 1.8699551569506727, "no_speech_prob": 3.6688343243440613e-06}, {"id": 1255, "seek": 597992, "start": 5979.92, "end": 5984.6, "text": " Reading that jpeg and resizing it to 64 by 64", "tokens": [29766, 300, 361, 494, 70, 293, 725, 3319, 309, 281, 12145, 538, 12145], "temperature": 0.0, "avg_logprob": -0.2141060299343533, "compression_ratio": 1.515, "no_speech_prob": 2.4439864318992477e-06}, {"id": 1256, "seek": 597992, "start": 5985.08, "end": 5990.42, "text": " Turns out to actually take more time than training the confident dots for each batch", "tokens": [29524, 484, 281, 767, 747, 544, 565, 813, 3097, 264, 6679, 15026, 337, 1184, 15245], "temperature": 0.0, "avg_logprob": -0.2141060299343533, "compression_ratio": 1.515, "no_speech_prob": 2.4439864318992477e-06}, {"id": 1257, "seek": 597992, "start": 5990.96, "end": 5995.86, "text": " Right. So basically all resize does is it says hey", "tokens": [1779, 13, 407, 1936, 439, 50069, 775, 307, 309, 1619, 4177], "temperature": 0.0, "avg_logprob": -0.2141060299343533, "compression_ratio": 1.515, "no_speech_prob": 2.4439864318992477e-06}, {"id": 1258, "seek": 597992, "start": 5995.86, "end": 6000.3, "text": " I'm not going to be using any images bigger than size times 1.3", "tokens": [286, 478, 406, 516, 281, 312, 1228, 604, 5267, 3801, 813, 2744, 1413, 502, 13, 18], "temperature": 0.0, "avg_logprob": -0.2141060299343533, "compression_ratio": 1.515, "no_speech_prob": 2.4439864318992477e-06}, {"id": 1259, "seek": 597992, "start": 6000.84, "end": 6005.92, "text": " So just go through once and create new jpegs of this size", "tokens": [407, 445, 352, 807, 1564, 293, 1884, 777, 361, 494, 21559, 295, 341, 2744], "temperature": 0.0, "avg_logprob": -0.2141060299343533, "compression_ratio": 1.515, "no_speech_prob": 2.4439864318992477e-06}, {"id": 1260, "seek": 600592, "start": 6005.92, "end": 6011.12, "text": " Right and and they're rectangular right so new jpegs were the smallest", "tokens": [1779, 293, 293, 436, 434, 31167, 558, 370, 777, 361, 494, 21559, 645, 264, 16998], "temperature": 0.0, "avg_logprob": -0.19245255109175896, "compression_ratio": 1.602510460251046, "no_speech_prob": 2.5215667847078294e-06}, {"id": 1261, "seek": 600592, "start": 6011.92, "end": 6016.2, "text": " Edges of this size and again, it's like you never have to do this", "tokens": [3977, 2880, 295, 341, 2744, 293, 797, 11, 309, 311, 411, 291, 1128, 362, 281, 360, 341], "temperature": 0.0, "avg_logprob": -0.19245255109175896, "compression_ratio": 1.602510460251046, "no_speech_prob": 2.5215667847078294e-06}, {"id": 1262, "seek": 600592, "start": 6016.52, "end": 6020.4800000000005, "text": " There's no reason to ever use it if you don't want to it's just a speed up", "tokens": [821, 311, 572, 1778, 281, 1562, 764, 309, 498, 291, 500, 380, 528, 281, 309, 311, 445, 257, 3073, 493], "temperature": 0.0, "avg_logprob": -0.19245255109175896, "compression_ratio": 1.602510460251046, "no_speech_prob": 2.5215667847078294e-06}, {"id": 1263, "seek": 600592, "start": 6020.92, "end": 6027.64, "text": " Okay, but if you've got really big images coming in it saves you a lot of time and you'll often see on like Kaggle kernels or", "tokens": [1033, 11, 457, 498, 291, 600, 658, 534, 955, 5267, 1348, 294, 309, 19155, 291, 257, 688, 295, 565, 293, 291, 603, 2049, 536, 322, 411, 48751, 22631, 23434, 1625, 420], "temperature": 0.0, "avg_logprob": -0.19245255109175896, "compression_ratio": 1.602510460251046, "no_speech_prob": 2.5215667847078294e-06}, {"id": 1264, "seek": 600592, "start": 6028.4400000000005, "end": 6030.9400000000005, "text": " forum posts or whatever people will have like", "tokens": [17542, 12300, 420, 2035, 561, 486, 362, 411], "temperature": 0.0, "avg_logprob": -0.19245255109175896, "compression_ratio": 1.602510460251046, "no_speech_prob": 2.5215667847078294e-06}, {"id": 1265, "seek": 603094, "start": 6030.94, "end": 6039.54, "text": " bash scripts stuff like that to like loop through and resize images to save time you never have to do that right just you can", "tokens": [46183, 23294, 1507, 411, 300, 281, 411, 6367, 807, 293, 50069, 5267, 281, 3155, 565, 291, 1128, 362, 281, 360, 300, 558, 445, 291, 393], "temperature": 0.0, "avg_logprob": -0.21119520166418054, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.7061779544746969e-06}, {"id": 1266, "seek": 603094, "start": 6039.54, "end": 6042.0, "text": " Just say dot resize and it'll just", "tokens": [1449, 584, 5893, 50069, 293, 309, 603, 445], "temperature": 0.0, "avg_logprob": -0.21119520166418054, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.7061779544746969e-06}, {"id": 1267, "seek": 603094, "start": 6042.78, "end": 6046.7, "text": " Create you know once off it'll go through and create that if it's already there", "tokens": [20248, 291, 458, 1564, 766, 309, 603, 352, 807, 293, 1884, 300, 498, 309, 311, 1217, 456], "temperature": 0.0, "avg_logprob": -0.21119520166418054, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.7061779544746969e-06}, {"id": 1268, "seek": 603094, "start": 6047.339999999999, "end": 6051.86, "text": " It'll use the resized ones for you. Okay, so it's just it's just a", "tokens": [467, 603, 764, 264, 725, 1602, 2306, 337, 291, 13, 1033, 11, 370, 309, 311, 445, 309, 311, 445, 257], "temperature": 0.0, "avg_logprob": -0.21119520166418054, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.7061779544746969e-06}, {"id": 1269, "seek": 603094, "start": 6052.7, "end": 6055.2, "text": " Speed up convenience function no more", "tokens": [18774, 493, 19283, 2445, 572, 544], "temperature": 0.0, "avg_logprob": -0.21119520166418054, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.7061779544746969e-06}, {"id": 1270, "seek": 603094, "start": 6057.179999999999, "end": 6058.54, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.21119520166418054, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.7061779544746969e-06}, {"id": 1271, "seek": 605854, "start": 6058.54, "end": 6063.06, "text": " So for those of you that are kind of past dog breeds", "tokens": [407, 337, 729, 295, 291, 300, 366, 733, 295, 1791, 3000, 41609], "temperature": 0.0, "avg_logprob": -0.18139082320193026, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.7693959054886363e-06}, {"id": 1272, "seek": 605854, "start": 6064.06, "end": 6065.62, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.18139082320193026, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.7693959054886363e-06}, {"id": 1273, "seek": 605854, "start": 6065.62, "end": 6070.82, "text": " Would be looking at planet next you know like try like play around", "tokens": [6068, 312, 1237, 412, 5054, 958, 291, 458, 411, 853, 411, 862, 926], "temperature": 0.0, "avg_logprob": -0.18139082320193026, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.7693959054886363e-06}, {"id": 1274, "seek": 605854, "start": 6071.9, "end": 6073.5, "text": " with", "tokens": [365], "temperature": 0.0, "avg_logprob": -0.18139082320193026, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.7693959054886363e-06}, {"id": 1275, "seek": 605854, "start": 6073.5, "end": 6077.42, "text": " With trying to get a sense of like how can you get this as an accurate model?", "tokens": [2022, 1382, 281, 483, 257, 2020, 295, 411, 577, 393, 291, 483, 341, 382, 364, 8559, 2316, 30], "temperature": 0.0, "avg_logprob": -0.18139082320193026, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.7693959054886363e-06}, {"id": 1276, "seek": 605854, "start": 6078.7, "end": 6081.62, "text": " One thing to mention and I'm not really going to go into it in detail", "tokens": [1485, 551, 281, 2152, 293, 286, 478, 406, 534, 516, 281, 352, 666, 309, 294, 2607], "temperature": 0.0, "avg_logprob": -0.18139082320193026, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.7693959054886363e-06}, {"id": 1277, "seek": 605854, "start": 6081.62, "end": 6085.66, "text": " There's nothing to do with deep learning particularly is that I'm using a different metric", "tokens": [821, 311, 1825, 281, 360, 365, 2452, 2539, 4098, 307, 300, 286, 478, 1228, 257, 819, 20678], "temperature": 0.0, "avg_logprob": -0.18139082320193026, "compression_ratio": 1.6222222222222222, "no_speech_prob": 2.7693959054886363e-06}, {"id": 1278, "seek": 608566, "start": 6085.66, "end": 6090.86, "text": " I didn't use metrics equals accuracy, but I said metrics equals f2", "tokens": [286, 994, 380, 764, 16367, 6915, 14170, 11, 457, 286, 848, 16367, 6915, 283, 17], "temperature": 0.0, "avg_logprob": -0.16366480526171232, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.6797279158708989e-06}, {"id": 1279, "seek": 608566, "start": 6093.54, "end": 6099.38, "text": " Just remember from last week that confusion matrix that like two by two you know", "tokens": [1449, 1604, 490, 1036, 1243, 300, 15075, 8141, 300, 411, 732, 538, 732, 291, 458], "temperature": 0.0, "avg_logprob": -0.16366480526171232, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.6797279158708989e-06}, {"id": 1280, "seek": 608566, "start": 6099.9, "end": 6102.16, "text": " Correct incorrect for each of dogs and cats", "tokens": [12753, 18424, 337, 1184, 295, 7197, 293, 11111], "temperature": 0.0, "avg_logprob": -0.16366480526171232, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.6797279158708989e-06}, {"id": 1281, "seek": 608566, "start": 6105.26, "end": 6109.139999999999, "text": " There's a lot of different ways you could turn that confusion matrix into a score", "tokens": [821, 311, 257, 688, 295, 819, 2098, 291, 727, 1261, 300, 15075, 8141, 666, 257, 6175], "temperature": 0.0, "avg_logprob": -0.16366480526171232, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.6797279158708989e-06}, {"id": 1282, "seek": 608566, "start": 6109.5, "end": 6112.0599999999995, "text": " You know do you care more about false negatives?", "tokens": [509, 458, 360, 291, 1127, 544, 466, 7908, 40019, 30], "temperature": 0.0, "avg_logprob": -0.16366480526171232, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.6797279158708989e-06}, {"id": 1283, "seek": 611206, "start": 6112.06, "end": 6116.76, "text": " Or do you care more about false positives, and how do you weight them, and how do you combine them together right?", "tokens": [1610, 360, 291, 1127, 544, 466, 7908, 35127, 11, 293, 577, 360, 291, 3364, 552, 11, 293, 577, 360, 291, 10432, 552, 1214, 558, 30], "temperature": 0.0, "avg_logprob": -0.2016514848779749, "compression_ratio": 1.8666666666666667, "no_speech_prob": 3.446570417509065e-06}, {"id": 1284, "seek": 611206, "start": 6118.22, "end": 6121.38, "text": " There's a base. There's basically a function called f beta", "tokens": [821, 311, 257, 3096, 13, 821, 311, 1936, 257, 2445, 1219, 283, 9861], "temperature": 0.0, "avg_logprob": -0.2016514848779749, "compression_ratio": 1.8666666666666667, "no_speech_prob": 3.446570417509065e-06}, {"id": 1285, "seek": 611206, "start": 6122.26, "end": 6128.5, "text": " Where the beta says how much do you weight false negatives versus false positives and so f2 is?", "tokens": [2305, 264, 9861, 1619, 577, 709, 360, 291, 3364, 7908, 40019, 5717, 7908, 35127, 293, 370, 283, 17, 307, 30], "temperature": 0.0, "avg_logprob": -0.2016514848779749, "compression_ratio": 1.8666666666666667, "no_speech_prob": 3.446570417509065e-06}, {"id": 1286, "seek": 611206, "start": 6129.02, "end": 6135.700000000001, "text": " F beta with beta equals 2 and it's basically as particular way of waiting false negatives and false positives", "tokens": [479, 9861, 365, 9861, 6915, 568, 293, 309, 311, 1936, 382, 1729, 636, 295, 3806, 7908, 40019, 293, 7908, 35127], "temperature": 0.0, "avg_logprob": -0.2016514848779749, "compression_ratio": 1.8666666666666667, "no_speech_prob": 3.446570417509065e-06}, {"id": 1287, "seek": 611206, "start": 6135.700000000001, "end": 6140.46, "text": " And the reason we use it is because cattle told us that planet who were running this competition", "tokens": [400, 264, 1778, 321, 764, 309, 307, 570, 19992, 1907, 505, 300, 5054, 567, 645, 2614, 341, 6211], "temperature": 0.0, "avg_logprob": -0.2016514848779749, "compression_ratio": 1.8666666666666667, "no_speech_prob": 3.446570417509065e-06}, {"id": 1288, "seek": 614046, "start": 6140.46, "end": 6142.46, "text": " Wanted to use this particular?", "tokens": [11773, 292, 281, 764, 341, 1729, 30], "temperature": 0.0, "avg_logprob": -0.23252550760904947, "compression_ratio": 1.6346153846153846, "no_speech_prob": 1.3081725001029554e-06}, {"id": 1289, "seek": 614046, "start": 6143.3, "end": 6145.3, "text": " F beta metric", "tokens": [479, 9861, 20678], "temperature": 0.0, "avg_logprob": -0.23252550760904947, "compression_ratio": 1.6346153846153846, "no_speech_prob": 1.3081725001029554e-06}, {"id": 1290, "seek": 614046, "start": 6145.58, "end": 6150.06, "text": " The important thing for you to know is that you can create", "tokens": [440, 1021, 551, 337, 291, 281, 458, 307, 300, 291, 393, 1884], "temperature": 0.0, "avg_logprob": -0.23252550760904947, "compression_ratio": 1.6346153846153846, "no_speech_prob": 1.3081725001029554e-06}, {"id": 1291, "seek": 614046, "start": 6150.78, "end": 6152.86, "text": " Custom metrics so in this case you can see here", "tokens": [16649, 16367, 370, 294, 341, 1389, 291, 393, 536, 510], "temperature": 0.0, "avg_logprob": -0.23252550760904947, "compression_ratio": 1.6346153846153846, "no_speech_prob": 1.3081725001029554e-06}, {"id": 1292, "seek": 614046, "start": 6152.86, "end": 6160.1, "text": " It says from planet import f2 and really I've got this here so that you can see how to do it right so if you look", "tokens": [467, 1619, 490, 5054, 974, 283, 17, 293, 534, 286, 600, 658, 341, 510, 370, 300, 291, 393, 536, 577, 281, 360, 309, 558, 370, 498, 291, 574], "temperature": 0.0, "avg_logprob": -0.23252550760904947, "compression_ratio": 1.6346153846153846, "no_speech_prob": 1.3081725001029554e-06}, {"id": 1293, "seek": 614046, "start": 6160.3, "end": 6162.3, "text": " inside", "tokens": [1854], "temperature": 0.0, "avg_logprob": -0.23252550760904947, "compression_ratio": 1.6346153846153846, "no_speech_prob": 1.3081725001029554e-06}, {"id": 1294, "seek": 614046, "start": 6163.3, "end": 6165.3, "text": " Courses deal one", "tokens": [383, 5067, 279, 2028, 472], "temperature": 0.0, "avg_logprob": -0.23252550760904947, "compression_ratio": 1.6346153846153846, "no_speech_prob": 1.3081725001029554e-06}, {"id": 1295, "seek": 616530, "start": 6165.3, "end": 6172.820000000001, "text": " You can see there's something called planet dot py right and so if I look at planet dot py", "tokens": [509, 393, 536, 456, 311, 746, 1219, 5054, 5893, 10664, 558, 293, 370, 498, 286, 574, 412, 5054, 5893, 10664], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1296, "seek": 616530, "start": 6173.58, "end": 6175.58, "text": " You'll see there's a", "tokens": [509, 603, 536, 456, 311, 257], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1297, "seek": 616530, "start": 6176.02, "end": 6177.78, "text": " function there called", "tokens": [2445, 456, 1219], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1298, "seek": 616530, "start": 6177.78, "end": 6179.02, "text": " F2", "tokens": [479, 17], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1299, "seek": 616530, "start": 6179.02, "end": 6181.02, "text": " right and so f2", "tokens": [558, 293, 370, 283, 17], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1300, "seek": 616530, "start": 6181.62, "end": 6184.9400000000005, "text": " simply calls f beta score from", "tokens": [2935, 5498, 283, 9861, 6175, 490], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1301, "seek": 616530, "start": 6185.78, "end": 6187.14, "text": " psychic", "tokens": [35406], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1302, "seek": 616530, "start": 6187.14, "end": 6189.14, "text": " Or sci-pi and can't remember where it came from", "tokens": [1610, 2180, 12, 22630, 293, 393, 380, 1604, 689, 309, 1361, 490], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1303, "seek": 616530, "start": 6190.14, "end": 6193.900000000001, "text": " And does a couple little tweaks that are particularly important", "tokens": [400, 775, 257, 1916, 707, 46664, 300, 366, 4098, 1021], "temperature": 0.0, "avg_logprob": -0.36614557154038374, "compression_ratio": 1.6031746031746033, "no_speech_prob": 1.9333483578520827e-06}, {"id": 1304, "seek": 619390, "start": 6193.9, "end": 6195.9, "text": " but", "tokens": [457], "temperature": 0.0, "avg_logprob": -0.1931042273839315, "compression_ratio": 1.7534883720930232, "no_speech_prob": 3.0894818792148726e-06}, {"id": 1305, "seek": 619390, "start": 6196.179999999999, "end": 6201.66, "text": " The important thing is like you can write any metric you like right as long as it takes in", "tokens": [440, 1021, 551, 307, 411, 291, 393, 2464, 604, 20678, 291, 411, 558, 382, 938, 382, 309, 2516, 294], "temperature": 0.0, "avg_logprob": -0.1931042273839315, "compression_ratio": 1.7534883720930232, "no_speech_prob": 3.0894818792148726e-06}, {"id": 1306, "seek": 619390, "start": 6202.42, "end": 6204.42, "text": " set of predictions and", "tokens": [992, 295, 21264, 293], "temperature": 0.0, "avg_logprob": -0.1931042273839315, "compression_ratio": 1.7534883720930232, "no_speech_prob": 3.0894818792148726e-06}, {"id": 1307, "seek": 619390, "start": 6204.5, "end": 6211.86, "text": " A set of targets and they're both going to be numpy arrays one dimensional numpy arrays, and then you return back a number", "tokens": [316, 992, 295, 12911, 293, 436, 434, 1293, 516, 281, 312, 1031, 8200, 41011, 472, 18795, 1031, 8200, 41011, 11, 293, 550, 291, 2736, 646, 257, 1230], "temperature": 0.0, "avg_logprob": -0.1931042273839315, "compression_ratio": 1.7534883720930232, "no_speech_prob": 3.0894818792148726e-06}, {"id": 1308, "seek": 619390, "start": 6212.46, "end": 6215.139999999999, "text": " Okay, and so as you create a function that takes two", "tokens": [1033, 11, 293, 370, 382, 291, 1884, 257, 2445, 300, 2516, 732], "temperature": 0.0, "avg_logprob": -0.1931042273839315, "compression_ratio": 1.7534883720930232, "no_speech_prob": 3.0894818792148726e-06}, {"id": 1309, "seek": 621514, "start": 6215.14, "end": 6224.18, "text": " Vectors and returns art number you can call it as a metric and so then when we said", "tokens": [691, 557, 830, 293, 11247, 1523, 1230, 291, 393, 818, 309, 382, 257, 20678, 293, 370, 550, 562, 321, 848], "temperature": 0.0, "avg_logprob": -0.21801159116956922, "compression_ratio": 1.4820512820512821, "no_speech_prob": 1.1189400765942992e-06}, {"id": 1310, "seek": 621514, "start": 6230.26, "end": 6236.02, "text": " Learn metrics equals and then passed in that array which just contains a single function f2", "tokens": [17216, 16367, 6915, 293, 550, 4678, 294, 300, 10225, 597, 445, 8306, 257, 2167, 2445, 283, 17], "temperature": 0.0, "avg_logprob": -0.21801159116956922, "compression_ratio": 1.4820512820512821, "no_speech_prob": 1.1189400765942992e-06}, {"id": 1311, "seek": 621514, "start": 6236.18, "end": 6240.62, "text": " Then it's just going to be printed out after every epoch for you", "tokens": [1396, 309, 311, 445, 516, 281, 312, 13567, 484, 934, 633, 30992, 339, 337, 291], "temperature": 0.0, "avg_logprob": -0.21801159116956922, "compression_ratio": 1.4820512820512821, "no_speech_prob": 1.1189400765942992e-06}, {"id": 1312, "seek": 624062, "start": 6240.62, "end": 6248.0199999999995, "text": " Okay, so in general like the the fast AI library everything is customizable so kind of the idea is that", "tokens": [1033, 11, 370, 294, 2674, 411, 264, 264, 2370, 7318, 6405, 1203, 307, 47922, 370, 733, 295, 264, 1558, 307, 300], "temperature": 0.0, "avg_logprob": -0.20099400820797436, "compression_ratio": 1.5515463917525774, "no_speech_prob": 4.637837719201343e-06}, {"id": 1313, "seek": 624062, "start": 6248.74, "end": 6250.74, "text": " everything is", "tokens": [1203, 307], "temperature": 0.0, "avg_logprob": -0.20099400820797436, "compression_ratio": 1.5515463917525774, "no_speech_prob": 4.637837719201343e-06}, {"id": 1314, "seek": 624062, "start": 6252.0599999999995, "end": 6253.94, "text": " Everything is", "tokens": [5471, 307], "temperature": 0.0, "avg_logprob": -0.20099400820797436, "compression_ratio": 1.5515463917525774, "no_speech_prob": 4.637837719201343e-06}, {"id": 1315, "seek": 624062, "start": 6253.94, "end": 6261.3, "text": " Kind of gives you what you might want by default, but also everything can be changed as well", "tokens": [9242, 295, 2709, 291, 437, 291, 1062, 528, 538, 7576, 11, 457, 611, 1203, 393, 312, 3105, 382, 731], "temperature": 0.0, "avg_logprob": -0.20099400820797436, "compression_ratio": 1.5515463917525774, "no_speech_prob": 4.637837719201343e-06}, {"id": 1316, "seek": 624062, "start": 6262.62, "end": 6264.62, "text": " Yes, you know", "tokens": [1079, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.20099400820797436, "compression_ratio": 1.5515463917525774, "no_speech_prob": 4.637837719201343e-06}, {"id": 1317, "seek": 624062, "start": 6264.94, "end": 6267.86, "text": " We have a little bit of confusion about the difference between", "tokens": [492, 362, 257, 707, 857, 295, 15075, 466, 264, 2649, 1296], "temperature": 0.0, "avg_logprob": -0.20099400820797436, "compression_ratio": 1.5515463917525774, "no_speech_prob": 4.637837719201343e-06}, {"id": 1318, "seek": 626786, "start": 6267.86, "end": 6269.86, "text": " multi-label", "tokens": [4825, 12, 75, 18657], "temperature": 0.0, "avg_logprob": -0.3784560001257694, "compression_ratio": 1.6995515695067265, "no_speech_prob": 1.1478479791549034e-05}, {"id": 1319, "seek": 626786, "start": 6271.099999999999, "end": 6275.58, "text": " To single label uh-huh do you buy any chance an example in which you compute?", "tokens": [1407, 2167, 7645, 2232, 12, 18710, 360, 291, 2256, 604, 2931, 364, 1365, 294, 597, 291, 14722, 30], "temperature": 0.0, "avg_logprob": -0.3784560001257694, "compression_ratio": 1.6995515695067265, "no_speech_prob": 1.1478479791549034e-05}, {"id": 1320, "seek": 626786, "start": 6276.259999999999, "end": 6278.259999999999, "text": " similarly to the example of the", "tokens": [14138, 281, 264, 1365, 295, 264], "temperature": 0.0, "avg_logprob": -0.3784560001257694, "compression_ratio": 1.6995515695067265, "no_speech_prob": 1.1478479791549034e-05}, {"id": 1321, "seek": 626786, "start": 6278.58, "end": 6283.7, "text": " You just show us oh I didn't get to that activation function. Yeah, so", "tokens": [509, 445, 855, 505, 1954, 286, 994, 380, 483, 281, 300, 24433, 2445, 13, 865, 11, 370], "temperature": 0.0, "avg_logprob": -0.3784560001257694, "compression_ratio": 1.6995515695067265, "no_speech_prob": 1.1478479791549034e-05}, {"id": 1322, "seek": 626786, "start": 6284.86, "end": 6292.86, "text": " So I'm so sorry. I said I'd do that and then I didn't so the activation the output activation function for single label", "tokens": [407, 286, 478, 370, 2597, 13, 286, 848, 286, 1116, 360, 300, 293, 550, 286, 994, 380, 370, 264, 24433, 264, 5598, 24433, 2445, 337, 2167, 7645], "temperature": 0.0, "avg_logprob": -0.3784560001257694, "compression_ratio": 1.6995515695067265, "no_speech_prob": 1.1478479791549034e-05}, {"id": 1323, "seek": 626786, "start": 6293.139999999999, "end": 6296.259999999999, "text": " Classification is softmax for all the reasons that we talked about", "tokens": [9471, 3774, 307, 2787, 41167, 337, 439, 264, 4112, 300, 321, 2825, 466], "temperature": 0.0, "avg_logprob": -0.3784560001257694, "compression_ratio": 1.6995515695067265, "no_speech_prob": 1.1478479791549034e-05}, {"id": 1324, "seek": 629626, "start": 6296.26, "end": 6297.66, "text": " but", "tokens": [457], "temperature": 0.0, "avg_logprob": -0.20044391074877108, "compression_ratio": 1.654708520179372, "no_speech_prob": 1.2679248584390734e-06}, {"id": 1325, "seek": 629626, "start": 6297.66, "end": 6302.900000000001, "text": " If we were trying to predict something that was like zero zero one one zero", "tokens": [759, 321, 645, 1382, 281, 6069, 746, 300, 390, 411, 4018, 4018, 472, 472, 4018], "temperature": 0.0, "avg_logprob": -0.20044391074877108, "compression_ratio": 1.654708520179372, "no_speech_prob": 1.2679248584390734e-06}, {"id": 1326, "seek": 629626, "start": 6303.7, "end": 6310.780000000001, "text": " Then softmax would be a terrible choice because it's very hard to come up with something where both of these are high in fact", "tokens": [1396, 2787, 41167, 576, 312, 257, 6237, 3922, 570, 309, 311, 588, 1152, 281, 808, 493, 365, 746, 689, 1293, 295, 613, 366, 1090, 294, 1186], "temperature": 0.0, "avg_logprob": -0.20044391074877108, "compression_ratio": 1.654708520179372, "no_speech_prob": 1.2679248584390734e-06}, {"id": 1327, "seek": 629626, "start": 6310.780000000001, "end": 6315.02, "text": " It's impossible because they have to add up to one so the closest they could be would be point five", "tokens": [467, 311, 6243, 570, 436, 362, 281, 909, 493, 281, 472, 370, 264, 13699, 436, 727, 312, 576, 312, 935, 1732], "temperature": 0.0, "avg_logprob": -0.20044391074877108, "compression_ratio": 1.654708520179372, "no_speech_prob": 1.2679248584390734e-06}, {"id": 1328, "seek": 629626, "start": 6315.9800000000005, "end": 6318.9800000000005, "text": " so for multi-label classification", "tokens": [370, 337, 4825, 12, 75, 18657, 21538], "temperature": 0.0, "avg_logprob": -0.20044391074877108, "compression_ratio": 1.654708520179372, "no_speech_prob": 1.2679248584390734e-06}, {"id": 1329, "seek": 629626, "start": 6319.9800000000005, "end": 6321.9800000000005, "text": " Activation function is called", "tokens": [28550, 399, 2445, 307, 1219], "temperature": 0.0, "avg_logprob": -0.20044391074877108, "compression_ratio": 1.654708520179372, "no_speech_prob": 1.2679248584390734e-06}, {"id": 1330, "seek": 632198, "start": 6321.98, "end": 6330.099999999999, "text": " Sigmoid okay and again the fast AI library does this automatically for you if it notices you have a multi-label", "tokens": [37763, 3280, 327, 1392, 293, 797, 264, 2370, 7318, 6405, 775, 341, 6772, 337, 291, 498, 309, 32978, 291, 362, 257, 4825, 12, 75, 18657], "temperature": 0.0, "avg_logprob": -0.20851001285371326, "compression_ratio": 1.5539906103286385, "no_speech_prob": 2.1907717382418923e-06}, {"id": 1331, "seek": 632198, "start": 6330.98, "end": 6336.7, "text": " Problem and it does that by checking your data set to see if anything has more than one label applied to it", "tokens": [11676, 293, 309, 775, 300, 538, 8568, 428, 1412, 992, 281, 536, 498, 1340, 575, 544, 813, 472, 7645, 6456, 281, 309], "temperature": 0.0, "avg_logprob": -0.20851001285371326, "compression_ratio": 1.5539906103286385, "no_speech_prob": 2.1907717382418923e-06}, {"id": 1332, "seek": 632198, "start": 6337.219999999999, "end": 6341.54, "text": " and so sigmoid is a function which is equal to", "tokens": [293, 370, 4556, 3280, 327, 307, 257, 2445, 597, 307, 2681, 281], "temperature": 0.0, "avg_logprob": -0.20851001285371326, "compression_ratio": 1.5539906103286385, "no_speech_prob": 2.1907717382418923e-06}, {"id": 1333, "seek": 632198, "start": 6342.94, "end": 6344.94, "text": " It's basically the same thing", "tokens": [467, 311, 1936, 264, 912, 551], "temperature": 0.0, "avg_logprob": -0.20851001285371326, "compression_ratio": 1.5539906103286385, "no_speech_prob": 2.1907717382418923e-06}, {"id": 1334, "seek": 632198, "start": 6345.58, "end": 6347.62, "text": " Except rather than we never add up", "tokens": [16192, 2831, 813, 321, 1128, 909, 493], "temperature": 0.0, "avg_logprob": -0.20851001285371326, "compression_ratio": 1.5539906103286385, "no_speech_prob": 2.1907717382418923e-06}, {"id": 1335, "seek": 634762, "start": 6347.62, "end": 6354.58, "text": " All of these X's but instead we just take this X when we say it's just equal to it", "tokens": [1057, 295, 613, 1783, 311, 457, 2602, 321, 445, 747, 341, 1783, 562, 321, 584, 309, 311, 445, 2681, 281, 309], "temperature": 0.0, "avg_logprob": -0.3090734950831679, "compression_ratio": 1.4172661870503598, "no_speech_prob": 2.6425746000313666e-06}, {"id": 1336, "seek": 634762, "start": 6355.7, "end": 6357.58, "text": " divided by", "tokens": [6666, 538], "temperature": 0.0, "avg_logprob": -0.3090734950831679, "compression_ratio": 1.4172661870503598, "no_speech_prob": 2.6425746000313666e-06}, {"id": 1337, "seek": 634762, "start": 6357.58, "end": 6359.58, "text": " one plus", "tokens": [472, 1804], "temperature": 0.0, "avg_logprob": -0.3090734950831679, "compression_ratio": 1.4172661870503598, "no_speech_prob": 2.6425746000313666e-06}, {"id": 1338, "seek": 634762, "start": 6360.3, "end": 6362.3, "text": " It", "tokens": [467], "temperature": 0.0, "avg_logprob": -0.3090734950831679, "compression_ratio": 1.4172661870503598, "no_speech_prob": 2.6425746000313666e-06}, {"id": 1339, "seek": 634762, "start": 6362.46, "end": 6368.7, "text": " And so the nice thing about that is that now like multiple things can be", "tokens": [400, 370, 264, 1481, 551, 466, 300, 307, 300, 586, 411, 3866, 721, 393, 312], "temperature": 0.0, "avg_logprob": -0.3090734950831679, "compression_ratio": 1.4172661870503598, "no_speech_prob": 2.6425746000313666e-06}, {"id": 1340, "seek": 634762, "start": 6369.66, "end": 6371.66, "text": " high at once", "tokens": [1090, 412, 1564], "temperature": 0.0, "avg_logprob": -0.3090734950831679, "compression_ratio": 1.4172661870503598, "no_speech_prob": 2.6425746000313666e-06}, {"id": 1341, "seek": 634762, "start": 6372.0599999999995, "end": 6373.38, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.3090734950831679, "compression_ratio": 1.4172661870503598, "no_speech_prob": 2.6425746000313666e-06}, {"id": 1342, "seek": 637338, "start": 6373.38, "end": 6380.34, "text": " And so generally then if something is less than zero its sigmoid is going to be less than point five", "tokens": [400, 370, 5101, 550, 498, 746, 307, 1570, 813, 4018, 1080, 4556, 3280, 327, 307, 516, 281, 312, 1570, 813, 935, 1732], "temperature": 0.0, "avg_logprob": -0.22081654601626927, "compression_ratio": 1.8389261744966443, "no_speech_prob": 4.356860245025018e-06}, {"id": 1343, "seek": 637338, "start": 6380.66, "end": 6384.54, "text": " If it's greater than zero its sigmoid is going to be greater than point five", "tokens": [759, 309, 311, 5044, 813, 4018, 1080, 4556, 3280, 327, 307, 516, 281, 312, 5044, 813, 935, 1732], "temperature": 0.0, "avg_logprob": -0.22081654601626927, "compression_ratio": 1.8389261744966443, "no_speech_prob": 4.356860245025018e-06}, {"id": 1344, "seek": 637338, "start": 6385.06, "end": 6390.78, "text": " And so the important thing to know about a sigmoid function is that its shape", "tokens": [400, 370, 264, 1021, 551, 281, 458, 466, 257, 4556, 3280, 327, 2445, 307, 300, 1080, 3909], "temperature": 0.0, "avg_logprob": -0.22081654601626927, "compression_ratio": 1.8389261744966443, "no_speech_prob": 4.356860245025018e-06}, {"id": 1345, "seek": 637338, "start": 6391.86, "end": 6393.86, "text": " is", "tokens": [307], "temperature": 0.0, "avg_logprob": -0.22081654601626927, "compression_ratio": 1.8389261744966443, "no_speech_prob": 4.356860245025018e-06}, {"id": 1346, "seek": 637338, "start": 6396.46, "end": 6398.46, "text": " Something which", "tokens": [6595, 597], "temperature": 0.0, "avg_logprob": -0.22081654601626927, "compression_ratio": 1.8389261744966443, "no_speech_prob": 4.356860245025018e-06}, {"id": 1347, "seek": 639846, "start": 6398.46, "end": 6403.58, "text": " Asymptotes at the top to one and asymptotes. Oh, I drew that as", "tokens": [1018, 34029, 17251, 412, 264, 1192, 281, 472, 293, 35114, 17251, 13, 876, 11, 286, 12804, 300, 382], "temperature": 0.0, "avg_logprob": -0.3359689340962992, "compression_ratio": 1.5280898876404494, "no_speech_prob": 3.4465670069039334e-06}, {"id": 1348, "seek": 639846, "start": 6406.38, "end": 6408.38, "text": " Some totes at the bottom", "tokens": [2188, 1993, 279, 412, 264, 2767], "temperature": 0.0, "avg_logprob": -0.3359689340962992, "compression_ratio": 1.5280898876404494, "no_speech_prob": 3.4465670069039334e-06}, {"id": 1349, "seek": 639846, "start": 6409.58, "end": 6414.14, "text": " To zero and so therefore it's a good thing to model a probability with", "tokens": [1407, 4018, 293, 370, 4412, 309, 311, 257, 665, 551, 281, 2316, 257, 8482, 365], "temperature": 0.0, "avg_logprob": -0.3359689340962992, "compression_ratio": 1.5280898876404494, "no_speech_prob": 3.4465670069039334e-06}, {"id": 1350, "seek": 639846, "start": 6415.22, "end": 6417.42, "text": " Anybody who has done any?", "tokens": [19082, 567, 575, 1096, 604, 30], "temperature": 0.0, "avg_logprob": -0.3359689340962992, "compression_ratio": 1.5280898876404494, "no_speech_prob": 3.4465670069039334e-06}, {"id": 1351, "seek": 639846, "start": 6418.82, "end": 6420.7, "text": " logistic regression", "tokens": [3565, 3142, 24590], "temperature": 0.0, "avg_logprob": -0.3359689340962992, "compression_ratio": 1.5280898876404494, "no_speech_prob": 3.4465670069039334e-06}, {"id": 1352, "seek": 639846, "start": 6420.7, "end": 6423.7, "text": " Will be familiar with this. It's what we do in logistic regression", "tokens": [3099, 312, 4963, 365, 341, 13, 467, 311, 437, 321, 360, 294, 3565, 3142, 24590], "temperature": 0.0, "avg_logprob": -0.3359689340962992, "compression_ratio": 1.5280898876404494, "no_speech_prob": 3.4465670069039334e-06}, {"id": 1353, "seek": 642370, "start": 6423.7, "end": 6430.86, "text": " So it kind of appears everywhere in machine learning and you'll see that kind of a sigmoid and a softmax. They're very close", "tokens": [407, 309, 733, 295, 7038, 5315, 294, 3479, 2539, 293, 291, 603, 536, 300, 733, 295, 257, 4556, 3280, 327, 293, 257, 2787, 41167, 13, 814, 434, 588, 1998], "temperature": 0.0, "avg_logprob": -0.20588048299153647, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.084506266124663e-06}, {"id": 1354, "seek": 642370, "start": 6431.7, "end": 6433.54, "text": " To each other", "tokens": [1407, 1184, 661], "temperature": 0.0, "avg_logprob": -0.20588048299153647, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.084506266124663e-06}, {"id": 1355, "seek": 642370, "start": 6433.54, "end": 6438.46, "text": " Conceptually, but this is what we want is our activation function for multi-label", "tokens": [47482, 671, 11, 457, 341, 307, 437, 321, 528, 307, 527, 24433, 2445, 337, 4825, 12, 75, 18657], "temperature": 0.0, "avg_logprob": -0.20588048299153647, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.084506266124663e-06}, {"id": 1356, "seek": 642370, "start": 6438.46, "end": 6445.26, "text": " And this is what we want the single label and again fast AI does it all for you. There was a question over here. Yes", "tokens": [400, 341, 307, 437, 321, 528, 264, 2167, 7645, 293, 797, 2370, 7318, 775, 309, 439, 337, 291, 13, 821, 390, 257, 1168, 670, 510, 13, 1079], "temperature": 0.0, "avg_logprob": -0.20588048299153647, "compression_ratio": 1.5674418604651164, "no_speech_prob": 1.084506266124663e-06}, {"id": 1357, "seek": 644526, "start": 6445.26, "end": 6454.46, "text": " I have a question about the initial training that you do if I understand correctly you have we have frozen the", "tokens": [286, 362, 257, 1168, 466, 264, 5883, 3097, 300, 291, 360, 498, 286, 1223, 8944, 291, 362, 321, 362, 12496, 264], "temperature": 0.0, "avg_logprob": -0.5085691687178938, "compression_ratio": 1.650273224043716, "no_speech_prob": 2.8792021112167276e-05}, {"id": 1358, "seek": 644526, "start": 6455.9800000000005, "end": 6461.46, "text": " The pre-trained model and you only need initially try to train the latest", "tokens": [440, 659, 12, 17227, 2001, 2316, 293, 291, 787, 643, 9105, 853, 281, 3847, 264, 6792], "temperature": 0.0, "avg_logprob": -0.5085691687178938, "compression_ratio": 1.650273224043716, "no_speech_prob": 2.8792021112167276e-05}, {"id": 1359, "seek": 644526, "start": 6462.54, "end": 6464.54, "text": " Layer right, right", "tokens": [35166, 558, 11, 558], "temperature": 0.0, "avg_logprob": -0.5085691687178938, "compression_ratio": 1.650273224043716, "no_speech_prob": 2.8792021112167276e-05}, {"id": 1360, "seek": 644526, "start": 6465.26, "end": 6469.26, "text": " But from the other hand we said that only the initial layer", "tokens": [583, 490, 264, 661, 1011, 321, 848, 300, 787, 264, 5883, 4583], "temperature": 0.0, "avg_logprob": -0.5085691687178938, "compression_ratio": 1.650273224043716, "no_speech_prob": 2.8792021112167276e-05}, {"id": 1361, "seek": 644526, "start": 6469.26, "end": 6471.26, "text": " So let's last probably the first layer", "tokens": [407, 718, 311, 1036, 1391, 264, 700, 4583], "temperature": 0.0, "avg_logprob": -0.5085691687178938, "compression_ratio": 1.650273224043716, "no_speech_prob": 2.8792021112167276e-05}, {"id": 1362, "seek": 647126, "start": 6471.26, "end": 6478.9800000000005, "text": " Is like important to us and the other two are more like features that are image net related and we didn't apply in this case", "tokens": [1119, 411, 1021, 281, 505, 293, 264, 661, 732, 366, 544, 411, 4122, 300, 366, 3256, 2533, 4077, 293, 321, 994, 380, 3079, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.4583541621332583, "compression_ratio": 1.6923076923076923, "no_speech_prob": 6.540238700836198e-06}, {"id": 1363, "seek": 647126, "start": 6478.9800000000005, "end": 6480.9800000000005, "text": " What's that they?", "tokens": [708, 311, 300, 436, 30], "temperature": 0.0, "avg_logprob": -0.4583541621332583, "compression_ratio": 1.6923076923076923, "no_speech_prob": 6.540238700836198e-06}, {"id": 1364, "seek": 647126, "start": 6481.7, "end": 6483.7, "text": " The layers are very important", "tokens": [440, 7914, 366, 588, 1021], "temperature": 0.0, "avg_logprob": -0.4583541621332583, "compression_ratio": 1.6923076923076923, "no_speech_prob": 6.540238700836198e-06}, {"id": 1365, "seek": 647126, "start": 6484.14, "end": 6491.26, "text": " But the pre-trained weights in them aren't so it's the later layers that we really want to train the most", "tokens": [583, 264, 659, 12, 17227, 2001, 17443, 294, 552, 3212, 380, 370, 309, 311, 264, 1780, 7914, 300, 321, 534, 528, 281, 3847, 264, 881], "temperature": 0.0, "avg_logprob": -0.4583541621332583, "compression_ratio": 1.6923076923076923, "no_speech_prob": 6.540238700836198e-06}, {"id": 1366, "seek": 647126, "start": 6491.58, "end": 6493.58, "text": " So earlier layers", "tokens": [407, 3071, 7914], "temperature": 0.0, "avg_logprob": -0.4583541621332583, "compression_ratio": 1.6923076923076923, "no_speech_prob": 6.540238700836198e-06}, {"id": 1367, "seek": 647126, "start": 6493.74, "end": 6495.74, "text": " Like me to be like already", "tokens": [1743, 385, 281, 312, 411, 1217], "temperature": 0.0, "avg_logprob": -0.4583541621332583, "compression_ratio": 1.6923076923076923, "no_speech_prob": 6.540238700836198e-06}, {"id": 1368, "seek": 647126, "start": 6496.38, "end": 6498.38, "text": " Closer to the initial layers", "tokens": [2033, 22150, 281, 264, 5883, 7914], "temperature": 0.0, "avg_logprob": -0.4583541621332583, "compression_ratio": 1.6923076923076923, "no_speech_prob": 6.540238700836198e-06}, {"id": 1369, "seek": 649838, "start": 6498.38, "end": 6501.9800000000005, "text": " Me to be like already closer to what we want", "tokens": [1923, 281, 312, 411, 1217, 4966, 281, 437, 321, 528], "temperature": 0.0, "avg_logprob": -0.23369230008592792, "compression_ratio": 1.6782608695652175, "no_speech_prob": 3.1875420063443016e-06}, {"id": 1370, "seek": 649838, "start": 6503.06, "end": 6508.82, "text": " Okay, so you start with the latest one and then you go right so if you go back to our quick dogs and cats right?", "tokens": [1033, 11, 370, 291, 722, 365, 264, 6792, 472, 293, 550, 291, 352, 558, 370, 498, 291, 352, 646, 281, 527, 1702, 7197, 293, 11111, 558, 30], "temperature": 0.0, "avg_logprob": -0.23369230008592792, "compression_ratio": 1.6782608695652175, "no_speech_prob": 3.1875420063443016e-06}, {"id": 1371, "seek": 649838, "start": 6510.2, "end": 6518.1, "text": " When we create a model from pre-trained from a pre-trained model it returns something where all of the convolutional layers are frozen and", "tokens": [1133, 321, 1884, 257, 2316, 490, 659, 12, 17227, 2001, 490, 257, 659, 12, 17227, 2001, 2316, 309, 11247, 746, 689, 439, 295, 264, 45216, 304, 7914, 366, 12496, 293], "temperature": 0.0, "avg_logprob": -0.23369230008592792, "compression_ratio": 1.6782608695652175, "no_speech_prob": 3.1875420063443016e-06}, {"id": 1372, "seek": 649838, "start": 6518.82, "end": 6520.9800000000005, "text": " some randomly set", "tokens": [512, 16979, 992], "temperature": 0.0, "avg_logprob": -0.23369230008592792, "compression_ratio": 1.6782608695652175, "no_speech_prob": 3.1875420063443016e-06}, {"id": 1373, "seek": 649838, "start": 6521.78, "end": 6523.78, "text": " Fully connected layers we add to the end", "tokens": [479, 2150, 4582, 7914, 321, 909, 281, 264, 917], "temperature": 0.0, "avg_logprob": -0.23369230008592792, "compression_ratio": 1.6782608695652175, "no_speech_prob": 3.1875420063443016e-06}, {"id": 1374, "seek": 649838, "start": 6525.22, "end": 6527.22, "text": " Unfrozen and so when we go fit", "tokens": [8170, 340, 2904, 293, 370, 562, 321, 352, 3318], "temperature": 0.0, "avg_logprob": -0.23369230008592792, "compression_ratio": 1.6782608695652175, "no_speech_prob": 3.1875420063443016e-06}, {"id": 1375, "seek": 652722, "start": 6527.22, "end": 6528.42, "text": " at", "tokens": [412], "temperature": 0.0, "avg_logprob": -0.30028462409973145, "compression_ratio": 1.5380710659898478, "no_speech_prob": 3.866961151288706e-07}, {"id": 1376, "seek": 652722, "start": 6528.42, "end": 6530.42, "text": " first it just trains", "tokens": [700, 309, 445, 16329], "temperature": 0.0, "avg_logprob": -0.30028462409973145, "compression_ratio": 1.5380710659898478, "no_speech_prob": 3.866961151288706e-07}, {"id": 1377, "seek": 652722, "start": 6530.820000000001, "end": 6536.9800000000005, "text": " The randomly set a randomly initialized fully connected layers right and", "tokens": [440, 16979, 992, 257, 16979, 5883, 1602, 4498, 4582, 7914, 558, 293], "temperature": 0.0, "avg_logprob": -0.30028462409973145, "compression_ratio": 1.5380710659898478, "no_speech_prob": 3.866961151288706e-07}, {"id": 1378, "seek": 652722, "start": 6537.58, "end": 6544.58, "text": " If something is like really close to image net that's often all we need right because the other layer layers are already", "tokens": [759, 746, 307, 411, 534, 1998, 281, 3256, 2533, 300, 311, 2049, 439, 321, 643, 558, 570, 264, 661, 4583, 7914, 366, 1217], "temperature": 0.0, "avg_logprob": -0.30028462409973145, "compression_ratio": 1.5380710659898478, "no_speech_prob": 3.866961151288706e-07}, {"id": 1379, "seek": 652722, "start": 6545.22, "end": 6550.1, "text": " Good at finding edges gradients repeating patterns for", "tokens": [2205, 412, 5006, 8819, 2771, 2448, 18617, 8294, 337], "temperature": 0.0, "avg_logprob": -0.30028462409973145, "compression_ratio": 1.5380710659898478, "no_speech_prob": 3.866961151288706e-07}, {"id": 1380, "seek": 652722, "start": 6550.820000000001, "end": 6553.22, "text": " Ears and dog's heads, you know", "tokens": [462, 685, 293, 3000, 311, 8050, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.30028462409973145, "compression_ratio": 1.5380710659898478, "no_speech_prob": 3.866961151288706e-07}, {"id": 1381, "seek": 655322, "start": 6553.22, "end": 6555.22, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.17458967367808023, "compression_ratio": 1.6805555555555556, "no_speech_prob": 2.68418489213218e-06}, {"id": 1382, "seek": 655322, "start": 6555.42, "end": 6557.34, "text": " Then when we unfreeze", "tokens": [1396, 562, 321, 3971, 701, 1381], "temperature": 0.0, "avg_logprob": -0.17458967367808023, "compression_ratio": 1.6805555555555556, "no_speech_prob": 2.68418489213218e-06}, {"id": 1383, "seek": 655322, "start": 6557.34, "end": 6561.46, "text": " We set the learning rates for the early layers to be really low", "tokens": [492, 992, 264, 2539, 6846, 337, 264, 2440, 7914, 281, 312, 534, 2295], "temperature": 0.0, "avg_logprob": -0.17458967367808023, "compression_ratio": 1.6805555555555556, "no_speech_prob": 2.68418489213218e-06}, {"id": 1384, "seek": 655322, "start": 6562.06, "end": 6566.9800000000005, "text": " Because we don't want to change them much for us the later ones we set them to be higher", "tokens": [1436, 321, 500, 380, 528, 281, 1319, 552, 709, 337, 505, 264, 1780, 2306, 321, 992, 552, 281, 312, 2946], "temperature": 0.0, "avg_logprob": -0.17458967367808023, "compression_ratio": 1.6805555555555556, "no_speech_prob": 2.68418489213218e-06}, {"id": 1385, "seek": 655322, "start": 6567.54, "end": 6569.780000000001, "text": " Where else for satellite data?", "tokens": [2305, 1646, 337, 16016, 1412, 30], "temperature": 0.0, "avg_logprob": -0.17458967367808023, "compression_ratio": 1.6805555555555556, "no_speech_prob": 2.68418489213218e-06}, {"id": 1386, "seek": 655322, "start": 6570.54, "end": 6571.900000000001, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.17458967367808023, "compression_ratio": 1.6805555555555556, "no_speech_prob": 2.68418489213218e-06}, {"id": 1387, "seek": 655322, "start": 6571.900000000001, "end": 6575.46, "text": " This is no longer true. You know the early layers are still like", "tokens": [639, 307, 572, 2854, 2074, 13, 509, 458, 264, 2440, 7914, 366, 920, 411], "temperature": 0.0, "avg_logprob": -0.17458967367808023, "compression_ratio": 1.6805555555555556, "no_speech_prob": 2.68418489213218e-06}, {"id": 1388, "seek": 655322, "start": 6576.26, "end": 6581.42, "text": " Better than the later layers, but we still probably need to change them quite a bit", "tokens": [15753, 813, 264, 1780, 7914, 11, 457, 321, 920, 1391, 643, 281, 1319, 552, 1596, 257, 857], "temperature": 0.0, "avg_logprob": -0.17458967367808023, "compression_ratio": 1.6805555555555556, "no_speech_prob": 2.68418489213218e-06}, {"id": 1389, "seek": 658142, "start": 6581.42, "end": 6587.06, "text": " So that's right. This learning rate is nine times smaller than the final learning rate", "tokens": [407, 300, 311, 558, 13, 639, 2539, 3314, 307, 4949, 1413, 4356, 813, 264, 2572, 2539, 3314], "temperature": 0.0, "avg_logprob": -0.2737954457600911, "compression_ratio": 1.6455696202531647, "no_speech_prob": 7.889173502917401e-06}, {"id": 1390, "seek": 658142, "start": 6587.58, "end": 6589.34, "text": " rather than a", "tokens": [2831, 813, 257], "temperature": 0.0, "avg_logprob": -0.2737954457600911, "compression_ratio": 1.6455696202531647, "no_speech_prob": 7.889173502917401e-06}, {"id": 1391, "seek": 658142, "start": 6589.34, "end": 6591.34, "text": " thousand times smaller", "tokens": [4714, 1413, 4356], "temperature": 0.0, "avg_logprob": -0.2737954457600911, "compression_ratio": 1.6455696202531647, "no_speech_prob": 7.889173502917401e-06}, {"id": 1392, "seek": 658142, "start": 6597.5, "end": 6599.5, "text": " Yeah, normally", "tokens": [865, 11, 5646], "temperature": 0.0, "avg_logprob": -0.2737954457600911, "compression_ratio": 1.6455696202531647, "no_speech_prob": 7.889173502917401e-06}, {"id": 1393, "seek": 658142, "start": 6599.5, "end": 6604.74, "text": " Most of the stuff you see online if they talk about this at all they'll talk about unfreezing", "tokens": [4534, 295, 264, 1507, 291, 536, 2950, 498, 436, 751, 466, 341, 412, 439, 436, 603, 751, 466, 3971, 701, 8781], "temperature": 0.0, "avg_logprob": -0.2737954457600911, "compression_ratio": 1.6455696202531647, "no_speech_prob": 7.889173502917401e-06}, {"id": 1394, "seek": 658142, "start": 6605.62, "end": 6607.62, "text": " different subsets of layers", "tokens": [819, 2090, 1385, 295, 7914], "temperature": 0.0, "avg_logprob": -0.2737954457600911, "compression_ratio": 1.6455696202531647, "no_speech_prob": 7.889173502917401e-06}, {"id": 1395, "seek": 660762, "start": 6607.62, "end": 6611.82, "text": " And indeed we do unfreeze our randomly generated ones", "tokens": [400, 6451, 321, 360, 3971, 701, 1381, 527, 16979, 10833, 2306], "temperature": 0.0, "avg_logprob": -0.192867746158522, "compression_ratio": 1.728, "no_speech_prob": 5.0146286412200425e-06}, {"id": 1396, "seek": 660762, "start": 6612.58, "end": 6619.78, "text": " But what I found is although the fast AI library you can type learned up freeze to and just freeze a subset of layers", "tokens": [583, 437, 286, 1352, 307, 4878, 264, 2370, 7318, 6405, 291, 393, 2010, 3264, 493, 15959, 281, 293, 445, 15959, 257, 25993, 295, 7914], "temperature": 0.0, "avg_logprob": -0.192867746158522, "compression_ratio": 1.728, "no_speech_prob": 5.0146286412200425e-06}, {"id": 1397, "seek": 660762, "start": 6620.14, "end": 6623.82, "text": " this approach of using differential learning rates seems to be like", "tokens": [341, 3109, 295, 1228, 15756, 2539, 6846, 2544, 281, 312, 411], "temperature": 0.0, "avg_logprob": -0.192867746158522, "compression_ratio": 1.728, "no_speech_prob": 5.0146286412200425e-06}, {"id": 1398, "seek": 660762, "start": 6624.9, "end": 6629.74, "text": " More flexible to the point that I never find myself unfreezing subsets of layers", "tokens": [5048, 11358, 281, 264, 935, 300, 286, 1128, 915, 2059, 3971, 701, 8781, 2090, 1385, 295, 7914], "temperature": 0.0, "avg_logprob": -0.192867746158522, "compression_ratio": 1.728, "no_speech_prob": 5.0146286412200425e-06}, {"id": 1399, "seek": 660762, "start": 6629.82, "end": 6633.58, "text": " So but what I didn't understand is that I would expect you to start with that", "tokens": [407, 457, 437, 286, 994, 380, 1223, 307, 300, 286, 576, 2066, 291, 281, 722, 365, 300], "temperature": 0.0, "avg_logprob": -0.192867746158522, "compression_ratio": 1.728, "no_speech_prob": 5.0146286412200425e-06}, {"id": 1400, "seek": 663358, "start": 6633.58, "end": 6636.66, "text": " with a differential the different", "tokens": [365, 257, 15756, 264, 819], "temperature": 0.0, "avg_logprob": -0.17689856662545153, "compression_ratio": 1.871559633027523, "no_speech_prob": 6.240844413696323e-06}, {"id": 1401, "seek": 663358, "start": 6637.54, "end": 6644.54, "text": " Learning rates rather than trying to learn the last layer. So the reason okay, so you could skip", "tokens": [15205, 6846, 2831, 813, 1382, 281, 1466, 264, 1036, 4583, 13, 407, 264, 1778, 1392, 11, 370, 291, 727, 10023], "temperature": 0.0, "avg_logprob": -0.17689856662545153, "compression_ratio": 1.871559633027523, "no_speech_prob": 6.240844413696323e-06}, {"id": 1402, "seek": 663358, "start": 6645.46, "end": 6647.22, "text": " this", "tokens": [341], "temperature": 0.0, "avg_logprob": -0.17689856662545153, "compression_ratio": 1.871559633027523, "no_speech_prob": 6.240844413696323e-06}, {"id": 1403, "seek": 663358, "start": 6647.22, "end": 6651.1, "text": " Training just the last layers and just go straight to differential learning rates", "tokens": [20620, 445, 264, 1036, 7914, 293, 445, 352, 2997, 281, 15756, 2539, 6846], "temperature": 0.0, "avg_logprob": -0.17689856662545153, "compression_ratio": 1.871559633027523, "no_speech_prob": 6.240844413696323e-06}, {"id": 1404, "seek": 663358, "start": 6651.1, "end": 6658.98, "text": " But you probably don't want to the reason you probably don't want to is that there's a difference the convolutional layers all contain", "tokens": [583, 291, 1391, 500, 380, 528, 281, 264, 1778, 291, 1391, 500, 380, 528, 281, 307, 300, 456, 311, 257, 2649, 264, 45216, 304, 7914, 439, 5304], "temperature": 0.0, "avg_logprob": -0.17689856662545153, "compression_ratio": 1.871559633027523, "no_speech_prob": 6.240844413696323e-06}, {"id": 1405, "seek": 665898, "start": 6658.98, "end": 6665.299999999999, "text": " Pre-trained weights, so they're like they're not random for things that are close to image net", "tokens": [6001, 12, 17227, 2001, 17443, 11, 370, 436, 434, 411, 436, 434, 406, 4974, 337, 721, 300, 366, 1998, 281, 3256, 2533], "temperature": 0.0, "avg_logprob": -0.15345041950543722, "compression_ratio": 1.8640350877192982, "no_speech_prob": 1.1544593689905014e-06}, {"id": 1406, "seek": 665898, "start": 6665.299999999999, "end": 6669.82, "text": " They're actually really good for things that are not close to image net. They're better than nothing", "tokens": [814, 434, 767, 534, 665, 337, 721, 300, 366, 406, 1998, 281, 3256, 2533, 13, 814, 434, 1101, 813, 1825], "temperature": 0.0, "avg_logprob": -0.15345041950543722, "compression_ratio": 1.8640350877192982, "no_speech_prob": 1.1544593689905014e-06}, {"id": 1407, "seek": 665898, "start": 6671.379999999999, "end": 6674.879999999999, "text": " All of our fully connected layers, however are totally random", "tokens": [1057, 295, 527, 4498, 4582, 7914, 11, 4461, 366, 3879, 4974], "temperature": 0.0, "avg_logprob": -0.15345041950543722, "compression_ratio": 1.8640350877192982, "no_speech_prob": 1.1544593689905014e-06}, {"id": 1408, "seek": 665898, "start": 6676.299999999999, "end": 6683.0599999999995, "text": " So therefore you would always want to make the fully connected weights better than random by training them a bit first", "tokens": [407, 4412, 291, 576, 1009, 528, 281, 652, 264, 4498, 4582, 17443, 1101, 813, 4974, 538, 3097, 552, 257, 857, 700], "temperature": 0.0, "avg_logprob": -0.15345041950543722, "compression_ratio": 1.8640350877192982, "no_speech_prob": 1.1544593689905014e-06}, {"id": 1409, "seek": 665898, "start": 6683.58, "end": 6686.5, "text": " Because otherwise if you go straight to unfreeze", "tokens": [1436, 5911, 498, 291, 352, 2997, 281, 3971, 701, 1381], "temperature": 0.0, "avg_logprob": -0.15345041950543722, "compression_ratio": 1.8640350877192982, "no_speech_prob": 1.1544593689905014e-06}, {"id": 1410, "seek": 668650, "start": 6686.5, "end": 6688.74, "text": " Then you're actually going to be like", "tokens": [1396, 291, 434, 767, 516, 281, 312, 411], "temperature": 0.0, "avg_logprob": -0.2558720167293105, "compression_ratio": 1.5658536585365854, "no_speech_prob": 5.093642812425969e-06}, {"id": 1411, "seek": 668650, "start": 6689.34, "end": 6696.42, "text": " Fiddling around to those early early can early layer weights when the later ones are still random. That's probably not what you want. I", "tokens": [479, 14273, 1688, 926, 281, 729, 2440, 2440, 393, 2440, 4583, 17443, 562, 264, 1780, 2306, 366, 920, 4974, 13, 663, 311, 1391, 406, 437, 291, 528, 13, 286], "temperature": 0.0, "avg_logprob": -0.2558720167293105, "compression_ratio": 1.5658536585365854, "no_speech_prob": 5.093642812425969e-06}, {"id": 1412, "seek": 668650, "start": 6697.06, "end": 6699.06, "text": " Think there's another question here", "tokens": [6557, 456, 311, 1071, 1168, 510], "temperature": 0.0, "avg_logprob": -0.2558720167293105, "compression_ratio": 1.5658536585365854, "no_speech_prob": 5.093642812425969e-06}, {"id": 1413, "seek": 668650, "start": 6700.98, "end": 6702.98, "text": " So when we unfreeze", "tokens": [407, 562, 321, 3971, 701, 1381], "temperature": 0.0, "avg_logprob": -0.2558720167293105, "compression_ratio": 1.5658536585365854, "no_speech_prob": 5.093642812425969e-06}, {"id": 1414, "seek": 668650, "start": 6703.42, "end": 6705.42, "text": " What are the things?", "tokens": [708, 366, 264, 721, 30], "temperature": 0.0, "avg_logprob": -0.2558720167293105, "compression_ratio": 1.5658536585365854, "no_speech_prob": 5.093642812425969e-06}, {"id": 1415, "seek": 668650, "start": 6706.34, "end": 6708.34, "text": " We're trying to change there", "tokens": [492, 434, 1382, 281, 1319, 456], "temperature": 0.0, "avg_logprob": -0.2558720167293105, "compression_ratio": 1.5658536585365854, "no_speech_prob": 5.093642812425969e-06}, {"id": 1416, "seek": 668650, "start": 6709.3, "end": 6711.3, "text": " when it changed the", "tokens": [562, 309, 3105, 264], "temperature": 0.0, "avg_logprob": -0.2558720167293105, "compression_ratio": 1.5658536585365854, "no_speech_prob": 5.093642812425969e-06}, {"id": 1417, "seek": 668650, "start": 6711.58, "end": 6713.58, "text": " kernels themselves or", "tokens": [23434, 1625, 2969, 420], "temperature": 0.0, "avg_logprob": -0.2558720167293105, "compression_ratio": 1.5658536585365854, "no_speech_prob": 5.093642812425969e-06}, {"id": 1418, "seek": 671358, "start": 6713.58, "end": 6718.42, "text": " That that's always what SGD does. Yeah, so the only thing", "tokens": [663, 300, 311, 1009, 437, 34520, 35, 775, 13, 865, 11, 370, 264, 787, 551], "temperature": 0.0, "avg_logprob": -0.21323060989379883, "compression_ratio": 1.5971223021582734, "no_speech_prob": 1.9947215150750708e-06}, {"id": 1419, "seek": 671358, "start": 6719.0599999999995, "end": 6721.0599999999995, "text": " What training means is?", "tokens": [708, 3097, 1355, 307, 30], "temperature": 0.0, "avg_logprob": -0.21323060989379883, "compression_ratio": 1.5971223021582734, "no_speech_prob": 1.9947215150750708e-06}, {"id": 1420, "seek": 671358, "start": 6722.38, "end": 6724.38, "text": " setting these numbers", "tokens": [3287, 613, 3547], "temperature": 0.0, "avg_logprob": -0.21323060989379883, "compression_ratio": 1.5971223021582734, "no_speech_prob": 1.9947215150750708e-06}, {"id": 1421, "seek": 671358, "start": 6725.34, "end": 6727.34, "text": " right and", "tokens": [558, 293], "temperature": 0.0, "avg_logprob": -0.21323060989379883, "compression_ratio": 1.5971223021582734, "no_speech_prob": 1.9947215150750708e-06}, {"id": 1422, "seek": 671358, "start": 6728.78, "end": 6730.78, "text": " These numbers and", "tokens": [1981, 3547, 293], "temperature": 0.0, "avg_logprob": -0.21323060989379883, "compression_ratio": 1.5971223021582734, "no_speech_prob": 1.9947215150750708e-06}, {"id": 1423, "seek": 671358, "start": 6734.38, "end": 6736.54, "text": " These numbers the weights", "tokens": [1981, 3547, 264, 17443], "temperature": 0.0, "avg_logprob": -0.21323060989379883, "compression_ratio": 1.5971223021582734, "no_speech_prob": 1.9947215150750708e-06}, {"id": 1424, "seek": 671358, "start": 6737.5, "end": 6740.9, "text": " so the weights are the weights of the fully connected layers and", "tokens": [370, 264, 17443, 366, 264, 17443, 295, 264, 4498, 4582, 7914, 293], "temperature": 0.0, "avg_logprob": -0.21323060989379883, "compression_ratio": 1.5971223021582734, "no_speech_prob": 1.9947215150750708e-06}, {"id": 1425, "seek": 674090, "start": 6740.9, "end": 6746.179999999999, "text": " The weights in those kernels in the convolution, so that's what training means", "tokens": [440, 17443, 294, 729, 23434, 1625, 294, 264, 45216, 11, 370, 300, 311, 437, 3097, 1355], "temperature": 0.0, "avg_logprob": -0.24446703258313632, "compression_ratio": 1.634517766497462, "no_speech_prob": 1.4593679225072265e-06}, {"id": 1426, "seek": 674090, "start": 6746.62, "end": 6752.54, "text": " It's and we'll learn about how to do it with SGD, but training literally is setting those numbers", "tokens": [467, 311, 293, 321, 603, 1466, 466, 577, 281, 360, 309, 365, 34520, 35, 11, 457, 3097, 3736, 307, 3287, 729, 3547], "temperature": 0.0, "avg_logprob": -0.24446703258313632, "compression_ratio": 1.634517766497462, "no_speech_prob": 1.4593679225072265e-06}, {"id": 1427, "seek": 674090, "start": 6753.219999999999, "end": 6755.219999999999, "text": " These numbers on the other hand", "tokens": [1981, 3547, 322, 264, 661, 1011], "temperature": 0.0, "avg_logprob": -0.24446703258313632, "compression_ratio": 1.634517766497462, "no_speech_prob": 1.4593679225072265e-06}, {"id": 1428, "seek": 674090, "start": 6756.0199999999995, "end": 6762.7, "text": " Activations they're calculated. They're calculated from the weights and the previous layers", "tokens": [28550, 763, 436, 434, 15598, 13, 814, 434, 15598, 490, 264, 17443, 293, 264, 3894, 7914], "temperature": 0.0, "avg_logprob": -0.24446703258313632, "compression_ratio": 1.634517766497462, "no_speech_prob": 1.4593679225072265e-06}, {"id": 1429, "seek": 674090, "start": 6763.82, "end": 6765.82, "text": " activations or inputs", "tokens": [2430, 763, 420, 15743], "temperature": 0.0, "avg_logprob": -0.24446703258313632, "compression_ratio": 1.634517766497462, "no_speech_prob": 1.4593679225072265e-06}, {"id": 1430, "seek": 676582, "start": 6765.82, "end": 6773.04, "text": " I have a question so can you lift it up higher and speak about it? So in your example of a training a satellite image", "tokens": [286, 362, 257, 1168, 370, 393, 291, 5533, 309, 493, 2946, 293, 1710, 466, 309, 30, 407, 294, 428, 1365, 295, 257, 3097, 257, 16016, 3256], "temperature": 0.0, "avg_logprob": -0.4099172776745212, "compression_ratio": 1.6375545851528384, "no_speech_prob": 3.882884266204201e-05}, {"id": 1431, "seek": 676582, "start": 6774.7, "end": 6777.74, "text": " Examples are you starting with very small size access before yeah", "tokens": [48591, 366, 291, 2891, 365, 588, 1359, 2744, 2105, 949, 1338], "temperature": 0.0, "avg_logprob": -0.4099172776745212, "compression_ratio": 1.6375545851528384, "no_speech_prob": 3.882884266204201e-05}, {"id": 1432, "seek": 676582, "start": 6777.74, "end": 6785.0, "text": " So does it literally mean that you know the model takes a small area from the entire image that is 64 by 64?", "tokens": [407, 775, 309, 3736, 914, 300, 291, 458, 264, 2316, 2516, 257, 1359, 1859, 490, 264, 2302, 3256, 300, 307, 12145, 538, 12145, 30], "temperature": 0.0, "avg_logprob": -0.4099172776745212, "compression_ratio": 1.6375545851528384, "no_speech_prob": 3.882884266204201e-05}, {"id": 1433, "seek": 676582, "start": 6785.46, "end": 6789.74, "text": " So how do we get that 64 by 64 depends on?", "tokens": [407, 577, 360, 321, 483, 300, 12145, 538, 12145, 5946, 322, 30], "temperature": 0.0, "avg_logprob": -0.4099172776745212, "compression_ratio": 1.6375545851528384, "no_speech_prob": 3.882884266204201e-05}, {"id": 1434, "seek": 676582, "start": 6790.38, "end": 6792.299999999999, "text": " the transforms", "tokens": [264, 35592], "temperature": 0.0, "avg_logprob": -0.4099172776745212, "compression_ratio": 1.6375545851528384, "no_speech_prob": 3.882884266204201e-05}, {"id": 1435, "seek": 676582, "start": 6792.299999999999, "end": 6794.9, "text": " by default our transform", "tokens": [538, 7576, 527, 4088], "temperature": 0.0, "avg_logprob": -0.4099172776745212, "compression_ratio": 1.6375545851528384, "no_speech_prob": 3.882884266204201e-05}, {"id": 1436, "seek": 679490, "start": 6794.9, "end": 6796.9, "text": " takes the", "tokens": [2516, 264], "temperature": 0.0, "avg_logprob": -0.27827696152675296, "compression_ratio": 1.6082474226804124, "no_speech_prob": 2.60159617937461e-06}, {"id": 1437, "seek": 679490, "start": 6797.179999999999, "end": 6799.179999999999, "text": " smallest edge and", "tokens": [16998, 4691, 293], "temperature": 0.0, "avg_logprob": -0.27827696152675296, "compression_ratio": 1.6082474226804124, "no_speech_prob": 2.60159617937461e-06}, {"id": 1438, "seek": 679490, "start": 6799.94, "end": 6807.299999999999, "text": " Resight zooms the whole thing out resamples it so the smallest edge is the size 64 and then it takes a center crop", "tokens": [5015, 397, 5721, 4785, 264, 1379, 551, 484, 725, 335, 2622, 309, 370, 264, 16998, 4691, 307, 264, 2744, 12145, 293, 550, 309, 2516, 257, 3056, 9086], "temperature": 0.0, "avg_logprob": -0.27827696152675296, "compression_ratio": 1.6082474226804124, "no_speech_prob": 2.60159617937461e-06}, {"id": 1439, "seek": 679490, "start": 6807.94, "end": 6810.339999999999, "text": " of that okay, although", "tokens": [295, 300, 1392, 11, 4878], "temperature": 0.0, "avg_logprob": -0.27827696152675296, "compression_ratio": 1.6082474226804124, "no_speech_prob": 2.60159617937461e-06}, {"id": 1440, "seek": 679490, "start": 6812.0599999999995, "end": 6816.5, "text": " When we're using data augmentation it actually takes a randomly chosen", "tokens": [1133, 321, 434, 1228, 1412, 14501, 19631, 309, 767, 2516, 257, 16979, 8614], "temperature": 0.0, "avg_logprob": -0.27827696152675296, "compression_ratio": 1.6082474226804124, "no_speech_prob": 2.60159617937461e-06}, {"id": 1441, "seek": 679490, "start": 6817.5, "end": 6819.299999999999, "text": " crop", "tokens": [9086], "temperature": 0.0, "avg_logprob": -0.27827696152675296, "compression_ratio": 1.6082474226804124, "no_speech_prob": 2.60159617937461e-06}, {"id": 1442, "seek": 679490, "start": 6819.299999999999, "end": 6823.62, "text": " But in the case where the image has multiple objects like in this case", "tokens": [583, 294, 264, 1389, 689, 264, 3256, 575, 3866, 6565, 411, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.27827696152675296, "compression_ratio": 1.6082474226804124, "no_speech_prob": 2.60159617937461e-06}, {"id": 1443, "seek": 682362, "start": 6823.62, "end": 6825.54, "text": " like", "tokens": [411], "temperature": 0.0, "avg_logprob": -0.2866185313523418, "compression_ratio": 1.8177966101694916, "no_speech_prob": 1.3006683730054647e-05}, {"id": 1444, "seek": 682362, "start": 6825.54, "end": 6830.18, "text": " Would it be possible like you would just lose the other things that I tried to forget yeah", "tokens": [6068, 309, 312, 1944, 411, 291, 576, 445, 3624, 264, 661, 721, 300, 286, 3031, 281, 2870, 1338], "temperature": 0.0, "avg_logprob": -0.2866185313523418, "compression_ratio": 1.8177966101694916, "no_speech_prob": 1.3006683730054647e-05}, {"id": 1445, "seek": 682362, "start": 6830.18, "end": 6834.66, "text": " Which is why data augmentation is important so by and particularly their", "tokens": [3013, 307, 983, 1412, 14501, 19631, 307, 1021, 370, 538, 293, 4098, 641], "temperature": 0.0, "avg_logprob": -0.2866185313523418, "compression_ratio": 1.8177966101694916, "no_speech_prob": 1.3006683730054647e-05}, {"id": 1446, "seek": 682362, "start": 6835.14, "end": 6841.98, "text": " Test time augmentation is going to be particularly important because you would you wouldn't want to you know that there may be a", "tokens": [9279, 565, 14501, 19631, 307, 516, 281, 312, 4098, 1021, 570, 291, 576, 291, 2759, 380, 528, 281, 291, 458, 300, 456, 815, 312, 257], "temperature": 0.0, "avg_logprob": -0.2866185313523418, "compression_ratio": 1.8177966101694916, "no_speech_prob": 1.3006683730054647e-05}, {"id": 1447, "seek": 682362, "start": 6842.5, "end": 6849.94, "text": " Artisanal mine out in the corner which if you take a center crop you you don't see so data augmentation becomes very important", "tokens": [5735, 14804, 304, 3892, 484, 294, 264, 4538, 597, 498, 291, 747, 257, 3056, 9086, 291, 291, 500, 380, 536, 370, 1412, 14501, 19631, 3643, 588, 1021], "temperature": 0.0, "avg_logprob": -0.2866185313523418, "compression_ratio": 1.8177966101694916, "no_speech_prob": 1.3006683730054647e-05}, {"id": 1448, "seek": 682362, "start": 6850.26, "end": 6852.26, "text": " Yeah", "tokens": [865], "temperature": 0.0, "avg_logprob": -0.2866185313523418, "compression_ratio": 1.8177966101694916, "no_speech_prob": 1.3006683730054647e-05}, {"id": 1449, "seek": 685226, "start": 6852.26, "end": 6854.26, "text": " One other question so", "tokens": [1485, 661, 1168, 370], "temperature": 0.0, "avg_logprob": -0.30077610763848994, "compression_ratio": 1.6746987951807228, "no_speech_prob": 4.610996984411031e-05}, {"id": 1450, "seek": 685226, "start": 6854.860000000001, "end": 6858.84, "text": " So when we talk about metrics like either is our here see the floor or f2", "tokens": [407, 562, 321, 751, 466, 16367, 411, 2139, 307, 527, 510, 536, 264, 4123, 420, 283, 17], "temperature": 0.0, "avg_logprob": -0.30077610763848994, "compression_ratio": 1.6746987951807228, "no_speech_prob": 4.610996984411031e-05}, {"id": 1451, "seek": 685226, "start": 6859.820000000001, "end": 6864.62, "text": " That's not really what the model tries to that's a great point. That's not the loss function", "tokens": [663, 311, 406, 534, 437, 264, 2316, 9898, 281, 300, 311, 257, 869, 935, 13, 663, 311, 406, 264, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.30077610763848994, "compression_ratio": 1.6746987951807228, "no_speech_prob": 4.610996984411031e-05}, {"id": 1452, "seek": 685226, "start": 6864.62, "end": 6868.4400000000005, "text": " Yeah, right the loss function is something. We'll be learning about next week", "tokens": [865, 11, 558, 264, 4470, 2445, 307, 746, 13, 492, 603, 312, 2539, 466, 958, 1243], "temperature": 0.0, "avg_logprob": -0.30077610763848994, "compression_ratio": 1.6746987951807228, "no_speech_prob": 4.610996984411031e-05}, {"id": 1453, "seek": 685226, "start": 6868.9800000000005, "end": 6874.3, "text": " And it uses cross entropy or otherwise known as like negative log likelihood", "tokens": [400, 309, 4960, 3278, 30867, 420, 5911, 2570, 382, 411, 3671, 3565, 22119], "temperature": 0.0, "avg_logprob": -0.30077610763848994, "compression_ratio": 1.6746987951807228, "no_speech_prob": 4.610996984411031e-05}, {"id": 1454, "seek": 685226, "start": 6876.1, "end": 6879.900000000001, "text": " The metric is just the thing that's printed so we can see what's going on", "tokens": [440, 20678, 307, 445, 264, 551, 300, 311, 13567, 370, 321, 393, 536, 437, 311, 516, 322], "temperature": 0.0, "avg_logprob": -0.30077610763848994, "compression_ratio": 1.6746987951807228, "no_speech_prob": 4.610996984411031e-05}, {"id": 1455, "seek": 687990, "start": 6879.9, "end": 6881.58, "text": " just", "tokens": [445], "temperature": 0.0, "avg_logprob": -0.2761047322263, "compression_ratio": 1.7251184834123223, "no_speech_prob": 5.6822750593710225e-06}, {"id": 1456, "seek": 687990, "start": 6881.58, "end": 6883.5, "text": " next year", "tokens": [958, 1064], "temperature": 0.0, "avg_logprob": -0.2761047322263, "compression_ratio": 1.7251184834123223, "no_speech_prob": 5.6822750593710225e-06}, {"id": 1457, "seek": 687990, "start": 6883.5, "end": 6885.98, "text": " So in the context of multi class", "tokens": [407, 294, 264, 4319, 295, 4825, 1508], "temperature": 0.0, "avg_logprob": -0.2761047322263, "compression_ratio": 1.7251184834123223, "no_speech_prob": 5.6822750593710225e-06}, {"id": 1458, "seek": 687990, "start": 6886.58, "end": 6893.28, "text": " Modeling cannot training data does a training data also have to be multiclass or can I train on just like images of pure cats and", "tokens": [6583, 11031, 2644, 3097, 1412, 775, 257, 3097, 1412, 611, 362, 281, 312, 30608, 14549, 420, 393, 286, 3847, 322, 445, 411, 5267, 295, 6075, 11111, 293], "temperature": 0.0, "avg_logprob": -0.2761047322263, "compression_ratio": 1.7251184834123223, "no_speech_prob": 5.6822750593710225e-06}, {"id": 1459, "seek": 687990, "start": 6893.28, "end": 6895.42, "text": " pure dogs and expect it at prediction time to", "tokens": [6075, 7197, 293, 2066, 309, 412, 17630, 565, 281], "temperature": 0.0, "avg_logprob": -0.2761047322263, "compression_ratio": 1.7251184834123223, "no_speech_prob": 5.6822750593710225e-06}, {"id": 1460, "seek": 687990, "start": 6896.259999999999, "end": 6898.9, "text": " Predict if I give it a picture of both having cat and a dog", "tokens": [430, 24945, 498, 286, 976, 309, 257, 3036, 295, 1293, 1419, 3857, 293, 257, 3000], "temperature": 0.0, "avg_logprob": -0.2761047322263, "compression_ratio": 1.7251184834123223, "no_speech_prob": 5.6822750593710225e-06}, {"id": 1461, "seek": 689890, "start": 6898.9, "end": 6908.139999999999, "text": " I've never tried that and I've never seen an example of something that needed it I", "tokens": [286, 600, 1128, 3031, 300, 293, 286, 600, 1128, 1612, 364, 1365, 295, 746, 300, 2978, 309, 286], "temperature": 0.0, "avg_logprob": -0.2063171342871655, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.3709501445191563e-06}, {"id": 1462, "seek": 689890, "start": 6910.179999999999, "end": 6912.339999999999, "text": " Guess conceptually there's no reason it wouldn't work", "tokens": [17795, 3410, 671, 456, 311, 572, 1778, 309, 2759, 380, 589], "temperature": 0.0, "avg_logprob": -0.2063171342871655, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.3709501445191563e-06}, {"id": 1463, "seek": 689890, "start": 6913.74, "end": 6915.74, "text": " But it's kind of out there", "tokens": [583, 309, 311, 733, 295, 484, 456], "temperature": 0.0, "avg_logprob": -0.2063171342871655, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.3709501445191563e-06}, {"id": 1464, "seek": 689890, "start": 6916.139999999999, "end": 6920.339999999999, "text": " And you still use a sigmoid activation you would have to make sure you're using a sigmoid loss function", "tokens": [400, 291, 920, 764, 257, 4556, 3280, 327, 24433, 291, 576, 362, 281, 652, 988, 291, 434, 1228, 257, 4556, 3280, 327, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.2063171342871655, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.3709501445191563e-06}, {"id": 1465, "seek": 689890, "start": 6920.339999999999, "end": 6923.94, "text": " So in this case fast AI's default would not work because by default fast", "tokens": [407, 294, 341, 1389, 2370, 7318, 311, 7576, 576, 406, 589, 570, 538, 7576, 2370], "temperature": 0.0, "avg_logprob": -0.2063171342871655, "compression_ratio": 1.619047619047619, "no_speech_prob": 1.3709501445191563e-06}, {"id": 1466, "seek": 692394, "start": 6923.94, "end": 6929.259999999999, "text": " I would say your training data never has both a cat and a dog so you would have to override the loss function", "tokens": [286, 576, 584, 428, 3097, 1412, 1128, 575, 1293, 257, 3857, 293, 257, 3000, 370, 291, 576, 362, 281, 42321, 264, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.18235800425211587, "compression_ratio": 1.5637254901960784, "no_speech_prob": 4.495160737860715e-06}, {"id": 1467, "seek": 692394, "start": 6935.86, "end": 6938.099999999999, "text": " When you use the differential learning rates", "tokens": [1133, 291, 764, 264, 15756, 2539, 6846], "temperature": 0.0, "avg_logprob": -0.18235800425211587, "compression_ratio": 1.5637254901960784, "no_speech_prob": 4.495160737860715e-06}, {"id": 1468, "seek": 692394, "start": 6938.82, "end": 6943.419999999999, "text": " Those three learning rates do they just kind of spread evenly across the layers", "tokens": [3950, 1045, 2539, 6846, 360, 436, 445, 733, 295, 3974, 17658, 2108, 264, 7914], "temperature": 0.0, "avg_logprob": -0.18235800425211587, "compression_ratio": 1.5637254901960784, "no_speech_prob": 4.495160737860715e-06}, {"id": 1469, "seek": 692394, "start": 6944.179999999999, "end": 6949.339999999999, "text": " Yeah, we'll talk more about this later in the course, but I'm in the fast AI library", "tokens": [865, 11, 321, 603, 751, 544, 466, 341, 1780, 294, 264, 1164, 11, 457, 286, 478, 294, 264, 2370, 7318, 6405], "temperature": 0.0, "avg_logprob": -0.18235800425211587, "compression_ratio": 1.5637254901960784, "no_speech_prob": 4.495160737860715e-06}, {"id": 1470, "seek": 694934, "start": 6949.34, "end": 6954.62, "text": " There's a concept of layer groups so in something like a resonant 50", "tokens": [821, 311, 257, 3410, 295, 4583, 3935, 370, 294, 746, 411, 257, 12544, 394, 2625], "temperature": 0.0, "avg_logprob": -0.18842267990112305, "compression_ratio": 1.6388888888888888, "no_speech_prob": 5.173872523300815e-06}, {"id": 1471, "seek": 694934, "start": 6954.62, "end": 6960.9400000000005, "text": " You know there's hundreds of layers, and I figured you don't want to write down hundreds of learning rates, so I've", "tokens": [509, 458, 456, 311, 6779, 295, 7914, 11, 293, 286, 8932, 291, 500, 380, 528, 281, 2464, 760, 6779, 295, 2539, 6846, 11, 370, 286, 600], "temperature": 0.0, "avg_logprob": -0.18842267990112305, "compression_ratio": 1.6388888888888888, "no_speech_prob": 5.173872523300815e-06}, {"id": 1472, "seek": 694934, "start": 6961.58, "end": 6964.42, "text": " basically decided for you how to split them and", "tokens": [1936, 3047, 337, 291, 577, 281, 7472, 552, 293], "temperature": 0.0, "avg_logprob": -0.18842267990112305, "compression_ratio": 1.6388888888888888, "no_speech_prob": 5.173872523300815e-06}, {"id": 1473, "seek": 694934, "start": 6965.14, "end": 6968.84, "text": " the the last one always refers just to the", "tokens": [264, 264, 1036, 472, 1009, 14942, 445, 281, 264], "temperature": 0.0, "avg_logprob": -0.18842267990112305, "compression_ratio": 1.6388888888888888, "no_speech_prob": 5.173872523300815e-06}, {"id": 1474, "seek": 694934, "start": 6969.26, "end": 6976.88, "text": " Fully connected layers that we've randomly initialized and added to the end and then these ones are split generally about halfway through", "tokens": [479, 2150, 4582, 7914, 300, 321, 600, 16979, 5883, 1602, 293, 3869, 281, 264, 917, 293, 550, 613, 2306, 366, 7472, 5101, 466, 15461, 807], "temperature": 0.0, "avg_logprob": -0.18842267990112305, "compression_ratio": 1.6388888888888888, "no_speech_prob": 5.173872523300815e-06}, {"id": 1475, "seek": 697688, "start": 6976.88, "end": 6978.32, "text": " to", "tokens": [281], "temperature": 0.0, "avg_logprob": -0.16818875074386597, "compression_ratio": 1.7971530249110321, "no_speech_prob": 8.801033800409641e-06}, {"id": 1476, "seek": 697688, "start": 6978.32, "end": 6980.32, "text": " basically I've tried to make it so that", "tokens": [1936, 286, 600, 3031, 281, 652, 309, 370, 300], "temperature": 0.0, "avg_logprob": -0.16818875074386597, "compression_ratio": 1.7971530249110321, "no_speech_prob": 8.801033800409641e-06}, {"id": 1477, "seek": 697688, "start": 6980.52, "end": 6985.88, "text": " these you know these ones are kind of the ones which you hardly want to change at all and these are the ones you might want", "tokens": [613, 291, 458, 613, 2306, 366, 733, 295, 264, 2306, 597, 291, 13572, 528, 281, 1319, 412, 439, 293, 613, 366, 264, 2306, 291, 1062, 528], "temperature": 0.0, "avg_logprob": -0.16818875074386597, "compression_ratio": 1.7971530249110321, "no_speech_prob": 8.801033800409641e-06}, {"id": 1478, "seek": 697688, "start": 6985.88, "end": 6987.88, "text": " to change a little bit and", "tokens": [281, 1319, 257, 707, 857, 293], "temperature": 0.0, "avg_logprob": -0.16818875074386597, "compression_ratio": 1.7971530249110321, "no_speech_prob": 8.801033800409641e-06}, {"id": 1479, "seek": 697688, "start": 6988.0, "end": 6989.4800000000005, "text": " I don't think we'll cover it in the course", "tokens": [286, 500, 380, 519, 321, 603, 2060, 309, 294, 264, 1164], "temperature": 0.0, "avg_logprob": -0.16818875074386597, "compression_ratio": 1.7971530249110321, "no_speech_prob": 8.801033800409641e-06}, {"id": 1480, "seek": 697688, "start": 6989.4800000000005, "end": 6994.4400000000005, "text": " But if you're interested we can talk about in the forum there are ways you can override this behavior to define your own way", "tokens": [583, 498, 291, 434, 3102, 321, 393, 751, 466, 294, 264, 17542, 456, 366, 2098, 291, 393, 42321, 341, 5223, 281, 6964, 428, 1065, 636], "temperature": 0.0, "avg_logprob": -0.16818875074386597, "compression_ratio": 1.7971530249110321, "no_speech_prob": 8.801033800409641e-06}, {"id": 1481, "seek": 697688, "start": 6994.4400000000005, "end": 7001.84, "text": " Of groups if you want to and is there any way to visualize the model easily or like dump dump the layers of the model?", "tokens": [2720, 3935, 498, 291, 528, 281, 293, 307, 456, 604, 636, 281, 23273, 264, 2316, 3612, 420, 411, 11430, 11430, 264, 7914, 295, 264, 2316, 30], "temperature": 0.0, "avg_logprob": -0.16818875074386597, "compression_ratio": 1.7971530249110321, "no_speech_prob": 8.801033800409641e-06}, {"id": 1482, "seek": 697688, "start": 7002.32, "end": 7003.96, "text": " Yeah, absolutely", "tokens": [865, 11, 3122], "temperature": 0.0, "avg_logprob": -0.16818875074386597, "compression_ratio": 1.7971530249110321, "no_speech_prob": 8.801033800409641e-06}, {"id": 1483, "seek": 700396, "start": 7003.96, "end": 7007.6, "text": " You can let's make sure we've got one here", "tokens": [509, 393, 718, 311, 652, 988, 321, 600, 658, 472, 510], "temperature": 0.0, "avg_logprob": -0.22513524373372396, "compression_ratio": 1.4819277108433735, "no_speech_prob": 4.09287622460397e-06}, {"id": 1484, "seek": 700396, "start": 7008.52, "end": 7010.52, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.22513524373372396, "compression_ratio": 1.4819277108433735, "no_speech_prob": 4.09287622460397e-06}, {"id": 1485, "seek": 700396, "start": 7011.1, "end": 7016.88, "text": " So if you just type learn it doesn't tell you much at all, but what you can do is go", "tokens": [407, 498, 291, 445, 2010, 1466, 309, 1177, 380, 980, 291, 709, 412, 439, 11, 457, 437, 291, 393, 360, 307, 352], "temperature": 0.0, "avg_logprob": -0.22513524373372396, "compression_ratio": 1.4819277108433735, "no_speech_prob": 4.09287622460397e-06}, {"id": 1486, "seek": 700396, "start": 7018.0, "end": 7020.0, "text": " learn dot summary and", "tokens": [1466, 5893, 12691, 293], "temperature": 0.0, "avg_logprob": -0.22513524373372396, "compression_ratio": 1.4819277108433735, "no_speech_prob": 4.09287622460397e-06}, {"id": 1487, "seek": 700396, "start": 7022.04, "end": 7024.04, "text": " That spits out", "tokens": [663, 637, 1208, 484], "temperature": 0.0, "avg_logprob": -0.22513524373372396, "compression_ratio": 1.4819277108433735, "no_speech_prob": 4.09287622460397e-06}, {"id": 1488, "seek": 700396, "start": 7024.36, "end": 7025.68, "text": " basically", "tokens": [1936], "temperature": 0.0, "avg_logprob": -0.22513524373372396, "compression_ratio": 1.4819277108433735, "no_speech_prob": 4.09287622460397e-06}, {"id": 1489, "seek": 700396, "start": 7025.68, "end": 7027.08, "text": " everything", "tokens": [1203], "temperature": 0.0, "avg_logprob": -0.22513524373372396, "compression_ratio": 1.4819277108433735, "no_speech_prob": 4.09287622460397e-06}, {"id": 1490, "seek": 700396, "start": 7027.08, "end": 7030.08, "text": " There's all the letters and so you can see in this case", "tokens": [821, 311, 439, 264, 7825, 293, 370, 291, 393, 536, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.22513524373372396, "compression_ratio": 1.4819277108433735, "no_speech_prob": 4.09287622460397e-06}, {"id": 1491, "seek": 703008, "start": 7030.08, "end": 7037.32, "text": " These are the names I mentioned how they all got names right so the first layer is called conv 2d-1", "tokens": [1981, 366, 264, 5288, 286, 2835, 577, 436, 439, 658, 5288, 558, 370, 264, 700, 4583, 307, 1219, 3754, 568, 67, 12, 16], "temperature": 0.0, "avg_logprob": -0.2016293111473623, "compression_ratio": 1.6523605150214593, "no_speech_prob": 4.092882591066882e-06}, {"id": 1492, "seek": 703008, "start": 7038.16, "end": 7040.16, "text": " And it's going to take his input", "tokens": [400, 309, 311, 516, 281, 747, 702, 4846], "temperature": 0.0, "avg_logprob": -0.2016293111473623, "compression_ratio": 1.6523605150214593, "no_speech_prob": 4.092882591066882e-06}, {"id": 1493, "seek": 703008, "start": 7041.24, "end": 7047.12, "text": " This is useful to actually look at it's taking 64 by 64 images, which is what we told it", "tokens": [639, 307, 4420, 281, 767, 574, 412, 309, 311, 1940, 12145, 538, 12145, 5267, 11, 597, 307, 437, 321, 1907, 309], "temperature": 0.0, "avg_logprob": -0.2016293111473623, "compression_ratio": 1.6523605150214593, "no_speech_prob": 4.092882591066882e-06}, {"id": 1494, "seek": 703008, "start": 7047.12, "end": 7050.76, "text": " We're going to transform things to this is three channels pi torch", "tokens": [492, 434, 516, 281, 4088, 721, 281, 341, 307, 1045, 9235, 3895, 27822], "temperature": 0.0, "avg_logprob": -0.2016293111473623, "compression_ratio": 1.6523605150214593, "no_speech_prob": 4.092882591066882e-06}, {"id": 1495, "seek": 703008, "start": 7052.28, "end": 7058.76, "text": " Like most things have channels at the end would say 64 by 64 by 3 pi torch moves it to the front", "tokens": [1743, 881, 721, 362, 9235, 412, 264, 917, 576, 584, 12145, 538, 12145, 538, 805, 3895, 27822, 6067, 309, 281, 264, 1868], "temperature": 0.0, "avg_logprob": -0.2016293111473623, "compression_ratio": 1.6523605150214593, "no_speech_prob": 4.092882591066882e-06}, {"id": 1496, "seek": 705876, "start": 7058.76, "end": 7064.400000000001, "text": " So it's 3 by 64 by 64. That's because it turns out that some of the GPU", "tokens": [407, 309, 311, 805, 538, 12145, 538, 12145, 13, 663, 311, 570, 309, 4523, 484, 300, 512, 295, 264, 18407], "temperature": 0.0, "avg_logprob": -0.22307102950577884, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.4593715604860336e-06}, {"id": 1497, "seek": 705876, "start": 7064.76, "end": 7071.72, "text": " Computations run faster when it's in that order okay, but that happens all behind the scenes automatically so part of that transformation", "tokens": [37804, 763, 1190, 4663, 562, 309, 311, 294, 300, 1668, 1392, 11, 457, 300, 2314, 439, 2261, 264, 8026, 6772, 370, 644, 295, 300, 9887], "temperature": 0.0, "avg_logprob": -0.22307102950577884, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.4593715604860336e-06}, {"id": 1498, "seek": 705876, "start": 7072.320000000001, "end": 7075.360000000001, "text": " Stuff that's kind of all done automatically is to do that", "tokens": [31347, 300, 311, 733, 295, 439, 1096, 6772, 307, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.22307102950577884, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.4593715604860336e-06}, {"id": 1499, "seek": 705876, "start": 7076.8, "end": 7078.6, "text": " minus 1", "tokens": [3175, 502], "temperature": 0.0, "avg_logprob": -0.22307102950577884, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.4593715604860336e-06}, {"id": 1500, "seek": 705876, "start": 7078.6, "end": 7081.52, "text": " Means however however big the batch size is", "tokens": [40290, 4461, 4461, 955, 264, 15245, 2744, 307], "temperature": 0.0, "avg_logprob": -0.22307102950577884, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.4593715604860336e-06}, {"id": 1501, "seek": 705876, "start": 7082.280000000001, "end": 7088.1, "text": " In Keras they use the number they use a special number none in pi torch", "tokens": [682, 591, 6985, 436, 764, 264, 1230, 436, 764, 257, 2121, 1230, 6022, 294, 3895, 27822], "temperature": 0.0, "avg_logprob": -0.22307102950577884, "compression_ratio": 1.6359832635983265, "no_speech_prob": 1.4593715604860336e-06}, {"id": 1502, "seek": 708810, "start": 7088.1, "end": 7091.88, "text": " They use minus 1 so this is a four dimensional mini batch", "tokens": [814, 764, 3175, 502, 370, 341, 307, 257, 1451, 18795, 8382, 15245], "temperature": 0.0, "avg_logprob": -0.20873340340547783, "compression_ratio": 1.74, "no_speech_prob": 1.5779554587425082e-06}, {"id": 1503, "seek": 708810, "start": 7092.64, "end": 7094.400000000001, "text": " the number of", "tokens": [264, 1230, 295], "temperature": 0.0, "avg_logprob": -0.20873340340547783, "compression_ratio": 1.74, "no_speech_prob": 1.5779554587425082e-06}, {"id": 1504, "seek": 708810, "start": 7094.400000000001, "end": 7100.700000000001, "text": " Elements in the number of images in the image mini batch is dynamic you can change that the number of channels is three", "tokens": [8024, 1117, 294, 264, 1230, 295, 5267, 294, 264, 3256, 8382, 15245, 307, 8546, 291, 393, 1319, 300, 264, 1230, 295, 9235, 307, 1045], "temperature": 0.0, "avg_logprob": -0.20873340340547783, "compression_ratio": 1.74, "no_speech_prob": 1.5779554587425082e-06}, {"id": 1505, "seek": 708810, "start": 7101.04, "end": 7108.780000000001, "text": " Number of images is 64 by 64 okay, and so then you can basically see that this particular convolutional kernel", "tokens": [5118, 295, 5267, 307, 12145, 538, 12145, 1392, 11, 293, 370, 550, 291, 393, 1936, 536, 300, 341, 1729, 45216, 304, 28256], "temperature": 0.0, "avg_logprob": -0.20873340340547783, "compression_ratio": 1.74, "no_speech_prob": 1.5779554587425082e-06}, {"id": 1506, "seek": 708810, "start": 7109.76, "end": 7111.76, "text": " Apparently has 64 kernels in it", "tokens": [16755, 575, 12145, 23434, 1625, 294, 309], "temperature": 0.0, "avg_logprob": -0.20873340340547783, "compression_ratio": 1.74, "no_speech_prob": 1.5779554587425082e-06}, {"id": 1507, "seek": 708810, "start": 7112.280000000001, "end": 7113.92, "text": " And it's also", "tokens": [400, 309, 311, 611], "temperature": 0.0, "avg_logprob": -0.20873340340547783, "compression_ratio": 1.74, "no_speech_prob": 1.5779554587425082e-06}, {"id": 1508, "seek": 711392, "start": 7113.92, "end": 7120.06, "text": " Halving we haven't talked about this but convolutions can have something called a stride that it's like max pooling the changes the size", "tokens": [13896, 798, 321, 2378, 380, 2825, 466, 341, 457, 3754, 15892, 393, 362, 746, 1219, 257, 1056, 482, 300, 309, 311, 411, 11469, 7005, 278, 264, 2962, 264, 2744], "temperature": 0.0, "avg_logprob": -0.247652462550572, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.86276928515872e-06}, {"id": 1509, "seek": 711392, "start": 7120.28, "end": 7124.84, "text": " So it's returning a 32 by 32 by 64 kernel", "tokens": [407, 309, 311, 12678, 257, 8858, 538, 8858, 538, 12145, 28256], "temperature": 0.0, "avg_logprob": -0.247652462550572, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.86276928515872e-06}, {"id": 1510, "seek": 711392, "start": 7125.84, "end": 7128.2, "text": " tensor and so on and so forth", "tokens": [40863, 293, 370, 322, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.247652462550572, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.86276928515872e-06}, {"id": 1511, "seek": 711392, "start": 7130.0, "end": 7136.08, "text": " So that summary and we'll learn all about what that's doing in detail in the second half of the course", "tokens": [407, 300, 12691, 293, 321, 603, 1466, 439, 466, 437, 300, 311, 884, 294, 2607, 294, 264, 1150, 1922, 295, 264, 1164], "temperature": 0.0, "avg_logprob": -0.247652462550572, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.86276928515872e-06}, {"id": 1512, "seek": 711392, "start": 7137.16, "end": 7139.16, "text": " one more I", "tokens": [472, 544, 286], "temperature": 0.0, "avg_logprob": -0.247652462550572, "compression_ratio": 1.5707317073170732, "no_speech_prob": 5.86276928515872e-06}, {"id": 1513, "seek": 713916, "start": 7139.16, "end": 7144.76, "text": " Collected my own data set and I try to use the it is a really small data set these currencies from", "tokens": [31896, 292, 452, 1065, 1412, 992, 293, 286, 853, 281, 764, 264, 309, 307, 257, 534, 1359, 1412, 992, 613, 36886, 490], "temperature": 0.0, "avg_logprob": -0.17785628367278536, "compression_ratio": 1.7613636363636365, "no_speech_prob": 1.6797133639556705e-06}, {"id": 1514, "seek": 713916, "start": 7145.28, "end": 7147.68, "text": " Google images, and I tried to do a", "tokens": [3329, 5267, 11, 293, 286, 3031, 281, 360, 257], "temperature": 0.0, "avg_logprob": -0.17785628367278536, "compression_ratio": 1.7613636363636365, "no_speech_prob": 1.6797133639556705e-06}, {"id": 1515, "seek": 713916, "start": 7148.44, "end": 7155.0199999999995, "text": " Learning rate find and then the plot and it just it gave me some numbers which I didn't understand on the learning rate font", "tokens": [15205, 3314, 915, 293, 550, 264, 7542, 293, 309, 445, 309, 2729, 385, 512, 3547, 597, 286, 994, 380, 1223, 322, 264, 2539, 3314, 10703], "temperature": 0.0, "avg_logprob": -0.17785628367278536, "compression_ratio": 1.7613636363636365, "no_speech_prob": 1.6797133639556705e-06}, {"id": 1516, "seek": 713916, "start": 7155.0199999999995, "end": 7160.5199999999995, "text": " Yeah, and then the plot was empty so yeah, I mean let's let's talk about that on the forum, but basically", "tokens": [865, 11, 293, 550, 264, 7542, 390, 6707, 370, 1338, 11, 286, 914, 718, 311, 718, 311, 751, 466, 300, 322, 264, 17542, 11, 457, 1936], "temperature": 0.0, "avg_logprob": -0.17785628367278536, "compression_ratio": 1.7613636363636365, "no_speech_prob": 1.6797133639556705e-06}, {"id": 1517, "seek": 713916, "start": 7161.04, "end": 7166.48, "text": " The learning rate finder is going to go through a mini batch at a time if you've got a tiny data set", "tokens": [440, 2539, 3314, 915, 260, 307, 516, 281, 352, 807, 257, 8382, 15245, 412, 257, 565, 498, 291, 600, 658, 257, 5870, 1412, 992], "temperature": 0.0, "avg_logprob": -0.17785628367278536, "compression_ratio": 1.7613636363636365, "no_speech_prob": 1.6797133639556705e-06}, {"id": 1518, "seek": 716648, "start": 7166.48, "end": 7171.799999999999, "text": " There's just not enough mini batches so the trick is to make your mini that it makes your batch size really small", "tokens": [821, 311, 445, 406, 1547, 8382, 15245, 279, 370, 264, 4282, 307, 281, 652, 428, 8382, 300, 309, 1669, 428, 15245, 2744, 534, 1359], "temperature": 0.0, "avg_logprob": -0.19425404590109122, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.611956799431937e-06}, {"id": 1519, "seek": 716648, "start": 7171.959999999999, "end": 7173.959999999999, "text": " Like try making it like four or eight", "tokens": [1743, 853, 1455, 309, 411, 1451, 420, 3180], "temperature": 0.0, "avg_logprob": -0.19425404590109122, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.611956799431937e-06}, {"id": 1520, "seek": 716648, "start": 7178.759999999999, "end": 7181.959999999999, "text": " Okay, they were great questions nothing online to add in it", "tokens": [1033, 11, 436, 645, 869, 1651, 1825, 2950, 281, 909, 294, 309], "temperature": 0.0, "avg_logprob": -0.19425404590109122, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.611956799431937e-06}, {"id": 1521, "seek": 716648, "start": 7183.879999999999, "end": 7189.16, "text": " They were great questions we've got a little bit past where I hope to but let's let's quickly talk about", "tokens": [814, 645, 869, 1651, 321, 600, 658, 257, 707, 857, 1791, 689, 286, 1454, 281, 457, 718, 311, 718, 311, 2661, 751, 466], "temperature": 0.0, "avg_logprob": -0.19425404590109122, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.611956799431937e-06}, {"id": 1522, "seek": 716648, "start": 7190.24, "end": 7192.879999999999, "text": " Structured data so we can start thinking about it for next week", "tokens": [745, 46847, 1412, 370, 321, 393, 722, 1953, 466, 309, 337, 958, 1243], "temperature": 0.0, "avg_logprob": -0.19425404590109122, "compression_ratio": 1.6521739130434783, "no_speech_prob": 3.611956799431937e-06}, {"id": 1523, "seek": 719288, "start": 7192.88, "end": 7194.88, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.24808413946806496, "compression_ratio": 1.60625, "no_speech_prob": 1.2098607840016484e-06}, {"id": 1524, "seek": 719288, "start": 7197.76, "end": 7203.36, "text": " This is really weird right to me there's basically two types of data set we use in machine learning", "tokens": [639, 307, 534, 3657, 558, 281, 385, 456, 311, 1936, 732, 3467, 295, 1412, 992, 321, 764, 294, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.24808413946806496, "compression_ratio": 1.60625, "no_speech_prob": 1.2098607840016484e-06}, {"id": 1525, "seek": 719288, "start": 7203.56, "end": 7206.6, "text": " There's a type of data like audio", "tokens": [821, 311, 257, 2010, 295, 1412, 411, 6278], "temperature": 0.0, "avg_logprob": -0.24808413946806496, "compression_ratio": 1.60625, "no_speech_prob": 1.2098607840016484e-06}, {"id": 1526, "seek": 719288, "start": 7208.16, "end": 7209.76, "text": " images", "tokens": [5267], "temperature": 0.0, "avg_logprob": -0.24808413946806496, "compression_ratio": 1.60625, "no_speech_prob": 1.2098607840016484e-06}, {"id": 1527, "seek": 719288, "start": 7209.76, "end": 7211.76, "text": " natural language text", "tokens": [3303, 2856, 2487], "temperature": 0.0, "avg_logprob": -0.24808413946806496, "compression_ratio": 1.60625, "no_speech_prob": 1.2098607840016484e-06}, {"id": 1528, "seek": 719288, "start": 7211.84, "end": 7217.92, "text": " Where all of the all of the things inside an object like all of the pixels inside an image?", "tokens": [2305, 439, 295, 264, 439, 295, 264, 721, 1854, 364, 2657, 411, 439, 295, 264, 18668, 1854, 364, 3256, 30], "temperature": 0.0, "avg_logprob": -0.24808413946806496, "compression_ratio": 1.60625, "no_speech_prob": 1.2098607840016484e-06}, {"id": 1529, "seek": 721792, "start": 7217.92, "end": 7222.92, "text": " Are all the same kind of thing they're all pixels or they're all?", "tokens": [2014, 439, 264, 912, 733, 295, 551, 436, 434, 439, 18668, 420, 436, 434, 439, 30], "temperature": 0.0, "avg_logprob": -0.22397616068522136, "compression_ratio": 1.5919540229885059, "no_speech_prob": 3.785312173931743e-06}, {"id": 1530, "seek": 721792, "start": 7223.8, "end": 7225.8, "text": " amplitudes of a waveform or", "tokens": [9731, 16451, 295, 257, 36512, 420], "temperature": 0.0, "avg_logprob": -0.22397616068522136, "compression_ratio": 1.5919540229885059, "no_speech_prob": 3.785312173931743e-06}, {"id": 1531, "seek": 721792, "start": 7226.2, "end": 7228.2, "text": " They're all words", "tokens": [814, 434, 439, 2283], "temperature": 0.0, "avg_logprob": -0.22397616068522136, "compression_ratio": 1.5919540229885059, "no_speech_prob": 3.785312173931743e-06}, {"id": 1532, "seek": 721792, "start": 7228.4, "end": 7234.16, "text": " I call this kind of data unstructured and then there's data sets like a", "tokens": [286, 818, 341, 733, 295, 1412, 18799, 46847, 293, 550, 456, 311, 1412, 6352, 411, 257], "temperature": 0.0, "avg_logprob": -0.22397616068522136, "compression_ratio": 1.5919540229885059, "no_speech_prob": 3.785312173931743e-06}, {"id": 1533, "seek": 721792, "start": 7235.04, "end": 7237.04, "text": " profit and loss statement or", "tokens": [7475, 293, 4470, 5629, 420], "temperature": 0.0, "avg_logprob": -0.22397616068522136, "compression_ratio": 1.5919540229885059, "no_speech_prob": 3.785312173931743e-06}, {"id": 1534, "seek": 721792, "start": 7237.72, "end": 7239.72, "text": " the information about a Facebook user", "tokens": [264, 1589, 466, 257, 4384, 4195], "temperature": 0.0, "avg_logprob": -0.22397616068522136, "compression_ratio": 1.5919540229885059, "no_speech_prob": 3.785312173931743e-06}, {"id": 1535, "seek": 721792, "start": 7240.4800000000005, "end": 7242.4800000000005, "text": " Where each column is like?", "tokens": [2305, 1184, 7738, 307, 411, 30], "temperature": 0.0, "avg_logprob": -0.22397616068522136, "compression_ratio": 1.5919540229885059, "no_speech_prob": 3.785312173931743e-06}, {"id": 1536, "seek": 724248, "start": 7242.48, "end": 7249.48, "text": " Structurally quite different you know one thing is representing like how many pageviews last month another one is there sex", "tokens": [745, 1757, 6512, 1596, 819, 291, 458, 472, 551, 307, 13460, 411, 577, 867, 3028, 1759, 82, 1036, 1618, 1071, 472, 307, 456, 3260], "temperature": 0.0, "avg_logprob": -0.20388586456711227, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.963797103599063e-06}, {"id": 1537, "seek": 724248, "start": 7249.679999999999, "end": 7253.919999999999, "text": " Another one is what zip code there in and I call this structured data", "tokens": [3996, 472, 307, 437, 20730, 3089, 456, 294, 293, 286, 818, 341, 18519, 1412], "temperature": 0.0, "avg_logprob": -0.20388586456711227, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.963797103599063e-06}, {"id": 1538, "seek": 724248, "start": 7255.28, "end": 7263.0199999999995, "text": " That particular terminology is not unusual like lots of people use that terminology, but lots of people don't there's no", "tokens": [663, 1729, 27575, 307, 406, 10901, 411, 3195, 295, 561, 764, 300, 27575, 11, 457, 3195, 295, 561, 500, 380, 456, 311, 572], "temperature": 0.0, "avg_logprob": -0.20388586456711227, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.963797103599063e-06}, {"id": 1539, "seek": 724248, "start": 7264.08, "end": 7266.0, "text": " particularly agreed upon", "tokens": [4098, 9166, 3564], "temperature": 0.0, "avg_logprob": -0.20388586456711227, "compression_ratio": 1.6699507389162562, "no_speech_prob": 1.963797103599063e-06}, {"id": 1540, "seek": 726600, "start": 7266.0, "end": 7274.08, "text": " Terminology so when I say structured data, I'm referring to kind of columnar data as you might find in a database", "tokens": [19835, 259, 1793, 370, 562, 286, 584, 18519, 1412, 11, 286, 478, 13761, 281, 733, 295, 7738, 289, 1412, 382, 291, 1062, 915, 294, 257, 8149], "temperature": 0.0, "avg_logprob": -0.2540412275758508, "compression_ratio": 1.609375, "no_speech_prob": 2.5215472305717412e-06}, {"id": 1541, "seek": 726600, "start": 7274.16, "end": 7281.48, "text": " Or a spreadsheet where different columns represent different kinds of things and each row represents an observation", "tokens": [1610, 257, 27733, 689, 819, 13766, 2906, 819, 3685, 295, 721, 293, 1184, 5386, 8855, 364, 14816], "temperature": 0.0, "avg_logprob": -0.2540412275758508, "compression_ratio": 1.609375, "no_speech_prob": 2.5215472305717412e-06}, {"id": 1542, "seek": 726600, "start": 7281.48, "end": 7283.84, "text": " And so structured data is", "tokens": [400, 370, 18519, 1412, 307], "temperature": 0.0, "avg_logprob": -0.2540412275758508, "compression_ratio": 1.609375, "no_speech_prob": 2.5215472305717412e-06}, {"id": 1543, "seek": 726600, "start": 7284.64, "end": 7286.64, "text": " Probably what most of you?", "tokens": [9210, 437, 881, 295, 291, 30], "temperature": 0.0, "avg_logprob": -0.2540412275758508, "compression_ratio": 1.609375, "no_speech_prob": 2.5215472305717412e-06}, {"id": 1544, "seek": 726600, "start": 7288.16, "end": 7290.16, "text": " Analyzing most of the time", "tokens": [1107, 5222, 8781, 881, 295, 264, 565], "temperature": 0.0, "avg_logprob": -0.2540412275758508, "compression_ratio": 1.609375, "no_speech_prob": 2.5215472305717412e-06}, {"id": 1545, "seek": 729016, "start": 7290.16, "end": 7298.32, "text": " Funnily enough you know academics in the deep learning world don't really give a shit about structured data", "tokens": [11166, 77, 953, 1547, 291, 458, 25695, 294, 264, 2452, 2539, 1002, 500, 380, 534, 976, 257, 4611, 466, 18519, 1412], "temperature": 0.0, "avg_logprob": -0.15086539073656963, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.048800969438162e-06}, {"id": 1546, "seek": 729016, "start": 7299.08, "end": 7303.08, "text": " Because it's pretty hard to get published in fancy conference proceed proceedings", "tokens": [1436, 309, 311, 1238, 1152, 281, 483, 6572, 294, 10247, 7586, 8991, 37254], "temperature": 0.0, "avg_logprob": -0.15086539073656963, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.048800969438162e-06}, {"id": 1547, "seek": 729016, "start": 7303.08, "end": 7308.639999999999, "text": " If you're like if you've got a better logistics model, you know it's the thing that makes the world goes round", "tokens": [759, 291, 434, 411, 498, 291, 600, 658, 257, 1101, 27420, 2316, 11, 291, 458, 309, 311, 264, 551, 300, 1669, 264, 1002, 1709, 3098], "temperature": 0.0, "avg_logprob": -0.15086539073656963, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.048800969438162e-06}, {"id": 1548, "seek": 729016, "start": 7308.639999999999, "end": 7314.04, "text": " It's a thing that makes everybody you know money and efficiency and makes stuff work", "tokens": [467, 311, 257, 551, 300, 1669, 2201, 291, 458, 1460, 293, 10493, 293, 1669, 1507, 589], "temperature": 0.0, "avg_logprob": -0.15086539073656963, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.048800969438162e-06}, {"id": 1549, "seek": 729016, "start": 7315.36, "end": 7317.639999999999, "text": " But it's largely ignored sadly", "tokens": [583, 309, 311, 11611, 19735, 22023], "temperature": 0.0, "avg_logprob": -0.15086539073656963, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.048800969438162e-06}, {"id": 1550, "seek": 731764, "start": 7317.64, "end": 7319.64, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.1834059411829168, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.425447514222469e-06}, {"id": 1551, "seek": 731764, "start": 7319.72, "end": 7322.360000000001, "text": " We're not going to ignore it because we're practical deep learning", "tokens": [492, 434, 406, 516, 281, 11200, 309, 570, 321, 434, 8496, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.1834059411829168, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.425447514222469e-06}, {"id": 1552, "seek": 731764, "start": 7322.8, "end": 7328.9400000000005, "text": " And Kaggle doesn't ignore it either because people put prize money up on Kaggle to solve real-world problems", "tokens": [400, 48751, 22631, 1177, 380, 11200, 309, 2139, 570, 561, 829, 12818, 1460, 493, 322, 48751, 22631, 281, 5039, 957, 12, 13217, 2740], "temperature": 0.0, "avg_logprob": -0.1834059411829168, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.425447514222469e-06}, {"id": 1553, "seek": 731764, "start": 7329.0, "end": 7333.4800000000005, "text": " So there are some great Kaggle competitions. We can look at there's one running right now", "tokens": [407, 456, 366, 512, 869, 48751, 22631, 26185, 13, 492, 393, 574, 412, 456, 311, 472, 2614, 558, 586], "temperature": 0.0, "avg_logprob": -0.1834059411829168, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.425447514222469e-06}, {"id": 1554, "seek": 731764, "start": 7334.320000000001, "end": 7339.160000000001, "text": " Which is the grocery sales forecasting competition for Ecuador's largest chain?", "tokens": [3013, 307, 264, 14410, 5763, 44331, 6211, 337, 41558, 311, 6443, 5021, 30], "temperature": 0.0, "avg_logprob": -0.1834059411829168, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.425447514222469e-06}, {"id": 1555, "seek": 731764, "start": 7341.92, "end": 7343.72, "text": " It's always a little", "tokens": [467, 311, 1009, 257, 707], "temperature": 0.0, "avg_logprob": -0.1834059411829168, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.425447514222469e-06}, {"id": 1556, "seek": 734372, "start": 7343.72, "end": 7349.52, "text": " I've got to be a little careful about how much I show you about currently running competitions because I don't want to you know", "tokens": [286, 600, 658, 281, 312, 257, 707, 5026, 466, 577, 709, 286, 855, 291, 466, 4362, 2614, 26185, 570, 286, 500, 380, 528, 281, 291, 458], "temperature": 0.0, "avg_logprob": -0.15738610161675348, "compression_ratio": 1.5807860262008733, "no_speech_prob": 3.0894598239683546e-06}, {"id": 1557, "seek": 734372, "start": 7349.52, "end": 7354.0, "text": " Help you cheat, but it so happens there was a competition a year or two ago", "tokens": [10773, 291, 17470, 11, 457, 309, 370, 2314, 456, 390, 257, 6211, 257, 1064, 420, 732, 2057], "temperature": 0.0, "avg_logprob": -0.15738610161675348, "compression_ratio": 1.5807860262008733, "no_speech_prob": 3.0894598239683546e-06}, {"id": 1558, "seek": 734372, "start": 7354.68, "end": 7360.52, "text": " For one of Germany's largest grocery chains, which is almost identical, so I'm going to show you how to do that", "tokens": [1171, 472, 295, 7244, 311, 6443, 14410, 12626, 11, 597, 307, 1920, 14800, 11, 370, 286, 478, 516, 281, 855, 291, 577, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.15738610161675348, "compression_ratio": 1.5807860262008733, "no_speech_prob": 3.0894598239683546e-06}, {"id": 1559, "seek": 734372, "start": 7364.320000000001, "end": 7366.84, "text": " So that was called the Rossman stores data", "tokens": [407, 300, 390, 1219, 264, 16140, 1601, 9512, 1412], "temperature": 0.0, "avg_logprob": -0.15738610161675348, "compression_ratio": 1.5807860262008733, "no_speech_prob": 3.0894598239683546e-06}, {"id": 1560, "seek": 734372, "start": 7367.68, "end": 7368.8, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.15738610161675348, "compression_ratio": 1.5807860262008733, "no_speech_prob": 3.0894598239683546e-06}, {"id": 1561, "seek": 736880, "start": 7368.8, "end": 7374.88, "text": " So I would suggest you know first of all try practicing what we're learning on Rossman, right?", "tokens": [407, 286, 576, 3402, 291, 458, 700, 295, 439, 853, 11350, 437, 321, 434, 2539, 322, 16140, 1601, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17593854144938942, "compression_ratio": 1.6263736263736264, "no_speech_prob": 4.2892852434306405e-06}, {"id": 1562, "seek": 736880, "start": 7374.96, "end": 7379.2, "text": " But then see if you can get it working on on grocery because currently", "tokens": [583, 550, 536, 498, 291, 393, 483, 309, 1364, 322, 322, 14410, 570, 4362], "temperature": 0.0, "avg_logprob": -0.17593854144938942, "compression_ratio": 1.6263736263736264, "no_speech_prob": 4.2892852434306405e-06}, {"id": 1563, "seek": 736880, "start": 7380.400000000001, "end": 7385.88, "text": " On the leaderboard no one seems to basically know what they're doing in the groceries competition if you look at the leaderboard", "tokens": [1282, 264, 5263, 3787, 572, 472, 2544, 281, 1936, 458, 437, 436, 434, 884, 294, 264, 31391, 6211, 498, 291, 574, 412, 264, 5263, 3787], "temperature": 0.0, "avg_logprob": -0.17593854144938942, "compression_ratio": 1.6263736263736264, "no_speech_prob": 4.2892852434306405e-06}, {"id": 1564, "seek": 736880, "start": 7387.56, "end": 7389.56, "text": " The", "tokens": [440], "temperature": 0.0, "avg_logprob": -0.17593854144938942, "compression_ratio": 1.6263736263736264, "no_speech_prob": 4.2892852434306405e-06}, {"id": 1565, "seek": 736880, "start": 7389.64, "end": 7393.56, "text": " Let's see here. Yeah, these ones around five to nine five three", "tokens": [961, 311, 536, 510, 13, 865, 11, 613, 2306, 926, 1732, 281, 4949, 1732, 1045], "temperature": 0.0, "avg_logprob": -0.17593854144938942, "compression_ratio": 1.6263736263736264, "no_speech_prob": 4.2892852434306405e-06}, {"id": 1566, "seek": 736880, "start": 7393.56, "end": 7398.0, "text": " Oh are people that are literally finding like group averages and submitting those", "tokens": [876, 366, 561, 300, 366, 3736, 5006, 411, 1594, 42257, 293, 31836, 729], "temperature": 0.0, "avg_logprob": -0.17593854144938942, "compression_ratio": 1.6263736263736264, "no_speech_prob": 4.2892852434306405e-06}, {"id": 1567, "seek": 739800, "start": 7398.0, "end": 7403.88, "text": " I know because they're the kernels that they're using so you know the basically the people around 20th place", "tokens": [286, 458, 570, 436, 434, 264, 23434, 1625, 300, 436, 434, 1228, 370, 291, 458, 264, 1936, 264, 561, 926, 945, 392, 1081], "temperature": 0.0, "avg_logprob": -0.231270576009945, "compression_ratio": 1.6056910569105691, "no_speech_prob": 3.3405110571038676e-06}, {"id": 1568, "seek": 739800, "start": 7404.32, "end": 7407.32, "text": " Are not actually doing any machine learning", "tokens": [2014, 406, 767, 884, 604, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.231270576009945, "compression_ratio": 1.6056910569105691, "no_speech_prob": 3.3405110571038676e-06}, {"id": 1569, "seek": 739800, "start": 7408.6, "end": 7410.6, "text": " So yeah, let's see if we can improve things", "tokens": [407, 1338, 11, 718, 311, 536, 498, 321, 393, 3470, 721], "temperature": 0.0, "avg_logprob": -0.231270576009945, "compression_ratio": 1.6056910569105691, "no_speech_prob": 3.3405110571038676e-06}, {"id": 1570, "seek": 739800, "start": 7412.28, "end": 7415.36, "text": " So you'll see there's a lesson three Rossman", "tokens": [407, 291, 603, 536, 456, 311, 257, 6898, 1045, 16140, 1601], "temperature": 0.0, "avg_logprob": -0.231270576009945, "compression_ratio": 1.6056910569105691, "no_speech_prob": 3.3405110571038676e-06}, {"id": 1571, "seek": 739800, "start": 7415.92, "end": 7421.36, "text": " Notebook make sure you get pull okay in fact you know just reminder you know before you start working", "tokens": [11633, 2939, 652, 988, 291, 483, 2235, 1392, 294, 1186, 291, 458, 445, 13548, 291, 458, 949, 291, 722, 1364], "temperature": 0.0, "avg_logprob": -0.231270576009945, "compression_ratio": 1.6056910569105691, "no_speech_prob": 3.3405110571038676e-06}, {"id": 1572, "seek": 739800, "start": 7421.76, "end": 7425.34, "text": " Get pool in your fast AI repo and from time to time", "tokens": [3240, 7005, 294, 428, 2370, 7318, 49040, 293, 490, 565, 281, 565], "temperature": 0.0, "avg_logprob": -0.231270576009945, "compression_ratio": 1.6056910569105691, "no_speech_prob": 3.3405110571038676e-06}, {"id": 1573, "seek": 742534, "start": 7425.34, "end": 7433.7, "text": " Condor and update for you guys doing the in-person course the condor and update you should do it more often because we're", "tokens": [21793, 284, 293, 5623, 337, 291, 1074, 884, 264, 294, 12, 10813, 1164, 264, 2224, 284, 293, 5623, 291, 820, 360, 309, 544, 2049, 570, 321, 434], "temperature": 0.0, "avg_logprob": -0.24009258230936895, "compression_ratio": 1.616326530612245, "no_speech_prob": 4.0928848648036364e-06}, {"id": 1574, "seek": 742534, "start": 7434.5, "end": 7439.82, "text": " Changing things a little bit folks in the MOOC. You know more like once a month should be fine", "tokens": [45773, 721, 257, 707, 857, 4024, 294, 264, 49197, 34, 13, 509, 458, 544, 411, 1564, 257, 1618, 820, 312, 2489], "temperature": 0.0, "avg_logprob": -0.24009258230936895, "compression_ratio": 1.616326530612245, "no_speech_prob": 4.0928848648036364e-06}, {"id": 1575, "seek": 742534, "start": 7441.78, "end": 7446.5, "text": " So anyway, I just I just changed this a little bit so make sure you get pulled get less than three Rossman", "tokens": [407, 4033, 11, 286, 445, 286, 445, 3105, 341, 257, 707, 857, 370, 652, 988, 291, 483, 7373, 483, 1570, 813, 1045, 16140, 1601], "temperature": 0.0, "avg_logprob": -0.24009258230936895, "compression_ratio": 1.616326530612245, "no_speech_prob": 4.0928848648036364e-06}, {"id": 1576, "seek": 742534, "start": 7447.7, "end": 7452.54, "text": " And there's a couple of new libraries here one is fast AI dot structured", "tokens": [400, 456, 311, 257, 1916, 295, 777, 15148, 510, 472, 307, 2370, 7318, 5893, 18519], "temperature": 0.0, "avg_logprob": -0.24009258230936895, "compression_ratio": 1.616326530612245, "no_speech_prob": 4.0928848648036364e-06}, {"id": 1577, "seek": 745254, "start": 7452.54, "end": 7458.94, "text": " Fast AI dot structured contains stuff which is actually not at all pie torch specific", "tokens": [15968, 7318, 5893, 18519, 8306, 1507, 597, 307, 767, 406, 412, 439, 1730, 27822, 2685], "temperature": 0.0, "avg_logprob": -0.22095636574618788, "compression_ratio": 1.663677130044843, "no_speech_prob": 4.495150278671645e-06}, {"id": 1578, "seek": 745254, "start": 7459.14, "end": 7464.62, "text": " We actually use that in the machine learning course as well for doing random forests with no pie torch at all", "tokens": [492, 767, 764, 300, 294, 264, 3479, 2539, 1164, 382, 731, 337, 884, 4974, 21700, 365, 572, 1730, 27822, 412, 439], "temperature": 0.0, "avg_logprob": -0.22095636574618788, "compression_ratio": 1.663677130044843, "no_speech_prob": 4.495150278671645e-06}, {"id": 1579, "seek": 745254, "start": 7464.62, "end": 7471.5, "text": " I mentioned that because you can use that particular library without any of the other parts of fast AI", "tokens": [286, 2835, 300, 570, 291, 393, 764, 300, 1729, 6405, 1553, 604, 295, 264, 661, 3166, 295, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.22095636574618788, "compression_ratio": 1.663677130044843, "no_speech_prob": 4.495150278671645e-06}, {"id": 1580, "seek": 745254, "start": 7472.3, "end": 7474.3, "text": " So that can be handy", "tokens": [407, 300, 393, 312, 13239], "temperature": 0.0, "avg_logprob": -0.22095636574618788, "compression_ratio": 1.663677130044843, "no_speech_prob": 4.495150278671645e-06}, {"id": 1581, "seek": 745254, "start": 7474.82, "end": 7477.46, "text": " And then we're also going to use faster column data", "tokens": [400, 550, 321, 434, 611, 516, 281, 764, 4663, 7738, 1412], "temperature": 0.0, "avg_logprob": -0.22095636574618788, "compression_ratio": 1.663677130044843, "no_speech_prob": 4.495150278671645e-06}, {"id": 1582, "seek": 747746, "start": 7477.46, "end": 7483.42, "text": " Which is basically some stuff that allows us to do fast AI pie torch stuff with", "tokens": [3013, 307, 1936, 512, 1507, 300, 4045, 505, 281, 360, 2370, 7318, 1730, 27822, 1507, 365], "temperature": 0.0, "avg_logprob": -0.2197658447992234, "compression_ratio": 1.63681592039801, "no_speech_prob": 1.248267608389142e-06}, {"id": 1583, "seek": 747746, "start": 7484.22, "end": 7486.22, "text": " columnar structured data", "tokens": [7738, 289, 18519, 1412], "temperature": 0.0, "avg_logprob": -0.2197658447992234, "compression_ratio": 1.63681592039801, "no_speech_prob": 1.248267608389142e-06}, {"id": 1584, "seek": 747746, "start": 7487.46, "end": 7491.3, "text": " The structured data we need to use pandas a lot", "tokens": [440, 18519, 1412, 321, 643, 281, 764, 4565, 296, 257, 688], "temperature": 0.0, "avg_logprob": -0.2197658447992234, "compression_ratio": 1.63681592039801, "no_speech_prob": 1.248267608389142e-06}, {"id": 1585, "seek": 747746, "start": 7492.06, "end": 7498.3, "text": " Anybody who's used our data frames will be very familiar with pandas pandas is basically an attempt to kind of replicate", "tokens": [19082, 567, 311, 1143, 527, 1412, 12083, 486, 312, 588, 4963, 365, 4565, 296, 4565, 296, 307, 1936, 364, 5217, 281, 733, 295, 25356], "temperature": 0.0, "avg_logprob": -0.2197658447992234, "compression_ratio": 1.63681592039801, "no_speech_prob": 1.248267608389142e-06}, {"id": 1586, "seek": 747746, "start": 7498.82, "end": 7501.14, "text": " data frames in Python", "tokens": [1412, 12083, 294, 15329], "temperature": 0.0, "avg_logprob": -0.2197658447992234, "compression_ratio": 1.63681592039801, "no_speech_prob": 1.248267608389142e-06}, {"id": 1587, "seek": 747746, "start": 7502.1, "end": 7504.1, "text": " You know and a bit more", "tokens": [509, 458, 293, 257, 857, 544], "temperature": 0.0, "avg_logprob": -0.2197658447992234, "compression_ratio": 1.63681592039801, "no_speech_prob": 1.248267608389142e-06}, {"id": 1588, "seek": 747746, "start": 7504.26, "end": 7506.26, "text": " if you're", "tokens": [498, 291, 434], "temperature": 0.0, "avg_logprob": -0.2197658447992234, "compression_ratio": 1.63681592039801, "no_speech_prob": 1.248267608389142e-06}, {"id": 1589, "seek": 750626, "start": 7506.26, "end": 7511.7, "text": " Not entirely familiar with pandas. There's a great book", "tokens": [1726, 7696, 4963, 365, 4565, 296, 13, 821, 311, 257, 869, 1446], "temperature": 0.0, "avg_logprob": -0.21071547966498833, "compression_ratio": 1.4476190476190476, "no_speech_prob": 1.760337454470573e-06}, {"id": 1590, "seek": 750626, "start": 7516.66, "end": 7518.66, "text": " Which I think I might have mentioned before", "tokens": [3013, 286, 519, 286, 1062, 362, 2835, 949], "temperature": 0.0, "avg_logprob": -0.21071547966498833, "compression_ratio": 1.4476190476190476, "no_speech_prob": 1.760337454470573e-06}, {"id": 1591, "seek": 750626, "start": 7520.58, "end": 7526.18, "text": " Python for data analysis by Wes McKinney, there's a new addition that just came out a couple of weeks ago", "tokens": [15329, 337, 1412, 5215, 538, 23843, 21765, 259, 2397, 11, 456, 311, 257, 777, 4500, 300, 445, 1361, 484, 257, 1916, 295, 3259, 2057], "temperature": 0.0, "avg_logprob": -0.21071547966498833, "compression_ratio": 1.4476190476190476, "no_speech_prob": 1.760337454470573e-06}, {"id": 1592, "seek": 750626, "start": 7528.62, "end": 7533.54, "text": " Obviously being by the pandas author its coverage of pandas is excellent, but it also covers", "tokens": [7580, 885, 538, 264, 4565, 296, 3793, 1080, 9645, 295, 4565, 296, 307, 7103, 11, 457, 309, 611, 10538], "temperature": 0.0, "avg_logprob": -0.21071547966498833, "compression_ratio": 1.4476190476190476, "no_speech_prob": 1.760337454470573e-06}, {"id": 1593, "seek": 750626, "start": 7534.22, "end": 7535.46, "text": " numpy", "tokens": [1031, 8200], "temperature": 0.0, "avg_logprob": -0.21071547966498833, "compression_ratio": 1.4476190476190476, "no_speech_prob": 1.760337454470573e-06}, {"id": 1594, "seek": 753546, "start": 7535.46, "end": 7536.54, "text": " sci-fi", "tokens": [2180, 12, 13325], "temperature": 0.0, "avg_logprob": -0.259410992790671, "compression_ratio": 1.5144230769230769, "no_speech_prob": 7.183188699855236e-06}, {"id": 1595, "seek": 753546, "start": 7536.54, "end": 7538.54, "text": " plot lib scikit-learn", "tokens": [7542, 22854, 2180, 22681, 12, 306, 1083], "temperature": 0.0, "avg_logprob": -0.259410992790671, "compression_ratio": 1.5144230769230769, "no_speech_prob": 7.183188699855236e-06}, {"id": 1596, "seek": 753546, "start": 7539.42, "end": 7545.3, "text": " I Python and Jupiter really well, okay, and so I'm kind of going to assume", "tokens": [286, 15329, 293, 24567, 534, 731, 11, 1392, 11, 293, 370, 286, 478, 733, 295, 516, 281, 6552], "temperature": 0.0, "avg_logprob": -0.259410992790671, "compression_ratio": 1.5144230769230769, "no_speech_prob": 7.183188699855236e-06}, {"id": 1597, "seek": 753546, "start": 7546.5, "end": 7551.02, "text": " That you know your way around these libraries to some extent", "tokens": [663, 291, 458, 428, 636, 926, 613, 15148, 281, 512, 8396], "temperature": 0.0, "avg_logprob": -0.259410992790671, "compression_ratio": 1.5144230769230769, "no_speech_prob": 7.183188699855236e-06}, {"id": 1598, "seek": 753546, "start": 7551.94, "end": 7558.14, "text": " Also, there was the workshop we did before this started and there's a video of that online where we kind of have a brief mention", "tokens": [2743, 11, 456, 390, 264, 13541, 321, 630, 949, 341, 1409, 293, 456, 311, 257, 960, 295, 300, 2950, 689, 321, 733, 295, 362, 257, 5353, 2152], "temperature": 0.0, "avg_logprob": -0.259410992790671, "compression_ratio": 1.5144230769230769, "no_speech_prob": 7.183188699855236e-06}, {"id": 1599, "seek": 753546, "start": 7558.42, "end": 7560.42, "text": " of all of those tools", "tokens": [295, 439, 295, 729, 3873], "temperature": 0.0, "avg_logprob": -0.259410992790671, "compression_ratio": 1.5144230769230769, "no_speech_prob": 7.183188699855236e-06}, {"id": 1600, "seek": 756042, "start": 7560.42, "end": 7563.02, "text": " I'm", "tokens": [286, 478], "temperature": 0.0, "avg_logprob": -0.2635353435169567, "compression_ratio": 1.62015503875969, "no_speech_prob": 1.5689209249103442e-05}, {"id": 1601, "seek": 756042, "start": 7563.02, "end": 7567.58, "text": " Structured data is generally shared as CSV files. That was no different in this competition", "tokens": [745, 46847, 1412, 307, 5101, 5507, 382, 48814, 7098, 13, 663, 390, 572, 819, 294, 341, 6211], "temperature": 0.0, "avg_logprob": -0.2635353435169567, "compression_ratio": 1.62015503875969, "no_speech_prob": 1.5689209249103442e-05}, {"id": 1602, "seek": 756042, "start": 7568.22, "end": 7571.7, "text": " As you'll see there's a hyperlink to the Rossman data set here", "tokens": [1018, 291, 603, 536, 456, 311, 257, 9848, 22473, 281, 264, 16140, 1601, 1412, 992, 510], "temperature": 0.0, "avg_logprob": -0.2635353435169567, "compression_ratio": 1.62015503875969, "no_speech_prob": 1.5689209249103442e-05}, {"id": 1603, "seek": 756042, "start": 7571.9, "end": 7572.46, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.2635353435169567, "compression_ratio": 1.62015503875969, "no_speech_prob": 1.5689209249103442e-05}, {"id": 1604, "seek": 756042, "start": 7572.46, "end": 7577.1, "text": " Now if you look at the bottom of my screen you'll see this goes to files dot faster AI", "tokens": [823, 498, 291, 574, 412, 264, 2767, 295, 452, 2568, 291, 603, 536, 341, 1709, 281, 7098, 5893, 4663, 7318], "temperature": 0.0, "avg_logprob": -0.2635353435169567, "compression_ratio": 1.62015503875969, "no_speech_prob": 1.5689209249103442e-05}, {"id": 1605, "seek": 756042, "start": 7577.42, "end": 7582.82, "text": " Because this doesn't require any login or anything to grab this data set. It's as simple as right-clicking", "tokens": [1436, 341, 1177, 380, 3651, 604, 24276, 420, 1340, 281, 4444, 341, 1412, 992, 13, 467, 311, 382, 2199, 382, 558, 12, 3474, 10401], "temperature": 0.0, "avg_logprob": -0.2635353435169567, "compression_ratio": 1.62015503875969, "no_speech_prob": 1.5689209249103442e-05}, {"id": 1606, "seek": 756042, "start": 7583.62, "end": 7585.62, "text": " copy link address", "tokens": [5055, 2113, 2985], "temperature": 0.0, "avg_logprob": -0.2635353435169567, "compression_ratio": 1.62015503875969, "no_speech_prob": 1.5689209249103442e-05}, {"id": 1607, "seek": 756042, "start": 7585.62, "end": 7587.7, "text": " head over to wherever you want it and", "tokens": [1378, 670, 281, 8660, 291, 528, 309, 293], "temperature": 0.0, "avg_logprob": -0.2635353435169567, "compression_ratio": 1.62015503875969, "no_speech_prob": 1.5689209249103442e-05}, {"id": 1608, "seek": 758770, "start": 7587.7, "end": 7589.7, "text": " and just type", "tokens": [293, 445, 2010], "temperature": 0.0, "avg_logprob": -0.22126304940001607, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.5612707759137265e-06}, {"id": 1609, "seek": 758770, "start": 7591.139999999999, "end": 7593.139999999999, "text": " W get and", "tokens": [343, 483, 293], "temperature": 0.0, "avg_logprob": -0.22126304940001607, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.5612707759137265e-06}, {"id": 1610, "seek": 758770, "start": 7594.26, "end": 7601.58, "text": " The URL okay, so that's because you know it's it's not behind a login or anything", "tokens": [440, 12905, 1392, 11, 370, 300, 311, 570, 291, 458, 309, 311, 309, 311, 406, 2261, 257, 24276, 420, 1340], "temperature": 0.0, "avg_logprob": -0.22126304940001607, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.5612707759137265e-06}, {"id": 1611, "seek": 758770, "start": 7603.42, "end": 7606.099999999999, "text": " So you can grab the grab it from there and", "tokens": [407, 291, 393, 4444, 264, 4444, 309, 490, 456, 293], "temperature": 0.0, "avg_logprob": -0.22126304940001607, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.5612707759137265e-06}, {"id": 1612, "seek": 758770, "start": 7607.139999999999, "end": 7613.639999999999, "text": " You can always read a CSV file with just pandas dot read CSV now in this particular case. There's a lot of", "tokens": [509, 393, 1009, 1401, 257, 48814, 3991, 365, 445, 4565, 296, 5893, 1401, 48814, 586, 294, 341, 1729, 1389, 13, 821, 311, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.22126304940001607, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.5612707759137265e-06}, {"id": 1613, "seek": 761364, "start": 7613.64, "end": 7619.280000000001, "text": " pre-processing that we do and what I've actually done here is I've", "tokens": [659, 12, 41075, 278, 300, 321, 360, 293, 437, 286, 600, 767, 1096, 510, 307, 286, 600], "temperature": 0.0, "avg_logprob": -0.20738811304073523, "compression_ratio": 1.6271929824561404, "no_speech_prob": 6.475927989413321e-07}, {"id": 1614, "seek": 761364, "start": 7620.160000000001, "end": 7622.160000000001, "text": " I've actually", "tokens": [286, 600, 767], "temperature": 0.0, "avg_logprob": -0.20738811304073523, "compression_ratio": 1.6271929824561404, "no_speech_prob": 6.475927989413321e-07}, {"id": 1615, "seek": 761364, "start": 7622.8, "end": 7624.8, "text": " Stolen the entire", "tokens": [745, 11940, 264, 2302], "temperature": 0.0, "avg_logprob": -0.20738811304073523, "compression_ratio": 1.6271929824561404, "no_speech_prob": 6.475927989413321e-07}, {"id": 1616, "seek": 761364, "start": 7624.88, "end": 7629.12, "text": " Pipeline from the third place winner of Rossman. Okay, so they made all their data", "tokens": [35396, 5440, 490, 264, 2636, 1081, 8507, 295, 16140, 1601, 13, 1033, 11, 370, 436, 1027, 439, 641, 1412], "temperature": 0.0, "avg_logprob": -0.20738811304073523, "compression_ratio": 1.6271929824561404, "no_speech_prob": 6.475927989413321e-07}, {"id": 1617, "seek": 761364, "start": 7629.96, "end": 7630.96, "text": " They're really great", "tokens": [814, 434, 534, 869], "temperature": 0.0, "avg_logprob": -0.20738811304073523, "compression_ratio": 1.6271929824561404, "no_speech_prob": 6.475927989413321e-07}, {"id": 1618, "seek": 761364, "start": 7630.96, "end": 7637.68, "text": " You know they've had a github available with everything that we need and I've ported it all across and simplified it and tried to make it", "tokens": [509, 458, 436, 600, 632, 257, 290, 355, 836, 2435, 365, 1203, 300, 321, 643, 293, 286, 600, 2436, 292, 309, 439, 2108, 293, 26335, 309, 293, 3031, 281, 652, 309], "temperature": 0.0, "avg_logprob": -0.20738811304073523, "compression_ratio": 1.6271929824561404, "no_speech_prob": 6.475927989413321e-07}, {"id": 1619, "seek": 761364, "start": 7638.0, "end": 7640.0, "text": " pretty easy to understand", "tokens": [1238, 1858, 281, 1223], "temperature": 0.0, "avg_logprob": -0.20738811304073523, "compression_ratio": 1.6271929824561404, "no_speech_prob": 6.475927989413321e-07}, {"id": 1620, "seek": 761364, "start": 7640.360000000001, "end": 7641.88, "text": " this", "tokens": [341], "temperature": 0.0, "avg_logprob": -0.20738811304073523, "compression_ratio": 1.6271929824561404, "no_speech_prob": 6.475927989413321e-07}, {"id": 1621, "seek": 764188, "start": 7641.88, "end": 7646.8, "text": " Course is about deep learning not about data processing, so I'm not going to go through it", "tokens": [27327, 307, 466, 2452, 2539, 406, 466, 1412, 9007, 11, 370, 286, 478, 406, 516, 281, 352, 807, 309], "temperature": 0.0, "avg_logprob": -0.1584378029536275, "compression_ratio": 1.7188755020080322, "no_speech_prob": 1.4285309589467943e-05}, {"id": 1622, "seek": 764188, "start": 7647.92, "end": 7653.84, "text": " But we will be going through it in the machine learning course in some detail because feature engineering is really important", "tokens": [583, 321, 486, 312, 516, 807, 309, 294, 264, 3479, 2539, 1164, 294, 512, 2607, 570, 4111, 7043, 307, 534, 1021], "temperature": 0.0, "avg_logprob": -0.1584378029536275, "compression_ratio": 1.7188755020080322, "no_speech_prob": 1.4285309589467943e-05}, {"id": 1623, "seek": 764188, "start": 7653.84, "end": 7655.84, "text": " So if you're interested", "tokens": [407, 498, 291, 434, 3102], "temperature": 0.0, "avg_logprob": -0.1584378029536275, "compression_ratio": 1.7188755020080322, "no_speech_prob": 1.4285309589467943e-05}, {"id": 1624, "seek": 764188, "start": 7655.88, "end": 7657.88, "text": " You know check out the machine learning course", "tokens": [509, 458, 1520, 484, 264, 3479, 2539, 1164], "temperature": 0.0, "avg_logprob": -0.1584378029536275, "compression_ratio": 1.7188755020080322, "no_speech_prob": 1.4285309589467943e-05}, {"id": 1625, "seek": 764188, "start": 7658.96, "end": 7660.96, "text": " for that I", "tokens": [337, 300, 286], "temperature": 0.0, "avg_logprob": -0.1584378029536275, "compression_ratio": 1.7188755020080322, "no_speech_prob": 1.4285309589467943e-05}, {"id": 1626, "seek": 764188, "start": 7661.04, "end": 7663.04, "text": " Will however show you", "tokens": [3099, 4461, 855, 291], "temperature": 0.0, "avg_logprob": -0.1584378029536275, "compression_ratio": 1.7188755020080322, "no_speech_prob": 1.4285309589467943e-05}, {"id": 1627, "seek": 764188, "start": 7663.2, "end": 7666.56, "text": " Kind of what it looks like so once we read the CSVs in", "tokens": [9242, 295, 437, 309, 1542, 411, 370, 1564, 321, 1401, 264, 48814, 82, 294], "temperature": 0.0, "avg_logprob": -0.1584378029536275, "compression_ratio": 1.7188755020080322, "no_speech_prob": 1.4285309589467943e-05}, {"id": 1628, "seek": 766656, "start": 7666.56, "end": 7671.4800000000005, "text": " You can see basically what's there so the key one is", "tokens": [509, 393, 536, 1936, 437, 311, 456, 370, 264, 2141, 472, 307], "temperature": 0.0, "avg_logprob": -0.24526378086635045, "compression_ratio": 1.5263157894736843, "no_speech_prob": 2.2603087472816696e-06}, {"id": 1629, "seek": 766656, "start": 7675.360000000001, "end": 7677.360000000001, "text": " For a particular store", "tokens": [1171, 257, 1729, 3531], "temperature": 0.0, "avg_logprob": -0.24526378086635045, "compression_ratio": 1.5263157894736843, "no_speech_prob": 2.2603087472816696e-06}, {"id": 1630, "seek": 766656, "start": 7680.92, "end": 7682.92, "text": " We have the", "tokens": [492, 362, 264], "temperature": 0.0, "avg_logprob": -0.24526378086635045, "compression_ratio": 1.5263157894736843, "no_speech_prob": 2.2603087472816696e-06}, {"id": 1631, "seek": 766656, "start": 7685.240000000001, "end": 7688.68, "text": " We have the date and we have the sales", "tokens": [492, 362, 264, 4002, 293, 321, 362, 264, 5763], "temperature": 0.0, "avg_logprob": -0.24526378086635045, "compression_ratio": 1.5263157894736843, "no_speech_prob": 2.2603087472816696e-06}, {"id": 1632, "seek": 766656, "start": 7689.64, "end": 7693.080000000001, "text": " For that particular store. We know whether that", "tokens": [1171, 300, 1729, 3531, 13, 492, 458, 1968, 300], "temperature": 0.0, "avg_logprob": -0.24526378086635045, "compression_ratio": 1.5263157894736843, "no_speech_prob": 2.2603087472816696e-06}, {"id": 1633, "seek": 769308, "start": 7693.08, "end": 7696.12, "text": " Thing is on promo or not", "tokens": [30902, 307, 322, 26750, 420, 406], "temperature": 0.0, "avg_logprob": -0.18666007600981613, "compression_ratio": 1.5, "no_speech_prob": 9.276344030695327e-07}, {"id": 1634, "seek": 769308, "start": 7697.76, "end": 7700.96, "text": " We know the number of customers that that particular store had", "tokens": [492, 458, 264, 1230, 295, 4581, 300, 300, 1729, 3531, 632], "temperature": 0.0, "avg_logprob": -0.18666007600981613, "compression_ratio": 1.5, "no_speech_prob": 9.276344030695327e-07}, {"id": 1635, "seek": 769308, "start": 7702.5599999999995, "end": 7704.72, "text": " We know whether that date was a school holiday", "tokens": [492, 458, 1968, 300, 4002, 390, 257, 1395, 9960], "temperature": 0.0, "avg_logprob": -0.18666007600981613, "compression_ratio": 1.5, "no_speech_prob": 9.276344030695327e-07}, {"id": 1636, "seek": 769308, "start": 7710.44, "end": 7712.44, "text": " We also know", "tokens": [492, 611, 458], "temperature": 0.0, "avg_logprob": -0.18666007600981613, "compression_ratio": 1.5, "no_speech_prob": 9.276344030695327e-07}, {"id": 1637, "seek": 769308, "start": 7714.32, "end": 7718.76, "text": " What kind of store it is so like this is pretty common right you'll often get", "tokens": [708, 733, 295, 3531, 309, 307, 370, 411, 341, 307, 1238, 2689, 558, 291, 603, 2049, 483], "temperature": 0.0, "avg_logprob": -0.18666007600981613, "compression_ratio": 1.5, "no_speech_prob": 9.276344030695327e-07}, {"id": 1638, "seek": 771876, "start": 7718.76, "end": 7724.4800000000005, "text": " Data sets where there's some column with like just some kind of code. We don't really know what the code means", "tokens": [11888, 6352, 689, 456, 311, 512, 7738, 365, 411, 445, 512, 733, 295, 3089, 13, 492, 500, 380, 534, 458, 437, 264, 3089, 1355], "temperature": 0.0, "avg_logprob": -0.12658386055482637, "compression_ratio": 1.6948529411764706, "no_speech_prob": 4.092885774298338e-06}, {"id": 1639, "seek": 771876, "start": 7725.400000000001, "end": 7730.68, "text": " Most of the time I find it doesn't matter what it means like normally you get given a data dictionary", "tokens": [4534, 295, 264, 565, 286, 915, 309, 1177, 380, 1871, 437, 309, 1355, 411, 5646, 291, 483, 2212, 257, 1412, 25890], "temperature": 0.0, "avg_logprob": -0.12658386055482637, "compression_ratio": 1.6948529411764706, "no_speech_prob": 4.092885774298338e-06}, {"id": 1640, "seek": 771876, "start": 7731.12, "end": 7736.7, "text": " When you start on a project and obviously if you're working on an internal project you can ask the people at your company", "tokens": [1133, 291, 722, 322, 257, 1716, 293, 2745, 498, 291, 434, 1364, 322, 364, 6920, 1716, 291, 393, 1029, 264, 561, 412, 428, 2237], "temperature": 0.0, "avg_logprob": -0.12658386055482637, "compression_ratio": 1.6948529411764706, "no_speech_prob": 4.092885774298338e-06}, {"id": 1641, "seek": 771876, "start": 7736.7, "end": 7738.7, "text": " What does this column mean I?", "tokens": [708, 775, 341, 7738, 914, 286, 30], "temperature": 0.0, "avg_logprob": -0.12658386055482637, "compression_ratio": 1.6948529411764706, "no_speech_prob": 4.092885774298338e-06}, {"id": 1642, "seek": 771876, "start": 7739.16, "end": 7744.4800000000005, "text": " Kind of stay away from learning too much about it. I prefer to like see what the data says first", "tokens": [9242, 295, 1754, 1314, 490, 2539, 886, 709, 466, 309, 13, 286, 4382, 281, 411, 536, 437, 264, 1412, 1619, 700], "temperature": 0.0, "avg_logprob": -0.12658386055482637, "compression_ratio": 1.6948529411764706, "no_speech_prob": 4.092885774298338e-06}, {"id": 1643, "seek": 774448, "start": 7744.48, "end": 7750.919999999999, "text": " There's something about what kind of product are we selling in this particular row", "tokens": [821, 311, 746, 466, 437, 733, 295, 1674, 366, 321, 6511, 294, 341, 1729, 5386], "temperature": 0.0, "avg_logprob": -0.18784513840308556, "compression_ratio": 1.5165562913907285, "no_speech_prob": 6.577915883099195e-07}, {"id": 1644, "seek": 774448, "start": 7753.839999999999, "end": 7761.179999999999, "text": " And then there's information about like how far away is the nearest competitor how long have they been open for", "tokens": [400, 550, 456, 311, 1589, 466, 411, 577, 1400, 1314, 307, 264, 23831, 27266, 577, 938, 362, 436, 668, 1269, 337], "temperature": 0.0, "avg_logprob": -0.18784513840308556, "compression_ratio": 1.5165562913907285, "no_speech_prob": 6.577915883099195e-07}, {"id": 1645, "seek": 774448, "start": 7764.32, "end": 7766.48, "text": " How long has the promo been on for", "tokens": [1012, 938, 575, 264, 26750, 668, 322, 337], "temperature": 0.0, "avg_logprob": -0.18784513840308556, "compression_ratio": 1.5165562913907285, "no_speech_prob": 6.577915883099195e-07}, {"id": 1646, "seek": 776648, "start": 7766.48, "end": 7774.4, "text": " For each store we can find out what state it's in for each state", "tokens": [1171, 1184, 3531, 321, 393, 915, 484, 437, 1785, 309, 311, 294, 337, 1184, 1785], "temperature": 0.0, "avg_logprob": -0.19437218889778043, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014702765038237e-06}, {"id": 1647, "seek": 776648, "start": 7774.4, "end": 7778.12, "text": " we can find out the name of the state this is in Germany and", "tokens": [321, 393, 915, 484, 264, 1315, 295, 264, 1785, 341, 307, 294, 7244, 293], "temperature": 0.0, "avg_logprob": -0.19437218889778043, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014702765038237e-06}, {"id": 1648, "seek": 776648, "start": 7779.4, "end": 7782.48, "text": " Interestingly they were allowed to download any data external data", "tokens": [30564, 436, 645, 4350, 281, 5484, 604, 1412, 8320, 1412], "temperature": 0.0, "avg_logprob": -0.19437218889778043, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014702765038237e-06}, {"id": 1649, "seek": 776648, "start": 7782.48, "end": 7788.879999999999, "text": " They wanted in this competition just very common as long as you share it with everybody else and so some folks tried downloading", "tokens": [814, 1415, 294, 341, 6211, 445, 588, 2689, 382, 938, 382, 291, 2073, 309, 365, 2201, 1646, 293, 370, 512, 4024, 3031, 32529], "temperature": 0.0, "avg_logprob": -0.19437218889778043, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014702765038237e-06}, {"id": 1650, "seek": 776648, "start": 7789.44, "end": 7791.2, "text": " data from", "tokens": [1412, 490], "temperature": 0.0, "avg_logprob": -0.19437218889778043, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014702765038237e-06}, {"id": 1651, "seek": 776648, "start": 7791.2, "end": 7793.2, "text": " Google Trends", "tokens": [3329, 37417, 82], "temperature": 0.0, "avg_logprob": -0.19437218889778043, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.014702765038237e-06}, {"id": 1652, "seek": 779320, "start": 7793.2, "end": 7798.74, "text": " I'm not sure exactly what it was that they were checking the trend of but we have this information from Google Trends", "tokens": [286, 478, 406, 988, 2293, 437, 309, 390, 300, 436, 645, 8568, 264, 6028, 295, 457, 321, 362, 341, 1589, 490, 3329, 37417, 82], "temperature": 0.0, "avg_logprob": -0.21633374886434587, "compression_ratio": 1.4350282485875707, "no_speech_prob": 4.8603997129248455e-06}, {"id": 1653, "seek": 779320, "start": 7799.96, "end": 7803.8, "text": " Somebody downloaded the weather for every day in Germany every state", "tokens": [13463, 21748, 264, 5503, 337, 633, 786, 294, 7244, 633, 1785], "temperature": 0.0, "avg_logprob": -0.21633374886434587, "compression_ratio": 1.4350282485875707, "no_speech_prob": 4.8603997129248455e-06}, {"id": 1654, "seek": 779320, "start": 7808.639999999999, "end": 7812.599999999999, "text": " And yeah, that's about it right so", "tokens": [400, 1338, 11, 300, 311, 466, 309, 558, 370], "temperature": 0.0, "avg_logprob": -0.21633374886434587, "compression_ratio": 1.4350282485875707, "no_speech_prob": 4.8603997129248455e-06}, {"id": 1655, "seek": 779320, "start": 7816.84, "end": 7819.24, "text": " You can get a data frame summary", "tokens": [509, 393, 483, 257, 1412, 3920, 12691], "temperature": 0.0, "avg_logprob": -0.21633374886434587, "compression_ratio": 1.4350282485875707, "no_speech_prob": 4.8603997129248455e-06}, {"id": 1656, "seek": 781924, "start": 7819.24, "end": 7825.2, "text": " With pandas which kind of lets you see how many observations and means and standard deviations", "tokens": [2022, 4565, 296, 597, 733, 295, 6653, 291, 536, 577, 867, 18163, 293, 1355, 293, 3832, 31219, 763], "temperature": 0.0, "avg_logprob": -0.13620410531254137, "compression_ratio": 1.75, "no_speech_prob": 4.006213566754013e-05}, {"id": 1657, "seek": 781924, "start": 7826.0, "end": 7828.12, "text": " Again, I don't do a hell of a lot with that early on", "tokens": [3764, 11, 286, 500, 380, 360, 257, 4921, 295, 257, 688, 365, 300, 2440, 322], "temperature": 0.0, "avg_logprob": -0.13620410531254137, "compression_ratio": 1.75, "no_speech_prob": 4.006213566754013e-05}, {"id": 1658, "seek": 781924, "start": 7829.24, "end": 7831.24, "text": " But it's nice to note there", "tokens": [583, 309, 311, 1481, 281, 3637, 456], "temperature": 0.0, "avg_logprob": -0.13620410531254137, "compression_ratio": 1.75, "no_speech_prob": 4.006213566754013e-05}, {"id": 1659, "seek": 781924, "start": 7832.24, "end": 7838.32, "text": " So what we do you know this is called a relational data set a relational data set is one where there's quite a few tables", "tokens": [407, 437, 321, 360, 291, 458, 341, 307, 1219, 257, 38444, 1412, 992, 257, 38444, 1412, 992, 307, 472, 689, 456, 311, 1596, 257, 1326, 8020], "temperature": 0.0, "avg_logprob": -0.13620410531254137, "compression_ratio": 1.75, "no_speech_prob": 4.006213566754013e-05}, {"id": 1660, "seek": 781924, "start": 7838.32, "end": 7842.0, "text": " We have to join together. It's very easy to do that in pandas", "tokens": [492, 362, 281, 3917, 1214, 13, 467, 311, 588, 1858, 281, 360, 300, 294, 4565, 296], "temperature": 0.0, "avg_logprob": -0.13620410531254137, "compression_ratio": 1.75, "no_speech_prob": 4.006213566754013e-05}, {"id": 1661, "seek": 781924, "start": 7842.0, "end": 7846.48, "text": " There's a thing called merge so a great little function to do that and so I just started joining everything together", "tokens": [821, 311, 257, 551, 1219, 22183, 370, 257, 869, 707, 2445, 281, 360, 300, 293, 370, 286, 445, 1409, 5549, 1203, 1214], "temperature": 0.0, "avg_logprob": -0.13620410531254137, "compression_ratio": 1.75, "no_speech_prob": 4.006213566754013e-05}, {"id": 1662, "seek": 784648, "start": 7846.48, "end": 7850.4, "text": " I join in the weather the Google Trends the stores", "tokens": [286, 3917, 294, 264, 5503, 264, 3329, 37417, 82, 264, 9512], "temperature": 0.0, "avg_logprob": -0.17145382179008736, "compression_ratio": 1.5848214285714286, "no_speech_prob": 8.801020157989115e-06}, {"id": 1663, "seek": 784648, "start": 7856.08, "end": 7858.08, "text": " Yeah, that's about everything I guess", "tokens": [865, 11, 300, 311, 466, 1203, 286, 2041], "temperature": 0.0, "avg_logprob": -0.17145382179008736, "compression_ratio": 1.5848214285714286, "no_speech_prob": 8.801020157989115e-06}, {"id": 1664, "seek": 784648, "start": 7858.12, "end": 7863.799999999999, "text": " You'll see there's one thing that I'm using from the fast AI library, which is called add date part", "tokens": [509, 603, 536, 456, 311, 472, 551, 300, 286, 478, 1228, 490, 264, 2370, 7318, 6405, 11, 597, 307, 1219, 909, 4002, 644], "temperature": 0.0, "avg_logprob": -0.17145382179008736, "compression_ratio": 1.5848214285714286, "no_speech_prob": 8.801020157989115e-06}, {"id": 1665, "seek": 784648, "start": 7863.799999999999, "end": 7866.4, "text": " We talk about this a lot in the machine learning course", "tokens": [492, 751, 466, 341, 257, 688, 294, 264, 3479, 2539, 1164], "temperature": 0.0, "avg_logprob": -0.17145382179008736, "compression_ratio": 1.5848214285714286, "no_speech_prob": 8.801020157989115e-06}, {"id": 1666, "seek": 784648, "start": 7866.4, "end": 7873.0199999999995, "text": " But basically this is going to take a date and pull out of a bunch of columns day of week is at the start of a", "tokens": [583, 1936, 341, 307, 516, 281, 747, 257, 4002, 293, 2235, 484, 295, 257, 3840, 295, 13766, 786, 295, 1243, 307, 412, 264, 722, 295, 257], "temperature": 0.0, "avg_logprob": -0.17145382179008736, "compression_ratio": 1.5848214285714286, "no_speech_prob": 8.801020157989115e-06}, {"id": 1667, "seek": 787302, "start": 7873.02, "end": 7880.160000000001, "text": " Quarter month of year so on and so forth and add them all in to the data set okay, so this is all standard pre-processing", "tokens": [43794, 1618, 295, 1064, 370, 322, 293, 370, 5220, 293, 909, 552, 439, 294, 281, 264, 1412, 992, 1392, 11, 370, 341, 307, 439, 3832, 659, 12, 41075, 278], "temperature": 0.0, "avg_logprob": -0.17150564101135846, "compression_ratio": 1.6979591836734693, "no_speech_prob": 2.769394768620259e-06}, {"id": 1668, "seek": 787302, "start": 7883.360000000001, "end": 7888.740000000001, "text": " Right so we join everything together we fiddle around with some of the dates a little bit some of them are in month and year", "tokens": [1779, 370, 321, 3917, 1203, 1214, 321, 24553, 2285, 926, 365, 512, 295, 264, 11691, 257, 707, 857, 512, 295, 552, 366, 294, 1618, 293, 1064], "temperature": 0.0, "avg_logprob": -0.17150564101135846, "compression_ratio": 1.6979591836734693, "no_speech_prob": 2.769394768620259e-06}, {"id": 1669, "seek": 787302, "start": 7888.740000000001, "end": 7890.740000000001, "text": " Format we turn it into date format", "tokens": [10126, 267, 321, 1261, 309, 666, 4002, 7877], "temperature": 0.0, "avg_logprob": -0.17150564101135846, "compression_ratio": 1.6979591836734693, "no_speech_prob": 2.769394768620259e-06}, {"id": 1670, "seek": 787302, "start": 7891.040000000001, "end": 7893.040000000001, "text": " We spend a lot of time", "tokens": [492, 3496, 257, 688, 295, 565], "temperature": 0.0, "avg_logprob": -0.17150564101135846, "compression_ratio": 1.6979591836734693, "no_speech_prob": 2.769394768620259e-06}, {"id": 1671, "seek": 787302, "start": 7894.080000000001, "end": 7895.92, "text": " trying to", "tokens": [1382, 281], "temperature": 0.0, "avg_logprob": -0.17150564101135846, "compression_ratio": 1.6979591836734693, "no_speech_prob": 2.769394768620259e-06}, {"id": 1672, "seek": 787302, "start": 7895.92, "end": 7901.96, "text": " Take information about for example holidays and add a column for like how long until the next holiday", "tokens": [3664, 1589, 466, 337, 1365, 15734, 293, 909, 257, 7738, 337, 411, 577, 938, 1826, 264, 958, 9960], "temperature": 0.0, "avg_logprob": -0.17150564101135846, "compression_ratio": 1.6979591836734693, "no_speech_prob": 2.769394768620259e-06}, {"id": 1673, "seek": 790196, "start": 7901.96, "end": 7903.96, "text": " How long has it been since the last holiday?", "tokens": [1012, 938, 575, 309, 668, 1670, 264, 1036, 9960, 30], "temperature": 0.0, "avg_logprob": -0.14872157782839054, "compression_ratio": 1.6377358490566039, "no_speech_prob": 9.874618172034388e-07}, {"id": 1674, "seek": 790196, "start": 7904.52, "end": 7906.52, "text": " Did over promos?", "tokens": [2589, 670, 2234, 329, 30], "temperature": 0.0, "avg_logprob": -0.14872157782839054, "compression_ratio": 1.6377358490566039, "no_speech_prob": 9.874618172034388e-07}, {"id": 1675, "seek": 790196, "start": 7906.96, "end": 7913.36, "text": " So on and so forth okay, so we do all that and at the very end we basically save a big", "tokens": [407, 322, 293, 370, 5220, 1392, 11, 370, 321, 360, 439, 300, 293, 412, 264, 588, 917, 321, 1936, 3155, 257, 955], "temperature": 0.0, "avg_logprob": -0.14872157782839054, "compression_ratio": 1.6377358490566039, "no_speech_prob": 9.874618172034388e-07}, {"id": 1676, "seek": 790196, "start": 7913.88, "end": 7917.04, "text": " Structured data file that contains all that stuff", "tokens": [745, 46847, 1412, 3991, 300, 8306, 439, 300, 1507], "temperature": 0.0, "avg_logprob": -0.14872157782839054, "compression_ratio": 1.6377358490566039, "no_speech_prob": 9.874618172034388e-07}, {"id": 1677, "seek": 790196, "start": 7918.28, "end": 7923.4, "text": " Something that those of you that use pandas may not be aware of is that there's a very cool new format called feather", "tokens": [6595, 300, 729, 295, 291, 300, 764, 4565, 296, 815, 406, 312, 3650, 295, 307, 300, 456, 311, 257, 588, 1627, 777, 7877, 1219, 25852], "temperature": 0.0, "avg_logprob": -0.14872157782839054, "compression_ratio": 1.6377358490566039, "no_speech_prob": 9.874618172034388e-07}, {"id": 1678, "seek": 790196, "start": 7924.08, "end": 7926.08, "text": " Which you can save a pandas?", "tokens": [3013, 291, 393, 3155, 257, 4565, 296, 30], "temperature": 0.0, "avg_logprob": -0.14872157782839054, "compression_ratio": 1.6377358490566039, "no_speech_prob": 9.874618172034388e-07}, {"id": 1679, "seek": 792608, "start": 7926.08, "end": 7933.2, "text": " Data frame into this feather format. It's kind of pretty much takes it as it sits in RAM and dumps it to the disk", "tokens": [11888, 3920, 666, 341, 25852, 7877, 13, 467, 311, 733, 295, 1238, 709, 2516, 309, 382, 309, 12696, 294, 14561, 293, 11430, 82, 309, 281, 264, 12355], "temperature": 0.0, "avg_logprob": -0.1682749355540556, "compression_ratio": 1.7103174603174602, "no_speech_prob": 8.93958167580422e-06}, {"id": 1680, "seek": 792608, "start": 7933.2, "end": 7938.76, "text": " and so it's like really really really fast the reason that you need to know this is because the", "tokens": [293, 370, 309, 311, 411, 534, 534, 534, 2370, 264, 1778, 300, 291, 643, 281, 458, 341, 307, 570, 264], "temperature": 0.0, "avg_logprob": -0.1682749355540556, "compression_ratio": 1.7103174603174602, "no_speech_prob": 8.93958167580422e-06}, {"id": 1681, "seek": 792608, "start": 7939.64, "end": 7944.16, "text": " Ecuadorian grocery competition that's on now has 350 million records", "tokens": [41558, 952, 14410, 6211, 300, 311, 322, 586, 575, 18065, 2459, 7724], "temperature": 0.0, "avg_logprob": -0.1682749355540556, "compression_ratio": 1.7103174603174602, "no_speech_prob": 8.93958167580422e-06}, {"id": 1682, "seek": 792608, "start": 7944.84, "end": 7950.86, "text": " So you will care about how long things take it took I believe about six seconds for me to save", "tokens": [407, 291, 486, 1127, 466, 577, 938, 721, 747, 309, 1890, 286, 1697, 466, 2309, 3949, 337, 385, 281, 3155], "temperature": 0.0, "avg_logprob": -0.1682749355540556, "compression_ratio": 1.7103174603174602, "no_speech_prob": 8.93958167580422e-06}, {"id": 1683, "seek": 792608, "start": 7951.16, "end": 7954.42, "text": " 350 million records to feather format so it's pretty cool", "tokens": [18065, 2459, 7724, 281, 25852, 7877, 370, 309, 311, 1238, 1627], "temperature": 0.0, "avg_logprob": -0.1682749355540556, "compression_ratio": 1.7103174603174602, "no_speech_prob": 8.93958167580422e-06}, {"id": 1684, "seek": 795442, "start": 7954.42, "end": 7959.78, "text": " So at the end of all that I'd save it as feather format and for the rest of this discussion", "tokens": [407, 412, 264, 917, 295, 439, 300, 286, 1116, 3155, 309, 382, 25852, 7877, 293, 337, 264, 1472, 295, 341, 5017], "temperature": 0.0, "avg_logprob": -0.20773836544581822, "compression_ratio": 1.6628787878787878, "no_speech_prob": 4.4254620661376975e-06}, {"id": 1685, "seek": 795442, "start": 7959.78, "end": 7963.66, "text": " I'm just going to take it as given that we've got this nicely pre-processed", "tokens": [286, 478, 445, 516, 281, 747, 309, 382, 2212, 300, 321, 600, 658, 341, 9594, 659, 12, 41075, 292], "temperature": 0.0, "avg_logprob": -0.20773836544581822, "compression_ratio": 1.6628787878787878, "no_speech_prob": 4.4254620661376975e-06}, {"id": 1686, "seek": 795442, "start": 7964.26, "end": 7967.7, "text": " Feature engineered file and I can just go read better", "tokens": [3697, 1503, 38648, 3991, 293, 286, 393, 445, 352, 1401, 1101], "temperature": 0.0, "avg_logprob": -0.20773836544581822, "compression_ratio": 1.6628787878787878, "no_speech_prob": 4.4254620661376975e-06}, {"id": 1687, "seek": 795442, "start": 7967.82, "end": 7973.1, "text": " Okay, but for you to play along at home you will have to run those previous cells oh", "tokens": [1033, 11, 457, 337, 291, 281, 862, 2051, 412, 1280, 291, 486, 362, 281, 1190, 729, 3894, 5438, 1954], "temperature": 0.0, "avg_logprob": -0.20773836544581822, "compression_ratio": 1.6628787878787878, "no_speech_prob": 4.4254620661376975e-06}, {"id": 1688, "seek": 795442, "start": 7973.74, "end": 7975.74, "text": " except the", "tokens": [3993, 264], "temperature": 0.0, "avg_logprob": -0.20773836544581822, "compression_ratio": 1.6628787878787878, "no_speech_prob": 4.4254620661376975e-06}, {"id": 1689, "seek": 795442, "start": 7976.3, "end": 7977.9800000000005, "text": " See these ones are commented out", "tokens": [3008, 613, 2306, 366, 26940, 484], "temperature": 0.0, "avg_logprob": -0.20773836544581822, "compression_ratio": 1.6628787878787878, "no_speech_prob": 4.4254620661376975e-06}, {"id": 1690, "seek": 795442, "start": 7977.9800000000005, "end": 7982.4, "text": " You don't have to run those because the file that you download from files dot faster day", "tokens": [509, 500, 380, 362, 281, 1190, 729, 570, 264, 3991, 300, 291, 5484, 490, 7098, 5893, 4663, 786], "temperature": 0.0, "avg_logprob": -0.20773836544581822, "compression_ratio": 1.6628787878787878, "no_speech_prob": 4.4254620661376975e-06}, {"id": 1691, "seek": 798240, "start": 7982.4, "end": 7984.74, "text": " I has already done that for you, okay", "tokens": [286, 575, 1217, 1096, 300, 337, 291, 11, 1392], "temperature": 0.0, "avg_logprob": -0.22280401423357535, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.2679239489443717e-06}, {"id": 1692, "seek": 798240, "start": 7986.139999999999, "end": 7987.86, "text": " All right", "tokens": [1057, 558], "temperature": 0.0, "avg_logprob": -0.22280401423357535, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.2679239489443717e-06}, {"id": 1693, "seek": 798240, "start": 7987.86, "end": 7989.86, "text": " So we basically have", "tokens": [407, 321, 1936, 362], "temperature": 0.0, "avg_logprob": -0.22280401423357535, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.2679239489443717e-06}, {"id": 1694, "seek": 798240, "start": 7990.299999999999, "end": 7992.299999999999, "text": " all these columns", "tokens": [439, 613, 13766], "temperature": 0.0, "avg_logprob": -0.22280401423357535, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.2679239489443717e-06}, {"id": 1695, "seek": 798240, "start": 7992.82, "end": 7995.46, "text": " So it basically is going to tell us", "tokens": [407, 309, 1936, 307, 516, 281, 980, 505], "temperature": 0.0, "avg_logprob": -0.22280401423357535, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.2679239489443717e-06}, {"id": 1696, "seek": 798240, "start": 7996.58, "end": 8001.0199999999995, "text": " You know how many of this thing was sold on?", "tokens": [509, 458, 577, 867, 295, 341, 551, 390, 3718, 322, 30], "temperature": 0.0, "avg_logprob": -0.22280401423357535, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.2679239489443717e-06}, {"id": 1697, "seek": 798240, "start": 8001.74, "end": 8008.0599999999995, "text": " This date at this store and so the goal of this competition is to find out", "tokens": [639, 4002, 412, 341, 3531, 293, 370, 264, 3387, 295, 341, 6211, 307, 281, 915, 484], "temperature": 0.0, "avg_logprob": -0.22280401423357535, "compression_ratio": 1.475609756097561, "no_speech_prob": 1.2679239489443717e-06}, {"id": 1698, "seek": 800806, "start": 8008.06, "end": 8014.4400000000005, "text": " How many things will be sold for each store for each type of thing in the future?", "tokens": [1012, 867, 721, 486, 312, 3718, 337, 1184, 3531, 337, 1184, 2010, 295, 551, 294, 264, 2027, 30], "temperature": 0.0, "avg_logprob": -0.15828708648681641, "compression_ratio": 1.8067632850241546, "no_speech_prob": 3.2887332963582594e-06}, {"id": 1699, "seek": 800806, "start": 8015.64, "end": 8018.92, "text": " Okay, and so that's basically what we're going to be trying to do", "tokens": [1033, 11, 293, 370, 300, 311, 1936, 437, 321, 434, 516, 281, 312, 1382, 281, 360], "temperature": 0.0, "avg_logprob": -0.15828708648681641, "compression_ratio": 1.8067632850241546, "no_speech_prob": 3.2887332963582594e-06}, {"id": 1700, "seek": 800806, "start": 8019.84, "end": 8022.580000000001, "text": " And so here's an example of what some of the data looks like", "tokens": [400, 370, 510, 311, 364, 1365, 295, 437, 512, 295, 264, 1412, 1542, 411], "temperature": 0.0, "avg_logprob": -0.15828708648681641, "compression_ratio": 1.8067632850241546, "no_speech_prob": 3.2887332963582594e-06}, {"id": 1701, "seek": 800806, "start": 8024.360000000001, "end": 8025.4400000000005, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.15828708648681641, "compression_ratio": 1.8067632850241546, "no_speech_prob": 3.2887332963582594e-06}, {"id": 1702, "seek": 800806, "start": 8025.4400000000005, "end": 8026.64, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.15828708648681641, "compression_ratio": 1.8067632850241546, "no_speech_prob": 3.2887332963582594e-06}, {"id": 1703, "seek": 800806, "start": 8026.64, "end": 8030.38, "text": " Next week we're going to see how to go through these steps", "tokens": [3087, 1243, 321, 434, 516, 281, 536, 577, 281, 352, 807, 613, 4439], "temperature": 0.0, "avg_logprob": -0.15828708648681641, "compression_ratio": 1.8067632850241546, "no_speech_prob": 3.2887332963582594e-06}, {"id": 1704, "seek": 800806, "start": 8030.38, "end": 8036.52, "text": " But basically what we're going to learn is we're going to learn to split the columns into two types", "tokens": [583, 1936, 437, 321, 434, 516, 281, 1466, 307, 321, 434, 516, 281, 1466, 281, 7472, 264, 13766, 666, 732, 3467], "temperature": 0.0, "avg_logprob": -0.15828708648681641, "compression_ratio": 1.8067632850241546, "no_speech_prob": 3.2887332963582594e-06}, {"id": 1705, "seek": 803652, "start": 8036.52, "end": 8037.8, "text": " some", "tokens": [512], "temperature": 0.0, "avg_logprob": -0.26790878295898435, "compression_ratio": 1.8657407407407407, "no_speech_prob": 2.829130778536637e-07}, {"id": 1706, "seek": 803652, "start": 8037.8, "end": 8041.72, "text": " Columns we're going to treat as categorical which is to say", "tokens": [4004, 449, 3695, 321, 434, 516, 281, 2387, 382, 19250, 804, 597, 307, 281, 584], "temperature": 0.0, "avg_logprob": -0.26790878295898435, "compression_ratio": 1.8657407407407407, "no_speech_prob": 2.829130778536637e-07}, {"id": 1707, "seek": 803652, "start": 8042.8, "end": 8049.4800000000005, "text": " Store ID one and store ID two are not numerically related to each other their categories", "tokens": [17242, 7348, 472, 293, 3531, 7348, 732, 366, 406, 7866, 984, 4077, 281, 1184, 661, 641, 10479], "temperature": 0.0, "avg_logprob": -0.26790878295898435, "compression_ratio": 1.8657407407407407, "no_speech_prob": 2.829130778536637e-07}, {"id": 1708, "seek": 803652, "start": 8049.72, "end": 8056.68, "text": " All right, we're going to treat day of week like that to Monday and Tuesday day zero and day one not numerically related to each other", "tokens": [1057, 558, 11, 321, 434, 516, 281, 2387, 786, 295, 1243, 411, 300, 281, 8138, 293, 10017, 786, 4018, 293, 786, 472, 406, 7866, 984, 4077, 281, 1184, 661], "temperature": 0.0, "avg_logprob": -0.26790878295898435, "compression_ratio": 1.8657407407407407, "no_speech_prob": 2.829130778536637e-07}, {"id": 1709, "seek": 803652, "start": 8057.320000000001, "end": 8061.040000000001, "text": " Where else distance in kilometers to the nearest?", "tokens": [2305, 1646, 4560, 294, 13904, 281, 264, 23831, 30], "temperature": 0.0, "avg_logprob": -0.26790878295898435, "compression_ratio": 1.8657407407407407, "no_speech_prob": 2.829130778536637e-07}, {"id": 1710, "seek": 803652, "start": 8061.64, "end": 8063.040000000001, "text": " competitor", "tokens": [27266], "temperature": 0.0, "avg_logprob": -0.26790878295898435, "compression_ratio": 1.8657407407407407, "no_speech_prob": 2.829130778536637e-07}, {"id": 1711, "seek": 803652, "start": 8063.040000000001, "end": 8065.280000000001, "text": " That's a number that we're going to treat numerically", "tokens": [663, 311, 257, 1230, 300, 321, 434, 516, 281, 2387, 7866, 984], "temperature": 0.0, "avg_logprob": -0.26790878295898435, "compression_ratio": 1.8657407407407407, "no_speech_prob": 2.829130778536637e-07}, {"id": 1712, "seek": 806528, "start": 8065.28, "end": 8070.5599999999995, "text": " Right so in other words the categorical variables. We basically are going to one-hot encode them", "tokens": [1779, 370, 294, 661, 2283, 264, 19250, 804, 9102, 13, 492, 1936, 366, 516, 281, 472, 12, 12194, 2058, 1429, 552], "temperature": 0.0, "avg_logprob": -0.20023137872869318, "compression_ratio": 1.7008928571428572, "no_speech_prob": 2.482471700204769e-06}, {"id": 1713, "seek": 806528, "start": 8071.28, "end": 8077.92, "text": " You can think of it as one-hot encoding them where else the continuous variables. We're going to be feeding into fully connected layers", "tokens": [509, 393, 519, 295, 309, 382, 472, 12, 12194, 43430, 552, 689, 1646, 264, 10957, 9102, 13, 492, 434, 516, 281, 312, 12919, 666, 4498, 4582, 7914], "temperature": 0.0, "avg_logprob": -0.20023137872869318, "compression_ratio": 1.7008928571428572, "no_speech_prob": 2.482471700204769e-06}, {"id": 1714, "seek": 806528, "start": 8078.679999999999, "end": 8080.48, "text": " Just as is", "tokens": [1449, 382, 307], "temperature": 0.0, "avg_logprob": -0.20023137872869318, "compression_ratio": 1.7008928571428572, "no_speech_prob": 2.482471700204769e-06}, {"id": 1715, "seek": 806528, "start": 8080.48, "end": 8082.44, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.20023137872869318, "compression_ratio": 1.7008928571428572, "no_speech_prob": 2.482471700204769e-06}, {"id": 1716, "seek": 806528, "start": 8082.44, "end": 8084.8, "text": " So what we'll be doing is we'll be basically", "tokens": [407, 437, 321, 603, 312, 884, 307, 321, 603, 312, 1936], "temperature": 0.0, "avg_logprob": -0.20023137872869318, "compression_ratio": 1.7008928571428572, "no_speech_prob": 2.482471700204769e-06}, {"id": 1717, "seek": 806528, "start": 8085.92, "end": 8087.88, "text": " creating a", "tokens": [4084, 257], "temperature": 0.0, "avg_logprob": -0.20023137872869318, "compression_ratio": 1.7008928571428572, "no_speech_prob": 2.482471700204769e-06}, {"id": 1718, "seek": 806528, "start": 8087.88, "end": 8090.8, "text": " Validation set and you'll see like a lot of these are start to look familiar", "tokens": [7188, 327, 399, 992, 293, 291, 603, 536, 411, 257, 688, 295, 613, 366, 722, 281, 574, 4963], "temperature": 0.0, "avg_logprob": -0.20023137872869318, "compression_ratio": 1.7008928571428572, "no_speech_prob": 2.482471700204769e-06}, {"id": 1719, "seek": 809080, "start": 8090.8, "end": 8095.2, "text": " This is the same function we used on planet and dog breeds to create a validation set", "tokens": [639, 307, 264, 912, 2445, 321, 1143, 322, 5054, 293, 3000, 41609, 281, 1884, 257, 24071, 992], "temperature": 0.0, "avg_logprob": -0.19373339873093826, "compression_ratio": 1.6377952755905512, "no_speech_prob": 3.9278563690459123e-07}, {"id": 1720, "seek": 809080, "start": 8097.08, "end": 8099.08, "text": " There's some stuff that you haven't seen before", "tokens": [821, 311, 512, 1507, 300, 291, 2378, 380, 1612, 949], "temperature": 0.0, "avg_logprob": -0.19373339873093826, "compression_ratio": 1.6377952755905512, "no_speech_prob": 3.9278563690459123e-07}, {"id": 1721, "seek": 809080, "start": 8099.96, "end": 8101.96, "text": " Where we're going to?", "tokens": [2305, 321, 434, 516, 281, 30], "temperature": 0.0, "avg_logprob": -0.19373339873093826, "compression_ratio": 1.6377952755905512, "no_speech_prob": 3.9278563690459123e-07}, {"id": 1722, "seek": 809080, "start": 8102.0, "end": 8106.28, "text": " Basically rather than saying image data dot from CSV", "tokens": [8537, 2831, 813, 1566, 3256, 1412, 5893, 490, 48814], "temperature": 0.0, "avg_logprob": -0.19373339873093826, "compression_ratio": 1.6377952755905512, "no_speech_prob": 3.9278563690459123e-07}, {"id": 1723, "seek": 809080, "start": 8106.4400000000005, "end": 8110.24, "text": " We're going to say column our data from data frame, right?", "tokens": [492, 434, 516, 281, 584, 7738, 527, 1412, 490, 1412, 3920, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.19373339873093826, "compression_ratio": 1.6377952755905512, "no_speech_prob": 3.9278563690459123e-07}, {"id": 1724, "seek": 809080, "start": 8110.24, "end": 8115.72, "text": " So you can see like the basic API concepts will be the same, but they're a little different right?", "tokens": [407, 291, 393, 536, 411, 264, 3875, 9362, 10392, 486, 312, 264, 912, 11, 457, 436, 434, 257, 707, 819, 558, 30], "temperature": 0.0, "avg_logprob": -0.19373339873093826, "compression_ratio": 1.6377952755905512, "no_speech_prob": 3.9278563690459123e-07}, {"id": 1725, "seek": 811572, "start": 8115.72, "end": 8119.6, "text": " but just like before we're going to get a learner and", "tokens": [457, 445, 411, 949, 321, 434, 516, 281, 483, 257, 33347, 293], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1726, "seek": 811572, "start": 8120.92, "end": 8122.92, "text": " We're going to go LR find", "tokens": [492, 434, 516, 281, 352, 441, 49, 915], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1727, "seek": 811572, "start": 8123.16, "end": 8125.16, "text": " to find our best learning rate and", "tokens": [281, 915, 527, 1151, 2539, 3314, 293], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1728, "seek": 811572, "start": 8125.84, "end": 8128.64, "text": " Then we're going to go dot fit with a metric", "tokens": [1396, 321, 434, 516, 281, 352, 5893, 3318, 365, 257, 20678], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1729, "seek": 811572, "start": 8129.240000000001, "end": 8131.240000000001, "text": " with a cycle length", "tokens": [365, 257, 6586, 4641], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1730, "seek": 811572, "start": 8131.4800000000005, "end": 8135.16, "text": " Okay, so the basic sequence is going to end up looking", "tokens": [1033, 11, 370, 264, 3875, 8310, 307, 516, 281, 917, 493, 1237], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1731, "seek": 811572, "start": 8135.96, "end": 8139.280000000001, "text": " Hopefully very familiar okay, so we're out of time", "tokens": [10429, 588, 4963, 1392, 11, 370, 321, 434, 484, 295, 565], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1732, "seek": 811572, "start": 8140.12, "end": 8142.76, "text": " so what I suggest you do this week is like", "tokens": [370, 437, 286, 3402, 291, 360, 341, 1243, 307, 411], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1733, "seek": 811572, "start": 8143.52, "end": 8145.320000000001, "text": " try to", "tokens": [853, 281], "temperature": 0.0, "avg_logprob": -0.2239340949304325, "compression_ratio": 1.642156862745098, "no_speech_prob": 1.873869109658699e-06}, {"id": 1734, "seek": 814532, "start": 8145.32, "end": 8151.679999999999, "text": " Enter as many Kaggle image competitions as possible like like try to really get this feel for like", "tokens": [10399, 382, 867, 48751, 22631, 3256, 26185, 382, 1944, 411, 411, 853, 281, 534, 483, 341, 841, 337, 411], "temperature": 0.0, "avg_logprob": -0.17323821630233374, "compression_ratio": 1.64, "no_speech_prob": 6.854250386822969e-06}, {"id": 1735, "seek": 814532, "start": 8152.4, "end": 8154.4, "text": " cycle lengths learning rates", "tokens": [6586, 26329, 2539, 6846], "temperature": 0.0, "avg_logprob": -0.17323821630233374, "compression_ratio": 1.64, "no_speech_prob": 6.854250386822969e-06}, {"id": 1736, "seek": 814532, "start": 8155.759999999999, "end": 8157.759999999999, "text": " plotting things", "tokens": [41178, 721], "temperature": 0.0, "avg_logprob": -0.17323821630233374, "compression_ratio": 1.64, "no_speech_prob": 6.854250386822969e-06}, {"id": 1737, "seek": 814532, "start": 8158.4, "end": 8160.4, "text": " You know that", "tokens": [509, 458, 300], "temperature": 0.0, "avg_logprob": -0.17323821630233374, "compression_ratio": 1.64, "no_speech_prob": 6.854250386822969e-06}, {"id": 1738, "seek": 814532, "start": 8161.639999999999, "end": 8167.62, "text": " That post I showed you at the start of class today that kind of took you through lesson one like", "tokens": [663, 2183, 286, 4712, 291, 412, 264, 722, 295, 1508, 965, 300, 733, 295, 1890, 291, 807, 6898, 472, 411], "temperature": 0.0, "avg_logprob": -0.17323821630233374, "compression_ratio": 1.64, "no_speech_prob": 6.854250386822969e-06}, {"id": 1739, "seek": 814532, "start": 8168.24, "end": 8172.679999999999, "text": " Really go through that on as many image data sets as you can to just feel", "tokens": [4083, 352, 807, 300, 322, 382, 867, 3256, 1412, 6352, 382, 291, 393, 281, 445, 841], "temperature": 0.0, "avg_logprob": -0.17323821630233374, "compression_ratio": 1.64, "no_speech_prob": 6.854250386822969e-06}, {"id": 1740, "seek": 817268, "start": 8172.68, "end": 8175.360000000001, "text": " Really comfortable with it right?", "tokens": [4083, 4619, 365, 309, 558, 30], "temperature": 0.0, "avg_logprob": -0.18350601196289062, "compression_ratio": 1.625, "no_speech_prob": 7.646171070518903e-06}, {"id": 1741, "seek": 817268, "start": 8176.4400000000005, "end": 8180.12, "text": " Because you want to get to the point where next week when we start talking about structured data", "tokens": [1436, 291, 528, 281, 483, 281, 264, 935, 689, 958, 1243, 562, 321, 722, 1417, 466, 18519, 1412], "temperature": 0.0, "avg_logprob": -0.18350601196289062, "compression_ratio": 1.625, "no_speech_prob": 7.646171070518903e-06}, {"id": 1742, "seek": 817268, "start": 8180.240000000001, "end": 8186.84, "text": " That this idea of like how learners kind of work and data works and data loaders and data sets and looking at pictures", "tokens": [663, 341, 1558, 295, 411, 577, 23655, 733, 295, 589, 293, 1412, 1985, 293, 1412, 3677, 433, 293, 1412, 6352, 293, 1237, 412, 5242], "temperature": 0.0, "avg_logprob": -0.18350601196289062, "compression_ratio": 1.625, "no_speech_prob": 7.646171070518903e-06}, {"id": 1743, "seek": 818684, "start": 8186.84, "end": 8204.36, "text": " Should be really you know intuitive all right good luck. See you next week you", "tokens": [50364, 6454, 312, 534, 291, 458, 21769, 439, 558, 665, 3668, 13, 3008, 291, 958, 1243, 291, 51240], "temperature": 0.0, "avg_logprob": -0.39484970193160207, "compression_ratio": 1.04, "no_speech_prob": 2.4268740162369795e-05}], "language": "en"}