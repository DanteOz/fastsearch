{"text": " Welcome to another episode of Arraycast. I'm your host, Connor, and today we have a very exciting guest, which we will introduce in a second. But before we do that, we'll do brief introductions and then one announcement. So first we'll go to Bob and then we'll go to Adam, who has the one announcement. And then we will introduce our guest. I'm Bob Theriot. I'm a J enthusiast and I do some work with the J Wiki we're underway in trying to get it all set up for the fall. I'm Adam B\u0142ocewski, full-time APL programmer at Dialog Limited. Besides for actually programming APL, I also take care of all kinds of social things, including the APL Wiki. And then for my announcements, part of what we do at Dialog is arrange a yearly user meeting or a type of conference. And at that user meeting, there is also a presentation by the winner of the APL problem solving competition. That competition closes at the end of the month. So hurry up if you want to participate. It's not too late even to get started at this point. And also at the end of the month is the end of the early bird discount for the user meeting itself. Awesome. And just a note about that contest. I think and Adam can correct me if I'm wrong. There's two phases. In the first phase, it's just 10 short problems. A lot of them are just one liners. And even if you only solve one of the 10, I think you can win a small cash prize just from answering one. Is that correct? I'm not even sure you might need to solve. Might need to solve them all. They're really easy. So the point being those that you don't need to complete the whole contest in order to be eligible to win prizes. For sure. There's a certain amount that if you get to that point, you hit a certain threshold and you can be eligible to win some free money, which is always awesome. And yeah, just briefly, as I introduced myself in every other episode, I'm your host, Connor C++ professional developer. Not an array language developer in my day to day, but a huge array language and combinator enthusiast at large, which brings us to introducing our guest. Who is Jeremy Howard, who has a very, very, very long career. And you probably have heard him on other podcasts or have been giving other talks. I'll read the first paragraph of his three paragraph bio because I don't want to embarrass him too much, but he has a very accomplished career. So Jeremy Howard is a data scientist, researcher, developer, educator and entrepreneur. He is the founding researcher at Fast AI, a research institute dedicated to making deep learning more accessible and is an honorary professor at the University of Queensland. That's in Australia, I believe. Previously, Jeremy was a distinguished research scientist at the University of San Francisco, where he was the founding chair of the Wicklow Artificial Intelligence and Medical Medical Research Initiative. He's also been the CEO of Unlitic and was the president and chief scientist of CAGO, which is the basically data science version of LeakCode, which many software developers are familiar with. He was the CEO of two successful Australian startups, Fastmail and Optimal Decisions Group. And before that, in between doing a bunch of other things, he worked in management consulting at McKinsey, which is an incredibly interesting start to a career that he has had now. Because for those of you that don't know, McKinsey is one of the three biggest management consulting firms alongside, I think, Bain & Co and BCG. So I'm super interested to hear how he started in management consulting and ended up being the author of one of the most popular AI libraries in Python and also the course that's attached to it, which I think is, if not, the most popular, a very, very popular course that students all around the world are taking. So I will stop there, throw it over to Jeremy, and he can fill in all the gaps that he wants, jump back to however far you want to to tell us how you got to where you are now. And I think the one thing I forgot to mention, too, is that he recently tweeted on July 1st and we're recording this on July 4th that he quote the tweets reads, next week, I'm starting a daily study group on my most loved programming language, APL. And so obviously interested to hear more about that tweet and what's going to be happening with that study group. So over to you, Jeremy. Well, the study group is starting today as we record this. So depending on how long it takes to get this out, it'll have just started. And so definitely time for people to join in. So I'm sure we'll include a link to that in the show notes. I definitely feel kind of like I'm your least qualified array programming person ever interviewed on this show. I love APL and J, but I've done very, very little with them, particularly APL. I've done a little, little bit with J mucking around, but like, I find a couple of weeks here and there every few years and I have for a couple of decades. Having said that, I am a huge enthusiast of array programming as it is used, you know, in a loopless style in other languages. Additionally, in Pell and nowadays in Python. Yeah, maybe I'll come back to that because I guess you wanted to get a sense of my background. Yeah. So I actually started at McKinsey. I grew up in Melbourne, Australia, and I didn't know what I wanted to do when I grew up at the point that you're meant to know when you choose a university, you know, major. So I picked philosophy on the basis that it was like, you know, the best way of punting down the road, what you might do because with philosophy, you can't do anything. And honestly, that kind of worked out in that I needed money, and I needed money to get through university so I got a one day a week kind of IT support job at McKinsey, the McKinsey Melbourne office during university from first year, I think that's from first year. But it turned out that like, yeah, I was very curious and so I'm so curious about management consulting so every time consultants would come down and ask me to like, you know, clean out the sticky coke they spilt in their keyboard or whatever. I would always ask them what they were working on and ask them to show me and I've been really interested in like doing analytics see kind of things for a few years at that point so during high school basically every holidays I kind of worked on. I kind of worked on stuff with spreadsheets or Microsoft access or whatever so I turned out I knew more about like stuff like Microsoft Excel than they did. So within about two months of me starting this one day a week job I was working 90 hour weeks, basically doing analytical work for the consultants. And that, you know, that actually worked out really well because I kind of did a deal with them where they would, they gave me a full time office and they would pay me $50 an hour for whatever time I needed and so suddenly I was actually making a lot of money, you know, working, working 90 hours a week. And, yeah, it was great because then the, I would come up with these solutions to things are doing in the projects and I'd have to present it to the client so next thing I knew I was basically on the client side all the all the time. So I ended up actually not going to any lectures at university. And I somehow kind of managed this thing where I would take two weeks off before each exam, go and talk to all my lecturers and say hey I was meant to be in your university course. I know you didn't see me but I was kind of busy. Can you tell me what I was meant to have done. So I kind of scraped by a BA in philosophy but I don't, yeah, you know, I don't really have much of an academic background, but that did give me a great background in like applying stuff like, you know, linear regression and just regression and linear programming and you know the basic analytical tools of the day, generally through VBA scripts in Excel or, you know, access, you know, the kind of stuff that a consultant could check out it you know on to their, onto their laptop at a client site. Anyway, I always feel guilty about doing that because it just seemed like this ridiculously nerdy thing to be doing when I was surrounded by all these very important, you know, consultant types who seemed to be doing much more impressive strategy work so I tried to get away from that as quickly as I could, because I didn't want to be the nerd in the company. And yeah so I ended up spending the next 10 years basically doing strategy consulting. But throughout that time I did, you know, because I didn't have the same background that they did that the expertise they did the MBA they did I had to solve things using data and analytically intensive approaches so, although in theory I was a strategy management consultant and I was working on problems like, you know, how do we fix the rice industry in Australia, or, you know, how do we, you know, like, you know, how do we deal with this new competitor coming into this industry or whatever it was I always did it by analyzing data, which actually turned out to be a good niche you know because I was the one McKinsey consultant in Australia who did things that way and so I was successful and I became I think the, I ended up moving to ATKani which is the other of the two original management consulting firms. I think I became like the youngest manager in the world and you know, through this weird parallel path I was doing. And then through that learned about insurance industry discovered it like the whole insurance industry was basically pricing things in a really dumb way. I focused on optimization of optimized pricing launched a company with my university friend who had a PhD in operations research. And, yeah, so we built this new approach to pricing insurance which is, it was kind of fun I mean it's, you know, it went well in the set you know commercially took a bit about 10 years doing, doing that, and at the same time, running an email company called fast mail, which also went well. So I started out basically using C++, and I would say that was kind of the start of my array programming journey in that in those days this is like 1999. The very first expression templates based approaches to C++ numeric programming were appearing. And so I, you know, was talking to the people working on those libraries doing stuff like particularly stuff doing the big kind of high energy physics experiments that were going on in Europe. It was ultimately pretty annoying to work with though like the amount of time it took to compile those things that would take hours, and it was quirky as all hell, you know it's still pretty quirky doing meta programming in C++ but in those days it was just a nightmare every compiler was different. So I ended up switching to C sharp shortly after that came out, and, you know, move in a way it was disappointing because that was much less expressive as a kind of array programming paradigm. And so instead I ended up basically grabbing Intel's MKL library, which is basically a blast on steroids, if you like, and writing my own C sharp wrapper to give me, you know, kind of array programming ish capabilities but not with any of the features that anyone would come to expect from a real array programming language around kind of dealing with rank sensibly and, you know, not much in the way of broadcasting, which reminds me we should come back to talking about blast at some stage because a lot of the reasons that most languages are so disappointing at array programming is because of our reliance on blasts, you know as an industry. Fast mail on the other hand is being written in Perl, which I really enjoyed as a programming language and still to still love pill a lot. But the scientific programming in Pearl. I didn't love at all. And so, at the time, Pearl six, you know, we was just starting to the idea of it was being developed so I ended up running the Pell six working group to add scientific programming capabilities or kind of, you know, and at the time I described it as APL inspired programming capabilities to Pearl. And so I did an RFC around what we ended up calling hyper operators which is basically the idea that any operator can can operate on arrays and can broadcast over any axes that are that are that are mismatched or whatever. And those RFC is all ended up getting accepted and Damien Conway and Larry war kind of expanded them a little bit. Pell six never exactly happened it ended up becoming a language called record. With the butterfly logo. Yeah, and that, you know, and the kind of the performance ideas I really worked hard on never really happened either so that was a bit of a, yeah, that was all a bit of a failure. But it was fun and it was interesting. I, you know, so after running these companies for 10 years. One of the big problems with running a company is that you're surrounded by people who you hired, and they, you know, have to make you like them if they want to get promoted, you know get fired and so you could never trust anything anybody says. So I was, you know, very bad very low expectations about my capabilities analytics leaks I hadn't like, you know, I basically been running companies for 10 years. I did a lot of coding and stuff but it was in our own little wealth. And so, after I sold those companies. Yeah, I, one of the things I decided to do was to try actually to become more competent. You know I had lost my. To some extent, I had, I had lost my feeling that I should hide my nerdiness, you know, and try to act like a real business person, and I thought no I should actually see if I'm actually any good at this stuff. So I tried entering a machine learning competition at a new company that had just been launched called Kaggle. With this goal of like not coming last. And basically, the, you know, the way these things work is you have to make predictions on a data set, and at the end of the competition who has predictions for the most accurate wins the prize. And so my goal was, yeah, try not to come last, which I wasn't convinced I'd be able to achieve. Because as I say I didn't feel like this is. I'd never had any technical training, you know and everybody else in these competitions with PhDs and professors or whatever else so it felt like a high bar. Anyway, I ended up winning it. And that that changed my life. Right, because, yeah, it was like, Oh, okay I am, you know, empirically good at this thing. And people at my local user groups I we used are quite a bit as well. Were you know I told them, I'm going to try entering this competition, anyone want to create a team with me I want to like learn to use our properly and I kind of went back to the next user group meeting and people were like, I thought you were just learning this thing. How did you. How did you win. I don't know. I just use common sense. Yeah, so I ended up becoming the chief scientist and president of Kaggle and Kaggle as you know anybody in the data science world knows is kind of grown into this huge, huge thing ended up selling it to Google. So I ended up being an equal partner in the company I was the first investor in it. And that was great that was like, I just dove in we moved to San Francisco for 10 years. And, you know, surrounded, surrounded by all these people who I just sort of role models and idols, and partly getting to meet all these people in San Francisco was this experience of realizing all these people were actually totally normal, you know, they weren't like some super genius level like they're just normal people who. I think in Australia. It's very easy to feel at it all like, yeah, we, we're not very confident about capabilities over here other than in sport, perhaps. Yeah, so one of the things that happened well as a Kaggle was, I had played around with neural networks, a bit, a good bit, you know, like 20 years earlier. And I always felt like neural networks were one day going to be the thing it's like you know they are on a theoretical level, infinitely capable. But, you know, they never quite did it for me and. But then in 2012, suddenly, neural networks started achieving superhuman performance for the first time on really challenging problems like recognizing traffic signs, you know, like recognizing pictures. And I'd always said to myself, I was going to watch for this moment and when it happened I wanted to like jump on it. So as soon as I saw that I tried to jump on it so I started a new company. After a year of research into like the, you know, what, what a neural networks going to do. I decided medicine was going to be huge. I knew nothing about medicine. And I, yeah, I started a medicine company to see what we could do with deep learning and medicine. So that was analytic. Yeah, that ended up going pretty well. And, yeah, eventually I kind of got like a bit frustrated with that though because it felt like big learning can do so many things and I'm only doing such a small part of those things. So deep learning is like neural networks with multiple layers. And so the only way to actually help people really, you know, make the most of this incredibly valuable technology is to teach other people how to do it, and to help other people to do it. So my wife and I ended up studying a new, I call it kind of a research lab, Fast AI, to help to help do that basically initially focus on education and then increasingly focus on research and software development to basically make it easier for folks to use deep learning. And that's, yeah, that's where I am now. And that everything in deep learning is all Python. And in Python, we're very lucky to have, you know, excellent libraries that behave pretty consistently with each other, basically based around this NumPy library, which treats arrays very, very similarly to how Jay does, except rather than leading access, it's trailing access but basically you get, you know, you get loop free, you get broadcasting, you know, you don't get things like a rank conjunction, but there's very easy ways to permute axes so you can do basically the same thing. Things like Einstein notation, you know, built into the libraries and then you know it's, it's trivially easy to have them run on GPUs or TPUs or whatever, you know, so for the last few years of my life, nearly all the code I write is array programming code, even though I'm not using a purely array language. All right, so where do we start now with the questions. I'll let Bob and Adam go first if they want. And if they if they don't have a, okay, Bob, you go ahead. I've got a quick question about, about neural networks and stuff because when I was going to university all those years ago. People were talking about neural networks and then they just sort of dropped off the face and as you said around 2010 suddenly they resurfaced again. What do you think was the cause of that resurfacing was it hardware was it somebody discovered a new method or what. Yeah, mainly hardware. So what happened was people figured out how to do GP GPU so general purpose, GPU computing. So before that I tried a few times to use GPUs with neural nets I felt like that would be the thing that GPUs were all about like creating shaders and whatever, and it was a whole jargon thing I didn't even understand what was going on. So, the key thing was Nvidia coming up with this CUDA approach, which it's it's all loops, right, but it's much easier than the old way like the loops you basically, it's kind of loops you basically say to to CUDA. This is my kernel which is the piece of code I want to basically run on each symmetric multi processing unit. And then you basically say launch a bunch of threads. And it's going to call your kernel, you know, basically incrementing the x and y coordinates and passing it to your kernel or making them available to your kernel. So it's a kind of it's not exactly a loop but it's this case more like a map, I guess. So when CUDA appeared, very quickly, neural network libraries appeared to take advantage, appeared that would take advantage of it. And then suddenly, you know, you get orders of magnitude more performance, and it's cheaper, and you get to buy an Nvidia graphics card with a free copy of Batman, you know, on the excuse that actually this is all for work. But it was it was mainly that there's also this just like at the same time. The thing I've been doing for 25 years, suddenly got a name, data science, you know, we like this is very small industry of people like applying data driven approaches to solving business problems. And we were always looking for a name. I know this but back in the very early days, there was an attempt to calling it industrial mathematics. Sometimes people would like shoehorn it into operations research or management science but that was almost exclusively optimization people and specifically people focused more on linear programming approaches. So yeah, once data science appeared and also like, you know, basically every company had finally built their data warehouse and the data was there. So yeah, it's like a more awareness of using data to solve business problems, and for the first time availability of the hardware that we actually needed. And as I say in 2012. It just it's it reached the point like it been growing. Since the first neural network was built in was at 1957, I guess, that this kind of gradual rate, but once it passed human performance on some tasks. It just kept going. And so now, in the last couple of months you know it's now like getting decent marks on MIT math tests and stuff it's it's it's an amazing trajectory. It's kind of a critical mass kind of thing you get a certain amount of information and able to process and information. It, I guess, as you as you do with your hand it's an exponential curve. Yeah, humans and exponential curves I think we're finding over and over again. We're not really great at at understanding an exponent. No, we're not. And that's like why I promised myself that as soon as I saw neural nets starting to look like they're doing interesting things I would drop everything and jump on it, because I wanted to jump on that curve as early as possible. And we're now in this situation where people are just making huge amounts of money with neural nets, which they then reinvest back into making the neural nets better. And so we are also seeing this kind of bifurcation of capabilities where there's a small number of organizations who are extremely good at this stuff and invested in it and a lot of organizations that are, you know, really struggling to figure it out. And because of the exponential nature when it happens it happens very quickly. It feels like you didn't see it coming and suddenly it's there and then it was past you. I think we're all experiencing that now. Yeah, and it's happened in so many industries, you know, back in my medical startup. You know, we were interviewing folks around medicines we interviewed a guy finishing his PhD in histopathology. And I remember he you know he came in to do an interview with us. And he basically gave us a presentation about his thesis on kind of graph cut segmentation approaches pathology slides. And at the end he is like anyway that was my PhD and then yesterday because I knew I was coming to see you guys and I heard you like neural nets I just thought I'd check out neural nets. And about four hours later I trained a neural net to do the same thing I did for my PhD, and it way outperformed my PhD thesis I'd spent the last five years on. And so that's where I'm at, you know, and we hear this a lot. existential crisis in the middle of an interview. So I kind of have, I don't know this is like a one, a, b and c. And I'm not sure if I should ask them all at once. But so you said sort of at the tail end of the 90s is when your array language journey started but it seems from the way you explained it that you had already at some point along the way heard about the array languages, APL and Jay, and have sort of alluded to, you know, picking up some knowledge about the paradigm and the languages. So, my first part of the question is sort of, you know, at what point were you exposed to the paradigm in these languages. The second part is what what's causing you in 2022 to, you know, really dive into it because you said, you feel like maybe a bit of an imposter or the least qualified guest, which probably is you just being very modest I'm sure you know still quite a bit. So, the third part is, do you have thoughts about, and I've always sort of wondered how the array language paradigm sort of missed out on, like, and Python ended up being the main data science language. And so, while like there's like an article that's floating around online called numpy. The ghost of Iverson, which it's it's this sort of you can see that in the names and the design of the library that there is an core of APL and even the documentation acknowledges that it took inspiration greatly from J and APL, but that, like the array languages clearly missed missed what was a golden opportunity for their paradigm. And so, I'm going to go back to the question of libraries and other languages so I just asked three questions at once or feel free to tackle them in any order. I have a pretty bad memory so I'll. I think I've forgotten the second one already so you can feel free to come back to any or all of them. So, my journey, which is what you started with was. I always felt like I was going to be left without using code, because I, or at least like kind of traditional what I guess we'd call nowadays imperative code. I, there was a couple of tools in my early days which I've got huge amounts of leverage from because nobody else in, in, at least the consulting firms or generally in our clients knew about them. SQL and pivot tables. And so pivot tables if you haven't come across it was basically the one of the earliest purchase to overlap you know slicing and dicing. There was actually something slightly earlier called Lotus improv. But that was actually a separate product Excel was basically the first one to put our lab in the spreadsheet. So no loops, you just drag and drop the things you want to group by and you right click to choose how to summarize. And then you can go to SQL, you know, you declaratively say what you want to do you don't have to loop through things. SAS actually had something similar, you know with SAS you could basically declare a prop that would run on your data. So yeah, I kind of felt like this was the way I would rather do stuff if I could. I was always out of doing the C++ implementation of the insurance pricing stuff of being much more drawn to these meta programming approaches. I just didn't want to be writing loops in loops and dealing with all that stuff just, I'm too lazy, you know, to do that. I think I'm very driven by laziness, which is Larry Wall said is one of the three virtues of a great programmer. Then, yeah, so I think when, as soon as I saw NumPy had reached a level of some reasonable confidence in Python, I was very drawn to that because that's what I've been looking for. And I think maybe that actually is going to bring us to answering the question of like what happened to array languages. Python has a lot of problems, but at its heart, it's a very well designed language. It has a very small flexible core. Personally, I don't like the way most people write it, but I've been so flexible I've able to create almost my own version of Python, which is very functionally oriented, I basically have stolen the type dispatch ideas from Julia, created an implementation of that in Python. So I you know my Python code doesn't look like most Python code, but I can use all the stuff that's that's in Python. So this is very nicely designed core of a language, which I then have this almost this DSL on top of, you know, NumPy is able to create this kind of DSL again because it's working on such a flexible foundation. Ideally, you know, I mean, it will okay so Python also has another DSL built into it which is math, you know, I can use the operators plus times minus that's that's convenient and in every array library, NumPy, PyTorch, TensorFlow and Python, those operators work over arrays and do broadcasting over axes and so forth and, you know, accelerate on an accelerator, like a GPU or TPU. That's all great. I, you know, my ideal world would be that I wouldn't just get to use plus times minus but I get to use all the APL symbols. You know, that would be, that would be amazing. But given a choice between a really beautiful language, you know, at its core like Python, in which I can then add a slightly cobbled together DSL like NumPy, I would much prefer that over a really beautiful notation like APL, but without the fantastic language underneath, you know, like I don't feel like I, there's nothing about APL or JP or J or K's like programming language that attracts me, you know what I mean, I feel like in terms of like what I could do around, around whether it be type dispatch or how OO is designed, or, you know, how I package modules or almost anything else I would prefer the Python way. So I feel like that's, that's basically what we've ended up with you kind of either compromise between, you know, a good language with, you know, slightly substandard notation or amazingly great notation with the substandard language, not just language but ecosystem. I think, I hope one day we'll get the best of both. Right. Like, here's my. Okay, here's my controversial take it may just represent my lack of knowledge. What I like about APL is its notation. I think it's a, it's a beautiful notation I don't think it's a beautiful programming language. I think some things, possibly everything, you know, some things work very well as a notation. But to get to get to raise something to the point that it is a notation requires some years of study and development, and often some genius, you know, like the genius of Feynman diagrams, or the genius of juggling notation, you know, like, there are people who, who find a way to turn a field into a notation, and suddenly they blow that field apart and make it better for everybody. For me, like, I don't want to think too hard all the time. Every time I come across something that really hasn't been turned into a notation yet. I just like, I just want to get it done, you know, and so I would rather only use notation. When I'm in these fields that either somebody else had figured out how to make that a notation, or I feel like it's really worth be investing to figure that out. Otherwise, you know, there are, and the other thing I'd say is we already have notations for things that aren't APL that actually work really well, like regular expressions, for example, that's, that's a fantastic notation, and I don't want to replace that with APL glyphs, I just want to use regular expressions. So yeah, my ideal world would be one where we, where I can write pytorch code, but maybe instead of like Einstein operations, Einstein notation, I could use APL notation. I think that's where I would love to get to one day and I would love that to totally transparently run on a GPU or TPU as well. That would be my happy place. It has no reason to do with the fact that I work in Nvidia that I would love that. But interesting, I've never heard that before the difference between basically appreciating or being in love with the notation but not the language itself. I've never heard that. I know it started out as a notation right like I was in talk, you know, it was a notation they used for representing state machines whatever on the early IBM hardware, you know, when he did his Turing Award essay he chose to talk about his notation. And I've seen with people like, like, like Aaron, with, with his code defense stuff that if you take a very smart person and give them a few years, they can use that notation to solve incredibly challenging problems like build a compiler and do it better than you can without that notation. And I think like, yeah, a PL can't be used for almost anything you want to use it for but a lot of the time we don't have five years to study something very closely, we just want to, you know, we've got to get something done by tomorrow. Interesting. We still didn't get a answer to. Oh yeah, when did you first, when did you first meet a PL, how did you even find a PL. I first found J, I think, which obviously led me to a PL, and I don't quite remember where I saw it. Yeah. And actually, when I got to San Francisco. So that would be I don't remember 2010 or something I'm not sure. I actually reached out to Eric Iverson and I said like, Oh, we're starting this machine learning company called Kaggle and I kind of feel like, you know, everybody does stuff in Python and it's kind of in a lot of ways really disappointing I wish we were doing stuff in J, you know, but we really need everything to be running on the GPU or at least everything to be automatically using SIMD and multi processor everywhere. He was kind enough to actually jump on a Skype call with me, not just jump on a Skype call, but it's like, how do you want to chat and say, how about Skype and he created a Skype account. Yeah, we chatted for quite a while. We talked about, you know, these, these, these kinds of hopes and yeah, but I just, you know, never really because because neither J or APL is in that space yet. There was just never a reason for me to do anything other than like, I kind of felt like each time I'd have a bit of a break for a couple of months I'd always spend a couple of weeks fiddling around with J just for fun. But that's, that's as far as I got really. Yeah, I think the first time I'd heard of you was in an interview that Leo Laporte did with you on triangulation and you were talking about Kaggle. That was a specific thing. But I think I was riding my bike along some logging or something and suddenly he said, Oh yeah, but a lot of people use J. I like J. It's the first time I'd ever heard anybody on a podcast say anything about J. It was just like, wow, that's amazing. I didn't know what, you know, like, and, and the whole interview about Kaggle. There was so much of it about the importance of data processing, not just having a lot of data, but you know how to filter it down, not over filtering all those tricks. I'm thinking, wow, these guys really doing some deep stuff with this stuff and this guy is using J. I was actually very surprised at that point that somebody, I guess not somebody who was working so much with data would know about J, but just that it would be, I guess just suddenly popped onto my headsets and I'm just, wow. Yeah. And I will say like in the array programming community, I find this like essentially a common misconception that like the reason people aren't using array programming languages is because they don't know about them or don't understand them. You know, which is a kernel of truth of that, but the truth is like, nowadays, there's huge, massively funded research labs at places like Google Brain and you know Facebook AI research and OpenAI and so forth where large teams of people are literally writing new programming languages because they've tried everything else and what's out there is not sufficient, you know. I find this you know, in the array programming world there's a, offered a huge kind of underappreciation of what Python can do nowadays, for example, like I, as recently as last week I heard it described in a chat room is like, people obviously don't care about performance because they're using Python. And I'm like, well, you know, a large amount of the world's highest performance computing now is done with Python, like it's, it's not because Python is fast it's because like, but if you want to use rapids, for example, which literally holds records for the highest performance, you know recommendation systems and tabular analysis. You write it in Python, you know, so this idea of having a fast kernel that's not written in the language and then something else talking to it in a very flexible way I think is great. And as I say at the moment, we are very hamstrung in a lot of ways that we, or at least until recently we very heavily relied on on Blast, which is totally the wrong thing for that kind of flexible high performance computing because it's this, you know, bunch of somewhat arbitrary kind of selection of linear algebra algorithms which, you know, things like the C sharp work I did, you know, they were just wrappers on top of Blast. And what we really want is a way to write really expressive kernels that can do anything over any axes. And then there are other newer approaches, like Julia, for example, which is is kind of like got some risky elements to it and this type dispatch system, but because it's, you know, in the end it's on top of LLVM. And what you write in Julia, you know, it does end up getting optimized very well and you can write pretty much arbitrary kernels in Julia and often get best in class performance. And then there's other approaches like Jax, and Jax sits on top of something totally different which is it sits on top of XLA. And XLA is a compiler, which is mainly designed to compile things to run fast on Google's TPUs. But it's also does an okay job of compiling things to run on on GPUs. And then really excitingly I think you know for me is the, the MLIR project, and particularly the affine dialects that was created by my friend Chris Latner who you probably know from creating Klang and LLVM and Swift. So he, he joined Google for a couple of years and we worked really closely together on trying to like, think about the vision of really powerful programming on accelerators that's really developer friendly. Unfortunately, didn't work out Google was a bit too tied to the TensorFlow. So the big ideas that did come out of that was MLIR and that's still going strong and I do think there's, you know, if, if something like APL, you know, could target MLIR and then become a DSL inside Python. It may yet win, you know, Yeah, I've heard you in the past say that on different podcasts and talks that you don't think that Python, like even in light of, you know, just saying, people don't realize how much you can get done with Python that you don't think that the future of data science and AI and neural networks and that type of computation is going to live in the Python ecosystem and I've, I've heard on some podcasts you've said that you know Swift has a shot based on sort of the way that they've designed that language and you just mentioned, you know, a plethora of different sort of, I wouldn't say initiatives but you know, Jack's, XLA, Julia, etc. Do you have like a sense of where you, where you think the future of not necessarily sort of array language computation but this this kind of computation is going with all the different avenues. I do. You know, I think we're certainly seeing the limitations of Python, and the limitations of the, the pie torch, you know, lazy evaluation model, which is the way most things are done in Python at the moment for a kind of array programming is you have an expression, which is, you know, working on arrays possibly have different ranks with implicit looping. And, you know, that's one line of Python code. And generally that then gets your, you know, on your computer that will get turned into, you know, a request to run some particular optimized pre written operation on the GPU or TPU, and then get sent off to the GPU or TPU, where your data has already been moved there. And then it runs. And then it tells the CPU when it's finished. And there's a lot of latency in this right so if you want to create your own kernel like your own way of doing, you know, your own operation effectively. You know, good luck with that. That's not going to happen in Python. And I hate this. I hate it as a teacher, because, you know, I can't show my students what's going on. Right, it kind of goes off into, you know, kind of Cuda land and then comes back later. I hate it as a hacker because I can't go in and hack at that I can't trace it I can't debug it I can't easily profile it. And I hate it as a researcher because very often I'm like, I know we need to change this thing in this way but I'm damned if I'm going to go and write my own Cuda code, let alone deploy it. So, Jack's is, I think a path to this it's where you say okay let's not target pre written Cuda things let's instead target a compiler. And you know working with Chris Latner I'd say he did have too many nice things to say as about XLA as a compiler it was not written by compiler writers it was written by machine learning people, really, but it does the job, you know, and it's certainly better than having no compiler. And so, Jack's is something which, instead of turning our line of Python code into a call to some pre written operation, and instead is turning it into something that's going to be read by a compiler. And so the compiler can then, you know, optimize that as compilers do. So yeah, I would guess that Jack's probably has a part to play here, particularly because you get to benefit from the whole Python ecosystem package management libraries, you know, visualization tools, etc. But you know longer term. It's a mess you know it's a mess using a language like Python which wasn't designed for this. It wasn't really even designed as something that you can chuck different compilers on onto so people put horrible hacks. So for example pytorch. There's something called torch stripped which is a bit similar, you know, it takes Python and kind of compiles it, but they literally wrote their own parser using a bunch of regular expressions, and it's, it's, you know, it's not very good at what it does it even misreads comments and stuff. But you know I do think there's definitely room for, you know, a language of which Julia would certainly be the leading contender at the moment to come in and do it properly, and Julia's got you know Julia is written on a scheme basis so there's this little scheme kernel that does the parsing and whatnot, and then pretty much everything else. After that is written in Julia. And of course, leveraging LLVM very heavily. But that's, I think that's what we want right is that something which I got something also I didn't love about Swift when when the team at Google wanted to add differentiation support into Swift. They read it in c++. And I was just like, that's not a good sign. So, like apart from anything else you end up with this group of developers who are, in theory, Swift experts but they actually write everything in c++. And so they actually don't have much feel for what it's like to write stuff in Swift, they're writing stuff for Swift. And Julia pretty much everybody who's writing stuff for Julia is writing stuff in Julia. And I think that's, that's something you guys have talked about around APL and J as well is that there's the idea of writing J things in J and APL things in APL is very powerful idea. Yeah, I was wondering about. Oh, yeah, sorry, I just remembered your third question. I'll come back to it. No, no, you go ahead you had. You asked me why now am I coming back to APL and J, which is totally orthogonal to everything else we've talked about, which is, I had a daughter. She got old enough to actually start learning math so she's six. And, oh my god there's so many great educational apps nowadays there's one called Dragon Box algebra it's so much fun Dragon Box algebra five plus. And it's like five plus algebra, like what the hell so when she was, I think she's still four I gave, you know I let her play with Dragon Box algebra five plus. And she learned algebra, you know by helping dragon eggs hatch. And she liked it so much I let her try doing Dragon Box algebra 12 plus, and she loved that as well and finished it and so suddenly I had a five year old kid that liked algebra. And I was like, much, much surprised. Kids really can surprise you. And so, yeah she struggled with a lot of the math that they were meant to be doing a primary school like, like division and multiplication but she liked the algebra. And we ended up homeschooling her. And then one of her best friend is also homeschooled. So this, this year I decided I'd try tutoring them in math together. And so, my daughter's name is Claire so her friend gave. So her friend gave discovered on his Mac the world of alternative keyboards so he would start typing in the chat in, you know, Greek characters or Russian characters. And one day I was like, okay check this out so I like tapped in some APL characters. And they were just like, wow, what's that we need that. So, initially we installed dialogue APL so they could type APL characters in the chat. And I explained to them that this is actually like super fancy math that you're typing in. They really wanted to try it. So, and that was at the time I was trying to teach them sequences and series, and they were not getting it at all it was my first year time as a, as a math tutor with them you know they've been zipping along fractions you know greatest common denominator factor trees. Okay, everything's fine it makes sense and then we hit sequences and series and it's just like, they had no idea what I was talking about. So, we put that aside, then we spent like three one hour lessons, doing the basics of APL, you know, the basic operations and doing stuff with lists and dietic versus monadic. It's still good up this primary school level math. And we also did the same thing in NumPy using Jupiter. And they really enjoyed all that like they were more engaged than our normal lessons. And so then we came back to like, you know, sigma i equals one to five of i squared, whatever it is like okay that means this, you know, in APL and this in NumPy. And they're like, Oh, settle. Fine, with, you know, that's like. Yeah, so that was the problem this idea of like TN equals TN minus one plus blah blah blah it's like. What is this stuff but when you're actually indexing real things and can print out the intermediate values and all that and you've got iota or a range. They were just like, Oh, okay. I don't know why you explained it this dumb way before. And I will say, given a choice between doing something on a whiteboard or doing something in NumPy or doing something in APL. You know, always pick APL, because the APL version. It's just so much easier, you know, there's less to type this has to think about this as boilerplate. And so it's been it's only been a few weeks but like yesterday. We did the power operator, you know, and so we literally started doing the foundations of mathematics, mathematics, I was like, Okay, let's create a function called capital S, capital S arrow. Plus, jot one. Right. So for those Python people listening jot is if you give it a an array or a scalar, it's the same as partial in in in Python or bind in C++. So okay we've now got something that adds one to things okay I said okay this is called the successor function. And so I said to them okay what would happen if we go SSS zero. And they're like, hmm. Oh, that would be three. And so I said okay well what's it what's addition. And then one of them is like, oh, it's repeated s, like yeah it's repeated s so how do we say repeated so in APL we say repeated by using this star dioresis it's called power. Okay, so now we've done that. What is multiplication. And then when I think is after a while, oh, it's repeated addition. So we define addition and then we define multiplication. And then I'm like okay well what about, you know, exponent. Oh, that's just another one they've heard 1000 times they're both immediately like oh that's repeated multiplication so like okay we've now defined that. And then okay well subtraction that's a bit tricky. Well it turns out that subtraction is just, you know, is the opposite of something what's the opposite of that both know that as the opposite of addition, okay well opposite of which in math we call inverse is just a negative power. So now we define subtraction. So how would you define division. Oh, okay, how would you define roots. Oh, okay. So we kind of like, you know, designing the foundations of, of mathematics. There's mathematics here at APL, you know, with a six year old and an eight year old. And during this whole thing at one point we're like okay well now, I can't remember why but we're like okay now we got to do one divided by half. And they're both like we don't know how to do that. You know, APL, this stuff that's considered like college level math, suddenly becomes easy and you know at a point when still primary school level math like one divided by a half is considered hard. So it definitely made me rethink, you know, what is easy and what is hard and how to teach this math stuff and have been doing a lot of teaching of math with APL and the kids are loving it, and I'm loving it. And that's actually why I started this study group, which will be on today. Today as we record this a few days ago, as you put it out there. As I kind of started saying on Twitter to people like oh it's really been fun teaching my kids you know my kid and her friend math using APL and a lot of adults were like, can we learn math. So, so that's what we're going to do. It's a notation thing isn't it. It's the notion you get away from the sigma's and the pies and all that you know subscripts. I know right, this is exactly what I've been wanting. Yeah, exactly. I mean who wants this, you know, why should capital pi be product and capital sigma be some like, you know, we did plus slash and that's like okay how do we do product, they like those of us time slash, and I show them backslash like how do we do a cumulative product and that's obviously times backslash. Yeah, this stuff. And, but, you know, a large group of adults can't can't handle this because I'll put stuff on Twitter I'll be like here's a cool thing in APL, and like half the replies will be like, well that's line noise that's not intuitive. It's this classic thing that it's this classic thing that I have a son always say it's like the difference between what you said that you don't understand it, or is it that it's hard. And, you know, kids don't know, you know, for kids, everything's new. So that you know they see something they've never seen before they just like teach me that, or else adults, or at least a good chunk of adults just like. I don't really understand that therefore it's too hard for me therefore I'm going to belittle the very idea of the thing. I did it I did a tacit program on one liner on a PL farm the other day and somebody said that looks like Greek to me. I said, well, Greek looks like Greek to me because I don't know Greek. I mean, sure, if you don't know it. Absolutely it looks silly. Yeah, if you know it, then it's, it's not that hard. I will say like, you know, a lot of people have put a lot of hard work into resources for a PL and J teaching but I think there's still a long way to go. And one of the challenges is, it's like when I was learning Chinese. I really wanted to, I like the idea of learning Chinese. New words by looking them up in a Chinese dictionary. But of course I didn't know what the characters in the dictionary meant so I couldn't look them up. So when I learned Chinese I really spent the first 18 months, just focused on learning characters. So I got through 6000 characters in 18 months of very hard work. And then I could start looking things up in dictionary. My hope is to do a similar thing for APL like for these study groups, I want to try to find a way to introduce every cliff in an order that never refers to glyphs you haven't learned yet. So like that's something I don't feel like we really have and so that then you can look up stuff in the dialogue documentation, because now still I don't know that many glyphs. So like most of the stuff that documentation I don't understand because it explains glyphs using glyphs I don't yet know and then I look those up and those are the used explain things with glyphs I don't know. So, you know, step one for me is I think we're just going to go in through and try to teach what every glyph is. And then I feel like we should be able to study this better together because then we can actually read the documentation, you know, going to publish these sessions online. Yeah, so the study group will be recorded as videos. But I also then want to actually create, you know, written materials using Jupiter, which I will then publish. That's my goal. So, when you said very much resonates with me that I often find myself in a when teaching people this this bind that to explain everything I need to have everything explained. And I think so and especially it comes down to, in order to explain what many of these gifts are doing. I need some fancy arrays, if I restrict myself to simple vectors and scalars then I can't really show their power. And I cannot create these higher rank arrays, without already using those glyphs. And so hopefully, it was this long running project since like 2015 I think this is to add a literal array notation to a PL. And then there is a way in, then you can start by looking at an array and then you can start manipulating and see the effects of the glyphs and into it from there, what they do. Yeah, no, I think that'll be very very helpful. And in the meantime, you know my approach with the kids has just been to teach row quite early on it so row is the equivalent of reshape in Python most Python libraries. And, yeah, so once you know how to reshape you can start with a vector and shape it to anything you like it it's you know, it's not a difficult concept to understand so I think that yeah basically the trick at the moment is just to say okay, you know the dictionary of APL, one of the first things we will learn is, is row. And that was really fun with the kids doing monadic row, you know, to be like okay well what's row of this what's row of that and okay what's row of row of this and then what's row of row of row, which then led me to the to the Storman poem about how does it row row row is one, etc etc, which they loved as well. Yeah, we'll link that in the show notes. Yeah, while you were saying all that, that really resonated me with me when I first started learning APL is like one of the first things that happened when I was like oh okay you can you can fold you can map. So like how do you filter you know what are the classic, you know, three functional things and the problem with APL and array languages is they don't have an equivalent filter that takes a predicate function they have a filter that is called compress that takes a mask that you know drops anything that corresponds to a zero. And it wasn't until a few months later that I ended up discovering it but for both APL and the newer APL BQN there's these two sites, Adam was the one that wrote the APL one apple info, and they can create that info I also think, and so you can basically semantically search for what you're trying to do. And it'll give you small expressions that do that. So if you type in the word filter, which is what you would call it coming from you know a functional language or even I think Python calls it filter, you can get a list of small expressions and really really often sometimes you need to know the exact thing that it's called, like one time I was searching for you know all the combinations or permutations and really what I was looking for was power set. And so, until you have that, you know the word power set. It's you know it's a fuzzy search right so but it's still a very very useful tool when it's like you said you're trying to learn something like Chinese and it's like well where do I even start I don't, I don't know the language to search the words to search for. But yeah, it is. I agree that there's a large room for improvement and how to onboard people without them immediately going, like you said this looks like hieroglyphics which I think Iverson considered a compliment like there's some anecdote I've heard where someone was like this is hieroglyphics and he says yes exactly. And then they think the other thing like that I want to do is help in particular Python programmers and maybe also do something for JavaScript programmers which are the two most popular languages, like at the moment. Like a lot of the tutorials for stuff like Jay or whatever like J for C programmers, you know, great book but most people aren't C programmers, and also a lot of the stuff like, you know, it'd be so much easier if somebody just like said to me early on. Oh, you know, just, just the same as partial in Python, you know, or, like, you know, putting things in a box with the health of box if somebody basically said oh it's basically the same as a reference. It's like oh okay, you know, I think it might have your podcast somebody said us like void star. Yeah, okay. You know this is kind of like lack of just saying like, this is actually the same thing as blah in in Python and JavaScript so I do want to do some kind of. Yeah, mapping. Yeah, like that, particularly for kind of NumPy programmers and stuff because a lot of it's so extremely similar. So it would be nice to kind of say like okay well this is you know Jay maps things over leading axes which is exactly the same as NumPy does it over trailing axes so if you know the NumPy rules you basically know the, the J rules. If you send somebody down the wrong road with a metaphor that almost works in some of these areas. It can really be challenging for them because they see it in with you know through their lens of their experience, but that would say in this area it would work differently than it actually does. So, there is a challenge in that. And we find it even between APL BQN and Jay. I'm trying to think of what we were talking about recently, it was transpose. The language is dyadic transposes they handle, they handle them differently. They're functionally you can do the same things but you have to be aware that they are going to do it differently, according to the language. Absolutely. But that's not a reason to throw out the analogy right like I think everybody agrees that that it's easier for an APL programmer to learn Jay, then for a CEO JavaScript programmer to learn Jay, you know, because there are, there are some ideas you understand and you can actually say to people like okay well this is the rank conjunction in Jay and you may recognize this as being like the rank, you know, operator in APL. So if we can do something like that and say like oh well okay this is the you know this would do the same thing as, you know, permute.lar in PyTorch. It's like okay, I see it. Well as the maintainer of AppleCart, I'd like to throw in a little call to the listeners, like what Connor mentioned, I do fairly often get people saying well I couldn't find this and this and ask them what did you search for. And if you let me know contact me by whatever means, say if you couldn't find something either because it's altogether missing and I might be able to edit, or tell me what you search for and couldn't find, or maybe you found it later by searching for something else, and I'll add those keywords for future users. And I have put in a lot of like function names from other programming languages so that you can search for those and find the APL equivalent. I will say, I feel like either I'm not smart enough to use applecart.info, or I haven't got the right tutorial yet because I went there, I've been there a few times. And there's this like whole lot of like impressive looking stuff, and I just, I don't want to know what to do with it and then I sometimes click things and it sends me over to this tio.run that tells me like real time 0.02 seconds. And I find it, you know, a little, not a little I have not yet I don't yet know how to use it. And so, you know, I guess given hearing you guys say this is a really useful tool that a lot of people put a lot of time into. I should obviously invest time learning how to use it, and maybe after doing that I should explain to people how to use it. Thank you on it and there's also a little question mark icon one can click on and get to the I have tried the question mark icon. As well as I say it might just you know, I think this often happens with APL stuff, I often hit things I feel like maybe I'm not smart enough to understand this. Really don't think that's if you we we humbly disagree. Yeah, I do recall you saying a few minutes ago that you managed to teach your, you know, four year old daughter like 12th grade or age 12 algebra. I know I didn't I just gave her the app right it's like it's it. I've heard other parents have given it to their kids they also need to handle it. It's, it's just this fun game where you hatch dragon eggs by like dragging things around on the iPad screen, and it just, it just shows that the things you're doing with dragons eggs are the rules of algebra, and after a while it starts to switch out some of the like monsters with symbols like x and y, you know, and it doesn't gradually gradually and at the end. It's like oh now you're doing algebra so I can't get any credit for that that's some very very clever people wrote a very cool. It really is an amazing program I homeschooled my son as well and we use that for algebra. It's a bit more age appropriate but it's, I, I looked at that and said that that really is well put together, it's it's an amazing program. I will say it'll be a dragon box IPO one day. It's not a bad idea. Not a bad idea at all. I was going to say when you're teaching somebody one of the big challenges when you're sort of trying to get a language across to a general audience is who is the audience because, as you say if you're if you're dealing with kids or people who haven't been exposed to programming before. That's a very different audience and somebody might have been exposed to some other type of programming functional programming is a bit closer but if your procedural programmer imperative programmer. It's going to be a stretch to try and bend your mind in the different ways that you know, a PL or J, or BQN expect you to think about things. Yeah, I think the huge rise of functional programming is very helpful for coming to array programming, you know, both in JavaScript and in Python. It's, you know, I think most people are doing stuff, particularly in the, in the machine learning and deep learning world are doing a lot of functional stuff. Often that's the only way you can do things, particularly in deep learning. So I think yeah I think that does help a lot like like kind of said like you've probably come across, you know, map and reduce and filter, and certainly in in Python you'll have done list comprehensions and dictionary comprehensions. And a lot of people don't SQL. So it's, yeah, I think a lot of people come into it with some relevant analogies if we can help connect it for them. Yeah, one of the things that, you know, really it's reinforcing my idea that, or it's not my idea I think it's just an idea that multiple people have had but that the tool doesn't exist yet. Because we'll link to some documentation that I use frequently when I'm going sometimes between a PL and J on the BQM website they have BQN to dialogue APL dictionaries and BQ and the J dictionary so sometimes I'll like, if I'm trying to convert between the two, the BQM docs are so good I'll just use BQN is like an IR to go back and forth but I've mentioned on previous podcasts that really what would be amazing and it would only work to a certain extent is something like a multi directional array language transpiler and adding numpy to that list would probably be, you know, a huge, I don't know what the word for it is but beneficial for the array community if you can type in some numpy expression, you know, like I said it's only going to work to an extent that you can do simple you know rank one vectors or arrays that you're just reversing and summing and doing simple you know reduction and scan operations, you could translate that pretty easily into a PLJ and BQN, and it's, I think that would make it so much easier to understand, aka the hieroglyphics or the Greek or the Chinese or whatever metaphor you want to use. And it's very easy to hit a wall early on. So, I've been thinking about is basically rewrite numpy in APL. It doesn't seem like a whole lot of work where just take all those names that are available in number, and just define the message functions and people can explore that by opening them up and seeing how they defined. Oh, so not not actually you're saying like, it wouldn't be a new thing you're just saying like rename the symbols what they're known as in numpy so that you'd still be in a like an APL. Yeah, I mean you could use it as a library, but I was thinking a bit more as an interactive exploring type thing where you open up this library, and then you, you write the name of some numpy thing functionality and open it up in the editor and see, well, how is this defined in APL. And then you could use it obviously, since it's defined. Interesting, then you could slowly you could use these library functions. And then, as you get better at APL you can start actually writing out the role appeal instead of using these covers for it. Well, I guess, Jeremy that's an interesting. Do you think that, because you've mentioned about sort of the notation versus the programming language, and where do you think the like in your dream scenario, are you actually coding in sort of an Iversonian like notation, or no, is it at the end of the day does it still look like numpy, but it's just all of the expressive to expressivity and power that you have in the language like APL is brought to and combined with what numpy sort of currently looks like is, I mean, well, it'd be a bit of a combination Connor in that like, you know, my classes and my type dispatch and my packaging and, you know, all the, you know, my function definitions and whatever that's, that's Python. But you know, everywhere I can use plus and times and divide and whatever I could also use any, any APL glyph. And so it'd be you know basically an embedded DSL for kind of high dimensional notation. It would work automatically on numpy arrays and TensorFlow tenses and pi torch tenses. And the thing that's interesting is, to a large degree, APL and pi torch and friends have actually arrived at a similar place with the same, you know, grandparents, which is, I have a son actually said his inspiration for some of the APL ideas was tensor analysis. And a lot of the folks, as you can gather from the fact that in pi torch we don't call them arrays because the tensors a lot of the folks working on deep learning. Their inspiration was also from tensor analysis so it comes from physics right. And so I would say, you know, a lot more folks have worked on pi torch were familiar with tensor analysis and physics than were familiar with APL. So, and then of course there's been other notations, like explicitly based on Einstein notation there's a thing called I know, which like takes. It's very interesting kind of approach of taking Einstein notation, much further. And like Einstein notation if you think about it is the kind of the loop free programming of math right that the equivalent of loops in math is indices, and Einstein notation does away with indices. And so that's why stuff like I know it's incredibly powerful because you can write, you know, an expression in in in I know, with no indices and no loops, and it's all implicit reductions and implicit loops, I guess yeah my ideal thing would be. We wouldn't have to use I know, we can use APL, you know, and it wouldn't be embedded in a string. But they would actually be operators, yeah that's what it is that the operators in the language that Python operators would not just be plus times minus slash, that would be all the APL glyphs would be Python operators and they would work on all Python data types, including all the different tensor and array data types. Yeah, it sounds like you're describing a kind of hybrid hybrid language JavaScript to you. I would love the whole DSL to be in JavaScript as well. You know, that'd be great. And I feel like I saw that somewhere I feel like I saw somebody actually do an ACMA script. So, you know, RFC with an implementation. It was a false joke. Yeah, but it actually worked it not like it was actually an implementation that. I don't think they had the implementation there was just very very well specced, it could actually work kind of thing. No, I definitely I read the I read the code I was I don't know how complete it was, but there was definitely some code there. I can't find it again. If you know where it is. There's a JavaScript implementation of APL by Nick Nickalove. But my problem with it, it's not tightly enough connected with underlying JavaScript. It shouldn't be an April Fool's joke, should it? You know, it's like, it's like, it's like Gmail was an April Fool's joke right Gmail came out on April the 1st and totally destroyed my plans for fast mail, because it was an April Fool's joke that was real. And flask you know the flask library I think was originally an April Fool's joke of like, you know, we basically saying we shouldn't be losing frameworks because I created a framework that's so stupidly small that it shouldn't be a framework and now that's the most popular web framework in Python. So yeah, maybe this should be an April Fool's joke becomes real. How close. This is maybe an odd question but because it from what I know about Julia you can define your own Unicode operators and I did try at one point to create a small composition of two different symbols you know square root and reverse or something and it ended up not working for me for parentheses. But do you think Julia could evolve to be that kind of hybrid language that. Yeah, maybe, you know, maybe I'm actually doing a keynote at Julia con in a couple of weeks so maybe I should raise that. I think the Q&A section say, any questions but first I've got one for the community at large. Here's what I'd like to know how talks going to be kind of like what Julia needs to be, you know, to move to the next level. I'm not sure I can demand that a complete APL implementations that thing but I could certainly put it out there is something to consider. It always bothers me though that if you try to extend those languages like this so you could use some kind of pre compiler for it. Then their order of execution ends up messing up APL. I think if you're very much depends on having a strict one directional order of functions. Otherwise it's hopeless to keep track of. That's that is a big challenge because currently the DSL inside Python, which is the basic mathematical operations to have the bod mass or PEMDAS order operations. And so there would need to be some way. So in Python that wouldn't be too hard actually because in Python. From Dunder futures import APL precedence. And then from then on everything in your file is going to use right to left precedence. Interesting and cool. I didn't know that. Awesome. I've been spending a lot of time thinking about function precedence and just the differences and different languages and I'm not sure if any other languages have this but something that I find very curious about BQN and APL is that they have functions basically that have higher precedence than other functions. So operators in APL and conjunction is an adverbs. They have higher precedence than your regular functions that apply to arrays, you know I'm simplifying a tiny bit but this idea that like in Haskell function application always has the highest precedence you can never get anything that has a higher function precedence that and it always having stumbled into the array world now it's seems like a very powerful thing that these combinator like functions don't have just by default the higher precedence because if you have a folder a scan or a map. You're always combining that with a some kind of binary operation or unary operation to create another function that you're then going to eventually apply to something and. Yeah, but the basic like right to left, you know, putting aside the, the higher order functions or operators as they're known in APL, the basic right to left path I mean. And for teaching and for my own brain gosh that's so much nicer than like in C++. Oh my god, they're not being able to operate a precedence. Yeah, there's no way I can ever remember that, and there's a good chance when I'm reading somebody else's code that, you know, they haven't used parentheses because they didn't really need them that I have no idea where they have to go and then I have to go and look it up. So it's another of these things that with the kids I'm like, okay you remember that stuff we spent ages on about like, you know, first you do exponents, and then you do times, it's like, okay you don't have to do any of that and they feel, you just go right to left, and they're just like, oh, that's so much better. What is your, this literally came up at work like a month ago, where I was giving this mini APL like we had 10 minutes at the end of a meeting, and then I just made this offhand remark that of course like the evaluation order and APL is a much simpler model than what we learned in school. And like, I upset like there was I don't know 20 people in the meeting, and it was the most controversial thing I had said, like, and I, I almost had like an out of body experience because I thought I was saying something that was like, objectively just true and then I was like, wait a second what I'm clearly missed like is there. Yeah, well you were wrong like how do you know I mean, at most adults are incapable of like new ideas, it's just, it's, it's that's what I should have said in the meeting. I mean this is a reason that I another reason I like doing things like APL study groups because it's a way of like self selecting that small group of humanity who's actually interested in trying new things despite the fact that they're grown ups and then try to surround myself with those people in my life. But isn't it sad then, I mean what has happened to those grownups like when you mentioned, teaching these people and trying to like map their existing knowledge onto a PL things what does mean to box and so on. I find that to children and non programmers, expanding their array model and and how the functions are applied and so on, is almost trivial meets no resistance at all. And it's all those adults that have either learned their, their PEMDAS or BOTMAS or whatever the rules are, and all the computer science people that know their precedence tables and their lists of lists and so on. Those are the ones that are really really struggling it's not just resisting, they're clearly struggling. They're really trying and it's a lot of effort. So, there is actually I mean that is a known thing in educational research. Yeah, I mean I spent months earlier this year, and like last year, reading every paper I quote about, you know, education, because I thought if I'm going to be homeschooling that I should try to know what I'm doing. And, yeah, what you describe it arm is absolutely a thing, which is that, that, you know, the research shows that trying, you know, when you've got a, you know, an existing idea which is a, an incorrect understanding of something and you're trying to place it with a correct understanding that is much harder than learning the correct version directly. So which is obviously a challenge when you think about analogies and analogy has to be good enough to lead directly to the, to the correct version. But I think you know the important thing is to find the people who are who have the curiosity and tenacity to be prepared to go over that hurdle, even though it's difficult, you know, because yeah it is like that's just, that's just how human brains are so so be it, you know. Yeah unlearning is really hard work actually. And if you think about it, it probably should be because you spend a lot of time and energy to put some kind of a pattern into your brain. Right, I don't want to have that evaporate very quickly. Yeah, and our, you know, my elimination occurs around what like ages eight to 12 or something so like our brains are literally trying to stop us from having to learn new things because our brains think that they've got stuff sorted out at that point and so they should focus on keeping long term memories around so yeah, it does become harder. But, you know, a little bit. It's still totally doable. The solution is obvious. That's what I'm doing. What was the word you mentioned a mile a mile nation mile mile nation me y, l i n. At i n. Interesting. I'd not heard that word before it's a physical coating that I can't remember goes on the dendrites. I think it's on the axons, isn't it. It's these fat layers or cholesterol layers. I've never taken a biology courses in my education so clearly I've, I've missed out on that aspect. You you mile in a you mile in aided anyway. Isn't that an appeal function. You also mentioned the word tenacity, Jeffrey. Yeah, and, and, and I was watching an interview did with Samian butani. Yeah, and you were talking about, because it sounds like he was you spotted at an early point in his working with Kaggle that he was something probably different than you said was the tenacity to keep working at something. Yeah, I think that's a really important part about educating people that they don't necessarily expect learning something new to be easy. Yeah, but you can do it. Yeah, I mean I really noticed that when I was started learning Chinese, like I went to, you know, just some local class in in Melbourne, and everybody was very very enthusiastic, you know, and everybody was going to learn Chinese. And we all talked about the things we were going to do. And each week there'd be fewer and fewer people there. And, you know, I kind of tried to keep in touch with them. But after a year. Every single other person had given up and I was the only one still doing it, you know, so then after a couple of years people would be like, Wow, you're so smart you learn Chinese, this is like, no man like during those first few weeks, I was pretty sure I was learning more slowly than the other students. And I stopped doing it. So, of course they didn't learn Chinese. And I don't know what the trick is because, yeah, it's the same thing with, you know, like it fast AI courses they're really designed to keep people interested and get people doing fun stuff from, from day one and, you know, still, I'd say most people drop out. And the ones that don't. Most of them end up becoming like actual world class practitioners and they, you know, build new products and startups and whatever else. And people will be like, Oh, I wish I knew neural nets and deep learnings. It's like, okay, here's the course. Just, just do it and don't give up. But yeah, I don't know, tenacity. It's not a very common virtue, I think, for some reason. It's something effort, I think it's Joe Bowler at Stanford talk about the growth mindset. And I think that is something that, for whatever reason, some people tend to and maybe it's my own nation. At those ages you start to get that mindset where you're not so concerned about having something happen, that's easy to do well. But just the fact that if you keep working at it, you will get it. And not everybody, I guess, is maybe put in the situations that they, they get that feedback that tells you if I keep trying this I'll get it. Yeah, if it's not easy, they stop. Yeah, I mean that that area of growth mindsets are very controversial idea in education. Specifically the question of, can you, can you modify it? And I think it's certainly pretty well established to this point that the kind of stuff that schools have tended to do, which is put posters up around the place saying like, you know, make things a learning opportunity or don't give up, like they do nothing at all. You know, with my daughter, we do all kinds of stuff around this. So we've actually invented a whole family of clams. And as you can imagine clams don't have a growth mindset, they tend to sit on the bottom of the ocean, not moving. And so the family of clams that we invented that we live with, you know, always at every point that we're going to have to like learn something new or try something new, always start screaming and don't want to have anything to do with it. So we actually have Claire telling the clams how it's going to be okay. And, you know, it's actually a good thing to learn new things. And so we're trying stuff like that to try to like have have imaginary creatures that don't have a growth mindset and for her to realize how, how silly that is, which is fun. And the things that you were talking about in terms of the meta mathematics, you didn't say, oh, the successor, this is what pluses you said, how do you how do you how would you use this, how would you start to put it together themselves, which to me that's the growth mindset that if you're creating that. But then like, you know, gosh, you're getting to all the most controversial things in education here, Bob, because that's the other big one is discovery learning. So this idea of having kids explore and find. It's also controversial because it turns out that actually the best way to have people understand something is to give them a good explanation. So it is important, like, that you combine this like, okay, how would you do this with them like, okay, let me just tell you what, you know, why this is. It's easier for homeschooling with two kids, because I can make sure their exploration is short and correct. You know, if you spend a whole class, you know, 15 minutes doing totally the wrong thing, then you end up with these really incorrect understandings which you then have to kind of deprogram. So, yeah, education is hard, you know. And I think a lot of people look for these simple shortcuts, and they don't really exist. So you actually have to have good, good explanations and good problem solving methods and yeah, all this stuff. It's a really interesting area though. Notations. Yeah, and you know notation, I mean, it's not I do a live coding, you know, video thing every day with a bunch of folks, and in the most recent one. We started talking about a PL why we're going to be doing a PL this week instead. And I gave, you know, somebody actually said like oh my god is going to be like red checks it's. And, you know, I kind of said like okay so red checks is there a notation for doing stuff. And we spent an hour, solving the problem with red checks is. And, oh my god it was such a powerful tool for this problem and you know by the end of it they're all like okay we want to like deeply study red checks is and obviously that's a much less flexible and powerful tool notation then a PL. But you know we kind of talked about how once you start understanding these notations you can build things on top of them and then you kind of create these abstractions and that's yeah notation is how, you know, deep human thought kind of progresses, right, in a lot of ways. Yeah, it's like I actually spoke to a math professor friend a couple of months ago about, you know, my renewed interest in APL. And he was like, and I kind of sent him some I can't remember what it was maybe doing the golden ratio or something that will snippet and he was just like, yeah, something like that looks like Greek to me I don't understand that. But do you do a math professor, you know, like if I said somebody who isn't in math like a page of your, you know, research, what are they going to say. And, you know, it's interesting I said like this, you know, there are ideas in here like Iverson brackets, for example, have you ever heard of Iverson brackets, he's like well of course I've heard of it like you know it's a fundamental tool in math is like, well, you know, that's one thing that you guys have stolen from APL, you know, that's a powerful thing right it's like fantastic I'd never want to do without Iverson brackets. So I kind of tried to say like okay well imagine like every other glyph that you don't understand here has some rich thing like Iverson brackets you could now learn about. Okay, maybe I should give it a go. I'm not sure he has. But I think that's a that's a good example for mathematicians is to show like his one thing at least that found its way from APL that maybe gives you a sense that for a mathematician that there might be something in here. On that note, because I know we are potentially well we've gone way over but this has been awesome. But, but a question I think that might be a good question to end on is, is, do you have any advice for folks that want to learn something, like Chinese, or an array language, or to get through your fast AI course. And is there because I think, you know, like you said you like to self select for folks that are the curious types and that want to learn new things and new ways to solve things. Is there any way, other than just being tenacious to like be tenacious is there tips to, you know, approaching something with some angle because I think a lot of the folks may be listening to this don't have that issue but I definitely know a ton of people that are the are the kind of folks that you know they'll join a study group but then three weeks and they, you know, the kind of lose interest or, or they decide it's too much work or too difficult. As an educator and you know, it seems like you operate in this space. Do you have advice to tell folks you know, I mean so much Connor. I actually kind of embedded in my courses a lot. I can give you some quick summaries but what I will say is my friend radicals mouse key who's been taking my courses for like four years has taken everything I've said, and his experience of those things and turn it into a book. So if you read it as mouse keys book is called meta learning. Powerful mental models for deep learning. This is learning as in learning deeply. So, yeah, check out his book to get the full answer. I mean, there's just, there's a lot of things you can do to make learning easier. You know, and a key thing I do in my courses as I always teach top down. So like often people with like, let's take deep learning and neural networks they'll be like okay well first thing I have to learn linear algebra and calculus and blah blah blah and, you know, four or five years later they still haven't actually trained a neural network. Our approach in our courses in lesson one the very first thing you do in the first 15 minutes as you train a neural network. And it is more like how we learn baseball, or how we learn music, you know, like you say like okay well let's play baseball comes you stand there you stand there I've read it to you, you're going to hit it, you're going to run. You know you don't start by learning. You know, the parabolic trajectory of a ball or the, you know, history of the game or whatever you just start playing. So that's, you know, you want to be playing. And if you're doing stuff from the start that's fun and interesting and useful. Then top down doesn't mean it's shallow. You can then work from there to like then understand like what's each line of code doing, and then how is it doing it, and then why is it doing it, and then what happens if we do it a different way and until eventually with, without fast AI program, you actually end up rewriting your own neural network library from scratch, which means you have to very deeply understand every single part of it, and then we start reading research papers and then we start learning how to implement those research papers in the library we just wrote. So yeah, I'd say go top down, make it fun, make it applied for things like APL or Chinese, where there's just stuff you have to remember. Use Anki, use repetitive space learning. You know, that's been around, Ebbinghaus came up with that, I don't know what 200, 150 200 years ago. It, it works you know you, you. Everybody, if you tell them something, we'll forget it in a week's time. Everybody, you know, and so you shouldn't expect to read something and remember it, because you're human, and humans don't do that. So, repetitive space learning will have you quiz you on that thing tomorrow. So, it's in four days time, and then in 14 days time and then in three weeks time. And if you ever forget it, it will reset that schedule. And it'll make sure it's impossible to forget it, you know, so it's, it's depressing to study things that then disappear. And so it's important to recognize that unless you use Anki or SuperMemo or something like that. Every day it will, it will disappear. But if you do use repetitive space learning. It's guaranteed not to. And I told this to my daughter. A couple of years ago I said, I, you know, what if I told you there was a way you can guarantee to never ever forget something you want to know. It's like, that's impossible. This is like some kind of magic. It's like no it's not magic. And like I sat down and I drew out the Epping House for Getting Curves and explained how it works. And I explained how, you know, if you get quizzed on it in these schedules, it flattens out and she was just like, what do you think? I want to use that. So she's been using Anki ever since. Maybe those are just two. Let's just start with those two. Yeah. So go top down and use Anki. I think could make your learning process much more fulfilling, because you'll be doing stuff with what you're learning and you'll be remembering it. Well, that is awesome. And yeah, definitely we'll leave links to not just Anki and the book Meta Learning but everything that we've discussed throughout this conversation because I think there's a ton of really really awesome advice. And obviously to your FASA AI course in the library. And we'll also link to, I know you've been on, like we mentioned before, a ton of other podcasts and talks. So, if you'd like to hear more from Jeremy, there's a ton of resources online. Hopefully, it sounds like you're going to be, you know, building some learning materials over the next however many months or years. And so, in the future, if you'd love to come back and update us on your journey with your array languages, that would be, yeah, super fun for us because I've thoroughly enjoyed this conversation. And thank you so much for waking up early, all on the other way side of the world from us at least in Australia. Thanks for having me. And, yeah, I guess with that we'll say happy array programming. Happy array programming.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.0, "text": " Welcome to another episode of Arraycast.", "tokens": [4027, 281, 1071, 3500, 295, 1587, 3458, 3734, 13], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 1, "seek": 0, "start": 3.0, "end": 6.28, "text": " I'm your host, Connor, and today we have a very exciting guest,", "tokens": [286, 478, 428, 3975, 11, 33133, 11, 293, 965, 321, 362, 257, 588, 4670, 8341, 11], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 2, "seek": 0, "start": 6.28, "end": 8.16, "text": " which we will introduce in a second.", "tokens": [597, 321, 486, 5366, 294, 257, 1150, 13], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 3, "seek": 0, "start": 8.16, "end": 11.200000000000001, "text": " But before we do that, we'll do brief introductions and then one announcement.", "tokens": [583, 949, 321, 360, 300, 11, 321, 603, 360, 5353, 48032, 293, 550, 472, 12847, 13], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 4, "seek": 0, "start": 11.200000000000001, "end": 14.0, "text": " So first we'll go to Bob and then we'll go to Adam, who has the one announcement.", "tokens": [407, 700, 321, 603, 352, 281, 6085, 293, 550, 321, 603, 352, 281, 7938, 11, 567, 575, 264, 472, 12847, 13], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 5, "seek": 0, "start": 14.0, "end": 15.56, "text": " And then we will introduce our guest.", "tokens": [400, 550, 321, 486, 5366, 527, 8341, 13], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 6, "seek": 0, "start": 16.2, "end": 17.04, "text": " I'm Bob Theriot.", "tokens": [286, 478, 6085, 334, 260, 6471, 13], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 7, "seek": 0, "start": 17.04, "end": 23.6, "text": " I'm a J enthusiast and I do some work with the J Wiki we're underway in trying to get it all set up for the fall.", "tokens": [286, 478, 257, 508, 18076, 525, 293, 286, 360, 512, 589, 365, 264, 508, 35892, 321, 434, 27534, 294, 1382, 281, 483, 309, 439, 992, 493, 337, 264, 2100, 13], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 8, "seek": 0, "start": 25.0, "end": 28.84, "text": " I'm Adam B\u0142ocewski, full-time APL programmer at Dialog Limited.", "tokens": [286, 478, 7938, 363, 1221, 905, 1023, 18020, 11, 1577, 12, 3766, 5372, 43, 32116, 412, 29658, 664, 43231, 13], "temperature": 0.0, "avg_logprob": -0.2812472681845388, "compression_ratio": 1.6855345911949686, "no_speech_prob": 0.08360610157251358}, {"id": 9, "seek": 2884, "start": 28.84, "end": 35.84, "text": " Besides for actually programming APL, I also take care of all kinds of social things, including the APL Wiki.", "tokens": [13212, 337, 767, 9410, 5372, 43, 11, 286, 611, 747, 1127, 295, 439, 3685, 295, 2093, 721, 11, 3009, 264, 5372, 43, 35892, 13], "temperature": 0.0, "avg_logprob": -0.17890859686810037, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.00016064658120740205}, {"id": 10, "seek": 2884, "start": 35.84, "end": 43.24, "text": " And then for my announcements, part of what we do at Dialog is arrange a yearly user meeting or a type of conference.", "tokens": [400, 550, 337, 452, 23785, 11, 644, 295, 437, 321, 360, 412, 29658, 664, 307, 9424, 257, 39102, 4195, 3440, 420, 257, 2010, 295, 7586, 13], "temperature": 0.0, "avg_logprob": -0.17890859686810037, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.00016064658120740205}, {"id": 11, "seek": 2884, "start": 43.24, "end": 53.24, "text": " And at that user meeting, there is also a presentation by the winner of the APL problem solving competition.", "tokens": [400, 412, 300, 4195, 3440, 11, 456, 307, 611, 257, 5860, 538, 264, 8507, 295, 264, 5372, 43, 1154, 12606, 6211, 13], "temperature": 0.0, "avg_logprob": -0.17890859686810037, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.00016064658120740205}, {"id": 12, "seek": 2884, "start": 53.24, "end": 58.24, "text": " That competition closes at the end of the month.", "tokens": [663, 6211, 24157, 412, 264, 917, 295, 264, 1618, 13], "temperature": 0.0, "avg_logprob": -0.17890859686810037, "compression_ratio": 1.610878661087866, "no_speech_prob": 0.00016064658120740205}, {"id": 13, "seek": 5824, "start": 58.24, "end": 60.04, "text": " So hurry up if you want to participate.", "tokens": [407, 11025, 493, 498, 291, 528, 281, 8197, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 14, "seek": 5824, "start": 60.04, "end": 62.24, "text": " It's not too late even to get started at this point.", "tokens": [467, 311, 406, 886, 3469, 754, 281, 483, 1409, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 15, "seek": 5824, "start": 62.24, "end": 68.64, "text": " And also at the end of the month is the end of the early bird discount for the user meeting itself.", "tokens": [400, 611, 412, 264, 917, 295, 264, 1618, 307, 264, 917, 295, 264, 2440, 5255, 11635, 337, 264, 4195, 3440, 2564, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 16, "seek": 5824, "start": 69.84, "end": 70.24000000000001, "text": " Awesome.", "tokens": [10391, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 17, "seek": 5824, "start": 70.24000000000001, "end": 71.64, "text": " And just a note about that contest.", "tokens": [400, 445, 257, 3637, 466, 300, 10287, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 18, "seek": 5824, "start": 71.64, "end": 73.84, "text": " I think and Adam can correct me if I'm wrong.", "tokens": [286, 519, 293, 7938, 393, 3006, 385, 498, 286, 478, 2085, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 19, "seek": 5824, "start": 73.84, "end": 75.24000000000001, "text": " There's two phases.", "tokens": [821, 311, 732, 18764, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 20, "seek": 5824, "start": 75.24000000000001, "end": 77.44, "text": " In the first phase, it's just 10 short problems.", "tokens": [682, 264, 700, 5574, 11, 309, 311, 445, 1266, 2099, 2740, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 21, "seek": 5824, "start": 77.44, "end": 79.04, "text": " A lot of them are just one liners.", "tokens": [316, 688, 295, 552, 366, 445, 472, 22896, 433, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 22, "seek": 5824, "start": 79.04, "end": 86.84, "text": " And even if you only solve one of the 10, I think you can win a small cash prize just from answering one.", "tokens": [400, 754, 498, 291, 787, 5039, 472, 295, 264, 1266, 11, 286, 519, 291, 393, 1942, 257, 1359, 6388, 12818, 445, 490, 13430, 472, 13], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 23, "seek": 5824, "start": 86.84, "end": 87.44, "text": " Is that correct?", "tokens": [1119, 300, 3006, 30], "temperature": 0.0, "avg_logprob": -0.1370591594748301, "compression_ratio": 1.705685618729097, "no_speech_prob": 4.822713526664302e-05}, {"id": 24, "seek": 8744, "start": 87.44, "end": 91.03999999999999, "text": " I'm not even sure you might need to solve.", "tokens": [286, 478, 406, 754, 988, 291, 1062, 643, 281, 5039, 13], "temperature": 0.0, "avg_logprob": -0.16293826935783265, "compression_ratio": 1.683673469387755, "no_speech_prob": 9.310399764217436e-05}, {"id": 25, "seek": 8744, "start": 91.03999999999999, "end": 94.24, "text": " Might need to solve them all.", "tokens": [23964, 643, 281, 5039, 552, 439, 13], "temperature": 0.0, "avg_logprob": -0.16293826935783265, "compression_ratio": 1.683673469387755, "no_speech_prob": 9.310399764217436e-05}, {"id": 26, "seek": 8744, "start": 94.24, "end": 95.64, "text": " They're really easy.", "tokens": [814, 434, 534, 1858, 13], "temperature": 0.0, "avg_logprob": -0.16293826935783265, "compression_ratio": 1.683673469387755, "no_speech_prob": 9.310399764217436e-05}, {"id": 27, "seek": 8744, "start": 95.64, "end": 100.84, "text": " So the point being those that you don't need to complete the whole contest in order to be eligible to win prizes.", "tokens": [407, 264, 935, 885, 729, 300, 291, 500, 380, 643, 281, 3566, 264, 1379, 10287, 294, 1668, 281, 312, 14728, 281, 1942, 27350, 13], "temperature": 0.0, "avg_logprob": -0.16293826935783265, "compression_ratio": 1.683673469387755, "no_speech_prob": 9.310399764217436e-05}, {"id": 28, "seek": 8744, "start": 100.84, "end": 101.64, "text": " For sure.", "tokens": [1171, 988, 13], "temperature": 0.0, "avg_logprob": -0.16293826935783265, "compression_ratio": 1.683673469387755, "no_speech_prob": 9.310399764217436e-05}, {"id": 29, "seek": 8744, "start": 101.64, "end": 108.64, "text": " There's a certain amount that if you get to that point, you hit a certain threshold and you can be eligible to win some free money, which is always awesome.", "tokens": [821, 311, 257, 1629, 2372, 300, 498, 291, 483, 281, 300, 935, 11, 291, 2045, 257, 1629, 14678, 293, 291, 393, 312, 14728, 281, 1942, 512, 1737, 1460, 11, 597, 307, 1009, 3476, 13], "temperature": 0.0, "avg_logprob": -0.16293826935783265, "compression_ratio": 1.683673469387755, "no_speech_prob": 9.310399764217436e-05}, {"id": 30, "seek": 8744, "start": 108.64, "end": 116.64, "text": " And yeah, just briefly, as I introduced myself in every other episode, I'm your host, Connor C++ professional developer.", "tokens": [400, 1338, 11, 445, 10515, 11, 382, 286, 7268, 2059, 294, 633, 661, 3500, 11, 286, 478, 428, 3975, 11, 33133, 383, 25472, 4843, 10754, 13], "temperature": 0.0, "avg_logprob": -0.16293826935783265, "compression_ratio": 1.683673469387755, "no_speech_prob": 9.310399764217436e-05}, {"id": 31, "seek": 11664, "start": 116.64, "end": 126.64, "text": " Not an array language developer in my day to day, but a huge array language and combinator enthusiast at large, which brings us to introducing our guest.", "tokens": [1726, 364, 10225, 2856, 10754, 294, 452, 786, 281, 786, 11, 457, 257, 2603, 10225, 2856, 293, 2512, 31927, 18076, 525, 412, 2416, 11, 597, 5607, 505, 281, 15424, 527, 8341, 13], "temperature": 0.0, "avg_logprob": -0.10835516452789307, "compression_ratio": 1.6431226765799256, "no_speech_prob": 6.1009919591015205e-05}, {"id": 32, "seek": 11664, "start": 126.64, "end": 132.24, "text": " Who is Jeremy Howard, who has a very, very, very long career.", "tokens": [2102, 307, 17809, 17626, 11, 567, 575, 257, 588, 11, 588, 11, 588, 938, 3988, 13], "temperature": 0.0, "avg_logprob": -0.10835516452789307, "compression_ratio": 1.6431226765799256, "no_speech_prob": 6.1009919591015205e-05}, {"id": 33, "seek": 11664, "start": 132.24, "end": 136.44, "text": " And you probably have heard him on other podcasts or have been giving other talks.", "tokens": [400, 291, 1391, 362, 2198, 796, 322, 661, 24045, 420, 362, 668, 2902, 661, 6686, 13], "temperature": 0.0, "avg_logprob": -0.10835516452789307, "compression_ratio": 1.6431226765799256, "no_speech_prob": 6.1009919591015205e-05}, {"id": 34, "seek": 11664, "start": 136.44, "end": 145.44, "text": " I'll read the first paragraph of his three paragraph bio because I don't want to embarrass him too much, but he has a very accomplished career.", "tokens": [286, 603, 1401, 264, 700, 18865, 295, 702, 1045, 18865, 12198, 570, 286, 500, 380, 528, 281, 9187, 796, 886, 709, 11, 457, 415, 575, 257, 588, 15419, 3988, 13], "temperature": 0.0, "avg_logprob": -0.10835516452789307, "compression_ratio": 1.6431226765799256, "no_speech_prob": 6.1009919591015205e-05}, {"id": 35, "seek": 14544, "start": 145.44, "end": 150.64, "text": " So Jeremy Howard is a data scientist, researcher, developer, educator and entrepreneur.", "tokens": [407, 17809, 17626, 307, 257, 1412, 12662, 11, 21751, 11, 10754, 11, 31237, 293, 14307, 13], "temperature": 0.0, "avg_logprob": -0.10145886090337014, "compression_ratio": 1.6891891891891893, "no_speech_prob": 7.242144056363031e-05}, {"id": 36, "seek": 14544, "start": 150.64, "end": 159.44, "text": " He is the founding researcher at Fast AI, a research institute dedicated to making deep learning more accessible and is an honorary professor at the University of Queensland.", "tokens": [634, 307, 264, 22223, 21751, 412, 15968, 7318, 11, 257, 2132, 26860, 8374, 281, 1455, 2452, 2539, 544, 9515, 293, 307, 364, 49365, 8304, 412, 264, 3535, 295, 36913, 13], "temperature": 0.0, "avg_logprob": -0.10145886090337014, "compression_ratio": 1.6891891891891893, "no_speech_prob": 7.242144056363031e-05}, {"id": 37, "seek": 14544, "start": 159.44, "end": 161.44, "text": " That's in Australia, I believe.", "tokens": [663, 311, 294, 7060, 11, 286, 1697, 13], "temperature": 0.0, "avg_logprob": -0.10145886090337014, "compression_ratio": 1.6891891891891893, "no_speech_prob": 7.242144056363031e-05}, {"id": 38, "seek": 14544, "start": 161.44, "end": 172.16, "text": " Previously, Jeremy was a distinguished research scientist at the University of San Francisco, where he was the founding chair of the Wicklow Artificial Intelligence and Medical Medical Research Initiative.", "tokens": [33606, 11, 17809, 390, 257, 21702, 2132, 12662, 412, 264, 3535, 295, 5271, 12279, 11, 689, 415, 390, 264, 22223, 6090, 295, 264, 47702, 14107, 5735, 10371, 27274, 293, 15896, 15896, 10303, 26166, 13], "temperature": 0.0, "avg_logprob": -0.10145886090337014, "compression_ratio": 1.6891891891891893, "no_speech_prob": 7.242144056363031e-05}, {"id": 39, "seek": 17216, "start": 172.16, "end": 183.04, "text": " He's also been the CEO of Unlitic and was the president and chief scientist of CAGO, which is the basically data science version of LeakCode, which many software developers are familiar with.", "tokens": [634, 311, 611, 668, 264, 9282, 295, 1156, 23062, 299, 293, 390, 264, 3868, 293, 9588, 12662, 295, 22852, 11601, 11, 597, 307, 264, 1936, 1412, 3497, 3037, 295, 1456, 514, 34, 1429, 11, 597, 867, 4722, 8849, 366, 4963, 365, 13], "temperature": 0.0, "avg_logprob": -0.11162607246470228, "compression_ratio": 1.5890410958904109, "no_speech_prob": 8.200295269489288e-05}, {"id": 40, "seek": 17216, "start": 183.04, "end": 187.84, "text": " He was the CEO of two successful Australian startups, Fastmail and Optimal Decisions Group.", "tokens": [634, 390, 264, 9282, 295, 732, 4406, 13337, 28041, 11, 15968, 11799, 293, 21455, 10650, 12427, 4252, 10500, 13], "temperature": 0.0, "avg_logprob": -0.11162607246470228, "compression_ratio": 1.5890410958904109, "no_speech_prob": 8.200295269489288e-05}, {"id": 41, "seek": 17216, "start": 187.84, "end": 197.35999999999999, "text": " And before that, in between doing a bunch of other things, he worked in management consulting at McKinsey, which is an incredibly interesting start to a career that he has had now.", "tokens": [400, 949, 300, 11, 294, 1296, 884, 257, 3840, 295, 661, 721, 11, 415, 2732, 294, 4592, 23682, 412, 21765, 259, 7399, 11, 597, 307, 364, 6252, 1880, 722, 281, 257, 3988, 300, 415, 575, 632, 586, 13], "temperature": 0.0, "avg_logprob": -0.11162607246470228, "compression_ratio": 1.5890410958904109, "no_speech_prob": 8.200295269489288e-05}, {"id": 42, "seek": 19736, "start": 197.36, "end": 204.56, "text": " Because for those of you that don't know, McKinsey is one of the three biggest management consulting firms alongside, I think, Bain & Co and BCG.", "tokens": [1436, 337, 729, 295, 291, 300, 500, 380, 458, 11, 21765, 259, 7399, 307, 472, 295, 264, 1045, 3880, 4592, 23682, 18055, 12385, 11, 286, 519, 11, 363, 491, 3693, 3066, 293, 14359, 38, 13], "temperature": 0.0, "avg_logprob": -0.1009992082542348, "compression_ratio": 1.6813186813186813, "no_speech_prob": 7.707987970206887e-05}, {"id": 43, "seek": 19736, "start": 204.56, "end": 221.56, "text": " So I'm super interested to hear how he started in management consulting and ended up being the author of one of the most popular AI libraries in Python and also the course that's attached to it, which I think is, if not, the most popular, a very, very popular course that students all around the world are taking.", "tokens": [407, 286, 478, 1687, 3102, 281, 1568, 577, 415, 1409, 294, 4592, 23682, 293, 4590, 493, 885, 264, 3793, 295, 472, 295, 264, 881, 3743, 7318, 15148, 294, 15329, 293, 611, 264, 1164, 300, 311, 8570, 281, 309, 11, 597, 286, 519, 307, 11, 498, 406, 11, 264, 881, 3743, 11, 257, 588, 11, 588, 3743, 1164, 300, 1731, 439, 926, 264, 1002, 366, 1940, 13], "temperature": 0.0, "avg_logprob": -0.1009992082542348, "compression_ratio": 1.6813186813186813, "no_speech_prob": 7.707987970206887e-05}, {"id": 44, "seek": 22156, "start": 221.56, "end": 231.76, "text": " So I will stop there, throw it over to Jeremy, and he can fill in all the gaps that he wants, jump back to however far you want to to tell us how you got to where you are now.", "tokens": [407, 286, 486, 1590, 456, 11, 3507, 309, 670, 281, 17809, 11, 293, 415, 393, 2836, 294, 439, 264, 15031, 300, 415, 2738, 11, 3012, 646, 281, 4461, 1400, 291, 528, 281, 281, 980, 505, 577, 291, 658, 281, 689, 291, 366, 586, 13], "temperature": 0.0, "avg_logprob": -0.10239125181127477, "compression_ratio": 1.6121673003802282, "no_speech_prob": 8.734391303732991e-05}, {"id": 45, "seek": 22156, "start": 231.76, "end": 245.56, "text": " And I think the one thing I forgot to mention, too, is that he recently tweeted on July 1st and we're recording this on July 4th that he quote the tweets reads, next week, I'm starting a daily study group on my most loved programming language, APL.", "tokens": [400, 286, 519, 264, 472, 551, 286, 5298, 281, 2152, 11, 886, 11, 307, 300, 415, 3938, 25646, 322, 7370, 502, 372, 293, 321, 434, 6613, 341, 322, 7370, 1017, 392, 300, 415, 6513, 264, 25671, 15700, 11, 958, 1243, 11, 286, 478, 2891, 257, 5212, 2979, 1594, 322, 452, 881, 4333, 9410, 2856, 11, 5372, 43, 13], "temperature": 0.0, "avg_logprob": -0.10239125181127477, "compression_ratio": 1.6121673003802282, "no_speech_prob": 8.734391303732991e-05}, {"id": 46, "seek": 24556, "start": 245.56, "end": 252.56, "text": " And so obviously interested to hear more about that tweet and what's going to be happening with that study group. So over to you, Jeremy.", "tokens": [400, 370, 2745, 3102, 281, 1568, 544, 466, 300, 15258, 293, 437, 311, 516, 281, 312, 2737, 365, 300, 2979, 1594, 13, 407, 670, 281, 291, 11, 17809, 13], "temperature": 0.0, "avg_logprob": -0.0947925993736754, "compression_ratio": 1.5815899581589958, "no_speech_prob": 2.1100544472574256e-05}, {"id": 47, "seek": 24556, "start": 252.56, "end": 261.56, "text": " Well, the study group is starting today as we record this. So depending on how long it takes to get this out, it'll have just started.", "tokens": [1042, 11, 264, 2979, 1594, 307, 2891, 965, 382, 321, 2136, 341, 13, 407, 5413, 322, 577, 938, 309, 2516, 281, 483, 341, 484, 11, 309, 603, 362, 445, 1409, 13], "temperature": 0.0, "avg_logprob": -0.0947925993736754, "compression_ratio": 1.5815899581589958, "no_speech_prob": 2.1100544472574256e-05}, {"id": 48, "seek": 24556, "start": 261.56, "end": 270.56, "text": " And so definitely time for people to join in. So I'm sure we'll include a link to that in the show notes.", "tokens": [400, 370, 2138, 565, 337, 561, 281, 3917, 294, 13, 407, 286, 478, 988, 321, 603, 4090, 257, 2113, 281, 300, 294, 264, 855, 5570, 13], "temperature": 0.0, "avg_logprob": -0.0947925993736754, "compression_ratio": 1.5815899581589958, "no_speech_prob": 2.1100544472574256e-05}, {"id": 49, "seek": 27056, "start": 270.56, "end": 278.56, "text": " I definitely feel kind of like I'm your least qualified array programming person ever interviewed on this show.", "tokens": [286, 2138, 841, 733, 295, 411, 286, 478, 428, 1935, 15904, 10225, 9410, 954, 1562, 19770, 322, 341, 855, 13], "temperature": 0.0, "avg_logprob": -0.11818992259890534, "compression_ratio": 1.5656108597285068, "no_speech_prob": 5.2187115215929225e-05}, {"id": 50, "seek": 27056, "start": 278.56, "end": 299.56, "text": " I love APL and J, but I've done very, very little with them, particularly APL. I've done a little, little bit with J mucking around, but like, I find a couple of weeks here and there every few years and I have for a couple of decades.", "tokens": [286, 959, 5372, 43, 293, 508, 11, 457, 286, 600, 1096, 588, 11, 588, 707, 365, 552, 11, 4098, 5372, 43, 13, 286, 600, 1096, 257, 707, 11, 707, 857, 365, 508, 275, 33260, 926, 11, 457, 411, 11, 286, 915, 257, 1916, 295, 3259, 510, 293, 456, 633, 1326, 924, 293, 286, 362, 337, 257, 1916, 295, 7878, 13], "temperature": 0.0, "avg_logprob": -0.11818992259890534, "compression_ratio": 1.5656108597285068, "no_speech_prob": 5.2187115215929225e-05}, {"id": 51, "seek": 29956, "start": 299.56, "end": 311.56, "text": " Having said that, I am a huge enthusiast of array programming as it is used, you know, in a loopless style in other languages.", "tokens": [10222, 848, 300, 11, 286, 669, 257, 2603, 18076, 525, 295, 10225, 9410, 382, 309, 307, 1143, 11, 291, 458, 11, 294, 257, 6367, 1832, 3758, 294, 661, 8650, 13], "temperature": 0.0, "avg_logprob": -0.12309533527919224, "compression_ratio": 1.435483870967742, "no_speech_prob": 3.119143002550118e-05}, {"id": 52, "seek": 29956, "start": 311.56, "end": 315.56, "text": " Additionally, in Pell and nowadays in Python.", "tokens": [19927, 11, 294, 430, 898, 293, 13434, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.12309533527919224, "compression_ratio": 1.435483870967742, "no_speech_prob": 3.119143002550118e-05}, {"id": 53, "seek": 29956, "start": 315.56, "end": 322.56, "text": " Yeah, maybe I'll come back to that because I guess you wanted to get a sense of my background.", "tokens": [865, 11, 1310, 286, 603, 808, 646, 281, 300, 570, 286, 2041, 291, 1415, 281, 483, 257, 2020, 295, 452, 3678, 13], "temperature": 0.0, "avg_logprob": -0.12309533527919224, "compression_ratio": 1.435483870967742, "no_speech_prob": 3.119143002550118e-05}, {"id": 54, "seek": 32256, "start": 322.56, "end": 337.56, "text": " Yeah. So I actually started at McKinsey. I grew up in Melbourne, Australia, and I didn't know what I wanted to do when I grew up at the point that you're meant to know when you choose a university, you know, major.", "tokens": [865, 13, 407, 286, 767, 1409, 412, 21765, 259, 7399, 13, 286, 6109, 493, 294, 27496, 11, 7060, 11, 293, 286, 994, 380, 458, 437, 286, 1415, 281, 360, 562, 286, 6109, 493, 412, 264, 935, 300, 291, 434, 4140, 281, 458, 562, 291, 2826, 257, 5454, 11, 291, 458, 11, 2563, 13], "temperature": 0.0, "avg_logprob": -0.07659547182978416, "compression_ratio": 1.6297872340425532, "no_speech_prob": 2.177687201765366e-05}, {"id": 55, "seek": 32256, "start": 337.56, "end": 348.56, "text": " So I picked philosophy on the basis that it was like, you know, the best way of punting down the road, what you might do because with philosophy, you can't do anything.", "tokens": [407, 286, 6183, 10675, 322, 264, 5143, 300, 309, 390, 411, 11, 291, 458, 11, 264, 1151, 636, 295, 4468, 783, 760, 264, 3060, 11, 437, 291, 1062, 360, 570, 365, 10675, 11, 291, 393, 380, 360, 1340, 13], "temperature": 0.0, "avg_logprob": -0.07659547182978416, "compression_ratio": 1.6297872340425532, "no_speech_prob": 2.177687201765366e-05}, {"id": 56, "seek": 34856, "start": 348.56, "end": 370.56, "text": " And honestly, that kind of worked out in that I needed money, and I needed money to get through university so I got a one day a week kind of IT support job at McKinsey, the McKinsey Melbourne office during university from first year, I think that's from first year.", "tokens": [400, 6095, 11, 300, 733, 295, 2732, 484, 294, 300, 286, 2978, 1460, 11, 293, 286, 2978, 1460, 281, 483, 807, 5454, 370, 286, 658, 257, 472, 786, 257, 1243, 733, 295, 6783, 1406, 1691, 412, 21765, 259, 7399, 11, 264, 21765, 259, 7399, 27496, 3398, 1830, 5454, 490, 700, 1064, 11, 286, 519, 300, 311, 490, 700, 1064, 13], "temperature": 0.0, "avg_logprob": -0.1473817080259323, "compression_ratio": 1.5963855421686748, "no_speech_prob": 1.7227033822564408e-05}, {"id": 57, "seek": 37056, "start": 370.56, "end": 384.56, "text": " But it turned out that like, yeah, I was very curious and so I'm so curious about management consulting so every time consultants would come down and ask me to like, you know, clean out the sticky coke they spilt in their keyboard or whatever.", "tokens": [583, 309, 3574, 484, 300, 411, 11, 1338, 11, 286, 390, 588, 6369, 293, 370, 286, 478, 370, 6369, 466, 4592, 23682, 370, 633, 565, 38935, 576, 808, 760, 293, 1029, 385, 281, 411, 11, 291, 458, 11, 2541, 484, 264, 14470, 33659, 436, 637, 2352, 294, 641, 10186, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.11609639944853606, "compression_ratio": 1.7375886524822695, "no_speech_prob": 1.6435484212706797e-05}, {"id": 58, "seek": 37056, "start": 384.56, "end": 399.56, "text": " I would always ask them what they were working on and ask them to show me and I've been really interested in like doing analytics see kind of things for a few years at that point so during high school basically every holidays I kind of worked on.", "tokens": [286, 576, 1009, 1029, 552, 437, 436, 645, 1364, 322, 293, 1029, 552, 281, 855, 385, 293, 286, 600, 668, 534, 3102, 294, 411, 884, 15370, 536, 733, 295, 721, 337, 257, 1326, 924, 412, 300, 935, 370, 1830, 1090, 1395, 1936, 633, 15734, 286, 733, 295, 2732, 322, 13], "temperature": 0.0, "avg_logprob": -0.11609639944853606, "compression_ratio": 1.7375886524822695, "no_speech_prob": 1.6435484212706797e-05}, {"id": 59, "seek": 39956, "start": 399.56, "end": 410.56, "text": " I kind of worked on stuff with spreadsheets or Microsoft access or whatever so I turned out I knew more about like stuff like Microsoft Excel than they did.", "tokens": [286, 733, 295, 2732, 322, 1507, 365, 23651, 1385, 420, 8116, 2105, 420, 2035, 370, 286, 3574, 484, 286, 2586, 544, 466, 411, 1507, 411, 8116, 19060, 813, 436, 630, 13], "temperature": 0.0, "avg_logprob": -0.10982830596692635, "compression_ratio": 1.52, "no_speech_prob": 1.9825758499791846e-05}, {"id": 60, "seek": 39956, "start": 410.56, "end": 424.56, "text": " So within about two months of me starting this one day a week job I was working 90 hour weeks, basically doing analytical work for the consultants.", "tokens": [407, 1951, 466, 732, 2493, 295, 385, 2891, 341, 472, 786, 257, 1243, 1691, 286, 390, 1364, 4289, 1773, 3259, 11, 1936, 884, 29579, 589, 337, 264, 38935, 13], "temperature": 0.0, "avg_logprob": -0.10982830596692635, "compression_ratio": 1.52, "no_speech_prob": 1.9825758499791846e-05}, {"id": 61, "seek": 42456, "start": 424.56, "end": 441.56, "text": " And that, you know, that actually worked out really well because I kind of did a deal with them where they would, they gave me a full time office and they would pay me $50 an hour for whatever time I needed and so suddenly I was actually making a lot of money,", "tokens": [400, 300, 11, 291, 458, 11, 300, 767, 2732, 484, 534, 731, 570, 286, 733, 295, 630, 257, 2028, 365, 552, 689, 436, 576, 11, 436, 2729, 385, 257, 1577, 565, 3398, 293, 436, 576, 1689, 385, 1848, 2803, 364, 1773, 337, 2035, 565, 286, 2978, 293, 370, 5800, 286, 390, 767, 1455, 257, 688, 295, 1460, 11], "temperature": 0.0, "avg_logprob": -0.06985210418701172, "compression_ratio": 1.5916230366492146, "no_speech_prob": 4.067031113663688e-05}, {"id": 62, "seek": 42456, "start": 441.56, "end": 446.56, "text": " you know, working, working 90 hours a week.", "tokens": [291, 458, 11, 1364, 11, 1364, 4289, 2496, 257, 1243, 13], "temperature": 0.0, "avg_logprob": -0.06985210418701172, "compression_ratio": 1.5916230366492146, "no_speech_prob": 4.067031113663688e-05}, {"id": 63, "seek": 44656, "start": 446.56, "end": 459.56, "text": " And, yeah, it was great because then the, I would come up with these solutions to things are doing in the projects and I'd have to present it to the client so next thing I knew I was basically on the client side all the all the time.", "tokens": [400, 11, 1338, 11, 309, 390, 869, 570, 550, 264, 11, 286, 576, 808, 493, 365, 613, 6547, 281, 721, 366, 884, 294, 264, 4455, 293, 286, 1116, 362, 281, 1974, 309, 281, 264, 6423, 370, 958, 551, 286, 2586, 286, 390, 1936, 322, 264, 6423, 1252, 439, 264, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.11566335625118679, "compression_ratio": 1.538860103626943, "no_speech_prob": 1.405985949531896e-05}, {"id": 64, "seek": 44656, "start": 459.56, "end": 464.56, "text": " So I ended up actually not going to any lectures at university.", "tokens": [407, 286, 4590, 493, 767, 406, 516, 281, 604, 16564, 412, 5454, 13], "temperature": 0.0, "avg_logprob": -0.11566335625118679, "compression_ratio": 1.538860103626943, "no_speech_prob": 1.405985949531896e-05}, {"id": 65, "seek": 46456, "start": 464.56, "end": 477.56, "text": " And I somehow kind of managed this thing where I would take two weeks off before each exam, go and talk to all my lecturers and say hey I was meant to be in your university course. I know you didn't see me but I was kind of busy.", "tokens": [400, 286, 6063, 733, 295, 6453, 341, 551, 689, 286, 576, 747, 732, 3259, 766, 949, 1184, 1139, 11, 352, 293, 751, 281, 439, 452, 5899, 14198, 293, 584, 4177, 286, 390, 4140, 281, 312, 294, 428, 5454, 1164, 13, 286, 458, 291, 994, 380, 536, 385, 457, 286, 390, 733, 295, 5856, 13], "temperature": 0.0, "avg_logprob": -0.08830668528874715, "compression_ratio": 1.5248618784530388, "no_speech_prob": 1.722724482533522e-05}, {"id": 66, "seek": 46456, "start": 477.56, "end": 480.56, "text": " Can you tell me what I was meant to have done.", "tokens": [1664, 291, 980, 385, 437, 286, 390, 4140, 281, 362, 1096, 13], "temperature": 0.0, "avg_logprob": -0.08830668528874715, "compression_ratio": 1.5248618784530388, "no_speech_prob": 1.722724482533522e-05}, {"id": 67, "seek": 48056, "start": 480.56, "end": 498.56, "text": " So I kind of scraped by a BA in philosophy but I don't, yeah, you know, I don't really have much of an academic background, but that did give me a great background in like applying stuff like, you know, linear regression and just regression and linear", "tokens": [407, 286, 733, 295, 13943, 3452, 538, 257, 21050, 294, 10675, 457, 286, 500, 380, 11, 1338, 11, 291, 458, 11, 286, 500, 380, 534, 362, 709, 295, 364, 7778, 3678, 11, 457, 300, 630, 976, 385, 257, 869, 3678, 294, 411, 9275, 1507, 411, 11, 291, 458, 11, 8213, 24590, 293, 445, 24590, 293, 8213], "temperature": 0.0, "avg_logprob": -0.10322171847025553, "compression_ratio": 1.539877300613497, "no_speech_prob": 1.8339333109906875e-05}, {"id": 68, "seek": 49856, "start": 498.56, "end": 517.56, "text": " programming and you know the basic analytical tools of the day, generally through VBA scripts in Excel or, you know, access, you know, the kind of stuff that a consultant could check out it you know on to their, onto their laptop at a client site.", "tokens": [9410, 293, 291, 458, 264, 3875, 29579, 3873, 295, 264, 786, 11, 5101, 807, 691, 9295, 23294, 294, 19060, 420, 11, 291, 458, 11, 2105, 11, 291, 458, 11, 264, 733, 295, 1507, 300, 257, 24676, 727, 1520, 484, 309, 291, 458, 322, 281, 641, 11, 3911, 641, 10732, 412, 257, 6423, 3621, 13], "temperature": 0.0, "avg_logprob": -0.12635062480794973, "compression_ratio": 1.5153374233128833, "no_speech_prob": 1.0287491932103876e-05}, {"id": 69, "seek": 51756, "start": 517.56, "end": 534.56, "text": " Anyway, I always feel guilty about doing that because it just seemed like this ridiculously nerdy thing to be doing when I was surrounded by all these very important, you know, consultant types who seemed to be doing much more impressive strategy work so I tried to get away from", "tokens": [5684, 11, 286, 1009, 841, 12341, 466, 884, 300, 570, 309, 445, 6576, 411, 341, 41358, 18219, 3173, 551, 281, 312, 884, 562, 286, 390, 13221, 538, 439, 613, 588, 1021, 11, 291, 458, 11, 24676, 3467, 567, 6576, 281, 312, 884, 709, 544, 8992, 5206, 589, 370, 286, 3031, 281, 483, 1314, 490], "temperature": 0.0, "avg_logprob": -0.06781880223021215, "compression_ratio": 1.6804511278195489, "no_speech_prob": 1.5932255337247625e-05}, {"id": 70, "seek": 51756, "start": 534.56, "end": 540.56, "text": " that as quickly as I could, because I didn't want to be the nerd in the company.", "tokens": [300, 382, 2661, 382, 286, 727, 11, 570, 286, 994, 380, 528, 281, 312, 264, 23229, 294, 264, 2237, 13], "temperature": 0.0, "avg_logprob": -0.06781880223021215, "compression_ratio": 1.6804511278195489, "no_speech_prob": 1.5932255337247625e-05}, {"id": 71, "seek": 51756, "start": 540.56, "end": 545.56, "text": " And yeah so I ended up spending the next 10 years basically doing strategy consulting.", "tokens": [400, 1338, 370, 286, 4590, 493, 6434, 264, 958, 1266, 924, 1936, 884, 5206, 23682, 13], "temperature": 0.0, "avg_logprob": -0.06781880223021215, "compression_ratio": 1.6804511278195489, "no_speech_prob": 1.5932255337247625e-05}, {"id": 72, "seek": 54556, "start": 545.56, "end": 561.56, "text": " But throughout that time I did, you know, because I didn't have the same background that they did that the expertise they did the MBA they did I had to solve things using data and analytically intensive approaches so, although in theory I was a strategy", "tokens": [583, 3710, 300, 565, 286, 630, 11, 291, 458, 11, 570, 286, 994, 380, 362, 264, 912, 3678, 300, 436, 630, 300, 264, 11769, 436, 630, 264, 26674, 436, 630, 286, 632, 281, 5039, 721, 1228, 1412, 293, 10783, 984, 18957, 11587, 370, 11, 4878, 294, 5261, 286, 390, 257, 5206], "temperature": 0.0, "avg_logprob": -0.07155975565180048, "compression_ratio": 1.8646616541353382, "no_speech_prob": 1.9828985386993736e-05}, {"id": 73, "seek": 54556, "start": 561.56, "end": 573.56, "text": " management consultant and I was working on problems like, you know, how do we fix the rice industry in Australia, or, you know, how do we, you know, like, you know, how do we deal with this new competitor coming into this industry or whatever", "tokens": [4592, 24676, 293, 286, 390, 1364, 322, 2740, 411, 11, 291, 458, 11, 577, 360, 321, 3191, 264, 5090, 3518, 294, 7060, 11, 420, 11, 291, 458, 11, 577, 360, 321, 11, 291, 458, 11, 411, 11, 291, 458, 11, 577, 360, 321, 2028, 365, 341, 777, 27266, 1348, 666, 341, 3518, 420, 2035], "temperature": 0.0, "avg_logprob": -0.07155975565180048, "compression_ratio": 1.8646616541353382, "no_speech_prob": 1.9828985386993736e-05}, {"id": 74, "seek": 57356, "start": 573.56, "end": 589.56, "text": " it was I always did it by analyzing data, which actually turned out to be a good niche you know because I was the one McKinsey consultant in Australia who did things that way and so I was successful and I became I think the, I ended up moving to ATKani", "tokens": [309, 390, 286, 1009, 630, 309, 538, 23663, 1412, 11, 597, 767, 3574, 484, 281, 312, 257, 665, 19956, 291, 458, 570, 286, 390, 264, 472, 21765, 259, 7399, 24676, 294, 7060, 567, 630, 721, 300, 636, 293, 370, 286, 390, 4406, 293, 286, 3062, 286, 519, 264, 11, 286, 4590, 493, 2684, 281, 8872, 42, 3782], "temperature": 0.0, "avg_logprob": -0.12423567454020182, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.7101090381620452e-05}, {"id": 75, "seek": 57356, "start": 589.56, "end": 594.56, "text": " which is the other of the two original management consulting firms.", "tokens": [597, 307, 264, 661, 295, 264, 732, 3380, 4592, 23682, 18055, 13], "temperature": 0.0, "avg_logprob": -0.12423567454020182, "compression_ratio": 1.5384615384615385, "no_speech_prob": 2.7101090381620452e-05}, {"id": 76, "seek": 59456, "start": 594.56, "end": 603.56, "text": " I think I became like the youngest manager in the world and you know, through this weird parallel path I was doing.", "tokens": [286, 519, 286, 3062, 411, 264, 17747, 6598, 294, 264, 1002, 293, 291, 458, 11, 807, 341, 3657, 8952, 3100, 286, 390, 884, 13], "temperature": 0.0, "avg_logprob": -0.1687431508844549, "compression_ratio": 1.6011904761904763, "no_speech_prob": 1.5443351003341377e-05}, {"id": 77, "seek": 59456, "start": 603.56, "end": 612.56, "text": " And then through that learned about insurance industry discovered it like the whole insurance industry was basically pricing things in a really dumb way.", "tokens": [400, 550, 807, 300, 3264, 466, 7214, 3518, 6941, 309, 411, 264, 1379, 7214, 3518, 390, 1936, 17621, 721, 294, 257, 534, 10316, 636, 13], "temperature": 0.0, "avg_logprob": -0.1687431508844549, "compression_ratio": 1.6011904761904763, "no_speech_prob": 1.5443351003341377e-05}, {"id": 78, "seek": 61256, "start": 612.56, "end": 628.56, "text": " I focused on optimization of optimized pricing launched a company with my university friend who had a PhD in operations research.", "tokens": [286, 5178, 322, 19618, 295, 26941, 17621, 8730, 257, 2237, 365, 452, 5454, 1277, 567, 632, 257, 14476, 294, 7705, 2132, 13], "temperature": 0.0, "avg_logprob": -0.20058222917410043, "compression_ratio": 1.2169811320754718, "no_speech_prob": 1.643904033699073e-05}, {"id": 79, "seek": 62856, "start": 628.56, "end": 645.56, "text": " And, yeah, so we built this new approach to pricing insurance which is, it was kind of fun I mean it's, you know, it went well in the set you know commercially took a bit about 10 years doing, doing that, and at the same time, running an email company", "tokens": [400, 11, 1338, 11, 370, 321, 3094, 341, 777, 3109, 281, 17621, 7214, 597, 307, 11, 309, 390, 733, 295, 1019, 286, 914, 309, 311, 11, 291, 458, 11, 309, 1437, 731, 294, 264, 992, 291, 458, 41751, 1890, 257, 857, 466, 1266, 924, 884, 11, 884, 300, 11, 293, 412, 264, 912, 565, 11, 2614, 364, 3796, 2237], "temperature": 0.0, "avg_logprob": -0.16007646354469093, "compression_ratio": 1.5315789473684212, "no_speech_prob": 2.3182210497907363e-05}, {"id": 80, "seek": 62856, "start": 645.56, "end": 650.56, "text": " called fast mail, which also went well.", "tokens": [1219, 2370, 10071, 11, 597, 611, 1437, 731, 13], "temperature": 0.0, "avg_logprob": -0.16007646354469093, "compression_ratio": 1.5315789473684212, "no_speech_prob": 2.3182210497907363e-05}, {"id": 81, "seek": 65056, "start": 650.56, "end": 661.56, "text": " So I started out basically using C++, and I would say that was kind of the start of my array programming journey in that in those days this is like 1999.", "tokens": [407, 286, 1409, 484, 1936, 1228, 383, 25472, 11, 293, 286, 576, 584, 300, 390, 733, 295, 264, 722, 295, 452, 10225, 9410, 4671, 294, 300, 294, 729, 1708, 341, 307, 411, 19952, 13], "temperature": 0.0, "avg_logprob": -0.1300181405884879, "compression_ratio": 1.4310344827586208, "no_speech_prob": 2.39167293329956e-05}, {"id": 82, "seek": 65056, "start": 661.56, "end": 669.56, "text": " The very first expression templates based approaches to C++ numeric programming were appearing.", "tokens": [440, 588, 700, 6114, 21165, 2361, 11587, 281, 383, 25472, 7866, 299, 9410, 645, 19870, 13], "temperature": 0.0, "avg_logprob": -0.1300181405884879, "compression_ratio": 1.4310344827586208, "no_speech_prob": 2.39167293329956e-05}, {"id": 83, "seek": 66956, "start": 669.56, "end": 684.56, "text": " And so I, you know, was talking to the people working on those libraries doing stuff like particularly stuff doing the big kind of high energy physics experiments that were going on in Europe.", "tokens": [400, 370, 286, 11, 291, 458, 11, 390, 1417, 281, 264, 561, 1364, 322, 729, 15148, 884, 1507, 411, 4098, 1507, 884, 264, 955, 733, 295, 1090, 2281, 10649, 12050, 300, 645, 516, 322, 294, 3315, 13], "temperature": 0.0, "avg_logprob": -0.06963614667399545, "compression_ratio": 1.6600790513833992, "no_speech_prob": 1.0949054740194697e-05}, {"id": 84, "seek": 66956, "start": 684.56, "end": 698.56, "text": " It was ultimately pretty annoying to work with though like the amount of time it took to compile those things that would take hours, and it was quirky as all hell, you know it's still pretty quirky doing meta programming in C++", "tokens": [467, 390, 6284, 1238, 11304, 281, 589, 365, 1673, 411, 264, 2372, 295, 565, 309, 1890, 281, 31413, 729, 721, 300, 576, 747, 2496, 11, 293, 309, 390, 49515, 382, 439, 4921, 11, 291, 458, 309, 311, 920, 1238, 49515, 884, 19616, 9410, 294, 383, 25472], "temperature": 0.0, "avg_logprob": -0.06963614667399545, "compression_ratio": 1.6600790513833992, "no_speech_prob": 1.0949054740194697e-05}, {"id": 85, "seek": 69856, "start": 698.56, "end": 702.56, "text": " but in those days it was just a nightmare every compiler was different.", "tokens": [457, 294, 729, 1708, 309, 390, 445, 257, 18724, 633, 31958, 390, 819, 13], "temperature": 0.0, "avg_logprob": -0.11383000214894613, "compression_ratio": 1.4426229508196722, "no_speech_prob": 2.930493610620033e-05}, {"id": 86, "seek": 69856, "start": 702.56, "end": 717.56, "text": " So I ended up switching to C sharp shortly after that came out, and, you know, move in a way it was disappointing because that was much less expressive as a kind of array programming paradigm.", "tokens": [407, 286, 4590, 493, 16493, 281, 383, 8199, 13392, 934, 300, 1361, 484, 11, 293, 11, 291, 458, 11, 1286, 294, 257, 636, 309, 390, 25054, 570, 300, 390, 709, 1570, 40189, 382, 257, 733, 295, 10225, 9410, 24709, 13], "temperature": 0.0, "avg_logprob": -0.11383000214894613, "compression_ratio": 1.4426229508196722, "no_speech_prob": 2.930493610620033e-05}, {"id": 87, "seek": 71756, "start": 717.56, "end": 737.56, "text": " And so instead I ended up basically grabbing Intel's MKL library, which is basically a blast on steroids, if you like, and writing my own C sharp wrapper to give me, you know, kind of array programming ish capabilities but not with any of the features", "tokens": [400, 370, 2602, 286, 4590, 493, 1936, 23771, 19762, 311, 30770, 43, 6405, 11, 597, 307, 1936, 257, 12035, 322, 45717, 11, 498, 291, 411, 11, 293, 3579, 452, 1065, 383, 8199, 46906, 281, 976, 385, 11, 291, 458, 11, 733, 295, 10225, 9410, 307, 71, 10862, 457, 406, 365, 604, 295, 264, 4122], "temperature": 0.0, "avg_logprob": -0.090643677218207, "compression_ratio": 1.4180790960451977, "no_speech_prob": 6.4379187278973404e-06}, {"id": 88, "seek": 73756, "start": 737.56, "end": 752.56, "text": " that anyone would come to expect from a real array programming language around kind of dealing with rank sensibly and, you know, not much in the way of broadcasting, which reminds me we should come back to talking about blast at some stage because a lot of the", "tokens": [300, 2878, 576, 808, 281, 2066, 490, 257, 957, 10225, 9410, 2856, 926, 733, 295, 6260, 365, 6181, 2923, 3545, 293, 11, 291, 458, 11, 406, 709, 294, 264, 636, 295, 30024, 11, 597, 12025, 385, 321, 820, 808, 646, 281, 1417, 466, 12035, 412, 512, 3233, 570, 257, 688, 295, 264], "temperature": 0.0, "avg_logprob": -0.14021180924915133, "compression_ratio": 1.7012987012987013, "no_speech_prob": 3.218327765353024e-05}, {"id": 89, "seek": 73756, "start": 752.56, "end": 762.56, "text": " reasons that most languages are so disappointing at array programming is because of our reliance on blasts, you know as an industry.", "tokens": [4112, 300, 881, 8650, 366, 370, 25054, 412, 10225, 9410, 307, 570, 295, 527, 1039, 6276, 322, 12035, 82, 11, 291, 458, 382, 364, 3518, 13], "temperature": 0.0, "avg_logprob": -0.14021180924915133, "compression_ratio": 1.7012987012987013, "no_speech_prob": 3.218327765353024e-05}, {"id": 90, "seek": 76256, "start": 762.56, "end": 771.56, "text": " Fast mail on the other hand is being written in Perl, which I really enjoyed as a programming language and still to still love pill a lot.", "tokens": [15968, 10071, 322, 264, 661, 1011, 307, 885, 3720, 294, 3026, 75, 11, 597, 286, 534, 4626, 382, 257, 9410, 2856, 293, 920, 281, 920, 959, 8100, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.21464135096623346, "compression_ratio": 1.4154929577464788, "no_speech_prob": 6.603338260902092e-05}, {"id": 91, "seek": 76256, "start": 771.56, "end": 776.56, "text": " But the scientific programming in Pearl.", "tokens": [583, 264, 8134, 9410, 294, 24639, 13], "temperature": 0.0, "avg_logprob": -0.21464135096623346, "compression_ratio": 1.4154929577464788, "no_speech_prob": 6.603338260902092e-05}, {"id": 92, "seek": 76256, "start": 776.56, "end": 778.56, "text": " I didn't love at all.", "tokens": [286, 994, 380, 959, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.21464135096623346, "compression_ratio": 1.4154929577464788, "no_speech_prob": 6.603338260902092e-05}, {"id": 93, "seek": 77856, "start": 778.56, "end": 795.56, "text": " And so, at the time, Pearl six, you know, we was just starting to the idea of it was being developed so I ended up running the Pell six working group to add scientific programming capabilities or kind of, you know, and at the time I described", "tokens": [400, 370, 11, 412, 264, 565, 11, 24639, 2309, 11, 291, 458, 11, 321, 390, 445, 2891, 281, 264, 1558, 295, 309, 390, 885, 4743, 370, 286, 4590, 493, 2614, 264, 430, 898, 2309, 1364, 1594, 281, 909, 8134, 9410, 10862, 420, 733, 295, 11, 291, 458, 11, 293, 412, 264, 565, 286, 7619], "temperature": 0.0, "avg_logprob": -0.1314066196310109, "compression_ratio": 1.5220125786163523, "no_speech_prob": 1.4966537492000498e-05}, {"id": 94, "seek": 79556, "start": 795.56, "end": 813.56, "text": " it as APL inspired programming capabilities to Pearl. And so I did an RFC around what we ended up calling hyper operators which is basically the idea that any operator can can operate on arrays and can broadcast over any axes that are that are", "tokens": [309, 382, 5372, 43, 7547, 9410, 10862, 281, 24639, 13, 400, 370, 286, 630, 364, 497, 18671, 926, 437, 321, 4590, 493, 5141, 9848, 19077, 597, 307, 1936, 264, 1558, 300, 604, 12973, 393, 393, 9651, 322, 41011, 293, 393, 9975, 670, 604, 35387, 300, 366, 300, 366], "temperature": 0.0, "avg_logprob": -0.18471516095674956, "compression_ratio": 1.4727272727272727, "no_speech_prob": 2.0454288460314274e-05}, {"id": 95, "seek": 81356, "start": 813.56, "end": 825.56, "text": " that are mismatched or whatever. And those RFC is all ended up getting accepted and Damien Conway and Larry war kind of expanded them a little bit.", "tokens": [300, 366, 23220, 24102, 420, 2035, 13, 400, 729, 497, 18671, 307, 439, 4590, 493, 1242, 9035, 293, 5885, 1053, 2656, 676, 293, 18145, 1516, 733, 295, 14342, 552, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.2048269377814399, "compression_ratio": 1.4037267080745341, "no_speech_prob": 3.70391717297025e-05}, {"id": 96, "seek": 81356, "start": 825.56, "end": 831.56, "text": " Pell six never exactly happened it ended up becoming a language called record.", "tokens": [430, 898, 2309, 1128, 2293, 2011, 309, 4590, 493, 5617, 257, 2856, 1219, 2136, 13], "temperature": 0.0, "avg_logprob": -0.2048269377814399, "compression_ratio": 1.4037267080745341, "no_speech_prob": 3.70391717297025e-05}, {"id": 97, "seek": 83156, "start": 831.56, "end": 844.56, "text": " With the butterfly logo. Yeah, and that, you know, and the kind of the performance ideas I really worked hard on never really happened either so that was a bit of a, yeah, that was all a bit of a failure.", "tokens": [2022, 264, 22140, 9699, 13, 865, 11, 293, 300, 11, 291, 458, 11, 293, 264, 733, 295, 264, 3389, 3487, 286, 534, 2732, 1152, 322, 1128, 534, 2011, 2139, 370, 300, 390, 257, 857, 295, 257, 11, 1338, 11, 300, 390, 439, 257, 857, 295, 257, 7763, 13], "temperature": 0.0, "avg_logprob": -0.11123798466935943, "compression_ratio": 1.6117021276595744, "no_speech_prob": 9.077023605641443e-06}, {"id": 98, "seek": 83156, "start": 844.56, "end": 848.56, "text": " But it was fun and it was interesting.", "tokens": [583, 309, 390, 1019, 293, 309, 390, 1880, 13], "temperature": 0.0, "avg_logprob": -0.11123798466935943, "compression_ratio": 1.6117021276595744, "no_speech_prob": 9.077023605641443e-06}, {"id": 99, "seek": 83156, "start": 848.56, "end": 854.56, "text": " I, you know, so after running these companies for 10 years.", "tokens": [286, 11, 291, 458, 11, 370, 934, 2614, 613, 3431, 337, 1266, 924, 13], "temperature": 0.0, "avg_logprob": -0.11123798466935943, "compression_ratio": 1.6117021276595744, "no_speech_prob": 9.077023605641443e-06}, {"id": 100, "seek": 85456, "start": 854.56, "end": 867.56, "text": " One of the big problems with running a company is that you're surrounded by people who you hired, and they, you know, have to make you like them if they want to get promoted, you know get fired and so you could never trust anything anybody says.", "tokens": [1485, 295, 264, 955, 2740, 365, 2614, 257, 2237, 307, 300, 291, 434, 13221, 538, 561, 567, 291, 13144, 11, 293, 436, 11, 291, 458, 11, 362, 281, 652, 291, 411, 552, 498, 436, 528, 281, 483, 21162, 11, 291, 458, 483, 11777, 293, 370, 291, 727, 1128, 3361, 1340, 4472, 1619, 13], "temperature": 0.0, "avg_logprob": -0.11789885900353872, "compression_ratio": 1.6385542168674698, "no_speech_prob": 6.3383304222952574e-06}, {"id": 101, "seek": 85456, "start": 867.56, "end": 878.56, "text": " So I was, you know, very bad very low expectations about my capabilities analytics leaks I hadn't like, you know, I basically been running companies for 10 years.", "tokens": [407, 286, 390, 11, 291, 458, 11, 588, 1578, 588, 2295, 9843, 466, 452, 10862, 15370, 28885, 286, 8782, 380, 411, 11, 291, 458, 11, 286, 1936, 668, 2614, 3431, 337, 1266, 924, 13], "temperature": 0.0, "avg_logprob": -0.11789885900353872, "compression_ratio": 1.6385542168674698, "no_speech_prob": 6.3383304222952574e-06}, {"id": 102, "seek": 87856, "start": 878.56, "end": 885.56, "text": " I did a lot of coding and stuff but it was in our own little wealth.", "tokens": [286, 630, 257, 688, 295, 17720, 293, 1507, 457, 309, 390, 294, 527, 1065, 707, 7203, 13], "temperature": 0.0, "avg_logprob": -0.1422319258413007, "compression_ratio": 1.4038461538461537, "no_speech_prob": 6.438225227611838e-06}, {"id": 103, "seek": 87856, "start": 885.56, "end": 891.56, "text": " And so, after I sold those companies.", "tokens": [400, 370, 11, 934, 286, 3718, 729, 3431, 13], "temperature": 0.0, "avg_logprob": -0.1422319258413007, "compression_ratio": 1.4038461538461537, "no_speech_prob": 6.438225227611838e-06}, {"id": 104, "seek": 87856, "start": 891.56, "end": 901.56, "text": " Yeah, I, one of the things I decided to do was to try actually to become more competent. You know I had lost my.", "tokens": [865, 11, 286, 11, 472, 295, 264, 721, 286, 3047, 281, 360, 390, 281, 853, 767, 281, 1813, 544, 29998, 13, 509, 458, 286, 632, 2731, 452, 13], "temperature": 0.0, "avg_logprob": -0.1422319258413007, "compression_ratio": 1.4038461538461537, "no_speech_prob": 6.438225227611838e-06}, {"id": 105, "seek": 90156, "start": 901.56, "end": 915.56, "text": " To some extent, I had, I had lost my feeling that I should hide my nerdiness, you know, and try to act like a real business person, and I thought no I should actually see if I'm actually any good at this stuff.", "tokens": [1407, 512, 8396, 11, 286, 632, 11, 286, 632, 2731, 452, 2633, 300, 286, 820, 6479, 452, 23229, 1324, 11, 291, 458, 11, 293, 853, 281, 605, 411, 257, 957, 1606, 954, 11, 293, 286, 1194, 572, 286, 820, 767, 536, 498, 286, 478, 767, 604, 665, 412, 341, 1507, 13], "temperature": 0.0, "avg_logprob": -0.09325102473912614, "compression_ratio": 1.5903083700440528, "no_speech_prob": 2.947810116893379e-06}, {"id": 106, "seek": 90156, "start": 915.56, "end": 924.56, "text": " So I tried entering a machine learning competition at a new company that had just been launched called Kaggle.", "tokens": [407, 286, 3031, 11104, 257, 3479, 2539, 6211, 412, 257, 777, 2237, 300, 632, 445, 668, 8730, 1219, 48751, 22631, 13], "temperature": 0.0, "avg_logprob": -0.09325102473912614, "compression_ratio": 1.5903083700440528, "no_speech_prob": 2.947810116893379e-06}, {"id": 107, "seek": 90156, "start": 924.56, "end": 928.56, "text": " With this goal of like not coming last.", "tokens": [2022, 341, 3387, 295, 411, 406, 1348, 1036, 13], "temperature": 0.0, "avg_logprob": -0.09325102473912614, "compression_ratio": 1.5903083700440528, "no_speech_prob": 2.947810116893379e-06}, {"id": 108, "seek": 92856, "start": 928.56, "end": 944.56, "text": " And basically, the, you know, the way these things work is you have to make predictions on a data set, and at the end of the competition who has predictions for the most accurate", "tokens": [400, 1936, 11, 264, 11, 291, 458, 11, 264, 636, 613, 721, 589, 307, 291, 362, 281, 652, 21264, 322, 257, 1412, 992, 11, 293, 412, 264, 917, 295, 264, 6211, 567, 575, 21264, 337, 264, 881, 8559], "temperature": 0.0, "avg_logprob": -0.14425021248894768, "compression_ratio": 1.515625, "no_speech_prob": 8.662990694574546e-06}, {"id": 109, "seek": 92856, "start": 944.56, "end": 953.56, "text": " wins the prize. And so my goal was, yeah, try not to come last, which I wasn't convinced I'd be able to achieve.", "tokens": [10641, 264, 12818, 13, 400, 370, 452, 3387, 390, 11, 1338, 11, 853, 406, 281, 808, 1036, 11, 597, 286, 2067, 380, 12561, 286, 1116, 312, 1075, 281, 4584, 13], "temperature": 0.0, "avg_logprob": -0.14425021248894768, "compression_ratio": 1.515625, "no_speech_prob": 8.662990694574546e-06}, {"id": 110, "seek": 95356, "start": 953.56, "end": 965.56, "text": " Because as I say I didn't feel like this is. I'd never had any technical training, you know and everybody else in these competitions with PhDs and professors or whatever else so it felt like a high bar.", "tokens": [1436, 382, 286, 584, 286, 994, 380, 841, 411, 341, 307, 13, 286, 1116, 1128, 632, 604, 6191, 3097, 11, 291, 458, 293, 2201, 1646, 294, 613, 26185, 365, 14476, 82, 293, 15924, 420, 2035, 1646, 370, 309, 2762, 411, 257, 1090, 2159, 13], "temperature": 0.0, "avg_logprob": -0.12338400399813088, "compression_ratio": 1.5344827586206897, "no_speech_prob": 3.611441798057058e-06}, {"id": 111, "seek": 95356, "start": 965.56, "end": 968.56, "text": " Anyway, I ended up winning it.", "tokens": [5684, 11, 286, 4590, 493, 8224, 309, 13], "temperature": 0.0, "avg_logprob": -0.12338400399813088, "compression_ratio": 1.5344827586206897, "no_speech_prob": 3.611441798057058e-06}, {"id": 112, "seek": 95356, "start": 968.56, "end": 982.56, "text": " And that that changed my life. Right, because, yeah, it was like, Oh, okay I am, you know, empirically good at this thing.", "tokens": [400, 300, 300, 3105, 452, 993, 13, 1779, 11, 570, 11, 1338, 11, 309, 390, 411, 11, 876, 11, 1392, 286, 669, 11, 291, 458, 11, 25790, 984, 665, 412, 341, 551, 13], "temperature": 0.0, "avg_logprob": -0.12338400399813088, "compression_ratio": 1.5344827586206897, "no_speech_prob": 3.611441798057058e-06}, {"id": 113, "seek": 98256, "start": 982.56, "end": 990.56, "text": " And people at my local user groups I we used are quite a bit as well.", "tokens": [400, 561, 412, 452, 2654, 4195, 3935, 286, 321, 1143, 366, 1596, 257, 857, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1909696405584162, "compression_ratio": 1.6762295081967213, "no_speech_prob": 3.0234676160034724e-05}, {"id": 114, "seek": 98256, "start": 990.56, "end": 1001.56, "text": " Were you know I told them, I'm going to try entering this competition, anyone want to create a team with me I want to like learn to use our properly and I kind of went back to the next user group meeting and people were like, I thought you were just learning", "tokens": [12448, 291, 458, 286, 1907, 552, 11, 286, 478, 516, 281, 853, 11104, 341, 6211, 11, 2878, 528, 281, 1884, 257, 1469, 365, 385, 286, 528, 281, 411, 1466, 281, 764, 527, 6108, 293, 286, 733, 295, 1437, 646, 281, 264, 958, 4195, 1594, 3440, 293, 561, 645, 411, 11, 286, 1194, 291, 645, 445, 2539], "temperature": 0.0, "avg_logprob": -0.1909696405584162, "compression_ratio": 1.6762295081967213, "no_speech_prob": 3.0234676160034724e-05}, {"id": 115, "seek": 98256, "start": 1001.56, "end": 1002.56, "text": " this thing.", "tokens": [341, 551, 13], "temperature": 0.0, "avg_logprob": -0.1909696405584162, "compression_ratio": 1.6762295081967213, "no_speech_prob": 3.0234676160034724e-05}, {"id": 116, "seek": 98256, "start": 1002.56, "end": 1003.56, "text": " How did you.", "tokens": [1012, 630, 291, 13], "temperature": 0.0, "avg_logprob": -0.1909696405584162, "compression_ratio": 1.6762295081967213, "no_speech_prob": 3.0234676160034724e-05}, {"id": 117, "seek": 98256, "start": 1003.56, "end": 1005.56, "text": " How did you win.", "tokens": [1012, 630, 291, 1942, 13], "temperature": 0.0, "avg_logprob": -0.1909696405584162, "compression_ratio": 1.6762295081967213, "no_speech_prob": 3.0234676160034724e-05}, {"id": 118, "seek": 98256, "start": 1005.56, "end": 1010.56, "text": " I don't know. I just use common sense.", "tokens": [286, 500, 380, 458, 13, 286, 445, 764, 2689, 2020, 13], "temperature": 0.0, "avg_logprob": -0.1909696405584162, "compression_ratio": 1.6762295081967213, "no_speech_prob": 3.0234676160034724e-05}, {"id": 119, "seek": 101056, "start": 1010.56, "end": 1021.56, "text": " Yeah, so I ended up becoming the chief scientist and president of Kaggle and Kaggle as you know anybody in the data science world knows is kind of grown into this huge, huge thing ended up selling it to Google.", "tokens": [865, 11, 370, 286, 4590, 493, 5617, 264, 9588, 12662, 293, 3868, 295, 48751, 22631, 293, 48751, 22631, 382, 291, 458, 4472, 294, 264, 1412, 3497, 1002, 3255, 307, 733, 295, 7709, 666, 341, 2603, 11, 2603, 551, 4590, 493, 6511, 309, 281, 3329, 13], "temperature": 0.0, "avg_logprob": -0.08576264945409631, "compression_ratio": 1.6160337552742616, "no_speech_prob": 4.197432645014487e-05}, {"id": 120, "seek": 101056, "start": 1021.56, "end": 1026.56, "text": " So I ended up being an equal partner in the company I was the first investor in it.", "tokens": [407, 286, 4590, 493, 885, 364, 2681, 4975, 294, 264, 2237, 286, 390, 264, 700, 18479, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.08576264945409631, "compression_ratio": 1.6160337552742616, "no_speech_prob": 4.197432645014487e-05}, {"id": 121, "seek": 101056, "start": 1026.56, "end": 1033.56, "text": " And that was great that was like, I just dove in we moved to San Francisco for 10 years.", "tokens": [400, 300, 390, 869, 300, 390, 411, 11, 286, 445, 23287, 294, 321, 4259, 281, 5271, 12279, 337, 1266, 924, 13], "temperature": 0.0, "avg_logprob": -0.08576264945409631, "compression_ratio": 1.6160337552742616, "no_speech_prob": 4.197432645014487e-05}, {"id": 122, "seek": 103356, "start": 1033.56, "end": 1049.56, "text": " And, you know, surrounded, surrounded by all these people who I just sort of role models and idols, and partly getting to meet all these people in San Francisco was this experience of realizing all these people were actually totally normal, you know,", "tokens": [400, 11, 291, 458, 11, 13221, 11, 13221, 538, 439, 613, 561, 567, 286, 445, 1333, 295, 3090, 5245, 293, 29959, 11, 293, 17031, 1242, 281, 1677, 439, 613, 561, 294, 5271, 12279, 390, 341, 1752, 295, 16734, 439, 613, 561, 645, 767, 3879, 2710, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.09521091209267671, "compression_ratio": 1.6129032258064515, "no_speech_prob": 1.7227375792572275e-05}, {"id": 123, "seek": 104956, "start": 1049.56, "end": 1068.56, "text": " they weren't like some super genius level like they're just normal people who.", "tokens": [436, 4999, 380, 411, 512, 1687, 14017, 1496, 411, 436, 434, 445, 2710, 561, 567, 13], "temperature": 0.0, "avg_logprob": -0.21066274642944335, "compression_ratio": 1.054054054054054, "no_speech_prob": 1.4504146747640334e-05}, {"id": 124, "seek": 106856, "start": 1068.56, "end": 1081.56, "text": " I think in Australia.", "tokens": [286, 519, 294, 7060, 13], "temperature": 0.0, "avg_logprob": -0.21213978812808082, "compression_ratio": 1.2727272727272727, "no_speech_prob": 1.2602817150764167e-05}, {"id": 125, "seek": 106856, "start": 1081.56, "end": 1095.56, "text": " It's very easy to feel at it all like, yeah, we, we're not very confident about capabilities over here other than in sport, perhaps.", "tokens": [467, 311, 588, 1858, 281, 841, 412, 309, 439, 411, 11, 1338, 11, 321, 11, 321, 434, 406, 588, 6679, 466, 10862, 670, 510, 661, 813, 294, 7282, 11, 4317, 13], "temperature": 0.0, "avg_logprob": -0.21213978812808082, "compression_ratio": 1.2727272727272727, "no_speech_prob": 1.2602817150764167e-05}, {"id": 126, "seek": 109556, "start": 1095.56, "end": 1104.56, "text": " Yeah, so one of the things that happened well as a Kaggle was, I had played around with neural networks, a bit, a good bit, you know, like 20 years earlier.", "tokens": [865, 11, 370, 472, 295, 264, 721, 300, 2011, 731, 382, 257, 48751, 22631, 390, 11, 286, 632, 3737, 926, 365, 18161, 9590, 11, 257, 857, 11, 257, 665, 857, 11, 291, 458, 11, 411, 945, 924, 3071, 13], "temperature": 0.0, "avg_logprob": -0.14085548400878906, "compression_ratio": 1.5408163265306123, "no_speech_prob": 2.1777235815534368e-05}, {"id": 127, "seek": 109556, "start": 1104.56, "end": 1117.56, "text": " And I always felt like neural networks were one day going to be the thing it's like you know they are on a theoretical level, infinitely capable.", "tokens": [400, 286, 1009, 2762, 411, 18161, 9590, 645, 472, 786, 516, 281, 312, 264, 551, 309, 311, 411, 291, 458, 436, 366, 322, 257, 20864, 1496, 11, 36227, 8189, 13], "temperature": 0.0, "avg_logprob": -0.14085548400878906, "compression_ratio": 1.5408163265306123, "no_speech_prob": 2.1777235815534368e-05}, {"id": 128, "seek": 111756, "start": 1117.56, "end": 1123.56, "text": " But, you know, they never quite did it for me and.", "tokens": [583, 11, 291, 458, 11, 436, 1128, 1596, 630, 309, 337, 385, 293, 13], "temperature": 0.0, "avg_logprob": -0.10044926184195059, "compression_ratio": 1.4853801169590644, "no_speech_prob": 1.2603631148522254e-05}, {"id": 129, "seek": 111756, "start": 1123.56, "end": 1136.56, "text": " But then in 2012, suddenly, neural networks started achieving superhuman performance for the first time on really challenging problems like recognizing traffic signs, you know, like recognizing pictures.", "tokens": [583, 550, 294, 9125, 11, 5800, 11, 18161, 9590, 1409, 19626, 1687, 18796, 3389, 337, 264, 700, 565, 322, 534, 7595, 2740, 411, 18538, 6419, 7880, 11, 291, 458, 11, 411, 18538, 5242, 13], "temperature": 0.0, "avg_logprob": -0.10044926184195059, "compression_ratio": 1.4853801169590644, "no_speech_prob": 1.2603631148522254e-05}, {"id": 130, "seek": 113656, "start": 1136.56, "end": 1147.56, "text": " And I'd always said to myself, I was going to watch for this moment and when it happened I wanted to like jump on it. So as soon as I saw that I tried to jump on it so I started a new company.", "tokens": [400, 286, 1116, 1009, 848, 281, 2059, 11, 286, 390, 516, 281, 1159, 337, 341, 1623, 293, 562, 309, 2011, 286, 1415, 281, 411, 3012, 322, 309, 13, 407, 382, 2321, 382, 286, 1866, 300, 286, 3031, 281, 3012, 322, 309, 370, 286, 1409, 257, 777, 2237, 13], "temperature": 0.0, "avg_logprob": -0.10013497530759036, "compression_ratio": 1.6481481481481481, "no_speech_prob": 8.26532232167665e-06}, {"id": 131, "seek": 113656, "start": 1147.56, "end": 1158.56, "text": " After a year of research into like the, you know, what, what a neural networks going to do. I decided medicine was going to be huge. I knew nothing about medicine.", "tokens": [2381, 257, 1064, 295, 2132, 666, 411, 264, 11, 291, 458, 11, 437, 11, 437, 257, 18161, 9590, 516, 281, 360, 13, 286, 3047, 7195, 390, 516, 281, 312, 2603, 13, 286, 2586, 1825, 466, 7195, 13], "temperature": 0.0, "avg_logprob": -0.10013497530759036, "compression_ratio": 1.6481481481481481, "no_speech_prob": 8.26532232167665e-06}, {"id": 132, "seek": 115856, "start": 1158.56, "end": 1166.56, "text": " And I, yeah, I started a medicine company to see what we could do with deep learning and medicine.", "tokens": [400, 286, 11, 1338, 11, 286, 1409, 257, 7195, 2237, 281, 536, 437, 321, 727, 360, 365, 2452, 2539, 293, 7195, 13], "temperature": 0.0, "avg_logprob": -0.10103833554971098, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.4737146557308733e-05}, {"id": 133, "seek": 115856, "start": 1166.56, "end": 1168.56, "text": " So that was analytic.", "tokens": [407, 300, 390, 40358, 13], "temperature": 0.0, "avg_logprob": -0.10103833554971098, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.4737146557308733e-05}, {"id": 134, "seek": 115856, "start": 1168.56, "end": 1170.56, "text": " Yeah, that ended up going pretty well.", "tokens": [865, 11, 300, 4590, 493, 516, 1238, 731, 13], "temperature": 0.0, "avg_logprob": -0.10103833554971098, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.4737146557308733e-05}, {"id": 135, "seek": 115856, "start": 1170.56, "end": 1182.56, "text": " And, yeah, eventually I kind of got like a bit frustrated with that though because it felt like big learning can do so many things and I'm only doing such a small part of those things.", "tokens": [400, 11, 1338, 11, 4728, 286, 733, 295, 658, 411, 257, 857, 15751, 365, 300, 1673, 570, 309, 2762, 411, 955, 2539, 393, 360, 370, 867, 721, 293, 286, 478, 787, 884, 1270, 257, 1359, 644, 295, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.10103833554971098, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.4737146557308733e-05}, {"id": 136, "seek": 115856, "start": 1182.56, "end": 1187.56, "text": " So deep learning is like neural networks with multiple layers.", "tokens": [407, 2452, 2539, 307, 411, 18161, 9590, 365, 3866, 7914, 13], "temperature": 0.0, "avg_logprob": -0.10103833554971098, "compression_ratio": 1.6680327868852458, "no_speech_prob": 1.4737146557308733e-05}, {"id": 137, "seek": 118756, "start": 1187.56, "end": 1198.56, "text": " And so the only way to actually help people really, you know, make the most of this incredibly valuable technology is to teach other people how to do it, and to help other people to do it.", "tokens": [400, 370, 264, 787, 636, 281, 767, 854, 561, 534, 11, 291, 458, 11, 652, 264, 881, 295, 341, 6252, 8263, 2899, 307, 281, 2924, 661, 561, 577, 281, 360, 309, 11, 293, 281, 854, 661, 561, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.07473253673977322, "compression_ratio": 1.4573643410852712, "no_speech_prob": 3.426001421757974e-05}, {"id": 138, "seek": 119856, "start": 1198.56, "end": 1218.56, "text": " So my wife and I ended up studying a new, I call it kind of a research lab, Fast AI, to help to help do that basically initially focus on education and then increasingly focus on research and software development to basically make it easier for folks to use", "tokens": [407, 452, 3836, 293, 286, 4590, 493, 7601, 257, 777, 11, 286, 818, 309, 733, 295, 257, 2132, 2715, 11, 15968, 7318, 11, 281, 854, 281, 854, 360, 300, 1936, 9105, 1879, 322, 3309, 293, 550, 12980, 1879, 322, 2132, 293, 4722, 3250, 281, 1936, 652, 309, 3571, 337, 4024, 281, 764], "temperature": 0.0, "avg_logprob": -0.12513547330289274, "compression_ratio": 1.5808080808080809, "no_speech_prob": 7.765575901430566e-06}, {"id": 139, "seek": 119856, "start": 1218.56, "end": 1222.56, "text": " deep learning. And that's, yeah, that's where I am now.", "tokens": [2452, 2539, 13, 400, 300, 311, 11, 1338, 11, 300, 311, 689, 286, 669, 586, 13], "temperature": 0.0, "avg_logprob": -0.12513547330289274, "compression_ratio": 1.5808080808080809, "no_speech_prob": 7.765575901430566e-06}, {"id": 140, "seek": 122256, "start": 1222.56, "end": 1246.56, "text": " And that everything in deep learning is all Python. And in Python, we're very lucky to have, you know, excellent libraries that behave pretty consistently with each other, basically based around this NumPy library, which treats arrays very, very similarly to how", "tokens": [400, 300, 1203, 294, 2452, 2539, 307, 439, 15329, 13, 400, 294, 15329, 11, 321, 434, 588, 6356, 281, 362, 11, 291, 458, 11, 7103, 15148, 300, 15158, 1238, 14961, 365, 1184, 661, 11, 1936, 2361, 926, 341, 22592, 47, 88, 6405, 11, 597, 19566, 41011, 588, 11, 588, 14138, 281, 577], "temperature": 0.0, "avg_logprob": -0.13757744005748204, "compression_ratio": 1.4802259887005649, "no_speech_prob": 2.0779925762326457e-05}, {"id": 141, "seek": 124656, "start": 1246.56, "end": 1264.56, "text": " Jay does, except rather than leading access, it's trailing access but basically you get, you know, you get loop free, you get broadcasting, you know, you don't get things like a rank conjunction, but there's very easy ways to permute axes so you can do basically the same thing.", "tokens": [11146, 775, 11, 3993, 2831, 813, 5775, 2105, 11, 309, 311, 944, 4883, 2105, 457, 1936, 291, 483, 11, 291, 458, 11, 291, 483, 6367, 1737, 11, 291, 483, 30024, 11, 291, 458, 11, 291, 500, 380, 483, 721, 411, 257, 6181, 27482, 11, 457, 456, 311, 588, 1858, 2098, 281, 4784, 1169, 35387, 370, 291, 393, 360, 1936, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.16461854906224493, "compression_ratio": 1.6352941176470588, "no_speech_prob": 5.736039383918978e-05}, {"id": 142, "seek": 126456, "start": 1264.56, "end": 1293.56, "text": " Things like Einstein notation, you know, built into the libraries and then you know it's, it's trivially easy to have them run on GPUs or TPUs or whatever, you know, so for the last few years of my life, nearly all the code I write is array programming code, even though I'm not using a purely array language.", "tokens": [9514, 411, 23486, 24657, 11, 291, 458, 11, 3094, 666, 264, 15148, 293, 550, 291, 458, 309, 311, 11, 309, 311, 1376, 85, 2270, 1858, 281, 362, 552, 1190, 322, 18407, 82, 420, 314, 8115, 82, 420, 2035, 11, 291, 458, 11, 370, 337, 264, 1036, 1326, 924, 295, 452, 993, 11, 6217, 439, 264, 3089, 286, 2464, 307, 10225, 9410, 3089, 11, 754, 1673, 286, 478, 406, 1228, 257, 17491, 10225, 2856, 13], "temperature": 0.0, "avg_logprob": -0.12787527915758964, "compression_ratio": 1.5297029702970297, "no_speech_prob": 1.6697709725121967e-05}, {"id": 143, "seek": 129356, "start": 1293.56, "end": 1297.56, "text": " All right, so where do we start now with the questions.", "tokens": [1057, 558, 11, 370, 689, 360, 321, 722, 586, 365, 264, 1651, 13], "temperature": 0.0, "avg_logprob": -0.12133087983002534, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0001632944622542709}, {"id": 144, "seek": 129356, "start": 1297.56, "end": 1311.56, "text": " I'll let Bob and Adam go first if they want. And if they if they don't have a, okay, Bob, you go ahead. I've got a quick question about, about neural networks and stuff because when I was going to university all those years ago.", "tokens": [286, 603, 718, 6085, 293, 7938, 352, 700, 498, 436, 528, 13, 400, 498, 436, 498, 436, 500, 380, 362, 257, 11, 1392, 11, 6085, 11, 291, 352, 2286, 13, 286, 600, 658, 257, 1702, 1168, 466, 11, 466, 18161, 9590, 293, 1507, 570, 562, 286, 390, 516, 281, 5454, 439, 729, 924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.12133087983002534, "compression_ratio": 1.518716577540107, "no_speech_prob": 0.0001632944622542709}, {"id": 145, "seek": 131156, "start": 1311.56, "end": 1325.56, "text": " People were talking about neural networks and then they just sort of dropped off the face and as you said around 2010 suddenly they resurfaced again. What do you think was the cause of that resurfacing was it hardware was it somebody discovered a new method or what.", "tokens": [3432, 645, 1417, 466, 18161, 9590, 293, 550, 436, 445, 1333, 295, 8119, 766, 264, 1851, 293, 382, 291, 848, 926, 9657, 5800, 436, 16042, 48691, 797, 13, 708, 360, 291, 519, 390, 264, 3082, 295, 300, 16042, 44046, 390, 309, 8837, 390, 309, 2618, 6941, 257, 777, 3170, 420, 437, 13], "temperature": 0.0, "avg_logprob": -0.1022061166309175, "compression_ratio": 1.513089005235602, "no_speech_prob": 2.2120777430245653e-05}, {"id": 146, "seek": 131156, "start": 1325.56, "end": 1327.56, "text": " Yeah, mainly hardware.", "tokens": [865, 11, 8704, 8837, 13], "temperature": 0.0, "avg_logprob": -0.1022061166309175, "compression_ratio": 1.513089005235602, "no_speech_prob": 2.2120777430245653e-05}, {"id": 147, "seek": 132756, "start": 1327.56, "end": 1343.56, "text": " So what happened was people figured out how to do GP GPU so general purpose, GPU computing. So before that I tried a few times to use GPUs with neural nets I felt like that would be the thing that GPUs were all about like creating shaders and whatever,", "tokens": [407, 437, 2011, 390, 561, 8932, 484, 577, 281, 360, 26039, 18407, 370, 2674, 4334, 11, 18407, 15866, 13, 407, 949, 300, 286, 3031, 257, 1326, 1413, 281, 764, 18407, 82, 365, 18161, 36170, 286, 2762, 411, 300, 576, 312, 264, 551, 300, 18407, 82, 645, 439, 466, 411, 4084, 5744, 433, 293, 2035, 11], "temperature": 0.0, "avg_logprob": -0.12495693918001854, "compression_ratio": 1.4911242603550297, "no_speech_prob": 6.437987849494675e-06}, {"id": 148, "seek": 134356, "start": 1343.56, "end": 1365.56, "text": " and it was a whole jargon thing I didn't even understand what was going on. So, the key thing was Nvidia coming up with this CUDA approach, which it's it's all loops, right, but it's much easier than the old way like the loops you basically, it's kind of loops", "tokens": [293, 309, 390, 257, 1379, 15181, 10660, 551, 286, 994, 380, 754, 1223, 437, 390, 516, 322, 13, 407, 11, 264, 2141, 551, 390, 46284, 1348, 493, 365, 341, 29777, 7509, 3109, 11, 597, 309, 311, 309, 311, 439, 16121, 11, 558, 11, 457, 309, 311, 709, 3571, 813, 264, 1331, 636, 411, 264, 16121, 291, 1936, 11, 309, 311, 733, 295, 16121], "temperature": 0.0, "avg_logprob": -0.12396573308688491, "compression_ratio": 1.4606741573033708, "no_speech_prob": 4.1980489186244085e-05}, {"id": 149, "seek": 136556, "start": 1365.56, "end": 1378.56, "text": " you basically say to to CUDA. This is my kernel which is the piece of code I want to basically run on each symmetric multi processing unit. And then you basically say launch a bunch of threads.", "tokens": [291, 1936, 584, 281, 281, 29777, 7509, 13, 639, 307, 452, 28256, 597, 307, 264, 2522, 295, 3089, 286, 528, 281, 1936, 1190, 322, 1184, 32330, 4825, 9007, 4985, 13, 400, 550, 291, 1936, 584, 4025, 257, 3840, 295, 19314, 13], "temperature": 0.0, "avg_logprob": -0.10094249473427827, "compression_ratio": 1.734375, "no_speech_prob": 1.833995702327229e-05}, {"id": 150, "seek": 136556, "start": 1378.56, "end": 1393.56, "text": " And it's going to call your kernel, you know, basically incrementing the x and y coordinates and passing it to your kernel or making them available to your kernel. So it's a kind of it's not exactly a loop but it's this case more like a map, I guess.", "tokens": [400, 309, 311, 516, 281, 818, 428, 28256, 11, 291, 458, 11, 1936, 26200, 278, 264, 2031, 293, 288, 21056, 293, 8437, 309, 281, 428, 28256, 420, 1455, 552, 2435, 281, 428, 28256, 13, 407, 309, 311, 257, 733, 295, 309, 311, 406, 2293, 257, 6367, 457, 309, 311, 341, 1389, 544, 411, 257, 4471, 11, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.10094249473427827, "compression_ratio": 1.734375, "no_speech_prob": 1.833995702327229e-05}, {"id": 151, "seek": 139356, "start": 1393.56, "end": 1411.56, "text": " So when CUDA appeared, very quickly, neural network libraries appeared to take advantage, appeared that would take advantage of it. And then suddenly, you know, you get orders of magnitude more performance, and it's cheaper, and you get to buy an Nvidia graphics card", "tokens": [407, 562, 29777, 7509, 8516, 11, 588, 2661, 11, 18161, 3209, 15148, 8516, 281, 747, 5002, 11, 8516, 300, 576, 747, 5002, 295, 309, 13, 400, 550, 5800, 11, 291, 458, 11, 291, 483, 9470, 295, 15668, 544, 3389, 11, 293, 309, 311, 12284, 11, 293, 291, 483, 281, 2256, 364, 46284, 11837, 2920], "temperature": 0.0, "avg_logprob": -0.11426417032877605, "compression_ratio": 1.5990990990990992, "no_speech_prob": 1.5932773749227636e-05}, {"id": 152, "seek": 139356, "start": 1411.56, "end": 1417.56, "text": " with a free copy of Batman, you know, on the excuse that actually this is all for work.", "tokens": [365, 257, 1737, 5055, 295, 15432, 11, 291, 458, 11, 322, 264, 8960, 300, 767, 341, 307, 439, 337, 589, 13], "temperature": 0.0, "avg_logprob": -0.11426417032877605, "compression_ratio": 1.5990990990990992, "no_speech_prob": 1.5932773749227636e-05}, {"id": 153, "seek": 141756, "start": 1417.56, "end": 1424.56, "text": " But it was it was mainly that there's also this just like at the same time.", "tokens": [583, 309, 390, 309, 390, 8704, 300, 456, 311, 611, 341, 445, 411, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.12537095387776692, "compression_ratio": 1.5145631067961165, "no_speech_prob": 8.266570148407482e-06}, {"id": 154, "seek": 141756, "start": 1424.56, "end": 1437.56, "text": " The thing I've been doing for 25 years, suddenly got a name, data science, you know, we like this is very small industry of people like applying data driven approaches to solving business problems.", "tokens": [440, 551, 286, 600, 668, 884, 337, 3552, 924, 11, 5800, 658, 257, 1315, 11, 1412, 3497, 11, 291, 458, 11, 321, 411, 341, 307, 588, 1359, 3518, 295, 561, 411, 9275, 1412, 9555, 11587, 281, 12606, 1606, 2740, 13], "temperature": 0.0, "avg_logprob": -0.12537095387776692, "compression_ratio": 1.5145631067961165, "no_speech_prob": 8.266570148407482e-06}, {"id": 155, "seek": 141756, "start": 1437.56, "end": 1439.56, "text": " And we were always looking for a name.", "tokens": [400, 321, 645, 1009, 1237, 337, 257, 1315, 13], "temperature": 0.0, "avg_logprob": -0.12537095387776692, "compression_ratio": 1.5145631067961165, "no_speech_prob": 8.266570148407482e-06}, {"id": 156, "seek": 143956, "start": 1439.56, "end": 1453.56, "text": " I know this but back in the very early days, there was an attempt to calling it industrial mathematics. Sometimes people would like shoehorn it into operations research or management science but that was almost exclusively optimization people", "tokens": [286, 458, 341, 457, 646, 294, 264, 588, 2440, 1708, 11, 456, 390, 364, 5217, 281, 5141, 309, 9987, 18666, 13, 4803, 561, 576, 411, 12796, 31990, 309, 666, 7705, 2132, 420, 4592, 3497, 457, 300, 390, 1920, 20638, 19618, 561], "temperature": 0.0, "avg_logprob": -0.10546707023273814, "compression_ratio": 1.6948529411764706, "no_speech_prob": 1.8338108930038288e-05}, {"id": 157, "seek": 143956, "start": 1453.56, "end": 1458.56, "text": " and specifically people focused more on linear programming approaches.", "tokens": [293, 4682, 561, 5178, 544, 322, 8213, 9410, 11587, 13], "temperature": 0.0, "avg_logprob": -0.10546707023273814, "compression_ratio": 1.6948529411764706, "no_speech_prob": 1.8338108930038288e-05}, {"id": 158, "seek": 143956, "start": 1458.56, "end": 1468.56, "text": " So yeah, once data science appeared and also like, you know, basically every company had finally built their data warehouse and the data was there.", "tokens": [407, 1338, 11, 1564, 1412, 3497, 8516, 293, 611, 411, 11, 291, 458, 11, 1936, 633, 2237, 632, 2721, 3094, 641, 1412, 22244, 293, 264, 1412, 390, 456, 13], "temperature": 0.0, "avg_logprob": -0.10546707023273814, "compression_ratio": 1.6948529411764706, "no_speech_prob": 1.8338108930038288e-05}, {"id": 159, "seek": 146856, "start": 1468.56, "end": 1479.56, "text": " So yeah, it's like a more awareness of using data to solve business problems, and for the first time availability of the hardware that we actually needed.", "tokens": [407, 1338, 11, 309, 311, 411, 257, 544, 8888, 295, 1228, 1412, 281, 5039, 1606, 2740, 11, 293, 337, 264, 700, 565, 17945, 295, 264, 8837, 300, 321, 767, 2978, 13], "temperature": 0.0, "avg_logprob": -0.14407517617208915, "compression_ratio": 1.3892215568862276, "no_speech_prob": 1.1297984201519284e-05}, {"id": 160, "seek": 146856, "start": 1479.56, "end": 1485.56, "text": " And as I say in 2012. It just it's it reached the point like it been growing.", "tokens": [400, 382, 286, 584, 294, 9125, 13, 467, 445, 309, 311, 309, 6488, 264, 935, 411, 309, 668, 4194, 13], "temperature": 0.0, "avg_logprob": -0.14407517617208915, "compression_ratio": 1.3892215568862276, "no_speech_prob": 1.1297984201519284e-05}, {"id": 161, "seek": 148556, "start": 1485.56, "end": 1498.56, "text": " Since the first neural network was built in was at 1957, I guess, that this kind of gradual rate, but once it passed human performance on some tasks.", "tokens": [4162, 264, 700, 18161, 3209, 390, 3094, 294, 390, 412, 46256, 11, 286, 2041, 11, 300, 341, 733, 295, 32890, 3314, 11, 457, 1564, 309, 4678, 1952, 3389, 322, 512, 9608, 13], "temperature": 0.0, "avg_logprob": -0.12230483079567933, "compression_ratio": 1.4479638009049773, "no_speech_prob": 1.3843993656337261e-05}, {"id": 162, "seek": 148556, "start": 1498.56, "end": 1514.56, "text": " It just kept going. And so now, in the last couple of months you know it's now like getting decent marks on MIT math tests and stuff it's it's it's an amazing trajectory.", "tokens": [467, 445, 4305, 516, 13, 400, 370, 586, 11, 294, 264, 1036, 1916, 295, 2493, 291, 458, 309, 311, 586, 411, 1242, 8681, 10640, 322, 13100, 5221, 6921, 293, 1507, 309, 311, 309, 311, 309, 311, 364, 2243, 21512, 13], "temperature": 0.0, "avg_logprob": -0.12230483079567933, "compression_ratio": 1.4479638009049773, "no_speech_prob": 1.3843993656337261e-05}, {"id": 163, "seek": 151456, "start": 1514.56, "end": 1526.56, "text": " It's kind of a critical mass kind of thing you get a certain amount of information and able to process and information. It, I guess, as you as you do with your hand it's an exponential curve.", "tokens": [467, 311, 733, 295, 257, 4924, 2758, 733, 295, 551, 291, 483, 257, 1629, 2372, 295, 1589, 293, 1075, 281, 1399, 293, 1589, 13, 467, 11, 286, 2041, 11, 382, 291, 382, 291, 360, 365, 428, 1011, 309, 311, 364, 21510, 7605, 13], "temperature": 0.0, "avg_logprob": -0.13527950487638774, "compression_ratio": 1.689119170984456, "no_speech_prob": 0.00012139769387431443}, {"id": 164, "seek": 151456, "start": 1526.56, "end": 1534.56, "text": " Yeah, humans and exponential curves I think we're finding over and over again. We're not really great at at understanding an exponent.", "tokens": [865, 11, 6255, 293, 21510, 19490, 286, 519, 321, 434, 5006, 670, 293, 670, 797, 13, 492, 434, 406, 534, 869, 412, 412, 3701, 364, 37871, 13], "temperature": 0.0, "avg_logprob": -0.13527950487638774, "compression_ratio": 1.689119170984456, "no_speech_prob": 0.00012139769387431443}, {"id": 165, "seek": 153456, "start": 1534.56, "end": 1548.56, "text": " No, we're not. And that's like why I promised myself that as soon as I saw neural nets starting to look like they're doing interesting things I would drop everything and jump on it, because I wanted to jump on that curve as early as possible.", "tokens": [883, 11, 321, 434, 406, 13, 400, 300, 311, 411, 983, 286, 10768, 2059, 300, 382, 2321, 382, 286, 1866, 18161, 36170, 2891, 281, 574, 411, 436, 434, 884, 1880, 721, 286, 576, 3270, 1203, 293, 3012, 322, 309, 11, 570, 286, 1415, 281, 3012, 322, 300, 7605, 382, 2440, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.07865098248357358, "compression_ratio": 1.6762295081967213, "no_speech_prob": 5.013932877773186e-06}, {"id": 166, "seek": 153456, "start": 1548.56, "end": 1558.56, "text": " And we're now in this situation where people are just making huge amounts of money with neural nets, which they then reinvest back into making the neural nets better.", "tokens": [400, 321, 434, 586, 294, 341, 2590, 689, 561, 366, 445, 1455, 2603, 11663, 295, 1460, 365, 18161, 36170, 11, 597, 436, 550, 6561, 5571, 646, 666, 1455, 264, 18161, 36170, 1101, 13], "temperature": 0.0, "avg_logprob": -0.07865098248357358, "compression_ratio": 1.6762295081967213, "no_speech_prob": 5.013932877773186e-06}, {"id": 167, "seek": 155856, "start": 1558.56, "end": 1576.56, "text": " And so we are also seeing this kind of bifurcation of capabilities where there's a small number of organizations who are extremely good at this stuff and invested in it and a lot of organizations that are, you know, really struggling to figure it out.", "tokens": [400, 370, 321, 366, 611, 2577, 341, 733, 295, 272, 351, 374, 46252, 295, 10862, 689, 456, 311, 257, 1359, 1230, 295, 6150, 567, 366, 4664, 665, 412, 341, 1507, 293, 13104, 294, 309, 293, 257, 688, 295, 6150, 300, 366, 11, 291, 458, 11, 534, 9314, 281, 2573, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.046220282072662024, "compression_ratio": 1.6693227091633467, "no_speech_prob": 2.710017179197166e-05}, {"id": 168, "seek": 155856, "start": 1576.56, "end": 1585.56, "text": " And because of the exponential nature when it happens it happens very quickly. It feels like you didn't see it coming and suddenly it's there and then it was past you.", "tokens": [400, 570, 295, 264, 21510, 3687, 562, 309, 2314, 309, 2314, 588, 2661, 13, 467, 3417, 411, 291, 994, 380, 536, 309, 1348, 293, 5800, 309, 311, 456, 293, 550, 309, 390, 1791, 291, 13], "temperature": 0.0, "avg_logprob": -0.046220282072662024, "compression_ratio": 1.6693227091633467, "no_speech_prob": 2.710017179197166e-05}, {"id": 169, "seek": 158556, "start": 1585.56, "end": 1594.56, "text": " I think we're all experiencing that now. Yeah, and it's happened in so many industries, you know, back in my medical startup.", "tokens": [286, 519, 321, 434, 439, 11139, 300, 586, 13, 865, 11, 293, 309, 311, 2011, 294, 370, 867, 13284, 11, 291, 458, 11, 646, 294, 452, 4625, 18578, 13], "temperature": 0.0, "avg_logprob": -0.1269170812198094, "compression_ratio": 1.4107142857142858, "no_speech_prob": 4.830346369999461e-05}, {"id": 170, "seek": 158556, "start": 1594.56, "end": 1603.56, "text": " You know, we were interviewing folks around medicines we interviewed a guy finishing his PhD in histopathology.", "tokens": [509, 458, 11, 321, 645, 26524, 4024, 926, 24251, 321, 19770, 257, 2146, 12693, 702, 14476, 294, 1758, 27212, 1793, 13], "temperature": 0.0, "avg_logprob": -0.1269170812198094, "compression_ratio": 1.4107142857142858, "no_speech_prob": 4.830346369999461e-05}, {"id": 171, "seek": 160356, "start": 1603.56, "end": 1616.56, "text": " And I remember he you know he came in to do an interview with us. And he basically gave us a presentation about his thesis on kind of graph cut segmentation approaches pathology slides.", "tokens": [400, 286, 1604, 415, 291, 458, 415, 1361, 294, 281, 360, 364, 4049, 365, 505, 13, 400, 415, 1936, 2729, 505, 257, 5860, 466, 702, 22288, 322, 733, 295, 4295, 1723, 9469, 399, 11587, 3100, 1793, 9788, 13], "temperature": 0.0, "avg_logprob": -0.09122327316639035, "compression_ratio": 1.5965665236051503, "no_speech_prob": 3.6464767617871985e-05}, {"id": 172, "seek": 160356, "start": 1616.56, "end": 1625.56, "text": " And at the end he is like anyway that was my PhD and then yesterday because I knew I was coming to see you guys and I heard you like neural nets I just thought I'd check out neural nets.", "tokens": [400, 412, 264, 917, 415, 307, 411, 4033, 300, 390, 452, 14476, 293, 550, 5186, 570, 286, 2586, 286, 390, 1348, 281, 536, 291, 1074, 293, 286, 2198, 291, 411, 18161, 36170, 286, 445, 1194, 286, 1116, 1520, 484, 18161, 36170, 13], "temperature": 0.0, "avg_logprob": -0.09122327316639035, "compression_ratio": 1.5965665236051503, "no_speech_prob": 3.6464767617871985e-05}, {"id": 173, "seek": 162556, "start": 1625.56, "end": 1635.56, "text": " And about four hours later I trained a neural net to do the same thing I did for my PhD, and it way outperformed my PhD thesis I'd spent the last five years on.", "tokens": [400, 466, 1451, 2496, 1780, 286, 8895, 257, 18161, 2533, 281, 360, 264, 912, 551, 286, 630, 337, 452, 14476, 11, 293, 309, 636, 484, 610, 22892, 452, 14476, 22288, 286, 1116, 4418, 264, 1036, 1732, 924, 322, 13], "temperature": 0.0, "avg_logprob": -0.10106880823771158, "compression_ratio": 1.4623655913978495, "no_speech_prob": 1.9830318706226535e-05}, {"id": 174, "seek": 162556, "start": 1635.56, "end": 1641.56, "text": " And so that's where I'm at, you know, and we hear this a lot.", "tokens": [400, 370, 300, 311, 689, 286, 478, 412, 11, 291, 458, 11, 293, 321, 1568, 341, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.10106880823771158, "compression_ratio": 1.4623655913978495, "no_speech_prob": 1.9830318706226535e-05}, {"id": 175, "seek": 162556, "start": 1641.56, "end": 1647.56, "text": " existential crisis in the middle of an interview.", "tokens": [37133, 5869, 294, 264, 2808, 295, 364, 4049, 13], "temperature": 0.0, "avg_logprob": -0.10106880823771158, "compression_ratio": 1.4623655913978495, "no_speech_prob": 1.9830318706226535e-05}, {"id": 176, "seek": 164756, "start": 1647.56, "end": 1656.56, "text": " So I kind of have, I don't know this is like a one, a, b and c. And I'm not sure if I should ask them all at once.", "tokens": [407, 286, 733, 295, 362, 11, 286, 500, 380, 458, 341, 307, 411, 257, 472, 11, 257, 11, 272, 293, 269, 13, 400, 286, 478, 406, 988, 498, 286, 820, 1029, 552, 439, 412, 1564, 13], "temperature": 0.0, "avg_logprob": -0.1381426525115967, "compression_ratio": 1.5798319327731092, "no_speech_prob": 1.8336915672989562e-05}, {"id": 177, "seek": 164756, "start": 1656.56, "end": 1671.56, "text": " But so you said sort of at the tail end of the 90s is when your array language journey started but it seems from the way you explained it that you had already at some point along the way heard about the array languages, APL and Jay, and have sort of alluded to,", "tokens": [583, 370, 291, 848, 1333, 295, 412, 264, 6838, 917, 295, 264, 4289, 82, 307, 562, 428, 10225, 2856, 4671, 1409, 457, 309, 2544, 490, 264, 636, 291, 8825, 309, 300, 291, 632, 1217, 412, 512, 935, 2051, 264, 636, 2198, 466, 264, 10225, 8650, 11, 5372, 43, 293, 11146, 11, 293, 362, 1333, 295, 33919, 281, 11], "temperature": 0.0, "avg_logprob": -0.1381426525115967, "compression_ratio": 1.5798319327731092, "no_speech_prob": 1.8336915672989562e-05}, {"id": 178, "seek": 167156, "start": 1671.56, "end": 1683.56, "text": " you know, picking up some knowledge about the paradigm and the languages. So, my first part of the question is sort of, you know, at what point were you exposed to the paradigm in these languages.", "tokens": [291, 458, 11, 8867, 493, 512, 3601, 466, 264, 24709, 293, 264, 8650, 13, 407, 11, 452, 700, 644, 295, 264, 1168, 307, 1333, 295, 11, 291, 458, 11, 412, 437, 935, 645, 291, 9495, 281, 264, 24709, 294, 613, 8650, 13], "temperature": 0.0, "avg_logprob": -0.07400372793089668, "compression_ratio": 1.7056603773584906, "no_speech_prob": 3.2171650673262775e-05}, {"id": 179, "seek": 167156, "start": 1683.56, "end": 1698.56, "text": " The second part is what what's causing you in 2022 to, you know, really dive into it because you said, you feel like maybe a bit of an imposter or the least qualified guest, which probably is you just being very modest I'm sure you know still quite a bit.", "tokens": [440, 1150, 644, 307, 437, 437, 311, 9853, 291, 294, 20229, 281, 11, 291, 458, 11, 534, 9192, 666, 309, 570, 291, 848, 11, 291, 841, 411, 1310, 257, 857, 295, 364, 704, 7096, 420, 264, 1935, 15904, 8341, 11, 597, 1391, 307, 291, 445, 885, 588, 25403, 286, 478, 988, 291, 458, 920, 1596, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.07400372793089668, "compression_ratio": 1.7056603773584906, "no_speech_prob": 3.2171650673262775e-05}, {"id": 180, "seek": 169856, "start": 1698.56, "end": 1712.56, "text": " So, the third part is, do you have thoughts about, and I've always sort of wondered how the array language paradigm sort of missed out on, like, and Python ended up being the main data science language.", "tokens": [407, 11, 264, 2636, 644, 307, 11, 360, 291, 362, 4598, 466, 11, 293, 286, 600, 1009, 1333, 295, 17055, 577, 264, 10225, 2856, 24709, 1333, 295, 6721, 484, 322, 11, 411, 11, 293, 15329, 4590, 493, 885, 264, 2135, 1412, 3497, 2856, 13], "temperature": 0.0, "avg_logprob": -0.09867462515830994, "compression_ratio": 1.4125874125874125, "no_speech_prob": 1.9825343770207837e-05}, {"id": 181, "seek": 171256, "start": 1712.56, "end": 1728.56, "text": " And so, while like there's like an article that's floating around online called numpy. The ghost of Iverson, which it's it's this sort of you can see that in the names and the design of the library that there is an core of APL and even the documentation acknowledges", "tokens": [400, 370, 11, 1339, 411, 456, 311, 411, 364, 7222, 300, 311, 12607, 926, 2950, 1219, 1031, 8200, 13, 440, 8359, 295, 286, 840, 266, 11, 597, 309, 311, 309, 311, 341, 1333, 295, 291, 393, 536, 300, 294, 264, 5288, 293, 264, 1715, 295, 264, 6405, 300, 456, 307, 364, 4965, 295, 5372, 43, 293, 754, 264, 14333, 15195, 2880], "temperature": 0.0, "avg_logprob": -0.1538472519707434, "compression_ratio": 1.6420233463035019, "no_speech_prob": 1.695511491561774e-05}, {"id": 182, "seek": 171256, "start": 1728.56, "end": 1739.56, "text": " that it took inspiration greatly from J and APL, but that, like the array languages clearly missed missed what was a golden opportunity for their paradigm.", "tokens": [300, 309, 1890, 10249, 14147, 490, 508, 293, 5372, 43, 11, 457, 300, 11, 411, 264, 10225, 8650, 4448, 6721, 6721, 437, 390, 257, 9729, 2650, 337, 641, 24709, 13], "temperature": 0.0, "avg_logprob": -0.1538472519707434, "compression_ratio": 1.6420233463035019, "no_speech_prob": 1.695511491561774e-05}, {"id": 183, "seek": 173956, "start": 1739.56, "end": 1746.56, "text": " And so, I'm going to go back to the question of libraries and other languages so I just asked three questions at once or feel free to tackle them in any order.", "tokens": [400, 370, 11, 286, 478, 516, 281, 352, 646, 281, 264, 1168, 295, 15148, 293, 661, 8650, 370, 286, 445, 2351, 1045, 1651, 412, 1564, 420, 841, 1737, 281, 14896, 552, 294, 604, 1668, 13], "temperature": 0.0, "avg_logprob": -0.2978445169877033, "compression_ratio": 1.611353711790393, "no_speech_prob": 1.8922863091574982e-05}, {"id": 184, "seek": 173956, "start": 1746.56, "end": 1749.56, "text": " I have a pretty bad memory so I'll.", "tokens": [286, 362, 257, 1238, 1578, 4675, 370, 286, 603, 13], "temperature": 0.0, "avg_logprob": -0.2978445169877033, "compression_ratio": 1.611353711790393, "no_speech_prob": 1.8922863091574982e-05}, {"id": 185, "seek": 173956, "start": 1749.56, "end": 1758.56, "text": " I think I've forgotten the second one already so you can feel free to come back to any or all of them. So, my journey, which is what you started with", "tokens": [286, 519, 286, 600, 11832, 264, 1150, 472, 1217, 370, 291, 393, 841, 1737, 281, 808, 646, 281, 604, 420, 439, 295, 552, 13, 407, 11, 452, 4671, 11, 597, 307, 437, 291, 1409, 365], "temperature": 0.0, "avg_logprob": -0.2978445169877033, "compression_ratio": 1.611353711790393, "no_speech_prob": 1.8922863091574982e-05}, {"id": 186, "seek": 173956, "start": 1758.56, "end": 1762.56, "text": " was.", "tokens": [390, 13], "temperature": 0.0, "avg_logprob": -0.2978445169877033, "compression_ratio": 1.611353711790393, "no_speech_prob": 1.8922863091574982e-05}, {"id": 187, "seek": 173956, "start": 1762.56, "end": 1765.56, "text": " I always felt like", "tokens": [286, 1009, 2762, 411], "temperature": 0.0, "avg_logprob": -0.2978445169877033, "compression_ratio": 1.611353711790393, "no_speech_prob": 1.8922863091574982e-05}, {"id": 188, "seek": 176556, "start": 1765.56, "end": 1778.56, "text": " I was going to be left without using code, because I, or at least like kind of traditional what I guess we'd call nowadays imperative code.", "tokens": [286, 390, 516, 281, 312, 1411, 1553, 1228, 3089, 11, 570, 286, 11, 420, 412, 1935, 411, 733, 295, 5164, 437, 286, 2041, 321, 1116, 818, 13434, 32490, 3089, 13], "temperature": 0.0, "avg_logprob": -0.2067438761393229, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8629532860359177e-05}, {"id": 189, "seek": 176556, "start": 1778.56, "end": 1791.56, "text": " I, there was a couple of tools in my early days which I've got huge amounts of leverage from because nobody else in, in, at least the consulting firms or generally in our clients knew about them.", "tokens": [286, 11, 456, 390, 257, 1916, 295, 3873, 294, 452, 2440, 1708, 597, 286, 600, 658, 2603, 11663, 295, 13982, 490, 570, 5079, 1646, 294, 11, 294, 11, 412, 1935, 264, 23682, 18055, 420, 5101, 294, 527, 6982, 2586, 466, 552, 13], "temperature": 0.0, "avg_logprob": -0.2067438761393229, "compression_ratio": 1.5654205607476634, "no_speech_prob": 1.8629532860359177e-05}, {"id": 190, "seek": 179156, "start": 1791.56, "end": 1795.56, "text": " SQL and pivot tables.", "tokens": [19200, 293, 14538, 8020, 13], "temperature": 0.0, "avg_logprob": -0.12181198353670081, "compression_ratio": 1.6891385767790261, "no_speech_prob": 2.5065322915907018e-05}, {"id": 191, "seek": 179156, "start": 1795.56, "end": 1805.56, "text": " And so pivot tables if you haven't come across it was basically the one of the earliest purchase to overlap you know slicing and dicing. There was actually something slightly earlier called Lotus improv.", "tokens": [400, 370, 14538, 8020, 498, 291, 2378, 380, 808, 2108, 309, 390, 1936, 264, 472, 295, 264, 20573, 8110, 281, 19959, 291, 458, 46586, 293, 274, 5776, 13, 821, 390, 767, 746, 4748, 3071, 1219, 44769, 29424, 13], "temperature": 0.0, "avg_logprob": -0.12181198353670081, "compression_ratio": 1.6891385767790261, "no_speech_prob": 2.5065322915907018e-05}, {"id": 192, "seek": 179156, "start": 1805.56, "end": 1816.56, "text": " But that was actually a separate product Excel was basically the first one to put our lab in the spreadsheet. So no loops, you just drag and drop the things you want to group by and you right click to choose how to summarize.", "tokens": [583, 300, 390, 767, 257, 4994, 1674, 19060, 390, 1936, 264, 700, 472, 281, 829, 527, 2715, 294, 264, 27733, 13, 407, 572, 16121, 11, 291, 445, 5286, 293, 3270, 264, 721, 291, 528, 281, 1594, 538, 293, 291, 558, 2052, 281, 2826, 577, 281, 20858, 13], "temperature": 0.0, "avg_logprob": -0.12181198353670081, "compression_ratio": 1.6891385767790261, "no_speech_prob": 2.5065322915907018e-05}, {"id": 193, "seek": 181656, "start": 1816.56, "end": 1824.56, "text": " And then you can go to SQL, you know, you declaratively say what you want to do you don't have to loop through things.", "tokens": [400, 550, 291, 393, 352, 281, 19200, 11, 291, 458, 11, 291, 16694, 19020, 584, 437, 291, 528, 281, 360, 291, 500, 380, 362, 281, 6367, 807, 721, 13], "temperature": 0.0, "avg_logprob": -0.2201478746202257, "compression_ratio": 1.5742574257425743, "no_speech_prob": 1.6961743313004263e-05}, {"id": 194, "seek": 181656, "start": 1824.56, "end": 1832.56, "text": " SAS actually had something similar, you know with SAS you could basically declare a prop that would run on your data.", "tokens": [33441, 767, 632, 746, 2531, 11, 291, 458, 365, 33441, 291, 727, 1936, 19710, 257, 2365, 300, 576, 1190, 322, 428, 1412, 13], "temperature": 0.0, "avg_logprob": -0.2201478746202257, "compression_ratio": 1.5742574257425743, "no_speech_prob": 1.6961743313004263e-05}, {"id": 195, "seek": 181656, "start": 1832.56, "end": 1840.56, "text": " So yeah, I kind of felt like this was the way I would rather do stuff if I could.", "tokens": [407, 1338, 11, 286, 733, 295, 2762, 411, 341, 390, 264, 636, 286, 576, 2831, 360, 1507, 498, 286, 727, 13], "temperature": 0.0, "avg_logprob": -0.2201478746202257, "compression_ratio": 1.5742574257425743, "no_speech_prob": 1.6961743313004263e-05}, {"id": 196, "seek": 184056, "start": 1840.56, "end": 1851.56, "text": " I was always out of doing the C++ implementation of the insurance pricing stuff of being much more drawn to these meta programming approaches.", "tokens": [286, 390, 1009, 484, 295, 884, 264, 383, 25472, 11420, 295, 264, 7214, 17621, 1507, 295, 885, 709, 544, 10117, 281, 613, 19616, 9410, 11587, 13], "temperature": 0.0, "avg_logprob": -0.13628893220022822, "compression_ratio": 1.584033613445378, "no_speech_prob": 4.068481575814076e-05}, {"id": 197, "seek": 184056, "start": 1851.56, "end": 1869.56, "text": " I just didn't want to be writing loops in loops and dealing with all that stuff just, I'm too lazy, you know, to do that. I think I'm very driven by laziness, which is Larry Wall said is one of the three virtues of a great programmer.", "tokens": [286, 445, 994, 380, 528, 281, 312, 3579, 16121, 294, 16121, 293, 6260, 365, 439, 300, 1507, 445, 11, 286, 478, 886, 14847, 11, 291, 458, 11, 281, 360, 300, 13, 286, 519, 286, 478, 588, 9555, 538, 19320, 1324, 11, 597, 307, 18145, 9551, 848, 307, 472, 295, 264, 1045, 41106, 295, 257, 869, 32116, 13], "temperature": 0.0, "avg_logprob": -0.13628893220022822, "compression_ratio": 1.584033613445378, "no_speech_prob": 4.068481575814076e-05}, {"id": 198, "seek": 186956, "start": 1869.56, "end": 1888.56, "text": " Then, yeah, so I think when, as soon as I saw NumPy had reached a level of some reasonable confidence in Python, I was very drawn to that because that's what I've been looking for.", "tokens": [1396, 11, 1338, 11, 370, 286, 519, 562, 11, 382, 2321, 382, 286, 1866, 22592, 47, 88, 632, 6488, 257, 1496, 295, 512, 10585, 6687, 294, 15329, 11, 286, 390, 588, 10117, 281, 300, 570, 300, 311, 437, 286, 600, 668, 1237, 337, 13], "temperature": 0.0, "avg_logprob": -0.11701981008869328, "compression_ratio": 1.4827586206896552, "no_speech_prob": 3.7044370401417837e-05}, {"id": 199, "seek": 186956, "start": 1888.56, "end": 1896.56, "text": " And I think maybe that actually is going to bring us to answering the question of like what happened to array languages.", "tokens": [400, 286, 519, 1310, 300, 767, 307, 516, 281, 1565, 505, 281, 13430, 264, 1168, 295, 411, 437, 2011, 281, 10225, 8650, 13], "temperature": 0.0, "avg_logprob": -0.11701981008869328, "compression_ratio": 1.4827586206896552, "no_speech_prob": 3.7044370401417837e-05}, {"id": 200, "seek": 189656, "start": 1896.56, "end": 1906.56, "text": " Python has a lot of problems, but at its heart, it's a very well designed language. It has a very small flexible core.", "tokens": [15329, 575, 257, 688, 295, 2740, 11, 457, 412, 1080, 1917, 11, 309, 311, 257, 588, 731, 4761, 2856, 13, 467, 575, 257, 588, 1359, 11358, 4965, 13], "temperature": 0.0, "avg_logprob": -0.15001781170184797, "compression_ratio": 1.628099173553719, "no_speech_prob": 5.827374116051942e-05}, {"id": 201, "seek": 189656, "start": 1906.56, "end": 1925.56, "text": " Personally, I don't like the way most people write it, but I've been so flexible I've able to create almost my own version of Python, which is very functionally oriented, I basically have stolen the type dispatch ideas from Julia, created an implementation of that in Python.", "tokens": [21079, 11, 286, 500, 380, 411, 264, 636, 881, 561, 2464, 309, 11, 457, 286, 600, 668, 370, 11358, 286, 600, 1075, 281, 1884, 1920, 452, 1065, 3037, 295, 15329, 11, 597, 307, 588, 2445, 379, 21841, 11, 286, 1936, 362, 15900, 264, 2010, 36729, 3487, 490, 18551, 11, 2942, 364, 11420, 295, 300, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.15001781170184797, "compression_ratio": 1.628099173553719, "no_speech_prob": 5.827374116051942e-05}, {"id": 202, "seek": 192556, "start": 1925.56, "end": 1934.56, "text": " So I you know my Python code doesn't look like most Python code, but I can use all the stuff that's that's in Python.", "tokens": [407, 286, 291, 458, 452, 15329, 3089, 1177, 380, 574, 411, 881, 15329, 3089, 11, 457, 286, 393, 764, 439, 264, 1507, 300, 311, 300, 311, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.09921089621151195, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.663115295348689e-06}, {"id": 203, "seek": 192556, "start": 1934.56, "end": 1951.56, "text": " So this is very nicely designed core of a language, which I then have this almost this DSL on top of, you know, NumPy is able to create this kind of DSL again because it's working on such a flexible foundation.", "tokens": [407, 341, 307, 588, 9594, 4761, 4965, 295, 257, 2856, 11, 597, 286, 550, 362, 341, 1920, 341, 15816, 43, 322, 1192, 295, 11, 291, 458, 11, 22592, 47, 88, 307, 1075, 281, 1884, 341, 733, 295, 15816, 43, 797, 570, 309, 311, 1364, 322, 1270, 257, 11358, 7030, 13], "temperature": 0.0, "avg_logprob": -0.09921089621151195, "compression_ratio": 1.539906103286385, "no_speech_prob": 8.663115295348689e-06}, {"id": 204, "seek": 195156, "start": 1951.56, "end": 1968.56, "text": " Ideally, you know, I mean, it will okay so Python also has another DSL built into it which is math, you know, I can use the operators plus times minus that's that's convenient and in every array library, NumPy, PyTorch, TensorFlow and Python, those operators work", "tokens": [40817, 11, 291, 458, 11, 286, 914, 11, 309, 486, 1392, 370, 15329, 611, 575, 1071, 15816, 43, 3094, 666, 309, 597, 307, 5221, 11, 291, 458, 11, 286, 393, 764, 264, 19077, 1804, 1413, 3175, 300, 311, 300, 311, 10851, 293, 294, 633, 10225, 6405, 11, 22592, 47, 88, 11, 9953, 51, 284, 339, 11, 37624, 293, 15329, 11, 729, 19077, 589], "temperature": 0.0, "avg_logprob": -0.17943272732272006, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.1109450244694017e-05}, {"id": 205, "seek": 195156, "start": 1968.56, "end": 1978.56, "text": " over arrays and do broadcasting over axes and so forth and, you know, accelerate on an accelerator, like a GPU or TPU. That's all great.", "tokens": [670, 41011, 293, 360, 30024, 670, 35387, 293, 370, 5220, 293, 11, 291, 458, 11, 21341, 322, 364, 39889, 11, 411, 257, 18407, 420, 314, 8115, 13, 663, 311, 439, 869, 13], "temperature": 0.0, "avg_logprob": -0.17943272732272006, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.1109450244694017e-05}, {"id": 206, "seek": 197856, "start": 1978.56, "end": 1987.56, "text": " I, you know, my ideal world would be that I wouldn't just get to use plus times minus but I get to use all the APL symbols.", "tokens": [286, 11, 291, 458, 11, 452, 7157, 1002, 576, 312, 300, 286, 2759, 380, 445, 483, 281, 764, 1804, 1413, 3175, 457, 286, 483, 281, 764, 439, 264, 5372, 43, 16944, 13], "temperature": 0.0, "avg_logprob": -0.12639255523681642, "compression_ratio": 1.4132231404958677, "no_speech_prob": 1.0951125659630634e-05}, {"id": 207, "seek": 197856, "start": 1987.56, "end": 1990.56, "text": " You know, that would be, that would be amazing.", "tokens": [509, 458, 11, 300, 576, 312, 11, 300, 576, 312, 2243, 13], "temperature": 0.0, "avg_logprob": -0.12639255523681642, "compression_ratio": 1.4132231404958677, "no_speech_prob": 1.0951125659630634e-05}, {"id": 208, "seek": 199056, "start": 1990.56, "end": 2012.56, "text": " But given a choice between a really beautiful language, you know, at its core like Python, in which I can then add a slightly cobbled together DSL like NumPy, I would much prefer that over a really beautiful notation like APL, but without the fantastic language underneath,", "tokens": [583, 2212, 257, 3922, 1296, 257, 534, 2238, 2856, 11, 291, 458, 11, 412, 1080, 4965, 411, 15329, 11, 294, 597, 286, 393, 550, 909, 257, 4748, 598, 6692, 1493, 1214, 15816, 43, 411, 22592, 47, 88, 11, 286, 576, 709, 4382, 300, 670, 257, 534, 2238, 24657, 411, 5372, 43, 11, 457, 1553, 264, 5456, 2856, 7223, 11], "temperature": 0.0, "avg_logprob": -0.07991594738430446, "compression_ratio": 1.4598930481283423, "no_speech_prob": 1.0781769560708199e-05}, {"id": 209, "seek": 201256, "start": 2012.56, "end": 2035.56, "text": " you know, like I don't feel like I, there's nothing about APL or JP or J or K's like programming language that attracts me, you know what I mean, I feel like in terms of like what I could do around, around whether it be type dispatch or how OO is designed, or,", "tokens": [291, 458, 11, 411, 286, 500, 380, 841, 411, 286, 11, 456, 311, 1825, 466, 5372, 43, 420, 34336, 420, 508, 420, 591, 311, 411, 9410, 2856, 300, 37026, 385, 11, 291, 458, 437, 286, 914, 11, 286, 841, 411, 294, 2115, 295, 411, 437, 286, 727, 360, 926, 11, 926, 1968, 309, 312, 2010, 36729, 420, 577, 422, 46, 307, 4761, 11, 420, 11], "temperature": 0.0, "avg_logprob": -0.21273982006570566, "compression_ratio": 1.5204678362573099, "no_speech_prob": 1.2605526535480749e-05}, {"id": 210, "seek": 203556, "start": 2035.56, "end": 2042.56, "text": " you know, how I package modules or almost anything else I would prefer the Python way.", "tokens": [291, 458, 11, 577, 286, 7372, 16679, 420, 1920, 1340, 1646, 286, 576, 4382, 264, 15329, 636, 13], "temperature": 0.0, "avg_logprob": -0.09203753600249419, "compression_ratio": 1.5735294117647058, "no_speech_prob": 8.663831067678984e-06}, {"id": 211, "seek": 203556, "start": 2042.56, "end": 2060.56, "text": " So I feel like that's, that's basically what we've ended up with you kind of either compromise between, you know, a good language with, you know, slightly substandard notation or amazingly great notation with the substandard language,", "tokens": [407, 286, 841, 411, 300, 311, 11, 300, 311, 1936, 437, 321, 600, 4590, 493, 365, 291, 733, 295, 2139, 18577, 1296, 11, 291, 458, 11, 257, 665, 2856, 365, 11, 291, 458, 11, 4748, 1422, 1115, 515, 24657, 420, 31762, 869, 24657, 365, 264, 1422, 1115, 515, 2856, 11], "temperature": 0.0, "avg_logprob": -0.09203753600249419, "compression_ratio": 1.5735294117647058, "no_speech_prob": 8.663831067678984e-06}, {"id": 212, "seek": 206056, "start": 2060.56, "end": 2065.56, "text": " not just language but ecosystem.", "tokens": [406, 445, 2856, 457, 11311, 13], "temperature": 0.0, "avg_logprob": -0.231565232370414, "compression_ratio": 1.3357142857142856, "no_speech_prob": 1.2409385817591101e-05}, {"id": 213, "seek": 206056, "start": 2065.56, "end": 2081.56, "text": " I think, I hope one day we'll get the best of both. Right. Like, here's my. Okay, here's my controversial take it may just represent my lack of knowledge.", "tokens": [286, 519, 11, 286, 1454, 472, 786, 321, 603, 483, 264, 1151, 295, 1293, 13, 1779, 13, 1743, 11, 510, 311, 452, 13, 1033, 11, 510, 311, 452, 17323, 747, 309, 815, 445, 2906, 452, 5011, 295, 3601, 13], "temperature": 0.0, "avg_logprob": -0.231565232370414, "compression_ratio": 1.3357142857142856, "no_speech_prob": 1.2409385817591101e-05}, {"id": 214, "seek": 208156, "start": 2081.56, "end": 2092.56, "text": " What I like about APL is its notation. I think it's a, it's a beautiful notation I don't think it's a beautiful programming language.", "tokens": [708, 286, 411, 466, 5372, 43, 307, 1080, 24657, 13, 286, 519, 309, 311, 257, 11, 309, 311, 257, 2238, 24657, 286, 500, 380, 519, 309, 311, 257, 2238, 9410, 2856, 13], "temperature": 0.0, "avg_logprob": -0.11341499460154567, "compression_ratio": 1.5874125874125875, "no_speech_prob": 1.520229852758348e-05}, {"id": 215, "seek": 208156, "start": 2092.56, "end": 2100.56, "text": " I think some things, possibly everything, you know, some things work very well as a notation.", "tokens": [286, 519, 512, 721, 11, 6264, 1203, 11, 291, 458, 11, 512, 721, 589, 588, 731, 382, 257, 24657, 13], "temperature": 0.0, "avg_logprob": -0.11341499460154567, "compression_ratio": 1.5874125874125875, "no_speech_prob": 1.520229852758348e-05}, {"id": 216, "seek": 210056, "start": 2100.56, "end": 2118.56, "text": " But to get to get to raise something to the point that it is a notation requires some years of study and development, and often some genius, you know, like the genius of Feynman diagrams, or the genius of juggling notation, you know, like,", "tokens": [583, 281, 483, 281, 483, 281, 5300, 746, 281, 264, 935, 300, 309, 307, 257, 24657, 7029, 512, 924, 295, 2979, 293, 3250, 11, 293, 2049, 512, 14017, 11, 291, 458, 11, 411, 264, 14017, 295, 46530, 77, 1601, 36709, 11, 420, 264, 14017, 295, 361, 29921, 24657, 11, 291, 458, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.08493809042305782, "compression_ratio": 1.6482758620689655, "no_speech_prob": 9.078481525648385e-06}, {"id": 217, "seek": 211856, "start": 2118.56, "end": 2130.56, "text": " there are people who, who find a way to turn a field into a notation, and suddenly they blow that field apart and make it better for everybody.", "tokens": [456, 366, 561, 567, 11, 567, 915, 257, 636, 281, 1261, 257, 2519, 666, 257, 24657, 11, 293, 5800, 436, 6327, 300, 2519, 4936, 293, 652, 309, 1101, 337, 2201, 13], "temperature": 0.0, "avg_logprob": -0.09146913340393927, "compression_ratio": 1.5792349726775956, "no_speech_prob": 6.961252438486554e-06}, {"id": 218, "seek": 211856, "start": 2130.56, "end": 2140.56, "text": " For me, like, I don't want to think too hard all the time. Every time I come across something that really hasn't been turned into a notation yet.", "tokens": [1171, 385, 11, 411, 11, 286, 500, 380, 528, 281, 519, 886, 1152, 439, 264, 565, 13, 2048, 565, 286, 808, 2108, 746, 300, 534, 6132, 380, 668, 3574, 666, 257, 24657, 1939, 13], "temperature": 0.0, "avg_logprob": -0.09146913340393927, "compression_ratio": 1.5792349726775956, "no_speech_prob": 6.961252438486554e-06}, {"id": 219, "seek": 214056, "start": 2140.56, "end": 2158.56, "text": " I just like, I just want to get it done, you know, and so I would rather only use notation. When I'm in these fields that either somebody else had figured out how to make that a notation, or I feel like it's really worth be investing to figure that out.", "tokens": [286, 445, 411, 11, 286, 445, 528, 281, 483, 309, 1096, 11, 291, 458, 11, 293, 370, 286, 576, 2831, 787, 764, 24657, 13, 1133, 286, 478, 294, 613, 7909, 300, 2139, 2618, 1646, 632, 8932, 484, 577, 281, 652, 300, 257, 24657, 11, 420, 286, 841, 411, 309, 311, 534, 3163, 312, 10978, 281, 2573, 300, 484, 13], "temperature": 0.0, "avg_logprob": -0.12654801777430943, "compression_ratio": 1.5149700598802396, "no_speech_prob": 5.421831247076625e-06}, {"id": 220, "seek": 215856, "start": 2158.56, "end": 2174.56, "text": " Otherwise, you know, there are, and the other thing I'd say is we already have notations for things that aren't APL that actually work really well, like regular expressions, for example, that's, that's a fantastic notation, and I don't want to replace that", "tokens": [10328, 11, 291, 458, 11, 456, 366, 11, 293, 264, 661, 551, 286, 1116, 584, 307, 321, 1217, 362, 406, 763, 337, 721, 300, 3212, 380, 5372, 43, 300, 767, 589, 534, 731, 11, 411, 3890, 15277, 11, 337, 1365, 11, 300, 311, 11, 300, 311, 257, 5456, 24657, 11, 293, 286, 500, 380, 528, 281, 7406, 300], "temperature": 0.0, "avg_logprob": -0.09588906734804564, "compression_ratio": 1.6473684210526316, "no_speech_prob": 5.68194536754163e-06}, {"id": 221, "seek": 215856, "start": 2174.56, "end": 2180.56, "text": " with APL glyphs, I just want to use regular expressions.", "tokens": [365, 5372, 43, 22633, 950, 82, 11, 286, 445, 528, 281, 764, 3890, 15277, 13], "temperature": 0.0, "avg_logprob": -0.09588906734804564, "compression_ratio": 1.6473684210526316, "no_speech_prob": 5.68194536754163e-06}, {"id": 222, "seek": 218056, "start": 2180.56, "end": 2198.56, "text": " So yeah, my ideal world would be one where we, where I can write pytorch code, but maybe instead of like Einstein operations, Einstein notation, I could use APL notation.", "tokens": [407, 1338, 11, 452, 7157, 1002, 576, 312, 472, 689, 321, 11, 689, 286, 393, 2464, 25878, 284, 339, 3089, 11, 457, 1310, 2602, 295, 411, 23486, 7705, 11, 23486, 24657, 11, 286, 727, 764, 5372, 43, 24657, 13], "temperature": 0.0, "avg_logprob": -0.09798176344050917, "compression_ratio": 1.36, "no_speech_prob": 4.936106506647775e-06}, {"id": 223, "seek": 219856, "start": 2198.56, "end": 2212.56, "text": " I think that's where I would love to get to one day and I would love that to totally transparently run on a GPU or TPU as well. That would be my happy place.", "tokens": [286, 519, 300, 311, 689, 286, 576, 959, 281, 483, 281, 472, 786, 293, 286, 576, 959, 300, 281, 3879, 7132, 6420, 1190, 322, 257, 18407, 420, 314, 8115, 382, 731, 13, 663, 576, 312, 452, 2055, 1081, 13], "temperature": 0.0, "avg_logprob": -0.14855586650759675, "compression_ratio": 1.3305084745762712, "no_speech_prob": 1.544457336422056e-05}, {"id": 224, "seek": 221256, "start": 2212.56, "end": 2229.56, "text": " It has no reason to do with the fact that I work in Nvidia that I would love that. But interesting, I've never heard that before the difference between basically appreciating or being in love with the notation but not the language itself.", "tokens": [467, 575, 572, 1778, 281, 360, 365, 264, 1186, 300, 286, 589, 294, 46284, 300, 286, 576, 959, 300, 13, 583, 1880, 11, 286, 600, 1128, 2198, 300, 949, 264, 2649, 1296, 1936, 3616, 990, 420, 885, 294, 959, 365, 264, 24657, 457, 406, 264, 2856, 2564, 13], "temperature": 0.0, "avg_logprob": -0.1903379697066087, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.777660691004712e-05}, {"id": 225, "seek": 222956, "start": 2229.56, "end": 2247.56, "text": " I've never heard that. I know it started out as a notation right like I was in talk, you know, it was a notation they used for representing state machines whatever on the early IBM hardware, you know, when he did his Turing Award essay he chose to talk about", "tokens": [286, 600, 1128, 2198, 300, 13, 286, 458, 309, 1409, 484, 382, 257, 24657, 558, 411, 286, 390, 294, 751, 11, 291, 458, 11, 309, 390, 257, 24657, 436, 1143, 337, 13460, 1785, 8379, 2035, 322, 264, 2440, 23487, 8837, 11, 291, 458, 11, 562, 415, 630, 702, 314, 1345, 13894, 16238, 415, 5111, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.21884442820693506, "compression_ratio": 1.5454545454545454, "no_speech_prob": 3.7263600916048745e-06}, {"id": 226, "seek": 222956, "start": 2247.56, "end": 2251.56, "text": " his notation.", "tokens": [702, 24657, 13], "temperature": 0.0, "avg_logprob": -0.21884442820693506, "compression_ratio": 1.5454545454545454, "no_speech_prob": 3.7263600916048745e-06}, {"id": 227, "seek": 225156, "start": 2251.56, "end": 2269.56, "text": " And I've seen with people like, like, like Aaron, with, with his code defense stuff that if you take a very smart person and give them a few years, they can use that notation to solve incredibly challenging problems like build a compiler and do it better", "tokens": [400, 286, 600, 1612, 365, 561, 411, 11, 411, 11, 411, 14018, 11, 365, 11, 365, 702, 3089, 7654, 1507, 300, 498, 291, 747, 257, 588, 4069, 954, 293, 976, 552, 257, 1326, 924, 11, 436, 393, 764, 300, 24657, 281, 5039, 6252, 7595, 2740, 411, 1322, 257, 31958, 293, 360, 309, 1101], "temperature": 0.0, "avg_logprob": -0.19736083348592123, "compression_ratio": 1.5591397849462365, "no_speech_prob": 2.3685522592131747e-06}, {"id": 228, "seek": 225156, "start": 2269.56, "end": 2274.56, "text": " than you can without that notation.", "tokens": [813, 291, 393, 1553, 300, 24657, 13], "temperature": 0.0, "avg_logprob": -0.19736083348592123, "compression_ratio": 1.5591397849462365, "no_speech_prob": 2.3685522592131747e-06}, {"id": 229, "seek": 227456, "start": 2274.56, "end": 2291.56, "text": " And I think like, yeah, a PL can't be used for almost anything you want to use it for but a lot of the time we don't have five years to study something very closely, we just want to, you know, we've got to get something done by tomorrow.", "tokens": [400, 286, 519, 411, 11, 1338, 11, 257, 6999, 393, 380, 312, 1143, 337, 1920, 1340, 291, 528, 281, 764, 309, 337, 457, 257, 688, 295, 264, 565, 321, 500, 380, 362, 1732, 924, 281, 2979, 746, 588, 8185, 11, 321, 445, 528, 281, 11, 291, 458, 11, 321, 600, 658, 281, 483, 746, 1096, 538, 4153, 13], "temperature": 0.0, "avg_logprob": -0.23118476112290184, "compression_ratio": 1.6444444444444444, "no_speech_prob": 7.766271664877422e-06}, {"id": 230, "seek": 227456, "start": 2291.56, "end": 2292.56, "text": " Interesting.", "tokens": [14711, 13], "temperature": 0.0, "avg_logprob": -0.23118476112290184, "compression_ratio": 1.6444444444444444, "no_speech_prob": 7.766271664877422e-06}, {"id": 231, "seek": 227456, "start": 2292.56, "end": 2302.56, "text": " We still didn't get a answer to. Oh yeah, when did you first, when did you first meet a PL, how did you even find a PL.", "tokens": [492, 920, 994, 380, 483, 257, 1867, 281, 13, 876, 1338, 11, 562, 630, 291, 700, 11, 562, 630, 291, 700, 1677, 257, 6999, 11, 577, 630, 291, 754, 915, 257, 6999, 13], "temperature": 0.0, "avg_logprob": -0.23118476112290184, "compression_ratio": 1.6444444444444444, "no_speech_prob": 7.766271664877422e-06}, {"id": 232, "seek": 230256, "start": 2302.56, "end": 2308.56, "text": " I first found J, I think,", "tokens": [286, 700, 1352, 508, 11, 286, 519, 11], "temperature": 0.0, "avg_logprob": -0.12223201049001593, "compression_ratio": 1.2116788321167884, "no_speech_prob": 4.329334478825331e-05}, {"id": 233, "seek": 230256, "start": 2308.56, "end": 2315.56, "text": " which obviously led me to a PL, and I don't quite remember where I saw it.", "tokens": [597, 2745, 4684, 385, 281, 257, 6999, 11, 293, 286, 500, 380, 1596, 1604, 689, 286, 1866, 309, 13], "temperature": 0.0, "avg_logprob": -0.12223201049001593, "compression_ratio": 1.2116788321167884, "no_speech_prob": 4.329334478825331e-05}, {"id": 234, "seek": 230256, "start": 2315.56, "end": 2317.56, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.12223201049001593, "compression_ratio": 1.2116788321167884, "no_speech_prob": 4.329334478825331e-05}, {"id": 235, "seek": 230256, "start": 2317.56, "end": 2320.56, "text": " And actually,", "tokens": [400, 767, 11], "temperature": 0.0, "avg_logprob": -0.12223201049001593, "compression_ratio": 1.2116788321167884, "no_speech_prob": 4.329334478825331e-05}, {"id": 236, "seek": 230256, "start": 2320.56, "end": 2323.56, "text": " when I got to San Francisco.", "tokens": [562, 286, 658, 281, 5271, 12279, 13], "temperature": 0.0, "avg_logprob": -0.12223201049001593, "compression_ratio": 1.2116788321167884, "no_speech_prob": 4.329334478825331e-05}, {"id": 237, "seek": 230256, "start": 2323.56, "end": 2325.56, "text": " So that would be", "tokens": [407, 300, 576, 312], "temperature": 0.0, "avg_logprob": -0.12223201049001593, "compression_ratio": 1.2116788321167884, "no_speech_prob": 4.329334478825331e-05}, {"id": 238, "seek": 232556, "start": 2325.56, "end": 2332.56, "text": " I don't remember 2010 or something I'm not sure.", "tokens": [286, 500, 380, 1604, 9657, 420, 746, 286, 478, 406, 988, 13], "temperature": 0.0, "avg_logprob": -0.14303135545286413, "compression_ratio": 1.446078431372549, "no_speech_prob": 1.1475627616164275e-05}, {"id": 239, "seek": 232556, "start": 2332.56, "end": 2346.56, "text": " I actually reached out to Eric Iverson and I said like, Oh, we're starting this machine learning company called Kaggle and I kind of feel like, you know, everybody does stuff in Python and it's kind of in a lot of ways really disappointing I wish", "tokens": [286, 767, 6488, 484, 281, 9336, 286, 840, 266, 293, 286, 848, 411, 11, 876, 11, 321, 434, 2891, 341, 3479, 2539, 2237, 1219, 48751, 22631, 293, 286, 733, 295, 841, 411, 11, 291, 458, 11, 2201, 775, 1507, 294, 15329, 293, 309, 311, 733, 295, 294, 257, 688, 295, 2098, 534, 25054, 286, 3172], "temperature": 0.0, "avg_logprob": -0.14303135545286413, "compression_ratio": 1.446078431372549, "no_speech_prob": 1.1475627616164275e-05}, {"id": 240, "seek": 234656, "start": 2346.56, "end": 2359.56, "text": " we were doing stuff in J, you know, but we really need everything to be running on the GPU or at least everything to be automatically using SIMD and multi processor everywhere.", "tokens": [321, 645, 884, 1507, 294, 508, 11, 291, 458, 11, 457, 321, 534, 643, 1203, 281, 312, 2614, 322, 264, 18407, 420, 412, 1935, 1203, 281, 312, 6772, 1228, 24738, 35, 293, 4825, 15321, 5315, 13], "temperature": 0.0, "avg_logprob": -0.1728740171952681, "compression_ratio": 1.6322869955156951, "no_speech_prob": 1.3841957297699992e-05}, {"id": 241, "seek": 234656, "start": 2359.56, "end": 2368.56, "text": " He was kind enough to actually jump on a Skype call with me, not just jump on a Skype call, but it's like, how do you want to chat and say, how about Skype and he created a Skype account.", "tokens": [634, 390, 733, 1547, 281, 767, 3012, 322, 257, 31743, 818, 365, 385, 11, 406, 445, 3012, 322, 257, 31743, 818, 11, 457, 309, 311, 411, 11, 577, 360, 291, 528, 281, 5081, 293, 584, 11, 577, 466, 31743, 293, 415, 2942, 257, 31743, 2696, 13], "temperature": 0.0, "avg_logprob": -0.1728740171952681, "compression_ratio": 1.6322869955156951, "no_speech_prob": 1.3841957297699992e-05}, {"id": 242, "seek": 236856, "start": 2368.56, "end": 2379.56, "text": " Yeah, we chatted for quite a while. We talked about, you know, these, these, these kinds of hopes and", "tokens": [865, 11, 321, 417, 32509, 337, 1596, 257, 1339, 13, 492, 2825, 466, 11, 291, 458, 11, 613, 11, 613, 11, 613, 3685, 295, 13681, 293], "temperature": 0.0, "avg_logprob": -0.1565283354338225, "compression_ratio": 1.6547619047619047, "no_speech_prob": 5.506538400368299e-06}, {"id": 243, "seek": 236856, "start": 2379.56, "end": 2387.56, "text": " yeah, but I just, you know, never really because because neither J or APL is in that space yet.", "tokens": [1338, 11, 457, 286, 445, 11, 291, 458, 11, 1128, 534, 570, 570, 9662, 508, 420, 5372, 43, 307, 294, 300, 1901, 1939, 13], "temperature": 0.0, "avg_logprob": -0.1565283354338225, "compression_ratio": 1.6547619047619047, "no_speech_prob": 5.506538400368299e-06}, {"id": 244, "seek": 236856, "start": 2387.56, "end": 2397.56, "text": " There was just never a reason for me to do anything other than like, I kind of felt like each time I'd have a bit of a break for a couple of months I'd always spend a couple of weeks fiddling around with J just for fun.", "tokens": [821, 390, 445, 1128, 257, 1778, 337, 385, 281, 360, 1340, 661, 813, 411, 11, 286, 733, 295, 2762, 411, 1184, 565, 286, 1116, 362, 257, 857, 295, 257, 1821, 337, 257, 1916, 295, 2493, 286, 1116, 1009, 3496, 257, 1916, 295, 3259, 283, 14273, 1688, 926, 365, 508, 445, 337, 1019, 13], "temperature": 0.0, "avg_logprob": -0.1565283354338225, "compression_ratio": 1.6547619047619047, "no_speech_prob": 5.506538400368299e-06}, {"id": 245, "seek": 239756, "start": 2397.56, "end": 2402.56, "text": " But that's, that's as far as I got really.", "tokens": [583, 300, 311, 11, 300, 311, 382, 1400, 382, 286, 658, 534, 13], "temperature": 0.0, "avg_logprob": -0.13139354421737345, "compression_ratio": 1.5486725663716814, "no_speech_prob": 1.5443818483618088e-05}, {"id": 246, "seek": 239756, "start": 2402.56, "end": 2411.56, "text": " Yeah, I think the first time I'd heard of you was in an interview that Leo Laporte did with you on triangulation and you were talking about Kaggle. That was a specific thing.", "tokens": [865, 11, 286, 519, 264, 700, 565, 286, 1116, 2198, 295, 291, 390, 294, 364, 4049, 300, 19344, 42498, 12752, 630, 365, 291, 322, 19335, 2776, 293, 291, 645, 1417, 466, 48751, 22631, 13, 663, 390, 257, 2685, 551, 13], "temperature": 0.0, "avg_logprob": -0.13139354421737345, "compression_ratio": 1.5486725663716814, "no_speech_prob": 1.5443818483618088e-05}, {"id": 247, "seek": 239756, "start": 2411.56, "end": 2417.56, "text": " But I think I was riding my bike along some logging or something and suddenly he said, Oh yeah, but a lot of people use J. I like J.", "tokens": [583, 286, 519, 286, 390, 9546, 452, 5656, 2051, 512, 27991, 420, 746, 293, 5800, 415, 848, 11, 876, 1338, 11, 457, 257, 688, 295, 561, 764, 508, 13, 286, 411, 508, 13], "temperature": 0.0, "avg_logprob": -0.13139354421737345, "compression_ratio": 1.5486725663716814, "no_speech_prob": 1.5443818483618088e-05}, {"id": 248, "seek": 241756, "start": 2417.56, "end": 2430.56, "text": " It's the first time I'd ever heard anybody on a podcast say anything about J. It was just like, wow, that's amazing. I didn't know what, you know, like, and, and the whole interview about Kaggle.", "tokens": [467, 311, 264, 700, 565, 286, 1116, 1562, 2198, 4472, 322, 257, 7367, 584, 1340, 466, 508, 13, 467, 390, 445, 411, 11, 6076, 11, 300, 311, 2243, 13, 286, 994, 380, 458, 437, 11, 291, 458, 11, 411, 11, 293, 11, 293, 264, 1379, 4049, 466, 48751, 22631, 13], "temperature": 0.0, "avg_logprob": -0.10291299512309413, "compression_ratio": 1.6177777777777778, "no_speech_prob": 2.0455190679058433e-05}, {"id": 249, "seek": 241756, "start": 2430.56, "end": 2440.56, "text": " There was so much of it about the importance of data processing, not just having a lot of data, but you know how to filter it down, not over filtering all those tricks.", "tokens": [821, 390, 370, 709, 295, 309, 466, 264, 7379, 295, 1412, 9007, 11, 406, 445, 1419, 257, 688, 295, 1412, 11, 457, 291, 458, 577, 281, 6608, 309, 760, 11, 406, 670, 30822, 439, 729, 11733, 13], "temperature": 0.0, "avg_logprob": -0.10291299512309413, "compression_ratio": 1.6177777777777778, "no_speech_prob": 2.0455190679058433e-05}, {"id": 250, "seek": 244056, "start": 2440.56, "end": 2460.56, "text": " I'm thinking, wow, these guys really doing some deep stuff with this stuff and this guy is using J. I was actually very surprised at that point that somebody, I guess not somebody who was working so much with data would know about J, but just that it would be, I guess just suddenly", "tokens": [286, 478, 1953, 11, 6076, 11, 613, 1074, 534, 884, 512, 2452, 1507, 365, 341, 1507, 293, 341, 2146, 307, 1228, 508, 13, 286, 390, 767, 588, 6100, 412, 300, 935, 300, 2618, 11, 286, 2041, 406, 2618, 567, 390, 1364, 370, 709, 365, 1412, 576, 458, 466, 508, 11, 457, 445, 300, 309, 576, 312, 11, 286, 2041, 445, 5800], "temperature": 0.0, "avg_logprob": -0.1741274218016033, "compression_ratio": 1.6581632653061225, "no_speech_prob": 5.09275560034439e-06}, {"id": 251, "seek": 244056, "start": 2460.56, "end": 2463.56, "text": " popped onto my headsets and I'm just, wow.", "tokens": [21545, 3911, 452, 8050, 1385, 293, 286, 478, 445, 11, 6076, 13], "temperature": 0.0, "avg_logprob": -0.1741274218016033, "compression_ratio": 1.6581632653061225, "no_speech_prob": 5.09275560034439e-06}, {"id": 252, "seek": 246356, "start": 2463.56, "end": 2477.56, "text": " Yeah. And I will say like in the array programming community, I find this like essentially a common misconception that like the reason people aren't using array programming languages is because they don't know about them or don't understand them.", "tokens": [865, 13, 400, 286, 486, 584, 411, 294, 264, 10225, 9410, 1768, 11, 286, 915, 341, 411, 4476, 257, 2689, 41350, 300, 411, 264, 1778, 561, 3212, 380, 1228, 10225, 9410, 8650, 307, 570, 436, 500, 380, 458, 466, 552, 420, 500, 380, 1223, 552, 13], "temperature": 0.0, "avg_logprob": -0.11733047485351562, "compression_ratio": 1.5375, "no_speech_prob": 5.681448328687111e-06}, {"id": 253, "seek": 247756, "start": 2477.56, "end": 2500.56, "text": " You know, which is a kernel of truth of that, but the truth is like, nowadays, there's huge, massively funded research labs at places like Google Brain and you know Facebook AI research and OpenAI and so forth where large teams of people are literally writing new programming languages", "tokens": [509, 458, 11, 597, 307, 257, 28256, 295, 3494, 295, 300, 11, 457, 264, 3494, 307, 411, 11, 13434, 11, 456, 311, 2603, 11, 29379, 14385, 2132, 20339, 412, 3190, 411, 3329, 29783, 293, 291, 458, 4384, 7318, 2132, 293, 7238, 48698, 293, 370, 5220, 689, 2416, 5491, 295, 561, 366, 3736, 3579, 777, 9410, 8650], "temperature": 0.0, "avg_logprob": -0.1948013146718343, "compression_ratio": 1.484375, "no_speech_prob": 4.709470886155032e-06}, {"id": 254, "seek": 250056, "start": 2500.56, "end": 2507.56, "text": " because they've tried everything else and what's out there is not sufficient, you know.", "tokens": [570, 436, 600, 3031, 1203, 1646, 293, 437, 311, 484, 456, 307, 406, 11563, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.14533519744873047, "compression_ratio": 1.582995951417004, "no_speech_prob": 2.0138635591138154e-05}, {"id": 255, "seek": 250056, "start": 2507.56, "end": 2522.56, "text": " I find this you know, in the array programming world there's a, offered a huge kind of underappreciation of what Python can do nowadays, for example, like I, as recently as last week I heard it described in a chat room is like, people obviously don't care about", "tokens": [286, 915, 341, 291, 458, 11, 294, 264, 10225, 9410, 1002, 456, 311, 257, 11, 8059, 257, 2603, 733, 295, 833, 1746, 3326, 399, 295, 437, 15329, 393, 360, 13434, 11, 337, 1365, 11, 411, 286, 11, 382, 3938, 382, 1036, 1243, 286, 2198, 309, 7619, 294, 257, 5081, 1808, 307, 411, 11, 561, 2745, 500, 380, 1127, 466], "temperature": 0.0, "avg_logprob": -0.14533519744873047, "compression_ratio": 1.582995951417004, "no_speech_prob": 2.0138635591138154e-05}, {"id": 256, "seek": 250056, "start": 2522.56, "end": 2526.56, "text": " performance because they're using Python.", "tokens": [3389, 570, 436, 434, 1228, 15329, 13], "temperature": 0.0, "avg_logprob": -0.14533519744873047, "compression_ratio": 1.582995951417004, "no_speech_prob": 2.0138635591138154e-05}, {"id": 257, "seek": 252656, "start": 2526.56, "end": 2542.56, "text": " And I'm like, well, you know, a large amount of the world's highest performance computing now is done with Python, like it's, it's not because Python is fast it's because like, but if you want to use rapids, for example, which literally holds records for the", "tokens": [400, 286, 478, 411, 11, 731, 11, 291, 458, 11, 257, 2416, 2372, 295, 264, 1002, 311, 6343, 3389, 15866, 586, 307, 1096, 365, 15329, 11, 411, 309, 311, 11, 309, 311, 406, 570, 15329, 307, 2370, 309, 311, 570, 411, 11, 457, 498, 291, 528, 281, 764, 5099, 3742, 11, 337, 1365, 11, 597, 3736, 9190, 7724, 337, 264], "temperature": 0.0, "avg_logprob": -0.1710056776411078, "compression_ratio": 1.6457399103139014, "no_speech_prob": 2.318227052455768e-05}, {"id": 258, "seek": 252656, "start": 2542.56, "end": 2547.56, "text": " highest performance, you know recommendation systems and tabular analysis.", "tokens": [6343, 3389, 11, 291, 458, 11879, 3652, 293, 4421, 1040, 5215, 13], "temperature": 0.0, "avg_logprob": -0.1710056776411078, "compression_ratio": 1.6457399103139014, "no_speech_prob": 2.318227052455768e-05}, {"id": 259, "seek": 252656, "start": 2547.56, "end": 2551.56, "text": " You write it in Python, you know,", "tokens": [509, 2464, 309, 294, 15329, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1710056776411078, "compression_ratio": 1.6457399103139014, "no_speech_prob": 2.318227052455768e-05}, {"id": 260, "seek": 255156, "start": 2551.56, "end": 2562.56, "text": " so this idea of having a fast kernel that's not written in the language and then something else talking to it in a very flexible way I think is great.", "tokens": [370, 341, 1558, 295, 1419, 257, 2370, 28256, 300, 311, 406, 3720, 294, 264, 2856, 293, 550, 746, 1646, 1417, 281, 309, 294, 257, 588, 11358, 636, 286, 519, 307, 869, 13], "temperature": 0.0, "avg_logprob": -0.11120100657145182, "compression_ratio": 1.544502617801047, "no_speech_prob": 6.601715722354129e-05}, {"id": 261, "seek": 255156, "start": 2562.56, "end": 2573.56, "text": " And as I say at the moment, we are very hamstrung in a lot of ways that we, or at least until recently we very heavily relied on on Blast, which", "tokens": [400, 382, 286, 584, 412, 264, 1623, 11, 321, 366, 588, 7852, 9733, 1063, 294, 257, 688, 295, 2098, 300, 321, 11, 420, 412, 1935, 1826, 3938, 321, 588, 10950, 35463, 322, 322, 2177, 525, 11, 597], "temperature": 0.0, "avg_logprob": -0.11120100657145182, "compression_ratio": 1.544502617801047, "no_speech_prob": 6.601715722354129e-05}, {"id": 262, "seek": 257356, "start": 2573.56, "end": 2590.56, "text": " is totally the wrong thing for that kind of flexible high performance computing because it's this, you know, bunch of somewhat arbitrary kind of selection of linear algebra algorithms which, you know, things like the C sharp work I did, you know,", "tokens": [307, 3879, 264, 2085, 551, 337, 300, 733, 295, 11358, 1090, 3389, 15866, 570, 309, 311, 341, 11, 291, 458, 11, 3840, 295, 8344, 23211, 733, 295, 9450, 295, 8213, 21989, 14642, 597, 11, 291, 458, 11, 721, 411, 264, 383, 8199, 589, 286, 630, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.10044348239898682, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.1439687770907767e-05}, {"id": 263, "seek": 257356, "start": 2590.56, "end": 2602.56, "text": " they were just wrappers on top of Blast. And what we really want is a way to write really expressive kernels that can do anything over any axes.", "tokens": [436, 645, 445, 7843, 15226, 322, 1192, 295, 2177, 525, 13, 400, 437, 321, 534, 528, 307, 257, 636, 281, 2464, 534, 40189, 23434, 1625, 300, 393, 360, 1340, 670, 604, 35387, 13], "temperature": 0.0, "avg_logprob": -0.10044348239898682, "compression_ratio": 1.6428571428571428, "no_speech_prob": 2.1439687770907767e-05}, {"id": 264, "seek": 260256, "start": 2602.56, "end": 2621.56, "text": " And then there are other newer approaches, like Julia, for example, which is is kind of like got some risky elements to it and this type dispatch system, but because it's, you know, in the end it's on top of LLVM.", "tokens": [400, 550, 456, 366, 661, 17628, 11587, 11, 411, 18551, 11, 337, 1365, 11, 597, 307, 307, 733, 295, 411, 658, 512, 21137, 4959, 281, 309, 293, 341, 2010, 36729, 1185, 11, 457, 570, 309, 311, 11, 291, 458, 11, 294, 264, 917, 309, 311, 322, 1192, 295, 441, 43, 53, 44, 13], "temperature": 0.0, "avg_logprob": -0.15134717707048384, "compression_ratio": 1.3831168831168832, "no_speech_prob": 1.59335759235546e-05}, {"id": 265, "seek": 262156, "start": 2621.56, "end": 2636.56, "text": " And what you write in Julia, you know, it does end up getting optimized very well and you can write pretty much arbitrary kernels in Julia and often get best in class performance.", "tokens": [400, 437, 291, 2464, 294, 18551, 11, 291, 458, 11, 309, 775, 917, 493, 1242, 26941, 588, 731, 293, 291, 393, 2464, 1238, 709, 23211, 23434, 1625, 294, 18551, 293, 2049, 483, 1151, 294, 1508, 3389, 13], "temperature": 0.0, "avg_logprob": -0.11048625266715272, "compression_ratio": 1.5073891625615763, "no_speech_prob": 5.681644324795343e-06}, {"id": 266, "seek": 262156, "start": 2636.56, "end": 2645.56, "text": " And then there's other approaches like Jax, and Jax sits on top of something totally different which is it sits on top of XLA.", "tokens": [400, 550, 456, 311, 661, 11587, 411, 508, 2797, 11, 293, 508, 2797, 12696, 322, 1192, 295, 746, 3879, 819, 597, 307, 309, 12696, 322, 1192, 295, 1783, 11435, 13], "temperature": 0.0, "avg_logprob": -0.11048625266715272, "compression_ratio": 1.5073891625615763, "no_speech_prob": 5.681644324795343e-06}, {"id": 267, "seek": 264556, "start": 2645.56, "end": 2654.56, "text": " And XLA is a compiler, which is mainly designed to compile things to run fast on Google's TPUs.", "tokens": [400, 1783, 11435, 307, 257, 31958, 11, 597, 307, 8704, 4761, 281, 31413, 721, 281, 1190, 2370, 322, 3329, 311, 314, 8115, 82, 13], "temperature": 0.0, "avg_logprob": -0.07799643886332609, "compression_ratio": 1.32, "no_speech_prob": 1.7498547094874084e-05}, {"id": 268, "seek": 264556, "start": 2654.56, "end": 2661.56, "text": " But it's also does an okay job of compiling things to run on on GPUs.", "tokens": [583, 309, 311, 611, 775, 364, 1392, 1691, 295, 715, 4883, 721, 281, 1190, 322, 322, 18407, 82, 13], "temperature": 0.0, "avg_logprob": -0.07799643886332609, "compression_ratio": 1.32, "no_speech_prob": 1.7498547094874084e-05}, {"id": 269, "seek": 266156, "start": 2661.56, "end": 2681.56, "text": " And then really excitingly I think you know for me is the, the MLIR project, and particularly the affine dialects that was created by my friend Chris Latner who you probably know from creating Klang and LLVM and Swift.", "tokens": [400, 550, 534, 4670, 356, 286, 519, 291, 458, 337, 385, 307, 264, 11, 264, 21601, 7740, 1716, 11, 293, 4098, 264, 2096, 533, 24652, 82, 300, 390, 2942, 538, 452, 1277, 6688, 7354, 1193, 567, 291, 1391, 458, 490, 4084, 16053, 656, 293, 441, 43, 53, 44, 293, 25539, 13], "temperature": 0.0, "avg_logprob": -0.18827258023348722, "compression_ratio": 1.3540372670807452, "no_speech_prob": 3.168412877130322e-05}, {"id": 270, "seek": 268156, "start": 2681.56, "end": 2697.56, "text": " So he, he joined Google for a couple of years and we worked really closely together on trying to like, think about the vision of really powerful programming on accelerators that's really developer friendly.", "tokens": [407, 415, 11, 415, 6869, 3329, 337, 257, 1916, 295, 924, 293, 321, 2732, 534, 8185, 1214, 322, 1382, 281, 411, 11, 519, 466, 264, 5201, 295, 534, 4005, 9410, 322, 10172, 3391, 300, 311, 534, 10754, 9208, 13], "temperature": 0.0, "avg_logprob": -0.0910431908779457, "compression_ratio": 1.4461538461538461, "no_speech_prob": 5.770697043772088e-06}, {"id": 271, "seek": 268156, "start": 2697.56, "end": 2703.56, "text": " Unfortunately, didn't work out Google was a bit too tied to the TensorFlow.", "tokens": [8590, 11, 994, 380, 589, 484, 3329, 390, 257, 857, 886, 9601, 281, 264, 37624, 13], "temperature": 0.0, "avg_logprob": -0.0910431908779457, "compression_ratio": 1.4461538461538461, "no_speech_prob": 5.770697043772088e-06}, {"id": 272, "seek": 270356, "start": 2703.56, "end": 2717.56, "text": " So the big ideas that did come out of that was MLIR and that's still going strong and I do think there's, you know, if, if something like APL, you know, could target MLIR and then become a DSL inside Python.", "tokens": [407, 264, 955, 3487, 300, 630, 808, 484, 295, 300, 390, 21601, 7740, 293, 300, 311, 920, 516, 2068, 293, 286, 360, 519, 456, 311, 11, 291, 458, 11, 498, 11, 498, 746, 411, 5372, 43, 11, 291, 458, 11, 727, 3779, 21601, 7740, 293, 550, 1813, 257, 15816, 43, 1854, 15329, 13], "temperature": 0.0, "avg_logprob": -0.11767422974999271, "compression_ratio": 1.484076433121019, "no_speech_prob": 6.338641924230615e-06}, {"id": 273, "seek": 270356, "start": 2717.56, "end": 2721.56, "text": " It may yet win, you know,", "tokens": [467, 815, 1939, 1942, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.11767422974999271, "compression_ratio": 1.484076433121019, "no_speech_prob": 6.338641924230615e-06}, {"id": 274, "seek": 272156, "start": 2721.56, "end": 2734.56, "text": " Yeah, I've heard you in the past say that on different podcasts and talks that you don't think that Python, like even in light of, you know, just saying, people don't realize how much you can get done with Python that you don't think that the future of data", "tokens": [865, 11, 286, 600, 2198, 291, 294, 264, 1791, 584, 300, 322, 819, 24045, 293, 6686, 300, 291, 500, 380, 519, 300, 15329, 11, 411, 754, 294, 1442, 295, 11, 291, 458, 11, 445, 1566, 11, 561, 500, 380, 4325, 577, 709, 291, 393, 483, 1096, 365, 15329, 300, 291, 500, 380, 519, 300, 264, 2027, 295, 1412], "temperature": 0.0, "avg_logprob": -0.08128411666206692, "compression_ratio": 1.8394160583941606, "no_speech_prob": 8.937719940149691e-06}, {"id": 275, "seek": 272156, "start": 2734.56, "end": 2745.56, "text": " science and AI and neural networks and that type of computation is going to live in the Python ecosystem and I've, I've heard on some podcasts you've said that you know Swift has a shot based on sort of the way that they've designed that language", "tokens": [3497, 293, 7318, 293, 18161, 9590, 293, 300, 2010, 295, 24903, 307, 516, 281, 1621, 294, 264, 15329, 11311, 293, 286, 600, 11, 286, 600, 2198, 322, 512, 24045, 291, 600, 848, 300, 291, 458, 25539, 575, 257, 3347, 2361, 322, 1333, 295, 264, 636, 300, 436, 600, 4761, 300, 2856], "temperature": 0.0, "avg_logprob": -0.08128411666206692, "compression_ratio": 1.8394160583941606, "no_speech_prob": 8.937719940149691e-06}, {"id": 276, "seek": 274556, "start": 2745.56, "end": 2752.56, "text": " and you just mentioned, you know, a plethora of different sort of, I wouldn't say initiatives but you know, Jack's, XLA, Julia, etc.", "tokens": [293, 291, 445, 2835, 11, 291, 458, 11, 257, 499, 302, 7013, 295, 819, 1333, 295, 11, 286, 2759, 380, 584, 16194, 457, 291, 458, 11, 4718, 311, 11, 1783, 11435, 11, 18551, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.1399468013218471, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.8571100756380474e-06}, {"id": 277, "seek": 274556, "start": 2752.56, "end": 2762.56, "text": " Do you have like a sense of where you, where you think the future of not necessarily sort of array language computation but this this kind of computation is going with all the different avenues.", "tokens": [1144, 291, 362, 411, 257, 2020, 295, 689, 291, 11, 689, 291, 519, 264, 2027, 295, 406, 4725, 1333, 295, 10225, 2856, 24903, 457, 341, 341, 733, 295, 24903, 307, 516, 365, 439, 264, 819, 43039, 13], "temperature": 0.0, "avg_logprob": -0.1399468013218471, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.8571100756380474e-06}, {"id": 278, "seek": 274556, "start": 2762.56, "end": 2764.56, "text": " I do.", "tokens": [286, 360, 13], "temperature": 0.0, "avg_logprob": -0.1399468013218471, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.8571100756380474e-06}, {"id": 279, "seek": 274556, "start": 2764.56, "end": 2767.56, "text": " You know, I think", "tokens": [509, 458, 11, 286, 519], "temperature": 0.0, "avg_logprob": -0.1399468013218471, "compression_ratio": 1.6175115207373272, "no_speech_prob": 2.8571100756380474e-06}, {"id": 280, "seek": 276756, "start": 2767.56, "end": 2781.56, "text": " we're certainly seeing the limitations of Python, and the limitations of the, the pie torch, you know, lazy evaluation model, which is", "tokens": [321, 434, 3297, 2577, 264, 15705, 295, 15329, 11, 293, 264, 15705, 295, 264, 11, 264, 1730, 27822, 11, 291, 458, 11, 14847, 13344, 2316, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.1104059092203776, "compression_ratio": 1.6359223300970873, "no_speech_prob": 9.663562195783015e-06}, {"id": 281, "seek": 276756, "start": 2781.56, "end": 2794.56, "text": " the way most things are done in Python at the moment for a kind of array programming is you have an expression, which is, you know, working on arrays possibly have different ranks with implicit looping.", "tokens": [264, 636, 881, 721, 366, 1096, 294, 15329, 412, 264, 1623, 337, 257, 733, 295, 10225, 9410, 307, 291, 362, 364, 6114, 11, 597, 307, 11, 291, 458, 11, 1364, 322, 41011, 6264, 362, 819, 21406, 365, 26947, 6367, 278, 13], "temperature": 0.0, "avg_logprob": -0.1104059092203776, "compression_ratio": 1.6359223300970873, "no_speech_prob": 9.663562195783015e-06}, {"id": 282, "seek": 279456, "start": 2794.56, "end": 2812.56, "text": " And, you know, that's one line of Python code. And generally that then gets your, you know, on your computer that will get turned into, you know, a request to run some particular optimized pre written operation on the GPU or TPU,", "tokens": [400, 11, 291, 458, 11, 300, 311, 472, 1622, 295, 15329, 3089, 13, 400, 5101, 300, 550, 2170, 428, 11, 291, 458, 11, 322, 428, 3820, 300, 486, 483, 3574, 666, 11, 291, 458, 11, 257, 5308, 281, 1190, 512, 1729, 26941, 659, 3720, 6916, 322, 264, 18407, 420, 314, 8115, 11], "temperature": 0.0, "avg_logprob": -0.10493231423293488, "compression_ratio": 1.5879396984924623, "no_speech_prob": 7.410268608509796e-06}, {"id": 283, "seek": 279456, "start": 2812.56, "end": 2820.56, "text": " and then get sent off to the GPU or TPU, where your data has already been moved there.", "tokens": [293, 550, 483, 2279, 766, 281, 264, 18407, 420, 314, 8115, 11, 689, 428, 1412, 575, 1217, 668, 4259, 456, 13], "temperature": 0.0, "avg_logprob": -0.10493231423293488, "compression_ratio": 1.5879396984924623, "no_speech_prob": 7.410268608509796e-06}, {"id": 284, "seek": 282056, "start": 2820.56, "end": 2835.56, "text": " And then it runs. And then it tells the CPU when it's finished. And there's a lot of latency in this right so if you want to create your own kernel like your own way of doing, you know, your own operation effectively.", "tokens": [400, 550, 309, 6676, 13, 400, 550, 309, 5112, 264, 13199, 562, 309, 311, 4335, 13, 400, 456, 311, 257, 688, 295, 27043, 294, 341, 558, 370, 498, 291, 528, 281, 1884, 428, 1065, 28256, 411, 428, 1065, 636, 295, 884, 11, 291, 458, 11, 428, 1065, 6916, 8659, 13], "temperature": 0.0, "avg_logprob": -0.11239600508180383, "compression_ratio": 1.5628415300546448, "no_speech_prob": 4.425029146659654e-06}, {"id": 285, "seek": 282056, "start": 2835.56, "end": 2839.56, "text": " You know, good luck with that. That's not going to happen in Python.", "tokens": [509, 458, 11, 665, 3668, 365, 300, 13, 663, 311, 406, 516, 281, 1051, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.11239600508180383, "compression_ratio": 1.5628415300546448, "no_speech_prob": 4.425029146659654e-06}, {"id": 286, "seek": 283956, "start": 2839.56, "end": 2854.56, "text": " And I hate this. I hate it as a teacher, because, you know, I can't show my students what's going on. Right, it kind of goes off into, you know, kind of Cuda land and then comes back later.", "tokens": [400, 286, 4700, 341, 13, 286, 4700, 309, 382, 257, 5027, 11, 570, 11, 291, 458, 11, 286, 393, 380, 855, 452, 1731, 437, 311, 516, 322, 13, 1779, 11, 309, 733, 295, 1709, 766, 666, 11, 291, 458, 11, 733, 295, 383, 11152, 2117, 293, 550, 1487, 646, 1780, 13], "temperature": 0.0, "avg_logprob": -0.09170864952935112, "compression_ratio": 1.718232044198895, "no_speech_prob": 1.593349406903144e-05}, {"id": 287, "seek": 283956, "start": 2854.56, "end": 2861.56, "text": " I hate it as a hacker because I can't go in and hack at that I can't trace it I can't debug it I can't easily profile it.", "tokens": [286, 4700, 309, 382, 257, 38155, 570, 286, 393, 380, 352, 294, 293, 10339, 412, 300, 286, 393, 380, 13508, 309, 286, 393, 380, 24083, 309, 286, 393, 380, 3612, 7964, 309, 13], "temperature": 0.0, "avg_logprob": -0.09170864952935112, "compression_ratio": 1.718232044198895, "no_speech_prob": 1.593349406903144e-05}, {"id": 288, "seek": 286156, "start": 2861.56, "end": 2872.56, "text": " And I hate it as a researcher because very often I'm like, I know we need to change this thing in this way but I'm damned if I'm going to go and write my own Cuda code, let alone deploy it.", "tokens": [400, 286, 4700, 309, 382, 257, 21751, 570, 588, 2049, 286, 478, 411, 11, 286, 458, 321, 643, 281, 1319, 341, 551, 294, 341, 636, 457, 286, 478, 46397, 498, 286, 478, 516, 281, 352, 293, 2464, 452, 1065, 383, 11152, 3089, 11, 718, 3312, 7274, 309, 13], "temperature": 0.0, "avg_logprob": -0.09356128085743297, "compression_ratio": 1.5330188679245282, "no_speech_prob": 4.860146418650402e-06}, {"id": 289, "seek": 286156, "start": 2872.56, "end": 2886.56, "text": " So, Jack's is, I think a path to this it's where you say okay let's not target pre written Cuda things let's instead target a compiler.", "tokens": [407, 11, 4718, 311, 307, 11, 286, 519, 257, 3100, 281, 341, 309, 311, 689, 291, 584, 1392, 718, 311, 406, 3779, 659, 3720, 383, 11152, 721, 718, 311, 2602, 3779, 257, 31958, 13], "temperature": 0.0, "avg_logprob": -0.09356128085743297, "compression_ratio": 1.5330188679245282, "no_speech_prob": 4.860146418650402e-06}, {"id": 290, "seek": 288656, "start": 2886.56, "end": 2901.56, "text": " And you know working with Chris Latner I'd say he did have too many nice things to say as about XLA as a compiler it was not written by compiler writers it was written by machine learning people, really, but it does the job, you know, and it's certainly", "tokens": [400, 291, 458, 1364, 365, 6688, 7354, 1193, 286, 1116, 584, 415, 630, 362, 886, 867, 1481, 721, 281, 584, 382, 466, 1783, 11435, 382, 257, 31958, 309, 390, 406, 3720, 538, 31958, 13491, 309, 390, 3720, 538, 3479, 2539, 561, 11, 534, 11, 457, 309, 775, 264, 1691, 11, 291, 458, 11, 293, 309, 311, 3297], "temperature": 0.0, "avg_logprob": -0.13160313878740584, "compression_ratio": 1.7419354838709677, "no_speech_prob": 1.3005612345295958e-05}, {"id": 291, "seek": 288656, "start": 2901.56, "end": 2915.56, "text": " better than having no compiler. And so, Jack's is something which, instead of turning our line of Python code into a call to some pre written operation, and instead is turning it into something that's going to be read by a compiler.", "tokens": [1101, 813, 1419, 572, 31958, 13, 400, 370, 11, 4718, 311, 307, 746, 597, 11, 2602, 295, 6246, 527, 1622, 295, 15329, 3089, 666, 257, 818, 281, 512, 659, 3720, 6916, 11, 293, 2602, 307, 6246, 309, 666, 746, 300, 311, 516, 281, 312, 1401, 538, 257, 31958, 13], "temperature": 0.0, "avg_logprob": -0.13160313878740584, "compression_ratio": 1.7419354838709677, "no_speech_prob": 1.3005612345295958e-05}, {"id": 292, "seek": 291556, "start": 2915.56, "end": 2930.56, "text": " And so the compiler can then, you know, optimize that as compilers do. So yeah, I would guess that Jack's probably has a part to play here,", "tokens": [400, 370, 264, 31958, 393, 550, 11, 291, 458, 11, 19719, 300, 382, 715, 388, 433, 360, 13, 407, 1338, 11, 286, 576, 2041, 300, 4718, 311, 1391, 575, 257, 644, 281, 862, 510, 11], "temperature": 0.0, "avg_logprob": -0.098052479326725, "compression_ratio": 1.4578947368421054, "no_speech_prob": 9.22250092116883e-06}, {"id": 293, "seek": 291556, "start": 2930.56, "end": 2944.56, "text": " particularly because you get to benefit from the whole Python ecosystem package management libraries, you know, visualization tools, etc.", "tokens": [4098, 570, 291, 483, 281, 5121, 490, 264, 1379, 15329, 11311, 7372, 4592, 15148, 11, 291, 458, 11, 25801, 3873, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.098052479326725, "compression_ratio": 1.4578947368421054, "no_speech_prob": 9.22250092116883e-06}, {"id": 294, "seek": 294456, "start": 2944.56, "end": 2948.56, "text": " But you know longer term.", "tokens": [583, 291, 458, 2854, 1433, 13], "temperature": 0.0, "avg_logprob": -0.09709103427716155, "compression_ratio": 1.4915254237288136, "no_speech_prob": 1.4283516975410748e-05}, {"id": 295, "seek": 294456, "start": 2948.56, "end": 2953.56, "text": " It's a mess you know it's a mess using a language like Python which wasn't designed for this.", "tokens": [467, 311, 257, 2082, 291, 458, 309, 311, 257, 2082, 1228, 257, 2856, 411, 15329, 597, 2067, 380, 4761, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.09709103427716155, "compression_ratio": 1.4915254237288136, "no_speech_prob": 1.4283516975410748e-05}, {"id": 296, "seek": 294456, "start": 2953.56, "end": 2962.56, "text": " It wasn't really even designed as something that you can chuck different compilers on onto so people put horrible hacks. So for example pytorch.", "tokens": [467, 2067, 380, 534, 754, 4761, 382, 746, 300, 291, 393, 20870, 819, 715, 388, 433, 322, 3911, 370, 561, 829, 9263, 33617, 13, 407, 337, 1365, 25878, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.09709103427716155, "compression_ratio": 1.4915254237288136, "no_speech_prob": 1.4283516975410748e-05}, {"id": 297, "seek": 296256, "start": 2962.56, "end": 2977.56, "text": " There's something called torch stripped which is a bit similar, you know, it takes Python and kind of compiles it, but they literally wrote their own parser using a bunch of regular expressions, and it's, it's, you know, it's not very good at what it does", "tokens": [821, 311, 746, 1219, 27822, 33221, 597, 307, 257, 857, 2531, 11, 291, 458, 11, 309, 2516, 15329, 293, 733, 295, 715, 4680, 309, 11, 457, 436, 3736, 4114, 641, 1065, 21156, 260, 1228, 257, 3840, 295, 3890, 15277, 11, 293, 309, 311, 11, 309, 311, 11, 291, 458, 11, 309, 311, 406, 588, 665, 412, 437, 309, 775], "temperature": 0.0, "avg_logprob": -0.164500803560824, "compression_ratio": 1.5051546391752577, "no_speech_prob": 1.618486021470744e-05}, {"id": 298, "seek": 296256, "start": 2977.56, "end": 2981.56, "text": " it even misreads comments and stuff.", "tokens": [309, 754, 3346, 2538, 82, 3053, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.164500803560824, "compression_ratio": 1.5051546391752577, "no_speech_prob": 1.618486021470744e-05}, {"id": 299, "seek": 298156, "start": 2981.56, "end": 2999.56, "text": " But you know I do think there's definitely room for, you know, a language of which Julia would certainly be the leading contender at the moment to come in and do it properly, and Julia's got you know Julia is written on a scheme basis so there's this little", "tokens": [583, 291, 458, 286, 360, 519, 456, 311, 2138, 1808, 337, 11, 291, 458, 11, 257, 2856, 295, 597, 18551, 576, 3297, 312, 264, 5775, 660, 3216, 412, 264, 1623, 281, 808, 294, 293, 360, 309, 6108, 11, 293, 18551, 311, 658, 291, 458, 18551, 307, 3720, 322, 257, 12232, 5143, 370, 456, 311, 341, 707], "temperature": 0.0, "avg_logprob": -0.10463211148284203, "compression_ratio": 1.6563876651982379, "no_speech_prob": 4.93660172651289e-06}, {"id": 300, "seek": 298156, "start": 2999.56, "end": 3008.56, "text": " scheme kernel that does the parsing and whatnot, and then pretty much everything else. After that is written in Julia.", "tokens": [12232, 28256, 300, 775, 264, 21156, 278, 293, 25882, 11, 293, 550, 1238, 709, 1203, 1646, 13, 2381, 300, 307, 3720, 294, 18551, 13], "temperature": 0.0, "avg_logprob": -0.10463211148284203, "compression_ratio": 1.6563876651982379, "no_speech_prob": 4.93660172651289e-06}, {"id": 301, "seek": 300856, "start": 3008.56, "end": 3023.56, "text": " And of course, leveraging LLVM very heavily. But that's, I think that's what we want right is that something which I got something also I didn't love about Swift when when the team at Google wanted to add differentiation support into Swift.", "tokens": [400, 295, 1164, 11, 32666, 441, 43, 53, 44, 588, 10950, 13, 583, 300, 311, 11, 286, 519, 300, 311, 437, 321, 528, 558, 307, 300, 746, 597, 286, 658, 746, 611, 286, 994, 380, 959, 466, 25539, 562, 562, 264, 1469, 412, 3329, 1415, 281, 909, 38902, 1406, 666, 25539, 13], "temperature": 0.0, "avg_logprob": -0.15455180406570435, "compression_ratio": 1.457142857142857, "no_speech_prob": 2.2470148905995302e-05}, {"id": 302, "seek": 300856, "start": 3023.56, "end": 3025.56, "text": " They read it in c++.", "tokens": [814, 1401, 309, 294, 269, 25472, 13], "temperature": 0.0, "avg_logprob": -0.15455180406570435, "compression_ratio": 1.457142857142857, "no_speech_prob": 2.2470148905995302e-05}, {"id": 303, "seek": 300856, "start": 3025.56, "end": 3029.56, "text": " And I was just like, that's not a good sign.", "tokens": [400, 286, 390, 445, 411, 11, 300, 311, 406, 257, 665, 1465, 13], "temperature": 0.0, "avg_logprob": -0.15455180406570435, "compression_ratio": 1.457142857142857, "no_speech_prob": 2.2470148905995302e-05}, {"id": 304, "seek": 302956, "start": 3029.56, "end": 3044.56, "text": " So, like apart from anything else you end up with this group of developers who are, in theory, Swift experts but they actually write everything in c++. And so they actually don't have much feel for what it's like to write stuff in Swift, they're writing stuff", "tokens": [407, 11, 411, 4936, 490, 1340, 1646, 291, 917, 493, 365, 341, 1594, 295, 8849, 567, 366, 11, 294, 5261, 11, 25539, 8572, 457, 436, 767, 2464, 1203, 294, 269, 25472, 13, 400, 370, 436, 767, 500, 380, 362, 709, 841, 337, 437, 309, 311, 411, 281, 2464, 1507, 294, 25539, 11, 436, 434, 3579, 1507], "temperature": 0.0, "avg_logprob": -0.11304677405008455, "compression_ratio": 1.7598039215686274, "no_speech_prob": 8.397190867981408e-06}, {"id": 305, "seek": 302956, "start": 3044.56, "end": 3050.56, "text": " for Swift. And Julia pretty much everybody who's writing stuff for Julia is writing stuff in Julia.", "tokens": [337, 25539, 13, 400, 18551, 1238, 709, 2201, 567, 311, 3579, 1507, 337, 18551, 307, 3579, 1507, 294, 18551, 13], "temperature": 0.0, "avg_logprob": -0.11304677405008455, "compression_ratio": 1.7598039215686274, "no_speech_prob": 8.397190867981408e-06}, {"id": 306, "seek": 305056, "start": 3050.56, "end": 3066.56, "text": " And I think that's, that's something you guys have talked about around APL and J as well is that there's the idea of writing J things in J and APL things in APL is very powerful idea.", "tokens": [400, 286, 519, 300, 311, 11, 300, 311, 746, 291, 1074, 362, 2825, 466, 926, 5372, 43, 293, 508, 382, 731, 307, 300, 456, 311, 264, 1558, 295, 3579, 508, 721, 294, 508, 293, 5372, 43, 721, 294, 5372, 43, 307, 588, 4005, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1863928463148034, "compression_ratio": 1.5311004784688995, "no_speech_prob": 1.4062582522456069e-05}, {"id": 307, "seek": 305056, "start": 3066.56, "end": 3067.56, "text": " Yeah, I was wondering about.", "tokens": [865, 11, 286, 390, 6359, 466, 13], "temperature": 0.0, "avg_logprob": -0.1863928463148034, "compression_ratio": 1.5311004784688995, "no_speech_prob": 1.4062582522456069e-05}, {"id": 308, "seek": 305056, "start": 3067.56, "end": 3071.56, "text": " Oh, yeah, sorry, I just remembered your third question. I'll come back to it.", "tokens": [876, 11, 1338, 11, 2597, 11, 286, 445, 13745, 428, 2636, 1168, 13, 286, 603, 808, 646, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.1863928463148034, "compression_ratio": 1.5311004784688995, "no_speech_prob": 1.4062582522456069e-05}, {"id": 309, "seek": 305056, "start": 3071.56, "end": 3073.56, "text": " No, no, you go ahead you had.", "tokens": [883, 11, 572, 11, 291, 352, 2286, 291, 632, 13], "temperature": 0.0, "avg_logprob": -0.1863928463148034, "compression_ratio": 1.5311004784688995, "no_speech_prob": 1.4062582522456069e-05}, {"id": 310, "seek": 307356, "start": 3073.56, "end": 3083.56, "text": " You asked me why now am I coming back to APL and J, which is totally orthogonal to everything else we've talked about, which is, I had a daughter.", "tokens": [509, 2351, 385, 983, 586, 669, 286, 1348, 646, 281, 5372, 43, 293, 508, 11, 597, 307, 3879, 41488, 281, 1203, 1646, 321, 600, 2825, 466, 11, 597, 307, 11, 286, 632, 257, 4653, 13], "temperature": 0.0, "avg_logprob": -0.1378859823400324, "compression_ratio": 1.5676855895196506, "no_speech_prob": 2.0782372303074226e-05}, {"id": 311, "seek": 307356, "start": 3083.56, "end": 3090.56, "text": " She got old enough to actually start learning math so she's six.", "tokens": [1240, 658, 1331, 1547, 281, 767, 722, 2539, 5221, 370, 750, 311, 2309, 13], "temperature": 0.0, "avg_logprob": -0.1378859823400324, "compression_ratio": 1.5676855895196506, "no_speech_prob": 2.0782372303074226e-05}, {"id": 312, "seek": 307356, "start": 3090.56, "end": 3100.56, "text": " And, oh my god there's so many great educational apps nowadays there's one called Dragon Box algebra it's so much fun Dragon Box algebra five plus.", "tokens": [400, 11, 1954, 452, 3044, 456, 311, 370, 867, 869, 10189, 7733, 13434, 456, 311, 472, 1219, 11517, 15112, 21989, 309, 311, 370, 709, 1019, 11517, 15112, 21989, 1732, 1804, 13], "temperature": 0.0, "avg_logprob": -0.1378859823400324, "compression_ratio": 1.5676855895196506, "no_speech_prob": 2.0782372303074226e-05}, {"id": 313, "seek": 310056, "start": 3100.56, "end": 3109.56, "text": " And it's like five plus algebra, like what the hell so when she was, I think she's still four I gave, you know I let her play with Dragon Box algebra five plus.", "tokens": [400, 309, 311, 411, 1732, 1804, 21989, 11, 411, 437, 264, 4921, 370, 562, 750, 390, 11, 286, 519, 750, 311, 920, 1451, 286, 2729, 11, 291, 458, 286, 718, 720, 862, 365, 11517, 15112, 21989, 1732, 1804, 13], "temperature": 0.0, "avg_logprob": -0.13293309211730958, "compression_ratio": 1.7787610619469028, "no_speech_prob": 6.203664088388905e-05}, {"id": 314, "seek": 310056, "start": 3109.56, "end": 3115.56, "text": " And she learned algebra, you know by helping dragon eggs hatch.", "tokens": [400, 750, 3264, 21989, 11, 291, 458, 538, 4315, 12165, 6466, 17387, 13], "temperature": 0.0, "avg_logprob": -0.13293309211730958, "compression_ratio": 1.7787610619469028, "no_speech_prob": 6.203664088388905e-05}, {"id": 315, "seek": 310056, "start": 3115.56, "end": 3128.56, "text": " And she liked it so much I let her try doing Dragon Box algebra 12 plus, and she loved that as well and finished it and so suddenly I had a five year old kid that liked algebra.", "tokens": [400, 750, 4501, 309, 370, 709, 286, 718, 720, 853, 884, 11517, 15112, 21989, 2272, 1804, 11, 293, 750, 4333, 300, 382, 731, 293, 4335, 309, 293, 370, 5800, 286, 632, 257, 1732, 1064, 1331, 1636, 300, 4501, 21989, 13], "temperature": 0.0, "avg_logprob": -0.13293309211730958, "compression_ratio": 1.7787610619469028, "no_speech_prob": 6.203664088388905e-05}, {"id": 316, "seek": 312856, "start": 3128.56, "end": 3131.56, "text": " And I was like, much, much surprised.", "tokens": [400, 286, 390, 411, 11, 709, 11, 709, 6100, 13], "temperature": 0.0, "avg_logprob": -0.20319797992706298, "compression_ratio": 1.61, "no_speech_prob": 3.704738992382772e-05}, {"id": 317, "seek": 312856, "start": 3131.56, "end": 3145.56, "text": " Kids really can surprise you. And so, yeah she struggled with a lot of the math that they were meant to be doing a primary school like, like division and multiplication but she liked the algebra.", "tokens": [15694, 534, 393, 6365, 291, 13, 400, 370, 11, 1338, 750, 19023, 365, 257, 688, 295, 264, 5221, 300, 436, 645, 4140, 281, 312, 884, 257, 6194, 1395, 411, 11, 411, 10044, 293, 27290, 457, 750, 4501, 264, 21989, 13], "temperature": 0.0, "avg_logprob": -0.20319797992706298, "compression_ratio": 1.61, "no_speech_prob": 3.704738992382772e-05}, {"id": 318, "seek": 312856, "start": 3145.56, "end": 3153.56, "text": " And we ended up homeschooling her. And then one of her best friend is also homeschooled.", "tokens": [400, 321, 4590, 493, 7388, 21856, 278, 720, 13, 400, 550, 472, 295, 720, 1151, 1277, 307, 611, 7388, 21856, 292, 13], "temperature": 0.0, "avg_logprob": -0.20319797992706298, "compression_ratio": 1.61, "no_speech_prob": 3.704738992382772e-05}, {"id": 319, "seek": 315356, "start": 3153.56, "end": 3159.56, "text": " So this, this year I decided I'd try tutoring them in math together.", "tokens": [407, 341, 11, 341, 1064, 286, 3047, 286, 1116, 853, 44410, 552, 294, 5221, 1214, 13], "temperature": 0.0, "avg_logprob": -0.10654621965744916, "compression_ratio": 1.4974358974358974, "no_speech_prob": 5.736852835980244e-05}, {"id": 320, "seek": 315356, "start": 3159.56, "end": 3175.56, "text": " And so, my daughter's name is Claire so her friend gave. So her friend gave discovered on his Mac the world of alternative keyboards so he would start typing in the chat in, you know, Greek characters or Russian characters.", "tokens": [400, 370, 11, 452, 4653, 311, 1315, 307, 22605, 370, 720, 1277, 2729, 13, 407, 720, 1277, 2729, 6941, 322, 702, 5707, 264, 1002, 295, 8535, 47808, 370, 415, 576, 722, 18444, 294, 264, 5081, 294, 11, 291, 458, 11, 10281, 4342, 420, 7220, 4342, 13], "temperature": 0.0, "avg_logprob": -0.10654621965744916, "compression_ratio": 1.4974358974358974, "no_speech_prob": 5.736852835980244e-05}, {"id": 321, "seek": 317556, "start": 3175.56, "end": 3185.56, "text": " And one day I was like, okay check this out so I like tapped in some APL characters. And they were just like, wow, what's that we need that.", "tokens": [400, 472, 786, 286, 390, 411, 11, 1392, 1520, 341, 484, 370, 286, 411, 38693, 294, 512, 5372, 43, 4342, 13, 400, 436, 645, 445, 411, 11, 6076, 11, 437, 311, 300, 321, 643, 300, 13], "temperature": 0.0, "avg_logprob": -0.1682147979736328, "compression_ratio": 1.4645161290322581, "no_speech_prob": 1.3842983207723591e-05}, {"id": 322, "seek": 317556, "start": 3185.56, "end": 3193.56, "text": " So, initially we installed dialogue APL so they could type APL characters in the chat.", "tokens": [407, 11, 9105, 321, 8899, 10221, 5372, 43, 370, 436, 727, 2010, 5372, 43, 4342, 294, 264, 5081, 13], "temperature": 0.0, "avg_logprob": -0.1682147979736328, "compression_ratio": 1.4645161290322581, "no_speech_prob": 1.3842983207723591e-05}, {"id": 323, "seek": 319356, "start": 3193.56, "end": 3212.56, "text": " And I explained to them that this is actually like super fancy math that you're typing in. They really wanted to try it. So, and that was at the time I was trying to teach them sequences and series, and they were not getting it at all it was my first", "tokens": [400, 286, 8825, 281, 552, 300, 341, 307, 767, 411, 1687, 10247, 5221, 300, 291, 434, 18444, 294, 13, 814, 534, 1415, 281, 853, 309, 13, 407, 11, 293, 300, 390, 412, 264, 565, 286, 390, 1382, 281, 2924, 552, 22978, 293, 2638, 11, 293, 436, 645, 406, 1242, 309, 412, 439, 309, 390, 452, 700], "temperature": 0.0, "avg_logprob": -0.12901297410329182, "compression_ratio": 1.5060240963855422, "no_speech_prob": 2.177916576329153e-05}, {"id": 324, "seek": 321256, "start": 3212.56, "end": 3229.56, "text": " year time as a, as a math tutor with them you know they've been zipping along fractions you know greatest common denominator factor trees. Okay, everything's fine it makes sense and then we hit sequences and series and it's just like, they had no idea what", "tokens": [1064, 565, 382, 257, 11, 382, 257, 5221, 35613, 365, 552, 291, 458, 436, 600, 668, 710, 6297, 2051, 36058, 291, 458, 6636, 2689, 20687, 5952, 5852, 13, 1033, 11, 1203, 311, 2489, 309, 1669, 2020, 293, 550, 321, 2045, 22978, 293, 2638, 293, 309, 311, 445, 411, 11, 436, 632, 572, 1558, 437], "temperature": 0.0, "avg_logprob": -0.15566764244666467, "compression_ratio": 1.489247311827957, "no_speech_prob": 1.202836665470386e-05}, {"id": 325, "seek": 321256, "start": 3229.56, "end": 3231.56, "text": " I was talking about.", "tokens": [286, 390, 1417, 466, 13], "temperature": 0.0, "avg_logprob": -0.15566764244666467, "compression_ratio": 1.489247311827957, "no_speech_prob": 1.202836665470386e-05}, {"id": 326, "seek": 323156, "start": 3231.56, "end": 3248.56, "text": " So, we put that aside, then we spent like three one hour lessons, doing the basics of APL, you know, the basic operations and doing stuff with lists and dietic versus monadic.", "tokens": [407, 11, 321, 829, 300, 7359, 11, 550, 321, 4418, 411, 1045, 472, 1773, 8820, 11, 884, 264, 14688, 295, 5372, 43, 11, 291, 458, 11, 264, 3875, 7705, 293, 884, 1507, 365, 14511, 293, 1026, 3532, 5717, 1108, 43341, 13], "temperature": 0.0, "avg_logprob": -0.1835778342352973, "compression_ratio": 1.5485232067510548, "no_speech_prob": 8.266521945188288e-06}, {"id": 327, "seek": 323156, "start": 3248.56, "end": 3251.56, "text": " It's still good up this primary school level math.", "tokens": [467, 311, 920, 665, 493, 341, 6194, 1395, 1496, 5221, 13], "temperature": 0.0, "avg_logprob": -0.1835778342352973, "compression_ratio": 1.5485232067510548, "no_speech_prob": 8.266521945188288e-06}, {"id": 328, "seek": 323156, "start": 3251.56, "end": 3260.56, "text": " And we also did the same thing in NumPy using Jupiter. And they really enjoyed all that like they were more engaged than our normal lessons.", "tokens": [400, 321, 611, 630, 264, 912, 551, 294, 22592, 47, 88, 1228, 24567, 13, 400, 436, 534, 4626, 439, 300, 411, 436, 645, 544, 8237, 813, 527, 2710, 8820, 13], "temperature": 0.0, "avg_logprob": -0.1835778342352973, "compression_ratio": 1.5485232067510548, "no_speech_prob": 8.266521945188288e-06}, {"id": 329, "seek": 326056, "start": 3260.56, "end": 3275.56, "text": " And so then we came back to like, you know, sigma i equals one to five of i squared, whatever it is like okay that means this, you know, in APL and this in NumPy.", "tokens": [400, 370, 550, 321, 1361, 646, 281, 411, 11, 291, 458, 11, 12771, 741, 6915, 472, 281, 1732, 295, 741, 8889, 11, 2035, 309, 307, 411, 1392, 300, 1355, 341, 11, 291, 458, 11, 294, 5372, 43, 293, 341, 294, 22592, 47, 88, 13], "temperature": 0.0, "avg_logprob": -0.17520902633666993, "compression_ratio": 1.6287128712871286, "no_speech_prob": 8.529513252142351e-06}, {"id": 330, "seek": 326056, "start": 3275.56, "end": 3278.56, "text": " And they're like, Oh, settle.", "tokens": [400, 436, 434, 411, 11, 876, 11, 11852, 13], "temperature": 0.0, "avg_logprob": -0.17520902633666993, "compression_ratio": 1.6287128712871286, "no_speech_prob": 8.529513252142351e-06}, {"id": 331, "seek": 326056, "start": 3278.56, "end": 3282.56, "text": " Fine, with, you know, that's like.", "tokens": [12024, 11, 365, 11, 291, 458, 11, 300, 311, 411, 13], "temperature": 0.0, "avg_logprob": -0.17520902633666993, "compression_ratio": 1.6287128712871286, "no_speech_prob": 8.529513252142351e-06}, {"id": 332, "seek": 326056, "start": 3282.56, "end": 3288.56, "text": " Yeah, so that was the problem this idea of like TN equals TN minus one plus blah blah blah it's like.", "tokens": [865, 11, 370, 300, 390, 264, 1154, 341, 1558, 295, 411, 314, 45, 6915, 314, 45, 3175, 472, 1804, 12288, 12288, 12288, 309, 311, 411, 13], "temperature": 0.0, "avg_logprob": -0.17520902633666993, "compression_ratio": 1.6287128712871286, "no_speech_prob": 8.529513252142351e-06}, {"id": 333, "seek": 328856, "start": 3288.56, "end": 3299.56, "text": " What is this stuff but when you're actually indexing real things and can print out the intermediate values and all that and you've got iota or a range.", "tokens": [708, 307, 341, 1507, 457, 562, 291, 434, 767, 8186, 278, 957, 721, 293, 393, 4482, 484, 264, 19376, 4190, 293, 439, 300, 293, 291, 600, 658, 741, 5377, 420, 257, 3613, 13], "temperature": 0.0, "avg_logprob": -0.1371202157891315, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.3417917216429487e-05}, {"id": 334, "seek": 328856, "start": 3299.56, "end": 3301.56, "text": " They were just like, Oh, okay.", "tokens": [814, 645, 445, 411, 11, 876, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.1371202157891315, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.3417917216429487e-05}, {"id": 335, "seek": 328856, "start": 3301.56, "end": 3313.56, "text": " I don't know why you explained it this dumb way before. And I will say, given a choice between doing something on a whiteboard or doing something in NumPy or doing something in APL.", "tokens": [286, 500, 380, 458, 983, 291, 8825, 309, 341, 10316, 636, 949, 13, 400, 286, 486, 584, 11, 2212, 257, 3922, 1296, 884, 746, 322, 257, 2418, 3787, 420, 884, 746, 294, 22592, 47, 88, 420, 884, 746, 294, 5372, 43, 13], "temperature": 0.0, "avg_logprob": -0.1371202157891315, "compression_ratio": 1.5622317596566524, "no_speech_prob": 1.3417917216429487e-05}, {"id": 336, "seek": 331356, "start": 3313.56, "end": 3318.56, "text": " You know, always pick APL, because the APL version.", "tokens": [509, 458, 11, 1009, 1888, 5372, 43, 11, 570, 264, 5372, 43, 3037, 13], "temperature": 0.0, "avg_logprob": -0.20621292546110334, "compression_ratio": 1.6465863453815262, "no_speech_prob": 9.36772357817972e-06}, {"id": 337, "seek": 331356, "start": 3318.56, "end": 3324.56, "text": " It's just so much easier, you know, there's less to type this has to think about this as boilerplate.", "tokens": [467, 311, 445, 370, 709, 3571, 11, 291, 458, 11, 456, 311, 1570, 281, 2010, 341, 575, 281, 519, 466, 341, 382, 39228, 37008, 13], "temperature": 0.0, "avg_logprob": -0.20621292546110334, "compression_ratio": 1.6465863453815262, "no_speech_prob": 9.36772357817972e-06}, {"id": 338, "seek": 331356, "start": 3324.56, "end": 3328.56, "text": " And so it's been it's only been a few weeks but like yesterday.", "tokens": [400, 370, 309, 311, 668, 309, 311, 787, 668, 257, 1326, 3259, 457, 411, 5186, 13], "temperature": 0.0, "avg_logprob": -0.20621292546110334, "compression_ratio": 1.6465863453815262, "no_speech_prob": 9.36772357817972e-06}, {"id": 339, "seek": 331356, "start": 3328.56, "end": 3340.56, "text": " We did the power operator, you know, and so we literally started doing the foundations of mathematics, mathematics, I was like, Okay, let's create a function called capital S, capital S arrow.", "tokens": [492, 630, 264, 1347, 12973, 11, 291, 458, 11, 293, 370, 321, 3736, 1409, 884, 264, 22467, 295, 18666, 11, 18666, 11, 286, 390, 411, 11, 1033, 11, 718, 311, 1884, 257, 2445, 1219, 4238, 318, 11, 4238, 318, 11610, 13], "temperature": 0.0, "avg_logprob": -0.20621292546110334, "compression_ratio": 1.6465863453815262, "no_speech_prob": 9.36772357817972e-06}, {"id": 340, "seek": 334056, "start": 3340.56, "end": 3359.56, "text": " Plus, jot one. Right. So for those Python people listening jot is if you give it a an array or a scalar, it's the same as partial in in in Python or bind in C++.", "tokens": [7721, 11, 27873, 472, 13, 1779, 13, 407, 337, 729, 15329, 561, 4764, 27873, 307, 498, 291, 976, 309, 257, 364, 10225, 420, 257, 39684, 11, 309, 311, 264, 912, 382, 14641, 294, 294, 294, 15329, 420, 14786, 294, 383, 25472, 13], "temperature": 0.0, "avg_logprob": -0.16402429929921325, "compression_ratio": 1.4756756756756757, "no_speech_prob": 1.4970362826716155e-05}, {"id": 341, "seek": 334056, "start": 3359.56, "end": 3364.56, "text": " So okay we've now got something that adds one to things okay I said okay this is called the successor function.", "tokens": [407, 1392, 321, 600, 586, 658, 746, 300, 10860, 472, 281, 721, 1392, 286, 848, 1392, 341, 307, 1219, 264, 31864, 2445, 13], "temperature": 0.0, "avg_logprob": -0.16402429929921325, "compression_ratio": 1.4756756756756757, "no_speech_prob": 1.4970362826716155e-05}, {"id": 342, "seek": 336456, "start": 3364.56, "end": 3370.56, "text": " And so I said to them okay what would happen if we go SSS zero.", "tokens": [400, 370, 286, 848, 281, 552, 1392, 437, 576, 1051, 498, 321, 352, 12238, 50, 4018, 13], "temperature": 0.0, "avg_logprob": -0.181671026478643, "compression_ratio": 1.7268722466960353, "no_speech_prob": 2.840654633473605e-05}, {"id": 343, "seek": 336456, "start": 3370.56, "end": 3376.56, "text": " And they're like, hmm. Oh, that would be three. And so I said okay well what's it what's addition.", "tokens": [400, 436, 434, 411, 11, 16478, 13, 876, 11, 300, 576, 312, 1045, 13, 400, 370, 286, 848, 1392, 731, 437, 311, 309, 437, 311, 4500, 13], "temperature": 0.0, "avg_logprob": -0.181671026478643, "compression_ratio": 1.7268722466960353, "no_speech_prob": 2.840654633473605e-05}, {"id": 344, "seek": 336456, "start": 3376.56, "end": 3387.56, "text": " And then one of them is like, oh, it's repeated s, like yeah it's repeated s so how do we say repeated so in APL we say repeated by using this star dioresis it's called power.", "tokens": [400, 550, 472, 295, 552, 307, 411, 11, 1954, 11, 309, 311, 10477, 262, 11, 411, 1338, 309, 311, 10477, 262, 370, 577, 360, 321, 584, 10477, 370, 294, 5372, 43, 321, 584, 10477, 538, 1228, 341, 3543, 1026, 2706, 271, 309, 311, 1219, 1347, 13], "temperature": 0.0, "avg_logprob": -0.181671026478643, "compression_ratio": 1.7268722466960353, "no_speech_prob": 2.840654633473605e-05}, {"id": 345, "seek": 336456, "start": 3387.56, "end": 3389.56, "text": " Okay, so now we've done that.", "tokens": [1033, 11, 370, 586, 321, 600, 1096, 300, 13], "temperature": 0.0, "avg_logprob": -0.181671026478643, "compression_ratio": 1.7268722466960353, "no_speech_prob": 2.840654633473605e-05}, {"id": 346, "seek": 336456, "start": 3389.56, "end": 3391.56, "text": " What is multiplication.", "tokens": [708, 307, 27290, 13], "temperature": 0.0, "avg_logprob": -0.181671026478643, "compression_ratio": 1.7268722466960353, "no_speech_prob": 2.840654633473605e-05}, {"id": 347, "seek": 339156, "start": 3391.56, "end": 3399.56, "text": " And then when I think is after a while, oh, it's repeated addition. So we define addition and then we define multiplication.", "tokens": [400, 550, 562, 286, 519, 307, 934, 257, 1339, 11, 1954, 11, 309, 311, 10477, 4500, 13, 407, 321, 6964, 4500, 293, 550, 321, 6964, 27290, 13], "temperature": 0.0, "avg_logprob": -0.17687240647680966, "compression_ratio": 1.707070707070707, "no_speech_prob": 6.814078369643539e-05}, {"id": 348, "seek": 339156, "start": 3399.56, "end": 3404.56, "text": " And then I'm like okay well what about, you know, exponent.", "tokens": [400, 550, 286, 478, 411, 1392, 731, 437, 466, 11, 291, 458, 11, 37871, 13], "temperature": 0.0, "avg_logprob": -0.17687240647680966, "compression_ratio": 1.707070707070707, "no_speech_prob": 6.814078369643539e-05}, {"id": 349, "seek": 339156, "start": 3404.56, "end": 3411.56, "text": " Oh, that's just another one they've heard 1000 times they're both immediately like oh that's repeated multiplication so like okay we've now defined that.", "tokens": [876, 11, 300, 311, 445, 1071, 472, 436, 600, 2198, 9714, 1413, 436, 434, 1293, 4258, 411, 1954, 300, 311, 10477, 27290, 370, 411, 1392, 321, 600, 586, 7642, 300, 13], "temperature": 0.0, "avg_logprob": -0.17687240647680966, "compression_ratio": 1.707070707070707, "no_speech_prob": 6.814078369643539e-05}, {"id": 350, "seek": 341156, "start": 3411.56, "end": 3426.56, "text": " And then okay well subtraction that's a bit tricky. Well it turns out that subtraction is just, you know, is the opposite of something what's the opposite of that both know that as the opposite of addition, okay well opposite of which in math we call inverse is just a", "tokens": [400, 550, 1392, 731, 16390, 313, 300, 311, 257, 857, 12414, 13, 1042, 309, 4523, 484, 300, 16390, 313, 307, 445, 11, 291, 458, 11, 307, 264, 6182, 295, 746, 437, 311, 264, 6182, 295, 300, 1293, 458, 300, 382, 264, 6182, 295, 4500, 11, 1392, 731, 6182, 295, 597, 294, 5221, 321, 818, 17340, 307, 445, 257], "temperature": 0.0, "avg_logprob": -0.18862053385952063, "compression_ratio": 1.95850622406639, "no_speech_prob": 3.59086952812504e-05}, {"id": 351, "seek": 341156, "start": 3426.56, "end": 3428.56, "text": " negative power.", "tokens": [3671, 1347, 13], "temperature": 0.0, "avg_logprob": -0.18862053385952063, "compression_ratio": 1.95850622406639, "no_speech_prob": 3.59086952812504e-05}, {"id": 352, "seek": 341156, "start": 3428.56, "end": 3440.56, "text": " So now we define subtraction. So how would you define division. Oh, okay, how would you define roots. Oh, okay. So we kind of like, you know, designing the foundations of, of mathematics.", "tokens": [407, 586, 321, 6964, 16390, 313, 13, 407, 577, 576, 291, 6964, 10044, 13, 876, 11, 1392, 11, 577, 576, 291, 6964, 10669, 13, 876, 11, 1392, 13, 407, 321, 733, 295, 411, 11, 291, 458, 11, 14685, 264, 22467, 295, 11, 295, 18666, 13], "temperature": 0.0, "avg_logprob": -0.18862053385952063, "compression_ratio": 1.95850622406639, "no_speech_prob": 3.59086952812504e-05}, {"id": 353, "seek": 344056, "start": 3440.56, "end": 3453.56, "text": " There's mathematics here at APL, you know, with a six year old and an eight year old. And during this whole thing at one point we're like okay well now, I can't remember why but we're like okay now we got to do one divided by half.", "tokens": [821, 311, 18666, 510, 412, 5372, 43, 11, 291, 458, 11, 365, 257, 2309, 1064, 1331, 293, 364, 3180, 1064, 1331, 13, 400, 1830, 341, 1379, 551, 412, 472, 935, 321, 434, 411, 1392, 731, 586, 11, 286, 393, 380, 1604, 983, 457, 321, 434, 411, 1392, 586, 321, 658, 281, 360, 472, 6666, 538, 1922, 13], "temperature": 0.0, "avg_logprob": -0.13869180307759868, "compression_ratio": 1.5297297297297296, "no_speech_prob": 4.7570214519510046e-05}, {"id": 354, "seek": 344056, "start": 3453.56, "end": 3456.56, "text": " And they're both like we don't know how to do that.", "tokens": [400, 436, 434, 1293, 411, 321, 500, 380, 458, 577, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.13869180307759868, "compression_ratio": 1.5297297297297296, "no_speech_prob": 4.7570214519510046e-05}, {"id": 355, "seek": 345656, "start": 3456.56, "end": 3470.56, "text": " You know, APL, this stuff that's considered like college level math, suddenly becomes easy and you know at a point when still primary school level math like one divided by a half is considered hard.", "tokens": [509, 458, 11, 5372, 43, 11, 341, 1507, 300, 311, 4888, 411, 3859, 1496, 5221, 11, 5800, 3643, 1858, 293, 291, 458, 412, 257, 935, 562, 920, 6194, 1395, 1496, 5221, 411, 472, 6666, 538, 257, 1922, 307, 4888, 1152, 13], "temperature": 0.0, "avg_logprob": -0.13155490835917363, "compression_ratio": 1.6958333333333333, "no_speech_prob": 1.644133953959681e-05}, {"id": 356, "seek": 345656, "start": 3470.56, "end": 3484.56, "text": " So it definitely made me rethink, you know, what is easy and what is hard and how to teach this math stuff and have been doing a lot of teaching of math with APL and the kids are loving it, and I'm loving it.", "tokens": [407, 309, 2138, 1027, 385, 34595, 11, 291, 458, 11, 437, 307, 1858, 293, 437, 307, 1152, 293, 577, 281, 2924, 341, 5221, 1507, 293, 362, 668, 884, 257, 688, 295, 4571, 295, 5221, 365, 5372, 43, 293, 264, 2301, 366, 9344, 309, 11, 293, 286, 478, 9344, 309, 13], "temperature": 0.0, "avg_logprob": -0.13155490835917363, "compression_ratio": 1.6958333333333333, "no_speech_prob": 1.644133953959681e-05}, {"id": 357, "seek": 348456, "start": 3484.56, "end": 3490.56, "text": " And that's actually why I started this study group, which will be on today.", "tokens": [400, 300, 311, 767, 983, 286, 1409, 341, 2979, 1594, 11, 597, 486, 312, 322, 965, 13], "temperature": 0.0, "avg_logprob": -0.12741216659545898, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.545968527556397e-05}, {"id": 358, "seek": 348456, "start": 3490.56, "end": 3496.56, "text": " Today as we record this a few days ago, as you put it out there.", "tokens": [2692, 382, 321, 2136, 341, 257, 1326, 1708, 2057, 11, 382, 291, 829, 309, 484, 456, 13], "temperature": 0.0, "avg_logprob": -0.12741216659545898, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.545968527556397e-05}, {"id": 359, "seek": 348456, "start": 3496.56, "end": 3510.56, "text": " As I kind of started saying on Twitter to people like oh it's really been fun teaching my kids you know my kid and her friend math using APL and a lot of adults were like, can we learn math.", "tokens": [1018, 286, 733, 295, 1409, 1566, 322, 5794, 281, 561, 411, 1954, 309, 311, 534, 668, 1019, 4571, 452, 2301, 291, 458, 452, 1636, 293, 720, 1277, 5221, 1228, 5372, 43, 293, 257, 688, 295, 8865, 645, 411, 11, 393, 321, 1466, 5221, 13], "temperature": 0.0, "avg_logprob": -0.12741216659545898, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.545968527556397e-05}, {"id": 360, "seek": 348456, "start": 3510.56, "end": 3513.56, "text": " So, so that's what we're going to do.", "tokens": [407, 11, 370, 300, 311, 437, 321, 434, 516, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.12741216659545898, "compression_ratio": 1.5836909871244635, "no_speech_prob": 2.545968527556397e-05}, {"id": 361, "seek": 351356, "start": 3513.56, "end": 3522.56, "text": " It's a notation thing isn't it. It's the notion you get away from the sigma's and the pies and all that you know subscripts. I know right, this is exactly what I've been wanting.", "tokens": [467, 311, 257, 24657, 551, 1943, 380, 309, 13, 467, 311, 264, 10710, 291, 483, 1314, 490, 264, 12771, 311, 293, 264, 29640, 293, 439, 300, 291, 458, 2325, 39280, 13, 286, 458, 558, 11, 341, 307, 2293, 437, 286, 600, 668, 7935, 13], "temperature": 0.0, "avg_logprob": -0.3009282625638522, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.00013977197522763163}, {"id": 362, "seek": 351356, "start": 3522.56, "end": 3540.56, "text": " Yeah, exactly. I mean who wants this, you know, why should capital pi be product and capital sigma be some like, you know, we did plus slash and that's like okay how do we do product, they like those of us time slash, and I show them backslash like how do we do a cumulative product", "tokens": [865, 11, 2293, 13, 286, 914, 567, 2738, 341, 11, 291, 458, 11, 983, 820, 4238, 3895, 312, 1674, 293, 4238, 12771, 312, 512, 411, 11, 291, 458, 11, 321, 630, 1804, 17330, 293, 300, 311, 411, 1392, 577, 360, 321, 360, 1674, 11, 436, 411, 729, 295, 505, 565, 17330, 11, 293, 286, 855, 552, 646, 10418, 1299, 411, 577, 360, 321, 360, 257, 38379, 1674], "temperature": 0.0, "avg_logprob": -0.3009282625638522, "compression_ratio": 1.8221343873517786, "no_speech_prob": 0.00013977197522763163}, {"id": 363, "seek": 354056, "start": 3540.56, "end": 3543.56, "text": " and that's obviously times backslash.", "tokens": [293, 300, 311, 2745, 1413, 646, 10418, 1299, 13], "temperature": 0.0, "avg_logprob": -0.1957048069347035, "compression_ratio": 1.4816753926701571, "no_speech_prob": 1.2218100891914219e-05}, {"id": 364, "seek": 354056, "start": 3543.56, "end": 3559.56, "text": " Yeah, this stuff. And, but, you know, a large group of adults can't can't handle this because I'll put stuff on Twitter I'll be like here's a cool thing in APL, and like half the replies will be like, well that's line noise that's not intuitive.", "tokens": [865, 11, 341, 1507, 13, 400, 11, 457, 11, 291, 458, 11, 257, 2416, 1594, 295, 8865, 393, 380, 393, 380, 4813, 341, 570, 286, 603, 829, 1507, 322, 5794, 286, 603, 312, 411, 510, 311, 257, 1627, 551, 294, 5372, 43, 11, 293, 411, 1922, 264, 42289, 486, 312, 411, 11, 731, 300, 311, 1622, 5658, 300, 311, 406, 21769, 13], "temperature": 0.0, "avg_logprob": -0.1957048069347035, "compression_ratio": 1.4816753926701571, "no_speech_prob": 1.2218100891914219e-05}, {"id": 365, "seek": 355956, "start": 3559.56, "end": 3570.56, "text": " It's this classic thing that it's this classic thing that I have a son always say it's like the difference between what you said that you don't understand it, or is it that it's hard.", "tokens": [467, 311, 341, 7230, 551, 300, 309, 311, 341, 7230, 551, 300, 286, 362, 257, 1872, 1009, 584, 309, 311, 411, 264, 2649, 1296, 437, 291, 848, 300, 291, 500, 380, 1223, 309, 11, 420, 307, 309, 300, 309, 311, 1152, 13], "temperature": 0.0, "avg_logprob": -0.18656351016117975, "compression_ratio": 1.8333333333333333, "no_speech_prob": 3.647115227067843e-05}, {"id": 366, "seek": 355956, "start": 3570.56, "end": 3574.56, "text": " And, you know, kids don't know, you know, for kids, everything's new.", "tokens": [400, 11, 291, 458, 11, 2301, 500, 380, 458, 11, 291, 458, 11, 337, 2301, 11, 1203, 311, 777, 13], "temperature": 0.0, "avg_logprob": -0.18656351016117975, "compression_ratio": 1.8333333333333333, "no_speech_prob": 3.647115227067843e-05}, {"id": 367, "seek": 355956, "start": 3574.56, "end": 3581.56, "text": " So that you know they see something they've never seen before they just like teach me that, or else adults, or at least a good chunk of adults just like.", "tokens": [407, 300, 291, 458, 436, 536, 746, 436, 600, 1128, 1612, 949, 436, 445, 411, 2924, 385, 300, 11, 420, 1646, 8865, 11, 420, 412, 1935, 257, 665, 16635, 295, 8865, 445, 411, 13], "temperature": 0.0, "avg_logprob": -0.18656351016117975, "compression_ratio": 1.8333333333333333, "no_speech_prob": 3.647115227067843e-05}, {"id": 368, "seek": 358156, "start": 3581.56, "end": 3589.56, "text": " I don't really understand that therefore it's too hard for me therefore I'm going to belittle the very idea of the thing.", "tokens": [286, 500, 380, 534, 1223, 300, 4412, 309, 311, 886, 1152, 337, 385, 4412, 286, 478, 516, 281, 989, 703, 264, 588, 1558, 295, 264, 551, 13], "temperature": 0.0, "avg_logprob": -0.16443496639445676, "compression_ratio": 1.7459016393442623, "no_speech_prob": 2.8401711460901424e-05}, {"id": 369, "seek": 358156, "start": 3589.56, "end": 3596.56, "text": " I did it I did a tacit program on one liner on a PL farm the other day and somebody said that looks like Greek to me.", "tokens": [286, 630, 309, 286, 630, 257, 25018, 270, 1461, 322, 472, 24468, 322, 257, 6999, 5421, 264, 661, 786, 293, 2618, 848, 300, 1542, 411, 10281, 281, 385, 13], "temperature": 0.0, "avg_logprob": -0.16443496639445676, "compression_ratio": 1.7459016393442623, "no_speech_prob": 2.8401711460901424e-05}, {"id": 370, "seek": 358156, "start": 3596.56, "end": 3600.56, "text": " I said, well, Greek looks like Greek to me because I don't know Greek.", "tokens": [286, 848, 11, 731, 11, 10281, 1542, 411, 10281, 281, 385, 570, 286, 500, 380, 458, 10281, 13], "temperature": 0.0, "avg_logprob": -0.16443496639445676, "compression_ratio": 1.7459016393442623, "no_speech_prob": 2.8401711460901424e-05}, {"id": 371, "seek": 358156, "start": 3600.56, "end": 3606.56, "text": " I mean, sure, if you don't know it. Absolutely it looks silly. Yeah, if you know it, then it's, it's not that hard.", "tokens": [286, 914, 11, 988, 11, 498, 291, 500, 380, 458, 309, 13, 7021, 309, 1542, 11774, 13, 865, 11, 498, 291, 458, 309, 11, 550, 309, 311, 11, 309, 311, 406, 300, 1152, 13], "temperature": 0.0, "avg_logprob": -0.16443496639445676, "compression_ratio": 1.7459016393442623, "no_speech_prob": 2.8401711460901424e-05}, {"id": 372, "seek": 360656, "start": 3606.56, "end": 3619.56, "text": " I will say like, you know, a lot of people have put a lot of hard work into resources for a PL and J teaching but I think there's still a long way to go.", "tokens": [286, 486, 584, 411, 11, 291, 458, 11, 257, 688, 295, 561, 362, 829, 257, 688, 295, 1152, 589, 666, 3593, 337, 257, 6999, 293, 508, 4571, 457, 286, 519, 456, 311, 920, 257, 938, 636, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.11258315180873012, "compression_ratio": 1.69140625, "no_speech_prob": 2.9299111702130176e-05}, {"id": 373, "seek": 360656, "start": 3619.56, "end": 3624.56, "text": " And one of the challenges is, it's like when I was learning Chinese.", "tokens": [400, 472, 295, 264, 4759, 307, 11, 309, 311, 411, 562, 286, 390, 2539, 4649, 13], "temperature": 0.0, "avg_logprob": -0.11258315180873012, "compression_ratio": 1.69140625, "no_speech_prob": 2.9299111702130176e-05}, {"id": 374, "seek": 360656, "start": 3624.56, "end": 3627.56, "text": " I really wanted to, I like the idea of learning Chinese.", "tokens": [286, 534, 1415, 281, 11, 286, 411, 264, 1558, 295, 2539, 4649, 13], "temperature": 0.0, "avg_logprob": -0.11258315180873012, "compression_ratio": 1.69140625, "no_speech_prob": 2.9299111702130176e-05}, {"id": 375, "seek": 360656, "start": 3627.56, "end": 3634.56, "text": " New words by looking them up in a Chinese dictionary. But of course I didn't know what the characters in the dictionary meant so I couldn't look them up.", "tokens": [1873, 2283, 538, 1237, 552, 493, 294, 257, 4649, 25890, 13, 583, 295, 1164, 286, 994, 380, 458, 437, 264, 4342, 294, 264, 25890, 4140, 370, 286, 2809, 380, 574, 552, 493, 13], "temperature": 0.0, "avg_logprob": -0.11258315180873012, "compression_ratio": 1.69140625, "no_speech_prob": 2.9299111702130176e-05}, {"id": 376, "seek": 363456, "start": 3634.56, "end": 3640.56, "text": " So when I learned Chinese I really spent the first 18 months, just focused on learning characters.", "tokens": [407, 562, 286, 3264, 4649, 286, 534, 4418, 264, 700, 2443, 2493, 11, 445, 5178, 322, 2539, 4342, 13], "temperature": 0.0, "avg_logprob": -0.07795514765473985, "compression_ratio": 1.5475285171102662, "no_speech_prob": 1.3840215615346096e-05}, {"id": 377, "seek": 363456, "start": 3640.56, "end": 3649.56, "text": " So I got through 6000 characters in 18 months of very hard work. And then I could start looking things up in dictionary.", "tokens": [407, 286, 658, 807, 41789, 4342, 294, 2443, 2493, 295, 588, 1152, 589, 13, 400, 550, 286, 727, 722, 1237, 721, 493, 294, 25890, 13], "temperature": 0.0, "avg_logprob": -0.07795514765473985, "compression_ratio": 1.5475285171102662, "no_speech_prob": 1.3840215615346096e-05}, {"id": 378, "seek": 363456, "start": 3649.56, "end": 3663.56, "text": " My hope is to do a similar thing for APL like for these study groups, I want to try to find a way to introduce every cliff in an order that never refers to glyphs you haven't learned yet.", "tokens": [1222, 1454, 307, 281, 360, 257, 2531, 551, 337, 5372, 43, 411, 337, 613, 2979, 3935, 11, 286, 528, 281, 853, 281, 915, 257, 636, 281, 5366, 633, 22316, 294, 364, 1668, 300, 1128, 14942, 281, 22633, 950, 82, 291, 2378, 380, 3264, 1939, 13], "temperature": 0.0, "avg_logprob": -0.07795514765473985, "compression_ratio": 1.5475285171102662, "no_speech_prob": 1.3840215615346096e-05}, {"id": 379, "seek": 366356, "start": 3663.56, "end": 3674.56, "text": " So like that's something I don't feel like we really have and so that then you can look up stuff in the dialogue documentation, because now still I don't know that many glyphs.", "tokens": [407, 411, 300, 311, 746, 286, 500, 380, 841, 411, 321, 534, 362, 293, 370, 300, 550, 291, 393, 574, 493, 1507, 294, 264, 10221, 14333, 11, 570, 586, 920, 286, 500, 380, 458, 300, 867, 22633, 950, 82, 13], "temperature": 0.0, "avg_logprob": -0.13752835926256682, "compression_ratio": 1.838095238095238, "no_speech_prob": 0.00011400208313716576}, {"id": 380, "seek": 366356, "start": 3674.56, "end": 3684.56, "text": " So like most of the stuff that documentation I don't understand because it explains glyphs using glyphs I don't yet know and then I look those up and those are the used explain things with glyphs I don't know.", "tokens": [407, 411, 881, 295, 264, 1507, 300, 14333, 286, 500, 380, 1223, 570, 309, 13948, 22633, 950, 82, 1228, 22633, 950, 82, 286, 500, 380, 1939, 458, 293, 550, 286, 574, 729, 493, 293, 729, 366, 264, 1143, 2903, 721, 365, 22633, 950, 82, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.13752835926256682, "compression_ratio": 1.838095238095238, "no_speech_prob": 0.00011400208313716576}, {"id": 381, "seek": 368456, "start": 3684.56, "end": 3698.56, "text": " So, you know, step one for me is I think we're just going to go in through and try to teach what every glyph is. And then I feel like we should be able to study this better together because then we can actually read the documentation, you know,", "tokens": [407, 11, 291, 458, 11, 1823, 472, 337, 385, 307, 286, 519, 321, 434, 445, 516, 281, 352, 294, 807, 293, 853, 281, 2924, 437, 633, 22633, 950, 307, 13, 400, 550, 286, 841, 411, 321, 820, 312, 1075, 281, 2979, 341, 1101, 1214, 570, 550, 321, 393, 767, 1401, 264, 14333, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.11134916328522096, "compression_ratio": 1.538812785388128, "no_speech_prob": 8.083586726570502e-05}, {"id": 382, "seek": 368456, "start": 3698.56, "end": 3702.56, "text": " going to publish these sessions online.", "tokens": [516, 281, 11374, 613, 11081, 2950, 13], "temperature": 0.0, "avg_logprob": -0.11134916328522096, "compression_ratio": 1.538812785388128, "no_speech_prob": 8.083586726570502e-05}, {"id": 383, "seek": 368456, "start": 3702.56, "end": 3707.56, "text": " Yeah, so the study group will be recorded as videos.", "tokens": [865, 11, 370, 264, 2979, 1594, 486, 312, 8287, 382, 2145, 13], "temperature": 0.0, "avg_logprob": -0.11134916328522096, "compression_ratio": 1.538812785388128, "no_speech_prob": 8.083586726570502e-05}, {"id": 384, "seek": 370756, "start": 3707.56, "end": 3716.56, "text": " But I also then want to actually create, you know, written materials using Jupiter, which I will then publish. That's my goal.", "tokens": [583, 286, 611, 550, 528, 281, 767, 1884, 11, 291, 458, 11, 3720, 5319, 1228, 24567, 11, 597, 286, 486, 550, 11374, 13, 663, 311, 452, 3387, 13], "temperature": 0.0, "avg_logprob": -0.12420286851770737, "compression_ratio": 1.532994923857868, "no_speech_prob": 2.4253002266050316e-05}, {"id": 385, "seek": 370756, "start": 3716.56, "end": 3729.56, "text": " So, when you said very much resonates with me that I often find myself in a when teaching people this this bind that to explain everything I need to have everything explained.", "tokens": [407, 11, 562, 291, 848, 588, 709, 41051, 365, 385, 300, 286, 2049, 915, 2059, 294, 257, 562, 4571, 561, 341, 341, 14786, 300, 281, 2903, 1203, 286, 643, 281, 362, 1203, 8825, 13], "temperature": 0.0, "avg_logprob": -0.12420286851770737, "compression_ratio": 1.532994923857868, "no_speech_prob": 2.4253002266050316e-05}, {"id": 386, "seek": 372956, "start": 3729.56, "end": 3742.56, "text": " And I think so and especially it comes down to, in order to explain what many of these gifts are doing. I need some fancy arrays, if I restrict myself to simple vectors and scalars then I can't really show their power.", "tokens": [400, 286, 519, 370, 293, 2318, 309, 1487, 760, 281, 11, 294, 1668, 281, 2903, 437, 867, 295, 613, 11449, 366, 884, 13, 286, 643, 512, 10247, 41011, 11, 498, 286, 7694, 2059, 281, 2199, 18875, 293, 15664, 685, 550, 286, 393, 380, 534, 855, 641, 1347, 13], "temperature": 0.0, "avg_logprob": -0.16186939940160636, "compression_ratio": 1.5820895522388059, "no_speech_prob": 7.642559467058163e-06}, {"id": 387, "seek": 372956, "start": 3742.56, "end": 3758.56, "text": " And I cannot create these higher rank arrays, without already using those glyphs. And so hopefully, it was this long running project since like 2015 I think this is to add a literal array notation to a PL.", "tokens": [400, 286, 2644, 1884, 613, 2946, 6181, 41011, 11, 1553, 1217, 1228, 729, 22633, 950, 82, 13, 400, 370, 4696, 11, 309, 390, 341, 938, 2614, 1716, 1670, 411, 7546, 286, 519, 341, 307, 281, 909, 257, 20411, 10225, 24657, 281, 257, 6999, 13], "temperature": 0.0, "avg_logprob": -0.16186939940160636, "compression_ratio": 1.5820895522388059, "no_speech_prob": 7.642559467058163e-06}, {"id": 388, "seek": 375856, "start": 3758.56, "end": 3770.56, "text": " And then there is a way in, then you can start by looking at an array and then you can start manipulating and see the effects of the glyphs and into it from there, what they do.", "tokens": [400, 550, 456, 307, 257, 636, 294, 11, 550, 291, 393, 722, 538, 1237, 412, 364, 10225, 293, 550, 291, 393, 722, 40805, 293, 536, 264, 5065, 295, 264, 22633, 950, 82, 293, 666, 309, 490, 456, 11, 437, 436, 360, 13], "temperature": 0.0, "avg_logprob": -0.11664385648117852, "compression_ratio": 1.6390041493775933, "no_speech_prob": 3.268586806370877e-05}, {"id": 389, "seek": 375856, "start": 3770.56, "end": 3787.56, "text": " Yeah, no, I think that'll be very very helpful. And in the meantime, you know my approach with the kids has just been to teach row quite early on it so row is the equivalent of reshape in Python most Python libraries.", "tokens": [865, 11, 572, 11, 286, 519, 300, 603, 312, 588, 588, 4961, 13, 400, 294, 264, 14991, 11, 291, 458, 452, 3109, 365, 264, 2301, 575, 445, 668, 281, 2924, 5386, 1596, 2440, 322, 309, 370, 5386, 307, 264, 10344, 295, 725, 42406, 294, 15329, 881, 15329, 15148, 13], "temperature": 0.0, "avg_logprob": -0.11664385648117852, "compression_ratio": 1.6390041493775933, "no_speech_prob": 3.268586806370877e-05}, {"id": 390, "seek": 378756, "start": 3787.56, "end": 3799.56, "text": " And, yeah, so once you know how to reshape you can start with a vector and shape it to anything you like it it's you know, it's not a difficult concept to understand so I think that yeah basically the trick at the moment is just to say okay, you know", "tokens": [400, 11, 1338, 11, 370, 1564, 291, 458, 577, 281, 725, 42406, 291, 393, 722, 365, 257, 8062, 293, 3909, 309, 281, 1340, 291, 411, 309, 309, 311, 291, 458, 11, 309, 311, 406, 257, 2252, 3410, 281, 1223, 370, 286, 519, 300, 1338, 1936, 264, 4282, 412, 264, 1623, 307, 445, 281, 584, 1392, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.1553368260783534, "compression_ratio": 1.5625, "no_speech_prob": 3.821830250672065e-05}, {"id": 391, "seek": 379956, "start": 3799.56, "end": 3817.56, "text": " the dictionary of APL, one of the first things we will learn is, is row. And that was really fun with the kids doing monadic row, you know, to be like okay well what's row of this what's row of that and okay what's row of row of this and then what's row of row of row, which then", "tokens": [264, 25890, 295, 5372, 43, 11, 472, 295, 264, 700, 721, 321, 486, 1466, 307, 11, 307, 5386, 13, 400, 300, 390, 534, 1019, 365, 264, 2301, 884, 1108, 43341, 5386, 11, 291, 458, 11, 281, 312, 411, 1392, 731, 437, 311, 5386, 295, 341, 437, 311, 5386, 295, 300, 293, 1392, 437, 311, 5386, 295, 5386, 295, 341, 293, 550, 437, 311, 5386, 295, 5386, 295, 5386, 11, 597, 550], "temperature": 0.0, "avg_logprob": -0.1641381072998047, "compression_ratio": 1.74375, "no_speech_prob": 6.919291627127677e-05}, {"id": 392, "seek": 381756, "start": 3817.56, "end": 3833.56, "text": " led me to the to the Storman poem about how does it row row row is one, etc etc, which they loved as well.", "tokens": [4684, 385, 281, 264, 281, 264, 20494, 282, 13065, 466, 577, 775, 309, 5386, 5386, 5386, 307, 472, 11, 5183, 5183, 11, 597, 436, 4333, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.2176902347140842, "compression_ratio": 1.3243243243243243, "no_speech_prob": 1.722132583381608e-05}, {"id": 393, "seek": 381756, "start": 3833.56, "end": 3835.56, "text": " Yeah, we'll link that in the show notes.", "tokens": [865, 11, 321, 603, 2113, 300, 294, 264, 855, 5570, 13], "temperature": 0.0, "avg_logprob": -0.2176902347140842, "compression_ratio": 1.3243243243243243, "no_speech_prob": 1.722132583381608e-05}, {"id": 394, "seek": 383556, "start": 3835.56, "end": 3848.56, "text": " Yeah, while you were saying all that, that really resonated me with me when I first started learning APL is like one of the first things that happened when I was like oh okay you can you can fold you can map.", "tokens": [865, 11, 1339, 291, 645, 1566, 439, 300, 11, 300, 534, 47957, 385, 365, 385, 562, 286, 700, 1409, 2539, 5372, 43, 307, 411, 472, 295, 264, 700, 721, 300, 2011, 562, 286, 390, 411, 1954, 1392, 291, 393, 291, 393, 4860, 291, 393, 4471, 13], "temperature": 0.0, "avg_logprob": -0.12010153983403178, "compression_ratio": 1.7915057915057915, "no_speech_prob": 5.771333690063329e-06}, {"id": 395, "seek": 383556, "start": 3848.56, "end": 3861.56, "text": " So like how do you filter you know what are the classic, you know, three functional things and the problem with APL and array languages is they don't have an equivalent filter that takes a predicate function they have a filter that is called compress that", "tokens": [407, 411, 577, 360, 291, 6608, 291, 458, 437, 366, 264, 7230, 11, 291, 458, 11, 1045, 11745, 721, 293, 264, 1154, 365, 5372, 43, 293, 10225, 8650, 307, 436, 500, 380, 362, 364, 10344, 6608, 300, 2516, 257, 3852, 8700, 2445, 436, 362, 257, 6608, 300, 307, 1219, 14778, 300], "temperature": 0.0, "avg_logprob": -0.12010153983403178, "compression_ratio": 1.7915057915057915, "no_speech_prob": 5.771333690063329e-06}, {"id": 396, "seek": 386156, "start": 3861.56, "end": 3876.56, "text": " takes a mask that you know drops anything that corresponds to a zero. And it wasn't until a few months later that I ended up discovering it but for both APL and the newer APL BQN there's these two sites, Adam was the one that wrote the APL one apple", "tokens": [2516, 257, 6094, 300, 291, 458, 11438, 1340, 300, 23249, 281, 257, 4018, 13, 400, 309, 2067, 380, 1826, 257, 1326, 2493, 1780, 300, 286, 4590, 493, 24773, 309, 457, 337, 1293, 5372, 43, 293, 264, 17628, 5372, 43, 363, 48, 45, 456, 311, 613, 732, 7533, 11, 7938, 390, 264, 472, 300, 4114, 264, 5372, 43, 472, 10606], "temperature": 0.0, "avg_logprob": -0.11028648558117095, "compression_ratio": 1.447674418604651, "no_speech_prob": 1.544424048915971e-05}, {"id": 397, "seek": 387656, "start": 3876.56, "end": 3892.56, "text": " info, and they can create that info I also think, and so you can basically semantically search for what you're trying to do. And it'll give you small expressions that do that. So if you type in the word filter, which is what you would call it coming from you know a", "tokens": [13614, 11, 293, 436, 393, 1884, 300, 13614, 286, 611, 519, 11, 293, 370, 291, 393, 1936, 4361, 49505, 3164, 337, 437, 291, 434, 1382, 281, 360, 13, 400, 309, 603, 976, 291, 1359, 15277, 300, 360, 300, 13, 407, 498, 291, 2010, 294, 264, 1349, 6608, 11, 597, 307, 437, 291, 576, 818, 309, 1348, 490, 291, 458, 257], "temperature": 0.0, "avg_logprob": -0.08487725890843215, "compression_ratio": 1.7765957446808511, "no_speech_prob": 1.7229467630386353e-05}, {"id": 398, "seek": 387656, "start": 3892.56, "end": 3905.56, "text": " functional language or even I think Python calls it filter, you can get a list of small expressions and really really often sometimes you need to know the exact thing that it's called, like one time I was searching for you know all the", "tokens": [11745, 2856, 420, 754, 286, 519, 15329, 5498, 309, 6608, 11, 291, 393, 483, 257, 1329, 295, 1359, 15277, 293, 534, 534, 2049, 2171, 291, 643, 281, 458, 264, 1900, 551, 300, 309, 311, 1219, 11, 411, 472, 565, 286, 390, 10808, 337, 291, 458, 439, 264], "temperature": 0.0, "avg_logprob": -0.08487725890843215, "compression_ratio": 1.7765957446808511, "no_speech_prob": 1.7229467630386353e-05}, {"id": 399, "seek": 390556, "start": 3905.56, "end": 3913.56, "text": " combinations or permutations and really what I was looking for was power set. And so, until you have that, you know the word power set.", "tokens": [21267, 420, 4784, 325, 763, 293, 534, 437, 286, 390, 1237, 337, 390, 1347, 992, 13, 400, 370, 11, 1826, 291, 362, 300, 11, 291, 458, 264, 1349, 1347, 992, 13], "temperature": 0.0, "avg_logprob": -0.08506821273663721, "compression_ratio": 1.751054852320675, "no_speech_prob": 3.479500810499303e-05}, {"id": 400, "seek": 390556, "start": 3913.56, "end": 3924.56, "text": " It's you know it's a fuzzy search right so but it's still a very very useful tool when it's like you said you're trying to learn something like Chinese and it's like well where do I even start I don't, I don't know the language to search the words", "tokens": [467, 311, 291, 458, 309, 311, 257, 34710, 3164, 558, 370, 457, 309, 311, 920, 257, 588, 588, 4420, 2290, 562, 309, 311, 411, 291, 848, 291, 434, 1382, 281, 1466, 746, 411, 4649, 293, 309, 311, 411, 731, 689, 360, 286, 754, 722, 286, 500, 380, 11, 286, 500, 380, 458, 264, 2856, 281, 3164, 264, 2283], "temperature": 0.0, "avg_logprob": -0.08506821273663721, "compression_ratio": 1.751054852320675, "no_speech_prob": 3.479500810499303e-05}, {"id": 401, "seek": 390556, "start": 3924.56, "end": 3926.56, "text": " to search for.", "tokens": [281, 3164, 337, 13], "temperature": 0.0, "avg_logprob": -0.08506821273663721, "compression_ratio": 1.751054852320675, "no_speech_prob": 3.479500810499303e-05}, {"id": 402, "seek": 390556, "start": 3926.56, "end": 3928.56, "text": " But yeah, it is.", "tokens": [583, 1338, 11, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.08506821273663721, "compression_ratio": 1.751054852320675, "no_speech_prob": 3.479500810499303e-05}, {"id": 403, "seek": 392856, "start": 3928.56, "end": 3942.56, "text": " I agree that there's a large room for improvement and how to onboard people without them immediately going, like you said this looks like hieroglyphics which I think Iverson considered a compliment like there's some anecdote I've heard where someone was like", "tokens": [286, 3986, 300, 456, 311, 257, 2416, 1808, 337, 10444, 293, 577, 281, 24033, 561, 1553, 552, 4258, 516, 11, 411, 291, 848, 341, 1542, 411, 3296, 38353, 950, 1167, 597, 286, 519, 286, 840, 266, 4888, 257, 16250, 411, 456, 311, 512, 49845, 286, 600, 2198, 689, 1580, 390, 411], "temperature": 0.0, "avg_logprob": -0.10447039045729078, "compression_ratio": 1.745819397993311, "no_speech_prob": 1.66961362992879e-05}, {"id": 404, "seek": 392856, "start": 3942.56, "end": 3945.56, "text": " this is hieroglyphics and he says yes exactly.", "tokens": [341, 307, 3296, 38353, 950, 1167, 293, 415, 1619, 2086, 2293, 13], "temperature": 0.0, "avg_logprob": -0.10447039045729078, "compression_ratio": 1.745819397993311, "no_speech_prob": 1.66961362992879e-05}, {"id": 405, "seek": 392856, "start": 3945.56, "end": 3957.56, "text": " And then they think the other thing like that I want to do is help in particular Python programmers and maybe also do something for JavaScript programmers which are the two most popular languages, like at the moment.", "tokens": [400, 550, 436, 519, 264, 661, 551, 411, 300, 286, 528, 281, 360, 307, 854, 294, 1729, 15329, 41504, 293, 1310, 611, 360, 746, 337, 15778, 41504, 597, 366, 264, 732, 881, 3743, 8650, 11, 411, 412, 264, 1623, 13], "temperature": 0.0, "avg_logprob": -0.10447039045729078, "compression_ratio": 1.745819397993311, "no_speech_prob": 1.66961362992879e-05}, {"id": 406, "seek": 395756, "start": 3957.56, "end": 3974.56, "text": " Like a lot of the tutorials for stuff like Jay or whatever like J for C programmers, you know, great book but most people aren't C programmers, and also a lot of the stuff like, you know, it'd be so much easier if somebody just like said to me early on.", "tokens": [1743, 257, 688, 295, 264, 17616, 337, 1507, 411, 11146, 420, 2035, 411, 508, 337, 383, 41504, 11, 291, 458, 11, 869, 1446, 457, 881, 561, 3212, 380, 383, 41504, 11, 293, 611, 257, 688, 295, 264, 1507, 411, 11, 291, 458, 11, 309, 1116, 312, 370, 709, 3571, 498, 2618, 445, 411, 848, 281, 385, 2440, 322, 13], "temperature": 0.0, "avg_logprob": -0.18888276720803882, "compression_ratio": 1.5911949685534592, "no_speech_prob": 3.5333050618646666e-05}, {"id": 407, "seek": 397456, "start": 3974.56, "end": 3987.56, "text": " Oh, you know, just, just the same as partial in Python, you know, or, like, you know, putting things in a box with the health of box if somebody basically said oh it's basically the same as a reference.", "tokens": [876, 11, 291, 458, 11, 445, 11, 445, 264, 912, 382, 14641, 294, 15329, 11, 291, 458, 11, 420, 11, 411, 11, 291, 458, 11, 3372, 721, 294, 257, 2424, 365, 264, 1585, 295, 2424, 498, 2618, 1936, 848, 1954, 309, 311, 1936, 264, 912, 382, 257, 6408, 13], "temperature": 0.0, "avg_logprob": -0.230732933949616, "compression_ratio": 1.849802371541502, "no_speech_prob": 1.8623471987666562e-05}, {"id": 408, "seek": 397456, "start": 3987.56, "end": 4003.56, "text": " It's like oh okay, you know, I think it might have your podcast somebody said us like void star. Yeah, okay. You know this is kind of like lack of just saying like, this is actually the same thing as blah in in Python and JavaScript so I do want to do some kind of.", "tokens": [467, 311, 411, 1954, 1392, 11, 291, 458, 11, 286, 519, 309, 1062, 362, 428, 7367, 2618, 848, 505, 411, 22009, 3543, 13, 865, 11, 1392, 13, 509, 458, 341, 307, 733, 295, 411, 5011, 295, 445, 1566, 411, 11, 341, 307, 767, 264, 912, 551, 382, 12288, 294, 294, 15329, 293, 15778, 370, 286, 360, 528, 281, 360, 512, 733, 295, 13], "temperature": 0.0, "avg_logprob": -0.230732933949616, "compression_ratio": 1.849802371541502, "no_speech_prob": 1.8623471987666562e-05}, {"id": 409, "seek": 400356, "start": 4003.56, "end": 4014.56, "text": " Yeah, mapping. Yeah, like that, particularly for kind of NumPy programmers and stuff because a lot of it's so extremely similar.", "tokens": [865, 11, 18350, 13, 865, 11, 411, 300, 11, 4098, 337, 733, 295, 22592, 47, 88, 41504, 293, 1507, 570, 257, 688, 295, 309, 311, 370, 4664, 2531, 13], "temperature": 0.0, "avg_logprob": -0.1030416777639678, "compression_ratio": 1.1743119266055047, "no_speech_prob": 3.821404243353754e-05}, {"id": 410, "seek": 401456, "start": 4014.56, "end": 4039.56, "text": " So it would be nice to kind of say like okay well this is you know Jay maps things over leading axes which is exactly the same as NumPy does it over trailing axes so if you know the NumPy rules you basically know the, the J rules.", "tokens": [407, 309, 576, 312, 1481, 281, 733, 295, 584, 411, 1392, 731, 341, 307, 291, 458, 11146, 11317, 721, 670, 5775, 35387, 597, 307, 2293, 264, 912, 382, 22592, 47, 88, 775, 309, 670, 944, 4883, 35387, 370, 498, 291, 458, 264, 22592, 47, 88, 4474, 291, 1936, 458, 264, 11, 264, 508, 4474, 13], "temperature": 0.0, "avg_logprob": -0.1937971438391734, "compression_ratio": 1.5032679738562091, "no_speech_prob": 2.3545117073808797e-05}, {"id": 411, "seek": 403956, "start": 4039.56, "end": 4056.56, "text": " If you send somebody down the wrong road with a metaphor that almost works in some of these areas. It can really be challenging for them because they see it in with you know through their lens of their experience, but that would say in this area it would work differently", "tokens": [759, 291, 2845, 2618, 760, 264, 2085, 3060, 365, 257, 19157, 300, 1920, 1985, 294, 512, 295, 613, 3179, 13, 467, 393, 534, 312, 7595, 337, 552, 570, 436, 536, 309, 294, 365, 291, 458, 807, 641, 6765, 295, 641, 1752, 11, 457, 300, 576, 584, 294, 341, 1859, 309, 576, 589, 7614], "temperature": 0.0, "avg_logprob": -0.1347473188378345, "compression_ratio": 1.5738396624472575, "no_speech_prob": 5.731701457989402e-05}, {"id": 412, "seek": 403956, "start": 4056.56, "end": 4064.56, "text": " than it actually does. So, there is a challenge in that. And we find it even between APL BQN and Jay.", "tokens": [813, 309, 767, 775, 13, 407, 11, 456, 307, 257, 3430, 294, 300, 13, 400, 321, 915, 309, 754, 1296, 5372, 43, 363, 48, 45, 293, 11146, 13], "temperature": 0.0, "avg_logprob": -0.1347473188378345, "compression_ratio": 1.5738396624472575, "no_speech_prob": 5.731701457989402e-05}, {"id": 413, "seek": 406456, "start": 4064.56, "end": 4073.56, "text": " I'm trying to think of what we were talking about recently, it was transpose. The language is dyadic transposes they handle, they handle them differently.", "tokens": [286, 478, 1382, 281, 519, 295, 437, 321, 645, 1417, 466, 3938, 11, 309, 390, 25167, 13, 440, 2856, 307, 14584, 43341, 7132, 4201, 436, 4813, 11, 436, 4813, 552, 7614, 13], "temperature": 0.0, "avg_logprob": -0.1520864262300379, "compression_ratio": 1.6353591160220995, "no_speech_prob": 6.50106740067713e-05}, {"id": 414, "seek": 406456, "start": 4073.56, "end": 4080.56, "text": " They're functionally you can do the same things but you have to be aware that they are going to do it differently, according to the language.", "tokens": [814, 434, 2445, 379, 291, 393, 360, 264, 912, 721, 457, 291, 362, 281, 312, 3650, 300, 436, 366, 516, 281, 360, 309, 7614, 11, 4650, 281, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.1520864262300379, "compression_ratio": 1.6353591160220995, "no_speech_prob": 6.50106740067713e-05}, {"id": 415, "seek": 408056, "start": 4080.56, "end": 4097.5599999999995, "text": " Absolutely. But that's not a reason to throw out the analogy right like I think everybody agrees that that it's easier for an APL programmer to learn Jay, then for a CEO JavaScript programmer to learn Jay, you know, because there are, there are some ideas you understand", "tokens": [7021, 13, 583, 300, 311, 406, 257, 1778, 281, 3507, 484, 264, 21663, 558, 411, 286, 519, 2201, 26383, 300, 300, 309, 311, 3571, 337, 364, 5372, 43, 32116, 281, 1466, 11146, 11, 550, 337, 257, 9282, 15778, 32116, 281, 1466, 11146, 11, 291, 458, 11, 570, 456, 366, 11, 456, 366, 512, 3487, 291, 1223], "temperature": 0.0, "avg_logprob": -0.15371653238932292, "compression_ratio": 1.5, "no_speech_prob": 1.4967140486987773e-05}, {"id": 416, "seek": 409756, "start": 4097.56, "end": 4113.56, "text": " and you can actually say to people like okay well this is the rank conjunction in Jay and you may recognize this as being like the rank, you know, operator in APL. So if we can do something like that and say like oh well okay this is the you know this would do the same thing as, you know,", "tokens": [293, 291, 393, 767, 584, 281, 561, 411, 1392, 731, 341, 307, 264, 6181, 27482, 294, 11146, 293, 291, 815, 5521, 341, 382, 885, 411, 264, 6181, 11, 291, 458, 11, 12973, 294, 5372, 43, 13, 407, 498, 321, 393, 360, 746, 411, 300, 293, 584, 411, 1954, 731, 1392, 341, 307, 264, 291, 458, 341, 576, 360, 264, 912, 551, 382, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.19687856946672713, "compression_ratio": 1.680232558139535, "no_speech_prob": 1.4281130461313296e-05}, {"id": 417, "seek": 411356, "start": 4113.56, "end": 4133.56, "text": " permute.lar in PyTorch. It's like okay, I see it. Well as the maintainer of AppleCart, I'd like to throw in a little call to the listeners, like what Connor mentioned, I do fairly often get people saying well I couldn't find this and this and ask them what did you search for.", "tokens": [4784, 1169, 13, 2200, 294, 9953, 51, 284, 339, 13, 467, 311, 411, 1392, 11, 286, 536, 309, 13, 1042, 382, 264, 6909, 260, 295, 6373, 34, 446, 11, 286, 1116, 411, 281, 3507, 294, 257, 707, 818, 281, 264, 23274, 11, 411, 437, 33133, 2835, 11, 286, 360, 6457, 2049, 483, 561, 1566, 731, 286, 2809, 380, 915, 341, 293, 341, 293, 1029, 552, 437, 630, 291, 3164, 337, 13], "temperature": 0.0, "avg_logprob": -0.2686730448404948, "compression_ratio": 1.4680851063829787, "no_speech_prob": 3.821207792498171e-05}, {"id": 418, "seek": 413356, "start": 4133.56, "end": 4146.56, "text": " And if you let me know contact me by whatever means, say if you couldn't find something either because it's altogether missing and I might be able to edit, or tell me what you search for and couldn't find, or maybe you found it later by searching for something else,", "tokens": [400, 498, 291, 718, 385, 458, 3385, 385, 538, 2035, 1355, 11, 584, 498, 291, 2809, 380, 915, 746, 2139, 570, 309, 311, 19051, 5361, 293, 286, 1062, 312, 1075, 281, 8129, 11, 420, 980, 385, 437, 291, 3164, 337, 293, 2809, 380, 915, 11, 420, 1310, 291, 1352, 309, 1780, 538, 10808, 337, 746, 1646, 11], "temperature": 0.0, "avg_logprob": -0.1335944474912157, "compression_ratio": 1.7067669172932332, "no_speech_prob": 9.97074857878033e-06}, {"id": 419, "seek": 413356, "start": 4146.56, "end": 4158.56, "text": " and I'll add those keywords for future users. And I have put in a lot of like function names from other programming languages so that you can search for those and find the APL equivalent.", "tokens": [293, 286, 603, 909, 729, 21009, 337, 2027, 5022, 13, 400, 286, 362, 829, 294, 257, 688, 295, 411, 2445, 5288, 490, 661, 9410, 8650, 370, 300, 291, 393, 3164, 337, 729, 293, 915, 264, 5372, 43, 10344, 13], "temperature": 0.0, "avg_logprob": -0.1335944474912157, "compression_ratio": 1.7067669172932332, "no_speech_prob": 9.97074857878033e-06}, {"id": 420, "seek": 415856, "start": 4158.56, "end": 4171.56, "text": " I will say, I feel like either I'm not smart enough to use applecart.info, or I haven't got the right tutorial yet because I went there, I've been there a few times.", "tokens": [286, 486, 584, 11, 286, 841, 411, 2139, 286, 478, 406, 4069, 1547, 281, 764, 10606, 44672, 13, 259, 16931, 11, 420, 286, 2378, 380, 658, 264, 558, 7073, 1939, 570, 286, 1437, 456, 11, 286, 600, 668, 456, 257, 1326, 1413, 13], "temperature": 0.0, "avg_logprob": -0.1247534888131278, "compression_ratio": 1.620408163265306, "no_speech_prob": 2.014276833506301e-05}, {"id": 421, "seek": 415856, "start": 4171.56, "end": 4185.56, "text": " And there's this like whole lot of like impressive looking stuff, and I just, I don't want to know what to do with it and then I sometimes click things and it sends me over to this tio.run that tells me like real time 0.02 seconds.", "tokens": [400, 456, 311, 341, 411, 1379, 688, 295, 411, 8992, 1237, 1507, 11, 293, 286, 445, 11, 286, 500, 380, 528, 281, 458, 437, 281, 360, 365, 309, 293, 550, 286, 2171, 2052, 721, 293, 309, 14790, 385, 670, 281, 341, 256, 1004, 13, 12997, 300, 5112, 385, 411, 957, 565, 1958, 13, 12756, 3949, 13], "temperature": 0.0, "avg_logprob": -0.1247534888131278, "compression_ratio": 1.620408163265306, "no_speech_prob": 2.014276833506301e-05}, {"id": 422, "seek": 418556, "start": 4185.56, "end": 4194.56, "text": " And I find it, you know, a little, not a little I have not yet I don't yet know how to use it.", "tokens": [400, 286, 915, 309, 11, 291, 458, 11, 257, 707, 11, 406, 257, 707, 286, 362, 406, 1939, 286, 500, 380, 1939, 458, 577, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.0839630506371939, "compression_ratio": 1.7336683417085428, "no_speech_prob": 2.391909401922021e-05}, {"id": 423, "seek": 418556, "start": 4194.56, "end": 4201.56, "text": " And so, you know, I guess given hearing you guys say this is a really useful tool that a lot of people put a lot of time into.", "tokens": [400, 370, 11, 291, 458, 11, 286, 2041, 2212, 4763, 291, 1074, 584, 341, 307, 257, 534, 4420, 2290, 300, 257, 688, 295, 561, 829, 257, 688, 295, 565, 666, 13], "temperature": 0.0, "avg_logprob": -0.0839630506371939, "compression_ratio": 1.7336683417085428, "no_speech_prob": 2.391909401922021e-05}, {"id": 424, "seek": 418556, "start": 4201.56, "end": 4208.56, "text": " I should obviously invest time learning how to use it, and maybe after doing that I should explain to people how to use it.", "tokens": [286, 820, 2745, 1963, 565, 2539, 577, 281, 764, 309, 11, 293, 1310, 934, 884, 300, 286, 820, 2903, 281, 561, 577, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.0839630506371939, "compression_ratio": 1.7336683417085428, "no_speech_prob": 2.391909401922021e-05}, {"id": 425, "seek": 420856, "start": 4208.56, "end": 4217.56, "text": " Thank you on it and there's also a little question mark icon one can click on and get to the I have tried the question mark icon.", "tokens": [1044, 291, 322, 309, 293, 456, 311, 611, 257, 707, 1168, 1491, 6528, 472, 393, 2052, 322, 293, 483, 281, 264, 286, 362, 3031, 264, 1168, 1491, 6528, 13], "temperature": 0.0, "avg_logprob": -0.22068867051457786, "compression_ratio": 1.542857142857143, "no_speech_prob": 7.719513087067753e-05}, {"id": 426, "seek": 420856, "start": 4217.56, "end": 4228.56, "text": " As well as I say it might just you know, I think this often happens with APL stuff, I often hit things I feel like maybe I'm not smart enough to understand this.", "tokens": [1018, 731, 382, 286, 584, 309, 1062, 445, 291, 458, 11, 286, 519, 341, 2049, 2314, 365, 5372, 43, 1507, 11, 286, 2049, 2045, 721, 286, 841, 411, 1310, 286, 478, 406, 4069, 1547, 281, 1223, 341, 13], "temperature": 0.0, "avg_logprob": -0.22068867051457786, "compression_ratio": 1.542857142857143, "no_speech_prob": 7.719513087067753e-05}, {"id": 427, "seek": 420856, "start": 4228.56, "end": 4232.56, "text": " Really don't think that's if you", "tokens": [4083, 500, 380, 519, 300, 311, 498, 291], "temperature": 0.0, "avg_logprob": -0.22068867051457786, "compression_ratio": 1.542857142857143, "no_speech_prob": 7.719513087067753e-05}, {"id": 428, "seek": 423256, "start": 4232.56, "end": 4244.56, "text": " we we humbly disagree. Yeah, I do recall you saying a few minutes ago that you managed to teach your, you know, four year old daughter like 12th grade or age 12 algebra.", "tokens": [321, 321, 1484, 25021, 14091, 13, 865, 11, 286, 360, 9901, 291, 1566, 257, 1326, 2077, 2057, 300, 291, 6453, 281, 2924, 428, 11, 291, 458, 11, 1451, 1064, 1331, 4653, 411, 2272, 392, 7204, 420, 3205, 2272, 21989, 13], "temperature": 0.0, "avg_logprob": -0.1790068686545432, "compression_ratio": 1.6282527881040891, "no_speech_prob": 6.0118527471786365e-05}, {"id": 429, "seek": 423256, "start": 4244.56, "end": 4258.56, "text": " I know I didn't I just gave her the app right it's like it's it. I've heard other parents have given it to their kids they also need to handle it. It's, it's just this fun game where you hatch dragon eggs by like dragging things around on the iPad screen, and it just,", "tokens": [286, 458, 286, 994, 380, 286, 445, 2729, 720, 264, 724, 558, 309, 311, 411, 309, 311, 309, 13, 286, 600, 2198, 661, 3152, 362, 2212, 309, 281, 641, 2301, 436, 611, 643, 281, 4813, 309, 13, 467, 311, 11, 309, 311, 445, 341, 1019, 1216, 689, 291, 17387, 12165, 6466, 538, 411, 24385, 721, 926, 322, 264, 12945, 2568, 11, 293, 309, 445, 11], "temperature": 0.0, "avg_logprob": -0.1790068686545432, "compression_ratio": 1.6282527881040891, "no_speech_prob": 6.0118527471786365e-05}, {"id": 430, "seek": 425856, "start": 4258.56, "end": 4274.56, "text": " it just shows that the things you're doing with dragons eggs are the rules of algebra, and after a while it starts to switch out some of the like monsters with symbols like x and y, you know, and it doesn't gradually gradually and at the end.", "tokens": [309, 445, 3110, 300, 264, 721, 291, 434, 884, 365, 27240, 6466, 366, 264, 4474, 295, 21989, 11, 293, 934, 257, 1339, 309, 3719, 281, 3679, 484, 512, 295, 264, 411, 15785, 365, 16944, 411, 2031, 293, 288, 11, 291, 458, 11, 293, 309, 1177, 380, 13145, 13145, 293, 412, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.18626426349986683, "compression_ratio": 1.7595419847328244, "no_speech_prob": 3.534461575327441e-05}, {"id": 431, "seek": 425856, "start": 4274.56, "end": 4286.56, "text": " It's like oh now you're doing algebra so I can't get any credit for that that's some very very clever people wrote a very cool. It really is an amazing program I homeschooled my son as well and we use that for algebra.", "tokens": [467, 311, 411, 1954, 586, 291, 434, 884, 21989, 370, 286, 393, 380, 483, 604, 5397, 337, 300, 300, 311, 512, 588, 588, 13494, 561, 4114, 257, 588, 1627, 13, 467, 534, 307, 364, 2243, 1461, 286, 7388, 21856, 292, 452, 1872, 382, 731, 293, 321, 764, 300, 337, 21989, 13], "temperature": 0.0, "avg_logprob": -0.18626426349986683, "compression_ratio": 1.7595419847328244, "no_speech_prob": 3.534461575327441e-05}, {"id": 432, "seek": 428656, "start": 4286.56, "end": 4297.56, "text": " It's a bit more age appropriate but it's, I, I looked at that and said that that really is well put together, it's it's an amazing program.", "tokens": [467, 311, 257, 857, 544, 3205, 6854, 457, 309, 311, 11, 286, 11, 286, 2956, 412, 300, 293, 848, 300, 300, 534, 307, 731, 829, 1214, 11, 309, 311, 309, 311, 364, 2243, 1461, 13], "temperature": 0.0, "avg_logprob": -0.15471297044020432, "compression_ratio": 1.7335907335907337, "no_speech_prob": 1.5684876416344196e-05}, {"id": 433, "seek": 428656, "start": 4297.56, "end": 4301.56, "text": " I will say it'll be a dragon box IPO one day.", "tokens": [286, 486, 584, 309, 603, 312, 257, 12165, 2424, 50220, 472, 786, 13], "temperature": 0.0, "avg_logprob": -0.15471297044020432, "compression_ratio": 1.7335907335907337, "no_speech_prob": 1.5684876416344196e-05}, {"id": 434, "seek": 428656, "start": 4301.56, "end": 4314.56, "text": " It's not a bad idea. Not a bad idea at all. I was going to say when you're teaching somebody one of the big challenges when you're sort of trying to get a language across to a general audience is who is the audience because, as you say if you're if you're dealing", "tokens": [467, 311, 406, 257, 1578, 1558, 13, 1726, 257, 1578, 1558, 412, 439, 13, 286, 390, 516, 281, 584, 562, 291, 434, 4571, 2618, 472, 295, 264, 955, 4759, 562, 291, 434, 1333, 295, 1382, 281, 483, 257, 2856, 2108, 281, 257, 2674, 4034, 307, 567, 307, 264, 4034, 570, 11, 382, 291, 584, 498, 291, 434, 498, 291, 434, 6260], "temperature": 0.0, "avg_logprob": -0.15471297044020432, "compression_ratio": 1.7335907335907337, "no_speech_prob": 1.5684876416344196e-05}, {"id": 435, "seek": 431456, "start": 4314.56, "end": 4328.56, "text": " with kids or people who haven't been exposed to programming before. That's a very different audience and somebody might have been exposed to some other type of programming functional programming is a bit closer but if your procedural programmer", "tokens": [365, 2301, 420, 561, 567, 2378, 380, 668, 9495, 281, 9410, 949, 13, 663, 311, 257, 588, 819, 4034, 293, 2618, 1062, 362, 668, 9495, 281, 512, 661, 2010, 295, 9410, 11745, 9410, 307, 257, 857, 4966, 457, 498, 428, 43951, 32116], "temperature": 0.0, "avg_logprob": -0.13176494294946844, "compression_ratio": 1.6762295081967213, "no_speech_prob": 3.942504190490581e-05}, {"id": 436, "seek": 431456, "start": 4328.56, "end": 4338.56, "text": " imperative programmer. It's going to be a stretch to try and bend your mind in the different ways that you know, a PL or J, or BQN expect you to think about things.", "tokens": [32490, 32116, 13, 467, 311, 516, 281, 312, 257, 5985, 281, 853, 293, 11229, 428, 1575, 294, 264, 819, 2098, 300, 291, 458, 11, 257, 6999, 420, 508, 11, 420, 363, 48, 45, 2066, 291, 281, 519, 466, 721, 13], "temperature": 0.0, "avg_logprob": -0.13176494294946844, "compression_ratio": 1.6762295081967213, "no_speech_prob": 3.942504190490581e-05}, {"id": 437, "seek": 433856, "start": 4338.56, "end": 4348.56, "text": " Yeah, I think the huge rise of functional programming is very helpful for coming to array programming, you know, both in JavaScript and in Python.", "tokens": [865, 11, 286, 519, 264, 2603, 6272, 295, 11745, 9410, 307, 588, 4961, 337, 1348, 281, 10225, 9410, 11, 291, 458, 11, 1293, 294, 15778, 293, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.0572958787282308, "compression_ratio": 1.622340425531915, "no_speech_prob": 3.4457109450158896e-06}, {"id": 438, "seek": 433856, "start": 4348.56, "end": 4359.56, "text": " It's, you know, I think most people are doing stuff, particularly in the, in the machine learning and deep learning world are doing a lot of functional stuff.", "tokens": [467, 311, 11, 291, 458, 11, 286, 519, 881, 561, 366, 884, 1507, 11, 4098, 294, 264, 11, 294, 264, 3479, 2539, 293, 2452, 2539, 1002, 366, 884, 257, 688, 295, 11745, 1507, 13], "temperature": 0.0, "avg_logprob": -0.0572958787282308, "compression_ratio": 1.622340425531915, "no_speech_prob": 3.4457109450158896e-06}, {"id": 439, "seek": 435956, "start": 4359.56, "end": 4375.56, "text": " Often that's the only way you can do things, particularly in deep learning. So I think yeah I think that does help a lot like like kind of said like you've probably come across, you know, map and reduce and filter, and certainly in in Python you'll have", "tokens": [20043, 300, 311, 264, 787, 636, 291, 393, 360, 721, 11, 4098, 294, 2452, 2539, 13, 407, 286, 519, 1338, 286, 519, 300, 775, 854, 257, 688, 411, 411, 733, 295, 848, 411, 291, 600, 1391, 808, 2108, 11, 291, 458, 11, 4471, 293, 5407, 293, 6608, 11, 293, 3297, 294, 294, 15329, 291, 603, 362], "temperature": 0.0, "avg_logprob": -0.15971332872417612, "compression_ratio": 1.5765306122448979, "no_speech_prob": 6.5389808696636464e-06}, {"id": 440, "seek": 435956, "start": 4375.56, "end": 4380.56, "text": " done list comprehensions and dictionary comprehensions.", "tokens": [1096, 1329, 10753, 8302, 293, 25890, 10753, 8302, 13], "temperature": 0.0, "avg_logprob": -0.15971332872417612, "compression_ratio": 1.5765306122448979, "no_speech_prob": 6.5389808696636464e-06}, {"id": 441, "seek": 438056, "start": 4380.56, "end": 4391.56, "text": " And a lot of people don't SQL. So it's, yeah, I think a lot of people come into it with some relevant analogies if we can help connect it for them.", "tokens": [400, 257, 688, 295, 561, 500, 380, 19200, 13, 407, 309, 311, 11, 1338, 11, 286, 519, 257, 688, 295, 561, 808, 666, 309, 365, 512, 7340, 16660, 530, 498, 321, 393, 854, 1745, 309, 337, 552, 13], "temperature": 0.0, "avg_logprob": -0.10856353971693251, "compression_ratio": 1.6407766990291262, "no_speech_prob": 1.0613118320179638e-05}, {"id": 442, "seek": 438056, "start": 4391.56, "end": 4404.56, "text": " Yeah, one of the things that, you know, really it's reinforcing my idea that, or it's not my idea I think it's just an idea that multiple people have had but that the tool doesn't exist yet.", "tokens": [865, 11, 472, 295, 264, 721, 300, 11, 291, 458, 11, 534, 309, 311, 48262, 452, 1558, 300, 11, 420, 309, 311, 406, 452, 1558, 286, 519, 309, 311, 445, 364, 1558, 300, 3866, 561, 362, 632, 457, 300, 264, 2290, 1177, 380, 2514, 1939, 13], "temperature": 0.0, "avg_logprob": -0.10856353971693251, "compression_ratio": 1.6407766990291262, "no_speech_prob": 1.0613118320179638e-05}, {"id": 443, "seek": 440456, "start": 4404.56, "end": 4419.56, "text": " Because we'll link to some documentation that I use frequently when I'm going sometimes between a PL and J on the BQM website they have BQN to dialogue APL dictionaries and BQ and the J dictionary so sometimes I'll like, if I'm trying to convert", "tokens": [1436, 321, 603, 2113, 281, 512, 14333, 300, 286, 764, 10374, 562, 286, 478, 516, 2171, 1296, 257, 6999, 293, 508, 322, 264, 363, 48, 44, 3144, 436, 362, 363, 48, 45, 281, 10221, 5372, 43, 22352, 4889, 293, 363, 48, 293, 264, 508, 25890, 370, 2171, 286, 603, 411, 11, 498, 286, 478, 1382, 281, 7620], "temperature": 0.0, "avg_logprob": -0.2263325394177046, "compression_ratio": 1.4583333333333333, "no_speech_prob": 9.816847523325123e-06}, {"id": 444, "seek": 441956, "start": 4419.56, "end": 4434.56, "text": " between the two, the BQM docs are so good I'll just use BQN is like an IR to go back and forth but I've mentioned on previous podcasts that really what would be amazing and it would only work to a certain extent is something like a multi directional", "tokens": [1296, 264, 732, 11, 264, 363, 48, 44, 45623, 366, 370, 665, 286, 603, 445, 764, 363, 48, 45, 307, 411, 364, 16486, 281, 352, 646, 293, 5220, 457, 286, 600, 2835, 322, 3894, 24045, 300, 534, 437, 576, 312, 2243, 293, 309, 576, 787, 589, 281, 257, 1629, 8396, 307, 746, 411, 257, 4825, 42242], "temperature": 0.0, "avg_logprob": -0.12172635396321614, "compression_ratio": 1.439306358381503, "no_speech_prob": 9.97095321508823e-06}, {"id": 445, "seek": 443456, "start": 4434.56, "end": 4449.56, "text": " array language transpiler and adding numpy to that list would probably be, you know, a huge, I don't know what the word for it is but beneficial for the array community if you can type in some numpy expression, you know, like I said it's only going to work to an extent", "tokens": [10225, 2856, 7132, 5441, 293, 5127, 1031, 8200, 281, 300, 1329, 576, 1391, 312, 11, 291, 458, 11, 257, 2603, 11, 286, 500, 380, 458, 437, 264, 1349, 337, 309, 307, 457, 14072, 337, 264, 10225, 1768, 498, 291, 393, 2010, 294, 512, 1031, 8200, 6114, 11, 291, 458, 11, 411, 286, 848, 309, 311, 787, 516, 281, 589, 281, 364, 8396], "temperature": 0.0, "avg_logprob": -0.0977987592870539, "compression_ratio": 1.5112359550561798, "no_speech_prob": 6.852806109236553e-06}, {"id": 446, "seek": 444956, "start": 4449.56, "end": 4464.56, "text": " that you can do simple you know rank one vectors or arrays that you're just reversing and summing and doing simple you know reduction and scan operations, you could translate that pretty easily into a PLJ and BQN, and it's, I think that would make it so much easier", "tokens": [300, 291, 393, 360, 2199, 291, 458, 6181, 472, 18875, 420, 41011, 300, 291, 434, 445, 14582, 278, 293, 2408, 2810, 293, 884, 2199, 291, 458, 11004, 293, 11049, 7705, 11, 291, 727, 13799, 300, 1238, 3612, 666, 257, 6999, 41, 293, 363, 48, 45, 11, 293, 309, 311, 11, 286, 519, 300, 576, 652, 309, 370, 709, 3571], "temperature": 0.0, "avg_logprob": -0.197229128035288, "compression_ratio": 1.5773809523809523, "no_speech_prob": 1.3836891412211116e-05}, {"id": 447, "seek": 446456, "start": 4464.56, "end": 4481.56, "text": " to understand, aka the hieroglyphics or the Greek or the Chinese or whatever metaphor you want to use.", "tokens": [281, 1223, 11, 28042, 264, 3296, 38353, 950, 1167, 420, 264, 10281, 420, 264, 4649, 420, 2035, 19157, 291, 528, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.13012061467984828, "compression_ratio": 1.2719298245614035, "no_speech_prob": 4.0655559132574126e-05}, {"id": 448, "seek": 446456, "start": 4481.56, "end": 4484.56, "text": " And it's very easy to hit a wall early on.", "tokens": [400, 309, 311, 588, 1858, 281, 2045, 257, 2929, 2440, 322, 13], "temperature": 0.0, "avg_logprob": -0.13012061467984828, "compression_ratio": 1.2719298245614035, "no_speech_prob": 4.0655559132574126e-05}, {"id": 449, "seek": 448456, "start": 4484.56, "end": 4504.56, "text": " So, I've been thinking about is basically rewrite numpy in APL. It doesn't seem like a whole lot of work where just take all those names that are available in number, and just define the message functions and people can explore that by opening them up and", "tokens": [407, 11, 286, 600, 668, 1953, 466, 307, 1936, 28132, 1031, 8200, 294, 5372, 43, 13, 467, 1177, 380, 1643, 411, 257, 1379, 688, 295, 589, 689, 445, 747, 439, 729, 5288, 300, 366, 2435, 294, 1230, 11, 293, 445, 6964, 264, 3636, 6828, 293, 561, 393, 6839, 300, 538, 5193, 552, 493, 293], "temperature": 0.0, "avg_logprob": -0.20576346923257702, "compression_ratio": 1.629496402877698, "no_speech_prob": 1.0126888810191303e-05}, {"id": 450, "seek": 448456, "start": 4504.56, "end": 4513.56, "text": " seeing how they defined. Oh, so not not actually you're saying like, it wouldn't be a new thing you're just saying like rename the symbols what they're known as in numpy so that you'd still be in a", "tokens": [2577, 577, 436, 7642, 13, 876, 11, 370, 406, 406, 767, 291, 434, 1566, 411, 11, 309, 2759, 380, 312, 257, 777, 551, 291, 434, 445, 1566, 411, 36741, 264, 16944, 437, 436, 434, 2570, 382, 294, 1031, 8200, 370, 300, 291, 1116, 920, 312, 294, 257], "temperature": 0.0, "avg_logprob": -0.20576346923257702, "compression_ratio": 1.629496402877698, "no_speech_prob": 1.0126888810191303e-05}, {"id": 451, "seek": 451356, "start": 4513.56, "end": 4534.56, "text": " like an APL. Yeah, I mean you could use it as a library, but I was thinking a bit more as an interactive exploring type thing where you open up this library, and then you, you write the name of some numpy thing functionality and open it up in the editor", "tokens": [411, 364, 5372, 43, 13, 865, 11, 286, 914, 291, 727, 764, 309, 382, 257, 6405, 11, 457, 286, 390, 1953, 257, 857, 544, 382, 364, 15141, 12736, 2010, 551, 689, 291, 1269, 493, 341, 6405, 11, 293, 550, 291, 11, 291, 2464, 264, 1315, 295, 512, 1031, 8200, 551, 14980, 293, 1269, 309, 493, 294, 264, 9839], "temperature": 0.0, "avg_logprob": -0.122583472210428, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.3842948646924924e-05}, {"id": 452, "seek": 451356, "start": 4534.56, "end": 4537.56, "text": " and see, well, how is this defined in APL.", "tokens": [293, 536, 11, 731, 11, 577, 307, 341, 7642, 294, 5372, 43, 13], "temperature": 0.0, "avg_logprob": -0.122583472210428, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.3842948646924924e-05}, {"id": 453, "seek": 451356, "start": 4537.56, "end": 4541.56, "text": " And then you could use it obviously, since it's defined.", "tokens": [400, 550, 291, 727, 764, 309, 2745, 11, 1670, 309, 311, 7642, 13], "temperature": 0.0, "avg_logprob": -0.122583472210428, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.3842948646924924e-05}, {"id": 454, "seek": 454156, "start": 4541.56, "end": 4553.56, "text": " Interesting, then you could slowly you could use these library functions. And then, as you get better at APL you can start actually writing out the role appeal instead of using these covers for it.", "tokens": [14711, 11, 550, 291, 727, 5692, 291, 727, 764, 613, 6405, 6828, 13, 400, 550, 11, 382, 291, 483, 1101, 412, 5372, 43, 291, 393, 722, 767, 3579, 484, 264, 3090, 13668, 2602, 295, 1228, 613, 10538, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.18369171836159445, "compression_ratio": 1.6828358208955223, "no_speech_prob": 1.38447321660351e-05}, {"id": 455, "seek": 454156, "start": 4553.56, "end": 4569.56, "text": " Well, I guess, Jeremy that's an interesting. Do you think that, because you've mentioned about sort of the notation versus the programming language, and where do you think the like in your dream scenario, are you actually coding in sort of an Iversonian", "tokens": [1042, 11, 286, 2041, 11, 17809, 300, 311, 364, 1880, 13, 1144, 291, 519, 300, 11, 570, 291, 600, 2835, 466, 1333, 295, 264, 24657, 5717, 264, 9410, 2856, 11, 293, 689, 360, 291, 519, 264, 411, 294, 428, 3055, 9005, 11, 366, 291, 767, 17720, 294, 1333, 295, 364, 286, 840, 43294], "temperature": 0.0, "avg_logprob": -0.18369171836159445, "compression_ratio": 1.6828358208955223, "no_speech_prob": 1.38447321660351e-05}, {"id": 456, "seek": 456956, "start": 4569.56, "end": 4586.56, "text": " like notation, or no, is it at the end of the day does it still look like numpy, but it's just all of the expressive to expressivity and power that you have in the language like APL is brought to and combined with what numpy sort of currently looks like", "tokens": [411, 24657, 11, 420, 572, 11, 307, 309, 412, 264, 917, 295, 264, 786, 775, 309, 920, 574, 411, 1031, 8200, 11, 457, 309, 311, 445, 439, 295, 264, 40189, 281, 5109, 4253, 293, 1347, 300, 291, 362, 294, 264, 2856, 411, 5372, 43, 307, 3038, 281, 293, 9354, 365, 437, 1031, 8200, 1333, 295, 4362, 1542, 411], "temperature": 0.0, "avg_logprob": -0.08402573677801317, "compression_ratio": 1.5240963855421688, "no_speech_prob": 1.4282933989306912e-05}, {"id": 457, "seek": 458656, "start": 4586.56, "end": 4607.56, "text": " is, I mean, well, it'd be a bit of a combination Connor in that like, you know, my classes and my type dispatch and my packaging and, you know, all the, you know, my function definitions and whatever that's, that's Python.", "tokens": [307, 11, 286, 914, 11, 731, 11, 309, 1116, 312, 257, 857, 295, 257, 6562, 33133, 294, 300, 411, 11, 291, 458, 11, 452, 5359, 293, 452, 2010, 36729, 293, 452, 16836, 293, 11, 291, 458, 11, 439, 264, 11, 291, 458, 11, 452, 2445, 21988, 293, 2035, 300, 311, 11, 300, 311, 15329, 13], "temperature": 0.0, "avg_logprob": -0.12125487246755827, "compression_ratio": 1.4899328859060403, "no_speech_prob": 5.592486559180543e-06}, {"id": 458, "seek": 460756, "start": 4607.56, "end": 4619.56, "text": " But you know, everywhere I can use plus and times and divide and whatever I could also use any, any APL glyph.", "tokens": [583, 291, 458, 11, 5315, 286, 393, 764, 1804, 293, 1413, 293, 9845, 293, 2035, 286, 727, 611, 764, 604, 11, 604, 5372, 43, 22633, 950, 13], "temperature": 0.0, "avg_logprob": -0.19153712136404855, "compression_ratio": 1.4591836734693877, "no_speech_prob": 3.041216359633836e-06}, {"id": 459, "seek": 460756, "start": 4619.56, "end": 4635.56, "text": " And so it'd be you know basically an embedded DSL for kind of high dimensional notation. It would work automatically on numpy arrays and TensorFlow tenses and pi torch tenses.", "tokens": [400, 370, 309, 1116, 312, 291, 458, 1936, 364, 16741, 15816, 43, 337, 733, 295, 1090, 18795, 24657, 13, 467, 576, 589, 6772, 322, 1031, 8200, 41011, 293, 37624, 256, 9085, 293, 3895, 27822, 256, 9085, 13], "temperature": 0.0, "avg_logprob": -0.19153712136404855, "compression_ratio": 1.4591836734693877, "no_speech_prob": 3.041216359633836e-06}, {"id": 460, "seek": 463556, "start": 4635.56, "end": 4660.56, "text": " And the thing that's interesting is, to a large degree, APL and pi torch and friends have actually arrived at a similar place with the same, you know, grandparents, which is, I have a son actually said his inspiration for some of the APL ideas was tensor", "tokens": [400, 264, 551, 300, 311, 1880, 307, 11, 281, 257, 2416, 4314, 11, 5372, 43, 293, 3895, 27822, 293, 1855, 362, 767, 6678, 412, 257, 2531, 1081, 365, 264, 912, 11, 291, 458, 11, 21876, 11, 597, 307, 11, 286, 362, 257, 1872, 767, 848, 702, 10249, 337, 512, 295, 264, 5372, 43, 3487, 390, 40863], "temperature": 0.0, "avg_logprob": -0.18718279202779134, "compression_ratio": 1.4767441860465116, "no_speech_prob": 1.7499893147032708e-05}, {"id": 461, "seek": 466056, "start": 4660.56, "end": 4673.56, "text": " analysis. And a lot of the folks, as you can gather from the fact that in pi torch we don't call them arrays because the tensors a lot of the folks working on deep learning. Their inspiration was also from tensor analysis so it comes from physics right.", "tokens": [5215, 13, 400, 257, 688, 295, 264, 4024, 11, 382, 291, 393, 5448, 490, 264, 1186, 300, 294, 3895, 27822, 321, 500, 380, 818, 552, 41011, 570, 264, 10688, 830, 257, 688, 295, 264, 4024, 1364, 322, 2452, 2539, 13, 6710, 10249, 390, 611, 490, 40863, 5215, 370, 309, 1487, 490, 10649, 558, 13], "temperature": 0.0, "avg_logprob": -0.1426494017891262, "compression_ratio": 1.7937219730941705, "no_speech_prob": 5.06185824633576e-05}, {"id": 462, "seek": 466056, "start": 4673.56, "end": 4682.56, "text": " And so I would say, you know, a lot more folks have worked on pi torch were familiar with tensor analysis and physics than were familiar with APL.", "tokens": [400, 370, 286, 576, 584, 11, 291, 458, 11, 257, 688, 544, 4024, 362, 2732, 322, 3895, 27822, 645, 4963, 365, 40863, 5215, 293, 10649, 813, 645, 4963, 365, 5372, 43, 13], "temperature": 0.0, "avg_logprob": -0.1426494017891262, "compression_ratio": 1.7937219730941705, "no_speech_prob": 5.06185824633576e-05}, {"id": 463, "seek": 468256, "start": 4682.56, "end": 4693.56, "text": " So, and then of course there's been other notations, like explicitly based on Einstein notation there's a thing called I know, which like takes.", "tokens": [407, 11, 293, 550, 295, 1164, 456, 311, 668, 661, 406, 763, 11, 411, 20803, 2361, 322, 23486, 24657, 456, 311, 257, 551, 1219, 286, 458, 11, 597, 411, 2516, 13], "temperature": 0.0, "avg_logprob": -0.13418113667031992, "compression_ratio": 1.7932489451476794, "no_speech_prob": 2.3917469661682844e-05}, {"id": 464, "seek": 468256, "start": 4693.56, "end": 4698.56, "text": " It's very interesting kind of approach of taking Einstein notation, much further.", "tokens": [467, 311, 588, 1880, 733, 295, 3109, 295, 1940, 23486, 24657, 11, 709, 3052, 13], "temperature": 0.0, "avg_logprob": -0.13418113667031992, "compression_ratio": 1.7932489451476794, "no_speech_prob": 2.3917469661682844e-05}, {"id": 465, "seek": 468256, "start": 4698.56, "end": 4710.56, "text": " And like Einstein notation if you think about it is the kind of the loop free programming of math right that the equivalent of loops in math is indices, and Einstein notation does away with indices.", "tokens": [400, 411, 23486, 24657, 498, 291, 519, 466, 309, 307, 264, 733, 295, 264, 6367, 1737, 9410, 295, 5221, 558, 300, 264, 10344, 295, 16121, 294, 5221, 307, 43840, 11, 293, 23486, 24657, 775, 1314, 365, 43840, 13], "temperature": 0.0, "avg_logprob": -0.13418113667031992, "compression_ratio": 1.7932489451476794, "no_speech_prob": 2.3917469661682844e-05}, {"id": 466, "seek": 471056, "start": 4710.56, "end": 4728.56, "text": " And so that's why stuff like I know it's incredibly powerful because you can write, you know, an expression in in in I know, with no indices and no loops, and it's all implicit reductions and implicit loops, I guess yeah my ideal thing would be.", "tokens": [400, 370, 300, 311, 983, 1507, 411, 286, 458, 309, 311, 6252, 4005, 570, 291, 393, 2464, 11, 291, 458, 11, 364, 6114, 294, 294, 294, 286, 458, 11, 365, 572, 43840, 293, 572, 16121, 11, 293, 309, 311, 439, 26947, 40296, 293, 26947, 16121, 11, 286, 2041, 1338, 452, 7157, 551, 576, 312, 13], "temperature": 0.0, "avg_logprob": -0.1817753609646572, "compression_ratio": 1.638095238095238, "no_speech_prob": 5.86252326684189e-06}, {"id": 467, "seek": 471056, "start": 4728.56, "end": 4734.56, "text": " We wouldn't have to use I know, we can use APL, you know, and it wouldn't be embedded in a string.", "tokens": [492, 2759, 380, 362, 281, 764, 286, 458, 11, 321, 393, 764, 5372, 43, 11, 291, 458, 11, 293, 309, 2759, 380, 312, 16741, 294, 257, 6798, 13], "temperature": 0.0, "avg_logprob": -0.1817753609646572, "compression_ratio": 1.638095238095238, "no_speech_prob": 5.86252326684189e-06}, {"id": 468, "seek": 473456, "start": 4734.56, "end": 4755.56, "text": " But they would actually be operators, yeah that's what it is that the operators in the language that Python operators would not just be plus times minus slash, that would be all the APL glyphs would be Python operators and they would work on all Python", "tokens": [583, 436, 576, 767, 312, 19077, 11, 1338, 300, 311, 437, 309, 307, 300, 264, 19077, 294, 264, 2856, 300, 15329, 19077, 576, 406, 445, 312, 1804, 1413, 3175, 17330, 11, 300, 576, 312, 439, 264, 5372, 43, 22633, 950, 82, 576, 312, 15329, 19077, 293, 436, 576, 589, 322, 439, 15329], "temperature": 0.0, "avg_logprob": -0.11469703996685189, "compression_ratio": 1.7637362637362637, "no_speech_prob": 6.338912498904392e-06}, {"id": 469, "seek": 473456, "start": 4755.56, "end": 4761.56, "text": " data types, including all the different tensor and array data types.", "tokens": [1412, 3467, 11, 3009, 439, 264, 819, 40863, 293, 10225, 1412, 3467, 13], "temperature": 0.0, "avg_logprob": -0.11469703996685189, "compression_ratio": 1.7637362637362637, "no_speech_prob": 6.338912498904392e-06}, {"id": 470, "seek": 476156, "start": 4761.56, "end": 4771.56, "text": " Yeah, it sounds like you're describing a kind of hybrid hybrid language JavaScript to you. I would love the whole DSL to be in JavaScript as well. You know, that'd be great.", "tokens": [865, 11, 309, 3263, 411, 291, 434, 16141, 257, 733, 295, 13051, 13051, 2856, 15778, 281, 291, 13, 286, 576, 959, 264, 1379, 15816, 43, 281, 312, 294, 15778, 382, 731, 13, 509, 458, 11, 300, 1116, 312, 869, 13], "temperature": 0.0, "avg_logprob": -0.2624588929689847, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.1658164112304803e-05}, {"id": 471, "seek": 476156, "start": 4771.56, "end": 4778.56, "text": " And I feel like I saw that somewhere I feel like I saw somebody actually do an ACMA script.", "tokens": [400, 286, 841, 411, 286, 1866, 300, 4079, 286, 841, 411, 286, 1866, 2618, 767, 360, 364, 8157, 9998, 5755, 13], "temperature": 0.0, "avg_logprob": -0.2624588929689847, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.1658164112304803e-05}, {"id": 472, "seek": 476156, "start": 4778.56, "end": 4782.56, "text": " So, you know, RFC with an implementation.", "tokens": [407, 11, 291, 458, 11, 497, 18671, 365, 364, 11420, 13], "temperature": 0.0, "avg_logprob": -0.2624588929689847, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.1658164112304803e-05}, {"id": 473, "seek": 476156, "start": 4782.56, "end": 4789.56, "text": " It was a false joke. Yeah, but it actually worked it not like it was actually an implementation that.", "tokens": [467, 390, 257, 7908, 7647, 13, 865, 11, 457, 309, 767, 2732, 309, 406, 411, 309, 390, 767, 364, 11420, 300, 13], "temperature": 0.0, "avg_logprob": -0.2624588929689847, "compression_ratio": 1.6693877551020408, "no_speech_prob": 1.1658164112304803e-05}, {"id": 474, "seek": 478956, "start": 4789.56, "end": 4801.56, "text": " I don't think they had the implementation there was just very very well specced, it could actually work kind of thing. No, I definitely I read the I read the code I was I don't know how complete it was, but there was definitely some code there.", "tokens": [286, 500, 380, 519, 436, 632, 264, 11420, 456, 390, 445, 588, 588, 731, 1608, 1232, 11, 309, 727, 767, 589, 733, 295, 551, 13, 883, 11, 286, 2138, 286, 1401, 264, 286, 1401, 264, 3089, 286, 390, 286, 500, 380, 458, 577, 3566, 309, 390, 11, 457, 456, 390, 2138, 512, 3089, 456, 13], "temperature": 0.0, "avg_logprob": -0.223265570563239, "compression_ratio": 1.6923076923076923, "no_speech_prob": 8.612998499302194e-05}, {"id": 475, "seek": 478956, "start": 4801.56, "end": 4803.56, "text": " I can't find it again.", "tokens": [286, 393, 380, 915, 309, 797, 13], "temperature": 0.0, "avg_logprob": -0.223265570563239, "compression_ratio": 1.6923076923076923, "no_speech_prob": 8.612998499302194e-05}, {"id": 476, "seek": 478956, "start": 4803.56, "end": 4805.56, "text": " If you know where it is.", "tokens": [759, 291, 458, 689, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.223265570563239, "compression_ratio": 1.6923076923076923, "no_speech_prob": 8.612998499302194e-05}, {"id": 477, "seek": 478956, "start": 4805.56, "end": 4811.56, "text": " There's a JavaScript implementation of APL by Nick Nickalove.", "tokens": [821, 311, 257, 15778, 11420, 295, 5372, 43, 538, 9449, 9449, 304, 1682, 13], "temperature": 0.0, "avg_logprob": -0.223265570563239, "compression_ratio": 1.6923076923076923, "no_speech_prob": 8.612998499302194e-05}, {"id": 478, "seek": 478956, "start": 4811.56, "end": 4818.56, "text": " But my problem with it, it's not tightly enough connected with underlying JavaScript.", "tokens": [583, 452, 1154, 365, 309, 11, 309, 311, 406, 21952, 1547, 4582, 365, 14217, 15778, 13], "temperature": 0.0, "avg_logprob": -0.223265570563239, "compression_ratio": 1.6923076923076923, "no_speech_prob": 8.612998499302194e-05}, {"id": 479, "seek": 481856, "start": 4818.56, "end": 4832.56, "text": " It shouldn't be an April Fool's joke, should it? You know, it's like, it's like, it's like Gmail was an April Fool's joke right Gmail came out on April the 1st and totally destroyed my plans for fast mail, because it was an April Fool's joke that was real.", "tokens": [467, 4659, 380, 312, 364, 6929, 41583, 311, 7647, 11, 820, 309, 30, 509, 458, 11, 309, 311, 411, 11, 309, 311, 411, 11, 309, 311, 411, 36732, 390, 364, 6929, 41583, 311, 7647, 558, 36732, 1361, 484, 322, 6929, 264, 502, 372, 293, 3879, 8937, 452, 5482, 337, 2370, 10071, 11, 570, 309, 390, 364, 6929, 41583, 311, 7647, 300, 390, 957, 13], "temperature": 0.0, "avg_logprob": -0.17550091213650174, "compression_ratio": 2.047970479704797, "no_speech_prob": 1.8628656107466668e-05}, {"id": 480, "seek": 481856, "start": 4832.56, "end": 4845.56, "text": " And flask you know the flask library I think was originally an April Fool's joke of like, you know, we basically saying we shouldn't be losing frameworks because I created a framework that's so stupidly small that it shouldn't be a framework and now that's the most popular web", "tokens": [400, 932, 3863, 291, 458, 264, 932, 3863, 6405, 286, 519, 390, 7993, 364, 6929, 41583, 311, 7647, 295, 411, 11, 291, 458, 11, 321, 1936, 1566, 321, 4659, 380, 312, 7027, 29834, 570, 286, 2942, 257, 8388, 300, 311, 370, 6631, 356, 1359, 300, 309, 4659, 380, 312, 257, 8388, 293, 586, 300, 311, 264, 881, 3743, 3670], "temperature": 0.0, "avg_logprob": -0.17550091213650174, "compression_ratio": 2.047970479704797, "no_speech_prob": 1.8628656107466668e-05}, {"id": 481, "seek": 481856, "start": 4845.56, "end": 4846.56, "text": " framework in Python.", "tokens": [8388, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.17550091213650174, "compression_ratio": 2.047970479704797, "no_speech_prob": 1.8628656107466668e-05}, {"id": 482, "seek": 484656, "start": 4846.56, "end": 4852.56, "text": " So yeah, maybe this should be an April Fool's joke becomes real.", "tokens": [407, 1338, 11, 1310, 341, 820, 312, 364, 6929, 41583, 311, 7647, 3643, 957, 13], "temperature": 0.0, "avg_logprob": -0.13472362665029672, "compression_ratio": 1.5021645021645023, "no_speech_prob": 6.539802143379347e-06}, {"id": 483, "seek": 484656, "start": 4852.56, "end": 4873.56, "text": " How close. This is maybe an odd question but because it from what I know about Julia you can define your own Unicode operators and I did try at one point to create a small composition of two different symbols you know square root and reverse or something and it ended up not working", "tokens": [1012, 1998, 13, 639, 307, 1310, 364, 7401, 1168, 457, 570, 309, 490, 437, 286, 458, 466, 18551, 291, 393, 6964, 428, 1065, 1156, 299, 1429, 19077, 293, 286, 630, 853, 412, 472, 935, 281, 1884, 257, 1359, 12686, 295, 732, 819, 16944, 291, 458, 3732, 5593, 293, 9943, 420, 746, 293, 309, 4590, 493, 406, 1364], "temperature": 0.0, "avg_logprob": -0.13472362665029672, "compression_ratio": 1.5021645021645023, "no_speech_prob": 6.539802143379347e-06}, {"id": 484, "seek": 487356, "start": 4873.56, "end": 4881.56, "text": " for me for parentheses. But do you think Julia could evolve to be that kind of hybrid language that.", "tokens": [337, 385, 337, 34153, 13, 583, 360, 291, 519, 18551, 727, 16693, 281, 312, 300, 733, 295, 13051, 2856, 300, 13], "temperature": 0.0, "avg_logprob": -0.15975579193660192, "compression_ratio": 1.4415584415584415, "no_speech_prob": 3.3207357773790136e-05}, {"id": 485, "seek": 487356, "start": 4881.56, "end": 4892.56, "text": " Yeah, maybe, you know, maybe I'm actually doing a keynote at Julia con in a couple of weeks so maybe I should raise that.", "tokens": [865, 11, 1310, 11, 291, 458, 11, 1310, 286, 478, 767, 884, 257, 33896, 412, 18551, 416, 294, 257, 1916, 295, 3259, 370, 1310, 286, 820, 5300, 300, 13], "temperature": 0.0, "avg_logprob": -0.15975579193660192, "compression_ratio": 1.4415584415584415, "no_speech_prob": 3.3207357773790136e-05}, {"id": 486, "seek": 489256, "start": 4892.56, "end": 4905.56, "text": " I think the Q&A section say, any questions but first I've got one for the community at large. Here's what I'd like to know how talks going to be kind of like what Julia needs to be, you know, to move to the next level.", "tokens": [286, 519, 264, 1249, 5, 32, 3541, 584, 11, 604, 1651, 457, 700, 286, 600, 658, 472, 337, 264, 1768, 412, 2416, 13, 1692, 311, 437, 286, 1116, 411, 281, 458, 577, 6686, 516, 281, 312, 733, 295, 411, 437, 18551, 2203, 281, 312, 11, 291, 458, 11, 281, 1286, 281, 264, 958, 1496, 13], "temperature": 0.0, "avg_logprob": -0.19600707160101996, "compression_ratio": 1.5411255411255411, "no_speech_prob": 1.0950730938930064e-05}, {"id": 487, "seek": 489256, "start": 4905.56, "end": 4913.56, "text": " I'm not sure I can demand that a complete APL implementations that thing but I could certainly put it out there is something to consider.", "tokens": [286, 478, 406, 988, 286, 393, 4733, 300, 257, 3566, 5372, 43, 4445, 763, 300, 551, 457, 286, 727, 3297, 829, 309, 484, 456, 307, 746, 281, 1949, 13], "temperature": 0.0, "avg_logprob": -0.19600707160101996, "compression_ratio": 1.5411255411255411, "no_speech_prob": 1.0950730938930064e-05}, {"id": 488, "seek": 491356, "start": 4913.56, "end": 4922.56, "text": " It always bothers me though that if you try to extend those languages like this so you could use some kind of pre compiler for it.", "tokens": [467, 1009, 33980, 385, 1673, 300, 498, 291, 853, 281, 10101, 729, 8650, 411, 341, 370, 291, 727, 764, 512, 733, 295, 659, 31958, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.16405688105402766, "compression_ratio": 1.488262910798122, "no_speech_prob": 8.267045814136509e-06}, {"id": 489, "seek": 491356, "start": 4922.56, "end": 4927.56, "text": " Then their order of execution ends up messing up APL.", "tokens": [1396, 641, 1668, 295, 15058, 5314, 493, 23258, 493, 5372, 43, 13], "temperature": 0.0, "avg_logprob": -0.16405688105402766, "compression_ratio": 1.488262910798122, "no_speech_prob": 8.267045814136509e-06}, {"id": 490, "seek": 491356, "start": 4927.56, "end": 4936.56, "text": " I think if you're very much depends on having a strict one directional order of functions. Otherwise it's hopeless to keep track of.", "tokens": [286, 519, 498, 291, 434, 588, 709, 5946, 322, 1419, 257, 10910, 472, 42242, 1668, 295, 6828, 13, 10328, 309, 311, 27317, 281, 1066, 2837, 295, 13], "temperature": 0.0, "avg_logprob": -0.16405688105402766, "compression_ratio": 1.488262910798122, "no_speech_prob": 8.267045814136509e-06}, {"id": 491, "seek": 493656, "start": 4936.56, "end": 4949.56, "text": " That's that is a big challenge because currently the DSL inside Python, which is the basic mathematical operations to have the bod mass or PEMDAS order operations.", "tokens": [663, 311, 300, 307, 257, 955, 3430, 570, 4362, 264, 15816, 43, 1854, 15329, 11, 597, 307, 264, 3875, 18894, 7705, 281, 362, 264, 16737, 2758, 420, 430, 6683, 35, 3160, 1668, 7705, 13], "temperature": 0.0, "avg_logprob": -0.2672981964914422, "compression_ratio": 1.2734375, "no_speech_prob": 9.816582860366907e-06}, {"id": 492, "seek": 494956, "start": 4949.56, "end": 4966.56, "text": " And so there would need to be some way. So in Python that wouldn't be too hard actually because in Python.", "tokens": [400, 370, 456, 576, 643, 281, 312, 512, 636, 13, 407, 294, 15329, 300, 2759, 380, 312, 886, 1152, 767, 570, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.15655958457071273, "compression_ratio": 1.4539877300613497, "no_speech_prob": 4.4942175918549765e-06}, {"id": 493, "seek": 494956, "start": 4966.56, "end": 4970.56, "text": " From Dunder futures import APL precedence.", "tokens": [3358, 413, 6617, 26071, 974, 5372, 43, 16969, 655, 13], "temperature": 0.0, "avg_logprob": -0.15655958457071273, "compression_ratio": 1.4539877300613497, "no_speech_prob": 4.4942175918549765e-06}, {"id": 494, "seek": 494956, "start": 4970.56, "end": 4977.56, "text": " And then from then on everything in your file is going to use right to left precedence.", "tokens": [400, 550, 490, 550, 322, 1203, 294, 428, 3991, 307, 516, 281, 764, 558, 281, 1411, 16969, 655, 13], "temperature": 0.0, "avg_logprob": -0.15655958457071273, "compression_ratio": 1.4539877300613497, "no_speech_prob": 4.4942175918549765e-06}, {"id": 495, "seek": 497756, "start": 4977.56, "end": 4983.56, "text": " Interesting and cool. I didn't know that.", "tokens": [14711, 293, 1627, 13, 286, 994, 380, 458, 300, 13], "temperature": 0.0, "avg_logprob": -0.10486869251026827, "compression_ratio": 1.5894736842105264, "no_speech_prob": 1.1297863238723949e-05}, {"id": 496, "seek": 497756, "start": 4983.56, "end": 5000.56, "text": " Awesome. I've been spending a lot of time thinking about function precedence and just the differences and different languages and I'm not sure if any other languages have this but something that I find very curious about BQN and APL is that they have functions", "tokens": [10391, 13, 286, 600, 668, 6434, 257, 688, 295, 565, 1953, 466, 2445, 16969, 655, 293, 445, 264, 7300, 293, 819, 8650, 293, 286, 478, 406, 988, 498, 604, 661, 8650, 362, 341, 457, 746, 300, 286, 915, 588, 6369, 466, 363, 48, 45, 293, 5372, 43, 307, 300, 436, 362, 6828], "temperature": 0.0, "avg_logprob": -0.10486869251026827, "compression_ratio": 1.5894736842105264, "no_speech_prob": 1.1297863238723949e-05}, {"id": 497, "seek": 500056, "start": 5000.56, "end": 5017.56, "text": " basically that have higher precedence than other functions. So operators in APL and conjunction is an adverbs. They have higher precedence than your regular functions that apply to arrays, you know I'm simplifying a tiny bit but this idea that like", "tokens": [1936, 300, 362, 2946, 16969, 655, 813, 661, 6828, 13, 407, 19077, 294, 5372, 43, 293, 27482, 307, 364, 614, 43348, 13, 814, 362, 2946, 16969, 655, 813, 428, 3890, 6828, 300, 3079, 281, 41011, 11, 291, 458, 286, 478, 6883, 5489, 257, 5870, 857, 457, 341, 1558, 300, 411], "temperature": 0.0, "avg_logprob": -0.11550404407359936, "compression_ratio": 1.55, "no_speech_prob": 3.187134780091583e-06}, {"id": 498, "seek": 501756, "start": 5017.56, "end": 5031.56, "text": " in Haskell function application always has the highest precedence you can never get anything that has a higher function precedence that and it always having stumbled into the array world now it's seems like a very powerful thing that these", "tokens": [294, 8646, 43723, 2445, 3861, 1009, 575, 264, 6343, 16969, 655, 291, 393, 1128, 483, 1340, 300, 575, 257, 2946, 2445, 16969, 655, 300, 293, 309, 1009, 1419, 36668, 666, 264, 10225, 1002, 586, 309, 311, 2544, 411, 257, 588, 4005, 551, 300, 613], "temperature": 0.0, "avg_logprob": -0.12094693382581075, "compression_ratio": 1.6258503401360545, "no_speech_prob": 5.769937615696108e-06}, {"id": 499, "seek": 503156, "start": 5031.56, "end": 5048.56, "text": " combinator like functions don't have just by default the higher precedence because if you have a folder a scan or a map. You're always combining that with a some kind of binary operation or unary operation to create another function that you're then going to eventually apply to", "tokens": [2512, 31927, 411, 6828, 500, 380, 362, 445, 538, 7576, 264, 2946, 16969, 655, 570, 498, 291, 362, 257, 10820, 257, 11049, 420, 257, 4471, 13, 509, 434, 1009, 21928, 300, 365, 257, 512, 733, 295, 17434, 6916, 420, 517, 822, 6916, 281, 1884, 1071, 2445, 300, 291, 434, 550, 516, 281, 4728, 3079, 281], "temperature": 0.0, "avg_logprob": -0.1209464523027528, "compression_ratio": 1.7709923664122138, "no_speech_prob": 7.181689397839364e-06}, {"id": 500, "seek": 503156, "start": 5048.56, "end": 5049.56, "text": " something and.", "tokens": [746, 293, 13], "temperature": 0.0, "avg_logprob": -0.1209464523027528, "compression_ratio": 1.7709923664122138, "no_speech_prob": 7.181689397839364e-06}, {"id": 501, "seek": 503156, "start": 5049.56, "end": 5060.56, "text": " Yeah, but the basic like right to left, you know, putting aside the, the higher order functions or operators as they're known in APL, the basic right to left path I mean.", "tokens": [865, 11, 457, 264, 3875, 411, 558, 281, 1411, 11, 291, 458, 11, 3372, 7359, 264, 11, 264, 2946, 1668, 6828, 420, 19077, 382, 436, 434, 2570, 294, 5372, 43, 11, 264, 3875, 558, 281, 1411, 3100, 286, 914, 13], "temperature": 0.0, "avg_logprob": -0.1209464523027528, "compression_ratio": 1.7709923664122138, "no_speech_prob": 7.181689397839364e-06}, {"id": 502, "seek": 506056, "start": 5060.56, "end": 5067.56, "text": " And for teaching and for my own brain gosh that's so much nicer than like in C++.", "tokens": [400, 337, 4571, 293, 337, 452, 1065, 3567, 6502, 300, 311, 370, 709, 22842, 813, 411, 294, 383, 25472, 13], "temperature": 0.0, "avg_logprob": -0.13252626401241693, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.506850432837382e-05}, {"id": 503, "seek": 506056, "start": 5067.56, "end": 5080.56, "text": " Oh my god, they're not being able to operate a precedence. Yeah, there's no way I can ever remember that, and there's a good chance when I'm reading somebody else's code that, you know, they haven't used parentheses because they didn't really need them that I have", "tokens": [876, 452, 3044, 11, 436, 434, 406, 885, 1075, 281, 9651, 257, 16969, 655, 13, 865, 11, 456, 311, 572, 636, 286, 393, 1562, 1604, 300, 11, 293, 456, 311, 257, 665, 2931, 562, 286, 478, 3760, 2618, 1646, 311, 3089, 300, 11, 291, 458, 11, 436, 2378, 380, 1143, 34153, 570, 436, 994, 380, 534, 643, 552, 300, 286, 362], "temperature": 0.0, "avg_logprob": -0.13252626401241693, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.506850432837382e-05}, {"id": 504, "seek": 506056, "start": 5080.56, "end": 5084.56, "text": " no idea where they have to go and then I have to go and look it up.", "tokens": [572, 1558, 689, 436, 362, 281, 352, 293, 550, 286, 362, 281, 352, 293, 574, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.13252626401241693, "compression_ratio": 1.6967213114754098, "no_speech_prob": 2.506850432837382e-05}, {"id": 505, "seek": 508456, "start": 5084.56, "end": 5097.56, "text": " So it's another of these things that with the kids I'm like, okay you remember that stuff we spent ages on about like, you know, first you do exponents, and then you do times, it's like, okay you don't have to do any of that and they feel, you just go right to left,", "tokens": [407, 309, 311, 1071, 295, 613, 721, 300, 365, 264, 2301, 286, 478, 411, 11, 1392, 291, 1604, 300, 1507, 321, 4418, 12357, 322, 466, 411, 11, 291, 458, 11, 700, 291, 360, 12680, 791, 11, 293, 550, 291, 360, 1413, 11, 309, 311, 411, 11, 1392, 291, 500, 380, 362, 281, 360, 604, 295, 300, 293, 436, 841, 11, 291, 445, 352, 558, 281, 1411, 11], "temperature": 0.0, "avg_logprob": -0.2002331744665387, "compression_ratio": 1.6458333333333333, "no_speech_prob": 1.7502097762189806e-05}, {"id": 506, "seek": 508456, "start": 5097.56, "end": 5100.56, "text": " and they're just like, oh, that's so much better.", "tokens": [293, 436, 434, 445, 411, 11, 1954, 11, 300, 311, 370, 709, 1101, 13], "temperature": 0.0, "avg_logprob": -0.2002331744665387, "compression_ratio": 1.6458333333333333, "no_speech_prob": 1.7502097762189806e-05}, {"id": 507, "seek": 510056, "start": 5100.56, "end": 5114.56, "text": " What is your, this literally came up at work like a month ago, where I was giving this mini APL like we had 10 minutes at the end of a meeting, and then I just made this offhand remark that of course like the evaluation order and APL is a much simpler model than what", "tokens": [708, 307, 428, 11, 341, 3736, 1361, 493, 412, 589, 411, 257, 1618, 2057, 11, 689, 286, 390, 2902, 341, 8382, 5372, 43, 411, 321, 632, 1266, 2077, 412, 264, 917, 295, 257, 3440, 11, 293, 550, 286, 445, 1027, 341, 766, 5543, 7942, 300, 295, 1164, 411, 264, 13344, 1668, 293, 5372, 43, 307, 257, 709, 18587, 2316, 813, 437], "temperature": 0.0, "avg_logprob": -0.10679201095823258, "compression_ratio": 1.7077922077922079, "no_speech_prob": 3.373112849658355e-05}, {"id": 508, "seek": 510056, "start": 5114.56, "end": 5128.56, "text": " we learned in school. And like, I upset like there was I don't know 20 people in the meeting, and it was the most controversial thing I had said, like, and I, I almost had like an out of body experience because I thought I was saying something that was like,", "tokens": [321, 3264, 294, 1395, 13, 400, 411, 11, 286, 8340, 411, 456, 390, 286, 500, 380, 458, 945, 561, 294, 264, 3440, 11, 293, 309, 390, 264, 881, 17323, 551, 286, 632, 848, 11, 411, 11, 293, 286, 11, 286, 1920, 632, 411, 364, 484, 295, 1772, 1752, 570, 286, 1194, 286, 390, 1566, 746, 300, 390, 411, 11], "temperature": 0.0, "avg_logprob": -0.10679201095823258, "compression_ratio": 1.7077922077922079, "no_speech_prob": 3.373112849658355e-05}, {"id": 509, "seek": 512856, "start": 5128.56, "end": 5143.56, "text": " objectively just true and then I was like, wait a second what I'm clearly missed like is there. Yeah, well you were wrong like how do you know I mean, at most adults are incapable of like new ideas, it's just, it's, it's", "tokens": [46067, 445, 2074, 293, 550, 286, 390, 411, 11, 1699, 257, 1150, 437, 286, 478, 4448, 6721, 411, 307, 456, 13, 865, 11, 731, 291, 645, 2085, 411, 577, 360, 291, 458, 286, 914, 11, 412, 881, 8865, 366, 44174, 295, 411, 777, 3487, 11, 309, 311, 445, 11, 309, 311, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.17214529279252172, "compression_ratio": 1.5170454545454546, "no_speech_prob": 3.4802684240275994e-05}, {"id": 510, "seek": 512856, "start": 5143.56, "end": 5147.56, "text": " that's what I should have said in the meeting.", "tokens": [300, 311, 437, 286, 820, 362, 848, 294, 264, 3440, 13], "temperature": 0.0, "avg_logprob": -0.17214529279252172, "compression_ratio": 1.5170454545454546, "no_speech_prob": 3.4802684240275994e-05}, {"id": 511, "seek": 514756, "start": 5147.56, "end": 5159.56, "text": " I mean this is a reason that I another reason I like doing things like APL study groups because it's a way of like self selecting that small group of humanity who's actually interested in trying new things despite the fact that they're grown ups and then try", "tokens": [286, 914, 341, 307, 257, 1778, 300, 286, 1071, 1778, 286, 411, 884, 721, 411, 5372, 43, 2979, 3935, 570, 309, 311, 257, 636, 295, 411, 2698, 18182, 300, 1359, 1594, 295, 10243, 567, 311, 767, 3102, 294, 1382, 777, 721, 7228, 264, 1186, 300, 436, 434, 7709, 15497, 293, 550, 853], "temperature": 0.0, "avg_logprob": -0.15763228762466297, "compression_ratio": 1.7679180887372015, "no_speech_prob": 2.5458311938564293e-05}, {"id": 512, "seek": 514756, "start": 5159.56, "end": 5171.56, "text": " to surround myself with those people in my life. But isn't it sad then, I mean what has happened to those grownups like when you mentioned, teaching these people and trying to like map their existing knowledge onto a PL things what does mean to box and so on.", "tokens": [281, 6262, 2059, 365, 729, 561, 294, 452, 993, 13, 583, 1943, 380, 309, 4227, 550, 11, 286, 914, 437, 575, 2011, 281, 729, 7709, 7528, 411, 562, 291, 2835, 11, 4571, 613, 561, 293, 1382, 281, 411, 4471, 641, 6741, 3601, 3911, 257, 6999, 721, 437, 775, 914, 281, 2424, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.15763228762466297, "compression_ratio": 1.7679180887372015, "no_speech_prob": 2.5458311938564293e-05}, {"id": 513, "seek": 517156, "start": 5171.56, "end": 5184.56, "text": " I find that to children and non programmers, expanding their array model and and how the functions are applied and so on, is almost trivial meets no resistance at all.", "tokens": [286, 915, 300, 281, 2227, 293, 2107, 41504, 11, 14702, 641, 10225, 2316, 293, 293, 577, 264, 6828, 366, 6456, 293, 370, 322, 11, 307, 1920, 26703, 13961, 572, 7335, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.18697246638211337, "compression_ratio": 1.6008403361344539, "no_speech_prob": 4.679375342675485e-05}, {"id": 514, "seek": 517156, "start": 5184.56, "end": 5196.56, "text": " And it's all those adults that have either learned their, their PEMDAS or BOTMAS or whatever the rules are, and all the computer science people that know their precedence tables and their lists of lists and so on.", "tokens": [400, 309, 311, 439, 729, 8865, 300, 362, 2139, 3264, 641, 11, 641, 430, 6683, 35, 3160, 420, 363, 5068, 44, 3160, 420, 2035, 264, 4474, 366, 11, 293, 439, 264, 3820, 3497, 561, 300, 458, 641, 16969, 655, 8020, 293, 641, 14511, 295, 14511, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.18697246638211337, "compression_ratio": 1.6008403361344539, "no_speech_prob": 4.679375342675485e-05}, {"id": 515, "seek": 519656, "start": 5196.56, "end": 5206.56, "text": " Those are the ones that are really really struggling it's not just resisting, they're clearly struggling. They're really trying and it's a lot of effort.", "tokens": [3950, 366, 264, 2306, 300, 366, 534, 534, 9314, 309, 311, 406, 445, 43940, 11, 436, 434, 4448, 9314, 13, 814, 434, 534, 1382, 293, 309, 311, 257, 688, 295, 4630, 13], "temperature": 0.0, "avg_logprob": -0.14214491844177246, "compression_ratio": 1.5578231292517006, "no_speech_prob": 1.7220281733898446e-05}, {"id": 516, "seek": 519656, "start": 5206.56, "end": 5212.56, "text": " So, there is actually I mean that is a known thing in educational research.", "tokens": [407, 11, 456, 307, 767, 286, 914, 300, 307, 257, 2570, 551, 294, 10189, 2132, 13], "temperature": 0.0, "avg_logprob": -0.14214491844177246, "compression_ratio": 1.5578231292517006, "no_speech_prob": 1.7220281733898446e-05}, {"id": 517, "seek": 521256, "start": 5212.56, "end": 5226.56, "text": " Yeah, I mean I spent months earlier this year, and like last year, reading every paper I quote about, you know, education, because I thought if I'm going to be homeschooling that I should try to know what I'm doing.", "tokens": [865, 11, 286, 914, 286, 4418, 2493, 3071, 341, 1064, 11, 293, 411, 1036, 1064, 11, 3760, 633, 3035, 286, 6513, 466, 11, 291, 458, 11, 3309, 11, 570, 286, 1194, 498, 286, 478, 516, 281, 312, 7388, 21856, 278, 300, 286, 820, 853, 281, 458, 437, 286, 478, 884, 13], "temperature": 0.0, "avg_logprob": -0.11800197254527699, "compression_ratio": 1.396103896103896, "no_speech_prob": 5.303305442794226e-05}, {"id": 518, "seek": 522656, "start": 5226.56, "end": 5242.56, "text": " And, yeah, what you describe it arm is absolutely a thing, which is that, that, you know, the research shows that trying, you know, when you've got a, you know, an existing idea which is a, an incorrect understanding of something and you're trying to", "tokens": [400, 11, 1338, 11, 437, 291, 6786, 309, 3726, 307, 3122, 257, 551, 11, 597, 307, 300, 11, 300, 11, 291, 458, 11, 264, 2132, 3110, 300, 1382, 11, 291, 458, 11, 562, 291, 600, 658, 257, 11, 291, 458, 11, 364, 6741, 1558, 597, 307, 257, 11, 364, 18424, 3701, 295, 746, 293, 291, 434, 1382, 281], "temperature": 0.0, "avg_logprob": -0.14309237080235634, "compression_ratio": 1.6556291390728477, "no_speech_prob": 3.589212064980529e-05}, {"id": 519, "seek": 524256, "start": 5242.56, "end": 5260.56, "text": " place it with a correct understanding that is much harder than learning the correct version directly. So which is obviously a challenge when you think about analogies and analogy has to be good enough to lead directly to the, to the correct version.", "tokens": [1081, 309, 365, 257, 3006, 3701, 300, 307, 709, 6081, 813, 2539, 264, 3006, 3037, 3838, 13, 407, 597, 307, 2745, 257, 3430, 562, 291, 519, 466, 16660, 530, 293, 21663, 575, 281, 312, 665, 1547, 281, 1477, 3838, 281, 264, 11, 281, 264, 3006, 3037, 13], "temperature": 0.0, "avg_logprob": -0.1010907397550695, "compression_ratio": 1.6274509803921569, "no_speech_prob": 7.249235204653814e-05}, {"id": 520, "seek": 526056, "start": 5260.56, "end": 5278.56, "text": " But I think you know the important thing is to find the people who are who have the curiosity and tenacity to be prepared to go over that hurdle, even though it's difficult, you know, because yeah it is like that's just, that's just how human brains are so so be it, you know.", "tokens": [583, 286, 519, 291, 458, 264, 1021, 551, 307, 281, 915, 264, 561, 567, 366, 567, 362, 264, 18769, 293, 2064, 19008, 281, 312, 4927, 281, 352, 670, 300, 47423, 11, 754, 1673, 309, 311, 2252, 11, 291, 458, 11, 570, 1338, 309, 307, 411, 300, 311, 445, 11, 300, 311, 445, 577, 1952, 15442, 366, 370, 370, 312, 309, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.07563645699444939, "compression_ratio": 1.5771428571428572, "no_speech_prob": 3.319585448480211e-05}, {"id": 521, "seek": 527856, "start": 5278.56, "end": 5291.56, "text": " Yeah unlearning is really hard work actually. And if you think about it, it probably should be because you spend a lot of time and energy to put some kind of a pattern into your brain. Right, I don't want to have that evaporate very quickly.", "tokens": [865, 25272, 2341, 307, 534, 1152, 589, 767, 13, 400, 498, 291, 519, 466, 309, 11, 309, 1391, 820, 312, 570, 291, 3496, 257, 688, 295, 565, 293, 2281, 281, 829, 512, 733, 295, 257, 5102, 666, 428, 3567, 13, 1779, 11, 286, 500, 380, 528, 281, 362, 300, 26315, 473, 588, 2661, 13], "temperature": 0.0, "avg_logprob": -0.11118763068626666, "compression_ratio": 1.4011627906976745, "no_speech_prob": 6.400253187166527e-05}, {"id": 522, "seek": 529156, "start": 5291.56, "end": 5309.56, "text": " Yeah, and our, you know, my elimination occurs around what like ages eight to 12 or something so like our brains are literally trying to stop us from having to learn new things because our brains think that they've got stuff sorted out at that point and so they should focus on keeping", "tokens": [865, 11, 293, 527, 11, 291, 458, 11, 452, 29224, 11843, 926, 437, 411, 12357, 3180, 281, 2272, 420, 746, 370, 411, 527, 15442, 366, 3736, 1382, 281, 1590, 505, 490, 1419, 281, 1466, 777, 721, 570, 527, 15442, 519, 300, 436, 600, 658, 1507, 25462, 484, 412, 300, 935, 293, 370, 436, 820, 1879, 322, 5145], "temperature": 0.0, "avg_logprob": -0.164754907708419, "compression_ratio": 1.6245210727969348, "no_speech_prob": 5.824902837048285e-05}, {"id": 523, "seek": 529156, "start": 5309.56, "end": 5317.56, "text": " long term memories around so yeah, it does become harder. But, you know, a little bit. It's still totally doable. The solution is obvious.", "tokens": [938, 1433, 8495, 926, 370, 1338, 11, 309, 775, 1813, 6081, 13, 583, 11, 291, 458, 11, 257, 707, 857, 13, 467, 311, 920, 3879, 41183, 13, 440, 3827, 307, 6322, 13], "temperature": 0.0, "avg_logprob": -0.164754907708419, "compression_ratio": 1.6245210727969348, "no_speech_prob": 5.824902837048285e-05}, {"id": 524, "seek": 531756, "start": 5317.56, "end": 5321.56, "text": " That's what I'm doing.", "tokens": [663, 311, 437, 286, 478, 884, 13], "temperature": 0.0, "avg_logprob": -0.3212132868559464, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.301109533524141e-05}, {"id": 525, "seek": 531756, "start": 5321.56, "end": 5328.56, "text": " What was the word you mentioned a mile a mile nation mile mile nation me y, l i n.", "tokens": [708, 390, 264, 1349, 291, 2835, 257, 12620, 257, 12620, 4790, 12620, 12620, 4790, 385, 288, 11, 287, 741, 297, 13], "temperature": 0.0, "avg_logprob": -0.3212132868559464, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.301109533524141e-05}, {"id": 526, "seek": 531756, "start": 5328.56, "end": 5330.56, "text": " At i n.", "tokens": [1711, 741, 297, 13], "temperature": 0.0, "avg_logprob": -0.3212132868559464, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.301109533524141e-05}, {"id": 527, "seek": 531756, "start": 5330.56, "end": 5338.56, "text": " Interesting. I'd not heard that word before it's a physical coating that I can't remember goes on the dendrites. I think it's on the axons, isn't it.", "tokens": [14711, 13, 286, 1116, 406, 2198, 300, 1349, 949, 309, 311, 257, 4001, 20163, 300, 286, 393, 380, 1604, 1709, 322, 264, 274, 521, 30931, 13, 286, 519, 309, 311, 322, 264, 6360, 892, 11, 1943, 380, 309, 13], "temperature": 0.0, "avg_logprob": -0.3212132868559464, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.301109533524141e-05}, {"id": 528, "seek": 531756, "start": 5338.56, "end": 5345.56, "text": " It's these fat layers or cholesterol layers.", "tokens": [467, 311, 613, 4046, 7914, 420, 24716, 7914, 13], "temperature": 0.0, "avg_logprob": -0.3212132868559464, "compression_ratio": 1.6296296296296295, "no_speech_prob": 6.301109533524141e-05}, {"id": 529, "seek": 534556, "start": 5345.56, "end": 5351.56, "text": " I've never taken a biology courses in my education so clearly I've, I've missed out on that aspect.", "tokens": [286, 600, 1128, 2726, 257, 14956, 7712, 294, 452, 3309, 370, 4448, 286, 600, 11, 286, 600, 6721, 484, 322, 300, 4171, 13], "temperature": 0.0, "avg_logprob": -0.2817499137219088, "compression_ratio": 1.5260416666666667, "no_speech_prob": 6.293084879871458e-05}, {"id": 530, "seek": 534556, "start": 5351.56, "end": 5356.56, "text": " You you mile in a you mile in aided anyway.", "tokens": [509, 291, 12620, 294, 257, 291, 12620, 294, 257, 2112, 4033, 13], "temperature": 0.0, "avg_logprob": -0.2817499137219088, "compression_ratio": 1.5260416666666667, "no_speech_prob": 6.293084879871458e-05}, {"id": 531, "seek": 534556, "start": 5356.56, "end": 5361.56, "text": " Isn't that an appeal function.", "tokens": [6998, 380, 300, 364, 13668, 2445, 13], "temperature": 0.0, "avg_logprob": -0.2817499137219088, "compression_ratio": 1.5260416666666667, "no_speech_prob": 6.293084879871458e-05}, {"id": 532, "seek": 534556, "start": 5361.56, "end": 5370.56, "text": " You also mentioned the word tenacity, Jeffrey. Yeah, and, and, and I was watching an interview did with Samian butani.", "tokens": [509, 611, 2835, 264, 1349, 2064, 19008, 11, 28721, 13, 865, 11, 293, 11, 293, 11, 293, 286, 390, 1976, 364, 4049, 630, 365, 4832, 952, 457, 3782, 13], "temperature": 0.0, "avg_logprob": -0.2817499137219088, "compression_ratio": 1.5260416666666667, "no_speech_prob": 6.293084879871458e-05}, {"id": 533, "seek": 537056, "start": 5370.56, "end": 5385.56, "text": " Yeah, and you were talking about, because it sounds like he was you spotted at an early point in his working with Kaggle that he was something probably different than you said was the tenacity to keep working at something.", "tokens": [865, 11, 293, 291, 645, 1417, 466, 11, 570, 309, 3263, 411, 415, 390, 291, 21010, 412, 364, 2440, 935, 294, 702, 1364, 365, 48751, 22631, 300, 415, 390, 746, 1391, 819, 813, 291, 848, 390, 264, 2064, 19008, 281, 1066, 1364, 412, 746, 13], "temperature": 0.0, "avg_logprob": -0.1377892549010529, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.4730734619661234e-05}, {"id": 534, "seek": 537056, "start": 5385.56, "end": 5393.56, "text": " Yeah, I think that's a really important part about educating people that they don't necessarily expect learning something new to be easy.", "tokens": [865, 11, 286, 519, 300, 311, 257, 534, 1021, 644, 466, 28835, 561, 300, 436, 500, 380, 4725, 2066, 2539, 746, 777, 281, 312, 1858, 13], "temperature": 0.0, "avg_logprob": -0.1377892549010529, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.4730734619661234e-05}, {"id": 535, "seek": 537056, "start": 5393.56, "end": 5396.56, "text": " Yeah, but you can do it.", "tokens": [865, 11, 457, 291, 393, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.1377892549010529, "compression_ratio": 1.6666666666666667, "no_speech_prob": 1.4730734619661234e-05}, {"id": 536, "seek": 539656, "start": 5396.56, "end": 5416.56, "text": " Yeah, I mean I really noticed that when I was started learning Chinese, like I went to, you know, just some local class in in Melbourne, and everybody was very very enthusiastic, you know, and everybody was going to learn Chinese.", "tokens": [865, 11, 286, 914, 286, 534, 5694, 300, 562, 286, 390, 1409, 2539, 4649, 11, 411, 286, 1437, 281, 11, 291, 458, 11, 445, 512, 2654, 1508, 294, 294, 27496, 11, 293, 2201, 390, 588, 588, 28574, 11, 291, 458, 11, 293, 2201, 390, 516, 281, 1466, 4649, 13], "temperature": 0.0, "avg_logprob": -0.09997720578137566, "compression_ratio": 1.580110497237569, "no_speech_prob": 4.32687702414114e-05}, {"id": 537, "seek": 539656, "start": 5416.56, "end": 5420.56, "text": " And we all talked about the things we were going to do.", "tokens": [400, 321, 439, 2825, 466, 264, 721, 321, 645, 516, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.09997720578137566, "compression_ratio": 1.580110497237569, "no_speech_prob": 4.32687702414114e-05}, {"id": 538, "seek": 542056, "start": 5420.56, "end": 5429.56, "text": " And each week there'd be fewer and fewer people there. And, you know, I kind of tried to keep in touch with them. But after a year.", "tokens": [400, 1184, 1243, 456, 1116, 312, 13366, 293, 13366, 561, 456, 13, 400, 11, 291, 458, 11, 286, 733, 295, 3031, 281, 1066, 294, 2557, 365, 552, 13, 583, 934, 257, 1064, 13], "temperature": 0.0, "avg_logprob": -0.11516193043101917, "compression_ratio": 1.681992337164751, "no_speech_prob": 4.6071309043327346e-05}, {"id": 539, "seek": 542056, "start": 5429.56, "end": 5443.56, "text": " Every single other person had given up and I was the only one still doing it, you know, so then after a couple of years people would be like, Wow, you're so smart you learn Chinese, this is like, no man like during those first few weeks, I was pretty sure I was", "tokens": [2048, 2167, 661, 954, 632, 2212, 493, 293, 286, 390, 264, 787, 472, 920, 884, 309, 11, 291, 458, 11, 370, 550, 934, 257, 1916, 295, 924, 561, 576, 312, 411, 11, 3153, 11, 291, 434, 370, 4069, 291, 1466, 4649, 11, 341, 307, 411, 11, 572, 587, 411, 1830, 729, 700, 1326, 3259, 11, 286, 390, 1238, 988, 286, 390], "temperature": 0.0, "avg_logprob": -0.11516193043101917, "compression_ratio": 1.681992337164751, "no_speech_prob": 4.6071309043327346e-05}, {"id": 540, "seek": 542056, "start": 5443.56, "end": 5447.56, "text": " learning more slowly than the other students.", "tokens": [2539, 544, 5692, 813, 264, 661, 1731, 13], "temperature": 0.0, "avg_logprob": -0.11516193043101917, "compression_ratio": 1.681992337164751, "no_speech_prob": 4.6071309043327346e-05}, {"id": 541, "seek": 544756, "start": 5447.56, "end": 5453.56, "text": " And I stopped doing it. So, of course they didn't learn Chinese.", "tokens": [400, 286, 5936, 884, 309, 13, 407, 11, 295, 1164, 436, 994, 380, 1466, 4649, 13], "temperature": 0.0, "avg_logprob": -0.13535913857080603, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00012720903032459319}, {"id": 542, "seek": 544756, "start": 5453.56, "end": 5468.56, "text": " And I don't know what the trick is because, yeah, it's the same thing with, you know, like it fast AI courses they're really designed to keep people interested and get people doing fun stuff from, from day one and, you know, still, I'd say most people drop out.", "tokens": [400, 286, 500, 380, 458, 437, 264, 4282, 307, 570, 11, 1338, 11, 309, 311, 264, 912, 551, 365, 11, 291, 458, 11, 411, 309, 2370, 7318, 7712, 436, 434, 534, 4761, 281, 1066, 561, 3102, 293, 483, 561, 884, 1019, 1507, 490, 11, 490, 786, 472, 293, 11, 291, 458, 11, 920, 11, 286, 1116, 584, 881, 561, 3270, 484, 13], "temperature": 0.0, "avg_logprob": -0.13535913857080603, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00012720903032459319}, {"id": 543, "seek": 544756, "start": 5468.56, "end": 5471.56, "text": " And the ones that don't.", "tokens": [400, 264, 2306, 300, 500, 380, 13], "temperature": 0.0, "avg_logprob": -0.13535913857080603, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.00012720903032459319}, {"id": 544, "seek": 547156, "start": 5471.56, "end": 5482.56, "text": " Most of them end up becoming like actual world class practitioners and they, you know, build new products and startups and whatever else. And people will be like, Oh, I wish I knew neural nets and deep learnings.", "tokens": [4534, 295, 552, 917, 493, 5617, 411, 3539, 1002, 1508, 25742, 293, 436, 11, 291, 458, 11, 1322, 777, 3383, 293, 28041, 293, 2035, 1646, 13, 400, 561, 486, 312, 411, 11, 876, 11, 286, 3172, 286, 2586, 18161, 36170, 293, 2452, 2539, 82, 13], "temperature": 0.0, "avg_logprob": -0.17258175599922254, "compression_ratio": 1.5690376569037656, "no_speech_prob": 4.067798363394104e-05}, {"id": 545, "seek": 547156, "start": 5482.56, "end": 5489.56, "text": " It's like, okay, here's the course. Just, just do it and don't give up.", "tokens": [467, 311, 411, 11, 1392, 11, 510, 311, 264, 1164, 13, 1449, 11, 445, 360, 309, 293, 500, 380, 976, 493, 13], "temperature": 0.0, "avg_logprob": -0.17258175599922254, "compression_ratio": 1.5690376569037656, "no_speech_prob": 4.067798363394104e-05}, {"id": 546, "seek": 547156, "start": 5489.56, "end": 5493.56, "text": " But yeah, I don't know, tenacity.", "tokens": [583, 1338, 11, 286, 500, 380, 458, 11, 2064, 19008, 13], "temperature": 0.0, "avg_logprob": -0.17258175599922254, "compression_ratio": 1.5690376569037656, "no_speech_prob": 4.067798363394104e-05}, {"id": 547, "seek": 547156, "start": 5493.56, "end": 5496.56, "text": " It's not a very common virtue, I think, for some reason.", "tokens": [467, 311, 406, 257, 588, 2689, 20816, 11, 286, 519, 11, 337, 512, 1778, 13], "temperature": 0.0, "avg_logprob": -0.17258175599922254, "compression_ratio": 1.5690376569037656, "no_speech_prob": 4.067798363394104e-05}, {"id": 548, "seek": 549656, "start": 5496.56, "end": 5502.56, "text": " It's something effort, I think it's Joe Bowler at Stanford talk about the growth mindset.", "tokens": [467, 311, 746, 4630, 11, 286, 519, 309, 311, 6807, 12903, 1918, 412, 20374, 751, 466, 264, 4599, 12543, 13], "temperature": 0.0, "avg_logprob": -0.14870126941536047, "compression_ratio": 1.608910891089109, "no_speech_prob": 0.0001353359839413315}, {"id": 549, "seek": 549656, "start": 5502.56, "end": 5508.56, "text": " And I think that is something that, for whatever reason, some people tend to and maybe it's my own nation.", "tokens": [400, 286, 519, 300, 307, 746, 300, 11, 337, 2035, 1778, 11, 512, 561, 3928, 281, 293, 1310, 309, 311, 452, 1065, 4790, 13], "temperature": 0.0, "avg_logprob": -0.14870126941536047, "compression_ratio": 1.608910891089109, "no_speech_prob": 0.0001353359839413315}, {"id": 550, "seek": 549656, "start": 5508.56, "end": 5517.56, "text": " At those ages you start to get that mindset where you're not so concerned about having something happen, that's easy to do well.", "tokens": [1711, 729, 12357, 291, 722, 281, 483, 300, 12543, 689, 291, 434, 406, 370, 5922, 466, 1419, 746, 1051, 11, 300, 311, 1858, 281, 360, 731, 13], "temperature": 0.0, "avg_logprob": -0.14870126941536047, "compression_ratio": 1.608910891089109, "no_speech_prob": 0.0001353359839413315}, {"id": 551, "seek": 551756, "start": 5517.56, "end": 5529.56, "text": " But just the fact that if you keep working at it, you will get it. And not everybody, I guess, is maybe put in the situations that they, they get that feedback that tells you if I keep trying this I'll get it.", "tokens": [583, 445, 264, 1186, 300, 498, 291, 1066, 1364, 412, 309, 11, 291, 486, 483, 309, 13, 400, 406, 2201, 11, 286, 2041, 11, 307, 1310, 829, 294, 264, 6851, 300, 436, 11, 436, 483, 300, 5824, 300, 5112, 291, 498, 286, 1066, 1382, 341, 286, 603, 483, 309, 13], "temperature": 0.0, "avg_logprob": -0.09049839260934413, "compression_ratio": 1.6323529411764706, "no_speech_prob": 6.961276540096151e-06}, {"id": 552, "seek": 551756, "start": 5529.56, "end": 5532.56, "text": " Yeah, if it's not easy, they stop.", "tokens": [865, 11, 498, 309, 311, 406, 1858, 11, 436, 1590, 13], "temperature": 0.0, "avg_logprob": -0.09049839260934413, "compression_ratio": 1.6323529411764706, "no_speech_prob": 6.961276540096151e-06}, {"id": 553, "seek": 551756, "start": 5532.56, "end": 5540.56, "text": " Yeah, I mean that that area of growth mindsets are very controversial idea in education.", "tokens": [865, 11, 286, 914, 300, 300, 1859, 295, 4599, 9634, 1385, 366, 588, 17323, 1558, 294, 3309, 13], "temperature": 0.0, "avg_logprob": -0.09049839260934413, "compression_ratio": 1.6323529411764706, "no_speech_prob": 6.961276540096151e-06}, {"id": 554, "seek": 554056, "start": 5540.56, "end": 5550.56, "text": " Specifically the question of, can you, can you modify it? And I think it's certainly pretty well established to this point that the kind of stuff that schools have tended to do,", "tokens": [26058, 264, 1168, 295, 11, 393, 291, 11, 393, 291, 16927, 309, 30, 400, 286, 519, 309, 311, 3297, 1238, 731, 7545, 281, 341, 935, 300, 264, 733, 295, 1507, 300, 4656, 362, 34732, 281, 360, 11], "temperature": 0.0, "avg_logprob": -0.10607276424284905, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.3845206012774725e-05}, {"id": 555, "seek": 554056, "start": 5550.56, "end": 5561.56, "text": " which is put posters up around the place saying like, you know, make things a learning opportunity or don't give up, like they do nothing at all.", "tokens": [597, 307, 829, 28172, 493, 926, 264, 1081, 1566, 411, 11, 291, 458, 11, 652, 721, 257, 2539, 2650, 420, 500, 380, 976, 493, 11, 411, 436, 360, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.10607276424284905, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.3845206012774725e-05}, {"id": 556, "seek": 554056, "start": 5561.56, "end": 5566.56, "text": " You know, with my daughter, we do all kinds of stuff around this.", "tokens": [509, 458, 11, 365, 452, 4653, 11, 321, 360, 439, 3685, 295, 1507, 926, 341, 13], "temperature": 0.0, "avg_logprob": -0.10607276424284905, "compression_ratio": 1.6208333333333333, "no_speech_prob": 1.3845206012774725e-05}, {"id": 557, "seek": 556656, "start": 5566.56, "end": 5578.56, "text": " So we've actually invented a whole family of clams. And as you can imagine clams don't have a growth mindset, they tend to sit on the bottom of the ocean, not moving.", "tokens": [407, 321, 600, 767, 14479, 257, 1379, 1605, 295, 46377, 13, 400, 382, 291, 393, 3811, 46377, 500, 380, 362, 257, 4599, 12543, 11, 436, 3928, 281, 1394, 322, 264, 2767, 295, 264, 7810, 11, 406, 2684, 13], "temperature": 0.0, "avg_logprob": -0.08416116237640381, "compression_ratio": 1.7652173913043478, "no_speech_prob": 4.131203968427144e-05}, {"id": 558, "seek": 556656, "start": 5578.56, "end": 5592.56, "text": " And so the family of clams that we invented that we live with, you know, always at every point that we're going to have to like learn something new or try something new, always start screaming and don't want to have anything to do with it.", "tokens": [400, 370, 264, 1605, 295, 46377, 300, 321, 14479, 300, 321, 1621, 365, 11, 291, 458, 11, 1009, 412, 633, 935, 300, 321, 434, 516, 281, 362, 281, 411, 1466, 746, 777, 420, 853, 746, 777, 11, 1009, 722, 12636, 293, 500, 380, 528, 281, 362, 1340, 281, 360, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.08416116237640381, "compression_ratio": 1.7652173913043478, "no_speech_prob": 4.131203968427144e-05}, {"id": 559, "seek": 559256, "start": 5592.56, "end": 5600.56, "text": " So we actually have Claire telling the clams how it's going to be okay. And, you know, it's actually a good thing to learn new things.", "tokens": [407, 321, 767, 362, 22605, 3585, 264, 46377, 577, 309, 311, 516, 281, 312, 1392, 13, 400, 11, 291, 458, 11, 309, 311, 767, 257, 665, 551, 281, 1466, 777, 721, 13], "temperature": 0.0, "avg_logprob": -0.11599304149677227, "compression_ratio": 1.5846153846153845, "no_speech_prob": 5.3051251597935334e-05}, {"id": 560, "seek": 559256, "start": 5600.56, "end": 5612.56, "text": " And so we're trying stuff like that to try to like have have imaginary creatures that don't have a growth mindset and for her to realize how, how silly that is, which is fun.", "tokens": [400, 370, 321, 434, 1382, 1507, 411, 300, 281, 853, 281, 411, 362, 362, 26164, 12281, 300, 500, 380, 362, 257, 4599, 12543, 293, 337, 720, 281, 4325, 577, 11, 577, 11774, 300, 307, 11, 597, 307, 1019, 13], "temperature": 0.0, "avg_logprob": -0.11599304149677227, "compression_ratio": 1.5846153846153845, "no_speech_prob": 5.3051251597935334e-05}, {"id": 561, "seek": 561256, "start": 5612.56, "end": 5631.56, "text": " And the things that you were talking about in terms of the meta mathematics, you didn't say, oh, the successor, this is what pluses you said, how do you how do you how would you use this, how would you start to put it together themselves, which to me that's the growth mindset that if you're creating that.", "tokens": [400, 264, 721, 300, 291, 645, 1417, 466, 294, 2115, 295, 264, 19616, 18666, 11, 291, 994, 380, 584, 11, 1954, 11, 264, 31864, 11, 341, 307, 437, 1804, 279, 291, 848, 11, 577, 360, 291, 577, 360, 291, 577, 576, 291, 764, 341, 11, 577, 576, 291, 722, 281, 829, 309, 1214, 2969, 11, 597, 281, 385, 300, 311, 264, 4599, 12543, 300, 498, 291, 434, 4084, 300, 13], "temperature": 0.0, "avg_logprob": -0.2008149817183211, "compression_ratio": 1.6906077348066297, "no_speech_prob": 3.1184164981823415e-05}, {"id": 562, "seek": 563156, "start": 5631.56, "end": 5645.56, "text": " But then like, you know, gosh, you're getting to all the most controversial things in education here, Bob, because that's the other big one is discovery learning. So this idea of having kids explore and find.", "tokens": [583, 550, 411, 11, 291, 458, 11, 6502, 11, 291, 434, 1242, 281, 439, 264, 881, 17323, 721, 294, 3309, 510, 11, 6085, 11, 570, 300, 311, 264, 661, 955, 472, 307, 12114, 2539, 13, 407, 341, 1558, 295, 1419, 2301, 6839, 293, 915, 13], "temperature": 0.0, "avg_logprob": -0.061181384247618834, "compression_ratio": 1.5855855855855856, "no_speech_prob": 4.984160477761179e-05}, {"id": 563, "seek": 563156, "start": 5645.56, "end": 5654.56, "text": " It's also controversial because it turns out that actually the best way to have people understand something is to give them a good explanation.", "tokens": [467, 311, 611, 17323, 570, 309, 4523, 484, 300, 767, 264, 1151, 636, 281, 362, 561, 1223, 746, 307, 281, 976, 552, 257, 665, 10835, 13], "temperature": 0.0, "avg_logprob": -0.061181384247618834, "compression_ratio": 1.5855855855855856, "no_speech_prob": 4.984160477761179e-05}, {"id": 564, "seek": 565456, "start": 5654.56, "end": 5665.56, "text": " So it is important, like, that you combine this like, okay, how would you do this with them like, okay, let me just tell you what, you know, why this is.", "tokens": [407, 309, 307, 1021, 11, 411, 11, 300, 291, 10432, 341, 411, 11, 1392, 11, 577, 576, 291, 360, 341, 365, 552, 411, 11, 1392, 11, 718, 385, 445, 980, 291, 437, 11, 291, 458, 11, 983, 341, 307, 13], "temperature": 0.0, "avg_logprob": -0.138287585714589, "compression_ratio": 1.5057471264367817, "no_speech_prob": 2.1107973225298338e-05}, {"id": 565, "seek": 565456, "start": 5665.56, "end": 5674.56, "text": " It's easier for homeschooling with two kids, because I can make sure their exploration is short and correct.", "tokens": [467, 311, 3571, 337, 7388, 21856, 278, 365, 732, 2301, 11, 570, 286, 393, 652, 988, 641, 16197, 307, 2099, 293, 3006, 13], "temperature": 0.0, "avg_logprob": -0.138287585714589, "compression_ratio": 1.5057471264367817, "no_speech_prob": 2.1107973225298338e-05}, {"id": 566, "seek": 567456, "start": 5674.56, "end": 5685.56, "text": " You know, if you spend a whole class, you know, 15 minutes doing totally the wrong thing, then you end up with these really incorrect understandings which you then have to kind of deprogram.", "tokens": [509, 458, 11, 498, 291, 3496, 257, 1379, 1508, 11, 291, 458, 11, 2119, 2077, 884, 3879, 264, 2085, 551, 11, 550, 291, 917, 493, 365, 613, 534, 18424, 1223, 1109, 597, 291, 550, 362, 281, 733, 295, 1367, 340, 1342, 13], "temperature": 0.0, "avg_logprob": -0.14768965769622286, "compression_ratio": 1.4585987261146496, "no_speech_prob": 1.892120963020716e-05}, {"id": 567, "seek": 567456, "start": 5685.56, "end": 5690.56, "text": " So, yeah, education is hard, you know.", "tokens": [407, 11, 1338, 11, 3309, 307, 1152, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.14768965769622286, "compression_ratio": 1.4585987261146496, "no_speech_prob": 1.892120963020716e-05}, {"id": 568, "seek": 569056, "start": 5690.56, "end": 5712.56, "text": " And I think a lot of people look for these simple shortcuts, and they don't really exist. So you actually have to have good, good explanations and good problem solving methods and yeah, all this stuff.", "tokens": [400, 286, 519, 257, 688, 295, 561, 574, 337, 613, 2199, 34620, 11, 293, 436, 500, 380, 534, 2514, 13, 407, 291, 767, 362, 281, 362, 665, 11, 665, 28708, 293, 665, 1154, 12606, 7150, 293, 1338, 11, 439, 341, 1507, 13], "temperature": 0.0, "avg_logprob": -0.17762831390881148, "compression_ratio": 1.4678362573099415, "no_speech_prob": 1.0128714166057762e-05}, {"id": 569, "seek": 569056, "start": 5712.56, "end": 5714.56, "text": " It's a really interesting area though.", "tokens": [467, 311, 257, 534, 1880, 1859, 1673, 13], "temperature": 0.0, "avg_logprob": -0.17762831390881148, "compression_ratio": 1.4678362573099415, "no_speech_prob": 1.0128714166057762e-05}, {"id": 570, "seek": 569056, "start": 5714.56, "end": 5716.56, "text": " Notations.", "tokens": [1726, 763, 13], "temperature": 0.0, "avg_logprob": -0.17762831390881148, "compression_ratio": 1.4678362573099415, "no_speech_prob": 1.0128714166057762e-05}, {"id": 571, "seek": 571656, "start": 5716.56, "end": 5731.56, "text": " Yeah, and you know notation, I mean, it's not I do a live coding, you know, video thing every day with a bunch of folks, and in the most recent one.", "tokens": [865, 11, 293, 291, 458, 24657, 11, 286, 914, 11, 309, 311, 406, 286, 360, 257, 1621, 17720, 11, 291, 458, 11, 960, 551, 633, 786, 365, 257, 3840, 295, 4024, 11, 293, 294, 264, 881, 5162, 472, 13], "temperature": 0.0, "avg_logprob": -0.16624600092569988, "compression_ratio": 1.5424528301886793, "no_speech_prob": 5.8618938965082634e-06}, {"id": 572, "seek": 571656, "start": 5731.56, "end": 5736.56, "text": " We started talking about a PL why we're going to be doing a PL this week instead.", "tokens": [492, 1409, 1417, 466, 257, 6999, 983, 321, 434, 516, 281, 312, 884, 257, 6999, 341, 1243, 2602, 13], "temperature": 0.0, "avg_logprob": -0.16624600092569988, "compression_ratio": 1.5424528301886793, "no_speech_prob": 5.8618938965082634e-06}, {"id": 573, "seek": 571656, "start": 5736.56, "end": 5742.56, "text": " And I gave, you know, somebody actually said like oh my god is going to be like red checks it's.", "tokens": [400, 286, 2729, 11, 291, 458, 11, 2618, 767, 848, 411, 1954, 452, 3044, 307, 516, 281, 312, 411, 2182, 13834, 309, 311, 13], "temperature": 0.0, "avg_logprob": -0.16624600092569988, "compression_ratio": 1.5424528301886793, "no_speech_prob": 5.8618938965082634e-06}, {"id": 574, "seek": 574256, "start": 5742.56, "end": 5756.56, "text": " And, you know, I kind of said like okay so red checks is there a notation for doing stuff. And we spent an hour, solving the problem with red checks is.", "tokens": [400, 11, 291, 458, 11, 286, 733, 295, 848, 411, 1392, 370, 2182, 13834, 307, 456, 257, 24657, 337, 884, 1507, 13, 400, 321, 4418, 364, 1773, 11, 12606, 264, 1154, 365, 2182, 13834, 307, 13], "temperature": 0.0, "avg_logprob": -0.19535391330718993, "compression_ratio": 1.3217391304347825, "no_speech_prob": 1.3207622032496147e-05}, {"id": 575, "seek": 575656, "start": 5756.56, "end": 5773.56, "text": " And, oh my god it was such a powerful tool for this problem and you know by the end of it they're all like okay we want to like deeply study red checks is and obviously that's a much less flexible and powerful tool notation then a PL.", "tokens": [400, 11, 1954, 452, 3044, 309, 390, 1270, 257, 4005, 2290, 337, 341, 1154, 293, 291, 458, 538, 264, 917, 295, 309, 436, 434, 439, 411, 1392, 321, 528, 281, 411, 8760, 2979, 2182, 13834, 307, 293, 2745, 300, 311, 257, 709, 1570, 11358, 293, 4005, 2290, 24657, 550, 257, 6999, 13], "temperature": 0.0, "avg_logprob": -0.15029491697038924, "compression_ratio": 1.453416149068323, "no_speech_prob": 1.2604760740941856e-05}, {"id": 576, "seek": 577356, "start": 5773.56, "end": 5793.56, "text": " But you know we kind of talked about how once you start understanding these notations you can build things on top of them and then you kind of create these abstractions and that's yeah notation is how, you know, deep human thought kind of progresses,", "tokens": [583, 291, 458, 321, 733, 295, 2825, 466, 577, 1564, 291, 722, 3701, 613, 406, 763, 291, 393, 1322, 721, 322, 1192, 295, 552, 293, 550, 291, 733, 295, 1884, 613, 12649, 626, 293, 300, 311, 1338, 24657, 307, 577, 11, 291, 458, 11, 2452, 1952, 1194, 733, 295, 41929, 11], "temperature": 0.0, "avg_logprob": -0.09593212421123798, "compression_ratio": 1.6369047619047619, "no_speech_prob": 1.2215252354508266e-05}, {"id": 577, "seek": 577356, "start": 5793.56, "end": 5797.56, "text": " right, in a lot of ways.", "tokens": [558, 11, 294, 257, 688, 295, 2098, 13], "temperature": 0.0, "avg_logprob": -0.09593212421123798, "compression_ratio": 1.6369047619047619, "no_speech_prob": 1.2215252354508266e-05}, {"id": 578, "seek": 579756, "start": 5797.56, "end": 5805.56, "text": " Yeah, it's like I actually spoke to a math professor friend a couple of months ago about, you know, my renewed interest in APL.", "tokens": [865, 11, 309, 311, 411, 286, 767, 7179, 281, 257, 5221, 8304, 1277, 257, 1916, 295, 2493, 2057, 466, 11, 291, 458, 11, 452, 30228, 1179, 294, 5372, 43, 13], "temperature": 0.0, "avg_logprob": -0.1891621242869984, "compression_ratio": 1.5589519650655022, "no_speech_prob": 2.7522040909389034e-05}, {"id": 579, "seek": 579756, "start": 5805.56, "end": 5817.56, "text": " And he was like, and I kind of sent him some I can't remember what it was maybe doing the golden ratio or something that will snippet and he was just like, yeah, something like that looks like Greek to me I don't understand that.", "tokens": [400, 415, 390, 411, 11, 293, 286, 733, 295, 2279, 796, 512, 286, 393, 380, 1604, 437, 309, 390, 1310, 884, 264, 9729, 8509, 420, 746, 300, 486, 35623, 302, 293, 415, 390, 445, 411, 11, 1338, 11, 746, 411, 300, 1542, 411, 10281, 281, 385, 286, 500, 380, 1223, 300, 13], "temperature": 0.0, "avg_logprob": -0.1891621242869984, "compression_ratio": 1.5589519650655022, "no_speech_prob": 2.7522040909389034e-05}, {"id": 580, "seek": 581756, "start": 5817.56, "end": 5829.56, "text": " But do you do a math professor, you know, like if I said somebody who isn't in math like a page of your, you know, research, what are they going to say.", "tokens": [583, 360, 291, 360, 257, 5221, 8304, 11, 291, 458, 11, 411, 498, 286, 848, 2618, 567, 1943, 380, 294, 5221, 411, 257, 3028, 295, 428, 11, 291, 458, 11, 2132, 11, 437, 366, 436, 516, 281, 584, 13], "temperature": 0.0, "avg_logprob": -0.21550003987438274, "compression_ratio": 1.8063063063063063, "no_speech_prob": 2.4675740860402584e-05}, {"id": 581, "seek": 581756, "start": 5829.56, "end": 5840.56, "text": " And, you know, it's interesting I said like this, you know, there are ideas in here like Iverson brackets, for example, have you ever heard of Iverson brackets, he's like well of course I've heard of it like you know it's a fundamental tool in math", "tokens": [400, 11, 291, 458, 11, 309, 311, 1880, 286, 848, 411, 341, 11, 291, 458, 11, 456, 366, 3487, 294, 510, 411, 286, 840, 266, 26179, 11, 337, 1365, 11, 362, 291, 1562, 2198, 295, 286, 840, 266, 26179, 11, 415, 311, 411, 731, 295, 1164, 286, 600, 2198, 295, 309, 411, 291, 458, 309, 311, 257, 8088, 2290, 294, 5221], "temperature": 0.0, "avg_logprob": -0.21550003987438274, "compression_ratio": 1.8063063063063063, "no_speech_prob": 2.4675740860402584e-05}, {"id": 582, "seek": 584056, "start": 5840.56, "end": 5850.56, "text": " is like, well, you know, that's one thing that you guys have stolen from APL, you know, that's a powerful thing right it's like fantastic I'd never want to do without Iverson brackets.", "tokens": [307, 411, 11, 731, 11, 291, 458, 11, 300, 311, 472, 551, 300, 291, 1074, 362, 15900, 490, 5372, 43, 11, 291, 458, 11, 300, 311, 257, 4005, 551, 558, 309, 311, 411, 5456, 286, 1116, 1128, 528, 281, 360, 1553, 286, 840, 266, 26179, 13], "temperature": 0.0, "avg_logprob": -0.08853305710686578, "compression_ratio": 1.6747967479674797, "no_speech_prob": 0.00010886140807997435}, {"id": 583, "seek": 584056, "start": 5850.56, "end": 5861.56, "text": " So I kind of tried to say like okay well imagine like every other glyph that you don't understand here has some rich thing like Iverson brackets you could now learn about.", "tokens": [407, 286, 733, 295, 3031, 281, 584, 411, 1392, 731, 3811, 411, 633, 661, 22633, 950, 300, 291, 500, 380, 1223, 510, 575, 512, 4593, 551, 411, 286, 840, 266, 26179, 291, 727, 586, 1466, 466, 13], "temperature": 0.0, "avg_logprob": -0.08853305710686578, "compression_ratio": 1.6747967479674797, "no_speech_prob": 0.00010886140807997435}, {"id": 584, "seek": 584056, "start": 5861.56, "end": 5866.56, "text": " Okay, maybe I should give it a go. I'm not sure he has.", "tokens": [1033, 11, 1310, 286, 820, 976, 309, 257, 352, 13, 286, 478, 406, 988, 415, 575, 13], "temperature": 0.0, "avg_logprob": -0.08853305710686578, "compression_ratio": 1.6747967479674797, "no_speech_prob": 0.00010886140807997435}, {"id": 585, "seek": 586656, "start": 5866.56, "end": 5882.56, "text": " But I think that's a that's a good example for mathematicians is to show like his one thing at least that found its way from APL that maybe gives you a sense that for a mathematician that there might be something in here.", "tokens": [583, 286, 519, 300, 311, 257, 300, 311, 257, 665, 1365, 337, 32811, 2567, 307, 281, 855, 411, 702, 472, 551, 412, 1935, 300, 1352, 1080, 636, 490, 5372, 43, 300, 1310, 2709, 291, 257, 2020, 300, 337, 257, 48281, 300, 456, 1062, 312, 746, 294, 510, 13], "temperature": 0.0, "avg_logprob": -0.10725003022413987, "compression_ratio": 1.5136986301369864, "no_speech_prob": 3.372348874108866e-05}, {"id": 586, "seek": 588256, "start": 5882.56, "end": 5901.56, "text": " On that note, because I know we are potentially well we've gone way over but this has been awesome. But, but a question I think that might be a good question to end on is, is, do you have any advice for folks that want to learn something,", "tokens": [1282, 300, 3637, 11, 570, 286, 458, 321, 366, 7263, 731, 321, 600, 2780, 636, 670, 457, 341, 575, 668, 3476, 13, 583, 11, 457, 257, 1168, 286, 519, 300, 1062, 312, 257, 665, 1168, 281, 917, 322, 307, 11, 307, 11, 360, 291, 362, 604, 5192, 337, 4024, 300, 528, 281, 1466, 746, 11], "temperature": 0.0, "avg_logprob": -0.06931993516825014, "compression_ratio": 1.4691358024691359, "no_speech_prob": 2.3548931494588032e-05}, {"id": 587, "seek": 590156, "start": 5901.56, "end": 5918.56, "text": " like Chinese, or an array language, or to get through your fast AI course. And is there because I think, you know, like you said you like to self select for folks that are the curious types and that want to learn new things and new ways to solve things.", "tokens": [411, 4649, 11, 420, 364, 10225, 2856, 11, 420, 281, 483, 807, 428, 2370, 7318, 1164, 13, 400, 307, 456, 570, 286, 519, 11, 291, 458, 11, 411, 291, 848, 291, 411, 281, 2698, 3048, 337, 4024, 300, 366, 264, 6369, 3467, 293, 300, 528, 281, 1466, 777, 721, 293, 777, 2098, 281, 5039, 721, 13], "temperature": 0.0, "avg_logprob": -0.14461843172709146, "compression_ratio": 1.5333333333333334, "no_speech_prob": 4.936558980261907e-06}, {"id": 588, "seek": 591856, "start": 5918.56, "end": 5935.56, "text": " Is there any way, other than just being tenacious to like be tenacious is there tips to, you know, approaching something with some angle because I think a lot of the folks may be listening to this don't have that issue but I definitely know a ton of people", "tokens": [1119, 456, 604, 636, 11, 661, 813, 445, 885, 2064, 22641, 281, 411, 312, 2064, 22641, 307, 456, 6082, 281, 11, 291, 458, 11, 14908, 746, 365, 512, 5802, 570, 286, 519, 257, 688, 295, 264, 4024, 815, 312, 4764, 281, 341, 500, 380, 362, 300, 2734, 457, 286, 2138, 458, 257, 2952, 295, 561], "temperature": 0.0, "avg_logprob": -0.07561971539648894, "compression_ratio": 1.7704280155642023, "no_speech_prob": 1.428368159395177e-05}, {"id": 589, "seek": 591856, "start": 5935.56, "end": 5945.56, "text": " that are the are the kind of folks that you know they'll join a study group but then three weeks and they, you know, the kind of lose interest or, or they decide it's too much work or too difficult.", "tokens": [300, 366, 264, 366, 264, 733, 295, 4024, 300, 291, 458, 436, 603, 3917, 257, 2979, 1594, 457, 550, 1045, 3259, 293, 436, 11, 291, 458, 11, 264, 733, 295, 3624, 1179, 420, 11, 420, 436, 4536, 309, 311, 886, 709, 589, 420, 886, 2252, 13], "temperature": 0.0, "avg_logprob": -0.07561971539648894, "compression_ratio": 1.7704280155642023, "no_speech_prob": 1.428368159395177e-05}, {"id": 590, "seek": 594556, "start": 5945.56, "end": 5951.56, "text": " As an educator and you know, it seems like you operate in this space.", "tokens": [1018, 364, 31237, 293, 291, 458, 11, 309, 2544, 411, 291, 9651, 294, 341, 1901, 13], "temperature": 0.0, "avg_logprob": -0.08438162900963608, "compression_ratio": 1.3529411764705883, "no_speech_prob": 1.384148436045507e-05}, {"id": 591, "seek": 594556, "start": 5951.56, "end": 5959.56, "text": " Do you have advice to tell folks you know, I mean so much Connor. I actually kind of embedded in my courses a lot.", "tokens": [1144, 291, 362, 5192, 281, 980, 4024, 291, 458, 11, 286, 914, 370, 709, 33133, 13, 286, 767, 733, 295, 16741, 294, 452, 7712, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.08438162900963608, "compression_ratio": 1.3529411764705883, "no_speech_prob": 1.384148436045507e-05}, {"id": 592, "seek": 595956, "start": 5959.56, "end": 5975.56, "text": " I can give you some quick summaries but what I will say is my friend radicals mouse key who's been taking my courses for like four years has taken everything I've said, and his experience of those things and turn it into a book.", "tokens": [286, 393, 976, 291, 512, 1702, 8367, 4889, 457, 437, 286, 486, 584, 307, 452, 1277, 12001, 82, 9719, 2141, 567, 311, 668, 1940, 452, 7712, 337, 411, 1451, 924, 575, 2726, 1203, 286, 600, 848, 11, 293, 702, 1752, 295, 729, 721, 293, 1261, 309, 666, 257, 1446, 13], "temperature": 0.0, "avg_logprob": -0.16913628578186035, "compression_ratio": 1.617391304347826, "no_speech_prob": 2.246473559353035e-05}, {"id": 593, "seek": 595956, "start": 5975.56, "end": 5981.56, "text": " So if you read it as mouse keys book is called meta learning.", "tokens": [407, 498, 291, 1401, 309, 382, 9719, 9317, 1446, 307, 1219, 19616, 2539, 13], "temperature": 0.0, "avg_logprob": -0.16913628578186035, "compression_ratio": 1.617391304347826, "no_speech_prob": 2.246473559353035e-05}, {"id": 594, "seek": 595956, "start": 5981.56, "end": 5987.56, "text": " Powerful mental models for deep learning. This is learning as in learning deeply.", "tokens": [7086, 906, 4973, 5245, 337, 2452, 2539, 13, 639, 307, 2539, 382, 294, 2539, 8760, 13], "temperature": 0.0, "avg_logprob": -0.16913628578186035, "compression_ratio": 1.617391304347826, "no_speech_prob": 2.246473559353035e-05}, {"id": 595, "seek": 598756, "start": 5987.56, "end": 6000.56, "text": " So, yeah, check out his book to get the full answer. I mean, there's just, there's a lot of things you can do to make learning easier.", "tokens": [407, 11, 1338, 11, 1520, 484, 702, 1446, 281, 483, 264, 1577, 1867, 13, 286, 914, 11, 456, 311, 445, 11, 456, 311, 257, 688, 295, 721, 291, 393, 360, 281, 652, 2539, 3571, 13], "temperature": 0.0, "avg_logprob": -0.13459305910720037, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.1123755939479452e-05}, {"id": 596, "seek": 598756, "start": 6000.56, "end": 6015.56, "text": " You know, and a key thing I do in my courses as I always teach top down. So like often people with like, let's take deep learning and neural networks they'll be like okay well first thing I have to learn linear algebra and calculus and blah blah blah and,", "tokens": [509, 458, 11, 293, 257, 2141, 551, 286, 360, 294, 452, 7712, 382, 286, 1009, 2924, 1192, 760, 13, 407, 411, 2049, 561, 365, 411, 11, 718, 311, 747, 2452, 2539, 293, 18161, 9590, 436, 603, 312, 411, 1392, 731, 700, 551, 286, 362, 281, 1466, 8213, 21989, 293, 33400, 293, 12288, 12288, 12288, 293, 11], "temperature": 0.0, "avg_logprob": -0.13459305910720037, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.1123755939479452e-05}, {"id": 597, "seek": 601556, "start": 6015.56, "end": 6020.56, "text": " you know, four or five years later they still haven't actually trained a neural network.", "tokens": [291, 458, 11, 1451, 420, 1732, 924, 1780, 436, 920, 2378, 380, 767, 8895, 257, 18161, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1368640528784858, "compression_ratio": 1.7926829268292683, "no_speech_prob": 2.546184441598598e-05}, {"id": 598, "seek": 601556, "start": 6020.56, "end": 6027.56, "text": " Our approach in our courses in lesson one the very first thing you do in the first 15 minutes as you train a neural network.", "tokens": [2621, 3109, 294, 527, 7712, 294, 6898, 472, 264, 588, 700, 551, 291, 360, 294, 264, 700, 2119, 2077, 382, 291, 3847, 257, 18161, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1368640528784858, "compression_ratio": 1.7926829268292683, "no_speech_prob": 2.546184441598598e-05}, {"id": 599, "seek": 601556, "start": 6027.56, "end": 6043.56, "text": " And it is more like how we learn baseball, or how we learn music, you know, like you say like okay well let's play baseball comes you stand there you stand there I've read it to you, you're going to hit it, you're going to run.", "tokens": [400, 309, 307, 544, 411, 577, 321, 1466, 14323, 11, 420, 577, 321, 1466, 1318, 11, 291, 458, 11, 411, 291, 584, 411, 1392, 731, 718, 311, 862, 14323, 1487, 291, 1463, 456, 291, 1463, 456, 286, 600, 1401, 309, 281, 291, 11, 291, 434, 516, 281, 2045, 309, 11, 291, 434, 516, 281, 1190, 13], "temperature": 0.0, "avg_logprob": -0.1368640528784858, "compression_ratio": 1.7926829268292683, "no_speech_prob": 2.546184441598598e-05}, {"id": 600, "seek": 604356, "start": 6043.56, "end": 6046.56, "text": " You know you don't start by learning.", "tokens": [509, 458, 291, 500, 380, 722, 538, 2539, 13], "temperature": 0.0, "avg_logprob": -0.08045549769150584, "compression_ratio": 1.6337209302325582, "no_speech_prob": 3.168205148540437e-05}, {"id": 601, "seek": 604356, "start": 6046.56, "end": 6054.56, "text": " You know, the parabolic trajectory of a ball or the, you know, history of the game or whatever you just start playing.", "tokens": [509, 458, 11, 264, 971, 26956, 21512, 295, 257, 2594, 420, 264, 11, 291, 458, 11, 2503, 295, 264, 1216, 420, 2035, 291, 445, 722, 2433, 13], "temperature": 0.0, "avg_logprob": -0.08045549769150584, "compression_ratio": 1.6337209302325582, "no_speech_prob": 3.168205148540437e-05}, {"id": 602, "seek": 604356, "start": 6054.56, "end": 6057.56, "text": " So that's, you know, you want to be playing.", "tokens": [407, 300, 311, 11, 291, 458, 11, 291, 528, 281, 312, 2433, 13], "temperature": 0.0, "avg_logprob": -0.08045549769150584, "compression_ratio": 1.6337209302325582, "no_speech_prob": 3.168205148540437e-05}, {"id": 603, "seek": 604356, "start": 6057.56, "end": 6064.56, "text": " And if you're doing stuff from the start that's fun and interesting and useful.", "tokens": [400, 498, 291, 434, 884, 1507, 490, 264, 722, 300, 311, 1019, 293, 1880, 293, 4420, 13], "temperature": 0.0, "avg_logprob": -0.08045549769150584, "compression_ratio": 1.6337209302325582, "no_speech_prob": 3.168205148540437e-05}, {"id": 604, "seek": 606456, "start": 6064.56, "end": 6079.56, "text": " Then top down doesn't mean it's shallow. You can then work from there to like then understand like what's each line of code doing, and then how is it doing it, and then why is it doing it, and then what happens if we do it a different way and until eventually", "tokens": [1396, 1192, 760, 1177, 380, 914, 309, 311, 20488, 13, 509, 393, 550, 589, 490, 456, 281, 411, 550, 1223, 411, 437, 311, 1184, 1622, 295, 3089, 884, 11, 293, 550, 577, 307, 309, 884, 309, 11, 293, 550, 983, 307, 309, 884, 309, 11, 293, 550, 437, 2314, 498, 321, 360, 309, 257, 819, 636, 293, 1826, 4728], "temperature": 0.0, "avg_logprob": -0.08020301376070295, "compression_ratio": 1.8639705882352942, "no_speech_prob": 6.143151949800085e-06}, {"id": 605, "seek": 606456, "start": 6079.56, "end": 6093.56, "text": " with, without fast AI program, you actually end up rewriting your own neural network library from scratch, which means you have to very deeply understand every single part of it, and then we start reading research papers and then we start learning", "tokens": [365, 11, 1553, 2370, 7318, 1461, 11, 291, 767, 917, 493, 319, 19868, 428, 1065, 18161, 3209, 6405, 490, 8459, 11, 597, 1355, 291, 362, 281, 588, 8760, 1223, 633, 2167, 644, 295, 309, 11, 293, 550, 321, 722, 3760, 2132, 10577, 293, 550, 321, 722, 2539], "temperature": 0.0, "avg_logprob": -0.08020301376070295, "compression_ratio": 1.8639705882352942, "no_speech_prob": 6.143151949800085e-06}, {"id": 606, "seek": 609356, "start": 6093.56, "end": 6097.56, "text": " how to implement those research papers in the library we just wrote.", "tokens": [577, 281, 4445, 729, 2132, 10577, 294, 264, 6405, 321, 445, 4114, 13], "temperature": 0.0, "avg_logprob": -0.16472768337927132, "compression_ratio": 1.471042471042471, "no_speech_prob": 1.6698708350304514e-05}, {"id": 607, "seek": 609356, "start": 6097.56, "end": 6107.56, "text": " So yeah, I'd say go top down, make it fun, make it applied for things like APL or Chinese, where there's just stuff you have to remember.", "tokens": [407, 1338, 11, 286, 1116, 584, 352, 1192, 760, 11, 652, 309, 1019, 11, 652, 309, 6456, 337, 721, 411, 5372, 43, 420, 4649, 11, 689, 456, 311, 445, 1507, 291, 362, 281, 1604, 13], "temperature": 0.0, "avg_logprob": -0.16472768337927132, "compression_ratio": 1.471042471042471, "no_speech_prob": 1.6698708350304514e-05}, {"id": 608, "seek": 609356, "start": 6107.56, "end": 6111.56, "text": " Use Anki, use repetitive space learning.", "tokens": [8278, 1107, 2984, 11, 764, 29404, 1901, 2539, 13], "temperature": 0.0, "avg_logprob": -0.16472768337927132, "compression_ratio": 1.471042471042471, "no_speech_prob": 1.6698708350304514e-05}, {"id": 609, "seek": 609356, "start": 6111.56, "end": 6118.56, "text": " You know, that's been around, Ebbinghaus came up with that, I don't know what 200, 150 200 years ago.", "tokens": [509, 458, 11, 300, 311, 668, 926, 11, 20418, 4324, 23321, 1361, 493, 365, 300, 11, 286, 500, 380, 458, 437, 2331, 11, 8451, 2331, 924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.16472768337927132, "compression_ratio": 1.471042471042471, "no_speech_prob": 1.6698708350304514e-05}, {"id": 610, "seek": 609356, "start": 6118.56, "end": 6122.56, "text": " It, it works you know you, you.", "tokens": [467, 11, 309, 1985, 291, 458, 291, 11, 291, 13], "temperature": 0.0, "avg_logprob": -0.16472768337927132, "compression_ratio": 1.471042471042471, "no_speech_prob": 1.6698708350304514e-05}, {"id": 611, "seek": 612256, "start": 6122.56, "end": 6136.56, "text": " Everybody, if you tell them something, we'll forget it in a week's time. Everybody, you know, and so you shouldn't expect to read something and remember it, because you're human, and humans don't do that.", "tokens": [7646, 11, 498, 291, 980, 552, 746, 11, 321, 603, 2870, 309, 294, 257, 1243, 311, 565, 13, 7646, 11, 291, 458, 11, 293, 370, 291, 4659, 380, 2066, 281, 1401, 746, 293, 1604, 309, 11, 570, 291, 434, 1952, 11, 293, 6255, 500, 380, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.13015234297600345, "compression_ratio": 1.5271739130434783, "no_speech_prob": 3.882193777826615e-05}, {"id": 612, "seek": 612256, "start": 6136.56, "end": 6142.56, "text": " So, repetitive space learning will have you quiz you on that thing tomorrow.", "tokens": [407, 11, 29404, 1901, 2539, 486, 362, 291, 15450, 291, 322, 300, 551, 4153, 13], "temperature": 0.0, "avg_logprob": -0.13015234297600345, "compression_ratio": 1.5271739130434783, "no_speech_prob": 3.882193777826615e-05}, {"id": 613, "seek": 614256, "start": 6142.56, "end": 6152.56, "text": " So, it's in four days time, and then in 14 days time and then in three weeks time. And if you ever forget it, it will reset that schedule.", "tokens": [407, 11, 309, 311, 294, 1451, 1708, 565, 11, 293, 550, 294, 3499, 1708, 565, 293, 550, 294, 1045, 3259, 565, 13, 400, 498, 291, 1562, 2870, 309, 11, 309, 486, 14322, 300, 7567, 13], "temperature": 0.0, "avg_logprob": -0.13317429501077402, "compression_ratio": 1.7, "no_speech_prob": 1.4737333003722597e-05}, {"id": 614, "seek": 614256, "start": 6152.56, "end": 6167.56, "text": " And it'll make sure it's impossible to forget it, you know, so it's, it's depressing to study things that then disappear. And so it's important to recognize that unless you use Anki or SuperMemo or something like that.", "tokens": [400, 309, 603, 652, 988, 309, 311, 6243, 281, 2870, 309, 11, 291, 458, 11, 370, 309, 311, 11, 309, 311, 36355, 281, 2979, 721, 300, 550, 11596, 13, 400, 370, 309, 311, 1021, 281, 5521, 300, 5969, 291, 764, 1107, 2984, 420, 4548, 44, 36221, 420, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.13317429501077402, "compression_ratio": 1.7, "no_speech_prob": 1.4737333003722597e-05}, {"id": 615, "seek": 616756, "start": 6167.56, "end": 6172.56, "text": " Every day it will, it will disappear. But if you do use repetitive space learning.", "tokens": [2048, 786, 309, 486, 11, 309, 486, 11596, 13, 583, 498, 291, 360, 764, 29404, 1901, 2539, 13], "temperature": 0.0, "avg_logprob": -0.1051473617553711, "compression_ratio": 1.5799086757990868, "no_speech_prob": 3.53492796421051e-05}, {"id": 616, "seek": 616756, "start": 6172.56, "end": 6176.56, "text": " It's guaranteed not to. And I told this to my daughter.", "tokens": [467, 311, 18031, 406, 281, 13, 400, 286, 1907, 341, 281, 452, 4653, 13], "temperature": 0.0, "avg_logprob": -0.1051473617553711, "compression_ratio": 1.5799086757990868, "no_speech_prob": 3.53492796421051e-05}, {"id": 617, "seek": 616756, "start": 6176.56, "end": 6186.56, "text": " A couple of years ago I said, I, you know, what if I told you there was a way you can guarantee to never ever forget something you want to know.", "tokens": [316, 1916, 295, 924, 2057, 286, 848, 11, 286, 11, 291, 458, 11, 437, 498, 286, 1907, 291, 456, 390, 257, 636, 291, 393, 10815, 281, 1128, 1562, 2870, 746, 291, 528, 281, 458, 13], "temperature": 0.0, "avg_logprob": -0.1051473617553711, "compression_ratio": 1.5799086757990868, "no_speech_prob": 3.53492796421051e-05}, {"id": 618, "seek": 616756, "start": 6186.56, "end": 6190.56, "text": " It's like, that's impossible. This is like some kind of magic.", "tokens": [467, 311, 411, 11, 300, 311, 6243, 13, 639, 307, 411, 512, 733, 295, 5585, 13], "temperature": 0.0, "avg_logprob": -0.1051473617553711, "compression_ratio": 1.5799086757990868, "no_speech_prob": 3.53492796421051e-05}, {"id": 619, "seek": 619056, "start": 6190.56, "end": 6199.56, "text": " It's like no it's not magic. And like I sat down and I drew out the Epping House for Getting Curves and explained how it works.", "tokens": [467, 311, 411, 572, 309, 311, 406, 5585, 13, 400, 411, 286, 3227, 760, 293, 286, 12804, 484, 264, 462, 3759, 4928, 337, 13674, 7907, 977, 293, 8825, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.15418298782840853, "compression_ratio": 1.5288461538461537, "no_speech_prob": 1.56874430103926e-05}, {"id": 620, "seek": 619056, "start": 6199.56, "end": 6207.56, "text": " And I explained how, you know, if you get quizzed on it in these schedules, it flattens out and she was just like, what do you think?", "tokens": [400, 286, 8825, 577, 11, 291, 458, 11, 498, 291, 483, 43425, 292, 322, 309, 294, 613, 28078, 11, 309, 932, 1591, 694, 484, 293, 750, 390, 445, 411, 11, 437, 360, 291, 519, 30], "temperature": 0.0, "avg_logprob": -0.15418298782840853, "compression_ratio": 1.5288461538461537, "no_speech_prob": 1.56874430103926e-05}, {"id": 621, "seek": 619056, "start": 6207.56, "end": 6209.56, "text": " I want to use that.", "tokens": [286, 528, 281, 764, 300, 13], "temperature": 0.0, "avg_logprob": -0.15418298782840853, "compression_ratio": 1.5288461538461537, "no_speech_prob": 1.56874430103926e-05}, {"id": 622, "seek": 619056, "start": 6209.56, "end": 6213.56, "text": " So she's been using Anki ever since.", "tokens": [407, 750, 311, 668, 1228, 1107, 2984, 1562, 1670, 13], "temperature": 0.0, "avg_logprob": -0.15418298782840853, "compression_ratio": 1.5288461538461537, "no_speech_prob": 1.56874430103926e-05}, {"id": 623, "seek": 621356, "start": 6213.56, "end": 6228.56, "text": " Maybe those are just two. Let's just start with those two. Yeah. So go top down and use Anki. I think could make your learning process much more fulfilling, because you'll be doing stuff with what you're learning and you'll be remembering it.", "tokens": [2704, 729, 366, 445, 732, 13, 961, 311, 445, 722, 365, 729, 732, 13, 865, 13, 407, 352, 1192, 760, 293, 764, 1107, 2984, 13, 286, 519, 727, 652, 428, 2539, 1399, 709, 544, 25800, 11, 570, 291, 603, 312, 884, 1507, 365, 437, 291, 434, 2539, 293, 291, 603, 312, 20719, 309, 13], "temperature": 0.0, "avg_logprob": -0.1281732487901349, "compression_ratio": 1.6643356643356644, "no_speech_prob": 1.6438618331449106e-05}, {"id": 624, "seek": 621356, "start": 6228.56, "end": 6241.56, "text": " Well, that is awesome. And yeah, definitely we'll leave links to not just Anki and the book Meta Learning but everything that we've discussed throughout this conversation because I think there's a ton of really really awesome advice.", "tokens": [1042, 11, 300, 307, 3476, 13, 400, 1338, 11, 2138, 321, 603, 1856, 6123, 281, 406, 445, 1107, 2984, 293, 264, 1446, 6377, 64, 15205, 457, 1203, 300, 321, 600, 7152, 3710, 341, 3761, 570, 286, 519, 456, 311, 257, 2952, 295, 534, 534, 3476, 5192, 13], "temperature": 0.0, "avg_logprob": -0.1281732487901349, "compression_ratio": 1.6643356643356644, "no_speech_prob": 1.6438618331449106e-05}, {"id": 625, "seek": 624156, "start": 6241.56, "end": 6245.56, "text": " And obviously to your FASA AI course in the library.", "tokens": [400, 2745, 281, 428, 479, 3160, 32, 7318, 1164, 294, 264, 6405, 13], "temperature": 0.0, "avg_logprob": -0.15001267972199814, "compression_ratio": 1.6511627906976745, "no_speech_prob": 4.828557212022133e-05}, {"id": 626, "seek": 624156, "start": 6245.56, "end": 6255.56, "text": " And we'll also link to, I know you've been on, like we mentioned before, a ton of other podcasts and talks. So, if you'd like to hear more from Jeremy, there's a ton of resources online.", "tokens": [400, 321, 603, 611, 2113, 281, 11, 286, 458, 291, 600, 668, 322, 11, 411, 321, 2835, 949, 11, 257, 2952, 295, 661, 24045, 293, 6686, 13, 407, 11, 498, 291, 1116, 411, 281, 1568, 544, 490, 17809, 11, 456, 311, 257, 2952, 295, 3593, 2950, 13], "temperature": 0.0, "avg_logprob": -0.15001267972199814, "compression_ratio": 1.6511627906976745, "no_speech_prob": 4.828557212022133e-05}, {"id": 627, "seek": 624156, "start": 6255.56, "end": 6270.56, "text": " Hopefully, it sounds like you're going to be, you know, building some learning materials over the next however many months or years. And so, in the future, if you'd love to come back and update us on your journey with your array languages, that would be, yeah, super fun for us because I've thoroughly enjoyed this conversation.", "tokens": [10429, 11, 309, 3263, 411, 291, 434, 516, 281, 312, 11, 291, 458, 11, 2390, 512, 2539, 5319, 670, 264, 958, 4461, 867, 2493, 420, 924, 13, 400, 370, 11, 294, 264, 2027, 11, 498, 291, 1116, 959, 281, 808, 646, 293, 5623, 505, 322, 428, 4671, 365, 428, 10225, 8650, 11, 300, 576, 312, 11, 1338, 11, 1687, 1019, 337, 505, 570, 286, 600, 17987, 4626, 341, 3761, 13], "temperature": 0.0, "avg_logprob": -0.15001267972199814, "compression_ratio": 1.6511627906976745, "no_speech_prob": 4.828557212022133e-05}, {"id": 628, "seek": 627056, "start": 6270.56, "end": 6277.56, "text": " And thank you so much for waking up early, all on the other way side of the world from us at least in Australia. Thanks for having me.", "tokens": [400, 1309, 291, 370, 709, 337, 20447, 493, 2440, 11, 439, 322, 264, 661, 636, 1252, 295, 264, 1002, 490, 505, 412, 1935, 294, 7060, 13, 2561, 337, 1419, 385, 13], "temperature": 0.0, "avg_logprob": -0.17071113251803213, "compression_ratio": 1.4671052631578947, "no_speech_prob": 0.00024708276032470167}, {"id": 629, "seek": 627056, "start": 6277.56, "end": 6282.56, "text": " And, yeah, I guess with that we'll say happy array programming.", "tokens": [400, 11, 1338, 11, 286, 2041, 365, 300, 321, 603, 584, 2055, 10225, 9410, 13], "temperature": 0.0, "avg_logprob": -0.17071113251803213, "compression_ratio": 1.4671052631578947, "no_speech_prob": 0.00024708276032470167}, {"id": 630, "seek": 628256, "start": 6282.56, "end": 6301.56, "text": " Happy array programming.", "tokens": [50364, 8277, 10225, 9410, 13, 51314], "temperature": 0.0, "avg_logprob": -0.36692350251334055, "compression_ratio": 0.75, "no_speech_prob": 0.000568551302421838}], "language": "en"}