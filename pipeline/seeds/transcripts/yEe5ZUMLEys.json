{"text": " Okay, hi everybody can you see me? Can you hear me okay? Okay, this will be an interesting experiment. Great, recording. I'm going to go back to RISC-DIVE, we were looking at 08. So, we need to make sure we git pull, because we're always changing stuff. And restart. Okay, so where we're up to is we want how to create basically a function, actually something that derives from transform, but it just looks exactly like a function, so you pass it an argument, transform will send that off to the encodes method, kind of like how nn.module in PyTorch passes it off to a forward method, and it will calculate the result of the function and return it. And then we also learned that something which works that way, you can also optionally add a decode, which will basically something that you undo that transform, or at least enough that you can display it, and so that has to return something which has a show method, so that's just a function basically. And then we learned that you can pipeline functions, which basically just means that you are composing functions together, or transforms, and the interesting thing in this one is that when you return a tuple, it will then let you things after that, you can make them tuple transforms, and it will apply the function only to those items in the tuple individually that are of this requested type. I think we have one unnecessary annotation here, let me check. Yep. Okay. So, yes, Armand, can we decode from pipeline? That's kind of the whole point really, is that a pipeline that encodes can also decode. So, you can see here, for instance, so we could go t equals pipe zero, and so there's t, which is a tuple with a boolean and a tensor, actually we've already called that one. Oh, sorry, they're doing the same thing, so it's two images and a boolean, so we could say decoded t equals pipe.decode t, and there it is. And so now that is, let's see, pipe.decode, so that's going to, actually none of these have a decode in them, so that's a pretty boring example. Let's go back to the previous one. Oh, that's not a pipeline. We'll come back to it. We'll see one later, but basically, yes, so none of these have a decode. We don't have to decode Siamese image tuples. Yes, if you say pipe.decode, then it will pipeline through all of the steps calling decode on each. And actually, pipe.show is an interesting one, because to show a pipeline, it's going to decode every part of the tuple, which is normally the last step of the tuple, and it will keep decoding it, but it will stop as soon as it gets to a type which has a show method defined. So in this case, actually, the output type of pipe is a Siamese image, and the Siamese image has a show method defined, so when we call.show, it doesn't really need to decode at all. But for other types, it does need to decode. And transform data source is something where we give it arrays of transforms or functions. Each one will be turned into a pipeline, and each one of those pipelines will be applied to each item, and that will then give us a tuple, which was not working yesterday, but is working now. So, you can see, actually, this is a good example of decode. A transformed dataset, a TwifmDS, can decode, and what that's going to do is it's going to take our PIO image and our number, and it's going to decode each part of the tuple by decoding each of the pipelines, and then you end up with, as you see, the correct name, in this case, of the pet breed. And so show, again, will decode each part of that tuple up until the point where it finds the show method, and then it will show it. Now, I don't think we got as far as TwifmDL yesterday. No, I guess we couldn't have, because it wasn't working. So, TwifmDL is a data loader which understands fast AI version 2 stuff, and specifically, it understands two pieces of stuff. One is that it understands how to maintain types. So, it makes sure that, you know, transform or pillow image subtypes are maintained, and it understands decoding. So, basically, it lets you have transforms in a transformed data loader, and they will behave the same way as transformed in a transformed dataset. So, here, what we're going to do is we're going to do the same thing we had before. Let's just copy it down so we remember. So, this was how we did pets last time. So, previously, our first pipeline was image.create, resize to tensor, byte to float tensor, and our second pipeline was labeler and categorize, and just to remind you, labeler was a regex labeler function. This time, the labeling pipeline is the same, but the image pipeline is just PIO image.create. So, what's PIO image? PIO image is simply a... Here it is. Oh, yeah, here it is. It's this. It's one line of code, and it's just a thing that inherits from PIO base, and PIO base is something which inherits from PIO image. And there's a bit more information than we need here, but the key thing to recognize about this is that it has a create method and a show method, which are the things that we need for it to be able to work in our transform pipelines. And the create is static. So, PIO image.create is simply going to call load image, which is the thing that opens the PIO image in the usual way. Okay. So, that's that. So, why are we able to get rid of all of these things from our image pipeline? The reason is that we've moved them into our data loader transformation pipeline, which is going to turn out to be pretty handy. In this case, it doesn't make much of a difference, but basically what's going to happen now is we'll learn a bit more about the data loaders today. But basically, the data loaders also have places you can add transform pipelines, and in this case, after creating the data set, it's going to call these on inside the actual data loader itself. One thing to recognize is that image resize and byte to float tensor don't make sense for categories, but that's okay because image resizer only defines encodes for PIO image and PIO mask. It doesn't define them for anything else, so it'll just ignore the categories. And byte to float tensor is the same. It's defined on tensor image, encodes, and tensor mask, encodes, and nothing else. So, it won't change our categories. So, that is why that works. So, there it is. Okay. The last kind of piece of this part of the API is data source, and so each thing is going to build on each other thing. So, a data source is basically a transformed data set, but with the ability to create separate training and validation sets, and in fact, to create as many subsets as you like. So, okay. So, if you're having trouble with code not running, best place to ask is on the forum because I can't debug it while we go, but feel free to ask on the forum. Okay. So, what we're going to do now is we're going to use this thing that looks a lot like a TFMDS, a transformed data source, but it's going to allow us to separate training and validation sets. And so, if you look at how TFMDS was defined, here it is here. So, when we created our TFMDS, we passed in items and transforms. This time we've got to pass in items and transforms and the indices of our splits. So, remember split IDX was something with two arrays in it, and the arrays just had lists of IDs for the training validation set. Okay. So, by passing the data source's extra piece of information, we'll end up with something that you can use exactly the same way as TFMDS. So, you can still just ask for an element from it. So, this is kind of a superset of the functionality of TFMDS. But you can also ask for a subset. So, the zeroth subset will be all the things that were in split IDX 0, and the first subset will be all the things in split IDX 1. So, in other words, pets.subset1 is the validation set. And so, there is indeed a shortcut for that, which is pets.valid. So, you'll find that there is a pets.valid. Hi, Joseph. Just to remind you again, if you have bugs in the code, please ask on the forums, not on the live chat, because I won't be able to answer them here. So, the validation set, for example, and the training set, for example. And so, pets.valid is exactly the same as pets.subset1. And the training set is exactly the same as pets.subset0. So, one of the nice things here is that we're not just limited to just a train set and a validation set. You can actually have as many data sets as you like. You can have multiple validation sets. You can include a test set and so forth. So, it's kind of a bit more flexible here than fast.ai.v1. Okay. So, now we've got something. So, basically, these training and validation sets act pretty much exactly like a tiffMDS. The type is something, is in fact a tiffMDS, as you can see. So, that makes it nice and easy. All right. So, because these things are just tiffMDSs, you can decode them just like before, as you can see. And yeah, we can show them just like before. So, here is something even more interesting, which is we've seen already tiffMDL after item. That's going to run, that's going to be a transform that runs on each individual tuple that comes out of the transform pipelines. But then there's another one called afterBatch, and that's going to run after the tuples have been collated together by the PyTorch data loader into a single batch. And what that means is that we can put transforms in here that we can run on a whole batch at a time, and that means we have the ability to easily run GPU transforms. So, in this case, the most obvious GPU transform to do, of course, or the most obvious batch transform to do is CUDA, which will simply move it onto the GPU, if you have one. And then we can convert it from byte to float on the GPU. Now that might seem like a pretty minor thing, but actually converting a byte to a float is really slow for two reasons. The first is that floats are much bigger than bytes, so it's taking up a lot of memory to transfer it to your GPU as floats. And the second is that converting from a byte to a float actually takes a non-trivial amount of time on the CPU. It actually is quite... It does actually take up quite a lot of time. So here's the first example of something that was very, very hard to do before, which is to actually do computation on the GPU. And the nice thing is that we just use the GPU transforms often don't even need to be written in a different way. So if you look at byte to float tensor, for instance, you can see that encodes simply goes O.float divided by 255. So thanks to kind of broadcast tensor computations and stuff, we don't normally have to write it at all differently to make it work at a batch level. So often you'll be able to just transparently move your transformations onto the GPU, and suddenly things will just run much faster. So I think that's one of the pretty exciting things here. So now we're getting pretty close to having something which looks like what you would actually train with. It's something which is categorizing our pet types. We have separate training and validation sets. It's converting them into batches. And we can even go trainDL.showBatch, and it will actually give us a full set of these. So this is kind of really getting everything together nicely. One of the very neat subtleties of data source is that data source, well, it's not really data source. It's really categorized. So we're using categorize here. And what happens, we'll learn more about this shortly, but what happens when pipeline first gets its data source is it calls a special method in a transform called setup, if you have one. And you can see here that what we actually do is we try to grab, if there is one, the training subset of the data source. So one of the cool things here is that automatically this stuff will ensure that your categories vocab is only done on the training set. So these are the kind of things that are very easy to mess up. So the questions here, does byte to float normalize? No, it doesn't. As you'll see, there is a separate normalize function. However, it does have a, oops, byte to float tensor. It does have an optional div argument, which will divide it by 255. So that'll give you between zero and one. So not quite normalized, but at least it's on the right track. But yeah, there's also, as we'll see later, a normalize transform. Text transformations are rarely done lazily. They're normally done once pre-processing style. So they're not generally a great, so kind of such a good match for the GPU. But if there are, there's nothing to stop you from doing text transformations on the GPU. But as you'll see, we've actually, text transformations are a lot faster now anyway. And then any reason we don't do all transforms on GPU. Yes, there is, Molly. The issue is basically, and that's a great question. The issue is basically, have a look here. If you want to be able to easily process things on the GPU, then you need a batch. And if you have a batch, that means you need a tensor. But if you have a tensor, that means that all of the items in the batch have to have the same shape. So if we didn't have this image resizer here, then the images would all be different shapes. And so you wouldn't be able to collect them into a batch. So specifically, the things that you probably want to do on the CPU are load the JPEG in some way, make sure that all of the things are the same size, and then convert them into a tensor. So those are basically the three things you have to do, at least for vision on the GPU. Sorry, on the CPU. Having said that, there is a project by Nvidia called Dali, which we'll endeavor to provide some support for. Once it stabilizes a bit, it's still pre-release. And they've actually written the custom kernels to do stuff on things that aren't all the same size. So there might be possibilities to do some stuff there. So images can absolutely be rectangular. It doesn't have to be 128 by 128. We'll see more of that later. And hopefully, I've already answered the question about what's best on the GPU. I would say everything on the GPU that you can. So I would say try to do everything on the GPU that you can. But specifically, turning everything into something of the same size so that they can be translated into a batch has to happen before it goes into the GPU. So that would be my rule of thumb. So let's look at another example. There's no new things I'm going to show you. I'm just going to show you another example, which is segmentation. So let's grab a subset of CanVid. Get those image files. Create a random splitter. Create the split indexes. Create the labeling function. So the transforms are basically the same as we had before, except that for the y, we first of all call CVLabel. So that's the thing that's going to grab the name of the mask file from the image file. And then we're going to call pilMask.create. And pilMask, as you can see, is just a single line of code. And really the only reason it exists, or the main reason it exists, is so that we can do stuff like we did back here where we had separate encodes for images and masks. So by giving things different types, it allows us to give different functionality. In this case, it ensures when we resize things, we're going to use nearest neighbors instead of bilinear. So that's a pretty interesting trick. And so as you can see, the amount of code necessary to do segmentation, even though we haven't got any data blocks API yet, is pretty tiny. So the idea here, and it all looks almost identical to pets, even though it's a very, very different task. In fact, even things like the DL transforms are literally identical, so we didn't have to redefine them. So the idea of this kind of intermediate API that's halfway between data blocks and the lowest level stuff is to make it super simple, to make it really easy to do custom stuff. And my guess is that people doing a lot of Kaggle competitions or more advanced stuff that's a little bit different to the things we show in the lessons or whatever is that you'll probably use this level of the API a lot because it just doesn't require much thinking and it's all pretty transparent and easy to understand. And then as you'll see, the stuff that is in data blocks and stuff is all built on top of this and takes very little code. So Jacob asks how to profile code to see where the bottlenecks are. I'd have to say I'm not terribly good at that. I mean, I just, I mean, or at least I'm not terribly smart about it. I just, if I want to, if I want to know where bottlenecks are in training, I'll just check H-top to see if all the CPUs are being used 100% and I'll check Nvidia SMI to see if my GPUs are being used 100%. So if you haven't done that before, you basically go Nvidia SMI daemon and it starts bidding out stuff like this. And the key column that you're going to care about is this one here, SM. That should, when you're training something, that should be basically saying above 90 and preferably around 100 all the time. That means your GPUs are being well used. If it's less than that, then it probably means that your CPUs are being overtaxed. And so that would be kind of step one. And if it's then your CPUs are overtaxed, then you can just use the normal Python profilers to find out why. If your GPU is being overtaxed, then that's probably just basically a good thing. It's using your GPUs effectively most of the time. OK. So that's 08. So I thought from here maybe we'll take a look at Tiffen DL, which is in 05. And by the way, there's a file called local notebook index.txt, which is automatically generated, which tells you which notebook everything's in. Although the easier way to quickly jump there is you can just go, let's just import some local notebook show.importster. You can go source link tiffen DL. And as you can see, you'll get a link straight there. And as you can see, it's got an anchor. So it's going to jump straight to this right section once we wait. There we go. OK. So that's a nice fast way to go to the right part of the right notebook and the right part of a notebook. That was source link. OK. So here is 05 data core. And we may as well look at the whole thing from the top while we're here. So basically what we're going to learn is how get files works and get image files, splitter, labeler, categorize, multi-categorize, and then we'll put it all that together with mnist and then we'll see tiffen DL. OK. So let's start. So as you can see here, the first bits are a kind of three major data box-ish components, get, split, and label. So the basic get thing we use, same as in fast.ai version 1, is get files. So get files is going to take 1, 2, 3, 4 parameters, the path that we're going to look for files in, which extensions to look for, whether we want to do it recursively, and whether there's just some subset of folders to include. So we have in this notebook, we're using mnist. And so it's important to know here that this notebook is not just a tutorial notebook. This is a notebook that actually defines the module called data.core. So we're going to end up with something called data core. OK. So this is the thing that we're building. You can see we've got get image files, get files, and so forth. You'll notice that it's automatically creating a Thunderall array. So that's created automatically by the fast.ai notebook functionality. This is the thing that Python uses to decide what to import. If you say import star, in most Python libraries, people don't bother creating this. And that's one of the reasons that people normally say don't use import star, is because if you don't bother to create this, and it's actually going to import also everything that is imported recursively, it gets really awful. But since we're super careful about what gets exported and how things are structured, you'll very rarely have problems if you use import star. So we tried to make it as kind of REPL-friendly, interactive-friendly as possible. And so particularly because this is created automatically, it's a really, really handy thing. So that's why you'll see it in the Python module, but you won't see it in the notebook because it's automatic. So yeah, so this is kind of our first deep dive into literate programming because we're actually building the data.core module. But as you can see, we have, you know, pros along the way. So the first step is to get a list of items. An item is... can be kind of anything you like. An item list can be anything you like. So for stuff with vision, it's normally a list of paths, but an item list could be a data frame, could be a connection to a database, could be a network, type. As you see, you'll be able to do pretty much anything. But for now, for these ones, we're going to be using paths. And we'll be looking at using data frames later. So we grab our path. We're going to be... So get files is going to be calling underscore get files. So that's what this is. And you'll see underscore get files, if we search for it here, underscore get, underscore get files, it did not appear in thunder all. And the reason for that is that by default, anything that starts with an underscore is not exported by fastai. Okay. So this is just a little function that will... Let's see, we're being passed a bunch of files to look at. And so we're just going to turn them into pathlib.path objects. We don't include things that start with dot because we're hidden. We also make sure that the extension appears in the extensions list or that you didn't include an extension list because if you didn't include an extension list, it means we don't care. Then get files, the key thing is to understand how os.walk works, which we briefly mentioned in the fastai courses. So look it up if you want some details. Basically, os.walk is a ridiculously fast Python API for very, very, very rapidly looking for things on your file system. And get files, we spent a lot of time optimizing this and get files can run on the entirety of ImageNet to grab all 1.3 million files in just a few seconds. I think it was like eight seconds or something. There's no limit on how many files that can be, except of course the memory on your computer. So remember then that the way we kind of demonstrate functionality in the documentation is generally through tests. So the test here is we're going to grab all of the PNG files in train slash three in MNIST. So and in three and in seven, in the MNIST sample, that's the entirety of the images that we have, so we do things like make sure that the number of images in the parent when you use recursion is equal to both of the child, children, stuff like that. And then we also just print out a few examples. And as you can see, like most things in fastai, we're getting back a capital L, an L object, so you can see how big it is and it shows you a subset of some of the paths that are in it. Okay. So sometimes we kind of have additional checks that probably aren't that interesting for documentation purposes, but are just useful as tests. And when that happens, we add hash hide to the top of our cell and that'll cause it not to be included in the docs. So let's have a look. Data core. So if we have a look at get files, so you can see here's the output, the HTML output of what we were just seeing. This is the most general way, blah, blah, blah. This is the most general way, blah, blah, blah. Okay. So you can see that the first set of tests and stuff are shown here. The output is shown here, but the hash hide version is not shown. Okay. As we've discussed before, in order to kind of easily get partial functions, we sometimes define things which, that's a bit smaller, we sometimes define functions that return functions. So here's a nice easy way to say, oh, this is going to create a function that non recursively searches for PNG files, for instance. So then its behavior is just like what we saw. So this is really doing something very similar to just doing a partial function in Python. To get image files, we just call get files passing in image extensions, which is everything in mime types that starts with image. Okay. So then we can test that one. So image getter is the same as a file getter, but we get image files. Just that one. And so there you go. So there's the whole of the functionality that currently exists for getting items. And I can imagine we'll add more of those over time. But that's a good start. So the second thing we need is functions for creating splits. And these are just things that return two lists, the list of stuff in the training set and the list of stuff in the validation set. So for example, a random spitter is something which returns a function. Optionally you can set the seed. And it's just going to randomly commute all of your indexes and then cut it at wherever you asked for and then return those two halves. So there you can see. And so some simple tests of that. Splitter is something which looks at the parent of the parent. So like an MNIST or an ImageNet. That would be where the path would be valid or train. So that's that. And so that all works the way you expect. So as you can see, these functions are super tiny. And so generally if you want to know more detail about how something works. And we should add more documentation obviously to some of this stuff as well. It's still early days. Feel free to send in PRs with docs if you're interested. So good question from Kevin about what if you wanted to get audio files, for instance. I think I would probably put that in an audio module. Yeah. I don't feel super strongly about it though. It would probably make more sense to get image files actually to be in vision.core. Now I think about it. But yeah. Yeah, probably easy to have. Probably better to have everything for an application in an application module. Okay. So labeling is the thing which will, for example, take a path and pull the label out of it. So a parent label, for instance, we'll just label it with the name of the parent. So there's nothing to customize in this case. So we don't need a capital letter thing that returns a function. We can just call it directly. Where else red checks label are, we actually need to pass in a pattern for what red checks to label with. So that's why it's a capital thing which returns a function. So here's what red checks label looks like. So remember if you want to really understand how these things work. If any of them are confusing, open up the notebook and just like we do in the fast AI lessons, you know, experiment. Try some other tests. You know, add some cells to the docs and try things out. You know, so you're like, oh, what's in items? And there they all are. And it's like, oh, so what if we f items zero. You know, lots of experimenting, lots of debugging, all that kind of stuff. All right, so those are three basic steps. GetsBitLabel, they're all very easy functions. So categorize is a thing that we have already used in 08. So to remind you, and so we're going to create something called category.create which is simply categorize. So when you see category.create, that's actually creating a categorize object. So for instance, if we create a transform data set, which goes cat dog cat, there's the items in it and the transforms is this categorize. And then here we can test its behavior. So the vocabulary from those items should be cat dog, for instance. The transformed version of cat should be zero. The decoded version of one should be dog and so on. So Edurand's question is, should there be a hash test? No, we don't need hash test. As you can see, they just appear directly. So we don't need to add anything to say this is a test. You just include tests. If a test doesn't pass, let's make one that doesn't pass. Dog, dog, then you get an error. OK. And as we mentioned last time, in class.dei.dev, in the read me, is the line that will run the notebooks in parallel. And if any of them fail, in fact, I just ran it before and one of them failed, so I can show you. Here we are. If one of them fails, it looks like this. Exception in blah, blah, blah, dot ipo mb. And then it'll show you the stack trace. And then it'll show you there. So that's how tests work. Tests are just regular cells, which happen to have something which has an assertion in, basically. That's all test ec is. We'll get to the 0, 0 test notebook eventually. And so how do we get coverage tests? No idea. It's not something I've thought about. That would be an interesting question to look at. It's not something I've cared about so much, though, I must say, because the tests always sit right next to the thing that they're testing. So it's really hard to have functionality that's not tested. It tends to be pretty obvious because you're kind of staring at it on the same screen. OK, so a categorize is a transform. So therefore, it has an encodes and a decodes. So when you create it, so that's just calling categorize, it's just a normal Python object here. So it's done to inner. It works in the usual way. So you can actually create it with a predefined vocab if you like. And if so, it'll assign it. If not, then it's going to use this special setup method. When does setup get called? Well, you can see here when we create a tiffmds, we're saying this is the list of items that we want to use with these transforms. So tiffmds is going to, let's see, what's the best way to show you this. Actually, it's going to create a number of tiffm lists. So we want to look at tiffm list. And so here you can see tiffm list in init will call self.setup. And self.setup will set up your transforms. And so that's the thing which is going to call setup, which in this case will set your vocab to a category map. We'll look at it in a moment. This is to map the vocab of categories. And it will use, this is a nice little idiom, it will use dsource.train if dsource has a train attribute. If it doesn't, it'll just use dsource. It'll use your training set if there's a training set defined. Otherwise, it'll just use the whole data source. So that's a super important idea. This is setup thing. We'll see more details of that when we look at the code for pipeline and tiffmdl, tiffmds, tiffm list. You'll see that decodes is saying that I want to return something of type category. And that has a category.create. And a category is pretty tiny. It's inheriting from show title. And it's inheriting from show title. And it's inheriting from show title. And it's inheriting from show title. And it's inheriting from show title. Which simply has a show method, as you would expect. And show title is going to show passing in the keyword arguments that are in self.underscore show args. So in this case, it's going to label it with the category. So the only other piece here is the category map. And the category map is just simply something which will grab all of the unique values in your column, optionally sort them. And then we'll also create the object to int, which is simply the opposite direction. So l has a value to index, which is a reverse map. OK, so that's category. So Hector's question about the videos reminds me to talk about the forum, which is I was to, thanks to people who contributed notes and other things. I was trying to think about how to structure this. What we might do is let's create a fastai v2 code walkthrough2. I use this to walk through two notes, questions, and expression after query. So let's make that into a wiki. And so now that would be a good place to put notes. And so this good set of notes are ready for number one, thanks to Elena on it post. They're not quite complete yet. So either Elena or somebody else can hopefully finish off the last bit. But it looks like maybe they are complete now. Ah, there you go. She's done some more than since I last looked. Very nice. OK, so it is finished. Beautiful. So it's a bit tricky in the forums if multiple people edit the same wiki post at the same time. You'll get conflicts. So one thing you could do is you could add notes by replying to this. And then I can copy and paste them into the wiki. Might be one way to avoid conflicts. Also, if you look at the fastai version2 transforms pipeline data blocks, Ian Vijay was kind enough to start adding some notes. So I've tried to try to get that some structure. So you can basically create something where you've got second level headings for modules, third level headings for classes and functions. And then what I did for these was if you click on this random splitter instance, it will actually take you to the line of code in GitHub. To do that, you can just click on the line of code, like so, and then click on the three dots and say Copy Permalink. And it will actually create a link to that exact line of code, which is pretty cool. And so that was for random splitter. So we can then go down here and say, bump, like so. And so that's a permalink to that line of code. So that's that. And then in the daily code walkthrough thread, as I'm sure you've noticed, I'm going to start putting the video and the notes link just in the list at the top here. How many walkthroughs are planned? As many as we need. What is D source? That's just a data source. It could be a data source object, but really it's anything which can be treated as a list, or anything which works with any transform you're using. It doesn't even have to be necessarily treated as a list. Merge conflicts. Yeah, as Molly said, once you've run run after git clone, that'll get rid of a lot of the conflicts, because a lot of the metadata is removed and stuff like that. Other than that, we just try to push regularly. If we're going to be working on a notebook for a while that we think somebody else might be working on, we'll let them know. Yeah, nowadays we don't have too many conflict problems anymore. Miguel asked, how did I start using PyTorch? I started using it kind of when it was first released. So yeah, I guess I just read the docs and the tutorials. I think nowadays just using the fast AI lessons is probably the easiest way to get started. The further you get into them, the more you'll learn about PyTorch. That'd be a good thing to ask other people on the forums, too, because there are a lot of other people that have started using PyTorch more recently than me. It might be a better place to answer that question. OK, so as well as the category, we also have multi-category. The multi-category is something like we have in Planet. Remember in Planet, each image can have multiple things, like cloudy and primary and road. So here's an example of items for a multi-category dependent variable. You can see each one now is a list. So item number one is labeled with B and C. Item number two is labeled with A. Item number three is labeled with A and C. So the vocab that we get from that should be A, B, C. And categorizing A, C should give us 0, 2. So that's what multi-categorize does. And as you can see, it looks super similar to what we had before, except encodes has to do it for everything in the list, and decodes has to do it for everything in the list as well. And so multi-category show is a little bit different because we've now got multiple things to show. So we have to use the string join in Python. And so one of the handy test functions that we'll learn more about later is just stood it out because the show functions actually print things. And so how do you test whether something is printed correctly? Well, this will actually test whether this function prints out this thing or not. So that's a useful little thing to know about. OK. So normally, you need to one-hot encode multi-category stuff. So we've got a one-hot encoding here, which works the same way that you've seen in PyTorch version 1 and the lessons. And so here's a transform for that, where the encodes is simply going to call one-hot, as you see. And to decode, it does one-hot decode. I think these return types are unnecessary. Yes. It looks like they are. Let's see if this still works when I remove them. Yep. Looks like it does. OK. Now, the way we've done types and dispatching and stuff has changed a little bit over time. So some of our code still has stuff that's more complex than necessary. I will try to remove it as I see it. If you're ever not sure why a type annotation exists, feel free to ask. The answer might be that it's not needed. OK. So here's a good little test then, a kind of a little mini integration test of taking a bunch of items and passing it through a pipeline that contains multi-categorized and one-hot encode. And so that should. So TDS1, that would be A, should be 100. And then decode of 011 should be BC. And just do that. OK. So that is that. So we can put all this together to do MNIST by calling get image files, splitter. And so notice these aren't being exported because this is data core. So we haven't created any of the vision application yet. So we don't want to export anything that uses Pillow. But you can certainly include it in the tests, right? So for the tests, we can bring these basic functions in, something that can open an image, something that convert an image into a tensor. So here's our two transform pipelines that will look pretty similar to what we did in 08. And so here's our TFMDS that takes our training set and our transforms. And so then we can grab one item of it. We can decode it. And show at will take our TFMDS and show the thing at this point. And you can optionally pass in some parameters that will be passed along to Matpotlib. And these kinds of things, we also check that there are some tests, that the title looks right, and that the figure is actually created. So that's like a good little, you know, this entire thing is pretty self-standing. So this is pretty self-standing, so it's kind of a good place to get going. So Miguel says, completed class.di, but you need to learn more PyTorch. That would be a good thing to ask on the forums, I think. I mean, if you're doing all the assignments, and by the end of 14 lessons, I would have thought you'd have to be pretty damn good at PyTorch, because you do a lot of practice. But yeah, I guess other people might be able to have their own ideas about that. So I guess that's it for this one. I guess other people might be able to have their own ideas about that. So Vishnu said, I made a mistake about what image to tensor is doing. That's true. It's actually creating an array. So I'm glad you asked that question, because this is going to be turned. OK, so this is actually a great question. The return type of here is tensor image. And tensor image is one of these nifty little things we've added, which is something which is taking a long time. Looks like our server is going slowly, which, as you can see, is simply calling this path. So it's just something which we use to mark the type so that we can create transforms that are restricted to that type. But it's basically just a tensor. It's a subclass of tensor, in fact. But you'll notice this is actually not a transform. It's just a function. But the cool thing is that any time that you create something that's going to be turned into a pipeline, any functions in there that aren't transforms will be turned into transforms. So you can actually just go transform image to tensor. And that creates a transform object that will run that function. So that's a handy little trick. And we'll learn more about it when we get to the transform thing. So because this gets turned into a transform, that means that this will automatically take our NumPy array and will cast it to a tensor. And it will also make sure that it only gets called on images. OK. OK, so last thing for today, tiffMDL. So tiffMDL is something that inherits from Data Loader. But actually, this is not a PyTorch Data Loader. This is a fastai data.load.DataLoader. So we've actually created our own Data Loader to add a lot of handy extra stuff to PyTorch's Data Loader. And one of the nice things we've made it is much more inheritable. So we've inherited from that Data Loader. And what tiffMDL does is it turns the Data Loader into something which understands transforms, as the name suggests. So to fully understand this, we'll need to look at the code for Data Loader, which we can do next time. But there's a few interesting things to show. Let's have a look at it in use first of all. So here's a bunch of familiar-looking transforms. So here's a tiffMDS, which takes our items, which is the MNIST paths, and transforms them. So it's going to create a pillow image and labeled categories. And then tiffMDL is going to take that data set and convert the images to tensors in the Data Loader. So let's try that. And so we can now see there's our batch. And so this is a batch size of 4. So we've got four labels and four images. But one of the really interesting lines of code here is the test at the bottom. It's testing that the decoded version of the batch, when we map the function type over it, is that it's going to be tensor image, category. So why is that interesting? Well, that's interesting because what this is showing is that Fast.ai knows how to take a tensor that comes out of a Data Loader, which doesn't generally have types, and we'll put the correct types back onto it. And so this is super handy for inference, because what it means is that in production, your predictions and stuff are going to have proper types. So you can actually call normal methods and transforms and stuff on them. So it's super handy for inference and also for applying stuff to a test set, things like that. So this is actually an interesting line of code. So let's look at it. So we're going to start with tdl.decodeBatchB. So remember, B was our batch. It's going to contain four MNIST images and four labels. So the decoded version of that is nearly the same thing, but now we've got, rather than two things, we've got four things because they're four pairs of image and label. And now you'll see the label's a string. Image and label. So that's what decodeBatch is going to do, is it's going to turn it into a form that's much more ready for showing. And so I think we should be able to go show titled image. And then we could say, show us the 0th one of those. Yeah, there it is. OK? So and so then what I wanted to do was I basically, that contains two things. If I just grab the first image, it contains the image and the category. And what I really wanted to do was to say, x comma y equals that, and then print out type x comma type y, which is a little bit awkward. So what we can do instead is we can wrap this in an L and then just call mapped. And that will map a function over it. And the function I want to map over it is type. And that gives me exactly the same thing. So that's what that does. Aravain asks, did Swift AI influence the design of v2? Yeah, a bit. I've been using static languages a lot longer than dynamic languages, honestly. So I don't think the type stuff is particularly from that. In fact, we're using types in a very, very different way to Swift. Swift is statically typed, so you can't quite do the same kinds of things with types. This is, to me, a really interesting use of dynamic types. And so I think part of it comes out of saying, OK, Python has a lot of issues with performance because it's a dynamically typed language. But we may as well at least take advantage of the dynamic typing of the language. So we're trying to take more advantage of the Python's foundations as part of what's going on. But yeah, I think doing this stuff with Swift certainly had some influence. And certainly talking to Chris Latner had some influence specifically. So a TransformDataLoader has a.1 batch method, which actually you'll see isn't here. And that's because it's in DataLoader. But we can look at to fmdl.1 batch. And as you can see, it'll give us the definition, even though it's actually in a superclass. And as you can see, it's just going next in a superclass. Which we do all the time. So we thought we may as well put it into a method. It's really something you just use for interactive usage and tests. So let's look at to fmdl some more. Here's a transform with encodes and decodes. And so specifically, encodes is negative x. Decodes is negative x. That makes sense. It's a reversible negative transform. And these are both things that can be applied to a whole batch at a time. Because the negative operator in Python doesn't care what rank something is. So we can put that in the after batch. And so if we had CUDA as well, then this would actually run on the GPU. And these things also all work with more than one worker. So there's no need to do next in a TDO. We can just do tdl.1 batch. And in this case, it's actually making sure that, so if we look at train.ds, it's actually train.ds that's got an image and a label. Let's give train.ds 0, an image and a label. And the type of train.ds 0 image is a tensor image. And so one of the interesting things here is we're checking that the type after going through the transform is still a tensor image. Now that's actually not particularly easy to do. Because look at this. What if we say t equals that, and then we'll go t2 equals negative t. So type of t is tensor image. But type of t2, oh, sorry. Let's do it actually a different way. Torch.meg t is tensor. You've got to be a bit careful. And so actually this would be a better test if we use torch.meg. Torch.meg x. Torch.meg x. Still passes, even though it looks like it shouldn't pass. And the reason for that is that all of the transformation pipelines, tiffinds, tiffindol, stuff like that, all check after it goes through encodes or decodes that the type doesn't change. And if it does change, then it will convert the type back to what it used to be. But it only does that in a specific situation, which is this one, where you end up with a superclass, torch.tensor, of the input, whereas the input was a subclass of that. So tensor image is a subclass of tensor. This is something that happens all the time with like pillow subclasses and tensor subclasses that very often the operations will forget what subclass it was. So you don't have to do anything. It will automatically put back the correct subclass for you. It's possible to opt out of that behavior by just putting return type of none. And that tells the transform system not to do that for you. As you can see, it now doesn't pass. So that's how you can opt out of it. I don't think I've ever needed it yet, though. So far, it always has made sense in everything I've done that you always want to keep the subclass type information. So that all happens automatically. OK, so why is this here? I don't think this is meant to be here. I think it's in the wrong spot. Let's double check. I think we've got this over here already. I think O1 core is getting too big. We might have to split it up. I'll just build it up. Oh, that does look different. That's interesting. It's just adding much. I might leave that out. Okay. So here's another example. We've created a class called capital I int. So the normal int in Python is small i int. Capital i int is a subclass of that, which is also a subclass of showTitle. So it's a type of int that has a show method, basically. So we generally, if you want to be able to show an int, then you just put returns a capital I int. And so here, let's see, are we doing a different deal? Yeah. So here we're just basically checking that this type annotation works. We'll learn more about those type annotations once we look at the transforms notebook. But as you can see, all the trends, all the types are following through correctly. Okay. So some of these other things I want to come back to later, specifically how filters work. So let's have a bit more of a look at Dataloader. So I'm just going to show you a couple of pieces of TFMDL, and then we'll go back to Dataloader, and then we'll come back to TFMDL. One thing that's interesting here is that there is a thing called delegates on the top here, a decorator, which we have on position. There we go. I have described in more detail in this article. Okay. But I'll give you a quick summary of what's going on. Have a look here. So basically, TFMDL is a subclass of Dataloader. So when we call ThunderInnit, we basically want to pass along any keyword arguments that you gave us. The problem is that normally when you put quags like this, there are a couple of issues. The first issue is that if we want to use things like shift tab, and we go to TFMDL, and then we say shift tab, rather than seeing the actual list of things that we can pass in, we would see quags, which is super annoying. But check this out. That's not what happens here. We see the actual arguments. How does that happen? And it's not just we see them, but we also have all the normal tab completion for them as well, even though those are actually coming from Dataloader. The reason that's working is because of this delegates decorator. And what the delegates decorator does is it will replace the signature of a class in it or function, depending on what you put it on. And if you put it on a class, by default, it will take it will remove the quags from the signature and replace them with the arguments of the parent class. And so that's why this works so nicely. So we use this kind of stuff quite a lot. So you'll quite often see quags used in FastAI version 2, but you should find in every case that we've used them, you'll always get proper shift tab and completion support. And so if you ever find that's not true, then feel free to let us know, because that would be considered a bug, generally speaking. So this really does behave like a Dataloader. It's a Dataloader which has a few extra things. Perhaps most interestingly, it has showBatch. So showBatch is the thing that we saw over here. We saw it for segmentation showBatch and we saw it for pets showBatch. So the idea is that you can take a tiffmdl and call showBatch and it will know how to display whatever's there. And it even knows how to combine the information from multiple data types, in this case a mask and an image, in this case an image in a category. You can pass in a batch to show. If you don't, it will default to one batch, as it says, and as you can see here. And so what it will do is it will first of all decode that batch, and specifically decode means decode using decode the afterBatch transform and decode the beforeBatch transform. So that's all the stuff that happens after it's collated. We then have these things called contexts, and contexts is like, it's either the plots, like in this grid of plots, each one of these will be a different CTX, a different context. For things that display a data frame, each column I think it is, or maybe it's a row, is a different context. So here, if you don't tell it what context to use, it will actually ask the type, the object in the batch to provide it for us. We'll learn more about that later. And it will then attempt to decode the batch using the afterItem decode. And it will then attempt to call.show, which we will see.show in more detail later. You'll see that we're often using things like compose, so hopefully you've seen that from previous FastAI, that basically compose is going to call this function and then this function. This is a really useful idiom. If your data set has a decode method, then this will get self.dataset.decode. If it doesn't, it will get noop, so it does nothing. That's a nice easy way to do that. OK. So, yeah, that's probably enough for now. That's 90 minutes. Oh, the other thing you'll see is we kind of generally have documentation and examples for the kind of high level, how the class works first. And then underneath it, you'll have a subsection called methods, where we go through each method and show you how to use each method separately. And again, there's lots of room to add more pros and examples to a lot of these. But every one of them has at least one example, so you can see how each thing works independently. OK. So next time we will at least make sure we go through and finish off the CUDA, byte to float transform, normalization and data bunch. And then not quite sure where we'll go from there, but we will figure it out. OK. Thanks, everybody, for joining in and thanks also for those of you who have been so helpful in adding some documentation and notes and stuff on the forums. That is super cool. See you next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 18.48, "text": " Okay, hi everybody can you see me?", "tokens": [1033, 11, 4879, 2201, 393, 291, 536, 385, 30], "temperature": 0.0, "avg_logprob": -0.8008321615365835, "compression_ratio": 0.8095238095238095, "no_speech_prob": 0.1910691261291504}, {"id": 1, "seek": 1848, "start": 18.48, "end": 30.48, "text": " Can you hear me okay?", "tokens": [50364, 1664, 291, 1568, 385, 1392, 30, 50964], "temperature": 0.0, "avg_logprob": -0.6629354688856337, "compression_ratio": 0.7241379310344828, "no_speech_prob": 0.0068746209144592285}, {"id": 2, "seek": 4848, "start": 48.48, "end": 61.48, "text": " Okay, this will be an interesting experiment.", "tokens": [1033, 11, 341, 486, 312, 364, 1880, 5120, 13], "temperature": 0.0, "avg_logprob": -0.6224872148953952, "compression_ratio": 0.8490566037735849, "no_speech_prob": 0.1092166006565094}, {"id": 3, "seek": 6148, "start": 61.48, "end": 85.47999999999999, "text": " Great, recording.", "tokens": [3769, 11, 6613, 13], "temperature": 0.0, "avg_logprob": -0.89360511302948, "compression_ratio": 0.68, "no_speech_prob": 8.4758285083808e-05}, {"id": 4, "seek": 8548, "start": 85.48, "end": 107.48, "text": " I'm going to go back to RISC-DIVE, we were looking at 08.", "tokens": [286, 478, 516, 281, 352, 646, 281, 497, 2343, 34, 12, 3085, 7540, 11, 321, 645, 1237, 412, 1958, 23, 13], "temperature": 0.0, "avg_logprob": -0.6499784851074218, "compression_ratio": 0.9827586206896551, "no_speech_prob": 7.133676263038069e-05}, {"id": 5, "seek": 10748, "start": 107.48, "end": 122.48, "text": " So, we need to make sure we git pull, because we're always changing stuff.", "tokens": [407, 11, 321, 643, 281, 652, 988, 321, 18331, 2235, 11, 570, 321, 434, 1009, 4473, 1507, 13], "temperature": 0.0, "avg_logprob": -0.35088592105441624, "compression_ratio": 1.0481927710843373, "no_speech_prob": 9.74942886386998e-05}, {"id": 6, "seek": 10748, "start": 122.48, "end": 130.48000000000002, "text": " And restart.", "tokens": [400, 21022, 13], "temperature": 0.0, "avg_logprob": -0.35088592105441624, "compression_ratio": 1.0481927710843373, "no_speech_prob": 9.74942886386998e-05}, {"id": 7, "seek": 13048, "start": 130.48, "end": 142.48, "text": " Okay, so where we're up to is we want how to create basically a function, actually something", "tokens": [1033, 11, 370, 689, 321, 434, 493, 281, 307, 321, 528, 577, 281, 1884, 1936, 257, 2445, 11, 767, 746], "temperature": 0.0, "avg_logprob": -0.26534241267613, "compression_ratio": 1.5139664804469273, "no_speech_prob": 0.00016337375564035028}, {"id": 8, "seek": 13048, "start": 142.48, "end": 147.48, "text": " that derives from transform, but it just looks exactly like a function, so you pass it an", "tokens": [300, 1163, 1539, 490, 4088, 11, 457, 309, 445, 1542, 2293, 411, 257, 2445, 11, 370, 291, 1320, 309, 364], "temperature": 0.0, "avg_logprob": -0.26534241267613, "compression_ratio": 1.5139664804469273, "no_speech_prob": 0.00016337375564035028}, {"id": 9, "seek": 13048, "start": 147.48, "end": 153.48, "text": " argument, transform will send that off to the encodes method, kind of like how nn.module", "tokens": [6770, 11, 4088, 486, 2845, 300, 766, 281, 264, 2058, 4789, 3170, 11, 733, 295, 411, 577, 297, 77, 13, 8014, 2271], "temperature": 0.0, "avg_logprob": -0.26534241267613, "compression_ratio": 1.5139664804469273, "no_speech_prob": 0.00016337375564035028}, {"id": 10, "seek": 15348, "start": 153.48, "end": 160.48, "text": " in PyTorch passes it off to a forward method, and it will calculate the result of the function", "tokens": [294, 9953, 51, 284, 339, 11335, 309, 766, 281, 257, 2128, 3170, 11, 293, 309, 486, 8873, 264, 1874, 295, 264, 2445], "temperature": 0.0, "avg_logprob": -0.1470482631396222, "compression_ratio": 1.7523364485981308, "no_speech_prob": 4.3998443288728595e-05}, {"id": 11, "seek": 15348, "start": 160.48, "end": 162.48, "text": " and return it.", "tokens": [293, 2736, 309, 13], "temperature": 0.0, "avg_logprob": -0.1470482631396222, "compression_ratio": 1.7523364485981308, "no_speech_prob": 4.3998443288728595e-05}, {"id": 12, "seek": 15348, "start": 162.48, "end": 168.48, "text": " And then we also learned that something which works that way, you can also optionally add", "tokens": [400, 550, 321, 611, 3264, 300, 746, 597, 1985, 300, 636, 11, 291, 393, 611, 3614, 379, 909], "temperature": 0.0, "avg_logprob": -0.1470482631396222, "compression_ratio": 1.7523364485981308, "no_speech_prob": 4.3998443288728595e-05}, {"id": 13, "seek": 15348, "start": 168.48, "end": 175.48, "text": " a decode, which will basically something that you undo that transform, or at least enough", "tokens": [257, 979, 1429, 11, 597, 486, 1936, 746, 300, 291, 23779, 300, 4088, 11, 420, 412, 1935, 1547], "temperature": 0.0, "avg_logprob": -0.1470482631396222, "compression_ratio": 1.7523364485981308, "no_speech_prob": 4.3998443288728595e-05}, {"id": 14, "seek": 15348, "start": 175.48, "end": 180.48, "text": " that you can display it, and so that has to return something which has a show method,", "tokens": [300, 291, 393, 4674, 309, 11, 293, 370, 300, 575, 281, 2736, 746, 597, 575, 257, 855, 3170, 11], "temperature": 0.0, "avg_logprob": -0.1470482631396222, "compression_ratio": 1.7523364485981308, "no_speech_prob": 4.3998443288728595e-05}, {"id": 15, "seek": 18048, "start": 180.48, "end": 184.48, "text": " so that's just a function basically.", "tokens": [370, 300, 311, 445, 257, 2445, 1936, 13], "temperature": 0.0, "avg_logprob": -0.09380703926086426, "compression_ratio": 1.5827338129496402, "no_speech_prob": 9.516068530501798e-06}, {"id": 16, "seek": 18048, "start": 184.48, "end": 190.48, "text": " And then we learned that you can pipeline functions, which basically just means that", "tokens": [400, 550, 321, 3264, 300, 291, 393, 15517, 6828, 11, 597, 1936, 445, 1355, 300], "temperature": 0.0, "avg_logprob": -0.09380703926086426, "compression_ratio": 1.5827338129496402, "no_speech_prob": 9.516068530501798e-06}, {"id": 17, "seek": 18048, "start": 190.48, "end": 201.48, "text": " you are composing functions together, or transforms, and the interesting thing in this one is that", "tokens": [291, 366, 715, 6110, 6828, 1214, 11, 420, 35592, 11, 293, 264, 1880, 551, 294, 341, 472, 307, 300], "temperature": 0.0, "avg_logprob": -0.09380703926086426, "compression_ratio": 1.5827338129496402, "no_speech_prob": 9.516068530501798e-06}, {"id": 18, "seek": 20148, "start": 201.48, "end": 216.48, "text": " when you return a tuple, it will then let you things after that, you can make them tuple", "tokens": [562, 291, 2736, 257, 2604, 781, 11, 309, 486, 550, 718, 291, 721, 934, 300, 11, 291, 393, 652, 552, 2604, 781], "temperature": 0.0, "avg_logprob": -0.09202569502371329, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.048826890037162e-06}, {"id": 19, "seek": 20148, "start": 216.48, "end": 221.48, "text": " transforms, and it will apply the function only to those items in the tuple individually", "tokens": [35592, 11, 293, 309, 486, 3079, 264, 2445, 787, 281, 729, 4754, 294, 264, 2604, 781, 16652], "temperature": 0.0, "avg_logprob": -0.09202569502371329, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.048826890037162e-06}, {"id": 20, "seek": 20148, "start": 221.48, "end": 224.48, "text": " that are of this requested type.", "tokens": [300, 366, 295, 341, 16436, 2010, 13], "temperature": 0.0, "avg_logprob": -0.09202569502371329, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.048826890037162e-06}, {"id": 21, "seek": 22448, "start": 224.48, "end": 236.48, "text": " I think we have one unnecessary annotation here, let me check.", "tokens": [286, 519, 321, 362, 472, 19350, 48654, 510, 11, 718, 385, 1520, 13], "temperature": 0.0, "avg_logprob": -0.19284215569496155, "compression_ratio": 1.3708609271523178, "no_speech_prob": 1.8630522390594706e-05}, {"id": 22, "seek": 22448, "start": 236.48, "end": 239.48, "text": " Yep.", "tokens": [7010, 13], "temperature": 0.0, "avg_logprob": -0.19284215569496155, "compression_ratio": 1.3708609271523178, "no_speech_prob": 1.8630522390594706e-05}, {"id": 23, "seek": 22448, "start": 239.48, "end": 241.48, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.19284215569496155, "compression_ratio": 1.3708609271523178, "no_speech_prob": 1.8630522390594706e-05}, {"id": 24, "seek": 22448, "start": 241.48, "end": 244.48, "text": " So, yes, Armand, can we decode from pipeline?", "tokens": [407, 11, 2086, 11, 11893, 474, 11, 393, 321, 979, 1429, 490, 15517, 30], "temperature": 0.0, "avg_logprob": -0.19284215569496155, "compression_ratio": 1.3708609271523178, "no_speech_prob": 1.8630522390594706e-05}, {"id": 25, "seek": 22448, "start": 244.48, "end": 253.48, "text": " That's kind of the whole point really, is that a pipeline that encodes can also decode.", "tokens": [663, 311, 733, 295, 264, 1379, 935, 534, 11, 307, 300, 257, 15517, 300, 2058, 4789, 393, 611, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.19284215569496155, "compression_ratio": 1.3708609271523178, "no_speech_prob": 1.8630522390594706e-05}, {"id": 26, "seek": 25348, "start": 253.48, "end": 267.48, "text": " So, you can see here, for instance, so we could go t equals pipe zero, and so there's", "tokens": [407, 11, 291, 393, 536, 510, 11, 337, 5197, 11, 370, 321, 727, 352, 256, 6915, 11240, 4018, 11, 293, 370, 456, 311], "temperature": 0.0, "avg_logprob": -0.20591771161114727, "compression_ratio": 1.0759493670886076, "no_speech_prob": 1.2218097253935412e-05}, {"id": 27, "seek": 26748, "start": 267.48, "end": 291.48, "text": " t, which is a tuple with a boolean and a tensor, actually we've already called that one.", "tokens": [256, 11, 597, 307, 257, 2604, 781, 365, 257, 748, 4812, 282, 293, 257, 40863, 11, 767, 321, 600, 1217, 1219, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.39038446971348356, "compression_ratio": 1.1, "no_speech_prob": 2.468086859153118e-05}, {"id": 28, "seek": 29148, "start": 291.48, "end": 298.48, "text": " Oh, sorry, they're doing the same thing, so it's two images and a boolean, so we could", "tokens": [876, 11, 2597, 11, 436, 434, 884, 264, 912, 551, 11, 370, 309, 311, 732, 5267, 293, 257, 748, 4812, 282, 11, 370, 321, 727], "temperature": 0.0, "avg_logprob": -0.23437723200371924, "compression_ratio": 1.287037037037037, "no_speech_prob": 1.2029453500872478e-05}, {"id": 29, "seek": 29148, "start": 298.48, "end": 314.48, "text": " say decoded t equals pipe.decode t, and there it is.", "tokens": [584, 979, 12340, 256, 6915, 11240, 13, 42821, 1429, 256, 11, 293, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.23437723200371924, "compression_ratio": 1.287037037037037, "no_speech_prob": 1.2029453500872478e-05}, {"id": 30, "seek": 31448, "start": 314.48, "end": 332.48, "text": " And so now that is, let's see, pipe.decode, so that's going to, actually none of these", "tokens": [400, 370, 586, 300, 307, 11, 718, 311, 536, 11, 11240, 13, 42821, 1429, 11, 370, 300, 311, 516, 281, 11, 767, 6022, 295, 613], "temperature": 0.0, "avg_logprob": -0.1517319260982045, "compression_ratio": 1.3984375, "no_speech_prob": 2.058031896012835e-06}, {"id": 31, "seek": 31448, "start": 332.48, "end": 335.48, "text": " have a decode in them, so that's a pretty boring example.", "tokens": [362, 257, 979, 1429, 294, 552, 11, 370, 300, 311, 257, 1238, 9989, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1517319260982045, "compression_ratio": 1.3984375, "no_speech_prob": 2.058031896012835e-06}, {"id": 32, "seek": 31448, "start": 335.48, "end": 338.48, "text": " Let's go back to the previous one.", "tokens": [961, 311, 352, 646, 281, 264, 3894, 472, 13], "temperature": 0.0, "avg_logprob": -0.1517319260982045, "compression_ratio": 1.3984375, "no_speech_prob": 2.058031896012835e-06}, {"id": 33, "seek": 33848, "start": 338.48, "end": 344.48, "text": " Oh, that's not a pipeline.", "tokens": [876, 11, 300, 311, 406, 257, 15517, 13], "temperature": 0.0, "avg_logprob": -0.15631839362057773, "compression_ratio": 1.558139534883721, "no_speech_prob": 4.784983957506483e-06}, {"id": 34, "seek": 33848, "start": 344.48, "end": 345.48, "text": " We'll come back to it.", "tokens": [492, 603, 808, 646, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.15631839362057773, "compression_ratio": 1.558139534883721, "no_speech_prob": 4.784983957506483e-06}, {"id": 35, "seek": 33848, "start": 345.48, "end": 348.48, "text": " We'll see one later, but basically, yes, so none of these have a decode.", "tokens": [492, 603, 536, 472, 1780, 11, 457, 1936, 11, 2086, 11, 370, 6022, 295, 613, 362, 257, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.15631839362057773, "compression_ratio": 1.558139534883721, "no_speech_prob": 4.784983957506483e-06}, {"id": 36, "seek": 33848, "start": 348.48, "end": 352.48, "text": " We don't have to decode Siamese image tuples.", "tokens": [492, 500, 380, 362, 281, 979, 1429, 318, 2918, 1130, 3256, 2604, 2622, 13], "temperature": 0.0, "avg_logprob": -0.15631839362057773, "compression_ratio": 1.558139534883721, "no_speech_prob": 4.784983957506483e-06}, {"id": 37, "seek": 33848, "start": 352.48, "end": 360.48, "text": " Yes, if you say pipe.decode, then it will pipeline through all of the steps calling", "tokens": [1079, 11, 498, 291, 584, 11240, 13, 42821, 1429, 11, 550, 309, 486, 15517, 807, 439, 295, 264, 4439, 5141], "temperature": 0.0, "avg_logprob": -0.15631839362057773, "compression_ratio": 1.558139534883721, "no_speech_prob": 4.784983957506483e-06}, {"id": 38, "seek": 33848, "start": 360.48, "end": 363.48, "text": " decode on each.", "tokens": [979, 1429, 322, 1184, 13], "temperature": 0.0, "avg_logprob": -0.15631839362057773, "compression_ratio": 1.558139534883721, "no_speech_prob": 4.784983957506483e-06}, {"id": 39, "seek": 36348, "start": 363.48, "end": 370.48, "text": " And actually, pipe.show is an interesting one, because to show a pipeline, it's going", "tokens": [400, 767, 11, 11240, 13, 34436, 307, 364, 1880, 472, 11, 570, 281, 855, 257, 15517, 11, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.09067391737913474, "compression_ratio": 1.5988372093023255, "no_speech_prob": 2.1907401333010057e-06}, {"id": 40, "seek": 36348, "start": 370.48, "end": 379.48, "text": " to decode every part of the tuple, which is normally the last step of the tuple, and it", "tokens": [281, 979, 1429, 633, 644, 295, 264, 2604, 781, 11, 597, 307, 5646, 264, 1036, 1823, 295, 264, 2604, 781, 11, 293, 309], "temperature": 0.0, "avg_logprob": -0.09067391737913474, "compression_ratio": 1.5988372093023255, "no_speech_prob": 2.1907401333010057e-06}, {"id": 41, "seek": 36348, "start": 379.48, "end": 387.48, "text": " will keep decoding it, but it will stop as soon as it gets to a type which has a show", "tokens": [486, 1066, 979, 8616, 309, 11, 457, 309, 486, 1590, 382, 2321, 382, 309, 2170, 281, 257, 2010, 597, 575, 257, 855], "temperature": 0.0, "avg_logprob": -0.09067391737913474, "compression_ratio": 1.5988372093023255, "no_speech_prob": 2.1907401333010057e-06}, {"id": 42, "seek": 36348, "start": 387.48, "end": 389.48, "text": " method defined.", "tokens": [3170, 7642, 13], "temperature": 0.0, "avg_logprob": -0.09067391737913474, "compression_ratio": 1.5988372093023255, "no_speech_prob": 2.1907401333010057e-06}, {"id": 43, "seek": 38948, "start": 389.48, "end": 398.48, "text": " So in this case, actually, the output type of pipe is a Siamese image, and the Siamese", "tokens": [407, 294, 341, 1389, 11, 767, 11, 264, 5598, 2010, 295, 11240, 307, 257, 318, 2918, 1130, 3256, 11, 293, 264, 318, 2918, 1130], "temperature": 0.0, "avg_logprob": -0.10533978905476316, "compression_ratio": 1.5442176870748299, "no_speech_prob": 1.349683770968113e-06}, {"id": 44, "seek": 38948, "start": 398.48, "end": 404.48, "text": " image has a show method defined, so when we call.show, it doesn't really need to decode", "tokens": [3256, 575, 257, 855, 3170, 7642, 11, 370, 562, 321, 818, 2411, 34436, 11, 309, 1177, 380, 534, 643, 281, 979, 1429], "temperature": 0.0, "avg_logprob": -0.10533978905476316, "compression_ratio": 1.5442176870748299, "no_speech_prob": 1.349683770968113e-06}, {"id": 45, "seek": 38948, "start": 404.48, "end": 405.48, "text": " at all.", "tokens": [412, 439, 13], "temperature": 0.0, "avg_logprob": -0.10533978905476316, "compression_ratio": 1.5442176870748299, "no_speech_prob": 1.349683770968113e-06}, {"id": 46, "seek": 38948, "start": 405.48, "end": 411.48, "text": " But for other types, it does need to decode.", "tokens": [583, 337, 661, 3467, 11, 309, 775, 643, 281, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.10533978905476316, "compression_ratio": 1.5442176870748299, "no_speech_prob": 1.349683770968113e-06}, {"id": 47, "seek": 41148, "start": 411.48, "end": 419.48, "text": " And transform data source is something where we give it arrays of transforms or functions.", "tokens": [400, 4088, 1412, 4009, 307, 746, 689, 321, 976, 309, 41011, 295, 35592, 420, 6828, 13], "temperature": 0.0, "avg_logprob": -0.07590600027554277, "compression_ratio": 1.6022727272727273, "no_speech_prob": 1.544560473121237e-05}, {"id": 48, "seek": 41148, "start": 419.48, "end": 423.48, "text": " Each one will be turned into a pipeline, and each one of those pipelines will be applied", "tokens": [6947, 472, 486, 312, 3574, 666, 257, 15517, 11, 293, 1184, 472, 295, 729, 40168, 486, 312, 6456], "temperature": 0.0, "avg_logprob": -0.07590600027554277, "compression_ratio": 1.6022727272727273, "no_speech_prob": 1.544560473121237e-05}, {"id": 49, "seek": 41148, "start": 423.48, "end": 435.48, "text": " to each item, and that will then give us a tuple, which was not working yesterday, but", "tokens": [281, 1184, 3174, 11, 293, 300, 486, 550, 976, 505, 257, 2604, 781, 11, 597, 390, 406, 1364, 5186, 11, 457], "temperature": 0.0, "avg_logprob": -0.07590600027554277, "compression_ratio": 1.6022727272727273, "no_speech_prob": 1.544560473121237e-05}, {"id": 50, "seek": 41148, "start": 435.48, "end": 439.48, "text": " is working now.", "tokens": [307, 1364, 586, 13], "temperature": 0.0, "avg_logprob": -0.07590600027554277, "compression_ratio": 1.6022727272727273, "no_speech_prob": 1.544560473121237e-05}, {"id": 51, "seek": 43948, "start": 439.48, "end": 443.48, "text": " So, you can see, actually, this is a good example of decode.", "tokens": [407, 11, 291, 393, 536, 11, 767, 11, 341, 307, 257, 665, 1365, 295, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.2759598248625455, "compression_ratio": 1.481012658227848, "no_speech_prob": 1.4284546523413155e-05}, {"id": 52, "seek": 43948, "start": 443.48, "end": 450.48, "text": " A transformed dataset, a TwifmDS, can decode, and what that's going to do is it's going", "tokens": [316, 16894, 28872, 11, 257, 2574, 351, 76, 11844, 11, 393, 979, 1429, 11, 293, 437, 300, 311, 516, 281, 360, 307, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.2759598248625455, "compression_ratio": 1.481012658227848, "no_speech_prob": 1.4284546523413155e-05}, {"id": 53, "seek": 43948, "start": 450.48, "end": 461.48, "text": " to take our PIO image and our number, and it's going to decode each part of the tuple", "tokens": [281, 747, 527, 430, 15167, 3256, 293, 527, 1230, 11, 293, 309, 311, 516, 281, 979, 1429, 1184, 644, 295, 264, 2604, 781], "temperature": 0.0, "avg_logprob": -0.2759598248625455, "compression_ratio": 1.481012658227848, "no_speech_prob": 1.4284546523413155e-05}, {"id": 54, "seek": 46148, "start": 461.48, "end": 470.48, "text": " by decoding each of the pipelines, and then you end up with, as you see, the correct name,", "tokens": [538, 979, 8616, 1184, 295, 264, 40168, 11, 293, 550, 291, 917, 493, 365, 11, 382, 291, 536, 11, 264, 3006, 1315, 11], "temperature": 0.0, "avg_logprob": -0.12144785563151042, "compression_ratio": 1.6037735849056605, "no_speech_prob": 5.8623822951631155e-06}, {"id": 55, "seek": 46148, "start": 470.48, "end": 472.48, "text": " in this case, of the pet breed.", "tokens": [294, 341, 1389, 11, 295, 264, 3817, 18971, 13], "temperature": 0.0, "avg_logprob": -0.12144785563151042, "compression_ratio": 1.6037735849056605, "no_speech_prob": 5.8623822951631155e-06}, {"id": 56, "seek": 46148, "start": 472.48, "end": 479.48, "text": " And so show, again, will decode each part of that tuple up until the point where it", "tokens": [400, 370, 855, 11, 797, 11, 486, 979, 1429, 1184, 644, 295, 300, 2604, 781, 493, 1826, 264, 935, 689, 309], "temperature": 0.0, "avg_logprob": -0.12144785563151042, "compression_ratio": 1.6037735849056605, "no_speech_prob": 5.8623822951631155e-06}, {"id": 57, "seek": 46148, "start": 479.48, "end": 490.48, "text": " finds the show method, and then it will show it.", "tokens": [10704, 264, 855, 3170, 11, 293, 550, 309, 486, 855, 309, 13], "temperature": 0.0, "avg_logprob": -0.12144785563151042, "compression_ratio": 1.6037735849056605, "no_speech_prob": 5.8623822951631155e-06}, {"id": 58, "seek": 49048, "start": 490.48, "end": 496.48, "text": " Now, I don't think we got as far as TwifmDL yesterday.", "tokens": [823, 11, 286, 500, 380, 519, 321, 658, 382, 1400, 382, 2574, 351, 76, 35, 43, 5186, 13], "temperature": 0.0, "avg_logprob": -0.11583759360117456, "compression_ratio": 1.3941176470588235, "no_speech_prob": 9.368363862449769e-06}, {"id": 59, "seek": 49048, "start": 496.48, "end": 502.48, "text": " No, I guess we couldn't have, because it wasn't working.", "tokens": [883, 11, 286, 2041, 321, 2809, 380, 362, 11, 570, 309, 2067, 380, 1364, 13], "temperature": 0.0, "avg_logprob": -0.11583759360117456, "compression_ratio": 1.3941176470588235, "no_speech_prob": 9.368363862449769e-06}, {"id": 60, "seek": 49048, "start": 502.48, "end": 514.48, "text": " So, TwifmDL is a data loader which understands fast AI version 2 stuff, and specifically,", "tokens": [407, 11, 2574, 351, 76, 35, 43, 307, 257, 1412, 3677, 260, 597, 15146, 2370, 7318, 3037, 568, 1507, 11, 293, 4682, 11], "temperature": 0.0, "avg_logprob": -0.11583759360117456, "compression_ratio": 1.3941176470588235, "no_speech_prob": 9.368363862449769e-06}, {"id": 61, "seek": 49048, "start": 514.48, "end": 518.48, "text": " it understands two pieces of stuff.", "tokens": [309, 15146, 732, 3755, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.11583759360117456, "compression_ratio": 1.3941176470588235, "no_speech_prob": 9.368363862449769e-06}, {"id": 62, "seek": 51848, "start": 518.48, "end": 522.48, "text": " One is that it understands how to maintain types.", "tokens": [1485, 307, 300, 309, 15146, 577, 281, 6909, 3467, 13], "temperature": 0.0, "avg_logprob": -0.09961018195519081, "compression_ratio": 1.7771428571428571, "no_speech_prob": 3.555925104592461e-06}, {"id": 63, "seek": 51848, "start": 522.48, "end": 534.48, "text": " So, it makes sure that, you know, transform or pillow image subtypes are maintained, and", "tokens": [407, 11, 309, 1669, 988, 300, 11, 291, 458, 11, 4088, 420, 18581, 3256, 1422, 874, 5190, 366, 17578, 11, 293], "temperature": 0.0, "avg_logprob": -0.09961018195519081, "compression_ratio": 1.7771428571428571, "no_speech_prob": 3.555925104592461e-06}, {"id": 64, "seek": 51848, "start": 534.48, "end": 536.48, "text": " it understands decoding.", "tokens": [309, 15146, 979, 8616, 13], "temperature": 0.0, "avg_logprob": -0.09961018195519081, "compression_ratio": 1.7771428571428571, "no_speech_prob": 3.555925104592461e-06}, {"id": 65, "seek": 51848, "start": 536.48, "end": 541.48, "text": " So, basically, it lets you have transforms in a transformed data loader, and they will", "tokens": [407, 11, 1936, 11, 309, 6653, 291, 362, 35592, 294, 257, 16894, 1412, 3677, 260, 11, 293, 436, 486], "temperature": 0.0, "avg_logprob": -0.09961018195519081, "compression_ratio": 1.7771428571428571, "no_speech_prob": 3.555925104592461e-06}, {"id": 66, "seek": 51848, "start": 541.48, "end": 546.48, "text": " behave the same way as transformed in a transformed dataset.", "tokens": [15158, 264, 912, 636, 382, 16894, 294, 257, 16894, 28872, 13], "temperature": 0.0, "avg_logprob": -0.09961018195519081, "compression_ratio": 1.7771428571428571, "no_speech_prob": 3.555925104592461e-06}, {"id": 67, "seek": 54648, "start": 546.48, "end": 550.48, "text": " So, here, what we're going to do is we're going to do the same thing we had before.", "tokens": [407, 11, 510, 11, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 360, 264, 912, 551, 321, 632, 949, 13], "temperature": 0.0, "avg_logprob": -0.10524875042485256, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.169248884660192e-05}, {"id": 68, "seek": 54648, "start": 550.48, "end": 554.48, "text": " Let's just copy it down so we remember.", "tokens": [961, 311, 445, 5055, 309, 760, 370, 321, 1604, 13], "temperature": 0.0, "avg_logprob": -0.10524875042485256, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.169248884660192e-05}, {"id": 69, "seek": 54648, "start": 554.48, "end": 559.48, "text": " So, this was how we did pets last time.", "tokens": [407, 11, 341, 390, 577, 321, 630, 19897, 1036, 565, 13], "temperature": 0.0, "avg_logprob": -0.10524875042485256, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.169248884660192e-05}, {"id": 70, "seek": 54648, "start": 559.48, "end": 567.48, "text": " So, previously, our first pipeline was image.create, resize to tensor, byte to float tensor, and", "tokens": [407, 11, 8046, 11, 527, 700, 15517, 390, 3256, 13, 14066, 473, 11, 50069, 281, 40863, 11, 40846, 281, 15706, 40863, 11, 293], "temperature": 0.0, "avg_logprob": -0.10524875042485256, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.169248884660192e-05}, {"id": 71, "seek": 54648, "start": 567.48, "end": 575.48, "text": " our second pipeline was labeler and categorize, and just to remind you, labeler was a regex", "tokens": [527, 1150, 15517, 390, 2715, 6185, 293, 19250, 1125, 11, 293, 445, 281, 4160, 291, 11, 2715, 6185, 390, 257, 319, 432, 87], "temperature": 0.0, "avg_logprob": -0.10524875042485256, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.169248884660192e-05}, {"id": 72, "seek": 57548, "start": 575.48, "end": 577.48, "text": " labeler function.", "tokens": [2715, 6185, 2445, 13], "temperature": 0.0, "avg_logprob": -0.2085586856393253, "compression_ratio": 1.496124031007752, "no_speech_prob": 2.601550022518495e-06}, {"id": 73, "seek": 57548, "start": 577.48, "end": 587.48, "text": " This time, the labeling pipeline is the same, but the image pipeline is just PIO image.create.", "tokens": [639, 565, 11, 264, 40244, 15517, 307, 264, 912, 11, 457, 264, 3256, 15517, 307, 445, 430, 15167, 3256, 13, 14066, 473, 13], "temperature": 0.0, "avg_logprob": -0.2085586856393253, "compression_ratio": 1.496124031007752, "no_speech_prob": 2.601550022518495e-06}, {"id": 74, "seek": 57548, "start": 587.48, "end": 591.48, "text": " So, what's PIO image?", "tokens": [407, 11, 437, 311, 430, 15167, 3256, 30], "temperature": 0.0, "avg_logprob": -0.2085586856393253, "compression_ratio": 1.496124031007752, "no_speech_prob": 2.601550022518495e-06}, {"id": 75, "seek": 57548, "start": 591.48, "end": 597.48, "text": " PIO image is simply a...", "tokens": [430, 15167, 3256, 307, 2935, 257, 485], "temperature": 0.0, "avg_logprob": -0.2085586856393253, "compression_ratio": 1.496124031007752, "no_speech_prob": 2.601550022518495e-06}, {"id": 76, "seek": 57548, "start": 597.48, "end": 601.48, "text": " Here it is.", "tokens": [1692, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.2085586856393253, "compression_ratio": 1.496124031007752, "no_speech_prob": 2.601550022518495e-06}, {"id": 77, "seek": 57548, "start": 601.48, "end": 603.48, "text": " Oh, yeah, here it is.", "tokens": [876, 11, 1338, 11, 510, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.2085586856393253, "compression_ratio": 1.496124031007752, "no_speech_prob": 2.601550022518495e-06}, {"id": 78, "seek": 60348, "start": 603.48, "end": 605.48, "text": " It's this.", "tokens": [467, 311, 341, 13], "temperature": 0.0, "avg_logprob": -0.08330875093286688, "compression_ratio": 1.691891891891892, "no_speech_prob": 8.397902092838194e-06}, {"id": 79, "seek": 60348, "start": 605.48, "end": 617.48, "text": " It's one line of code, and it's just a thing that inherits from PIO base, and PIO base", "tokens": [467, 311, 472, 1622, 295, 3089, 11, 293, 309, 311, 445, 257, 551, 300, 9484, 1208, 490, 430, 15167, 3096, 11, 293, 430, 15167, 3096], "temperature": 0.0, "avg_logprob": -0.08330875093286688, "compression_ratio": 1.691891891891892, "no_speech_prob": 8.397902092838194e-06}, {"id": 80, "seek": 60348, "start": 617.48, "end": 623.48, "text": " is something which inherits from PIO image.", "tokens": [307, 746, 597, 9484, 1208, 490, 430, 15167, 3256, 13], "temperature": 0.0, "avg_logprob": -0.08330875093286688, "compression_ratio": 1.691891891891892, "no_speech_prob": 8.397902092838194e-06}, {"id": 81, "seek": 60348, "start": 623.48, "end": 627.48, "text": " And there's a bit more information than we need here, but the key thing to recognize", "tokens": [400, 456, 311, 257, 857, 544, 1589, 813, 321, 643, 510, 11, 457, 264, 2141, 551, 281, 5521], "temperature": 0.0, "avg_logprob": -0.08330875093286688, "compression_ratio": 1.691891891891892, "no_speech_prob": 8.397902092838194e-06}, {"id": 82, "seek": 60348, "start": 627.48, "end": 631.48, "text": " about this is that it has a create method and a show method, which are the things that", "tokens": [466, 341, 307, 300, 309, 575, 257, 1884, 3170, 293, 257, 855, 3170, 11, 597, 366, 264, 721, 300], "temperature": 0.0, "avg_logprob": -0.08330875093286688, "compression_ratio": 1.691891891891892, "no_speech_prob": 8.397902092838194e-06}, {"id": 83, "seek": 63148, "start": 631.48, "end": 637.48, "text": " we need for it to be able to work in our transform pipelines.", "tokens": [321, 643, 337, 309, 281, 312, 1075, 281, 589, 294, 527, 4088, 40168, 13], "temperature": 0.0, "avg_logprob": -0.10098550744252661, "compression_ratio": 1.4679487179487178, "no_speech_prob": 7.296308012882946e-06}, {"id": 84, "seek": 63148, "start": 637.48, "end": 639.48, "text": " And the create is static.", "tokens": [400, 264, 1884, 307, 13437, 13], "temperature": 0.0, "avg_logprob": -0.10098550744252661, "compression_ratio": 1.4679487179487178, "no_speech_prob": 7.296308012882946e-06}, {"id": 85, "seek": 63148, "start": 639.48, "end": 646.48, "text": " So, PIO image.create is simply going to call load image, which is the thing that opens", "tokens": [407, 11, 430, 15167, 3256, 13, 14066, 473, 307, 2935, 516, 281, 818, 3677, 3256, 11, 597, 307, 264, 551, 300, 9870], "temperature": 0.0, "avg_logprob": -0.10098550744252661, "compression_ratio": 1.4679487179487178, "no_speech_prob": 7.296308012882946e-06}, {"id": 86, "seek": 63148, "start": 646.48, "end": 652.48, "text": " the PIO image in the usual way.", "tokens": [264, 430, 15167, 3256, 294, 264, 7713, 636, 13], "temperature": 0.0, "avg_logprob": -0.10098550744252661, "compression_ratio": 1.4679487179487178, "no_speech_prob": 7.296308012882946e-06}, {"id": 87, "seek": 63148, "start": 652.48, "end": 653.48, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.10098550744252661, "compression_ratio": 1.4679487179487178, "no_speech_prob": 7.296308012882946e-06}, {"id": 88, "seek": 63148, "start": 653.48, "end": 657.48, "text": " So, that's that.", "tokens": [407, 11, 300, 311, 300, 13], "temperature": 0.0, "avg_logprob": -0.10098550744252661, "compression_ratio": 1.4679487179487178, "no_speech_prob": 7.296308012882946e-06}, {"id": 89, "seek": 65748, "start": 657.48, "end": 664.48, "text": " So, why are we able to get rid of all of these things from our image pipeline?", "tokens": [407, 11, 983, 366, 321, 1075, 281, 483, 3973, 295, 439, 295, 613, 721, 490, 527, 3256, 15517, 30], "temperature": 0.0, "avg_logprob": -0.07104901778392303, "compression_ratio": 1.507462686567164, "no_speech_prob": 3.2377338357036933e-06}, {"id": 90, "seek": 65748, "start": 664.48, "end": 675.48, "text": " The reason is that we've moved them into our data loader transformation pipeline, which", "tokens": [440, 1778, 307, 300, 321, 600, 4259, 552, 666, 527, 1412, 3677, 260, 9887, 15517, 11, 597], "temperature": 0.0, "avg_logprob": -0.07104901778392303, "compression_ratio": 1.507462686567164, "no_speech_prob": 3.2377338357036933e-06}, {"id": 91, "seek": 65748, "start": 675.48, "end": 679.48, "text": " is going to turn out to be pretty handy.", "tokens": [307, 516, 281, 1261, 484, 281, 312, 1238, 13239, 13], "temperature": 0.0, "avg_logprob": -0.07104901778392303, "compression_ratio": 1.507462686567164, "no_speech_prob": 3.2377338357036933e-06}, {"id": 92, "seek": 65748, "start": 679.48, "end": 684.48, "text": " In this case, it doesn't make much of a difference, but basically what's going to happen now is", "tokens": [682, 341, 1389, 11, 309, 1177, 380, 652, 709, 295, 257, 2649, 11, 457, 1936, 437, 311, 516, 281, 1051, 586, 307], "temperature": 0.0, "avg_logprob": -0.07104901778392303, "compression_ratio": 1.507462686567164, "no_speech_prob": 3.2377338357036933e-06}, {"id": 93, "seek": 68448, "start": 684.48, "end": 688.48, "text": " we'll learn a bit more about the data loaders today.", "tokens": [321, 603, 1466, 257, 857, 544, 466, 264, 1412, 3677, 433, 965, 13], "temperature": 0.0, "avg_logprob": -0.08742971079690116, "compression_ratio": 1.616504854368932, "no_speech_prob": 4.637798156181816e-06}, {"id": 94, "seek": 68448, "start": 688.48, "end": 693.48, "text": " But basically, the data loaders also have places you can add transform pipelines, and", "tokens": [583, 1936, 11, 264, 1412, 3677, 433, 611, 362, 3190, 291, 393, 909, 4088, 40168, 11, 293], "temperature": 0.0, "avg_logprob": -0.08742971079690116, "compression_ratio": 1.616504854368932, "no_speech_prob": 4.637798156181816e-06}, {"id": 95, "seek": 68448, "start": 693.48, "end": 702.48, "text": " in this case, after creating the data set, it's going to call these on inside the actual", "tokens": [294, 341, 1389, 11, 934, 4084, 264, 1412, 992, 11, 309, 311, 516, 281, 818, 613, 322, 1854, 264, 3539], "temperature": 0.0, "avg_logprob": -0.08742971079690116, "compression_ratio": 1.616504854368932, "no_speech_prob": 4.637798156181816e-06}, {"id": 96, "seek": 68448, "start": 702.48, "end": 705.48, "text": " data loader itself.", "tokens": [1412, 3677, 260, 2564, 13], "temperature": 0.0, "avg_logprob": -0.08742971079690116, "compression_ratio": 1.616504854368932, "no_speech_prob": 4.637798156181816e-06}, {"id": 97, "seek": 68448, "start": 705.48, "end": 712.48, "text": " One thing to recognize is that image resize and byte to float tensor don't make sense", "tokens": [1485, 551, 281, 5521, 307, 300, 3256, 50069, 293, 40846, 281, 15706, 40863, 500, 380, 652, 2020], "temperature": 0.0, "avg_logprob": -0.08742971079690116, "compression_ratio": 1.616504854368932, "no_speech_prob": 4.637798156181816e-06}, {"id": 98, "seek": 71248, "start": 712.48, "end": 724.48, "text": " for categories, but that's okay because image resizer only defines encodes for PIO image", "tokens": [337, 10479, 11, 457, 300, 311, 1392, 570, 3256, 725, 6545, 787, 23122, 2058, 4789, 337, 430, 15167, 3256], "temperature": 0.0, "avg_logprob": -0.10022895336151123, "compression_ratio": 1.4313725490196079, "no_speech_prob": 4.637824986275518e-06}, {"id": 99, "seek": 71248, "start": 724.48, "end": 725.48, "text": " and PIO mask.", "tokens": [293, 430, 15167, 6094, 13], "temperature": 0.0, "avg_logprob": -0.10022895336151123, "compression_ratio": 1.4313725490196079, "no_speech_prob": 4.637824986275518e-06}, {"id": 100, "seek": 71248, "start": 725.48, "end": 731.48, "text": " It doesn't define them for anything else, so it'll just ignore the categories.", "tokens": [467, 1177, 380, 6964, 552, 337, 1340, 1646, 11, 370, 309, 603, 445, 11200, 264, 10479, 13], "temperature": 0.0, "avg_logprob": -0.10022895336151123, "compression_ratio": 1.4313725490196079, "no_speech_prob": 4.637824986275518e-06}, {"id": 101, "seek": 71248, "start": 731.48, "end": 737.48, "text": " And byte to float tensor is the same.", "tokens": [400, 40846, 281, 15706, 40863, 307, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.10022895336151123, "compression_ratio": 1.4313725490196079, "no_speech_prob": 4.637824986275518e-06}, {"id": 102, "seek": 73748, "start": 737.48, "end": 744.48, "text": " It's defined on tensor image, encodes, and tensor mask, encodes, and nothing else.", "tokens": [467, 311, 7642, 322, 40863, 3256, 11, 2058, 4789, 11, 293, 40863, 6094, 11, 2058, 4789, 11, 293, 1825, 1646, 13], "temperature": 0.0, "avg_logprob": -0.15119320770789837, "compression_ratio": 1.4083333333333334, "no_speech_prob": 8.714237083040643e-07}, {"id": 103, "seek": 73748, "start": 744.48, "end": 749.48, "text": " So, it won't change our categories.", "tokens": [407, 11, 309, 1582, 380, 1319, 527, 10479, 13], "temperature": 0.0, "avg_logprob": -0.15119320770789837, "compression_ratio": 1.4083333333333334, "no_speech_prob": 8.714237083040643e-07}, {"id": 104, "seek": 73748, "start": 749.48, "end": 754.48, "text": " So, that is why that works.", "tokens": [407, 11, 300, 307, 983, 300, 1985, 13], "temperature": 0.0, "avg_logprob": -0.15119320770789837, "compression_ratio": 1.4083333333333334, "no_speech_prob": 8.714237083040643e-07}, {"id": 105, "seek": 73748, "start": 754.48, "end": 759.48, "text": " So, there it is.", "tokens": [407, 11, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.15119320770789837, "compression_ratio": 1.4083333333333334, "no_speech_prob": 8.714237083040643e-07}, {"id": 106, "seek": 73748, "start": 759.48, "end": 762.48, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.15119320770789837, "compression_ratio": 1.4083333333333334, "no_speech_prob": 8.714237083040643e-07}, {"id": 107, "seek": 76248, "start": 762.48, "end": 770.48, "text": " The last kind of piece of this part of the API is data source, and so each thing is going", "tokens": [440, 1036, 733, 295, 2522, 295, 341, 644, 295, 264, 9362, 307, 1412, 4009, 11, 293, 370, 1184, 551, 307, 516], "temperature": 0.0, "avg_logprob": -0.08885928204185084, "compression_ratio": 1.6263736263736264, "no_speech_prob": 1.2606455129571259e-05}, {"id": 108, "seek": 76248, "start": 770.48, "end": 771.48, "text": " to build on each other thing.", "tokens": [281, 1322, 322, 1184, 661, 551, 13], "temperature": 0.0, "avg_logprob": -0.08885928204185084, "compression_ratio": 1.6263736263736264, "no_speech_prob": 1.2606455129571259e-05}, {"id": 109, "seek": 76248, "start": 771.48, "end": 778.48, "text": " So, a data source is basically a transformed data set, but with the ability to create separate", "tokens": [407, 11, 257, 1412, 4009, 307, 1936, 257, 16894, 1412, 992, 11, 457, 365, 264, 3485, 281, 1884, 4994], "temperature": 0.0, "avg_logprob": -0.08885928204185084, "compression_ratio": 1.6263736263736264, "no_speech_prob": 1.2606455129571259e-05}, {"id": 110, "seek": 76248, "start": 778.48, "end": 785.48, "text": " training and validation sets, and in fact, to create as many subsets as you like.", "tokens": [3097, 293, 24071, 6352, 11, 293, 294, 1186, 11, 281, 1884, 382, 867, 2090, 1385, 382, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.08885928204185084, "compression_ratio": 1.6263736263736264, "no_speech_prob": 1.2606455129571259e-05}, {"id": 111, "seek": 78548, "start": 785.48, "end": 793.48, "text": " So, okay.", "tokens": [407, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.1929799238840739, "compression_ratio": 1.0795454545454546, "no_speech_prob": 1.0615306564432103e-05}, {"id": 112, "seek": 78548, "start": 793.48, "end": 812.48, "text": " So, if you're having trouble with code not running, best place to ask is on the forum", "tokens": [407, 11, 498, 291, 434, 1419, 5253, 365, 3089, 406, 2614, 11, 1151, 1081, 281, 1029, 307, 322, 264, 17542], "temperature": 0.0, "avg_logprob": -0.1929799238840739, "compression_ratio": 1.0795454545454546, "no_speech_prob": 1.0615306564432103e-05}, {"id": 113, "seek": 81248, "start": 812.48, "end": 820.48, "text": " because I can't debug it while we go, but feel free to ask on the forum.", "tokens": [570, 286, 393, 380, 24083, 309, 1339, 321, 352, 11, 457, 841, 1737, 281, 1029, 322, 264, 17542, 13], "temperature": 0.0, "avg_logprob": -0.12395884115484697, "compression_ratio": 1.4861878453038675, "no_speech_prob": 9.368515748064965e-06}, {"id": 114, "seek": 81248, "start": 820.48, "end": 821.48, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.12395884115484697, "compression_ratio": 1.4861878453038675, "no_speech_prob": 9.368515748064965e-06}, {"id": 115, "seek": 81248, "start": 821.48, "end": 829.48, "text": " So, what we're going to do now is we're going to use this thing that looks a lot like a", "tokens": [407, 11, 437, 321, 434, 516, 281, 360, 586, 307, 321, 434, 516, 281, 764, 341, 551, 300, 1542, 257, 688, 411, 257], "temperature": 0.0, "avg_logprob": -0.12395884115484697, "compression_ratio": 1.4861878453038675, "no_speech_prob": 9.368515748064965e-06}, {"id": 116, "seek": 81248, "start": 829.48, "end": 836.04, "text": " TFMDS, a transformed data source, but it's going to allow us to separate training and", "tokens": [40964, 44, 11844, 11, 257, 16894, 1412, 4009, 11, 457, 309, 311, 516, 281, 2089, 505, 281, 4994, 3097, 293], "temperature": 0.0, "avg_logprob": -0.12395884115484697, "compression_ratio": 1.4861878453038675, "no_speech_prob": 9.368515748064965e-06}, {"id": 117, "seek": 81248, "start": 836.04, "end": 837.6800000000001, "text": " validation sets.", "tokens": [24071, 6352, 13], "temperature": 0.0, "avg_logprob": -0.12395884115484697, "compression_ratio": 1.4861878453038675, "no_speech_prob": 9.368515748064965e-06}, {"id": 118, "seek": 83768, "start": 837.68, "end": 844.68, "text": " And so, if you look at how TFMDS was defined, here it is here.", "tokens": [400, 370, 11, 498, 291, 574, 412, 577, 40964, 44, 11844, 390, 7642, 11, 510, 309, 307, 510, 13], "temperature": 0.0, "avg_logprob": -0.16915408674492893, "compression_ratio": 1.5945945945945945, "no_speech_prob": 3.8227710319915786e-05}, {"id": 119, "seek": 83768, "start": 844.68, "end": 850.64, "text": " So, when we created our TFMDS, we passed in items and transforms.", "tokens": [407, 11, 562, 321, 2942, 527, 40964, 44, 11844, 11, 321, 4678, 294, 4754, 293, 35592, 13], "temperature": 0.0, "avg_logprob": -0.16915408674492893, "compression_ratio": 1.5945945945945945, "no_speech_prob": 3.8227710319915786e-05}, {"id": 120, "seek": 83768, "start": 850.64, "end": 857.0799999999999, "text": " This time we've got to pass in items and transforms and the indices of our splits.", "tokens": [639, 565, 321, 600, 658, 281, 1320, 294, 4754, 293, 35592, 293, 264, 43840, 295, 527, 37741, 13], "temperature": 0.0, "avg_logprob": -0.16915408674492893, "compression_ratio": 1.5945945945945945, "no_speech_prob": 3.8227710319915786e-05}, {"id": 121, "seek": 83768, "start": 857.0799999999999, "end": 866.76, "text": " So, remember split IDX was something with two arrays in it, and the arrays just had", "tokens": [407, 11, 1604, 7472, 7348, 55, 390, 746, 365, 732, 41011, 294, 309, 11, 293, 264, 41011, 445, 632], "temperature": 0.0, "avg_logprob": -0.16915408674492893, "compression_ratio": 1.5945945945945945, "no_speech_prob": 3.8227710319915786e-05}, {"id": 122, "seek": 86676, "start": 866.76, "end": 872.76, "text": " lists of IDs for the training validation set.", "tokens": [14511, 295, 48212, 337, 264, 3097, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.20329723138918823, "compression_ratio": 1.49009900990099, "no_speech_prob": 1.4063584785617422e-05}, {"id": 123, "seek": 86676, "start": 872.76, "end": 875.76, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.20329723138918823, "compression_ratio": 1.49009900990099, "no_speech_prob": 1.4063584785617422e-05}, {"id": 124, "seek": 86676, "start": 875.76, "end": 884.6, "text": " So, by passing the data source's extra piece of information, we'll end up with something", "tokens": [407, 11, 538, 8437, 264, 1412, 4009, 311, 2857, 2522, 295, 1589, 11, 321, 603, 917, 493, 365, 746], "temperature": 0.0, "avg_logprob": -0.20329723138918823, "compression_ratio": 1.49009900990099, "no_speech_prob": 1.4063584785617422e-05}, {"id": 125, "seek": 86676, "start": 884.6, "end": 887.76, "text": " that you can use exactly the same way as TFMDS.", "tokens": [300, 291, 393, 764, 2293, 264, 912, 636, 382, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.20329723138918823, "compression_ratio": 1.49009900990099, "no_speech_prob": 1.4063584785617422e-05}, {"id": 126, "seek": 86676, "start": 887.76, "end": 890.56, "text": " So, you can still just ask for an element from it.", "tokens": [407, 11, 291, 393, 920, 445, 1029, 337, 364, 4478, 490, 309, 13], "temperature": 0.0, "avg_logprob": -0.20329723138918823, "compression_ratio": 1.49009900990099, "no_speech_prob": 1.4063584785617422e-05}, {"id": 127, "seek": 86676, "start": 890.56, "end": 894.64, "text": " So, this is kind of a superset of the functionality of TFMDS.", "tokens": [407, 11, 341, 307, 733, 295, 257, 37906, 302, 295, 264, 14980, 295, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.20329723138918823, "compression_ratio": 1.49009900990099, "no_speech_prob": 1.4063584785617422e-05}, {"id": 128, "seek": 89464, "start": 894.64, "end": 898.48, "text": " But you can also ask for a subset.", "tokens": [583, 291, 393, 611, 1029, 337, 257, 25993, 13], "temperature": 0.0, "avg_logprob": -0.1939098272430763, "compression_ratio": 1.6589595375722543, "no_speech_prob": 5.173831141291885e-06}, {"id": 129, "seek": 89464, "start": 898.48, "end": 904.72, "text": " So, the zeroth subset will be all the things that were in split IDX 0, and the first subset", "tokens": [407, 11, 264, 44746, 900, 25993, 486, 312, 439, 264, 721, 300, 645, 294, 7472, 7348, 55, 1958, 11, 293, 264, 700, 25993], "temperature": 0.0, "avg_logprob": -0.1939098272430763, "compression_ratio": 1.6589595375722543, "no_speech_prob": 5.173831141291885e-06}, {"id": 130, "seek": 89464, "start": 904.72, "end": 908.08, "text": " will be all the things in split IDX 1.", "tokens": [486, 312, 439, 264, 721, 294, 7472, 7348, 55, 502, 13], "temperature": 0.0, "avg_logprob": -0.1939098272430763, "compression_ratio": 1.6589595375722543, "no_speech_prob": 5.173831141291885e-06}, {"id": 131, "seek": 89464, "start": 908.08, "end": 914.28, "text": " So, in other words, pets.subset1 is the validation set.", "tokens": [407, 11, 294, 661, 2283, 11, 19897, 13, 30131, 3854, 16, 307, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.1939098272430763, "compression_ratio": 1.6589595375722543, "no_speech_prob": 5.173831141291885e-06}, {"id": 132, "seek": 89464, "start": 914.28, "end": 918.08, "text": " And so, there is indeed a shortcut for that, which is pets.valid.", "tokens": [400, 370, 11, 456, 307, 6451, 257, 24822, 337, 300, 11, 597, 307, 19897, 13, 3337, 327, 13], "temperature": 0.0, "avg_logprob": -0.1939098272430763, "compression_ratio": 1.6589595375722543, "no_speech_prob": 5.173831141291885e-06}, {"id": 133, "seek": 91808, "start": 918.08, "end": 924.96, "text": " So, you'll find that there is a pets.valid.", "tokens": [407, 11, 291, 603, 915, 300, 456, 307, 257, 19897, 13, 3337, 327, 13], "temperature": 0.0, "avg_logprob": -0.19657874474158654, "compression_ratio": 1.3691275167785235, "no_speech_prob": 1.459368149880902e-06}, {"id": 134, "seek": 91808, "start": 924.96, "end": 931.2800000000001, "text": " Hi, Joseph.", "tokens": [2421, 11, 11170, 13], "temperature": 0.0, "avg_logprob": -0.19657874474158654, "compression_ratio": 1.3691275167785235, "no_speech_prob": 1.459368149880902e-06}, {"id": 135, "seek": 91808, "start": 931.2800000000001, "end": 935.48, "text": " Just to remind you again, if you have bugs in the code, please ask on the forums, not", "tokens": [1449, 281, 4160, 291, 797, 11, 498, 291, 362, 15120, 294, 264, 3089, 11, 1767, 1029, 322, 264, 26998, 11, 406], "temperature": 0.0, "avg_logprob": -0.19657874474158654, "compression_ratio": 1.3691275167785235, "no_speech_prob": 1.459368149880902e-06}, {"id": 136, "seek": 91808, "start": 935.48, "end": 940.32, "text": " on the live chat, because I won't be able to answer them here.", "tokens": [322, 264, 1621, 5081, 11, 570, 286, 1582, 380, 312, 1075, 281, 1867, 552, 510, 13], "temperature": 0.0, "avg_logprob": -0.19657874474158654, "compression_ratio": 1.3691275167785235, "no_speech_prob": 1.459368149880902e-06}, {"id": 137, "seek": 94032, "start": 940.32, "end": 948.22, "text": " So, the validation set, for example, and the training set, for example.", "tokens": [407, 11, 264, 24071, 992, 11, 337, 1365, 11, 293, 264, 3097, 992, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.12171922881027748, "compression_ratio": 1.8709677419354838, "no_speech_prob": 3.905400262738112e-06}, {"id": 138, "seek": 94032, "start": 948.22, "end": 958.6, "text": " And so, pets.valid is exactly the same as pets.subset1.", "tokens": [400, 370, 11, 19897, 13, 3337, 327, 307, 2293, 264, 912, 382, 19897, 13, 30131, 3854, 16, 13], "temperature": 0.0, "avg_logprob": -0.12171922881027748, "compression_ratio": 1.8709677419354838, "no_speech_prob": 3.905400262738112e-06}, {"id": 139, "seek": 94032, "start": 958.6, "end": 961.1600000000001, "text": " And the training set is exactly the same as pets.subset0.", "tokens": [400, 264, 3097, 992, 307, 2293, 264, 912, 382, 19897, 13, 30131, 3854, 15, 13], "temperature": 0.0, "avg_logprob": -0.12171922881027748, "compression_ratio": 1.8709677419354838, "no_speech_prob": 3.905400262738112e-06}, {"id": 140, "seek": 94032, "start": 961.1600000000001, "end": 969.12, "text": " So, one of the nice things here is that we're not just limited to just a train set and a", "tokens": [407, 11, 472, 295, 264, 1481, 721, 510, 307, 300, 321, 434, 406, 445, 5567, 281, 445, 257, 3847, 992, 293, 257], "temperature": 0.0, "avg_logprob": -0.12171922881027748, "compression_ratio": 1.8709677419354838, "no_speech_prob": 3.905400262738112e-06}, {"id": 141, "seek": 94032, "start": 969.12, "end": 970.12, "text": " validation set.", "tokens": [24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.12171922881027748, "compression_ratio": 1.8709677419354838, "no_speech_prob": 3.905400262738112e-06}, {"id": 142, "seek": 97012, "start": 970.12, "end": 973.04, "text": " You can actually have as many data sets as you like.", "tokens": [509, 393, 767, 362, 382, 867, 1412, 6352, 382, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.2833110119434113, "compression_ratio": 1.5339805825242718, "no_speech_prob": 1.0952263437502552e-05}, {"id": 143, "seek": 97012, "start": 973.04, "end": 974.84, "text": " You can have multiple validation sets.", "tokens": [509, 393, 362, 3866, 24071, 6352, 13], "temperature": 0.0, "avg_logprob": -0.2833110119434113, "compression_ratio": 1.5339805825242718, "no_speech_prob": 1.0952263437502552e-05}, {"id": 144, "seek": 97012, "start": 974.84, "end": 977.32, "text": " You can include a test set and so forth.", "tokens": [509, 393, 4090, 257, 1500, 992, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.2833110119434113, "compression_ratio": 1.5339805825242718, "no_speech_prob": 1.0952263437502552e-05}, {"id": 145, "seek": 97012, "start": 977.32, "end": 983.76, "text": " So, it's kind of a bit more flexible here than fast.ai.v1.", "tokens": [407, 11, 309, 311, 733, 295, 257, 857, 544, 11358, 510, 813, 2370, 13, 1301, 13, 85, 16, 13], "temperature": 0.0, "avg_logprob": -0.2833110119434113, "compression_ratio": 1.5339805825242718, "no_speech_prob": 1.0952263437502552e-05}, {"id": 146, "seek": 97012, "start": 983.76, "end": 985.8, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2833110119434113, "compression_ratio": 1.5339805825242718, "no_speech_prob": 1.0952263437502552e-05}, {"id": 147, "seek": 97012, "start": 985.8, "end": 988.72, "text": " So, now we've got something.", "tokens": [407, 11, 586, 321, 600, 658, 746, 13], "temperature": 0.0, "avg_logprob": -0.2833110119434113, "compression_ratio": 1.5339805825242718, "no_speech_prob": 1.0952263437502552e-05}, {"id": 148, "seek": 97012, "start": 988.72, "end": 996.32, "text": " So, basically, these training and validation sets act pretty much exactly like a tiffMDS.", "tokens": [407, 11, 1936, 11, 613, 3097, 293, 24071, 6352, 605, 1238, 709, 2293, 411, 257, 256, 3661, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.2833110119434113, "compression_ratio": 1.5339805825242718, "no_speech_prob": 1.0952263437502552e-05}, {"id": 149, "seek": 99632, "start": 996.32, "end": 1002.72, "text": " The type is something, is in fact a tiffMDS, as you can see.", "tokens": [440, 2010, 307, 746, 11, 307, 294, 1186, 257, 256, 3661, 44, 11844, 11, 382, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.30487278529575895, "compression_ratio": 1.4532374100719425, "no_speech_prob": 5.507510195457144e-06}, {"id": 150, "seek": 99632, "start": 1002.72, "end": 1008.32, "text": " So, that makes it nice and easy.", "tokens": [407, 11, 300, 1669, 309, 1481, 293, 1858, 13], "temperature": 0.0, "avg_logprob": -0.30487278529575895, "compression_ratio": 1.4532374100719425, "no_speech_prob": 5.507510195457144e-06}, {"id": 151, "seek": 99632, "start": 1008.32, "end": 1010.32, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.30487278529575895, "compression_ratio": 1.4532374100719425, "no_speech_prob": 5.507510195457144e-06}, {"id": 152, "seek": 99632, "start": 1010.32, "end": 1016.12, "text": " So, because these things are just tiffMDSs, you can decode them just like before, as you", "tokens": [407, 11, 570, 613, 721, 366, 445, 256, 3661, 44, 11844, 82, 11, 291, 393, 979, 1429, 552, 445, 411, 949, 11, 382, 291], "temperature": 0.0, "avg_logprob": -0.30487278529575895, "compression_ratio": 1.4532374100719425, "no_speech_prob": 5.507510195457144e-06}, {"id": 153, "seek": 99632, "start": 1016.12, "end": 1022.44, "text": " can see.", "tokens": [393, 536, 13], "temperature": 0.0, "avg_logprob": -0.30487278529575895, "compression_ratio": 1.4532374100719425, "no_speech_prob": 5.507510195457144e-06}, {"id": 154, "seek": 102244, "start": 1022.44, "end": 1027.56, "text": " And yeah, we can show them just like before.", "tokens": [400, 1338, 11, 321, 393, 855, 552, 445, 411, 949, 13], "temperature": 0.0, "avg_logprob": -0.21127180151037267, "compression_ratio": 1.4751381215469612, "no_speech_prob": 2.332035819563316e-06}, {"id": 155, "seek": 102244, "start": 1027.56, "end": 1039.56, "text": " So, here is something even more interesting, which is we've seen already tiffMDL after", "tokens": [407, 11, 510, 307, 746, 754, 544, 1880, 11, 597, 307, 321, 600, 1612, 1217, 256, 3661, 44, 35, 43, 934], "temperature": 0.0, "avg_logprob": -0.21127180151037267, "compression_ratio": 1.4751381215469612, "no_speech_prob": 2.332035819563316e-06}, {"id": 156, "seek": 102244, "start": 1039.56, "end": 1040.56, "text": " item.", "tokens": [3174, 13], "temperature": 0.0, "avg_logprob": -0.21127180151037267, "compression_ratio": 1.4751381215469612, "no_speech_prob": 2.332035819563316e-06}, {"id": 157, "seek": 102244, "start": 1040.56, "end": 1049.68, "text": " That's going to run, that's going to be a transform that runs on each individual tuple", "tokens": [663, 311, 516, 281, 1190, 11, 300, 311, 516, 281, 312, 257, 4088, 300, 6676, 322, 1184, 2609, 2604, 781], "temperature": 0.0, "avg_logprob": -0.21127180151037267, "compression_ratio": 1.4751381215469612, "no_speech_prob": 2.332035819563316e-06}, {"id": 158, "seek": 102244, "start": 1049.68, "end": 1052.04, "text": " that comes out of the transform pipelines.", "tokens": [300, 1487, 484, 295, 264, 4088, 40168, 13], "temperature": 0.0, "avg_logprob": -0.21127180151037267, "compression_ratio": 1.4751381215469612, "no_speech_prob": 2.332035819563316e-06}, {"id": 159, "seek": 105204, "start": 1052.04, "end": 1059.76, "text": " But then there's another one called afterBatch, and that's going to run after the tuples have", "tokens": [583, 550, 456, 311, 1071, 472, 1219, 934, 33, 852, 11, 293, 300, 311, 516, 281, 1190, 934, 264, 2604, 2622, 362], "temperature": 0.0, "avg_logprob": -0.16983778723354997, "compression_ratio": 1.6467661691542288, "no_speech_prob": 1.1365558520992636e-06}, {"id": 160, "seek": 105204, "start": 1059.76, "end": 1064.68, "text": " been collated together by the PyTorch data loader into a single batch.", "tokens": [668, 1263, 770, 1214, 538, 264, 9953, 51, 284, 339, 1412, 3677, 260, 666, 257, 2167, 15245, 13], "temperature": 0.0, "avg_logprob": -0.16983778723354997, "compression_ratio": 1.6467661691542288, "no_speech_prob": 1.1365558520992636e-06}, {"id": 161, "seek": 105204, "start": 1064.68, "end": 1072.48, "text": " And what that means is that we can put transforms in here that we can run on a whole batch at", "tokens": [400, 437, 300, 1355, 307, 300, 321, 393, 829, 35592, 294, 510, 300, 321, 393, 1190, 322, 257, 1379, 15245, 412], "temperature": 0.0, "avg_logprob": -0.16983778723354997, "compression_ratio": 1.6467661691542288, "no_speech_prob": 1.1365558520992636e-06}, {"id": 162, "seek": 105204, "start": 1072.48, "end": 1078.96, "text": " a time, and that means we have the ability to easily run GPU transforms.", "tokens": [257, 565, 11, 293, 300, 1355, 321, 362, 264, 3485, 281, 3612, 1190, 18407, 35592, 13], "temperature": 0.0, "avg_logprob": -0.16983778723354997, "compression_ratio": 1.6467661691542288, "no_speech_prob": 1.1365558520992636e-06}, {"id": 163, "seek": 107896, "start": 1078.96, "end": 1085.24, "text": " So, in this case, the most obvious GPU transform to do, of course, or the most obvious batch", "tokens": [407, 11, 294, 341, 1389, 11, 264, 881, 6322, 18407, 4088, 281, 360, 11, 295, 1164, 11, 420, 264, 881, 6322, 15245], "temperature": 0.0, "avg_logprob": -0.10950859591492221, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6425504984217696e-06}, {"id": 164, "seek": 107896, "start": 1085.24, "end": 1092.56, "text": " transform to do is CUDA, which will simply move it onto the GPU, if you have one.", "tokens": [4088, 281, 360, 307, 29777, 7509, 11, 597, 486, 2935, 1286, 309, 3911, 264, 18407, 11, 498, 291, 362, 472, 13], "temperature": 0.0, "avg_logprob": -0.10950859591492221, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6425504984217696e-06}, {"id": 165, "seek": 107896, "start": 1092.56, "end": 1096.6000000000001, "text": " And then we can convert it from byte to float on the GPU.", "tokens": [400, 550, 321, 393, 7620, 309, 490, 40846, 281, 15706, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.10950859591492221, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6425504984217696e-06}, {"id": 166, "seek": 107896, "start": 1096.6000000000001, "end": 1101.6000000000001, "text": " Now that might seem like a pretty minor thing, but actually converting a byte to a float", "tokens": [823, 300, 1062, 1643, 411, 257, 1238, 6696, 551, 11, 457, 767, 29942, 257, 40846, 281, 257, 15706], "temperature": 0.0, "avg_logprob": -0.10950859591492221, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6425504984217696e-06}, {"id": 167, "seek": 107896, "start": 1101.6000000000001, "end": 1104.04, "text": " is really slow for two reasons.", "tokens": [307, 534, 2964, 337, 732, 4112, 13], "temperature": 0.0, "avg_logprob": -0.10950859591492221, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6425504984217696e-06}, {"id": 168, "seek": 107896, "start": 1104.04, "end": 1108.1200000000001, "text": " The first is that floats are much bigger than bytes, so it's taking up a lot of memory to", "tokens": [440, 700, 307, 300, 37878, 366, 709, 3801, 813, 36088, 11, 370, 309, 311, 1940, 493, 257, 688, 295, 4675, 281], "temperature": 0.0, "avg_logprob": -0.10950859591492221, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6425504984217696e-06}, {"id": 169, "seek": 110812, "start": 1108.12, "end": 1110.52, "text": " transfer it to your GPU as floats.", "tokens": [5003, 309, 281, 428, 18407, 382, 37878, 13], "temperature": 0.0, "avg_logprob": -0.1305360994840923, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.173846147954464e-06}, {"id": 170, "seek": 110812, "start": 1110.52, "end": 1114.56, "text": " And the second is that converting from a byte to a float actually takes a non-trivial amount", "tokens": [400, 264, 1150, 307, 300, 29942, 490, 257, 40846, 281, 257, 15706, 767, 2516, 257, 2107, 12, 83, 470, 22640, 2372], "temperature": 0.0, "avg_logprob": -0.1305360994840923, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.173846147954464e-06}, {"id": 171, "seek": 110812, "start": 1114.56, "end": 1116.4799999999998, "text": " of time on the CPU.", "tokens": [295, 565, 322, 264, 13199, 13], "temperature": 0.0, "avg_logprob": -0.1305360994840923, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.173846147954464e-06}, {"id": 172, "seek": 110812, "start": 1116.4799999999998, "end": 1118.12, "text": " It actually is quite...", "tokens": [467, 767, 307, 1596, 485], "temperature": 0.0, "avg_logprob": -0.1305360994840923, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.173846147954464e-06}, {"id": 173, "seek": 110812, "start": 1118.12, "end": 1122.76, "text": " It does actually take up quite a lot of time.", "tokens": [467, 775, 767, 747, 493, 1596, 257, 688, 295, 565, 13], "temperature": 0.0, "avg_logprob": -0.1305360994840923, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.173846147954464e-06}, {"id": 174, "seek": 110812, "start": 1122.76, "end": 1128.6799999999998, "text": " So here's the first example of something that was very, very hard to do before, which is", "tokens": [407, 510, 311, 264, 700, 1365, 295, 746, 300, 390, 588, 11, 588, 1152, 281, 360, 949, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.1305360994840923, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.173846147954464e-06}, {"id": 175, "seek": 110812, "start": 1128.6799999999998, "end": 1132.3999999999999, "text": " to actually do computation on the GPU.", "tokens": [281, 767, 360, 24903, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.1305360994840923, "compression_ratio": 1.5972222222222223, "no_speech_prob": 5.173846147954464e-06}, {"id": 176, "seek": 113240, "start": 1132.4, "end": 1141.68, "text": " And the nice thing is that we just use the GPU transforms often don't even need to be", "tokens": [400, 264, 1481, 551, 307, 300, 321, 445, 764, 264, 18407, 35592, 2049, 500, 380, 754, 643, 281, 312], "temperature": 0.0, "avg_logprob": -0.15844028179462138, "compression_ratio": 1.3652694610778444, "no_speech_prob": 7.811387945366732e-07}, {"id": 177, "seek": 113240, "start": 1141.68, "end": 1142.96, "text": " written in a different way.", "tokens": [3720, 294, 257, 819, 636, 13], "temperature": 0.0, "avg_logprob": -0.15844028179462138, "compression_ratio": 1.3652694610778444, "no_speech_prob": 7.811387945366732e-07}, {"id": 178, "seek": 113240, "start": 1142.96, "end": 1151.8400000000001, "text": " So if you look at byte to float tensor, for instance, you can see that encodes simply", "tokens": [407, 498, 291, 574, 412, 40846, 281, 15706, 40863, 11, 337, 5197, 11, 291, 393, 536, 300, 2058, 4789, 2935], "temperature": 0.0, "avg_logprob": -0.15844028179462138, "compression_ratio": 1.3652694610778444, "no_speech_prob": 7.811387945366732e-07}, {"id": 179, "seek": 113240, "start": 1151.8400000000001, "end": 1156.8000000000002, "text": " goes O.float divided by 255.", "tokens": [1709, 422, 13, 43645, 267, 6666, 538, 3552, 20, 13], "temperature": 0.0, "avg_logprob": -0.15844028179462138, "compression_ratio": 1.3652694610778444, "no_speech_prob": 7.811387945366732e-07}, {"id": 180, "seek": 115680, "start": 1156.8, "end": 1163.08, "text": " So thanks to kind of broadcast tensor computations and stuff, we don't normally have to write", "tokens": [407, 3231, 281, 733, 295, 9975, 40863, 2807, 763, 293, 1507, 11, 321, 500, 380, 5646, 362, 281, 2464], "temperature": 0.0, "avg_logprob": -0.08873116826436606, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.122835204929288e-07}, {"id": 181, "seek": 115680, "start": 1163.08, "end": 1168.6599999999999, "text": " it at all differently to make it work at a batch level.", "tokens": [309, 412, 439, 7614, 281, 652, 309, 589, 412, 257, 15245, 1496, 13], "temperature": 0.0, "avg_logprob": -0.08873116826436606, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.122835204929288e-07}, {"id": 182, "seek": 115680, "start": 1168.6599999999999, "end": 1174.68, "text": " So often you'll be able to just transparently move your transformations onto the GPU, and", "tokens": [407, 2049, 291, 603, 312, 1075, 281, 445, 7132, 6420, 1286, 428, 34852, 3911, 264, 18407, 11, 293], "temperature": 0.0, "avg_logprob": -0.08873116826436606, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.122835204929288e-07}, {"id": 183, "seek": 115680, "start": 1174.68, "end": 1177.12, "text": " suddenly things will just run much faster.", "tokens": [5800, 721, 486, 445, 1190, 709, 4663, 13], "temperature": 0.0, "avg_logprob": -0.08873116826436606, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.122835204929288e-07}, {"id": 184, "seek": 115680, "start": 1177.12, "end": 1181.12, "text": " So I think that's one of the pretty exciting things here.", "tokens": [407, 286, 519, 300, 311, 472, 295, 264, 1238, 4670, 721, 510, 13], "temperature": 0.0, "avg_logprob": -0.08873116826436606, "compression_ratio": 1.5454545454545454, "no_speech_prob": 5.122835204929288e-07}, {"id": 185, "seek": 118112, "start": 1181.12, "end": 1186.76, "text": " So now we're getting pretty close to having something which looks like what you would", "tokens": [407, 586, 321, 434, 1242, 1238, 1998, 281, 1419, 746, 597, 1542, 411, 437, 291, 576], "temperature": 0.0, "avg_logprob": -0.09704150183726165, "compression_ratio": 1.4906832298136645, "no_speech_prob": 1.2679051906161476e-06}, {"id": 186, "seek": 118112, "start": 1186.76, "end": 1189.1999999999998, "text": " actually train with.", "tokens": [767, 3847, 365, 13], "temperature": 0.0, "avg_logprob": -0.09704150183726165, "compression_ratio": 1.4906832298136645, "no_speech_prob": 1.2679051906161476e-06}, {"id": 187, "seek": 118112, "start": 1189.1999999999998, "end": 1198.4799999999998, "text": " It's something which is categorizing our pet types.", "tokens": [467, 311, 746, 597, 307, 19250, 3319, 527, 3817, 3467, 13], "temperature": 0.0, "avg_logprob": -0.09704150183726165, "compression_ratio": 1.4906832298136645, "no_speech_prob": 1.2679051906161476e-06}, {"id": 188, "seek": 118112, "start": 1198.4799999999998, "end": 1201.6799999999998, "text": " We have separate training and validation sets.", "tokens": [492, 362, 4994, 3097, 293, 24071, 6352, 13], "temperature": 0.0, "avg_logprob": -0.09704150183726165, "compression_ratio": 1.4906832298136645, "no_speech_prob": 1.2679051906161476e-06}, {"id": 189, "seek": 118112, "start": 1201.6799999999998, "end": 1206.2399999999998, "text": " It's converting them into batches.", "tokens": [467, 311, 29942, 552, 666, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.09704150183726165, "compression_ratio": 1.4906832298136645, "no_speech_prob": 1.2679051906161476e-06}, {"id": 190, "seek": 120624, "start": 1206.24, "end": 1214.36, "text": " And we can even go trainDL.showBatch, and it will actually give us a full set of these.", "tokens": [400, 321, 393, 754, 352, 3847, 35, 43, 13, 34436, 33, 852, 11, 293, 309, 486, 767, 976, 505, 257, 1577, 992, 295, 613, 13], "temperature": 0.0, "avg_logprob": -0.1392523125757145, "compression_ratio": 1.5136612021857923, "no_speech_prob": 3.5558980471250834e-06}, {"id": 191, "seek": 120624, "start": 1214.36, "end": 1218.36, "text": " So this is kind of really getting everything together nicely.", "tokens": [407, 341, 307, 733, 295, 534, 1242, 1203, 1214, 9594, 13], "temperature": 0.0, "avg_logprob": -0.1392523125757145, "compression_ratio": 1.5136612021857923, "no_speech_prob": 3.5558980471250834e-06}, {"id": 192, "seek": 120624, "start": 1218.36, "end": 1232.32, "text": " One of the very neat subtleties of data source is that data source, well, it's not really", "tokens": [1485, 295, 264, 588, 10654, 7257, 2631, 530, 295, 1412, 4009, 307, 300, 1412, 4009, 11, 731, 11, 309, 311, 406, 534], "temperature": 0.0, "avg_logprob": -0.1392523125757145, "compression_ratio": 1.5136612021857923, "no_speech_prob": 3.5558980471250834e-06}, {"id": 193, "seek": 120624, "start": 1232.32, "end": 1233.32, "text": " data source.", "tokens": [1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.1392523125757145, "compression_ratio": 1.5136612021857923, "no_speech_prob": 3.5558980471250834e-06}, {"id": 194, "seek": 120624, "start": 1233.32, "end": 1235.0, "text": " It's really categorized.", "tokens": [467, 311, 534, 19250, 1602, 13], "temperature": 0.0, "avg_logprob": -0.1392523125757145, "compression_ratio": 1.5136612021857923, "no_speech_prob": 3.5558980471250834e-06}, {"id": 195, "seek": 123500, "start": 1235.0, "end": 1247.04, "text": " So we're using categorize here.", "tokens": [407, 321, 434, 1228, 19250, 1125, 510, 13], "temperature": 0.0, "avg_logprob": -0.11715353271107615, "compression_ratio": 1.5561224489795917, "no_speech_prob": 1.9637911918835016e-06}, {"id": 196, "seek": 123500, "start": 1247.04, "end": 1252.52, "text": " And what happens, we'll learn more about this shortly, but what happens when pipeline first", "tokens": [400, 437, 2314, 11, 321, 603, 1466, 544, 466, 341, 13392, 11, 457, 437, 2314, 562, 15517, 700], "temperature": 0.0, "avg_logprob": -0.11715353271107615, "compression_ratio": 1.5561224489795917, "no_speech_prob": 1.9637911918835016e-06}, {"id": 197, "seek": 123500, "start": 1252.52, "end": 1257.56, "text": " gets its data source is it calls a special method in a transform called setup, if you", "tokens": [2170, 1080, 1412, 4009, 307, 309, 5498, 257, 2121, 3170, 294, 257, 4088, 1219, 8657, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.11715353271107615, "compression_ratio": 1.5561224489795917, "no_speech_prob": 1.9637911918835016e-06}, {"id": 198, "seek": 123500, "start": 1257.56, "end": 1258.96, "text": " have one.", "tokens": [362, 472, 13], "temperature": 0.0, "avg_logprob": -0.11715353271107615, "compression_ratio": 1.5561224489795917, "no_speech_prob": 1.9637911918835016e-06}, {"id": 199, "seek": 123500, "start": 1258.96, "end": 1263.96, "text": " And you can see here that what we actually do is we try to grab, if there is one, the", "tokens": [400, 291, 393, 536, 510, 300, 437, 321, 767, 360, 307, 321, 853, 281, 4444, 11, 498, 456, 307, 472, 11, 264], "temperature": 0.0, "avg_logprob": -0.11715353271107615, "compression_ratio": 1.5561224489795917, "no_speech_prob": 1.9637911918835016e-06}, {"id": 200, "seek": 126396, "start": 1263.96, "end": 1267.64, "text": " training subset of the data source.", "tokens": [3097, 25993, 295, 264, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.169864042305652, "compression_ratio": 1.6, "no_speech_prob": 3.393112820049282e-06}, {"id": 201, "seek": 126396, "start": 1267.64, "end": 1275.6000000000001, "text": " So one of the cool things here is that automatically this stuff will ensure that your categories", "tokens": [407, 472, 295, 264, 1627, 721, 510, 307, 300, 6772, 341, 1507, 486, 5586, 300, 428, 10479], "temperature": 0.0, "avg_logprob": -0.169864042305652, "compression_ratio": 1.6, "no_speech_prob": 3.393112820049282e-06}, {"id": 202, "seek": 126396, "start": 1275.6000000000001, "end": 1280.2, "text": " vocab is only done on the training set.", "tokens": [2329, 455, 307, 787, 1096, 322, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.169864042305652, "compression_ratio": 1.6, "no_speech_prob": 3.393112820049282e-06}, {"id": 203, "seek": 126396, "start": 1280.2, "end": 1285.44, "text": " So these are the kind of things that are very easy to mess up.", "tokens": [407, 613, 366, 264, 733, 295, 721, 300, 366, 588, 1858, 281, 2082, 493, 13], "temperature": 0.0, "avg_logprob": -0.169864042305652, "compression_ratio": 1.6, "no_speech_prob": 3.393112820049282e-06}, {"id": 204, "seek": 126396, "start": 1285.44, "end": 1287.96, "text": " So the questions here, does byte to float normalize?", "tokens": [407, 264, 1651, 510, 11, 775, 40846, 281, 15706, 2710, 1125, 30], "temperature": 0.0, "avg_logprob": -0.169864042305652, "compression_ratio": 1.6, "no_speech_prob": 3.393112820049282e-06}, {"id": 205, "seek": 126396, "start": 1287.96, "end": 1288.96, "text": " No, it doesn't.", "tokens": [883, 11, 309, 1177, 380, 13], "temperature": 0.0, "avg_logprob": -0.169864042305652, "compression_ratio": 1.6, "no_speech_prob": 3.393112820049282e-06}, {"id": 206, "seek": 128896, "start": 1288.96, "end": 1294.28, "text": " As you'll see, there is a separate normalize function.", "tokens": [1018, 291, 603, 536, 11, 456, 307, 257, 4994, 2710, 1125, 2445, 13], "temperature": 0.0, "avg_logprob": -0.18600224256515502, "compression_ratio": 1.4583333333333333, "no_speech_prob": 7.183150046330411e-06}, {"id": 207, "seek": 128896, "start": 1294.28, "end": 1302.16, "text": " However, it does have a, oops, byte to float tensor.", "tokens": [2908, 11, 309, 775, 362, 257, 11, 34166, 11, 40846, 281, 15706, 40863, 13], "temperature": 0.0, "avg_logprob": -0.18600224256515502, "compression_ratio": 1.4583333333333333, "no_speech_prob": 7.183150046330411e-06}, {"id": 208, "seek": 128896, "start": 1302.16, "end": 1307.16, "text": " It does have an optional div argument, which will divide it by 255.", "tokens": [467, 775, 362, 364, 17312, 3414, 6770, 11, 597, 486, 9845, 309, 538, 3552, 20, 13], "temperature": 0.0, "avg_logprob": -0.18600224256515502, "compression_ratio": 1.4583333333333333, "no_speech_prob": 7.183150046330411e-06}, {"id": 209, "seek": 128896, "start": 1307.16, "end": 1308.72, "text": " So that'll give you between zero and one.", "tokens": [407, 300, 603, 976, 291, 1296, 4018, 293, 472, 13], "temperature": 0.0, "avg_logprob": -0.18600224256515502, "compression_ratio": 1.4583333333333333, "no_speech_prob": 7.183150046330411e-06}, {"id": 210, "seek": 128896, "start": 1308.72, "end": 1312.04, "text": " So not quite normalized, but at least it's on the right track.", "tokens": [407, 406, 1596, 48704, 11, 457, 412, 1935, 309, 311, 322, 264, 558, 2837, 13], "temperature": 0.0, "avg_logprob": -0.18600224256515502, "compression_ratio": 1.4583333333333333, "no_speech_prob": 7.183150046330411e-06}, {"id": 211, "seek": 131204, "start": 1312.04, "end": 1321.0, "text": " But yeah, there's also, as we'll see later, a normalize transform.", "tokens": [583, 1338, 11, 456, 311, 611, 11, 382, 321, 603, 536, 1780, 11, 257, 2710, 1125, 4088, 13], "temperature": 0.0, "avg_logprob": -0.15805886300762048, "compression_ratio": 1.6381909547738693, "no_speech_prob": 2.026092033702298e-06}, {"id": 212, "seek": 131204, "start": 1321.0, "end": 1324.44, "text": " Text transformations are rarely done lazily.", "tokens": [18643, 34852, 366, 13752, 1096, 19320, 953, 13], "temperature": 0.0, "avg_logprob": -0.15805886300762048, "compression_ratio": 1.6381909547738693, "no_speech_prob": 2.026092033702298e-06}, {"id": 213, "seek": 131204, "start": 1324.44, "end": 1327.96, "text": " They're normally done once pre-processing style.", "tokens": [814, 434, 5646, 1096, 1564, 659, 12, 41075, 278, 3758, 13], "temperature": 0.0, "avg_logprob": -0.15805886300762048, "compression_ratio": 1.6381909547738693, "no_speech_prob": 2.026092033702298e-06}, {"id": 214, "seek": 131204, "start": 1327.96, "end": 1334.44, "text": " So they're not generally a great, so kind of such a good match for the GPU.", "tokens": [407, 436, 434, 406, 5101, 257, 869, 11, 370, 733, 295, 1270, 257, 665, 2995, 337, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.15805886300762048, "compression_ratio": 1.6381909547738693, "no_speech_prob": 2.026092033702298e-06}, {"id": 215, "seek": 131204, "start": 1334.44, "end": 1338.04, "text": " But if there are, there's nothing to stop you from doing text transformations on the", "tokens": [583, 498, 456, 366, 11, 456, 311, 1825, 281, 1590, 291, 490, 884, 2487, 34852, 322, 264], "temperature": 0.0, "avg_logprob": -0.15805886300762048, "compression_ratio": 1.6381909547738693, "no_speech_prob": 2.026092033702298e-06}, {"id": 216, "seek": 131204, "start": 1338.04, "end": 1339.04, "text": " GPU.", "tokens": [18407, 13], "temperature": 0.0, "avg_logprob": -0.15805886300762048, "compression_ratio": 1.6381909547738693, "no_speech_prob": 2.026092033702298e-06}, {"id": 217, "seek": 133904, "start": 1339.04, "end": 1344.6399999999999, "text": " But as you'll see, we've actually, text transformations are a lot faster now anyway.", "tokens": [583, 382, 291, 603, 536, 11, 321, 600, 767, 11, 2487, 34852, 366, 257, 688, 4663, 586, 4033, 13], "temperature": 0.0, "avg_logprob": -0.12565533749692076, "compression_ratio": 1.6909871244635193, "no_speech_prob": 3.726589739017072e-06}, {"id": 218, "seek": 133904, "start": 1344.6399999999999, "end": 1348.04, "text": " And then any reason we don't do all transforms on GPU.", "tokens": [400, 550, 604, 1778, 321, 500, 380, 360, 439, 35592, 322, 18407, 13], "temperature": 0.0, "avg_logprob": -0.12565533749692076, "compression_ratio": 1.6909871244635193, "no_speech_prob": 3.726589739017072e-06}, {"id": 219, "seek": 133904, "start": 1348.04, "end": 1351.3999999999999, "text": " Yes, there is, Molly.", "tokens": [1079, 11, 456, 307, 11, 26665, 13], "temperature": 0.0, "avg_logprob": -0.12565533749692076, "compression_ratio": 1.6909871244635193, "no_speech_prob": 3.726589739017072e-06}, {"id": 220, "seek": 133904, "start": 1351.3999999999999, "end": 1353.68, "text": " The issue is basically, and that's a great question.", "tokens": [440, 2734, 307, 1936, 11, 293, 300, 311, 257, 869, 1168, 13], "temperature": 0.0, "avg_logprob": -0.12565533749692076, "compression_ratio": 1.6909871244635193, "no_speech_prob": 3.726589739017072e-06}, {"id": 221, "seek": 133904, "start": 1353.68, "end": 1358.6, "text": " The issue is basically, have a look here.", "tokens": [440, 2734, 307, 1936, 11, 362, 257, 574, 510, 13], "temperature": 0.0, "avg_logprob": -0.12565533749692076, "compression_ratio": 1.6909871244635193, "no_speech_prob": 3.726589739017072e-06}, {"id": 222, "seek": 133904, "start": 1358.6, "end": 1364.3, "text": " If you want to be able to easily process things on the GPU, then you need a batch.", "tokens": [759, 291, 528, 281, 312, 1075, 281, 3612, 1399, 721, 322, 264, 18407, 11, 550, 291, 643, 257, 15245, 13], "temperature": 0.0, "avg_logprob": -0.12565533749692076, "compression_ratio": 1.6909871244635193, "no_speech_prob": 3.726589739017072e-06}, {"id": 223, "seek": 133904, "start": 1364.3, "end": 1367.68, "text": " And if you have a batch, that means you need a tensor.", "tokens": [400, 498, 291, 362, 257, 15245, 11, 300, 1355, 291, 643, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.12565533749692076, "compression_ratio": 1.6909871244635193, "no_speech_prob": 3.726589739017072e-06}, {"id": 224, "seek": 136768, "start": 1367.68, "end": 1370.76, "text": " But if you have a tensor, that means that all of the items in the batch have to have", "tokens": [583, 498, 291, 362, 257, 40863, 11, 300, 1355, 300, 439, 295, 264, 4754, 294, 264, 15245, 362, 281, 362], "temperature": 0.0, "avg_logprob": -0.11146193592488265, "compression_ratio": 1.749003984063745, "no_speech_prob": 7.766770977468695e-06}, {"id": 225, "seek": 136768, "start": 1370.76, "end": 1372.24, "text": " the same shape.", "tokens": [264, 912, 3909, 13], "temperature": 0.0, "avg_logprob": -0.11146193592488265, "compression_ratio": 1.749003984063745, "no_speech_prob": 7.766770977468695e-06}, {"id": 226, "seek": 136768, "start": 1372.24, "end": 1377.3400000000001, "text": " So if we didn't have this image resizer here, then the images would all be different shapes.", "tokens": [407, 498, 321, 994, 380, 362, 341, 3256, 725, 6545, 510, 11, 550, 264, 5267, 576, 439, 312, 819, 10854, 13], "temperature": 0.0, "avg_logprob": -0.11146193592488265, "compression_ratio": 1.749003984063745, "no_speech_prob": 7.766770977468695e-06}, {"id": 227, "seek": 136768, "start": 1377.3400000000001, "end": 1380.64, "text": " And so you wouldn't be able to collect them into a batch.", "tokens": [400, 370, 291, 2759, 380, 312, 1075, 281, 2500, 552, 666, 257, 15245, 13], "temperature": 0.0, "avg_logprob": -0.11146193592488265, "compression_ratio": 1.749003984063745, "no_speech_prob": 7.766770977468695e-06}, {"id": 228, "seek": 136768, "start": 1380.64, "end": 1388.8, "text": " So specifically, the things that you probably want to do on the CPU are load the JPEG in", "tokens": [407, 4682, 11, 264, 721, 300, 291, 1391, 528, 281, 360, 322, 264, 13199, 366, 3677, 264, 508, 5208, 38, 294], "temperature": 0.0, "avg_logprob": -0.11146193592488265, "compression_ratio": 1.749003984063745, "no_speech_prob": 7.766770977468695e-06}, {"id": 229, "seek": 136768, "start": 1388.8, "end": 1394.76, "text": " some way, make sure that all of the things are the same size, and then convert them into", "tokens": [512, 636, 11, 652, 988, 300, 439, 295, 264, 721, 366, 264, 912, 2744, 11, 293, 550, 7620, 552, 666], "temperature": 0.0, "avg_logprob": -0.11146193592488265, "compression_ratio": 1.749003984063745, "no_speech_prob": 7.766770977468695e-06}, {"id": 230, "seek": 136768, "start": 1394.76, "end": 1396.1200000000001, "text": " a tensor.", "tokens": [257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.11146193592488265, "compression_ratio": 1.749003984063745, "no_speech_prob": 7.766770977468695e-06}, {"id": 231, "seek": 139612, "start": 1396.12, "end": 1401.1999999999998, "text": " So those are basically the three things you have to do, at least for vision on the GPU.", "tokens": [407, 729, 366, 1936, 264, 1045, 721, 291, 362, 281, 360, 11, 412, 1935, 337, 5201, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.18571900702142097, "compression_ratio": 1.4074074074074074, "no_speech_prob": 2.684130095076398e-06}, {"id": 232, "seek": 139612, "start": 1401.1999999999998, "end": 1407.3999999999999, "text": " Sorry, on the CPU.", "tokens": [4919, 11, 322, 264, 13199, 13], "temperature": 0.0, "avg_logprob": -0.18571900702142097, "compression_ratio": 1.4074074074074074, "no_speech_prob": 2.684130095076398e-06}, {"id": 233, "seek": 139612, "start": 1407.3999999999999, "end": 1415.58, "text": " Having said that, there is a project by Nvidia called Dali, which we'll endeavor to provide", "tokens": [10222, 848, 300, 11, 456, 307, 257, 1716, 538, 46284, 1219, 413, 5103, 11, 597, 321, 603, 34975, 281, 2893], "temperature": 0.0, "avg_logprob": -0.18571900702142097, "compression_ratio": 1.4074074074074074, "no_speech_prob": 2.684130095076398e-06}, {"id": 234, "seek": 139612, "start": 1415.58, "end": 1417.04, "text": " some support for.", "tokens": [512, 1406, 337, 13], "temperature": 0.0, "avg_logprob": -0.18571900702142097, "compression_ratio": 1.4074074074074074, "no_speech_prob": 2.684130095076398e-06}, {"id": 235, "seek": 139612, "start": 1417.04, "end": 1420.8, "text": " Once it stabilizes a bit, it's still pre-release.", "tokens": [3443, 309, 11652, 5660, 257, 857, 11, 309, 311, 920, 659, 12, 265, 1122, 13], "temperature": 0.0, "avg_logprob": -0.18571900702142097, "compression_ratio": 1.4074074074074074, "no_speech_prob": 2.684130095076398e-06}, {"id": 236, "seek": 142080, "start": 1420.8, "end": 1426.72, "text": " And they've actually written the custom kernels to do stuff on things that aren't all the", "tokens": [400, 436, 600, 767, 3720, 264, 2375, 23434, 1625, 281, 360, 1507, 322, 721, 300, 3212, 380, 439, 264], "temperature": 0.0, "avg_logprob": -0.1515752260501568, "compression_ratio": 1.549800796812749, "no_speech_prob": 6.240662060008617e-06}, {"id": 237, "seek": 142080, "start": 1426.72, "end": 1428.32, "text": " same size.", "tokens": [912, 2744, 13], "temperature": 0.0, "avg_logprob": -0.1515752260501568, "compression_ratio": 1.549800796812749, "no_speech_prob": 6.240662060008617e-06}, {"id": 238, "seek": 142080, "start": 1428.32, "end": 1434.32, "text": " So there might be possibilities to do some stuff there.", "tokens": [407, 456, 1062, 312, 12178, 281, 360, 512, 1507, 456, 13], "temperature": 0.0, "avg_logprob": -0.1515752260501568, "compression_ratio": 1.549800796812749, "no_speech_prob": 6.240662060008617e-06}, {"id": 239, "seek": 142080, "start": 1434.32, "end": 1437.08, "text": " So images can absolutely be rectangular.", "tokens": [407, 5267, 393, 3122, 312, 31167, 13], "temperature": 0.0, "avg_logprob": -0.1515752260501568, "compression_ratio": 1.549800796812749, "no_speech_prob": 6.240662060008617e-06}, {"id": 240, "seek": 142080, "start": 1437.08, "end": 1438.8, "text": " It doesn't have to be 128 by 128.", "tokens": [467, 1177, 380, 362, 281, 312, 29810, 538, 29810, 13], "temperature": 0.0, "avg_logprob": -0.1515752260501568, "compression_ratio": 1.549800796812749, "no_speech_prob": 6.240662060008617e-06}, {"id": 241, "seek": 142080, "start": 1438.8, "end": 1441.8, "text": " We'll see more of that later.", "tokens": [492, 603, 536, 544, 295, 300, 1780, 13], "temperature": 0.0, "avg_logprob": -0.1515752260501568, "compression_ratio": 1.549800796812749, "no_speech_prob": 6.240662060008617e-06}, {"id": 242, "seek": 142080, "start": 1441.8, "end": 1444.3999999999999, "text": " And hopefully, I've already answered the question about what's best on the GPU.", "tokens": [400, 4696, 11, 286, 600, 1217, 10103, 264, 1168, 466, 437, 311, 1151, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.1515752260501568, "compression_ratio": 1.549800796812749, "no_speech_prob": 6.240662060008617e-06}, {"id": 243, "seek": 142080, "start": 1444.3999999999999, "end": 1450.18, "text": " I would say everything on the GPU that you can.", "tokens": [286, 576, 584, 1203, 322, 264, 18407, 300, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.1515752260501568, "compression_ratio": 1.549800796812749, "no_speech_prob": 6.240662060008617e-06}, {"id": 244, "seek": 145018, "start": 1450.18, "end": 1454.4, "text": " So I would say try to do everything on the GPU that you can.", "tokens": [407, 286, 576, 584, 853, 281, 360, 1203, 322, 264, 18407, 300, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.23849805918606845, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.76650176703697e-06}, {"id": 245, "seek": 145018, "start": 1454.4, "end": 1459.52, "text": " But specifically, turning everything into something of the same size so that they can", "tokens": [583, 4682, 11, 6246, 1203, 666, 746, 295, 264, 912, 2744, 370, 300, 436, 393], "temperature": 0.0, "avg_logprob": -0.23849805918606845, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.76650176703697e-06}, {"id": 246, "seek": 145018, "start": 1459.52, "end": 1463.1200000000001, "text": " be translated into a batch has to happen before it goes into the GPU.", "tokens": [312, 16805, 666, 257, 15245, 575, 281, 1051, 949, 309, 1709, 666, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.23849805918606845, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.76650176703697e-06}, {"id": 247, "seek": 145018, "start": 1463.1200000000001, "end": 1470.88, "text": " So that would be my rule of thumb.", "tokens": [407, 300, 576, 312, 452, 4978, 295, 9298, 13], "temperature": 0.0, "avg_logprob": -0.23849805918606845, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.76650176703697e-06}, {"id": 248, "seek": 145018, "start": 1470.88, "end": 1473.96, "text": " So let's look at another example.", "tokens": [407, 718, 311, 574, 412, 1071, 1365, 13], "temperature": 0.0, "avg_logprob": -0.23849805918606845, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.76650176703697e-06}, {"id": 249, "seek": 145018, "start": 1473.96, "end": 1474.96, "text": " There's no new things I'm going to show you.", "tokens": [821, 311, 572, 777, 721, 286, 478, 516, 281, 855, 291, 13], "temperature": 0.0, "avg_logprob": -0.23849805918606845, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.76650176703697e-06}, {"id": 250, "seek": 147496, "start": 1474.96, "end": 1480.8400000000001, "text": " I'm just going to show you another example, which is segmentation.", "tokens": [286, 478, 445, 516, 281, 855, 291, 1071, 1365, 11, 597, 307, 9469, 399, 13], "temperature": 0.0, "avg_logprob": -0.18003685243668094, "compression_ratio": 1.3758389261744965, "no_speech_prob": 3.785278750001453e-06}, {"id": 251, "seek": 147496, "start": 1480.8400000000001, "end": 1484.16, "text": " So let's grab a subset of CanVid.", "tokens": [407, 718, 311, 4444, 257, 25993, 295, 1664, 53, 327, 13], "temperature": 0.0, "avg_logprob": -0.18003685243668094, "compression_ratio": 1.3758389261744965, "no_speech_prob": 3.785278750001453e-06}, {"id": 252, "seek": 147496, "start": 1484.16, "end": 1487.04, "text": " Get those image files.", "tokens": [3240, 729, 3256, 7098, 13], "temperature": 0.0, "avg_logprob": -0.18003685243668094, "compression_ratio": 1.3758389261744965, "no_speech_prob": 3.785278750001453e-06}, {"id": 253, "seek": 147496, "start": 1487.04, "end": 1490.7, "text": " Create a random splitter.", "tokens": [20248, 257, 4974, 4732, 3904, 13], "temperature": 0.0, "avg_logprob": -0.18003685243668094, "compression_ratio": 1.3758389261744965, "no_speech_prob": 3.785278750001453e-06}, {"id": 254, "seek": 147496, "start": 1490.7, "end": 1493.76, "text": " Create the split indexes.", "tokens": [20248, 264, 7472, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.18003685243668094, "compression_ratio": 1.3758389261744965, "no_speech_prob": 3.785278750001453e-06}, {"id": 255, "seek": 147496, "start": 1493.76, "end": 1499.28, "text": " Create the labeling function.", "tokens": [20248, 264, 40244, 2445, 13], "temperature": 0.0, "avg_logprob": -0.18003685243668094, "compression_ratio": 1.3758389261744965, "no_speech_prob": 3.785278750001453e-06}, {"id": 256, "seek": 149928, "start": 1499.28, "end": 1509.6, "text": " So the transforms are basically the same as we had before, except that for the y, we first", "tokens": [407, 264, 35592, 366, 1936, 264, 912, 382, 321, 632, 949, 11, 3993, 300, 337, 264, 288, 11, 321, 700], "temperature": 0.0, "avg_logprob": -0.15189394685957167, "compression_ratio": 1.515527950310559, "no_speech_prob": 5.285482416184095e-07}, {"id": 257, "seek": 149928, "start": 1509.6, "end": 1510.6, "text": " of all call CVLabel.", "tokens": [295, 439, 818, 22995, 43, 18657, 13], "temperature": 0.0, "avg_logprob": -0.15189394685957167, "compression_ratio": 1.515527950310559, "no_speech_prob": 5.285482416184095e-07}, {"id": 258, "seek": 149928, "start": 1510.6, "end": 1518.1, "text": " So that's the thing that's going to grab the name of the mask file from the image file.", "tokens": [407, 300, 311, 264, 551, 300, 311, 516, 281, 4444, 264, 1315, 295, 264, 6094, 3991, 490, 264, 3256, 3991, 13], "temperature": 0.0, "avg_logprob": -0.15189394685957167, "compression_ratio": 1.515527950310559, "no_speech_prob": 5.285482416184095e-07}, {"id": 259, "seek": 149928, "start": 1518.1, "end": 1522.0, "text": " And then we're going to call pilMask.create.", "tokens": [400, 550, 321, 434, 516, 281, 818, 6429, 44, 3863, 13, 14066, 473, 13], "temperature": 0.0, "avg_logprob": -0.15189394685957167, "compression_ratio": 1.515527950310559, "no_speech_prob": 5.285482416184095e-07}, {"id": 260, "seek": 152200, "start": 1522.0, "end": 1534.12, "text": " And pilMask, as you can see, is just a single line of code.", "tokens": [400, 6429, 44, 3863, 11, 382, 291, 393, 536, 11, 307, 445, 257, 2167, 1622, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.16610588133335114, "compression_ratio": 1.5, "no_speech_prob": 1.9333497220941354e-06}, {"id": 261, "seek": 152200, "start": 1534.12, "end": 1539.0, "text": " And really the only reason it exists, or the main reason it exists, is so that we can do", "tokens": [400, 534, 264, 787, 1778, 309, 8198, 11, 420, 264, 2135, 1778, 309, 8198, 11, 307, 370, 300, 321, 393, 360], "temperature": 0.0, "avg_logprob": -0.16610588133335114, "compression_ratio": 1.5, "no_speech_prob": 1.9333497220941354e-06}, {"id": 262, "seek": 152200, "start": 1539.0, "end": 1551.32, "text": " stuff like we did back here where we had separate encodes for images and masks.", "tokens": [1507, 411, 321, 630, 646, 510, 689, 321, 632, 4994, 2058, 4789, 337, 5267, 293, 11830, 13], "temperature": 0.0, "avg_logprob": -0.16610588133335114, "compression_ratio": 1.5, "no_speech_prob": 1.9333497220941354e-06}, {"id": 263, "seek": 155132, "start": 1551.32, "end": 1555.1599999999999, "text": " So by giving things different types, it allows us to give different functionality.", "tokens": [407, 538, 2902, 721, 819, 3467, 11, 309, 4045, 505, 281, 976, 819, 14980, 13], "temperature": 0.0, "avg_logprob": -0.12231019827035758, "compression_ratio": 1.6496350364963503, "no_speech_prob": 2.2125068426248617e-05}, {"id": 264, "seek": 155132, "start": 1555.1599999999999, "end": 1560.52, "text": " In this case, it ensures when we resize things, we're going to use nearest neighbors instead", "tokens": [682, 341, 1389, 11, 309, 28111, 562, 321, 50069, 721, 11, 321, 434, 516, 281, 764, 23831, 12512, 2602], "temperature": 0.0, "avg_logprob": -0.12231019827035758, "compression_ratio": 1.6496350364963503, "no_speech_prob": 2.2125068426248617e-05}, {"id": 265, "seek": 155132, "start": 1560.52, "end": 1563.6399999999999, "text": " of bilinear.", "tokens": [295, 8588, 533, 289, 13], "temperature": 0.0, "avg_logprob": -0.12231019827035758, "compression_ratio": 1.6496350364963503, "no_speech_prob": 2.2125068426248617e-05}, {"id": 266, "seek": 155132, "start": 1563.6399999999999, "end": 1567.0, "text": " So that's a pretty interesting trick.", "tokens": [407, 300, 311, 257, 1238, 1880, 4282, 13], "temperature": 0.0, "avg_logprob": -0.12231019827035758, "compression_ratio": 1.6496350364963503, "no_speech_prob": 2.2125068426248617e-05}, {"id": 267, "seek": 155132, "start": 1567.0, "end": 1571.8, "text": " And so as you can see, the amount of code necessary to do segmentation, even though", "tokens": [400, 370, 382, 291, 393, 536, 11, 264, 2372, 295, 3089, 4818, 281, 360, 9469, 399, 11, 754, 1673], "temperature": 0.0, "avg_logprob": -0.12231019827035758, "compression_ratio": 1.6496350364963503, "no_speech_prob": 2.2125068426248617e-05}, {"id": 268, "seek": 155132, "start": 1571.8, "end": 1575.6399999999999, "text": " we haven't got any data blocks API yet, is pretty tiny.", "tokens": [321, 2378, 380, 658, 604, 1412, 8474, 9362, 1939, 11, 307, 1238, 5870, 13], "temperature": 0.0, "avg_logprob": -0.12231019827035758, "compression_ratio": 1.6496350364963503, "no_speech_prob": 2.2125068426248617e-05}, {"id": 269, "seek": 155132, "start": 1575.6399999999999, "end": 1580.4399999999998, "text": " So the idea here, and it all looks almost identical to pets, even though it's a very,", "tokens": [407, 264, 1558, 510, 11, 293, 309, 439, 1542, 1920, 14800, 281, 19897, 11, 754, 1673, 309, 311, 257, 588, 11], "temperature": 0.0, "avg_logprob": -0.12231019827035758, "compression_ratio": 1.6496350364963503, "no_speech_prob": 2.2125068426248617e-05}, {"id": 270, "seek": 158044, "start": 1580.44, "end": 1583.24, "text": " very different task.", "tokens": [588, 819, 5633, 13], "temperature": 0.0, "avg_logprob": -0.1400495875965465, "compression_ratio": 1.470873786407767, "no_speech_prob": 4.356786575954175e-06}, {"id": 271, "seek": 158044, "start": 1583.24, "end": 1587.52, "text": " In fact, even things like the DL transforms are literally identical, so we didn't have", "tokens": [682, 1186, 11, 754, 721, 411, 264, 413, 43, 35592, 366, 3736, 14800, 11, 370, 321, 994, 380, 362], "temperature": 0.0, "avg_logprob": -0.1400495875965465, "compression_ratio": 1.470873786407767, "no_speech_prob": 4.356786575954175e-06}, {"id": 272, "seek": 158044, "start": 1587.52, "end": 1590.3200000000002, "text": " to redefine them.", "tokens": [281, 38818, 533, 552, 13], "temperature": 0.0, "avg_logprob": -0.1400495875965465, "compression_ratio": 1.470873786407767, "no_speech_prob": 4.356786575954175e-06}, {"id": 273, "seek": 158044, "start": 1590.3200000000002, "end": 1595.8, "text": " So the idea of this kind of intermediate API that's halfway between data blocks and the", "tokens": [407, 264, 1558, 295, 341, 733, 295, 19376, 9362, 300, 311, 15461, 1296, 1412, 8474, 293, 264], "temperature": 0.0, "avg_logprob": -0.1400495875965465, "compression_ratio": 1.470873786407767, "no_speech_prob": 4.356786575954175e-06}, {"id": 274, "seek": 158044, "start": 1595.8, "end": 1608.44, "text": " lowest level stuff is to make it super simple, to make it really easy to do custom stuff.", "tokens": [12437, 1496, 1507, 307, 281, 652, 309, 1687, 2199, 11, 281, 652, 309, 534, 1858, 281, 360, 2375, 1507, 13], "temperature": 0.0, "avg_logprob": -0.1400495875965465, "compression_ratio": 1.470873786407767, "no_speech_prob": 4.356786575954175e-06}, {"id": 275, "seek": 160844, "start": 1608.44, "end": 1614.8, "text": " And my guess is that people doing a lot of Kaggle competitions or more advanced stuff", "tokens": [400, 452, 2041, 307, 300, 561, 884, 257, 688, 295, 48751, 22631, 26185, 420, 544, 7339, 1507], "temperature": 0.0, "avg_logprob": -0.09103263749016656, "compression_ratio": 1.6856060606060606, "no_speech_prob": 2.3687700831942493e-06}, {"id": 276, "seek": 160844, "start": 1614.8, "end": 1619.16, "text": " that's a little bit different to the things we show in the lessons or whatever is that", "tokens": [300, 311, 257, 707, 857, 819, 281, 264, 721, 321, 855, 294, 264, 8820, 420, 2035, 307, 300], "temperature": 0.0, "avg_logprob": -0.09103263749016656, "compression_ratio": 1.6856060606060606, "no_speech_prob": 2.3687700831942493e-06}, {"id": 277, "seek": 160844, "start": 1619.16, "end": 1623.88, "text": " you'll probably use this level of the API a lot because it just doesn't require much", "tokens": [291, 603, 1391, 764, 341, 1496, 295, 264, 9362, 257, 688, 570, 309, 445, 1177, 380, 3651, 709], "temperature": 0.0, "avg_logprob": -0.09103263749016656, "compression_ratio": 1.6856060606060606, "no_speech_prob": 2.3687700831942493e-06}, {"id": 278, "seek": 160844, "start": 1623.88, "end": 1628.78, "text": " thinking and it's all pretty transparent and easy to understand.", "tokens": [1953, 293, 309, 311, 439, 1238, 12737, 293, 1858, 281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.09103263749016656, "compression_ratio": 1.6856060606060606, "no_speech_prob": 2.3687700831942493e-06}, {"id": 279, "seek": 160844, "start": 1628.78, "end": 1632.56, "text": " And then as you'll see, the stuff that is in data blocks and stuff is all built on top", "tokens": [400, 550, 382, 291, 603, 536, 11, 264, 1507, 300, 307, 294, 1412, 8474, 293, 1507, 307, 439, 3094, 322, 1192], "temperature": 0.0, "avg_logprob": -0.09103263749016656, "compression_ratio": 1.6856060606060606, "no_speech_prob": 2.3687700831942493e-06}, {"id": 280, "seek": 160844, "start": 1632.56, "end": 1636.2, "text": " of this and takes very little code.", "tokens": [295, 341, 293, 2516, 588, 707, 3089, 13], "temperature": 0.0, "avg_logprob": -0.09103263749016656, "compression_ratio": 1.6856060606060606, "no_speech_prob": 2.3687700831942493e-06}, {"id": 281, "seek": 163620, "start": 1636.2, "end": 1642.04, "text": " So Jacob asks how to profile code to see where the bottlenecks are.", "tokens": [407, 14117, 8962, 577, 281, 7964, 3089, 281, 536, 689, 264, 44641, 2761, 366, 13], "temperature": 0.0, "avg_logprob": -0.19232465570623225, "compression_ratio": 1.6837209302325582, "no_speech_prob": 9.665393008617684e-06}, {"id": 282, "seek": 163620, "start": 1642.04, "end": 1644.32, "text": " I'd have to say I'm not terribly good at that.", "tokens": [286, 1116, 362, 281, 584, 286, 478, 406, 22903, 665, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.19232465570623225, "compression_ratio": 1.6837209302325582, "no_speech_prob": 9.665393008617684e-06}, {"id": 283, "seek": 163620, "start": 1644.32, "end": 1648.32, "text": " I mean, I just, I mean, or at least I'm not terribly smart about it.", "tokens": [286, 914, 11, 286, 445, 11, 286, 914, 11, 420, 412, 1935, 286, 478, 406, 22903, 4069, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.19232465570623225, "compression_ratio": 1.6837209302325582, "no_speech_prob": 9.665393008617684e-06}, {"id": 284, "seek": 163620, "start": 1648.32, "end": 1653.0, "text": " I just, if I want to, if I want to know where bottlenecks are in training, I'll just check", "tokens": [286, 445, 11, 498, 286, 528, 281, 11, 498, 286, 528, 281, 458, 689, 44641, 2761, 366, 294, 3097, 11, 286, 603, 445, 1520], "temperature": 0.0, "avg_logprob": -0.19232465570623225, "compression_ratio": 1.6837209302325582, "no_speech_prob": 9.665393008617684e-06}, {"id": 285, "seek": 163620, "start": 1653.0, "end": 1660.8400000000001, "text": " H-top to see if all the CPUs are being used 100% and I'll check Nvidia SMI to see if my", "tokens": [389, 12, 19337, 281, 536, 498, 439, 264, 13199, 82, 366, 885, 1143, 2319, 4, 293, 286, 603, 1520, 46284, 13115, 40, 281, 536, 498, 452], "temperature": 0.0, "avg_logprob": -0.19232465570623225, "compression_ratio": 1.6837209302325582, "no_speech_prob": 9.665393008617684e-06}, {"id": 286, "seek": 166084, "start": 1660.84, "end": 1668.3999999999999, "text": " GPUs are being used 100%.", "tokens": [18407, 82, 366, 885, 1143, 2319, 6856], "temperature": 0.0, "avg_logprob": -0.16116122007369996, "compression_ratio": 1.4660194174757282, "no_speech_prob": 9.368432984047104e-06}, {"id": 287, "seek": 166084, "start": 1668.3999999999999, "end": 1678.52, "text": " So if you haven't done that before, you basically go Nvidia SMI daemon and it starts bidding", "tokens": [407, 498, 291, 2378, 380, 1096, 300, 949, 11, 291, 1936, 352, 46284, 13115, 40, 1120, 36228, 293, 309, 3719, 39702], "temperature": 0.0, "avg_logprob": -0.16116122007369996, "compression_ratio": 1.4660194174757282, "no_speech_prob": 9.368432984047104e-06}, {"id": 288, "seek": 166084, "start": 1678.52, "end": 1680.24, "text": " out stuff like this.", "tokens": [484, 1507, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.16116122007369996, "compression_ratio": 1.4660194174757282, "no_speech_prob": 9.368432984047104e-06}, {"id": 289, "seek": 166084, "start": 1680.24, "end": 1684.8799999999999, "text": " And the key column that you're going to care about is this one here, SM.", "tokens": [400, 264, 2141, 7738, 300, 291, 434, 516, 281, 1127, 466, 307, 341, 472, 510, 11, 13115, 13], "temperature": 0.0, "avg_logprob": -0.16116122007369996, "compression_ratio": 1.4660194174757282, "no_speech_prob": 9.368432984047104e-06}, {"id": 290, "seek": 166084, "start": 1684.8799999999999, "end": 1688.6799999999998, "text": " That should, when you're training something, that should be basically saying above 90 and", "tokens": [663, 820, 11, 562, 291, 434, 3097, 746, 11, 300, 820, 312, 1936, 1566, 3673, 4289, 293], "temperature": 0.0, "avg_logprob": -0.16116122007369996, "compression_ratio": 1.4660194174757282, "no_speech_prob": 9.368432984047104e-06}, {"id": 291, "seek": 168868, "start": 1688.68, "end": 1690.96, "text": " preferably around 100 all the time.", "tokens": [45916, 926, 2319, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.08660656472911006, "compression_ratio": 1.7410714285714286, "no_speech_prob": 7.183090929174796e-06}, {"id": 292, "seek": 168868, "start": 1690.96, "end": 1693.3200000000002, "text": " That means your GPUs are being well used.", "tokens": [663, 1355, 428, 18407, 82, 366, 885, 731, 1143, 13], "temperature": 0.0, "avg_logprob": -0.08660656472911006, "compression_ratio": 1.7410714285714286, "no_speech_prob": 7.183090929174796e-06}, {"id": 293, "seek": 168868, "start": 1693.3200000000002, "end": 1701.3, "text": " If it's less than that, then it probably means that your CPUs are being overtaxed.", "tokens": [759, 309, 311, 1570, 813, 300, 11, 550, 309, 1391, 1355, 300, 428, 13199, 82, 366, 885, 670, 1328, 87, 292, 13], "temperature": 0.0, "avg_logprob": -0.08660656472911006, "compression_ratio": 1.7410714285714286, "no_speech_prob": 7.183090929174796e-06}, {"id": 294, "seek": 168868, "start": 1701.3, "end": 1703.1200000000001, "text": " And so that would be kind of step one.", "tokens": [400, 370, 300, 576, 312, 733, 295, 1823, 472, 13], "temperature": 0.0, "avg_logprob": -0.08660656472911006, "compression_ratio": 1.7410714285714286, "no_speech_prob": 7.183090929174796e-06}, {"id": 295, "seek": 168868, "start": 1703.1200000000001, "end": 1707.3200000000002, "text": " And if it's then your CPUs are overtaxed, then you can just use the normal Python profilers", "tokens": [400, 498, 309, 311, 550, 428, 13199, 82, 366, 670, 1328, 87, 292, 11, 550, 291, 393, 445, 764, 264, 2710, 15329, 1740, 388, 433], "temperature": 0.0, "avg_logprob": -0.08660656472911006, "compression_ratio": 1.7410714285714286, "no_speech_prob": 7.183090929174796e-06}, {"id": 296, "seek": 168868, "start": 1707.3200000000002, "end": 1710.4, "text": " to find out why.", "tokens": [281, 915, 484, 983, 13], "temperature": 0.0, "avg_logprob": -0.08660656472911006, "compression_ratio": 1.7410714285714286, "no_speech_prob": 7.183090929174796e-06}, {"id": 297, "seek": 168868, "start": 1710.4, "end": 1716.24, "text": " If your GPU is being overtaxed, then that's probably just basically a good thing.", "tokens": [759, 428, 18407, 307, 885, 670, 1328, 87, 292, 11, 550, 300, 311, 1391, 445, 1936, 257, 665, 551, 13], "temperature": 0.0, "avg_logprob": -0.08660656472911006, "compression_ratio": 1.7410714285714286, "no_speech_prob": 7.183090929174796e-06}, {"id": 298, "seek": 171624, "start": 1716.24, "end": 1720.92, "text": " It's using your GPUs effectively most of the time.", "tokens": [467, 311, 1228, 428, 18407, 82, 8659, 881, 295, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.23677583977028174, "compression_ratio": 1.141732283464567, "no_speech_prob": 9.972653970180545e-06}, {"id": 299, "seek": 171624, "start": 1720.92, "end": 1722.28, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.23677583977028174, "compression_ratio": 1.141732283464567, "no_speech_prob": 9.972653970180545e-06}, {"id": 300, "seek": 171624, "start": 1722.28, "end": 1725.8, "text": " So that's 08.", "tokens": [407, 300, 311, 1958, 23, 13], "temperature": 0.0, "avg_logprob": -0.23677583977028174, "compression_ratio": 1.141732283464567, "no_speech_prob": 9.972653970180545e-06}, {"id": 301, "seek": 171624, "start": 1725.8, "end": 1745.04, "text": " So I thought from here maybe we'll take a look at Tiffen DL, which is in 05.", "tokens": [407, 286, 1194, 490, 510, 1310, 321, 603, 747, 257, 574, 412, 314, 3661, 268, 413, 43, 11, 597, 307, 294, 1958, 20, 13], "temperature": 0.0, "avg_logprob": -0.23677583977028174, "compression_ratio": 1.141732283464567, "no_speech_prob": 9.972653970180545e-06}, {"id": 302, "seek": 174504, "start": 1745.04, "end": 1754.92, "text": " And by the way, there's a file called local notebook index.txt, which is automatically", "tokens": [400, 538, 264, 636, 11, 456, 311, 257, 3991, 1219, 2654, 21060, 8186, 13, 83, 734, 11, 597, 307, 6772], "temperature": 0.0, "avg_logprob": -0.23072186831770272, "compression_ratio": 1.481012658227848, "no_speech_prob": 3.446508344495669e-06}, {"id": 303, "seek": 174504, "start": 1754.92, "end": 1760.24, "text": " generated, which tells you which notebook everything's in.", "tokens": [10833, 11, 597, 5112, 291, 597, 21060, 1203, 311, 294, 13], "temperature": 0.0, "avg_logprob": -0.23072186831770272, "compression_ratio": 1.481012658227848, "no_speech_prob": 3.446508344495669e-06}, {"id": 304, "seek": 174504, "start": 1760.24, "end": 1773.24, "text": " Although the easier way to quickly jump there is you can just go, let's just import some", "tokens": [5780, 264, 3571, 636, 281, 2661, 3012, 456, 307, 291, 393, 445, 352, 11, 718, 311, 445, 974, 512], "temperature": 0.0, "avg_logprob": -0.23072186831770272, "compression_ratio": 1.481012658227848, "no_speech_prob": 3.446508344495669e-06}, {"id": 305, "seek": 177324, "start": 1773.24, "end": 1780.6, "text": " local notebook show.importster.", "tokens": [2654, 21060, 855, 13, 20737, 3120, 13], "temperature": 0.0, "avg_logprob": -0.3116353352864583, "compression_ratio": 1.1442307692307692, "no_speech_prob": 1.0450844456499908e-05}, {"id": 306, "seek": 177324, "start": 1780.6, "end": 1791.36, "text": " You can go source link tiffen DL.", "tokens": [509, 393, 352, 4009, 2113, 256, 3661, 268, 413, 43, 13], "temperature": 0.0, "avg_logprob": -0.3116353352864583, "compression_ratio": 1.1442307692307692, "no_speech_prob": 1.0450844456499908e-05}, {"id": 307, "seek": 179136, "start": 1791.36, "end": 1803.52, "text": " And as you can see, you'll get a link straight there.", "tokens": [400, 382, 291, 393, 536, 11, 291, 603, 483, 257, 2113, 2997, 456, 13], "temperature": 0.0, "avg_logprob": -0.19766436125102796, "compression_ratio": 1.7528735632183907, "no_speech_prob": 4.710840585175902e-06}, {"id": 308, "seek": 179136, "start": 1803.52, "end": 1805.32, "text": " And as you can see, it's got an anchor.", "tokens": [400, 382, 291, 393, 536, 11, 309, 311, 658, 364, 18487, 13], "temperature": 0.0, "avg_logprob": -0.19766436125102796, "compression_ratio": 1.7528735632183907, "no_speech_prob": 4.710840585175902e-06}, {"id": 309, "seek": 179136, "start": 1805.32, "end": 1809.8, "text": " So it's going to jump straight to this right section once we wait.", "tokens": [407, 309, 311, 516, 281, 3012, 2997, 281, 341, 558, 3541, 1564, 321, 1699, 13], "temperature": 0.0, "avg_logprob": -0.19766436125102796, "compression_ratio": 1.7528735632183907, "no_speech_prob": 4.710840585175902e-06}, {"id": 310, "seek": 179136, "start": 1809.8, "end": 1810.8, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.19766436125102796, "compression_ratio": 1.7528735632183907, "no_speech_prob": 4.710840585175902e-06}, {"id": 311, "seek": 179136, "start": 1810.8, "end": 1811.8, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.19766436125102796, "compression_ratio": 1.7528735632183907, "no_speech_prob": 4.710840585175902e-06}, {"id": 312, "seek": 179136, "start": 1811.8, "end": 1815.56, "text": " So that's a nice fast way to go to the right part of the right notebook and the right part", "tokens": [407, 300, 311, 257, 1481, 2370, 636, 281, 352, 281, 264, 558, 644, 295, 264, 558, 21060, 293, 264, 558, 644], "temperature": 0.0, "avg_logprob": -0.19766436125102796, "compression_ratio": 1.7528735632183907, "no_speech_prob": 4.710840585175902e-06}, {"id": 313, "seek": 179136, "start": 1815.56, "end": 1816.56, "text": " of a notebook.", "tokens": [295, 257, 21060, 13], "temperature": 0.0, "avg_logprob": -0.19766436125102796, "compression_ratio": 1.7528735632183907, "no_speech_prob": 4.710840585175902e-06}, {"id": 314, "seek": 179136, "start": 1816.56, "end": 1819.56, "text": " That was source link.", "tokens": [663, 390, 4009, 2113, 13], "temperature": 0.0, "avg_logprob": -0.19766436125102796, "compression_ratio": 1.7528735632183907, "no_speech_prob": 4.710840585175902e-06}, {"id": 315, "seek": 181956, "start": 1819.56, "end": 1822.84, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.19461161403332727, "compression_ratio": 1.3636363636363635, "no_speech_prob": 3.393111228433554e-06}, {"id": 316, "seek": 181956, "start": 1822.84, "end": 1828.8, "text": " So here is 05 data core.", "tokens": [407, 510, 307, 1958, 20, 1412, 4965, 13], "temperature": 0.0, "avg_logprob": -0.19461161403332727, "compression_ratio": 1.3636363636363635, "no_speech_prob": 3.393111228433554e-06}, {"id": 317, "seek": 181956, "start": 1828.8, "end": 1835.24, "text": " And we may as well look at the whole thing from the top while we're here.", "tokens": [400, 321, 815, 382, 731, 574, 412, 264, 1379, 551, 490, 264, 1192, 1339, 321, 434, 510, 13], "temperature": 0.0, "avg_logprob": -0.19461161403332727, "compression_ratio": 1.3636363636363635, "no_speech_prob": 3.393111228433554e-06}, {"id": 318, "seek": 181956, "start": 1835.24, "end": 1849.48, "text": " So basically what we're going to learn is how get files works and get image files, splitter,", "tokens": [407, 1936, 437, 321, 434, 516, 281, 1466, 307, 577, 483, 7098, 1985, 293, 483, 3256, 7098, 11, 4732, 3904, 11], "temperature": 0.0, "avg_logprob": -0.19461161403332727, "compression_ratio": 1.3636363636363635, "no_speech_prob": 3.393111228433554e-06}, {"id": 319, "seek": 184948, "start": 1849.48, "end": 1862.64, "text": " labeler, categorize, multi-categorize, and then we'll put it all that together with mnist", "tokens": [7645, 260, 11, 19250, 1125, 11, 4825, 12, 66, 2968, 284, 1125, 11, 293, 550, 321, 603, 829, 309, 439, 300, 1214, 365, 275, 77, 468], "temperature": 0.0, "avg_logprob": -0.223068259228235, "compression_ratio": 1.4736842105263157, "no_speech_prob": 7.646460289834067e-06}, {"id": 320, "seek": 184948, "start": 1862.64, "end": 1865.48, "text": " and then we'll see tiffen DL.", "tokens": [293, 550, 321, 603, 536, 256, 3661, 268, 413, 43, 13], "temperature": 0.0, "avg_logprob": -0.223068259228235, "compression_ratio": 1.4736842105263157, "no_speech_prob": 7.646460289834067e-06}, {"id": 321, "seek": 184948, "start": 1865.48, "end": 1867.8, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.223068259228235, "compression_ratio": 1.4736842105263157, "no_speech_prob": 7.646460289834067e-06}, {"id": 322, "seek": 184948, "start": 1867.8, "end": 1870.88, "text": " So let's start.", "tokens": [407, 718, 311, 722, 13], "temperature": 0.0, "avg_logprob": -0.223068259228235, "compression_ratio": 1.4736842105263157, "no_speech_prob": 7.646460289834067e-06}, {"id": 323, "seek": 184948, "start": 1870.88, "end": 1875.88, "text": " So as you can see here, the first bits are a kind of three major data box-ish components,", "tokens": [407, 382, 291, 393, 536, 510, 11, 264, 700, 9239, 366, 257, 733, 295, 1045, 2563, 1412, 2424, 12, 742, 6677, 11], "temperature": 0.0, "avg_logprob": -0.223068259228235, "compression_ratio": 1.4736842105263157, "no_speech_prob": 7.646460289834067e-06}, {"id": 324, "seek": 184948, "start": 1875.88, "end": 1877.64, "text": " get, split, and label.", "tokens": [483, 11, 7472, 11, 293, 7645, 13], "temperature": 0.0, "avg_logprob": -0.223068259228235, "compression_ratio": 1.4736842105263157, "no_speech_prob": 7.646460289834067e-06}, {"id": 325, "seek": 187764, "start": 1877.64, "end": 1886.0400000000002, "text": " So the basic get thing we use, same as in fast.ai version 1, is get files.", "tokens": [407, 264, 3875, 483, 551, 321, 764, 11, 912, 382, 294, 2370, 13, 1301, 3037, 502, 11, 307, 483, 7098, 13], "temperature": 0.0, "avg_logprob": -0.1218148051081477, "compression_ratio": 1.5838509316770186, "no_speech_prob": 3.844888396997703e-06}, {"id": 326, "seek": 187764, "start": 1886.0400000000002, "end": 1899.1200000000001, "text": " So get files is going to take 1, 2, 3, 4 parameters, the path that we're going to look for files", "tokens": [407, 483, 7098, 307, 516, 281, 747, 502, 11, 568, 11, 805, 11, 1017, 9834, 11, 264, 3100, 300, 321, 434, 516, 281, 574, 337, 7098], "temperature": 0.0, "avg_logprob": -0.1218148051081477, "compression_ratio": 1.5838509316770186, "no_speech_prob": 3.844888396997703e-06}, {"id": 327, "seek": 187764, "start": 1899.1200000000001, "end": 1904.2, "text": " in, which extensions to look for, whether we want to do it recursively, and whether", "tokens": [294, 11, 597, 25129, 281, 574, 337, 11, 1968, 321, 528, 281, 360, 309, 20560, 3413, 11, 293, 1968], "temperature": 0.0, "avg_logprob": -0.1218148051081477, "compression_ratio": 1.5838509316770186, "no_speech_prob": 3.844888396997703e-06}, {"id": 328, "seek": 190420, "start": 1904.2, "end": 1908.8, "text": " there's just some subset of folders to include.", "tokens": [456, 311, 445, 512, 25993, 295, 31082, 281, 4090, 13], "temperature": 0.0, "avg_logprob": -0.1651599884033203, "compression_ratio": 1.6020408163265305, "no_speech_prob": 8.53011260915082e-06}, {"id": 329, "seek": 190420, "start": 1908.8, "end": 1915.04, "text": " So we have in this notebook, we're using mnist.", "tokens": [407, 321, 362, 294, 341, 21060, 11, 321, 434, 1228, 275, 77, 468, 13], "temperature": 0.0, "avg_logprob": -0.1651599884033203, "compression_ratio": 1.6020408163265305, "no_speech_prob": 8.53011260915082e-06}, {"id": 330, "seek": 190420, "start": 1915.04, "end": 1919.3600000000001, "text": " And so it's important to know here that this notebook is not just a tutorial notebook.", "tokens": [400, 370, 309, 311, 1021, 281, 458, 510, 300, 341, 21060, 307, 406, 445, 257, 7073, 21060, 13], "temperature": 0.0, "avg_logprob": -0.1651599884033203, "compression_ratio": 1.6020408163265305, "no_speech_prob": 8.53011260915082e-06}, {"id": 331, "seek": 190420, "start": 1919.3600000000001, "end": 1923.38, "text": " This is a notebook that actually defines the module called data.core.", "tokens": [639, 307, 257, 21060, 300, 767, 23122, 264, 10088, 1219, 1412, 13, 12352, 13], "temperature": 0.0, "avg_logprob": -0.1651599884033203, "compression_ratio": 1.6020408163265305, "no_speech_prob": 8.53011260915082e-06}, {"id": 332, "seek": 190420, "start": 1923.38, "end": 1928.1200000000001, "text": " So we're going to end up with something called data core.", "tokens": [407, 321, 434, 516, 281, 917, 493, 365, 746, 1219, 1412, 4965, 13], "temperature": 0.0, "avg_logprob": -0.1651599884033203, "compression_ratio": 1.6020408163265305, "no_speech_prob": 8.53011260915082e-06}, {"id": 333, "seek": 190420, "start": 1928.1200000000001, "end": 1929.64, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1651599884033203, "compression_ratio": 1.6020408163265305, "no_speech_prob": 8.53011260915082e-06}, {"id": 334, "seek": 192964, "start": 1929.64, "end": 1934.3200000000002, "text": " So this is the thing that we're building.", "tokens": [407, 341, 307, 264, 551, 300, 321, 434, 2390, 13], "temperature": 0.0, "avg_logprob": -0.1058500852340307, "compression_ratio": 1.625668449197861, "no_speech_prob": 1.4593679225072265e-06}, {"id": 335, "seek": 192964, "start": 1934.3200000000002, "end": 1944.16, "text": " You can see we've got get image files, get files, and so forth.", "tokens": [509, 393, 536, 321, 600, 658, 483, 3256, 7098, 11, 483, 7098, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.1058500852340307, "compression_ratio": 1.625668449197861, "no_speech_prob": 1.4593679225072265e-06}, {"id": 336, "seek": 192964, "start": 1944.16, "end": 1950.1000000000001, "text": " You'll notice that it's automatically creating a Thunderall array.", "tokens": [509, 603, 3449, 300, 309, 311, 6772, 4084, 257, 21023, 336, 10225, 13], "temperature": 0.0, "avg_logprob": -0.1058500852340307, "compression_ratio": 1.625668449197861, "no_speech_prob": 1.4593679225072265e-06}, {"id": 337, "seek": 192964, "start": 1950.1000000000001, "end": 1954.8000000000002, "text": " So that's created automatically by the fast.ai notebook functionality.", "tokens": [407, 300, 311, 2942, 6772, 538, 264, 2370, 13, 1301, 21060, 14980, 13], "temperature": 0.0, "avg_logprob": -0.1058500852340307, "compression_ratio": 1.625668449197861, "no_speech_prob": 1.4593679225072265e-06}, {"id": 338, "seek": 192964, "start": 1954.8000000000002, "end": 1958.64, "text": " This is the thing that Python uses to decide what to import.", "tokens": [639, 307, 264, 551, 300, 15329, 4960, 281, 4536, 437, 281, 974, 13], "temperature": 0.0, "avg_logprob": -0.1058500852340307, "compression_ratio": 1.625668449197861, "no_speech_prob": 1.4593679225072265e-06}, {"id": 339, "seek": 195864, "start": 1958.64, "end": 1965.24, "text": " If you say import star, in most Python libraries, people don't bother creating this.", "tokens": [759, 291, 584, 974, 3543, 11, 294, 881, 15329, 15148, 11, 561, 500, 380, 8677, 4084, 341, 13], "temperature": 0.0, "avg_logprob": -0.11986549695332845, "compression_ratio": 1.7944664031620554, "no_speech_prob": 2.6425443593325326e-06}, {"id": 340, "seek": 195864, "start": 1965.24, "end": 1969.5800000000002, "text": " And that's one of the reasons that people normally say don't use import star, is because", "tokens": [400, 300, 311, 472, 295, 264, 4112, 300, 561, 5646, 584, 500, 380, 764, 974, 3543, 11, 307, 570], "temperature": 0.0, "avg_logprob": -0.11986549695332845, "compression_ratio": 1.7944664031620554, "no_speech_prob": 2.6425443593325326e-06}, {"id": 341, "seek": 195864, "start": 1969.5800000000002, "end": 1973.68, "text": " if you don't bother to create this, and it's actually going to import also everything that", "tokens": [498, 291, 500, 380, 8677, 281, 1884, 341, 11, 293, 309, 311, 767, 516, 281, 974, 611, 1203, 300], "temperature": 0.0, "avg_logprob": -0.11986549695332845, "compression_ratio": 1.7944664031620554, "no_speech_prob": 2.6425443593325326e-06}, {"id": 342, "seek": 195864, "start": 1973.68, "end": 1977.6000000000001, "text": " is imported recursively, it gets really awful.", "tokens": [307, 25524, 20560, 3413, 11, 309, 2170, 534, 11232, 13], "temperature": 0.0, "avg_logprob": -0.11986549695332845, "compression_ratio": 1.7944664031620554, "no_speech_prob": 2.6425443593325326e-06}, {"id": 343, "seek": 195864, "start": 1977.6000000000001, "end": 1982.92, "text": " But since we're super careful about what gets exported and how things are structured, you'll", "tokens": [583, 1670, 321, 434, 1687, 5026, 466, 437, 2170, 42055, 293, 577, 721, 366, 18519, 11, 291, 603], "temperature": 0.0, "avg_logprob": -0.11986549695332845, "compression_ratio": 1.7944664031620554, "no_speech_prob": 2.6425443593325326e-06}, {"id": 344, "seek": 195864, "start": 1982.92, "end": 1985.5800000000002, "text": " very rarely have problems if you use import star.", "tokens": [588, 13752, 362, 2740, 498, 291, 764, 974, 3543, 13], "temperature": 0.0, "avg_logprob": -0.11986549695332845, "compression_ratio": 1.7944664031620554, "no_speech_prob": 2.6425443593325326e-06}, {"id": 345, "seek": 198558, "start": 1985.58, "end": 1989.6799999999998, "text": " So we tried to make it as kind of REPL-friendly, interactive-friendly as possible.", "tokens": [407, 321, 3031, 281, 652, 309, 382, 733, 295, 31511, 43, 12, 22864, 11, 15141, 12, 22864, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.13787581302501536, "compression_ratio": 1.6733870967741935, "no_speech_prob": 4.495092525758082e-06}, {"id": 346, "seek": 198558, "start": 1989.6799999999998, "end": 1994.8799999999999, "text": " And so particularly because this is created automatically, it's a really, really handy", "tokens": [400, 370, 4098, 570, 341, 307, 2942, 6772, 11, 309, 311, 257, 534, 11, 534, 13239], "temperature": 0.0, "avg_logprob": -0.13787581302501536, "compression_ratio": 1.6733870967741935, "no_speech_prob": 4.495092525758082e-06}, {"id": 347, "seek": 198558, "start": 1994.8799999999999, "end": 1997.8799999999999, "text": " thing.", "tokens": [551, 13], "temperature": 0.0, "avg_logprob": -0.13787581302501536, "compression_ratio": 1.6733870967741935, "no_speech_prob": 4.495092525758082e-06}, {"id": 348, "seek": 198558, "start": 1997.8799999999999, "end": 2001.3999999999999, "text": " So that's why you'll see it in the Python module, but you won't see it in the notebook", "tokens": [407, 300, 311, 983, 291, 603, 536, 309, 294, 264, 15329, 10088, 11, 457, 291, 1582, 380, 536, 309, 294, 264, 21060], "temperature": 0.0, "avg_logprob": -0.13787581302501536, "compression_ratio": 1.6733870967741935, "no_speech_prob": 4.495092525758082e-06}, {"id": 349, "seek": 198558, "start": 2001.3999999999999, "end": 2003.8, "text": " because it's automatic.", "tokens": [570, 309, 311, 12509, 13], "temperature": 0.0, "avg_logprob": -0.13787581302501536, "compression_ratio": 1.6733870967741935, "no_speech_prob": 4.495092525758082e-06}, {"id": 350, "seek": 198558, "start": 2003.8, "end": 2008.76, "text": " So yeah, so this is kind of our first deep dive into literate programming because we're", "tokens": [407, 1338, 11, 370, 341, 307, 733, 295, 527, 700, 2452, 9192, 666, 2733, 473, 9410, 570, 321, 434], "temperature": 0.0, "avg_logprob": -0.13787581302501536, "compression_ratio": 1.6733870967741935, "no_speech_prob": 4.495092525758082e-06}, {"id": 351, "seek": 198558, "start": 2008.76, "end": 2010.76, "text": " actually building the data.core module.", "tokens": [767, 2390, 264, 1412, 13, 12352, 10088, 13], "temperature": 0.0, "avg_logprob": -0.13787581302501536, "compression_ratio": 1.6733870967741935, "no_speech_prob": 4.495092525758082e-06}, {"id": 352, "seek": 201076, "start": 2010.76, "end": 2016.32, "text": " But as you can see, we have, you know, pros along the way.", "tokens": [583, 382, 291, 393, 536, 11, 321, 362, 11, 291, 458, 11, 6267, 2051, 264, 636, 13], "temperature": 0.0, "avg_logprob": -0.1752827803293864, "compression_ratio": 1.507936507936508, "no_speech_prob": 1.6963771486189216e-05}, {"id": 353, "seek": 201076, "start": 2016.32, "end": 2022.2, "text": " So the first step is to get a list of items.", "tokens": [407, 264, 700, 1823, 307, 281, 483, 257, 1329, 295, 4754, 13], "temperature": 0.0, "avg_logprob": -0.1752827803293864, "compression_ratio": 1.507936507936508, "no_speech_prob": 1.6963771486189216e-05}, {"id": 354, "seek": 201076, "start": 2022.2, "end": 2029.6, "text": " An item is... can be kind of anything you like.", "tokens": [1107, 3174, 307, 485, 393, 312, 733, 295, 1340, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.1752827803293864, "compression_ratio": 1.507936507936508, "no_speech_prob": 1.6963771486189216e-05}, {"id": 355, "seek": 201076, "start": 2029.6, "end": 2032.76, "text": " An item list can be anything you like.", "tokens": [1107, 3174, 1329, 393, 312, 1340, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.1752827803293864, "compression_ratio": 1.507936507936508, "no_speech_prob": 1.6963771486189216e-05}, {"id": 356, "seek": 203276, "start": 2032.76, "end": 2042.8, "text": " So for stuff with vision, it's normally a list of paths, but an item list could be a", "tokens": [407, 337, 1507, 365, 5201, 11, 309, 311, 5646, 257, 1329, 295, 14518, 11, 457, 364, 3174, 1329, 727, 312, 257], "temperature": 0.0, "avg_logprob": -0.11455258236655706, "compression_ratio": 1.5307262569832403, "no_speech_prob": 1.6027908031901461e-06}, {"id": 357, "seek": 203276, "start": 2042.8, "end": 2049.44, "text": " data frame, could be a connection to a database, could be a network, type.", "tokens": [1412, 3920, 11, 727, 312, 257, 4984, 281, 257, 8149, 11, 727, 312, 257, 3209, 11, 2010, 13], "temperature": 0.0, "avg_logprob": -0.11455258236655706, "compression_ratio": 1.5307262569832403, "no_speech_prob": 1.6027908031901461e-06}, {"id": 358, "seek": 203276, "start": 2049.44, "end": 2055.84, "text": " As you see, you'll be able to do pretty much anything.", "tokens": [1018, 291, 536, 11, 291, 603, 312, 1075, 281, 360, 1238, 709, 1340, 13], "temperature": 0.0, "avg_logprob": -0.11455258236655706, "compression_ratio": 1.5307262569832403, "no_speech_prob": 1.6027908031901461e-06}, {"id": 359, "seek": 203276, "start": 2055.84, "end": 2059.44, "text": " But for now, for these ones, we're going to be using paths.", "tokens": [583, 337, 586, 11, 337, 613, 2306, 11, 321, 434, 516, 281, 312, 1228, 14518, 13], "temperature": 0.0, "avg_logprob": -0.11455258236655706, "compression_ratio": 1.5307262569832403, "no_speech_prob": 1.6027908031901461e-06}, {"id": 360, "seek": 205944, "start": 2059.44, "end": 2066.88, "text": " And we'll be looking at using data frames later.", "tokens": [400, 321, 603, 312, 1237, 412, 1228, 1412, 12083, 1780, 13], "temperature": 0.0, "avg_logprob": -0.16262940724690755, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.8738492144620977e-06}, {"id": 361, "seek": 205944, "start": 2066.88, "end": 2069.56, "text": " So we grab our path.", "tokens": [407, 321, 4444, 527, 3100, 13], "temperature": 0.0, "avg_logprob": -0.16262940724690755, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.8738492144620977e-06}, {"id": 362, "seek": 205944, "start": 2069.56, "end": 2071.92, "text": " We're going to be...", "tokens": [492, 434, 516, 281, 312, 485], "temperature": 0.0, "avg_logprob": -0.16262940724690755, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.8738492144620977e-06}, {"id": 363, "seek": 205944, "start": 2071.92, "end": 2078.52, "text": " So get files is going to be calling underscore get files.", "tokens": [407, 483, 7098, 307, 516, 281, 312, 5141, 37556, 483, 7098, 13], "temperature": 0.0, "avg_logprob": -0.16262940724690755, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.8738492144620977e-06}, {"id": 364, "seek": 205944, "start": 2078.52, "end": 2080.34, "text": " So that's what this is.", "tokens": [407, 300, 311, 437, 341, 307, 13], "temperature": 0.0, "avg_logprob": -0.16262940724690755, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.8738492144620977e-06}, {"id": 365, "seek": 205944, "start": 2080.34, "end": 2087.16, "text": " And you'll see underscore get files, if we search for it here, underscore get, underscore", "tokens": [400, 291, 603, 536, 37556, 483, 7098, 11, 498, 321, 3164, 337, 309, 510, 11, 37556, 483, 11, 37556], "temperature": 0.0, "avg_logprob": -0.16262940724690755, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.8738492144620977e-06}, {"id": 366, "seek": 208716, "start": 2087.16, "end": 2092.08, "text": " get files, it did not appear in thunder all.", "tokens": [483, 7098, 11, 309, 630, 406, 4204, 294, 19898, 439, 13], "temperature": 0.0, "avg_logprob": -0.3100699391858331, "compression_ratio": 1.4054054054054055, "no_speech_prob": 7.002094548624882e-07}, {"id": 367, "seek": 208716, "start": 2092.08, "end": 2095.92, "text": " And the reason for that is that by default, anything that starts with an underscore is", "tokens": [400, 264, 1778, 337, 300, 307, 300, 538, 7576, 11, 1340, 300, 3719, 365, 364, 37556, 307], "temperature": 0.0, "avg_logprob": -0.3100699391858331, "compression_ratio": 1.4054054054054055, "no_speech_prob": 7.002094548624882e-07}, {"id": 368, "seek": 208716, "start": 2095.92, "end": 2099.16, "text": " not exported by fastai.", "tokens": [406, 42055, 538, 2370, 1301, 13], "temperature": 0.0, "avg_logprob": -0.3100699391858331, "compression_ratio": 1.4054054054054055, "no_speech_prob": 7.002094548624882e-07}, {"id": 369, "seek": 208716, "start": 2099.16, "end": 2102.2, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.3100699391858331, "compression_ratio": 1.4054054054054055, "no_speech_prob": 7.002094548624882e-07}, {"id": 370, "seek": 208716, "start": 2102.2, "end": 2106.44, "text": " So this is just a little function that will...", "tokens": [407, 341, 307, 445, 257, 707, 2445, 300, 486, 485], "temperature": 0.0, "avg_logprob": -0.3100699391858331, "compression_ratio": 1.4054054054054055, "no_speech_prob": 7.002094548624882e-07}, {"id": 371, "seek": 210644, "start": 2106.44, "end": 2117.68, "text": " Let's see, we're being passed a bunch of files to look at.", "tokens": [961, 311, 536, 11, 321, 434, 885, 4678, 257, 3840, 295, 7098, 281, 574, 412, 13], "temperature": 0.0, "avg_logprob": -0.1068057506642443, "compression_ratio": 1.812807881773399, "no_speech_prob": 8.664478627906647e-06}, {"id": 372, "seek": 210644, "start": 2117.68, "end": 2122.76, "text": " And so we're just going to turn them into pathlib.path objects.", "tokens": [400, 370, 321, 434, 445, 516, 281, 1261, 552, 666, 3100, 38270, 13, 31852, 6565, 13], "temperature": 0.0, "avg_logprob": -0.1068057506642443, "compression_ratio": 1.812807881773399, "no_speech_prob": 8.664478627906647e-06}, {"id": 373, "seek": 210644, "start": 2122.76, "end": 2126.28, "text": " We don't include things that start with dot because we're hidden.", "tokens": [492, 500, 380, 4090, 721, 300, 722, 365, 5893, 570, 321, 434, 7633, 13], "temperature": 0.0, "avg_logprob": -0.1068057506642443, "compression_ratio": 1.812807881773399, "no_speech_prob": 8.664478627906647e-06}, {"id": 374, "seek": 210644, "start": 2126.28, "end": 2131.92, "text": " We also make sure that the extension appears in the extensions list or that you didn't", "tokens": [492, 611, 652, 988, 300, 264, 10320, 7038, 294, 264, 25129, 1329, 420, 300, 291, 994, 380], "temperature": 0.0, "avg_logprob": -0.1068057506642443, "compression_ratio": 1.812807881773399, "no_speech_prob": 8.664478627906647e-06}, {"id": 375, "seek": 210644, "start": 2131.92, "end": 2135.08, "text": " include an extension list because if you didn't include an extension list, it means we don't", "tokens": [4090, 364, 10320, 1329, 570, 498, 291, 994, 380, 4090, 364, 10320, 1329, 11, 309, 1355, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.1068057506642443, "compression_ratio": 1.812807881773399, "no_speech_prob": 8.664478627906647e-06}, {"id": 376, "seek": 213508, "start": 2135.08, "end": 2138.08, "text": " care.", "tokens": [1127, 13], "temperature": 0.0, "avg_logprob": -0.18821608714568308, "compression_ratio": 1.4739583333333333, "no_speech_prob": 2.2252513645071303e-06}, {"id": 377, "seek": 213508, "start": 2138.08, "end": 2146.12, "text": " Then get files, the key thing is to understand how os.walk works, which we briefly mentioned", "tokens": [1396, 483, 7098, 11, 264, 2141, 551, 307, 281, 1223, 577, 3003, 13, 12490, 1985, 11, 597, 321, 10515, 2835], "temperature": 0.0, "avg_logprob": -0.18821608714568308, "compression_ratio": 1.4739583333333333, "no_speech_prob": 2.2252513645071303e-06}, {"id": 378, "seek": 213508, "start": 2146.12, "end": 2149.16, "text": " in the fastai courses.", "tokens": [294, 264, 2370, 1301, 7712, 13], "temperature": 0.0, "avg_logprob": -0.18821608714568308, "compression_ratio": 1.4739583333333333, "no_speech_prob": 2.2252513645071303e-06}, {"id": 379, "seek": 213508, "start": 2149.16, "end": 2150.7599999999998, "text": " So look it up if you want some details.", "tokens": [407, 574, 309, 493, 498, 291, 528, 512, 4365, 13], "temperature": 0.0, "avg_logprob": -0.18821608714568308, "compression_ratio": 1.4739583333333333, "no_speech_prob": 2.2252513645071303e-06}, {"id": 380, "seek": 213508, "start": 2150.7599999999998, "end": 2158.12, "text": " Basically, os.walk is a ridiculously fast Python API for very, very, very rapidly looking", "tokens": [8537, 11, 3003, 13, 12490, 307, 257, 41358, 2370, 15329, 9362, 337, 588, 11, 588, 11, 588, 12910, 1237], "temperature": 0.0, "avg_logprob": -0.18821608714568308, "compression_ratio": 1.4739583333333333, "no_speech_prob": 2.2252513645071303e-06}, {"id": 381, "seek": 213508, "start": 2158.12, "end": 2160.24, "text": " for things on your file system.", "tokens": [337, 721, 322, 428, 3991, 1185, 13], "temperature": 0.0, "avg_logprob": -0.18821608714568308, "compression_ratio": 1.4739583333333333, "no_speech_prob": 2.2252513645071303e-06}, {"id": 382, "seek": 216024, "start": 2160.24, "end": 2165.4799999999996, "text": " And get files, we spent a lot of time optimizing this and get files can run on the entirety", "tokens": [400, 483, 7098, 11, 321, 4418, 257, 688, 295, 565, 40425, 341, 293, 483, 7098, 393, 1190, 322, 264, 31557], "temperature": 0.0, "avg_logprob": -0.13698772283700797, "compression_ratio": 1.49, "no_speech_prob": 3.844843831757316e-06}, {"id": 383, "seek": 216024, "start": 2165.4799999999996, "end": 2170.16, "text": " of ImageNet to grab all 1.3 million files in just a few seconds.", "tokens": [295, 29903, 31890, 281, 4444, 439, 502, 13, 18, 2459, 7098, 294, 445, 257, 1326, 3949, 13], "temperature": 0.0, "avg_logprob": -0.13698772283700797, "compression_ratio": 1.49, "no_speech_prob": 3.844843831757316e-06}, {"id": 384, "seek": 216024, "start": 2170.16, "end": 2173.8399999999997, "text": " I think it was like eight seconds or something.", "tokens": [286, 519, 309, 390, 411, 3180, 3949, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.13698772283700797, "compression_ratio": 1.49, "no_speech_prob": 3.844843831757316e-06}, {"id": 385, "seek": 216024, "start": 2173.8399999999997, "end": 2183.6, "text": " There's no limit on how many files that can be, except of course the memory on your computer.", "tokens": [821, 311, 572, 4948, 322, 577, 867, 7098, 300, 393, 312, 11, 3993, 295, 1164, 264, 4675, 322, 428, 3820, 13], "temperature": 0.0, "avg_logprob": -0.13698772283700797, "compression_ratio": 1.49, "no_speech_prob": 3.844843831757316e-06}, {"id": 386, "seek": 218360, "start": 2183.6, "end": 2191.12, "text": " So remember then that the way we kind of demonstrate functionality in the documentation is generally", "tokens": [407, 1604, 550, 300, 264, 636, 321, 733, 295, 11698, 14980, 294, 264, 14333, 307, 5101], "temperature": 0.0, "avg_logprob": -0.18552975905568977, "compression_ratio": 1.5449735449735449, "no_speech_prob": 5.255205905996263e-06}, {"id": 387, "seek": 218360, "start": 2191.12, "end": 2196.2999999999997, "text": " through tests.", "tokens": [807, 6921, 13], "temperature": 0.0, "avg_logprob": -0.18552975905568977, "compression_ratio": 1.5449735449735449, "no_speech_prob": 5.255205905996263e-06}, {"id": 388, "seek": 218360, "start": 2196.2999999999997, "end": 2205.88, "text": " So the test here is we're going to grab all of the PNG files in train slash three in MNIST.", "tokens": [407, 264, 1500, 510, 307, 321, 434, 516, 281, 4444, 439, 295, 264, 430, 30237, 7098, 294, 3847, 17330, 1045, 294, 376, 45, 19756, 13], "temperature": 0.0, "avg_logprob": -0.18552975905568977, "compression_ratio": 1.5449735449735449, "no_speech_prob": 5.255205905996263e-06}, {"id": 389, "seek": 218360, "start": 2205.88, "end": 2212.2799999999997, "text": " So and in three and in seven, in the MNIST sample, that's the entirety of the images", "tokens": [407, 293, 294, 1045, 293, 294, 3407, 11, 294, 264, 376, 45, 19756, 6889, 11, 300, 311, 264, 31557, 295, 264, 5267], "temperature": 0.0, "avg_logprob": -0.18552975905568977, "compression_ratio": 1.5449735449735449, "no_speech_prob": 5.255205905996263e-06}, {"id": 390, "seek": 221228, "start": 2212.28, "end": 2219.6400000000003, "text": " that we have, so we do things like make sure that the number of images in the parent when", "tokens": [300, 321, 362, 11, 370, 321, 360, 721, 411, 652, 988, 300, 264, 1230, 295, 5267, 294, 264, 2596, 562], "temperature": 0.0, "avg_logprob": -0.13461334364754812, "compression_ratio": 1.53, "no_speech_prob": 4.784901648235973e-06}, {"id": 391, "seek": 221228, "start": 2219.6400000000003, "end": 2225.52, "text": " you use recursion is equal to both of the child, children, stuff like that.", "tokens": [291, 764, 20560, 313, 307, 2681, 281, 1293, 295, 264, 1440, 11, 2227, 11, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.13461334364754812, "compression_ratio": 1.53, "no_speech_prob": 4.784901648235973e-06}, {"id": 392, "seek": 221228, "start": 2225.52, "end": 2228.1600000000003, "text": " And then we also just print out a few examples.", "tokens": [400, 550, 321, 611, 445, 4482, 484, 257, 1326, 5110, 13], "temperature": 0.0, "avg_logprob": -0.13461334364754812, "compression_ratio": 1.53, "no_speech_prob": 4.784901648235973e-06}, {"id": 393, "seek": 221228, "start": 2228.1600000000003, "end": 2235.5600000000004, "text": " And as you can see, like most things in fastai, we're getting back a capital L, an L object,", "tokens": [400, 382, 291, 393, 536, 11, 411, 881, 721, 294, 2370, 1301, 11, 321, 434, 1242, 646, 257, 4238, 441, 11, 364, 441, 2657, 11], "temperature": 0.0, "avg_logprob": -0.13461334364754812, "compression_ratio": 1.53, "no_speech_prob": 4.784901648235973e-06}, {"id": 394, "seek": 223556, "start": 2235.56, "end": 2243.32, "text": " so you can see how big it is and it shows you a subset of some of the paths that are", "tokens": [370, 291, 393, 536, 577, 955, 309, 307, 293, 309, 3110, 291, 257, 25993, 295, 512, 295, 264, 14518, 300, 366], "temperature": 0.0, "avg_logprob": -0.23612474840740824, "compression_ratio": 1.5545023696682465, "no_speech_prob": 3.2376071885664715e-06}, {"id": 395, "seek": 223556, "start": 2243.32, "end": 2245.32, "text": " in it.", "tokens": [294, 309, 13], "temperature": 0.0, "avg_logprob": -0.23612474840740824, "compression_ratio": 1.5545023696682465, "no_speech_prob": 3.2376071885664715e-06}, {"id": 396, "seek": 223556, "start": 2245.32, "end": 2246.32, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.23612474840740824, "compression_ratio": 1.5545023696682465, "no_speech_prob": 3.2376071885664715e-06}, {"id": 397, "seek": 223556, "start": 2246.32, "end": 2253.24, "text": " So sometimes we kind of have additional checks that probably aren't that interesting for", "tokens": [407, 2171, 321, 733, 295, 362, 4497, 13834, 300, 1391, 3212, 380, 300, 1880, 337], "temperature": 0.0, "avg_logprob": -0.23612474840740824, "compression_ratio": 1.5545023696682465, "no_speech_prob": 3.2376071885664715e-06}, {"id": 398, "seek": 223556, "start": 2253.24, "end": 2256.48, "text": " documentation purposes, but are just useful as tests.", "tokens": [14333, 9932, 11, 457, 366, 445, 4420, 382, 6921, 13], "temperature": 0.0, "avg_logprob": -0.23612474840740824, "compression_ratio": 1.5545023696682465, "no_speech_prob": 3.2376071885664715e-06}, {"id": 399, "seek": 223556, "start": 2256.48, "end": 2260.84, "text": " And when that happens, we add hash hide to the top of our cell and that'll cause it not", "tokens": [400, 562, 300, 2314, 11, 321, 909, 22019, 6479, 281, 264, 1192, 295, 527, 2815, 293, 300, 603, 3082, 309, 406], "temperature": 0.0, "avg_logprob": -0.23612474840740824, "compression_ratio": 1.5545023696682465, "no_speech_prob": 3.2376071885664715e-06}, {"id": 400, "seek": 226084, "start": 2260.84, "end": 2265.92, "text": " to be included in the docs.", "tokens": [281, 312, 5556, 294, 264, 45623, 13], "temperature": 0.0, "avg_logprob": -0.27337347942849866, "compression_ratio": 1.7358490566037736, "no_speech_prob": 2.2958865883992985e-06}, {"id": 401, "seek": 226084, "start": 2265.92, "end": 2268.92, "text": " So let's have a look.", "tokens": [407, 718, 311, 362, 257, 574, 13], "temperature": 0.0, "avg_logprob": -0.27337347942849866, "compression_ratio": 1.7358490566037736, "no_speech_prob": 2.2958865883992985e-06}, {"id": 402, "seek": 226084, "start": 2268.92, "end": 2271.92, "text": " Data core.", "tokens": [11888, 4965, 13], "temperature": 0.0, "avg_logprob": -0.27337347942849866, "compression_ratio": 1.7358490566037736, "no_speech_prob": 2.2958865883992985e-06}, {"id": 403, "seek": 226084, "start": 2271.92, "end": 2283.48, "text": " So if we have a look at get files, so you can see here's the output, the HTML output", "tokens": [407, 498, 321, 362, 257, 574, 412, 483, 7098, 11, 370, 291, 393, 536, 510, 311, 264, 5598, 11, 264, 17995, 5598], "temperature": 0.0, "avg_logprob": -0.27337347942849866, "compression_ratio": 1.7358490566037736, "no_speech_prob": 2.2958865883992985e-06}, {"id": 404, "seek": 226084, "start": 2283.48, "end": 2284.48, "text": " of what we were just seeing.", "tokens": [295, 437, 321, 645, 445, 2577, 13], "temperature": 0.0, "avg_logprob": -0.27337347942849866, "compression_ratio": 1.7358490566037736, "no_speech_prob": 2.2958865883992985e-06}, {"id": 405, "seek": 226084, "start": 2284.48, "end": 2287.36, "text": " This is the most general way, blah, blah, blah.", "tokens": [639, 307, 264, 881, 2674, 636, 11, 12288, 11, 12288, 11, 12288, 13], "temperature": 0.0, "avg_logprob": -0.27337347942849866, "compression_ratio": 1.7358490566037736, "no_speech_prob": 2.2958865883992985e-06}, {"id": 406, "seek": 226084, "start": 2287.36, "end": 2289.7200000000003, "text": " This is the most general way, blah, blah, blah.", "tokens": [639, 307, 264, 881, 2674, 636, 11, 12288, 11, 12288, 11, 12288, 13], "temperature": 0.0, "avg_logprob": -0.27337347942849866, "compression_ratio": 1.7358490566037736, "no_speech_prob": 2.2958865883992985e-06}, {"id": 407, "seek": 226084, "start": 2289.7200000000003, "end": 2290.7200000000003, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.27337347942849866, "compression_ratio": 1.7358490566037736, "no_speech_prob": 2.2958865883992985e-06}, {"id": 408, "seek": 229072, "start": 2290.72, "end": 2294.9199999999996, "text": " So you can see that the first set of tests and stuff are shown here.", "tokens": [407, 291, 393, 536, 300, 264, 700, 992, 295, 6921, 293, 1507, 366, 4898, 510, 13], "temperature": 0.0, "avg_logprob": -0.20566862137591252, "compression_ratio": 1.4110429447852761, "no_speech_prob": 3.3930884910660097e-06}, {"id": 409, "seek": 229072, "start": 2294.9199999999996, "end": 2302.2799999999997, "text": " The output is shown here, but the hash hide version is not shown.", "tokens": [440, 5598, 307, 4898, 510, 11, 457, 264, 22019, 6479, 3037, 307, 406, 4898, 13], "temperature": 0.0, "avg_logprob": -0.20566862137591252, "compression_ratio": 1.4110429447852761, "no_speech_prob": 3.3930884910660097e-06}, {"id": 410, "seek": 229072, "start": 2302.2799999999997, "end": 2305.2799999999997, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.20566862137591252, "compression_ratio": 1.4110429447852761, "no_speech_prob": 3.3930884910660097e-06}, {"id": 411, "seek": 229072, "start": 2305.2799999999997, "end": 2314.56, "text": " As we've discussed before, in order to kind of easily get partial functions, we sometimes", "tokens": [1018, 321, 600, 7152, 949, 11, 294, 1668, 281, 733, 295, 3612, 483, 14641, 6828, 11, 321, 2171], "temperature": 0.0, "avg_logprob": -0.20566862137591252, "compression_ratio": 1.4110429447852761, "no_speech_prob": 3.3930884910660097e-06}, {"id": 412, "seek": 231456, "start": 2314.56, "end": 2326.36, "text": " define things which, that's a bit smaller, we sometimes define functions that return", "tokens": [6964, 721, 597, 11, 300, 311, 257, 857, 4356, 11, 321, 2171, 6964, 6828, 300, 2736], "temperature": 0.0, "avg_logprob": -0.18808993248090353, "compression_ratio": 1.5138121546961325, "no_speech_prob": 1.5294025388357113e-06}, {"id": 413, "seek": 231456, "start": 2326.36, "end": 2327.36, "text": " functions.", "tokens": [6828, 13], "temperature": 0.0, "avg_logprob": -0.18808993248090353, "compression_ratio": 1.5138121546961325, "no_speech_prob": 1.5294025388357113e-06}, {"id": 414, "seek": 231456, "start": 2327.36, "end": 2332.7599999999998, "text": " So here's a nice easy way to say, oh, this is going to create a function that non recursively", "tokens": [407, 510, 311, 257, 1481, 1858, 636, 281, 584, 11, 1954, 11, 341, 307, 516, 281, 1884, 257, 2445, 300, 2107, 20560, 3413], "temperature": 0.0, "avg_logprob": -0.18808993248090353, "compression_ratio": 1.5138121546961325, "no_speech_prob": 1.5294025388357113e-06}, {"id": 415, "seek": 231456, "start": 2332.7599999999998, "end": 2336.2799999999997, "text": " searches for PNG files, for instance.", "tokens": [26701, 337, 430, 30237, 7098, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.18808993248090353, "compression_ratio": 1.5138121546961325, "no_speech_prob": 1.5294025388357113e-06}, {"id": 416, "seek": 231456, "start": 2336.2799999999997, "end": 2340.56, "text": " So then its behavior is just like what we saw.", "tokens": [407, 550, 1080, 5223, 307, 445, 411, 437, 321, 1866, 13], "temperature": 0.0, "avg_logprob": -0.18808993248090353, "compression_ratio": 1.5138121546961325, "no_speech_prob": 1.5294025388357113e-06}, {"id": 417, "seek": 234056, "start": 2340.56, "end": 2349.56, "text": " So this is really doing something very similar to just doing a partial function in Python.", "tokens": [407, 341, 307, 534, 884, 746, 588, 2531, 281, 445, 884, 257, 14641, 2445, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.22165989875793457, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.788048621165217e-06}, {"id": 418, "seek": 234056, "start": 2349.56, "end": 2358.0, "text": " To get image files, we just call get files passing in image extensions, which is everything", "tokens": [1407, 483, 3256, 7098, 11, 321, 445, 818, 483, 7098, 8437, 294, 3256, 25129, 11, 597, 307, 1203], "temperature": 0.0, "avg_logprob": -0.22165989875793457, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.788048621165217e-06}, {"id": 419, "seek": 234056, "start": 2358.0, "end": 2364.44, "text": " in mime types that starts with image.", "tokens": [294, 275, 1312, 3467, 300, 3719, 365, 3256, 13], "temperature": 0.0, "avg_logprob": -0.22165989875793457, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.788048621165217e-06}, {"id": 420, "seek": 236444, "start": 2364.44, "end": 2372.2400000000002, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.132398479125079, "compression_ratio": 1.5342465753424657, "no_speech_prob": 8.664551387482788e-06}, {"id": 421, "seek": 236444, "start": 2372.2400000000002, "end": 2374.36, "text": " So then we can test that one.", "tokens": [407, 550, 321, 393, 1500, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.132398479125079, "compression_ratio": 1.5342465753424657, "no_speech_prob": 8.664551387482788e-06}, {"id": 422, "seek": 236444, "start": 2374.36, "end": 2380.68, "text": " So image getter is the same as a file getter, but we get image files.", "tokens": [407, 3256, 483, 391, 307, 264, 912, 382, 257, 3991, 483, 391, 11, 457, 321, 483, 3256, 7098, 13], "temperature": 0.0, "avg_logprob": -0.132398479125079, "compression_ratio": 1.5342465753424657, "no_speech_prob": 8.664551387482788e-06}, {"id": 423, "seek": 236444, "start": 2380.68, "end": 2382.0, "text": " Just that one.", "tokens": [1449, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.132398479125079, "compression_ratio": 1.5342465753424657, "no_speech_prob": 8.664551387482788e-06}, {"id": 424, "seek": 236444, "start": 2382.0, "end": 2383.0, "text": " And so there you go.", "tokens": [400, 370, 456, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.132398479125079, "compression_ratio": 1.5342465753424657, "no_speech_prob": 8.664551387482788e-06}, {"id": 425, "seek": 236444, "start": 2383.0, "end": 2390.88, "text": " So there's the whole of the functionality that currently exists for getting items.", "tokens": [407, 456, 311, 264, 1379, 295, 264, 14980, 300, 4362, 8198, 337, 1242, 4754, 13], "temperature": 0.0, "avg_logprob": -0.132398479125079, "compression_ratio": 1.5342465753424657, "no_speech_prob": 8.664551387482788e-06}, {"id": 426, "seek": 239088, "start": 2390.88, "end": 2395.08, "text": " And I can imagine we'll add more of those over time.", "tokens": [400, 286, 393, 3811, 321, 603, 909, 544, 295, 729, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.2361801802509963, "compression_ratio": 1.6785714285714286, "no_speech_prob": 7.646461199328769e-06}, {"id": 427, "seek": 239088, "start": 2395.08, "end": 2397.2400000000002, "text": " But that's a good start.", "tokens": [583, 300, 311, 257, 665, 722, 13], "temperature": 0.0, "avg_logprob": -0.2361801802509963, "compression_ratio": 1.6785714285714286, "no_speech_prob": 7.646461199328769e-06}, {"id": 428, "seek": 239088, "start": 2397.2400000000002, "end": 2400.32, "text": " So the second thing we need is functions for creating splits.", "tokens": [407, 264, 1150, 551, 321, 643, 307, 6828, 337, 4084, 37741, 13], "temperature": 0.0, "avg_logprob": -0.2361801802509963, "compression_ratio": 1.6785714285714286, "no_speech_prob": 7.646461199328769e-06}, {"id": 429, "seek": 239088, "start": 2400.32, "end": 2407.2000000000003, "text": " And these are just things that return two lists, the list of stuff in the training set", "tokens": [400, 613, 366, 445, 721, 300, 2736, 732, 14511, 11, 264, 1329, 295, 1507, 294, 264, 3097, 992], "temperature": 0.0, "avg_logprob": -0.2361801802509963, "compression_ratio": 1.6785714285714286, "no_speech_prob": 7.646461199328769e-06}, {"id": 430, "seek": 239088, "start": 2407.2000000000003, "end": 2408.96, "text": " and the list of stuff in the validation set.", "tokens": [293, 264, 1329, 295, 1507, 294, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.2361801802509963, "compression_ratio": 1.6785714285714286, "no_speech_prob": 7.646461199328769e-06}, {"id": 431, "seek": 239088, "start": 2408.96, "end": 2415.4, "text": " So for example, a random spitter is something which returns a function.", "tokens": [407, 337, 1365, 11, 257, 4974, 637, 3904, 307, 746, 597, 11247, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.2361801802509963, "compression_ratio": 1.6785714285714286, "no_speech_prob": 7.646461199328769e-06}, {"id": 432, "seek": 239088, "start": 2415.4, "end": 2417.6, "text": " Optionally you can set the seed.", "tokens": [29284, 379, 291, 393, 992, 264, 8871, 13], "temperature": 0.0, "avg_logprob": -0.2361801802509963, "compression_ratio": 1.6785714285714286, "no_speech_prob": 7.646461199328769e-06}, {"id": 433, "seek": 241760, "start": 2417.6, "end": 2426.64, "text": " And it's just going to randomly commute all of your indexes and then cut it at wherever", "tokens": [400, 309, 311, 445, 516, 281, 16979, 36750, 439, 295, 428, 8186, 279, 293, 550, 1723, 309, 412, 8660], "temperature": 0.0, "avg_logprob": -0.23474543949343124, "compression_ratio": 1.3741007194244603, "no_speech_prob": 7.29630983187235e-06}, {"id": 434, "seek": 241760, "start": 2426.64, "end": 2431.92, "text": " you asked for and then return those two halves.", "tokens": [291, 2351, 337, 293, 550, 2736, 729, 732, 38490, 13], "temperature": 0.0, "avg_logprob": -0.23474543949343124, "compression_ratio": 1.3741007194244603, "no_speech_prob": 7.29630983187235e-06}, {"id": 435, "seek": 241760, "start": 2431.92, "end": 2437.64, "text": " So there you can see.", "tokens": [407, 456, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.23474543949343124, "compression_ratio": 1.3741007194244603, "no_speech_prob": 7.29630983187235e-06}, {"id": 436, "seek": 241760, "start": 2437.64, "end": 2442.8399999999997, "text": " And so some simple tests of that.", "tokens": [400, 370, 512, 2199, 6921, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.23474543949343124, "compression_ratio": 1.3741007194244603, "no_speech_prob": 7.29630983187235e-06}, {"id": 437, "seek": 244284, "start": 2442.84, "end": 2448.0, "text": " Splitter is something which looks at the parent of the parent.", "tokens": [19788, 3904, 307, 746, 597, 1542, 412, 264, 2596, 295, 264, 2596, 13], "temperature": 0.0, "avg_logprob": -0.1665469636308386, "compression_ratio": 1.5829383886255923, "no_speech_prob": 1.280514698009938e-05}, {"id": 438, "seek": 244284, "start": 2448.0, "end": 2450.8, "text": " So like an MNIST or an ImageNet.", "tokens": [407, 411, 364, 376, 45, 19756, 420, 364, 29903, 31890, 13], "temperature": 0.0, "avg_logprob": -0.1665469636308386, "compression_ratio": 1.5829383886255923, "no_speech_prob": 1.280514698009938e-05}, {"id": 439, "seek": 244284, "start": 2450.8, "end": 2455.6000000000004, "text": " That would be where the path would be valid or train.", "tokens": [663, 576, 312, 689, 264, 3100, 576, 312, 7363, 420, 3847, 13], "temperature": 0.0, "avg_logprob": -0.1665469636308386, "compression_ratio": 1.5829383886255923, "no_speech_prob": 1.280514698009938e-05}, {"id": 440, "seek": 244284, "start": 2455.6000000000004, "end": 2462.88, "text": " So that's that.", "tokens": [407, 300, 311, 300, 13], "temperature": 0.0, "avg_logprob": -0.1665469636308386, "compression_ratio": 1.5829383886255923, "no_speech_prob": 1.280514698009938e-05}, {"id": 441, "seek": 244284, "start": 2462.88, "end": 2464.28, "text": " And so that all works the way you expect.", "tokens": [400, 370, 300, 439, 1985, 264, 636, 291, 2066, 13], "temperature": 0.0, "avg_logprob": -0.1665469636308386, "compression_ratio": 1.5829383886255923, "no_speech_prob": 1.280514698009938e-05}, {"id": 442, "seek": 244284, "start": 2464.28, "end": 2468.0, "text": " So as you can see, these functions are super tiny.", "tokens": [407, 382, 291, 393, 536, 11, 613, 6828, 366, 1687, 5870, 13], "temperature": 0.0, "avg_logprob": -0.1665469636308386, "compression_ratio": 1.5829383886255923, "no_speech_prob": 1.280514698009938e-05}, {"id": 443, "seek": 244284, "start": 2468.0, "end": 2472.5, "text": " And so generally if you want to know more detail about how something works.", "tokens": [400, 370, 5101, 498, 291, 528, 281, 458, 544, 2607, 466, 577, 746, 1985, 13], "temperature": 0.0, "avg_logprob": -0.1665469636308386, "compression_ratio": 1.5829383886255923, "no_speech_prob": 1.280514698009938e-05}, {"id": 444, "seek": 247250, "start": 2472.5, "end": 2476.32, "text": " And we should add more documentation obviously to some of this stuff as well.", "tokens": [400, 321, 820, 909, 544, 14333, 2745, 281, 512, 295, 341, 1507, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.21222065113208913, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.665738616604358e-06}, {"id": 445, "seek": 247250, "start": 2476.32, "end": 2478.28, "text": " It's still early days.", "tokens": [467, 311, 920, 2440, 1708, 13], "temperature": 0.0, "avg_logprob": -0.21222065113208913, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.665738616604358e-06}, {"id": 446, "seek": 247250, "start": 2478.28, "end": 2483.56, "text": " Feel free to send in PRs with docs if you're interested.", "tokens": [14113, 1737, 281, 2845, 294, 11568, 82, 365, 45623, 498, 291, 434, 3102, 13], "temperature": 0.0, "avg_logprob": -0.21222065113208913, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.665738616604358e-06}, {"id": 447, "seek": 247250, "start": 2483.56, "end": 2493.1, "text": " So good question from Kevin about what if you wanted to get audio files, for instance.", "tokens": [407, 665, 1168, 490, 9954, 466, 437, 498, 291, 1415, 281, 483, 6278, 7098, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.21222065113208913, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.665738616604358e-06}, {"id": 448, "seek": 247250, "start": 2493.1, "end": 2499.44, "text": " I think I would probably put that in an audio module.", "tokens": [286, 519, 286, 576, 1391, 829, 300, 294, 364, 6278, 10088, 13], "temperature": 0.0, "avg_logprob": -0.21222065113208913, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.665738616604358e-06}, {"id": 449, "seek": 247250, "start": 2499.44, "end": 2500.44, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.21222065113208913, "compression_ratio": 1.4545454545454546, "no_speech_prob": 9.665738616604358e-06}, {"id": 450, "seek": 250044, "start": 2500.44, "end": 2504.4, "text": " I don't feel super strongly about it though.", "tokens": [286, 500, 380, 841, 1687, 10613, 466, 309, 1673, 13], "temperature": 0.0, "avg_logprob": -0.23391814183707188, "compression_ratio": 1.5887445887445888, "no_speech_prob": 7.183124580478761e-06}, {"id": 451, "seek": 250044, "start": 2504.4, "end": 2509.92, "text": " It would probably make more sense to get image files actually to be in vision.core.", "tokens": [467, 576, 1391, 652, 544, 2020, 281, 483, 3256, 7098, 767, 281, 312, 294, 5201, 13, 12352, 13], "temperature": 0.0, "avg_logprob": -0.23391814183707188, "compression_ratio": 1.5887445887445888, "no_speech_prob": 7.183124580478761e-06}, {"id": 452, "seek": 250044, "start": 2509.92, "end": 2512.84, "text": " Now I think about it.", "tokens": [823, 286, 519, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.23391814183707188, "compression_ratio": 1.5887445887445888, "no_speech_prob": 7.183124580478761e-06}, {"id": 453, "seek": 250044, "start": 2512.84, "end": 2513.84, "text": " But yeah.", "tokens": [583, 1338, 13], "temperature": 0.0, "avg_logprob": -0.23391814183707188, "compression_ratio": 1.5887445887445888, "no_speech_prob": 7.183124580478761e-06}, {"id": 454, "seek": 250044, "start": 2513.84, "end": 2516.0, "text": " Yeah, probably easy to have.", "tokens": [865, 11, 1391, 1858, 281, 362, 13], "temperature": 0.0, "avg_logprob": -0.23391814183707188, "compression_ratio": 1.5887445887445888, "no_speech_prob": 7.183124580478761e-06}, {"id": 455, "seek": 250044, "start": 2516.0, "end": 2521.32, "text": " Probably better to have everything for an application in an application module.", "tokens": [9210, 1101, 281, 362, 1203, 337, 364, 3861, 294, 364, 3861, 10088, 13], "temperature": 0.0, "avg_logprob": -0.23391814183707188, "compression_ratio": 1.5887445887445888, "no_speech_prob": 7.183124580478761e-06}, {"id": 456, "seek": 250044, "start": 2521.32, "end": 2523.12, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.23391814183707188, "compression_ratio": 1.5887445887445888, "no_speech_prob": 7.183124580478761e-06}, {"id": 457, "seek": 250044, "start": 2523.12, "end": 2530.2200000000003, "text": " So labeling is the thing which will, for example, take a path and pull the label out of it.", "tokens": [407, 40244, 307, 264, 551, 597, 486, 11, 337, 1365, 11, 747, 257, 3100, 293, 2235, 264, 7645, 484, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.23391814183707188, "compression_ratio": 1.5887445887445888, "no_speech_prob": 7.183124580478761e-06}, {"id": 458, "seek": 253022, "start": 2530.22, "end": 2536.8199999999997, "text": " So a parent label, for instance, we'll just label it with the name of the parent.", "tokens": [407, 257, 2596, 7645, 11, 337, 5197, 11, 321, 603, 445, 7645, 309, 365, 264, 1315, 295, 264, 2596, 13], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 459, "seek": 253022, "start": 2536.8199999999997, "end": 2538.68, "text": " So there's nothing to customize in this case.", "tokens": [407, 456, 311, 1825, 281, 19734, 294, 341, 1389, 13], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 460, "seek": 253022, "start": 2538.68, "end": 2541.3999999999996, "text": " So we don't need a capital letter thing that returns a function.", "tokens": [407, 321, 500, 380, 643, 257, 4238, 5063, 551, 300, 11247, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 461, "seek": 253022, "start": 2541.3999999999996, "end": 2544.08, "text": " We can just call it directly.", "tokens": [492, 393, 445, 818, 309, 3838, 13], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 462, "seek": 253022, "start": 2544.08, "end": 2548.7599999999998, "text": " Where else red checks label are, we actually need to pass in a pattern for what red checks", "tokens": [2305, 1646, 2182, 13834, 7645, 366, 11, 321, 767, 643, 281, 1320, 294, 257, 5102, 337, 437, 2182, 13834], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 463, "seek": 253022, "start": 2548.7599999999998, "end": 2549.7599999999998, "text": " to label with.", "tokens": [281, 7645, 365, 13], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 464, "seek": 253022, "start": 2549.7599999999998, "end": 2555.04, "text": " So that's why it's a capital thing which returns a function.", "tokens": [407, 300, 311, 983, 309, 311, 257, 4238, 551, 597, 11247, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 465, "seek": 253022, "start": 2555.04, "end": 2557.6, "text": " So here's what red checks label looks like.", "tokens": [407, 510, 311, 437, 2182, 13834, 7645, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 466, "seek": 253022, "start": 2557.6, "end": 2559.8399999999997, "text": " So remember if you want to really understand how these things work.", "tokens": [407, 1604, 498, 291, 528, 281, 534, 1223, 577, 613, 721, 589, 13], "temperature": 0.0, "avg_logprob": -0.15740984268770872, "compression_ratio": 1.8419117647058822, "no_speech_prob": 1.593622255313676e-05}, {"id": 467, "seek": 255984, "start": 2559.84, "end": 2564.6800000000003, "text": " If any of them are confusing, open up the notebook and just like we do in the fast AI", "tokens": [759, 604, 295, 552, 366, 13181, 11, 1269, 493, 264, 21060, 293, 445, 411, 321, 360, 294, 264, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.33624323005350226, "compression_ratio": 1.7136563876651982, "no_speech_prob": 6.643225788138807e-06}, {"id": 468, "seek": 255984, "start": 2564.6800000000003, "end": 2567.44, "text": " lessons, you know, experiment.", "tokens": [8820, 11, 291, 458, 11, 5120, 13], "temperature": 0.0, "avg_logprob": -0.33624323005350226, "compression_ratio": 1.7136563876651982, "no_speech_prob": 6.643225788138807e-06}, {"id": 469, "seek": 255984, "start": 2567.44, "end": 2568.44, "text": " Try some other tests.", "tokens": [6526, 512, 661, 6921, 13], "temperature": 0.0, "avg_logprob": -0.33624323005350226, "compression_ratio": 1.7136563876651982, "no_speech_prob": 6.643225788138807e-06}, {"id": 470, "seek": 255984, "start": 2568.44, "end": 2573.2000000000003, "text": " You know, add some cells to the docs and try things out.", "tokens": [509, 458, 11, 909, 512, 5438, 281, 264, 45623, 293, 853, 721, 484, 13], "temperature": 0.0, "avg_logprob": -0.33624323005350226, "compression_ratio": 1.7136563876651982, "no_speech_prob": 6.643225788138807e-06}, {"id": 471, "seek": 255984, "start": 2573.2000000000003, "end": 2575.48, "text": " You know, so you're like, oh, what's in items?", "tokens": [509, 458, 11, 370, 291, 434, 411, 11, 1954, 11, 437, 311, 294, 4754, 30], "temperature": 0.0, "avg_logprob": -0.33624323005350226, "compression_ratio": 1.7136563876651982, "no_speech_prob": 6.643225788138807e-06}, {"id": 472, "seek": 255984, "start": 2575.48, "end": 2576.88, "text": " And there they all are.", "tokens": [400, 456, 436, 439, 366, 13], "temperature": 0.0, "avg_logprob": -0.33624323005350226, "compression_ratio": 1.7136563876651982, "no_speech_prob": 6.643225788138807e-06}, {"id": 473, "seek": 255984, "start": 2576.88, "end": 2584.2400000000002, "text": " And it's like, oh, so what if we f items zero.", "tokens": [400, 309, 311, 411, 11, 1954, 11, 370, 437, 498, 321, 283, 4754, 4018, 13], "temperature": 0.0, "avg_logprob": -0.33624323005350226, "compression_ratio": 1.7136563876651982, "no_speech_prob": 6.643225788138807e-06}, {"id": 474, "seek": 255984, "start": 2584.2400000000002, "end": 2588.4, "text": " You know, lots of experimenting, lots of debugging, all that kind of stuff.", "tokens": [509, 458, 11, 3195, 295, 29070, 11, 3195, 295, 45592, 11, 439, 300, 733, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.33624323005350226, "compression_ratio": 1.7136563876651982, "no_speech_prob": 6.643225788138807e-06}, {"id": 475, "seek": 258840, "start": 2588.4, "end": 2591.2400000000002, "text": " All right, so those are three basic steps.", "tokens": [1057, 558, 11, 370, 729, 366, 1045, 3875, 4439, 13], "temperature": 0.0, "avg_logprob": -0.2677142842610677, "compression_ratio": 1.4325842696629214, "no_speech_prob": 1.130066993937362e-05}, {"id": 476, "seek": 258840, "start": 2591.2400000000002, "end": 2597.96, "text": " GetsBitLabel, they're all very easy functions.", "tokens": [460, 1385, 33, 270, 43, 18657, 11, 436, 434, 439, 588, 1858, 6828, 13], "temperature": 0.0, "avg_logprob": -0.2677142842610677, "compression_ratio": 1.4325842696629214, "no_speech_prob": 1.130066993937362e-05}, {"id": 477, "seek": 258840, "start": 2597.96, "end": 2606.0, "text": " So categorize is a thing that we have already used in 08.", "tokens": [407, 19250, 1125, 307, 257, 551, 300, 321, 362, 1217, 1143, 294, 1958, 23, 13], "temperature": 0.0, "avg_logprob": -0.2677142842610677, "compression_ratio": 1.4325842696629214, "no_speech_prob": 1.130066993937362e-05}, {"id": 478, "seek": 258840, "start": 2606.0, "end": 2610.2000000000003, "text": " So to remind you, and so we're going to create something called category.create which is", "tokens": [407, 281, 4160, 291, 11, 293, 370, 321, 434, 516, 281, 1884, 746, 1219, 7719, 13, 14066, 473, 597, 307], "temperature": 0.0, "avg_logprob": -0.2677142842610677, "compression_ratio": 1.4325842696629214, "no_speech_prob": 1.130066993937362e-05}, {"id": 479, "seek": 258840, "start": 2610.2000000000003, "end": 2612.2400000000002, "text": " simply categorize.", "tokens": [2935, 19250, 1125, 13], "temperature": 0.0, "avg_logprob": -0.2677142842610677, "compression_ratio": 1.4325842696629214, "no_speech_prob": 1.130066993937362e-05}, {"id": 480, "seek": 261224, "start": 2612.24, "end": 2618.56, "text": " So when you see category.create, that's actually creating a categorize object.", "tokens": [407, 562, 291, 536, 7719, 13, 14066, 473, 11, 300, 311, 767, 4084, 257, 19250, 1125, 2657, 13], "temperature": 0.0, "avg_logprob": -0.22248663418534873, "compression_ratio": 1.5575757575757576, "no_speech_prob": 4.637832716980483e-06}, {"id": 481, "seek": 261224, "start": 2618.56, "end": 2623.7599999999998, "text": " So for instance, if we create a transform data set, which goes cat dog cat, there's", "tokens": [407, 337, 5197, 11, 498, 321, 1884, 257, 4088, 1412, 992, 11, 597, 1709, 3857, 3000, 3857, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.22248663418534873, "compression_ratio": 1.5575757575757576, "no_speech_prob": 4.637832716980483e-06}, {"id": 482, "seek": 261224, "start": 2623.7599999999998, "end": 2632.7, "text": " the items in it and the transforms is this categorize.", "tokens": [264, 4754, 294, 309, 293, 264, 35592, 307, 341, 19250, 1125, 13], "temperature": 0.0, "avg_logprob": -0.22248663418534873, "compression_ratio": 1.5575757575757576, "no_speech_prob": 4.637832716980483e-06}, {"id": 483, "seek": 261224, "start": 2632.7, "end": 2636.06, "text": " And then here we can test its behavior.", "tokens": [400, 550, 510, 321, 393, 1500, 1080, 5223, 13], "temperature": 0.0, "avg_logprob": -0.22248663418534873, "compression_ratio": 1.5575757575757576, "no_speech_prob": 4.637832716980483e-06}, {"id": 484, "seek": 263606, "start": 2636.06, "end": 2642.72, "text": " So the vocabulary from those items should be cat dog, for instance.", "tokens": [407, 264, 19864, 490, 729, 4754, 820, 312, 3857, 3000, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.2421749786094383, "compression_ratio": 1.6726457399103138, "no_speech_prob": 1.4823366427663132e-06}, {"id": 485, "seek": 263606, "start": 2642.72, "end": 2646.36, "text": " The transformed version of cat should be zero.", "tokens": [440, 16894, 3037, 295, 3857, 820, 312, 4018, 13], "temperature": 0.0, "avg_logprob": -0.2421749786094383, "compression_ratio": 1.6726457399103138, "no_speech_prob": 1.4823366427663132e-06}, {"id": 486, "seek": 263606, "start": 2646.36, "end": 2651.32, "text": " The decoded version of one should be dog and so on.", "tokens": [440, 979, 12340, 3037, 295, 472, 820, 312, 3000, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.2421749786094383, "compression_ratio": 1.6726457399103138, "no_speech_prob": 1.4823366427663132e-06}, {"id": 487, "seek": 263606, "start": 2651.32, "end": 2654.04, "text": " So Edurand's question is, should there be a hash test?", "tokens": [407, 3977, 374, 474, 311, 1168, 307, 11, 820, 456, 312, 257, 22019, 1500, 30], "temperature": 0.0, "avg_logprob": -0.2421749786094383, "compression_ratio": 1.6726457399103138, "no_speech_prob": 1.4823366427663132e-06}, {"id": 488, "seek": 263606, "start": 2654.04, "end": 2655.48, "text": " No, we don't need hash test.", "tokens": [883, 11, 321, 500, 380, 643, 22019, 1500, 13], "temperature": 0.0, "avg_logprob": -0.2421749786094383, "compression_ratio": 1.6726457399103138, "no_speech_prob": 1.4823366427663132e-06}, {"id": 489, "seek": 263606, "start": 2655.48, "end": 2657.72, "text": " As you can see, they just appear directly.", "tokens": [1018, 291, 393, 536, 11, 436, 445, 4204, 3838, 13], "temperature": 0.0, "avg_logprob": -0.2421749786094383, "compression_ratio": 1.6726457399103138, "no_speech_prob": 1.4823366427663132e-06}, {"id": 490, "seek": 263606, "start": 2657.72, "end": 2660.52, "text": " So we don't need to add anything to say this is a test.", "tokens": [407, 321, 500, 380, 643, 281, 909, 1340, 281, 584, 341, 307, 257, 1500, 13], "temperature": 0.0, "avg_logprob": -0.2421749786094383, "compression_ratio": 1.6726457399103138, "no_speech_prob": 1.4823366427663132e-06}, {"id": 491, "seek": 263606, "start": 2660.52, "end": 2662.24, "text": " You just include tests.", "tokens": [509, 445, 4090, 6921, 13], "temperature": 0.0, "avg_logprob": -0.2421749786094383, "compression_ratio": 1.6726457399103138, "no_speech_prob": 1.4823366427663132e-06}, {"id": 492, "seek": 266224, "start": 2662.24, "end": 2670.0, "text": " If a test doesn't pass, let's make one that doesn't pass.", "tokens": [759, 257, 1500, 1177, 380, 1320, 11, 718, 311, 652, 472, 300, 1177, 380, 1320, 13], "temperature": 0.0, "avg_logprob": -0.3667333629769339, "compression_ratio": 1.4324324324324325, "no_speech_prob": 1.2679146266236785e-06}, {"id": 493, "seek": 266224, "start": 2670.0, "end": 2676.16, "text": " Dog, dog, then you get an error.", "tokens": [13472, 11, 3000, 11, 550, 291, 483, 364, 6713, 13], "temperature": 0.0, "avg_logprob": -0.3667333629769339, "compression_ratio": 1.4324324324324325, "no_speech_prob": 1.2679146266236785e-06}, {"id": 494, "seek": 266224, "start": 2676.16, "end": 2678.64, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.3667333629769339, "compression_ratio": 1.4324324324324325, "no_speech_prob": 1.2679146266236785e-06}, {"id": 495, "seek": 266224, "start": 2678.64, "end": 2688.72, "text": " And as we mentioned last time, in class.dei.dev, in the read me,", "tokens": [400, 382, 321, 2835, 1036, 565, 11, 294, 1508, 13, 1479, 72, 13, 40343, 11, 294, 264, 1401, 385, 11], "temperature": 0.0, "avg_logprob": -0.3667333629769339, "compression_ratio": 1.4324324324324325, "no_speech_prob": 1.2679146266236785e-06}, {"id": 496, "seek": 266224, "start": 2688.72, "end": 2691.3999999999996, "text": " is the line that will run the notebooks in parallel.", "tokens": [307, 264, 1622, 300, 486, 1190, 264, 43782, 294, 8952, 13], "temperature": 0.0, "avg_logprob": -0.3667333629769339, "compression_ratio": 1.4324324324324325, "no_speech_prob": 1.2679146266236785e-06}, {"id": 497, "seek": 269140, "start": 2691.4, "end": 2694.92, "text": " And if any of them fail, in fact, I just ran it before and one of them", "tokens": [400, 498, 604, 295, 552, 3061, 11, 294, 1186, 11, 286, 445, 5872, 309, 949, 293, 472, 295, 552], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 498, "seek": 269140, "start": 2694.92, "end": 2696.28, "text": " failed, so I can show you.", "tokens": [7612, 11, 370, 286, 393, 855, 291, 13], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 499, "seek": 269140, "start": 2699.1600000000003, "end": 2699.88, "text": " Here we are.", "tokens": [1692, 321, 366, 13], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 500, "seek": 269140, "start": 2699.88, "end": 2701.62, "text": " If one of them fails, it looks like this.", "tokens": [759, 472, 295, 552, 18199, 11, 309, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 501, "seek": 269140, "start": 2701.62, "end": 2704.88, "text": " Exception in blah, blah, blah, dot ipo mb.", "tokens": [2111, 7311, 294, 12288, 11, 12288, 11, 12288, 11, 5893, 28501, 78, 275, 65, 13], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 502, "seek": 269140, "start": 2704.88, "end": 2708.82, "text": " And then it'll show you the stack trace.", "tokens": [400, 550, 309, 603, 855, 291, 264, 8630, 13508, 13], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 503, "seek": 269140, "start": 2708.82, "end": 2713.52, "text": " And then it'll show you there.", "tokens": [400, 550, 309, 603, 855, 291, 456, 13], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 504, "seek": 269140, "start": 2713.52, "end": 2715.8, "text": " So that's how tests work.", "tokens": [407, 300, 311, 577, 6921, 589, 13], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 505, "seek": 269140, "start": 2715.8, "end": 2719.36, "text": " Tests are just regular cells, which happen", "tokens": [314, 4409, 366, 445, 3890, 5438, 11, 597, 1051], "temperature": 0.0, "avg_logprob": -0.2777949152766047, "compression_ratio": 1.6884422110552764, "no_speech_prob": 2.8408818252501078e-05}, {"id": 506, "seek": 271936, "start": 2719.36, "end": 2724.52, "text": " to have something which has an assertion in, basically.", "tokens": [281, 362, 746, 597, 575, 364, 19810, 313, 294, 11, 1936, 13], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 507, "seek": 271936, "start": 2724.52, "end": 2725.6800000000003, "text": " That's all test ec is.", "tokens": [663, 311, 439, 1500, 11437, 307, 13], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 508, "seek": 271936, "start": 2725.6800000000003, "end": 2729.2400000000002, "text": " We'll get to the 0, 0 test notebook eventually.", "tokens": [492, 603, 483, 281, 264, 1958, 11, 1958, 1500, 21060, 4728, 13], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 509, "seek": 271936, "start": 2729.2400000000002, "end": 2733.32, "text": " And so how do we get coverage tests?", "tokens": [400, 370, 577, 360, 321, 483, 9645, 6921, 30], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 510, "seek": 271936, "start": 2733.32, "end": 2734.04, "text": " No idea.", "tokens": [883, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 511, "seek": 271936, "start": 2734.04, "end": 2736.7200000000003, "text": " It's not something I've thought about.", "tokens": [467, 311, 406, 746, 286, 600, 1194, 466, 13], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 512, "seek": 271936, "start": 2736.7200000000003, "end": 2738.96, "text": " That would be an interesting question to look at.", "tokens": [663, 576, 312, 364, 1880, 1168, 281, 574, 412, 13], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 513, "seek": 271936, "start": 2742.48, "end": 2744.36, "text": " It's not something I've cared about so much,", "tokens": [467, 311, 406, 746, 286, 600, 19779, 466, 370, 709, 11], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 514, "seek": 271936, "start": 2744.36, "end": 2746.36, "text": " though, I must say, because the tests always", "tokens": [1673, 11, 286, 1633, 584, 11, 570, 264, 6921, 1009], "temperature": 0.0, "avg_logprob": -0.1812810805237409, "compression_ratio": 1.6175115207373272, "no_speech_prob": 5.422151843959e-06}, {"id": 515, "seek": 274636, "start": 2746.36, "end": 2749.32, "text": " sit right next to the thing that they're testing.", "tokens": [1394, 558, 958, 281, 264, 551, 300, 436, 434, 4997, 13], "temperature": 0.0, "avg_logprob": -0.200749138991038, "compression_ratio": 1.5868544600938967, "no_speech_prob": 6.85413306200644e-06}, {"id": 516, "seek": 274636, "start": 2749.32, "end": 2752.6400000000003, "text": " So it's really hard to have functionality that's not tested.", "tokens": [407, 309, 311, 534, 1152, 281, 362, 14980, 300, 311, 406, 8246, 13], "temperature": 0.0, "avg_logprob": -0.200749138991038, "compression_ratio": 1.5868544600938967, "no_speech_prob": 6.85413306200644e-06}, {"id": 517, "seek": 274636, "start": 2752.6400000000003, "end": 2754.94, "text": " It tends to be pretty obvious because you're kind of staring", "tokens": [467, 12258, 281, 312, 1238, 6322, 570, 291, 434, 733, 295, 18043], "temperature": 0.0, "avg_logprob": -0.200749138991038, "compression_ratio": 1.5868544600938967, "no_speech_prob": 6.85413306200644e-06}, {"id": 518, "seek": 274636, "start": 2754.94, "end": 2756.04, "text": " at it on the same screen.", "tokens": [412, 309, 322, 264, 912, 2568, 13], "temperature": 0.0, "avg_logprob": -0.200749138991038, "compression_ratio": 1.5868544600938967, "no_speech_prob": 6.85413306200644e-06}, {"id": 519, "seek": 274636, "start": 2759.7200000000003, "end": 2766.2400000000002, "text": " OK, so a categorize is a transform.", "tokens": [2264, 11, 370, 257, 19250, 1125, 307, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.200749138991038, "compression_ratio": 1.5868544600938967, "no_speech_prob": 6.85413306200644e-06}, {"id": 520, "seek": 274636, "start": 2766.2400000000002, "end": 2770.44, "text": " So therefore, it has an encodes and a decodes.", "tokens": [407, 4412, 11, 309, 575, 364, 2058, 4789, 293, 257, 979, 4789, 13], "temperature": 0.0, "avg_logprob": -0.200749138991038, "compression_ratio": 1.5868544600938967, "no_speech_prob": 6.85413306200644e-06}, {"id": 521, "seek": 274636, "start": 2770.44, "end": 2775.2000000000003, "text": " So when you create it, so that's just calling categorize,", "tokens": [407, 562, 291, 1884, 309, 11, 370, 300, 311, 445, 5141, 19250, 1125, 11], "temperature": 0.0, "avg_logprob": -0.200749138991038, "compression_ratio": 1.5868544600938967, "no_speech_prob": 6.85413306200644e-06}, {"id": 522, "seek": 277520, "start": 2775.2, "end": 2780.48, "text": " it's just a normal Python object here.", "tokens": [309, 311, 445, 257, 2710, 15329, 2657, 510, 13], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 523, "seek": 277520, "start": 2780.48, "end": 2781.3199999999997, "text": " So it's done to inner.", "tokens": [407, 309, 311, 1096, 281, 7284, 13], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 524, "seek": 277520, "start": 2781.3199999999997, "end": 2783.8399999999997, "text": " It works in the usual way.", "tokens": [467, 1985, 294, 264, 7713, 636, 13], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 525, "seek": 277520, "start": 2783.8399999999997, "end": 2786.96, "text": " So you can actually create it with a predefined vocab", "tokens": [407, 291, 393, 767, 1884, 309, 365, 257, 659, 37716, 2329, 455], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 526, "seek": 277520, "start": 2786.96, "end": 2787.52, "text": " if you like.", "tokens": [498, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 527, "seek": 277520, "start": 2787.52, "end": 2790.2, "text": " And if so, it'll assign it.", "tokens": [400, 498, 370, 11, 309, 603, 6269, 309, 13], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 528, "seek": 277520, "start": 2790.2, "end": 2798.04, "text": " If not, then it's going to use this special setup method.", "tokens": [759, 406, 11, 550, 309, 311, 516, 281, 764, 341, 2121, 8657, 3170, 13], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 529, "seek": 277520, "start": 2798.04, "end": 2799.8799999999997, "text": " When does setup get called?", "tokens": [1133, 775, 8657, 483, 1219, 30], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 530, "seek": 277520, "start": 2799.8799999999997, "end": 2803.48, "text": " Well, you can see here when we create a tiffmds,", "tokens": [1042, 11, 291, 393, 536, 510, 562, 321, 1884, 257, 256, 3661, 76, 16063, 11], "temperature": 0.0, "avg_logprob": -0.1677641081578523, "compression_ratio": 1.5071090047393365, "no_speech_prob": 2.947978828160558e-06}, {"id": 531, "seek": 280348, "start": 2803.48, "end": 2807.04, "text": " we're saying this is the list of items", "tokens": [321, 434, 1566, 341, 307, 264, 1329, 295, 4754], "temperature": 0.0, "avg_logprob": -0.2105908570466218, "compression_ratio": 1.5741935483870968, "no_speech_prob": 4.637791334971553e-06}, {"id": 532, "seek": 280348, "start": 2807.04, "end": 2810.32, "text": " that we want to use with these transforms.", "tokens": [300, 321, 528, 281, 764, 365, 613, 35592, 13], "temperature": 0.0, "avg_logprob": -0.2105908570466218, "compression_ratio": 1.5741935483870968, "no_speech_prob": 4.637791334971553e-06}, {"id": 533, "seek": 280348, "start": 2810.32, "end": 2821.92, "text": " So tiffmds is going to, let's see,", "tokens": [407, 256, 3661, 76, 16063, 307, 516, 281, 11, 718, 311, 536, 11], "temperature": 0.0, "avg_logprob": -0.2105908570466218, "compression_ratio": 1.5741935483870968, "no_speech_prob": 4.637791334971553e-06}, {"id": 534, "seek": 280348, "start": 2821.92, "end": 2825.56, "text": " what's the best way to show you this.", "tokens": [437, 311, 264, 1151, 636, 281, 855, 291, 341, 13], "temperature": 0.0, "avg_logprob": -0.2105908570466218, "compression_ratio": 1.5741935483870968, "no_speech_prob": 4.637791334971553e-06}, {"id": 535, "seek": 280348, "start": 2825.56, "end": 2828.6, "text": " Actually, it's going to create a number of tiffm lists.", "tokens": [5135, 11, 309, 311, 516, 281, 1884, 257, 1230, 295, 256, 3661, 76, 14511, 13], "temperature": 0.0, "avg_logprob": -0.2105908570466218, "compression_ratio": 1.5741935483870968, "no_speech_prob": 4.637791334971553e-06}, {"id": 536, "seek": 280348, "start": 2828.6, "end": 2829.96, "text": " So we want to look at tiffm list.", "tokens": [407, 321, 528, 281, 574, 412, 256, 3661, 76, 1329, 13], "temperature": 0.0, "avg_logprob": -0.2105908570466218, "compression_ratio": 1.5741935483870968, "no_speech_prob": 4.637791334971553e-06}, {"id": 537, "seek": 282996, "start": 2829.96, "end": 2833.2, "text": " And so here you can see tiffm list in init", "tokens": [400, 370, 510, 291, 393, 536, 256, 3661, 76, 1329, 294, 3157], "temperature": 0.0, "avg_logprob": -0.2963190880891319, "compression_ratio": 1.696969696969697, "no_speech_prob": 9.368542123411316e-06}, {"id": 538, "seek": 282996, "start": 2833.2, "end": 2835.44, "text": " will call self.setup.", "tokens": [486, 818, 2698, 13, 3854, 1010, 13], "temperature": 0.0, "avg_logprob": -0.2963190880891319, "compression_ratio": 1.696969696969697, "no_speech_prob": 9.368542123411316e-06}, {"id": 539, "seek": 282996, "start": 2835.44, "end": 2840.36, "text": " And self.setup will set up your transforms.", "tokens": [400, 2698, 13, 3854, 1010, 486, 992, 493, 428, 35592, 13], "temperature": 0.0, "avg_logprob": -0.2963190880891319, "compression_ratio": 1.696969696969697, "no_speech_prob": 9.368542123411316e-06}, {"id": 540, "seek": 282996, "start": 2840.36, "end": 2844.96, "text": " And so that's the thing which is going to call setup,", "tokens": [400, 370, 300, 311, 264, 551, 597, 307, 516, 281, 818, 8657, 11], "temperature": 0.0, "avg_logprob": -0.2963190880891319, "compression_ratio": 1.696969696969697, "no_speech_prob": 9.368542123411316e-06}, {"id": 541, "seek": 282996, "start": 2844.96, "end": 2850.44, "text": " which in this case will set your vocab to a category map.", "tokens": [597, 294, 341, 1389, 486, 992, 428, 2329, 455, 281, 257, 7719, 4471, 13], "temperature": 0.0, "avg_logprob": -0.2963190880891319, "compression_ratio": 1.696969696969697, "no_speech_prob": 9.368542123411316e-06}, {"id": 542, "seek": 282996, "start": 2850.44, "end": 2851.64, "text": " We'll look at it in a moment.", "tokens": [492, 603, 574, 412, 309, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.2963190880891319, "compression_ratio": 1.696969696969697, "no_speech_prob": 9.368542123411316e-06}, {"id": 543, "seek": 282996, "start": 2851.64, "end": 2854.7200000000003, "text": " This is to map the vocab of categories.", "tokens": [639, 307, 281, 4471, 264, 2329, 455, 295, 10479, 13], "temperature": 0.0, "avg_logprob": -0.2963190880891319, "compression_ratio": 1.696969696969697, "no_speech_prob": 9.368542123411316e-06}, {"id": 544, "seek": 282996, "start": 2854.7200000000003, "end": 2857.36, "text": " And it will use, this is a nice little idiom,", "tokens": [400, 309, 486, 764, 11, 341, 307, 257, 1481, 707, 18014, 298, 11], "temperature": 0.0, "avg_logprob": -0.2963190880891319, "compression_ratio": 1.696969696969697, "no_speech_prob": 9.368542123411316e-06}, {"id": 545, "seek": 285736, "start": 2857.36, "end": 2862.76, "text": " it will use dsource.train if dsource has a train attribute.", "tokens": [309, 486, 764, 274, 41676, 13, 83, 7146, 498, 274, 41676, 575, 257, 3847, 19667, 13], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 546, "seek": 285736, "start": 2862.76, "end": 2865.2000000000003, "text": " If it doesn't, it'll just use dsource.", "tokens": [759, 309, 1177, 380, 11, 309, 603, 445, 764, 274, 41676, 13], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 547, "seek": 285736, "start": 2865.2000000000003, "end": 2868.28, "text": " It'll use your training set if there's a training set defined.", "tokens": [467, 603, 764, 428, 3097, 992, 498, 456, 311, 257, 3097, 992, 7642, 13], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 548, "seek": 285736, "start": 2868.28, "end": 2873.52, "text": " Otherwise, it'll just use the whole data source.", "tokens": [10328, 11, 309, 603, 445, 764, 264, 1379, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 549, "seek": 285736, "start": 2873.52, "end": 2875.84, "text": " So that's a super important idea.", "tokens": [407, 300, 311, 257, 1687, 1021, 1558, 13], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 550, "seek": 285736, "start": 2875.84, "end": 2877.04, "text": " This is setup thing.", "tokens": [639, 307, 8657, 551, 13], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 551, "seek": 285736, "start": 2877.04, "end": 2878.48, "text": " We'll see more details of that when", "tokens": [492, 603, 536, 544, 4365, 295, 300, 562], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 552, "seek": 285736, "start": 2878.48, "end": 2881.32, "text": " we look at the code for pipeline and tiffmdl,", "tokens": [321, 574, 412, 264, 3089, 337, 15517, 293, 256, 3661, 76, 67, 75, 11], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 553, "seek": 285736, "start": 2881.32, "end": 2883.6400000000003, "text": " tiffmds, tiffm list.", "tokens": [256, 3661, 76, 16063, 11, 256, 3661, 76, 1329, 13], "temperature": 0.0, "avg_logprob": -0.3175319413007316, "compression_ratio": 1.727699530516432, "no_speech_prob": 9.665839570516255e-06}, {"id": 554, "seek": 288364, "start": 2883.64, "end": 2890.8799999999997, "text": " You'll see that decodes is saying that I want to return", "tokens": [509, 603, 536, 300, 979, 4789, 307, 1566, 300, 286, 528, 281, 2736], "temperature": 0.0, "avg_logprob": -0.5047417563953619, "compression_ratio": 2.230769230769231, "no_speech_prob": 3.966914391639875e-06}, {"id": 555, "seek": 288364, "start": 2890.8799999999997, "end": 2893.44, "text": " something of type category.", "tokens": [746, 295, 2010, 7719, 13], "temperature": 0.0, "avg_logprob": -0.5047417563953619, "compression_ratio": 2.230769230769231, "no_speech_prob": 3.966914391639875e-06}, {"id": 556, "seek": 288364, "start": 2893.44, "end": 2896.24, "text": " And that has a category.create.", "tokens": [400, 300, 575, 257, 7719, 13, 14066, 473, 13], "temperature": 0.0, "avg_logprob": -0.5047417563953619, "compression_ratio": 2.230769230769231, "no_speech_prob": 3.966914391639875e-06}, {"id": 557, "seek": 288364, "start": 2896.24, "end": 2902.6, "text": " And a category is pretty tiny.", "tokens": [400, 257, 7719, 307, 1238, 5870, 13], "temperature": 0.0, "avg_logprob": -0.5047417563953619, "compression_ratio": 2.230769230769231, "no_speech_prob": 3.966914391639875e-06}, {"id": 558, "seek": 288364, "start": 2902.6, "end": 2904.96, "text": " It's inheriting from show title.", "tokens": [467, 311, 9484, 1748, 490, 855, 4876, 13], "temperature": 0.0, "avg_logprob": -0.5047417563953619, "compression_ratio": 2.230769230769231, "no_speech_prob": 3.966914391639875e-06}, {"id": 559, "seek": 288364, "start": 2904.96, "end": 2907.52, "text": " And it's inheriting from show title.", "tokens": [400, 309, 311, 9484, 1748, 490, 855, 4876, 13], "temperature": 0.0, "avg_logprob": -0.5047417563953619, "compression_ratio": 2.230769230769231, "no_speech_prob": 3.966914391639875e-06}, {"id": 560, "seek": 288364, "start": 2907.52, "end": 2909.52, "text": " And it's inheriting from show title.", "tokens": [400, 309, 311, 9484, 1748, 490, 855, 4876, 13], "temperature": 0.0, "avg_logprob": -0.5047417563953619, "compression_ratio": 2.230769230769231, "no_speech_prob": 3.966914391639875e-06}, {"id": 561, "seek": 288364, "start": 2909.52, "end": 2911.52, "text": " And it's inheriting from show title.", "tokens": [400, 309, 311, 9484, 1748, 490, 855, 4876, 13], "temperature": 0.0, "avg_logprob": -0.5047417563953619, "compression_ratio": 2.230769230769231, "no_speech_prob": 3.966914391639875e-06}, {"id": 562, "seek": 291152, "start": 2911.52, "end": 2915.0, "text": " And it's inheriting from show title.", "tokens": [400, 309, 311, 9484, 1748, 490, 855, 4876, 13], "temperature": 0.0, "avg_logprob": -0.18067000893985524, "compression_ratio": 1.597883597883598, "no_speech_prob": 5.255280484561808e-06}, {"id": 563, "seek": 291152, "start": 2915.0, "end": 2918.4, "text": " Which simply has a show method, as you would expect.", "tokens": [3013, 2935, 575, 257, 855, 3170, 11, 382, 291, 576, 2066, 13], "temperature": 0.0, "avg_logprob": -0.18067000893985524, "compression_ratio": 1.597883597883598, "no_speech_prob": 5.255280484561808e-06}, {"id": 564, "seek": 291152, "start": 2921.72, "end": 2926.04, "text": " And show title is going to show passing in the keyword", "tokens": [400, 855, 4876, 307, 516, 281, 855, 8437, 294, 264, 20428], "temperature": 0.0, "avg_logprob": -0.18067000893985524, "compression_ratio": 1.597883597883598, "no_speech_prob": 5.255280484561808e-06}, {"id": 565, "seek": 291152, "start": 2926.04, "end": 2930.24, "text": " arguments that are in self.underscore show args.", "tokens": [12869, 300, 366, 294, 2698, 13, 997, 433, 12352, 855, 3882, 82, 13], "temperature": 0.0, "avg_logprob": -0.18067000893985524, "compression_ratio": 1.597883597883598, "no_speech_prob": 5.255280484561808e-06}, {"id": 566, "seek": 291152, "start": 2930.24, "end": 2934.68, "text": " So in this case, it's going to label it with the category.", "tokens": [407, 294, 341, 1389, 11, 309, 311, 516, 281, 7645, 309, 365, 264, 7719, 13], "temperature": 0.0, "avg_logprob": -0.18067000893985524, "compression_ratio": 1.597883597883598, "no_speech_prob": 5.255280484561808e-06}, {"id": 567, "seek": 291152, "start": 2937.2, "end": 2940.6, "text": " So the only other piece here is the category map.", "tokens": [407, 264, 787, 661, 2522, 510, 307, 264, 7719, 4471, 13], "temperature": 0.0, "avg_logprob": -0.18067000893985524, "compression_ratio": 1.597883597883598, "no_speech_prob": 5.255280484561808e-06}, {"id": 568, "seek": 294060, "start": 2940.6, "end": 2943.16, "text": " And the category map is just simply something", "tokens": [400, 264, 7719, 4471, 307, 445, 2935, 746], "temperature": 0.0, "avg_logprob": -0.12685491016932895, "compression_ratio": 1.5174418604651163, "no_speech_prob": 3.2887057841435308e-06}, {"id": 569, "seek": 294060, "start": 2943.16, "end": 2951.4, "text": " which will grab all of the unique values in your column,", "tokens": [597, 486, 4444, 439, 295, 264, 3845, 4190, 294, 428, 7738, 11], "temperature": 0.0, "avg_logprob": -0.12685491016932895, "compression_ratio": 1.5174418604651163, "no_speech_prob": 3.2887057841435308e-06}, {"id": 570, "seek": 294060, "start": 2951.4, "end": 2952.64, "text": " optionally sort them.", "tokens": [3614, 379, 1333, 552, 13], "temperature": 0.0, "avg_logprob": -0.12685491016932895, "compression_ratio": 1.5174418604651163, "no_speech_prob": 3.2887057841435308e-06}, {"id": 571, "seek": 294060, "start": 2958.7999999999997, "end": 2960.72, "text": " And then we'll also create the object", "tokens": [400, 550, 321, 603, 611, 1884, 264, 2657], "temperature": 0.0, "avg_logprob": -0.12685491016932895, "compression_ratio": 1.5174418604651163, "no_speech_prob": 3.2887057841435308e-06}, {"id": 572, "seek": 294060, "start": 2960.72, "end": 2964.2799999999997, "text": " to int, which is simply the opposite direction.", "tokens": [281, 560, 11, 597, 307, 2935, 264, 6182, 3513, 13], "temperature": 0.0, "avg_logprob": -0.12685491016932895, "compression_ratio": 1.5174418604651163, "no_speech_prob": 3.2887057841435308e-06}, {"id": 573, "seek": 296428, "start": 2964.28, "end": 2974.84, "text": " So l has a value to index, which is a reverse map.", "tokens": [407, 287, 575, 257, 2158, 281, 8186, 11, 597, 307, 257, 9943, 4471, 13], "temperature": 0.0, "avg_logprob": -0.2523707983628759, "compression_ratio": 1.3253968253968254, "no_speech_prob": 1.0845097904166323e-06}, {"id": 574, "seek": 296428, "start": 2974.84, "end": 2978.2000000000003, "text": " OK, so that's category.", "tokens": [2264, 11, 370, 300, 311, 7719, 13], "temperature": 0.0, "avg_logprob": -0.2523707983628759, "compression_ratio": 1.3253968253968254, "no_speech_prob": 1.0845097904166323e-06}, {"id": 575, "seek": 296428, "start": 2978.2000000000003, "end": 2982.6400000000003, "text": " So Hector's question about the videos", "tokens": [407, 389, 20814, 311, 1168, 466, 264, 2145], "temperature": 0.0, "avg_logprob": -0.2523707983628759, "compression_ratio": 1.3253968253968254, "no_speech_prob": 1.0845097904166323e-06}, {"id": 576, "seek": 296428, "start": 2982.6400000000003, "end": 2993.76, "text": " reminds me to talk about the forum, which is I was to,", "tokens": [12025, 385, 281, 751, 466, 264, 17542, 11, 597, 307, 286, 390, 281, 11], "temperature": 0.0, "avg_logprob": -0.2523707983628759, "compression_ratio": 1.3253968253968254, "no_speech_prob": 1.0845097904166323e-06}, {"id": 577, "seek": 299376, "start": 2993.76, "end": 2998.36, "text": " thanks to people who contributed notes and other things.", "tokens": [3231, 281, 561, 567, 18434, 5570, 293, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.27197367079714513, "compression_ratio": 1.3153846153846154, "no_speech_prob": 2.7693374704540474e-06}, {"id": 578, "seek": 299376, "start": 2998.36, "end": 3002.96, "text": " I was trying to think about how to structure this.", "tokens": [286, 390, 1382, 281, 519, 466, 577, 281, 3877, 341, 13], "temperature": 0.0, "avg_logprob": -0.27197367079714513, "compression_ratio": 1.3153846153846154, "no_speech_prob": 2.7693374704540474e-06}, {"id": 579, "seek": 299376, "start": 3002.96, "end": 3019.5600000000004, "text": " What we might do is let's create a fastai v2 code walkthrough2.", "tokens": [708, 321, 1062, 360, 307, 718, 311, 1884, 257, 2370, 1301, 371, 17, 3089, 1792, 11529, 17, 13], "temperature": 0.0, "avg_logprob": -0.27197367079714513, "compression_ratio": 1.3153846153846154, "no_speech_prob": 2.7693374704540474e-06}, {"id": 580, "seek": 301956, "start": 3019.56, "end": 3029.52, "text": " I use this to walk through two notes, questions,", "tokens": [286, 764, 341, 281, 1792, 807, 732, 5570, 11, 1651, 11], "temperature": 0.0, "avg_logprob": -0.24629545211791992, "compression_ratio": 1.4304635761589404, "no_speech_prob": 1.3006648259761278e-05}, {"id": 581, "seek": 301956, "start": 3029.52, "end": 3034.6, "text": " and expression after query.", "tokens": [293, 6114, 934, 14581, 13], "temperature": 0.0, "avg_logprob": -0.24629545211791992, "compression_ratio": 1.4304635761589404, "no_speech_prob": 1.3006648259761278e-05}, {"id": 582, "seek": 301956, "start": 3034.6, "end": 3036.96, "text": " So let's make that into a wiki.", "tokens": [407, 718, 311, 652, 300, 666, 257, 261, 9850, 13], "temperature": 0.0, "avg_logprob": -0.24629545211791992, "compression_ratio": 1.4304635761589404, "no_speech_prob": 1.3006648259761278e-05}, {"id": 583, "seek": 301956, "start": 3039.7999999999997, "end": 3043.56, "text": " And so now that would be a good place to put notes.", "tokens": [400, 370, 586, 300, 576, 312, 257, 665, 1081, 281, 829, 5570, 13], "temperature": 0.0, "avg_logprob": -0.24629545211791992, "compression_ratio": 1.4304635761589404, "no_speech_prob": 1.3006648259761278e-05}, {"id": 584, "seek": 301956, "start": 3043.56, "end": 3048.72, "text": " And so this good set of notes are ready for number one,", "tokens": [400, 370, 341, 665, 992, 295, 5570, 366, 1919, 337, 1230, 472, 11], "temperature": 0.0, "avg_logprob": -0.24629545211791992, "compression_ratio": 1.4304635761589404, "no_speech_prob": 1.3006648259761278e-05}, {"id": 585, "seek": 304872, "start": 3048.72, "end": 3052.2, "text": " thanks to Elena on it post.", "tokens": [3231, 281, 39603, 322, 309, 2183, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 586, "seek": 304872, "start": 3052.2, "end": 3053.7999999999997, "text": " They're not quite complete yet.", "tokens": [814, 434, 406, 1596, 3566, 1939, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 587, "seek": 304872, "start": 3053.7999999999997, "end": 3056.64, "text": " So either Elena or somebody else can hopefully", "tokens": [407, 2139, 39603, 420, 2618, 1646, 393, 4696], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 588, "seek": 304872, "start": 3056.64, "end": 3057.8799999999997, "text": " finish off the last bit.", "tokens": [2413, 766, 264, 1036, 857, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 589, "seek": 304872, "start": 3057.8799999999997, "end": 3060.2, "text": " But it looks like maybe they are complete now.", "tokens": [583, 309, 1542, 411, 1310, 436, 366, 3566, 586, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 590, "seek": 304872, "start": 3060.2, "end": 3061.3599999999997, "text": " Ah, there you go.", "tokens": [2438, 11, 456, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 591, "seek": 304872, "start": 3061.3599999999997, "end": 3063.68, "text": " She's done some more than since I last looked.", "tokens": [1240, 311, 1096, 512, 544, 813, 1670, 286, 1036, 2956, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 592, "seek": 304872, "start": 3063.68, "end": 3064.9199999999996, "text": " Very nice.", "tokens": [4372, 1481, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 593, "seek": 304872, "start": 3064.9199999999996, "end": 3066.04, "text": " OK, so it is finished.", "tokens": [2264, 11, 370, 309, 307, 4335, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 594, "seek": 304872, "start": 3066.04, "end": 3067.3599999999997, "text": " Beautiful.", "tokens": [14724, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 595, "seek": 304872, "start": 3067.3599999999997, "end": 3073.4399999999996, "text": " So it's a bit tricky in the forums", "tokens": [407, 309, 311, 257, 857, 12414, 294, 264, 26998], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 596, "seek": 304872, "start": 3073.4399999999996, "end": 3076.9199999999996, "text": " if multiple people edit the same wiki post at the same time.", "tokens": [498, 3866, 561, 8129, 264, 912, 261, 9850, 2183, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 597, "seek": 304872, "start": 3076.9199999999996, "end": 3078.24, "text": " You'll get conflicts.", "tokens": [509, 603, 483, 19807, 13], "temperature": 0.0, "avg_logprob": -0.19069907335731073, "compression_ratio": 1.573643410852713, "no_speech_prob": 5.9204245189903304e-05}, {"id": 598, "seek": 307824, "start": 3078.24, "end": 3081.9599999999996, "text": " So one thing you could do is you could add notes", "tokens": [407, 472, 551, 291, 727, 360, 307, 291, 727, 909, 5570], "temperature": 0.0, "avg_logprob": -0.13939421885722392, "compression_ratio": 1.4301675977653632, "no_speech_prob": 3.3929684377653757e-06}, {"id": 599, "seek": 307824, "start": 3081.9599999999996, "end": 3083.3199999999997, "text": " by replying to this.", "tokens": [538, 1085, 7310, 281, 341, 13], "temperature": 0.0, "avg_logprob": -0.13939421885722392, "compression_ratio": 1.4301675977653632, "no_speech_prob": 3.3929684377653757e-06}, {"id": 600, "seek": 307824, "start": 3083.3199999999997, "end": 3089.12, "text": " And then I can copy and paste them into the wiki.", "tokens": [400, 550, 286, 393, 5055, 293, 9163, 552, 666, 264, 261, 9850, 13], "temperature": 0.0, "avg_logprob": -0.13939421885722392, "compression_ratio": 1.4301675977653632, "no_speech_prob": 3.3929684377653757e-06}, {"id": 601, "seek": 307824, "start": 3089.12, "end": 3094.4799999999996, "text": " Might be one way to avoid conflicts.", "tokens": [23964, 312, 472, 636, 281, 5042, 19807, 13], "temperature": 0.0, "avg_logprob": -0.13939421885722392, "compression_ratio": 1.4301675977653632, "no_speech_prob": 3.3929684377653757e-06}, {"id": 602, "seek": 307824, "start": 3094.4799999999996, "end": 3101.16, "text": " Also, if you look at the fastai version2 transforms pipeline", "tokens": [2743, 11, 498, 291, 574, 412, 264, 2370, 1301, 3037, 17, 35592, 15517], "temperature": 0.0, "avg_logprob": -0.13939421885722392, "compression_ratio": 1.4301675977653632, "no_speech_prob": 3.3929684377653757e-06}, {"id": 603, "seek": 307824, "start": 3101.16, "end": 3105.08, "text": " data blocks, Ian Vijay was kind enough", "tokens": [1412, 8474, 11, 19595, 41201, 320, 390, 733, 1547], "temperature": 0.0, "avg_logprob": -0.13939421885722392, "compression_ratio": 1.4301675977653632, "no_speech_prob": 3.3929684377653757e-06}, {"id": 604, "seek": 310508, "start": 3105.08, "end": 3108.4, "text": " to start adding some notes.", "tokens": [281, 722, 5127, 512, 5570, 13], "temperature": 0.0, "avg_logprob": -0.1706674893697103, "compression_ratio": 1.560846560846561, "no_speech_prob": 3.0415085348067805e-06}, {"id": 605, "seek": 310508, "start": 3108.4, "end": 3111.2, "text": " So I've tried to try to get that some structure.", "tokens": [407, 286, 600, 3031, 281, 853, 281, 483, 300, 512, 3877, 13], "temperature": 0.0, "avg_logprob": -0.1706674893697103, "compression_ratio": 1.560846560846561, "no_speech_prob": 3.0415085348067805e-06}, {"id": 606, "seek": 310508, "start": 3111.2, "end": 3115.7599999999998, "text": " So you can basically create something", "tokens": [407, 291, 393, 1936, 1884, 746], "temperature": 0.0, "avg_logprob": -0.1706674893697103, "compression_ratio": 1.560846560846561, "no_speech_prob": 3.0415085348067805e-06}, {"id": 607, "seek": 310508, "start": 3115.7599999999998, "end": 3119.3199999999997, "text": " where you've got second level headings for modules,", "tokens": [689, 291, 600, 658, 1150, 1496, 1378, 1109, 337, 16679, 11], "temperature": 0.0, "avg_logprob": -0.1706674893697103, "compression_ratio": 1.560846560846561, "no_speech_prob": 3.0415085348067805e-06}, {"id": 608, "seek": 310508, "start": 3119.3199999999997, "end": 3123.3199999999997, "text": " third level headings for classes and functions.", "tokens": [2636, 1496, 1378, 1109, 337, 5359, 293, 6828, 13], "temperature": 0.0, "avg_logprob": -0.1706674893697103, "compression_ratio": 1.560846560846561, "no_speech_prob": 3.0415085348067805e-06}, {"id": 609, "seek": 310508, "start": 3126.52, "end": 3128.36, "text": " And then what I did for these was", "tokens": [400, 550, 437, 286, 630, 337, 613, 390], "temperature": 0.0, "avg_logprob": -0.1706674893697103, "compression_ratio": 1.560846560846561, "no_speech_prob": 3.0415085348067805e-06}, {"id": 610, "seek": 310508, "start": 3128.36, "end": 3133.48, "text": " if you click on this random splitter instance,", "tokens": [498, 291, 2052, 322, 341, 4974, 4732, 3904, 5197, 11], "temperature": 0.0, "avg_logprob": -0.1706674893697103, "compression_ratio": 1.560846560846561, "no_speech_prob": 3.0415085348067805e-06}, {"id": 611, "seek": 313348, "start": 3133.48, "end": 3136.48, "text": " it will actually take you to the line of code in GitHub.", "tokens": [309, 486, 767, 747, 291, 281, 264, 1622, 295, 3089, 294, 23331, 13], "temperature": 0.0, "avg_logprob": -0.14045839211375444, "compression_ratio": 1.7253886010362693, "no_speech_prob": 1.4367092262546066e-06}, {"id": 612, "seek": 313348, "start": 3136.48, "end": 3140.48, "text": " To do that, you can just click on the line of code, like so,", "tokens": [1407, 360, 300, 11, 291, 393, 445, 2052, 322, 264, 1622, 295, 3089, 11, 411, 370, 11], "temperature": 0.0, "avg_logprob": -0.14045839211375444, "compression_ratio": 1.7253886010362693, "no_speech_prob": 1.4367092262546066e-06}, {"id": 613, "seek": 313348, "start": 3140.48, "end": 3144.72, "text": " and then click on the three dots and say Copy Permalink.", "tokens": [293, 550, 2052, 322, 264, 1045, 15026, 293, 584, 25653, 41006, 304, 475, 13], "temperature": 0.0, "avg_logprob": -0.14045839211375444, "compression_ratio": 1.7253886010362693, "no_speech_prob": 1.4367092262546066e-06}, {"id": 614, "seek": 313348, "start": 3144.72, "end": 3153.44, "text": " And it will actually create a link to that exact line of code,", "tokens": [400, 309, 486, 767, 1884, 257, 2113, 281, 300, 1900, 1622, 295, 3089, 11], "temperature": 0.0, "avg_logprob": -0.14045839211375444, "compression_ratio": 1.7253886010362693, "no_speech_prob": 1.4367092262546066e-06}, {"id": 615, "seek": 313348, "start": 3153.44, "end": 3156.2, "text": " which is pretty cool.", "tokens": [597, 307, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.14045839211375444, "compression_ratio": 1.7253886010362693, "no_speech_prob": 1.4367092262546066e-06}, {"id": 616, "seek": 313348, "start": 3156.2, "end": 3158.16, "text": " And so that was for random splitter.", "tokens": [400, 370, 300, 390, 337, 4974, 4732, 3904, 13], "temperature": 0.0, "avg_logprob": -0.14045839211375444, "compression_ratio": 1.7253886010362693, "no_speech_prob": 1.4367092262546066e-06}, {"id": 617, "seek": 315816, "start": 3158.16, "end": 3165.44, "text": " So we can then go down here and say, bump, like so.", "tokens": [407, 321, 393, 550, 352, 760, 510, 293, 584, 11, 9961, 11, 411, 370, 13], "temperature": 0.0, "avg_logprob": -0.16536714789572726, "compression_ratio": 1.5642458100558658, "no_speech_prob": 5.7717461459105834e-06}, {"id": 618, "seek": 315816, "start": 3165.44, "end": 3168.2799999999997, "text": " And so that's a permalink to that line of code.", "tokens": [400, 370, 300, 311, 257, 4784, 304, 475, 281, 300, 1622, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.16536714789572726, "compression_ratio": 1.5642458100558658, "no_speech_prob": 5.7717461459105834e-06}, {"id": 619, "seek": 315816, "start": 3170.6, "end": 3173.92, "text": " So that's that.", "tokens": [407, 300, 311, 300, 13], "temperature": 0.0, "avg_logprob": -0.16536714789572726, "compression_ratio": 1.5642458100558658, "no_speech_prob": 5.7717461459105834e-06}, {"id": 620, "seek": 315816, "start": 3173.92, "end": 3177.92, "text": " And then in the daily code walkthrough thread,", "tokens": [400, 550, 294, 264, 5212, 3089, 1792, 11529, 7207, 11], "temperature": 0.0, "avg_logprob": -0.16536714789572726, "compression_ratio": 1.5642458100558658, "no_speech_prob": 5.7717461459105834e-06}, {"id": 621, "seek": 315816, "start": 3177.92, "end": 3179.52, "text": " as I'm sure you've noticed, I'm going", "tokens": [382, 286, 478, 988, 291, 600, 5694, 11, 286, 478, 516], "temperature": 0.0, "avg_logprob": -0.16536714789572726, "compression_ratio": 1.5642458100558658, "no_speech_prob": 5.7717461459105834e-06}, {"id": 622, "seek": 315816, "start": 3179.52, "end": 3184.04, "text": " to start putting the video and the notes link just in the list", "tokens": [281, 722, 3372, 264, 960, 293, 264, 5570, 2113, 445, 294, 264, 1329], "temperature": 0.0, "avg_logprob": -0.16536714789572726, "compression_ratio": 1.5642458100558658, "no_speech_prob": 5.7717461459105834e-06}, {"id": 623, "seek": 315816, "start": 3184.04, "end": 3187.2, "text": " at the top here.", "tokens": [412, 264, 1192, 510, 13], "temperature": 0.0, "avg_logprob": -0.16536714789572726, "compression_ratio": 1.5642458100558658, "no_speech_prob": 5.7717461459105834e-06}, {"id": 624, "seek": 318720, "start": 3187.2, "end": 3188.8799999999997, "text": " How many walkthroughs are planned?", "tokens": [1012, 867, 1792, 11529, 82, 366, 8589, 30], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 625, "seek": 318720, "start": 3188.8799999999997, "end": 3191.7599999999998, "text": " As many as we need.", "tokens": [1018, 867, 382, 321, 643, 13], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 626, "seek": 318720, "start": 3191.7599999999998, "end": 3192.8399999999997, "text": " What is D source?", "tokens": [708, 307, 413, 4009, 30], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 627, "seek": 318720, "start": 3192.8399999999997, "end": 3196.3599999999997, "text": " That's just a data source.", "tokens": [663, 311, 445, 257, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 628, "seek": 318720, "start": 3196.3599999999997, "end": 3197.7599999999998, "text": " It could be a data source object,", "tokens": [467, 727, 312, 257, 1412, 4009, 2657, 11], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 629, "seek": 318720, "start": 3197.7599999999998, "end": 3203.12, "text": " but really it's anything which can be treated as a list,", "tokens": [457, 534, 309, 311, 1340, 597, 393, 312, 8668, 382, 257, 1329, 11], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 630, "seek": 318720, "start": 3203.12, "end": 3205.96, "text": " or anything which works with any transform you're using.", "tokens": [420, 1340, 597, 1985, 365, 604, 4088, 291, 434, 1228, 13], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 631, "seek": 318720, "start": 3205.96, "end": 3208.2799999999997, "text": " It doesn't even have to be necessarily treated as a list.", "tokens": [467, 1177, 380, 754, 362, 281, 312, 4725, 8668, 382, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 632, "seek": 318720, "start": 3211.3999999999996, "end": 3212.3599999999997, "text": " Merge conflicts.", "tokens": [6124, 432, 19807, 13], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 633, "seek": 318720, "start": 3212.3599999999997, "end": 3216.16, "text": " Yeah, as Molly said, once you've run run after git clone,", "tokens": [865, 11, 382, 26665, 848, 11, 1564, 291, 600, 1190, 1190, 934, 18331, 26506, 11], "temperature": 0.0, "avg_logprob": -0.17808306217193604, "compression_ratio": 1.6033755274261603, "no_speech_prob": 2.7534901164472103e-05}, {"id": 634, "seek": 321616, "start": 3216.16, "end": 3217.74, "text": " that'll get rid of a lot of the conflicts,", "tokens": [300, 603, 483, 3973, 295, 257, 688, 295, 264, 19807, 11], "temperature": 0.0, "avg_logprob": -0.17930455361643144, "compression_ratio": 1.576036866359447, "no_speech_prob": 3.5007712995138718e-06}, {"id": 635, "seek": 321616, "start": 3217.74, "end": 3222.96, "text": " because a lot of the metadata is removed and stuff like that.", "tokens": [570, 257, 688, 295, 264, 26603, 307, 7261, 293, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.17930455361643144, "compression_ratio": 1.576036866359447, "no_speech_prob": 3.5007712995138718e-06}, {"id": 636, "seek": 321616, "start": 3222.96, "end": 3227.3999999999996, "text": " Other than that, we just try to push regularly.", "tokens": [5358, 813, 300, 11, 321, 445, 853, 281, 2944, 11672, 13], "temperature": 0.0, "avg_logprob": -0.17930455361643144, "compression_ratio": 1.576036866359447, "no_speech_prob": 3.5007712995138718e-06}, {"id": 637, "seek": 321616, "start": 3227.3999999999996, "end": 3230.3199999999997, "text": " If we're going to be working on a notebook for a while", "tokens": [759, 321, 434, 516, 281, 312, 1364, 322, 257, 21060, 337, 257, 1339], "temperature": 0.0, "avg_logprob": -0.17930455361643144, "compression_ratio": 1.576036866359447, "no_speech_prob": 3.5007712995138718e-06}, {"id": 638, "seek": 321616, "start": 3230.3199999999997, "end": 3232.2799999999997, "text": " that we think somebody else might be working on,", "tokens": [300, 321, 519, 2618, 1646, 1062, 312, 1364, 322, 11], "temperature": 0.0, "avg_logprob": -0.17930455361643144, "compression_ratio": 1.576036866359447, "no_speech_prob": 3.5007712995138718e-06}, {"id": 639, "seek": 321616, "start": 3232.2799999999997, "end": 3235.3599999999997, "text": " we'll let them know.", "tokens": [321, 603, 718, 552, 458, 13], "temperature": 0.0, "avg_logprob": -0.17930455361643144, "compression_ratio": 1.576036866359447, "no_speech_prob": 3.5007712995138718e-06}, {"id": 640, "seek": 321616, "start": 3235.3599999999997, "end": 3240.16, "text": " Yeah, nowadays we don't have too many conflict problems anymore.", "tokens": [865, 11, 13434, 321, 500, 380, 362, 886, 867, 6596, 2740, 3602, 13], "temperature": 0.0, "avg_logprob": -0.17930455361643144, "compression_ratio": 1.576036866359447, "no_speech_prob": 3.5007712995138718e-06}, {"id": 641, "seek": 324016, "start": 3240.16, "end": 3247.48, "text": " Miguel asked, how did I start using PyTorch?", "tokens": [29150, 2351, 11, 577, 630, 286, 722, 1228, 9953, 51, 284, 339, 30], "temperature": 0.0, "avg_logprob": -0.17548750081193557, "compression_ratio": 1.6196581196581197, "no_speech_prob": 3.555793227860704e-06}, {"id": 642, "seek": 324016, "start": 3247.48, "end": 3252.12, "text": " I started using it kind of when it was first released.", "tokens": [286, 1409, 1228, 309, 733, 295, 562, 309, 390, 700, 4736, 13], "temperature": 0.0, "avg_logprob": -0.17548750081193557, "compression_ratio": 1.6196581196581197, "no_speech_prob": 3.555793227860704e-06}, {"id": 643, "seek": 324016, "start": 3252.12, "end": 3258.7999999999997, "text": " So yeah, I guess I just read the docs and the tutorials.", "tokens": [407, 1338, 11, 286, 2041, 286, 445, 1401, 264, 45623, 293, 264, 17616, 13], "temperature": 0.0, "avg_logprob": -0.17548750081193557, "compression_ratio": 1.6196581196581197, "no_speech_prob": 3.555793227860704e-06}, {"id": 644, "seek": 324016, "start": 3258.7999999999997, "end": 3261.0, "text": " I think nowadays just using the fast AI lessons", "tokens": [286, 519, 13434, 445, 1228, 264, 2370, 7318, 8820], "temperature": 0.0, "avg_logprob": -0.17548750081193557, "compression_ratio": 1.6196581196581197, "no_speech_prob": 3.555793227860704e-06}, {"id": 645, "seek": 324016, "start": 3261.0, "end": 3264.16, "text": " is probably the easiest way to get started.", "tokens": [307, 1391, 264, 12889, 636, 281, 483, 1409, 13], "temperature": 0.0, "avg_logprob": -0.17548750081193557, "compression_ratio": 1.6196581196581197, "no_speech_prob": 3.555793227860704e-06}, {"id": 646, "seek": 324016, "start": 3264.16, "end": 3265.7999999999997, "text": " The further you get into them, the more", "tokens": [440, 3052, 291, 483, 666, 552, 11, 264, 544], "temperature": 0.0, "avg_logprob": -0.17548750081193557, "compression_ratio": 1.6196581196581197, "no_speech_prob": 3.555793227860704e-06}, {"id": 647, "seek": 324016, "start": 3265.7999999999997, "end": 3267.44, "text": " you'll learn about PyTorch.", "tokens": [291, 603, 1466, 466, 9953, 51, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.17548750081193557, "compression_ratio": 1.6196581196581197, "no_speech_prob": 3.555793227860704e-06}, {"id": 648, "seek": 324016, "start": 3267.44, "end": 3269.92, "text": " That'd be a good thing to ask other people on the forums, too,", "tokens": [663, 1116, 312, 257, 665, 551, 281, 1029, 661, 561, 322, 264, 26998, 11, 886, 11], "temperature": 0.0, "avg_logprob": -0.17548750081193557, "compression_ratio": 1.6196581196581197, "no_speech_prob": 3.555793227860704e-06}, {"id": 649, "seek": 326992, "start": 3269.92, "end": 3271.56, "text": " because there are a lot of other people", "tokens": [570, 456, 366, 257, 688, 295, 661, 561], "temperature": 0.0, "avg_logprob": -0.16893190625070156, "compression_ratio": 1.6, "no_speech_prob": 4.222695679345634e-06}, {"id": 650, "seek": 326992, "start": 3271.56, "end": 3274.12, "text": " that have started using PyTorch more recently than me.", "tokens": [300, 362, 1409, 1228, 9953, 51, 284, 339, 544, 3938, 813, 385, 13], "temperature": 0.0, "avg_logprob": -0.16893190625070156, "compression_ratio": 1.6, "no_speech_prob": 4.222695679345634e-06}, {"id": 651, "seek": 326992, "start": 3274.12, "end": 3277.36, "text": " It might be a better place to answer that question.", "tokens": [467, 1062, 312, 257, 1101, 1081, 281, 1867, 300, 1168, 13], "temperature": 0.0, "avg_logprob": -0.16893190625070156, "compression_ratio": 1.6, "no_speech_prob": 4.222695679345634e-06}, {"id": 652, "seek": 326992, "start": 3280.36, "end": 3285.96, "text": " OK, so as well as the category, we also have multi-category.", "tokens": [2264, 11, 370, 382, 731, 382, 264, 7719, 11, 321, 611, 362, 4825, 12, 66, 48701, 13], "temperature": 0.0, "avg_logprob": -0.16893190625070156, "compression_ratio": 1.6, "no_speech_prob": 4.222695679345634e-06}, {"id": 653, "seek": 326992, "start": 3285.96, "end": 3289.7200000000003, "text": " The multi-category is something like we have in Planet.", "tokens": [440, 4825, 12, 66, 48701, 307, 746, 411, 321, 362, 294, 22146, 13], "temperature": 0.0, "avg_logprob": -0.16893190625070156, "compression_ratio": 1.6, "no_speech_prob": 4.222695679345634e-06}, {"id": 654, "seek": 326992, "start": 3289.7200000000003, "end": 3295.2000000000003, "text": " Remember in Planet, each image can have multiple things,", "tokens": [5459, 294, 22146, 11, 1184, 3256, 393, 362, 3866, 721, 11], "temperature": 0.0, "avg_logprob": -0.16893190625070156, "compression_ratio": 1.6, "no_speech_prob": 4.222695679345634e-06}, {"id": 655, "seek": 329520, "start": 3295.2, "end": 3301.0, "text": " like cloudy and primary and road.", "tokens": [411, 33060, 293, 6194, 293, 3060, 13], "temperature": 0.0, "avg_logprob": -0.11066038855190935, "compression_ratio": 1.6685393258426966, "no_speech_prob": 2.3687700831942493e-06}, {"id": 656, "seek": 329520, "start": 3301.0, "end": 3306.4399999999996, "text": " So here's an example of items for a multi-category dependent", "tokens": [407, 510, 311, 364, 1365, 295, 4754, 337, 257, 4825, 12, 66, 48701, 12334], "temperature": 0.0, "avg_logprob": -0.11066038855190935, "compression_ratio": 1.6685393258426966, "no_speech_prob": 2.3687700831942493e-06}, {"id": 657, "seek": 329520, "start": 3306.4399999999996, "end": 3307.3999999999996, "text": " variable.", "tokens": [7006, 13], "temperature": 0.0, "avg_logprob": -0.11066038855190935, "compression_ratio": 1.6685393258426966, "no_speech_prob": 2.3687700831942493e-06}, {"id": 658, "seek": 329520, "start": 3307.3999999999996, "end": 3311.3599999999997, "text": " You can see each one now is a list.", "tokens": [509, 393, 536, 1184, 472, 586, 307, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.11066038855190935, "compression_ratio": 1.6685393258426966, "no_speech_prob": 2.3687700831942493e-06}, {"id": 659, "seek": 329520, "start": 3311.3599999999997, "end": 3314.08, "text": " So item number one is labeled with B and C.", "tokens": [407, 3174, 1230, 472, 307, 21335, 365, 363, 293, 383, 13], "temperature": 0.0, "avg_logprob": -0.11066038855190935, "compression_ratio": 1.6685393258426966, "no_speech_prob": 2.3687700831942493e-06}, {"id": 660, "seek": 329520, "start": 3314.08, "end": 3316.3599999999997, "text": " Item number two is labeled with A. Item number three", "tokens": [31066, 1230, 732, 307, 21335, 365, 316, 13, 31066, 1230, 1045], "temperature": 0.0, "avg_logprob": -0.11066038855190935, "compression_ratio": 1.6685393258426966, "no_speech_prob": 2.3687700831942493e-06}, {"id": 661, "seek": 329520, "start": 3316.3599999999997, "end": 3321.2799999999997, "text": " is labeled with A and C. So the vocab that we get from that", "tokens": [307, 21335, 365, 316, 293, 383, 13, 407, 264, 2329, 455, 300, 321, 483, 490, 300], "temperature": 0.0, "avg_logprob": -0.11066038855190935, "compression_ratio": 1.6685393258426966, "no_speech_prob": 2.3687700831942493e-06}, {"id": 662, "seek": 332128, "start": 3321.28, "end": 3328.1200000000003, "text": " should be A, B, C. And categorizing A, C", "tokens": [820, 312, 316, 11, 363, 11, 383, 13, 400, 19250, 3319, 316, 11, 383], "temperature": 0.0, "avg_logprob": -0.10565352439880371, "compression_ratio": 1.6395348837209303, "no_speech_prob": 5.507480636879336e-06}, {"id": 663, "seek": 332128, "start": 3328.1200000000003, "end": 3331.96, "text": " should give us 0, 2.", "tokens": [820, 976, 505, 1958, 11, 568, 13], "temperature": 0.0, "avg_logprob": -0.10565352439880371, "compression_ratio": 1.6395348837209303, "no_speech_prob": 5.507480636879336e-06}, {"id": 664, "seek": 332128, "start": 3331.96, "end": 3335.32, "text": " So that's what multi-categorize does.", "tokens": [407, 300, 311, 437, 4825, 12, 66, 2968, 284, 1125, 775, 13], "temperature": 0.0, "avg_logprob": -0.10565352439880371, "compression_ratio": 1.6395348837209303, "no_speech_prob": 5.507480636879336e-06}, {"id": 665, "seek": 332128, "start": 3335.32, "end": 3341.1200000000003, "text": " And as you can see, it looks super similar to what", "tokens": [400, 382, 291, 393, 536, 11, 309, 1542, 1687, 2531, 281, 437], "temperature": 0.0, "avg_logprob": -0.10565352439880371, "compression_ratio": 1.6395348837209303, "no_speech_prob": 5.507480636879336e-06}, {"id": 666, "seek": 332128, "start": 3341.1200000000003, "end": 3343.2000000000003, "text": " we had before, except encodes has", "tokens": [321, 632, 949, 11, 3993, 2058, 4789, 575], "temperature": 0.0, "avg_logprob": -0.10565352439880371, "compression_ratio": 1.6395348837209303, "no_speech_prob": 5.507480636879336e-06}, {"id": 667, "seek": 332128, "start": 3343.2000000000003, "end": 3345.28, "text": " to do it for everything in the list,", "tokens": [281, 360, 309, 337, 1203, 294, 264, 1329, 11], "temperature": 0.0, "avg_logprob": -0.10565352439880371, "compression_ratio": 1.6395348837209303, "no_speech_prob": 5.507480636879336e-06}, {"id": 668, "seek": 334528, "start": 3345.28, "end": 3352.0400000000004, "text": " and decodes has to do it for everything in the list as well.", "tokens": [293, 979, 4789, 575, 281, 360, 309, 337, 1203, 294, 264, 1329, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1393683712656905, "compression_ratio": 1.517766497461929, "no_speech_prob": 2.2602896478929324e-06}, {"id": 669, "seek": 334528, "start": 3352.0400000000004, "end": 3354.76, "text": " And so multi-category show is a little bit different", "tokens": [400, 370, 4825, 12, 66, 48701, 855, 307, 257, 707, 857, 819], "temperature": 0.0, "avg_logprob": -0.1393683712656905, "compression_ratio": 1.517766497461929, "no_speech_prob": 2.2602896478929324e-06}, {"id": 670, "seek": 334528, "start": 3354.76, "end": 3357.2000000000003, "text": " because we've now got multiple things to show.", "tokens": [570, 321, 600, 586, 658, 3866, 721, 281, 855, 13], "temperature": 0.0, "avg_logprob": -0.1393683712656905, "compression_ratio": 1.517766497461929, "no_speech_prob": 2.2602896478929324e-06}, {"id": 671, "seek": 334528, "start": 3357.2000000000003, "end": 3363.6400000000003, "text": " So we have to use the string join in Python.", "tokens": [407, 321, 362, 281, 764, 264, 6798, 3917, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.1393683712656905, "compression_ratio": 1.517766497461929, "no_speech_prob": 2.2602896478929324e-06}, {"id": 672, "seek": 334528, "start": 3366.5600000000004, "end": 3369.0400000000004, "text": " And so one of the handy test functions", "tokens": [400, 370, 472, 295, 264, 13239, 1500, 6828], "temperature": 0.0, "avg_logprob": -0.1393683712656905, "compression_ratio": 1.517766497461929, "no_speech_prob": 2.2602896478929324e-06}, {"id": 673, "seek": 334528, "start": 3369.0400000000004, "end": 3372.84, "text": " that we'll learn more about later is just stood it out", "tokens": [300, 321, 603, 1466, 544, 466, 1780, 307, 445, 9371, 309, 484], "temperature": 0.0, "avg_logprob": -0.1393683712656905, "compression_ratio": 1.517766497461929, "no_speech_prob": 2.2602896478929324e-06}, {"id": 674, "seek": 337284, "start": 3372.84, "end": 3376.48, "text": " because the show functions actually print things.", "tokens": [570, 264, 855, 6828, 767, 4482, 721, 13], "temperature": 0.0, "avg_logprob": -0.1608702845689727, "compression_ratio": 1.5824742268041236, "no_speech_prob": 8.939496183302253e-06}, {"id": 675, "seek": 337284, "start": 3376.48, "end": 3379.52, "text": " And so how do you test whether something is printed correctly?", "tokens": [400, 370, 577, 360, 291, 1500, 1968, 746, 307, 13567, 8944, 30], "temperature": 0.0, "avg_logprob": -0.1608702845689727, "compression_ratio": 1.5824742268041236, "no_speech_prob": 8.939496183302253e-06}, {"id": 676, "seek": 337284, "start": 3379.52, "end": 3385.1200000000003, "text": " Well, this will actually test whether this function prints out", "tokens": [1042, 11, 341, 486, 767, 1500, 1968, 341, 2445, 22305, 484], "temperature": 0.0, "avg_logprob": -0.1608702845689727, "compression_ratio": 1.5824742268041236, "no_speech_prob": 8.939496183302253e-06}, {"id": 677, "seek": 337284, "start": 3385.1200000000003, "end": 3387.0, "text": " this thing or not.", "tokens": [341, 551, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.1608702845689727, "compression_ratio": 1.5824742268041236, "no_speech_prob": 8.939496183302253e-06}, {"id": 678, "seek": 337284, "start": 3387.0, "end": 3391.4, "text": " So that's a useful little thing to know about.", "tokens": [407, 300, 311, 257, 4420, 707, 551, 281, 458, 466, 13], "temperature": 0.0, "avg_logprob": -0.1608702845689727, "compression_ratio": 1.5824742268041236, "no_speech_prob": 8.939496183302253e-06}, {"id": 679, "seek": 337284, "start": 3391.4, "end": 3391.9, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1608702845689727, "compression_ratio": 1.5824742268041236, "no_speech_prob": 8.939496183302253e-06}, {"id": 680, "seek": 337284, "start": 3397.44, "end": 3402.44, "text": " So normally, you need to one-hot encode multi-category stuff.", "tokens": [407, 5646, 11, 291, 643, 281, 472, 12, 12194, 2058, 1429, 4825, 12, 66, 48701, 1507, 13], "temperature": 0.0, "avg_logprob": -0.1608702845689727, "compression_ratio": 1.5824742268041236, "no_speech_prob": 8.939496183302253e-06}, {"id": 681, "seek": 340244, "start": 3402.44, "end": 3405.32, "text": " So we've got a one-hot encoding here,", "tokens": [407, 321, 600, 658, 257, 472, 12, 12194, 43430, 510, 11], "temperature": 0.0, "avg_logprob": -0.1859874859662123, "compression_ratio": 1.411764705882353, "no_speech_prob": 5.594259164354298e-06}, {"id": 682, "seek": 340244, "start": 3405.32, "end": 3408.0, "text": " which works the same way that you've seen in PyTorch version", "tokens": [597, 1985, 264, 912, 636, 300, 291, 600, 1612, 294, 9953, 51, 284, 339, 3037], "temperature": 0.0, "avg_logprob": -0.1859874859662123, "compression_ratio": 1.411764705882353, "no_speech_prob": 5.594259164354298e-06}, {"id": 683, "seek": 340244, "start": 3408.0, "end": 3411.36, "text": " 1 and the lessons.", "tokens": [502, 293, 264, 8820, 13], "temperature": 0.0, "avg_logprob": -0.1859874859662123, "compression_ratio": 1.411764705882353, "no_speech_prob": 5.594259164354298e-06}, {"id": 684, "seek": 340244, "start": 3411.36, "end": 3414.36, "text": " And so here's a transform for that,", "tokens": [400, 370, 510, 311, 257, 4088, 337, 300, 11], "temperature": 0.0, "avg_logprob": -0.1859874859662123, "compression_ratio": 1.411764705882353, "no_speech_prob": 5.594259164354298e-06}, {"id": 685, "seek": 340244, "start": 3414.36, "end": 3421.88, "text": " where the encodes is simply going to call one-hot,", "tokens": [689, 264, 2058, 4789, 307, 2935, 516, 281, 818, 472, 12, 12194, 11], "temperature": 0.0, "avg_logprob": -0.1859874859662123, "compression_ratio": 1.411764705882353, "no_speech_prob": 5.594259164354298e-06}, {"id": 686, "seek": 340244, "start": 3421.88, "end": 3422.44, "text": " as you see.", "tokens": [382, 291, 536, 13], "temperature": 0.0, "avg_logprob": -0.1859874859662123, "compression_ratio": 1.411764705882353, "no_speech_prob": 5.594259164354298e-06}, {"id": 687, "seek": 342244, "start": 3422.44, "end": 3432.44, "text": " And to decode, it does one-hot decode.", "tokens": [400, 281, 979, 1429, 11, 309, 775, 472, 12, 12194, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.39804869431715745, "compression_ratio": 1.2777777777777777, "no_speech_prob": 1.8923967218142934e-05}, {"id": 688, "seek": 342244, "start": 3437.44, "end": 3442.44, "text": " I think these return types are unnecessary.", "tokens": [286, 519, 613, 2736, 3467, 366, 19350, 13], "temperature": 0.0, "avg_logprob": -0.39804869431715745, "compression_ratio": 1.2777777777777777, "no_speech_prob": 1.8923967218142934e-05}, {"id": 689, "seek": 342244, "start": 3445.44, "end": 3445.94, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.39804869431715745, "compression_ratio": 1.2777777777777777, "no_speech_prob": 1.8923967218142934e-05}, {"id": 690, "seek": 342244, "start": 3445.94, "end": 3448.44, "text": " It looks like they are.", "tokens": [467, 1542, 411, 436, 366, 13], "temperature": 0.0, "avg_logprob": -0.39804869431715745, "compression_ratio": 1.2777777777777777, "no_speech_prob": 1.8923967218142934e-05}, {"id": 691, "seek": 344844, "start": 3448.44, "end": 3452.44, "text": " Let's see if this still works when I remove them.", "tokens": [961, 311, 536, 498, 341, 920, 1985, 562, 286, 4159, 552, 13], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 692, "seek": 344844, "start": 3457.44, "end": 3457.94, "text": " Yep.", "tokens": [7010, 13], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 693, "seek": 344844, "start": 3457.94, "end": 3458.94, "text": " Looks like it does.", "tokens": [10027, 411, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 694, "seek": 344844, "start": 3458.94, "end": 3459.44, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 695, "seek": 344844, "start": 3462.44, "end": 3464.76, "text": " Now, the way we've done types and dispatching and stuff", "tokens": [823, 11, 264, 636, 321, 600, 1096, 3467, 293, 4920, 29569, 293, 1507], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 696, "seek": 344844, "start": 3464.76, "end": 3466.04, "text": " has changed a little bit over time.", "tokens": [575, 3105, 257, 707, 857, 670, 565, 13], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 697, "seek": 344844, "start": 3466.04, "end": 3467.7200000000003, "text": " So some of our code still has stuff", "tokens": [407, 512, 295, 527, 3089, 920, 575, 1507], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 698, "seek": 344844, "start": 3467.7200000000003, "end": 3469.6, "text": " that's more complex than necessary.", "tokens": [300, 311, 544, 3997, 813, 4818, 13], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 699, "seek": 344844, "start": 3469.6, "end": 3471.52, "text": " I will try to remove it as I see it.", "tokens": [286, 486, 853, 281, 4159, 309, 382, 286, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 700, "seek": 344844, "start": 3471.52, "end": 3474.68, "text": " If you're ever not sure why a type annotation exists,", "tokens": [759, 291, 434, 1562, 406, 988, 983, 257, 2010, 48654, 8198, 11], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 701, "seek": 344844, "start": 3474.68, "end": 3476.52, "text": " feel free to ask.", "tokens": [841, 1737, 281, 1029, 13], "temperature": 0.0, "avg_logprob": -0.16975819298980432, "compression_ratio": 1.5194805194805194, "no_speech_prob": 1.8339569578529336e-05}, {"id": 702, "seek": 347652, "start": 3476.52, "end": 3478.52, "text": " The answer might be that it's not needed.", "tokens": [440, 1867, 1062, 312, 300, 309, 311, 406, 2978, 13], "temperature": 0.0, "avg_logprob": -0.24268126185936265, "compression_ratio": 1.4597701149425288, "no_speech_prob": 1.9333267573529156e-06}, {"id": 703, "seek": 347652, "start": 3481.8, "end": 3482.3, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.24268126185936265, "compression_ratio": 1.4597701149425288, "no_speech_prob": 1.9333267573529156e-06}, {"id": 704, "seek": 347652, "start": 3485.08, "end": 3487.84, "text": " So here's a good little test then,", "tokens": [407, 510, 311, 257, 665, 707, 1500, 550, 11], "temperature": 0.0, "avg_logprob": -0.24268126185936265, "compression_ratio": 1.4597701149425288, "no_speech_prob": 1.9333267573529156e-06}, {"id": 705, "seek": 347652, "start": 3487.84, "end": 3489.92, "text": " a kind of a little mini integration test", "tokens": [257, 733, 295, 257, 707, 8382, 10980, 1500], "temperature": 0.0, "avg_logprob": -0.24268126185936265, "compression_ratio": 1.4597701149425288, "no_speech_prob": 1.9333267573529156e-06}, {"id": 706, "seek": 347652, "start": 3489.92, "end": 3494.8, "text": " of taking a bunch of items and passing it", "tokens": [295, 1940, 257, 3840, 295, 4754, 293, 8437, 309], "temperature": 0.0, "avg_logprob": -0.24268126185936265, "compression_ratio": 1.4597701149425288, "no_speech_prob": 1.9333267573529156e-06}, {"id": 707, "seek": 347652, "start": 3494.8, "end": 3499.58, "text": " through a pipeline that contains multi-categorized", "tokens": [807, 257, 15517, 300, 8306, 4825, 12, 66, 2968, 284, 1602], "temperature": 0.0, "avg_logprob": -0.24268126185936265, "compression_ratio": 1.4597701149425288, "no_speech_prob": 1.9333267573529156e-06}, {"id": 708, "seek": 347652, "start": 3499.58, "end": 3502.44, "text": " and one-hot encode.", "tokens": [293, 472, 12, 12194, 2058, 1429, 13], "temperature": 0.0, "avg_logprob": -0.24268126185936265, "compression_ratio": 1.4597701149425288, "no_speech_prob": 1.9333267573529156e-06}, {"id": 709, "seek": 347652, "start": 3502.44, "end": 3505.08, "text": " And so that should.", "tokens": [400, 370, 300, 820, 13], "temperature": 0.0, "avg_logprob": -0.24268126185936265, "compression_ratio": 1.4597701149425288, "no_speech_prob": 1.9333267573529156e-06}, {"id": 710, "seek": 350508, "start": 3505.08, "end": 3511.88, "text": " So TDS1, that would be A, should be 100.", "tokens": [407, 314, 11844, 16, 11, 300, 576, 312, 316, 11, 820, 312, 2319, 13], "temperature": 0.0, "avg_logprob": -0.1951761245727539, "compression_ratio": 1.3008130081300813, "no_speech_prob": 1.863115539890714e-05}, {"id": 711, "seek": 350508, "start": 3511.88, "end": 3517.7999999999997, "text": " And then decode of 011 should be BC.", "tokens": [400, 550, 979, 1429, 295, 1958, 5348, 820, 312, 14359, 13], "temperature": 0.0, "avg_logprob": -0.1951761245727539, "compression_ratio": 1.3008130081300813, "no_speech_prob": 1.863115539890714e-05}, {"id": 712, "seek": 350508, "start": 3517.7999999999997, "end": 3519.92, "text": " And just do that.", "tokens": [400, 445, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1951761245727539, "compression_ratio": 1.3008130081300813, "no_speech_prob": 1.863115539890714e-05}, {"id": 713, "seek": 350508, "start": 3519.92, "end": 3521.08, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1951761245727539, "compression_ratio": 1.3008130081300813, "no_speech_prob": 1.863115539890714e-05}, {"id": 714, "seek": 350508, "start": 3521.08, "end": 3523.24, "text": " So that is that.", "tokens": [407, 300, 307, 300, 13], "temperature": 0.0, "avg_logprob": -0.1951761245727539, "compression_ratio": 1.3008130081300813, "no_speech_prob": 1.863115539890714e-05}, {"id": 715, "seek": 350508, "start": 3523.24, "end": 3529.6, "text": " So we can put all this together to do MNIST", "tokens": [407, 321, 393, 829, 439, 341, 1214, 281, 360, 376, 45, 19756], "temperature": 0.0, "avg_logprob": -0.1951761245727539, "compression_ratio": 1.3008130081300813, "no_speech_prob": 1.863115539890714e-05}, {"id": 716, "seek": 352960, "start": 3529.6, "end": 3535.7999999999997, "text": " by calling get image files, splitter.", "tokens": [538, 5141, 483, 3256, 7098, 11, 4732, 3904, 13], "temperature": 0.0, "avg_logprob": -0.1680072593688965, "compression_ratio": 1.6607929515418502, "no_speech_prob": 3.6119308788329363e-06}, {"id": 717, "seek": 352960, "start": 3535.7999999999997, "end": 3539.7599999999998, "text": " And so notice these aren't being exported because this", "tokens": [400, 370, 3449, 613, 3212, 380, 885, 42055, 570, 341], "temperature": 0.0, "avg_logprob": -0.1680072593688965, "compression_ratio": 1.6607929515418502, "no_speech_prob": 3.6119308788329363e-06}, {"id": 718, "seek": 352960, "start": 3539.7599999999998, "end": 3540.64, "text": " is data core.", "tokens": [307, 1412, 4965, 13], "temperature": 0.0, "avg_logprob": -0.1680072593688965, "compression_ratio": 1.6607929515418502, "no_speech_prob": 3.6119308788329363e-06}, {"id": 719, "seek": 352960, "start": 3540.64, "end": 3543.7999999999997, "text": " So we haven't created any of the vision application yet.", "tokens": [407, 321, 2378, 380, 2942, 604, 295, 264, 5201, 3861, 1939, 13], "temperature": 0.0, "avg_logprob": -0.1680072593688965, "compression_ratio": 1.6607929515418502, "no_speech_prob": 3.6119308788329363e-06}, {"id": 720, "seek": 352960, "start": 3543.7999999999997, "end": 3546.48, "text": " So we don't want to export anything that uses Pillow.", "tokens": [407, 321, 500, 380, 528, 281, 10725, 1340, 300, 4960, 44656, 305, 13], "temperature": 0.0, "avg_logprob": -0.1680072593688965, "compression_ratio": 1.6607929515418502, "no_speech_prob": 3.6119308788329363e-06}, {"id": 721, "seek": 352960, "start": 3546.48, "end": 3549.08, "text": " But you can certainly include it in the tests, right?", "tokens": [583, 291, 393, 3297, 4090, 309, 294, 264, 6921, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1680072593688965, "compression_ratio": 1.6607929515418502, "no_speech_prob": 3.6119308788329363e-06}, {"id": 722, "seek": 352960, "start": 3549.08, "end": 3553.56, "text": " So for the tests, we can bring these basic functions in,", "tokens": [407, 337, 264, 6921, 11, 321, 393, 1565, 613, 3875, 6828, 294, 11], "temperature": 0.0, "avg_logprob": -0.1680072593688965, "compression_ratio": 1.6607929515418502, "no_speech_prob": 3.6119308788329363e-06}, {"id": 723, "seek": 352960, "start": 3553.56, "end": 3558.2599999999998, "text": " something that can open an image, something that", "tokens": [746, 300, 393, 1269, 364, 3256, 11, 746, 300], "temperature": 0.0, "avg_logprob": -0.1680072593688965, "compression_ratio": 1.6607929515418502, "no_speech_prob": 3.6119308788329363e-06}, {"id": 724, "seek": 355826, "start": 3558.26, "end": 3561.88, "text": " convert an image into a tensor.", "tokens": [7620, 364, 3256, 666, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.13975951936509873, "compression_ratio": 1.6132596685082874, "no_speech_prob": 1.644196527195163e-05}, {"id": 725, "seek": 355826, "start": 3561.88, "end": 3564.88, "text": " So here's our two transform pipelines", "tokens": [407, 510, 311, 527, 732, 4088, 40168], "temperature": 0.0, "avg_logprob": -0.13975951936509873, "compression_ratio": 1.6132596685082874, "no_speech_prob": 1.644196527195163e-05}, {"id": 726, "seek": 355826, "start": 3564.88, "end": 3568.28, "text": " that will look pretty similar to what we did in 08.", "tokens": [300, 486, 574, 1238, 2531, 281, 437, 321, 630, 294, 1958, 23, 13], "temperature": 0.0, "avg_logprob": -0.13975951936509873, "compression_ratio": 1.6132596685082874, "no_speech_prob": 1.644196527195163e-05}, {"id": 727, "seek": 355826, "start": 3568.28, "end": 3570.88, "text": " And so here's our TFMDS that takes our training", "tokens": [400, 370, 510, 311, 527, 40964, 44, 11844, 300, 2516, 527, 3097], "temperature": 0.0, "avg_logprob": -0.13975951936509873, "compression_ratio": 1.6132596685082874, "no_speech_prob": 1.644196527195163e-05}, {"id": 728, "seek": 355826, "start": 3570.88, "end": 3573.5600000000004, "text": " set and our transforms.", "tokens": [992, 293, 527, 35592, 13], "temperature": 0.0, "avg_logprob": -0.13975951936509873, "compression_ratio": 1.6132596685082874, "no_speech_prob": 1.644196527195163e-05}, {"id": 729, "seek": 355826, "start": 3573.5600000000004, "end": 3576.6400000000003, "text": " And so then we can grab one item of it.", "tokens": [400, 370, 550, 321, 393, 4444, 472, 3174, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.13975951936509873, "compression_ratio": 1.6132596685082874, "no_speech_prob": 1.644196527195163e-05}, {"id": 730, "seek": 355826, "start": 3576.6400000000003, "end": 3579.76, "text": " We can decode it.", "tokens": [492, 393, 979, 1429, 309, 13], "temperature": 0.0, "avg_logprob": -0.13975951936509873, "compression_ratio": 1.6132596685082874, "no_speech_prob": 1.644196527195163e-05}, {"id": 731, "seek": 355826, "start": 3579.76, "end": 3587.8, "text": " And show at will take our TFMDS and show", "tokens": [400, 855, 412, 486, 747, 527, 40964, 44, 11844, 293, 855], "temperature": 0.0, "avg_logprob": -0.13975951936509873, "compression_ratio": 1.6132596685082874, "no_speech_prob": 1.644196527195163e-05}, {"id": 732, "seek": 358780, "start": 3587.8, "end": 3590.76, "text": " the thing at this point.", "tokens": [264, 551, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.20380639441219378, "compression_ratio": 1.5401069518716577, "no_speech_prob": 8.530069862899836e-06}, {"id": 733, "seek": 358780, "start": 3590.76, "end": 3594.5600000000004, "text": " And you can optionally pass in some parameters", "tokens": [400, 291, 393, 3614, 379, 1320, 294, 512, 9834], "temperature": 0.0, "avg_logprob": -0.20380639441219378, "compression_ratio": 1.5401069518716577, "no_speech_prob": 8.530069862899836e-06}, {"id": 734, "seek": 358780, "start": 3594.5600000000004, "end": 3597.96, "text": " that will be passed along to Matpotlib.", "tokens": [300, 486, 312, 4678, 2051, 281, 6789, 17698, 38270, 13], "temperature": 0.0, "avg_logprob": -0.20380639441219378, "compression_ratio": 1.5401069518716577, "no_speech_prob": 8.530069862899836e-06}, {"id": 735, "seek": 358780, "start": 3601.5600000000004, "end": 3604.0800000000004, "text": " And these kinds of things, we also", "tokens": [400, 613, 3685, 295, 721, 11, 321, 611], "temperature": 0.0, "avg_logprob": -0.20380639441219378, "compression_ratio": 1.5401069518716577, "no_speech_prob": 8.530069862899836e-06}, {"id": 736, "seek": 358780, "start": 3604.0800000000004, "end": 3608.48, "text": " check that there are some tests, that the title looks right,", "tokens": [1520, 300, 456, 366, 512, 6921, 11, 300, 264, 4876, 1542, 558, 11], "temperature": 0.0, "avg_logprob": -0.20380639441219378, "compression_ratio": 1.5401069518716577, "no_speech_prob": 8.530069862899836e-06}, {"id": 737, "seek": 358780, "start": 3608.48, "end": 3610.4, "text": " and that the figure is actually created.", "tokens": [293, 300, 264, 2573, 307, 767, 2942, 13], "temperature": 0.0, "avg_logprob": -0.20380639441219378, "compression_ratio": 1.5401069518716577, "no_speech_prob": 8.530069862899836e-06}, {"id": 738, "seek": 358780, "start": 3612.8, "end": 3616.6400000000003, "text": " So that's like a good little, you know,", "tokens": [407, 300, 311, 411, 257, 665, 707, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.20380639441219378, "compression_ratio": 1.5401069518716577, "no_speech_prob": 8.530069862899836e-06}, {"id": 739, "seek": 361664, "start": 3616.64, "end": 3618.8799999999997, "text": " this entire thing is pretty self-standing.", "tokens": [341, 2302, 551, 307, 1238, 2698, 12, 8618, 13], "temperature": 0.0, "avg_logprob": -0.286403374593766, "compression_ratio": 1.4285714285714286, "no_speech_prob": 9.223218512488529e-06}, {"id": 740, "seek": 361664, "start": 3627.48, "end": 3629.8399999999997, "text": " So this is pretty self-standing, so it's kind of a good place", "tokens": [407, 341, 307, 1238, 2698, 12, 8618, 11, 370, 309, 311, 733, 295, 257, 665, 1081], "temperature": 0.0, "avg_logprob": -0.286403374593766, "compression_ratio": 1.4285714285714286, "no_speech_prob": 9.223218512488529e-06}, {"id": 741, "seek": 361664, "start": 3629.8399999999997, "end": 3632.68, "text": " to get going.", "tokens": [281, 483, 516, 13], "temperature": 0.0, "avg_logprob": -0.286403374593766, "compression_ratio": 1.4285714285714286, "no_speech_prob": 9.223218512488529e-06}, {"id": 742, "seek": 361664, "start": 3632.68, "end": 3635.12, "text": " So Miguel says, completed class.di,", "tokens": [407, 29150, 1619, 11, 7365, 1508, 13, 4504, 11], "temperature": 0.0, "avg_logprob": -0.286403374593766, "compression_ratio": 1.4285714285714286, "no_speech_prob": 9.223218512488529e-06}, {"id": 743, "seek": 361664, "start": 3635.12, "end": 3637.04, "text": " but you need to learn more PyTorch.", "tokens": [457, 291, 643, 281, 1466, 544, 9953, 51, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.286403374593766, "compression_ratio": 1.4285714285714286, "no_speech_prob": 9.223218512488529e-06}, {"id": 744, "seek": 363704, "start": 3637.04, "end": 3639.44, "text": " That would be a good thing to ask on the forums, I think.", "tokens": [663, 576, 312, 257, 665, 551, 281, 1029, 322, 264, 26998, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.4671312728018131, "compression_ratio": 1.5580357142857142, "no_speech_prob": 6.539305559272179e-06}, {"id": 745, "seek": 363704, "start": 3642.88, "end": 3644.64, "text": " I mean, if you're doing all the assignments,", "tokens": [286, 914, 11, 498, 291, 434, 884, 439, 264, 22546, 11], "temperature": 0.0, "avg_logprob": -0.4671312728018131, "compression_ratio": 1.5580357142857142, "no_speech_prob": 6.539305559272179e-06}, {"id": 746, "seek": 363704, "start": 3644.64, "end": 3646.36, "text": " and by the end of 14 lessons, I would", "tokens": [293, 538, 264, 917, 295, 3499, 8820, 11, 286, 576], "temperature": 0.0, "avg_logprob": -0.4671312728018131, "compression_ratio": 1.5580357142857142, "no_speech_prob": 6.539305559272179e-06}, {"id": 747, "seek": 363704, "start": 3646.36, "end": 3650.16, "text": " have thought you'd have to be pretty damn good at PyTorch,", "tokens": [362, 1194, 291, 1116, 362, 281, 312, 1238, 8151, 665, 412, 9953, 51, 284, 339, 11], "temperature": 0.0, "avg_logprob": -0.4671312728018131, "compression_ratio": 1.5580357142857142, "no_speech_prob": 6.539305559272179e-06}, {"id": 748, "seek": 363704, "start": 3650.16, "end": 3651.88, "text": " because you do a lot of practice.", "tokens": [570, 291, 360, 257, 688, 295, 3124, 13], "temperature": 0.0, "avg_logprob": -0.4671312728018131, "compression_ratio": 1.5580357142857142, "no_speech_prob": 6.539305559272179e-06}, {"id": 749, "seek": 363704, "start": 3655.72, "end": 3657.64, "text": " But yeah, I guess other people might", "tokens": [583, 1338, 11, 286, 2041, 661, 561, 1062], "temperature": 0.0, "avg_logprob": -0.4671312728018131, "compression_ratio": 1.5580357142857142, "no_speech_prob": 6.539305559272179e-06}, {"id": 750, "seek": 363704, "start": 3657.64, "end": 3660.44, "text": " be able to have their own ideas about that.", "tokens": [312, 1075, 281, 362, 641, 1065, 3487, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.4671312728018131, "compression_ratio": 1.5580357142857142, "no_speech_prob": 6.539305559272179e-06}, {"id": 751, "seek": 363704, "start": 3660.44, "end": 3662.7599999999998, "text": " So I guess that's it for this one.", "tokens": [407, 286, 2041, 300, 311, 309, 337, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.4671312728018131, "compression_ratio": 1.5580357142857142, "no_speech_prob": 6.539305559272179e-06}, {"id": 752, "seek": 366276, "start": 3662.76, "end": 3668.36, "text": " I guess other people might be able to have their own ideas about that.", "tokens": [286, 2041, 661, 561, 1062, 312, 1075, 281, 362, 641, 1065, 3487, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.1434198580290142, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.6441623301943764e-05}, {"id": 753, "seek": 366276, "start": 3668.36, "end": 3671.5200000000004, "text": " So Vishnu said, I made a mistake about what image to tensor is doing.", "tokens": [407, 36752, 16241, 848, 11, 286, 1027, 257, 6146, 466, 437, 3256, 281, 40863, 307, 884, 13], "temperature": 0.0, "avg_logprob": -0.1434198580290142, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.6441623301943764e-05}, {"id": 754, "seek": 366276, "start": 3671.5200000000004, "end": 3672.0800000000004, "text": " That's true.", "tokens": [663, 311, 2074, 13], "temperature": 0.0, "avg_logprob": -0.1434198580290142, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.6441623301943764e-05}, {"id": 755, "seek": 366276, "start": 3672.0800000000004, "end": 3675.5600000000004, "text": " It's actually creating an array.", "tokens": [467, 311, 767, 4084, 364, 10225, 13], "temperature": 0.0, "avg_logprob": -0.1434198580290142, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.6441623301943764e-05}, {"id": 756, "seek": 366276, "start": 3675.5600000000004, "end": 3680.2400000000002, "text": " So I'm glad you asked that question, because this is going to be turned.", "tokens": [407, 286, 478, 5404, 291, 2351, 300, 1168, 11, 570, 341, 307, 516, 281, 312, 3574, 13], "temperature": 0.0, "avg_logprob": -0.1434198580290142, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.6441623301943764e-05}, {"id": 757, "seek": 366276, "start": 3680.2400000000002, "end": 3683.96, "text": " OK, so this is actually a great question.", "tokens": [2264, 11, 370, 341, 307, 767, 257, 869, 1168, 13], "temperature": 0.0, "avg_logprob": -0.1434198580290142, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.6441623301943764e-05}, {"id": 758, "seek": 366276, "start": 3683.96, "end": 3686.84, "text": " The return type of here is tensor image.", "tokens": [440, 2736, 2010, 295, 510, 307, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1434198580290142, "compression_ratio": 1.5981308411214954, "no_speech_prob": 1.6441623301943764e-05}, {"id": 759, "seek": 368684, "start": 3686.84, "end": 3694.1600000000003, "text": " And tensor image is one of these nifty little things we've added,", "tokens": [400, 40863, 3256, 307, 472, 295, 613, 297, 37177, 707, 721, 321, 600, 3869, 11], "temperature": 0.0, "avg_logprob": -0.18835433541911922, "compression_ratio": 1.5314285714285714, "no_speech_prob": 5.093460003990913e-06}, {"id": 760, "seek": 368684, "start": 3694.1600000000003, "end": 3698.88, "text": " which is something which is taking a long time.", "tokens": [597, 307, 746, 597, 307, 1940, 257, 938, 565, 13], "temperature": 0.0, "avg_logprob": -0.18835433541911922, "compression_ratio": 1.5314285714285714, "no_speech_prob": 5.093460003990913e-06}, {"id": 761, "seek": 368684, "start": 3702.8, "end": 3706.36, "text": " Looks like our server is going slowly, which, as you can see,", "tokens": [10027, 411, 527, 7154, 307, 516, 5692, 11, 597, 11, 382, 291, 393, 536, 11], "temperature": 0.0, "avg_logprob": -0.18835433541911922, "compression_ratio": 1.5314285714285714, "no_speech_prob": 5.093460003990913e-06}, {"id": 762, "seek": 368684, "start": 3706.36, "end": 3709.84, "text": " is simply calling this path.", "tokens": [307, 2935, 5141, 341, 3100, 13], "temperature": 0.0, "avg_logprob": -0.18835433541911922, "compression_ratio": 1.5314285714285714, "no_speech_prob": 5.093460003990913e-06}, {"id": 763, "seek": 368684, "start": 3709.84, "end": 3714.48, "text": " So it's just something which we use to mark the type so that we", "tokens": [407, 309, 311, 445, 746, 597, 321, 764, 281, 1491, 264, 2010, 370, 300, 321], "temperature": 0.0, "avg_logprob": -0.18835433541911922, "compression_ratio": 1.5314285714285714, "no_speech_prob": 5.093460003990913e-06}, {"id": 764, "seek": 371448, "start": 3714.48, "end": 3719.6, "text": " can create transforms that are restricted to that type.", "tokens": [393, 1884, 35592, 300, 366, 20608, 281, 300, 2010, 13], "temperature": 0.0, "avg_logprob": -0.11614235678871909, "compression_ratio": 1.7295918367346939, "no_speech_prob": 1.3496816109181964e-06}, {"id": 765, "seek": 371448, "start": 3719.6, "end": 3723.12, "text": " But it's basically just a tensor.", "tokens": [583, 309, 311, 1936, 445, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.11614235678871909, "compression_ratio": 1.7295918367346939, "no_speech_prob": 1.3496816109181964e-06}, {"id": 766, "seek": 371448, "start": 3723.12, "end": 3726.4, "text": " It's a subclass of tensor, in fact.", "tokens": [467, 311, 257, 1422, 11665, 295, 40863, 11, 294, 1186, 13], "temperature": 0.0, "avg_logprob": -0.11614235678871909, "compression_ratio": 1.7295918367346939, "no_speech_prob": 1.3496816109181964e-06}, {"id": 767, "seek": 371448, "start": 3726.4, "end": 3729.6, "text": " But you'll notice this is actually not a transform.", "tokens": [583, 291, 603, 3449, 341, 307, 767, 406, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.11614235678871909, "compression_ratio": 1.7295918367346939, "no_speech_prob": 1.3496816109181964e-06}, {"id": 768, "seek": 371448, "start": 3729.6, "end": 3731.96, "text": " It's just a function.", "tokens": [467, 311, 445, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.11614235678871909, "compression_ratio": 1.7295918367346939, "no_speech_prob": 1.3496816109181964e-06}, {"id": 769, "seek": 371448, "start": 3731.96, "end": 3738.2, "text": " But the cool thing is that any time that you create something that's", "tokens": [583, 264, 1627, 551, 307, 300, 604, 565, 300, 291, 1884, 746, 300, 311], "temperature": 0.0, "avg_logprob": -0.11614235678871909, "compression_ratio": 1.7295918367346939, "no_speech_prob": 1.3496816109181964e-06}, {"id": 770, "seek": 371448, "start": 3738.2, "end": 3743.88, "text": " going to be turned into a pipeline, any functions in there that aren't", "tokens": [516, 281, 312, 3574, 666, 257, 15517, 11, 604, 6828, 294, 456, 300, 3212, 380], "temperature": 0.0, "avg_logprob": -0.11614235678871909, "compression_ratio": 1.7295918367346939, "no_speech_prob": 1.3496816109181964e-06}, {"id": 771, "seek": 374388, "start": 3743.88, "end": 3748.6800000000003, "text": " transforms will be turned into transforms.", "tokens": [35592, 486, 312, 3574, 666, 35592, 13], "temperature": 0.0, "avg_logprob": -0.12179170156780042, "compression_ratio": 1.728813559322034, "no_speech_prob": 2.3687882730882848e-06}, {"id": 772, "seek": 374388, "start": 3748.6800000000003, "end": 3756.88, "text": " So you can actually just go transform image to tensor.", "tokens": [407, 291, 393, 767, 445, 352, 4088, 3256, 281, 40863, 13], "temperature": 0.0, "avg_logprob": -0.12179170156780042, "compression_ratio": 1.728813559322034, "no_speech_prob": 2.3687882730882848e-06}, {"id": 773, "seek": 374388, "start": 3759.44, "end": 3764.96, "text": " And that creates a transform object that will run that function.", "tokens": [400, 300, 7829, 257, 4088, 2657, 300, 486, 1190, 300, 2445, 13], "temperature": 0.0, "avg_logprob": -0.12179170156780042, "compression_ratio": 1.728813559322034, "no_speech_prob": 2.3687882730882848e-06}, {"id": 774, "seek": 374388, "start": 3764.96, "end": 3766.4, "text": " So that's a handy little trick.", "tokens": [407, 300, 311, 257, 13239, 707, 4282, 13], "temperature": 0.0, "avg_logprob": -0.12179170156780042, "compression_ratio": 1.728813559322034, "no_speech_prob": 2.3687882730882848e-06}, {"id": 775, "seek": 374388, "start": 3766.4, "end": 3769.4, "text": " And we'll learn more about it when we get to the transform thing.", "tokens": [400, 321, 603, 1466, 544, 466, 309, 562, 321, 483, 281, 264, 4088, 551, 13], "temperature": 0.0, "avg_logprob": -0.12179170156780042, "compression_ratio": 1.728813559322034, "no_speech_prob": 2.3687882730882848e-06}, {"id": 776, "seek": 374388, "start": 3769.4, "end": 3771.84, "text": " So because this gets turned into a transform,", "tokens": [407, 570, 341, 2170, 3574, 666, 257, 4088, 11], "temperature": 0.0, "avg_logprob": -0.12179170156780042, "compression_ratio": 1.728813559322034, "no_speech_prob": 2.3687882730882848e-06}, {"id": 777, "seek": 377184, "start": 3771.84, "end": 3774.92, "text": " that means that this will automatically take our NumPy array", "tokens": [300, 1355, 300, 341, 486, 6772, 747, 527, 22592, 47, 88, 10225], "temperature": 0.0, "avg_logprob": -0.20766198116800058, "compression_ratio": 1.3305084745762712, "no_speech_prob": 3.6688020372821484e-06}, {"id": 778, "seek": 377184, "start": 3774.92, "end": 3778.96, "text": " and will cast it to a tensor.", "tokens": [293, 486, 4193, 309, 281, 257, 40863, 13], "temperature": 0.0, "avg_logprob": -0.20766198116800058, "compression_ratio": 1.3305084745762712, "no_speech_prob": 3.6688020372821484e-06}, {"id": 779, "seek": 377184, "start": 3778.96, "end": 3783.1200000000003, "text": " And it will also make sure that it only gets called on images.", "tokens": [400, 309, 486, 611, 652, 988, 300, 309, 787, 2170, 1219, 322, 5267, 13], "temperature": 0.0, "avg_logprob": -0.20766198116800058, "compression_ratio": 1.3305084745762712, "no_speech_prob": 3.6688020372821484e-06}, {"id": 780, "seek": 377184, "start": 3786.6400000000003, "end": 3787.1400000000003, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.20766198116800058, "compression_ratio": 1.3305084745762712, "no_speech_prob": 3.6688020372821484e-06}, {"id": 781, "seek": 378714, "start": 3787.14, "end": 3799.14, "text": " OK, so last thing for today, tiffMDL.", "tokens": [2264, 11, 370, 1036, 551, 337, 965, 11, 256, 3661, 44, 35, 43, 13], "temperature": 0.0, "avg_logprob": -0.23317981216142764, "compression_ratio": 1.2456140350877194, "no_speech_prob": 8.7141893345688e-07}, {"id": 782, "seek": 378714, "start": 3803.5, "end": 3810.18, "text": " So tiffMDL is something that inherits from Data Loader.", "tokens": [407, 256, 3661, 44, 35, 43, 307, 746, 300, 9484, 1208, 490, 11888, 6130, 8312, 13], "temperature": 0.0, "avg_logprob": -0.23317981216142764, "compression_ratio": 1.2456140350877194, "no_speech_prob": 8.7141893345688e-07}, {"id": 783, "seek": 378714, "start": 3810.18, "end": 3814.66, "text": " But actually, this is not a PyTorch Data Loader.", "tokens": [583, 767, 11, 341, 307, 406, 257, 9953, 51, 284, 339, 11888, 6130, 8312, 13], "temperature": 0.0, "avg_logprob": -0.23317981216142764, "compression_ratio": 1.2456140350877194, "no_speech_prob": 8.7141893345688e-07}, {"id": 784, "seek": 381466, "start": 3814.66, "end": 3820.1, "text": " This is a fastai data.load.DataLoader.", "tokens": [639, 307, 257, 2370, 1301, 1412, 13, 2907, 13, 35, 3274, 31645, 8312, 13], "temperature": 0.0, "avg_logprob": -0.12999783348791377, "compression_ratio": 1.6117021276595744, "no_speech_prob": 1.191093815577915e-06}, {"id": 785, "seek": 381466, "start": 3820.1, "end": 3823.42, "text": " So we've actually created our own Data Loader", "tokens": [407, 321, 600, 767, 2942, 527, 1065, 11888, 6130, 8312], "temperature": 0.0, "avg_logprob": -0.12999783348791377, "compression_ratio": 1.6117021276595744, "no_speech_prob": 1.191093815577915e-06}, {"id": 786, "seek": 381466, "start": 3823.42, "end": 3829.8199999999997, "text": " to add a lot of handy extra stuff to PyTorch's Data Loader.", "tokens": [281, 909, 257, 688, 295, 13239, 2857, 1507, 281, 9953, 51, 284, 339, 311, 11888, 6130, 8312, 13], "temperature": 0.0, "avg_logprob": -0.12999783348791377, "compression_ratio": 1.6117021276595744, "no_speech_prob": 1.191093815577915e-06}, {"id": 787, "seek": 381466, "start": 3829.8199999999997, "end": 3833.3399999999997, "text": " And one of the nice things we've made it is much more inheritable.", "tokens": [400, 472, 295, 264, 1481, 721, 321, 600, 1027, 309, 307, 709, 544, 9484, 16772, 13], "temperature": 0.0, "avg_logprob": -0.12999783348791377, "compression_ratio": 1.6117021276595744, "no_speech_prob": 1.191093815577915e-06}, {"id": 788, "seek": 381466, "start": 3833.3399999999997, "end": 3836.06, "text": " So we've inherited from that Data Loader.", "tokens": [407, 321, 600, 27091, 490, 300, 11888, 6130, 8312, 13], "temperature": 0.0, "avg_logprob": -0.12999783348791377, "compression_ratio": 1.6117021276595744, "no_speech_prob": 1.191093815577915e-06}, {"id": 789, "seek": 381466, "start": 3836.06, "end": 3839.6, "text": " And what tiffMDL does is it turns the Data Loader", "tokens": [400, 437, 256, 3661, 44, 35, 43, 775, 307, 309, 4523, 264, 11888, 6130, 8312], "temperature": 0.0, "avg_logprob": -0.12999783348791377, "compression_ratio": 1.6117021276595744, "no_speech_prob": 1.191093815577915e-06}, {"id": 790, "seek": 383960, "start": 3839.6, "end": 3845.46, "text": " into something which understands transforms, as the name suggests.", "tokens": [666, 746, 597, 15146, 35592, 11, 382, 264, 1315, 13409, 13], "temperature": 0.0, "avg_logprob": -0.12478679208194508, "compression_ratio": 1.5786802030456852, "no_speech_prob": 1.6441967090941034e-05}, {"id": 791, "seek": 383960, "start": 3845.46, "end": 3850.22, "text": " So to fully understand this, we'll", "tokens": [407, 281, 4498, 1223, 341, 11, 321, 603], "temperature": 0.0, "avg_logprob": -0.12478679208194508, "compression_ratio": 1.5786802030456852, "no_speech_prob": 1.6441967090941034e-05}, {"id": 792, "seek": 383960, "start": 3850.22, "end": 3854.7799999999997, "text": " need to look at the code for Data Loader, which we can do next time.", "tokens": [643, 281, 574, 412, 264, 3089, 337, 11888, 6130, 8312, 11, 597, 321, 393, 360, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.12478679208194508, "compression_ratio": 1.5786802030456852, "no_speech_prob": 1.6441967090941034e-05}, {"id": 793, "seek": 383960, "start": 3857.22, "end": 3859.14, "text": " But there's a few interesting things to show.", "tokens": [583, 456, 311, 257, 1326, 1880, 721, 281, 855, 13], "temperature": 0.0, "avg_logprob": -0.12478679208194508, "compression_ratio": 1.5786802030456852, "no_speech_prob": 1.6441967090941034e-05}, {"id": 794, "seek": 383960, "start": 3859.14, "end": 3862.98, "text": " Let's have a look at it in use first of all.", "tokens": [961, 311, 362, 257, 574, 412, 309, 294, 764, 700, 295, 439, 13], "temperature": 0.0, "avg_logprob": -0.12478679208194508, "compression_ratio": 1.5786802030456852, "no_speech_prob": 1.6441967090941034e-05}, {"id": 795, "seek": 383960, "start": 3862.98, "end": 3867.3399999999997, "text": " So here's a bunch of familiar-looking transforms.", "tokens": [407, 510, 311, 257, 3840, 295, 4963, 12, 16129, 35592, 13], "temperature": 0.0, "avg_logprob": -0.12478679208194508, "compression_ratio": 1.5786802030456852, "no_speech_prob": 1.6441967090941034e-05}, {"id": 796, "seek": 386734, "start": 3867.34, "end": 3872.86, "text": " So here's a tiffMDS, which takes our items, which is the MNIST paths,", "tokens": [407, 510, 311, 257, 256, 3661, 44, 11844, 11, 597, 2516, 527, 4754, 11, 597, 307, 264, 376, 45, 19756, 14518, 11], "temperature": 0.0, "avg_logprob": -0.12568273100742075, "compression_ratio": 1.5138121546961325, "no_speech_prob": 2.9022667149547487e-06}, {"id": 797, "seek": 386734, "start": 3872.86, "end": 3874.02, "text": " and transforms them.", "tokens": [293, 35592, 552, 13], "temperature": 0.0, "avg_logprob": -0.12568273100742075, "compression_ratio": 1.5138121546961325, "no_speech_prob": 2.9022667149547487e-06}, {"id": 798, "seek": 386734, "start": 3874.02, "end": 3879.94, "text": " So it's going to create a pillow image and labeled categories.", "tokens": [407, 309, 311, 516, 281, 1884, 257, 18581, 3256, 293, 21335, 10479, 13], "temperature": 0.0, "avg_logprob": -0.12568273100742075, "compression_ratio": 1.5138121546961325, "no_speech_prob": 2.9022667149547487e-06}, {"id": 799, "seek": 386734, "start": 3879.94, "end": 3885.7400000000002, "text": " And then tiffMDL is going to take that data set", "tokens": [400, 550, 256, 3661, 44, 35, 43, 307, 516, 281, 747, 300, 1412, 992], "temperature": 0.0, "avg_logprob": -0.12568273100742075, "compression_ratio": 1.5138121546961325, "no_speech_prob": 2.9022667149547487e-06}, {"id": 800, "seek": 386734, "start": 3885.7400000000002, "end": 3891.26, "text": " and convert the images to tensors in the Data Loader.", "tokens": [293, 7620, 264, 5267, 281, 10688, 830, 294, 264, 11888, 6130, 8312, 13], "temperature": 0.0, "avg_logprob": -0.12568273100742075, "compression_ratio": 1.5138121546961325, "no_speech_prob": 2.9022667149547487e-06}, {"id": 801, "seek": 386734, "start": 3891.26, "end": 3895.38, "text": " So let's try that.", "tokens": [407, 718, 311, 853, 300, 13], "temperature": 0.0, "avg_logprob": -0.12568273100742075, "compression_ratio": 1.5138121546961325, "no_speech_prob": 2.9022667149547487e-06}, {"id": 802, "seek": 389538, "start": 3895.38, "end": 3903.06, "text": " And so we can now see there's our batch.", "tokens": [400, 370, 321, 393, 586, 536, 456, 311, 527, 15245, 13], "temperature": 0.0, "avg_logprob": -0.13337001535627577, "compression_ratio": 1.5121951219512195, "no_speech_prob": 7.934424957056763e-07}, {"id": 803, "seek": 389538, "start": 3903.06, "end": 3906.94, "text": " And so this is a batch size of 4.", "tokens": [400, 370, 341, 307, 257, 15245, 2744, 295, 1017, 13], "temperature": 0.0, "avg_logprob": -0.13337001535627577, "compression_ratio": 1.5121951219512195, "no_speech_prob": 7.934424957056763e-07}, {"id": 804, "seek": 389538, "start": 3906.94, "end": 3911.82, "text": " So we've got four labels and four images.", "tokens": [407, 321, 600, 658, 1451, 16949, 293, 1451, 5267, 13], "temperature": 0.0, "avg_logprob": -0.13337001535627577, "compression_ratio": 1.5121951219512195, "no_speech_prob": 7.934424957056763e-07}, {"id": 805, "seek": 389538, "start": 3911.82, "end": 3917.82, "text": " But one of the really interesting lines of code here is the test at the bottom.", "tokens": [583, 472, 295, 264, 534, 1880, 3876, 295, 3089, 510, 307, 264, 1500, 412, 264, 2767, 13], "temperature": 0.0, "avg_logprob": -0.13337001535627577, "compression_ratio": 1.5121951219512195, "no_speech_prob": 7.934424957056763e-07}, {"id": 806, "seek": 389538, "start": 3917.82, "end": 3924.58, "text": " It's testing that the decoded version of the batch,", "tokens": [467, 311, 4997, 300, 264, 979, 12340, 3037, 295, 264, 15245, 11], "temperature": 0.0, "avg_logprob": -0.13337001535627577, "compression_ratio": 1.5121951219512195, "no_speech_prob": 7.934424957056763e-07}, {"id": 807, "seek": 392458, "start": 3924.58, "end": 3930.02, "text": " when we map the function type over it, is that it's going to be tensor image,", "tokens": [562, 321, 4471, 264, 2445, 2010, 670, 309, 11, 307, 300, 309, 311, 516, 281, 312, 40863, 3256, 11], "temperature": 0.0, "avg_logprob": -0.1544338893890381, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.029393494420219e-06}, {"id": 808, "seek": 392458, "start": 3930.02, "end": 3931.2599999999998, "text": " category.", "tokens": [7719, 13], "temperature": 0.0, "avg_logprob": -0.1544338893890381, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.029393494420219e-06}, {"id": 809, "seek": 392458, "start": 3931.2599999999998, "end": 3934.38, "text": " So why is that interesting?", "tokens": [407, 983, 307, 300, 1880, 30], "temperature": 0.0, "avg_logprob": -0.1544338893890381, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.029393494420219e-06}, {"id": 810, "seek": 392458, "start": 3934.38, "end": 3937.14, "text": " Well, that's interesting because what this is showing", "tokens": [1042, 11, 300, 311, 1880, 570, 437, 341, 307, 4099], "temperature": 0.0, "avg_logprob": -0.1544338893890381, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.029393494420219e-06}, {"id": 811, "seek": 392458, "start": 3937.14, "end": 3945.1, "text": " is that Fast.ai knows how to take a tensor that comes out of a Data Loader,", "tokens": [307, 300, 15968, 13, 1301, 3255, 577, 281, 747, 257, 40863, 300, 1487, 484, 295, 257, 11888, 6130, 8312, 11], "temperature": 0.0, "avg_logprob": -0.1544338893890381, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.029393494420219e-06}, {"id": 812, "seek": 392458, "start": 3945.1, "end": 3950.94, "text": " which doesn't generally have types, and we'll put the correct types back onto it.", "tokens": [597, 1177, 380, 5101, 362, 3467, 11, 293, 321, 603, 829, 264, 3006, 3467, 646, 3911, 309, 13], "temperature": 0.0, "avg_logprob": -0.1544338893890381, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.029393494420219e-06}, {"id": 813, "seek": 392458, "start": 3950.94, "end": 3954.1, "text": " And so this is super handy for inference,", "tokens": [400, 370, 341, 307, 1687, 13239, 337, 38253, 11], "temperature": 0.0, "avg_logprob": -0.1544338893890381, "compression_ratio": 1.5905172413793103, "no_speech_prob": 4.029393494420219e-06}, {"id": 814, "seek": 395410, "start": 3954.1, "end": 3961.1, "text": " because what it means is that in production, your predictions and stuff", "tokens": [570, 437, 309, 1355, 307, 300, 294, 4265, 11, 428, 21264, 293, 1507], "temperature": 0.0, "avg_logprob": -0.14500293447010554, "compression_ratio": 1.5722543352601157, "no_speech_prob": 5.173797035240568e-06}, {"id": 815, "seek": 395410, "start": 3961.1, "end": 3963.38, "text": " are going to have proper types.", "tokens": [366, 516, 281, 362, 2296, 3467, 13], "temperature": 0.0, "avg_logprob": -0.14500293447010554, "compression_ratio": 1.5722543352601157, "no_speech_prob": 5.173797035240568e-06}, {"id": 816, "seek": 395410, "start": 3963.38, "end": 3969.06, "text": " So you can actually call normal methods and transforms and stuff on them.", "tokens": [407, 291, 393, 767, 818, 2710, 7150, 293, 35592, 293, 1507, 322, 552, 13], "temperature": 0.0, "avg_logprob": -0.14500293447010554, "compression_ratio": 1.5722543352601157, "no_speech_prob": 5.173797035240568e-06}, {"id": 817, "seek": 395410, "start": 3969.06, "end": 3977.06, "text": " So it's super handy for inference and also for applying stuff to a test set,", "tokens": [407, 309, 311, 1687, 13239, 337, 38253, 293, 611, 337, 9275, 1507, 281, 257, 1500, 992, 11], "temperature": 0.0, "avg_logprob": -0.14500293447010554, "compression_ratio": 1.5722543352601157, "no_speech_prob": 5.173797035240568e-06}, {"id": 818, "seek": 395410, "start": 3977.06, "end": 3980.3399999999997, "text": " things like that.", "tokens": [721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.14500293447010554, "compression_ratio": 1.5722543352601157, "no_speech_prob": 5.173797035240568e-06}, {"id": 819, "seek": 398034, "start": 3980.34, "end": 3986.54, "text": " So this is actually an interesting line of code.", "tokens": [407, 341, 307, 767, 364, 1880, 1622, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1668270054985495, "compression_ratio": 1.3624161073825503, "no_speech_prob": 2.2602916942560114e-06}, {"id": 820, "seek": 398034, "start": 3986.54, "end": 3988.2200000000003, "text": " So let's look at it.", "tokens": [407, 718, 311, 574, 412, 309, 13], "temperature": 0.0, "avg_logprob": -0.1668270054985495, "compression_ratio": 1.3624161073825503, "no_speech_prob": 2.2602916942560114e-06}, {"id": 821, "seek": 398034, "start": 3988.2200000000003, "end": 3995.1800000000003, "text": " So we're going to start with tdl.decodeBatchB.", "tokens": [407, 321, 434, 516, 281, 722, 365, 256, 67, 75, 13, 42821, 1429, 33, 852, 33, 13], "temperature": 0.0, "avg_logprob": -0.1668270054985495, "compression_ratio": 1.3624161073825503, "no_speech_prob": 2.2602916942560114e-06}, {"id": 822, "seek": 398034, "start": 3995.1800000000003, "end": 3997.06, "text": " So remember, B was our batch.", "tokens": [407, 1604, 11, 363, 390, 527, 15245, 13], "temperature": 0.0, "avg_logprob": -0.1668270054985495, "compression_ratio": 1.3624161073825503, "no_speech_prob": 2.2602916942560114e-06}, {"id": 823, "seek": 398034, "start": 3997.06, "end": 4003.06, "text": " It's going to contain four MNIST images and four labels.", "tokens": [467, 311, 516, 281, 5304, 1451, 376, 45, 19756, 5267, 293, 1451, 16949, 13], "temperature": 0.0, "avg_logprob": -0.1668270054985495, "compression_ratio": 1.3624161073825503, "no_speech_prob": 2.2602916942560114e-06}, {"id": 824, "seek": 400306, "start": 4003.06, "end": 4012.58, "text": " So the decoded version of that is nearly the same thing,", "tokens": [407, 264, 979, 12340, 3037, 295, 300, 307, 6217, 264, 912, 551, 11], "temperature": 0.0, "avg_logprob": -0.14791496889090833, "compression_ratio": 1.5917159763313609, "no_speech_prob": 7.002118422860804e-07}, {"id": 825, "seek": 400306, "start": 4012.58, "end": 4015.34, "text": " but now we've got, rather than two things,", "tokens": [457, 586, 321, 600, 658, 11, 2831, 813, 732, 721, 11], "temperature": 0.0, "avg_logprob": -0.14791496889090833, "compression_ratio": 1.5917159763313609, "no_speech_prob": 7.002118422860804e-07}, {"id": 826, "seek": 400306, "start": 4015.34, "end": 4021.02, "text": " we've got four things because they're four pairs of image and label.", "tokens": [321, 600, 658, 1451, 721, 570, 436, 434, 1451, 15494, 295, 3256, 293, 7645, 13], "temperature": 0.0, "avg_logprob": -0.14791496889090833, "compression_ratio": 1.5917159763313609, "no_speech_prob": 7.002118422860804e-07}, {"id": 827, "seek": 400306, "start": 4021.02, "end": 4023.2999999999997, "text": " And now you'll see the label's a string.", "tokens": [400, 586, 291, 603, 536, 264, 7645, 311, 257, 6798, 13], "temperature": 0.0, "avg_logprob": -0.14791496889090833, "compression_ratio": 1.5917159763313609, "no_speech_prob": 7.002118422860804e-07}, {"id": 828, "seek": 400306, "start": 4023.2999999999997, "end": 4026.5, "text": " Image and label.", "tokens": [29903, 293, 7645, 13], "temperature": 0.0, "avg_logprob": -0.14791496889090833, "compression_ratio": 1.5917159763313609, "no_speech_prob": 7.002118422860804e-07}, {"id": 829, "seek": 400306, "start": 4026.5, "end": 4029.02, "text": " So that's what decodeBatch is going to do,", "tokens": [407, 300, 311, 437, 979, 1429, 33, 852, 307, 516, 281, 360, 11], "temperature": 0.0, "avg_logprob": -0.14791496889090833, "compression_ratio": 1.5917159763313609, "no_speech_prob": 7.002118422860804e-07}, {"id": 830, "seek": 402902, "start": 4029.02, "end": 4033.54, "text": " is it's going to turn it into a form that's much more ready for showing.", "tokens": [307, 309, 311, 516, 281, 1261, 309, 666, 257, 1254, 300, 311, 709, 544, 1919, 337, 4099, 13], "temperature": 0.0, "avg_logprob": -0.24159969500641323, "compression_ratio": 1.401360544217687, "no_speech_prob": 3.844825641863281e-06}, {"id": 831, "seek": 402902, "start": 4036.9, "end": 4042.5, "text": " And so I think we should be able to go show titled image.", "tokens": [400, 370, 286, 519, 321, 820, 312, 1075, 281, 352, 855, 19841, 3256, 13], "temperature": 0.0, "avg_logprob": -0.24159969500641323, "compression_ratio": 1.401360544217687, "no_speech_prob": 3.844825641863281e-06}, {"id": 832, "seek": 402902, "start": 4042.5, "end": 4044.9, "text": " And then we could say, show us the 0th one of those.", "tokens": [400, 550, 321, 727, 584, 11, 855, 505, 264, 1958, 392, 472, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.24159969500641323, "compression_ratio": 1.401360544217687, "no_speech_prob": 3.844825641863281e-06}, {"id": 833, "seek": 402902, "start": 4049.14, "end": 4050.3, "text": " Yeah, there it is.", "tokens": [865, 11, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.24159969500641323, "compression_ratio": 1.401360544217687, "no_speech_prob": 3.844825641863281e-06}, {"id": 834, "seek": 402902, "start": 4050.3, "end": 4051.22, "text": " OK?", "tokens": [2264, 30], "temperature": 0.0, "avg_logprob": -0.24159969500641323, "compression_ratio": 1.401360544217687, "no_speech_prob": 3.844825641863281e-06}, {"id": 835, "seek": 405122, "start": 4051.22, "end": 4063.9399999999996, "text": " So and so then what I wanted to do was I basically,", "tokens": [407, 293, 370, 550, 437, 286, 1415, 281, 360, 390, 286, 1936, 11], "temperature": 0.0, "avg_logprob": -0.17838970531116832, "compression_ratio": 1.4883720930232558, "no_speech_prob": 1.136551190938917e-06}, {"id": 836, "seek": 405122, "start": 4063.9399999999996, "end": 4066.5, "text": " that contains two things.", "tokens": [300, 8306, 732, 721, 13], "temperature": 0.0, "avg_logprob": -0.17838970531116832, "compression_ratio": 1.4883720930232558, "no_speech_prob": 1.136551190938917e-06}, {"id": 837, "seek": 405122, "start": 4066.5, "end": 4073.4599999999996, "text": " If I just grab the first image, it contains the image and the category.", "tokens": [759, 286, 445, 4444, 264, 700, 3256, 11, 309, 8306, 264, 3256, 293, 264, 7719, 13], "temperature": 0.0, "avg_logprob": -0.17838970531116832, "compression_ratio": 1.4883720930232558, "no_speech_prob": 1.136551190938917e-06}, {"id": 838, "seek": 405122, "start": 4073.4599999999996, "end": 4076.1, "text": " And what I really wanted to do was to say,", "tokens": [400, 437, 286, 534, 1415, 281, 360, 390, 281, 584, 11], "temperature": 0.0, "avg_logprob": -0.17838970531116832, "compression_ratio": 1.4883720930232558, "no_speech_prob": 1.136551190938917e-06}, {"id": 839, "seek": 407610, "start": 4076.1, "end": 4085.18, "text": " x comma y equals that, and then print out type x comma type y,", "tokens": [2031, 22117, 288, 6915, 300, 11, 293, 550, 4482, 484, 2010, 2031, 22117, 2010, 288, 11], "temperature": 0.0, "avg_logprob": -0.11926559566222515, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.3845872672391124e-05}, {"id": 840, "seek": 407610, "start": 4085.18, "end": 4087.14, "text": " which is a little bit awkward.", "tokens": [597, 307, 257, 707, 857, 11411, 13], "temperature": 0.0, "avg_logprob": -0.11926559566222515, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.3845872672391124e-05}, {"id": 841, "seek": 407610, "start": 4087.14, "end": 4092.8199999999997, "text": " So what we can do instead is we can wrap this in an L", "tokens": [407, 437, 321, 393, 360, 2602, 307, 321, 393, 7019, 341, 294, 364, 441], "temperature": 0.0, "avg_logprob": -0.11926559566222515, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.3845872672391124e-05}, {"id": 842, "seek": 407610, "start": 4092.8199999999997, "end": 4094.46, "text": " and then just call mapped.", "tokens": [293, 550, 445, 818, 33318, 13], "temperature": 0.0, "avg_logprob": -0.11926559566222515, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.3845872672391124e-05}, {"id": 843, "seek": 407610, "start": 4094.46, "end": 4096.54, "text": " And that will map a function over it.", "tokens": [400, 300, 486, 4471, 257, 2445, 670, 309, 13], "temperature": 0.0, "avg_logprob": -0.11926559566222515, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.3845872672391124e-05}, {"id": 844, "seek": 407610, "start": 4096.54, "end": 4099.94, "text": " And the function I want to map over it is type.", "tokens": [400, 264, 2445, 286, 528, 281, 4471, 670, 309, 307, 2010, 13], "temperature": 0.0, "avg_logprob": -0.11926559566222515, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.3845872672391124e-05}, {"id": 845, "seek": 407610, "start": 4099.94, "end": 4102.3, "text": " And that gives me exactly the same thing.", "tokens": [400, 300, 2709, 385, 2293, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.11926559566222515, "compression_ratio": 1.6565656565656566, "no_speech_prob": 1.3845872672391124e-05}, {"id": 846, "seek": 410230, "start": 4102.3, "end": 4106.900000000001, "text": " So that's what that does.", "tokens": [407, 300, 311, 437, 300, 775, 13], "temperature": 0.0, "avg_logprob": -0.18466253714127975, "compression_ratio": 1.4656862745098038, "no_speech_prob": 1.1189334827577113e-06}, {"id": 847, "seek": 410230, "start": 4106.900000000001, "end": 4112.18, "text": " Aravain asks, did Swift AI influence the design of v2?", "tokens": [316, 13404, 491, 8962, 11, 630, 25539, 7318, 6503, 264, 1715, 295, 371, 17, 30], "temperature": 0.0, "avg_logprob": -0.18466253714127975, "compression_ratio": 1.4656862745098038, "no_speech_prob": 1.1189334827577113e-06}, {"id": 848, "seek": 410230, "start": 4112.18, "end": 4114.3, "text": " Yeah, a bit.", "tokens": [865, 11, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.18466253714127975, "compression_ratio": 1.4656862745098038, "no_speech_prob": 1.1189334827577113e-06}, {"id": 849, "seek": 410230, "start": 4114.3, "end": 4118.860000000001, "text": " I've been using static languages a lot longer than dynamic languages,", "tokens": [286, 600, 668, 1228, 13437, 8650, 257, 688, 2854, 813, 8546, 8650, 11], "temperature": 0.0, "avg_logprob": -0.18466253714127975, "compression_ratio": 1.4656862745098038, "no_speech_prob": 1.1189334827577113e-06}, {"id": 850, "seek": 410230, "start": 4118.860000000001, "end": 4119.74, "text": " honestly.", "tokens": [6095, 13], "temperature": 0.0, "avg_logprob": -0.18466253714127975, "compression_ratio": 1.4656862745098038, "no_speech_prob": 1.1189334827577113e-06}, {"id": 851, "seek": 410230, "start": 4119.74, "end": 4124.42, "text": " So I don't think the type stuff is particularly from that.", "tokens": [407, 286, 500, 380, 519, 264, 2010, 1507, 307, 4098, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.18466253714127975, "compression_ratio": 1.4656862745098038, "no_speech_prob": 1.1189334827577113e-06}, {"id": 852, "seek": 410230, "start": 4124.42, "end": 4129.3, "text": " In fact, we're using types in a very, very different way to Swift.", "tokens": [682, 1186, 11, 321, 434, 1228, 3467, 294, 257, 588, 11, 588, 819, 636, 281, 25539, 13], "temperature": 0.0, "avg_logprob": -0.18466253714127975, "compression_ratio": 1.4656862745098038, "no_speech_prob": 1.1189334827577113e-06}, {"id": 853, "seek": 412930, "start": 4129.3, "end": 4133.1, "text": " Swift is statically typed, so you can't quite do the same kinds of things", "tokens": [25539, 307, 2219, 984, 33941, 11, 370, 291, 393, 380, 1596, 360, 264, 912, 3685, 295, 721], "temperature": 0.0, "avg_logprob": -0.1298476517802537, "compression_ratio": 1.625, "no_speech_prob": 2.902251026171143e-06}, {"id": 854, "seek": 412930, "start": 4133.1, "end": 4134.74, "text": " with types.", "tokens": [365, 3467, 13], "temperature": 0.0, "avg_logprob": -0.1298476517802537, "compression_ratio": 1.625, "no_speech_prob": 2.902251026171143e-06}, {"id": 855, "seek": 412930, "start": 4134.74, "end": 4140.900000000001, "text": " This is, to me, a really interesting use of dynamic types.", "tokens": [639, 307, 11, 281, 385, 11, 257, 534, 1880, 764, 295, 8546, 3467, 13], "temperature": 0.0, "avg_logprob": -0.1298476517802537, "compression_ratio": 1.625, "no_speech_prob": 2.902251026171143e-06}, {"id": 856, "seek": 412930, "start": 4140.900000000001, "end": 4147.62, "text": " And so I think part of it comes out of saying, OK,", "tokens": [400, 370, 286, 519, 644, 295, 309, 1487, 484, 295, 1566, 11, 2264, 11], "temperature": 0.0, "avg_logprob": -0.1298476517802537, "compression_ratio": 1.625, "no_speech_prob": 2.902251026171143e-06}, {"id": 857, "seek": 412930, "start": 4147.62, "end": 4150.3, "text": " Python has a lot of issues with performance", "tokens": [15329, 575, 257, 688, 295, 2663, 365, 3389], "temperature": 0.0, "avg_logprob": -0.1298476517802537, "compression_ratio": 1.625, "no_speech_prob": 2.902251026171143e-06}, {"id": 858, "seek": 412930, "start": 4150.3, "end": 4153.22, "text": " because it's a dynamically typed language.", "tokens": [570, 309, 311, 257, 43492, 33941, 2856, 13], "temperature": 0.0, "avg_logprob": -0.1298476517802537, "compression_ratio": 1.625, "no_speech_prob": 2.902251026171143e-06}, {"id": 859, "seek": 412930, "start": 4153.22, "end": 4155.14, "text": " But we may as well at least take advantage", "tokens": [583, 321, 815, 382, 731, 412, 1935, 747, 5002], "temperature": 0.0, "avg_logprob": -0.1298476517802537, "compression_ratio": 1.625, "no_speech_prob": 2.902251026171143e-06}, {"id": 860, "seek": 412930, "start": 4155.14, "end": 4158.58, "text": " of the dynamic typing of the language.", "tokens": [295, 264, 8546, 18444, 295, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.1298476517802537, "compression_ratio": 1.625, "no_speech_prob": 2.902251026171143e-06}, {"id": 861, "seek": 415858, "start": 4158.58, "end": 4166.5, "text": " So we're trying to take more advantage of the Python's foundations", "tokens": [407, 321, 434, 1382, 281, 747, 544, 5002, 295, 264, 15329, 311, 22467], "temperature": 0.0, "avg_logprob": -0.1975118374002391, "compression_ratio": 1.4518072289156627, "no_speech_prob": 1.3709224049307522e-06}, {"id": 862, "seek": 415858, "start": 4166.5, "end": 4168.5, "text": " as part of what's going on.", "tokens": [382, 644, 295, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.1975118374002391, "compression_ratio": 1.4518072289156627, "no_speech_prob": 1.3709224049307522e-06}, {"id": 863, "seek": 415858, "start": 4168.5, "end": 4173.82, "text": " But yeah, I think doing this stuff with Swift certainly had some influence.", "tokens": [583, 1338, 11, 286, 519, 884, 341, 1507, 365, 25539, 3297, 632, 512, 6503, 13], "temperature": 0.0, "avg_logprob": -0.1975118374002391, "compression_ratio": 1.4518072289156627, "no_speech_prob": 1.3709224049307522e-06}, {"id": 864, "seek": 415858, "start": 4173.82, "end": 4177.78, "text": " And certainly talking to Chris Latner had some influence specifically.", "tokens": [400, 3297, 1417, 281, 6688, 7354, 1193, 632, 512, 6503, 4682, 13], "temperature": 0.0, "avg_logprob": -0.1975118374002391, "compression_ratio": 1.4518072289156627, "no_speech_prob": 1.3709224049307522e-06}, {"id": 865, "seek": 417778, "start": 4177.78, "end": 4189.0599999999995, "text": " So a TransformDataLoader has a.1 batch method, which actually you'll see", "tokens": [407, 257, 27938, 35, 3274, 31645, 8312, 575, 257, 2411, 16, 15245, 3170, 11, 597, 767, 291, 603, 536], "temperature": 0.0, "avg_logprob": -0.34851989005375833, "compression_ratio": 1.6402116402116402, "no_speech_prob": 6.643201231781859e-06}, {"id": 866, "seek": 417778, "start": 4189.0599999999995, "end": 4189.98, "text": " isn't here.", "tokens": [1943, 380, 510, 13], "temperature": 0.0, "avg_logprob": -0.34851989005375833, "compression_ratio": 1.6402116402116402, "no_speech_prob": 6.643201231781859e-06}, {"id": 867, "seek": 417778, "start": 4189.98, "end": 4193.0599999999995, "text": " And that's because it's in DataLoader.", "tokens": [400, 300, 311, 570, 309, 311, 294, 11888, 31645, 8312, 13], "temperature": 0.0, "avg_logprob": -0.34851989005375833, "compression_ratio": 1.6402116402116402, "no_speech_prob": 6.643201231781859e-06}, {"id": 868, "seek": 417778, "start": 4193.0599999999995, "end": 4197.74, "text": " But we can look at to fmdl.1 batch.", "tokens": [583, 321, 393, 574, 412, 281, 283, 76, 67, 75, 13, 16, 15245, 13], "temperature": 0.0, "avg_logprob": -0.34851989005375833, "compression_ratio": 1.6402116402116402, "no_speech_prob": 6.643201231781859e-06}, {"id": 869, "seek": 417778, "start": 4197.74, "end": 4201.58, "text": " And as you can see, it'll give us the definition,", "tokens": [400, 382, 291, 393, 536, 11, 309, 603, 976, 505, 264, 7123, 11], "temperature": 0.0, "avg_logprob": -0.34851989005375833, "compression_ratio": 1.6402116402116402, "no_speech_prob": 6.643201231781859e-06}, {"id": 870, "seek": 417778, "start": 4201.58, "end": 4203.5, "text": " even though it's actually in a superclass.", "tokens": [754, 1673, 309, 311, 767, 294, 257, 1687, 11665, 13], "temperature": 0.0, "avg_logprob": -0.34851989005375833, "compression_ratio": 1.6402116402116402, "no_speech_prob": 6.643201231781859e-06}, {"id": 871, "seek": 417778, "start": 4203.5, "end": 4207.219999999999, "text": " And as you can see, it's just going next in a superclass.", "tokens": [400, 382, 291, 393, 536, 11, 309, 311, 445, 516, 958, 294, 257, 1687, 11665, 13], "temperature": 0.0, "avg_logprob": -0.34851989005375833, "compression_ratio": 1.6402116402116402, "no_speech_prob": 6.643201231781859e-06}, {"id": 872, "seek": 420722, "start": 4207.22, "end": 4208.820000000001, "text": " Which we do all the time.", "tokens": [3013, 321, 360, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.22997537631432988, "compression_ratio": 1.6338028169014085, "no_speech_prob": 2.1444266167236492e-05}, {"id": 873, "seek": 420722, "start": 4208.820000000001, "end": 4212.3, "text": " So we thought we may as well put it into a method.", "tokens": [407, 321, 1194, 321, 815, 382, 731, 829, 309, 666, 257, 3170, 13], "temperature": 0.0, "avg_logprob": -0.22997537631432988, "compression_ratio": 1.6338028169014085, "no_speech_prob": 2.1444266167236492e-05}, {"id": 874, "seek": 420722, "start": 4212.3, "end": 4215.9800000000005, "text": " It's really something you just use for interactive usage and tests.", "tokens": [467, 311, 534, 746, 291, 445, 764, 337, 15141, 14924, 293, 6921, 13], "temperature": 0.0, "avg_logprob": -0.22997537631432988, "compression_ratio": 1.6338028169014085, "no_speech_prob": 2.1444266167236492e-05}, {"id": 875, "seek": 420722, "start": 4220.14, "end": 4221.9800000000005, "text": " So let's look at to fmdl some more.", "tokens": [407, 718, 311, 574, 412, 281, 283, 76, 67, 75, 512, 544, 13], "temperature": 0.0, "avg_logprob": -0.22997537631432988, "compression_ratio": 1.6338028169014085, "no_speech_prob": 2.1444266167236492e-05}, {"id": 876, "seek": 420722, "start": 4224.66, "end": 4226.62, "text": " Here's a transform with encodes and decodes.", "tokens": [1692, 311, 257, 4088, 365, 2058, 4789, 293, 979, 4789, 13], "temperature": 0.0, "avg_logprob": -0.22997537631432988, "compression_ratio": 1.6338028169014085, "no_speech_prob": 2.1444266167236492e-05}, {"id": 877, "seek": 420722, "start": 4229.34, "end": 4232.02, "text": " And so specifically, encodes is negative x.", "tokens": [400, 370, 4682, 11, 2058, 4789, 307, 3671, 2031, 13], "temperature": 0.0, "avg_logprob": -0.22997537631432988, "compression_ratio": 1.6338028169014085, "no_speech_prob": 2.1444266167236492e-05}, {"id": 878, "seek": 420722, "start": 4232.02, "end": 4233.3, "text": " Decodes is negative x.", "tokens": [12427, 4789, 307, 3671, 2031, 13], "temperature": 0.0, "avg_logprob": -0.22997537631432988, "compression_ratio": 1.6338028169014085, "no_speech_prob": 2.1444266167236492e-05}, {"id": 879, "seek": 420722, "start": 4233.3, "end": 4234.02, "text": " That makes sense.", "tokens": [663, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.22997537631432988, "compression_ratio": 1.6338028169014085, "no_speech_prob": 2.1444266167236492e-05}, {"id": 880, "seek": 423402, "start": 4234.02, "end": 4240.1, "text": " It's a reversible negative transform.", "tokens": [467, 311, 257, 44788, 3671, 4088, 13], "temperature": 0.0, "avg_logprob": -0.12005499344837817, "compression_ratio": 1.4875621890547264, "no_speech_prob": 3.237718374293763e-06}, {"id": 881, "seek": 423402, "start": 4240.1, "end": 4244.700000000001, "text": " And these are both things that can be applied to a whole batch at a time.", "tokens": [400, 613, 366, 1293, 721, 300, 393, 312, 6456, 281, 257, 1379, 15245, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.12005499344837817, "compression_ratio": 1.4875621890547264, "no_speech_prob": 3.237718374293763e-06}, {"id": 882, "seek": 423402, "start": 4244.700000000001, "end": 4251.620000000001, "text": " Because the negative operator in Python doesn't care what rank something is.", "tokens": [1436, 264, 3671, 12973, 294, 15329, 1177, 380, 1127, 437, 6181, 746, 307, 13], "temperature": 0.0, "avg_logprob": -0.12005499344837817, "compression_ratio": 1.4875621890547264, "no_speech_prob": 3.237718374293763e-06}, {"id": 883, "seek": 423402, "start": 4251.620000000001, "end": 4254.18, "text": " So we can put that in the after batch.", "tokens": [407, 321, 393, 829, 300, 294, 264, 934, 15245, 13], "temperature": 0.0, "avg_logprob": -0.12005499344837817, "compression_ratio": 1.4875621890547264, "no_speech_prob": 3.237718374293763e-06}, {"id": 884, "seek": 423402, "start": 4254.18, "end": 4257.14, "text": " And so if we had CUDA as well, then this would actually run on the GPU.", "tokens": [400, 370, 498, 321, 632, 29777, 7509, 382, 731, 11, 550, 341, 576, 767, 1190, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.12005499344837817, "compression_ratio": 1.4875621890547264, "no_speech_prob": 3.237718374293763e-06}, {"id": 885, "seek": 425714, "start": 4257.14, "end": 4262.860000000001, "text": " And these things also all work with more than one worker.", "tokens": [400, 613, 721, 611, 439, 589, 365, 544, 813, 472, 11346, 13], "temperature": 0.0, "avg_logprob": -0.457561280992296, "compression_ratio": 1.4210526315789473, "no_speech_prob": 2.601577079985873e-06}, {"id": 886, "seek": 425714, "start": 4262.860000000001, "end": 4265.38, "text": " So there's no need to do next in a TDO.", "tokens": [407, 456, 311, 572, 643, 281, 360, 958, 294, 257, 314, 26649, 13], "temperature": 0.0, "avg_logprob": -0.457561280992296, "compression_ratio": 1.4210526315789473, "no_speech_prob": 2.601577079985873e-06}, {"id": 887, "seek": 425714, "start": 4265.38, "end": 4266.820000000001, "text": " We can just do tdl.1 batch.", "tokens": [492, 393, 445, 360, 256, 67, 75, 13, 16, 15245, 13], "temperature": 0.0, "avg_logprob": -0.457561280992296, "compression_ratio": 1.4210526315789473, "no_speech_prob": 2.601577079985873e-06}, {"id": 888, "seek": 425714, "start": 4273.46, "end": 4280.1, "text": " And in this case, it's actually making sure that,", "tokens": [400, 294, 341, 1389, 11, 309, 311, 767, 1455, 988, 300, 11], "temperature": 0.0, "avg_logprob": -0.457561280992296, "compression_ratio": 1.4210526315789473, "no_speech_prob": 2.601577079985873e-06}, {"id": 889, "seek": 425714, "start": 4280.1, "end": 4286.780000000001, "text": " so if we look at train.ds, it's actually", "tokens": [370, 498, 321, 574, 412, 3847, 13, 16063, 11, 309, 311, 767], "temperature": 0.0, "avg_logprob": -0.457561280992296, "compression_ratio": 1.4210526315789473, "no_speech_prob": 2.601577079985873e-06}, {"id": 890, "seek": 428678, "start": 4286.78, "end": 4291.0599999999995, "text": " train.ds that's got an image and a label.", "tokens": [3847, 13, 16063, 300, 311, 658, 364, 3256, 293, 257, 7645, 13], "temperature": 0.0, "avg_logprob": -0.2483675541021885, "compression_ratio": 1.8066666666666666, "no_speech_prob": 1.4738207028131e-05}, {"id": 891, "seek": 428678, "start": 4291.0599999999995, "end": 4294.58, "text": " Let's give train.ds 0, an image and a label.", "tokens": [961, 311, 976, 3847, 13, 16063, 1958, 11, 364, 3256, 293, 257, 7645, 13], "temperature": 0.0, "avg_logprob": -0.2483675541021885, "compression_ratio": 1.8066666666666666, "no_speech_prob": 1.4738207028131e-05}, {"id": 892, "seek": 428678, "start": 4294.58, "end": 4302.78, "text": " And the type of train.ds 0 image is a tensor image.", "tokens": [400, 264, 2010, 295, 3847, 13, 16063, 1958, 3256, 307, 257, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2483675541021885, "compression_ratio": 1.8066666666666666, "no_speech_prob": 1.4738207028131e-05}, {"id": 893, "seek": 428678, "start": 4302.78, "end": 4305.259999999999, "text": " And so one of the interesting things here is we're", "tokens": [400, 370, 472, 295, 264, 1880, 721, 510, 307, 321, 434], "temperature": 0.0, "avg_logprob": -0.2483675541021885, "compression_ratio": 1.8066666666666666, "no_speech_prob": 1.4738207028131e-05}, {"id": 894, "seek": 428678, "start": 4305.259999999999, "end": 4313.98, "text": " checking that the type after going through the transform is still a tensor image.", "tokens": [8568, 300, 264, 2010, 934, 516, 807, 264, 4088, 307, 920, 257, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2483675541021885, "compression_ratio": 1.8066666666666666, "no_speech_prob": 1.4738207028131e-05}, {"id": 895, "seek": 431398, "start": 4313.98, "end": 4317.299999999999, "text": " Now that's actually not particularly easy to do.", "tokens": [823, 300, 311, 767, 406, 4098, 1858, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.24393452962239584, "compression_ratio": 1.4417177914110428, "no_speech_prob": 5.014635917177657e-06}, {"id": 896, "seek": 431398, "start": 4317.299999999999, "end": 4318.459999999999, "text": " Because look at this.", "tokens": [1436, 574, 412, 341, 13], "temperature": 0.0, "avg_logprob": -0.24393452962239584, "compression_ratio": 1.4417177914110428, "no_speech_prob": 5.014635917177657e-06}, {"id": 897, "seek": 431398, "start": 4318.459999999999, "end": 4328.459999999999, "text": " What if we say t equals that, and then we'll go t2 equals negative t.", "tokens": [708, 498, 321, 584, 256, 6915, 300, 11, 293, 550, 321, 603, 352, 256, 17, 6915, 3671, 256, 13], "temperature": 0.0, "avg_logprob": -0.24393452962239584, "compression_ratio": 1.4417177914110428, "no_speech_prob": 5.014635917177657e-06}, {"id": 898, "seek": 431398, "start": 4328.459999999999, "end": 4332.179999999999, "text": " So type of t is tensor image.", "tokens": [407, 2010, 295, 256, 307, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.24393452962239584, "compression_ratio": 1.4417177914110428, "no_speech_prob": 5.014635917177657e-06}, {"id": 899, "seek": 431398, "start": 4332.179999999999, "end": 4337.179999999999, "text": " But type of t2, oh, sorry.", "tokens": [583, 2010, 295, 256, 17, 11, 1954, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.24393452962239584, "compression_ratio": 1.4417177914110428, "no_speech_prob": 5.014635917177657e-06}, {"id": 900, "seek": 431398, "start": 4337.179999999999, "end": 4338.62, "text": " Let's do it actually a different way.", "tokens": [961, 311, 360, 309, 767, 257, 819, 636, 13], "temperature": 0.0, "avg_logprob": -0.24393452962239584, "compression_ratio": 1.4417177914110428, "no_speech_prob": 5.014635917177657e-06}, {"id": 901, "seek": 433862, "start": 4338.62, "end": 4349.54, "text": " Torch.meg t is tensor.", "tokens": [7160, 339, 13, 42800, 256, 307, 40863, 13], "temperature": 0.0, "avg_logprob": -0.42666503361293245, "compression_ratio": 1.3425925925925926, "no_speech_prob": 2.1567796011368046e-06}, {"id": 902, "seek": 433862, "start": 4349.54, "end": 4351.26, "text": " You've got to be a bit careful.", "tokens": [509, 600, 658, 281, 312, 257, 857, 5026, 13], "temperature": 0.0, "avg_logprob": -0.42666503361293245, "compression_ratio": 1.3425925925925926, "no_speech_prob": 2.1567796011368046e-06}, {"id": 903, "seek": 433862, "start": 4351.26, "end": 4354.14, "text": " And so actually this would be a better test if we use torch.meg.", "tokens": [400, 370, 767, 341, 576, 312, 257, 1101, 1500, 498, 321, 764, 27822, 13, 42800, 13], "temperature": 0.0, "avg_logprob": -0.42666503361293245, "compression_ratio": 1.3425925925925926, "no_speech_prob": 2.1567796011368046e-06}, {"id": 904, "seek": 433862, "start": 4358.66, "end": 4359.86, "text": " Torch.meg x.", "tokens": [7160, 339, 13, 42800, 2031, 13], "temperature": 0.0, "avg_logprob": -0.42666503361293245, "compression_ratio": 1.3425925925925926, "no_speech_prob": 2.1567796011368046e-06}, {"id": 905, "seek": 435986, "start": 4359.86, "end": 4369.46, "text": " Torch.meg x.", "tokens": [7160, 339, 13, 42800, 2031, 13], "temperature": 0.0, "avg_logprob": -0.23208028078079224, "compression_ratio": 1.4630872483221478, "no_speech_prob": 8.714150112609786e-07}, {"id": 906, "seek": 435986, "start": 4369.46, "end": 4374.38, "text": " Still passes, even though it looks like it shouldn't pass.", "tokens": [8291, 11335, 11, 754, 1673, 309, 1542, 411, 309, 4659, 380, 1320, 13], "temperature": 0.0, "avg_logprob": -0.23208028078079224, "compression_ratio": 1.4630872483221478, "no_speech_prob": 8.714150112609786e-07}, {"id": 907, "seek": 435986, "start": 4374.38, "end": 4378.0599999999995, "text": " And the reason for that is that all of the transformation pipelines,", "tokens": [400, 264, 1778, 337, 300, 307, 300, 439, 295, 264, 9887, 40168, 11], "temperature": 0.0, "avg_logprob": -0.23208028078079224, "compression_ratio": 1.4630872483221478, "no_speech_prob": 8.714150112609786e-07}, {"id": 908, "seek": 435986, "start": 4378.0599999999995, "end": 4383.82, "text": " tiffinds, tiffindol, stuff like that, all check after it goes through encodes", "tokens": [256, 3661, 471, 82, 11, 256, 3661, 471, 401, 11, 1507, 411, 300, 11, 439, 1520, 934, 309, 1709, 807, 2058, 4789], "temperature": 0.0, "avg_logprob": -0.23208028078079224, "compression_ratio": 1.4630872483221478, "no_speech_prob": 8.714150112609786e-07}, {"id": 909, "seek": 438382, "start": 4383.82, "end": 4390.219999999999, "text": " or decodes that the type doesn't change.", "tokens": [420, 979, 4789, 300, 264, 2010, 1177, 380, 1319, 13], "temperature": 0.0, "avg_logprob": -0.11482687094776901, "compression_ratio": 1.7040816326530612, "no_speech_prob": 2.6015752609964693e-06}, {"id": 910, "seek": 438382, "start": 4390.219999999999, "end": 4395.42, "text": " And if it does change, then it will convert the type back to what it used to be.", "tokens": [400, 498, 309, 775, 1319, 11, 550, 309, 486, 7620, 264, 2010, 646, 281, 437, 309, 1143, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.11482687094776901, "compression_ratio": 1.7040816326530612, "no_speech_prob": 2.6015752609964693e-06}, {"id": 911, "seek": 438382, "start": 4395.42, "end": 4401.219999999999, "text": " But it only does that in a specific situation, which is this one,", "tokens": [583, 309, 787, 775, 300, 294, 257, 2685, 2590, 11, 597, 307, 341, 472, 11], "temperature": 0.0, "avg_logprob": -0.11482687094776901, "compression_ratio": 1.7040816326530612, "no_speech_prob": 2.6015752609964693e-06}, {"id": 912, "seek": 438382, "start": 4401.219999999999, "end": 4406.7, "text": " where you end up with a superclass, torch.tensor, of the input,", "tokens": [689, 291, 917, 493, 365, 257, 1687, 11665, 11, 27822, 13, 83, 23153, 11, 295, 264, 4846, 11], "temperature": 0.0, "avg_logprob": -0.11482687094776901, "compression_ratio": 1.7040816326530612, "no_speech_prob": 2.6015752609964693e-06}, {"id": 913, "seek": 438382, "start": 4406.7, "end": 4410.259999999999, "text": " whereas the input was a subclass of that.", "tokens": [9735, 264, 4846, 390, 257, 1422, 11665, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.11482687094776901, "compression_ratio": 1.7040816326530612, "no_speech_prob": 2.6015752609964693e-06}, {"id": 914, "seek": 438382, "start": 4410.259999999999, "end": 4412.7, "text": " So tensor image is a subclass of tensor.", "tokens": [407, 40863, 3256, 307, 257, 1422, 11665, 295, 40863, 13], "temperature": 0.0, "avg_logprob": -0.11482687094776901, "compression_ratio": 1.7040816326530612, "no_speech_prob": 2.6015752609964693e-06}, {"id": 915, "seek": 441270, "start": 4412.7, "end": 4415.5, "text": " This is something that happens all the time with like pillow subclasses", "tokens": [639, 307, 746, 300, 2314, 439, 264, 565, 365, 411, 18581, 1422, 11665, 279], "temperature": 0.0, "avg_logprob": -0.1301641929440382, "compression_ratio": 1.6195121951219513, "no_speech_prob": 4.637672645912971e-06}, {"id": 916, "seek": 441270, "start": 4415.5, "end": 4422.0599999999995, "text": " and tensor subclasses that very often the operations will forget what subclass it was.", "tokens": [293, 40863, 1422, 11665, 279, 300, 588, 2049, 264, 7705, 486, 2870, 437, 1422, 11665, 309, 390, 13], "temperature": 0.0, "avg_logprob": -0.1301641929440382, "compression_ratio": 1.6195121951219513, "no_speech_prob": 4.637672645912971e-06}, {"id": 917, "seek": 441270, "start": 4422.0599999999995, "end": 4423.46, "text": " So you don't have to do anything.", "tokens": [407, 291, 500, 380, 362, 281, 360, 1340, 13], "temperature": 0.0, "avg_logprob": -0.1301641929440382, "compression_ratio": 1.6195121951219513, "no_speech_prob": 4.637672645912971e-06}, {"id": 918, "seek": 441270, "start": 4423.46, "end": 4431.74, "text": " It will automatically put back the correct subclass for you.", "tokens": [467, 486, 6772, 829, 646, 264, 3006, 1422, 11665, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.1301641929440382, "compression_ratio": 1.6195121951219513, "no_speech_prob": 4.637672645912971e-06}, {"id": 919, "seek": 441270, "start": 4431.74, "end": 4441.34, "text": " It's possible to opt out of that behavior by just putting return type of none.", "tokens": [467, 311, 1944, 281, 2427, 484, 295, 300, 5223, 538, 445, 3372, 2736, 2010, 295, 6022, 13], "temperature": 0.0, "avg_logprob": -0.1301641929440382, "compression_ratio": 1.6195121951219513, "no_speech_prob": 4.637672645912971e-06}, {"id": 920, "seek": 444134, "start": 4441.34, "end": 4448.900000000001, "text": " And that tells the transform system not to do that for you.", "tokens": [400, 300, 5112, 264, 4088, 1185, 406, 281, 360, 300, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.14238523182116056, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.0589970378969156e-07}, {"id": 921, "seek": 444134, "start": 4448.900000000001, "end": 4451.34, "text": " As you can see, it now doesn't pass.", "tokens": [1018, 291, 393, 536, 11, 309, 586, 1177, 380, 1320, 13], "temperature": 0.0, "avg_logprob": -0.14238523182116056, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.0589970378969156e-07}, {"id": 922, "seek": 444134, "start": 4451.34, "end": 4453.34, "text": " So that's how you can opt out of it.", "tokens": [407, 300, 311, 577, 291, 393, 2427, 484, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.14238523182116056, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.0589970378969156e-07}, {"id": 923, "seek": 444134, "start": 4453.34, "end": 4455.58, "text": " I don't think I've ever needed it yet, though.", "tokens": [286, 500, 380, 519, 286, 600, 1562, 2978, 309, 1939, 11, 1673, 13], "temperature": 0.0, "avg_logprob": -0.14238523182116056, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.0589970378969156e-07}, {"id": 924, "seek": 444134, "start": 4455.58, "end": 4459.82, "text": " So far, it always has made sense in everything I've done", "tokens": [407, 1400, 11, 309, 1009, 575, 1027, 2020, 294, 1203, 286, 600, 1096], "temperature": 0.0, "avg_logprob": -0.14238523182116056, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.0589970378969156e-07}, {"id": 925, "seek": 444134, "start": 4459.82, "end": 4464.22, "text": " that you always want to keep the subclass type information.", "tokens": [300, 291, 1009, 528, 281, 1066, 264, 1422, 11665, 2010, 1589, 13], "temperature": 0.0, "avg_logprob": -0.14238523182116056, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.0589970378969156e-07}, {"id": 926, "seek": 444134, "start": 4464.22, "end": 4465.860000000001, "text": " So that all happens automatically.", "tokens": [407, 300, 439, 2314, 6772, 13], "temperature": 0.0, "avg_logprob": -0.14238523182116056, "compression_ratio": 1.6274509803921569, "no_speech_prob": 3.0589970378969156e-07}, {"id": 927, "seek": 446586, "start": 4465.86, "end": 4471.58, "text": " OK, so why is this here?", "tokens": [2264, 11, 370, 983, 307, 341, 510, 30], "temperature": 0.0, "avg_logprob": -0.44046741832386366, "compression_ratio": 1.3277310924369747, "no_speech_prob": 7.368250953732058e-05}, {"id": 928, "seek": 446586, "start": 4471.58, "end": 4473.58, "text": " I don't think this is meant to be here.", "tokens": [286, 500, 380, 519, 341, 307, 4140, 281, 312, 510, 13], "temperature": 0.0, "avg_logprob": -0.44046741832386366, "compression_ratio": 1.3277310924369747, "no_speech_prob": 7.368250953732058e-05}, {"id": 929, "seek": 446586, "start": 4473.58, "end": 4474.58, "text": " I think it's in the wrong spot.", "tokens": [286, 519, 309, 311, 294, 264, 2085, 4008, 13], "temperature": 0.0, "avg_logprob": -0.44046741832386366, "compression_ratio": 1.3277310924369747, "no_speech_prob": 7.368250953732058e-05}, {"id": 930, "seek": 446586, "start": 4481.0599999999995, "end": 4482.38, "text": " Let's double check.", "tokens": [961, 311, 3834, 1520, 13], "temperature": 0.0, "avg_logprob": -0.44046741832386366, "compression_ratio": 1.3277310924369747, "no_speech_prob": 7.368250953732058e-05}, {"id": 931, "seek": 446586, "start": 4482.38, "end": 4484.94, "text": " I think we've got this over here already.", "tokens": [286, 519, 321, 600, 658, 341, 670, 510, 1217, 13], "temperature": 0.0, "avg_logprob": -0.44046741832386366, "compression_ratio": 1.3277310924369747, "no_speech_prob": 7.368250953732058e-05}, {"id": 932, "seek": 448494, "start": 4484.94, "end": 4500.82, "text": " I think O1 core is getting too big.", "tokens": [286, 519, 422, 16, 4965, 307, 1242, 886, 955, 13], "temperature": 0.6, "avg_logprob": -0.7261739571889242, "compression_ratio": 0.9420289855072463, "no_speech_prob": 7.966840348672122e-05}, {"id": 933, "seek": 448494, "start": 4500.82, "end": 4504.9, "text": " We might have to split it up.", "tokens": [492, 1062, 362, 281, 7472, 309, 493, 13], "temperature": 0.6, "avg_logprob": -0.7261739571889242, "compression_ratio": 0.9420289855072463, "no_speech_prob": 7.966840348672122e-05}, {"id": 934, "seek": 450490, "start": 4504.9, "end": 4506.46, "text": " I'll just build it up.", "tokens": [50364, 286, 603, 445, 1322, 309, 493, 13, 50442], "temperature": 1.0, "avg_logprob": -1.364466667175293, "compression_ratio": 0.7333333333333333, "no_speech_prob": 0.22827135026454926}, {"id": 935, "seek": 453490, "start": 4534.9, "end": 4540.9, "text": " Oh, that does look different. That's interesting.", "tokens": [876, 11, 300, 775, 574, 819, 13, 663, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.5168664883344601, "compression_ratio": 1.1727272727272726, "no_speech_prob": 0.14794103801250458}, {"id": 936, "seek": 453490, "start": 4540.9, "end": 4552.9, "text": " It's just adding much. I might leave that out. Okay.", "tokens": [467, 311, 445, 5127, 709, 13, 286, 1062, 1856, 300, 484, 13, 1033, 13], "temperature": 0.0, "avg_logprob": -0.5168664883344601, "compression_ratio": 1.1727272727272726, "no_speech_prob": 0.14794103801250458}, {"id": 937, "seek": 453490, "start": 4552.9, "end": 4558.9, "text": " So here's another example.", "tokens": [407, 510, 311, 1071, 1365, 13], "temperature": 0.0, "avg_logprob": -0.5168664883344601, "compression_ratio": 1.1727272727272726, "no_speech_prob": 0.14794103801250458}, {"id": 938, "seek": 455890, "start": 4558.9, "end": 4568.9, "text": " We've created a class called capital I int. So the normal int in Python is small i int.", "tokens": [492, 600, 2942, 257, 1508, 1219, 4238, 286, 560, 13, 407, 264, 2710, 560, 294, 15329, 307, 1359, 741, 560, 13], "temperature": 0.0, "avg_logprob": -0.15658491308038885, "compression_ratio": 1.4965986394557824, "no_speech_prob": 1.6963318557827733e-05}, {"id": 939, "seek": 455890, "start": 4568.9, "end": 4577.9, "text": " Capital i int is a subclass of that, which is also a subclass of showTitle.", "tokens": [21502, 741, 560, 307, 257, 1422, 11665, 295, 300, 11, 597, 307, 611, 257, 1422, 11665, 295, 855, 51, 270, 306, 13], "temperature": 0.0, "avg_logprob": -0.15658491308038885, "compression_ratio": 1.4965986394557824, "no_speech_prob": 1.6963318557827733e-05}, {"id": 940, "seek": 455890, "start": 4577.9, "end": 4581.9, "text": " So it's a type of int that has a show method, basically.", "tokens": [407, 309, 311, 257, 2010, 295, 560, 300, 575, 257, 855, 3170, 11, 1936, 13], "temperature": 0.0, "avg_logprob": -0.15658491308038885, "compression_ratio": 1.4965986394557824, "no_speech_prob": 1.6963318557827733e-05}, {"id": 941, "seek": 458190, "start": 4581.9, "end": 4595.9, "text": " So we generally, if you want to be able to show an int, then you just put returns a capital I int.", "tokens": [407, 321, 5101, 11, 498, 291, 528, 281, 312, 1075, 281, 855, 364, 560, 11, 550, 291, 445, 829, 11247, 257, 4238, 286, 560, 13], "temperature": 0.0, "avg_logprob": -0.13157528165786986, "compression_ratio": 1.393939393939394, "no_speech_prob": 8.397891178901773e-06}, {"id": 942, "seek": 458190, "start": 4595.9, "end": 4602.9, "text": " And so here, let's see, are we doing a different deal?", "tokens": [400, 370, 510, 11, 718, 311, 536, 11, 366, 321, 884, 257, 819, 2028, 30], "temperature": 0.0, "avg_logprob": -0.13157528165786986, "compression_ratio": 1.393939393939394, "no_speech_prob": 8.397891178901773e-06}, {"id": 943, "seek": 458190, "start": 4602.9, "end": 4607.9, "text": " Yeah. So here we're just basically checking that this type annotation works.", "tokens": [865, 13, 407, 510, 321, 434, 445, 1936, 8568, 300, 341, 2010, 48654, 1985, 13], "temperature": 0.0, "avg_logprob": -0.13157528165786986, "compression_ratio": 1.393939393939394, "no_speech_prob": 8.397891178901773e-06}, {"id": 944, "seek": 460790, "start": 4607.9, "end": 4613.9, "text": " We'll learn more about those type annotations once we look at the transforms notebook.", "tokens": [492, 603, 1466, 544, 466, 729, 2010, 25339, 763, 1564, 321, 574, 412, 264, 35592, 21060, 13], "temperature": 0.0, "avg_logprob": -0.10830383002758026, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.078481702483259e-05}, {"id": 945, "seek": 460790, "start": 4613.9, "end": 4622.9, "text": " But as you can see, all the trends, all the types are following through correctly.", "tokens": [583, 382, 291, 393, 536, 11, 439, 264, 13892, 11, 439, 264, 3467, 366, 3480, 807, 8944, 13], "temperature": 0.0, "avg_logprob": -0.10830383002758026, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.078481702483259e-05}, {"id": 946, "seek": 460790, "start": 4622.9, "end": 4635.9, "text": " Okay. So some of these other things I want to come back to later, specifically how filters work.", "tokens": [1033, 13, 407, 512, 295, 613, 661, 721, 286, 528, 281, 808, 646, 281, 1780, 11, 4682, 577, 15995, 589, 13], "temperature": 0.0, "avg_logprob": -0.10830383002758026, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.078481702483259e-05}, {"id": 947, "seek": 463590, "start": 4635.9, "end": 4640.9, "text": " So let's have a bit more of a look at Dataloader.", "tokens": [407, 718, 311, 362, 257, 857, 544, 295, 257, 574, 412, 9315, 10334, 8312, 13], "temperature": 0.0, "avg_logprob": -0.11399641804311467, "compression_ratio": 1.5856353591160222, "no_speech_prob": 6.438909622374922e-06}, {"id": 948, "seek": 463590, "start": 4640.9, "end": 4647.9, "text": " So I'm just going to show you a couple of pieces of TFMDL, and then we'll go back to Dataloader, and then we'll come back to TFMDL.", "tokens": [407, 286, 478, 445, 516, 281, 855, 291, 257, 1916, 295, 3755, 295, 40964, 44, 35, 43, 11, 293, 550, 321, 603, 352, 646, 281, 9315, 10334, 8312, 11, 293, 550, 321, 603, 808, 646, 281, 40964, 44, 35, 43, 13], "temperature": 0.0, "avg_logprob": -0.11399641804311467, "compression_ratio": 1.5856353591160222, "no_speech_prob": 6.438909622374922e-06}, {"id": 949, "seek": 463590, "start": 4647.9, "end": 4657.9, "text": " One thing that's interesting here is that there is a thing called delegates on the top here, a decorator,", "tokens": [1485, 551, 300, 311, 1880, 510, 307, 300, 456, 307, 257, 551, 1219, 45756, 322, 264, 1192, 510, 11, 257, 7919, 1639, 11], "temperature": 0.0, "avg_logprob": -0.11399641804311467, "compression_ratio": 1.5856353591160222, "no_speech_prob": 6.438909622374922e-06}, {"id": 950, "seek": 465790, "start": 4657.9, "end": 4669.9, "text": " which we have on position.", "tokens": [597, 321, 362, 322, 2535, 13], "temperature": 0.0, "avg_logprob": -0.12153917200425092, "compression_ratio": 1.2769230769230768, "no_speech_prob": 1.4970733900554478e-05}, {"id": 951, "seek": 465790, "start": 4669.9, "end": 4677.9, "text": " There we go. I have described in more detail in this article.", "tokens": [821, 321, 352, 13, 286, 362, 7619, 294, 544, 2607, 294, 341, 7222, 13], "temperature": 0.0, "avg_logprob": -0.12153917200425092, "compression_ratio": 1.2769230769230768, "no_speech_prob": 1.4970733900554478e-05}, {"id": 952, "seek": 465790, "start": 4677.9, "end": 4682.9, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.12153917200425092, "compression_ratio": 1.2769230769230768, "no_speech_prob": 1.4970733900554478e-05}, {"id": 953, "seek": 465790, "start": 4682.9, "end": 4686.9, "text": " But I'll give you a quick summary of what's going on. Have a look here.", "tokens": [583, 286, 603, 976, 291, 257, 1702, 12691, 295, 437, 311, 516, 322, 13, 3560, 257, 574, 510, 13], "temperature": 0.0, "avg_logprob": -0.12153917200425092, "compression_ratio": 1.2769230769230768, "no_speech_prob": 1.4970733900554478e-05}, {"id": 954, "seek": 468690, "start": 4686.9, "end": 4690.9, "text": " So basically, TFMDL is a subclass of Dataloader.", "tokens": [407, 1936, 11, 40964, 44, 35, 43, 307, 257, 1422, 11665, 295, 9315, 10334, 8312, 13], "temperature": 0.0, "avg_logprob": -0.08501451406905901, "compression_ratio": 1.4058823529411764, "no_speech_prob": 6.30221693427302e-05}, {"id": 955, "seek": 468690, "start": 4690.9, "end": 4699.9, "text": " So when we call ThunderInnit, we basically want to pass along any keyword arguments that you gave us.", "tokens": [407, 562, 321, 818, 21023, 4575, 77, 270, 11, 321, 1936, 528, 281, 1320, 2051, 604, 20428, 12869, 300, 291, 2729, 505, 13], "temperature": 0.0, "avg_logprob": -0.08501451406905901, "compression_ratio": 1.4058823529411764, "no_speech_prob": 6.30221693427302e-05}, {"id": 956, "seek": 468690, "start": 4699.9, "end": 4707.9, "text": " The problem is that normally when you put quags like this, there are a couple of issues.", "tokens": [440, 1154, 307, 300, 5646, 562, 291, 829, 421, 12109, 411, 341, 11, 456, 366, 257, 1916, 295, 2663, 13], "temperature": 0.0, "avg_logprob": -0.08501451406905901, "compression_ratio": 1.4058823529411764, "no_speech_prob": 6.30221693427302e-05}, {"id": 957, "seek": 470790, "start": 4707.9, "end": 4718.9, "text": " The first issue is that if we want to use things like shift tab, and we go to TFMDL, and then we say shift tab,", "tokens": [440, 700, 2734, 307, 300, 498, 321, 528, 281, 764, 721, 411, 5513, 4421, 11, 293, 321, 352, 281, 40964, 44, 35, 43, 11, 293, 550, 321, 584, 5513, 4421, 11], "temperature": 0.0, "avg_logprob": -0.0873319404881175, "compression_ratio": 1.5515463917525774, "no_speech_prob": 1.5688934581703506e-05}, {"id": 958, "seek": 470790, "start": 4718.9, "end": 4726.9, "text": " rather than seeing the actual list of things that we can pass in, we would see quags, which is super annoying.", "tokens": [2831, 813, 2577, 264, 3539, 1329, 295, 721, 300, 321, 393, 1320, 294, 11, 321, 576, 536, 421, 12109, 11, 597, 307, 1687, 11304, 13], "temperature": 0.0, "avg_logprob": -0.0873319404881175, "compression_ratio": 1.5515463917525774, "no_speech_prob": 1.5688934581703506e-05}, {"id": 959, "seek": 470790, "start": 4726.9, "end": 4735.9, "text": " But check this out. That's not what happens here. We see the actual arguments.", "tokens": [583, 1520, 341, 484, 13, 663, 311, 406, 437, 2314, 510, 13, 492, 536, 264, 3539, 12869, 13], "temperature": 0.0, "avg_logprob": -0.0873319404881175, "compression_ratio": 1.5515463917525774, "no_speech_prob": 1.5688934581703506e-05}, {"id": 960, "seek": 473590, "start": 4735.9, "end": 4742.9, "text": " How does that happen? And it's not just we see them, but we also have all the normal tab completion for them as well,", "tokens": [1012, 775, 300, 1051, 30, 400, 309, 311, 406, 445, 321, 536, 552, 11, 457, 321, 611, 362, 439, 264, 2710, 4421, 19372, 337, 552, 382, 731, 11], "temperature": 0.0, "avg_logprob": -0.06517974138259888, "compression_ratio": 1.4166666666666667, "no_speech_prob": 6.962045972613851e-06}, {"id": 961, "seek": 473590, "start": 4742.9, "end": 4753.9, "text": " even though those are actually coming from Dataloader.", "tokens": [754, 1673, 729, 366, 767, 1348, 490, 9315, 10334, 8312, 13], "temperature": 0.0, "avg_logprob": -0.06517974138259888, "compression_ratio": 1.4166666666666667, "no_speech_prob": 6.962045972613851e-06}, {"id": 962, "seek": 473590, "start": 4753.9, "end": 4758.9, "text": " The reason that's working is because of this delegates decorator.", "tokens": [440, 1778, 300, 311, 1364, 307, 570, 295, 341, 45756, 7919, 1639, 13], "temperature": 0.0, "avg_logprob": -0.06517974138259888, "compression_ratio": 1.4166666666666667, "no_speech_prob": 6.962045972613851e-06}, {"id": 963, "seek": 475890, "start": 4758.9, "end": 4767.9, "text": " And what the delegates decorator does is it will replace the signature of a class in it or function,", "tokens": [400, 437, 264, 45756, 7919, 1639, 775, 307, 309, 486, 7406, 264, 13397, 295, 257, 1508, 294, 309, 420, 2445, 11], "temperature": 0.0, "avg_logprob": -0.09588064216985935, "compression_ratio": 1.7225130890052356, "no_speech_prob": 1.428508767276071e-05}, {"id": 964, "seek": 475890, "start": 4767.9, "end": 4776.9, "text": " depending on what you put it on. And if you put it on a class, by default, it will take it will remove the quags from the signature", "tokens": [5413, 322, 437, 291, 829, 309, 322, 13, 400, 498, 291, 829, 309, 322, 257, 1508, 11, 538, 7576, 11, 309, 486, 747, 309, 486, 4159, 264, 421, 12109, 490, 264, 13397], "temperature": 0.0, "avg_logprob": -0.09588064216985935, "compression_ratio": 1.7225130890052356, "no_speech_prob": 1.428508767276071e-05}, {"id": 965, "seek": 475890, "start": 4776.9, "end": 4787.9, "text": " and replace them with the arguments of the parent class. And so that's why this works so nicely.", "tokens": [293, 7406, 552, 365, 264, 12869, 295, 264, 2596, 1508, 13, 400, 370, 300, 311, 983, 341, 1985, 370, 9594, 13], "temperature": 0.0, "avg_logprob": -0.09588064216985935, "compression_ratio": 1.7225130890052356, "no_speech_prob": 1.428508767276071e-05}, {"id": 966, "seek": 478790, "start": 4787.9, "end": 4794.9, "text": " So we use this kind of stuff quite a lot. So you'll quite often see quags used in FastAI version 2,", "tokens": [407, 321, 764, 341, 733, 295, 1507, 1596, 257, 688, 13, 407, 291, 603, 1596, 2049, 536, 421, 12109, 1143, 294, 15968, 48698, 3037, 568, 11], "temperature": 0.0, "avg_logprob": -0.08640133792703802, "compression_ratio": 1.5446428571428572, "no_speech_prob": 5.862649231858086e-06}, {"id": 967, "seek": 478790, "start": 4794.9, "end": 4805.9, "text": " but you should find in every case that we've used them, you'll always get proper shift tab and completion support.", "tokens": [457, 291, 820, 915, 294, 633, 1389, 300, 321, 600, 1143, 552, 11, 291, 603, 1009, 483, 2296, 5513, 4421, 293, 19372, 1406, 13], "temperature": 0.0, "avg_logprob": -0.08640133792703802, "compression_ratio": 1.5446428571428572, "no_speech_prob": 5.862649231858086e-06}, {"id": 968, "seek": 478790, "start": 4805.9, "end": 4812.9, "text": " And so if you ever find that's not true, then feel free to let us know, because that would be considered a bug, generally speaking.", "tokens": [400, 370, 498, 291, 1562, 915, 300, 311, 406, 2074, 11, 550, 841, 1737, 281, 718, 505, 458, 11, 570, 300, 576, 312, 4888, 257, 7426, 11, 5101, 4124, 13], "temperature": 0.0, "avg_logprob": -0.08640133792703802, "compression_ratio": 1.5446428571428572, "no_speech_prob": 5.862649231858086e-06}, {"id": 969, "seek": 481290, "start": 4812.9, "end": 4818.9, "text": " So this really does behave like a Dataloader.", "tokens": [407, 341, 534, 775, 15158, 411, 257, 9315, 10334, 8312, 13], "temperature": 0.0, "avg_logprob": -0.15617368334815615, "compression_ratio": 1.2522522522522523, "no_speech_prob": 1.9221393813495524e-05}, {"id": 970, "seek": 481290, "start": 4818.9, "end": 4825.9, "text": " It's a Dataloader which has a few extra things.", "tokens": [467, 311, 257, 9315, 10334, 8312, 597, 575, 257, 1326, 2857, 721, 13], "temperature": 0.0, "avg_logprob": -0.15617368334815615, "compression_ratio": 1.2522522522522523, "no_speech_prob": 1.9221393813495524e-05}, {"id": 971, "seek": 481290, "start": 4825.9, "end": 4833.9, "text": " Perhaps most interestingly, it has showBatch.", "tokens": [10517, 881, 25873, 11, 309, 575, 855, 33, 852, 13], "temperature": 0.0, "avg_logprob": -0.15617368334815615, "compression_ratio": 1.2522522522522523, "no_speech_prob": 1.9221393813495524e-05}, {"id": 972, "seek": 483390, "start": 4833.9, "end": 4842.9, "text": " So showBatch is the thing that we saw over here.", "tokens": [407, 855, 33, 852, 307, 264, 551, 300, 321, 1866, 670, 510, 13], "temperature": 0.0, "avg_logprob": -0.12190008163452148, "compression_ratio": 1.582191780821918, "no_speech_prob": 9.97223560261773e-06}, {"id": 973, "seek": 483390, "start": 4842.9, "end": 4852.9, "text": " We saw it for segmentation showBatch and we saw it for pets showBatch.", "tokens": [492, 1866, 309, 337, 9469, 399, 855, 33, 852, 293, 321, 1866, 309, 337, 19897, 855, 33, 852, 13], "temperature": 0.0, "avg_logprob": -0.12190008163452148, "compression_ratio": 1.582191780821918, "no_speech_prob": 9.97223560261773e-06}, {"id": 974, "seek": 483390, "start": 4852.9, "end": 4862.9, "text": " So the idea is that you can take a tiffmdl and call showBatch and it will know how to display whatever's there.", "tokens": [407, 264, 1558, 307, 300, 291, 393, 747, 257, 256, 3661, 76, 67, 75, 293, 818, 855, 33, 852, 293, 309, 486, 458, 577, 281, 4674, 2035, 311, 456, 13], "temperature": 0.0, "avg_logprob": -0.12190008163452148, "compression_ratio": 1.582191780821918, "no_speech_prob": 9.97223560261773e-06}, {"id": 975, "seek": 486290, "start": 4862.9, "end": 4871.9, "text": " And it even knows how to combine the information from multiple data types, in this case a mask and an image,", "tokens": [400, 309, 754, 3255, 577, 281, 10432, 264, 1589, 490, 3866, 1412, 3467, 11, 294, 341, 1389, 257, 6094, 293, 364, 3256, 11], "temperature": 0.0, "avg_logprob": -0.08783992793824938, "compression_ratio": 1.5416666666666667, "no_speech_prob": 1.4284614735515788e-05}, {"id": 976, "seek": 486290, "start": 4871.9, "end": 4878.9, "text": " in this case an image in a category.", "tokens": [294, 341, 1389, 364, 3256, 294, 257, 7719, 13], "temperature": 0.0, "avg_logprob": -0.08783992793824938, "compression_ratio": 1.5416666666666667, "no_speech_prob": 1.4284614735515788e-05}, {"id": 977, "seek": 486290, "start": 4878.9, "end": 4888.9, "text": " You can pass in a batch to show. If you don't, it will default to one batch, as it says, and as you can see here.", "tokens": [509, 393, 1320, 294, 257, 15245, 281, 855, 13, 759, 291, 500, 380, 11, 309, 486, 7576, 281, 472, 15245, 11, 382, 309, 1619, 11, 293, 382, 291, 393, 536, 510, 13], "temperature": 0.0, "avg_logprob": -0.08783992793824938, "compression_ratio": 1.5416666666666667, "no_speech_prob": 1.4284614735515788e-05}, {"id": 978, "seek": 488890, "start": 4888.9, "end": 4900.9, "text": " And so what it will do is it will first of all decode that batch, and specifically decode means decode using", "tokens": [400, 370, 437, 309, 486, 360, 307, 309, 486, 700, 295, 439, 979, 1429, 300, 15245, 11, 293, 4682, 979, 1429, 1355, 979, 1429, 1228], "temperature": 0.0, "avg_logprob": -0.09164816235739087, "compression_ratio": 1.6503496503496504, "no_speech_prob": 1.1842729691124987e-05}, {"id": 979, "seek": 488890, "start": 4900.9, "end": 4907.9, "text": " decode the afterBatch transform and decode the beforeBatch transform.", "tokens": [979, 1429, 264, 934, 33, 852, 4088, 293, 979, 1429, 264, 949, 33, 852, 4088, 13], "temperature": 0.0, "avg_logprob": -0.09164816235739087, "compression_ratio": 1.6503496503496504, "no_speech_prob": 1.1842729691124987e-05}, {"id": 980, "seek": 488890, "start": 4907.9, "end": 4912.9, "text": " So that's all the stuff that happens after it's collated.", "tokens": [407, 300, 311, 439, 264, 1507, 300, 2314, 934, 309, 311, 1263, 770, 13], "temperature": 0.0, "avg_logprob": -0.09164816235739087, "compression_ratio": 1.6503496503496504, "no_speech_prob": 1.1842729691124987e-05}, {"id": 981, "seek": 491290, "start": 4912.9, "end": 4923.9, "text": " We then have these things called contexts, and contexts is like, it's either the plots, like in this grid of plots,", "tokens": [492, 550, 362, 613, 721, 1219, 30628, 11, 293, 30628, 307, 411, 11, 309, 311, 2139, 264, 28609, 11, 411, 294, 341, 10748, 295, 28609, 11], "temperature": 0.0, "avg_logprob": -0.14594088102641858, "compression_ratio": 1.660919540229885, "no_speech_prob": 1.5935585906845517e-05}, {"id": 982, "seek": 491290, "start": 4923.9, "end": 4927.9, "text": " each one of these will be a different CTX, a different context.", "tokens": [1184, 472, 295, 613, 486, 312, 257, 819, 19529, 55, 11, 257, 819, 4319, 13], "temperature": 0.0, "avg_logprob": -0.14594088102641858, "compression_ratio": 1.660919540229885, "no_speech_prob": 1.5935585906845517e-05}, {"id": 983, "seek": 491290, "start": 4927.9, "end": 4933.9, "text": " For things that display a data frame, each column I think it is, or maybe it's a row, is a different context.", "tokens": [1171, 721, 300, 4674, 257, 1412, 3920, 11, 1184, 7738, 286, 519, 309, 307, 11, 420, 1310, 309, 311, 257, 5386, 11, 307, 257, 819, 4319, 13], "temperature": 0.0, "avg_logprob": -0.14594088102641858, "compression_ratio": 1.660919540229885, "no_speech_prob": 1.5935585906845517e-05}, {"id": 984, "seek": 493390, "start": 4933.9, "end": 4948.9, "text": " So here, if you don't tell it what context to use, it will actually ask the type, the object in the batch to provide it for us.", "tokens": [407, 510, 11, 498, 291, 500, 380, 980, 309, 437, 4319, 281, 764, 11, 309, 486, 767, 1029, 264, 2010, 11, 264, 2657, 294, 264, 15245, 281, 2893, 309, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.10654870323512865, "compression_ratio": 1.3064516129032258, "no_speech_prob": 5.862661055289209e-06}, {"id": 985, "seek": 493390, "start": 4948.9, "end": 4953.9, "text": " We'll learn more about that later.", "tokens": [492, 603, 1466, 544, 466, 300, 1780, 13], "temperature": 0.0, "avg_logprob": -0.10654870323512865, "compression_ratio": 1.3064516129032258, "no_speech_prob": 5.862661055289209e-06}, {"id": 986, "seek": 495390, "start": 4953.9, "end": 4964.9, "text": " And it will then attempt to decode the batch using the afterItem decode.", "tokens": [400, 309, 486, 550, 5217, 281, 979, 1429, 264, 15245, 1228, 264, 934, 3522, 443, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.08063749207390679, "compression_ratio": 1.4857142857142858, "no_speech_prob": 6.339085302897729e-06}, {"id": 987, "seek": 495390, "start": 4964.9, "end": 4980.9, "text": " And it will then attempt to call.show, which we will see.show in more detail later.", "tokens": [400, 309, 486, 550, 5217, 281, 818, 2411, 34436, 11, 597, 321, 486, 536, 2411, 34436, 294, 544, 2607, 1780, 13], "temperature": 0.0, "avg_logprob": -0.08063749207390679, "compression_ratio": 1.4857142857142858, "no_speech_prob": 6.339085302897729e-06}, {"id": 988, "seek": 498090, "start": 4980.9, "end": 4988.9, "text": " You'll see that we're often using things like compose, so hopefully you've seen that from previous FastAI,", "tokens": [509, 603, 536, 300, 321, 434, 2049, 1228, 721, 411, 35925, 11, 370, 4696, 291, 600, 1612, 300, 490, 3894, 15968, 48698, 11], "temperature": 0.0, "avg_logprob": -0.10529458217131786, "compression_ratio": 1.5502645502645502, "no_speech_prob": 7.296186595340259e-06}, {"id": 989, "seek": 498090, "start": 4988.9, "end": 4997.9, "text": " that basically compose is going to call this function and then this function.", "tokens": [300, 1936, 35925, 307, 516, 281, 818, 341, 2445, 293, 550, 341, 2445, 13], "temperature": 0.0, "avg_logprob": -0.10529458217131786, "compression_ratio": 1.5502645502645502, "no_speech_prob": 7.296186595340259e-06}, {"id": 990, "seek": 498090, "start": 4997.9, "end": 5000.9, "text": " This is a really useful idiom.", "tokens": [639, 307, 257, 534, 4420, 18014, 298, 13], "temperature": 0.0, "avg_logprob": -0.10529458217131786, "compression_ratio": 1.5502645502645502, "no_speech_prob": 7.296186595340259e-06}, {"id": 991, "seek": 498090, "start": 5000.9, "end": 5009.9, "text": " If your data set has a decode method, then this will get self.dataset.decode.", "tokens": [759, 428, 1412, 992, 575, 257, 979, 1429, 3170, 11, 550, 341, 486, 483, 2698, 13, 20367, 296, 302, 13, 1479, 22332, 13], "temperature": 0.0, "avg_logprob": -0.10529458217131786, "compression_ratio": 1.5502645502645502, "no_speech_prob": 7.296186595340259e-06}, {"id": 992, "seek": 500990, "start": 5009.9, "end": 5013.9, "text": " If it doesn't, it will get noop, so it does nothing.", "tokens": [759, 309, 1177, 380, 11, 309, 486, 483, 572, 404, 11, 370, 309, 775, 1825, 13], "temperature": 0.0, "avg_logprob": -0.1542144332613264, "compression_ratio": 1.2357723577235773, "no_speech_prob": 2.7106549168820493e-05}, {"id": 993, "seek": 500990, "start": 5013.9, "end": 5020.9, "text": " That's a nice easy way to do that.", "tokens": [663, 311, 257, 1481, 1858, 636, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1542144332613264, "compression_ratio": 1.2357723577235773, "no_speech_prob": 2.7106549168820493e-05}, {"id": 994, "seek": 500990, "start": 5020.9, "end": 5024.9, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1542144332613264, "compression_ratio": 1.2357723577235773, "no_speech_prob": 2.7106549168820493e-05}, {"id": 995, "seek": 500990, "start": 5024.9, "end": 5030.9, "text": " So, yeah, that's probably enough for now.", "tokens": [407, 11, 1338, 11, 300, 311, 1391, 1547, 337, 586, 13], "temperature": 0.0, "avg_logprob": -0.1542144332613264, "compression_ratio": 1.2357723577235773, "no_speech_prob": 2.7106549168820493e-05}, {"id": 996, "seek": 500990, "start": 5030.9, "end": 5032.9, "text": " That's 90 minutes.", "tokens": [663, 311, 4289, 2077, 13], "temperature": 0.0, "avg_logprob": -0.1542144332613264, "compression_ratio": 1.2357723577235773, "no_speech_prob": 2.7106549168820493e-05}, {"id": 997, "seek": 503290, "start": 5032.9, "end": 5042.9, "text": " Oh, the other thing you'll see is we kind of generally have documentation and examples for the kind of high level, how the class works first.", "tokens": [876, 11, 264, 661, 551, 291, 603, 536, 307, 321, 733, 295, 5101, 362, 14333, 293, 5110, 337, 264, 733, 295, 1090, 1496, 11, 577, 264, 1508, 1985, 700, 13], "temperature": 0.0, "avg_logprob": -0.08976578712463379, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.041424633920542e-06}, {"id": 998, "seek": 503290, "start": 5042.9, "end": 5051.9, "text": " And then underneath it, you'll have a subsection called methods, where we go through each method and show you how to use each method separately.", "tokens": [400, 550, 7223, 309, 11, 291, 603, 362, 257, 1422, 11963, 1219, 7150, 11, 689, 321, 352, 807, 1184, 3170, 293, 855, 291, 577, 281, 764, 1184, 3170, 14759, 13], "temperature": 0.0, "avg_logprob": -0.08976578712463379, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.041424633920542e-06}, {"id": 999, "seek": 503290, "start": 5051.9, "end": 5056.9, "text": " And again, there's lots of room to add more pros and examples to a lot of these.", "tokens": [400, 797, 11, 456, 311, 3195, 295, 1808, 281, 909, 544, 6267, 293, 5110, 281, 257, 688, 295, 613, 13], "temperature": 0.0, "avg_logprob": -0.08976578712463379, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.041424633920542e-06}, {"id": 1000, "seek": 505690, "start": 5056.9, "end": 5065.9, "text": " But every one of them has at least one example, so you can see how each thing works independently.", "tokens": [583, 633, 472, 295, 552, 575, 412, 1935, 472, 1365, 11, 370, 291, 393, 536, 577, 1184, 551, 1985, 21761, 13], "temperature": 0.0, "avg_logprob": -0.09973492733267851, "compression_ratio": 1.485981308411215, "no_speech_prob": 7.646311132702976e-06}, {"id": 1001, "seek": 505690, "start": 5065.9, "end": 5066.9, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.09973492733267851, "compression_ratio": 1.485981308411215, "no_speech_prob": 7.646311132702976e-06}, {"id": 1002, "seek": 505690, "start": 5066.9, "end": 5076.9, "text": " So next time we will at least make sure we go through and finish off the CUDA, byte to float transform, normalization and data bunch.", "tokens": [407, 958, 565, 321, 486, 412, 1935, 652, 988, 321, 352, 807, 293, 2413, 766, 264, 29777, 7509, 11, 40846, 281, 15706, 4088, 11, 2710, 2144, 293, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.09973492733267851, "compression_ratio": 1.485981308411215, "no_speech_prob": 7.646311132702976e-06}, {"id": 1003, "seek": 505690, "start": 5076.9, "end": 5080.9, "text": " And then not quite sure where we'll go from there, but we will figure it out.", "tokens": [400, 550, 406, 1596, 988, 689, 321, 603, 352, 490, 456, 11, 457, 321, 486, 2573, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.09973492733267851, "compression_ratio": 1.485981308411215, "no_speech_prob": 7.646311132702976e-06}, {"id": 1004, "seek": 505690, "start": 5080.9, "end": 5081.9, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.09973492733267851, "compression_ratio": 1.485981308411215, "no_speech_prob": 7.646311132702976e-06}, {"id": 1005, "seek": 508190, "start": 5081.9, "end": 5091.9, "text": " Thanks, everybody, for joining in and thanks also for those of you who have been so helpful in adding some documentation and notes and stuff on the forums.", "tokens": [2561, 11, 2201, 11, 337, 5549, 294, 293, 3231, 611, 337, 729, 295, 291, 567, 362, 668, 370, 4961, 294, 5127, 512, 14333, 293, 5570, 293, 1507, 322, 264, 26998, 13], "temperature": 0.0, "avg_logprob": -0.0763096312681834, "compression_ratio": 1.416058394160584, "no_speech_prob": 1.4046619980945252e-05}, {"id": 1006, "seek": 508190, "start": 5091.9, "end": 5093.9, "text": " That is super cool.", "tokens": [663, 307, 1687, 1627, 13], "temperature": 0.0, "avg_logprob": -0.0763096312681834, "compression_ratio": 1.416058394160584, "no_speech_prob": 1.4046619980945252e-05}, {"id": 1007, "seek": 509390, "start": 5093.9, "end": 5112.9, "text": " See you next time.", "tokens": [50364, 3008, 291, 958, 565, 13, 51314], "temperature": 0.0, "avg_logprob": -0.26605579257011414, "compression_ratio": 0.6923076923076923, "no_speech_prob": 1.854503898357507e-05}], "language": "en"}